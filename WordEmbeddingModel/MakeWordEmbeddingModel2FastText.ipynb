{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbee066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import fasttext\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import spearmanr\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4fe4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relatedness(model):\n",
    "    # Baca file rw untuk evaluasi word embedding dengan teknik relatedness cbow\n",
    "    dir_file = '/Users/williamnehemia/Documents/Skripsi/TugasAkhir/DataEvaluasiGitHub/word-similarity/monolingual/en/rw.csv'\n",
    "    list_model_similarity = []\n",
    "    words_exist = []\n",
    "    words_not_exist = []\n",
    "    list_human_score = []\n",
    "    \n",
    "    df = pd.read_csv(dir_file)\n",
    "    list_human_score = df['similarity'].to_list()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        word_1 = row[\"word1\"].lower()\n",
    "        word_2 = row[\"word2\"].lower()\n",
    "        try:\n",
    "            wv_1 = []\n",
    "            wv_2 = []\n",
    "            wv_1.append(model.get_word_vector(word_1))\n",
    "            \n",
    "            if word_1 not in words_exist:\n",
    "                words_exist.append(word_1)\n",
    "            \n",
    "            wv_2.append(model.get_word_vector(word_2))\n",
    "            \n",
    "            if word_2 not in words_exist:\n",
    "                words_exist.append(word_2)\n",
    "                \n",
    "            similarity = cosine_similarity(wv_1, wv_2)[0][0]\n",
    "            list_model_similarity.append(similarity)\n",
    "            \n",
    "        except:\n",
    "            if word_1 in words_exist: # kata 2 yang tidak ada di model\n",
    "                if word_2 not in words_not_exist:\n",
    "                    words_not_exist.append(word_2)\n",
    "            \n",
    "            if word_2 in words_exist: # kata 1 yang tidak ada di model\n",
    "                if word_1 not in words_not_exist:\n",
    "                    words_not_exist.append(word_1)\n",
    "        \n",
    "    \n",
    "   \n",
    "        \n",
    "\n",
    "    rho_model, p_model = spearmanr(list_model_similarity, list_human_score)\n",
    "    print(\"banyak kata ada di model\", len(words_exist))\n",
    "    print(\"banyak kata tidak ada di model\", len(words_not_exist))\n",
    "    return rho_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e9ac14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_analogy(model):\n",
    "    # Baca file word_analogy untuk evaluasi word embedding dengan teknik word analogy (menggunakan library)\n",
    "\n",
    "    dir_file = '/Users/williamnehemia/Documents/Skripsi/TugasAkhir/DataEvaluasiGitHub/word-analogy/monolingual/en/semeval.csv'\n",
    "    df = pd.read_csv(dir_file)\n",
    "    true_predicted = 0\n",
    "    false_predicted = 0\n",
    "    words_exist = []\n",
    "    words_not_exist = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        word_1 = row[\"word1\"].lower()\n",
    "        word_2 = row[\"word2\"].lower()\n",
    "        word_3 = row[\"word3\"].lower()\n",
    "        word_4 = row[\"target\"].lower()\n",
    "        word_predicted_curr = \"\"\n",
    "        try:\n",
    "            list_of_result_analogy = model.get_analogies(word_1, word_2, word_3)\n",
    "            word_predicted_curr = list_of_result_analogy[0][1] \n",
    "            if word_predicted_curr == word_4:\n",
    "                true_predicted += 1\n",
    "            else:\n",
    "                false_predicted += 1\n",
    "            \n",
    "            if word_1 not in words_exist:\n",
    "                words_exist.append(word_1)\n",
    "            \n",
    "            if word_2 not in words_exist:\n",
    "                words_exist.append(word_2)\n",
    "            \n",
    "            if word_3 not in words_exist:\n",
    "                words_exist.append(word_3)\n",
    "            \n",
    "            if word_4 not in words_exist:\n",
    "                words_exist.append(word_4)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        # untuk menambahkan word_1 jika tidak ada di model    \n",
    "        try:\n",
    "            word_vector = model.get_word_vector(word_1)\n",
    "        except:\n",
    "            if word_1 not in words_not_exist:\n",
    "                    words_not_exist.append(word_1)\n",
    "        \n",
    "        # untuk menambahkan word_2 jika tidak ada di model    \n",
    "        try:\n",
    "            word_vector = model.get_word_vector(word_2)\n",
    "        except:\n",
    "            if word_2 not in words_not_exist:\n",
    "                    words_not_exist.append(word_2)\n",
    "\n",
    "        # untuk menambahkan word_3 jika tidak ada di model    \n",
    "        try:\n",
    "            word_vector = model.get_word_vector(word_3)\n",
    "        except:\n",
    "            if word_3 not in words_not_exist:\n",
    "                    words_not_exist.append(word_3)\n",
    "        \n",
    "        # untuk menambahkan word_4 jika tidak ada di model    \n",
    "        try:\n",
    "            word_vector = model.get_word_vector(word_4)\n",
    "        except:\n",
    "            if word_4 not in words_not_exist:\n",
    "                    words_not_exist.append(word_4)\n",
    "\n",
    "    print(\"true_predicted\", true_predicted, true_predicted / (true_predicted+false_predicted))\n",
    "    print(\"false_predicted\", false_predicted, false_predicted / (true_predicted+false_predicted))\n",
    "    print(\"banyak kata ada di model\", len(words_exist))\n",
    "    print(\"banyak kata tidak ada di model\", len(words_not_exist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d32bf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil jumlah paragraf dari file asli per dokumen\n",
    "directory_path_real = '/Users/williamnehemia/Documents/Skripsi/TugasAkhir/DataPreprocessing/DataTahap7(DataCleaning)'\n",
    "\n",
    "files_real = os.listdir(directory_path_real)\n",
    "list_files_real = []\n",
    "all_text_real = \"\"\n",
    "\n",
    "# Ambil daftar nama file\n",
    "for file in files_real:\n",
    "    if '.DS_Store' not in file:\n",
    "        list_files_real.append(file)\n",
    "        \n",
    "all_text_real = \"\"\n",
    "for file in list_files_real:\n",
    "    with open('/Users/williamnehemia/Documents/Skripsi/TugasAkhir/DataPreprocessing/DataTahap7(DataCleaning)/' + file, 'r') as fileNow:\n",
    "        content = fileNow.read()\n",
    "        all_text_real += content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3912b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil jumlah paragraf dari file parafrasa per dokumen\n",
    "directory_path_paraphrased = '/Users/williamnehemia/Documents/Skripsi/TugasAkhir/WordEmbeddingModel/Data/Data_parafrasa'\n",
    "\n",
    "files_paraphrased = os.listdir(directory_path_paraphrased)\n",
    "list_files_paraphrased = []\n",
    "all_text_paraphrased = \"\"\n",
    "\n",
    "# Ambil daftar nama file\n",
    "for file in files_paraphrased:\n",
    "    if '.DS_Store' not in file:\n",
    "        list_files_paraphrased.append(file)\n",
    "        \n",
    "all_text_paraphrased = \"\"\n",
    "for file in list_files_paraphrased:\n",
    "    with open('/Users/williamnehemia/Documents/Skripsi/TugasAkhir/WordEmbeddingModel/Data/Data_parafrasa/' + file, 'r') as fileNow:\n",
    "        content = fileNow.read()\n",
    "        all_text_paraphrased += content\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b7ddee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan lowercase lagi\n",
    "all_text_real = all_text_real.lower()\n",
    "all_text_paraphrased = all_text_paraphrased.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d898285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggabungkan teks asli dan parafrasa\n",
    "all_text = all_text_real + '\\n' + all_text_paraphrased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db45969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hanya mengambil huruf dan titik\n",
    "all_text = re.sub(r'[^a-zA-Z.]', ' ', all_text)\n",
    "all_text = re.sub(r'\\s+', ' ', all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5445f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat file sementara\n",
    "with open('/Users/williamnehemia/Documents/Skripsi/TugasAkhir/WordEmbeddingModel/Data/dataCurr.txt', 'w') as file:\n",
    "    file.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67ae6d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  73023\n",
      "Number of labels: 0\n",
      "Progress:  99.9% words/sec/thread:  196221 lr:  0.000005 avg.loss:  1.779276 ETA:   0h 0m 0s  4.4% words/sec/thread:  289668 lr:  0.009561 avg.loss:  2.306376 ETA:   0h 2m22s  5.3% words/sec/thread:  284993 lr:  0.009466 avg.loss:  2.265436 ETA:   0h 2m22s0.009145 avg.loss:  2.182118 ETA:   0h 2m21s 12.6% words/sec/thread:  262765 lr:  0.008740 avg.loss:  2.094773 ETA:   0h 2m23savg.loss:  2.080030 ETA:   0h 2m25s 14.9% words/sec/thread:  247337 lr:  0.008510 avg.loss:  2.063075 ETA:   0h 2m28s 20.6% words/sec/thread:  238072 lr:  0.007943 avg.loss:  2.020056 ETA:   0h 2m23s 24.4% words/sec/thread:  230981 lr:  0.007556 avg.loss:  1.997369 ETA:   0h 2m20s 26.4% words/sec/thread:  226428 lr:  0.007358 avg.loss:  1.989278 ETA:   0h 2m19s 27.0% words/sec/thread:  226072 lr:  0.007304 avg.loss:  1.987154 ETA:   0h 2m19s 29.2% words/sec/thread:  224063 lr:  0.007084 avg.loss:  1.981219 ETA:   0h 2m16s% words/sec/thread:  220074 lr:  0.006537 avg.loss:  1.956773 ETA:   0h 2m 7s 35.7% words/sec/thread:  219265 lr:  0.006430 avg.loss:  1.953017 ETA:   0h 2m 6s 38.8% words/sec/thread:  214861 lr:  0.006118 avg.loss:  1.944793 ETA:   0h 2m 2s 40.5% words/sec/thread:  215010 lr:  0.005948 avg.loss:  1.942041 ETA:   0h 1m59savg.loss:  1.940695 ETA:   0h 1m57s 45.5% words/sec/thread:  213705 lr:  0.005445 avg.loss:  1.927814 ETA:   0h 1m49s 51.5% words/sec/thread:  215642 lr:  0.004847 avg.loss:  1.919906 ETA:   0h 1m36s 54.7% words/sec/thread:  215622 lr:  0.004530 avg.loss:  1.915715 ETA:   0h 1m30s 56.8% words/sec/thread:  216158 lr:  0.004316 avg.loss:  1.913637 ETA:   0h 1m25s215176 lr:  0.004173 avg.loss:  1.912485 ETA:   0h 1m23s 59.7% words/sec/thread:  210726 lr:  0.004029 avg.loss:  1.911638 ETA:   0h 1m22s 60.7% words/sec/thread:  208509 lr:  0.003934 avg.loss:  1.911213 ETA:   0h 1m21s 62.6% words/sec/thread:  205368 lr:  0.003741 avg.loss:  1.910736 ETA:   0h 1m18s 62.8% words/sec/thread:  205080 lr:  0.003720 avg.loss:  1.910573 ETA:   0h 1m18s 70.7% words/sec/thread:  193954 lr:  0.002930 avg.loss:  1.900302 ETA:   0h 1m 5s 74.9% words/sec/thread:  187858 lr:  0.002508 avg.loss:  1.892415 ETA:   0h 0m57s 0.002387 avg.loss:  1.890428 ETA:   0h 0m54s 88.2% words/sec/thread:  191346 lr:  0.001183 avg.loss:  1.839000 ETA:   0h 0m26s 89.7% words/sec/thread:  191817 lr:  0.001032 avg.loss:  1.831061 ETA:   0h 0m23s 98.6% words/sec/thread:  195777 lr:  0.000145 avg.loss:  1.785770 ETA:   0h 0m 3s 99.4% words/sec/thread:  196037 lr:  0.000057 avg.loss:  1.781662 ETA:   0h 0m 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 0 hours 3 minutes 40 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress: 100.0% words/sec/thread:  196238 lr: -0.000000 avg.loss:  1.779026 ETA:   0h 0m 0s\r",
      "Progress: 100.0% words/sec/thread:  196238 lr:  0.000000 avg.loss:  1.779026 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Membuat model word embedding fasttext menggunakan CBOW 1\n",
    "\n",
    "# waktu mulai\n",
    "start_time = time.time()\n",
    "\n",
    "model_cbow = fasttext.train_unsupervised(input='/Users/williamnehemia/Documents/Skripsi/TugasAkhir/WordEmbeddingModel/Data/dataCurr.txt', model='cbow', lr=0.01, dim=20, ws=5, epoch=100, minCount=1, minn=3, maxn=3, thread=10)\n",
    "\n",
    "# waktu selesai\n",
    "end_time = time.time()\n",
    "\n",
    "# hitung waktu training\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# convert ke jam, menit, detik\n",
    "hours = int(training_time // 3600)\n",
    "minutes = int((training_time % 3600) // 60)\n",
    "seconds = int(training_time % 60)\n",
    "\n",
    "print(\"Total training time:\", hours, \"hours\", minutes, \"minutes\", seconds, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7205683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_cbow.save_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_cbow_fasttext_1.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a784771c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_cbow = fasttext.load_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_cbow_fasttext_1.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96056d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyak kata ada di model 2951\n",
      "banyak kata tidak ada di model 0\n",
      "0.18404157070874463\n"
     ]
    }
   ],
   "source": [
    "# relatedness model cbow 1\n",
    "print(relatedness(model_cbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88f125de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_predicted 1 9.986019572598362e-05\n",
      "false_predicted 10013 0.9999001398042741\n",
      "banyak kata ada di model 3233\n",
      "banyak kata tidak ada di model 0\n"
     ]
    }
   ],
   "source": [
    "# word analogy model cbow 1\n",
    "word_analogy(model_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe28693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  73023\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   70146 lr:  0.000000 avg.loss:  0.700793 ETA:   0h 0m 0s  2.0% words/sec/thread:  120453 lr:  0.009801 avg.loss:  2.090265 ETA:   0h 5m50s  3.4% words/sec/thread:  111408 lr:  0.009662 avg.loss:  2.075347 ETA:   0h 6m13s  4.4% words/sec/thread:  106813 lr:  0.009555 avg.loss:  2.069773 ETA:   0h 6m24s  6.0% words/sec/thread:   98863 lr:  0.009401 avg.loss:  2.068552 ETA:   0h 6m49s  6.1% words/sec/thread:   98532 lr:  0.009389 avg.loss:  2.069732 ETA:   0h 6m49s  6.7% words/sec/thread:   95575 lr:  0.009332 avg.loss:  2.074458 ETA:   0h 7m 0savg.loss:  2.076156 ETA:   0h 7m 9s  7.8% words/sec/thread:   89922 lr:  0.009220 avg.loss:  2.081098 ETA:   0h 7m21s  8.2% words/sec/thread:   88669 lr:  0.009179 avg.loss:  2.083637 ETA:   0h 7m25s  8.2% words/sec/thread:   88641 lr:  0.009177 avg.loss:  2.083841 ETA:   0h 7m25s  8.5% words/sec/thread:   88462 lr:  0.009147 avg.loss:  2.084312 ETA:   0h 7m24s  9.2% words/sec/thread:   87433 lr:  0.009076 avg.loss:  2.086625 ETA:   0h 7m26s 10.6% words/sec/thread:   85540 lr:  0.008938 avg.loss:  2.088360 ETA:   0h 7m29s 11.1% words/sec/thread:   85360 lr:  0.008885 avg.loss:  2.089168 ETA:   0h 7m27s 11.6% words/sec/thread:   85021 lr:  0.008837 avg.loss:  2.087833 ETA:   0h 7m27s 12.7% words/sec/thread:   83811 lr:  0.008731 avg.loss:  2.063483 ETA:   0h 7m28s 13.6% words/sec/thread:   83526 lr:  0.008638 avg.loss:  2.046735 ETA:   0h 7m24s 14.1% words/sec/thread:   83401 lr:  0.008587 avg.loss:  2.037555 ETA:   0h 7m22s19s 16.7% words/sec/thread:   79989 lr:  0.008327 avg.loss:  2.002612 ETA:   0h 7m27s 18.3% words/sec/thread:   74670 lr:  0.008175 avg.loss:  1.988566 ETA:   0h 7m51s 18.4% words/sec/thread:   74178 lr:  0.008159 avg.loss:  1.987018 ETA:   0h 7m53s 18.6% words/sec/thread:   73645 lr:  0.008142 avg.loss:  1.985353 ETA:   0h 7m55s 19.7% words/sec/thread:   71001 lr:  0.008027 avg.loss:  1.975341 ETA:   0h 8m 6s 19.9% words/sec/thread:   70702 lr:  0.008010 avg.loss:  1.973831 ETA:   0h 8m 7s 20.2% words/sec/thread:   70065 lr:  0.007976 avg.loss:  1.970018 ETA:   0h 8m 9s 20.4% words/sec/thread:   69664 lr:  0.007959 avg.loss:  1.968207 ETA:   0h 8m11s20.7% words/sec/thread:   69152 lr:  0.007934 avg.loss:  1.966455 ETA:   0h 8m13s 20.7% words/sec/thread:   69003 lr:  0.007927 avg.loss:  1.965824 ETA:   0h 8m14s 21.2% words/sec/thread:   68060 lr:  0.007876 avg.loss:  1.961854 ETA:   0h 8m17s 21.4% words/sec/thread:   67780 lr:  0.007859 avg.loss:  1.960699 ETA:   0h 8m18s 21.6% words/sec/thread:   67483 lr:  0.007843 avg.loss:  1.959656 ETA:   0h 8m20s  66947 lr:  0.007810 avg.loss:  1.957686 ETA:   0h 8m21s 22.1% words/sec/thread:   66694 lr:  0.007793 avg.loss:  1.956286 ETA:   0h 8m22s 22.5% words/sec/thread:   65919 lr:  0.007749 avg.loss:  1.953200 ETA:   0h 8m25s 22.7% words/sec/thread:   65522 lr:  0.007728 avg.loss:  1.951792 ETA:   0h 8m27s 23.2% words/sec/thread:   64453 lr:  0.007678 avg.loss:  1.948714 ETA:   0h 8m32s 23.4% words/sec/thread:   64169 lr:  0.007661 avg.loss:  1.947717 ETA:   0h 8m33s 23.9% words/sec/thread:   63563 lr:  0.007612 avg.loss:  1.945038 ETA:   0h 8m35s 0.007566 avg.loss:  1.942325 ETA:   0h 8m37s 24.7% words/sec/thread:   62347 lr:  0.007527 avg.loss:  1.940280 ETA:   0h 8m39s 25.1% words/sec/thread:   61823 lr:  0.007493 avg.loss:  1.933277 ETA:   0h 8m41s61626 lr:  0.007478 avg.loss:  1.923266 ETA:   0h 8m42s words/sec/thread:   61436 lr:  0.007462 avg.loss:  1.913801 ETA:   0h 8m42s 25.6% words/sec/thread:   61236 lr:  0.007445 avg.loss:  1.903232 ETA:   0h 8m43s 25.9% words/sec/thread:   60736 lr:  0.007412 avg.loss:  1.883650 ETA:   0h 8m45s 27.2% words/sec/thread:   59189 lr:  0.007277 avg.loss:  1.809451 ETA:   0h 8m49s  58575 lr:  0.007211 avg.loss:  1.775262 ETA:   0h 8m49s 28.4% words/sec/thread:   58106 lr:  0.007163 avg.loss:  1.751580 ETA:   0h 8m50s words/sec/thread:   57289 lr:  0.007034 avg.loss:  1.691029 ETA:   0h 8m48s 29.9% words/sec/thread:   57103 lr:  0.007012 avg.loss:  1.681156 ETA:   0h 8m48s 30.5% words/sec/thread:   56692 lr:  0.006947 avg.loss:  1.651739 ETA:   0h 8m47s 30.7% words/sec/thread:   56582 lr:  0.006933 avg.loss:  1.645392 ETA:   0h 8m47s44s 32.0% words/sec/thread:   55964 lr:  0.006801 avg.loss:  1.591460 ETA:   0h 8m42s 32.5% words/sec/thread:   55743 lr:  0.006752 avg.loss:  1.572574 ETA:   0h 8m41s 37.8% words/sec/thread:   58346 lr:  0.006220 avg.loss:  1.398134 ETA:   0h 7m38s 38.1% words/sec/thread:   58487 lr:  0.006193 avg.loss:  1.390469 ETA:   0h 7m35s 0.006175 avg.loss:  1.385694 ETA:   0h 7m33s 40.3% words/sec/thread:   59740 lr:  0.005970 avg.loss:  1.330894 ETA:   0h 7m 9s 41.6% words/sec/thread:   60122 lr:  0.005843 avg.loss:  1.299044 ETA:   0h 6m58s 47.7% words/sec/thread:   63170 lr:  0.005233 avg.loss:  1.171088 ETA:   0h 5m56s words/sec/thread:   64196 lr:  0.004976 avg.loss:  1.122511 ETA:   0h 5m33sss:  1.115211 ETA:   0h 5m30s64448 lr:  0.004854 avg.loss:  1.100881 ETA:   0h 5m24s 52.7% words/sec/thread:   64709 lr:  0.004733 avg.loss:  1.080994 ETA:   0h 5m14s words/sec/thread:   64808 lr:  0.004675 avg.loss:  1.071811 ETA:   0h 5m10sss:  1.065914 ETA:   0h 5m 7s 54.5% words/sec/thread:   65063 lr:  0.004553 avg.loss:  1.053510 ETA:   0h 5m 1s 1.013180 ETA:   0h 4m40s 82.1% words/sec/thread:   69707 lr:  0.001786 avg.loss:  0.793367 ETA:   0h 1m50s 82.7% words/sec/thread:   69718 lr:  0.001733 avg.loss:  0.790140 ETA:   0h 1m46s   69754 lr:  0.001676 avg.loss:  0.786696 ETA:   0h 1m43s84.8% words/sec/thread:   69790 lr:  0.001519 avg.loss:  0.777328 ETA:   0h 1m33s 85.2% words/sec/thread:   69820 lr:  0.001479 avg.loss:  0.775048 ETA:   0h 1m31s 88.1% words/sec/thread:   70019 lr:  0.001194 avg.loss:  0.759054 ETA:   0h 1m13s 93.2% words/sec/thread:   70327 lr:  0.000684 avg.loss:  0.732066 ETA:   0h 0m41savg.loss:  0.729988 ETA:   0h 0m39s 97.0% words/sec/thread:   70720 lr:  0.000301 avg.loss:  0.713742 ETA:   0h 0m18s   70754 lr:  0.000242 avg.loss:  0.711117 ETA:   0h 0m14s% words/sec/thread:   70438 lr:  0.000065 avg.loss:  0.703534 ETA:   0h 0m 3s 99.6% words/sec/thread:   70330 lr:  0.000040 avg.loss:  0.702483 ETA:   0h 0m 2s 99.8% words/sec/thread:   70241 lr:  0.000021 avg.loss:  0.701695 ETA:   0h 0m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 0 hours 10 minutes 14 seconds\n"
     ]
    }
   ],
   "source": [
    "# Membuat model word embedding fasttext menggunakan skip gram 1\n",
    "\n",
    "# waktu mulai\n",
    "start_time = time.time()\n",
    "\n",
    "model_sg = fasttext.train_unsupervised(input='/Users/williamnehemia/Documents/Skripsi/TugasAkhir/WordEmbeddingModel/Data/dataCurr.txt', model='skipgram', lr=0.01, dim=20, ws=5, epoch=100, minCount=1, minn=3, maxn=3, thread=10)\n",
    "\n",
    "# waktu selesai\n",
    "end_time = time.time()\n",
    "\n",
    "# hitung waktu training\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# convert ke jam, menit, detik\n",
    "hours = int(training_time // 3600)\n",
    "minutes = int((training_time % 3600) // 60)\n",
    "seconds = int(training_time % 60)\n",
    "\n",
    "print(\"Total training time:\", hours, \"hours\", minutes, \"minutes\", seconds, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "294b267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_sg.save_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_sg_fasttext_1.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdd5e282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_sg = fasttext.load_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_sg_fasttext_1.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85b801d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyak kata ada di model 2951\n",
      "banyak kata tidak ada di model 0\n",
      "0.19614537472060697\n"
     ]
    }
   ],
   "source": [
    "# relatedness model sg 1\n",
    "print(relatedness(model_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87bd66e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_predicted 9 0.0008987417615338526\n",
      "false_predicted 10005 0.9991012582384662\n",
      "banyak kata ada di model 3233\n",
      "banyak kata tidak ada di model 0\n"
     ]
    }
   ],
   "source": [
    "# word analogy model sg 1\n",
    "word_analogy(model_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "658e5717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  73023\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:  137938 lr:  0.000000 avg.loss:  2.090869 ETA:   0h 0m 0s  2.4% words/sec/thread:  267271 lr:  0.000976 avg.loss:  3.403772 ETA:   0h 2m37s  7.6% words/sec/thread:  244464 lr:  0.000924 avg.loss:  2.700732 ETA:   0h 2m42s 11.2% words/sec/thread:  228339 lr:  0.000888 avg.loss:  2.586280 ETA:   0h 2m47s 18.1% words/sec/thread:  214613 lr:  0.000819 avg.loss:  2.479659 ETA:   0h 2m44s 20.4% words/sec/thread:  209762 lr:  0.000796 avg.loss:  2.453553 ETA:   0h 2m43s 21.9% words/sec/thread:  206488 lr:  0.000781 avg.loss:  2.438140 ETA:   0h 2m42s 23.3% words/sec/thread:  204844 lr:  0.000767 avg.loss:  2.424301 ETA:   0h 2m41s 25.3% words/sec/thread:  203120 lr:  0.000747 avg.loss:  2.404988 ETA:   0h 2m38s 26.6% words/sec/thread:  201346 lr:  0.000734 avg.loss:  2.393816 ETA:   0h 2m36s 31.5% words/sec/thread:  198568 lr:  0.000685 avg.loss:  2.362891 ETA:   0h 2m28s 32.7% words/sec/thread:  194271 lr:  0.000673 avg.loss:  2.356984 ETA:   0h 2m29s 33.5% words/sec/thread:  193033 lr:  0.000665 avg.loss:  2.353294 ETA:   0h 2m28s 34.9% words/sec/thread:  191756 lr:  0.000651 avg.loss:  2.346675 ETA:   0h 2m25s 38.1% words/sec/thread:  190034 lr:  0.000619 avg.loss:  2.333477 ETA:   0h 2m20s 41.6% words/sec/thread:  189605 lr:  0.000584 avg.loss:  2.321407 ETA:   0h 2m12s 43.6% words/sec/thread:  189301 lr:  0.000564 avg.loss:  2.315262 ETA:   0h 2m 8s 45.5% words/sec/thread:  189243 lr:  0.000545 avg.loss:  2.309737 ETA:   0h 2m 3s 47.3% words/sec/thread:  189125 lr:  0.000527 avg.loss:  2.305308 ETA:   0h 1m59s 50.9% words/sec/thread:  188713 lr:  0.000491 avg.loss:  2.294887 ETA:   0h 1m51s53.7% words/sec/thread:  188644 lr:  0.000463 avg.loss:  2.287529 ETA:   0h 1m45s 188812 lr:  0.000443 avg.loss:  2.282912 ETA:   0h 1m40s 58.6% words/sec/thread:  186570 lr:  0.000414 avg.loss:  2.276832 ETA:   0h 1m35s 59.0% words/sec/thread:  185292 lr:  0.000410 avg.loss:  2.275231 ETA:   0h 1m35s 59.8% words/sec/thread:  183014 lr:  0.000402 avg.loss:  2.272942 ETA:   0h 1m34s60.3% words/sec/thread:  182071 lr:  0.000397 avg.loss:  2.271927 ETA:   0h 1m33s 61.9% words/sec/thread:  178286 lr:  0.000381 avg.loss:  2.268033 ETA:   0h 1m31s 62.4% words/sec/thread:  177033 lr:  0.000376 avg.loss:  2.265491 ETA:   0h 1m31s 64.4% words/sec/thread:  173364 lr:  0.000356 avg.loss:  2.252701 ETA:   0h 1m28s 65.3% words/sec/thread:  171650 lr:  0.000347 avg.loss:  2.247070 ETA:   0h 1m27s 67.0% words/sec/thread:  169152 lr:  0.000330 avg.loss:  2.237315 ETA:   0h 1m23s22s  0h 1m17s 72.0% words/sec/thread:  161362 lr:  0.000280 avg.loss:  2.208525 ETA:   0h 1m14s 72.1% words/sec/thread:  161208 lr:  0.000279 avg.loss:  2.207848 ETA:   0h 1m14s 0.000265 avg.loss:  2.200485 ETA:   0h 1m11s 73.9% words/sec/thread:  158850 lr:  0.000261 avg.loss:  2.198305 ETA:   0h 1m10s 74.8% words/sec/thread:  157818 lr:  0.000252 avg.loss:  2.193868 ETA:   0h 1m 8ss 75.2% words/sec/thread:  157313 lr:  0.000248 avg.loss:  2.191942 ETA:   0h 1m 7s 75.6% words/sec/thread:  156822 lr:  0.000244 avg.loss:  2.189860 ETA:   0h 1m 6s 76.1% words/sec/thread:  156311 lr:  0.000239 avg.loss:  2.187813 ETA:   0h 1m 5s ETA:   0h 1m 5s155435 lr:  0.000231 avg.loss:  2.184167 ETA:   0h 1m 3s 78.2% words/sec/thread:  154137 lr:  0.000218 avg.loss:  2.178064 ETA:   0h 1m 0s 79.5% words/sec/thread:  153023 lr:  0.000205 avg.loss:  2.170586 ETA:   0h 0m57s 79.9% words/sec/thread:  152600 lr:  0.000201 avg.loss:  2.168963 ETA:   0h 0m56savg.loss:  2.166656 ETA:   0h 0m55s 82.5% words/sec/thread:  150127 lr:  0.000175 avg.loss:  2.157193 ETA:   0h 0m50s  0.000164 avg.loss:  2.152719 ETA:   0h 0m47s 84.2% words/sec/thread:  148788 lr:  0.000158 avg.loss:  2.150020 ETA:   0h 0m45s 84.6% words/sec/thread:  148365 lr:  0.000154 avg.loss:  2.148320 ETA:   0h 0m44s 85.0% words/sec/thread:  147973 lr:  0.000150 avg.loss:  2.146610 ETA:   0h 0m43s85.3% words/sec/thread:  147715 lr:  0.000147 avg.loss:  2.145489 ETA:   0h 0m42s 2.144818 ETA:   0h 0m42s 85.5% words/sec/thread:  147573 lr:  0.000145 avg.loss:  2.144627 ETA:   0h 0m42s 86.0% words/sec/thread:  147270 lr:  0.000140 avg.loss:  2.142991 ETA:   0h 0m41s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 0 hours 5 minutes 12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress: 100.0% words/sec/thread:  137906 lr: -0.000000 avg.loss:  2.090842 ETA:   0h 0m 0s\r",
      "Progress: 100.0% words/sec/thread:  137906 lr:  0.000000 avg.loss:  2.090842 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Membuat model word embedding fasttext menggunakan CBOW 2\n",
    "\n",
    "# waktu mulai\n",
    "start_time = time.time()\n",
    "\n",
    "model_cbow = fasttext.train_unsupervised(input='/Users/williamnehemia/Documents/Skripsi/TugasAkhir/WordEmbeddingModel/Data/dataCurr.txt', model='cbow', lr=0.001, dim=20, ws=5, epoch=100, minCount=1, minn=3, maxn=3, thread=10)\n",
    "\n",
    "# waktu selesai\n",
    "end_time = time.time()\n",
    "\n",
    "# hitung waktu training\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# convert ke jam, menit, detik\n",
    "hours = int(training_time // 3600)\n",
    "minutes = int((training_time % 3600) // 60)\n",
    "seconds = int(training_time % 60)\n",
    "\n",
    "print(\"Total training time:\", hours, \"hours\", minutes, \"minutes\", seconds, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0aea16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_cbow.save_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_cbow_fasttext_2.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1333016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_cbow = fasttext.load_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_cbow_fasttext_2.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfed5d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyak kata ada di model 2951\n",
      "banyak kata tidak ada di model 0\n",
      "0.16557757338755275\n"
     ]
    }
   ],
   "source": [
    "# relatedness model cbow 2\n",
    "print(relatedness(model_cbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7bc41ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_predicted 0 0.0\n",
      "false_predicted 10014 1.0\n",
      "banyak kata ada di model 3233\n",
      "banyak kata tidak ada di model 0\n"
     ]
    }
   ],
   "source": [
    "# word analogy model cbow 2\n",
    "word_analogy(model_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba61f6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  73023\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   69288 lr:  0.000000 avg.loss:  0.743549 ETA:   0h 0m 0s  1.8% words/sec/thread:  129548 lr:  0.000982 avg.loss:  2.941371 ETA:   0h 5m25savg.loss:  2.798698 ETA:   0h 5m40s  4.2% words/sec/thread:  108471 lr:  0.000958 avg.loss:  2.571348 ETA:   0h 6m19s  5.0% words/sec/thread:  108604 lr:  0.000950 avg.loss:  2.528103 ETA:   0h 6m16s  5.7% words/sec/thread:  107371 lr:  0.000943 avg.loss:  2.501015 ETA:   0h 6m17s  6.2% words/sec/thread:  104855 lr:  0.000938 avg.loss:  2.486565 ETA:   0h 6m24savg.loss:  2.476607 ETA:   0h 6m31s 7.0% words/sec/thread:  101213 lr:  0.000930 avg.loss:  2.465971 ETA:   0h 6m35s  8.6% words/sec/thread:   97813 lr:  0.000914 avg.loss:  2.436626 ETA:   0h 6m41s  0.000907 avg.loss:  2.426136 ETA:   0h 6m52s  9.9% words/sec/thread:   93647 lr:  0.000901 avg.loss:  2.416547 ETA:   0h 6m54s 11.0% words/sec/thread:   90153 lr:  0.000890 avg.loss:  2.392697 ETA:   0h 7m 4s 11.1% words/sec/thread:   88769 lr:  0.000889 avg.loss:  2.389913 ETA:   0h 7m10sm33s 22.4% words/sec/thread:   77924 lr:  0.000776 avg.loss:  2.147462 ETA:   0h 7m 8s 26.6% words/sec/thread:   78316 lr:  0.000734 avg.loss:  1.865104 ETA:   0h 6m43s 27.9% words/sec/thread:   74885 lr:  0.000721 avg.loss:  1.796464 ETA:   0h 6m54s% words/sec/thread:   73327 lr:  0.000715 avg.loss:  1.764686 ETA:   0h 6m59s29.9% words/sec/thread:   70705 lr:  0.000701 avg.loss:  1.696684 ETA:   0h 7m 6s 30.1% words/sec/thread:   70374 lr:  0.000699 avg.loss:  1.687726 ETA:   0h 7m 7s 30.5% words/sec/thread:   69959 lr:  0.000695 avg.loss:  1.673817 ETA:   0h 7m 7s 32.2% words/sec/thread:   67195 lr:  0.000678 avg.loss:  1.601352 ETA:   0h 7m13s 32.4% words/sec/thread:   66855 lr:  0.000676 avg.loss:  1.593420 ETA:   0h 7m14s 33.3% words/sec/thread:   66087 lr:  0.000667 avg.loss:  1.561900 ETA:   0h 7m14s 35.9% words/sec/thread:   66827 lr:  0.000641 avg.loss:  1.472617 ETA:   0h 6m52s 37.3% words/sec/thread:   67078 lr:  0.000627 avg.loss:  1.432414 ETA:   0h 6m42s 38.8% words/sec/thread:   67633 lr:  0.000612 avg.loss:  1.389675 ETA:   0h 6m29s 1.386149 ETA:   0h 6m28s 39.8% words/sec/thread:   67914 lr:  0.000602 avg.loss:  1.361712 ETA:   0h 6m21s 42.0% words/sec/thread:   68166 lr:  0.000580 avg.loss:  1.309765 ETA:   0h 6m 6savg.loss:  1.301114 ETA:   0h 6m 3s 43.0% words/sec/thread:   68305 lr:  0.000570 avg.loss:  1.287396 ETA:   0h 5m59s 43.5% words/sec/thread:   68403 lr:  0.000565 avg.loss:  1.276863 ETA:   0h 5m55s 44.2% words/sec/thread:   68523 lr:  0.000558 avg.loss:  1.260725 ETA:   0h 5m50s 44.7% words/sec/thread:   68630 lr:  0.000553 avg.loss:  1.250605 ETA:   0h 5m46s 45.7% words/sec/thread:   68802 lr:  0.000543 avg.loss:  1.231064 ETA:   0h 5m39s 47.4% words/sec/thread:   69323 lr:  0.000526 avg.loss:  1.199839 ETA:   0h 5m26s  0.000516 avg.loss:  1.182879 ETA:   0h 5m19s 50.2% words/sec/thread:   70072 lr:  0.000498 avg.loss:  1.151143 ETA:   0h 5m 5s.145053 ETA:   0h 5m 2s 54.7% words/sec/thread:   71279 lr:  0.000453 avg.loss:  1.085216 ETA:   0h 4m33s 56.1% words/sec/thread:   71595 lr:  0.000439 avg.loss:  1.067499 ETA:   0h 4m24s 56.9% words/sec/thread:   71819 lr:  0.000431 avg.loss:  1.057561 ETA:   0h 4m18s 57.7% words/sec/thread:   72019 lr:  0.000423 avg.loss:  1.047961 ETA:   0h 4m12s 58.1% words/sec/thread:   72045 lr:  0.000419 avg.loss:  1.042676 ETA:   0h 4m10s7s 60.2% words/sec/thread:   72529 lr:  0.000398 avg.loss:  1.017320 ETA:   0h 3m56s 60.5% words/sec/thread:   72596 lr:  0.000395 avg.loss:  1.014548 ETA:   0h 3m54s 3m48s 62.4% words/sec/thread:   72938 lr:  0.000376 avg.loss:  0.993679 ETA:   0h 3m41s0.981100 ETA:   0h 3m33ss 0.000241 avg.loss:  0.876785 ETA:   0h 2m20s77.0% words/sec/thread:   73933 lr:  0.000230 avg.loss:  0.868894 ETA:   0h 2m13s 80.9% words/sec/thread:   74314 lr:  0.000191 avg.loss:  0.843239 ETA:   0h 1m50s 85.5% words/sec/thread:   74668 lr:  0.000145 avg.loss:  0.815229 ETA:   0h 1m23s 85.6% words/sec/thread:   74662 lr:  0.000144 avg.loss:  0.814857 ETA:   0h 1m23s 88.0% words/sec/thread:   74641 lr:  0.000120 avg.loss:  0.801852 ETA:   0h 1m 9s 90.6% words/sec/thread:   73000 lr:  0.000094 avg.loss:  0.787560 ETA:   0h 0m55s 95.4% words/sec/thread:   70740 lr:  0.000046 avg.loss:  0.763826 ETA:   0h 0m27s 95.7% words/sec/thread:   70638 lr:  0.000043 avg.loss:  0.762783 ETA:   0h 0m26s 97.2% words/sec/thread:   70114 lr:  0.000028 avg.loss:  0.755909 ETA:   0h 0m17s 98.3% words/sec/thread:   69757 lr:  0.000017 avg.loss:  0.751240 ETA:   0h 0m10s 99.5% words/sec/thread:   69446 lr:  0.000005 avg.loss:  0.746099 ETA:   0h 0m 3s69377 lr:  0.000003 avg.loss:  0.744997 ETA:   0h 0m 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 0 hours 10 minutes 22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress: 100.0% words/sec/thread:   69278 lr: -0.000000 avg.loss:  0.743535 ETA:   0h 0m 0s\r",
      "Progress: 100.0% words/sec/thread:   69278 lr:  0.000000 avg.loss:  0.743535 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Membuat model word embedding fasttext menggunakan skip gram 2\n",
    "\n",
    "# waktu mulai\n",
    "start_time = time.time()\n",
    "\n",
    "model_sg = fasttext.train_unsupervised(input='/Users/williamnehemia/Documents/Skripsi/TugasAkhir/WordEmbeddingModel/Data/dataCurr.txt', model='skipgram', lr=0.001, dim=20, ws=5, epoch=100, minCount=1, minn=3, maxn=3, thread=10)\n",
    "\n",
    "# waktu selesai\n",
    "end_time = time.time()\n",
    "\n",
    "# hitung waktu training\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# convert ke jam, menit, detik\n",
    "hours = int(training_time // 3600)\n",
    "minutes = int((training_time % 3600) // 60)\n",
    "seconds = int(training_time % 60)\n",
    "\n",
    "print(\"Total training time:\", hours, \"hours\", minutes, \"minutes\", seconds, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d485774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_sg.save_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_sg_fasttext_2.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8ebf18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_sg = fasttext.load_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_sg_fasttext_2.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f31e80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banyak kata ada di model 2951\n",
      "banyak kata tidak ada di model 0\n",
      "0.21906551118069492\n"
     ]
    }
   ],
   "source": [
    "# relatedness model sg 2\n",
    "print(relatedness(model_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d48f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_predicted 5 0.0004993009786299181\n",
      "false_predicted 10009 0.9995006990213701\n",
      "banyak kata ada di model 3233\n",
      "banyak kata tidak ada di model 0\n"
     ]
    }
   ],
   "source": [
    "# word analogy model sg 2\n",
    "word_analogy(model_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat model word embedding fasttext menggunakan CBOW 3\n",
    "\n",
    "# waktu mulai\n",
    "start_time = time.time()\n",
    "\n",
    "model_cbow = fasttext.train_unsupervised(input='/Users/williamnehemia/Documents/Skripsi/TugasAkhir/WordEmbeddingModel/Data/dataCurr.txt', model='cbow', lr=0.1, dim=20, ws=5, epoch=100, minCount=1, minn=3, maxn=3, thread=10)\n",
    "\n",
    "# waktu selesai\n",
    "end_time = time.time()\n",
    "\n",
    "# hitung waktu training\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# convert ke jam, menit, detik\n",
    "hours = int(training_time // 3600)\n",
    "minutes = int((training_time % 3600) // 60)\n",
    "seconds = int(training_time % 60)\n",
    "\n",
    "print(\"Total training time:\", hours, \"hours\", minutes, \"minutes\", seconds, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_cbow.save_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_cbow_fasttext_3.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_cbow = fasttext.load_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_cbow_fasttext_3.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relatedness model cbow 3\n",
    "print(relatedness(model_cbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word analogy model cbow 3\n",
    "word_analogy(model_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38751d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
