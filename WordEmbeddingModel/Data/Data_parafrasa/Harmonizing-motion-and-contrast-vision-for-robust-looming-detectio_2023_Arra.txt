However, current methods are still heavily influenced by spatial contrast, which refers to the difference in illumination between adjacent local areas within the receptive field. The model's response fluctuates over time with a high variability in relation to the natural input signals. Recognizing low-contrast looming motion has always been a challenging issue for artificial vision systems due to the non-linear nature of motion detection and the large variation in local contrast of natural signals.

To address the computational implementation of contrast neural computation in motion-sensitive visual systems, Fu et al. introduced fly contrast mechanisms and pathways for estimating natural background motion, which resulted in improved response compared to neural models processing only motion signals. Li et al. incorporated contrast neural computation into a single-channel LGMD model and demonstrated its effectiveness in looming detection. Wang et al. also demonstrated the effectiveness of contrast computation in a small target motion detector to prevent false detections. In contrast to these works, and drawing from the latest physiological research, this paper presents an approach to harmonize motion and contrast vision within four parallel on/off channels for looming detection, validated by a large dataset of natural signals.

The second part involves testing the model in complex scenarios using a dataset of 1100 original videos, including various indoor and outdoor scenes, with different grey values and simulated insect visual stimulation. The performance of the proposed neural model in extremely low-contrast scenarios against various natural signals is emphasized, along with the effects of dynamic normalization mechanisms and on/off parallel contrast pathways on looming detection.

The coefficient of variation is used to measure the model's performance, with denser distributions indicating better statistical results. The model's performance is greatly affected by contrast, and the proposed model consistently outperforms the model of Li et al. across different contrasts, particularly in low-contrast environments.

Incorporating on/off channels significantly improves the model's performance compared to previous models, as the proposed model smoothly detects looming motions in a wide range of natural scenes. The statistical results show that the proposed model is more robust against environmental illumination, with densely distributed coefficients of variation and smaller inner distances.

The proposed neural model effectively coordinates contrast and motion vision to improve looming detection in extremely low-contrast scenarios and various natural signals. It features feed-forward visual processing in a stratified neural network with four bio-plausible parallel on/off channels encoding polarity motion and contrast information separately. The contrast neural computation acts as an instant, dynamic normalization mechanism and includes on/off contrast pathways to stabilize model response against high input variability of natural scenes.

A new dataset consisting of thousands of looming-square motions in cluttered and dynamic backgrounds was created to validate the proposed method, and comparative experiments demonstrate its robustness for looming detection in natural scenes, especially at extremely low contrast.

In addressing real-world detection problems, progress has been made in image processing, deep learning methods, and advanced sensor strategies. Drawing insights from neuroscience, particularly insect intelligence, offers promising paradigms for building artificial vision systems and neuromorphic sensors. The proposed approach has potential applications in bio-inspired robotic systems and micro/aerial robotic systems.

In summary, the proposed approach effectively addresses the challenges of low-contrast looming motion detection in natural scenes through the coordination of contrast and motion vision within a neural model, with potential applications in real-world scenarios and bio-inspired robotic systems.