Increasingly, concurrent and distributed systems are evolving into open environments where components, agents, or services interact with each other by dynamically establishing connections. For example, in service-oriented architectures, computational resources may be accessed through temporary interactive sessions. Such open interaction environments, characterized by the dynamic binding of their components, may lead to systems being only partially defined even at runtime. This paper aims to describe and analyze the behavior of systems in such open-interaction environments in the presence of incomplete information.

Web crawlers, also known as bots, spiders, or scutters, are software programs that systematically traverse the web to collect and generate data. They are utilized for various purposes, ranging from feeding search engines (e.g., Googlebot) to malicious activities such as collecting email addresses or posting spam or phishing content. Certain protocols exist to facilitate the collaboration between crawlers and websites. For instance, the robot exclusion and inclusion protocols (e.g., robots.txt and sitemaps) are widely used by websites to communicate to crawlers which links to exclude or include in their crawling activities. While crawlers are not obligated to adhere to these protocols, web servers can sometimes differentiate between crawlers and human browsers and exert control over their adherence to the protocols based on factors such as navigation speed and patterns.

We introduce three types of crawlers: polite, cautious, and rash. A polite crawler requests the existence of a page before communicating it to its database, while a cautious crawler changes the target page in a similar manner but does not check the page's existence before communicating its URL to the database. A rash crawler assumes the existence of pages without performing any checks. All three types of crawlers are capable of examining existing pages. For the sake of simplicity, we consider static networks where no pages are added or removed during crawling activities.

We present a simple name-based calculus to model the interactions of crawler agents operating within a web of links. The web system may comprise crawlers, links, and their composition. Pages are viewed as collections of links with the same origin, and if the collection is empty, the page is considered missing; otherwise, it is valid. A link is termed broken if its target page is missing.

Crawlers are capable of learning new site addresses by examining the links departing from their current site. The rules governing the acquisition of new site addresses are identical for all three types of crawlers and abstract away the specific interactions that would occur in actual crawlers. These rules illustrate that the interface of the crawler agent can be expanded through the acquisition of a new site address.

We utilize theorem 4.9 to derive a proper decoration for the observation link(x, y)| y, and the case for c| link(x, y)| y is analogous. This demonstrates the consequences of link observations under the specified conditions.