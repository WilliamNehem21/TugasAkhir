We introduce a dataset named ERMDs that addresses the challenge of assessing the resilience of LB-MDs by producing a variety of malware instances with diverse characteristics. To this end, we designed three types of obfuscation spaces--binary, source code, and packing--each of which comprises multiple obfuscation techniques with various parameters. The techniques from these spaces can be used individually or in combination, creating a potentially infinite number of obfuscation combinations to generate malware instances that encompass a wide range of features not addressed by LB-MDs.

As the landscape of malware threats becomes more complex, traditional signature-based detection methods are becoming less effective. In response, antivirus software providers are increasingly turning to machine learning techniques to enhance their detection capabilities and keep pace with emerging threats. By integrating machine learning algorithms into their software, these vendors can improve the accuracy of their detection capabilities.

In addressing the challenge of evaluating the robustness of LB-MDs, we propose the ERMDs dataset as a means to provide a more realistic assessment of model performance by incorporating a diverse set of model-agnostic adversarial examples. Unlike previous methods, ERMDs aims to capture various failure modes of modern models rather than exclusively focusing on worst-case scenarios. The dataset is designed to encompass three types of obfuscation spaces, each with multiple obfuscation techniques and parameters, enabling the generation of a wide range of malware instances that present novel features not accounted for by LB-MDs.

We believe that the ERMDs dataset and the proposed methods to enhance the resilience of malware detectors will serve as valuable resources for future research aimed at developing more effective and robust MDs. This enhanced robustness will better protect users and organizations from the ever-evolving threats of malware and cyber attacks.

However, existing datasets for malware analysis, including the recently released BODMAS, predominantly feature samples collected between 2017 and 2020, potentially failing to capture recent malware behaviors accurately. In addressing this issue, we intend to release a new malware dataset containing samples from January to December 2022, sourced from VirusShare for malicious samples and GitHub and SourceForge for benign samples.

We observed that the performance of LB-MD models and commercial antivirus software on the ERMDs-X dataset varied, with an average accuracy of 62.47%. This lower accuracy can be attributed to the broad spectrum of model-agnostic adversarial examples present in the ERMDs-X dataset, aiming to provide a realistic evaluation of model performance by capturing various failure modes of modern models.

Overall, our analysis demonstrates the ability of the ERMDs-X dataset to assess the robustness of existing LB-MDs models. Moreover, we present suggestions for improving the robustness of LB-MDs and commercial antivirus software based on our experimental findings.

The study confirms that obfuscation techniques can be used to evaluate the robustness of MDs, but future work may incorporate additional adversarial attack techniques to generate a more diverse range of samples in the EMRDS dataset and further enhance its richness.