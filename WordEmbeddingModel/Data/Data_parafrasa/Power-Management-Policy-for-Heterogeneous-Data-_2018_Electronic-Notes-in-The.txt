Multiple research studies, such as those referenced in [23, 10, 17, 5], demonstrate a notable increase in energy consumption and digital pollution attributed to the recent proliferation of clouds and data centers. Data centers alone account for more than 1.3% of global energy consumption, with each server in a data center capable of producing over 10 kilograms of CO2 per day, as evidenced by surveys conducted in [23, 40]. This trend underscores the growing significance of data centers and necessitates the development of energy-saving strategies to address the associated environmental and energetic challenges. While data centers are designed to accommodate peak traffic loads, the global load typically hovers at around 60%.

Research, such as that found in [26, 3], indicates that the majority of energy consumption within data centers stems from server operation and cooling, which collectively account for approximately 70% of the total data center energy costs. Consequently, efforts have been directed towards enhancing server efficiency and cooling systems, as well as implementing optimized kernels and energy networks, to mitigate this energy consumption. Moreover, implementing a power policy to manage server activation and deactivation in data centers serves as an additional approach to conserve energy while maintaining service quality.

The complexity of determining the optimal policy for large Markov Decision Processes (MDPs) poses a significant challenge. Analyzing the structural properties of the optimal policy becomes crucial in expediting computations. Various studies, such as those in [46, 29, 43, 19, 38], have examined the structural properties of the optimal policy and proposed conditions to assess the double-threshold structure.

The subsequent sections of this paper are organized as follows: Section 2 details the modeling of job arrivals using discrete distributions derived from actual Google traffic traces [47, 41], and introduces a method for creating identically and independently distributed discrete distributions. Section 3 outlines the system modeled as a simple queue, while Section 4 formulates the optimization problem as a discrete-time MDP. Section 5 presents proofs of structural properties related to the optimal policy, and finally, Section 6 provides an example illustrating the distribution of arrival jobs.

The composition of a data center encompasses heterogeneous servers organized into multiple levels of energy consumption. For simplicity, we consider a set of server levels denoted as g={high, medium, low}, with respective numbers of operational servers represented as mg and maximum server capacities as maxg.

The dynamic nature of data center operations, which directly correlates with traffic and performance indicators, introduces complexity in analyzing the system, particularly in terms of managing waiting and lost jobs, as well as fluctuating energy consumption due to varying server numbers. Consequently, decision-making regarding the adjustment of mhigh, mmed, and mlow is contingent upon factors such as traffic volume, performance metrics, and cost considerations.

As previously discussed, the dimensions of the MDP are influential, and deriving the optimal policy for large-scale data centers can be arduous, if not infeasible. Hence, understanding the structural properties of the optimal policy is essential for computational efficiency. Notably, the double-threshold structure, which has been demonstrated in homogeneous data center models, does not hold true for our heterogeneous data center model.

A case study utilizing real traffic traces, specifically the open cluster-data-2011-2 trace [47, 41], is presented. This study models arrival jobs and service rates using discrete distributions generated from job and machine events recorded at a specific Google data center throughout May 2011. The data trace's sampling period ensures the assumption of independence and identical distribution (i.i.d), allowing for the construction of empirical distributions in 136-second intervals.

The intricate nature of the MDP model specification presents challenges when dealing with large system parameters. While it is manageable to write specifications for systems with small parameters, the task becomes daunting when considering real systems with extensive parameters. For instance, the PRISM specification for a data center with 10 heterogeneous servers spans several thousand lines, each differing from the next. Attempting to manually generate the specification is time-consuming, prone to errors, and necessitates substantial effort for updating and maintenance. As a result, a tool has been developed to automate the generation of the PRISM specification file for our heterogeneous model.

The results indicate that the heterogeneous model achieves a 12% improvement in energy conservation compared to the homogeneous model. However, it is important to note that the size of the heterogeneous model far surpasses that of the three homogeneous models, primarily due to the larger number of unique action combinations.