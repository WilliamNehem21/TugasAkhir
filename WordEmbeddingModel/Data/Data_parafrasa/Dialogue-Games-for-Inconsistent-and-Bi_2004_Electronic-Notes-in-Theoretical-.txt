Many existing approaches lack an analysis of dialogue games in multi-agent systems that can handle epistemic modalities. The authors suggest that locutions are considered inconsistent when the information they convey is contradictory with the content of other locutions, and biased when an agent has more evidence to believe a statement than to disbelieve it, or vice versa. To address this, a multi-valued logic is introduced to focus on the semantics of inconsistent and biased information exchange in conversation, aiming to show that inconsistent and biased information can be managed consistently in dialogue games. They propose the use of truth values from bilattice structures in the dialogue game to formulate the cognitive state of agents as a set of multivalued theories based on the bilattice structure. Additionally, update and dialogue rules are defined to handle biased and inconsistent information, allowing agents to deal with possibly inconsistent information states without being forced into belief revision.

The paper then presents a fictitious dialogue from Sesame Street as an example. In this dialogue, Elmo seeks to know if he can play outside, and the information exchange among characters leads to inconsistency, but the authors argue that this does not necessitate belief revision.

The remainder of the paper is structured as follows: Section 2 formalizes inconsistent and biased information using bilattice structures and describes a multi-valued logic based on these structures. Section 3 presents a dialogue game based on a multi-valued logic, and the Sesame Street example dialogue is translated into a formal one. Section 4 gives a proof of the validity of the example dialogue, and the paper concludes with Section 5.

In the example dialogue, the authors demonstrate the use of truth values and biased information states, emphasizing the need for agents to handle incoming inconsistent information.

The paper also discusses a situation where agents are motivated to offer information to others, specifying that if an agent desires another agent to believe a proposition and is not aware that the other agent already believes it, the agent is allowed to offer the proposition.

Furthermore, the paper outlines the different roles belief statements can have in a dialogue in relation to the cognitive state of the agents, noting that belief statements may serve as partial, overinformative, or minimal answers to a question based on the interests and states of the agents involved.