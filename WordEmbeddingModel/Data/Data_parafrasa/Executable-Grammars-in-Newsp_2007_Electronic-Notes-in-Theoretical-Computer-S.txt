The idea of parser combinators has been present in functional programming for a long time [11, 13, 21]. From an object-oriented perspective, it involves treating the operators of BNF as methods, called combinators, which operate on objects representing grammar productions. Each such object is a parser that accepts the language generated by a specific production. The results of the combinator invocations are also parsers.

In this context, slots are initialized to their corresponding parsers, with each slot definition representing a production rule of the grammar. The rules for digit and letter directly correspond to the grammar and utilize the utility method charbetween:and: to produce a parser that accepts characters within a specified range.

The ID rule remains unchanged from before, but it becomes clear that the lack of distinction between lexing and parsing poses a problem. Traditionally, a lexer is relied upon to tokenize the input, eliminating whitespace and comments. This functionality is addressed by the tokenfor: operator, which skips leading whitespace and comments and then accepts whatever the provided parser accepts. Additionally, this parser attaches start and end source indices to the result, making it useful when integrating a parser into an IDE. It is beneficial to define a production identifier that produces tokenized results.

Concerns have been raised about using closures as arguments for parser combinators, as it is feared that programmers may mistakenly pass parsers as arguments directly. However, this is not a significant issue, as such mistakes were dynamically detected in an earlier framework. Although the detection was dynamic and occurred during the construction of the grammar rather than during actual parsing, the effect was essentially the same as with static checking. Moreover, it would be straightforward to allow combinators to accept either parsers or closures.

Despite the attractiveness of defining a parser by closely corresponding to the grammar, it is essential to perform further processing, such as producing an abstract syntax tree (AST). To address this need, a new operator on parsers, wrapper:, has been introduced to process the results generated during parsing and produce an AST using a closure.

Some parser combinator libraries support naming parsers, which aids in debugging errors in the grammar and reporting errors with the production names. However, this approach adds clutter and obscures the grammar, leading to repetition of information already specified.

The paper also discusses the representation of grammars, the handling of types in parser combinator frameworks, and the possibility of parsing context-sensitive grammars using the framework. Additionally, it notes the development of a parser combinator framework in Smalltalk, inspired by monadic parser combinator frameworks in Haskell.