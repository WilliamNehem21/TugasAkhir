Model checking algorithms are limited by main memory resources due to the state explosion problem. Despite the development of memory-limited algorithms, such as [16,20,24], the core issue of dealing with large programs remains memory limitations. Although the theoretical limit of RAM has increased with the advent of 64-bit machines, practical limitations imposed by hardware and operating systems make it difficult to use more than 64 gigabytes of RAM. The use of virtual memory as a solution to the state space explosion in model checking can significantly slow down the performance.

The model checker provides various blind and directed search algorithms, including depth-first search, breadth-first search, best-first search, IDA*, and A*. The types of safety errors addressed by the model checker include deadlocks, segmentation faults, and assertion violations. The model checker branches the execution on threads or on variable ranges, and for search guidance, it offers a range of state-to-error estimates including the active process heuristics to accelerate the search for deadlocks.

A state in the program consists of registers, stack frames, global variables, and memory pool, and the state size grows with every memory allocation in the program, potentially reaching several megabytes. Consequently, one of the major challenges for program model checking at the object code level is the significant size of the state vector.

To mitigate these challenges, separate caches for different components of the system state (data section, binary section, stack contents, and other system state components) were implemented, allowing individual components to be flushed to and read from disk. This approach, referred to as external collapse compression, utilized an AVL tree sorted by individual hash values.

In order to avoid infinite behavior during the reading of the MPI queue, a limit on the number of extracted mini-states in one scan was set. Similarly, the "idle" flag was used to avoid repeatedly sending idle messages to the root.

A hash-based distribution as proposed by Stern and Dill with a linear hash function defined on the full state vector was attempted. However, with states of large sizes, such a partitioning can be costly as computing the hash function is expensive. To address this, the tool offers the option for incremental hashing that relies on the hash difference between the state and its successor only.

External exploration was implemented on top of the tool, realized through MPI. The experiments were performed on a cluster of workstations, and the results showed linear speedup in all examples. Future work includes the integration of dynamic load balancing and the evaluation of larger C++ models.