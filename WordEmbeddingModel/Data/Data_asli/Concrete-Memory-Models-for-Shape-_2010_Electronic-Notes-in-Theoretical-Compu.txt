the purpose of shape analysis is to infer properties on the runtime structure of the memory heap. shape analysis goes beyond alias and null-pointer analyses, in term of expressivity and precision. the applications of shape analyses include optimizing compilation, absence of runtime errors(dereference of dangling or null pointers), proof of programs, automatic parallelisation,...



c, c++, and to a lesser extent ada, in which pointers can also point inside an object, and where more operations are allowed, such as taking the address of a record field, either explicitly(c, c++) or implicitly(reference parameter passing in c++, ada), pointer arithmetics,...



motivations. analyses, like tvla, were developed for java-like languages. others, such as the separation-logic-based xisa, target a subset of c. the memory models for shape analyses are often only described at the abstract level. a clear view of the concrete memory model is needed to understand the scope of these analyses and be able to reuse them in different context.



more generally, all the semantics we presented assume a static typing of expressions. casts introduce a dynamic typing and are not handled by any of them. to handle casts, additional assumptions on the internal representation of types are needed(this could be provided by the abi), and the memory model needs to keep the value of each byte, like in.



we classified the concrete store-based memory models using two criteria: the way they store pointers and the way they represent offsets. for each of the four memory models, we gave a compact semantics of a fragment of clight, which includes arrays and pointer arithmetics. for this language, the usual semantics can be expressed with our standard memory model(sect. 3). the object memory model, commonly considered in shape analyses, leads to strong semantic restrictions, that we overcome by instrumentation(sects. 4 and 5).



