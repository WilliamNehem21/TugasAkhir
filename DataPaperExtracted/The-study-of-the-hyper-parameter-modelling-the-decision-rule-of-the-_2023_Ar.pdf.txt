Array 19 (2023) 100310
Available online 20 July 2023
2590-0056/Â© 2023 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).
Contents lists available at ScienceDirect
Array
journal homepage: www.elsevier.com/locate/array
The study of the hyper-parameter modelling the decision rule of the cautious
classifiers based on the ğ¹ğ›½measure
Abdelhak Imoussaten
EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France
A R T I C L E I N F O
Keywords:
Cautious classification
Set-valued classification
Belief functions
Supervised machine learningA B S T R A C T
In some sensitive domains where data imperfections are present, standard classification techniques reach their
limits. To avoid misclassifications that have serious consequences, recent works propose cautious classification
algorithms to handle this problem. Despite of the presence of uncertainty and/or imprecision, a point prediction
classifier is forced to bet on a single class. While a cautious classifier proposes the appropriate subset of
candidate classes that can be assigned to the sample in the presence of imperfect information. On the other
hand, cautiousness should not be at the expense of precision and a trade-off has to be made between these
two criteria. Among the existing cautious classifiers, two classifiers propose to manage this trade-off in the
decision step by the mean of a parametrized objective function. The first one is the non-deterministic classifier
(ndc) proposed within the framework of probability theory and the second one is â€˜â€˜evidential classifier based
on imprecise relabellingâ€™â€™ (eclair) proposed within the framework of belief functions. The theoretical aim of
the mentioned hyper-parameters is to control the size of predictions for both classifiers. This paper proposes to
study this hyper-parameter in order to select the â€˜â€˜bestâ€™â€™ value in a classification task. First the utility for each
candidate subset is studied related to the values of the hyper-parameter and some thresholds are proposed to
control the size of the predictions. Then two illustrations are proposed where a method to choose this hyper-
parameters based on the calibration data is proposed. The first illustration concerns randomly generated data
and the second one concerns the images data of fashion mnist. These illustrations show how to control the
size of the predictions and give a comparison between the performances of the two classifiers for a tuning
based on our proposition and the one based on grid search method.
1. Introduction
In some sensitive applications misclassification can have serious
consequences. This is the case in applications having impacts either on
peopleâ€™s health or on the environment [ 1], e.g., in medical diagnosis
applications when a classifier is involved to detect early-stage cancer.
In such applications, cautious decisions are necessary when imperfect
data are present. This leads some recent works to focus on cautious
classification. Among the existing cautious classifiers, we focus on
those providing a subset of candidate class labels to a new sample to
classify. We refer to those classifiers as set-valued classifiers. We can
cite among these classifiers the Naive Credal Classifier (ncc) [2,3], the
strong dominance based classifier [ 4], the non-deterministic classifier
(ndc) [ 5], the credal decision trees (CDT) [ 6], the imprecise credal
decision trees (ICDT) [ 7], the classifiers based on generalized criteria
such as Hurwicz (GHC), OWA (GOWAC) [ 8], eclair classifier [ 9,10],
etc. One can find in [ 8â€“10] other works concerning cautious prediction
including works about conformal prediction [ 11â€“14] that are discussed
in this paper. But cautiousness should not be at the expense of precision
E-mail address: abdelhak.imoussaten@mines-ales.fr .and a trade-off has to be made between these two criteria. On one
hand, a classifier that predicts always the whole set of the candidate
classes is cautious but its predictions are uninformative. On the other
hand, a classifier that predicts always a single class is precise when the
predictions are good but it is not cautious. Some set-valued classifiers
can control this trade-off as the ndcand eclair classifiers. Indeed, the
utility function implemented in the decision step of both classifiers
has a hyper-parameter ğ›½that is used to control the trade-off between
precision and cautiousness. This hyper parameter is considered as a
user-modifiable parameter for the application of those classifiers and
its theoretical aim is to control the size of the predicted subset of
classes. The choice of ğ›½depends on the level of cautiousness required
for the application in which the classifier is going to be used. This paper
proposes to study this parameter in the case of the two classifiers and
aims to propose suggestions for the choice of the parameter value in the
case of classification task. In the first experiment results, we show, on
simulated data, the impact of the selected hyper-parameter value on the
prediction of the two classifiers when faced to strange samples, i.e., to
https://doi.org/10.1016/j.array.2023.100310
Received 1 April 2023; Received in revised form 5 July 2023; Accepted 17 July 2023Array 19 (2023) 100310
2A. Imoussaten
which the standard classifiers failed to predict the true class labels. In
the second experiment, concerning the images data of fashion mnist, a
comparison between the performances of the two classifiers for a tuning
based on our proposition and the one based on grid search method is
presented. The paper is organized as follows. In the second section,
the reminders about the decision step in the classifiers eclair and ndc
and the measures of set-valued classification performances are given.
The third section presents the studies of the expected utility functions
introduced in the decision step of the two classifiers. Finally, the fourth
section presents the experimental results.
2. Reminders and notations
The set-valued classifiers eclair and ndcare based on the results
of the standard point prediction classifiers to provide respectively the
posterior mass function and the posterior probability function for a
sampleğ’™to classify among a set of classes ğ›©= {ğœƒ1,â€¦,ğœƒğ‘›}. We
focus in this paper on the decision step of those two classifiers that
involves a utility function that is the ğ¹ğ›½score. In this section we give
some reminders about the ğ¹ğ›½score and it exploitation in the case of
imprecise predictions by the two classifiers. The evaluation of imprecise
predictions is performed using five measures from the state of the art
that are presented in the end of this section. To simplify notations, we
adopt the following notations for the singleton subsets and subsets of
two elements, in the rest of the paper: ğœƒğ‘–âˆ¶= {ğœƒğ‘–},ğœƒğ‘–ğ‘—âˆ¶= {ğœƒğ‘–,ğœƒğ‘—}.
2.1.ğ¹ğ›½score
Theğ¹ğ›½score used in the decision step of eclair and ndcto predict
a subset of candidate classes is an adaptation of the ğ¹ğ›½score from
information retrieval field and supervised classification methods to
set-valued classification. In the context of binary point prediction for
classification, the ğ¹ğ›½score is defined as:
ğ¹ğ›½(ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ ,ğ‘¡ğ‘Ÿğ‘¢ğ‘¡â„ ) =(1 +ğ›½2) recallâ‹…precision
(ğ›½2â‹…precision) + recall, (1)
where the quantity precision defined as:
ğ‘ğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› =ğ‘›ğ‘ ğ‘œğ‘“ ğ‘¡ğ‘Ÿğ‘¢ğ‘’ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘  ğ‘¡ğ‘Ÿğ‘¢ğ‘’
ğ‘›ğ‘ ğ‘œğ‘“ ğ‘¡ğ‘Ÿğ‘¢ğ‘’ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘  ğ‘¡ğ‘Ÿğ‘¢ğ‘’ +ğ‘›ğ‘ ğ‘œğ‘“ ğ‘“ğ‘ğ‘™ğ‘ ğ‘’ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘  ğ‘¡ğ‘Ÿğ‘¢ğ‘’,
and the quantity recall defined as:
ğ‘Ÿğ‘’ğ‘ğ‘ğ‘™ğ‘™ =ğ‘›ğ‘ ğ‘œğ‘“ ğ‘¡ğ‘Ÿğ‘¢ğ‘’ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘  ğ‘¡ğ‘Ÿğ‘¢ğ‘’
ğ‘›ğ‘ ğ‘œğ‘“ ğ‘¡ğ‘Ÿğ‘¢ğ‘’ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘  ğ‘¡ğ‘Ÿğ‘¢ğ‘’ +ğ‘›ğ‘ ğ‘œğ‘“ ğ‘¡ğ‘Ÿğ‘¢ğ‘’ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ ğ‘ğ‘  ğ‘“ğ‘ğ‘™ğ‘ ğ‘’,
are two known performance measures in information retrieval and
machine learning. This general expression of ğ¹ğ›½score in Eq. (1) is
parametrized by ğ›½that is chosen such that recall is considered ğ›½times
as important as precision .
2.2. The decision step in ndc classifier
The principle of ndcis very simple. Let us consider a sample ğ’™and a
trained point prediction model, denoted ğ›¿, that can provide a posterior
probability for the classification of ğ’™. The ndcclassifier consists in a
decision rule ğ‘Ÿğ‘›ğ‘‘ğ‘that is applied to determine the set-valued prediction
forğ’™. Note that, precise predictions are given as singleton subsets. The
predicted subset of classes, using the rule ğ‘Ÿğ‘›ğ‘‘ğ‘, is the one maximizing
the expected utility where the utility associated to each subset of classes
is defined using the ğ¹ğ›½measure. More precisely, let us consider a set
ofğ‘›class labels ğ›©= {ğœƒ1,â€¦,ğœƒğ‘›}, the utility of each subset of candidate
classesğ´âŠ†ğ›© as the good prediction for ğ’™, having the true class ğœƒğ’™, is
evaluated using the ğ¹ğ›½measure as follows:
ğ¹ğ›½(ğ´,ğœƒğ’™) =(1 +ğ›½2)â‹…|{ğœƒğ’™} âˆ©ğ´|
ğ›½2+|ğ´|, (2)
whereğ›½is a positive real number and |ğ‘‹|, forğ‘‹ âŠ† ğ›© , denotes
the number of elements in ğ‘‹. The quantity ğ¹ğ›½(ğ´,ğœƒğ’™)is interpretedas the utility obtained when predicting the subset of class labels ğ´
when the true class label is ğœƒğ’™. Eq. (2) is analogue to the one in (1)
where the quantities precision andrecall are redefined as precision(ğ´) =
|{ğœƒğ’™}âˆ©ğ´|
ğ‘›ğ‘ğ‘œğ‘“ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘ ğ‘–ğ‘›ğ´andrecall(ğ´) =|{ğœƒğ’™} âˆ©ğ´|. Note that when the value of ğ›½
is close to 0,ğ¹ğ›½(ğ´,ğœƒğ’™)becomes close to precision(ğ´)thus the size of ğ´is
disadvantageous, i.e. the larger size of ğ´the smaller the utility. On the
other hand, when ğ›½is high,ğ¹ğ›½(ğ´,ğœƒğ’™)becomes close to recall(ğ´)and in
this case the size of ğ´is advantageous. Let us suppose that a posterior
probability distribution ğ‘ğ›¿(.|ğ’™)is provided by a point prediction method
ğ›¿for the sample ğ’™, then the non-deterministic classifier ndcpredicts
forğ’™the subset of candidate classes that maximize the expected utility
function E(ğ¹ğ›½(ğ´,.)|ğ’™), i.e. :
E(ğ¹ğ›½(ğ´,.)|ğ’™) =ğ‘›âˆ‘
ğ‘–=1ğ¹ğ›½(ğ´,ğœƒğ‘–)â‹…ğ‘ğ›¿(ğœƒğ‘–|ğ’™). (3)
Finally, the predicted subset ğ‘Ÿğ‘›ğ‘‘ğ‘(ğ’™)forğ’™using the classifier ndcis given
as:
ğ‘Ÿğ‘›ğ‘‘ğ‘(ğ’™) =ğ‘ğ‘Ÿğ‘” max
ğ´âˆˆ2ğ›©â§µâˆ…E(ğ¹ğ›½(ğ´,.)|ğ’™). (4)
2.3. The decision step in eclair classifier
The decision step with eclair consists in providing for a sample ğ’™a
subset of classes as prediction, by considering as input the posterior
mass function ğ‘š(.|ğ’™)and a hyper-parameter ğ›½. The predicted subset
of classes is the one maximizing the expected utility where the utility
associated to each subset of classes is defined using a generalization of
Eq. (2) [9,10]. The main change regarding Eq. (2) is to consider the
general case where the available information about the true class of ğ’™
can be partially known, i.e., a subset ğµğ’™ofğ›©. It is the case, for example,
when data are coarse [15,16]. The new utility function is then defined
for two subsets ğ´andğµğ’™ofğ›©as follows:
ğ¹ğ›½(ğ´,ğµğ’™) =(1 +ğ›½2)â‹…|ğ´âˆ©ğµğ’™|
ğ›½2â‹…|ğµğ’™|+|ğ´|(5)
The quantity ğ¹ğ›½(ğ´,ğµğ’™)is interpreted as the utility obtained when
predicting the subset of class labels ğ´for the sample ğ’™when its true
class label is partially known and represented by a subset of classes ğµğ’™.
In this case, the precision andrecall quantities become:
precision(ğ´) =|ğ´âˆ©ğµğ’™|
ğ‘›ğ‘ğ‘œğ‘“ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘ ğ‘–ğ‘›ğ´,
and
recall(ğ´) =|ğ´âˆ©ğµğ’™|
ğ‘›ğ‘ğ‘œğ‘“ğ‘ğ‘™ğ‘ğ‘ ğ‘ ğ‘’ğ‘ ğ‘–ğ‘›ğµğ’™.
Let us suppose that a posterior mass function ğ‘š(.|ğ’™)is known for
the sampleğ’™, the eclair classifier predicts for ğ’™the subset of candidate
classes that maximize the expected utility function E(ğ¹ğ›½(ğ´,.)|ğ’™), i.e :
E(ğ¹ğ›½(ğ´,.)|ğ’™) =âˆ‘
ğµâŠ†ğ›©ğ¹ğ›½(ğ´,ğµ)â‹…ğ‘š(ğµ|ğ’™), (6)
whereğµis the variable representing the true class label of ğ’™. Finally,
the predicted subset ğ‘Ÿğ‘’ğ‘ğ‘™ğ‘ğ‘–ğ‘Ÿ(ğ’™)forğ’™using the classifier eclair is given as:
ğ‘Ÿğ‘’ğ‘ğ‘™ğ‘ğ‘–ğ‘Ÿ(ğ’™) =ğ‘ğ‘Ÿğ‘” max
ğ´âˆˆ2ğ›©â§µâˆ…E(ğ¹ğ›½(ğ´,.)|ğ’™). (7)
2.4. Evaluation measures for the set-valued classifiers
When evaluating a set-valued classifier one ensures that the pre-
dicted subset of classes (1) includes the â€˜â€˜trueâ€™â€™ class and (2) it is as small
as possible depending on the sample data imperfection. Several works
have studied this problem and provide some measures to check the two
conditions (1) and (2) [2,7,17]. Between the least drastic one that is
imprecise accuracy which checks if the prediction contains the true class
label of the sample and the most drastic one that is classical accuracy
which checks if the prediction is equal to the true class label of theArray 19 (2023) 100310
3A. Imoussaten
sample, one can find intermediate measure as Discounted accuracy [18]
that seems to be an interesting measure as it takes into account the size
of the predicted subset. But in order to increase the cautiousness reward
to the degree to which the decision maker prefers to fix it depending
on his application and the quality of the information obtained for the
samples, a family of measure are constructed from Discounted accuracy
measure that are represented by a function ğ‘”taking its values in [0,1]
and guaranteeing ğ‘”(ğ‘§)â‰¥ğ‘§, i.e., the reward with ğ‘”is at least the same as
the one given by the discounted accuracy ,ğ‘”(0) = 0 andğ‘”(1) = 1 (see [19]
for more details). Let us consider a samples ğ’™having the true class ğœƒğ’™
and a set-valued classifier ğ›¿ğ‘–ğ‘. The five following measures are proposed
to evaluate the performance of ğ›¿ğ‘–ğ‘regarding its output for ğ’™:
â€¢theclassical accuracy denoted acc:
ğ‘ğ‘ğ‘(ğ›¿ğ‘–ğ‘,ğœƒğ’™) =1{ğœƒğ’™}(ğ›¿ğ‘–ğ‘(ğ’™)).
â€¢theimprecise accuracy denoted impr. acc :
ğ‘–ğ‘šğ‘ğ‘Ÿ.ğ‘ğ‘ğ‘ (ğ›¿ğ‘–ğ‘,ğœƒğ’™) =1ğ›¿ğ‘–ğ‘(ğ’™)(ğœƒğ’™).
â€¢thediscounted accuracy (discAcc) corresponds to the function
ğ‘”(ğ‘§) =ğ‘§[18]:
ğ‘‘ğ‘–ğ‘ ğ‘ğ´ğ‘ğ‘ (ğ›¿ğ‘–ğ‘,ğœƒğ’™) =1ğ›¿ğ‘–ğ‘(ğ’™)(ğœƒğ’™)
|ğ›¿ğ‘–ğ‘(ğ’™)|,
where|ğ´|denotes the size of the subset ğ´. This measure is also
denotedğ‘¢50.
â€¢Theğ‘¢65measure that corresponds to the function ğ‘”(ğ‘§) = âˆ’0.6â‹…
ğ‘§2+ 1.6â‹…ğ‘§[19]:
ğ‘¢65(ğ›¿ğ‘–ğ‘,ğ‘‘ğ‘ ğ‘¡) = âˆ’0.6â‹…[ğ‘‘ğ‘–ğ‘ ğ‘ğ´ğ‘ğ‘ (ğ›¿ğ‘–ğ‘,ğœƒğ’™)]2+ 1.6â‹…ğ‘‘ğ‘–ğ‘ ğ‘ğ´ğ‘ğ‘ (ğ›¿ğ‘–ğ‘,ğœƒğ’™).
â€¢Theğ‘¢80measure that corresponds to the function ğ‘”(ğ‘§) = âˆ’1.2â‹…
ğ‘§2+ 2.2â‹…ğ‘§[19]:
ğ‘¢80(ğ›¿ğ‘–ğ‘,ğœƒğ’™) = âˆ’1.2â‹…[ğ‘‘ğ‘–ğ‘ ğ‘ğ´ğ‘ğ‘ (ğ›¿ğ‘–ğ‘,ğœƒğ’™)]2+ 2.2â‹…ğ‘‘ğ‘–ğ‘ ğ‘ğ´ğ‘ğ‘ (ğ›¿ğ‘–ğ‘,ğœƒğ’™).
Note thatğ‘¢65is the average measure of ğ‘¢50andğ‘¢80and it is the
better suited one to quantify the compromise between precision and
cautiousness.
3. The expected utilities related to ğœ·
3.1. The case of ndc classifier
Let us consider that the posterior probability distribution of a sam-
pleğ’™is known. We denote this distribution by ğ‘(.|ğ’™) âˆ¶ğ›©â†’[0,1]. We
consider the parameter ğ›½as a variable and we express the expected
utility function in Section 2.2 for a ğ›½âˆˆ[0,+âˆ[,ğ´âŠ†ğ›© andğ‘(.|ğ’™)as:
ğ‘¢(ğ›½,ğ´) =E(ğ¹ğ›½(ğ´,.)|ğ’™) =ğ‘›âˆ‘
ğ‘–=1ğ¹ğ›½(ğ´,ğœƒğ‘–)â‹…ğ‘(ğœƒğ‘–|ğ’™). (8)
In addition, let us consider the situation where the class ğœƒğ‘˜is the most
likely class of ğ’™and some times the class ğœƒğ‘˜is confused with the class
ğœƒğ‘˜â€²,ğ‘˜â‰ ğ‘˜â€²due to data imperfection. The Propositions 3.1 and 3.2 give
some results concerning the predicted subset of classes for ğ’™among the
three options ğœƒğ‘˜,ğœƒğ‘˜ğ‘˜â€²andğ›©.
Proposition 3.1. Let suppose that ğ‘(ğœƒğ‘˜|ğ’™)> ğ‘(ğœƒ|ğ’™),âˆ€ğœƒâˆˆğ›©â§µğœƒğ‘˜and
ğœƒğ‘˜â€²=ğ‘ğ‘Ÿğ‘”maxğœƒâˆˆğ›©â§µğœƒğ‘˜ğ‘(ğœƒ|ğ’™).
Ifğ‘(ğœƒğ‘˜â€²|ğ’™)>0then it exists ğ›½1â‰¥0such that:
{
ğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²)â‰¤ğ‘¢(ğ›½,ğœƒğ‘˜)ifğ›½â‰¤ğ›½1
ğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²)>ğ‘¢(ğ›½,ğœƒğ‘˜)ifğ›½ >ğ›½1.(9)
Elsewhereğ‘¢(ğ›½,ğ›©)<ğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²),âˆ€ğ›½â‰¥0.
Proof. We have for all ğ›½â‰¥0,
ğ‘¢(ğ›½,ğœƒğ‘˜) =ğ‘(ğœƒğ‘˜|ğ’™).Table 1
The posterior probability distributions.
ğ‘¥ ğœƒ1 ğœƒ2 ğœƒ3
ğ‘¥1 0.333 0.333 0.333
ğ‘¥2 1 0 0
ğ‘¥3 0.5 0.5 0
ğ‘¥4 0.5 0.4 0.1
and
ğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²) =1 +ğ›½2
2 +ğ›½2â‹…[ğ‘(ğœƒğ‘˜|ğ’™) +ğ‘(ğœƒğ‘˜â€²|ğ’™)] =1 +ğ›½2
2 +ğ›½2â‹…P(ğœƒğ‘˜ğ‘˜â€²|ğ’™),
where for all subset ğ´ofğ›©,P(ğ´|ğ’™) =âˆ‘
ğœƒâˆˆğ´ğ‘(ğœƒ|ğ’™). On one hand, the
functionğ‘¢(.,ğœƒğ‘˜ğ‘˜â€²)increases related to ğ›½. Thusğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²)â‰¥ğ‘¢(0,ğœƒğ‘˜ğ‘˜â€²) =
1
2P(ğœƒğ‘˜ğ‘˜â€²|ğ’™), for allğ›½â‰¥0. On the other hand, ğ‘(ğœƒğ‘˜|ğ’™)> ğ‘(ğœƒğ‘˜â€²|ğ’™)then
ğ‘(ğœƒğ‘˜|ğ’™)>1
2P(ğœƒğ‘˜ğ‘˜â€²|ğ’™). So,ğ‘¢(.,ğœƒğ‘˜ğ‘˜â€²)intersectsğ‘¢(.,ğœƒğ‘˜)atğ›½1â‰¥0such that:
1 +ğ›½2
1
2 +ğ›½2
1â‹…P(ğœƒğ‘˜ğ‘˜â€²|ğ’™) =ğ‘(ğœƒğ‘˜|ğ’™).
It comes:
ğ›½1=âˆš
ğ‘(ğœƒğ‘˜|ğ’™) âˆ’ğ‘(ğœƒğ‘˜â€²|ğ’™)
ğ‘(ğœƒğ‘˜â€²|ğ’™).â–¡ (10)
Note that the same reasoning for the comparison between the
utilities of ğœƒğ‘˜andğœƒğ‘˜ğ‘˜â€²in Proposition 3.1 can be generalized for the
comparisons between the utilities of ğœƒğ‘˜and all the subsets ğ´ âŠ‚ ğ›©
containing ğœƒğ‘˜where
ğ‘¢(ğ›½,ğ´) =1 +ğ›½2
|ğ´|+ğ›½2â‹…P(ğ´|ğ’™),
in this case, ğ›½1becomes:
ğ›½1=âˆš
|ğ´|â‹…ğ‘(ğœƒğ‘˜|ğ’™) âˆ’P(ğ´|ğ’™)
P(ğ´|ğ’™) âˆ’ğ‘(ğœƒğ‘˜|ğ’™). (11)
Proposition 3.2. Let suppose that ğ‘(ğœƒğ‘˜|ğ’™)>ğ‘(ğœƒ|ğ’™),âˆ€ğœƒâˆˆğ›©â§µğœƒğ‘˜.
IfP(ğœƒğ‘˜ğ‘˜â€²|ğ’™) âˆˆ[2
3,1[ then it exists ğ›½2>0such that:
{
ğ‘¢(ğ›½,ğ›©)â‰¤ğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²)ifğ›½â‰¤ğ›½2
ğ‘¢(ğ›½,ğ›©)>ğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²)ifğ›½ >ğ›½2.(12)
Proof. We have for all ğ›½â‰¥0,
ğ‘¢(ğ›½,ğ›©) =1 +ğ›½2
3 +ğ›½2,
and
ğ‘¢(ğ›½,ğ›©) âˆ’ğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²) =(1 +ğ›½2)â‹…(2 âˆ’ 3â‹…P(ğœƒğ‘˜ğ‘˜â€²) + (1 âˆ’ P(ğœƒğ‘˜ğ‘˜â€²)â‹…ğ›½2))
(3 +ğ›½2)â‹…(2 +ğ›½2).
IfP(ğœƒğ‘˜ğ‘˜â€²|ğ’™)<2
3, thenğ‘¢(ğ›½,ğ›©)> ğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²),âˆ€ğ›½â‰¥0. Else, if P(ğœƒğ‘˜ğ‘˜â€²|ğ’™) = 1 ,
thenğ‘¢(ğ›½,ğ›©) =1+ğ›½2
3+ğ›½2<1+ğ›½2
2+ğ›½2=ğ‘¢(ğ›½,ğœƒğ‘˜ğ‘˜â€²),âˆ€ğ›½â‰¥0. Otherwise, let us
consider the following value ğ›½âˆ—â‰¥0such that:
ğ›½âˆ—2=3P(ğœƒğ‘˜ğ‘˜â€²|ğ’™) âˆ’ 2
1 âˆ’P(ğœƒğ‘˜ğ‘˜â€²|ğ’™), (13)
theğ›½2=ğ›½âˆ—verify the inequalities of Proposition 3.2. â–¡
Example 3.1. Let us consider the case where ğ›©= {ğœƒ1,ğœƒ2,ğœƒ3}. The
posterior probabilities of four samples are given in Table 1 and in Fig. 1.
These distributions express several situations of sharing the probability
masses between the three classes. For the first sample ğ‘¥1the mass
is uniformly distributed between the classes; for ğ‘¥2the total mass is
given to the class ğœƒ1; forğ‘¥3the mass is uniformly distributed between
ğœƒ1andğœƒ2; and forğ‘¥4the mass distribution is as follows ğ‘(ğœƒ3|ğ’™4)<
ğ‘(ğœƒ1|ğ’™4)<ğ‘(ğœƒ2|ğ’™4). As one can see in Fig. 1, for the samples ğ‘¥1,ğ‘¥2andArray 19 (2023) 100310
4A. Imoussaten
Fig. 1. The expected utility associated to the four posterior probabilities.
ğ‘¥3,ğ›©,ğœƒ1, andğœƒ1,2are respectively the predictions as they maximize
the expected utility regardless the value of ğ›½. While in the case of
ğ‘¥4, the prediction depends on the value of the parameter ğ›½. Indeed,
ifğ›½ <ğ›½1=âˆš
ğ‘(ğœƒ1|ğ’™4)âˆ’ğ‘(ğœƒ2|ğ’™4)
ğ‘(ğœƒ2|ğ’™4)= 0.5, i.e., the value of ğ›½where the curves
ofğ‘¢(.,ğœƒ1)andğ‘¢(.,ğœƒ1,2)intersect, then ğœƒ1dominates all the other options.
Whenğ›½2> ğ›½ > ğ›½1(ğ›½2=âˆš
3P(ğœƒ1,2|ğ’™)âˆ’2
1âˆ’P(ğœƒ1,2|ğ’™)= 2.65), thenğœƒ1,2dominates all
the other options. When ğ›½â‰¥ğ›½2, it is the turn of ğ›©to dominate the other
options.
3.2. The case of eclair classifier
In this subsection, we consider that the posterior mass function of
a sampleğ’™is known. We denote this mass function by ğ‘š(.|ğ’™) âˆ¶ 2ğ›©â†’
[0,1]. In this case, the expected utility function used as the criterion to
choose the subset of classes to associate to ğ’™is the following:
ğ‘¢ğ‘š(ğ›½,ğ´) =E(ğ¹ğ›½(ğ´,.)|ğ’™) =âˆ‘
ğµâŠ†ğ›©ğ¹ğ›½(ğ´,ğµ)â‹…ğ‘š(ğµ|ğ’™), (14)
In this section, we treat only the case of two classes. Consequently,
the multi-class case can be treated using one-against-one prediction
techniques and then infer the final prediction by merging all the
one-against-one predictions.
Proposition 3.3. Let us consider the case where ğ›©= {ğœƒ1,ğœƒ2}. Ifğ‘š(ğœƒ1|ğ’™)>
ğ‘š(ğœƒ2|ğ’™), then it exists ğ›½3â‰¥0such that:
{
ğ‘¢ğ‘š(ğ›½,ğœƒ12)â‰¤ğ‘¢(ğ›½,ğœƒ1)ifğ›½â‰¤ğ›½3
ğ‘¢ğ‘š(ğ›½,ğœƒ12)>ğ‘¢(ğ›½,ğœƒ1)ifğ›½ >ğ›½3(15)
Elsewhere,ğ‘¢ğ‘š(ğ›½,ğœƒ12)â‰¥ğ‘¢(ğ›½,ğœƒ1),âˆ€ğ›½â‰¥0.
Proof. In one hand, we have,
ğ‘‘ğ‘¢ğ‘š(ğ›½,ğœƒ1)
ğ‘‘ğ›½= âˆ’2ğ›½
(1 + 2ğ›½2)2ğ‘š(ğœƒ12|ğ’™)consequently ğ‘¢ğ‘š(.,ğœƒ1)decreases âˆ€ğ›½â‰¥0withğ‘¢ğ‘š(0,ğœƒ1) =ğ‘š(ğœƒ1|ğ’™) +
ğ‘š(ğœƒ12|ğ’™)and limğ›½â†’+âˆğ‘¢ğ‘š(ğ›½,ğœƒ1) =ğ‘š(ğœƒ1|ğ’™) +ğ‘š(ğœƒ12|ğ’™)
2. In the other hand,
we have,
ğ‘‘ğ‘¢ğ‘š(ğ›½,ğœƒ12)
ğ‘‘ğ›½=2ğ›½
(2 +ğ›½2)2[1 âˆ’ğ‘š(ğœƒ12|ğ’™)]
consequently ğ‘¢ğ‘š(.,ğœƒ12)increases âˆ€ğ›½â‰¥0withğ‘¢ğ‘š(0,ğœƒ12) =1
2+ğ‘š(ğœƒ12|ğ’™)
2and
limğ›½â†’+âˆğ‘¢ğ‘š(ğ›½,ğœƒ12) = 1 . Obviously, if ğ‘¢ğ‘š(0,ğœƒ1)> ğ‘¢ğ‘š(0,ğœƒ12)thenğ‘¢ğ‘š(.,ğœƒ1)
andğ‘¢ğ‘š(.,ğœƒ12)intersect, elsewhere ğ‘¢ğ‘š(ğ›½,ğœƒ12)â‰¥ğ‘¢ğ‘š(ğ›½,ğœƒ1),âˆ€ğ›½â‰¥0. The
inequalityğ‘¢ğ‘š(0,ğœƒ1)> ğ‘¢ğ‘š(0,ğœƒ12)corresponds to ğ‘š(ğœƒ1|ğ’™) +ğ‘š(ğœƒ12|ğ’™)>
1
2+ğ‘š(ğœƒ12|ğ’™)
2which is verified when ğ‘š(ğœƒ1|ğ’™)> ğ‘š(ğœƒ2|ğ’™). Finally,ğ›½3is
the solution of ğ‘¢ğ‘š(ğ›½,ğœƒ1) =ğ‘¢ğ‘š(ğ›½,ğœƒ12)which corresponds to the solution
of Eq. (16):
ğ‘š(ğœƒ1|ğ’™) +1 +ğ›½2
1 + 2ğ›½2ğ‘š(ğœƒ12|ğ’™) =1 +ğ›½2
2 +ğ›½2+1
2 +ğ›½2ğ‘š(ğœƒ12|ğ’™).â–¡ (16)
Remark 3.1. Note that when ğ‘šis a Bayesian mass function, i.e.,
ğ‘š(ğœƒ12|ğ’™) = 0 , Eq. (16) becomes: ğ‘š(ğœƒ1|ğ’™) =1+ğ›½2
2+ğ›½2, which is verified for
the following value of ğ›½3:
ğ›½3=ğ›½1=âˆš
ğ‘š(ğœƒ1|ğ’™) âˆ’ğ‘š(ğœƒ2|ğ’™)
ğ‘š(ğœƒ2|ğ’™).
Example 3.2. To illustrate different situations, we consider six mass
functions (see Table 2 and Fig. 2). Fig. 2 shows that when ğ‘š(ğœƒ1|ğ‘¥) =
ğ‘š(ğœƒ2|ğ‘¥), e.g.ğ‘š1andğ‘š4, regardless the mass of ğœƒ12, the option ğœƒ12obtains
the maximal gains for all ğ›½ > 0. In the other cases, the value of ğ›½3
depends on the mass of ğœƒ12, i.e, ignorance. Indeed, the higher the mass
of ignorance, the smaller the value of ğ›½3. This means that if the decision-
maker desire to make precise predictions for examples like those, he
needs to use very small value of ğ›½3lower than the solution of Eq. (16).Array 19 (2023) 100310
5A. Imoussaten
Fig. 2. The utility function for some examples of masses.
Table 2
Mass functions representing several uncertainty situations.
ğœƒ1ğœƒ2ğœƒ1,2 ğœƒ1ğœƒ2ğœƒ1,2
ğ‘š1 0.5 0.5 0 ğ‘š4 0.3 0.3 0.4
ğ‘š2 0.7 0.2 0.1 ğ‘š5 0.2 0 0.8
ğ‘š3 0.5 0.2 0.3 ğ‘š6 0.7 0.3 0
4. Illustration
In this section we present the illustration of the performances of
the classifiers ndcand eclair using generated data in Section 4.1 and
using fashion mnist data in Section 4.2. In the two subsections we
give the comparisons of the classifiers when the hyper-parameter is
tuned based on grid search method or based on the proposition of this
paper regarding the set-valued classification metrics and in Section 4.2
we show how to control the number of the predictions using our
propositions.
4.1. Illustration using simulated data
In this first illustration, we consider a simulated data for three class
labels a,b, and c. For each class label 500training samples of a bivariate
Gaussian distribution are considered, îˆº(ğœ‡ğ‘= (0.2,0.65),ğ›´ğ‘= 0.01ğ¼2)
for the class label ğ‘,îˆº(ğœ‡ğ‘= (0.5,0.9),ğ›´ğ‘= 0.01ğ¼2)for the class label
ğ‘andîˆº(ğœ‡ğ‘= (0.8,0.6),ğ›´ğ‘= 0.01ğ¼2)for the class label ğ‘. In addition,
a testing dataset of 50samples for each label are generated using the
same bivariate Gaussian distributions with a Gaussian noise îˆº(ğœ‡=
(0,0),ğ›´= 0.001ğ¼2). In the end, we have a dataset of 1500 training data
and150test data. First, nine point prediction classifiers are trained and
tested on these data. The point prediction classifiers considered are
the naive Bayes ( nbc), the k-Nearest Neighbour ( knn), the evidential
k-Nearest Neighbour ( eknn), the decision tree ( cart), the random forest(rfc), linear discriminant analysis ( lda), support vector machine ( svm)
and artificial neural networks ( ann), the logistic classifier ( logistic ). The
obtained accuracies are: logistic, ann: 94.67; svm, eknn: 95.33; and
knn, nbc, rfc, lda, cart: 96. These classifiers are introduced here to
detect the samples that are considered as â€˜â€˜strange samplesâ€™â€™ in this
paper, i.e., most point prediction classifiers fail to predict the true class
of those samples. In the opposite case, the samples are considered as
â€˜â€˜usual samplesâ€™â€™. This term will also be used, for a given classifier, to
distinguish the samples for which the predicted class obtains a large
probability, i.e., usual, from the others, i.e., strange.
4.1.1. The case of ndc classifier
The idea here for choosing the ndchyper-parameter ğ›½is to avoid
misclassification when the samples are strange and then predict a
subset of classes for those samples. For the samples that are â€˜â€˜usualâ€™â€™,
the posterior probability of one of the classes is close to 1, thus the
later class obtain the maximum utility regardless the value given to
ğ›½(see Section 3.1). Consequently, it is more interesting to fix the
value ofğ›½regarding the strange samples in the validation step. Indeed,
the training data of 1500 samples is divided to 1200 samples for
training and 300 (20%) samples for validation. The proposition of this
paper is to consider a fictive probability distribution ğ‘ğ‘“where the first
component is the mean of the maximal probabilities ğ‘1obtained for
strange samples of the validation data set and the second component is
the mean of the second maximal probabilities ğ‘2, and so on. Thus, ğ‘ğ‘“=
(ğ‘1,ğ‘2,â€¦). To determine the strange samples a probability threshold
is considered and it is fixed at 0.99 in this illustration. The value
ofğ›½is considered as the threshold behind which if the samples are
considered strange, we should predict the subset of the two first classes
with maximal probabilities. In Proposition 3.1 this theoretical value
corresponds to:
ğ›½ğ‘›ğ‘‘ğ‘=âˆš
ğ‘1âˆ’ğ‘2
ğ‘2. (17)Array 19 (2023) 100310
6A. Imoussaten
Fig. 3. The predictions obtained with ndc: a large size is given to the point symbols representing predictions that are errors or imprecise.
In Fig. 3, we present the predictions on the data set when ğ›½ğ‘›ğ‘‘ğ‘= 2.677
is determined as in Eq. (17) on the validation data. The samples that
are considered strange for the point prediction classifiers are labelled
by their number in the test dataset. Only the sample number 140is
misclassified in the predictions of ğ‘›ğ‘‘ğ‘and only three â€˜â€˜usualâ€™â€™ samples
have imprecise predictions. In general, among the ten strange samples,
eight samples are predicted as subsets of two classes containing the true
class and one as the whole set.
4.1.2. The case of eclair classifier
For the case of eclair classifier, we consider binary classifications
â€˜â€˜a against bâ€™â€™, â€˜â€˜a against câ€™â€™ and â€˜â€˜b against câ€™â€™. We apply the same
reasoning as in Section 4.1.1, the training data of is divided to 80%
samples for training and 20% samples for validation. Here, also we
consider only strange samples with the same mass threshold, i.e., 0.99.
From Section 3.2, to avoid misclassification for strange samples ğ›½
should be heigh enough to predict ğœƒ12when ignorance is heigh. Let
us denoteğ‘š12the average of ğ‘š(ğœƒ12|ğ‘¥)obtained for each strange sample
in the validation data set. The proposed value of ğ›½isğ›½ğ‘’ğ‘ğ‘™ğ‘ğ‘–ğ‘Ÿ that is the
solution of the quadratic Eq. (16) with ğ‘š(ğœƒ12|ğ‘¥) =ğ‘š12andğ‘š(ğœƒ1|ğ‘¥) =
2â‹…(1 âˆ’ğ‘š12)âˆ•3. In Fig. 4, we can see that, for the case â€˜â€˜a against bâ€™â€™
(ğ›½ğ‘’ğ‘ğ‘™ğ‘ğ‘–ğ‘Ÿ = 0.519), we have one misclassification and four set-valued
classification for the strange samples. For the case of â€˜â€˜a against câ€™â€™
(ğ›½ğ‘’ğ‘ğ‘™ğ‘ğ‘–ğ‘Ÿ = 0), we have one misclassification and all the other strange
samples are good predictions. While for the case â€˜â€˜b against câ€™â€™( ğ›½ğ‘’ğ‘ğ‘™ğ‘ğ‘–ğ‘Ÿ =
0.581), we have one misclassification and one set-valued classification
for the strange samples.
4.2. Illustration using fashion mnist data
In this section we propose to select the hyper-parameter ğ›½for the
two classifiers ndcandeclair based on Eq. (10) for the modern version
of mnist dataset [20], i.e. fashion mnist dataset [21]. These data are
more difficult to handle compared to the original ones. Fashion-MNIST,a direct drop-in replacement for the original Y. Lecunâ€™ MNIST dataset
for benchmarking machine learning algorithms [20], is a dataset of
Zalandoâ€™s article images [21] consisting of a training set of 60,000
examples and a test set of 10,000 examples. Each example is a 28 Ã—28
gray-scale image, associated with a label from 10 classes. Fig. 5 shows
several images from this dataset where each class takes three-rows. As
one can see in Figs. 6 and 7 (taken from [22]) from the visualization of
datasets that makes comparison between mnist and fashion mnist [21,
22], fashion mnist dataset seems to be more challenging while for mnist
dataset, classes are clearly separated.
Note that this illustration is presented only for the ndc classifier.
First, we apply a grid search optimization to select the hyper-parameter
ğ›½for ndc classifier. The grid search method is based on the objective
functionğ‘¢65as it is better suited to quantify the compromise between
precision and cautiousness. Fig. 8 shows the performances obtained
for the selected grid within the interval [0,3]on the validation data
sets, i.e., 20% of training data, ğ›½= 0.857gives the optimal mean
performance at 0.954.
The fashion mnist data set has 10classes, so it is more difficult
to fix the probability threshold for strange samples compared to the
simulated dated in Section 4.1. Thus, to calculate the different values of
ğ›½in the same way as in Section 4.1.1, we considered several threshold
of probabilities and represent the number of predicted subsets for each
valueğ›½1calculated as in Eq. (11) on the validation data. Let recall that
the number of data test is 10000 . Moreover, the point prediction classi-
fier used regarding the data nature to learn the posterior probabilities
is the artificial neural networks (sequential model). Fig. 9 gives the
parameter details of the employed architecture. Figures from 10 to 17
give the number of times a subset of 2, 3, 4, 5, 6 and 10 are predicted
related of the values of ğ›½given in the legend. Obviously when changing
the threshold of probabilities for strange examples, the values of ğ›½1
change. In Fig. 10, the value ğ›½1= 0.511corresponds to the ğ›½beyond
which the utility of predicting a subset of size 2 is higher than the
utility of prediction a single class; the value ğ›½1= 1.004correspondsArray 19 (2023) 100310
7A. Imoussaten
Fig. 4. The predictions obtained with eclair : a large size is given to the point symbols representing predictions that are errors or imprecise.
Fig. 5. Fashion-MNIST samples (by Zalando, MIT License).
The classes are: 1=â€˜T-shirt/topâ€™, 2=â€˜Trouserâ€™, 3=â€˜Pulloverâ€™, 4=â€˜Dressâ€™, 5=â€˜Coatâ€™, 6=â€˜Sandalâ€™, 7=â€˜Shirtâ€™, 8=â€˜Sneakerâ€™, 9=â€˜Bagâ€™, 10=â€˜Ankle bootâ€™.
to theğ›½beyond which the utility of predicting a subset of size 3 is
higher than the utility of prediction a subset of size 2; and so on.
One can see that only subsets of size 2, 3, 4 and 5 are predicted, therest of the prediction are single classes. Furthermore, we can observe
a slight increase of the predictions of 2, 3, 4 and 5 classes when the
probability threshold increase. This is due to the mean of probabilitiesArray 19 (2023) 100310
8A. Imoussaten
Fig. 6. mnist data clustering.
Fig. 7. Fashion mnist data clustering.
Fig. 8.ğ›½hyper-parameter grid search optimization for ndc.
Fig. 9. The neural networks architecture.
Fig. 10. Threshold fixed at ğ‘= 0.55.
Table 3
ğ‘¢65performances for difference values of ğ›½andğ‘on the test data of fashion mnist.
ğ‘= 0.55ğ‘= 0.6ğ‘= 0.65ğ‘= 0.7ğ‘= 0.75 Grid search
ğ‘¢65 0.9241 0.9245 0.9249 0.9245 0.9244 0.9244
ğ›½1 1.379 1.118 1.224 1.339 0.803 0.857
that are influenced by the values of large probabilities of â€˜â€˜usualâ€™â€™
samples.
Table 3 shows the best ğ‘¢65performance measure for each probability
threshold. One can see also, in the last column, the ğ‘¢65performance
measure obtained using the optimal hyper-parameters tuned with grid
search method. As we can except for ğ‘= 0.55, the results obtained with
our proposition are better than grid search one.
5. Related works
The closest work, in principle, to that of the proposal of this article,
is the one of conformal prediction. Conformal prediction is designed to
perform label predictions successively, each one begin revealed before
the next is predicted [ 11â€“13], but it is also adapted to classical predic-
tion task as for regression [ 14]. The general principal is the following:Array 19 (2023) 100310
9A. Imoussaten
Fig. 11. Threshold fixed at ğ‘= 0.6.
Fig. 12. Threshold fixed at ğ‘= 0.65.
Fig. 13. Threshold fixed at ğ‘= 0.7.
(1) training data are divided to training part and calibration/validation
part; (2) a classifier/regressor ğ›¿is learnt using the training part; (3)
non-conformity (strangeness) score is computed on the calibration part
by comparing the predictions of ğ›¿to the true labels; (4) in the same
way as in 3-, each potential class ğ‘¦of a sample ğ‘¥in the test data is
associated a non-conformity score ğ›¼ğ‘¦related the prediction of ğ›¿; (5)
then theğ‘-value is defined for the potential class ğ‘¦ofğ‘¥as the portion
of the calibration data and ğ‘¥that have a non-conformity scores greater
thanğ›¼ğ‘¦; (6) for a given small positive value ğœ–(1% or 5%), the predictive
region output (or the set-valued prediction) is the subset: {ğ‘¦âˆ¶ğ‘(ğ‘¦)>ğœ–}.
The common point between the two classifiers is the fact of building
the predictions for the new samples on the basis of the non-conformity
or the strangeness of some (or all) the samples of the calibration data
Fig. 14. Threshold fixed at ğ‘= 0.75.
Fig. 15. Threshold fixed at ğ‘= 0.8.
Fig. 16. Threshold fixed at ğ‘= 0.85.
compared to what was learned by the classifiers. While the difference
lies in how the non-conformity scores are calculated on the one hand,
and how the predictions are performed on the other hand. Indeed, in
our proposal, non-conformity score is calculated with respect to the
certainty of the prediction, i.e., how closely the sample resembles other
training samples regardless the true class of the calibration samples.
Concerning the set-valued predictions conformal prediction is based
on the concept of confidence level which well established in statistics,
while in our proposal predictions are based on a compromise through
a subjective utility which compares the subsets of classes. Moreover,
Table 4 shows the results obtained by the conformal predictions for
two different confidence levels (0.95% and 0.99%) for the fashion mnist
data. As one can see in the comparison with the result shown in Table 3,
our proposition obtained better ğ‘¢65scores. But with a high confidence
level, conformal prediction shows a very high score for â€˜â€˜impr. accâ€™â€™ atArray 19 (2023) 100310
10A. Imoussaten
Fig. 17. Threshold fixed at ğ‘= 0.9.
Table 4
Conformal predictions for the test data of fashion mnist.
ğ‘ğ‘ğ‘ ğ‘¢50 ğ‘¢65 ğ‘¢80 Impr. acc
ğœ–= 0.05 0.6785 0.792 0.83 0.868 0.947
ğœ–= 0.01 0.4817 0.6642 0.729 0.7945 0.9888
the expense of a very low accuracy score. The decision rule strategies
have different complexity and it is challenging as the set of alternatives
size is 2ğ‘›,ğ‘›=|ğ›©|. The ndcclassifier has the lowest optimized computa-
tional complexity, i.e., at worst ğ‘‚(ğ‘›)[5]. However, the computational
complexity is challenging for conformal prediction (see [ 14] for more
details) and for eclair classifiers (see [ 10] for more details). Indeed, for
conformal predictions, the non-conformity scores are calculated using
the nearest neighbours of the calibration or test samples in the training
data [ 11]. Regarding eclair classifier, as for any approach representing
imprecision in the data, the computational complexity can be very high.
Indeed, the computational complexity of the reasoning step of the eclair
classifiers becomes very high, i.e., ğ‘‚(22ğ‘›), at worst. One can find in [ 10]
some optimizations to overcame the problem. For example, by selecting
the relevant candidate subsets for prediction to a subset of 2ğ›©.
6. Conclusion
In this paper we are interested in the set-valued classification. Espe-
cially, we focus on the study of the parameter ğ›½involved in the utility
function used in the decision step of two set-valued classifiers. More
precisely, we studied the predicted subsets depending on this hyper-
parameter. In addition to theoretical propositions, we give practical
method to control the size of the predicted subset in machine learning
applications. While trying to remain very efficient on point prediction
task, set-valued classifiers have the challenge of making machine learn-
ing methods more trustworthy, especially in the presence of imperfect
data. The decision-maker who knows well his data could better control,
using the proposal of this article, the size of the predictions by fixing
the suited value for ğ›½. As a perspective, we intend in our next work
to provide a demonstration that relies on theoretical foundations and
statistical hypotheses to support the choices of the different thresholds
that are experimentally set in our illustrations. We will also try to
handle the merging part of the â€˜â€˜one against allâ€™â€™ solution suggested
in the eclair part. Indeed, we obtain different values of ğ›½3for each
pair comparisons which make the merging part of the pair comparisons
difficult to handle.CRediT authorship contribution statement
Abdelhak Imoussaten: Study conception and design, Data collec-
tion, Analysis and interpretation of results, Writing â€“ original draft.
Declaration of competing interest
The authors declare that they have no known competing finan-
cial interests or personal relationships that could have appeared to
influence the work reported in this paper.
Data availability
The information about the data are given in the paper.
References
[1] Jacquin L, Imoussaten A, Trousset F, Perrin D, Montmain J. Control of waste frag-
ment sorting process based on MIR imaging coupled with cautious classification.
Resour Conserv Recy 2021;168:105258.
[2] Zaffalon M. A credal approach to naive classification. In: ISIPTA, vol. 99. 1999,
p. 405â€“14.
[3] Zaffalon M. Statistical inference of the naive credal classifier. In: ISIPTA, vol. 1.
2001, p. 384â€“93.
[4] Troffaes MC. Decision making under uncertainty using imprecise probabilities.
Int J Approx Reason 2007;45(1):17â€“29.
[5] Coz JJd, DÃ­ez J, Bahamonde A. Learning nondeterministic classifiers. J Mach
Learn Res 2009;10(Oct):2273â€“93.
[6] AbellÃ¡n J, Moral S. Building classification trees using the total uncertainty
criterion. Int J Intell Syst 2003;18(12):1215â€“25.
[7] Abellan J, Masegosa AR. Imprecise classification with credal decision trees. Int
J Uncertain Fuzziness Knowl-Based Syst 2012;20(05):763â€“87.
[8] Ma L, Denoeux T. Partial classification in the belief function framework.
Knowl-Based Syst 2021;106742.
[9] Jacquin L, Imoussaten A, Trousset F, Montmain J, Perrin D. Evidential classifica-
tion of incomplete data via imprecise relabelling: Application to plastic sorting.
In: Ben Amor N, Quost B, Theobald M, editors. Scalable uncertainty management.
Cham: Springer International Publishing; 2019, p. 122â€“35.
[10] Imoussaten A, Jacquin L. Cautious classification based on belief functions theory
and imprecise relabelling. Internat J Approx Reason 2022;142:130â€“46.
[11] Shafer G, Vovk V. A tutorial on conformal prediction. J Mach Learn Res
2008;9(Mar):371â€“421.
[12] Vovk V, Gammerman A, Shafer G. Conformal prediction. Algorithmic Learn
Random World 2005;17â€“51.
[13] Gammerman A, Vovk V, Vapnik V. Learning by transduction. 2013, arXiv
preprint arXiv:1301.7375 .
[14] Papadopoulos H, Proedrou K, Vovk V, Gammerman A. Inductive confidence
machines for regression. In: Machine learning: ECML 2002: 13th European con-
ference on machine learning Helsinki, Finland, August 19â€“23, 2002 proceedings
13. Springer; 2002, p. 345â€“56.
[15] Couso I, SÃ¡nchez L. Machine learning models, epistemic set-valued data
and generalized loss functions: an encompassing approach. Inform Sci
2016;358:129â€“50.
[16] Sanchez L, Couso I. A framework for learning fuzzy rule-based models with
epistemic set-valued data and generalized loss functions. Internat J Approx
Reason 2018;92:321â€“39.
[17] Yang G, Destercke S, Masson M-H. The costs of indeterminacy: How to determine
them? IEEE Trans Cybern 2016;47(12):4316â€“27.
[18] Tsoumakas G, Vlahavas I. Random k-labelsets: An ensemble method for multil-
abel classification. In: European conference on machine learning. Springer; 2007,
p. 406â€“17.
[19] Zaffalon M, Corani G, MauÃ¡ D. Evaluating credal classifiers by utility-discounted
predictive accuracy. Internat J Approx Reason 2012;53(8):1282â€“301.
[20] LeCun Y. The MNIST database of handwritten digits. 1998, http://yann.lecun.
com/exdb/mnist/ .
[21] Xiao H, Rasul K, Vollgraf R. Fashion-mnist: a novel image dataset for
benchmarking machine learning algorithms. 2017, arXiv preprint arXiv:1708.
07747 .
[22] Agrawal A, Ali A, Boyd S. Minimum-distortion embedding. 2021, arXiv.