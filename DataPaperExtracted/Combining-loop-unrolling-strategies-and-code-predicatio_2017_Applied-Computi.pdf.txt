Original Article
Combining loop unrolling strategies and code predication to reduce theworst-case execution time of real-time software
Andreu Carminatia,b,⇑, Renan Augusto Starkec, Rômulo Silva de Oliveiraa
aUniversidade Federal de Santa Catarina, DAS-CTC-UFSC, Caixa Postal 476, Florianp ´olis, SC, Brazil
bInstituto Federal de Santa Catarina, Campus Gaspar, Gaspar, SC, Brazil
cInstituto Federal de Santa Catarina, Campus Florianp ´olis, Florianp´olis, SC, Brazil
article info
Article history:Received 19 October 2016Revised 29 March 2017Accepted 31 March 2017Available online 13 April 2017Keywords:Real-time systemsLoop unrollingWorst-case execution timePredicationabstract
Worst-case execution time (WCET) is a parameter necessary to guarantee timing constraints on real-timesystems. The higher the worst-case execution time of tasks, the higher will be the resource demand forthe associated system. The goal of this paper is to propose a different way to perform loop unrolling ondata-dependent loops using code predication targeting WCET reduction, because existing techniquesonly consider loops with ﬁxed execution counts. We also combine our technique with existing unrollingapproaches. Results showed that this combination can produce aggressive WCET reductions when com-pared with the original code./C2112017 Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an open accessarticle under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. IntroductionWCET is an important parameter necessary for the developmentof real-time applications and systems. Usually denoted by C,o r computation time of a task, this parameter is required by virtuallyall scheduling strategies that can be used to guarantee that all tasksof a given real-time system will meet their deadlines [1–3]. The schedulability of a real-time system can be enhanced if we reducetasks’ worst-case execution times and consequently the processordemand. For this objective, we can employ a faster processor,which is usually an expensive approach, or optimize the softwareresponsible for the tasks function. The second approach can be per-formed automatically at compile time using code optimizationstrategies, as done by[4,5].The key aspect of optimizations directed to WCET reduction isthe use of timing analyzers to evaluate the result of code transfor-mations in terms of WCET. Such timing analyzers are frequentlyconnected with compilers to inform if a code transformationincreases, decreases or has no effect concerning WCET. This com-piler integration with WCET analyzers is important to discoverwhich path is responsible for generating the worst-case executiontime, and to track any path change due to successive codetransformations.Loops are frequently good target candidates for compiler opti-mizations to extract performance of modern processor architec-tures. Loop unrolling is a well-known technique used to improveaverage-case performance of programs. This technique consists inreplicating the loop body for a certain number of times to avoidbranch and jump overhead and to reduce the number of incre-ment/decrement operations, inserting extra code to verify exitingcorner cases, if necessary. The number of body replications is oftencalledunrolling factorand the original loop is calledrolled loop. Loop unrolling can contribute to improve the instruction levelparallelism (ILP) and execution performance of programs, byenabling more optimization that are affected by code expansion.Although, this code expansion can lead to instruction-cache perfor-mance degradation, if not carefully applied. If loop unrolling isapplied before the register allocation phase, register pressure canbe increased, leading to the insertion of more spill and reload oper-ations in the code. However, a standard compiler cannot use loopunrolling directly if worst-case execution time (WCET) reductionis desirable, due to the instability of the execution path that gener-ates the worst possible execution time and negative cache effects.Some techniques were proposed in the literature to achieve WCETreduction using loop unrolling, as in [4,6]. In these works, loops are
http://dx.doi.org/10.1016/j.aci.2017.03.0022210-8327//C2112017 Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).⇑Corresponding author at: Universidade Federal de Santa Catarina, DAS-CTC-UFSC, Caixa Postal 476, Florianp ´olis, SC, Brazil. E-mail address:andreu.carminati@posgrad.ufsc.br (A. Carminati). Peer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics 13 (2017) 184–193
Contents lists available atScienceDirect
Applied Computing and Informatics
journal homepage: www.sciencedirect.com
carefully unrolled to promote WCET reduction and limit codeincrease. But, only loops with ﬁxed execution counts areconsidered.The contribution of this paper is twofold. Firstly, we propose analternative way to perform loop unrolling on loops with arbitrary(or variable) execution counts. Traditionally, loops with unknownexecution counts are unrolled with ﬁxed unrolling factors, withthe corner conditions (i.e, the unrolling factor is not a multiple ofthe number of iterations) treated with branch instructions. Theapproach adopted in this work is to treat the same corner condi-tions using code predication instead of instructions that performcontrol ﬂow changes. Code predication is already used in softwarepipelining of loops, but its application directly with loop unrollingwas not reported in the literature. Code predication also can beexplored using a transformation called If-Conversion, which is a standard compiler optimization that converts control dependen-cies into data dependencies, removing branches.The second contribution of this paper is the combination of ourtechnique with other standard unrolling approaches for datadependent loops and loops with ﬁxed execution counts. In thisway, we can decide on a per loop level which of the approachesshould be used for loop unrolling. This combination of techniquesis important because not every loop can be unrolled in the sameway. For example, loops with variable number of iterations mustinclude compare and branch instructions to treat different exitconditions, but loops with static execution counts can be unrolledwithout these instructions. The necessity of compare and branchinstructions is not the only difference when unrolling these twotypes of loops, but the selection of a valid unrolling factor is alsodifferent. In loops with a static number of iterations, we can onlyconsider unrolling factors that perfectly divide such number ofiterations. Until the present moment, no work addressing the com-bination of different unrolling techniques was identiﬁed in theliterature.We evaluated the results on an experimental processor, whichimplements a subset of thevery long instruction word(VLIW) ST231 ISA that was extended to support a simpliﬁed full-predication mechanism.The remainder of this paper is organized as follows: Section 2 outlines the related work on loop unrolling directed to WCETreduction. Section3shows the motivations of this work. Section 4 explains the proposed approach to perform loop unrolling target-ing real-time applications. In Section 5we describe brieﬂy our testbed. Section6presents the obtained results using a benchmarksuite. In Section7presents our conclusions and ﬁnal remarks.2. Related workThe ﬁrst work that concerns WCET reduction using loop unrol-ling, consists in applying this optimization directly at assemblylevel[4]. In this work, only innermost loops with ﬁxed numberof iterations are unrolled and the unrolling factor used for all loopsis 2. Although, not all candidate loops are unrolled, but only thosethat are present in the worst-case execution path (WCEP), and theyare kept unrolled only if WCET reduction is achieved. At every opti-mization application, the WCET information must be re-calculatedto update the worst-case path information that drives the algo-rithm. This recalculation is necessary because any code change thataffects the WCET may result in a WCEP change. These WCET recal-culations are a common strategy employed by compilers focused inworst-case execution time reduction. Experiments using a proces-sor with no caches showed that a WCET reduction up to 10% wasachieved for all benchmarks.Another approach to perform loop unrolling aiming at WCETreduction was proposed in[6]. Here, the optimization is appliedat the source code level and uses a processor with instructioncache and scratchpad memory. As the optimization is applied atthe source code level, the success of next optimizations performedby the compiler is enhanced, specially for those that beneﬁt fromcode expansion. The key aspects of the technique are: (1) choosethe most proﬁtable loops concerning WCET reduction and (2) cal-culate an unrolling factor considering memory constraints. Conse-quently, the algorithm balances memory utilization and WCETreduction.Both the previously presented approaches consider only loopswith ﬁxed number of iterations. In fact, both techniques can beused to unroll loops with arbitrary counts or data-dependent loops,providing necessary code to exit the loop when the terminationcondition is reached. This code is commonly generated as branchinstructions.If-Conversion[7]is a technique used to convert control depen-dencies into data dependencies. The basic principle consists ineliminating gotos and branches and inserting logical variables to
control the execution of instructions in the program. If- Conversioncan be performed at IR-level or machine-level as statedby[8]and is related to region enlargement techniques used toexpand the instruction scheduling scope beyond a single basicblock, which is specially beneﬁcial for very long instruction word machines(VLIW).The application ofIf-Conversiontechniques in loops is not a novelidea. Software pipeline[9]can beneﬁt fromIf-Conversionand code predication to control the execution of prologue and epilogue ofpipelined loops[10]. Another technique that can beneﬁt from If- Conversionis loop ﬂattening[11]. Loop ﬂattening is a form of soft-ware pipelining that merges nested loops into a single loop body,providing necessary code to control the execution and the ﬂow ofdata between blocks. In[12]If-Conversionis used to eliminate back-edges of ﬂattened loops. The next section outlines the motiva-tion and the key ideas behind the proposed unrolling technique.3. MotivationWe can consider the loop of the code listing of Listing 1as a motivational example. This code shows a loop with the numberof iterations dependent on the value of a variable (called data-dependent loop). For this loop, a compiler commonly generates acontrol ﬂow structure that is shown in Fig. 1. In this structure, a simpleforloop has two basic blocks calledheaderandbodywhich are surrounded by anentryand anexitbasic blocks. There are some approaches to perform the loop unrolling opti-mization considering this loop. The simpler strategy consists inoptimizing only loops with ﬁxed counts. In this case, the compilerchooses an unrolling factor that exactly divides the number of iter-ations of the loop. If a compiler is able to optimize data-dependent
Listing 1.Simple data-dependent loop.A. Carminati et al. / Applied Computing and Informatics 13 (2017) 184–193 185loops with unknown number of iterations, it must take care of left-over iterations. Another problem with data-dependent loops is thedifﬁculty to choose an effective unrolling factor.Listing2shows the application of loop unrolling on the data-dependent loop of Listing1(in C code for simplicity). Is this case,if the compiler is not able to calculate the number of iterationsfor the loop, or determine whether this number is odd or even, itmust check the exit condition on every body replication, as doneby theifstatements. This condition checking leads to a control ﬂowgraph that is shown inFig. 2.Note that with this approach, the number of branching instruc-tions is augmented, also increasing the number of basic blocks.From the WCET perspective, by increasing the number of basicblocks, we increase the search space that contains the worst-caseexecution path that produces the WCET. From the code generationpoint of view, a branch may need up to 3 intermediate operationsthat are not necessarily in this order: (1) condition calculation, (2)target address calculation and (3) branch execution. Depending onthe target architecture, all previous operations are executed by oneinstruction or are segmented in sequences of 2 or 3 instructions.Considering the use of a target architecture with instructionpredication support, it is possible to remove branch operations (ifany) from loops that are unrolled. For this purpose, we can con-sider the loop of Listing3and its respective CFG shown inFig. 3. This loop is semantically equivalent to the loop of Listing 2.I fw e can rewrite an unrolled loop in terms of conditional expressions,as done to Listing2to obtain Listing3, it is possible to applyIf- Conversionsto the code. Until the writing of this paper, no tech-
niques exist in the literature to perform these transformations tounrolled data-dependent loops. As we stated before, If-Conversion is an optimization technique that converts control dependence intodata dependence through the deﬁnition of guards to control theexecution of instructions. If the target architecture supportsinstruction predication,If-Conversioncan result in branchless code, reducing code size and number of basic blocks. Generically, anapplication ofIf-Conversionto the code of Listing3would produce the control ﬂow graph ofFig. 4. The preﬁx (p) means that the exe- cution of the basic blocksbody 2andbody 3are conditioned to some predication guardp.From the WCET perspective, the common behavior of analyzersis to consider the complete execution of the loop iterations. In thisway, the last iteration will be considered fully executed, even withthe possibility of an early loop exit if the condition is reached. If aentry
header
body exit
Fig. 1.Control ﬂow graph of Listing 1.
Listing 2.Unrolled loop.entry
header
body 1
exit body 3body 2
Fig. 2.Control ﬂow graph of Listing 2.
Listing 3.Unrolled loop rewritten with conditional expressions.186 A. Carminati et al. / Applied Computing and Informatics 13 (2017) 184–193loop is always fully executed in the worst case, it is beneﬁcial toreduce the number of instructions of the unrolled loop, and if pre-mature exits will never be taken (branch instructions), we caneliminate them from the code using predication. Using code pred-ication we decrease the number of instructions while preservingthe semantics of the code.In the next section, we present our approach to perform loopunrolling which applies simultaneously code predication directlyin machine code. The technique starts from a simple data-dependent loop and directly generates an unrolled and predicatedversion, as done step-by-step in this section. The main improve-ment of our approach is that it avoids the use of branch instruc-tions, differently from what is usually done by traditionaltechniques.4. Our loop unrolling approachOur loop unrolling algorithm performs code predication in con-junction with the unrolling steps. In this way, sophisticated If- Conversionstrategies can be avoided. The algorithm must be useddirectly in assembly representation. The architectural requirementof the technique is the existence of full-predication mechanisms tocontrol the execution of instructions. As example of such mecha-nisms, we can cite IA-64[13]and ARM[14](except for Thumb instructions). The technique also beneﬁts from branches that aresegmented in sequences of more than one operation.The steps to unroll a loop are shown by Algorithm 1. The algo- rithm assumes that every loop that will be unrolled is composed bya header and a body. This constraint must be ensured by the callerof the algorithm procedure. Another requirement is the implemen-tation of loop headers with compare instruction followed bybranch instructions to control the loop exit.Algorithm 1.Predicated Loop Unrolling algorithm.1:procedurePREDICATED LOOPUNROLLINGðLoop;U;PÞ .Unroll loop u times2:Header loopHeaderðLoopÞ3:Body loopBodyðLoopÞ4:remo
veUncondBranchðBodyÞ5:BodyCopy createCopyðBodyÞ 6:fori 1t oU/C01do7:NewHeader createCopyðHeaderÞ 8:remo
veConditionalBranchðNewHeaderÞ 9:changeCompareOutputðNewHeader;PÞ 10:Body unifyðBody;NewHeaderÞ 11:NewBody createPredCopyðBodyCopy;PÞ 12:Body unifyðBody;NewBodyÞ 13:end for14:insertUncondBranchðBody;HeaderÞ 15:end procedureThe algorithm works as follows: First, header and body areidentiﬁed, which is done by Lines 2 and 3. The second step removesthe unconditional branch from the loop body to the header. Thisbranch instruction will be re-inserted at the end of the algorithm,as a last instruction (Line 14). The next step is to unroll the loopusing the provided unrolling factor, using the original loop bodyas ﬁrst copy.For each unroll step, we create a copy of the header, convertingcontrol ﬂow instructions into instructions that control the predica-tion of subsequent copies of the loop body (Lines 7–10). Then, wemake a predicated copy of the body that is amended at the end ofthe original body (Lines 11 and 12). The algorithm basicallyremoves forward branches used to exit the loop and inserts boo-lean guards to control the execution of the remaining part of theloop. These guards are stored in the Pvariable.It is relevant to notice that the ﬁrst copy of the loop body doesnot need to be predicated, because the header condition veriﬁca-tion ensures that at least one iteration (in relation to the rolledloop) must be executed, otherwise the loop must be already termi-nated. In this way, the ﬁrst copy of the body represents exactly theoriginal basic block of the loop.4.1. ExampleAs an example, the algorithm is applied to the Listing 1. The assembly code dialect used is referent to the ST231 ISA, which isentry
header
body 1 if 1exit
jumpbody 2
if 2
body 3
Fig. 3.Control ﬂow graph ofTable 3.
entry
header
body 1 (p)body 2(p)body 3
exit
Fig. 4.Control ﬂow graph representing an If-Conversionof the code from Listing3.A. Carminati et al. / Applied Computing and Informatics 13 (2017) 184–193 187also used in our testbed. We omit bundles delimitation in code list-ings for simplicity. Before the unroll, the sequence of instructionsgenerated is shown in Listing4.After the application of the algorithm and using an unrollingfactor of 2, we obtain the code as shown in Listing 5. The sequence (p) means that the operation execution is conditioned to the con-tent of the ﬂag registerp, which is a common notation of predi-cated code. For comparison purposes, the same code is unrolledin the standard way as shown in code listing of Listing 6. Compar- ing the two approaches, we can see that the predicated versionpresented fewer instructions than the standard counterpart (withbranches).4.2. Combining loop unrolling techniquesAs each loop unrolling technique can be applied to a set of loopsthat share a certain characteristic, makes more sense to combinethe techniques to get a more aggressive WCET reduction, insteadof comparing them. In this way, we decide in a per loop level whichapproach should be applied.Depending on loop attributes, we consider three unrollingalternatives: Standard without branchesFor loops that are not data-dependent (ﬁxed execution counts), wecan use the simplest loop unrolling approach. This approach repli-cates the loop body using an unrolling factor that divides the exe-cution count of the loop. As this approach is a common strategyconsidering compiler optimization, we will omit its representationin pseudo-code. If we use this approach, we will refer tosimpleLoopUnrollingðloop;unrollingFacÞas the algorithm represen- tation and its parameters.Standard with branchesFor data-dependent loops with some kind of control ﬂow changeinside of the loop body, we can use loop unrolling with compareand branch instructions to exit the loop when the condition isreached. For simplicity, we apply this unrolling alternative to loopswith call instructions in the body. This approach is also a commonstrategy considering compiler optimization, and we will omit itsrepresentation in pseudo-code. If we must use this approach, wewill refer tobranchedLoopUnrollingðloop;unrollingFacÞas the algo- rithm representation and its parameters. This approach cannotbe used with function inlining, although this is not a problembecause we do not use this type of optimization for two reasons:(1) we do not apply any optimization when we cannot quantifyWCET effects. (2) with inlining, we lose the one-to-one mappingbetween the object code and source code, which is necessary toperform WCET calculation.PredicatedFor data-dependent loops with simple loop bodies, we can use thepredicated version. We cannot use this type of unrolling in loopswith call instructions because condition or ﬂag registers are notcommonly exposed to the calling conventions used in processors.If we had to save the ﬂag registers, it would be better to use theprevious approach. We will call this approach as predi- catedLoopUnrolling, as presented byAlgorithm 1.Algorithm 2chooses the adequate unrolling technique throughinspection of the loop characteristics. The ﬁeld loop:ufrepresents the unrolling factor that must be used for a speciﬁed loop. We can-not choose unrolling factors arbitrarily if our objective is WCETreduction. In the next section, we will show how to use WCETinformation to choose adequate unrolling factors.
Listing 4.Example of loop in assembly code.
Listing 5.Example of unrolled loop using code predication.Listing 6.Example of unrolled loop using the standard approach.188 A. Carminati et al. / Applied Computing and Informatics 13 (2017) 184–193Algorithm 2.Optimization algorithm that is executed by thecompiler.1:procedureO
PTIMIZELOOPS (Program) 2:LoopList getLoopsðProgramÞ 3:for eachloop2LoopListdo4:ifnotloop:isDataDepthen5:simpleLoopUnrollingðloop;loop:ufÞ 6:else ifloop:hasCallthen7:branchedLoopUnrollingðloop;loop:ufÞ 8:else9:predicatedLoopUnrollingðloop;loop:uf;PÞ 10:end if11:end foreach12:end procedureIn relation to the predication ﬂag that must be given as param-eter ofAlgorithm 1in Line 9, the same register can be used to holdall conditions for all loops, because each copy of the loop bodymust be guarded by only one condition, i.e., that related to the exitcondition of the loop, which is updated before the execution of thisbody copy. In this way, we can pass any register or ﬂag that can beused to predicate instructions. In this algorithm, we consider can-didates for loop unrolling: (1) innermost loops and (2) loops com-posed by two basic blocks header and body, as the example ofFig. 1. We use these restrictions to process only small loops, wherewe can easily achieve gains using loop unrolling.4.3. Ensuring WCET reduction by unrolling factor selectionThe previous algorithm is responsible for unrolling the loops ofa program using a set of unrolling factors. It is also necessary tochoose a unrolling factor for each loop that minimizes the WCET.As we are interested only in verifying the effectiveness of our tech-nique, we are not concerned in choosing an optimal unrolling fac-tor considering code increase and WCET reduction.We adopted a scheme that tries to iteratively choose an unrol-ling factor for each loop in the program. If the loop has no impacton the worst-case execution time, i.e. resides outside the WCEP(worst-case execution path), it will be kept rolled, otherwise it willbe unrolled. The set of unrolling factors will vary according to char-acteristics of the loop, such as data dependency and parity of exe-cution counts.If the unrolled loop increases the WCET, then it will be also keptrolled. Otherwise it will be maintained unrolled using the factorthat best minimizes the WCET considering the previously consid-ered ones from the set. Each loop is processed exactly once, andafter each loop handling the WCET (and WCEP) information must
be updated to guide the treatment of the next loops. To verify ifa WCET increase occurs, it is necessary to perform a programrecompilation and an invocation to the WCET analyzer. We donot reconsider loops in case of path changes, since typically allloops in a program are on the WCEP, as stated by [6]. We only check if the current loop is on the WCEP.Algorithm 3presents our approach for selection of unrollingfactors. This algorithm is designed to be executed as a complemen-tary part of the compilation process, and can be implemented as aseparated tool. Regarding the ﬂow of information point of view, itis necessary the following interactions between the compiler andthe algorithm:/C15Compiler!Algorithm: the compiler must export all informa-tion related to all loops that can be unrolled. The informationmust allow the correlation between the loops and the worst-case execution time related data. Execution counts must beexported as well. In case of data-dependent loops, executioncounts can be provided as annotations in the source code, forexample. These execution counts are also necessary for the cal-culation of the worst-case execution time./C15Algorithm!Compiler: The algorithm can provide unrollingfactors for all loops that were exported for a determined pro-gram. If such unrolling factors are not provided, the compilerkeeps the loops rolled. To decide which unrolling factor touse, the algorithm uses WCET analysis and loop information.As we can see, the previous relation between compiler and algo-rithm forms a cyclic and incremental approach to optimize loops.The parameter ofAlgorithm 3is the representation of a compiledprogram. The ﬁrst step of the algorithm is to retrieve a list of(exported) loops of the program representation (Line 2) followedby a WCET analysis (Line 3). The main loop of the algorithm iter-ates over the loop list (Line 4), considering only loops that are inthe WCEP (Line 5). Then, we assume that it will be kept rolled (Line6) if its is not possible to choose an unrolling factor. The next stepconsists into test different unrolling factors in the interval½2;17/C138.I f a loop can be unrolled, we have basically two alternatives to con-sider an unrolling factor as valid:Data independent loopsfor data-independent loops (Line 8), theunrolling factor must exactly divide theexecution count of the loop (Line 9),because we do not want to generateinstructions to control the reaching ofthe exit condition inside the replicatedcopies of the body.Data dependent loopsfor data-dependent loops (sentence ofLine 8 is evaluated to false) we do nottest if the unrolling factor divides theexecution count, because leftover itera-tions are treated explicitly by compareand branch or compare and predicateinstruction, depending on theapproach. However, we use a heuristicapproach that considers factors whoseparity is equal to the loop bounds’ par-ity (Lines 13).Note that a loop can have more than one possible unrolling fac-tor from the interval½2;17/C138. In this case, we will use the one thatmost reduces the WCET. Experience says that even small unrollingfactors can produce instruction cache degradation, so, the interval½2;17/C138is able to cover a useful range of unrolling factors for realprograms. Although, depending on the compiler used and proces-sor characteristics, these values can be tuned experimentally. Ifsuch unrolling factor exists, we recompile the program and testfor WCET changes. In case of WCET increase (Line 21), we usethe last chosen unrolling factor (Line 22) and skip to the next loop.Otherwise we use the actual factor updating the WCET (Line 24and 25).The algorithm only cares about data dependency and parity ofexecution counts to choose unrolling factors. The ﬁnal decisionabout which unrolling approach must be applied to data-dependent loops is left to the compiler that implements Algorithm
2.A. Carminati et al. / Applied Computing and Informatics 13 (2017) 184–193 189Algorithm 3.Algorithm that deﬁnes unrolling factors for alloptimizable loops inProgram.1:procedure
CALCULATE UNROLLING FACTORS (Program). Algorithm executed by the optimization planning tool2:LoopList getLoopsðProgramÞ 3:wcetData calculateWCETðProgramÞ 4:for eachloop2LoopListdo5:ifisInWCEPðloop;wcetDataÞthen 6:lastUF 07:fori 2t o1 7do8:if notloop:isDataDepthen 9:if notdi
videsðloop:bound;iÞthen 10:continue11:end if12:end if13:ifparityðloop:boundÞ¼parityðiÞthen 14:loop:uf i 15:recompileðProgramÞ 16:newWcet calculateWCETðProgramÞ 17:ifnewWcetData:
value>¼wcetData:
valuethen18:loop:uf lastUF 19:else20:wcetData newWcetData 21:lastUF i 22:end if23:end if24:end for25:end if26:end for each27:end procedureThe time complexity ofAlgorithm 3isOðn
2Þ, wherenis the number of loops. In fact, there will be, for any program, one initialinvocation to the analyzer to estimate the WCET and other invoca-tions for each loop to test the considered unrolling factors, giving atotal of 1þ16/C2ninvocations to the analyzer. The worst caseoccurs when all loops are data independent and can be dividedby factors in the interval½2;17/C138. In practice, this situation onlyoccurs when the loop count represents a common multiple of allconsidered unrolling factors. For each loop considered in this algo-rithm, an invocation torecompile(Program)must be performed (Line 15). In this invocation, all loops will be unrolled ( Algorithm 2is invoked inside the compiler), justifying the quadratic complex-ity. Although our approach is simple, complex heuristics that try tobalance code expansion and WCET as proposed by [6]can be applied as well. Our combination of loop unrolling strategies canincrease the compilation time due to the fact that we need to pro-cess more code that in the original program. Choosing adequateunrolling factors can also increase considerably the compilationtime due to the necessity of WCET analyses. As pointed by [6], per- formance improvements are a primary focus of embedded systems,being longer compilation times of less importance.5. EvaluationTo evaluate the technique proposed in this paper we conductedexperiments using an architecture with a simpliﬁed completepredication support. In the next subsections, we will give a shortdescription of the target architecture, compiler support and WCETanalyzer. The concluding part of this section presents numericalresults obtained from the use of the proposed technique appliedto a set of benchmarks commonly used in the literature.5.1. Target architectureThe architecture used to evaluate the proposed technique wasan experimental deterministic 32-bit microprocessor [15,16]with RISC instructions that follows a subset of the HP VLIW ST231 ISA[17]. The processor has a VHDL model, which can be both simu-lated and synthesized to a FPGA. This processor has a VLIW ( very long instruction word) design. VLIW is a design philosophy wherethe hardware is not only exposed by instructions but the instruc-tion level parallelism (ILP) is exposed as well. Since the processoris intended for real-time applications, n-associative or sharedcaches and out-of-order execution are not utilized. The processorhas an instruction cache memory comprising 32 lines with 256 bitsper line forming a 1024 kb direct-mapped cache memory. The pro-cessor does not have a data cache, but has a scratchpad memory.The processor has a four issue ﬁve stage static scheduled pipe-line. Each instruction (or bundle) encodes up to four operationsthat will be dispatched in parallel. The used processor has an ISAextension that enables code predication in a simpliﬁed waythrough the thirtieth bit, which is otherwise unused. If an opera-tion has its 30th bit enabled, then the result of the instruction willonly be committed if the predication ﬂag is conﬁgured to true. Ifthe predication ﬂag has false as value, then the operation will pro-duce no effect (or nop). The predication ﬂag is a 1-bit register thatcan be accessed through comparison instructions. This ﬂag is con-nected to the branch register number 4 that is already deﬁned bythe ISA. In this way, the branch register number 4 controls the exe-cution of predicated instructions.5.2. Compiler and WCET analysisWe used a custom compiler back-end developed for the targetarchitecture using the LLVM[18]infrastructure. The compiler alsoproduces all necessary information for WCET calculation, as anannotated CFG containing information like loop bounds and map-pings between CFG nodes (basic blocks) and a target program code.For data-dependent loops, worst-case execution counts (orbounds) must be provided through source code annotations.We also used a custom WCET analyzer implemented in C++,that produces cycle-accurate estimates of the worst-case executiontime for the target architecture considering the program binaryand the data produced by the compiler. This WCET analyzer pro-duces an annotated CFG that includes worst-case counts for eachbasic block and a single numerical value that represents the calcu-lated WCET.The unrolling technique was implemented in our back-end atthe end of machine code generation. It is difﬁcult to perform
WCET-oriented optimization using LLVM due to its highly opti-mized pass-manager that isolates the treatment of each functionof a compilation unit. Due to this fact, we cannot optimize the pro-gram as a whole aiming at WCET reduction using the standardLLVM pass-manager because the generated code is only fully mate-rialized at the end of the complete process. Moreover, the pass-manager deallocates any machine related code representationstructures of a function after writing its generated object code toﬁle at the end of the pass-manager execution. So, when we canﬁnally calculate the WCET of a program, we cannot use this datato change the code (optimization application), because the neededintermediate structures no longer exist. Due to this fact, strategieslike that proposed by[5], where the analyzer is invoked directly bythe compiler to take optimization decisions cannot be used.To overcome this limitation, we adopted an approach similar to[19]. In this approach, a tool in a higher or planning level is190 A. Carminati et al. / Applied Computing and Informatics 13 (2017) 184–193responsible to select the parts of the program that must be opti-mized, using WCET information as guidance. This tool shares adatabase with the compiler that is used as communication chan-nel. This database stores facts about the structure of the programand values that specify if such structure must be touched by aspeciﬁc optimization. The tool invokes the compiler to generatethe object code and data used as input for the WCET analyzer. Afterthat, WCET information is obtained through the WCET analyzer.Using this information, the planning tool updates the databaseusing heuristics like the one proposed in Section 4.3, which chooses the loops and unrolling factors and invokes the compileragain. This task repeats until WCET stabilization or when the entirecode is already analyzed by the planning tool.Using this strategy, we can perform any WCET-oriented opti-mization in an iterative way. Optimizations must keep consistencybetween the transformed code and the annotations provided in thesource. In this way, if a data-dependent loop is unrolled, the execu-tion bound provided as an annotation must be updated before theWCET calculation. A simpliﬁed diagram of our tools and their con-nection can be seen in a ﬁgure on the Supplementary material.A s we can see, both LLVM infrastructure and planning tool share adata-base containing information about loops, which is empty onthe ﬁrst program compilation. From the ﬁrst compilation, the plan-ning tool can invoke the WCET analyzer tool and execute Algo- rithm 3to choose an unrolling factor for each loop.6. ResultsWe used the Mälardalen WCET benchmarks [20]to evaluate the effectiveness of the proposed technique. These benchmarks arewidely used to evaluate and compare methods and techniquesrelated to WCET analysis. We excluded benchmarks with indirectrecursion. We considered a constant time for complex library func-tion calls, as those that are used to handle ﬂoating point numbers.The description of each benchmark can be seen in a table on theSupplementary material.The results of the experiments are shown in Table 1. The col- umnInitial WCETshows the WCET of the benchmark without theapplication of the loop unrolling.Initial code sizepresents the size of the code (in bytes) in this initial scenario. Optimized WCETpre- sents the WCET of the optimized version with its respective codesize (Optimized code size). The columnsWCET reductionandCode increasepresent the percentage of WCET reduction and its relativecode augmentation, respectively.WCET reductionis calculated as
Initial WCET/C0 Optimized WCETInitial WCET/C2100 andCode increaseas
Optimized code size/C0Initial code sizeInitial code size /C2100. We omitted in this table bench-marks where no gain was obtained. In this way, a total of 18 from33 benchmarks are shown.Table 2shows how many loops of each type were unrolled andthe maximum unrolling factor (Max. uf) in each benchmark. Analyzing the obtained results, we can see that the combinationof techniques was able to reduce the WCET of half of the bench-marks. For example, considering the adpcm.cbenchmark, we achieved a small WCET reduction (1.19%) in contrast with a highercode increase (31.10%). If we look at Table 2we can see that two loops ofadpcm.cwere unrolled (one with ﬁxed execution countand another with a call instruction), and the maximum unrollingfactor used was 2. On the other hand, we can see a high WCETreduction for theexptint.cbenchmark, with less code increase thenin theadpcm.c. In this benchmark, only one loop was unrolled, withan unrolling factor of 7. The average WCET reduction consideringall benchmarks was 6.72%, while the average code increase was15.56%. As maximum values, we got 32.44% and 80.19%, for WCETreduction and code increase, respectively.
Table 1Obtained results
Benchmark Initial WCET Initial code size Optimized WCET Optimized code size WCET reduction (%) Code increase (%)adpcm.c 19,607 10,208 19,373 14,816 1.19 31.10bsort100.c 272,623 432 271,985 560 0.23 22.86cnt.c 9046 752 8566 864 5.31 12.96compress.c 140,139 4912 137,162 5488 2.12 10.50crc.c 113,846 2048 112,671 2624 1.03 21.95duff.c 1859 592 1397 816 24.85 27.45edn.c 96,871 2336 73,042 3296 24.60 29.13expint.c 113,473 1540 76,661 1812 32.44 15.01fft1.c 1,034,634 19,984 727,844 44,272 29.65 54.86ﬁr.c 509,930,221 976 444,387,758 1616 12.85 39.60insertsort.c 2720 304 2111 432 22.39 29.63jfdctint.c 3947 1264 3568 1536 9.60 17.71lms.c 352,360,015 14,016 303,674,957 70,768 13.82 80.19ludcmp.c 43,902 3296 43,622 4320 0.64 23.70matmult.c 268,362 1008 225,657 1968 15.91 48.78ndes.c 146,612 5376 144,282 7248 1.59 25.83qsort-exam.c 503,582 2528 480,816 2784 4.52 9.20st.c 1,480,353 5088 1,198,582 5856 19.03 13.11 Average 6.72 15.56Maximum 32.44 80.19Table 2Obtained results
Benchmark Simple With pred. With branch Max. ufadpcm.c 2 0 2 2bsort100.c 1 0 0 5cnt.c 0 0 1 2compress.c 1 1 0 2crc.c 0 0 1 2duff.c 0 1 0 10edn.c 4 1 0 9expint.c 0 1 0 7fft1.c 0 1 2 13ﬁr.c 0 1 0 6insertsort.c 0 1 0 3jfdctint.c 1 0 0 4lms.c 0 1 3 15ludcmp.c 0 0 1 5matmult.c 1 0 1 4ndes.c 2 0 1 2qsort-exam.c 0 0 1 2st.c 0 0 1 4A. Carminati et al. / Applied Computing and Informatics 13 (2017) 184–193 191Our approach could be applied to 7 benchmarks, which are com- press.c,duff.c,edn.c,fft1.c,ﬁr.c,insertsort.candlms.c. To understand how much WCET reduction we can achieve with the predicatedloop unrolling, we unrolled those three benchmarks with the bran- chedLoopUnrollinginstead ofpredicatedLoopUnrollingalgorithm, because every loop that can be unrolled with the last methodcan be unrolled with the ﬁrst as well. The results are shown inTable 3. We can observe that the predicated loop unrolling hasnoticeable effects considering theduff.c,ﬁr.candinsertsort.cbench- marks. Forinsertsort.candﬁr.cbenchmarks, using the branchedapproach, we simply do not achieve WCET reduction, so the loopis kept rolled, which also explains the difference in code sizes. Aswe can see, the predicated approach, even with its limited applica-bility, can exploit cases where the standard approach fails to getWCET reduction. In theedn.ccase, we achieved WCET reductionwith negative code decrease because the algorithm could use ahigher unrolling factor with the predicated version (9 instead 5for a branch).It is important to say that these results can be enhanced usingheuristics to ﬁnd better unrolling factors to control code expansion[6], which is out of the scope of this paper.7. ConclusionThe correct scheduling of tasks in a real-time system demandsthe knowing of the worst-case execution time of each of thesetasks. The higher the worst-case execution times, the higher willbe the resource demand for the associated system. To reduce theWCET of tasks, one approach that was proposed in the literatureconsists in applying compiler optimizations on the software thatimplements the task’s behavior in a feedback oriented way. Sinceworst-case reduction is the objective, WCET timing analyzers pro-vide this feedback, instead of execution proﬁles commonly used inaverage-case optimization. Loop unrolling for WCET reduction isconsidered by[4,6]. Though, in both works only loops with ﬁxediteration counts are unrolled.We proposed in this paper an alternative way to perform loopunrolling with arbitrary iteration counts. Traditionally, this typeof loop is unrolled using compare and branch operations to controldifferent exit conditions or contexts. What we propose is the use ofcode predication to control the loop execution under different exitconditions, since worst-case analyzers tend to consider that eachloop, even unrolled, is always fully executed up to its executionbound. The approach can be used in architectures with full predi-cation support and is better applicable when branch operationsare segmented in more than one step.We introduced an algorithm that performs this code transfor-mation directly at the machine code level (or assembly). In ourframework, each data dependent loop of each benchmark is anno-tated with a safe loop bound that represents an upper bound onthe execution count. After loop unrolling application, the annota-tion is transformed to reﬂect the new loop bound of the unrolledloop. Since our technique does not depend on branches, the num-ber of instructions is reduced and the instruction scheduling scopeis enhanced, as the whole body of the unrolled ﬁts in a single basicblock. This scope enhancement can enable more optimizations tobe applied to the code.We also proposed a strategy that selects which unrolling tech-nique to apply in a per loop basis. For loops with ﬁxed executioncounts, we applied the standard technique that unrolls loops usingunrolling factors that perfectly divide execution counts to avoidcompare and branch instructions. For data dependent loops, weused our predicated or the branch-based approach, depending onthe case.We observed in the experiments that the combination of unrol-ling techniques was able to reduce the WCET of 18 from 33 bench-marks. For six benchmarks we obtained gains above 20%. In theexperiments, we also showed that the predicated approach, evenwith its limited applicability, can exploit cases where the standardapproach fails to get WCET reduction.As we are not interested in code increase limitation, higher code
expansion was observed as well. To work around this situation,techniques like[6]can be applied to our heuristic of unrolling fac-tor selection.AcknowledgmentsThe authors would like to thank CAPES and CNPq for the partialfunding of this research.Appendix A. Supplementary materialSupplementary data associated with this article can be found, inthe online version, athttp://dx.doi.org/10.1016/j.aci.2017.03.002 .References
[1] L. Sha, T. Abdelzaher, K.-E. Årzén, A. Cervin, T. Baker, A. Burns, G. Buttazzo, M.Caccamo, J. Lehoczky, A.K. Mok, Real time scheduling theory: a historicalperspective, Real-Time Syst. 28 (2/3) (2004) 101–155, http://dx.doi.org/ 10.1023/B:TIME.0000045315.61234.1e . [2] H. Back, H.S. Chwa, I. Shin, Schedulability analysis and priority assignment forglobal job-level ﬁxed-priority multiprocessor scheduling, in: Proceedings ofthe Real-Time Technology and Application, 2012, pp. 297–306, http://dx.doi. org/10.1109/RTAS.2012.33. [3] M. Short, Timing analysis for embedded systems using non-preemptive EDFscheduling under bounded error arrivals, Appl. Comput. Infor. 13 (2) (2017)130–139.http://dx.doi.org/10.1016/j.aci.2016.07.001 . [4] W. Zhao, W. Kreahling, D. Whalley, C. Healy, F. Mueller, Improving WCET byapplying worst-case path optimizations, Real-Time Syst. 34 (2) (2006) 129–152,http://dx.doi.org/10.1007/s11241-006-8643-4 . [5] H. Falk, P. Lokuciejewski, A compiler framework for the reduction of worst-case execution times, Real-Time Syst. 46 (2) (2010) 251–300, http://dx.doi.org/ 10.1007/s11241-010-9101-x. [6]
P. Lokuciejewski, Peter Marwedel, Worst-case Execution Time AwareCompilation Techniques for Real-time Systems, Springer Science & BusinessMedia, 2010
.[7] J.R. Allen, K. Kennedy, C. Porterﬁeld, J. Warren, Conversion of controldependence to data dependence, in: Proceedings of the 10th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages – POPL ’83,ACM Press, New York, New York, USA, 1983, pp. 177–189, http://dx.doi.org/ 10.1145/567067.567085.[8] A. Jordan, N. Kim, A. Krall, IR-level versus machine-level if-conversion forpredicated architectures, in: Proceedings of the 10th Workshop onTable 3ComparingpredicatedLoopUnrollingwithbranchedLoopUnrolling
Benchmark Branched unroll. WCET Branched code size Predicated unroll. WCET Predicated code size WCET reduction (%) Code size reduction (%)compress.c 138,875 5968 137,162 5488 1.23 8.04duff.c 1515 912 1397 816 7.79 10.53edn.c 73,181 3072 73,042 3296 0.19 /C07.29 fft1.c 727,868 44,272 727,844 44,272 0.00 0.00ﬁr.c 509,930,221 976 444,387,758 1616 12.85 /C065.57 insertsort.c 2720 304 2111 432 22.39 /C042.11 lms.c 305,531,002 83,248 303,674,957 70,768 0.61 14.99192 A. Carminati et al. / Applied Computing and Informatics 13 (2017) 184–193Optimizations for DSP and Embedded Systems – ODES ’13, ACM Press, NewYork, New York, USA, p. 3,http://dx.doi.org/10.1145/2443608.2443611 . [9]A.E. Charlesworth, An approach to scientiﬁc array processing: the architecturaldesign of the AP-12OB/FPS-164 family, IEEE Comput. (1981) 18–27
. [10] J.C. Dehnert, P.Y.-T. Hsu, J.P. Bratt, Overlapped loop support in the Cydra 5, in:ACM SIGARCH Computer Architecture News, vol. 17 (2), 1989, pp. 26–38.http://dx.doi.org/10.1145/68182.68185 . [11] R.V. Hanxleden, K. Kennedy, Relaxing SIMD control ﬂow constraints using looptransformations, ACM SIGPLAN Not. 27 (7) (1992) 188–199, http://dx.doi.org/ 10.1145/143103.143133. [12] Q. Pop, S. Yazdani, R. Neill, Improving GCC’s auto-vectorization with if-conversion and loop ﬂattening for AMD’s Bulldozer processors, in: Proceedingsof the GCC Developers’ Summit 2010, 2010.[13] R. Geva, D. Morris, IA-64 Architecture Disclosures White Paper, Tech. Rep., HP/Intel, 1999.[14]
S.B. Furber, ARM System Architecture, Addison-Wesley Longman Publishing,1996
.[15] R.A. Starke, A. Carminati, R.S. de Oliveira, Investigating a four-issuedeterministic VLIW architecture for real-time systems, in: 2015 IEEE 13thInternational Conference on Industrial Informatics (INDIN), 2015, pp. 215–220.http://dx.doi.org/10.1109/INDIN.2015.7281737 .[16] R.A. Starke, A. Carminati, R.S.D. Oliveira, Evaluating the design of a VLIWprocessor for real-time systems, ACM Trans. Embed. Comput. Syst. 15 (3)(2016) 1–26,http://dx.doi.org/10.1145/2889490 . [17]J.A. Fisher, P. Faraboschi, C. Young, Embedded Computing: A VLIW Approach toArchitecture, Compilers and Tools, Elsevier, 2005
. [18] C. Lattner, V. Adve, LLVM: a compilation framework for lifelong programanalysis & transformation, in: Proceedings of the International Symposium onCode Generation and Optimization (CGO’04), IEEE Computer Society, 2004, pp.75–86,http://dx.doi.org/10.1109/CGO.2004.1281665 . [19] P. Puschner, D. Prokesch, B. Huber, J. Knoop, S. Hepp, G. Gebhard, The T-CRESTapproach of compiler and WCET-analysis integration, in: Proceedings of the16th IEEE International Symposium on Object/Component/Service-orientedReal-time Distributed Computing (ISORC 2013), 2013, pp. 1–8. http://dx.doi. org/10.1109/ISORC.2013.6913220 . [20] J. Gustafsson, A. Betts, The Mälardalen WCET benchmarks: past, present andfuture, in: Proceedings of the 10th International Workshop on Worst-CaseExecution Time Analysis (WCET’10), Schloss Dagstuhl–Leibniz-Zentrum fuerInformatik, 2010, pp. 136–146. http://dx.doi.org/10.4230/OASIcs.WCET.2010. 136.A. Carminati et al. / Applied Computing and Informatics 13 (2017) 184–193 193