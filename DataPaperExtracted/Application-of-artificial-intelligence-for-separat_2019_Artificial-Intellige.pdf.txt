Application of artiﬁcial intelligence for separation of live and deadrainbow troutﬁsh eggs
Abbas Rohania,⁎, Morteza Takib, Ghasem Bahramia
aDepartment of Biosystems Engineering, Faculty of Agriculture, Ferdowsi University of Mashhad, Mashhad, Iran
bDepartment of Agricultural Machinery and Mechanization, Agricultural Sciences and Natural Resources University of Khuzestan, Mollasani, Iran
abstract article info
Article history:Received 23 January 2019Received in revised form 20 March 2019Accepted 21 March 2019Available online 25 March 2019In this study a visual machine technology-based intelligent system was developed and evaluated for separationand recognizing the alive and dead eggs of rainbow trout ﬁsh. The features derived from imagery processing of alive and dead eggs were used as the decision-making variables in the classi ﬁer. Multi-layer Perceptron neural network (MLP) and Support Vector Machine (SVM) models were used as the classi ﬁers. With pairedt-test, 10 effective features were selected from 15 features for classi ﬁcation. Thek-fold cross validation method was used for better evaluation the classiﬁers. By changing the size of the training data set from 80% to 20%, the clas- siﬁer ability and stability were evaluated. The results showed that in the training phase, all the mean values of thestatistical indices for MLP and SVM classi ﬁcations were complete for all categories (100% of the classi ﬁcation was predicted correctly). Also, in the test phase, the performance indicators of both classi ﬁers were very satisfactory (the average accuracy was 99.45%). Therefore, it is possible to use both classi ﬁers with certainty for separation the rainbow troutﬁsh eggs.© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Rainbow troutFish eggK-fold cross validationMachine vision system
1. IntroductionIn Iran and some of other countries, healthy ﬁsh eggs are separated from the unhealthy ones traditionally and manually. Now, this methodis used in manyﬁsh farms. But in someﬁsh egg production centers, the eggs were separated by semi-automatically methods. This method isconstrained by low speed, low accuracy and high cost. These big disad-vantages have increased the efforts to build a more accurate device byimage processing method to solve the problems and improve the ef ﬁ- ciency. Machine vision system includes a camera for taking a pictureand also a computer with efﬁcient software and hardware and lightingsystem. The quality of the images depends on the light conditions at thetime of shooting. So if this factor is better, more accurate processing re-sults will be achieved (Du and Sun, 2004). In this method, images pro- cessing needs the new tools for smart grids to process the images inshorter time with the high level of conﬁdence. The network is based on the general trainings to acquire data and it can be implemented forother data (Mitchell et al., 1996). Color and texture are useful featuresthat can be extracted from the images. Color is regarded as a low-levelfeature. This feature can be extracted from the homogeneous imagesand parts of objects in the image (Kim and Hong, 2009). The histological features play a very important role in the classi ﬁcation of pattern. The best algorithms for texture feature are GLCM (Gray-Level Co-Occurrence Matrix) (Sengur, 2008). Since counting the number ofﬁsh by hand is difﬁcult and also the possibility of error is high, a systembased on the image processing in different places and conditions wasdesigned (Zion et al., 2006). The system can count the number ofﬁshes. The algorithm can work with 98% accuracy. In another study, a commer-cial software was designed to count theﬁsh eggs (Friedland et al., 2005). The images were taken fromﬁsh eggs. By algorithm dilation erosion,seven geometric and dimensional features were extracted and ﬁnally theﬁsh eggs were counted properly.Kunrui et al. (2015), built an egg grading machine (Kunrui et al., 2015). In this system, images were taken when the eggs moved by a typical rails. Then, the images wereprocessed to drive their features such as morphological and color char-acteristics. Six features were extracted from color space. The procedurespeed was 5400 eggs per hour. Experimental results showed that preci-sion of this system was approximately 90%. In another research, imageprocessing techniques was applied for analysis the silkworm eggs(Kiratiratanapruk et al., 2014). This technique could detect objects andtypes of eggs. The experiment was conducted in Thailand SericultureCenter. The authors extracted 60 samples from seven kinds of silkwormeggs. Color properties in RGB, HSV, LAB and YUV domains were ex-tracted. Silkworm eggs processing speed was up to 140 eggs per second.Precision of this system was approximately 90%. Omid et al. (2013),d e - signed a technique based on machine vision and neural network tograde the eggs (Omid et al., 2013). This system could detect some fea-tures such as blood clots and egg shell cracking. Color characteristicswere extracted from HSV space. Fuzzy inference system was used forArtiﬁcial Intelligence in Agriculture 1 (2019) 27 –34
⁎Corresponding author.E-mail address:arohani@um.ac.ir(A. Rohani).
https://doi.org/10.1016/j.aiia.2019.03.0022589-7217/© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the C C BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/griding. Precision of this system was 95%, 94.5% and 98% for the size,crack and fracture, respectively. In another study, Soltani and Omid (2015), designed a system based on electrochemical impedance spec-troscopy technique and machine vision ( Soltani and Omid, 2015). This method was based on the variations of dielectric properties. In this sys-tem, when the eggs were put into the sensor, dielectric properties werechanged. The eggs were graded on the basis of some characteristics suchas mass, thickness and length. The separation technique involves the Ar-tiﬁcial Neural Network (ANN), Bayesian Network (BN), Decision Trees(DT) and Support Vector Machine (SVM). All these methods had agood precision. In a research, applied machine vision systems were pro-posed to detect and identify the sardine eggs ( Powell et al., 2003). On- line imaging system was used for detecting and counting the ﬁsh eggs included lamps,ﬂow cells, pumps and computer with suitable hardwareand software for image processing. Some features such as size, shapeand shadow were extracted. These characteristics were used as the in-puts in the regression tree algorithms. With this system, 9987 sardineeggs were counted. Results showed that SVM is a very useful techniquefor pattern recognition and distinguishing the two groups. Today, appli-cation of SVM and ANN as powerful algorithms for distinguish betweenthe two groups is quite common (Robotham et al., 2010;Cortes and Vapnik, 1995). In theﬁelds of ecological and biological applications,SVM is better than ANN (Morris et al., 2001). Some of researchers used these methods for the ecological and biological subject. Hu et al. (2012), used SVM and ANN technique for the separation of commonsardineﬁsh and jack mackerel in south-central Chile ( Hu et al., 2012). The extracted features such as morphological, bathymetric, energeticaand positional were used for classiﬁcation the two species. The resultsshowed that this method had 89.5% conﬁdence for theﬁsh classiﬁcation. To help Chineseﬁshermen and diagnoseﬁsh diseases, Storbeck and Dan developed a method (Storbeck and Daan, 2001). In this system, at the ﬁrst step, theﬁshes were taken on the rail. Then images capturedfromﬁshes by smartphones. Some characteristics such as width, length,textural properties and statistical properties of wavelet transform wereextracted. Multi class SVM was used for grouping the ﬁsh species. The results showed that the best method for diagnosing the diseases ofﬁsh was the extracting properties of the color in the HSV space anduse of one-against-one algorithm in SVM. In another study, twomethods including pattern recognition and near infrared was combinedfor classifying the freshness of egg (Zhao et al., 2010). For classiﬁcation, support vector machine data description (SVDD) was used. In this re-search, the range of spectra for egg was 10–4000 cm
−1. For examination of the classiﬁcation method, some methods like k-Nearest Neighbors(KNN), ANN and SVM were used. At last, SVDD had the best results. Pre-cision of this system was approximately 93.3%. The results showed thatthis method was an excellent way for solving similar problems.The above literatures showed that little research was done for sepa-ration and identiﬁcation theﬁsh eggs especially in Iran. So, the presentstudy was aimed to develop a visual machine for separation the aliveand deadﬁsh eggs. The images were categorized with two classi ﬁers: SVM and MLP. The results of this research can be useful for food engi-neers to construct an accurate device for solve this problem.2. Materials and methods2.1. Image acquisition and features extractionIn this research, images were captured with a Canon Digital Asus 500VHS. Since theﬁsh eggs were small, the size of images was selected as280 × 280 pixels. After several image capturing, the camera was ﬁxed at 40 cm above the plate containing the samples. After analysis of im-ages, the quality of theﬁsh eggs was determined. The texture andcolor features were derived from image processing. This process con-sists of two stages:1. Image processing technique including:•Capturing the images ofﬁsh eggs.•Resize the images to 280 × 280 pixels.•Convert the images from RGB to LAB (for color features).•Convert images from RGB to GRAY (for texture features).•Labeling the each object.2. Feature extraction. In this section, color and texture features were ex-tracted from each labeled. Features of the ﬁsh egg are including the contrast, correlation, energy, homogeneity, LBP (mean and standarddeviation) and LAB (mean, standard deviation and range) values.These features were used for separating the ﬁsh eggs.Fig. 1shows the original and converted image of a sample egg.2.1.1. Color featuresIn this section, atﬁrst, backgrounds of the images were omitted.After that, it was needed a color space that was not affected by imaginginstrument and condition. RGB color space dos not have this condition.So, LAB color space was used. Unlike the RGB, this system is similar tothe human eye. Also, it is not affected by the instrument ( Shaﬁee et al., 2014). In this space, L is the equivalent to brightness and A hasan unlimited amount (the positive values represent the red and the neg-ative values are green). The positive value of B is equal to yellow and thenegative is equal to blue. In the literatures, most food industry re-searchers use LAB space frequently. For each space of LAB, three statis-tical properties and nine color features were extracted.Mean is the average of statistical factor or central tendency. Standarddeviation (Std) is used to determine the amount of the data dispersionandﬁnally, range is the span between the largest and smallest value(Zion et al., 2006).2.1.2. Texture's featuresAnother aspect of analysis is the extraction of features from texture.For this stage, the images were converted from color to gray. After that,for extract the texture features, functions GLCM and LBP were applied.In this method, the images were converted into a two dimensional ma-trix as a GLCM, where each element was the probability of getting colorintensityiandjin the neighborhood of the distance d and the angle θ (00,4 50,9 00,1 3 50). Finally, by using the function, the features were ex-tracted. Before calculating the function on the co-occurrence matrix,each element of the matrix should be normalized. Data were normal-ized by dividing each element by the total numbers of considered pixelspairs.Haralick and Shanmugam (1973)used co-occurrence matrix for theﬁrst time to extract texture features of images to troubleshootgrapefruit (Haralick and Shanmugam, 1973). However, the closer the amount of pixels to each other, the more concentrated the main diago-nal matrix and as compared to a simple histogram of pixels in the loca-tion information, location data are lost and only the frequency of pixelNomenclatureMLPMulti-layer PerceptronSVMSupport Vector MachineGLCMGray-Level Co-Occurrence MatrixMSEmean of the squared errorTrainbrBayesian regularization back-propagationTrainlmLevenberg–Marquardt back-propagationANNArtiﬁcial Neural NetworkBNBayesian NetworkDTDecision TreesKNNk-Nearest NeighborsSVDDSupport Vector Machine Data DescriptionCIconﬁdence interval28 A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27 –34gray values is calculated and locations of the pixel matrix areconsidered.In this research, energy is a measurement of image homogeneity. Be-cause the homogeneous gray level is low, the values are squared ( Gong et al., 1992). Contrast is the local variations in the pixels of an image. Dif-ference between the brightest whites and deepest blacks in an image isdeﬁned as contrast. If the difference between these two factors is high,the value of the factors become high and then the quality of the imagewill increase. Homogeneity is deﬁned as the combination of the ele-ments, parts and characters of the image. Correlation is the linear de-pendence of gray levels in neighboring pixels or certain parts of theimage. If the same gray level is high, it implies that the correlation be-tween them is high (Broomhead and Lowe, 1988). In this study, 100 im- ages were derived from both alive and dead eggs. Fifteen features wereextracted from each image as shown in Table 1.2.2. MLP classiﬁerMultilayer perception (MLP) neural network with back propagationalgorithm was used to classify theﬁsh eggs. MLP neural network is aclassiﬁer method and composed of at least three layers ( Fig. 2). The ﬁrst layer is the input layer whose size is equivalent to the number offeatures intended for the classiﬁcation. There is a weight equivalent toeach input. The hidden layer is formed by some neurons. The present re-search, evaluated 3, 5,…, 13 neurons in hidden layer. The number ofneurons in hidden layer at most cases, found out by trial and error(Abutaleb, 1991). The output layer was supposed to include two neu-rons since the objective of the present study was to classify ﬁsh eggs of alive eggs with optimum output [1 0] and dead ones with optimumoutput [0 1]. The transfer function of output layer was sigmoid type.Two functions, sigmoid and hyperbolic tangent, were evaluated astransfer function for the hidden layer as below:out¼
11þe
−∑F iwijþbð1Þout¼
21þe
−∑2F iwijþb−1 ð2Þwhere, F
i,ba n dw ijdenoteith input, bias and weight ofjth neuron, respectively.
Fig. 1.The original and converted image (A and B) of a sample egg.
Table 1Features derived from the images of ﬁsh eggs.Feature Symbol Feature Symbol Feature Symbol Feature SymbolContrast F
1 Mean local binary pattern F 5 Range (in the space L) F 9 Std (in the space B) F 13
Correlation F 2 Standard deviation of local binary pattern F 6 Mean (in the space A) F 10 Range (in the space b). F 14
Energy F 3 Mean (in the space L) F 7 Range (in the space A) F 11 Range (in the space B). F 15
Homogeneity F 4 Std (in the space L) F 8 Mean (in the space B) F 12 –
Fig. 2.MLP classiﬁer with three inputs and two outputs.29 A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27 –34The optimum weights and biases in MLP classi ﬁer were derived by training functions. In this research, two functions were used: Bayesianregularization back-propagation (Trainbr) and Levenberg –Marquardt back-propagation (Trainlm), for the training and optimization ofnetwork weights. Mean of the squared error (MSE) criterion was usedas the optimization index for MLP network performance:mse¼1nXni¼1Ti−P i ðÞ2ð3Þwhere, T
iand P irepresent target and predicted class, respectively. Aftereach training cycle, the weights of network were updated to reach min-imize MSE (Ripley, 2007).2.3. SVM classiﬁerSupport Vector Machine (SVM) is a classi ﬁer based on statistical learning. It uses two strategies of keeping empirical risk at a constantvalue and minimizing conﬁdence interval (CI) (Vapnik, 2013). The
Fig. 3.Linear SVM classiﬁer.
Fig. 4.Flow chart of the present research.Table 2Comparison of means for the features.Feature Mean p-Value Feature Mean p-ValueClass I Class II Class I Class IIF
1 13,344.3 13,088.0 0.00⁎F 9 18.809 13.195 0.00⁎ F
2 0.0018−0.0006 0.16nsF10 23.674 5.334 0.00⁎ F
3 0.00001 0.00001 0.35nsF11 1.4971 1.1556 0.00⁎ F
4 0.03376 0.03351 0.00⁎F 12 20.043 14.434 0.00⁎ F
5 16.2205 16.2205 0.09nsF13 51.947 36.226 0.00⁎ F
6 35.178 28.989 0.00⁎F 14 1.2642 1.0425 0.01⁎ F
7 69.622 59.303 0.00⁎F 15 18.465 16.913 0.08ns
F8 0.8563 0.7860 0.213ns
⁎Signiﬁcant at 0.01 level.
nsNot signiﬁcant.30 A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27 –34main idea of SVM is to apply a hyperplane to separate the input patternsinto two classes.Fig. 3shows the SVM classiﬁer with a linear hyper- plane. As it was mentioned, in this research, two-class classi ﬁcation problem were examined.The patterns derived from the processing of ﬁsh egg images have an N-dimensional feature vector. The value y∈{−1,+1} is deﬁned for each input vectorfas:f¼f
1;f2;f3;…;f m fg∈RNð4ÞAnd for a linear SVM classiﬁer:ffðÞ ¼f:wðÞ þb ð5Þwherew∈R
Nand b∈R. The training dataset was deﬁned as:y
1;f1 ðÞ;…;yl;flðÞ;yi∈−1;1fg ð6ÞIt can be assumed that the training set is linearly separable, whereasthe following inequalities hold valid for all members of training set:w:f
iþb≥1i fyi¼1w:f
iþb≤−1i fyi¼−1/C26 ð7ÞThe optimum hyperplane is unique and is derived during trainingphase in order to obtain the highest margin. MATLAB 2016b softwarepackage was used to develop SVM and MLP models. Fig. 4shows the total procedure of the work.2.4. Performance assessment of SVM and MLP classi ﬁersTo evaluate the performance of the model, some criteria have beenused from the literature. In this research the following criteria used toevaluate the classiﬁers based on the number of patterns recognized cor-rectly (TP), rejected correctly (TN) and also the number of patterns rec-ognized incorrectly (FP) or rejected incorrectly (FN) as the followingequations:Accuracy%ðÞ ¼TPþTNTPþTNþFPþFN/C2100ð8ÞPrecision%ðÞ ¼
TPTPþFP/C2100 ð9ÞSensitivity%ðÞ ¼
TPTPþFN/C2100 ð10ÞF−score%ðÞ ¼
2/C2Sensitivity/C2PrecisionSensitivityþPrecision/C2100ð11ÞSpecificity%ðÞ ¼
TNTNþFP/C2100 ð12ÞAUC¼
12/C2 TPTPþFNþ TNTNþFP/C18/C19 ð13ÞYI¼Sensitivity−1−SpecificityðÞ ð14ÞTable 3The results of statistical indexes for MLP classi ﬁer.Nn TF Trainlm TrainbrTrain phase Test phase Train phase Test PhaseAccuracy Precision Accuracy Precision Accuracy Precision Accuracy Precision3logsig 99.99 ± 0.06 99.99 ± 0.12 99.45 ± 1.04 99.00 ± 2.01 99.99 ± 0.06 99.99 ± 0.12 99.65 ± 0.89 99.25 ± 1.79tansig 99.38 ± 0.08 99.97 ± 0.16 99.59 ± 0.93 99.19 ± 1.85 100 ± 0.00 100 ± 0.00 99.35 ± 1.10 98.87 ± 2.205logsig 99.96 ± 0.14 99.93 ± 0.29 99.56 ± 1.05 99.10 ± 1.93 99.53 ± 0.98 99.05 ± 1.97 99.53 ± 0.98 99.05 ± 1.97tansig 99.96 ± 0.32 99.98 ± 0.18 99.28 ± 1.14 98.60 ± 2.26 100 ± 0.00 100 ± 0.00 99.40 ± 1.07 98.80 ± 2.147logsig 99.98 ± 0.10 99.96 ± 0.21 99.30 ± 1.12 98.80 ± 2.14 100 ± 0.00 100 ± 0.00 99.66 ± 0.89 99.25 ± 1.79tansig 99.99 ± 0.06 99.99 ± 0.13 99.42 ± 1.05 98.85 ± 2.11 100 ± 0.00 100 ± 0.00 99.48 ± 1.02 98.95 ± 2.049logsig 99.98 ± 0.12 99.95 ± 0.25 99.38 ± 1.08 98.75 ± 2.18 100 ± 0.00 100 ± 0.00 99.40 ± 0.89 98.80 ± 2.14tansig 99.96 ± 0.15 99.93 ± 0.29 99.58 ± 0.94 99.15 ± 1.88 99.99 ± 0.06 98.75 ± 0.12 99.72 ± 0.78 99.45 ± 1.5711logsig 99.99 ± 0.06 99.99 ± 0.12 99.48 ± 1.00 99.00 ± 2.00 100 ± 0.00 100 ± 0.00 99.62 ± 0.89 99.25 ± 1.79tansig 99.99 ± 0.06 99.99 ± 0.12 99.50 ± 1.02 99.05 ± 1.97 100 ± 0.00 100 ± 0.00 99.62 ± 0.89 99.25 ± 1.7913logsig 99.98 ± 0.10 99.96 ± 0.21 99.48 ± 1.02 98.95 ± 2.05 100 ± 0.00 100 ± 0.00 99.50 ± 1.00 99.00 ± 2.01tansig 99.96 ± 0.15 99.92 ± 0.29 99.42 ± 1.05 99.15 ± 1.88 100 ± 0.00 100 ± 0.00 99.62 ± 0.89 99.25 ± 1.79
Table 4The results of sensitivity analysis for MLP classi ﬁer.Train phase Test phaseAccuracy Precision Accuracy PrecisionAll 100 ± 0.00 100 ± 0.00 99.66 ± 0.89 99.25 ± 1.79All except F
1 100 ± 0.00 100 ± 0.00 99.65 ± 0.86 99.30 ± 1.30All except F
4 99.25 ± 1.05 99.72 ± 0.79 97.00 ± 2.31 97.60 ± 3.23All except F
6 100 ± 0.00 100 ± 0.00 99.65 ± 0.87 99.30 ± 1.75All except F
7 100 ± 0.00 100 ± 0.00 99.20 ± 1.17 98.40 ± 2.35All except F
9 99.96 ± 0.15 99.92 ± 0.29 99.40 ± 1.07 99.00 ± 2.02All except F
10 99.98 ± 0.12 99.95 ± 0.25 99.65 ± 0.87 99.30 ± 1.75All except F
11 100 ± 0.00 100 ± 0.00 99.60 ± 0.92 99.20 ± 1.85Al except F
12 100 ± 0.00 100 ± 0.00 99.60 ± 0.92 99.20 ± 1.85All except F
13 100 ± 0.00 100 ± 0.00 99.35 ± 1.10 98.70 ± 2.21All except F
14 100 ± 0.00 100 ± 0.00 99.65 ± 0.87 99.30 ± 1.75F
4F9F10 100 ± 0.00 100 ± 0.00 99.45 ± 1.04 98.89 ± 2.07Table 5The performance of MLP classiﬁer at three phases (train, test and total).Accuracy Precision Sensitivity F-score Speci ﬁcity AUC Y
I
TrainMin 100 100 100 100 100 1 1Max 100 100 100 100 100 1 1Mean 100 100 100 100 100 1 1std 0 0 0 0 0 0 0TestMin 97.50 95.00 100 97.44 95.24 0.98 0.95Max 100 100 100 100 100 1 1Mean 99.45 98.90 100 99.44 98.95 0.99 0.99std 1.04 2.08 0 1.06 1.98 0.01 0.01TotalMin 99.50 99.00 100 99.49 99.00 0.99 0.99Max 100 100 100 100 100 1 1Mean 99.45 99.78 100 99.89 98.95 0.99 0.99Std 0.20 0.42 0 0.20 1.98 0.00 0.0031 A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27 –343. Results and discussion3.1. Feature selectionThe number of features can be reduced to minimize the calculationsand increase the classiﬁcation speed. In this research, paired t-test was applied for statistical comparison. In this method, the features showinginsigniﬁcant differences between alive and dead egg classes are re-moved from the set of features (Table 2). As it can show, there are no signiﬁcant differences (p-valueN0.05) inﬁve features (F
2,F3,F5,F8, and F
15) between two classes at the 5% level. The lack of signi ﬁcant dif- ferences between the features of two classes con ﬁrms that these twoclasses cannot be distinguished by these features. So other 10 featureswere selected for classiﬁcation.3.2. MLP classiﬁerMLP neural network is used as an intelligent method to separatetheﬁsh eggs. Ten selected features (Table 2) were included as the inputs of the MLP model.Table 3s h o w st h em e a n sa n ds t a n d a r dd e -viations of two performance features of the classi ﬁers (accuracy and precision) at the train and test phases. The values in Table 3were derived from 100 different datasets for train and test by 5-foldcross validation method with 20 replications. Two training algo-rithms (Trainlm and Trainbr) and two transformation functions(logsig and tansig) were used for the neurons of the hidden layer.Also, the number of neurons in the hidden layer was changed from3 to 13. The value of standard deviation was unequal to zero becausethe network performance at the train and test phases depended onthe datasets selected for the trainphase. As it can be observed, thebest result in training algorithm (Trainlm) at both training andtest phases was derived by tansig transformation function at 11neurons in the hidden layer. Theperformance comparison of twotraining algorithms revealed that the Trainbr algorithm is better
Fig. 5.Dispersion of two classes of alive and dead eggs based on the three selectedvariables.
100 10099.5799.15
9596979899100101
Accuracy Precision(a)
Train
Test99.4898.9699.5799.15
9596979899100101
Accuracy Precision(b)
Train
Test
100 10099.5799.15
9596979899100101
Accuracy Precision(c)
Train
Test100 10099.5799.15
9596979899100101
Accuracy Precision(d)
Train
Test
Fig. 6.Results of SVM based on four types of kernel function: (a: RBF), (b: linear), (c: poly2) and (d: poly3).Table 6The performance of SVM-rbf classi ﬁer at train, test and total phases.Accuracy Precision Sensitivity F-score Speci ﬁcity AUC Y
I
Train Min 100 100 100 100 100 1 1Max 100 100 100 100 100 1 1Mean 100 100 100 100 100 1 1std 0 0 0 0 0 0 0Test Min 97.5 95 100 97.47 95.23 0.98 0.95Max 100 100 100 100 100 1 1Mean 99.57 99.15 100 99.56 99.19 0.99 0.99std 0.94 1.88 0 0.96 1.79 0.00 0.00Total Min 99.5 99 100 99.49 99.49 0.99 0.99Max 100 100 100 100 100 1 1Mean 99.92 99.83 100 99.91 99.91 0.99 0.99std 0.18 0.37 0 0.18 0.37 0.00 0.0032 A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27 –34than Trainlm at train phase because its recognition error was zero inmost cases and its results were better than Trainlm at test phase.The best performance of Trainbr was observed by seven neurons(in the hidden layer) with logsig transformation function. So, theTrainbr algorithm led to a better result than Trainlm with lowernumber of neurons.3.2.1. Sensitivity analysisAt theﬁrst step, 10 features that could effectively separate alive anddeadﬁsh eggs were selected by statistical comparison. Then, the mostappropriate training algorithm and transformation function of neuronsin the hidden layer and their number was selected for MLP neural net-work. At this step, the sensitivity analysis was carried out to determinethe most sensitive features (Table 4). In this table, MLP performance isshown after the removal of the ten features (one-by-one) at the trainand test phases. If the removal of a feature had a negative impact onthe performance of the classiﬁer, it would be considered as a highly im-portant feature for the separation of the two classes (alive and deadeggs). So, three variables (F
4,F9and F 10) were selected as the most im- portant and effective features in the separation of ﬁsh eggs because their exclusion from the inputs, affected the performance of the classi ﬁer as compared to the inclusion of all ten features.Table 5shows the minimum, mean and standard deviation of theperformance parameters for MLP neural network at train, test andwhole phases for 100 various datasets of 5-fold cross validation method.In this section, MLP was trained by three inputs selected at sensitivityanalysis step. The results of training phase showed that MLP classi ﬁer could perfectly separate the alive and dead ﬁsh eggs by the three se- lected features. Also the results of test phase showed that MLP had agood performance at this phase, too. In total, mean precision of MLPneural network was found to be 99.45%.Fig. 5shows the features dispersion of alive and dead ﬁsh egg classes. Accordingly, these two classes were highly separable based on the threeselected variables.3.3. SVM classiﬁerIn the present study, SVM model was used as another classi ﬁer. Ac- cording to the results ofTable 4, three features (F
4,F9and F 10)w e r es e - lected as the inputs of SVM. One important parameter that in ﬂuences the performance of SVM is the kernel function type. Means and standarddeviations of accuracy and precision at train and test phases are shownfor different types of kernel functions including linear, second-orderpolynomial (poly2), third-order polynomial (poly3) and radial basisfunction (rbf) (Fig. 6). The results showed that rbf function type hasthe better performance than other function types. However, all thethree functions of rbf, poly2 and poly3 had similar mean results, butstandard deviation of rbf was lower than the other two types. Thus,rbf was more stable and had the better generalizability. In this analysis,linear function had the weakest performance. So, the separation of theclasses needs a non-linear function.Table 6shows some descriptive statistical features of SVM-rbf per-formance parameters at three phases of train, test, and total for 100 dif-ferent datasets of 5-fold cross validation. Similar to MLP, the results oftraining phase of SVM-rbf was derived with 100% precision for alldatasets. Furthermore, results of test phase con ﬁrmed the capability of SVM. SVM results were highly similar to MLP ( Table 5). So, both classi- ﬁers were found to be equally capable for recognition and separation ofalive and deadﬁsh eggs.3.4. Evaluation of data size on the classi ﬁer performanceTo evaluate the capability and generalizability of two classi ﬁers, i.e. MLP and SVM, different sizes of datasets were used for training.So, 80, 60, 40 and 20% of all data were randomly devoted to trainingset and the rest was proportionately used for test section. So, themodels with large (80%) to small (20%) sizes of training set wereevaluated. For the evaluation, the same 100 datasets selected by 5-fold method with 20 replications were used and the mean and stan-dard deviation of the performance parameters were estimated attrain and test phases (Table 7). Results of train phase showed thatboth classiﬁers had perfect capability because their error was zeroat train phase. The results of test phase showed that larger size oftest set will decrease the total error of prediction and no signi ﬁcant differences were observed between SVM and MLP. So, it can be con-cluding that both SVM and MLP have high capability in separatingalive and dead eggs.4. Conclusion and recommendationIn this paper, 15 features were selected out of 200 images of aliveand dead eggs of rainbow troutﬁsh by image processing technique. Be-tween them, 10 features were chosen as the effective ones by statisticalcomparison of two classes. The 5-fold cross validation technique wasused with 20 replications to evaluate the performance of MLP andSVM models. The results showed that the best choice for the classi ﬁca- tion for theﬁsh eggs was MLP with Trainbr training algorithm andseven neurons with logsig transformation function in hidden layer.The results of MLP sensitivity analysis showed that with three features(F
4,F9and F 10), almost 100% classiﬁcations could be achieved. The same features were used by SVM classiﬁcation. The rbf type was applied as a kernel function for SVM. The results of SVM classi ﬁcation showed insigniﬁcant differences between MLP and SVM classi ﬁers. Finally, the generalizability of two classiﬁers was assessed by reducing the size ofTable 7Evaluation of MLP and SVM with different sizes in training set.Classiﬁer Accuracy Precision Sensitivity F-score Speci ﬁcity AUC Y
I
Train 80 MLP 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 1 ± 0.00 1 ± 0.00SVM 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 1 ± 0.00 1 ± 0.0060 MLP 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 1 ± 0.00 1 ± 0.00SVM 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 1 ± 0.00 1 ± 0.0040 MLP 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 1 ± 0.00 1 ± 0.00SVM 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 1 ± 0.00 1 ± 0.0020 MLP 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 1 ± 0.00 1 ± 0.00SVM 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 100 ± 0.0 1 ± 0.00 1 ± 0.00Test 20 MLP 99.45 ± 1.04 98.90 ± 2.08 100 ± 0.0 99.44 ± 1.06 98.95 ± 1.98 0.99 ± 0.01 0.99 ± 0.01SVM 99.58 ± 0.94 99.15 ± 1.89 100 ± 0.0 99.56 ± 0.97 99.19 ± 1.80 0.99 ± 0.01 0.99 ± 0.0240 MLP 99.53 ± 0.61 99.05 ± 1.22 100 ± 0.0 99.52 ± 0.62 99.07 ± 1.19 0.99 ± 0.01 0.99 ± 0.01SVM 99.53 ± 0.61 99.05 ± 1.22 100 ± 0.0 99.52 ± 0.62 99.07 ± 1.19 0.99 ± 0.01 0.99 ± 0.0160 MLP 99.57 ± 0.42 99.13 ± 0.84 100 ± 0.0 99.56 ± 0.42 99.15 ± 0.82 1.00 ± 0.00 0.99 ± 0.01SVM 99.56 ± 0.42 99.13 ± 0.84 99.98 ± 0.16 99.55 ± 0.42 99.15 ± 0.82 0.99 ± 0.00 0.99 ± 0.0080 MLP 99.49 ± 0.25 98.99 ± 0.49 100 ± 0.0 99.49 ± 0.25 99.00 ± 0.49 1.00 ± 0.0 0.99 ± 0.00SVM 99.49 ± 0.26 99.00 ± 0.50 99.98 ± 0.24 99.48 ± 0.26 99.01 ± 0.50 0.99 ± 0.00 0.99 ± 0.0133 A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27 –34training set. The results showed that both classi ﬁers had the equally high capability. Finally, the proposed method can play an effective rolein separating the alive and deadﬁsh eggs. Some recommendations arebelow:1. Extracting some of the properties such as the volume and weight ofeachﬁsh egg can lead to a stronger algorithm design.2. Designing an algorithm based on a large amount of ﬁsh and not one- on-one can play a signiﬁcant role in the speed of the separating.3. The design of an algorithm that does not require the removal of eggsfrom water and can eliminate the noise of water in the photos shouldbe considered in the next researches.AcknowledgmentsFinancial supports from the Ferdowsi University of Mashhad and Ag-ricultural Sciences and Natural Resources University of Khuzestan, arehighly appreciated.References
Abutaleb, A.S., 1991.A neural network for the estimation of forces acting on radar targets.Neural Netw. 4 (5), 667–678.Broomhead, D.S., Lowe, D., 1988. Radial Basis Functions, Multi-variable Functional Inter-polation and Adaptive Networks (Retrieved from).Cortes, C., Vapnik, V., 1995.Support-vector networks. Mach. Learn. 20 (3), 273 –297. D u ,C . - J . ,S u n ,D . - W . ,2 0 0 4 .Recent developments in the applications of image processingtechniques for food quality evaluation. Trends Food Sci. Technol. 15 (5), 230 –249. Friedland, K., Ama-Abasi, D., Manning, M., Clarke, L., Kligys, G., Chambers, R., 2005. Auto- mated egg counting and sizing from scanned images: rapid sample processing andlarge data volumes for fecundity estimates. J. Sea Res. 54 (4), 307 –316. Gong, P., Marceau, D.J., Howarth, P.J., 1992. A comparison of spatial feature extraction al- gorithms for land-use classiﬁcation with SPOT HRV data. Remote Sens. Environ. 40(2), 137–151.Haralick, R.M., Shanmugam, K., 1973. Textural features for image classiﬁcation. IEEE Trans. Syst. Man Cybern. 3 (6), 610–621.Hu, J., Li, D., Duan, Q., Han, Y., Chen, G., Si, X., 2012. Fish species classiﬁcation by color, tex- ture and multi-class support vector machine using computer vision. Comput. Elec-tron. Agric. 88, 133–140.Kim, J.-S., Hong, K.-S., 2009.Color–texture segmentation using unsupervised graph cuts. Pattern Recogn. 42 (5), 735–750. Kiratiratanapruk, K., Watcharapinchai, N., Methasate, I., Sinthupinyo, W., 2014. Silkworm Eggs Detection and Classiﬁcation Using Image Analysis (Paper presented at the Com-puter Science and Engineering Conference (ICSEC), 2014 International).Kunrui, X., Xi, L., Qiaohua, W., Meihu, M., 2015. Online automatic grading of salted eggs based on machine vision. Int. J. Agric. Biol. Eng. 8 (1), 35 –41. Mitchell, R.S., Sherlock, R.A., Smith, L.A., 1996. An investigation into the use of machine learning for determining oestrus in cows. Comput. Electron. Agric. 15 (3), 195 –213. Morris, C.W., Autret, A., Boddy, L., 2001. Support vector machines for identifying organ- isms—a comparison with strongly partitioned radial basis function networks. Ecol.Model. 146 (1), 57–67.Omid, M., Soltani, M., Dehrouyeh, M.H., Mohtasebi, S.S., Ahmadi, H., 2013. An expert egg grading system based on machine vision and arti ﬁcial intelligence techniques. J. Food Eng. 118 (1), 70–77.Powell, J., Krotosky, S., Ochoa, B., Checkley, D., Cosman, P., 2003. Detection and Identiﬁca- tion of Sardine Eggs at Sea Using a Machine Vision System Oceans 2003. Celebratingthe Past…Teaming Toward the Future (IEEE Cat. No. 03CH37492).Ripley, B.D., 2007.Pattern Recognition and Neural Networks. Cambridge University Press.Robotham, H., Bosch, P., Gutiérrez-Estrada, J.C., Castillo, J., Pulido-Calvo, I., 2010. Acoustic identiﬁcation of small pelagicﬁsh species in Chile using support vector machines and neural networks. Fish. Res. 102 (1), 115 –122. Sengur, A., 2008.Wavelet transform and adaptive neuro-fuzzy inference system for colortexture classiﬁcation. Expert Syst. Appl. 34 (3), 2120 –2128. Shaﬁee, S., Minaei, S., Moghaddam-Charkari, N., Barzegar, M., 2014. Honey characteriza- tion using computer vision system and arti ﬁcial neural networks. Food Chem. 159, 143–150.Soltani, M., Omid, M., 2015.Detection of poultry egg freshness by dielectric spectroscopyand machine learning techniques. LWT Food Sci. Technol. 62 (2), 1034 –1042. Storbeck, F., Daan, B., 2001.Fish species recognition using computer vision and a neuralnetwork. Fish. Res. 51 (1), 11–15. Vapnik, V., 2013.The Nature of Statistical Learning Theory. Springer Science & BusinessMedia.Zhao, J., Lin, H., Chen, Q., Huang, X., Sun, Z., Zhou, F., 2010. Identiﬁcation of egg's freshness using NIR and support vector data description. J. Food Eng. 98 (4), 408 –414. Zion, B., Doitch, N., Ostrovsky, V., Alchanatis, V., Segev, R., Barki, A., Karplus, I., 2006. Orna- mental Fish Fry Counting by Image Processing. Agricultural Research Organization,Bet Dagan.34 A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27 –34