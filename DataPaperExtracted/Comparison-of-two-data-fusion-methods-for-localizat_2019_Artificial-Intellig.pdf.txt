Comparison of two data fusion methods for localization of wheeledmobile robot in farm conditions
S. Erfani ⁎, A. Jafari, A. Hajiahmad
Department of Agricultural Machinery Engineering, College of Agriculture and Natural Resources, University of Tehran, Karaj, Iran
abstract article info
Article history:Received 29 January 2019Received in revised form 10 May 2019Accepted 11 May 2019Available online 15 May 2019Localization of a mobile robot with any structure, work space and task is one of the most fundamental issues intheﬁeld of robotics and the prerequisite for moving any mobile robot that has always been a challenge for re-searchers. In this paper, the Dempster-Shafer (D.S.) and Kalman ﬁlter (K.F.) methods are used as the two main tools for the integration and processing of sensor data in robot localization to achieve the best estimate of posi-tioning according to the unsteady environmental conditions in agricultural applications. Also, by providing a newmethod, the initial weighing on each of these GPS sensors and wheel encoders is done based on the reliability ofeach one. Also, using the two MAD and MSE criteria, the localization error was compared in both K.F. and D.S.methods. In normal Gaussian noise, the K.F. with a mean error of 2.59% performed better than the D.S. methodwith a 3.12% error. However, in terms of non-Gaussian noise exposure, the K.F. information was associatedwith a moderate error of 1.4, while the D.S. behavior in the face of these conditions was not signi ﬁcantly changed. The experimental tests conﬁrmed the statement.© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Sensory data fusionMobile robotLocalizationDempster - Shafer methodKalmanﬁlter
1. IntroductionToday, agricultural automation is inevitable in order to save on costsand produce more per unit area. Robotics can also meet the goals of au-tomation in agriculture, by minimizing the tough, risky, deadly and longworking conditions, along with precise monitoring and control. Withthe development of research in thisﬁeld and the development of tools used to guide robots, including optical, ultrasound and radio sensors,the problem of increasing the accuracy and speed of the robots was con-sidered (Murakami et al., 2006). Data fusion is a method for combiningthe data from several sources of information used to obtain a brighterpicture of the problem being investigated and measured. Data fusionsystems are currently being used in a variety of ﬁelds, including sensor networks, robotics, photo and video processing, and smart system de-sign. A lot of research, especially in recent years, has been done in theﬁeld of data fusion, but there is still a long gap between intelligent sys-tems in this area with the ability of organisms, especially the ability ofthe human brain (Hall and Llinas, 1997).Klein (1993)provided a deﬁni- tion of the integration of sensor data, which combines sensor data, fromone type or from different sources of data. Both de ﬁnitions provide a general form in the use of sensors and can be used in a variety of appli-cations, including remote sensing. The authors have reviewed many ofthe methods of data fusion and discussed each one. Based on thestrengths and weaknesses of previous work, a basic de ﬁnition of infor- mation integration is presented as follows: Information integration isan effective way to automatically or semi-automatic conversion of infor-mation from different sources or at different time points into an effec-tive output that in the decision-making process, acts automatically orsupports human decision-making. In studies for localization, the combi-nation of the global positioning system and other sensors such as iner-tial measurement sensors, position detection sensors (digitalcompass), camera, radar and laser sensors, have shown more accurateresults than the use of only the GPS ( Keicher and Seufert, 2000; Subramanian et al., 2006;Li et al., 2010). The combination of GPS speed with the INS sensor was used to measure the slip angle of the ve-hicle and the tire when it was turned ( Bevly et al., 2001). In other re- search,Zhang et al. (2002)equipped an agricultural tractor with anintelligent navigation system with machine vision sensors and opticalﬁber gyroscope. In a research conducted by Mizushima et al. (2011)po- sitioning sensors were combined with three vibrational gyroscopes andtwo inclinometers.Park (2016)for safe and comfortable mobile robotnavigation in dynamic and uncertain environments, extended thestate of the art in analytic control of mobile robots, sampling based op-timal path planning, and stochastic model predictive control.Shafer et al. (2003)introduced the theory of evidence, later knownas the Dempster-Shefer theory. The basis of this approach is to integratedata into evidence or beliefs that can manage information de ﬁciencies. This was a reinterpretation of Arthur Dempster's research in the1960s, which, according to Dempster, has been largely modi ﬁed by Shafer (Shafer et al., 2003).Denoeux et al. (2017)provided two newArtiﬁcial Intelligence in Agriculture 1 (2019) 48 –55
⁎Corresponding author.E-mail addresses:saeederfani@ut.ac.ir(S. Erfani),Jafarya@ut.ac.ir(A. Jafari), Hajiahmad@ut.ac.ir(A. Hajiahmad).
https://doi.org/10.1016/j.aiia.2019.05.0022589-7217/© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the C C BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/division methods, along with simulation of some applications in the D.Smethod.Liu et al. (2017), in their research, proposed a new weightingmethod in Dempster-Shafer theory by a fuzzy algorithm that can usethe evidence obtained from different methods to classify the target.Despite extensive research in theﬁeld of robotics and control, the implementation of plans and methods of localization in the agriculturalindustry has been less studied due to the fundamental difference in thelaboratory environment with real conditions. Because highly accuratesensors such as DGPS, in addition to the high cost, have access restric-tions, In this paper, various methods of integrating global positioningunit and inertia measurement unit are utilized by Dempster-Shafer the-ory as well as Kalmanﬁltering, and the results were compared to selectan accurate method for localization at an appropriate cost. Also, by in-troducing a new method, initial weighting has been made on the infor-mation of each of the GPS sensors and wheel encoders, based on thereliability of each one. In addition to obtaining the geometric equationsgoverning the robot, a PD controller was implemented for kinematiccontrol and evaluation of the robot localization algorithms.The rest of the paper is organized as follows: The kinematic model-ing of the agricultural robot, the simulation of the robot in theMATLAB SimMechanic, localization by Dempster- Shafer and Kalmanﬁlter are given inMaterials and Methodsection. Comparing of these two methods and the results is presented in Result and Discussions. The experimental tests were designed to investigate the validity of sim-ulation results. Andﬁnally, last section, where some conclusions arehighlighted.2. Materials and method2.1. ModelingIn this section, a model will be created for a robot that is a car-likerobot. The typical model for the four-wheel robots is the bicyclemodel shown inFig. 1. The two-wheel drive model has a rear wheelmounted on its body, and the front wheel plate rotates around a verticalaxis for steering. The position of the robot is represented by a movingcoordinate system whose x-axis is in the direction of moving forwardof the robot and its center corresponds to the center of the rear axle ofthe robot. The conﬁguration of the robot is also deﬁned by general coor- dinatesq=(x,y,θ)∈Cin which,C, is an Euclidean two-dimensionalspace. In this coordinate system, the speed of the robot is along the x-axis, because the robot cannot slip sideways. And because of the lowspeed, longitudinal slip and centrifugal force can be ignored.v
x¼v;v y¼0 ð1ÞThe wheels cannot move in the direction of the dashes, and thesetwo dashes cut off at one point, which is called the instantaneous centerof rotation. This point is the center of the circle the robot tracks and theangular velocity of the robot is obtained from the following equation._θ¼
vR
1ð2ÞIn whichR
1¼L/C14
tanγandLis equal to the length of the robot.As can be imagined, the radius of the robot's circular path increaseswith increasing length of the robot. On the other hand, the steeringangle has a mechanical limit and its maximum value speci ﬁes the min- imumR
1value. So if the steering angle is constant, the robot runs a cir-cular arc.According toFig. 1,R
2NR1, which means that the front wheel musttravel longer and therefore have a higher speed than the rear wheel.Also, in a four-wheel robot, the outer wheels are rotational with differ-ent radials from the inner wheels. Therefore, there is very little differ-ence between the steering angle of the steering wheels, and thisdifference can be made using the Ackerman steering mechanism onthe steering wheels. Similarly, in moving wheels, the speed of rotationvaries. The speed of the robot is equal to ( vcosθ,vsinθ) in the reference coordinate system. By combining it with Eq. (2), the equations of mo- tion are obtained as follows._x¼vcosθ ð3Þ _y¼vsinθ ð4Þ_θ¼
vLtanγ ð5ÞThis model is a kinematic model of the robot, because it is describedby the speed of the robot, not the force and torque that speeds up. In theglobal or reference coordinate system:_ycosθ−_xsinθ¼0 ð6ÞThis is a non-holonomic motion control. Another important featureof this model is that when the robot speed is zero, then _θ¼0. This means that the robot direction cannot be changed without moving. Itcomes from Eq.(5). Because,_θis the instantaneous velocity of rotation.Also the robot command is always less than
π=2.2.2. SimulationIn this section, according to the kinematic model of the robot, a sim-ulation of the robot in the MATLAB software has been addressed. Fig. 2 shows the implementation of Eqs.(3) to (5)in the Simulink environ- ment. Linear speed and steering angle as input, and position and angleof the robot are considered as output of this model.In order to have a dynamic environment and visual representation ofthe robot's motion, the robot model is interconnected individually in theSimMechanics of Matlab software to allow the robot's behavior in deal-ing with various control algorithms be observed by combining it withSimulink environment. By placing a sensor on a robot, in order to reportits position and angles (such as the gyroscope sensor), these robot fea-tures are available throughout the path. The robot moves with constantvelocity and the steering angle is the only control variable.The control commands to the simulated model have been imple-mented from controllers written in the Simulink. In addition, byreporting the amount of rotation of each joint, in fact, will be an encoder
Fig. 1.Bicycle model of four wheeled robot.49 S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48 –55on the each wheel which produces output in radians per second. InFig. 3, simulation of the robot and the transfer of various parts ofSolidWorks to the SimMechanics, along with an explanation of eachpart, are presented.2.3. LocalizationNow, the robot positioning in the simulation environment is per-formed using two methods, Kalmanﬁlter and Dempster-Shafer. Also, the initial weighing to the sensors' results will be explained and applied.2.3.1. Dempster - Shafer's theoryDempster-Shafer's Theory of Evidence according to many crediblereferences, is the most powerful method in data fusion. In fact, thismethod merges data at the decision level. This method has the abilityto integrate any numerical, signal, and multi-dimensional data. One ofthe areas that this tool and its features are underused is the localization.In this paper,ﬁrstly will be shown how D.S. Theory of Evidence can beused in precise positioning of moving objects, and then the performanceof this method in localization will be compared with K.F. method. D.Stheory is a generalization of the Bayesian method that can handle sensorinformation defects. In the event that all necessary information is avail-able, all data fusion methods provide a comprehensive and acceptableapproach but in the face of lack of sensitivity and sensitivity data, theyare not reliable. In such cases, data fusion methods should make as-sumptions about sensor data which may not match on real data.Consequently, conﬂicting results may be obtained. But D.S. theory isnot limited by model defects or previous information defects. So, the ev-idence is determined solely on the basis of the obtained data, and not bythe assumed data. So it can be concluded that this method is a quick andan accurate tool for combining incomplete data. For sensory data fusionusing the D.S. method, a given weight must be assigned to each datasource at any given time. For this purpose, ﬁrstly, by the standard devi- ation of data, for the N last produced data, the amount of data validationfor each sensor is determined. If the standard deviation of the N last datais smaller than the speciﬁed valueα, there are fewer jumps and moreconﬁdence in that sensor, and if the standard deviation is greater thanthat value, reliability will be less.αand N values are empirically deter-mined based on the behavior of sensor data or expert opinion. Initially,the variance of each sensor's data is calculated:σ
2¼1NXNi¼1xi−μðÞ2ð16ÞHihgly reliable level c
1¼1ðÞσ2≤αð17ÞPoorly reliable level c
2¼2ðÞσ2NαWith each new data, the variance of the N last data is updated andthe upper and lower levels of conﬁdence are speciﬁed. These levels
Fig. 2.Simulation of the kinematics model of robot.
Fig. 3.Simulate a robot and transfer parts to the simulator SimMechanics.50 S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48 –55(a) 
(b) 
(c) 
Fig. 4.Noise simulation diagrams and the results of applying the fusion tool to the robot position parameters.51 S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48 –55are used in Shannon entropy relations as follows: ( Lu et al., 2016)P
c1t¼Rc
1tRc
1tþRc 2t;Pc2t¼Rc
2tRc
1tþRc 2tð18ÞAnd the entropy criterion for each of the Sensors is obtained as fol-lows:H
it¼X2c¼1Pcitlog2Pcitð19ÞFinally, by the entropy obtained for each Sensor, and using the for-mula below, its weight will be determined ( Lu et al., 2016):Wit¼1H
itðÞ2PIi¼1HitðÞ−2ð20ÞThe greater the entropy of a sensor's data, the lower the con ﬁdence level, and consequently the lower the weight assigned.2.3.2. Sensor noise simulation and performance analysis of fusion toolsFirstly, the positioning data of two sensor data sources- Sensor 1: theGPS data and Sensor 2: the total of IMU data and the rear wheelencoders- is received from sensor blocks in the Simulink toolbox, andre-simulated after adding noise and bias up to 10% of the turmoil to
Fig. 5.Entropy graph of sensor data and weight assigned to sensor sources.
Table 1Comparison of the performance of two data fusion tools in simulation.Test number Benchmarking D.S (% error) K.F (% error)1 MAD MSE 1.994.76 1.452.59 2 MAD MSE 2.236.02 1.593.22 3 MAD MSE 1.944.76 1.422.62 4 MAD MSE 1.774.01 1.492.85 5 MAD MSE 1.783.45 2.035.23 6 MAD MSE 1.432.77 1.593.2252 S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48 –55those. Then, in theﬁrst step, for a speciﬁc semicircular path, the sensor values are combined by Kalmanﬁlter and Dempster-Shafer separately.In the following, there are three series of diagrams, each showing oneof the robot position parameters. In each series of charts, the output ofthe simulated blocks of two sensor sources that are coupled withnoise, and the results of applying two data fusion tools are shown. InFig. 4a, the parameter x, in theFig. 4b, the parameter y and in the Fig. 4c, the parameterθare analyzed and in MATLAB simulation toolbox,the performance of these two data fusion tools is shown in a given timeperiod and path. As indicated in these diagrams, the red-dashed pathsare the real robot motions in the simulation environment, which is ex-pected to show by the ideal sensors. Purple and pale green colors areshown simulated sensor data after the noise respectively for the ﬁrst and second sensor sources. Also the blue color shows the fusion oftwo noisy sensor data by D.S. method and the dark green color showsthe fusion by the K.F. method. It is clear that the Kalman methodshows better performance in Gaussian noise.Fig. 5a is the entropy graph of the two sensor sources, and Fig. 5bi s the obtained weight graph based on sensor data. As shown in thesecharts, the entropy of the Sensor 1 is greater than the Sensor 2, which
Fig. 6.a) Mobile robot implemented for tests. b) GPS module. c) IMU/AHRS module.
Fig. 7.a) Dempster-Shafer method. b) Kalman Filter method.
Fig. 8.a) Dempster-Shafer method. b) Kalman Filter method.53 S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48 –55indicates more disorder in GPS data than the encoder plus IMU data andso, the reliability of the data is less and the weight allocated to that Sen-sor will be less.3. Results and discussionsLooking at the diagrams ofFig. 4, K.F. seems to have a better perfor-mance than D.S., but according toFig. 5, the need to provide a bench- mark for comparing the performance of these two data fusion toolsseems to be necessary. For this reason, the Mean Absolute Deviation(MAD) and Mean square Error (MSE) criteria have been used. MAD,also referred to as the“mean deviation”or sometimes“average absolute deviation”, is the mean of the data's absolute deviations around thedata's mean: the average (absolute) distance from the mean. “Average absolute deviation”can refer to either this usage, or to the generalform with respect to a speciﬁed central point. The mean absolute devi-ation of a set {x
1,x2,x3,…,x n}i sMAD¼
1nXni¼1xi−mxðÞjj ð 21ÞWhich n is the number of values and m(x) is the mean. MAD hasbeen proposed to be used in place of standard deviation since it corre-sponds better to real life. Because the MAD is a simpler measure of var-iability than the standard deviation. This method's forecast accuracy isvery closely related to the MSE method which is just the averagesquared error of the forecasts. Although these methods are very closelyrelated, MAD is more commonly used because it is both easier to com-pute (avoiding the need for squaring) and easier to understand.MSE¼
1nXni¼1xi−bxi/C0/C12ð22Þwhichbx
iis predicted value.The numbers in the table below belong to the x variable in each sim-ulation test and for each evaluation criterion.The simulation reported in the previous section has been carried outsix times for two different paths (a linear path and a circular path). Intheﬁfth and sixth tests, the noise level applied to the Sensors is non-Gaussian noise. Typical IMU/GPS integration approaches usually adoptthe Gaussian error assumption. However, in practice, especially duringoff-road navigation and when several sources of GPS interference arepresent, this assumption does not hold. To this end, the best non-Gaussian noise model is the Huber estimator using a robust estimatoralgorithm, which is able to handle multipath GPS signals as well as in-tentional and unintentional interferences. Gaussian mixture modelsare based on the representation of any non-Gaussian distribution asthe sum of multiple Gaussian densities with different weights(Karlgaard and Schaubt, 2007). For the IMU/GPS algorithm discussedhere, the noise is assumed to be composed of two Gaussiancomponents.The results presented inTable 1show that the performance of theDempster-Shafer method in sensor data fusion associated with non-Gaussian noise is better than the Kalman ﬁlter. Since in real life the noise behavior is more non-Gaussian, it seems that the Dempstermethod will perform better in dealing with real issues.4. Experimental resultsIn this section, an unmanned ground vehicle is implemented practi-cally to perform real-time navigation. This vehicle has been constructedin Biosystem Mechanical Engineering Department of Tehran University.The vehicle used as mobile robot has a servo mechanism as its steeringmechanism. Then the aforementioned controller have been imple-mented and the platform is examined in two case study to verify the re-sults of simulation. The GPS module applied in the experiment is NEO-M8N and the IMU/AHRS module is GY-801. The vehicle and modulesc a nb es e e ni nFig. 6.In the platform test a linear and a circular smooth path are generatedas desired paths. These paths are fed into the system as inputs sepa-rately. So, the actual paths are obtained. The relation between the de-sired and actual path is shown inFigs. 7 and 8. The root mean square error (RMSE) criterion is used for comparing the performance of thesetwo methods. According toTable 2, the Dempster-Shafer method hadbetter performance in path tracking. Also the error between actualand desire orientation angles during the circle path is shown in Fig. 9 andTable 2.Axis units x and y are inFigs. 7 and 8in meter, and inFig. 9, the x-axis is in terms of time (second) and the y axis in radians.As seen from the Figures and Table above, the Dempster-Shafermethod provides better performance with less error than Kalman Filterin vehicle localization. Mean deviation from desire path in path trackingby Dempster-Shafer method is about 15.5 cm in linear path and about17 cm in circular path. This method shows an error about 17.7 degreein orientation during circular path tracking. Localization using KalmanFilter makes up a higher error about 4.7% in linear path and about 5%Table 2Comparison of the performance of two data fusion tools in experimental test.Path RMSED.S Linear path 0.156Circular path 0.172Orientation error 0.31K.F. Linear path 0.203Circular path 0.224Orientation error 0.40
Fig. 9.The error between actual and desire orientation angles. a) Dempster-Shafer method. b) Kalman Filter method.54 S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48 –55in circular path. Orientation error in circular path is about 23 degree byKalmanﬁlter method.5. ConclusionIn this paper, tried to simulate controlling of an agricultural tractorrobot and it's localization in real condition using Dempster-Shafer andKalmanﬁlter algorithms, as data fusion tools. The results showed a bet-ter performance of the Dempster-Shafer method when applying non-Gaussian noise which is the reliability validation of the Dempster-Shafer method in conditions close to real conditions. To verify the valid-ity of this statement and also to compare these two methods of data fu-sion for localization in real-world conditions, two paths were designedon the crop soil. The mobile robot prepared for autonomous navigationtracked the aforementioned paths by the controller described in thepaper. Results show the better performance of Dempster-Shafermethod in comparison with Kalman Filter.References
Bevly, D.M., Sheridan, R., Gerdes, J.C., 2001. Integrating INS sensors with GPS velocitymeasurements for continuous estimation of vehicle sideslip and tire cornering stiff-ness. Proceedings of the 2001 American Control Conference. IEEE, Arlington, VA,USAhttps://doi.org/10.1109/ACC.2001.945508 . Denoeux, T., Li, S., Sriboonchitta, S., 2017. Evaluating and comparing soft partitions: an ap-proach based on Dempster-Shafer Theory. Journal of IEEE Transactions on Fuzzy Sys-tems. 26 (3), 1231–1244.https://doi.org/10.1109/TFUZZ.2017.2718484 . Hall, D.L., Llinas, J., 1997. An introduction to multisensor data fusion. Journal of Proceed-ings of the IEEE. 85 (1), 6–23.https://doi.org/10.1109/5.554205 .Karlgaard, C.D., Schaubt, H., 2007. Huber-based divided difference ﬁltering. AIAA Journal of Guidance, Control and Dynamics 30 (3), 885 –891.https://doi.org/10.2514/ 1.27968.Keicher, R., Seufert, H., 2000. Automatic guidance for agricultural vehicles in Europe. Jour-nal of Computers and electronics in agriculture. 25 (1), 169 –194.https://doi.org/ 10.1016/S0168-1699(99)00062-9 . Klein, L.A. 1993. Sensor and data fusion concepts and applications. Society of Photo-Optical Instrumentation Engineers (SPIE) Bellingham, WA, USA. ISBN: 0819432318.Li, W., Huang, Y., Cui, Y., Dong, S., Wang, J., 2010. Traf ﬁcability analysis of lunar mare ter- rain by means of the discrete element method for wheeled rover locomotion.J. Terrramech. 47 (3), 161–172.https://doi.org/10.1016/j.jterra.2009.09.002 . Liu, Y.T., Pal, N.R., Marathe, A.R., Lin, C.T., 2017. Weighted fuzzy Dempster-Shafer frame-work for multi-modal information integration. Journal of IEEE Transactions onF u z z yS y s t e m s .2 6( 1 ) ,3 3 8–352.https://doi.org/10.1109/TFUZZ.2017.2659764 . Lu, C.-C., Ying, K.-C., Chen, H.-J., 2016. Real-time relief distribution in the aftermath ofdisasters–a rolling horizon approach. Journal of Transportation research part E: logis-tics and transportation review. 93, 1 –20.https://doi.org/10.1016/j.tre.2016.05.002 . Mizushima, A., Ishii, K., Noguchi, N., Matsuo, Y., Lu, R., 2011. Development of a low-costattitude sensor for agricultural vehicles. Journal of Computers and electronics in agri-culture. 76 (2), 198–204.https://doi.org/10.1016/j.compag.2011.01.017 . Murakami, N., Dale Will, J., Ito, A., Steffen, M., Inoue, K., Kita, K., Miyaura, S., 2006. Environ- ment identiﬁcation technique using hyper omni-vision and image map. Proceedingsof the 3rd IFAC Intl. Workshop Bio-Robotics, pp. 317 –320 (DOI:10.1.1.472.918). Park, J.J., 2016.Graceful Navigation for Mobile Robots in Dynamic and Uncertain Environ-ments. (Ph.D. diss.). Mechanical Engineering Dept., University of Michigan.Shafer, G., Gillett, P.R., Scherl, R.B., 2003. A new understanding of subjective probabilityand its generalization to lower and upper prevision. Int. J. Approx. Reason. 33 (1),1–49.https://doi.org/10.1016/S0888-613X(02)00134-2 . Subramanian, V., Burks, T.F., Arroyo, A., 2006. Development of machine vision and laserradar based autonomous vehicle guidance systems for citrus grove navigation. Jour-nal of Computers and electronics in agriculture. 53 (2), 130 –143.https://doi.org/ 10.1016/j.compag.2006.06.001 . Zhang, Q., Wu, D., Reid, J.F., Benson, E.R., 2002. Model recognition and validation for anoff-road vehicle electrohydraulic steering controller. J. Mech. 12 (6), 845 –858. https://doi.org/10.1016/S0957-4158(01)00030-7 .55 S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48 –55