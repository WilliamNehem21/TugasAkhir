A single fault localization technique based on failed test input
Abubakar Zakaria,*, Sai Peck Leeb, Ibrahim Abaker Targio Hashemc,**
aDepartment of Computer Science, Kano University of Science and Technology, Wudil, P.M.B, 3244, Kano, Nigeria
bDepartment of Software Engineering, Faculty of Computer Science and Information Technology, University of Malaya, 50603, Kuala Lumpur, Malaysia
cSchool of Computing and IT, Taylor ’s University, Subang Jaya, Selangor, 47500, Malaysia
ARTICLE INFO
Keywords:Complex networkFault localizationProgram debuggingProgram spectraSoftware testingABSTRACT
Testing and debugging are very important tasks in software development. Fault localization is a very criticalactivity in the debugging process and also is one of the most dif ﬁcult and time-consuming activities. The demand for effective fault localization techniques that can aid developers to the location of faults is high. In this paper, afault localization technique based on complex network theory named FLCN-S is proposed to improve localizationeffectiveness on single-fault subject programs. The proposed technique diagnoses and ranks faulty programstatements based on their behavioral anomalies and distance between statements in failed tests execution byutilizing two network centrality measures (degree centrality and closeness centrality). The proposed technique isevaluated on a well-known standard benchmark (Siemens test suite) and four Unix real-life utility subject pro-grams (gzip, sed,ﬂex, and grep). Overall, the results show that FLCN-S is signi ﬁcantly more effective in locating faults in comparison with other techniques. Furthermore, we observed that both degree and closeness centralityplay a vital role in the identiﬁcation of faults.
1. IntroductionDespite much advancement in software development and testing inrecent years, even software of the highest quality may still contain faults,and cause the software to fail [1]. On locating software faults, programdebugging generally consumes a momentous amount of resources in asoftware project. Essentially, a three-step process which consists of ﬁrst detecting program failure, secondly, determining the exact fault locationand the nature of the fault that caused the failure, and lastly, ﬁxing the identiﬁed fault itself [2]. Hence, while the entire debugging process isknown to be extremely difﬁcult, the second process (fault localization) isbroadly reported to be the most tedious, time-consuming, and costlyactivity among all [3–5]. Even in an educational environment, wherestudents were tasked toﬁnd the location of faults in a faulty programcode, the report shows that identifying faults location in a program codeis an extremely challenging task [6].In the past decades, several fault localization techniques were pro-posed with the aim of improving the fault localization process such asspectrum-based techniques [7–9], statistical-based techniques [10,11], model-based techniques [12], and machine learning-based techniques[13,14]. Among these techniques, spectrum-based fault localizationtechnique (SFL) has gained more popularity, thanks to its simplicity andminimal computational overhead. SFL requires little or no knowledge ofsoftware program semantics in order to localize faults. Generally, SFLuses test coverage data and their corresponding test results (passed/-failed) from dynamic execution to build a program spectrum. The pro-gram spectrum is used to deﬁne variables highlighting the distinctionbetween tests execution results (passed/failed). Lastly, similarity co-efﬁcients based on SFL techniques are used to compute program state-ments suspiciousness (the likelihood of statements to be faulty). Thestatements are then ranked based on their suspicious scores in descend-ing order for fault localization. Based on this insight, various similaritycoefﬁcients were proposed to calculate the suspicious score of programstatements, such as Ochiai [15], Jaccard [16], DStar [9] etc. This work builds on previous work [ 17] where we have proposed a new fault localization technique based on complex network theory(FLCN). Statements behavioral anomalies and the distance betweenprogram statements in both passed and failed tests execution are the twovariables that the technique takes into account. Degree centrality andcloseness centrality were adopted for fault diagnosis and a ranking for-mula was also proposed to aid in identifying fault location. The techniquelocates faulty statements irrespective of whether the statements were
* Corresponding author.** Corresponding author.E-mail addresses:abubakar.zakari@yahoo.com(A. Zakari),abubakar.zakari@yahoo.com(I.A.T. Hashem).
Contents lists available atScienceDirect
Array
journal homepage:www.elsevier.com/journals/array/2590-0056/open-access-journal
https://doi.org/10.1016/j.array.2019.100008Received 6 February 2019; Received in revised form 30 August 2019; Accepted 2 October 2019Available online 5 October 20192590-0056/©2019 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).Array 3-4 (2019) 100008executed by passed or failed test inputs. We observed that, on single-faultsubject programs, the effectiveness is not convincing, whereby a devel-oper can locate only 40% of faults by checking 10% of the program code.This is mainly due to the high sensitivity of the technique (FLCN) withprogram statements executed by passed test inputs. In this paper, weproposed a variant technique coined fault localization based on complexnetwork theory for single-fault program (FLCN-S) to address this issue.The technique utilizes failed tests execution alone for fault localization(Section3). Because for a program with a single fault, the faulty state-ment is more likely to be executed by failed test inputs due to lessfault-to-failure complexity as shown in previous studies [ 18–22]. High fault-to-failure complexity occurs mainly when a program has manyfaults, whereby fault interfere with each other and deters fault localiza-tion effectiveness [21,23].To demonstrate the effectiveness of utilizing the proposed technique,we perform an experiment on a well-known standard benchmark(Siemens test suite) and four Unix real-life utility programs ( gzip, sed,ﬂex, and grep). We compared the proposed technique with four different faultlocalization techniques, namely Ochiai, Tarantula, Jaccard, and SNCM.Overall, the results show a signiﬁcant improvement on the single-faultsubjects where 65% of all the faulty versions can be localized bychecking less than 10% of the program code on Siemens test suite pro-grams and is largely more effective on Unix real-life utility programs incomparison with other techniques. Furthermore, we observed that bothdegree centrality and closeness centrality plays an important role in theidentiﬁcation of faulty program statements. The major contributions ofthis paper are summarized as follows:/C15A new fault localization technique named FLCN-S is proposed toimprove localization effectiveness on single-fault subject programs./C15The impact of the adopted centrality measures on fault localizationeffectiveness was investigated./C15The effectiveness of the proposed technique is evaluated on a stan-dard benchmark (Siemens test suite), and four Unix real-life utilitysubject programs. The experimental results highlight that FLCN-S issigniﬁcantly more effective in localizing faults than the comparedtechniques.The rest of the paper is organized as follows. Section 2highlights some existing related work. Section3presents the proposed fault local- ization technique. Section4describes the experimental setup, results,and discussion. Lastly, the study is concluded in Section 5.2. Related workIn the last two decades, many automated fault localization techniqueswere proposed to localize software faults effectively. In this section, wesummarize some of these techniques that are mainly applied on a single-fault context.Automated fault localization techniques help facilitate localizationprocess. This facilitation helps in the increase in software quality andreduction in software delivery time [ 24]. SFL techniques exploits pro- gram dynamic coverage information of passed and failed test inputs toidentify program locations that are more prone to errors [ 19]. The ratio of passed and failure of test inputs on a given program statement de-termines how suspicious the statement is. In case if there are more failedtest inputs that execute the statement, the statement will have a highsuspicious score, and less suspicious score if more passed test inputsexecuted it. Program statements will then be ranked in descending orderof their suspicious score. According to the literature, SFL is one of themost utilized and effective fault localization techniques [ 24]. In the early days, researchers used failed tests execution alone in locating faults forSFL [25–27]. However, this practice was later shown to be ineffective inlocating program faults, particularly on manual fault localization tech-
niques [28]. Studies that use both passed and failed test cases have shownto achieve better results [15,18,29,30]. Renieres and Reiss proposed atechnique named nearest neighbor, which produces a suspiciousnessreport of program statements by measuring the distance between a failedtest input and a passed test input which is more similar to the failed one[31]. In SFL, the similarity between the test result vector and thecoverage matrix of each statement is measured. Hence, this similarity isquantiﬁed and measured by a similarity coefﬁcient-based fault localiza- tion technique. Various similarity coefﬁcients and techniques were pro- posed such as Tarantula [18], Ochiai [15], Crosstab [29], Jaccard [15], and Zoltar-S [32,33]. These similarity coefﬁcients/techniques have consistently shown to be useful in locating distinct sorts of softwarefaults. Jones and Harrold proposed a fault localization technique calledTarantula [18]. Tarantula utilizes coverage information of tests execution(passed/failed) to localize faults. Executable statements are rank basedon their suspiciousness score value. Hence, a developer will examine theprogram code based on their suspiciousness score value in descendingorder to identify faulty statements. Tarantula has shown to be one of themost effective software fault localization techniques. However, othercoefﬁcients have been found in recent years that surpass Tarantula interms of effectiveness in locating program faults [ 29,34]. For example, the Ochiai similarity coefﬁcient-based fault localization technique isregarded to be more effective than Tarantula [ 15]. Ochiai coefﬁcient,SS, is calculated as depicted in Equation (1).S
s¼NcfﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃðNcfþNnfÞ/C2ðNcfþNcsÞp (1)Ncfrepresents the total number of failed test inputs that cover astatement, andNnfrepresents the total number of failed test inputs thatdo not cover a statement, whileNcsrepresents the total number of passedtest inputs that cover a statement. Notations that are widely used insuspiciousness calculation are highlighted in Table 1. Naish et al. pro- posed two SFL techniques, which are O and O <SUP>P</SUP>[35]. The former was built for programs with a single fault, while the latter is forprograms containing multiple faults. The result of the study showed thatO and O<SUP>P</SUP>are more effective in localizing faults thanTarantula. Shu et al. proposed a fault localization method based onstatement frequency to improve the diagnosis accuracy of SFL techniques[36]. The statement frequency information of each statement in thesoftware program is used to localize faults. The study showed that theproposed approach outperforms Tarantula in terms of stability andeffectiveness, respectively. An improved form of Kulczynski coef ﬁcient metric coined DStar was proposed in Ref. [ 9]. The greater the DStar value, the more efﬁcient the technique is in locating program faults.DStar has proven to be very effective and surpasses various fault locali-zation techniques in terms of effectiveness in locating faults. However,researchers in Refs. [19,37] conducted a comparison study of SFL tech-niques. They concluded that SFL techniques ’performance varies based on the debugging scenarios they were applied to, whereby a coef ﬁcient can be more effective in a given scenario and less effective in otherscenarios [38]. Therefore, there is no coefﬁcient that can outperform all others under every scenario.Table 2highlights some of the existing similarity coefﬁcient-based fault localization techniques.De Souza et al. proposed a technique to contextualize code inspection
Table 1Some of the notations commonly utilized in suspiciousness calculation.
Notation DescriptionN The total number of test inputsN
f The total number of failed test inputsNsThe total number of passed test inputsNcfThe total number of failed test inputs that cover a statementNcsThe total number of passed test inputs that cover a statementNc The total number of test inputs that cover a statementNufThe total number of failed test inputs that cannot cover a statementNnfThe total number of failed test inputs that do not cover a statementNusThe total number of passed test inputs that cannot cover a statementNuThe total number of test inputs that cannot cover a statementA. Zakari et al. Array 3-4 (2019) 100008
2to offer direction during fault localization and increase localizationeffectiveness of SFL techniques. This technique will help in localizingfault in theﬁrst generated suspiciousness list [39]. The result shows that the technique is useful in guiding developers to fault locations and im-proves localization effectiveness. Another study by Kim et al. proposed atechnique to enhance the performance of existing SFL techniques [ 40]. The technique extracts variables that are suspicious and utilize the var-iables to generate a suspicious ranked list. The result shows that theirproposed technique outperforms existing similarity coef ﬁcient-based techniques. Landsberg et al. improve the effectiveness of SFL techniqueby introducing a new method that generates a viable and ef ﬁcient test suite for effective fault localization [41]. In another study by Ref. [42], a fault localization technique named FDDI was proposed. The technique(FDDI) chooses the most suspicious function and applies invariantdetection tools to the function distinctly. Hence, for the variables whichare not in a set of passed/failed test inputs speci ﬁed by using these tools, FDDI will select those variables for further fault examination.There are also works on statistical-based fault localization and ma-chine learning-based techniques in locating program faults. In a previousstudy [43], an algorithm based on statistical-based debugging techniquecoined SOBER was proposed to rank and isolate suspicious programpredicates on faulty programs. The technique categorizes the effects ofdistinct faults andﬁnds predicates that are related to individual faults.The predicates clarify the circumstances and regularities of fault mani-festations and make it simpler to manage and prioritize debugging effort.In addition, Wong et al. introduced a crosstab-based method for effectivefault localization [29]. The technique calculates the suspiciousness scorevalue of program statement to know its likelihood of containing faults.Hence, two columns of variables (covered/not covered) of a programstatement are generated with two rows indicating tests results (pas-sed/failed). The suspiciousness score value of each program statement isthen calculated based on the degree of relationship between statementscoverage and their execution results. Furthermore, Liblit et al. proposed astatistical debugging technique to separate faults in a software programwith instrumented predicates [44]. Predicates are ranked based on theirsuspicious score. Predicates with high suspiciousness score are checkedﬁrst, and if a fault is found andﬁxed, the faulty data is then removed. Theprocess is then repeated toﬁnd the remaining faults until all predicatesare examined.Moreover, a statistical debugging approach was proposed to examinethe behavior of continuously linked predicates in a given programexecution [45]. For each test input, the approach constructs a weightedexecution graph with predicates as vertices against change betweensequential predicates as edges. Hence, for each edge in the graph, asuspicious score is computed to identify its fault relevant likelihood.Additionally, a novel probabilistic model for fault localization based onan important sampling of program statements was proposed [ 10]. By utilizing probability updates and sampling, the approach can help iden-tify statements that have a high likelihood of being faulty. The approachwas found to be more sensitive to failed test inputs than passed test in-puts. In addition, Wong et al. proposed two machine learning-basedtechniques for fault localization, fault localization based on BP (back--propagation) neural network [34] and fault localization based on RBF(radial basis function) neural network [ 14] to localize faults effectively. The result shows that these techniques are effective in locating programfaults. However, these techniques have problems of paralysis and localminima. In another study by Zheng and Wang, a fault localization basedon Deep Neural Network (DNN) was proposed to tackle the problems ofparalysis and local minima [13]. DNN was found to be very effective incomparison to other machine learning-based techniques.Zhu et al. proposed a fault localization technique named SNCM [ 46].
The technique uses two centrality measures, namely degree centralityand structural hole, to measure statements correlation with failure.Recently, a fault localization technique based on complex network theory(FLCN) has been proposed to localize faults effectively [ 17]. Behavioral abnormalities of program statements and distance between them in bothpassed and failed tests execution are the two variables that the techniquetakes into account. Degree centrality and closeness centrality wereadopted for fault diagnosis and a new ranking formula was also proposed.Most recent studies have shifted to fault localization on multiple faults [ 4, 17,33,47–50] introducing various approaches and methods to localizefaults efﬁciently.3. Proposed techniqueBefore we start explaining our proposed technique, we need to revisitour initial benchmark technique (FLCN) and its observable limitation onsingle-fault context. We further need to highlight our current proposi-tions on how to deal with the aforementioned limitation.To improve the effectiveness of the former fault localization tech-nique (FLCN) in the single-fault context, we proposed a technique namedFault Localization based on Complex Network theory for Single-Faultprograms (FLCN-S), which is a variant of our initial technique inRef. [17] coined FLCN. FLCN localizes faults with the utilization of bothpassed and failed test inputs. However, from our initial results, weobserved that by utilizing both test inputs (passed/failed) in a single-faultcontext, the technique (FLCN) effectiveness reduces signi ﬁcantly. At best, FLCN aids developers in locating 40% of the faults by checking less than10% of the program code in single-fault subjects. This is mainly due tothe high sensitivity of FLCN with program statements executed by passedtest inputs. Hence, the effectiveness is not convincing in comparison withsimilarity coefﬁcient-based techniques such as Ochiai [ 19], Jaccard [15],Table 2Similarity coefﬁcient metrics.
S/N Coefﬁcient Formula S/N Coef ﬁcient Formula1 Pearson
n/C2ð ðNcf/C2NusÞ/C0ðNcs/C2NufÞÞ2 Nc/C2Nu/C2Ns/C2Nf9 Hamming NcfþNus2 Ochiai 1
NcfﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃðNcfþNnfÞ/C2 ðNcfþNcsÞp 10 Euclid ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃNcfþNusp3 Goodman
2Ncf/C0Nuf/C0Ncs2NcfþNufþNcs 11 Dice 2NcfNcfþNufþNcs 4 Naish 1 /C26/C01;ifNuf>0Nus;Otherwise 12 Anderberg
NcfNcfþ2ðNufþNcsÞ 5 Naish 2 Ncf/C0
NcsNcsþNusþ1 13 Sorensen-Dice 2Ncf2NcfþNufþNcs 6 Kulczynski
NcfNufþNcs 14 Braun-Banquet NcfmaxðNcfþNus;þNcfþNuf 7 Jaccard
NcfNcfþNufþNcs 15 Zoltar NcfNcfþNufþNcsþ
10000/C2Nuf/C2NcsNcf 8 Ample
NcfNcfþNuf/C0 NcsNcsþNus 16 Goodman 2Ncf/C0Nuf/C0Ncs2NcfþNufþNcsA. Zakari et al. Array 3-4 (2019) 100008
3or Zoltar-S [33]. Hence, to address this issue, we proposed the use offailed test inputs alone in the fault localization process in modeling theprogram complex network. This is because for a program with a singlefault, the faulty statement is more likely to be executed by failed testinputs due to less fault-to-failure complexity as shown in previous studies[18–22]. High fault-to-failure complexity occurs mainly when a programhas many faults, whereby fault interfere with each other and deters faultlocalization effectiveness [21,23]. In this paper, we proposed a newvariant technique called FLCN-S for single fault localization. This tech-nique adopts the same centrality measures and suspicious score formulaas utilized in our previous study [17]. The next section presents the proposed fault localization technique.3.1. Single-fault localization based on complex network theory (FLCN-S)Suppose we have a faulty program P with mexecutable statements and exactly a single fault. Suppose P is executed by t-test inputs, whereby some tests have passed while others have failed. The execution data isillustrated as presented inFig. 1. Theﬁgure illustrates a coverage matrix and a test result vector. For the matrix and test result vector with theentry of (i, j), the value of the matrix is 1 if the test input iexecutes statementj, and the value is 0 otherwise. Moreover, an entry iin the test result vector is 1 if the result of the test input iis failed, and 0 if the result is passed. Hence, each row of the coverage matrix highlights the state-ments that are executed by available test inputs, and each column showsthe coverage vector of the corresponding program statement.The proposed technique (FLCN-S) uses tamount of test inputs that failed in a program test run as an input to construct the complex networkN. The complex networkNwill be generated following the processdetailed in Section3.1.1. Two centrality measures will be used for faultdiagnosis which are degree centrality and closeness centrality.One of the most commonly utilized centrality measures in complexnetwork research domain is degree centrality. Degree centrality caneffectively be used to statistically quantify node signi ﬁcance in a given modeled network. Node degree is the aggregate measure of the edges agiven node has in a network. Hence, in this paper context, for statementm
iin an undirected/unweighted complex network, if there is a connec-tion from statementm
ito statementm j, then each of the statements will have a single edge. Hence, if statement m
ihas an edge from another statementm
fthat is executed by a distinct test input, then, statement m i
will have two edges since it is connected to two executable statements ( m j
andm f) executed by separate test inputs. The study in Ref. [ 51] concludes that a node with a higher degree centrality is more likely to be strongerconnected in a given network, therefore, the node will be more likely tobe the cause of failure or related to failure. This centrality measure(degree centrality) is aimed to identify behavioral anomalies in state-ments executions and identify the most central statements in the programnetworkN.Therefore, to calculate the degree centrality of a statement in N, Equation(2)will be computed wherem
iis the focal statement,m jrepresents any other neighbor statement, nrepresents the total number of statements inN, andais the adjacency matrix.Dcðm
iÞ¼Xnj¼1aðmi;m jÞ (2)Overall, the adjacency metric will be used to compute the statements ’ connections, whereby if there is a connection between two statements(m
i,mj),ais indicated as 1 and 0 otherwise as shown in Equation (3).að
mi;m jÞ¼/C261;connection;0;Otherwise (3)Next, closeness centrality measures the inverse of the average shortestpath between a statement and all other statements in N, which infers that all paths should lead to a statement [52]. This centrality measure tries to measure how long it will take to spread information, diseases, or failuresfrom the node of interest to all other nodes sequentially. For fault thatpropagates through multiple program statements or faulty statementsthat are close to each other in the program, this centrality measure willaid in identifying them. Therefore, statements that are closer to thestatements with abnormal behaviors (relatively high degree centrality) inNwill be identiﬁed because the higher the closeness centrality value of astatement, the closer it is to all other statements. To compute the close-ness centrality of statementm
ito all other statements in the network N, Equation(4)will be utilized.Ccðm
iÞ¼n/C01P
nj6¼id/C0m i;mj/C1 (4)where d (m
imj) is the shortest path distance between statement m iandm j, andnis the total number of statements in N. Furthermore, to calculate the suspiciousnessSof statementm
iinN, the technique (FLCN-S) computes the suspicious value ofm
iusing the degree centrality valueDcofm iand it’s closeness centralityCcvalue inN. For a given program statementm
i, the difference between the two values will be computed using Equation(5). Computing the difference of these values will give a developerquantiﬁable value of how suspicious a statement is.Sðm
iÞ¼Dc i/C0Cc i (5) For all statements inNwherem
ican be represented asm i¼{m 1,m2, m
3,…,m n}, the suspicious score value will be assigned to each statementinN. The program statements will be given in descending order of theirsuspicious score values. Henceforth, a developer will check the programstatements with the highest suspicious score values until the ﬁrst faulty program statement is found.3.1.1. Constructing a complex network using failed test inputsTo model the complex networkN, the single fault program inTable 3 is used for illustration. The program has twelve statements, six test inputs(t¼6), and exactly one fault in statement m
5. Therefore, if a statement
Fig. 1.Coverage data and execution result.Table 3A single fault program with tests execution.
mi mid ( ) { input x, y, z, m; t 1 t2 t3 t4 t5 t6
m1 if (y<z ) 111111m
2 if (x<y ) 111111m
3 m¼y ; 110011m
4 else if (x<z ) 010000m
5 m¼z;//fault 1 m¼x 100011 m
6 else 1 0 0 0 0 1m
7 if (x>z ) 001100m
8 m¼x ; 101101m
9 else if (x>y ) 001000m
10 m¼y 000100m
11 print (“middle number is:“, m ) ; 000000 m
12 } 000110Result Pass/Fail Status 000011A. Zakari et al. Array 3-4 (2019) 100008
4execution is labeled as 1, it indicates that the statement is executed by thetest input in that test run, and 0 otherwise. For the test result of each testinput, 0 means the test input has passed while 1 means the test input hasfailed. Out of the six available test inputs, two of which are failed testinputs t
f¼(t 5,t6) while four are passed test inputs t p¼(t 1,t2,t3,t4). In order to model the complex network, failed test inputs t
f¼(t 5,t6)i st ob e utilized. For theﬁrst failed test input t
5, there is an edge fromm 1tom 2, m
2tom 3,m3tom 5, andm 5tom 12. For the second failed test t 6, there is an extra edge fromm
5tom 6andm 6tom 8, respectively.Therefore, all the failed test inputs in corresponding to the statementswill be modeled asN. As a result, a single networkNwill be generated to capture the entire tests execution behavior with statements representedas nodes and execution between statements as edges. Cytoscape softwareplatform (http://www.cytoscape.org/) is used for network construction and generation. We model the network as an undirected/unweightedcomplex network. The next section highlights the general framework ofthe proposed fault localization technique.3.1.2. General frameworkThis section presents the detail steps of the proposed fault localizationtechnique (FLCN-S) in locating a single fault./C15Step 1:In this step, the faulty program P will be executed by all theavailable test inputs inTand the execution data will be collected. Theexecution proﬁle of statements with respect to each test input will becollected. The set of passed and failed test inputs will be identi ﬁed. /C15Step 2:A networkNwill be modeled using the execution proﬁle of failed test inputs as input based on the process detailed in Section3.1.1./C15Step 3:For all program statementsnmodeled asN, theDcandCcof each statement will be calculated based on Equation (2)and Equation (4). Furthermore, Equation(5)will be computed to calculate thesuspicious score valueSof each statement inN. /C15Step 4:Based on the suspicious score value of program statements,rank the statementsm
1,m2,m3,…,m nbased onS 1,S2,S3,…,S nin descending order of their suspicious score values. A developer will betasked to check the statements one by one from the top until the faultlocation is identiﬁed.3.2. A running exampleLet’s use a sample program inTable 3which takes three integers as input to demonstrate how FLCN-S can be used to locate fault. The pro-gram has 12 statements (n¼12) with 11 executable statements and asingle fault in statementsm
5. The faulty statementm 5is executed by one passed test input {t
1} and two failed test inputs {t 5and t 6}. The proposed technique will rank the faulty statement at the top of the ranking listbecause it takes into consideration behavioral anomalies and distancebetween statements in failed tests execution.At step 2, to model the networkN, the process detailed in Section 3.1.1will be used. The network inFig. 2is generated using the above- failed tests execution. For theﬁrst failed test input t
5, there is an edge fromm
1tom 2,m2tom 3,m3tom 5, andm 5tom 12. For the second failed test input t
6, there is an extra edge fromm 5tom 6andm 6tom 8, respectively. The faulty statement m
5is executed by all the failed test inputs. Thus, the network as shown in Fig. 2is generated. Step 1 and step 2 is now completed.Moving to step 3, the degree centrality Dcof a statementm
iand the closeness centralityCcof a statementm
ito all other statements in the networkNis calculated. Next, in step 4, the suspicious score Sof the program statements will be calculated according to Equation (5). Rank the statementsm
1,m2,m3,…,m 12based onS 1,S2,S3,…,S 12in descending order of their suspicious score values. The developer willcheck the statements one by one from the top until the location of thefault is identiﬁed. Lastly, the localization result is shown in Table 4. Looking at the result, the faulty statement m
5is rank at the top of theranking list with the highest suspicious score.4. ExperimentationIn this section, the subject programs, data collection process, andevaluation metrics and criteria for the experimental process are high-lighted in Section 4.1. The results and discussion are also presented inSection 4.2.4.1. Experimental setup4.1.1. Subject programsFor the experiment, we utilized Siemens test suite subject programs[53] and four Unix real-life utility programs ( gzip, sed,ﬂex, and grep)[54] to evaluate the proposed technique. Generally, various studies haveutilized these subject programs for fault localization [ 9,18,19]. Siemens test suite programs are utilized because the programs contains singlefault each, while Unix real-life utility programs contains both real andseeded faults [33]. All of these subject programs are also written in Cprogramming language.Siemens test suite is composed of seven subject programs, namelyschedule, schedule2, print_tokens, print_tokens2, replace, tot_info, andtcas where each of the subject programs has more than 1000 test inputs. Forthe Unix real-life utility program, gzipprogram is utilized forﬁle compression and decompression. The program is normally utilized todecrease the size of nameﬁles. The input ofgzipprogram comprises of 13
Fig. 2.Network for a single fault program mid ( ).
Table 4Localization result of mid ( ) with single fault.
mi m1 m2 m3 m5 m6 m8 m12
Dci 1223 211Cc
i 0.316 0.428 0.545 0.6 0.461 0.333 0.4S
i 0.684 1.572 1.455 2.4 1.539 0.667 0.6Rank 5 2 4 1 3 6 7A. Zakari et al. Array 3-4 (2019) 100008
5options with a list ofﬁles as well. The program has 6573 lines of code and211 test inputs. Thesedprogram performs simple changes in an inputstream. It is basically utilized to parse textual input and also to apply aspeciﬁed user changes to the input. The program has 12,062 lines of codeand 360 test inputs.Theﬂexprogram is a lexical analyzer. It reads aﬁle and produces aC sourceﬁle called scanner. The inputﬁles contain sets of consistent expression andCcode, called rules. The program has 13,892 lines of codeand 525 test inputs. Thegrepprogram has two input parameters whicharepatternsandﬁles. The program prints lines in eachﬁle that contains a match of any of the patterns. The program has 12,653 lines of code and470 test inputs. Henceforth, the Unix real-life utility programs containboth real and seeded faults.Table 5gives a brief characteristic of each program: the number of lines of code, the number of test inputs, thenumber of faulty versions, and brief descriptions of the programs. All thesubject programs including the corresponding test inputs were down-loaded from the software infrastructure repository (SIR) ( http://sir.unl.e du/portal/index.php)[54].4.1.2. Data collectionWe executed each faulty version using all its available test inputs. Testinputs status (passed/failed) are determined by comparing tests execu-tion output for each faulty version to its corresponding original fault-freeversion. If the output of a faulty version is different from the output of itscorresponding fault-free version, the test input will be recorded as afailed test. However, if the output did not differ, the test input will berecorded as a passed test. Moreover, based on the documentation done onSiemens test suite programs and the experimental process in previousworks, it is known that Siemens test suite programs contain single fault[42,44,55,56]. Hence, we removed versions whose fault cannot berevealed by any test input because the proposed technique requires failedtests execution for fault localization.All our programs were executed on a PC with 2.13 GHz Intel Core 2Duo CPU and an 8 GB physical memory. We use GCC compiler to compilethe programs and we use Gcov to obtain the code coverage informationfor each test execution.4.1.3. Evaluation metrics and criteriaTo measure the effectiveness of a given fault localization technique,suitable metrics are essential for evaluation. In this paper, four metricsare utilized, namely the cumulative number of statements examined,Exam score, Wilcoxon signed-rank test, and Top-N.4.1.3.1. Exam Score.To access the overall effectiveness of a faultlocalization technique, a suitable metric must be used for evaluation. Thework in Ref. [18] uses a metric namedScorewhich is deﬁned as the percentage of code that need not be examined to ﬁnd a fault. However, in this paper, we will use a metric named Exam scorewhich is a variant of theScoremetric. Although these two metrics provide virtually the sameinformation,
Exam scoreis more straightforward and easy to understand.Exam scoreis deﬁned as the percentage of code that needs to be examineduntil theﬁrst statement where the fault resides is reached. Many studieshave usedExam scoreto access the effectiveness of a single fault locali-zation technique [15,18,19,46]. The metric is stated in Equation(6).Exam score¼
rank of faultnumber of executable statements/C2100%(6)Largely, for any given fault localization technique, the techniquelocalization effectiveness can be known with Exam score. Therefore, if a given technique A has a lesserExam scorethan another technique B, then technique A will be considered to be the most effective in comparison totechnique B because technique A need to examined less code to locate thefaults.4.1.3.2. Cumulative Number of Statements Examined. In addition, apart from utilizingExam score, the cumulative (or total) number of statementsthat need to be examined with respect to subject programs to locate faultsis also considered [9]. Therefore, fornfaulty versions of a given program where X(i) and Y(i) are the number of statements that need to beexamined to locate all the faults in the ithfaulty version by two fault localization techniques X and Y, respectively. Therefore, technique X ismore effective than technique Y if technique X requires a developer toexamine less amount of statements than technique Y to ﬁnd all faults in the faulty versions as shown in Equation (7).X
ni¼1XðiÞ<Xni¼1YðiÞ (7)4.1.3.3. Wilcoxon Signed-Rank Test. Wilcoxon signed-rank test is an alternative option to other existing hypothesis tests such as z-test andpaired student’s t-test particularly when a normal distribution of a givenpopulation sample cannot be assumed [ 9,57]. Wilcoxon signed-rank test is also utilized to give a comparison with a solid statistical basis betweentwo or more techniques in terms of effectiveness. Since the aim is todemonstrate that the proposed technique is more effective than thecompared techniques, after computing the total number of statementsthat a developer needs to check on all techniques, an evaluation will beconducted on the one-tailed alternative hypothesis that the other tech-niques used for cross-comparison require the examination of an equal orgreater number of statements than the proposed technique. The nullhypothesis is stated as follows:H
0. The number of statements examined by other techniques /C20the number of statements examined by the proposed technique.Therefore, if H
0is rejected, the alternative hypothesis is accepted. Thealternative hypothesis implies that the proposed technique will requirethe examination of fewer statements than the compared techniqueswhich indicates that the proposed technique is more effective.4.1.3.4. Top-N.Top-N symbolizes the percentage of faults a fault local-ization technique ranks for all faulty statements among the Top N (N ¼1, 5, 10) positions in the ranked list. Hence, the smaller the value of N inTop-N, the stricter the metric. For instance, Top-5 metric demands thatall faults are ranked within the top 5 positions in the ranked list.4.2. Result and discussionIn this section, the results and discussion are presented. The result ofTable 5Experimental subject programs.
Program Number ofFaulty versionsLines ofcode (LOC)Number oftest inputsDescriptionprint_tokens 7 565 4130 Lexical analyser print_tokens2 10 510 4115 Lexical analyser replace 32 412 2650 Pattern replacement schedule 9 307 2710 Priority scheduler schedule2 10 563 5542 Priority scheduler tcas 41 173 1608 Altitude separation tot_info 23 406 1052 Information measure sed 7 12,062 360 Textual manipulator gzip 5 6573 211 Data compression ﬂex 22 13,892 525 Lexical analyser grep 7 12,653 470 Pattern searcherA. Zakari et al. Array 3-4 (2019) 100008
6our comparison with other fault localization techniques is also high-lighted and discussed. For all our experiments in this paper, we presumedthat the best case effectiveness entails that the faulty statement is iden-tiﬁed at the top of the list of statements with the same suspiciousnessscore values, while for the worst case effectiveness, the faulty statementresides at the bottom of the list with the same suspicious score values. Inour evaluation of FLCN-S technique, the result is mostly presented be-tween these two levels of effectiveness for all the evaluation metrics(except for the result presented inFig. 4). For all our subject programs use in this experiment, each faulty version has exactly one fault.4.2.1. Effectiveness of FLCN-S on siemens test suite programsTable 6andTable 7present the cumulative (total) number of state-ments examined by FLCN-S and other techniques in both the best andworst cases. For each program, in the best case scenarios, FLCN-S re-quires the examination of fewer statements than the compared tech-niques. The same applies to the worst case scenarios. For instance, weobserved that forprint_tokensprogram, FLCN-S can locate all the faultyversions by examining no more than 251 statements in the best casescenario, and 699 in the worst case scenario, respectively. Furthermore,with respect to theprint_tokensprogram, the second best technique isOchiai, which requires the examination of no more than 324 statementsin the best case and 712 statements in the worst case scenarios.Is worth knowing that these values represent the total number ofstatements that each technique requires to examine to locate the faults ineach subject program. Looking atTables 6 and 7, we observed that irrespective of which scenario is considered (best case or worst case),FLCN-S is consistently the most effective technique. Another importantpoint worth noting is that, in some exceptional cases, Tarantula (which isthe third best technique) is more effective than Ochiai (the second besttechnique). For example, with respect to scheduleprogram, the best case of Tarantula (350) is better than the best case of Ochiai (363), the sameapplied to their worst cases as well. Nonetheless, the difference betweenthe two techniques (Ochiai and Tarantula) is not that signi ﬁcant where Ochiai is more effective than Tarantula in most cases. Henceforth, isworth re-emphasizing that FLCN-S is the most effective technique withrespect to both the best and worst case scenarios.However, without arriving at anyﬁrm conclusion, we present the evaluation of FLCN-S with respect to Exam score. The single fault versions oftcas, print_tokens,andprint_tokens2in the best and worst cases are highlighted inFig. 3. Theﬁgure shows the effectiveness of FLCN-S incomparison with four other techniques, namely Ochiai, Tarantula, Jac-card, and SNCM. Therefore, the conclusions drawn with respect to theseprograms applied to the remaining programs in the Siemens test suite.They-axis indicates the percentage of faults located in all the programfaulty versions, while thex-axis indicates the effort wasted to locate thecorresponding faults.For instance, based on part (a) and (b) of Fig. 3, we observed that on thetcasprogram, by examining less than 10% of the program code,FLCN-S can locate 85% of the faults in the best case, and 45% in the worstcase. Correspondingly, by examining the same amount of code (less than10%), Ochiai (the second best) can only locate 85% (best case) and 40%(worst case).In part (c) and (d), the effectiveness score of print_tokensis presented. We observed that, by examining less than 10% of the program code,FLCN-S can only locate 65% of the faulty versions in the best case and35% in the worst case. Ochiai (the second best) can locate 60% of thefaults in the best case, and 25% in the worst case. Moreover, the per-centage for Tarantula (the third best) is 55% (best case), and 15% (worstcase). However, looking at the curves in part (c) and (d), the two tech-niques (Jaccard and SNCM) are the least effective on print_tokensprogram
faulty versions.Furthermore, in part (e) and (f) ofFig. 3, with respect toExam score, FLCN-S performs relatively better. The curves show that by examiningless than 20% of the program code, FLCN-S can locate 55% of the faultyversions in the best case and 35% in the worst case. Ochiai (the secondbest) can only locate 50% in the best case and 25% in the worst casewhen examining the same amount of code. For Tarantula (the third best),by examining the same amount of code (less than 10%), is 45% (bestcase), and 20% (worst case), while for SNCM is 35% (best case) and 15%(worst case).Fig. 4gives the overall effectiveness score of FLCN-S and other faultlocalization techniques on Siemens test suite programs. Based on theresult, FLCN-S can locate 65% of the fault in all faulty versions of theSiemens test suite by examining less than 10% of the programs ’code. We observed that FLCN-S has yielded a drastic improvement from ourbenchmark technique (FLCN) [17] with a 25% increase in located faultyversions by checking less than 10% of the programs ’code. Furthermore, FLCN-S has also outperformed Zoltar-S approach as concluded by Abreuet al. [33] where the latter can only locate 60% of the faults by checkingless than 10% of the programs’code.Based on the third evaluation metric, Table 8andTable 9gives the effectiveness comparisons of FLCN-S with other techniques using theWilcoxon signed-rank test. The entries in the tables give the con ﬁdence of which the alternative hypothesis (which implies that FLCN-S requires theexamination of fewer statements than the compared techniques to locatefaults) can be accepted. For example, one can say with 97.88% con ﬁ- dence that FLCN-S is more effective than Ochiai on scheduleprogram in both best and worst cases. Nevertheless, for schedule2, replace,andtot_info programs, the conﬁdence to accept the alternative hypothesis is higherTable 6Cumulative number of statements examined to locate faults for each program in Siemens test suite (best case).
tcas print_tokens print_tokens2 schedule schedule2 replace tot_infoFLCN-S 195 251 408 311 499 340 200Ochiai 205 324 423 363 550 370 270Tarantula 243 391 443 350 555 381 299Jaccard 259 404 451 388 561 401 304SNCM 508 490 501 423 603 463 399
Table 7Cumulative number of statements examined to locate faults for each program in Siemens test suite (worst case).
tcas print_tokens print_tokens2 schedule schedule2 replace tot_infoFLCN-S 388 699 600 655 583 455 350Ochiai 408 712 653 702 627 500 420Tarantula 483 750 699 701 650 603 550Jaccard 500 799 708 750 641 513 608SNCM 812 825 800 801 713 670 800A. Zakari et al. Array 3-4 (2019) 100008
7than 96% in all scenarios (best&worst cases).Few scenarios have conﬁdence level that is lesser than 95%, forinstance, FLCN-S being more effective than Ochiai with 90.00% con ﬁ- dence for the best case oftcas, 93.33% conﬁdence being better than Ochiai for the best case ofprint_tokens2, and with 92.31% conﬁdence being better than Ochiai for the worst case of print_tokens. In summary,the results from the Wilcoxon signed-rank test clearly shows that FLCN-Sis more effective than the compared techniques on Siemens test suitesubject programs. The result is also in line with our former conclusionthat FLCN-S performs better than the compared techniques in terms ofthe cumulative number of statements that need to be examined to ﬁnd all the faults and theExam score.
Fig. 3.Exam score-based comparison between FLCN-S and other techniques. (a and b) best case and worst case on tcas, (c and d) best case and worst case onprint_tokens, (e and f) best and worst case on print_tokens2.A. Zakari et al. Array 3-4 (2019) 100008
84.2.2. Effectiveness of FLCN-S on unix real-life utility programsTable 10gives the total number of statements examined by FLCN-Sand Ochiai across four programs ( gzip, sed, grep,andﬂex) to locate all faults in the programs faulty versions. Each faulty version underconsideration has exactly one fault for this experiment. From Table 10, we observed that in all scenarios (best and worst cases), FLCN-S is alwaysthe most effective in comparison with Ochiai. In some cases, often theworst case of FLCN-S is better than the best case of Ochiai. For instance,with respect togrepprogram, the worst case of FLCN-S (2592) is stillbetter than the best case of Ochiai (3092).Next, we give the evaluation of FLCN-S with respect to Exam score.I n Fig. 5, the best and worst case ofgzipandsedprograms were presented. However, the conclusions drawn on these two programs are also appli-cable to the remaining two programs (ﬂexandgrep). Theﬁgure shows the effectiveness on FLCN-S in comparison with Ochiai similarity coef ﬁcient- based technique. The black curve represents FLCN-S technique and thered curve represents Ochiai similarity coef ﬁcient-based technique. Looking at part (a) and (b) ofFig. 5,w eﬁnd out that ongzipprogram, by examining less than 30% of the program code, FLCN-S can locate 99% ofthe faulty versions in the best case and 55% in the worst case. In contrast,by examining the same amount of program code, Ochiai can only locate85% of faults in the best case and 50% in the worst case.In part (c) and (d), the effectiveness score of sedprogram is presented. The curves show that by examining less than 20% of the program code,FLCN-S can locate 65% of faults in the best case and 40% in the worstcase, respectively. Correspondingly, by examining the same amount ofprogram code, Ochiai can locate 55% (best case) and 15% (worst case).The conclusion drawn fromFig. 5with respect toExam scoreof both techniques (FLCN-S and Ochiai) is that FLCN-S performs better thanOchiai. This result is consistent with the observations from Table 10that FLCN-S is the most effective technique. Looking at our third evaluationmetric,Table 11highlights data comparing FLCN-S with Ochiai usingWilcoxon signed-rank test. The table highlights the con ﬁdence to which the alternative hypothesis can be accepted. For instance, one can say with99.88% (best case) and 99.82% (worst case) that FLCN-S is more effec-tive than Ochiai on thesedprogram.Generally, forgzip, sed, grep,andﬂexprograms, the conﬁdence to accept the alternative hypothesis is higher than 99%. In total, the resultsfrom this test (Wilcoxon signed-rank test) show that FLCN-S is moreeffective than Ochiai similarity coefﬁcient-based technique which is consistent with our former results using Exam scoreand the cumulative (total) number of statements examined metrics.Table 12gives results comparing FLCN-S with Ochiai in terms of Top-N. From the table, the percentage of faults that can be successfullylocated at Top-1, Top-5, and Top-10 by FLCN-S on gzipprogram is 25.92%, 35.62%, and 51.01%. On the other hand, Ochiai is 19.58%,29.15%, and 44.27%, respectively. Looking at the table ( Table 12), FLCN-S is more effective than Ochiai similarity coef ﬁcient-based tech- nique in all scenarios.4.2.3. Centrality measuresIn our earlier work, we studied the impact of degree centrality andhow statements degree relates to faults. We concluded that statementdegree is vital in identifying faulty program statements, especially in amultiple-fault context. In this paper, we observed that on Siemens testsuite programs, 23% of all faulty statements have degree centrality of 3while 77% have a degree centrality of 2. Hence, we found out that in thesingle-fault context, closeness centrality plays a vital role in ranking andidentifying program statements. Moreover, on both Siemens test suiteand Unix real-life utility programs, both degree centrality and closenesscentrality play a critical and vital role in the identi ﬁcation of faulty program statements.
Fig. 4.Overall Effectiveness Comparison on Siemens test suite.
Table 8The conﬁdence with which it can be claimed that FLCN-S is more effective than other techniques on Siemens test suite programs (best case).
tcas print_tokens print_tokens2 schedule schedule2 replace tot_infoOchiai 90.00% 98.64% 93.33% 97.88% 98.04% 96.67% 98.58%Tarantula 97.92% 99.29% 97.15% 97.44% 98.22% 97.57% 98.99%Jaccard 98.44% 99.35% 97.68% 98.71% 98.39% 98.37% 99.04%SNCM 99.69% 99.59% 98.93% 99.11% 99.04% 99.19% 99.50%
Table 9The conﬁdence with which it can be claimed that FLCN-S is more effective than other techniques on Siemens test suite programs (worst case).
tcas print_tokens print_tokens2 schedule schedule2 replace tot_infoOchiai 95.00% 92.31% 98.08% 97.88% 97.73% 97.78% 98.58%Tarantula 98.95% 98.04% 98.99% 97.83% 98.51% 99.33% 99.50%Jaccard 99.11% 99.00% 99.08% 98.95% 98.28% 98.28% 99.62%SNCM 99.77% 99.21% 99.50% 99.32% 99.24% 99.54% 99.78%Table 10Cumulative number of statements examined by FLCN-S and Ochiai (best &worst cases).
Best Case Worst CaseFLCN-S Best Ochiai Best FLCN-S Worst Ochiai Worstgzip 1944 2692 2770 3992sed 3201 3885 4100 4652grep 1102 3092 2592 4825ﬂex 924 1141 1672 1853A. Zakari et al. Array 3-4 (2019) 100008
9InFig. 6, we observe that most of the faults are located on programstatement with degree centrality of 2. However, a signi ﬁcant amount of faults were located on programs with a degree centrality of 3 and 4.Degree centrality is a single factor when localizing faults using ourtechnique with closeness centrality playing a critical role in the faultlocalization process. From part (h)Fig. 6(gzip), we can see that there are a little number of faults that is located on program statements with de-gree centrality of 4. Hence, almost 80% of all the faults are located onstatements with the degree centrality of 2. This analysis is aimed atconﬁrming the claims of previous studies in various research domainswhere researchers indicate the important role degree centrality plays inthe identiﬁcation of the most inﬂuential and faulty nodes in a network[46,58–61].4.2.4. Overall observationsGenerally, the effectiveness of a given technique is not always con-stant and can change depending on the subject program used. Weobserved that by utilizing failed test inputs alone, the effectiveness of theproposed fault localization technique (FLCN-S) has increased on single-fault programs. In our initial work, we utilized both test inputs(passed/failed) to localize single faults, the accuracy was not convincing,where we achieved 40%Exam scoreby checking less than 10% of the program faulty versions on Siemens test suite programs. This is mainly
Fig. 5.Exam score-based comparison between FLCN-S and Ochiai similarity coef ﬁcient-based technique. (a and b) best case and worst case on gzip, (c and d) best case and worst case on sed.
Table 11The conﬁdence with which it can be claimed that FLCN-S is more effective thanOchiai (best&worst cases).
Ochiai Best Ochiai Worstgzip 99.87% 99.92%sed 99.86% 99.82%grep 99.95% 99.96%ﬂex 99.54% 99.45%
Table 12Percentage of faults successfully located at each Top-N metric by FLCN-S andOchiai.
Programs Techniques Top-1 Top-5 Top-10gzip FLCN-S 25.92% 35.62% 51.01%Ochiai 19.58% 29.15% 44.27%sed FLCN-S 34.78% 41.01% 49.00%Ochiai 20.09% 32.82% 40.67%ﬂex FLCN-S 39.46% 48.01% 58.44%Ochiai 20.08% 29.11% 39.12%A. Zakari et al. Array 3-4 (2019) 100008
10Fig. 6.Degree centrality correlation with failure for Siemens suite programs and two Unix real-life utility programs. (a) schedule, (b) schedule2, (c) pri nt_tokens, (d) print_tokens2, (e) tcas, (f) replace, (g) tot_info, (h) gzip, and (i) sed.A. Zakari et al. Array 3-4 (2019) 100008
11due to the high sensitivity of the technique (FLCN) with program state-ments executed by passed test inputs. Therefore, we concluded that byutilizing failed test inputs alone, the accuracy of our proposed technique(FLCN-S) increases in the context of single fault due to the minimal fault-to-failure complexity that affects localization on multiple-fault programs.Our technique can effectively localize 65% of all faulty versions onSiemens test suite subjects by checking less than 10% of the programcode and is largely more effective on Unix real-life utility program incomparison with other techniques in both best and worst case scenarios.Finally, we also observed that both degree centrality and closeness cen-trality plays a vital role in the identiﬁcation of faulty program statements.5. ConclusionIn this paper, we presented an automated debugging technique,coined FLCN-S to improve localization effectiveness in a single-faultcontext. The proposed technique is a variant inspired by our previouswork [17] which uses both passed and failed tests executions. Our pre-vious technique has proven to be less effective on single-fault subjectprograms where both test inputs (passed/failed) are taken into account.In contrast, FLCN-S diagnoses and rank program statements based ontheir behavioral anomalies and distance between statements in failed testinputs.The proposed technique is evaluated on a well-known standardbenchmark (Siemens test suite) and four Unix real-life utility programs(gzip, sed,ﬂex,andgrep). We compared our technique with four faultlocalization techniques, namely Ochiai, Tarantula, Jaccard, and SNCM.Overall, the results show a signiﬁcant improvement on the single-faultsubjects where 65% of all the faulty versions can be localized bychecking less than 10% of the program code on Siemens test suite pro-grams and is largely more effective on Unix real-life utility program incomparison with other techniques in both best and worst case scenarios.Furthermore, we observed that both degree centrality and closenesscentrality play a vital role in the identiﬁcation of faults. For future work, we will like to explore other centrality measures forfault localization. And we plan to further explore the effectiveness of ourtechnique on larger datasets to further substantiate our claims. Moreover,the proposed fault localization technique (FLCN-S) is considerably moreeffective in localizing faults in a single-fault context in comparison withour previous work and other techniques compared with.Declaration of Competing InterestThe authors declare no conﬂict of interest.References
[1]Debroy V, Wong WE. Combining mutation and fault localization for automatedprogram debugging. J Syst Softw 2014;90:45 –60. [2]Myers GJ, Sandler C, Badgett T. The art of software testing. John Wiley &Sons; 2011.[3]Cleve H, Zeller A. Locating causes of program failures. In: Software engineering,2005. ICSE 2005. Proceedings. 27th international conference on. IEEE; 2005 . [4]Gao R, Wong WE. MSeer-an advanced technique for locating multiple bugs inparallel. IEEE Trans Softw Eng 2017;45(3):301 –18. [5]Zakari A, et al. software fault localization: a systematic mapping study. IETSoftware; 2018.[6]Fitzgerald S, et al. Debugging from the student perspective. IEEE Trans Educ 2010;53(3):390–6.[7]Zhang M, et al. Boosting spectrum-based fault localization using PageRank. In:Proceedings of the 26th ACM SIGSOFT international symposium on software testingand analysis. ACM; 2017. [8]Tang CM, et al. Accuracy graphs of spectrum-based fault localization formulas. IEEETrans Reliab 2017;66(2):403–24. [9]Wong WE, et al. The DStar method for effective software fault localization. IEEETrans Reliab 2014;63(1):290–308. [10]Namin AS. Statistical fault localization based on importance sampling. In: Machinelearning and applications (ICMLA), 2015 IEEE 14th international conference on.IEEE; 2015.[11]Parsa S, Vahidi-Asl M, Asadi-Aghbolaghi M. Hierarchy-Debug: a scalable statisticaltechnique for fault localization. Softw Qual J 2014;22(3):427 –66.[12]Wotawa F, Nica M, Moraru I. Automated debugging based on a constraint model ofthe program and a test case. J Log Algebr Program 2012;81(4):390 –407. [13]Zheng W, Hu DS, Wang J. fault localization analysis based on Deep neural network.Math Probl Eng 2016;2016:1820454. 2016 . [14]Wong WE, et al. Effective software fault localization using an RBF neural network.IEEE Trans Reliab 2012;61(1):149 –69. [15]Abreu R, Zoeteweij P. An evaluation of similarity coef ﬁcients for software fault localization. In: 2006 12th paciﬁc rim international symposium on dependable computing (PRDC’06). IEEE; 2006. [16]Chen MY, et al. Pinpoint: problem determination in large, dynamic internetservices. In: Dependable systems and networks, 2002. DSN 2002. Proceedings.International conference on. IEEE; 2002 . [17]Zakari A, Lee SP, Chong CY. Simultaneous localization of software faults based oncomplex network theory. IEEE Access; 2018 . [18]Jones JA, Harrold MJ. Empirical evaluation of the tarantula automatic fault-localization technique. In: 20th IEEE/ACM international conference on automatedsoftware engineering, ASE 2005; 2005 . [19]Abreu R, Zoeteweij P, Van Gemund AJ. On the accuracy of spectrum-based faultlocalization. In: Testing: academic and industrial conference practice and researchtechniques-MUTATION, 2007. IEEE; 2007. TAICPART-MUTATION 2007 . [20]DiGiuseppe N, Jones JA. Fault density, fault types, and spectra-based faultlocalization. Empir Softw Eng 2015;20(4):928 –67. [21]Zakari A, Lee SP, Hashem IAT. A community-based fault isolation approach foreffective simultaneous localization of faults. IEEE Access 2019;7:50012 –30. [22]Zakari A, Lee SP. Simultaneous isolation of software faults for effective faultlocalization. In: 2019 IEEE 15th international colloquium on signal processing &its applications (CSPA). IEEE; 2019 . [23]Zakari A, Lee SP. Parallel debugging: an investigative study. J Softw: Evolution andProcess 2019:e2178.[24]Wong WE, et al. A survey on software fault localization. IEEE Trans Softw Eng 2016;42(8):707–40.[25]Agrawal H, De Millo RA, Spafford EH. An execution-backtracking approach todebugging. IEEE Software 1991;8(3):21 –6. [26]Korel B. PELAS-program error-locating assistant system. IEEE Trans Softw Eng1988;14(9):1253–60.[27]Korel B, Laski J. STAD-A system for testing and debugging: user perspective. In:Software testing, veriﬁcation, and analysis, 1988., proceedings of the secondworkshop on. IEEE; 1988. [28]Agrawal H, et al. Fault localization using execution slices and data ﬂow tests. In: Software reliability engineering, 1995. Proceedings., sixth international symposiumon. IEEE; 1995.[29]Wong E, et al. A crosstab-based statistical method for effective fault localization. In:Software testing, veriﬁcation, and validation, 2008 1st international conference on.IEEE; 2008.[30]Neelofar N, et al. Improving spectral-based fault localization using static analysis.Software: Practice and Experience; 2017 . [31]Renieres M, Reiss SP. Fault localization with nearest neighbor queries. In:Automated software engineering, 2003. Proceedings. 18th IEEE internationalconference on. IEEE; 2003. [32]Abreu R, Zoeteweij P, van Gemund AJ. Localizing software faults simultaneously.In: 2009 ninth international conference on quality software. IEEE; 2009 . [33]Abreu R, Zoeteweij P, Van Gemund AJ. Simultaneous debugging of software faults.J Syst Softw 2011;84(4):573–86. [34]Wong WE, Qi Y. BP neural network-based effective fault localization. Int J SoftwEng Knowl Eng 2009;19(4):573 –97. [35]Naish L, Lee HJ, Ramamohanarao K. A model for spectra-based software diagnosis.ACM Trans Software Eng Methodol 2011;20(3):11 . [36]Shu T, et al. Fault localization based on statement frequency. Inf Sci 2016;360:43 –56. [37]Le T-DB, Thung F, Lo D. Theory and practice, do they match? a case with spectrum-
based fault localization. In: Software maintenance (ICSM), 2013 29th IEEEinternational conference on. IEEE; 2013 . [38]Yoo S, et al. No pot of gold at the end of program spectrum rainbow: greatest riskevaluation formula does not exist. RN 2014;14(14):14 . [39]de Souza HA, et al. Contextualizing spectrum-based fault localization. Inf SoftwTechnol 2018;94:245–61. [40]Kim J, Kim J, Lee E. A novel variable-centric fault localization technique. In:Proceedings of the 40th international conference on software engineering:companion proceeedings. ACM; 2018 . [41]Landsberg D, Sun Y, Kroening D. Optimising spectrum based fault localisation forsingle fault programs using speciﬁcations. In: International conference on fundamental approaches to software engineering. Springer; 2018 . [42]Wang X, Liu Y. Fault localization using disparities of dynamic invariants. J SystSoftw 2016;122:144–54. [43]Liu C, et al. Statistical debugging: a hypothesis testing-based approach. IEEE TransSoftw Eng 2006;32(10):831–48. [44]Liblit B, et al. Scalable statistical bug isolation. ACM SIGPLAN Not 2005;40(6):15–26.[45]You Z, Qin Z, Zheng Z. Statistical fault localization using execution sequence. In:Machine learning and cybernetics (ICMLC), 2012 international conference on. IEEE;2012.[46]Zhu L-Z, Yin B-B, Cai K-Y. Software fault localization based on centrality measures.In: Computer software and applications conference workshops (COMPSACW), 2011IEEE 35th annual. IEEE; 2011 . [47]Xiaobo Y, Bin L, Jianxing L. The failure behaviors of multi-faults programs: anempirical study. In: Software quality, reliability and security companion (QRS-C),2017 IEEE international conference on. IEEE; 2017 .A. Zakari et al. Array 3-4 (2019) 100008
12[48]Sun X, et al. IPSETFUL: an iterative process of selecting test cases for effective faultlocalization by exploring concept lattice of program spectra. Front Comput Sci2016;10(5):812–31.[49]Liu B, et al. Localizing multiple faults in simulink models. In: Software analysis,evolution, and reengineering (SANER), 2016 IEEE 23rd international conferenceon. IEEE; 2016.[50]Naish L, Ramamohanarao K. Multiple bug spectral fault localization using geneticprogramming. In: Software engineering conference (ASWEC), 2015 24thaustralasian. IEEE; 2015. [51]Opsahl T, Panzarasa P. Clustering in weighted networks. Soc Netw 2009;31(2):155–63.[52]/C20Subelj L, Bajec M. Software systems through complex networks science: review,analysis and applications. In: Proceedings of the ﬁrst international workshop on software mining. ACM; 2012. [53]Hutchins M, et al. Experiments of the effectiveness of data ﬂow-and controlﬂow- based test adequacy criteria. In: Proceedings of the 16th international conference onSoftware engineering. IEEE Computer Society Press; 1994 .[54]Do H, Elbaum S, Rothermel G. Supporting controlled experimentation with testingtechniques: an infrastructure and its potential impact. Empir Softw Eng 2005;10(4):405–35.[55]Zhang Z, et al. Fault localization through evaluation sequences. J Syst Softw 2010;83(2):174–87.[56]Zhang Z, Chan WK, Tse T. Fault localization based only on failed runs. Computer2012;45(6):64–71.[57]Ott RL, Longnecker MT. An introduction to statistical methods and data analysis.Nelson Education; 2015. [58]Girvan M, Newman ME. Community structure in social and biological networks.Proc Natl Acad Sci 2002;99(12):7821 –6. [59]Borgatti SP. Centrality and network ﬂow. Soc Netw 2005;27(1):55–71. [60]Li D, Han Y, Hu J. Complex network thinking in software engineering. In: Computerscience and software engineering, 2008 international conference on. IEEE; 2008 . [61]Cai K-Y, Yin B-B. Software execution processes as an evolving complex network. InfSci 2009;179(12):1903–28.A. Zakari et al. Array 3-4 (2019) 100008
13