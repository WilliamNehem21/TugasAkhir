Disease detection, severity prediction, and crop loss estimationin MaizeCrop using deep learning
Nidhi Kundua, Geeta Rania,⁎, Vijaypal Singh Dhakaa,K a l p i tG u p t aa, Siddaiah Chandra Nayakab, Eugenio Vocaturo
c,d, Ester Zumpanoc,d
aDepartment of Computer and Communication Engineering, Manipal University Jaipur, Jaipur, India.
bICAR DOS in Biotechnology,University of Mysore Manasagangotri, Mysore 570005, India
cDIMES (Department of Computer Engineering, Modeling, Electronics and Systems), University of Calabria, Italy
dNanotec, Italian National Research Council, 87036 Rende, CS, Italy
abstract article info
Article history:Received 26 July 2022Received in revised form 13 November 2022Accepted 13 November 2022Available online 17 November 2022The increasing gap between the demand and productivity of maize crop is a point of concern for the food indus-try, and farmers. Its' susceptibility to diseases such as Turcicum Leaf Blight, and Rust is a major cause for reducingits production. Manual detection, and classi ﬁcation of these diseases, calculation of disease severity, and crop loss estimation is a time-consuming task. Also, it requires expertise in disease detection. Thus, there is a need to ﬁnd an alternative for automatic disease detection, severity prediction, and crop loss estimation. The promising re-sults of machine learning, and deep learning algorithms in pattern recognition, object detection, and data analysismotivate researchers to employ these techniques for disease detection, classi ﬁcation, and crop loss estimation in maize crop. The research works available in literature, have proven their potential in automatic disease detectionusing machine learning, and deep learning models. But, there is a lack none of these works a reliable and real-lifelabelled dataset for training these models. Also, none of the existing works focus on severity prediction, and croploss estimation. The authors in this manuscript collect the real-life dataset labelled by plant pathologists. Theypropose a deep learning-based framework for pre-processing of dataset, automatic disease detection, severityprediction, and crop loss estimation. It uses the K-Means clustering algorithm for extracting the region of interest.Next, they employ the customized deep learning model ‘MaizeNet’for disease detection, severity prediction, and crop loss estimation. The model reports the highest accuracy of 98.50%. Also, the authors perform the feature vi-sualization using the Grad-CAM. Now, the proposed model is integrated with a web application to provide a user-friendly interface. The efﬁcacy of the model in extracting the relevant features, a smaller number of parameters,low training time, high accuracy favors its importance as an assisting tool for plant pathology experts.The copy-right for the associated web application ‘Maize-Disease-Detector ’isﬁled with diary number: 17006/2021-CO/ SW.© 2022 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Disease detectionCrop lossSeverityDeep learningMaize
1. IntroductionDifferent varieties of maize crop such as corn, sweet corn, popcornand baby corn are source of human and poultry feed ( Modi, 2014). Maize is a preferred energy cereal, therefore approximately 47% of themaize yield in India is used as poultry feed ( Panda et al., 2013), 13% aslivestock feed and 12% to meet the human food demand. Further, 12%of the maize yield is used for industrial purposes. Maize is helpful in im-proving the digestive health and reducing the risk of chronic diseasessuch as cardiovascular disease, diabetes and obesity ( Sheng et al., 2018). Thus, its' demand is increasing among the populace.To meet the demands, nearly 1147.7 million Metric Tons (MT) ofmaize is produced across 170 countries on an area of 193.7 million ha.Its average productivity across the globe is reported as 5.75 t/ha. But,the productivity in India is reported as 3070 kg/ha, which is muchlower than the global average productivity of 5920 kg/ha ( Alla Singh et al., 2019). The water, and nutrient requirements of maize is 80 –90% lesser than widely grown crops such as rice, and wheat ( Timsina et al., 2010). This reduces its cost of production. The low cost of production,capacity to adapt in a wide range of environment conditions, andArtiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
⁎Corresponding author.E-mail addresses:kundu.nidhi1990@gmail.com(N. Kundu), geetachhikara@gmail.com(G. Rani),vijaypalsingh.dhaka@jaipur.manipal.edu (V.S. Dhaka),kalpitgupta369@gmail.com(K. Gupta),moonnayak@gmail.com (S.C. Nayaka),e.vocaturo@dimes.unical.it(E. Vocaturo),e.zumpano@dimes.unical.it (E. Zumpano).
https://doi.org/10.1016/j.aiia.2022.11.0022589-7217/© 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/myriad uses make the maize a prime driver of the global agriculturaleconomy.The diseases, such as Turcicum Leaf Blight (TLB) or Northern CornLeaf Blight (NCLB), Polysora rust, Charcoal rot, Common rust and Sor-ghum downy mildew, cause a huge loss in the productivity of maizecrop (Smith, 1988;Taylor et al., 2008). Therefore, it has become an ur- gent requirement to detect these diseases at an early stage. Also, thereis a strong need to predict the crop loss due to these diseases. The man-ual disease detection by plant pathologists based on the visual symp-toms is not effective before onset of symptoms. Further, there is arequirement of laboratory tests for crop sample analysis and calculationof disease severity. The manual disease detection and laboratory testsare expensive and time-consuming. Also, these methods are less effec-tive in early disease prediction, disease severity prediction, and croploss estimation. This has raised the demand for automating the diseasedetection, severity prediction, and crop loss estimation.The potential of Deep Learning (DL) and Machine learning (ML)techniques in healthcare (Cao et al., 2020;Pradhan et al., 2020;Bedi and Gole, 2021;Kundu et al., 2021), image processing (Wang et al., 2019;Singh et al., 2020;Kundu et al., 2021), data analysis (Agarwal et al., 2020;Rani and Agarwal, 2020), pattern recognition (Hijazi et al., 2015), behavior analysis (Luque et al., 2020), and object detection (Chen et al., 2017;Lee et al., 2020;Oza et al., 2021) etc. motivated us to employ these techniques for early disease prediction, disease severitydetection, and crop loss estimation in maize crop.In this research, we develop a DL based framework “Early Maize Dis- ease Detector and Evaluator ”(EMDDE) for early prediction of TLB, Rust,and multiple diseases in the same plant of maize crop. Here, multiplediseases labelled as‘multidisease’represents the occurrence of bothTLB, and Rust on the same leaf of the plant. We focus on causing agentsof diseases, symptoms in terms of leaf colour and shape of infected re-gions, stage of infection and favorable conditions for occurrence ofthese diseases as shown inTable 1.The proposed architecture has potential to accurately classify thehealthy and maize plants infected with TLB, Rust and multiple diseases.It also has competence to detect the severity of identi ﬁed disease. Fur- ther, it is effective in assessing the number of infected plants and areaof infection in the diseased plants present in a farmland. Based on thisassessment, we can predict the severity of TLB and Rust ( Bock et al., 2010) on a 1 to 9 normalized scale designed by pathology scientists ofICAR Ludhiana (Hooda et al., 2018). In this scale, (0) denotes the lowestdegree of severity, whereas (9) indicates the highest severity of disease.The crop loss of 100% is assumed if a plant is infected with multiple dis-eases. The efﬁcacy of the proposed architecture is validated by the plantpathologists from ICAR-Mysore involved in this research. They manu-ally visualized the segmented region of interest, diseased area calcu-lated, and severity predicted on the rating scale. Based on the results,they validated the performance of the model. The overview of the pro-posed approach is shown inFig. 1, and its' key contributions are listedbelow.
•Collection of maize crop dataset in close supervision of the maizepathologist.•Developing the novel deep learning architecture for disease predic-tion.•Minimizing training time for the devised deep learning model.•Calculating the Diseased Leaf Area of the infected plants•Predicting disease severity using a normalized scale.•Developing an intelligent system for disease prediction and crop lossestimation.2. Related worksThe study of literature related to segmentation, disease recognition,classiﬁcation, severity prediction, and crop loss estimation is presentedin this section.Segmentation is theﬁrst step for disease detection. It is importantto segment the Region of Interest (ROI) from the input images. Theauthors (Ma et al., 2009) reviewed various segmentation techniquesbased on threshold, pattern recognition and on deformable models.In these techniques, threshold is either decided manually or auto-matically based on edge, region, and hybrid one. The authors claimedthat the Laplacian and canny edge detection techniques are mostwidely used for image segmentation ( Al-amri, et al, 2010). The Laplacian technique is used toﬁnd the dark and light side of anedge, whereas canny is used to isolate noise before edges, and deter-mine critical values for threshold.The authors (Khan et al., 2019) applied the strong correlation-basedmethod for segmentation of apple leaves. They optimized the results byfusion of Expectation Maximization (EM) technique. But this method issuitable only for the segmentation of small spots of infection. Thus, itleaves a scope for improvement. A team of researchers ( Usha Kumari et al., 2019) employed K-means algorithm and improved the correct-ness of segmentation. But, they could not enhance the accuracy of clas-siﬁcation.Next, the authors (Dechant et al., 2017) demonstrated a DL based system for identiﬁcation of maize plants infected with northern leafblight. For the experiments, they used a dataset comprising 1796maize images (nlb_annotated_public_2016_Maize dataset , 2016). They trained three Convolutional Neural Network (CNN) models on collecteddataset, classiﬁed them into diseased and non-diseased categories, andgenerated heat maps. Their model achieved the accuracy of 97.8%. Butits large memory requirement is a hinderance in its real-life use.For extending the real-life applicability of disease detection, the au-thors (Mishra et al., 2020)u s e dm o b i l eo rd r o n ec a m e r at oc a p t u r ethe images and forwarded to Raspberry pi 3b + module. They de-ployed the Intel Movidius Neural Compute Stick (NCSDK) over Rasp-berry pi. Then, they applied a pretrained deep CNN model to detectthe disease and reported the average accuracy of 98.40%. Followingthe similar line of research, the authors ( Chen et al., 2020)p r e s e n t e d a lightweight network for recognizing eight types of diseases inmaize crop. They developed a Mobile-DANet based on the DenseNetmodel (Huang et al., 2017) to minimize the memory requirements.Their model achieved the average accuracy of 98.50%, and 95.86% re-spectively. But the network is inefﬁcient in classiﬁcation of images with complex background.To address the issue of complex background, the authors ( Lv et al., 2020) proposed a DL based novel network for maize feature enhance-ment under complex environment. Its feature enhancement capacityremoves the noise from the images using Retinex and wavelet-basedmethod. They developed a DMS-Robust AlexNet model (
Krizhevsky,
Table 1Indicative parameters of Maize Leaf Diseases.Name ofdiseaseCausing agent Leaf Colour Shape of infected region Stage of infectionFavorable conditionsTLB orNCLBExserohilumturcicum •Initial stage: Gray-green.•Later stage: Tan-brown. •Early stage: Oval.•Severe stage: Cigar--shaped.Tasseling Humid weather and moderate temperature of approximately 8°C to 27 °C.Heavy dew and rainfall with temperature of 18 °C to 27 °C. RustPuccinia sorghiDark reddish-brown elongatedpustules. Oval to elongated. AftertasselingCold temperature of approximately 16 °C to 23° C,highhumidity.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
2772010) that reported the highest accuracy of 98.62%. Although, thismethod eliminates the need to select the speci ﬁc features, it is time con- suming process to train the model with such enhancement. The authors(Agarwal and Sharma, 2021) followed the research carried out by ( Chen et al., 2020) and proposed a system to identify nine classes of maize dis-eases. They focused on removal of background noise using EnhancedCNN model. Their model gave the accuracy of 95.69% on the plantvillagedataset (PlantVillage dataset, 2018). Similarly, the authors (Zhang et al., 2018) proposed the improved CNN models for identi ﬁcation of eight types of diseases in maize crop. They employed modi ﬁed GoogleNet and Cifar10 models, and achieved the accuracy of 98.9%, and 98.8% re-spectively. Further, a group of researchers ( Sun et al., 2020) observed that classiﬁcation accuracy degrades when DL based classi ﬁcation models are applied on images captured in high light intensity. To re-solve this challenge, they employed an improved Retinex algorithmand gave an accuracy of 91.83% for detection of NCLB disease in maizecrop. To further improve the classiﬁcation accuracy on a real-life dataset, the authors (Haque et al., 2022)proposed a DL-based approach for disease detection. They used digital images of maize crop capturedfrom land of Indian Council of Agricultural Research-All India Coordi-nated Research Project (ICAR (AICRP-Mysore center)), Ludhiana. Theyreduced the noise of dataset using brightness enhancement techniques.They reported the accuracy of 95.99% using Inception-v3 model. But theincrease in training parameters increased the computation time.The researchers (Ramamurthy, 2019) worked in another dimension of disease detection. They developed an IoT and DL-based system forsensing the environmental parameters such as temperature, humidity,soil moisture, and pH for the rice crop. Based on the collected parame-ters, and images of crop plants, they predicted the crop disease and no-tiﬁed the farmers. Their tool may prove useful in reducing the crop lossand improving the crop yield. The crop loss is directly determined by theseverity of disease. Thus, the authors ( Bock et al., 2010) discussed hyperspectral imaging and image analysis techniques for calculatingdisease severity in plants. They claimed that hyperspectral way is ex-pensive due to need of a large amount of data and storage space. Theyalso highlighted that severity assessment can be less time intensive ifit is automated using DL and ML techniques. To work in the same lineof research, the authors (Prabhakar et al., 2020) applied ResNet101 model on plantvillage dataset and classiﬁed it into mild, moderate and severe classes. The model gave an accuracy of 94.60%. Another team ofresearchers (Wang et al., 2017) measured the severity of diseases inapple leaves using pretrained DL models viz. VGG-16, VGG-19(Simonyan and Zisserman, 2015), Inception-v3 (Szegedy et al., 2016), and ResNet50 (He et al., 2016). They claimed that the VGG-16 modeloutperformed other models with the accuracy of 90.4%.It is evident from the above discussion that several researchers fo-cused on segmentation and crop disease identi ﬁcation using deep CNN. But a few of them worked on maize crop for automatic severitymeasurement and crop loss estimation. Moreover, none of the above-mentioned approaches provide a complete system for data collection,data pre-processing, disease identiﬁcation, severity prediction, diseasedarea visualization, and crop loss estimation in maize crop. Also, themodels proposed in literature have low accuracy, large number of train-able parameters, high computation cost, and long training time. More-
over, there is a lack of visualization of features involved in diseaseprediction. These challenges refrain the use of these models for real-life predictions. Thus, none of the existing models have been evaluatedon real-life datasets. Toﬁll the above identiﬁed gaps, the authors in this manuscript propose a novel framework integrated with a web applica-tion for collecting the dataset, labelling and validation of dataset by theplant pathology experts, segmentation of diseased area, classi ﬁcation of dataset into healthy, TLB, Rust, and multiple disease classes. The frame-work includes a mechanism for severity prediction, and crop loss esti-mation. Further, it employs GradCam for visualizing the infectedregions involved in decision making.3. Material and methodsIn this section, we describe the detailed architecture and working ofthe proposed framework Early Maize Disease Detector and Evaluator(EMDDE). The architecture of EMDDE is shown in Fig. 2. The framework is involved in image acquisition, pre-processing, classi ﬁcation, and crop loss assessment. The details of these activities are discussedsubsequently.3.1. Dataset acquisitionIn the farmland of Indian Council of Agricultural Research- All IndiaCoordinated Research Project (ICAR (AICRP- Mysore center)), themaize crop infected with TLB, and Rust was grown purposefully by theplant pathology scientists involved in this research. Next, the leaf im-ages of the plants infected with TLB, Rust and multidisease were
Fig. 1.Overview of proposed approach.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
278captured in close supervision of the plant pathology expert. Based onthe visible symptoms shown inTable 1, the experts identiﬁed the dis- eased plants of maize. Further, the dataset comprising 2996 imageswas prepared. The sample images of the dataset are shown in Fig. 3. Next, the collected dataset has been split into training and testingdatasets on the basis of trial and error mechanism as discussed in ( Xu and Goodacre, 2018). To prevent the problem of data leakage, the im-ages of different classes namely Healthy, TLB, Rust, and Multidiseasewere distributed in such a way that one image is a part of either training,or test dataset. Also, it is ensured that multiple copies of the same im-ages are not a part of training, and test datasets. The training dataset isused only to train the model while the test dataset is used to evaluateand compare the performance of different model architectures.Now, the authors of this manuscript experimented with the trainingand testing datasets in the ratios 70:30, 75:25 and 80:20, respectively.They observed that the model performed the minimum misclassi ﬁca- tions when 80% of the total dataset was used for training and 20% fortesting. Thus, they considered 80% dataset comprising 2460 images,for training the model and 20% dataset comprising 536 images for test-ing. The number of images in each class are shown in Table 2.3.2. Dataset preparationThe leaf images were captured in the high intensity of bright sun-light. Therefore, these images have noisy background, which may affectthe performance of the model. We also observed that these leaf imagesvary in the Region of Interest (ROI) comprising leaf and the backgroundregion. The pixel values for the leaf and background regions of an imageare different. In a coloured image, the pixel value is zero for a black pixel,255 for a white pixel, and between 0 and 255 for any colour other thanblack and white. These pixels can be easily grouped together based onsimilarities in their values. To divide an image into its foreground andbackground, the authors employed an unsupervised clustering ap-proach‘K-Means’with pre-set the value of K as 2. Further, it has beenobserved that the leaf area is larger than the background region insome samples and vice-versa. Thus, we calculated the number of blackand non-black pixels in an image by using inbuilt functions of openCV, and NumPy libraries (Harris et al., 2020)a ss h o w ni ne q s .(1), and (2)for calculating the number of white pixels, and black pixelsrespectively.White
pixels¼np:sum img¼¼255ðÞ ð 1ÞBlack
pixels¼np:sum img¼¼0ðÞ ð 2ÞBlack pixels represent the background region whereas non-blackpixels represent the leaf area. Simultaneously, the pixels encounteredin region of infection are also transformed to white pixels. This avoidsthe inclusion of ROI in the background region. Then, we applied K-means (Usha Kumari et al., 2019) algorithm for segmentation of leafimage into two clusters namely ROI and background region. In casethe sample images have Larger Leaf Area (LLA) than their background
Fig. 2.The architecture of“Early Maize Disease Detector and Evaluator ”.
Fig. 3.Sample dataset.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
279region, then the algorithm selects a cluster with LLA. On the contrary, if asample has Smaller Leaf Area (SLA) than its background region, then thealgorithm chooses a cluster with SLA. In both the cases, leaf area consti-tutes the ROI. Thus, the background region is removed from the sampleimage. This strategy is demonstrated in Fig. 4.3.3. ArchitectureIn this section, the authors demonstrate the architecture of DL basedmodel MaizeNet developed for multi-class classi ﬁcation of dataset com- prising images of maize leaves into four classes viz. healthy, TLB, Rustand multidisease. The model comprises of nine convolution layers andthree max pooling layers as shown in Fig. 5. The authors applied Batch Normalization (BN) at second,ﬁfth and eighth convolutional layers tostandardize the model's deep layers. This reduces Internal CovariateShift (ICS) (Ioffe and Szegedy, 2015). Also, BN provides theﬂexibility in choosing the activation function and learning rate. Further, they em-ployed the activation function at third, fourth, sixth and ninthconvolutional layers. The last convolution layer is followed by theﬂatten and dense layer. This combination is important for multidimen-sional data stacking. Dense layer alone does not support multidimen-sional data stacking. Therefore, aﬂatten layer is embedded betweenconvolutional and dense layer to convert multidimensional input in 1-D and to provide correct predictions ( Kurtulmuş,2 0 2 0).3.4. Training detailsThe proposed model MaizeNet is trained on the Kaggle platformwhich provides 13 GB RAM, 15.9 GB GPU, and 19.6 GB disk space for acontinuous session of 30 h per week ( Kaggle Server, 2017). The model MaizeNet is trained using the dataset comprising 2460images of leaves of maize infected with TLB, Rust or multidisease. Itshyperparameters areﬁne-tuned as discussed in the subsequent sub-section. Also, the pre-training of the proposed model is performedusing the ImageNet dataset (Lab, 2017) and the impact of transfer learn- ing on its performance is illustrated in the result section. The samedataset was used for training the pre-trained MaizeNet model, non-pre-trained MaizeNet model and state-of-the-art models viz. VGG-16,VGG-19 (Simonyan and Zisserman, 2015), Inception-v3 (Szegedy, et al., 2019). Then, the performance of the proposed model was com-pared with the above-mentioned state-of-the-art models.3.5. Fine-tuning of training parametersThe softmax activation function, Adam optimizer and categoricalcross entropy loss was employed for training the model MaizeNet. Thelearning rate of 0.001 was pre-set and it is multiplied with 0.9 afterevery epoch when model completed its training for ten epochs. Thelearning rate was decided based on the experiments conducted in refer-ence (Prechelt, 2012), and the set of experiments conducted in this re-search with varying learning rates of 0.01, 0.001+ 0.0001, 0.001* 0.9and 0.001–0.0001. The impact of these learning rates on the value ofloss function is demonstrated inFig. 7. It is evident from the results shown inFig. 6that among all the above-stated values of learningrate, the loss function decreases more smoothly at the learning rate of0.001. Thus, the authors used this value of loss function for further ex-periments.Next, the choice of the optimum loss function is made by employingdifferent loss functions viz. mean squared logarithmic error, meansquared error, Mean absolute error, kullback leibler divergence and bi-nary cross entropy. It is obvious from the results shown in Fig. 7that the model converges smoothly when binary cross entropy loss functionis employed. Therefore, the authors employed this loss function for fur-ther experiments.3.6. Evaluation metricsThe performance of the Early Maize Disease Detector and Evaluator(EMDDE) was evaluated in terms of confusion matrix, precision, recall,
F1 score, accuracy and disease severity scale. These metrics are de ﬁned from eq.(3)through eq.(15), by taking clues from the reference(Simonyan and Zisserman, 2015).Confusion Matrix for multiclass classiﬁcation: This is the tabular rep- resentation of the number of correctly and incorrectly classi ﬁed samples into each labelled class as shown inTable 3. The sample confusion ma- trix for showing the correct and incorrect classi ﬁcations to the healthy, TLB, rust and multidisease are shown in Table 3.H e r e ,T P
HH,TPRR,T P TT,
and TP MMare the number of correctly classiﬁed samples of healthy leaves, rust, TLB, and multidisease, respectively. Similarly, F
HR,FHM,FHT
denotes samples belongs to rust, multidisease and TLB class respec-tively, but are classiﬁed to healthy class. Similarly, F
RH,FRM,FRT
denotes samples belongs to healthy, multidisease and TLB class respec-tively, but are classiﬁed to rust class. Similarly, F
MH,FMR,a n dF MTdenotes samples belongs to healthy, rust and TLB class respectively, but are clas-siﬁed to the multidisease class. Similarly, F
TH,FTR,FTMdenotes samples belongs to healthy, rust and multidisease class respectively, but areclassiﬁed to TLB class.i. Precision: This is the measure of correctly predicted samples to aparticular class from the total number of samples classi ﬁed to that class. For example, Precision
Healthy is the ratio of number of correctly predicted healthy leaf images to that of total number ofimages predicted to the healthy class. Its de ﬁnition is shown in eq. (3). Similarly, Precision
Rustis the number of correctly predictedsamples of rust to that of total number of samples predicted in therust class as deﬁned in eq.(4). By following the same notation,Precision
TLBis deﬁned as the number of correctly predictedsamples of TLB to that of total number of samples predicted to theTLB class, as shown in eq.(5). Similarly, Precision
multidisease is theTable 2Size of training and testing datasets.Classes Number of images in thetraining datasetNumber of images inthe testing datasetTotal numberof imagesHealthy 800 176 976TLB 800 197 997Rust 800 138 938Multidisease 60 25 85Total 2460 536 2996
Fig. 4.Dataset preparation strategy.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
280ratio of number of correctly predicted samples of multidisease classto that of total number of samples predicted to the multidiseaseclass, as deﬁned in eq.(6). The average precision as deﬁned in eq. (7)is the average of the precision calculated for each class fromeqs.(3)to eq.(6).Precision
Healthy ¼TPHH
TPHHþF RHþF THþF MHð3ÞPrecision
Rust¼TPRR
TPRRþF HRþF TRþF MRð4ÞPrecision
TLB¼TPTT
TPTTþF HTþF RTþF MTð5ÞPrecision
Multidisease ¼TPMM
TPMMþF HMþF RMþF TMð6ÞAverage Precision¼Precision Healthy þPrecision RustþPrecision TLBþPrecision Multidisease
4ð7Þii. Recall: This is the ratio of the correctly predicted samples of a class tothat of total number of samples of that class. For example,Recall
Healthy as deﬁned in eq.(8), is the ratio of correctly classiﬁed samples of the healthy class to that of total number of samples ofthe healthy class. The recall of Rust, TLB and multidisease is also de-ﬁned on a similar notion from eq.(9)to eq.(11). Average Recall as deﬁned in eq.(12), is the average of the Recall calculated for all thefour classes.Recall
Healthy ¼TPHH
TPHHþF HRþF HTþF HMð8ÞRecall
Rust¼TPRR
TPRRþF RHþF RTþF RMð9Þ
Fig. 5.Architecture of‘MaizeNet’model.
Fig. 6.Learning rate comparison (a) Learning rates: 0.01, 0.001+ 0.0001 and 0.001* 0.9; (b) Learning rate: 0.001 –0.0001.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
281Recall TLB¼TPTT
TPTTþF THþF TRþF TMð10ÞRecall
Multidisease ¼TPMM
TPMMþF MHþF MRþF MTð11ÞAverage Recall¼
Recall Healthy þRecall RustþRecall TLBþRecall Multidisease
4ð12Þiii. F1 score: This is the weighted average of precision and recall. Theformula to calculate the F1 score is given in eq. (13).F1¼2:
precision:recallprecisionþrecall ð13Þiv. Average accuracy: It is the measure of the degree of correctness ofthe classiﬁcation. It can be calculated using the formula given ineq.(14).Accuracy¼
TPHHþTP RRþTP TTþTP MM
Total dataset ð14Þv. Degree of Infected Region: The % of infected region is calculated byperforming the experiments with the labelled dataset. The datasetof each class is divided into Red [R], Blue [B] and Green [G] channels.The range of values of these channels is observed for each class. Fur-thermore, using the range, the following mechanism given in Fig. 8is introduced.Disease Severity Scale: In this manuscript, the authors used the se-verity scale designed by the plant pathologist working at ICAR, ( Indian Institute of Maize Research,2 0 1 5)a n d(Hooda et al., 2018). It is the 0 to 9 rating scale to represent the disease severity of TLB, and rust diseasesbased on the visual symptoms of the disease. Rating ‘0’denotes the min- imum severity, and rating ‘9’denotes the maximum severity. The plantpathology experts involved in this research manually analyzed the se-verity predicted in this research, and validated the level of disease se-verity according to the severity scale. The ratings are assigned basedon the ratio of Diseased Leaf Area (DLA) and Total Leaf Area (TLA).The scales for TLB, and Rust are shown in Figs. 9, and 10respectively. An image showing <10% infected region, indicates the minimum sever-ity. It may cause the minimum crop loss. Whereas >80% region infectedwith one disease, indicates the maximum severity. It may cause themaximum crop loss. Also, the leaves infected with multiple diseasesare considered highly susceptible irrespective of the infected area.Such leaves are rated with the maximum rating.Next, referring the formula given by Mckinney in 1923, and the se-verity predicted using the rating scale formulated for TLB and rust, thedegree of disease severity is estimated by following the eq. (15).H e r e , the conversion of rating scale to disease index or percentage is essentialf\scale90%or parametric statistics.Disease Severity%ðÞ¼∑Sum of all ratingðÞTotal number of rating/C2maximum disease ratingðÞ /C2100ð15Þ4. ResultsIn this section, the authors present the experimental results ob-tained on employing the MaizeNet, VGG-19, VGG-16, Inception ResNetV2, Inception V3, and ResNet-50 models on the dataset collected andprepared as a part of this research. They trained these models on the
Fig. 7.Comparison of Loss Functions.
Table 3Sample confusion matrix.
Healthy Rust Multidisease TLB
Healthy TPHH FHR FHM FHT
Rust FRH TPRR FRM FRT
Multidisease FMH FMR TPMM FMT
TLB FTH FTR FTM TPTTActual LabelPredictedLabel
Fig. 8.K-means disease classiﬁcation.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
2822460 images in a batch size of 32 for 100 epochs. The authors employedbinary cross entropy loss function based on the analysis presented inFig. 7. They used the pre-set learning rate of 0.001 as illustrated in Fig. 6.4.1. Impact of pre-processing on the performance of the classi ﬁerThe authors pre-processed the images and segment the ROI from allleaves using K-means. Samples of extracting ROI from leaves infectedwith TLB and Rust are shown inFigs. 11, and 12respectively. The region of infection is highlighted with blue colour in the extracted ROI. The seg-mentation used as a pre-processing technique extracts the region of in-teresti.eleaf area. Therefore, it allows the DL model to extract featuresonly from the ROI. This minimizes the interference of irrelevant featuresin decision making. Hence, it improves the accuracy of disease predic-tion, and reliability of the DL model.After pre-processing, the performance of MaizeNet was evaluated.The confusion matrices obtained without employing pre-processing,and with pre-processing are shown in Tables 4, and 5respectively. It is noticeable from the results shown in these tables that the numberof false positive decreases when the MaizeNet model is applied on theROI extracted by pre-processing. Thus, pre-processing improves theclassiﬁcation accuracy of MaizeNet model.Further, the trends of loss functions reported by the MaizeNet modelwith pre-processing, and without pre-processing are demonstrated inFigs. 13. It is observable from the graphs that the MaizeNet model re-ports lower value of loss function after pre-processing. Also, the de-crease in loss function is smoother when the model is applied on ROIextracted by pre-processing.4.2. Classiﬁcation and clusteringTo further validate the performance of the proposed modelMaizeNet, we applied unsupervised K-Means clustering technique onthe classiﬁed images. The clustering technique recognize the clustersof healthy, TLB, rust and multidisease classes based on the similarity ofpixel values. It assigns a label to each image using the function‘kmeans.labels’(Khairnar and Goje, 2020). The label is important to identify the cluster to which an image belongs. We considered k as144 rather than 4 toﬁnd the clusters based on multiple orientations of
Fig. 9.TLB scale.
Fig. 10.Rust scale.
Fig. 11.Extracting ROI from Leaves infected with TLB Disease.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
283an image. Here, the trained model scans an image from various orienta-tions and divide them into clusters.We also conducted a similar set of experiments by employingMaizeNet, VGG-16, VGG-19, Inception V3, InceptionResNet-v2 andResNet-50 models as shown inTable 6. The results obtained are demon- strated fromFigs. 14 to 19.4.2.1. PrecisionThe values of precision reported by MaizeNet, and above-mentionedstate-of-the-art models on the dataset comprising 536 images are dem-onstrated inFig. 14.I ti sa p p a r e n tf r o mt h eﬁgure that VGG-19 model re- ported the highest value of average precision as 99.82% on the pre-processed dataset and 99.56% without pre-processing. Pre-processingfeebly improved the precision by 0.26%. Next, Inception ResNet-v2model reported the highest values of precision as 95.30% before pre-processing and 99.82% after pre-processing. Here, an improvement of04.52% is observed in the value of precision. The proposed MaizeNetmodel reported the precision of 95.85% without pre-processing, and98.87% after pre-processing. The precision reported by MaizeNetmodel is equivalent to ResNet-v2 model after pre-processing. An im-provement of 3.02% in the value of average precision is observed onemploying pre-processing.4.2.2. RecallIt is evident from the results shown in Fig. 15that the VGG-19 and Inception ResNet-v2 reported highest recall of 99% after pre-processing. Further, analysis shows an increment of 0.37% and 3.84%in the values of recall reported when these are applied on pre-processed dataset. Whereas, the proposed model MaizeNet gave the av-erage recall of 95.31% and reported no change on the pre-processeddataset.4.2.3. F1-scoreTo further validate the quality of classiﬁcation, we calculated the values of F1 score as demonstrated in Fig. 16. VGG-19 and Inception ResNet-50 reported highest F1-score of 99.40% after pre-processing. Itis obvious from the Figure that pre-processing shows an increment inthe values of F1 score. The increment reported as 0.31% and 4.18% inthe F1-score reported by VGG-19 and Inception ResNet-50 respectively.The proposed model reported the F1 score of 97.13% which is equivalentto VGG-19 model.4.2.4. Average accuracyFor assessing the correctness of classiﬁcation, we calculated the values of average accuracy of all the above-mentioned models. Thesevalues are demonstrated inFig. 17. It is evident from theﬁgure that VGG-19 and Inception ResNet-50 reported the highest average accuracyof 99.81%. Whereas, the proposed model MaizeNet reported a slightlylower value of average accuracy as 98.50%.4.2.5. Computation costAlthough, the values of precision, recall, F1-score and accuracy re-ported by the model MaizeNet are slightly lower than VGG-19, its train-ing time is much lower than state-of-the-art models mentioned above
Fig. 12.Extracting ROI from Leaves infected with Rust Disease.
Table 4Confusion matrix of'maizenet ’with preprocessing.
Actual LabelPredictedLabelHealthy Rust Multi
diseaseTLB
Healthy 175 1 0 0
Rust 0 135 0 3
Multidisease 1 1 21 2
TLB 0 0 0 197
Table 5Confusion matrix of'maizenet ’without preprocessing.
   Healthy Rust Multi 
disease TLB 
Healthy 171 2 0 3 
Rust 1 130 3 1 
Multidisease 3 4 17 1 
TLB 2 2 3 190 Actual Label Predicted Label 
 Fig. 13.MaizeNet: trend of loss function with preprocessing.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
284as shown inFig. 18. It is clear from the results shown in Fig. 19that MaizeNet has 1,55,956 training parameters that are signi ﬁcantly lesser than 5,43,86,786 parameters extracted by Inception ResNet-v2 model.Therefore, there is a signiﬁcant decrease of 140 s in training time ofMaizeNet.4.2.6. Grad-CamIt is difﬁcult for the plant pathologists to rely on the classi ﬁcation re- sults reported by a computer vision based model. Therefore, it is neces-sary to visualize the features involved in decision making. We employedthe Gradient-weighted Class Activation Mapping (Grad-CAM)(Selvaraju et al., 2020) for visualization of features involved in classify-ing images to four classes viz. healthy, rust, TLB and multidisease on pre-processed as well as non-pre-processed dataset as shown in Figs. 20-21. To plot the Grad-CAM, the model uses the gradients of the last layer ofCNN model. It is evident from the Grad-CAM shown in Figs. 20 and 21 that the features are visible with more clear boundaries when themodels are employed on pre-processed dataset. Further, it is evidentfrom theﬁgures that the proposed model ’MaizeNet’is efﬁcient in mark- ing the maximum regions of infection in a given sample. It clearly distin-guishes the features of healthy, TLB, rust, and multidisease. Hence, itproves the reliability of the model in classi ﬁcation.4.3. Disease severityMerely detecting and classifying diseases is not suf ﬁcient to prevent and estimate the crop loss. Therefore, we extended the research workand calculated the disease severity in maize crop. For this purpose, weused 1 to 9 rating scale to mark the severity of TLB, rust, andmultidisease in maize crop. The scale is designed by plant pathologists,ICAR, maize, Ludhiana(Hooda et al., 2018). Using the scale, we calcu- lated the percentage of disease severity for TLB and rust as shown inTable 7 and 8respectively. Further, by following the deﬁnition of disease severity presented in eq.(13), we calculated the severity of TLB, and rustdiseases in the dataset prepared in this manuscript. The calculations forseverity of TLB, and rust is shown in eqs. (14), and (15)respectively. It is evident from the results calculated in eqs. (16), and (17)that maize crop studied in this manuscript is more affected by rust than TLB. Theseverity for rust is reported as 82.13%, whereas for TLB, it is reportedas 57.48%.Severity of TLB%ðÞ ¼
5158997/C29/C2100¼57:48%ð16ÞSeverity of Rust%ðÞ ¼
69348442/C29/C2100¼82:13%ð17Þ4.4. Crop loss estimationEstimation of crop loss is important to maintain a balance betweenthe demand, and supply of a crop. This is also signi ﬁcant in regulating the price of a crop. Thus, we worked for estimating the crop loss inmaize crop. In this study, we used the maize dataset comprising 2996images. This dataset contains 938 images of maize plants infected byrust and 976 infected by TLB. Following the recommendations of plantpathologists, we used rating scale for predicting percentage of croploss. We recorded the number of leaves with disease severity in therange of 1 to 5 rating, and 6 to 9 rating on the rating scale. Leaveswhich report the severity in the range of 1 to 5 rating cause the croploss of approximately 40%. Whereas, the leaves with rating 6 to 9cause >50% crop loss. The leaves infected with multidisease are consid-ered the cause for 100% crop loss. Further details for the crop loss esti-mation are illustrated inTable 9. The estimated crop loss is validatedby the plant pathologists involved in this research. The estimationof crop loss is validated based on the results reported for the disease de-tection, classiﬁcation, visualization of infected regions, and severitycalculated.Table 6Evaluation metrics with and without preprocessing.Model Before preprocessing After preprocessingPrecision Recall F1-score Accuracy (%) Precision Recall F1-score Accuracy (%)MaizeNet 95.85 95.31 95.57 98.32 98.87 95.31 97.13 98.50VGG-16 99.56 98.63 99.09 99.44 99.64 98 98.81 99.62VGG-19 99.56 98.63 99.09 99.34 99.82 99 99.40 99.81ResNet-50 99.56 98.63 99.09 99.44 99.34 96.85 98.07 99.25Inception-v3 99.38 97.63 98.49 99.25 99.51 97.81 98.65 99.44Inception ResNet-v2 95.30 95.16 95.22 97.38 99.82 99 99.40 99.81k-means 95.57 94.77 95.17 97.01 93.45 95.56 94.49 95.89
Fig. 14.Average Precision of different models.
 Fig. 15.Average Recall of different models.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
2855. Web applicationTo develop a one-point solution from disease detection to crop lossestimation, we integrated the proposed framework with an interactiveand user-friendly web application. The web application provides an op-tion to choose the input image and submit it. The uploaded originalimage and its corresponding mask generated by K-means mask willbe displayed on screen. Next, the image is sent to the proposed DLbased model MaizeNet that classiﬁes it to one of the four classes viz.TLB, rust, multidisease or healthy. Next, the model detects the infectedregion and calculate the area affected. Based on the area of infection, itprovides a rating to mark the disease severity and estimates the croploss. Theﬁnal white image is the area infected. The work ﬂow of the web application is demonstrated inFig. 22.6. DiscussionIn this section, the authors present the inferences deduced from theexperimental results obtained by employing the MaizeNet, VGG-16,VGG-19, ResNet-50, Inception-v3, and Inception ResNet-v2 models.The number of layers in MaizeNet is decided by conducting the experi-ments and analyzing the performance of the models with different net-work depths. It was observed that the model with nine convolutionlayers outperformed the models withﬁv et h r o u g he l e v e nc o n v o l u t i o n s .Our study uses a dataset of 2996 images captured from the farmlandof ICAR -AICRP, Mysore. The diseased crops were grown intentionallyfor carrying out the research work and labelled by plant pathologists.The images are labelled as Healthy, TLB, rust, or multidisease.In this research, the authors worked on the most ubiquitous foliardiseases of maize crop namely TLB and rust. They applied pre-processing as a proviso, for better recognition of the disease spotsusing K-means algorithm. Here, k is set to ‘2’for segmenting the back- ground and region of interest from the images. The authors also appliededge detection for detecting the infected area and separating the leafand background regions. But, in many cases, it was observed that back-ground had the same colour scheme as of leaf. So, no combination ofRGB could distinguish background from leaf. Thus, the authors decidedto employ K-means algorithm for distinguishing images based on thedifference in area occupied by ROI and background. Then, segmenteddataset classiﬁed using supervised approach viz. K-means and unsuper-vised approaches viz. MaizeNet, VGG-16, VGG-19, Resnet-50, Inception-v3 and InceptionResNet-v2. This classiﬁed data is clustered in four clas- ses namely TLB, rust, multidisease and healthy.It is apparent from the results shown in Fig. 17that the pre- processed versions of VGG-19 and Inception ResNet-v2 give the highestaverage accuracy. Whereas the non-pre-processed version of InceptionResNet-v2 reported the minimum value of average accuracy. Also, theunsupervised classiﬁcation using K-means shows the least accuracy.The pre-processing of these models leads to increase of 2.43% in the av-erage accuracy. This proves that the above-mentioned deep networksrequire pre-processing of vast dataset for training. In contrast with,the models viz. ResNet-50 reports a decrease in accuracy after pre-processing. Similarly, a low impact of 0.18% is observed on the averageaccuracy MaizeNet by applying pre-processing.It is inferred from the above discussion that the unsupervisedlearning shows the least average accuracy and deeper networksshow a low impact of pre-processing as compared to shallow neuralnetworks.
Fig. 16.F1-score of different models.
Fig. 17.Accuracy of different models.
Fig. 18.Training time of different models.
Fig. 19.Training parameters of different models.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
286Fig. 20.Grad-Cam to visualize the features of non-pre-processed models.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
287Fig. 21.Grad-Cam to visualize the features of pre-processed models.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
288Further, the trends of the precision, recall, and F1 measures of theabove-stated models are demonstrated in Figs. 14 to 16. It is evident fromFig. 15that the pre-processed VGG-19 and Inception ResNet-v2models reported the highest precision of 99.82%. In contrast, the non-pre-processed VGG-19 and Inception ResNet-v2 reported 0.26% and4.52% lower precision than pre-processed models. In contrast, ResNet-50 and K-means reported 0.22%, 2.12% decrease in precision afterpre-processing. The small variation in the precision of all the pre-processed versions of the above-stated models implies that thesemodels are efﬁcient in recognizing the relevant instances of each classfrom the input test dataset. The discussion proves that the pre-processing helps to discriminate the irrelevant features and improvesthe performance.Further analysis of results shown in Fig. 15reveals that pre- processed VGG-19 and Inception ResNet-v2 models reported 99% recall.The pre-processed Inception ResNet-v2 reported 4.84% increase in recallthan non-pre-processed. The other models viz. ResNet-50, Inception-v3,and MaizeNet reported lower values of recall, as shown in Fig. 15. Further, it is evident from the F1-score shown in Fig. 16that the pre- processed VGG-19 and Inception ResNet-v2 models reported thehighest F1-score of 99.40%. There is a hike of 2.02% from non-pre-processed Inception ResNet-v2 model. Simultaneously, it is observedthat the models ResNet-50, Inception-v3 and MaizeNet reported the de-crease of 1.02% and increase of 0.16% and 1.48% respectively in thevalues after pre-processing.Furthermore, it is coherent from the Grad-Cam plotted in Figs. 20, and 21that the pre-processed MaizeNet model is effective in classifyinghealthy, rust, TLB and multidisease.However, the MaizeNet model shows the comparable values of aver-age accuracy, precision, recall, and F1 score with the state-of-the-artmodels, there is a signiﬁcant decrease in the number of trainable param-eters and training time. It is noticeable from Fig. 19that the MaizeNet model has the minimum number of trainable parameters. Further, it isevident from the training time presented in Fig. 18that the MaizeNet model requires a minimum training time of 140 s through 20 epochs.Apart from disease detection in maize, the proposed frameworkdoes the assessment of disease severity by predicting Disease LeafArea (DLA). It also estimates the crop loss based on the severity scale de-signed by maize plant pathologist, ICAR, Ludhiana, as shown in Figs. 9, and 10. Disease severity of 57.48%, 82.13% was reported for TLB andrust respectively. These results were validated by experts from ICAR.This is obvious from the above discussion and experimental resultsreported that the framework reports higher accuracy than approachesproposed in literature. The authors applied state-of the-art models viz.ResNet-101(Prabhakar et al., 2020), VGG-16 (Wang et al., 2017), En- hanced CNN (Agarwal and Sharma, 2021) and GoogleNet (Zhang et al., 2018) on the dataset comprising maize crop images and reportedthe average accuracy of 90.4%, 94.6%, and 95.12%, and 98.9% respec-tively. Furthermore, the authors in literature calculated severity at anearly, middle, and end stage. But, none of them calculated the severityon the normalized scale designed by plant pathologists. Also, they didnot predict the percentage of diseased leaf area, and estimated croploss in maize crop. Moreover, no research work was found in whichthe results of DL based system were validated by the plant pathology ex-perts and integrated with a user-friendly web application.7. ConclusionsIn this manuscript, the authors achieved the objective of automatingthe disease detection, classiﬁcation, severity calculation, and crop lossTable 7TLB: disease severity calculation.Grade Total rating Number of ratings1–20 03 99 2974 252 10085 203 10156 272 16327 166 116281 894 3 6997 5158
Table 8Rust: disease severity calculation.Grade Total scaling Number of scaling1–40 05 22 1106 55 3307 415 29058 425 34009 21 189938 6934Table 9Crop loss prediction.Scaling Number ofTLB leavesNumber ofrust leavesMultidiseaseleavesTotal Croploss1–5 554 22 –576 30–40% 6–9 443 816 1259 >50%=9–– 85 85 100%
Fig. 22.Workﬂow of the web application.N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
289estimation for the maize crop. They collected the real-life dataset com-prising images of healthy maize crop and crop infected with TLB, rust,and multidisease.The authors pre-processed the collected dataset by applying K-Means algorithm. Further, they applied both supervised and unsuper-vised algorithms on pre-processed, and non-pre-processed dataset forclassifying images to all the four classes mentioned above. The authorstrained K-means (Khairnar and Goje, 2020), VGG-19 (Simonyan and Zisserman, 2015), ResNet-50 (He et al., 2016), Inception-v3 (Szegedy et al., 2016),ﬁnetuned VGG-16 models (Wang et al., 2017), and the pro- posed DL model MaizeNet, on a dataset comprising 2460 images. Theseimages include four classes namely healthy, TLB, rust and multidisease.Among all the above-stated models, MaizeNet reported the highest ac-curacy of 98.50% on the testing dataset comprising 536 images.Furthermore, the proposed model has lowest number of parametersas 1,55,956. Therefore, its training time is minimum of all the above-stated models. This model completes 20 epochs of training in merely140 s. Moreover, its efﬁcacy in calculating the diseased leaf area, severityprediction, and crop loss estimation prove its supremacy over the re-search works proposed in the literature. Further, the model is integratedwith a web-application for its real-life use as a disease predictionassisting tool. Although, the proposed framework is ef ﬁcient in classify- ing maize crop into TLB, rust, multidisease, and healthy classes,predicting the disease severity, and estimating the crop loss, there is ascope of making the predictions based on soil parameters, atmosphericconditions, and genomics of plants, and disease-causing agents. Also,the framework can be generalized for crop loss estimation of any crop.FundingThis work was supported by the Department of Informatics, Model-ing, Electronics and Systems (DIMES), University of Calabria [Grant/Award Number: SIMPATICO_ZUMPANO].Author statementAll authors have equally contributed in conducting this research andpreparing the manuscript.Declaration of Competing InterestThe authors declare no conﬂict of interest.AcknowledgmentsThe authors world like to thank “The Indian Council of AgriculturalResearch”(ICAR), Mysore branch for collection of the dataset for exper-iments and evaluating the efﬁcacy of the framework. The authors alsoacknowledge Manipal University Jaipur for providing the computing re-sources required to conduct the experiments involved in this research.References
Agarwal, M., Rani, G., Dhaka, V.S., 2020. Optimized contrast enhancement for tumor de-tection. Int. J. Imaging Syst. Technol. 30, 687 –703.https://doi.org/10.1002/ima.22408 . Agarwal, R., Sharma, H., 2021. Enhanced Convolutional Neural Network (ECNN) for MaizeLeaf Diseases. pp. 297 –307.Al-amri, S.S., Kalyankar, N.V., S.D, K, 2010. Image segmentation by using edge detection. Int. J. Comput. Sci. Eng. 2, 804 –807. Alla Singh, S.B., Jat, Suby Sumit Kumar Aggarwal B.S., Das, Shanti Bamboriya SantoshKumar Abhijit, 2019.ICAR-IIMR Annual Report..Bedi, P., Gole, P., 2021. Plant disease detection using hybrid model based on convolutionalautoencoder and convolutional neural network. Artif. Intell. Agric. 5, 90 –101.https:// doi.org/10.1016/j.aiia.2021.05.002 . Bock, C.H., Poole, G.H., Parker, P.E., Gottwald, T.R., 2010. Plant disease severity estimatedvisually, by digital photography and image analysis, and by hyperspectral imaging.CRC. Crit. Rev. Plant Sci. 29, 59 –107.https://doi.org/10.1080/07352681003617285 . Cao, P., Li, X., Mao, K., Lu, F., Ning, G., Fang, L., et al., 2020. A novel data augmentationmethod to enhance deep neural networks for detection of atrial ﬁbrillation. Biomed. Signal Process. Control 56, 101675. https://doi.org/10.1016/j.bspc.2019.101675 .Chen, J., Wang, W., Zhang, D., Zeb, A., Nanehkaran, Y.A., 2020. Attention Embedded Light-weight Network for Maize Disease Recognition, pp 1 –13https://doi.org/10.1111/ppa. 13322.Chen, S.W., Shivakumar, S.S., Dcunha, S., Das, J., Okon, E., Qu, C., et al., 2017. Countingapples and oranges with deep learning: a data-driven approach. IEEE Robot. Autom.Lett. 2, 781–788.https://doi.org/10.1109/LRA.2017.2651944 . Dechant, C., Wiesner-hanks, T., Chen, S., Stewart, E.L., Gore, M.A., Nelson, R.J., et al., 2017.Automated identiﬁcation of northern leaf blight-infected maize plants from ﬁeld im- agery using deep learning. Phytopathology 107 (11), 1 –26. Haque, M.A., Marwaha, S., Deb, C.K., Nigam, S., Arora, A., Hooda, K.S., et al., 2022. Deeplearning-based approach for identi ﬁcation of diseases of maize crop. Sci. Rep. 12. https://doi.org/10.1038/s41598-022-10140-z . Harris, C.R., Millman, K.J., van der Walt, et al., 2020. Array programming with NumPy.Nature 585, 357–362.https://doi.org/10.1038/s41586-020-2649-2 . He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. Proc.IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit .2016-Decem, pp. 770 –778 https://doi.org/10.1109/CVPR.2016.90 . Hijazi, S., Kumar, R., Rowen, C., 2015. Using convolutional neural networks for imagerecognition. Cadence.https://doi.org/10.2458/azu_js_rc.55.16783 . Hooda, K.S., Bagaria, P.K., Khokhar, Mukesh, Kaur, Harleen, Rakshit, S., 2018. Mass Screening Techniques for Resistance to Maize Diseases.Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., 2017. Densely connectedconvolutional networks. Proc. - 30th IEEE Conf. Comput. Vis. Pattern recognition,CVPR 2017 2017-Janua, pp. 2261 –2269https://doi.org/10.1109/CVPR.2017.243 . Indian Institute of Maize Research. Available at: https://iimr.icar.gov.in/world-maze- scenario/.Ioffe, S., Szegedy, C., 2015.Batch normalization: accelerating deep network training byreducing internal covariate shift. International Conference on Machine Learning,pp. 448–456.Kaggle Server. Available at:https://www.kaggle.com/getting-started/44318 . Khairnar, Khushal, Goje, Nitin, 2020. Image Processing Based Approach for DiseasesDetection and Diagnosis on Cotton Plant Leaf. Techno-Societal 2018. Springer 1,pp. 55–65https://doi.org/10.1007/978-3-030-16848-3_6 . Khan, M.A., Lali, M.I.U., Sharif, M., Javed, K., Aurangzeb, K., Haider, S.I., et al., 2019. Anoptimized method for segmentation and classi ﬁcation of apple diseases based on strong correlation and genetic algorithm based feature selection. IEEE Access 7,46261–46277.https://doi.org/10.1109/ACCESS.2019.2908040 . Krizhevsky, Alex, 2010. ImageNet Classi ﬁcation with Deep Convolutional Neural Networks, pp 1–1432https://doi.org/10.1201/9781420010749 . Kundu, N., Rani, G., Dhaka, V.S., Gupta, K., Nayak, S.C., Verma, S., et al., 2021. Iot and inter-pretable machine learning based framework for disease prediction in pearl millet.Sensors 21, 1–23.https://doi.org/10.3390/s21165386 . Kurtulmuş, F., 2020. Identiﬁcation of sunﬂower seeds with deep convolutional neural networks. J. Food Meas. Charact. https://doi.org/10.1007/s11694-020-00707-7 . Lab, S. Vision and Pronceton University, 2017. ImageNet Dataset. Available at: http:// image-net.org[Accessed October 2, 2020].Lee, S.H., Goëau, H., Bonnet, P., Joly, A., 2020. New perspectives on plant disease character-ization based on deep learning. Comput. Electron. Agric. 170, 105220. https://doi.org/ 10.1016/j.compag.2020.105220 . Luque, F., Hupont, I., Tabik, S., Herrera, F., 2020. Revisiting crowd behaviour analysisthrough deep learning : Taxonomy, anomaly detection, crowd emotions, datasets,opportunities and prospects. Inf. Fusion 64, 318 –335.https://doi.org/10.1016/j. inffus.2020.07.008.Lv, M., Zhou, G., He, M., Zhang, W., Hu, Y., Chen, A., 2020. Maize Leaf Disease Identiﬁcation Based on Feature Enhancement and DMS-Robust Alexnet. p. 8.Ma, Z., Tavares, J.M.R.S., Jorge, R.M.N., 2009. A review on the current segmentationalgorithms for medicalimages. IMAGAPP 2009 - Proc. 1st Int. Conf. Comput. ImagingTheory Appl., pp. 135 –140https://doi.org/10.5220/0001793501350140 Mishra, S., Sachan, R., Rajpal, D., 2020. Deep convolutional neural network based detec-tion system for real-time Corn Plant disease recognition. Procedia Comput. Sci. 167,2003–2010.https://doi.org/10.1016/j.procs.2020.03.236 . Modi, Ajay, 2014. Maize Production Growing faster in India on Higher Demand.BusinessToday.in Available at: https://www.businesstoday.in/magazine/features/ cargill-india-ceo-siraz-chaudhury-maize/story/205721.html . nlb_annotated_public_2016_Maize dataset. Available at: https://bisque.cyverse.org/ client_service/view?resource=https://bisque.cyverse.org/data_service/00-4Vcp37UZhQmfcVzBQ2JBhk. Oza, M.G., Rani, G., Dhaka, V.S., 2021. Glaucoma detection using convolutional neural networks. Handbook of Research on Disease Prediction Through Data Analytics andMachine Learning (IGI Global), pp. 1 –7. Panda, A.K., Prakash, B., Rao, S.V.R., Sunder, G.S., 2013. Utilisation of High Quality Protein
Maize in poultry. 69, pp. 877 –888.https://doi.org/10.1017/S0043933913000871 . PlantVillage Dataset. Available at: https://www.kaggle.com/emmarex/plantdisease . Prabhakar, M., Purushothaman, R., Awasthi, D.P., 2020. Deep learning based assessment ofdisease severity for early blight in tomato crop. Multimed. Tools Appl. 79,28773–28784.https://doi.org/10.1007/s11042-020-09461-w . Pradhan, N., Rani, G., Dhaka, V.S., Poonia, R.C., 2020. Diabetes prediction using artiﬁcial neural network. Deep Learn. Tech. Biomed. Heal. Inform. 327 –339. Prechelt, L., 2012. Early Stopping - But When? 7700. Springer, Berlin, Heidelb, pp. 53 –67. https://doi.org/10.1007/978-3-642-35289-8_5Ramamurthy, K., 2019.Electronic Monitoring and Disease Diagnosis of oryza Sativa Cropsthrough an IoT Enabled Embedded System Feature Ranking of Spatial DomainFeatures for Efﬁcient Characterization of Stroke Lesions View Project Low PowerReal Time GPS Tracking Enabled with RTOS and Serverless Architecture View Project.Rani, G., Agarwal, M., 2020. Contrast enhancement using optimum threshold selection.Int. J. Softw. Innov. 8, 96 –118.https://doi.org/10.4018/IJSI.2020070107 .N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
290Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., 2020. Grad-CAM:visual explanations from deep networks via gradient-based localization. Int.J. Comput. Vis. 128, 336 –359.https://doi.org/10.1007/s11263-019-01228-7 . Sheng, S., Li, T., Liu, R., 2018. Food science and human wellness corn phytochemicals andtheir health beneﬁts. Food Sci. Human Wellness 7, 185 –195.https://doi.org/10.1016/ j.fshw.2018.09.003.Simonyan, K., Zisserman, A., 2015. Very deep convolutional networks for large-scale image recognition. 3rd Int. Conf. Learn. Represent. ICLR 2015 - Conf .Track Proc., pp. 1–14Singh, V., Sharma, N., Singh, S., 2020. A review of imaging techniques for plant diseasedetection. Artif. Intell. Agric. 4, 229 –242.https://doi.org/10.1016/j.aiia.2020.10.002 . Smith, D.R., 1988.Diseases of Corn.Sun, J.U.N., Yang, Y.U., He, X., Wu, X., 2020. Northern maize leaf blight detection undercomplexﬁeld environment based on deep learning. IEEE Access 8, 33679 –33688. https://doi.org/10.1109/ACCESS.2020.2973658 . Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., 2016. Rethinking the inceptionarchitecture for computer vision. Proc. IEEE Comput. Soc. Conf. Comput. Vis. PatternRecognit. 2016-Decem, pp. 2818 –2826https://doi.org/10.1109/CVPR.2016.308 . Szegedy, Christian, Liu, Wei, Jia, Yangqing, Pierre Sermanet, S.R., 2019. Going deeper withconvolutions. Des. Track. Knowl. Manag. Metrics, 163 –182https://doi.org/10.1108/ 978-1-78973-723-320191012 . Taylor, P., Payak, M.M., Sharma, R.C., 2008. Maize Diseases and Approaches to their Man- agement in India. pp. 37 –41.Timsina, J., Jat, M.L., Majumdar, K., 2010. Rice-maize systems of South Asia: current status,future prospects and research priorities for nutrient management. Plant Soil 335,65–82.https://doi.org/10.1007/s11104-010-0418-y . Usha Kumari, C., Jeevan Prasad, S., Mounika, G., 2019. Leaf disease detection: feature ex-traction with k-means clustering and classi ﬁcation with ANN. Proc. 3rd Int. Conf. Comput. Methodol. Commun. 2019. ICCMC, pp. 1095 –1098.https://doi.org/10. 1109/ICCMC.2019.8819750. Wang, G., Sun, Y., Wang, J., 2017. Automatic image-based plant disease severity estima-tion using deep learning. Comput. Intell. Neurosci. 2017. https://doi.org/10.1155/ 2017/2917536.Wang, J., Li, M., Zhang, J., Zeng, W., Yang, X., 2019. DCNN Transfer Learning and Multi-model Integration for Disease and Weed Identi ﬁcation. 2, pp. 492–504.https://doi. org/10.1007/978-981-13-9917-6 . Xu, Y., Goodacre, R., 2018. On splitting training and validation set: a comparative study ofcross-validation, bootstrap and systematic sampling for estimating the generalizationperformance of supervised learning. J. Anal. Test. 2, 249 –262.https://doi.org/10.1007/ s41664-018-0068-2.Zhang, X., Qiao, Y., Meng, F., Fan, C., Zhang, M., 2018. Identi
ﬁcation of maize leaf diseases using improved deep convolutional neural networks. IEEE Access 6, 30370 –30377. https://doi.org/10.1109/ACCESS.2018.2844405 .N. Kundu, G. Rani, V.S. Dhaka et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 276 –291
291