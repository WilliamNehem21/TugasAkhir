Automatic marker-free registration of single tree point-clouddata based on rotating projection
Xiuxian Xua,P e iW a n ga,⁎, Xiaozheng Gana,J i n g q i a nS u na,Y a x i nL ia,L iZ h a n ga,Q i n gZ h a n ga, Mei Zhoub, Yinghui Zhao
c,X i n w e iL ia
aSchool of Science, Beijing Forestry University, Beijing 100083, China
bKey Laboratory of Quantitative Remote Sensing Information Technology, Academy of Opto-Electronics, Beijing 100094, China
cAerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China
abstract article info
Article history:Received 21 February 2022Received in revised form 18 August 2022Accepted 19 September 2022Available online 21 September 2022Point-cloud data acquired using a terrestrial laser scanner play an important role in digital forestry research. Mul-tiple scans are generally used to overcome occlusion effects and obtain complete tree structural information.However, the placement of artiﬁcial reﬂectors in a forest with complex terrain for marker-based registration is time-consuming and difﬁcult. In this study, an automatic coarse-to- ﬁne method for the registration of point- cloud data from multiple scans of a single tree was proposed. In coarse registration, point clouds produced byeach scan are projected onto a spherical surface to generate a series of two-dimensional (2D) images, whichare used to estimate the initial positions of multiple scans. Corresponding feature-point pairs are then extractedfrom these series of 2D images. Inﬁne registration, point-cloud data slicing and ﬁtting methods are used to ex- tract corresponding central stem and branch centers for use as tie points to calculate ﬁne transformation param- eters. To evaluate the accuracy of registration results, we propose a model of error evaluation via calculating thedistances between center points from corresponding branches in adjacent scans. For accurate evaluation, we con-ducted experiments on two simulated trees and six real-world trees. Average registration errors of the proposedmethod were 0.026 m around on simulated tree point clouds, and 0.049 m around on real-world tree pointclouds.© 2022 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Coarse registrationFeature-point matchingFine registrationMulti-station tree point cloudPoint-cloud registration
1. IntroductionThree-dimensional (3D) geometric information describing trees isvery important in many researchﬁelds for processes such as biomassestimation, forest inventory, forest management, and urban environ-ment modeling (Dubayah and Drake, 2000;Hopkinson et al., 2004; Popescu, 2007;Popescu et al., 2003;Wulder et al., 2008). Some valid methods used to acquire tree structure information include traditionalﬁeld measurement, photography, and laser scanning. Field measure-ment is effective, butﬁne manual measurement is very labor-intensive and time-consuming. Close-range photogrammetry (CRP)method is an emerging and potential solution to get 3D information.CRP can compute a series of overlapped tree images to generate 3Dpoint cloud, which can be used to estimate tree diameters ( Mokroš et al., 2018)a n dv o l u m e s(Marzulli et al., 2020). Due to the lower accu- racy, CRP is considered as an low-cost alternative to laser scanning.For trees with complex structures and dense foliage, the point cloudArtiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
⁎Corresponding author.E-mail address:wangpei@bjfu.edu.cn(P. Wang).
generation efﬁciency and accuracy of CRP will decrease. However, asan active direct measurement method, laser scanning can acquire treestructures fast and accurately, although it is also limited by the hard-ware cost and low mobility.In recent years, the performance of 3D laser scanner is increasing,while the cost and volume are decreasing. More laser scanners havebeen widely applied to acquire 3D tree information for different typesof experiments. Terrestrial laser scanner (TLS)-based methods havebeen developed to construct 3D models of trees for data extraction(Dassot et al., 2011;Henning and Radtke, 2006;Pfeifer et al., 2004; Raumonen et al., 2013;Thies⁎et al., 2004). Due to the geometric com- plexity of trees, TLS methods result in occlusion effects in each scan.This limitation leads to partial observation and incomplete structural in-formation, which greatly increases the dif ﬁculty of fully reconstructing trees within a single scan. Reconstruction based on multiple scans is anefﬁcient complementary method to mitigate occlusion effects and facili-tate the full reconstruction of trees. Multiple-scan approaches producepoint clouds from different scans that lie within different coordinatesystems. Thus, multiple scans must be transformed to a common coordi-nate system via a registration procedure (Guiyun Zhou et al., 2014).
https://doi.org/10.1016/j.aiia.2022.09.0052589-7217/© 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/Point-cloud registration methods can be categorized into twoclasses: marker-based and marker-free registrations. Marker-based reg-istration relies on artiﬁcial markers that are manually placed at thescene and manual or automatic recognition of these markers in differentscans to establish correspondences ( Bienert and Maas, 2009;Hilker et al., 2012). The markers are often reﬂective and can have various shapes (e.g., circular, cylindrical, or spherical). Based on correspondingpoint pairs extracted by identifying the same markers in adjacentscans, the relative transformation matrix between overlapping areasin multiple scans can be calculated by many commercial software pack-ages to complete the registration procedure.Marker-based registrationis accurate and reliable but has many limitations. In complex environ-ments, artiﬁcial markers can be difﬁcult to place, and marker-based reg-istration is often time-consuming in theﬁeld (Pfeifer et al., 2004). By contrast, marker-free registration attempts to automaticallymerge two or more scans directly without using arti ﬁcial markers. Re- searchers using marker-free methods often focus on extracting naturalgeometric features (e.g., points, lines, and surfaces) from the scans(Böhm and Becker, 2007;Brenner et al., 2008). These features are uti- lized to extract tie points during registration. In forestry scenes, groundsurface points, stem centers, and skeletons can be extracted to establishcorrespondence between multiple scans ( Aschoff and Spiecker, 2004; Henning and Radtke, 2008a). The iterative closest point (ICP) algorithmand its variants are commonly used methods for marker-free registra-tion.(Besl and McKay, 1992;Rusinkiewicz and Levoy, 2001). The ICP al- gorithm starts with two scans and an initial guess for relative rigid-bodytransformation; an iterative approach is then applied to re ﬁne the trans- formation by alternately establishing correspondence. Due to sensitivityto the initial position and the large computational cost of multiple iter-ations, ICP methods are often used inﬁne registration processes. An- other important registration method is the four-point congruent set(4PCS), which extracts coplanar four-point sets from approximatelycongruent scans to complete global registration ( Aiger et al., 2008). Without the requirement of assumptions about initial alignment, 4PCScan establish reliable corresponding sets within a limited number of tri-als and is robust against noise and low-overlap scans.In forest scenes, the complex geometric distribution of branches andlarge number of leaf points pose a challenge to maker-free registrationof tree point-cloud data (Bailey and Ochoa, 2018). Because we cannot guarantee the simultaneous acquisition of multiple scans, natural ele-ments (e.g., wind, sun, and animals) will introduce inconsistencies inoverlapping parts among multiple scans. In most situations, leaf pointswill interfere with accurate registration; a few methods have been pro-posed to solve this problem. (Henning and Radtke, 2008a, 2008b ) achieved forestry scenes registration based on tie points estimatedfrom ground surfaces and stem centers in range images. The processof extracting tree stems in the method is not free of manual steps.(Bucksch and Khoshelham, 2013) applied localized registration usinga skeletonization method to detect correspondences between branchsegments in multiple scans. However, this approach relied on roughlyregistered tree point-cloud data prior to ﬁne registration. (Guiyun Zhou et al., 2014) applied a skeleton extraction method to a rough auto-matic registration procedure—based on the extracted skeleton, the ini-tial translation vector and rotation angle were estimated using rootpoint positions, distances between branch segments, and a mappingcost function between skeletons. By minimizing the mapping costfunction, the transformation parameter was further re
ﬁned inﬁne registration.Recently, (Zhang et al., 2016) proposed a coarse-to-ﬁne strategy to address the difﬁculty of forestry scene registration. In coarse registra-tion, a backsighting orientation procedure is used to calculate transfor-mation parameters instead of placing arti ﬁcial reﬂectors. Based on the initial values, stem-center locations are extracted as tie points to re ﬁne the rigid-body transformation forﬁne registration. The coarse-to-ﬁne strategy improves the robustness and accuracy of forest scene registra-tion, but also has several limitations. First, coarse registration requiresmanual placement of backsighting reﬂectors, which can be difﬁcult to apply in complex environments. Second, due to the features of stem-ﬁtting methods,ﬁne registration cannot guarantee high registration ac-curacy in the vertical direction, especially for bent trunks whose crosssections cannot be treated as circles; the stem- ﬁtting approach fails in such situations.The registration of single-tree point-cloud data without re ﬂectors remains a challenge. Unlike multiple tree registration in a forest scene,where the spatial relationship between trees can be useful information,geometrical structure is the only information that can be used inmarker-free registration of single-tree point-cloud data.The objective of this study was to develop a fully automaticmarker-free registration algorithm with high registration accuracy.Ac o a r s e - t o -ﬁne registration strategy was adopted to align pointclouds with bad initial positions without reference points in a
Fig. 1.Simulated point clouds for trees (a) and (b). Green, red, and blue points indicatescans 1, 2, and 3, respectively.
Table 1The characteristics of RIEGL VZ-400 scanner.Technical parametersThe farthest distance measurement 600 m (natural object reﬂectivity≥90%) The scanning rate (points / second) 300,000 (emission), 125,000 (reception) The scanning range −40°∼60°(vertical)0°∼360°(horizontal) Laser divergence 0.3 mradConnection LAN / WLAN, wireless data transmissionX. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
177stepwise manner. In our coarse registration, each 3D point cloud wasprojected onto a sphere to generate a series of 2D projection imagesfor the extraction of feature-point pairs, whose spatial informationcan be used to estimate the transformation matrix for the coarse reg-istration of multiple scans. Sliced point-cloud data were then used toestimate the centers of trunks and branches using ﬁtting methods. The estimated centers were used as tie points to perform ﬁne registration.2. Experimental dataEight groups of tree point clouds were used to test the proposedmethod in the experiments. Among them, there are two simulatedtrees and six real trees. Each tree is composed of three point cloudsscanned from three different viewpoints.Two simulated trees have simpler and deﬁned geometric structures, which are simulated using the scanning geometric and less noise with-out leaf interference (Fig. 1). Simulated tree point clouds are useful foranalyzing the advantages and limitations of our method.Given that tree structures in nature scenes are more complex thanthat of simulated trees, the veriﬁcation of our method on real-worldtree point clouds is important. In the study, six trees in the campus ofBeijing Forestry University were scanned to obtain the groups of real-world tree point clouds. Data collection was conducted using a RIEGLVZ−400 TLS scanner (RIEGL Laser Measurement Systems GmbH,3580 Horn, Austria), whose characteristics are shown in Table 1. Each
Fig. 2.Workﬂow of the coarse-to-ﬁne registration procedure.
Fig. 3.The point-cloud projection model. P ′is the projection of point P on the spherical surface. E is the foot of the perpendicular line from P ′to the X-Y plane.αis the angle between OE and the x-axis.βis the angle between OP' and the X-Y plane.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
178group of tree point clouds contains three scans scanned from differentpositions with the vertical and horizontal scanning angular resolutionof 0.02°. To facilitate the processing and analysis, the small branchesand noisy leaf points wereﬁltered out manually.3. MethodologyIn our proposed method, the registration procedure comprises twoparts: coarse andﬁne registration. The objective of the coarse-to- ﬁne strategy is to transform coordinates from target points to referencepoints in a stepwise manner. In coarse registration, a rough transforma-tion matrix is calculated to transform the target points into a positionthat is close to the reference points. Based on the close relative positionsof the two point sets, more information can be used to achieve an accu-rate transformation towards the reference points in ﬁne registration. Inboth steps, rigid-body transformation is determined by translation androtation parameters. The registration procedure is described by follow-ing equations:ptcoarse ¼R coarse⋅pttarþT coarse
ptref¼R fine⋅ptcoarse þT fine ð1ÞWherept
tarandpt refare points in the target and reference scans,respectively;Ris the rotation matrix; andTis the translation vector. In coarse registration, our method simpliﬁes the 3d point matching problem into a 2d point matching problem by projecting from the 3Dpoint cloud to 2D images. The matched points are estimated usingfeature-point-matching algorithms on images generated by projection.These matched points are then used to e stimate the rough transformation.Inﬁne registration, point-cloud slicing andﬁtting methods are used to extract corresponding trunk and branch centers, which function as tiepoints to calculate theﬁne transformation parameters. The workﬂow is illustrated inFig. 2.We also proposed a simple model in this section to evaluate the re-sults of registration, which can help to compare the coarse registration,ﬁne registration and ICP registration using the above-mentioned simu-lated tree point clouds and real-world tree point clouds.3.1. Coarse registration3.1.1. Point-cloud projectionWe established a point-cloud projection model to convert 3D pointclouds to 2D images. The tree point-cloud is projected onto a spherecentered at the origin of the coordinate system, where the scanner is lo-cated. The projection was then used to generate an image on the spher-ical surface. The model is shown inFig. 3. Each point projected onto the sphere corresponds to a pair of angles,αandβ(Fig. 3), which are used to determine the pixel coordinates ofeach point and generate corresponding images.In the model, each set of pixel coordinates corresponds to a pair ofintervals [α
l,αh]a n d[β l,βh] for anglesαandβrespectively. The pixel coordinates of a point is determined by which pair of intervals itscorresponding anglesαandβlie in. Each point is allocated a pixelcoordinate in this manner. The minimum steps of angle αandβare equal to the horizontal and vertical angular step widths of the TLS in-strument, denotedφandϕ, respectively. In this study, each pixel inthe image covered a region of 2φand 2ϕin the horizontal and vertical directions, respectively, which reduced the impact of discontinuousscanning points. The projected image has a size of m × n, where thevalues of m and n are calculated using the following equations:
Fig. 4.Sample image generated via projection.
Fig. 5.Generation of image sequences.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
179m¼αmax/C0αminðÞ=2φþ2r 1 jjn¼βmax/C0βminðÞ=2ϕþ2r
2 jj ð 2Þwhereα
min,αmax,βmin,a n dβ maxare the minimum and maximumvalues ofαandβof all points, respectively; andr
1andr 2are pixels forming a border around the image, which ensures that the size of theimage satisﬁes our demands.For any point P with corresponding angles α
pandβ p, the pixel coordinates (x,y) can be calculated as follows:x¼αp/C0αminðÞ=2φþr
1
y¼βp/C0βminðÞ=2ϕþr 2 ð3ÞAs a result, each scanning point corresponds to a certain set of pixelcoordinates, and each pixel may have several corresponding points. Theimage generated via projection is a binary image. Pixels with andwithout corresponding scanning points are set to values of 0 and 255,respectively.As shown inFig. 4,Aij(i=1 ,2 ,…,m–2r;j=1 ,2 ,…,n–2r 2)i sa pixel that corresponds to a pair of angle intervals. For example:A
11 :α min,αminþΔα½Þ,βmin,βminþΔβ½ÞðÞ,A 12
:α minþΔα,α minþ2Δα½Þ,βmin,βminþΔβ½ÞðÞ ,...,A 1m/C02r 1
:α max/C0Δα,α max ½Þ,βmin,βminþΔβ½ÞðÞA
21:( [α min,αmin+Δα),[β min+Δβ,β min+2Δβ)),A 31
:( [α min,αmin+Δα),[β min+2Δβ,β min+3Δβ)),…,A n−2r21
:( [α min,αmin+Δα),[β max−Δβ,β max))3.1.2. Generation of image sequencesAccording to the projection method, projected images of the sameobject may differ due to differences among viewpoints. In our model,the projection viewpoint is determined by the position of the scanner.Due to occlusion, some valuable tree structural information will belost in the process of projection. Thus, two scans with different view-points may be similar in 3D space, but their projected images may differgreatly, which can be an obstacle in identifying corresponding pointsbetween scans.
Fig. 6.Sliced points from a tree point-cloud. Q3, Q2, and Q1 are quartiles of tree height.
Fig. 7.Separation results. (a) Overview. (b) Close-up view of the connected part (within green rectangular box). (c) Close-up view of nine adjacent points i n the connected part. Blue, yellow, and green points correspond to the angle pairs ( α,β), (α+Δα,β), and (α+Δα,β+Δβ), respectively.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
180To solve this problem, we continuously rotated the tree point-cloudin 3D space prior to projection, which is equivalent to continuallychanging the viewpoint. In the rotation step, the mean values
x,yof the X and Y coordinates of all points in the scan were ﬁrst calculated. We then continuously rotated the points by a certain degree aroundthe axis, which is perpendicular to the xyplane and passes through the point (
x,y, 0). As a result, a sequence of images was generated foreach scan (Fig. 5).The number of rotations required is determined by the number ofscans n and the rotation degreeθ. In our experiments, the rotation de-greeθwas typically 10° and the rotation number was
720n/C2θ(rotation ob- tained from/C0
360nto360n).3.1.3. Feature-point matchingDue to the lack of detailed texture information available in binaryimages, we used the ORB (oriented FAST and rotated BRIEF) algorithmto detect and match feature points (Rublee et al., 2011). This method is faster and more suitable for less complicated images than methodssuch as the SURF (speeded up robust feature) or SIFT (scale invariantfeature transform) algorithms (Bay et al., 2006;Lowe, 2004). The com- bination of the oriented FAST key point detector and rotated BRIEF de-scriptor makes the ORB algorithm scale- and rotation-invariant.The feature point matching algorithm should be applied on the pairof images with similar shapes that can reﬂect the overlapping areas be- tween adjacent scans. Toﬁnd the similar image pairs, we calculated thesimilarity of every two images between the two image sequences andselected the pairs of high similarity. The method of similarity calculationis based on the idea of the image hashing algorithm which constructsﬁngerprints that uniquely identiﬁes the content of the images.(Venkatesan et al., 2000). A simple code was utilized to construct theﬁngerprints of binary images, in which pixel value 255 corresponds to1 in the code, and pixel value 0 corresponds to 0. The hamming distancebetween the codes of the images were calculated to estimate theirsimilarity.The key points in three pairs of similar images from adjacentscans were extracted and described using ORB. In each image pair,we selected thek(k≥4) pairs of matching points with the highestscores.3.1.4. Transformation calculationsOnce the matching points in images were determined, we were ableto map the points to their corresponding 3D points in the tree point-cloud. First, we determined the intervals, [α
l,αh] and [β l,βh], of each matching point based on its pixel coordinates. All scanning points
Fig. 8.Complete simulated tree point-clouds for the experiment. (a) Simulated tree A. (b) Simulated tree B. Red, sliced branch parts. (c) Cross-sections of branches at a given height in a well-registered tree point-cloud. (d) Cross-sections of branches at a given height in a poorly registered tree point-cloud.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
181with a corresponding pair of angles (α,β) within these intervals were then extracted. The central point O among the extracted points wascalculated and used as the tie point in 3D space. After obtaining morethan four pairs of tie points in adjacent scans, a rough rigid-body trans-formation matrix between scans was calculated using singular-valuedecomposition (SVD) (Challis, 1995).3.2. Fine registrationCoarse registration roughly aligns the postures of adjacent scans andprovides a better initial position for subsequent ﬁne registration. How- ever, obvious dislocation and separation remain between adjacentscans after coarse registration. Therefore, it is necessary to improvethe transformation matrix inﬁne registration. Theﬁne registration process includes three parts: point-cloud slicing, point separation, andcircle and cylinderﬁtting.3.2.1. Point-cloud slicingQualiﬁed tie points are the basis for the calculation of accuratetransformation parameters inﬁne registration. For a single scan ofa single tree, the point cloud is incomplete, and it is dif ﬁcult to ﬁnd tie points directly based on tree structure. In our method, wesliced points from the stem and branch parts of the tree andextracted the center points of stems and branches for use as tiepoints by applying circle- and cylinder- ﬁtting methods to the sliced points. We sliced the points at quartiles of tree height and obtainedthree layers of points. Each layer was sliced to a thickness of 10 cm(Fig. 6).Different slicing heights result in differences in the number, distribu-tion, and relative position of the sliced points in the layer. Points inlower layers are generally all extracted from the stem. However, mostpoints in high layers are extracted from branches. The stem is usually
Fig. 9.Slicing results for one branch. (a) Three sliced layers of branch B in simulated tree B.Red and blue points indicate scans 1 and 2, respectively. (b) Corresponding center-pointextraction results for the three sliced layers of branch B. D1, D2, D3 indicate distances be-tween the pairs of corresponding points.
Fig. 10.Feature-point matching results. (a) Results of scan 2 to scan 1 for simulated tree A. (b) results of scan 3 to scan 1 for simulated tree A. (c) Results of sc an 2 to scan 1 for simulated tree B. (d) Results of scan 3 to scan 1 for simulated tree B.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
182perpendicular to the ground and its horizontal cross section is roughlytreated as a circle. Thus, the center of the stem can be estimated via cir-cleﬁtting. Branches are often at an oblique angle to the stem and theirhorizontal sections are similar to ellipsoids. Given that the geometricstructure of branches in 3D space is similar to that of cylinders, weused a cylinder-ﬁtting method to estimate the center points of thebranches.3.2.2. Point separationEvery sliced-point layer contains several arcs of points corre-sponding to branches and the stem. Before applying ﬁtting methods, we shouldﬁrst separate these arcs of points. Because the angular stepof the TLS isﬁxed, whether two points are consecutive can be judgedfrom the distance between their corresponding angles αandβ (Fig. 3). Based on the horizontal and vertical angular step widths —φ andϕ—of the TLS instrument, we separated the points by judgingtheir connectivity (Bu and Wang, 2016) .T h ep o i n t si na na r ca r e consecutive, and the distance between the angles —ΔαandΔβ— corresponding to each pair of adjacent points should equal φandϕ, respectively, under ideal conditions ( Fig. 7c). Because discontinuity can be caused by scanning errors or unusual tree structures, wedetermined the consecutive nature of two points by comparing Δα andΔβto 3φand 3ϕ, respectively. By examining distances betweenpoints, the method identiﬁed all connected areas and separated allsliced-point arcs (Fig. 7).3.2.3. Circle and cylinderﬁttingAmong the three sliced layers, the lowest layer usually contains onlyone arc, corresponding to the stem. For the stem section, the circle-center position (X
0,Y0) was extracted as the center of the stem byapplying the Taubin method (Taubin, 1991). For sections of branches in higher layers, we determined centerpoints by cylindricalﬁtting based on the least squares method(Shakarji, 1998). In theﬁtted cylinder, we obtained the direction vectorof the central axis (a,b,c), a starting point on the axis (x
0,y0,z0), and radius R.The axis of the branches could describe the tree to some extent ( Eysn et al., 2013). Thus, the starting point and a point one distance unit awayfrom it in the positive direction of the axis were used as tie points. Thepositive direction of the axis was deﬁned as the direction in which the Z coordinate of the point increases. For stem points, the center of theﬁtted circle was regarded as a tie point.
Fig. 11.Coarse registration results. (a) Registration result between scan 2 and scan 1 forsimulated tree A. (b) Registration results between scan 3 and scan 1 added to resultsfrom (a). (c) Registration results between scan 2 and scan 1 for simulated tree B.(d) Registration results between scan 3 and scan 1 added to results from (c). Green, red,and blue points indicate scans 1, 2, and 3, respectively.
Fig. 12.Fine registration results. (a) Registration results between scan 2 and scan 1 for sim-ulated tree A. (b) Registration results between scan 3 and scan 1 added to results from (a).(c) Registration results between scan 2 and scan 1 for simulated tree B. (d) Registration re-sults between scan 3 and scan 1 added to results from (c). Green, red, and blue points in-dicate scans 1, 2, and 3, respectively.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
183As a result, we obtained a group of corresponding tie points with po-sitions at different positions in the tree based on the search of nearestneighbour. Based on these tie points, transformation parameters werecalculated forﬁne adjustment inﬁne registration.3.3. Accuracy evaluation methodTo evaluate our registration results, we developed an simple evalua-tion model to quantitatively estimate registration accuracy. Point cloudsof simulated Trees A and B contained many branch parts ( Fig. 8). Accu- rate registration would align corresponding branches between adjacentscans; the cross-section of a branch in a well-registered tree should bean ellipse or a circle. However, poor registration often results inbranches that appear to be aligned correctly, but have cross-sectionscomposed of several separate arcs. Thus, the alignment accuracy of cor-responding branches between adjacent scans can be used to evaluateregistration accuracy.In our evaluation model, we extracted corresponding branches be-tween adjacent scans to calculate registration error. For each pair of cor-responding branches, we sliced three pairs of layers from the bottom,middle, and top of the corresponding branches. Points in these layerswere used for cylinderﬁtting to estimate their center axes. By extractingpoints with the same z-values on the corresponding axes of each layerpair, we obtained three pairs of corresponding center points ( Fig. 9). Calculating the distances between these pairs of center points canfacilitate the estimation of registration error between adjacent scans,as follows:
d¼d1þd2þd3⋯þd n
n ð8ÞWhered
1,d2,…,d nare the distances of corresponding center points,n is the number of pairs of corresponding points, and average distance d is treated as registration error.4. Experimental resultsSince two kinds of tree point clouds were used in the experiment,the results were demonstrated separately. And the results of coarse reg-istration,ﬁne registration and ICP registration were evaluated using theproposed evaluation model in 3.3 subsection.4.1. Results of simulated tree point clouds4.1.1. Coarse registrationAs shown inFig. 1, each simulated tree was composed of three scans.In the registration procedure, the local coordinate system of the ﬁrst scan of each simulated tree was used as a reference coordinate system,and the registration order was scan 2 to scan 1, and scan 3 to scan 1.Similar image pairs between image sequences from adjacent scanswere matched; the results of feature-point matching for two simulated
Fig. 13.Registration accuracy for simulated tree A. (a) Registration accuracy for scan 2 to scan 1. (b) Registration accuracy for scan 3 to scan 1.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
184trees are shown inFig. 10. In each group of adjacent scans, three similarimage pairs were selected for application of the ORB algorithm; 15matching points were obtained.The coarse registration results are shown in Fig. 11. Corresponding stems and branches between adjacent scans of both simulated treeswere either crisscrossed or separate after coarse registration; i.e., not ac-curately aligned. Although registration errors cannot be ignored, coarseregistration correctly matched corresponding stems and branches be-tween adjacent scans and transformed the target scan to a good initialposition forﬁne registration. Coarse registration is also completelyautomatic and marker-free, which expands the potential ﬁelds for its application.4.1.2. Fine registrationBased on target-scan initial positions, the center points of corre-sponding stems and branches between adjacent scans were extractedas tie points to achieve better alignment in ﬁne registration. Fine regis- tration results for the two simulated trees are shown in Fig. 12. The re- sults indicate that contours of the stem and branches were completeand that a complete simulated tree could be composed from threescans. Alignment between adjacent scans was more accurate after ﬁne registration.Because multiple layers at different heights are sliced to facilitate theextraction of corresponding tie points,ﬁne registration not only en- hances the accuracy of coarse registration, but also achieves betteralignment of branch and stem parts between adjacent scans than ﬁne registration via stem-centerﬁtting methods.4.1.3. Evaluating registration resultsTo evaluate the registration accuracy of the two simulated trees,all corresponding branches between adjacent scans were extractedto calculate the corresponding center points and their distances.Branch section numbers for simulated trees A and B are shown inFig. 8a and b. In our practice, absolutely unreasonable registrationresults got when we registering the tree point clouds directly witht h eI C Pa l g o r i t h m .D u et ot h eh i g h computational demand for the initial positions of adjacent scans, the ICP algorithm was only usedinﬁne registration stage for comparison to ensure that the compari-son was meaningful. The accuracy results of the coarse registration,ﬁne registration and ICP registration for each simulated tree areshown inFigs. 13 and 14.These results demonstrate thatﬁne registration errors were muchsmaller than those of coarse registration and that smaller ﬂuctuations occurred among registration errors for branches. The ICP algorithmlargely depends on the initial position of the point clouds, especiallyfor adjacent scans with low-overlap areas. In most situations in our ex-periments, the ICP method exhibited no clear improvement comparedwith coarse registration, and registration errors even increased afterICPﬁne registration. However, when coarse registration accuracy wasrelatively high, ICPﬁne registration enhanced registration accuracy, asshown by the registration results of scan 2 to scan 1 for simulated treeB(Fig. 14a).To evaluate the error quantitatively, Table 2shows the calculated mean registration errors of coarse registration, ﬁne registration and ICP registration. The average coarse registration error is about 0.204
Fig. 14.Registration accuracy for simulated tree B. (a) Registration accuracy for scan 2 to scan 1. (b) Registration accuracy of scan 3 to scan 1.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
185m, and the averageﬁne registration error is about 0.026 m. Meanwhile,the the average registration error of ICP is about 0.187 m, which is moreseven times of the proposed method.4.2. Results of real-tree point cloudsSix group of real-world tree point clouds were processed using theproposed method. The results of coarse registration and ﬁne registration are shown inFig. 15.I ne a c hs u b -ﬁgure, the coarse registration result ison the left, and theﬁne registration result is on the right. Three pointclouds scanned from different viewpoints are demonstrated in red,green and blue colors respectively. Apparently, the results of ﬁne registra- tion are better than coarse registration, especially at the part of branches.To evaluate the registration accuracy, corresponding branches be-tween adjacent scans were extracted out to calculate the registrationerror in each group based on previous evaluation model. The mean ac-curacy errors of the coarse andﬁne registrations for each group wereshown inTable 3.As shown inTable 3, the average coarse registration error isabout 0.325 m, and the averageﬁne registration error is about 0.049 m. Both coarse andﬁne registration errors of real-world treepoint clouds are larger than that of simulated trees. But the errorsare still acceptable for a marker-free registration method of treepoint clouds.5. Discussion5.1. Veriﬁcation of feature-point matchingIn the proposed algorithm, coarse registration provided the initialposition of the point cloud, which played an important role in the suc-cess ofﬁne registration. In coarse registration, the matching accuracyof similar images determines tie-point quality and directly affectscoarse-registration accuracy. However, due to the lack of texture infor-mation in binary images, wrong matching points cannot be avoided infeature-point matching (Fig. 11).With fewer pairs of matching points, the impact of wrong matchingpoints on the estimation of the transformation matrix between adjacentscans is greater. To enhance matching accuracy, veri ﬁcation of point pairs is performed to eliminate bad matches. Each pair of points(P
1,P2) corresponds to a pair of intervals of angles αandβ,w h i c h corresponds to the 3D spaceσ
1,σ2. In a correct matching-point pair,the relative position ofσ
1in the tree point-cloudPC 1is roughly equivalent to the relative position ofσ
2in the tree point-cloudPC 2. Given that the tree is composed of different parts in the verticaldirection and can be roughly divided into the crown, limb, and stemfrom top to bottom, the correct matching-point pair should be in thesame part of the tree. For example, a point in the crown should bematched to a point in the crown. Thus, the correctness of matching-point pairs can be veriﬁed by comparing their corresponding intervalsof angleβ, which indicate their position in the vertical direction.Suppose that each pair of matching points corresponds to the inter-vals [β
1k,β1k+2ϕ] and [β 2k,β2k+2ϕ](k=1 ,2 ,…, 15), where 15 is the number of pairs of matching points to be checked. We can then calculatethe distancedk=|β 1k–β2k| and obtain the mean value dkand standard deviationσ
dofd k. A point pair whosed kvalue is not within
dk/C0σ d,dkþσ d/C16/C17will be excluded as a bad pair from potentialmatching points.
Fig. 15.Registration results of six trees. The registration order is scan 2 to scan 1, scan 3 toscan 1. In each sub-ﬁgure, the left one is the coarse registration result, and the right one istheﬁne registration result. Green, red, and blue points indicate scans 1, 2, and 3, respec-tively. (a) Tree1. (b) Tree2. (c) Tree3. (d) Tree4. (e) Tree5. (f) Tree6.Table 2The errors of registration of simulated tree A and simulated tree B.Registration errors(m) Coarse registration Fine registration ICP registrationSimulated Tree A 2–1 0.164 0.024 0.183Simulated Tree A 3–1 0.205 0.023 0.207Simulated Tree B 2–1 0.122 0.028 0.062Simulated Tree B 3–1 0.324 0.030 0.296Note:2–1 means the registration order “Scan 2 to Scan 1”,3–1 means the registration order“Scan 3 to Scan 1”.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
1865.2. Improvement of point separationThe separation ofﬁne-registration sliced points can be inﬂuenced by tree structure. In this study, points were sliced at quartiles of tree height.Fig. 16. shows an example in which parts of the stem and branches areclose at these speciﬁc heights. Due to the small distances betweenbranches at height Q2, the sliced points of different branchesintersected. Our method these considered intersected sliced points asa single connected part. Therefore, the corresponding sliced pointscould not be correctly separated (Fig. 16b).One method to improve our approach is to verify the correctness ofseparated parts. Points in rectangle S2 in Fig. 16bc o n t a i n e dt h r e ea r c s , which roughly compose an arc with the largest radius among all arcs.In most single trees, the thickness of stems and branches tends to de-crease as height increases, such that lower parts of the stem or branchesare often thick and higher parts are thinner. Therefore, the radius of alower part of a stem or branch should be larger than that of a higherpart. According to this rule, we can verify the correctness of a separatedpart by checking its corresponding radius after ﬁtting. For example, by applying aﬁtting method, we obtained radiusr
1of the separated part shown inFig. 16c and radiusr
2of separated part S2 inFig. 16b. Asr 2
was larger thanr 1r1, S2 was considered an incorrect result and wasexcluded from further registration procedures.5.3. Limitations of the proposed methodThree limitations need to be considered and studied further forthe proposed method. First, the rotation of large amount of points istime-consuming. In our proposed method, tree point clouds wererotated continuously in 3D space prior to projection to improve thepossibility of detecting similar image pairs from the correspondingimages in adjacent scans. The number and degree of rotations shouldbe further optimized to reduce redundancy. Second, feature-point-matching results were not stable, especially for trees with complexgeometric structures. When there are many asymmetric structuresin a tree, the extraction of sufﬁcient correct matching-point pairswill be challenging. Third, theﬁne registration will be affected bybranch characteristics. Slim tree branches, high branch density andmore horizontal branch direction may increase the dif ﬁculty of accu- rate circleﬁtting and cylinderﬁtting, which will result in the decreaseof registration accuracy.6. ConclusionTree point cloud registration is fundamental and important to for-estry research and tree structure analysis. The study proposed an auto-matic registration method that uses a coarse-to- ﬁne strategy to register multiple scans of a single tree without the aid of arti ﬁcial reﬂectors. The proposed method is veriﬁed as a feasible and effective automatic regis-tration method using two simulated and six real tree point clouds. Theautomated and marker-free registration method provides a new wayto assist the tree structure analysis.In the future work, we will concentrate on improving the matchingaccuracy of tie points, and accelerating the pipeline by further optimiz-ing the matrix computations of rotation process. Meanwhile, we willalso make efforts to increase the robustness of the method, and try toapply the method to handle more complicated geometric tree struc-tures in natural scenes.CRediT authorship contribution statementXiuxian Xu:Conceptualization, Methodology, Validation, Software,Visualization, Writing–original draft, Writing–review & editing.Pei Wang:Conceptualization, Methodology, Validation, Software, Visuali-zation, Writing–original draft, Writing–review & editing.Xiaozheng Gan:Data curation, Investigation.Jingqian Sun:Writing–review & editing.Yaxin Li:Data curation, Investigation.Li Zhang:Resources. Qing Zhang:Resources.Mei Zhou:Resources.Yinghui Zhao:Re- sources.Xinwei Li:Data curation, Investigation.
Fig. 15(continued).
Table 3The registration errors of the tree point clouds.Tree Number Coarse registration(m) Fine registration(m)Tree1 0.225 0.041Tree2 0.321 0.048Tree3 0.351 0.050Tree4 0.396 0.057Tree5 0.382 0.053Tree6 0.274 0.046
Fig. 16.Point-cloud slicing and separation results. (a) Point-slicing results. Q1, Q2, and Q3are quartiles of tree height. (b) Separation of points sliced at Q2. (c) Separation of pointssliced at Q1.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
187Declaration of Competing InterestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to in ﬂu- ence the work reported in this paper.AcknowledgmentsThis research is funded by the Fundamental Research Funds for theCentral Universities (No.2021ZY92), National Students' innovation andentrepreneurship training program (No. 201710022076) and the StateScholarship Fund from China Scholarship Council (CSC No.201806515050).References
Aiger, D., Mitra, N.J., Cohen-Or, D., 2008. 4-points Congruent Sets for Robust Pairwise Sur-face Registration. ACM SIGGRAPH 2008 papers on - SIGGRAPH ’08 27, 1.https://doi. org/10.1145/1399504.1360684 . Aschoff, T., Spiecker, H., 2004. Algorithms for the automatic detection of trees in laserscanner data. Int. Arch. Photogramm. Remote. Sens. Spat. Inf. Sci. 36, W2.Bailey, B.N., Ochoa, M.H., 2018. Semi-direct tree reconstruction using terrestrial LiDARpoint cloud data. Remote Sens. Environ. 208, 133 –144.https://doi.org/10.1016/j.rse. 2018.02.013.Bay, H., Tuytelaars, T., Van Gool, L., 2006. Surf: speeded up robust features. Eur. Conf. Comp. Vision. 404–417.Besl, P.J., McKay, N.D., 1992.Method for registration of 3-D shapes. Sensor Fusion IV: Con-trol Paradigms and Data Structures, pp. 586 –606. Bienert, A., Maas, H.-G., 2009.Methods for the automatic geometric registration of terres-trial laser scanner point clouds in forest stands. ISPRS Int. Arch. Photogramm. Rem.Sens. Spat. Inf. Sci 93–98.Böhm, J., Becker, S., 2007.Automatic marker-free registration of terrestrial laser scansusing reﬂectance, in. Proceedings of the 8th Conference on Optical 3D MeasurementTechniques, Zurich, Switzerland, pp. 9 –12. Brenner, C., Dold, C., Ripperda, N., 2008. Coarse orientation of terrestrial laser scans inurban environments. ISPRS J. Photogramm. Remote Sens. 63, 4 –18.https://doi.org/ 10.1016/j.isprsjprs.2007.05.002 . Bu, G., Wang, P., 2016.Adaptive circle-ellipseﬁtting method for estimating tree diameter based on single terrestrial laser scanning. J. Appl. Remote. Sens. 10, 26040.Bucksch, A., Khoshelham, K., 2013. Localized registration of point clouds of botanic trees.IEEE Geosci. Remote Sens. Lett. 10, 631 –635.https://doi.org/10.1109/LGRS.2012. 2216251.Challis, J.H., 1995.A procedure for determining rigid body transformation parameters.J. Biomech. 28, 733–737.Dassot, M., Constant, T., Fournier, M., 2011. The use of terrestrial LiDAR technology in for- est science: applicationﬁelds, beneﬁts and challenges. Ann. For. Sci. 68, 959 –974. Dubayah, R.O., Drake, J.B., 2000. Lidar remote sensing for forestry. J. For. 98, 44 –46. Eysn, L., Pfeifer, N., Ressl, C., Hollaus, M., Gra ﬂ, A., Morsdorf, F., 2013. A practical approach for extracting tree models in forest environments based on equirectangular projec-tions of terrestrial laser scans. Remote Sens. 5, 5424 –5448.https://doi.org/10.3390/ rs5115424.Henning, J.G., Radtke, P.J., 2006. Detailed stem measurements of standing trees fromground-based scanning lidar. For. Sci. 52, 67 –80. Henning, Jason G., Radtke, P.J., 2008a. Multiview range-image registration for forestedscenes using explicitly-matched tie points estimated from natural surfaces. ISPRSJ. Photogramm. Remote Sens. 63, 68 –83.https://doi.org/10.1016/j.isprsjprs.2007.07. 006.Henning, Jason G., Radtke, P.J., 2008b.Multiview range-image registration for forested scenes using explicitly-matched tie points estimated from natural surfaces. ISPRSJ. Photogramm. Remote Sens. 63, 68 –83. Hilker, T., Coops, N.C., Culvenor, D.S., Newnham, G., Wulder, M.A., Bater, C.W., Siggins, A.,2012. A simple technique for co-registration of terrestrial LiDAR observations for for-estry applications. Remote Sens. Lett. 3, 239 –247.https://doi.org/10.1080/01431161. 2011.565815.Hopkinson, C., Chasmer, L., Young-Pow, C., Treitz, P., 2004. Assessing forest metrics with a ground-based scanning lidar. Can. J. For. Res. 34, 573 –583. Lowe, D.G., 2004.Distinctive image features from scale-invariant keypoints. Int. J. Comput.Vis. 60, 91–110.Marzulli, M.I., Raumonen, P., Greco, R., Persia, M., Tartarino, P., 2020. Estimating tree stemdiameters and volume from smartphone photogrammetric point clouds. Forestry(Lond).https://doi.org/10.1093/forestry/cpz067 . Mokroš, M., Liang, X., Surový, P., Valent, P., Čerňava, J., Chudý, F., Tunák, D., Salo ň,Š., Merganič, J., 2018. Evaluation of close-range photogrammetry image collectionmethods for estimating tree diameters. ISPRS Int. J. Geo Inf. 7. https://doi.org/10. 3390/ijgi7030093.Pfeifer, N., Gorte, B., Winterhalder, D., Sensing, R., Range, C., 2004. Automatic Reconstruc- tion of Single Trees from TLS Date 1 –6. Popescu, S.C., 2007.Estimating biomass of individual pine trees using airborne lidar. Bio-mass Bioenergy 31, 646–655.Popescu, S.C., Wynne, R.H., Nelson, R.F., 2003. Measuring individual tree crown diameter with lidar and assessing its inﬂuence on estimating forest volume and biomass. Can. J. Remote. Sens. 29, 564–577.Raumonen, P., Kaasalainen, M., Markku, Å., Kaasalainen, S., Kaartinen, H., Vastaranta, M.,Holopainen, M., Disney, M., Lewis, P., 2013. Fast automatic precision tree modelsfrom terrestrial laser scanner data. Remote Sens. 5, 491 –520.https://doi.org/10. 3390/rs5020491.Rublee, E., Rabaud, V., Konolige, K., Bradski, G.R., 2011. ORB: An efﬁcient alternative to SIFT or SURF. ICCV, p. 2.Rusinkiewicz, S., Levoy, M., 2001. Efﬁcient variants of the ICP algorithm. 3dim, pp. 145–152.Shakarji, C.M., 1998.Least-squaresﬁtting algorithms of the NIST algorithm testing system. J. Res. Nat. Inst. Stand. Technol. 103, 633.Taubin, G., 1991.Estimation of planar curves, surfaces, and nonplanar space curves de-ﬁned by implicit equations with applications to edge and range image segmentation.IEEE Trans. Pattern Anal. Machine Intell. 1115 –1138. Thies*, M., Pfeifer, N., Winterhalder, D., Gorte, B.G.H., 2004. Three-dimensional recon- struction of stems for assessment of taper, sweep and lean based on laser scanningof standing trees. Scand. J. For. Res. 19, 571 –581.
Venkatesan, R., Koon, S.-., Jakubowski, M.H., Moulin, P., 2000. Robust image hashing. Pro-ceedings 2000 International Conference on Image Processing (Cat. No.00CH37101),Vancouver, BC, Canada. vol. 3, pp. 664 –666.https://doi.org/10.1109/ICIP.2000. 899541.Wulder, M.A., Bater, C.W., Coops, N.C., Hilker, T., White, J.C., 2008. The role of LiDAR in sus- tainable forest management. For. Chron. 84, 807 –826. Zhang, W., Chen, Y., Wang, H., Chen, M., Wang, X., Yan, G., 2016. Ef ﬁcient registration of terrestrial LiDAR scans using a coarse-to- ﬁne strategy for forestry applications. Agric. For. Meteorol. 225, 8–23.https://doi.org/10.1016/j.agrformet.2016.05.005 . Zhou, Guiyun, Wang, Bin, Zhou, Ji, 2014. Automatic registration of tree point clouds fromterrestrial LiDAR scanning for reconstructing the ground scene of vegetated surfaces.IEEE Geosci. Remote Sens. Lett. 11, 1654 –1658.https://doi.org/10.1109/lgrs.2014. 2314179.X. Xu, P. Wang, X. Gan et al. Artiﬁcial Intelligence in Agriculture 6 (2022) 176 –188
188