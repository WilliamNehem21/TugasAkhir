Sparse representation of 3D images for piecewise dimensionality reductionwith high quality reconstruction
Laura Rebollo-Neira*, Daniel Whitehouse
Mathematics Department, Aston University, B47ET, Birmingham, UK
ARTICLE INFO
Keywords:Image representation with dictionariesGreedy pursuit algorithmsABSTRACT
Sparse representation of 3D images is considered within the context of data reduction. The goal is to produce highquality approximations of 3D images using fewer elementary components than the number of intensity points inthe 3D array. This is achieved by means of a highly redundant dictionary and a dedicated pursuit strategyespecially designed for low memory requirements. The bene ﬁt of the proposed framework is illustrated in the ﬁrst instance by demonstrating the gain in dimensionality reduction obtained when approximating true color imagesas very thin 3D arrays, instead of performing an independent channel by channel approximation. The full powerof the approach is further exempliﬁed by producing high quality approximations of hyper-spectral images with a reduction of up to 371 times the number of data points in the representation.
1. IntroductionSparse representation of 2D images has been a subject of extensiveresearch in the lastﬁfteen years[1–3]. Applications which beneﬁt from sparsity range from image restoration [4,5]and classiﬁcation[6–8]to feature extraction[9,10]and super resolution reconstructions [11,12]. While sparse representation of 3D arrays has received less attention, theadvantage of modeling these arrays as a superposition of 3D elementarycomponents is recognized in previous publications [13–16]. At present, the most widely used multichannel images in every daylife are true color images. The simplest way of sparsely representing theseimages is channel by channel, or adding constraints of correlation acrosscolors[4,17]. However, as demonstrated in this work, sparsity in therepresentation of true color images can increase substantially if theapproximation is realized by means of 3D elements taken from a highlyredundant dictionary. The effect is of course more pronounced for arraysinvolving more channels, such as hyper-spectral images.From a practical view point, the current drawbacks of 3D sparsemodeling using a large dictionary are (i) storage requirements and (ii) thecomplexity of the concomitant calculations. In this paper we propose amethod which, by addressing (i) leaves room for possible high perfor-mance implementations using Graphics Processing Unit (GPU) pro-gramming. While the approach is illustrated using Central ProcessingUnit (CPU) programming, the storage requirements are shown to ﬁt within 48 Kb's of fast access shared memory of a GPU when theapproximation of a 3D image is realized with a partition block size of8/C28/C28 and with a separable dictionary of redundancy 125.The main contributions of the paper are listed below./C15The low memory implementation of the Orthogonal Matching Pursuit(OMP) strategy, called Self Projected Matching Pursuit (SPMP) [18]is dedicated to operating in 3D (SPMP3D) with separable dictionaries.This technique delivers an iterative solution to the 3D least squaresproblem which requires much less storage than direct linear algebramethods. It could therefore be also applied with any other of thepursuit strategies that include a least squares step [14,19–22]. /C15The CþþMEXﬁle for the SPMP3D method has been made availableon a dedicated website[23]. All the scripts for reproducing the resultsof the paper in the MATLAB environment have also been placed onthat website./C15Remarkable reduction in the dimensionality of the representation oftrue color images and hyper-spectral images, with high qualityreconstruction, is demonstrated using highly redundant and highlycoherent separable dictionaries.The results suggest that the method may be of assistance to imageprocessing applications which rely on a transformation for data reductionas aﬁrst step of further processing. For examples of relevant applicationswe refer to Refs.[24–28].
* Corresponding author.E-mail address:rebollol@aston.ac.uk(L. Rebollo-Neira).
Contents lists available atScienceDirect
Array
journal homepage:www.elsevier.com/journals/array/2590-0056/open-access-journal
https://doi.org/10.1016/j.array.2019.100001Received 10 February 2019; Received in revised form 17 April 2019; Accepted 29 May 2019Available online 20 June 20192590-0056/©2019 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).Array 1-2 (2019) 1000012. Notational conventionRrepresents the set of real numbers. Boldface letters are used toindicate Euclidean vectors, 2D and 3D arrays. Standard mathematicalfonts indicate components, e.g.,d2R
Nis a vector of componentsdðiÞ2R; i¼1;…;N. The elements of a 3D arrayI2R
Nx/C2Ny/C2Nzare indicated asIði;j; mÞ;i¼1;…;N
x;j¼1;…;N y;m¼1;…;N z. Moreover, for eachm-value I
m2RNx/C2Nystands for the 2D array of elementsI mði;jÞ¼Iði;j;mÞ;i¼1;…; N
x;j¼1;…;N y, which, when not leaving room for ambiguity will also berepresented asIð:;:;mÞ. The transpose of a matrix,Gsay, is indicated as G
>.The inner product between 3D arrays, say I2R
Nx/C2Ny/C2NzandG2 R
Nx/C2Ny/C2Nz, is given as:DG;Ii
3D¼XNx
i¼1XNy
j¼1XNz
m¼1Gði;j;mÞIði;j;mÞ:ForG2R
Nx/C2Ny/C2Nzwith tensor product structure, i.e. forG¼gx/C10gy/C10 g
z, withgx2RNx;gy2RNyandgz2RNz, we further have/C10G;Ii
3D¼XNz
m¼1hgx;Imgy/C11gzðmÞ¼hp;gz/C11;(1)where for each value ofmthe vectorI
mgy2RNxarises by the standard matrix-vector multiplication rule andp2R
Nzis given by its components pðmÞ¼hg
x;Imgyi;m¼1;…;N z. Note thathp;gziindicates the Euclidean inner product in 1D, i.e./C10p;g
zi¼XNz
m¼1pðmÞgzðmÞ:The deﬁnitionð1Þinduces the normI
3D¼ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃhI;Ii3Dp.3. Sparse representation of multi-channel imagesSuppose that a 3D image, given as an array I2R
Nx/C2Ny/C2Nzof intensity pixels, is to be approximated by the linear decompositionI
k¼Xkn¼1cðnÞD ℓn; (2)where eachcðnÞis a scalar and eachD
ℓnis an element ofRNx/C2Ny/C2Nzto be selected from a set,D¼fD
ngMn¼1, called a‘dictionary’. A sparse approximation ofI2R
Nx/C2Ny/C2Nzis an approximation of the form (2) such that the numberkof elements in the decomposition issigniﬁcantly smaller thanN¼N
xNyNz. The terms in the decomposition (2) are taken from a large redundant dictionary, from where the elementsD
ℓnin (2), called‘atoms’, are chosen according to an optimality criterion.Within the redundant dictionary framework for approximation, theproblem ofﬁnding the sparsest decomposition of a given multi-channelimage can be formulated as follows: Given an image and a dictionary, approximate the image by the ‘atomic decomposition’(2) such that the number k of atoms is minimum.Unfortunately, the numerical minimizationof the number of terms to produce an approximation up to a desirederror, involves a combinatorial problem for exhaustive search. Hence, thesolution is intractable. Consequently, instead of looking for the sparsestsolution, one looks for a ‘satisfactory solution’, i.e., a solution such that the number ofk-terms in (2) is considerably smaller than the imagedimension. For 2D images this can be effectively achieved by greedypursuit strategies in the line of the Matching Pursuit (MP) [29]and OMP [30]methods, if dedicated to 2D separable dictionaries [14,18,32,33]. Within a tensor product framework the consideration of OMP in 3D isnatural.Let's assume that a 3D dictionary is obtained as the tensor productD¼Dx/C10Dy/C10Dzof three 1D dictionariesDx¼fdxm2RNxgMx
m¼1, D
y¼fdym2RNygMy
m¼1, andDz¼fdzm2RNzgMz
m¼1, withM xMyMz¼M. For computational purposes the 1D dictionaries are stored as threematricesD
x2RNx/C2M x,Dy2RNy/C2M yandDz2RNz/C2M z. Suppose now that a 3D arrayI2R
Nx/C2Ny/C2Nzis to be approximated by an atomic decompositionof the formI
k¼Xkn¼1cðnÞdx
ℓxn/C10dy
ℓyn/C10dz
ℓzn; (3)where forn¼1;…;kthe atomsd
x
ℓxn,dy
ℓynanddz
ℓznare selected from the given 1D dictionaries. The common step of the techniques we consider forconstructing approximations of the form (3) is the stepwise selection ofthe atoms in the atomic decomposition. On setting k¼1andI
0¼0at iterationkthe algorithm selects the indices
ℓxk,ℓykandℓzkas follows
ℓxk;ℓyk;ℓzk¼arg max
n¼1;…;M xi¼1;…;M ys¼1;…;M z/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C10d
xn/C10dyi/C10dzs;Rk/C01i3D/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12;(4)
withR
k/C01¼I/C0Ik/C01. It is the determination of the coefﬁcientscðnÞ;n¼ 1;…;kin (3) that gives rise to pursuit strategies which go with differentnames.3.1. Matching Pursuit in 3D (MP3D)The MP approach in 3D would simply calculate the coef ﬁcients in (3) ascðnÞ¼Dd
x
ℓxn/C10dy
ℓyn/C10dz
ℓzn;Rn/C01i3D;n¼1;…;k:(5) The main drawback of the MP method is that it may select linearlydependent atoms. Moreover, that approximation is not stepwise optimalbecause at iterationkthe coefﬁcients (5) do not minimize the norm of theresidual error. The pursuit strategy that overcomes these limitations isthe so called OMP[30].3.2. Orthogonal Matching Pursuit in 3DThe implementation of OMP in 3D (OMP3D) we describe here is the3D extension of the implementation of OMP in 2D given in Ref. [32].A n alternative algorithm called Kronecker-OMP, which is based on theTucker representation of a tensor, is discussed in Ref. [14]. Our algorithm is based on adaptive biorthogonalization and Gram-Schmidt orthogo-nalization procedures, as proposed in Ref. [31]for the one dimensional case.In order to ensure the coefﬁcientscðnÞ;n¼1;…;kinvolved in (3) are such that/C13/C13R
k/C13/C1323D¼hRk;Rki3Dis minimum, the decomposition (3) shouldfulﬁll thatI
k¼Xkn¼1cðnÞdx
ℓxn/C10dy
ℓyn/C10dz
ℓzn¼bPVkI;(6)wherebP
Vkis the orthogonal projection operator onto V k¼ spanfd
x
ℓxn/C10dy
ℓyn/C10dz
ℓzngkn¼1. This is ensured by requiring thatRk¼I/C0bP
VkI. The required representation ofbP Vkis of the formbP VkI¼Pkn¼1Anh B
kn;Ii3D, where eachA n2RNx/C2Ny/C2Nzis an array with the selected atomsA
n¼dx
ℓxn/C10dy
ℓyn/C10dx
ℓzn. The concomitant biorthogonal reciprocal set Bkn; n¼1;…;kcomprises the unique elements ofR
Nx/C2Ny/C2Nzsatisfying theL. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
2conditions:i)hA
n;Bkmi3D¼δ n;m¼8<:1i fn¼m0i fn6¼m:ii)V
k¼spanfBkngkn¼1:Thus, the coefﬁcientscðnÞ;n¼1;…;Nin (6) which guarantee mini- mum norm of the residual error are calculated ascðnÞ¼/C10B
kn;Ii3D;n¼1;…;k:The required arraysB
kn;n¼1;…;kshould be upgraded and updated to account for each newly selected atom. Starting from k¼1;R
0¼I,B11¼ W
1¼A 1¼dx
ℓx1/C10dy
ℓy1/C10dz
ℓz1, where
ℓx1;ℓy1;ℓz1¼arg max
n¼1;…;M x
i¼1;…;M y
s¼1;…;M z/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C10d
xn/C10dyi/C10dzs;Rk/C01i3D/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12/C12;
at iterationkþ1the indices
ℓxkþ1;ℓykþ1;ℓzkþ1corresponding to the new atomA
kþ1¼dx
ℓxkþ1/C10dy
ℓykþ1/C10dz
ℓzkþ1are selected as in (4). The requiredreciprocal setB
kþ1n;n¼1;…;kþ1is adapted and upgraded by extendingthe recursion formula given in Ref.[31]as follows.B
kþ1n¼Bkn/C0Bkþ1kþ1/C10A
kþ1;Bkni3D;n¼1;…;k;whereB
kþ1kþ1¼W kþ1/C14kW
kþ1k23D;withW
kþ1¼A kþ1/C0Xkn¼1Wn
kW nk23DhW n;Akþ1i3D;including, for numerical accuracy, the re-orthogonalization step:W
kþ1←W kþ1/C0Xkn¼1Wn
jjW njj23DhW n;W kþ1i3D:Although the image approximation is carried out by partitioning theimages into relatively small 3D blocks, memory requirements of theOMP3D method are high. Indeed, the above are 2 ðkþ1Þnonseparable arrays each of dimensionN¼N
xNyNzwhich need to be stored in double precision. Hence, we consider next a low memory implementation of theorthogonal projection step, which avoids having to store the arrays W
n; n¼1;…;kandB
kn;n¼1;…;kand fully exploits the separability of thedictionary.3.3. Self Projected Matching Pursuit in 3D (SPMP3D)The Self Projected Matching Pursuit (SPMP) methodology wasintroduced in Ref.[18]and conceived to be used with separable dictio-naries in 2D (SPMP2D). Because the technique is based on calculations ofinner products, it can be easily extended to operate in 3D (SPMP3D).Suppose that at iterationkthe selection process has chosen the atomslabelled by the triple of indicesf
ℓxn;ℓyn;ℓzngkn¼1and let~Ikbe the atomic decomposition~I
k¼Xkn¼1aðnÞdx
ℓxn/C10dy
ℓynB/C10dz
ℓzn; (7)where the coefﬁcientsaðnÞ;n¼1;…;kare arbitrary numbers. Every arrayI2RNx/C2Ny/C2Nzcan be expressed asI¼~I
kþ~R: (8) For~I
kto be the optimal representation of IinV k¼ spanfd
x
ℓxn/C10dy
ℓyn/C10dz
ℓzngkn¼1, in the sense of minimizing the norm of theresidual~R, it should be true thatbP
Vk~R¼0. The SPMP3D method fulﬁlls this property by approximating ~RinV
k, via the MP method, and sub- tracting that component from ~R. The following algorithm describes thewhole procedure.Starting fromk¼0andR
0¼I, at each iteration, implement the stepsbelow.i) Increasek←kþ1and apply the criterion (4) for selecting the triple ofindicesð
ℓxk;ℓyk;ℓzkÞ. Save this triple in the arrayLðk;1:3Þ¼ ð ℓxk;ℓyk;ℓzkÞ; and setcðkÞ¼Dd
x
ℓxk/C10dy
ℓyk/C10dz
ℓzk;Rk/C01i3D
and implement the update of the residueRk¼Rk/C01/C0cðkÞdx
ℓxk/C10dy
ℓyk/C10 d
z
ℓzkas follows:Fors¼1;…N zcalculateΔR
kð:;:;sÞ¼Rk/C01ð:;:;sÞ/C0cðkÞdx
ℓxk/C16dy
ℓyk/C17>
dz
ℓzkðsÞ;to updateR
kasR
k¼Rk/C01/C0ΔRk:ii) Given the indicesLðn;1:3Þ¼ð
ℓxn;ℓyn;ℓznÞ;n¼1;…;kof the previously selected atoms, and a tolerance
εfor the projection error, realize theorthogonal projection up to that error as follows. Set j¼1,~R
0¼ R
kand at iterationjapply the steps a) - c) below.a) Forn¼1;…;kevaluate
αðnÞ¼Ddx
ℓxn/C10dy
ℓyn/C10dz
ℓzn;~Rj/C01i3D; (9)and single out the valuek
/C3such thatk
/C3¼arg max
n¼1;…;k/C12/C12αðnÞ/C12/C12: (10)The valuek
/C3signalizes the indices ℓxk
/C3;ℓyk
/C3;ℓzk
/C3corresponding to the already selected atoms with maximum correlation with the residual ~R
j/C01. cðk
/C3Þ←cðk/C3Þþαðk/C3Þand fors¼1;…;N
zevaluateΔ~R
jð:;:;sÞ¼ αðk/C3Þdx
ℓxk/C3/C16dy
ℓyk/C3/C17>
dz
ℓzk/C3ðsÞto update the residual~R
jas~R
j¼~Rj/C01/C0Δ~Rj:b) Ifj
αðk/C3Þj<εstop. Otherwise update the coefﬁcientThis step subtracts from the residual a component in V
kand add that component to the approximation. ~I
kL. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
3c) Increasej←jþ1and repeat the steps a) - c) to keep subtractingcomponents of~R
jinV kuntil iteration,Jsay, for which the stopping criterion b) is met. This criterion indicates that, up to tolerance
ε, the residual has no component inV
kso that one can setRk¼~RJ/C01.Continue with steps i) and ii) to keep enlargingV
kuntil, for a required tolerance error
ρ, the conditionRk3D<ρis reached. Remark 1. For eachﬁxed valuekthe rate of convergencelim
j→∞I/C0~Rj¼bPVkIthrough the steps a) - c) above is given in Ref. [34]for the one dimen- sional case. The proof for 3D is identical to that proof, because a 3D arraycan be represented as a long 1D vector. What varies is the implementa-tion. A vectorized version of the algorithm would not be applicable in thiscontext.3.3.1. Implementation detailsThe bulk of the computational burden in the SPMP3D method lies inthe realization of the selection of atoms (4). Algorithm 1 outlines aprocedure implementing the process. It should be stressed once againthat the algorithm is designed to use as little memory as possible, ratherthan to reduce complexity.
Algorithm 1Implementation of the selection of atoms (c.f. (4))Procedure½
α;ℓx;ℓy;ℓz/C138¼Sel3DAtomðR;D x;Dy;DzÞ Input:3D arrayR, matricesD
x,DyDzthe columns of which are the atoms in the corresponding dictionaries.Output:selected indices
ℓx;ℓy;ℓz, and α¼hdx
ℓx/C10dy
ℓy/C10dz
ℓz;Ri3D
{Initiate the algorithm}ðN
z;MzÞ¼sizeðD zÞ;M x¼sizeðD x;2Þ;M y¼sizeðD y;2Þq¼zerosðM x;MyÞα¼0 form¼1:M
zdoqð:;:Þ¼0fors¼1:N
z
qð:;:Þ¼qð:;:ÞþD>xRð:;:;sÞD ydzmðsÞ end for{Realize (4) byﬁnding the partial maximum, and its argument, for each m-plane} ½l
1;l2;~q/C138¼maxðjqð:;:ÞjÞif~q>
αthen
α¼~q;ℓx¼l1;ℓy¼l2;ℓz¼m end ifend for
At iterationkthe outputs of Algorithm 1 are saved as cðkÞ¼ αandLðk; 1:3Þ¼ ð
ℓx;ℓy;ℓzÞ. The implementation details for selecting the triple ofindices at the projection step are given in Algorithm 2. This is used inAlgorithm 3 for the realization of the actual projection to recalculate thecoefﬁcients in the atomic decomposition.
Algorithm 2Selection of the triple of indices from the reduced dictionary (c.f. (10))Procedure½
α/C3;k/C3/C138¼SelTripðR;D x;Dy;Dz;LÞ Input:As in Algorithm 1 plus the arrayL, with the triple of indices Lðn;1:3Þ¼ð
ℓxn;ℓyn;ℓznÞ;n¼1…k Output:k
/C3and the corresponding values of α(c.f. (10)) to update the coefﬁcients and residual {Initiate the algorithm}
α/C3¼0forn¼1:kdop¼0fors¼1:N
zdop¼pþðd
x
ℓxnÞ>Rð:;:;sÞdy
ℓyndz
ℓznðsÞ end forifjpj>j
α/C3jthenk
/C3¼nand α/C3¼pend ifend forAlgorithm 3Implementation of the self projection steps a) - c).Procedure½~R;c/C138¼Proj3D(R;D x;Dy;Dz;L;c;ε;MaxJ). Input:As in Algorithm 2, plus the coefﬁcients of the atomic decomposition c,a tolerance parameter
εfor the numerical error of the projection, and a maximumnumber of permitted iterations, MaxJ.Output:Orthogonal residual~R. Coefﬁcients~cof the optimized atomic decomposition. forj¼1:MaxJ{Selection of atoms using Algorithm 2}½
α/C3;k/C3/C138¼SelTrip(R;D x;Dy;Dz;L) {Check stopping criterion}ifj
α/C3j<εthenstopend if{Update the coefﬁcients}cðk
/C3Þ←cðk/C3Þþα/C3
{Update the residual}fors¼1:N
zthenRð:;:;sÞ←Rð:;:;sÞ/C0
α/C3ðdx
ℓxk/C3Þ>Rð:;:;sÞdy
ℓyk/C3dz
ℓzk/C3ðsÞ end forend for{For clarity in the description only, we re-name here the residual and coef ﬁcients}
R¼R; c¼c
Due to computational complexity and memory requirements, pursuitstrategies using general dictionaries can only be implemented on animage partitioned into small blocks.We consider nonoverappling blocks. The approximation of each blockis carried out independently of the others. When the approximation of allthe blocks is concluded, these are assembled together to produce theapproximation of the whole image. While the sparsity results yielded bythe OMP3D and the SPMP3D methods are theoretically equivalent, wehave seen that the latter implementation is much more economic in termsof storage demands. As discussed in Remark 2below, this feature makes the SPMP3D algorithm suitable for possible GPU implementations usingonly the fast access shared memory. Assuming for simplicity in the no-tation that a 3D image is partitioned into cubes of size N
3band the dic- tionariesD
x,D yandD zare all of the same sizeN b/C2rN b, wherer>1i s the redundancy of the 1D dictionary, the SPMP3D algorithm storageneeds are as follows.1. TwoN
3barrays for the intensity block in the image partition and theresidual of the corresponding approximation.2. Three matrices of sizeN
b/C2rN bfor each dictionary, in case they aredifferent.3. Ar
2/C2N2barray for the selection of indices in Algorithm 1.4. A vector ofkreal numbers to store the coefﬁcients of the atomic decomposition andkvectors of size 3 to store the indices of the atomsin the atomic decomposition. The value of kis the total number of atoms in the approximation of the block.Since the stepwise complexity is dominated by the selection of indices(c.f. (4)), within this setup it is O( r
3N5b) and for true color images O(r
3N3b).Remark 2. By considering blocks of size 8/C28/C28 and dictionaries of redundancyr¼5 in each dimension, the above listed storage needs ofthe SPMP3D algorithm comfortablyﬁt the fast access shared memory of a GPU in CUDA, which currently is 48 Kb. Indeed, in the worst-case sce-nario (corresponding to an approximation of zero error using k¼8
3
atoms for the approximation of an 8 /C28/C28 block) SPMP3D would require 38 Kb to store most of the arrays in double precision, except forthose with the selected indices which contain integer numbers. This stillleaves 10 Kb for temporary variables to be used within calculations.L. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
43.4. Mixed dictionariesA key factor for the success in the construction of sparse representa-tions is to have a good dictionary. While a number of techniques forlearning dictionaries from training data have been proposed in theliterature[35–42], they are not designed for learning large and highlycoherent separable dictionaries. Nevertheless, previous works [18,32,33, 43]have demonstrated that highly redundant and highly coherentseparable dictionaries, which are easy to construct, achieve remarkablelevels of sparsity in the representation of 2D images. Such dictionaries arenot speciﬁc to a particular class of images. A discrimination is only madeto take into account whether the approximation is carried out in the pixelintensity or in the wavelet domain.As will be illustrated by the numerical examples in the next section,the approximation of the images we are considering are sparser whenrealized in the wavelet domain (wd). This entails the following steps:/C15Apply a wavelet transform to each channelI
m;m¼1;…;N zto obtain the arraysU
m;m¼1;…;N z. For the numerical examples we have usedthe 9/7 Cohen-Daubechies-Feauveau biorthogonal wavelet transform[44]./C15Approximate the arrayU2R
Nx/C2Ny/C2Nzexactly as it is done in the pixel domain (pd)./C15Apply the inverse wavelet transform to the approximated planes torecover the approximated intensity channels.The mixed dictionary we consider for the 2D approximation consistsof two sub-dictionaries: A trigonometric dictionary,D
xT, which is the common sub-dictionary for the approximation in both domains, and adictionary of localized atoms, which contains atoms of different shapeswhen used in each domain.The trigonometric dictionary is the union of the dictionaries D
xCand D
xSdeﬁned below:D
xC¼/C26w cðnÞcosπð2i/C01Þðn/C01Þ2M
x;i¼1;…;N x/C27Mx
n¼1
DxS¼/C26w sðnÞsinπð2i/C01ÞðnÞ2M
x;i¼1;…;N x/C27Mx
n¼1;wherew
cðnÞandw sðnÞ;n¼1;…;M xare normalization factors, and usuallyM
x¼2N x. Thus, the trigonometric dictionary is constructed asD
xT¼DxC[DxS.For approximations in the pd we add the dictionary,D
xLp, which is built by translation of the prototype atoms in the left graph of Fig. 1. This type of dictionary is inspired by a general result holding for continuousspline spaces. Namely, that spline spaces on a compact interval can bespanned by dictionaries of B-splines of broader support than the corre-sponding B-spline basis functions[45,46]. Thus, theﬁrst 4 prototypeatomshi;i¼1;…;4 in the left graph ofFig. 1are generated by dis- cretization of linear B-spline functions of different support. For m¼ 1;2;3;4 those functions are deﬁned as follows:h
mðxÞ¼8>>>>>>><>>>>>>>:xmif 0/C20x<m2/C0
xmifm/C20x<2m0 otherwise:(11)The remaining prototypes,h
5;h6andh 7, in the left graph ofFig. 1are generated taken the derivatives of the previous functions: h
5ðxÞ¼ ðh
2ðxÞÞ0,h6ðxÞ¼ðh 3ðxÞÞ0andh 7¼ðh 4ðxÞÞ0. The corresponding dictio- nariesD
Hm;m¼1;…;7 are built by discretization of the variable xin (11) and sequential translation of one sampling point, i.e.,D
Hm¼fw hmðnÞh mði/C0nÞjN x;i¼1;…;N xgMn¼1;m¼1;…;7;where the notationh
mði/C0nÞjN xindicates the restriction to be an array ofsizeN
x. The numbersw hmðnÞ;n¼1;…;M;m¼1;…;7 are normaliza- tion factors. The dictionaryD
xLparises by the union of the dictionariesD
Hm;m¼1;…;7 i.e.,DxLp¼[7m¼1DHm. The whole mixed dictionaryD
xpdisﬁnally formed asDxpd¼DxC[DxS[DxLp. For the other dimension we takeD
ypd¼Dxpd.For approximations in the wd we use the dictionary of localized atomsD
xLwas proposed in Ref.[33], which is built by translation of the pro-totype atomsp
i;i¼1;…;7 in the right graph ofFig. 1. Notice thatp1¼ h
1andp3¼h 5. The remaining prototypes are given by the vectors:p
2¼ð1;1;0;0;…;0Þ?2RNx;p4¼ð1;1;1;0;…;0Þ?2RNx;p5¼ ð/C01;1;1;0;…;0Þ
?2RNx;p6¼ð1;/C01;1;0;…;0Þ?2RNx;p7¼ ð/C01;/C01;1;0;…;0Þ
?2RNx;The corresponding dictionariesD Pm;m¼1; …;7 are built as in the previous case by sequential translation of onesampling point,D
Pm¼/C8w pmðnÞp mði/C0nÞ/C12/C12N x;i¼1;…;N x/C9Mn¼1;m¼1;…;7;where the numbersw
pmðnÞ;n¼1;…;M;m¼1;…;7 are normalization factors. The dictionariesD
Pm;m¼1;…;7 give rise toDxLw¼[7i¼1DPm. The latter generates the mixed dictionaryD
xwd¼DxC[DxS[DxLwand D
ywd¼Dxwd.The corresponding 2D dictionariesD
pd¼Dxpd/C10Dypdand D
wd¼Dxwd/C10Dywdare very large, but never used as such. All the cal-culations are carried out using the 1D dictionaries. In order to demon-strate the gain in sparsity attained by the approximation of 3D images bypartitioning into 3D blocks, we use dictionariesD
wdandD pdonly for the approximation of the single channel 2D images. For the 3D case we
Fig. 1.The left graph illustrates the prototype atoms which generate by translation the dictionaries D Hm;m¼1;…;7:The prototypes in the right graph generate by translation the dictionaries.D
Pm;m¼1;…;7:L. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
5maintain the redundancy of the 3D dictionary equivalent to that of the 2Ddictionary, by considering the 1D dictionary ~D
xpd¼DxC[DxS[D P1: Notice thatD
P1is the standard Euclidean basis forRNx, also called the Dirac's basis, i.e., the basis arising by translation of the ﬁrst atom inFig. 1. Notice that~D
xpd⊂Dxpdand~Dxpd⊂Dxwd. We also consider~Dypd¼~Dxpdand ~D
zpd¼~Dxpd, but takingN x¼N z. The redundancy of the resulting dic-tionary~D
pd¼~Dxpd/C10~Dypd/C10~Dzpdis equivalent to the redundancy of the2D dictionaryD
pd. In 3D we use the same dictionary in both domains~D
wd¼~D pd.4. Numerical resultsThe merit of the simultaneous approximation of multiple channelimages is illustrated in this section by recourse to two numerical exam-ples. Firstly we make the comparison between the sparsity produced bythe joint approximation of the Red-Green-Blue (RGB) channel imagespartitioned into blocks of sizeN
b/C2N b/C23 and the sparsity obtained by the independent approximation of each channel partitioned into blocksof sizeN
b/C2N b. Secondly, the full power of the approach is illustratedthrough the gain in sparsity attained by approximating hyper-spectralimages partitioned into 3D blocks, vs the plane by plane approximation.In both cases, once the approximation of each 3D block I
qin the image partition is completed, for q¼1;…;Qthek
q-term atomic decomposition of the corresponding block is expressed in the formI
kq
q¼Xkq
n¼1cqðnÞdx
ℓx;qn/C10dy
ℓy;qn/C10dz
ℓz;qn: (12)The sparsity of the representation of an image of dimension N¼N
x/C1 N
y/C1Nzis measured by the Sparsity Ratio (SR), which is de ﬁned as:SR¼
NK; (13)where for the 3D representationK¼PQq¼1kq;withk qthe number of atoms in the atomic decomposition (12). For the channel by channeldecomposition of aN
z-channel image, each channel is partitioned intoP¼ðN
x/C1NyÞ=N2bblocksI p;z;p¼1;…;P, which are approximated by the 2D atomic decompositionsI
kp;l
p¼Xkp;l
n¼1cp;lpðnÞdx
ℓx;p;ln/C10dy
ℓy;p;ln;l¼1;…;N z;(14)where the indices
ℓx;p;ln;ℓy;p;lnare selected for each channellby the OMP2D algorithm. Accordingly, the number Kin (13) is given asK¼P
Nz
l¼1PPp¼1kp;l, withk p;lthe number of atoms in the atomic decomposi-tion (14).Notice that the SR is a measure of the reduction of dimensionality forrepresenting an image. The larger the value of the SR the smaller thedimensionality of the atomic decomposition representing the wholeimage. The required quality of the approximation is ensured with respectto the Mean Structural SIMilarity (MSSIM) index [47,48]and the clas- sical Peak Signal-to-Noise Ratio (PSNR), which for a 3D image is de ﬁned asPSNR¼10 log
10 
ðImaxÞ2
MSE!;MSE¼kI/C0IKk3D
Nx/C1Ny/C1Nz;where Imax is the maximum intensity range and I
Kthe image approxi- mation.4.1. Example IIn this example we use the Kodak data set consisting of 24 true colorimages shown inFig. 2.The approximations are realized in both domains by maintaining the
Fig. 2.Illustration of the Kodak data set consisting of 24 true color images, credit Rich Franzen [49]. The size of these images is 768 /C2512/C23, for most of them, except for numbers 4, 9, 10, 17, 18 and 19, which are of size 512 /C2768/C23. (For interpretation of the references to color in this ﬁgure legend, the reader is referred to the Web version of this article.)L. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
6same redundancy in the 2D and 3D dictionaries. For the independentapproximation of the 2D channels the partitions are realized with blocksof size 8/C28 and 16/C216 (a partition of block size 24/C224 does not improve results for this data set). Accordingly, the simultaneousapproximation of the 3 color channels involves partitions of block size8/C28/C23 and 16/C216/C23 respectively.As already discussed, for the independent approximation of the 2Dchannels we consider the dictionariesD
pd(in the pd) andD wd(in the wd) as given in Sec.3.4. For the simultaneous approximation of the 3channels we consider the dictionaries ~D
pdgiven in the same section. Both dictionaries have redundancy of 125.The average values of SR (
SR), with respect to the 24 images in theset, are given inTable 1for the approaches and partitions indicated bytheﬁrst column.All the results in the left half of the table correspond to PSNR ¼45 dB and all the results in the right half correspond to PSNR ¼41 dB. The third andﬁfth columns give the standard deviations (std). For completeness wehave also produced the
SR rendered by nonlinear thresholding of thewavelets coefﬁcients (last row in the table). Notice that the resultingsparsity is poor in comparison with the other 2D results.All the results were obtained in the MATLAB environment on anotebook 2.9 GHz dual core i7 3520 M CPU and 4 GB of memory. For thechannel by channel approximation a C þþMEXﬁle implementing OMP2D was used. For the 3D approximation SPMP3D was implementedby a CþþMEXﬁle.As observed inTable 1the largest
SR is achieved in the wd and partition 16/C216/C23 (c.f. last but one row ofTable 1). However, the results obtained by partition 8/C28/C23 are very close (c.f. last row of the upper half ofTable 1) and constitute a better tradeoff between SR andapproximation time.Fig. 3shows the actual values of SRs for this partition in the wd foreach of the 24 images in the data set (c.f. Fig. 2). The average time for the 3D approximation was 53 s per image.Fig. 4demonstrates the gain in visual quality obtained when theapproximation of Images 3, 7 and 12 are realized simultaneously in 3D,instead of independently for each 2D channel. In both cases the SR isﬁxed at a high value SR¼63.5. While the 3D approximation is still ofgood quality (c.f. images on the left in Fig. 4) the distortion of the channel by channel approximation is very noticeable even at the scale of theﬁgure (c.f. images on the right inFig. 4). As aﬁnal remark it is worth noting that the number k
qof atoms in the approximation of each blockqof an image partition produces a mean-ingful summary of local sparsity.The upper graphs ofFig. 5are a representation of the piecewisesparsity corresponding to Image 22 in the Kodak data set. Both graphs arearrays of 64/C296 points. Each point corresponds to the number k
qof atoms in the approximation of a block q. The left graph corresponds to block size 8/C28 in the 2D approximation, by taking the average k
qoverthe three channels in the block, which is roughly the kq-value corre- sponding to the equivalent block in the gray scale image. The right graphcorresponds tok
qfor each block of size 8/C28/C23 in the 3D approxima- tion. Both approximations are realized in the pd. The lower graph is theimage given as 3 channels of 512/C2768 pixels each. It follows from theﬁgure that the points corresponding to the 3D approximation give modedetails about the image.4.2. Example IIWe consider now the approximation of the hyper-spectral imagesillustrated inFig. 6. Details on the images acquisition and processing aredescribed in Refs.[50–52].All four images are of size 1016/C21336/C232, and have been approximated in partitions of block size N
b/C2N b, withN b¼8;16, and 24 for the 2D approximation, and 8/C28/C28 for the 3D approximation. For the 2D channel by channel approximation we use the dictionaries D
pd
andD wdas deﬁned in Sec.3.4. For the 3D approximation we maintainthe redundancy as in 2D using the dictionary ~D
pdintroduced Sec.3.4 and~D
awd¼~Dapd.Because the range of intensity varies across the images, in order tocompare SRs with different approaches we ﬁx the Signal to Noise Ratio (SNR)
Table 1Mean value of the SR, with respect to the 24 images in the set, obtained with the 2D and 3D approximations in both the pd and wd for two different sizes of the image partition. The last row in the table gives the results corresponding to standard nonlinear thresholding of wavelet coef ﬁcients, to achieve the same quality of the approximation as with the dictionaries: PSNR ¼45dB (left half) and PSNR¼41dB (right half).
PSNR 45 dB 41 dB
SR std SR stdpd 2D 8/C28 6.2 2.0 9.1 3.5pd 3D 8/C28/C23 10.3 2.9 16.1 5.5wd 2D 8/C28 7.1 2.6 11.8 5.8wd 3D 8/C28/C23 11.6 3.8 20.9 9.2pd 2D 16/C216 7.1 2.5 11.1 5.0pd 3D 16/C216/C23 11.6 3.6 18.8 7.5wd 2D 16/C216 7.5 2.7 12.0 6.2wd 3D 16/C216/C23 12.4 3.9 20.4 8.9Thresholding in the wd 3.2 1.1 4.9 2.6Fig. 3.SR for the 45 dB approximation, in the wd, of each of the 24 images inthe Kodak data set (c.f.Fig. 2enumerated from top left to bottom right). Theresults for the independent approximation of each 2D color channel are repre-sented by theﬁlled circles and those corresponding to the simultaneousapproximation of the 3 channels are represented by the ﬁlled squares. The corresponding partitions are of size 8 /C28 and 8/C28/C23. (For interpretation of the references to color in thisﬁgure legend, the reader is referred to the Web version of this article.)L. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
7Fig. 4.Approximations of Images 3, 7 and 12 in the Kodak data set, for SR ¼63.5. The images on the left are the 3D approximations. The images on the right are the 2D channel by channel approximations.
Fig. 5.The upper graphs are a representation of the piecewise sparsity corresponding to Image 22 in the Kodak data set. Both graphs are arrays of 64 /C296 points. Each point corresponds to the number k
qof atoms in the approximation of a block q. The left graph corresponds to the 2D approximation and the right graph to the 3D approximation. The lower graph is the image given as 3 channels of 512 /C2768 pixels each.L. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
8SNR¼10 log10 
kIk23D
kI/C0IKk23D!: (15)Every block in the partition is approximated up to the same error.With all the approaches, two global values of SNR (31 dB and 33 dB)were considered. These values of SNR correspond to the values of PSNRshown inTables 2 and 3. In all of the cases the approximations are ofexcellent visual quality.The SRs produced by the 3D approximation are indicated by SR
3Dand those produced by the 2D plane by plane approximation by SR
2D. The times for completing the approximations are given in the row right afterthe corresponding sparsity result.Remark 3. In bothTables 2 and 3the values of SR
3Dare signiﬁcantly larger than the values of SR
2D, except for the Col. image and 24/C224 blocks. For this image we were able to increase the 3D block size up to16/C216/C216 and the results for SNR¼31dB are SR
3D¼357 in the pd and SR
3D¼892 in the wd (35 min and 10 min respectively). For SNR ¼ 33 dB SR
3D¼247 in the pd and SR 3D¼590 in the wd (55 min and 20 min respectively).
Fig. 6.Illustration of the hyper-spectral images available on [53,54]. From top left to bottom right in Table 2are labelled as Ribei., Graff., Rose, and Col. The of size of all four images is 1016/C21336/C232 pixels.
Table 3Same description as inTable 2, but the approximations are realized by applyingﬁrst a wavelet transform to each of the 32 channels.
Image Ribei. Graff. Rose Col.SNR¼31 dBPSNR 46.8 48.2 47.8 46.7SR
2DNb¼8 28.6 26.8 38.6 56.5Time (min) 1.4 1.5 1.2 0.8SR
2DNb¼16 36.5 34.1 63.4 144.8Time (min) 2.7 3.5 2.3 0.9SR
2DNb¼24 37.2 35.7 71.1 193Time (min) 9.2 12 4.8 1.8SR
3DNb¼8 86.5 108.0 182.2 371.7Time (min) 13 10 6 3SNR¼33 dBPSNR 48.8 50.2 49.9 48.7SR
2DNb¼8 22.6 21.8 33.0 56.1Time (min) 1.7 1.8 1.5 1.0SR
2DNb¼16 26.6 25.8 48.2 118.3Time (min) 3.5 5.0 2.3 1.1SR
2DNb¼24 21.9 26.8 52.0 144.0Time (min) 12 15 8.5 1.9SR
3DNb¼8 55.1 70.5 129.5 313.3Time (min) 23 18 10 1.8Table 2Values of SR for the approximation in the pixel-intensity domain of the imageslisted in theﬁrst row. SR
2Dindicates the SR for the plane by plane approximationin partition of block sideN
b¼8;16, and 24. SR 3Dcorresponds to a partition in 3D blocks of size 8/C28/C28. The times for completing the approximations aregiven immediately below the sparsity results in minutes.
Image Ribei. Graff. Rose Col.SNR¼31 dBPSNR 46.8 48.2 47.8 46.7SR
2DNb¼8 19.2 19.2 24.1 47.7Time (min) 1.6 1.6 1.3 0.9SR
2DNb¼1627.3 25.5 38.7 110.6Time (min) 3.4 3.8 2.1 1.1SR
2DNb¼2429.6 26.8 44.2 147.5Time (min) 7.6 9.2 4.5 1.5SR
3DNb¼8 49.1 59.7 74.6 137.2Time (min) 18 15 10 6SNR¼33 dBPSNR 48.8 50.2 49.8 48.7SR
2DNb¼8 15.2 15.4 19.3 41.5Time (min) 2.3 2.1 1.7 1.1SR
2DNb¼1620.4 19.5 29.1 86.4Time (min) 5.4 5.6 2.9 1.2SR
2DNb¼2421.9 20.5 32.7 106.3Time (min) 12 14 6.8 1.9SR
3DNb¼8 33.5 41.6 53.2 106.5Time (min) 25 21 16 8L. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
9On comparing the two tables a drastic improvement in the values ofSR
3Dis observed when the approximation is realized in the waveletdomain. This feature is a consequence of the fact that the planes of thenatural images are very sparse in the wavelet domain. In order to high-light differences we produce next the SR
3Dcorresponding to the two remote sensing images inFig. 7. The graph on the left represents theUrban remote sensing hyper-spectral image taken from Ref. [55]. The graph on the right is a portion of the University of Pavia image also takenfrom Ref.[55].Fig. 8plots the SR vs four values of SNR, corresponding to the 3Dapproximations of the Urban and University of Pavia images in both thepd and wd.Notice that the results in the pd are much closer to the results in thewd than they are in the case of the natural images in Fig. 6. This is because, as illustrated inFig. 9, the planes of the remote sensing imagesare not as sparse in the wd as the planes of the natural images are.5. ConclusionsHigh quality approximation of 3D images has been considered withinthe context of data reduction. A remarkable improvement in sparsityachieved by the simultaneous approximation of multiple channels hasbeen illustrated through numerical experiments of different natures.Firstly it was demonstrated that a standard data set of RGB images can beapproximated at high quality using far fewer elementary components ifeach image is treated as a very thin 3D array instead of as 3 independent2D arrays. Secondly the full power of the approach was demonstratedthrough the approximation of hyper-spectral images. For the hyper-spectral natural images the sparsity is remarkably higher if the approx-imation is realized in the wavelet domain. For the remote sensing imagesthe domain of approximation has less inﬂuence because, as opposed to natural images, these images are not as sparse in the wavelet domain asnatural images are.Taking into account the major reduction of dimensionality demon-strated by the numerical examples in this work, we feel con ﬁdent that the proposed approach will be of assistance to the broad range of imageprocessing applications which rely on a transformation for data reductionas aﬁrst step of further processing.
Fig. 7.Illustration of two remote sensing hyper-spectral images taken from Ref. [55]. The graph on the left is the Urban image (size 320 /C2320/C2128 pixels). The graph on the right is a portion of the University of Pavia image (256 /C2256/C296 pixels).
Fig. 8.SR vs SNR values for the 3D approximation in both the pd and wd for theUrban and University of Pavia remote sensing images.
Fig. 9.Absolute value of the wavelet transform of a plane in the Col. image (left graph) and in the University of Pavia image (right graph).L. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
10Declaration of Competing InterestThe authors declare no conﬂict of interest.AcknowledgmentsWe are also indebted to P. Getreuer, for making available the wave-letcdf97 MATLAB function that we have used for the transformation ofeach single channel image to the wavelet domain.References
[1]Wright J, Ma Yi, Mairal J, Sapiro G, Huang TS, Yan S. Sparse representation forcomputer vision and pattern recognition. Proc of the IEEE 2010;98:1031 –44. [2]Elad M. Sparse and redundant representations: from theory to applications in signaland image processing. Springer; 2010 . [3]Zhang Z, Xu Y, Yang J, Li X, Zhang D. A survey of sparse representation: algorithmsand applications. IEEE access; 2015 . [4]Mairal J, Eldar M, Sapiro G. Sparse representation for color image restoration. IEEETrans Image Process 2008;17:53 –69. [5]Dong W, Zhang L, Shi G, Li X. Nonlocally centralized sparse representation forimage restoration. IEEE Trans Image Process 2013;22:1620 –30. [6] Gou J, Hou B, Ou W, Mao Q, Yang H, Liu Y. Several robust extensions ofcollaborative representation for image classi ﬁcation. Neurocomputing 2018. https://doi.org/10.1016/j.neucom.2018.06.089 . [7]Gou J, Yi Z, Zhang D, Zhan Y, Shen X, Du L. Sparsity and geometry preserving graphembedding for dimensionality reduction. IEEE Access 2018;6:75748 –66. 10.1109/ ACCESS.2018.2884027.[8] Gou J, Wang L, Yi Z, Lv J, Mao Q, Yuan Y-H. A new discriminative collaborativeneighbor representation method for robust face recognition. IEEE Access 2018;6:74713–27.https://doi.org/10.1109/ACCESS.2018.2883527 . 2018. [9]Wright J, Yang AY, Ganesh A. Robust face recognition via sparse representation.IEEE Trans Pattern Anal Mach Intell 2009;31:210 –27. [10]Yuan XT, Liu X, Yan S. Visual classi ﬁcation with multitask joint sparse representation. IEEE Trans Image Process 2012;21:4349 –60. [11]Yang J, Wright J, Huang T. Image super-resolution via sparse representation. IEEETrans Image Process 2010;19:2861 –73. [12]Zhang Y, Liu J, Yang W, Guo Z. Image super-resolution based on structure-modulated sparse representation. IEEE Trans Image Process 2015;9:2797 –810. [13]Dabov K, Foi A, Katkovnik V. Image denoising by sparse 3-D transform-domaincollaborativeﬁltering. IEEE Trans Image Process 2007;16:2080 –95. [14]Caiafa CF, Cichocki A. Computing sparse representations of multidimensionalsignals Using Kronecker Bases. Neural Comput 2013;25:186 –220. [15]Cichocki A, Mandic D, De Lathauweri L, Zhou G, Zhao Q, Caiafai C, Phan HA.Tensor decompositions for signal processing applications: from two-way tomultiway component analysis. IEEE Signal Process Mag 2015;32:145 –63. [16]Dai Q, Yoo S, Kappeler A. Sparse representation-based multiple frame video super-resolution”. IEEE Trans Image Process 2017;26:2080 –95. [17]
Mousavi HS, Monga V. Sparsity-based color image super resolution via exploitingcross channel constraints. IEEE Trans Image Process 2017;26:5094 –106. [18]Rebollo-Neira L, Bowley J. Sparse representation of astronomical images. J Opt SocAm 2013;30:758–68.[19]Donoho DL, Tsaig Y, Drori I, Starck J. Stagewise orthogonal matching pursuit. IEEETrans Inf Theory 2006;58:1094 –121. [20]Needell D, Tropp JA. CoSaMP: Iterative signal recovery from incomplete andinaccurate samples”. Appl Comput Harmon Anal 2009;26:301 –21. [21]Eldar Y, Kuppinger P, Bi €olcskei H. Block-sparse signals: uncertainty relations andefﬁcient recovery. IEEE Trans Signal Process 2010;58:3042 –54. [22]Rebollo-Neira L, Matiol R, Bibi S. Hierarchized block wise image approximation bygreedy pursuit strategies. IEEE Signal Process Lett 2013;20:1175 –8. [23] L. Rebollo-Neira,http://www.nonlinear-approx.info/examples/node09.html (Last access April 2019)..[24]Tao JianWen, Wen Shiting, Hu Wenjun. Robust domain adaptation imageclassiﬁcation via sparse and low rank representation. J Vis Commun ImageRepresent 2015;33:134–48. [25]Nie Wei-Zhi, Liu An-An, Su Yu-Ting. 3D object retrieval based on sparse coding inweak supervision. J Vis Commun Image Represent 2016;37:40 –5.[26]Gao Z, Li SH, Zhu YJ, Wang C, Zhang H. Collaborative sparse representation leaningmodel for RGBD action recognition. J Vis Commun Image Represent 2017;48:442–52.[27]Zhang Youqiang, Guo Cao, Li Xuesong, Wang Bisheng. Cascaded random forest forhyperspectral image classiﬁcation. IEEE JSelect Top Appl Earth Observ Remote Sens2018;11:1082–94.[28]Li Guiji, Peng Manman, Ke Nai, Li Zhiyong, Li Keqin. Visual tracking via context-aware local sparse appearance model. J Vis Commun Image Represent 2018;56:92–105.[29]Mallat S, Zhang Z. Matching pursuit with time-frequency dictionaries. IEEE TransSignal Process 1993;41(12):3397 –415. [30]Pati YC, Rezaiifar R, Krishnaprasad PS. Orthogonal matching pursuit: recursivefunction approximation with applications to wavelet decomposition, ”Proc. of the 27th ACSSC, vol. 1; 1993. p. 40 –4. [31]Rebollo-Neira L, Lowe D. Optimized orthogonal matching pursuit approach. IEEESignal Process Lett 2002;9:137–40. [32]Rebollo-Neira L, Bowley J, Constantinides A, Plastino A. Self contained encryptedimage folding. Physica A 2012;391:5858 –70. [33] Rebollo-Neira L. Effective sparse representation of X-Ray medical images. Int J NumMethod Biomed Eng 2017.https://doi.org/10.1002/cnm.2886 . [34] Rebollo-Neira L, Rozlo /C20zník M, Sasmal P. Analysis of a low memory implementationof the Orthogonal Matching Pursuit greedy strategy. http://arxiv.org/abs/1 609.00053; 2017.[35]Kreutz-Delgado K, Murray JF, Rao BD, Engan K, Lee Te-Won, Sejnowski TJ.Dictionary learning algorithms for sparse representation. Neurocomputing 2003;15:349–96.[36]Aharon M, Elad M, Bruckstein A. K-SVD: an algorithm for designing overcompletedictionaries for sparse representation. IEEE Trans Signal Process 2006;54:4311 –22. [37]Rubinstein R, Zibulevsky M, Elad M. Double sparsity: learning sparse dictionariesfor sparse signal approximation. IEEE Trans Signal Process 2010;58:1553 –64. [38]Tosi/C19c I, Frossard P. Dictionary Learning: what is the right representation for mysignal? IEEE Signal Process Mag 2011;28:27 –38. [39]Zepeda J, Guillemot C, Kijak E. Image compression using sparse representations andthe iteration-tuned and aligned dictionary. IEEE J Select Top Signal Process 2011;5:1061–73.[40]Hawe S, Seibert M, Kleinsteuber M. Separable dictionary learning. In: Proceedingsof the 2013 IEEE conference on computer vision and pattern recognition; 2013.p. 438–45.[41]Srinivas M, Naidu RR, Sastry CS, Krishna Mohana C. Content based medical imageretrieval using dictionary learning. Neurocomputing 2015;168:880 –95. [42]Wen B, Ravishankar S, Bresler Y. Structured overcomplete sparsifying transformlearning with convergence guarantees and applications. Int J Comput Vis 2015;114:137–67.[43] Rebollo-Neira L. A competitive scheme for storing sparse representation of X-Raymedical images. PLoS One 2018. https://doi.org/10.1371/journal.pone.0201455 . [44]Cohen A, Daubechies I, Feauveau JC. Biorthogonal bases of compactly supportedwavelets. Commun Pure Appl Math 1992;45:485 –560. [45]Andrle M, Rebollo-Neira L. Cardinal B-spline dictionaries on a compact interval.Appl Comput Harmon Anal 2005;18:336 –46. [46]Rebollo-Neira L, Xu Z. Adaptive non-uniform B-spline dictionaries on a compactinterval. Signal Process 2010;90:2308 –13. [47]Wang Z, Bovik AC, Sheikh HR, Simoncelli EP. Image quality assessment: from errorvisibility to structural similarity. IEEE Trans Image Process 2004;13:600 –12.
[48] I. Kowalik-Urbaniak, D. Brunet, J. Wang, D. Koff, N. Smolarski-Koff, E. Vrscay, B.Wallace, and Z. Wang,“The quest for ‘diagnostically lossless’medical image compression: a comparative study of objective quality metrics for compressedmedical images”, Proc. SPIE 9037, Medical Imaging 2014: Image Perception,Observer Performance, and Technology Assessment, 903717 (March 11, 2014); doi:10.1117/12.2043196.[49] R. Franzen,http://r0k.us/graphics/kodak/ (Last access April 2019).. [50]Foster DH, Nascimento SMC, Amano K. Information limits on neural identi ﬁcation of colored surfaces in natural scenes. Vis Neurosci 2004;21:331 –6. [51]Foster DH, Amano K, Nascimento SMC, Foster MJ. Frequency of metamerism innatural scenes. J Opt Soc Am 2006;23:2359 –72. [52]Nascimento SMC, Amano K, Forster D. Spatial distributions of local illuminationcolor in natural scenes. Vis Res 2016;120:39 –44. [53] D. H. Foster,https://personalpages.manchester.ac.uk/staff/d.h.foster/Hyperspectral_images_of_natural_scenes_04.html (Last access April 2019).. [54] D. H. Foster,http://personalpages.manchester.ac.uk/staff/d.h.foster/Local_Illumination_HSIs/Local_Illumination_HSIs_2015.html (Last access April 2019).. [55]http://lesun.weebly.com/hyperspectral-data-set.html (Last access April 2019)..L. Rebollo-Neira, D. Whitehouse Array 1-2 (2019) 100001
11