Combining machine learning, space-time cloud restorationand phenology for farm-level wheat yield prediction
Andualem Aklilu Tesfayea,⁎,D a n i e lO s g o o db, Berhane Gessesse Awekec
aDepartment of Remote sensing at Ethiopian Space Science and Technology Institute, Addis Ababa University, Ethiopia
bInternational Research Institute for Climate and Society, Earth Institute, Columbia University, United States of America
cDepartment head of the remote sensing unit at Ethiopian Space Science and Technology Institute, Addis Ababa University, Ethiopia
abstract article info
Article history:Received 17 August 2021Received in revised form 8 October 2021Accepted 9 October 2021Available online 12 October 2021Though studies showed the potential of high-resolution optical sensors for crop yield prediction, several factorshave limited their wider application. The main factors are obstruction of cloud, identi ﬁcation of phenology, de- mand for high computing infrastructure and the complexity of statistical methods. In this research, we createda novel approach by combining four methods. First, we implemented the cloud restoration algorithm calledgapﬁll to restore missed Normalized Difference Vegetation Index (NDVI) values derived from Sentinel-2 sensor(S2) due to cloud obstruction. Second, we created square tiles as a solution for high computing infrastructure de-mand due to the use of high-resolution sensor. Third, we implemented gap ﬁll following critical crop phenology stage. Fourth, observations from restored images combined with original (from cloud-free images) values andapplied for winter wheat prediction. We applied seven base machine learning as well as two groups of superlearning ensembles. The study successfully applied gap ﬁll on high-resolution image to get good quality estimates for cloudy pixels. Consequently, yield prediction accuracy increased due to the incorporation of restored values inthe regression process. Base models such as Generalized Linear Regression (GLM) and Random Forest (RF)showed improved capacity compared to other base and ensemble models. The two models revealed RMSE of0.001 t/ha and 0.136 t/ha on the holdout group. The two models also revealed consistent and better performanceusing scatter plot analysis across three datasets. The approach developed is useful to predict wheat yield at ﬁeld scale, which is a rarely available but vital in many developmental projects, using optical sensors.© 2021 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Cloud restorationEnsemble learningMachine learningPhenologySentinel-2Wheat yield prediction
1. IntroductionCrop yield estimation is at the hub of numerous global developmen-tal challenges such as food security, hunger reduction, and internationalcrop trade among others (Kim et al., 2019;Dodds and Bartram, 2016). Yield estimation is the process of accurately predicting crop yield beforeharvest. Remote sensing technologies coupled with empirical methodsused to predict crop yield having some comparative advantages, nota-bly, covering a large area, enabling continuous monitoring, and provid-ing timely data (Potgieter et al., 2014;Lobell et al., 2015). These methods discriminate the potential of a range of vegetation indices(VIs). The relationship between satellite-derived VIs and crop yield isestablished because important crop characteristics that determinecrop yield such as leaf area index, biomass, and chlorophyll contentare represented by VIs. Speciﬁcally, VIs record canopy level properties(reﬂectance, transmission, and absorbance) which enable to infervaluable canopy attributes (biochemical, physiological, and morpholog-ical) (Zhao et al., 2020).Nonetheless, several issues have challenged the application of VIs forcrop yield prediction. Three major categories could be identi ﬁed: sensor (obstruction of images by cloud, missing orbits, and geometry artifacts),data (absence of long years of crop yield data), and statistics (the com-plex relationship between predictor and response variables). Besides,images obtained at some crop growth stages, which are commonly re-ferred to as critical stages, have paramount importance for crop yieldprediction. A study revealed that using Quickbird image at end of theheading and in particular after inﬂorescence fully emerged, NDVI ishighly correlated with yield with an average correlation coef ﬁcient of 0.77 (Kumhálová and Matějková, 2017). However, in some studies due to cloud coverage, observations of greenness measured by NDVIat important critical windows such asﬂowering and grainﬁlling stages were left out from the regression process ( Kumhálová and Matějková, 2017;Zhao et al., 2007).Although several solutions are available, cloud restoration (gapﬁlling) methods are among the most widely applied ones. CloudArtiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
⁎Corresponding author.E-mail addresses:anduak@yahoo.com(A.A. Tesfaye),deo@iri.columbia.edu (D. Osgood).
https://doi.org/10.1016/j.aiia.2021.10.0022589-7217/© 2021 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/restoration methods employ some sort of algorithms for replacingcloudy pixels with estimates from the non-cloud part of the image. Interms of exploiting sensor potential, three major categories of cloud res-toration exist: temporal, spatial, and spatio-temporal ( Gerber et al., 2018). Methods under the temporal category include most of theexisting algorithms. For instance, the widely established method calledTIMESAT exploits the temporal dependence structure and smooth timeseries data and overlooks spatial dependence ( Verger et al., 2013; Atkinson et al., 2012;Hird and McDermid, 2009). In general, spatio- temporal methods are rarely available and in this regard, one of the re-cently available methods named gapﬁll exploits the spatial coherence and temporal regularity of images (Garonna et al., 2016;Zscheischler and Mahecha, 2014). In terms of the root-mean-squared error(RMSE), it overperformed two of its competitors: the gap ﬁll-MAP and TIMESAT (Weiss et al., 2014). As it is available in R platform, it is openaccess and transparent, and it could easily be applied and further devel-oped (Gerber et al., 2018). Nonetheless, gapﬁll was applied using MODIS (Moderate Resolution Imaging Spectroradiometer) NDVIwhich has medium spatial resolution and its performance on high spa-tial resolution is left unaddressed.The availability of high spatial and temporal remote sensing prod-ucts offered untapped potential in many applications. Nonetheless, asthese products are both data and compute intensive, their usage hasits challenges (Zhong et al., 2013).Voluminous pixel and multiple spectral bands (multispectral/hyperspectral) of large size satellite data cause great challenges toread, process, store and display (Pektürk and Ünal, 2018). The pro- cessing challenge of high volume remote sensing data is associatedwith the intrinsic nature of data mining algorithm. Speci ﬁcally, the computational complexity of processing algorithms is superliner tothe size of the sample and the number of samples ( Kalluri et al., 2001). This is more signiﬁcant in implementing spatio-temporal al-gorithms that discriminate both the high temporal and spatial resolu-tion of newly available sensors. One solution has been the use of HighPerformance Computing (HPC) that includes clusters, grids, clouds,distributed networks or specialized hardware devices that provideuseful architectural developments for increased computation of re-mote sensing images (Lee et al., 2011). For instance, a spatio- temporal image restoration algorithm, gap ﬁll, demanded 80 cores running for 10 h using MODIS sensor, which is only high temporal(Gerber et al., 2018). Likewise, a HiTempo platform, which is de-signed to facilitate the analysis of time-series satellite images underparallelized setup, required 32 processors to process 415 tiles over9y e a r s(Van Den Bergh et al., 2012). However, due to their recent ad-vancement and hence limited availability, HPCs are rarely available inmany image processing environments.To model, the complex relationship between crop yield and poten-tial predictors various statistical and machine learning (ML) approachesused. Correlation analysis was less useful for understanding and quanti-fying yield response (Drummond et al., 2003). Several multiple linear regression models were widely applied and overall revealed poor re-sults (Drummond et al., 1995;Kbakural et al., 1999). Nonetheless, other authors reported linear models performed well on some datasets(Kbakural et al., 1999). In some studies, polynomial methods showedsome improvement over strictly linear models (
Kitchen et al., 1999). Nonlinear methods such as boundary line analysis ( Kitchen et al., 1999), state-space analysis (Wendroth et al., 1999), bayesian networks, and regression trees (Adams et al., 1999) were also used. Nonetheless, the implementation and the lack of common measurement scale foroutputs from these diverse models were the major dif ﬁculties. Artiﬁcial Neural Network (ANN) model showed higher accuracy than multivari-ate regression models using Advanced Very High Resolution Radiome-ter (AVHRR) sensor for winter wheat ( Jiang et al., 2004). On other studies, Support Vector Machine used to estimate rice yields ( Jaikla et al., 2008). Therefore, the selection of a given method needs consider-ing the characteristics of the predictors and response variable.Nonetheless, based on the current trend, machine learning methodsare not only contemporary but also preferred ones.Satellite-based farm-level estimation methods are seldom available.This is associated with the widely available and most exploited sensors(MODIS and Landsat) possess only limited potential to be applied atﬁner spatial scales. In this regard, the launch of Sentinel 2 (S2) withhigh spatial and temporal resolution has offered a new opportunity. Arecent study compared the commercial Skysat, RapidEye satellites,and the publicly accessible S2 using VIs for predicting farm-level cropyield in the Eastern African region. Though the study overlooks thecrop phenology, it evaluates the link between farm size units withmodel performance (Gomez et al., 2019). The study applied some ma- chine learning models on yield predictor variables derived from S2 topredict potato yield. The study reported that potato yield is predicted1–2 months ahead of the harvest period with satisfactory result(11.16% RMSE, R2= 0.89 and 8.71% MAE) (Gomez et al., 2019). Simi- larly, in another study, the S2 sensor integrated with the ecosystemmodel used for estimating cotton yield over the Southern UnitedStates (He and Mostovoy, 2019).Therefore, this study motivated to address some of the key chal-lenges of farm-level crop yield estimation using optical sensors. Thisstudy is novel as it integrates and implements four methods: applicationof gapﬁll on high-resolution S2 sensor, application of gap ﬁll following crop phenology stage, the use of tilling approach within gap ﬁll frame- work, and evaluation of observations from cloud restored images foryield prediction using seven machine learning and ensemble methods.We hypothesized that by discriminating the spatio-temporal potentialof the S2 sensor, the gapﬁll method will provide a good estimate ofcloudy pixels and the machine learning methods will learn the non-linearity between the NDVI variable and winter wheat yield. Hence,the two methods: gapﬁll and machine learning potentially complementand offer an increased skill for wheat yield prediction. Therefore, thepurpose of this study is twofold. First, we implement the gap ﬁll algo- rithm for cloud restoration on NDVI variables derived from high spatialand temporal resolution S2 sensor. Second, observations from restoredimages combined with original (from cloud-free images) values usedfor wheat yield prediction.2. Methodology2.1. Study area, preprocessing and dataset descriptionWheat is one of the widely produced crops in Ethiopia. It accountsfor 16% of the total grain production in which 4.8 million farmers takepart. The current study is placed in some parts of the wheat belt regionof Ethiopia and in particular in Arsi-Sire district which is located inCentral-Eastern Oromia Region. Rainfed smallholder crop productiondominated in the study area, where wheat monocropping exercised.Annually the area has two crop growing seasons, the major seasoncalled:‘Meher’(September–February) and the second ‘Belg’(March– August) (Brasesco et al., 2019).We used the multispectral bands of S2 sensors with 10 m spatial and5 days temporal resolutions. The original accessed S2 product was level-1C data (top of atmosphere) downloaded from the Copernicus OpenAcess Hub. We used Sentinel Application Platform (SNAP) and R-programming software to implement the preprocessing activities andto prepare theﬁnal input data for the gapﬁll process. First, an atmo- spheric correction algorithm implemented to get level-2A product (bot-tom of the atmosphere) from level-1C. Second, the NDVI productderived from a level-2A product. Third, level-2A products resampledto get quality scene classiﬁcation output. Fourth, theﬁnal NDVI mask product was prepared by masking some classes (dark feature shadow,cloud shadow, cloud medium probability, cloud high probability, andthin cirrus) of the quality scene classiﬁcation product. Finally, the mask applied to NDVI data (Fig. 1).A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
209Based on previous studies, images obtained at some crop stagesdemonstrated increased potential for yield estimation. For cerealcrops, these stages range from heading up to ripening ( Fischer, 2011). Likewise,Mirasi et al., 2019reported milky and ripening stages as keyperiods. Under the current study area, planting enters as early as July8 and stays up to July 18; and harvesting starts on October 29 and sus-tains up to November 9. Therefore, this study focused on the majorcrop-growing period:‘Meher’, and speciﬁcally on the crop development stage from the date of September 26 –October 26 which referred as study season. From a phenology perspective, the study season overlapswith crop development stages such as Flowering, Anthesis, Develop-ment of fruit, and Ripening.The input dataset for gapﬁll should be prepared in four-dimensional arrays: x (dimension one), y (dimension two), s (sea-son: dimension three), and a (year index: dimension four). Theinput dataset in this study has a spatial extent of 1486 grids alongthe x and 1837 grids along the y. To the season index, seven imagesfound in the study season used. We grouped images per phenologyconsidering the hypothesis that images found in one phenologystage represents a single physiological crop development andcould yield a composite that offers reliable prediction values. Thestudy applied data from threeyears: 2017, 2018, and 2019, whichare year indexes. Finally, the total number of images used in the res-toration process equals 21 (seven images per season for each yearconsidered).The keyﬁeld-collected data in this study was dry weightedwheat yield measured in ton per hectare (t/ha). It was collectedfrom 67 farmers'ﬁelds for two crop seasons: 2017 and 2018. Fur-thermore, in this study, with the primary purpose of getting a bet-ter yield prediction method, som e potential predictors added. Speciﬁcally, two types of fertilizers that have been widely used inthe study area such as Urea fertilizer that contains 46% nitrogen;and NPS, which contain nitrogen, phosphorous and sulfur witht h er a t i oo f1 9 %N ,3 8 %P 2 O 5a n d7 %Sw e r eu s e d( Meessen and Petersen,2010).2.2. Gapﬁll descriptionThe overall workﬂow of the gapﬁll method could be presented in two major parts: the extraction (subset) component and predictioncomponent, which were implemented in sequential order. In R plat-form, we used packages that include gapﬁll, raster, foreach, doParallel, and rgdal to support the overall process. Details of the gap ﬁll method are described in the paper (Gerber et al., 2018).Cloud Masked NDVIResampling NDVI Computa/g415onAtmospheric Correc/g415onSen/g415nel-2 level-1CSTART
Sen/g415nel-2 level-2A
Cloud Mask
Phenology Based Composites
NDVI SUMNDVI Restored data
ENDGapﬁll Implementa/g415on
Fig. 1.Data processing workﬂow from image preprocessing to cloud restoration.A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
2102.2.1. Extraction componentThis is theﬁrst step in which the algorithm iteratively selects a bigenough neighborhood which is referred to as a prediction set alongthe spatio-temporal dimension. The subset is constructed around thetarget value (missing value) considered at a time. The row remote sens-ing data need to be stored in a four-dimensional array and missingvalues will be stored as NA. For an array Z with four dimensions x (x spa-tial dimension), y (y spatial dimension), s (season or position within ayear), and a (year index) for a target value T, the subset function selectsa suitable subset of Z around T. The subset function is given by the fol-lowing equation:fZ;iðÞ ¼fZ;i;xT;yT;sT;aT;λx;λy;λs;λa ðÞ¼Zx T−λxþiðÞðÞ:xTþλxþiðÞ;yT−λyþiðÞðÞ:yTþλyþiðÞ; ½sT−λsðÞ:sTþλsðÞ;aT−λaðÞ:aTþλaðÞ /C138:ð
1Þλx,λy,λs,λa∈N are tuning parameters, which deﬁne the initial size of the subset; and i that grows the subset in the spatial dimension, willhave values from 0 and iteratively increases by 1 when the subsetdoes not contain enough data.2.2.2. Prediction component2.2.2.1. Decision on the subset.This is theﬁrst step of the prediction com- ponent that decides whether it is possible to predict the target value de-ﬁned by Eq.(1)above. The process evaluates two criteria; ﬁrst, the subset should have the minimum number of non-empty sub-imagesdeﬁned byθ1. Second, the sub-images in the subset containing the tar-get value should have the minimum number of observed values in thetarget sub-image set byθ2. If the two criteria met, then the speciﬁcs u b - set is selected as prediction set. A sub-image is any image found withinthe array dataset identiﬁed by season and year indexes.2.2.2.2. Rank the image.At this stage, for all the sub-images within theprediction set, a scoring algorithm ranks each of them. The score of asub-image is the proportion of values in the sub-image that are largercompared to the values at the same spatial coordinates in all othersub-images. The sub-images are ranked by increasing score, i.e., asub-image with the smallest score will be assigned rank 1 and so on.2.2.2.3. Estimate quantile.For sub-images within the prediction set hav-ing an observed value at the spatial location of the target pixel, here,the algorithm determines to which empirical quantile level that valuecorresponds relatively to all values of the image. The observed valuesin the prediction set are used to estimate an empirical cumulative distri-bution function for each sub-image. Theﬁnal quantile level will be the mean of all quantiles levels for all the sub-images in the prediction set.A tuning parameter, v, which is the minimum number of quantiles, con-trols the process.2.2.2.4. Quantile regression.Theﬁnal step of the prediction component isdevelopment of a quantile regression model and applying it for predic-tion. An intercept and the associated rank, r, is added as inputs in the re-gression process as linear predictors for all observed values in theprediction set. For a given quantile level,τ, the regression equation is given by.QτjrðÞ ¼β0τðÞ þβ1τðÞr ð2ÞWhereβ0(τ)andβ1(
τ)∈Ra r et h ec o e fﬁcients. Then, the prediction of the target value is implemented based on ﬁtted quantile regression.2.2.3. Validation of the prediction procedureValidation is the process of evaluation of outputs from the predictionprocess compared to observed values. The gap ﬁll algorithm enables thecomputation of RMSE using a cross-validation procedure. The proce-dure starts with true data and removes some validation points to obtainartiﬁcially generated points, which referred to as data observed. Then,the observed data will be predicted andﬁlled with values. The compar- ison between dataﬁlled and the original data set will yield the metricRMSE (Gerber, 2018). In addition, the validity of the restored datasetassessed visually employing spatial coherence and a non-arti ﬁcial (nat- ural) look.2.3. Machine learning methodsIn this study three groups of data mining techniques: linear regres-sion, individual machine learning (base models), and ensemblemethods applied. Linear regression methods, both linear and multiple,are used to evaluate the inﬂuence of incorporating restored valuesfrom gapﬁll on wheat yield prediction. The latter two groups of modelsapplied to establish prediction models between predictors and responsevariable. In the second group, seven types of machine learning methodsi.e., Regularized Regression (GLMNET), Generalized Linear Regression(GLM), Neural Network (NNET), K-nearest Neighbors (KNN), RecursivePartitioning and Regression Trees (RPART), Support Vector Machine(SVM) and Random Forest (RF) applied. In general, the potential of ma-chine learning methods roots in the use of large dataset for training;nonetheless, as this study used a small dataset (67 points) we appliedseven different machine learning methods in light of harnessing the po-tential of each method under small dataset domain. Besides, the sevenmethods cover the wide diversity and potential representing variousgroups of ML in terms of their function. Thus, KNN and SVM methodsare selected from instance-based algorithms ( Aha et al., 1991) whereas GLMNET represents the regularization algorithms group. RPART is se-lected from decision tree algorithms category while RF is obtainedfrom ensemble group of algorithms. Neural Net has its own categoryand GLM model is from the group of linear regression ( Piccini, 2019; Brownlee, 2016).For each of the seven models, the following Sections ( 2.3.1–2.3.7) presented a short description of the methods, the hyperparameterswith their tuned values as well as theﬁnal selected hyperparameters.2.3.1. Regularized regression (GLMNET)Itﬁts generalized linear and similar models via penalized maximumlikelihood using gaussian regression model ( Friedman et al., 2010). It computes lasso or elastic net penalties at a grid of values for the regu-larization parameter lambda. Regularization methods are applied toestimate dependable predictor coefﬁcients when predictors are corre-lated. All the predictors in the model are kept if ridge regression isused. LASSO ensures sparsity of the results by shrinking some coef ﬁ- cients exactly to zero, while Elastic Net is a hybrid of ridge regressionand LASSO by adjusting the values of hyperparameter α(alpha) (Friedman et al., 2009) that has values in the range of 0≤α≤1. An alpha = 1 is the lasso penalty, and an alpha = 0 applies the ridge pen-alty. In this study,αis searched at three values of 0, 0.2, and 0.05, whilelambda, which controls the amount of regularization, is tuned for valuesof 10^seq (−3,−2, length = 8). The studyﬁnds an alpha = 0, and lambda = 0.007196857 as best tuning parameters.2.3.2. Support vector machine (SVM)Support Vector Machine is a supervised non-parametric algorithmcharacterized by using kernels, which act, on the margins ( Gunn, 1998). In regression, the input is mapped to a high-dimensional featurespace using a kernel function. Then, a linear regression model is con-structed in the new feature space (Cai et al., 2019;Hearst et al., 1998). In this study, the radial basis kernel, which is one of the widely used ker-nels, thatﬁts non-linear model used. Then, parameters such as sigmaand cost (C) are searched at values of 2^ (−11:-9) and 2^ (5,7) respec- tively. The studyﬁnds, sigma = 0.0004882812 and C = 128 as besttuning parameters.A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
2112.3.3. K-nearest neighbors (KNN)K-nearest Neighbors (KNN) is a supervised machine learning algo-rithms used for classiﬁcation and regression. In KNN, the number ofneighbors (k) is a constant used to calculate nearest neighbors distancesvector (RSrivastava, 2020). KNN is an instance-based learning; the out-put is the mean of the values of its k nearest neighbors ( Appelhans et al., 2015). The study tuned k for the range of 1:16 and selected k = 12 astheﬁnal value.2.3.4. Neural network (NNET)It is a network model consisting of input, hidden, and output layersto emulate a biological neural system. This study ﬁts a single-hidden- layer neural network. In NNET, the size parameter assigns the numberof units in the hidden layer. The weight decay parameter, or regulariza-tion, is a technique applied to the weights of a neural network. This pa-rameter prevents the weight from increasing too large as it multipliesthe weights after each update. In this study, linear activation functionis applied. The size parameter is searched for size = 1:3 and decay =10^ (seq(−3,−1, length = 5)) (Bishop, 1995;Fritsch et al., 2019). The NNET implementation in this study obtained size = 1, decay = 0.1,trace = FALSE, and linout = TRUE asﬁnal best values.2.3.5. Random forest (RF)It aggregates the predictions made by multiple decision trees. Eachtree relies on the values of a random vector sampled independentlyand with the same distribution (Breiman, 2001). The most important parameter, mtry that is the number of predictors that are picked ran-domly is searched for mtry = 2:6 (Breiman, 2002). The Random Forest implementation in this study obtained mtry = 2 as best value.2.3.6. Recursive partitioning and regression trees (RPART)These are decision tree algorithms used for classi ﬁcation and regres- sion learning tasks (Breiman et al., 2017;Terry and Beth, 2019). The complexity parameter (cp), which is the minimum improvement inthe model needed at each node, imposes a penalty to the tree for havingtoo many splits. It helps to select the optimal tree size as it controls thesize of the decision tree (Therneau and Atkinson, 2019). The study tuned cp at values of 10^seq (−3,−0.75, length = 25). The studyﬁnds an optimum cp = 0.07498942.2.3.7. Generalized linear regression (GLM)It generalizes linear regression by allowing the linear model to berelated to the response variable via a link function by allowing themagnitude of the variance of each measurement to be a function ofits predicted value (Nelder and Wedderburn, 1972;Hardin et al., 2007). This model allows us to build a linear relationship betweenthe response and predictors, even though their underlying relation-ship is not linear. The error distribution of the response variableneed not to have normal distribution, however it assumed to followan exponential family of distribution (i.e. normal, binomial, poisson,or gamma distributions). It applies a unique link function for eachof the probability distribution (McCullagh and Nelder, 1989). Thus, this study used a gaussian probability distribution with identity linkfunction.The dataset that contains both predictors and response variables waspartitioned into 80:20 ratios for training and testing (holdout) group.All parameters put on the same scale using data scaling method. In thelearning process, parameter tuning was implemented for each method.Caret package parameter tuning was implemented using the train con-trol function in R software, and the expand grid function supported thesearch process (Kuhn et al., 2020
).To estimate the generalization error,25 numbers of subsamples were created as training groups usingbootstrapping resampling method. The bootstrap method is a resam-pling approach used to calculate statistics on a population by iterativelysampling a dataset with replacement. It is a widely applicable and pow-erful statistical technique used to measure the uncertainty associatedwith a given statistical learning method ( James et al., 2013). Since we work with a small sample size in this study, the use of boot strappingis very relevant to estimation problems with small sample size and un-known distribution of the actual population ( Karthik and Abhishek, 2019).For each model, the best tuning parameters were selected using RootMean Squared Error (RMSE) metric. Then, the seven models were com-bined in Caret List function using the best tuning parameters on thetraining group using bootstrapping resampling procedure. The CaretList function is used as it supports building lists of caret models on thesame training data.2.4. Ensemble methodsEnsemble methods are the third major machine learning approachapplied. Ensemble learning is the process of learning from the advan-tage of combining multiple algorithms for better model performance.In applying a single method of supervised algorithms, the task is tosearch for a solution in parameter space, while ensembles combine mul-tiple parameter spaces to form a better hypothesis. The above sevenbase models were combined in an ensemble learning called Stackingor Super Learning (Wolpert, 1992) that trains a second-level metalearner to get the optimal combination of the base learners ( Laan et al., 2007).In this study, using Caret Stack function we applied the 5 fold cross-validation resampling method on the training dataset. Cross-validationis one of the commonly used techniques for model evaluation and con-sidered as a better technique than residual-based metrics ( Kohavi, 1995). This method ensures that every data point gets to be in a testset exactly once and disadvantageous to when used in large datasetdue to increasing computation cost, which was not relevant as thisstudy applied small dataset (Karthik and Abhishek, 2019). Outputs from the seven base models combined in a Caret Stack usingeach of the seven methods, which resulted in seven ensemble versions(Deane-Mayer and Knowles, 2019). The seven ensemble models in-clude ensemble Regularized Regression (en.GLMNET), ensemble Gener-alized Linear Regression (en.GLM), ensemble Neural Network (en.NNET), ensemble K-nearest Neighbors (en.KNN), ensemble RecursivePartitioning and Regression Trees (en.RPART), ensemble Support VectorMachine (en.SVM) and ensemble Random Forest (en.RF).The RMSE metric used to select the best tuning parameters. Finally,the performance of the models was measured on the holdout group.The overall steps used are presented in Fig. 2. Finally, in addition to the RMSE metric, this study used scatter anal-ysis to validate the performance of machine learning methods. In partic-ular, scatter plots of measured grain versus estimated grain valuesprepared for training and holdout groups helped to validate model per-formances (Wang et al., 2019).3. Result3.1. Cloud restoration and prediction accuracyWe implemented gapﬁll on images from the study season using 21images. The demand for high performance computing (HPC) challengedthe implementation of the gapﬁll. Hence, we divided the study area intosmaller spatial units such as tiles of size 100 pixels by 100 pixels. Thisenabled us to get prediction results for all images except where cloudcoverage per a sub-image was 100%. Accordingly, in Fig. 3, the overall cloud percentage per the subset was 16%; all the sub-images weregapﬁlled except in a sub-image dated October 11 of the year 2019. Tooffer prediction results, gapﬁll requires non-zero observation valuesper a sub-image as evidenced on October 1, 2017, and October 16, 2017.The detailed visual examination of prediction outputs showed thepresence of differences in spatial coherence property compared toneighboring pixels. For example, sub-images with smaller cloudA.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
212Fig. 3.A subset of 100 *100 pixels of NDVI with 16% cloud percentage (top) and the corresponding gap ﬁlled image (bottom).RMSE and Sca/g425er PlotExpand grid
Boot Strapping
Train Control
Boot Strapping
Train ControlIndividual ML Methods
Tuning Parameters
Base models (Caret List)
Ensemble in Caret Stack
Base and Ensemble
Fig. 2.Showing major learning steps applied for base and ensemble models.A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
213coverage such as September 26, 2018, and October 1, 2019, have a uni-form texture; whereas, an image dated October 16, 2017, that has largecloud coverage shows a different and unique texture compared with theadjacent images. This indicates the cloud percentage per sub-imageinﬂuences the spatial coherence and texture of the image. Besides,outputs from quantitative analysis presented in Table 1revealed similar result.As expected with an increasing percentage of cloud coverage persubset, the RMSE increases too. For instance, in column 15, the RMSEhas increased from 0.04 to 0.07 and then to 0.26 as the cloud percentageincreases from 28% to 54% and then to 58%. This is because with increas-ing cloud coverage the prediction method iteratively enlarges theprediction subset along the spatio-temporal dimension to get the re-quired statistics. It could add also heterogeneous values in the subsetthat increases the probability of offering poor prediction estimates. Inaddition, it contradicts the theoretical assumption that a much narrowprediction subset is expected to offer good quality prediction in linewith Tobler'sﬁrst law of geography that states near things are morerelated than distant things.3.2. Challenges of the restoration processThe original work of gapﬁll prediction method implemented onMODIS dataset that has a medium spatial resolution (500 m). In north-ern Alaska, gapﬁll was applied using 48 images that comprise missingvalues of≈3.7×1 0
6using 80 cores of an Intel Xeon CPU E7 –2850 at 2 GHz and it took 10 h. In this study, we applied gap ﬁll on NDVI derived from S2 with 10 m spatial resolution and 5 days temporal resolution.Such an increment in spatial resolution resulted to increase the missingvalues largely. In the meantime, our goal was to test the feasibility of theprediction method in an environment with limited computing capacity.In this regard, we tiled the study area along the x and y dimensions withan approximate dimension of 100*100 pixels. Accordingly, for an arrayof dim1 = 100, dim2 = 100, dim3 = 7, dim4 = 3, with a total numberof data values of 210,000, the data restoration process took an average of9 min using Intel(R) Core(TM) i9-9900k cpu @3.60 GHz 3.60 GHz with32 GB Ram and with 8/16 number of Cores/Threads. For 5.7 × 107obser- vation pixels, it took≈41 h to predict. In the absence of HPC, we usedtiling as a solution; nonetheless, it compromised the quality of the out-puts in two ways. First, it creates lines along the boundaries of the tilesin contrast to the seamless boundary. Second, it creates sub-imageswith 100% cloud coverage that do not restore because of the inherentproperty of the gapﬁll algorithm. For instance,Fig. 4demonstrates two cases where tiling creates boundary lines. On the left image wherehigh NDVI values dominated, the tile boundaries are more visible com-pared to the right one where low values are prominent.The limitation of the gapﬁll in sub-images with 100% cloud coverageis illustrated usingFig. 5. Sub-image dated October 11, 2019, returnedno prediction values. The computing demand could be reduced usingsmaller tiles. However, as the size of the tile decreases, the number ofsub-images with 100% cloud coverage increases. For instance, on theleft side ofFig. 5prepared using four tiles each with 100*100 dimensionshowed fully unrestored (NA) output on the top left corner. Whereas,the corresponding image on the right using 200*200 pixel dimensionfully recovered.Hence, tiling implementation need to consider techniques that avoidthe creation of sub-images with full cloud coverage taking the tradeoffbetween the available computing infrastructures versus the size of thetile. In this research, as we applied square tiles we obtained some sub-images with partial restoration. Nonetheless, as shown in Fig. 6pixels restored for most of the study area.3.3. Data mining techniques3.3.1. Linear regressionUnderSection 3.2, phenology-based cloud restoration implementedusing gapﬁll. The restored NDVI used to create the NDVI variable calledsum-NDVI. Sum-NDVI is the sum of all NDVI values per each of the studyfarm boundaries (Mirasi et al, 2019). We also validated the accuracy ofthe restoration process. In this section as a prediction problem, weimplement linear regression analysis by combining observations bothfrom original cloud-free and restored images. The addition of observa-tions from the restored image increases the total number of observa-tions. Nevertheless, whether such increment positively in ﬂuences the prediction problem should be explained. Hence, the purpose of the anal-ysis is to identify how the inclusion of observations from restored im-ages affects the regression process.Accordingly, for images dated 2017/10/01 and 2017/10/16, the res-toration process offered newly restored observations of 20 and 22with the corresponding adj R
2values of 0.40 and 0.54 (Table 2fully re- stored column). An increase in the number of observations for the com-bined analysis is associated with an increase in prediction metrics. Inparticular, images from 2017/10/11, 2018/10/01, 2018/10/21 andTable 1Validation of the gapﬁll prediction output across a range of cloud percent-age.No Column Cloud % per subset RMSE1 1 19% 0.062 1 40% 0.043 1 52% 0.084 7 20% 0.065 7 46% 0.236 7 50% 0.117 15 28% 0.048 15 54% 0.079 15 58% 0.26
Fig. 4.Two groups of NDVI mosaicked using four tiles (each with 100*100 pixels size), on the left tile boundaries exist and on the right closer to seamless mosa ic (no boundary lines).A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
2142018/10/26 that got increment of observations resulted in improve-ment of adj R
2values from 0.44, 0.56, 0.27 and 0.42 to 0.55, 0.57, 0.41and 0.46 respectively.This revealed the incorporation of restored obser-vations in the regression process is advantageous in increasing predic-tion capability and implies the values are good enough.Nonetheless, an image from the date of 2017/09/26 did not showany improvement. Furthermore, in 2018/10/16 image, though thetotal number of observations increased from 40 to 67, the adj R
2de- creased from 0.65 to 0.44. In this study, we applied similar tuning pa-rameters across the spatio-temporal image set; nonetheless, theperformance of these tuning parameters could vary across the scenesin space and time domain. This in turn could in ﬂuence the quality of the restored images and ultimately the derived variables.The advantage of restored values for a possible increment ofyield prediction also assessed using multiple linear regressions(Table 3). Accordingly, the multiple linear regression output donot show improvement over univariate regression which is pre-sented underTable 2. Besides, in light of boosting the prediction po-tential, we added two additional predictors, namely, NPS and Urea.The result has shown an increase in prediction potential from 0.54using sum-NDVI composite to 0.65 using the combined dataset(sum-NDVI plus inputs). Such increment in prediction capability isresulted from the application of NPS and Urea and showed signi ﬁ- cance levels at 99.9 and 95% conﬁdence intervals respectively (SeeTable 3).3.3.2. Machine learning methodsThe study applied seven machine learning methods for regressionproblems using three datasets: sum-NDVI (2018), sum-NDVI & inputs(2018) and sum-NDVI (2017) (Table 4).
Table 2Comparison of original, combined (original + restored), and fully restored observations using linear regression model for the years of 2017 and 2018 .Univariate Linear Regressions for 2017 and 2018No Date Original Combined (Original + Restored) Fully restoredR
2p-value N R2p-value N R2p-value N1 2017/09/26 ⁎⁎⁎0.51 1.60e-09 52 0.50 1.02e-10 62 –– – 2 2017/10/01 ⁎⁎–– – –– – 0.40 0.00 20 3 2017/10/11 ⁎⁎⁎0.44 5.96e-09 59 0.55 4.68e-13 67 –– – 4 2017/10/16 ⁎⁎⁎–– – –– – 0.54 6.26e-05 22 5 2018/10/01 ⁎⁎⁎0.57 1.01e-12 62 0.57 1.68e-13 66 –– – 6 2018/10/16 ⁎⁎⁎0.66 1.51e-10 40 0.45 4.28e-10 67 –– – 7 2018/10/21 ⁎⁎⁎0.27 2.71e-10 15 0.41 8.48e-09 63 –– – 8 2018/10/26 ⁎⁎⁎0.42 3.52e-08 56 0.46 2.10e-10 67 –– –⁎⁎⁎Signiﬁcant at 99.9%. ⁎⁎Signiﬁcant at 99%.
Fig. 5.Gapﬁlled images of NDVI prepared by mosaicking four tiles of 100*100 pixel dimension(left) and images using 200*200 pixel dimension (right).
Fig. 6.Gapﬁlled NDVI images of the full study area for the two study years with unrestored areas depicted as black spots).A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
215In general, across the seven methods and along with the threedatasets RPART, GLMNET, GLM and NNET are the four models yieldingthe lowest RMSE values on the training dataset. All the four models re-sulted in RMSE values of 0.001 t/ha for sum-NDVI dataset of the year2018 and 2017, while RPART revealed the same result on the thirddataset too. Random Forest is also among the models yielding smallestRMSE values on sum-NDVI and inputs (2018) dataset. Conversely, twomodels such as SVM and KNN showed in relative terms lower perfor-mance across the three datasets except KNN revealed one of the lowestoutputs (0.001 t/ha) on sum-NDVI & inputs(2018) dataset.3.3.3. Ensemble modelsUnderSection 3.3.2, individual base models were prepared and hereoutputs from the seven base models used as predictors and trained toprepare seven ensemble models (Table 5).Accordingly, two ensembles: en.GLMNET and en.RPART are the twomodels with better training performance. For instance, on sum-NDVI of2018 dataset, en.GLMNET (0.012 t/ha), en.GLM (0.015 t/ha) and RPART(0.018 t/ha) produced the lowest values of RMSE. On sum-NDVI & in-puts (2018) dataset, en.RPART (0.018 t/ha), en.GLMNET (0.056 t/ha),en.GLM (0.061 t/ha) and en.RF (0.051 t/ha) offer the lowest values ofRMSE. On the sum-NDVI (2017) dataset, the seven ensemble versionsrevealed closer outputs; nonetheless, en.GLMNET and en.RPART pro-duced some of the optimum results within the group.3.3.4. Validation on holdout groupSection 3.3.2presented results from base models on the traininggroup. In this section, outputs using three datasets on the holdoutgroup presented (Fig. 7).Accordingly, the GLMNET, GLM and NNET models, which show bet-ter performance on the training group, revealed good generalization onsum-NDVI (2018) and sum-NDVI (2017) datasets. Regularized Regres-sion (GLMNET) model showed a slight increase of RMSE from0.001 t/ha on the training group to 0.006 t/ha on holdout group usingsum-NDVI (2018) dataset. Likewise, the GLM model on sum-NDVI(2017) showed a slight increase of RMSE from 0.001 t/ha on the traininggroup to 0.015 t/ha on holdout group. The neural net model has RMSE of0.001 t/ha, 0.001 t/ha, and 0.017 t/ha on the training group compared to0.033 t/ha, 0.006 t/ha, and 0.09 t/ha on hold out group for datasets ofsum-NDVI (2018), sum-NDVI (2017) and sum-NDVI & inputs (2018)respectively.Conversely, RPART and RF in relative terms showed over ﬁtting across the three datasets. For instance, RPART and RF models on sum-NDVI (2018) have RMSE 0.001 t/ha and 0.028 t/ha on the trainingdataset that increased to 0.161 t/ha and 0.136 t/ha on the holdoutgroup. On the other hand, SVM and KNN models demonstrate proper-ties of underﬁtting where performance on the training is lower thanthe holdout.In general, ensemble models expected to outperform basemodels.Fig. 8presented the comparison of base models and ensem-bles across the three datasets on holdout group. On sum-NDVI andinputs (2018) dataset, ensemble models constitute two of the topfour models i.e., GLMNET (0.001 t/ha), GLM (0.001 t/ha) en.RPART(0.015 t/ha), and en.GLMNET (0.045 t/ha). Similarly, on sum-NDVI(2018) dataset, GLMNET (0.001 t/ha), GLM (0.001 t/ha), en.GLMNET(0.015 t/ha), KNN (0.01 t/ha) and en.RPART (0.015 t/ha) are the topﬁve models of which the two are ensembles. On the other hand, acomparison using sum-NDVI (2017) dataset showed that an ensem-ble model, en.RF (0.008 t/ha), is among the top four models. None-theless, ensembles such as en.SVM (0.245 t/ha) and en.NNET(0.172 t/ha) are among the least performing ones on sum-NDVI(2017) dataset.3.3.5. Model validation using scatter plot analysisModel comparisons presented under Sections of 3.3.2,3.3.3and3.3.4 applied RMSE measure. To further consolidate and verify performancesin this part graphical analysis is used. In particular, scatter plots for mea-sured grain yield versus estimated grain yield implemented for modelsthat revealed better performance based on RMSE metric. A perfect scat-ter plot demonstrated two characteristics. First, the 1:1 diagonal lineshould pass through the origin of the plot. Second, the range of esti-mated values (y-axis) should be equal to the range of measured values(x-axis).Fig. 9presented six scatter plots for the sum-NDVI (2018) dataset forthree base models where each model has two plots for the traininggroup and its holdout equivalent. Thus, based on scatter plot analysis,GLM, RF and GLMNET in their order are the three better models. In par-ticular, the GLM model revealed better performance both on the train-ing and holdout group because the 1:1 diagonal line placed closely tothe origin and the good match between the range of values along thex and y axes. Besides, the performance of these models also veri ﬁed using RMSE error presented under
Section 3.3.4. Based on RMSE measure ensemble models such as en.GLMNETand en.GLM were also among the best models as discussed underSection 3.3.4. Nonetheless, their scatter plot performance does notsupport the RMSE performance.Fig. 10presented eight scatterTable 3Multiple linear regression outputs of three groups of combined (original and restored observations) datasets and inputs: sum-NDVI of 2017, sum-NDV I of 2018 and sum-NDVI of 2018 with inputs.No Dataset R
2p-value1 2017/10/21 + 2017/10/11 + 2017/10/06 + 2017/10/26 0.54 1.141e-10 2 2018/09/26 + 2018/10/01 + 2018/10/06 + 2018/10/11 + 2018/10/16 + 2018/10/21 + 2018/10/26 0.54 8.962e-093 2018/09/26 + 2018/10/01 + 2018/10/06 + 2018/10/11 + 2018/10/16 + 2018/10/21 + 2018/10/26 + NPS ⁎⁎⁎+ UREA⁎0.65 1.155e-09⁎⁎⁎Signiﬁcant at 99.9%. ⁎Signiﬁcant at 95%.
Table 4Comparison of base models for the years of 2018 and 2017 using RMSE(t/ha) on trainingdata using Boot Strapping Method.Models sum-NDVI (2018) sum-NDVI & inputs (2018) sum-NDVI (2017)GLMNET 0.001 0.073 0.001SVM 0.027 0.076 0.154KNN 0.058 0.001 0.006NNET 0.001 0.017 0.001RF 0.028 0.001 0.015RPART 0.001 0.001 0.001GLM 0.001 0.089 0.001
Table 5Seven ensemble models using the seven base models as input on training data (RMSE arereported in t/ha).Models sum-NDVI (2018) sum-NDVI & inputs (2018) sum-NDVI (2017)en.GLMNET 0.012 0.056 0.163en.SVM 0.099 0.165 0.311en.KNN 0.298 0.109 0.079en.NNET 0.354 0.180 0.194en.RF 0.051 0.123 0.166en.RPART 0.018 0.018 0.128en.GLM 0.015 0.061 0.166A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
216plots for four better ensemble models. Accordingly, ensemblesmodels showed poor performance, i. e., lower generalization on the holdout group. To be exact, the diagonal lines showed a clear shiftfrom the origin on the holdout group. Consequently, based onRMSE and graphical measures ensemble models do not show im-provement over base models.3.3.6. Ensembles based on ranking of base learnersThe ensemble models, presented under Section 3.3.5, were imple- mented using seven base learners as input and do not show improve-ment over base models. Nonetheless, previous studies revealed, todevelop an ensemble learner with better predictive potential, two con-ditions need to be met (Krogh and Vedelsby, 1995;Zhou, 2009). First,
GLMNETSVM KNNNNETRFRPARTGLMen.GLMen.RFen.SVMen.GL
MNETen.NNETen.KNNen.RPART sum-NDVI(2018)0.001 0.020 0.010 0.033 0.136 0.161 0.001 0.019 0.084 0.081 0.015 0.296 0.166 0.015sum-NDVI & Inputs(2018)0.001 0.058 0.097 0.090 0.126 0.161 0.001 0.044 0.140 0.130 0.045 0.135 0.175 0.015sum-NDVI(2017)0.001 0.123 0.027 0.006 0.192 0.001 0.001 0.066 0.008 0.245 0.067 0.172 0.108 0.1010.0000.0500.1000.1500.2000.2500.3000.350RMSE( t/ha)sum-NDVI(2018) sum-NDVI & Inputs(2018) sum-NDVI(2017)
Fig. 8.Comparison of base models and ensembles on holdout group in RMSE (t/ha) for three dataset groups.
0.0000.0500.1000.1500.2000.250
GLMNET SVM KNN NNET RF RPART GLMRMSE (t/ha)
Base Modelssum-NDVI(2018)Train sum-NDVI(2018)Holdout sum-NDVI & Inputs(2018)Trainsum-NDVI & Inputs(2018)Holdout sum-NDVI(2017)Train sum-NDVI(2017)Holdout
Fig. 7.Bar graph showing performance of base machine learning methods across three datasets using RMSE (t/ha).A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
217the input base learners should have sufﬁcient diversity. Second, each of the individual base learners ought to be as accurate as possible. Practi-cally, methods such as sub-sampling the training examples, modifyingthe attributes, manipulating the outputs, adding randomness into learn-ing methods, or even using multiple ways at the same time help toachieve the diversity of the base learners ( Krogh and Vedelsby, 1995; Zhou, 2009). The accuracy of learners could be estimated using methodssuch as cross-validation and holdout. On the other hand, Yang and Lv, 2021described three groups of strategies for selecting the base learnersuch as clustering-based methods, ranking-based methods andselection-based methods. The ranking-based method ﬁrst applies a cer- tain accuracy measurement to rank the base learners. Then, it uses asuitable stopping criterion to choose some base learners for creatingan ensemble (Martinez-Munoz et al., 2008). Therefore, in this study, we adopted the ranking-based methodusing the performance of base learners on the holdout group. That is,ensembles are developed using outputs from the three best performingbase learners such as GLM, RF and GLMNET models as predictors. Onceagain, the seven machine learning methods used to create seven ensem-ble versions. Thus,Fig. 11revealed scatter plots for the top four ensem-bles based on ranking method.A c c o r d i n g l y ,t h es a m et y p eo fe n s e m b l e ss u c ha se n . R F ,e n . K N N ,en.GLM and en.GLMNET that were better using the full base learnersfound to be also the better ones using the ranking method too. None-theless, the new sets of ensembles based on ranking method do notshow improvement over theﬁrst group of ensembles using fullbase learners. In summary, in this study, though ensembles devel-oped using two different approaches, they did not result in improvedperformance over base learners. This could be associated with thelimited diversity of base learners and the use of a small datasetwhere each observation point has a large weight on model perfor-mance affecting model stability.4. DiscussionWe applied gapﬁll algorithm on NDVI dataset derived from S2 im-ages having a high spatial and temporal resolution. The pioneer researchusing gapﬁll used MODIS NDVI product with eight days of temporal res-olution and 500 m spatial resolution in Northern Alaska. The study usedimages from six years period: 2004 –2009 and from the dates of May 24to September 13. In such a setup, the good data per day of the year was30%, and 48 images (Gerber et al., 2018).
Fig. 9.Scatter plot showing graphical performance of better performing base models for sum-NDVI(2018) dataset. On the left column, T represents performan ce on training group; on the right column, H represents performance on holdout group. The diagonal lines showed the 1:1 relationship.A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
218In this study, we used images from three years period (2017-2019)and from August 26 to September 26 making 21 images. The tiling pro-cess affected the percentage of cloud coverage in sub-images. It createdfully covered sub-images; hence, the good data per day of the year wasas low as 0%. Consequently, the gapﬁll did not result in a full restorationof the study area. In contrast, in the original study as the maximumcloud percentage was 70% all the missing values restored. Yet, on bothof the studies, the prediction accuracy decreases with the increment ofcloud percentage per subset. In the pioneer study, for cloud percentagesof 20%, 30%, 40% and 50% the RMSPE (Root Mean Square PercentageError) were 41.86, 42.54, 41.34, and 59.58 respectively ( Gerber et al., 2018).Therefore, in terms of getting a fully restored subset, the cloud per-centage per day of the year is the most important parameter. In thisstudy, we used square tiles that resulted in full cloud cover in somesub-images and get predictions for most of the study area. Future stud-ies might consider other tiling procedures that potentially avoid or min-imizes the number of sub-images with full cloud cover.In this study, the gapﬁll algorithm implemented using the defaultconﬁguration. It begins by identifying a four-dimensional array aroundthe missing values to predict. Then, the subset has λx=λy=5p i x e l salong the x and y dimensions from the missing value, λs = 1step in both directions of the seasonal index and,λa = 3 years in both direc- tions of the year index. Thus, the major difference between the currentstudy and the pioneer study is on the value of the year index. In the pi-oneer study (Gerber et al., 2018),λa = 6 years was used, while the cur-rent study usedλa = 3. The two studies have closer values of themaximum seasonal index, i.e., on the pioneer research λs could have a maximum value of 8 while the current study could have a maximumλs=7 .In applying gapﬁll, in this study, we started by considering two keychallenges. First, since the S2 sensor is recently available, images areavailable only for three years. Second,S2is a high spatial resolution sen- sor (10 m) making the total number of missing values to be too large.Hence, it demands the use of high computing infrastructure, which isunfortunately not available in many situations.Given such limitations, the study has successfully applied gap ﬁll under the current study area. In this study, our main goal was to under-stand the predictive skill of the sum-NDVI parameter using original andrestored observations using gapﬁll. Except for a single date (2018/10/16), the incorporation of restored observations in regression analysis of-fered an increased prediction skill. Thus, the gap ﬁll method offered
Fig. 10.Scatter plot showing graphical performance of better performing four ensemble models for sum-NDVI(2018) dataset. On the left column, T represents p erformance on the training group; on the right column, H represents performance on the holdout group. The diagonal lines showed the 1:1 relationship.A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
219quality estimates for cloudy pixels that are useful in empirical-basedy i e l de s t i m a t i o nw i t hp o s i t i v ei nﬂuence in theﬁnal models. In this study, ensemble models do not show improvement over basemodels. Base models such as GLM, RF and GLMNET revealed RMSE of0.001 t/ha, 0.136 t/ha and 0.001 t/ha for sum-NDVI(2018) dataset aswell as 0.001 t/ha, 0.192 t/ha and 0.001 t/ha for sum-NDVI(2017)dataset. In contrast, RPART and RF models in relative terms showedoverﬁtting across the three datasets. On the other hand, models suchas SVM and KNN demonstrate properties of under ﬁtting in which per- formance on the training is lower than the holdout. The addition ofother hyperparameters besides the limited parameters used in the cur-rent study could improve the performance of these models.The superior performance of the GLM algorithm could be associatedwith the inherent nature of the model and the relationship between theresponse and predictor variables. Generalized Linear Model used tohandle non-linear relationship as it transforms the original responsevariable using the link function to be linearly related to the independentvariables (Hardin et al., 2007). As previous studies indicated, the major-ity of the relationship between wheat yield and sum-NDVI is linear(Kumhálová and Matějková, 2017). Yet, there is some non-linearity(Zhao and Cen, 2013;Ram, 2021) that needs to be explained. Hence,the use of the GLM with Gaussian distribution and identify link functionwill transform such non-linearity to linear model offering increasedmodel representation.Random Forest is an ensemble algorithm that use bootstrap aggrega-tion method, in particular, it computes average prediction from variousdecision trees predictions. This enables RF models to be less in ﬂuenced by outliers. This study is implemented using small number of observa-tion and decided to keep all the sample observations that potentiallyconstitute some outliers. Thus, algorithms such as RF, which are lessprone to outliers, are expected to yield increased performance. Besides,RF algorithm is powerful in handling both linear and non-linear rela-tionship (Murthy, 2020;Trehan, 2020).The ability of machine learning to learn information directly fromobserved data is commonly applied using big dataset, whereas ML forsmall dataset is a new and growing area of research and development(Forman and Cohen, 2004;Shaikhina et al., 2014). This is associated partly with, in some applications, for instance, in biomedical and mate-rial sciences; the collection of samples requires high cost ( Feng et al., 2019). The training and initialization routines of machine learning algo-rithms involve randomization that commonly improves the conver-gence of the learning process to the global minimum. Nonetheless,
Fig. 11.Scatter plot showing graphical performance of better performing four ensemble models based on ranking method for sum-NDVI (2018) dataset. On the lef t column, T represents performance on the training group, on the right column; H represents performance on the holdout group. The diagonal lines showed the 1:1 relationship .A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
220this process negatively affects the stability and generalization capacityof algorithms. In using small dataset, the problem becomes more pro-nounced (Forman and Cohen, 2004).As a growingﬁeld of research, the use of ML under small dataset do-main various across various disciplines. In some ﬁelds, for instance, in materials physics and chemistry, numerous studies applied ML tosmall dataset. A backpropagated Neural Network model using 53 pointsused successfully to predict the properties of ultrahigh-performanceconcrete (Ghafari et al., 2015). A strategy named as crude estimationproperty was proposed to improve ML on small datasets (around 100data points) (Zhang and Ling, 2018). Similarly, Shaikhina et al., 2015 de-signed neural net and decision tree algorithms for prediction ofantibody-mediated kidney transplant rejection using 35 bone speci-mens and 80 kidney transplants and achieved high accuracy of 98.3%and 85% respectively.In some previous studies, ensemble models showed superiority tobase models. For example, a stacking ensemble of ANN revealed a rela-tive RMSE of 6.8% and R
2of 0.68 at the predicted yield in sugar cane cropusing MODIS NDVI time series (Fernandes et al., 2017). The superior performance of ensemble models is also reported on other bio-physical datasets. An Ensemble of gradient boosting, multi-narrativeadaptive regression spline, random forest, and Support Vector Machineoutperformed the individual models for surface soil organic carbonstocks (Mishra et al., 2020). An average-ensemble model is recom-mended as the best model in materials design using 25 numbers of ob-servations (Vanpoucke et al., 2020).Nonetheless, in this study, although two ensemble approaches areapplied, the performances of ensemble models do not show improve-ment over base models.Overall, comparison of the current outputs with previous studyoutputs could be problematic due to factors such as discipline differ-ence and difference in study design and procedure. Even for samediscipline, the implementation of different study design (resamplingprocedures, outlier treatments, data split, and the number and typeof hyperparameters searched) might contribute to reveal differentresult. Therefore, the difference between the two models (GLM andRF) and the restﬁve models could be explained partly by the studydesign implemented.5. Conclusion and recommendationsIn this study, the application of gapﬁll on high-resolution imagery, S2, resulted in good quality estimates of cloudy pixels. Consequently,regression-based crop prediction methods bene ﬁted. The rare availabil- ity of HPC, especially in resource-limited environments is the majorchallenge of applying gapﬁll in high-resolution sensors. The studyshowed that the use of images from a critical window of the crop phe-nology and implementation of square tiles are the possible solutionsfor decreasing the demand for HPC.The study evaluated base machine learning and ensemble methodsfor wheat yield prediction. Ensemble methods produced a similar per-formance with that of base models. Ensemble models using the sevenpredictors from base models as well as using three selected predictorsbased on accuracy following the ranking methodology showed similarperformance. The study, employing sum-NDVI dataset, predicts wheatgrain yield with RMSE of 0.001 t/ha and 0.136 t/ha using GLM and RFmodels respectively. The two models showed consistent and better per-formance across the three dataset groups. Besides, they showed goodgeneralization on holdout dataset that is also supported using scatterplot analysis.Given the small number of observation samples, the study success-fully exploited the synergy of combining the spatio-temporal gap ﬁll method, phenology and machine learning methods and revealed a reli-able yield prediction approach.Overall, satellite-based farm-level yield prediction methods arerarely available in many crop production systems. Therefore, themethods revealed in this study will be crucial in numerous projectssuch as food security, crop insurance among others where farm-levelyield data are key inputs. Furthermore, though the study revealedyield prediction methodology for wheat, the same approach could beadopted to develop reliable remote sensing based yield predictionmethods for other cereal crops including barley, maize, and sorghum.FundingThe authors would like to thank the Ethiopian Space Science andTechnology Institute for providingﬁnancial support. Besides, we ac- knowledge the Ethiopian Civil Service University for sponsoring theprincipal investigator.Data availability statementWe would like to conﬁrm that the data supporting the current studyis available based on reasonable request.Declaration of Competing InterestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to in ﬂu- ence the work reported in this paper.AcknowledgmentArsi-Sire Wereda administration facilitated the ﬁeld data collection. We acknowledge to Ethiopian Geospatial Institute and in particular toTulu Besha (Ph.D) for offering computing infrastructure. We offer ourspecial gratitude to Dagmawi Teklu (Ph.D) for commenting the manu-script.References
Adams, M.L., Cook, S.E., Caccetta, P.A., Pringle, M.J., 1999, January. Machine learning methods in site-speciﬁc management research: An Australian case study. Proceed-ings of the Fourth International Conference on Precision Agriculture. American Soci-ety of Agronomy, Crop Science Society of America, Soil Science Society of America,Madison, WI, USA, pp. 1321 –1333. Aha, D.W., Kibler, D., Albert, M.K., 1991. Instance-based learning algorithms. Mach. Learn. 6 (1), 37–66.Appelhans, T., Mwangomo, E., Hardy, D.R., Hemp, A., Nauss, T., 2015. Evaluating machine learning approaches for the interpolation of monthly air temperature at Mt. Kiliman-jaro, Tanzania. Spatial Stat. 14, 91 –113. Atkinson, P.M., Jeganathan, C., Dash, J., Atzberger, C., 2012. Inter-comparison of four models for smoothing satellite sensor time-series data to estimate vegetation phenol-ogy. Remote Sens. Environ. 123, 400 –417. Bishop, C.M, 1995.Neural networks for pattern recognition . Oxford university press. Brasesco, F., Asgedom, D., Casari, G., 2019. Strategic Analysis and Intervention Plan for Fresh and Industrial Tomato in the Agro-Commodities Procurement Zone of thePilot Integrated Agro-Industrial Park in Central-Eastern Oromia, Ethiopia. FAO,Addis Ababa.Breiman, L., 2001.Random forests. Mach. Learn. 45, 5 –32. Breiman, L., 2002. Manual On Setting Up, Using, And Understanding Random Forests.Berkeley.https://www.stat.berkeley.edu/~breiman/Using_random_forests_V3.1.pdf . Breiman, L., Friedman, J.H., Olshen, R.A., Stone, C.J., 2017. Classiﬁcation and Regression Trees. Routledge.Brownlee, J., 2016.Master Machine Learning Algorithms: Discover how they Work andImplement them from Scratch. Machine Learning Mastery.Cai, Y., Guan, K., Lobell, D., Potgieter, A.B., Wang, S., Peng, J., Xu, T., Asseng, S., Zhang, Y.,You, L., Peng, B., 2019.Integrating satellite and climate data to predict wheat yieldin Australia using machine learning approaches. Agric. For. Meteorol. 274, 144 –159. Deane-Mayer, Z.A., Knowles, J.E., 2019. caretEnsemble: Ensembles of Caret Models. p. 35 R package version,2(1).Dodds, F., Bartram, J., 2016.The Water, Food, Energy and Climate Nexus: Challenges andan Agenda for Action. Routledge.Drummond, S.T., Sudduth, K.A., Birrell, S.J., 1995. Analysis and Correlation Methods for Spatial Data. ASAE Paper No. 951335ASAE, St. Joseph, Mich.Drummond, S.T., Sudduth, K.A., Joshi, A., Birrell, S.J., Kitchen, N.R., 2003. Statistical and neural methods for site –speciﬁc yield prediction. Trans. ASAE 46 (1), 5. Feng, S., Zhou, H., Dong, H., 2019. Using deep neural network with small dataset to predictmaterial defects. Mater. Des. 162, 300 –310. Fernandes, J.L., Ebecken, N.F.F., Esquerdo, J.C.D.M., 2017. Sugarcane yield prediction in Brazil using NDVI time series and neural networks ensemble. Int. J. Remote Sens.38 (16), 4631–4644.A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
221Fischer, R.A., 2011.Wheat physiology: a review of recent developments. Crop Pasture Sci.62 (2), 95–114.Forman, G., Cohen, I., 2004, September. Learning from little: comparison of classi ﬁers given little training. European Conference on Principles of Data Mining and Knowl-edge Discovery. Springer, Berlin, Heidelberg, pp. 161 –172. Friedman, J., Hastie, T., Tibshirani, R., 2009. Glmnet: Lasso and Elastic-Net Regularized Generalized Linear Models. R package version 1.Friedman, J., Hastie, T., Tibshirani, R., 2010. Regularization paths for generalized linear models via coordinate descent. J. Stat. Softw. 33 (1), 1.Fritsch, Stefan, Guenther, Frauke, Wright, Marvin N., 2019. neuralnet: Training of Neuraletworks. R package version 1.44.2. https://CRAN.R-project.org/package=neuralnet . Garonna, I., de Jong, R., Schaepman, M.E., 2016. Variability and evolution of global land surface phenology over the past three decades (1982 –2012). Glob. Chang. Biol. 22 (4), 1456–1468.Gerber, F., 2018. Fill Missing Values in Satellite Data. Package ‘gapﬁll’.https://git.math. uzh.ch/ﬂorian.gerber/gapﬁll. Gerber, F., de Jong, R., Schaepman, M.E., Schaepman-Strub, G., Furrer, R., 2018. Predicting missing values in spatio-temporal remote sensing data. IEEE Trans. Geosci. RemoteSens. 56 (5), 2841–2853.Ghafari, E., Bandarabadi, M., Costa, H., Júlio, E., 2015. Prediction of fresh and hardened state properties of UHPC: comparative study of statistical mixture design and an ar-tiﬁcial neural network model. J. Mater. Civ. Eng. 27 (11), 04015017.Gomez, D., Salvador, P., Sanz, J., Casanova, J.L., 2019. Potato yield prediction using machine learning techniques and sentinel 2 data. Remote Sens. 2019 (11), 1745.Gunn, S.R., 1998.Support vector machines for classi ﬁcation and regression. ISIS Tech. Rep. 14 (1), 5–16.Hardin, J.W., Hardin, J.W., Hilbe, J.M., Hilbe, J., 2007. Generalized Linear Models and Exten- sions. Stata press.He, L., Mostovoy, G., 2019.Cotton yield estimate using Sentinel-2 data and an ecosystemmodel over the southern US. Remote Sens. 2019 (11), 2000.Hearst, M.A., Dumais, S.T., Osuna, E., Platt, J., Scholkopf, B., 1998. Support vector machines. IEEE Intell. Syst. Appl. 1998 (13), 18 –28. Hird, J.N., McDermid, G.J., 2009. Noise reduction of NDVI time series: an empirical com-parison of selected techniques. Remote Sens. Environ. 113 (1), 248 –258. Jaikla, R., Auephanwiriyakul, S., Jintrawet, A., 2008. Rice yield prediction using a SupportVector Regression method. Conference: Electrical Engineering/Electronics, Computer,Telecommunications and Information Technology, 2008. ECTI-CON 2008. 5th Inter-national Conference on. Vol. 1. https://doi.org/10.1109/ECTICON.2008.4600365 . James, G., Witten, D., Hastie, T., Tibshirani, R., 2013. An Introduction to Statistical Learning. Vol. 112. springer, New York, p. 18.Jiang, D., Yang, X., Clinton, N., Wang, N., 2004. An artiﬁcial neural network model for es- timating crop yields using remotely sensed information. Int. J. Remote Sens. 25 (9),1723–1732.Kalluri, S.N.V., Zhang, Z., JaJa, J., Liang, S., Townshend, J.R.G., 2001. Characterizing land sur- face anisotropy from AVHRR data at a global scale using high performance comput-ing. Int. J. Remote Sens. 22 (11), 2171
–2191. Karthik, R., Abhishek, S., 2019. Machine Learning Using R: With Time Series and Industry-Based Use Cases in R.Kbakural, B.R., Robert, P.C., Huggins, D.R., 1999, January. Variability of corn/soybean yield and soil/landscape properties across a southwestern Minnesota landscape. Proceed-ings of the Fourth International Conference on Precision Agriculture. American Soci-ety of Agronomy, Crop Science Society of America, Soil Science Society of America,Madison, WI, USA, pp. 573 –579. Kim, N., Ha, K.J., Park, N.W., Cho, J., Hong, S., Lee, Y.W., 2019. A comparison between major artiﬁcial intelligence models for crop yield prediction: case study of the midwesternunited states, 2006–2015. ISPRS Int. J. Geo Inf. 8 (5), 240.Kitchen, N.R., Sudduth, K.A., Drummond, S.T., 1999. Soil electrical conductivity as a crop productivity measure for claypan soils. J. Prod. Agric. 12 (4), 607 –617. Kohavi, R., 1995, August.A study of cross-validation and bootstrap for accuracy estima-tion and model selection. Ijcai 14 (2), 1137 –1145. Krogh, A., Vedelsby, J., 1995. Neural network ensembles, cross validation, and activelearning. Adv. Neural Inf. Proces. Syst. 7, 231 –238. Kuhn, M., Wing, J., Weston, S., Williams, A., Keefer, C., Engelhardt, A., Cooper, T., Mayer, Z.,Kenkel, B., 2020. caret: Classiﬁcation and Regression Training. R package version 6.0–86. Avaliable at:https://cran.r-project.org/web/packages/caret/caret.Pdf . Kumhálová, J., Matějková,Š., 2017.Yield variability prediction by remote sensing sensors with different spatial resolution. Int. Agrophys. 31 (2), 195.van der Laan, M.J., Polley, Eric C., Hubbard, Alan E., 2007. Super learner. Statistical Appli- cations in Genetics and Molecular Biology. 6. Lee, Craig, Gasster, Samuel, Plaza, Antonio, Chang, Chein-I, Huang, Bormin, 2011. Recentdevelopments in high performance computing for remote sensing: a review. selectedtopics in applied earth observations and remote sensing. IEEE J. 4, 508 –527.https:// doi.org/10.1109/JSTARS.2011.2162643 . Lobell, D.B., Thau, D., Seifert, C., Engle, E., Little, B., 2015. A scalable satellite-based crop yield mapper. Remote Sens. Environ. 164, 324 –333. Martinez-Munoz, G., Hernández-Lobato, D., Suárez, A., 2008. An analysis of ensemble pruning techniques based on ordered aggregation. IEEE Trans. Pattern Anal. Mach.Intell. 31 (2), 245–259.McCullagh, P., Nelder, J.A., 1989. Generalized Linear Models. 2nd ed. Chapman & Hall,London.Meessen, J.H., Petersen, H., 2010. Urea. Ullmann ’s Encyclopedia of Industrial Chemistry. Wiley-VCH, Weinheimhttps://doi.org/10.1002/14356007.a27_333 . Mirasi, A., Mahmoudi, A., Navid, H., Valizadeh Kamran, K., Asoodar, M.A., 2019. Evaluation of sum-NDVI values to estimate wheat grain yields using multi-temporal Landsat OLIdata. Geocarto Int. 1–16.Mishra, U., Gautam, S., Riley, W., Hoffman, F.M., 2020. Ensemble machine learning ap- proach improves predicted spatial variation of surface soil organic carbon stocks indata-limited northern circumpolar region. Front. Big Data 3, 40.Murthy, S., 2020.Be the Outlier: How to Ace Data Science Interviews. New Degree Press,Kindle Edition.Nelder, J.A., Wedderburn, R.W., 1972. Generalized linear models. J. Royal Stat. Soc. Series A (General) 135 (3), 370 –384.Pektürk, M.K., Ünal, M., 2018, August. Performance-aware high-performance computing for remote sensing big data analytics. Data Mining. BoD –Books on Demand, p. 69. Piccini, Nathan, 2019. 101 Machine Learning Algorithms for Data Science with CheatSheets. datasciencedojo(blog). August 21 https://online.datasciencedojo.com/blogs/ 101-machine-learning-algorithms-for-data-science-with-cheat-sheets . Potgieter, A.B., Power, B., Mclean, J., Davis, P., Rodriguez, D., 2014. Spatial estimation of wheat yields from Landsat ’s visible, near infrared and thermal re ﬂectance bands. Int. J. Remote Sens. Appl 4, 134 –143. Ram, P., Apr 27, 2021. “Generalized Linear Models | What does it mean? ”Great Learning Team (blog).https://www.mygreatlearning.com/blog/generalized-linear-models/ . RSrivastava, T., 2020.Introduction to k-Nearest Neighbors: A powerful Machine LearningAlgorithm (with implementation in Python & R). Analytics Vidhya, Mar. 26, 2018.Shaikhina, T., Khovanova, N.A., Mallick, K.K., 2014, June. Artiﬁcial neural networks in hard tissue engineering: another look at age-dependence of trabecular bone properties inosteoarthritis. IEEE-EMBS International Conference on Biomedical and Health Infor-matics (BHI). IEEE, pp. 622 –625. Terry, T., Beth, A., 2019. rpart: Recursive Partitioning and Regression Trees. R package ver-sion 4.1–15.https://CRAN.R-project.org/package=rpart . Therneau, T.M., Atkinson, E.J., 2019. Mayo Foundation (An introduction to recursive partitioning using the RPART routines).Trehan, D., July 2, 2020. “Why Choose Random Forest and Not Decision Trees ”. TOWARDS AI (blog).https://towardsai.net/p/machine-learning/why-choose-random-forest-and-not-decision-trees.Van Den Bergh, F., Wessels, K.J., Miteff, S., Van Zyl, T.L., Gazendam, A.D., Bachoo, A.K., 2012.HiTempo: a platform for time-series analysis of remote-sensing satellite data in ahigh-performance computing environment. Int. J. Remote Sens. 33 (15), 4720 –4740. Vanpoucke, D.E., van Knippenberg, O.S., Hermans, K., Bernaerts, K.V., Mehrkanoon, S.,2020.Small data materials design with machine learning: when the average modelknows best. J. Appl. Phys. 128 (5), 054901.Verger, A., Baret, F., Weiss, M., Kandasamy, S., Vermote, E., 2013. The CACAO method for smoothing, gapﬁlling, and characterizing seasonal anomalies in satellite time series.IEEE Trans. Geosci. Remote Sens. 51 (4), 1963 –1972. Wang, J., Dai, Q., Shang, J., Jin, X., Sun, Q., Zhou, G., Dai, Q., 2019. Field-scale rice yield estimation using sentinel-1A synthetic aperture radar (SAR) data in coastal salineregion of Jiangsu Province, China. Remote Sens. 11 (19), 2274.Weiss, D.J., Atkinson, P.M., Bhatt, S., Mappin, B., Hay, S.I., Gething, P.W., 2014. An effective approach for gap-ﬁlling continental scale remotely sensed time-series. ISPRSJ. Photogramm. Remote Sens. 98, 106 –118. Wendroth, O., Jürschik, P., Nielsen, D.R., 1999. Spatial crop yield prediction from soil and land surface state variables using an autoregressive state-space approach. Precisionagriculture'99, Part 1 and Part 2. Papers presented at the 2nd European Conferenceon Precision Agriculture, Odense, Denmark, 11-15 July 1999. Shef ﬁeld Academic Press, pp. 419–428.Wolpert, D.H., 1992.Stacked generalization. Neural Netw. 5 (2), 241 –259.
Yang, Y., Lv, H., 2021. Discussion of Ensemble Learning under the Era of Deep Learning.arXiv preprintarXiv:2101.08387. Zhang, Y., Ling, C., 2018.A strategy to apply machine learning to small datasets in mate-rials science. Npj Comp. Mater. 4 (1), 1 –8. Zhao, Y., Cen, Y., 2013.Data Mining Applications with R. Academic Press.Zhao, D., Reddy, K.R., Kakani, V.G., Read, J.J., Koti, S., 2007. Canopy reﬂectance in cotton for growth assessment and lint yield prediction. Eur. J. Agron. 26 (3), 335 –344. Zhao, Y., Potgieter, A.B., Zhang, M., Wu, B., Hammer, G.L., 2020. Predicting wheat yield at theﬁeld scale by combining high-resolution Sentinel-2 satellite imagery and cropmodelling. Remote Sens. 12 (6), 1024.Zhong, Y., Fang, J., Zhao, X., 2013, July. VegaIndexer: a distributed composite index scheme for big spatio-temporal sensor data on cloud. 2013 IEEE International Geosci-ence and Remote Sensing Symposium-IGARSS. IEEE, pp. 1713 –1716. Zhou, Z.H., 2009.Ensemble Learning, Encyclopedia of Biometrics.Zscheischler, J., Mahecha, M.D., 2014. An extended approach for spatiotemporal gapﬁlling: dealing with large and systematic gaps in geoscienti ﬁc datasets. Nonlinear Process. Geophys. 21 (1), 203 –215.A.A. Tesfaye, D. Osgood and B.G. Aweke Artiﬁcial Intelligence in Agriculture 5 (2021) 208 –222
222