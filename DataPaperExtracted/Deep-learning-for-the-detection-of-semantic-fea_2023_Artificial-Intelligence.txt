Deep learning for the detection of semantic features in treeX-ray CT scans
Salim Khazema,b,⁎, Antoine Richarde,J e r e m yF i xb,d, Cédric Pradaliera,c
aGeorgiaTech-CNRS IRL 2958, Metz, France
bCentraleSupélec, Metz, France
cGeorgiaTech Lorraine, Metz, France
dLORIA, CNRS UMR 7503, Metz, France
eUniversity of Luxembourg, Campus Kirchberg, 6, rue Richard Coudenhove-Kalergi L-1359 Luxembourg
abstract article info
Article history:Received 10 August 2022Received in revised form 13 December 2022Accepted 24 December 2022Available online 4 January 2023According to the industry, the value of wood logs is heavily in ﬂuenced by their internal structure, particularly the distribution of knots within the trees. Nowadays, CT scanners combined with classical computer vision approachare the most common tool for obtaining reliable and accurate images of the interior structure of trees. Knowingwhere the tree semantic features, especially knots, contours and centers are within a tree could improve the ef-ﬁciency of the overall tree industry by minimizing waste and enhancing the quality of wood-log by-products.However, this requires to automatically process the CT-scanner images so as to extract the different elementssuch as tree centerline, knot localization and log contour, in a robust and ef ﬁcient manner. In this paper, we pro- pose an effective methodology based on deep learning for performing these different tasks by processing CT-scanner images with deep convolutional neural networks. To meet this objective, three end-to-end trainablepipelines are proposed. Theﬁrst pipeline is focused on centers detection using CNNs architecture with a regres-sion head, the second and the third one address contour estimation and knot detection as a binary segmentationtask based on an Encoder-Decoder architecture. The different architectures are tested on several tree species.With these experiments, we demonstrate that our approaches can be used to extract the different elements oftrees in a precise manner while preserving good performances of robustness. The main objective was to demon-strate that methods based on deep learning might be used and have a relevant potential for segmentation andregression on CT-scans of tree trunks.© 2023 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:X-rays imagesDeep learningConvolutional neural networksImage segmentationWood knotsCoordinates detectionContour estimation
1. IntroductionKnots are one of the most signiﬁcant factors in the wood processingchain. A knot is deﬁned as the part of a branch embedded in thetrunk that generally arises at the tip of the trunk ( Longo et al., 2019). Biologically, all branches grow up from the pith, the center of the treestem and the growth rings. The knots have a direct impact on the qualityand value of logs, which makes knowing their exact localization and dis-tribution within the logs relevant and crucial for foresters and sawyers.If the knot, defect location and size are known before sawing(Bhandarkar et al., 1999), this could generate a potential gain of15–18% in value of products. Moreover, this knowledge would supportforest scientist by providing an insight on the mechanisms of treegrowth based on geometric measurements such as (knot length, ringdiameter, etc.), without having to fell the tree.Detection of centers, contours, and knots is a very relevant task forthe wood industry, which can signiﬁcantly improve production quality,and yield. Nowadays, sawmills address these needs by scanning treelogs with various sensors before planning how it will be cut. Amongthese sensors, 3D scanners build a 3D model of the tree exterior, mostlytowards volume estimation, and X-ray Computed Tomography (CT)provides a 3D density model of the tree interior, represented as astack of image describing slices orthogonal to the length of the tree.From such image stacks, tree semantic features (centerline, contour,knots) are localized using traditional computer vision methods(Krähenbühl et al., 2012, 2013a, 2014).These traditional approaches have shown promising results on somespecies. However, they may lack robustness in challenging cases such asfor detecting knots when the sapwood is wet (in these situations, thedensity of the wood is similar to the density of the knot). With theArtiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
⁎Corresponding author at: GeorgiaTech-CNRS IRL 2958, Metz, France.E-mail address:skhazem@georgiatech-metz.fr (S. Khazem).
https://doi.org/10.1016/j.aiia.2022.12.0012589-7217/© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/recent advent of deep learning and its success on a variety of machinelearning problems, the limitations of traditional approaches may beovercome, although at the cost of requiring a larger amount of anno-tated data.In this paper, we demonstrate how data driven machine learningand speciﬁcally deep learning, can be used to address these robustnessissues on three speciﬁc applications:•For tree centerline detection, we train a regression model to pre-dict the intersection of the tree centerline with each X-ray CT images(for a given slice, we refer to this intersection as the tree center). In com-parison to previous studies, this is tested on a large set of species and hasshown its robustness.•Using an Encoder-Decoder architecture, we demonstrate howtree contour extraction can be reliably cast as an image segmentationproblem. Here as well, we tested on a large set of species than previousstudies, and we demonstrate its robustness.•Finally, using the same segmentation network, we showcase thedetection of knots in the CT images and validate it on a subset of speciesfor which knots have been labeled by hand. This allows us to highlightthe robustness challenges and the performance of our approach.All the results presented in this paper have been evaluated on a treedatabase containing CT-scans of 682 trees from 23 species (see Fig. 1). Fig. 2illustrates the number of trees by species and the number of im-ages by species according to the indexes reported on Table 1.2. Related workThis paper can be compared with two categories of related work. Onthe one hand, a signiﬁcant body of work in the deep learning commu-nity addresses questions of regression from images, image segmenta-tion or detection of objects. However, these tools have rarely beenapplied to support the wood processing industry. On the other hand,we identiﬁed a number of works applied speciﬁcally to wood imagery, either using traditional imaging techniques on planks or trunks or X-ray tomography.2.1. The deep learning toolbox for image processingDeep learning approaches have shown considerable promise in var-ious tasks that involve handling massive volumes of digital data. In theﬁeld of computer vision, deep learning methods are also rapidly beingapplied in a wide range of area and have demonstrated remarkable im-provement in several tasks such as image reconstruction, object detec-tion, image classiﬁcation and image segmentation. During the pastdecade, many approaches and architectures have been developed inthisﬁeld such as ResNet-50 (He et al., 2016), MobileNets (Howard et al., 2017), EfﬁcientNet (Tan and Le, 2019). These networks have been introduced for classiﬁcation tasks, but can also be used for regres-sion and as backbone for segmentation tasks. For the different segmen-tation tasks such as Semantic segmentation which is based on pixellevel classiﬁcation into a predeﬁned set of classes or Instance segmenta-tion which consists of detect, segment and classify each individual ob-ject. Some architectures such as UNet, SegNet, LinkNet, MaskRCNNand Upsnet (Ronneberger et al., 2015;Badrinarayanan et al., 2016; Chaurasia and Culurciello, 2017;He et al., 2017;Xiong et al., 2019) have shown great performances.2.1.1. Network architecturesA deep learning architecture is deﬁ
ned as a multi-layers stack of basic modules which have the ability to learn to transform their inputto improve the representation selectivity and invariance ( LeCun et al., 2015). In the computer visionﬁeld, many deep learning architectureshave evolved over the last few years. In particular, architectures based
Fig. 1.Illustration of the different tree species contained in the dataset with respective in-dexes (seeTable 1).
Fig. 2.Overview of the distribution of the number of tree per species and the number of Xray images per species.S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
14on Convolutional Neural Networks (CNNs) such as VGG, Residual net-work (ResNet), MobileNets and EfﬁcientNet (Simonyan and Zisserman, 2015;He et al., 2016;Howard et al., 2017;Tan and Le, 2019) are developed to solve problems in different domains or use-cases and have signiﬁcantly driven the performance of vision tasksbased on their rich representation power. This led to the advent ofmore complex neural network such as ( Liu et al., 2022) and those based on attention such as Vision Transformer (ViT), Data-Ef ﬁcient Image Transformers (DeiT) and Swin Transformer ( Dosovitskiy et al., 2021;Touvron et al., 2021;Liu et al., 2021).2.1.2. Network lossesThe training of a deep neural network is tightly speci ﬁed by the loss function used to quantify the quality of the network's prediction withrespect to and what it should have predicted, named label, ground-truth or target depending on the applications. In the case of a networkperforming a regression task, the typical loss is the mean-squarederror deﬁned below, whereMis the number of dimension of the net-work output,y
ithe target value andp ithe output of the network:L
MSE¼1M∑Mi¼1yi/C0pi ðÞ2ð1ÞFor binary classiﬁcation problems, the binary cross-entropy betweenthe predicted probability of being positive and the ground truth, as de-ﬁned in Eq.(2), is typically selected as the loss function to be minimizedduring the network training.L
BCE¼/C01M∑Mi¼1yilog piðÞ þ1/C0yi ðÞlog1/C0pi ðÞ ð2ÞAdditionally, when the classes are unbalanced, the BCE is usually notsufﬁcient to learn a good predictor and training may favor the majorityclasses. In such case, other losses such as the Dice loss might be pre-ferred. The Dice loss function (Sudre et al., 2017), deﬁned in Eq.(5), which tends to focus on pixels that are mispredicted by the model canalso be included to supervise the model's training.L
Dice¼1/C02∑Mi¼1piyiþε∑
Mi¼1piþ∑Mi¼1yiþεð3ÞIn the context of an image segmentation task, for example for theprediction of the presence of knots, in Eqs. (2) and (3),Mdenotes thetotal number of pixels in the image and yi∈{0,1} represents the label of the i-th pixel, where 0 indicates that the pixel belongs to the back-ground and 1 means that the pixel belongs to a knot. The probabilityof the segmentation model to predict a pixel belongs to a knot is de-notedp
i∈[0,1] andεis a smoothness coefﬁcient. In the different experiments, we empirically set ε=1 .2.1.3. Data augmentationData augmentation is a commonly used technique for arti ﬁcially in- creasing the size of the sample databases by applying different transfor-mations to the available pair (images and labels). It increases the size ofthe input and creates diversity in the data. If correctly calibrated, dataaugmentation can improve generalization and performance of the train-ing model (Shorten and Khoshgoftaar, 2019;Perez and Wang, 2017). In Computer vision, image augmentation has become a common implicitregularization approach to prevent over ﬁtting (poor generalization) and generally enhances performances.2.2. Detecting semantic features in treesIn the one hand, traditional optical imaging technique are still usedin industry to perform processing and tasks such as object detection,classiﬁcation and segmentation. In the wood industry, when it comesto detect defects on the surface of either the tree or planks, we usuallyuse this kind of data due to their ease of acquisition and their practicaluse. In this context, we have identiﬁed some previous work using thistype of data to detect defects and surface knots using deep learningbased approaches (Gao et al., 2021a;Lopes et al., 2020;Norlander et al., 2015;Gao et al., 2021b). In the other hand, X-ray tomography rep-resents one of the standard medical imaging modality which is consid-ered as the most efﬁcient way to get accurate and informative images ofthe inner structure non-invasively. In recent years, several industries, inparticular the wood processing industry, have chosen to take advantageof this technology to obtain better understanding of their products inorder to increase yield. Several approaches that aim to detect theinner properties and features of the tree have been proposed based onthis modality (Kerautret and Lachaud, 2009;Krähenbühl et al., 2012, 2013a) and will be discussed below.2.2.1. Expert methodsTree semantic features (centers, knots, contours) within log cross-sections are an active area of research where high variability in knot ap-pearance and labeled data availability are major challenges. Methods,such as (Johansson et al., 2013;Krähenbühl et al., 2013b) are developed to address this challenge.Johansson et al. (2013)is based on modeling the knot by non-concentric ellipses inside the log with different radiusto localize the knots. They propose an ellipse detection algorithm thatinvolves the following steps. First, they try to detect the heartwood Con-centric Surface (CS), which is considered similar to a cylindrical shell, byﬁtting ellipses to the annual rings of the log. Then, all the objects (re-gions with high density value) on the concentric heartwood surfaceareﬁtted to ellipses andﬁnally all overlapping ellipses across the heart-wood concentric surface are tracked until reaching a sapwood CS whichis considered as the end of the knot. (Krähenbühl et al., 2013a) proposed an approach to tackle the problem of segmenting wet area: they ﬁrst de- tect the knot areas using (Krähenbühl et al., 2012) approach, and then exploit the geometrical properties such as dominant points and curva-ture computed from discrete contours ( Kerautret and Lachaud, 2009)
to estimate the position and orientation of the knots in the sapwood.Finally, this information is used to report a segmentation mask. How-ever, these methods heavily rely on user expertise to adjust the param-eters of the algorithms correctly. Let us take as example knot detection.Knots can have varied shapes that is hard to delineate. In addition,taking into the tree type, which its speciﬁc density, is not an easy task.Table 1Species indexes.Scientiﬁc name English name Index Scienti ﬁcnameEnglishnameIndexCarpinus Hornbeam 0 Betula Birch 12Prunus aviumGean 1 Fraxinus Ash 13Acer Maple 2 AcercampestreHedgeMaple14Sorbus torminalisWhitebeam 3Picea abiesSpruce 15 Pinus sylvestrisScotsﬁr 4 Abies Pine 16Quercus Oak 5 FagussylvaticaBeech 17Acacia Acacia 6 Larix deciduaLarch 18 PseudotsugamenziesiiDouglasﬁr 7 Tilia Lime 19Alnus Alder 8 QuercuspetraeaSessile oak 20Quercus rubraRed oak 9PopulustremulaAspen 21Acer platanoidesNorway maple 10 Ulmus Elm 22AcerpseudoplatanusSycamoreMaple11 / / /S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
15Indeed, the expert methods have been experimented only on a few treespecies. In comparison, we are proposing end-to-end trained pipelinesbased on deep learning to address these different tree semantic applica-tions, and we consider a much more diverse set of species.2.2.2. Data driven methodsWith the recent successes of neural networks on a wide range of ma-chine learning problems, these techniques have also beenexperimented on wood logs CT scans. The work of ( Norlander et al., 2015) showed that deep learning approaches, and speci ﬁcally convolutional neural networks, outperformed a commercial detectorbased on feature descriptors and Support Vector Machine (SVM)(Cortes and Vapnik, 1995) when the task was to detect knots in oaktree planks. According toNorlander et al. (2015), the appropriate ap- proach is to rely on neural networks architectures instead of relyingon the traditional computer vision methods usually used in this ﬁeld to locate the knots inside the CT-Scanned wood-logs. Several ap-proaches are also proposed to detect knots on the surface of wood.Gao et al. (2021a)proposed an approach based on transfer learningusing residual neural networks to detect defects (knots) on the surfaceof wood and perform a classiﬁcation task to categorize them into sevendefect types. The work ofLopes et al. (2020)consists of using and train- ing The”You only look once”(Yolov3) (Redmon and Farhadi, 2018)a r - chitecture from scratch to perform knots detection on the surface ofwood at high speed and have shown good results on knots that are onthe surface. However, this approach has not been tested either on X-ray images or the inner knots which are very challenging.Although many different architectures and models are available (see2.1.1), their application in the wood industry remains limited and couldbe improved. Our work can be split into two main tasks: Regression andSegmentation. Pith estimation from CT scans is a regression task fromimages, and several end-to-end trainable neural networks mentionedin (2.1.1) with a regression head can be trained on this task. Knot detec-tion can be either formulated as a segmentation task or object detectiontask, and there exists also a variety of end-to-end trainable neural net-works in the computer vision community for solving this task. Contourestimation, on the other hand, can be addressed in several ways. Oneapproach is to cast the contour estimation as tree segmentation wherethe task is to predict all the pixels belonging to the tree, hence a binarysemantic segmentation task from which U-Net, Faster-RCNN, and anysemantic segmentation neural network can be applied. That ﬁrst ap- proach, although classical, suffers from the dif ﬁculty of producing an output that is not necessarily a closed curve as expected for a contourpredictor. A second approach relies on end-to-end trainable predictorsoutputting a closed curve. This is not straightforward to design a train-able neural network for outputting a closed curve, but recent workson differentiable active contours follow that track ( Marcos et al., 2018). This is a recently proposed approach which has the bene ﬁtt o output a closed curve, by constraint, but that we did not explore yet inthis paper.2.3. Synthesis on the related workThe various techniques described above highlight both the availabil-ity of a large and well-proven toolbox of deep-learning-based robustimage processing techniques, and the existence of a number of imageprocessing challenges whose solution would support the wood indus-try. This paper builds on these two observations to deploy and evaluatedeep-learning solutions to the speciﬁc context of processing X-ray to- mography of wood logs.3. Materials and methodsWithin this section we will cover different wood-logs semantic featuresextractions and propose techniques and models for the different tasks suchas centerline detection, contour extraction, and knot segmentation.3.1. Tree centerline detectionWithin this part, we will present the proposed architecture for cen-ters detection and the data augmentation strategy we selected.Instead of proposing a new architecture, we have exploited theknowledge of a set of already existing convolutional neural network ar-chitectures (see 2.1.1) that have performed excellently on several imagetasks. The choice of convolution networks is driven by the fact that ourtask consists on performing regression on images. For our work, we useResNet-34 (He et al., 2016) which is a variant of the residual neural net-
work with a total of 34 layers, the advantage of this architecture is that itoffers a good combination of number of parameters and performance,and has proven its performance on image classi ﬁcation tasks. Another reason for exploiting the residual network architecture is the possibilityof feeding images of different sizes from those with which they aretrained thanks to global average pooling layer,
1which computes the av- erage value over the spatial dimensions of each features then feeded di-rectly to the softmax activation. This is considered a crucial part to dotransfer learning, which help us to achieve high performance on a net-work using very few epochs. The ResNet-34 network contains 21.2 mil-lion of trainable parameters.Detecting the centers in the wood-log tomography slices is a pixel-coordinate regression, since the labels of the images are the center coor-dinates X and Y. Our work attempts to automate this task with an end-to-end trainable pipeline.We trained a ResNet34 (He et al., 2016) on 256 × 256 pixel images with a regression head (the last linear layer pretrained on ImageNet isreplaced with a linear layer with two units, initialized using the defaultpytorch strategy with both the weights and biases sampled fromU/C0
1ﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ
faninp,1ﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ
faninp/C18/C19) and a mean-squared error loss (Eq.(1)). For reg- ularization, we tested some data augmentation strategies (see 2.1.3)and early stopping to prevent overﬁtting. To ensure that the augmenta-tion of these images is achievable with reasonable memory usage andspeed, we used an open source library, Albumentations ( Buslaev et al., 2020). The images are normalized between the values [0,1]. We trainedthe network with the convolutional part pretrained on ImageNet, theﬁrst convolutional layer
2being randomly initialized using the Henormal strategy and the linear layer is randomly initialized using thedefault pytorch strategy with both the weights and biases sampledfromU/C0
1ﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ
faninp,1ﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ
faninp/C18/C19. We used Adam (Kingma and Ba, 2015)a s an optimizer with a learning rate 1e−3 and the learning rate is reduced by a factor of 0.1 every time the validation metric stalls. We used a batchsize of 256. We also used mixed precision training ( Micikevicius et al., 2017) which sped up training without loss of performance. The lossfunction used in implementation is the Mean Squared Error (MSE)loss. We split the dataset into training and validation folds of, respec-tively, 90% and 10%.Fig. 3illustrates our detailed regression pipelinef o rc e n t e rd e t e c t i o n .For the data augmentation (seen insubsection 2.1.3), after testing several ones, we selected the following relevant transformations: shift,scale, color augmentation (saturation, brightness, contrast), randomhorizontal and verticalﬂipping, and rotations. We used the augmenta-tion only with the training data. At the end, we did some experimentsthat consist of augmenting test data to evaluate the robustness ofthe model. The random seed of the data augmentation is ﬁxed for reproducibility.
1It might appear as surprising that a network with global average pooling is able to pre-dict a spatialized output but the empirical results actually show that this works and thisarchitecture is signiﬁcantly less parametrized than the same without the global averagepooling layer.
2The networks pretrained on ImageNet involve color images with 3 inputs channelswhile our data involve only one channel, hence the ﬁrst convolutional layer is replaced with convolutional kernels expected one input channel.S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
163.2. Trees contour detectionThis part deals with the prediction of the contour of the tree. Thecontour is a thin line separating the wood log from the rest (back-ground, wedges, etc…) in the CT-scan images. Rather than predictingthat thin line, we transform the machine learning problem into the seg-mentation of the wood log from the rest, from which we can derive thecontour.We propose to use an Encoder-Decoder based model, and speci ﬁ- cally U-Net (Ronneberger et al., 2015). In the encoder part, the model takes an image as input and applies a sequence of convolutions, max-pooling and ReLU activation and compresses the image into a latentspace while extracting the most relevant features. The decoder part isa sequence of convolutional and transposed convolutional layers thatattempt to decode the segmentation mask from the latent space andinput image. Skip connections are used to take advantage of high-resolution layers of the encoder by sending information to the corre-sponding layers of the decoder, which allows the model to use ﬁne- grained details learned from the encoder part to construct the imageon the decoder part. These connections help the network to better cap-ture small details that are present in high-resolution. The parameters ofall the convolutional layers of the network are randomly initialized fromU/C0
1ﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ
faninp,1ﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ
faninp/C18/C19. Before training, theﬁrst stage of our pipeline performs pre-processing on 512 × 512 pixels images by normalizingthem in [0,1]. We use some on-the-ﬂy non-destructive augmentation scheme to expand the dataset's size and improve the variability of sam-ples, including random rotation and horizontal, vertical ﬂip with a prob- abilityp= 0.5. The second stage consists of feeding the preprocesseddata to the U-Net architecture and performing training. The loss func-tion used for the U-Net is binary cross entropy
3(Eq.(2)). We used RMSprop as an optimizer with a learning rate 1 e−3, a momentum 0.9 and a batch size of 8. The learning rate is decreased by a factor of0.1 every time the validation error reaches a plateau. The data are splitinto a training fold of 90% and a validation fold of 10%. In the fold con-struction, it is possible that among consecutive slices, one is present inthe training fold and the other in the validation fold, which may inducea bias in the estimation of the real risk from the validation fold. How-ever, as will be shown in the results, the selected network which mini-mizes the validation loss is still able to generalize to unseen trees, evenfrom unseen species. To prevent overﬁtting, in addition to the augmen- tation strategy, and weight decay of 10
−8, we used early stopping by selecting the best model as the one minimizing the BCE loss on the val-idation fold. The dataset used for the training is composed of 9 Abies(Fir) tree which represents 2504 annotated images. The pipeline forcontour segmentation is illustrated in Fig. 4. More details of the architec- ture are illustrated in appendixAppendix C.3.3. Tree knots detectionIn this part, we present our approach to perform the knot segmenta-tion task as binary mask prediction from single channel 512 × 512 CT-scan images.The segmentation task requires separating the foreground (knots)and the background (other tissues). The network architecture is thesame U-Net architecture used for the segmentation task in section 3.2. However, in addition to the binary cross entropy loss (Eq. (2))a n d given that the wood slices present very few knots, we additionally usea Dice loss (Eq.(5)) to try to overcome class unbalancing. To handlethe limited number of samples issue, we used a simple data augmenta-tion strategy by applying horizontal and vertical ﬂips on theﬂy. The dataset is split into training and validation folds of, respectively, 90%and 10 % . For the training parameters, we used the same as in the seg-mentation task insection 3.2.Fig. 5depicts our detailed proposed pipe-line to perform the knot segmentation task.4. Experiments and comparisonsIn this section, we present the various experiments and the results ofthe different tasks on stems of several tree species.4.1. Datasets4.1.1. CT imagesThe used images come from X-ray CT scanners in Digital Imagingand Communication in Medicine (DICOM) format which is considered the most popular standard in medicine, which makes medical image ex-change easier and more independent of the imaging equipment manu-facturer. In addition to the image, the DICOM format can also supportother useful information to best describe the image such as width,height, in addition to some details related to the acquisition such as,technology used, serial number, date of acquisition ( Mustra et al., 2008). The 512 × 512 pixels images are extracted from the DICOMsfor the three tasks of center detection, contour and knots segmentation.Some sample images with their apparent knots are shown in Fig. 6.T h e Figs. 6show X-ray images containing from 1 to 5 knots.4.1.2. AnnotationsThe dataset has been manually annotated for the different tasks byourselves. For the center detection task, the labels are provided in theform of X, Yﬂoating coordinates of the wood-logs biological centers.For the segmentation tasks (eq. knots and contours) the labels are pro-vided in the form of binary masks, each wood-log is associated with itsrelated binary mask.
Fig. 3.The pipeline for regressing the tree center is based on a ResNet-34 convolutional backbone, pretrained on ImageNet, and a randomly initialized ﬁrst convolutional layer and regres- sion head. Training is performed on augmented data, applying random transformations to the training images and targets.
3In this task, on every slice, positive and negative samples are approximately balanced,hence a BCE loss makes sense.S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
174.2. Implementation detailsWe used Neptune
4and Tensorboard5platforms to track the experi- ments and log the curves (mean absolute error, cross entropy loss andDice loss). We used several workstations with an NVIDIA RTX 3090GPU, an AMD Ryzen 5950 × 16 cores and 32 threads for training andinference.The entire data preprocessing, the network models involved in theexperiment, as well as the network training, were programmed in Py-thon and Pytorch (Paszke et al., 2019) with Nvidia CUDA.
6The center detection task was conducted for 40 epochs, The segmentation tasks(contour and knots) were conducted for 100 epochs per model.4.3. MetricsFor the several experiments, we used different quantitative metricsto evaluate the quality and performance of our approaches. For the re-gression task (centers detection) we use the Mean Absolute Error
Fig. 4.The pipeline for the tree contour segmentation is based on an Encoder-Decoder U-Net architecture. Training is performed on augmented data, applying random non-destructive transformation to the training images and binary masks.
Fig. 5.Pipeline for the tree knots segmentation is based on an Encoder-Decoder U-Net architecture. Training is performed on augmented data, applying rando m non-destructive transfor- mation to the training images and binary masks. The image on the right of the pipeline illustrates a prediction (yellow mask) overlayed with the input.
Fig. 6.Examples of used X-ray images and knot con ﬁguration with a color coding representing the wood density.(6-a) shows an example of a con ﬁguration which contains 1 knot.(6-b) illustrates an example with 3 knots which contain noise caused by the wet sapwood and (6-c) shows an example with 5 knots which also contain some noise ca use by the wet sapwood.
4https://neptune.ai
5https://www.tensorﬂow.org/tensorboard
6Compute Uniﬁed Device ArchitectureTable 2Model comparison with different parameters. The metrics are evaluated on the validationfold.Augmentation MAE (px) MAE (mm)/ 6.6 6.58Random Contrast 3.9 3.89Vertical Flip 3.1 3.09Horizontal Flip 2.3 2.29Shift Scale Rotation 1.2 1.19All 1.1 1.09S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
18(MAE) as a metric to measures the quality of the predictor. For segmen-tation tasks (contour and knots), we evaluate the Dice coef ﬁcient (Dice), Accuracy and Mean Intersection Over Union (mean IoU). We denoted by asﬁnal prediction andythe true value to be predicted. For the segmen-tation tasks, we denote TP, TN, FP, FN respectively the number of truepositives, true negatives, false positives and false negatives between y andby. All the evaluation metrics adopted in our experiments could beformulated as follows:4.3.1. Mean absolute error (MAE)∀y;^y∈ℝ;MAE y;^yðÞ ¼ jy−^yjð 4Þ4.3.2. Dice score / F1 score∀y,by∈0, 1fg
N,Dice y,by/C0/C1¼2TP y,by/C0/C12TP y,by/C0/C1þFP y,by/C0/C1þFN y,by/C0/C1ð5Þ4.3.3. Mean intersection over Union (mean IoU)∀y,by∈0, 1fg
N,IoU y,by/C0/C1¼TP y,by/C0/C1TP y,by/C0/C1þFP y,by/C0/C1þFN y,by/C0/C1ð6Þ4.4. Results and discussions4.4.1. Center detectionIn this section, we present the results of the network performance onthe tree centerline detection task, as well as the quantitative metrics weused.Table 2presents the results of performances on center detectiontask with different parameters.As shown inTable 2, our network achieves a good MAE for the differ-ent parameters we evaluated. In particular, we tested different types ofaugmentations individually to see the effect of each one on the perfor-mance of the model. We can observe that the data augmentation tech-niques improved considerably the performance of the networks. It canbe also observed that Shift-Scale-Rotation and Horizontal Flip whichare spatial-level transforms have more effect on the performance thanpixel-level transform such as Random Contrast. Nevertheless, by com-bining all the proposed augmentations, we achieved a better perfor-mance with aMAEof1.1 pixelon the valid dataset, which correspond to an error of2.2 mm. The MAE metric is calculated onthe original image (256 × 256).To better highlight the robustness of the model to the differentspecies, we tested our model with several species. The Fig. 7presents the quantitative result for each specie. We noticed that except the littlevariability of the precision between species, the experience reveals thatthe model is globally robust. We also evaluated a simple predictor thatalways output the center of the image, independently of the species.We obtained an error of 7.88 pixel compared to 2.84 pixel for our model.Fig. 7.Overview of the results of the model for different species for 8000 samples.S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
19Additionally, we tested the impact of using AMP (Automated MixedPrecision) on the performance of the model, and we noticed that the dif-ference in performance is not signiﬁcant. For simple models, we ob- tained 6.1 pixel (6.09mm) without AMP and 6.6 pixel (6.58 mm) with AMP. However, when using AMP, the gain of training time and the useof memory is signiﬁcant. This is consistent with the work of(Micikevicius et al., 2018), which showed that the use of AMP leads tospeedups of a factor 2-6× compared to the traditional method (FP32)with less memory consumption. As a result, all the evaluations pre-sented in this paper use AMP by default.Qualitative results are shown inFig. 8. Visually, this reveals that the model detected the centers precisely. Speci ﬁcally, the last row of the Fig. 8highlights how small is the error between the ground truth andthe prediction, as shown in theTable 2. Globally, the experimental result shows that our approach, in combination with some ﬁne-tuning, is efﬁ- cient to tackle the center detection task accurately while having a goodgeneralization.4.4.2. Contour segmentationIn this section, we present the results of the network performanceand the quantitative metrics used for the contour segmentation task.Table 3presents the performance of the model, both with and withoutdata augmentation. As shown in the same table, we can see that the pro-posed network achieves good scores in both cases. We see a small im-provement for the performance using random ﬂip and random rotation. The performances of the segmentation network are reasonablygood but the data augmentation has only a very limited impact on them.Qualitative results are shown inFig. 9. Visually, the network detected the masks of the wood log area precisely.Taking into account that our model was only trained on ﬁr trees, and to better highlight its robustness, we experimented it on many specieswith different shapes and sizes, none of which was seen in training.Fig. 10presents the qualitative results of the robustness of our model.We noticed that our model was able to generalize the prediction withother species that have never been observed on training process. Unfor-tunately, due to the lack of labels for all the other species at the time ofthis writing, we cannot compute the metrics on all the dataset as we didfor the centerline prediction.This experimental result reveals that the U-Net architecture, witha good pre-processing combined with a good set of parameters andhyperparameters, is sufﬁcient to capture the complex texture oftree slice CT images while having a good performance and robust-ness. The acacia andﬁr trees presented inFig. 10prove the ability of the model to generalize the prediction to different shapes andsizes, as the acacia tree is smaller than the example data used during
Fig. 8.Qualitative analysis of our model with different trees. The ﬁrst row corresponds to the input images, the second row is the associated ground truth, the third one is the predictions and the last one illustrates a zoom in on the predictions where the blue cross represents the prediction and the yellow is the ground truth.
Table 3Model comparison with different parameters, the metrics being computed on the valida-tion fold of theﬁrt r e ed a t a s e t .Architecture Augmentation mean Dice/F1 score Mean IoUU-Net / 0.875 0.780U-Net Flip and Rotate 0.878 0.785S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
20Fig. 9.Qualitative analysis of our model for different Fir tree species. The ﬁrst row corresponds to the input images, the second row is the associated ground truth and the ﬁnal one is the predictions. These samples all belong to the validation set.
Fig. 10.Qualitative analysis of the robustness of our model with different tree species. The ﬁrst row corresponds to the input images, the second row is the predictions, and the last one illustrates an overlay of the prediction.
Fig. 11.Example of network mispredictions. The ﬁrst column corresponds to the input images, the second column is the associated ground truth and the ﬁnal one is the predictions. The red frame highlights the misprediction part.S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26the training, and thisﬁr tree log has a particular shape. Despite this,the model was able to segment precisely the entire visible part ofthe tree. More samples of different species are illustrated in appendixAppendix A.Additionally, to better highlight the limits of our approach, we se-lected the validation samples for which the Dice score was the lowest.These samples, along with their predictions and ground truths, areshown inFig. 11. On these samples, the difﬁculty seems to stem from the similarity between the trunk and the objects around them. More-over, the model struggles to distinguish between the boundary of thetrunk and the wedge that is very close to it. The misprediction is high-lighted in a red frame inFig. 11.4.4.3. Knot segmentationFinally, we experimented our proposed methodology for the knotsegmentation task. Quantitative results of the best model minimizingthe Dice score on the validation are shown in Table 4,w i t ho rw i t h o u t data augmentation. Quantitatively, on a per-case basis, we can see thatthe proposed architecture achieves a good score. We can also see thata simple data augmentation pipeline brings improvement, which vali-dates the importance of variability of the dataset and the ef ﬁciencyTable 4Model comparison with different parameters.Architecture Augmentation Mean Dice/F1 scoreU-Net / 0.645U-Net Flipping & rotation 0.698
Fig. 12.Qualitative analysis of our model for different ﬁr trees. Theﬁrst row corresponds to the input images, the second row is the associated ground truth and the ﬁnal one is the predictions.
Fig. 13.Qualitative analysis of the robustness of the knot segmentation model with different tree species. The ﬁrst row corresponds to the input images, the second row is the mask predictions, and the last one illustrates an overlay of the prediction.S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
22of using data augmentation on the performance of the segmentationnetwork.Qualitative results are shown inFig. 12, we can see visually that our network detects the knots precisely, we also noticed that the proposedmethodology exhibits a good performance on the segmentation task de-spite the limited annotated data (2504 images), which prove the ef ﬁ- ciency of our approach.Similarly to the contour segmentation task, and to better evaluatethe robustness of our model, we tested it on different species thathave never been observed during the training process. The Fig. 13pre- sents the qualitative results of the robustness, we noticed that themodel was able to generalize well despite the challenge of the differentstructures and shapes of the knots. Unfortunately, due to lack of labelsfor all the other species at the time of this writing, we cannot computethe metrics on all the dataset as we did for the centerline prediction.The appendixAppendix Billustrates more samples for different species.To better highlight the limits of our model on this challenging task,we selected a validation sample for which the Dice score was low. Thesample, along with his prediction and ground truth, is shown inFig. 14. On this sample, the difﬁculty seems to stem from the smallsize of the knot and the similarity between the density of the knot andthe surrounding wood, which may explain why the network fails to pre-dict the entire knot. As a side note, on this ﬁgure, one can notice some high-density radial features not labeled as knots in the ground-truth.These wood defects are not labeled as knots because they are not relatedto the growth of a branch. The network correctly ignores them in thissegmentation task.5. ConclusionIn this paper, we introduced an effective methodology based ondeep convolutional neural networks to perform detection andprediction of tree semantic features in X-ray images. The proposedmethods include three end-to-end pipelines that perform respec-tively the tree centerline regression, the contours and knots seg-mentations. The different results obtained have demonstrated theefﬁciency of this methodology and mainly its robustness on newunseen samples, which supports the relevance of deep learningbased approaches for these tasks. These results also highlighted the generalization capacity of the models on different species withvarious shapes and sizes, despite the limited number of annotateddata.However, as of today, we also identiﬁed the following limita- tions. Theﬁrst limitation comes from the small size of challengingdetails that the model was unable to capture on some species. Thisis especially true with the contours task as shown in Fig. 11where the model struggle to distinguish the boundary of the trunk fromthe supporting wedge, and with th e knot segmentation task (See Fig. 14) where the model fails to detect the entire knot in a chal-lenging image characterized by the small size of the knot. The sec-ond limitation comes from the complexity of the knot structuresand the density similarity with the surrounding wood in some in-stances, which leads to complete detection failure ( Fig. 14). These limitations could be partially addressed by annotating more datawith complex structures so as to help the model to capture smalldetails and species-speciﬁc features. There are also various networkarchitectural opportunities that could allow improving the perfor-mances of the presented approach. Compared to the single frameapproach which uses only spatial information, we intend to explorethe use of image sequences to take advantage of the sequential in-formation as well. In addition, we are also considering adding a spa-tial attention block to focus on the most important, possibly distant,features to compute the predictions ( Woo et al., 2018).CRediT authorship contribution statementSalim Khazem:Conceptualization, Methodology, Software,Formal analysis, Investigation, Writing –original draft.Antoine Richard:Writing–
review & editing, Software, Data curation. Jeremy Fix:Supervision, Writing–review & editing, Software, Validation.Cédric Pradalier:Supervision, Writing–review & editing, Data curation, Validation.Declaration of competing interestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to in ﬂu- ence the work reported in this paper.AcknowledgmentThis research was made possible with the support from the FrenchNational Research Agency, in the framework of the project WoodSeer,ANR-19-CE10-011.
Fig. 14.Example of network prediction limits, the ﬁrst column corresponds to the input image, the second one is the associated ground truth and the third one is the predictionon which we see that part of the knot is not correctly detected.S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
23Appendix A. Contour segmentationTheﬁgure below depicts a number of qualitative results of contour segmentation applied to various tree species not seen in the training datasetand for which the ground truth is not available.
S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
24Appendix B. Knots segmentationTheﬁgure below depicts a number of qualitative results of knot segmentation applied to various tree species not seen in the training dataset andfor which the ground truth is not available.
S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
25Appendix C. UNet architecture
Table C.5Unet architecture. Conv(n) denotes a 2D convolutional layer with nkernels of size (3,3). Every convolution has a stride 1 and zero padding of size 1. MaxPool is a 2D max poolinglayer with kernel size (2,2), stride 2.Input (512 × 512)E
1: Conv(64), BatchNorm, ReluE
n: for n in {2.0.5}:withc
0= 1284/C2MaxPoolConvð2
ðn−2Þ/C2c0Þ;BatchNorm;Relu Convð2
ðn−2Þ/C2c0Þ;BatchNorm;Relu24D
1: ConvTranspose(512) Concat(E4)Conv(512), BatchNorm, Relu D
2: ConvTranspose(256) Concat(E3)Conv(256), BatchNorm, Relu D
3: ConvTranspose(128) Concat(E2)Conv(128), BatchNorm, Relu D
4: ConvTranspose(64) Concat(E1)Conv(64), BatchNorm, Relu Output: Conv( n
cls), Sigmoid Output shape (512 × 512)
References
Badrinarayanan, V., Kendall, A., Cipolla, R., 2016. SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation. arXiv:1511.00561 [cs] URL http:// arxiv.org/abs/1511.00561. Bhandarkar, S.M., Faust, T.D., Tang, M., 1999. CATALOG: a system for detection and ren-dering of internal log defects using computer tomography. Mach. Vis. Appl. 11,171–190.https://doi.org/10.1007/s001380050100 . Buslaev, A., Iglovikov, V.I., Khvedchenya, E., Parinov, A., Druzhinin, M., Kalinin, A.A., 2020.Albumentations: fast andﬂexible image augmentations. Inf. 11, 125. https://doi.org/ 10.3390/info11020125.Chaurasia, A., Culurciello, E., 2017. LinkNet: exploiting encoder representations for ef ﬁ- cient semantic segmentation. IEEE Visual Communications and Image Processing(VCIP), pp. 1–4U R L .Cortes, C., Vapnik, V., 1995.Support-vector networks. Mach. Learn. 20, 273 –297. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T.,Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., Houlsby, N., 2021. AnImage Is Worth 16x16 Words: Transformers for Image Recognition at Scale. 9th Inter-national Conference on Learning Representations, ICLR 2021, Virtual Event, Austria,May 3–7, 2021. OpenReview.net URL https://openreview.net/forum?id= YicbFdNTTy.Gao, M., Song, P., Wang, F., Liu, J., Mandelis, A., Qi, D., 2021b. A novel deep convolutionalneural network based on resnet-18 and transfer learning for detection of wood knotdefects. J. Sensor.https://doi.org/10.1155/2021/4428964 . Gao, M., Chen, J., Mu, H., Qi, D., 2021a. A transfer residual neural network based on resnet-34 for detection of wood knot defects. Forests 12, 1 –16.https://doi.org/10.3390/ F12020212.He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 770 –778. He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017. Mask r-cnn. Proceedings of the Ieee Inter- national Conference on Computer Vision, pp. 2961 –2969. Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M.,Adam, H., 2017.Mobilenets: Efﬁcient Convolutional Neural Networks for Mobile Vi- sion Applications arXiv preprint arXiv:1704.04861.Johansson, E., Johansson, D., Skog, J., Fredriksson, M., 2013. Automated knot detection for high speed computed tomography on pinus sylvestris l. and picea abies (l.) karst.Using ellipseﬁtting in concentric surfaces. Comput. Electron. Agric. 96, 238 –245 URL. Kerautret, B., Lachaud, J.O., 2009. Curvature estimation along noisy digital contours by ap-proximate global optimization. Pattern Recogn. 42, 2265 –2278.https://doi.org/10. 1016/J.PATCOG.2008.11.013.Kingma, D.P., Ba, J., 2015.Adam: a method for stochastic optimization. ICLR (Poster).Krähenbühl, A., Kerautret, B., Debled-Rennesson, I., Longuetaud, F., Mothe, F., 2012. Knot detection in X-ray CT images of wood. International Symposium on Visual Comput-ing. Springer, pp. 209–218.Krähenbühl, A., Kerautret, B., Debled-Rennesson, I., 2013a. Knot segmentation in noisy 3d images of wood. International Conference on Discrete Geometry for Computer Imag-ery. Springer, pp. 383–394.Krähenbühl, A., Kerautret, B., Debled-Rennesson, I., 2013b. Tkdetection: a Software to De-tect and Segment Wood Knots. Imagen-a 3. URL https://hal.archives-ouvertes.fr/hal-01265531.Krähenbühl, A., Kerautret, B., Debled-Rennesson, I., Mothe, F., Longuetaud, F., 2014. Knot segmentation in 3d ct images of wet wood. Pattern Recogn. 47, 3852 –3869. LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning. Nature 521, 436 –444.https://doi. org/10.1038/nature14539. Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., Guo, B., 2021. Swin transformer:hierarchical vision transformer using shifted windows. 2IEEE/CVF International Con-ference on Computer Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, 2021.IEEE, pp. 9992–10002https://doi.org/10.1109/ICCV48922.2021.00986 . Liu, Z., Mao, H., Wu, C., Feichtenhofer, C., Darrell, T., Xie, S., 2022. A Convnet for the 2020s.CoRR abs/2201.03545. URLhttps://arxiv.org/abs/2201.03545 .arXiv:2201.03545. Longo, B., Brüchert, F., Becker, G., Sauter, U., 2019. Validation of a ct knot detection algo-rithm on fresh Douglas-ﬁr (pseudotsuga menziesii (mirb.) franco) logs. Ann. For. Sci.76.https://doi.org/10.1007/s13595-019-0812-4 . Lopes, D.J.V., dos Santos Bobadilha, G., Grebner, K.M., 2020. A fast and robust arti ﬁcial in- telligence technique for wood knot detection. BioResources 15, 9351 –9361.https:// doi.org/10.15376/BIORES.15.4.9351-9361 . Marcos, D., Tuia, D., Kellenberger, B., Zhang, L., Bai, M., Liao, R., Urtasun, R., 2018. Learning deep structured active contours end-to-end. Proc. IEEE Conf. Comput. Vis. PatternRecognit, pp. 8877–8885.Micikevicius, P., Narang, S., Alben, J., Diamos, G., Elsen, E., Garcia, D., Ginsburg, B., Houston,M., Kuchaiev, O., Venkatesh, G., et al., 2017. Mixed Precision Training arXiv preprint arXiv:1710.03740.Micikevicius, P., Narang, S., Alben, J., Diamos, G., Elsen, E., Garcia, D., Ginsburg, B., Houston,M., Kuchaiev, O., Venkatesh, G., Wu, H., 2018. Mixed precision training. arXiv:1710.03740 [cs, stat] URLhttp://arxiv.org/abs/1710.03740 . Mustra, M., Delac, K., Grgic, M., 2008. Overview of the dicom standard. 50th international symposium ELMAR. IEEE, pp. 39 –44. Norlander, R., Grahn, J., Maki, A., 2015. Wooden knot detection using convnet transfer learning. Scandinavian Conference on Image Analysis. Springer, pp. 263 –274. Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z.,Gimelshein, N., Antiga, L., et al., 2019. Pytorch: an imperative style, high- performance deep learning library. Adv. Neural Inf. Proces. Syst. 32.Perez, L., Wang, J., 2017.The Effectiveness of Data Augmentation in Image Classi ﬁcation Using Deep Learning arXiv preprint arXiv:1712.04621.Redmon, J., Farhadi, A., 2018.Yolov3: An Incremental Improvement arXiv preprint arXiv:1804.02767.Ronneberger, O., Fischer, P., Brox, T., 2015. U-Net: Convolutional Networks for BiomedicalImage Segmentation. arXiv:1505.04597 [cs] URL http://arxiv.org/abs/1505.04597 . Shorten, C., Khoshgoftaar, T.M., 2019. A survey on image data augmentation for deeplearning. J. Big Data 6, 60.https://doi.org/10.1186/s40537-019-0197-0 . Simonyan, K., Zisserman, A., 2015. Very deep convolutional networks for large-scaleimage recognition. In: Bengio, Y., LeCun, Y. (Eds.), 3rd International Conference onLearning Representations, ICLR 2015, San Diego, CA, USA, May 7 –9, 2015, Conference Track Proceedings URLhttp://arxiv.org/abs/1409.1556 . Sudre, C.H., Li, W., Vercauteren, T., Ourselin, S., Jorge Cardoso, M., 2017. Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations. DeepLearning in Medical Image Analysis and Multimodal Learning for Clinical DecisionSupport. Springer, pp. 240
–248. Tan, M., Le, Q., 2019.Efﬁcientnet: rethinking model scaling for convolutional neural net-works. International Conference on Machine Learning. PMLR, pp. 6105 –6114. Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., Jégou, H., 2021. Training data-efﬁcient image transformers & distillation through attention. In: Meila, M., Zhang, T.(Eds.), Proceedings of the 38th International Conference on Machine Learning,ICML 2021, 18–24 July 2021, Virtual Event. PMLR , pp. 10347 –10357 URLhttp:// proceedings.mlr.press/v139/touvron21a.html . Woo, S., Park, J., Lee, J.Y., Kweon, I.S., 2018. Cbam: convolutional block attention module. Proceedings of the European Conference on Computer Vision (ECCV), pp. 3 –19. Xiong, Y., Liao, R., Zhao, H., Hu, R., Bai, M., Yumer, E., Urtasun, R., 2019. Upsnet: a uniﬁed panoptic segmentation network. Proceedings of the IEEE/CVF Conference on Com-puter Vision and Pattern Recognition, pp. 8818 –8826.S. Khazem, A. Richard, J. Fix et al. Artiﬁcial Intelligence in Agriculture 7 (2023) 13 –26
26