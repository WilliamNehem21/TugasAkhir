The potential of self-supervised networks for random noise suppression inseismic data
Claire Birnie*, Matteo Ravasi, Sixiu Liu, Tariq Alkhalifah
King Abdullah University of Science and Technology, Thuwal, Saudi Arabia
ARTICLE INFO
Keywords:Machine learningNoise suppressionSelf-supervised learningABSTRACT
Noise suppression is an essential step in many seismic processing work ﬂows. A portion of this noise, particularly in land datasets, presents itself as random noise. In recent years, neural networks have been successfully used todenoise seismic data in a supervised fashion. However, supervised learning always comes with the oftenunachievable requirement of having noisy-clean data pairs for training. Using blind-spot networks, we rede ﬁne the denoising task as a self-supervised procedure where the network uses the surrounding noisy samples to es-timate the noise-free value of a central sample. Based on the assumption that noise is statistically independentbetween samples, the network struggles to predict the noise component of the sample due to its randomicity,whilst the signal component is accurately predicted due to its spatio-temporal coherency. Illustrated on syntheticexamples, the blind-spot network is shown to be an ef ﬁcient denoiser of seismic data contaminated by random noise with minimal damage to the signal; therefore, providing improvements in both the image domain anddown-the-line tasks, such as post-stack inversion. To conclude our study, the suggested approach is applied toﬁeld data and the results are compared with two commonly used random denoising techniques: FX-deconvolutionand sparsity-promoting inversion by Curvelet transform. By demonstrating that blind-spot networks are an ef ﬁ- cient suppressor of random noise, we believe this is just the beginning of utilising self-supervised learning inseismic applications.
1. IntroductionNoise consistently appears as an unwanted companion to the desiredsignal in seismic recordings. As such, noise suppression is a fundamentalstep in all seismic processing workﬂows (Yilmaz, 2001). Arising from local site conditions, as well as being excited by a seismic source, the totalnoiseﬁeld can be seen as the sum of many noise components arising fromdifferent sources, each with their own characteristics ( Birnie et al., 2016). Typically, noise suppression procedures identify a de ﬁning property that easily distinguishes the targeted noise from the desiredsignal and leverage that to separate the former from the latter. In thispaper, we consider the random component of the noise ﬁeld and leverage its non-predictable nature to build a suppression procedure.Random noise suppression has been extensively investigated by theseismic community with the majority of the proposed techniques fallinginto one of the following categories: prediction-, transformation- anddecomposition-based. Prediction-based approaches typically employprediction-ﬁlters which aim to leverage the predictable nature of thecoherent signal and therefore act as noise suppressors. Examples of suchapproaches include t-x predictiveﬁltering and f-x deconvolution both ofwhich can be applied in a stationary or non-stationary manner (e.g.,Chase, 1992;Abma and Claerbout, 1995;Gülünay, 2000;Liu and Chen, 2013). Transformation-based approaches transform the data into adomain, usually sparse, in which the signal and noise can be easilydistinguished due to their individual characteristics. By exploiting thesparse nature of seismic data in the curvelet domain, the curvelettransform is an example of a commonly used transformation-baseddenoising procedure (e.g.,Hennenfent and Herrmann, 2006;Neela- mani et al., 2008;Lianyu et al., 2009). Similarly, other transformation-based methods have been proposed in the literature thatuse different transforms, for example, the wavelet- ( Zhang and Ulrych, 2003;Mousavi et al., 2016), shearlet- (Merouane et al., 2015), and seislet-transforms (Fomel and Liu, 2010), among others. Finally, decomposition-based procedures express the seismic data as thecomposition of weighted basis functions and suppress those associated tothe noise components. Such decomposition procedures utilise the likes ofspectral decomposition (Fomel, 2013), Empirical Mode Decomposition (Bekara and Van der Baan, 2009), and Singular Value Decomposition
* Corresponding author.E-mail address:cebirnie@gmail.com(C. Birnie).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Geosciences
journal homepage:www.keaipublishing.com/en/journals/artiﬁcial-intelligence-in-geosciences
https://doi.org/10.1016/j.aiig.2021.11.001Received 31 August 2021; Received in revised form 1 November 2021; Accepted 2 November 2021Available online 13 November 20212666-5441/©2021 The Authors. Publishing Services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY license
(http://creativecommons.org/licenses/by/4.0/ ).Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59(Bekara and Van der Baan, 2007), among others.With the increased interest in the use of Machine Learning (ML) ingeophysics, a new class of random noise suppression procedures havebeen proposed. The majority of these approaches fall into the realm ofDeep Learning (DL) and use a supervised training approach, which re-quires clean data for training to accompany the noisy input data. As isprevalent across seismic applications of DL, a number of studies haveconsidered the use of synthetic seismic datasets for training a Con-volutional Neural Network (CNN) (e.g., Si et al., 2019;Kim et al., 2019; Wang and Chen, 2019), with a number of other studies utilisingsemi-synthetic datasets, where recorded noise is added to modelledwaveform data (e.g.,Zhang et al., 2020;Brusova et al., 2021). Whilst these experiments have shown promising denoising capabilities onsynthetic datasets, they usually struggle generalizing to ﬁeld data (Zhang et al., 2019). Alternatively, conventional denoising proceduresc a nb eu s e dt oc r e a t e ‘clean’counterparts to the noisy input data fortheir CNN denoising procedures (e.g., Mandelli et al., 2019). However, the performance of such an approach would be bounded by the per-formance of the classical denoiser as well as including prediction errorsdue to the model's imperfection. Moving away from the constraint ofnoisy-clean data pairs, a number of denoising studies have consideredthe potential of Cycle Generative Adversarial Networks (CycleGANs)which do not require paired training data (e.g., Mandelli et al., 2019). Whilst such approaches do not require data pairs, clean and noisy datasamples are still required for training therefore the quandary of creatingclean data samples with similar characteristics to their noisy counter-part–e.g., frequency content–remains. Unsupervised DL procedureshave no such requirements of clean data samples for training. Recently,Zhang et al. (2019)illustrated how an encoder-decoder network couldbe trained on noisy seismic data for random noise attenuation whilstQiu et al. (2021)detailed how an alternative convolutional networkarchitecture can be used without any requirement on windowing thedata. Both these approaches were shown to outperform theFX-deconvolution noise suppression procedure.Considering the broader scientiﬁc community, most DL approachesfor random noise suppression of images, or image-like data, are typicallysupervised and therefore have the requirement of paired noisy-cleandatasets for training (Lehtinen et al., 2018). This is often an unrealistic requirement - not just in seismology but across many other ﬁelds where there is no monitoring technique in which a clean dataset can becollected. In 2018,Lehtinen et al. (2018)proposed Noise2Noise which illustrated how, under the assumption of a stationary signal, a NeuralNetwork (NN) could be trained to denoise an image based on trainingover two noisy samples. Whilst this removes the requirement ofnoisy-clean pairs, it requires noisy-noisy pairs in which the signal isconsistent but the noise is varying within each pair - a problematicrequirement for many monitoring applications. Building on this, Krull et al. (2019)proposed Noise2Void (N2V) which requires only a singlenoisy image for training. Under the assumption that noise is statisticallyindependent between samples, a blind-spot network is used to predict acentral sample's value based on neighbouring samples. As the noise isindependent between samples, the noise's contribution to the sample'svalue cannot be predicted and therefore only the signal's contribution ispredicted, resulting in an efﬁcient denoising procedure. Whilst N2V is anML approach, it can also be considered as a prediction-based approach;wherein, it leverages the ability to predict the signal and the inability topredict the noise resulting in a denoised image.Previously applied to natural images and microscopy data amongothers, in this paper we investigate the adaptation of the N2V work ﬂow to handle the highly oscillatory nature of seismic signal and pseudo-
random noise. Through an extensive hyper-parameter analysis, wefurther identify the optimum hyper-parameters for the seismic denoisingscenario considering both immediate improvements in the image domainand those observed for down-the-line tasks, such as seismic inversion.The paper concludes by illustrating the potential of N2V through anapplication to aﬁeld dataset.2. Theory: blind-spot networksNoise2Void (Krull et al., 2019) is based on the concept of blind-spotNNs, which aim to predict a central pixel value based on neighbouringpixels. Operating on patchesx
jof a single imagex, N2V works by replacing a set of non-adjacent pixels x
jii¼1;2;N pfrom each patch, herein referred to as active pixels, with randomly selected neighbouringpixels, that pertain to the receptiveﬁeld of the chosen networkΩ
ji,a s illustrated inFig. 1. The corrupted patches, in the bottom left of Fig. 1, become the input to a NN whilst the corresponding original patchesrepresents the target values, in the bottom right of Fig. 1. In theory, the NN architecture, denoted asf
θwhereθrefers to the trainable parameters, could be anything that can realistically map between the input and targetvalues. In this paper, we follow the original N2V NN architecture: a2-layer UNet styled afterRonneberger et al. (2015), as illustrated in Fig. 1. As opposed to standard NN image processing tasks, the lossfunction here is not computed on every pixel in the image, instead it isonly evaluated for the active pixels, i.e., those that were corrupted in theinput image:
Fig. 1.Schematic illustration of the Noise2Void denoising procedure.C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
48^θ¼arg min
θ1N
sNpXNs
j¼1XNp
i¼1jxji/C0fθðΩjx
iÞjp(1)wherep¼1, 2 refers to the norm used in the loss - Mean Absolute Error(MAE) or Mean Squared Error (MSE), respectively - and N
sis the number of available training samples (i.e., patches extracted from the image).Krull et al. (2019)illustrated how MSE is the preferred choice fordenoising additive WGN with respect to N2V. However, MAE is some-times the preferred choice for seismic deep learning applications. InAppendix 1, we provide a mathematical formulation that explains underwhich circumstances MSE and MAE should be used, respectively. Finally,we also highlight that no theoretical guarantee can be provided in thecase of correlated noise. Therefore, we decided to experiment with bothloss functions in the following numerical examples.Once trained, the model is applied directly to the full seismic data.Note that at this stage, windowing of the seismic data is not required dueto the ability of CNNs to handle dynamically varying input sizes. How-ever, in the scenario where the data dimensions are not compatible withthe down-/up-sampling of the UNet, then the input data are zero-paddedto achieve an acceptable input data size.2.1. Performance metricsWhilst theoretically, N2V can be applied at any processing stagewhere random noise is observed in the seismic data, in this paper wefocus on seismic images after time migration. A common challenge withmany denoising procedures is that as part of the noise suppression pro-cess not only is the noise suppressed but also the signal is signi ﬁcantly damaged; something that may have a negative effect on down-the-linetasks. With this in mind, three performance metrics are considered:1. Image Peak Signal-to-Noise Ratio (PSNR),2. Frequency correlation, and3. Post-stack inversion PSNR.The image PSNR is calculated asPSNR¼10/C1log
10 
maxfxg2
nxntk^x/C0xk2!; (2)wherexrepresents the clean data,^xthe modiﬁed data (either noisy or denoised), andn
tandn xrepresent the number of time samples and re-ceivers, respectively. To quantify the effect of the N2V denoising, wecompute the percent change in the PSNR between the noisy and denoisedimages. This can be written as,%PSNR¼
100PSNR
noisy/C1PSNR N2V; (3)wherePSNR
noisyandPSNR n2vare thePSNRvalues computed from the noisy and denoised images, respectively.The change in frequency is quantiﬁed using the sample Pearson's correlation coefﬁcient,r
xywhere the aim is to return the noisy data'samplitude spectra to that of the clean data. This is computed as:
rX;Y¼Pnf
i¼0ðXi/C0XÞPnf
i¼0ðYi/C0YÞﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃP
nf
i¼0ðXi/C0XÞ2q ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃP
nf
i¼0ðYi/C0YÞ2q;(4)whereXandYare the amplitude spectra of the clean and denoised data,respectively, averaged over the spatial-axis, XandYare the sample means ofXandY, respectively, andn
fis the number of samples in the spectra. Similarly to the image PSNR, to analyse the effect of N2V wecompute the percent change in the sample Pearson's correlation coef ﬁ- cient when computed with the noisy versus denoised data,
Fig. 2.Datasets (top) used for training and testing N2V and their respective amplitude spectra (bottom): (a,d) Hess synthetic dataset with WGN, (b,e) Hess s ynthetic dataset with 5–100 Hz band-passed noise, and (c,f) land ﬁeld dataset.C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
49%r¼100r
cl;n/C1rcl;N2V ; (5)wherer
cl,nis the correlation coefﬁcient between the clean and noisy dataandr
cl,N2V is the correlation coefﬁcient between the clean and denoiseddata.As aﬁnal metric of comparison, the denoised data are used as inputfor a standard down-the-line task, namely post-stack inversion ( Veeken and Silva, 2004). By doing so, we can inspect the effect of denoising andpossible signal damage on our ability to estimate an acoustic impedancemodel of the subsurface. Post-stack inversion assumes that each trace ofthe post-stack seismic data can be represented by a simple convolutionalmodel as follows:dðtÞ¼
12wðtÞ* dlnðAIðtÞÞdt; (6)whereAI(t) is the acoustic impedance proﬁle in the time domain andw(t) is the time domain seismic wavelet. We rewrite this expression for theentire set of traces in the post-stack data in a compact matrix-vectornotation,d¼WDm, wheredandmare vectorized seismic data and the natural logarithm of the acoustic impedance model, Wis a convo- lution operator andDis aﬁrst derivative operator. The model vector isthen estimated by means of L2-regularised inversion using the PyLopscomputation framework (Ravasi and Vasconcelos, 2020). The PSNR values for the inverted models are calculated as in equation (4)wherexis the true model and^xis the inverted model. As with the above two per-formance metrics, for the inversion PSNR we calculate the percentchange between the inversions for the noisy and denoised inversions.Finally, for theﬁeld dataset there is no ‘clean’dataset for comparison and as such, the above metrics cannot be easily computed. In this situ-ation, we perform qualitative comparison of the raw and denoised im-ages, frequency content, and inversion products. In addition to this, webenchmark the N2V approach against two commonly used techniques forrandom noise suppression: FX-deconvolution and sparsity-promotinginversion with Curvelet transform. FX-deconvolution ( Canales et al., 1984) is based on the concept that the coherent part of a seismic trace canbe predicted in the FX domain from the previous traces via spatial pre-dictiveﬁlters. Our results are based on the Madagascar implementationof FX-deconvolution (Gulunay, 1986) with the same parameters used byLiu and Li (2018)for this dataset, namely a window of 20 traces with aﬁlter length of 4 traces. The second method is instead based on theprinciple that seismic data have a sparse representation in the Curveletdomain (Neelamani et al., 2008) whilst random noise maps incoherentlyacross the Curvelet domain. We employ sparsity-promoting inversionwith the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) solver(Beck and Teboulle, 2009) and soft-thresholding to attenuate randomnoise in our seismic data.3. DataTo be able to perform a quantitative analysis of our denoising pro-cedure the majority of this study is performed on synthetically generateddata. Utilising the SEG Hess VTI model and a 30 Hz Ricker wavelet, 30 2Dslices are created in order to mimic the multiple in-lines or cross-linesthat would be available from a 3D survey. Two different syntheticdatasets are created with this base waveform data: one with White,Gaussian Noise (WGN) as illustrated in Fig. 2(a,d) and one with 5
–100 Hz band-passed noise as illustrated inFig. 2(b,e). The paper concludes with an application of the N2V denoising pro-cedure on aﬁeld dataset from a land acquisition in China that is heavilycontaminated by random noise. Previously analysed by Liu and Chen (2013)andLiu and Li (2018), a single 2D line from the post-stack volumewas released under the Madagascar framework as part of a continuedeffort towards reproducible research. Fig. 2(c,f) illustrates the seismic image and its respective amplitude spectra. The sampling rate for thedatasets (synthetic andﬁeld) is 2 ms.3.1. Data preparationFollowing the procedure of N2V, patches are randomly extractedfrom the seismic lines to form the training dataset. To further increase thesize of such dataset, common data augmentation techniques of bothrotation and polarity reversal are employed. This results in the data
Fig. 3.Data augmentation techniques of polarity reversal and rotation ( β) applied to increase the size of the training data.
Table 1Hyper-parameters of N2V method for the three examples presented in this paper.Those chosen for Exp.2: BP Noise are selected from a hyper-parameter sweep,whilst those for Exp.3: Land Data are manually tuned initialised from those ofExp.2: BP Noise.
Exp.1: Exp.2: Exp.3:WGN BP Noise Land DataTrain-Validate 4500 –500 4500–500 4500–500 Epochs 150 25 15Batch size 128 64 128Patch size 64 /C264 32/C232 32/C232 % Active pixels 0.2 25 33Neighborhood radius 5 15 15Loss MSE MAE MAEUNet depth 2 2 2Kernel size 3 /C233/C233/C23C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
50increasing 8-fold as illustrated inFig. 3. The number and size of the training patches varies between the examples in this paper and aredetailed inTable 1.4. Numerical examples4.1. Synthetic with WGNThe initial example portrays a layman's application of N2V ontoseismic data utilising the same noise properties (i.e., WGN) and hyper-parameters as detailed in the original N2V study on natural images(Krull et al., 2019) and displayed inTable 1.Fig. 4shows the progression of the loss (equation(1)) during the training period for all the activepixels in the 4500 training patches and the 500 validation patches. It isworth noting that the loss in the N2V procedure is slightly different fromclassical losses in supervised learning - in that it does not measure themismatch between the prediction and the ground truth. In the N2Vapplication a loss of zero is not desirable as this indicates that thenetwork has learnt to reproduce both signal and noise. We can observefrom the losses that the validation loss is lower than the training loss fortheﬁrst ~ 20 epochs. While this phenomenon has not been discussed inthe original paper, we argue that it may be due to a combination offactors, such as: (i) data leakage, as the random patch selection procedureallows for partial overlap between the patches in the training and vali-dation sets, and; (ii) the need for strong regularization to avoidover-ﬁtting the noise.An application of the trained model to a 2D line from the syntheticdataset is illustrated inFig. 5. The training took 12.5 min on an NvidiaQuadro RTX 4000 while the application on the 2D line composed of 198traces of 453 time samples took 38 ms. In the image domain, the PSNRhas increased by 73% whilst in the frequency domain there is a muchhigher similarity between the spectra of the noise-free wave ﬁeld (black) and the denoised data (green), as opposed to the noisy data (red). Wheninversion is performed on the data, it is clear that the inversion on thedenoised data produces an acoustic impedance model that is closer to thetrue model than that of the noisy data, with signi ﬁcantly fewer artefacts. Overall, for seismic data contaminated by WGN, it is shown that N2V canFig. 4.Progression of train (red) and validation (black) losses for N2V trainingon the Hess VTI model with additive WGN.
Fig. 5.Trained N2V model applied to a synthetic dataset with WGN. (a) Noise-free synthetic, (b) noisy synthetic given as input to the model, and (c) result of t he N2V denoising procedure. (d) and (e) portray the differences between the noisy and denoised datasets and between the noise-free and denoised datasets, r espectively. Whilst (g), (h) and (i) are the results of an L2-regularised inversion for the clean, noisy and denoised data, respectively.C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
51accurately learn to reproduce the seismic signal from surrounding sam-ples without recreating the noise. This signi ﬁcantly improves the data quality both for current tasks (in the image domain) and down-the-linetasks, such as inversion.4.2. Synthetic with band-passed noiseThe second example focuses on providing a more realistic exampleusing band-passﬁltered noise to identify the potential of N2V for seismicapplications. In this example, we have performed a hyper-parametersweep to identify the optimum hyper-parameters for denoising ofband-passﬁltered random noise. Over 860 parameter combinations wereconsidered from the values detailed in Table 2. Due to the computational cost of training, only one model is generated per hyper-parameter com-bination. However, 100 additional synthetic datasets are generated toanalyse each models’performance.Fig. 6illustrates the performance of a subset of the hyper-parameters for aﬁxed window-size (32/C0by/C032) andﬁxed loss function (MAE).As detailed above, the models are evaluated on the PSNR gain inboth the image and acoustic impedance domains, as well as the increasein the correlation with the amplitude spectra of the noise-free data.ConsideringFig. 6, the general trend of the experiments shows that astraining progresses, i.e. the number of epochs increases, the PSNR gainin the image domain (top row) slightly decreases whilst the PSNR gainin the acoustic impedance domain (bottom row) moderately increases.Finally, the batch size is shown to have a limited in ﬂuence in com- parison to the other hyper-parameters. The optimum hyper-parametercombination is a sum of the ranking of each combination across allthree scoring criteria.The optimum hyper-parameter combination, as detailed in themiddle column ofTable 1, is used to train the band-passed N2V modelwithFig. 7illustrating the loss function progression during training.Fig. 8shows the result of the trained network applied to a synthetic slicecontaminated by band-passﬁltered noise. Similar to the WGN results, aPSNR increase is observed in the image domain, alongside an increasein the similarity with the amplitude spectra of the noise free data.However, more substantial signal leakage is observed around the cen-tral salt body in comparison to the WGN results, as well as some noiseresidual remaining in the denoised result. Despite this, the inversion onthe denoised image results in a cleaner subsurface model than that fromthe noisy image.Table 2Hyper-parameters considered during the hyper-parameter sweep aimed atidentifying an optimal combination for denoising of 5 –100 Hz band-passed noise.
Parameter value optionsEpochs [5, 10, 25, 50, 75, 100, 150]Batch size [32, 64, 128]Patch size [32 /C232, 64/C264] % Active pixels [2, 10, 25, 33]Neighborhood radius [5, 15,30]Loss [MSE, MAE]Train-Validate 4500 –500 UNet depth 2Kernel size 3 /C23
Fig. 6.Subset of grid-search results on hyper-parameter selection of N2V for synthetic data with 5 –100 Hz band-passed noise, a patch size of 32 x32, and the MAE loss function. The top row illustrates the % change in the image PSNR, the middle row the % change in the frequency correlation with the noise-free data, and t he bottom row shows the % change in the PSNR of the inverted acoustic impedance models. The colours represent the different number of active pixels per patch whil st the marker shapes represent the training batch size.Fig. 7.Progression of train (red) and validation (black) losses for N2V trainingon the Hess VTI model with additive 5 /C0100 Hz band-passﬁltered noise.C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
524.3. Field data applicationTo conclude, the N2V workﬂow is applied to a land dataset, which isknown to be contaminated by random noise. Trained using 500 patches,the model is applied to the full 2D line. The resulting denoised image isshown inFig. 9and we compare it with results from the conventional FX-deconvolution and Curvelet denoising procedures. Fig. 10provides a zoomed-in comparison for three areas of interest spanning the model'sdepth range. Considering the difference between the original anddenoised datasets (bottom row ofFig. 9), the Curvelet approach has removed the most noise however we argue that it has possibly over-smoothed the data (effectively reducing the resolution) as well asintroduced some linear artefacts (particularly noticeable in the top row ofFig. 10). This is likely due to the fact that since the Curvelet transformexplains an image as the superposition of localised oriented wavepackets, the denoising process may have slightly corrupted the relativeweighting of the different wave packets whilst trying to suppress thenoise. On the other hand, while the FX approach has also removed moreenergy than the N2V approach, the resulting denoised image is stillheavily contaminated by noise, which is particularly observable in thecloseups ofFig. 10. In addition to this, all approaches have resulted in acertain amount of signal leakage, even though of different nature frommethod to method.Supporting what is observed in the image domain, Fig. 11illustrates the differences in the amplitude spectra between the different denoiseddatasets. Both the FX-deconvolution and Curvelet domain results havereduced the energy across all bandwidths with the Curvelet approachoutperforming the FX approach between 60 and 100 Hz. The N2V resultsshow less reduction in the bandwidths around which the signal is ex-pected with a reduction in energy being observed above 85 Hz. However,even at higher frequencies where signal is likely not to be present, theN2V approach does not reduce the amplitude spectrum to the levels ofthe other two procedures.Finally,Fig. 12shows the inversion products for the original data andthe denoised results. Similar to the observations in the image domain, theN2V results seem to have more details than the overly-smoothed Curveletresults. Conversely, the partial attenuation of genuine signal in the FXdata leads to lower contrasts between features in the inverted acousticimpedance model.5. DiscussionBlind-spot networks offer a solution to the predicament of requiringnoisy-clean pairs of training images for deep learning denoising pro-cedures. Previously utilised in applications on the likes of natural images(Krull et al., 2019), Computed Tomography (CT) images ( Liang et al., 2021) and Synthetic Aperture Radar (SAR) images ( Molini et al., 2021), we have shown that under the right circumstances, N2V can also be apowerful denoiser for seismic data. N2V relies on the assumption thatnoise is statistically independent between pixels, or, as in the seismiccase, between each spatio-temporal sample. In reality, noise in seismicdata is always correlated to some extent. Despite this, we have shownthat, whilst providing the best results on WGN, N2V can still ef ﬁciently denoise both synthetic band-passﬁltered noise as well as recorded noise
Fig. 8.Trained N2V model applied to a synthetic dataset with 5 –100 Hz band-passed noise. (a) The noise-free synthetic, (b) the noisy synthetic given as input to the model, and (c) the result of the N2V denoising procedure. (d) and (e) portray the differences between the noisy and denoised datasets and between the no ise-free and denoised datasets, respectively. Whilst (g), (h) and (i) are the results of an L2-regularised inversion for the clean, noisy and denoised data, respe ctively.C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
53from aﬁeld acquisition. It was observed that for seismic denoising thenumber of epochs had to be signiﬁcantly reduced in comparison to theinitial N2V applications, whilst the number of active pixels had to beincreased. The reduction of epochs hinders the network from learning toreplicate mildly correlated noise whilst still providing adequate trainingtime to learn the dominant signals in the data. Whereas, increasing thenumber of active pixels acts as a regulariser to the training procedure byintroducing additional corruption into the training dataset.Typically in seismic applications, denoising is performed either priorto interpretation or as preparation for down-the-line tasks such asinversion. In this paper, we took a backseat approach and choose a hyper-parameter selection that was a compromise between the three perfor-mance metrics. This resulted in a PSNR gain of 39.28% in the imagedomain and 1.32% in the inversion domain for the realistic syntheticexample (Hess VTI model with bandpassﬁltered noise). However, if the denoising was being performed on data only for direct interpretation, wecould have selected the best hyper-parameters for this task, which wouldhave resulted in an image domain PSNR gain of 50.24%. Similar can besaid for inversion, where the inversion PSNR gain would have been6.27% for the optimum hyper-parameter combination (as illustrated inFig. 6). Typically DL procedures are accompanied by a lengthy trainingtime, often rendering the approaches signiﬁcantly more computationally expensive than conventional procedures ( Birnie et al., 2021). However, due to the small number of epochs required, the N2V approach can betrained and subsequently applied within a matter of minutes for the ﬁeld data - 7 min for ourﬁeld data experiment training. Where post-stackvolumes are available, an extension to 3D denoising would be possiblethrough the adaption from 2D convolutional layers in the NN to 3Dconvolutional blocks. This would likely further improve the denoisingprocedure at the price of increasing the computational cost and memoryrequirements of the network.The potential of N2V was illustrated using post-stack seismic data,however there is no limitation on the processing stage at which blind-spot networks could be applied for denoising. The post-stack scenariowas used due to the availability of aﬁeld dataset that is known to be contaminated by random noise and that has been extensively investi-gated by others as a benchmark dataset for random noise suppressionprocedures (e.g.,Liu and Chen, 2013;Liu and Li, 2018). However, in theory the technique could equally be applied to shot-gathers, receivergathers, or even passive seismic data, assuming each of these arecontaminated by random noise.One known limitation of N2V is the assumption of statistical inde-pendence between samples.Broaddus et al. (2020)proposed an exten- sion to the N2V workﬂow to adapt the approach for structured noisesuppression. Structured N2V utilises selective masking to minimise anycontribution of correlated noise into the prediction of the active pixelsvalue. This extension suggests the potential of utilising self-supervisednetworks for the suppression of correlated noise signals in seismicdata. The simplest adaption would be for the case where noise is inde-pendent across one dimension of the data. For example, individual noisytraces on a common-shot-gather, perhaps from poor receiver coupling, orblended simultaneous shots in a common-receiver-gather. Fig. 13sche- matically illustrates the adaptation of the N2V work ﬂow for the scenario of poorly-coupled receivers. Unlike in N2V, where only the active pixel iscorrupted, in the scenario of StructN2V the full mask, in this case trace, iscorrupted to ensure no relationship can be derived between the active
Fig. 9.Comparison of different random noise suppression procedures. The top row shows the original data (left) followed by the results from the FX-, curvele t- and N2V-denoising procedures, from left to right. The bottom row illustrates the difference between the denoising results and the original data.C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
54pixel and neighbouring pixels contaminated by the same noise source,illustrated by the blue rectangle inFig. 13. Similar to N2V, there is no corruption or additional processing steps required during the denoisingprocedure, assuming the network has been satisfactorily trained. Whilstnot using the masking and loss computation approach of StructN2V,Wang et al. (2021)illustrated how nulling a shot in the common receivergather prior to training, a U-Net could be used to successful deblendmarine seismic data via a self-supervised approach.Finally, in the initial publication of N2V, the authors acknowledgethat:“Intuitively, N2V cannot be expected to outperform methods thathave more information available during training. ”. In other words, N2V is likely to be outmatched by well trained, supervised denoising net-works. However, as noted above, creating seismic datasets with thenoisy-clean pairs required for training traditional supervised proceduresis not trivial. When noisy-clean pairs are generated using a previousdenoising technique, such as by the Curvelet transform, the inclusion ofDL can only serve to speed up the original denoising procedure. As thenetwork learns from the training samples provided then it cannotoutperform the denoising technique which was used to generate thetraining data. Alternatively, when synthetic data is generated to act as the
Fig. 10.Close-up comparison of different random noise suppression procedures from areas highlighted in Fig. 9.
Fig. 11.Comparison of the effect of the different random noise suppression procedures on the amplitude spectra of the data.C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
55Fig. 12.Comparison of the effect of the different random noise suppression procedures when the denoised datasets are fed into an L2 inversion.
Fig. 13.Schematic of the workﬂow for training and inference utilising Structured Noise2Void for the suppression of coherent noise along a trace. The green box indicates the active pixel on which the loss is computed whilst the blue box indicates the area to be corrupted as part of the masking procedure.C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
56training dataset, the clean image will deﬁnitely not contain any noise residual. However, generating synthetic data that accurately representﬁeld data is a well-known challenge ( Birnie et al., 2020). Therefore, whilst certain steps can be taken to reduce the synthetic- ﬁeld data gap for DL applications (Alkhalifah et al., 2021), there is no guarantee that a synthetically trained network will be as effective when applied to ﬁeld data. Recently,Laine et al. (2019)proposed theﬁrst blind-spot network procedure that was shown to perform on-par with, and sometimesoutperform, supervised denoising approaches for natural imagescontaminated by independent and identically distributed additiveGaussian noise. Future studies will consider circumstances under whichself-supervised networks, of varying architectures and training proced-ures, can outperform supervised networks trained on synthetic seismicdata, and vice versa.6. ConclusionWe have shown how blind-spot networks can be applied to accuratelypredict seismic signals without replicating noise, and as such, provide apowerful random noise suppression procedure. As a self-learning pro-cedure, no additional data are required for training, removing thecommon barriers of most deep learning denoising procedures that oftenrequire a‘clean’training dataset. The Noise2Void method has beensuccessfully applied on two synthetic and one ﬁeld datasets. Whilst originally developed for random, additive, white noise, our numericalresults show that such networks can be successfully trained to alsoremove partially correlated noise provided that the number of trainingiterations is reduced whilst the number of corrupted pixels is increased.Declaration of competing interestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to in ﬂuence the work reported in this paper.AcknowledgementsThe authors thank A. Krull, T.-O. Buchholz, and F. Jug for open-sourcing their TensorFlow implementation of Noise2Void. For com-puter time, this research used the resources of the SupercomputingLaboratory at King Abdullah University of Science Technology (KAUST)in Thuwal, Saudi Arabia.Appendix: A. statistical interpretation of blind-spot networksIn this Appendix, we provide a statistical interpretation of the blind-spot networks used in this work following a derivation similar to that of Laine et al. (2019)andBatson and Royer (2019). First of all, we recall the Maximum Likelihood Estimator (MLE) that is generally used as the starting point for the derivation of supervised learningtraining strategies:^θ¼argmax
θpðYjX;;θÞ (7)whereXandyare the distributions of the input and target data, respectively. Such distributions are generally unknown, but a set of ( x
i,yi)i¼1, 2N s
samples are available, which can provide us with a marginal distribution. Under the assumption that such samples are drawn independently from theunderlying distributions, the MLE can expressed as:^θ¼argmax
θQ
ipðy ijxi;θÞ¼argmax
θP
ilogðpðy ijxi;θÞÞ/C25argmax
θEx;y/C24X;Y ½logðpðyjx;θÞÞ/C138; (8)where the trainable parametersθare obtained by maximizing the mean of the log-likelihood evaluated over all available pairs of inputs and targets.In the context of denoising, the noisy image yis expressed as the clean imagesxcorrupted by some noisenwith possibly known statistical properties i.e.,y¼xþn. However, as discussed in the main text, availability of clean images is not always possible: therefore, blind-spot networks assume that theunknown clean values depend on the context of neighbouring (noisy) pixels denoted as Ω
x. Moreover, when the noise can be assumed to be uncorrelated from pixel to pixel, the noisy image is used as target under the assumption that the network will only be able to reproduce its coherent part and fail torecreate the noise component, i.e.y/C25f
θ(Ωx). In mathematical terms the MLE can be rewritten as: ^θ¼argmax
θEx/C24X½logðpðxjΩ x;θÞÞ/C138¼arg min
θ/C01N
sX
ilogðpðx ijΩxi;θÞÞ; (9)where we consider here for simplicity the i/C0thtraining patch. Summing over all available patches leads to the loss function in equation (1). Let's now consider the two most commonly used statistical distributions for the noise ﬁeldnin seismic data and identify the corresponding MLE estimator:●White Gaussian noise:n/C24Nð0;
σ2Þ. The corresponding noisy image is distributed as x/C25f θðΩxÞ/C0n/C24Nðf θðΩxÞ;σ2Þ. Given the probability density function:pðxjΩ
x;θÞ¼1
σﬃﬃﬃﬃﬃ2πpe/C012
σ2ðx/C0f θðΩxÞÞ2(10)C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
57its corresponding training loss function becomes the well-know Mean Square Error (i.e., p ¼2 in equation(1)):/C0X
ilogðpðx ijΩxi;θÞÞ ¼X
iðxi/C0fθðΩxiÞÞ2(11)
●Laplace noise:n/C24L ð0;
σÞ. The corresponding noisy image is distributed as x/C25f θðΩxÞ/C0n/C24L ðf θðΩxÞ;σÞ. Given the probability density function:pðxjΩ
x;θÞ¼12
σe/C0jx/C0fθðΩxÞj
σ (12)its corresponding training loss function becomes the well-know Mean Absolute Error (i.e., p ¼1 in equation(1)):/C0X
ilogðpðx ijΩxi;θÞÞ ¼X
ijxi/C0fθðΩxiÞj (13)A numerical validation of the correspondence between statistical models for the additive noise and the choice of the training loss function is ﬁnally provided inFig. 14. MSE and MAE provide the best denoising performance in terms of PSNR for Gaussian and Laplace noise, respectively.
Fig. 14.Denoising of synthetic dataset for 3 different noise models: left) White Gaussian noise, center) Laplace noise, right) Band-passed Gaussian noise. Top) Noisy data, middle) Denoised data using MAE as training loss, bottom) Denoised data using MSE as training loss.
Finally, as noise in seismic data is generally correlated in time, space, or both, we observe that neither of the above de ﬁned models is correct. On the other hand, if we assume the noise to have a certain correlation length in either time and/or space, we can express the noise within the correlationwindow asn/C24Nð0;ΣÞwhereΣis the covariance matrix of the noise. To take into account such correlation we must therefore write x/C25f
θðΩxÞ/C0n/C24 Nðf
θðΩxÞ;ΣÞwhere we have grouped the nearby correlated pixels to form the vectors xandn. The corresponding probability density function becomes:pðxjΩ
x;θÞ¼1ð2
πÞk=2detðΣÞ1=2e/C012ðx/C0f θðΩxÞÞΣ/C01ðx/C0f θðΩxÞÞ; (14)and the training loss can be written as:C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
58/C0X
ilogðpðx ijΩxi;θÞÞ ¼X
iðxi/C0fθðΩxiÞÞΣ/C01ðxi/C0fθðΩxiÞÞ; (15)We observe that if the covariance matrix is unknown, neither MAE nor MSE can correctly approximate this loss function. In this case, empiricalevidence inFig. 14supports our choice of using MAE in the case of mildly correlated noise, although more sophisticated denosing models that take intoaccount noise correlation will be investigated in the context of seismic data denoising.References
Abma, R., Claerbout, J., 1995. Lateral prediction for noise attenuation by tx and fxtechniques. Geophysics 60, 1887 –1896. Alkhalifah, T., Wang, H., Ovcharenko, O., 2021. Mlreal: bridging the gap betweentraining on synthetic data and real data applications in machine learning. In: 82ndEAGE Annual Conference&Exhibition. European Association of Geoscientists & Engineers, pp. 1–5.Batson, J., Royer, L., 2019. Noise2self: blind denoising by self-supervision. In:International Conference on Machine Learning. PMLR, pp. 524 –533. Beck, A., Teboulle, M., 2009. A fast iterative shrinkage-thresholding algorithm for linearinverse problems. SIAM J. Imag. Sci. 2, 183 –202. Bekara, M., Van der Baan, M., 2007. Local singular value decomposition for signalenhancement of seismic data. Geophysics 72, V59 –V65. Bekara, M., Van der Baan, M., 2009. Random and coherent noise attenuation by empiricalmode decomposition. Geophysics 74, V89 –V98. Birnie, C., Chambers, K., Angus, D., Stork, A., 2016. Analysis and models of pre-injectionsurface seismic array noise recorded at the aquistore carbon storage site. Geophys. J.Int. 206 (2), 1246–1260.https://doi.org/10.1093/gji/ggw203 . Birnie, C., Chambers, K., Angus, D., Stork, A.L., 2020. On the importance ofbenchmarking algorithms under realistic noise conditions. Geophys. J. Int. 221,504–520.Birnie, C., Jarraya, H., Hansteen, F., 2021. An Introduction to Distributed Training ofDeep Neural Networks for Segmentation Tasks with Large Seismic Datasets arXivpreprint arXiv:2102.13003. Broaddus, C., Krull, A., Weigert, M., Schmidt, U., Myers, G., 2020. Removing structurednoise with self-supervised blind-spot networks. In: 2020 IEEE 17th InternationalSymposium on Biomedical Imaging (ISBI). IEEE, pp. 159 –163. Brusova, O., Poche, S., Kainkaryam, S., Valenciano, A., Sharma, A., 2021. An innovativestrategy for seismic swell noise removal using deep neural networks. In: FirstInternational Meeting for Applied Geoscience &Energy. Society of Exploration Geophysicists, pp. 3179 –3183. Canales, L.L., et al., 1984. Random noise reduction. In: 1984 SEG Annual Meeting. Societyof Exploration Geophysicists. Chase, M.K., 1992. Random noise reduction by fxy prediction ﬁltering. Explor. Geophys. 23, 51–56.Fomel, S., 2013. Seismic data decomposition into spectral components using regularizednonstationary autoregression regularized nonstationary autoregression. Geophysics78, O69–O76.Fomel, S., Liu, Y., 2010. Seislet transform and seislet frame. Geophysics 75, V25 –V38. Gulunay, N., 1986. Fxdecon and complex wiener prediction ﬁlter. In: SEG Technical Program Expanded Abstracts 1986. Society of Exploration Geophysicists,pp. 279–281.Gülünay, N., 2000. Noncausal spatial prediction ﬁltering for random noise reduction on 3-d poststack data. Geophysics 65, 1641 –1653.
Hennenfent, G., Herrmann, F.J., 2006. Seismic denoising with nonuniformly sampledcurvelets. Comput. Sci. Eng. 8, 16 –25. Kim, Y., Hardisty, R., Marfurt, K.J., 2019. Seismic random noise attenuation in fx domainusing complex-valued residual convolutional neural network. In: SEG TechnicalProgram Expanded Abstracts 2019. Society of Exploration Geophysicists,pp. 2579–2583.Krull, A., Buchholz, T.O., Jug, F., 2019. Noise2void-learning denoising from single noisyimages. In: Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition, pp. 2129–2137. Laine, S., Karras, T., Lehtinen, J., Aila, T., 2019. High-quality self-supervised deep imagedenoising. Adv. Neural Inf. Process. Syst. 32, 6970 –6980.Lehtinen, J., Munkberg, J., Hasselgren, J., Laine, S., Karras, T., Aittala, M., Aila, T., 2018.Noise2noise: Learning Image Restoration without Clean Data arXiv preprint arXiv:1803.04189.Liang, K., Zhang, L., Xing, Y., 2021. Training a low-dose ct denoising network with onlylow-dose ct dataset: comparison of ddln and noise2void. In: Medical Imaging 2021:Physics of Medical Imaging. International Society for Optics and Photonics,p. 115950I.Lianyu, S., Jinrong, F., Junhua, Z., Xugang, Z., Yanshu, M., 2009. Curvelet transform andits application in seismic data denoising. In: 2009 International Conference onInformation Technology and Computer Science. IEEE, pp. 396 –399. Liu, G., Chen, X., 2013. Noncausal f –x–y regularized nonstationary prediction ﬁltering for random noise attenuation on 3d seismic data. J. Appl. Geophys. 93, 60 –66. Liu, Y., Li, B., 2018. Streaming orthogonal prediction ﬁlter in the t-x domain for random noise attenuation. Geophysics 83, F41 –F48. Mandelli, S., Lipari, V., Bestagini, P., Tubaro, S., 2019. Interpolation and Denoising ofSeismic Data Using Convolutional Neural Networks arXiv preprint arXiv:1901.07927 . Merouane, A., Yilmaz, O., Baysal, E., 2015. Random noise attenuation using 2-dimen-sional shearlet transform. In: SEG Technical Program Expanded Abstracts 2015.Society of Exploration Geophysicists, pp. 4770 –4774. Molini, A.B., Valsesia, D., Fracastoro, G., Magli, E., 2021. Speckle2void: deep self-supervised sar despeckling with blind-spot convolutional neural networks. IEEETrans. Geosci. Rem. Sens. 1 –17.https://doi.org/10.1109/TGRS.2021.3065461 . IEEE. Mousavi, S.M., Langston, C.A., Horton, S.P., 2016. Automatic microseismic denoising andonset detection using the synchrosqueezed continuous wavelet transform. Geophysics81, V341–V355.Neelamani, R., Baumstein, A.I., Gillard, D.G., Hadidi, M.T., Soroka, W.L., 2008. Coherentand random noise attenuation using the curvelet transform. Lead. Edge 27, 240 –248. Qiu, C., Wu, B., Liu, N., Zhu, X., Ren, H., 2021. Deep learning prior model forunsupervised seismic data random noise attenuation. IEEE Geosci. Rem. Sens. Lett.1–5.https://doi.org/10.1109/LGRS.2021.3053760 . IEEE. Ravasi, M., Vasconcelos, I., 2020. PyLops - a Linear-Operator Python Library for scalablealgebra and optimization. SoftwareX 11, 100361. https://doi.org/10.1016/ j.softx.2019.100361.Ronneberger, O., Fischer, P., Brox, T., 2015. U-net: convolutional networks for biomedicalimage segmentation. In: International Conference on Medical Image Computing andComputer-assisted Intervention. Springer, pp. 234 –241. Si, X., Yuan, Y., Si, T., Gao, S., 2019. Attenuation of random noise using denoisingconvolutional neural networks. Interpretation 7, SE269 –SE280. Veeken, P., Silva, M., 2004. Seismic Inversion Methods and Some of Their Constraints.First Break 22.Wang, F., Chen, S., 2019. Residual learning of deep convolutional neural network forseismic random noise attenuation. IEEE Geosci. Rem. Sens. Lett. 16, 1314 –1318. Wang, S., Hu, W., Yuan, P., Wu, X., Zhang, Q., Nadukandi, P., Ocampo Botero, G.,Chen, J., 2021. Seismic deblending by self-supervised deep learning with a blind-trace network. In: First International Meeting for Applied Geoscience &Energy. Society of Exploration Geophysicists, pp. 3194 –3198. Yilmaz,€O., 2001. Seismic Data Analysis, vol. 1. Society of Exploration Geophysicists,Tulsa.Zhang, H., Ma, C., Pazzi, V., Zou, Y., Casagli, N., 2020. Microseismic signal denoising andseparation based on fully convolutional encoder –decoder network. Appl. Sci. 10, 6621.Zhang, M., Liu, Y., Chen, Y., 2019. Unsupervised seismic random noise attenuation basedon deep convolutional neural network. IEEE Access 7, 179810 –179822. Zhang, R., Ulrych, T.J., 2003. Physical wavelet frame denoising. Geophysics 68, 225 –231.C. Birnie et al. Artiﬁcial Intelligence in Geosciences 2 (2021) 47 –59
59