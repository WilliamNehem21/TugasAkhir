Cumulative unsupervised multi-domain adaptation for Holsteincattle re-identiﬁcation
Fabian Dubourvieuxa,b,⁎,1, Guillaume Lapougea,⁎,1, Angélique Loescha, Bertrand Luvisona,R o m a r i cA u d i g i e ra
aUniversité Paris-Saclay, CEA List, Palaiseau 91120, France
bLITIS, INSA Rouen, Normandie Université, Saint-Etienne-du-Rouvray 76801, France
abstract article info
Article history:Received 26 May 2023Received in revised form 1 October 2023Accepted 7 October 2023Available online 17 October 2023In dairy farming, ensuring the health of each cow and minimizing economic losses requires individualmonitoring, achieved through cow Re-Identiﬁcation (Re-ID). Computer vision-based Re-ID relies on visually dis- tinguishing features, such as the distinctive coat patterns of breeds like Holstein.However, annotating every cow in each farm is cost-prohibitive. Our objective is to develop Re-ID methods applicable to both labeled and unlabeled farms, accommodating new individuals and diverse environments. Un-supervised Domain Adaptation (UDA) techniques bridge this gap, transferring knowledge from labeled sourcedomains to unlabeled target domains, but have only been mainly designed for pedestrian and vehicle Re-ID applications.Our work introduces Cumulative Unsupervised Multi-Domain Adaptation (CUMDA) to address challenges of lim-ited identity diversity and diverse farm appearances. CUMDA accumulates knowledge from all domains, enhanc-ing specialization in known domains and improving generalization to unseen domains. Our contributions includea CUMDA method adapting to multiple unlabeled target domains while preserving source domain performance,along with extensive cross-dataset experiments on three cattle Re-ID datasets. These experiments demonstrate signiﬁcant enhancements in source preservation, target domain specialization, and generalization to unseendomains.© 2023 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Re-identiﬁcationDomain adaptationHolstein cattleUnsupervised learningMonitoring
1. IntroductionTraditionally, farmers have shouldered the vital responsibility ofoverseeing the health and behavior of their dairy cows. Detectingearly indicators of heat or unusual behavior in these animals is of para-mount importance, not only to ensure their overall well-being but alsoto mitigate potential economic losses. As we transition from manualmonitoring to computer vision-based individual tracking, there arisesthe need for precise identiﬁcation of each cow within a farm. This intri-cate task is commonly referred to as cow Re-Identiﬁcation (Re-ID). In this paper, we focus the cow Re-ID on the Holstein breed, notable forits visually distinctive spot patterns. Besides, we match observations ofthe same individual in the short term, i.e. over a de ﬁned timeframe dur- ing which its visual appearance is presumed to remain unchanged.Historically,Re-ID has been a focal point in image interpretation,particularly in the context of pedestrian video surveillance Zheng et al. (2016). The primary objective ofRe-ID in this context is to track orretrieve individuals of interest through camera networks with non-overlappingﬁelds of view. The introduction of supervised learning, fa-cilitated by deep Convolutional Neural Networks (CNNs) Krizhevsky et al. (2012), has signiﬁcantly advanced the performance of supervisedpersonRe-IDYe et al. (2021).TheRe-ID paradigm has expanded beyond pedestrian tracking to en-compass a broader array of real-world applications, including vehicleRe-ID for trafﬁc surveillanceKhan and Ullah (2019)and animalRe-ID for monitoring cattleSchneider et al. (2020);Liu et al. (2019a, 2019d, 2019b).SupervisedRe-ID demands the painstaking annotation of datasets. Inthe speciﬁc context of cow Re-ID, the impracticality and cost of annotat-ing every cow in each farm necessitate the development of a Re-ID method capable of generalizing effectively across both labeled and unla-beled farms. This adaptability is crucial to accommodate the introduc-tion of new cows into established farms and the deployment of thetechnology in novel farm environments. However, Re-ID grapples with a notable decline in performance when the test image distribution di-verges from that of the training dataset.To address these challenges, Unsupervised Domain Adaptation(UDA) methods have been devised for Re-ID Ge et al. (2019, 2020);Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
⁎Corresponding authors at: Université Paris-Saclay, CEA List, Palaiseau 91120, France.E-mail address:guillaume.lapouge@cea.fr(G. Lapouge).
1These authors contributed equally to this work.
https://doi.org/10.1016/j.aiia.2023.10.0022589-7217/© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/Dubourvieux et al. (2021a). UDA seeks to adapt a model to a domainof interest by leveraging an annotated dataset from anotherdomain (the source domain) and unlabeled data from the domain of in-terest (the target domain). While extensively explored for pedestrianand vehicleRe-ID, UDA proves particularly relevant in cow Re-ID appli-cations, given the impracticality of annotating each cow in numerousfarms.However, the unique constraints and requirements inherent in thecow Re-ID application have spurred further developments, whichform the core focus of this paper. In cow Re-ID, each farm represents a distinct domain, characterized by its unique set of individuals, cameras,and environmental context. Consequently, cross-domain performancedegradation becomes a pertinent issue. Additionally, each domain typi-cally comprises a limited subset of animals, restricting the generaliza-tion potential ofRe-ID networks trained on individual datasets, as inconventional UDA.In pursuit of enhancing the model's discriminatory capabilitiesamong cows, we propose a novel framework: Cumulative UnsupervisedMulti-Domain Adaptation (CUMDA). CUMDA aims to accumulate Re-ID knowledge from data collected across multiple farms (diverse do-mains), enabling superior specialization within known domains andimproved performance when confronted with previously unseendomains.To our knowledge, existing UDA Re-ID methods have primarilyfocused on multi-domain scenarios with multiple annotated sourcedomains. No UDA Re-ID approach has been designed speci ﬁcally for multiple unlabeled target domains. Moreover, while the Domain Gener-alization frameworkWang et al. (2021)seeks to create models that per- form well on unseen target domains, it differs from CUMDA. CUMDAassumes knowledge of all target domains during training and accessto unlabeled data from these domains, with the objective of enhancingspecialization and cross-domainRe-ID performance through knowledgeaccumulation. While generalization is not the primary aim, we antici-pate that a CUMDA model, through the accumulation of knowledgefrom diverse target domains, can enhance its generalization topreviously unseen domains.Furthermore, traditional UDA frameworks often prioritize maximiz-ing performance on the target domain at the expense of forgetting orneglecting source domain knowledge Dubourvieux et al. (2021a).I n practice, when new cameras are deployed on a farm, the adaptation oftheRe-ID model to these new devices is desired, while maintaininghigh performance on existing ones—a characteristic we term”source conservation.”In summary, while existingRe-ID methods may be directly applica-ble to cattleRe-ID, none of them fully addresses the unique constraintsand practical requirements of cow Re-ID that underscore the choice ofa CUMDA framework over a conventional UDA approach. Driven bythese practical considerations and the need for cross-domain cattleRe-ID solutions, this paper endeavors to design a cross-domainmodel tailored to the distinctive challenges of cattle Re-ID across mul-tiple farms, an area that has seen limited study. Our aim is to developsuch a method within the framework of CUMDA, emphasizing sourceconservation and the accumulation of knowledge from multipleunsupervised target domains. This paper comprises two primarycontributions:•A Source-Guided CUMDA method, that can improve cross-domain re-ID performance, on one or multiple target domains, whilebeing able to accumulate knowledge from multiple domains and pre-serve the source performance.•Extensive cross-dataset experiments for CUMDA re-ID on 2public cow re-ID datasets and a private one.2. Related workThis work is at the intersection of two research areas: cattle re-IDand cross-domain re-ID.2.1. Cattle re-IDRe-ID has been mainly focused on pedestrian and vehicles Ye et al. (2021). Some work exists for animal re-ID, focusing for instance onAmur tiger re-IDLiu et al. (2019a)
;Li et al. (2019a);Liu et al. (2019d). Nevertheless, Amur tigers have a coat of spots visually very distinctfrom cows, as well as the deformations of these spots their movementsspeciﬁc to their morphology. This leads us to believe that cows have asufﬁciently distinct appearance from Amur tigers to be considered a dis-tinct class of interest for re-IDLiu et al. (2019d). That's why he speciﬁc- ity of the appearance of cows has led to speci ﬁc worksBergamini et al. (2018);Andrew et al. (2021, 2016, 2017);Gao et al. (2021), studying it under the frameworks of supervised learning or self-supervised learn-ingGao et al. (2021)assuming access to tracklets. However, supervisedlearning or self-supervised learning are not suitable for learning com-bining data from multiple farms, due to the increased annotation costfor the supervised paradigm or the failure to account for inter-domainheterogeneities with multiple farm data in the self-supervised frame-work. To the best of our knowledge, cattle re-ID has therefore neverfocused on the cross-domain setting nor the multiple-domain one.2.2. Cross-domain person and vehicle re-ID via UDA paradigmCross-domain re-ID has been extensively studied for people andvehicle re-ID problems. It can be divided into two main families ofapproaches.Domain-translationapproaches were theﬁrst ones considered for cross-domain person re-ID. Among these approaches, image-to-image translationmethods seek to transfer the source images into the targetdomain styleWei et al. (2018a);Bak et al. (2018);Deng et al. (2018); Zhong et al. (2018);Liu et al. (2019c);Huang et al. (2019);Chen et al. (2019);Li et al. (2019b). They are based on generative models such asthe CycleGANZhu et al. (2017). They are constrained during trainingto translate images to new style while preserving the identity class.This allows the identity label to be reused for supervised re-ID learningfrom labeled source images with a new target-style. Domain-invariant feature learningmethodsWang et al. (2018);Lin et al. (2018);Chang et al. (2019b);Li et al. (2018, 2019b);Qi et al. (2019)directly constrain the feature space of the learned model, e.g. by aligning feature distribu-tions between domains, with the objective that the re-ID model learnedto be discriminative on the source domain, is also discriminative on thetarget domain in this domain-invariant space.Because of limited cross-domain performance of domain-translationapproaches, researchers have been interested in pseudo-labelingap- proachesSong et al. (2020);Zhang et al. (2019);Jin et al. (2020);
Tang et al. (2019);Zhai et al. (2020a);Zou et al. (2020);Fu et al. (2019). They consist in predicting identity labels for images of the targetdomain, by clustering features obtained with an initial feature encoder,generally learned to perform re-ID in a supervised way on the sourcedomain. Pseudo-label approaches have allowed a clear improvementof the cross-domain re-ID performance Ge et al. (2019, 2020); Dubourvieux et al. (2021b, 2022). To achieve even better performance,techniques have been developed to get better pseudo-labels or makethe framework more robust against noisy labels Chen et al. (2020); Zhai et al. (2020b);Zhao et al. (2020);Peng et al. (2020);Yu et al. (2019);Zhong et al. (2019);Luo et al. (2020);Dubourvieux et al. (2021a).The approach proposed in this paper is also in line with pseudo-labeling approaches. Contrary to existing work, this one focuses on anew class of objects for cross-domain re-ID, the cross-domain cow re-ID, for which no UDA approach has been considered. Moreover, unlikeexisting work in pseudo-labeling for cross-domain person re-ID,which considers a single target domain scenario, this work tackles amore challenging, yet practical and more speci ﬁc to cattle re-ID real- world requirements, cross-domain problem: Cumulative UnsupervisedMulti-Domain Adaptation (CUMDA). This cross-domain frameworkF. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
47seeks to leverage the knowledge from one or several domains of interest
(e.g.: various cattle farms), to improve the cross-domain re-ID perfor-
mance for each domain (each farm), including on the source domain
re-ID ability of the model.
3. Methodology
Lower part: proposed pseudo-labeling method for multi-target
CUMDA re-ID. Black arrows indicate the pseudo-labeling and training
cycle, gray arrows indicate the clustering parameters optimization
steps. It considers a set of ntarget domains 1,,nand a source do-
main . For each target, SOURCE CALIBRATION computes an associated
labeled source validation set x1
val,…,xn
val. After FEATURE EXTRAC-
TION of all source validation and target sets, SOURCE-GUIDED AUTO HP
TUNING computes target-speci ﬁc optimal hyperparameter (HP) values
λ∗
1,,λ∗
nfrom calibrated source validation sets by maximizing cluster-
ing quality (Sec. 3.4). Target-speci ﬁcPSEUDO LABELING BY CLUSTER-
INGis then carried out. TRAINING is jointly done on all pseudo-labeled
target sets and on the labeled source domain by minimizing
LSG CUMDA (Sec. 3.2).
Our goal is to design a CUMDA re-ID method that can improve re-ID
performance on all seen domains. More speci ﬁcally, it is expected that
this method can:
•specialize for one or multiple target domains to improve perfor-
mance on them;
•ensure good performance on the source domain.
We also expect such a model to generalize well on an unseen new
target domain, as it should accumulate knowledge from multiple do-
mains.
As illustrated in the upper part of Fig. 1 , existing pseudo-labeling
methods are designed for UDA re-ID, i.e. to improve re-ID performance
on a single target domain, using only data from this domain. Therefore,
they need to be rethought in order to meet the previously mentioned
objectives of CUMDA re-ID, and to incorporate the use of data from mul-
tiple domains. This section introduces key elements of our CUMDA re-ID
method.
The lower part introduces our CUMDA re-ID method whose compo-
nents will be motivated in this section.
General notations. We consider a set of ntarget domains of interest
1,,n,n∈N and a source domain , from which a set of labeled
data Sfrom , and unlabeled data T1,,Tnfrom 1,,n(the target
domains) are available.
3.1. Pseudo-labeling by clustering
A feature encoder fθ,θ∈Rp,p∈N (usually a CNN) is trained on the
labeled source dataset T, by minimizing a re-ID loss function (e.g.: Clas-
siﬁcation Loss, Triplet Loss as in Hermans et al. (2017) , a combination of
both as in Luo et al. (2019) …)LIDθ,T, w.r.t θ.T h e n ,ac l u s t e r i n gf u n c -
tion Cλdeﬁned by hyperparameters (HP) λ∈Rm,m∈Ni su s e dt op r e -
dict pseudo-labels of data samples in each target set, by using the
feature representation of their data. Pseudo-labeled target sets
T1,,Tncan then be obtained:
∀k∈1,n,TkCλfθ,Tk 1
This step, described by Eq. 1, is called Pseudo-Labeling by Clustering
(PLC). These pseudo-labels will be used to de ﬁne the loss that super-
vises the learning on the targets.
3.2. Source-guided CUMDA re-ID learning
The objectives of CUMDA re-ID are being able to improve the cross-
domain performance for one or multiple target domains, while being
able to preserve the source re-ID performance. Inspired by thesource-guided loss function designed by Dubourvieux et al. (2021a)
for single-target domain UDA re-ID, we de ﬁne a new Source-Guided
loss function extended for CUMDA re-ID. Therefore, fθisﬁne-tuned by
minimizing a Source-Guided CUMDA (SG-CUMDA) loss function
LSG CUMDA which aggregates all the individual re-ID loss functions on
each domain, as follows:
LSG CUMDA θ,S,T1,,Tn LIDθ,S∑n
k1LIDθ,Tk 2
3.3. Alleviating the domain gap with domain-speci ﬁc batch normalization
It is argued that the gap domain can degrade performance
Dubourvieux et al. (2021a) . The proposed methodology proposes to
mitigate it at the level of batch normalization layers.
Batch Normalization (batchnorm) is a widely-used technique to ac-
celerate and improve the training of deep neural networks, by reducing
the internal covariate-shift Ioffe and Szegedy (2015) . It consists in nor-
malizing the batch after each convolutional or linear layers, using the
batch-wise mean and variance of activations, and learnable af ﬁne pa-
rameters that rescale the features into batch-normalized features.
Prior works highlighted the negative impact on training stage when
computing batchnorm statistics with data from different domains
Zajkac et al. (2019) . Domain-Speci ﬁc Batch Normalization (DSBN)
layers have been proposed to be effective for various domain adaptation
problems such as UDA classi ﬁcation Chang et al. (2019a) and UDA re-ID
Dubourvieux et al. (2021a) . It consists in using domain-speci ﬁc
batchnorm af ﬁne parameters and computing domain-speci ﬁc mean
and variance. Other network parameters are still shared and used what-
ever the domain. fθbeing implemented by a CNN, DSBN layers are used
after each convolutional and fully-connected layers.
3.4. Improving pseudo-labels with multi-target automatic source-guided
selection of Pseudo-labeling Hyperparameters
Pseudo-labeling UDA approaches are sensitive to the quality of
the proposed labeling, which depends on the good tuning of cluster-
ing hyperparameters λ. In the context of pedestrian and vehicle re-
ID, the ideal λvalue called λ∗has been shown to depend on the target
dataset distribution in the feature space, as well as the target dataset
statistics (e.g. the number of shots per identity) Dubourvieux et al.
(2021b) . Most of the works that focus on pedestrian and vehicle
UDA re-ID reuse the same values empirically tuned for a speci ﬁc
cross-dataset experiment, on all different cross-datasets considered
afterward. It has been shown that this can result in signi ﬁcantly re-
duced performance compared to getting a suitable value
Dubourvieux et al. (2021b) .
For real world cow-re-ID, because the target is unlabeled, it is impos-
sible to build a labeled validation set to tune this value. Besides, usual λ
value used for person re-ID may not translate well to cow re-ID prob-
lem, given the particularities of cow datasets (color distribution, view-
points …). Therefore, we propose to automate the tuning of λfrom
the labeled data. To do so, we use the HyperParameters Automated by
Source & Similarities (HyPASS) algorithm Dubourvieux et al. (2021b) .
HyPASS was designed and tested for single-target domain pedestrian
and vehicle UDA re-ID. It optimizes clustering hyperparameters from
the labeled data of the source validation dataset. More concretely,
HyPASS estimates by model selection on Cλ, the value λ∗such as λ
arg max λCλSvalwhere is a clustering quality function and Svala
labeled validation set from the source data. It is illustrated in Fig. 1 as
source-guided auto HP tuning.
HyPASS-SC for CUMDA: improving the robustness to domain gap.
In this paper, we adapt HyPASS to our cow re-ID CUMDA problem, by
selecting a speci ﬁc value λkfor each target dataset Tk. The PLC de ﬁned
by Eq. 1,i sr e d e ﬁned as a Domain-speci ﬁc PLC given by:F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
48∀k∈1,n,TkCλkfθ,Tk 3
HyPASS functioning relies on domain-gap reduction. In the multi-
target use-case, we propose to achieve it in two ways:
•At the feature level, target-speci ﬁc DSBN is leveraged to reduce
the domain-gap in the feature space (cf. section 3.3);•At the dataset statistics level, a new Source validation Calibration
(SC) approach is proposed.
While cross-dataset statistic gap may be overlooked for an academic
person and vehicle re-ID such as in Dubourvieux et al. (2021b) , it be-
comes crucial in the considered cow re-ID problematic. Indeed, in the
well-known person re-ID datasets, usual statistics discrepancies are
Fig. 1. Upper part: pseudo-labeling paradigm for single-target UDA re-ID. Black arrows indicate the pseudo-labeling and training cycle. FEATURE EXTRACTION is carried out for images x1
of the target domain 1with a feature encoder fθ.PSEUDO LABELING BY CLUSTERING computes pseudo-labels y1on clustered features. TRAINING is done on the pseudo-labeled target
set x1,y1by minimizing LID.F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
49minimal, with between 21 and 36 shots per ID (e.g. Market1501 Zheng et al. (2015),D u k e M T M CRistani et al. (2016), personXSun and Zheng (2019)and MSMT17Wei et al. (2018b)). However, that does not hold true in all cases. Especially in scarcer animal-related re-ID, where thedata may be difﬁcult to acquire, resulting in higher discrepancies inshots per ID. Moreover, contrary to person or vehicle re-ID applicationsin open-world, the number of cows in a farm of interest is generallyknown, or can be easily estimated for a cross-domain re-ID applications.This allows us to design SC for cattle re-ID, which consists in equalizingthe number of shots per ID of the source to match that of the target. SCgenerates target-speciﬁc source validation setsS
valkfromSval, that reduce the cross-dataset statistics gap with the corresponding target trainingsetT
k. SC is represented as Source Calibration on Fig. 1. HyPASS is then run onS
valkto computeλ∗k, the optimal hyperparameter value forclustering onT
k. The combined use of HyPASS and SC will be referredto as HyPASS-SC in the rest of the paper. Implementation details aregiven in Sec. 4.2.7.4. Experiments4.1. DatasetsIn this paper, we employ three different datasets: Cows2021 Gao et al. (2021), HolsteinCattleRecognitionBhole et al. (2019)and the pri- vate dataset CowFisheye. The content of each dataset is illustrated inFig. 2.4.1.1. Cows2021Cows2021Gao et al. (2021)is a dataset featuring RGB images andvideos of 186 individuals. The data was acquired from 4 m above theground by a pinhole camera pointed downwards.Image extraction.The images were extracted over one month of ac-quisition. The extraction of cow images from the video stream relies onan oriented bounding-box detector and a tracker. The boxes arecentered around cow torsos, excluding their heads, with all individualsfacing right. For more details on data acquisition, please refer to Gao et al. (2021).IDs & samples.In this study, labeled annotations for initial super-vised training are needed for relevant performance comparisons withunsupervised UDA. Therefore, only its labeled data is used. A total of8670 images depicting 181 distinct individuals were extracted, for anaverage of 48 shots per identity. More details on image repartition canbe found inTable 1.Complexity.Despite an acquisition that spreads over one month, theillumination and viewpoint of the cows vary little between acquisitions.There is little to no occlusion in the images.4.1.2. HolsteinCattleRecognitionHolsteinCattleRecognitionBhole et al. (2019)is a dataset featuring RGB and infrared images of 1237 individuals. The data was acquiredby a pinhole camera placed at gound level, 5 m away from the milkingmachine itﬁlms. For concision, we refer to it as HolsteinCattle in therest of the paper.Image extraction.The images were extracted over nine days of ac-quisition. Each of them contains a single cow in the milking machine.For more details on data acquisition, please refer to Bhole et al. (2019). IDs & samples.In this study, only the RGB data is used. A total of1227 images depicting 136 distinct individuals were extracted, for anaverage of 9 shots per identity. More details on image repartition canbe found inTable 1.Complexity.This dataset features partially occluded cattle posi-tioned differently in the milking machine.4.1.3. CowFisheyeCowFisheye is a private dataset featuring RGB images of 78 individ-uals. It was acquired from a single farm from 4 ﬁsheye cameras pointing downwards, positioned 6 m above the ground. Identities were annotedmanually. This dataset reﬂects the usual challenging data encounteredin the use case where cows must be identi ﬁed 24/7 wherever they are in the farm.Image extraction.Images were extracted over 6 days of acquisition,during both day and night. A detector gives images containing thewhole cow body and head, aligned horizontally and facing right.IDs & samples.Manual selection and annotation of images weredone to ensure a good variability of viewpoints and lighting conditionsfor each cow. A total of 8709 images depicting 78 distinct individualswere extracted for an average of 112 instances per identity. More detailson images repartition can be found in Table 1andFig. 3. Complexity.The CowFisheye dataset complexity reﬂects the desired application: re-ID for 24/7 monitoring of cows in the whole camera net-work. More precisely, the low angle-shot camera con
ﬁguration required for coverage of the whole farm, may introduce signi ﬁcant cow occlusion by obstacles or other individuals. Distortions inherent to ﬁsheye cameras are also present. Besides, the acquisition is done in varied illu-mination conditions, which can cause signi ﬁcant discrepancies in the appearance of a cow. At night speciﬁcally, a near-infrared mode is activated resulting in black and white pictures. An illustration of thecomplexity of the CowFisheye dataset is proposed in Fig. 4.4.2. Experimental settings4.2.1. Use caseOur use case is speciﬁc to re-ID of animals in multiple farms, withlabeled images from one farm, and one or many unlabeled imagesfrom multiple farms. The objective of our CUMDA re-ID method pre-sented in Sec. 3 is twofold:
Fig. 2.Illustration of the content of each dataset. From left to right: Cows2021 Gao et al. (2021), HolsteinCattleRecognitionBhole et al. (2019), CowFisheye (private).Table 1Dataset statistics. For Cows2021 Gao et al. (2021)and HolsteinCattleBhole et al. (2019),
∗indicates that the dataset is extracted from the RGB annotated portion of the completedataset, following a 50/50 ID split for Train/Test. There is no overlap between train IDsand test IDs (cf. Sec. 4.2.6).Dataset # trainIDs# trainimages# testIDs# queryimages# galleryimagesCows2021
∗90 4602 91 855 3213HolsteinCattle
∗68 609 68 204 414CowFisheye 62 6334 16 151 2224F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
50•conservation on the source (labeled) domain;
•specialization on the target (unlabeled) domains.
We also expect better generalization on a new unseen target domain
which would correspond to a new farm in a real world application.
Therefore, for each training, performance on all three datasets is
reported. Throughout the experiments, we evaluate the different com-
ponents of our CUMDA method: source guidance (cf. Sec. 3.2), DSBN
(cf. Sec. 3.3) and HyPASS-SC (cf. Sec. 3.4). Please note that this work
does not aim at optimizing the network architecture or tuning
hyperparameters, it rather proposes an methodology for ef ﬁcient
CUMDA re-ID by pseudo-labeling.
4.2.2. Framework
In order to introduce some robustness to the pseudo-labels noise, we
use the state-of-the-art framework Mutual Mean Teaching (MMT) Ge
et al. (2019) paired with a Resnet-18 He et al. (2016) backbone
pretrained on ImageNet Deng et al. (2009) . The last stride of the
Resnet-18 is set to 1 to increase the feature map resolution. The
DBSCAN clustering algorithm is run on the k-reciprocal encoded fea-
tures with k30. DBSCAN parameters nminand epsare set to nmin
04a n d eps 06, their usual values Dubourvieux et al. (2021b) .T h e i r
values remain constant, except when epsis optimized by HyPASS-SC.
All other unspeci ﬁed values are set similarly to the original MMT
paper Ge et al. (2019) . The work conducted in this paper is however
not limited to MMT and could be applied to any UDA framework.
4.2.3. Data preprocessing
Per domain, mini-batches of size 16 are built with P= 4 identities
and K = 4 shots per identity. CUMDA batches may vary in size as they
are constructed from one mini-batch for the source dataset and onefor each target dataset, when applicable. Thus, their size depends on
ndomain , the number of domains used during training. Here, the batch
size is equal to 16 ndomain . Images are resized to 128 128 pixels.
Re-ID related data augmentations such as crop and ﬂip are applied dur-
ing the training stage. Random erasing was not applied because it ex-
perimentally decreased the cow re-ID performance.
4.2.4. Initial supervised pre-training
The network is trained during 20 epochs on each on the chosen
source dataset. The learning rate is set to lr35104. Both triplet
and cross-entropy losses are used during the training on source images
Ge et al. (2019) .
4.2.5. Domain adaptation
The network is trained during 15 epochs of 200 iterations. This
choice is driven to avoid over ﬁtting on the smaller datasets. The learn-
ing rate is set to lr35104. Both triplet and cross-entropy losses
are used during the training. Source and target share the same fully con-
nected layer for classi ﬁcation. When using MMT, testing is systemati-
cally done on model number 1 as in real-world applications since
determining which model performs best on the target is impossible. In-
deed, the target dataset is not annotated. Concerning the adaptation on
multiple target datasets, when applicable, DSBN is generalized so as to
have one Batch Normalization (BN) per domain. During testing, the
BN of the domain that is most similar in appearance to the tested do-
main is used. More speci ﬁcally, the test domain BN is used if it has
been computed during training. Otherwise, the BN of CowFisheye is
used when testing on Cows2021 or HolsteinCattle, and the BN of
Cows2021 is used when testing on CowFisheye.
Fig. 3. Number of images per ID in CowFisheye dataset.
Fig. 4. Illustration of the complexity of the CowFisheye dataset. Left: varied lighting conditions, Center: occlusion by objects/cows, Right: varied view points. All pictures represent the same
individual.F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
514.2.6. Testing
Because most datasets are extracted from a unique camera, the eval-
uation is done without ﬁltering images from the same camera. The
mean Average Precision (mAP) is reported as evaluation metric. It is
an indicator of the network ability to correctly recall the different
shots in a gallery corresponding to a query individual, and should be
maximized.
For completeness sake, rank-1 is also reported in Appendix A. It indi-
cates the accuracy of the rank-1 proposal for each query individual and
is representative of the retrieval performance. However, rank-1 is sensi-
tive to shortcomings in the dataset that are especially present in the
studied cattle re-id use case (low diversity of images, noise etc.). There-
fore, all in text analysis will be made on mAP as it is more robust and
representative of the performance on the whole dataset.
No re-ranking is applied during testing. The ID splitting for
Cows2021 and HolsteinCattle, is done following the original ascending
numbering. The ﬁrst half of the identities is taken as train set and the
other half as test set.
4.2.7. HyPASS-SC
HyPASS-SC optimizes the value of DBSCAN hyperparameter epsin
the range 0 35, 0 65, which is the range of acceptable values for
human datasets applications Dubourvieux et al. (2021b) . There is an
order of magnitude difference in number of shots per individual be-
tween HolsteinCattle (9) and other datasets (48 and 112). Therefore,
when dealing with HolsteinCattle as target or as source, HyPASS-SC
resp. computes a subsampled or oversampled source validation dataset
resp., so that the number of shots per identity in the source validation
set roughly matches the one of the target, as described in Sec. 3.4. Im-
pact on the performance of shots leveling will be shown in section 5.3.
Random subsampling Cows2021 or CowFisheye is straightforward,
while oversampling HolsteinCattle is done by applying the same data
augmentation than for training. Please note that the source data used
for training is not impacted by this step. In a real-world application,
the number of cows in a farm is known and the number of instances
per identity can be approximated by dividing the number of acquired
images by the estimated number of cows in the exploitation.
5. Results
All results presented below are derived from the experiments de-
tailed in Appendix A. Both mAP and rank-1 metrics are reported in
Tables A.11 - A.16 , however, only mAP related results are discussed
below cf. section 4.2.6.
5.1. Effectiveness of our CUMDA, single target
Supervised training & direct transfer. Supervised training results
can be found in Table 2 . These results, when training and testing on
the same dataset, give an idea of the complexity of each dataset. From
highest to lowest: CowFisheye, HolsteinCattle and Cows2021.
We also show the cross-domain performance of models supervised
on a source dataset and directly evaluated on the other datasets, with-
out adaptation. The low performance on these datasets demonstrates
the need for domain adaptation. In Table 2 , two cross-domainexperiments stand out. First, the direct transfer Cows2021
HolsteinCattle shows the poorest performance on the target domain at
8.0% mAP vs the 81.2% which can be attained if annotations were avail-
able. Second, the direct transfer CowFisheye Cows2021 shows the
highest performance of all cross-domain experiments, with 71.0% mAP
on the target dataset. These results indicate that the domain gap be-
tween farms greatly in ﬂuences the network ability to perform on a
new style of images and is higher between HolsteinCattle and the
other datasets than between CowFisheye and Cows2021. Also, the
abundance of information present in CowFisheye with its varied view-
points and occultations helps bridge the gap with other domains as
shown by higher direct transfer scores when pre-training on
CowFisheye.
UDA baseline. In the rest of the paper, we will refer to domain adap-
tation without source guidance as UDA. Its functioning is illustrated in
the upper part of Fig. 1 . We remind the reader that the MMT framework
has been chosen as baseline here Ge et al. (2019) and could be replaced
by any other baseline as shown in Dubourvieux et al. (2021b) and
Dubourvieux et al. (2022) .
As shown in Table 3 , the performance on the target dataset increases
withΔmAPvalues in the range [+1.7 p.p., +55.5 p.p.], meaning a lower
bound for performance variation of +1.7 percentage points (p.p.) and
an upper bound of +55.5 p.p.. This shows that the domain adaptation
is efﬁcient on the target dataset for all presented cases. However, the de-
crease seen in all diagonal elements of Table 3 , indicates that the source
dataset is partially forgotten by the network. This effect is drastic with
ΔmAPvalues in the range [ −61.6 p.p., −11.2 p.p.].
The generalization performance on an unseen dataset is inconsistent
and seems to evolve towards that of a supervised network that is super-
vised on the target dataset. For example, in the case CowFisheye
HolsteinCattle, the performance of the network on Cows2021 decreases
from 71.0% mAP (cf. Table 2 ) before UDA to 30.8% mAP after (cf.
Table 3 ). This performance ressembles the 29.1% mAP performance
seen for a network solely supervised on HolsteinCattle (cf. Table 2 ). In
conclusion, the UDA approach adapts the network to a single dataset,
without ensuring performance gains on any other dataset.
CUMDA. In the rest of the paper, we will refer to domain adaptation
with source guidance, DSBN and HyPASS-SC as CUMDA. Its functioning
is illustrated in the lower part of Fig. 1 . The results with CUMDA are re-
ported in Table 4 . The improvements over UDA (cf. Table 3 )a r em u l t i -
ple.
First, it outperforms the supervised network on source, target and a
third unseen domain in a consistent way. On the source domain, the
performance is equivalent or better, with a 96p . p .i n c r e a s ei nt e r m s
of mAP for CowFisheye. On the target domain, the performance increase
is drastic with an average ΔmAPof389p . p . , 165p . p .a n d 78p . p .o n
Cows2021, HolsteinCattle and CowFisheye when they are taken as tar-
get domains respectively. Generalization performance on the unseen
domain increases on average of 144 p.p., 27 p.p. and 30 p.p. on
the same datasets.
Second, on the target domain, our proposed CUMDA method
outperforms the UDA. To characterize this, we compute the increment
in performance between Tables 4 and 3 . On the source domain, the per-
formance increase is drastic with values as high as 81 1196 615
p.p. for the cross domain HolsteinCattle CowFisheye. On the target
Table 2
Performance (mAP in % and accuracy in % of the rank-1 closest element in the gallery) of models supervised on a single source dataset and direct transfer on each target dataset without
adaptation.
Train Test
Method Source Target Cows2021 HolsteinCattle CowFisheye
mAP rank-1 mAP rank-1 mAP rank-1
Supervised training Cows2021 None 95.3 98.2 8.0 13.7 16.8 45.7
Supervised training HolsteinCattle None 29.1 73.1 81.2 91.7 12.7 25.2
Supervised training CowFisheye None 71.0 95.1 13.6 24.5 50.5 75.5F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
52domain, the performance increases consistently with values between
+1.7 p.p. and + 15.9p.p.. Generalization performance on the unseen
domain increases with values between −0.7 p.p. and + 40.1 p.p..
All these results demonstrate the network ability to both remember
the source dataset and leverage information from all domains to
increase performance steadily on all domains. Our CUMDA method
therefore can ensure conservation on the source domain, better special-
ization on each seen domain and better generalization on unseen
domains.
5.2. Ablation study, single target
In section 5.1, we have demonstrated the performance gains
brought by our proposed CUMDA method over direct transfer and
UDA domain adaptation. In this section, the relative importance of all
components of our CUMDA method is investigated through an ablation
study. Averaged performance variations with respect to a network su-
pervised on source are reported in Tables 5 - 8 . The performance on
source, target and a third domain are computed following the protocol
presented in Appendix A.2. All results are derived from the experiments
detailed in Appendix A, Tables A.11 - A.16 . Please be reminded that the
components of our CUMDA method refer to the use of source-guidance,
DSBN and HyPASS-SC.
Source guidance. Averaged performance with source guidance is re-
ported in Table 6 . We compare these results to those of UDA, reported in
Table 5 .Providing the source as labeled data during training increases the
performance drastically on the source dataset. Compared to regular
UDA, the average performance increase is equal to 33 704 333
p.p., 581p . p .a n d 426 p.p. when considering Cows2021,
HolsteinCattle and CowFisheye as source respectively. However, the
performance on target dataset is approximately unchanged with an av-
erage delta in performance of 01 p.p., 09p . p .a n d 11 p.p.. The
model better generalizes thanks to the knowledge of both source and
target domains with an increase of 214 p.p., 23 p.p. and 55 p.p.
on Cows2021, HolsteinCattle and CowFisheye respectively.
In summary, compared to UDA, the source guidance allows the
model to perform similarly on the target while ensuring good conserva-
tion of the source. Bene ﬁting from the information of both source and
target, the model better generalizes to an unseen dataset.
DSBN. In this paper, alleviating the domain gap is achieved with the
use of DSBN. Averaged performance with source guidance + DSBN is re-
ported in Table 7 . We compare these results to those of the source
guided approach, reported in Table 6 .
When compared to source-guided UDA, there is signi ﬁcant perfor-
mance increase on the target of 40 2366 36p . p . , 40p . p .a n d
25 p.p. for Cows2021, HolsteinCattle and CowFisheye respectively.
However, performance on the source dataset slightly decreases with
deltas of 07 p.p., 18p . p .a n d 17 p.p.. Overall, the generalization
to an unseen dataset is unchanged.
In summary, in our experiments, DSBN does not seem to guarantee
better cow re-identi ﬁcation. However, we will see that it is useful by
allowing the use of HyPASS.Table 3
Performance of MMT Ge et al. (2019) . mAP (in %), ΔmAP(in p.p.) indicates the difference with initial supervised models (cf Table 2 ).
Train Test
Method Source Target Cows2021 HolsteinCattle CowFisheye
mAP ΔmAP mAP ΔmAP mAP ΔmAP
UDA Cows2021 HolsteinCattle 39.2 −56.1 12.6 +4.6 9.1 −7.7
UDA Cows2021 CowFisheye 84.1 −11.2 10.8 +2.8 24.3 +7.5
UDA HolsteinCattle Cows2021 84.6 +55.5 25.5 −55.7 16.0 +3.3
UDA HolsteinCattle CowFisheye 54.9 +25.8 19.6 −61.6 14.4 +1.7
UDA CowFisheye Cows2021 88.9 +17.9 8.5 −5.1 19.9 −30.6
UDA CowFisheye HolsteinCattle 30.8 −40.2 22.7 +9.1 14.3 −36.2
Table 4
Performance of our CUMDA method (source guidance, DSBN and HyPASS-SC). mAP (in %), ΔmAP(in p.p.) indicates the difference with initial supervised models (cf Table 2 ).
Train Test
Method Source Target Cows2021 HolsteinCattle CowFisheye
mAP ΔmAP mAP ΔmAP mAP ΔmAP
CUMDA Cows2021 HolsteinCattle 95.4 +0.1 15.9 +7.9 20.1 +3.3
CUMDA Cows2021 CowFisheye 95.0 −0.3 13.7 +5.7 28.2 +11.4
CUMDA HolsteinCattle Cows2021 87.2 +58.1 80.8 −0.4 15.3 +2.6
CUMDA HolsteinCattle CowFisheye 57.9 +28.8 81.1 −0.1 16.8 +4.1
CUMDA CowFisheye Cows2021 90.6 +19.6 13.3 −0.3 60.1 +9.6
CUMDA CowFisheye HolsteinCattle 70.9 −0.1 38.6 +25.0 60.1 +9.6
Table 5
Relative performance of UDA, compared to direct transfer. ΔmAP(in p.p.) indicates the dif-
ference of mAP (in %) with direct transfer (cf. Table 2 ).
Test
Cows2021 HolsteinCattle CowFisheye
Test set as ΔmAP ΔmAP ΔmAP
Source −33.7 −58.7 −33.4
Target +36.7 +6.9 +4.6
Unseen −7.2 −1.2 −2.2Table 6
Relative performance of source-guided UDA, compared to direct transfer. ΔmAP(in p.p.) in-
dicates the difference of mAP (in %) with direct transfer (cf. Table 2 ).
Test
Cows2021 HolsteinCattle CowFisheye
Test set as ΔmAP ΔmAP ΔmAP
Source −0.4 −0.6 +9.2
Target +36.6 +6.0 +5.7
Unseen +14.2 +1.1 +3.3F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
53HyPASS-SC.
The use of DSBN allows for source-guided selection of pseudo-
labeling hyperparameters, achieved here with HyPASS-SC. Averaged
performance of UDA with source guidance + DSBN + HyPASS-SC =
CUMDA is reported in Table 8 . We compare these results to those of
the source-guided + DSBN approach, reported in Table 7 .
In comparison with source-guided + DSBN UDA, the performance
on the target domain HolsteinCattle increases of 16 5100 65p.p.. This may be explained by the signi ﬁcant differences between
HolsteinCattle and other domains, which may result in a signi ﬁcant
shift of the optimal value of clustering parameters. On the Cows2021
dataset, HyPASS-SC seems to perform slightly worse than source-
guided + DSBN with a difference of 13 p.p.. This seems to indicate
that HyPASS-SC may not be optimal in all cases, especially when the
source test set has few images. However, HyPASS-SC retains its usage
by removing the need for user-set parameters. On the source domain,
the performance increases with deltas of 0103 04 p.p.,
21p . p .a n d 21 p.p.. It even exceeds the performance of source-
guided UDA (cf. Table 6 ). The generalization performance is increased
of14p . p . , 04p . p .a n d 05 p.p..
In conclusion, we ﬁnd that HyPASS-SC has a positive effect on perfor-
mance on all datasets. Indeed, it ensures good clustering on all targets.
This allows for better source conservation, target specialization and
generalization on an unseen dataset than the other approaches pre-
sented here.
For the cross-domain HolsteinCattle CowFisheye, a t-SNE visuali-
zation of the effects of domain adaptation, source-guidance and other
components of the CUMDA method on the embedding space, is pro-
posed in Fig. 5 . It shows: the decreased performance on source with
UDA, the increased performance on all datasets with source guidance
and the best performances obtained by combining all the components
of our CUMDA method.
CUMDA re-ID with multiple-targets (CowFisheye and Cows2021) is
also illustrated with clear gains on all three datasets. Quantitative
evaluations are presented in Sec. 5.4.
5.3. Bene ﬁt of the source calibration in HyPASS-SC
As explained in section 3.4, HyPASS is sensitive to dataset statistics.
More speci ﬁcally, in our case, to the number of shots per identity of
Cows2021 (48), HolsteinCattle (9) and CowFisheye (112).Table 7
Relative performance of source-guided + DSBN UDA, compared to direct transfer. ΔmAP
(in p.p.) indicates the difference of mAP (in %) with direct transfer (cf. Table 2 ).
Test
Cows2021 HolsteinCattle CowFisheye
Test set as ΔmAP ΔmAP ΔmAP
Source +0.3 −2.4 +7.5
Target +40.2 +10.0 +8.2
Unseen +13.0 +3.1 +2.5
Table 8
Relative performance of our single target CUMDA, compared to direct transfer. ΔmAP(in p.
p.) indicates the difference of mAP (in %) with direct transfer (cf. Table 2 ).
Test
Cows2021 HolsteinCattle CowFisheye
Test set as ΔmAP ΔmAP ΔmAP
Source −0.1 −0.3 +9.6
Target +38.9 +16.5 +7.8
Unseen +14.4 +2.7 +3.0
Fig. 5. Evolution of the embedding space on all validation datasets for the cross-domain HolsteinCattle CowFisheye. Visualization with t-SNE where each identity is assigned a random
color and size. Each point represents an image in the embedding space. Each row corresponds to a dataset. Each column corresponds to a method. Acronyms .UDA: UDA baseline with
MMT; s.g.: source guided; CUMDA : Cumulative Unsupervised Multi-Domain Adaptation; s.t.:s i n g l e - t a r g e t ; m.t.: multi-target (with Cows2021). Ideally, points of the same colors should
be clustered and well separated from all other clusters. Corresponding ranking visualization is available in Fig. A.7 in the appendix. Best viewed in color.F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
54To validate the importance of our proposed source validation set cal-
ibration, we compare the performance of HyPASS-SC and HyPASS on the
cross domains HolsteinCattle Cows2021 (oversampling use-case) and
CowFisheye HolsteinCattle (subsampling use-case).
The quality of the clustering is evaluated with the Adjusted Random
Index (ARI) which is a measure of the similarity between two data clus-
terings. It is computed between the target training set labels and the
cluster predictions, using the scikit-learn implementation2.Fig. 6 illus-
trates the evolution of ARI when leveling the source and target statistics.
Higher values of ARI indicate a better clustering. Performance is com-
pared at the 3000thiteration.
In the cross-domain HolsteinCattle Cows2021, an oversampling of
HolsteinCattle from 9 shots/ID to around 90 shots/ID is carried out. As a
result, the ARI doubles, increasing from 0.40 without calibration, to 0.83
with it. In terms of mAP, the performance on the target Cows2021 in-
creases from 77.4% without calibration, to 87.2% with it.
In the cross-domain CowFisheye HolsteinCattle, a subsampling of
CowFisheye from 112 shots/ID to around 9 shots/ID is carried out. The
resulting ARI increase is substantial, evolving from 0.03 without calibra-
tion, to 0.23 with it. In terms of mAP, the performance on the target
HolsteinCattle increases from 29.3% without calibration, to 38.6% with it.
These results show the importance of source validation set calibra-
tion in the case of datasets with highly different number of shots per
ID, which can be a recurrent issue when dealing with animal datasets.
We kindly remind the reader that the calibration of the source has
been systematically applied on all aforementioned experiments.
5.4. Effectiveness of our CUMDA, multiple targets
One of our goals is to generalize the domain adaptation to multiple
target domains. This use-case re ﬂects real-world needs where, from a
labeled dataset, the model should be adapted to multiple farming ex-
ploitations. Averaged performance of our CUMDA approach (source
guidance, DSBN and HyPASS-SC) is reported in Table 10 .I ti sc o m p u t e d
from the detailed results that can be found in Tables A.11 - A.16 of
Appendix A. We compare these results to those of the source-guided
approach, reported in Table 9 .
On the target datasets, our approach outperforms the source-guided
UDA approach with ΔmAPof28p . p . , 60p . p .a n d 37p . p .f o r
Cows2021, HolsteinCattle and CowFisheye respectively. Besides, theperformance on the source dataset is conserved. This demonstrates
the importance of the proposed CUMDA method when it comes to mul-
tiple datasets application. This performance increase can be explained
by the complementarity of DSBN and HyPASS-SC.
DSBN allows some domain gap alleviation through domain speci ﬁc
normalization. It also authorizes domains to share the same backbone,
which helps generalization. HyPASS-SC provides optimized clustering
parameters on each target dataset, depending on its statistics. This en-
sures good clustering quality on the target domains, which in turn in-
creases the network performance on all datasets.
5.5. Limitations
In this paper, we have shown signi ﬁcant improvements on unsuper-
vised domain adaptation performance when compared with traditional
pseudo-labelling-based UDA methods. However, it can be seen that the
performance on a domain when it is unlabeled, taken as a target, re-
mains far from the performance on the same domain when it is labeled,
taken as a source.
This is a peculiarity of the cow re-ID problem. Indeed, color
information usually facilitates the pseudo-labeling in human re-ID and
the performance of unsupervised UDA is close to the performance of su-
pervised training Ge et al. (2019) .F o rc o wr e - I D ,c o l o rd o e sn o tc o n t a i n
relevant information for pseudo-labeling. Therefore, subtle information
such as shape has to be considered instead. Also, in this paper and cow
re-ID in general, the domain gap existing between the chosen datasets
can be greater than the one usually seen in person re-ID.
In other words, even if the pseudo-labelling hyperparameters are
automatically optimized, the proposed solution is still limited by the
pseudo-labelling strategy itself. Namely, pseudo-labels quality depend
on the the chosen clustering algorithm, and the networks ability to
extract discriminative representations. Detailed discussion on the
inﬂuence of pseudo-labelling methods on UDA can be found in
Dubourvieux et al. (2021b) .Fig. 6. Evolution of the Adjusted Random Index (ARI) of target clustering. In ﬂuence of the calibration of source validation set on HyPASS performances. In blue and dashed lines
HolsteinCattle Cows2021, in red, CowFisheye HolsteinCattle. Acronyms. h.p.: HyPASS Dubourvieux et al. (2021b) ;inst. Red. :s o u r c ei n s t a n c er e d u c t i o n ; inst. Aug. : source instance
augmentation. (For interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this article.)
Table 9
Relative performance of source-guided + multi-target UDA, compared to direct transfer.
ΔmAP(in p.p.) indicates the difference of mAP (in %) with direct transfer (cf. Table 2 ).
Test
Cows2021 HolsteinCattle CowFisheye
Test set as ΔmAP ΔmAP ΔmAP
Source −0.3 −1.5 +10.5
Target +36.0 +7.4 +3.82https://scikit-learn.org/ .F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
556. Conclusion
In this paper, we have proposed a new CUMDA re-ID method for ef-
ﬁcient cumulative multi-domain adaptation motivated by practical cat-
tle re-ID constraints and requirements. This work re ﬂects real-world
application needs for a model to perform better on all domains as the
number of farms increase but annotation on them is not necessarily
available. Indeed, it extends domain adaptation to multiple target
domains, with high discrepancies in both target datasets statistics and
domain representations, which are challenges often encountered in
practical applications. The proposed CUMDA method consists in: source
guidance, domain gap reduction and an automatic source-guided
hyperparameter selection for clustering based on HyPASS. A source cal-
ibration method to increase HyPASS performance on datasets of great
diversity, usually encountered in farming applications, has indeed
been proposed. We have compared our solution to direct transfer, do-
main adaptation and source-guided domain adaptation. Results show
signiﬁcant performance improvements with better source conservation,target specialization and generalization on unseen domains when com-
pared with classical pseudo-labelling-based UDA methods.
CRediT authorship contribution statement
Fabian Dubourvieux: Conceptualization, Methodology, Software,
Validation, Formal analysis, Investigation, Writing –original draft, Visu-
alization. Guillaume Lapouge : Conceptualization, Methodology, Soft-
ware, Validation, Formal analysis, Investigation, Writing –original
draft, Visualization. Angélique Loesch :W r i t i n g –review & editing.
Bertrand Luvison :W r i t i n g –review & editing. Romaric Audigier :
Writing –review & editing.
Declaration of Competing Interest
The authors declare that they have no known competing ﬁnancial
interests or personal relationships that could have appeared to in ﬂu-
ence the work reported in this paper.
Acknowledgments
Partial ﬁnancial support was received from the AIHerd companyb.
This publication was made possible by the use of the FactoryIA
supercomputer, ﬁnancially supported by the Ile-de-France Regional
Council.
The CowFisheye dataset was kindly provided by the AIHerd
companyb.
Ablation study detail
Appendix A.1. Visualization of predictions
A visualization of the ranking proposed by the re-identi ﬁcation network is proposed in Fig.A.7 . The chosen scenario is the HolsteinCattle
CowFisheye unsupervised domain adaptation, also represented in the embedding space in Fig. 5 .
Appendix A.2. Performance computation detailed
In this paper, Tables 5 - 8 exhibit the variation in performance of the network, for each ablation step. The ΔmAPis computed from detailed results in
Tables A.11 –A.16 under the following protocol. Let us consider a set of n domains 1,…,n, and let us test on the domain i,i∈1, ,n.
If iis tested as a source, the performance for all cross-domain experiments i k,k∈1, ,n∖i, is compared to the network supervised on
i. The result is then averaged.
If iis tested as a target, the performance for all cross-domain experiments k i,k∈1, ,n∖i, is compared to the network supervised on
k. The result is then averaged.
If iis tested as an unseen dataset, the performance for all cross-domain experiments k m,k,m∈1, ,n∖iwith k≠m,i sc o m p a r e dt ot h e
networked supervised on k. The result is then averaged.
For the sake of clarity, let us detail the computation of the ﬁrst line and ﬁrst column of Table 5 : testing UDA (MMT) on Cows2021 as a source dataset.
UDA mAP on Cows2021 as a source is equal to 84.1% and 39.2%, for the cross domains Cows2021 CowFisheye (cf. Table A.12 ) and Cows2021
HolsteinCattle (cf. Table A.14 ) respectively. A supervised network on Cows2021 has a mAP of 95.3% on Cows2021 (cf. Table 2 ). Therefore, the
ΔmAPis equal to 84 1953 3929532 337p . p . .
Appendix A.3. All results
Detailed experimental results are reported in Tables A.11-A.16 . Each line corresponds to a different method, +/indicates that an element is added/
removed from the line immediately above.
Table A.11
Effects of different domain adaptation strategies on re-ID performances, for cross-domain CowFisheye HolsteinCattle. ΔmAP(in p.p.) indicates the difference of mAP (in %) with direct
transfer. Rank-1 (in %) is also reported.
Train Test
Method Source Target Cows2021 HolsteinCattle CowFisheye
mAP ΔmAP rank-1 mAP ΔmAP rank-1 mAP ΔmAP rank-1
direct transfer CowFisheye None 71.0 0 95.1 13.6 0 24.5 50.5 0 75.5
UDA CowFisheye HolsteinCattle 30.8 −40.2 72.6 22.7 +9.1 38.2 14.3 −36.2 31.1
+ source guided CowFisheye HolsteinCattle 71.5 +0.5 93.9 25.6 +12.0 41.7 59.6 +9.1 86.1
+ DSBN CowFisheye HolsteinCattle 72.3 +1.3 94.5 26.8 +13.2 42.2 55.4 +4.9 82.1
+ HyPASS-SC CowFisheye HolsteinCattle 70.9 −0.1 94.4 38.6 +25.0 61.8 60.1 +9.6 84.1
+ multi-target CowFisheye HolsteinCattle 90.8 +19.8 98.2 34.5 +20.9 54.9 60.9 +10.4 85.4
Cows2021
HyPASS-SC DSBN CowFisheye HolsteinCattle 89.2 +18.2 97.8 25.3 +11.7 44.1 61.0 +10.5 84.8
Cows2021Table 10
Relative performance of our CUMDA method, compared to direct transfer. ΔmAP(in p.p.)
indicates the difference of mAP (in %) with direct transfer (cf. Table 2 ).
Test
Cows2021 HolsteinCattle CowFisheye
Test set as ΔmAP ΔmAP ΔmAP
Source 0.0 −0.9 +10.4
Target +38.8 +13.4 +7.5
bhttps://www.aiherd.io .F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
56Fig. A.7. Visualization of the ranking performance on all validation datasets for the cross-domain HolsteinCattle CowFisheye. For each query, the top 9 results in the gallery are plotted
from left to right. Pictures framed in green are correct results, and in red, incorrect ones. The animal identity is plotted on top of each image. Each li ne corresponds to a use-case. Acronyms.
UDA:U D Aw i t hM M T ; s.g.: source guided; CUMDA : Cumulative Unsupervised Multi-Domain Adaptation; s.t.: single-target; m.t.: multi-target (with Cows2021). Best viewed in color. (For
interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this article.)F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
57Table A.12
Effects of different domain adaptation strategies on re-ID performances, for cross-domain Cows2021 CowFisheye. ΔmAP(in p.p.) indicates the difference of mAP (in %) with direct trans-
fer. Rank-1 (in %) is also reported.
Train Test
Method Source Target Cows2021 HolsteinCattle CowFisheye
mAP ΔmAP rank-1 mAP ΔmAP rank-1 mAP ΔmAP rank-1
direct transfer Cows2021 None 95.3 0 98.2 8.0 0 13.7 16.8 0 45.7
UDA Cows2021 CowFisheye 84.1 −11.2 97.0 10.8 +2.8 15.7 24.3 +7.5 59.6
+ source guided Cows2021 CowFisheye 94.9 −0.4 98.6 10.5 +2.5 17.2 26.0 +9.2 60.9
+ DSBN Cows2021 CowFisheye 95.1 −0.2 98.5 15.1 +7.1 21.1 30.5 +13.7 67.5
+ HyPASS-SC Cows2021 CowFisheye 95.0 −0.3 98.4 13.7 +5.7 23.5 28.2 +11.4 64.9
+ multi-target Cows2021 CowFisheye 95.3 0.0 98.5 13.8 +5.8 24.0 27.2 +10.4 66.2
HolsteinCattle
HyPASS-SC DSBN Cows2021 CowFisheye 95.0 −0.3 98.4 11.1 +3.1 17.6 22.3 +5.5 57.0
HolsteinCattle
Table A.13
Effects of different domain adaptation strategies on re-ID performances, for cross-domain HolsteinCattle CowFisheye. ΔmAP(in p.p.) indicates the difference of mAP (in %) with direct
transfer. Rank-1 (in %) is also reported.
Train Test
Method Source Target Cows2021 HolsteinCattle CowFisheye
mAP ΔmAP rank-1 mAP ΔmAP rank-1 mAP ΔmAP rank-1
direct transfer HolsteinCattle None 29.1 0 73.1 81.2 0 91.7 12.7 0 25.2
UDA HolsteinCattle CowFisheye 54.9 +25.8 90.6 19.6 −61.6 31.9 14.4 +1.7 37.7
+ source guided HolsteinCattle CowFisheye 57.0 +27.9 90.5 81.7 +0.5 92.6 14.8 +2.1 39.1
+ DSBN HolsteinCattle CowFisheye 53.8 +24.7 87.6 78.9 −2.3 89.2 15.4 +2.7 46.4
+ HyPASS-SC HolsteinCattle CowFisheye 57.9 +28.8 90.8 81.1 −0.1 92.2 16.8 +4.1 47.0
+ multi-target HolsteinCattle CowFisheye 86.8 +57.7 97.2 80.3 −0.9 90.7 17.2 +4.5 55.6
Cows2021
HyPASS-SC DSBN HolsteinCattle CowFisheye 82.8 +53.7 96.6 79.7 −1.5 90.7 14.7 +2.0 43.0
Cows2021
Table A.14
Effects of different domain adaptation strategies on re-ID performances, for cross-domain Cows2021 HolsteinCattle. ΔmAP(in p.p.) indicates the difference of mAP (in %) with direct
transfer. Rank-1 (in %) is also reported.
Train Test
Method Source Target Cows2021 HolsteinCattle CowFisheye
mAP ΔmAP rank-1 mAP ΔmAP rank-1 mAP ΔmAP rank-1
direct transfer Cows2021 None 95.3 0 98.2 8.0 0 13.7 16.8 0 45.7
UDA Cows2021 HolsteinCattle 39.2 −56.1 81.5 12.6 +4.6 24.0 9.1 −7.7 12.6
+ source guided Cows2021 HolsteinCattle 94.8 −0.5 98.1 7.9 −0.1 18.6 18.9 +2.1 53.0
+ DSBN Cows2021 HolsteinCattle 96.0 +0.7 98.4 14.7 +6.7 26.0 19.3 +2.5 51.7
+ HyPASS-SC Cows2021 HolsteinCattle 95.4 +0.1 98.6 15.9 +7.9 26.5 20.1 +3.3 55.6
+ multi-target Cows2021 CowFisheye 95.3 0.0 98.5 13.8 +5.8 24.0 27.2 +10.4 66.2
HolsteinCattle
HyPASS-SC DSBN Cows2021 CowFisheye 95.0 −0.3 98.4 11.1 +3.1 17.6 22.3 +5.5 57.0
HolsteinCattle
Table A.15
Effects of different domain adaptation strategies on re-ID performances, for cross-domain CowFisheye Cows2021. ΔmAP(in p.p.) indicates the difference of mAP (in %) with direct trans-
fer. Rank-1 (in %) is also reported.
Train Test
Method Source Target Cows2021 HolsteinCattle CowFisheye
mAP ΔmAP rank-1 mAP ΔmAP rank-1 mAP ΔmAP rank-1
direct transfer CowFisheye None 71.0 0 95.1 13.6 0 24.5 50.5 0 75.5
UDA CowFisheye Cows2021 88.9 +17.9 97.8 8.5 −5.1 14.2 19.9 −30.6 52.3
+ source guided CowFisheye Cows2021 89.9 +18.9 97.8 13.2 −0.4 23.5 59.8 +9.3 82.1
+ DSBN CowFisheye Cows2021 91.5 +20.5 98.4 12.7 −0.9 22.1 60.6 +10.1 88.1
+ HyPASS-SC CowFisheye Cows2021 90.6 +19.6 98.0 13.3 −0.3 21.1 60.1 +9.6 88.1
+ multi-target CowFisheye HolsteinCattle 90.8 +19.8 98.2 34.5 +20.9 54.9 60.9 +10.4 85.4
Cows2021
HyPASS-SC DSBN CowFisheye HolsteinCattle 89.2 +18.2 97.8 25.3 +11.7 44.1 61.0 +10.5 84.8
Cows2021F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
58Table A.16
Effects of different domain adaptation strategies on re-ID performances, for cross-domain HolsteinCattle Cows2021. ΔmAP(in p.p.) indicates the difference of mAP (in %) with direct
transfer. Rank-1 (in %) is also reported.
Train Test
Method Source Target Cows2021 HolsteinCattle CowFisheye
mAP ΔmAP rank-1 mAP ΔmAP rank-1 mAP ΔmAP rank-1
direct transfer HolsteinCattle None 29.1 0 73.1 81.2 0 91.7 12.7 0 25.2
UDA HolsteinCattle Cows2021 84.6 +55.5 96.1 25.5 −55.7 37.3 16.0 +3.3 52.3
+ source guided HolsteinCattle Cows2021 83.4 +54.3 97.1 79.4 −1.8 89.2 17.1 +4.4 49.0
+ DSBN HolsteinCattle Cows2021 89.0 +59.9 98.4 78.8 −2.4 87.3 15.2 +2.5 47.7
+ HyPASS-SC HolsteinCattle Cows2021 87.2 +58.1 97.3 80.8 −0.4 90.7 15.3 +2.6 49.0
+ multi-target HolsteinCattle CowFisheye 86.8 +57.7 97.2 80.3 −0.9 90.7 17.2 +4.5 55.6
Cows2021
HyPASS-SC DSBN HolsteinCattle CowFisheye 82.8 +53.7 96.6 79.7 −1.5 90.7 14.7 +2.0 43.0
Cows2021
References
Andrew, W., Hannuna, S., Campbell, N., Burghardt, T., 2016. Automatic individual Holstein
friesian cattle identi ﬁcation via selective local coat pattern matching in rgb-d imag-
ery. IEEE Proc. Int. Conf. Image. Proc. 484 –488.
Andrew, W., Greatwood, C., Burghardt, T., 2017. Visual localisation and individual identi-
ﬁcation of Holstein friesian cattle via deep learning. Proc. IEEE Int. Conf. Comput. Vis.
Workshop, pp. 2850 –2859.
Andrew, W., Gao, J., Mullan, S., Campbell, N., Dowsey, A.W., Burghardt, T., 2021. Visual
identi ﬁcation of individual Holstein-friesian cattle via deep metric learning. Comput.
Electron. Agric. 185, 106133.
Bak, S., Carr, P., Lalonde, J.F., 2018. Domain adaptation through synthesis for unsupervised
person re-identi ﬁcation. Comput. Vis. ECCV 189 –205.
Bergamini, L., Porrello, A., Dondona, A.C., Del Negro, E., Mattioli, M., D ’alterio, N., Calderara,
S., 2018. Multi-views embedding for cattle re-identi ﬁcation. IEEE International Con-
ference on Signal-Image Technology & Internet-Based Systems, pp. 184 –191.
Bhole, A., Falzon, O., Biehl, M., Azzopardi, G., 2019. A computer vision pipeline that uses
thermal and rgb images for the recognition of Holstein cattle. Computer Analysis of
Images and Patterns. 11679, 108 –119.
Chang, W.G., You, T., Seo, S., Kwak, S., Han, B., 2019a. Domain-speci ﬁc batch normalization
for unsupervised domain adaptation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pat-
tern Recognit, pp. 7354 –7362.
Chang, X., Yang, Y., Xiang, T., Hospedales, T.M., 2019b. Disjoint label space transfer learn-
ing with common factorised space. Proc. AAAI Conf. Artif. Intell.
Chen, Y., Zhu, X., Gong, S., 2019. Instance-guided context rendering for cross-domain per-
son re-identi ﬁcation. Proc. IEEE Int. Conf. Comput. Vis, pp. 232 –242.
Chen, G., Lu, Y., Lu, J., Zhou, J., 2020. Deep credible metric learning for unsupervised do-
main adaptation person re-identi ﬁcation. Comput. Vis. ECCV 643 –659.
Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., 2009. Imagenet: a large-scale hierar-
chical image database. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.,
pp. 248 –255
Deng, W., Zheng, L., Ye, Q., Kang, G., Yang, Y., Jiao, J., 2018. Image-image domain adapta-
tion with preserved self-similarity and domain-dissimilarity for person re-
identi ﬁcation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit,
pp. 994 –1003.
Dubourvieux, F., Audigier, R., Loesch, A., Ainouz, S., Canu, S., 2021a. a. Unsupervised do-
main adaptation for person re-identi ﬁcation through source-guided pseudo-
labeling. IEEE proc. Int. Conf. Pattern Recogn, pp. 4957 –4964.
Dubourvieux, F., Loesch, A., Audigier, R., Ainouz, S., Canu, S., 2021b. b. Improving unsuper-
vised domain adaptive re-identi ﬁcation via source-gided selection of pseudo-labeling
hyperparameters. IEEE Access 9, 149780 –149795.
Dubourvieux, F., Audigier, R., Loesch, A., Ainouz, S., Canu, S., 2022. Af o r m a la p p r o a c ht o
good practices in pseudo-labeling for unsupervised domain adaptive re-
identi ﬁcation. Comput. Vis. Image Underst. 223, 103527.
Fu, Y., Wei, Y., Wang, G., Zhou, Y., Shi, H., Huang, T.S., 2019. Self-similarity grouping: a sim-
ple unsupervised cross domain adaptation approach for person re-identi ﬁcation.
Proc. IEEE Int. Conf. Comput. Vis. 6112 –6121.
Gao, J., Burghardt, T., Andrew, W., Dowsey, A.W., Campbell, N.W., 2021. Towards self-
supervision for video identi ﬁcation of individual holstein-friesian cattle: the
Cows2021 dataset. arXiv preprint arXiv:2105.01938.
Ge, Y., Chen, D., Li, H., 2019. Mutual mean-teaching: pseudo label re ﬁnery for unsuper-
vised domain adaptation on person re-identi ﬁcation. International Conference on
Learning Representations.
Ge, Y., Zhu, F., Chen, D., Zhao, R., Li, H., 2020. Self-paced contrastive learning with hybrid
memory for domain adaptive object re-id, in: Adv. Neural. Inf. Process. Syst, pp.
11309 –11321.
He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. Proc.
IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 770 –778.
Hermans, A., Beyer, L., Leibe, B., 2017. In defense of the triplet loss for person re-
identi ﬁcation. arXiv preprint. arXiv:1703.07737 .Huang, Y., Wu, Q., Xu, J., Zhong, Y., 2019. Sbsgan: suppression of inter-domain background
shift for person re-identi ﬁcation. Proc. IEEE Int. Conf. Comput. Vis. 9527 –9536.
Ioffe, S., Szegedy, C., 2015. Batch normalization: accelerating deep network training by re-
ducing internal covariate shift. Proc. Int. Conf. Mach. Learn. 448 –456.
Jin, X., Lan, C., Zeng, W., Chen, Z., 2020. Global distance-distributions separation for unsu-
pervised person re-identi ﬁcation. Comput. Vis. ECCV 735 –751.
Khan, S.D., Ullah, H., 2019. A survey of advances in vision-based vehicle re-identi ﬁcation.
Comput. Vis. Image Underst. 182, 50 –63.
Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet classi ﬁcation with deep
convolutional neural networks. Adv. Neural Inf. Proces. Syst. 25.
Li, Y.J., Yang, F.E., Liu, Y.C., Yeh, Y.Y., Du, X., Frank Wang, Y.C., 2018. Adaptation and re-
identi ﬁcation network: an unsupervised deep transfer learning approach to person
re-identi ﬁcation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Work-
shops, pp. 172 –178.
Li, S., Li, J., Tang, H., Qian, R., Lin, W., 2019a. Atrw: a benchmark for amur tiger re-
identi ﬁcation in the wild. arXiv preprint. arXiv:1906.05586 .
Li, Y.J., Lin, C.S., Lin, Y.B., Wang, Y.C.F., 2019b. Cross-dataset person re-identi ﬁcation via
unsupervised pose disentanglement and adaptation. Proc. IEEE Int. Conf. Comput.
Vis. 7919 –7929.
Lin, S., Li, H., Li, C.T., Kot, A.C., 2018. Multi-task mid-level feature alignment network for
unsupervised cross-dataset person re-identi ﬁcation, in: 29th British Machine Vision
Conference, BMVC 2018.
Liu, C., Zhang, R., Guo, L., 2019a. Part-pose guided amur tiger re-identi ﬁcation. IEEE/CVF
International Conference on Computer Vision Workshops.
Liu, J., Zha, Z.J., Chen, D., Hong, R., Wang, M., 2019b. Adaptive transfer network for cross-
domain person re-identi ﬁcation. proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern
Recognit, pp. 7202 –7211.
Liu, J., Zha, Z.J., Chen, D., Hong, R., Wang, M., 2019c. Adaptive transfer network for cross-
domain person re-identi ﬁcation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern
Recognit, pp. 7202 –7211.
Liu, N., Zhao, Q., Zhang, N., Cheng, X., Zhu, J., 2019d. Pose-guided complementary features
learning for amur tiger re-identi ﬁcation. IEEE/CVF international conference on com-
puter vision workshops.
Luo, H., Gu, Y., Liao, X., Lai, S., Jiang, W., 2019. Bag of tricks and a strong baseline for deep
person re-identi ﬁcation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit
Workshops.
Luo, C., Song, C., Zhang, Z., 2020. Generalizing person re-identi ﬁcation by camera-aware
invariance learning and cross-domain mixup. Comput. Vis. ECCV 224 –241.
Peng, J., Wang, Y., Wang, H., Zhang, Z., Fu, X., Wang, M., 2020. Unsupervised vehicle re-
identi ﬁcation with progressive adaptation. arXiv preprint. arXiv:2006.11486 .
Qi, L., Wang, L., Huo, J., Zhou, L., Shi, Y., Gao, Y., 2019. A novel unsupervised camera-aware
domain adaptation framework for person re-identi ﬁcation. Proc. IEEE Int. Conf.
Comput. Vis, pp. 8080 –8089.
Ristani, E., Solera, F., Zou, R., Cucchiara, R., Tomasi, C., 2016. Performance measures and a
data set for multi-target, multi-camera tracking. Comput. Vis. ECCV.
Schneider, S., Taylor, G.W., Kremer, S.C., 2020. Similarity learning networks for animal in-
dividual re-identi ﬁcation-beyond the capabilities of a human observer. IEEE Winter
Conf. Appl. Comput. Vis. Workshops, pp. 44 –52.
Song, L., Wang, C., Zhang, L., Du, B., Zhang, Q., Huang, C., Wang, X., 2020. Unsupervised do-
main adaptive re-identi ﬁcation: theory and practice. Pattern Recogn. 102, 107173.
Sun, X., Zheng, L., 2019. Dissecting person re-identi ﬁcation from the viewpoint of view-
point. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 608 –617.
Tang, H., Zhao, Y., Lu, H., 2019. Unsupervised person re-identi ﬁcation with iterative self-
supervised domain adaptation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern
Recognit. Workshops.
Wang, J., Zhu, X., Gong, S., Li, W., 2018. Transferable joint attribute-identity deep learning
for unsupervised person re-identi ﬁcation. Proc. IEEE Comput. Soc. Conf. Comput. Vis.
Pattern Recognit, pp. 2275 –2284.
Wang, J., Lan, C., Liu, C., Ouyang, Y., Qin, T., 2021. Generalizing to unseen domains: a sur-
vey on domain generalization. Inte Joint Conf on Artif Intell 4627 –4635.F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
59Wei, L., Zhang, S., Gao, W., Tian, Q., 2018a. Person transfer Gan to bridge domain gap for person re-identiﬁcation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit,pp. 79–88.Wei, L., Zhang, S., Gao, W., Tian, Q., 2018b. Person transfer Gan to bridge domain gap for person re-identiﬁcation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit,pp. 79–88.Ye, M., Shen, J., Lin, G., Xiang, T., Shao, L., Hoi, S.C., 2021. Deep learning for person re- identiﬁcation: a survey and outlook. IEEE Trans. Pattern Anal. Mach. Intell. 44,2872–2893.Yu, H.X., Zheng, W.S., Wu, A., Guo, X., Gong, S., Lai, J.H., 2019. Unsupervised person re- identiﬁcation by soft multilabel learning. Proc. IEEE Comput. Soc. Conf. Comput. Vis.Pattern Recognit, pp. 2148–2157. Zajkac, M., Zolna, K., Jastrzkebski, S., 2019. Split batch normalization: improving semi-supervised learning under domain shift. arXiv preprint. arXiv:1904.03515. Zhai, Y., Lu, S., Ye, Q., Shan, X., Chen, J., Ji, R., Tian, Y., 2020a. Ad-cluster: augmented dis- criminative clustering for domain adaptive person re-identi ﬁcation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 9021 –9030. Zhai, Y., Ye, Q., Lu, S., Jia, M., Ji, R., Tian, Y., 2020b. Multiple expert brainstorming for do- main adaptive person re-identiﬁcation. Comput. Vis. ECCV 594 –611.Zhang, X., Cao, J., Shen, C., You, M., 2019. Self-training with progressive augmentation for unsupervised cross-domain person re-identi ﬁcation. Proc. IEEE Int. Conf. Comput. Vis. 8222–8231.Zhao, F., Liao, S., Xie, G.S., Zhao, J., Zhang, K., Shao, L., 2020. Unsupervised domain adapta- tion with noise resistible mutual-training for person re-identi ﬁcation. Comput. Vis. ECCV 526–544.Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., Tian, Q., 2015. Scalable person re- identiﬁcation: A benchmark. Proc. IEEE Int. Conf. Comput. Vis.Zheng, L., Yang, Y., Hauptmann, A.G., 2016. Person re-identi ﬁcation: past, present and fu- ture. arXiv preprint.arXiv:1610.02984. Zhong, Z., Zheng, L., Li, S., Yang, Y., 2018. Generalizing a person retrieval model hetero-and homogeneously. Comput. Vis. ECCV 172 –188. Zhong, Z., Zheng, L., Luo, Z., Li, S., Yang, Y., 2019. Invariance matters: exemplar memory for domain adaptive person re-identi ﬁcation. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 598–607. Zhu, J.Y., Park, T., Isola, P., Efros, A.A., 2017. Unpaired image-to-image translation using cycle-consistent adversarial networks. Proc. IEEE Int. Conf. Comput. Vis. 2223 –2232. Zou, Y., Yang, X., Yu, Z., Kumar, B.V., Kautz, J., 2020. Joint disentangling and adaptation for cross-domain person re-identiﬁcation. Comput. Vis. ECCV 87
–104.F. Dubourvieux, G. Lapouge, A. Loesch et al. Artiﬁcial Intelligence in Agriculture 10 (2023) 46 –60
60