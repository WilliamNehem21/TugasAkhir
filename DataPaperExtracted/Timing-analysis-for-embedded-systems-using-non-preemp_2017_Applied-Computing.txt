ORIGINAL ARTICLE
Timing analysis for embedded systems usingnon-preemptive EDF scheduling under boundederror arrivals
Michael Short
School of Science and Engineering, Teesside University, Middlesbrough TS1 3BA, UKReceived 8 June 2016; revised 22 July 2016; accepted 28 July 2016Available online 4 August 2016
KEYWORDSReal-time and embeddedsystems;Timing analysis;Non-preemptive scheduling;Transient error protection;Fault-toleranceAbstractEmbedded systems consist of one or more processing units which are completely encap-sulated by the devices under their control, and they often have stringent timing constraints associ-ated with their functional speciﬁcation. Previous research has considered the performance ofdifferent types of task scheduling algorithm and developed associated timing analysis techniquesfor such systems. Although preemptive scheduling techniques have traditionally been favored, rapidincreases in processor speeds combined with improved insights into the behavior of non-preemptivescheduling techniques have seen an increased interest in their use for real-time applications such asmultimedia, automation and control. However when non-preemptive scheduling techniques areemployed there is a potential lack of error conﬁnement should any timing errors occur in individualsoftware tasks. In this paper, the focus is upon adding fault tolerance in systems using non-preemptive deadline-driven scheduling. Schedulability conditions are derived for fault-tolerant peri-odic and sporadic task sets experiencing bounded error arrivals under non-preemptive deadlinescheduling. A timing analysis algorithm is presented based upon these conditions and its run-time properties are studied. Computational experiments show it to be highly efﬁcient in terms ofrun-time complexity and competitive ratio when compared to previous approaches.
/C2112016 The Author. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is anopen access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. Introduction1.1. MotivationRecent results quantifying the optimality gap between non-preemptive scheduling and its preemptive counterpart onuniprocessors have been very encouraging. Using processorspeedup analysis as a quantiﬁcation metric, it has been shownthat any task set which can be successfully scheduled by a fully
E-mail address:m.short@tees.ac.ukPeer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics (2017) 13, 130–139
Saudi Computer Society, King Saud University
Applied Computing and Informatics
(http://computer.org.sa)www.ksu.edu.sawww.sciencedirect.com
http://dx.doi.org/10.1016/j.aci.2016.07.0012210-8327/C2112016 The Author. Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).preemptive optimal scheduling algorithm on a uniprocessorcan also be scheduled by its non-idling, non-preemptive coun-terpart if the processor is speeded up by a factor which is nomore than a simple linear function of the timing requirements(and is usually quite small for realistic applications) [1,2]. Since timing requirements are typically ﬁxed by application con-straints and processor speeds are much faster than one ortwo decades ago, this has renewed interest in non-preemptiveand limited-preemptive scheduling on low cost microcontrollerand microprocessor platforms[1–5]. For embedded real-timeapplications such as multimedia, automation and control,increases in hardware parallelism (such as multicore proces-sors, DMA, programmable ADCs/DACs and dedicated com-munication controllers) also favor the use of non-preemptivescheduling as the workload on the host CPU can be consider-ably reduced. Such applications are the focus of this paper.There are several reasons to implement an application usinga non-preemptive scheduler if it is possible to do so: theseinclude an easier code implementation (no need to implementcontext switching and advanced stack management), lowerCPU and memory overheads, exclusive access to sharedresources by design, fewer cache/pipeline-related ﬂushingevents and potentially less susceptibility to transient errors[6–10]. Indeed, the principal advantage of preemptive softwarearchitectures is their comparative ﬂexibility around timingrequirements[6], which as mentioned has recently been explic-itly quantiﬁed[1]. Among the available options for non-preemptive scheduling, the non-preemptive Earliest DeadlineFirst (npEDF) dynamic priority-driven scheduling algorithmis known to be optimal among the class of non-preemptiveschedulers that do not allow the use of inserted idle-time[8,11,12](For recent developments in the area of priority-driven non-preemptive scheduling allowing the use of insertedidle-time, the interested reader is referred to Nasri and Kargahi[4]and Nasri and Fohler[5]. The results demonstrated byAbugchem et al.[1]and Thekkilakattil1 et al.[2]are directly applicable to the npEDF scheduler. Since very efﬁcient run-time implementations (with effectivelyO(1) CPU overheads)are relatively straightforward to create[13], npEDF becomesthe focus of the current paper.1.2. Problem statementNon-trivial problems can arise with npEDF with respect totask failures and overloads, due to its single-tasking mode ofoperation. Such failures occur in situations when assumptionsof ﬁnite and known worst-case execution times are violatedand a task overrun its determined execution time, overloadingthe CPU. Although overloads are also problematic in preemp-tive architectures, Allworth[14]has noted:‘‘[The] main drawback with this [non-preemptive] approachis that while the current process is running, the system is notresponsive to changes in the environment ”.Unless evasive action is taken when a task fails, programﬂow will never be returned to the scheduler; the entire systemwill effectively ‘freeze’ indeﬁnitely, or at least until the problemis cleared. Such a situation is depicted inFig. 1for two peri- odic taskss
1ands 2, both having a period and relative deadlineof 50 ms. Supposing that tasks
1fails during its third invoca-tion (att= 105), then both tasks will miss their deadlinesindeﬁnitely; or at least until the situation is detected andrecovered.Timeline breaks such as that depicted above are especiallyproblematic in real-time control systems. Physical processessuch as chemical reactors, aircraft and nuclear power plantare open-loop unstable, and the automatic control of such sys-tems is safety-critical in nature as interruptions of the providedcontrol service may lead to hazardous physical conditions [15]. Even with open loop stable systems, interruptions of controlservices can lead to deleterious or degraded performancebecause of the effect of introducing large time delays and jittersin the feedback loop[16]. Considering that experimental stud-ies employing fault-injection have reported that approximately58% of faults injected into a representative real-time operatingsystem and its application tasks resulted in either complete sys-tem failures or multiple task ‘crashes’[17], adding fault toler-ance into npEDF would seem to be advisory. Fault-tolerancein this context refers tofault detection and recoveryand also temporal redundancy, i.e., indirectly detecting a fault (causedby an error) through its effect on the execution time of a task,recovering the state of the CPU and attempting re-execution ofthe failed task at some appropriate future point in time.1.3. Contributions and structureIn this paper, schedulability conditions to ensure that a set offault-tolerant tasks (which can be periodic or sporadic, orboth) under npEDF scheduling will meet their deadlines givensome mild assumptions about the nature of errors and theirarrival rate will be developed. The efﬁciency of fault-tolerantnpEDF when compared to other fault-tolerant non-preemptive scheduling methods will also be investigated. Thespeciﬁc contributions include the following: (i) the develop-ment of efﬁcient schedulability testing conditions for fault tol-erant task sets under bounded error arrival rates and (ii) results
Figure 1Task failure leading to a schedule (‘timeline’) break.Timing analysis for embedded systems using EDF scheduling 131from a computational study which provide an evaluation ofthe relative effectiveness of the proposed techniques in com-parison with previous works. The remainder of this paper isorganized as follows. Section2reviews some relevant previouswork in the area of fault tolerant real-time scheduling. Sec-tion3presents the system and error models while Section 4 derives the schedulability analysis. Section5presents the com-putational simulation results. Section6concludes the paperand presents some areas for future work.2. Related workA watchdog timer is arguably the simplest approach for errordetection and correction in a computer system [18,19]. How- ever the use of a watchdog can have several drawbacks withrespect to a real-time control system, as outlined in Shortand Sheikh[24]. Previous work has therefore considered moreelaborate error/fault detection and recovery means for taskfailures for a variety of non-preemptively scheduled systems:the key related works are now elaborated.Mosse and Melham[20], consider a real-time schedulerwhich is capable of recovering from task failures in an aperi- odictask environment. The authors consider npEDF alongwith a ‘suitable error detection’ capability, such that failedtasks can be detected at or before the end of their allotted exe-cution times. They propose an optimal scheduling algorithm(SFS) with time complexity that is quadratic in the numberof active jobs to reserve idle (backup) slots in the aperiodicschedule at least everyDftime units to execute backup tasksshould a fault occur. The authors also propose a linear-timeheuristic (LTH) to reduce the overheads, and demonstrate thatthe degree of sub-optimality is small. However, for periodic (c.f. aperiodic) tasks, deciding schedulability becomes intractabledue to strong NP-hardness[21]. Sporadic tasks cannot be sup-ported directly in the scheduler. Broster and Burns [22]con- sider situations in which messages can fail due toelectromagnetic interference in a Controller Area Network(CAN). A CAN supports ﬁxed-priority non-preemptivescheduling of messages in a broadcast environment. Theauthors propose a technique to upper-bound the latest timethat a particular message can be scheduled for retransmissionusing an estimate of message worst-case response times. FornpEDF, response times require considerably more effort fortheir computation and no equivalent to the method has yetbeen proposed. Hughes and Pont have previously describeda simple task guardian to be used with the TTC periodic taskscheduler[23]. TTC is a compact form of ‘cyclic executive’ (see[9]or[14]for further details). Although the technique ofHughes and Pont[23]gives a basic form of error/fault toler-ance, the underlying scheduler itself does not support sporadictasks. For periodic tasks, schedulability testing involves acheck across the least common multiple of the task periodsthat the timeline is free of overloads. This procedure is againstrongly NP-hard; Short[10]proposed a re-design of theTTC approach which allows for an improved form of FIFO-based TTC scheduler. This reduces the schedulability test topseudo-polynomial complexity[10]. Exploiting the predictabil-ity and lack of interference in the non-preemptive schedule, asimple means to detect task failures and execute a backup taskin an npEDF scheduler was proposed by Short and Sheikh[24]. Although the technique was successfully applied to con-trol an unstable system in the presence of errors, a major draw-back in this work is that worst-case non-preemptive blockingwas signiﬁcantly increased; this in turn had a very negativeeffect on task schedulability and a loss of achievable CPUutilization.Overload detection and recovery has also been investigatedwith respect to fully preemptive scheduling. As outlined by thesurvey paper of Gardner and Liu[25], these techniques typi-cally rely upon the detection of a task exceeding its executionbudget and the application of corrective action. An effectivesolution for preemptive EDF lies in the Constant BandwidthServer (CBS)[26], which for the case of real-time control sys-tems typically involves the dynamic elongation of the period(s)of the offending task(s) to maintain a constant utilization. TheCBS, however, cannot deal with timeline breaks such as thatdepicted inFig. 1. Although each of these schemes may beapplied (to a certain extent) within the framework of npEDF,to the knowledge of the current author no schedulability con-ditions for the general case of fault-tolerant npEDF schedulingof recurring tasks under bounded error arrivals have previ-
ously been described. This is aimed to be addressed in the nextsection.3. System and error model3.1. System modelLet the single processor task system be represented by a set T ofnrecurring (periodic/sporadic) tasks, denoted as T={s
1, s
2,...,s n}. Each task is parameterized by a 3-tuple:s
i¼ðpi;ci;diÞð 1Þ In whichp
iis the task period (minimum inter-arrival time), c iis the (worst-case) computation requirement of the task, d
iis the task (relative) deadline. Each invocation of a task is called ajob. When a job of taskibecomes ready at timet, its absolute deadline is set at timet+d
iand the scheduling algorithmmust allocatec
iunits of CPU time to process the job in theinterval [t,t+d
i); otherwise, a deadline miss will occur. Jobsare scheduled according to the npEDF scheduling policy, inwhich the ready job with the earliest (absolute) deadline isselected to be run to completion. Ties between ready jobs shar-ing a common deadline are broken arbitrarily but consistently,typically by lowest task index. An executing job is said to beblockinganother job, if this ready job has an earlier deadlineand is waiting for the current job to complete before it can exe-cute on the processor; note that in a fully preemptive system,the blocking task would have been preempted (suspended,paused) by the arrival of the blocked job. Under the npEDFscheduling policy, a job can be blocked if and only if it isinvoked subsequently to the blocking job being selected forexecution.The utilization of an individual task is given by u
i=c i/pi, and the utilization of the task setU=Ru
i. Successive job arri-vals from sporadic tasks are always separated by at least p
i
units of time; job arrivals from periodic tasks are always sep-arated byexactly p
itime units. In this paper no speciﬁc rela-tionships between task periods and deadlines are assumed:for any taskithe deadline may be constrained (d
i<p i), impli- cit (d
i=p i) or unconstrained (d i>p i). A task set is consideredto be schedulable if and only if every valid job sequence that132 M. Shortcould be generated at run-time meets all deadlines [11].I n order to facilitate schedulability analysis, two further functionsrelated to the task set parameters will be deﬁned as follows:hðtÞ¼X
ni¼1tþpi/C0d i
pi/C22/C23/C1c
i ð2Þ bðtÞ¼max
dj>tfcj/C01gð3Þ The quantityh(t) is the processor demand function, represent-ing the worst-case execution requirement of jobs with releasetime and deadline in the interval [0,t). The quantityb(t)i s the blocking function, representing the worst-case blockingdue to non-preemption that a job may experience in the inter-val [0,t). See, for example, Refs.[1,11,12]for details of thederivations of these functions.3.2. Error modelIn the current context, a job error can be deﬁned as an incor-rect state arising during the computation of a job (arising dueto electromagnetic inference or other disturbances); a job faultis the inability of a job to function in a correct manner (due tothe manifestation of an error or a software defect); and a jobfailure is a loss of service where the required computationalresults cannot be delivered on-time due to faults. The paperis concerned with temporal effects of errors and defects uponsystem timing. The terms job error, job fault and job failurewill be used interchangeably on occasion; it should be takenthat this refers to a job which has exceeded its assumedworst-case execution time. In this paper, it is assumed thatjob failures occur intermittently due to transient errors(EMI) and/or particle strikes. Any transient upset affectingthe CPU (and its constituent components or peripheraldevices) can potentially lead to control-ﬂow or data errorsoccurring, which leads to job faults and failures – these job-level faults and failures will ultimately lead to timing failures(deadline misses). Previous estimates of bit corruption proba-bility in an IC arrange from/C2510
/C09to 10/C07bit failures per hour, varying upon altitude[27]. Other types of failure mayalso occur intermittently (pseudo-randomly) due to interac-tions between sensor signals and other inputs and latent soft-ware defects, see for example[19,24]. The arrival of errors(or the encountering of software defects) leading to timingfaults and failures of jobs is therefore considered sporadic innature, in the sense that the occurrence of two consecutivejob failures is always separated by at least p
ftime units. In other words, suppose that the last job failure affecting the sys-tem occurred at timet
1(with probabilityk), then the probabil-ity of a job failure occurring at some time t
2>t1is eitherkif (t
2/C0t1)Pp fand zero otherwise. This assumption of pseudo-periodic error arrivals leading to job failures has been used inseveral previous works (e.g.[20,22]), and is thought to give agood approximation of reality.In the analysis that follows, the following assumptions aremade regarding the nature of errors, job faults and failuresand the resulting behavior of the scheduler: (i) the arrival/occurrence of an error or fault during the execution of a jobwill cause it to fail; (ii) failures are detectable at or beforethe end of a job’s execution (the job will generate a run-timeexception or subsequently try to exceed its determined worst-case execution time); (iii) a period of lost computation timeequal tocftime units is experienced after every job failure(e.g. the time taken to execution of a fault handler or recoverymechanism) and (iv) a failed job is notimmediatelyre-executed but is simply re-queued for execution using its original dead-line. Assumption (ii) in the above can be enforced by employ-ing suitable run-time error detection techniques (e.g. [19,24]). However, unlike the method proposed in Short and Sheikh[24], assumption (iv) requires that control be returned to thenpEDF scheduler upon completion of a fault handler. Thisis very beneﬁcial from the perspective of schedulability as willbe described in the next Section. The schedulability guaranteesthat will be developed ensure that all jobs generated by alltasks will meet their deadlines in an environment in whicherror arrivals are repetitive (sporadic), but are bounded inthe sense that they are separated by at least p
ftime units. In the absence of any empirical data or speciﬁc knowledgeregarding the error separationp
f, one may look to practicalguidelines that have been developed within industry. Forindustrial measurement and process control systems, Electro-magnetic Compatibility (EMC) testing according to IEC61000-4-4 requires a system to be able to tolerate short burstsof interference (of duration/C2515 ms) with a repetition period of300 ms. Therefore, settingp
f= 300 ms andc f=1 5m s ( i n addition to the time actually required for any additional faultrecovery mechanisms) seems a practical choice for most typesof industrial embedded systems.4. npEDF schedulability analysis of fault-tolerant task sets4.1. PreliminariesTo include the effects of sporadic task failures in the schedula-bility analysis, it must be assumed that error load (along withprocessor demand and blocking) will manifest simultaneouslyin the worst-case manner. To begin, the worst-case sporadicfault manifestation pattern with respect to npEDF schedulingwill be categorized. Although intuitively it may seem that theworst-case sporadic fault manifestation is the same as for spo-radic tasks (the ﬁrst job failure occurs att= 0 and subsequentfailures arrive with minimum separation), this does not seem tobe the case as the following example will illustrate. Considertwo implicit-deadline taskss
1= {11,3} ands 2= {5,2} with p
f= 20 andc f= 0. The tasks are schedulable under npEDFwhen no job failures occur, as the worst-case blocking thats
1can induce upons 2is (3–1) = 2, leaving enough slack fors
2to meet its deadline. Consider the situation in which an erroroccurs att= 0, causings
1to fail (indicated by ‘F’) as shown inFig. 2(top). When the job failure is detected at t=2 , a scheduling decision is made and although s
1is re-scheduled for execution, this execution is suspended until a later time(indicated by ‘R’ in the ﬁgure) ass
2has become active andhas the earlier deadline;s
2still meets its deadline. Supposenow that the occurrence of the error is delayed until t=2 , causings
2to fail as shown inFig. 2(bottom). In this case,when the failure is detected att= 4, a scheduling decision ismade and althoughs
2is immediately re-executed, it nowmisses its deadline att=5 .Observation 1.Under npEDF, considering a job with adeadline att=d, then the worst-case arrival of a single errorleading to a job failure must be delayed until at least t=b(d)Timing analysis for embedded systems using EDF scheduling 133as a failed job with deadline >dwill not be eligible for re-execution under the npEDF scheduling policy until all jobswith deadlines at or beforedhave been successfully executed.hObservation 2.Under npEDF, considering a job with a dead-line att=dand a single error occurs in the interval [ b(d),d), then the worst-case behavior is induced when the eligible jobwith the largest execution time fails. Under the npEDFscheduling policy, jobs which are eligible for execution in theinterval [b(d),d) are those which are generated by tasks satisfy-ing the relationshipd
i6d.hExtending this analysis to the case in which multiple jobfailures may occur in a given interval is not a trivial matter,since there are situations in which the effect of multiple jobfailures (with each job having a short execution time) maynot necessarily be as severe as the manifestation of only a sin-gle job failure (having a comparatively longer job executiontime). In addition, there are situations in which the absenceof blocking due to non-preemption can lead to worse failurebehaviors that with blocking present; such a case may occurif more failures can be packed into the interval [0, d) than [b (d),d) andb(d) is less than the largest execution time of the eli-gible jobs in [b(d),d). Another complicating factor is that if afailure is detected immediately, then this may have the effectof inserting a preemption point in the schedule, which mayreduce run-time blocking (although the worst-case blockingis clearly not effected). As such, although the exact categoriza-tion of the worst-case behavior could potentially be obtained,this may require consideration of an excessive number of situ-ations and would be very difﬁcult to compute. However, it isrelatively easy to use the observations above to calculate a safeupper bound on the worst-case failure workload, which is pre-sented in the following Lemma:Lemma 1.Following a synchronous arrival pattern of tasks att=0 ,for npEDF scheduling an upper bound on the cumulativeworst-case workload due to failed job executions in an interval[0,t)in an environment with a minimum error inter-arrival rateof pfis given by the function f(t)deﬁned below:fðtÞ¼
tp
f&’/C1c
fþmax
dj6tfcjg/C18/C19ð4ÞProof.As the minimum fault inter-arrival rate is p
f, the largest number of errors that may occur in an interval [0, t) is given by the smallest integer that is greater than or equal to the quantityt/p
f. If blocking due to non-preemption is present, re-executionof jobs beforetdoes not need to be considered for errorsaffecting jobs with deadline >t, and since it holds that:
t/C0bðtÞp
f&’6
tp
f&’ð5ÞWe also have that the number of assumed error arrivals isalways greater than or equal to the actual number of error arri-vals, regardless of whether blocking is present or not. As it wasassumed that an error arrival will cause the executing job tofail, and since any task with a relative deadline at or before t generates jobs which are eligible for execution in the interval[0,t), taking the largest execution time among those tasks sat-isfying the relationshipd
i6tgives an upper bound on the exe-cution time of the largest valid job executed; hence adding thisvalue to the worst-case execution time of the fault handler c
f
gives the worst-case computational demand due to any single error arrival. The functionf(t) in Eq.(4)multiplies this upperbound on the number of error arrivals (and hence job failures)by an upper bound on the worst-case computational demandof any single job failure; it must therefore upper bound thecumulative computational demand due to failed job executionsregardless of the presence or absence of blocking or the actualarrival pattern of any valid set of errors.hAs with processor demand and blocking, the actual run-time load induced by faults may be much lower than thatobtained by the functionf(t) since it represents a worst-casevalue. Building upon this Lemma, it is also possible to makeone further observation that will prove useful.
Figure 2Illustration that a fault arrival occurring during blocking situations is not necessarily the worst-case behavior.134 M. ShortObservation 3.Deﬁningc max= max{c i}+c f, the following inequality holds as an upper bound on the value of f(t)"tP0:fðtÞ6c
maxþt/C1cmax
pfð6Þ ¼c
maxþt/C1u0f ð7Þ withu
f0=c max/pfbeing the utilization of an equivalent spo-radic task to capture the worst-case effects of job failures onthe CPU over its lifetime.h4.2. Schedulability conditionsIt is now possible to incorporate the effects of task failures intoa sufﬁcient schedulability analysis in a relatively straightfor-ward way, which is summarized in the Theorem and Corollarybelow:Theorem 1.A set of fault-tolerant tasks scheduled using npEDFin an environment with a minimum fault inter-arrival rate p
fand fault handler execution time c
fis schedulable if: U
0<1:0 ð8Þ And:8t;d
min6t<t max :hðtÞþbðtÞþfðtÞ6tð9Þ where d
minis the smallest relative deadline among the tasks ,h(t), b(t)and f(t)are as given by(2)–(4),U
0=U+u f0and the bound t
maxis given byt
max¼max max
16i6nfdi/C0pig;Pni¼1uiðpi/C0d iÞþ2c max/C0c f
ð1/C0U0Þ/C26/C27ð10Þ with c
max= max{c i}+c f.Proof.Lemma 1has established the validity of the upperboundf(t), and it is straightforward to see that whether thesummation of the processor demand h(t), non-preemptiveblockingb(t) and the upper bound on workload due to failedjob executionsf(t) is always less than or equal to the CPU timeavailable then the tasks will be schedulable. Condition (8)is sufﬁcient to ensure that the CPU is not overloaded duringthe course of its lifetime (in the limit as t?1), as we have from(7)that job failures will in effect manifest as a sporadictask requiring a fraction of the CPU utilization proportionalto no more thanu
f. Thus it remains to verify that no deadlineswill be missed in some initial portion of the schedule underworst-case assumptions, and to show that the test intervalfor this can be bounded by the proposed value of t
maxto com- plete the proof. We have that fortPmax{d
i/C0p i}, it holds thattPd
i/C0p i"iand hencet/C0d iP/C0p i"i. Inspecting the individual terms of the processor demand function (Eq. (2)) for each task we have that
piþt/C0d i
pi/C22/C23>0!max 0;tþpi/C0d i
pi/C22/C23/C1c
i/C26/C27¼
piþt/C0d i
pi/C22/C23/C1c
i6piþt/C0d i
pi/C1ci ð11ÞThus"tPmax{di/C0p i}, sincec max= max{c i}+c fand using Eq.(7)the following relationship can be written:hðtÞþbðtÞþfðtÞ¼X
ni¼1piþt/C0d i
pi/C22/C23/C1c
iþmax
dj>tfcj/C01gþ
tp
f&’/C1c
fþmax
dj6tfcjg/C18/C196X
ni¼1piþt/C0d i
pi/C1ciþcmax/C0c fþcmax
þt/C1u0f ð12Þ WhenU
0< 1.0 and some deadline(s) will be missed, there willexist sometsuch thatt<h(t)+b(t)+f(t) corresponding to adeadline miss and we can write the following:t<hðtÞþbðtÞþfðtÞ6X
ni¼1piþt/C0d i
pi/C1ciþ2c max/C0c fþt/C1u0f ð13ÞSimplifying and solving fort:t<X
ni¼1ci
pitþXni¼1ci
piðpi/C0d iÞþ2c max/C0c fþt/C1u0f
t<tUþu0f/C16/C17þX ni¼1uiðpi/C0d iÞþ2c max/C0c f
tð1/C0U0Þ<Xni¼1uiðpi/C0d iÞþ2c max/C0c f
*t<Pni¼1uiðpi/C0d iÞþ2c max/C0c f
ð1/C0U0Þð14Þ
And since condition(8)requires thatU
0< 1.0 the denomina-tor in Eq.(14)is non-zero. Thus if there exists some job dead-line at whicht<h(t)+b(t)+f(t), this will occur before thelarger of the value max{d
i/C0p i} and the value fortgiven in (14), which yields the desired bound oft
maxas originally statedin the Theorem.hCondition(9)needs to be evaluated only at values oftcor- responding to absolute job deadlines within the interval [ d
min, t
max)[11]. If the CPU utilizationU0is bounded to be less thansome small ﬁxed constantc, the worst-case complexity of eval-uating the conditions ofTheorem 1is pseudo-polynomial withrun-timeO(nmax{p
i/C0d i}), which follows from Theorem 3.1in Stankovic et al.[11]. In the case whereU
0is exactly equal to unity, then the complexity of deciding schedulability canbecome exponential as the condition of(9)is required to be checked over the least common multiple ( lcm) of the task periods/inter-arrivals. Since for many real-world task sets theCPU utilization can be bounded below the value of some con-stant close to unity (e.g.c= 0.999), the schedulability test canbe made to be very efﬁcient. In fact, for implicit deadline tasksets the categorization of the run-time complexity can be fur-ther improved as will now be shown:Corollary 1.Ifthe CPU utilization U
0is bounded to be less thansome small ﬁxed constant c and all tasks have deadlines equal totheir periods, the worst-case complexity of an algorithm toevaluate the conditions ofTheorem 1is O(n
2). Proof.Whend
i=p i"i, evaluation oft maxreduces toTiming analysis for embedded systems using EDF scheduling 135tmax¼max max
16i6nfdi/C0pig;Pni¼1uiðpi/C0d iÞþ2c max/C0c f
ð1/C0U0Þ/C26/C27¼max 0;
2cmax/C0c f
ð1/C0U0Þ/C26/C27¼2cmax/C0c f
ð1/C0U0Þð15Þ And sinceU
06c< 1.0 for some ﬁxed constantcwe can fur- ther writet
max62cmax/C0c f
1/C0c62cmax
1/C0cð16Þ Now, sinceh(d
min)+b(d min)+f(d min)Pc max, the condition c
max6d min=p minis necessary for schedulability (and caneasily be checked inO(n) steps), and any task set failing thiscondition can immediately be ﬂagged as unschedulable; hence,this quantity becomes a lower bound on the smallest period ofany task in a schedulable task set. Thus, the maximum numberof absolute deadlinesd
0for the jobs generated byntasks in the interval [0,t
max) is upper bounded byd
06ntmax
cmax62n1/C0cð17Þ For ﬁxedc, no more thanO(n) deadlines need to be checked,and as the evaluation of the functionsh(t),b(t) andf(t) takes time linear innfor each of these deadlines, the overall proce-dure requires not more thanO(n
2) iterations.hEven in cases of relatively high CPU utilization the boundon the number of absolute deadlines given by Eq. (17)is useful. For example whenc= 0.999, not more than 2000ndeadlines ever need checking. This is in contrast to methods proposedby Mosse and Melham[20]and Hughes and Pont[23],i n which evaluation of schedulability surmounts to checking overthe task hyper-period. The following example illustrates thisefﬁciency gain.4.3. Illustrative exampleTo illustrate the efﬁciency of the proposed schedulability anal-ysis with respect to previous work, an illustrative example isgiven below.Example 1.Consider a task system consisting of three implicit-deadline periodic tasks with parameters s
1= {11,2},s 2= {15,3} ands
3= {40,4} to be scheduled with npEDF operatingin an environment withp
f= 12 and (for ease of exposition)c
f=0 .Using the technique proposed by Mosse and Melham [20], it would have to be determined whether the equivalentaperiodic jobs generated by the periodic tasks over the systemlifetime can be accommodated, by executing the LTHalgorithm (with npEDF as the underlying rule for orderingthe priority queue) for each and every new job occurring in L which represents the planning cycle (hyper-period) of theschedule. The length ofLcorresponds to the least commonmultiple of the task periods, which in this case is equal to 1320and therefore/C25240 applications of LTH are required to verifyschedulability of the tasks. Using the basic TTC schedulertechnique with ‘task guardians’[23]requires a number ofchecks exactly equal to the length ofL(1320) to carry out aschedulability analysis. However, note that the tasks are notschedulable using the basic TTC technique without fault-tolerance asgcd(11,15,40) = 1 < max{2,3,4} = 4.Alternatively, using the schedulability analysis techniquedeveloped in this Section, it is ﬁrst determined that cmax=4 and computeU= 0.482 andu
f= 0.333, and henceU
0= 0.815. This allows the computation of t max= 43.28 and therefore each absolute task deadline in the interval [1,43]requires checking to verify schedulability. This requires eval-uating the functionsh(t),b(t) andf(t) for values oftequal to 11, 15, 22, 30, 33 and 40. These values are tabulated in Table 1 below.From this table it may be observed that the combined CPUloadh(t)+b(t)+f(t) is always less than the time available forits processing across the required test interval; therefore,schedulability is veriﬁed after checking only 6 absolutedeadlines.h5. Computational studyRecall that the motivation for the current paper was to developan efﬁcient mechanism to add fault-tolerance to npEDF withefﬁciently veriﬁable schedulability conditions. The analysisand illustrative example in the previous Section gave a promis-ing indication of the suitability of the proposed method in thisrespect; computational experiments using randomly generatedrepresentative task sets will be used to give further evidence inthis respect. Speciﬁcally, the competitive ratio and analysiscomplexity will be investigated in more depth. First, themethodology employed to generate the task parameters andthe design of the experiment is described.5.1. Task parameter generation/experiment designIndividual task sets were randomly generated for the experi-ments, and in each case the number of tasks nwas varied between 5 and 30 in multiples of 5. For each value of n, the total CPU utilizationU
0was varied between 0.6 and 0.999 inmultiples of 0.1 (or 0.099 for the last step), and for each com-bination ofU
0andn, the fault utilizationu f0was varied between 0.1 and 0.3 in steps of 0.1. Next, the individual utiliza-tion allowed for each tasku
iwas generated (without bias)using the UniFast algorithm[28], such that the CPU utiliza-tion for all tasksU=U
0/C0u f0. The individual task periods/inter-arrivalsp
iwere then uniformly selected from the interval[10,1000] in multiples of 10, and computation times c
iwere computed usingc
i=p i/C1ui. Next, relative deadlinesd iwere uniformly drawn from the interval [0.7p
i,1.3p i]. The minimum fault inter-arrival was computed according to p
f=c max/uf.
Table 1Illustration of the schedulability test.
th(t)b(t)f(t)h(t)+b(t)+f(t) 1 1 232 715 5 3 6 1422 7 3 6 1630 10 3 9 2233 12 3 9 2440 16 0 16 32136 M. ShortNext, task sets were generated using this procedure and thenﬁltered until 10
5task sets satisfying conditions(8) and (9) had been obtained for each combination of n,U
0andu f0, giving a total of 900,000 task sets covering a wide range of periods,relative deadlines, utilizations, computation times and faultarrival rates.For each of the generated task sets, a measure of the com-petitive ratio of the proposed technique was obtained byapplying a modiﬁed TTC schedulability test (described inShort[10]) to each set of tasks; note that the test was modiﬁedto include a fault bounding function (conceptually similar to(5)) to reﬂect that a failed task is immediately re-inserted intothe head of the FIFO queue when using the ‘task guardian’technique. Note that to maximize the chance of schedulability,‘tick overruns’ were assumed allowed in this case for reasonsdiscussed in Short[10]. Results are also reported for the mea-sure of competitive ratio of the proposed technique with thetechnique described by Mosse and Melham [20]using the LTH algorithm with npEDF, with the caveat that the resultspresented may not be full accurate, due to the complexity ofthe analysis; in most cases the CPU running time was pro-hibitive. Instead, this measure was accurately estimated basedon a limited range of examples with tractable running time. Toobtain further insight into algorithm complexity as comparedto other methods, the ratio of the length of the testing interval(t
max) given by(10)with the duration of the synchronousFIFO busy period, which deﬁnes the number of iterationsrequired for the test in Short[10], and also with thelcmof the task periods (as this deﬁnes the complexity of the test pro-posed in Mosse and Melham[20]) is also measured. These dataare reported as average case values, as the worst-case value wasalways <1 and the best case effectively was 0.5.2. Results and observationsThe results that were obtained from the experiment are asshown inTable 2. In the table, ratios are expressed as percent-ages. From these data it can be observed that only 20.06% ofthe task sets deemed schedulable by the proposed techniquewere found to be schedulable using the modiﬁed TTC sched-uler. This provides further quantiﬁable evidence of the degreeof sub-optimality of the TTC approach as compared with theproposed approach: less than a quarter of the task sets couldbe successfully scheduled. No task sets were schedulable withthe modiﬁed TTC scheduler and not npEDF, which is to beexpected given the optimality of the latter. Among those taskswhich could be tested by LTH in a reasonable time, none werefound that were not able to be scheduled; given that npEDFwas used as the underlying scheduling heuristic, this was alsonot surprising. When comparing the test interval lengths, itcan be observed that an 84.49% reduction in the number ofdeadline checks was required for proposed approach usingnpEDF than with the modiﬁed TTC. A more revealing ﬁgureis the ratio obtained for the LTH; on average, less than0.043% of the deadline checks required by LTH were neededby the proposed approach, which is a signiﬁcant improvement.Note that since the length of the test interval in the originalTTC approach as described in Pont and Hughes (2008) is ofidentical length to LTH, this also gives an indication of theimprovement in performance over this method.
Table 2Competitive ratios and relative testing complexity.
Competitive ratio Test interval lengthTTC LTH TTC LTH20.06 100.00 84.49 0.043
Figure 3Competitive ratio as a function of both the number of tasks and CPU utilization.Timing analysis for embedded systems using EDF scheduling 137In order to further investigate the sub-optimality of themodiﬁed TTC approach, an investigation was made of theparameters that inﬂuence the achieved competitive ratio. Thecompetitive ratio was calculated (as a percentage) for eachconﬁguration of number of tasks and CPU utilization U
0. Fig. 3shows the obtained ratios for these two indices.From the ﬁgure it is apparent that the competitive ratiovaries considerably with changes to these parameters. Thecompetitive ratio approaches 90% when 5 tasks are presentwith utilizationU
0= 0.6, but decreases to 50% in a close tolinear fashion as the CPU utilization increases. Increasingthe number of tasks for a given CPU utilization leads to a dra-matic (exponential) drop in the competitive ratio. For 20 ormore tasks and utilization of 0.8 or greater, the competitiveratio remained below the 5% level. These data give additionalsupporting evidence that the goal of creating a simple and ﬂex-ible approach for adding fault tolerance to npEDF has beenachieved, in that the technique has a good competitive schedul-ing ratio and comparatively low analysis complexity.6. Conclusions and further workNon-preemptive scheduling techniques can provide a simpleand attractive option for meeting real-time constraints inembedded systems. In this paper, the fault-tolerant npEDFscheduling of periodic and sporadic tasks has been studied.Schedulability analysis techniques for task sets experiencingbounded sporadic error arrivals have been developed, andhave been shown to provide an efﬁciency improvement overprevious methods in terms of competitive ratio and/or analysiscomplexity. In conclusion, the proposed technique may be ofinterest to developers of fault-tolerant, non-preemptive embed-ded systems which may be exposed to interference and errors.Further work will concentrate upon better categorizations ofthe fault load, the application of probabilistic schedulabilityguarantees and extensions to multiprocessor environments,extending techniques such as those proposed in Andrei et al.[29].AcknowledgmentThis research did not receive any speciﬁc grant from fundingagencies in the public, commercial, or not-for-proﬁt sectors.The author declares no conﬂict of interests regarding the pub-lication of this article.References
[1]F. Abugchem, M. Short, D. Xu, On the sub-optimality of non-preemptive real-time scheduling, IEEE Embed. Syst. Lett. 7 (3)(2015) 69–72, ISSN 1943-0663
.[2]
A. Thekkilakattil1, R. Dobrin, S. Punnekkat, The limited-preemptive feasibility of real-time tasks on uniprocessors, Real-Time Syst. 51 (2015) 247–273
.[3]
G.C. Buttazzo, M. Bertogna, G. Yao, Limited preemptivescheduling for real-time systems: a survey, IEEE Trans. Industr.Inf. 9 (1) (2013) 3–15
.[4]
M. Nasri, M. Kargahi, Precautious-RM: a predictable non-preemptive scheduling algorithm for harmonic tasks, Real-TimeSyst. 50 (4) (2014) 548–584
.[5]
M. Nasri, G. Fohler, Non-work-conserving non-preemptivescheduling: motivations, challenges, and potential solutions, in:Proceedings of the 28th Euromicro Conference on Real-TimeSystems (ECRTS), Tolouse, France, July, 2016
. [6]
G.C. Buttazzo, Hard Real-Time Computing Systems:Predictable Scheduling Algorithms and Applications, Springer-Verlag, New York, 2005
.[7]
M. Short, M.J. Pont, J. Fang, Exploring the impact of pre-emption on dependability in time-triggered embedded systems: apilot study, in: Proceedings of the 20th Euromicro Conferenceon Real-Time Systems (ECRTS 2008), Prague, Czech Republic,2008, pp. 83–91
.[8]
K. Jeffay, D. Stanat, C. Martel, On non-preemptive schedulingof periodic and sporadic tasks, in: Proceedings of the IEEEReal-Time Systems Symposium, 1991, pp. 129–139
. [9]
M.J. Pont, Patterns for Time Triggered Embedded Systems,Addison Wesley, 2001
.[10]
M. Short, Analysis and redesign of the ‘TTC’ and ‘TTH’schedulers, J. Syst. Architect. 58 (1) (2012) 38–47
. [11]
J.A. Stankovic, M. Spuri, K. Ramamritham, G.C. Buttazzo,Deadline Scheduling for Real-Time Systems: EDF and RelatedAlgorithms, Kluwer Academic Publishing, 1998
. [12]
L. George, N. Rivierre, M. Supri, Preemptive and Non-Preemptive Real-Time Uni-Processor Scheduling ResearchReport RR-2966, INRIA, Le Chesnay Cedex, France, 1996
. [13]
M. Short, Improved task management techniques for enforcingEDF scheduling on recurring task sets, in: Proceedings of the16th IEEE Real-Time and Embedded Technology andApplications Symposium (RTAS 2010), Stockholm, Sweden,2010, pp. 56–65
.[14]
S. Allworth, Introduction to Real-time Software Design,Springer-Verlag, 1991
.[15]
K.G. Shin, H. Kim, Derivation and application of harddeadlines for real time control systems, IEEE Trans. Syst.Man Cybern. 22 (1992) 1403–1413
.[16]
C.R. Elks, J.B. Dugan, B.W. Johnson, Reliability analysis ofhard real-time systems in the presence of controller faults, in:Proceedings of the Annual IEEE Reliability and MaintainabilitySymposium, 2000, pp. 58–64
.[17]
N. Ignat, Y. Nicolescu, G. Savaria, G. Nicolescu, Soft-errorclassiﬁcation and impact analysis on real-time operationsystems, Proceedings of the Design Automation & Test inEurope Conference (DATE), vol. 1, 2006, pp. 47–52
. [18]
M.J. Pont, R.H.L. Ong, Using watchdog timers to improve thereliability of single-processor embedded systems: seven newpatterns and a case study, in: Proceedings of the First NordicConference on Pattern Languages of Programs, Otaniemi,Finland, 2003
.[19]
M. Short, Development guidelines for dependable real-timeembedded systems, in: Proceedings of the 6th IEEE/ACSInternational Conference on Computer Systems andApplications (AICCSA 2008), Doha, Qatar, 2008, pp. 1032–1039. April
.[20]
D. Mosse, R. Melham, A nonpreemptive real-time schedulerwith recovery from transient faults and its implementation,IEEE Trans. Softw. Eng. 29 (8) (2003) 752–767
. [21]
M.R. Garey, D.S. Johnson, Computers and Intractability: AGuide to the Theory of NP-Completeness, W.H. Freeman & CoLtd, 1979
.[22]
I. Broster, A. Burns, Timely use of the CAN protocol in criticalhard real-time systems with faults, in: Proceedings of the 13thEuromicro Conference on Real-Time Systems (ECRTS), Delft,The Netherlands, 2001
.[23]
Z. Hughes, M.J. Pont, Reducing the impact of task overruns inresource-constrained embedded systems in which a time-triggered software architecture is employed, Trans. Inst. Meas.Control 30 (5) (2008) 427–450
.[24]
M. Short, I. Sheikh, Timely recovery from task failures in non-preemptive, deadline–driven schedulers, in: Proceedings of the138 M. Short7th IEEE International Conference on Embedded Software andSystems (ICESS 2010), Bradford, UK, pp. 1856–1863
. [25]
M.K. Gardner, J.W.S. Liu, Performance of algorithms forscheduling real-time systems with overrun and overload, in:Proceedings of the 11th Euromicro Conference on Real-TimeSystems (ECRTS), York, UK, 1999
. [26]
M. Caccamo, G.C. Buttazzo, L. Sha, Handling executionoverruns in hard real-time control systems, IEEE Trans.Comput. 51 (7) (2002) 835–849
.[27]E. Normand, Single event effects in avionics, IEEE Trans. Nucl.Sci. 43 (2) (1996) 461–474
.[28]
E. Bini, G.C. Buttazzo, Measuring the performance ofschedulability tests, Real-Time Syst. 30 (2005) 127–152
. [29]
S. Andrei, A. Cheng, V. Radulescu, An improved upper-boundalgorithm for non-preemptive task scheduling, in: Proceedingsof 17th International Symposium on Symbolic and NumericAlgorithms for Scientiﬁc Computing, September 21–24, IEEEComputer Society, Timisoara, Romania, 2015
.Timing analysis for embedded systems using EDF scheduling 139