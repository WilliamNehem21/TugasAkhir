Classiﬁcation of ﬁngerprint images with the aid of morphologicaloperation and AGNN classiﬁer
Subba Reddy Borraa,⇑, G. Jagadeeswar Reddyb, E. Sreenivasa Reddyc
aDepartment of Computer Science and Engineering, JNTUH, Hyderabad 500085, India
bNarayana Engineering College, Nellore, AP 524004, India
cUniversity College of Engineering, Acharya Nagarjuna University, AP 522508, India
article info
Article history:Received 8 May 2017Revised 12 June 2017Accepted 13 July 2017Available online 15 July 2017abstract
The uniqueness, public recognition, ﬁrmness, and their least jeopardy of ﬁngerprints made an extensivelyand proﬁciently utilized personal authentication metrics. Fingerprint technology is a biometric methodthat is used to recognize persons on the basis of their physical traits. These physical forms comprise ofridges and valleys prevailing on the surface of ﬁngertips. Fingerprint images are direction-oriented pat-tern fashioned using ridges and valleys. The reputation of the ﬁngerprint image regulates the durability ofa ﬁngerprint authentication scheme. For enhancing the restrictions of prevailing ﬁngerprint image aug-mentation approaches we have proposed an effectual method to pact with various ﬁngerprint images.The proposed methodology alienated into three modules. Primarily, the ﬁngerprint image is endangeredto denoising procedure where Wave atom transform is used. Once this procedure is accomplished theimage augmentation is achieved for improving the classiﬁcation rate. The morphological operation isused in our proposed technique in order to augment the image. The morphological operators such as dila-tion and area opening are used here for improvement. Finally the ordering of ﬁngerprint image is done.Adaptive Genetic Neural Network (AGNN) is used for classiﬁcation of images efﬁciently./C2112017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is anopen access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. IntroductionIn this extremely electronically harmonized society, authenticappreciation is crucial in numerous arenas of life. An entity’s phys-iological and behavioral features, acknowledged as biometrics, areimportant tools utilized for documentation and authentication [7]. Biometric schemes have been extensively utilized in numerousimplementations namely access control, law enforcement schemesand border management schemes to human empathy grounded onbiological traits like face, ﬁngerprints, iris, etc. Currently, an exten-sive variability of methods has been established to accomplish therising demand for safety[8]. In today’s atmosphere of augmentedprominence of safety and association, documentation and authen-tication approaches have industrialized into a key technology. Suchobligation for dependable personal empathy in electronic accesscontrol has occasioned in the augmented awareness in biometrics[10].The uniqueness and perseverance of ﬁngerprint images and itstechnology, become the most mature biometrics and is extensivelyimplemented to ID conﬁrm scheme. Fingerprint image quality sig-niﬁcantly affects the presentation of ﬁngerprint identiﬁcationscheme, so it is beneﬁcial and essential for assessing the composedﬁngerprint images quality in the ﬁngerprint recognition system[1]. Currently, the ﬁngerprint is the most frequently utilized bio-metric identiﬁer in authentication schemes [4]. Natural ﬁnger- prints are unevenly characterized into three generic patternsrendering to the complete ﬂow of ridgelines: Arch, Loop, andWhorl. Considering more details like the presence and comparativepositions of core and delta in ﬁngerprint images, ﬁngerprint exam-iners further distribute each generic pattern into two or four sub-groups[2].The uniqueness of ﬁnger print identiﬁcation scheme needs anassessment of his/her ﬁngerprints with all the ﬁngerprints in thedatabase to designate individuals in the storage. Selection of clas-siﬁcation method signiﬁcantly decreases the number of compar-isons throughout ﬁngerprint recovery and therefore decrease theresponse time of the identiﬁcation procedure [3]. Fingerprint matching hinge on the comparison measure within some
http://dx.doi.org/10.1016/j.aci.2017.07.0012210-8327//C2112017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).⇑Corresponding author.E-mail addresses:bvsr79@gmail.com(S.R. Borra),jagsuni@yahoo.com (G. Jagadeeswar Reddy),esreddy67@gmail.com(E. Sreenivasa Reddy). Peer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics 14 (2018) 166–176
Contents lists available atScienceDirect
Applied Computing and Informatics
journal homepage: www.sciencedirect.com
characteristic features. There are principally two types of featuresutilized in ﬁngerprint matching: local features and universal fea-tures. Two greatest pertinent local features, known as minutiae,are ridge ending and ridge bifurcation, while universal featuresare distinctiveness points, speciﬁcally core and delta [5]. The minu- tia set is the most extensively utilized ﬁngerprint feature. Currentdevelopment in ﬁngerprint reconstruction has illustrated that,from the minutia set only, we attain much data about a ﬁngerprint[6]. The procedure of ﬁngerprint documentation is usually done intwo stages: a coarse mapping with the help of classiﬁcation and byﬁltering the local singularities mapping [9]. The paper is summarized as follows. In Section 2provides a brief account about the current research work that is performedin the ﬁeld of face acknowledgment. Section 3elucidates the pro- posed system of ﬁngerprint image organization by proposed Adap-tive Genetic Neural Network (AGNN). Section 4provides the results and discussion of our anticipated technique and Section 5 lastly concludes our proposed technique.2. Related workAbundant research works are performed in the ﬁeld of ﬁnger-print image organization recently. Some of the current investiga-tions done in the ﬁeld of ﬁngerprint image organization aredeﬁned in this section, ﬁngerprint classiﬁcation refers to conveyinga ﬁngerprint image into a number of pre-speciﬁed classes, gives anachievable indexing mechanism. In the area of criminal explorationthe mission of classifying ﬁngerprints consumes much time andlabor. Frequent attempts have been made to systematize the clas-siﬁcation procedure with the help of conventional image process-ing methods but very few have been comprised with the help oflaw implementation agencies because of their restricted achieve-ments in resolving the issue. The repetition of curiosity in neuralnetworks in current years has wedged the courtesy of those convo-luted in ﬁngerprint recognition as they begin to distinguish thepotential recompenses of a neural network method. EbtesamNajim Abdullah AlShemmary[11]deﬁned a method to ﬁngerprintclassiﬁcation on the basis of both individualities and neural net-work investigation. As noise occurs in many of the ﬁngerprintimages comprising those in the NIST databases that are utilizedby numerous investigators, it was challenging to acquire the cor-rect number and situation of the singularities like core or deltapoints that are extensively utilized in current structural classiﬁca-tion methods.A few transitional solutions on ﬁngerprint organization adopt-ing a neural network as decision stage were given by Patil and Sur-alkar[12]. The neural network was equipped to accomplishmatching procedure and was effectively industrialized to recognizeand categorize the ﬁngerprint by back propagation algorithm. Theinvestigational solutions presented the technique proposed couldprogress ﬁngerprint image quality classiﬁcation accuracy moreefﬁciently than others.The themes of ﬁngerprint cataloguing, indexing, and reposses-sion have been premeditated broadly in the previous ten years.One issue faced by investigators was that in all publicly accessibleﬁngerprint databases, only some ﬁngerprint sections from eachindividual are accessible for training and testing, creating it unsuit-able to usage urbane statistical approaches for recognition. C.Leung and C. H. Leung[13]attempted the issue by chief affectedlyintensifying the group of training samples with the help of our pro-posed spatial modeling method. With the prolonged training set,they were capable to engage a more urbane classiﬁer like the Bayesclassiﬁer for recognition. They implemented the proposed processto the issue of one-to- ﬁngerprint documentation and retrieval.An algorithm to perceive and remedy skin distortion groundedon a single ﬁngerprint image was presented by Si et al. [14]. Distor- tion recognition was regarded as a two-class classiﬁcation issue, forthat the enumerated ridge orientation map and epoch map of a ﬁn-gerprint are utilized as the feature vector and a SVM classiﬁer wasskilled to accomplish the organization mission. Distortion rectiﬁca-tion was observed as a regression issue, where the input was a mis-leading ﬁngerprint and the output was the distortion ﬁeld. Toresolve this issue, a database (known reference database) of numer-ous distorted reference ﬁngerprints and consistent distortion ﬁeldswas manufactured in the ofﬂine stage, and then in the online stage,the adjacent neighbor of the input ﬁngerprint was instituted in thereference database and the consistent distortion ﬁeld was utilizedto transmute the input ﬁngerprint into a usual one.Raid Al-Nima et al.[15]proposed human authenticationmethod in which Finger Texture (FT) patterns was used to makeit efﬁcient. To differentiate the ﬁngers from the hand images, arobust and automatic ﬁnger extraction method was used.Enhanced Local Line Binary Pattern (ELLBP) was used to extract
new features. The information embedded within the poorly imagedregions of the FTs a method is suggested to salvage missing featureelements. Classiﬁcation was done by performing Probabilistic Neu-ral Network (PNN).Al-Nima et al.[16]deﬁned an approach which authenticatesbased on their ﬁnger textures. Finger Texture (FT) features of thefour ﬁnger images (index, middle, ring and little) are extractedfrom a low resolution contactless hand image. To enhance theFTs, new Image Feature Enhancement (IFE) was used method toenhance the FTs. The resulting feature image is segmented and aProbabilistic Neural Network (PNN) is employed to classify intelli-gently for recognition.Fingerprint image improvement was one among the greatestcrucial stages in an automated ﬁngerprint identiﬁcation scheme.Wang et al.[17]deﬁned an operative algorithm for ﬁngerprintimage quality enhancement. The algorithm involves of two phases.The primary stage was disintegrating the input ﬁngerprint imageinto four subbands by implementing two-dimensional discretewavelet transform. At the secondary phase, the remunerated imagewas fashioned by adaptively procurement the compensation coef-ﬁcient for each subband on the basis of the mentioned Gaussiantemplate. The proposed algorithm could progress the clarity andcontinuity of ridge ediﬁces in a ﬁngerprint image.3. Proposed methodologyFingerprints are a consistently individual identiﬁcation biomet-rics because of the singularity, dependability through life, unique-ness among individuals, public acceptance and their minimum riskof intrusion. Because of its uniqueness among people ﬁngerprintauthentication is generally acknowledged in all method for effortsto establish safety. Unique ﬁngerprint images are bearing focusedexample framed by ridges and valleys where the physical patternscomprise of ridges and valleys existing on the surface of ﬁngertips.Fingerprints ridges assume a vital part in the enhancement of ﬁn-gerprints. An effective strategy to manage unique ﬁngerprintimages and the enhancement of such images with better qualityyield in our proposed work.In order to enhance the limitations of existing unique ﬁnger-print image enhancement methods we proposed an effectivemethod to manage ﬁnger impression pictures. The proposedmethodology can be classiﬁed into three modules. To begin with,the ﬁngerprint image is subjected to denoising process whereWave Atom Transform is used. When this procedure is ﬁnishedthe image enhancement is performed in order to improve theclassiﬁcation rate. The morphological operation is used in our pro-S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176 167posed method in order to enhance the image quality. The morpho-logical operators like dilation and area opening are used here forimprovement. The last stage of proposed method is the classiﬁca-tion of ﬁngerprint image. Here we have used Adaptive genetic neu-ral system (AGNN) for ﬁngerprint classiﬁcation (see Fig. 1).3.1. Wave atom transformThe wave Atom Transform is utilized for denoising the imageswhere the images that are to be processed in system have to be ﬁn-ished noise free. To de-noise the image by the Wave Atom Trans-form executes the consequent stages:Step 1:Apply the right circular movement process to the inputimage. This is the initial step utilized for noise removal utilizingthe wave atom transfer.Step 2:At the point when the right circular movement is ﬁn-ished, we initiate the forward 2D Wave atom transform.Step 3:The wave atom coefﬁcients obtained using 2D Waveatom transform is subjected to hard thresholding inorder toimprove the image qualityStep 4:Inverse 2D wave atom transform is applied to the aboveresult for reﬁning the process of waveatom transform.Step 5:The ﬁnal stage in the denoising process is the applica-tion of left circular shift to the result obtained at the step 4,which completes the denoising process.Wave molecule changes are utilized with the directional casingto expel noise in ﬁnger print images. Once the denoising is done,the following stage in our proposed framework is the image upgradation where we use morphological operation for improvingthe ﬁngerprint images.3.2. Image enhancement using morphological operationIn the wake of denoising of the images by modifying the con-trast and intensity of the image utilizing waveatom change, mor-phological operation is performed on the image. In morphologicaloperation, the estimation of every pixel in the yield image dependson a correlation of the comparing pixel in the output with itsneighbors. By picking the size and shape of the area, we developa morphological operation that is delicate to particular shapes inthe input image. Here two morphological operations, for example,dilation and area opening./C15Dilation:In dilation, the estimation of the output pixel is the mostextreme estimation of the considerable number of pixels in theinput pixel’s neighborhood. In a binary image, if any of the pixelsis set to the level 1, the yield pixel is set to 1. It is utilized to buildthe object in the image. It has the condition,
gSðIÞ¼fijS i\I–/gð 1Þ
whereS imeansStranslated withi,Iis the image andSis the struc- ture element.
/C15Area opening:From a binary image the ﬁlter that its connected componentswith area smaller than a parameter
qis called area opening. From a morphological perspective, this ﬁlter is an algebraic opening, andit can be extended to grayscale images. In particular, the area open-ing of parameter
qof an imageIis the supremum of the grayscaleimages that are smaller thanIand whose regional maxima are ofarea greater than or equal to
q.It can be deﬁned as:LetI/C26Qand
q/C210:The area of opening of parameter qofIis given by
ng
qðIÞ¼fi2IjAðH iðIÞÞ /C21 qgð 2Þ
Apparently, ifðI nÞn2Ndenote the connected components ofN;n
g
qðIÞis equal to the union ofN n’s with area greater than or equalto
q:
ng
qðIÞ¼[ fI njn2N;AðI nÞ/C21 g ð 3Þ
By using these morphological operation maximum intensitypixels of the image alone is selected. Thus, the operation employedcontrast and intensity adjusted image is further enhanced by uti-lizing the morphological operation. After morphological operationstage, the ﬁnal stage is the classiﬁcation of ﬁngerprint image withthe aid of AGNN.3.3. Classiﬁcation using Adaptive Genetic Neural Network (AGNN)The Adaptive Genetic Neural Network is used to determine theﬁnger print classiﬁcation and it is skilled by engaging the featuresvalues that are extracted from each and every image. The AdaptiveGenetic Neural Network is well skilled by the way of the extractedfeatures. The Adaptive Genetic Neural Network is home-based tothree input units, n unseen units and one output unit. The inputof the neural network is the feature vector we have abstractedfrom the images. The network is qualiﬁed under a great group ofdissimilar ﬁngerprint images to permit them to efﬁciently catego-rize the exact query image in the testing stage. The neural networkworks making usage of two stages, one is the training phase andthe further is the testing phase.
Fingerprint image 
Denoising using Wave atom Transform Image Enhancement using Morphological O
peration 
Classification Using AGNN Classified Output 
Fig. 1.Block diagram for proposed method.168 S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176Training phaseIn the training stage, the input image is subjected to featureextraction and this feature vector is given as the input to the neuralsystem. Primarily, the nodes are speciﬁed with random weights. Asthe output is previously recognized in the training phase, the out-put attained from the neural network is associated with the origi-nal and weights are diverse so as to decrease the error. Thisprocedure is performed for a great number of images so as to pro-vide a stable scheme having weights allocated in the nodes.Multilayer feed forward neural network is used in our proce-dure. The structure is portrayed in Fig. 2. The input layer hasN neurons i.e. number of matrix elements, the unseen layer has N
sl
neurons and the output layer has Nneurons i.e. the number of typescripts ranging from A to Z and letters 0–9. Back propagationalgorithm is utilized to train the neural network that is designatedas follows.Step 1:Produce arbitrary weights between the interval [0, 1]and dispense it to the hidden layer neurons and also the outputlayer neurons. Preserve a unity value weight for all neurons ofthe input layer.Step 2:Input the training datasetDto the classiﬁer and regulatethe BP error as trails
BPE¼O T/C0O NN ð4Þ
In Eq.(4),O Tis the target output andO NNis the network output that can be dogged asO
NN¼½oð1Þ2oð2Þ2...oðMÞ2/C138. The network out- puts can be dogged as
oðLÞ2¼XMhid
j¼1we2j1O1ðjÞð 5Þ
where,
O1ðjÞ¼11þexpð/C0we
11r/C1OinÞð6ÞEqs.(5) and (6)signiﬁes the activation performance achieved inthe output layer and hidden layer correspondingly.Step 3:Regulate the weights of all neurons as we¼weþ
Dwe, where,
Dweis the change in weight that can be dogged as
Dwe¼r:O2:BPE ð7Þ
In Eq.(7), ris the learning rate, frequently it ranges from 0.2 to0.5.Step 4:Reprise the procedure from step 2, till BP error getsdiminished to a least value. Virtually, the standard to be grati-ﬁed isBP
E<0:1.Testing phaseIn the testing stage, the input image is applied to the trainedneural network having speciﬁc weights in the hubs and the yieldis ascertained to classify the images taking into account the traineddataset. In common neural network the procedure will be halted inthe wake of testing. In the proposed modiﬁed neural network, fortesting process we have consolidated the optimization techniqueinorder to enhance the weight utilized for testing. In our proposedstrategy the weights are improved with the assistance of theGenetic algorithm. By integrating optimization procedure the clas-siﬁcation accuracy will be enhanced there by giving improvedrecognition of the images. The assembly of the artiﬁcial neural net-work is demonstrated inFig. 2.3.3.1. Weight optimization using genetic algorithmsWith a speciﬁc end goal to keep up assortment over the span ofoptimization process the components are isolated into chromo-somes in the suggested ﬁngerprint classiﬁcation technique bymeans of adaptive GA. Till the most incredible solution are got pastthe arrangement of chromosomes this technique is repeated everyonce in a while. Relocation of individuals among different chromo-
HN2ww222 1 
NHC2
NN2 w1N2Hww22Nw222w221w21Nw211
N HN1w
w|M|2w|M|1w121 
2 
I2w11
HN|M|wI11 
Input layer Hidden layer Output layer |M2 w212C1
CN I|M|w21
w2N2H
Fig. 2.Structure of Artiﬁcial Neural Network.S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176 169somes raced using the implementation of genetic operators end inthe production of fresh individuals. To accomplish the level of vari-ety the rate of migration authorities the algorithm and is sustainedprivileged the chromosomes.Step 1: Generation of chromosomeThe input for AGA is the random weights which are used fortraining phase in neural network. The generation of chromo-some for the optimization is the initial phase of GA. Here, ‘ N’ numbers of chromosomes are generated from the solutionspace. The initial chromosome are indicated using the belowexpression,
Ci¼½cðnÞ0cðnÞ1...cðnÞQ/C01/C138;06n6Q/C01;06k6P/C01ð8Þ
where,cðnÞkis thekthgene of the chromosome,Qis the population pool,Pis the length of the chromosome.
Step 2: Fitness functionA type of objective function is the Fitness function that is thetop target parameter to the optimized value. With the help ofthe subsequent formula the ﬁtness performance is assessed.
Fn¼Xpn¼1wn=p ð9Þ
On the basis of the threshold weight values the ﬁtness of everychromosome is considered here. By picking the result and pro-ceeding to step 5 or moving towards the succeeding step 3 isdone after scheming the ﬁtness values.Step 3: Crossover operationTo attain a latest chromosome termed offspring, the crossoveroperation is accomplished among two parent chromosomes.The genes are selected and a latest child chromosome is fash-ioned on the basis of the crossover rate CO
R. The ﬁtness function is utilized to the lately fashioned child chromosome after con-structing a new chromosome. The formula for calculating thecrossover rate is set as,
COR¼Gco
CLð10Þ
where,
COR– Crossover rateG
co– Genes CrossoverC
L– Chromosome lengthThe implemented crossover operation make sure that theweights chosen for training the image, are supergenes endureunbroken via the crossover operation that means no liabilitycan be go down out of the scheme or can be swapped. By treat-ment a one-point crossover the crossover operation seams twosubsets of duties with their applicable values.Step 4: Adaptive mutation operationThe recommended technique is based on GA by Adaptive Muta-tion so that the union of the solution is quickened. On the basisof the mutation rateðM
rÞthe mutation operation is conveyedout. On the basis of the quantiﬁed mutation rate genes aretransformed individually here. The formula for mutation rateis set as,
MU R¼MU Pt
CLð11ÞwhereMU Ptis the mutation point,C Lis chromosome length.
By changing the mutation point actively the mutation is accom-plished adaptive in the recommended method as professed for-mer. With respect to the ﬁtness of the accomplishedchromosome, the mutation point is accomplished to alterdynamically. The mutation rate is designated on the basis ofthe ﬁtness intended. At this time the ﬁtness is on the basis ofthe errands and dependencies.The vector that embodies the possible mutation points is pro-vided as follows
MU Pt¼fmu 1;mu 2;...;mu Lg;ð12Þ
At this point L signiﬁes the chromosome length. The mutationrate will be recognized based onF
n.
MUnR¼1;if Fn/C20T0;else/C26 ð13Þ
At this timeTis intended on the basis of the average responsi-bility value. The mutation is performed in the position consid-ered in Eq.(7). It will be adaptively altered on the basis of theﬁtness value of every chromosome in iterations.Step 5: SelectionAt the time of the selection process, the Qcomprehensively pro- duce chromosomes and theQnovel chromosomes are situatedin a selection pool based on their ﬁtness values. The chromo-somes that encompass good ﬁtness lodge the top positions ofthe pool in the selection pool. The primary Qchromosomes that are at the top of the selection pool are designated for the subse-quent generation among the 2Qchromosomes. At this time theselection is grounded on the ﬁtness and implementation timefor each task.4. Results and discussionThe experiment was carried out in MATLAB (2015a) by applyingthe proposed approach and Image Processing Toolbox was used toproduce the improved ﬁnger print image. Proposed methodologywas validated against FVC2000 dataset. The ﬁngerprint and fakeimages are collected using the Fingerprint Veriﬁcation Competitionor FVC2000[18]as well as from the samples that were drawn fromSFinGE. Different sensors are applied on FVC2000 to collect almostfour databases from this FVC2000 database. As the function of opti-cal sensor is different for every individual, the samples collectedare different from each other. Low cost Optical sensor was usedto collect images for DB1. Low cost Capacitive Optical sensor wasused to collect images for DB2. DB3 is collated using a fairly size-able quality of optical sensors. At last, databases DB4 is syntheti-cally generated using SFinGE. These data base speciﬁcations aregiven inTable 1and the ample images are shown from Figs. 3–10. Fig. 11speciﬁed below displays the processed output for theinput ﬁngerprint images. Dissimilar query ﬁngerprint images areimplemented to our proposed scheme and are classiﬁed accord-ingly and is portrayed in the below ﬁg.As publicized in above ﬁgure, the input image is substance tonoise reduction and then improved by the morphological operation
Table 1The four FVC2000 databases.
Database names Sensor type Image sizeDB1 Low-cost optical 388 /C2300 DB2 Low-cost capacitive optical sensor 256 /C2364 DB3 Optical sensor 448 /C2478 DB4 Synthetic generator 240 /C2320170 S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176such as dilation and opening. The improved images are then clas-siﬁed on the basis of the input query image with the help of Adap-tive genetic neural network. The categorized images are thenstowed for empathy. The presentations of proposed technique inorganization of exact images are then assessed and are associatedwith that of available neural network.4.1. Performance evaluationThe evaluation metrics like Precision, sensitivity, speciﬁcity,accuracy and F-Measure are estimated in order to evaluate the per-formance of the proposed system. These metrics are assessed fordifferent training testing percentages and are tabularized. Similar
Fig. 3.Sample images from DB1; each row shows different impressions of the same ﬁnger.
Fig. 4.Images from DB1; all the samples are from different ﬁngers and are ordered by quality (top-left: high quality, bottom-right: low quality).
Fig. 5.Sample images from DB2; each row shows different impressions of the same ﬁnger.S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176 171Fig. 8.Images from DB3; all the samples are from different ﬁngers and are ordered by quality (top-left: high quality, bottom-right: low quality).
Fig. 6.Images from DB2; all the samples are from different ﬁngers and are ordered by quality (top-left: high quality, bottom-right: low quality).
Fig. 7.Sample images from DB3; each row shows different impressions of the same ﬁnger.172 S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176metrics for the existing methods are also evaluated and tabulatedfor comparing with proposed method. In our proposed schemewe have utilized neural network which is one of the existingmethod for classiﬁcation. The performance metrics are deﬁned inTable 2./C15Precisionshows the class agreement of the data labels with thepositive labels given by the classiﬁer./C15Sensitivityshows the effectiveness of a classiﬁer to identify thepositive labels./C15Speciﬁcityshows how effectively a classiﬁer identiﬁes the neg-ative labels./C15Accuracyshows the overall effectiveness of a classiﬁer./C15F-measureshows the relation between data’s positive labelsand those given by a classiﬁer.In[19]the author’s deﬁned non neural network approach forclassiﬁcation of images. Here they deﬁned threshold between thevalues of the real data and the fake ones for the various non-reference image quality measures (NR-IQM). Afterwards, in thesecond stage, used the quality scores for a leave-one-out cross val-idation to get an exact assertion about the classiﬁcation possibilitywith NR-IQM. To classify data used k-nearest neighbors (kNN) clas-siﬁcation. This method allowed testing all possible combinations ofIQM in a simple way. Finally the classiﬁcation accuracy for discrim-inating real from fake images is calculated.Tables 3and4given below illustrates the performance metricsvalues such as Precision, sensitivity, speciﬁcity, accuracy and F-measure attained by the proposed and NR-IQM with kNN approachfor different training and testing percentages. From the valuesattained it is evident that proposed scheme has outdone the avail-able technique.Fig. 12below depicts the graphical illustration of Precisionattained for the proposed and prevailing technique. The graph val-idates that the planned scheme displays better Precision whenassociated with available neural network technique.Fig. 13below indicates the graphical illustration of Accuracyattained for the proposed and available technique. The graph vali-dates that the proposed scheme exhibits better Accuracy whenweighed against the available neural network technique.Fig. 14indicated below presents the graphical view of Sensitiv-ity accomplished for the proposed and existing strategy. The chartconﬁrms that the proposed system shows better Sensitivity whencompared with accessible neural network procedure.Fig. 15indicated below presents the graphical view of Speci-ﬁcity accomplished for the proposed and existing strategy. Thechart conﬁrms that the proposed system shows better Speciﬁcitywhen compared with accessible neural network procedure.
Fig. 9.Sample images from DB4; each row shows different impressions of the same ﬁnger.
Fig. 10.Images from DB4; all the samples are from different ﬁngers and are ordered by quality (top-left: high quality, bottom-right: low quality).S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176 173S.No Input images Enhanced image Classified Results
1.
2.
3.
4.
5.
Fig. 11.Processed output of ﬁngerprint image classiﬁcation.
Table 2Performance metrics.
True Positive(tp) The number of images identiﬁed as correct, which are actually correctFalse Positive(fp) The number of images identiﬁed as correct, which are actually out of classiﬁcation or wrong.True Negative(tn) The number of images identiﬁed as wrong or out of classiﬁcation, which are actually wrong or out of classiﬁcationFalse Negative(fn) The number of images identiﬁed as wrong or out of classiﬁcation, which are actually correct.Precision
tptpþfp
Recall/sensitivitytptpþfn
Speciﬁcitytntnþfp
Accuracytnþtptpþtnþfpþfn
F-measure 2/C3 recall/C3precisionrecallþprecision/C16/C17
Table 3Performance metric values and comparison between AGNN and NR-kNN approach.
Training –Testing Percentage (%) Proposed Method (AGNN) NR-IQM with kNN algorithmPrecision Accuracy Sensitivity Speciﬁcity F-Measure Precision Accuracy Sensitivity Speciﬁcity F-Measure90–10 0.9756 0.9781 1 0.95625 0.9375 0.9638 0.9625 0.975 0.75 0.90780–20 0.9652 0.9647 0.98657 0.93879 0.9084 0.9350 0.9589 0.9247 0.75478 0.88770–30 0.9453 0.9482 0.98546 0.92587 09532 0.9250 0.9307 0.92589 0.9563 0.902174 S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176Fig. 16.Graphical representation for F-Measure obtained using proposed andexisting methods.
Fig. 17.Training time required for the proposed and other methods in msec.Table 4Performance metric values and comparison between AGNN, Neural network and NR-kNN approaches.
Training–Testing Percentage (%) Proposed Method (AGNN) Existing Neural network NR-IQM with kNN algorithm90–10 80–20 70–30 90–10 80–20 70–30 90–10 80–20 70–30Precision 0.9756 0.9652 0.9453 0.9723 0.9525 0.9385 0.9638 0.935 0.925Accuracy 0.9781 0.9647 0.9482 0.93125 0.915896 0.907895 0.9625 0.958962 0.930789Sensitivity 1 0.98657 0.98546 0.9775 0.962479 0.97259 0.955 0.92479 0.925896Speciﬁcity 0.95625 0.93879 0.92587 0.875 0.895478 0.917856 0.75 0.75478 0.9563F-Measure 0.9375 0.9084 0.9532 0.9274 0.9045 0.9325 0.9075 0.8875 0.9025
Fig. 13.Graphical representation for Accuracy obtained using proposed andexisting methods.
Fig. 12.Graphical representation for Precision attained by proposed and availablemethods.
Fig. 14.Graphical representation for Sensitivity obtained using proposed andexisting methods.
Fig. 15.Graphical representation for Speciﬁcity obtained using proposed andexisting methods.S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176 175Fig. 16indicated below presents the graphical view of F-Measure accomplished for the proposed and existing strategy.The chart conﬁrms that the proposed system shows better F-Measure when compared with accessible neural networkprocedure.The training time and testing time required for the proposedapproach AGNN and other neural network approach along withthe non neural network approach NR-IQM with kNN are calculatedfor various image quantities are given Figs. 17and18. Although the time required to preprocess and classify the images correct or fakeby neural network takes more time than the proposed approach,but the training and testing approaches in proposed approachtakes very minimum time and are efﬁcient than other methods.5. ConclusionIn this work, in order to overcome the disadvantage of variousﬁngerprint images an efﬁcient and productive procedure forunique ﬁngerprint image classiﬁcation method was proposed.The proposed technique uses Wave atom transform for denoising,morphological operation for image upgradation and Adaptivegenetic neural system for image classiﬁcation. The proposed strat-egy helped in classifying the images precisely in view of the imageunder question since the images are upgraded and classiﬁer isaltered utilizing the enhancement systems. The outcomes acquireddemonstrates the adequacy of proposed AGNN based ﬁngerprintclassiﬁcation method as it conveys better parameter values likePrecision, sensitivity, speciﬁcity, accuracy and F-Measure whencontrasted with existing system neural network and non neuralnetwork method NR-IQM with kNN approaches.References[1] Xiu-kun Yang, Yang Luo, A classiﬁcation method of ﬁngerprint quality basedon neural network, in: Proc. of International Conference on MultimediaTechnology (ICMT), 2011.[2] Qinghai Gao, Daniel Pinto, Some challenges in forensic ﬁngerprintclassiﬁcation and interpretation, in: Proc. of IEEE Long Island Systems,Applications and Technology Conference (LISAT), 2016.[3] Fadzilah Ahmad, Dzulkiﬂi Mohamad, A review on ﬁngerprint classiﬁcationtechniques, in: Proc. of International Conference on Computer Technology andDevelopment, 2009.[4]
L.F.A. Pereira, H.N.B. Pinheiro, G.D.C. Cavalcanti, Tsang Ing Ren, Spatial surfacecoarseness analysis: technique for ﬁngerprint spoof detection, Electron. Lett.49 (4) (2013)
.[5] V. Conti, C. Militello, F. Sorbello, S. Vitabile, Introducing pseudo-singularitypoints for efﬁcient ﬁngerprints classiﬁcation and recognition, in: Proc. ofInternational Conference on Complex, Intelligent and Software IntensiveSystems, 2010.[6]
E. Liu, H. Zhao, L. Pang, K. Cao, J. Liang, J. Tian, Method for ﬁngerprintorientation ﬁeld reconstruction from minutia template, Electron. Lett. 47 (2)(2011)
.[7] Manish Kumar Saini, J.S. Saini, Shachi Sharma, Moment Based Wavelet FilterDesign for Fingerprint Classiﬁcation, in: Proc. of International Conference onSignal Processing and Communication (ICSC), 2013.[8] V. Sasikala, Dr. V. LakshmiPrabha, A Comparative Study on the SwarmIntelligence Based Feature Selection Approaches for Fake and RealFingerprint Classiﬁcation, in: Proc. of International Conference on Soft-Computing and Network Security, 2015.[9] Amina Serir, Farida Bennabes, Fingerprint Classiﬁcation by Block Ridgelet andSVM, in: Proc. of 10th International Conference on Information Science, SignalProcessing and their Applications, 2010.[10] Suchita Tarare, Akhil Anjikar, Hemant Turkar, Fingerprint based genderclassiﬁcation using DWT transform, in: Proc. of International Conference onComputing Communication Control and Automation, 2015.[11]
Ebtesam Najim Abdullah AlShemmary, Classiﬁcation of ﬁngerprint imagesusing neural networks technique, J. Eng. (JOE) 1 (3) (2012)
. [12]
S.R. Patil (Waghjale), S.R. Suralkar, Fingerprint classiﬁcation using artiﬁcialneural network, Int. J. Emerg. Technol. Adv. Eng. 2 (10) (2012)
. [13]
K.C. Leung, C.H. Leung, Improvement of ﬁngerprint retrieval by a statisticalclassiﬁer, IEEE Trans. Inform. Forensics Secur. 6 (1) (2011)
. [14]
Xuanbin Si, Jianjiang Feng, Jie Zhou, Yuxuan Luo, Detection and rectiﬁcation ofdistorted ﬁngerprints, IEEE Trans. Pattern Anal. Mach. Intel. 37 (3) (2015)
. [15]
Raid Al-Nima, S.S. Dlay, Al-Sumaidaee, W.L. Woo, J.A. Chambers, Robustfeature extraction and salvage schemes for ﬁnger texture based biometrics, IETBiometrics 6 (2) (2016) 43–52
. [16] R. Al-Nima, S.S. Dlay, W.L. Woo, J.A. Chambers, Human authentication withﬁnger textures based on image feature enhancement, in: Proc. of 2nd IETInternational Conference on Intelligent Signal Processing (ISP), 2015, London,UK, pp. 1–6.[17]
Jing-Wein Wang, Ngoc Tuyen Le, Chou-Chen Wang, Jiann-Shu Lee, Enhancedridge structure for improving ﬁngerprint image quality based on a waveletdomain, IEEE Signal Process. Lett. 22 (4) (2015)
. [18]
Dario Maio et al., FVC2000: Fingerprint veriﬁcation competition, Pattern Anal.Mach. Intel., IEEE Trans. 24 (3) (2002) 402–412
. [19] Amrit Pal Singh Bhogal, Dominik Söllinger, Pauline Trung, Andreas Uhl Non-reference image quality assessment for biometric presentation attackdetection, in: 5th International Workshop on Biometrics and Forensics(IWBF), Coventry, United Kingdom, United Kingdom, 2017.
Fig. 18.Testing time required for the proposed and other methods in msec.176 S.R. Borra et al. / Applied Computing and Informatics 14 (2018) 166–176