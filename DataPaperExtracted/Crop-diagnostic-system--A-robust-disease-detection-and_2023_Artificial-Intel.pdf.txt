Crop diagnostic system: A robust disease detection and managementsystem for leafy green crops grown in an aquaponics facility
R. Abbasia, P. Martinezb,R .A h m a da,⁎
aAquaponics 4.0 Learning Factory (AllFactory), Department of Mechanical Engineering, University of Alberta, 9211 116 St., Edmonton, AB T6G 2G8, Can ada
bMechanical and Construction Engineering Department, Northumbria University, Newcastle Upon Tyne NE7 7YT, UK
abstract article info
Article history:Received 4 August 2022Received in revised form 7 July 2023Accepted 6 September 2023Available online 09 September 2023Crops grown on aquaponics farms are susceptible to various diseases or biotic stresses during their growth cycle,just like traditional agriculture. The early detection of diseases is crucial to witnessing the ef ﬁciency and progress of the aquaponics system. Aquaponics combines recirculating aquaculture and soilless hydroponics methods andpromises to ensure food security, reduce water scarcity, and eliminate carbon footprint. For the large-scale imple-mentation of this farming technique, a uni ﬁed system is needed that can detect crop diseases and support re- searchers and farmers in identifying potential causes and treatments at early stages. This study proposes anautomatic crop diagnostic system for detecting biotic stresses and managing diseases in four leafy green crops,lettuce, basil, spinach, and parsley, grown in an aquaponics facility. First, a dataset comprising 2640 images is con-structed. Then, a disease detection system is developed that works in three phases. The ﬁrst phase is a crop clas- siﬁcation system that identiﬁes the type of crop. The second phase is a disease identi ﬁcation system that determines the crop's health status. The ﬁnal phase is a disease detection system that localizes and detects the diseased and healthy spots in leaves and categorizes the disease. The proposed approach has shown promisingresults with accuracy in each of the three phases, reaching 95.83%, 94.13%, and 82.13%, respectively. The ﬁnal dis- ease detection system is then integrated with an ontology model through a cloud-based application. This ontol-ogy model contains domain knowledge related to crop pathology, particularly causes and treatments of differentdiseases of the studied leafy green crops, which can be automatically extracted upon disease detection allowingagricultural practitioners to take precautionary measures. The proposed application ﬁnds its signiﬁcance as a de- cision support system that can automate aquaponics facility health monitoring and assist agricultural practi-tioners in decision-making processes regarding crop and disease management.© 2023 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Computer visionDeep learningDisease detectionLeafy cropsAquaponicsDigital farming
1. IntroductionAn aquaponic system is the combination of two well-known tech-nologies, namely recirculating aquaculture system (RAS) and a hydro-ponics system (soilless growing of plants) that work together in anintegrated environment (Abbasi et al., 2021a). The rationale of this soil- less growing system involves sharing the mutual bene ﬁt of the available resources, such as water and nutrients, between aquaculture and plantproduction. Fish eats food and excretes waste consisting of ammonia(NH
3+) and other constituents, which are then converted by certainmicrobes to nitrates (NO
3−). This enriched efﬂuent is then pumped into the hydroponic component of the system, where the nutrients arereadily available for uptake. Under this general idea, it can be impliedthat aquaponic is a green and sustainable food production system(Yanes et al., 2020).Despite all the advantages offered by this emerging and growingtechnology, a few challenges need special attention, particularly consid-ering its large-scale implementation. Being a greenhouse and a symbi-otic environment, the parameters and factors (light, temperature, pH,moisture, etc.) that need to be controlled are diverse ( Abbasi et al., 2021b). For the system to be functional and efﬁcient, a delicate equilib- rium among these parameters must be established ( Gillani et al., 2022). Optimal conditions must be met for the growth and development of allthree varieties of organisms that are present in the system ( ﬁsh, bacte- ria, and plants). Another signiﬁcant challenge is related to crop diseasesresulting from either nutrient deﬁciency or inadequate management ofthe system, impacting crop quality and causing crop wastage ( Dhal et al., 2022;Stouvenakers et al., 2019). As Khirade and Patil pointed out, identifying crop diseases and applying disease management prac-tices are key to preventing losses in the yield and quantity of agriculturalArtiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
⁎Corresponding author.E-mail address:raﬁq.ahmad@ualberta.ca(R. Ahmad).
https://doi.org/10.1016/j.aiia.2023.09.0012589-7217/© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/products (Khirade and Patil, 2015). For this reason, early detection ofdisease outbreaks is crucial for the progress of aquaponics farms. Tradi-tionally, crop diagnostic is performed by agricultural specialists who vi-sually examine the plant leaves. This practice, however, is subjective,destructive, time-consuming, and labor-intensive ( Dutot et al., 2013). Moreover, it also requires the experts to be pro ﬁcient with extensive knowledge of various diseases, their symptoms, and treatments ( Khan et al., 2022). Other methods include chemical analyses, leaf color chart(LCC) matching, soil plant analysis development (SPAD), hyperspectralimaging, and spectral remote sensing, which again are either time-consuming or costly or destructive techniques ( Weaver et al., 2020). To address these problems, different automatic crop disease detectionsystems based on artiﬁcial intelligence (AI) techniques such as machinelearning and deep learning are developed as they offer contactless,rapid, environmental-friendly, and accurate methods for performing anon-invasive evaluation of crops' health and quality ( Bedi and Gole, 2021;Singh et al., 2020). Deep learning techniques offer two signi ﬁcant advantages over machine learning techniques. First, the feature extrac-tion process is automatic, and second, the time to process large datasetsof high dimensions is signiﬁcantly reduced (Bedi and Gole, 2021). In addition to disease detection, it is also paramount that farm prac-titioners and researchers have access to relevant information about cropmanagement strategies that allow them to pick up methods and treat-ments appropriately to prevent diseases, thereby gaining both eco-nomic and environmental beneﬁts (Barosa et al., 2019). In most cases, such information is dispersed throughout multiple heterogeneousdata sources—posing a need for a uniﬁed model that contains knowl- edge about the causes and treatments of different crop diseases. Seman-tic technologies such as ontologies have proven effective for dataintegration in multiple domains (Rodríguez-García et al., 2021). An on- tology is a formal and explicit speciﬁcation of a shared conceptualiza-tion (Studer et al., 1998). The logical formalisms behind ontologicalmodels allow autonomous agents to interpret the information that isbeing processed (Horrocks et al., 2005). Ontology can be used to con- struct a knowledge base containing relevant information about causesand suggested treatments of crop diseases, which can be extractedupon disease detection (Rodríguez-García et al., 2021). With this infor- mation, farm practitioners are able to get clear guidelines to effectivelyperform crop monitoring and disease management.In this study, an automatic system based on deep learning tech-niques is presented for the detection and classi ﬁcation of diseases in four leafy green crops, lettuce, basil, parsley, and spinach, grown in anaquaponics facility. Taking advantage of semantic technologies, an on-tology model,‘AquaONT’is developed by authors in previous work(Abbasi et al., 2021b) that contains knowledge about causes and treat-ments of different diseases. This ontology model is integrated with a dis-ease detection system through an interface established on a cloud-based application.The remainder of the paper is structured as follows: Section 2sum- marizes the most recent literature related to crop disease detection sys-tems,
Section 3presents the methodology used to design the proposedsystem,Section 4discusses the experimental results andﬁndings, and ﬁnally, Section 6 concludes the paper and presents the future prospects.2. Related workThe rapid developments in AI have made a major breakthrough indeep learning (DL) and computer vision (CV) technologies by solvingcomplex problems like image classiﬁcation, object detection, speech recognition, voice recognition, natural language processing, and medi-cal imaging, among others (Abbasi et al., 2022a;Subeesh and Mehta, 2021). In particular, convolutional neural networks (CNNs) have provedtheir efﬁciency in various sectors such as automotive, healthcare, or re-tail, and are also being integrated in agriculture for automatic crop dis-ease detection—presenting a reasonable alternative to traditionalpractices (Pathan et al., 2020). In recent years, several models andapplications have been developed for crop disease identi ﬁcation and diagnosis. This section investigates some latest works present in theliterature.Anami et al. designed a deep convolutional neural network (DCNN)based framework for automatic recognition and classi ﬁcation of various biotic and abiotic paddy crop stresses using the pre-trained visual ge-ometry group model, VGG-16 (Anami et al., 2020). Theﬁeld images are used in the proposed approach captured during the booting growthstage. Bedi and Gole proposed a hybrid model based on a convolutionalautoencoder (CAE) network and CNN for automatic bacterial spot dis-ease detection present in peach plants using their leaf images from apublicly available dataset named ‘PlantVillage’(Bedi and Gole, 2021). Paymode and Malode developed a CNN-based method using pre-trained VGG-16 for detecting healthy, unhealthy, and diseased leavesin tomato and grape plants (Paymode and Malode, 2022). Fuentes et al. combined ResNet with Faster R-CNN, R-FCN, and SSD. They pro-posed a method to detect the diseases and insect pests of tomato plants,achieving the effective identiﬁcation of nine different types of diseasesand insect pests (Fuentes et al., 2017). Chen et al. proposed a method to detect rice plant diseases using the DenseNet model of deep transferlearning (Chen et al., 2020).To identify the cucumber disease spots in greenhouses, Ma et al. de-veloped a CNN-based system, combining a compound color feature witha region-growing algorithm (Ma et al., 2018). A disease recognition al- gorithm based on VGGNet and InceptionV3 with reduced model sizeand improved recognition accuracy is proposed by Rahman et al. forrice plants (Rahman et al., 2020). Oppenheim et al. proposed a diseaseclassiﬁcation algorithm based on an improved VGG network for accu-rate and quick identiﬁcation and classiﬁcation of spots on potato crops (Oppenheim et al., 2019). A method based on an improved CNN is pro-posed by Fan et al. to identify nine kinds of common corn diseases fromimages with a complex background ( Fan et al., 2021). Khan et al. pro- posed an apple disease detection system that works in two stages(Khan et al., 2022). Based on the Xception model, theﬁrst stage clas- siﬁes whether the leaf is healthy or diseased, and the second stage,based on Faster-RCNN, performs disease detection.Qi et al. developed a disease recognition system based on an im-proved YOLOv5 (squeeze-and-excitation (SE) module is added) modelto identify the tomato virus diseases in the greenhouse ( Qi et al., 2022). Nandhini et al. proposed a deep learning model that combinesRNN and CNN for disease classiﬁcation and early prediction in the Plan-tain tree (Nandhini et al., 2022). Abbas et al. proposed a deep learning-based method for tomato disease detection that utilizes the ConditionalGenerative Adversarial Network (C-GAN) to generate synthetic imagesof tomato plant leaves (Abbas et al., 2021). A DenseNet121 model was then trained on synthetic and real images using transfer learning to clas-sify the tomato leaves images into ten categories of diseases. An ef ﬁcient detection model (EFDet) consisting of an ef ﬁcient backbone network, a feature fusion module, and a predictor is proposed for the detection ofcucumber leaf diseases in complex backgrounds by Liu et al. ( Liu et al., 2021). Likewise, a YOLOv5-based disease detection model to detect bac-terial spot disease in bell pepper plant from the symptoms seen on theleaves (Mathew and Mahesh, 2022).A framework is proposed for an aquaponics system based on imageprocessing and decision tree methodology that performs disease detec-tion of four leaf species, eggplant, chilli, citrus, and mandarin, and auto-matically generates a report which is sent to the owner through themobile application if the disease is detected ( Barosa et al., 2019). Like- wise, a CNN-based approach for detecting plant disease in smart hydro-ponics provides a tool to the farmers capable of doing the task of anagricultural extension worker with even better accuracy ( Musa et al., 2021). An application based on image processing and SVM is developedto classify apple diseases (Lisha Kamala and Anna Alex, 2021). Yudha et al. proposed a model based on Faster R-CNN with Inception V2 algo-rithm to recognize the diseases in hydroponic lettuce ( Yudha Pratama et al., 2020).R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
2The literature survey has revealed that researchers have extensivelyused deep learning techniques for plant or crop disease detection andclassiﬁcation. The analysis shows that most disease detection systemsare developed for open-air farms. Only a few systems are developedfor modern farming systems, such as aquaponics or hydroponics. Mostmodels are developed considering multiple diseases of only one crop.Moreover, to the best of the authors' knowledge, no comprehensiveand uniﬁed disease detection system is proposed for identifying dis-eases of multiple leafy green crops grown in aquaponics facilities.Disease detection in leafy green presents various challenges. For in-stance, there exists a strong resemblance among the foliage of differentleafy green crops that might impact the performance of the detectionsystem. Secondly, due to differences in light illumination during imag-ing, the visual symptoms of different diseases may appear similar. An-other challenge is the availability of a dataset of leafy green crops thatcan be used for disease detection. Deep learning models require ahuge amount of data for training, and to the best of the author's knowl-edge, there is no sufﬁcient sized large-scale open-source dataset avail-able that can be utilized for this research. There are a few datasets,such as PlantVillage, PlantDoc, and CropDeep ( Noyan, 2022;Singh et al., 2019;Zheng et al., 2019). PlantDoc and PlantVillage are open-source datasets with no categories of leafy green crops. CropDeepdataset contains images of some of the leafy green, but it is not opensource. Lastly, none of the aforementioned models provides informationrelated to the causes and treatments of detected diseases.Apart from AI techniques, ontology-based systems are also devel-oped over the years for plant disease diagnosis and treatment recom-mendations. Jearanaiwongkul et al. developed an ontology-basedexpert system called‘RiceMan’for disease identiﬁcation and control recommendation in rice crops (Jearanaiwongkul et al., 2021). Likewise, Rodríguez-García et al. proposed a decision support system based on anontology model for crop pests and diseases recognition ( Rodríguez- García et al., 2021). It also provides information on agriculture practicesand permitted pest control measures. In these systems, users are re-quired to select crop and observed symptoms from the list for furtherprocessing, which is a time-consuming process. Whereas, in deep learn-ing models, this information can be obtained by using crop images. Deeplearning techniques can be combined with ontology models to developefﬁcient decision support systems for disease mana gement in crops. The idea of combining the two techniques is relatively new in the agricul-ture sector, and hence, limited work is done in this regard that primarilyfocuses on enabling smart services (monitoring and control) in IoT-based farming systems or detection of cyber-attacks ( Abbasi et al., 2021b).Considering the research gaps and potential opportunities, thisstudy aims to create a dataset consisting of high-quality RGB images(healthy and diseased) of four leafy green crops: little gem romaine let-tuce, spinach, parsley, and basil. This study also aims to develop a cropdiagnostic system based on deep learning models and ontology modelsfor detecting diseases and identifying causes and potential treatmentsin stated crops, respectively.3. Research methodologyThe block diagram illustrating the three sequential modules of theresearch methodology is shown inFig. 1. First module involves the preparation of the dataset and training of classi ﬁcation and object de- tection models. The disease detection model works in three phases.Theﬁrst and second phase uses lightweight classi ﬁcation models to classify the type of crop and identify whether the classi ﬁed crop has a disease or not, respectively. Phase 3 is the detection stage thatuses an object detection model to detect and localize the diseasedand non-diseased spots in the crops. The third phase also tells theclass of the diseased spots. The purpose behind adding two classi ﬁca- tion phases before the detection phase is three-fold. First, to improve
the detection performance by reducing the number of wrongdetections which could arise as the model has to identify and localizedifferent disease spots of varying sizes. Second, to determine thecharacteristics of the crop identiﬁed in theﬁrst phase in relation to aquaponics' system design by linking it with the knowledge model.Lastly, to reduce the overall processing time by ﬁltering out invalid inputs in the second phase. The second module aims to extract the in-stances of relevant classes such as potential causes and treatments ofdetected diseases from the ontology model ‘AquaONT’developed by authors in previous work (Abbasi et al., 2021b). In the third module, a cloud-based application is developed using Streamlit1,w h e r ea pre-trained disease detection model and ontology model are de-ployed to obtain a complete crop diagnostic system. Upon identi ﬁca- tion of the crop in phase 1, its characteristics in relation to optimalenvironmental (pH, temperature, illumination, etc.), growth (width,height, area, etc.), and grow bed design (plant site spacing) parame-ters for an aquaponics facility are extracted from ontology modelusing OWLready2
2(ontology-oriented programming package in Py-thon). The authors have conducted a study that identi ﬁed design pa- rameters as vital knowledge in ensuring high crop yields and productquality in an aquaponics facility (Abbasi et al., 2021a). Likewise, once the disease and its type are detected in phase 3, the potential causesand recommended treatments are extracted from the ontologymodel. Each element of each module is presented in detail in the fol-lowing subsections.3.1. Dataset preparationThe dataset preparation involves three steps, i) data acquisition, ii)data annotation, and iii) data augmentation, which are detailed below.3.1.1. Data acquisitionThis study considers four leafy green crops, lettuce, basil, parsley,and spinach. The dataset consists of healthy and diseased images ofthese crops, which are acquired from different sources such as NFTbased aquaponics facility built in AllFactory 4.0 Lab (University of Al-berta, Canada), Google search engine, and Ecosia
3(a search engine based in Berlin, Germany). The diseases considered for the four cropswhile developing the dataset are listed below.•Lettuce: Bacterial leaf spot and Downy mildew•Basil: Downy mildew•Parsley: Septoria leaf spot•Spinach: Downy mildew and Stemphylium leaf spotTo enhance theﬂexibility of the model to correctly classify and de-tect disease, it is ensured that images have non-homogeneous back-grounds, different illumination conditions, and disease maturity stages(Jha et al., 2019). A total of 2000 images are gathered from all the re-sources. Among these images, 800 images showed healthy crops (200images per crop), and 1200 images showed the diseases mentionedabove (240 images per disease).Fig. 2shows some of the sample images from the dataset.3.1.2. Data annotationData annotation is one of the vital steps for the successful devel-opment of object detection models. The process is manual and in-volves labeling the desired objects in an image with a label or tagthat refers to a particular class. The labeled data is used during thetraining of the model. There are various open-source annotationtools, but in this study, LabelImg
4is used. LabelImg is a python based graphical annotation tool that supports a variety of deeplearning algorithms (Qi et al., 2022). In this study, the annotations
1https://streamlit.io/.
2https://pypi.org/project/Owlready2/ .
3https://www.ecosia.org/.
4https://github.com/tzutalin/labelImg .R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
3are generated in COCO JSON and YOLO Darknet TXT formats becausein the disease detection phase, two object detection models aretested to design theﬁnal system.3.1.3. Data augmentationNext, the data augmentation process is performed to supplementand enrich the dataset. This helps increase the model's generalizabilityand overcome the problem of overﬁtting. Moreover, it also allows themodel to learn as many relevant features as possible. This study usesAlbumentations, a Python library, for fast and ﬂexible image augmenta- tions (Buslaev et al., 2020). The different augmentation techniques ap-plied areﬂip, rotation, noise, blur, and brightness. Fig. 3shows examples of different augmentation operations. After applying thedata augmentation, theﬁnal dataset comprises of 2640 images withtheir annotations. Theﬁnal distribution of the dataset is presented inTable 1.3.2. Disease detection model developmentObject detection is a complex task, and disease detection of leafygreen crops comes with its own set of challenges. To overcome thesechallenges, the detection process in this study is divided into three pri-mary phases.Fig. 4shows the detailed pipeline of the disease detectionmodel.Theﬁrst phase of the proposed system uses a lightweight CNN ar-chitecture to classify input images into one of the four types of crops:lettuce, basil, parsley, and spinach. ResNet-50 is used as the basemodel for the CNN architecture in this study and its last layer is re-placed with one global average pooling layer, one dense layer (fullyconnected layer) of size 1024 and activation function ReLu, and oneoutput layer that uses Softmax for classi ﬁcation task and making ﬁnal predictions. ResNet050 is used as it has a simple design, high ac-curacy, and is suitable for small datasets ( He et al., 2015). The crop
Fig. 2.Samples from leafy green image dataset. (For interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this article.)
Fig. 1.Proposed methodology for disease detection and control recommendation system.R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
4type identiﬁed in this stage saves to a folder and also acts as an inputto the next phase.Phase 2 of the system also uses ResNet-50 and classi ﬁes the input from phase 1 into one of the following eight classes.i) Lettuce-Healthyii) Lettuce-Diseasediii) Basil-Heathyiv) Basil-Diseasedv) Spinach-Healthyvi) Spinach-Diseasedvii) Parsley -Healthyviii) Parsley-DiseasedThe architectural design of ReNet-50 used in phase 2 is kept similaras in phase 1 except for the output layer which now has eight classes. Ifthe input image classiﬁed into one of the‘Diseased’crop categories, it goes to phase 3. On the other hand, if any of the ‘Healthy’crop categories are identiﬁed, the process ends, and the classiﬁed image does not go to the next phase for further processing.The third phase of the proposed system is disease detection, whichinvolves classifying and localizing the diseased spots in an image andclassifying them into one of the disease classes mentioned below.i. Lettuce-Bacterial leaf spotii. Lettuce-Downy mildewiii. Basil-Downy mildewiv. Parsley-Septoria leaf spotv. Spinach-Downy mildewvi. Spinach-Stemphylium leaf spotPhase 3 activates only when the input from the previous phase is oneof the‘Diseased’categories. To develop a disease detection model, anobject detection algorithm is used. In the past recent years, advancesin deep learning and computer vision have greatly accelerated the mo-mentum of object detection (Khan et al., 2022). Numerous object detec- tion algorithms (object detectors) are developed and used in the diseasedetection of crops. These detectors are broadly classi ﬁed into twocategories: i) two-stage detectors based on region proposal and ii)one-stage detectors based on regression or classi ﬁcation (Nguyen et al., 2020). The popular two-stage detectors are Fast-RCNN, Faster-RCNN, and Mask-RCNN, and one-stage detectors involve YOLO (YouOnly Look Once) family (Liu et al., 2021).Khan et al. conducted a research where they ran three differentmodels, Faster-RCNN, YOLOv4, and EfﬁcientDet, to solve a similar kind of problem for apple crops (Khan et al., 2022). It has been observed that Faster RCNN with mAP (mean average precision) of 42.1%outperformed YOLOv4 (mAP of 41.4%) and Ef ﬁcientDet (mAP of 38%). As per these results, Faster-RCNN seems the right choice for this study.But YOLOv5 model developed by Ultralytics ( Glenn, 2023) has substan- tially improved the detection speed while maintaining the detection ac-curacy. Therefore, both approaches are tested in this study.3.3. Disease detection model trainingNVIDIA GeForce RTX 3090 is used to train all the models in threephases of the disease detection system. The classi ﬁcation model devel- oped in stage 1 is implemented in PyTorch (an open source machinelearning framework based on the torch library developed by MetaAI
5). Using the transfer learning (TL) approach, ResNet-50 pre-trainedon ImageNet is used (Russakovsky et al., 2015). The pre-trained model
Fig. 3.Example of different augmentation operations applied on original image.
Table 1Distribution of crop information in the used dataset among the studied crops.Crop Healthy Diseased TotalDisease 1 Disease 2Lettuce 240 280 280 800Basil 240 280 –520 Spinach 240 280 280 800Parsley 240 280 –520
5https://pytorch.org/hub/pytorch_vision_resnet/ .R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
5saves a lot of time as it is already trained on some dataset and hencecontains the weights and biases of previous training that represent thefeatures of the dataset it was trained on, which are often transferableto different datasets (Abbas et al., 2021). Hence, model parameters are initialized using the TL approach and then retrained on a custom datasetprepared insection 3.1.1with a learning rate of 0.0001, a batch size of64, an input size of 224×224×3, and 100 epochs. The modelwas tuned using the Adam optimizer. For the classi ﬁcation model in phase 2, a batch size of 64 is used, and values of the remaininghyperparameters are kept the same.For training the object detection models, the dataset is split into 75%for training, 20% for validation, and 5% for testing. The ﬁrst model is im- plemented in Detectron2 that uses pre-trained architecture (trained onCOCO dataset)‘Faster-RCNN with ResNet-101 + FPN ’. The model uses COCO JSON annotation format and is trained for 3000 iterations withthe initial learning rate of 0.01 for theﬁrst 500 iterations and then 0.001 for the next 2500 iterations.The second model, YOLOv5s, is implemented in PyTorch. Again, apre-trained version of the algorithm is used to enhance the training pro-cess and reduce time. For YOLOv5s, the annotation format is YOLODarknet TXT but with the addition of a YAML ﬁle containing model con- ﬁguration and class values. The model is trained for 3000 iterations. Thehyperparameters and their values for the two models are shown inTable 2.3.4. Ontology modelThe complete development and details of all the concepts and in-stances of ontology model‘AquaONT’developed by authors are avail- able at (Abbasi et al., 2021b). AquaONT is a uniﬁed ontology model that represents and stores the essential knowledge of an aquaponics4.0 system. It consists of six concepts: Consumer Product, Ambient Envi-ronment, Contextual Data, Production System, Product Quality, and Pro-duction Facility. In this study, two classes, ‘Consumer Product’and ‘Product Quality’are used for knowledge extraction. The ‘Consumer Product’class provides an abstract view of the type, growth status,and growth parameters of ready-to-harvest crops in an aquaponics sys-tem. Whereas the‘Product Quality’class provides knowledge on cropattributes related to pathology (crop diseases, causes, and the waysand means by which these can be managed or controlled) and morphol-ogy (canopy dimensions such as area, length, width, etc.). Four crops:lettuce, basil, parsley, and spinach, are considered in this study. Theirgrowth conditions and morphological and pathological attributes storedas instances of the respective classes are extracted once the crop anddisease are classiﬁed.Fig. 5shows the hierarchical architecture of the‘Consumer Product’and‘Product Quality’classes with their instances for the‘Basil’crop in Protégé
6(an open-source ontology editor andframework developed at Stanford University) environment.3.5. Cloud-based applicationThe trained model of the crop disease detection system is then savedand deployed on a cloud-based application built on Streamlit. The ontol-ogy model‘AquaONT’is also deployed on application, and relevant clas-ses are integrated with theﬁnal disease detection model throughOwlready2 library. The layout of the application is shown in Fig. 6.I t consists of two user inputs‘Select Model’and‘Upload Image’.‘Select Model’provides an option to select the model as per requirement,which in this study are‘Crop Classiﬁcation’referring to phase 1,‘Disease or No Disease’referring to phase 2, and‘Disease Type, causes and Treat- ments’referring to phase 3 of the proposed disease detection system.
Fig. 4.Detailed pipeline for the crop diagnostic process.
Table 2Values of hypermeters used for two objection detection methods.Hyperparameters MethodsFaster-RCNN YOLOv5sInput size 600 × 600 416 × 416Batch size 16 16Learning rate 0.001 lr
0= 0.01, lr f= 0.001 Momentum 0.89 0.937Gamma value 0.1 ﬂ_gamma = 0.0 Weight decay 0.0001 0.0005Training time 1.5 h 50 min
6https://protege.stanford.edu/products.php#desktop-protege .R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
6After model selection, an image is uploaded which is used by all themodels. Once the disease is detected and classi ﬁed, the causes and treat- ments of the disease are extracted from the ontology model automati-cally and displayed on the application panel. This kind of informationis useful as it will allow agricultural practitioners to determine thecauses of diseases and take precautionary steps in the early stages toavoid crop wastage and economic loss.4. Experimental results and discussionThis section presents the results of experiments performed in thecurrent research work. First, the performance evaluation of deep learn-ing models in three phases of the disease detection system is discussed.Next, the trained and validated system is tested on new data. In the end,the signiﬁcance of the complete system is presented.T h ep e r f o r m a n c eo ft h ec l a s s iﬁcation model in phase 1 is evalu-ated using a validation dataset. For this phase, there are four classesto be classiﬁed, namely lettuce, basil, spinach, and parsley. The distri-bution of labeled images in the validation set for this model is showninTable 3.The performance of the model is presented in the form of a confu-sion matrix (CM) shown inFig. 7. The overall accuracy, precision, recall,and F-measure are computed by using the respective formulae, follow-ing common metrics for the performance of deep learning models in theliterature (Khan et al., 2022). The computed metrics are summarized inTable 4.The classiﬁcation model in phase 1 has achieved an overall accuracyof 95.83%, average precision of 96.25%, average recall of 96%, and aver-age F1-score of 96.25%. As noted inTable 4, the performance metrics of the‘spinach’class are lower than the other classes. Most model con-fusion comes in between spinach, basil, and lettuce leaves, particularlyduring the initial stages of their growth cycle.Next, the performance of the classiﬁcation model in phase 2 is eval- uated in a similar fashion. For phase 2, there are six classes that modelclassiﬁes, which are mentioned insection 3.2.Table 5shows the distri- bution of the validation set used for the model in phase 2.The CM for this model is shown inFig. 8and performance metrics are summarized inTable 6.The classiﬁcation model in phase 2 has achieved an overall accuracyof 94.13%, average precision of 94%, average recall of 94%, and averageF1-score of 93.6%. It can be observed from the CM in Fig. 8that the model is also prone to confusion in distinguishing between some ofthe classes. For instance, six examples of LD (Lettuce-Diseased) are clas-siﬁed among LH (1), BD (1), SH (2), and SD (2). This might be due to alack of clarity in identifying leaf patterns and diseased spots.Finally, the performance of selected models for the detection phase(phase 3) is evaluated using a validation dataset. For this phase, thereare six different diseases that models have to detect in crop leaves.These six diseases and their distribution in the validation dataset aregiven inTable 7.In this phase, the metric that is used to evaluate and compare theperformance of two models, i-e, Faster-RCNN, and YOLOv5s, is mean av-erage precision (mAP). The mAP is the primary evaluation indicatorused for the evaluation of object detection models ( Khan et al., 2022). In particular, mAP
@0.5(mean value of mAP at IOU threshold = 0.5) isevaluated. The comparison of the two models against all the classes ispresented inTable 8. It can be seen that YOLOv5s with mAP
@0.5of 82.13% have outperformed Faster R-CNN. The two models haveachieved the best mAP score for Lettuce-Bacterial Leaf Spot (LBS),Parsley-Septoria Leaf Spot (PSS), and Spinach-Stemphylium Leaf Spot(SSS), whereas a low mAP score is observed for Lettuce-Downy Mildew(LDM), Basil-Downy Mildew (BDM), and Spinach-Downy Mildew(SDM). Downy Mildew initially causes light green to yellow angularspots on the upper surfaces of leaves and hence looks similar indepen-dently of the crop type. This causes confusion for the detector in distin-guishing the crop-speciﬁc Downy Mildew. But with more data, thisissue can easily be resolved. Later in the growth cycle, the plant tissueaffected with Downy Mildew turns tan in spinach, purplish brown in
Fig. 5.Hierarchical structure of ‘Consumer Product’and‘Product Quality’classes and respective instances in relation to Basil Crop.R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
7basil, and light brown in lettuce, which are correctly identi ﬁed by the detector.The performance evaluations of models in three phases have shownthat detection models are not as straightforward as classi ﬁcation models. This is because an image consists of many objects which belongto either the same class or different classes. Hence, three things must beveriﬁed during evaluation, including object class, bounding box (objectlocation), and conﬁdence.In the end, the two detection models are compared in terms of infer-ence time which is an important metric that determines the detectionspeed. It is observed that one-stage detector i-e., YOLOv5s with a
Fig. 6.Layout of cloud-based application for disease detection.
Table 3Dataset distribution of validation set for phase 1.Class (Health + Diseased) Number of imagesLettuce 160Basil 104Spinach 160Parsley 104
Fig. 7.Confusion matrix of classiﬁcation results in phase 1.R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
8detection speed of 52.8 FPS (frames per second) is faster than Faster-RCNN with a detection speed of 43.2 FPS. Moreover, it is also observedthat YOLOv5s accurately detect objects of varying sizes with little tono overlapping boxes. All the comparisons between the two detectionmodels show that YOLOv5s have a clear advantage in terms of accuracyand run speed. Therefore, in this study, YOLOv5s is used for developingthe disease detection system.After training and validation, theﬁnal crop disease detection system with YOLOv5s is tested using the test set containing new images. Thesystem has shown promising results by effectively classifying and de-tecting the diseases in speciﬁed crops, which shows the system's ro-bustness in terms of dealing with a variety of objects having differentshapes, patterns, textures, and colors. Fig. 9shows examples where the system has accurately classiﬁed the crop and detected the diseasedand healthy spots in crop leaves. Images in the ﬁrst row ofFig. 9are the results from three phases of the disease detection system for the Lettucecrop, which is suffering from Bacterial Leaf Spot disease. Similarly, row 2and row 3 are the results from three phases of the system showing Spin-ach and Parsley, respectively, and the diseases they are suffering from,such as Downy Mildew and Septoria Leaf Spot disease respectively.Theﬁnal crop disease detection system is then deployed on a cloud-based application developed insection 3.5.Fig. 6shows the layout of the application. The ontology model discussed in section 3.4is also inte- grated with theﬁnal system to build a complete real-time crop diagnos-tic system. The images are acquired wirelessly from the aquaponicsfacility through an interface developed on the Google Cloud PlatformTable 4Results of classiﬁcation model in phase 1.Crop Accuracy Precision Recall F1-ScoreLettuce 0.97 0.95 0.96 0.96Basil 0.98 0.96 0.96 0.96Spinach 0.96 0.94 0.94 0.94Parsley 0.99 1 0.98 0.99Average –96.25% 96% 96.25% Overall accuracy 95.83%
Table 5Distribution of validation dataset for phase 2.Class Number of imagesLettuce-Healthy (LH) 48Lettuce-Diseased (LD) 112Basil-Healthy (BH) 48Basil-Diseased (BD) 56Spinach-Healthy (SH) 48Spinach-Diseased (SD) 112Parsley-Healthy (PH) 48Parsley-Diseased (PD) 56
Fig. 8.Confusion matrix of classiﬁcation results in phase 2.Table 6Performance metrics of classiﬁcation model in phase 2.Class Accuracy Precision Recall F1-scoreLH 0.979 0.86 0.92 0.89LD 0.981 0.96 0.95 0.95BH 0.989 0.90 0.98 0.94BD 0.983 0.91 0.93 0.92SH 0.981 0.91 0.88 0.89SD 0.983 0.96 0.96 0.96PH 0.994 0.98 0.96 0.97PD 0.992 0.98 0.96 0.97Average –94% 94% 93.6% Overall accuracy 94.13%
Table 7Distribution of validation dataset in phase 3.Class Number of imagesLettuce-Bacterial Leaf Spot (LBS) 56Lettuce-Downy Mildew (LDM) 56Basil-Downy Mildew (BDM) 56Parsley-Septoria Leaf Spot (PSS) 56Spinach-Downy Mildew (SDM) 56Spinach- Stemphylium Leaf Spot (SSS) 56R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
9by the authors in previous work (Abbasi et al., 2022b). The images are stored in a folder to be used by the crop diagnostic system. Once thecrop type and its disease are identiﬁed, the causes and treatments areautomatically extracted from the ontology model and displayed on theapplication panel. For instance,Fig. 6shows an example of working crop diagnostic system for parsley crops. The disease detected by thesystem after image uploading is Septoria Leaf Spot. The crop diagnosticsystem extracts the knowledge about potential causes and generaltreatments of this disease from AquaONT. The primary causes ofSeptoria Leaf Spot in Parsley could be high humidity level, infectedseeds, leaf wetness, etc. This disease could also be caused due to irregu-lar variations in air temperature. The potential preventive measures andtreatments suggested by the system for this disease include:maintaining optimal humidity and temperature levels in accordancewith Parsley crop and indoor aquaponics environment throughout thegrowth cycle, treating seeds before germination with hot water orClorox bleach, using conventional fungicides if the disease is spreadout in multiple plants. Downy Mildew disease is one of the most com-mon diseases observed in different crops ( McGrath, 2021). In the greenhouse or indoor farming environment, the potential causes ofthis disease are the same irrespective of crop type, which includes:high humidity, cool temperatures, infected seeds, and leaf wetness(Margaret TuttleMcGrath, 2021). Therefore, the methods to treatDowny Mildew in lettuce, basil, and spinach are also similar. Thismeans that the classiﬁcation of Downy Mildew disease with respect tocrop type does not impact the results related to disease treatments. De-spite this independence, it is still signiﬁcant to perform the classiﬁcation of Downy Mildew for each crop individually as its symptoms for threecrops, lettuce, basil, and parsley, change later in the growth cycle. Thismight cause confusion for the detector to distinguish Downy Mildewfrom other diseases. For instance, the lettuce tissue affected withDowny Mildew eventually turns brown in later stages and these symp-toms are similar to the Bacterial Leaf Spot symptom in lettuce, and bothdiseases have different treatment methods.The signiﬁcance of the proposed system is that it can act as a vitaltool for agriculturalists who wants to develop and digitize aquaponicsfarm. This system will allow them to diagnose diseases at early stagesand also assist them in decision-making regarding crop characteristicsTable 8Class-wise comparison of two detection models.Class mAPFaster-RCNN YOLOV5sLettuce-Bacterial Leaf Spot (LBS) 77.32 83.86Lettuce-Downy Mildew (LDM) 73.89 78.63Basil-Downy Mildew (BDM) 75.47 80.11Parsley-Septoria Leaf Spot (PSS) 78.63 84.55Spinach-Downy Mildew (SDM) 74.19 79.87Spinach-Stemphylium Leaf Spot (SSS) 79.52 85.74mAP
@0.5 76.34 82.13
Fig. 9.Results from proposed disease detection system.R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
10and treatments of diseases. Moreover, this study will also promote theintroduction of new implementations, such as research on the complexrelationship between dynamic parameters (environmental and water)and diseases in aquaponics farms and self-adapting farms in case of dis-ease detection. These smart technologies in the aquaponics system willreduce crop wastage and ensure both economic and environmentalbeneﬁts.5. Conclusions and future prospectsThis study proposes a crop diagnostic system for leafy green cropsgrown in an aquaponics environment. Four leafy green crops, lettuce,basil, spinach, and parsley, are considered. The ﬁrst dataset is devel- oped that contains 2640 healthy and diseased images of these fourcrops collected from various sources. Next, a system is proposedthat can efﬁciently and effectively identify crops and diseases. Thedetection system works in three phases. The ﬁrst phase classiﬁes the crop type, the second phase classiﬁes whether the crop is healthy or diseased, and then in the third phase, the disease is detected if thecrop is classiﬁed as diseased in the previous phase. All the modelsused in this study are initialized using transfer learning and thentrained on a dataset prepared for leafy green crops. The performanceof the models is evaluated, and promising results are achieved. For in-stance, in the detection phase, YOLOv5s with mAP
@0.5of 82.13% and detection speed of 52.8 FPS has outperformed Faster-RCNN. Basedon the performance, YOLOv5s is selected as a ﬁnal model for this study. The ontology model that contains knowledge related to causesand treatments of diseases is then integrated with the ﬁnal crop dis- ease detection system. Finally, a cloud-based application is designedwhere theﬁnal crop diagnostic system consisting of a disease detec-tion system and ontology model is deployed. The proposed systemproves to be accurate andﬂexible enough to be used in real scenariosand hence is not limited to being disturbed by potential changingconditions and environments. It can be a helpful tool for agriculturalpractitioners who want to explore modern farming practices andwant to integrate smart techniques into their farms. This systemwill not only help them in disease diagnosis and quanti ﬁcation but will also assist them in decision-making regarding potential treat-ments against identiﬁed diseases at early stages.For future work, the system will be extended to include other leafygreen crops. Moreover, the dataset will also be extended, and morereal-ﬁeld images will be incorporated. Moreover, a mobile applicationwill be constructed, reducing the latency, and providing data privacy,which normally occurs in cloud-based systems.CRediT authorship contribution statementR. Abbasi:Conceptualization, Methodology, Software, Validation,Formal analysis, Visualization, Investigation, Data curation, Writing – original draft, Writing–review & editing.P. Martinez:Conceptualiza- tion, Methodology, Visualization, Writing –review & editing, Supervision.R. Ahmad:Supervision, Funding acquisition, Projectadministration, Writing–review & editing.Declaration of Competing InterestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to in ﬂu- ence the work reported in this paper.AcknowledgmentsThe authors acknowledge theﬁnancial support of this work from theNatural Sciences and Engineering Research Council of Canada (NSERC)(Grant File No. ALLRP 545537-19 and RGPIN-2017-04516).ReferencesAbbas, A., Jain, S., Gour, M., Vankudothu, S., 2021. Tomato plant disease detection usingtransfer learning with C-GAN synthetic images. Comput. Electron. Agric. 187,106279.https://doi.org/10.1016/J.COMPAG.2021.106279 . Abbasi, R., Martinez, P., Ahmad, R., 2021a. An ontology model to support the automateddesign of aquaponic grow beds. Proced. CIRP 100, 55 –60.https://doi.org/10.1016/j. procir.2021.05.009.Abbasi, R., Martinez, P., Ahmad, R., 2021b. An ontology model to represent aquaponics 4.0system’s knowledge. Inf. Process. Agric. https://doi.org/10.1016/J.INPA.2021.12.001 . Abbasi, R., Martinez, P., Ahmad, R., 2022a. The digitization of agricultural industry –a sys- tematic literature review on agriculture 4.0. Smart Agric. Technol. 2, 100042. https:// doi.org/10.1016/J.ATECH.2022.100042 . Abbasi, R., Martinez, P., A.R, 2022b. Data acquisition and monitoring dashboard for IoT en- abled aquaponics facility. The 10th International Conference on Control,Mechatronics and Automation (ICCMA 2022) (Accepted). IEEE.Anami, B.S., Malvade, N.N., Palaiah, S., 2020. Deep learning approach for recognition andclassiﬁcation of yield affecting paddy crop stresses using ﬁeld images. Artif. Intell. Agric. 4, 12–20.https://doi.org/10.1016/J.AIIA.2020.03.001 . Barosa, R., Hassen, S.I.S., Nagowah, L., 2019. Smart aquaponics with disease detection. 2ndInt. Conf. Next Gener. Comput. Appl. 2019, NextComp 2019 - Proc https://doi.org/10. 1109/NEXTCOMP.2019.8883437 . Bedi, P., Gole, P., 2021. Plant disease detection using hybrid model based on convolutionalautoencoder and convolutional neural network. Artif. Intell. Agric. 5, 90 –101.https:// doi.org/10.1016/J.AIIA.2021.05.002 . Buslaev, A., Iglovikov, V.I., Khvedchenya, E., Parinov, A., Druzhinin, M., Kalinin, A.A., 2020.Albumentations: Fast andﬂexible image augmentations. Inf. 11. https://doi.org/10. 3390/INFO11020125.Chen, J., Zhang, D., Nanehkaran, Y.A., Li, D., 2020. Detection of rice plant diseases based ondeep transfer learning. J. Sci. Food Agric. 100, 3246 –3256.https://doi.org/10.1002/ JSFA.10365.Dhal, S.B., Bagavathiannan, M., Braga-Neto, U., Kalafatis, S., 2022. Nutrient optimizationfor plant growth in Aquaponic irrigation using machine learning for small trainingdatasets. Artif. Intell. Agric. 6, 68 –76.https://doi.org/10.1016/J.AIIA.2022.05.001 . Dutot, M., Nelson, L.M., Tyson, R.C., 2013. Predicting the spread of postharvest disease instored fruit, with application to apples. Postharvest Biol. Technol. 85, 45 –56.https:// doi.org/10.1016/J.POSTHARVBIO.2013.04.003 . Fan, X., Zhou, J., Xu, Y., Peng, X., 2021. Corn disease recognition under complicated back-ground based on improved convolutional neural network. Nongye Jixie Xuebao/transactions Chinese Soc. Agric. Mach. 52, 210 –217.https://doi.org/10.6041/J.ISSN. 1000-1298.2021.03.023.Fuentes, A., Yoon, S., Kim, S.C., Park, D.S., 2017. A robust deep-learning-based detector forreal-time tomato plant diseases and pests recognition. Sensors 17, 2022. https://doi. org/10.3390/S17092022.Gillani, S.A., Abbasi, R., Martinez, P., Ahmad, R., 2022. Review on energy ef ﬁcient artiﬁcial illumination in aquaponics. Clean. Circ. Bioecon. 2, 100015. https://doi.org/10.1016/J. CLCB.2022.100015
.Glenn, 2023. Ultralytics/yolov5 [WWW Document]. URL. https://github.com/ultralytics/ yolov5.He, K., Zhang, X., Ren, S., Sun, J., 2015. Deep residual learning for image recognition. Proc.IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. 2016-December, pp. 770 –778 https://doi.org/10.48550/arxiv.1512.03385 . Horrocks, I., Patel-Schneider, P.F., Bechhofer, S., Tsarkov, D., 2005. OWL rules: a proposaland prototype implementation. Web Semant. https://doi.org/10.1016/j.websem. 2005.05.003.Jearanaiwongkul, W., Anutariya, C., Racharak, T., Andres, F., 2021. An ontology-based ex-pert system for Rice disease identi ﬁcation and control recommendation. Appl. Sci. 11, 10450.https://doi.org/10.3390/APP112110450 . Jha, K., Doshi, A., Patel, P., Shah, M., 2019. A comprehensive review on automation in ag-riculture using artiﬁcial intelligence. Artif. Intell. Agric. 2, 1 –12.https://doi.org/10. 1016/J.AIIA.2019.05.004.Khan, A.I., Quadri, S.M.K., Banday, S., Latief Shah, J., 2022. Deep diagnosis: a real-timeapple leaf disease detection system based on deep learning. Comput. Electron.Agric. 198, 107093.https://doi.org/10.1016/J.COMPAG.2022.107093 . Khirade, S.D., Patil, A.B., 2015. Plant disease detection using image processing. Proc. - 1stInt. Conf. Comput. Commun. Control Autom. ICCUBEA 2015, pp. 768 –771.https://doi. org/10.1109/ICCUBEA.2015.153 . Lisha Kamala, K., Anna Alex, S., 2021. Apple fruit disease detection for hydroponic plantsusing leading edge technology machine learning and image processing. Proc. - 2ndInt. Conf. Smart Electron. Commun. ICOSEC 2021, pp. 820 –825.https://doi.org/10. 1109/ICOSEC51865.2021.9591903 . Liu, C., Zhu, H., Guo, W., Han, X., Chen, C., Wu, H., 2021. EFDet: an ef ﬁcient detection method for cucumber disease under natural complex environments. Comput. Elec-tron. Agric. 189, 106378.https://doi.org/10.1016/J.COMPAG.2021.106378 . Ma, J., Du, K., Zheng, F., Zhang, L., Sun, Z., 2018. Disease recognition system for greenhousecucumbers based on deep convolutional neural network. Nongye GongchengXuebao/transactions Chinese Soc. Agric. Eng. 34, 186 –192.https://doi.org/10.11975/ J.ISSN.1002-6819.2018.12.022. Mathew, M.P., Mahesh, T.Y., 2022. Leaf-based disease detection in bell pepper plant usingYOLO v5. Signal, Image Video Process. 16, pp. 841 –847.https://doi.org/10.1007/ S11760-021-02024-Y/FIGURES/12 . McGrath, Margaret Tuttle, 2021. Pest management [WWW Document]. Cornell Univ URLhttps://www.vegetables.cornell.edu/pest-management/ accessed 8.3.22. Musa, A., Hamada, M., Aliyu, F.M., Hassan, M., 2021. An intelligent plant Dissease detec-tion system for smart hydroponic using convolutional neural network. Proc. - 2021R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
11IEEE 14th Int. Symp. Embed. Multicore/Many-Core Syst. MCSoC 2021, pp. 345 –351. https://doi.org/10.1109/MCSOC51149.2021.00058 . Nandhini, M., Kala, K.U., Thangadarshini, M., Madhusudhana Verma, S., 2022. Deep learn-ing model of sequential image classi ﬁer for crop disease detection in plantain tree cultivation. Comput. Electron. Agric. 197, 106915. https://doi.org/10.1016/J. COMPAG.2022.106915.Nguyen, N.D., Do, T., Ngo, T.D., Le, D.D., 2020. An evaluation of deep learning methods forsmall object detection. J. Electr. Comput. Eng. 2020. https://doi.org/10.1155/2020/ 3189691.Noyan, M.A., 2022. Uncovering Bias in the Plant Village Dataset. https://doi.org/10.48550/ arxiv.2206.04374.Oppenheim, D., Shani, G., Erlich, O., Tsror, L., 2019. Using deep learning for image-basedpotato tuber disease detection. Phytopathology 109, 1083 –1087.https://doi.org/10. 1094/PHYTO-08-18-0288-R. Pathan, M., Patel, N., Yagnik, H., Shah, M., 2020. Arti ﬁcial cognition for applications in smart agriculture: a comprehensive review. Artif. Intell. Agric. 4, 81 –95.https://doi. org/10.1016/J.AIIA.2020.06.001 . Paymode, A.S., Malode, V.B., 2022. Transfer learning for multi-crop leaf disease imageclassiﬁcation using convolutional neural network VGG. Artif. Intell. Agric. 6, 23 –33. https://doi.org/10.1016/J.AIIA.2021.12.002 . Qi, J., Liu, X., Liu, K., Xu, F., Guo, H., Tian, X., Li, M., Bao, Z., Li, Y., 2022. An improved YOLOv5model based on visual attention mechanism: application to recognition of tomatovirus disease. Comput. Electron. Agric. 194, 106780. https://doi.org/10.1016/J. COMPAG.2022.106780.Rahman, C.R., Arko, P.S., Ali, M.E., Iqbal Khan, M.A., Apon, S.H., Nowrin, F., Wasif, A., 2020.Identiﬁcation and recognition of rice diseases and pests using convolutional neuralnetworks. Biosyst. Eng. 194, 112 –120.https://doi.org/10.1016/J.BIOSYSTEMSENG. 2020.03.020.Rodríguez-García, M.Á., García-Sánchez, F., Valencia-García, R., 2021. Knowledge-basedsystem for crop pests and diseases recognition. Electron 10, 905. https://doi.org/10. 3390/ELECTRONICS10080905. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A.,Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2015. ImageNet large scale visualrecognition challenge. Int. J. Comput. Vis. 115, 211 –252.https://doi.org/10.1007/ S11263-015-0816-Y.Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., Batra, N., 2019. PlantDoc: a dataset forvisual plant disease detection. ACM Int. Conf. Proceeding Ser. 249 –253.https://doi. org/10.1145/3371158.3371196 . Singh, V., Sharma, N., Singh, S., 2020. A re view of imaging techniques for plant dis- ease detection. Artif. Intell. Agric. 4, 229 –242.https://doi.org/10.1016/J.AIIA. 2020.10.002.Stouvenakers, Gilles, Dapprich, Peter, Massart, Sebastien, Jijakli, M.H., Stouvenakers, G.,Massart, S., Jijakli, M.H., Dapprich, P., 2019. Plant pathogens and control strategiesin aquaponics. Aquapon. Food Prod. Syst. 353 –378.https://doi.org/10.1007/978-3- 030-15943-6_14.Studer, R., Benjamins, V.R., Fensel, D., 1998. Knowledge engineering: principles andmethods. Data Knowl. Eng.https://doi.org/10.1016/S0169-023X(97)00056-6
. Subeesh, A., Mehta, C.R., 2021. Automation and digitization of agriculture using arti ﬁcial intelligence and internet of things. Artif. Intell. Agric. 5, 278 –291.https://doi.org/10. 1016/J.AIIA.2021.11.004.Weaver, W.N., Ng, J., Laport, R.G., 2020. LeafMachine: using machine learning to automateleaf trait extraction from digitized herbarium specimens. Appl. Plant Sci. 8. https:// doi.org/10.1002/APS3.11367. Yanes, A.R., Martinez, P., Ahmad, R., 2020. Towards automated aquaponics: a review onmonitoring, IoT, and smart systems. J. Clean. Prod. https://doi.org/10.1016/j.jclepro. 2020.121571.Yudha Pratama, I., Wahab, A., Alaydrus, M., 2020. Deep learning for assessing unhealthylettuce hydroponic using convolutional neural network based on faster R-CNN withInception V2. 2020 5th Int. Conf. Informatics Comput. 2020. ICIC. https://doi.org/10. 1109/ICIC50835.2020.9288554 . Zheng, Y.Y., Kong, J.L., Jin, X.B., Wang, X.Y., Su, T.L., Zuo, M., 2019. CropDeep: the crop vi-sion dataset for deep-learning-based classi ﬁcation and detection in precision agricul- ture. Sensors 19, 1058.https://doi.org/10.3390/S19051058 .R. Abbasi, P. Martinez and R. Ahmad Artiﬁcial Intelligence in Agriculture 10 (2023) 1 –12
12