 AASRI Procedia   1  ( 2012 )  468 ‚Äì 473 
2212-6716 ¬© 2012 Published by Elsevier Ltd. doi: 10.1016/j.aasri.2012.06.073 
 2012AASRI Conference on Computational Intelligence and Bioinformatics  
A Sentence Alignment Model Based on Combined Clues and Kernel Extensional Matrix Matching Method 
Wu Honglina, Liu Yiyanga,*,  Liu Shaominga,b 
aNortheastern University, Shenyang, 110004, China; 
bFuji Xerox Co., Ltd., Kanagawa, 2208668, Japan   
Abstract 
A sentence alignment model based on combined clues and Kernel Extensional Matrix Matching (KEMM) method is proposed. In this model, a similarity matrix for sentence aligning is formed by the similarities of bilingual sentences calculated by the combined clues, such as lexicon, morphology, length and special symbols, etc.; then this similarity matrix is used to construct a select matrix for sentence aligning; finally, obtains the sentence alignments by KEMM. Experimental results illustrated that our model outperforms over the Gale‚Äôs system on handling any types of sentence alignments, with 30% total sentence alignment error rate decreasing. 
 2012 Published by Elsevier B.V. Selection and/or peer review under responsibility of American Applied Science Research Institute  
Key Words ÀñSentence AlignmentÀà Combined CluesÀàKernel Extensional Matrix Matching 
1. Introduction In various fields of research on natural language processing, the importance of bilingual corpus is more and more obvious. Different applications call for aligne d bilingual corpus of different granularities and corresponding technology, which includes article, paragraph, sentence, phrase and word level. Sentence level aligned bilingual corpus is indispensable to example based machine translation. 
  
*Liu Yiyang. Tel.: +86-24-83672480. E-mail address: lyy880315@yahoo.cn. 
AASRI
Procedia
www.elsevier.com/locate/procediaAvailable online at www.sciencedirect.com
Open access under CC BY-NC-ND license.
Open access under CC BY-NC-ND license.469  Wu Honglin et al.  /  AASRI Procedia   1  ( 2012 )  468 ‚Äì 473 
 A sentence alignment model based on combined clue s and KEMM method is proposed. In this model, a similarity matrix for sentence aligning is formed by the similarities of bilingual sentences calculated by the combined clues; then this similarity matrix is used to construct a select matrix for sentence aligning; finally, obtains the sentence alignments by KEMM. 2.  Similarities of Bilingual Sentences Calculated By the Combined Clues To the translations needed to have sentence alignmen t for Chinese text C and Japanese text J, we assume that the number of C is m and to be expressed as C=CS
1CS 2‚Ä¶CS m , the number of J is n and to be expressed as J=JS
1JS2‚Ä¶JS n. The similarities of all bilingual sentences calculated  by the combined clues included lexicon, morphology and length. Results by each approach are summed up after multiplied by different weights and then plus special symbols similarity to be the final similarity between Chinese and Japanese sentences. The formula to calculate similarity of Chinese sentence CS
h and Japanese sentence JS k:  
) , ( ) , () , () , () , ( kJShCS SValuekJShCSSimLength kJShCSSimMorphkJShCS SimDictkJShCS Simuu u  JED                       (1) ¬¢,¬£and¬§ are the weights, and¬¢+¬£+¬§=0.8; 0ƒ∞SValue(CS
h,JSk)ƒ∞0.2. 2.1. Based on Bilingual Dictionary In this calculating method, sentences are expressed as a set of words. Chinese and Japanese sentences are expressed as 
} , , , {2 1mh c c c CS" and } , , , {2 1nk j j j JS" .Similarity calculatingbased on bilingual dictionary (SimDict) is: 
k hk hJS CSTransSetJTransSetCJS CS SimDict ) , (      (2) |CS
h| and |JS k| are the number of content words in Chinese and Japanese, |TransSetC|and  |TransSetC| are the number of content words that have translations. 2.2.  Based on Font Sentence is expressed as a set of characters in calculating. Chinese and Japanese sentences are expressed as 
} , , , {2 1rh cc cc cc CS"  and } , , , {2 1sk jc jc jc JS"  . The calculating method based on font: 
k hk hJS CSMorphSetJMorphSetCJS CSSimMorph ) , (                          (3) |CS
h| and |JS k| are the number of characters in sentences, |MorphSetC| is the number of the same Chinese characters CS
hhave inJS k. |MorphSetJ| is the number of the same Chinese characters JS k have in CS h. 2.3. Based on Sentence Length Block=<C,J> is proposed as a translation block that have been aligned. Then alignment A=P
1P2P3‚Ä¶P k. Pi(1 ƒ∞iƒ∞k) is a couple of translation and P
i=<CS i,JSi>; CS i is a set of Chinese sentences, it expresses from zero to more sentences in C; JS
i is a set of Japanese sentences, it expresses from zero to more sentences in J. In a couple of translation P=ÀòCS,JS>, to propose that l
1=length(CS) is the length of CS and l 2=length(JS) is the length of JS.In a word, l
1«Él2 are the number of characters in CS and JS. To the translation block 470   Wu Honglin et al.  /  AASRI Procedia   1  ( 2012 )  468 ‚Äì 473 
 
 Block=<C,J>, sentence alignment based on length statistic is to look for the one has the largest probability in all probable alignment A. Condition below must be met: 
) , |Pr(maxarg) |Pr(maxarg!   J C ABlock AA                 (4) To propose that each couple of translation is absolutely, and Pr(P|<C,J>) is not depend on translation block, it‚Äôs only decided by P=<CS,JS>. It can be thought base d on statistic that Pr(P|<CS,JS>) is only decided by matching pattern match(P) of P and the length of CS and JS.  Since the Bayesian theory: 
)) (Pr()) ( | ,Pr(maxarg2 1 P matchP match l lA
A PA¬ò!  ¬ñ
¬è            (5) Pr(match(P)) is the matching probability. To propose that 
) , (2 1l lG  is a function satisfied Standard normal distribution, and  the key of model above is the design of the evaluate function 
) , (2 1l lG . It‚Äôs given in Gale: 
211 22 1) , (s ll c ll l¬ò¬ò  G                     (6) 
¬¶ ¬¶
¬è ¬è 
TC P TC Pl l c1 2 / , s2is the slope of the line that the result of all points ) ) ( , (21 2 1l l l  in training corpus being linear regression analyzed. s
2 is a normalization factor to make sure ) , (2 1l lG  is a normal distribution. To the Chinese and Japanese sentence alignment, c=1.06 and S
2=6.8 are from the statistic of the corpus. In Gale test, Pr(match(P)) in formula(6) is a pena lty factor to multi-alignment. Since the sentence alignment model in this paper is a method of combin ing some different approaches, the final alignment similarity needs a penalty calculating. Then formula(6) becomes: 
¬ñ
¬è 
A PAk hP match l lJS CS SimLen)) ( | ) , (Pr(maxarg) , (2 1G          (7) 2.4. Based on Special Character Numbers (such as 1978, 03, 24, etc.), English characters (such as China, Henry, etc.), quotation marks and brackets are used to calculate the similarity of Chines e and Japanese special characters. The maximum value of special characters‚Äô similarity (SValue) is set as 0.2. When CS
h and JS k have the same special characters, SValue(CS
h,JSk) is added 0.05, and it‚Äôs added to 0.2 for max. It is a supplement for the similarity calculating of SimDict,SimMorph and SimLength. 2.5. Multi-alignment Penalty Factor Multi-alignment penalty factor is to deal with alignm ent conflict. For an instance, when aligned conflicts happen and judge if the style is 1-2 or the two aligned 1-1 and 0-1, we need to calculate the similarity of these three kinds and then multiply the corresponding penalty factor. Then we can compare their similarity modified. We stat the proportion of different alignment in Chinese and Japanese corpus including 9679 aligned sentences. Combining researches to set the penalty factor (»ü) as the table 1 shows. 
Table 1 Penaltyfactor for multi-alignment Alignment style Penalty factor(»ü) 
1-2;2-1 0.95 
2-2 0.60 1-0;0-1 0.55 471  Wu Honglin et al.  /  AASRI Procedia   1  ( 2012 )  468 ‚Äì 473 
 3. SentenceMatching Based on Kernel Extensional Matrix Method 3.1. Alignment Similarity Matrix and Alignment Selecting Matrix       An alignment similarity two-dimensional matrix  (SimMatrix) is constructed by Chinese and Japanese sentences that the number of them is m and n. The element in the matrix is the similarity. 
) , ( ] ][ [k hJS CS Sim k h SimMatrix                                                              (8)        Then we construct a sentence alignment selecting matrix (SelMatrix). Each element is the sorting information of the alignment similarity. 3.2. Sentence Matching       Sentence matching is to choose the alignmen t results from the sentence alignment selecting matrix. 1) Select the Alignment in ‚Äú1/1‚Äù Row       Six steps are included in this process.       Step1: According to the SelMatrix to select the location where "1/1" is. And then construct a 3h3 matrix to calculate similarity and check the probability if there is some multi-alignment.        Step2:To calculate the probability of the multi-alignment. 
  If SelMatrix[i-1][j-1] = ‚Äú1/1‚Äù and SelMatrix[i+1][j+1] = ‚Äú1/1‚Äù; 
 NCA = (CSi)-(JSj);   Else If SelMatrix[i-1][j-1] or SelMatrix[i+1][j+1] is not "1/1"  
) (maxargP SimNCA
A P¬è        MultiSim= Cal(min(SimAdd, Selmatrix[i][j]));       Compare MutiSim with NCA; 
      If MutiSim is larger than NCA, we put the mu lti-alignment into CandSet. Otherwise turn to step5.       Step3:To judge the style of new member of CandSet. Processing is according to its style.       Step4:The new multi-alignment processing can be consider ed as 10 categories, and one of them can be made formal to : If 
) ) ( ) ( : ) ( ) 1 ( : (1 CA JS JS CS i k m k kj j k¬èz ¬ö d d   
 If )) ( ) (( ) (1j j kJS JS CS Sim NCA Sim!     
)}( )/{(1j j kJS JS CS CA CA     
} {NCA CA CA¬â      return true;  return false; 
      Step5:Add the ensured alignment in the aligned queue and record the aligning status of sentences.       Step6:To judge whether all "1/1" locations are dealt with. If not, turn to step1.  2) Select the Alignment not in ‚Äú1/1‚Äù Row       This processing is to look for the locations without "1/1" and look for the minimum sum of similarity in its row. And then to judge whether cross-aligned will be happened in this location.       And the processing in column is similar with the processing above.3) Spatial Alignment Processing        Step1:To look for unaligned row. 472   Wu Honglin et al.  /  AASRI Procedia   1  ( 2012 )  468 ‚Äì 473 
 
       Step2:To select the point "1/1" in the previous row and back row. And then to calculate the similarity of the unaligned row with previous row and back row.       Step3:To compare the modified multi-alignment similarity with the point.       Step4:Accoring to the comparing results to deal with them further.       Step5:To store the results and record the alignment status. And to look for if there is any unaligned row. 4. Expriments and Results Analysis       The test set used in sentence alignment expri ment is randomly selected from the Chinese and Japanese chapter-aligned corpus and they are artifically marked standard answers of stence alignment.The test set includes 558 alignments, the style distribution shown as table 2.        To verify the effectiveness of the model put forward in this paper, we achieve the sentence alignment system with the method given in this paper. We test th e error rate of the system we construct on the test set and compare the results with Gale system which is famous in sentence alignment field. 
Table 2 Alignment types distribution of Testing set Style Distribution Distribution Rate(%) 
1-0;0-1 6 1 
1-1 505 90.5 1-2;2-1 47 8.5 
Table 3 shows the distributionof all kinds of alignment style in our test set and corpus. We can see that the distribution of our test set is approaching the distribution of our corpus. So our test set is representative, it can represent the test result of our corpus. 
Table 3 Comparison of alignment types distribution Style Test Set(%) Bilingual Corpus(%) Gale(%) 
1-0;0-1 1 0.2 1 
1-1 90.5 93.8 89 1-2;2-1 8.5 5.8 9 
We achieve the align method in Gale as beseline sy stem. But the test results of the system have differences from reference (it‚Äôs worse than the results in  reference). So the data is not faith to Gale system. We use the better experimental results from Gale shown in reference. As shown in table 3, the distribution of our test set is approaching the test set in Gale. So this comparison is faithful. Test set in Gale includes some rare alignment and they don‚Äôt appeared in our test set. Since the experiental results in Gale show that the error rate of processing the styles is 100%, the difference cannot make effects. So the comparison is sloped to Baseline. In summary, we try our best to ensure the faith and accurate in experiment. Table 4 shows the experiental results of sentence alignment.       From the table 4, we can know that our system  has a lower error rate. We analysis the test results and find that the reson for lower error rate is to use the KEMM to avoid error spreading phenomenon.        On all kinds of alignment styles our system always has a lower error rate than Gale system. The error rate of our system is 2.3% and Gale is 3.5%. The ex primental results and analysis above fully prove the effectiveness of our calculating model. 473  Wu Honglin et al.  /  AASRI Procedia   1  ( 2012 )  468 ‚Äì 473 
 Table 4 Experiment result: error rate Align Style Test Set Align Num Our Error Nu m Our Error rate (%) Gale Error rate (%) 1-0;0-1 6 2 33.3 100 
1-1 505 7 1.4 2 1-2;2-1 47 4 8.5 9 Sum 558 13 2.3 3.5 
5. Conclusion       A sentence alignment model based on combined clues and Kernel Extensional Matrix Matchingmethod is proposed in this paper.       In this model, a similarity matrix for sentence a ligning is formed by the similarities of bilingual sentences calculated by the combined clues, such as lexicon, morphology, length and special symbols, etc.; then this similarity matrix is used to construct a select matrix for sentence aligning; finally, obtains the sentence alignments by KEMM.       Experimental results illustrated that our model out performs over the Gale‚Äôs system on handling any types of sentence alignments, with 30% total sentence alignment error rate decreasing. These can prove the effectiveness of our model proposed in this paper. Acknowledgements This work was supported in part by the Fundamental Research Funds for the Central Universities of Northeastern University(N100304006). References [1] Gale W, Church K. A program for aligning sentences in bilingual corpora. Proceedings of the 29th Annual Meeting of the Association for Comput ational Linguistics. Berkeley 1991;177-184. [2] Elithorn A., Banerji R.Nagao. M.A Framework of a Mechanical Translation Between Japanese and English by Analogy Principle. Artifical and Human Inteligence. New York: Elsevier Science Publishers Corporation; 1984; 173-180. [3] Brown, R.D. Automated Generalization of Translation Examples. Proceedings of the Eighteenth International Conference on Computational Linguistics 2000;125-131. [4] Halil Altay Guvenir, Ilyas Cicekli. Learning Tr anslation Templates from Examples. Information Systems 1998; 23(6):353--363. [5] Arnold D., Balkan L., Humphreys R. Lee, Meij er S., Sadler L.. Machine Translation. 1994. 