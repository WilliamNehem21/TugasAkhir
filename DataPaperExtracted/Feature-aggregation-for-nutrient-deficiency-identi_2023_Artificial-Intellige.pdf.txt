Feature aggregation for nutrient deﬁciency identiﬁcation in chili based onmachine learning
Deffa Rahadiyana, Sri Hartatia,⁎,W a h y o n oa, Andri Prima Nugrohob
aDepartment of Computer Science and Electronics, Universitas Gadjah Mada (UGM), Yogyakarta, Indonesia
bDepartment of Agricultural and Biosystems Engineering, Universitas Gadjah Mada (UGM), Yogyakarta, Indonesia
abstract article info
Article history:Received 18 July 2022Received in revised form 5 April 2023Accepted 25 April 2023Available online 28 April 2023Macronutrient deﬁciency inhibits the growth and development of chili plants. One of the non-destructivemethods that plays a role in processing plant image data based on speci ﬁc characteristics is computer vision. This study uses 5166 image data after augmentation process for six plant health conditions. But the analysis ofone feature cannot represent plant health condition. Therefore, a careful combination of features is required.This study combines three types of features with HSV and RGB for color, GLCM and LBP for texture, and Hu mo-ments and centroid distance for shapes. Each feature and its combination are trained and tested using the sameMLP architecture. The combination of RGB, GLCM, Hu moments, and Distance of centroid features results the bestperformance. In addition, this study compares the MLP architecture used with previous studies such as SVM, Ran-dom Forest Technique, Naive Bayes, and CNN. CNN produced the best performance, followed by SVM and MLP,with accuracy reaching 97.76%, 90.55% and 89.70%, respectively. Although MLP has lower accuracy than CNN,the model for identifying plant health conditions has a reasonably good success rate to be applied in a simple ag-ricultural environment.© 2023 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Feature CombinationMulti-Layer PerceptronClassiﬁerNutrient deﬁciency
1. IntroductionLack of macronutrient or micronutrient is one of the causes for thenumber of chili production being lower than consumption inIndonesia (Bahtiar et al., 2020;Chen and Wang, 2019). Macronutrients include N, P, K, Ca, Mg, S (1000 mg/kg dry matter), and micronutrientsinclude Iron, Mn, Zn, Cu, Cl, B, and Mo (100 mg/kg dry matter)(Wulandhari et al., 2019;Tran et al., 2019). Chili plants that lack macro- nutrients show visual characteristics on the leaves, such as changes incolor, shape, and leaf texture (Taujuddin et al., 2020;Tran et al., 2019; daSilva et al., 2019;N and Saju, 2018;Shah et al., 2018). Nevertheless, identifying nutrient deﬁciency is difﬁcult for ordinary farmers because several nutrients show similar characteristics ( Sinha and Shekhawat, 2020;Watchareeruetai et al., 2018;Harjoko et al., 2019). Two methods for identifying nutrient deﬁciencies in plants are de- structive and non-destructive. One of the destructive methods is labora-tory testing, but the risk of error is more signi ﬁcant due to human error (Harjoko et al., 2019). Digital image processing with machine learning isa non-destructive method that gives more objective results ( Kameliaet al., 2020;Myo Han and Watchareeruetai, 2020). Many studies iden- tify macronutrient deﬁciencies based on plant images, especially leaveimages. Several studies used RGB images of leaves of tomatoes, chilies,cucumbers, and others (Bahtiar et al., 2020;Lewis and Espineli, 2020; Jose et al., 2021;Shah et al., 2018). The rule-based method analyzesRGB leaf color information in statistical values, but their model cannothandle high data dimensions (Latte et al., 2017;Latte and Shidnal, 2016;Halim et al., 2021). Several studies have used machine learningto identify macronutrient deﬁciencies in plants. The Backpropogation-Artiﬁcial Neural Network (BP-ANN) model with a diagnostic rate of97.5%, using hyperspectral image (Shi et al., 2021). In addition, the com- parison of K-Nearest Neighbor (KNN) with other methods such as J48,Naive Bayes, Partial Least Square (PLS), Classi ﬁcation and Regression Tree (CART), and Classiﬁcation Tree (CT). The highest accuracy is86.52% for the KNN method (Kumar et al., 2015, 2021). Other studies use logistic regression, Support Vector Machine (SVM), and MultiLayer Perceptron (MLP) to identify nutrient de ﬁciency of black gram
plants (Rahadiyan et al., 2022a). MLP performs better with 88.33% accu-racy than logistic regression and SVM ( Myo Han and Watchareeruetai, 2020). Then, another classiﬁer method, such as Naive Bayes and Ran-dom Forest Technique (RFT) (Siedliska et al., 2021;Vassallo-Barco et al., 2017). However, the success of the identiﬁcation model is not only based on the machine learning method used, but also on the com-bination of features analyzed.Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
⁎Corresponding authors.E-mail addresses:deffa.rahadiyan@mail.ugm.ac.id (D. Rahadiyan),shartati@ugm.ac.id (S. Hartati),wahyo@ugm.ac.id(Wahyono),andrew@ugm.ac.id(A.P. Nugroho).
https://doi.org/10.1016/j.aiia.2023.04.0012589-7217/© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/Several studies have tried to use certain features and their combina-tion to identify macronutrient deﬁciencies. Research (Drdsh et al., 2021) compares YGB and the percentage of RGB value using ANN, and RGBshows the best accuracy. In addition, HSV and RGB values can be used(Qur'ania et al., 2020;Mashumah et al., 2018). The Gray-Level Co- occurrence matrix (GLCM) method extracts the color and texture infor-mation with four different angles (Sosa et al., 2019;Sabri et al., 2020; Vassallo-Barco et al., 2017). Another method for texture is Local BinaryPattern (LBP), but in (Tan et al., 2021)’s study, GLCM is more suitable than LBP for their data. Another extraction method is shape feature ex-traction using canny and Sobel edge detection ( Qur'ania et al., 2020), but research (Lukic et al., 2017) utilizes statistical characteristics of Humoments from binary leaf image. Not only using one feature, Combiningfeatures is important in identifying macronutrient de ﬁciencies (Jeyalakshmi and Radha, 2017;Rahadiyan et al., 2022b). In several re- searches, the combination of the features improves the result, such asa combination of RGB statistics values and Sobel edge ( Wulandhari et al., 2019;Wang et al., 2021b), the combination of GLCM, hue, andcolor histogram to analyze maize plants ( Sabri et al., 2020). Then, the combination of RGB values and texture value of the leaves ( Merchant et al., 2018) and the descriptors Blurred Shape Model (BSM) andGLCM to extract shape and texture characteristics in coffee leaves im-ages (Vassallo-Barco et al., 2017). Another study uses K-means Cluster-ing based on texture characteristics with RGB values in the image(Merchant et al., 2018). However, the resulting accuracy is still lowdue to the limited features used (Yan et al., 2019). However, most studies' feature combinations cannot always improve the accuracy(Qur'ania et al., 2020). The classiﬁcation model using RGB color extrac-tion produces 70.25% of accuracy, and Sobel edge detection produces59.52% accuracy (Qur'ania et al., 2020). Nevertheless, the combination of RGB and Sobel edge produces lower accuracy than RGB only. It isabout 65.36% of accuracy.Deep learning, especially Convolutional Neural Network (CNN), isbecoming a popular classiﬁcation method today. However, the CNNmethod uses an automatic feature extraction feature, so it is challengingto analyze the effect of features combination on the results obtained(Buzzy et al., 2020;Khew et al., 2021). In (Senan et al., 2020), the study compares CNN with other machine learning such as ANN, MLP,and SVM. CNN shows the best result because the convolutional layerlearns multi features such as color or texture images ( Senan et al., 2020). However, in (Watchareeruetai et al., 2018), CNN produces an accuracy of less than 60% because the de
ﬁciency classes have similar characteristics. In another study, (Wang et al., 2021a) performs data augmentation until each class has the same amount of data. Deeplearning with an augmentation process increases the accuracy upto 5% (Guerrero et al., 2021;Wang et al., 2021a;Myo Han and Watchareeruetai, 2020). In (Jiang et al., 2020), the study compares the results of processing with segmentation and without segmentation.The result is that image segmentation shows better results than withoutsegmentation.This study aims to classify six chili plant health conditions using thecombination of shape, texture, and color features. Chili in Indonesia isusually grown in an uncontrolled lighting conditions. The use of one fea-ture such as color has a great risk of identi ﬁcation errors because of the lighting condition. So, the proposed study varies several features for nutri-ent deﬁciency identiﬁcation. A careful feature selection was carried out toproduce an accurate model that robust in the uncontrolled lighting condi-tion. Some features considered are the leaves' color, shape, and texture.Several other machine learning and deep learning methods, such asMLP, SVM, Naive Bayes, RFT, and CNN were tested to compare the perfor-mance models in our data. The contributions of this paper are as follows.a. Perform features combination (color, texture, and shape of the chilileaves image) that can be used to identify plant conditions.b. Find a suitable MLP architecture based on the combination of thesethree features.c. The data used is in-House dataset.2. Materials and methodsThis study identiﬁed six chili plant conditions using digital imageprocessing based on single leaf image data. There are several stagesfor identiﬁcation, namely image acquisition, segmentation, image aug-mentation, feature extraction, and identiﬁcation tasks.Fig. 1shows the identiﬁcation workﬂow design.2.1. Leaf data and nutrient statusThe initial stage in the identiﬁcation process is the collection ofimage data. The dataset used in this case was collected from the hydro-ponics chili plant in Sleman, Special Region of Yogyakarta, Indonesia.The hydroponics used is a Nutrient Film Technique (NFT) system. Thesix plant health conditions observed were Healthy, Calcium, Magne-sium, Sulfur, Magnesium-Sulfur, and multi-de ﬁciency. The characteris- tics of each plant's health condition are summarized in Table 1.T h e initial condition of hydroponic plants is a healthy plant. The data collec-tion scenario is described as follows:a Some chili plants suitable to the criteria can grow and develop in anNFT hydroponic system until six weeks after planting. All plantshave the same Health condition as shown on Fig. 2(g). b This study combines nutrients using various single compound fertil-izers according to the criteria for plant needs. Based on ( Singh et al., 2019), the need for chili plants in the juvenile phase is shown inTable 2andTable 3. The reduction of certain single compound fertil-izers is calculated to obtain a nutrient solution with a certain macro-nutrient deﬁciency.c 7 selected plants were sampled in a hydroponic environment byproviding macronutrients based on certain levels. The level used inthis study consists of 5 levels. Each level is a dose reduction of mac-ronutrient types by 10%, 30%, 50%, 70%, and 90%. The content of thesemacronutrients is maintained for seven days to observe visible visualcharacteristics properly.d This study validated the data with agricultural experts to ascertainthe visual characteristics of the emerging leaves. If appropriate,chili plant data is acquired.e The leaf acquired is a single leaf sample that represent the plant'scondition.Visual changes in the leaves are captured using the camera sensorwith HD 1080 resolution on a certain background. RGB image cameraworks like the human eye which is sensitive to RGB light bands. A sam-ple of six classes of data is shown inFig. 2. The result is obtained many data in speciﬁc classes as shown inTable 4, where AAug is data after augmentation and BAug is data before augmentation.2.2. Preprocessing, segmentation, and augmentation processThis study uses two types of preprocessing to improve image quality.Theﬁrst is resizing the image to a size of 512⋅512. While the second is to apply Histogram Equalization (HE) ( Abdul et al., 2015). Image acqui- sition takes place in a natural environment so that the lighting varies. HEis applied to reduce the impact of lighting on the resulting image.Eq.(1) and (2)are formula to do HE, wherecdfis a normalization func- tion. Then, intensity transformation of the input image r
ktoskis whereL is the number of possible intensities and n
rjis the number of pixels of levelr
j.D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
78cdf jðÞ ¼∑kj¼0nrj
n ð1Þs
k¼Tr kðÞ ¼round cdf r kðÞ /C2L/C01ðÞðÞ ð 2ÞSegmentation is the process of separating an object from the back-ground. Histogram equalization results will be segmented to separateobjects from complex backgrounds using the thresholding method(Vassallo-Barco et al., 2017). Thresholding is a segmentation methodbased on certain pixel values. The HE results were converted to a LABcolor model in this study. LAB was chosen because it proved suitablefor primary colors, including leaf color. The lower threshold valueused is 122 and the upper limit is 245. The a∗channel on the LAB is used. Several morphological operations such as erosion and dilationare used to cover some holes formed. The results of the morphologicaloperations are performedbitwisenotfor the masking process of HE im-ages and binary images.Data augmentation is a process to multiply data ( Guerrero et al., 2021). In several studies, data augmentation has proven to improvethe model performance (Guerrero et al., 2021;Kuznichov et al., 2019). The data is reproduced through speciﬁcm o d iﬁcation processes. In this study, the data augmentation for the training set is executed by severalbehaviors, namely rotation, shear, zoom, and brightness. Rotation was
Fig. 1.Stages of identiﬁcation of macronutrient deﬁciencies in chili plants.
Table 1The visual characteristics of nutrient de ﬁciency.Plant Condition Characteristics of the leavesColor Shape Texture Part of the plantHealthy Green Ellipse Smooth Overall(\\Ca) Healthy Green Misshapen Curling leaf tip Top(\\Mg) Necrosis (cell injury), interveinal chlorosis Ellipse/ Misshapen Smooth Bottom(\\S) Turning brown on the edge of the leaf Ellipse/ Misshapen Smooth/ Curling leaf tip Bottom(-MgS) Necrosis (cell injury), interveinal chlorosis, turning brown on the edge of the leaf Ellipse/ Misshapen Smooth/ Curling leaf tip Bottom(−Multi) Multi characteristics Ellipse/ Misshapen Smooth/ Curling leaf tip Top/BottomD. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
79chosen because this model is expected to be used in real environmentswith irregular leaf positions. In addition, shearandzoomare applied so that the model can cope with the problem of different data acquisitiondistances. The identiﬁcation system is designed to be applied to a realenvironment, so the model must be able to overcome different lightingproblems. Therefore, data augmentation also considers brightness be-havior. The augmentation data in this study uses Keras tools with a ro-tational parameter range of 40, a shear range of 0.2, a zoom range of0.2, and a brightness range of 0.5 to 1.5. Each data is augmented into 8data. The image resolution was reduced to 500 × 500 pixels before theaugmentation process.2.3. Feature extractionThe feature extraction helps retrieve information such as color, tex-ture, shape, geometry, and others from the chili leave image. Some stud-ies only analyze one feature, but other studies combine them. This studycompares two-color feature extraction methods using statistical valueof the RGB and HSV color models. The RGB and HSV leaf color featuresare helpful features that have been widely used. Color model conversionfrom RGB to HSV aims to limit the size and type of color space. Then, thetexture feature extraction methods compared are LBP and GLCM. Theshape feature extraction used is the value of Hu moments and statisticalcharacteristics of the centroid distance in the binary image. Table 5 shows the number of features for each method. The feature combinationcannot always improve the performance of the model. Therefore, the se-lection of features combination must be conducted to obtain an accurateclassiﬁcation.2.3.1. Color feature extractionThe HSV and RGB color spaces are robust for color extraction fea-tures (Latte et al., 2017;Latte and Shidnal, 2016). They analyze the sta- tistical characteristics such as mean, standard deviation, and skewnesson each channel in the color model as shown in Eq. (3)–(5). Whereμ is Mean,σis Standard Deviation,Skewnessis image dimension based i-th pixel,Mis the total number ofj-th, andNis value of thej-th pixel of the image at thei-th color channel. In (Qur'ania et al., 2020;Drdsh et al., 2021), RGB produces a high accuracy. However, in ( Latte et al., 2017) HSV is robust for macronutrient identi ﬁcation. Therefore, this study looks for HSV or RGB feature extraction features that are suitablefor our chili plant data. This study extracted the red, green, and bluecolor component of the RGB image and extracted hue, saturation, andvalue of the HSV image.μ¼1MN∑Mi¼1∑Nj¼1Iij/C0/C1 ð3Þσ¼ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1MN∑Mi¼1∑Nj¼1Iij/C0μ/C0/C12 2s ð4ÞSkewness¼
1MN∑Mi¼1∑Nj¼1Iij/C0μ/C0/C13/C16/C17=σ3 ! ð5Þ2.3.2. Texture feature extractionThe texture is a feature that can be used to identify macronutrientdeﬁciencies. In this study, the class that clearly shows the visual charac-teristics of the textural features is Calcium. If the research only usescolor, then the class labelled Calcium will be challenging to identify be-cause it has color characteristics that are very similar to healthy. In thisstudy, the texture feature extraction method uses two differentmethods, namely GLCM and LBP. GLCM has been used for texture fea-ture extraction in cases (Sabri et al., 2020;Tan et al., 2021) and give good results. Meanwhile, LBP was tested in case ( Kumar et al., 2020). GLCM is obtained by calculating the probability of the adjacency re-lationship between two pixels at a certain distance and angle orienta-tion (Widodo et al., 2018). After obtaining the co-occurrence matrix,the observed image's statistical characteristics can be calculated. GLCMstatistical features include Contrast, Correlation, ASM, IDM, and Entropyfor four angles (0
∘,4 5∘,9 0∘,a n d1 3 5∘) and one distance (1 pixel) as s h o w ni nE q .(6)–(10). WhereGLCM(i,j) is the distribution of joint prob- abilities of a pixel pair, one with gray level iand the other with gray level j. The number of rows and columns of the GLCM matrix depends on thegray level of an image.Lis the number of gray levels used minus 1 forcomputation. The gray level value (grayscale) of an image between 0and 255. The symbolsμ
i′,μj′,σi′,σj′are means and standard deviationsof the marginal distributions associated with GLCM(i,j).ASM¼∑
Li¼1∑Lj¼1GLCM i,jðÞðÞ2ð6ÞContrast¼∑
Ln¼1n2∑
i/C0jjj ¼nGLCM i,jðÞðÞ2() ð7ÞIDM¼∑
Li¼1∑Lj¼1GLCM i,jðÞðÞ2
1þi/C0jðÞ2ð8ÞEntropy¼∑
Li¼1∑Lj¼1GLCM i,jðÞlogGLCM i,jðÞðÞðÞ ð 9ÞCorrelation¼
∑Li¼1∑Lj¼1i;jðÞGLCM i;jðÞ−μ0iμ0j/C16/C17σ
0iσ0j;whereμ
0i¼XLi¼1XLj¼1i/C2GLCM i;jðÞ;μ
0j¼XLi¼1XLj¼1j/C2GLCM i;jðÞ;σ
0i¼XLi¼1XLj¼1GLCM i;jðÞi−μ0i/C0/C12
σ0j¼XLi¼1XLj¼1GLCM i;jðÞj−μ0i/C0/C12ð10Þ
LBP is a feature extraction method of binary images. In ( Kumar et al., 2020) proves that LBP can solve the problem of rotation on objects ac-cording to the data used in this study. For the LBP, we selected the uni-form pattern and set the value of bins to 10. Thus, this study extractedTable 2Chili plant nutritional requirements.Compound PPM Compound PPM%N-NO3 180.0 %Cl 0.0%N-NH4 7.2 %Fe 1.72%P2O5 48.0 %B 0.23%K2O 225.0 %Cu 0.37%CaO 170.3 %Zn 0.38%MgO 40.0 %Mn 0.34%Na 0.0 %Mo 0.06%SO3 32.5
Table 3Amount of compound requirement for 10 Liters nutrient solution.Substance name Formula Amount (grams)Magnesium Sulfate MgSO4, 7H2O 2.5Calcium Nitrate 5Ca(NO3)2.NH4NO3.10H20 6.55Potassium Nitrate KNO3 5.22Meroke VITAFLEX Fe, Mn, Zn, Cu, B, Mo 0.23Meroke MAP N, P2O5 1.11Meroke MKP P2O5, K2O 0.82D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
80ten texture features with the LBP method. The LBP intensity value is cal-culated for such a speciﬁed center pixel gray color by comparing it to itsnearest neighbors, as seen in Eq.(11).W h e r eg
ccorresponds to the value of the center pixel,g
pto the value of the eight surroundingpixels,Pis the total number of involved neighbors, Ris the radius of the neighborhood, and functionf
1(x).LBP
P;R¼Xp−1p¼02p/C2f1gp−gc/C16/C17;wheref
1xðÞ ¼1;x≥00;else/C26 ð11Þ2.3.3. Shape feature extractionThere is a change in leaf shape in plants that lack macronutrients, es-pecially leaf edges. Leaves can be more rounded or even irregular. Thisstudy uses the moment to determine the centroid point of an object.The centroid or the center moment of an object is ( x′,y′) shown in Eq.(12),w h e r eM
ijisxandycoordinate of thei-th location cross the vol- ume of goods moved to or fromi-th location.x′¼
M10
M00,y′¼M01
M00,w h e r e:M
ij¼∑
x∑
yxiyjIx,yðÞ ð12ÞHowever, this study presents two different approaches in processingdata from the centroid point, such as:a. The centroid point is used to produce moment invariant. Usingmoment invariants, feature extraction of shape producedseven-moment invariant values that are not sensitive to translation,scale change, and rotation (Kumar et al., 2020). The seven moment invariant values are shown in Eq.(14)–(20).H1is theﬁrst moment invariant,H
2is the second moment invariant, and others, where μ ij
in Eq.(13)is means value of distributionI(x,y).μ
ij¼X
xX
yx−x0ðÞiy−y0ðÞjIx;yðÞ;where:ð13ÞH
1¼μ20þμ02 ð14ÞH
2¼μ20/C0μ02 ðÞ2þ4μ211 ð15ÞH
3¼μ30/C03μ12 ðÞ2þ3μ21/C0μ03 ðÞ2ð16ÞH
4¼μ30þμ12 ðÞ2þμ21þμ03 ðÞ2ð17ÞH
5¼μ30/C03μ12 ðÞμ30þμ12 ðÞμ30þμ12 ðÞ2/C03μ21þμ03 ðÞ2hi3μ
21/C0μ03 ðÞμ21þμ03 ðÞ3μ30þμ12 ðÞ2/C0μ21þμ03 ðÞ2ih ð18Þ
H6¼μ20/C0μ02 ðÞμ30þμ12 ðÞ2/C0μ21þμ03 ðÞ2iþ4μ
11μ30þ3μ12 ðÞμ21þμ03 ðÞh
ð19ÞH
7¼3μ21/C0μ03 ðÞμ30þμ12 ðÞμ30þμ12 ðÞ2/C03μ21þμ03 ðÞ2hi/C0 μ
30/C03μ12 ðÞμ21þμ03 ðÞh3μ30þμ12 ðÞ2/C0μ21þμ03 ðÞ2ið20Þ
Fig. 2.Sample chili plant leaf images condition, (a) Healthy, (b) Calcium, (c) Magnesium, (d) Sulfur, (e) Magnesium-Sulfur, (f) Multi-de ﬁciency, (g) Hydroponics plant.
Table 4Data used in this study.Plant condition Total data Training data Testing dataBAug AaugHealthy (complete nutrient) 98 68 612 30Calcium (\\Ca) 101 71 639 30Magnesium (\\Mg) 100 70 630 30Sulfur (\\S) 96 66 594 30Magnesium-Sulfur (Mg\\S) 102 72 648 30Multi deﬁciency (more than 2) 97 67 603 30 Table 5The number of features.Type of features Method Number of featuresColor HSV Color model 9 RGB Color model 9 Texture Statistics feature of GLCM 24Local Binary Pattern (LBP) 10Shape Hu moments 7 Distance of centroid 5D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
81b. The distance between the centroid and each edge pixel is obtainedby calculating the Euclidean distance. Then, the distance is visual-ized, and the statistical value is sought from the data for each dis-tance to the centroid. The features obtained from this stage arestatistical features such as mean, min, max, median, and average.2.4. Identiﬁcation modelTo classify the six classes of chili plant condition, MLP architecture isused. MLP is an artiﬁcial neural network that includes at least threelayers of neuron nodes, namely the input layer, the output layer andone or more hidden layers. Except for the input neuron, each nodeuses a different nonlinear activation than the linear perceptron. Fig. 3 shows the MLP architecture used.The number of input neurons corresponds to the number of featuresvalue used. This study looks for a suitable number of nodes and hiddenlayers based on the three features combination. In the decision layer,this study uses six nodes which represent six classes of plant health con-ditions using One-hot encoding output representation. The recti ﬁed linear unit (ReLU), is used as the activation function. In mathematicalform,Y=ϕ(wx+b), wherewis the weight,xdenotes as the vectors of input,bis the value of bias andϕis the nonlinear activation.This study uses the MLP architecture model in ( Myo Han and Watchareeruetai, 2020) against our data to analyze the combinationof three features. In (Myo Han and Watchareeruetai, 2020), the research use two hidden layers with 2048 and 512 nodes. The suitable learningrate is 0.002 with the Adam optimizer. After the best combination ofthe three features is obtained, this study tries to ﬁnd the best MLP archi- tecture based on our data. This study varies the number of hiddenlayers, the number of nodes, the learning rate, and the epochs to pro-duce an accurate model based on a combination of three features,namely color, texture, and leaf shape.This study also compares the bestM L Pa r c h i t e c t u r eb a s e do nt h e experiment with other previous work, such as Naive Bayes, RFT, andSVM. Naive Bayes is used on (Vassallo-Barco et al., 2017)w i t hc e r - tain parameters, and RFT is used (Sonobe et al., 2020). SVM effec- tively solves local minima and high dimension problems ( Sonobe et al., 2020). SVM has several kernels, and (Xu et al., 2020)u s e st h e Gaussian Radial Basis Function (RBF) kernel. In this method, twohyperparameters, theCregularization parameter and gamma value
Fig. 3.The multi layer perceptron architecture.
Fig. 4.Comparison of original image and Histogram Equalization result.D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
82are set to generate a classiﬁcation model. ForC, a high score may re- sult in over-ﬁtting due to a high penalty for non-separable points,whereas a low value may result in under- ﬁtting. The value deﬁnition of the range of a single training instance of Kernel RBF ﬁts our data with hyperparameter values of gamma of 0.0001,Cof 100, and the decision function shape using One vs One classi ﬁer (OvO). OvO is used as a multi-class strategy to train models. In addition, this study also tries other SVM kernel such as the Linear kernel ( Myo Han and Watchareeruetai, 2020).2.5. Performance measurementThe parameters used to measure the success of identifying macronu-trient deﬁciencies in plants in this study were accuracy, precision, andrecall. The measurement of model performance accuracy is chosen todetermine the model's ability to detect all objects correctly. Precisionis chosen because several macronutrients exhibit very similar character-istics that the system must distinguish between them. If the systemcannot tell the difference, the wrong solution can occur, causing theplant to die. The recall refers to the ratio of correctly predicted positiveobservations to all the actual class observations ( Xu et al., 2020). The equations used to calculate accuracy, sensitivity, and speci ﬁcity are shown in Eq.(21)−(23),w h e r eTPis the number of true positive,TN is true negative,FPis false positive, andFNis false negative.Accuracy¼
TPþTNTPþTNþFPþFN/C2100%ð21ÞPrecision¼
TPTPþFP/C2100% ð22ÞRecall¼
TPTPþFN/C2100% ð23Þ3. Result and discussionChili plant data were collected in natural environments, so the light-ing condition varied. Toﬁx this problem, this study uses HE.Fig. 4shows the result of histogram equalization. To separate the object from back-ground, the segmentation process is used. This research uses the
Fig. 5.Result of (a) segmentation, (b) data augmentation process.
Fig. 6.Histogram of each RGB and HSV color spaces in Calcium and Multi-de ﬁciency data classes.D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
83colorspace segmentation method on channel a* of the CIELAB image.The approach is to choose a small sample region for each color and tocalculate each sample region's average color in a
∗space. Based on ob- servations, channela
∗can distinguish object information from the back-ground well, with a range of 122 and 245. However, some noises such asholes can be removed by applied the morphological operations. The re-sult of segmentation is shown inFig. 5(a). In addition, to increase the model's accuracy, the augmentation process is applied with the resultsshown byFig. 5(b).This study performs a combination of colors, shapes, and textures.For color feature, statistical feature of HSV and RGB are compared.RGB was chosen because research (Qur'ania et al., 2020) is the feature that produces the best performance, while HSV was chosen because inother studies, it can produce the best performance as well. HSV hasmore complex components to represent object features in more detail.Fig. 6shows the different characteristics of the two classes. In thegreen channel of RGB, the Calcium class shows a frequency range from[0, 1400] for intensity level 25 to 185, while unhealthy leaves in the fre-quency range [0, 1350] for intensity level [10, 135]. In the V channel ofthe HSV histogram, the peak value for the intensity of the highest fre-quency of Calcium and Multi-deﬁciency is around 3000.This study compares the GLCM and LBP methods for texture featureextraction, while the Hu moments value and the edge distance to thecentroid for shape feature extraction. GLCM is a second-order featureextraction where the matrix describes the neighbor relationship be-tween pixels in an image in various directions and local distances. Therelationship between class and one of the GLCM features can be seeninFig. 7. Meanwhile, LBP is a texture extraction feature that is consid-ered invariant to lighting and rotation. The Hu moments value forshape feature extraction consists of seven values that identify the char-acteristics of a digital image object. These values are independent oftranslation, rotation, and scaling. At the same time, the other shape ex-traction feature used is the statistical feature of each edge pixel distanceto the centroid. It refers to the visual characteristics of chili leaves thathave wavy edges if there is a lack of macronutrient Calcium, multi-deﬁciency, and others. Therefore, the distance of each leaf edge pixelto the centroid is considered capable of representing the shape featuresof the leaf.Fig. 8shows the effect of the pixel distance from the edge tothe centroid in different classes. According to Fig. 8below, healthy ex- hibits a visual feature that is not smooth/tortuous. This study appliesto resizing pixel data into 100⋅100, so that the distance of each edgepixel point looks far. It causes the visualization to be noisier, coupledwith the elliptical leaf shape and tends to be round. Meanwhile, the cal-cium data shows less noise because the leaf shape is not round.There are four experimental in this study. The ﬁrst experiment com- pares each feature's performance against six chili health condition dataclasses. The second is the comparison of the feature combination perfor-mance. The third experiment compares several MLP hyperparametersagainst the combination of the three best features obtained from theprevious experiment. While the fourth experiment is a comparison ofthe results of the third experiment with several previous studies.3.1. Comparison of single feature performanceBefore combining features, this study analyzes the abilities of eachfeature. The MLP architecture in (Myo Han and Watchareeruetai,2020) is used to determine the features' performance. In addition, thisstudy also analyzes the effect of the data augmentation stage in the re-sulting identiﬁcation model. A summary of experiments related to thecapabilities of each feature is shown in Table 6. There are three types of features analyzed: color, texture, and shapefeatures. This study compares the statistical characteristics of RGB andHSV images for color, LBP and GLCM features for textures, and statisticalcharacteristics of the edge pixel distance to centroid and Hu momentsfor shape characteristics. For color characteristics, the results are in ac-cordance with (Qur'ania et al., 2020) that RGB data in this study producehigher accuracy, precision, and recall values than HSV with an accuracyof 66.28% compared to HSV, which is 49.56%. GLCM produces higherperformance than LBP for texture characteristics, which is 50.74%. It isbecause of LBP describes the texture locally. As for the shape character-istics, statistical characteristics from the edge pixel distance to the cen-troid resulted in a higher performance of 41.43%.Furthermore, this study analyzes the augmentation stage's effect oneach resulting feature's performance. The result is that augmentation oncrop images can increase accuracy by more than 10%, such as RGB fea-tures, from 66.28% to 80.00%. This res ult corresponds with the research (
Guerrero et al., 2021;Wang et al., 2021a). After augmentation, RGB and GLCM feature performance remains higher than HSV and LBP. How-ever, different results were obtained on the shape characteristics. The fea-tures of Hu moments obtained higher results than the statisticalcharacteristics of the edge pixel distance data set to the centroid. Afterthe augmentation process, features that produce more than 60% accuracyon augmented data are used on a combination of two and three features.3.2. Comparison of feature combinationThe second experiment is to combine different features. The architec-ture used is MLP by (Myo Han and Watchareeruetai, 2020), same as the previous experiment.Table 7shows the results of these combinations.This study performs a combination of two features and three fea-tures. A combination of two features is applied to the data before
Fig. 7.An example of data visualization in GLCM features.D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
84augmentation with a combination of color+texture, color + shape, andtexture + shape. The combination of RGB color and GLCM texture pro-duces the highest accuracy, which is 76.13%, compared to the combina-tion of the other two characteristics. In the combination of threefeatures experiment, RGB, GLCM, and Hu moments produces the higheraccuracy than combination of RGB, GLCM, and distance of centroid. Thisis not in line with the results of previous combinations where the dis-tance of centroid results a higher accuracy than Hu moments feature.In addition, this study also did a combination of 3 features by combiningthe distance of centroid feature and Hu moments feature. The result wasbeyond our expectations where the combination accuracy is greater,which is 84.77%.This study also tries to compare the results of the combination ofthree data features without augmentation and with augmentation.The result is that data with augmentation yields higher accuracy, ac-cording to the previous experiments. The results of the augmentationof the three-feature combination data produce accuracy that is notmuch different. The combination of RGB, GLCM, and Hu moments pro-duces an accuracy of 86.35%, while RGB, GLCM, and distance of centroidproduces an accuracy of 86.21%. But, the combination of RGB, GLCM, Hu,and distance of centroid produced the highest accuracy, which is87.47%. Because of this, we decided to use this combination in thenext experiment.3.3. Comparison of MLP hyperparameterThis study tries to compare the combination of MLP hyper-parameters, such as the number of learning rates and epochs. Thenumber of hidden layers used is three. Based on previous experiments
Fig. 8.The distance between edge pixels to the centroid visualization of: (a) Healthy and (b) Ca.
Table 6The performance of single feature with augmentation and without augmentation.Feature No. Method Total Accuracy (%)Precision(%)Recall(%)noAug Color 1 RGB 9 66.28 69.83 65.042 HSV 9 49.56 51.13 49.33Texture 3 LBP 10 40.85 43.36 40.454 GLCM 24 50.74 55.43 50.25Shape 5 Distance ofcentroid5 41.43 54.29 37.686 Hu moments 7 34.84 33.93 33.42Aug Color 7 RGB 9 80.00 81.08 81.868 HSV 9 71.57 72.52 71.35Texture 9 LBP 10 54.83 58.66 56.3610 GLCM 24 61.38 64.77 63.25Shape 11 Distance ofcentroid5 66.21 64.32 68.1412 Hu moments 7 70.53 69.44 71.09D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
85as shown onTable 8, the number of nodes are 2048, 1024, and 512. Theresult of hyperparameter shows onTable 9. The third experiment was carried out by varying the learning ratevalue from 2 to 0.0001 with aﬁxed epoch value of 200. The value of0.0001 was chosen because the resulting performance trend decreasedat that value. Based on the experimental results, the highest perfor-mance was produced by a learning rate of 0.002, with each accuracy,precision, and recall value of 89.70%, 90.62%, and 89.17%. In comparison,the lowest performance is generated by the learning rate with a value of2. In training using the Adam optimizer, the learning rate value regu-lates the number of updates made to the weight value of w. If the learn- ing rate value is decrease, the error function will decrease. However, alearning rate that is too small can cause the performance of trainingmodel decreases, as shown by the experiment. After obtaining the ap-propriate learning rate, this study also looks for the appropriate epochvalue based on the previous MLP architecture. The epoch value variedfrom 100 to 400. The epochs value stopped varying at 400 becausethe performance trend had declined at that number. Based on theexperimental results, the highest model performance is produced bythe MLP architecture with an epoch value of 300. The resulting accuracy,precision, and recall values are 89.70%, 90.62%, and 89.17%, respectively.The greater the iteration value, the more learning is generated. How-ever, an epoch value that is too large can result in an over ﬁtting model. Therefore, the correct learning rate and epoch values must beobtained so that the resulting model performs well.3.4. Comparison of the MLP in this study with previous studyIn the fourth experiment, this study compares the combination ofthree features with several types of classiﬁers. For the MLP method, this study compares the architecture in ( Myo Han and Watchareeruetai, 2020) in the existing data with the best MLP architecture based on thisstudy. The MLP architecture in this study uses three hidden layers with2048, 1024, and 512 nodes respectively and an output layer with threenodes. The architecture uses Rectiﬁed Linear Unit (ReLU) as an activationfunction and 300 for epochs. This study uses the cross-entropy category as a loss function because the problem is multi-classi ﬁcation. The study uses Adam as solver (Shi et al., 2019), with a learning rate of 0.002. The result isthat the (Myo Han and Watchareeruetai, 2020) architecture produces a relatively high accuracy of 87.47%, but the MLP architecture in thisstudy produces a greater accuracy of89.18%. In addition, this study com-pares two SVM kernels: the RBF kernel and the linear kernel. Where C is 1and gamma is 1, the linear kernel can produce an accuracy of 90.55%. InTable 7The performance of feature combination with augmentation and without augmentation.Feature No. Method Total Accuracy(%) Precision(%) Recall(%)noAug Color+Texture 1 RGB + GLCM 33 76.13 75.42 73.21 2 HSV + GLCM 33 72.38 76.10 68.36 Color+Shape 3 RGB + Hu 16 68.87 72.53 71.33 4 RGB + Distance of centroid 14 70.29 70.00 70.18 Texture+Shape 5 GLCM + Hu 31 57.73 51.88 60.25 6 GLCM + Distance of centroid 29 63.12 67.35 65.23 Color+Texture+Shape 7 RGB + GLCM + Hu 40 83.27 83.14 81.32 8 RGB + GLCM + Centroid 38 78.26 72.63 77.329 HSV + GLCM + Hu 40 74.14 68.39 71.4310 HSV + GLCM + Centroid 38 78.26 72.63 77.3211 RGB + GLCM + Hu + Centroid 45 84.77 85.21 84.62 Aug Color+Texture 1 RGB + GLCM 33 80.04 85.48 82.36 2 HSV + GLCM 33 80.75 82.84 81.28 Color+Shape 3 RGB + Hu 16 82.73 83.13 83.87 4 RGB + Distance of centroid 14 77.85 78.05 76.573 HSV + Hu 16 65.80 70.64 65.764 HSV + Distance of centroid 14 70.65 69.93 70.23 Texture+Shape 5 GLCM + Hu 31 62.46 66.25 64.81 6 GLCM + Distance of centroid 29 70.58 71.66 70.41 Color+Texture+Shape 7 RGB + GLCM + Hu 40 86.35 88.14 86.52 8 RGB + GLCM + Centroid 38 86.21 87.67 84.939 RGB + GLCM + Hu + Centroid 40 87.47 88.93 87.16
Table 8The number of hidden layer and node experiment.HL1 HL2 HL3 Accuracy(%) Precision(%) Recall(%)4096––85.50 85.93 86.11 2048––83.74 84.97 84.64 1024––81.43 83.88 82.32 512––80.87 82.62 81.04 256––80.25 82.19 80.83 128––73.73 77.10 74.48 4096 4096 –82.17 84.62 83.86 2048 2048 –86.58 87.37 87.97 2048 1024 –84.94 86.80 84.54 2048 512 –84.32 85.75 85.39 2048 256 –84.83 85.45 84.61 2048 128 –79.27 81.49 80.55 2048 2048 2048 78.48 80.33 78.182048 2048 1024 86.26 87.40 86.622048 2048 512 85.60 86.81 85.282048 2048 256 84.78 84.43 84.202048 1024 1024 85.52 87.26 85.292048 1024 512 87.42 88.70 87.982048 1024 256 85.14 87.21 85.372048 512 512 86.08 87.37 86.242048 512 256 82.84 84.49 83.632048 256 256 85.15 86.72 85.462048 256 128 80.71 84.06 82.58
Table 9Tuning hyperparameter in MLP architecture.LR Epochs Accuracy(%) Precision(%) Recall(%)2 200 20.72 23.12 17.202 200 21.13 18.10 17.470.1 200 33.25 20.54 27.650.05 200 35.81 33.26 34.160.001 200 86.74 88.86 86.930.002 200 87.91 88.12 88.330.003 200 82.26 84.57 83.100.005 200 81.72 84.13 83.270.0001 200 77.83 82.80 76.540.002 100 86.11 88.45 87.320.002 250 87.34 88.39 87.760.002 300 89.70 90.62 89.170.002 350 87.25 88.14 87.320.002 400 85.85 86.77 85.81D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
86contrast, the RBF kernel requires parameter tuning with a signi ﬁcant value to produce high accuracy, 100 for C and the gamma value of0.001. The linear kernel separates the data based on a ﬁrm line. Then, SVM can handle non-linear data based on the kernel. This is in accordancewith the results of experiments in research ( N and Saju, 2018). Besides MLP and SVM, this study also tries to compare other classi ﬁers, such as Naive Bayes and RFT, but their accuracy is not higher than SVM andMLP. This study also compares machine learning methods with CNN(Cevallos et al., 2020). CNN produces the highest accuracy, which isequal to 97.76%. However, CNN has a higher complexity than MLP. Theconfusion matrix of the proposed MLP architecture and linear SVM kernelis shown inFig. 9(a) andFig. 9(b). While the training and validationgraphs from CNN are shown in theFig. 10. The performance comparison shown onTable 10.The highest overall accuracy is generated by the CNN method, whilethe second is the SVM linear kernel, and the third is MLP. SVM produces
higher accuracy in detecting Mg, S, Mg\\S, and Multi-deﬁciency classes. However, the MLP architecture in this study yielded higher precision forHealthy and Ca classes. Example of testing data against to the proposedmethod show onFig. 11. Even though it is lower, the training time re-quired for MLP is relatively less compared to CNN and SVM linear ker-nel. It is caused by optimize the C regularization and parameter whichmeans that performing a grid search will usually take more time in SVM.Several cases cannot be adequately identi ﬁed in the macronutrient deﬁciency identiﬁcation system. Theﬁrst is healthy, Calcium, and Sulfur. For Calcium, the lack of macronutrient at low levels only gave a slightimpact in the form of differences in texture, while sulfur at low levels
Fig. 9.Confusion matrix of nutrient deﬁciency identiﬁcation using The MLP and SVM.
Fig. 10.CNN result.
Table 10Comparison of accuracy, precision, and recall with a previous work.Feature Method Accuracy (%)Precision(%)Recall(%)RGB + GLCM + Hu moments+Distance of centroid MLP [26] 87.47 88.93 87.16MLP (Results ofthis study)89.70 90.62 89.17SVM (Linearkernel) [26]90.55 90.34 89.90SVM (RBFkernel) [50]82.37 84.58 83.82Naive Bayes [44] 70.66 68.72 70.16RFT [36] 63.25 64.33 64.65 Automatic feature extraction CNN [4] 97.76 93.21 96.95D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
87only gave a black color change at the base of the leaves. Therefore, eventhough a combination of 3 characteristics has been carried out, the de-veloped model can still give incorrect identi ﬁcation results. In addition, there are conditions of overlapping characteristics such as Mg, S, andMg\\S. So, the identiﬁcation model cannot recognize them correctlyin certain cases, especially if the Mg\\S is still at a low level.4. ConclusionDetermining nutrient deﬁciencies in chili plants can be done usingmachine learning and deep learning approaches. This study comparesthe combination of several features. The combination of the leavescolor, texture, and shape has been proven to increase the model's accu-racy. The best feature combination is generated by RGB, GLCM, Hu, anddistance of centroid. The features combined in the augmented data re-sults produce the best performance using a 0.002 of learning rate and300 epochs with 89.70% of accuracy. This study compares the MLP ar-chitecture with several machine learning in the previous study. The re-sult is that SVM produces the best performance with 90.55% of accuracy.Although SVM linear kernel produces higher accuracy than MLP, MLP inthis study still has a high success rate. So it can be concluded that thetwo models can be recommended to identify plant health conditions.MLP in this study proved to be better at identifying plant conditions inthe form of Calcium and Sulfur than linear SVM kernels. In addition,augmented data has been shown to improve accuracy by more than3%. In addition, this study also compares machine learning with deeplearning, such as CNN. CNN is proven to produce higher performancecompared to machine learning. However, CNN has a high complexitycompared to ordinary machine learning. The model for identifyingplant health conditions can be applied to the agricultural environment.One example is the intelligent hydroponic farming system. In additionto monitoring and controlling agricultural environmental conditions,farmers can also embed our model to monitor plant health regularlyand provide nutrient solutions based on plant conditions. To supportprecision agriculture, we will focus on a model that can identify thetype of macronutrient deﬁciency and estimate the percentage of de ﬁ- ciency in the future.CRediT authorship contribution statementDeffa Rahadiyan:Conceptualization, Methodology, Software,Validation, Formal analysis, Investigation, Writing –original draft, Writing –review & editing, Visualization.Sri Hartati:Conceptualization, Method- ology, Validation, Writing –review & editing, Formal analysis, Investiga- tion, Visualization, Supervision, Project administration. Wahyono: Conceptualization, Methodology, Validation, Writing –review & editing, Visualization, Project administration.Andri Prima Nugroho:Conceptuali- zation, Methodology, Validation, Writing –review & editing, Visualization.
Fig. 11.Examples of some test data results against proposed models.D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
88Declaration of Competing InterestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to in ﬂu- ence the work reported in this paper.AcknowledgementsThis research was funded by the Directorate of Research and Com-munity Service, Deputy for Strengthening Research and Development,Ministry of Research, Technology/National Research and InnovationAgency of the Republic of Indonesia in the PMDSU program with grantID 018/E5/PG.02.00. PT/2022 and 1773/UN1/DITLIT/Dit -Lit/PT.01.03/2022.References
Abdul, M., Radhi, H., Musa, A., Al-Hsniue, O., 2015. Enhancement of the captured images under different lighting conditions using histogram equalization method. Intern.J. Latest Res. Sci. Technol. ISSN 3, 25 –28. Bahtiar, A.R., Pranowo Santoso, A.J., Juhariah, J., 2020. Deep learning detected nutrient de-ﬁciency in chili plant. 2020 8th International Conference on Information and Commu-nication Technology (ICoICT), pp. 1 –4.https://doi.org/10.1109/ICoICT49345.2020. 9166224.Buzzy, M., Thesma, V., Davoodi, M., Velni, J.M., 2020. Real-time plant leaf counting usingdeep object detection networks. Sensors (Switzerland) 20, 1 –14.https://doi.org/10. 3390/s20236896.Cevallos, C., Ponce, H., Moya-Albor, E., Brieva, J., 2020. Vision-based analysis on leaves oftomato crops for classifying nutrient de ﬁciency using convolutional neural networks. 2020 International Joint Conference on Neural Networks (IJCNN), pp. 1 –7.https://doi. org/10.1109/IJCNN48605.2020.9207615 . Chen, Z., Wang, X., 2019. Model for estimation of total nitrogen content in sandalwoodleaves based on nonlinear mixed effects and dummy variables using multispectralimages. Chemom. Intell. Lab. Syst. 195, 103874. https://doi.org/10.1016/j.chemolab. 2019.103874.daSilva, M.P.S., Mendonc Freitas, M.S., CesarSantos, P., de Carvalho, A.J.C., Jorge, T.S., 2019.Capsicum annuum var. annuum under macronutrients and boron de ﬁciencies: leaf content and visual symptoms. J. Plant Nutr. 42, 417 –427.https://doi.org/10.1080/ 01904167.2018.1544255.Drdsh, J., Eleyan, D., Eleyan, A., 2021. A prediction olive diseases using machine learning m o d e l s ,d e c i s i o nt r e ea n dN a ï v eB a y e sm o d e l s .J .T h e o r .A p p l .I n f .T e c h n o l .9 9 ,4231–4240.Guerrero, R., Renteros, B., Castañeda, R., Villanueva, A., Belupú, I., 2021. Detection of nutri-ent deﬁciencies in banana plants using deep learning. 2021 IEEE International Confer-ence on Automation/XXIV Congress of the Chilean Association of Automatic Control(ICA-ACCA), pp. 1–7.https://doi.org/10.1109/ICAACCA51523.2021.9465311 . Halim, N.H.N.A., Husin, Z.H., Qadir, T.O., 2021. Brown spot disease severity level detectionusing binary-RGB image masking. (IJACSA). Int. J. Adv. Comput. Sci. Appl. 12,548–553.https://doi.org/10.14569/IJACSA.2021.0120962 . Harjoko, A., Prahara, A., Supardi, T.W., Candradewi, I., Pulungan, R., Hartati, S., 2019. Imageprocessing approach for grading tobacco leaf based on color and quality. Intern.J. Smart Sens. Intell. Syst. 12, 1 –10.https://doi.org/10.21307/ijssis-2019-010 . Jeyalakshmi, S., Radha, R., 2017. A review on diagnosis of nutrient de ﬁciency symptoms in plant leaf image using digital image processing. ICTACT J. Image Video Proces. 7,1515–1524.https://doi.org/10.21917/ijivp.2017.0216 . Jiang, F., Lu, Y., Chen, Y., Cai, D., Li, G., 2020. Image recognition of four rice leaf diseasesbased on deep learning and support vector machine. Comput. Electron. Agric. 179,105824.https://doi.org/10.1016/j.compag.2020.105824 . Jose, A., Nandagopalan, S., Ubalanka, V., Viswanath, D., 2021. Detection and classi ﬁcation of nutrient deﬁciencies in plants using machine learning. J. Phys. Conf. Ser. 1850,012050.https://doi.org/10.1088/1742-6596/1850/1/012050 . Kamelia, L., Rahman, T.K.B.A., Saragih, H., Haerani, R., 2020. The comprehensive review ondetection of macro nutrients de
ﬁciency in plants based on the image processing tech- nique. Proceedings - 2020 6th International Conference on Wireless and Telematics,ICWT 2020, pp. 7–10.https://doi.org/10.1109/ICWT50448.2020.9243623 . Khew, C.Y., Teow, Y.Q., Lau, E.T., Hwang, S.S., Bong, C.H., Lee, N.K., 2021. Evaluation of deeplearning for image-based black pepper disease and nutrient de ﬁciency classiﬁcation. 2021 2nd International Conference on Arti ﬁcial Intelligence and Data Sciences (AiDAS), pp. 1–6.https://doi.org/10.1109/AiDAS53897.2021.9574346 . Kumar, A., Patidar, V., Khazanachi, D., Saini, P., 2015. An approach to improve classi ﬁca- tion accuracy of leaf images using dorsal and ventral features. Int. J. Adv. Comput.Sci. Appl. 6.https://doi.org/10.14569/ijacsa.2015.060917 . Kumar, S., A.G.T, Sreekumar, K., 2020. Classi ﬁcation of rice leaf spot disease using local bi- nary patterns. Intern. J. Innov. Technol. Expl. Eng. 9, 510 –512.https://doi.org/10. 35940/ijitee.f3866.049620. Kumar, S., Jain, A., Shukla, A.P., Singh, S., Raja, R., Rani, S., Harshitha, G., Alzain, M.A.,Masud, M., 2021. A comparative analysis of machine learning algorithms for detec-tion of organic and nonorganic cotton diseases. Math. Probl. Eng. 2021. https://doi. org/10.1155/2021/1790171. Kuznichov, D., Zvirin, A., Honen, Y., Kimmel, R., 2019. Data augmentation for leaf segmen- tation and counting tasks in rosette plants. IEEE/CVF Conference on Computer Visionand Pattern Recognition Workshops (CVPRW), Long Beach, CA, USA, 2019, pp. 2580-2589, doi: 10.1109/CVPRW.2019.00314.Latte, M.V., Shidnal, S., 2016. Multiple nutrient de ﬁciency detection in paddy leaf images using color and pattern analysis. International Conference on Communication andSignal Processing, ICCSP 2016, pp. 1247 –1250.https://doi.org/10.1109/ICCSP.2016. 7754352.Latte, M.V., Shidnal, S., Anami, B.S., 2017. Rule based approach to determine nutrient de- ﬁciency in Paddy leaf images. Intern. J. Agric. Technol. 13, 227 –245. Lewis, K.P., Espineli, J.D., 2020. Classiﬁcation and detection of nutritional de ﬁciencies in coffee plants using image processing and convolutional neural network (Cnn). Int.J. Sci. Technol. Res. 9, 2076 –2081. Lukic, M., Tuba, E., Tuba, M., 2017. Leaf recognition algorithm using support vector ma-chine with Hu moments and local binary patterns. SAMI 2017 - IEEE 15th Interna-tional Symposium on Applied Machine Intelligence and Informatics, Proceedings,pp. 485–490.https://doi.org/10.1109/SAMI.2017.7880358 . Mashumah, S., Rivai, M., Irfansyah, A.N., 2018. Nutrient Film Technique based HydroponicSystem Using Fuzzy Logic Control. Proceeding –2018 International Seminar on Intel- ligent Technology and Its Application. 2018. ISITIA, pp. 387 –390.https://doi.org/10. 1109/ISITIA.2018.8711201. Merchant, M., Paradkar, V., Khanna, M., Gokhale, S., 2018. Mango Leaf De ﬁciency Detec- tion Using Digital Image Processing and Machine Learning. 2018 3rd InternationalConference for Convergence in Technology, I2CT 2018. pp. 1 –3.https://doi.org/10. 1109/I2CT.2018.8529755.Myo Han, K.A., Watchareeruetai, U., 2020. Black gram plant nutrient de ﬁciency classiﬁca- tion in combined images using convolutional neural network. 2020 8th InternationalElectrical Engineering Congress, iEECON 2020. https://doi.org/10.1109/iEECON48109. 2020.229562.N, L, Saju, K.K., 2018. Classiﬁcation of macronutrient deﬁciencies in maize plant using ma- chine learning. Intern. J. Elect. Comput. Eng. (IJECE) 8, 4197 –4203.https://doi.org/10. 11591/ijece.v8i6.pp4197-4203 . Qur’ania, A., Harsani, P., Triastinurmiatiningsih, T., Wulandhari, L.A., Gunawan, A.A.S.,2020. Color extraction and edge detection of nutrient de ﬁciencies in cucumber leaves using artiﬁcial neural networks. CommIT (Commun. Inform. Technol.) J. 14, 23.https://doi.org/10.21512/commit.v14i1.5952 . Rahadiyan, D., Hartati, S., Wahyono, Nugroho, A.P, 2022a. An overview of identiﬁcation and estimation nutrient on plant leaves image using machine learning. J. Theor.Appl. Inf. Technol. 100.Rahadiyan, D., Hartati, S., Wahyono, Nugroho, A.P, 2022b. Design of an intelligent hydro-ponics system to identify macronutrient de ﬁciencies in chili. Int. J. Adv. Comput. Sci. Appl. 13.https://doi.org/10.14569/IJACSA.2022.0130117 . Sabri, N., Kassim, N.S., Ibrahim, S., Roslan, R., Mangshor, N.N.A., Ibrahim, Z., 2020. Nutrientdeﬁciency detection in maize (Zea maysL.) leaves using image processing. IAES In- tern. J. Artif. Intell. 9, 304 –309.https://doi.org/10.11591/ijai.v9.i2.pp304-309 . Senan, N., Aamir, M., Ibrahim, R., Taujuddin, N.S., Muda, W.H., 2020. An ef ﬁcient convolutional neural network for paddy leaf disease and pest classi ﬁcation. Int. J. Adv. Comput. Sci. Appl. 11, 116 –122.https://doi.org/10.14569/IJACSA.2020. 0110716.Shah, A., Gupta, P., Ajgar, Y.M., 2018. Macro-Nutrient De ﬁciency Identiﬁcation in Plants Using Image Processing and Machine Learning. 2018 3rd International Conferencefor Convergence in Technology, I2CT 2018, pp. 1 –4.https://doi.org/10.1109/I2CT. 2018.8529789.Shi, J., Wang, Y., Li, Z., Huang, X., Shen, T., Zou, X., 2021. Characterization of invisible symp-toms caused by early phosphorus de ﬁciency in cucumber plants using near-infrared hyperspectral imaging technology. Spectrochim. Acta A Mol. Biomol. Spectrosc.,120540.https://doi.org/10.1016/j.saa.2021.120540 . Shi, W., van de Zedde, R., Jiang, H., Kootstra, G., 2019. Plant-part segmentation using deeplearning and multi-view vision. Biosyst. Eng. 187, 81 –95.https://doi.org/10.1016/j. biosystemseng.2019.08.014. Siedliska, A., Baranowski, P., Pastuszka-Wo źniak, J., Zubik, M., Krzyszczak, J., 2021. Identi- ﬁcation of plant leaf phosphorus content at different growth stages based on
hyperspectral reﬂectance. BMC Plant Biol. 21, 1 –17.https://doi.org/10.1186/s12870- 020-02807-4.Singh, H., Dunn, B.L., Payton, M., Brandenberger, L., 2019. Selection of fertilizer and culti-var of sweet pepper and eggplant for hydroponic production. agronomy 433, 1 –11. https://doi.org/10.3390/rs12193265 . Sinha, A., Shekhawat, R.S., 2020. Olive spot disease detection and classi ﬁcation using anal- ysis of leaf image textures. Proc. Comp. Sci. 167, 2328 –2336.https://doi.org/10.1016/ j.procs.2020.03.285.Sonobe, R., Yamashita, H., Mihara, H., Morita, A., Ikka, T., 2020. Estimation of leaf chloro-phyll a, b and carotenoid contents and their ratios using hyperspectral re ﬂectance. Remote Sens. 12, 1–19.https://doi.org/10.3390/agronomy9080433 . Sosa, J., Ramírez, J., Vives, L., Kemper, G., 2019. An algorithm for detection of nutritionaldeﬁciencies from digital images of coffee leaves based on descriptors and neural net-works. 2019 22nd Symposium on Image, Signal Processing and Arti ﬁcial Vision, STSIVA 2019 - Conference Proceedings, pp. 3 –7.https://doi.org/10.1109/STSIVA. 2019.8730286.Tan, L., Lu, J., Jiang, H., 2021. Tomato leaf diseases classi ﬁcation based on leaf images: a comparison between classical machine learning and deep learning methods.AgriEngineering 3, 542 –558.https://doi.org/10.3390/agriengineering3030035 . Taujuddin, N.S., Mazlan, A.I., Ibrahim, R., Sari, S., Ghani, A.R., Senan, N., Muda, W.H., 2020.Detection of plant disease on leaves using blobs detection and statistical analysis. Int.J. Adv. Comput. Sci. Appl. 11, 407 –411.https://doi.org/10.14569/IJACSA.2020. 0110852.Tran, T.T., Choi, J.W., Le, T.T.H., Kim, J.W., 2019. A comparative study of deep CNN in fore-casting and classifying the macronutrient de ﬁciencies on development of tomato plant. Appl. Sci. (Switzerl.) 9.https://doi.org/10.3390/app9081601 .D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
89Vassallo-Barco, M., Vives-Garnique, L., Tuesta-Monteza, V., Mejía-Cabrera, H.I., Toledo,R.Y., 2017.Automatic detection of nutritional de ﬁciencies in coffee tree leaves through shape and texture descriptors. J. Digit. Inf. Manag. 15, 7 –18. Wang, C., Ye, Y., Tian, Y., Yu, Z., 2021a. Classi ﬁcation of nutrient deﬁciency in rice based on CNN model with Reinforcement Learning augmentation. Proceedings - 2021 Interna-tional Symposium on Artiﬁcial Intelligence and its Application on Media. 2021.ISAIAM, pp. 107–111.https://doi.org/10.1109/ISAIAM53259.2021.00029 . Wang, Q., Mao, X., Jiang, X., Pei, D., Shao, X., 2021b. Digital image processing technologyunder backpropagation neural network and KMeans clustering algorithm on nitrogenutilization rate of Chinese cabbages. PLoS One 16, 1 –24.https://doi.org/10.1371/jour- nal.pone.0248923.Watchareeruetai, U., Noinongyao, P., Wattanapaiboonsuk, C., Khantiviriya, P., Duangsrisai,S., 2018. Identiﬁcation of plant nutrient deﬁciencies using ConvolutionalNeuralNetworks. iEECON 2018-6th International Electr ical Engineering Congress, pp. 2018 –2021.https:// doi.org/10.1109/IEECON.2018.8712217 .Widodo, R., Widodo, A.W., Supriyanto, A., 2018. Pemanfaatan Ciri Gray Level Co- Occurrence Matrix (GLCM) Citra Buah Jeruk Keprok (Citrus reticulata Blanco)untuk Klasiﬁkasi Mutu. J. Pengemb. Teknol. Inform. Ilmu Komput. 2, 5769 –5776. Wulandhari, L.A., Gunawan, A.A.S., Qurania, A., Harsani, P., Triastinurmiatiningsih,Tarawan, Hermawan, R.F., 2019. Plant nutrient de ﬁciency detection using deep convolutional neural network. ICIC Expr. Lett. 13, 971 –977.https://doi.org/10. 24507/icicel.13.10.971.Xu, Z., Guo, X., Zhu, A., He, X., Zhao, X., Han, Y., Subedi, R., 2020. Using deep convolutionalneural networks for image-based diagnosis of nutrient de ﬁciencies in rice. Comput. Intell. Neurosci.https://doi.org/10.1155/2020/7307252 . Yan, X., Wen, L., Gao, L., Perez-Cisneros, M., 2019. A fast and effective image preprocessingmethod for hot round steel surface. Math. Probl. Eng. 2019. https://doi.org/10.1155/ 2019/9457826.D. Rahadiyan, S. Hartati, Wahyono et al. Artiﬁcial Intelligence in Agriculture 8 (2023) 77 –90
90