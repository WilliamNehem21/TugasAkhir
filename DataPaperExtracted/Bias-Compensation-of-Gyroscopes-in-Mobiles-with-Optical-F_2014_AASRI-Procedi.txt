 AASRI Procedia   9  ( 2014 )  152 – 157 Available online at www.sciencedirect.com
2212-6716 © 2014 The Authors. Published by Elsevier B. V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/).Peer-review under responsibility of Scientific Committee of American Applied Science Research Institutedoi: 10.1016/j.aasri.2014.09.024 
ScienceDirect
2014 AASRI Conference on Circuit and Signal Processing (CSP 2014)  
Bias Compensation of Gyroscopes in Mobiles with Optical Flow 
László Kundraa*, Péter Eklera 
a Department of Automation and Applied Informatics, Budapest University of Technology and Economics, Budapest 1117, Hungary   
Abstract 
In this paper a new technique is introduced for bias compensation of gyroscopes with a focus on  mobiles phones. The stan dard problem of using gyroscopes is that integration of raw angular rates  with non-zero bias will lead to continuous d
 rift of the estimated orientation. To examine the nature of this bias, a simple error model was constructed for the whole d
evice in terms of inertial sensing. For eliminating the bias, a sensor fusion algorithm was developed using the benefits of optical flow from the camera of the device. Our orientation estimator and bias removal method is based on complementary filters, in combination with an adaptive reliability filter for the optical flow features. The feedback of the fused result is combined with the raw gyroscope angular rates to compensate th
 e bias. Various measurements were recorded on a real device running the demanding optical flow onboard. This way  a robust and reliable fusion was constructed, which matched
  our expectations, and has been validated with simulations and real world measurements . 
 © 2014 László Kundra, Péter Ekler. Published by Elsevier B.V. Selection and/or peer review under responsibility o
 f American Applied Science Research Institute   
Keywords: optical flow; sensor fusion, orientation estimation, gyroscope bias; mobile  
1. Introduction Orientation estimation is a significant and desired feature to be im
 plemented in more and more reliable and robust way. Pedestrian tracking, controlling unma nned aerial vehicles (UAV), professional cinematography with post-processing, and many other fields may take advantage of these techniques. Unfortunately available sen
sors on the market are not capable of producing stable and reliable output on the long -term. For this 
 
 
* Corresponding author. Tel.: +36-1-463-3971. E-mail address: laszlo.kundra@aut.bme.hu . 
© 2014 The Authors. Published by Elsevier B. V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/).Peer-review under responsibility of Scientific Committee of American Applied Science Research Institute153  László Kundra and Péter Ekler  /  AASRI Procedia   9  ( 2014 )  152 – 157 
situation, many methods have been developed us ing complex algorithms like extended Kalman  filters [1], co mbining different sensors (accelerometer, magnetometer), and relying on a custom movement nature of the tracked object. In this paper we propose an algorithm to fuse the benefits of optical flow from the camera of th
e device with the angular rates of the gyroscope in a reliable way in terms of resulting angle.  For measuring sensor data a Samsung Galaxy S2 mobile phone was used with an unofficial Android 4.4.2  operating system. The device was attached to th e ar
 m of an industrial Mitsubishi MELFA RV-3SDB robot to do p recise rotations. The rated repeatability of this robot arm is less than 0.05 mm . On the Android side, the m
 ethods perform the same way on 2.2+ versions. Although Android KitKat (4.4) has some new methods bu
ilt-in to fuse raw motion sensor values (built-in virtual sensors and pedometer), our project relies on raw sen
sor values for better portability. Android reports inertial se nsor v
 alue changes as events for the developer. Asking the operating system, to provide sensor changes at the fastest possible rate, we could measure an average 20 ms between samples.  Camera images used for optical flow are rather laggy and imprecise in ti
me, for these are delivered at 30 fps in best circumstances, but this value tends to fall below 20 fps caused by external lighting condition chan
 ges and demanding system load on the CPU. For th is, an interpolation stage was added to the system to match optical flow samples consistently with real gyroscope values. In our measurements we used the iterativ
 e Lucas-Kanade method with pyramids by Bouguet, 2000 [2] to track 25
 - 225 features on the images. T he feature point selection was done by distributing these features equally on the image in that case, when the count of matched features fall below 65%. From the results of feature displacement of optical flow a vector field was calculated and used for the fusion algorithm. The aggregation of these vectors into a final output vector can be performed in various ways, and is out of the scope of this paper. In case the device has only orientation changes but no physical movement, the output values can reliably be used for absolute, so -called wo
 rld-frame orientation estimation. In comparison with others, in [3], authors presents a motion model-based method for robust estimation of orien
 tation via fusing the inertial measurements with the imaging sensor’s data.  Their method yields a robust recu
 rsive estimator of the gyro error parameters, which is inde pendent of the scene’s structure. The algorithm’s performance is demonstrated using synthetic d ata as well as visual data extracted from an image stream of high-fidelity computer-generated urban scenes. The accuracy of optical flow estimation algorithms have  been improving steadily as evidenced by results on
  the Middlebury optical flow benchmark. In [4] the authors  attempt to uncover what has made recent ad
 vances possible through a thorough analysis of ho w the objective function, the optimization method, and modern implementation practices influence accuracy. They have found  that while median filtering of in
 termediate flow fields during optimization is a key to recent performance gains, it leads to higher energy solutions. In order to understand the principles behind this phenomenon, they have  derived a new objective th
 at formalizes the median filtering heuristic and they have developed a method that ranks at the top of the Mid
 dlebury benchmark. Recently, in paper [5] authors introduce a state estimation framework that allows estimation of  the attitude, of
  an IMU-camera system with respect to a plane. The filter relies on
 ly on a single optical flow feature as well as gyroscope and accelerometer measurements. The under lying assumption is that the observed visual feature lies on a static plane. The estimation framework fuse s visual and inertial measurements in an Unscented Kalman Filter (UKF). Compared to our work, authors on ly use one optical feature, and it has to be on a static plane, whereas our approach does not require such limitation. Simulations were done in MATLAB after all raw data had been
  recorded on the mobile device. For testing different critical situations, various datasets were ge nerated and also used to measure reliability of the algorithm. In this paper focus is taken on real world measurements. 154   László Kundra and Péter Ekler  /  AASRI Procedia   9  ( 2014 )  152 – 157 
2. The Error Model In order to construct a precise orientation estimator the error m
 odel of the device needs to be described. For this, we performed various measurements on the device. The factors that affect all the measurements can be categorized in two groups: external thus independent, and  dependent on device orientation and movement. B
 ased on the sensors that have been applied in th e sensor fusion, the following model was constructed.  It can be saf
 ely stated, that all the sensors have different amou nt of Gaussian noise. All the other error functions have been marked on figure 1.  As it had been already discussed by many [1][6 ], accelerometer data has a great a
mount of perturbation in the aspect of orientation estimation, for it not only measures the useful gravity, but has additive linear acceleration that perish the results. This linear acceleration is based on
  actual device movement for which no estimation can be constructed forward. With the use of an adequately filtered accelerometer , two angles of the device can
  be estimated on the long term for its low-pass nature.  To find the third absolute angle, magnetometers ca n
  be utilized. Measuring the geomagnetic field that is  strictly not parallel with the gravity vector, a 3D Earth -based absolute orientation can be constructed using the previou
 s filtered gravity and the geomagnetic data. Althou gh, magnetic field is often perturbed mostly in non - natural scenes, such as buildings, undergroun d, 
 close to wiring or electrical devices. If an orientation esti mation algorithm relies on the fact that on the long term magnetometer values are trustworthy,  the output ang
 les will be deceiving in the mentioned situations.  
 
Fig.1. Ideal sensors with additive errors on the left, and bias estimation model on the right.  
Continuing with the gyroscope, it definitely suffers from a couple of errors and perturbation  [3]. As it is ma rked on figure 1, its additive error over a standard Gaussian n
 oise is a function of time and current orientation. Finding the precise error function is not the purpos e of
  this paper, however the basic behavior of the sensor must be known for better filtering, estimation and bias-removal. Based on our measurements, we f
 ound that the bias of the gyroscope has changed over time: it always had a different mean at every m
easurement, repeated 10 times each with 10 minutes delay. Orientation dependent bias effects were also m
 easured: rotating the device 90° on different axes each tim
e, and waiting and measuring in a steady state for a m inute, in each direction all the gyroscope values have been changed at every orientation, even at returning to the initial one.  Bias added to an ideal gyroscope will lead to the drift of orientation. However,  this bias can be estimated and co
 mpensated. For this, it is assumed that a precise orientation estimator is already available using multiple sensors including the gyroscope. As absolute orientation can reliably calculated from magnetometer, accelerom
eter and optical flow, the advantage of using a gyroscope is that it respon
 ds in a more reliable and precise way to fast orientation changes compared to the other  sensors. Considering that a bias is ad
ded to the ideal gyroscope value, the previous estimated angular rate can be subtracted, thus resulting in the difference to the previous estimation plus the bias. Fortunately, this two can be separated for bias is changing in a slow rate 155  László Kundra and Péter Ekler  /  AASRI Procedia   9  ( 2014 )  152 – 157 
compared to the useful, large angular rates needed by the estimator. For this, a high-pass filter was applied on th e signal before using it in the estimator, while the bias was estimated using a low -pass filter. 3. Optical Flow The basic idea is to take advantage of the calc u
 lated optical flow from the camera to refine IMU measurements. Finding the optical flow of an image sequence is a combination of two steps: finding features in the first picture, and tracking them through  the new images (see figure 2). In case the number of detected f
 eatures are lowering below a specified amount, a new feature finding process is executed. In our tests we chose this minimum detected feature count to be the 65% of the initially found ones. The angular rate estimation from optical flow is calculated  from
  the aggregation of reliable flow vectors. A flow vector (that is a vector between the two consecutiv e positions of a feature on the images) is considered trustworthy based on how its movement relates to the angular rate of the gyroscope. Without further specifications of this relationship and decision algorith m, it can be stated that flow vectors are marked as reliable or unreliable at every cycle in an adaptive way. This way, the output of the reliability calculation (see figure 3) has less or equal elements as its input, howe ver for angular rate fusion an aggregation is needed to combine these vectors. This aggregation can be a simp le averaging or median computation, but the use of more advanced techniques like weighted median may produce more satisfying  results. In the measurements of th
 is paper, we used the median in each measured direction. The length of this vector from pixels per sample ti
 me can be calculating to radians per sec using the resolution of the image and the field of view. 
     
  
Fig.2. On-device preview images of calculated optical flow displacements (initial feature count is 22 5). It can be clearly seen, that not all vectors represent well the real orientation change. All of these vectors are saved each time for processing later.  
4. Filtering The filtering algorithm is constructed by three main blocks. The reliability calculation and aggregation has already
 been discussed. On its input it receives all the feature displacements and the bias compensated angular rate of the gyroscope. Both the result of optical flow  and the compensated gyroscope value are processed by a com
 plementary filter. The aim of this block is to cr eate a good balance between slowly changing but on the long-term precise optical flow results, and the f
ast changing gyroscope angular rates. Complementary filters are easy  to implement, quick to be computed, and in this case the results are satisfying. For it is assumed that th
 e final output angular rate will be used by a sophisticated orientation estimator that combines it with acceleration and geomagnetic data, (like extended Kalman filters or the algorithm of Madgwick [1]) it is u
 nnecessary here to apply such for the results. On its input it high-pass and low-pass filters the data, and uses 156   László Kundra and Péter Ekler  /  AASRI Procedia   9  ( 2014 )  152 – 157 
a standard complementary filter technique to add them with a weighting factor  α. T he output ω* is a fused, reliable and precise angular rate, that is also used for co
 mpensational feedback. In our tests we constructed and used FIR filters with a sampling frequency of 40Hz, order of 30, and cutoff frequency of 0.2Hz. Compared to the introduction, an additional low -pass filter was added to the bias compensational block. T
 he main reason was to filter out the effects of Gaussian noise of the input  ω
g from the bias compensations, f or these two are completely independent. This way only the bias compensated angular rates are passed to the complementary filter and to the reliability calculation that relies on ideal gyroscope values (see figure 3).   
 
Fig.3. The inner model of the bias removal algorithm.  
5. Results In our measurements we used to rotate the phone on two of its axes with 90° and 60° respectively. The n
 umber of feature points of optical flow were alter ed between each measurement, recording the rotation with 25, 36, 10
 0, and 225 features. While the 25 features could have been tracked with an average frame rate of 15, a m
ore demanding test with 225 features overwhelmed the processor falling between 1 – 2 fps. In the f
 ollowing the results of measurement with 36 feature points are shown. With the above described algorithm and para
meters we could compensate the bias, resulting in a very low-drifting angle. On figure 4/a, the recordin
 g interval was more than a minute, whereas no significant drift resulted compared to the integral of the raw angular rates. These values are a result of only optical flow and gyroscope fusion in a reliable way, no accelerometer or magnetometer data was used. The only dow nside of the current version of this algorithm is that integrated final angle not always fall between -45° and 45°, as
 it supposed to be by the symmetric rotation of 90°. We also measured the same quality of outputs for the other cases.  On figure 4/b, the estimated bias co
 mpensation level is plotted with the input raw angular rates of the gyroscope. 6. Conclusions and Future Work In this paper we showed that with the use of optical flow from the camera of today’s mobile devices a reliab
le filter can be built used for bias compensation of the gyroscope. In our test cases we could tune the parameters and filters to provide a satisfactory result. Compared to the raw integration of angular rates from the gyroscope our bias compensation resulted in a long -term stable angle. Although bias compensation was calcu
 lated in MATLAB on PC side, the whole heavy optical flow processing was done on the device, 157  László Kundra and Péter Ekler  /  AASRI Procedia   9  ( 2014 )  152 – 157 
therefore the minimal processing demand of the fusion  algorithm could also be ported to the device, this way running the whole system onboard without performance drawback.  Future plans include testing of other methods f
 or the correlation observation of gyroscope angular rates and optical f low feature displacement values. Other plans include the testing of Kalman filters, and RANSAC for th
 e optical flow processing. The aggregation method of th e reliable features has also further possibilities by using more sophisticated methods, like weighted median filters.  
 
Fig.4. (a) The result of the bias compensation: angular rates integrated to angle; (b) The measured raw gyroscope angular rates  and the estimated compensation level for the bias.  
Acknowledgements This work was partially supported by the European  U
 nion and the European Social Fund through project FuturICT.hu (grant no.: TAMOP-4.2.2.C-11/1/KONV-2012-0013) organized by VIKING Zrt. Balatonfüred.  This work is connected to the scientific prog
ram of the "Development of quality-oriented and harmonized R +D+I strategy and functional model at BME" project. Th is project is supported by the New Széchényi Plan (Project ID: TÁMOP-4.2.1/B-09/1/KMR-2010-0002). References [1] Madgwick, S.O.H.; Harrison, A. J L; Vaidyanathan , R., 
 Estimation of IMU and MARG orientation using a gradient descent algorithm, 2011 International Conference on Rehabilitation Robotics, pp.1- 7, July 2011 [2] J.-Y. Bouguet, Pyramidal implementation of the lucas kanade feature  tracker description of the algorithm, In
 tel Corporation Microprocessor Research Labs , 2000 [3] Goldshtein, M.; Oshman, Y.; Efrati, T
., Seeker gyro calibration via model-based fusion of visual and in ertial data, 10th International Conference on Information Fusion, pp.1,8, 9 -12 July 2007 [4] D. Sun; S. Roth.; M.J. Black, "Secrets of optical flow estimation and their principles," 2010 IEEE Conf
erence on Computer Vision and Pattern Recognition (CVPR), pp. 2432-2439, June 2010. [5] Omari, S.; Ducard, G., Metric visual-inertial navigation system using single optical 
 flow feature, Control Conference (ECC), pp.1310-1316, 17-19 July 2013 [6] Ligorio, G.; Sabatini, A.M. Extended Kalman Filter -Based Methods for Pose Estimation Using Visual, In
 ertial and Magnetic Sensors: Comparative Analysis and Performance Evaluation. Sensors 2013, 1919 -1941. 