Big Data: Hadoop framework vulnerabilities, security issues and attacks
Gurjit Singh Bhathal*, Amardeep Singh
aDepartment of Computer Science and Engineering, Punjabi University Patiala, Punjab 147002, India
ARTICLE INFO
Keywords:Big DataHadoopMapReduceSecurity threatsVulnerabilityABSTRACT
Big Data is a collection of different hardware and software technologies, which have heterogeneous infrastructure.Hadoop framework plays a leading role in storing and processing Big Data. It offers fast and cost-effective solutionfor Big Data and is used in different sectors like healthcare, insurance and social media. Hadoop is an open sourceframework based on a distributed computing model and is applied for processing and storing data on a cluster ofcommodity computers. Due to theﬂexibility of framework, some vulnerabilities arise. These vulnerabilities are threats to the data and lead to attacks. In this paper, different types of vulnerabilities are discussed and possiblesolutions are provided to reduce or eliminate these vulnerabilities. The experiment setup used to perform commonattacks to understand the concept and implementation of a solution to avoid those attacks is presented. The resultsshow the effect of attacks on the performance. According to results, there is need to protect data using defense-in-depth to security.
1. IntroductionBig Data is a collection of huge amount of historical and importantdata, which is the most valuable asset of every organization and beingutilized intelligently for business can support decisions based on realfacts rather than perceptions. The term Big Data was coined by CharlesTilly in Oxford dictionary in 1980[1]. At present, considerable data is generated from multiple sources including social media sites, differentremote sensors, cell-phone GPS signals, transaction records, and log ﬁles. Owing to the socialization of the Internet, terabytes of structured, un-structured, and semi-structured data are produced online every day andmuch of this information has inherent business values. Thus, if it's notcaptured and analyzed properly, then considerable vital data will begetting lost. Big Data is to archive a collection of historical data, usingHadoop framework with the help of different tools for analytics, whichare faster than previous traditional analytic tools.Hadoop is a synonym of Big data. Big Data comprises of four V's orcharacteristics: volume, velocity, variety, and veracity [2,3]. The signif- icant growth of data has led to issues related to not only volume, velocity,variety and veracity of data but also to data security and privacy.Recently, the addition of another “V”, i.e., vulnerability, has been pro- posed to be related to it (SeeFig. 1)[4].Big Data technology extracts interesting value from a data lake andmany countries have launched important projects based on this tech-nology. USA is one of the leaders to seize the Big Data opportunity. InMarch 2012, under Obama’s Administration, USA launched the Big DataResearch and Development Initiative with a budget of $200 millions [5]. Due to this Big Data project initiated globally with new technologies,frameworks, many new models have been developed. Infrastructure hasbeen created to provide for more storage capacity, parallel processing,and real-time analysis in a heterogeneous environment [6]. Big Data technology offers improvedﬂexibility, scalability, and performance in acost-effective manner with commodity computers. The cost of moststorage and processing solutions is continuously dropping due to the useof the advanced sustainable technology [7]. This new technology has been developed to ensure data privacy andsecurity in contrast of traditional technologies. However, this technologycan also be used for negative purposes. As a growing number of busi-nesses and individuals store and process their private data using thistechnology, it has become a signiﬁcant target of data attacks.2. Hadoop frameworkHadoop is an open source framework by Apache Software Foundationprimarily based on distributed computing and parallel processing con-cepts for batch operations[33]. Hadoop has combination of components- HDFS for storage, MapReduce for data processing and YARN forresource management in cluster.Hadoop was originally developed in 2005 and ﬁrst released in 2011 to support distribution for the Nutch search engine project at Yahoo [8].
* Corresponding author.E-mail addresses:gurjit.bhathal@gmail.com(G.S. Bhathal),amardeep_dhiman@yahoo.com(A. Singh).
Contents lists available atScienceDirect
Array
journal homepage:www.elsevier.com/journals/array/2590-0056/open-access-journal
https://doi.org/10.1016/j.array.2019.100002Received 2 March 2019; Received in revised form 29 June 2019; Accepted 10 July 2019Available online 20 July 20192590-0056/©2019 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).Array 1-2 (2019) 100002This release was with minimum security support, being run on the trustedenvironment. Hadoop has since emerged as one of the most cutting-edgetechnologies to store, process and analyze big data through use of acluster scale-out environment[9]. Hadoop users are spread all over theworld, mostly large companies including eBay (Using Apache Hadoop of532 nodes cluster), Facebook (using 1100-machine cluster with 8800cores and about 12 PB raw storage) and Yahoo (biggest Hadoop cluster:with 4500 nodes each 2*4cpu boxes w 4*1TB disk&16GB RAM)[10]. Forrester predicts the global Big Data software market will increase from$42B in 2018 to $103B in 2027[11].In 2008 Google processed 20 petabyte of data on a single day. Thiswas the starting phase of new technology which can process a largeamount of data in a short time span. The size of the cluster is scalinghorizontally and vertically with increased demand [9]. Due to expanded (scaled out) clusters, the network threats and vulnerabilities have alsoincreased. To fulﬁll the market demands of security and centralizeadministration, some vendor speciﬁc Hadoop distributions improvisedthe ofﬁcial release of Apache Hadoop. The popular Hadoop distributionsare Cloudera CDH-5.13 (Cloudera Distribution Including ApacheHadoop), Hortonworks HDP-3.1 (Hortonworks Data Platform) and MapR[12,13]. It is considered to to scale up to a cluster of 4000 nodes, torecognize server crashes as“normal”in large organizations, and to put together data storage and analytics robust against failures. The functionalparts of Hadoop are Name Node for metadata, Data Node to store actualblocks (64 MB or 128 MB) of data, Job Tracker and TaskTracker. Hadoophas multiple interfaces, default settings, large volume, and lack of in-ternal cluster security, and hence, it is under threat [14].2.1. Hadoop distributedﬁle system (HDFS)Hadoop distributedﬁle system is a fault tolerant storage system. Itdistributes largeﬁles across the cluster consisting of many Data Nodeswith local storage. During this process Name Node partitions, the originalﬁle into a block, size of 64 MB by default and replicates it to the differentData Nodes based on pre-deﬁned rules. Name Node also maintains themetadata for this replication and allocation. Each data block is replicatedthree times for high availability, two on same rack Data Nodes and onefrom different rack Data Node. Data Node of the cluster stores a smallfragment of the entireﬁle. Name Node is always aware of which datablock belongs to whichﬁle,where the data blocks are placed, and wherestorage capacities are occupied. Using periodically transmitted signals,Name Node always knows which Data Nodes are still alive. If a signal(heartbeat) is missing, Name Node recognizes the failure of a Data Node,removes the failed Data Node from the Hadoop cluster, and tries todistribute the data load equally across the existing Data Nodes.Furthermore, the Name Node ensures that the de ﬁned number of data copies are always maintained for high availability.2.2. Map reduceMapReduce is a parallel processing framework work based on themaster-slave principle, similar to HDFS. It is a combination of one master(JobTracker) daemon and 3 slaves (TaskTracker), daemons per slave in acluster. Map Readuce processing data parallel based on different algo-rithms for a map and reduce. This works in two steps, map task andreduce task. This JobTracker divides the dataset into multiple chunkscalled tasks (Map tasks) and distribute them to three Data Nodes (Task-Tracker) by default across the distributed connected commodity com-putrers on a network for parallel processing.Typically, the map tasks run on the same cluster Data Nodes wheredata resides (Data locality). If a node is already heavily loaded, anothernode that is close to the data, i.e., preferably a node in the same rack, isselected. Intermediate results are unavailable to the user and areexchanged among the nodes(Shufﬂing), and thereafter, merged by thereduced tasks to obtain the results.Intermediate results of map phases can be aggregated by keeping thedata volume as low as possible during trasnfer from map tasks to reducetasks. The intermediate results are deposited in the local ﬁle system of the Data Nodes. The JobTracker is responsible for monitoring to rescheduleany task in case of disruption.If a task does not notify any progress in apre-determined time, or if a Data Node fails completely, all tasks arerestarted on another server including tasks but, they are not ﬁnished. If a task runs extremely slowly, the JobTracker also restarts the task onanother server in order to execute the overall job in appropriate time(speculative execution).The only weak spot here is the JobTracker itself because it representsa single point of failure. Hence, to overcome this problem, secondaryName Node is introduced in the system to make as many redundantcomponents as possible, in order to keep the probability of failure low.MapReduce can be directly applied for executing business analytics, afrequent use case is to transform data into an optimized shape for ana-lytics. The security issues with the MapReduce framework include lack ofauthentication within Hadoop, communication between Hadoop dae-mons being unsecured, and the fact that Hadoop daemons do notauthenticate each other.2.3. Yet another resource negotiator (YARN)YARN is the sub-project of Apache Hadoop. In 2012, MapReduce wasdivided into two parts: MapReduce and YARN [8]. The basic principle of YARN is to divide resource management and job scheduling functional-ities into separate daemons. The function of a resource manager is toarbitrate resources between all system applications, and with the help ofa node manager, to monitor feedback of the resource usage of CPU,memory, disk, and network on each node. The resource manager has twomain components: scheduler and application manager. The schedulerallocates resources to the various running applications, and performsscheduling based on the resource requirements of the applications. Theresource manager accepts job submissions, and each job is allocated toapplication manager. The application manager allocates container forexecuting the application, and to restart the application master containeron failure, each application has application-speci ﬁc master.3. VulnerabilityVulnerability is aﬂaw or weakness in system security procedures,design, implementation, or internal controls. Vulnerability can be
Fig. 1.The V's are represent different characteristics of Big Data, due the systemvulnerabilities one more V is included.G.S. Bhathal, A. Singh Array 1-2 (2019) 100002
2accidently triggered or intentionally exploited, causing security breaches[15].All Hadoop environment components like Sentry, Flink, and Stormare prone to attacks caused by various vulnerabilities; it can be in soft-ware, web interface, or network. The Hadoop framework is a complexcollection of application programs, distributed computing software,hardware, and policies for assessing these resources. Vulnerabilities aredivided into the following three categories:/C15Technology/Software Vulnerabilities; for example, the Hadoopframework is written entirely in Java, which is heavily exploited bycybercriminals and implicated in various security breaches./C15Conﬁguration/Web Interface Vulnerabilities: Hadoop has a weakconﬁguration because numerous default settings such as default portsand IP addresses are vulnerable and have been recently exploited.Mostly Hadoop web interfaces are vulnerable to XSS scripting attack,such as Hue./C15Network/Security Policy Vulnerabilities: the Hadoop framework is amixture of various databases; different types of users in these policiesare not conﬁgured properly, and thus,ﬁne-grained policies are required at both the service level and the data level.3.1. Litrature reviewVulnerabilities are divided into three major categories: infrastructuresecurity, data privacy, and data management [16]. These are further categoriesd in three dimensions: architecture dimension, life cycle ofdata dimension, and data value chain dimension. According to theauthor, infrastructure involves the hardware and software vulnerabilitieswhich are in architecture dimension. Data privacy involves the data atrest and data in transit which involve the life cycle of the data.As per another work[17], research on security and privacy issues ofBig Data is divided intoﬁve heads: Hadoop security, monitoring andauditing, key management and anonymization. This paper speci ﬁcally discusses security and privacy issues of data in cloud environment ofHadoop. Author also discusses various encryption mechanisms toimpalement security in Hadoop HDFS (Hadoop Distributed File System)to achieve authentication in Hadoop, Kerberos network authenticationprotocol used. Other methods and algorithms discussed for monitoringand security of sensitive information are Bull eye algorithm and theNNSE (Name Node Security Enhance) method, used between the masternode and data nodes in Hadoop.Verizon released a white paper[18]on cloud security. In that paper, the cloud infrastructure layered security model is proposed. That modelis divided into four parts: basic security, logical security, value-addedsecurity, and governance. In that paper Verizon also explained thesticky policy framework architecture. This is proposed for securing theBig Data applications on cloud infrastructure.In another paper[19], author has discussed the different types ofattacks such as impersonation, denial of service, replay, eavesdropping,man in middle, and repudiation. According to the author, MapReducecomputation is distributed in nature and open opportunities for a widerange of attacks. Secure MapReduce computation requires properauthentication, authorization, access control, and availability of data forthe mapper and reducer, and conﬁdentiality of data. The Kerberos pro-tocol is recommended for authentication. It uses various tokens such asdelegation, block access, and job tokens. Other security tools such asApache Knox, Apache Sentry, and Apache Ranger are discussed andrecommended. In the paper, data privacy protection from advisory andmultiuser cloud providers on a single public cloud are also discussed.3.2. Vulnerability databasesNumerous online databases are available on internet and these areexposing countless vulnerabilities in different types of products includinghardware and software. National Vulnerability Database (NVD) is avulnerability management repository containing security-related soft-wareﬂaws and impact metrics. The Computer Emergency ReadinessTeam (CERT) is another vulnerability database providing informationabout software vulnerabilties. Microsoft Security Bulletins is also relatedto security issues discovered in Microsoft software, published by theMicrosoft Security Response Center (MSRC). Common Vulnerabilitiesand Exposures (CVE) is another database list of vulnerabilities with anidentiﬁcation number. Open Source Vulnerability Database (OSVDB)provides accurate and unbiased information about security vulnerabil-ities. CVE contains numerous vulnerabilities of cyber security productsand services from around the world.
CVE determines vulnerabilities unambiguously by CVE numbers likeCVE–2017–3161. The central set in these numbers indicates the year ofdiscovery, whereas the last set indicates AN number ranging from one toany, started from one every year and incremented by one for eachreportable vulnerability. The CWD ID –79 (Common Weakness Enumer- ation ID) uniquely identiﬁes this vulnerability type, such as cross-sitescripting (XSS). The newly reported vulnerability is added into CVEDatabase after following some steps of procedure before displayingpublicly, which is controlled by an organization called MITRE. Hadoop isalso a software framework that contains several vulnerabilities, whichwill be discussed in this paper. The list of Hadoop system vulnerabilitiestaken from the CVE database is given below [20]. As per the CVE data- base records of last nine years, the Apache Software Foundation detec-ted/reported several vulnerabilities in their products, but in current year2019 till date total 49 vulnerabilities have been detected out of those 14are related to XSS and one DoS. According to the data available in theCVE database, web interfaces are the most vulnerable. Almost alldetected vulnerabilities are patched, but some of them are exploited bythe attackers with DoS, XSS, and gain access of system (see Table 1) list the vulnerabilities categories[21]. In table (SeeTable 2) data shows details of vulnerability. Some of the vulnerabilities have been detected2018 and were reported in 2019.3.3. Patch managementVulnerability of patch management is the process of rooting out andeliminating these weaknesses before these are abused. Ef ﬁciency of patch management system depends on how fast vulnerability is detected, cor-rected, and patched through periodic penetration (pen testing) and codereview using vulnerability scanning. As per the 2017 report, usage ofvulnerability scanning has increased by 41.7% globally [22]. In patch management, newly discovered vulnerabilities are patched usingvendor-provided patches. Input validation/sanitization should be con-ducted by theﬁltering and veriﬁcation of incoming trafﬁc by using a web applicationﬁrewall, which blocks attacks before they can exploit vul-nerabilities and is a substitute for fully sanitizing an application code.Vulnerability scanners automate security auditing by scanning yournetwork and websites for different security risks and also possible forsome to even automate the patching process. The most popular tools areNexpose is an open source developed by Rapid7 carrying out a wide
Table 1Different Vulnerabilities year wise data which are detected and reported inHadoop framework.
Year Total Vulnerabilities DoS XSS2011 44 15 72012 63 19 62013 74 25 92014 92 23 62015 57 19 52016 103 15 172017 217 29 222018 148 15 92019 49 1 14G.S. Bhathal, A. Singh Array 1-2 (2019) 100002
3range of network checks, others are openVAS, Nmap and wireshark etc.4. Architectural security issues in hadoopHadoop, as we recognize, is an open-source venture that includesvarious modules, which are separately developed over time to adddifferent types of functionalities to its core capabilities. Security was alate addition, and thus, Hadoop lacks a consistent security model. Bydefault, Hadoop assumes a trusted environment. Hadoop has focused onimproving its efﬁciency. Researchers are gradually paying attention toHadoop security concerns and building security modules for it. However,currently, there is no existing evaluation for these Hadoop securitymodules.Due to huge volume, rapid growth, and diversity of data, these areunstoppable and existing security solutions are not adequate, which werenot designed and build with Big Data in consideration. The Hadoop eco-system is a mixture of different applications including Pig, Hive, Flume,Oozie, HBase, Spark, and Strom. Each of these applications requirehardening to add security capabilities to a Big Data environment andfunctions to be scaled with the data. Bolt-on security doesn't scale welland easy. The security tools vendor have customizable offerings andapplying a one point entry (gateway/perimeter) so that commands anddata are entered into the cluster from single entry.Hadoop is distinguished by its fundamentally different deploymentmodel, which exhibits highly distributed, redundant, and elastic datarepositories[34]. However, the architecture of distributed computingpresent a unique set of following vulnerabilities and security threats fordata center managers and security professionals./C15Distributed computing and fragmented data/C15Node-to-Node communication and access to data/C15Multiple interfaces5. Security threats and possible attacksA threat is a potential danger to an information system. A threat isthat someone, or something, will identify a speci ﬁc vulnerability and use it against a company or individual to attack the system [15]. The basic principle of security is CIA, which refers to con ﬁdentiality, integrity, and availability. Conﬁdentiality is only possible if only an authenticated usercan assess the system; it is also important to determine who should haveaccess to the system and what resources a user can access. Hadoop se-curity is divided into two levels. With respect to the time at level-1, theHadoop system starts with a minimum security computing in only atrusted environment. The Hadoop system adds Kerberos for authentica-tion as a perimeter security but not inside the cluster in level-2. Differentsecurity projects such as Apache Sentry, Apache KNOX, Apache Ranger,and Rhino are included in Hadoop at security phase Level-3. Kerberosalso integrates with AD and LDAP. Each security product provides adiscrete security solution due to the different purposes and functionalityof each project. However, the Hadoop system is still required to move tosecurity level-4 as a concrete solution for centralized security in oneproject.How to investigate data leakage attacks in Hadoop is important but along-neglected issue as per McAfee's report, which states that differentthreats to data have increased recently [23]. The following section ex- plains security threats that can hamper the operation of MapReduce andall framework components in the absence of a protected MapReduceenvironment. A dispersed and replicated data processing of MapReducecan unlock an opportunity for a large range of attacks./C15Authentication and authorization: Identity and authentication arecentral to any security effort. Without it we cannot determine whoshould have access to data and who should not. This is done at userlevel by full integration of Active directory (AD) and LightweightDirectory Access Protocol (LDAP) with Kerberos, and at service levelwith Role-Based Access Control (RBAC) at the node level./C15Administrative data access should be ACL's, File Permission andSegregation of administrative roles of OS administrators and Hadoopadministrators./C15Hadoop stacks have many different components which come withdefault setting and no security. Conﬁguration and patch managementis required when running different conﬁgurations and patch levels at one time./C15There are no built-in monitoring tools to detect misuse or block ma-licious queries. Logs should conﬁgure to capture both the correctevent types and sufﬁcient information to determine user actions.Audit and Monitoring tools are important when volume and velocityof data are high.
/C15Applications are built on web service models, especially in socialnetworks like Facebook, Yahoo and Snap Chat. Hadoop Web Appli-cations may be vulnerable to well-known attacks due to insecureAPI's. Big Data cluster APIs need to be protected from usual webservice attacks command injection, buffer over ﬂow attacks, and all the other.5.1. Impersonation attacksImpersonation attacks occur when an attacker tries to access re-sources by impersonating as an authorized identity. The attacker stealsthe credentials of an authorized user by using different methods andattacks Hadoop cluster resources, services, and jobs. Impersonation canbe performed by replaying the tickets issued by the authentication server(Kerberos) for different purposes. Once the attacker gets access to thecluster, they can perform any type of data leak and slow down the pro-cessing of MapReduce.5.2. DENIAL-OF-SERVICE (DoS)A DoS attack[24]occurs when the resources are unavailable toauthorized users. As per the Verizon 2017 Data Breaches Report, 11246attack incidents have been reported and out of those 5 breaches havebeen successful[25]. DoS attacks are accomplished byﬂooding the target with trafﬁc or causes a crash of data. In each instances, the DoS attackdeprives legitimate users of the service or resource they expect. There aretwo general ways of DoS attacks:ﬂooding services or crashing services.Flood attacks occur once the system receives an excessive amount oftrafﬁc for the server to buffer, inﬂicting it to abate and eventually stop.Table 2Detailed CVE of Apache Hadoop and Hadoop distributions already reported.
CVE ID DescriptionCVE-2018-11767Hadoop 2.7.5 to 2.9.1, KMS blocking users or granting access to usersincorrectly, if the system uses non-default groups mappingmechanismsCVE-2018-11766Apache Hadoop 2.7.4 to 2.7.6 privilege escalation vulnerability. Auser who can escalate to yarn user can possibly run arbitrarycommands as root userCVE-2017-7669In Apache Hadoop 2.8.0 the LinuxContainerExecutor runs dockercommands as root with insufﬁcient input validation. When the docker feature is enabled, authenticated users can run commands asroot.CVE-2017-3162HDFS clients interact with a servlet on the Data Node to browse theHDFS namespace. The Name Node is provided as a query parameterthat is not validated in Apache Hadoop before 2.7.0.CVE-2017-3161The HDFS web UI in Apache Hadoop before 2.7.0 is vulnerable to across-site scripting (XSS) attack through an unescaped queryparameter.CVE-2017-15713Vulnerability in Apache Hadoop 3.0.0 allows a cluster user to exposeprivateﬁles owned by the user running the MapReduce job historyserver process. The malicious user can construct a con ﬁgurationﬁle containing XML directives that reference sensitive ﬁles on the MapReduce job history server host.G.S. Bhathal, A. Singh Array 1-2 (2019) 100002
4Well-knownﬂood attacks embody distributed denial of service (DDoS),buffer overﬂow, SYNﬂood, Ping to Death, and HTTPﬂood. In Hadoop, the Name Node and authentication server are vulnerable to DoS attacks.The Name Node has a master daemon that is responsible for schedulingand coordinating the execution of MapReduce applications on the datanodes. A DoS attack on the Name Node can halt all computations ofMapReduce and read-write operations of HDFS.5.3. CROSS-SITE scripting (XSS)XSS[26]is a common attack which injects a malicious code into avulnerable web application. It differs from SQL injection because in thatit does not directly target the application itself. But instead, the webapplication users are the ones at risk. XSS attacks can be broken downinto two types: stored and reﬂected. Stored XSS, also known as persistentXSS, is more damaging than reﬂected XSS and occurs when a maliciousscript is injected directly into a vulnerable web application. Re ﬂected XSS involves reﬂecting a malicious script of a web application onto a user'sbrowser. The script is embedded into a link and is only activated oncethat link is clicked on. Hadoop web UI's are vulnerable to attacks, andrecently, different database installations have been attacked.5.4. Recent attacksHadoop is reportedly easily identiﬁable to hackers worldwide by simply snifﬁng to open instances, and around 5307 Hadoop clusters areexposed to the web with their security settings off, exploit them withreceptive attack by hackers[27]. The online search engine Shodan2shows details about all servers and devices connected to the Internet. Themerit of this is security recommendation, while the demerit is that it isused by hackers to see all details of any network, server location, andother settings. How to protect data attacks in Hadoop is an importantissue. To counter these attacks and stop data theft, it is ﬁrst important to thoroughly understand the vulnerabilities as well as threats, and then, itcan be worked toward devising a strategy using defense-in-depth tosecure data.6. Attack implementation setupIn our experiment, Hadoop cluster was setup in a virtual environmentwith a quick-start cloudera cluster in virtual box. The environment wasconﬁgured on Intel processor i3 with 16 GB RAM and 1 TB hard disk. Toperform the experiment, latest version of CentOS 7 was used and Hadoop3.1.1 was included in CHD-5.13. In cluster, one Name Node and threeData Nodes are conﬁgured. The secure terminal was inbuilt and wasrunning on port 4200 and Web UI also known as cloudera manager atport 7180 to perform the attack, some information gathered like IP ad-dresses and open ports of the Name Node using zenmap and wireshark tocapture the trafﬁc. To run MapReduce job the wordcount example takenfrom the link includes mapper, reducer, combiner and main java programin one singleﬁle.https://archive.cloudera.com/cdh5/cdh/5/hadoop/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html.6.1. Denial-of-service attackTo perform Denial of service (DoS) attack, need to focus on thecommunication between a Name Nodes and Data Nodes, this commu-nication is totally based on the TCP connection, which performs three-way handshaking to establish a connection ﬁrst send the SYK packet then receive SYK ACK packet back and then ACK to complete theconnection. SYK-ﬂood attack was performed which is suitable for Denialof service (DoS) attack against the TCP connection and this attack wasperformed from a compromised Data Node. In this attack Name Nodedin’t shutdown or crashed due to the high availabiltyof architecture andfault tolerant but decreases the performance as shown in the experiment.To perform a Denial-of-Service attack against Name Node, the pene-
tration testing tool hping3 is used. Previously, this tool was used as asecurity tool for aﬁrewall security check, port scanning and trace route.It allows many different types of packets (like: TCP, UDP, ICMP andRAW-IP Protocols) for attack to the destination address Port 50070, theopen port for the web interface of the Name Node, was targeted with aSYK-ﬂood attack on Name Node IP address. At the same time it is neededto perform a MapReduce job to check any effect of attack on systemperformance. A largeﬁle was chosen to perform the experiments. Thistextﬁle is downloaded fromhttps://www.hdfstutorial.com/blog/datasets-for-hadoop-practice/and the block size was 128 MB in order tosimulate Hadoop cluster. Which would have many blocks per Node. Thespeciﬁc MapReduce word count program runs in the Hadoop cluster (SeeFig. 2). It was observed DoS attacks slows down the execution of runningjobs. The job was run during the attack using hping3 and same job wasalso run without any attack against the cluster so as to know the effect on
Fig. 2.Screen with details after Hadoop MapReduce completion.G.S. Bhathal, A. Singh Array 1-2 (2019) 100002
5completion time, which could be compared in table (See Table 3)t o check DoS attack affect on MapReduce processing in Hadoop cluster.6.2. Block port communicationTo block the communication between a Name Node and Data Nodes,the strategy made was little bit different because Hadoop system isresilient in the case of hardware failure, so there is no way to stop anyhardware of Data Node or Name Node. For implementing blockcommunication, the different types of available ports and services wereobserved between a Name Node and Data Node. Hadoop system detectsfailure dynamically and allocates data to the other Data Node. The failuredetects with the help of the heartbeat signal sent by Data Nodes to theName Node, sowe targeted heartbeat signal meansif a Name Node re-ceives heartbeat signal regularly Name Node sending other data to theData Node even Data Node is compromised.To implement blocks communication attack, the network traf ﬁc was captured and analyzed using the wireshark tool (See Fig. 3). In analysis, constant trafﬁc was found between the Name Node and the Data Nodeson the Name Node ports of 7255 (a value which depends upon each in-dividual conﬁguration of Hadoop) and 8031 (default resource trackerport).After examining the contents of packets on both of these portsfound that both of them have been involved in the heartbeat messagesexchanged between Name Node and Data Node. To block the othercommunicationﬁrewall rule added to block other ports traf ﬁc except these two ports.7. Security tools for hadoop clusterThe below section brieﬂy explains some existing reviewed securitytools for Hadoop cluster security. Diffrent features of these tools arecompared in detail in table (SeeTable 4).7.1. Apache KNOXApache Knox Gateway[28]is a single access point to a single ormultiple Hadoop clusters based on the concept of the stateless reverseproxy framework. It also provides authentication to a group of authen-ticated users, authorization, auditing, and system monitoring. Knox hidesdata and details of Hadoop cluster installations, simpli ﬁes the amount of services that user have to be compelled to move with, and limits thenumbers of access points with single entrance URL. Knox has a REST API-based perimeter security entrance system that authenticates user cre-dentials against AD/LDAP and solely a successfully authenticated user isallowed access to the Hadoop cluster.7.2. Apache SentryApache Sentry[29]is a granular, role-based authorization and amulti-tenant administration module for Hadoop. Sentry can manage ac-cess to data and metadata by enforcing an accurate level of privileges toauthenticated users and applications in a Hadoop cluster. It is extraor-dinarily standard and might support authorization for a broad vary ofdata models in Hadoop. It is versatile and permits the de ﬁnition ofTable 3Different processing time of MapReduce job without attack and with attack.
Experiment (Same dataset) Time (s) taken to process MapReduce jobWithoutAttackPorts BlockAttackSYK FloodAttacks1 142.635 851.917 268.2572 117.952 701.605 253.3183 127.164 980.829 273.765Average 129.25 844.783 265.113
Fig. 3.Wireshark Screen short captured trafﬁc during hping3 SYN attack.G.S. Bhathal, A. Singh Array 1-2 (2019) 100002
6authorization rules to validate a user's or application's access requests forHadoop resources. Sentry is meant to be a pluggable authorization enginefor Hadoop elements like Apache Hive, Apache Solr, Impala, and HDFS.7.3. Apache RangerApache Ranger[30]provides a centralized framework for securingHadoop. Ranger is associate authorization system that allows/deniesaccess to Hadoop cluster resources (HDFS ﬁles, Hive tables, etc.) sup- ported pre-deﬁned Ranger policies to authenticated users. When a userrequest comes to Ranger, it is assumed to have been already authenti-cated. Apache Ranger uses Kerberos for authentication and Apache Knoxfor authorization: role -based access control (RBAC). Apache Knox alsosupports auditing of HDFS, Hive, and HBase, and Apache Ranger useswire encryption for data protection.7.4. Project RhinoProject Rhino[31]provides data protection to Hadoop stack with thesingle-sign-on (SSO) concept and supports encryption, a commonauthentication–authorization module key management. Rhino enhancescell-level encryption andﬁne-grained access control to HBase 0.98 andencryption to data-at-rest in Apache Hadoop. Data encryption in Hadooprequires both data-at-rest and data-in-transit; however, most Hadoopcomponents provide encryption for data-in-transit only.7.5. KerberosKerberos[32]is an authentication protocol developed by MIT. It isused in Hadoop to provide authentication to the user to access a Hadoopcluster. The Kerberos protocol uses secret-key cryptography to providesecure communications over a non -secure network. Kerberos is an SSOticket-based system that relies on KDC. The Kerberos protocol generatesthree types of tickets for authentication: delegation token is a secret keybetween a user and Name Node for authentication, block access token isused to access aﬁle from HDFS authenticated by Name Node and DataNode jointly to access a data block on the Data Node, and job token isgenerated by JobTracker to authenticate tasks at TaskTrackers. KerberosKDC comprises of three components: an authentication server, a ticket-granting server (TGS), and a database.8. DiscussionTo protect the Hadoop environment, authentication, authorization,and accounting policies for accessing and using data stored in the Hadoopclusters must be implemented. If one node of Hadoop cluster iscompromised then there are chances of any type of attack and data theftis possible. Securing the data in transit as well as data at rest is required.Securing Hadoop not only involves securing access to Hadoop andsecuring the stored data (data at rest) but also the whole gamut of se-curity that all IT operations use, such as network security and operatingsystem security.Various open source communities, IT development organizations andresearch institutes are working together to improve the Hadoop infra-structure, tools, and services. Big Data innovations are shared throughopen-source platforms which are helpful to promote Big Data technolo-gies. However, users facing difﬁculties due various versions of modulesfrom different sources combined into a Hadoop framework. Because eachHadoop module has its own curve of maturity, there is a risk of versionincompatibility inside the Hadoop framework. In addition, the integra-tion of different modules of different vendors with different technologieson a single platform increases security risks. However, most of the time,the combination of technologies from different sources may bring hiddenrisks that are neither fully investigated nor tested. To overcome this issue,many IT products/solution vendors such as IBM, Cloudera, MapR, andHortonworks have developed their own modules and packaged them intocore Apache Hadoop API and delievered improvised Hadoop distributiosto the market. One of the goals is to ensure compatibility, security, andperformance of all combined modules. Currently, the Hadoop system anddifferent distributions use more than one security solutions for securingdata and computation, as mentioned in the previous section, such asApache Ranger, Apache Sentry, and Apache Knox. Each new module hasits own set of vulnerabilities. If the system is needed to be ﬂexible and interpretable, then automatically system will be vulnerable. Hadoop re-quires single security solution so that vulnerability can reduce that leadsto attacks due to third party softwares and due to different modules usedin Hadoop. The results of our the experiment shows the impact of attackson performance in Table-III, as well as security breach possible due tovulnerabilities. Before implementing any module in Hadoop environ-ment, risk management study of system and defense in depth isrecommended.9. ConclusionTraditional enterprise security products implement security controls,but are still insufﬁcient for holistically addressing the security challengesintroduced by Big Data. To address the problems posed by data aggre-gation, organizations mustﬁnd new ways to safeguard their critical tools,techniques, and procedures used to acquire, maintain, and analyze dataof particular concern to improve the robustness of its security infra-
structure, as most commercially available security software have accessto all real and derived data available on the network. The add-on securityfeatures provided by the third party are not useful in the Big Data envi-ronment. Furthermore, analysts and other users of information technol-ogy need more effective security training that will help them understandthe speciﬁc threats they face, that how their security choices will impactTable 4Comparison detailed feature of security solutions used in Apache Hadoop Framework and in vendor speci ﬁc Hadoop distributions.
Functions Apache Knox Gateway Apache Sentry Apache Ranger Project Rhino KerberosIntroduced By Hortonworks Cloudera Hortonworks Intel MITAdministration/AuthenticationAuthentication Single Accesspoint HTTP, Perimeter Securityusing REST API, Integration withuser Credential AD/LDAPIntegration with ApacheKnox Centralized securityadministration using RESTAPIs and authorizationSingle Sign-on and token-based authentication,common authorizationframework for HadoopEncrypted Token-basedAuthentication to AllHadoop ResourcesAuthorization Support Service-Level Audit Fine- Grained Role Based but Granularity forColumns not supported,At File level in HDFSCentralized Authorizationusing RBAC, attribute-basedaccess control. Granularity forColumns in HiveCell-Level support for HBase Not Supported
Audit Support Service-Level Audit Not Supported Centralize auditing of user access for all the componentsof HadoopSupport Logging audit Not SupportedData Protection Not Supported Not Supported Not Supported Encryption and Key Management Not SupportedG.S. Bhathal, A. Singh Array 1-2 (2019) 100002
7the outcomes, and how to reconcile security objectives with missionobjectives. Finally, system designers need to consider the security im-plications affecting user-facing tools. Users would bene ﬁt from features, giving them security-relevant feedback throughout their work ﬂows, rather than using a separate security tool for forensic validation.Measuring the impact of these “little”security mechanisms may prove challenging and problematic. However,ﬁeld studies such as those cited in this paper suggest that they can have a large impact on scaling securityin a manner that paces with the scale of data that they protect. Thus,there is a need to upgrade the complete Hadoop system released with allsecurity features without installing and to con ﬁgure it separately.Declaration of Competing InterestThe authors declare no conﬂict of interest.References
[1] Dontha R. The origins of big data. Available: https://www.kdnuggets.com/2017/ 02/origins-big-data.html. [Accessed 2 January 2019]. [2]Hashem IAT, et al. The rise of "big data" on cloud computing: review and openresearch issues. Inf Syst 2015:98 –115. [3]Hurwitz JS, Nugent A, Halper F, Kaufman M. Big data for dummies. USA: wiley;2013.[4] Sharma S. Vulnerability –introducing V of big data. Available: https://www.datas ciencecentral.com/proﬁles/blogs/vulnerability-introducing-10th-v-of-big-data . [Accessed 2 January 2019].[5]Weiss R, Zgorski LJ. Obama administration unveils "big data" initiative: announces$200 million in new R&D investments. Washington, DC: The White House; 2012 . [6]Brauna TD, Siegel HJ. A comparison of eleven static heuristics for mapping a classof independent tasks onto heterogeneous distributed computing systems. J ParallelDistrib Comput 2001:810 –37. [7]Purcell BM. Big Data using cloud computing. Holy Family University Journal ofTechnology; 2013.[8] Rouse M. Apache Hadoop YARN. Available: https://searchdatamanagement.techtar get.com/deﬁnition/Apache-Hadoop-YARN-Yet-Another-Resource-Negotiator . [Accessed 4 January 2019].[9] Scaling. Available:https://stackoverﬂow.com/questions/11707879/difference-bet ween-scaling-horizontally-and-vertically-for-databases/12349220 . [Accessed 4 January 2019].[10] XingWang. Powered by Apache Hadoop. Available: https://wiki.apache.org/hadoo p/PoweredBy. [Accessed 4 January 2019].[11]Columbus L. Forecast of Big Data market size, based on revenue. may 2018. p. 23.Available: https://www.forbes.com/sites/louiscolumbus/2018/05/23/10-charts-that-will-change-your-perspective-of-big-datas-growth/#1a9db88e2926. [Accessed5 january 2019].[12] SteveLoughran. Products that include Apache Hadoop or derivative works andcommercial support. Available: https://wiki.apache.org/hadoop/Distributions% 20and%20Commercial%20Support . [Accessed 5 January 2019]. [13]Gurjit singh Bhathal ASD. Big data solution: improvised distributions. In:Proceedings of the second international conference on intelligent computing andcontrol systems. Madurai, India: ICICCS 2018; 2018 . [14]Fujitsu. FUJITSU technology solutions. Munich: Fujitsu; 2017 . [15]Amal Dahbur BMABT. A survey of risks, threats and vulnerabilities in cloudcomputing. Int J Cloud Appl Comput (IJCAC) 2011:11 –5. [16]Ye H, Cheng X, Yuan M, Xu L, Gao J, Cheng C. A survey of security and privacy inbig data. In: 16th international symposium on communications and informationtechnologies. ISCIT); 2016. [17]Terzi DS, Terzi R, Sagiroglu S. A survey on security and privacy issues in big data.In: 10th international conference for internet technology and secured transactions.ICITST); 2015.[18]Sharif A, Cooney S, Gong S. Current security threats and prevention measuresrelating to cloud services, Hadoop concurrent processing, and big data. In: IEEEinternational conference on big data; 2015. Washington, DC, USA . [19]Derbeko P, et al. Security and privacy aspects in MapReduce on clouds: a survey.Comput Sci Rev 2016:1–28. [20] MITRE Corporation. Apache vulnerability statistics. Available: https://www.cvede tails.com/vendor/45/Apache.html . [Accessed 7 January 2019]. [21] Yoder M. Cloudera's process for handling security vulnerabilities. Available:https://blog.cloudera.com/blog/2016/05/clouderas-process-for-handling-security-vulnerabilities/. [Accessed 8 January 2019].[22] Bekker G. 2019 thales data threat report –global edition. Available:https: //www.thalesesecurity.com/2019/data-threat-report . [Accessed 8 January 2019]. [23] Raj Samani CB. McAfee threats report 2018. Available: https://www.mcafee.com/e nterprise/en-us/assets/reports/rp-quarterly-threats-dec-2018.pdf . [Accessed 2 February 2019].[24] CyberPedia. An overview of DoS attacks. Available: https://www.paloaltonet works.com/cyberpedia/what-is-a-denial-of-service-attack-dos . [Accessed 20 January 2019].[25] Verizon. Data breach digest: perspective is reality. Available: https://enterprise.ve rizon.com/resources/reports/data-breach-digest/ . [Accessed 2 February 2019]. [26] Incapsula. CROSS SITE SCRIPTING (XSS) ATTACK. Available: htt ps://www.incapsula.com/web-application-security/cross-site-scripting-xss- attacks.html. [Accessed 4 February 2019].[27] Millman R. Thousands of Hadoop clusters still not being secured against attacks.Available:https://www.scmagazineuk.com/thousands-of-hadoop-clusters-still-not-being-secured-against- attacks/article/637389/ . [Accessed 5 February 2019]. [28] Apache. Apache Knox gateway 0.14.x user's guide. Available: https://knox.apach e.org/books/knox-0-14-0/user-guide.html . [Accessed 6 February 2019]. [29] Sun D. Sentry tutorial. Available: https://cwiki.apache.org/conﬂuence/display/S ENTRY/SentryþTutorial. [Accessed 5 February 2019]. [30] A. S. Foundation. Apache ranger. Available: http://ranger.apache.org/index.html . [Accessed 5 February 2019].[31] Andrew Wang CL. Project Rhino goal: at-rest encryption for Apache Hadoop.Available:https://blog.cloudera.com/blog/2014/06/project-rhino-goal-at-rest-encryption/. [Accessed 1 March 2019].[32] Tom Yu e a. Kerberos: the network authentication protocol. Available: https://we b.mit.edu/kerberos/. [Accessed March 2019].[33] Bhathal GS, Singh A. Big data computing with distributed computing frameworks.In: Saini H, Singh R, Kumar G, Rather G, Santhi K, editors. Innovations inElectronics and Communication Engineering. Lecture Notes in Networks andSystems, vol. 65. Singapore: Springer; 2019. https://doi.org/10.1007/978-981-13- 3765-9_49.[34] Parmar RR, et al. Large-Scale Encryption in the Hadoop Environment: Challengesand Solutions. IEEE Access 2017;5:7156 –63.https://doi.org/10.1109/ ACCESS.2017.2700228.
Gurjit Singh Bhathal. Mr. Gurjit Singh Bhathal is an AssistantProfessor in Department of Computer Science and Engineeringin Punjabi University Patiala. He has over 18 years of experi-ence in India and abroad in theﬁeld of Information Technology. His research interests in the area of security including, Cloudsecurity, Big Data security and Cyber Security. He hascompleted his B.Tech in Computer Science and Engineeringfrom SLIET Longowal and M.Tech from Punjabi University. Heis a Microsoft Certiﬁed Engineer (MCSE) and IBM certi ﬁed of Big Data and Data Privacy Fundamentals. He has more than 60Publications including International journals, National and In-ternational conferences and three books in his credit. He hasserved as a system engineer in Toronto (Canada). He also servedas a principal in college before joining the Punjabi University.He was also invited for Expert talk on Big Data in differentcolleges and universities in National level workshops.Mr. Gurjit Singh Bhathal recently awarded Outstanding Scien-tist in Computer Science and Engineering in 4th AnnualResearch Meet - ARM 2018G.S. Bhathal, A. Singh Array 1-2 (2019) 100002
8