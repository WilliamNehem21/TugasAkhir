An investigation into the potential of Gabor wavelet features for sceneclassiﬁcation in wild blueberryﬁelds
Gashaw Ayalewa,⁎, Qamar Uz Zamanb, Arnold W. Schumannc, David C. Percivald, Young Ki Changb
aIndependent Researcher, Thorold, ON L2V 1Z8, Canada
bEngineering Department, Dalhousie University Faculty of Agriculture, Truro, NS B2N 5E3, Canada
cCitrus Research and Education Centre, University of Florida, Lake Alfred, FL33850, USA
dPlant, Animal and Environmental Sciences Department, Dalhousie University Faculty of Agriculture, Truro, NS B2N 5E3, Canada
abstract article info
Article history:Received 4 October 2020Received in revised form 22 December 2020Accepted 30 March 2021Available online 1 April 2021
Keywords:Wavelet transformsWild blueberryComputer visionMachine learningDiscriminant analysisPrecision agricultureA Gabor wavelets based technique was investigated as a potential tool for scene classi ﬁcation (into one of bare patch, plant, or weed) for its ultimate utility in site-speci ﬁc application of agrochemicals in wild blueberry ﬁelds. Images were gathered fromﬁve sites located in central Nova Scotia, Canada. Gabor wavelet features extractedfrom these images were used to classify scenes according to visually determined classes using step-wise lineardiscriminant analysis.For individualﬁelds, classiﬁcation accuracy attained ranged between 87.9% and 98.3%; selected Gabor featuresranged between 27 and 72; contextual accuracy for herbicide ranged between 67.5% and 96.7%, and contextualaccuracy for fertilizer ranged between 63.6% and 97.1%. The pooled scenes yielded a classi ﬁcation accuracy of 81.4%, and contextual accuracyﬁgures of 61.1% and 73.1% for herbicide and fertilizer, respectively, with selectedGabor features of 36.Calibrations based on LDA coefﬁcients from the pooled scenes could help avoid the need to re-calibrate for eachﬁeld, whereas those based on individual ﬁeld LDA coefﬁcients could improve accuracy, hence enable saving on expensive agrochemicals.© 2021 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. IntroductionBlueberries constitute an important crop, covering an estimated areaof >76,000 ha in Canada, and distributed among >3500 farms ( Statistics Canada, 2018). During the 2014 to 2018 production years, these farmsproduced an average of ca. 190,000 T annually ( Statistics Canada, 2019). This amounted to an average of ca. CAD 253 million in farmgate price over the same duration (Statistics Canada, 2019). It is also in- dicated that wild blueberry makes up ca. 30% of the North Americanblueberry production(Yarborough, 2017)–proving the economic sig- niﬁcance of wild blueberry production.Due to the wild and perennial nature of wild blueberry plants, cul-tural practices of weed control are meagre to nonexistent. This necessi-tates reliance on herbicides for weed control. As a result, millions ofdollars are spent by the industry on herbicides ( Esau et al., 2016). It is widely recognized that site-speciﬁc agrochemical application re- duces the economic as well as environmental costs incurred in wildblueberry production (Chang et al., 2012;Tian and Reid, 1999). Various investigations on weed detection methods were made and varyingdegrees of success achieved using different technologies, in differentcropping systems, including wild blueberry.These technologies included digital colour image based co-occurrence matrix algorithm to classify wild blueberry plantationscenes into bare patches, weed or plant ( Chang et al., 2012); ultrasonic ranging to differentiate between wild blueberry plants, weeds and barepatches (Swain et al., 2009); Gabor wavelets to differentiate betweenbroad leaf and grassy weeds (Tang et al., 2003) and discrete wavelet transforms of digital images for the development of site-speci ﬁch e r b i - cide application (Tian and Reid, 1999).Among these, those systems utilizing digital image classi ﬁcation are reported to demonstrate the ability to identify weeds and bare patchesmore effectively irrespective of plant or weed height ( Chang et al., 2012; Tang et al., 2003;Tian and Reid, 1999). Particularly, in wild blueberryﬁelds, image based spot application of fertilizer ( Chang et al., 2017; Chang et al., 2014), herbicide (Esau et al., 2016;Esau et al., 2014a; Chang et al., 2012)a n df u n g i c i d e(Esau et al., 2014b) were investigated in more recent studies, and promising results obtained.However, the features extracted in the digital image based tech-niques were largely dependent on colour variations, a parameter thatis affected by lighting and plant conditions ( Yazawa, 1977). These ef- fects, coupled to variations in camera settings and potential similaritiesin colour between blueberry and weed plants, and the promising resultsArtiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
⁎Corresponding author.E-mail addresses:gayalew@niagaracollege.ca,gayalew@addisscience.net(G. Ayalew).
https://doi.org/10.1016/j.aiia.2021.03.0012589-7217/© 2021 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/from past texture related studies (Chang et al., 2012;Castleman, 1996), a texture based method was chosen for this study.Nonetheless, the use of colour-based preprocessing enables to de-rive enhanced images that would serve as input to texture based tech-niques. For instance, it has been shown that chlorophyll estimation ispossible from the ratio, (Red−Blue)/(Red+Blue), of colour compo- nents of wheat and rye crop images under different weather conditions(Kawashima and Nakatani, 1998), nitrogen deﬁciency in barley (Pagola et al., 2009), and yield in wild blueberry (Swain et al., 2010). It is, there- fore, held that colour based preprocessing will aid in accentuating dif-ferences between plants and weeds.The Gabor wavelet transform enables the analysis of image scenesboth in spatial and frequency domains ( Daugman, 1985). Selection of this technique for the current study is inspired by previous successfulinvestigations byTang et al. (2003)andTian and Reid (1999), in the identiﬁcation of isolated broad-leaved and grassy weeds; Tian et al. (2000), on identiﬁcation of weeds interspersed with corn plants; andKurtulmus et al. (2014), on the detection of immature peach. It is tobe noted that wavelet transform of images is an established techniqueof multi-resolutionﬁltering to extract textural features. As such it canbe thought of as an“orientation and scale tunable”line and edge detec- tor (Manjunath and Ma, 1996).A Gabor wavelet transform of an image is obtained by its convolu-tion with a Gabor waveletﬁlter. Waveletﬁlters, as applied to images, are designed to selectively pass regions containing a certain size and ori-entation of a given shape structure. For instance, a wavelet transform,based on a mother wavelet designed to pass elliptic shapes, would pri-marily allow the passage of similarly shaped and sized objects withclose orientation to the particularﬁlter (Castleman, 1996;Daugman, 1988). In Gabor wavelet transforms such mother wavelet is generatedby a Gabor function given (Manjunath and Ma, 1996)a s :gx,yðÞ¼
12πσ
xσy/C18/C19exp−12x2
σ2xþy2
σ2y !þ2πjWx"# ð1Þand its Fourier transform, given (Manjunath and Ma, 1996)b y :Gu,vðÞ ¼exp−
12u−WðÞ2
σ2uþv2
σ2v"#() ð2Þwhereσ
u=1 / 2πσ x,σv=1 / 2πσ y,a n dσ xandσ yare scale factors along thexandydimensions, respectively. The self-similar Gabor wavelet ﬁl- ters are produced through scaling and rotation of the mother waveletdescribed in Eq.1according to the equations:g
mnx,yðÞ ¼a−mgx0,y0ðÞx
0¼a−mxcosθþysinθðÞy
0¼a−m−xsinθþycosθðÞ ð3Þwhereθ=nπK,a>1 ,m,n= 0,1,2,…,a n dKis the total number of ori- entations, and the scale factora
−mis included to ensure independence ofspectral energy onm–the scale for a particularﬁlter (Manjunath and Ma, 1996). The Gaussian envelope that is responsible for the shape ofthe function is evident from Eq.2. It is shown by (Manjunath and Ma, 1996;Daugman, 1988;Daugman, 1985) that redundancy of information inﬁltered images is reduced by ensuring that the half-peak amplitudes ofﬁlter responses (for the given set of scale and orientation parameters) donot overlap.Daugman (1985)also shows that two-dimensional Gaborﬁlters are optimal in the sense that they closely approach the theoreti-cally attainable limit of minimum joint uncertainty in space and fre-quency. Detailed treatment of the subject is available elsewhere(Manjunath and Ma, 1996;Daugman, 1993;Daugman, 1988). Once images are convolved with the given bank of Gabor ﬁlters, the mean and standard deviations of the transformed images are computedas features of the image, for the given scale and orientation ( Manjunath and Ma, 1996).This study aimed at the assessment of the potential of Gabor waveletfeatures for automatic classiﬁcation of digital color scenes from wildblueberryﬁelds.2. Materials and methods2.1. Wild blueberryﬁelds and imaging conditionsDigital color images were collected fromﬁve wild blueberry produc- tionﬁelds located in central Nova Scotia, Canada. Table 1provides data on theﬁelds and the images collected.Field 1 was in its fruit year, and was made up of predominantlydense plant patches–some plants being inﬂorescent. The lighting con- dition was a mid-day sunlight. Some of the blueberry leaves had huesranging from yellow to pink. The predominant weed in this ﬁeld was goldenrod (Solidago spp.). Dead grassy and woody plant materialswere visually classiﬁed as bare patches.Field 2 and Field 3 were in their vegetative year, and the lighting con-dition was cloudy in both cases. They generally consisted of sparselypopulated wild blueberry plants interspersed with weeds and barepatches. Predominant weeds were lamb's-quarters ( Chenopodium album L.), sheep sorrel (Rumex acetosella L.,b o t hv e g e t a t i v ea n di nﬂores- cence), goldenrod, poplar (Populus spp.) spreading dogbane (Apocynum androsaemifolium), mouse-eared hawkweed (Hieracium pilosella L.)a n d a few black bulrush (Scirpus atrocinctus).Field 4 was in its fruit year, with scattered colony of dense wild blue-berry plants. The lighting condition was a mid-afternoon sunlight. Pre-dominant weeds were sheep sorrel, lamb's-quarters, goldenrod andwire grass (Danthonia spicata (L.) Beauv.). Bare patches comprised of bare soil and areas covered with dead plant remains.Field 5 was in its fruit year, and the lighting condition was an earlyafternoon sunlight. Predominant weeds were goldenrod and sheep sor-rel, the inﬂorescence of the latter being dominant. A few incidences ofwire grass also existed. Some wild blueberry plant colonies had pre-dominantly pink leaves, and others had yellowish colored leaves. Themajority, however, had leaves with a mixture of these colors. In fewother cases, the blueberry leaves at the shoot apex had hues rangingfrom yellow to pink. Some bare patches were covered with dead grassand woody weeds, others constituted completely bare soil.Anonymous (2019),LeBlanc and McCully (2005)andSampson et al. (1990)were used as references for the identiﬁcation of weed.2.2. Acquisition and preprocessing of imagesWild blueberry canopy images were acquired using an IDS μEye 1220SE/C industrial camera (IDS Imaging Development Systems Inc.,Woburn, MA 01801, USA),ﬁtted with an LM4NCL C-mount lens(Kowa Optimed Inc., Torrance, CA 90502, USA), with 3.5 mm focallength and set at an aperture off/4. The camera was kept approximatelyat 1.2 m above the ground surface. Resolution of the collected imageswas 720 × 128 pixel, and stored in the 24-bit colour bitmap format.The 720 × 128 pixel images wereﬁrst divided into two 360 × 128 pixel regions, and then each was further divided into three regions of
Table 1Wild blueberryﬁelds and scene characteristics.Field Stage of growth Number of images PriorsBARE PLANT WEEDField 1 Fruit year⁎108 11 67 30 Field 2 Vegetative year⁎⁎999 100 651 248 Field 3 Vegetative year 1110 117 608 385Field 4 Fruit year 411 12 11 388Field 5 Fruit year 653 65 387 201Pooled Mixed 3281 305 1724 1252⁎The growth year immediately before harvest.⁎⁎The growth year following harvest and subsequent mowing of the stand.G. Ayalew, Q.U. Zaman, A.W. Schumann et al. Artiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
73128 × 128 pixel. Overlapping patches of 12 × 128 pixel regions wereallowed between consecutive 128 × 128 pixel regions to avoid the re-quirement for zero padding for use with the Fast Fourier Transform(Gonzalez and Wintz, 1987). Each of these 128 × 128 pixel regionscorresponded approximately to a ground surface area of 27.5 cm ×27.5 cm.Fig. 1shows representative images from theﬁveﬁelds. Due to dependence on plant (Yazawa, 1977) and lighting conditions (Kawashima and Nakatani, 1998), it was decided to use differences and/or ratios of the primary color components, Red (R), Green (G) and Blue(B). 2D arrays were populated with numerical ﬁgures derived according to the relationships given in Eqs.4a–4j, and subsequently Gabor trans-formed to enable the computation of features used to carryout sceneclassiﬁcation. Eqs.4ato 4 are due toKawashima and Nakatani (1998), whereas Eq.4jrepresented the difference in the magnitude of theGreen component on one hand and the Red and the Blue componentson the other, and is applied in the differentiation of green plants andsoil (Hamuda et al., 2016).Redratio,RR¼R=RþGþBðÞ ð 4aÞ Green ratio,GR¼G=RþGþBðÞ ð 4bÞ Blue ratio,BR¼B=RþGþBðÞ ð 4cÞ Red−Green normalized index,RGI¼R−GðÞ=RþGðÞ ð4dÞ Red−Blue normalized index,RBI¼R−BðÞ=RþBðÞ ð4eÞ Green−Blue normalized index,GBI¼G−BðÞ=GþBðÞð4fÞ Red−Green ratio,RGR¼R−GðÞ=RþGþBðÞ ð 4gÞ Red−Blue ratio,RBR¼R−BðÞ=RþGþBðÞð4hÞ Green−Blue ratio,GBR¼G−BðÞ=RþGþBðÞ ð 4iÞ Excess Green,ExG¼2G−0:8R−1:2B
ð4jÞ2.3. Visual classiﬁcation of scenesArguably, the most popular approach for classi ﬁcation of wild blue- berryﬁeld scenes is along whether they are bare patch, all wild blue-berry plants or weed (or weed interspersed with wild blueberryplants) (Chang et al., 2012;Swain et al., 2010;Zaman et al., 2009). To fa- cilitate the visual classiﬁcation of wild blueberry scenes along the abovescheme quickly and consistently, a GUI-based tool was developed andused (Fig. 2).The user would choose whether to start a new classi ﬁcation task or to resume an ongoing one. This would allow the user to open an appro-priateﬁle, containing a list ofﬁles to begin a new task, or a decisionﬁle to resume a previous task, respectively. The user would then choose theimage with which to begin the classiﬁcation. The six parts of the se- lected image would then be displayed in the respective windows. The
Fig. 1.Sample images from eachﬁeld.
Fig. 2.Custom made visual classiﬁcation tool.G. Ayalew, Q.U. Zaman, A.W. Schumann et al. Artiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
74user would then click on the button below each of the image segmentsto toggle the class of the concerned image segment. The classes areBARE, PLANT, WEED and DEFER, where the last class is applied whenthe image is considered unﬁt due to such effects as motion blur or par-tial shadow. The term“weed”refers to the usual deﬁnition in agronomy. Relative abundance of weeds was not considered in designating a sceneas WEED–presence of any recognizable amount of weed suf ﬁced. The results of visual classiﬁcation were then recorded to an ASCII de-cisionﬁle where each segment was identiﬁed with a unique name.2.4. Extraction of Gabor wavelet featuresFig. 3is a pictorial representation of the workﬂow for the feature ex- traction, and statistical classiﬁcation. Each derived (preprocessed)image wasﬁltered with a bank of Gabor waveletﬁlters computed with designated lower (U
l) and higher (U h) frequencies selected to be 0.1 and 0.5, respectively (Manjunath and Ma, 1996). Four levels of ori- entation, and ten levels of scale were chosen. The mean ( μ-features) and standard deviation (σ-features) of the magnitudes of each of theGabor transformed derived image segments were eventually computedto represent features for the given set of parameters in a similar fashionas inManjunath and Ma (1996),Daugman (1988),a n dDaugman (1985). Feature data were recorded in an ASCIIﬁle with each image seg- ment given a unique name.All computation required for feature extraction was carried out withcustom programs coded in theC/C
++programming languages. How- ever, we would like to acknowledge the use of a modi ﬁed version of Manjunath and Ma (1996)’s code to design the Gabor waveletﬁlters. One major modiﬁcation was the creation of aﬁlter dictionary at the global scope and use its portion that relates to a particular combinationof scale and orientation as required –rather than re-creatingﬁlters for every image segment.2.5. Statistical analysisThe unique names provided in the two ASCII ﬁles mentioned above (one from visual classiﬁcation, the other from Gabor wavelet feature ex-traction) were used to match visual classes with computed features.Matched data from the twoﬁles, excluding those with a“DEFER”class, were then used for discriminant analysis.A step-wise linear discriminant analysis (SLDA) was carried out oneach of the groups of images collected from the ﬁelds. Wavelet feature selection was carried out using the stepclass() function of the klaR pack-age (Weihs et al., 2005) for R. The criteria for selection was accuracy,with a threshold of incremental improvement of 0.1%. The direction forselecting features was set to“both”(i.e., adding features to, or removingfeatures from the LDA model as feature selection proceeded), and cross-validation was based on a leave-one-out strategy. The same process wasrepeated for the pooled data set from allﬁelds.2.6. Overall and contextual accuracy of classi ﬁcationEvery individual scene that crossed over to another class accordingto the SLDA was automatically identiﬁed and counted. Overall accuracy,referred to as“accuracy”in short, was quoted as the percentage of cor-rectly classiﬁed scenes out of the total number of scenes. In addition, toput the signiﬁcance of accuracy of classiﬁcation in the context of practi- cal applications, two hypothetical agrochemical applications were con-sidered: herbicide and fertilizer. The Tanimoto Similarity Criterion(Ayalew et al., 2004), as adapted to take the form shown in Eqs. 5a n d 6, respectively, was used to measure the accuracy for a hypotheticalsite-speciﬁc application of herbicide and fertilizer. The criterion wouldassume values between 0.0% (complete failure), and 100% (completesuccess).
Fig. 3.Illustration of the Gabor wavelet based classi ﬁcation procedure.G. Ayalew, Q.U. Zaman, A.W. Schumann et al. Artiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
75TCHerbicide ¼True WEED−Missed WEEDTrue WEEDþFalse WEED/C2100ð5ÞT
CFertilizer ¼True PLANT−Missed PLANTTrue PLANTþFalse PLANT/C2100ð6Þ3. Results and discussion3.1. Classiﬁcation performancePlots of linear discriminant analysis of visually classi ﬁedﬁeld scenes, with respect to Gabor wavelet features, together with the 95% con ﬁ- dence limits for the clusters, are shown in Fig. 4.
Fig. 4.Linear discriminant plots with 95% con ﬁdence limits. (a) Field 1; Field 2; (c) Field 3; (d) Field 4; (e) Field 5 and (f) Pooled ﬁeld data analyzed as a singleﬁeld.G. Ayalew, Q.U. Zaman, A.W. Schumann et al. Artiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
76Table 2shows the total number of scenes, the number of features se-lected, classiﬁcation accuracy, inter-class misclassiﬁcation, and total misclassiﬁcation for the Gabor wavelet based method, for scenes col-lected from eachﬁeld, and also for all scenes pooled together.Number of Gabor features ranged between 27 and 72, among which36 were selected for the pooled scenes. These 36 features, despiteresulting in lower accuracy, would enable the design of a simpler systemfor a hypothetical sprayer or fertilizer spreader without the need to re-conﬁgure the system for a particularﬁeld.With regard to classiﬁcation accuracy, the highest value wasattained by Field 4, at 98.3%, and the least, by the set at 81.4%. Resultsachieved in this study were comparable with those attained with thecolour co-occurrence matrix based texture analysis technique reportedbyChang et al. (2012).In addition, as it can be seen fromFig. 4andTable 2, misclassiﬁcation between plant and weed samples was the most pronounced. As a result,bare patches were more accurately classiﬁed in comparison to plant and weed scenes. This may be explained in terms of the fact that both plantand weed groups are made up of live plants that share similar hues andare generally broad leaved. On the contrary, bare patches were mostlybrownish soil, or brown plant debris that may also occasionally includetwigs without leaves. This is evident from Fig. 4that greater separation existed between bare patches on one hand and weed and plant sceneson the other with respect to theﬁrst LDA coefﬁcients (LDA1). It was with respect to the second LDA coefﬁcients (LDA2) that separation existed between plants and weeds, albeit incompletely in some cases.As can be expected, the accuracy of SLDA classi ﬁcation for images was lower than that of any of the individualﬁelds.The contextual classiﬁcation accuracy for herbicide and fertilizer ap-plications are shown inTable 3. Due to an incidentally high weed priors,and low weed misclassiﬁcation rate, Field 4 exhibited the highest con-textual accuracy for herbicide application. On the contrary, this groupexhibited the lowest contextual accuracy for fertilizer, owing to 4 outof 11 missed plant scenes.With only one out of 67 plant priors misclassi ﬁed as bare patch, and 1 out of 30 weed misclassiﬁed as plant, Field 1 exhibited the highestcontextual accuracy with respect to fertilizer. Field 1 also exhibitedone of the highest contextual accuracy for herbicide, with only 1 outof 11 weed scene misclassiﬁed as plant.Field 5 also exhibited a large discrepancy between the two contex-tual accuracyﬁgures. Low herbicide contextual accuracy resulted dueto 48 out of 201 of weed misclassiﬁed to plant, 2 to bare patch, 1 frombare patch, and 21 from plant. On the other hand, contextual accuracywith respect to fertilizer was higher due to a proportionally lower mis-classiﬁcation of plant scenes in the form of 22 missed plants and 50 falseplants. Field 2 and Field 3 performed moderately with regard to contex-
tual accuracy.As with accuracy of classiﬁcation, the contextual accuracyﬁgures are higher for classiﬁcation based on individual scene SLDA, compared withthose based on pooled scene SLDA. It can, therefore, be argued that asimple system can be designed with the LDA parameters for the pooledTable 2Classiﬁcation performance.Fields Scenes Features Misclassi ﬁcationsAcc.(%) B→PB→WP→BP→WW→BW→P TotalField 1 108 27 98.1 0 0 1 0 0 1 2Field 2 999 53 89.8 7 5 5 24 3 58 102Field 3 1110 53 87.9 4 0 7 34 9 80 134Field 4 411 31 98.3 0 2 1 3 1 0 7Field 5 653 72 88.5 2 1 1 21 2 48 75Pooled
∗3281 36 81.4 14 22 38 157 25 353 609Keys: Acc.(%) = accuracy in percent; B = BARE; P = PLANT; W = WEED;Misclassiﬁcations: X→Y≡visual scene X misclassiﬁed as scene Y according to SLDA;
∗Pooled before SLDA and treated as a stand-alone ﬁeld data.
Table 3Classiﬁcation performance in terms of the Tanimoto SimilarityCriterion in the context of herbicide (T
CH) and fertilizer (T CF).Field T
CH(%) T CF(%)Field 1 96.7 97.1Field 2 67.5 86.9Field 3 70.6 81.9Field 4 98.5 63.6Field 5 67.7 83.5Pooled 61.1 73.1
Fig. 5.Plot of count of features against orientation grouped by ﬁeld, and sorted in descending order.G. Ayalew, Q.U. Zaman, A.W. Schumann et al. Artiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
77set for low-cost agrochemicals, and aﬁeld-speciﬁc calibration for more accurate operation to be used in the application of more expensiveagrochemicals.3.2. The effects of orientation and scaleFig. 5shows the number of features selected for each level of the ori-entation parameter, for eachﬁeld, and sorted in descending order. Ken-dall correlation test was carried out to test if there is any order ofpreference, hence rank correlation between ﬁelds with regard to the numbers of features for each orientation parameter. Fig. 7(a) shows the correlogram of Kendall-τvalues forﬁelds with respect to rank of selected orientations.Generally, the number of features grouped according to orientationshows a very weak, or nonexistent correlation between ﬁelds, asshown in the Figure. Only one of the correlations is found to be signi ﬁ- cant at the level of 0.05. This was the correlation between the set andField 3. Even in this case, it could be argued that it is attributed to thebias caused by the highest membership of Field 3 in the set.As the result of this weak correlation, and with the anecdotal knowl-edge of random orientation of leaves of wild blueberry and weed plants,it is concluded that the effect of orientation on the selection of featuresis of a statistically random nature.Like the case for orientation, a rank correlation was carried out be-tween theﬁelds in terms of the order of number of features selectedfor each scale (Fig. 6), to test if there was any order of preference inthe selection of scales.Fig. 7(b) depicts the associated Kendall- τ correlogram.ComparingFigs. 7(a) and7(b), it could be seen that there is more sig-niﬁcant correlation betweenﬁelds for scale than orientation. It is to be
Fig. 6.Plot of count of features against scale, grouped by ﬁeld, and sorted in descending order.
Fig. 7.Kendall-τcorrelograms, with signiﬁcant correlations at the level of 0.05 shaded. Cells not shaded indicate correlations that were not signi ﬁcant at the same signiﬁcance level with respect to: (a) orientation; and (b) scale.G. Ayalew, Q.U. Zaman, A.W. Schumann et al. Artiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
78noted that scale is animportant factor in the derivation of features, hencethe fact that more correlations were signi ﬁcant is not surprising. How- ever, weak correlations existed even in the signi ﬁcant values of Kendall-τat the level of 0.05. The correlation between Field 3 and Field5 and between Field 3 and Field 4 are low and incoherent. Therefore, itcanbeconcluded that theselection of features wasnot determined or sig-niﬁcantly affected by the scale parameter and depended very much onthe individual scenes. The reason for this disparity may be explained interms of uneven height of plants and weeds, whereby actual sizes ofleaves appear disproportionately larger or smaller than other featuresin the scene–based on their location on the tall or short plant.3.3. The effects of preprocessing operationsFig. 8shows the breakdown of features according to preprocessingoperations of images that were used as input to the Gabor feature ex-traction routine. The count of features selected was plotted againstimage preprocessing procedure, grouped by ﬁeld and sorted in de- scending order. As shown in theﬁgure, the most frequently selected fea-tures were based on normalized difference indices(Eqs. 4d to 4f), ExG (Eq.4j), Saturation, Intensity and Hue. There were also a few featuresbased on difference ratios (Eqs.4g to 4i).It is also interesting to note that Field 4 and Field 1, being the ﬁelds that exhibited the top accuracy of classiﬁcation, did not use Hue based features. Even in theﬁelds for which Hue features were selected, itwas not among the top three preprocessing operations. This may be at-tributed to the ambiguity that could result between plants and weedwith respect to Hue. Another observation is that features based on sim-ple ratios of R, G and B (Eqs.4a–4c) were not selected for classiﬁcation indicating that indices based on color differences are more reliable thanthe basic colors alone.Similar to orientation and scale, rank correlations were computedbetweenﬁelds to test if there was a preferred order of selection. Fig. 9 shows the correlogram for the Kendall- τvalues that existed between
Fig. 8.Plot of count of features against preprocessing operations grouped by ﬁeld, and sorted in descending order.
Fig. 9.Kendall-τcorrelogram for count of features according to image preprocessing operations. Shaded cells in the plot signify correlations that were signi ﬁcant at the level of 0.05.G. Ayalew, Q.U. Zaman, A.W. Schumann et al. Artiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
79theﬁelds, with respect to the ranking of feature counts according to pre-processing operations. With low correlation, and insigni ﬁcance of most Kendall-τvalues at the level of 0.05 (i.e., white background cells), it canbe said that there is no signiﬁcant correlation betweenﬁelds with re- spect to selection of preprocessing operations, perhaps due to the diver-sity of colors of both plants and weeds.3.4. General discussionGiven the diversity of hues and texture features existing in a givenﬁeld depending on the stage of growth of the plant, the season, typeof weed and its stage of growth, classiﬁcation will be more accurate if it was based on the context of agrochemical, namely fertilizer, herbicide,or pesticide. Further improvement could be achieved if classi ﬁcation was based on the speciﬁc herbicide or pesticide. This would incidentallyenable the decision to fall into one of two levels (i.e., “ON”or“OFF”), and hence result in a faster processing time. In addition, the use of both theﬁrst and the second linear discriminant functions simultaneously (asshown inFigs. 4) when applied to real-time control would improve ac-curacy, albeit with a higher computational cost.Reduction of wavelet transform artifacts could be achieved withincreased resolution of scene images. Although this could improve accu-racy of classiﬁcation, it reduces processing speed, for a given hardware.Therefore, with the selection of more powerful hardware, and a properbalance between the resolution and processing speed, it would be pos-sible to apply this method for a real-time application of agrochemicals.Consistency in classiﬁcation of scenes, and hence accuracy in auto-matic operation of a sprayer system operating on the basis of the currentmethod depends on the level of coherence of distances between plantsand the camera. Greater uniformity between distances from the camerawould enable greater accuracy in the selection of scales for the Gaborwaveletﬁlters, which would in turn enable greater accuracy in classi ﬁ- cation. Perhaps a future study would be the development of an auto-matic correction for the effects of variation in plant height, wherebyleaves are scaled according to their height from the ground, to offsetthe effect of height variations.4. ConclusionsThe potential of the Gabor wavelet based texture analysis to theidentiﬁcation of wild blueberry plants, weeds, and bare patches hasbeen demonstrated. It is shown that classi ﬁcation accuracy levels in ex- cess of 90% are possible for individualﬁelds.Results show that the scale parameter has a signi ﬁcant effect on the performance of the method, hence error or variations in scale of fea-tures, such as due to variations in plant height can cause deteriorationof accuracy of classiﬁcation. On the contrary, orientation of leaves andother image constituents has a random effect, suggesting that no needto differentiate features based on orientation as long as reasonably di-verse levels of orientation (four levels in this study) have been used.Features based on normalized difference indices, excess green, satu-ration, intensity, and hue were among the most frequently selected fea-tures, showing that preprocessing based on relative colors enhances theefﬁcacy of the Gabor wavelet texture analysis.The evaluation of a conceptual system for the application of fertilizer,herbicide or pesticide based on the results of the Gabor wavelet textureclassi
ﬁcation shows that it is feasible to build a reasonably precise “ON”/ “OFF”control system. Further improvement is also possible if the train-ing is tuned to the active ingredient suitable for a particular weed.Further study is necessary for the assessment of the ef ﬁcacy of this technique in real-time application of agrochemicals. An improvementin classiﬁcation accuracy can be attained with the development of amechanism to automatically control the distance between the plantcanopy and the camera.Credit Author StatementGashaw Ayalew: conceptualization, data curation, formal Analysis,investigation, methodology, software development, validation, visuali-zation, writing, and editing.Qamar Zaman: funding acquisition, project administration,supervision.Arnold Schumann: funding acquisition, methodology, review,supervision.David Percival: funding acquisition, methodology.Young Ki Chang: data curation, resources, validation.Declaration of Competing InterestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to in ﬂu- ence the work reported in this paper.AcknowledgementsWe would like to thank Oxford Frozen Foods Limited, Canada; Agri-culture and Agri-food Canada under grant NS-Agri-Futures (ACAAF) un-der ACAAF-NS0153 (2007–2010) and Department of AgricultureTechnology Development Program for jointly funding the project par-tially; and Dr. Travis Esau, Dr. Aitazaz Farooque, Mr. Kelsey Laking andMr. Scott Read for their assistance during the collection of images. Firstauthor would also like to thank Professor Tessema Astatkie for his colle-giality and his family for their support.ReferencesAnonymous, 2019. Integrated Pest Management Images. New Brunswick Department ofAgriculture and Aquaculture URL:. https://daafmaapextweb.gnb.ca/010-002/Default. aspx?Culture=en-CAAccessed on 20 June 2019.Ayalew, G., Holden, N.M., Grace, P.M., Ward, S.M., 2004. Detection of glass contamination in horticultural peat with dual-energy X-ray absorptiometry (DXA). Comput. Elec-tron. Agric. 42, 1–17.Castleman, K.R., 1996.Digital Image Processing. Prentice-Hall, Inc., Upper Saddle River,New Jersey.Chang, Y.K., Zaman, Q., Schumann, A.W., Percival, D.C., Esau, T.J., Ayalew, G., 2012. Devel- opment of color co-occurrence matrix based machine vision algorithms for wild blue-berryﬁelds. Appl. Eng. Agric. 28, 315 –323. Chang, Y.K., Zaman, Q., Chattha, H., Reads, S., Schumann, A., 2014. Sensing system using digital cameras for spot application of fertilizer in wild blueberry ﬁelds. Paper written for presentation at the 2014 ASABE –CSBE/SCGAB Annual International Meeting. Meeting Paper Number 141913445.Chang, Y.K., Zaman, Q.U., Farooque, A., Chattha, H., Read, S., Schumann, A., 2017. Sensing and control system for spot-application of granular fertilizer in wild blueberry ﬁeld. Precis. Agric. 18, 210–223.Daugman, J.G., 1985.Uncertainty relation for resolution in space, spatial frequency, andorientation optimized by two-dimensional visual cortical ﬁlters. J. Opt. Soc. Am. A. 2, 1160–1169.Daugman, J.G., 1988.Complete discrete 2-D Gabor transforms by neural networks forimage analysis and compression. IEEE Trans. Acoust. 36, 1169 –1179. Daugman, J., 1993.High conﬁdence visual recognition of persons by a test of statistical in-dependence. IEEE Trans. Pattern Anal. Mach. Intell. 15, 1148 –1161. Esau, T.J., Zaman, Q.U., Chang, Y.K., Groulx, D., Schumann, A.W., Farooque, A.A., 2014a. Pro- totype variable rate sprayer for spot-application of agrochemicals in wild blueberry.Appl. Eng. Agric. 30, 717–725.Esau, T.J., Zaman, Q.U., Chang, Y.K., Schumann, A.W., Percival, D.C., Farooque, A.A., 2014b.Spot-application of fungicide for wild blueberry using an automated prototype vari-able rate sprayer. Precis. Agric. 15, 147 –161. Esau, T., Zaman, Q., Groulx, D., Corscadden, K., Chang, Y., Schumann, A., Havard, P., 2016.Economic analysis for smart sprayer application in wild blueberry ﬁelds. Precis. Agric. 17, 753–765.Gonzalez, R.C., Wintz, P., 1987. Digital Image Processing. second ed. Addison-Wesley Pub-lishing Company, Reading, Massachusetts.Hamuda, E., Glavin, M., Jones, E., 2016. A survey of image processing techniques for plant extraction and segmentation in the ﬁeld. Comput. Electron. Agric. 125, 184 –199. Kawashima, S., Nakatani, M., 1998. An algorithm for estimating chlorophyll content in leaves using a video camera. Ann. Bot. 81, 49 –54. Kurtulmus, F., Suk Lee, W., Vardar, A., 2014. Immature peach detection in colour images acquired in natural illumination conditions using statistical classi ﬁers and neural net- work. Precis. Agric. 15, 57–79.G. Ayalew, Q.U. Zaman, A.W. Schumann et al. Artiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
80LeBlanc, L., McCully, K., 2005. Weed Identi ﬁcation Guide. URL.https://novascotia.ca/agri/ documents/weed-identiﬁcation-guide.pdfAccessed on 20 June 2019. Manjunath, B.S., Ma, W., 1996. Texture features for browsing and retrieval of image data.IEEE Trans. Pattern Anal. Mach. Intell. 18, 837 –842. Pagola, M., Ortiz, R., Irigoyen, I., Bustince, H., Barrenechea, E., Aparicio-Tejo, P., Lamsfus, C.,Lasa, B., 2009.New method to assess barley nitrogen nutrition status based on imagecolour analysis: comparison with SPAD-502. Comput. Electron. Agric. 65, 213 –218. Sampson, M.G., McCully, K., Sampson, D., 1990. Weeds of Eastern Canadian Blueberry Fields. Nova Scotia Agricultural College Bookstore. Truro, Nova Scotia.Statistics Canada, 2018. Table 32-10-0417-01: Fruits, berries and nuts. URL. https:// www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=3210041701 Accessed on 06 August 2018.Statistics Canada, 2019. Table 32-10-0364-01: Estimates, production and farm gate valueof fresh and processed fruits. URL. https://www150.statcan.gc.ca/t1/tbl1/en/tv. action?pid=321003640Accessed on 18 June 2019.Swain, K., Zaman, Q., Schumann, A.W., Percival, D.C., 2009. Detecting weed and bare-spot in wild blueberry using ultrasonic sensor technology. Paper presented at the 2009ASABE Annual meeting, Grand Sierra Resort and Casino, Reno, Nevada. ASABEPaper Number: 096879.Swain, K.C., Zaman, Q.U., Schumann, A.W., Percival, D.C., Bochtis, D.D., 2010. Computer vi- sion system for wild blueberry fruit yield mapping. Biosyst. Eng. 106, 389 –394.Tang, L., Tian, L., Steward, B.L., 2003. Classiﬁcation of broadleaf and grass weeds using Gabor wavelets and an artiﬁcial neural network. Trans. ASAE 46, 1247 –1254. Tian, L., Reid, F., Hummel, J.W., 1999. Development of a precision sprayer for site-speci ﬁc weed management. Trans. ASAE 42, 893 –900. Tian, L., Reid, J.F., Hummel, J.W., 2000. Development of a precision sprayer for site-speci ﬁc weed management. Technical Report. University of Illinois. Agricultural EngineeringDepartment, University of Illinois, 1304 W. Pennsylvania Ave., Urbana, IL 61801.Weihs, C., Ligges, U., Luebke, K., Raabe, N., 2005. klaR analyzing German business cycles. In: Baier, D., Decker, R., Schmidt-Thieme, L. (Eds.), Data Analysis and Decision Sup-port. Springer-Verlag, Berlin, pp. 335 –343. Yarborough, D., 2017.Blueberry crop trends 1996–2017. A presentation at the Wild Blue- berry Producers Association of Nova Scotia, 17 November 2017.Yazawa, F., 1977.Diagnosis of nutrition of crop plants by their leaf colors. Jpn. Agric. Res.Q. 11, 145–150.Zaman, Q.U., Zhang, F., Schumann, A.W., Percival, D.C., 2009. Bare spots mapping in wild blueberryﬁelds using digital photography. Paper written for presentation at the 2009ASABE Annual International Meeting, Reno Nevada, June 21 –June 24, 2009. ASABE Paper Number 095582.G. Ayalew, Q.U. Zaman, A.W. Schumann et al. Artiﬁcial Intelligence in Agriculture 5 (2021) 72 –81
81