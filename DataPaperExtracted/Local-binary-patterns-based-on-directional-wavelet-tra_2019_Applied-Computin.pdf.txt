Original Article
Local binary patterns based on directional wavelet transform forexpression and pose-invariant face recognition
Mohd. Abdul Muqeeta,⇑, Raghunath S. Holambeb
aElectrical Engineering Department, Muffakham Jah College of Engineering and Technology, Hyderabad, TS 500034, India
bDepartment of Instrumentation Engineering, S.G.G.S Institute of Engineering and Technology, Nanded, Maharashtra 431606, India
article info
Article history:Received 1 July 2017Revised 21 October 2017Accepted 15 November 2017Available online 13 December 2017Keywords:Face recognitionDirectional wavelet transform (DIWT)Local binary patterns (LBP)abstract
Face image variations such as expression and pose radically increase the intra-class variations whichaffect the performance of feature extraction methods. It is desirable to extract more robust local discrim-inative features to effectively represent such face variations. This paper proposes a novel facial featureextraction method which utilizes interpolation-based directional wavelet transform (DIWT) and localbinary patterns (LBP). An efﬁcient direction assessment method based on quadtree partitioning is imple-mented to facilitate adaptive direction selection in the local regions from the face images to obtain DIWTsub-bands. LBP histogram features are extracted from selected top-level DIWT sub-bands to obtain localdescriptive feature set. Experimental results are simulated on ORL database, GT database, and FEI data-base. A comparison with various contemporary methods which include holistic, local descriptors andLBP-based non-adaptive multiresolution analysis methods illustrate the efﬁcacy of the proposed method./C2112017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is anopen access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
1. IntroductionIn the security-heightened world, face recognition has emergedas a popular biometric recognition method with non-intrusive andlow precision equipment for image acquisition. Prominent holisticface recognition methods are PCA[1], LDA[2], and locality preserv- ing projections (LPP)[3]. Local descriptors[4–7]are attaining much interest due to their ease of implementation and robustnessto noise. Local binary patterns (LBP) [4]are effectively applied for facial feature extraction owing to its texture discrimination capa-bility and computational efﬁciency [5]. Jabid et al.[6]proposed a robust local facial feature descriptor based on local directional pat-terns (LDP) and conﬁrmed good results compared to LBP. But LDPexhibit sensitivity to noise and rotation. Weber local descriptors(WLD)[7]are more descriptive and computationally efﬁcient thanLBP. Recently, Zhang et al.[8]used the WLD to extract local facialfeatures at predeﬁned facial landmarks and effectively capturedpose-invariant features. Ullah et al. [9]applied WLD for gender classiﬁcation from face images. Although such local descriptorsachieve higher recognition results than holistic methods, their per-formance restricts due to variations in expression, pose, illumina-tion and occlusion.DWT-based methods are increasingly admired for face recogni-tion and assure good recognition results with certain modiﬁcationin the way the DWT sub-bands are utilized [10–12]. But due to iso- tropic property and less directionality, these methods do notassure superior recognition results for moderate to extreme varia-tions in expression and pose. Numerous multiresolution analysis(MRA) methods with anisotropic scaling and better directionalityare combined with LBP to extract MRA-based local descriptive fea-tures. Local Gabor binary patterns (LGBP) [13]combine the Gabor ﬁlters with LBP and provide high accuracy at the cost of highdimensionality histogram features. Arousi et al. [14]presented a face recognition technique under illumination-variant conditionsusing the SPT decomposition and LBP. Recently, Zou et al. [15] evolved a new feature descriptor based on the curvelet transformand LBP. Here, authors used the LBP coded image of low-frequency approximation sub-band and mid-frequency subbandsto form the feature set. These MRA [10–12]and LBP-based MRA methods[13–15]despite capturing the directional informationlack the adaptation in selecting directions based on image charac-teristics. Moreover, suffer from various issues such as sub-bandselection to form an efﬁcient feature set, a high computational rate,
https://doi.org/10.1016/j.aci.2017.11.0022210-8327//C2112017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).⇑Corresponding author at: Electrical Engineering Department, Muffakham JahCollege of Engineering and Technology, Banjara Hills, Hyderabad 500034, TS, India.E-mail address:ab.muqeet2013@gmail.com (M.A. Muqeet). Peer review under responsibility of King Saud University.
Production and hosting by ElsevierApplied Computing and Informatics 15 (2019) 163–171
Contents lists available atScienceDirect
Applied Computing and Informatics
journal homepage: www.sciencedirect.com
and complex ﬁlter design. Face variations mainly affect the edgemanifolds of an image and if directional information and orienta-tion of such edge manifolds can be approximated adaptively it willsigniﬁcantly improve the performance.Adaptive directional lifting wavelet transforms [16–18]due to the beneﬁt of directional lifting and adaptation in the directionselection as per characteristics of the image have been effectivelyused for image compression. Chang et al. [16]proposed a direction adaptive discrete wavelet transform (DA-DWT) for image compres-sion. Only one pair of lifting step and non-interpolated distant inte-ger samples are used to realize directional lifting. Here Nevilleﬁlters[21]are used as the prediction and update ﬁlters. Dinget al.[17]suggested adaptive directional lifting (ADL) for imagecoding and used interpolated fractional samples. ADL methodcould be implemented with one or two pairs of lifting steps with5/3 or 9/7 tap ﬁlters[20]. Maleki et al.[18]proposed directional wavelets (DIW) with megaquad partitioning algorithm in the adap-tive directional lifting based framework to efﬁciently capture edgefeatures.Furthermore, due to lifting based factorization, perfect recon-struction is also assured and the resultant multiresolution imageis completely compatible with that of the conventional 2-D DWTmultiresolution image. Recently, Muqeet and Holambe proposeda face recognition method[19]using DA-DWT[16]for face veriﬁ- cation and established its effectiveness compared to variousfamous subspace and non-adaptive MRA methods.To effectively deal with the expression and pose variation inface images this paper consider the underlying theory of DIWand proposes interpolation-based directional wavelet transform(DIWT). In the implementation of DIWT, we used quadtree parti-tioning instead of megaquad partitioning which is used in DIW[18]. LBP is applied to the selected top-level DIWT sub-bandswhich eventually extract the descriptive histogram features.Finally, LDA is applied to obtain discriminant features in reducedspace. Nearest Neighbor (NN)[2]classiﬁer is used in an identiﬁca-tion process. The outline of the paper is depicted as follows. Areview of the related methodology is explained in Section 2includ- ing the DIWT and LBP. Further, in Section 3, proposed facial feature extraction method is explained. In Section 4experimental results are performed on three eminent face databases and results of theproposed method are compared with various contemporary meth-ods. Conclusions based on the method are presented in Section 5.2. Material and methodsThe primary motivation of the proposed method is to obtainefﬁcient MRA-based local descriptive features from the faceimages. The subsections will illustrate the DIWT with theimproved quadtree partitioning method, and review LBP and itsimportance in proposed facial feature extraction method.2.1. Directional wavelet transform (DIWT)The essence of directional wavelet transform (DIWT) is to per-form the lifting wavelet transform steps at a viable variety of direc-tions while preserving the characteristics of multiresolution,localization, and isotropy intact. The DIWT still performs the con-ventional lifting wavelet transform but consist of modiﬁcation inthe prediction and update step. The 2-D DIWT can be realized withonly one pair of lifting step, which means only one prediction stepfollowed by one update step.LetX¼f ði;jÞji;j2Z
2gsignify an image deﬁned on a 2-D orthog-onal sampling grid. Letx
e¼xð2i;jÞandxo¼xð2iþ1;jÞrepresent even and odd samples respectively. Here we consider row sub-sampling. Column sub-sampling follows the same relations withexchange of row and column variables.In the prediction step, odd samples xoði;jÞ2X oare predicted from even samplesx
eði;jÞ2X e. The prediction of each odd sampleis a linear combination of neighboring even samples with a strongcorrelation. We express that the pixels have a strong correlation inthe directiond. Here samples from six even rows are selected totake part in prediction step given in (1)and the generated high- pass sub-bandHði;jÞis depicted in(2),
Pðxoði;jÞÞ ¼XNp/C01n¼/C0N
pKpn/C1xeðiþn;jþntan/C01dÞð1ÞHði;jÞ¼g
H/C1½xoði;jÞ/C0Pðxoði;jÞÞ/C138 ð2Þ
where 2N p,Kp, andgHare the length of the prediction ﬁlter, thecoefﬁcient of the prediction ﬁlter, and scaling factor respectively.Now in update step, even samples x
eði;jÞare updated from odd row samples of high pass signal along the same optimal directiond. Similarly samples from six nearest even rows take part in updatestep. The update step and the low-pass sub-band Lði;jÞare given in (3) and (4)respectively,
Uðxeði;jÞÞ ¼XNu/C01n¼/C0N
uKun/C1xoðiþn;jþntan/C01dÞ/C0Pðx
oðiþn;jþntan/C01dÞÞ"# ð3ÞLði;jÞ¼g
L/C1½xeði;jÞþg/C01H/C1½UðHði;jÞÞ/C138/C138 ð4Þ
where 2N u,Ku, andgLare the length of the update ﬁlter, the coefﬁ-cient of the update ﬁlter, and scaling factor respectively. Neville ﬁl-ters[21]with six vanishing moments are used for prediction andupdate ﬁlter[16], i.e.N
p¼N u¼3. These ﬁlters possess linear phasecharacteristics with high vanishing moments which increase theirtexture discrimination capability. From [21], the coefﬁcients of the prediction ﬁlter can be obtained as K
pn¼½3;/C025;150;150; /C025;3/C138=2
8and the coefﬁcients of update ﬁlter can be obtained asK
un¼½3;/C025;150;150;/C025;3/C138=29. For our feature extractionmethod, we consider ﬁve directions aligned at f45
/C14;72:5/C14;90/C14; 112:5
/C14;135/C14g[18]. This direction set is used to demonstrate the efﬁ-cacy of DIWT to capture directional multiresolution features. Thetermjþntan
/C01in(1) and (3)may not always be an integer sampleand does not exist on the original sampling grid. Consequently, aninterpolation scheme is carried out to estimate the intensity at thisnon-integer sample[18],
xðiþn;jþntan/C01dÞ¼XNc/C01l¼/C0N
cal/C1xðiþn;½jþntan/C01d/C0l/C138Þ ð5Þ
where½/C1/C138denotes the integer part,N c¼1 and a/C01¼a0¼0:5 which selects the two closest even samples for interpolation [18]. The inte- ger samples used to interpolate the non-integer samples at the opti-mal directiondhave to be even sampled. If the optimal directioncrosses over the integer sample the value is estimated by the near-est even sample otherwise, the fractional sample is calculated frominterpolation of two nearest even samples as given in (5). The sub- pixel interpolation improves the directional orientation property ofthe image and maximises the compaction of image energy into lowfrequency sub-band.
Due to face variations, each face image contains a varyingamount of information located at different local pixel regions. Toconsider these local regions the quadtree partitioning scheme isapplied which facilitate effective direction assignment. Here eachface image is quadtree partitioned into non-overlapping blocksand a direction from the direction set is selected for each blockbased upon the minimum value of the prediction error energy.All the pixels in a quadtree block will have the same direction.164 M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171The proposed partitioning scheme used in our proposed method isexplained here. Let each face image is quadtree partitioned intonon-overlapping blocks with initial block size as S
iniand minimum block size asS
minwhere quadtree partitioning need to stop. Eachblock is denoted byS
b2Xand sample from each block is denotedasx
Sb2S b. The energy summation of the prediction error for eachblock is calculated as,
PEðSdb;iÞ¼X
ikxSb;i/C0P Sb;iðxSb;iÞk22þkDð6Þ
The complexity of this partitioning is controlled by a value ofLagrangian multiplierk, speciﬁcally if we set it to zero; we mayobtain a full tree and if we set it to1does not allow any partition- ing[18].Dis the number of bits spent on signaling the selection ofdirection. The direction which gives the minimum prediction erroris obtained as,
db¼argmin ifPEðSdb;iÞg ð 7Þ
To check each of quadtree partition is an optimal partition ornot, an improvement in the quadtree partitioning is presented.Now further quadtree partitioned each block S
binto four sub- blocksS
b;r;r¼1;...;4 and for eachS b;rcalculate the prediction errorPEðS
db;rÞand consecutively the direction d b;r.I f PEðS
db;rÞPPEðSdbÞand size of sub-blockS b;rreaches toS minthen stop partitioning and store the optimal direction and optimal blockotherwise, repeat the previous step of quadtree partitioning. Quad-tree partitioned blocks improves the adaptive direction selection ofpre-assigned ﬁve directions and thus the edge manifolds present atthe diagonal directions including horizontal and vertical directioncan be effectively approximated in DIWT implementation.The above-mentioned 1-D process can be easily extended to the2-D case where second dimension lifting is again performed onHði;jÞhigh pass andLði;jÞlow pass sub-bands generating foursub-bandsLHði;jÞ,LLði;jÞ,HHði;jÞ, andHLði;jÞ. The schematic of 2- D DIWT is presented inFig. 1. Partitioning structure with directionestimation is presented inFig. 2for a face image from GT database[23].2.2. Local binary patternsThe local binary patterns (LBP)[4]has emerged as an efﬁcient local feature descriptor for face recognition [5,13–15]. To assign a label for each pixel, the LBP operator uses its intensity value as athreshold and compares it against pixel values in a 3 /C23 neighbor- hood and considers the result as a binary number. Generally, theLBP is computed withPsampling pointsðx
p2ð0;...;P/C01ÞÞin the neighborhood of center pixelx
mðic;jcÞat a radial distance given byR[4],
LBP P;R¼XP/C01p¼0ts/C1ðxp/C0x mÞ/C12pð8Þt
sðdiffÞ¼1;ðdiffÞP10;ðdiffÞ<0/C26 ð9Þwheret sðdiffÞis a threshold function.Fig. 3illustrates the LBP oper- ator and the consequent label for center pixel x
m. If the sampling pointsp’sare not mapped in the neighborhood of the center pixel,they are bi-linearly interpolated[4]. Ojala et al.[4]introduced uni- form patterns, where a binary pattern is uniform if it contains atmost two bitwise transitions from 0 to 1, or vice versa when thebinary pattern is considered circularly,
UðLBP P;RÞ¼jsðx p/C01/C0x mÞ/C0sðx 0/C0x mÞj þXP/C01p¼1jsðx p/C0x mÞ/C0sðx
p/C01/C0x mÞj ð 10Þ
It was veriﬁed that ‘‘uniform” patterns are fundamental pat-terns of local image textures[4]. In the mapping ofLBP
P;Rto LBP
u2P;R, subscriptu2means that the uniform patterns U(LBP)have a value of at most 2. There areP/C2ðP/C01Þþ2 uniform patterns and remaining non-uniform patterns are accumulated into one sin-gle bin resulting inP/C2ðP/C01Þþ3 feature dimension. After LBPlabeling of the image, codes of all pixels of an input image x
Lði;jÞ are collected and formed into a histogram [4]given as,
Hl¼X
i;jFfx Lði;jÞ¼lg;l¼0;1;2;...;n/C01ð11ÞFfAg¼1;if A is true0;if A is false/C26 ð12Þ
wherenis the number of different labels produced by the LBP oper-ator. WithLBP
u28;1, the feature dimension is 59. The LBP histogram isa composition of micro-patterns and provides information aboutthe local distribution of spots, edges over the entire image. LBP
Fig. 1.Schematic of 2-D DIWT.
Fig. 2.(a) Face image (GT face database). (b) Quadtree partitioning structure withdirection estimation.
Fig. 3.Example of LBP computation.M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171 165has tolerance to illumination and offer simplicity in implementationand can be effectively used for local feature descriptor in our pro-posed method.
3. Proposed face recognition methodIn the proposed method, LBP histograms are extracted fromDIWT sub-bands to form a novel MRA-based local feature descrip-tor. To achieve this, we perform DIWT decomposition and considerthe top-level low-frequency approximation sub-band LLand high- frequency sub-bandsHL, andLH.Due to the adaptive direction selection within the quadtree partitioned blocks and directionallifting, dependencies found over image discontinuities can beeffectively de-correlated which concentrate most of the energy ofhigh-frequency sub-bands into low-frequency LLsub-band[17]. But the sub-bandsHLandLHalso contain edge and contour detailsof face images signiﬁcant in extracting pose and expression rele-vant features with the aid of LBP. We ignored the high-frequencyHHsub-band as it mostly contains the noise with negligible featuredetails. Histogram encoded for the whole sub-band describes onlythe occurrences of the micro-patterns without describing theirlocation information. To preserve the spatial characteristics andto a form a robust local feature descriptor, multi-region LBP
u28;1uni- form pattern-based histograms features [4]are obtained from non- overlapping regions of DIWT sub-bands { LL,HL,LH}.LBP
u28;1patterns are statistically signiﬁcant and offer reduced dimensionality withincreased robustness to noise.Each of the sub-band {LL,HL,LH} is equally divided intomnon- overlapping rectangle regionsR
0;R1;...;R m, each of sizex/C2ypix- els. From each of thesemregions we extract local histogram fea-turesLBP
Rkeach with 59 labels separately. Local histogramsfeatures from successive regions are concatenated to form amulti-region single enhanced histogram feature with dimension59/C2m. LetLL
Hl;k,HL Hl;k, andLH Hl;kdenote the concatenated his- togram features forLL,HL, andLHsub-bands respectively,
LLHl;k¼X
i;jFfLL Lði;jÞ¼lgLLfði;jÞ2R kgð13ÞHL
Hl;k¼X
i;jFfHL Lði;jÞ¼lgHLfði;jÞ2R kgð14ÞLH
Hl;k¼X
i;jFfLH Lði;jÞ¼lgLHfði;jÞ2R kgð15Þ
wherel¼0;1;2;...;n/C01;k¼0;...;m/C01.
FurthermoreLL Hl;k,HL Hl;k, andLH Hl;khistogram features are concatenated to formLBP
FVfeature set representing DIWT-based local histogram feature,LBP FV¼½LL Hl;k;HLHl;k;LH Hl;k/C138ð16Þ
We have maintained 128/C2128 pixels uniform size for faceimages of all the face databases. Each of the DIWT sub-bands { LL, HL,LH} is of size 32/C232 pixels. In our proposed method each ofthese sub-bands is divided intom¼16 regions withx/C2y¼8/C28 pixels regions with collective dimension of LBP_FVis 59/C2m/C23¼2832. The consideration of size of each regionx/C2y¼8/C28 and obtaining 16 regions from the DIWT sub-bandcoefﬁcients provides a trade-off between recognition performanceand feature vector length. The multi-region histogram featureLBP
FVprovides a novel DIWT-based local descriptive feature fromthe sub-band coefﬁcients. LDA is applied to LBP
FVto obtain reduced dimension discriminant feature space. Similarly, DIWTand consecutively LBP are applied on test face images to obtain testhistogram features. Next, LDA is applied to obtain the reduceddimension test features. Finally, we apply the NN classiﬁer to clas-sify test features in the reduced space for face identiﬁcation. Theoverall ﬂow of the proposed method is presented in Fig. 4.4. Experimental resultsAll experiments are conducted using Matlab 2014a on a stan-dard i3-330 2.13 GHz machine with 2.0 GB RAM. To evaluate theefﬁcacy of the proposed expression and pose-invariant featureextraction method, we consider three face databases such as ORLdatabase[22], Georgia Tech (GT) database[23]and FEI face data- base[24,25]. Face feature extraction methods such as LDA [2], LPP[3], LBP[5], LDP[6], WLD[7], LGBP[13], and LSPBPS[14] and CTLBP[15]have been compared against our proposed method.4.1. Parameter settingsIn this sub-section, we discuss parameter settings for imple-mentation of our proposed and different comparative methods.With face image size 128/C2128, the DIWT decomposition level J for all the databases is selected two as optimal [19]. A set of experiment is also conducted on databases to select theoptimal value ofS
iniandk. The parameterS iniis the initial block size required to start the quadtree partitioning. The parameter kcon- trols the quadtree partitioning. With reference to [19], for quadtree partitioning we select three different values of Lagrangian multi-plier, speciﬁcallyk¼5,k¼7 andk¼9 to obtain the optimal value. Again considering[19], we performed the proposed method fortwo different block sizesS
ini¼8/C28 andS ini¼16/C216 individually. We also considerS
min¼4/C24 pixels. We randomly selected ﬁveimages as training and rest images as test images for all the threedatabases. Moreover, we repeat the individual experiment onindividual database ten times and noted the average rank-one
Fig. 4.Diagram of the proposed method.166 M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171recognition rate as depicted inTable 1. Based upon the results, we considerS
ini¼8/C28 pixels andk¼9 as optimal, which demon- strate their effectiveness to capture directional features as regardsto local face variations.For LDA, and LPP based methods the NN classiﬁer is used withEuclidean distance measure. For LBP and LGBP, images are parti-tioned into the 8/C28 pixel region. For LGBP, we used ﬁlters at ﬁvedifferent scales and eight orientations [13].LBP
u28;1with NN classi- ﬁer and Chi-square distance measure is used for both the methods[5]. For LDP, 56 bin histogram features are extracted from 8 /C28 non-overlapped regions of face images. Chi-square dissimilaritymeasure is used to compare two spatially encoded LDP histogramsfeatures. For WLD, a patch size of 3 /C23 pixel is considered for cod- ing and generated histograms of differential excitation and orien-taion component are concatenated into a 2-D histogram. Laterthis 2-D histogram is encoded into a 1-D histogram to be used asthe feature vector and Chi-square dissimilarity measure is usedto compare two histograms. For LSPBPS, multi-region LBP
u28;1is obtained from all the generated sub-bands to form the featureset and Chi-square dissimilarity measure is used to compare twoLSPBPS histogram features. For CTLBP, the LBP coded image oflow-frequency sub-band with mid-frequency sub-bands are usedto form the feature set and LPP is used for dimensionality reduction[15]. To evaluate the performance we use cumulative match char-acteristic (CMC) curves[26,27]. CMC curve is used as a measure of1:midentiﬁcation system performance. It judges the ranking capa-bilities of our proposed method. Due to random selectionapproach, we run the experiment ten times on each databaseand only report the average rank-one recognition rates in all fol-lowing experiments.4.2. Experiment on the ORL face databaseThe ORL database entails 400 images composed from 40 dissim-ilar subjects with 10 diverse images of each subject. The faceimages exhibit changes in the capture time, lighting, head position,facial expressions such as eyes open or closed, smiling or not smil-ing. All the face images are resized to 128 /C2128. Some samples images of one subject are shown in Fig. 5. We randomly chooseN(N= 2, 3, 4, 5) images of each subject fortraining and the rest images for testing. Table 2shows the average rank-one recognition rates of different comparative methods.SelectingN= 5 randomly, the average CMC for different methodsare also depicted inFig. 6. It is visible both fromTable 2and Fig. 6that the proposed method yields superior results. A substan-tial improvement of 11.77%, 10.72% can be observed over LDA andLPP methods forN= 2. We can also observe an improvement of12.59%, 11.55%, 9.25% over LBP, LDP, and WLD respectively for N = 2. Compared with LBP-based non-adaptive MRA methods suchas LGBP, LSPBPS, and CTLBP our method exhibit higher rank-onerecognition rates even for fewer numbers of training images. Theproposed method makes an adaptive selection of best lifting direc-tion from the direction set and uses interpolated samples at thespatial resolution of ﬁve directions and preserves the local detailsof expression and pose-variant features. Such details, whenextracted in terms of LBP histogram features, improves the overallperformance.4.3. Experiments on the GT face databaseThe Georgia Tech (GT) face database comprises of 750 JPEGcolor images of 50 distinct persons. All images are captured againsta cluttered background with dissimilar facial expression, lightingconditions, and scale. All images are converted to grayscale imagesand resized to 128/C2128 pixels. Some sample images of a subjectare shown inFig. 7. We randomly considerN(N= 3 ,4 ,5 ,6 ,7 ) images of each subject for training, respectively, and in every case,the remaining images for testing. Comparative results are depictedinTable 3. The average cumulative match curves for differentmethods are described inFig. 8forN= 7. It is observed that the proposed method not only outperforms LDA and LPP but alsoexcels with LBP, LDP, and WLD. As compared to LGBP, LSPBPS,and CTLBP forN= 3, our method offers improvement of 16.80%,8.84%, and 7.30% respectively. Speciﬁcally, the improvement is sig-niﬁcant for less number of training images. LGBP, CTLBP, andLSPBPS do not provide adaptation in selecting a direction withina block of samples. Whereas, DIWT performs directional liftingwith the adaptive directional selection and considers the edgemanifolds relating to expression and pose variations effectively.Table 1Comparison of different sub-block size and value of Lagrangian multiplier (%).
Block Size/Database k¼5 k¼7 k¼98/C281 6/C216 8/C281 6/C216 8/C281 6/C216ORL 95.19 94.34 95.81 95.00 97.00 96.22GT 67.12 66.44 67.89 67.11 68.40 67.23FEI 81.78 80.25 82.60 81.00 84.67 83.50
Fig. 5.Samples face images of a subject from the ORL face database.Table 2Benchmarking of the rank-one recognition rates on the ORL face database (%).
Number of training samples per subject 2 3 4 5LDA 73.63 76.29 83.33 87.00LPP 74.50 78.00 87.75 90.50LBP 72.94 80.61 86.39 90.49LDP 73.81 83.22 85.58 91.00WLD 75.73 84.60 89.37 92.50LGBP 79.20 83.90 90.43 92.52LSPBPS 81.27 84.50 92.10 94.50CTLBP 82.50 84.86 93.33 95.00Proposed method (DIWTLBP) 83.45 88.26 94.17 97.00M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171 167Moreover, LBP histogram features from DIWT sub-bands containmost signiﬁcant details which improve the recognition rate.4.4. Experiments on the FEI face databaseThe FEI database contains 14 color images of 200 subjects takenagainst a white homogenous background. The images are inupright front position but a proﬁle rotation of about 180
/C14is consid- ered while capturing the images which increase the complexity ofthis database[25]. Sample images of a subject are shown in Fig. 9. All the images are manually cropped and resized to 128 /C2128 pixels and converted to grayscale images. We randomly choose N(N= 3, 4, 5, 6, 7) images of each subject for training and the restimages for testing.Table 4illustrates the average rank-one recog-nition rates for different methods. The average CMC curves for dif-ferent methods are depicted inFig. 10forN= 7. LDA and LPP being holistic methods fail to consider the extreme expression and posevariations. We observe an improvement of 21.10%, 14.24%, and10.89% over LBP, LDP, and WLD respectively for N= 3. As compared to LSPBPS and CTLBP which considers more sub-bands to achievegood results we used only three top-level sub-bands of DIWT toeffectively generate descriptive features using the LBP histogram.WhenN= 6, there is an improvement of 6.81%, 5.96%, and 4.82%over LGBP, LSPBPS, and CTLBP respectively. Thus the proposed
Fig. 6.CMC curves of comparative methods for ORL database.
Fig. 7.Samples face images of a subject from the GT face database.
Table 3Benchmarking of the rank-one recognition rates on the GT face database (%).
Number of training samples per subject 3 4 5 6 7LDA 31.50 45.45 48.40 52.22 58.50LPP 45.17 54.55 57.60 64.89 70.75LBP 43.20 51.64 56.20 62.78 68.74LDP 47.33 56.71 61.45 66.40 72.75WLD 52.00 60.82 64.40 71.22 75.49LGBP 48.67 58.91 63.80 70.00 74.76LSPBPS 53.33 61.36 66.20 73.56 77.50CTLBP 54.23 62.35 67.60 74.89 78.73Proposed method (DIWTLBP) 58.50 65.66 68.40 77.33 82.25168 M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171method also works well for the database with a large number offace images under pose and expression variations.4.5. Comparison with different adaptive directional lifting methodsIn order to demonstrate the efﬁcacy of DIWT with ﬁve direc-tions, we compare it with two adaptive directional lifting methodssuch as ADWT with nine directions [19]and ADL[17]with nine directions with 9/7 tap ﬁlters. To implement ADWT and ADL, sim-ilar settings from Section4.1are considered such asJ=2 , S
ini¼8/C28,S min¼4/C24 andk= 9. Furthermore, for a fair compar-ison similar LBP setting are also applied for histogram featureextraction. For ORL databaseN= 5, and for GT and FEI face databaseN= 7 images are randomly considered as training images and restas testing images.Table 5illustrates the comparative results.ADWT incorporates block-based partitioning and do not considersthe interpolation of fractional samples. In our proposed methodquadtree partitioning scheme and incorporation of interpolationmechanism for fractional samples considers the face image charac-teristics more efﬁciently. In ADL, adaptation of nine directionsincreases computational complexity.4.6. Computational complexityThe proposed method also has a comparable computationaltime for feature extraction compared with different methods.Fig. 11shows the computation time of some of the comparativemethod to process an ORL database face image of size 128 /C2128
Fig. 8.CMC curves of comparative methods for GT face database.
Fig. 9.Samples face images of a subject from the FEI face database.
Table 4Benchmarking of the rank-one recognition rates on the FEI face database (%).
Number of training samples per person 3 4 5 6 7LDA 46.73 48.20 56.89 68.50 74.29LPP 48.55 51.20 59.78 72.00 78.00LBP 51.36 56.40 65.33 74.25 84.57LDP 55.82 65.32 67.61 77.25 86.29WLD 58.00 67.60 70.19 78.57 86.86LGBP 54.73 63.00 75.11 82.00 87.71LSPBPS 59.45 66.20 76.67 82.75 88.29CTLBP 60.91 64.40 78.89 83.75 90.29Proposed method (DIWTLBP) 65.09 73.80 84.67 88.00 91.14M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171 169pixel resolution and to produce the features and no further step ofdimensionality reduction and classiﬁcation is applied. We mainlyconsidered those methods which require the feature extraction atthe pre-processing stage. The LGBP method has the highest compu-tation time.5. ConclusionThis paper offered a novel expression and pose-invariant facialfeature extraction method primarily based on DIWT-based LBP his-togram features. To implement the DIWT an effective quadtreepartitioning scheme is implemented. DIWT provides adaptationin directional selection based on image characteristics and efﬁ-ciently represents image edge manifolds. Multi-region LBP his-togram features from the top level sub-bands { LL,HL,LH} form an efﬁcient feature set. According to Tables 2–4, it is proven that the proposed method demonstrates superior discrimination abilityand yields the best rank-one recognition results for the selectedface databases. From the results, we can signify that the proposedmethod not only excels with the holistic method such as LDA andLPP but also demonstrate superiority against various local descrip-tors such as LBP, LDP, and WLD methods for face images with les-ser to extreme expressions and pose variations. Our experimentalresults verify that the proposed method also outperforms somenon-adaptive LBP-based MRA methods such as LGBP, LSPBPS, andCTLBP. We also demonstrated the effectiveness of our method overother adaptive directional lifting methods.References[1]M. Turk, A. Pentland, Eigenfaces for recognition, J. Cognit. Neurosci. 3 (1)(1991) 71–86
.[2]
P.N. Belhumeur, J.P. Hespanha, D.J. Kriegman, Eigenfaces vs. Fisherfaces:recognition using class speciﬁc linear projection, IEEE Trans. Pattern Anal.Mach. Intell. 19 (7) (1997) 711–720
. [3]
X. He, S. Yan, Y. Hu, P. Niyogi, H. Zhang, Face recognition using laplacianfaces,IEEE Trans. Pattern Anal. Mach. Intell. 27 (3) (2005) 328–340
. [4]
T. Ojala, M. Pietikäinen, T. Maenpää, Multiresolution gray-scale and rotationinvariant texture classiﬁcation with local binary patterns, IEEE Trans. PatternAnal. Mach. Intell. 24 (7) (2002) 971–987
. [5]
T. Ahonen, A. Hadid, M. Pietikäinen, Face description with local binarypatterns: application to face recognition, IEEE Trans. Pattern Anal. Mach.Intell. 28 (12) (2006) 2037–2041
. [6] T. Jabid, M.H. Kabir, O. Chae, Local directional pattern (LDP)-a robust imagedescriptor for Object Recognition, in: Proceedings of 7th IEEE InternationalConference on Advanced Video and Signal Based Surveillance, 2010, pp. 482–487.[7]
J. Chen, S. Shan, C. He, et al., WLD: a robust local image descriptor, IEEE Trans.Pattern Anal. Mach. Intell. 32 (9) (2010) 1705–1720
. [8]
Z. Zhang, L. Wang, Q. Zhu, S.K. Chen, Y. Chen, Pose-invariant face recognitionusing facial landmarks and weber local descriptor, Knowl.-Based Syst. 84(2015) 78–88
.[9] I. Ullah, M. Hussain, G. Muhammad, H. Aboalsamh, G. Bebis, A.M. Mirza,Gender recognition from face images with local WLD descriptor, in: 19thInternational Conference Systems, Signals and Image Processing (IWSSIP), pp.417, 420, 11–13 April 2012.[10]
J.T. Chien, C.C. Wu, Discriminant waveletfaces and nearest feature classiﬁersfor face recognition, IEEE Trans. Pattern Anal. Mach. Intell. 24 (12) (Dec. 2002)1644–1649
.[11]
Z.H. Huang, W.J. Li, J. Wang, T. Zhang, Face recognition based on pixel-level andfeature-level fusion of the top-level’s wavelet sub-bands, Info. Fusion 22(2015) 95–104
.[12]
Z.H. Huang, W.J. Li, J. Shang, J. Wang, T. Zhang, Non-uniform patch based facerecognition via 2D-DWT, Image Vision Comput. 37 (2015) 12–19
. [13] W. Zhang, S. Shan, W. Gao, H. Zhang, Local Gabor binary pattern histogramsequence (LGBP): a novel non-statistical model for face representation andrecognition, in: Proceedings of IEEE International Conference and ComputerVision, 2005, pp. 786–791.[14]
M. El Aroussi, M. El Hassouni, S. Ghouzali, M. Rziza, D. Aboutajdine, Localsteerable pyramid binary pattern sequence LSPBPS for face recognitionmethod, Int. J. Signal Process. 5 (4) (2009) 281–284
.
Fig. 10.CMC curves of comparative methods for FEI face database.
Table 5Rank-one recognition rates for different LBP-based adaptive directional transformmethods (%).
Database ADWTLBP ADLLBP DIWTLBPORL 95.00 95.50 97.00GT 81.72 81.00 82.25FEI 89.67 90.80 91.14
00.511.522.5Seconds
Fig. 11.Computation time for ORL face image.170 M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171[15] L. Zhou, W. Liu, Z.M. Lu, T. Nie, Face recognition based on curvelets and localbinary pattern features via using local property preservation, J. Syst. Software95, 209–216.https://doi.org/10.1016/j.jss.2014.04.037 . [16]C.L. Chang, B. Girod, Direction-adaptive discrete wavelet transform for imagecompression, IEEE Trans. Image Process. 16 (5) (May 2007) 1289–1302
. [17]
W. Ding, F. Wu, X. Wu, S. Li, H. Li, Adaptive directional lifting-based wavelettransform for image coding, IEEE Trans. Image Process. 16 (2) (Feb. 2007) 416–427
.[18]
A. Maleki, B. Rajaei, H.R. Pourreza, Rate-distortion analysis of directionalwavelets, image processing, IEEE Trans. Image Process. 21 (2) (2012) 588–600
. [19] M.A. Muqeet, R.S. Holambe, Local appearance-based face recognition usingadaptive directional wavelet transform, J. King Saud Univ. – Comput. Inform.Sci. (2017),https://doi.org/10.1016/j.jksuci.2016.12.008 . [20]
W. Sweldens, The lifting scheme: construction of second generation wavelets,SIAM J. Math. Anal. 29 (2) (1998) 511–546
.[21]J. Kovacevic, W. Sweldens, Wavelet families of increasing order in arbitrarydimensions, IEEE Trans. Image Process. 9 (3) (2000) 480–496
. [22] [Online] ORL database, http://www.uk.research.att.com/pub/data/att_faces.zip.[23] [Online] GT Database,http://www.aneﬁan.com/research/facereco.htm . [24] [Online] FEI Database,http://fei.edu.br/cet/facedatabase.html . [25]
G. Thomaz, C. Eduardo, G. Antonio, A new ranking method for principalcomponents analysis and its application to face image analysis, Image Vis.Comput. 28 (2010) 902–913
. [26] P. Phillips, P. Grother, R. Michaels, D. Blackburn, T. Elham, J.Bone, FRVT 2002: Facial Recognition Vendor Test, Technical report,DoD, April 2003.[27] V. Štruc, N. Pavešic, The Complete Gabor-Fisher Classiﬁer for Robust FaceRecognition, EURASIP Advances in Signal Processing, vol. 2010, 2010,https://doi.org/10.1155/2010/847680 .M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171 171