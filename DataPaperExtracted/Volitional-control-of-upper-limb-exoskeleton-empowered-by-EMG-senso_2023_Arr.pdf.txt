Array 17 (2023) 100277
Available online 23 January 2023
2590-0056/© 2023 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-
nc-nd/4.0/ ).Volitional control of upper-limb exoskeleton empowered by EMG sensors 
and machine learning computing 
Biao Chena,b, Yang Zhoua, Chaoyang Chena,c,*, Zain Sayeedc, Jie Hub,**, Jin Qib, Todd Frushc, 
Henry Goitzc, John Hovorkad, Mark Chenga,e, Carlos Palaciod 
aDepartment of Biomedical Engineering, Wayne State University, Detroit, MI, 48201, USA 
bState Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, 200240, China 
cOrthopaedic Surgery and Sports Medicine, Detroit Medical Center, Detroit, MI, 48201, USA 
dSouth Texas Health System – McAllen Department of Trauma, McAllen, TX, 78503, USA 
eDepartment of Electrical and Computer Engineering, University of Alabama, Tuscaloosa, AL, 35487, USA   
ARTICLE INFO  
Keywords: 
Exoskeleton 
EMG 
Sensor 
Wearable device 
Machine learning 
Volitional control 
Motion pattern recognition ABSTRACT  
Processing multiple channels of bioelectrical signals for bionic assistive robot volitional motion control is still a 
challenging task due to the interference of systematic noise, artifacts, individual bio-variability, and other fac-
tors. Emerging machine learning (ML) provides an enabling technology for the development of the next gen-
eration of smart devices and assistive systems and edging computing. However, the integration of ML into a 
robotic control system faces major challenges. This paper presents ML computing to process twelve channels of 
shoulder and upper limb myoelectrical signals for shoulder motion pattern recognition and real-time upper arm 
exoskeleton volitional control. Shoulder motion patterns included drinking, opening a door, abducting, and 
resting. ML algorithms included support vector machine (SVM), artificial neural network (ANN), and Logistic 
regression (LR). The accuracy of the three ML algorithms was evaluated respectively and compared to determine 
the optimal ML algorithm. Results showed that overall SVM algorithms yielded better accuracy than the LR and 
ANN algorithms. The offline accuracy was 96 ±3.8% for SVM, 96 ±3.8% for ANN, and 93 ±6.3% for LR, while 
the online accuracy was 90 ±9.1% for SVM, 86 ±12.0% for ANN, and 85 ±11.3% for LR respectively. The 
offline pattern recognition had a higher accuracy than the accuracy of real-time exoskeleton motion control. This 
study demonstrated that ML computing provides a reliable approach for shoulder motion pattern recognition and 
real-time exoskeleton volitional motion control.   
1.Introduction 
Processing multiple channels of bioelectrical signals for bionic as-
sistive robot volitional motion control is still a challenging task due to 
the interference of systematic noise, artifacts, individual bio-variability, 
a difference of sensors or devices used for signal acquisition, and human 
limb motion speeds [1,2]. Scientists have devoted efforts to the devel -
opment of assistive robots and bionic limbs empowered by edge 
computing [3]. Machine learning (ML) has been a significant trend to be 
applied in along with other technologies for the development of the next 
generation of smart devices. Scientists believe that integrating ML into 
embedded systems can be an important approach to building the next 
generation of intelligent devices [4]. However, the deployment of an ML model on an embedded system faces major challenges. An embedded 
system used in a robotic exoskeleton system imposes constraints in terms 
of system performance accuracy, user experience, energy consumption, 
processing speed, size, and cost aiming at product commercialization 
[5]. An additional challenge is a feasibility of implementing the ML 
training process on the device for the robotic sensory and motion control 
systems that can be adapted online and used instantly. Online learning 
and adaptation are still important tasks and are required for the future 
generation of computing system when tackling real life challenges in 
unpredictable and dynamically changing environments. This paper 
presents an approach to adapting the ML computing to process twelve 
channels of shoulder myoelectrical signals for shoulder motion pattern 
recognition and real-time upper arm exoskeleton volitional control. 
*Corresponding author. Department of Biomedical Engineering, Wayne State University, Detroit, MI, 48201, USA. 
**Corresponding author. 
E-mail addresses: cchen@wayne.edu (C. Chen), hujie@sjtu.edu.cn (J. Hu).  
Contents lists available at ScienceDirect 
Array 
u{�~zkw! s{yo|kr o>!ÐÐÐ1�mtoz mont~om�1m{ y2u{�~zkw2k ~~kÞ!
https://doi.org/10.1016/j.array.2023.100277 
Received 14 November 2022; Received in revised form 15 January 2023; Accepted 20 January 2023   Array 17 (2023) 100277
2Upper-Limb Exoskeletons have been designed for use in the indus -
trial working environment [1,6–8] and medical rehabilitation [9,10]. 
Stroke survivors need long-term physical rehabilitation services [11]. 
The effective outcome of a traditional rehabilitation depends on the skill 
of therapists and the timeline of rehabilitation plans [12,13]. The 
traditional manual hands-on approach is labor-intensive and cannot 
provide long-term rehabilitation services at a low cost. The upper-limb 
exoskeleton systems have been studied and developed for upper-limb 
rehabilitation since two decades ago [14], which has shown encour -
aging results in the rehabilitation of upper limbs [15–17]. However, 
there are still many limitations and issues that exist in this area [18]. It 
still lacks a bionic/ergonomic mechanical design for the upper-limb 
exoskeleton, primarily focused on human-machine joint misalignment. 
Also, bioelectric signal-based volitional control for upper-limb exo-
skeletons is still far from satisfactory. The development of robust and 
reliable systems is still required targeting the recovery of lost motor 
control [10]. The use of active devices in rehabilitation was proved to be 
feasible [17], with direct benefits limited not only to patients with 
neuromotor injuries but also to other human movement areas of opti-
mization of the working environment [6]. 
Most of the current assistive upper limb robotic rehabilitation de-
vices use a conventional user interface (UI) such as a pushbutton or 
joystick, hands-free and intuitive interfaces are a desire of users. Current 
commercial upper arm exoskeletons used on-off mode control, this 
control strategy does not always align with patients’ intentions. Thus, a 
more intuitive control strategy is needed for the upper arm exoskeleton, 
which could be operated by the user’s intention. 
The myoelectrical signals (electromyography, EMG) contain human 
neural information that interprets the human motion intents. Stroke 
patients can still generate weak EMG signals during limb motion or 
static muscle contraction, making it feasible for an EMG-based pattern 
recognition approach in post-stroke robot-aided rehabilitation [19]. 
EMG-control mechanisms can be divided into two groups: motion 
pattern recognition-based and non-motion pattern recognition-based 
[20]. Motion pattern recognition needs artificial intelligence (AI) for 
signal processing to generate classifications. Non-motion pattern 
recognition controllers are mainly constructed on threshold control and 
finite state machines, thus output limited and predefined control com-
mands according to a sequence of input signals [21]. 
The implementation of computational techniques based on AI tech-
niques embedded in a robotic upper limb exoskeleton system represents 
the main topic for the present study. In this paper, a novel EMG-based 
online shoulder motion recognition and control system is introduced. 
The online signal sensation system and robot motion control system are 
connected by LabVIEW software using a graphical computer program -
ming approach. The essential role of this system is to connect the EMG 
acquisition system (the Delsys system) and stream all the sensors’ data 
into the analysis module of the software. The system collected raw EMG 
data for the offline machine learning (ML) training process to generate a 
trained ML model, then the trained ML model was used for online EMG 
activation-based motion pattern recognition and robot motion control. 
2.Related works 
2.1. EMG for upper arm motion pattern recognition 
The myoelectric signals (electromyography, EMG) have been 
considered a promising physiological signal for detecting motion intents 
and used in rehabilitation therapy [22–24], but system performance 
accuracy can be affected by many factors including systematic noise and 
artifacts [25–27] and individual bio-variabilities [28,29], leading to 
special procedures or electrodes required for filtering off the noise and 
on-site calibration for system setup [30,31]. Aiming at developing 
user-friendly systems, ML-based motion pattern recognition methods 
have been proposed to avoid the efforts devoted to noise removal or 
complex multiple-channel EMG signal processing [32–35]. Surface EMG (sEMG) pattern recognition has been studied for the feasibility of 
voluntary control of a robotic device [19,35,36], including EMG-based 
pattern recognition for upper-limb motion pattern recognition [37, 
38]. Most of the studies processed EMG signals only for one DoF motion 
pattern recognition [39]. We have started to develop a computer system 
that can sense muscle activation patterns and process the multiple 
channels of EMG signals for upper limb exoskeleton motion control to 
assist the activities of daily living (ADL) [34,35]. The performance has 
been evaluated and preliminary outcomes published in papers [35,40], 
however, the architecture of the EMG-controlled, ML-based computer 
system has not been introduced or published. This paper presents detail 
information regarding online data acquisition, signal processing, and 
system connection. This paper also compares the difference between 
offline analysis accuracy and online performance accuracy. 
2.2. Shoulder exoskeleton control based on the motion pattern 
Processing EMG signals for robotic upper arm control has been 
developed according to the neuromuscular characterization, but robot 
motions are still cumbersome because of the complexity of the muscu -
loskeletal system of the upper limb [41]. The EMG-controlled prosthesis 
also faces challenges from electrode placement location and pattern 
changes of EMG activation over time, leading to a longer training pro-
cess [42]. To date, most of the literatures have reported the mechanisms 
of hand/wrist control with fewer DoFs (degree of freedom) of motions 
compared with shoulder joint [41]. The bionic control of an upper-limb 
exoskeleton is more complex that the control of other joint exoskeletons 
such as the wrist, knee, or ankle joint exoskeletons. Currently, there are 
only a few of literature that reported the studies of EMG-controlled 
upper limb/shoulder exoskeletons [43–46]. Artificial 
intelligence-based wearable robotic exoskeletons for upper limb reha-
bilitation have been proposed, the main trend in the research is the 
development of wearable robotic exoskeletons controlled by the fusion 
of data collected from multiple sensors with the training of intelligent 
algorithms [10]. The focus of our current study is on shoulder/upper 
limb exoskeleton intuitive control for carrying out activities of daily 
living (ADL). The long-term goal of our research is to develop reliable 
systems through industrial or clinical validation and improvement of 
technical features targeting at intuitive control of the robot in order to 
have positive impacts on human strength augment and the rehabilita -
tion process. The current study reports an approach of EMG-based 
multiple-sensors signal fusion for shoulder motion pattern recognition 
and integration of the sensor system and ML processing system into a 
customized prototype of an upper limb exoskeleton system for intuitive 
control. This approach will enable the systems to be used in various 
applications related to robotic exoskeletons, including human perfor -
mance enhancement, workload reduction, medical rehabilitation, or 
support for daily living activities. 
2.3. Machine learning in EMG sing processing 
Machine learning (ML) computing can extract the specified features 
from the targeted data and quantify the features for model training using 
a supervised learning process [47], including K-Nearest Neighbor (KNN) 
[48], Linear Discriminant Analysis (LDA) [49], Support Vector Machine 
(SVM) [48,50,51], and Artificial Neural Networks (ANN) [52,53]. These 
supervised ML methods have been used in on EMG signal-based limb 
motion recognition, robot control, rehabilitation, and clinical research 
[54]. The accuracy of feature extraction from the EMG signals is affected 
by many factors, including EMG recording methods (such as different 
electrodes, electrode placement locations on the body surface, or 
recording devices), bio-variability (age and BMI (body mass index)), 
environmental factor (room temperature), electrical power line noise, 
and motion artifact. These factors reduce the efficiency of system 
robustness and accuracy of recognition [55], and extra efforts are sub-
sequently required in signal processing with complex procedures. B. Chen et al.                                                                                                                                                                                                                                    Array 17 (2023) 100277
3Embedded software and firmware can be used to remove systemic noise 
as shown in a signal channel system [27], multiple channels systems 
required significant efforts and computing in system setup. ML may be 
the optimal approach to processing multiple-channel EMG signals for 
robot control without devoting effort to noise removal. 
To improve the accuracy of ML in motion pattern recognition, deep 
learning (DL) has been proposed in signal processing, DL has made 
remarkable progress in image recognition, natural language, and 
behavior prediction [35,56–58]. Hinton et al. reduced the dimension -
ality of data using multiple layers of neural network algorithms [59], 
leading to the development of deep neural network structures, the 
convolutional neural network (CNN), and the recurrent neural network 
(RNN) [60–62]. DL has been used for EMG signal processing for motion 
recognition, unlike other machine learning algorithms such as KNN and 
LDA DL does not manually set standards to extract features. Through 
repeated iterations of the neural network structure to optimize the al-
gorithm, DL implements the propagation rules from the training data. 
CNN algorithm yielded better outcomes in motion pattern recognition 
by processing EMG signals [51,63–65]. The SVM and NN algorithms 
have been applied in shoulder pattern recognition without controlling a 
robot system using EMG signals recorded from six muscles of the upper 
limb among 7 healthy subjects, the results showed that NN yielded an 
accuracy of up to 88.7% during the training process while SVM obtained 
an accuracy up to 85.9% in model validation [66]. Using EMG signals 
recorded from 12 muscles of the upper limb among 15 healthy subjects, 
the results showed that CNN obtained a recognition accuracy between 
79.64% and 97.57%, the accuracy was affected by motion speed and the 
devices used for EMG signal recording [40]. 
Extreme learning machine (ELM) is a newer machine learning 
method for EMG signal processing to detect motion patterns [67]. 
During multiple EMG channel processing, the structural features of each 
EMG channel including time domain, frequency domain, and 
time-frequency domain information should be considered. For this 
reason, synergy feature extraction is required across multiple EMG 
channels for motion pattern recognition to simplify control strategy 
including the control dimensionality reduction [68]. ELM demonstrated 
an optimal performance for synergetic feature extraction of multiple 
channels of EMG signals to classify upper limb motions [69–71]. 
3.Materials and methods 
3.1. Experiment setup and experimental protocol 
Twenty-eight healthy subjects (seven males and three females, 26 ±
3.3 years) with no reported shoulder injury nor neuromuscular disorders 
were tested in this study. All of their right shoulders were used in this 
study. They were informed and signed an informed content sheet. They 
were instructed and practiced the specified movement before the real 
test. Eighteen subjects participated in the offline EMG recognition 
experiment, and 10 subjects participated in the real-time control 
experiment. This experiment has been approved by the ethics committee 
(Institutional Review Board) of Wayne State University and conforms to 
the Helsinki declaration. 
Twelve muscles ’ surface EMG signals were acquired by a commercial 
EMG acquisition system (Delsys Trigno wireless system, Delsys Inc, MA, 
USA). The twelve muscles and their corresponding functions were listed 
in Table 1. These muscles activate all shoulder and partial elbow degrees 
of freedom. All sensors were placed at the muscle belly along the muscle 
fiber direction. The skin underneath the sensors was cleaned with 70% 
alcohol, and excessive hair was removed if needed. The EMG signal 
sampling rate for each sensor was 1.11 kHz. Fig. 1 shows the system 
setup for the experiment. 
The EMG signals were processed in a real-time environment for 
shoulder motion pattern recognition using ML computing executed by 
Machine Learning Toolbox embedded in LabView software (National 
Instrument, Austin, TX). The motion pattern recognition outcomes were used for the control of an upper-limb exoskeleton system to perform 
upper-limb trajectory movements based on the user’s intents. 
The experiment was divided into two sessions: 1) offline data anal-
ysis to determine the accuracy of ML algorithms in shoulder motion 
pattern recognition, 2) real-time shoulder motion pattern recognition, 
and instant upper arm exoskeleton movement control to determine the 
accuracy of whole system performance. 
3.2. The design of an offline EMG recognition system 
Eighteen healthy subjects (ten males and eight females aged 25 ±3.1 
years) participated in the experiment aiming at motion pattern recog -
nition based on offline data analysis. Each subject was asked to follow a 
pre-recorded video performing a series of shoulder movements. The 
shoulder movements were repeated twenty times for each action, and all 
the movements should be controlled at a constant speed. The constant 
speed of movements was beneficial for the EMG data segmentation and 
feature extraction using a fixed time window during offline data 
analysis. 
The EMG sensors were placed on the muscle as shown in Table 1. 
Delsys EMGworks (Boston, Massachusetts) was used for the EMG signals 
recording and segmentation into datasets. Delsys EMGworks data 
acquisition system is a wireless EMG recording and processing system 
with 16 channels available for EMG signal recording. Twelve channels of 
EMG sensors were used in this study. Table 1 
EMG Sensors channel and muscle function.  
sEMG Sensor Muscle Functional Action 
1 Middle Deltoid Humerus Abduction 
2 Anterior Deltoid Humerus forward flexion 
3 Posterior Deltoid Humerus backward extension 
4 Supraspinatus Humerus abduction in initial 0-30•
5 Pectoralis Humerus Abduction/Inner rotation 
6 Trapezius Shoulder elevation 
7 Infraspinatus Humerus external rotation 
8 Teres Major Humerus extension toward the spine 
9 Bicep Long head – abducts the arm, rotating medially 
Short head – abducts the arm 
Flexes the shoulder joint 
10 Triceps Extensor of the elbow 
The long head extends the arm 
11 Wrist flexor Wrist joint flexion and rotation 
12 Wrist extensor Wrist joint extension and rotation  
Fig. 1.The illustration of the real-time ML-based motion pattern recognition 
and exoskeleton motion control system. Twelve wireless Delsys EMG sensors 
are placed on the muscles indexed in Table 1 for EMG signal acquisition. The 
EMG signals are processed instantly for shoulder motion pattern recognition 
using ML computing executed by ML Toolbox embedded in LabView software. 
This system was used for the control of an upper-limb exoskeleton system to 
perform upper-limb motions based on the user’s intents. B. Chen et al.                                                                                                                                                                                                                                    Array 17 (2023) 100277
4There were four consecutive phases during a movement including 
arm motion initialization, arm elevation, arm isometric hold, and arm 
return to rest. The activities of daily living (ADL) including drinking, 
open-door, abduction, and resecting were selected for motion pattern 
recognition. The detailed movements of ADL were listed in Table 2. 
These shoulder movements were studied because they are frequently 
used in rehabilitation movement training in post-stroke therapy [72,73], 
as well as in the industrial workforce [74]. 
All the EMG data were recorded by Delsys Trigno wireless system, 
and the Delsys EMGworks was used to segment and label the EMG data. 
Fig. 2 shows the flowchart of the offline EMG recognition system. Each 
subject performed 7 movements, and each movement was repeated 20 
times. For each subject, there were 140 segmented EMG signals sets. In 
the EMG model training process, 80% of the dataset was used as the 
training data, and 20% was used as the testing data. 
3.3. The design of a real-time EMG volitional control experiment 
3.3.1. The overview of the real-time control system 
Ten healthy subjects (seven males and three females, 28 ±3.5 years) 
without reported shoulder injury or neuromuscular disorders were 
recruited and tested in this real-time EMG-controlled system study. Four 
different movements including arm abduction adduction, drinking, arm 
forward and backward, and resting state was tested. Each subject was 
asked to stand still and relax the tested arm for a resting state. The 
subject performed other 3 movements respectively following a pre- 
recorded video paradigm to ensure the same movement speed of arm 
movements. 
The real-time control system consisted of two subsystems: the EMG- 
models-ML training subsystem and the online EMG-based motion 
pattern recognition subsystem. The EMG-model-training subsystem 
collected EMG raw data and performed feature extraction, and then the 
features were used for data training to generate trained machine 
learning models. 
The online-EMG-based-motion-pattern-recognition subsystem down 
streamed EMG raw signal data and perform feature extraction. The 
system then loaded the trained machine learning model from the EMG 
acquisition & training subsystem and performed real-time EMG-based 
motion pattern recognition and classification. The workflow of the two 
subsystems is shown in Fig. 3. 
3.3.2. The EMG models training subsystem 
Connected with the Delsys EGM data acquisition system, the Lab-
VIEW acquisition program was run to read all EMG signals from the 
Delsys system and perform the feature extraction process simulta -
neously. Both raw EMG signals and EMG features were saved by the 
program as a CSV formatted file. Subjects were asked to perform a non- 
stop single pattern of motion repetitive twenty times following the pre- 
recorded video paradigm. For each motion, two CSV format files (one for 
raw EMG, one for EMG features) were saved. After the acquisition 
process, Python programs were developed to combine all EMG features 
files and label the EMG features for the later training process. A customized offline machine learning training LabVIEW system was 
then used to generate machine learning models for the online EMG 
recognition process. In this study, SVM models (linear kernel-based and 
RBF kernel-based), one single-layer neural network model, and linear 
regression model were generated. The offline machine learning training 
LabVIEW system was developed using the Analytics and Machine 
Learning Toolkit. This system read the training data from the CSV file 
and generated JSON format trained models, which were used in the real- 
time system. 
The first step of the model training process was to input the CSV file 
path into the system and define the hyperparameters of the SVM and the 
ANN methods. The second step was to run the LabVIEW program. Then 
the system saved the trained models as JASON files. For each subject, 
three machine learning models including LR (logistic regression), SVM 
(support vector machine), and ANN (artificial neural network) were 
trained by their training data [35]. 
3.3.3. The real-time EMG recognition subsystem 
The real-time EMG recognition subsystem consisted of two real-time 
EMG processing functions and real-time recognition function. The EMG 
processing function was the same as the EMG acquisition and processing 
module used in the offline training process (section 2.2). The EMG 
processing function directly streamed the feature data into the online 
EMG recognition function. This EMG processing function used the 
trained model from the offline training process and made a classification 
decision based on the real-time input from the EMG processing and 
feature extraction subsystem. After the classification decision was made, 
a motion command was sent to the upper-limb exoskeleton system to 
perform the responding motion. In the system performance test, each 
subject was asked to perform the selected motions ten times for each 
motion, and the accuracy of the system performance was determined. 
Also, the tests were repeated for each machine learning model. 
3.3.4. TCP/IP connection between LabVIEW and the Delsys system for real- 
time system 
Trigno SDK software was used in the development of the EMG real- 
time control system. The Trigno SDK software was used to connect 
Trigno Avati EMG acquisition hardware and software to the LabVIEW 
software (NI, TX) for two software system interactions. Using LabVIEW, 
the program connected the Trigno SDK through an IP address and then 
communicate with a NI data board through a command port. The time 
window frame interval for Trigno SDK was set at 13.5 ms. 
For the EMG data acquisition, there were 12 EMG channels in total, 
and the sampling rate was fixed at 1.11 kHz. Since the Trigno SDK frame 
rate was fixed at 13.5 ms, thus 15 EMG samples were streamed in every 
frame interval. And 960 bytes were read from the EMG port in each 
frame interval. This accurate number of bytes (960) was defined in the 
LabVIEW program set to be read for each loop to ensure the data be 
properly translated into readable and meaningful numbers. Fig. 4 shows 
the data structure of EMG signals processing output for control. 
3.4. Signal processing and machine learning implementation 
Multiple channels of EMG signals were processed using processing 
was performed to eliminate noise and extract EMG features for pattern 
recognition using the machine learning method in the next step. 
After noise filtering, the features of EMG data were extracted. In this 
study, sliding root mean square (RMS) was used to extract the features 
from the raw EMG signals of 12 muscles with a sliding window of 540 ms 
and an overlapping window of 81 ms. These features were then input 
into the pattern recognition module. A pre-trained machine learning 
module was loaded into the system for shoulder motion pattern 
recognition. 
Three algorithms were used in our study: support vector machine 
(SVM), artificial neural network (ANN), and linear regression (LR). All 
three algorithms were designed to perform multi-patterns classification. Table 2 
The movement studied in the experiment.  
NO Name of movement Abbreviation of 
movement 
1 picking up a cup to mouth PU 
2 putting down a cup from the mouth PD 
3 pushing forward on the horizontal plane without 
resistance PF 
4 pulling backward on the horizontal without 
resistance PB 
5 shoulder abduction 90•on the coronal plane AB 
6 shoulder adduction 90•on the coronal plane AD 
7 resting of arm RE  B. Chen et al.                                                                                                                                                                                                                                    Array 17 (2023) 100277
5ANN in LabVIEW has three types of layers: the input layer, the hidden 
layer, and the output layer with all hyperparameters used to implement 
ANN algorithms [75]. 
A sigmoid function was adopted in logistic regression (LR) algorithm 
implementation. After the input dataset training, LR generated decision 
boundaries to determine classification based on the highest probability. 
In the application of multi-class classification, LR used the one vs. rest 
method. For classification with more than two classes, the one vs. rest 
method generated and trains LR models for each class vs. the rest of the 
classes. The following equation defines the logistic regression model. 
pxpy1†x]
1
1exp β0x0β1x1⋯βkxk
where. 
x is the input vector with k1 dimensions where x0 is always 1. 
y is the output vector with a value 0 or 1. β is the weight vector with k1 dimensions 
py1†xis the probability of y 1 for a known instance of x 
LabVIEW 2018 (National Instruments, USA) and Analytics and Ma-
chine Learning (ML) package were used to build the training process and 
testing processes of the three machine learning models [76]. The same 
toolbox software was used to implement the SVM and ANN ML 
processes. 
The support vector machine (SVM) finds a hyperplane in N-dimen -
sional space (N– the number of features) that distinguishes the data 
points. The algorithm finds a plane with the maximum margin so that 
the feature dataset can be classified with maximal confidence. The SVM 
algorithms can implemented using a kernel. The most common kernels 
include the linear kernel, polynomial kernel, and radial kernel. A 
polynomial kernel was used in this study. SVM algorithm has been used 
in wrist motion classification [77] and multiple channels of EMG signals 
for gait pattern recognition [78]. In this study, the same SVM ML 
method was used for multi-DoF shoulder related motions classification 
and exoskeleton motion control thereafter. Fig. 5 shows the ML method 
and procedures of training and validating an SVM model in the LabVIEW 
platform, as well as the online exoskeleton motion control. 
The artificial neural network (ANN) [79–81] used in this study is a 
feed-forward neural network, as shown in Fig. 6. Multiple hidden layer 
neuron numbers (5,10, 20, 40,60) were tested. Also, the influence of 
using multiple hidden layers was also tested. The number of output layer 
neurons was equivalent to the number of movement classes (4 classes). 
The four neurons of the output layer show the probabilities range [0,1] 
of the four-movement classes. The activation functions were set differ -
ently for each layer: rectified linear unit function (ReLu) for the hidden 
layer and Softmax for the output layer. 
3.5. Statistical analysis 
One-way ANOVA with PostHoc LSD was used to determine the sta-
tistical difference in the average accuracy of motion pattern recognition 
between different ML algorithms. The Chi-Square Pearson test was 
Fig. 2.Flowchart of training and testing trained machine models.  
Fig. 3.The workflow of EMG models training subsystem and online EMG 
recognition subsystem. The motion classification outcomes were used to control 
the upper-limb exoskeleton to perform pre-defined motions. 
Fig. 4.The data structure and flowchart of EMG signals for processing and 
transporting to the communication port. Fifteen EMG datasets were streamed 
through TCP/IP every 13.5 ms. The LabVIEW software read 960 bytes every 
13.4 ms in order to downstream the whole EMG data. Twelve EMG sensors were 
used for signal acquisition from 12 upper limb muscles. 
Fig. 5.The flowchart of SVM based EMG processing for exoskeleton mo-
tion control. B. Chen et al.                                                                                                                                                                                                                                    Array 17 (2023) 100277
6performed to determine the difference in accuracy of each motion 
pattern recognition among the three individual machine learning algo-
rithms for different motion patterns. The accuracy of motion recognition 
was also compared between offline analysis and real-time performance. 
SPSS software (Version 28, IBM, Armonk, NY) was used for statistical 
analysis. A p value smaller than 0.05 was considered to be statistically 
significant. 
4.Result 
4.1. Result of offline EMG model experiment 
4.1.1. Comparison of offline model training process 
LR training showed that loss value decreased over the iterations 
(Fig. 7). The loss value of the LR model converged rapidly in the early 
stage of training. The loss curve plateaued after about 16 iterations, 
indicating that the model had converged after 16 iterations. The cost 
function of LR is: 
Jθ 1
m⌈̂m
i1yiloghθ 
xi)
 
1 yi)
loghθ 
1 xi)⌉
where. 
hθ is the hypothesis of the LR, 
xiis the feature of the ith sample, 
yiis the predicted label of the ith sample. 
The process of automatic optimization of the SVM model showed the 
observed error decreased with the increase in iterations (Fig. 8). At the 
37th iteration, the SVM model had the smallest observed loss value, 
indicating that the SVM model achieved the most optimal parameters. 
The optimizer for SVM is Bayesian Optimization. 
The typical loss curves were found in the ANN model training and 
model validation (Fig. 9). The loss curve plateaued after about 120 it-
erations, indicating that the model has converged after 120 iterations. 
The loss function of ANN is cross-entropy Loss̂n
i1yilog}yi  
where. 
yi is the true label of the ith sample 
}yi is the predicted label of the ith sample. 
4.1.2. Comparison of classification accuracy of four ML algorithms 
Fig. 10 shows the results of three confusion matrices of validation 
from one subject ’s dataset using the three machine learning algorithms 
as classifiers. The columns in each matrix show the number of accuracies 
of each motion which were predicted by the machine learning models, 
while the rows show the accuracy of these subjects ’ actual motion out-
comes. The numbers on the diagonal line of these matrices show the 
correct prediction accuracy for the different designated motions, while 
other cells show the accuracy of the wrongly prediction. The accuracy 
was calculated from true positive, true negative, false positive, and false 
negative cases derived from the confusion matrix. The accuracy, 
together with precision, recall, and f1 score for each specific motion 
were thus obtained. 
4.2. Result of real-time robotic motion control experiment 
Fig. 11(a) shows the average accuracy of the real-time system per-
formance following the subject ’s motion using SVM as a classifier with a 
scanning time window of 135 ms. The average accuracy was 97% for 
abduction motion recognition, 99% for resting recognition 99%, 84% for 
drinking motion recognition, and 81% for pushing forward. The results 
showed 16% of real drinking motions were misclassified as abduction 
Fig. 6.Flowchart of ANN in EMG signal processing.  
Fig. 7.LR training loss over iterations.  
Fig. 8.SVM training loss value over iterations.  
Fig. 9.ANN training loss value over iterations.  B. Chen et al.                                                                                                                                                                                                                                    Array 17 (2023) 100277
7and pushing forward while 19% of really pushing forward motions were 
misclassified as abduction and drinking. 
Fig. 11(b) the average accuracy of the real-time exoskeleton system 
performance following the subject ’s motion using ANN as a classifier. 
The scanning time window was kept unchanged. The average accuracy 
of exoskeleton motion followed subject ’s motion was 95% for abduction, 
98% for resting, 74% for drinking, and 78% for pushing forward motion. 
The results showed that 26% of real-time drinking motions were 
Fig. 10.Confusion matrices of offline EMG model experiment. (a) SVM; (b) 
ANN; (c) LR. The number in the cells represents the accuracy. The number in 
cells is indexed for percentage, for example, 0.98 mean 98% of accuracy. 
Fig. 11.Confusion matrices of real-time EMG model experiment. (a) SVM; (b) 
ANN; (c)LR. B. Chen et al.                                                                                                                                                                                                                                    Array 17 (2023) 100277
8misclassified as abduction or pushing forward, while 22% of really 
pushing forward motions were misclassified as abduction and drinking. 
Fig. 11(c) shows the average accuracy of the real-time exoskeleton 
system performance following the subject ’s motion using LR as a clas-
sifier and the time window is 135 ms. The average accuracy of the 
system performance following a subject ’s motion was 88% for abduc -
tion, 98% for resting 71% for drinking, and 72% for pushing forward. 
The results show 29% of real drinking motions were recognized as 
abduction and pushing forward, leading to the exoskeleton performed a 
wrong motion. And 28% of real-time pushing forward motions were 
misclassified as abduction and drinking. 
4.3. Comparisons of offline analysis and real-time performance 
The average accuracy of offline analysis (97.0%) was higher than 
real-time performance (74%) for drinking motion pattern recognition 
and robot control (Chi-Square, Pearson test, p D0.001). 
There was no a statistical difference of performance accuracy be-
tween off-analysis (88.0%) and real-time performance (95%) for 
abduction motion pattern recognition and robot control (Chi-Square, 
Pearson test, p 0.128). 
The average accuracy of offline analysis (89.0%) was higher than 
real-time performance (78%) for forward motion pattern recognition 
and robot control (Chi-Square, Pearson test, p 0.036). 
There was no a statistical difference of performance accuracy be-
tween offline analysis (99.0%) and real-time performance (98%) for 
resting status motion pattern recognition and robot control (Chi-Square, 
Pearson test, p 0.516). 
For offline analysis, the accuracy of LR was lower than SVM and ANN 
(One-Way ANOVA PostHoc LSD, p D0.001). For real-time motion 
pattern recognition and robot control, the accuracy of SVM was higher 
than ANN and LR (One-Way ANOVA PostHoc LSD, p D0.001) (Table 3). 
5.Discussion 
This research demonstrated that multiple channels of EMG signals 
can be processed for real-time machine-learning-based upper limb mo-
tion pattern recognition and subsequent upper-limb exoskeleton motion 
control. The system consisted of twelve channels of EMG signal acqui -
sition sensors and ML-based signal processing toolkit software, a robotic 
motion control board and embedded algorithms, and an upper limb 
exoskeleton system. Three machine learning algorithms were evaluated 
for the efficiency in EMG signal processing for motion pattern recogni -
tion and then real-time exoskeleton motion control following the user’s 
intents. 
The novelties of this study included that an ML-based computing 
platform in a wearable sensor-controlled exoskeleton system was built 
that can be used to test various ML algorithms in the future. New AI 
techniques are emerging such as deep learning (DL), and extreme 
learning machine (ELM), etc., an effective platform is required to test 
new AI techniques including their applications in volitional control 
robot system. The outcomes of this study demonstrated the system 
developed in this study can perform the tasks as we desired. 
The development of a volitional controlled exoskeleton system has become a hot research topic recently. In past years, research has shown 
that a volitional control mechanism can improve the exoskeleton per-
formance and a user’s experience [82,83]. Myoelectrical signal (EMG 
signal) is a promising physiological signal used for understanding a 
user’s motion intention, and EMG signal has been widely used in 
robot-assistive rehabilitation therapy [23,24,83–85]. However, there 
are still challenges in EMG signal processing for robot control, including 
removing systematic noise and artifacts [25,26], increasing bio-fidelity 
quality such as signal-noise ratio (SNR) using special electrodes [28, 
29,31], precisely determining the onset and offset of muscle contraction 
[30,86], and reducing the complexity of algorithms [41,87]. In this 
study, using ML computing toolkits and the newer ML computing al-
gorithms, we spared of manual noise filtering, on-site threshold setup 
and calibration, and heavy-duty complex algorithm preparation for 
EMG processing steps. 
There are studies reported shoulder sEMG-based motion classifica -
tion algorithm for controlling the exoskeleton system in real-time, most 
studies remain on an offline analysis level [44,88,89], however, to our 
best knowledge, no groups have developed a real-time ML-based 
EMG-based control system for the upper arm multiple joint exo-
skeletons, hence the performance difference has not been studied pre-
viously. The results of this study demonstrated that the accuracy of 
offline motion pattern recognition was higher than the accuracy of 
real-time motion following a subject ’s designated motions. This could be 
caused by the difference in the testing environment. A subject could pay 
attention to the exoskeleton ’s motion in real-time motion control 
testing, while the subject only focused on upper limb motion, indicative 
of a distraction from checking robot motion. There was a pause between 
each test in real-time motion control testing to waiting for the robot to 
complete its movement, while during the pure motion pattern recogni -
tion for offline analysis, a subject performed the designated motion 
consecutively without waiting for the completion of exoskeleton 
movements. 
These three ML algorithms performed upper limb motion pattern 
recognition and exoskeleton motion control with an accuracy ranging 
between 71% and 98. In real-time motion pattern recognition and mo-
tion control, SVM outperformed ANN and LR. SVM is designed for small- 
size dataset applications. ANN fits better for medium-sized datasets. The 
dataset we collected in this study was smaller; thus, SVM revealed better 
performance [90]. LR fits better for dichotomous data [91,92] since the 
datasets in this study consisted of multiple-dimension information 
including EMG channel, EMG amplitude, and time point variables, 
hence the LR could yield a relatively lower accuracy in motion pattern 
recognition. 
In real-time exoskeleton motion control testing, the system recog -
nized resting and abduction with higher accuracy than drinking and 
pushing forward motions. One reason might be that these two kinds of 
motions are very similar, especially during the initial phase of motion. 
This could cause the machine-learning-based system confused in motion 
pattern recognition during the initial phase of drinking and pushing 
forward actions. 
Various rehabilitation robotic devices have been developed for 
upper-limb training in stroke patients. Among them, MIT-Manus (1999) 
[93] was one of the first systems to be developed and can provide stroke 
survivors with plane movements. Furthermore, MIME (2005) [94], 
GENTLE/s (2008) [95], T-WREX (2011) [96], and NEREBOT (2014) 
[97] were proposed to permit three-dimensional exercise training for 
patients with impaired arms [98]. Most of these upper-limb rehabilita -
tion robots were developed targeting robot-assisted therapy for the 
upper limb after a stroke. Our upper limb exoskeleton system was also 
developed aiming for medical rehabilitation; however, it can also be 
applied to industrial robots. 
In this study, twelve upper-limb muscles were recorded by Delsys 
wireless sensors. The EMG signals were processed and used for training 
machine-learning models which can be used for motion recognition. The 
users didn ’t wear the upper-limb exoskeleton for safety concerns since Table 3 
Classification accuracy of offline analysis and real-time control.   
Offline Real-time 
SVM ANN LR SVM ANN LR 
Abduction 96% 96% 90% 97% 95% 88% 
Drinking 98% 98% 98% 84% 74% 71% 
Forward 90% 90% 86% 81% 78% 82% 
Rest 98% 98% 99% 99% 98% 98% 
Average 96 ±
3.8% 96 ±
3.8% 93 ±
6.3% 90 ±
9.1% 86 ±
12.0% 85 ±
11.3%  B. Chen et al.                                                                                                                                                                                                                                    Array 17 (2023) 100277
9this upper-limb exoskeleton has not been validated through the FDA 
investigation device evaluation process. 
Limitations of this study include that this real-time system can only 
recognize four different motion patterns, which is far from enough for 
the activity of daily life (ADL) training. The motion control is trajectory 
instead of adaptive motion control. Twelve EMG modules were used to 
recognize 4 kinds of discrete actions of ADL. Too many sensors may 
increase the complexity of actual use and commercial product devel -
opment. The minimal number of sensors for optimal performance was 
not studied. This EMG-controlled shoulder/upper limb exoskeleton has 
not been tested among clinical patients or industrial workers, it is un-
known how the system will work among patients with remnant weak 
EMG signal. 
Future work will focus on the development of a better computing 
system for the wearable sensor-controlled upper-limb exoskeleton sys-
tem to better discriminate similar motions. The investigation will be 
performed to determine the minimal number of EMG sensors for optimal 
performance. The effects of ML-based EMG signals on the adaptive 
control of an upper limb exoskeleton will be studied. 
Since we have built a platform for EMG signal processing using ML 
techniques, new machine learning algorithms, and new features can be 
tested using this platform. More research will be performed to discover a 
better solution for the shorter responsiveness time and higher accuracy. 
6.Conclusion 
This study demonstrated the feasibility of ML computing in multiple 
channels of EMG signal processing for a real-time shoulder motion 
pattern recognition and wearable exoskeleton motion control. SVM 
yielded better accuracy than the LR and ANN in performance. The off-
line pattern recognition had a higher accuracy than the accuracy of real- 
time exoskeleton motion control. 
Credit author statement 
Biao Chen: Conceptualization, methodology, investigation, software, 
data curation, formal analysis, original draft preparation. Yang Zhou: 
Conceptualization, methodology, investigation, software, data curation, 
formal analysis, original draft preparation. Chaoyang Chen: Conceptu -
alization, investigation, methodology, validation, resources, wri-
ting—review and editing, supervision, project administration, funding 
acquisition. Zain Sayeed: Conceptualization, methodology, investiga -
tion, writing —review and editing. Jie Hu: Conceptualization, method -
ology, resources, writing —review and editing, supervision. Jin Qi: 
Conceptualization, methodology, resources, writing —review and edit-
ing. Todd Frush: Conceptualization, methodology, resources, wri-
ting—review and editing. Henry Goitz: Conceptualization, 
methodology, resources, writing —review and editing. John Hovorka: 
Conceptualization, methodology, resources, writing —review and edit-
ing. Mark Cheng: Conceptualization, investigation, methodology, soft-
ware, validation, writing —review and editing, supervision. Carlos 
Palacio: Conceptualization, methodology, resources, writing —review 
and editing. 
Declaration of competing interest 
The authors declare that they have no known competing financial 
interests or personal relationships that could have appeared to influence 
the work reported in this paper. 
Data availability 
Data will be made available on request. Acknowledgements 
This study was performed in the Department of Orthopaedic Surgery 
and Sports Medicine, Detroit Medical Center, and the Robotic Rehabil -
itation Laboratory, Department of Biomedical Engineering, Wayne State 
University, Detroit, Michigan, USA. This work is supported by the 
Wayne State University UPTF Professional Development Grant (Grant# 
20201020) and Rehabilitation Institute of Michigan Foundation 
(Grant# 22-2-003) and by the National Natural Science Foundation of 
China (Grant# 51975360, 52035007). The authors would like to thank 
Edward Rozek, Rachel Toccalino, and Linda Gross assistance in this 
research. 
References 
[1]Manna SK, Dubey VN. Comparative study of actuation systems for portable upper 
limb exoskeletons. Med Eng Phys 2018;60:1 –13. 
[2]Esposito D, Centracchio J, Andreozzi E, Gargiulo GD, Naik GR, Bifulco P. Biosignal- 
based human-machine interfaces for assistance and rehabilitation: a survey. 
Sensors 2021;21 . 
[3]Aguiar Noury G, Walmsley A, Jones RB, Gaudl SE. The barriers of the assistive 
robotics market-what inhibits health innovation? Sensors 2021:21 . 
[4]Xu Y, Liu X, Cao X, Huang C, Liu E, Qian S, Liu X, Wu Y, Dong F, Qiu CW, Qiu J, 
Hua K, Su W, Wu J, Xu H, Han Y, Fu C, Yin Z, Liu M, Roepman R, Dietmann S, 
Virta M, Kengara F, Zhang Z, Zhang L, Zhao T, Dai J, Yang J, Lan L, Luo M, Liu Z, 
An T, Zhang B, He X, Cong S, Liu X, Zhang W, Lewis JP, Tiedje JM, Wang Q, An Z, 
Wang F, Zhang L, Huang T, Lu C, Cai Z, Wang F, Zhang J. Artificial intelligence: a 
powerful paradigm for scientific research. Innovation 2021;2:100179 . 
[5]Tiboni M, Borboni A, V˘erit˘e F, Bregoli C, Amici C. Sensors and actuation 
technologies in exoskeletons: a review. Sensors 2022;22 . 
[6]Moeller T, Krell-Roesch J, Woll A, Stein T. Effects of upper-limb exoskeletons 
designed for use in the working environment-A literature review. Front Robot AI 
2022;9:858893 . 
[7]Weston EB, Alizadeh M, Hani H, Knapik GG, Souchereau RA, Marras WS. 
A physiological and biomechanical investigation of three passive upper-extremity 
exoskeletons during simulated overhead work. Ergonomics 2022;65:105 –17. 
[8]De Bock S, Rossini M, Lefeber D, Rodriguez-Guerrero C, Geeroms J, Meeusen R, De 
Pauw K. An occupational shoulder exoskeleton reduces muscle activity and fatigue 
during overhead work. IEEE Trans Biomed Eng 2022;69:3008 –20. 
[9]Maciejasz P, Eschweiler J, Gerlach-Hahn K, Jansen-Troy A, Leonhardt S. A survey 
on robotic devices for upper limb rehabilitation. J NeuroEng Rehabil 2014;11:3 . 
[10] V˘elez-Guerrero MA, Callejas-Cuervo M, Mazzoleni S. Artificial intelligence-based 
wearable robotic exoskeletons for upper limb rehabilitation: a review,. Sensors 
2021;21 . 
[11] Young J, Forster A. Review of stroke rehabilitation. BMJ 2007;334:86 –90. 
[12] Azma K, RezaSoltani Z, Rezaeimoghaddam F, Dadarkhah A, Mohsenolhosseini S. 
Efficacy of tele-rehabilitation compared with office-based physical therapy in 
patients with knee osteoarthritis: a randomized clinical trial. J Telemed Telecare 
2018;24:560 –5. 
[13] Longley V, Peters S, Swarbrick C, Bowen A. What factors affect clinical decision- 
making about access to stroke rehabilitation? A systematic review. Clin Rehabil 
2019;33:304 –16. 
[14] Vukobratovic MK. When were active exoskeletons actually born? Int J Humanoid 
Rob 2011;4:459 –86. 
[15] Pons JL. Rehabilitation exoskeletal robotics. IEEE Eng Med Biol Mag 2010;29: 
57–63. 
[16] Dellon B, Matsuoka Y. Prosthetics, exoskeletons, and rehabilitation [grand 
challenges of robotics]. IEEE Robot Autom Mag 2007;14:30 –4. 
[17] Mekki M, Delgado AD, Fry A, Putrino D, Huang V. Robotic rehabilitation and spinal 
cord injury: a narrative review. Neurotherapeutics 2018;15:604 –17. 
[18] Gorgey AS. Robotic exoskeletons: the current pros and cons. World J Orthoped 
2018;9:112 –9. 
[19] Cesqui B, Tropea P, Micera S, Krebs HI. EMG-based pattern recognition approach in 
post stroke robot-aided rehabilitation: a feasibility study. J NeuroEng Rehabil 
2013;10:75 . 
[20] Hudgins B, Parker P, Scott RN. A new strategy for multifunction myoelectric 
control. IEEE (Inst Electr Electron Eng) Trans Biomed Eng 1993;40:82 –94. 
[21] Oskoei MA, Hu H. Myoelectric control systems —a survey. Biomed Signal Process 
Control 2007;2:275 –94. 
[22] Yin G, Zhang X, Chen D, Li H, Chen J, Chen C, Lemos S. Processing surface EMG 
signals for exoskeleton motion control. Front Neurorob 2020;14:40 . 
[23] Kawase T, Sakurada T, Koike Y, Kansaku K. A hybrid BMI-based exoskeleton for 
paresis: EMG control for assisting arm movements. J Neural Eng 2017;14:016015 . 
[24] Gordleeva SY, Lobov SA, Grigorev NA, Savosenkov AO, Shamshin MO, 
Lukoyanov MV, Khoruzhko MA, Kazantsev VB. Real-time EEG–EMG 
human –machine interface-based control system for a lower-limb exoskeleton. IEEE 
Access 2020;8:84070 –81. 
[25] McCool P, Fraser GD, Chan AD, Petropoulakis L, Soraghan JJ. Identification of 
contaminant type in surface electromyography (EMG) signals. IEEE Trans Neural 
Syst Rehabil Eng 2014;22:774 –83. 
[26] Roland T, Amsuess S, Russold MF, Baumgartner W. Ultra-low-power digital 
filtering for insulated EMG sensing. Sensors 2019;19:959 . B. Chen et al.                                                                                                                                                                                                                                    Array 17 (2023) 100277
10[27] Chen B, Chen C, Hu J, Nguyen T, Qi J, Yang B, Chen D, Alshahrani Y, Zhou Y, 
Tsai A, Frush T, Goitz H. A real-time EMG-based fixed-bandwidth frequency- 
domain embedded system for robotic hand. Front Neurorob 2022;16:880073 . 
[28] Zhang X, Chen C, Ni G, Hai Y, Chen B, Zhou Y, Zhang B, Chen G, Cheng MMC. 
Carbon multi-electrode arrays as peripheral nerve interface for neural recording 
and nerve stimulation. Med Dev Sensors 2019;2:e10026 . 
[29] Fu Y, Zhao J, Dong Y, Wang X. Dry electrodes for human bioelectrical signal 
monitoring. Sensors 2020;20:3651 . 
[30] Xu Q, Quan Y, Yang L, He J. An adaptive algorithm for the determination of the 
onset and offset of muscle contraction by EMG signal processing. IEEE Trans Neural 
Syst Rehabil Eng 2012;21:65 –73. 
[31] Chen B, Zhang B, Chen C, Hu J, Qi J, He T, Tian P, Zhang X, Ni G, Cheng MM-C. 
Penetrating glassy carbon neural electrode arrays for brain-machine interfaces. 
Biomed Microdevices 2020;22:1 –10. 
[32] P˘erez-Reynoso F, Farrera-Vazquez N, Capetillo C, M˘endez-Lozano N, Gonz ˘alez- 
Guti˘errez C, L˘opez-Neri E. Pattern recognition of EMG signals by machine learning 
for the control of a manipulator robot. Sensors 2022;22 . 
[33] Zha X, Wehbe L, Sclabassi RJ, Mace Z, Liang YV, Yu A, Leonardo J, Cheng BC, 
Hillman TA, Chen DA, Riviere CN. A deep learning model for automated 
classification of intraoperative continuous EMG. IEEE Trans Med Robot Bionics 
2021;3:44 –52. 
[34] Jiang Y, Chen C, Zhang X, Chen C, Zhou Y, Ni G, Muh S, Lemos S. Shoulder muscle 
activation pattern recognition based on sEMG and machine learning algorithms. 
Comput Methods Progr Biomed 2020;197:105721 . 
[35] Zhou Y, Chen C, Cheng M, Alshahrani Y, Franovic S, Lau E, Xu G, Ni G, 
Cavanaugh JM, Muh S. Comparison of machine learning methods in sEMG signal 
processing for shoulder motion recognition. Biomed Signal Process Control 2021; 
68:102577 . 
[36] Meeker C, Park S, Bishop L, Stein J, Ciocarlie M. EMG pattern classification to 
control a hand orthosis for functional grasp assistance after stroke. In: 2017 
international conference on rehabilitation robotics. IEEE; 2017. p. 1203 –10. 
ICORR) . 
[37] Liu J, Zhang D, Sheng X, Zhu X. Quantification and solutions of arm movements 
effect on sEMG pattern recognition. Biomed Signal Process Control 2014;13: 
189–97. 
[38] Tsai A-C, Hsieh T-H, Luh J-J, Lin T-T. A comparison of upper-limb motion pattern 
recognition using EMG signals during dynamic and isometric muscle contractions. 
Biomed Signal Process Control 2014;11:17 –26. 
[39] Nazmi N, Abdul Rahman MA, Yamamoto S, Ahmad SA, Zamzuri H, Mazlan SA. 
A review of classification techniques of EMG signals during isotonic and isometric 
contractions. Sensors 2016;16 . 
[40] Jiang Y, Chen C, Zhang X, Chen C, Zhou Y, Ni G, Muh S, Lemos S. Shoulder muscle 
activation pattern recognition based on sEMG and machine learning algorithms. 
Comput Methods Progr Biomed 2020;197:105721 . 
[41] Jarque-Bou NJ, Sancho-Bru JL, Vergara M. A systematic review of EMG 
applications for the characterization of forearm and hand muscle activity during 
activities of daily living: results, challenges, and open issues. Sensors 2021:21 . 
[42] Johnson SS, Mansfield E. Prosthetic training: upper limb. Phys Med Rehabil Clin 
2014;25:133 –51. 
[43] Trigili E, Crea S, Mois ˇe M, Baldoni A, Cempini M, Ercolini G, Marconi D, 
Posteraro F, Carrozza MC, Vitiello N. Design and experimental characterization of a 
shoulder-elbow exoskeleton with compliant joints for post-stroke rehabilitation. 
IEEE ASME Trans Mechatron 2019;24:1485 –96. 
[44] Amanpreet K. Machine learning-based novel approach to classify the shoulder 
motion of upper limb amputees. Biocybern Biomed Eng 2019;39:857 –67. 
[45] Rivela D, Scannella A, Pavan EE, Frigo CA, Belluco P, Gini G. Analysis and 
comparison of features and algorithms to classify shoulder movements from sEMG 
signals. IEEE Sensor J 2018;18:3714 –21. 
[46] Rivela D, Scannella A, Pavan EE, Frigo CA, Belluco P, Gini G. Processing of surface 
EMG through pattern recognition techniques aimed at classifying shoulder joint 
movements. In: 37th annual international conference of the IEEE engineering in 
medicine and biology society (EMBC). IEEE; 2015. p. 2107 –10. 2015 . 
[47] Phinyomark A, Quaine F, Charbonnier S, Serviere C, Tarpin-Bernard F, Laurillau Y. 
EMG feature evaluation for improving myoelectric pattern recognition robustness. 
Expert Syst Appl 2013;40:4832 –40. 
[48] Atzori M, Gijsberts A, Castellini C, Caputo B, Hager AG, Elsig S, Giatsidis G, 
Bassetto F, Muller H. Electromyography data for non-invasive naturally-controlled 
robotic hand prostheses. Sci Data 2014;1:140053 . 
[49] Khushaba RN, Kodagoda S. Electromyogram (EMG) feature reduction using mutual 
components analysis for multifunction prosthetic fingers control. In: 2012 12th 
international conference on control automation robotics & vision (ICARCV). IEEE; 
2012. p. 1534 –9. 
[50] Atzori M, Muller H. Control capabilities of myoelectric robotic prostheses by hand 
amputees: a scientific research and market overview. Front Syst Neurosci 2015;9: 
162. 
[51] Atzori M, Cognolato M, Muller H. Deep learning with convolutional neural 
networks applied to electromyography data: a resource for the classification of 
movements for prosthetic hands. Front Neurorob 2016;10 . 
[52] Meng L, Pang J, Wang Z, Xu R, Ming D. The role of surface electromyography in 
data fusion with inertial sensors to enhance locomotion recognition and prediction. 
Sensors 2021:21 . 
[53] Ahsan MR, Ibrahimy MI, , O.O.J.E.J.o.S.R., Khalifa. EMG signal classification for 
human computer interaction. Review 2009;33:480 –501. 
[54] Kuiken TA, Miller LA, Turner K, Hargrove LJ. A comparison of pattern recognition 
control and direct control of a multiple degree-of-freedom transradial prosthesis. 
Ieee J Transl Eng He 2016;4 . [55] Jiang N, Dosen S, Muller KR, Farina D. Myoelectric control of artificial limbs-is 
there a need to change focus? Ieee Signal Proc Mag 2012;29:147 –50. 
[56] Liu S, Deng W. Very deep convolutional neural network based image classification 
using small training sample size. In: 2015 3rd IAPR Asian conference on pattern 
recognition (ACPR). IEEE; 2015. p. 730–4. 
[57] Zhou B, Lapedriza A, Khosla A, Oliva A, Torralba A. Places: a 10 million image 
database for scene recognition. IEEE Trans Pattern Anal Mach Intell 2018;40: 
1452 –64. 
[58] Tu Z, Xie W, Qin Q, Poppe R, Veltkamp RC, Li B, Yuan J. Multi-stream CNN: 
learning representations based on human-related regions for action recognition. 
Pattern Recogn 2018;79:32 –43. 
[59] Hinton GE, Salakhutdinov RR. Reducing the dimensionality of data with neural 
networks. Science 2006;313:504 –7. 
[60] LeCun Y, Bengio Y, Hinton G. Deep learning, Nature 2015;521:436 –44. 
[61] Szegedy C, Liu W, Jia YQ, Sermanet P, Reed S, Anguelov D, Erhan D, Vanhoucke V, 
Rabinovich A. Going deeper with convolutions. Proc Cvpr Ieee 2015:1 –9. 
[62] Hochreiter S, Schmidhuber J. Long short-term memory. Neural Comput 1997;9: 
1735 –80. 
[63] Zhai XL, Jelfs B, Chan RHM, Tin C. Self-recalibrating surface EMG pattern 
recognition for neuroprosthesis control based on convolutional neural network. 
Front Neurosci-Switz 2017;11 . 
[64] Allard UC, Nougarou F, Fall CL, Giguere P, Gosselin C, Laviolette F, Gosselin B. 
A convolutional neural network for robotic arm guidance using sEMG based 
frequency-features. In: 2016 Ieee/Rsj International Conference on Intelligent 
Robots and Systems (Iros 2016); 2016. p. 2464 –70. 
[65] Du Y, Jin WG, Wei WT, Hu Y, Geng WD. Surface EMG-based inter-session gesture 
recognition enhanced by deep domain adaptation. Sensors-Basel 2017;17 . 
[66] Guo S, Pang M, Gao B, Hirata H, Ishihara H. Comparison of sEMG-based feature 
extraction and motion classification methods for upper-limb movement. Sensors 
2015;15:9022 –38. 
[67] Peng F, Chen C, Lv D, Zhang N, Wang X, Zhang X, Wang Z. Gesture recognition by 
ensemble extreme learning machine based on surface electromyography signals. 
Front Hum Neurosci 2022;16:911204 . 
[68] Muceli S, Boye AT, d’Avella A, Farina D. Identifying representative synergy 
matrices for describing muscular activation patterns during multidirectional 
reaching in the horizontal plane. J Neurophysiol 2010;103:1532 –42. 
[69] Antuvan CW, Bisio F, Cambria E, Masia L. Muscle synergies for reliable 
classification of arm motions using myoelectric interface. In: 37th annual 
international conference of the IEEE engineering in medicine and biology society. 
EMBC); 2015. p. 1136 –9. 2015 . 
[70] Antuvan CW, Bisio F, Marini F, Yen SC, Cambria E, Masia L. Role of muscle 
synergies in real-time classification of upper limb motions using extreme learning 
machines. J NeuroEng Rehabil 2016;13:76 . 
[71] Anam K, Al-Jumaily A. Adaptive myoelectric pattern recognition for arm 
movement in different positions using advanced online sequential extreme learning 
machine. Annu Int Conf IEEE Eng Med Biol Soc 2016:900 –3. 2016 . 
[72] Alt Murphy M, Will˘en C, Sunnerhagen KS. Movement kinematics during a drinking 
task are associated with the activity capacity level after stroke. Neurorehabilitation 
Neural Repair 2012;26:1106 –15. 
[73] Gottlieb D, Kipnis M, Sister E, Vardi Y, Brill S. Validation of the 50 ml3 drinking 
test for evaluation of post-stroke dysphagia. Disabil Rehabil 1996;18:529 –32. 
[74] Cools AM, Struyf F, De Mey K, Maenhout A, Castelein B, Cagnie B. Rehabilitation of 
scapular dyskinesis: from the office worker to the elite overhead athlete. Br J Sports 
Med 2014;48:692 –7. 
[75] Zhou Y, Chen C, Cheng M, Alshahrani Y, Franovic S, Lau E, Xu G, Ni G, 
Cavanaugh JM, Muh S, Lemos S. Comparison of machine learning methods in 
sEMG signal processing for shoulder motion recognition. Biomed Signal Process 
Control 2021;68 . 
[76] Elliott C, Vijayakumar V, Zink W, Hansen R. National Instruments LabVIEW: a 
programming environment for laboratory automation and measurement, JALA. 
J Assoc Lab Autom 2007;12:17 –24. 
[77] Oskoei MA, Hu H. Support vector machine-based classification scheme for 
myoelectric control applied to upper limb. IEEE Trans Biomed Eng 2008;55: 
1956 –65. 
[78] Fricke C, Alizadeh J, Zakhary N, Woost TB, Bogdan M, Classen J. Evaluation of 
three machine learning algorithms for the automatic classification of EMG patterns 
in gait disorders. Front Neurol 2021;12:666458 . 
[79] Gandolla M, Ferrante S, Ferrigno G, Baldassini D, Molteni F, Guanziroli E, Cotti 
Cottini M, Seneci C, Pedrocchi A. Artificial neural network EMG classifier for 
functional hand grasp movements prediction. J Int Med Res 2017;45:1831 –47. 
[80] Schabron B, Alashqar Z, Fuhrman N, Jibbe K, Desai J. Artificial neural network to 
detect human hand gestures for a robotic arm control. Annu Int Conf IEEE Eng Med 
Biol Soc 2019:1662 –5. 2019 . 
[81] Zhang Z, Yang K, Qian J, Zhang L. Real-time surface EMG pattern recognition for 
hand gestures based on an artificial neural network. Sensors 2019;19 . 
[82] Lotze M, Braun C, Birbaumer N, Anders S, Cohen LG. Motor learning elicited by 
voluntary drive. Brain 2003;126:866 –72. 
[83] Gui K, Liu H, Zhang D. A practical and adaptive method to achieve EMG-based 
torque estimation for a robotic exoskeleton. IEEE ASME Trans Mechatron 2019;24: 
483–94. 
[84] Yao S, Zhuang Y, Li Z, Song R. Adaptive admittance control for an ankle 
exoskeleton using an EMG-driven musculoskeletal model. Front Neurorob 2018;12: 
16. 
[85] Li M, Chen J, He G, Cui L, Chen C, Secco EL, Yao W, Xie J, Xu G, Wurdemann H. 
Attention enhancement for exoskeleton-assisted hand rehabilitation using fingertip 
haptic stimulation. Front Robot AI 2021;8:144 . B. Chen et al.                                                                                                                                                                                                                                    Array 17 (2023) 100277
11[86] Yin G, Zhang X, Chen D, Li H, Chen J, Chen C, Lemos S. Processing surface EMG 
signals for exoskeleton motion control. Front Neurorob 2020;14. 
[87] Türkler L, Akkan T, Akkan L. Usage of evolutionary algorithms in swarm robotics 
and design problems. Sensors 2022;22. 
[88] Yamaba H, Kurogi T, Aburada K, Kubota S-I, Katayama T, Park M, Okazaki N. On 
applying support vector machines to a user authentication method using surface 
electromyogram signals. Artif Life Robot 2018;23:87–93. 
[89] Cai S, Chen Y, Huang S, Wu Y, Zheng H, Li X, Xie L. SVM-based classification of 
sEMG signals for upper-limb self-rehabilitation training. Front Neurorob 2019;13: 
31. 
[90] Chen B, Chen C, Hu J, Sayeed Z, Qi J, Darwiche HF, Little BE, Lou S, Darwish M, 
Foote C, Palacio-Lascano C. Computer vision and machine learning-based gait 
pattern recognition for flat fall prediction. Sensors 2022;22. 
[91] Wirtz MA. [Basic statistical measures for dichotomous data formats: risk, odds, 
logits, relative risk, odds ratio]. Rehabilitation 2017;56:264–71. 
[92] Rijnhart JJM, Twisk JWR, Eekhout I, Heymans MW. Comparison of logistic- 
regression based methods for simple mediation analysis with a dichotomous 
outcome variable. BMC Med Res Methodol 2019;19:19. [93] Krebs HI, Hogan N, Volpe BT, Aisen ML, Edelstein L, Diels C. Overview of clinical 
trials with MIT-MANUS: a robot-aided neuro-rehabilitation facility. Technol Health 
Care 1999;7:419–23. 
[94] Lum PS, Burgar CG, Van der Loos M, Shor PC, Majmundar M, Yap R. The MIME 
robotic system for upper-limb neuro-rehabilitation: results from a clinical trial in 
subacute stroke. In: 9th international conference on rehabilitation robotics. ICORR 
2005.; 2005. p. 511–4. 2005. 
[95] Coote S, Murphy B, Harwin W, Stokes E. The effect of the GENTLE/s robot- 
mediated therapy system on arm function after stroke. Clin Rehabil 2008;22: 
395–405. 
[96] Gijbels D, Lamers I, Kerkhofs L, Alders G, Knippenberg E, Feys P. The Armeo Spring 
as training tool to improve upper limb functionality in multiple sclerosis: a pilot 
study. J NeuroEng Rehabil 2011;8:5. 
[97] Masiero S, Armani M, Ferlini G, Rosati G, Rossi A. Randomized trial of a robotic 
assistive device for the upper extremity during early inpatient stroke rehabilitation. 
Neurorehabilitation Neural Repair 2014;28:377–86. 
[98] Cai S, Chen Y, Huang S, Wu Y, Zheng H, Li X, Xie L. SVM-based classification of 
sEMG signals for upper-limb self-rehabilitation training. Front Neurorob 2019;13: 
31. B. Chen et al.                                                                                                                                                                                                                                    