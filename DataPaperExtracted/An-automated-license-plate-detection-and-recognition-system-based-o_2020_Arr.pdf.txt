An automated license plate detection and recognition system based onwavelet decomposition and CNN
Ibtissam Slimani*, Abdelmoghit Zaarane, Wahban Al Okaishi, Issam Atouf, Abdellatif Hamdoun
LTI Lab, Department of Physics, Faculty of Sciences Ben M ’Sik, Hassan II University Of Casablanca, Morocco
ARTICLE INFO
Keywords:Image processingLicense plate detectionCharacter recognitionWavlet transformVertical edgesLocal entropyConnected componentCNNABSTRACT
The License Plate detection and recognition (LPDR) is a challenging task that plays a signi ﬁcant role in intelligent transportation systems (ITS). Where it could be used as a core in various applications, such as security, traf ﬁc control, and electronic payment systems (e.g. freeway toll payment and parking fee payment). A variety of al-gorithms are developed for this work and each one has advantages and disadvantages for extracting plates inimages under different circumstances. However, the complexity of some methods requires a high calculation costand this could be time-consuming. In the current paper, a simple and ef ﬁcient method is proposed to tackle the issue of license plate detection and character recognition. The license plate is detected ﬁrst based on the two- dimensional wavelet transform to extract the vertical edges of the input image. The high density of verticaledges is computedﬁrst to detect the potential areas of the license plate. Then these potential areas are veri ﬁed by using a plate/non-plate CNN classiﬁer. After the license plate is detected, the characters are segmented by using a simple method that is based on the empty distance between the characters. Finally, these character candidates areclassiﬁed by training another CNN classiﬁer. The experiments were done on vehicles that carry Moroccan license plates and showed high accuracy, where the results obtained go up to 99.43% in term of localization and 98.9% interm of recognition. Besides, the efﬁciency and the high accuracy of the proposed method were proved by per- forming a comparison with other works from the literature on different datasets. All processes of the proposedmethod were implemented on a Hardware Processor System (HPS) located in a VEEK-MT2S provided byTERASIC.
I. IntroductionYear after year, trafﬁc problems are increasing rapidly due to rapidurban development and increasing car ownership. Traf ﬁc congestion, trafﬁc violations, stealing cars, and fugitive criminals impose big chal-lenges on trafﬁc management systems. Several systems are developed tosolve these problems such as self-driving systems [ 1], Trafﬁc surveillance systems [2,3], Tracking vehicle systems and Vehicle speed detectionsystems [4,5]. License plate detection and character recognition (LPDR)is one of the most important topics in intelligent infrastructure systems,like electronic payment systems (for tolls, parking, and public trans-portation). The LPDR system is an image processing technology used toidentify vehicles using their license plate to help the traf ﬁc managementdepartment for monitoring purposes. Usually, a license plate detectionand character recognition (LPDR) system has mainly three phases. Theﬁrst phase is image pre-processing, once the image is captured furtherprocessing of the image is carried out like converting the image from acolor space to another, resizing the image resolution, and removingnoises. The second phase is license plate localization, the region of in-terest is detected based on some license plate characteristics and imagefeatures. Theﬁnal phase is the optical character recognition, this phase isconsidered the most crucial step because it helps to read the plate numberand identify the vehicle.To detect license plates, various methods have been proposed basedon image processing. The most common proposed methods include someimage features such as color information [ 6–8], edges information and,
Abbreviations:LPDR, License Plate Detection and Recognition; LP, License Plate; ITS, Intelligent Transportation Systems; 2D-WD, two dimensional waveletdecomposition; CTC, connectionist temporal classi ﬁcation; CCA, connected component analysis; CNN, Convolutional neural network; HPS, Hardware Processor System; SVM, support vector machine; AdaBoost, Adaptive boosting; FPGA, Field Programmable Gate Arrays; AC, access control; LE, traf ﬁc law enforcement; RP, road patrol.* Corresponding author.E-mail addresses:ibtissamslimani7@gmail.com(I. Slimani),z.abdelmoghit@gmail.com(A. Zaarane).
Contents lists available atScienceDirect
Array
journal homepage:www.elsevier.com/journals/array/2590-0056/open-access-journal
https://doi.org/10.1016/j.array.2020.100040Received 1 May 2020; Received in revised form 26 August 2020; Accepted 27 August 2020Available online 3 September 20202590-0056/©2020 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).Array 8 (2020) 100040textures information [9,10]. Jia et al. [11], relied on three features to extract the candidate of license plate (LP), rectangularity, aspect ratio,and edge density. Theyﬁrst used the mean shift toﬁlter and segment color images into candidate regions, then they utilized Mahalanobisclassiﬁer to classify license plate candidates and non-license plate can-didates based on the three features mentioned previously. Davis et al.[12], used vertical edges features to localize the LP. They ﬁrst convert the color image into a gray image, then they use an adaptive thresholdingtechnique to binarize the image, after that they used an algorithm calledvertical edges detection algorithm (VEDA) to extract the vertical edgesandﬁnally, they use the highlighting desired details (HDD) algorithm forhighlighting the license plate area. Ashtari et al. [ 8] proposed a modiﬁed template matching technique to localize the LP based on color informa-tion. They detect the LP based onﬁnding a blue rectangle that appears onthe side of an Iranian and some European license plates and then theycropped the LP in the same direction as that of the width of the blue pixel.Other methods are relied on combining multiple methods to localize theLP to increase the precision rate. Rashedi et al. [ 13] relied on four methods to locate the LP, including an edge-based method, a methodbased on cascade classiﬁers, and local binary pattern (LBP) features, acolor-based method, and a contrast-based method.To recognize the characters of the LP, two processes should be done.Theﬁrst process includes character segmentation and the second oneincludes character classiﬁcation, where the segmented characters shouldbe classiﬁed into 36 classes (26 capital letters and 10 digits). Severalclassiﬁers are used in theﬁeld of license plate recognition such as supportvector machine (SVM), Adaptive boosting (AdaBoost) and Convolutionalneural network (CNN). In Ref. [14], the characters are segmentedﬁrst by using different treatments including 2D convolution, morphologicaloperation, and some equations for region segmentation. Then a featureselection is applied by using entropy to select the most relevant features.Finally, these features are classiﬁed through SVM for character recogni-tion. In Ref. [15] theyﬁrst calibrate the LP tilt, and then they use theprojection method to segment the characters. Finally, they based on theback-propagation neural network to recognize each character. InRef. [16], they proposed two different methods, the ﬁrst one performs the character segmentationﬁrst and then character recognition. The otherone is character string recognition, all characters are recognized in thelicense plate one-off. In theﬁrst proposition, the cropped candidate li-cense plate is binarizedﬁrst to increases the image contrast. Then, thecharacters are segmented by applying the connected component algo-rithm and classiﬁ
ed by using CNN classiﬁer. In the second proposition, the features are extractedﬁrst by using a pre-trained 9-layer CNN model,then a sequence labeling is applied by using bidirectional-RNNs, andﬁnally, sequence decoding is performed by applying connectionist tem-poral classiﬁcation (CTC).Although there is a lot of research on the license plate detection andrecognition, most of the proposed methods have some restrictions andperform well only under certain predeﬁned conditions. Some common restrictions include illumination problems, complex scenes and thepresence of blur or distortions on the license plate. Moreover, thetoughness of this task resides in the huge variety of characters shapes,like different fonts, forms sizes and colors of each character through thedifferent license plates in each country.The goal of this paper is to establish a low-cost, highly ef ﬁcient automatic vehicle license plate detection and recognition system. Theidea presented in this paper is divided into two stages: license platelocalization and character recognition. In the ﬁrst stage, the license plate regions are extracted from the input image. The potential license platesare extracted based on vertical edges where the high density of theseedges is inside the LP. To extract the vertical edges from the input image,we have used the two-dimensional wavelet decomposition (2D-WD). The2D-WD divides the image into four sub-bands where the vertical edgesare in one of these sub-bands. After getting the vertical edges, we extractthe license plate candidates by looking for the high density of verticaledges. Finally, to verify the correctness of these candidates, a plate/non-plate CNN classiﬁer is trained to remove the false positive. In the secondstage, the separating columns between the characters are extracted tosegment the license plate characters and to generate the segmentedcandidates. Finally, these character candidates are classi ﬁed by training another CNN classiﬁer.This paper is organized as follows: In Section II, the license plate detection process is detailed. Section IIIpresents the character recogni- tion process in detail. Experimental evaluations are presented in SectionIV. Finally, SectionVconcludes the paper.II. Proposed method1. License plate detectionLicense plate detection is a very important step in the proposedmethod, where its efﬁciency plays a big role in the detection andrecognition of license plate characters. The principle of this step is to lookfor the potential license plate locations in the input image (zones of in-terest) then verify these locations as a license plate or not. In our prop-osition, we have based on vertical edges to detect the potential licenseplate candidates. First, the 2D-WD is used to extract the vertical edges.Then, the high density of the vertical edges is calculated to detect thepotential license plate candidates. These candidates are then classi ﬁed by training a plate/non-plate CNN classiﬁer to remove the false positive.1.1. License plate candidatesFor license plate detection, the license plate candidates need to begeneratedﬁrst. To extract the regions where it could be the license plate,we have based on extracting the vertical edges of the input image(Fig. 2(a)). The horizontal and vertical edges are one of the best featuresthat can be extracted in the image processing domain. However, in thispaper, we focus just on the vertical edges which the high density of thevertical edges in a vehicle is inside the license plate because of the shapeof the license plate characters. To extract these features, the two-dimensional wavelet transform [17] is applied after converting the input image to a gray level.1.1.1. Two-dimensional wavelet decompositionThe 2D-WD [18] divides an image into four sub-bands as shown inFig. 1, each sub-band contains different information of the originalimage. Three sub-bands for detail coef
ﬁcients“vertical detail, horizontal
Fig. 1.Sub-bands of 2D-WD.I. Slimani et al. Array 8 (2020) 100040
2detail and diagonal detail”and the fourth sub-band for the approxima-tion coefﬁcients. Detail coefﬁcients represent the high frequency of theinput image, approximation coefﬁcients represent the low frequency.Therefore, in this paper, we take just the vertical detail ( Fig. 2(b)) which represents the vertical edges of the input image.1.1.2. High vertical edge density extractionTo extract the high vertical edge density areas, we have based oncalculating the maximum entropy areas. The entropy is a measure ofdisorder or randomness of a system, it measures the degree of disorder oruncertainty associated with a random variable. Therefore, the area wherethe entropy is maximum returns to the areas where there is a high verticaledge density. Entropy is usually calculated from an image using Shannonentropy, where the probability distribution could be easily estimatedfrom image histogram [19]. The entropy formula is given as follows (1):E¼/C0X
L1pklog 2pk (1)with a color value (index k¼1,…, L) that occurs with a probabilityp
k. Wherep
kcontains the normalized histogram counts. In this paper, wecalculate the local entropy of the grayscale image, where each pixel of theresulted image contains the entropy value of the 9-by-9 neighborhoodaround the corresponding pixel in the input image.After computing the locale entropy, the resulted image ( Fig. 2(c)) is converted to a binary image (Fig. 2(d)) by using a predeﬁned threshold K to deﬁne the areas that have the maximum entropy (2).
(2)where Pi is the new pixel and Xi is the value of each pixel of the imageafter computing the local entropy.Unfortunately, in the binary image, weﬁnd some noisy holes and some broken areas where the region of interest might be divided into tworegions. To solve this problem, a morphological operation is used. Theclosing operation (dilation followed by erosion) is performed to recoverthese holes.To extract the regions of interest, the connected component analysis(CCA) is applied. The connected component analysis is an important taskused in several image processing domains to detect linked regions inbinary images. The principle of this method is based on a crossing win-dow that crosses the entire input image from the left to the right from thetop to the bottom.The algorithm.1illustrates the whole technique usedto generate the CCA. Therefore, based on the length, the height, andcoordinates of each connected component, the bounding box is drawn.Based on the area, the small and the big bounding box are eliminated.The area is the number of white pixels in each connected component andthe length and the height are computed from the minimum and themaximum coordinates of each connected component along the verticaland the horizontal axes.Fig. 2(e) shows the image resulted after applyingthe CCA and drawing bounding box.Algorithm.1
- Let Im denotes the input image having size LxC- For y 1 to C do- For x 1 to L do/C15If Im (x,y)¼1d o/C15Scan pixels around Im (x,y)./C15When all pixels around are black, a new label is assigned to Im (x,y)./C15If one of the pixels around is white, its label is assigned to Im (x,y)./C15If more than one of the pixels around are white, one of their labels is assigned to Im(x,y) and the other labels are taken as notes.- Each pixel’s label and its corresponding labels in the note are mixed and consideredas one label.- Each connected component is represented by a label.
1.2. License plate veriﬁcationTo verify the license plate candidates, The CNN classi ﬁer is trained, to represent the image for classiﬁcation of a license plate and non-licenseplate, with positive samples of gray-scale license plates that are takenfrom diverse countries. Some positive samples are cropped from realimages, and some negative samples are set up by images of some generaltext strings as well as some images of rectangles. Finally, the images thatare classiﬁed as license plate (seeFig. 2(f)) are fed to the next step.
Fig. 2.Following steps for license plate detection (a) the input grayscale image; (b) the vertical detail of 2D-DW; (c) the image after applying the entropy a rea al- gorithm; (d) image binarized; (e) the extracted connected component; (f) the result after CNN classi ﬁer.I. Slimani et al. Array 8 (2020) 100040
3Convolutional neural network (CNN) is a special architecture ofartiﬁcial neural networks and the best performing model to classify im-ages. It is divided into two main parts, Convolutional layers and fullyconnected layers. The convolutional layer is the building block of CNN, itis responsible for features extraction from images by applying convolu-tionﬁltering operations. However, the fully connected layers areresponsible for the prediction part. With one or more fully connectedlayers that are fed by the output of the convolution layers the predictionpart is done. The CNN computes the score of each class using the featuresextracted from the previous layers. However, training convolutionalneural networks are very expensive because they require a signi ﬁcant amount of data and resources in training. Therefore, there are severalopen-source pre-trained models like Inception-v3, ResNet-50, andVGG16 which are the most utilized [ 20].In this paper, we have based on the Inception-v3 model that is amodel formed by Google. This model is formed on about 1.2 millionimages per 1000 categories which represent classes of objects from ourdaily life. This model consists of 42 layers, which are considered assymmetric and asymmetric blocks, including convolutional, averagepooling, max pooling, dropouts, and fully connected layers. We havechosen the inception v3 model because it performs well in terms ofprecision and does not require a lot of calculation in the processing phase,which makes it much easier to use this system on average performancecomputers. In addition, this model is highly recommended by most datascientists.2. License plate recognitionAfter the localization, the license plates are cropped from their orig-inal image and classiﬁed. Then they go through the recognition processfor classifying and recognizing their letters and numbers. Where theprinciple of this step is to look for the characters candidates in thedetected license plate then match them with the characters. In the pro-posed method, the empty lines between the characters are detected tosegment the license plate characters and generate the segmented candi-dates. Then, these segmented candidates are classi ﬁed by training CNN classiﬁer to recognize the license plate characters.2.1. License plate segmentationThe license plate characters are generally separated and each char-acter is far from the other character by the same distance. Based on thisseparation space, the characters have been segmented in this work. Theidea is to scan the detected license plate vertically, column by columnfrom top to the bottom and compute the number of black pixels in eachcolumn. If the number of successive black pixels in the column reachesmore than a predeﬁned value of black pixels, we consider this column asa part of a character then we move directly to the next column to reducethe computational cost. Otherwise, the column is saved as a potentialseparating column and the black pixels of this column are considered asnoise. All potential separating columns segmenting the license plateimage are printed in red color as shown in Fig. 3(b). Successive potential separating columns are considered as a separating distance between thecharacters and the average value is considered as the separating columnas shown inFig. 3(c).Fig. 3shows an example of a segmented licenseplate.2.2. Characters recognitionThe characters, after the segmentation, are cropped from their licenseplate image by using the separating columns. To recognize these char-acters, another 42-class CNN classiﬁer is trained, 10 digits, 26 upper letters plus 6 Arabic letters. In our work, we have used Moroccan licenseplates to test the performance of our system, for this reason, the Arabiccharacters used in Moroccan license plates are treated too ( Fig. 4). The open-source pre-trained CNN model Inception-v3, formed by Google, isused to classify these characters.III. Results and discussionThe proposed system was implemented using Cþþand OpenCV on 1.2 GHz Dual-core ARM Cortex-A9 (HPS) that runs under LXDE desktopwith 1.0 GB memory DDR3. The HPS is located in a VEEKMT2S that iscomposed of DE10 standard FPGA and the MTLC2 module provided byTERASIC.1. DatasetsTwo experiments have been done to test the performance of theproposed detection and recognition system. The ﬁrst experiment was done on Moroccan License Plates using real traf ﬁc video sequences
collected from different situations in different lighting conditions. As
Fig. 3.License plate segmentation; (a) the input image; (b) segmentation col-umns; (c)ﬁnal segmentation.
Fig. 4.Some examples of character templates.
Table 1The experimental conditions.
Scenes Highways, urban roadwaysWeather Sunny, foggy, shadyTime Day and night timeCamera specs 2160p/30fps videoLicense plate sizes and designe Different sizes with single rowVehicle colors Different colorsI. Slimani et al. Array 8 (2020) 100040
4shown inTable 1, we have three video sequences corresponding todifferent situations. Theﬁrst sequence was taken on the highways innormal daylight conditions. The second one was taken on urban road-ways. In contrast, the third one was recorded during the night. Theexperimental conditions of the collected sequences are described inTable 1.The second experiment was done using the Caltech cars dataset(Rear) [21] and the AOLP dataset. The Caltech cars dataset consists of126 images with a resolution of 890/C2592 pixels taken during the day from complex outside scenes, each of which contains only one vehicle.The second dataset, the application-oriented license plate (AOLP), in-cludes 2049 images of vehicles. It is categorized into three subsets: accesscontrol (AC), trafﬁc law enforcement (LE), and road patrol (RP) that areavailable in Ref. [22].For the classiﬁcation, we have used a pre-trained CNN model, so thatwe do not need a large training dataset for successful classi ﬁcation. For license plate detection, theﬁrst CNN model was re-trained using 200license plate images and 200 non-license plate images that were croppedby ourselves from Caltech [21] and AOLP [22] datasets. For license plate recognition, about 600 images of cropped characters from the Caltechand AOLP datasets and some images of Arabic letters taken from imagesof Moroccan cars, as well as about 600 samples of non-characters fromdifferent scenes under different conditions, are used to re-train the sec-ond CNN model.2. Performance metricsTo evaluate the proposed system’s effectiveness, three different testing cases using Moroccan car video sequences from several scenes atdifferent conditions are used. The license plate detection accuracies andthe character recognition accuracies of this evaluation were recorded andlisted inTable 2.For the rating Criteria, the proposed system is evaluated by calcu-lating the accuracy of the detection and the recognition which is de ﬁned as the number of correctly detected license plates divided by the numberof correctly detected plus the number of incorrectly detected.Accuracy¼true positivetrue positiveþfalse positiveThe results listed inTable 2show that the proposed method giveshigh accuracy for the three sequences and con ﬁrms that it can effectively detect the license plate and recognize its characters in different situa-tions. Detection accuracy goes up to 98.4% and recognition accuracygoes up to 98.9% in some cases.Fig. 5shows some results of the detection and recognition process of Moroccan license plates.3. Evaluation results3.1. Evaluation of license plate detectionFor license plate detection, the performance has been evaluated usingthree methods to compare our work with. Rashedi et al. [ 13] have been detecting the license plate based on combining four methods, theContrast-based method, Color-based method, Edge-based method, and amethod uses cascade classiﬁers and local binary pattern (LBP). Yuan et al.[23] have based their work on connecting the high-density regions in thebinary edge image using a novel line density ﬁlter to localize license plates. Davis et al. [12] have been detecting the license plates based onTable 2License plate detection and character recognition accuracies.
Video Sequences Detection accuracy (%) Recognition accuracy (%)198.4 98.9296.23 98.5397.4 97.9
Fig. 5.Some results of the localization and recognition of Moroccan license plates.Table 3Evaluation results of the license plate detection.
Methods Detection Accuracy (%)Yuan et al. [23] 91.27Rashedi et al. [13] 93.32Davis et al. [12] 88.05Proposed method 96.72I. Slimani et al. Array 8 (2020) 100040
5detecting vertical edges using the VEDA algorithm. Table 3shows the result of the comparison between these methods and our proposedmethod using the Caltech cars dataset. Furthermore, according toTable 3, the comparison shows that our proposed method gives highaccuracy and efﬁciently detect the license plate and outperforms theother methods in terms of detection accuracy which achieves a detectionrate of 96.72% and a 3.4% improvement over the best method proposedby Rashedi et al. [13].There are many reasons for this improvement in the results of theproposed method. For example, the features extracted using 2D-WD(vertical details) are very important and signi ﬁcantly improve the accu- racy of the results of the proposed method instead of using an ordinaryedge detector which helps to reduce the false detection rate and also toreduce the processing time. Unlike other methods, they rely only onbinarization to extract features. Besides, the use of the entropy functionhelps a lot to detect potential regions more than the other proven algo-rithm. This combination of useful algorithms reduces the error rate andimproves the generated true candidates. Also, the classi ﬁcation of these generated candidates using CNN classiﬁer is one of the main reasons that improved accuracy.Some examples of the license plate detection results using the Caltechcars dataset are shown inFig. 6.3.2. Evaluation of character recognitionFor character recognition, our work has been compared with Hui Liet al. [16] using the AOLP dataset. Hui Li et al. [ 16] have used a recog- nition technique, which treats the license plate characters as an unseg-mented sequence, and trained 36-class convolutional neural network(CNN) to recognize the characters. The comparison data listed in Table 4 shows that the proposed method accuracy is slightly better than the othermethod. Some examples of the license plates recognition results for theAOLP dataset are shown inFig. 7.
Fig. 6.Some results of the detection process performed on the Caltech dataset.
Table 4Evaluation results of the character recognition process.
Methods Accuracy (%)AC LE RPHui Li et al. [16] 97.84 97.27 95.57Proposed method 98,03 97,9 96,11
Fig. 7.Some results of the recognition process performed on the AOLP dataset.I. Slimani et al. Array 8 (2020) 100040
6IV. ConclusionA license plate detection and recognition system is proposed in thispaper. The proposed system included two stages: the license platedetection stage and the character recognition stage. In the ﬁrst stage, the license plate candidates are generated based on vertical edges to detectthe potential license plate candidates. First, the 2D-WD is used to extractthe vertical edges. Then, the high-density areas of the vertical edges areextracted by calculating the maximum entropy areas to detect the po-tential license plate candidates. These candidates are then classi ﬁed by training a plate/non-plate CNN classiﬁer to remove the false positive. In the second stage, the characters are segmented ﬁrst by detecting the empty lines between the characters then these segmented candidates areclassiﬁed by training 42-class CNN classiﬁer to recognize the license plate characters. The proposed system was tested ﬁrst on Moroccan cars using three collected videos in different situations and it gives very encour-aging results where the high accuracy has gotten is 98,36% in term ofdetection and 98,9% in term of recognition. Thus, a comparative studyhas done using different works from the literature and shows that ourwork outperforms the other works. The comparative study of the licenseplate localization process was done on the Caltech dataset and shows theperformance of our work. For character recognition, the comparativestudy was done on the AOLP dataset and also gives satisfying results. Theexperiment results are satisﬁed and encouraging and show the efﬁciency of the proposed system.Declaration of competing interestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to in ﬂuence the work reported in this paper.Author Contribution StatementIbtissam Slimani:Conceptualization, Methodology, Resources,Software, Formal analysis, Writing - Original Draft, Writing - Review & Editing.Abdelmoghit Zaarane:Methodology, Software, Formal anal-ysis, Writing - Original Draft, Writing - Review&Editing.Wahban Al Okaishi:Investigation, Resources, Writing - Review&Editing.Issam Atouf:Validation, Visualization, Supervision. Abdellatif Hamdoun: Validation, Visualization, Supervision.FundingWe have no funding resources.Availability of data and materialsThe data used to support theﬁndings of this study are included withinthe article [21,22]. Please contact author for more requests.AcknowledgmentsThanks to all those who have suggested and given guidance for thisarticle.References
[1] Zaarane A, Slimani I, Hamdoun A, Atouf I. Real-Time vehicle detection using cross-correlation and 2D-DWT for feature extraction. J. Electr. Comput. Eng. 2019:1 –9. https://doi.org/10.1155/2019/6375176 . Jan. 2019. [2]Slimani I, Zaarane A, Hamdoun A, Atouf I. Traf ﬁc surveillance system for vehicle detection using discrete wavelet transform. J Theor Appl Inf Technol 2018;96(17):5905–17.[3]AL Okaishi W, Zaarane A, Slimani I, Atouf I, Benrabh M. Vehicular queue lengthmeasurement based on edge detection and vehicle feature extraction. J Theor ApplInf Technol 2019;97(5):1595–603. [4] Zaarane A, Slimani I, Hamdoun A, Atouf I. “Vehicle to vehicle distance measurement for self-driving systems. In: 2019 6th international conference oncontrol, decision and information technologies. CoDIT; 2019. https://doi.org/ 10.1109/CoDIT.2019.8820572 . 2019. [5] Zaarane A, Slimani I, Al Okaishi W, Atouf I, Hamdoun A. Distance measurementsystem for autonomous vehicles using stereo camera. Array Jan. 2020:100016.https://doi.org/10.1016/J.ARRAY.2020.100016 . [6] Shi X, Zhao W, Shen Y. Automatic license plate recognition system based on colorimage processing. Lect Notes Comput Sci 2005;3483(IV):1159 –68.https://doi.org/ 10.1007/11424925_121.[7] Dun J, Zhang S, Ye X, Zhang Y. Chinese license plate localization in multi-lane withcomplex background based on concomitant colors. IEEE Intell. Transp. Syst. Mag.Sep. 2015;7(3):51–61.https://doi.org/10.1109/MITS.2015.2412146 . [8] Ashtari AH, Nordin MJ, Fathy M. An Iranian license plate recognition system basedon color features. IEEE Trans Intell Transport Syst 2014;15(4):1690 –705.https:// doi.org/10.1109/TITS.2014.2304515 . [9] Zheng D, Zhao Y, Wang J. An ef ﬁcient method of license plate location. Pattern Recogn Lett Nov. 2005;26(15):2431 –8.https://doi.org/10.1016/ j.patrec.2005.04.014.[10] Deb K, Chae HU, Jo KH. Vehicle license plate detection method based on slidingconcentric windows and histogram. J Comput 2009;4(8):771 –7.https://doi.org/ 10.4304/jcp.4.8.771-777. [11] Jia W, Zhang H, He X, Piccardi M. “Mean shift for accurate license plate localization,”inIEEE Conference on Intelligent Transportation Systems . Proceedings, ITSC 2005;2005:566–71.https://doi.org/10.1109/ITSC.2005.1520110 . [12] Davis AM, Arunvinodh C, Arathy Menon NP. “Automatic license plate detection using vertical edge detection method. In: ICIIECS 2015 - 2015 IEEE internationalconference on innovations in information, embedded and communication systems;Aug. 2015.https://doi.org/10.1109/ICIIECS.2015.7193073 . [13] Rashedi E, Nezamabadi-pour H. A hierarchical algorithm for vehicle license platelocalization. Multimed Tool Appl Jan. 2018;77(2):2771 –90.https://doi.org/ 10.1007/s11042-017-4429-z. [14] Khan MA, Sharif M, Javed MY, Akram T, Yasmin M, Saba T. License number platerecognition system using entropy-based features selection approach with SVM. IETImage Process Feb. 2018;12(2):200 –9.
https://doi.org/10.1049/iet-ipr.2017.0368 . [15] Hung KM, Hsieh CT. A real-time mobile vehicle license plate detection andrecognition. Tamkang J Sci Eng 2010. https://doi.org/10.6180/jase.2010.13.4.09 . [16] Li H, Wang P, You M, Shen C. Reading car license plates using deep neuralnetworks. Image Vis Comput 2018. https://doi.org/10.1016/j.imavis.2018.02.002 . [17] Daubechies I. The wavelet transform, time-frequency localization and signalanalysis. IEEE Trans Inf Theor 1990. https://doi.org/10.1109/18.57199 . [18] Slimani I, Zaarane A, Hamdoun A. Convolution algorithm for implementing 2Ddiscrete wavelet transform on the FPGA. In: Proceedings of IEEE/ACS internationalconference on computer systems and applications. AICCSA; 2016. https://doi.org/ 10.1109/AICCSA.2016.7945831 . [19] Silva LEV, Filho ACSS, Fazan VPS, Felipe JC, Murta LO. Two-dimensional sampleentropy: assessing image texture through irregularity. Biomed. Phys. Eng. Express2016.https://doi.org/10.1088/2057-1976/2/4/045002 . [20] Nogueira K, Penatti OAB, dos Santos JA. Towards better exploiting convolutionalneural networks for remote sensing scene classi ﬁcation.Pattern Recognit.; 2017. https://doi.org/10.1016/j.patcog.2016.07.001 . [21]“The Caltech Database (Computational Vision at California Institute of Technology,Pasadena),.”http://www.vision.caltech.edu/archive.html.[22] Hsu GS, Chen JC, Chung YZ. Application-oriented license plate recognition. IEEETrans Veh Technol 2013.https://doi.org/10.1109/TVT.2012.2226218 . [23] Yuan Y, Zou W, Zhao Y, Wang X, Hu X, Komodakis N. A robust and ef ﬁcient approach to license plate detection. IEEE Trans Image Process 2017. https:// doi.org/10.1109/TIP.2016.2631901 .I. Slimani et al. Array 8 (2020) 100040
7