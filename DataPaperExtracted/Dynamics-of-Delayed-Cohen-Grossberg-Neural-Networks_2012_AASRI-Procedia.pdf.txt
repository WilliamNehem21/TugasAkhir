 AASRI Procedia   3  ( 2012 )  254 – 261 
2212-6716 © 2012 The Authors. Published by Elsevier B.V. Selection and/or peer review under responsibility of American Applied Science Research Institutedoi: 10.1016/j.aasri.2012.11.042 
 
 2012 AASRI Conference on Modeling, Identification and Control 
Dynamics of delayed Cohen-Grossberg neural networks 
Ancheng Chang Changlin Peng and Chuangxia Huang * 
College of Mathematics and Computing Science, Changsha University of  Science and Technology, Changsha, Hunan 410114, China.  
Abstract 
This paper studies the boundedness of Cohen-Grossberg neural networks with discrete delays and distributed delays (CGNN). Applying Lyapunov function and linear matrix inequalities technique (LMI), some novel sufficient conditions on the issue of the uniformly ultimate boundness, the existence of an attractor and the globally exponential stability for CGNN are established, which can be easily checked by the effective LMI toolbox in Matlab in practice. 
 © 2012 Published by Elsevier B.V. Selection and/or peer review under responsibility of American Applied Science Research Institute  
Keywords: Linear matrix inequalities technique (LMI), Neural Networks, Distributed delay, Boundedness, Attractor, Stability. 
1. Introduction In recent years, much attention has been paid on neural networks since they have been fruitfully applied in signal and image processing
 [1,2,3]. These applications rely crucially on the analysis of the dynamical behavior 
[4,5,6,7]. Among them, CGNN [8] can be described as follows  
1( ) ( ( )) ( ( )) ( ( )) , []nii i i i i j j jijxt xt xt af x t J                                                                     (1)  
 * Corresponding author. Tel.:0-086-731-85258787; fax: 0-086-731-85258787. E-mail: cxiahuang@126.com.. 
Available online at www.sciencedirect.com
© 2012 The Authors. Published by Elsevier B.V. Selection and/or peer review under responsibility of American Applied Science Research Institute Open access under CC BY-NC-ND license.
Open access under CC BY-NC-ND license.255  Ancheng Chang et al.  /  AASRI Procedia   3  ( 2012 )  254 – 261 
 where 0, 2tn ; n corresponds to the number of units in a neural network; ()ixt  denotes the potential (or voltage) of cell  
iat time t; (( ) )jfx t  denotes a non-linear output function; (( ) ) 0ixt  represents an amplification function; 
(( ) )ixt  represents an appropriately behaved function; the nn  connection matrix 
()ij n n Aa  denotes the strengths of connectivity between cells, and if the output from neuron jexcites (respectively, inhibits) neuron 
i, then 0ija (respectively, 0)ija ,  iJ denotes an external input source.  During hardware implementation, time delays do exis t due to finite switching speed of the amplifiers and communication time and may lead to an oscillation which is degenerate to the instability of networks furthermore. For model (1),    Ye et al. [9] introduce d delays by considering the following delay differential equations 
1( ) ( ( )) ( ( )) ( ( )) , 1, , . []nii i i i i j j j j ijxt xt xt af x t Ji n                                         (2)   Although constant fixed delays in the models of delayed feedback systems serve as a good approximation in simple circuits consisting of a small number of cells, neural networks usually have a spatial extent due to the presence of an amount of parallel pathways with a variety of axon sizes and lengths [10, 12]. Therefore, there will be a distribution of conduction velocities along these pathways. In this paper, we will consider the following CGNN m odel with mixed delays (discrete delays and       distributed delays):  
11( ) ( ( )) ( ( )) ( ( )) ( ( ))  [nni i i i i i jj ji jj j j jjxt xt xt af x t bf x t   
1(( ) ) d . ]
jntij j j ithjcf x s s J      (3)  Over the past decades, the stability of neural networks has been intensively investigated. In fact, except      for stability property, boundedness is also one of the foundational concepts of dynamical neural networks, which plays an important role in investigation for the uniqueness of equilibrium point (periodic solutions), global asymptotic stability, global exponentially stable and its synchronization and so on [14, 15]. To the best of the authors
 knowledge, few authors have considered on the ultimate boundedness and attractor for CGNN with interval time-varying delays and distributed time-varying delays. As is well known, compared with linear matrix inequalities (LMI) result, algebraic result is more conservative, and criteria in terms of LMI can be ea sily checked by using the powerful MATLAB LMI toolbox. This motivates us to investigate the problem  of the ultimate boundedness and attractor for CGNN in this paper. 2. Problem formulation System (3) for convenience can be rewritten as the following vector form  
( ) (( ) ) (( ) ) (( ) ) (( ) ) (() ) d []tthxt xt xt A F xt B F xt C F xs s J                     (4)  
(( ) ) ( ) .xt Ht Where,1 ( ) ( ( ), , ( ))Tnnxt x t x t R  is the neural state vector; (( ) )xt  
11 diag( ( ( )), , ( ( )))nnnnxt xt R ;   (( ) )xt , (( ) )Fx t  are appropriate dimensions functions;   
1(, , )Tn, 1(, , )Tnhh h ;  1(, , ) ,TnJJ J ( ) (( ) ) (( ) ) (( ) )Ht xt A F xt B F xt  256   Ancheng Chang et al.  /  AASRI Procedia   3  ( 2012 )  254 – 261 
 (() )tthCF x s J . The discrete delays and distributed delays are bounded:*1 0, m a x { } ;iiin 
*1 0, m a x { } ;iiinhh h  **max{ , }h , here **,,h  are scalars. As usual, the initial conditions associated with system (4) are given in the form  
() () ,xt t   0,t where ()t is a differentiable vector-valued function. Throughout this paper, we make the following assumptions. 
()1H  We assume that the delay kernels satisfy (0) 0, 1, ,jfj n , and there exist constants jl andjL, 
1, 2, , ,in  such that      
() (),, , .jjjjfx fylLxyRxyxy  
()2H There exist positive constants ,ii   such that                                                                                        
(( ) ) ;ii i iaxt  
()3H  There exist positive constantsjb, such that                                                                                            
2() ( () ) () .jj j j jxt xt b xt  Remark 2.1 The constants 
jl andjL can be positive, negative or zero. Therefore, the activation functions 
(( ) )fx t  are more general than the forms |( ) | | | , 0 , 1 , 2 ,,jj jfu K uK j n . Definition 2.1 [13] System (4) is uniformly ultimately bounded, if there is  
0B, for any constant 
0, there is (') 0'tt , such that 0(, , )xtt B  for all 00', 0, ,tt t t  where 
0010(, , ) m a x s u p | ( , , ) | .iinsxttx t st   Lemma 2.1 [11] For any positive definite constant matrix 
,nnWR scalar 0r, vector function  
() : [ ,] ,nut t rt R  0t, then
00 0() d () d () () d.() ()rr rTTus s W us s r u sW us s  3. Main Results Theorem 3.1 For a given constant
0a, if there is positive-definite matrix 12 diag( , , ),n Pp p p  
12 diag( , , )ii i i nDD D D , 1, 2i, ,QR such that the following condition holds  257  Ancheng Chang et al.  /  AASRI Procedia   3  ( 2012 )  254 – 261 
 11 12 132224334455 5666770000 0 000000000 ,00PB PC
                                                                       (5)  where  
11 1222 0,QQQQ 11 1222 0,SSSS11 1222 0,RRRR 0, 1, 2,iDi   
*** 11 1 2 11 3 12,/aaP aPP S e h R D**12, /aSe  
*1312 12 4 1,PA Q h R D*** 2211 3 2/,aaeQ DS e  
*
2412 4 2 ,aeQ D*33 22 1 22,QD h R*
4422 2 ,aeQ D  
**55 11/ahRe h ,**56 12, /ahRe h**66 22/ahRe h ,*277S, 
11diag{ 1/ ,1/ },n 21diag{ , , },n bb  31 1diag{ , , },nn lL lL  
41 1diag{( )/2, ,( )/2},nn lL lL  the symbol 
'*' within the matrix represents the symmetric term of the matrix, then System (4) is uniformly ultimately bounded.  Proof. Choosing the following Lyapunov functional  
1234 () () () () () ,V t Vt Vt Vt Vt                                                                                     (6)   where 
()101() 2d,()jnxtatjjj sVt p e ss
2() () () d,tas TtVt e s Q s s  () () , ( () )[]TT Ttx t F x t ,  
03() () () dd ,tas TtVt ex s S x s s   04()() () ddtas ThtVt e s R s s .  Computing the derivative of 
1()Vt along the trajectory of system (4), one can get   
1()Vt=()012d()[jnxtatjjj sap ess() ( () ) ]atjj j jp ext xt   258   Ancheng Chang et al.  /  AASRI Procedia   3  ( 2012 )  254 – 261 
  2 () ( () ) 2 ()[TTx t PAF x t x t PJ 2( ) ( ( ) )Tx t PBF x t 2( ) ( ( ) ) d . ]tTa tthxt P C F x s s e   (7)              According to Assumption (
2H), we obtain the following inequalities  
() 2 02d ().()jxtjj jjj saaps p x ts                                                                                (8)  From Assumption (
3H), inequalities (7) and (8), we obtain  
1()Vt12() () 2 () ()[]at TTae x t Px t x t Px t 2( ) ( ( ) )[Tx t PAF x t                                            (9)                  
2( ) ( ( ) )Tx t PBF x t 2( ) ( ( ) ) dtTthxt P C F x s s () () ]TT atx t Px t J PJ e .  Similarly, computing the derivative of $V_2(t)$ along the trajectory of system (4), one can get   
2()Vt () , () ) () , () )[] []at T T T T Te xtF x t Q xtF x t                 
()(( ) ) , () )[]at TTex t t F x t (( ) ) , () )[]TT TQx t t Fxt                            (10)     =
1112 () () ( () ) ()[at TTTe x tQ xt F xt Q xt12 22 ( ) (( ) ) (( ) ) (( ) ) ]TTxt Q F x t F x tQ F x t                 
*()11()()[at Tex t Q x t12 (( ) ) ( )TTFx t Q x t                                 
12 () ( () )Txt Q F x t22 (( ) ) (( ) ) ]TFx t Q F x t .  Computing the derivative of 
3()Vt along the trajectory of system (4), one can get               
3()Vt= 0() ()[at Tex t S x t()() () d ]at Tex tS x t                           
*() ()at Tex t S x t*()() () d,tat Ttex s S x s s                                                          (11)  Where 
*1max{ }.iin Denote 12 Max{ , , , }n, we obtain  
*() ()at Tex t S x t =*(( ) ) ( ) (( ) ) ( )[]atTex t H t S x t H t  *2() () .at TeH t S H t              (12)                259  Ancheng Chang et al.  /  AASRI Procedia   3  ( 2012 )  254 – 261 
   Using Lemma 2.1, the following inequality is easily obtained   
*()() () dtat Ttex s S x s s*()*
() d () d() ()atttTttexs s S xs s                                              (13)  =
*() */( ) ( ) 2 ( ) ( )[atTTex t S x t x t S x t () () ]Txt S x t . Similarly, computing the derivative of 
4()Vt along the trajectory of system (4), one can get        
4()Vt*11 12() () 2 ( () ) ()[at TTThe x t R xt F xt R xt22 (( ) ) (( ) ) ]TFx t R F x t                          (14)                                  
*() *()) d /d(() ()ttTath ththss R ss e h   From Assumption 
1()H , we have                                         
(( ) ) (( ) )0, 1, 2, , .() ()[] [ ]jjjjjjjjfx t fx tlL j nxt xt                            (15)  Then we obtain                                      
31 411()()0,(( ) )(( ) )T atDDxt xteDFx tFx t                                     (16)  and                           
32 422(( ) )( ( ( )))TDDxt tDFx t t (( ) )0(( ( ) ) ) at xt teFx t t.                          (17)  Denote 
( ) ( ( ), ( ), ( ( )), ( ( )),( ( )d ) ,( ( ( ))d ) , ( ( )) , ) tt TT T T T T T T T ththMt xtxt F x t F x t x ss F x s s H x t  combing with (9)-(17), we have 
12 1 () () () () () .at Tat TVt Vt V t eM t Mt e JP J                       (18) Therefore, one obtains 
22 1 1() ( ( 0 ) ),at at TKe xt V x a e J P J                                            (19)  where 
11/min{a }jjjnKn p , which implies                                                                        
22 11( ) [ ( (0))]/ .at Txt e V x a J P J K                (20) 260   Ancheng Chang et al.  /  AASRI Procedia   3  ( 2012 )  254 – 261 
 If one choose11/21[(1 )/ ] 0TBa J P J K , then for any constant 0and , there is
(') 0'tt , such that  2(( 0 ) ) 1ateV x for all 'tt. According to Definition 2.1, we have  
(, 0 , )xt B  for all  'tt. That is to say, system (4) is   uniformly ultimately bounded.   Theorem 3.2 If all of the conditions of Theorem 3.1 hold, then there exists an attractor 
B for the solutions of system (4), where
0 {( ) : ( ) , } Bxt xt Bt t . Proof.  If one choose
11/21[(1 )/ ] 0TBa J P J K , Theorem 3.1 shows that for any , there is '0t , such that 
(, 0 , )xt B  for all 'tt.  Let  B denote by 0 {( ) : ( ) , } .Bxt xt Bt t  Clearly,  
Bis closed, bounded and invariant. Furthermore, limsup inf ( ;0, ) 0
Btyxt y . Therefore, B is an attractor for the solutions of system (4).  Theorem 3.3 In addition to all of the conditions of Theorem 3.1 hold, if 
0J, then system (4) has a trivial solution 
() 0xt  and the trivial solution of system (4) is globally exponentially stable. Proof. If
0J, then system (4) has a trivial solution () 0xt . From Theorem 3.1, one has                                                 
22(; 0 , )atxt Ke  for all                                                                (21)    where
221(( 0 ) ) /KV x K .  Therefore, the trivial solution of system (4) is globally exponentially stable.  4. Conclusions In this paper, the dynamics of Cohen-Grossberg neur al networks with mixed delays is investigated. Novel multiple Lyapunov-Krasovkii functionals are designed  to get new sufficient conditions guaranteeing the uniformly ultimate boundedness, the existence of an  attractor and the globally exponential stability. The derived conditions are expressed in terms of LMIs, wh ich are more relax than algebraic formulation and can be easily checked by the effective LMI toolbox in Matlab in practice. Acknowledgements This work was supported in part by National Natural Science Foundation of China ( No.11101053), the Key Project of Chinese Ministry of Education (No.211118), the Excellent Youth Foundation of Educational Committee of Hunan Provincial (No.10B002), Science and Technology Project of Hunan of China (No. 2010FK3025, No. 2012SK3096). References [1] Z. Yuan, L. Huang, D. Hu, B. Liu. Convergence of Nonautonomous Cohen-Grossberg-Type neural networks with variable delays. IEEE Trans. Neural Netw., 2008; 19, 140-147.  [2] T. Roska, L.O. Chua. Cellular neural networks with nonlinear and delay-type template. Int. J. Circuit Theor. Appl., 1992; 20, 469-481.  261  Ancheng Chang et al.  /  AASRI Procedia   3  ( 2012 )  254 – 261 
 [3] D. Liu, A.N. Michel. Celular neural networks for associative memories. IEEE Trans. Circuits. Syst., 1993; 40, 119-121.  [4] P. Venetianer, T. Roska. Image compression by delayed CNNs. IEEE Trans. Circuits. Syst. I, 1998; 45, 205-215.  [5] T. Chen. 
. Neural Networks, 2001; 14, 977-980.  [6] K. Lu, D. Xu, Z. Yang. Global attraction and stability for Cohen-Grossberg neural networks with delays. Neural Networks, 2006; 19, 1538-1549.  [7] H. Chen, etl.. Image-processing algorithms realized by discrete-time cellular neural networks and their circuit implementations. Chaos, Solitons, Fractals, 2006; 29, 1100-1108.  [8] M. Cohen, S. Grossberg. Absolute stability and global pattern formation and parallel memory storage by competitive neural networks. IEEE Trans. Syst. Man Cybern., 1983; 13, 815-821.  [9] H. Ye, A. Michel, K. Wang. Qualitative analysis  of Cohen-Grossberg neural networks with multiple delays.  Phys. Rev. E, 1995; 50, 2611-2618.  [10] J. Cao, K. Yuan, H. Li. Global asymptotical s tability of gneralized recurrent neural networks with multiple discrete delays and distributed delays.  IEEE Trans. Neural Networks, 2006; 17, 1646-1651.  [11] K. Yuan, J. Cao, J. Li. Robust stability of sw itched Cohen-Grossberg neural networks with mixed time- varying delays.  IEEE Trans. Syst. Man Cybern, 2006; 36, 1356-1363.  [12] J. Lian, K. Zhang. Exponential stability for sw itched Cohen-Grossberg neural networks with average dwell time. Nonlinear Dyn., 2011; 63, 331-343.  [13] J. Cao, J. Liang. Boundedness and stability fo r Cohen-Grossberg neural networks with time-varying delays. J. Math. Anal. Appl., 2004; 296, 665-685.  [14] H. Zhang, Y. Wang. Stability analysis of Ma rkovian jumping stochastic Cohen-Grossberg neural networks with mixed time delays. IEEE Trans. Neural Netw., 2008; 19, 366-370.  [15] C. Huang, L. Huang. Dynamics of a class of Cohe n-Grossberg neural networks with time-varying delays.  Nonlinear Anal. RWA, 2007; 8, 40-52. 