Deep learning models for automatic identiﬁcationof plant-parasitic nematode
Nabila Husna Shabrinaa,⁎, Ryukin Aranta Likaa, Siwi Indartib
aDepartment of Computer Engineering, Universitas Multimedia Nusantara, Jl. Scientia Boulevard, Tangerang 15111, Indonesia
bDepartment of Plant Protection, Faculty of Agriculture, Universitas Gadjah Mada, Jl. Flora, Bulaksumur, Yogyakarta 55581, Indonesia
abstract article info
Article history:Received 29 July 2022Received in revised form 21 October 2022Accepted 30 December 2022Available online 4 January 2023Plant-parasitic nematodes cause various diseases that can be fatal to the infected plants. It causes losses to theagricultural industry, such as crop failure and poor crop quality. Developing an accurate nematode classi ﬁcation system is vital for pest identiﬁcation and control. Deep learning classi ﬁcation techniques can help speed up Nem- atode identiﬁcation as it can perform tasks directly from images. In the present study, four state-of-the-art deeplearning models (ResNet101v2, CoAtNet-0, Ef ﬁ- cientNetV2B0, and EfﬁcientNetV2M) were evaluated in plant- parasitic nematode classiﬁcation from microscopic image. The models were trained using a combination ofthree different optimizers (Adam, SGD, dan RMSProp) and several data augmentation with image transforma-tions, such as imageﬂip, blurring, noise addition, brightness, and contrast adjustment. The performance of thetrained models was varied. Regarding test accuracy, Ef ﬁcientNetV2B0 and EfﬁcientNetV2M using RMSProp and brightness augmentation give the best result of 97.94% However, the overall performance of Ef ﬁcientNetV2M was superior, with 98.66% mean class accuracy, 97.99%F1 score, 98.26% average precision, and 97.94% averagerecall.© 2023 The Authors. Publishing servic es by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:AugmentationsClassiﬁcationsDeep learningNematodeOptimization
1. IntroductionNematodes are one of the living things with very abundant and di-verse species (Abad et al., 2008). From the 26,000 types of nematodesidentiﬁed, there are over 4100 plant- parasitic nematodes ( Jones et al., 2013). Plant-parasitic nematodes are microorganisms that cause exten-sive damage and substantial crop yield losses ( De and Elsen, 2007). They will continue to threaten agricultural production since they are foundand infect various plants, including food crops, horticulture, and estate.Estimation of the world's economic crop losses caused by parasitic nem-atodes may reach 80 billion USD. In Indonesia, nematodes problems in-crease yearly since the most destructive plant-parasitic nematodes onpotato, Globodera rostochiensis, was found ( Indarti et al., 2004) and fallowed their distribution become wider in potato growing areas.New species of plant parasitic nematodes were also found in rice, garlic,and potato (Ajri et al., 2021;Indarti et al., 2018;Mutala'liah et al., 2018). Plant parasitic nematodes are tiny life forms varying in size andshape. Due to their little measure and the assortment of genera, it be-comes challenging to distinguish which sorts are shown in a speci ﬁc test. The current strategy may be a conventional one which is time-consuming and helpless to error. Improvement technique forobservation and classiﬁcation of plant parasitic nematode is essentialfor pest identiﬁcation and control. Therefore, the development of auto-matic image-based methods capable of identifying nematodes quicklyand reliably is required.Implementing deep learning techniques in image-based classi ﬁca- tion became an alternative for speeding up the nematode's identi ﬁca- tion process, as it is suitable for detecting discriminative nematodesfeatures and handling large specimens. Various deep learning classi ﬁca- tion techniques are readily available (e.g., Keras and TensorFlow) andare easy to implement. The deep learning techniques are also provento recognize pests and diseases, such as in leaves, with high accuracyby providing sufﬁcient data (Li et al., 2021). Convolutional Neural Networks (CNN) via transfer learning wereimplemented for multi-crop leaf disease image classi ﬁcation. This pro- posed research has achieved accuracy for grape and tomato leaf diseaseclassiﬁcation by 98.40% and 95.71%, respectively ( Paymode and Malode, 2022). Data augmentation and extension of deep learning VGG-16 pre-trained network model were applied for the multi-pest classi ﬁcation of Indonesian mango leaves image. The overall accuracy achieved fromthose training is 73% on the validation dataset and 76% for the testingdata (Kusrini et al., 2020). Improved CNN was built for the real-time de-tection of apple leaf diseases. Using a dataset of 26,377 images of dis-eased apple leaves, the implementation of INAR-SSD (SSD withInception module and Rainbow concatenation) gave a detectionArtiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
⁎Corresponding author.E-mail address:nabila.husna@umn.ac.id(N.H. Shabrina).
https://doi.org/10.1016/j.aiia.2022.12.0022589-7217/© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/performance of 78.80% mAP on the dataset ( Jiang et al., 2019). The cor- relation effect of several optimization techniques on CNN performancefor olive disease classiﬁcation was also observed. It was found that thehighest rate in the experiment without data augmentation was 92.59%(Raouhi et al., 2022).There are several works implemented for nematodes classi ﬁcation using deep learning. Xception models were trained with different initialconditions on the dataset of various stages of nematodes (both juvenileand adult). It is found that the model with pretrained weights onImageNet performed the best compared to random weight and noweight initialization. However, due to hardware limitations, the authorscould not train better but heavier models, and the images in the datasetlack variation (Uhlemann et al., 2020). Another research focused on in-creasing the availability of nematodes datasets to the public while pro-viding species recognition benchmarks by testing multiple state-of-the-art deep learning models on the dataset. The dataset consists of 2769nematodes samples classiﬁed manually into 19 classes. From thisbenchmark, it is found that the ResNet family model has the highestperformance in terms of accuracy ( Li et al., 2021). A new proposed CNN model, deﬁned as NemaNet, was used to identify a new datasetfor nematodes soybean crop in Brazil. The NemaNet model reached96.99% accuracy, while the best fold was 98.03% ( Abade et al., 2022). Previous research does not include many other nematodes speciescommonly found in Indonesia. This research provides data that containsthese species and assesses the performance of a state-of-the-artdeep learning model for use in Indonesia. This paper compares fourstate-of-the-art deep learning models (ResNet101v2, CoAtNet-0,EfﬁcientNetV2B0, and EfﬁcientNetV2M) trained on nematodes datasetspecies commonly found in Indonesian soil. Data augmentation wasemployed to determine if image transformation can further increasethe accuracy of the tested models. The effect of several optimizer func-tions was also observed on the performance result. The contributionsof the paper are listed as follows:•To build an additional image dataset for species of nematodes com-monly found in Indonesia•To provide model benchmark comparison for real classi ﬁcation sys- tem implementation•To implement 4 state-of-the-art deep learning techniques(ResNet101v2, CoAtNet-0, EfﬁcientNetV2B0, and EfﬁcientNetV2M) for multi-class classiﬁcation of plant-parasitic nematodes•To evaluate the performance of 4 state-of-the-art deep learningmodels with respect to data augmentation and optimizer function•To design and develop a web application to classify plant-parasiticnematodesThe structure of this paper is organized as follows. Section 2presents Materials and Method, starting with the datasets and then describingthe implemented deep learning architecture. Section 3presents the de- tailed Result and Discussion on the comparison of 4 state-of-the-artdeep learning models for multi-class classi ﬁcation of plant-parasitic nematodes. Finally, inSection 4, the paper concludes with a remark onthe model comparison and some perspective for future work.2. Materials and methods2.1. Proposed researchThe schematic inFig. 1shows an overview workﬂow for multi-class plant-parasitic nematodes classiﬁ
cation. Initially, plant-parasitic nema-todes dataset is collected and classiﬁed into several classes. Data pre- processing was applied to the dataset using edge detection, cropping,and converting into grayscale. Imageﬂip, noise addition, image blurring, brightening and contrast are applied in single augmentation to enhancethe size of the dataset. The photos are then used as input to train themodel using several augmentation and optimizer function combina-tions. The result was recorded and analyzed based on the metric perfor-mance. The best performance is then deployed as a web-based system.2.2. Nematodes dataset2.2.1. Data collectionAll nematodes were collected from an infected agricultural plant inIndonesia to gather the required pictures. Nematodes were isolatedfrom plant root and rhizosphere soil and then proceeded to the speci-men for further observation. First, soil samples were extracted for nem-atodes presence utilizing the adjusted Whitehead Tray method.Nematodes extractions from root samples were cut into 1 mm pieces;at that point were laid on the channel paper on the nylon screen bol-stered by the altered bucket, allowing water to join the root tests. Thenematodes swimming out to the water were collected on the tubes toassist both morphological perceptions. The plunging was at room tem-perature for 24 h. This method alluded to Whitehead Plate Method(Southey, 1986) with adjustment. Before further observation, nema-todes were killed, andﬁxed with cooled Formalin Acetic Acid (FAA) re-ferred to (Southey, 1986). Finally, the nematodes morphologicalcharacters of each genus were observed using a light microscope Olym-pus CX 31 with a magniﬁcation of 40–1000. The image was captured with optical connected with the microscope and laptop.Dataset consists of 957 nematode samples that were classi ﬁed into 11 classiﬁcations. This dataset represents nematodes commonly foundin Indonesian soil.Table 1shows some statistics of nematodes genusdistribution in the dataset. As shown in the given table, the genus distri-bution is diverse. Genus with less than 65 images accounts for 45% of thewhole class. This happened due to the limited nematodes distributionarea and only a speciﬁc host that could develop the nematode. Fig. 2 presents sample nematodes images from the dataset.2.2.2. Data preprocessingObtained samples are then preprocessed with a similar method usedfor previous work (Lu et al., 2021). Samples were cropped based onedge detection in an attempt to equalize which regions the nematodesspecimen exists in the image. This also reduces redundant informationby cutting empty spaces. Samples were converted into grayscale imagessince classiﬁcation is solely based on morphological features of the sam-ples. All images are then resized to 224 × 224 to ﬁt the input size of all tested models. The data preprocessing steps are shown in Fig. 3.2.2.3. Data augmentation processData augmentation processes often increase image diversity in adataset by applying image manipulation techniques or syntheticallycreating new data. This process aims to increase generalization, preventmodel overﬁtting to the training dataset and lead to better performance(Shorten and Khoshgoftaar, 2019). Common manipulation techniquesapplied in data augmentation processes include image transformationbyﬂipping, rotation, translation, noise addition, blurring, change inbrightness, contrast, and other color space transformations. This will in-crease the discriminative feature of each class that model needs to learnto not overﬁt. Image manipulation techniques need to be chosen basedon the nature of the sample, as some image transformations can resultin contextually incorrect data that does not re ﬂect the nature of the real specimen. With the correct augmentation techniques, model per-formance can be improved, especially on the dataset with imbalancedclass distribution. However, the augmentation process increases thetime it required to train the model as it increases the size of the dataset. Image transformation techniques also affect model accuracy, as sometechniques decrease model accuracy ( Shijie et al., 2017). This research applied augmentation on the ﬂy (online augmenta- tion) to increase data diversity. Image manipulation techniques usedareﬂipping (horizontally and vertically), noise addition, blurring,change in brightness, and change in contrast. Some manipulationN.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
2techniques such as translation and rotation were not chosen due to theconcern that augmentation results could hide important discriminativefeatures of the sample, which can decrease model accuracy. The follow-ing list describes the applied image augmentation.1. Imageﬂip is applied randomly on images in the dataset, and theﬂip type is chosen randomly as well, whether no ﬂip is applied, the horizontalﬂip is applied, the verticalﬂip is applied, or bothﬂips are applied.2. Noise addition is performed by adding white gaussian noise to theimage sample with a mean value of 0 and a standard deviation of0.15. This is applied randomly with a probability of 50% on each sample.3. Image blurring is performed by applying a gaussian ﬁlter with a ker- nel size of {3 × 3} and standard deviation value of 1. This is appliedrandomly with a probability of 50% on each sample.4. Change in brightness is applied by the increase of brightness withbrightness parameter of random value from 0 to 0.35. Change in contrast is applied by increase of contrast with contrast pa-rameter of random value from 0 to 3.The datasets and their augmented variations are then used to trainthe models. In evaluating the model performance, the dataset is splitinto a training set, validation set, and test set with a ratio of 80:10:10.To summarize, the dataset consists of 957 nematodes sample with 11classiﬁcations, split into 766, 96, and 95 for training, validation, andtest respectively. Note that augmentation processes are performedonly on the training set of the dataset.2.3. Deep learning architectureNematodes classiﬁcations are performed using several state-of-the-art models in terms of image classiﬁcation problems, namely ResNetV2,CoAtNet, and EfﬁcientNetV2. Model families are chosen based on theirperformance on Image Classiﬁcation on ImageNet Benchmark (Keras, 2021;Stojnic et al., 2022). Based on hardware limitations and the sizeof datasets used in the experiments, a speci ﬁc variant of models applied are ResNet101V2, CoAtNet-0, EfﬁcientNetV2B0, and EfﬁcientNetV2M.
Fig. 1.Research workﬂow.
Table 1Nematode genus distribution in the dataset.Genus No. of samplesGenus Criconema 3Genus Criconemoides 103Genus Helicotylenchus 135Genus Hemicycliophora 6Genus Hirschmanniella 130Genus Hoplolaimus 151Genus Meloidogyne 211Genus Pratylenchus 116Genus Radopholus 12Genus Trichodorus 30Genus Xiphinema 60Total 957N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
32.3.1. Residual networksThe original Residual Networks (ResNet) architecture is a CNN basedon VGG architecture that employs residual learning in its buildingblocks by adding shortcut connections that skips one or more layers.This alleviates the degradation problem that VGG architecture haswhen a deeper model is used (He et al., 2016a). The ResNetV2 is the im- proved version of ResNet architecture that improves the speed of datapropagation on each residual block by utilizing identity mapping asthe skip connections and after-addition activation. This eases(a) Genus Criconema (b) Genus Criconemoides (c) Genus Helicotylenchus 
(d)  Genus Hemicycliophora (e) Genus Hirsmaniella (f) Genus Hoplolaimus 
(g)  Genus Meloidogyne (h) Genus Pratylenchus (i) Genus Radopholus 
(j) Genus Trichodorus (k) Genus Xiphinema 
Fig. 2.Sample of plant-parasitic nematodes used in this study
Fig. 3.Data pre-processingﬂowchart.N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
4optimization loss compared to the baseline ResNet and improves theregularization of the models. Several variations of the ResNet models,based on the number of layers inside the network, are ResNetV2 –50, ResNetV2–101, and ResNetV2–1 5 22(He et al., 2016b). The ResNet model network architecture implanted in this paper is presented inFig. 4.2.3.2. Convolution and attention networksThe Convolution and Attention Networks (CoAtNet) architecture is afamily of hybrid models that combines CNN and Transformer architec-ture to achieve better generalization and larger capacity. Transformerarchitectures with a self-attention mechanism have a higher model ca-pacity that can beneﬁt from larger and more diverse datasets, mean-while, convolutional architectures have a better generalization andfaster-converging speed. This architecture consists of 5 stages (1convolutional layer, 2 MBConv layers, and 2 transformer layers), withdifferent properties depending on the model variant. The main variationof the CoAtNet model consists of 5 basic variations (CoAtNet-0 toCoAtNet-4) and 3 variations with different block parameters(CoAtNet-5 to CoAtNet-7) (Dai et al., 2021). The CoAtNet network archi- tecture is presented inFig. 5.2.3.3. EfﬁcientNetT h eb a s e l i n eE fﬁcientNet architecture is based on a new scalingmethod for increasing model capacity by scaling the dimensions ofwidth, depth, and resolution of the model using a simple compound co-efﬁcient (Tan and Le, 2019). Neural Architecture Search (NAS) is thenused to design a new baseline model using MBConv blocks and scale itusing the compound coefﬁcient to create EfﬁcientNet (Elsken et al., 2019). This new family of models achieve state-of-the-art performanceon ImageNet dataset while having a far smaller model and faster con-verging speed (Tan and Le, 2019). This family of models are thenimproved even further by employing Fused-MBConv. The speci ﬁcc o m - bination of MBConv and Fused-MBConv used in the network improvestraining speed and decreases the model size. The new and improvedmodels are then called EfﬁcientNetV2, which with a speciﬁc training method, can achieve 5×–11× faster-converging speed compared toother state-of-the-art models with up to 6× smaller in size ( Tan and Le, 2021). EfﬁcientNetV2 implemented in this research was B0 and Mversion. EﬁccientNetV2B0 has better trade-off on accuracy and FLOPs,while EfﬁcientNetV2M reduces parameter and FLOPs but run faster intraining and inference compared to the V1-B7 version ( Tan and Le, 2021). The applied EfﬁcientNetV2B0 and EfﬁcientNetV2M network ar- chitecture in this research are presented in Fig. 6andFig. 7, respectively.2.3.4. Proposed classiﬁcation networks
The weights of each model are preserved from the pre-trainedmodel based on ImageNet dataset, with its ImageNet classi ﬁcation head layer removed. Feature extraction vectors of each model are then
Fig. 4.ResNet101V2 network architecture.
Fig. 5.CoAtNet network architecture.
Fig. 6.EfﬁcientNetV2B0 network architecture.N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
5connected to a dense layer with Soft-Max activation to perform classi ﬁ- cation, with class count adjusted to the dataset used, which is 11 genusclassiﬁcations. The proposed classiﬁcation layer is depicted inFig. 8.2.3.5. Optimization techniquesThree different optimizers were used in the training process to de-termine the best optimizer for each type of model and whether archi-tecture or dataset diversity affects the optimizers' use. This alsominimize unfair advantage of some model in case of hyperparameterﬁts the exact requirement of a speciﬁc model-dataset combination that can achieve better performance. Optimizers that were used in theexperiments are Adam, SGD, and RMSprop. Adam is chosen based onits favorable performance compared to other optimization method, asi tt e n d st ow o r kw e l li np r a c t i c e(Kingma and Ba, 2014). SGD is chosen to represent gradient descent optimizers and is often used to producethe state-of-the-art results in some deep learning research. SGD alsoproduce better generalization performance ( Zhou et al., 2020). RMSprop was chosen as it is suitable for optimizing non-stationaryand non-convex problems (Sun et al., 2020). For consistency, each model will be trained using the samehyperparameter value, including the same activation for dense layer(SoftMax), batch size of 32, and same optimizer parameters (learningrate of 0.001 for Adam and RMSprop, 0.01 for SGD; the momentum of0 for SGD and RMSprop; a beta value of 0.9 –0.999 for Adam), input size of 224x224x3, and sparse cross-entropy loss function for multi-label classiﬁcation problem. The training epoch was set to 100.2.3.6. Evaluation metricsSeveral evaluation metrics were employed in this experiment. TestAccuracy is used to evaluate the average accuracy of the model overall images on the test set. The F1-score metric is a classi ﬁcation evalua- tion metric based on the harmonic mean of precision, and recall is oftenused when the class distribution in the dataset is imbalanced. WeightedF1-score metric was used to evaluate the imbalanced datasets. Averageprecision and recall were recorded for data completeness. The formulafor test accuracy, F1 score, average precision and recall are given inEqs.(1)–(4), respectively (Alsaggaf et al., 2020).Test Accuracy¼TPþTNTPþTNþFPþFNð1ÞPrecision¼
TPTPþFP ð2ÞRecall¼
TPTPþFN ð3ÞF1score¼
2x Precision x RecallPrecisionþRecall ð4Þwhere TP–True Positive; FP–False Positive; TN–True Negative; FN– False Negative. Another evaluation metric applied in this experimentis Mean Class Accuracy (Diker et al., 2019;Toğaçar et al., 2021). It is used to evaluate the accuracy of each class that could indicate if the modellearns discriminative features of each class compared to other models.The formula is given in Eq.(5)Mean Class Accuracy¼
1c∑ci¼11n
i∑ni
j¼1aij ð5Þwherecis the number of classes (11 classes for nematodes genus), n
iis the number of the image ini−thclass,a
jiis the accuracy for image numberj−thini−thclass.2.3.7. System implementationCode implementation of each model is achieved using Keras(Chollet, 2015) and TensorFlow library that provides fully built modelswith pretrained weights on ImageNet dataset. Model training and infer-ence will be performed on the Google Colab Notebook (Pro Version),which has a minimum speciﬁcation of NVIDIA P100 or T4 as GPU, mem-ory up to 25GB, and CPU Xeon Processor @ 2.3GHz based on availability.3. Result and discussion3.1. Model performance with augmentationFig. 9present the sample data augmentation of the GenusTrichodorus using image augmentation method. Each model wastrained with the speciﬁed hyperparameter and optimizers on thedatasets augmented with an image transformation technique. Thedataset is used to gauge the performance of Nematodes commonlyfound in Indonesian soil. Model performances on the test dataset arethen compared to the model's base performance on the dataset withoutaugmentation.Table 2presents ResNet101V2 model performance using augmenta-tion. The“%Test”column is the accuracy of the model classi ﬁcation re- sults on the test dataset. The test dataset represents data that themodel has never seen before. The ResNet101v2 model trained with an
Fig. 7.EfﬁcientNetV2M network architecture.
Fig. 8.Proposed model classiﬁcation layer.N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
6augmentation dataset resulted in varying performance changes. Thehighest accuracy of 93.81% is obtained when trained without any aug-mentation, using SGD optimizer, whereas using RMSprop optimizer re-sulted in the lowest accuracy out of all model combinations, with anaccuracy of 18.56%.Fig. 10a shows the impact of augmentation on ResNet101V2 %TestAccuracy compared to the normal dataset. Using Adam Optimizer,Gaussian Blur Augmentation tends to improve accuracy. The augmenta-tion method implemented using SGD Optimizer leads to decreasing13.4% to 43.4 in %test accuracy, while applying RMSProp Optimizer in-creases the %test accuracy from 3.09% to 14.43%.The CoAtNet-0 model trained with an augmentation dataset resultedin small performance increases and varying performance decreases, asseen inTable 3. The highest accuracy of 96.91% is achieved with the normaldataset using SGD optimizer, while the lowest accuracy of 70.10% is ob-tained with the contrast augmentation dataset using RMSprop optimizer.The impact of augmentation on CoAtNet-0 %Test Accuracy is given inFig. 10b. Using Adam Optimizer, Flip and Gaussian Noise decreases theaccuracy while another augmentation tends to improve accuracy by1% to 5.12%. The augmentation method implemented using SGD Opti-mizer leads to decreasing 5.15% to 13.4% in %test accuracy. RMSProp Op-timizer applied with Brightness and Gaussian Blur increased the %testaccuracy by 5.15% and 4.12%, respectively, while other augmentationsdecreased the %test accuracy.The EfﬁcientNetV2B0 model trained with augmentation mostly de-creased performance, as shown inTable 4. The highest accuracy of 97.94% is obtained with brightness augmentation using RMSprop opti-mizer, whereas the lowest accuracy of 65.98% is obtained with the con-trast augmentation using SGD as the optimizer.The impact of augmentation on EfﬁcientNetV2B0 %Test Accuracy is presented inFig. 10c. The increasing test accuracy by 1.03% occurredwhen the model applied RMSProp with brightness augmentation. An-other method leads to a decrease in the %test accuracy from 4.12% to30.93%.The EfﬁcientNetV2M model trained with augmentation mostly de-creased performance, as seen inTable 5. The highest accuracy of 97.94% is obtained from the model which applied brightness augmenta-tion and RMSprop optimizer. The lowest accuracy of 76.29% is obtainedwith the noise augmentation dataset using SGD as the optimizer.The impact of augmentation on EfﬁcientNetV2M %Test Accuracy is presented inFig. 10d. The result is similar to EfﬁcientNetV2B0 in Fig. 10c but with a lower range. The increasing %test accuracy of 6.19%occurred when the model applied RMSProp with brightness augmenta-tion. Another method tends to give lower results in the %test accuracy,ranging from 1.03% to 21.65%.Applying augmentation to the dataset resulted in a more varied per-formances change. Notable performance improvements are on theResNet101v2 and CoAtNet-0 model with RMSprop optimizer andCoAtNet-0 with Adam optimizer. Nevertheless, it should be noted thatResNet101v2 with RMSprop has terrible base performance comparedto other optimizers (18.56% with RMSprop, compared to 88.66% withAdam and 93.81% with SGD).The best test accuracy is achieved by the Ef ﬁcientNetV2B0 and EfﬁcientNetV2M model with RMSprop optimizer, trained on the datasetwith brightness augmentation. This combination achieved 97.94% accu-racy. The CoAtNet family scored on average lower test accuracy differ-ence than other models, indicating higher generalization capabilitytowards augmented data than other family models.Based on the obtained data, it can be observed that there is a strongrelationship between using speciﬁc image manipulation technique asan augmentation method and the combination of the model-optimizerthat would determine its performance. Choice of augmentation method,optimizers, and parameters are essential in achieving the best result amodel can perform.3.2. Augmentation method impact on model performance3.2.1. Flip augmentationFrom the data gathered, 11 out of 12 models trained on the ﬂip dataset show a decrease in model accuracy. This is presumably due tothe relatively small dataset size causing the data to have a similar orien-tation distribution. All model families have up to ten million parameters.Therefore, the model is not only performing classi
ﬁcation based on the discriminatory features of each genus but also based on a similar orien-tation between each classiﬁcation. Adding data with different orienta-tions causes the model to be unable to classify data based onorientation and decreases performance. This indicates models over ﬁt the data's environmental aspect, such as data acquisition methods,rather than each genus' discriminative features.Observation of the performance of ResNet101v2 using Adam opti-mizer, visualization of the classiﬁcation layer activation of the GenusXiphinema class shows the discriminatory orientation of the class.When trained on the dataset without augmentation (normal dataset),the visualization shows the shapes commonly found in the Genus spec-imen. However, when it was trained using ﬂip augmentation, the layer activation area was not as clear as the normal dataset, as seen in Fig. 11. This shows that according to the model, important features of the genusare aligned in that speciﬁc way. In the dataset, the Genus Xiphinemadata does have some orientation as described in the activation propertyof the model with the normal dataset.Table 2Results obtained from ResNetV2 –101 Model.Optimizer Dataaugment% TestaccuracyMeanclassaccuracyF1scoreAverageprecisionAveragerecallAdam Normal 88.66% 0.7662 0.882 0.8955 0.8866Flip 77.32% 0.7715 0.7743 0.8048 0.7732Brightness 87.63% 0.9097 0.8758 0.8877 0.8763Contrast 81.44% 0.7996 0.8151 0.8294 0.8144Gaussian Blur 89.69% 0.8148 0.8948 0.9051 0.8969Gaussian Noise 86.60% 0.8697 0.8641 0.8727 0.866SGD Normal 93.81% 0.9329 0.9375 0.9398 0.9381Flip 69.07% 0.4808 0.6863 0.7065 0.6907Brightness 80.41% 0.6813 0.7929 0.7925 0.8041Contrast 62.89% 0.5768 0.6311 0.6485 0.6289Gaussian Blur 50.52% 0.4774 0.5139 0.5508 0.5052Gaussian Noise 68.04% 0.752 0.6848 0.766 0.6804RMSprop Normal 18.56% 0.0909 0.0581 0.0344 0.1856Flip 21.65% 0.1 0.0771 0.0469 0.2165Brightness 32.99% 0.2529 0.2972 0.326 0.3299Contrast 22.68% 0.1 0.0846 0.052 0.2268Gaussian Blur 24.74% 0.1026 0.1063 0.0677 0.2474Gaussian Noise 22.68% 0.087 0.0877 0.0543 0.2268
Fig. 9.Sample data of the Genus Trichodorus specimen resulting from image augmenta-tion.N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
7Only the ResNet101v2 with RMSprop optimizer got higher accuracyin terms of performance improvement. However, this increase in accu-racy can be attributed to the impact of using RMSprop as an optimizeron ResNet101v2 model instead of the augmentation itself because allother results of this model-optimizer combination result in unsatisfac-tory accuracies.3.2.2. Brightness augmentationApplying brightness augmentation resulted in varying performancesfor each model-optimizer combination. This augmentation caused asmall change in accuracy for models with Adam optimizer (±1% changein accuracy) and an increase in the model with RMSprop optimizer(+5.15% to +14.43%). Still, it showed a decrease in models with SGD(a) ResNet101V2 (b) CoAtNet-0 
(c) EfficientNetV2B0 (d) EfficientNetV2M 
Fig. 10.Impact of augmentation method on %test accuracy.
Table 3Results obtained from CoAtNet-0 Model.Optimizer Dataaugment% TestaccuracyMeanclassaccuracyF1scoreAverageprecisionAveragerecallAdam Normal 85.60% 0.694 0.8576 0.8547 0.866Flip 83.51% 0.8072 0.8418 0.8637 0.8351Brightness 86.60% 0.8893 0.8639 0.8823 0.866Contrast 87.63% 0.7987 0.8798 0.897 0.8763Gaussian Blur 90.72% 0.9244 0.9056 0.9147 0.9072Gaussian Noise 84.54% 0.8186 0.8455 0.8739 0.8454SGD Normal 96.91% 0.9747 0.9691 0.9697 0.9691Flip 90.72% 0.8209 0.9007 0.9047 0.9072Brightness 86.60% 0.8805 0.8664 0.8793 0.866Contrast 91.75% 0.939 0.9162 0.9255 0.9175Gaussian Blur 89.69% 0.8924 0.8965 0.9078 0.8969Gaussian Noise 83.51% 0.8286 0.8428 0.8808 0.8351RMSprop Normal 85.57% 0.7899 0.8562 0.8661 0.8557Flip 75.26% 0.8027 0.7533 0.7676 0.7526Brightness 90.72% 0.9014 0.9029 0.9158 0.9072Contrast 70.10% 0.7625 0.7021 0.7186 0.701Gaussian Blur 89.69% 0.8399 0.8889 0.8919 0.8969Gaussian Noise 84.54% 0.8663 0.8453 0.8549 0.8454Table 4Results obtained from EfﬁcientNetV2B0 Model.Optimizer Dataaugment% TestaccuracyMeanclassaccuracyF1ScoreAverageprecisionAveragerecallAdam Normal 94.85% 0.9709 0.9486 0.9507 0.9485Flip 78.35% 0.7335 0.7727 0.7833 0.7835Brightness 91.75% 0.8315 0.9137 0.9201 0.9175Contrast 87.63% 0.8212 0.8793 0.8979 0.8763Gaussian Blur 72.16% 0.6657 0.7178 0.8044 0.7216Gaussian Noise 80.41% 0.7338 0.8006 0.8184 0.8041SGD Normal 96.91% 0.9755 0.9691 0.9724 0.9691Flip 79.38% 0.8203 0.7941 0.8017 0.7938Brightness 81.44% 0.753 0.8114 0.8406 0.8144Contrast 65.98% 0.5918 0.6576 0.6946 0.6598Gaussian Blur 70.10% 0.6266 0.6983 0.7085 0.701Gaussian Noise 74.23% 0.7482 0.7355 0.7512 0.7423RMSprop Normal 96.91% 0.9744 0.9689 0.9731 0.9691Flip 84.54% 0.8662 0.8421 0.868 0.8454Brightness 97.94% 0.8923 0.9747 0.9716 0.9794Contrast 92.78% 0.952 0.9272 0.9293 0.9278Gaussian Blur 92.78% 0.8102 0.9168 0.9256 0.9278Gaussian Noise 81.44% 0.8748 0.8014 0.8763 0.8144N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
8optimizer (−10.31% to−20.62%). Brightness augmentation tends toimprove model performance or decrease less accuracy compared toother augmentation methods. The increase is due to the dataset's highbrightness variation between specimens.3.2.3. Contrast augmentationUsing contrast augmentation on the dataset resulted in decreasedmodel accuracy. Only 2 out of 12 observed data have higher accuracythan their normal data counterpart, namely ResNet101v2 withRMSprop and CoAtNet-0 with Adam optimizer. Based on observations,increasing contrast too much will result in contextually incorrect Nem-atodes images, i.e., Nematodes images that cannot be obtained fromreal-world photos. The increasing in contrast will also increase the clar-ity of some features of specimens that are not discriminatory betweenGenus. This could cause the model to learn irrelevant features of aGenus.3.2.4. Gaussian blur augmentationImage blurring with gaussian blur is expected to help models learnabout the general morphological characteristics of each Genus of Nem-atodes. Augmentation of gaussian blur caused some model-optimizercombinations to have increased accuracy. Based on observations, theprocess of image blurring in the dataset produces the variations neededby the model to study the features of the target class nematodes. Thismay be due to the selection of parameter values in the datasetaugmentation process, which affects the strength of the blurring andthe size of the gaussianﬁlter kernel used.3.2.5. Gaussian noise augmentationApplying Gaussian noise augmentation to the dataset results indecreased accuracy. An increase in accuracy only occurs on theResNet101v2 with the RMSprop optimizer. The decrease in accuracy ismore signiﬁcant compared to other types of augmentations. This ispresumably due to the addition of noise covers the discriminatory char-acteristics of each Nematodes class, as well as the selection of parame-ters from the augmentation process. With the resolution used (224 ×224), the addition of noise is considered ineffective in increasing themodel's accuracy.3.2.6. Optimizer impact on model performanceIt should be noted that in this research, each optimizer betweenmodels uses the same hyperparameters, a learning rate of 0.001 forAdam and RMSprop, and 0.01 for SGD; momentum value of 0 for SGDand RMSprop; a beta value of 0.9 –0.999 for Adam; epsilon value of 1e-07 for Adam and RMSprop; and a rho value of 0.9 for RMSprop. Param-eter value selection is based on the general usage of each optimizer, andsome of them are the default parameter values from the TensorFlow li-brary. Using different parameter values impacts the model's perfor-mance in learning essential features from the dataset. Based on dataobservation, several relations were obtained between the selection ofthe optimizer and the model used.3.2.7. Adam optimizerThe model performances using Adam optimizer resulted in a reason-ably high average accuracy for all models. Adam optimizer is consideredexcellent for achieving satisfactory results without adjusting the opti-mizer parameters to match the model used.3.2.8. SGD optimizerModel performances using SGD optimizer result in varying accuracy.In the CoAtNet model results, the SGD optimizer produces the highestaccuracy compared to other optimizers on the dataset without augmen-tation. However, models with the SGD optimizer signi ﬁcantly decrease accuracy when using augmented datasets, for example, in theResNet101v2 and EfﬁcientNetv2M models. This is presumably becausethe parameters used do not match the augmented data. The decreasein performance when using augmentation data shows that SGD opti-mizer is more sensitive to changes in the dataset. SGD optimizerdemands moreﬁne-tuning on its parameters to achieve high perfor-mance based on the model and dataset used.3.2.9. RMSProp optimizerThe use of the RMSprop optimizer produces different accuracyfor each model. In the ResNet101v2 model, the results obtained areinferior. However, the EfﬁcientNetV2M model obtained satisfactory re-sults and has one of the highest accuracies in the dataset. Observationsshow this is caused by the parameter values used. In the originalEfﬁcientNetV2 study, state-of-the-art performance was achieved usingthe RMSprop optimizer but with different parameters ( Tan and Le, 2021). While training the ResNet101v2 model, its training and valida-tion loss valueﬂuctuated signiﬁcantly. Based on research by (Verma et al., 2021), although with different problems, results of the ResNet50
model using a smaller learning rate value of 0.0001 got better accuracythan using a learning rate value of 0.0004. This indicates that the learn-ing rate value used is too high for this model, as in research,ResNet101v2 is trained using a learning rate value of 0.001.Based on research by (Choi et al., 2019), general optimizers like Adam should not produce worse results than specialized optimizerslike SGD and other optimizer variations. Adam optimizer and otheradaptive gradient methods have performance comparable to SGD ormomentum with proper parameter settings ( Choi et al., 2019). TheTable 5Results obtained from EfﬁcientNetV2M Model.Optimizer Dataaugment% TestaccuracyMeanclassaccuracyF1scoreAverageprecisionAveragerecallAdam Normal 92.78% 0.9397 0.9289 0.9351 0.9278Flip 82.47% 0.712 0.8175 0.8164 0.8247Brightness 91.75% 0.9247 0.9222 0.932 0.9175Contrast 88.66% 0.8012 0.8852 0.9008 0.8866Gaussian Blur 91.75% 0.8867 0.9143 0.9249 0.9175Gaussian Noise 92.78% 0.9459 0.9275 0.9342 0.9278SGD Normal 89.69% 0.8704 0.8953 0.9049 0.8969Flip 76.29% 0.6979 0.7613 0.7807 0.7629Brightness 69.07% 0.5759 0.6891 0.7164 0.6907Contrast 68.04% 0.5661 0.6713 0.7081 0.6804Gaussian Blur 69.07% 0.622 0.6764 0.7086 0.6907Gaussian Noise 67.01% 0.6278 0.6692 0.7015 0.6701RMSprop Normal 91.75% 0.9178 0.9183 0.9309 0.9175Flip 87.63% 0.875 0.8668 0.8843 0.8763Brightness 97.94% 0.9861 0.9799 0.9826 0.9794Contrast 91.75% 0.9107 0.9159 0.9232 0.9175Gaussian Blur 91.75% 0.9136 0.9168 0.9217 0.9175Gaussian Noise 84.54% 0.8319 0.841 0.8787 0.8454
Fig. 11.Comparison of classiﬁcation layer activation visualization against “Genus Xiphinema”class on Resnet101V2 model without augmentation (left) and with imagereversal augmentation (right).N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
9conclusion obtained from optimizer impact on the model performanceis that it's better to use an optimizer that is easy to use. Besides, param-eterﬁne-tuning which matches the problem to be solved will producethe best performance.3.3. The top 5 modelsAll model performance data are then sorted to determine the bestcombination of the model, optimizer, and augmentation. Rememberthat the model's performance obtained from the test may differ inreal-world applications. Because the amount of data for each class inthe dataset is not balanced, the model with the highest test accuracydoes not always have the highest mean class accuracy. A higher meanclass accuracy value can be interpreted as a better model's capabilityto learn all class features than other models.The top-5 models based on %test accuracy are: Ef ﬁcientNetV2M using RMSProp and brightness augmentation; Ef ﬁcientNetV2B0 usingRMSProp and brightness augmentation; CoAtNet-0 using SGD withoutaugmentation, EfﬁcientNetV2B0 using SGD without augmentation;and EfﬁcientNeTV2B0 using RMSProp without augmentation. The metricperformance for each model is presented in Fig. 12. All models have similar performance in all metrics, except mean class accuracy forEfﬁencientNetV2B0 using RMSProp and brightness augmentation. How-ever, the mean class accuracy is still acceptable as it is higher than 85%.It can be concluded that the simultaneous use of various types ofaugmentation does not always increase the model's performance.Some models achieve high accuracy using augmentation or withoutaugmentation. In this case, augmentation is used more to vary data col-lection conditions, i.e., microscope illumination level, specimen orienta-tion, or blurry photo. However, in the aspect of Nematodes morphology,the augmentation used did not signiﬁcantly increase the variation in themorphological characteristics of each class. These augmentations can-not improve the model's ability to generalize classi ﬁcation problems based on the morphology of each class.
Fig. 12.Metrics comparison from theﬁve-best performing models, ranked based on the accuracy of the test dataset.N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
10In addition, simultaneous image transformations can hide theimportant features studied in a class.3.4. Model Integration in web applicationsTo deploy the web app to be accessible to other people, Herokuapp, a cloud-based platforms was used. Following the result inFig. 12,E fﬁcientNetV2, both B0 and M versions have the highest ac-curacy of 97.94%. Although the models have similar performance,the model size was very distinctive. The Ef ﬁcientNetV2B0 model is around 25 MB in size while EfﬁcientNetV2B0 is 200 MB. To reducethe operational cost, EfﬁcientNetV2B0 was selected for integrationas the web platform. The implementation of the user interfacescreens is presented inFig. 13andFig. 14.T h ec l o u d - b a s e dw e bd e - ployment of the model has resulted in the inference time around5 s for the classiﬁcation of the input image and provides a result ofpest genus. The web-based for automatic identi ﬁcation of plant- parasitic nematodes can be assessed at https://nematode-classiﬁer. herokuapp.com/.Using this proposed approach, plant-parasitic nematodes can beidentiﬁed faster and more reliable. As explained in the previous para-graph, the system only needsﬁve seconds to give the result of identiﬁ- cations with an accuracy reach of up to 97.94%. The system's limitationis that it can only recognize the nematodes in perfect and undamagedconditions, as the dataset only represents those conditions. However,future research will be conducted to meet others' circumstances.4. ConclusionA novel plant-parasitic nematodes image dataset was built for spe-cies of nematodes commonly found in Indonesia. The feasibility ofdeep learning models for plant-parasitic classi ﬁcations, namely
Fig. 13.Home screen of web-based application for automatic identi ﬁcation of plant-parasitic nematodes.
Fig. 14.Sample result of web-based application for automatic identi ﬁcation of plant-parasitic nematodes.N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
11ResNet101V2, CoAtNet-0, EfﬁcientNetV2B0 and EfﬁcientNetV2M were explored. Deep learning techniques in image-based classi ﬁcation are promising and advance the automation of the nematode identi ﬁcation process. This work demonstrated the capability of using deep learningmodels to identify plant-parasitic nematodes commonly found inIndonesian soil. The performance of each of the tested models obtainedsatisfactory results. The exemplary performance for each model resultsfrom combining several optimizer functions (Adam, SGD, andRSMProp) and the augmentation process (Flip, Brightness, Contrast,Gaussian Blur, and Gaussian Noise). Based on the selected model vari-ants (ResNet101v2, CoAtNet0, EfﬁcientNetV2B0, and EfﬁcientNetV2M), the EfﬁcientNetV2B0 and EfﬁcientNetV2M models achieved the bestperformance on the dataset used, with the highest accuracy of 97.94%.Both of the best models were implemented using RMSProp optimizerand brightness augmentation. Theﬁnal contribution provides an inte-grated deep learning model as a web-based application thatIndonesia's prospective agriculturists can use directly. Further work isstill needed to improve model accuracy and reliability. Future workwill focus on the following:•Further development of the nematodes dataset to cope with unperfectconditions of nematode images and expand to non-parasitic nematodes •Investigate other deep learning models to improve the performance ofmulti-class nematodes identiﬁcationCRediT authorship contribution statementNabila Husna Shabrina:Conceptualization, Methodology, Formalanalysis, Visualization, Writing –original draft, Project administration,Funding acquisition.Ryukin Aranta Lika:Software, Investigation, Data curation, Writing–original draft.Siwi Indarti:Resources, Valida- tion, Writing–original draft.Declaration of competing interestThe authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared toinﬂuence the work reported in this paper.AcknowledgmentsWe would like to thank Rina Maharani, S.P., M.Sc who help us to col-lect and prepare nematodes dataset. We would also like to acknowledgethe support given by Universitas Multimedia Nusantara during this study.References
Abad, P., Gouzy, J., Aury, J.-M., Castagnone-Sereno, P., Danchin, E.G.J., Deleury, E., Perfus-Barbeoch, L., Anthouard, V., Artiguenave, F., Blok, V.C., Caillaud, M.-C., Coutinho,P.M., Dasilva, C., de Luca, F., Deau, F., Esquibet, M., Flutre, T., Goldstone, J.V.,Hamamouch, N., Hewezi, T., Jaillon, O., Jubin, C., Leonetti, P., Magliano, M., Maier,T.R., Markov, G.V., McVeigh, P., Pesole, G., Poulain, J., Robinson-Rechavi, M., Sallet,E., Ségurens, B., Steinbach, D., Tytgat, T., Ugarte, E., van Ghelder, C., Veronico, P.,Baum, T.J., Blaxter, M., Bleve-Zacheo, T., Davis, E.L., Ewbank, J.J., Favery, B., Grenier,E., Henrissat, B., Jones, J.T., Laudet, V., Maule, A.G., Quesneville, H., Rosso, M.-N.,Schiex, T., Smant, G., Weissenbach, J., Wincker, P., 2008. Genome sequence of themetazoan plant-parasitic nematode Meloidogyne incognita. Nat. Biotechnol. 26,909–915.https://doi.org/10.1038/nbt.1482 . Abade, A., Porto, L.F., Ferreira, P.A., de Barros Vidal, F., 2022. NemaNet: a convolutionalneural network model for identi ﬁcation of soybean nematodes. Biosyst. Eng. 213, 39–62.https://doi.org/10.1016/j.biosystemseng.2021.11.016 . Ajri, M., Indarti, S., Soffan, A., Huu, N.N., 2021. Morphological and phylogenetic character-istics of ditylenchus dipsaci among garlic plants. Jordan J. Biol. Sci. 14, 769 –773. https://doi.org/10.54319/jjbs/140418 . Alsaggaf, W., Cömert, Z., Nour, M., Polat, K., Brdesee, H., To ğaçar, M., 2020. Predicting fetal hypoxia using common spatial pattern and machine learning from cardiotocographysignals. Appl. Acoust. 167, 107429. https://doi.org/10.1016/j.apacoust.2020.107429 . Choi, D., Shallue, C.J., Nado, Z., Lee, J., Maddison, C.J., Dahl, G.E., 2019. On Empirical Compar-isons of Optimizers for Deep Learning. https://doi.org/10.48550/arXiv.1910.05446 . Chollet, F., 2015. Keras: Deep Learning for Humans [WWW Document]. URL https:// github.com/keras-team/keras (accessed 2.1.22).Dai, Z., Liu, H., Le, Q.V., Tan, M., 2021. CoAtNet: Marrying Convolution and Attention for AllData Sizes.https://doi.org/10.48550/arXiv.2106.04803 . De, W.D., Elsen, A., 2007. Challenges in tropical plant nematology. Annu. Rev. Phytopathol.45, 457–485.https://doi.org/10.1146/annurev.phyto.45.062806.094438 . Diker, A., Comert, Z., Avci, E., Togacar, M., Ergen, B., 2019. A novel application based onspectrogram and convolutional neural network for ECG classi ﬁcation. 2019 1st Inter- national Informatics and Software Engineering Conference (UBMYK). IEEE, pp. 1 –6 https://doi.org/10.1109/UBMYK48245.2019.8965506 . Elsken, T., Metzen, J.H., Hutter, F., 2019. Neural architecture search: a survey. J. Mach.Learn. Res. 20, 1997–2017.https://doi.org/10.48550/arXiv.1808.05377 . He, K., Zhang, X., Ren, S., Sun, J., 2016a. Deep residual learning for image recognition. IEEEConference on Computer Vision and Pattern Recognition (CVPR). IEEE, pp. 770 –778 https://doi.org/10.1109/CVPR.2016.90 . He, K., Zhang, X., Ren, S., Sun, J., 2016b. Identity mappings in deep residual networks.Computer Vision–ECCV 2016. Springer International Publishing, pp. 630 –645 https://doi.org/10.1007/978-3-319-46493-0_38 . Indarti, S., Bambang, R.T.P., Mulyadi B., Triman, 2004. First record of potato cyst nematodeglobodera rostochiensis in Indonesia. Australas. Plant Pathol. 33, 325. https://doi.org/ 10.1071/AP04018.Indarti, S., Wibowo, A., Subandiyah, S., Ajri, M., 2018. First record: a stem and bulb plantparasitic nematode at garlic area Centre temanggung, central java, Indonesia withspecies reference to ditylenchus dipsaci. Jurnal Perlindungan Tanaman Indonesia22, 233.https://doi.org/10.22146/jpti.35321 . Jiang, P., Chen, Y., Liu, B., He, D., Liang, C., 2019. Real-time detection of apple leaf diseasesusing deep learning approach based on improved convolutional neural networks.IEEE Access 7, 59069–59080.https://doi.org/10.1109/ACCESS.2019.2914929 . Jones, J.T., Haegeman, A., Danchin, E.G.J., Gaur, H.S., Helder, J., Jones, M.G.K., Kikuchi, T.,Manzanilla-López, R., Palomares-Rius, J.E., Wesemael, W.M.L., Perry, R.N., 2013. Top10 plant-parasitic nematodes in molecular plant pathology. Mol. Plant Pathol. 14,946–961.https://doi.org/10.1111/mpp.12057 . Keras, 2021. Keras Applications [WWW Document]. URL https://keras.io/api/applications/ (accessed 2.1.22).Kingma, D.P., Ba, J., 2014. Adam: A Method for Stochastic Optimization. https://doi.org/ 10.48550/arXiv.1412.6980. Kusrini, K., Suputa, S., Setyanto, A., Agastya, I.M.A., Priantoro, H., Chandramouli, K.,Izquierdo, E., 2020. Data augmentation for automated pest classi ﬁcation in mango farms. Comput. Electron. Agric. 179, 105842. https://doi.org/10.1016/j.compag.2020. 105842.Li, L., Zhang, S., Wang, B., 2021. Plant disease detection and classi ﬁcation by deep learning —a review. IEEE Access 9, 56683 –56698.https://doi.org/10.1109/ACCESS.2021. 3069646.Lu, X., Wang, Y., Fung, S., Qing, X., 2021. I-nema: A Biological Image Dataset for NematodeRecognition.https://doi.org/10.48550/arXiv.2103.08335 . Mutala’liah, M., Indarti, S., Wibowo, A., 2018. Short communication: the prevalence andspecies of root-knot nematode which infect on potato seed in central java,Indonesia. Biodivers. J. 20, 11 –16.https://doi.org/10.13057/biodiv/d200102 . Paymode, A.S., Malode, V.B., 2022. Transfer learning for multi-crop leaf disease imageclassiﬁcation using convolutional neural network vgg. Artif. Intell. Agric. 6, 23 –33. https://doi.org/10.1016/j.aiia.2021.12.002 . Raouhi, E.M., Lachgar, M., Hrimech, H., Kartit, A., 2022. Optimization techniques in deepconvolutional neuronal networks applied to olive diseases classi ﬁcation. Artif. Intell. Agric. 6, 77–89.https://doi.org/10.1016/j.aiia.2022.06.001 . Shijie, J., Ping, W., Peiyi, J., Siping, H., 2017. Research on data augmentation for image clas-siﬁcation based on convolution neural networks. 2017 Chinese Automation Congress(CAC). IEEE, pp. 4165–4170https://doi.org/10.1109/CAC.2017.8243510 . Shorten, C., Khoshgoftaar, T.M., 2019. A survey on image data augmentation for deeplearning. J. Big Data 6, 60.https://doi.org/10.1186/s40537-019-0197-0 . Southey, J., 1986.Laboratory Methods for Work with Plant and Soil Nematodes. HerMajesty’sS t a t i o n a r yO fﬁce, London.Stojnic, R., Taylor, R., Kardas, M., Elvis Cucurull, G., 2022. Image Classi ﬁcation on Imagenet [WWW Document]. URLhttps://paperswithcode.com/sota/image-classi ﬁcation-on- imagenet(accessed 2.1.22).Sun, S., Cao, Z., Zhu, H., Zhao, J., 2020. A survey of optimization methods from a machinelearning perspective. IEEE Trans. Cybern. 50, 3668 –3681.https://doi.org/10.1109/ TCYB.2019.2950779.Tan, M., Le, Q.V., 2019. Efﬁcientnet: Rethinking Model Scaling for Convolutional NeuralNetworks.https://doi.org/10.48550/arXiv.1905.11946
. Tan, M., Le, Q.V., 2021. Efﬁcientnetv2: Smaller Models and Faster Training. https://doi. org/10.48550/arXiv.2104.00298 . Toğaçar, M., Ergen, B., Cömert, Z., 2021. Tumor type detection in brain mr images of thedeep model developed using hypercolumn technique, attention modules, and resid-ual blocks. Med. Biol. Eng. Comput. 59, 57 –70.https://doi.org/10.1007/s11517-020- 02290-x.Uhlemann, J., Cawley, O., Kakouli-Duarte, T., 2020. Nematode identi ﬁcation using artiﬁcial neural networks. International Conference on Deep Learning Theory and Applica-tions. SCITEPRESS - Science and Technology Publications, pp. 13 –22https://doi.org/ 10.5220/0009776600130022. Verma, P., Tripathi, V., Pant, B., 2021. Comparison of different optimizers implemented onthe deep learning architectures for COVID-19 classi ﬁcation. Mater.Today: Proc. 46, 11098–11102.https://doi.org/10.1016/j.matpr.2021.02.244 . Zhou, P., Feng, J., Ma, C., Xiong, C., Hoi, S., E. W, 2020. Towards Theoretically Understand-ing Why SGD Generalizes better than Adam in Deep Learning. https://doi.org/10. 48550/arXiv.2010.05627.N.H. Shabrina, R.A. Lika and S. Indarti Artiﬁcial Intelligence in Agriculture 7 (2023) 1 –12
12