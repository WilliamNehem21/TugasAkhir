Identiﬁcation of maize (Zea maysL.) progeny genotypes based on twoprobabilistic approaches: Logistic regression and naïve Bayes
D. Sekaa,⁎, B.S. Bonnya, A.N. Yobouéb,S . R .S i éa, B.A. Adopo-Gourènea
aSchool of Natural Sciences, UFR-SN, University Nangui Abrogoua, 02 B.P. 801, Abidjan 02, Cote d'Ivoire
bSchool of Environmental Sciences, Jean Lorougnon Guédé University, B.P. 150, Daloa, Cote d'Ivoire
abstract article info
Article history:Received 11 November 2018Received in revised form 12 March 2019Accepted 12 March 2019Available online 21 March 2019We used two probabilistic methods, Gaussian Naïve Bayes and Logistic Regression to predict the genotypes of theoffspring of two maize strains, the BLC and the JNE genotypes, based on the phenotypic traits of the parents. Wedetermined the prediction performance of the two models with the overall accuracy and the area under the re-ceiver operating curve (AUC). The overall accuracy for both models ranged between 82% and 87%. The values ofthe area under the receiver operating curve were 0.90 or higher for Logistic Regression models, and 0.85 or higherfor Gaussian Naïve Bayes models. These statistics indicated that the two models were very effective in predictingthe genotypes of the offspring. Furthermore, both models predicted the BLC genotype with higher accuracy thanthey did the JNE genotype. The BLC genotype appeared more homogeneous and more predictable. A Chi-squaretest for the homogeneity of the confusion matrices showed that in all cases the two models produced similar pre-diction results. Thatﬁnding was in line with the assertion by Mitchell (2010) who theoretically showed that thetwo models are essentially the same. With logistic regression, each subset of the original data or its correspondingprincipal components produced exactly the same prediction results. The AUC value may be viewed as a criterionfor parent-offspring resemblance for each set of phenotypic traits considered in the analysis.© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an openaccess article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
Keywords:Gaussian naïve BayesLogistic regressionMaize genotypePredictionSelection
1. IntroductionThe development of the learning algorithms and theirimplementations have brought new ways to process data, to extract in-formation from data, and to formulate a basis for decision. The applica-tion of these learning algorithms spans to all ﬁelds of human activities. The literature on the development and the use of these algorithmsabounds.Hastie et al. (2001), andWebb (2002)provide a good over- view of these algorithms.Sambo et al. (2012)developed an algorithm for genetic biomarker selection and subjects' classi ﬁcation from the analysis of genome-wide SNP data. They found a signi ﬁcantly higher classiﬁcation accuracy with their algorithm in the identi ﬁcation of bio- markers for Type 1 diabetes.Douglass et al. (2016)used Naïve Bayes classiﬁer with small RNA deep-sequencing data and genomic featuresto identify plant miRNAs in soybean, peach, rice and Arabidopsis. Theyfound the classiﬁer for all four plants to be highly accurate in the iden-tiﬁcation of miRNA. They based the performance of the classi ﬁer on the values of the area under the curve of the receiver operating charac-teristic (ROC) curve. They reported AUC values between 0.9771 and0.9980, with the identiﬁcation of Arabidopsis miRNAs having thehighest value. These learning algorithms have extensively been usedin the classiﬁcation of plant organisms as well. In most cases, the identi-ﬁcation of plants was based on leaf attributes because the shape, thecolor and the texture of a leaf are speci ﬁc to the plant species (El- Hariri et al., 2014)a n du n l i k eﬂowers and fruits, the plant always carriesfunctional leaves throughout its existence ( Siravenha and Carvalho, 2015).Wu et al. (2007)developed an algorithm that uses probabilisticneural network with image and data processing techniques for an auto-mated leaf recognition and plant classiﬁcation. Its application resulted in the classiﬁcation of 32 different plants based on leaf features, withan accuracy greater than 90%. They found their algorithm to be fast inexecution, easy to implement, and efﬁcient in plant recognition and classiﬁcation.Hemming and Rath (2001)constructed an identiﬁcation system that distinguished weeds from two major crops, cabbage andcarrots. In their experiment, they initially used eight morphological fea-tures along with three color features, then conducted feature selectionto determine the most relevant features for discriminating betweenweed species and crops. They found that color features helped to in-crease the classiﬁcation accuracy. They reported that between 51% and95% of the plants were correctly classiﬁed. The mean classiﬁcation accu- racy was 88.15% for cabbage and 72.46% for carrots. Giselsson et al. (2013)constructed a data set representing shape features by using dis-
tance data from images of seedling of Centaurea cyanusandSolanum nigrum.T h e yﬁtted the distance data to a high degree Legendre polyno-mial and used the coefﬁcients of the polynomial which they calledArtiﬁcial Intelligence in Agriculture 1 (2019) 9 –13
⁎Corresponding author.E-mail address:seka.d@iugb.edu.ci(D. Seka).
https://doi.org/10.1016/j.aiia.2019.03.0012589-7217/© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the C C BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/ ).
Contents lists available atScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage:http://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/Legendre polynomial feature set. They collected another set of data andnamed it standard feature set. With the two set of data, they ran fourclassiﬁcation algorithms. They reported that the Legendre polynomialfeature set was very robust and its use with the classi ﬁcation algorithms resulted in an accuracy of 98.75% compared with the standard featureset which yielded an accuracy of 87.1%. However, they suggestedmore testing of this attribute data collection method in order to evaluateits true value.Siravenha and Carvalho (2015)explored a method of data collection on leaf features that involved the contour-centroid distanceand data transformation with the Fast Fourier Transform. They appliedfeature-selection techniques for dimensionality reduction and im-proved classiﬁcation accuracy. They then used various classi ﬁcation al- gorithms for plant identiﬁcation. They reported classiﬁcation accuracies ranging from 65.14% obtained with the C4.5 algorithm to97.45% resulting from the Pattern Net algorithm applied to principalcomponents. The learning algorithms combined with other statisticalmethods have signiﬁcantly contributed in the advancement of pheno-typic predictions of quantitative traits of sequenced whole genome.Guzzetta et al. (2010)explained a learning pipeline that use the L1L2regularization method based on the naive elastic net for the predictionof phenotypes. They found it to be very effective regarding the accuracyof phenotype prediction.Zhao et al. (2016)used machine learning methods to identify root traits that led to the differentiation of cultivarsin a binomial setting. AndLippert et al. (2017)developed models for the prediction of phenotypic traits. They combined those models in a singlemachine learning model for genome re-identi ﬁcation from the pheno- typic prediction. In all the studies, different learning methods havebeen used and in each case the performance of the method has provento be very satisfactory to excellent in prediction or in classi ﬁcation.Kell et al. (2001)mentioned that all machine learning methods have theirstrength and weaknesses and no single method works best for allsituations.Given the acclaimed high performance of these algorithms in theidentiﬁcation and classiﬁcation of the subjects under studies, we con-ducted this study to predict plant genotypes based on parents' pheno-typic traits. This study also provides a numerical proof of the elegantdemonstration byMitchell (2010)who showed that naïve Bayes withcontinuous features and logistic regression are essentially the same,even though one is generative and the other is discriminative ( Ng and Jordan, 2001).2. Materials and methodsWe used two maize (Zea maysL.) strains, BLC and JNE, in this study.The two strains were different by the color of their kernels. Kernels fromBLC were translucent giving the appearance of white kernels. Kernelsfrom JNE were yellow. In this study, the BLC strain underwent three cy-cles of selection for longer and wider leaves, a larger number of leavesand taller plants while the JNE strain was subjected to random selectionafter each cycle. Seed from selected plants of each strain were obtainedby pollination with a bulk of pollen from several male in ﬂorescences of the same strain. The controlled pollination was insured by the protec-tion of ear shoot with paper bag soon after it emerged.In spring 2017, seed from the third generation (parents in this study)and the fourth generation (offspring) of the two genotypes wereplanted in a completely randomized experiment with two factors (gen-eration and strain) at the experimental station of University NanguiAbrogoua, Abidjan, Cote d'Ivoire. We added fertilizer to the soil. Each ex-perimental unit consisted of a row 4 m long of either one of the twostrains. Rows were separated by 0.75 m. The plots were overseeded,and three weeks after planting, were thinned to 42,000 plants ha
−1. At silking, the day when about 50% of the plants in a plot developedsilks, we determined the number of leaves (ln) by counting nodes, wemeasured ear leaf length (ll) and maximum ear leaf width (lw) as sug- gested byCross (1991). We measured plant height (ht) as the length of the plant from the base at the soil level to the tip of the maleinﬂorescence. We determined the rate of grain ﬁlling (gf) as the linear coefﬁcient from the orthogonal contrast ( Carlone and Russell, 1987) on the sequential sampling of kernel dry weight during the linearphase of the grainﬁlling period.In predicting the genotypes of the offspring, we used two classi ﬁca- tion methods: the Gaussian naïve Bayes and the logistic regression. Weused the naïve Bayes algorithm to determine the posterior probability ofan individual progeny to be a descendant of either the BLC or the JNEstrain given its attribute values of plant height, leaf number, leafwidth, number of leaves and rate of grain ﬁlling. The probabilistic model is simpliﬁed as follows:PrClassjA1;A2;…;A 5 ðÞ ¼PrClassðÞ /C3Y5i¼1PrA ijClassðÞwhereClassis the class label with outcomes BLC or JNE, and A
iis the at- tribute. The model computes the posterior probability of a progeny,with respect to its lineage, as the product of the prior probability ofthe class label and the conditional probabilities of the attributes with re-spect to that class label. The application of this model in the predictionor the classiﬁcation of subjects in a population is said to be discrimina-tive as opposed to logistic regression that is generative ( Ng and Jordan, 2001).The measures on the parents of BLC and JNE genotypes were alsoused toﬁt a logistic regression model (McCullagh and Nelder, 1989) and to determine the parameters of the model in order to computethe posterior probabilities of the progeny to belong to the JNE or theBLC genotypes.PrClassjA
1;A2;…;A 5 ðÞThe parametric model assumed by logistic regression in the casewhere the class variable was binomial is given as follows ( Mitchell, 2010):PrClass¼
}BLC}/C12/C12/C12A
1;A2;A3;A5/C16/C17¼ 11þexpb
0þ∑5i¼1biAi/C16/C17andPrClass¼
}JNE}/C12/C12A
1;A2;…;A 5/C16/C17¼ expb 0þ∑5i¼1biAi/C16/C171þexpb
0þ∑5i¼1biAi/C16/C17:Mitchell (2010)showed that the parametric form of Pr( Class| A
1,A2,…A 5) used by logistic regression is precisely the form implied bythe assumptions of a Gaussian naïve Bayes classi ﬁer, and in most cases both methods produce similar results. However, it should be notedthat logistic regression directly estimates the parameters of Pr( Class| A
1,A2,…A 5), whereas Gaussian naïve Bayes directly estimates parame-ters of Pr(Class)a n dP r (A
1,A2,…A 5|Class)(Ng and Jordan, 2001). To test the assertion byMitchell (2010)that Gaussian naïve Bayes and logistic regression produce the same results, we created severalsubsets and their principal components from the original data by itera-tively removing attributes. We then predicted the progeny with each ofthe two models based on the retained attributes or the correspondingprincipal components of each subset. The principal components are anorthogonal transformation of the original observations that inherit thetotal variability. Their use should remove any bias associated with theassumption of independence between attributes in comparison to theuse of the original variables and should serve to assess any such biasin the prediction results. We performed an importance ranking ( Kuhn et al., 2017) of the traits with respect to their ability to discriminate be-tween the two classes. We computed statistics such as accuracy, sensi-tivity, speciﬁcity (Tze-Wey, 2003) and the maximum value of the areaunder the receiver operating characteristic curve ( Bradley, 1997) for10 D. Seka et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 9 –13each model. We assessed the performance of each model with the accu-racy and the AUC value. In running the two models, the BLC genotypewas considered the positive class. We used the statistical software R(R Core Team, 2017) for all the analyses.3. Results and discussionThe variable importance ranking technique ( Kuhn et al., 2017)i d e n - tiﬁedlw,gfandhtas the most important traits among the attributes ofthe data set in their ability to discriminate between the two genotypes.Their importance values were, respectively, 0.85, 0.82 and 0.72 on a1-point scale. Thatﬁnding was corroborated by the analysis of the logis-tic regression model that showed lw(p-value= 0.03888),gf(p-value= 0.04667), andht(p-value= 0.04942) as the most signiﬁcant predictor variables in the data set.Table 1shows the means and standard devia-tions of the 5 attributes. The trait ln showed little variability across gen-erations and genotypes. It was also ranked last in its ability todifferentiate the two genotypes with an importance value of 0.56.We predicted the progeny of the two parents using different subsetsof the original data and their principal components. We reported theperformances of the two models on those subsets in Table 2.C o m p a r i - son of the confusion matrices generated from the models on each subsetwas done with a Chi-square test (Agresti, 2007;Hope, 1968). The test of homogeneity of the confusion matrices produced p-values that ranged from 0.7692 to 1.000, proving the close similarity of the prediction per-formances of the two models. Gaussian naïve Bayes updates priorknowledge from the parents with current evidence of the offspring tocompute the conditional probability that an offspring belongs to a geno-type. And, logistic regression estimates the parameters of the modelwith the parents' phenotypic values to compute the same conditionalprobabilities. However,Mitchell (2010)gave an elaborate and elegant demonstration that under some conditions of binary response variable(Y)w i t hp a r a m e t e rπ=P r(Y=
"positive class"), Gaussian distributed attributes (A
i) that are conditionally independent with respect to Y,P r (A
i|Y=y k)∼N(μ ik,σi), the conditional probabilities under the Gaussiannaïve Bayes model can be written in parametric forms asPrClass¼
}BLC}/C12/C12/C12A
1;A2;…A 5/C16/C17¼ 11þexpw
0þ∑5i¼1wiAi/C16/C17andPrClass¼
}JNE}/C12/C12A
1;A2;…A 5/C16/C17¼ expw 0þ∑5i¼1wiAi/C16/C171þexpw
0þ∑5i¼1wiAi/C16/C17wherew
i¼μi0−μi1
σ2iandw
0¼Ln1−ππþX
iμ2i1−μ2i0
2σ2i:These probabilities are exactly the same given by logistic regressionwhen the response variable has binary outcomes and the predictor var-iables are Gaussian distributed. The results of this experiment provide anumerical evidence of that demonstration produced by Mitchell (2010), and simulation studies byBhowmik (2015).W es h o u l dm e n t i o nt h a tl o - gistic regression directly estimates the parameters for Pr( Class|A
i), and Gaussian naïve Bayes directly estimates the parameters for Pr( Class) and Pr(A
i|Class)(Ng and Jordan, 2001).Table 2shows that the logistic regression gave exactly the same pre-diction results whether we used subsets of the original data or their cor-responding principal components. This observation ﬁnds its explanation in the fact that the right hand-side of the logistic equationwith the original data is exactly the same as the right hand-side of thelogistic equation with the principal components,
11þexp^β
tobsA/C16/C17¼11þexp^β
tpcZ/C16/C17which leads to^β
tobsA¼^βtpcZwhere^β
tobsis the vector of estimated regression coef ﬁcients from the original data, A is the matrix formed with the subset of the original var-iables,^β
tpcsis the vector of estimated regression coef ﬁcients from the principal components, and Z is the matrix of principal components de-rived from the subset of the original data.Therefore,PrClass¼
}BLC}/C12/C12/C12A;β
obs/C16/C17¼PrClass¼}BLC}/C12/C12/C12Z;β
pc/C16/C17andPrClass¼
}JNE}/C12/C12A;β
obs/C16/C17¼PrClass¼}JNE}/C12/C12Z;β
pc/C16/C17 :With Gaussian naïve Bayes, the confusion matrices obtained fromthe subsets of the original data and their corresponding principal com-ponents were not always exactly the same. But the differences werenot signiﬁcant (p-values≥0.8227).The two models yielded very good prediction performances. Theoverall prediction accuracy ranged from 82% to 87% for all data tested(Table 2). The values of the area under the curve were between 0.85and 0.93. In general, both model predicted the BLC genotypes withhigher accuracy than they predicted the JNE genotypes. The relativelylow speciﬁcity and high sensitivity observed with the two models maybe linked to the structures of the BLC and JNE populations and howthey were developed. The BLC population was developed with a selec-tion procedure directed to wider and longer leaves, a larger number ofleaves and taller plants. Three cycles of selection may have contributedto the partial accomplishment of that goal. Except for the trait ln, moreindividuals of the BLC genotypes have developed the distinctive traitsdeﬁned by the selection criteria and have progressively formed agroup that was more homogenous and that was better predicted bythe models.Kudaravalli et al. (2009),Bersaglieri et al. (2004),Enattah et al. (2005),a n dTishkoff et al. (2007)reported corroborating evidence of the effect of selection on a trait. They proved that natural or arti ﬁcial selection affected the expression of the gene(s) that translated into amodiﬁed phenotype. AndWang et al. (2018)found that the maize leaf width is controlled by dominant genes not linked with gene
Table 1Mean and standard deviation of lw,ll,l n ,htandgfof the parents and the offspring.Trait Parent OffspringBLC JNE BLC JNElw(cm) 9.66 (0.61) 8.34 (1.18) 9.47 (0.67) 8.93 (0.82)ll(cm) 89.30 (6.47) 84.34 (7.36) 89.90 (5.23) 85.16 (5.86)ln(cm) 12.43 (1.61) 12.13 (1.11) 12.73 (1.05) 12.20 (1.19)ht(cm) 235.87 (23.59) 216.57 (24.32) 231.50 (21.12) 218.40 (21.12)gf(mg·d
−1) 5.41 (0.32) 4.98 (0.34) 5.49 (0.30) 5.10 (0.40)11 D. Seka et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 9 –13(s) controlling maize leaf length. That assertion implies that the maizeleaf width could be modiﬁed through selection without any direct effecton other traits of the canopy. The results of this study support that asser-tion. In this study, the comparative increase in maize leaf width andplant height of the BLC genotype could be attributed to the direct effectof selection for wider leaves and taller plants. As a result, the two traitsbecame the two most important discriminating traits between the twopopulations. The higher grainﬁlling rate observed with the BLC geno-types compared with the JNE genotypes may be attributed to an indirectselection for size of canopy. In the other hand, the JNE genotypes wererandomly selected. The measured traits consequently had larger vari-ability, and the individuals of the JNE genotypes were relatively less ho-mogeneous. The relatively larger dispersion that characterized the JNEstrains resulted in the reduced speciﬁcity of the models. Many individ- uals of the JNE strains had traits similar to the traits that characterizedmost of the BLC genotypes and the models identi ﬁed them as belonging to the class of the BLC genotype. However, the majority of the individ-uals of the JNE genotype conserved their traits and the models correctlypredicted those individuals.4. Summary and conclusionWe usedﬁeld data to predict progeny genotype of two maize strainsusing logistic regression and Gaussian naïve Bayes. The overall predic-tion accuracy ranged from 78% to 87% and the values of the areaunder the receiver operating characteristic curve were between 0.85and 0.93. Sensitivity, deﬁned as the correct identiﬁcation of the BLC ge- notype was high with a modal value of 0.90 for both Gaussian naïveBayes and logistic regression. On the other hand, speci ﬁcity which is the correct identiﬁcation of the JNE genotype had a modal value of0.73 for both Gaussian naïve Bayes and logistic regression. The observedhigher sensitivity and lower speciﬁcity of the two tests were due to thestructures of the two populations more than the quality of the tests. TheBLC population was more homogeneous and much easily identi ﬁable compared to the JNE population which was more diverse and a highproportion of its progeny was misclassiﬁed as BLC genotypes. The tests of prediction of offspring's genotypes was more a test ofparent-offspring resemblance. The models trained with parents' pheno-typic values and identiﬁed progenies having similar traits. With a singlepredictor variable or attribute, the area under the receiver operatingcharacteristic curve from such tests may be a good predictor ofheritability.Wray et al. (2010)formulated an equation that relatedmaximum area under the receiver operating characteristic curve to her-itability and the prevalence of the trait. And Dreyfuss et al. (2012)men- tioned that the accuracy of a test was a direct re ﬂect of the heritability of the trait being considered in that test. They added that a phenotypictrait with high heritability would be predicted with high accuracywhereas a trait with low and non-signiﬁcant heritability would not re- sult in a high prediction accuracy. Such trait was less in ﬂuenced by ge- netic factors and more by environmental factors. In this study, severalphenotypic traits were considered in the determination of offspring'sgenotype. We could not infer that the AUC value was a good estimatorof heritability. Instead, we may view the AUC value in this study as agood indicator, or criterion, of parent-offspring resemblance. And thehigher the AUC value, the greater the resemblance between parentsand offspring.We used several subsets of the data and their corresponding princi-pal components to conduct the genotype-prediction tests. For each dataset, the Chi-square test comparing the prediction results of the logisticregression and Gaussian naïve Bayes showed that the two models pro-duced similar prediction performances. The results of our ﬁeld study were consistent with theﬁnding byMitchell (2010)and the work by
Bhowmik (2015). With logistic regression, the use of the subset of thedata or its corresponding principal components gave exactly the sameprediction results. The principal components retained the total variabil-ity of the data and the product of the data matrix with the vector of es-timated regression coefﬁcients from a subset was the same as theproduct of the matrix of principal components with the vector of esti-mated coefﬁcients from the principal components. With Gaussiannaïve Bayes, the prediction results with a subset of the data or its corre-sponding principal components were not always exactly the same. Butwhere there is a difference, the difference was not signi ﬁcant.Conﬂict of interestOn behalf of all authors, the corresponding author states that there isno conﬂict of interest.References
Agresti, A., 2007.An Introduction to Categorical Data Analysis. 2nd ed. John Wiley & Sons,New York, p. 38.Table 2Prediction characteristics of the logistic regression (LR) and the Gaussian naïve Bayes (GNB) models with subsets of the original data and their prin cipal components.Data Attribute Model Confusion Matrix AUC Accuracy Chi-square ( p-value)TP FN TN FPOriginal data (a) lw+ll+l n+ht+gfLR 26 4 23 7 0.90 0.82 0.9674GNB 27 3 24 6 0.90 0.85 (b)lw+gf+ht+llLR 27 3 22 8 0.93 0.82 1.000GNB 27 3 22 8 0.91 0.82 (c)lw+gf+ht LR 27 3 22 8 0.93 0.82 0.9931GNB 27 3 23 7 0.90 0.83 (d)gf+ht LR 26 4 26 4 0.93 0.87 0.8868GNB 24 6 27 3 0.92 0.85 (e)lw+gf LR 27 3 23 7 0.91 0.83 0.9835GNB 26 4 23 7 0.89 0.82 Principal component pc
1+p c 2+p c 3+p c 4+p c 5from (a) LR 26 4 23 7 0.90 0.82 0.9931GNB 26 4 22 8 0.85 0.80 pc
1+p c 2+p c 3+p c 4from (b) LR 27 3 22 8 0.93 0.82 0.8227GNB 28 2 19 11 0.86 0.78 pc
1+p c 2+p c 3from (c) LR 27 3 22 8 0.93 0.82 1.000GNB 27 3 22 8 0.90 0.82 pc
1+p c 2from (d) LR 26 4 26 4 0.93 0.87 0.7692 GNB 23 7 25 5 0.90 0.80 pc
1+p c 2from (e) LR 27 3 23 7 0.91 0.83 0.9690 GNB 26 4 22 8 0.90 0.80TP = true positive; FN = false negative; TN = true negative; and FP = false negative.Note: pc
i(i=1 ,2 ,…, 5) are the principal components.12 D. Seka et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 9 –13Bersaglieri, T., Sabeti, P.C., Patterson, N., Vanderploeg, T., Schaffner, S.F., Drake, J.A., Rhodes,M., Reich, D.E., Hirschhorn, J.N., 2004. Genetic signatures of strong recent positive se- lection at the lactase gene. Am. J. Hum. Genet. 74, 1111 –1120. Bhowmik, T.K., 2015.Naive Bayes vs logistic regression: theory, implementation and ex-perimental validation. Intell. Artif. 18 (56), 14 –30. Bradley, A.P., 1997.The use of the area under the ROC curve in the evaluation of machinelearning algorithms. Pattern Recognit. 30, 1145 –1159. Carlone, M.R., Russell, W.A., 1987. Response to plant densities and nitrogen levels for fourmaize cultivars from different eras of breeding. Crop Sci. 27, 465 –470. Cross, H.Z., 1991.Leaf expansion rate effects on yield and yield components in early-maturing maize. Crop Sci. 31, 579–583. Douglass, S., Hsu, S.W., Cokus, S., Goldberg, R.B., Harada, J.J., Pellegrini, M., 2016. An a ï v e Bayesian classiﬁer for identifying plant microRNAs. Plant J. 86 (6), 481 –492. Dreyfuss, J.M., Levner, D., Galagan, J.E., George, M., Church, G.M., Ramoni, M.F., 2012. How accurate can genetic predictions be? BMC Genom. 13, 340.El-hariri, E., El-Bendary, N., Hassanien, A.E., 2014. Plant classi ﬁcation system based on leaf features. Proceedings of 2014 9th IEEE International Conference on Computer Engi-neering and Systems. ICCES 2014 https://doi.org/10.1109/ICCES.2014.7030971 . Enattah, N., Pekkarinen, T., Välimäki, M.J., Löyttyniemi, E., Järvelä, I., 2005. Genetically de- ﬁned adult-type hypolactasia and self-reported lactose intolerance as risk factors ofosteoporosis in Finnish postmenopausal women. Eur. J. Clin. Nutr. 59, 1105 –1111. Giselsson, T.M., Midtiby, H.S., Jørgensen, R.N., 2013. Seedling discrimination with shape features derived from a distance transform. Sensors 13, 5585 –5602. Guzzetta, G., Jurman, G., Furlanello, C., 2010. A machine learning pipeline for quantitative phenotype prediction from genotype data. BMC Bioinforma. 11 (Suppl. 8), S3.Hastie, T., Tibshirani, R., Friedman, J., 2001. The Elements of Statistical Learning. Springer, New York.Hemming, J., Rath, T., 2001.Computer-vision-based weed identi ﬁcation underﬁeld con- ditions using controlled lighting. J. Agric. Eng. Res. 78 (3), 233 –243. Hope, A.C.A., 1968.A simpliﬁed Monte Carlo signiﬁcance test procedure. J. Roy. Stat. Soc. B. 30, 582–598.Kell, D.B., Darby, R.M., Draper, J., 2001. Genomic computing. Explanatory analysis of plant expression proﬁling data using machine learning. Plant Physiol. 126, 943 –951. Kudaravalli, S., Veyrieras, J.B., Stranger, B.E., Dermitzakis, E.T., Pritchard, J.K., 2009. Gene expression levels are a target of recent natural selection in the human genome.Mol. Biol. Evol. 26 (3), 649–658. Kuhn, M., Wing, J., Weston, S., Williams, A., Keefer, C., Engelhardt, A., Cooper, T., Mayer, Z.,Kenkel, B., the R Core Team, Benesty, M., Lescarbeau, R., Ziem, A., Scrucca, L., Tang, Y.,Candan, C., Hunt, T., 2017.caret: Classiﬁcation and Regression Training (R package version 6.0-78).Lippert, C., Sabatini, R., Maher, M.C., Kang, E.Y., Lee, S., Arikan, O., Harley, A., Bernal, A.,Garst, P., Lavrenko, V., Yocum, K., Wong, T., Zhu, M., Yang, W.-Y., Chang, C., Lu, T.,
Lee, C.W.H., Hicks, B., Ramakrishnan, S., Tang, H., Xie, C., Piper, J., Brewerton, S.,Turpaz, Y., Telenti, A., Roby, R.K., Och, F.J., Venter, J.C., 2017. Identiﬁcation of individ- uals by trait prediction using whole-genome sequencing data. PNAS 114 (38),10166–10171.McCullagh, P., Nelder, J., 1989. Generalized Linear Models. Chapman & Hall. Mitchell, T.M., 2010. Generative and discriminative classi ﬁers: naive Bayes and logistic re- gression.https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf . Ng, A.Y., Jordan, M.I., 2001.On discriminative vs. generative classi ﬁers: a comparison of logistic regression and naive Bayes. Adv. Neural Inform. Process. Syst. 14,605–610.R Core Team, 2017.R: A Language and Environment for Statistical Computing. R Founda-tion for Statistical Computing, Vienna, Austria (URL).Sambo, F., Trifoglio, E., Di Camillo, B., Toffolo, G.M., Cobelli, C., 2012. Bag of naive Bayes: biomarker selection and classiﬁcation from genome-wide SNP data. BMC Bioinforma. 13 (Suppl. 14), S2.Siravenha, A.C.Q., Carvalho, S.R., 2015. Exploring the use of leaf shape frequencies for plant classiﬁcation. 2015 28th SIBGRAPI Conference on Graphics, Patterns and Im-ages, Salvador, pp. 297–304.Tishkoff, S.A., Floyd, A.R., Alessia, R., Voight, B.F., Babbitt, C.C., Silverman, J.S., Powell, K.,Mortensen, H.M., Hirbo, J.B., Osman, M., Ibrahim, M., Omar, S.A., Lema, G., Nyambo,T.B., Ghori, J., Bumpstead, S., Pritchard, J.K., Wray, G.A., Deloukas, P., 2007. Convergent adaptation of human lactase persistence in Africa and Europe. Nat. Genet. 39 (1),31–40.Tze-Wey, L., 2003.Understanding sensitivity and speci ﬁcity with the right side of the brain. BMJ 327 (7417), 716–719. Wang, B., Zhu, Y., Zhu, J., Liu, Z., Liu, H., Dong, X., Guo, J., Li, W., Chen, J., Gao, C., Zheng, X., E,L., Lai, J., Zhao, H., Song, W., 2018. Identiﬁcation andﬁne-mapping of a major maize leaf width QTL in a re-sequenced large recombinant inbred lines population. Front.Plant Sci. 9, 101.Webb, A., 2002.Statistical Pattern Recognition. 2nd ed. Wiley, New York.Wray, N.R., Yang, J., Goddard, M.E., Visscher, P.M., 2010. The genetic interpretation of area under the ROC curve in genomic pro ﬁling. PLoS Genet. 6 (2), e1000864. Wu, S.G., Sheng, B.F., You, X.E., Wang, Y.X., Chang, Y.F., Xiang, Q.L., 2007. Al e a fr e c o g n i t i o n algorithm for plant classiﬁcation using probabilistic neural network. IEEE Interna-tional Symposium on Signal Processing and Information Technology, pp. 11 –16. Z h a o ,J . ,B o d n e r ,G . ,R e w a l d ,B . ,2 0 1 6 . Phenotyping: using machine learning for im- proved pairwise genotype classi ﬁcation based on root traits. Front. Plant Sci. 7, 1864.13 D. Seka et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 9 –13