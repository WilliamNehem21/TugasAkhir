When a company plays an orchestration role it coordinates a business process to accomplish the work. The process can be static or dynamic. In traditional outsourcing contracts we envisage a static orchestration where the process is defined from the outset and partners and services do not change. For novel paradigms, such as virtual organizations, partners and services can be selected on the fly.

SSE-CMM (System Security Engineering Capability Maturity Model) [27] eval- uates a security management process. SSE-CMM assigns a level of maturity (from 1 to 5) to a security system engineering process. This appraisal denotes how well the organization fulfils all base practices.

Risk analysis [28,1,6] is one of the prominent of security system assessment approaches. The most used metric for this analysis is annual monetary loss. If other dimensions (e.g. hours of downtime, reputation) are also used the losses of an organization can not be measured in currency. In this case some form of normalization must be used [6].

We need some metrics to be sure that the promised level is achieved. Traditional SLA metrics measure some aspects of the process and represent the Quality of Service towards meeting the business objectives. The identification of the metrics is a core phase for agreement negotiation. The client must be sure that its objectives are completely reflected and chosen metrics are relevant for it. The Quality of Protection should be represented by metrics as well.

Example 4.1 For example, the speed of connection must be not less then 256 bits/s. Nobody will complain if the speed is higher. On the other hand, the number of successful virus attacks must not be higher then 10 per month (nobody will complain if the number of successful attacks is less).

In contrast, if the primary goal of outsourcing is to shift security services then a SLA should be specified on those activities. Indeed in this case, the functional service that we are outsourcing is simply a service whose particular function is a security function. So we should be able to distinguish when security is the service itself (SLA needed) from the case in which security protects the object of the service (PLA needed). Indeed, the processing of the data which is used to deliver the security services should be subject to a PLA.

An example might clarify better the point: if we are outsourcing a key generation function for identity-based cryptography we should set up a SLA on the minimum key size (i.e. SLA on the function). In contrast a PLA should be set up to protect our identities or our private key (i.e. PLA on the data for and from the function).

So which external metrics are most fruitful for a QoP? We do not recommend metrics based on risk analysis and financial results. At first these metrics have a number of limitations and are not precise [9]. Further, qualitative analysis amplifies these limitations because it operates with relative values (e.g. high, medium, low). The second and foremost reason is that these values are not connected to the service provided and cannot be monitored by the contractor and the client in a shared and agreed way (loss expectancy is difficult to estimate). This does not mean that clients should not use risk analysis to identify the appropriate PLA but simply that the outcomes of the risk analysis such as Annualized Loss Expectancy (ALE) themselves should not be a PLA.

Indeed, methods which estimate a security level are based on a set of questions to check compliance with standards [14]. The set is broken up into protection domains (cryptography, audit, networking). The questionnaire can be redivided into threat domains (protection against viruses, password sniffing, DoS). After that we receive a complete set of parameters and corresponding internal metrics which contribute to a threat protection. Now if we can tell how each of the techniques contributes to mitigation of the threat (e.g presence of a firewall reduces the number of Trojan Horses by 30 percents) correct internal parameters can be chosen to achieve external metrics (e.g. number of Trojan Horses per month).

One of the first papers discussing security SLA in a large enterprise is [13]. The main idea is to check compliance the system with fifteen security domains split into best practices. For each best practice the security service level is determined and added to the SLA (yet it does not consider task outsourcing). [7] extends the security division to compare two SLAs or to find a security SLA which is the closest to the desired one. A similar idea of divide-and-conquer technique was applied to evaluation of Web Service security in [30].

