by the instantiated right hand side (RHS). Since the rule and the redex are already given by ELAN, syntactic pattern matching in Coq in the worst case is linear in the size of this redex. Meanwhile, the cost of nding out a redex depends on the size of terms which can be very huge. Thus, ELAN performs the proof search and Coq checks this proof later. Coq and ELAN must work on the same canonical (con uent and terminating) TRS. In this context, ELAN should return to Coq the as compact as possible traces to minimise the time needed for replaying. This time depends not only on the number of rewrite steps but also on the positions of contracted redices since contracting inner redices creates bigger proof objects.

Due to laziness annotations, some subterms of a term will not be rewritten during lazy rewriting. These subterms are called lazy. Lazy rewriting nor- malises a term to its lazy normal forms where all active subterms are in head normal form (HNF). Some lazy subterms may be reducible, but their reduction may not be nite if the TRS is not terminating. Otherwise, all lazy subterms can recursively be normalised until HNF. In this case, lazy rewriting provides a means to get NFs.

Also in [8], the authors show how to correctly simulate lazy rewriting by innermost rewriting with respect to (w.r.t.) a new TRS obtained by transform- ing the original TRS. This transformation process is called thunki cation. A simulation is correct if it is complete, sound and termination preserving [12] [7]. In other words, correctness guarantees that no information on NFs in the orig- inal TRS is lost. In addition, we are strongly concerned with the relation be- tween the normalisation derivations in order to keep lazy normalisation traces still useful for the proof assistant.

Thunki cation only works with the TRSs where no non-variable term is put on the lazy arguments of a function symbol in the left hand sides of rewrite rules. In [8], the authors deal with this problem by transforming the original TRS into a minimal TRS (i.e. each LHS contains no more than two function symbols) [7]. Hence, this transformation generates a fairly large number of new but simple rules and of new function symbols. The minimal TRS given by their transformation is optimal for the abstract rewriting machine (ARM) [7] but not for ELAN whose compiler uses an improved version of the many-to-one pattern matching algorithm presented in [10]. Moreover, this transformation

substitution, then t denotes the result of applying on t. We write tfx 7! sg the term t in which each occurrence of variable x is replaced by the term s. Term s overlaps the term t if there exist a non-variable subterm tjp and a substitution  such that s  = t jp. Notice that the variables of s and t are

A rewrite rule over T is an ordered pair hl; ri of terms and is denoted by l ! r. We call l and r respectively the left hand side and the right hand side of rule. Rewrite rules are often restricted by two conditions: the LHS is not a variable and all variables occurred in the RHS must be contained by the LHS. A rewrite rule is called left-linear/right-linear if its LHS/RHS is linear.

A set of rewrite rules R over T is called a term rewriting system (TRS). In order to identify rewrite rules in TRSs, in this paper, a rewrite rule is often denoted by [`] l ! r where ` is the label of the rule. A TRS R is called left-linear if all its rules are. A TRS is overlapping if the LHSs of two (not necessary distinct) rules are. A symbol in F is called de ned symbol of a TRS R if it is the head symbol of the LHS of some rule in R. Function symbols which are not de ned symbols are called constructor symbols of R. R is called constructor-based if no de ned symbol can appear inside a LHS. In constructor-based TRSs, only overlapping at the roots of LHSs is allowed.

The set of active positions in a term t is denoted by APos(t). The subterms rooted at an active position is called active. The other subterms of the term are lazy. Thus, a subterm of t is active if and only if the path from its head symbol to the root of t contains no edge that connects a function symbol to one of its lazy arguments.

In order to apply lazy rewriting on a term t, we rst decorate it. That is, we annotate every subterm u of t by ux where p is the position of u in t and x = a meaning that u is active while x = l meaning that u is lazy. All subterms of a lazy subterm are also lazy. The following operator decorates subterm s which is rooted at position p and occurs as an argument of the

Lazy rewriting at the root of a decorated term t by rule l ! r is denoted by [l ! r](t) and is described by the rules in gure 2. These rules transform a 4-tuple: the rst component is the term to be reduced; the second component is the set of positions of essential subterms (ES), i.e. the lazy subterms of t which correspond to a non-variable subterm of l; the third component is of the form (l1;::: ; ln ! r) where l1;::: ; ln are the subterms of l; the fourth component is a list of decorated terms to be correspondingly matched with l1;::: ; ln.

The aim of these rules is for modelling both pattern matching and lazy rewriting in the same process as it is done in [3] for term rewriting. The rule SymbolClash returns the initial term in case of con ict caused by an active subterm of t during the pattern matching phase. The lazy subterms never cause con icts. This fact di erentiates pattern matching in lazy rewrit- ing which is called pattern matching modulo laziness from (normal) pattern matching. If a subterm of t is lazy and the corresponding subterm of l is not a variable, then this lazy subterm is called essential and EssentialSubterm in-

derivation from UD(t) to s only contracts the redices below root. Since t is in LNF, all its active subterms are also in LNF. By induction hypothesis, these subterms (after being removed their decoration) are in HNF and their head symbols cannot be changed by any derivation issued from UD(t) (**).

The new signature 0 is built from the original signature  = (V; F) by adding new function symbols introduced during thunki cation:  ; f ; vecf ; vect; t; inst for every f 2 F and for some subterms t of the RHSs of rewrite rules in the original TRS. The introduction of new function symbols allows one to mask lazy subterms. A lazy f -rooted subterm s is masked (or thunked) by a subterm in the form of ( f ; vecf (:: :)) and hence, cannot eagerly be rewritten. The structure of s is stored in this -rooted subterm so that one can recover it later.

In fact, S0 contains all rewrite rules in R whose RHS has been changed (or thunked): every lazy argument subterm t is thunked by a subterm in the form of ( t; vect(:: :)) and hence, t cannot eagerly be rewritten. A corresponding rule is then inserted into S2 in order to recover t later. The insertion of the symbol inst allows rewriting afterwards on the subterms which have instanti- ated migrant variables. The unique rule of S3 allows dealing with the direct subterms which are not thunked of symbol inst. This rule has the lowest priority and hence, is the last rule of S to be tried with terms since we use textual ordering.

In [8], only non-variable lazy argument subterms of RHSs are thunked. Since an innermost strategy will be used for rewriting by S, the subterms which instantiate variables of RHSs are always in NF before the application of any rule. In other words, the thunki cation of lazy argument subterms which are variables is unnecessary. However, in this work, we also thunk these subterms in order to ensure the correctness of lemma 5.1 in section 5.

This de nition of B is slightly di erent from [8] where g0 is not thunked (by '). The thunki cation of g0 helps to get NFs w.r.t. S more quickly. This fact is used in our normalisation procedure in section 5.

innermost rewriting on terms in the subset B of G 0  w.r.t. S via  up to the criteria gured in [12]. That is, is surjective, sound, complete and termination preserving. The mapping  is surjective since for every term g in

inherit the head symbol from the corresponding subterms of g (lemma 4.5). Furthermore, in (g), active subterms are never subterms of lazy subterms. In other words, (g) can be divided into two parts: the upper part contains active subterms while the lower part contains lazy subterms. Hence, the upper part of g contains the subterms which correspond to active subterms of (g) and which are in HNF w.r.t. R. The lower part of g correspond to the lazy subterms of  (g). The frontier between these two parts is composed of symbols

w.r.t. R. Notice that if a -rooted subterm is activated, then its \active" subterms are also unthunked. The activating procedure of -rooted subterms will be described later by operator . The process is recursively applied until all subterms of g are in HNF w.r.t. R and g is a NF of t.

Lemma 5.1 Let g be a term in B and g contains no symbol inst. Then g is divided into two parts. The upper part contains the subterms which correspond to active subterms of (g) while the lower part contains the subterms which correspond to lazy subterms of (g). The frontier between these two parts is composed of symbols  .

Remark 5.3 The normalisation of term t by procedure lazynorm(t; R) gen- erates a trace Tt containing the traces of all performed (leftmost-innermost) rewrite steps. Let us extract from Tt the pairs whose rst element is the label of some rule in S0. Due to theorem 4.9, this process yields a normalisation trace TR of t in R (in the sense of normal rewriting).

In this section, we present a transformation that allows to eliminate all non- variable lazy argument subterms and hence, all non-variable lazy subterms of LHSs. Our transformation works on (left-linear) constructor-based TRSs. It is proved to be correct and to preserve a good correspondence between nor- malisation traces in original and transformed TRSs.

We call 0(g) the simulation of lazy rewriting on terms in GDterm w.r.t. R by lazy rewriting on terms in B w.r.t. S. Obviously, S is also constructor- based and left-linear. That is, the transformation can be repeated until the LHSs contain no non-variable lazy argument subterm. Our transformation is terminating since in each step, the number of non-variable lazy argument subterms of LHSs is strictly decreased.

 0(g0). More precisely: if g ;S g0 by applying the added rule or the transformed rule, then 0(g) ;R 0(g0) by applying the source rule at the same position. Otherwise, 0(g) ;R 0(g0) by applying the same rule at the same position.

Corollary 6.5 (Correspondence of trace) Let Tg be a (lazy) normalisa- tion trace of term g 2 B w.r.t. S. Replacing the labels of added rule and transformed rule in Tg by the label of source rule, yields a (lazy) normalisa- tion trace of 0(g) w.r.t. R.

Example 7.1 We illustrate our method by considering the TRS (R) in ex- ample 3.4. Thunki cation cannot directly be applied on R since the LHS of r1 contains non-variable lazy subterm cons(y; z). Using preliminary transfor- mation, we get the TRS S in example 6.1.  This TRS ful lls all necessary

Since s(0) contains no symbol the normalisation procedure nishes and return this term as a NF of t w.r.t. S. Due to the soundness of preliminary transformation, s(0) is also a NF of t w.r.t. R. Thanks to theorem 4.9, one can extract from the normalising derivation above a normalisation trace

The rst method is not well-behaved if there is some non-variable lazy subterm in the LHS of a rule as in example 3.4, where the second argu- ment is omitted from the local strategy of cons. However, such a strategy reduces 2nd(inf (0)) to 2nd(cons(0; inf (s(0)))) instead of s(0) since the sub- term inf (s(0)) is not allowed to be reduced and r1 cannot be applied.

The second method is implemented in CafeOBJ using on-demand ag [18]. A negative integer i in the local strategy of function symbol f means the ith subterm of f is forced to be rewritten if and only if it causes a con ict during pattern matching. In example 3.4, the local strategy of cons is (1  2 0) and

step, r1 is tried with the term 2nd(cons(0; inf (s(0)))). The subterm inf (s(0)) causes a con ict and hence, it is forced to be rewritten. The E-strategies that can reduce terms to their HNF is characterised in [15] for left-linear and constructor-based TRSs. On-demand ag is very similar to the notion of essential node and thunki cation shares the same limit with the rst method described above. Preliminary transformation allows us to overcome this limit for left-linear and constructor-based TRSs.

In this paper, we described lazy rewriting and the mechanism of thunki ca- tion under a rule-based form. We showed the relation between normalising derivations in TRSs before and after thunki cation and proposed a normali- sation procedure based on lazy rewriting. A preliminary transformation that allows extending the application scope of thunki cation while preserving a nice correspondence between normalisation traces was also presented.

