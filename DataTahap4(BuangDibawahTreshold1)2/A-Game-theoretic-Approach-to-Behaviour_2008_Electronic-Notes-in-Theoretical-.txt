To bridge the gap between domain experts and formal methods experts, visualisations of the behaviour of formal models are used to let the domain expert understand and experiment with the formal model. In this paper we provide a definition of visualisations, founded in game-theory, which regards visualisations as transition systems synchronised with formal models. We show example visualisations, use them to show winning strategies of games, and demonstrate how an industrial application of formal models benefited from this approach.

Formal models are being used for specification and verification of complex systems [11, 5, 6, 12, 9, 3], provide valuable insight into the workings of the systems, and may detect errors early in the development process. One problem of constructing formal models of systems is that the domain experts, who have a lot of knowledge of the domain of the modelled system, typically have little or no knowledge of formal models. At the same time, experts in formal models typically have little knowledge of the system domain. One way to solve this is to let the domain expert describe the system to the formal methods expert, who then constructs a model for specification and validation. The drawback of this approach is that it is very difficult to know whether problems in the model represent errors in the model itself or in the modelled system. The formal methods expert typically does not know the domain well enough to make the judgement for subtle errors, and the domain expert

Mimic/CPN [19] is a library which facilitates visualisation of coloured Petri net models. Mimic/CPN provides an API which can be used to define and update visualisations. By annotating a model, these functions are called during execution of the model. The disadvantage of this approach is that it is very inconvenient to have to change the model in order to add a visualisation and the changes unnecessarily clutter the model. Furthermore, this library mainly focus on the state changes

of the system, and everything shown to the user must be formulated as explicit updates, so it is not possible to easily monitor the value of, e.g., a counter like in ExSpect. Finally, Mimic/CPN is unable to handle asynchronous input, which must be simulated by polling.

The Play-Engine [7] allows a prototype of a program to be implemented by in- putting scenarios (play-in) via an application-specific GUI. The resulting program can then be executed (play-out). Compared to the approach of the other described tools, this makes the model implicit as it is created indirectly via the input scenarios. Furthermore, the Play-Engine relies on heavy-weight techniques to perform visuali- sation as the model is given implicitly. In order to decide how to execute the model, a complete model-checking step is performed in each step, which is computationally expensive.

Synchronising visualisations with formal models using this technique is very useful and allows us to observe what happens in the model, but it does not allow us to interact with the model, e.g., to drive the model into interesting states. The

If the purpose of a visualisation is to get acquainted with the model or the modelled system, it is often reasonable to assume that a computer tool chooses controllable transitions at random. This can often be done very quickly, however, and this can make it difficult for the user to interact with the model. To overcome this, we may need to impose fairness during execution of the model.

Hitherto, we have used visualisations primarily for validation that the formal model reflects the intended behaviour by letting a domain expert stimulate and observe the model using visualisations. Now, we will turn to using visualisation for communicating the result of formal verification, i.e., convincing users that no winning strategy exists, which is decided using an algorithm from [4] as outlined in Sect. 3. The purpose of a counter example is to convince users that it is impossible to have a winning strategy, so we let the domain expert assume the role of the modelled system and let him try out ideas for winning strategies. At the same time we let a computer tool take charge of the uncontrollable actions according to the counter example that has been calculated. The user is urged to reach a winning state while the tool executes uncontrollable transitions to prevent that (by ensuring that the user is not allowed the ability to execute a transition leading to a good state). We can do this using the formal model, but often the formal methods expert does not have enough domain knowledge to have understand why the system should have

winning strategy, so the domain expert, who has little knowledge of the modelling language, has to find out whether the error is in the model or in the specification. Instead we let the domain expert control the controllable transitions of the model using a visualisation (the computer tool is able to let the visualisation assume control of either the controllable or uncontrollable transitions, as described in Sect. 4.1). We let the user stimulate the model in any way seen fit (according to the supposed winning strategy), and eventually the model will perform an unforeseen move (error in the specification) or the model will perform a disallowed move (error in the model).

In this paper we have given a theoretical foundation for viewing visualisations as game transition systems synchronised with formal models, providing a uniform and general framework for coupling formal models and behavioural visualisation. We have used game-theory to separate output from and input to the model and given two concrete examples of visualisations. We have demonstrated how an industrial case can benefit from using the method described in this paper. Furthermore, we have sketched how this can be used to create counter-examples to the existence of a winning strategy in games, so domain experts with no knowledge of the formalism used can understand them.

