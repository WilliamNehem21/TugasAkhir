We illustrate the limitations of classic automata with the following spam de- tection example. Spam detection is a notoriously hard task and spam filters are continuously modified to handle new malicious behaviours and to relax overly re- strictive conditions. While machine learning is the typical choice for spam detection, many companies prefer using custom filters created using regular expressions. The number of filters can be very large and redundant expressions that cover already considered behaviours are often mistakenly added to the set of filters. Efficiently processing all such expressions can become complicated and it is therefore desirable to avoid adding redundant filters to the list of processed ones.

accepted from state p if a1 is a lower-case letter and the string a2 ... an is accepted from state q1 or it is accepted from both q2 and q3. Using alternation, s-AFAs obtain Boolean operations with linear complexity, which is in sharp contrast with the quadratic intersection and exponential complementation of s-FAs.

(i.e., the set of states, set of final states, and transitions of the union/intersection s-AFAs are just the union of the component s-AFAs; they differ only in the initial state, which is either the disjunction (union) or conjunction (intersection) of the initial states of the components).

[25] for computing satisfiable Boolean combinations of a set of predicates, and also the representative character enumeration algorithm in Section 3). Normalization may (in the worst case) cause an exponential blow-up in the number of outgoing transitions of any one state in an s-AFA. Note, however, that the exponential factor does not depend on the number of states.

Proposition 3.8 yields a simple candidate algorithm for the CONGRUENCE problem: simply check whether the pair of positive Boolean formulae belongs to the logical closure of a relation using a SAT solver. The following proposition states that we cannot hope for an asymptotically superior algorithm.

Proof. Membership in NP follows immediately from Proposition 3.8. We prove NP-hardness of CONGRUENCE by giving a polytime reduction from SAT. The key insight is that the relation R can be used to axiomatize negation, so that arbitrary Boolean formulae can be encoded into positive Boolean formulae.

formulae over the automaton states and it can be easily integrated with exter- nally specified alphabet theories. To represent the positive Boolean formulae over the automaton states we implemented two algebras: one which simply maintains the explicit Boolean representations of formulae (referred to as DAG in the ex- periments) and one which instead maintains a BDD corresponding to each for- mula. We use the JDDFactory implementation in JavaBDD as our BDD li- brary (http://javabdd.sourceforge.net). To check membership of formulae to the congruence closure we use the SAT solver Sat4j [2].

2 We have separately evaluated the use of a priority queue for our worklist and our tool also has imple- mentations for FIFO and LIFO. The use of a priority queue consistently outperforms the other heuristics. Concretely, on our benchmarks FIFO and LIFO time out approximately twice as often as the priority queue implementation. We will report data only about the priority queue implementation because it is consistently faster than the other two.

We consider three sets of LTL formulae: 1) counter contains 15 formulae de- scribing counters for which satisfiability is notoriously hard [20]. 2) lift contains 8 parametric formulae describing a lift system of increasing complexity [13]. 3) More than 10,000 random formulae appearing in [7]. These formulae have size varying between 10 and 100, and number of atomic propositions varying between 2 and 4. We set the timeout at 60 and 5 seconds for the non-random and random formulae respectively.

satisfiability of LTL-f formulae using a BDD-based variant of alternating automata. After observing that Mona consistently outperformed Alaska, we decided to only report the comparison against Mona. We do not compare against non-symbolic automata libraries as these would not support large alphabets. Moreover, most libraries only support NFAs [4], which would force us to choose a way to encode the LTL formulae into NFAs. We also do not compare against model checkers such as NuSMV and Spin, since they only support LTL over infinite traces.

We consider regular expressions from http://www.regexlib.com/, a site con- taining more than 3,000 crowd-sourced regular expressions for tasks such as email filtering, phone number detection, and URL detection. We isolate the first 75 regu- lar expressions for email filtering and consider Boolean combinations of them. For each experiment we set the timeout at 20 seconds.

Alternating automata: Alternation is a classic concept in computer science and and the notion of alternating automata dates back to the 80s [5,6]. Vardi recog- nized the potential of such a model in program verification, in spite of their high theoretical complexities [24]. Alaska was one of the first practical implementations of alternating automata [12]. In Alaska, the alphabet and the set of states are both represented using bit-vectors and this allows to model the search space using BDD.

lar because they support arbitrary alphabets and alphabet representation (not just bit-vectors and BDDs) and arbitrary state representations (again not just BDDs). Alaska performs state-space reduction using antichains while checking AFA empti- ness. As shown by Bonchi and Pous [4], bisimulation up to congruence strictly subsumes antichain reduction.

