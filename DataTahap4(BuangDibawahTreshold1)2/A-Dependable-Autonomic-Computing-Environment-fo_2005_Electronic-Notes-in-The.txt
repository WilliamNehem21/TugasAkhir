This paper is part of a R&D project aiming at the definition and implementation of an environment for dependable autonomic computing. The primary goal of the study is the increase of dependability of digital systems using self-healing techniques. Mobile agents implement self-testing policies for complex and heterogeneous systems. The aim of this paper is to present the general ideas of the project, describe the design decisions and a detailed view of the current architecture. The research includes design and development of a working prototype.

Starting from the idea of dealing with dependability issues during the mis- sion operation of a system, our key point is an extensive use of mobile agents, i.e., autonomous and identifiable computer program that can move from host to host in a network under their own control, to periodically test a set of target systems (self-testing), and in case of failure to diagnose (self-diagnosis) and possibly solve the problem (self-repairing) before a severe malfunctioning occurs (self-healing).

In the field of Computer Science, there are a number of different definitions of software agent. According to Wooldridge and Jennings [4] an agent is a soft- ware module with the following properties: autonomy, i.e., state encapsulation and independent decision-making; reactivity, i.e., ability to perceive external environment and respond to changes; pro-activeness, i.e., goal-directed be- havior; social ability, i.e., interaction with other agents via a communication language with an agent-independent semantics. [5]

Mobile agents are programs that can migrate from one machine to another. Mobile agents evolve from the existing distributed computing paradigms with several novelties. [6][7] The main advantages are: autonomy, even more strongly than non-mobile agents; better support for mobile hosts; reduction of network traffic, since an agent can simply work on site; facilitation for software deployment. They can roam around, gather information about the

The periodic testing of critical component is provided by specific mobile agents. The tests we need to perform are software implemented hardware tests, such as testing the RAM of the target system or the hard disk before a failure occurs. As a matter of fact, before failing completely usually components show abnormal behavior, and testing can reveal it, in a similar way as the initial bootstrap memory testing of a PC.

The Agency is the core of the environment. The Agency receives the informa- tion about each target system and generates a healing plan elaborating the settings coming from the Local Agents and those established by the Global Administrator. It also creates (activates) new mobile agents and send simple commands (goals) to them.

The Manager Agent is a mobile agent responsible for the management and the timely execution of the test plan generated by the Agency. The Manager Agent is in charge of a set of target systems and it moves from one to another to check the status of the testing process, retrieve test history and collect results of the tasks performed by mobile agents. It can self-clone if in charge of too many target system.

pabilities needed by the environment and activated by the Agency when necessary. An agent moves towards a target system, analyzes available re- sources and possibly performs its task. It can receive other tasks while it is moving or acting on a specific target system, possibly self-cloning. When it has terminated its tasks, it dies.

Agency agents match the local administrator policies with the global poli- cies (Policy Manager) and, along with the software and hardware information, generate a list of tests to perform (Goal Generator). The result is a list of goals to communicate to a mobile manager agent. The mobile manager agent in charge of the addressed system moves to the target and if it is the right time (determined by policies/goals constraints) it starts the actions, i.e., it sends to the agency a list of goals each representing a single action to perform, respecting policies/goals constraints.

The agency (Goal Interpreter) selects an agent able to perform the specific action: if the agent exists in the environment, i.e., it has been already acti- vated, then the agency assigns the action (goal) to the existing agent, else the agency creates a new agent with information coming from the agent repository and activates it with the new action (goal).

The involved mobile agent migrates, moves to the target system and, if the resources are available, executes its task (goal); results are stored in the target system (local agent). The manager agent on duty is responsible for results acquisition and analysis. Depending on results, it sends new tasks (goals) to the agency, e.g., a diagnosis action after a failure of a specific test,

Local tests are triggered by goals in the Test agents. As soon as a new goal is processed by the Test agent it belongs to, this agent moves to the involved SUT (System Under Test). Here it finds the Local agent and its services.

