This article provides a survey of approximation metrics for stochastic processes. We deal with Markovian processes in discrete time evolving on general state spaces, namely on domains with infinite cardinality and endowed with proper measurability and metric structures. The focus of this work is to discuss approxima- tion metrics between two such processes, based on the notion of probabilistic bisimulation: in particular we investigate metrics characterized by an approximate variant of this notion. We suggest that metrics between two processes can be introduced essentially in two distinct ways: the first employs the probabilistic conditional kernels underlying the two stochastic processes under study, and leverages notions derived from algebra, logic, or category theory; whereas the second looks at distances between trajectories of the two processes, and is based on the dynamical properties of the two processes (either their syntax, via the notion

This contribution focuses on probabilistic processes with general (continuous) state spaces and aims at surveying and discussing approximation metrics between pairs of such processes. In particular, we provide an overview of results in the literature that are based on the notion of approximate bisimulation. We decide to concentrate on approximate version of the notion of strong (rather than weak) bisimulation, and we only touch upon the concepts of (probabilistic) simulations.

The concept of strong probabilistic bisimulation over a discrete-time, finite-state Markov chain has been introduced in [46], based on earlier notions for non- probabilistic models [49,51]. The work in [36] uses similar notions for Markov decision processes with finite state spaces, and puts forward procedures for find- ing factored bisimilar models. The notion of weak bisimulation is discussed in [9,38,54] for a number of (finite-state) probabilistic processes. The contributions in [39,59] cover the notion of probabilistic simulation relations for classes of proba- bilistic automata. [10,11] provide a recapitulation and draw relationships between these notions. These concepts are of applicative interest and build on earlier work on approximation techniques, such as that of lumpability for Markov chains [13]

For continuous space processes (namely, discrete-time labeled Markov processes as in Section 3), [21] provides a relational and logical characterization of bisimu- lation (see Section 4). Alternatively, probabilistic bisimulations relations can be introduced via coalgebraic [20] or categorical arguments [64]. Building on these results, the material in [22] is relevant in that metrics for labeled Markov processes are discussed (see Section 4), whereas [23] proposes metrics via weak bisimulations, and the contributions in [29,30] discusses metrics for respectively finite- and infinite- state Markov decision processes.

From a different perspective, [5] puts forward an approach based on random- ization techniques to characterize approximation distances between processes over finite time horizons, with no assumptions on their dynamics (see Section 6). This approach also promises to provide model reduction or approximation techniques for classes of stochastic processes. Along this line of research, [26] introduces an ap- proximation for such processes. This approximation can be related to the work in [3,4] (which works with discrete-time stochastic hybrid systems), as well as to that in [62] (which uses Wasserstein Pseudometrics over continuous space processes) and to the classical reference in [43,44], which discusses weak approximations of stochas- tic processes, which has been applied on hybrid models in [42,56], but which offers no explicit approximation bound. Related to this works, [58] has proposed explicit

In the following we introduce exact and approximate notions of bisimulations for CMP. We emphasize that both concepts are to be regarded as strong notions, as opposed to weak versions as in [9,38,54] 3 . The definitions can be looked at from three different aspects: via relations, via logics, and via categories.

The work in [21] further characterizes probabilistic bisimulations via categori- cal notions (based on zigzag morphisms). Related to this approach, [20] employ coalgebraic notions to precisely relate probabilistic models. Similarly, probabilis- tic bisimulations relations over continuous-space processes can be introduced via categorical arguments, as discussed in [64].

The idea to define discounted metrics over probability measures that admit bisimulation as a fixed point is taken up in [30], which uses the Kantorovic distance between probability measures to approximate MDP over infinite state spaces. This distance is related to that discussed in Section 6. The cited work in [64] introduces a discounted metric that is both closely related to that presented in this survey and which is also based on the Kantorovic distance.

Notice how in this definition the controls of the two CMP are treated quite differently than those in Definitions 4.1 and 4.4, which were originally stated for LMP and associated labels. We will comment on these semantical differences in Remark 5.6.

The contribution in [40] puts forward conditions to construct an SBF for certain classes of continuous-time stochastic processes, namely models that are linear in the drift, in the diffusion coefficient, and in the observation map. The setup allows for spontaneous jumps (under homogeneous arrivals) with related (linear) resets, thus resulting in a model with hybrid structure [12,17]. The reader is referred to [40] for practical examples of computation of stochastic bisimulation functions.

Example 5.4 Consider the models Si,i = 1, 2 from Example 4.2, where AiXi = Xi + ai(Xi), and where FiXi = bi(Xi). The processes are (semantically) au- tonomous, since ui = 1 is fixed. An SBF for Si,i = 1, 2 is obtained considering

Remark 5.6 [Labels vs Controls] Notice that the condition in Theorem 5.5 is set up as a dynamical game between the two models. This is in accord with the role that control inputs play in Definition 5.2, and is in contrast with Definition 4.1 or

Next we present an approach, first described in [5], which has the advantage to be valid for general models, with no specific structural assumptions raised on them. It examines sample trajectories of the two processes over finite horizons. In other words, while the approaches above focused on the syntax of the models, this technique directly exploits the process semantics. The material focuses on the autonomous case.

As discussed in Section 4 with reference to [26,64], the distance between two (comparable) stochastic processes can also be studied by setting up metrics on the corresponding probability distributions over their sample spaces. There is a vast literature on the use of metrics between probability measures [33]. Related to the work presented in this Section, the approach in [62] leverages Wasserstein pseudo- metrics between two processes, and approximates them by empirical quantities, obtained by taking samples of the trajectories of the two processes. While the empirical quantities are proven to converge to the actual distance with the number of samples taken, this approach does not provide explicit bounds based on finite samples for the distance between the two processes.

The use of metrics to quantify distances between processes has a long history [33]. This survey has focused on distances based on the approximate notion of probabilis- tic bisimulation, which has seen a recent increased interest both from the depend- ability and formal verification community, as well as within the systems and control field. The two communities clearly differ in the respective approach to the problem: in a quest for categorization, it superficially looks like the first method opts for em- ploying the underlying conditional kernels of the processes under study, whereas the second favors a trajectory-based approach to the problem. Furthermore, the two techniques are grounded on different mathematics: algebra, logics, and category the first, versus dynamical systems (Lyapunov theory, contractivity and invariance anal- ysis) the second. As an alternative, sampling approaches and randomized methods look at the approximation problem from a totally different perspective. Here the focus is on the semantics of the processes and on the possibility to extract trajec- tories over a finite time horizon. The latter approach appears to yield results that are perhaps less formal (they hold with given confidence bounds, though extremely high), yet with outcomes that are less conservative and not stymied by assumptions on the model syntax (such as model stability, contractivity, etc.).

The work in [1] puts forward a procedure that constructs a discrete approximation of a diffusion process. The procedure is based on the discretization of space and time. Given a diffusion process, sufficient conditions for the existence of such an approximation are raised. It shows that the abstraction is probabilistically bisimilar to the original process, up to a certain approximation precision.

