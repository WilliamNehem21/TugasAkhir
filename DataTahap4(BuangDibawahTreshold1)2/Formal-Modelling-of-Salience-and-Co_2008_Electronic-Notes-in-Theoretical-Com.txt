Well-designed interfaces use procedural and sensory cues to increase the salience of appropriate actions and intentions. However, empirical studies suggest that cognitive load can influence the strength of procedural and sensory cues. We formalise the relationship between salience and cognitive load revealed by empirical data. We add these rules to our abstract cognitive architecture developed for the verification of usability properties. The interface of a fire engine dispatch task used in the empirical studies is then formally verified to assess the salience and load rules. Finally, we discuss how the formal modelling and verification suggests further refinements of the rules derived from the informal analysis of empirical data.

As an assessment step for our extension, we formally model the fire engine dis- patch task used in the empirical studies [1]. One reason for doing this is to check whether the systematic errors identified during the experiments can also be de- tected by the formal verification of the same task, thus indicating that our extended cognitive architecture generates behaviours corresponding to those of real people. Another reason is that possible mismatches between the two sets of behaviours can suggest new empirical studies leading to refinements of our salience and load rules and their formalisation within the cognitive architecture.

There is little related work on salience and cognitive load. Cartwright-Finch and Lavie [7] developed a theory that a high extraneous load only reduces perception of a sensory cue when cognitive control functions are not available to maintain the active goal. More generally, work on human error has shown that the provision of visual cues can strengthen procedural cueing providing they manage to capture attention [8].

Duke et al. [10], and Bowman and Faconti [4] use Interactive Cognitive Sub- systems (ICS) [3] as the underlying model of human information processing. Their models deal with information flow between the different cognitive subsystems and constraints on the associated transformation processes. As a result, the above work focusses on reasoning about multi-modal interfaces and analyses whether interfaces based on several simultaneous modes of interaction are compatible with the capa- bilities of human cognition.

In the formal user model, we rely upon abstract cognitive principles that give a knowledge level description in the terms of Newell [15]. Their focus is on the internal goals and knowledge of a user. These principles are briefly discussed below. Their formalisation in SAL is described in Sections 2.2 and 3.

Presented with several options, a person chooses one that seems relevant to the task goals. For example, if the user goal is to get cash from an ATM, it would be cognitively implausible to choose the option allowing one to change a PIN. A person could of course press the wrong button by accident. Such classes of error are beyond the scope of our approach, focussing as it does on systematic slips.

Even though user choices are non-deterministic, they are affected by the salience of possible actions. For example, taking money released by a cash-point is a more salient, and thus much more likely, action to take than to terminate the interaction by walking away from the machine without cash. In general, salience could be affected by several factors such as the sensory (visual) salience of an action, its procedural cueing as a part of a learned task, and the cognitive load imposed by the complexity of the task performed.

discharge such goals, even when the device is prompting for a different action. Such pre-determined goals represent a partial plan that has arisen from knowledge of the task in hand, independent of the environment in which that task is performed. No fixed order other than a goal hierarchy is assumed over how pre-determined goals will be discharged.

A person may decide to terminate the interaction. As soon as the main task goal has been achieved, users intermittently, but persistently, terminate interactions [6], even if subsidiary tasks generated in achieving the main goal have not been completed. A cash-point example is a person walking away with the cash but leaving the card. Users also may terminate interactions when the signals from the device or environment suggest that task continuation is impossible due to some fault. For example, if the cash-point signals that the inserted card is invalid (and therefore retained), a person is likely to walk away and try to contact their bank.

subgoals A data structure, denoted subgoals, that specifies the subgoals of the goal. It takes the form comp(gls) when the goal consists of a set of subgoals gls. If the goal is atomic, its subgoals are represented by a reference, denoted atom(act) to an action in the array Actions (see below).

The state space of the user model consists of three parts: input variable in, output variable out, and global variable (memory) mem; the environment is modelled by a global variable, env. All of these are specified using type variables and are instantiated for each concrete interactive system. The state updates associated with an atomic goal are specified as an action. The latter is modelled as a record with the fields tout, tmem and tenv; the array Actions is a collection of all user actions. The three fields are relations from old to new states that describe how two components of the user model state (outputs out and memory mem) and environment env are updated by executing this action. These relations, provided when the generic user model is instantiated, are used to specify Transition(a) as follows:

When an atomic goal g is selected, the user model commits to the corresponding action act(Goals[g].subgoals). The record status keeps track of a history of selected goals. Thus, the element g of the array status.trace is set to true to indicate that the goal g has been selected, status.last records g as the last goal selected, and the counter of selected goals, status.length, is increased.

In the user model, we consider two ways of terminating an interaction. Voluntary completion (finished is set to ok) can occur when the main task goal, as the user perceives it, has been achieved (see the ExitTask command). Forced termination (finished is set to abort) models random user behaviour (see the Abort com- mand). Since the choice between enabled guarded commands is non-deterministic, the ExitTask action may still not be taken. Also, it is only possible when there are no earlier commitments to other actions.

Here, intr and extr represent the intrinsic and extraneous load, respectively. The variable default denotes the salience of a sensory cue without taking into account the cognitive load experienced, whereas sensory denotes the actual sensory salience of that cue. Note that our formalisation is non-deterministic, i.e., we assume that a sensory cue can be salient (and thus be noticed by people) even under the high cog- nitive load condition. This reflects the modality may in the corresponding informal rule.

Thus, this goal may be selected only if the priority selection menu is displayed. The choice strategy NotYetDischarged is a pre-defined predicate that allows one to choose a goal only when it has not been chosen before. We assume that the sensory salience of this goal is high, since the visual attention, at this point in task execution, should be in the correct area. The salience of this goal as a procedural cue for the call confirmation action is high, but it should not cue other actions. The corresponding action SelectPriority is defined as follows:

The definitions for the other two goals are similar. Their sensory salience is assumed to be high. ConfirmPriorityGoal serves as a procedural cue of high salience for the goal StartCallGoal, whereas the latter being the last step in the procedure does not cue other actions. Finally, the top goal PriorityGoal for the call priority subtask is defined as follows:

It includes all three atomic goals as its subgoals. Since setting call priority is a cognitively simple procedure, we assume that the intrinsic load for this task is low. Finally, the component achieved defines the perceived goal of the task. The latter is regarded as achieved when a wait message is displayed by the interface. This only

instead of ConfirmRouteAction which is procedurally cued with high salience by SelectBackupAction. This lead to the introduction of additional salience level, prioritising the goals with high procedural salience (e.g., ConfirmRouteAction) over those whose sensory salience is high (e.g., SendRouteAction). The modified version of the cognitive architecture was used for further verification.

Next we verify property (5) relevant to the termination error. In this case, the correlation with the empirical data is closer. For all load conditions but intrinsic being high and extraneous being low, verification of (5) yields the same results as the empirical studies. In the case when both the intrinsic and the extraneous load is high the omission of selecting backup is observed. When the intrinsic load is low verification of (5) is successful. This corresponds to low error rates for these load conditions in our empirical studies (non-systematic error). On the other hand, the single mismatch occurring when the intrinsic load is high and the extraneous load is low is potentially more serious than previous false positives. In this case, verification is successful, even though our empirical data indicates a systematic error.

One possible explanation for this mismatch is that our judgement about salience values for some goals was inappropriate. In fact, verification yields the termination error when, for SelectBackupGoal, the salience of procedural cueing is set to high and the sensory salience is set to low (in the original specification, these values were low and high, respectively). Furthermore, the new value for procedural cueing could be reasonably argued for, though admittedly the new value for the sensory salience is probably more difficult to defend. Another possible explanation is that our rules are simply too coarse. Whichever the case may be further experiments are necessary.

In this paper, we added to our cognitive architecture the concepts of procedural and sensory salience. We formalised the connection between both salience types and cognitive load imposed by the complexity of the task performed. We then refined the underlying principle of non-deterministic choice of goals by introducing a hierarchy of choices governed by the salience of goals. Verification attempts using the new version of the cognitive architecture suggested further refinements to the hierarchy of salience levels.

