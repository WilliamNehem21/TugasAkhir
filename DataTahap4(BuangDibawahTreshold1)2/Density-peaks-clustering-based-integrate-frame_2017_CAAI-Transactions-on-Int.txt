We present a novel unsupervised integrated score framework to generate generic extractive multi- document summaries by ranking sentences based on dynamic programming (DP) strategy. Consid- ering that cluster-based methods proposed by other researchers tend to ignore informativeness of words when they generate summaries, our proposed framework takes relevance, diversity, informativeness and length constraint of sentences into consideration comprehensively. We apply Density Peaks Clustering (DPC) to get relevance scores and diversity scores of sentences simultaneously. Our framework produces the best performance on DUC2004, 0.396 of ROUGE-1 score, 0.094 of ROUGE-2 score and 0.143 of ROUGE-SU4 which outperforms a series of popular baselines, such as DUC Best, FGB [7], and BSTM [10].

With the explosively growing of information overload over the Internet, consumers are flooded with all kinds of electronic docu- ments i.e. news, emails, tweets, blog. Now more than ever, there are urgent demands for multi-document summarization (MDS), which aims at generating a concise and informative version for the large collection of documents and then helps consumers grasp the comprehensive information of the original documents quickly. Most existing studies are extractive methods, which focus on extracting salient sentences directly from given materials without any modification and simply combining them together to form a summary for multi-document set. In this article, we study on the generic extractive summarization from multiple documents. Nowadays, an effective summarization method always properly considers four important issues [1,2]:

This article is organized as follows: Section 2 describes related research work about our motivation in detail. Section 3 presents our proposed Multi-Document Summarization framework and the summary generation process based on dynamic programming technology. Section 4 and Section 5 give the evaluation of the al- gorithm on the benchmark data set DUC2004 for the task of multi- document summarization. We then conclude at the end of this article and give some directions for future research.

Various extractive multi-document summarization methods have been proposed. For supervised methods, different models have been trained for the task, such as hidden Markov model, conditional random field and REGSUM [5]. Sparse coding [2] was introduced into document summarization due to its useful in image processing. Those supervised methods are based on algo- rithms that a large amount of labeled data is needed for precon- dition. The annotated data is chiefly available for documents, which are mostly relevant to the trained summarization model. Therefore, it's not necessary for the trained model to generate a satisfactory summary when documents are not parallel to the trained model. Furthermore, when consumers transform the aim of summarization or the characteristics of documents, the training data should be reconstructed and the model should be retrained necessarily.

[10] used generative model and provided an efficient way to model the Bayesian probability distributions of selecting salience sen- tences given themes. Wang et al. [11]combined different summa- rization results from single summarization systems. Besides, some papers considered reducing the redundancy in summary, i.e. MMR [12]. To eliminate redundancy among sentences, some systems selected the most important sentences first and calculated the similarity between previously selected ones and next candidate sentence, and add it to the summary only if it included sufficient new information.

We follow the idea of cluster-based method in this article. Different from previous work, we attempt to propose an integrated weighted score framework that can order sentences by evaluating salient scores and remove redundancy of summary. We also use the dynamic programming solution for optimal salient sentences selection.

In this section, diversity scoring is presented to argue a good summary should not include analogical sentences. A document set usually contains one core topic and some subtopics. In addition to the most evident topic, it's also necessary to get the sub-topics most evident topic so as to better understand the whole corpus. In other words, sentences of the summary should be less overlap mutually so as to eliminate redundancy. Maximal Marginal relevance (MMR), one of the typical methods reducing redundancy, uses a greedy approach to sentence selection through combing criterion of query relevance and novelty of information. Another hypothesis of DPC is that cluster centers also are characterized by a relatively large distance from points with higher densities, which ensure the similar sentences get larger difference scores. Therefore, by comparing with all the other sentences of the corpus, the sentence with a higher score could be extracted, which also can guarantee the diversity globally. The diversity score SCdiv(i) is defined as the following function.

and g of the integrated score framework, we carry out a set of ex- periments on development dataset. The value of a, b, and g was tuned by varying from 0 to 1.5, and chose the values, with which the method performs best.

In this section, DUC2007 is used as our development set to investigate howa, b, and g relate to integrated score framework. ROUGE version 1.5.5 toolkit [13], widely used in the research of automatic documents summarization, is applied to evaluate the performance of our summarization method in experiments. Among the evaluation methods implemented in Rouge, Rouge-1 focuses on the occurrence of the same words between generated summary and reference summary, while Rouge-2 and Rouge-SU4 concerns

handle the task of multi-document summarization. For ranking sentences, we proposed an integrated score framework. Informa- tive content words are used to get the informativeness, while DPC was employed to measure the relevance and diversity of sentences at the same time. We combined those scores with a length constraint and selected sentences based dynamic programming at last. Extensive experiments on standard datasets show that our method is quite effective for multi-document summarization.

