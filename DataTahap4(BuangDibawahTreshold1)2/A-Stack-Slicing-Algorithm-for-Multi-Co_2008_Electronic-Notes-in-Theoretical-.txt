A new set of algorithms [7,8] is currently in development to support multi-core veri- fications with the SPIN model checker [5]. A guiding principle in the design of these new algorithms has been to interfere as little as possible with the existing algorithms for the verification of safety and liveness properties. The extensions are designed to preserve most of the existing verification modes and optimization choices, including, for example, partial order reduction, bitstate hashing, and hashcompact state stor- age. The basic computational complexity of the verification procedure also remains unchanged. This means that the verification of all correctness properties remains linear in the size of the state graph, when parts of the search are done in parallel. The SPIN algorithms are known to be efficient, and we would like to preserve this advantage. As many have found, it can be hard to outperform a single-core run

In this paper we explore one of the new algorithms we are considering in a little more detail. We focus on the algorithm for the verification of safety properties, which is based on a stack slicing method that has some unexpected benefits beyond the intended purpose of scaling performance up to linearly with the number of available CPU cores. We will first summarize this stack slicing algorithm, show some performance results, and then discuss some of the more surprising features of this algorithm.

The Start() routine is initiated on each CPU, with a different core_id number in the range 0..(NCORE-1) passed to each one. The CPU with core_id 0 starts the search in the usual way by pushing the initial system state onto its search stack and calling its recursive search procedure. The main difference in the depth-first search procedure itself can be found on lines 28-30, where we check if the preset Handoff depth has been exceeded. If it has, we check if the target work queue has slots available and if so we hand off the state to that CPU by copying it (in shared memory) into the target queue. The search now immediately backtracks and starts exploring other reachable system states, without waiting for the subtree below the handoff state to be fully explored. Note that the handoff is suppressed if the target work queue is full, in which case the neighbor CPU already has a sufficient amount of pending work so nothing more can be gained from passing it still more work to do. In this case the CPU considered will continue the search locally, while remaining prepared to hand off any future successor to this state at a later point in the search as soon as slots open up in the target work queue.

Stack frames that become redundant as the search progresses can be recycled with a garbage collection process, e.g., by maintaining a reference count in each frame that records how many successors may still be relying on it. When the count drops to zero, the frame can be recycled. Garbage collection introduces the need for locking, though, which can negatively impact overall runtime performance.

The performance of the slice stack algorithm is often surprisingly good (surpris- ing for a relatively simple load balancing method and its minimal intrusion on the existing depth-first search process implemented in SPIN ). The handoff depth simultaneously provides locality and independence between cores, and trivial load balancing across cores. There are interesting engineering tradeoffs to be made. Note for instance that larger values for the handoff depth can give more independence in the search, and lower the overhead of state transfers between CPU cores, while shorter values can provide better load balancing.

cation was written. Each model checker supports constructs that it can exploit to optimize its search process. It is very hard for a translator to produce models for each target tool that use the same optimizations. Instead, the translated model is typically inefficient. This effects holds for the models in the BEEM database, in the sense that for each model provided in PROMELA , it is readily possible to rewrite that model by hand, without any change to the model semantics, to achieve very significant performance improvements. If we are interested in demonstrating the capability of a model checker to solve a given verification problem, then we would have to do so to achieve a fair comparison. In this case, though, the situation is dif- ferent. As long as we can show that each model checker explores roughly the same number of reachable states, we can achieve a fair comparison of the performance of the multi-core algorithms, irrespective of which verification problem is being repre- sented. The models in a sense merely serve to define a reachable statespace, and all we need to do is to explore this same statespace

64-bits) with 32 GB of memory and using the same version of gcc, also compiling in 32-bit mode. The results were normalized by multiplying our performance numbers with 2.3/2.6 to match the clockspeed of the computer used for the Brno results. All verifications were performed in the same way that they were done in [2], which means that we disabled statement merging (using spin -o3 to generate the veri- fiers), and we disabled partial order reduction (adding the compile-time directive

In all four cases, the performance of the liveness algorithm from SPIN 5.0 using two processing cores is better than the performance reported in [2] for runs using twelve or sixteen processing cores. Curiously, the performance of SPIN running on one single core also outperforms the performance of the alternative algorithm running on sixteen cores. The largest difference is seen for the BEEM leader elec- tion model, where SPIN performs the liveness verification 15 times faster on one processing cores than the alternative algorithm on 16 cores. We believe that the explanation for this phenomenon is the increased verification complexity that is in- curred by the alternative algorithms, only some of which can be made up with the use of larger numbers of cores. The improvements seen in the alternative algorithms are in these cases limited to roughly 12 cores, and no further improvement is seen by adding more.

The results are not exclusively positive for SPIN though. As it turns out, for these particular problem instances, the dual-core liveness verification algorithm in SPIN 5.0 does not succeed in delivering a meaningful improvement. It would be tempting to say that the search is already optimal and cannot be improved further in these cases, but that would be far from the truth. There are several factors that

generalized to the use of more than two processing cores while retaining a low search complexity. It would be easy to conclude that no such generalization is possible, but as we have seen there often are special cases where significant improvements can be achieved. In retrospect such findings often seem obvious. Finding a simple extension of the liveness algorithm, however, will for the time being have to remain non-obvious.

