A knowledge graph is a comprehensive and organized network of structured data, designed to illustrate the connections and relationships among various entities. It consists of nodes and edges, consists of nodes that represent distinct entities, and edges that denote the relationships between these entities [1]. At present, knowledge graphs are widely used in many AI fields, such as natural language processing and search recommendation [2]. However, although standard knowledge graphs (e. g., WordNet) are widely applied, they still face a problem of information incompleteness [3]. They contain large amounts of unrevealed semantic information. Therefore, knowledge graph completion, with the goal of automatically inferring the missing content based on the existing in- formation and external data in order to fill in missing and erroneous information to construct a more complete and accurate graph, has become a vital focus of research for enhancing the quality and

To address the abovementioned issues, this paper proposes the Att- CL method, which integrates hyperbolic representation learning and contrastive learning. This method involves embedding knowledge into a hyperbolic space. For samples with limited hierarchical characteristics and insufficient feature information, a method of overlaying adversarial noise is employed. The loss function of the embedded samples is back- propagated to the embedding vectors. Perturbations are added and adjusted in the gradient direction to make them smoother and more localized. Simultaneously, a hyperparameter is introduced to fine-tune the adversarial strength when constructing adversarial samples for

Embedding is a technique commonly employed for addressing the knowledge graph completion problem. It involves mapping entities and relations into a lower-dimensional vector space, allowing for the quan- tification of entity similarity and relation distance. Effectively capturing the interconnectedness among entities while retaining the integrity of the original information [10,11]. The TransE model [12] uses the Euclidean distance to measure the matching between entities and re- lations; it combines entity vectors with relation vectors to capture interentity relations, but it has difficulty handling complex relations. The DistMult model [13] uses the dot product to measure entity and relation similarity; it avoids illegitimate entity combinations by restricting the relation vectors, but it is limited in its representation ability. The ComplEx model [14] extends the DistMult model to the complex domain and uses complex vectors to represent entities and re- lations and compute their similarity, but it has many parameters and is computationally complex. Graph neural network models focus on capturing complex entity and relation interactions to forecast and recover missing data [15]. The ConvE model [16] uses convolutional neural networks to learn the interaction patterns of entities and re- lationships, which are then applied for information prediction and filling.

In contrastive learning [23], by comparing the similarities and dif- ferences between positive and negative sample pairs and increasing the diversity of the training samples, it is possible to better distinguish be- tween different entities and relationships to obtain more semantically informative representations [24]. SimCTG [25] is a contrastive learning framework proposed for neural text generation tasks that addresses the problems encountered in decoding methods, encourages diversity and coherence, and improves the calibration of the representation space of language models. SimKGC [26] uses a dual encoder architecture, in- troduces three harmful sample types, and uses the cosine similarity for tail entity prediction to improve the learning efficiency. KGE-CL [27]

number of relationally connected entities in the knowledge graph is low, Att-CL makes a judgement on each triple. Suppose that the number of connected entities is lower than the average. In that case, adversarial samples are generated via the introduction of adversarial noise for data augmentation, and the generated adversarial samples are added to the sample pairs for contrastive learning.

in knowledge graph completion. Owing to the comparatively modest dimensions of the WN18RR dataset and the fact that the relations it contains mainly involve associations between word meanings, it is pri- marily focused on semantic relations. Therefore, the Att-CL model shows greater improvement on the FB15k-237 dataset than on the WN18RR dataset.

2.2 %, 1.6 %, and 2.62 % in MRR, Hits@1, Hits@3, and Hits@10, respectively. Furthermore, further enhancement of the embedding space by integrating hyperbolic representation learning and contrastive learning mechanisms can yield superior results and performance in the task of completing knowledge graphs.

