We review links between three logic formalisms and three approaches to specifying operational semantics. In particular, we show that specifications written with (small-step and big-step) SOS, abstract machines, and multiset rewriting, are closely related to Horn clauses, binary clauses, and (a subset of) linear logic, respectively. We shall illustrate how binary clauses form a bridge between the other two logical formalisms. For example, using a continuation-passing style transformation, Horn clauses can be transformed into binary

clauses. Furthermore, binary clauses can be seen as a degenerative form of multiset rewriting: placing binary clauses within linear logic allows for rich forms of multiset rewriting which, in turn, provides a modular, big-step SOS specifications of imperative and concurrency primitives. Establishing these links between logic and operational semantics has many advantages for operational semantics: tools from automated deduction can be used to animate semantic specifications; solutions to the treatment of binding structures in logic can be used to provide solutions to binding in the syntax of programs; and the declarative nature of logical specifications provides broad avenues for reasoning about semantic specifications.

This same difference can also be applied to semantic specifications. In particular, denotational semantic specifications strongly resembles (pure) functional programs: the modern reader of, say, the early texts by Stoy [34] and Gordon [9] on denota- tional semantic will get a strong sense that the more involved denotational semantic specifications can be seen as Haskell or Scheme programs. We hope to convince the reader by the end of this article that many operational semantic specifications can be seen as logic programs and, furthermore, that there are significant advantages in viewing them that way.

Structural operational semantics was first used by Milner [26] to describe CCS and by Plotkin [31,32] to describe a wide range of programming language features. This style of specification, now commonly referred to as small-step SOS, allows for a natural treatment of concurrency via interleaving. Big-step SOS, introduced by Kahn [14], is convenient for specifying, say, functional programming but more awkward for specifying concurrency. Both of these forms of operational semantics define relations using inductive systems described by inference rules: Horn clauses provide a declarative setting for encoding such rules.

In order to encode a programming language, we first map syntactic expressions used in the specification of programming languages into logic-level terms. Since almost all interesting programming languages contain binding constructions, we choose a logic whose terms also contain bindings. Because we are only attempting to capture the syntax of the objects used to describe computation, we shall assume that the logic has sufficient typing to directly encode syntactic types. We shall use the following two natural principles to guide such an encoding.

(If n = 0 then the empty conjunction above can written as the true logical con- nective.) Of course, we assume that x1,..., xm are the schema variables in the inference rule. The formulas A0,..., An are universally quantified atomic formulas (usually, the list of such universal quantifiers is empty). A Horn clause is binary if its body contains exactly one atom: that is, in the displayed formula above, n = 1.

The reduced class of Horn clause, called binary clauses, can play an important role in modeling computation. As we argue below, they can be used to explicitly order computations whose order is left unspecified in Horn clauses: such an explicit ordering is important if one wishes to use the framework of big-step semantics to capture side-effects and concurrency. They can also be used to capture the notion of abstract machines, a common device for specifying operational semantics.

In order to motivate our next operational semantic framework, consider the prob- lem of specifying side-effects, exceptions, and concurrent (multi-threaded) compu- tation with binary clauses. Since all the dynamics of computation is represented via term structures (say, within s, s1,..., sn, t) all the information about these threads, reference cells, exceptions, etc., must be maintained as, say, lists within these other terms. Such an approach to specifying these features of a programming language lacks modularity and makes little use of logic. We now consider extending binary clauses so that these additional features have a much more natural and modular specification.

The only use of additive linear logic connectives, in particular & and T, in any of our semantic specifications is in the specification of polling: in an attempt to synchronize with (poll E) (with the continuation K) the goal (event E U T)& K is attempted (for some unimportant term U ). Thus, a copy of the current evaluation threads is made and (event E U T) is attempted in one of these copies. This atom is provable if and only if there is a complementary event for E in the current environment, in which case, the continuation T brings us to a quick completion and the continuation K is attempted in the original and unspoiled context of threads. If such a complementary event is not present, then the other clause for computing a polling event can be used, in which case, the result of the poll is none, which signals such a failure. The semantics of polling, unfortunately, is not exactly as intended in CML since it is possible to have a polling event return none even if the event being tested could be synchronized. This analysis of polling is similar to the analysis of testing in process calculus as described in [21].

