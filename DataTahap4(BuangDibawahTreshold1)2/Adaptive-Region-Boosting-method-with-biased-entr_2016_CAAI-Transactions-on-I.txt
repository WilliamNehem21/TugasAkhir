in order to make a thorough assessment to a local area. Three groups of experiments are conducted based on a dual-manipulator system with 12 DoFs. Experimental results indicate that ARB effectively improves the success rate and outperforms all the other related methods in various dynamical scenarios.

As one of the most fundamental researches in robotic field, path planning has been applied in many other disci- plines such as aviation, industrial manufacturing, games/ virtual reality and so on. The generalized motion planning problem has been proved to be PSPACE-hard [1]. Therefore, many sampling based methods have been proposed to reduce computational complexity. Probabilistic Roadmap method (PRM) [2] and rapidly exploring Random Tree (RRT) [3] are two of the most successful ones with prob- abilistic complete guarantee. Though in the past two de- cades many variants of PRM [4,5] have gained great success in solving path planning problems even in high-

By considering the difference between two adjacent frames, not only space information is captured, but also time infor- mation is taken into account to evaluate changing degree of a local region in updating phase. Our approach includes two steps. In preprocessing phase, a hierarchical sampling strategy is proposed to construct the roadmap by two layers of samples. In updating phase, more samples will be adaptively activated in difficult regions in order to boost sampling density within these regions.

The rest of this paper is organized as follows. Section 2 describes related works. Details of our method are given in Section 3. Three groups of experiments are conducted and analyzed in Section 4. Finally, conclusions are drawn in Section 5.

Some bridge builder planners are proposed to work out difficult regions in changing environments, such as Dynamic Bridge Builder (DBB) [18]. In preprocessing phase, DBB generates sample points and constructs a new roadmap like DRM. Then, DBB computes midpoints of edges in the road- map and generates incremental points around those midpoints. Afterward, W-C mapping of sampling points is calculated to ensure validity of sampling points and edges. If the midpoint of an edge is valid and two endpoints are invalid, this edge is regarded as a bridge which identifies a local region of a narrow passage. In updating phase, DBB rebuilds new bridges online by traversing all the edges.

When difficult regions are identified by DBB in updating phase, two different strategies are used to boost these regions. The first one is to activate incremental points around those bridges, which means more time will be consumed to compute W-C mapping for those incremental points during pre- processing phase. This strategy is written as DBB-I [18]. The other is to predict the validity of incremental points by using Parzen-Window estimation in updating phase and delaying collision detections to query phase. In this way, it can decrease the preprocessing time. This strategy is written as DBB-II [19].

Various machine learning algorithms [21] have been applied to estimate the probability density of valid sampling points in a local area. In this paper, active learning algorithms are utilized since the learner can classify different kinds of regions from which it learns. Parzen-Window is a well-known density estimation method which has been extensively used in pattern recognition, classification, prediction and so on. Parzen-window estimates the Probability Density Function (PDF) which is derived from a large amount of samples.

It is one of the most crucial problems to estimate how difficult a region is in real time. In this paper, the difficult degree of a region can be roughly estimated with information of a few sampling points. Biased entropy of a valid point represents the difficult degree of the local region around this point. The biased entropy difference between two adjacent frames can evaluate the changing degree of a region through time. With this difference, an Adaptive Region Boosting (ARB) method is proposed to boost difficult regions in order to find a free path effectively and efficiently.

In changing environment, a time period is divided into a series of slices. In each time slice, the environments are viewed as static environments. For convenience, a time slice is called a frame. Obviously, the more slices in a time period, the more accurate we simulate the real environment.

Bi is the set of the incremental points around pi. At the beginning, all points of B will be marked as inactive, which means they will be ignored in the course of searching a path. The W-C node mapping for points of P and B should be computed in the preprocessing phase, in order to update their validity fast for each query. In updating phase, when incre- mental points around the main points need to be activated, these incremental points are used to search a path.

when P = 0.5, H(P(q)) gains the maximum. However, it is not a monotone function. It is difficult to measure difficult degree of regions, such as, approximately free regions, obstacle boundaries and narrow passages. A new estimating function called biased entropy is defined as:

During updating phase, the roadmap needs to be updated all the time. In every frame, the roadmap is updated by W-C mapping according to which cell in W-space is occupied by obstacles or robots. In our method, the roadmap is also updated with an adaptive boosting region method, which is shown in Algorithm 2.

When obstacles move in W-Space, obstacle regions in C- space will change accordingly. Since the motion of obstacles is unknown, the changing degree of regions in C-space is quite different. For example, if some regions become narrow pas- sages from free regions between two frames, these regions have a more intensity change than the other regions in contrast. Thus, the difference of e( p) can represent the changing degree of region Rp, which is defined as:

Firstly, the value of a crucial parameter is discussed. In ARB, entropy value is calculated by K-nearest neighbors method. Thereby, parameter K has a significant influence on the performance of the planner. If K is very small, no enough sampling points to estimate accurately makes region classifi- cation unreliable. On the contrary, if K is very large, the region Rq becomes too large leading to an increasing error rate. In order to obtain optimal K, 100 experiments are carried out with different K in different scenarios.

The size of region Rq also depends on parameter K. The diameter of Rq is the furthest distance between two points which are K-nearest neighbors of q. Furthermore, as the center of region Rq is not always point q, all the regions are restricted in the boundaries of C-space.

During preprocessing phase, some samples are generated to construct the roadmap at first, called the main points. Then, the incremental points are generated around main points and connected to the roadmap. However, these incremental points are inactivated initially, which means these points and edges will not be searched until they are activated. In this paper, there are eight incremental points around every main point. After that, W-C nodes mapping of all points are computed to obtain validity of these points in updating phase.

P is crucial in realization. If it is too large, updating phase will be time consuming. If it is too small, roadmap does not contain enough information for C-space construction. Column NM is the number of the middle points which are used in DBB-I and DBB-II to identify narrow passages. NB is the number of the incremental points in ARB, DBB-I and DBB-II. Column NS is the total number of sampling points in C-space. Column Tc is the time of constructing roadmap without W-C mapping.

not computed and much fewer incremental points are gener- ated in ARB. The NS of DBB-II is smaller than DBB-I, because the incremental points are generated around main points instead of midpoints in DBB-I. Tc of ARB and DBB-I are similar to DRM, because ARB and DRM have similar NS. DBB-I has more sampling points and more time of roadmap construction, because more sampling points are generated and it needs much more time to connect these points.

With different speeds of obstacles, the SRavg of ARB is similar in each scenario. However, the SRavg of the other methods is decreasing with higher speed. It is due to the fact that the changing degree of environments is taken into account in ARB. The number of activated points depends on the changing degree of the region. The ARB has excellent uni- versality for various environments. In a word, the ARB gains better outstanding performance than the other related methods.

However, there are a few significative works on excavating information of regions in DRM method. For example, tracking the movement of obstacles and forecasting the changing of difficult regions will be our future work. Some predictive model to capture motion of regions is a much possible method.

D. Hsu, L.E. Kavraki, J.C. Latombe, R. Motwani, S. Sorkin, On finding narrow passages with probabilistic roadmap planners, in: Proceedings of the Third Workshop on the Algorithmic Foundations of Robotics on Robotics : The Algorithmic Perspective: the Algorithmic Perspective, 2002, pp. 141e153.

Risheng Kang received the B.E. degree in computer science and technology from Inner Mongolia Agri- cultural University, inner Mongolia, China, in 2012. He is currently pursuing M.S. degree in computer science of Peking University, China. His research in- terests in robot motion planning. Recently, he also serves as reviewer for the IEEE International Confer- ence on Robotics and Automation (ICRA).

Hao Tang received the B.E. degree in electronics and information engineering in 2013 and is working to- ward the Master degree at the School of Electronics and Computer Engineering, Peking University, China. His current research interests are image classification, hand gesture recognition, gender recognition, image retrieval, action recognition and deep learning. He has published several articles in ACM Multimedia Con- ference (MM), IEEE International Conference on Image Processing (ICIP) and International Joint Con- ference on Artificial Intelligence (IJCAI).

