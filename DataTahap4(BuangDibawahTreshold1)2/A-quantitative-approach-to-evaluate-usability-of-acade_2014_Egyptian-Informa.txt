This paper has been organized as follows. Section 2, provides a related work on the Usability. Following which, Section 3 provides the main objective of this paper. Section 4 provides detail report on the different methodologies used for Usability Evaluation of the websites. Analysis and the experimental results are provided in Section 5. Finally, Sec- tion 6, concludes our study.

In 2007 Kostaras and Xenos [10] employed Heuristic evaluation for usability assessment of Hellenic Open Univer- sity website. The evaluation was conducted in two phases by usability experts. In the first phase, the evaluators were encour- aged to navigate through the application to get a feel of the system. In the second phase, evaluators validated the implementation of each Heuristic rule derived by Nielsen. At the end all the evaluators submitted their individual reports describing their finding which included the rule violations that were detected by them. The detected violations for each heuris- tic rule are presented and discussed in this paper.

Daher and Elkabani in their research performed a qualita- tive study on usability of web portals in six Lebanese universi- ties [11]. Further they performed a usability study on Beirut Arab University (BAU) web portal. During the first part of the study, the researchers distributed questionnaires among students of six Lebanese Universities to gain an overview of the usability problems encountered. The questionnaire study measured nine common services on the web portals of the uni- versities. The researchers performed a comparative study of the usability of the common services available on the university web portals based on the results of the questionnaire. In the second part of the study, both qualitative and quantitative evaluation of usability of BAU web portal was performed. The students, faculty members and employees at BAU partic- ipated in the study. The researchers performed qualitative study by distributing a questionnaire among the participants. As part of the quantitative study, participants were asked to perform specific tasks while being videotaped, to gather

performance data including the time on task, webpage changes and the mouse clicks. After completing the tasks and filling the post-task questionnaire, the Six Sigma method was used to cal- culate the effectiveness, efficiency and satisfaction usability metrics. These usability metrics were then standardized to cal- culate the SUM usability metric to summarize the usability of the overall web portal services.

All the participants had to perform these five tasks on one of the 3 websites under study. Each of these tasks involved retrieving some information from the website. The participants recorded their usability sessions using Windows Media Encoder software that captures screen activity and shared the generated videos for our performance analysis.

A task was considered to have completed as soon as the participant finds the information from the website and pro- vides the same in his response. The time elapsed between the start and end of task was expressed in seconds. It is a measure of efficiency of the system.

Some participants agreed to take part in the Performance based evaluation. Others provided their consent to participate in the WAMMI questionnaire based evaluation. The partici- pants in the study were randomly divided into three groups (one corresponding to each website under study) and a between-subjects study was used to compare results for differ- ent participants.

Although these evaluation tools help in broadly determin- ing if a web page conforms to WCAG 2.0, passing the tool based checks does not necessarily guarantee accessibility. They should always be complemented with Manual accessibility testing which is a relatively more accurate method for deter- mining accessibility and helps in finding accessibility problems which are not found by testing tools by involving users with disabilities.

The data pertaining to the task completion time observed for each of the tasks across the three websites under study was measured. Time data was analyzed for tasks in which participants were successful as well as ones in which they were unsuccessful so as to obtain a relatively more accurate time data. The average amount of time taken in completion of the individual tasks was analyzed across the three websites. 95% Confidence intervals was calculated on time data and reported

Independent T-Tests were conducted to test the statistical significance of difference between the means among the three Institutes websites in terms of their Task completion time for each of the performed five tasks. It was done using MSTATC statistical tool developed by Dr. Russel D. Freed of Michigan State University, USA. The result of the analysis is presented below for individual tasks.

Post-Task Satisfaction rating was provided using After Sce- nario Questionnaire (ASQ). Participants filled ASQ post com- pletion of each task. The ASQ contains 3 questions, each with a 7-point rating scale (1 = Strongly disagree 7 = Strongly agree) with higher values indicating greater satisfaction associ- ated with the ease of use and the amount of time taken to com- plete the task.

In case of TASK 1 and TASK 2, ASQ scores varied signif- icantly between websites of Institute KGP and Institute K. The difference was also significant between websites of Institute KGP and Institute D. Institute KGP registered better ASQ score in both the cases.

In case of TASK 2, TASK 3 and TASK 5, the satisfaction levels across the three websites were seen to increase when time taken for task completion was less. The contribution of Task completion time to satisfaction levels was seen to be highest in case of Institute K among the 3 websites in TASK 3 (80.20%) and TASK 5 (87.90%). In case of TASK

On one of the scales (attractiveness), the website has scored 52.7, which is more than the average score as per the data con- tained in WAMMI database for other evaluated websites. In rest of the scales the scores have been observed to be near about the average score as per WAMMI database.

