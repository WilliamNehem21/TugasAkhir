The aim of partial evaluation (PE ) is to specialize a program w.r.t. part of its input, which is known as the static data[11]. The quality of the code generated by partial evaluation greatly depends on the control strategy used. Unfortunately, the existence of sophisticated control rules which behave (almost) optimally for all programs is still far from reality. Poly-controlled partial evaluation [15] (PCPE ) attempts to cope with this problem by employing a set of global and local control

rules instead of a predetermined combination (as done in traditional partial eval- uation algorithms). This allows using different global and local control rules for different call patterns (atoms). Thus, PCPE can produce specialized programs that are not achievable by traditional partial evaluation using any of the considered local and global control rules in isolation.

It is more user-friendly: existing partial evaluators usually provide several global and local control strategies, as well as many other parameters (global trees, com- putation rules, etc.) directly affecting the quality of the obtained solution. For a novice user, it is extremely hard to find the right combination of parameters in order to achieve the desired results (reduction of size of compiled code, reduction of execution time, etc.). Even for an experienced user, it is rather difficult to predict the behavior of partial evaluation, especially in terms of space-efficiency (size of the residual program). PCPE allows the user to simultaneously experi- ment with different combinations of parameters in order to achieve a specialized program with the desired characteristics.

Therefore, this step returns the set of resultants, i.e., a program, associated to the root-to-leaf derivations of these trees. The set of resultants for the computed SLD tree is called a partial evaluation for the initial goal (query). The partial evaluation for a set of goals is defined as the union of the partial evaluations for each goal in the set. We refer to [8] for details.

In addition to local termination, an abstraction operator is applied to properly add the atoms in the right-hand sides of resultants to the set of atoms to be partially evaluated. This abstraction operator performs the global control and is in charge of guaranteeing that the number of atoms which are generated remains finite. This is done by replacing atoms by more general ones, i.e., by losing precision in order to guarantee termination. The abstraction phase yields a new set of atoms, some of which may in turn need further evaluation and, thus, the process is iteratively repeated while new atoms are introduced.

Traditional algorithms for partial evaluation (PE) of logic programs (LP) are para- metric w.r.t. the global control and local control rules 1 . In these algorithms, once a specialization strategy has been selected, it is applied to all call patterns in the residual program. However, it is well known that several control strategies exist which can be of interest in different circumstances. It is indeed a rather difficult endeavor to find a specialization strategy which behaves well in all settings. Thus, rather than considering a single specialization strategy, at least in principle one can be interested in applying different specialization strategies to different atoms (call patterns). Unfortunately, this is something which existing algorithms for PE do not cater for. Poly-controlled partial evaluation (PCPE) [15] fills this gap by allowing the use of a set of specialization strategies instead of a predetermined one.

atoms are handled in later iterations of the algorithm. As a result, the set of atoms for which code is generated are not guaranteed to be independent. Two atoms are independent when they have no common instance. However, the pairs in H uniquely determine the version used at each program point. Since code generation produces a new predicate name per entry in H, independence is guaranteed, and thus the specialized program will not produce more solutions than the original one.

As mentioned in [15], one could think of a similar algorithm deciding a priori a control strategy to be applied to each atom. This algorithm would be more similar to the traditional PE algorithm, employing possibly different control rules for differ- ent atoms. Unfortunately, it is not clear how this decision can be made, so instead Algorithm 1 generates several candidate partial evaluations and then decides a pos- teriori which specialized program to use. Clearly, generating all possible candidate specialized programs is more costly than computing just one. However, selecting the best candidate a posteriori allows to make much more informed decisions than selecting it a priori.

In this experiment, let us choose the set of global control rules G={dynamic, hom emb}. The hom emb global control rule is based on homeomorphic embed- ding [8,9] and flags atoms as potentially dangerous (and are thus generalized) when they homeomorphically embed any of the previously visited atoms at the global con- trol level. Then, dynamic is the most abstract possible global control rule, which abstracts away the value of all arguments of the atom and replaces them with distinct variables. Also, let us choose the set of local control rules U={one step, df hom emb as}. The rule one step is the simplest possible unfolding rule which

always performs just one unfolding step for any atom. Finally, df hom emb as is an unfolding rule based on homeomorphic embedding. More details on this unfolding rule can be found in [14]. It can handle external predicates safely and can perform non-leftmost unfolding as long as unfolding is safe (see [1]) and local (see [14]).

In CiaoPP [7], the description of initial queries (i.e., the set of atoms of interest S in Algorithm 1 ) is obtained by taking into account the set of predicates exported by the module, in this case rev/2, possibly qualified by means of entry declarations. For example, the entry declaration in Listing 1(a) is used to specialize the naive reverse procedure for lists containing at least two elements.

As mentioned before, Algorithm 1 produces a set of candidate solutions. Of these, a few of them are pure, in the sense that they can be obtained via traditional PE (i.e., they apply the same control strategy to all atoms in the residual program), and the rest are hybrid, in the sense that they apply different specialization strategies to different atoms. In this section, we try to determine how heterogeneous are the fitness values of the different solutions obtained by PCPE.

The question of whether the solutions obtained by PCPE are heterogeneous w.r.t. their fitness values depends, in a great deal, on the particular choice of specializa- tion strategies to be used, as well as on the arity of the sets G and U of control rules. We can expect that by choosing control rules different enough, the candidate

Once we select an appropriate set of control rules for PCPE, we need to deter- mine whether the fitness of the solutions we obtain are heterogeneous. With this purpose, we have ran some experiments over a set of benchmarks and different fit- ness functions, in order to collect statistical facts such as Standard Deviation and Diameter that can help us to determine how different are the obtained solutions. In our experiments, as mentioned in Section 3, we have used a set of global con- trol rules G={dynamic, hom emb} and a set of local control rules U={one step, df hom emb as}. Besides, we used different fitness functions already introduced in [15]. For reasons of space, we will show some of the results obtained when using the following fitness functions:

speedup compares programs based on their time-efficiency, measuring run-time speedup w.r.t. the original program. When using this fitness function, the user needs to provide a set of run-time queries with which to time the execution of the program. Such queries should be representative of the real executions of the program 2 . This fitness function is computed as

These preliminary results are encouraging, showing that PCPE is capable of obtaining several heterogeneous solutions, most of them not being achievable by traditional partial evaluation. Similar results have been obtained for other fitness functions (not shown here due to lack of space). Though it is clear we need to prune the search space in order to make this approach practical, we should do it with care, in order to not to prune the good solutions.

Since the SPSR heuristic prunes the search space in a blind way, i.e., without making any evaluation of the candidates being pruned, there is a possibility of pruning the optimal solutions. In order to determine if this is the case, we have extended the experiments shown in Sec. 4, adding the results obtained when applying the SPSR heuristic to the example programs.

looking at the fitness value, we can see that the best solution is preserved, in spite of performing a blind pruning. But according to the Sols column, we are pruning away the redundant best solutions, and leaving only one of them. Clearly, the number of versions pruned by SPSR does not depend on the fitness function used, since the fitness function is used after generating all solutions in order to determine which candidates are the best ones.

With regard to the fitness value, it is interesting to note that the strategy do, i.e., dynamic as a global control and one step as a local control, produces a pro- gram that is very similar to the original one (probably having some variable and predicate renaming). This means that in situations where the original program has few predicates, it is difficult to obtain a residual program smaller than the origi- nal program. This is reflected in the benchmarks permute, nrev, relative and transpose, where the best control strategy is do and the fitness value is close to 1. However, note that PCPE still obtains better solutions in the cases of permute and relative, clearly through a hybrid solution.

