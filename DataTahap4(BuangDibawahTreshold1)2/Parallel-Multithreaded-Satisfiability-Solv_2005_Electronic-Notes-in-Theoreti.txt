This paper describes the design and implementation of a highly optimized, parallel multithreaded algorithm for solving the propositional satisfiability problem (SAT). SAT is a fundamental problem in the theory of computa- tion, one that has been studied extensively for more than four decades, ever since the introduction of the first algorithm for its solution in 1960 [5]. Eleven years later it became the first problem proven to be NP-complete, in a fa- mous paper by Cook [3]. Nowadays, the problem evidences great practical importance in a wide range of disciplines, including hardware verification [17], artificial intelligence [10], computer vision [2] and others. Indeed, one survey of satisfiability [6] contains over 200 references to applications.

In recent years, many sophisticated optimization techniques have been introduced to improve the performance of the core DPLL algorithm. These include watched literals, conflict analysis, non-chronological backtracking, vari- able state independent decaying sum (VSIDS) decision heuristics and restarts. Refer to [11,13] for a description of these techniques, all of which have been incorporated in the parallel solver presented here.

Note that with such dynamic partitioning of the search space, the work load is evenly distributed between the working threads, and these threads are all kept busy until the problem is solved. To minimize the thread waiting times and the time needed to find a new task, a list of available tasks is maintained. When a new open variable is introduced by a thread, the thread adds a description of a task that is associated with the new variable to the list of available tasks. Since the number of open variables is usually much larger than the number of working threads, the threads add new tasks to the list only until a certain threshold on the size of the list is reached. When a thread completes the execution of the current task, it chooses an available task from the list and removes the task from the list. The other threads promptly add a new task to the list, maintaining its size around the threshold. Due to the large discrepancy between the number of open variables and the number of threads, thread-waiting times on an empty list are very short. These times are restricted to the stage just after the beginning of execution of the algorithm, when the list is still empty, up to the time just prior to the completion of execution, when no more open variables remain.

that its current task is superfluous, since it leads to a conflict found by the current thread. The implementation of the termination signals may be com- plex and inefficient due to the need to implement synchronization mechanisms protecting the thread data from simultaneous access from different threads. Fortunately, if the distribution of conflict clauses is implemented, it becomes unnecessary to signal other threads explicitly. When the current thread finds a conflict, aside from backtracking over several variable assignments, it also generates a conflict clause that describes the reason for the conflict, and puts the clause on the list of conflicts. Once the other thread detects the presence of this clause on the list and initializes it in its own context, it will be forced to backtrack itself to avoid the conflict described in the conflict clause. Since the tasks are created based on the open variable found closest to the beginning of the corresponding guiding path, it is guaranteed that no more open vari- ables are on the guiding path of the thread, and the backtrack algorithm will terminate execution of the task once it reaches the beginning of the guiding path.

was used to collect data and to perform the analysis. The initial investigation of solver process behavior relative to the other processes in the system, load distribution of the threads inside the process and the distribution of func- tion calls inside the threads did not reveal the cause for the degradation of performance as the number of working threads increases. Independent of the number of working threads, the solver process took a large part of the total processor load, the load distribution between process threads was even, and the same function call patterns appeared in the performance bottlenecks inside the threads. Consistent with performance reports of other DPLL satisfiability solvers, for about 70% of total running time the threads were busy running boolean constraint propagation algorithms, while this number did not change with the number of working threads. The only thing that changed with the increased number of threads was the time that different functions spent wait- ing on synchronization locks for shared data structures. However, even in the case of four running threads, the total waiting time did not reach 10% of the total running time, a percentage that could not explain the performance

The other major distinction between this and previous works is that we have investigated the parallel execution of a SAT solving algorithm on a single multiprocessor workstation with shared memory architecture, as opposed to executing on a cluster of network-connected machines. In a typical industrial environment, it is usually difficult to dedicate a cluster of network-connected machines to the solution of a SAT problem, due to the lack of sufficient re- sources. On the other hand, it is quite common for one or more processors on a company workstation to be idle, since the operating system is unable to distribute the workload of a single-threaded SAT solving algorithm to other processors. However, while it is possible to achieve a linear speed-up on a cluster of network-connected machines, the effect of shared memory architec- ture on cache performance seemingly diminishes the advantages of parallel execution on a single multiprocessor workstation.

