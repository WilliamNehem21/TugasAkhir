The survey highlights some of the research topics which have attracted attention in the last two decades within the area of mathematical optimization of multiple objective functions. We give insights into topics where a huge progress can be seen within the last years. We give short introductions to the specific sub-fields as well as some selected references for further reading. Primarily, the survey covers the progress in the development of algorithms. In particular, we discuss publicly available solvers and approaches for new problem classes such as non-convex and mixed integer problems. Moreover, bilevel optimization problems and the handling of uncertainties by robust approaches and their relation to set optimization are presented. In addition, we discuss why numerical approaches which do not use scalarization techniques are of interest.

Multiobjective optimization, i.e., the optimization of multiple objec- tives at the same time, has been an active area of research since the early works of Edgeworth and Pareto. Edgeworth introduced an opti- mality notion for such problems in his book in 1881 (Edgeworth, 1881) and Pareto in his book on political economy in 1906 (Pareto, 1971). In mathematics, this branch of optimization started with a paper by Kuhn and Tucker (Kuhn and Tucker, 1951). Since about the end of the 1960s, research has intensively been made in this area. For a short historical overview see Eichfelder and Jahn (2016).

discussed. More recently, for linear multiobjective optimization prob- lems there is a book by Luc, 2016 . Another book written in the finite dimensional setting, but which focuses on nonlinear problems and addi- tionally covers interactive methods for decision making in multiobjec- tive optimization, is due to Miettinen, 1999.

In the last two decades, next to the above introductory books, sev- eral valuable books on more specific topics in vector optimization ap- peared. Many of those are part of the book series entitled Vector Op- timization with the series editor Jahn, which started in 2008 with the first book about adaptive scalarization methods (Eichfelder, 2008). The series contains publications in various sub-fields of optimization with vector-valued objective functions. So far, ten books have been published

problem in a decision making process. Such a selection is for instance reached by interactive methods or preference modeling. However, de- cision making is not the topic of this survey. Instead, we aim at finding all optimal solutions of the multiobjective optimization problem, which are, from a mathematical point of view, non-comparable.

The book Branke et al., 2008 edited by Branke, Deb, Miettinen, and Slowinski from 2008 covers interactive methods and evolutionary al- gorithms to solve multiobjective optimization problems. In the area of evolutionary approaches an intense progress has be seen since the fun- damental book by Deb (2001), but these approaches will also not be covered within this survey.

Finally, we would like to point out that since 2004 there has been a series of Dagstuhl meetings, with the first meeting organized by Branke, Deb, Miettinen, and Steuer, which bring together people from multi- criteria decision making, multiobjective optimization, and evolutionary algorithms. Until now, seven meetings have taken place which all cov- ered topics of recent research interest as Scalability in Multiobjective Optimization (Dag, 0000), Personalized Multiobjective Optimization, or Hybrid and Robust Approaches. A link to the websites of the ear- lier meetings can be found on the website of the most recent meeting (Dag, 0000).

non-convex problems are discussed in the literature. We will look into details of some of them later. However, only for a few classes of prob- lems, implementations of solvers exist which are freely available. The International Society on Multiple Criteria Decision Making (MCDM) lists (MCD, 0000) several freely available numerical algorithms for decision making and for multiobjective optimization. In the following we present some of them.

MOSQP makes use of derivative information of the objective func- tions and constraints to build quadratic models. Another well-known solver for constrained nonlinear multiobjective optimization problems, named Direct MultiSearch (DMS), aims to avoid exactly this. An al- gorithmic implementation with Matlab can be obtained by sending an email (DMS, 0000) and is freely available for academic use. The algo- rithm is based on Custodio et al. (2011) by Custodio, Madeira, Vaz and Vicente, which extends the idea of multisearch developed for single- objective optimization to multiobjective optimization.

However, in the last decade an increasing interest in numerical meth- ods without such scalarizations can be observed. While some of these methods still use scalarizations on subproblems, as for instance for find- ing new candidate points for weakly nondominated points in subregions of the image space, they avoid to first scalarize the overall problem and then to apply standard solvers from single-objective optimization. In this section, we discuss such approaches and collect arguments against a scalarization. But first we recall the basic ideas of scalarization appo- raches.

Many more of such scalarizations are known, and many of them can be seen as a special case of minimizing the very general Tammer-Weidner-functional, which is again related to the scalariaz- tion by Pascoletti and Serafini, c.f. Pascoletti and Serafini (1984). See Eichfelder (2009) for such relations and the recent paper (Bouza et al., 2019) by Bouza, Quintana and Tammer on a unified characterization of nonlinear scalarization functionals. Just recently, an extensive book on the Tammer-Weidner-functional appeared which presents all its useful properties and application fields, see (Tammer, Weidner, 2020) .

mization problem. Thus, in Thomann and Eichfelder (2019) the authors develop a tailored trust-region method to make use of the heterogeneity. Non-scalarization-based approaches might also have advantages for problems without such a heterogeneous structure but with purely ex- pensive functions. In Ryu and Kim (2014), and in Prinz et al., 2021, the authors work with model functions for expensive objective functions

Most of the extensions above (except the SQP extension) are for un- constrained optimization problems. In single-objective optimization one aims to find a stationary point, i.e., a point at which the gradient van- ishes. The well-known concept of stationarity from single-objective op- timization transfers as defined next, cf. Smale (1975). The transferred stationarity concept is used in a work on steepest descent methods for multiobjective optimization by Fliege and Svaiter (2000).

For non-convex problems a possible approach are scalarization methods, see, for instance, the method by Burachik, Kaya and Rizvi, Burachik et al. (2021). However, then the parameter dependent single- objective subproblems are non-convex and have to be solved to global optimality. Solving single-objective subproblems to global optimality

Among the decision space search algorithms, the method proposed by Mavrotas and Diakoulaki (1998) is the first branch-and-bound algo- rithm for solving mixed binary linear multiobjective problems. Also the method presented recently in De Santis et al., 2020 for solving convex mixed integer multiobjective problems is such a decision space method. An implementation of the algorithm from De Santis et al., 2020 is pro- vided in MOM (0000). The drawback of such methods is that in general the dimension of the decision space is much larger than the dimension of the criterion space. On the other hand, the decision space allows a more direct treatment of the integer variables and to transfer some of the techniques from single-objective optimization more directly.

In Stidsen et al. (2018), Stidsen and Andersen give a good overview on the literature and a discussion on the two different classes, decision space and criterion space methods. Moreover, the authors promote the use a hybrid approach and propose such an algorithm for linear mixed integer biobjective optimization problems.

exact algorithm to find all extreme supported solutions for a linear mixed integer multiobjective optimization problem. A more recent work on this topic by Przybylski, Klamroth and Lacour contains a good liter- ature review on such approaches, cf. Przybylski et al., 2019.

For non-convex single-objective optimization the generated lower bounds are used in general more directly than in Niebling and Eich- felder (2019) where they are only used for discarding tests. Using the lower bounds as in the single-objective setting was transferred recently to the multiobjective setting by Eichfelder, Kirst, Meng and Stein in Eichfelder et al. (2021a). As a result, the authors obtain a box-based coverage of the nondominated set, called enclosure in Eichfelder et al. (2021a). Recall that we denote the nondominated set

lems appear, one on the so-called upper level and one on the lower level. The optimization variable of the upper level is a parameter for the lower-level problem, and the optimal solutions of the lower-level problem influence the objective function value on the upper level. For a good introduction to the topic we refer to the book by Dempe, 2012. Due

tinen and Wiecek, Ruuska et al. (2012), this topic is thoroughly exam- ined together with an excellent literature survey on other contributions to this topic. It is still an open research question whether these refor- mulations can be used for developing numerical algorithms for bilevel problems with more than one or two variables on the upper level.

A first approach to extend minmax-robustness is due to Kuroiwa and Lee (2012). Doolittle, Kerivin and Wiecek, Doolittle et al. (2018), fol- low a similar approach. They replace each objective function of the un- certain multiobjective optimization problem by the worst case of the respective objective function values, i.e., they study the deterministic multiobjective optimization problem

might be a problem and imply a relaxation or restriction of the over- all problem. What is more, as discussed by Dempe and Mehlitz (2020), it can be a delicate issue if just locally optimal solutions of the scalar- ization are investigated. Further approaches are the characterization of the upper-level feasible set as solution set of specific multiobjective opti- mization problems, as proposed by Eichfelder (2010); Eichfelder, 2008. Bonnel and Morgan consider in Bonnel and Morgan (2006) a semivecto- rial bilevel optimization problem and propose a solution method based on a penalty approach. In Gebhardt and Jahn (2009), Gebhardt and Jahn propose to use a multiobjective search algorithm with a subdivi- sion technique. Approaches for solving multiobjective bilevel optimiza- tion problems by using evolutionary algorithms in combination with local solvers can be found, for instance, in Deb and Sinha (2010). In 2020, a survey on multiobjective bilevel optimization by Eichfelder ap- peared which summarizes the progress in numerical solvers in more de- tail, see Eichfelder (2020). Moreover, just recently, an implementation of the algorithm from Eichfelder (2010) was made publicly available MOB (0000).

In many real-world applications there are uncertainties in the opti- mization problems under examination which should be taken into ac- count when solving the problem. One way to deal with uncertainties is robust optimization. Then, the aim is to find solutions which remain feasible and of good quality for all possible scenarios, i.e., for all possi-

The author thanks the two anonymous referees for their very care- ful reading and their helpful comments on the first version of this manuscript. Moreover, the author thanks Dr. Tobias Gerlach, Dr. Ernest Quintana, and M.Sc. Leo Warnow for their valuable comments on an ear- lier version of this manuscript. The research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.

