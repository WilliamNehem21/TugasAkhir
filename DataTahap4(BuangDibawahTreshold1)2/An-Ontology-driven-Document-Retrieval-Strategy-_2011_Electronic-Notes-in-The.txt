Enterprises are inserted in a competitive environment in which knowledge is vital to survive in the current global market. Competition is no longer conceived as it was in traditional markets. In this global market, knowledge is considered an asset that has an economic value for an organization and a strategic resource used to increase productivity and offer stability in dynamic competitive environments [13].

We propose an extension to document annotation and retrieval strategies used by Onto-DOM. These strategies take in account the modifiers of nouns (e.g. adjec- tives) keeping all the semantics of a document. The rest of this work presents an integration among tools, techniques, and ontology-driven approaches for knowledge retrieval and document semantic annotation. The rest of the paper is organized as follows: Section 2 revises related work. Section 3 presents a KM system based on a distributed organizational memory [1]. Sections 4 and 5 describe strategies for document annotation and knowledge retrieval that use complex nouns and natural language queries. In Section 6 these strategies are evaluated. Finally, we present the conclusions.

In the semantic web area, SHOE [22] system and Ontobroker [15] were the first attempts to enable semantic annotation of web documents, allowing web page authors to manually annotate their documents with machine-readable metadata. Nevertheless, manual annotation is an expensive process and it often leads to a knowledge acquisition bottleneck. To overcome this problem, semi-automatic an- notation of documents has been proposed.

Cerno [21] is a framework for semi-automatic semantic annotation of textual data using light-wight analysis techniques. It applies a method, based on software code analysis techniques, for semantic annotations. Cerno divides the text into constituents, makes a parse tree that contains natural language document fragments (e.g. paragraph function, expression, word, etc.), and identifies e-mails addresses, phone numbers, etc. Then, the process recognizes concept instances based on an annotation scheme that includes a list of concept names and domain vocabulary. Finally, the annotated text is stored in an external database. Since Cerno does not use ontologies, the relationships between concepts are not considered, which loosing relevant semantics.

Gschwandtner et. al. [17] propose a semantic annotation system to annotate free medical text. This approach uses MMTx [4] which maps concepts from the Unified Medical Language System (UMLS) metathesaurus [4] to concepts in the text. It also provides an interactive editor that facilitates the annotation of doc- uments by MMTx, making it possible to create, visualize, and edit the semantic annotation of medical documents. This approach, unlike our own architecture, is domain dependent.

In this work, an organizational memory architecture is presented. In this architec- ture, organizations are composed of several functional units (areas, departments, groups, practice communities, etc.). Each functional unit is a knowledge domain that fulfills autonomy and coordination principles allowing a KM approach based on a distributed architecture. Autonomy capabilities enable each domain to manage lo- cal information, providing the possibility of choosing more appropriate perspectives,

modules are out of the scope of this paper. For more details, you can see [1,29,30]. Knowledge storage and retrieval strategies implemented in this architecture are driven by domain ontologies. These ontologies capture the domain knowledge in a generic way, and provide a commonly agreed understanding of a domain, which can be reused, shared, and applied by groups and applications. Ontological concepts are used as the core of annotation and retrieval strategies. They enable the query refinement and reasoning processes (a process of generalization/specialization using ontology classes and subclasses). An additional benefit offered by ontologies and exploited in this architecture is context representation. It provides a domain model that allows storing the context into knowledge objects, facilitating a later reusability

In the document annotation strategy implemented in the knowledge representa- tion module, each document of the corpus goes through a linguistic analysis process (tokenization, lemmatization, and Part-Of-Speech Tagging or POSTagging)[14]. At the end of this process, a tag with its syntactic nature (adjective, singular noun, verb, present time, third person singular, conjunction, etc.) is assigned to each element or token (words and symbols) in the document. Once the tagging process is finished, document concepts (DC ) are selected. The DCs selection is based on the following linguistic pattern: DC = {Noun+ | (Adjetive+Noun+} 8 .

With the unlinked DC list, each DC is compared with the ontological concepts. If some coincidence is found, that DC is marked as a candidate document descriptor, and it is linked to the concept. Such DC is eliminated from the unlinked DC list.

If there is no coincidence, the head noun of such DC is compared with the onto- logical concepts. If some coincidence is found, that noun is marked as a candidate document descriptor, and it is linked to the concept. The DC is eliminated from the unlinked DC list.

For each unlinked DC, a set of synonyms of the head nouns of DCs are searched in WordNet. The head nouns of DCs are replaced by these synonyms, and the ob- tained DCs are compared with concepts. If some coincidence between a replaced DC and a concept is found, the original DC is marked as a candidate document descriptor. It is linked to the concept, and the original DC is eliminated from the unlinked DC list.

For each unlinked DC, a set of hyperonyms of its head nouns is searched in WordNet. These hyperonyms are replaced by the head nouns of DCs and, the obtained DCs are compared with the concepts. If some coincidence between an obtained DC and an concept is found, the original DC is marked as a candidate document descriptor. It is linked to the concept, and the original DC is eliminated from the unlinked DC list.

For each unselected QC, a set of synonyms of the head noun of QCs is searched in WordNet. These synonyms are replaced by the head noun of QCs, and the obtained QCs are compared with the concepts. If a coincidence between a re- placed QC and a concept is found, the concept is selected, and the original QC is eliminated from the unselected QC list.

Finally, the strategy selects only instances and concepts that provide an answer to the wh-word of the query (who: a person, where: a place, etc), and then, the documents associated with these instances and concepts are retrieved. The retrieved documents are sorted out so that the first documents have more precise answers to the query. This order is based on the percentage of descriptors that have coincided, and also, if these coincidences were with instances (more important descriptors), concepts, synonyms, or hyperonyms (less important descriptors).

A tourism enterprise was considered as a study case, which includes a knowledge domain: Africa travel. An extension and specialization of the travel ontology 12 , including specific terms employed in these domains, were used. This ontology is formed by 267 concepts related to the vocabulary used in the domain. The corpus is composed of 125 documents, randomly selected from the Internet, with an average of 9187 words per document.

In this section, we evaluate the knowledge retrieval layer. For this reason, 50 questions are made. However, not all of the questions are shown in this paper due to space reasons. For each processed question, each retrieved document was classified as follows: contain an answer (C) or not contain an answer to the query

With a MAP value of 0.895, the proposed strategy ensures that relevant docu- ments are in the top of retrieved documents in most cases. Calculating in ascending order the average of precision value in each point at which each relevant document is retrieved, and then calculating the average of this average of precision values for a set of queries (i.e. the MAP value), a high value only is obtained if the best results are in the top positions of the answer provided by the system, aim sought in any information retrieval system.

