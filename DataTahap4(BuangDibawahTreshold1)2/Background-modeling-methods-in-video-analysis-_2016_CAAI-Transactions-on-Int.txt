Foreground detection based on video streams is the first step in computer vision applications, including real-time tracking [1,2] and event analysis [3e6]. Many researchers in the field of image and video semantics analysis pay attention to intelligent video surveillance in residential areas, junctions, shopping malls, subways, and airports which are closely associated with foreground detection [7e9]. Background modeling is an efficient way to obtain foreground objects. Though background modeling methods for foreground detec- tion have been studied for several decades, each method has its

Over the past few decades, a large number of background modeling methods have been proposed to identify foreground objects in a video. They generally share the same following scheme [2,12]: they utilize the first frame or previous frames to build a background model, and then compare the current frame with the background model to detect foreground ob- jects, and finally they update the background model. Various background modeling methods can be categorized into pixel- based, region-based, and hybrid methods. Background modeling methods can also be categorized into parametric and nonparametric methods. One of the most famous pixel-based parametric methods is the Gaussian model. Wren et al. [13] first proposed  modeling  the  background  at each  pixel

[1] and Panahi et al. [36] provided a comparison for various pixel-based background modeling methods. Their evaluation compared background modeling methods and described the challenges that background modeling methods need to deal with. Cheung et al. [81,82] evaluated six background modeling methods using traffic monitoring videos under different weather conditions. This comparison was only conducted on four grayscale test datasets. Parks et al. [37] and Brutzer et al.

Illumination changes are not only just progressive, but sudden once-off illumination changes also often occur in scenes. For example, a sudden switch of light or sunlight blocked by clouds strongly affect the appearance of the background model. Therefore, the ability to quickly adapt to sudden illumination changes is a key to evaluate the back- ground modeling methods.

The GMM algorithm is sensitive to illumination changes. It defines a pixel value within 2.5 standard deviations of a dis- tribution. This threshold can ensure that performance of the algorithm is only slightly perturbed by illumination changes which is extremely useful when different regions have different lighting. In order to minimize the effects of bright- ness changes, SOBS uses the HSV color space and SACON uses a normalized color space. The main reason is that RGB color space is sensitive to changes of illumination. In addition, a long term background model and a short term background model are combined in KDE to quickly adapt to changes in the scene to achieve sensitive detection and low false positive rates. CodeBook uses a color model to perform a separate evaluation of color distortion and brightness distortion. The motivation of this model is that background pixel values lie along the principal axis of the codeword along with the low and high boundaries of brightness, since the variation is mainly due to brightness.

To deal with the dynamic background, GMM and SOBS assume that the intensity values of a pixel are modeled by multimodal distributions. In contrast to a single unimodal model, multimodal models usually have high time complexity. Vibe and SACON are sample-based methods. They use the difference between new pixels and the sample to discriminate a moving background. SACON uses a selective strategy to update the background model. It can not only efficiently cope with lighting changes but can deal with objects appearing or fading in the background. It can incorporate the moved/ inserted background object into the background model. For example, if a background object is moved to a new place, or a new background object is inserted into the background scene, this method can adaptively add the corresponding pixels of the background object to the background model [55].

Among region-based methods, texture or descriptor-based methods model background changes using descriptors pro- vide reliable information to represent dynamic backgrounds and illumination changes. A discriminative texture called local binary pattern (LBP) [77] was used by Heikkila et al. [67] to model backgrounds. Zhu et al. [78] proposed a corner-based

The idea that a cast shadow certainly darkens the back- ground while a moving object can darken it or not is used in the SOBS algorithm to detect shadows [61]. Specifically, in a shadowed area, there is significant illumination variation, but only a small color variation. If a pixel belongs to the back- ground model but has been darkened by a shadow, then it belongs to the shadow cast by an object in the scene. KDE and SACON separate color information from lightness information and use the chromaticity coordinates to suppress shadows. However, using the chromaticity coordinates has the disad- vantage of losing lightness information which is related to the difference in whiteness, blackness, and grayness between different objects [62].

Vibe and SACON only need to compare the current pixel with a small number of close background samples rather than most of samples in the background model, so they can weaken the effects of noise in the model. Two factors explain why Vibe has a high resilience to noise. The first factor is that the design of the Vibe method allows the pixel model of Vibe to be exclusively comprised of observed pixel values. The pixel models of Vibe automatically adapt to noise, as they are constructed from noisy pixel values. The use of the pure conservative update scheme in Vibe is the other factor. By relying on pixel values exclusively classified as background, the model update scheme of Vibe prevents the inclusion of any outlier in the pixel models [24].

The traditional GMM has several advantages. It does not need to store a set of input data in the running process. GMM uses the mean value and covariance to measure the pixel. This means that each pixel has its own unique threshold without the constraint of a unified global threshold. The multimodality of GMM allows it to deal with multimodal backgrounds caused by waving trees and gradual illumination changes.

A new pixel xt, is checked against the exiting K Gaussian distributions, until a match is found. A match is defined as a pixel value within 2.5 standard deviations of a distribution. If none of K distributions match the current pixel value, the least probable distribution is replaced with a distribution with the current value as its mean value, an initially high variance, and low prior weight. The prior weights of the K distributions at time t, ui,t are updated as,

example, cars might enter or leave a parking area on a street surveillance application, and the system can detect the fore- ground. Kim et al. [28] also introduced another structure similar to codewords called cache book to avoid detecting false background or foreground pixels because codebook cannot be adapted to changes in the scene [53].

GMM with just a few Gaussians cannot accurately model quickly varying backgrounds. It depends on the learning rate to adapt to background changes, and thus for a low learning rate, it is difficult to detect a sudden change in the background. For a high learning rate, slowly moving object will be absor- bed into the background. To solve these problems, KDE was exploited [21]. It can quickly adapt to changes in the back- ground and detect the foreground with high sensitivity. How- ever, KDE cannot be used when long-time periods are needed to sufficiently sample the background.

The CodeBook algorithm was intended to sample values over a long time, but there are no parametric assumptions. It can capture background motion over a long period of time under limited memory which allows it to encode dynamic backgrounds. In addition, it can efficiently cope with local and global illumination changes. In contrast to GMM, it properly deals with moving foreground objects in the scene during the initial training period. However, there are some problems that codebook cannot cope with. For example, if the color of foreground pixels is similar to that of background pixels, it will incorrectly segment the foreground. Though it can tune

data points that are within error tolerance Tr of a mode [56] and Tn is influenced by sample size N. If N is large, Tn should also be large. Thus, Tn can be effectively set to tTrN where t is a constant and is empirically determined.

xi m i	1, ..., N, N < t , where xt(m) is an observation of a pixel m at time t. Each observation xt m	xC1 m , ..., xCk m has k channels. For each sample in the cache, the sample

When the value of TOM at a pixel is larger than threshold TTM, then the pixel is classified as a background pixel. Once the value of the pixel is assigned to the background, the value of TOM will be set to zero. In fact, TOM is used to record how many frames a pixel has been continuously classified as a foreground pixel.

If the TOM value of an object is higher than TTM, this object is judged as a static object and all its pixels are used as the back- ground samples. If a blob is judged to be moving, the TOM values of all pixels are set to zero. If a blob is judged to be static, the TOM value of all pixels of that blob are increased by 1. If the TOM value of an object is higher than TTM, all its pixels are

Wang and Suter [55] proposed to keep a cache (or history) of the last observed background samples for each pixel and classified a new pixel value as background if it matches most of the values stored in the pixel model. This method avoids the issues related to deviations from an arbitrarily assumed density model, but when a first-in-first-out scheme is used to update the background model, the method fails to avoid issues. Finally, to deal with lighting changes and objects appearing or fading in the background, two additional strategies (pixel-level and blob-level) are used to handle entire objects. When a part of an object is moving and other parts are static, the static part will be continuously classified as the foreground. Then, it will be updated as background at the pixel-level, but the moving regions will be judged as the foreground or background which

The algorithm utilizes the first frame of the video to initialize the background model based on an assumption the same as [59], i.e. neighboring pixels share a similar temporal distribution. The authors used t 0 to index the first frame and NG(x) is a spatial neighborhood of pixel location x, therefore

which prevents its background pixel model from being upda- ted. To address this problem, Vibe uses the spatial consistency via a background sample propagation scheme. According to this scheme, when a pixel has been updated, the algorithm uses this value v(x) to update the neighborhood pixel samples in M( y2Nc(x)).

Hofmann et al. [27] combined Vibe with SACON to create a novel pixel-based adaptive segmenter (PBAS) method for foreground segmentation. The PBAS method uses a history of N image values as the background model and uses a random update rule similar to Vibe. In contrast to Vibe, PBAS does not treat parameter values as fixed parameters, but instead as adaptive state variables, which can dynamically change over time for each pixel.

When pixel xi is classified as a background pixel, the background will be updated and a neighboring pixel yi which might be a foreground pixel can be updated as well. This means that foreground pixels at the boundary will gradually be included into the background model. However, it depends on the update parameter T(xi). T(xi) is updated as follows

We evaluated the performance of background modeling methods at the pixel-level. Thus, we considered foreground detection as binary classification of each pixel. The correct- ness of this classification is expressed by the framework of the CDnet 2014 challenges [76]. The framework implements the following seven different measure metrics: recall, specificity, false positive rate (FPR), false negative rate (FNR), percentage of wrong classification (PWC), precision, and F-measure. Let tp denote the number of true positives and tn denote the

If positive is regarded as foreground and negative is regarded as background, then tp gives the number of correctly detected foreground pixels, and tn gives the number of correctly identified background pixels. In contrast, fn is the number of pixels that are falsely marked as background whereas fp is the number of pixels that are falsely detected as foreground. The method can trivially optimize one of them by ignoring the other one with precision and recall conflict to each other. In Section 5, the values of the seven measure metrics are given in details.

GMM. The programs of Vibe and PBAS methods were pro- vided by the authors of Vibe and PBAS. We used the best parameters of two methods suggested by the authors. For the KDE method, we used the implementation available in the BGSlibrary. We adjusted the parameters by the suggestion in the BGSlibrary. Because the codes of SACON, SOBS, and CodeBook methods are not available, we finished the code by ourselves, and selected the optimal parameters following the paper of the authors.

We evaluated the eight state-of-the-art background modeling methods discussed in Section 3. We tested these different background modeling methods and did not use any pre-processing and post-processing schemes. We also present the amount of memory as well as the computational time used by each method.

than 20%. In addition, the FNR scores of AGMM and PBAS are also greater than 60%. Hence, in order to strengthen the results of detection, the background model needs to be able to quickly respond after the camera rotates or zooms.

The work reported in this paper is partly supported by NSFC under grants Nos. 61370163, as well as the Shenzhen Municipal Science and Technology Innovation Council under grant No. JCYJ20140904154630436. Thanks to Dr. Edward C. Mignot, Shandong University for linguistic advive.

