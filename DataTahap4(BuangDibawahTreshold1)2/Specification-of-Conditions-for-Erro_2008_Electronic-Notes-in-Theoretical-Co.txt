experience in the area of test and verification of avionics controllers all kinds of faults, errors and anomalies have been observed and detected by our workgroup. The obvious next step is to classify the encountered faults. Based on the fault models commonly used in semiconductor fault diagnostics[1][6] we applied these models and methods and provide a complete strategy for locating faults in distributed embedded systems within their environments. The methods, techniques and tools illustrated here rely on preceding investigations, which have been documented in [7].

Grey-box tests with respect to inter-controller communications: During system integration testing, network monitors are typically available to record at least a portion of the data exchange between communicating controllers. For example, AFDX monitors and ARINC 429 monitors can be used to record snapshots or specific types of data packages. Some communications, however, often cannot be observed, such as, for example, the data exchange between redundant fault- tolerant controllers.

The fault tree[8][11, pp. 43ff] constructed in Step 3 depicts the possible error hy- potheses, together with the boundary conditions which must hold in order to make a hypothetical error cause the observed failure on the interface between SUT and testing environment. The error classification used for each component follows the fault models introduced in [7, pp. 13ff] and the fault tree construction technique described in [7, pp. 6ff]. In the diagnostic procedure described here we omit the possibility of an external intruder (see [7]) because we are dealing with a closed system whose components are well-known.

If the hypothesis holds, an additional test stimulating v0 can be executed. If it passed then this implies that v1 was not lost within the SUT. In our case, the hypothesis is fulfilled by the SUT implementation. Therefore an additional test can

expected to mark the sensors as failed. If this occurs, we have proven that sensor state changes of SD5,6 are not lost within the SDCU. Since the SUT implementation really shows the expected messages, a signal deletion error can be excluded.

In our case, we perform a test where SD5 stays continuously in state ALARM, while the state of SD6 is toggled between STANDBY and ALARM. Then, in a correctly operating SUT, an output compAlarm[2]=1 should occur if and only if SD6 is in state ALARM. In the following test log, it can be seen that no compartment alarm for Comp2 is raised because only sensor SD5 is in state ALARM whereas sensor SD6 remains in state STANDBY. This is the expected behaviour.

In our case, all fault hypotheses but the potential stuck-at-0 fault can be falsi- fied by means of additional tests. The internal structure of the SDCU must be taken into account, so that the global input variables sensorSDSAlarm[] of the processMessages() method become visible. An additional unit test of this method reveals the presence of a stuck-at-0 fault within this method.

Our experience has shown that it is possible to locate any kind of fault when follow- ing the presented procedures (and refinements). Being state of the art for semicon- ductor error diagnostics, to our knowledge the presented strategy for fault detection is not yet commonly used within the area of distributed embedded systems. Through the tight integration of the procedures with the tool chain a reliable and efficient way of testing is introduced. The tool chain, consisting of the RT-Tester, its user interface (RTTUI) and the Interval Analyser, can be supplemented by tools 10 like Relex FTA or Isograph FaultTree+ for fault tree analysis.

