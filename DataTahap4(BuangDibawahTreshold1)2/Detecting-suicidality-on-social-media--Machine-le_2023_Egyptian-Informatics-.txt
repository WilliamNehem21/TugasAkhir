The rest of our article is divided into various sections. Section 2 dis- cusses the related work done in the domain of the detection and prevention of suicidality. Section 3 discusses the proposed methodology, which contains various subsections: data collection, data pre-processing, proposed novel feature engineering mecha- nism and finally, training of machine learning algorithms. Section 4 elaborates on the results and discussion. Section 5 compares our work with the previous research. Section 6 provides the conclusion and future scope of the work.

word count. Mbarek et al. [35]developed a suicide user profile detection model using a set of features that included a linguistic, emotional, facial, timeline, and public features. Mbarek et al. [36], in their other study, applied different machine learning algo- rithms to solve the suicidal user prediction problem using a rich set of features like Emotional features, Temporal features and Account features that have been effective in detecting suicidal users. The feasibility of their method was studied on people who committed suicide, and the results were shown to be in line with expectations.

The literature survey indicated that work done in the field of data mining for predicting suicidal ideation on social media and its prevention is minimal that needs a lot of effort. Data scarcity is also a big problem due to the privacy and ethical issues related to this research. Moreover, the above literature mostly focuses on binary classification and uses ordinary feature extraction tech- niques. Our work made a novel effort to collect big data related to suicidal tweets using the API of Twitter and Reddit and also focused on a feature extraction mechanism for the extraction of rich features. Then three machine learning algorithms were trained to classify the tweets into three classes of distress using the methodology discussed in Section 3.

The data was collected from two famous SNS: Twitter and Red- dit through their APIs. We neither collected any identifiable human data from the social posts nor saved any such information. A ran- dom identifier was assigned to each post. Twitter API was used to collect the tweets using the phrases or words as used in previous research [11,14,26] and other words suggested by the mental

Data extracted through social media contains very noise. The established methods [32] like tokenisation, stop word removal, and lemmatization was applied to filter the data to use it for machine learning. Moreover, the language of suicidal ideation lacks lexical and syntactic patterns. Therefore, there is a need for hand engineering to analyze a set of features. Feature engineering is pro- posed to differentiate between various levels of distress. Various features that were used in our model are as under:

thinner lines indicate a weaker relationship. The strength of the relationship between topics is determined by the degree of overlap between the words that make up each topic. If two topics share many common words, then they are likely to be strongly connected, and the line between them will be thicker. On the other hand, if two topics share few common words, then they are likely to be weakly connected, and the line between them will be thinner.

Suicidal ideation Detection is treated as a multi-class machine learning problem. The dataset we used to train our model consists of only two columns; the title of our text and the label. The prob- lem is in the same way as formulated by [18]. On a corpus consist-

and ensemble learning algorithms for text classification [40,41] viz. Support vector machine, Random forest and Extreme gradient boosting algorithm to train our multi-class classification model. The model is further validated through 5-cross validation tech- nique. The cross-validation approach reduces the bias and variance as the majority of the dataset is used for training the model, and most of the data is also used for testing the model. The empirical evidence suggests that 10-fold cross-validation and 5-fold cross- validation is generally preferred, but it is not a thumb rule as k can take any value.

ance between Precision and Recall & also when the dataset is imbalanced, having a large number of actual negative values. Usually, for learning models, false positives and false nega- tives provide an important role. The F1 score tries to give more weight to these values and contribute in minimizing the impact of true negative values.

Prediction models developed for binary classification and multi- class classification can be deployed as a product that can gener- ate the intervention messages. People can chat anonymously with mental health experts/therapists without leaving their homes and worrying about social stigma. When the user will give feedback about how intervention messages helped them, it can be channelized to improve the model.

