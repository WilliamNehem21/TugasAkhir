Second, techniques like model checking and theorem proving are performed on abstractions. These are given in some form of formalized transition sys- tems, or, more general, behavior models. 3 The assumption then is that the piece of software that is to be checked is embedded into a correctly functioning environment that meets the tacit assumptions in the model. Now, the environ- ment may be very complex, and formal verification technology cannot ensure whether or not the environment behaves the way it is anticipated in the system to be checked. The point is that verification technology like model checking or deductive theorem proving necessarily operates on abstractions. (Our notion of) testing operates on actual devices in their actual environments, and both activities are necessary.

The contribution of this paper is a catalog and discussion of applicable ab- stractions for model-based testing. We also relate models for testing purposes to other models in the development process. Sec. 2 sheds light on the nature of abstraction in the context of model-based development and model-based testing. Sec. 3 reviews abstractions for testing that are used in the literature. Sec. 4 discusses limitations of different abstractions, and Sec. 5 concludes. Related work is cited in the respective context.

The abstraction gap that is resolvable by compilers and linkers is more or less specific to a domain. While the concept of procedures is common to all programming languages, the Swing API is restricted to the domain of GUI programming, the ISO-OSI stack applies to communication, and the MDA is arguably concerned with business information systems rather than embedded real-time systems. It is certainly one of the most challenging and demanding tasks to develop abstraction techniques which are more or less domain specific and can be automatically translated to the concrete level using compilers, linkers, and the like.

To summarize, abstractions occur in two forms. They can be simplifica- tions where missing information can be inserted automatically, and they can be simplifications where information is deliberately missing in order to keep the model simple. Simplifications tend to be domain-specific, and the ultimate goal of model-based development seems to lie in finding these abstractions that are applicable to all systems of a given domain.

By abstractly specifying the crucial parts, e.g., those that are error-prone by experience, in rather small test models, one gains the advantages of small and manageable models. Models that can be used for full production code generation, on the other hand, can be seen as implementations, and it is a dubious endeavor to extract code and test cases from the same model.

The case study described in [11] concentrates on testing the protocols be- tween a smart card and its environment, a terminal. Therefore the model abstracts from the complex realization of all cryptographic functions imple- mented by a smart card. These functions and their responses are represented only symbolically by yielding data of type encryptedData when a command encrypt(data) is issued. No cryptographic computations are performed in the model. Instead, these computations are performed at the level of the driver component (see above).

The approach described in [6] uses separate models for testing different functionalities of the POSIX standard. The first model was developed for testing the byte range locking interface fcntl. This interface provides control over open files in order to deal with processes which are accessing the files. The model restricts the POSIX standard by allowing the extension of a file only once. The paper mentions a second model which was developed for testing the POSIX fork() operation.

main, an operation including its operands is represented by a byte string at the concrete level. In the model, an operation and its operands are conveniently symbolized by a string (a name). With this kind of model, the behavior of the smart cannot be tested directly if it receives byte string which are for example one byte too short or too long, respectively. It is up to the test engineer to decide whether to cope with such illegal input at the level of the model, or at the level of the driver component.

Intense data abstraction can lead to information loss that cannot be coped with for test case generation. For example we recall the smart card model abstracting from file contents [11] already discussed in Sec. 2. With this model only static properties like file length but not the dynamic evolution of file contents could be verified.

It is hard to detect feature interaction when functional abstraction is ap- plied to build separate models for testing distinct functionalities. For instance, in [6], separate models are used to test different operations of the POSIX stan- dard. These models help to verify the correct functioning of these operations in a stand-alone manner, but leave open the detection of unmeant behavior caused by feature interaction of these operations.

Finally, problems can arise if temporal abstraction is intensively used in the model. Obviously, in the domain of distributed real time systems a rigorous use of temporal abstraction can prohibit the detection of faults which stem from the intricate interleaved timing behavior of the separate components. As a counterexample, in [5], temporal abstraction is explicitly not used to test a processor. In order to trace generated test cases and to check the expected performance a clock cycle in the model corresponds exactly to a clock cycle in the real processor design.

Nevertheless, w.r.t. these limitations, we believe that model based testing is one of the most promising methodologies which will scale up for verification of complex systems in the near future and additionally provide a well struc- tured process for increasing the quality of hard- and software systems. Note that some see testing as model-based by definition: testing is always performed with a more or less explicitly defined intended behavior, i.e., a model.

Many activities of software engineering involve abstractions. Today, abstrac- tions are predominantly used as language constructs (e.g., procedures), trans- parently moved into the runtime environment (garbage collectors), used in the form of interfaces to libraries, components, or communication infrastruc- ture, and as architectures. Abstractions related to the behavior of a system

On the one hand, the specification describes the system under development in an abstract and comprehensive way. This is usually done in an informal and incomplete manner. The informal and incomplete specification is needed to build test models in the first place: test models are then refinements of the specifications. On the other hand, test models abstractly implement only parts of the more comprehensive specification, but these parts are implemented completely and unambiguously (functional abstractions, cf. Sec. 3). Test models can then be perceived as a supplement to specification documents which completely specifies the crucial parts of the system for verification. In principle, specifications and test models could be built at the same level of abstraction, completeness, and precision, but then one must solve the question whether a supplier or an OEM builds the model. This is, for instance, the situation in the automotive industries.

