Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 325 (2016) 221–236
www.elsevier.com/locate/entcs
Programs as Data Structures in λSF -Calculus
Barry Jay
Centre for Quantum Computing & Intelligent Systems School of Software
University of Technology Sydney Sydney
Australia

Abstract
Lambda-SF-calculus can represent programs as closed normal forms. In turn, all closed normal forms are data structures, in the sense that their internal structure is accessible through queries defined in the calculus, even to the point of constructing the Goedel number of a program. Thus, program analysis and optimisation can be performed entirely within the calculus, without requiring any meta-level process of quotation to produce a data structure.
Lambda-SF-calculus is a confluent, applicative rewriting system derived from lambda-calculus, and the combinatory SF-calculus. Its superior expressive power relative to lambda-calculus is demonstrated by the ability to decide if two programs are syntactically equal, or to determine if a program uses its input. Indeed, there is no homomorphism of applicative rewriting systems from lambda-SF-calculus to lambda-calculus. Program analysis and optimisation can be illustrated by considering the conversion of a programs to combi- nators. Traditionally, a program p is interpreted using fixpoint constructions that do not have normal forms, but combinatory techniques can be used to block reduction until the program arguments are given. That is, p is interpreted by a closed normal form M. Then factorisation (by F) adapts the traditional account of lambda-abstraction in combinatory logic to convert M to a combinator N that is equivalent to M in the following two senses. First, N is extensionally equivalent to M where extensional equivalence is defined in terms of eta-reduction. Second, the conversion is an intensional equivalence in that it does not lose any information, and so can be reversed by another definable conversion. Further, the standard optimisations of the conversion process are all definable within lambda-SF-calculus, even those involving free variable analysis.
Proofs of all theorems in the paper have been verified using the Coq theorem prover.
Keywords:  lambda-calculus, SF-calculus, self-interpretation, xi-rule


Introduction
λ-calculus [1] provides a completely general account of the extensional behaviour of functions, of all that can be discovered by evaluating them. This may be enough for applications, but the implementation of programming languages requires access to the internal structure of programs. As this is not possible from within the pure λ- calculus, meta-level analysis is commonly required. For example, self-interpretation

1 Thanks to Thomas Given-Wilson, Neil Jones, Jens Palsberg and Jose Vergara for helpful discussions as this work gestated, and the anonymous referees.
2 Email:Barry.Jay@uts.edu.au

http://dx.doi.org/10.1016/j.entcs.2016.09.040
1571-0661/© 2016 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

M, N, P := x | S | F | λx.M | MN 
(λx.M )N −→ {N/x}M SMNP −→ MP (NP )
FOMN −→ M	(O is S or F )
FPMN −→ NP| [P	(P is a compound of P| and [P ).
Fig. 1. λSF -calculus
of λ-calculus [12,17,2,14,15,4,3,18,9], usually begins by applying a meta-function quote which converts an arbitrary λ-term into a data structure, whose internal structure can be queried at will.
Recent work suggests an alternative approach, using calculi that support a more general class of queries. Pure pattern calculus [8,5] uses pattern matching to define generic queries of data structures built from arbitrary constructors. However, it is unable to analyse pattern-matching functions themselves. SF-calculus [7] can query any closed normal form by using its operator F to reveal its internal structure, e.g. the components P1 and P2 of a closed normal application P1P2. However, it does not provide first-class support for λ-abstraction or any other mechanism for binding variables.
This paper shows how to factorise abstractions in a new calculus, the λSF - calculus, by converting them to combinators when it is safe to do so, i.e. when this will not break any redexes in the body of the abstraction. The syntax and reduction rules of λSF -calculus are just those of λ-calculus and SF -calculus, as given in Figure 1, on the understanding that the compounds now include some abstractions as well as some applications. The result is a proper extension of λ- calculus in the sense that there is no function from λSF -calculus to λ-calculus that preserves its structure as an applicative rewriting system.
This expressive power can be used to support arbitrary queries of closed normal forms. In this sense, we can identify the data structures with the closed normal forms. What about programs? The standard interpretation of programs does not yield normal forms since recursion is modeled by a fixpoint function that does not have a normal form. However, traditional combinators can be used to identify programs, even recursive ones, with closed normal forms. Hence, we can identify the programs with closed normal forms, to get
programs = closed normal forms = data structures.
That is, programs can be represented by terms that are simultaneously functions, ready to act on arguments, and data structures, ready for analysis and optimisation, and this without any need for quotation. Except when justifying this equation, we will identify the programs with the closed normal forms.
This provides a more flexible foundation for computation than any of the tradi- tional models, as these emphasise only one aspect of a program’s nature. In partic- ular, λ-calculus emphasises its functional aspect, while Turing machines emphasise

its structure, as a string of symbols on a tape. This new flexibility suggests fresh approaches to many issues in theory and practice, especially the implementation of programming languages.
The structure of the paper is as follows. Section 1 is the introduction. Section 2 introduces λSF -calculus and its basic properties. Section 3 shows that equality of programs is definable. Section 4 defines extensional equivalence. Section 5 shows that there is no homomorphism of applicative rewriting systems from λSF -calculus to λ-calculus. Section 6 show how to represent recursive programs as closed normal forms. Section 7 converts programs to extensionally equivalent combinators. Sec- tion 8 optimises the conversion by program analysis. Section 9 converts programs to combinators in a way that preserves intensions as well as extensions. Section 9 discusses the proof verifications in Coq. Section 10 suggests some fresh approaches to existing issues. Section 11 draws conclusions.
λSF -calculus
The terms and reduction rules of λSF -calculus are given in Figure 1. The terms (meta-variables M, N, P, . . . consist of variables x, y, z,..., f, g,.. ., the operators S and F , abstractions λx.M with bound variable x and body M , and applications MN of M to N . The reduction rules for λ and S are standard. The rules for F have the same high-level semantics as in SF -calculus in that F branches according to whether its first argument P is an atom, i.e. an operator, or a compound. If P is an atom then return the first branch: if P is a compound then apply the second branch to its two components. The intention is that the compounds are terms whose decomposition into components does not break any redexes. They are, in a sense, head normal forms. The technical point is that there is a syntactic test for this property, even in the presence of abstractions. The reflexive, transitive closure of
−→ is denoted −→∗.
Compounds
In combinatory calculi, the compounds are all the partially applied operators. For example, in SF -calculus, the compounds are all terms of the form SM or SMN or FM or FMN . These forms are compounds in λSF -calculus, too. All other compounds of λSF -calculus are abstractions λx.M whose decomposition is safe because either M is already an atom or compound, or outermost reduction in M awaits the instantiation of x, i.e. x is active in M in the following sense.
Define the set active(M ) of active variables of a term M to be a set that has at most one element, that is defined by the pattern-matching function in Figure 2 (active(M ) − {x} removes x from active(M )).
Here are some examples of compounds. The body of λx.x y has x active. The body of λx.λy.x has x active. The body of λx.λy.y is a compound. The body of λx.F is an atom. The body of λx.Fx is a compound. The body of λx.FxM is a compound. The body of λx.FxMN has x active, since F is an intensional operator that needs to know the value of x to reduce. The body of λx.λy.F (FxMN )PQ has

active =
| x ⇒ {x}
| O ⇒ { }
| λx.M ⇒ active(M ) − {x}
| OM ⇒ { }
| OMN ⇒ { }
| SMNP ⇒ { }
| FMNP ⇒ active M
| MN ⇒ active M otherwise. Fig. 2. Active Variables
x active.
Star Abstraction
The decomposition of an abstraction λx.M will use the star abstraction λ∗x.M of M with respect to x. This is an adaptation of the standard technique for defining the abstraction of a combinator M with respect to a variable. Since this is defined using the combinators S, K and I, the latter two must be defined in terms of S and F , as follows. Define
K = FF 
so that KMN = FFMN −→ M for any choice of M and N . Then define
I = SKK
so that IM = SKKM −→ KM (KM ) −→ M for any M .
The star abstraction λ∗x.M of M with respect to x is defined by
λ∗x.x = I
λ∗x.y = Ky	(y /= x)
λ∗x.O = KO	(O an operator)
λ∗x.λy.M = λx.λ∗y.M λ∗x.MN = S(λx.M )(λx.N ) .
This definition modifies the traditional definition of λ∗x.M for combinators M in two ways. First, when the body is an application MN the result uses λx.N instead of λ∗x.N . To see why this is necessary, consider λ∗x.F (KN1N2). Now F (KN1N2) is a compound, so it is safe to separate F from KN1N2 but λ∗x.KN1N2 breaks the redex KN1N2 so a recursive call to λ∗x would here be unsafe. Second, there needs to be a rule for λ∗x when the body is an abstraction λy.M . The result is λx.λ∗y.M and not λ∗x.λ∗y.M since it is important that only one abstraction is eliminated at a time, namely, the innermost one.
Here are some simple examples of star abstraction. In SKI-calculus, the λ- abstraction λx.λy.y can be represented by
λ∗x.λ∗y.y = λ∗x.I = KI
where λ∗ is used to convert abstractions into combinators in the traditional man- ner. In λSF -calculus, the λx.λy.y is already a closed normal form. However, its

factorisation will introduce λ∗x.λy.y which is calculated as follows:
λ∗x.λy.y = λx.λ∗y.y = λx.I .
This has eliminated the innermost abstraction, just like the first step in the calcu- lation of λ∗x.λ∗y.y in SKI-calculus. A second factorisation exposes
λ∗x.SKK = S(λx.SK)(λx.K) .
Further factorisation eliminates the remaining abstractions to produce the combi- nator
S(S(KS)(S(KF )(KF )))(S(KF )(KF ))
which when applied to terms M and N reduces to N , just like the original ab- straction. Of course, it is much bigger than the original term, as it does not take advantage of the standard optimisation, in which λ∗x.I takes advantage of the fact that x is not free in I to produce KI. This will be addressed in Section 8.

Components
The left component M| of a term M is defined as follows (MN )| = M
M| = abs left  (otherwise)
where abs left = SKF will be used as the left component of any term that is not an application, especially of any abstraction. The key point about abs left is that it cannot be the left component of an application to some N since abs left N = SKFN is a fully applied instance of S. In general, words in sans-serif, such a abs left may be used to name particular terms of λSF -calculus, as well as the meta-variables M and N , etc.
Now the right component [M of M is defined by
[(MN )= N
[(λx.M )= λ∗x.M
[M = M  (otherwise.)
It follows that if M is a compound and M −→ N then M| −→ N| and [M −→ [N . That is, no redexes are broken by taking components of compounds. To put is another way, there is a derived reduction rule


(ξ)
M −→ N
λ∗x.M −→ λ∗x.N
(λx.M is a compound.)


Confluence
Theorem 2.1 (confluence lamSF red) Reduction in λSF-calculus is confluent.
Proof. The proof can be seen as an instantiation of Klop’s result [13] for extensions of λ-calculus, in that the additional reduction rules are left-linear and orthogonal.

The only catch is that the reduction rule for F has a side-condition, so some care is required.	2

Normal Forms
The normal forms are defined to be the variables, operators, abstractions of normal forms, and applications MN in which M and N are both normal and MN is either a compound or has an active variable.
Theorem 2.2 ( irreducible iff normal) A term is irreducible if and only if it is a normal form.
A program is a closed normal form. A factorable form is either an operator or a compound.
Theorem 2.3 (programs are factorable) All programs are factorable forms.
Hence, any closed term of the form FPMN must reduce. This is a form of progress result.
Definable Equality
It follows from Theorem 2.3 that the equality term defined in SF -calculus [7] serves to define equality in λSF -calculus too. The algorithm is as follows. Operators are equal if they have the same extensional behaviour, which can be decided by some term eqop. Atoms and compounds are never equal. Compounds are equal if their components are. The actual term is given
fix (λe.λx.λy.F x (eqop x y) (λxl.λxr.Fy(KI)(λyl.λyr.e xl yl(e xr yr)(KI)))) .
where fix is a fixpoint term. This, and other approaches to recursion, will be addressed in Section 6.
Theorem 3.1 (equal programs) equal M M −→∗ K for all programs M.
Theorem 3.2 (unequal programs) equal M N −→∗ KI for all distinct pro- grams M and N.
Proof. The proof is by induction on the rank of M , as defined in the Coq imple- mentation. The only case of interest arises when M is an abstraction and N is an application. Now the left component of N cannot be abs left since any application of abs left reduces, and so the left components of M and N cannot be equal.   2

Extensionality
Mathematically, two functions f and g are extensionally equivalent if they have the same graph. For unary functions, this means that f x = g x for all x. In λ-calculi, extensionality is captured by adding the η-reduction rule
λx.f x −→ f  if x is not free in f .

When added to the basic λ-calculus, with just the β-rule, we get the λβη-calculus, which is confluent. Define =βη to be the equivalence relation on λ-calculus induced by β-reduction and η-reduction. However, adding the η-rule to λSF -calculus is unsound, as can be seen from the following calculations. Define ≡βηSF to be the equivalence relation on λSF induced by its reduction rules and the η-rule. First, the operators S, K and I become equal to their usual interpretations, by
S ≡βηSF λx.λy.λz.Sxyz ≡βη λx.λy.λz.xz(yz) K ≡βηSF λx.λy.Kxy ≡βηSF λx.λy.x
I ≡βηSF λx.Ix ≡βηSF λx.x .
Then we have SKM ≡βηSF λx.x ≡βηSF (SKN ) for any terms M and N . Further,
F (SKM )I(KI) ≡βηSF KI(SK)M =βηSF M
shows that M ≡βηSF N and this for any M and N . The calculus has collapsed.
A more useful relation is obtained by excluding the rule for factoring compounds from the equivalence relation, to get the equivalence relation ≡βηSK. Define terms M and N of λSF to be extensionally equivalent if M ≡βηSK N . For example, we have the following lemma.
Lemma 4.1 (star equiv abs) λ∗x.M ≡βηSK λx.M for all terms M.
Here are three more examples of definable program manipulations that preserve extensional behaviour.
Define a combinator wait so that
wait M N −→∗ S(S(KM )(KN ))I
using standard combinatorial techniques. The right-hand side is normal if M and N are, but application to some P reduces this to M N P so that wait M N waits for P before applying M to N . It follows that
Lemma 4.2 (wait ext) For all terms M and N, wait M N ≡βηSK M N.
Define a combinator tag with the property that
tag T M −→∗ S(KM )(SKT ) .
Now SKT is an identity function for any T since
SKTP −→ KP (TP ) −→ P . 
It follows that when tag M N is applied to some P then it reduces by
S(KM )(SKT )P −→ KMP (SKTP ) −→∗ MP .
Lemma 4.3 (tag ext) For all terms T and M, tag T M ≡βηSK M.
The resulting system of tags is as rich as the calculus as a whole, and so can be used to carry information about, say, constructors or types. In this paper, we will use just three tags in program analysis as follows: abs = tag F will tag abstractions; com = tag S will tag combinators; and app = λx.λy.tag K (wait x y)) will tag applications.

Define a combinator eager such that eager M N reduces to M N if and only if N is factorable. That is, replacing M N by eager M N forces the application to evaluate N before evaluating the application of M to it. The target is a term similar to
FN (λx.xN )(λy.λz.λx.x(yz))M
where x, y and z are fresh. Now M is applied to N only if N has been reduced to factorable form. The new abstractions can be eliminated by ensuring
eager M N −→∗ FN (SI(KN ))(S(K(S(K(SI))))(S(KK)))
This will be used later to block non-terminating reductions. However, if your goal is to avoid re-computation of N then this approach has the weakness that if N reduces to an operator then it will be evaluated twice! This problem can be eliminated by introducing a variant of F in which the atomic branch uses its argument.
Lemma 4.4 (eager is eager) eager M N −→∗ M N for all programs M and N.
Homomorphisms
The common features shared by all these calculi are that they are applicative rewrit- ing systems [20] that have variables as a term form. Accordingly, it makes sense to define a homomorphism of applicative rewriting systems with variables to be a function from one such to another which has the following characteristics:
it preserves the equivalence relation derived from reduction;
it preserves applications;
it preserves variables;
it does not introduce free variables.
It is enough to require preservation up to equivalence, but for convenience, we will demand strict equality. Similarly, the requirement that a homomorphism does not introduce free variables can be weakened to require that closed terms be mapped to closed terms, or even that operators be mapped to closed terms. Note that the definition does not require that λ-abstractions be preserved, or that the image of S takes any particular form. All conditions are expressed in terms of concepts common to all the calculi under consideration, namely rewriting, variables and applications.
Theorem 5.1 (no homomorphism) There is no homomorphism from λSF- calculus to λ-calculus.
Proof. Assume that there is such a homomorphism. Then it can be composed with the embedding of λ-calculus into λβη-calculus to get a homomorphism [−]. It follows that
[S] ≡βη λx.λy.λz.[S]xyz ≡βη λx.λy.λz.[Sxyz] ≡βη λx.λy.λz.xz(yz) .
Similarly, we can show that [K] ≡βη λx.λy.x and [I] ≡βη-equivalent to λx.x. Finally, in SF -calculus we have F (SKM )F (KI) −→ KI(SK)M −→∗ M , for each term

M , and so
[F (SKM )I(KI)] ≡βη [F]([[S][K][M])[[I]([[K][I])
≡βη [F](λx.x)(λx.x)(λx.λy.y) .
Hence, by the homomorphism property, we have
[M] ≡βη [F](λx.x)(λx.x)(λx.λy.y) .
Now the right-hand side is independent of M and so we have, for any N , that
[M] ≡βη [N]. In particular we have x = [x] ≡βη [y] = y for any variables x and y, which yields a contradiction.	2
Corollary 5.2 There is no homomorphism from SF-calculus to λ-calculus.
Proof. The proof of Theorem 5.1 applies equally to SF -calculus.	2
Programs as Normal Forms
The identification of programs with (closed) normal forms in an untyped setting is rather unusual. Of course, we cannot isolate the terminating computations, as this would solve the Halting Problem. If, further, we allow any computation to be a program, i.e. albeit one that takes no inputs, then the game is over. However, by separating the program from its inputs, we can use combinatory techniques to block any troublesome reductions in the program until the input is given. In this manner, programs can be made strongly normalising, and so can be identified with (closed) normal forms.
A crude solution would be to replace all abstractions with the corresponding star abstractions, as these are closed normal forms by construction. However, this is surely more violent than necessary.
Ideally, the identification should be demonstrated using a small programming language, with a conversion function from programs to closed normal forms of λSF - calculus, but this is beyond our current scope. There may be several ways to do this, and the options will change dramatically if the language is typed. Rather than explore these options, which would take some time, let us rather show how to overcome the key difficulty, namely the representation of recursive programs.
Consider a recursive program of the form
let rec f x = M
where M may contain f and x as free variables. Its standard representation is by a term of the form fix (λf.λx.M ) where fix is a fixpoint function defined to be ωω where ω = λx.λf.f (xxf ) . It follows that
fix = λx.λf.f (xxf )ω −→ λf.f (ωωf )= λf.f (fix f ) .
so that fix f −→ f (fix f ). This expresses the recursion very cleanly, but now program representations do not have a normal form.
However, we can delay the application of ω to ω by replacing fix by the exten- sionally equivalent term
fix2 = λf.wait (wait ω ω) f . 

Its application to a normal form f also has a normal form, but further application to some x reduces to ω ω f x which is fix f x. Now the original program can be interpreted by fix2 (λf.λx.M ). In the same manner, we may define fix3 and fix4 etc, so that recursive programs can be made to wait for any number of arguments before risking non-termination.
This accounts for the outermost recursion in a program, but when recursive functions are composed then this technique produces terms of the form
λx.fix2 f (fix2 g x)
which re-introduces arbitrary computations into programs through fix2 g x. To block this, introduce eager evaluation, as described in Section 4 and define yet another fixpoint term by
fix eager = λf.λx.eager (wait (wait ω ω) f ) x . 
Now the composition of recursive programs normalises since evaluation of the re- cursion is blocked until the bound variable x takes a value. In this manner, the core constructions used to create recursive programs can be controlled by combinators to ensure that they do not introduce non-termination.

Extensional Conversion to Combinators
The extensional conversion of program to combinators is given by the recursive, pattern-matching function
to combinator :=
| O ⇒ O
| λx.M ⇒ to combinator (λ∗x.M )
| MN ⇒ (to combinator M ) (to combinator N ))
which eventually converts each abstraction λx.M in its argument to λ∗x.M .
Theorem 7.1 (to combinator makes combinators) If M is a closed term then to combinator M is a combinator.
Since it is easy to test for abstractions and compounds, there is no difficulty in representing to combinator as a program, namely,
to comb = fix(λf.λx.F x x (λxl.λxr.equal abs left xl (f xr) ((f xl) (f xr))).

Theorem 7.2 (to combinator is extensional) to combinator M ≡βηSK M for all terms M.
Theorem 7.3 (to combinator to comb) For all programs M we have
to comb M −→∗ to combinator M . 
Summarising, if M is a program then to comb M reduces to the combinator
to combinator M which is extensionally equivalent to M .

Program Analysis and Optimisation
The extensional conversion above can be optimised in various ways. In particular, there is no need to convert programs that are already combinators. Also, it is more efficient to convert λx.M to KM if x is not free in M . Define is comb by
is comb = fix(λf.λx.F x K(λxl.λxr.equal abs left xl (KI) ((f xl) (f xr) (KI)) .
Theorem 8.1 (is comb true) For all programs M, if M is a combinator then
is comb M reduces to K.
Theorem 8.2 (is comb false) For all programs M, if M is not a combinator then
is comb M reduces to KI.
The test for deciding if a program λx.M uses its argument x can be defined by a term binds that detects copies of I in λ∗x.M . It is given by
binds = fix (λf.λx.equal I x K (F x (KI) (λxl.λxr.(f xl) K (f xr)))) .
Theorem 8.3 (binds abs false) For all programs λx.M, if M is closed then
binds (λx.M ) reduces to KI.
Theorem 8.4 (binds abs true) For all programs λx.M, if x is free in M then
binds (λx.M ) reduces to K.
These ideas lead to the definition of the optimised extensional conversion func- tion given by
to combinator opt :=
| O ⇒ O
| λx.M ⇒ (to combinator opt (if binds (λx.M ) then (λx.M ) else (KM ))
| MN ⇒ if is combinator (MN )
then (MN )
else (to combinator opt M ) (to combinator opt N ))
It is easy to reprise the treatment of to combinator for to combinator opt, but since these ideas will recur in the next section, there is no particular reason to go through the details here.
Intensional Conversion to Combinators
Although the conversion functions above preserve extensionality, they lose inten- sional information, in that an abstraction λx.M becomes indistinguishable from a star abstraction λ∗x.M or combinator. A conversion function f preserves inten- sions if it does not lose information, i.e. there is another transformation g such that g(f M ) reduces to M for all programs M .
For example, star abstraction is intensional, since there is an inverse, given by
unstar =
| O ⇒ O
| λx.M ⇒ λx.(unstarM )
| KM ⇒ abs K M
| SMN ⇒ abs S M N 

where abs K = λx.λy.x and abs S = λx.λy.λz.x z (y z). The corresponding program, also called unstar, is given by program
unstar = fix (λf.λx.f x x (λxl.λxr.equal abs left xl (λz.f (x z)) (equal K xl (abs K xr) (F xl x (λxll.λxlr.abs S xlr xr) .
Theorem 9.1 (unstar star) Star abstraction is intensional, with inverse unstar.
The extensional conversion from programs to combinators can be made inten- sional, too, by adding tags to record the presence of abstractions and combinators.
The optimised, intensional conversion of programs to combinators is given by
to combinator int :=
| O ⇒ O
| λx.M ⇒ abs (to combinator int (if binds (λx.M ) then (λ∗x.M ) else (KM )))
| MN ⇒ if is combinator (MN )
then com (MN )
else app (to combinator opt M ) (to combinator opt N )
Theorem 9.2 (to combinator int makes combinators) If M is a closed term then to combinator int M is a combinator.
Theorem 9.3 (to combinator int is extensional) For all closed terms M we have to combinator int M ≡βηSK M .
The corresponding program to comb int is given by
to comb int = fix (λf.λx.F x x (λxl.λxr.equal abs left xl
(abs (f (binds xr xr (K(xrK))))
(is comb x (com x) (app (f xl) (f xr))).


Theorem 9.4 (to comb int to combinator int) For all programs M, there is a reduction to comb int M −→∗ to combinator int M.
For the conversion in the opposite direction, define to program by
to program :=
| O ⇒ O
| abs M ⇒ unstar(to program M )
| com M ⇒ M
| app MN ⇒ (to program M )(to program N )
This can be defined by a term to prog.
Theorem 9.5 (to comb int is intensional) to comb int is intensional, with in- verse given by to prog.
Summarising, to comb int maps programs to combinators in a manner that is both extensional and intensional.

Verification in Coq
The proofs of all the named lemmas and theorems in the paper have been verified using the Coq proof assistant. Details can be found in the source files [6]. This section will reprise some of the key definitions and theorems, to gain some feeling about how well aligned are the manual and automated approaches.
The operators and terms of lamSF are given by
Inductive operator := | Sop | Fop . Inductive lamSF : Set :=
| Ref : nat -> lamSF
| Op  : operator -> lamSF
| Abs : lamSF -> lamSF
| App : lamSF -> lamSF -> lamSF .
The declaration of operator declares a type operator with two constructors Sop and Fop. Then the declaration of the type lamSF introduces four constructors. Ref is used to construct variables, represented by de Bruijn indices of type nat, the type of natural numbers. Op is used to build the operators S and F as Op Sop and Op Fop. In most situations, all operators are treated uniformly, which is exploited by giving them a separate type. Abs constructs abstractions and App constructs applications. In this manner, the function λx.λy.xySF is represented by
Abs(Abs(App(App(App(Ref 1)(Ref 0))(Op Sop))(Op Fop))) .
The biggest gap between this representation and the paper representation is the use of de Bruijn indices for variables. For example, the requirement maxvar M = 1 means that M has exactly one free variable (indexed by 0).
The Coq versions of the named results in the paper are given in Figure 3. Most of the unexplained notation, such as confluence should be self-explanatory. Note, however, that homomorphism is here defined to be a homomorphism from lamSF to lambda rather than a homomorphism in general. Also, beta eta eq is here the equivalence relation generated from βηSK-reduction, and not just from β- and η-reduction.
Fresh Approaches
Having established the basic machinery of λSF -calculus and seen something of its expressive power, it is interesting to consider, at least in outline, how it suggests fresh approaches to some issues.
G¨odelisation Although λ-calculus is Turing-complete, in the sense of being able to compute any number that a Turing machine can, there are strong limits to its ability to compute functions of λ-terms. For example, equality of closed normal λ-abstractions is not definable as λ-abstraction [1]. Nor is it possible to so define the G¨odel number of a closed normal form. With a little effort, the conversion of programs to combinators can be extended to support G¨odelisation.
Self-interpretation Self-interpretation is used to support programming language implementation within the language itself. In particular, it can be used to impose an evaluation strategy upon a confluent calculus such as λ-calculus [14] or SF - calculus [9]. Traditionally, the first step in self-interpretation is to use meta-level

Theorem confluence_lamSF_red: confluence lamSF lamSF_red. Theorem irreducible_iff_normal:
forall M, irreducible M lamSF_red1 <-> normal M.
Theorem programs_are_factorable : forall M, program M  -> factorable M.
Theorem equal_programs : forall M, program M -> lamSF_red (App (App equal M) M) k_op. Theorem unequal_programs :
forall M N, program M -> program N -> M<>N -> lamSF_red (App (App equal M) N) (App k_op i_op).
Lemma star_equiv_abs : forall M, beta_eta_eq (star M) (Abs M) . Theorem no_homomorphism: forall h, homomorphism h -> False.
Theorem to_combinator_makes_combinators :
forall M, closed M -> combinator (to_combinator M).
Theorem to_combinator_is_extensional : forall M, beta_eta_eq M (to_combinator M). Theorem to_combinator_to_comb:
forall M, program M -> lamSF_red (App to_comb M) (to_combinator M).
Theorem is_comb_true: forall M, program M -> combinator M -> lamSF_red (App is_comb M) k_op. Theorem is_comb_false:
forall M, program M -> (combinator M -> False) -> lamSF_red (App is_comb M) (App k_op i_op).
Theorem binds_abs_false :
forall M, program (Abs M) -> closed M -> lamSF_red (App binds (Abs M)) (App k_op i_op).
Theorem binds_abs_true :
forall M, program (Abs M) -> maxvar M = 1 -> lamSF_red (App binds (Abs M)) k_op.
Theorem unstar_star : forall M, normal M -> lamSF_red (App unstar (star M)) (Abs M). Lemma wait_ext : forall M N, beta_eta_eq (wait M N) (App M N).
Lemma tag_ext : forall T M, beta_eta_eq (tag T M) M.
Lemma eager_is_eager : forall M N, factorable N -> lamSF_red (eager M N) (App M N). Theorem to_combinator_int_makes_combinators :
forall M, closed M -> combinator (to_combinator_int M).
Theorem to_combinator_int_is_extensional :
forall M, closed M -> beta_eta_eq M (to_combinator_int M).
Theorem to_comb_int_to_combinator_int: forall M, program M ->
lamSF_red (App to_comb_int M) (to_combinator_int M).
Theorem to_comb_int_is_intensional :
forall M, program M -> lamSF_red (App to_prog (App to_comb_int M)) M.

Fig. 3. Theorems Verified in Coq

calculations to quote a program, to produce a data structure that is suitable for analysis. Since programs in λSF -calculus are already data structures, there is no need for quotation. Indeed, evaluation strategies can be defined within the calculus, without the need for any meta-level analysis.
Term constructors In the traditional λ-calculus account, the same λ-abstraction may have several different meanings. For example, the natural number zero may be represented as λf.λx.x, in which f is applied zero times to x. Also, the boolean for falsehood may be represented by λx.λy.y in which the second branch, represented by its second argument, is taken. However, λf.λx.x and λx.λy.y are equivalent under renaming of bound variables, so that the same term has two different meanings. Traditionally, these have been distinguished by either introducing constructors, such as Zero and False, or adding types, such as Nat and Bool, or both. Now, we can tag these abstractions with information about their status as constructors, or their types. Similarly, constructor arities can be recorded by using wait.
Pattern calculus In λSF -calculus, it should be possible to give a complete ac- count of constructor equality and pattern-matching by manipulating intensional information.
Type checking Similarly, once terms are tagged with type information, the calculus should support type checking and type inference.
Evaluation strategy Confluent rewriting systems support a natural model of pro- gram optimisation by changing the order in which sub-expression are evaluated.

However, sequential execution requires that an evaluation strategy be imposed. As with intensional information, different strategies give rise to a variety of different calculi [16]. These can be captured by using terms such as wait and eager to control evaluation order.
Partial evaluation Once programs are represented by normal forms, it is much easier to understand the nature of partial evaluation, of static arguments versus dynamic arguments, etc [11]. As before, these analyses should now be representable as programs.
Domain specific languages Users are driven to create their own, domain-specific programming languages because general purpose languages prove to be sub-optimal for their needs. One approach is to grow a language from a small core [19,10]. This will be easier once program analysis and evaluation strategies are definable.
Conclusions
λSF -calculus combines the best features of λ-calculus and combinatory calculi within a single calculus in that λ-abstraction provides a natural account of func- tionality through its β-reduction, while combinators provide a natural account of data structures, once the factorisation operator F is supported. Together, they show how programs and data structures can both be identified with the closed nor- mal forms of λSF -calculus, so that they may be applied or analysed at any time. Further, the combinators can be used to tag programs with additional, intensional information, e.g. about constructors or types, or to control evaluation strategy by making applications wait before reducing.
The identification of programs and data structures also removes a layer of indi- rection from program analysis. There is no need to quote or G¨odelise abstractions. Nor is there need for a separate state machine, to evaluate programs expressed on a tape. The ramifications may extend to all aspects of programming language design and implementation, including analysis and optimisation.
Like pattern calculus and SF -calculus, λSF -calculus supports powerful collec- tion of generic queries for searching and updating data structures. However, the earlier calculi were far removed from current experience, making adoption diffi- cult. By contrast, λSF -calculus merely adds a couple of operators to the popular λ-calculus approach, which makes migration much easier.
In conclusion, λSF -calculus adds intensionality to the extensional nature of λ- calculus, so that one can query the internal structure of arbitrary closed normal forms, and treat programs as data structures.

References
H.P. Barendregt. The Lambda Calculus: Its Syntax and Semantics. North Holland, 1984. revised edition.
Henk Barendregt. Self-interpretations in lambda calculus. J. Funct. Program, 1(2):229–233, 1991.
Michel Bel. A recursion theoretic self interpreter for the lambda-calculus. http://www.belxs.com/ michel/#selfint.


Alessandro Berarducci and Corrado B¨ohm. A self-interpreter of lambda calculus having a normal form. In CSL, pages 85–99, 1992.
Barry Jay. Pattern Calculus: Computing with Functions and Structures. Springer, 2009.
Barry Jay. LamSF repository of proofs in Coq. https://github.com/Barry-Jay/lambdaSF, February 2016.
Barry Jay and Thomas Given-Wilson. A combinatory account of internal structure. Journal of Symbolic Logic, 76(3):807–826, 2011.
Barry Jay and Delia Kesner. First-class patterns. Journal of Functional Programming, 19(2):191–225, 2009.
Barry Jay and Jens Palsberg. Typed self-interpretation by pattern matching. In Proceedings of the 2011 ACM Sigplan International Conference on Functional Programming, pages 247–58, 2011.
Barry Jay and Jose Vergara. Growing a language in pattern calculus. In Theoretical Aspects of Software Engineering (TASE), 2013 International Symposium on, pages 233–240. IEEE, 2013.
N.D. Jones, C.K. Gomard, and P. Sestoft. Partial Evaluation and Automatic Program Generation. International Series in Computer Science. Prentice Hall International, 1993.
Stephen C. Kleene. λ-definability and recursiveness. Duke Math. J., pages 340–353, 1936.
J.W. Klop. Combinatory Reduction Systems. PhD thesis, Mathematical Center Amsterdam, 1980. Tracts 129.
Torben Æ. Mogensen. Efficient self-interpretations in lambda calculus. Journal of Functional Programming, 2(3):345–363, 1992. See also DIKU Report D–128, Sep 2, 1994.
Torben Æ. Mogensen. Linear-time self-interpretation of the pure lambda calculus. Higher-Order and Symbolic Computation, 13(3):217–237, 2000.
G.D. Plotkin. Call-by-name, call-by-value and the λ-calculus. Theoretical Computer Science, 1, 1975.
John C. Reynolds. Definitional interpreters for higher-order programming languages. In Proceedings of 25th ACM National Conference, pages 717–740. ACM Press, 1972. The paper later appeared in Higher-Order and Symbolic Computation.
Fangmin Song, Yongsen Xu, and Yuechen Qian. The self-reduction in lambda calculus. Theoretical Computer Science, 235(1):171–181, March 2000.
Guy L. Steele. Growing a language. Higher-Order and Symbolic Computation, 12(3), 1999.
Terese. Term Rewriting Systems, volume 53 of Tracts in Theoretical Computer Science. Cambridge University Press, 2003.
