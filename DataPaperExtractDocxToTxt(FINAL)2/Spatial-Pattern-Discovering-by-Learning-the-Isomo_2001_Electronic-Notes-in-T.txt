Electronic Notes in Theoretical Computer Science 46 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume46.html 20 pages


Spatial Pattern Discovering by Learning the Isomorphic Subgraph from Multiple Attributed Relational Graphs.

Pengyu Hong 1 and Thomas S. Huang 2
Beckman Institute for Advanced Science and Technology University of Illinois at Urbana Champaign
Urbana, IL61801, USA


Abstract
Inexact graph matching has been widely investigated to relate a set of object/scene primitives extracted from an image to a set of counterparts representing a model or reference. However, little has been done to address how to build such a model or reference. This paper develops the theory for automatic contextual pattern mod- elling to automatically learn a parametric pattern ARG model from multiple sample ARGs. The learned pattern ARG characterizes the sample ARGs, which represent a pattern observed under different conditions. The maximum-likelihood parame- ters of the pattern ARG model are estimated via the Expectation-Maximization algorithm. Particularly, for Gaussian attributed and relational density distribution assumptions, analytical expressions are derived to estimate the density parameters of the pattern ARG model. The pattern ARG model with Gaussian distribution as- sumptions is therefore called the Contextual Gaussian Mixture model. The theory and methodology is applied to the problems of unsupervised spatial pattern ex- traction from multiple images. The extracted spatial pattern can be used for data summarization, graph matching, and pattern detection. One immediate application of this newly developed theory will be information summarization and retrieval in digital image and video libraries.


Introduction
Contextual pattern modelling has been an important task in computer vision and pattern recognition [2,3,5,10,13]. It is fundamental to image registration, recognition, and classification. In contextual pattern modelling research, a model object/scene is usually represented as an attributed relational graph

1 Email: hong@ifp.uiuc.edu
2 Email: huang@ifp.uiuc.edu
◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


(ARG) [10] that consists of a set of nodes and arcs. An example of the ARG is illustrated at Fig. 1. The nodes of an ARG represent the object/scene primitives in the images. The attributes of the nodes encode the appearance properties of the object/scene primitives. The relations among the nodes specify the contextual information of nodes. Example of such relations are the relative distance between two primitives, the relative orientations of one primitive to the others, and so on. The relations of a node uniquely specifies that node given the identity of other nodes. In the rest of the paper, we assume that the observed images are processed and represented as sample ARGs.

(a)	(b)
Fig. 1. An ARG that represents a group of image segments. (a) A group of image segments with different colors, (b) the ARG representation of (a). The color of a node represents the color attribute of its corresponding image segment. The arcs represent the adjacent relations among the image segments.
Recently, ARG and graph matching techniques have begun to attract great attentions in content-based image/video retrieval community [12,15,16]. Basi- cally, the user submits a set of sample images (usually more than two) to the system. The system first summarizes the sample images in some ways. Then, the system uses the summarized information to search through its database and return a set of images, which are similar to the sample images based on its similarity measurement method.
Most image/video classification and retrieval approaches use the global fea- tures (texture, color, etc.) of the images [18]. The global features is a mixture of the features of the image primitives. This one of the main reasons that lead to ambiguities in image classification and retrieval applications. The introduc- tion of ARG representation enables the system to examine images at a finer and more meaningful level. Consequentially, techniques and algorithms for summarizing multiple sample ARGs are required. Although two-graph match- ing as a fundamental problem has been widely investigated [1,4,6,17,19,20,21], little has been done for summarizing multiple sample ARGs.
Some merely use ARG to represent samples and apply two-graph matching techniques to measuring the similarity between the samples in the database and the query for retrieval purpose. Huet and Hancock [12] used ARG to represent the geometric attributes and structural information of line-patterns. Ozer [15] used relational graph to annotate the images where the object of interest is present. However, both [12] and [15] only use ARG for informa-

tion representation and apply two-graph matching algorithms for information retrieval.
Recently, some approaches try to learn pattern from multiple instances. Ratan et al [16] used Diverse Density algorithm to learn “visual concepts”, or pattern in the context of this paper, from multiple sample images. The learned “visual concepts” can be used to classify new images. In [16], a concept is a pre-specified conjunction of several image primitives (e.g. image segments). The representation of the concept is similar to ARG. Nonetheless, the rela- tional information of the image primitives, which is essential for distinguishing image primitives, is not utilized in [16].
Frey and Jojic [9] defined transformation function as a discrete latent vari- able in the probabilistic graphical model and use the Expectation-Maximization (EM) algorithm [7] to learn patterns from images with clutter backgrounds. In their approach, transformation function is defined on the image pixel level. The values of the transformation functions are selected from a predefined dis- crete transformation set. The image pixels are just like the nodes of an ARG. The transformation set is similar to the value range of the matching function in graph matching algorithm. However, their approach does not consider the contextual information of image pixels. Therefore, the matching ambiguity of image pixels is left as an open problem. In addition, operating at pixel level limits the possible transformation set (many transformations are defined on pixel group and are continuous), increases pixel matching ambiguity, and brings about high computational complexity.
Multiple sample ARGs should provide more information about the pattern than two sample ARGs do. It is not appropriate to use one of the sample ARGs as the model or reference. The relations and the attributes of a sample ARG may not best represent those of other sample ARGs. This is due to the variance of the relations and attributes caused by noise, lighting conditions, transformations, and so on. We propose to learn a parametric pattern ARG from a set of sample ARGs. The learned pattern ARG model can be further used for object detection.
The rest of the paper is organized as below. Section 2 formulates the auto- matic contextual pattern modelling problem. Section 3 derives expressions for estimating the parameters of the pattern ARG via the EM algorithm. Ana- lytic expressions can be obtained for some parameters regardless the attributed and relational density distribution functions. Section 4 derives analytical ex- pressions for estimating the density parameters of a special case of the pattern ARG, called the Contextual Gaussian Mixture model. Section 5discusses how to used the learned pattern ARG model for pattern detection. Implementa- tion issues are presented in Section 6. Experimental results are provided in Section 7. Finally, the paper closes with summary and discussions in Section 8.



Fig. 2. Modelling S sample ARGs {Gi} by a pattern ARG with M model com- ponents (M << S). oij (1 ≤ i ≤ S, 1 ≤ j ≤ 4) represents a sample node. rmk (1 ≤ m ≤ S, 1 ≤ k ≤ 4) represents a sample relation. ωpq (1 ≤ p ≤ M, 1 ≤ q ≤ 4) represents a pattern node. ψabc (1 ≤ a ≤ M, 1 ≤ b ≤ 4, 1 ≤ c ≤ 4) represents a pattern relation.

Automatic Contextual Pattern Modelling
In [11], we used a pattern ARG model, which contains only one parametric ARG model, to model a set of sample ARGs. Here, we generalize the pattern ARG model so that it consists of a small number of parametric ARG models. The expanded pattern ARG model has larger modelling capacity and can be used to effectively model a larger set of sample ARGs that are observed under more diverse conditions. Fig. 2 illustrates the idea of modelling a large set of sample ARGs with a pattern ARG. The pattern ARG model is a compact representation of the sample ARGs. It explains each sample ARG on two scales. On the macro scale, a sample ARG is a linear combination of the model components. On the micro scale, if a model component is specified, a node of the sample ARG is a linear combination of the nodes of the model component in terms of node matching probabilities.
The contextual pattern modelling problem becomes straightforward if the node and relation correspondences between the sample ARGs and the com- ponents of the pattern ARG are specified. However, it is tedious and labor

intensive to manually specify the node and relation correspondences for a large set of sample ARGs. Moreover, the observed images always contain the pat- tern and its backgrounds. It is also tedious and labor intensive to manually label the pattern out of its backgrounds.
This paper is interested in automatic contextual pattern modelling that does not require to manually specify the correspondences and manually extract the pattern from the observed images. The automatic learning procedure should calculate: (a) the attributed parameters (appearance information) of the pattern ARG, (b) the relational parameters (contextual information) of the pattern ARG, (c) the structure (the number of nodes and that of the relations) of the pattern ARG, and (d) the node and relation correspondences between the components of the pattern ARG and the sample ARGs.
We first define the notations that will be used in the rest of the paper.
The observed sample ARGs is represented as G = {G1, ..., GS}, where
S is the number of the sample ARGs. Each sample ARG Gi = ⟨Oi, Ai, Ri, Bi⟩
(1 ≤ i ≤ S) has: (1) Ui data nodes 3 Oi = {oik}Ui  ; (2) the attribute set of the
data nodes Ai = {−→a ik}Ui	and −→a ik is the attribute vector of data node oik; (3)
Ui × Ui data relations Ri = {ricd} (1 ≤ c, d ≤ Ui); and (4) the feature vector

set of the data relation set Bi
−→
= { b icd
Ui c,d=1
and −→a

icd
is the feature vector

of the data relation ricd. Ri and Bi define the contextual information of the
nodes in Gi. Self-relation, which represents the relation between a node and itself, is allowed. For example, the distance relation between a node and itself

is 0. We have ricd = ridc and
−→
b icd =
−→
b idc if the relations are unidirectional.

The pattern ARG model Γ has M components and Γ = {Φw}M  .
Each component Φw = ⟨Ωw, Ψw, Θw⟩ consists of: (1) N model nodes Ωw =

{ωwk}N
; (2) N × N model relations Ψw = {ψwcd} (1 ≤ c, d ≤ N ); and (3)

the parameter set Θw. We will discuss the details of the parameter set Θw when we derive the expressions for estimating Θw. Let Θ denote {Θw}.
The correspondences between the sample ARGs and the pattern ARG

−→
is denoted by Y =
S . Y specify the ways that the pattern ARG model Γ

{ Y i}i=1
generates G. Y is a random variable governed by the distribution f (y|G, Γ) =
−→
f (y|G, Θ). Each element of Y , say Y i , is also a random variable. And let

−→y
= [q ,y 
, ..., y
−→
] denote an instance of	. The value of q
denotes that G

i	i	i1
iUi
Y i	i	i

matches with the model component Φqi or Gi is generated by Φqi . The value
of yij denotes that the data node oij matches with the model node ωqiyij or oij is generated by ωqiyij . We also have 1 ≤ qi ≤ M and 1 ≤ yij ≤ N . Once the value of Y is decided, the correspondences between the sample relations and
the model relations are fixed. Let ঩yi (ricd) ∈ Ψqi denote the corresponding
model relation of the data relation ricd respect to −→y i.

3 We allow Ui /= Uj if i /= j because the observed images may have different numbers of image primitives. This is due to noise or the fact that the pattern being placed in different backgrounds. For example, if a node represents a line, the lines tend to get broken during the process of line detection, which results in extraneous nodes.

Overall, Θ and Y are unknowns to be estimated.

Finding the Maximum Likelihood Parameters of the Pattern ARG via the EM Algorithm
An algorithm that simultaneously considers all the sample ARGs is needed to estimate the parameters of the pattern ARG and calculate the correspon- dences between the sample ARGs and the pattern ARG. In this paper, the EM algorithm [7] is used.

The Basic EM Algorithm
The EM algorithm is a technique for finding the maximum-likelihood estimate of the parameters of underlying distributions from a training data set, which is incomplete or has missing values. The EM algorithm works iteratively in two steps: Expectation and Maximization. The algorithm defines the function:
Q(Θ; Θ(t))= E[log p(Do, Dm; Θ)|Do, Θ(t)]	(1)
where Θ is the parameter to be estimated, Do is the observed data, Dm is the missing information, and t is the number of the iteration of the EM algorithm. Q(Θ; Θ(t)) is a function of Θ under the assumption that Θ = Θ(t). The right hand side of eq. (1) denotes that the expected value of the complete data log- likelihood log p(Do, Dm; Θ) with respect to Dm and Do and assuming Θ = Θ(t). In the Expectation step, Q(Θ; Θ(t)), is computed. In the Maximization step, the algorithm updates Θ by Θ(t+1) = arg maxQ(Θ; Θ(t)).
Θ

Derive Expressions for Estimating the Parameters of the pattern ARG via the EM algorithm
In the context of learning the pattern ARG model, the observed data Do is

G = {G }S
and the missing data D
is Y =
−→  S
. We can rewrite eq.

as:
i i=1
m	{ Y i}i=1


Q(Θ; Θ(t))= E[log p(G, Y ; Θ)|G, Θ(t)]
=Σ f (y|G, Θ(t))f (G|Θ(t)) log p(G, y|Θ)	(2)
where f (y|G, Θ(t)) is the marginal distribution of the unobserved data Y and is dependent on the observed data G and the current values of the parameter set Θ. Since f (G|Θ(t)) is not dependent on Θ and will not effect the final results, we can take it out. Without losing the generality, we can assume that
Gi is independent to each other, and consequently −→y i is independent to each

other. Therefore, eq. (2) can be rewritten as:


Q(Θ; Θ(t))= Σ ··· Σ Σ log(p(Gi|−→y
i, Θ)P (−→y
i))   f (−→y
j|Gj, Θ(t))	(3)

−→y 1
−→y S
i=1
j=1



where p(Gi|−→y i, Θ) is the density function of Gi
given the pattern ARG model

and the match −→y
i, and


p(Gi|−→y i, Θ) = p(Gi|[yi1 ··· yiU ], Θq )
Ui	Ui  Ui

=	p(oim
m=1
|ωqiyim
)	p(ricd
c=1 d=1
|঩→−y i
(ricd
(4)
))

where p(oim|ωqiyim ) is the attributed distribution function and p(ricd|঩−→y (ricd))
is the relational distribution function. If the relation is unidirectional, eq. (4)
should be written as:


Ui	Ui  Ui

p(Gi|−→y
i, Θ) =		p(oim m=1
|ωqiyim
)	p(ricd
c=1 d=1
|঩−→y  (r

icd
)) 1/2	(5)

In the following derivation, we use eq. (4). It can be easily shown the eq.
(5) will only affect part of the final results by a scale of 1/2.
We can also write down the term P (−→y i) in eq. (3) as:


P (−→y
Ui
i) = P (qi)		P (yin n=1
|qi)	(6)

Let P (qi = h)= αh (1 ≤ h ≤ M ), such that ΣM
αh = 1. Let P (yin = η|qi =

h) = βhη (1 ≤ η ≤ N ), such that ΣN
βhη = 1. The underlying intuitions of

eq. (6) are: (1) On the macro scale, a sample ARG is a linear combination of the model components weighted by αh; (2) On the micro scale, given the fact that Gi match with the model component Φh, a data node is a linear combination of the model nodes in Φh weighted by βhη. {αh}∪ {βhη} is part of the parameter set to be estimated, or {αh}∪ {βhη}⊂ Θ.
The term f (−→y j|Gj, Θ(t)) in eq.(3) is the marginal distribution of −→y j. Since
the contextual information is fully described in Gj, yjk is independent to each other. Hence,


f (−→y
Uj
|G , Θ(t))= P (q |G , Θ(t))	f (y
|G , Θ(t))	(7)



Submitting eq.(4),(6),(7) into eq. (3), we have


Q(Θ; Θ(t))= Σ ··· Σ Σ log(p(Gi|−→y
i, Θ)P (−→y
i))   f (−→y

j|Gj, Θ(t))

−→y i	−→y S
Σ Σ	Σ
i=1
Σ Σ
j=1
Σ Σ	 Ui

=	···	···	···	log
q1=1 y11=1	y1U1=1	qS=1 yS1=1	ySUS =1 i=1	m=1
p(oim|ωqiyim )
(8)

Ui  Ui	Ui
p(ricd|঩−→y i (ricd))P (qi)
S
P (yin|qi)
  P (qj|Gj, Θ(t))

c=1 d=1 Uj
(t)
qj
n=1
j=1

k=1
Replacing log(  g(x)) with Σ(log(g(x))) in eq.(8), we have:
Q(Θ; Θ(t))= Σ Σ ··· Σ ··· Σ Σ ··· Σ Σ log P (qi)+

q1=1 y11=1
y1U1=1
qS=1 yS1=1
ySUS =1 i=1

Ui	Ui	Ui

	




 j=1
  P (qj|Gj, Θ(t))
Uj


k=1
f (yjk|Gj, θ(t)) 

Eq. (9) can be greatly simplified into
Q(Θ; Θ(t))= Σ Σ log(αh)Pq (h|Gi, Θ(t))+
i=1 h=1
Ui	N
Σ Σ log(βhη)fy	(η|Gi, Θ(t))Pq (h|Gi, Θ(t))+

Ui	N
Σ Σ log(p(oim|ωhη))fy	(η|Gi, Θ(t))Pq (h|Gi, Θ(t))+


Ui	Ui
log(p(ricd|ψiστ ))fy
(σ|Gi, Θ(t))fy  (τ|Gi, Θ(t))Pq (h|Gi, Θ(t)) 

c=1 d=1 σ=1 τ =1
ic	h	id	h	i

(10)

where Pq (h|Gi, Θ(t)) denotes P (qi = h|Gi, Θ(t)) and fy	(η|Gi, Θ(t)) denotes
i	im	h
f (yim = η|Gi, Θ(t)). Note that fy	(η|Gi, Θ(t)) can be calculated using inexact
graph matching techniques. Readers are asked to refer to Appendix A for the details about simplifying eq. (9).

It is now clear that Θ = {αh}∪ {βhη}∪ {the parameters of the attributed distribution } ∪ { the parameters of the relational distribution }. In the Maximization step, Θ is updated by Θ(t+1) = arg maxQ(Θ; Θ(t)). Both the
Θ
parameters of the attributed distribution and those of the relational distribu-
tion depend on the forms of the distribution functions, and so are their update expressions. The expressions for updating αh and βhη can however be obtained as below regardless the forms of the attributed and relational distributions:


(t+1)
ΣS	Pq (h|Gi, Θ(t))

α	= 	i=1	i	
h	S
(11)



M ΣS
ΣUi
fy	(η|Gi, Θ(t))Pq (h|Gi, Θ(t))

hη	S
i=1	i

where fy
(η|Gi, Θ(t)) and Pq (h|Gi, Θ(t)) can be calculated using graph match-

im	h	i
ing techniques, which will be discussed in Section 6.1. Readers are asked to
refer to Appendix B for the details of deriving eq. (11) and (12).

Contextual Gaussian Mixture Model
In most applications, the attributed distribution and the relational distribu- tion are likely to be assumed to be Gaussian. This kind of pattern ARG model is called the Contextual Gaussian Mixture (CGM) model. Analyti- cal expressions for estimating the distribution parameters of the CGM in the Maximization step of the EM algorithm can be derived.
Assume the attributed distribution is


exp(− 1(−→a
− −→µ
)T Σ−1(−→a
− −→µ	))

p(o
|ω )= 	2	im	hη	hη	im	hη 
(13)

im	hη
(2π)ξ/2|Σhη
|1/2

where −→µ hη and Σhη are the mean and covariance matrix of the attribute of the model node ωhη, and ξ is the dimension of the attribute vector. We can
obtain the expressions for updating −→µ hη and Σhη as below:

ΣS	ΣUi
−→a	f

(η|G , Θ(t))P

(h|G , Θ(t))

hη	ΣS
ΣUi	f
(η|G , Θ(t))P
(h|G , Θ(t))



−→	ΣS
ΣUi
−→x (t) −→x (t) T f
(η|G , Θ(t))P
(h|G , Θ(t))

hη	ΣS
ΣUi	f
(η|G , Θ(t))P
(h|G , Θ(t))

where −→x (t) = −→a im − −→µ (t). Readers are asked to refer to Appendix C for the
details of deriving eq. (14) and (15).

Assume the relational distribution is

exp(− 1 −→
− −→γ	)T Λ−1 −→
− −→γ	))

p(r

icd
|ψhστ )= 
2( b icd
hστ
(2π)κ/2|Λ
hστ ( b icd
|1/2
hστ
(16)

where −→γ

hστ
and Λ

hστ
hστ
are the mean and covariance matrix of the feature vector

of the model relation ψhστ , and κ is the dimension of the relational feature

vector. We can obtain the expressions for updating −→γ
hστ
and Λ
hστ
as below:

−→	ΣS
ΣUi
ΣUi  −→


(t)

hστ
S
i=1
Ui c=1
Ui d=1
ϑh(yic
, yid
, σ,τ )Pqi
(h|Gi, Θ(t))



−→	ΣS
ΣUi
ΣUi
−→z (t) −→z (t) T ϑ (y
,y  , σ,τ )P
(h|G , Θ(t))

hστ
S
i=1
Ui c=1
Ui d=1
ϑh(yic
, yid
, σ,τ )Pqi
(h|Gi, Θ(t))

where ϑ (y ,y , σ,τ ) = f
(σ|G , Θ(t))f	(τ|G , Θ(t)) and −→z (t) = −→	−

h	ic	id
yic
i	h	yid	i	h
icd
b icd

−→(t)
hστ
. Readers are asked to refer to Appendix C for the details of deriving eq.

(17) and (18).
Use the Learned Pattern ARG Model to Detect the Pattern
The learned pattern ARG captures the characteristics of a pattern observed under various conditions. It can be further used to detect the pattern in a new ARG, say Gnew. Firstly, Pqnew (h|Gnew, Θ) (1 ≤ h ≤ M ) is computed using the learned pattern ARG. The details of how to calculate Pqnew (h|Gnew, Θ) will be discussed in Section 6.1. We select a component from the pattern ARG by picking up the component whose index l = arg minPqnew (h|Gnew, Θ). We then
h
use two-graph matching technique to match Gnew against the component Φl of the pattern ARG. Those nodes of Gnew that match with the non-null model nodes are selected. The relations among those selected nodes are preserved. The selected nodes and relations form an instance of the pattern ARG in Gnew.
Implementation Issues
Match the Sample ARGs with the Pattern ARG
We use an implementation of probabilistic relaxation graph matching algo- rithm [6] to match each sample ARG against each component of the pattern

ARG model. The matching results immediately provide fyim
(η|Gi, Θ(t)). The

matching algorithm decides which model node to match with a data node oim
by:

Υh(oim) = arg maxfyim
η
(η|Gi, Θ(t))	(19)

The sample images are usually noisy and contain backgrounds. This will not only affect the feature extracted for the object primitives but also create spurious nodes in the sample ARGs. To handle this problem, a null model node is generally used in the graph matching algorithms. We add a null node ωh0 to each model component Φh. The null node has no physical instance. Therefore, it neither has attributes nor has relations with other model nodes to be estimated. The null node provide a matching destination for the spurious nodes. We then define Pq (h|Gi, Θ(t)) as:

Σ  fy
(Υh(oim)|Gi, Θ(t))ℵ(Υh(oim))

i	ΣM  Σ  f
(Υ (o
)|G , Θ(t))ℵ(Υ (o	))

ℵ(Υh(oim)) = 1 if and only if Υh(oim) /= 0. ℵ(Υh(oim)) encourages the case in which a data node matches with a non-null model node.
Initialize the Pattern ARG Model
Initializing the pattern ARG model is the first step of the learning procedure and is very important. The number of the model components is decided by the user or the applications. The average number of the nodes of the sample ARGs is calculated. A sample ARG whose number of nodes is the closest to the average number is selected. Let G1 denote the selected sample ARG. The structure of G1 is used to initialize that of one component of the pattern ARG model. In the case of a CGM model, the attributes and relations of the selected sample ARG are used to initialize the corresponding attributed means and relational means of the model component. The attributed covariances and relational covariances of the component are initialized as identical matrixes. The rest components of the pattern ARG model are set as NULL graphs and will be initialized by the following algorithm.
Algorithm 1. Initialize the Pattern ARG Model.
for K =2 to M
Calculate eq.(20) for each sample ARG using current pattern ARG.
Select a sample ARG Gx = arg min ΣK−1 Pq (h|Gi, Θ(t)).

Initialize the component ΦK of the pattern ARG using Gx.
endfor
Modify the Pattern ARG Model
It is likely to initialize the components of the pattern ARG model with spuri- ous nodes and relations because the sample ARGs include backgrounds . To achieve better modelling results, those spurious nodes and relations should be detected and trimmed. Otherwise, they may cause serious mismatch prob- lem if we keep updating their parameters. During the iterations of the EM

algorithm, the graph matching results are examined. For each model nodes, we calculate the number of the data nodes that match with it. If the num- ber is smaller than a threshold ϵS/M , the model node and its relations will be removed. ϵ can be a constant or a user-defined ascendant function of the iteration number of the EM algorithm.
Experimental Results
We take the pictures of the MacDonald TM sign in various backgrounds, from different viewpoints, and under two different light conditions. Ten images are taken under each lighting condition. Some of the images are shown in Fig.
3. The images are segmented and represented as ARGs. The node of each ARG represents an image segment and the attribute of the node is the mean color feature vector (RGB) of the segment. The adjacent relations among the segments are considered. The attributes of the sign under two different lighting conditions are greatly different from each other. Even under the same lighting condition, the attributes of the signs are different from each other due to different viewpoints. For example, the attribute vectors of ‘m’ in the middle of the sign are (208, 150, 69), (202, 138, 60), (206, 144, 71), (240, 173,
116), (240, 180, 109), (241, 192, 120) in Fig. 3 (a), (b), (c), (d), (e) and (f)
respectively.

(b)	(c)




(d)	(e)	(f)
Fig. 3. The MacDonald TM sign.
A CGM model with two components is used. After learning, the training data set is summarized as two model components in the CGM model. Both of them have 8 nodes and 11 adjacent relations. To illustrate the learning results, we use the learned model to detect its isomorphic subgraph in the ARG of Fig. 3(a) and repaint the corresponding image segments using the means of the attributes of the corresponding model nodes. The same process is repeated on Fig. 3(d). The detection results are shown in Fig. 4. The mean

color vectors of the model nodes that corresponding to ‘m’ in the middle of the sign are (207.5, 140.3, 68.6) and (240.2, 179.7, 117.1) respectively.





(a)	(b)
Fig. 4. The components of the learned pattern ARG model. (a) Model component 1, (b) model component 2.
An experiment is also conducted to match the ARG of Fig. 3(a) against that of Fig. 3(e). We modify eq. (13) and (16) to measure the attributed and relational similarity between the two ARGs. The covariance matrix Λhστ in eq. (16) is replaced by the identical matrix I. And the covariance matrix Σhη in eq. (13) is replaced by a matrix ρI. We increase ρ from 1.0 with a step of
0.1 and calculate the matching between those two ARG for each value of ρ. If 1.0 ≤ ρ < 2.3, no correct node matching is found. If 2.3 ≤ ρ < 2.5, partial correct matching is found. If ρ ≥ 2.5, correct matching is achieved. The MacDonald TM signs in the Fig. 3(a) and (e) share part of background, which is in light blue color. If ρ ≥ 2.5, the light blue background, which is not part of the pattern, is however also correctly matched or extracted as part of the pattern.
Comparing the above experimental results, it won’t be difficult to real- ize two main advantages of the our framework. An implementation of the framework can start with same initializations as those in the experiment that is just been described above, and automatic calculate the best means and covariance matrixes of the attributes and relations instead of changing them manually and blindly. Moreover, it considers multiple samples simultaneously. If the pattern is not always observed in the same background, it can learn the pattern out of its backgrounds.

Summary and Discussions
This paper develops theory for evidence combining that fuses the observed attributed information and contextual information of the objects. The theory is applied to unsupervised spatial pattern extraction from sample ARGs. The extracted pattern summarize the sample images and can be used for pattern detection in new images. Although the proposed theory is applied to two dimensional images in this paper, it is in its nature suitable for general spatial pattern learning and discovery because ARG can be used to represent concepts in higher dimension.

However, the learning results depend on the quality of the results of the low-level image processing. Low-level image processing must be applied to the sample images before representing them as ARGs. Currently, not effective enough high-level knowledge can be utilized in low-level image processing step. Therefore, the processing results might not be good enough under some condi- tions. A possible improvement would be building a feedback loop between the high-level pattern learning step and the low-level image processing step. The learned pattern encode some reliable high-level knowledge that can be applied back to doing model-based low-level image processing. The pattern can then be refined given the new results of low-level image processing. Another way to improve it is to take advantage of user interaction. For example, in relevance feedback content-based image retrieval [18], the user tries to tell the computer their information need by iteratively providing some sample images as rele- vance feedbacks. Our theory can be used to develop algorithm to automatic learn what the user wants based on the feedback. The user then provides the correction to the automatic learning results as relevance feedbacks to make the learning procedure more purposeful and effective.

References
Almohamad, H. A., and S. O. Duffuaa, A Linear Programming Approach for the Weighted Graph Matching Problem, IEEE Trans. Pattern Analysis and Machine Intelligence 15 (1993), 522-525.
Barrow, H. G., and R.J. Popplestone, Relational Descriptions in Picture Processing, Machine Intelligence 6 (1971), 377-396.
Besl, P. J., and R. C. Jain, Three-dimensional object rec-ognition, Computing Surveys, 17 (1985), 75-145.
Bhanu, B., and O. D. Faugeras, Shape Matching of Two-Dimensional Objects, IEEE Trans. Pattern Analysis and Machine Intelligence, 6 (1984), 137-156.
Bledsoe W. W., and I. Browning, Pattern recognition and reading by machine, Proc. Eastern Joint Computer Conference, 16 (1959), 225-232.
Christmas, W. J., J. Kittler, and M. Petrou, Structural Matching in Computer Vision Using Probabilistic Relaxation, IEEE Trans. Pattern Analysis and Machine Intelligence 17 (1995), no 8., 749-764.
Dempster, A. P., N. M. Laird, and D. B. Rubin, Maximum Likelihood from Incomplete Data via the EM Algorithm, J. Royal Stat. Soc. Ser. B, 39 (1977), no. 1, 1-38.
Felzenszwalb, P. F., and D. O. Huttenlocher, Image Segmentation Using Local Variation, in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, (1998), 98-104.


Frey, B. J. and N. Jojic, Transformed component analysis: Joint estimation of spatial transformations and image components, International Conference on Computer Vision, (1999).
Fu, K. S., A Step towards Unification of Syntactic and Statistical Pattern Recognition, IEEE Trans. Pattern Analysis and Machine Intelligence, 5 (1983), 200-205.
Hong, P., R. Wang, and T. S. Huang, Learning Patterns from Images by Combining Soft Decisions and Hard Decisions, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, (2000), Hilton Head Island, South Carolina.
Huet, B., and E. R. Hancock, ”Inexact Graph Retrieval,” In Proceedings of IEEE Workshop on Content-based Access of Image and Video Libraries, pp. 40-44. 1999. Colorado. USA.
Kittler, J., and J. Fo¨glein, Contextual classification of multispectral pixel data, Image and Vision Computing, 2 (1984), 13-29.
Li, S. Z., Matching: Invariant to Translations, Rotations and Scale Changes, Pattern Recognition 25 (1992) 583-594.
Ozer, B., W. Wolf, and A. N. Akansu, A Graph Based Object Description for Information Retrieval in Digital Image and Video Libraries, In Proceedings of IEEE Workshop on Content-based Access of Image and Video Libraries, pp. 79-83. 1999.
Ratan, A. L., O. Maron, et al., A framework for learning query concepts in image classification, In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, (1999), 423-429.
Rosenfeld, A., R. Hummel and S. Zucker, Scene Labeling by Relaxation Operations, IEEE Trans. Systems, Man and Cybernetics 6 (1976), 420-433.
Rui, Y., T. S. Huang, et al., Relevance Feedback: A Power Tool for Interactive Content-Based Image Retrieval, IEEE Trans. on Circuits and Video Tech., Special Issue on Segmentation Description, and Retrieval of Video Content, 8(5), 1998.
Shapiro, L. G., and R. M. Haralick, Structural Descriptions and Inexact Matching, IEEE Trans. Pattern Analysis and Machine Intelligence 3 (1981), 504-519.
Umeyama, S., An Eigen-Decomposition Approach to Weighted Graph Matching Problems, IEEE Trans. Pattern Analysis and Machine Intelligence, 10 (1988), 695-703.
Wilson, R. C., and E. R. Hancock, Structural Matching by Discrete Relaxation, IEEE Trans. Pattern Analysis and Machine Intelligence 19 (1997), no. 6, pp. 634-648.

APPENDIX

A	Simplify the Maximum-Likelihood Function
Here, we simplify eq.(9) by simplifying its three terms separately. In the follow-
ing derivations, we use the function δm,n and the fact that ΣM  P (qj|Gj, Θ(t))= 

N
yjk=1
f (yjk|Gj, Θ(t)) = 1 from time to time. Note that δm,n = 1 if

m = n and δm,n =0 if m /= n.

Simplify the first term of eq.(9).


Σ Σ ··· Σ
··· Σ
Σ ··· Σ
Σ(log P (qi)) 

  P (qj|Gj, Θ(t))

q1=1 y11=1
y1U1 =1
Uj
qS=1 yS1=1
ySUS =1 i=1
j=1



M	N	N	M	N	N	S	M
= Σ Σ ··· Σ ··· Σ Σ ··· Σ Σ Σ δqi,h(log P (qi))
q1=1 y11=1	y1U1 =1	qS=1 yS1=1	ySUS =1 i=1 h=1




 j=1
  P (qj|Gj, Θ(t))
Uj


k=1
f (yjk|Gj, Θ(t)) 

S	M	M	N	N	M	N	N

= Σ Σ(log P (h)) Σ Σ ··· Σ ··· Σ Σ ··· Σ
δqi,h

i=1 h=1
 
q1=1 y11=1
y1U1 =1
Uj


qS=1 yS1=1
 


ySUS =1

= Σ Σ
(log P (h)) Σ
··· Σ
Uj
δq ,hP (qj|Gj, Θ(t))
f (yjk|Gj, Θ(t)) 

i=1 h=1
q1=1
qS=1 j=1
k=1 yjk

Σ Σ	Σ	Σ 
			

		
S	M	S	M
= Σ Σ log(P (h))   δq ,h Σ P (qj|Gj, Θ(t))

i=1 h=1
j=1
qj =1

S	M	S	M
= Σ Σ log(P (h))Pq (h|Gi, Θ(t))= Σ Σ log(αh)Pq (h|Gi, Θ(t))

i
i=1 h=1
i
i=1 h=1
(A.1)


Simplify the second term of eq.(9). The same method for simplifying the

first term of eq.(9) is used here.

Σ Σ	Σ	Σ Σ	Σ Σ

···	···	··· 
q1=1 y11=1	y1U1 =1	qS=1 yS1=1	ySUS =1 i=1 m=1
log
p(oim|ωqiyim )P (yim|qi)




 j=1
  P (qj|Gj, Θ(t))
Uj


k=1
f (yjk|Gj, Θ(t))

M	N	N	M	N	N	S	Ui	N

= Σ Σ ··· Σ
··· Σ Σ ··· Σ
Σ Σ Σ δyim,η

q1=1 y11=1	y1U1 =1
 

qS=1 yS1=1
  S
ySUS =1 i=1 m=1 η=1
Uj



Σ	Σ Σ
		 

	

Σ ··· Σ
··· Σ
··· Σ

δyim,η 
Uj
P (qj|Gj, Θ(t))
f (yjk|Gj, Θ(t)) 

y11=1	y1U1 =1
yS1=1
ySUS =1
j=1
k=1

Σ	Σ Σ

=
q1=1 S
··· 

qS=1 i=1 m=1 η=1
log
p(oim|ωqiη )P (η|qi)
fyim
(η|Gi, Θ(t))

P (qj|Gj, Θ(t))
j=1
Σ	Σ Σ

=
q1=1 S
··· 

qS=1 i=1 m=1 η=1 h=1
δqi,h log
p(oim|ωqiη )P (η|qi)
fyim
(η|Gi, Θ(t))

P (qj|Gj, Θ(t))
j=1
Ui

Ui
	  	

S	Ui	N	M

Σ Σ Σ Σ log(βhη)fy
(η|Gi, Θ(t))Pq (h|Gi, Θ(t))

i=1 m=1 η=1 h=1
im	h	i

(A.2)


Simplify the third term of eq.(9). Again, the same simplification method

is used.


Σ Σ ··· Σ
··· Σ
Σ ··· Σ

Ui	Ui

log

 p(ricd|঩−→y

i (ricd)) 

q1=1 y11=1
y1U1=1
qS=1 yS1=1
ySUS =1 i=1
c=1 d=1




 j=1
  P (qj|Gj, Θ(t))
Uj


k=1
f (yjk|Gj, Θ(t)) 

M	N	N	M	N	N	S	Ui	Ui	N	N

= Σ Σ ··· Σ
··· Σ
Σ ··· Σ
Σ Σ Σ Σ Σ δyic,σδyid,τ

q1=1 y11=1
y1U1=1
qS=1 yS1=1
ySUS =1 i=1
c=1 d=1 σ=1 τ =1

log

 p(ricd|঩−→y
S
i (ricd))
j=1
  P (qj|Gj, Θ(t))
Uj


k=1
f (yjk|Gj, Θ(t)) 

= Σ ··· Σ Σ
Ui	Ui
log
  p(ricd|ψqiστ )

q1=1
qS=1 i=1 c=1 d=1 σ=1 τ =1
S


fyic
(σ|Gi, Θ(t))fy
(τ|Gi, Θ(t))   P (qj|Gj, Θ(t))

Σ	Σ Σ


Ui	Ui
j=1
Σ Σ

=
q1=1
··· 
qS=1 i=1 c=1 d=1 σ=1 τ =1 h=1
S
δqi,h log p(ricd|ψqiστ )


fyic
(σ|Gi, Θ(t))fy (τ|Gi, Θ(t))   P (qj|Gj, Θ(t))

j=1
Ui	Ui

 

Pq (h|Gi, Θ(t))
(A.3)


Finally, we can obtain eq.(10) by submitting eq.(A.1), (A.2), (A.3) into eq.(9).



B  Derive Expressions for Updating αh and βhη

The four terms of the eq.(10) can be maximized separately while we try to calculate Θ(t+1).
First, we derive the update expression for αh by maximizing the first term of eq.(10). We introduce the Lagrange multiplier λ with the constraint that Σhαh = 1, and solve the following equation:




 ∂ 	S
∂αh
M
log(αh)Pq (h|Gi, Θ(t))+ λ

αh − 1 

i=1 h=1
S
h=1

= Σ  1 P
(h|G , Θ(t))+ λ =0 =⇒

α	qi	i
i=1
(B.1)

ΣM  ΣS
 1
Pq (h|Gi, Θ(t))+ λ
αh
 =0 =⇒ λ = −S =⇒

h=1
i=1
S
Pq (h|Gi, Θ(t))

αh = 	i=1	i	
S

Secondly, we derive the update expression for βhη by maximizing the second term of eq.(10). Again , we introduce the Lagrange multiplier λ with the constraint that Σηβhη = 1, and solve the following equation:


 ∂  ΣS  Σ

Ui
log(βhη)fy
N
(η|Gi, Θ(t))Pq (h|Gi, Θ(t))+ λ

βhη − 1 

∂βhη
S
i=1 h=1 m=1 η=1 Ui
im	h	i
η=1

= Σ Σ  1  f


(η|G , Θ(t))P
(h|G , Θ(t))+ λ =0 

Σ Σ ΣS


Ui  1 
			


ΣS	Ui
M ΣS
ΣUi
fy	(η|Gi, Θ(t))Pq (h|Gi, Θ(t))

M	hη
i=1 Ui

(B.2)


It will not be difficult to find out that eq.(11) and eq.(12) are eq.(B.1) and eq.(B.2) with the iteration index added respectively.


C Derive Expressions for Updating the Parameters of the Gaussian Attributed and Relational Distribu- tions
For Gaussian distribution assumptions, we obtain analytical expressions for updating the parameters of the distribution functions. (1) For Gaussian at- tributed distribution (eq.(13)), the update expression for the attributed dis- tribution parameters are derived by maximizing the third term of eq.(10).




S	M	Ui	N

Σ Σ Σ Σ log(p(oim|ωhη))fy


(η|Gi, Θ(t))Pq (h|Gi, Θ(t))

= Σ Σ
−1  ξ log(2π) + log(|Σ(t+1)|)+ (−→a
− −→µ (t+1))T
(C.1)

2
i=1 h=1 m=1 η=1
hη	im	hη

Σ(t+1)−1(−→a	− −→µ (t+1)) f
(η|G , Θ(t))P (h|G , Θ(t))


Take the derivative of eq.(C.1) with respect to −→µ (t+1) and set it equal to zero,
we can have:
S	Ui

Σ Σ Σ(t+1)−1(−→a
− −→µ (t+1))f
(η|G , Θ(t))P (h|G , Θ(t))=0 

hη
i=1 m=1
im	hη
yim
i	h	qi	i
(C.2)

ΣS	ΣUi
−→a	f
(η|G , Θ(t))P
(h|G , Θ(t))

hη	ΣS
ΣUi	f
(η|G , Θ(t))P
(h|G , Θ(t))

Take the derivative of eq.(C.1) with respect to Σ(t+1) and set it equal to zero,
we can have:


Ui
T

diag(Σ(t+1) − −→x (t) −→x (t) T )  =0 

hη
S	Ui
im	im
(C.3)

⇒ Σ Σ f
(η|G , Θ(t))P
(h|G , Θ(t))(Σ(t+1) − −→x (t) −→x (t) T )



ΣS	ΣUi
−→x (t) −→x (t) T f
(η|G , Θ(t))P
(h|G , Θ(t))

hη	ΣS
ΣUi	f
(η|G , Θ(t))P
(h|G , Θ(t))

where −→x (t) = −→a im
i=1
− −→µ (t).
m=1
yim
i	h	qi	i


For Gaussian relational distribution (eq.(16)), the update expressions for the relational distribution parameters are derived by maximizing the fourth term of eq.(10). Using the same procedure for deriving the expressions for

−→(t+1)
hη
and Σ(t+1), we can obtain the update expressions for −→γ
hστ
and Λhστ

as eq.(17) and eq.(18) respectively. Due to the space problem, the details will
be neglected here.
