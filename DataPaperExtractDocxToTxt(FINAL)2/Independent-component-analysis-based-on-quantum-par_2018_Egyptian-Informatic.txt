Egyptian Informatics Journal 19 (2018) 101–105








Full length article
Independent component analysis based on quantum particle swarm optimization
Nidaa AbdulMohsin Abbas a,⇑, Hussein Mohammed Salman a,b
a University of Babylon, Faculty of IT, Iraq
b University of Babylon, Faculty of Material Engineering, Iraq



a r t i c l e  i n f o 

Article history:
Received 21 May 2017
Revised 26 October 2017
Accepted 19 November 2017
Available online 27 November 2017

Keywords:
ICA
Kurtosis Negentropy PSO
QPSO
a b s t r a c t 

One of the Digital Signal Processing problems is a Blind Source Separation (BSS). There are some of meth- ods are employed to solve this problem which are so-called Independent Component Analysis (ICA) which based on the statistical distribution of the signal. Many mechanisms are used to improve the ICA as neural networks, genetic algorithm and particle swarm optimization. In this paper, a new method is introduced to improve the performance of the ICA using Quantum Particle Swarm Optimization (QPSO). A Negentropy is used as the fitness function of the proposed algorithm to maximize the independence of the statistical distribution of mixed signals, easily separated and recover the original signals. The algo- rithm is implemented with many speech signals under some conditions as the frequency of 8 kHz, the
i.i.d. and well-condition. The proposed method is considered the best from the previous method that depending on some measurements as SNR and SDR. The performance of this method has been tested on two metrics Signal-to-Noise Ratio (SNR) and Signal-to-Distortion Ratio (SDR).
© 2017 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo
University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/
licenses/by-nc-nd/4.0/).






Introduction

A Blind Source Separation (BSS) is one of the DSP which aims to estimate a set of latent source signals using that is a set of available statistical properties about these signals. The BSS appeared in the 1980s then expanded rapidly. There are many books describe the BSS in details as [1–3].

Abbreviations: BSS, Blind Source Separation; DSP, Digital Signal Processing; ICA, Independent Component Analysis; PCA, Principal Component Analysis; JADE, Joint Approximate Diagonalization of Eigen-matrices; EASI,, Equivariant Adaptive Sepa- ration via Independence; SOBI, Second Order Blind Identification; RADICAL, Robust, Accurate, Direct Independent Component Analysis Linear; i.i.d., identical and independent distribution; PSO, Particle Swarm Optimization; QPSO, Quantum Particle Swarm Optimization; SNR, Signal-to-Noise Ratio; SDR, Signal-to-Distortion Ratio; CE, Contrast-Expansion.
* Corresponding author.
E-mail addresses: drnidaa_muhsin@ieee.org (N.AbdulMohsin Abbas), hus12ms@gmail.com (H.M. Salman).
Peer review under responsibility of Faculty of Computers and Information, Cairo University.
In the BSS, multiple signals are obtained by an array of sensors and processed in order to recover the initial multiple source sig- nals. It assumes that the observed data was generated by interac- tions between latent variables.
The most commonly mechanism for analyzing latent data is Independent Component Analysis (ICA). ICA is a probabilistic and statistical method for separating a multivariate signal into additive subcomponents supposes the mutual statistical independence of the non-Gaussian signals of the sources. ICA methods use one of two properties: Non-Gaussianity or sample dependence [1,2].
The independence assumption is correct in the most cases, so, the blind, ICA, separation of mixed signals gives very good results. The methods, that use the statistical properties of the signals, it will find the independent components by minimizing the statisti- cal dependence of the estimated signal factors (components). Non-Gaussianity feature used to measure the independence of the component, by the kurtosis measurement or approximation of negentropy [4].
There are a linear and non-linear of ICA depending on the func- tion of the mixing operation. In the linear ICA, there are many methods such as: Non-linear PCA [5], JADE [6], EASI [7,8], SOBI [5], FastICA [8], INFOMAX (also called Bell-Sejnowski) [8], and RADICAL [9]. Also there are another methods, all these methods



https://doi.org/10.1016/j.eij.2017.11.001
1110-8665/© 2017 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



assume that the source signals (observations) are generated by using invertible filter driven by an independent identical distribu- tion (i.i.d.) random process [2]. So, all ICA methods follow same pre-processing procedures centering, whitening and de-noising processes.
In this paper, a new technique is proposed for the independent component analysis using Quantum Particle Swarm Optimization (QPSO). The QPSO algorithm is one probabilistic algorithm. It does not need to velocity vectors of particles, it requires a fewer param- eters and easier to implement. So, it has been good performance to solve a wide range of optimization problems [10,11].
In this paper, cocktail-party problem processed using Quantum Particle Swarm Optimization with kurtosis and negentropy as fit- ness function, to enhance the performance of ICA algorithm. The results showed that the accuracy of this technique is better than the particle swarm optimization. Accordingly, the QPSO is tested using many subjective (as figures and play) and objective metrics (as SNR and SDR). The characteristics of tested speeches signals: 8 kHz sample frequency, male and female of music signals.
The rest of this paper is organized as: Section 2 shows the back- ground theory which includes the fundamentals of ICA, PSO and QPSO. Section 3, the proposed technique is technique. Section 4 describes the results of experiments, and evaluates them of some evaluation measurements. The conclusion is reported in Section 5. Finally, the references in Section 6.

Literatures review

Azad and Hatam [16] proposed a method which combines the genetic algorithm and the PSO for solving maximum likelihood ICA problem. The method gives some improvement to the ICA but it consumes more computational requirements via Genetic Algorithm.
Li et al. [17] presented a method to reduce the drawbacks in the BSS by using improved Particle Swarm Optimization (PSO). Their method is based on updating the dynamic inertia weight in PSO and introduce the fitness function of PSO based on BSS.
Saikia et al. [18] proposed an algorithm to solve the BSS by using the discreet wavelet transform to transform the signal into wavelets and apply various shrinkage methods to de-noise the signal.
Krusienski and Jenkins [19] proposed a method to improve the nonparametric Independent Component Analysis by employing the advantages of the PSO algorithm.

Background theories

Independent Component Analysis (ICA)

ICA is a method which depends on the statistical properties of the mixed signals to estimate the original source signals. It only assumes that the mixed source signals are statistically indepen- dent without any prior information about the observation signals. The mathematical model of the unobservable signal and the observed mixed signal:
x(t)= As(t)	(1)
where s(t) denotes source signals, x(t) denote observed signals, A represents the matrix of mixing coefficients, and t represents time index. The aim of ICA is to estimate the inverse of the mixing matrix A,(W) that result y, the possible linear model of s:
y(t)= Wx(t)	(2)
where y(t) represents an estimating of s(t), while W denotes an esti- mated matrix of the separation process. Most of ICA algorithms can
be consist of two steps; the first one is called whitening process, in this step applying second order statistics for decoration. The aim of this step is to estimate the orthogonal matrix which necessary to independence that achieved in the second step [1,2].
The result of the approximation of independence hypothesis is the estimation of sources which is transformed into an optimiza- tion problem described by the contrast function that is minimum when the estimated sources are as independent as possible.

Pre-processing of ICA

Centering: It includes computing the mean of the observation signal and then subtract this mean from the observation source itself:
x' = x — E[x]	(3)
Add the mean vector to the estimated source vector, subsequently:
s = s' + A—1E[x]	(4)

Whitening: It whitens the mixed signal x. To obtain the obser- vation signals uncorrelated and have unit variance, applying the linear model transformation:
~x = KD—1/2KT x	(5)
where the columns of K and diagonal D are eigenvectors and the eigenvalues of E[xxT ] respectively. The aim of whitening process is orthogonal the mixing matrix. The orthogonal mixing matrix halves the number of estimated parameters, so, it has n (n—1)/2 free parameters [2].

Contrast (objective) functions in ICA

Negentropy (Negative Entropy): The randomness of the vari- able is measured by the entropy metric. For a discrete variable, the entropy is
H(Y)= — P(Y = ai) log P(Y = ai)	(6)
i

where the H represents the entropy of the mixed signals and esti- mates of the source signals. A Gaussian variables have larger entropy than other discrete and continuous variables. The Negen- tropy used to measuring the non-Gaussianity of the components, as the following model:
J(y)= H(yG )— H(y)	(7)
where yG represents a Gaussian variable. That J(y) is non negative, and for the Gaussian variable equals to zero. Negentropy is statisti- cally robust, but intensive is computationally, and non-parametric
possibly. Also its estimation is difficult, therefore the approxima- tions are used for this purpose: [2]
J(y)/ [E{G(y)} — E{G(v)}]2	(8)
where v and y represent Gaussian vectors without means (zero mean), also G denote the no quadratic function.

Kurtosis: It is the another measurement of non-Gaussianity, is the fourth order cumulant
kurt(y)= E[y4]— 3(E[y2])	(9)
Kurtosis can have any sign (—,+,0): (negative) subGaussian, (positive) superGaussian and (zero) Gaussian. The computation of the Kurtosis is being cheaper than other measurements.



The Particle Swarm Optimization (PSO)

Kennedy and Eberhart were devised a new method of optimiza- tion which is called Particle Swarm Optimization that is taken from the behavior of bird flocking [12].
The PSO algorithm starts with random particles and seeks about better solution than these initial particles and updated the swarm for the optimal solution based on its own experiences. The algo- rithm updates its parameters depending on two main factors:
present a good performance in solving a wide range of continuous optimization problems. It can be illustrated as:
It supposes that the individual particle seeks in the search space with a d potential on a specific dimension, around the point pij. Simplicity, the particle is represented in a specified dimensional space, with the center p of the potential. The Schrödinger equation is solved of specified dimensional d potential well, It can obtain the distribution function F and the probability density function Q as:
1

The velocity and the position of each particle in n-dimension for all particles. It repeat the searching and updating for n iteration as:
Q (Xij(t + 1)) = Lij (t)
e—2|pij (t)—xij (t+1)|/Lij(t)	(12)

vi (t + 1)= wvi (t)+ c1r1(t)(pbesti (t)— xi(t)) + c2r2(t)(gbesti (t)— xi(t))
(10)

xi(t + 1)= xi(t)+ vi(t + 1)	(11)
where v represents the velocity of the particle P, x denotes the posi- tion of P, pbest represents the best local (personal) position of the current P and gbest represent the best global position of all P’s in the search space in n-dimension, w represents an inertia weight (for the convergence speed), c1 and c2 are two parameters which represent the acceleration constants, Also, r1 and r2 represent two
random parameters valued in the range [0–1], [10,12].
F(Xij(t + 1)) = e—2|pij (t)—xij (t+1)|/Lij(t)	(13)
where Lij(t) represents the standard deviation of the distribution by using the Monte Carlo method as in (14), the position of the particle is:
Xij(t + 1)= Pij(t) Lij(t) ln(1/u),  u = rand(0, 1)	(14)
2
To evaluate Lij, a global point m called mean best position of the population. The m represents the mean of the pbest positions of all particles.
m(t)= (m1(t), m2(t), ..., mn(t))


Quantum Particle Swarm Optimization (QPSO)
1 M


M i=1
M
P	t 
i=1
M
P	t	
i=1
Pi,n(t)!

(15)

As mentioned (Jun Sun and others) in (the papers and books) [10,11,13], since 2004, the QPSO method represents the develop- ment version of the PSO method. QPSO does not need velocity vec- tors and has fewer parameters, and easier to implement. It can
where M is the population size and Pi is the pbest position of particle
i. The values of Lij(t) is:
Lij(t)= 2b * |mj(t)— Xij(t)|	(16)


Table 1
Plot the original, mixed and separated speeches signals.






Table 2
Results of measurement criteria for the speeches in Table 1.
where s(n) denotes the original source signal before mixing, and
^s(n) denotes the estimated signal.

Signal to distortion ratio (SDR): is calculated as:
P s(t)2

SDR = 10log 	t	 (dB)	(19)
t



and thus the position is:
Xij(t + 1)= Pij(t) b * |mj(t)— Xij(t)| * ln(1/u)	(17)
where b is contraction–expansion coefficient, is the control of the convergence of the algorithm. The PSO algorithm with Eq. (17) is QPSO algorithm.

Measurement criteria

In order to evaluate the performance of proposed system, many subjective metrics (as plotting of speeches signals and playing these speeches) and objective metrics (as SNR and SDR) are used. The plotting of the speeches signals are illustrated perfectly in figures at Table 1. The figures describe the accuracy between the original signals and the estimated signals after separated them.
The measurement metrics between the original speech signals and the separated speech signals, as SNR and SDR that are used in the evaluation process, can be shown in Table 2. The best range of SNR metric is between 0 and 1, the best results of SNR are closest to 0; whereas in the SDR metric, a higher value is good and desired [3,14,15].

Signal to Noise Ratio (SNR): is computed as:
P∞	s2(n)
  
where s(t) denotes the original source signal before mixing, and ~s(t) denotes the estimated signal.

Proposed system

The proposed system consists of two main stages: firstly, it includes the ICA and secondly, it includes enhancing the first stage results by implementing the QPSO algorithm. The system imple- ment the ICA method to process the cocktail-party problem which means how to separate many mixed sounds that received by many sensors (microphones). Inside the first stage, there are many steps as follows:

Initializing the free noise speech signals, at least two signals, and under i.i.d. (identical independent distributed) property, in same length and same frequency (the system deals with sounds 8 kHz).
Mix the speech signals, by using Eq. (1) after initializing the mixture matrix that achieves the well-condition, and gives best mixed signal.
Implementing the preprocessing of ICA on the result of step 2, preprocessing include centering and whitening (as mentioned in Section 3.1.1)
Implementing the Negentropy and Kurtosis as the contrast func- tions in ICA to separate the mixed signals (as mentioned in Section 3.1.2).



 

Fig. 1. Flowchart of the block-diagram of the proposed method.



Second stage, also, include following steps:

Initialize the parameters of the Quantum Particle Swarm Opti- mization as: population, maximum iteration (maxiter), and a parameter (sometimes called Contrast-Expansion coefficient
(CE)). Where population = 10, and maxiter = 50. So, in the proposed system, the a parameter, which is very important parameter in the QPSO algorithm, takes a value from the range
[0.5–2.0], where 0.75 gives best results in the optimization process.
Setting of fitness value and fitness function of the optimization method. Which use the Negentropy and Kurtosis as the fitness function.
The centering and whitening implement in each iteration.
Setting the ‘‘mean best” parameter of the particles mbest, according in Eq. (15).
During each iteration, the algorithm update the fitness value according to the results of the fitness function, and selects the best values. Until terminate the iterations.
After QPSO, evaluating the results that depends on some subjec- tive evaluation metrics (as signals depict and playing) and objective evaluation metrics (as SNR and SDR).

The above steps of the proposed system is illustrated in a dia- gram, in Fig. 1.

Simulation result and analysis

To achieve the validity of the proposed system, many pairs speech signals are examined, most of these speeches have been taken from the link of the database (‘‘ecs.utdallas.edu/loizou/spee ch/noizeus/”), these speeches clean (without noise) and in different conditions spoken with men and women. Cocktailing is simulated with two different speech signals, and input them to the system. According to the measurement metrics, the graphical results have been illustrated in Table 1.
Table 2 shows the measurement metrics between the original speech signals and the separated speech signals, as SNR and SDR, which used in the evaluation process, the best range of SNR metric


SNR-Measurment
0.4
0.3
0.2
0.1
0
A	C	D	E	F
 Proposed   FastICA

Fig. 2. The SNR measurement of the proposed method and the FastICA.


SDR-Measurement
60
50
40
30
20
10
0
A	C	D	E	F
 Proposed  FastICA

Fig. 3. The SDR measurement of the proposed method and the FastICA.
is between 0 and 1, and the best results are closest to 0; whereas the SDR metric, a higher value is good and desired.
In order to analyze the results of the algorithm implementation, two signal accuracy measurements (SNR and SDR) are applied as shown in Table 2. When, the traditional FastICA algorithm is applied with same samples of the speeches and/or sounds and sketch the results of both methods, the proposed method shows similar and sometime better than the FastICA and more stable. As shown in Figs. 2 and 3 .

Conclusion

The ICA methods are used in many disciplines (signals separa- tion, feature extraction, image compression, image encryption, etc.) especially in the recently years. Also, in the optimization field, recent direction focus on the QPSO method. This research employs the benefits of QPSO to enhance the performance of the ICA algorithm as new technique used in speech separation. The cocktail-party problem is studied of real different speeches signals of sampling frequency 8 kHz for different speakers and different sentences. The results are excellent, according to the signal plotting, SNR and SDR evaluation metrics.

References

Comon P, Jutten C. Handbook of blind source separation, independent component analysis and applications. Oxford: Academic Press; 2010.
Hyvarinen A, Karhunen J, Oja F. Independent component analysis. John Wily & Son; 2007.
Makino S, Lee TW, Sawada H. Blind speech separation. Springer; 2007.
Muhsin NA. A comparison among adaptive ICA algorithms for blind speech signals separation: cocktail party problem Ph.D. thesis. Iraq: University of Technology; 2006.
Sadkhan SB, Alnaji AJ, Muhsin NA. Performance evaluation algorithms based on neural networks. CSNDSP (5th International Symposium on Communication Systems, Networks and Digital Signal Processing), Greece, 2006.
Zhang K, Tian G, Tian L. Blind source separation based on JADE algorithm and application. In: 3rd international conference on mechatronics, robotics, and automation (ICMRA 2015).
Hyvarinen A. Independent component analysis: recent advances. Royal Society Publishing; 2016. December.
Mutihac R, Van Hulle MM. A comparative survey on adaptive neural network algorithms for independent component analysis. Faculty of physics, university of Bucharest, 76900 Romania.
Krishnaveni V et al. Comparison of independent component analysis algorithms for removal of ocular artifacts from electroencephalogram. Measur Sci Rev 2005;5. section 2.
Sun J, Lai C, Wu X. Particle swarm optimization classical and quantum perspectives. CRC Press; 2012.
Sun J, Feng B, Xu W. Particle swarm optimization with particles having quantum behavior. IEEE; 2004.
Kennedy J, Eberhart R. Particle swarm optimization. In: Proceedings of the IEEE international conference on neural networks, Perth, Australia; 1995. p. 1942–8.
Xi M, Sun J, Xu W. An improved quantum-behaved particle swarm optimization with weighted mean best position. Appl Math Comput 2016;11 (2):121–32. Elsevier Inc..
Abbas Nidaa AbdulMohsin. Image encryption based on Independent Component Analysis and Arnold’s Cat Map. Egyptian Inf J 2016;17 (1):139–46. Publisher Elsevier.
Vincent E et al. Performance measurement in blind audio source separation. IEEE Transactions on Audio, Speech and Language Processing, Institute of Electrical and Electronics Engineers 2006;14(4):1462–9.
Azad H, Hatam M. Maximum likelihood independent component analysis using GA and PSO. In: 2016 24th Iranian conference on electrical engineering (ICEE). IEEE; 2016.
Li M et al. Blind source separation based on improved particle swarm optimization. In: International conference on artificial intelligence and computational intelligence 2009. IEEE Computer Society; 2009.
Saikia B et al. Speech signal denoising using ICA-DWT and different shrinkage algorithms. IJRSI 2015;II(IV).
Krusienski D, Jenkins W. Nonparametric density estimation based independent component analysis via particle swarm optimization. ICASSP- 2005, IEEE 2005.
