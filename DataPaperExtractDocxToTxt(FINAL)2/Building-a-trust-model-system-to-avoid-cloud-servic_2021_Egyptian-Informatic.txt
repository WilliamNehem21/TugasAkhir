Egyptian Informatics Journal 22 (2021) 493–503











Building a trust model system to avoid cloud services reputation attacks
Salah T. Alshammari ⇑, Aiiad Albeshri, Khalid Alsubhi
Department of Computer Science, College of Computing and Information Technology, King Abdul-Aziz University, Jeddah, Saudi Arabia



a r t i c l e  i n f o 

Article history:
Received 8 August 2020
Revised 4 January 2021
Accepted 6 April 2021
Available online 1 June 2021

Keywords:
Trust model Reputation attacks Cloud computing On–off attack Collusion attack Sybil attack
a b s t r a c t 

The safety of cloud services within a Trust Model System (TMS) is certainly compromised by a lack of defense against security threats as well as by inaccuracy of the trust results. Our proposed model addresses well-known security threats to the reputation trust model system, and is shown to deal with all possible potential attack threats, such as Sybil, on–off, and collusion attacks, by specifying the identity of users and tracking activities undertaken by them in order to easily track unauthorized consumers or attackers and to provide proof of any kind of data leakage. The TMS can also oversee the authorization of whoever uploads feedback into the system. It can also identify invalid feedback and discard it from the system. The algorithms of the TMS first establish a variety of trust criteria in which trustworthiness is calculated. Then, feedback from the cloud service provider nodes is accepted only according to the rules of the TMS. A consumer’s trust value is finally computed using a flexible system capable of guaranteeing a good balance of consumer trust and owners’ feedback. Furthermore, a majority of the existing TMS mod- els do not take full account of interaction importance, thus impeding the accuracy of the trust values, a shortcoming that has been rectified in our proposed model.
© 2021 THE AUTHORS. Published by Elsevier BV. on behalf of Faculty of Computers and Artificial Intel-
ligence, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creative-
commons.org/licenses/by-nc-nd/4.0/).







Introduction

Consumers of cloud computing services are constantly exposed to a variety of threats, including trust and reputation attacks. These threats arise from the highly dynamic, distributed, and non- transparent nature of cloud computing services [1], which makes it extremely challenging for cloud service providers and consumers to maintain and manage trust within the cloud system [2]. Risks can also be attributed to the fact that cloud computing services are offered in a public domain, which gives access to many users. Threats are evident from the behavior of malicious users of cloud services who frequently submit feedback on their experiences with other cloud service consumers.

* Corresponding author.
E-mail addresses: salshammari0042@stu.kau.edu.sa (S.T. Alshammari), aaal- beshri@kau.edu.sa (A. Albeshri), kalsubhi@kau.edu.sa (K. Alsubhi).
Peer review under responsibility of Faculty of Computers and Artificial Intelligence, Cairo University.
According to Noor, Sheng, and Alfazi [1], service providers’ feed- back on their clients is a good source of information that can be used to assess the trustworthiness of cloud service consumers. Var- alakshmi, Judgi, and Balagi [3] also highlight the importance of ser- vice providers’ feedback in computing trust for cloud-based service consumers. Trust management systems and detection systems for reputation attacks have been extensively used by cloud computing providers and consumers to enhance the security and privacy of online data.
Despite the availability of trust management and reputation attack detection systems, cloud computing systems still experience targeted attacks from a variety of sources [4,5,6]. The literature reveals a gap in the availability of detection strategies targeted against reputation attacks [7,8]. This study will therefore provide essential insights on how reputation attack detection can be effectively used for effective assessment in cloud services, and particularly in addressing the reputation attacks that undermine trust assessment in cloud computing. This research will contribute significantly to the existing literature on how consumers and pro- viders of cloud services can enhance the security and privacy of the services, hence improving the overall user experience.
The fact that cloud services are often provided in the public domain makes security and privacy crucial and ought to be main-



https://doi.org/10.1016/j.eij.2021.04.001
1110-8665/© 2021 THE AUTHORS. Published by Elsevier BV. on behalf of Faculty of Computers and Artificial Intelligence, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



tained as public platforms that can be accessed by a wide range of users [9,10,11]. The invention of cloud data storage is certainly rev- olutionary, as it has eliminated the costliness, inconvenience, and need for more space that additional hardware brings. It allows sig- nificantly large amounts of data to be stored at a low cost [12,13]. This has dramatically increased the number of cloud services offered online as well as the number of consumers of such services. However, privacy and security have always been a challenge for digitally available data, as most of the data resides in the public domain, where every model of trust management service is endan- gered by some security threats [14]. These threats may either ele- vate the reputation of a specific entity with malicious intentions or entirely ruin it. Security threats that endanger a trust management service may sometimes arise from the consumers of the service themselves. However, in such cases, it can be very difficult to determine which kind of activities are malicious.

Problem statement

Authorization issues concerning access to cloud computing storage are of serious concern when there are a large number of consumers using the big data of cloud computing for sensitive data [15,16,17]. In most cases this has resulted in the use of access con- trols in cloud computing server application platforms. Neverthe- less, a serious lack of reliability has been discovered on access controls associated with distributed systems. This has been largely caused by failure to establish consumers’ identity in advance and their dynamic and complex population [18,19]. Such concerns can be properly attended to through the integration of control models with trust models as a better alternative for decentralized systems [20,21]. These models have resulted from a series of attempts by developers to design new trust models capable of resolving the most intricate and advanced issues of authorization [22,23]. There have been several proposals on integrated trust models with access controls that are still vulnerable to some attacks [24,25]. These threats may either elevate the reputation of any entity with a distinct extent with malicious intentions or entirely ruin it [26]. The security threats endangering a trust man- agement service may sometimes arise from the consumers of the service themselves.
One of the common types of threats in cloud environments is an on–off attack, where the user of a cloud service acts maliciously within a small time period but resumes the proper code of conduct afterward with the aim of deceiving the trust system and main- taining his/her own reputation. Another type of threat is a collu- sion attack, also called collusive malicious feedback behaviors, in which a group of people acting in concert gives false feedback aimed at ruining the reputation of someone else (a slandering attack) or increasing their own position (a self-promoting attack). Finally, there is the Sybil attack, where the attacker begins by cre- ating multiple memberships within the trust management service. Afterward, he/she make use of these fake identities in giving par- ticular people/entities regular feedback, which could either be pos- itive or negative. As such, the adversary is capable of boosting or ruining the reputation of those entities. This paper focuses on building a Trust Model System (TMS) that ensures the security of a cloud storage system by preventing reputation attacks.

Contribution

Among the key security requirements in cloud computing is access control. This is due to the fact that user access occurs remo-
tely when an organization transfers its applications to the cloud, which calls for the need to establish access control policies. Several studies have addressed a wide range of access control policies that seem suitable for implementation in cloud computing, but it is still vulnerable to some threats. In order to cover all threats in the pro- posed trust model, we will propose strategies that must be taken into consideration when we design our trust evaluation process. This paper will endeavor to decide the best possible solution to the trust issues with access control approaches and will propose trust models that can improve the security of information in dis- tributed storage frameworks that utilize cryptographic access con- trol approaches. In the investigation, it was determined that a trust model should provide accurate results in the assessment of trust- worthiness, which is the basis of our plan for the proposed trust- based distributed storage framework. The plan permits trust proto- types to be coordinated into a framework that utilizes the crypto- graphic access control approach. To make this effective, we propose a trust model that contributes to the following:

Upholding the utmost privacy of the consumers of cloud ser- vices, as their association with the trust management services may involve highly sensitive data.
Effectively protecting cloud services through effective detection of malicious as well as unbecoming behaviors by applying trust algorithms that detect on–off attacks, collusion attacks, and Sybil attacks, where each trust algorithm employs different cri- teria to avoid reputation attacks.
Ensuring trust management service availability sufficient to cloud services’ dynamic nature.
Offering reliable solutions for preventing reputation attacks and making consumers’ trust values more accurate by taking inter- action importance into consideration.

Related works

The number of techniques used to assess and manage trust for online services has been growing recently. The techniques, accord- ing to Noor, Sheng, and Alfazi [1] in 2013, are informed by feedback from consumers of cloud services. The advantage of this study is that the techniques focus on detecting the occasional and periodic reputation attacks that frequently hinder the security and privacy of cloud computing. However, the authors did not focus on how to prevent these attacks.
The evident lack of focus on solutions for periodic and occa- sional reputation attacks on cloud services can be attributed to the dynamic nature of cloud computing, which is further compli- cated by the fact that a single consumer may own multiple accounts for accessing a single service. The study by Noor, Sheng, and Alfazi [12] in 2013 provided essential information regarding the efficiency of occasional attack detection models in detecting occasional and period reputation attacks but did not focus on specific attacks such as on–off attacks. In 2014, Noor, Sheng, and Bouguettaya [27] also explored trust management in cloud computing, but their work not discuss how trust management models could avoid the three mentioned attacks. In 2015, Tong, Liang, Lu, and Jin [28] proposed a trust model that considers score value similarity and collusion size score but does not consider the effect of scoring time, nor include provisions to avoid all reputa- tion attacks.
Similarly, in 2015 Labraoui, Gueroui, and Sekhri [29] carried out a study to assess the effectiveness of trust and reputation networks in hindering reputation attacks. The study proposed the on–off (O2)



trust mitigation for trust systems, which is used in wireless sensor networks. The mitigation system works by penalizing the history of misbehavior on each network node. The penalties affect the trust value of each network node, hence averting the consequences of
expressed as a percentage. Interaction Trust (IT) is calculated as (1).

misbehavior. The main contribution of this study is that it provides essential information regarding the O2 Trust approach. However, it
n—1
IT(CR) =	 
at (CR) + PCR
at (CR) + PCR + bt(CR) + NCR 
(1)

does not explore whether the same approach would be effective in averting collusion and Sybil Attacks.
In 2018, Ghafoorian, Abbasinezhad-Mood, and Shakeri [30] also explored the use of the role-based access control (RBAC) model as a
i=1	i
i

t	t	···  at	t
CR1	V 1;1	V 1;2 ···	V 1;n—1 V 1;n

trust and reputation-based model used to secure data storage in the cloud. The study found that the RBAC model is effective in addressing security threats related to the trust and reputation of
cloud-based systems. In another study in 2018 [31], the authors
n i=1
at (CR) =	.	.
.	.
CRn	Vn;1
.	.	.	.
.	.
Vn;2  ···	Vn;n—1 Vn;n
b1t  b2t	···  bn — 1t  bnt

tried to decrease the overhead of the trust model while improving
CR1 0 V 1; 1	V 1; 2 ···	V 1; n — 1
V 1; n 1

the detection rate of malicious nodes. However, they did not con-
P i = 1 bi (CR) =	. 2 B	.	.	.
.	.	C

sidered all security requirements for the metrics of a reputation-
based system.
n  t	.	.
.	A

Other approaches for managing trust and reputation in cloud systems have been explored. In 2019, Nwebonyi, Martins, and Cor- reia [32] and Chang [33] investigated the effectiveness of different


PCR
NCR

at (CR)×II NF
bt (CR)×II
NF
CRn
Vn; 1
Vn; 2
··· 
Vn; n — 1
Vn; n

models in averting reputation and trust threats in cloud-based sys- tems. However, these studies primarily focus on the overall secu- rity and privacy of the system, thereby failing to address some of the specific attacks.
In a 2020 study [34], where the authors proposed a QoS-based model for trust evaluation of cloud service providers by calculating accumulative trust value. However, the authors did not focus on how to avoid all reputation attacks.

Organization

The rest of this paper is organized as follows. In section 2, we present the material and methods for a solution that prevents on–off, collusion, and Sybil attacks. In section 3, we analyze the components of the trust model. In section 4, we present the simu- lation results for reputation attacks. Finally, in sections 5 and 6 we discuss the results, along with plans for future works, and provide
a conclusion.
Where at represents positive feedback at a specific time, bt
represents negative feedback at a specific time, P represents
the value of new positive recommender feedback, N represents the value of new negative recommender feedback, II represents the interaction importance value, and NF represents the feedback number.
To avoid the danger of on–off attacks (O2), we need to add the penalty for an on–off attack (PO2 ), which is set from 1 to n, such that 1 represents no danger from a consumer role, and n represents high interaction importance multiplied by the danger rate (DR). The trust model will compute PO2 for any consumer by applying a new procedure, where PCO2 represents the limit of a minimum of the interactions with the greatest value.
O2	t	O2
n
else PO2 = 1

n—1	t

IT(CR) = X 	ai (CR)+ PCR	
	    

(2)


This study will focus on three types of attacks, which have sev- eral similarities, although they differ in how they are perpetrated in a cloud computing environment.

On-off attacks

In a direct trust model, on–off attacks are characterized by
We also need to add penalty of trust decline (PTD) to avoid dan- gers of trust decline (TD), where PTD is set from 1 to n, such that 1 represents no danger from this consumer role and n represents
high danger, PCTD represents the curve of a penalty of trust decline with an integer greater than 1, and LII represents the limit of low interaction.

opportunistic malicious behavior at different nodes, which com- promises the trust of the system. The behavior switches between good/bad, creating a facade that makes the node pass as trust- worthy even when it is behaving badly [29]. For example, a node
n—1
IT(CR) =
i=1

(at (CR)+ PCR
at (CR)+ PCR
)+ (bt(CR)+ NCR

× PO2 × PTD)

(3)

that passes as trustworthy on an e-commerce site can initiate malicious behavior, remaining undetected because the system initially considered the node trustworthy. First, the trust model system will calculate the interaction trust (IT), which provides an accurate result for the trust value of each cloud service con- sumer (CR) by computing the service providers (SP's) interaction importance (II). The feedback (F) is regarding an interaction is
t	TD	TD
n
else PTD = 1
PCTD =	TD  II PTD
To avoid this attack, we use PCTD to determine the value of pen- alty of trust decline (PTD) and we use the danger rate (DR) and the penalty for on–off attacks (PO2 ). Algorithm 1 is as follows:




Algorithm 1: On/off Attack Algorithm
Input: F, II;
Output: Consumer Trust Value;
1:	procedure Interaction Trust
2:	at (CR) = F
3:	bt (CR) = F — 1
4:	PCR ← (at (CR)× II)/NF
5:	NCR ← (bt (CR)× II)/NF
6:	if II ≥ PCO2 and at < II then PO2 = II × DR
7:	else PO2 = 1
8:	endif
9:	if at < II then PTD = PCTD
10: elsePTD = 1
11:  f or i = 1, i ≤ n — 1;
12: IT(CR) ← at (CR) + PCR / at (CR) + PCR 
recommenders cooperate to decrease the trust value of a specific consumer in the TMS.
To prevent collusion attacks, we propose a new solution by cal- culating three criteria representing different factors. The first crite- rion is malicious recommendations detection (MRD), which detects suspicious recommenders’ groups by measuring the probability of a suspicious recommender’s group being a collusion recom- mender’s group. In this criterion, the trust model will compute the time range of the collusion attack to determine the time range of all attacks that have happened in a short time. If there are any attacks from malicious recommenders to a specific consumer, the time range of these attacks will be very small. After that, the trust model will calculate the second criterion, malicious recom- menders’ behavior (MRB), which represents the similarity of mali- cious recommenders’ behaviors, which will be more similar when the malicious recommenders attack a specific consumer. The mali- cious recommendations detection (MRD) and malicious recom-


i
13: end f or

if T(F , CR)FS — T(F , CR)FS ≤ TR
and V (Fn, CR)FS ≥ V (Fi, CR)FSand V (Fn, CR)FS — V (Fi, CR)FS ≤ maxVR

14: endif
15: end procedure
>< ><
then move(Fi, CR)FSfrom FS to SS
else if T(Fn, CR)FS — T(Fi, CR)FS ≤ TR

and V (Fn, CR)FS
> >
< V (Fi, CR)FS
and V (Fn, CR)FS
— V (Fi, CR)FS
≥ minVR




We can examine an example of an on–off attack detailed below. The
> >

: endfor
then move(Fi, CR)FSfrom FS to SS
end else if
end if

example should exhibit how the penalty of on–off attack and pen- alty of trust decline impacts the roles’ trust values.
8> for i = 1 t on
> >

if T(Fn, CR)FS
FS

— T(Fi, CR)SS

≤ TR
SS

Let us assume the last value of IT(CR) = 0.75 and PCO2
= 0.61,
>>>< >>><
n	i
then move(Fn, CR)
n	i
FSfrom FS to SS


the greatest value, and this value should be more than 0.5 to
and V (Fn, CR)FS
> >
< V (Fi, CR)SS
and V (Fn, CR)FS
— V (Fi, CR)SS
≥ minVR

1.00, which is determined by the cloud administer. We have two conditions to apply this penalty in our formula. The first condition is if the interaction importance (II) is greater than or equal to PCO2 ,
and the second condition is the new feedback at is less than the
interaction importance  II
>>> >>:
n
end else if end if
endfor
8>< TR = T(Fn, CR)FS × TC

( ) of last interaction. If these two condi-
tions hold, then the trust model will compute the penalty of an on–off attack as PO2 = II × DR. Now, let us assume that the value
where
maxVR = V (Fn, CR)FS × VC
>: minVR = —V(Fn, CR)FS × VC
(4)

of the new feedback is at = 0.60 and the interaction importance
of these interactions is II = 0.90and the danger rate is DR = 3. In
this case, the trust model will compute the penalty of the on–off
attack PO2 = 0.90 × 3 = 2.7. Then, the TMS will calculate the new trust value of this consumer as follows:
IT(CR) = Pn—1 	at (CR)+PCR	

	
The TMS will compare the time and the value of all feedback in the feedback set (FS) that are given to a specific consumer. In the first comparison, the TMS will compare the time of last feedback T(Fn, CR)FS and the time of all T(Fi, CR)FS except for the last feed- back. After that, the TMS will compare between the value of the
last feedback V F  CR FS and the value of all V F CR FS except the

n—1 	0.75+0.27	
i=1 (0.75+0.27)+(0.25+0.18×2.7×2)
T(Fn, CR)FS and the value V (Fn, CR)FS of the last feedback in feedback

PCR = 0.60×0.90 = 0.27
SS	SS

0  2	set (FS) and the time T(Fi, CR)
and the value V (Fi, CR)
of all feed-

NCR =
.40×0.90 = 0.18
back in the suspected set (SS). In this way, the TMS will place all suspected feedback into the suspected set (SS). TC and VC are

Collusion attacks

A collusion Attack is a type of malicious behavior that is charac- terized by fake feedback from a single node, which is targeted at decreasing or increasing the productivity of ratings of products on an e-commerce site [35]. The behavior can also be non- collusive, whereby the node gives multiple misleading feedback items as a way of self-promoting or slandering another entity. If
two parameters to determine the range of feedback time and feed- back value.
To detect the malicious recommendations, or collusion feed- back, the trust model will compute the third criterion, the collusion attack frequency (CAF) for each recommender who has feedback in
the suspected set SS = {SF1, SF2, ··· , SFn}, where the higher the fre-
quency of attacks, the greater the strength of the attack.

malicious users comprise greater than 50% in the trust model sys- tem, the TMS will be ineffective. This attack also threatens the cor- rectness of recommendation trust values. There are two main types
CAF
FN(SR, CR)
(SR, CR) = FN(SS, CR)	(5)

of collusion attacks: a self-promoting attack, where the malicious recommenders cooperate to increase the trust value of a specific consumer in the TMS, and a slandering attack, where the malicious
if CAF(SR, CR) ≥ FL then move SF (SR, CR) to CS
else	move SF (SR, CR) to FS
: end if



First, the trust model will compute the collusion attack fre- quency (CAF), where FN(SR, CR) is the number of feedback items that are given from a specific recommender to a specific consumer in the suspected set (SS). FN(SS, CR) is the number of all feedback items in the suspected set (SS) that are given to the same con- sumer. If the collusion attack frequency (CAF) is greater than the feedback limit (FL), the trust model will move the suspected feed- back to the collusion set (CS), or else the trust model will move the
suspected feedback SF(SR, CR) from a specific recommender to a
specific consumer to the feedback set (FS).
To measure the attack scale (AS) for a specific consumer, the trust model will measure the size of the collusion set (CS), where the malicious recommenders in a recommender’s community must account for a large proportion of all recommenders to attack the trust model and cause damage to it. The collusion attack scale (AS) is calculated as (6):
* (continued)

Algorithm 2: Collusion Attack Algorithm


10: endf or
11:  f or i = 1 to n
12: if T(Fn, CR)FS — T(Fi, CR)SS ≤ TR
andV (Fn, CR)FS ≥ V (Fi, CR)SSand V (Fn, CR)FS — V (Fi, CR)SS ≤ maxVR
then move(Fn, CR)FSf rom FS to SS
13: else if T(Fn, CR)FS — T(Fi, CR)SS ≤ TR
and V (Fn, CR)FS < V (Fi, CR)SSand V (Fn, CR)FS — V (Fi, CR)SS ≥ minVR
then move (Fn, CR)FSf rom FS to SS
14: endelseif
15: endif

AS(CR) = 1 — RN(CS)
FN(CS, CR)
(6)
16: endf or
17:  f or i = 1 to n

where RN(CS) is the number of malicious recommenders in the collusion community and FN(CS, CR) is the number of malicious feedback items for all consumers in the collusion set (CS).
After that, the trust model will compute the attack target scale (ATS), which provides the malicious feedback rate for a specific consumer. The attack target scale (ATS) is calculated as (7):
18: CAF(SRi, CR) ← FN(SRi, CR)/FN(SS, CR)
19: if CAF(SRi, CR) ≥ FL then move SF(SRi, CR) to CS
20: else
21: move SF(SRi, CR) to FS
22: endif
23: endf or
24: AS(CR) ← 1 — RN(CS)/FN(CS, CR)

ATS(CR)= FN(CS, CR)
FN(AFS, CR)
(7)
25: ATS(CR) ← FN(CS, CR)/FN(AFS, CR)
26:  f or i = 1 ton

Where the FN(CS, CR) is the feedback number that has been pro- vided from malicious recommenders. FN(AFS, CR) represents the feedback number that has been provided from all feedback sets
in same community, where the set of malicious recommenders is part of all recommenders who evaluated a specific consumer.
Finally, to measure the strength of all collusion attacks for a specific consumer, the trust model will compute the collusion attack strength (CAS) by taking the number of all attack scale from different communities. Collusion attack strength (CAS) is then cal- culated as (8):
27: CAS(CR) ← FN(CSi, CR)/FN(AFSi, CR)
28: endf or
29: endprocedure



We can examine the example of the collusion attack detailed below. The example will show how the collusion attack algorithm impacts the roles’ trust values. Let us assume the below matrix contains all feedback times.
T(F1) ··· T(Fn 1)T(Fn)

Pn FN CS CR	0	1

(	Pn
FN(AFS , CR)	(
SP2	V 2,1
···	V 2,n—1
V 2,n

i=1
To detect collusion groups, the trust model will use the collu-
n i=1
FS(CR) =
.  B@  .

.	.	.
.	.

T(F1) ··· T(Fn—1) T(Fn)



  Algorithm 2: Collusion Attack Algorithm	
Input : FS, TC, VC, FL;
Output : SS, CS, AS(CR), ATS(CR), CAS(CR);

n i=1


FS(CR) =
SP1	04 : 22 ···	05 : 09 14 : 22
.	.	. . .	.	.
SPn	01 : 30 ···	20 : 01 22 : 30

1:	procedure collusion attack
The algorithm will compare all feedback time, starting with the

2:	TR ← T(Fn, CR)FS × TC
last feedback time V

n,n
. Let us assume the time range is two hours

3:	maxVR ← V (Fn, CR)FS × VC
4:	minVR ← —V (Fn, CR)FS × VC
5:	f or i = 1 to n — 1
6:	if T(Fn, CR)FS — T(Fi, CR)FS ≤ TR
and V (F , CR)FS ≥ V (F , CR)FSand V F CR FS	V F CR FS	maxVR
and all feedback is on same day. In this case, there are six feedback items in this time range, and the trust model will compare their values. Let us assume the following feedback values:
V (F1) ··· V (Fn—1)V (Fn) SP1	90% ···  99% 98%
Pn FS(CR) =	.  B	C

( n,
) — ( i,	)  ≤
i=1
.  @	A

   

7:	else if T(Fn, CR)FS — T(Fi, CR)FS ≤ TR
and V (Fn, CR)FS < V (Fi, CR)FSand V (Fn, CR)FS — V (Fi, CR)FS ≥ minVR
then move (Fi, CR)FS f rom FS to SS
8:	endelse if
9:	endif
In this case, the system will move the six feedback items to the suspected set (SS); then, the trust model will compute the collu- sion attack frequency for each recommender who has feedback in the suspected set (SS).
CAF(SR, CR) = FN(SR,CR)
CAF(SR, CR) = 3 = 50%

With the below condition, if the feedback limit FL = 10%, then	CA1  CA2  ·· ·  CAn

the trust model will move these feedback items to the collusion
PI1 0 V 1,1	V 1,2
···	V 1,n 1

8< if CAF (SR, CR) ≥ FL then move SF(SR, CR)to CS
Q =  .
.
BB@  .
.	.	.
.	.	.
CCA

else	move SF (SR, CR) to FS
PIm	Vm,1	Vm,2  ···	Vm,n

: end if

Sybil attacks

According to Mahajan, Mahajan, Jadhav, and Kolate [35], a Sybil attack involves the emulation of multiple behaviors by a single entity [36], typically by multiple accounts using a single entity/ node. The multiple identities can be stolen or fake, or even obtained through a Sybil attack. Sybil attackers can use multiple entities to either damage or build the reputation of an online sys- tem by giving either negative or positive feedback, respectively. The literature will be systematically reviewed for the effectiveness of detecting reputation attacks so as to prevent Sybil Attacks.
To avoid this attack, we need to apply two kinds of attack detec- tion, multi-identity detection (Mid) and Sybil attack detection(SA). We have all users’ credentials in the trust identity registry, and by comparing all credentials attributes for all users we can avoid this attack, where R represents a list of identity records for all users’
primary identities UP = {PI1, PI2, ·· · , PIm} and the credentials attri-
butes for all users UC = {CA1, CA2, ··· , CAn}, UM is UP × UC matrix which contains the credentials (CA) of all users who are registered
where PIm represents the primary identities for all consumers (for example, the consumer’s user name) and CAn represents the credential’s attributes (the consumer’s IP address, passwords, com- puter name, etc.). Q (CAn) is the frequency of any credential attri- bute CA represented as similar for all consumers. If Mid is greater than or equal to RL, then the TMS will ignore all fake trust results that come from different accounts that have the same credential attribute (CA).
Secondly, we need to use the time factor by calculating the number of identities |Nid(t)| within a specific time frame[F(t), L(t)] for all recommenders who send their feedback to the TMS. If there
is any change in the recommender’s behavior at a specific time, this situation indicates a Sybil attack. The TMS will calculate the percentage of occasional and periodic changes in the number of identities in the behavior of all identities (the identities for all rec- ommenders that provided feedback to any consumer). SA is calcu- lated as (11):
C(t) = |Nid(F(t)) × SC∫

if Nid(L(t)) > Nid(F(t)) + C(t) then
 id	id	

in the TMS. The attacker will use the same credentials in various identity records, and the TMS will identify patterns in anonymous consumers’ credentials.
t=n	SA F(t), L(t)) = N (L(t))—N (F(t))+C(t)
id
else	do nothing
=
CCA
(11)

The TMS will detect this attack by calculating the value of multi-identity detection (Mid ) as the appearance times (Q ) of cre- dential attribute value (CA), where the value of the credential is shown by the credentials attribute divided by the number of all
records with the user’s identity (Rid). The frequency of any creden- tials attribute (CA) is represented by the number of similar creden- tials. (Mid ) is calculated as in (9):
Xt=n CXA=n Q (CAn)!
whereC(t) represents the identities curve, SC represents the Sybil attack curve, Nid(F(t)) represents the number of identities at the beginning of the time frame, and Nid(L(t)) represents the num- ber of identities at the end.
As an example, let us assume the number of identities at the beginning  of  the  time  frame  Nid(F(t)) = 421  identities,
Nid(L(t)) = 487, and SC = 5%. Then, SA(R, F(t), L(t)) is calculated as
follows:
C(t) = |421 × 0.05∫ = 21

Mid =

t=1

CA=1
Rid
(9)
if	487 > 421 + 21	then
487 — 421 + 21

To make the TMS ignore all fake trust results, we need to apply a
SA(F(t), L(t)) =
B


421

RT(L(t)). The TMS will foil this attack by using the limit of a max-
t=1	else	do nothing
B	C

imum number of records (RL) that has the same value of the cre- dential attribute; for example, if there are many records that have the same credential attribute registered within a specific time
BB@
CCA

frame, the TMS will check whether the number of these records is greater than RL and ignore all feedback that comes from these rec- ommenders. Finally, the change rate factor of the trust result
RT(CR, F(t), L(t)) measures the consumer trust value by taking into
consideration the behavior of all recommenders in a specific time, calculated as (10):
RT(CR, F(t), L(t)) =	(10)
if Mid ≥ RL then RT(F(t)) = RT(F(t))
else	RT(F(t)) = RT(L(t))
We can examine the example of the Sybil attack detailed as follows:
CA1  CA2	···  CAn
Finally, the trust model will compute the recommender impor-
tance value, which means SPs are often influential depending on their trustworthiness as recommenders and their experience W(Ri, CR) by adding a weight function of the exchange transaction
(WEX ) and exchange transaction value (EX ) in the final equation, which measures the value of the number of exchange transactions for any recommender with a specific consumer. Another two fac- tors will be associated in this equation to measure the impact of time (t) in the recommender interaction, where the last time the service provider interacted with a specific consumer last(t) is mul-
tiplied by a weight function for the last time (WL). The trust value of any consumer RT(CR) can be calculated as below, where the feedback value is F(Ri, CR) for all recommenders who have enough experience to give feedback. To eliminate the challenge of all

PI1 0 V 1,1	V 1,2
···	V 1,n 1
attacks from the posited trust model, we need to add the time fac-

PI2	V 2,1	V 2,2  ···	V 2,n
.  B	C
		  
tor (12).
W(R , CR) = Pn

(EXi ×W

EX +Li (t)×WL )


8< if W(Ri, CR) ≥ II then RT(CR, F(t), L(t)) =   1  i	


(12)

else do nothing
As an example, consider the interaction importance II = 0.80,
W(Ri, CR) = {0.88, 0.72, 0.90, 0.96}, and recommender feedback is
F(Ri, CR) = {0.90, 0.89, 0.30, 0.67}. With this scenario, the con- sumer trust value is calculated as below.

W(Ri, CR) = Pn
(0.91×80+0.77×20) = 0.88

if 0.88 ≥ 0.70 then RT(CR, F(t), L(t)) = 0.90+0.30+0.67 = 0.62 or 62%



Algorithm 3: Sybil Attacks Algorithm


Input : RL, WEX , WL;
Output : RT;
1:	procedure Sybil Attacks
2:	f or t = 1 ton
3:	f or CA = 1 ton
4:	Mid ← Q (CAn)/Rid
5:	if Mid ≥ RL then RT(F(t)) = RT(F(t))
6:	else
7:	RT(F(t)) = RT(L(t))
8:	end if
9:	end f or
10:	endf or
11:	C(t) = |Nid(F(t)) × SC∫
12:	f or t = 1 ton
13:	if Nid(L(t)) > Nid(F(t)) + C(t) then
SA(F(t), L(t))
← (Nid(L(t))
—Nid(F(t)) + C(t))
/|Nid(F(t))|
14:	endif
15:	endf or
16:	f or i = 1 to n
17:	f or  t = 1 to n
18:	W(Ri, CR) = EXi × WEX + Li(t) × WL /100
19:	if W(Ri, CR) ≥ II then RT(CR, F(t), L(t)) = F(Ri, CR)SP/NR
20:	end if
21:	endf or
22:	endf or
23:	end procedure




Proposed framework architecture

This section provides an analysis of the different components of the trust model and the role it plays in ensuring that the system works effectively. Fig. 1 illustrates the proposed system architecture.
TMS will be the component of the proposed design that evalu- ates the extent to which providers of the cloud services are willing to depend on the consumers of the cloud services. It will also be entitled to the provision of certain cloud services as promised by the cloud service providers. The trust management system is com- posed of various subsections entitled with different tasks, all of which are aimed at ensuring the security and the privacy of the data in the cloud storage systems. It evaluates the rules that are determined within the level of trust depending on feedback from service providers. There is a need to specify the identity of the user and track the activities of this entity for easy tracking of unautho- rized consumers or attackers and issuance of proof of any form of data leakage. Through the TMS, the accounts of registered as well as recognized consumers are updated and all the incidents in

















Fig. 1. Trust model system architecture.



which a consumer is involved are also determined. This component will also oversee the authorization of whoever uploads the feed- back into the system. It is capable of identifying invalid feedback as well as discarding such invalid feedback from the system.
Trust Management System (TMS): This adds to the layers of the trust model, whose main aim is to make the entire system operate effectively and securely. The trust management system is com- posed of various subsections as elaborated below.
Central Repository: This assumes the role of interaction store, mainly operating to store all types of trust records and interaction histories generated by interacting tasks and roles for later utiliza- tion by the trust decision engine in the evaluation of the tasks and roles values.
Role Behavior Analyzer: This serves to analyze the functions and roles associated with minimum levels of trust regulations in relation to shared resources. Its role is to evaluate rules that are determined within the level of trust depending on the feedback that arises from service providers in the central repository. The role behavior analyzer entity links the roles in order to collect informa- tion concerning them and report any form of leakage if it arises. This entity fills the need to specify the identity of the user and track the activities undertaken for easy tracking of unauthorized consumers or attackers and issuance of proof of any form of data leakage. The role behavior analyzer also updates the accounts of registered as well as recognized consumers and assesses all of the incidents in which a consumer is involved.
Task Behavior Analyzer: This is responsible for analyzing tasks and functions concerning minimum trust level regulations upon accessing shared resources. It evaluates tasks determined within the trust level according to the feedback from owners through computing trust value and stores this value in the central reposi- tory. It listens to channels to collect information, the two channels in this case, including reports from the tasks regarding leakage of data and reports from the role behavior analyzer to identify the histories of the consumers regarding the stored data. The task behavior analyzer needs to specify identifying consumers and tracking the tasks performed. It can easily track attackers or unau- thorized consumers and issues proof of any data leakage. It will also update registered and recognized consumers’ accounts and determine whether a consumer account has been involved in the incident.



Feedback Collector: This is an agent tasked with the collection of feedback from the service owners to the repository headquarters before it is automatically allocated. Consumers’ trustworthiness is represented by the feedback on tasks and roles. For the purposes of security, the collector of roles and task feedback protects its integ- rity. This component serves the purpose of ensuring the authoriza- tion of whoever uploads the feedback into that system. It is capable of identifying invalid feedback as well as discarding such invalid feedback from the system. Furthermore, the collector of feedback gathers information concerning data assignments on tasks and roles before updating it to the central repository on the nature of the assignment.
Trust Decision Engine: This is a component that evaluates and determines the value of trust of the data owners, the roles, and the task entities. It gathers every form of information concerning the interaction histories that arise from the repository center and a particular consumer’s trust values output before making a deci- sion on the nature of the response required by the system.


Simulation results



Fig. 3. Penalties of on–off attack and trust decline.


The trust model will compute the Interaction Trust value for malicious consumers by applying the penalties of malicious behav- ior. Fig. 4 and Fig. 5 show the impact of new feedback on the value

We built a C#.net Windows Forms application to compare our architecture with several related works. In this section, we will evaluate through experiments the ability of the trust model to withstand reputation attacks. The TMS will compute penalties of an on–off attack by using two conditions. The first conditions, if the interaction importance greater than or equal to the PCO2 , where PCO2 represents the limit of a minimum of the interactions with the greatest value. The second condition if the feedback value (F) is less than interaction importance (II) then the trust model will com- pute the penalty of on–off attack (PO2 ). If the feedback (F) of the recommender is less than the interaction importance (II) then
the trust model will compute the trust decline penalty (PTD). Fig. 2 shows the impact of the penalty of on–off attack and trust decline in the interaction trust values Table 1.
of interaction trust consumers.
(IT) for malicious consumers and trusted






Fig. 2. Penalties of on–off attack and trust decline.




We tested big data to check the standard NIST metrics before and after adding the penalties to equations (1), (2), and (3) to check the five security functions. As we see in Fig. 3, due to the differ- ences between these three equations, attacks will occur if the penalties are not added. The impact on the trust value of users should be significant in the event of malicious behaviors in impor- tant transactions.
Fig. 4. Interaction trust values for 100 trusted consumers.






Fig. 5. Interaction trust values for 100 malicious consumers.


To avoid collusion attacks, the TMS will compute the collusion attack frequency (CAF), where the value of feedback frequency is directly proportional to the feedback collusion and inversely pro- portional to the feedback’s credibility. The frequency of feedback depends on the number of recommender feedback items and the number of all feedback items in the suspected set (SS).
Fig. 6 shows the feedback frequency of seven suspected recom- menders. We can see that five suspected recommenders have feed- back frequency greater than the feedback limit (FL), which means the TMS will move the feedback of these recommenders to the col- lusion set (CS), or else the trust model will move the suspected feedback by a specific recommender to a specific consumer to the feedback set (FS).





Fig. 8. Attack target scale.(ATS)



Table 1
Collusion attacks frequency.


Fig. 9 shows the value of the collusion attack strength (CAS) by calculating the rate of all malicious feedback from different com- munities for a specific consumer.


Fig. 9. Collusion attack strength.(CAS)

Discussion

Every model of trust management service is endangered by some security threats. These threats may either elevate the reputa- tion of a certain unit with malicious intentions or entirely ruin it. In order to build a robust, secure, and accurate trust model system,






Fig. 7. Attack scale.(AS)


Fig. 8 shows the value of the attack target scale (ATS), which provides the malicious feedback rate from one collusion set (CS) for a specific consumer.

Table 2
Comparison of security and accuracy.




we focus on all reputation attacks of cloud computing by applying different criteria to avoid these attacks. Table 2 shows the compar- ison between our proposed TMS with those given in related works.

Future work

The issue of cloud service trust has attracted many researchers, but there are still many concerns that must be addressed. In future work, we will introduce additional criteria that increase the secu- rity of the trust model. In addition, we will seek other types of rep- utation attacks that threaten the security of the cloud computing environment and propose solutions to avoid these attacks.

Conclusion

Authorization issues concerning access to cloud computing storage are of serious concern when there are a large number of consumers using the big data of cloud computing for sensitive data. Such concerns can be properly attended to through the integration of control models with trust models as an improved security strategy for decentralized systems. We can draw the con- clusion that cloud computing threats may either elevate the repu- tation of a unit with malicious intentions or entirely ruin it. This paper focuses on ensuring the security of cloud storage systems by building a trust model system to avoid reputation attacks of cloud services, effectively protecting cloud services through effi- cient detection of malicious as well as unbecoming behaviors by applying trust algorithms tailored to prevent on–off, collusion, and Sybil attacks, where each trust algorithm contains different criteria to avoid reputation attacks. Overall, our results demon- strate a robust ability to uphold the security of cloud service con- sumers. Their association with trust management services may involve highly sensitive data, so assurance of trust management services is crucial owing to cloud services’ dynamic nature. Our solution offers reliable solutions to avoid reputation attacks and makes for very accurate consumer trust values by taking interac- tion importance into consideration.

Declaration of Competing Interest

The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper.

Acknowledgement

This project was funded by the Deanship of Scientific Research (DSR), King Abdulaziz University, Jeddah, under grant No. (D- 066-611-1442). The authors, therefore, gratefully acknowledge DSR technical and financial support.
We would like to express our appreciation to the editor and reviewers for their time and effort in helping us to improve the quality of this manuscript.

References

Noor TH, Sheng QZ, Alfazi A. Reputation Attacks Detection for Effective Trust Assessment Among Cloud Services. In: in 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications. p. 469–76.
Mehraj S, Banday MT. Establishing a Zero Trust Strategy in Cloud Computing Environment. in International Conference on Computer Communication and Informatics, 2020.
Varalakshmi P, Judgi T, Balaji D. ‘‘Trust Management Model Based on Malicious Filtered Feedback in Cloud. In: In International Conference on Data Science Analytics and Applications”, in International Conference on Data Science Analytics and Applications. p. 178–87.
S. Bhatt, R. Sandhu, and F. Patwa, ‘‘An Access Control Framework for Cloud- Enabled Wearable Internet of Things,” in IEEE 3rd International Conference on Collaboration and Internet Computing (CIC), pp. 213–233, Oct. 2017.
Zhou L, Varadharajan V, Hitchens M. Integrating Trust with Cryptographic Role-based Access Control for Secure Cloud Data Storage. in 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications, 2013.
Deng W, Zhou Z. A Flexible RBAC Model Based on Trust in Open System. Third Global Congress on Intelligent Systems 2012.
Ismail R, Jøsang A. In: in Proceedings of the 15th Bled Electronic Commerce Conference. p. 2502–11.
Chang W, Xu F, Dou J. A Trust and Unauthorized Operation Based RBAC (TUORBAC) Model. in International Conference on Control Engineering and Communication Technology, 2012.
Tan Z, Tang Z, Li R, Sallam A, Yang L. Research on Trust-based Access Control Model in Cloud Computing. in 6th IEEE Joint International Information Technology and Artificial Intelligence Conference, 2011.
L. Huang, Z. Xiong, and G. Wang, ‘‘A Trust-role Access Control Model Facing Cloud Computing,” Proceedings of the 35th Chinese Control Conference, July 27-29, 2016.
Li X, Du J. Adaptive and Attribute-based Trust Model for Service Level Agreement Guarantee in Cloud Computing. IET Inf Secur 2013;7 (1):39–50.
Noor TH, Sheng QZ, Alfazi A. Detecting occasional reputation attacks on cloud services. In: in International Conference on Web Engineering. p. 416–23.
M. Varsha and P. Patil, ‘‘A Survey on Authentication and Access Control for Cloud Computing using RBDAC Mechanism,” International Journal of Innovative Research in Computer and Communication Engineering, 12125– 12129, 2015.
Lin G, Wang D, Bie Y, Lei M. MTBAC: A Mutual Trust Based Access Control Model in Cloud Computing. China Commun 2014;11(4):154–62.
Zhu C, Nicanfar H, Leung VCM, Yang LT. An Authenticated Trust and Reputation Calculation and Management System for Cloud and Sensor Networks Integration. IEEE Trans Inf Forensics Secur 2014;10 (1):118–31.
X. Li, H. Ma, F. Zhou, and X. Gui, ‘‘Service Operator-Aware Trust Scheme for Resource Matchmaking across Multiple Clouds,” IEEE Transactions on Parallel and Distributed Systems, vol. 26, no. 5, pp. 1419–1429, May. 2014.
S. Chakraborty, and I. Ray, ‘‘TrustBAC: Integrating Trust Relationships into the RBAC Model for Access Control in Open Systems,” in SACMAT ’06 Proceedings of the eleventh ACM symposium on Access control models and technologies, 2006, DOI:10.1145/1133058.1133067.
T.H. Noor Z. Quan Z. Sheng Maamar, and Sherali, Zeadally. Managing trust in the cloud: State of the art and research challenges Computer 49 2016 34 45
Zhao L, Liu S, Li J, Xu H, Zhao L. A Dynamic Access Control model Based on Trust. Information Application Technology; 2010.
Li X, Ma H, Zhou F, Yao W. T-Broker: A Trust-Aware Service Brokering Scheme for Multiple Cloud Collaborative Services. IEEE Trans Inf Forensics Secur 2015;10(7):1402–15.
Bhattasali T, Chaki R, Chaki N, Saeed K. An Adaptation of Context and Trust Aware Workflow Oriented Access Control for Remote Healthcare. Int J Software Eng Knowl Eng 2018;28(6):781–810.
Marudhadevi D, Neelaya Dhatchayani V, Shankar Sriram VS. A Trust Evaluation Model for Cloud Computing Using Service Level Agreement. The Computer Journal, Nov. 2014;58:2225–32.
Tsai WT, Zhong P, Bai X, Elston J. Role-Based Trust Model for Community of Interest. in IEEE International Conference on Service-Oriented Computing and Applications (SOCA), 2009.
Zhang L, Yin N, Liu J, Wang R. Collusion detector based on G-N algorithm for trust model. J Syst Eng Electron 2016;27(4):926–35.
V. Oleshchuk, ‘‘Trust-Aware RBAC,” in Lecture Notes in Computer Science, Springer, pp. 97–107, 2012.
Fan Y, Zhang Y. Trusted Access Control Model Based on Role and Task in Cloud Computing. in 7th International Conference on Information Technology in Medicine and Education, 2012.
Noor TH, Sheng QZ, Bouguettaya A. Trust management in cloud services. Springer; 2014.
W. Tong , J. Liang, L. Lu, and X. Jin, ‘‘Intrusion detection scheme based node trust value in WSNs,” in Systems Engineering and Electronics, pp. 1644–1649, 2015.
Labraoui Nabila, Gueroui Mourad, Sekhri Larbi. On-off Attacks mitigation against trust systems in wireless sensor networks. In: in IFIP International Conference on Computer Science and its Applications. p. 406–15.
Ghafoorian M, Abbasinezhad-Mood D, Shakeri H. A Thorough Trust and Reputation Based RBAC Model for Secure Data Storage in the Cloud. IEEE Trans Parallel Distrib Syst Apr. 2019;30(4).
Zhang P, Kong Y, Zhou M. A Domain Partition-Based Trust Model for Unreliable Clouds. IEEE Trans Inf Forensics Secur Sept. 2018;13(9):2167–78.
F. N. Nwebonyi, R. Martins, and M. E. Correia, ‘‘Reputation based approach for improved fairness and robustness in P2P protocols,” in Peer-to-Peer Networking and Applications, pp. 951–968, 2019.
Eric Chang, ‘‘General Attacks and Approaches in Cloud-Scale Networks,” in IEEE International Conference on Computer Communications, 2019.
Hassan H, El-Desouky AI, Ibrahim A, El-Kenawy EM. ‘‘Enhanced QoS-Based Model for Trust Assessment in Cloud Computing Environment”, in IEEE. Access 2020.



S. Mahajan, S. Mahajan, S. Jadhav, and Sangita K., ‘‘Trust Management in E- commerce Websites,” in International Research Journal of Engineering and Technology (IRJET), pp. 2934–2936, 2017.
Noor TH, Sheng QZ, Yao L, Dustdar S, Ngu AHH. CloudArmor: Supporting Reputation-Based Trust Management for Cloud Services. IEEE Trans Parallel Distrib Syst 2015;27(2):367–80.
Barsoum A, Hasan A. Enabling Dynamic Data and Indirect Mutual Trust for Cloud Computing Storage Systems. IEEE Trans Parallel Distrib Syst 2012;24 (12):2375–85.
C. Uikey and D. S. Bhilare, ‘‘TrustRBAC: Trust Role Based Access Control Model in Multi-domain Cloud Environments,” in International Conference on Information, Communication, Instrumentation and Control (ICICIC), p. 978- 1-5090-6314-7, 2017.
Fortino G, Fotia L, Messina F, Rosaci D, Sarné GML. ‘‘Trust and Reputation in the Internet of Things: State-of-the-Art and Research Challenges”, in IEEE. Access 2020.
