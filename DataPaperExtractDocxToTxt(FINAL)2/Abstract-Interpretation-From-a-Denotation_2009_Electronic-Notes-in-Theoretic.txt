

Electronic Notes in Theoretical Computer Science 249 (2009) 19–37
www.elsevier.com/locate/entcs

Abstract Interpretation From a Denotational-semantics Perspective
David A. Schmidt
Computing and Information Sciences Dept.
Kansas State University Manhattan, KS 66506 USA

Abstract
The basic principles of abstract interpretation are explained in terms of Scott-Strachey-style denotational semantics: abstract-domain creation is defined as the selection of a finite approximant in the inverse-limit construction of a Scott-domain. Abstracted computation functions are defined in terms of an embedding- projection pair extracted from the inverse-limit construction. The key notions of abstract-interpretation backwards and forwards completeness are explained in terms of topologically closed and continuous maps in a coarsened version of the Scott-topology. Finally, the inductive-definition format of a language’s denotational semantics is used as the framework into which the abstracted domain and abstracted computation functions are inserted, thus defining the language’s abstract interpretation.
Keywords: Abstract interpretation, denotational semantics, Galois connection, Scott-domains, Scott-topology


Introduction
Denotational semantics [19,29,31,32] and abstract interpretation [3,5,6] came to life about the same time, and their intents were complementary: denotational seman- tics showed how to define a program’s extensional meaning independently from a machine, and abstract interpretation showed how to deduce a program’s properties in advance of running the program on a machine. In a previous MFPS presentation [4], Patrick Cousot explained how abstract interpretation can derive a program’s denotational semantics as an abstraction of the program’s trace semantics, thus explaining denotational semantics from an abstract-interpretation perspective.
In this paper, we take the dual course: We derive a popular form of abstract interpretation from denotational semantics. Given a language’s denotational se- mantics, defined upon a domain, D∞, constructed by an inverse-limit construction,

1 Supported by NSF ITR-0326577.
2 Email: schmidt@cis.ksu.edu

1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.07.082



Fig. 1. Abstract domain, Sign, and associated functions
we replace D∞ in the semantics by one of its finite approximants, Dk, k ≥ 0, from the inverse-limit construction. Elements of Dk are interpreted to denote subsets of D∞. Functions that compute on D∞ are projected to operate on Dk; this is done with the aid of the embedding-projection pair between Dk and D∞. Soundness of this “abstract” denotational semantics is ensured by the embedding-projection pair. The inductive-definition format of a language’s denotational semantics is used as the framework into which the abstracted domain and abstracted computation functions are inserted, thus defining the language’s abstract interpretation.
We judge the quality of the abstract interpretation we have defined in terms of a coarser variant of Scott-topology, and we characterize the so-called forwards- and backwards-complete (“homomorphic”) functions of abstract-interpretation theory [11,10] as the topologically closed and topologically continuous maps on the weak- ened Scott-topology.
In this fashion, abstract interpretation is derived from denotational semantics.

Background: Abstract interpretation
Abstract interpretration is approximation by computation on properties. For concrete-data domain, Σ, we select a set of property names, A, such that each a ∈ A names a set γ(a) ⊆ Σ, for γ : A → P(Σ). γ identifies the family of properties (data-test sets) modelled by A. Order A s.t. a ± a' iff γ(a) ⊆ γ(a') — the result
should be a partial ordering.
Figure 1 displays an approximation of the concrete integers, Int , by sign prop- erties named by complete lattice, Sign.
When γ possesses an adjoint, α : P(Σ) → Sign, then there is a Galois connection (that is, S ⊆ γ(a) iff α(S) ± a, for all S ∈ P(Σ) and a ∈ A). α is the lower adjoint and γ is the upper adjoint, and we write this as P(Σ)⟨α, γ⟩Sign. This makes ρ = γ◦α



Fig. 2. An abstract interpretation using Sign

Fig. 3. Sound and complete forms of abstract functions
an upper closure operator — ρ : P(Σ) → P(Σ) is monotone, extensive (S ⊆ ρ(S)), and idempotent (ρ ◦ ρ = ρ).
ρ[P(Int )] identifies the properties expressible by abstract domain Sign, and ρ maps a test set to its minimal property, e.g., ρ{1} = {1, 2, ·· ·}, ρ{−1, 1} = Int , etc. Note that ρ[P(Int )] is closed under intersection (conjunction).
From here on, we work with Galois connections of form, (P(Σ), ⊆)⟨α, γ⟩(A, ± ), so that ρ = γ ◦ α maps sets to sets, and we assume that α is onto.
Computation functions, f : Σ → Σ, are soundly approximated by f : A → A iff α(f [S]) ± f (α(S)), for all S ∈ P(Σ) (equivalently, iff f [γ(a)] ⊆ γ(f (a)), for all a ∈ A), where we define f [S] = {f (s) | s ∈ S}, as usual. Figure 2 applies the functions from Figure 1 to interpret a program that computes upon Int so that it soundly computes upon Sign, which represents the data-test sets of interest.

Recall that ρ[P(Σ)] = γ[A] identifies the properties expressed by A. When α is onto, we can treat f : A → A as f : ρ[P(Σ)] → ρ[P(Σ)], for example, succ {0} = {1, 2, ·· ·}.
Proposition 2.1 For all φ ∈ ρ[P(Σ)], f : ρ[P(Σ)] → ρ[P(Σ)] is sound for f : Σ → Σ iff f (φ) ⊆ f (φ).
There is also the dual notion, underapproximating soundness, where f (φ) ⊇ f (φ); this is best developed with an interior map, ι : P(Σ) → P(Σ). We leave this for later in the paper.
The most precise (strongest) f for function f is defined f = α ◦ f ◦ γ. It is strongest in the sense that f ± f for all f that are sound for f .
We can define f : ρ[P(Σ)] → ρ[P(Σ)] in terms of ρ = γ ◦ α as f = ρ ◦ f . For
0	0
example, for the Sign domain and its closure map, ρ, succ {0} = {1, 2, ·· ·} and
succ {··· , −2, −1} = {··· , −2, −1, 0, 1, 2, ·· ·}.
Proposition 2.2 (strongest postcondition for f ): For all φ, ψ ∈ ρ[P(Σ)],  if
f (φ) ⊆ ψ, then f (φ) ⊆ ψ.
When f is approximated exactly by f such that f ◦ γ = γ ◦ f , we say f is forwards complete [10]. When f is approximated exactly such that α ◦ f = f ◦ α, we say f is backwards complete [11,27]. See Figure 3. In Figure 1, sq is backwards but not forwards complete; negate is both backwards and forwards complete, and succ is neither.
Define f  = ρ ◦ f : ρ[P(Σ)] → ρ[P(Σ)] as before.
Proposition 2.3 [10] The following are equivalent:
f is forwards complete for f
for all φ ∈ ρ[P(Σ)], f (φ) ∈ ρ[P(Σ)]
f ◦ ρ = ρ ◦ f ◦ ρ
Proposition 2.4 [6,11] The following are equivalent:
f is backwards complete for f
for all S1, S2 ∈ P(Σ), ρ(S1)= ρ(S2) implies ρ(f [S1]) = ρ(f [S2])
ρ ◦ f = ρ ◦ f ◦ ρ.
An abstract function, f , that is forwards or backwards complete for f is also strongest for f , so it is unclear at this point exactly what is gained from these notions. We will resolve this question later in the paper.

Background: Denotational semantics
One might explain denotational semantics as the interpretation of a program’s phrases as values from Scott-domains. We treat a Scott-domain as “an SFP ob- ject,” that is, as the inverse limit of a sequence of finite-cardinality bcpos, re- lated by embedding-projection pairs [14,25]. Figure 4 presents the Scott-domain



Fig. 4. Inverse limit of L = ({nil } + (D × L))⊥


of partial, total, finite, and infinite lists corresponding to the domain equation, L = ({nil } + (D × L))⊥. 3 For each i ≥ 0, the corresponding embedding-projection pair defines a Galois connection, Li⟨γi, αi⟩Li+1, as does Li⟨γi,∞, α∞,i⟩L∞. (Here, the γ maps are lower adjoints.)
Figure 5 shows a denotational semantics for a while-language based on L∞. A store is a mapping from a set of variables, V ar, to values in L∞. Absence of store is denoted by ⊥. The language uses a guarded-if construction, where a guard, Gj, filters the input store to its guarded command, Cj, and the results of all Gj : Cj pairs are joined. When the guards of an if-command are mutually exclusive, the semantics is the usual one. We use this formulation to ease the transition
into abstract interpretation, which treats analysis of software much like analysis of hardware circuits (cf. Figure 2).
The while-command is a tail-recursive guarded-if, such that while B do C has a denotation equal to if (¬B : skip), (B : C; (while B do C)) fi.
Here is an example: let σ0 = [ [x]] '→ nil]. Then,



3 As usual, + represents disjoint union, × is product, and ⊥ is lifting.



Fig. 5. Denotational semantics for while-language based on L∞

C[[if (isNil x : x = cons d0 x) (isNonNil x : x = x) fi]]σ0
= (C[[x = cons d0 x]] ◦ G[[isNil x]])σ0 H (C[[x = x]] ◦ G[[isNonNil x]])σ0
= C[[x = cons d0 x]]σ0 H C[[x = x]]⊥
= (update [[x]] (S[[cons d0 x]]σ0) σ0) H ⊥ = [ [x]] '→ (d0, nil)]
The example shows how G[[isNil x]] passes σ0 forwards because the guard holds true for the store, whereas G[[isNonNil x]] passes ⊥.

Collecting domains
Reconsidering the Lk domains in Figure 4, we note that an element like (d, ⊥) de- notes a list that has d as its head element and an unknown tail, that is, (d, ⊥) approximates the set, {(d, l) | l ∈ L∞} ⊆ L∞. In this sense, each Lk is an approx- imation domain, like the ones used for abstract interpretation (cf. Sign in Figure
1).
We can formalize this intuition. The collecting domain, У(L∞), defines all data- test sets that might be used with a program written in the language defined in Figure
5. If we “crown” L∞ with a T element, we have a Galois connection between the collecting domain and complete lattice, L∞T; see Figure 6. Element T ∈ L∞T denotes contradictory (literally, no) information content and maps to the empty data set in У(L∞)op. In contrast, ⊥ ∈ L∞T denotes all possible test data. One might also restrict the collecting domain to be just the totally defined lists or just the finite, total lists.
The Figure shows how the Galois connection composes with an embedding- projection pair, LT⟨γk,∞, α∞,k⟩L∞T, where Lk is also crowned.  The Galois con-




















Fig. 6. Collecting domain (data-test sets), P(L∞)op, for L∞ and associated Galois connections

nection that results, LT⟨γ, α⟩У(L∞)op, is significant: If we “rotate” it, we have a Galois connection suitable for abstract interpretation,



У(L∞)⟨α, γ⟩LTop:
P( L
)
op
	k





In this way, we have extracted a useful, crucial abstract interpretation from the Scott-domain’s inverse-limit construction.
An element, (dn, ⊥) ∈ LTop, represents those lists having at least n-many ele- ments, for 0 ≤ n ≤ k, and (dn, nil) represents a list that has exactly n elements. As
noted, ⊥∈ LTop stands for all lists; T∈ LTop for none. We can repeat the style of
k	k
abstract testing in Figure 2 for a program that computes on lists by using elements
of LTop as inputs. The next section develops this idea.
Other abstract domains can be synthesized by means of inverse limits and col- lecting domains. The Sign domain in Figure 1 is derived from these Scott-domain definitions:
N = {1}⊥ ⊕ N  where ⊕ denotes disjoint sum with merged ⊥s
S = (N + {0} + N )⊥
S denotes the integers partitioned into the negatives, zero, and the positives. The approximating domain, S1 = (N0 + {0} + N0)⊥, where N0 = {⊥}, defines Sign = STop in Figure 1. The Galois connection in Figure 1 goes between the collecting
domain of sets of total values of S∞ and Sign. We can define better-precision signs-
analyses by using domains Sk, k > 1, which would distinguish individual integers, e.g, STop = {T, neg , −1, zero, 1, pos , ⊥}.
Many abstract domains are defined this way — they are “partitions” of data-

test sets, “crowned” by a T, characterized by a finite domain from an inverse-limit sequence. But here are two that are not:

The Const domain, shown on the left, is used for constant-propagation analysis: a program’s variables are analyzed to see if they are uninitialized (⊥), are assigned a single, constant value (n ∈ Int ), or are assigned multiple values (T) [24]. Rather than an approximating domain, Const is N ∞Top, where N ∞ is the inverse limit of
N = ({0} + N )⊥.
On the right is the Interval domain, which is employed when an analysis must determine the range of values that a variable is assigned [6]. This domain is not finite and its opposite domain cannot be constructed as an SFP object. Further, the map, γ : Interval → У(Int ), is not defined as γ([a, b]) =↑[a, b] but as γ([a, b]) =
{n ∈ Int | a ≤ n ≤ b}. Because of its infinite height, this domain must be handled specially when used in an abstract interpretation; we discuss this later.
Domains like Sign, Const, and Interval are used to represent values from Σ; a relational domain is a nonfunctional domain that represents values from domain Var → Σ. The standard example of a relational domain is the polyhedral domain [8], whose values describe linear relationships between variables’ values in the store. For example, this set of inequalities between variables, x, y, and z, is an abstract value in the polyhedral domain that abstracts Var → Σ:
2x + 1y ≤ 100
4x + 1y + −3z ≤ 0
−1z ≤ 2
Such an abstract value is a conjunctive proposition of form,  ((Σ (aij · xij) ≤ bi), and can be implemented as a set of tuples, a matrix, or a graph. It represents all stores whose variables satisfy the conjunctive proposition.
Similar to the polyhedral domain is the octagon domain [20] and the predicate- abstraction domains [13,2]. None of these readily fit the format of a finite domain, LTop, in an inverse-limit sequence (but see the remark at the end of Section 6.)
There are also the usual constructions for collecting domains for products, sums,
and liftings. Figure 7 shows two such constructions, indexed product and lifting. Both constructions are common to abstract interpretation. The indexed product generates an independent attribute analysis [17], where a set of indexed tuples is



Fig. 7. Compound Galois connections for collecting domains
abstracted to a single tuple that covers the set. The lifting construction compresses the ⊥ element with the existing ⊥ in A and is used when an abstract interpretation ignores nontermination (which is almost always the case).

Some topology
The intuition that an element from an abstract domain models a set of concrete data-test elements, suggests a topological connection. Indeed, for an approximating domain, Lk, each γ(l), l ∈ Lk, is a Scott-basic open set [12,26] — a “computable property” [30]. As before, we define the closure operator, ρ = γ ◦ α : У(L∞) →
У(L∞), and we have that the family of sets, ρ[У(L∞)], are all Scott-basic opens
and the family is closed under intersection.
It is natural to close ρ[У(L∞)] under unions to generate a topology on L∞, one that is coarser than the Scott topology — it defines the “topology of the abstract interpretation.”
This construction does indeed exist in abstract-interpretation methodology — it is called the disjunctive completion [7] of the abstract domain, and it is used to add additional elements to an abstract domain when more precision is needed for an analysis. For example, the Sign domain in Figure 1 can be completed into this domain:

SignO = {none, neg , ≤ 0, zero, :
/= 0, ≥ 0, pos , any }

When the domain, SignO, used to analyze the program in Figure 2, the analysis can validate, for the test-data sets named by neg , zero, and pos , that the program’s output must be positive (pos ).

Some logic
There is another reason why the disjunctive completion is useful. It reminds us that
every abstract domain, LTop, defines a “logic,” where L ’s T denotes False, L ’s
k
⊥ denotes True, and LTop’s ± denotes entailment. This particular logic possesses

conjunction, and the disjunctive completion adds disjunction, making the domain a frame [16].
In general, for abstract domain A, its logic is the language of assertions that can be validated using an abstract intepretation based upon A. For example, one can use abstract domain Sign to validate that a program’s output satisfies assertion, pos , or assertion, any H pos , but the domain cannot be used to validate isEvenValued or zero H pos (but this last assertion can be validated in Sign’s disjunctive completion, SignO).
To start, A’s logic includes the primitive assertions, a, for every a ∈ A.
Next, define A’s ρ = γ ◦ α. Function f : Σ → Σ is a logical operator in A’s logic iff for all S ∈ ρ[У(Σ)], f [S] ∈ ρ[У(Σ)], that is, iff f ◦ ρ = ρ ◦ f ◦ ρ, that is, iff f = ρ ◦ f is forwards complete for f . The intuition is that f maps property sets to property sets “on the nose” and for this reason, one can use its f to compute exactly on the assertions in the logic. The concept of logical operator generalizes to n-ary f as well.
For example, Sign’s logic includes
φ ::= a | φ1 H φ2 | negate φ,	where a ∈ Sign
The logic contains primitive assertions like neg , zero, etc., as well as conjunctions. Since conjunctions compute on the nose, we have that meets in Sign compute to intersections in У(Int ):
a ± φ1 H φ2 iff γ(a) ⊆ γ(φ1) ∩ γ(φ2)
Since negate maps properties on the nose, we have that
a ± negate φ iff γ(a) ⊆ negate[γ(φ)]
and so on.
In constrast, union (∪) is not a logical operator for Sign (although it is for
Sign0).
The logic of the approximating domain is critical to an abstract interpretation, which must compute sound logical properties of a program in terms of the elements and operations in the abstract domain. Only properties that belong to the abstract domain’s logic may be soundly veriﬁed by the abstract interpretation. This makes notions like Galois connection, disjunctive completion, and forwards completeness critical to the design of a useful abstract interpretation.
Of course, the above development can be read as “domain logic” as presented by Abramsky [1], where a domain like L∞ is generated from a set of atomic (finite) elements, which are the primitive propositions in the logic, closed under frame-like axioms. And Jensen observed that one can use a finite subset of the atomic elements
to define an abstract domain that approximates L∞, much in the style that we used
Lk. Jensen’s methodology is called abstract interpretation in logical form [15].
It appears possible to use Jensen’s framework to describe the relational domains outlined in Section 4, but we do not try to do so here.



Fig. 8. Abstract interpretation derived from P(L∞)⟨α, g⟩LTop



Sound and complete abstract semantics
Recall from Section 2 that a Galois connection of form, У(C)⟨α, γ⟩A, defines the modelling of test-data sets from C as elements of A. Computation on a ∈ A by f : C → C is modelled by a f : A → A such that f (γ(a)) ⊆ γ(f (a)). The most precise such f is α ◦ f ◦ γ (where, for S ⊆ C, f [S]= {f (c) | c ∈ S}).
The Galois connection induces an abstract interpretation of a language’s deno- tational semantics: replace domain C by A and replace functions, f : C → C by f : A → A. An induction proof shows that the resulting valuation, C [[C]], is sound for C[[C]], for all phrases, C, in the language. Figure 8 shows the abstract denota- tional semantics that results from the Galois connection, У(L∞)⟨α, γ⟩LTop, and the
two constructions from Figure 7.
The Figure shows that an abstract interpretation is itself just a denotational semantics, where functions, f , are replaced by their sound approximations, f = α ◦ f ◦ γ. This style of abstract interpretation was first proposed by Donzeau-Gouge
[9] and Neilson [21,22,23].
Here is an example abstract denotation: Let σ0 = [ [x]] '→ ⊥] ∈ Σ , that is, x
might be any L∞-value at all (because γ(⊥)= L∞):
C [[if (isNil x : x = cons d0 x), (isNonNil x : x = x) fi]]σ0
= (C [[x = cons d0 x]] ◦ G [[isNil x]])σ0 H (C [[x = x]] ◦ G [[isNonNil x]])σ0 Now,

G [[isNil x]])σ0 = (α⊥ ◦ G[[isNil x]] ◦ γVar )σ0
= (α⊥ ◦ G[[isNil x]]){[[[x]] '→ l] | l ∈ L∞}
= α⊥{[[[x]] '→ nil], ⊥} = [ [x]] '→ nil]
The abstracted guard calculates the abstract store that covers all stores that satisfy isNil x. A similar calculation demonstrates that G [[isNonNil x]])σ0 = α⊥({[[[x]] '→ (d, l)] | l ∈ L∞}∪ {⊥})= [ [x]] '→ (d, ⊥)]. We complete the derivation:
C [[x = cons d0 x]][[[x]] '→ nil] H C [[x = x]][[[x]] '→ (d, ⊥)]
= (update [[x]] (S [[cons d0 x]][[[x]] '→ nil]) [[[x]] '→ nil]) H [[[x]] '→ (d, ⊥)]
= [ [x]] '→ (d0, nil)] H [[[x]] '→ (d, ⊥)]
= [ [x]] '→ (d0 H d, nil H Top ⊥)] = [ [x]] '→ (d0 H d, ⊥)]
k
The outcomes are joined, precision is lost, and the result is an abstract store that
maps x to a non-nil list whose head is d0 H d and whose tail is unknown (i.e., might be any L∞-value at all).
The previous derivation demonstrates how an abstract intepretation is used in
practice: a family of tests, covering the data sets of interest, are supplied to a pro- gram, and the outputs are calculated by derivation. Using this approach, one nat- urally wishes to unfold a higher-order abstract denotation of form, f = lfp λσ.Ffσ' . But we must ensure finite and detectable termination of the unfolding and calcula- tion.
A semantically sound technique for bounding the unfolding is explained in terms of “minimal function graph” semantics [18]: Starting from term, f (σ0), we generate the subsequent calls (unfoldings), f (σi), in the process constructing a family of k ﬁrst-order equations,
fσ0 = Ffσ1
fσ1 = Ffσ2
··· 
fσk = Ffσj , for some j ≤ k
which we can solve iteratively and can detect convergence. The equation set is guaranteed to be finite if the abstract domain from which σ is taken is finite (e.g., Sign, or LTop).
If the abstract domain is not finite (e.g., Const), k can be forced to be finite
by making the argument sequence, σ0, σ1, ··· , σk, into a chain so that the domain’s ﬁnite-height ensures a finite equation set. This is done by unfolding call f (σi) until a call, f (σi'), is uncovered. This generates a new first-order equation for f (σi+1), where σi+1 = σi H σi'. Since f (σi') ± f (σi+1), the solution to the former can be safely used in place of the latter. The abstract domain’s finite height bounds the quantity of the generated equation set.
The use of σi+1 = σi H σi' does not suffice for an abstract domain like Interval, which possesses infinitely ascending chains. In this situation, H is replaced by a

monotonic, extensive widening function that is guaranteed to generate chains of finite height only [5]. For the Interval domain, its widening function is defined widen(σi, σ'), where σi is the ith element in the chain under construction, and σ' is newly appearing in a call, f (σ'):
widen([], [c, d]) = [c, d]
widen([a, b], [c, d]) = [a, b], if a ≤ c and d ≤ b
widen([a, b], [c, d]) = [—∞, b], if c < a and d ≤ b
widen([a, b], [c, d]) = [a, +∞], if a ≤ c and b < d 
widen([a, b], [c, d]) = [—∞, +∞], if c < a and b < d 
Widening operations are also required when working with polyhedral domains.
When a chain of arguments is built during the process of generating the set of first-order equations it is common to solve just this one equation,
fσk = Ffσk
where σk is the last element in the generated chain.
Here is an example, for domain Sign and the semantics in Figure 8: For
C [[while NonNil x : x = tl x]] = f , where
f (σ)= G [[Nil x]]σ H f (C [[x = tl x]](G [[NonNil x]]σ)),
we calculate an abstract test with σdb: Let σdb = [x '→ (d, ⊥)] and σb = [x '→ ⊥].
(Please recall, in abstract domain LTop, that ⊥∈ LT means “all lists,” and T∈ LT
k	k	k
means ”no lists.”) C [[while NonNil x : x = tl x]]σdb = fσdb, where
fσdb = G [[Nil x]]σdb H f (C [[x = tl x]](G [[NonNil x]]σdb)
= [x '→ T] H f (C [[x = tl x]]σdb)
= fσb
fσb = G [[Nil x]]σb H f (C [[x = tl x]](G [[NonNil x]]σb)
= [x '→ nil ] H f (C [[x = tl x]]σdb)
= [x '→ nil ] H fσb
We solve these two first-order equations.
As noted earlier, the inductive definition format ensures soundness. This is because, for all phrase forms, E, we use the format, S[[op(Ei)]] = f (S[[Ei]]) to define E’s semantics, and we define the abstract semantics inductively as S [[op(Ei)]] =
f (S [[Ei]]), where f = α ◦ f ◦ γ.
0	0
Soundness is stated as S[[E]] ◦ γ = γ ◦ S [[E]] (equivalently stated as α ◦ S[[E]] =
S [[E]] ◦ α). It is easy to prove that S is sound for S.
Recall the two notions of completeness:
forwards completeness: For all E, S[[E]] ◦ γ = γ ◦ S [[E]]
backwards completeness: For all E, α ◦ S[[E]] = S [[E]] ◦ α

As proved by Cousot and Cousot [6], both forms of completeness are preserved by least- and greatest-fixed-point constructions, as well as by function composition and by inductive definition on syntax: If for every equation, S[[op(Ei)]] = f (S[[Ei]]), f is forwards (resp. backwards) complete for f , then S is forwards (resp. backwards) complete for S.
When there is not completeness, the inductive definition of S is sound but may be weaker than the strongest abstract interpretation: S [[E]] ± α ◦ S[[E]] ◦ γ.
It is puzzling that there are two forms of completeness. Both imply strongest postcondition properties, but the two notions are inequivalent [10]. What are they exactly? We learn the answer by considering the topology induced from the Galois connection: a forwards-complete function is is a topologically closed map and a backwards-complete function is a topologically continuous map.

Topological characterization of completeness
Topology plays a key role in denotational semantics. To solve the domain equation, D = D → D, Scott needed to limit the cardinality of functions on D. Topological continuity was the appropriate criterion: For complete lattice L, Scott defined L’s open sets to be those subsets of L that are (i) upwards closed and (ii) closed under tails of chains. 4 The functions that are topologically continuous for the Scott- topology of L are exactly the chain-continuous functions on L. Continuity limited the cardinality of D → D so that the recursive domain equation had a solution.
Consider the Scott-topology on an algebraic bcpo: D is algebraic if there is a subset, FD ⊆ D, of finite elements 5 such that for every d ∈ D, d = H{e ∈ FD | e ± d} Each e ∈ FD defines the property of “having e-information level,” and the basic open sets for D’s Scott-topology are {↑e | e ∈ FD}. 6
How does this relate to abstract interpretation? For abstract domain, LTop, its elements name properties that are used in an abstract interpretation: Each l ∈ LT names the set, ↑l ⊆ L∞, a Scott-basic open set in L∞. Indeed, the collection, γ[LT], is a family that is closed under intersection but not necessarily under union. If we close under union, we have a topology on L∞, coarser than the Scott-topology.
One defines a topology so to ask, “what are the continuous functions?” In the
case of the family, γ[LTop], we ask “what are the open/closed functions?” and
k	Top
“what are the continuous functions?”. Even when γ[Lk	] is not a topology, we will
see that those functions that preserve members of γ[LTop] are exactly the forwards- complete functions of abstract-interpretation theory, and those functions that reflect members of γ[LTop] are exactly the backwards-complete functions. We now develop these intuitions.
Let У(Σ)⟨α, γ⟩A be a Galois connection for Scott-domain Σ. Let FΣ = γ[A]= (γ ◦ α)[Σ] ⊆ У(Σ) define the properties of interest within Σ. For each U ∈ FΣ, its

4 That is, for every chain, C = {c0, c1, ··· ci, ·· ·} ⊆ L, when HC ∈ U , for open set U ⊆ L, then there exists some ck ∈ C such that ck ∈ U also. This means C’s tail, from ck onwards, is in U .
5  e ∈ D is finite iff for all chains C ⊆ D, e ± HC implies e ± c for some c ∈ C.
6 where †e = {d ∈ D | e ± d} and †S = ∪{†e | e ∈ S}



Fig. 9. Continuity and dual continuity at a set


complement is ∼ U = Σ—U ; for FΣ, its complement family, ∼ FΣ, is {∼ U | U ∈ FΣ}.
FΣ is an open family if it is closed under unions, and it is a closed family if it is closed under intersections. Every open family has an interior operation, ι, which computes the largest property contained within a set: ι : У(Σ) → FΣ is defined ι(S) = ∪{U ∈ FΣ | U ⊆ S}. Dually, every closed family has a closure operation, ρ, which computes the smallest property covering a set: ρ : Σ → FΣ is defined ρ(S) = ∩{K ∈ FΣ | S ⊆ K}. If FΣ is an open family, then its complement is a closed family (and vice versa). When we define FΣ = γ[A] and γ is the upper adjoint of a Galois connection, then FΣ is a closed family.
For f : Σ → Σ, define f : У(Σ) → У(Σ) as f [S] = {f (s) | s ∈ S}, and define
f −1 : У(Σ) → У(Σ) as f −1(T )= {s ∈ Σ | f (s) ∈ T }, as usual.
f is FΣ-preserving iff for all U ∈ FΣ, f [U] ∈ FΣ. In such a case, f : FΣ → FΣ is well defined. This generalizes the notions of open and closed mappings on a topology. Since FΣ = γ[A] is a closed family, we have immediately that f :Σ → Σ is forwards complete iff it is FΣ preserving, that is, iff it is a topologically closed map.
We can characterize backwards completeness similarly. But first, we must gen- eralize the definition of continuity so that it applies to property families that might not be topologies.
Let Us (respectively, US) denote a member of FΣ such that s ∈ Us (resp.,
S ⊆ US):
For c ∈ Σ, f :Σ → Σ is continuous at c iff for all Vf(c) ∈ FΣ, there exists some
Uc ∈ FΣ such that f [Uc] ⊆ Vf (c).
For S ⊆ Σ, f is continuous at S iff for all Vf [S] ∈ FΣ, there exists some US ∈ FΣ
such that f [US] ⊆ Vf[S].
f is FΣ-reflecting iff for all V ∈ FΣ, f −1(V) ∈ FΣ, that is, f −1 is FΣ-preserving. The second definition is needed because FΣ might not be an open family. Figure 9, part (i), diagrams the notion of continuity at a set. If FΣ is a topology, then all
three notions are equivalent.
We retain these fundamental results:

Proposition 8.1 [28]
f is FΣ-reflecting iff f is continuous at S, for all S ⊆ Σ.
If FΣ is an open family, then f is FΣ-reflecting iff f is continuous at s, for all
s ∈ Σ.
f :Σ → Σ is ∼ FΣ-reflecting iff f is FΣ-reflecting.
For S, S' ⊆ Σ, write S ≤J	S' iff for all K ∈ FΣ,S ⊆ K implies S' ⊆ K.

This is the specialization ordering from topology. Write S ≡JΣ
S' iff S ≤J
S' and

S' ≤J  S.
The following definition is the usual one for abstract-interpretation backwards
completeness: f :Σ → Σ is backwards-FΣ-complete iff for all S, S' ⊆ Σ, S ≡JΣ S'
'
implies f [S] ≡JΣ f [S ].
Lemma 8.2 [28] Let ρ be the closure operator for closed family, FΣ. The following are equivalent:
f is backwards-FΣ-complete;
for all S ⊆ Σ, f [S] ≡JΣ f [ρ(S)];
ρ ◦ f = ρ ◦ f ◦ ρ.
Item (iii) lets us conclude:
Theorem 8.3 For closed family, FΣ, f :Σ → Σ is backwards-FΣ-complete iff f is
FΣ-reflecting, that is, iff it is topologically continuous.
For domain L∞ and its finite approximants, Lk, let’s consider the relationship between the Scott-continuous functions, f : L∞ → L∞, and the backwards-complete
functions for each У(L∞)⟨αk, γk⟩LTop, k ≥ 0. First, all functions f are trivially L -

k
backwards complete (that is, backwards complete for У(L∞)⟨α0, γ0⟩LTop
0
). Since

the collection of property sets defined by γk[Lk] is a subset of those for γk+1[Lk+1],
any Lk-backwards complete f is Lj-backwards complete for j < k.
Consider the domain defined in Figure 6:
There is a Scott-continuous function, f : L∞ → L∞, that is not Lk-backwards complete for all k > 0. Define f as follows: f (dk, nil) = nil, for all k ≥ 0, and f (l) = ⊥, otherwise. This function is Scott-continuous. Consider f —1{nil}; it is exactly all the total, finite lists in L∞, and for no finite element e ∈ L∞ does this set equal ↑e. (Nor does the union of the upclosed sets of finite elements in any Lk equal f —1(nil) — the union of the basic opens of all finite lists in L∞ are required.)
For each k > 0, there is a monotone, Lk-backwards complete function that is not Scott-continuous. For k, define fk : L∞ → L∞ as follows: f (⊥)= ⊥; for j < k, fk(dj, nil) = (dj, nil) and fk(dj, ⊥) = (dj, ⊥). For j ≥ k, fk(dj, nil) = (dk, ⊥); fk(dj, ⊥)= (dk, ⊥). Finally, define fk(d∞)= d∞. This makes fk monotone and backwards complete but Scott-discontinuous. The result does not change when the sets defined by Lk are closed under union.

These results are not surprising, because the property family for each Lk-domain is coarser than the Scott topology for the corresponding domain. They are frustrating, however, because they show how difficult it is to establish a homomorphism property from a concrete to an abstract denotational semantics.
Now, what about open families? Let FΣ be open (closed under unions) and ι :
У(Σ) → FΣ be its interior map.
In abstract interpretation, one uses an open family to perform an underap- proximating precondition analysis: for f : Σ → Σ, define f —1 : У(Σ) → У(Σ) as f —1(S)= {s ∈ Σ | f (s) ∈ S}, as usual.
The strongest (weakest precondition) abstract function for f —1 is ι ◦ f —1 : FΣ → FΣ.
This makes forwards-FΣ-completeness defined as f —1 ◦ ι = ι ◦ f —1 ◦ ι and backwards-FΣ-completeness defined as ι ◦ f —1 = ι ◦ f —1 ◦ ι.
It is easy to understand forwards completeness: f —1 is FΣ-preserving iff f —1 is forwards-FΣ-complete iff f is ∼ FΣ-reflecting iff f is FΣ-reflecting. This is the classic pre- post-condition duality of predicate transformers.
Backwards completeness for an open family and f —1 is a “dual continuity” prop- erty. Say that f —1 : У(Σ) → У(Σ) is dual continuous at S ⊆ Σ iff for all U ∈ FΣ, if f —1[S] ⊇ U then there exists V ∈ FΣ, V ⊆ S, such that f —1[V] ⊇ U. Figure 9, part (ii), depicts dual continuity at a set.
Theorem 8.4 f —1 is dual continuous for all S ⊆ Σ iff f —1 is backwards-FΣ- complete, that is, ι ◦ f —1 = ι ◦ f —1 ◦ ι.

Conclusion
Abstract interpretation and denotational semantics share foundations and appli- cations, and the interaction between the two areas is intricate. The inverse-limit construction and its associated Scott-topology show how to derive abstract domains as structural approximations of inverse-limit-defined Scott-domains. The inductive format of denotational semantics definitions ensures the soundness of the resulting abstract interpretation, where abstract domain replaces Scott-domain. In this man- ner, abstract interpretation can be explained from the perspective of denotational semantics.

Acknowledgement
Robert Tennent’s depth of insight and clarity of presentation have been a continuing source of inspiration, and this paper is dedicated to him on the occasion of his 65th birthday.
The referees are thanked for their helpful comments.

References
S. Abramsky. Domain theory in logical form. Ann.Pure Appl.Logic, 51:1–77, 1991.
T. Ball, A. Podeksi, and S. Rajamani. Boolean and cartesian abstraction for model checking C programs. J. Software Tools for Technology Transfer, 5:49–58, 2003.
P. Cousot. M´ethodes it´eratives de construction et d’approximation de points fixes d’op´erateurs monotones sur un treillis, analyse s´emantique de programmes. PhD thesis, University of Grenoble, 1978.
P. Cousot. Constructive design of a hierarchy of semantics of a transition system by abstract interpretation. Theoretical Computer Science, 277:47–103, 2002.
P. Cousot and R. Cousot. Abstract interpretation: a unified lattice model for static analysis of programs. In Proc. 4th ACM Symp. on Principles of Programming Languages, pages 238–252. ACM Press, 1977.
P. Cousot and R. Cousot. Systematic design of program analysis frameworks. In Proc. 6th ACM Symp. on Principles of Programming Languages, pages 269–282. ACM Press, 1979.
P. Cousot and R. Cousot. Higher-order abstract interpretation. In Proceedings IEEE Int. Conf. Computer Lang., 1994.
P. Cousot and N. Halbwachs. Automatic discovery of linear restraints among variables of a program. In Proc. 5th ACM Symp. on Principles of Programming Languages, pages 84–96. ACM Press, 1978.
V. Donzeau-Gouge. Denotational definition of properties of program’s computations. In S. Muchnick and N.D. Jones, editors, Program Flow Analysis: Theory and Applications. Prentice-Hall, 1981.
R. Giacobazzi and E. Quintarelli. Incompleteness, counterexamples, and refinements in abstract model checking. In Static Analysis Symposium, LNCS 2126, pages 356–373. Springer Verlag, 2001.
R. Giacobazzi, F. Ranzato, and F. Scozzari. Making abstract interpretations complete. J. ACM, 47:361–416, 2000.
G. Gierz, K.H. Hofmann, K. Keimel, J.D. Lawson, M.W. Mislove, and D.S. Scott. Continuous Lattices and Domains. Cambridge Univ. Press, 2003.
S. Graf and H. Saidi. Construction of abstract state graphs with pvs. In Proc. Conf. Computer Aided Verification, pages 72–83. Springer LNCS 1254, 1997.
C. Gunter. Semantics of Programming Languages. MIT Press, Cambridge, MA, 1992.
T. Jensen. Abstract Interpretation in Logical Form. PhD thesis, Imperial College, London, 1992.
P. Johnstone. Stone Spaces. Cambridge University Press, 1986.
N.D. Jones and S. Muchnick. Flow analysis and optimization of LISP-like structures. In Proc. 6th. ACM Symp. Principles of Programming Languages, pages 244–256, 1979.
N.D. Jones and A. Mycroft. Data flow analysis of applicative programs using minimal function graphs. In Proc. 13th ACM Symp. on Principles of Prog. Languages, pages 296–306, 1986.
R. Milne and C. Strachey. A Theory of Programming Language Semantics. Chapman and Hall, 1976.
A. Min´e. The octagon abstract domain. J. Higher-Order and Symbolic Computation, 19:31–100, 2006.
F. Nielson. A denotational framework for data flow analysis. Acta Informatica, 18:265–287, 1982.
F. Nielson. Program transformations in a denotational setting. ACM Trans. Prog. Languages and Systems, 7:359–379, 1985.
F. Nielson and H. R. Nielson. Two-Level Functional Languages. Cambridge University Press, 1992.
F. Nielson, H.R. Nielson, and C. Hankin. Principles of Program Analysis. Springer Verlag, 1999.
G. Plotkin. Domains. Lecture notes, Univ. Pisa/Edinburgh, 1983.
J.C. Reynolds. Notes on a lattice-theoretic approach to the theory of computation. Technical report, Computer Science, Syracuse University, 1972.
D.A. Schmidt. Comparing completeness properties of static analyses and their logics. In Asian Symp. Prog. Lang. Systems (APLAS’06), LNCS 4279, pages 183–199. Springer Verlag, 2006.


D.A. Schmidt. Abstract interpretation from a topological perspective. Technical report 2009-1, Computing and Information Science, Kansas State University, 2009.
D.S. Scott and C. Strachey. Toward a mathematical semantics for computer languages. In J. Fox, editor, Proceedings of Symposium on Computers and Automata, pages 19–46. Microwave Research Institute Symposia Series: Volume 21, Polytechnic Institute of Brooklyn, 1971.
M.B. Smyth. Powerdomains and predicate transformers: a topological view. In Proc. ICALP’83, LNCS 154, pages 662–675. Springer, 1983.
R.D. Tennent. The denotational semantics of programming languages. Comm. ACM, 19:437–453, 1976.
R.D. Tennent. Language design methods based on semantic principles. Acta Informatica, 8:97–112, 1977.
