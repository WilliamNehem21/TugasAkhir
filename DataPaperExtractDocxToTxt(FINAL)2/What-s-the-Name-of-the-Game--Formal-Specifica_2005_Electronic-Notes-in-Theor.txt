Electronic Notes in Theoretical Computer Science 130 (2005) 129–150 
www.elsevier.com/locate/entcs


What’s the Name of the Game?
Formal Specification of Artificial Intelligence Games
Vladimir Di Iorio1
Departamento de Informa´tica, Universidade Federal de Vi¸cosa, Vi¸cosa, Brazil

Roberto S. Bigonha2, Mariza A. S. Bigonha3
Departamento de Ciˆencia da Computa¸c˜ao Universidade Federal de Minas Gerais Belo Horizonte, Brazil

Alcione Oliveira4, Eliseu Miguel5
Departamento de Informa´tica, Universidade Federal de Vi¸cosa, Vi¸cosa, Brazil


Abstract
Artificial intelligence games are a very interesting tool for teaching Artificial Intelligence tech- niques. Competitors write programs for agents, which are supposed to complete a given task or fight against other agents. In order to achieve the best performance, programs may have to use advanced Artificial Intelligence methods. In this paper, we present a framework to build artificial intelligence games, using Abstract State Machines (ASM) for the specification of the rules of the games. Choosing ASM, we expect that the competitors will be able to understand clearly the semantics of the rules. The framework includes a compiler for an ASM-based language, allows complete control of the order of execution of agents and easy integration with graphical libraries.
Keywords: Artificial Intelligence, computer games, Abstract State Machines.



1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2005.03.008

Introduction
Game playing is one of the oldest areas of research in Artificial Intelligence. The first studied games were board games, like chess. In the past years, re- search evolved to cover multi-agent games with sophisticated agent interaction, including simulation of human behaviour.
According to Russel and Norvig [22], an agent is anything that can be viewed as perceiving its environment through sensors and acting upon that environment through effectors, or actions. In multi-agent artificial intelligence games, a competition is established among agents, which are usually restricted to a small number of actions. The agents are given a task to complete, or they fight against other agents in order to achieve the best performance, according to the rules of the game. In a more complex competition, agents with different behaviour may form teams to maximize their results [24]. When the behaviour of the agents is specified by computer programs, with few or no human inter- ference, they are called bots [12]. Some games allow also an interaction among bots and human players.
The main goal of the competitors, in a multi-agent artificial intelligence game, is to write the best program for their bots. To achieve this goal, it is necessary to understand clearly the rules of the game, i. e. what actions the bots are allowed to execute and the consequences of the execution of these actions on the environment.
Abstract State Machines (ASM) [3,8] are an ideal formalism for giving a clear definition of a multi-agent artificial intelligence game. The semantics of an ASM specification is easy to understand and this method has been used for the specification of many distributed systems successfully [2,9].
In this paper, we present a framework for building artificial intelligence games, using ASM for the specification of the rules of the games. The frame- work includes a compiler from an ASM-based language called Machˇına [28] to C++. It should be interesting if games could be represented graphically, possibly with animation, so the framework provides for easy integration with graphical libraries. The compiled code is efficient enough to produce anima- tion with reasonable speed.



1 Email: vladimir@dpi.ufv.br
2 Email: bigonha@dcc.ufmg.br
3 Email: mariza@dcc.ufmg.br
4 Email: alcione@dpi.ufv.br
5 Email: emiguel@dpi.ufv.br

Related Work

There is a great number of available commercial games which use artificial intelligence techniques to specify the behaviour of bots [26]. Some of them have bots with a fixed behaviour, designed to fight against human players. Most first-person shooter (FPS) games are included in this category. FPS games are very popular 3D action games where the user moves through different scenes and collect weapons to destroy enemies. One example is Doom II [19]. We are interested in another kind of games: the ones in which it is possible for the users to program the behaviour of the bots. They are known as games with extensible AI [29].
Some modern FPS games have extensible AI. For example, Half-Life [18] offers a bot kit using C++ as the programming language. Some games, al- though classified as entertainment, have only programmable bots and no hu- man player. One example is AI Wars [20], with a programming language mix- ing specialized commands with basic programming resources. The Robocode project [13] implements a robotic battletank. The behaviour of the bots is defined using the Java programming language.
Some frameworks provide visual tools in order to make the program- ming tasks easier, even for users with no programming languages background. Stagecast [6] and Gamut [14] are good examples of systems which help users build games and simulations without writing code.
The Gamebots project [1,11] has been designed for education and research in artificial intelligence. It has created a test-bed for multi-agent systems using an extension for the commercial Unreal Tournament game engine [7]. Unlike other extensible AI games, Gamebots does not define a single benchmark task. The wide variety of predefined tasks and environments can be extended in various ways, using a C++-based scripting language called UnrealScript [25]. Communication between the game server and bots are done via sockets, so bots can be programmed in different languages. Examples using Java and Soar [21] are available.
Our work is similar to Gamebots, in the sense that the proposed games have no predefined tasks. But our approach is much more general, since we can define any kind of game. The proposed games are not restricted to a predefined environment or style. In the Gamebots project, games can be extended and even new games created, using Unreal Script, but in a limited way. And in order to understand the rules of the proposed game, it is necessary to know the script language, which was not designed to be a good formal specification method. We believe that Abstract State Machines are a very elegant solution for this problem. The semantics of the rules are clear as long as they are

written as a well designed ASM specification.
Abstract State Machines
In this section, we present a brief introduction to the formalism of Abstract State Machines, concentrating in the sequential model. Agents and concurrent execution will be addressed later. A more formal and complete presentation can be obtained in [3,8,27].
Vocabulary, functions and states
The vocabulary or signature of a sequential ASM A is a finite collection of function names, each with a fixed arity. A state of A is a nonempty set called superuniverse, together with interpretations of the vocabulary names on functions over the superuniverse. These interpretations are designated basic functions. Different states have different interpretations for the vocabulary names, but the superuniverse always remains unchanged.
Formally, in a superuniverse X, a basic function with arity r is a Xr → X function. When r = 0, a function is called distinct element . The superuniverse always contains the distinct elements true, false and undef , defined as logical constants. The element undef is used for representing partial functions, for example, f (a) = undef means that function f is undefined for tuple a. A r-ary relation over X can be represented by a Xr → {true,false} function. An universe U is a special basic function: an unary relation identified by the set of elements x such that U (x)= true, i.e., {x : U (x)}.
Programs
A program of A is a transition rule, specifying transformations over states, generating new states. A transition rule is composed by basic and non-basic rules. The basic rules are: update rule, block constructor and conditional constructor .
Update rule

An update rule is an expression f (t) := t0, where f is the name of a function on the vocabulary of A, t is a tuple of terms whose length equals the arity of f and t0 is another term. Terms have no free variables and are recursively built using names of distinct elements and application of function names to other terms. The semantics of the update rule is: the tuple t is evaluated and the value of the basic function f applied to the evaluation of t is updated with the evaluation of the term t0. In other words, the name f receives a new interpretation.

Conditional constructor
A conditional constructor is an expression with the following format:
if g0 then R0	elseif g1 then R1 ... elseif gk then Rk	endif
The semantics is: the rule Ri,0 ≤ i ≤ k, will be executed if the boolean terms
g0, ..., gi−1 evaluate to false and gi evaluates to true.

Block constructor
A block constructor is a set of rules:
R0,	R1,	. . . ,	Rk
with the following semantics: rules R0, R1, ..., Rk are executed in parallel. If this execution produces inconsistent updates, an unpredictable result is generated.

Non-basic rules
Non-basic rules use bound variables. They increase the power of expression of the language allowing, for example, the introduction of non-determinism and the extension of universes, creating new elements. One example is the var rule:
var v ranges over U  R0 endvar
where v is a variable, U is a finite universe and R0 is a rule. An instance of rule R0 is created for each element belonging to universe U , associating the variable v to each of these elements. Then, all rules are executed in parallel.

Runs
A run of a program of A is a sequence of states. Each state is generated by the execution of the transition rule over the previous state. If a run is not affected by the external environment, it ends when no update is produced by the execution of the transition rule. Most implementations of ASM define also a special command stop, which indicates an explicit end for a run.

External functions
In order to allow an interface with the external environment, external func- tions are defined in ASM. An external function may return different results, when called with the same arguments, in different steps of a run.

The Language Machˇına
Machˇına is a strongly typed ASM-based programming language, with special structures for modularity, visibility control and information hiding. In this section, we present only the main concepts of the language. Complete infor- mation about Machˇına is available in [28]. Examples are presented in sections 6 and 7.

Modules
The main syntactic structure of Machˇına programs is a module. A module con- tains a transition rule and declarations of types, actions and ASM functions. Only declarations qualified as public are visible outside the module.
To execute the transition rule of a module, it is necessary to dynamically create an agent based on this module. The exception is the Main module, for which an agent is automatically defined. When an agent executes the transition rule of a module, the function name self is interpreted as the current agent.
The first section of a module is the import section, where public names from other modules can be imported. Next, the declaration section defines types, functions and actions. Following the declarations, an initial state section may be defined, which is an ASM rule executed only once, before the execution of the transition rule of any module. Finally, the transition rule of the module can be defined. This rule is executed every time an agent associated with the module becomes active. Elements present in the declaration section of Machˇına modules are described bellow.

Types
New types can be created, using the predefined types and composition. Composed types are: lists, sets, tuples and agents. The type “Agent” is a generic agent and the type “Agent of M” defines an agent based on a mod- ule with name “M”. A functional type is defined by the syntactic construct (T1 -> T2), where T1 and T2 are types.

Functions
Functions can be qualified as static, dynamic, derived and external . Static functions are ASM functions that cannot be updated, dynamic functions are ASM functions that can be updated, derived functions receive parameters and return values and external functions are defined outside the system, possibly written in another programming language.

Actions
Actions are abstractions for ASM transition rules, discussed in detail in Section 4.3. Actions can also be qualified as external, when defined outside the system.

Transition Rules
The basic ASM transition rules, update, conditional and block rule, are imple- mented in Machˇına with the usual ASM semantics. Other rules are available:
choose : Non-basic rule for non-deterministic choices.
forall : Equivalent to the var rule, described in Section 3.
let : For local definitions.
stop: Interrupts the execution of a program and kills all agents.
create : Used for the creation of agents. When an agent is created, this rule indicates the program code which will be executed, associating the agent with a Machˇına module.

Actions
Actions are an important Machˇına feature, implementing abstractions for transition rules. Actions may receive parameters and execute a transtition rule with bound variables, using values instantiated at execution time. All val- ues in Machˇına are dynamically allocated, so when parameters are passed to actions in an action call , references are used, implementing a call-by-reference protocol. Examples of Machˇına actions are shown in Section 7.
The semantics of an action call is the following: all updates are collected, and then fired in parallel with other updates of the block where the action call is placed. In other words, updates produced by an action call in a state of a run only affect values in the next state of the same run.
There is also a special kind of action designated loop action. In this case, the transition rule of the action is repeatedly executed until a return command is executed. But a call to a loop action has the same semantics of a call to a simple, non-loop action: all updates are collected and fired in parallel, affecting only the next state of the run.

Multi-Agent Artificial Intelligence Games
In multi-agent artificial intelligence games, we can identify two kind of pro- grams: programs designed by the creator of the game, defining the rules of



Fig. 1. Scheme of a multi-agent artificial intelligence game.
the game, and programs created by users, simulating the behaviour of com- petitors. In this section, we discuss these programs and other components of a multi-agent artificial intelligence game in detail. It is important to understand the relationship between these components before we present the framework we have built, in Section 6.

Main Components
In Figure 1, environment represents the current state of a game. The envi- ronment consists of a set of objects. The attributes of these objects may be concurrently updated by agents, denoted in Figure 1 by A, B , C , D , E and F . Dashed arrows represent agents reading information about the environment, and solid arrows represent agents updating environment information.
Some agents are designed by the creator of the game, defining the rules of the proposed game. We will call them internal agents, represented in Figure 1 by A, B , C and D . Figure 1 shows also user-controlled agents, as the ones represented by E and F , which we will call user agents. User agents may receive information from the environment and try to act upon the objects.
Internal agents are always controlled by computer programs. User agents, on the other hand, may also be controlled by humans. But in this work, we will suppose that all user agents in an artificial intelligence game are controlled by computer programs. When the behaviour of agents is specified by computer programs, working intelligently without depending upon any human interac- tion, they may be called bots [12]. So the agents of Figure 1 will be classified as internal bots (the programs defining the rules of the game) and user bots (which are user-defined programs, representing the players in a multi-agent artificial intelligence game).
If graphical representation is necessary, it may be interesting to have an extra internal bot designed specifically to produce visual information. In Fig-


ure 1, it is represented by D , which reads the current state of the environment and displays it in a suitable way, in an output device.
Two or more bots may be running the same program code. In this case, they will present the same behaviour. A bot may update several objects, and an object may be updated concurrently by several bots. When there is just one internal bot in the system, objects have a centralized control. In Robocode [13], for example, the environment is controlled by a single agent, responsible also for producing visual representation. When objects are updated by differ- ent internal bots, the rules of the game are defined by a distributed program. This multi-agent definition for the environment is used in the framework pre- sented in Section 6, and represents a more general approach than the one adopted in systems like Robocode. No assumption is made for the relative execution speed of internal and user bot programs.

An Example: the Snake Game
To better illustrate the concepts presented in Section 5.1, we now show a simple example that uses all the main components of a general multi-agent artificial intelligence game. The example involves a game designated as the snake game, which is also used in the following sections.
In the snake game, several snakes move in a two-dimensional space, trying to reach an object designated as the vitamin. A snake is composed by a special first cell called the head , possibly followed by several other cells, known as the body . If there is at least one cell in the body, the last cell of the sequence is the tail . The movement is controlled by the head, and the other cells follow their respective previous neighbour in the sequence. When the head of a snake reachs the vitamin, we say that this snake “eats” the vitamin. In this case, the body of that snake grows one cell, and the vitamin appears somewhere else in the space. The goal is to make a snake longer, until reaching a predefined length. We have added some other rules in order to make the competition more interesting. We will present these rules in Section 7.
Using the snake game in an artificial intelligence context, we may have all the components shown in Figure 1, as described below.


Environment:
The environment is represented by the position of the vitamin and the position of the cells of each snake. In addition, we may have an attribute associated with each snake, representing the direction of its movement (north, south, east or west ).

Graphical Representation:
A special bot may read information from the environment and define a visual representation. Figure 2 shows an example of a simple graphical repre- sentation for the snake game. A snake head is represented by an image that indicates its direction of movement. Animation is generated by the sequence of state changes produced by the execution of the bot programs.

User Bots:
User bots may control the snake actions indirectly, changing their direction of movement. If two snakes have the same behaviour, they may be controlled by user bots that run the same program code. But each snake may be con- trolled by a single user bot.

Internal Bots:
Internal bots change the position of the snakes, according to the current direction of movement. For example, if the direction of movement of a snake is north, the associated internal bot will execute transformations in the envi- ronment in order to move the snake head one position to north, and move all other cells to the previous position of their neighbour in the sequence. There is exactly one internal bot associated with each snake. We say that an inter- nal bot A is controlled by an user bot B when B controls the snake to which A is associated. We may suppose that all snakes follow the same rules for movement, so all internal bots run the same program code.
Among other tasks, programs written for internal bots must have code for:
generating movement for a snake, according to the current direction of its head;
detecting collision of a snake’s head with the vitamin;
increasing a snake’s length when a collision with the vitamin is detected.
Notice that these items represent exactly the rules for the snake game. So, understanding the program code built for internal agents is crucial for under- standing exactly the rules of the game.

A Framework for Multi-Agent Artificial Intelligence Games
The framework we have developed is composed by a compiler from the ASM- based language Machˇına to C++, together with facilities to control the con- current execution of the agents and to produce graphical representation for





Fig. 2. Snapshot of the snake game.


games. The framework provides an implementation for all the components discussed in Section 5.

The Speciﬁcation Language
We have chosen Machˇına as the specification language for our framework. The use of an ASM-based language for the specification of the rules of the games provides a precise definition for them. If the specifications are carefully designed, the rules will be easily understood. Another advantage of using Machˇına is that the specifications can be executed, simulating animation at reasonable speed.
Important features present in Machˇına are: suitable data structures for the description of the environment in artificial intelligence games, possibility of specification of distributed programs, control of visibility of data and actions, efficient compilation to C++. The use of these features in the specification of multi-agent artificial intelligence games is discussed below.

Environment Specification:
When defining an artificial intelligence game, the first task is the specifi- cation of the environment . The environment is a collection of attributes that describe the current state of a game. Using an ASM-based language, these attributes may be represented by functions, defining an ASM state. Machˇına offers suitable data structures to represent these functions.

Programs executed by bots:
The possible transformations that the environment may suffer, together with the environment specification, define the rules of an artificial intelligence game. These transformations are carried out by internal and user bots. Dis- tributed ASM programs may provide an implementation for bot programs, which execute concurrently. These programs can be defined using Machˇına modules, and executed by Machˇına agents.

Visibility Control:
User bots may affect the game environment in a restricted way, following the rules of the game. The communication between user bots and the game environment can be implemented via ASM functions. With Machˇına, it is also possible to define this communication with actions, abstractions for ASM rules. Not all functions representing the environment state and not all defined actions may be visible for user bots. In Machˇına, it is possbile to define restrictions on the visibility of data structures and actions. This visibility control is important in preventing “cheating”, i. e. competitors are supposed to follow strictly the rules of the game.

Graphical Representation:
Visual representation of a game may be provided by an extra agent that reads information from the environment, as discussed in Section 5. This agent may have access to a graphical library via ASM external functions. Machˇına has also external actions, abstractions for ASM transition rules which may be defined elsewhere in the system, even using another programming language. We have developed examples written in C++, using the open source multi- platform game development library Clanlib [17].
Using ASM and Machˇına, the rules of an artificial intelligence game are represented by the environment specification and by distributed programs which will be executed by bots. We hope that, reading these specifications, a competitor is able to understand clearly the rules of the game and is ready to write programs which will compete in the proposed environment. ASM allows the creation of specifications at a natural level of abstraction, and this quality is inherited by Machˇına, which has the advantage of an efficient compilation to C++.

Controlling the Execution of Agents
In principle, no assumption is made for the relative execution speed of Machˇına agents. It means that an agent can execute several moves, before any other


agent has the chance to proceed. But sometimes it is interesting to define a more restrictive order of execution. For example, consider the snake game of Section 5.2. A special internal agent produces a visual representation for the environment. Every time an internal bot executes a move on a snake, a visual change should be produced. In order to create good animation, the agent that provides visual representation should be executed immediately after the execution of any other internal bot of the system.
Our framework has added to Machˇına the concept of active agents, sim- ilar to that presented in [8] for Distributed Algebras, using the additional unary relation name machActive. Only agents satisfying this relation are ac- tive and can make moves. But in our framework, every time an agent exe- cutes its transition rule, it also automatically executes the following update: machActive(self) := false. It means that the agent becomes idle until the frame- work changes its state to active again. There is also an additional relation machAllAgents, which is true for any agent, either active or not.
As presented in Section 4.1, Machˇına defines a special module named Main module, for which an agent is automatically defined. In our framework, this agent is designated the Main agent , and it is always active. The Main agent is allowed to create other agents and update the function machActive, building any desired policy for the execution of all other agents in the system.
Figures 3 and 4 show an example of a Main module that implements the policy discussed in the beginning of Section 6.2. The dynamic functions in- volved are:
curAg: Represents the current active agent.
nextAgents: Set from which an agent is picked up to be activated.
exib: Represents an agent that produces a visual representation for the game.
userBots: The set of user bots.
In this case, the set machAllAgents is formed by agent exib, together with the union of set userBots and the set of internal agents which produce movement for the snakes.
Suppose that a module named Exibition defines rules that produce a visual representation for a game. In the initial state section of the Main module of Figure 3, an agent that executes transition rules defined by module Exibition is created. This agent is then associated with the function name exib. Other agents may be created in this section, representing the internal and user bots of the game, as shown in Section 7.4.
In Figure 4, the transition rules received line numbers in order to make the following explanation easier. Lines 1-3 initialize the set nextAgents with



Fig. 3. Declarations of functions and initial state in a Main module.
all internal bots that move the snakes (all agents of the system, except exib and the user bots). Lines 4-9 choose, non-deterministically, an agent from the nextAgents set. This agent is activated, removed from the nextAgents set and defined as the current active agent. Lines 11-12 will only be executed after curAg has executed its transition rule, when it is automatically deactivated. Then, agent exib is activated to show the possible changes produced by curAg. Line 14 will only be executed after exib has executed its transition rule. A new agent is selected from the nextAgents set, in lines 4-9, until this set becomes empty. Then the process starts again in lines 1-3 with the set of all bots, except agent exib. Rules of lines 16-18 assures that all user bots will always be active, so the transition rules of the user bots may be executed at any time.
The semantics of the transition rules of Figure 4 assures that visual in- formation is provided immediately after any agent moves. Besides this, it implements a policy which is free from starvation.
The execution order of agents may be programmed directly in the code of the internal bots. But separating the rules for the scheduling policy from the rules of the game can make the specification more clear. It can also make proofs of properties related to the scheduling policy easier.
Our framework has the advantage that even the order of execution of agents is defined by a specification written in ASM.
The Snake Game Implemented in Machˇına
In this section, we show part of an implementation of the snake game in Machˇına. The first task is to develop an abstract data type for the represen- tation of snakes. Using the operations of this abstract data type, we build



Fig. 4. Transition rules for a Main module.
the rules of game, defining the code executed by internal bots, which produce movements for the snakes. Competitors may write user bots to control the direction of movement of the snakes. Finally, a Main module creates instances of the user bots.

Representing Snakes
Figure 5 shows part of the module SnakeData, that implements an abstract data type for the representation of snakes. Some basic structures, like Pos2D (position in a 2-dimensional space) and Direction (direction of movement) are imported from other modules.
The public type SnakeDescriptor is defined as a 3-tuple. A snake is rep- resented by its length, the position of each cell and the current direction of movement. The position of each cell is given by a function that associates the sequential number of the cells (the head is numbered as “1”) with positions in the 2-dimensional space.
Several public derived functions and actions implement operations on the abstract data type. The symbol “:=” (usually used as function update) is



Fig. 5. Module SnakeData : abstract data type representing a snake.
used here for the definition of the body of derived functions and actions. For example, given a snake descriptor, function getLength returns its length. Suppose that p is a position neighbour to the head of a snake described by a SnakeDescriptor s. Then action moveToPosition changes the position of the snake head to p, moving also the cells of the snake body. Notice that call-by-reference parameter passing is important for this action to work properly.
The name of a named tuple may also be used in Machˇına as a constructor . An example is shown by the public derived function buildSnake, which creates a new snake descriptor with just one cell, given an initial position and direction of movement.

The Rules of the Game
In figures 6 and 7, part of the code of module SnakeMove is presented. It imple- ments the rules that define the movements for snakes. These are in fact the

rules of the game.
As previously discussed in Section 5.2, the snake game involves two kind of agents. Internal bots produce movement for snakes, according to the current direction of movement, so they are agents based on module SnakeMove. User bots, on the other hand, are agents based on modules written by competitors. According to the rules informally presented in Section 5.2, each internal bot has a single user bot that controls it. So, in order to prevent “cheating”, the framework must provide resources to ensure that each SnakeMove agent will be controlled by a single user agent.
In Figure 6, the game environment is represented by the dynamic functions vitaminPos, the vitamin position, snakeControl, which maps an user bot to the SnakeMove agent that it controls, and snakeInfo, which maps a SnakeMove agent to the descriptor of the snake that it moves. An example of use of snakeInfo is shown by the derived function getLength. Given a SnakeMove agent, this function returns the length of the associated snake, using a derived function with the same name from module SnakeData (see also Figure 5).
The movement of all snakes follow the same rules, so it is natural that agents which move snakes execute the same code. Then, all internal bots run the same program code. Each internal bot access the attributes of its associ- ated snake using the function name self, which has a different interpretation when the code is executed by different agents. In module SnakeMove, self is interpreted as the current SnakeMove agent in execution. Examples are shown in the transition rule of Figure 7, where line numbers are added in order to make the following explanation easier.
If a snake achieves a predefined length, it is considered the winner of the game. Line 1 of the transition rule executes the Machˇına rule stop, which kills all agents, if the current agent has achieved the desired length. Otherwise, p is calculated as the new position of the snake head, according to the currrent direction of movement. Lines 5-6 are executed if the snake eats the vitamin. In this case, action calls make the snake grow one cell and make a new position to the vitamin be chosen. If p is a free cell, an action call in line 8 makes the snake move to that position (observe the definition of the action moveToPosition in figures 6 and 5). Lines 10-13 are executed when the snake head eats another snakes tail. In this case, the current snake grows one cell and the other loses one cell. If none of the above conditions are true, it means that p is the position of a snake cell, but not a tail. In this case, the action call in line 15 is executed and the snake loses one cell. The rules of the game are much more sophisticated than the ones presented in Section 5.2, but, using Machˇına, they are very clear and easy to understand. They define when a snake can move, grow and shrink.



Fig. 6. Declarations for the rules of the snake game (Module SnakeMove).

User Bots
User bots are based on modules written by competitors. The only public action from module SnakeMove they can execute is changeDirection (in Figure 6). It is executed by user bots in order to control the movement of a snake.
An user bot has access to its own agent using function self, but it has no access to other agents. The framework gives the permission of this kind of access only to the Main module. This restriction ensures that an user bot can only affect the direction of movement of the internal bot associated to it by function snakeControl.
In order to win the game, a competitor may write code that moves a snake toward the position of the vitamin. It may also try to eat the tail of other snakes. The code may be written in Machˇına or C++. We do not show an example here because of lack of space, and because our main goal is the specification of the rules of games. The complete code of all modules, including examples of user bots and visual animation using the graphical library Clanlib



Fig. 7. Transition rules of the snake game (Module SnakeMove).

[17] can be found in [5].


Creating Instances of User Bots
The Main module creates instances of the user bots. Association to internal bots is performed by action login, defined in module SnakeMove, in Figure 6. This action is not public, so it cannot be executed by another module, except the Main module.
The action login receives an user bot as a parameter. It creates a new agent, an internal bot, to move a snake. The new internal bot is associated to the user bot using function snakeControl. A descriptor is created to store information about the new snake. This descriptor is associated to the new internal bot using function snakeInfo. Using action login is the only way new snakes are inserted into the game.
For example, suppose that a competitor writes a module named Player1. The code below creates an user bot and its associated snake, with initial position (10,30) and initial direction of movement to north. This code should be placed in the specification of the initial state of the Main module (see

Figure 3):

Conclusions and Future Work
Artificial intelligence games are usually defined using logic languages like Pro- log. Examples of simple games created with Prolog can be found in [23]. A much more complex Prolog game is described in [15,16]. But problems with efficiency of generated code prevent logic languages of being used on games with visual animation.
Some systems like the Gamebots project [1,11] allow the definition of differ- ent scenarios for sophisticated 3D games, but the designer must be an expert on programming on the Unreal Script [25] language. And there is a worse problem: in order to understand the rules of a proposed game, either the competitors are also fluent in Unreal Script , or they must rely on a textual, non-precise description of the rules.
In this work, we have shown that ASM and Machˇına are a good alternative for the definition of artificial intelligence games. The advantages are:
ASM are a precise formal specification method. If a specification is care- fully designed, competitors can understand clearly the rules of the proposed game.
Machˇına provides an efficient implementation for ASM specifications. Gen- erated code is efficient enough to produce animation at a reasonable speed. Besides this, Machˇına includes features for visibility control of data and actions, and complete control of the order of execution of agents. These features are important for preventing “cheating” by the competitors.
Other languages based on ASM are also available. Perhaps the most im- portant is ASML [10]. For the purpose of this work, the main disadvantage of ASML is that the language does not implement yet distributed Abstract State Machines. Multi-agent systems can still be defined using ASML, but the specifications are not so elegant and clear as they can be with Machˇına.
The framewok presented in Section 6 can be used for the definition of any distributed system with animated visual representation. In this paper, we have concentrated on artificial intelligence games, but simulation of other distributed systems can be carried out without difficulty.
The framework is being prepared to be used in teaching AI for undergrad- uate students. Interesting, animated multi-agent games can be specified. A


competition will be established among students, who are supposed to write programs for bots representing the competitors in the proposed games. Ad- vanced artificial intelligence techniques may be used in order to produce the best programs. We expect that this competition will make students feel also motivated for learning formal specification methods like ASM.
Our future plans include the definition of more sophisticated games, using also 3D animation. A current project is the implementation of a classic ar- tificial intelligence problem known as Wumpus World [22], whose ASM rules were first presented in [4].

References
R. Adobbati, A. N. Marshall, A. Scholer, S. Tejada, G. Kaminka, S. Schaffer, and C. Sollitto. Gamebots: A 3d virtual world test-bed for multi-agent research. In Proceedings of the International Conference on Autonomous Agents (Agents-2001) - Workshop on Infrastructure for Agents, MAS, and Scalable MAS, 2001.
E. B¨orger, Y. Gurevich, and D. Rosenzweig. The Bakery Algorithm: Yet Another Specification and Verification. In E. B¨orger, editor, Speciﬁcation and Validation Methods, pages 231–243. Oxford University Press, 1995.
E. B¨orger and R. St¨ark. Abstract State Machines: A Method for High-Level System Design and Analysis. Springer-Verlag, 2003.
Vladimir O. Di Iorio, Alcione P. Oliveira, Eliseu C. Miguel, Roberto S. Bigonha, and Mariza
A. S. Bigonha. Utiliza¸c˜ao de M´aquinas de Estado Abstratas em Aplicac¸o˜es de Inteligˆencia Artificial e Jogos. In Proceedings of XXIX CLEI - Conferencia Latino Americana de Informatica, La Paz, 2003.
Vladimir	Oliveira	Di	Iorio.	Abstract State Machines and Artificial Intelligence Games. On-line documentation, 2004. (retrieved 2 July, 2004, from http://www.dpi.ufv.br/˜vladimir/asm/asmANDgames.htm).
P. Fleisher. Stagecast - software review. Technology & Learning Magazine, 2003.
J. Gerstmann. Unreal Tournament : Action game of the year. Gamespot, 1999. (retrieved 8 July, 2004, from www.gamespot.com/features/1999/p3 01a.html).
Y. Gurevich. Evolving Algebras 1993: Lipari Guide. In E. B¨orger, editor, Speciﬁcation and Validation Methods, pages 9–36. Oxford University Press, 1995.
Y. Gurevich and J. Huggins. The Railroad Crossing Problem: An Experiment with Instantaneous Actions and Immediate Reactions. In Proceedings of CSL’95 (Computer Science Logic), volume 1092 of LNCS, pages 266–290. Springer, 1996.
Yuri Gurevich, Benjamin Rossman, and Wolfram Schulte. Semantic Essence of Asml. Technical Report MSR-TR-2004-27, Microsoft Research, March 2004.
G. A. Kaminka, M. Veloso, S. Schaffer, C. Sollitto, R. Adobbati, A. N. Marshal, A. S. Scholer, and S. Tejada. Gamebots: the ever-challenging multi-agent research test-bed. Communications of the ACM, January 2002.
A. Leonard. Bots: The Origin of New Species. Hardwired, 1997.
S. Li.  Robocode: Advanced Robot Battle Simulation Engine.  IBM developerWorks, 2002. (retrieved 19 July, 2004, from http://www-106.ibm.com/developerworks/java/library/j- robocode/index.html).


Richard G. McDaniel and Brad A. Myers. Building Applications Using Only Demonstration. In Proceedings of IUI’98: 1998 International Conference On Intelligent User Interfaces, pages 109–116. ACM Press, January 1998.
Dennis Merritt. Adventure in Prolog. Springer Verlag, 1990.
Dennis Merritt. Exploring Prolog: Adventures, Objects, Animals, and Taxes. PC AI Magazine, 7.5, September/October 1993.
M. Norddahl and Kenneth Gangstoe. Clanlib, a multi-platform game development library., 2004. (retrieved 7 July, 2004, from http://www.clanlib.org/intro.html).
J. Ocampo. Half-Life - game review. Gamespot, 2004. (retrieved 22 November, 2004, from http://www.gamespot.com/pc/action/halflife2/review.html).
F. Provo. Doom II - game review. Gamespot, 2002. (retrieved 21 July, 2004, from http://www.gamespot.com/gba/action/doom2/review.html).
J. Reder. AI Wars (the insect mind), 2004. (retrieved 22 July, 2004, from http://www.tacticalneuronics.com).
P. Rosenbloom, J. Laird, and A. Newell. The Soar Papers. MIT Press, 1993.
S. Russel and P. Norvig. Artiﬁcal Intelligence: A Modern Approach. Prentice Hall, New Jersey, 1995.
Patrick Saint-Dizier. An Introduction to Programming in Prolog. Springer Verlag, 1990.
N. Schurr, S. Okamoto, R. Maheswaran, P. Scerri, and M. Tambe. Cognition and Multi-Agent Interaction: From Cognitive Modeling to Social Simulation, chapter “Evolution of a Teamwork Model”. Cambridge University Press, 2004.
T. Sweeney and A. Moise. UnrealScript Language Reference. Epic MegaGames, Inc., 1998. (retrieved 9 July, 2004, from http://unreal.epicgames.com/UnrealScript.htm).
P. Sweetser. Current AI in Games: A Review, 2002. (retrieved 15 July, 2004, from http://www.itee.uq.edu.au/˜penny/Game%20AI%20Review.pdf).
F. Tirelo, R.S. Bigonha, M. A. Maia, and V.O. Di Iorio. Tutorial em M´aquinas de Estado Abstratas. In Anexo dos Anais do III Simp´osio Brasileiro de Linguagens de Programac¸˜ao, Porto Alegre, Maio 1999.
Fbio Tirelo, Roberto S. Bigonha, Marcelo A. Maia, and Vladimir O. Di Iorio. Machˇına: An ASM-based Specification Language (in portuguese). Technical Report 08/1999, Laborat´orio de Linguagens de Programa¸c˜ao, Universidade Federal de Minas Gerais, 1999.
S. Woodcock. Games with Extensible AI, 2004. (retrieved 15 July, 2004, from http://www.gameai.com/exaigames.html).
