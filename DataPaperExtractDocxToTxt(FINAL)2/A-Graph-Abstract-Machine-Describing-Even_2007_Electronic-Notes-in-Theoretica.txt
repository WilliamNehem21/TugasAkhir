Electronic Notes in Theoretical Computer Science 175 (2007) 21–36	
www.elsevier.com/locate/entcs

A Graph Abstract Machine Describing Event Structure Composition 1
Claudia Faggian2 and Mauro Piccolo3
Dipartimento di Matematica Pura e Applicata – PPS Universita´ di Padova – Paris7-CNRS

Abstract
Event structures, Game Semantics strategies and Linear Logic proof-nets arise in different domains (con- currency, semantics, proof-theory) but can all be described by means of directed acyclic graphs (dag’s). They are all equipped with a specific notion of composition, interaction or normalization.
We report on-going work, aiming to investigate the common dynamics which seems to underly these different structures.
In this paper we focus on confusion free event structures on one side, and linear strategies [8,4] on the
other side. We introduce an abstract machine which is based on (and generalizes) strategies interaction; it processes labelled dag’s, and provides a common presentation of the composition at work in these different settings.
Keywords: Event structures, directed acyclic graph, game semantics, linear logic, proof nets


Introduction
Event structures [14], Game Semantics strategies and Linear Logic proof-nets [7] arise in different domains (concurrency, semantics, proof-theory) but can all be described by means of directed acyclic graphs (dag’s). They are all equipped with a specific notion of composition, interaction or normalization. In this paper we report ongoing work whose first aim is to investigate the common dynamics which appears to underly all these different structures, and eventually to transfer technologies between these settings.
As a first step in this direction, we present an abstract machine which processes labelled dag’s. The machine is based on the dynamics at work when composing

1 This work has been motivated from discussion with Nobuko Yoshida and Daniele Varacca. We are in debt with Daniele Varacca for many explanations, comments, and suggestions. We are grateful to Martin Hyland, Emmanuel Beffara, and Pierre-Louis Curien for interesting discussions. We also wish to thank the referees for many usefull remarks and suggestions.
2 Email: claudia@math.unipd.it
3 Email: piccolo@di.unito.it

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.04.014

Game Semantics strategies. When applied to linear strategies (in the form intro- duced in [8] or [4]) the machine implements strategies composition. When applied to event structures, the result is the same as the paralle composition of event structures defined by Varacca and Yoshida in [17].
Event structures are a causal model of concurrency (also called true concurrency models), i.e. causality, concurrency and conflict are directly represented, as opposite to interleaving models, which describe the system by means of all possible scheduling of concurrent actions.
An event structure models parallel computation by means of occurrence of events, and a partial order expressing causal dependency. Non-determinism is mod- elled by means of a conflict relation, which expresses how the occurrence of certain events rules out the occurrence of others.
Two events are concurrent if they are neither causally related, nor in conflict.
Events which are in conflict live in different possible evolutions of the system.
In this paper we will consider two classes of event structures: confusion free event structure (where conflict, and hence non-determinism, is well behaving), and conflict free event structures (where there is no conflict, and hence no non-determinism).
Confusion free event structure, are an important class of event structures because the choices which a process can do are “local” and not influenced by independent actions. In this sense, confusion freeness generalizes confluence to systems that allow nondeterminism.
A point which is central to our approach is that a confusion free event structure E can be seen as a superposition of conflict-free event structures (which we will call the slices of E): each slice represents a possible and independent evolution of the system. Because of this, if E is confusion free, the study of several properties can be reduced to the study of such properties in conflict free event structures.
Games and strategies provide denotational models for programming lan- guages and logical systems; games correspond to types (formulas), and strategies to programs (proofs). The central notion is that of interaction, which models program composition (normalization of proofs).
A distinction between causal and interleaving models is appearing also in Game Semantics. In this setting, a strategy describes in an abstract way the operational behaviour of a term. In the standard approach, a strategy is described by sequences of actions (plays), which represent the traces of the computation. However, there is an active line of research in Game Semantics aiming at relaxing sequentiality, either with the purpose to have “partial order” models of programming languages or to capture concurrency [1,12,9,11,16,4,2,10,6]. The underlying idea is to not completely specify the order in which the actions should be performed, while still being able to express constraints. Certain tasks may have to be performed before other tasks; other actions can be performed in parallel, or scheduled in any order. A strategy of this kind can be presented as a directed acyclic graph.
Content. An idea which underlies the work on typed π-calulus by Honda and Yoshida is that typed processes should be seen as a sort of Hyland-Ong strategies

(see for example [13]); this approach is implicit also in [17], on which our work builds. Varacca and Yoshida provide a typing system which guarantees that the composition of confusion free event structures is confusion free. The typing is inspired by Linear logic and Hyland-Ong strategies, and allows the authors to give an event structure semantics for (a variant of) Sangiorgi’s πI-calculus.
In this paper we define composition “operationally”, in such a way that when restricted to strategies the machine implements strategies composition. Applied to confusion free event structures, the result is the same as the composition obtained in a more standard way. In particular, we prove the equivalence with the composition in [17]. We believe that the machine provides a simple and direct implementation of event structures composition.
Perspective. This work is part of a larger project, aiming at relating event structures in concurrency theory and strategies in game semantics.
The connection between event structures and strategies is especially striking if we focus on linear strategies, i.e. strategies which correspond to the multiplicative- additive structure of Linear Logic. Linear strategies (as defined in [8] and then [4]) can be described as partial orders with a conflict relation, i.e. as a sort of event structures, which satisfy a number of conditions. In particular, they are confusion free. Many of the properties which make the composition work appear to depend only on confusion freeness.
Our aim on the long term is to see confusion free event structures as a gen- eralization of strategies (i.e. as morphisms), and the composition of such event structures as strategies composition. The machine we introduce in this paper al- lows us a common presentation of composition. In further work [5] we develop the game semantical structures.

Background
A sketch of strategies composition
In Game Semantics, the execution of a program is modelled as interaction between two players; let us call them P (Proponent) and O (Opponent). The role of a strategy is to tell the player how to respond to a counter-player move. The dialogue between the two players will produce an interaction (a play).
Figure 1 presents a simplified example of two (sequential) strategies. A specific move is played by (belongs to) only one of the players, so there are P-moves and O-moves. The active (positive) move of P are those that P plays, while its passive (negative) moves are those played by O, and to which P has to respond. In the picture, for each player strategy we distinguish the actives (positive) moves, i.e. those which belong to that player, with circles.
Let us look at the strategies (1). According to the P-player strategy, it will start with b0, then respond with a0 to Opponent move b1, and with † (termination) to Opponent move b2. Let us make it interact with the O-player strategy. The interaction goes as follows: O answer to b0 is b1, P answer to b1 is a0, O answer to



Tree strategies (1):
P-player:	O-player:
Tree strategies (2):
P-player:	O-player:





a1

†

b1	b2

.
b3



a0	b0


b1
†

b2


a1



b3

.
a0	b0



Interaction (1):
b0b1a0a1b3 ... b2†
Interaction (2):
a0a1b0 ... b1b3b2†
Fig. 1. Tree strategies

a0 is a1, and so on.
The algorithm to calculate the interaction is simple. (i.) Start from P-player initial move, (ii.) Check counter-player answer to that move, that is, go to the corresponding opposite action, and take the following move. (iii.) Repeat step (ii.) until terminating on †.
Figure 2 illustrates the same ideas for more parallel strategies [4].

Interaction :
†
b2
b3
a1	b1	.
a0	b0

Fig. 2. Graph strategies

The strategies are here graphs. The way to make them interact is similar to the previous one, but (1.) there are several threads running in parallel, (2.) on certain moves we need to synchronize.

Event structures
Let (E, ≤) be a partially ordered set. Elements of E are called events; we assume that E is at most countable. The order relation is called causality relation. The downward closure of a subset S ⊆ E is defined by [S| = {e' : e' ≤ e, e ∈ S}. For a singleton, we write [e|.

An event structure 4 is a triple (E, ≤, ×) such that
(E, ≤) is a partial order, as above;
For every e ∈ E, [e| is finite.
× is an irreflexive and symmetric relation, called conflict relation, which satisfies the following:
for every e1, e2, e3 ∈ E, if e1 ≤ e2 and e1 × e3 then e2 × e3.
If e1 ≤ e2 we say that the conflict e2 × e3 is inherited from the conflict e1 × e3.
If a conflict is not inherited, we say that it is immediate, written ×μ
Causal order and conflict are mutually exclusive.
With a slight abuse of notations, we identify an event structure (E, ≤, ×) and its set E of events.
[e)= [e|\{e} is the enabling set of e; Parents(e) will denotes the set of immediate predecessors of e (the preconditions of that event).
A labelled event structure is an event structure E together with a labelling function λ : E → L, where L is a set of labels.
A set S ⊆ E is conflict free if it does not contain any two elements in conflict; in particular, an event structure E is conflict free if its conflict relation is empty. Hence, a conflict free event structure is simply a partial order. Observe that, if e ∈ E, then [e| is conflict free.

Confusion free event structures
Confusion free event structures are a class of event structures where every choice is localized to cells, where a cell is a set of events that are pairwise in immediate conflict, and have the same enabling set.
Definition 2.1 A cell c is a maximal set of events such that e, e' ∈ c implies
e ×m e' and [e)= [e').
Definition 2.2 E is confusion free if the following holds:
(a.) for all distinct e, e', e'' ∈ E, e ×μ e' and e' ×μ e'' implies e ×μ e''
(b.) for all e, e' ∈ E,e ×μ e' implies [e)= [e')
The notion of cell express the idea that choices are local.

Example.
Below, we give an example (1.) of event structure which is confusion free, and an example (2.) of an event structure which is not. Waved lines denote conflict. The event structure in (2.) is not confusion free because t4 is in conflict with t2, t3, but fails to have the same parents.

4 In this paper we say event structures always meaning prime event structures.

(1.) Confusion free:	(2.) Confused state:


Well-labelled event structures
In this section we introduce a notion of well-labelled event structure, where the labelling guarantees that the composition of confusion free event structures is a confusion free event structure.
Our labelling can be seen as a minimalist variant of the typing in [17], without the whole setting of linear types and morphisms; this because here we are only interested in the preservation of confusion freeness via composition. The labelling we use is also a straightforward generalization of the technique developed in [8] to deal with additive strategies.
A key features of the labelling is that a name identiﬁes a cell (rather than a single event).

Names and actions.
We assume a countable set of names N , ranged over by α, β,.   We are going to
label a confusion free event structure with actions on these names. Let S be an index set. We define the alphabet 𝒩 as follows:
𝒩 = Σ Ni = {(α, i): α ∈ N and i ∈ S}
i∈S

We say that a = (α, i) uses the name α, and write name(a)= α.
A (polarized) action is given by an element a ∈ 𝒩 and a polarity, which can be positive (a+), negative (a−), or neutral (a±). Polarities correspond to one of the three main capabilities which a name (channel) can have: input (−), output (+), or match (±).
Remark 3.1 Actions of opposite polarity (a+, a−) denote matching dual actions, such as c and c in CCS, or Player/Opponent moves in Game Semantics.
We think of a± as a pair of matching actions a+, a− which have synchronized.
A more traditional and suggestive denotation for a± would be τa.
We use the variable ϵ to vary over polarities: ϵ ∈ {+, −, ±}. When clear from the context, or not relevant, we omit the explicit indication of the polarity. The polarities + and − are said opposite. If a is a positive or negative action, a will denote its opposite action.

Interfaces.
We are going to type event structures with an interface. The interface provides in particular the set of names on which the event structure communicate, and their polarity.
An interface (A, πA) is given by a finite set of names A, and a polarity (positive, negative, neutral) for each name. The polarization partitions A into three disjoint sets: positive, negative and neutral names.
Remark 3.2 The positive names can be thought of as sending, the negative name as receiving, and the neutral names as private.
The interface (A, π) generates the set of actions ffi = Σi∈S Ai = {(α, i): α ∈ A}.
The polarization of the names extends to the actions with that name.

Well-Labelled event structures.
An event structure of interface A is a tuple (S, A, λ, π) where
S is an event structure;
A = (A, πA) is an interface;
λ : S → {(α, i): α ∈ A, i ∈ S} is a labelling function;
π : S → {+, −, ±} is the polarization induced on the actions by πA.
If λ(e)= (α, i), we say that the event e uses the name α, and write name(e)= α.
Remark 3.3 If λ(e)= a, with a = (α, i), and πA(α)= ϵ, then e is labelled by the action aє.
A well-labelled event structure is guaranteed to be confusion free. We ask that:
(i) all the events in the same cell use the same name (and hence also have the same polarity); (ii) two events which use the same name (and the same polarity) are in conflict.
Definition 3.4 An event structure S of interface A is well-labelled, written S : A
if it satisfies the following, for all distinct e1, e2 ∈ S.
if e1 ×μ e2 and λ(e1)= (α, i), then λ(e2)= (α, j), with i /= j.
if name(e1)= name(e2)then e1 × e2.
e1 ×μ e2 ⇒ Parents(e1)= Parents(e2)

Properties of the labelling
S is well-labelled iff and only if it is confusion free.
Each event e ∈ S is uniquely identified by the set of labels λ[e| = {λe', e' ≤ e}.
Proposition 3.5 Given e1 /= e2 ∈ S, we have that λ[e1| /= λ[e2|
The conflict relation in well-labelled event structures can be inferred from the labels:

Proposition 3.6 Let S : A a well-labelled event structure and let e1, e2 ∈ S. Then the following holds:
(∗∗)	e1 × e2 ⇐⇒ ∃e' ≤ e1, e' ≤ e2 : name(e' )= name(e' )
1	2	1	2
Since in a well-labelled event structure the labels carry all the information on the conflict relation, from now on, we deal with the conflict implicitly: two distinct events e1 and e2 are in conflict iff (**) holds.
This allows us to focus only on the partial order. It is easy to see that
Proposition 3.7 Given e1 /= e2 ∈ S : A, we have that e1 ×μ e2 iff
e1, e2 use the same name
[e1)= [e2)
3.4.1  Well-Labelled event structures as dag’s
As seen in the previous section, given a well-labelled event structure, we can deal with the conflict implicitly; we are left to deal only with the partial order S, ≤.
In the following, it will be convenient to identify the partial order on S : A with the associated dag. This in particular allows us to describe composition in terms of graph rewriting.
A directed acyclic graph (dag) G is an oriented graph without (oriented) cycles. We will write c ← b if there is an edge from b to c. It is standard to represent a strict partial order as a dag, where we have a (non transitive) edge a ← b whenever there is no c such that a < c and c < b. Conversely (the transitive closure of) a dag is a strict partial order on the nodes.
In the following, we will identify the partial order on S : A with the associated dag. We take as canonical representative of S its skeleton (the minimal graph whose transitive closure is the same as that of S).
Remark 3.8 Observe that, by construction, the skeleton is always deﬁned, even if S can have a countable number of events (in particular, a cell can have a countable number of events). In fact, for each event e ∈ S, [e| does not contain any conflict, and it is ﬁnite.

Composition
We define composition “operationally”, in such a way that when restricted to strate- gies this procedure produces strategies composition.
Composition between event structures relies on two notions: synchronization and enabling (reachability). Intuitively, to compose, we synchronize (match) events which are labelled by the same action, and opposite polarity. The synchronization is possible only between events which have been enabled. We enable (reach) an action only if all the actions before it have been enabled (reached). We better illustrate this in Section 4.2.

Compatible interfaces
We compose two event structures when their interfaces are able to communicate.
Definition 4.1 [Compatible interfaces] Let (A, πA) and (C, πC ) be two interfaces.
The interfaces A and C are compatible if
for all b ∈ A ∩ C, the polarity of b in A is opposite to the polarity of b in C.
If the interfaces are compatible, we define their composition A ⊙ C = (A ∪ C, π) where π(α) is ± if α ∈ A ∩ C, and otherwise as originally in A or C.
Definition 4.2 Given two compatible interfaces A, C, we say that the name α is
private if α ∈ A ∩ C, public otherwise.
Example. If A = {a−, b+} and C = {b−, c+}, then A ⊙ C = {a−, c+, b±}. The name b is private, while the names a, c are public.
Composition is only defined on event structures which have compatible inter- faces.
Conflict free composition
Let us first analyze composition in the case of conflict free event structures, i.e. when no two events are in conflict. This case is very simple and clear, but contains all the dynamics of the general case.
The key property of this case is the following
If S : A is conflict free, no two events use the same name.
Through this section, let us assume that S1 : A and S2 : C are conflict free and have compatible interfaces. Their composition S1  S2 is a conflict free event structure of interface A ⊙ C.
Let us describe the composition by means of a wave of tokens travelling up on S1 S2. When a private action is reached, to continue, it is necessary to synchronize it with an action of opposite polarity. Observe that, by construction, there is at most one such action.
Remark 4.3 In S1  S2 there is only one occurrence of each polarized action. For this reason, in this section, we can identify each event with the polarized action which labels it.
	If a is public, and its parents have been enabled, then a is enabled. We illustrate this in the picture below, where the squares mark the enabled nodes.

a	~


If a is private, a+, a− are both present, and their parents have been enabled, then a is enabled, and the graph is transformed as follows:


	
a	a	~

end: The actions which have not been enabled are deleted (garbage collection).
The process above generates a new conflict free event structure (E, ≤), where E is a set of events labelled by the actions which have been enabled; the actions have the polarity induced by the new interface A ⊙ C.

Local rewriting rules
The process described in Section 4.2 can be expressed by means of a set of local graph rewriting rules on S, which we describe in Figure 3.
Private a:
There are a, a, parallel

a	a	~	τa



Otherwise:

~
a


Fig. 3. Graph Rewriting Rules

It is straightforward to show these rules are confluent. By using this fact, one can prove associativity for the composition.
Proposition 4.4 (Associativity) Let S1 : A, S2 : C, S3 : D be conflict free event structures. If the interfaces allow the composition, we have that
(S1  S2)  S3 = S1  (S2  S3)

Reducing composition to conflict free composition
A confusion free event structures S can be seen as a superposition of conflict-free event structures (which we call the slices of S). The study of confusion free event structures can be reduced to the study of conflict free event structures. In particular, composition of confusion free event structure can be reduced to the composition of its slices.

Slices
A slice S of S is a downward closed, conflict free subset of S, with the order induced by S. To choose a (maximal) slice of S corresponds to the selection of a single element in each cell of S.
Studying composition by slices
A key feature of the composition is that it takes place independently inside each single slices (Proposition 4.8) .
Several interesting properties of the composition of two event structures (such as confluence, or deadlocks) can be analyzed as properties of their slices (see 4.7).
Actually, following an approach which is well studied for proof nets and linear strategies, the process of composition itself could be reduced purely to conflict free composition:
decompose S into its slices
compose all slices pairwise
superpose the composed slices
Proposition 3.5 allows us to perform the superposition, by using the same technique developed in [8,4].
We do not give details here; however, after providing a direct description of composition in the general case, we show that the study of the composition can be reduced to the study of conflict free composition (Proposition 4.8).
Global composition
In this section, we provide a direct description of composition of well-labelled event structures, in the general case. The machine generates S = S1  S2 step by step; each time we add to S an event v which refers to [comes from] an event (or a pair of matching events) x in S1  S2. We add v to S only if:
the enabling set of x has already an “image” in S;
this image is conflict free.
Given a labelled event structure S, and a set of events S ⊆ S, we use the notation
λS = {λ(s)|s ∈ S}.
Let S1 : A and S2 : C be well-labelled event structures with compatible inter- faces. S1  S2 is an event structure of interface A ⊙ C, obtained as follows.
Case 1. Let e ∈ Si such that λ(e)= a and name(a) is public.
If S ⊆ S satisfies the following conditions:
parent condition: λS = λ[e).
conflict condition: the set S is conflict free add to S an event v such that
label: λ(v)= a
edges: for all vi ∈ [S| we have vi ← v

Case 2. Let e1 ∈ S1 and e2 ∈ S2 such that λ(e1) = λ(e2) = b and name(b) is private.
If S = S1 ∪ S2 where S1, S2 ⊆ S satisfy the following conditions
parent condition: λS1 = λ[e1), λS2 = λ[e2).
conflict condition: the set S is conflict free add to S an event v such that
label: λ(v)= b (this should be thought as τb, since π(b)= ± )
edges: for all vi ∈ [S| we have vi ← v
The parent condition checks that the enabling set of e ∈ Si has been considered, and relies on Proposition 3.5.
The conflict condition says that in [S| there are no two events using the same names (we are using Proposition 3.6. ) To understand the conflict condition, remember that events in conflict are events which are mutually exclusive. If we need a set of precondition to occur together, they must live in a conflict free event structure S ⊆ S.
The conflict condition, essentially guarantees that we are working slice by slice,
i.e. independently in each slice (see Proposition 4.8)
Example of composition
Consider the following event structures


e3	e6


e1
e2	e5


E1	E2

Here we run the machine:



E1 E2


v5  c1	v6  c1
∅




e1 ∈ E1
name(λ(e1 )) ∈ A

v3  τb

v4  τb

S = ∅



v1
v1	a1	a2
e6 ∈ E1	v2
name(λ(e6 )) ∈ C
S = {v2 , v4 }
v5	c1


e2 ∈ E1 name(λ(e2 )) ∈ A S = ∅


v3  τb


v4	τb




v1	v2

name(λ(v1 )= name(λ(v2 ))
e3 ∈ E1 e5 ∈ E2 λ(e3 )= λ(e5 )= b1 S1 = {v1 } S2 = ∅
v3
τb
e4 ∈ E1 e5 ∈ E2
a1	a2
v1	v2
e6 ∈ E1
name(λ(e6 )) ∈ C
S = {v3 , v1 }
v3	v4
τb	τb


a1	a2
v1	v2
λ(e4 )= λ(e5 )= b1
S1 = {v2 } S2 = ∅
a1	a2
v1	v2


Composition is well deﬁned and associative
Composition of well-labelled event structures produces a well-labelled event structure. Moreover, composition is associative.

Theorem 4.5 S1  S2 : A ⊙ C
Proof. W.r.t. definition 3.4, conditions 1. and 2. (the properties of the labelling) hold by construction. We have to verify 3., i.e. that u ×μ v implies [v) = [v). Let Su, Sv the two subset of the labelled parent condition. [u)= [v) if and only if Su = Sv. By labelling we have that name(λ(u)) = name(λ(v)) public or private. We develop the public case: the other is analogous. Without loss of generality we can assume name(λ(u)) ∈ A. Hence there exists e, d ∈ S1 such that λSu = λ[e) and λSv = λ[e). We have that e ×μ d: this holds (by 1. and 2.) and this conflict cannot be inherited because otherwise also u × v should be inherited. Hence we have λSu = λSv by confusion freeness of S1 and as immediate consequence of Proposition 3.5, we have Su = Sv, as required.	 
Remark 4.6 As a consequence, composition of confusion free event structures is confusion free.
Proposition 4.7 (Associativity) Given S1 : A, S2 : C, S3 : D, if the interfaces allow the composition, we have that
(S1  S2)  S3 = S1  (S2  S3)

Proof. The result follows from Proposition 4.4 and Proposition 4.8.	 

Working by slices
Proposition 4.8 (Slices) Let S = S1 : A  S2 : C. We have the following.
If S ⊆ S is a slice of S, then there exist two slices S1 ⊆ S1 and S2 ⊆ S2 such that
S = S1 : A  S2 : C.
If S1 ⊆ S1 and S2 ⊆ S2 are slices, then S = S1  S2 is a slice of S.
By reducing composition to composition of conflict free event structures, we can easily prove associativity.

Discussion
Relating with standard event structure composition
The abstract machine we have defined produces the same result as a “standard” approach to event structure composition. To do this, we choose a specific synchro- nization algebra, which is that defined in [17].
The typing defined by Varacca and Yoshida guarantees that the composition preserves confusion freeness, and allows the interpretation of a linear fragment of the π calculus.
The labelling induced by their typing is easily seen as a case of the labelling we define here, hence in particular we can apply our machine.
We have that
Proposition 5.1 If S1, S2 are confusion free event structures which are typed in the sense of [17], they are also well-labelled in the sense deﬁned here, and their composition S1  S2 as deﬁned here is isomorph to the parallel composition as deﬁned in [17].
The details are given in [15].
Let as briefly resume the “standard approach”.
Parallel composition of event structures
A more standard definition for the parallel composition of event structures is that used [17], based on the following ingredients:
fix through a synchronization algebra the events which will synchronize and those which will not. Two events synchronize if they have dual labels (for example one event has label a and the other a);
build the categorical product of the event structures
discard some events, and everything above them:
discard all the events of the product which are generated from pair which are not able to synchronize because they do not have matching labels
discard all the events of the product which are generated from a single private event: these are events which are private but not “consumed”.

Linear strategies with parallel composition are a sub-class of well-labelled event structures
Linear strategies as introduced in [8] and extended to dag’s in [4] are labelled dag’s. The labels are taken in

Σ

i∈Pfin(N)
Ni = {(α, i): α ∈ N and i ∈ Pfin(N)}

where N are the strings of natural numbers.
The labelling satisfies a certain discipline, which in particular satisfies all the constraints in Definition 3.4.
As for composition, the machine introduced here extends the LAM machine defined in [3,4] to implement the composition of linear strategies. The new machine has the same behaviour of the LAM when restricted to strategies. This in particular means that there is a morphism from strategies to well-labelled event structures, which preserves the parallel composition.
More precisely, strategies composition decomposes into parallel composition plus hiding, where parallel composition is the operation we have described here, and the hiding concerns the τ actions.
Bridging Game Semantics and event structures.
Our aim is to use event structure as a guide to generalize the definition of strategies. First results in this directions are presented in [5], which builds on the machine we introduce here, and extends it to a typed setting.
On the long term, we hope to build on the body of work on event structures to extend the approach of Game Semantics to concurrency, and in particular to deal with non determinism and process calculi.
The dynamics
The machine we have presented makes it immediate what is going on when compos- ing two labelled event structures S1, S2: we merge together the structure (events, order and conflicts) of S1, S2 to create a new event structure S. The dynamics appears the same as that which takes place when composing strategies, λ-terms or Linear Logic proof-nets.
Event structures and proof-nets
This work meet also another line of research, which is bringing together graph strategies and proof-nets. Proof-nets are a graph representation of proofs intro- duced by Girard in Linear Logic [7] and which are powerful tool for the analysis of normalization. In particular, they have been a fertile tool in the study of functional programming, in particular for optimization. Observe that proof-net normalization is performed via local rewriting rules.

We see event structures as a form of multiplicative-additive proof-nets, and hope to be able to apply some of the technology developed for proof-nets. For example, a key notion in proof-nets is that of correctness criterion, which states that there are no cyclic path, for a certain definition of path which is sensitive to the polarity of the nodes. The correctness criterion has a crucial role in guaranteeing that the normalization (composition) works, and in fact it guarantees that there are no deadlocks. We intend to investigate if a similar notion could be used on event structure, for an opportune typing, to guarantee that there are no deadlocks.

References
S. Abramsky and P.-A. Mellies. Concurrent games and full completeness. In Proceedings 15th Annual Symposium on Logic in Computer Science, 1999.
P.-L. Curien and C. Faggian. L-nets, strategies and proof-nets. In CSL 05 (Computer Science Logic), LNCS. Springer, 2005.
C. Faggian. Travelling on designs: ludics dynamics. In CSL’02 (Computer Science Logic), volume 2471 of LNCS. Springer Verlag, 2002.
C. Faggian and F. Maurel. Ludics nets, a game model of concurrent interaction. In Proc. of LICS’05 (Logic in Computer Science). IEEE Computer Society Press, 2005.
C. Faggian and M. Piccolo. Event structures and linear strategies. submitted.
Dan R. Ghica and Andrzej S. Murawski. Angelic semantics of fine-grained concurrency. In FOSSACS, 2004.
Jean-Yves Girard. Linear logic. Theoretical Computer Science, 50:1–102, 1987.
Jean-Yves Girard. Locus solum. Mathematical Structures in Computer Science, 11:301–506, 2001.
M. Hyland and A. Schalk. Games on graphs and sequentially realizable functionals. In LICS 02, pages 257–264. IEEE, 2002.
J. Laird. A game semantics of the asynchronous pi-calculus. In Concur 05, volume 3653 of LNCS, 2005.
G. McCusker and M. Wall. Categorical and game semantics for scir. In Galop 2005, pages 157–178, 2005.
P.-A. Mellies. Asynchronous games 2 : The true concurrency of innocence. In CONCUR 04, volume 3170 of LNCS. Springer Verlag, 2004.
K. Honda N. Yoshida and M. Berger. Sequentiality and the pi-calculus. In Proc. of TLCA 2001, the 5th International Conference on Typed Lambda Calculi and Applications, LNCS. Springer, 2001. Extended abstract.
M. Nielsen, G. Plotkin, and G. Winskel. Event structures and domains 1. Theoretical Computer Science, 13:85–108, 1981.
M. Piccolo. Event structures and strategies. Master’s thesis, Dip. Matematica Pura e Applicata, Universit´a di Padova, 2006.
A. Schalk and J.J. Palacios-Perez. Concrete data structures as games. In CTCS 04, volume 122 of
Electr. Notes Theor. Comput. Sci., 2005.
D. Varacca and N. Yoshida. Typed event structures and the pi-calculus. In MFPS, 2006.
