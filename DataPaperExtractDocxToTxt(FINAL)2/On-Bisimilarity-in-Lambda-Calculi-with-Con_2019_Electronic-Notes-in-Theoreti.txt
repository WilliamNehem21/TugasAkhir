Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 347 (2019) 121–141
www.elsevier.com/locate/entcs

On Bisimilarity in Lambda Calculi with Continuous Probabilistic Choice
Ugo Dal Lago2
University of Bologna Bologna, Italy
Francesco Gavazzo3
IMDEA Software Institute Madrid, Spain

Abstract
Applicative bisimiliarity is a coinductively-defined program equivalence in which programs are tested as argument-passing processes. Starting with the seminal work by Abramsky, applicative bisimiliarity has been proved to be a powerful technique for higher-order program equivalence. Recently, applicative bisimiliarity has also been generalised to lambda calculi with algebraic effects, and with discrete probabilistic choice in particular. In this paper, we show that applicative bisimiliarity behaves well in a lambda-calculus in which probabilistic choice is available in a more general form, namely through an operator for sampling of values from continuous distributions. Our main result shows that applicative bisimilarity is sound for contextual equivalence, hence providing a new reasoning principle for higher-order probabilistic languages.
Keywords: Probabilistic Computation, λ-calculus, Continuous Distributions.

Introduction
Program equivalence and refinement are central concepts in program semantics: giving meaning to programs has the positive effect of allowing one to compare pro- grams and to dub them equivalent whenever having the same semantics. But what comes first, the chicken or the egg? After all, any equivalence relation between program phrases implicitly gives meaning to a program through their equivalence class.
Among the many possible notions of program equivalence, Morris’ style contex- tual equivalence [37] has been considered as somehow canonical, being the largest,

1 Thanks to the ANR projects 14CE250005 ELICA and 16CE250011 REPAS.
2 Email: ugo.dallago@unibo.it
3 Email: francesco.gavazzo@gmail.com

https://doi.org/10.1016/j.entcs.2019.09.007 1571-0661/© 2019 Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

and thus coarsest, adequate and compatible relation between programs: by con- struction, one cannot do any better than that when trying to identify programs behaving the same. As such, contextual equivalence is accepted as the reference notion of equivalence in an higher-order scenario. When proving that two programs are actually equivalent, however, the universal quantification over all contexts (i.e. over all program environments) in the definition of contextual equivalence makes the proof burdensome, if not impossible.
This has stimulated the development of alternative techniques for program equiv- alence which, in one way or another, get rid of the aforementioned universal quan- tification. Examples are logical relations [42,54,48], applicative bisimilarity [1], and denotational semantics [52,53]. Traditionally, the first step in studying the nature of these notions of program equivalence consists, again, in proving compatibility and adequacy, from which inclusion in contextual equivalence easily follows. In some cases this comes more or less by definition, while in other cases, like the one of applicative bisimilarity, proofs of compatibility are nontrivial, and are typically carried out in indirect ways, by methodologies like the so-called Howe’s method [21]. Starting from Abramsky’s pioneering work on applicative bisimilarity [1], coinduc- tion has been proved to be a useful methodology for program equivalence in the context of pure λ-calculi.
All these (and others) techniques, give purely functional programming languages a clean semantics which makes it relatively easy to reason about them. Injecting various forms of effects (such as I/O, exceptions, or nondeterminism) complicates the matter considerably. Some of the aforementioned techniques for program equiv- alence have been proved to be remarkably robust in this respect, with contributions ranging from extensions encompassing speciﬁc notions of effect [6,14,29,12,24] to more abstract notions in which effects of a certain kind (e.g. algebraic effects [43,44]) are proved to work well in a given semantic framework [11,20,5,55,23].
One kind of effect which has received a lot of attention recently [56,56], but whose impact to the traditional techniques for program equivalence has been studied only marginally, is continuous probabilistic choice, i.e. the operation of sampling from continuous distributions. This by itself poses a challenge to the definition of an operational semantics, and thus to operationally-based techniques. Concerning the latter, the only contributions the authors are aware of are those by Culpepper et al. [10,61] on logical relations for a probabilistic λ-calculus with continuous distributions and scoring.
In this paper, we show that applicative (bi)simulation remains a sound methodol- ogy for program equivalence and refinement in presence of sampling from continuous distributions. We do it for a λ-calculus endowed with a very liberal recursive type system.
Noticeably, probabilistic bisimulation has been first defined in the abstract set- ting of discrete probabilistic transition systems, also known as labelled Markov chains [28], and later generalised to Markov decision processes [7]. The main tech- nical difficulty one faces when trying to turn probabilistic bisimulation into a notion of equivalence for higher-order programs consists in coming up with a sensible no-

tion of lifting, allowing to turn a relation between programs into a relation between program (sub)distributions [39]: there is a fundamental tension between the prop- erties one typically gets from the aforementioned abstract notions of bisimilarity, and those one needs in the proofs of congruence. This paper shows that there is indeed a point in which the two meet.
The rest of the paper is organised as follows. We begin our analysis with an example of a simple program transformation. Proving correctness of such a trans- formation, however, is nontrivial and requires the design of suitable operational techniques. We then introduce our main vehicle calculus, namely a probabilistic call-by-value λ-calculus with sum and recursive types (Section 2), as well as its operational semantics (Section 2). Section 4 introduces the relational calculus we will use to study notions of program equivalence and refinement. We instanti- ate such a framework to define contextual equivalence and approximation (Section 5), and applicative (bi)simulation (Section 6). We prove soundness of applicative (bi)similarity in Section 6. We conclude this paper with a short discussion on full abstraction (Section 7).

Warming Up
Before entering into the technicalities of our anlaysis, we discuss a simple, yet non- trivial example of program equivalence in presence of continuous distributions. This way, we also introduce some features of the languages we are going to study.
We consider higher-order functional languages enriched with primitives for real- valued (measurable) functions and for sampling from continuous (and discrete) dis- tributions. For instance, the program normal μ σ samples a real number from the normal distribution with mean (encoded by the numeral) μ and standard deviation σ. Similarly, we can write a program poisson μ which samples a real number from the Poisson distribution with rate μ.
We can also take advantage of the higher-order nature of functional languages, and use arbitrary programs eμ, eσ to compute the mean and standard deviation of the normal distribution:
let xμ = eμ in (let xσ = eσ in (normal xμ x2 )).
Notice that eμ, eσ may be defined sampling from other distributions as in:
let xμ = (poisson eλ ) in (let xσ = (poisson eλ ) in (normal xμ x2 )).
1	2	σ
This immediately raises the question of whether the order in which we evaluate (independent) expressions matter. That is, we ask whether the equivalence
let x1 = e1 in (let x2 = e2 in e3) ≡ let x2 = e2 in (let x1 = e1 in e3)
holds, assuming the variable x1 not to be free in e2, and similarity for x2 and e1. Such an equivalence is known as commutativity, and has been studied in [56,57] by

means of denotational methods, and in [10,61] by means of logical relations (in both cases, however, the target language also includes primitives for conditioning).
Let us now look at a more sophisticated example. Consider the following in- stances of the combinators map append, and zipwith:
map : (unit → real) → list(unit) → list(real)
append : list(real) → list(real) → list(real)
zipwith : (real → real) → list(real) → list(real) → list(real)
where map is the usual combinator for mapping functions on lists, append is the usual function for appending lists, and zipwith is a combinator taking as input a binary operation and two lists (which, for the sake of the argument, we assume to have the same length), and returning the list obtained by the pointwise application of the operation to the elements occurring at the same position in both lists. Let now zs be a list of n elements of type unit (we use zs to generate lists of random numbers), and let us write λ.e : unit → real for the thunk of a program e : real. Is the following program transformation, which avoids a (possibly expensive) list traversing correct?
⎛ let xs = map (λ. normal eμ1	) zs ⎞
2


λx.
ys = map (λ. normal eμ2  σ2 ) zs ⎟

⎝ in append x (zipwith (+) xs ys) ⎠

⎛ let xs = map (λ. normal (eμ
+ eμ ) (e2
+ e2
)) zs ⎞

≡ λx. ⎝

in append x xs
1	2	σ1	σ2

Proving the correctness of the above transformation requires to combine de- notational reasoning about probability measures with operational reasoning about program behaviour. On the one hand, the two programs above are values, so that looking at their computational behaviour in isolation is useless: in order to under- stand what these programs do we have to test them against any possible input the environment can pass them (which might have a probabilistic behaviour itself). On the other hand, such programs are somehow related by basic results in statistics (no- tably, given random variables with normal probability distribution X1 ∼ N (μ1, σ2) and X2 ∼ N (μ2, σ2), we have X1 + X2 ∼ N (μ1 + μ2, σ2 + σ2)). As we will see, the
2	1	2
techniques we develop in this paper give a handy proof of correctness of the above
program transformation.
Now that the reader has some insights on the kind of problems we aim to solve in this work, we can start our formal analysis of program equivalence and refinement.
A Calculus with Continuous Probabilities: Syntax
The target language of this work is a probabilistic fine-grain call-by-value [34] with finite sums and recursive types reminiscent of probabilistic PCF [16,40]. The syntax

and static semantics of ΛP is defined in Figure 1.
Types of ΛP are built starting from a countable set of type variables (denoted by the letter α in Figure 1) and the basic type real for real numbers, using finite sum, arrow, and recursive type constructors. In particular, in a type of the form i∈I τi we assume the letter I to stand for a finite set whose elements are denoted by ˆı, jˆ, . . .. We write void and unit for the empty sum type and void → void,
respectively.
Terms of ΛP are divided in two classes: values and expressions (also called computations). Intuitively, a value is the result of a computation, whereas an expression is a value producer, i.e. a term that once evaluated may produce a value (the evaluation process might not terminate) as well as side effects (the latter being probabilistic). Accordingly, computations must be explicitly sequenced by means of the sequencing constructor let x = − in −.
We use judgments of the form Γ ▶Λ e : τ for expressions, and Γ ▶V v : τ for values. In a judgment of the form Γ ▶Λ e : τ (resp. Γ ▶V v : τ ), Γ denotes an environment,
i.e. a finite sequence x1 : τ1,..., xn : τn of distinct variables with associated closed types (we denote by · the empty environment), τ is a closed type, and e (resp. v) is an expression (resp. value) with free variables among Γ. Notice that we work with closed types only. We use the letter e (possibly with sup- and subscripts) to denote expressions, and v (possibly with sup- and subscripts) to denote values. We also refer to sequents Γ ▶Λ τ as computation or expression sequents, and to Γ ▶V τ as value sequents. When the distinction between values and expressions is not relevant, we generically refer to terms.
Each real number r is represented in ΛP by the value r. Additionally, ΛP is parametric with respect to a N-indexed family C of countable sets Cn, each of which contains (symbols for) measurable functions from Rn to R. In particular, we assume standard real-valued arithmetic operations to be in C. We use letters F, G,... to denote elements in Cn. Notice that a function F ∈ Cn has values as arguments, rather than expressions. Indeed, we can encode the expression F (e1,..., en) as 4 let x1 = e1 in (let x2 = e2 in ... (let xn = en in F (x1,..., xn))).
Finally, the expression sample stands for the uniform distribution over the unit interval, which is nothing but the Lebesgue measure λ on [0, 1]. As it is shown in e.g. [40,16], starting from sample it is possible to define several probabilistic measures (e.g. binomial, geometric, and exponential distribution) using functions in C.

Example 2.1 Given closed terms eμ, eσ of type real (encoding mean μ and stan- dard deviation σ) we represent the normal distribution with mean μ and standard deviation σ as the ΛP expression normal eμ eσ, where the term normalstd encodes the normal distribution with mean 0 and standard deviation 1. Notice that the


4 This encoding reflects the standard semantics of operations, where to evaluate an expression of the form
F (e1,..., en) one first sequentially evaluates its arguments, proceeding from left to right.

expressions eμ, eσ may be themselves defined in terms of other distributions:

normalstd , let x = sample in (let y = sample in (	−2 log(x) cos(2πy)))
normal eμ eσ , let xμ = eμ, xσ = eσ,y = normalstd in ((xσ ∗ y)+ xμ).
We adopt the standard syntactical conventions as in [3], notably the so-called variable convention. In particular, we denote by FV (e) (resp. FV (v)) the col- lection of free variables of e (resp. v) (notice that, e.g., in a term of the form case v of {fold x → e} the variable x is bound in e). We refer to closed expres- sions as programs. We denote by e[v/x] (resp. vj[v/x]) the capture-free substitution of the value v for all free occurrences of x in e (resp. vj) and identify terms up to renaming of bound variables. We extend the aforementioned conventions to types. For instance, we denote by τ1[τ2/α] the result of capture-avoiding substitution of the type τ2 for the type variable α in τ1. Finally, we use the notation Λ and V to denote the collections of all typable expressions and values, respectively.



	 Γ ▶V v : τ
	r ∈ R	 	
Γ ▶V v1 : real  ···  Γ ▶V vn : real  F ∈ Cn

Γ,x : τ ▶V x : τ
Γ ▶Λ v : τ
Γ ▶V r : real  Γ ▶Λ sample : real
Γ ▶Λ F (v1,..., vn): real



Γ,x : τ1 ▶Λ e : τ2
Γ ▶V λx.e : τ1 → τ2
Γ ▶V v1 : τ1 → τ2  Γ ▶V v2 : τ2
Γ ▶Λ v1v2 : τ2
Γ ▶Λ e1 : τ1  Γ,x : τ1 ▶Λ e2 : τ2
Γ ▶Λ let x = e1 in e2 : τ2
Γ ▶V v : τˆı
Γ ▶V ⟨ˆı, v⟩ : Σi∈I τi

Γ ▶V v :	i∈I τi  Γ,x : τi ▶Λ ei : τ (∀i ∈ I) Γ ▶Λ case v of {⟨i, x⟩ → ei} : τ
Γ ▶V v : τ [μα.τ/α] Γ ▶V fold v : μα.τ
Γ ▶V v : μα.τ1  Γ,x : τ1[μα.τ1/α] ▶Λ e : τ2
Γ ▶Λ case v of {fold x → e} : τ2



Fig. 1. Static semantics of ΛP.

A Calculus with Continuous Probabilities: Semantics
The dynamic semantics of ΛP is given by a type-indexed family of evaluation func- tions J−)τ mapping programs of type τ to sub-probability measures over values of type τ . The collection of such measures can be abstractly described using the sub-Giry monad G [18], so that the evaluation function J−)τ will map a program e ∈ Λτ to a sub-probability measure Je)τ ∈ G(Vτ ). Additionally, since GX carries a measurable space structure whenever X does, we would like J−)τ to be a measurable function. For that to make sense, however, we first need to make Λ a measurable space itself. We follow [57,50,16] and rely on the measurable space structure of Rn and coproducts in Meas, the category of measurable spaces 5 . Before entering into the details we recall some useful mathematical preliminaries.
Mathematical Preliminaries: Stochastic Kernels and the Giry Monad
In this section we recall some mathematical preliminaries which are needed in order to give ΛP dynamic semantics. Unfortunately, there is no hope to be comprehensive,

5 Another approach is given in [8], where the set of terms inherits a measurable structure from a syntax- oriented metric.

and thus we assume the reader to be familiar with basic measure theory [45], domain theory [2], and category theory [35].
We denote by Meas the category of measurable spaces and measurable func- tions, by Set the category of sets and functions, and by ωCppo the category of ω-cppo and continuous functions. Given a measurable space (X, ΣX ) with a mea- sure μ on it and a function f : X → [0, ∞], we denote by X f dμ or X f (x)μ(dx) the number in [0, ∞] obtained by Lebesgue integrating f over X with respect to μ (when clear from the context, we will omit the subscript X).
In order to deal with nontermination, we work with sub-probability distributions rather than with full distributions. For instance, the measure JΩ) associated to the purely divergent expression Ω will naturally assign 0 to any measurable sets of values. Mathematically, this means working with the sub-Giry monad rather than with the (full) Giry monad.
Definition 3.1 The sub-Giry functor G : Meas → Meas maps a measurable space (X, ΣX ) to (GX, ΣGX ), where GX is the set of all sub-probability measures on X, and ΣGX is the least σ-algebra making the ΣX -indexed family of maps evalA : G(X) → [0, 1], defined by evalA(ν) = ν(A), measurable. Measurable functions f : X → Y are mapped to Gf : GX → GY , where (Gf )(ν) ∈ GX = ν(f−1(−)).

The functor G carries a monad structure, with unit ηX : X → GX given by Dirac measures (recall that for any x ∈ X, the Dirac measure δx on X is defined as δx(A)=1 if x ∈ A, and δx(A) = 0, otherwise), and multiplication μX : GGX → GX defined as μ (M )(A)=   eval (x)M (dx), for A ∈ Σ . Equivalently, we can use G to build a Kleisli triple [35] defining 6 f†(ν)(B)=  f (x)(B)ν(dx), for f : X → GY . Actually, Fubini’s Theorem implies that G has the structure of a commutative monad, with double strength dstX,Y : GX × GY → G(X × Y ) mapping measures μ ∈ GX, ν ∈ GY to their product measure μ ⊗ ν.
A measurable function f : X → GY is also called a (stochastic) kernel [38] from X to Y , as we can uncurry f obtaining a map fj : X × ΣY → [0, 1]. We write Kern for the Kleisli category of G. The category Kern enjoys several nice properties [38]. In particular, the collection of measurable functions from X to GY carries an ω-cppo structure under the pointwise order ± (i.e. f ± g if and only if ∀x ∈
X. ∀A ∈ ΣY . f (x)(A) ≤ g(x)(A)). The bottom element ⊥ is defined as the always zero distribution, whereas the least upper bound of an ω-chain (fn)n≥0 is defined as supn fn. Additionally, the monotone convergence theorem and the very definition o∫f Lebesgue integratio∫n give the following identities:  supn fndν = supn  fndν,
[26]. Finally, we recall that Meas is cartesian (although not cartesian closed) and that Kern has countable coproducts. For a countable family (Xi, ΣXi ) of measurable spaces we denote by  i(Xi, ΣXi ) its coproduct.


6 Notice that the function mapping an element x in X to f (x)(A) ∈ [0, 1] is integrable.

Evaluation Semantics
We define a (type-indexed) map J−)τ : Λτ → G(Vτ ) associating to each program e ∈ Λτ a (sub)probability measure over values in Vτ . We rely on the ωCppo- enrichment of Kern to deal with non-termination.
Definition 3.2 Define the type-indexed family of (N-indexed) maps J−)(n) :Λ →
τ	τ
G(Vτ ) as follows (for readability, we omit type annotations in J−)(n)):
Je)(0)(A)=0 
Jv)(n+1)(A)= δv(A)
JF (r1,..., rn))(n+1)(A)= JF(r1,..., rn))(n)(A)
Jsample)(n+1)(A)= λ{r | r ∈ A}
J(λx.e)v)(n+1)(A)= Je[v/x])(n)(A)
Jlet x = e1 in e2)(n+1)(A)= ∫ Je2[v/x])(n)Je1)(n)(dv)
Jcase ⟨ˆı, v⟩ of {⟨i, x⟩→ ei})(n+1)(A)= Jeˆı[v/x])(n)(A)
Jcase (fold v) of {fold x → e})(n+1)(A)= Je[v/x])(n)(A).
Lemma 3.3 For any type τ and natural number n, the map J−)(n) is a kernel.
Proof. [Sketch] First of all, we notice that for the statement of Lemma 3.3 to make sense, we first need to make Λτ (as well as Vτ ) a measurable space. This can be done as in [16,57], taking advantages of coproducts in Meas. By observing that for

any expression Γ,x : τ1 ▶Λ e : τ2, the map e[−/x] : VΓ▶τ
→ ΛΓ▶τ2
is measurable,

one can easily show J−)(n) to be measurable.	2

Additionally, we see that Je)(n) is actually an ω-chain in G(Vτ
), so that we can

define Je)τ
as supn
Je)(n). In particular, due to ωCppo-enrichment of Kern, we can

replace all the occurrences of J−)(n) in Definition 3.2 with J−). As usual, where
possible we omit type subscripts in J−).
Having defined the operational behaviour of programs, we can finally move to the study of notions of program equivalence and refinement.

Probabilistic Equivalence and Refinement
In the next sections we define notions of program equivalence and refinement for ΛP. Specifically, we introduce (probabilistic) contextual equivalence and approxi- mation, and (probabilistic) applicative (bi)similarity. Our main result states that applicative similarity (resp. bisimilarity) is a sound proof technique for contextual approximation (resp. equivalence).
Studying notions of program equivalence and refinement, it is useful to fix a proper notation and vocabulary for program relations. We do so following [29,19].

Relational Calculus
We use letter R, S, . . . to range over relations and write Rel(X, Y ) for the set of relations over X and Y . We call elements of Rel(X, X) endorelations. Given a relation R ⊆ X × Y and set A ⊆ X, we denote by R[A] the R-image of A, i.e.
{y ∈ Y | ∃x ∈ A. (x, y) ∈ R}. For relations R ⊆ X × Y , S ⊆ Y × Z, we write S ◦ R for their composition, and denote by =X the equality relation on X. As usual, an endorelation R ∈ Rel(X, X) is reflexive if =X ⊆ R, transitive if R ◦ R ⊆ R, and symmetric if RT ⊆ R, where RT denotes the converse or transpose of R. We also recall that Rel(X, X) carries a complete lattice structure with order given by set-theoretic inclusion.
Relational reasoning about programs oftentimes require to reason about open terms. It is thus useful to work with families of relations relating expressions typable within the same sequent. We refer to such (families of) relations as term relations.
Definition 4.1 A term relation R associates to each computation sequent Γ ▶Λ τ (resp. value sequent Γ ▶V τ ) a relation Γ ▶Λ − R − : τ (resp. Γ ▶V − R − : τ ) between its inhabitants.
Formally,	a	term	relation	is	thus	an	element	in	the	set	Rel	= Γ▶τ Rel(ΛΓ▶τ , ΛΓ▶τ )×Rel(VΓ▶τ , VΓ▶τ ). The latter inherits a complete lattice struc- ture from Rel(ΛΓ▶τ , ΛΓ▶τ ) and Rel(VΓ▶τ , VΓ▶τ ) pointwise, this way allowing one to define term relations both inductively and coinductively. Concerning notation, we
write R ⊆ S if:
∀Γ, e1, e2. Γ ▶Λ e1 R e2 =⇒ Γ ▶Λ e1 S e2,  ∀Γ, v1, v2. Γ ▶V v1 R v2 =⇒ Γ ▶V v1 S v2.
Example 4.2 The identity term relation is defined by the (0-ary) rules: Γ ▶Λ
e =Λ e : τ , Γ ▶V v =V v : τ . Given term relations R, S, we define S ◦ R as follows:

Γ ▶Λ e1 R e2 : τ	Γ ▶Λ e2 S e3 : τ


Γ ▶Λ e1 (S ◦ R) e3 : τ
Γ ▶V v1 R v2 : τ	Γ ▶V v2 S v3 : τ
Γ ▶V v1 (S ◦ R) v3 : τ

The notions of a preorder and equivalence term relation are defined as usual. In fact, we say that a term relation R is reflexive if = ⊆ R, transitive if R ◦ R ⊆ R, and symmetric if RT ⊆ R (where RT is defined in the obvious way).
Oftentimes we will be interested in defining relations between programs only. We denote by Rel0 the subspace  τ Rel(Λτ , Λτ ) × Rel(Vτ , Vτ ) of Rel, and refer to its elements as closed term relations. Every closed term relation R ∈ Rel0 induces a term relation, called the open extension of R, as follows: given Γ ▶Λ e : τ , let γ range over closed substitutions for Γ (i.e. for any variable (xi : τi) ∈ Γ, γ(xi) ∈ Vτi ). Define:
Γ ▶Λ e1 R e2 : τ ⇐⇒ ∀γ. · ▶Λ e1γ R e2γ : τ.
A similar definition can be given for values. Given a closed term relation R, we sometimes write (RΛ , RV ) to denote the (type-indexed families of) relations defining its action on expressions and values.

We tacitly require term relations to be closed under weakening, meaning that the following hold.


Γ ▶Λ e1 R e2 : τ

Γ,x : τ j ▶Λ e1 R e2 : τ
Γ ▶V v1 R v2 : τ

Γ,x : τ j ▶V v1 R v2 : τ

Notice that the open extension of a closed relation is indeed closed under weakening. In order to formalise compositional reasoning about program behaviour, we in- troduce the notion of a compatible term relation, i.e. of a term relation closed under
term constructors of ΛP.
Definition 4.3 Given a term relation R, its compatible refinement R is defined by the rules in Figure 2. A term relation R is compatible if R ⊆ R, and a closed term relation is compatible if its open extension is.


Γ ▶V v1 R v2 : τ
Γ,x : τ ▶V x R^ x : τ Γ ▶Λ v1 R^ v2 : τ Γ ▶V r R^ r : real Γ ▶Λ sample R^ sample : real

Γ ▶V v1 R v′ : real  ···  Γ ▶V vn R v′ : real

Γ,x : τ
▶Λ e
R e : τ
Γ ▶V v1 R v′ : τ1 → τ2  Γ ▶V v2 R v′ : τ1

1	n	1	1	2  2	1	2

Γ ▶Λ F (v1,..., vn) R^ F (v′ ,...,v′ ): real
Γ ▶V λx.e1 R^ λx.e2 : τ1 → τ2
Γ ▶Λ v1v2 R^ v′ v′ : τ2

Γ ▶Λ e1 R e′ : τ1  Γ,x : τ1 ▶Λ e2 R e′ : τ2
Γ ▶V v1 R v2 : τˆı
Γ ▶V v1 R v2 : τ [μα.τ/α]

Γ ▶Λ let x = e1 in e2 R^ let x = e′ in e′ : τ2  Γ ▶V ⟨ˆı, v1⟩ R^ ⟨ˆı, v2⟩ : Σ
τi Γ ▶V fold v1 R^ fold v2 : μα.τ

Γ ▶V v R v′ : Σi∈I τi  Γ,x : τi ▶Λ ei R e′ : τ  (∀i ∈ I) Γ ▶Λ case v of {⟨i, x⟩ → ei} R^ case v′ of {⟨i, x⟩ → e′} : τ
Γ ▶V v RV v′ : μα.τ1  Γ,x : τ1[μα.τ1/α] ▶Λ e R e′ : τ2
Γ ▶Λ case v of {fold x → e} R^ case v′ of {fold x → e′} : τ2

Fig. 2. Compatible refinement.
Notice that R^ is indeed a term relation (notably, R^ is closed under weakening).
Definition 4.3 induces a monotone endofuction −^ on Rel which distributes over
composition (S^◦  R = S ◦ R) and transpose (RT = (R)T). In particular, a term relation is compatible if and only if it is a pre-fixed point of −. It is not hard to prove that the identity term relation of Example 4.2 is a pre-fixed point of −, and actually the least such. As a consequence, any compatible relation is reflexive.
Lemma 4.4 The collection of compatible λ-term relations ordered by ⊆ has a com- plete lattice .
Lemma 4.4 allows us to define compatible λ-term relations both inductively and coinductively. Another central notion dealing with term relation is the one of substitutivity.
Definition 4.5  (i) A term relation R is value-substitutive if the following hold:


Γ,x : τ1 ▶Λ e1 R e2 : τ2	· ▶V v : τ1


Γ ▶Λ e1[v/x] R e2[v/x]: τ2
Γ,x : τ1 ▶V v1 R v2	· ▶V v : τ1


Γ ▶V v1[v/x] R v2[v/x]: τ2

(ii) A term relation R is substitutive if the following hold:


Γ,x : τ1 ▶Λ e1 R e2 : τ2	· ▶V v1 R v2 : τ1
Γ ▶Λ e1[v1/x] R e2[v2/x]: τ2
Γ,x : τ1 ▶V u1 R u2 : τ2	· ▶V v1 R v2 : τ1
Γ ▶V u1[v1/x] R u2[v2/x]: τ2
A closed relation is (value) substitutive if its open extension is. Moreover, we notice that the open extension of a closed term relation is trivially value-substitutive.

Contextual Approximation and Equivalence
Contextual equivalence [37] equates programs that behave the same in any possible environment. The notion of an environment is formalised by means of contexts, which are, roughly speaking, terms with a hole to be filled in with the program we aim to test. In order to avoid syntactic bureaucracy, we follow [29,19] and give a property-based definition of contextual equivalence and approximation based on the notion of (pre)adequacy. For readability, from now on we write R for Vreal ∈ Σreal.
Definition 5.1 Given a term relation R, we say that R is preadequate (resp. ade- quate) if:
· ▶Λ e1 R e2 : real =⇒ Je1)(R) ≤ Je2)(R); (resp. · ▶Λ e1 R e2 : real =⇒ Je1)(R)= Je2)(R)).
Definition 5.2 Contextual approximation ≤ctx (resp. contextual equivalence  ctx) is the largest compatible and preadequate (resp. adequate) term relation.
Definition 5.2 is not well-posed, as it is not clear whether such largest term relations exist. In fact, (pre)adequacy is not a monotone property, meaning that we cannot define ≤ctx (resp. ctx) as the greatest fixed point of the (non-monotone) endofuction on Rel induced by Definition 5.2. Nonetheless, we see that the the union of compatible (pre)adequate term relations is itself a compatible (pre)adequate term relation.
Additionally, Definition 5.2 gives a proof principle for contextual approximation (resp. equivalence) resembling a coinduction proof principle. In order to prove that a term relation R is included in ≤ctx (resp. ctx), it is sufficient to show that R is preadequate (resp. adequate) and compatible. Using such a proof principle it is a straightforward exercise to prove that ≤ctx is a precongruence and that ctx is a congruence term relation.
Example 5.3 Contextual equivalence gives the structural equalities in Figure 3, as well the quasi-denotational law: ∀e1, e2 ∈ Λτ . Je1) = Je2) =⇒ · ▶Λ e1  ctx e2 : τ . The quasi-denotational law can be used to export powerful results from measure theory, for instance (we slightly abuse notation by desequencing some computa- tions):

let x1 = (normal eμ1
2 ) in (let x2 = (normal eμ
2 ) in (x1 + x2))

 ctx normal (eμ
+ eμ ) (e2 + e2 )

1	2	σ1	σ2
Combining such laws with the structural equivalences in Figure 3 we can prove non- trivial program equivalences. For instance, recalling the program transformation studied in Section 1.1, we see that contextual equivalence gives correctness of the following program transformation, which avoid a list traversing.

⎛ let xs = map (λ. normal eμ1
e2 ) zs ⎞

, let xs = map (λ. normal (eμ

+ eμ ) (e2 + e2

)) zs

⎜⎝	ys = map (λ. normal eμ2 e2 ) zs ⎟⎠ 
ctx

in append x xs
1	2	σ1	σ2

in append x (zipwith (+) xs ys)
Similarly, we can prove the correctness of the program transformation studied in Section 1.1. Proving such equivalences and laws from first principles, however, is highly non-trivial. We will obtain these results relying on our notion of applicative bisimulation.

(λx.e)v  ctx e[v/x]
let x = v in e  ctx e[v/x]
let x = e1 in e2  ctx e2	(x /∈ FV (e2))
let x = e in (let y = e′ in e′′)  ctx let y = e′ in (let x = e in e′′)	(x /∈ FV (e′),y /∈ FV (e))

Fig. 3. Structural identities.


Applicative (Bi)simulation
Abramsky’s applicative bisimilarity [1] tests programs as argument-passing pro- cesses, i.e. by allowing the environment to interact with a program by passing it arbitrary inputs only. In a probabilistic setting, however, the result of a program is not a value, but a subdistribution of values, meaning that we have to refine the con- ceptual apparatus behind applicative bisimilarity to take into account probabilistic behaviours.
Following [58,22,33], we look at notions of (bi)simulation in terms of relation lifting operations. Suppose we are given a term relation R such that ▶Λ e1 R e2. How should we relate Je1), Je2) ∈ GVτ ? Answering such a question means nothing more than finding a proper way to lift RV to GVτ × GVτ .
Probabilistic Relation Lifting
From an abstract perspective, what we need in order to define applicative (bi)similarity is to find a lifting from Rel(X, Y ) to Rel(GX, GY ). The literature on probabilistic equivalence abounds of such notions of lifting (the interested reader can consult [39] for an overview, and [25] for a more technical treatment). For our purposes, the kind of lifting we are interested in is one that allows applicative (bi)similarity:
To be definable by coinduction;

To be a preorder (resp. equivalence) term relation;
To be a compatible and (pre)adequate term relation, and thus a sound proof technique for contextual approximation/equivalence.
The collection of notions of lifting satisfying these requirements has been identified in [11] with the one of relators or lax extension [4,58].
Unfortunately, finding non-trivial relators for the Giry monad has been proved to be extremely difficult, as the latter lacks some fundamental structural properties (notably, it does not preserve weak pullbacks [39]). Nonetheless, as first argued in [60], restricting the attention from arbitrary binary relations to reflexive endorela- tions allows one to define well-behaved notions of relation lifting for G.
At this point it is instructive to recall the standard notion of relation lifting proposed for G (see, e.g., [25]), and the kind of problems one faces when working with it. We also remark that the notions of lifting we are going to analyse are actually meant to model notions of program refinement, rather than equivalence. In fact, applicative bisimilarity can be defined in terms of applicative similarity, and compatibility of the former follows from compatibility of the latter.
Definition 6.1 Given measurable spaces (X, ΣX ), (Y, ΣY ), and a relation R ⊆ X × Y between them, we define ΓR ⊆ GX × GY as follows: ΓR = {(ν1, ν2) | ∀A ∈ ΣX. ∀B ∈ ΣY . R [A] ⊆ B =⇒ ν1(A) ≤ ν2(B)}.
The map Γ : Rel(X, Y ) → Rel(GX, GY ) satisfies many interesting properties (see e.g. [25]), but fails to satisfy the inclusion ΓS ◦ ΓR ⊆ Γ(S ◦ R), which we refer to as quasi transitivity. Quasi transitivity ensures applicative similarity to be transitive. Most importantly, it is a central ingredient in Howe’s method [21,41], the standard technique used to prove applicative (bi)similarity to be compatible.
A counterexample to quasi transitivity of Γ is given in [25] (Example 4.15), taking advantage of the sets X and Y to be distinct (notably, taking X and Y to be the discrete and indiscrete space over the two-elements set, respectively). However, as we are interested in term relations, we can look at endorelations only. Moreover, as observed in [60], working with reflexive endorelations (which still form a complete lattice), it is possible to refine Γ in such a way to guarantee quasi transitivity.
Definition 6.2 Given a measurable space (X, ΣX ), and a reflexive relation R ⊆ X × X, define ΓR ⊆ GX × GX as follows 7 : ΓR = {(ν1, ν2) | ∀A ∈ ΣX. R [A] ⊆ A =⇒ ν1(A) ≤ ν2(A)}.
Lemma 6.3 Let Rel=(X, X) denote the complete lattice of endorelations on X. Then Γ : Rel=(X, X) → Rel=(GX, GX) satisﬁes the following properties, for all R, S ∈ Rel=(X, X).
=GX ⊆ Γ(=X )		(quasi reflexivity) ΓS ◦ ΓR ⊆ Γ(S ◦ R).	(quasi transitivity) R ⊆ S =⇒ ΓR ⊆ ΓS.			(monotonicity)

7 Notice that R being reflexive, R[A] ⊆ A implies R[A]= A.

The proof of Lemma 6.3 is straightforward. Remarkably, we can give another characterisation of Γ.
Proposition 6.4 Given μ, ν ∈ GX and R ∈ Rel=(X, X), we have:


μ ΓRν ⇐⇒ ∀f : (X, R) −→1
([0, 1], ≤).	f dμ ≤	f dν,
X	X



where f : (X, R) −→1
([0, 1], ≤) means that f is a measurable function (notice that

[0, 1] ∼= G{∗}) such that xR y implies f (x) ≤ f (y).
The proof of Proposition 6.4 goes essentially as in [25] (Proposition 4.4). See also [51]. Using Proposition 6.4 we can show that Γ is well-behaved with respect to the monad structure of G, and thus that it nicely interacts with sequencing (observe that Jlet x = e1 in e2)(A)=  Je2[v/x])(A)Je1)(dv)= Je2[−/x])†Je1)(A)).
Lemma 6.5 Given R ∈ Rel=(X, X), S ∈ Rel=(Y, Y ), and measurable functions
f, g : X → Y , the following hold, for all x, y ∈ X and μ, ν ∈ GX
xR y =⇒ δx ΓR δy	(dirac) (∀x1, x2 ∈ X. x1 R x2 =⇒ f (x1) ΓS g(x2)) =⇒ (μ ΓRν =⇒ f†(μ) ΓS g†(ν))
(bind)
Finally, Γ nicely interacts with the ωCppo-enrichment of G, allowing the fol- lowing induction principle.
Lemma 6.6 For any relation R ∈ Rel=(X, X), any ω-chain (μn)n≥0 in GX, and any ν ∈ GX, if μn ΓRν holds for all n ≥ 0, then supn μn ΓR ν.
We can now rely on Γ to define a suitable notion of applicative (bi)simulation.

Applicative Similarly and Bisimilarity
We are now ready to formally define our notion of an applicative (bi)simulation.
Definition 6.7 A reflexive closed term relation R = (RΛ , RV ) is an applicative simulation if the following conditions hold:
· ▶Λ e1 R e2 : τ =⇒ Je1) ΓRV Je2)	(app eval)
· ▶V r1 R r2 : real =⇒ r1 = r2	(app num)
· ▶V λx.e1 R λx.e2 : τ1 → τ2 =⇒ ∀v ∈ Vτ . · ▶Λ e1[v/x] R e2[v/x]: τ2 (app abs)
· ▶V ⟨ˆı, vˆı⟩ R ⟨jˆ, vjˆ⟩ =⇒ ˆı = jˆ ∧ · ▶V vˆı R vjˆ : τˆı	(app inj)
· ▶V fold v1 R fold v1 : μα.τ =⇒ · ▶V v1 R v2 : τ [μα.τ/α].	(app fold)
Applicative similarity ≤A is defined as the largest applicative simulation, whereas applicative bisimilarity  A is the largest symmetric applicative simulation.

To see that ≤A indeed exists, we define the endofunction [−] on the complete lattice Rel0 as follows:
· ▶Λ e1 [R] e2 ⇐⇒ Je1) ΓRV Je2)
· ▶V r1 [R] r2 : real ⇐⇒ r1 = r2
· ▶V λx.e1 [R] λx.e2 : τ1 → τ2 ⇐⇒ ∀v ∈ Vτ . · ▶Λ e1[v/x] R e2[v/x]: τ2
· ▶V ⟨ˆı, vˆı⟩ [R] ⟨jˆ, vjˆ⟩ ⇐⇒ ˆı = jˆ ∧ · ▶V vˆı R vjˆ : τˆı
· ▶V fold v1 [R] fold v1 : μα.τ ⇐⇒ · ▶V v1 R v2 : τ [μα.τ/α].
We see that R is an applicative simulation if and only if R ⊆ [R]. Besides, Γ being monotone, [−] is monotone as well, and thus it has a greatest fixed point which is
≤A.
Remark 6.8 Notice that we have not required RV ⊆ RΛ for an applicative simula- tion R = (RΛ , RV ). However, it is straightforward to see that given such a simulation R, we can always extend RΛ adding the pairs of values (v1, v2) ∈ RV still obtaining a simulation. This directly follows from condition (dirac). In particular, ≤A ⊆ ≤A .
V	Λ
Applicative similarity being defined coinductively, it comes with an associated coinduction proof principle, which can be formally given as follows:


∃R. R ⊆ [R]	· ▶Λ e1 R e2 : τ


· ▶Λ e1 ≤A e2 : τ
∃R. R ⊆ [R]	· ▶V v1 R v2 : τ


· ▶V v1 ≤A v2 : τ


An easy application of the coinduction proof principle allows us to prove ≤A to be a preorder term relation.
Lemma 6.9 Applicative similarity is reflexive and transitive.
Proof. [Sketch] By coinduction, relying on the properties (quasi reflexivity) and (quasi transitivity).	2
Additionally, we see that A = ≤A ∩ (≤A)T, so that A is an equivalence term relation. In order to ensure compositionality, we need to prove ≤A and A to be compatible term relations. We first prove that applicative similarity is compatible,
i.e. ≤A ⊆ ≤A. To achieve such a goal, we use Howe’s technique [21,41].
Definition 6.10 Given a closed term relation R, the Howe extension of R is the term relation RH defined as the least solution to the equation:
ρ = Ro ◦ ρ,
where Ro denotes the open extension of R. Such a solution exists, since both −o and − are monotone endofunctions. More explicitly, we can inductively define RH by:


Γ ▶Λ e1 RH e3 : τ	Γ ▶Λ e3 R e2 : τ


Γ ▶Λ e1 RH e2 : τ
Γ ▶V v1 RH v3 : τ	Γ ▶V v3 R v2 : τ


Γ ▶V v1 RH v2 : τ

Notice that RH is not only the least solution to the equation ρ = Ro ◦ ρ, but actually to the inclusion Ro ◦ ρ ⊆ ρ [29,32]. The Howe extension of a reflexive and transitive (closed) term relation enjoys several interesting properties. In particular, it is a reflexive, compatible, and substitutive term relation.
Lemma 6.11 Let R be reflexive and transitive closed term relation. Then the fol- lowing hold:
Ro ⊆ RH.
Ro ◦ RH ⊆ RH
RH is compatible, and thus reflexive.
RH is substitutive.
The proof of Lemma 6.11 is standard, and the reader is referred to [41,29] for details. We are finally ready to prove our first main result, namely that applicative similarity is a precongruence term relation. To achieve such a goal, we prove that (≤A)H (restricted to closed terms) is an applicative simulation, and it is thus con- tained in ≤A. Since by Lemma 6.11 we have the opposite inclusion, we will conclude (≤A)H = ≤A.
Lemma 6.12 (Key Lemma) Given a reflexive and transitive closed term relation R, if R is an applicative simulation, then so is RH (restricted to closed expressions and values).
Proof. [Sketch] By Lemma 6.11, RH is reflexive, and thus a possible candidate simulation. It is easy to see that RH (restricted to closed values) satisfies conditions (app num)-(app fold). It thus remain to prove (app eval), i.e. · ▶Λ e1 R e2 : τ =⇒ Je1) ΓRH Je2). Since Je1) = supnJe1)(n) we can appeal to Lemma 6.6, and prove the statement: · ▶Λ e1 RH e2 : τ =⇒ ∀n ≥ 0. Je1)(n) ΓRH Je2).
We proceed by induction on n. The base case is trivial. The inductive step is proved by case analysis on the derivation of · ▶Λ e1 RH e2 : τ , which in turn gives a case analysis on RH . A central role is played by the inclusion ΓR ◦ ΓRH ⊆ ΓRH (which directly follows from Lemma 6.11 by monotonicity of Γ). Sequencing is handled as in [11], relying on property (bind), whereas the cases for measurable functions and numerals follows by condition (dirac). All other cases follow by in- duction hypothesis, relying on substitutivity of RH .	2
Theorem 6.13 Applicative similarity is a precongruence term relation and a sound proof technique for contextual approximation.
Proof. It is sufficient to show that ≤A is compatible and preadequate. By Lemma
6.12 and Lemma 6.11 we know that (≤A)H = ≤A when restricted to closed terms. This also holds on arbitrary terms, since (≤A)H is substitutive and, dealing with closed values only, sequential and simultaneous substitution coincide. As a conse- quence, the open extension of applicative similarity coincides with (≤A)H , and thus it is compatible. To see that ≤A is preadequate, simply observe that ≤A [R]= R. 2

Finally, since A = ≤A ∩ (≤A)T, we see that A is compatible and adequate, and thus a sound proof technique for contextual equivalence.

Theorem 6.14 Applicative bisimilarity A is a congruence term relation and a sound proof technique for contextual equivalence.

Finally, we observe that we can use A to prove the equalities and laws in Example 5.3. In particular, the commutativity equation follows by commutativity of G, whereas the soundness of the program transformation of Section 1.1 can be proved combining the quasi-denotational law with congruence properties of A, by passing the two programs an arbitrary value as input.


Digression: Towards Full Abstraction
Theorem 6.14 states that applicative bisimilarity is sound for contextual equivalence: is it also fully abstract (i.e. A = ctx)? In [9] this question is answered in the affirmative for a λ-calculus with sampling from discrete probability distributions. Such a result is proved going through testing equivalence [15,28], showing that tests can be implemented as λ-term contexts (meaning that testing equivalence includes contextual equivalence), on one hand, and that applicative bisimilarity coincides with testing equivalence, on the other hand.
The latter result has been proved in full generality in [60] relying on nontrivial results from domain theory, category theory, and measurable space theory. Re- markably, the equivalence between bisimilarity and testing equivalence holds not only for Markov chains, but also Markov processes, hence suggesting the possibility of proving full abstraction of applicative bisimilarity also in the continuous case. In fact, it is not hard to see that the operational semantics of ΛP induces a (labelled) Markov process on terms, so that one naturally obtains notions of bisimilarity and testing equivalence for it. However, there is a fundamental difference between such a Markov process and the ones studied in [60]. The former has uncountably many labels, whereas the latter requires the of labels to be countable.
Indeed, given a state λx.e of the Markov process, in order to model applicative
bisimulation we need to consider transitions of the form λx.e −→v  e[v/x], meaning
that the set of labels of the Markov process needs to contain (at least) all closed values, which are uncountably many.
A natural way to fix such a problem is to work with (uncountably many) forms of ‘countable’ bisimilarity relations  A , where E is a countable set of labels of
E
A	A	A
to be well-behaved, however, turns out to be highly nontrivial and to require the (abstract) identity Γ( i∈I Ri)= i∈I ΓR. Up to this point, the authors do not know whether such an identity holds, and leave further investigations on full abstraction as future work.

Conclusion
In this paper, we gave a notion of applicative bisimilarity for higher-order languages endowed with an operator performing sampling from continuous distributions. We proved that applicative bisimilarity is adequate and compatible, and thus sound for contextual equivalence. As far as the authors know, this is the first contribution on coinductive notions of equivalence for continuous probabilistic λ-calculi. We also gave evidence on the effectiveness of the introduced methodology by proving some nontrivial example equivalences. It is also interesting to notice that we can modify our framework to prove soundness of open (also known as normal form) bisimilarity [49,30], along the lines of [27] (although we should remark that ‘standard’ open bisimilarity is not very well-suited for typed languages [31]).

Related Work
Higher-order programming languages featuring sampling from continuous dis- tributions have received quite some attention in the last ten years, due to their use as idioms for bayesian programming. This has stimulated the study of opera- tional [8,46,40] and denotational [56,57,16,59] kinds of semantics for these languages. Recently, contextual equivalence and logical relations have been introduced and proved to coincide both in presence and in absence of full recursion by Culpepper et al. [10,61]. Such logical relations require to test programs against any possible evaluation context, a feature reflected by their characterisation as CIU equivalence [36]. This makes reasoning with and about logical relations quite difficult. How- ever, it is important to stress that such logical relations are defined for languages with conditioning (which makes program equivalence and semantics considerably harder), a feature not present in ΛP.

Future Work
A feature which is absent here, but which is desirable in fully-fledged proba- bilistic programming is conditioning, for example as expressed as a form of scor- ing. Coming up with an operational semantics for an extension of our λ-calculus with a scoring operator would be relatively easy, through the notion of s-finite ker- nel [56,57]. The latter, however, seem not to carry a monad structure. A better choice might be to work with the monad G(R∞ × −) associating to each expression a probability measures over (measurable sets of) pairs score-value. However, find- ing a way to compare such measures seems nontrivial. Of course, one can define a

relation lifting for G(R∞
× −) composing Γ with the ‘canonical’ relation lifting for

∞ × −, the latter being nothing but an instance of the output monad. Such a
lifting, however, is too fine-grained, as related values are required to have the same score. A better lifting of a relation R might be obtained requiring the expectations

of the scores in R-closed measurable subsets of R∞
×− to be equal. Proving such

a notion of lifting to be well-behaved is, however, nontrivial.
Finally, a further extension of the present work is the design of behavioural distances for probabilistic languages, possibly along the lines of [47,13,17].

References
Abramsky, S., The lazy lambda calculus, in: D. Turner, editor, Research Topics in Functional Programming (1990), pp. 65–117.
Abramsky, S. and A. Jung, Domain theory, in: Handbook of Logic in Computer Science (1994), pp. 1–168.
Barendregt, H., “The lambda calculus: its syntax and semantics,” Studies in logic and the foundations of mathematics, North-Holland, 1984.
Barr, M., Relational algebras, Lect. Notes Math. 137 (1970), pp. 39–55.
Biernacki, D., M. Piro´g, P. Polesiuk and F. Sieczkowski, Handle with care: relational interpretation of algebraic effects and handlers, PACMPL 2 (2018), pp. 8:1–8:30.
Bizjak, A. and L. Birkedal, Step-indexed logical relations for probability, in: Proc. of FOSSACS 2015, 2015, pp. 279–294.
Blute, R., J. Desharnais, A. Edalat and P. Panangaden, Bisimulation for labelled markov processes, in:
Proc. of LICS, 1997, pp. 149–158.
Borgstr¨om, J., U. D. Lago, A. D. Gordon and M. Szymczak, A lambda-calculus foundation for universal probabilistic programming, in: Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming, ICFP 2016, Nara, Japan, September 18-22, 2016, 2016, pp. 33–46.
Crubill´e, R. and U. Dal Lago, On probabilistic applicative bisimulation and call-by-value lambda-calculi, in: Proc. of ESOP 2014, 2014, pp. 209–228.
Culpepper, R. and A. Cobb, Contextual equivalence for probabilistic programs with continuous random variables and scoring, in: Proceedings of ESOP 2017, 2017, pp. 368–392.
Dal Lago, U., F. Gavazzo and P. Levy, Effectful applicative bisimilarity: Monads, relators, and howe’s method, in: Proc. of LICS 2017, 2017, pp. 1–12.
Dal Lago, U., D. Sangiorgi and M. Alberti, On coinductive equivalences for higher-order probabilistic functional programs, in: Proc. of POPL 2014, 2014, pp. 297–308.
de Amorim, A., M. Gaboardi, J. Hsu, S. Katsumata and I. Cherigui, A semantic account of metric preservation, in: Proc. of POPL 2017, 2017, pp. 545–556.
De Liguoro, U. and A. Piperno, Non deterministic extensions of untyped lambda-calculus, Inf. Comput.
122 (1995), pp. 149–177.
De Nicola, R. and M. Hennessy, Testing equivalence for processes, in: Automata, Languages and Programming, 10th Colloquium, Barcelona, Spain, July 18-22, 1983, Proceedings, 1983, pp. 548–560.
Ehrhard, T., M. Pagani and C. Tasson, Measurable cones and stable, measurable functions: a model for probabilistic higher-order programming, PACMPL 2 (2018), pp. 59:1–59:28.
Gavazzo, F., Quantitative behavioural reasoning for higher-order effectful programs: Applicative distances, in: Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science, LICS 2018, Oxford, UK, July 09-12, 2018, 2018, pp. 452–461.
Giry, M., A categorical approach to probability theory, in: B. Banaschewski, editor, Categorical Aspects of Topology and Analysis (1982), pp. 68–85.
Gordon, A., A tutorial on co-induction and functional programming, in: Workshops in Computing
(1994), pp. 78–95.
Goubault-Larrecq, J., S. Lasota and D. Nowak, Logical relations for monadic types, Mathematical Structures in Computer Science 18 (2008), pp. 1169–1217.
Howe, D., Proving congruence of bisimulation in functional programming languages, Inf. Comput. 124
(1996), pp. 103–112.
Hughes, J. and B. Jacobs, Simulations in coalgebra, Theor. Comput. Sci. 327 (2004), pp. 71–108.
Johann, P., A. Simpson and J. Voigtl¨ander, A generic operational metatheory for algebraic effects, in:
Proc. of LICS 2010 (2010), pp. 209–218.
Jones, C., “Probabilistic non-determinism,” Ph.D. thesis, University of Edinburgh, UK (1990).

Katsumata, S., T. Sato and T. Uustalu, Codensity lifting of monads and its dual, Logical Methods in Computer Science 14 (2018).
Kelly, G. M., Basic concepts of enriched category theory, Reprints in Theory and Applications of Categories (2005), pp. 1–136.
Lago, U. D. and F. Gavazzo, Effectful normal form bisimulation, in: Proc. of ESOP 2019, 2019, to appear.
Larsen, K. G. and A. Skou, Bisimulation through probabilistic testing, in: Proceedings of POPL 1989, 1989, pp. 344–352.
Lassen, S., “Relational Reasoning about Functions and Nondeterminism,” Ph.D. thesis, Dept. of Computer Science, University of Aarhus (1998).
Lassen, S. B., Bisimulation in untyped lambda calculus: B¨ohm trees and bisimulation up to context, Electr. Notes Theor. Comput. Sci. 20 (1999), pp. 346–374.
Lassen, S. B. and P. B. Levy, Typed normal form bisimulation, in: Computer Science Logic, 21st International Workshop, CSL 2007, 16th Annual Conference of the EACSL, Lausanne, Switzerland, September 11-15, 2007, Proceedings, 2007, pp. 283–297.
Levy, P., Infinitary howe’s method, Electr. Notes Theor. Comput. Sci. 164 (2006), pp. 85–104.
Levy, P., Similarity quotients as final coalgebras, in: Proc. of FOSSACS 2011, LNCS 6604, 2011, pp. 27–41.
Levy, P., J. Power and H. Thielecke, Modelling environments in call-by-value programming languages, Inf. Comput. 185 (2003), pp. 182–210.
MacLane, S., “Categories for the Working Mathematician,” Springer-Verlag, 1971.
Mason, I. A. and C. L. Talcott, Equivalence in functional languages with effects, J. Funct. Program. 1
(1991), pp. 287–327.
Morris, J., “Lambda Calculus Models of Programming Languages,” Ph.D. thesis, MIT (1969).
Panangaden, P., The category of markov kernels, Electr. Notes Theor. Comput. Sci. 22 (1999), pp. 171– 187.
Panangaden, P., “Probabilistic bisimulation,” Cambridge Tracts in Theoretical Computer Science, Cambridge University Press, 2011 p. 290–326.
Park, S., F. Pfenning and S. Thrun, A probabilistic language based upon sampling functions, in: Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 2005, Long Beach, California, USA, January 12-14, 2005, 2005, pp. 171–182.
Pitts, A., Howe’s method for higher-order languages, in: D. Sangiorgi and J. Rutten, editors, Advanced Topics in Bisimulation and Coinduction, Cambridge Tracts in Theoretical Computer Science 52, Cambridge University Press, 2011 pp. 197–232.
Plotkin, G., Lambda-definability and logical relations (1973), technical Report SAI-RM-4, School of A.I., University of Edinburgh.
Plotkin, G. D. and J. Power, Adequacy for algebraic effects, in: Proc. of FOSSACS 2001, 2001, pp. 1–24.
Plotkin, G. D. and J. Power, Notions of computation determine monads, in: Proc. of FOSSACS 2002, 2002, pp. 342–356.
Pollard, D., R. Gill and B. Ripley, “A User’s Guide to Measure Theoretic Probability,” Cambridge Series in Statistical and Probabilistic Mathematics, Cambridge University Press, 2002.
Ramsey, N. and A. Pfeffer, Stochastic lambda calculus and monads of probability distributions, in: Proc. of POPL 2002, 2002, pp. 154–165.
Reed, J. and B. Pierce, Distance makes the types grow stronger: a calculus for differential privacy, in:
Proc. of ICFP 2010, 2010, pp. 157–168.
Reynolds, J., Types, abstraction and parametric polymorphism, in: IFIP Congress, 1983, pp. 513–523.
Sangiorgi, D., The lazy lambda calculus in a concurrency scenario, Inf. Comput. 111 (1994), pp. 120– 153.

Sangiorgi, D., N. Kobayashi and E. Sumii, Environmental bisimulations for higher-order languages, ACM Trans. Program. Lang. Syst. 33 (2011), pp. 5:1–5:69.
Sato, T., Approximate relational hoare logic for continuous random samplings, Electr. Notes Theor. Comput. Sci. 325 (2016), pp. 277–298.
Scott, D., Outline of a mathematical theory of computation, Technical Report PRG02, OUCL (1970).
Scott, D. and C. Strachey, Toward a mathematical semantics for computer languages, Technical Report PRG06, OUCL (1971).
Sieber, K., Reasoning about sequential functions via logical relations, in: M. P. Fourman, P. T. Johnstone and A. M. Pitts, editors, Applications of Categories in Computer Science, London Mathematical Society Lecture Note Series 177, Cambridge University Press, 1992 pp. 258–269.
Simpson, A. and N. Voorneveld, Behavioural equivalence via modalities for algebraic effects, in: Proc. of ESOP 2018, 2018, pp. 300–326.
Staton, S., Commutative semantics for probabilistic programming, in: Programming Languages and Systems - 26th European Symposium on Programming, ESOP 2017, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2017, Uppsala, Sweden, April 22-29, 2017, Proceedings, 2017, pp. 855–879.
Staton, S., H. Yang, F. D. Wood, C. Heunen and O. Kammar, Semantics for probabilistic programming: higher-order functions, continuous distributions, and soft constraints, in: Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science, LICS ’16, New York, NY, USA, July 5-8, 2016, 2016, pp. 525–534.
Thijs, A., “Simulation and fixpoint semantics,” Rijksuniversiteit Groningen, 1996.
V´ak´ar, M., O. Kammar and S. Staton, A domain theory for statistical probabilistic programming, PACMPL 3 (2019), pp. 36:1–36:29.
Van Breugel, F., M. Mislove, J. Ouaknine and J. Worrell, Domain theory, testing and simulation for labelled markov processes, Theor. Comput. Sci. 333 (2005), pp. 171–197.
Wand, M., R. Culpepper, T. Giannakopoulos and A. Cobb, Contextual equivalence for a probabilistic language with continuous random variables and recursion, PACMPL 2 (2018), pp. 87:1–87:30.
