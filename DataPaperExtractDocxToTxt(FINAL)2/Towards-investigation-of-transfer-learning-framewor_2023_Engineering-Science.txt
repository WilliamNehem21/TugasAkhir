Engineering Science and Technology, an International Journal 48 (2023) 101589








Towards investigation of transfer learning framework for Globotruncanita	
genus and Globotruncana genus microfossils in Genus-Level and Species-Level prediction
Ilyas Ozer a, Ismail Kocak b,*,1, Onursal Cetin c,2, Ali Can Karaca d,3, Caner Kaya Ozer e,4,
Kutlucan Gorur c,5
a Computer Engineering Department, Bandırma Onyedi Eylul University, Balıkesir, Turkey
b Department of Engineering Science, Bandirma Onyedi Eylül University, Bandirma-Balikesir, Turkey
c Electrical and Electronics Engineering Department, Bandırma Onyedi Eylul University, Balıkesir, Turkey
d Computer Engineering Department, Yıldız Technical University, Istanbul, Turkey
e Department of Geological Engineering, Engineering and Architecture Faculty, Yozgat Bozok University, Yozgat, Turkey



A R T I C L E I N F O 

Keywords:
Microfossil Globotruncanita genus Globotruncana genus Transfer Learning Deep Learning
A B S T R A C T 

The applicability of digital imaging techniques and machine learning models to paleontological datasets is exploring the possibility of predicting microfossils extracted from the rock samples instead of the traditional identifying methodologies under the microscope in a one-by-one way via a domain expert. However, these processes, including labeling, are carried out manually and take a high time-consuming, especially for many quantities and diversity of complex morphological microfossil specimens. In this work, we propose a transfer learning framework based on a custom model CNN (Convolutional Neural Network) and diverse pre-trained deep models (ResNet50, Xception, InceptionV3, VGG6, MobileNet) trained with the millions of images for Globo- truncanita genus and Globotruncana genus in genus-level and species-level prediction. The second primary advantage of our framework is able to provide better and more robust decisions for a limited number of microfossil images captured by the low-cost light microscope imaging technology. The comparison of the diverse
methods was evaluated with different performance metrics, and the observation of the framework was made to perform high prediction scores reaching up to the outcomes (>99 % accuracy and > 0.99 AUC score for genus- level/>81 % accuracy and > 0.89 AUC score for species-level). As far as we know, this research study is the first attempt to investigate a transfer learning framework to predict the Globotruncanita genus and Globotruncana
genus families at the genus-level and species-level microfossils. Overall, it may extend the existing literature on paleontological science and automated/quick classification manner.





Introduction

Paleontology, a vital branch of Earth science, assists in compre- hending the evolution of life on Earth by scrutinizing the life of the geologic past, primarily through plant and animal fossils [1–3]. Pale-
ontologists delve into ancient life to uncover the reasons for the trans-
formations that occurred in the past. By scrutinizing the distinct
textures, structures, and forms of fossils, paleontologists can gain in- sights into the Earth’s history, ecology, and biology [4]. For example, the abundance and diversity of certain microfossil groups like forami-
nifera and diatoms can be used to reconstruct past ocean conditions such as temperature, salinity, and nutrient availability [5]. Additionally, the identification of pollen types in sedimentary rocks can reveal informa- tion about the timing and magnitude of past climate changes, as well as



* Corresponding author.
E-mail address: ikocak@bandirma.edu.tr (I. Kocak).
1 Orcid: 0000-0002-4519-4561
2 Orcid: 0000-0001-5220-3959
3 Orcid: 0000-0002-6835-7634
4 Orcid: 0000-0001-6886-740X
5 Orcid: 0000-0003-3578-0150

https://doi.org/10.1016/j.jestch.2023.101589
Received 17 May 2023; Received in revised form 12 October 2023; Accepted 23 November 2023
Available online 6 December 2023
2215-0986/© 2023 Karabuk University.	Publishing services by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



the evolution and distribution of plant species over time [6].
Microfossils, small fossilized organisms, furnish crucial information about past environments and the evolution of life on Earth [2]. The practical applications of microfossils are vast and include their use in oil exploration, biostratigraphy, paleoclimatology, and environmental studies [5]. Planktonic foraminifera is crucial for understanding how the world’s oceans have changed ecologically over time are still alive today.
To understand extinction events and evolutionary processes, paleon-
tologists examine fossil assemblages of planktonic foraminifers, which first emerged in the fossil record about 201–208 million years ago during the Jurassic period. Paleontologists can learn a lot from the
structure of planktonic foraminiferal tests, without using genetic infor- mation [7]. To investigate responses to climatic change, the exploitation of new niches, and even the emergence of new species, changes in morphology can be followed across time. Furthermore, since many planktonic foraminifera species have a relatively short life span, planktonic foraminifera fossils are used to estimate the age of sediments [7]. To indicate the time window, it is done by carefully recording the first and last appearances of common, short-lived species and using the presence of such species. It is also used for regional and global corre- lation of sedimantary rocks [8].
Advancements in technology have made it easier to study micro- fossils, but identifying and analyzing them still presents challenges due to their small size and the fact that they often require specialized tech- niques and equipment for analysis. Furthermore, manual biostrati- graphic studies of microfossils can be time-consuming and require significant financial resources [9,10]. Despite these challenges, auto- matic systems for identifying microfossils are becoming increasingly popular in recent years, and advances in technology continue to improve our understanding of these tiny fossils and their significance in the study
of Earth’s history. Paleontologists use a combination of automated methods to identify and categorize microfossils, including digital im-
aging, machine learning, and computer vision. These methods can speed up the analysis process and allow researchers to analyze much larger data sets than would be possible with manual methods alone [11,12].
The identification and classification of microfossils are useful to the study of hydrocarbon exploration, and they contain a wealth of infor- mation from small rock samples in the special part of the earth. This progress means that their investigation is engaged in finding and developing hydrocarbon resources or assessment of reservoir distribu- tion, such as the petroleum industry [13–15].
In our previous works [9,10], we have focused on classification of
three Globotruncana species: i) Globotruncana ventricosa, ii) Globo- truncana linneiana, iii) Globotruncana arca. In [9], we designed a 14- layered custom CNN architecture to identify these microfossils under limited number of samples. In addition, an hybrid version, custom CNN coupled with Long Short-Time Memory (LSTM) is proposed in [10]. Experiments in both studies are carried out by using our low cost re- flected microscopic imaging system. In this paper, we extend our dataset by adding new three different species of Globotruncanita genus. Note that Globotruncanita and Globotruncana are two genera of planktonic fora- minifera, are widely distributed in marine sediments around the world and have been used as index fossils for dating and correlating sedi- mentary rocks.
The paper focuses on identification of six different microfossils, namely, Globotruncana arca, Globotruncana ventricosa, Globotruncana linneina, Globotruncanita elevata, Globotruncanita stuarti, and Globo- truncanita stuartiformis. As is seen, three of them belong to Globotruncana genus where the others are from Globotruncanita. Paleontologists find it challenging to classify these species due to their closely resembling morphological structures. To the best of our knowledge, this is the first work that explores these two genus with deep learning methods and transfer learning technique. The paper not only focuses on classification of each species but also concentrates on identification of genus type.
Collection, preparation and labeling of microfossils are carried out by our team. A low-cost and conventional reflected microscopic imaging
system was utilized in the experiments, comprising an Olympus SZX16 microscope and a 12.5 MP camera. In comparison to alternative imaging methods, this system can be acquired inexpensively and run with min- imal technical knowledge.
The experiments are carried out by using 5 different popular deep learning models, namely, ResNet50, Xception, InceptionV3, VGG6, MobileNet, and a custom models used in k-fold cross validation and holdout methods. The potential usage of transfer learning is revealed to provide better discrimination against the limited microfossil dataset. We have also discovered the fully-depth custom CNN deep model, covering a range of performances, from the theoretical architecture to the application for microfossil prediction. Comparison is evaluated in terms of accuracy, precision, specificity, sensitivity, F-1 score, and AUC scores not only for the discrimination of six species but also for the identifi- cation of two genus types.
The contributions and novelties of this paper to the limited existing literature with gaps can be summarized as follows:

The number of microfossil samples for each species and genus of
the same/different family might vary depending on the number of potentials extracted from the sediments. In other words, the number of microfossil samples due to the partial sediments leads to the poor numbers of the species/genus specific. Hence,Globo- truncanitagenusand Globotruncanagenushave limited specimens for each family due to the existing potential and hard extraction/ labeling process. The main aim of this work is to reduce the ef- forts made by a paleontologist and to provide reliable and ac- curate prediction outcomes using a fast-to-train transfer learning
approach of pre-trained deep models’ complexity (learned by training on millions of images) without augmentation and a
custom full-depth CNN model for the limited number samples of these families.
The second primary advantage of this research is to qualita- tively identify and classify microfossils based on morphological
and histological characteristics via low-cost light microscope images captured by a CCD camera (12.5 MP /Olympus SZX16) instead of the high-sized SEM images. With access to more low- cost images with geologic noise (e.g., background rock matrix) for labeled data, training/testing can be improved, outlining a highly effective and inexpensive approach. Hence, it enables the sufficiently robust deep learning model to overcome the complications.
Ultimately, such automation does not replace the expert pale- ontologist, but it enables more rapid and efficient imple-
mentation of microfossil prediction tasks in species/genus level for Globotruncanita genus and Globotruncana genus in the existing limited literature background as a first attempt work.
The gaps in the existing literature are in a concise form as fol-
lows; the first problem is the limited source of information-rich datasets for generating robust deep-learning models. The sec- ond issue is hand-crafted feature extraction engineering for conventional machine learning models. The third problem is collecting and processing the high-sized datasets digitized by SEM technology. The fourth issue is a lack of deep learning model performances with/without transfer learning effect compared to species/genus level microfossil prediction tasks, especially for Globotruncanita genus and Globotruncana genus family. Overall, our research may lead to solutions for these issues regarding the literature background.

Literature survey

Identifying microfossils requires the use of imaging techniques that can reveal their physical characteristics, such as shape, size, internal
structures, surface features, and ultrastructures [16–20]. Some of the imaging techniques that paleontologists commonly use for identifying




Fig. 1. The schematic and algorithm of the genus-level and species-level microfossil prediction framework based on transfer learning technique for Globotruncanita
genus and Globotruncana genus.


microfossils include scanning electron microscopy (SEM) [18,21], transmission electron microscopy (TEM), X-ray computed tomography (MicroCT) [22,23], and light microscopic imaging [9–11]. SEM and
TEM use electron beams to create high-resolution images of microfossils,
while MicroCT generates 3D images of fossils by taking X-ray images from multiple angles. Light microscopic imaging, on the other hand, uses visible light to produce images of fossils and is often used to identify microfossils that are too small for other imaging techniques. By using these techniques, paleontologists can study the physical characteristics of microfossil, however, the use of these techniques can also be limited by the cost of equipment, the availability of specimens, and the need for expertise in handling the equipment and interpreting the results [9,10]. Because it is a conventional, cost-effective and non-invasive user- friendly technique, a light microscopy setup, consisting of an Olympus SZX16 microscope coupled with a 12.5 MP camera, was employed in this paper.
Automatic identification of microfossil species has long been a challenging task for paleontologists [11]. Although selecting the most efficient imaging technique such as SEM and light microscopy is important, it is also substantial to determine the machine learning method which will identify microfossils similar or better than the pa- leontologists. To this end, many researches have been conducted ex- periments using different methodologies for identification of various microfossil genus. The major part of these studies focused on Paleozoics [12], palynomorphs [24], diatoms [25], foraminiferas [4,26], phytolith [16], and planktonic radiolarians [20,21]. Here, machine learning methods can be categorized into three groups, namely, conventional methods, deep learning methods, and hybrid methods.
Conventional machine learning methods generally extract the hand- crafted features that provide information about texture, shape and infrastructure of the microfossils and applies them to traditional ma- chine learning methods [16,20,27]. For example, Solano, Gasmen and Marquez introduced a Support Vector Machine (SVM)-based identifi- cation system for the paleontologist to classify four different radiolarian species [20]. They suggested the best features are obtained from inverse
difference moment, correlation, maximum correlation coefficient and shape features such as round, solidity and circularity inside 23 different features [20]. In addition, Marmo, Amodio and Cantoni also underlined that the shape feature can describe 4 different foraminifera species well [27]. Furthermore, Diez-Pastor et. al used diverse and high number of features including perimeter, convex area, form factor, convexity, roundness and compactness called geometric and morphological attri- butes coupled with elliptic fourier descriptors to identify phytolith fos- sils. Similarly, the highest accuracies are obtained by using geometric and morphological attributes without EFDs [16]. However, the accu- racies are generally limited to 0.90 and they do not able to describe all variability of fossil types.
While the conventional method involved using hand-crafted features and traditional machine learning techniques, deep learning has emerged as the most popular artificial intelligence approach for image classifi- cation. Unlike hand-crafted features, deep learning models can learn the informative and the most diverse features automatically from the datasets. Many deep learning methods have been developed for micro- fossil identification, and transfer learning is one of the widely used techniques [12,26,28,29]. In [26], a dataset including 2673 images for 4 different foraminifera species was prepared by light microscope system, applied transfer learning benefitting from VGG16 model pre-trained on ImageNet database, and obtained the accuracy score of 98 %. In another paper, the dataset including fusulinid species such as Beedeina, Fusuli- nella and Parafusulina was generated by assembling fusulinid thin- section data from various sources. They obtained the best result by fine-tuning InceptionV3 model with the score of 0.89 among the popular architectures like VGG16, MobileNetV2 and ResNet50 [12].
There have been hybrid methods that use learned features supplied by a deep architecture in a traditional machine learning algorithms [18,30]. For example, Mitra et al. extracted learned feature from ResNet50 and VGG16 networks,and applied them to a neural network classifier to classify 6 different planktic foraminifera species. Compared to expert and novice paleontologists, the system achieves higher preci- sion, recall, and F1 score than novices and comparable precision but




Fig. 2. (a-b-c) Sandstone-milestone-marl alternation observed at the base of the Akveren Formation (NE of Bartın province) (left side), general view of marls in Akveren Formation (NE of Bartın Province) (right side), taking samples from the field at regular intervals (lower side). Sample preparation stages in the laboratory.d. the sample taken from the field, e. soaked the dry sample with water added with hydrogen peroxide, f. placing on the hot plate, (g-h) washing with pressurized water using a sieve, i. putting numbered glass beaker. Stages of examining fossils. j. placing the obtained material on a numbered slide, k. Separation of important genera and species under the microscope.


better recall and F1 score than experts [30]. Another study prepared by Keçeli, Kaya, and Keçeli classified SEM images collected from radio- larian by fusing deep features and hand-crafted features with the area under curve score of 99.10 % [18].
Deep learning models require extensive datasets to be trained effectively, making them data-hungry systems. Obtaining these samples can pose a significant challenge for paleontologists in certain cases. Especially, if the researchers aim to identify many species at the same time, large image samples are indispensable for deep learning models. Endless Forams dataset having more than 30,000 image samples of 35 different foraminifera classes and Diatom dataset with 160,000 samples for 80 different Diatom species can be given as an example [11,25]. In Diatom dataset, average accuracy of AlexNet architecture can reach up to 99.51 and this shows the impact of the data amount [25]. On the other hand, finding the microfossil samples, collecting the images of each sample, and labeling them are very time-consuming especially in rare
microfossils [31,32] and require significant financial resources. There- fore, it is also important to design an architecture that provides efficient results under limited number of samples condition. Mimura et al. have estimated microfossils of fish teeth and denticles by training deep learning models for object detection algorithms (YOLO-v7). These mi- crofossils have historically been used primarily for biostratigraphy and geochemistry, including depositional ages and marine ecosystems. The trained model achieved an F1 score of 0.87 with an original dataset [33].

Methods and dataset

Micropaleontologists’ paleontological expertise often needs more
quick access to recognize and categorize complex microfossil specimens of the Globotruncanita genus and Globotruncana genus. Accurate and systematic taxonomic knowledge of rare specimens of microfossils from thin-slice paleontological images requires important biostratigraphic




Fig. 3. Computer setup and specimens for Globotruncanita genus (upper-sequence) and Globotruncana genus (lower-sequence) a. Globotruncanita elevata, b. Globo- truncanita stuartiformis and c. Globotruncanita stuarti d. Globotruncana arca, e. Globotruncana linneiana and f. Globoturuncana ventricose.


analysis, and it poses a major challenge for the future of biostratigraphy [34]. Here, we employ the fully-depth custom CNN model and the po- tential usage of the transfer learning technique implementing the high- sized pre-trained deep learning models for the Globo- truncanita genus and Globotruncana genus over the low-cost light mi- croscope digital images (see Fig. 1).

Background knowledge of planktic foraminifera and data collection

Biostratigraphy
Planktonic foraminifers have shown high diversity and morpholog- ical changes from the time they appeared to the present day [8]. When identifying, paleontologists carefully examine many features of the species, such as the appearance of sutures and keels, the arrangement of the chambers, the structure of the wall, exterior decorations, pores, openings, the shape of the umbilical openings. Thus, this provides continuous evidence of evolutionary changes from which phylogenetic relationships can be established [8].
There is a noticeable increase in the diversity of planktonic fora- minifer assemblages in Cretaceous [8]. Especially during the Late Cretaceous (Campanian- Maastrichtian) planktonic foraminifera expe- rienced the highest morphological and taxonomic diversity in their evolutionary history [35,36].
In this study, three species of Globotruncana genus/Glbt. (Globo- truncana arca/98 samples, Globotruncana ventricose/102 samples, Globo- truncana linneiane/91 samples) and Globotruncanita genus/Glbtc. (Globotruncanita elevate/53 samples, Globotruncanita stuarti/54 samples, Globotruncanita stuartiformis/54 samples) were used. Distinguishing
these genus and species from each other is very important for biostratigraphic studies (see Fig. 3). Biozones are carried out based on the first occurrences of Globotruncanita elevata and Globotruncana ven- tricosa, especially in the Lower Campanian [37–40]. The sedimantary
rock samples were collected from marine clayey limestone and marls
every 10 cm–1 m from stratigraphic section from Akveren Formation in order to study their planktonic foraminiferal contents (Fig. 2 a.b.c). The
dry samples throughout the section were prepared for planktonic fora- miniferal analysis in the laboratory (Fig. 2d). The samples were soaked with water containing hydrogen peroxide to remove residual material (Fig. 2e). It was heated on hot plate to purify it better (Fig. 2f).
Then, they were kept overnight and washed through > 63 μm sieve
until clean (Fig. 2 g,h.i) and dried at room temperature. The dried ma-
terial was placed on numbered slides (Fig. 2j). In slatys, planktonic foraminifera genus and species were carefully separated under a binocular microscope (Fig. 2k) and photographed with a digital camera connected to the microscope and transferred to the computer.

Microfossil descriptions
The genera Globotruncana and Globotruncanita differ morphologi- cally. The test of Globotruncana Cushman (1927) is biconvex and pe- ripheral of the test is lobate-circular. Chambers vary from spherical to crescent-shaped [10]. Intercameral sutures are elevated on the spiral side, raised or depressed on the umbilical side. This form has a double keels. The primary opening is in the intraumbilical position and is covered by a tegillum. In addition, the status of the last chamber is extremely important in species distinction.
The test shape of Globotruncanita Reiss (1957) is biconvex and the




Fig. 4. Schematic of the general CNN architecture.


Fig. 5. Schematic of the custom-CNN architecture in microfossil prediction.


circumference is lobate to circular. The peripheral margin is angular and truncated. The shape of the chambers is variable, from trapezoidal to petaloid and crescent-shaped on the spiral side. The sutures on both sides are elevated but sometimes collapse on the umbilical side. It is single keel. The primary aperture covers with a porticus. The state and angle of the last chamber are used when identifying a species distinction [41–44]. The collection and labeling process setup of the microfossil
samples is made under the low-cost light microscope digital imaging
technology (see Fig. 3).

Deep learning models for prediction microfossil species

Convolutional neural network
N—1
yk =  xnhk—n	(1)
n=0
Within this framework, x represents an image pixel, h symbolizes the
kernel, N indicates the amount of data in x, and y refers to the feature map. The pooling layer is used to reduce the dimensionality of the feature maps, effectively addressing concerns about overfitting and computational complexity. The fully connected layers are employed to ascertain class scores. Two types of activation functions are used in this context [10]:
Rectified Linear Unit (ReLU): This function adds a non-linearity to the structure of the network, as shown in Eq. (2).

A convolutional neural network (CNN) is an advanced neural network architecture specifically designed for processing grid-like data
f (x) = { x, x > 0
(2)

structures, such as images. CNNs have been extensively used in various fields, such as speech recognition, natural language processing, and computer vision, to perform various tasks and achieve impressive re-
Softmax Function: This approach is used to calculate the probabili- ties for the ’k’ output classes, as depicted in Eq. (3).

sults. In these tasks, CNNs.
are trained to detect patterns in input images and categorize them accordingly. The CNN architecture consists mainly of three essential
pj =
exj
∑k exk
j = 1, ⋯k	(3)

layers, commonly known as the convolutional layer, the pooling layer and the fully connected layer. These layers are typically shown in Fig. 4. Through the utilization of convolutional and pooling layers, CNNs can automatically learn and extract significant features from the input data. The convolutional layer employs kernels, which are represented as matrices, to examine pixels in microfossil images and discern crucial features like edges, corners, and lines. Eq. (1) offers a mathematical
description of this process [10].
Fully-Depth Custom CNN architecture. In our study, we used a proprietary CNN architecture that features eight consecutive trainable layers. Each pair of layers separated by two convolution layers, and the last two layers are fully connected and also trainable. Initially, all images were resized to 100x100x3 before being input into the model. There are 32 maps with a filter size of 3x3 in the first two convolution layers, followed by batch normalization, an activation function, and 2x2 max- pooling layers. This configuration was repeated twice, with the second and third convolution layers having 64 and 128 feature maps, respec- tively. Subsequently, global average pooling and a dropout layer (0.5)




Fig. 6. The schematic of the ResNet50.


Fig. 7. The schematic fundamental architecture of the Xception (upper), computational complexity of each architecture (x axis shows million FLOPs) (lower).


Fig. 8. The confusion matrix for related performance metrics.


were incorporated into the structure [10]. Next, a fully connected layer was implemented, comprising 100 neurons. The final layer had the same number of neurons as the number of classes in the dataset. During the training phase, the Adam optimizer algorithm was used, and the Soft- max function was utilized as the activation function in the fully con- nected layer. All models were trained for a total of 400 epochs using categorical cross-entropy as the loss function. During the testing phase,
the epoch with the lowest loss value in the training set was used. The overall structure of the custom-CNN model is depicted in Fig. 5.

VGG16
In 2014, the Visual Geometry Group (VGG) at the University of Oxford presented the VGG16 convolutional neural network architecture [45]. Relying solely on 3x3 convolutional layers with increasing depths,




Fig. 9. Training, validation and test dataset parts of the microfossil images a- holdout strategy b- k-fold cross-validation strategy.



Table 1
Species-level prediction performances of different deep models in 10-fold cross validation strategy for 6-class microfossil samples.




Table 2
Genus-level prediction performances of different deep models in 10-fold cross validation strategy for 2-class microfossil samples.




Table 3
Genus-level prediction performances of different deep models in holdout vali- dation strategy for 2-class microfossil samples.

% for ACC, SENS, SPEC, PREC and F-1. AUC is in the range of [0–1]. F-1 stands for the F-score.

the VGG16 architecture has significantly influenced the fields of deep learning and computer vision. VGG16 has proven to be highly effective in image recognition and classification tasks, including but not limited
to object detection, image segmentation, and image captioning [45–47]. The architecture is highly regarded in deep learning due to its ability to
deliver remarkable results with a limited number of parameters.
Comprising 16 layers, the VGG16 architecture can classify images
into 1000 distinct categories, such as keyboards, animals, pens, and mice [45]. Its image input size is 224x224 [45]. Training of the VGG16 model took several weeks using Nvidia Titan Black GPUs [45], and it achieved a test accuracy of 92.7 % on ImageNet, a dataset containing over 14 million images spanning nearly 1000 classes [45,48].

InceptionV3
In 2014, Google researchers developed an advanced deep learning architecture called the GoogLeNet network [49,50]. It employs the Inception network topology, which reduces the number of network pa-
rameters while enhancing the network’s depth [49]. GoogLeNet is widely used in computer vision applications like image segmentation,
object recognition, and object detection due to its unique design and architecture [50,51]. It is also known as the Inception network, with the Inception network topology being its core component. The five main variations of the GoogLeNet network include Inception v1 (2014), Inception v2 (2015), Inception v3 (2015), Inception v4 (2016), and Inception-ResNet (2016) [49–51].
Generally, the Inception module consists of one maximum pooling
and three convolutions with varying sizes. After the convolution oper- ation, the channel is aggregated to the network output of the previous layer, followed by nonlinear fusion. This approach helps prevent over-
fitting while enhancing the network’s expressiveness and flexibility across different scales [49].
Inception v3, the third version of the Inception architecture, repre- sents a significant improvement over Inception v1 and v2. It utilizes a convolution kernel splitting method that breaks down large volume integrals into smaller convolutions [49,52]. It introduced several new techniques, such as label smoothing and the inclusion of a new layer type called “grid reduction,” which further decreased the model’s
parameter count. Moreover, Inception v3 introduced the concept of
“auxiliary classifiers” that are added to the network to provide extra regularization during training and enhance the model’s accuracy [49].

MobileNetV2
Previously developed deep learning software, which was mainly used on servers or distributed systems, has now been adapted for use on mobile devices. One of the most significant among these is the Mobile- NetV1 architecture. This convolutional design requires considerably less computation compared to traditional CNN models and is specifically tailored for low-resource or mobile devices. As a result, it has facilitated the implementation of classification and image processing on mobile devices [53,54].
Another prominent deep learning architecture utilized in the mobile environment is the MobileNetV2 architecture. Although designed with




Fig. 10. Pre-trained deep model performances for microfossil prediction of Globotruncanita genus vs Globotruncana genus a- Species-level prediction for 6-classes in 10-fold cross validation b- Genus-level prediction for 2-classes in 10-fold cross validation c- Genus-level prediction for 2-classes in holdout validation strategy.

choice for a wide array of applications where low latency and low power consumption are crucial, including object detection, semantic segmen- tation, and image classification [55,56].















Fig. 11. ROC analysis for genus-level prediction.

mobile environments in mind, it is also a preferred deep learning ar- chitecture for desktop environments. Introduced by Sandler et al. in 2018 [55], MobileNetV2 represents a significant improvement over its predecessor, MobileNetV1, in terms of accuracy and efficiency. Mobi- leNetV2 incorporates various innovative strategies, such as inverse re- siduals, linear bottlenecks, and shortcut connections, to minimize the number of parameters and computations required while maintaining high accuracy [55]. These characteristics make MobileNetV2 an ideal
ResNet50
The vanishing gradient problem in deep neural networks becomes more pronounced as the network depth increases, resulting in poor performance. To address this issue, He et al. [57] introduced a novel architecture called Residual Network (ResNet) that employs residual connections between layers. These connections enable gradients to flow more easily through the network, facilitating the training of much deeper networks. The fundamental building block of the ResNet archi- tecture, based on residual learning, is the residual block, which com- prises two or three convolutional layers followed by a shortcut connection. This shortcut connection adds the output of the preceding layer to the current layer, producing a residual that passes through a non-linear activation function [57].
ResNet50, an extension of the original ResNet architecture, consists of 50 layers, including 49 convolutional layers and one fully connected layer (see Fig. 6) [52]. The architecture is divided into five stages, each containing multiple residual blocks and an increasing number of filters. The first stage of ResNet50 includes only one convolutional layer and one pooling layer, while the following four stages contain several re- sidual blocks. The number of filters in each stage gradually increases, starting from 64 in stage 1 and doubling in each subsequent stage, culminating in 2048 in stage 5. The residual blocks, which serve as the core innovation of ResNet50, enable the network to be trained to new depths while mitigating the vanishing gradient problem. Each residual block features two or three convolutional layers followed by batch normalization, ReLU activation, and a shortcut connection [57,58]. Batch normalization reduces internal covariate shift, while ReLU in- troduces non-linearity to the network, simplifying the training of deep neural networks. After the output of the last residual block, a global average pooling layer calculates the average of each feature map across its spatial dimensions, preserving the most pertinent information while




Fig. 12. Confusion matrices for diverse pre-trained deep models in species-level prediction analyzed via 10-fold cross validation (Gl.ventri: Globotruncana ventricosa,
Gl.stf: Globotruncanita stuartiformis, Gl.linne: Globotruncana linneiana, Gl.st: Globotruncanita stuart, Gl.el: Globotruncanita elevate, Gl.arca: Globotruncana arca).




Fig. 13. Confusion matrices for diverse pre-trained deep models in genus-level prediction a-10-fold cross validation b- holdout validation results (Glbtc: Globo- truncanita, Glbt: Globotruncana).


reducing the dimensionality of the feature maps. The classification output is generated by passing the output of the global average pooling layer through a fully connected layer with 1000 units [57].

Xception
The Xception is a convolutional neural network architecture that connects each layer to every other layer and it is the improved version of Inception-v3. The connection topology of the network is structured to learn better for channel correlation and spatial correlation. Therefore, the network employ the depthwise separable convolution layers to replace the ordinary convolution operation layers as in Inception-v3 model [59,60]. The depthwise separable convolution, is commonly called “Separable Convolution”, is able to decompose ordinary convo-
significant rise in computational demands [6162]. Time constraints are a critical factor in many practical scenarios [62]. While there have been efforts to address this by using high-performance computing systems like GPU servers, challenges remain when deploying on devices with limited computational resources, such as mobile phones [61]. In this context, we focus on the time complexity of the convolutional layer. We’ve excluded the fully connected and pooling layers from our analysis
since they typically account for only 5–10 % of the overall computa-
tional load [63]. Given l as the layer index, d as the total number of convolutional layers, representing the filter count of the lth layer, as fl-1
the input channels, sl as the filter size, and ml as the feature map’s spatial dimensions, the time complexity is described as [61]:
O( ∑d f s f m )



the second step is defined as a pointwise convolution adopting a 1 × 1
kernel to convolve point-by-point to be more efficient in computation
costs (see Fig. 7). The network can decreases the number of hyper- parameters as well as reducing the number of calculations [59,60].

Comparison of computational complexity of models
In recent times, Convolutional Neural Networks (CNNs) have out- performed many traditional machine learning methods, particularly in tasks related to images [61]. However, this advancement has led to a
The formula provided earlier applies to the testing phase [6164]. During training, the time complexity is roughly triple that amount [6164]. All models in this study underwent identical pre-processing. Also, the images were applied to all models in the same dimensions. Therefore, to evaluate the model complexities against each other, we
assessed their computational complexity using Tensorflow’s profiler
tool. This tool quantifies the floating-point operations (FLOPs) a model utilizes in one forward pass. As can be seen in Fig. 7 (lower part), the highest  computational  requirement  belongs  to  the  ResNet50




diction in holdout validation d- AUC* scores (species-level prediction), AUC + scores (genus-level prediction in 10-fold cross validation), AUC# scores (genus-level pre- Fig. 14. Boxplot presentation for diverse performance metrics a- species-level prediction b- genus-level prediction in 10-fold cross validation c- genus-level pre- diction in holdout validation The separation of the training and testing for each set is shown in.


architecture. On the other hand, the computational complexity of the custom architecture is significantly lower compared to all other models.

Performance evaluation metrics
In this work, we carried out a performance assessment of pre-trained deep models with various metrics (see Fig. 8) and validation strategies (Fig. 9) in the current literature [10].
where, the related mathematical equations for performance metrics based.
on the fundemental metrics (TP, FN, FP and TN) are given below:
ACC = 	TP + TN		(5)
TP + TN + FP + FN
morphological end-members. However, this technique has only been applied in a limited way. In other cases, morphological variation is noted as an important verification as well as the genetic differentiation for each microfossil genus and species [9,10,21,65–67].
On this point, computer vision and machine learning models can
provide an effective quick way to not only automate a task that rela- tively few trained paleontologists are able to do (i.e., identification of all genera and species in terms of accurate decision) but also to undertake a level of consistency due to subjectivity and/or bias [9,10,21,65–67].
Results and discussion

In this study, Globotruncanita genus (Globotruncanita elevate, Globo-

SPEC =   TN	
TN + FP SENS =   TP	
TP + FN
  TP 
(6)


(7)
truncanita stuart, and Globotruncanita stuartiformis) and Globotruncana genus (Globotruncana arca, Globotruncana linneiana, and Globotruncana ventricose) were recognized by diverse deep learning models. Then they were analyzed via different types of classification performance metrics. Transfer learning technique was used for implementing the strengths of a deep convolutional neural network (CNN) model. These pre-trained

PREC = TP + FP	(8)


PREC × SENSF — Score = 2 ×	(9)
PREC + SENS
Accurate genus and species-level identification are reported as a hard
task, and taxonomic agreement is achieved around 70 %, even if for the experienced domain experts [34]. Planktonic foraminifera has highly complex and variable morphologies for each genus and species to define microfossil specimens via one-by-one examination under the microscope [22,30,34,65]. Furthermore, in some cases, genetic analysis is required to  provide  genus  or  species  distinction  for  the  existence  of
models employed its many layers of filters, learned by training on mil-
lions of images. The weights of these layers require an enormous amount of images because of the depth and complexity of the pre-trained deep models [9,10,21,26,58,65–68]. However, as far as we know, these
learned filters were transferred to new microfossil prediction domains
for the Globotruncanita genus and Globotruncana genus with a limited number of low-cost microscope images in this first attempt of a research. Moreover, re-using the weights of these pre-trained deep CNN models for new prediction tasks at the genus and species level was possible and promising [69,70].
Table 1 presents 6-class prediction for species-level in 10-fold cross-


Table 4
The concise literature comparison for species-level microfossil prediction.



Table 5
Number of samples per class in each set of holdout validation. Note that, ‘‘class’ term here is used in the machine learning field not for the biological sense.


Family Name	Species	Training	Testing
Glbt.genus	Gl.arca	77	21
Gl.ventricose	81	21
Gl.stuarti	43	11
Gl.stuartiformis	45	9
validation results in the diverse performance metrics. The highest ACC value (81.19 %) here belongs to the MobileNet pre-trained model. Here, the highest SENS, SPEC, PREC, F-score, and AUC scores were provided by the same model as 83.82 %, 96.10 %, 83.35 %, 83.13 %, and 0.899, respectively. On the other hand, the lowest ACC value (70.13 %) was calculated via the ResNet50 model, which provided a significantly lower
ACC value compared to other models (71.68–78.10 %). Here the other scores were obtained via this model as 73.45 % (SENS), 93.83 % (SPEC),
72.01 % (PREC), 72.37 % (F-1), and 0.824 (AUC), respectively.
Xception, InceptionV3, VGG16 and Custom-Model have achieved the rate of other performance metrics between 74.44 and 81.34 % (SENS), 94.09–95.42 % (SPEC), 75.43–81.23 % (PREC), 74.70–80.67 % (F-1)
and 0.842–0.87 (AUC).
According to the 10-fold cross-validation for genus-level microfossil prediction (Globotruncanita genus versus Globotruncana genus) results in Table 2, MobileNet has achieved the greatest accuracy (99.78 %) and sensitivity (99.38 %) among the other pre-trained deep models. The rest of the performance scores were obtained as 100 % (SPEC and PREC),
99.69 % (F-1), and 0.997 (AUC). However, the AUC score is the lowest one (0.958) acquired by Custom-Model pre-trained model. The accuracy (95.35 %) is the same lowest level as this model. The range of the classification accuracies succeeded at the rate of 97.57–99.78 %. The
other outcomes are seen in the lowest rate of > 94.41 % (SENS/VGG16),
>94.16 % (SPEC/Custom-Model), >90.23 % (PREC/Custom-Model),
>93.73 % (F-1/Custom-Model) and > 0.958 (Custom-Model/AUC).
Using the holdout validation strategy, the InceptionV3, Xception, and Custom-Model have provided the greatest accuracy results reaching up to the 98.90 % value in 2-class microfossil prediction for genus-level, as presented in Table 3. The best of the other metrics were obtained in InceptionV3 (100 % for SENS), Xception/MobileNet/Custom-Model (100 % for SPEC and PREC), InceptionV3 (98.36 % for F-1 score), and InceptionV3 (0.992 for AUC). In order to prove the effect of genus-level



and species-level prediction, the two steps are carried out on the pre- trained deep models. Hence, the distinction of the experimental groups (2)-class and 6-class) shows the great prediction outcomes for Globotruncanita genus and Globotruncana genus reaching up to the
99.78 % accuracy (genus-based differentiation) and 81.19 % (species- based differentiation). According to the results, the best of the outcomes have 18.59 % accuracy difference for genus-level versus species-level. However, the value of difference for holdout and 10-fold cross- validation strategy for genus-level prediction has not been observed to provide significantly prediction scores for each metric. The rates of prediction outcomes and the ROC curve were presented in Fig. 10 and Fig. 11, respectively.
According to Fig. 10, 6-class prediction performances were estimated by various deep models. MobileNet has achieved the best outcomes for
discriminating 6-class microfossils at the species-level regarding the 10- fold validation, especially regarding the SPEC values (>90 %). In order to observe the genus-level predictions, 10-fold validation is better than
the holdout technique for most deep models. 2-class outcomes are calculated significantly higher than the 6-class outcomes. Deep neural networks exhibit a cascading pattern to provide accurate probabilistic predictions. Herein, the ROC curve and AUC scores are important to avoid the bias of predictions that deep models generate. Hence, it may be critical to minimize one type of classification error. Observation of genus-level classification with different threshold levels shows a high AUC score of 0.958 for the Custom CNN model (see Fig. 11).
There is a limitted existing literature for microfossil taxonomy based on machine learning models evaluating the diverse pre-trained com- parisons in a single study [34]. Furthermore, this research study is the first attempt to investigate transfer learning technique performances of diverse pre-trained deep models for genus-level and species-level microfossil prediction over the Globotruncanita genus and Globo- truncana genus. Fig. 12/13 and 14 show the confusion matrices and AUC scores (boxplot presentations) for various pre-trained deep models and metrics, respectively. Confusion matrix is a performance measurement for machine learning prediction problems where the results can be two or multiple classes in different combinations of predicted and actual values. According to Figs. 12 and 13 for the 6-class species-level pre- diction outcomes, Globotruncana ventricosa was estimated by the Custom-CNN model as the best-discriminated microfossil species (92/ 102) among the other species. The same deep model has provided the best prediction performance for the Globotruncana arca (69/98). The Custom-CNN model handled the least discrimination (38/54) for - Globotruncanita stuartiformis among the other deep models. The other discriminations for genus-level prediction have presented that Mobile- Net has achieved the best deep model for Globotruncana genus regarding the 10-fold validation, whereas VGG-16 is the least successful deep model for Globotruncana genus regarding the holdout technique (see Fig. 13).
There is an observation for limitation of the hard collection process
and labeling task of planktonic foraminifera microfossils to form a robust machine learning model for genus-level and species-level pre- diction. Moreover, overfitting is an important issue for limited datasets for deep models. On the other hand, traditional methods tend to the time-consuming progress, labor-intensive work, and expert-based sub- jective decisions that rely on individual specimen identification [9,10]. Some papers estimated traditional machine learning models and hand- crafted feature extraction processes. This classic manner significantly improved the efficiency of sample analysis regarding the classification performances in a negative way. Furthermore, deep features extracted from the light microscope digital images are noted to be prone to distortion due to the unclear backgrounds caused by microscope illu- mination techniques, consisting of the source and optics. Thus these distorted patterns may lead to poor/low microscope resolution to reveal
the microfossil’s own complex patterns (dissimilar to the high-quality and costly SEM imaging) [9,10]. Hence the limited number of images
for specimens and resolution problems may limit the classification
ability of the deep-learning models. The transfer learning technique was observed to ease the computational burden and was analyzed to allow the robust models trained by the relatively small datasets for large-scale taxonomy of complex morphology of Globotruncanitagenus and Globo- truncana genusmicrofossils.The summary of the limited recent articles in microfossil taxonomy via machine learning models is shown in Table 4. According to the concise comparison works, species-level prediction performances of machine learning/deep learning models were estimated in various metrics with state-of-the-art approaches. However, AUC-ROC curve results were not explored with these models in addition to the correct recognition rates/ACC in species and genus level predictions. The AUC-ROC curve is an important performance measurement metric of a classification model at different threshold values. We have esti- mated AUC-ROC curve scores for all pre-trained and custom CNN models. This may support robust prediction outcomes with fine-tuning transfer learning effects of pre-trained deep models in species/genus level distinction.Table 5
The applicability of computational image analysis to paleontological data in real-time applications was reported in the limited works due to the hard-task identification of the fully-automation pipeline according to the existing literature [13,23]. Based on 3D images generated by Computed Tomography (CT), it makes it possible for real-time analysis [23]. The proposed pipeline begins with scanning and ends with the microfossil segmentation process. Hence, high data volumes and time- consuming are impractical for cost-effective reproducibility during
prediction outcomes to verify domain expert’s experience [23]. Most
works are reported offline to estimate microfossil predictions due to the less time-consuming process and more manageable, especially with LM images.
Limited works on microfossil prediction have been reported on families of the Palynomorphs, Radiolarians, and Fusulinids [18,24,29]. Some datasets for these tasks have been collected in abundance due to the nature of the microfossil existence extracted from the rocks or sed- iments. However, our employed microfossil families exist in rare-size samples in nature. Hence, AUC outcomes have been investigated in addition to the ACC values to provide robust discrimination for species and genus-level prediction.
The various performance metrics were added to better analyze the
Table 4, the discrimination range between ACC metrics is ≥ 64 % and ≤ discrimination for species and genus-level prediction. According to SPEC metrics have higher ranges for discrimination (≥14.57 % and ≤ 100 % for different kinds of microfossil families. However, SENS and 100 %) compared to the ACC values. Our examination results for the
prediction of Globotruncanita genus and Globotruncanagenusmicrofossils have verified that the range of the ACC, SENS, and SPEC values is lower (81.19–99.78 %/73.45–100 %/94.04–100 %). F-scores have the same
characteristic range (72.01–99.69 %) in our setup. The performance
analysis leads to the promising effect of the fine-tuned transfer learning pre-trained deep models for species-genus level.

Conclusion

Microfossils are generally found less than 5 mm in size and can include a wealth of knowledge from the earth, biostratigraphy, paleo- ceanography and paleoclimatology, and hydrocarbon research. The identification of microfossils is a fundamental task in micropaleontology science. Conventionally, the traditional methods for collecting and la- beling these tiny microfossil samples under a microscope are reportedly time-consuming and require considerable domain expertise due to the high diversity of microfossils. Moreover, there is not a vast quantity of specimens for each of the microfossil families, and limited datasets are able to be collected from the sedimental areas by paleontologists. Hence, this hard task needs rapid identification and automated methods to define microfossils at the genus and species levels during the end-to-end classification process. However, as far as we know, the current literature needs genus-level and species-level prediction machine-learning models



for the Globotruncanita genus and Globotruncana genusmicrofossils. In this paper, the transfer learning technique based on the diverse pre- trained deep models was implemented to provide a robust prediction model and high classification performances (99.78 % ACC-0.997 AUC/ Custom-Model for genus-level and 81.19 % ACC-0.899 AUC/MobileNet) were obtained in the limited dataset against the overfitting issue. This work’s primary limitation is finding limited samples for these families of
microfossils in terms of the species and genus level. The second limita-
tion is setting up real-time progress with many domain-based experts’
experience checking one-by-one specimens. Finally, our future study will focus on the easy-to-use real-time embedded prediction framework for a low-cost light microscope imaging system in the vast amounts of microfossil samples during the prediction tasks.

Declaration of competing interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

References

L.F. Laporte, What, after All, Is Paleontology? PALAIOS 3 (1988) 453, https://doi. org/10.2307/3514718.
M. Yasuhara, H.-H. Huang, P. Hull, M. Rillo, F. Condamine, D. Tittensor,
M. Kuˇcera, M. Costello, S. Finnegan, A. O’Dea, Y. Hong, T. Bonebrake,
R. McKenzie, H. Doi, C.-L. Wei, Y. Kubota, E. Saupe, Time machine biology: cross- timescale integration of ecology, evolution, and oceanography, Oceanography 33 (2020), https://doi.org/10.5670/oceanog.2020.225.
J. Harlan Johnson, Paleontology, petroleum, and the search for oil, Am. Assoc. Pet. Geol. Bull. 28 (1944) 902–908, https://doi.org/10.1306/3d93368e-16b1-11d7- 8645000102c1865d.
P.K. Saraswati, M.S. Srinivasan, Micropaleontology: Principles and applications, Springer International Publishing, Cham, 2015. 10.1007/978-3-319-14574-7.
H.A. Armstrong, M.D. Brasier, Microfossils: Second Edition, Wiley, 2013. 10.1002/ 9781118685440.
L.R. Wilson, The correlation of sedimentary rocks by fossil spores and pollen,
J. Sediment. Res. 16 (1946) 110–120.
J. Burke, Fossil focus: planktonic foraminifera – small fossils, big impacts, Palaeontol. Web. 8 (2018).
M.K. BouDagher-Fadel, Biostratigraphic and geological significance of planktonic foraminifera, UCL Press (2015), https://doi.org/10.2307/j.ctt1g69xwk.
K. Gorur, C. Kaya Ozer, I. Ozer, A. Can Karaca, O. Cetin, I. Kocak, Species-level microfossil prediction for globotruncana genus using machine learning models,
Arab. J. Sci. Eng. 48 (2023) 1315–1332, https://doi.org/10.1007/s13369-022-
06822-5.
I. Ozer, C.K. Ozer, A.C. Karaca, K. Gorur, I. Kocak, O. Cetin, Species-level microfossil identification for globotruncana genus using hybrid deep learning algorithms from the scratch via a low-cost light microscope imaging, Multimed.
Tools Appl. 82 (2023) 13689–13718, https://doi.org/10.1007/s11042-022-13810-
2.
R. Marchant, M. Tetard, A. Pratiwi, M. Adebayo, T. de Garidel-Thoron, Automated
analysis of foraminifera fossil records by image classification using a convolutional neural network, J. Micropalaeontology. 39 (2020) 183–202, https://doi.org/ 10.5194/jm-39-183-2020.
R. Pires De Lima, K.F. Welch, J.E. Barrick, K.J. Marfurt, R. Burkhalter, M. Cassel, G.
S. Soreghan, Convolutional neural networks as an aid to biostratigraphy and
micropaleontology: a test on late paleozoic microfossils, PALAIOS 35 (2020) 391–402, https://doi.org/10.2110/palo.2019.102.
T. Itaki, Y. Taira, N. Kuwamori, T. Maebayashi, S. Takeshima, K. Toya, Automated
collection of single species of microfossils using a deep learning–micromanipulator system, Prog. Earth Planet. Sci. 7 (2020) 19, https://doi.org/10.1186/s40645-020-
00332-4.
P. Copestake, Application of Micropalaeontology to Hydrocarbon Exploration in
the North Sea Basin, in: Appl. Micropalaeontology, Springer Netherlands, Dordrecht, 1993: pp. 93–152. 10.1007/978-94-017-0763-3_4.
D. Shahbazi-Gahrouei, S. Setayandeh, M. Gholami, A review on natural
background radiation, Adv. Biomed. Res. 2 (2013) 65, https://doi.org/10.4103/
2277-9175.115821.
J.F. Díez-Pastor, P. Latorre-Carmona, A´. Arnaiz-Gonza´lez, J. Ruiz-P´erez, D. Zurro, You are not my type: an evaluation of classification methods for automatic
phytolith identification, Microsc. Microanal. 26 (2020) 1158–1167, https://doi. org/10.1017/S1431927620024629.
Y. Xu, Z. Dai, J. Wang, Y. Li, H. Wang, Automatic recognition of palaeobios images under microscope based on machine learning, IEEE Access 8 (2020)
172972–172981, https://doi.org/10.1109/ACCESS.2020.3024819.
A.S. Keçeli, A. Kaya, S.U. Keçeli, Classification of radiolarian images with hand- crafted and deep features, Comput. Geosci. 109 (2017) 67–74, https://doi.org/ 10.1016/j.cageo.2017.08.011.
L.D. Mouro, L.D. Vieira, A.C. Moreira, E.K. Piovesan, C.P. Fernandes, G. Fauth, R.
S. Horodisky, R.P. Ghilardi, I.F. Mantovani, S. Baecker-Fauth, G. Krahl, B.
L. Waichel, M.S. da Silva, Testing the X-ray computed microtomography on microfossil identification: an example from Sergipe-Alagoas Basin, Brazil, J. South Am. Earth Sci. 107 (2021), https://doi.org/10.1016/j.jsames.2020.103074.
G.A. Solano, P. Gasmen, E.J. Marquez, Radiolarian Classification Decision Support
Using Supervised and Unsupervised Learning Approaches, in: 2018 9th Int. Conf. Information, Intell. Syst. Appl., IEEE, 2018: pp. 1–6. 10.1109/IISA.2018.8633617.
A. Dionisio, G. Solano, M. Quisote, E. Marquez, A Radiolarian Classifier using
Convolutional Neural Networks, in: 2020 Int. Conf. Artif. Intell. Signal Process. AISP 2020, IEEE, 2020: pp. 1–5. 10.1109/AISP48273.2020.9073212.
Y. Hou, X. Cui, M. Canul-Ku, S. Jin, R. Hasimoto-Beltran, Q. Guo, M. Zhu,
ADMorph: a 3D digital microfossil morphology dataset for deep learning, IEEE Access 8 (2020) 148744–148756, https://doi.org/10.1109/ ACCESS.2020.3016267.
L.E. Carvalho, G. Fauth, S. Baecker Fauth, G. Krahl, A.C. Moreira, C.P. Fernandes,
A. von Wangenheim, Automated microfossil identification and segmentation using a deep learning approach, Mar. Micropaleontol. 158 (2020), 101890, https://doi. org/10.1016/j.marmicro.2020.101890.
J.J. Charles, Automatic recognition of complete palynomorphs in digital images, Mach. vis. Appl. 22 (2011) 53–60, https://doi.org/10.1007/s00138-009-0200-4.
A. Pedraza, G. Bueno, O. Deniz, G. Cristo´bal, S. Blanco, M. Borrego-Ramos,
Automated diatom classification (Part B): a deep learning approach, Appl. Sci. 7 (2017) 460, https://doi.org/10.3390/app7050460.
T.H. Johansen, S.A. Sørensen, Towards detection and classification of microscopic
foraminifera using transfer learning, Proc. North. Light. Deep Learn. Work. 1 (2020) 6, https://doi.org/10.7557/18.5144.
R. Marmo, S. Amodio, V. Cantoni, Microfossils shape classification using a set of width values, in: 18th Int. Conf. Pattern Recognit., IEEE, 2006: pp. 691–694. 10.1109/ICPR.2006.797.
E.R. DeLancey, J.F. Simms, M. Mahdianpari, B. Brisco, C. Mahoney, J. Kariyeva, Comparing deep learning and shallow learning for large-scale wetland classification in Alberta, Canada, Remote Sens. 12 (2019) 2, https://doi.org/ 10.3390/rs12010002.
R. Pires de Lima, A. Bonar, D.D. Coronado, K. Marfurt, C. Nicholson, Deep
convolutional neural networks as a geological image classification tool, Sediment. Rec. 17 (2019) 4–9, https://doi.org/10.2110/sedred.2019.2.4.
R. Mitra, T.M. Marchitto, Q. Ge, B. Zhong, B. Kanakiya, M.S. Cook, J.
S. Fehrenbacher, J.D. Ortiz, A. Tripati, E. Lobaton, Automated species-level
identification of planktic foraminifera using convolutional neural networks, with comparison to human performance, Mar. Micropaleontol. 147 (2019) 16–24, https://doi.org/10.1016/j.marmicro.2019.01.005.
B. Wang, R. Sun, X. Yang, B. Niu, T. Zhang, Y. Zhao, Y. Zhang, Y. Zhang, J. Han, Recognition of rare microfossils using transfer learning and deep residual networks, Biology (basel). 12 (2022) 16, https://doi.org/10.3390/ biology12010016.
C. Hou, X. Lin, H. Huang, S. Xu, J. Fan, Y. Shi, H. Lv, Fossil Image Identification Using Deep Learning Ensembles of Data Augmented Multiviews (2023) 1–20. htt p://arxiv.org/abs/2302.08062.
Y. Mimura, Kazuhide;Nakamura, Kentaro;Yasukawa, Kazutaka;Sibert, Elizabeth; Ohta, Junichiro;Kitazawa, Takahiro;Kato, Applicability of Object Detection to Microfossil Research: Implications from Deep Learning Models to Detect
Microfossil Fish Teeth and Denticles Using YOLO-v7, ESS Open Arch. (2023) 1–21. 10.2254.
A.Y. Hsiang, A. Brombacher, M.C. Rillo, M.J. Mleneck-Vautravers, S. Conn,
S. Lordsmith, A. Jentzen, M.J. Henehan, B. Metcalfe, I.S. Fenton, B.S. Wade, L. Fox,
J. Meilland, C.V. Davis, U. Baranowski, J. Groeneveld, K.M. Edgar, A. Movellan,
T. Aze, H.J. Dowsett, C.G. Miller, N. Rios, P.M. Hull, Endless forams: >34,000 modern planktonic foraminiferal images for taxonomic training and automated species recognition using convolutional neural networks, Paleoceanogr.
Paleoclimatology. 34 (2019) 1157–1177, https://doi.org/10.1029/ 2019PA003612.
B.A. Masters, Mesozoic planktonic foraminifera, in: A.T.S. Ramsay (Ed.), Ocean. Micropaleontol., Academic Press, London, 1977: pp. 301–731.
L. Li, G. Keller, Maastrichtian climate, productivity and faunal turnovers in
planktic foraminifera in South Atlantic DSDP sites 525A and 21, Mar. Micropaleontol. 33 (1998) 55–86, https://doi.org/10.1016/S0377-8398(97)
00027-3.
I. Silva, W. V Sliter, Cretaceous planktonic foraminiferal biostratigraphy and evolutionary trends from the Bottaccione Section, Gubbio, Italy, in: 1995.
F. Robaszynski, M. Caron, Foraminiferes Planctoniques du Cretace: Commentaire de la zonation Europe-Mediterranee, Bull. La Soc. Geol. Fr. 6 (1995) 681–692.
J.A. Cushman, An outline of a reclassification of the foraminifera, Contrib. from
Cushman Lab. Foraminifer. Res. 3 (1927) 1–105.
Z.E.E. Reiss, The Bilamellidea nov. superfam., and remarks on Cretaceous globorotaliids Cushman Found, Foraminifreal Res. Contrib. 8 (1957) 127–145.
F. Brotzen, Foraminifera aus dem schwedischen altterti`aren Senon von Erikdal in
Schonen, Arsbok 30, Sverig. Geol. Unders., Stockholm, 1936.
J. De Lapparent, E´tude_lithologique_des_terrains_cr´etac, M´emoires pour servir a` l’explication de la carte g´eologique d´etaill´ee de la France, 1918.
F. Dalbiez, The genus Globotruncana in Tunisia, Micropaleontology 1 (1955)
161–170.
J.A. Postuma, Manual of planktonic Foraminifera, Elsevier Publishing Company, Amsterdam, 1971.



K. Simonyan, A. Zisserman, Very Deep Convolutional Networks for Large-Scale
Image Recognition, 3rd Int. Conf. Learn. Represent. ICLR 2015 - Conf. Track Proc. (2014) 1–14. http://arxiv.org/abs/1409.1556.
J. Long, E. Shelhamer, T. Darrell, Fully convolutional networks for semantic
segmentation, in: 2015 IEEE Conf. Comput. Vis. Pattern Recognit., IEEE, 2015: pp. 3431–3440. 10.1109/CVPR.2015.7298965.
J. Redmon, S. Divvala, R. Girshick, A. Farhadi, You Only Look Once: Unified, Real-
Time Object Detection, in: 2016 IEEE Conf. Comput. Vis. Pattern Recognit., IEEE, 2016: pp. 779–788. 10.1109/CVPR.2016.91.
J. Deng, W. Dong, R. Socher, L.-J. Li, Kai Li, Li Fei-Fei, ImageNet: A large-scale
hierarchical image database, in: 2009 IEEE Conf. Comput. Vis. Pattern Recognit., IEEE, 2009: pp. 248–255. 10.1109/CVPR.2009.5206848.
N. Dong, L. Zhao, C.H. Wu, J.F. Chang, Inception v3 based cervical cell
classification combined with artificially extracted features, Appl. Soft Comput. 93 (2020), 106311, https://doi.org/10.1016/j.asoc.2020.106311.
C. Szegedy, Wei Liu, Yangqing Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions, in: 2015 IEEE Conf.
Comput. Vis. Pattern Recognit., IEEE, 2015: pp. 1–9. 10.1109/ CVPR.2015.7298594.
C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna, Rethinking the Inception
Architecture for Computer Vision, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. 2016-Decem (2016) 2818–2826. 10.1109/CVPR.2016.308.
D. Zhao, J. Cao, X. Zhu, Z. Zhang, P.V. Arun, Y. Guo, K. Qian, L. Zhang, H. Zhou,
J. Hu, Hyperspectral video target tracking based on deep edge convolution feature and improved context filter, Remote Sens. 14 (2022) 6219, https://doi.org/ 10.3390/rs14246219.
M. Tog˘açar, Z. Co¨mert, B. Ergen, Intelligent skin cancer detection applying autoencoder, MobileNetV2 and spiking neural networks, Chaos Solitons Fractals 144 (2021), 110714, https://doi.org/10.1016/j.chaos.2021.110714.
M. Zhu, M. Liu, Mobile Video Object Detection with Temporally-Aware Feature
Maps, Proc. IEEE Comput. Soc. Conf. Comput. Vis Pattern Recognit. (2018) 5686–5695, https://doi.org/10.1109/CVPR.2018.00596.
M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, L.C. Chen, MobileNetV2: Inverted
Residuals and Linear Bottlenecks, Proc. IEEE Comput. Soc. Conf. Comput. Vis Pattern Recognit. (2018) 4510–4520, https://doi.org/10.1109/CVPR.2018.00474.
K. Dong, C. Zhou, Y. Ruan, Y. Li, MobileNetV2 Model for Image Classification,
Proc. - 2020 2nd Int. Conf. Inf. Technol. Comput. Appl. ITCA 2020. (2020) 476–480. 10.1109/ITCA52113.2020.00106.
K. He, X. Zhang, S. Ren, J. Sun, Deep Residual Learning for Image Recognition, in:
2016 IEEE Conf. Comput. Vis. Pattern Recognit., IEEE, 2016: pp. 770–778. 10.1109/CVPR.2016.90.
T. Liu, M. Chen, M. Zhou, S.S. Du, E. Zhou, T. Zhao, Towards understanding the importance of shortcut connections in residual networks, Adv. Neural Inf. Process. Syst. 32 (2019) 1–27. http://arxiv.org/abs/1909.04653.
K. Shaheed, A. Mao, I. Qureshi, M. Kumar, S. Hussain, I. Ullah, X. Zhang, DS-CNN: A pre-trained Xception model based on depth-wise separable convolutional neural network for finger vein recognition, Expert Syst. Appl. 191 (2022), 116288, https://doi.org/10.1016/j.eswa.2021.116288.
B. Chen, X. Liu, Y. Zheng, G. Zhao, Y.-Q. Shi, A Robust GAN-generated face detection method based on dual-color spaces and an improved Xception, IEEE
Trans. Circuits Syst. Video Technol. 32 (2022) 3527–3538, https://doi.org/ 10.1109/TCSVT.2021.3116679.
J.S. Kaiming He, Convolutional Neural Networks at Constrained Time Cost, Arxiv. Org/Abs/1412.1710 (Computer Vis. Pattern Recognition). (2014). 10.48550/ arXiv.1412.1710.
S. Jaiswal, G.C. Nandi, Robust real-time emotion detection system using CNN architecture, Neural Comput. Appl. 32 (2020) 11253–11262, https://doi.org/ 10.1007/s00521-019-04564-4.
P. Jiang, H. Fu, H. Tao, P. Lei, L. Zhao, Parallelized convolutional recurrent neural
network with spectral features for speech emotion recognition, IEEE Access 7 (2019) 90368–90377, https://doi.org/10.1109/ACCESS.2019.2927384.
I. Ozer, Pseudo-colored rate map representation for speech emotion recognition,
Biomed. Signal Process. Control. 66 (2021), 102502, https://doi.org/10.1016/j. bspc.2021.102502.
X. Liu, S. Jiang, R. Wu, W. Shu, J. Hou, Y. Sun, J. Sun, D. Chu, Y. Wu, H. Song, Automatic taxonomic identification based on the Fossil Image Dataset (>415,000 images) and deep convolutional neural networks, Paleobiology (2022) 1–22, https://doi.org/10.1017/pab.2022.14.
A.W.H. B´e, D.S. Tolderlund, Distribution and ecology of living planktonic foraminifera in surface waters of the Atlantic and Indian Oceans, in: B.M. Funnel,
W.R. Riedel (Eds.), Micropaleontol Ocean, Cambridge University Press, London, 1971, pp. 105–149.
G. Piazza, C. Valsecchi, G. Sottocornola, Deep learning applied to SEM images for
supporting marine coralline algae classification, Diversity 13 (2021) 640, https:// doi.org/10.3390/d13120640.
W. Li, S. Member, G. Wu, Q. Du, S. Member, Transferred deep learning for anomaly
detection in hyperspectral imagery, IEEE Geosci. Remote Sens. Lett. 14 (2017) 597–601, https://doi.org/10.1109/LGRS.2017.2657818.
C. Ko¨zkurt, S. Kiliçarslan, S. Bas¸, A. Elen, α-SechSig and α-TanhSig: two novel non-
monotonic activation functions, Soft Comput. (2023), https://doi.org/10.1007/ s00500-023-09279-2.
S. Kiliçarslan, C. Ko¨zkurt, S. Bas¸, A. Elen, Detection and classification of pneumonia using novel superior exponential (SupEx) activation function in convolutional neural networks, Expert Syst. Appl. 217 (2023), 119503, https://doi.org/10.1016/ j.eswa.2023.119503.
