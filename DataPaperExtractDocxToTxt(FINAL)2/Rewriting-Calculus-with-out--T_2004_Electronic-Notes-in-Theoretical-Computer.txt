Electronic Notes in Theoretical Computer Science 71 (2003)
URL: http://www.elsevier.nl/locate/entcs/volume71.html 17 pages



Rewriting Calculus with(out) Types

Horatiu Cirstea 1, Claude Kirchner, 1 and Luigi Liquori 1
LORIA, INRIA and University of Nancy 2
Campus Scientiﬁque, BP 239, 54506 Vandoeuvre-l`es-Nancy Cedex France


Abstract
The last few years have seen the development of a new calculus which can be considered as an outcome of the last decade of various researches on (higher order) term rewriting systems, and lambda calculi. In the Rewriting Calculus (or Rho Calculus, ρCal), algebraic rules are considered as sophisticated forms of “lambda terms with patterns”, and rule applications as lambda applications with pattern matching facilities.
The calculus can be customized to work modulo sophisticated theories, like commutativity, associativity, associativity-commutativity, etc. This allows us to encode complex structures such as list, sets, and more generally objects. The calculus can either be presented “`a la Curry” or “`a la Church” without sacrificing readability and without complicating too much the metatheory.
Many static type systems can be easily plugged-in on top of the calculus in the spirit of the rich type-oriented literature. The Rewriting Calculus could represent a lingua franca to encode many paradigms of computations together with a formal basis used to build powerful theorem provers based on lambda calculus and efficient rewriting, and a step towards new proof engines based on the Curry-Howard isomorphism.
Key words: Lambda calculus, Rho calculus, type systems, pattern matching, theoretical frameworks and foundations, Curry-Howard, logics, pure pattern type systems


Introduction
The ability to discriminate patterns is one of the main basic mechanisms the human reasoning is based on; as one commonly says “one picture is better than a thousand explanations”. Indeed, the ability to recognize patterns, i.e. pattern matching, is present since the beginning of information processing modeling.

1 Email: {Horatiu.Cirstea,Claude.Kirchner,Luigi.Liquori}@loria.fr
◯c 2003 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


Pattern matching occurs implicitly in many languages through the simple parameter passing mechanism, and explicitly in languages like ML and Prolog, where it can be quite sophisticated [29]. It is somewhat astonishing that one of the most commonly used model of computation, the lambda calculus, uses only trivial pattern matching. This has been extended, initially for programming concerns, either by the introduction of patterns in lambda calculi [34,36], or by the introduction of matching and rewrite rules in functional programming languages. And indeed, many works address the integration of term rewriting with lambda calculus, either by enriching first-order rewriting with higher- order capabilities [26,37,31], or by adding to lambda calculus algebraic features allowing one, in particular, to deal with equality in an efficient way [32,4,19,23]. Pattern abstractions generalize lambda abstractions by binding structured expressions instead of variables, and are commonly used to compile case- expressions in functional programming languages [34] and to provide term calculi for sequent calculi [25]. For example, the pattern abstractions λ0.0 and
λsucc(X ).X are used to compile the predecessor function λX. case X of{0 d 0 | succ(X ) d X }, whereas the pattern abstraction λ⟨X , Y⟩. X is used to encode the sequent derivation
σ, τ ▶ σ
  σ ∧ τ ▶ σ	
▶ (σ ∧ τ ) → σ
Rule abstractions generalize in turn pattern abstractions by binding arbitrary expressions instead of patterns, and are used in the Rewriting Calculus to provide a first-class account of rewrite rules and rewriting strategies. For example, rule abstractions can be used to encode innermost rewriting strategies for term rewriting systems. Furthermore, rule abstractions correspond to a form of higher-order natural deduction, where (parts of) proof trees are discharged instead of assumptions. Although such rule abstractions are a firmly grounded artifact both in logic and in programming language design and implementation, they lack established foundations.
In the Rewriting Calculus, the usual lambda abstraction λX.T is replaced by a rule abstraction T1 d T2, where T1 is an arbitrary term (in jargon a
pattern) and T2 is the argument to be fired, where the free variables of T1 are
bound (via pattern matching) in T2 .
The application of an abstraction T1 d T2 to a term T3 always “fires” and produces as result the term [T1 ¿ T3]T2 which represents a delayed matching constraint, i.e. a term where the matching equation is “put on the stack”. The matching constraint will be (self) evaluated (if a matching solution exists) or delayed (if no solution exists). If a solution σ exists, the delayed matching constraint self-evaluates to σ(T3).

The presentations is intentionally kept informal, with few definitions, no appendix, and no proofs; to stimulate the curious reader, some exercises are given. We adopt the simplest algebraic theory we know off: the syntactic


one. Quite simply, the main aim of this paper is to introduce, explain, provide examples, and stimulate the reader to hear more about the Rewriting Calculus [8,9,7,10].

Syntax
The untyped (i.e. `a la Curry) syntax of the Rho Calculus (ρCal) extends the one presented in [11,12] by adding delayed matching constraints. As in any calculus involving binders, we work modulo the “α-convention” of Church [6], and modulo the “hygiene-convention” of Barendregt [1], i.e. free and bound variables have different names. The symbol ≡ denotes syntactic identity of objects like terms or substitutions. The syntax of ρCal is defined as follows:

T ::= X | K | T d T | [T ¿ T ]T | T •T | T , T
where X represents the set of variables and K the set of constants. By abuse of notation, we denote members of these sets by the same letters possibly indexed. Notice that there are two kinds of “abstractions”:
T1 d T2 denotes a rule abstraction with pattern T1 and body T2; the free variables of T1 are bound in T2.
[T1 ¿ T2]T3 denotes a delayed matching constraint with pattern T1 ¿ T2
and body T3; the free variables of T1 are bound in T3 but not in T2.
To support the intuition, we mention here that the application of an abstraction T1 d T3 to a term T2 always “fires” and produces as result the term [T1 ¿ T2]T3 which represents a constrained term where the matching equation is “put on the stack”. The body of the constrained term will be evaluated or delayed according to the result of the corresponding matching
problem. If a solution exists, the delayed matching constraint self-evaluates to σ(T3), where σ is the solution of the matching between T1 and T2. Finally, as a sort of syntactic sugar, and directly inspired from previous works on the
ρCal, terms can be grouped together into structures built using the symbol
“,”.
We assume that the (very often hidden) application operator “•” associates to the left, while the other operators associate to the right. The priority of “•” is higher than that of “[ ¿ ] ” which is higher than that of the “d” which is, in turn, of higher priority than the “,”.
Definition 2.1 [Signatures and Abbreviations]


T1.T2
= T1 T2 T1	self-application

T (T ···T ) =Δ T	T	··· T
function-application

0	1	n	0	1	n

(Ti)i=1...n
= T1, ··· , Tn	structure


We draw the attention of the reader on the main difference between “•” denoting the application operator, and “.” denoting the object-oriented self- application operator of S. Kamin [24].

Matching
Before introducing the main machinery underneath ρCal, i.e. matching, we adapt the classical notion of simultaneous substitution application to deal with the new forms of constrained terms introduced in the ρCal.
Definition 3.1 [Substitutions]
A substitution σ is a mapping from the set of variables to the set of terms. A finite substitution has the form {T1/X1 ... Tm/Xm}; the empty substitution
{} is denoted by σID . The application of a substitution σ to a term T , denoted as usual by σ(T ), is defined as follows:


σID
(T )
=Δ T
Δ
σ(T1 d T2)
=Δ T d σ(T )
Δ

σ(K)	= K
σ([T1 ¿ T2]T3)
= [T1 ¿ σ(T2)]σ(T3)

 T
if X
∈ Dom(σ)
σ(T T )
=Δ σ(T ) σ(T )

 X	otherwise
σ(T , T )
=Δ σ(T ), σ(T )


This defines higher-order substitutions as we work modulo α-convention; when applying a substitution to an abstraction, we know that the free variables of the corresponding abstracted pattern do not belong to the domain of the substitution. This definition is compatible with the evaluation mechanism of the ρCal.
In ρCal, we deal with abstractions on patterns and their application; thus, computing the substitution which solves the matching from a pattern T1 to a subject T2 is a crucial ingredient of the calculus. We focus here on syntactic matching and we revisit the corresponding notions and algorithms. We denote
by ∆ a list of variables and we use the following definition for syntactic matching:
Definition 3.2 [Matching Equations and Solutions]
A match equation is a formula of the form T1 ≺≺∆ T2;

A  matching  system  T =
∧	Ti
i=0...n
≺≺∆i
Ti'
is a conjunction of match

equations, where ∧ is associative and commutative;
A matching system T is “successful” if it is empty or:

has the shape:	∧ Xi ≺≺∆i Ti	∧
Kj ≺≺∆j Kj;

i=0...n	j=0...m
for all h, k = 0 ... n: Xh ≡ Xk implies Th ≡ Tk;
for all i = 0 ... n: Xi ∈ ∆i implies Xi ≡ Ti;


for all i = 0 ... n, FV (Ti) ∩ ∆i /= ∅ implies Xi ≡ Ti.
The substitution σT = {T1/X1 ··· Tn/Xn} is the solution of a successful matching system T.
The engine underneath computations in ρCal solves matching constraints,
i.e. given a delayed matching constraint [T1 ¿ T2]T3, find a solution σ of the matching equation T1 ≺≺∅ T2 (if it exists), and continue the computation with σ(T3).
Definition 3.3 [Matching Algorithm ≺≺∆]
The matching substitution solving a matching equation can be computed by the following matching reduction system, where ∆' = FV (T1):

(Rule)	(T1 d T2) ≺≺∆ (T1 d T3)	❀ T2 ≺≺∆,∆' T3
(Delay) [T1 ¿ T2]T4 ≺≺∆ [T1 ¿ T3]T5 ❀ T2 ≺≺∆ T3 ∧ T4 ≺≺∆,∆' T5 (Appl)	(T1 T2) ≺≺∆ (T3 T4)	❀ T1 ≺≺∆ T3 ∧ T2 ≺≺∆ T4 (Struct) (T1, T2) ≺≺∆ (T3, T4)	❀ T1 ≺≺∆ T3 ∧ T2 ≺≺∆ T4
Starting from a matching equation T1 ≺≺∅ T2, the application of this rule set obviously terminates and either leads to an unsuccessful matching system in which case we say that the matching has failed or a substitution σ such that σ(T1) ≡ T2 is exhibited. We denote such a substitution by σ(T1¿T2).
Exercise. If you love matching algorithms:
complete the algorithm ≺≺∆ by adding the failure symbol F and enumerating all the possible reduction rules dealing with matching failures, that would lead to reductions like f (3) ≺≺∆ f (4) ❀ F;
customize the algorithm ≺≺∆ with more sophisticated algebraic theories,
e.g. the one where the “,” operator is associative and (or) commutative (hint: check the J.-M. Hullot’s or S. Eker’s algorithms [22,15]).

Semantics
Small-step Reduction Semantics
The small-step reduction semantics is defined by the reduction rules presented in Figure 1. The central idea of the (ρ) rule of the calculus is that the application of a term T1 d T2 to a term T3, reduces to the delayed matching constraint [T1 ¿ T3]T2, while (the application of) the (σ) rule consists in solving the matching equation T1 ≺≺∅ T3, and applying the obtained result to the the term T2. The rule (δ) deals with the distributivity of the application on the structures built with the “,” constructor.



Fig. 1. Small-step reduction semantics
It is important to remark that if T1 is a variable, then the subsequent combination of (ρ) and (σ) rules corresponds exactly to the (β) rule of the λ-calculus, and variable manipulations in substitutions are handled externally, using α-conversion and Barendregt’s hygiene convention if necessary.
As usual, we introduce the classical notions of one-step, many-steps, and congruence relation of →ρσδ.
Definition 4.1 [One-step, Multi-steps, Congruence of →ρσδ]
Let Ctx[−] be any context with a single hole, and let Ctx[T ] be the result of filling the hole with the term T ;
the one-step evaluation '→ρσδ is defined by the following inference rules:
T1 →ρσδ T2

Ctx[T1] '→

ρσδ
Ctx[T ] (Ctx[−])

where →ρσδ denotes one of the top-level rules of ρCal;
the multi-step evaluation →ρσδ is defined as the reflexive and transitive closure of '→ρσδ;
the congruence relation =ρσδ is the symmetric closure of →ρσδ.

Rigid Pattern Condition.
When no restrictions are imposed on the shape of terms and thus on the resulting matching equations, the small-step reduction looses the confluence property. Therefore, a suitable condition should be imposed on the shape of patterns. In this paper we adopted for ρCal the so called Rigid Pattern
Condition (RPC), that was firstly formalized in [36] and we restrict the syntax to terms of the following form:
T ::= P d T | [P ¿ T ]T | ... as before ...
with P the set of rigid patterns (i.e. terms satisfying RPC). We refer to [36,3] for a formal definition of RPC; for the purpose of this paper we just present a characterization of an “honest” subset P of T which properly contains V and satisfies RPC.
Definition 4.2 [Characterization of P] Let NF (ρσδ) be the set of terms that


cannot be reduced in the small-step reduction semantics; we define:
P =Δ {T ∈ NF (ρσδ) |T is linear with no active variables}
When a left-hand side of an application is a variable (e.g. in (X T )) we say that the respective variable X is A active.
Remark 4.3 (See [36]) The set P deﬁned by the above characterization satisﬁes RPC (i.e. its elements satisfy RPC) and properly contains V (hence lambda calculus can be encoded in ρCal). P is not the maximal set for which '→ is confluent, e.g. P =Δ P ∪ {Ω} where Ω =Δ (X d X X )(X d X X ) also satisﬁes RPC[36].
Small-step reduction semantics on terms satisfying RPC is confluent.
Proposition 4.4 (Church Rosser) The relation '→ρσδ is confluent.
In order to illustrate the small-step semantics of the calculus, we present the reduction of two terms using different evaluation strategies (outermost vs. innermost) and yielding in the first case a “successful” result (i.e. containing no delayed matching constraints) and in the second one an “unsuccessful” one.

Example 4.5 [Four small-step reductions] Take the terms
(f (X ) d (3 d 3)X ) f (3)	and	(f (X ) d (3 d 3)X ) f (4)
We reduce them, trying four possible (underlined) redexes.
(f (X ) d (3 d 3)X ) f (3) '→ρ [f (X ) ¿ f (3)]((3 d 3) X ) '→σ
	
(3 d 3) 3 '→ρ [3 ¿ 3]3 '→σ 3
	
(f (X ) d (3 d 3)X ) f (3) '→ρ (f (X ) d [3 ¿ X ]3) f (3) '→ρ
	
[f (X ) ¿ f (3)].([3 ¿ X ]3) '→σ [3 ¿ 3]3 '→σ 3
(f (X ) d (3 d 3)X ) f (4) '→ρ [f (X ) ¿ f (4)]((3 d 3) X ) '→σ
	
(3 d 3) 4 '→ρ [3 ¿ 4]3

(f (X ) d (3 d 3)X ) f (4) '→ρ (f (X ) d [3 ¿ X ]3) f (4) '→ρ
	
[f (X ) ¿ f (4)].([3 ¿ X ]3) '→σ [3 ¿ 4]3
It is worth noticing that the term [3 ¿ 4]3 represents de facto a computation failure, which can be read as follows: “an error occurred due to a matching failure”. The capability of ρCal to record failures is directly inherited from previous versions of the calculus where a special symbol null was explicitly introduced to denote computation failures.
We finish this subsection with some elaborated “object-oriented flavored” examples (see also [11]).
Example 4.6 [The Fix and P ara and Dna objects]


V ⇓ V (Red−V al)
T1 ⇓ T3 d T4	[T3 ¿ T2]T4 ⇓O 

T1 T2
⇓O	(Red−ρ1)



T1 ⇓ T3, T4	T3 T2 ⇓ O1	T4 T2 ⇓ O2 T1 T2 ⇓ O1, O2
(Red−δ)

∃σ. σ(T1) ≡ T2	σ(T3) ⇓O  (Red−σ )
[T ¿T ]T ⇓O	1
1	2	3
∄σ. σ(T1) ≡ T2

[T ¿T ]T
⇓ wrong (Red−σ2)

1	2	3
 T1 ⇓ wrong  (Red−ρ )
T1 T2 ⇓ wrong	2

Fig. 2. Big-step Operational Semantics

Let Fixf = rec d S d f (S.rec). Then, we obtain easily Fixf .rec →ρσδ f (Fix .rec). This fixed point can be generalized as Fix = rec d S d X d X (S.rec(X )) and its behavior will be Fix.rec(f ) →ρσδ f (Fix.rec(f )).
Let P ara = (par(X ) d S d S.X,a d S d 3, ...). The method par(X ) seeks for a method name that is assigned to the variable X and then sends (i.e. installs, as a first-class citizen) this method to the object itself, i.e.
Para.(par(a)) = Para (par(a)) Para →ρσδ(S d S.a) Para '→ρσδ Para.a →ρσδ 3.

Let Dna =Δ set d S d X d ((add d S' d Y d (Y, S')), X ).  The set method of Dna is used to create an object completely from scratch by receiving from outside all the components of a method, namely, the labels and the bodies. Once the object is installed, it has the capability to extend itself upon the reception of the message add. In some sense the “power” of Dna has been inherited by the created object. Then:
Dna.set(a d S d 3) = Dna set Dna (a d S d 3) →ρσδ
(X d ((add d S' d Y d (Y, S')), X )) (a d S d 3) '→ρσδ
((add d S' d Y d (Y, S')),a d S d 3) =Δ T , and
T .add(b d S d 4) →ρσδ T ,b d S d 4.

Big-step Operational Semantics
We define an operational semantics via a natural proof deduction system a` la Plotkin [35]. The purpose of the deduction system is to map every closed expression into a normal form, i.e. an irreducible term in weak head normal form. The presented strategy is lazy call-by-name since it does not work under


plain abstractions (i.e. T d T ), structures (i.e. T , T ), and algebraic terms (i.e. KT ). We define the set of values V and output values O as follows:
V ::= K| T d T | K T | T , T
O ::= V | wrong | O, O
The special output wrong represents the result obtained by a computation involving a “matching equation failure” (represented in [11] by null). The semantics is defined via a judgment of the shape T ⇓ O, and its rules (almost self explaining) are presented in Figure 2.
As in the small-step reduction semantics, the big-step semantics make use of the matching algorithm ≺≺∆ given in Definition 3.3. The big-step operational semantics is deterministic, and immediately suggests how to build an interpreter for the calculus. Moreover, big-step operational semantics is sound with respect to the relation →ρσδ, since the following holds:
Proposition 4.7 (Soundness of ⇓) For a closed T , if T ⇓ V, then T →' →ρσδ V.
Definition 4.8 [Convergence of ⇓] For a closed T , we say that T converges, and we write it as T ⇓, if there exists an output value O, such that T ⇓ O.
Given the above definition, we also conjecture the completeness, which shows that every terminating program also terminates in our interpreter.
Proposition 4.9 (Completeness of ⇓) For a closed T , if T ' →ρσδ V, then T
converges, i.e. T ⇓.
Exercise. [Call-by-value] If you want to play with big-step operational semantics, then modify the set of output values and the deduction rules of
⇓ in order to implement a lazy call-by-value strategy.
In order to illustrate the behavior of big-step semantics, we present the deduction trees of the previous two terms.
Example 4.10 [Two big-step derivations] Take the terms
(f (X ) d (3 d 3)X ) f (3)	and	(f (X ) d (3 d 3)X ) f (4)


The deduction trees are:

.


∄σ. σ(3) ≡ 4



σ ≡ {3/X}	(3 d 3)3 ⇓ 3
σ ≡ {4/X} 
(3 d 3)4 ⇓ wrong



∗	[f (X ) ¿ f (3)](3 d 3)X ⇓ 3
(f (X ) d (3 d 3)X ) f (3) ⇓ 3	and
∗	[f (X ) ¿ f (4)](3 d 3)X ⇓ wrong
(f (X ) d (3 d 3)X ) f (4) ⇓ wrong

with ∗≡ (f (X ) d (3 d 3)X ) ⇓ (f (X ) d (3 d 3)X ).
In the big-step operational semantics, the output value wrong is used in order to denote “bad” computations where matching failure occurs at run- time. As such, the presented semantics does not abort computations, as for


example in
	.	 (3 d 3, 4 d 4) 4 ⇓ wrong, 4
keeping in the final result the fact that one computation goes wrong. Of course, other choices are possible, like the one of “killing” the computation once a wrong value is produced, as in

	.	 (3 d 3, 4 d 4) 4 ⇓ wrong
This latter choice would need the modification of our big-step semantics. To resume: the first (presented) choice leads to an “optimistic” machine (at least one computation does not go wrong), while the latter choice leads to a “pessimistic” one (the machine stops if at least one wrong occurs).
Exercise. If you love natural semantics:
(pessimistic machine) modify the presented “optimistic” big-step seman- tics into a “pessimistic” one, e.g. add/modify all deduction rules raising (in premises) and propagating (from premises to conclusion) the wrong value;
(example 4.6) reduce, using the big-step operational semantics, the P ara and Dna objets: check whether the same results as for the small-step reduction semantics are obtained.

Dealing with Exceptions
In the previous section, we saw that the wrong output value aborts computations. Nevertheless, in modern programming languages one may be interested in trying some chunks of code in a protected environment, and whenever a run-time matching error occurs, catch it first, and then execute some exception handler, which can be declared many “miles” away from where the exception was raised. This is the case of the try{...}catch{...} mechanism of Java, or similar constructs in ML, C#, ... . In ρCal a possible exception can signal that some matching failure occurred at run-time, such as matching the constant 3 against another constant 4. In this case the term (3 d 3) 4 reduces to [3 ¿ 4]3 which can be read as follows:
“the result would be 3 but at run-time the program tried to match 3 against
4, yielding the (dirty) result [3 ¿ 4]3”
In the following, we present a comfortable extension of ρCal which takes into account matching exceptions and their handling. A simple exception handling mechanism for the rewriting-calculus has been already studied in [16]. By lack of space we present here only the big-step operational semantics, leaving the small-step one as an exercise. This extension was inspired from [28]. To do


(Red−V al), (Red−ρ1), (Red−σ1) as in Figure 2 
∄σ. σ(T1) ≡ T2

[T ¿T ]T
⇓ [T
¿T ] (Red−σ2)

1	2	3	1	2
	T1 ⇓ [T2 ¿ T3]	T4 ⇓ O	
(Red−Exc )
try T catch [T ¿T ] with T ⇓O	1
1	2	3	4
	T1 ⇓ O	O /≡ [T2 ¿ T3]	
(Red−Exc )

try T1 catch [T2 ¿ T3] with T4 ⇓O 
T1 ⇓ T3, T4	T3 T2 ⇓ V1	T4 T2 ⇓ V2 T1 T2 ⇓ V1, V2
2
(Red−δ)

 T1 ⇓ [T3 ¿ T4] 
(Red−Prop )
T1 T2 ⇓ [T3 ¿ T4]
T1 ⇓ T3, T4	T3 T2 ⇓ [T5 ¿ T6] (Red−Prop )
T1 T2 ⇓ [T5 ¿ T6]
T1 ⇓ T3, T4	T3 T2 ⇓ V	T4 T2 ⇓ [T5 ¿ T6] (Red−Prop )
T1 T2 ⇓ [T5 ¿ T6]	3
Fig. 3. Big-step dealing with Exception Handling
this we need first to add an exception handling constructor to the ρCal syntax,
i.e.
T ::= try T catch [T ¿ T ] with T | ... as before ...
Intuitively, [T ¿ T ] denotes a matching equation without solutions, like e.g. [3 ¿ 4]. Executing a try T1 catch [T2 ¿ T3] with T4 means that the scope of the matching failure [T2 ¿ T3] is active in T1, and that if that exception occurs, the handler T4 will be executed. Otherwise the raised exception will be propagated outside the scope of the try catch with.
More precisely: first, we evaluate T1 (the protected term). If T1 evaluates to an output without matching failures (i.e. an output value), then this value will be the result of the whole try catch with expression. This roughly corresponds to executing T1 without raising exceptions.
Counterwise, if a matching failure occurs, then we must check whether the failure is the one declared in the try catch with expression (i.e. [T2 ¿ T3]) or not; in the first case we execute the handler T4, while in the latter case we propagate the matching failure outside the scope of the try catch with expression. Note that the scope of the exception [T2 ¿ T3] ranges over T1 but not T4. In order to add an exception handling mechanism, we first modify the set of output values O as follows:


V ::= K| T d T | K T | T , T O ::= V | [T ¿ T ]
Intuitively, instead of introducing a simple wrong output signal, the special output [T ¿ T ] customizes exception signals (hence records the kind of matching failure) and ensures that exceptions can be propagated and caught correctly. Therefore, we keep the rules (Red−V al), (Red−ρ1), and (Red−σ1) and we add some extra deduction rules as shown in Figure 3.
The presented interpreter implements a “pessimistic” machine that strictly propagates the exception signals. Thus, one should notice that, according to the last three (propagation) rules, an exception signal is propagated independently of the other (possibly successful) computation. Note that the (Red−Exc2) can also be seen as a propagation rule since an exception signal
different from the one specified in the try catch with expression is strictly
propagated. If no matching failure is generated in the protected part, then the corresponding result is propagated.
Example 5.1 [One big-step derivation] The term

try (f (X ) d (3 d 3)X ) f (4) catch [3 ¿ 4] with g(4) is evaluated using the natural deduction showed below,


σ ≡ {4/X} 
∄σ. σ(3) ≡ 4


(3 d 3)4 ⇓ [3 ¿ 4]




∗	[f (X ) ¿ f (4)](3 d 3)X ⇓ [3 ¿ 4]
(f (X ) d (3 d 3)X ) f (4) ⇓ [3 ¿ 4]	f (4) ⇓ f (4)
try (f (X ) d (3 d 3)X ) f (4) catch [3 ¿ 4] withf (4) ⇓ f (4)

with ∗≡ (f (X ) d (3 d 3)X ) ⇓ (f (X ) d (3 d 3)X ).
Exercise. (i) (small-step semantics) Design the small-step reduction se- mantics for the ρCal enhanced with the new try catch with exception handler (hint: check the C and A control operators of M. Felleisen [17]);
(generalized exceptions) refine and generalize ⇓ in order to catch generalized failures like [T1 ¿ T2] representing any unsolvable matching equation trying to match a ﬁxed term T1 against any term T3, such that T2 ¿ T3 is solvable;
(more generalization) refine and generalize ⇓ of (ii) in order to declare generalized failures like [T1 ¿ T2] and capture any exception like [T3 ¿ T4], such that T1 ¿ T3 and T2 ¿ T4 are solvable;
(call-by-value) as in the previous exercise, modify ⇓ in the extended ρCal
with exceptions in order to implement a lazy call-by-value strategy.

Polymorphic Type Inference
We have presented so far an untyped (a` la Curry) syntax where the terms are not decorated with types. This section presents a simple type discipline which can be used to assign a semantical meaning to ρCal programs by statically type-checking and hence, catching some errors (unfortunately not the run-time matching one) before running the ρCal-terms.
Sophisticated typed systems were presented for the Rewriting Calculus and for lambda calculi with pattern facilities in [12,3]; those type disciplines range over simple, polymorphic, dependent, and higher-order types, following the “cubism” folklore of H. Barendregt [2].
Different type systems correspond in practice to different utilization of the ρCal: for example, dependent and higher-order types are widely used in theorem provers based on the Curry-Howard isomorphism, like Coq or Isabelle, while polymorphic types are mostly used to implement type inference algorithms for (functional) programming languages with pattern matching facilities, in the style of ML.
Here, we focus on the polymorphic type discipline; we do not discuss here the decidability of this system which is essentially an untyped presentation of the J.Y. Girard’s system F [20], as presented in D. Leivant’s polymorphic lambda calculus [27]. Nevertheless, we conjecture that the classical restrictions on universal quantifiers, as the one adopted in ML [13], suitably customized with pattern facilities, could apply also for our ρCal.
The syntax of types and contexts is defined as follows (σ, τ range over types, and α ranges over type-variables, and Γ ranges over contexts):
σ ::= α | ∀α.σ | σ d σ
Γ ::= ∅| Γ, X :σ | Γ, K:σ | α:σ
A type judgment in ρCal has the shape Γ ▶T : σ. The type inference system is defined by the rule schemas presented in Figure 4. In what follows, we briefly give a guided tour of the type inference rules and insist on the most intriguing ones.
The (Start) rules are standard and need no comments.
The (Struct) rule says that a structure (T1, T2), can be typed with the type
σ, provided that the same σ can be assigned to T1 and T2.
The (Abs) rule deals with abstractions in which we bind over (non trivial) patterns instead of variables; note that the context Γ' is charged in the premises in order to take into account the type of the free variables of T1 (possibly bound in T2).
The (Match) rule deals with terms in which a delayed matching equation occurs hard-coded into the term; this rule is essentially needed to ensure the well-typedness of terms leading to matching failures (e.g. (3 d 3) X ) and ensure the subject reduction property for the top-level rules (ρ) and (σ).
Again, Γ' records the type of the free variables of T1 (possibly bound in T3).



X :σ ∈ Γ Γ ▶X : σ
(Start1)	 K:σ ∈ Γ Γ ▶K : σ
(Start2)



Γ ▶ T1 : σ	Γ ▶ T2 : σ Γ ▶ T1, T2 : σ
(Struct)

Γ, Γ' ▶ T1 : σ	Γ, Γ' ▶ T2 : τ	Dom(Γ') = FV (T1)

Γ ▶T d T
: σ d τ	(Abs)

1	2
Γ, Γ' ▶ T1 : σ	Γ ▶ T2 : σ	Γ, Γ' ▶ T3 : τ	Dom(Γ') = FV (T1)

Γ ▶ [T1
¿T2
]T3
: τ	(Match)



Γ ▶ T1 : σ d τ	Γ ▶ T2 : σ Γ ▶ T1 T2 : τ
(Appl)

Γ ▶T : σ	α /∈ FV (Γ)
Γ ▶T : ∀α.σ	(Abs−∀)

 Γ ▶ T : ∀α.σ  (Appl−∀) Γ ▶T : σ{τ /α}

Fig. 4. Polymorphic Type Inference
The (Appl) rule is standard and needs no comments.
The (Abs−∀) and the (Appl−∀) rules introduce (resp. eliminate) polymorphic types: they are standard as in Leivant’s polymorphic lambda calculus. Note that those two rules are not syntax directed.
Theorem 6.1 (Subject Reduction) If Γ ▶ T1  : σ and T1 →ρσδ T2, then
Γ ▶ T2 : σ.
Exercise. If you really love type systems:
(normalization) show that all typable terms are strongly normalizing;
(feasable inference) find a suitable extension of the algorithm W of Damas-Milner [13] which fits with ρCal; study the complexity;
(typing exceptions) customise the type system in order to take into account try catch with exceptions (hint: check some works on exceptions in ML [21,33]);
(challenge) using the pessimistic big-step machine, show the (un)decidabi- lity of the following type soundness proposition: ∅▶T : σ, and T ⇓ O, then O /= wrong.

Conclusions
With this little “pilgrimage” we hope to have contributed to the understanding of some basic concepts of the Rewriting Calculus which is a relatively young


(but powerful) formalism. The calculus provides a well-behaved integration of (higher order) term rewriting systems and lambda calculus.
The calculus is suitable to further extensions and improvements. The possibility to plug-in sophisticated type theories open the road for the study of new powerful proof engines and (meta)languages.
New conditions less restrictive than RPC that would allow one a larger class of patterns in abstractions are worth studying.
Conceiving a denotational semantics with continuations dealing with exceptions and sophisticated (user customizable) strategies is also worth studying, the final aim being the integration of functional, and logic, and rule based programming paradigms.
The challenge of building a new type system which statically prevents the run-time match-fail errors (although we conjecture the undecidability) is very stimulating.
Exploring a limited form of decidable higher-order unification, in the style of λ-Prolog [29,30] is also challenging, the goal being to improve the automatization of theorem provers.
Finally, we conjecture that a suitable theory would allow one to deal with concurrency and, hopefully, with mobility, in the style of Join Calculus [18], Ambients [5], or Mobile Maude [14].

Acknowledgments.
Luigi would like to thank Furio Honsell and Simonetta Ronchi della Rocca, for the time spent to teach him the main “tips & tricks” underneath ML/Scheme exceptions and Girard’s system F. We all thank Benjamin Wack for a careful reading of the manuscript.

References
H. Barendregt. Lambda Calculus: its Syntax and Semantics. North Holland, 1984.
H. Barendregt. Lambda Calculi with Types. In Handbook of Logic in Computer Science, volume II, pages 118–310. Oxford University Press, 1992.
G. Barthe, H. Cirstea, C. Kirchner, and L. Liquori. Pure Pattern Type Systems. In The ACM press, editor, Proc. of POPL, 2003.
V. Breazu-Tannen. Combining Algebra and Higher-order Types. In Proc. of LICS, pages 82–90, 1988.
L. Cardelli and A. D. Gordon. Mobile Ambients. Theoretical Computer Science, 240(1), 2000.
A. Church. A Formulation of the Simple Theory of Types. Journal of Symbolic Logic, 5:56–68, 1941.


H. Cirstea. Calcul de R´e´ecriture : Fondements et Applications. Th`ese de Doctorat d’Universit´e, Universit´e Henri Poincar´e - Nancy I, 2000.
H. Cirstea and C. Kirchner. ρ-calculus. Its Syntax and Basic Properties. In
Proc. of Workshop CCL, 1998.
H. Cirstea and C. Kirchner. An Introduction to the Rewriting Calculus. Research Report RR-3818, INRIA, 1999.
H. Cirstea and C. Kirchner. The rewriting calculus — Part I and II. Logic Journal of the Interest Group in Pure and Applied Logics, 9(3):427–498, 2001.
H. Cirstea, C. Kirchner, and L. Liquori. Matching Power. In Proc. of RTA, volume 2051 of LNCS, pages 77–92. Springer-Verlag, 2001.
H. Cirstea, C. Kirchner, and L. Liquori. The Rho Cube. In Proc. of FOSSACS, volume 2030 of LNCS, pages 166–180, 2001.
L. Damas and R. Milner. Principal Type-Schemes for Functional Programs. In
Proc. of POPL, pages 207–212. The ACM Press, 1982.
F. Dura´n, S. Eker, P. Lincoln, and J. Meseguer. Principles of Mobile Maude. In Proc. of ASA/MA, volume 4 of LNCS, pages 73–85. Springer-Verlag, 2000.
S. Eker. Associative-Commutative Matching Via Bipartite Graph Matching.
The Computer Journal, 38(5):381–399, 1995.
G. Faure and C. Kirchner. Exceptions in the Rewriting Calculus. In Proc. of RTA, volume 2378 of LNCS, pages 66–82. Springer-Verlag, 2002.
M. Felleisen and D. P. Friedman.  A Syntactic Theory of Sequential State.
Theoretical Computer Science, 69:243–287, 1989.
C. Fournet, G. Gonthier, J.-J. L´evy, L. Maranget, and D. R´emy. A Calculus of Mobile Agents. In Proc. of CONCUR, volume 1119 of LNCS, pages 406–421. Springer-Verlag, 1996.
J. Gallier and V. Breazu-Tannen. Polymorphic Rewriting Conserves Algebraic Strong Normalization and Confluence. In Proc. of ICALP, volume 372 of LNCS, pages 137–150. Springer-Verlag, 1989.
J.Y. Girard. The System F of Variable Types, Fifteen Years Later. Theoretical Computer Science, 45:159–192, 1986.
C. A. Gunter, D. R´emy, and J. G. Riecke. A Generalization of Exceptions and Control in ML-like Languages. In Proc. of FPCA, volume 2378, pages 66–82. The ACM Press, 1995.
J.-M. Hullot. Associative-Commutative Pattern Matching. In Proc. of IJCAI, 1979.
J.P. Jouannaud and M. Okada. Abstract Data Type Systems. Theoretical Computer Science, 173(2):349–391, 1997.


S. N. Kamin. Inheritance in Smalltalk-80: A Denotational Definition. In The ACM press, editor, Proc. of POPL, pages 80–87, 1988.
D. Kesner, L. Puel, and V. Tannen. A Typed Pattern Calculus. Information and Computation, 124(1):32–61, 10 1996.
J.W. Klop, V. van Oostrom, and F. van Raamsdonk. Combinatory Reduction Systems: Introduction and Survey. Theoretical Computer Science, 121:279–308, 1993. Special issue in honour of Corrado Bo¨hm.
D. Leivant. Polymorphic Type Inference. In Proc. of POPL, pages 88–98. The ACM press, 1983.
L. Liquori. Semantica e Pragmatica di un Linguaggio Funzionale con le Continuazioni Esplicite. Laurea in Science dell’Informazione, University of Udine, 1990. In Italian, 74 pp.
D. Miller. A logic programming language with lambda-abstraction, function variables, and simple unification. In Proc. of ELP, volume 475 of LNCS, pages 253–281. Springer-Verlag, 1991.
D. Miller, G. Nadathur, F. Pfenning, and A. Shedrov.  Uniform Proofs as a Foundation for Logic Programming. Annals of Pure and Applied Logics, 51:125–157, 1991.
T. Nipkow and C. Prehofer. Higher-Order Rewriting and Equational Reasoning. In W. Bibel and P. Schmitt, editors, Automated Deduction — A Basis for Applications. Volume I: Foundations. Kluwer, 1998.
M. Okada. Strong Normalizability for the Combined System of the Typed λ Calculus and an Arbitrary Convergent Term Rewrite System. In Proc. of ISSAC, pages 357–363. ACM Press, 1989.
F. Pessaux and X. Leroy. Type-based Analysis of Uncaught Exceptions. ACM Transactions on Programming Languages and Systems, 22(2):340–377, 2000.
S. Peyton Jones. The Implementation of Functional Programming Languages. Prentice Hall, 1987.
G. Plotkin. A Structural Approach to Operational Semantics. Technical Report DAIMI FN-19, Computer Science Department, Aarhus University, Denmark, 1981.
V. van Oostrom. Lambda Calculus with Patterns. Technical Report IR-228, Faculteit der Wiskunde en Informatica, Vrije Universiteit Amsterdam, 1990.
D. A. Wolfram. The Clausal Theory of Types, volume 21 of Cambridge Tracts in Theoretical Computer Science. Cambridge University Press, 1993.
