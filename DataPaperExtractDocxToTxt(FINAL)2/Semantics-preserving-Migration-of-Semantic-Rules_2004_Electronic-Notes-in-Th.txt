Electronic Notes in Theoretical Computer Science 110 (2004) 133–148 
www.elsevier.com/locate/entcs


Semantics-preserving Migration of Semantic Rules During Left Recursion Removal in
Attribute Grammars
Wolfgang Lohmanna Gu¨nter Riedewalda Markus Stoya
a Department of Computer Science University of Rostock
18051 Rostock, Germany

Abstract
Several tools for source-to-source transformation are based on top down parsers. This restricts the user to use grammars without left recursion. Removing left recursion of a given grammar often makes it unreadable, preventing a user from concentrating on the original grammar. Additionally, the question arises, whether the tool implements the semantics of the original language, if it is implemented based on a different grammar than in the original language definition. Moreover, existing implementations of semantics for the original grammar cannot be reused directly.
The paper contributes to the field of automatic migration of software (here semantic rules) induced by a grammar change. It revises removal of left recursion in the context of grammar adaptations and demonstrates, that while removing left recursion at the same time the semantic rules can be migrated automatically. Thus, a programmer can continue to use semantic rules on a left recursive grammar. The problem is explained and justified.
Keywords: grammar engineering, grammar adaptation, attribute grammar, migration of semantic rules, transformation, parsing

Introduction
In the paper we consider the consequences of left recursion removal to se- mantics associated with grammar rules. Our starting point is the need for grammar engineering after semantic rules have been written for the grammar already. We will demonstrate that during automatic left recursion removal in attribute grammars semantic rules can be migrated automatically.
Grammar engineering Work with grammars is present in software devel- opment as well as in maintenance. Grammars are used to describe structure of


1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.06.006


data, to derive tools for manipulating those data, or to serve as reference be- tween developers, e.g. a language definition. As other software artifacts, gram- mars are subject to change, e.g. adaptations to make it usable for parser gen- eration, evolution of grammars (grammar corrections, changes and extensions of the language), grammar recovery from existing tools or documents, and refactoring of grammars (to make them more readable, parts better reusable, e.g. for tools adaptable to several language dialects).
Need for left recursion removal Removal of left recursion in grammars is an adaptation of the grammar to fit technical demands. Many syntactical structures are expressed naturally using recursion, often both, left and right recursion. However, there are tools like ANTLR, JavaCC, TXL, Prolog-based tools, dealing somehow with recursive descent parser generation, for the ease of combination with semantics [21], which would fall into infinite recursion. Removal of left recursion is known in compiler construction for over 40 years, and mostly considered wrt. to context-free grammars or to development of compilers. However, necessity of left recursion removal arises not only in compiler construction, but also during language development, prototyping, and in software maintenance, especially for adaptations in already used and tested grammars.
Technical challenge The first problem is that removal of left recursion leads to a badly readable grammar. More elaborate semantic rules are neces- sary. However, the user wants to work on the most comprehensible grammar, or even the reference grammar, if possible. Often the grammar is rewritten using EBNF, where left recursion turns into iteration, which might result in a problem with semantics in loops. Next, a language definition consists of syntax and semantics definitions. If the syntax is modified due to technical demands, this leads to changed semantics. Is the meaning of a language con- struct unchanged? Finally, if there are semantic rules for the left recursive grammar already (e.g. given as logic language), how are they affected by the change? Can they be reused or have all to be discarded?
Results and beneﬁts We argue the semantic meaning associated to gram- mar symbols of the original grammar can be still reconstructed after automatic left recursion removal. This will be justified for S-attributed grammar. We will discuss, how the approach can be generalised for multi-pass attribute gram- mars. Programmers benefit from our approach, because they can now work on a grammar similar to the reference grammar, i.e. one possibly containing left recursion. The adaptation of the grammar and the semantic rules can be done automatically, and can be implemented as a preprocessor, as shown in Figure 1. The approach can be combined with the above mentioned tools (e.g. ANTLR, Prolog-based tools).



Fig. 1. An example use of the approach
Remainder of the paper
Section 2 recalls the notions of attribute grammars. Section 3 uses the small example of arithmetic expressions to explain the basic idea for the trans- formation of semantic rules in Section 4. Section 5 gives a justification. Treat- ment of other kinds of attribute grammars is disussed in Section 6. Section 7 reports on practical experience so far. Section 8 points to some related work, before the paper is summarised in Section 9.

Notions of Attribute Grammars
This section recalls the definition of attribute grammars (AG). The following formal definition is similar to [1]. Semantic conditions, which can restrict the language generated by the context-free grammar are omitted without loss of generality of our approach. The semantics is as given in [1]. For the origin of attribute grammars, the reader is referred to Irons [6], and Knuth [9].
An attribute grammar without semantic conditions is a four-tuple AG = (G, SD, AD, R), where
G = (VN , VT , P, S) is the base context-free grammar. VN and VT are sets of nonterminals and terminals, V = VN ∪ VT and VN ∩ VT = ∅. P is a finite set of production rules, S ∈ VN denotes the start symbol, p ∈ P

will be written as p : Xp
→ Xp ... Xp , where np ≥ 0, Xp
∈ VN and

0
Xp ∈ V for 1 ≤ k ≤ np.
1	np	0

SD = (TY PES, FUNCS) denotes the semantic domain. TY PES is a

finite set and FUNCS a finite set of total functions with type1 × ... ×
typen → type0, n ≥ 0 and typei ∈ TY PES (0 ≤ i ≤ n).
AD = (AI, AS,TY PE) denotes the attributes. Each symbol X ∈ V gets finite sets of synthesized and inherited attributes associated, AI(X) and AS(X).  A(X) = AI(X) ∪ AS(X) and AI(X) ∩ AS(X) = ∅, and
A = ∪X∈V A(X) (for AI and AS analogously). An attribute a of some symbol X can be written X.a, if necessary for distinguishing. For a ∈ A TY PE(a) ∈ TY PES is the set of values of a (TY PE = ∪a∈ATY PE(a)).
R = ∪p∈P R(p) denotes the finite set of semantic rules associated with a

production p ∈ P . The production p : Xp → Xp ... Xp
has an attribute

0	1	np
occurrence Xp.a, if a ∈ A(Xp). The set of all attribute occurrences of
k	k
a production p is written as AO(p). It can be divided into two disjoint
subsets of defined occurrences DO(P ) and used occurrences UO(p), which are defined as follows:
DO(p)= {Xp.s | s ∈ AS(Xp)}∪ {Xp.i | i ∈ AI(Xp) ∧ 1 ≤ k ≤ np},
0	0	k	k
UO(p)= {Xp.i | i ∈ AI(Xp)}∪ {Xp.s | s ∈ AS(Xp) ∧ 1 ≤ k ≤ np}.
0	0	k	k
The semantic rules of R(p) define, how values of attribute occurrences in DO(p) can be computed as function of other attribute occurrences of AO(p). The defining rule for attribute occurrence Xp.a is of the form

Xp.a := fp (Xp .a1,... ,Xp
.am)

k	ka	k1	km

where Xp.a ∈ DO(p), fp
: TY PE(a1) × ... × TY PE(am) → TY PE(a),

k	ka

p  ∈ FUNCS and Xp
i
∈ AO(p) for 1 ≤ i ≤ m. The occurrence of

Xp.a depends on Xp .ai (1 ≤ i ≤ m). An AG is in normal form, if for
k	ki	p
each semantic rule additionally holds: Xki .ai ∈ UO(p). Each AG can be
transformed into normal form. Without loss of generality, we assume our grammar to be in normal form.
There are several subclasses of AG, among those S-attributed grammars (S-AG) and I-attributed grammars (I-AG). For S-AG is AI = ∅ and the com- putation is done bottom up, i.g. the attributes of the root node contain the determined meaning of the program. Analogously, for I-AG is AS = ∅, and the computation is top-down. The meaning is in the leaves.

Left recursion removal in an example AG
We demonstrate the basic idea using the common simple example for left recursive definition of arithmetic expressions. The context-free part of the grammar implements priority of arithmetic operators. Figure 2 gives the general algorithm for left recursion removal for context-free grammars (cf. e.g. [18]). This algorithm has to be extended to deal with semantic rules,



Fig. 2. Left recursion removal for context-free grammars

Fig. 3. Simple expression definition (left) with left recursion removed (right)
so that, in our example, expressions are calculated correctly. The left recur- sive attributed grammar for expressions is given in on the left side of Figure 3. The right side shows the context-free grammar with left recursion removed. It is not obvious at a first glance, how the semantic rules have to be mod- ified to describe the same meaning. To see how the semantic rules have to be modified, we examine the computation for the expression 1+2*3. Figure 4 depicts the constructed abstract syntax tree together with the computation of the attributes, using the original (left) and transformed (right) grammar. As can be seen on the tree from the transformed grammar, the original tree has been stretched. The given evaluation for the transformed tree presents the basic idea: The computation of synthesized attributes is redirected to in- herited attributes (i) of newly introduced nonterminals. From the leaves, the



Fig. 4. Attributed syntax tree for 1+2*3 (left) and without left recursion (right)
results are copied using synthesized attributes. The intermediate results thus are preserved and combined to the final value with different positions only. The new semantic rules to achieve such behaviour are given in Figure 5.

Fig. 5. Expression with removed left recursion and migrated semantic rules


General transformation algorithm for S-AG
The section gives the algorithm for left recursion removal for S-attribute gram- mars. The approach to migrate semantic rules guarantees that the root of the transformed syntax tree contains the same attribute values as the root in the original tree. A justification will be given in the next section.
















Fig. 6. Transformations of an S-attribute grammar, * representing inherited (on left side) and synthesized (on right side) attributes of a nonterminal
The algorithm for left recursion removal will be extended as follows (cf. Fig. 6):
for each nonterminal A' newly introduced during transformation holds:
AS(A')= AS(A)
AI (A')= {a' | a ∈ AS(A)}	with	TY PE(a')= TY PE(a)
A' gets all attributes of A, additionally an inherited attribute with the same type for each synthesized attribute of A.
During transformation of production p : A0 → A1α to p' : A' → αA'
R(p)= {A0.a := fa(Xp.a1,... ,Xp .an ) | a ∈ AS(A)}	=⇒

1
R(p')= {A' .a' := f ( p
na	a
p'
) | a' ∈ A (A')} ∪

1	a X1 .a1,... , Xna .ana	I
(2)	{A' .a := A' .a | a ∈ AS(A)}
0	1
'	⎨ A' .a' , if Xp = A1
⎩ Xp.ai, otherwise
The actual computation is redirected to the inherited attributes. For synthesized attributes new copy rules are added.
For translation of a production p : Ap → β to p' : Ap' → βA'
R(p)= {Ap.a := fa(X1.a1,... , Xn .an ) | a ∈ AS(A)}	=⇒
R(p')= {A'.a' := fa(X1.a1,... , Xn .an ) | a' ∈ AI(A)} ∪

(3)
'
A .a := A .a | a ∈ AS(A)}

Similar, but without replacements of parameters for semantic rules.
Adding a new production p : A' → ϵ requires
(4)	R(p)= {A'.a := A'.a' | a ∈ AS(A')}.
Copy rules are added from each inherited attribute to the corresponding

synthesized attribute.
During transition of a production p : Y → Xβ to p' : Y → αβ by deploying q : X → α with
R(q)= {Xq.a := fq(.. .) | a ∈ AS(X)}
R(p)= {Y p.a := fp(Xp.a1,... ,Xp .an ) | a ∈ AS(Y )}	=⇒

R(p')= {  p
a	1
:= fp(  p
na	a
p'
) | a ∈ A
(Y )}

Y  .a
a  X1 .a1,..., Xna .ana	S

⎧⎨ fq (.. .), if Xp = X
i	i
Xp.ai,  otherwise
Deploying the right hand side of a context-free rule the corresponding right hand side of a semantic rule is deployed parallely. As a consequence, Y p' .a is computed by a nested function application, which is not in line with the form given in Section 2. (The nested function application could be folded into semantic rules for the appropriate attribute to remove it.)
To sum up, the algorithm describes the transformation AG '→ AG' of an S-attributed grammar AG = (G, SD, AD, R) into AG' = (G', SD, AD', R') with G '→ G' according to the general algorithm for left recursion removal, AD '→ AD' (1), and R '→ R' (2 - 5).
Preservation of computed attribute values
Proposition: For each transformation AG '→ AG' following Section 4 holds: For each word derivable from the context-free grammar of AG and AG’ all attribute occurrences in the root nodes of the corresponding syntax trees have the same values.
Moreover, intermediate results are preserved in case of direct left recursion removal, though at different positions in the tree than in the original one.
In general, a left recursive rule is of the form
A → Aα1 | ... | Aαn | β1 | ... | βm. The choice of αi and βj does not matter for the argumentation, hence we assume A → Aα | β (with α, β ∈ V ∗). It can be seen that each such rule generates symbol sequences of the form βαn (cf. for example, [18]), similarly to the corresponding transformed rules
A → βA' and A' → αA' | ϵ. Fig. 7 shows syntax trees for the derivation βαn. The αi represent different derivations possible from α (instead of different alternatives of the rule). Note, that in general αi and β can contain subtrees
created by application of left recursive rules. Thus, they would need to be
transformed into αT and βT .
We denote root nodes in the highest level of α (all roots of the forests)

by Rα, Rα.a denotes an attribute occurrence at one of these nodes. AT
de-



Fig. 7. Syntax trees for the derivation of βαn


notes the nonterminal A at the root of the derivation tree of the transformed production.
Precondition (using structural induction on trees) is
(6)	∀a ∈ AS(Rαi ): Rαi .a = RαT .a,	∀a ∈ AS(Rβ): Rβ.a = RβT .a
Base case is the largest left recursive subtree without left recursive subtrees.
holds, because αi = αT ,β = βT . Hence, we will not distinguish between
αi and αT as well as β and βT .
For the removal of direct left recursion the induction step is to show that for the transformation depicted in Fig. 7 holds
∀a ∈ AS(A): An.a = AT .a
Therefore, we need the equation


∀i ∈ {0,..., n}∀a ∈ AS(A): Ai.a = A'
.a'

To show that it is valid, we use induction over depth of derivation trees n: Base case (n = 0):
A0.a = f (Rβ.a1,... , Rβ.ana )	cf. Def.
A' .a' = f (Rβ.a1,... , Rβ.an )	cf. (3)
1	a
‹→	A0.a = A' .a'	∀a ∈ AS(A)

Induction step (n '→ n + 1):
An+1.a = f (An.a1,... , An.ana , Rαn+1 .a1,... , Rαn+1 .am)	cf. Def.

A'	.a' = f (A'
.a' ,... , A'
.a'
, Rα
.a1,..., Rα
.am) cf. (2)

n+2
n+1  1
n+1  na
n+1
n+1

Ai.aj = A'
.a'
∀j ∈ {1,..., na}	ind.assp.

‹→	An+1.a = A'	.a'	∀a ∈ AS(A)
Thus, (8) holds for all n, and we can say that intermediate results of com- putations are preserved in computations of inherited attributes of other, well defined nodes in the transformed tree. Now holds ∀a ∈ AS(A):
∀i, j ∈ {1,...,n + 1} : A'.a = A' .a	conclusion from (2)
i	j
AT .a = A' .a	cf. (3)
0	1
‹→	AT .a = A'	.a

0	n+1
'
n+1
.a'	cf. (4)

= An.a    cf. (8)
From (5) we can conclude that attribute values in the root do not change by deployment of the right hand side of a rule while removing indirect left recursion.

Non-S-attributed grammars
I-AGs can be treated nearly analogously. Attributes are computed and copied top down. Intuitively, the procedure is turned upside down, i.e. the actual computation is done on newly added synthesized attributes and are copied downwards using existing inherited attributes. In simple multi-pass AGs, each attribute can be computed during a certain pass. We can suppose that each pass is defined by an S-AG or an I-AG. Therefore, our approach can be generalised to simple multi-pass AGs. Because a multi-pass AG can be transformed into an equivalent simple multi-pass AG such AGs can be treated, too.

Practical experiences
Prototype The given approach has been implemented as proof-of-concept pro- totype for multi-pass attribute grammar. I.e. it demonstrates the algorithm for simple examples, but is not ready for practical applications. For the im- plementation TXL [2] was chosen. For the experiments, we used grammars as





e(V) :- e(E), @"+", t(T), V is E+T.
e(V) :- e(E), @"-", t(T), V is E-T. e(V) :- t(T), V is T.

t(V) :- t(T), @"*", f(F), V is T*F.
t(V) :- t(T), @"/", f(F), V is T/F. t(V) :- f(F), V is F.

f(V) :- num(N), V is N.
f(V) :- @"(", e(E), @")", V is E.
TXL v10.3 (8.3.03) (c)1988-2003 Queen’s University Compiling ag.Txl ...
Parsing samples/exp.ag ... Transforming ...
e1(V,V3) :- @"+", t(T), e1(V,E2), E2 is V3+T.
e1(V,V4) :- @"-", t(T), e1(V,E3), E3 is V4-T. e(V) :- t(T), e1(V,V2), V2 is T.
t1(V,V7) :- @"*", f(F), t1(V,T2), T2 is V7*F.
t1(V,V8) :- @"/", f(F), t1(V,T3), T3 is V8/F.
t(V) :- f(F), t1(V,V6), V6 is F.
f(V) :- num(N), V is N.
f(V) :- @"(", e(E), @")", V is E. e1(V,V).
t1(V,V).


Fig. 8. Input (left) and output (right) of the prototype

used by Laptob [14]. Grammars are represented as logic rules in Prolog. Pred- icates represent nonterminals, @ interprets strings as terminals, and variables are attributes addressed by position. In Figure 8 the input (left) and output (right) for the prototype is given. The prototype is under reimplementation in Prolog for a smoother integration with Laptob.
A larger scenario We started to apply the approach to a 15 years evolution- ary grown YACC specification 1 describing LPC, a language for interpreted scripts in a multi-user environment 2 . The grammar currently possesses 99 rules with 310 alternatives altogether, and it is likely to change in future. We have no influence on grammar and code, as this is part of a kernel distribution for 100s of such environments. Since more than one year, complex moderni- sations of the class library are being done. As a consequence, there are 1000s of changes in the area code. Tool support is desirable, where each necessary change is specified with semantic rules according to the known grammar. For several reasons, an LL(k) grammar based tool was chosen. Figure 9 shows an extract from the context-free grammar of the definition for the expression. Even without left recursion removal, real grown grammar rules are difficult to read. The grammar rules can be automatically extracted from the YACC specification and converted in the grammar notation used for the tool. The context-free part of the grammar is then reused to specify source-to-source transformations by giving appropriate semantic rules. The above approach can then be used to transform the transformation into a form suitable for the used tool, as is demonstrated in Figure 10. Several technical problems have still to be solved. For example, ϵ-productions violate the conditions to apply the algorithm for left recursion removal.

1 http://www.ldmud.de
2 http://www.evermore.org



Fig. 9. Context-free extract from a yacc specification for expression definition

Fig. 10. Reuse of the original grammar for small maintenance transformations
Related Work
There are several approaches to left recursion removal, all of them dealing with the context-free grammar only, without caring for attributes. The gen- eral algorithm for left recursion removal is given in many compiler books, as representative see Louden [18]. He also demonstrates, how left recursion can


be avoided using EBNF-notation, and an implementation using iteration is given. Rechenberg/M¨ossenbo¨ck [21] use a translation of the grammar to syn- tax graphs, from which they construct parsers. Left recursion is handled by transforming it into iteration, while preserving the accepted language.
We mentioned the use of top-down tools for their ease of use. Pepper [20] unifies the paradigms for LR(k)- and LL(k)-parsing expressed by the formula LR(k) = 3NF + LL(k). The main aim is an easy comprehensible derivation method, easy to adapt, providing the power of LR parsing while providing efficiency known from LALR parsing. Grammars are enriched with null non- terminals, which do not change the language but may carry semantic actions or can act as assertions that guide reductions. Semantic rules are not con- sidered during the grammar transformation process. Schmeiser/Barnard [22] modify the standard table driven algorithm for bottom-up parsing to offer the programmer a top-down parse order while using a bottom-up parser. Besides states additionally rule lists are stored on the stack. When a rule is reduced, the rule lists are concatenated in suitable order.
We discussed that grammars are not only changed to implement compilers. The need of an engineering discipline for grammarware is emphasised in [8]. In [15] the authors propose an approach to the construction of grammars for existing languages. The main characteristic of the approach is that the gram- mars are not constructed from scratch but they are rather recovered by ex- tracting them from language references, compilers, and other artifacts. They provide a structured process to recover grammars including the automated transformation of raw extracted grammars and the derivation of parsers. Ex- amples for tool support for grammar engineering are Grammar Deployment Kit (GDK) [7] and F ramework for S DF T ransformation (FST) [16]. GDK provides support in the process to turn a grammar specification into a work- ing parser. FST supports the adaptation of grammars based on the syntax definition formalism SDF, where, for example, EBNF patterns are removed (YACCification) or introduced (deYACCification). Transformations by Cordy et al. to enable agile parsing based on problem-specific grammars [3,4] are ex- amples for grammar engineering as well as the transformations for deriving an abstract from a concrete syntax by Wile [23].
Theoretical work on general grammar adaptations can be found in [11]. A set of operators is defined together with properties. The operators can be used to describe grammar adaptations.
La¨mmel et al. [12,13,10] also work on grammar evolution. For example, a general framework for meta-programming is developed in [10] together with an operator suite, where its operators model schemata of program transformation, synthesis and composition. Examples are fold and unfold operations defined


on skeletons of declarative programs, i.e. attribute grammars, logic programs. Parameters are analysed and propagated through folded elements.
There is also a relation to refactoring [5,19], which can be applied to gram- mars and transformation rules. Indeed, left recursion removal could be con- sidered as a composite refactoring for grammars.
Related to this paper is a former paper on automatic migration of trans- formation rules after a grammar extension has been made [17]. The approach can be used to reuse transformation rules after a grammar extension, so that they do not break with code for the new grammar. It was shown on the prob- lem, how to make rewrite rules able to store layout information in the rewrite pattern. On the level for the rewriter, that information was invisible, thus the approach helped to reduce complexity of rewrite patterns for users.

Concluding remarks
Summary The paper contributes to the work on grammar adaptations and concentrates on semantics rules associated to grammar productions. The ap- proach attempts to reuse existing semantic rules for the new grammar. More- over, it offers the programmer of a program transformation the opportunity to specify semantic rules on a grammar closer to a grammar specification, while grammar and semantic rules can be adapted to meet technical demands, here left recursion removal. Hence, we provide the rewriter with a simpler gram- mar than necessary for the tool. The necessary transformation steps for the grammar are given, as well as a justification of the approach.
A disadvantage of the approach is the doubling of attribute numbers, and the introduction of additional copy rules. Though the added complexity is hidden, the problem might be the time overhead it adds to the process of tool construction. Semantic rules using the original grammar have to be adapted each time a tool is built from rules and grammar. In the case of interpretative used environments, e.g. in a Prolog setting, this may become annoying for larger grammars.
Future Work We are going to make the approach real life usable, the cur- rent state is still a weak prototype. There is still the problem of ϵ-productions. The algorithm could benefit from improvement by the use of lazy evaluation strategies. The approach would then only be implemented with S-AG, all other variants are automatically supported. It is also possible to construct terms instead of applying operations, then interpret the term in the root attributes. In future we will look for further grammar adaptations necessary during maintenance and investigate, if and how it is possible to derive changes for both, the software the grammar uses and for the semantic rules associated


with the grammar. We will examine, how we can connect such combined grammar/ transformation rule adaptations to more complex operations.

Acknowledgement
We would like to thank the anonymous reviewers for their suggestions and Anke Dittmar for their remarks on an earlier draft of the paper. We are grateful for collaboration with Ralf La¨mmel on the subject of grammar engi- neering and meta-programming. The idea to improve the algorithm by using a lazy evaluation strategy has been pointed out by Anke Dittmar. Jim Cordy helped us in questions concerning TXL.

References
Alblas, H., Introduction to Attribute Grammars, in: H. Alblas and B. Melichar, editors,
Attribute Grammars, Applications and Systems (SAGA 1991), LNCS 545 (1991), pp. 1–15.
Cordy, J., T. Dean, A. Malton and K. Schneider, Source Transformation in Software Engineering using the TXL T ransformation System, Journal of Information and Software Technology 44 (2002), pp. 827–837.
Dean, T., J. Cordy, A. Malton and K. Schneider, Grammar Programming in TXL, in: Proc. Source Code Analysis and Manipulation (SCAM’02) (2002).
Dean, T., J. Cordy, A. Malton and K. Schneider, Agile Parsing in TXL, Journal of Automated Software Engineering 10 (2003), pp. 311–336.
Fowler, M., K. Beck, J. Brant, W. Opdyke and D. Roberts, “Refactoring: Improving the Design of Existing Code,” Addison-Wesley, 1999.
Irons, E. T., A syntax-directed compiler for ALGOL 60, Communications of the ACM 4 (1961),
pp. 51–55.
Jan Kort and Ralf L¨ammel and Chris Verhoef, The Grammar Deployment Kit, in: M. G. v. d. Brand and R. L¨ammel, editors, Electronic Notes in Theoretical Computer Science, ENTCS 65 (2002).
Klint, P., R. L¨ammel and C. Verhoef, Towards an engineering discipline for grammarware
(2003), 32 pages, submitted for journal publication.
Knuth, D. E., Semantics of context-free languages, Mathematical Systems Theory 2 (1968),
pp. 127–145.
L¨ammel, R., “Functional meta-programs towards reusability in the declarative paradigm,” Ph.D. thesis, University of Rostock, Department of Computer Science (1999).
L¨ammel, R., Grammar Adaptation, in: Proc. Formal Methods Europe (FME) 2001, LNCS 2021
(2001), pp. 550–570.
L¨ammel, R., Evolution of Rule-Based Programs, Journal of Logic and Algebraic Programming (2004), Special Issue on Structural Operational Semantics; To appear.
L¨ammel, R. and G. Riedewald, Reconstruction of paradigm shifts, in: Second Workshop on Attribute Grammars and their Applications, WAGA 99, 1999, pp. 37–56, INRIA, ISBN 2-
7261-1138-6.


L¨ammel, R. and G. Riedewald, Prological Language Processing, in: M. G. v. d. Brand and
D. Parigot, editors, Proceedings of the First Workshop on Language Descriptions, Tools and Applications (LDTA’01), Genova, Italy, April 7, 2001, Satellite event of ETAPS’2001, ENTCS 44 (2001). URL http://www.elsevier.com/locate/entcs/volume44.html

L¨ammel, R. and C. Verhoef, Semi-automatic Grammar Recovery, Software—Practice & Experience 31 (2001), pp. 1395–1438.
L¨ammel, R. and G. Wachsmuth, Transformation of SDF syntax deﬁnitions in the ASF+SDF Meta-Environment, in: M. van den Brand and D. Parigot, editors, Proceedings of the First Workshop on Language Descriptions, Tools and Applications (LDTA’01), Genova, Italy, April 7, 2001, Satellite event of ETAPS’2001, ENTCS 44 (2001).
Lohmann, W. and G. Riedewald, Towards automatical migration of transformation rules after grammar extension, in: Proc. of 7th European Conference on Software Maintenance and Reengineering (CSMR’03) (2003), pp. 30–39.
Louden, K. C., “Compiler construction: principles and practice,” International Thomson Publishing, 1997.
Opdyke, W. F. and R. J. Johnson, Refactoring: An Aid in Designing Application Frameworks, in: Proceedings of the Symposium on Object-Oriented Programming emphasizing Practical Applications, ACM-SIGPLAN, 1990, pp. 145–160.
Pepper, P., LR Parsing = Grammar Transformation + LL Parsing, Technical Report CS-99- 05, TU Berlin (1999).
Rechenberg, P. and H. M¨ossenb¨ock, “Ein Compiler - Generator fu¨r Mikrocomputer,” Carl Hanser Verlag, 1985, in german.
Schmeiser, J. P. and D. T. Barnard, Producing a top-down parse order with bottom-up parsing, Information Processing Letters 54 (1995), pp. 323–326.
Wile, D., Abstract syntax from concrete syntax, in: Proc. International Conference on Software Engineering (ICSE’97) (1997), pp. 472–480.
