Electronic Notes in Theoretical Computer Science 53 (2001)
URL:  http://www.elsevier.nl/locate/entcs/volume53.html  12 pages



The dynamics of information exchange dialogues



Balder ten Cate 1

Institute for Logic, Language and Computation University of Amsterdam
Amsterdam, The Netherlands


Abstract
A simple model of cooperative information exchange between multiple participants is de ned, using propositional update semantics. The model is presented in the form of a reduction system. Several properties of the system are proven, concerning con uence, normalisation, properties of normal forms and reduction strategies. We end by discussing possible applications and extensions.




1	Introduction

Dynamic semantics (in its broad sense) is characterized by the fact that (1) the update e ects of utterances plays a central role, and (2) there is a shift of attention from individual sentences to discourse. For this reason, it lends itself well as a basis for the formal analysis of the pragmatics of information exchange dialogues. In this paper, we discuss a simple model of the \game of cooperative information exchange", based on propositional update semantics. As was suggested in [10], the model is formulated as an abstract reduction system.
Our starting point is Stalnaker's theory of assertions. In making assertions, people take some of their private information and make it common ground. In terms of possible world semantics, they eliminate possibilities from the common ground, which they know not to be the case [9].
At any point in a dialogue, people make choices concerning which informa- tion to exchange (which possibilities to eliminate). Typically, there are many alternatives to choose from. Notwithstanding this apparant divergence, there is a clear direction in which the conversation proceeds. During the conver- sation, the information states of the participants grow more and more alike.

1  Email:  b.ten.cate@hum.uva.nl
 c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.




Fig. 1. Process of information exchange

This process converges to a (hypothetical) situation in which there is no infor- mation left to communicate, i.e., all available information is common ground (i.e., the information that used to be distributed between them). Of course, this situation is never reached in practice. 2
If we assume for the moment that there are only two participants involved in the information exchange, then these considerations are re ected in Figure
1. The nodes of the graph represent states (i.e., Stalnakarian Contexts) and the arrows represent possible utterances, being transitions from one state to another.
The top three ovals together make up one state. In this state, the two agents each have certain information, and certain information is common ground between them. 3  At the \end state" (at the bottom of the picture) all three circles coincide. This corresponds to the hypothetical state that we discussed, in which each agent has the same information, and this information is common ground. 4
In information exchange dialogues, the participants typically have a spe- ci c goal, e.g. to resolve a decision problem [15]. We can think of such a goal as a set of states. Then, the outlined area in the bottom half of the picture represents a possible goal (the goal being to reach one of these states).
Various pragmatic notions t in this picture. For instance, relevance can be analysed as a strategy for achieving a goal. Intuitively, irrelevant utterances are utterances that will not help you to achieve your goal. This idea is further pursued in [11].
To formalise the picture of cooperative information exchange sketched here, we will combine notions from update semantics [16] and abstract reduction systems [8]. Abstract reduction systems (ARS's) form a eld of research in

2 This is an idealised model of information exchange. In practice, many complications arise (misunderstandings, mistakes, lying, etc.) that we will not address.
3 The bigger circle corresponds to the common ground. This re ects the fact that any information that is common ground, is also private information of both agents.
4 It is important to realise that Figure 1 contains only part of the general picture: only those states are depicted, that are reachable from the given starting state. The complete picture would contain all possible states as well as all possible utterances.Anticipating the discussion, in terms of reduction systems, Figure 1 gives the reduction graph of the state represented by the top three ovals.


theoretical computer science that is concerned with the reduction of terms or more abstract objects to a normal form. Combinatory logic and the lambda- calculus are the prime examples, but many other reduction systems have been devised, e.g. for braids and knots. For a general introduction, the reader is referred to [8] or [1].
The structure of the paper is as follows. First, we will formulate a model of cooperative information exchange, in the form of an ARS. Next, we will discuss some of its properties, concerning con uence, normalisation and normal forms. We will end with a discussion on possible applications and extensions.

2	Formulating the ARS

De ning an ARS involves two steps. First, one de nes a set of objects and second, one de nes a number of reduction relations over these objects. In our case, the objects will correspond to Stalnakerian \Contexts" or, as we will call them here, states. A state speci es the information that each agent has, as well as the information that is common ground between the agents.
We will keep things as simple as possible, and use ordinary propositional logic as our language. Let P be a propositional alphabet and A a nite set of agents. Let V be the set of all valuations over P . Then we de ne states as follows.
De nition 2.1 [States] A state is a function  : A[ fcg ! }(V ) such that 8a 2 A :  (a)   (c).  is the set of all states.
The c in the de nition refers to the common ground. Notice that it is required that the common ground contains less information than each of the participants has, which is a very natural requirement.
We will write  \  for a:( (a) \ (a)) and     for 8a :  (a)   (a). 5 In order to de ne the reduction relations, we need to introduce two cen-
tral notions from update semantics: support and update. These notions are
typically de ned for individual information states. Here, we will reformulate them in terms of our multi-agent states.
De nition 2.2 [Support]     if 8v 2  (a) : v j= 
This de nition states that agent a supports   (\knows that  ") in state
  whenever  is true in all the situations a considers possible (where  is a propositional formula over the given alphabet P ).
De nition 2.3 [Update]  +  = a:fv 2  (a) j v j=  g
According to this de nition, when the agents update with a sentence  , then all possibilities are eliminated in which  is not the case (from the private

5 This notation is justi ed by the fact that type-theoretically, the given de nition is equiv- alent to one in which a state is a relation between agents and possibilities.


information states as well as from the common ground). It is easy to see that the set of all states  is closed under arbitrary updates.
Having update and support at our disposal, we can de ne the reduction relations of our ARS. Each reduction step will correspond to the assertion of a proposition by an agent.
De nition 2.4 [Reduction relations]
a: 
i.  !  if   a  and  6 c  and  =  + 
a	a: 
ii.  !  if  !  for some 
iii.  !  if  !  for some a 2 A 
In a sense, these reduction relations specify the rules of the game. They specify when an agent can make an utterance and thereby reduce a state to another state: an agent can only make an utterance if he knows the content to be true, and it is not already common ground. The e ect of the utterance is a public update with this information. 6
The ARS that we will be concerned with in the rest of this paper is h  ; ( !
)a2Ai. Some notation conventions: let ! be any reduction relation. Then
 !	is the re exive closure of !. ! is the re exive, transitive closure of
 	 
 !. An object a is said to be in  !-normal form if there is no b such that
a ! b. If a ! b and b is in normal form, then b is an !-normal form of a. Whenever we talk about normal forms without mentioning a speci c reduction relation, then we mean !-normal forms.
Notice that the normal forms of our reduction relation !, being states that cannot be reduced any further, are precisely the hypothetical states that we discussed in the introduction (nobody has anything more to say).

3	Properties of the ARS

Having de ned our ARS, we now turn to some of its properties. We will be mainly concerned with con uence, normalisation and properties of the normal forms (these are central concepts from the ARS theory).
Proposition	3.1
i.  !  =) 
ii. The following diagrams hold. 7
6 As one can see, the role of the common ground c is to prevent the agents from repeating themselves. It is not possible to allow only utterances that are informative to some of the agents, for the speaker of a sentence does not know precisely the information state of the hearers. The only requirement that we can reasonably make is that when an utterance is made, the speaker considers it possible that the utterance is informative to some of the other agents. This is precisely what is done here, using the common ground.
7 The diagrams should be read as follows: given any situation conform the solid arrows, we can extend it by drawing the dashed arrows. For instance, the second diagram says that



b: 
- 
b: ! 
- 
a
 	-- 
 	-- 


			

b: 
b: 
a	a
? a	?	?	?

- 
-	 ?
-- ?
a
 ? -- ?

(subcommutativity)	(swap)	(con uence of !)	(con uence of !)
a	a
iii. If  is in  !-normal form and  !  then  is in  !-normal form.
Proof. (i) and the rst two diagrams are straightforward. The other two diagrams and (iii) follow by tiling with the rst two diagrams.	2
The last diagram of the above proposition tells us that  ! is con uent (or,
\has the Church-Rosser property"). This implies that any state has at most one normal form. We will now investigate which states have such a normal form, and what it looks like. If the propositional alphabet P is nite, then the answer is as follows.
Proposition	3.2
i. If P is nite, then ! is Strongly Normalising.
ii. If P is nite, then nf ( ) = a: Tb2A  (b)
iii. If P is nite, then  is in normal form i 8a 2 A : (a) = (c) Proof.
i. If P is nite, then so is V . Then by Proposition 3.1(i), there can be no
in nite reduction sequence.
ii. Let  = nf ( ). We must show that 8a :  (a) = Tb2A  (b).
[  ] Suppose v 62 Tb2A  (b). Then for some b, v 62  (b). Because P is
 nite, every valuation can be described completely by a  nite formula.
Let  be the complete description of v. Then   b : , so   b	But we
know that  is a normal form, so it must hold that   c	So, v 62 (c),
so v 62 (a).
[  ] Suppose v 2 Tb2A  (b). By induction on the length of the reduction
sequence from  to , we can show that v 2 Tb2A (b). From this it follows
that v 2  (a) for any a.
iii.  is in normal form i   = nf ( ). If P is nite, that means that  is in normal form i 8a :  (a) = Tb2A  (b). This is equivalent to saying that
8a 2 A :  (a) =  (c).
2

In plain words, these results can be described as follows. If the propo- sitional alphabet is nite, every state reduces to a normal form, and always in a nite number of steps. This normal form is precisely the state in which all all agents have the information that used to be distributed between them



a:  b: 
for all states  and  , if  ! !  then 
b: ! a: 
 ! ! .


(i.e. the intersection of the old information states of the agents) and all this information is also common ground.
However, this is all under the assumption that the propositional alphabet is nite. In the general case, things are a bit more complicated. In general, we do not have Strong Normalisation (in fact, some states might not even have a normal form). This means that if the agents keep on exchanging information, this process might go on forever. And even if the process ends in a normal form, it is not guaranteed that in this nal situation, all the agents have the same information. It might happen that one agent has more information then another, but he cannot communicate this information, because the language is not expressive enough (only nite sentences might be uttered). The following example illustrates this.
Example 3.3 Let P = fpn j n 2 N g and A = fa; bg. Furthermore, let state
  be such that  (a) =  (c) = V (i.e., all valuations) and  (b) = fv 2 V j v(p) = 1 for some p 2 P g. Then  is in normal form, even though agent b has more information then agent a.
In order to give precise characterisations of the normal forms of our system, we need to introduce the auxiliary notion of saturation. This is de ned in terms of ultra lters, cf. [3].
De nition 3.4 [Saturation] ^ =  a:fv 2 V j 9u 2Uf(V ) :  (a) 2 u & 8p	2
P : fw j w(p) = v(p)g 2 ug
Intuitively, ^ is a copy of in which some information is lost (some worlds are added to the information states of the agents).  The information that is lost, is precisely the inexpressible information that was causing us trouble. Consequently, in ^, all information that is available to the agents is expressible in the language.
Formally, ^ is the smallest saturated superset of  .  Furthermore, ^ is
equivalent to  , in the sense that ^    precisely if     .
Proposition	3.5
i.    ^
ii. ^ is saturated (i.e., \ nite satis ability implies satis ability")
iii. 8  :     &  is saturated =) ^ 

iv.
 ^ 
  () 

Proof.
i. Suppose v 2  (a). Let v be the principal ultra lter of v, i.e., fX  V j v 2 Xg. Then  (a) 2 v and 8p 2 P : fw j w(p) = v(p)g 2 v . Therefore, v 2 ^(a).
ii. Suppose  is nitely satis able in ^(a). Then ffw j w j=  g j  2  g [ f (a)g has the nite intersection property and can therefore be extended to an ultra lter u. Now let v be such that v(p) = 1 i fw j w(p) = 1g 2 u.


Then v and u meet the speci ed requirements, and therefore v 2 ^(a). Furthermore, v satis es  (by induction on the length of the formulae in
 ).
iii. Suppose   and  is saturated. Suppose v 2 ^(a). Then by de nition, there is an ultra lter u 2 Uf (V ) such that  (a) 2 u and 8p 2 P : fw j w(p) = v(p)g 2 u. Let be the theory of v. Then is satis able in ^(a). Because we know that u has the nite intersection property, it follows by induction on the formulae in  that  is nitely satis able in  (a). But we know that  , so then is also nitely satis able in (a). And by saturatedness of  ,  must be satis able in  . This can only be if v 2 .
iv. By induction on  .
2

Using saturation, we can generalise our results to the case where P is in nite: if a state   has a normal form, then it is  a:  (a) \ Tb2A ^(b) .
However, as was already noted, there can be states which do not have a
normal form. In general, in the absence of normal forms, co nal reduction sequences can play a similar role, functioning as a kind of in nitary version of normal forms (cf. [7]). A reduction sequence a1 ! a2 ! a3 ! ::: is called co nal if it holds that 8b : a1 ! b =) 9i : b ! ai. In our case, we will show that any co nal reduction sequence starting with  converges to
 a:  (a) \ Tb2A ^(b) .
Proposition	3.6
i. If  has a normal form, then nf ( ) = a:  (a) \ Tb2A ^(b) .
ii.  is in normal form i  8a 2 A : ^(a) = ^(c)
iii. If  1  !  2  ! ::: is a co nal reduction sequence, then Ti  i  =
 a:  1 (a) \ Tb2A ^1 (b) .
Proof.
i. Let  = nf ( ). I.e.,  ! and  is in normal form. We need to show that 8a : (a) =  (a) \ Tb2A ^(b).
[  ] Suppose v 2  (a).  Then by Proposition 3.1(i), v 2  (a).  Also
v 2 (c). Let  be the theory of v. Then  is satis able, and therefore also nitely satis able, in (c). Take any agent b 2 A. Because is in normal form, we know that 8  :   b  =)   c	From this it follows
that  is also nitely satis able in  (b). Then by Proposition 3.1(i),  is
also nitely satis able in  (b). So,  is satis able in ^(b). This can only be i v 2 ^(b).
[  ] By induction on the length of the reduction.
ii. [)] Suppose  is in normal form and v 2 ^(a). Let  be the theory of v. Then  is nitely satis able in ^(a) and therefore also in  (a). Because
  is in normal form, we have that 8  :   a   =)    c  . So,  is also
 nitely satis able in  (c). But then,   is  nitely satis able in ^(c) and


therefore also satis able in ^(c). This can only be if v 2 ^(c).
[(] Suppose 8a 2 A : ^(a) = ^(c) and suppose     . Then ^    .
But then also ^  c  , and then    c  . So, we can conclude that 8a;  :
   a  =)   c  . So  is in normal form.
iii. Suppose  1 ! 2 ! ::: is co nal. We must show that 8a : (Ti  i)(a) = 
 1 (a) \ Tb2A ^1 (b).
[ ] Suppose v 62  (a) \ Tb2A ^1 (a). Then there are two cases. The rst
case is that v 62  1 (a). In that case, trivially v 62 (Ti  i)(a). The second
case is that v 2  1(a) and v 62 Tb2A ^1 (b). Then there must be some
b 2 A such that v 62 ^1(b). We know that v 2  1 (c). Let  be the theory
of v.  is not satis able in ^1 (b) and therefore also not nitely satis able in ^ (b). So, there is a nite set  0    such that  0 is not satis able in
 ^1 (b). Let  be :^ 2 0  . Then ^1  b  and therefore  1  b  . But  1 6 c  .
So,  1 ! ( 1 + ) and v 62 ( 1 + )(a). By co nality and Proposition 3.1(i), v 62 i(a) for some i. So, v 62 Ti i.
[ ] By induction on i it can be shown that 8i8a :  i(a) \ Tb2A ^i(b)) =
 1 (a) \ Tb2A ^1 (b). Now suppose v 2  1 (a) \ Tb2A ^1 (b). Then it follows
that 8i : v 2  i(a). So, v 2 (Ti  i)(a).
2

Recapitulating, we have that if P is nite, then ! is co nal and every state  has normal form a:  (a)\ Tb2A ^(b) (which is, in that case, equal to
 a: Tb2A  (b)). Moreover, even if  does not have a normal form, any co nal
reduction sequence starting with  does converge to a:  (a) \ Tb2A ^(b) .
As we will see next, if P is countable, then for every state there is such a
co nal reduction sequence. A fortiori, if the agents all follow certain strategies, the resulting reduction sequence is guaranteed to be co nal (which means that any information that could be exchanged is exchanged at some point). To make this claim precise, consider the following standard de nition from rewriting literature [8].

De nition 3.7 A sequential reduction strategy for	 
is a map F such that

   = F( ) if  is in	 
-normal form, and

   ! F( ) otherwise.
Unlike the typical case in rewriting, we are concerned with several agents, each of which has their own strategy. Therefore, we need to de ne strategies pro les as tuples of strategies, one for each agent.
De nition 3.8 [Strategy pro les] A strategy pro le F is a tuple (Fa )a2A such that for each agent a 2 A, Fa is a sequential reduction strategy for !.
We must also require that the strategy of one agent does not make reference to the private information of another agent. Strategy pro les that have this property are called realistic.


De nition 3.9 [Realistic strategy pro les] A strategy pro le F is realistic if for all agents a 2 A and states  ;  2  it holds that if  (a) =  (a) and
 (c) =  (c) then Fa ( ) = Fa ( )
Essentially, a strategy pro le is realistic if the individual stategies of the players do not distinguish between states that should indistinguishable to them (i.e., in which they have the same information).
Given that the agents follow a certain strategy pro le and given a starting state, we can ask ourselves what happens if the agents start to communicate in accordance to their strategies. In general, the result will be a dialogue (that is, a reduction sequence), but the precise outcome depends on the particular system of turn taking that is used: although we know the strategies of the individual players, we don't know yet which player is at turn when.
At this point, it seems most sensible to make only the minimal requirement of fairness: every agent should have the oppurtunity to say something every once in a while. So, we de ne an F -dialogue to be a reduction sequence that is both in accordance to F and fair.
De nition 3.10 [Dialogue] An F -dialogue is a reduction sequence  1  !
 2 ! ::: such that
i. 8i9a 2 A :  i+1 = Fa ( i)
ii. 8a 2 A8i9j  i : either  j+1 = Fa ( j) or  j is in  !-normal form.
The rst of these two conditions speci es that the reduction sequence must be in accordance to the strategy pro le: every step is in accordance with the strategy of some agent. The second condition expresses fairness: every agents should say something every once in a while (unless he has nothing left to say). Formally, the latter requirement says that for any agent and at any moment, there should be a later moment at which the agent either makes an utterance or has nothing left to say.
Let us call a strategy pro le F co nal if all F -dialogues are co nal. Then we can prove the following.
Proposition	3.11
i. If P is nite, then every strategy pro le is co nal.
ii. If P is countable, then there are co nal realistic strategy pro les. Proof.
i. If P is nite, then ! is SN, so every reduction sequence is nite. But
then any dialogue of any strategy pro le must end in a normal form.
ii. If P is countable, then so is the set of all formulas over P . Let f be an injective mapping from formulae to natural numbers. Now de ne Fa (  ) = 
  +  , where  is the f -lowest formula such that   a  and  6 c  , or
Fa ( ) =  otherwise. Let F = (Fa )a2A. We will show that every F - dialogue is co nal.



a: 
 1  --   - 
?
?
 i
a: 
 1  --   - 
?
?
 i
a: 
 1  -- 	- 
?
?
 i
a: 
 1  --   - 



?	?	?
?	? a:	?
	0
k	k   -	k
(a)	(b)	(c)	(d)

Fig. 2. Steps in the proof of co nality
Suppose 1 ! 2 ! ::: is an F -dialogue. We must prove that for all
 , 1 ! =) 9i :  ! i. We do this by induction on the length of the reduction from 1 to . The base case (where 1 = ) is trivial. Now
a: 
for the inductive step, suppose  1 ! ! . By applying the inductive
hypothesis, we have the situation depicted in Figure 2(a).
We know that   a  , and so by monotonicity, 8j  i :  j  a  .
We also know that either there is a j  i such that j is in !-normal form, or there are in nitely many j  i's such that  j+1 = Fa ( j). In the
 rst case, let k = j. In the second case, as there are only nitely many
formulae  with f ( )  f ( ), there must be a k such that  k  c  . In either case, we have a k such that k c  (cf. Figure 2(b)).
By tiling with the subcommutativity-diagram, we come to situation

2(c). But by construction, k
 c  , so it cannot be the case that 
a: 
k !
 0 .

Therefore,   =  0 (cf. Figure 2(d)). This concludes our proof.
2
As a corrolary, we have that if P is countable, then for every state, there is a co nal reduction sequence: any fair dialogue in accordance with a co nal strategy pro le will do. 8


4	Conclusion and discussion

A model of cooperative information exchange was introduced, based on update semantics, as well as the theory of abstract reduction systems. The main focus was on the formal properties of the model. We took a very simple update semantics, namely one for propositional logic, where the worlds are propositional valuations. Also, the update mechanism is very simple: even when an assertion is made that contradicts the private information of some agents, the agents will still update with the information, ending up in an absurd information state. The reason for choosing such a naive model, was to have a \technically clean" basic framework that has clear formal properties and which is relatively easy to grasp. The model will serve as a basis for future extensions that will turn it into a more realistic model of information exchange.

8 As can be easily proven, F -dialogues exist for any strategy pro le F and starting state.


Various extensions present themselves. In [10] a start was already made with a similar system on the basis of [5]'s QL, which is a predicate logical lan- guage extended with questions. Also, attention has been directed to the theory of dynamic epistemic semantics and public announcements [4,2]. At rst sight, it seems quite straightforward to take the notion of public announcement and turn it into an ARS similar to the one presented here. However, many com- plications arise. One of the problems is that the resulting ARS is in general not con uent. 9 This topic is presently being investigated further.
In [11], some preliminary results are reported on the application of the present framework to the analysis of relevance. To this extent, a notion of communicative goal is introduced, and a notion of success relating strategies (or rather strategy pro les) to goals. In principle, such an approach can also be generalised to apply not only to assertions but also to questions, cf. [10].
Another possible application could be in the analysis of structural proper- ties of strategies for dealing with inconsistent information (which also relates to the use of corrective utterances in discourse, cf. [14,6,12]).
Finally, it is interesting to observe that the link between information ex- change and rewriting becomes even more apparent when we shift from the compositional/set-theoretic perspective of dynamic semantics to a more rep- resentational (DRT-style) one. In the latter case, information state are no longer sets of possible worlds, but rather formulas or DRT's. If we would proceed in this way, then our ARS starts to look much more like an actual term-rewriting system.


References

[1] Baader, F. and T. Nipkow, \Term rewriting and all that," Cambridge University Press, Cambridge, UK, 1998.
[2] Baltag, A., L. S. Moss and S. Solecki, The logic of public announcements, common knowledge and private suspicions, Technical report, CWI (1999).
[3] Blackburn, P., M. de Rijke and Y. Venema, \Modal logic," Cambridge University Press, Cambridge, UK, To appear.
[4] Gerbrandy, J., \Bisimulations on planet Kripke," Ph.D. thesis, ILLC, University of Amsterdam (1999).
[5] Groenendijk, J., The logic of interrogation: classical version, in: T. Matthews and D. Strolovitch, editors, Proceedings of the ninth conference on semantics and linguistics theory (SALT-9), Santa Cruz (1999).
[6] Groenendijk, J., M. Stokhof and F. Veltman, Coreference and modality in multi- speaker discourse, in: H. Kamp and B. Partee, editors, Context Dependence in the Analysis of Linguistic Meaning, I.M.S., Stuttgart, 1997 pp. 195{216.

9  [13] has shown that if we restrict ourselves to nite Kripke structures, we do have con-
 uence, as well as strong normalisation.


[7] Klop, J., \Combinatory Reduction Systems," Mathematical centre tracts 127, Mathematisch Centrum, Amsterdam, 1980.
[8] Klop, J. W., Term rewriting systems, Handbook of Logic in Computer Science 2, Oxford University Press, Oxford, 1992 pp. 1{117.
[9] Stalnaker, R., Assertion, Syntax and semantics 9, Pragmatics, Academic Press, New York, 1978 pp. 315{332.
[10] ten Cate, B., \Dynamic and epistemic semantics of questions: the logic of consultation," Master's thesis, Vrije Universiteit, Amsterdam (2000), available from    http://home.student.uva.nl/balder.tencate/.
[11] ten Cate, B., Information exchange as reduction, in: K. Striegnitz, editor, Proceedings ESSLLI 2001 Student Session, 2001.
[12] ten Cate, B. and M. Nilsenova, Representing model conversation failures with belief networks, in: Proceedings of the Twelfth Belgium-Netherlands Arti cial Intelligence Conference BNAIC '01, Amsterdam, To appear.
[13] van Benthem, J., Philosophy 298: Information update from a logical perspective (2000), available from http://turing.wins.uva.nl/~johan/298-2000.html.
[14] van Leusen, N., The interpretation of corrections, Technical Report LP-94-21, ILLC, Amsterdam (1994).
[15] van Rooy, R., Decision problems in pragmatics, in: D. Traum and M. Poesio, editors, Proceedings of GOTALOG 2000, 2000.
[16] Veltman, F., Defaults in update semantics, Journal of Philosophical Logic	25
(1996), pp. 221{261.
























12
