Electronic Notes in Theoretical Computer Science 42 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume42.html 19 pages


Operational Techniques in PVS
— A Preliminary Evaluation

Jonathan M. Ford 2 and Ian A. Mason 1,3
School of Mathematics, Statistics, & Computing Science, U.N.E Armidale, NSW 2351 Australia


Abstract
In this paper we present a preliminary analysis of the suitability of using PVS as a tool for developing operational semantics and programming logics in a semi- automatic fashion. To this end we present a formalized proof of the Church–Rosser theorem for a version of the call-by-value lambda calculus in the spirit of Landin’s ISWIM. The proof is developed in the PVS system, and is used as a test bed or benchmark for evaluating the applicability of that system for carrying out more complex operational arguments. Our approach is relatively unusual in that it is based on the named variable approach, and concentrates on the call-by-value version of the β rule. Although there are numerous computer-based proofs of the Church– Rosser theorem in the literature, all of the existing proofs eliminate the need to treat α conversion. The novel aspects of our approach are that: we use the PVS system, especially its built-in abstract data types facility, to verify a version of the Church–Rosser theorem; we formalize a version of the λ-calculus, as it normally appears in textbooks, rather than tailoring it to suit the machine or system; we treat an ISWIM variation on the call-by-value version of the λ-calculus, rather than the simpler traditional call-by-name version. However the main aim of the work reported here was to evaluate PVS as a tool for developing, state of the art, operational based programming logics for realistic programming languages.


Introduction
In this paper we present a formalized proof [4] of the Church–Rosser theorem for a version of the call-by-value lambda calculus [23] in the spirit of Landin’s ISWIM [9]. The proof is developed in the PVS [2] system, and is used as a test bed or benchmark for evaluating the applicability of that system for carrying out more complex operational arguments, such as computing with

1 The second author was partially supported by U.N.E small ARC grant No. 8202 881 499.
2 Email: jford@turing.une.edu.au
3 Email: iam@turing.une.edu.au
◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


contexts [11], developing Feferman-Landin logic [15] or proving the Curry- Howard isomorphism theorem for various versions of typed lambda calculi, and the corresponding logics [28].
Our approach is relatively unusual in that it is based on the named variable approach, and concentrates on the call-by-value version of the β rule. Our desire to handle the more complex β rule is motivated by our desire to extend this work to more realistic programming languages. The proof is based on the, now standard, Tait–Martin-Lo¨f notion of parallel reduction.
Although there are numerous computer-based proofs of the Church–Rosser theorem in the literature [26,8,25,22,17,20] (see section 5 for a brief survey), all of the existing proofs eliminate the need to treat α conversion by using reasonably standard encoding tricks. α conversion can be avoided either by eliminating the syntactic category of named variables in favour of de Bruijn indices [3], or by using the variables of the logical framework itself [6], rather than incorporating one into the encoded system.
Only the treatment by McKinna and Pollack [17] uses named variables, rather than de Bruijn indices or the variables of the logical framework itself. However McKinna and Pollack, following on in Gentzen and Prawitz’s foot- steps, make a rigorous syntactic distinction between free and bound variables. Our named variable approach differs from McKinna and Pollack in that we do not make such a distinction between free and bound variables. Conse- quently, unlike McKinna and Pollack, we must formalize α-equivalence, prior to developing the various notions of reduction. Again this desire to handle the λ-calculus as it is, rather than how the PVS system (or any other theorem prover) would prefer it to look, is motivated by our desire to extend this treat- ment to richer systems that may not be so easily streamlined. In a similar vein, McKinna and Pollack also use what they term tricky representations, that are faithful to the intuitive notion, but whose faithfulness is left unformalized. A typical example from [17] is the representation of a renaming of variables as a Lisp-style association list, i.e. a list of pairs of variables, and using a Lisp-style assoc operation to obtain the new name for a variable. The fact that such an alist represents a function is an accidental feature of assoc, as is the fact that consing onto a the front of an alist shadows any old values associated with the variable. Indeed they point out that this representation makes it very difficult to construct bijective renamings, to the point that they avoid doing so. In a similar vein McKinna and Pollack almost exclusively use lists for representations, when the natural mathematical treatments use functions. Our approach, on the other hand, elects to use the natural mathematical rep- resentation wherever possible. We will discuss this, and its consequences in more detail shortly. Thus the novel aspects of our approach are that:
we use the PVS system, especially its built-in abstract data types facility, to verify a version of the Church–Rosser theorem;
we formalize a version of the λ-calculus, as it normally appears in textbooks,

rather than tailoring it to suit the machine or system;
we treat an ISWIM variation on the call-by-value version of the λ-calculus, rather than the simpler traditional call-by-name version.
However the main aim of the work reported here was to evaluate PVS as a tool for developing, state of the art, operational based programming logics for realistic programming languages.

A Whirlwind Tour of the Church–Rosser Theorem
Following in the footsteps of [24] we provide a whirlwind tour of the call- by-value λ-calculus and the Church–Rosser Theorem. The Church–Rosser Theorem was historically taken to be a consistency proof for a system designed to be a functional foundation of Mathematics (i.e. λ-calculus) [1]. These days the λ-calculus and the Church–Rosser Theorem is part of almost any Theoretical Computer Scientist’s education.
Our treatment of the λ-calculus follows that of Landin [9] (a la ISWIM) in that we include constants and primitive operations, as well as the more usual λ- abstractions and applications. The primitive operations each posses an arity, whose existence we will suppress in the remainder of this paper. We start with an infinite set of variables, X (x, y, z range over X), a set of constants, A, and set of primitive operation symbols, O, and define by induction the set of λ-expressions Λ. For our purposes Λ is the least set satisfying:
Λ ::= X ∪ A ∪ λX.Λ ∪ Λ(Λ) ∪ O(Λ,..., Λ)
The inductive nature of Λ allows for a myriad of rank functions, as well as structural recursions. Simple definitions that use structural recursions are the sets of variables, free variables (FV(e)), and bound variables occurring in an expression. As a prelude to defining (capture avoiding) substitution, e0[x := e1], and the companion notion of renaming of bound variables (a.k.a α-conversion), careful treatments of the λ-calculus will define, by structural recursion, the notion of a variable renaming. One nice property possessed by variable renamings is that it preserves rank, unlike substitution. α-conversion and substitution are then themselves defined by structural recursion. At this
α

point it usual to define a notion of α-equivalence,
λ-expressions are now only distinguished up to
α
≡ , and either remark that
α
≡ , or much less frequently

form the quotient Λ/ ≡ . The latter of course requires first establishing that
α
≡ is a congruence, and that the operations of interest (such as renaming and
α
substitution) are functional with respect to it. The rule for deducing the ≡
α	α
of λ-abstractions, λx0.e0 ≡ λx1.e1, reduces to showing e0[x0 := y] ≡ e1[x1 := y]
for suitable y. From a logical point of view we have, at least, two choices: we can require that this hypothesis is true for some fresh y (i.e. y /∈ FV(e0) ∪ FV(e1)), or we can require that it is true for all such y. Even though these two


(β )	(λx.e)v −β→v  e[x := v]	for v a value.

(δ)	o(e ,...,e ) −β→v
v	if e ,...,e 
∈ Dom(δ) and δ(o, e ,...,e ) = v.


(Cλ)
1	n	1	n	1	n
e −β→v  e




βv
λx.e0 −→
βv
e −→
λx.e1
e

e −β→v  e

(Cleft)
0
e(e ) −β→v
1
e(e1)
(Cright)
0	1


e (e) −β→v  e (e)
1

(Cδi)
βv
e −→ e'

βv
o(e ,...,e , e,e	,...,e ) −→ o(e ,...,e , e',e	,...,e )

1	i	i+2	n	1	i	i+2	n
for 0 ≤ i ≤ n.

Fig. 1. Single Step β-value-reduction


forms will generate the same relation, the precise choice will have non-trivial consequences for the rigorous machine checked proof.
The time is now ripe to define (call-by-value) computation on λ terms. To do this one specifies the set of values, V , as a (sometimes inductively defined) subset of the λ terms, which in this case consists of constants, variables, and

λ abstractions. The single step β-value-reduction relation,
−β→v
, is parametric

in a δ function, δ : O(An) '→ V , and is generated by the rules in figure 1. As

defined
−β→v
is neither reflexive, nor transitive.

As is standard, given a relation R, we define R∗ to be the transitive reflexive closure of R. A relation R is said to have the diamond property written, ✸(R), iff

(∀e0, e1, e2)(e0 R e1 ∧ e0 R e2 ⇒ (∃e3)(e1 R e3 ∧ e2 R e3))

A relation is said to be Church–Rosser or confluent iff ✸(R∗). The Church–

Rosser theorem states that ✸( −β→v
∗
). Since
−β→v
in neither reflexive nor tran-

sitive it is not the case the ✸( −β→v
). To see this consider the following two

counterexamples. In each case the dotted arrow does not belong to
−β→v  .


Reflexivity:	(λx.y)(λw.((λx.¸x)z))



(λx.y)
,,,,,,,,
,,,,,,,,
¸¸¸¸¸¸¸¸
¸¸¸¸¸¸¸¸
¸¸¸¸zy _

λw.z¸¸¸¸¸
¸¸¸¸¸¸¸¸
¸¸¸¸¸¸¸¸

, , , ,
, , , ,
, , , ,

zy ,_.


Transitivity:	(λx.xx)(λw.((λx.¸y)z))

,,,,,,,,,
,,,,,,,,,
(λx.xx)(λw.y)
¸¸¸¸¸¸¸¸¸
¸¸¸¸¸¸¸¸¸
¸¸¸¸¸¸¸¸¸
¸¸¸¸¸¸¸¸¸
λw.(((λx.y)z)((λx.y)z))
, , , , ,
,¸,c, , ,

(λw.y)(λw.y)
The Tait–Martin-L¨of proof of this theorem involves defining a parallel re-
p
duction relation, −→ , which is reflexive, merges left and right application
reduction into a single rule, and allows, in a single step, both the abstraction and the value to be reduced in the βv reduction step, see figure 2 for the complete definition. The proof then follows from establishing three facts:
✸( −→ ) holds. This is the delicate part of the proof. Our version of the proof is a structural induction on the proof that e0 −→ e1 and proceeds by case analysis on the last step in this proof. This is not the only method of proof, for example Takahashi [29] has recently published a proof that does not analyse the reductions, but rather relies on taking the maximum parallel reduction step (called the complete development). We do not follow this version of the proof.
p	p  ∗
✸( −→ ) implies that ✸( −→ ). This actually holds for any relation R,
and has a nice geometric proof. It is also relatively simple to establish using a double induction.
L	 M1	 M2	 .. .	 M	L	 M1	 M2	 .. .	 M 


J 
N1


J 
N2	fills out to
J 
.
.
.
J	 KJ J	 KJ 
J 
.	.
.	.
.	.
 KJ 


... 

... 









.
.
.



J	J 
...	 J 

N	N	K



−p→ ∗ is the same relation as −β→v
∗
. Pollack points out [24] that this step is

usually considered trivial, but can cause problems for the named variable approach. In our version of the proof, neither of these observations is true. The proofs are non-trivial, but non-problematic.

A Summary of the Encodingand Proof
To summarize, our encoding of the λ-calculus, and the subsequent proof of the Church–Rosser theorem has the following shape:


(Prefl)	e −→ e
e −p→ e'	v −p→ v'

(Pβv )
for v a value.
(λx.e)v −p→ e'[x := v']
p

(δ)	o(e1,..., en) −→ v	if e1,..., en ∈ Dom(δ) and δ(o, e1,..., en) = v.
e0 −→ e1
(Pλ)
λx.e0 −→ λx.e1

(P	)
e0 −→ e1
e2 −→ e3
(P )
e −p→ e'
for 0 ≤ i ≤ n.

app
e (e ) −→ e (e )
δ
o(e ,...e ) −p→ o(e' ,..., e' )

0	2	1	3
1	n	1	n




Syntax:
Fig. 2. Parallel β-value-reduction

Define the syntax of the λ-expressions, and related notions of expression rank, free and bound variables, renaming, and substitution.
Alpha:

Define
α
≡ and establish that it is an equivalence (congruence) relation, and
α

that renaming, and substitution are functional modulo ≡ . Several lemmas
concerning the interaction between renaming, and substitution also need to be established.
Quotient:
α
Formalize the notion of identifying λ-expressions only up to ≡ .
β and δ:
Define single step β-value-reduction (parametric in a δ function)
Closures:
Develop a general mechanism for generating the transitive, reflexive closure of a relation, as well as a method for establishing facts about such closures (e.g. rank induction).
Parallel:
Define the notion of single step parallel reduction, and establish some basic facts concerning it. For example that it preserves values, and is preserved by substitution:
e −p→ e' ⇒ (e ∈ V ⇒ e' ∈ V )
p	p	p
(e0 −→ e1 ∧ v0 −→ v1) ⇒ e0[x := v0] −→ e1[x := v1]
Proof:
The proof now consists of the three steps described above.
✸( −→ ) holds
p	p  ∗
✸( −→ ) implies that ✸( −→ )

p	∗
−→	is the same relation as
∗
−β→v

An Overview of PVS
PVS is a verification system developed by SRI and draws on almost 20 years of experience at designing such systems. PVS has a very sophisticated type system, which includes predicate subtypes, dependent types, parameterized theories, a mechanism for defining abstract data types, numbers (both real and integral), ordinals, and forms of induction up to ϵ0. This power, of course, comes at a price. In this case the price is that typechecking is undecidable. As a consequence the typechecker generates TCCs (Type-Correctness Condi- tions) that need to be discharged either by the PVS system or its user. The advantage of the PVS type system is that preconditions and postconditions can be incorporated into a function’s type. A precondition is incorporated by declaring a more restrictive parameter type, while a postcondition is incorpo- rated by declaring a more restrictive return type.
With complicated specifications in PVS, it is possible to get overwhelmed by TCCs. Accordingly, a mechanism is provided to alleviate the buildup of TCCs via judgements, that make available more specific information to the typechecker. Judgements come in two varieties. Constant judgements state that a particular constant has a more specific type than its declared type, while subtype judgements state that one type is a subtype of another. We point out in the proof where we make use of the judgement mechanism.
A background collection of theories is provided in the PVS prelude. In- cluded are theories for numbers, set operations, finite sets, ordinals, functions, induction schemes and abstract data types, including a list definition. The prelude also contains a number of judgements.
The PVS prover accepts commands in Emacs via a Lisp-like interface. These commands consist of high level commands called strategies and a num- ber of more specific commands known as rules. Strategies are designed to tackle a broad range of problems and ideally finish proofs automatically. Rules, on the other hand, give the user much more control over the proof, although the actions taken are generally more atomic. For example, the split rule splits the current proof into a number of subproofs, while the prop strategy splits the proof and then applies propositional flattening and simplification. It is generally a good idea to attempt proofs using the higher level strategies first, resorting to lower level commands only when necessary. In addition to in- creasing the level of automation, this approach produces proofs that are more resistant to changes in the specifications.
PVS provides a mechanism for defining abstract data types (ADTs) induc- tively using a list of constructors. From these constructors, a complete set of axioms is automatically generated which contains:
Extensionality Axioms (two objects are the same if they are constructed from the same components).
Eta Axioms (an object constructed from the same components of X is identical to X)

Accessor axioms (a component of a constructor is the appropriate construc- tor argument)
Induction Schemes (for induction on the structure of the ADT)
Recursive Combinators (for defining rank functions either for the natural numbers, or the set of ordinals)
In addition to ADT axioms, PVS automatically generates induction schemes for all inductive definitions.
A PVS specification is split up into theories and data type definitions. Each theorem consists of a (possibly empty) list of parameters, importing and exporting statements, type definitions, constant definitions, function defini- tions, judgements, and lemmas. The parameters can be types, subtypes, or constants. Exporting statements are used to specify the names that are made visible to theories that are importing the current theory. Importing state- ments specify a list of theories to be imported and can be either parametrized or unparameterised.


A Tour of the Encoding of the λ-calculus and the Church–Rosser Proof
Syntax
The set of variables is defined as a type with the property that for every finite set of variables, there is a variable not contained within it. From this definition a new function can be defined on finite sets of variables, with the property that (6y ∈ Fin(X))new (y) /∈ y.
The set of λ-expressions is defined as an abstract data type.

Λ[A:
type+, O:
type+, # : [O → nat]]: datatype

begin
importing X
Var(x: X): Var?
λ(x: X, e: Λ): λ?
app(e: Λ, e': Λ): app? K(a: A): K?
δ(o: O, l: list[Λ]): δ?
end Λ
The datatype takes three parameters, a non-empty type A for the atoms, a non-empty type O for the primitive functions, and a function # which maps each primitive function to its arity.
The rank of a λ-expression is defined using the automatically generated recursive combinator (see section 3). The rank is used throughout our speci- fication for carrying out inductive proofs on λ-expressions. It is proved that

the rank of an expression is larger than the ranks of all its subexpressions.
rk(e)=1	e ∈ (X ∪ A) rk(λx.e)=1 + rk(e) rk(e(e0)) = 1 + rk(e)+ rk(e0)
rk(o(e1, e2,..., en)) = 1 + rk(e1)+ rk(e2)+ ... + rk(en)
We develop the notion of free variables (FV) via an inductive definition. FV(x)= {x}
FV(a)= {}
FV(λx.e) = FV(e) − {x}
FV(e(e0)) = FV(e) ∪ FV(e0)
FV(o(e1, e2,..., en)) = FV(e1) ∪ FV(e2) ∪ ... ∪ FV(en)
We can apply the new function to the set of free variables of an expression to get a fresh variable and thus avoid accidental capture. The problem here is that the new function is defined on finite sets of X, and FV(e) is defined as having type setof (X), so taking the new of FV(e) will lead to the generation of a TCC. Including a judgement, however stating that FV(e) ∈ Fin(X) in our specification suppresses the production of such TCCs. The prelude contains judgements about finite sets unions, intersection and so forth (e.g. (6X, Y ∈ Fin(T ))(X ∪ Y ) ∈ Fin(T )). Thus, even expressions of the form new (FV(e) ∪ FV(e0)) typecheck without producing TCCs.
Defining FV allows us to treat renaming and substitution. The renam- ing function replaces all free occurrences of one variable with another. To achieve this it may sometimes be necessary to rename the bound variables of an expression to prevent capture.
(λy.x)[x := y] /= λy.y
We do this by renaming all λ bound variables. (λy.x)[x := y]= λz.y	for some new variable z
In general for λ-abstractions, renaming is defined as
(λx.e)[y := z]= λx0.(e[x := x0][y := z])	where	x0 = new (FV(e) ∪ {y, z})
It is in defining the renaming function that we first run into trouble with TCCs. As mentioned in section 3, TCCs need to be proved by the PVS system, or the user. Unfortunately it is possible to generate unprovable TCCs, often from fairly innocuous specifications. For example, consider the lambda case

of our renaming function:
e[y := z] : Recursive Λ = Cases e of :
... 
λx.e0 : let x0 = new (FV(e) ∪ {y, z}) in
λx0.(e0[x := x0][y := z])
... 
Endcases Measure rk(e)
To prove that the function terminates, we need to show that each expres- sion in the recursive calls is smaller than the original expression. Now clearly rk(e0) < rk(e), as e0 is a subexpression of e, but in general PVS knows nothing about rk(e0[x := x0]). This will lead to the unprovable TCC:
6e' : rk(e') < rk(e)
To overcome this problem we build more information into the declared type of the renaiming function. In particular we express that the rank of its value is no greater than the rank of its argument:
e[y := z] : Recursive {e0 ∈ Λ	rk(e0) ≤ rk(e)} =	... 
This gives PVS the information it needs to establish that the nested recursion in the λ case terminates.


Alpha
We formally define


α
≡ using an inductive definition. As mentioned in sec-

tion 2, several such definitions are possible. Consider, for example, the first
α	α
case mentioned for λ-abstractions. Then λx0.e0 ≡ λx1.e1 and λx1.e1 ≡ λx2.e2
α	α
if ∃y1, y2 such that e0[x0 := y1] ≡ e1[x1 := y1] and e1[x1 := y2] ≡ e2[x2 := y2].
The problem with this is that transitivity is difficult to prove because y1 and
y2 are not necessarily the same variable (subsequent lemmas prove that the
α
choice of variables is irrelevant but rely on ≡ being transitive). The other
α
case for λ-abstractions requires e0[x0 := y] ≡ e1[x1 := y] for all y not free in e0
or e1. However this definition is unwieldy in proofs where we require the new variable to be outside the free variables of some other expression. Accordingly
α
the relation for ≡ is not either of the above, but relies instead on the existence
α
of a finite set of variables. For λx0.e0 and λx1.e1 to be ≡ , the rule requires
that 6y outside of this finite set, and not contained within the free variables of
α
either expression e0[x0 := y1] ≡ e1[x1 := y1]. This gives us the greatest control

over the new variable, and hence the greatest ease at proving theorems.
α
∃T ∈ Fin(X) where 6x /∈ T ∪ FV(e0) ∪ FV(e1) e0[x0 := x] ≡ e1[x1 := x])

α
λx0.e0 ≡ λx1.e1
α
Interestingly enough, proving the simplest properties of ≡ is quite challenging.
α
For example, the following three properties of ≡ are proved simultaneously
by induction on the rank of expressions, an approach similar to that used in [11]:
α	α
e0 ≡ e1 ⇒ e0[x := y] ≡ e1[x := y]
α
(x /= x1 ∧ x /= y1 ∧ x1 /= y) ⇒ e[x := y][x1 := y1] ≡ e[x1 := y1][x := y]
α
y /∈ FV(e) ⇒ e[x := y][y := z] ≡ e[x := z]


Quotient
In defining the quotient space modulo α equivalence,

α
≡ , we need to build a

comprehensive theory about the new type. Many of the lemmas are similar to those found in a PVS ADT file, but also require redefining such things as renaming and free variables. These are done with respect to the old functions. For example, let q be the function which maps a λ-expression to its α coset.
α
The free variables of a λ-expression of Λ/ ≡ is defined as:
FV(E)= {x	(∃e)(q(e)= E ∧ x ∈ FV(e))}


α
where E is in the quotient space Λ/ ≡ . However
fore:
q(e)= E ⇒ FV(e) = FV(E).
α
≡ preserves FV, and there-

From now on e, ei, ... will range over the newly formed quotient space. Work-
α
ing with the quotient space allows us to forget about ≡ , which makes defini-
tions and lemmas a lot more intuitive, and also makes proofs easier. The one difficulty which arises from the quotient space is that λ-abstractions now have infinitely many representations. We prove, however, the following important property about these representations:
y /∈ FV(e0) ⇒ λx.e0 = λy.e1 ⇐⇒ e1 = e0[x := y].

β and δ
The β and δ relations are defined on the quotient space, and are not inductive. The only thing of note about the β relation is that it only allows β reduction on values. The δ relation reduces primitive functions to values, and requires


(e0 R∗ e1 ∧ e0 /= e1) ⇒ (∃e)(e0 R e ∧ e R∗ e1 ∧ rk(e, e1) ≤ rk(e0, e1))

Fig. 3. Rank property for R∗
each argument to be reduced to an atom before evaluation. This relation is also parametric in a specific δ function. A predicate for a valid δ function is also defined which requires the function only to evaluate primitive functions with the correct number of arguments. In addition, certain combinations of arguments may not produce a valid result for a certain primitive operation. For example, one would assume that dividing by zero would fail to reduce under a reasonable δ function.

Closures
In defining β and δ reduction we develop the notion of the compatible closure of a relation. This is defined as being the minimal superset of the relation that is compatible with the structure of λ-expressions. In the case of β and δ, the compatible closure allows reduction of subexpressions.
e0 R e1 ⇒ λx.e0 R λx.e1 ∧ e(e0)R e(e1) ∧ e0(e)R e1(e) ∧
o(..., e0,.. .)R o(..., e1,.. .)
We use a different definition to [24] for the transitive reflexive closure of a relation.
e R∗ e	and	e0 R e1 ∧ e1 R∗ e2 ⇒ e0 R e2
To induct on the definition of the transitive reflexive closure, we define a rank. The difficulty here is that there may be more than one way to prove that a pair lies in the transitive reflexive closure. A path between two expressions e and e0 is a list whose first and last elements are e and e0 respectively, and with the property that every pair of consecutive elements are in the relation
R. We define a predicate rk?(e, e0, k) to be true if there is a path of length k + 1 between e and e0. So, for example e0 R e1 implies that rk?(e0, e1, 1) is true.
rk?(e, e, 0)
rk?(e0, e1, k) ∧ e R e0 ⇒ rk?(e, e1,k + 1)
We then take the rank rk(e, e0) of two expressions to be the minimum of all such k for which rk?(e, e0, k) holds, or 0 if ¬(e R∗ e0). This rank gives the important result shown in figure 3, which is an integral part of all inductive proofs on the transitive, reflexive closure of a relation.

Parallel

The definition of
−→ is inductive with the only difficulty coming from the
α

β-reduction and λ-abstraction cases. As in the case for ≡ , we have at least
two ways to define the relation. In this case we can either choose an individual representation for each λ-abstraction, or consider each possible representation.
p
Our −→ uses the latter approach, although it is likely that there is little
difference between the two. In fact, as soon as it is established that renaming
p
preserves −→ , the initial representation becomes irrelevant. To illustrate our
handling of λ-abstractions we provide the formal definition for the β-reduction case:
(6x /∈ FV(e))(∃e0, e1, v0, v1)(
(e = (λx.e )(v ) ∧ e' = e [x := v ] ∧ e −p→ e ∧ v −p→ v )) ⇒ e −p→ e'
Before we give a detailed analysis of the proof of ✸( −→ ) let us outline
p
our motivations for forming the quotient space. There are many possible −→
relations over the original (non quotient) Λ. The difficulty in defining such
α
a relation is how to incorporate ≡ into it. We consider the two approaches
that we attempted. Our first approach involves replacing equality, =, the Prefl
α	α	p
axiom of figure 2 of section 2 by ≡ (i.e: e ≡ e0 ⇒ e −→ e0). We had difficulty
proving that this gave us the correct transitive reflexive closure. We also could not establish the diamond lemma for the β-reduction and λ-abstraction cases.

The other approach we consider is defining
−→ without
α
≡ , and then

defining another relation, say	pα  , by:

α	α
(∃e ,e )(
)	pα	'

0	1 e ≡ e0 ∧ e ≡ e1 ∧ e0 −→ e1 ⇒ e −→ e


Unfortunately this too leads to problems in proving
λ-abstractions and δ-reduction.
−→ for applications,

Ideally we would like to add
α
≡ statements into each of the six cases, so

for example, the non-β application case would look something like (where e
and e' are applications):

α
(∃e ,e ,e ,e )(
(e )
' α	(e ) ∧ e
−→ e
∧ e −p→ e ) ⇒ e −p→ e'

0	1	2
3 e ≡ e0
1 ∧ e ≡ e2 3	0
2	1	3

Defining −→ like this is a messy process and subsequently proving anything
about it is likely to be difficult. It is clear that some mechanism is desirable
α
for removing ≡ from our definitions and lemmas, so it can be ignored except
where required. We feel that the most intuitive and elegant method is to form
α
the quotient space modulo ≡ .
Proof
Before we prove ✸( −→ ) we need to establish an important property of −→
p
that is required for the β-reduction case, namely that −→ is preserved by

substitution (see section 2.1). To see where it is used, consider the follow-
p	p	p	p
ing case in the ✸( −→ ) proof. Suppose that e −→ e1, e −→ e2, v −→ v1 and
v −→ v2. Then
(λx.e)v¸¸

,,,
,,,
  s,
¸¸¸¸¸
¸¸¸¸z˛

e1[x := v1]	e2[x := v2]
Now by the induction hypothesis we can find an e' and a v' so that ei

−p→ e'

p
and vi −→ v' for i ∈ {1, 2}. Thus we can complete the diagram:
(λx.e)v¸¸

,,,
,,,
  s,
e1[x := v¸1]
¸
¸¸¸
z˛
¸¸¸¸¸
¸¸¸¸z˛
e2[x := v2]
,,,
,,,
, s

e'[x := v']


The λ-abstraction case requires only that Suppose e −→ ei for i ∈ {1, 2}. Then
(λx.e)¸¸
−→ is preserved by renaming.

sss
ss
s,s
¸¸¸¸
¸¸¸z 

λx.e1	λx.e2
Thus by the induction hypothesis, there exists an e' such that e −p→ e' for i ∈ {1, 2}. Now for any y /∈ FV(e1) we can complete the diagram using λy.e'[x := y], since:
,,,,,,, λx.e ¸¸¸¸¸¸¸¸

,,,,,
,_,,.,
λy.e1[x := y] = ¸λx.e1
¸¸¸¸¸¸¸¸
¸¸¸¸¸¸¸¸
¸¸¸¸¸
¸¸¸z_
λx.e2, = λy.e2[x := y]
,,,,,,,,
,_,,.,,,,,

λy.e'[x := y]

The primitive operation case causes another problem as there are two ways for such an expression to reduce, namely by δ-reduction or by reduction on each of its arguments. Fortunately δ-reduction can only be performed if the arguments are all atoms. Furthermore, it is not hard to prove that under
p	p
−→ , atoms can only reduce to themselves.	Suppose that o(a¯) −→ v0 and
o(a¯) −p→ o(¯b) where a −→ b for 1 ≤ i ≤ n. However a ∈ A implies that
i	i
a = b . Thus o(¯b) −p→ v .
i	i	0
p
All in all, proving the diamond lemma for −→ is the hardest step in our
proof. The lemma is split up into different sub-lemmas (one for each case), to make editing, and revising the proofs easier.



Proving that
−p→ ∗ =
−β→v
∗ is a relatively simple process in comparison.

The proof consists of a number of separate lemmas which are given below:


(PBs)	e −p→ e	⇒ e −β→v
(PsBs)	e −p→ ∗e	⇒ e −β→v
∗e0
∗e0

(BPs)	e −β→v
(BsPs)	e −β→v
e	⇒ e −p→ ∗e
∗e	⇒ e −p→ ∗e



The lemmas (PBs) and (BPs) are proved by induction on the relevant in- ductive definition (parallel reduction and compatible closure respectively). In contrast, the proofs of (PsBs) and (BsPs) are carried out by induction on the rank of the transitive reflexive closure.
Previous, Current and Subsequent Work
We finish of this paper with a discussion of: previous related work, the con- clusions drawn from the work presented here, and finally our work with PVS subsequent to the work reported here.
Previous Work
Presumably because of its importance to the foundations of (Theoretical) Computer Science, the Church–Rosser theorem has been the subject of several machine based theorem proving studies [26,8,25,22,17,20].
The earliest treatment was by Shankar using the Boyer-Moore theorem prover [26], and later appears as a chapter in his PhD thesis [27]. The formal- ization of the λ-calculus uses de Bruijn indices, and the proof is the standard Tait–Martin-Lo¨f version. One notable point about this proof is that it is carried out in a very weak logic, one that has no explicit quantifiers.
The next treatment was Huet’s formal development of the theory of residu- als in the λ-calculus using the Coq system [8]. He uses de Bruijn indices in his formalization and establishes Church–Rosser as a corollary to his treatment of residuals.
Rasmussen [25] ports Huet’s treatment to Isabelle. The emphasis of his treatment is on the difficulties involved in translating one mechanical proof on one platform to another mechanical proof on another platform.
Nipkow [20] presents a very general and abstract treatment of Tait–Martin- L¨of style proofs of Church–Rosser in Isabelle. His treatment is based on a general theory of commutating relations, and covers both β and η reduction systems. He also encodes and compares both the original proof that parallel reduction has the diamond property, as well as the more recent one due to Takahashi [29].

Pfenning in [22] presents a development of the Tait–Martin-Lo¨f proof in his Elf implementation of the Edinburgh LF [6]. The novel aspect of this treatment is that it uses higher order abstract syntax to encode the lambda calculus. This encoding does not have a syntactic category for variables of the (object) λ calculus, but rather uses the variables of the LF framework. For example the λ constructor is modeled by a constant in the framework of the form λ : (Λ '→ Λ) '→ Λ, where Λ is the syntactic category corresponding to (object) λ expression.
Conclusions Concerningthe Work Reported Here
Our work differs from the previous work reported above in two important ways. The first and most obvious difference is that we use the PVS system, whereas the work reported above relied on older systems. Prior to the work reported here, little use had been made of the abstract datatype facility in PVS. The work reported here helped debug these facilities of PVS, and thus helped refine the system. This refinement of the PVS system is an ongoing process, for example the prover doesn’t automatically apply the correct extensionality and eta axioms, so that the specific axiom needs to be explicitly stated in the prover command. However, the bottom line is that the abstract datatype mechanism is extremely useful in encoding operational approaches to semantics, as is demonstrated by our subsequent work.
The second and more important difference is that we directly formalize and reason about α equivalence. Something that has not been done previously, to our knowledge. Indeed the main conclusion of this work, and of our subsequent work as well, is that it is indeed possible to formalize α equivalence, and remain faithful to the presentations found in text books and journals.
PVS Statistics
The actual proof of Church–Rosser in PVS took the first author approximately four months, although some of this time was spent learning PVS. Some time was also wasted attempting a direct proof of Church–Rosser without first forming the quotient space. The actual machine checked proof involves the proving of two hundred and thirty six (236) distinct facts, and takes PVS three hundred and sixty seconds (362) of CPU time running on a Linux ma- chine configured with 2 GBytes of main memory and 4×550 MHz Xeon PIII processors. The dump file containing all the PVS definitions, facts, and proofs is 2.396 MBytes and is available from http://mcs.une.edu.au/~pvs/ [4].
Subsequent Work
After successfully carrying out this first experiment reported here. We under- took a second sophisticated and substantial use of PVS, one that established a recent result in operational semantics. This experiment was of interest not

only because it required the substantial development of current higher order techniques in operational semantics, but also because it exposed several gaps in the published presentation of the result. Thus this experiment exempli- fies the possible benefit of serious formalization offers standard mathematical practice, which typically leaves much unsaid.
Much work has been done to develop methods for reasoning about oper- ational approximation and equivalence. An early example is Robin Milner’s context lemma [18] which greatly simplifies the proof of operational equiv- alence in the case of the typed λ calculus by reducing the contexts to be considered to a simple chain of applications. Mason and Talcott [13,14] in- troduced the CIU characterization of operational equivalence which is a form of context lemma for imperative languages. This lemma was then generalized by Carolyn Talcott to a very wide class of programming languages in [30]. It is this lemma that we verified in this second experiment. This lemma is fundamental to our formalization effort since it is the corner stone upon which we define the semantics of our specification logic [15]. Again we took great pains to formalize the actual theoretical treatment, rather than adapting it to the tastes of both the machine, and PVS. The results of this experiment have been briefly discussed at [12] and appear as [5].
Acknowledgements
In the course of our work we uncovered several bugs in PVS’s implementation. We wish to thank explicitly Sam Owre and Shankar at SRI in Menlo Park for promptly fixing these bugs, providing timely advice, and encouragement, and thus allowing our work to reach fruition. We would also like to thank Carolyn Talcott for providing constructive criticism, as well as encouragement. The two anonymous CATS’01 referees must also be thanked for their insightful comments, that helped improve both the veracity and presentation of this paper.

References
A. Church and J.B. Rosser. Some properties of conversion. Transactions of the AMS, Volume 39, pages 472–482, 1936.
J. Crow, S. Owre, J. Rushby, N. Shankar and M. Srivas. A Tutorial Introduction to PVS. Technical report, SRI International, 1995. Presented at WIFT ’95: Workshop on Industrial-Strength Formal Specification Techniques, Boca Raton, Florida.
N. G. de Bruijn. Lambda-Calculus Notation with Nameless Dummies: a Tool for Automatic Formula Manipulation with Application to the Church-Rosser Theorem. Indagationes Mathematicae, Volume 34, Number 5, pages 381–392,
1972.


J. Ford. The Church–Rosser theorem in PVS, 2000. PVS dump file (2.4 Megabytes) available at http://mcs.une.edu.au/~pvs/.
J. Ford and I. A. Mason. Establishing a General Context Lemma in PVS. In Proceedings of the 2nd Australasian Workshop on Computational Logic, AWCL’01 , 2000. submitted.
R. Harper, H. Honsell and G. Plotkin. A framework for defining logics. In
Second Annual Symposium on Logic in Computer Science. IEEE, 1987.
G. Huet. Residual Theory in λ-Calculus: A Formal Development. Technical Report 2009, INRIA, 1993.
G. Huet. Residual Theory in λ-Calculus: A Formal Development. Journal of Functional Programming, Volume 4, Number 3, pages 371–394, 1994. An earlier version appeared as [7].
P. J. Landin. A correspondence between Algol60 and Church’s lambda notation.
Comm. ACM, Volume 8, pages 89–101, 158–165, 1965.
I. A. Mason. Parametric Computation. In James Harland (editor), Proceedings of the Australasian Theory Symposium, CATS ’97, pages 103 – 112, 1997.
I. A. Mason. Computing with contexts. Higher-Order and Symbolic Computation, Volume 12, pages 171–201, 1999. An abridged version appears as [10].
I. A. Mason. A second glance at Feferman-Landin logic, 2000. Invited talk, HOOTS ’00 Montreal, Canada, September 2000.
I. A. Mason and C. L. Talcott. Programming, transforming, and proving with function abstractions and memories. In Proceedings of the 16th EATCS Colloquium on Automata, Languages, and Programming, Stresa, Volume 372 of Lecture Notes in Computer Science, pages 574–588. Springer-Verlag, 1989.
I. A. Mason and C. L. Talcott. Equivalence in functional languages with effects.
Journal of Functional Programming, Volume 1, pages 287–327, 1991.
I. A. Mason and C. L. Talcott.	Feferman–Landin Logic.	In W. Sieg,
R. Sommer and C. Talcott (editors), Reflections – A symposium honoring Solomon Feferman on his 70th birthday. to appear in Lecture Notes in Logic, 2000.
J. McKinna and R. Pollack. Pure Type Systems Formalized. In M. Bezem and
J. F. Groote (editors), Typed Lambda Calculi and Applications, Volume 664 of
Lecture Notes in Computer Science, pages 289 – 305. Springer Verlag, 1993.
J. McKinna and R. Pollack. Some Lambda Calculus and Type Theory Formalized. Journal of Automated Reasoning, Volume 23, 1999. An abridged version appeared as [16].
R. Milner. Fully abstract models of typed λ-calculi. Theoretical Computer Science, Volume 4, pages 1–22, 1977.


T. Nipkow. More Church-Rosser Proofs (in Isabelle/HOL). In M. McRobbie and J.K. Slaney (editors), Automated Deduction – CADE-13, Volume 1104 of Lecture Notes in Computer Science, pages 733–747. Springer Verlag, 1996.
T. Nipkow. More Church-Rosser Proofs (in Isabelle/HOL), 2000. to appear in
Journal of Automated Reasoning. An abridged version appears as [19].
F. Pfenning. A Proof of the Church-Rosser Theorem and its Representation in a Logical Framework. Technical Report CMU-CS-92-186, Carnegie Mellon University, 1992.
F. Pfenning. A Proof of the Church-Rosser Theorem and its Representation in a Logical Framework. Journal of Automated Reasoning (to appear), 2000. An earlier version appears as [21].
G. Plotkin. Call-by-name, call-by-value and the lambda calculus. Theoretical Computer Science, Volume 1, pages 125–159, 1975.
R Pollack. Polishing up the Tait-Martin-Lo¨f Proof of the Church–Rosser Theorem. Unpublished note, available from ftp://ftp.cs.chalmers.se/pub/ users/pollack/churchrosser.dvi.gz, 1995.
O. Rasmussen. The Church–Rosser theorem in Isabelle: A proof porting experiment. Technical Report 364, University of Cambridge, Computer Laboratory, 1995.
N. Shankar. A Mechanical Proof of the Church-Rosser Theorem. Journal of the Association for Computing Machinery, Volume 35, Number 3, pages 475–522, 1988.
N. Shankar. Metamathematics, Machines, and G¨odel’s Proof. Cambridge University Press, 1994.
M. Sorensen and P. Urzyczyn. Lectures on the Curry-Howard Isomorphism. Technical Report 14, DIKU Report, 1998.
M. Takahashi. Parallel reductions in the λ-calculus. Information and Computation, Volume 118, pages 120–127, 1995.
C. L. Talcott. Reasoning about functions with effects. In Higher Order Operational Techniques in Semantics. Cambridge University Press, 1996.
