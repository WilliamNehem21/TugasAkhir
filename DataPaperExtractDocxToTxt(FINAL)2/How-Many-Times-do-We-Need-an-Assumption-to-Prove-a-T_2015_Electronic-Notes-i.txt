Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 315 (2015) 31–46
www.elsevier.com/locate/entcs

How Many Times do We Need an Assumption to Prove a Tautology in Minimal Logic?
Examples on the Compression Power of Classical Reasoning ?

Edward Hermann Haeusler Departamento de Inform´atica PUC-Rio
Rio de Janeiro, Brazil

Abstract
In this article we present a class of formulas ϕn, 0 ≤ n, that need at least 2n assumption occurrences of other formula βn in any normal proof in Natural Deduction for purely implicational minimal propositional logic (M→). In classical implicational logic, each ϕn have normal proofs using at most one assumption occurrence. As a consequence, normal proofs of ϕn have exponential lower bound in M→ and linear lower bound in its classical version. In fact, 2n is the lower-bound for cut-free Sequent proofs too. The existence of this class of formulas have strong influence in designing automatic proof-procedures based in such systems. It is discussed proof-theoretically how tautologies in purely implicational classical logic can be proved by polynomially sized derivations when their minimal counterpart is exponentially sized.
Keywords: Propositional Logic Complexity, Natural Deduction, Minimal propositional logic, Proof Theory


Introduction
Providing proofs for propositional tautologies seems to be a hard task. Huge proofs are such that their size is super-polynomial with regard to the size of their conclu- sions. Knowing that there is a classical propositional logic tautology having only huge proofs is related to know whether NP = CoNP or not [2]. Intuitionistic logic is PSPACE-complete [11] and Richard Statman [17] showed that purely implica- tional minimal logic (M→) is PSPACE-complete too. We showed in [8] that, if a propositional logic has a Natural Deduction (ND) with the sub-formula property then it is in PSPACE. This follows from the fact that M→ polynomially encodes any propositional logic that has such ND system. Thus, the existence of huge proofs

٨ The author is grateful to CAPES and CNPq project PIER for their financial support. Email:hermann@inf.puc-rio.br

http://dx.doi.org/10.1016/j.entcs.2015.06.004
1571-0661/© 2015 The Author. Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

for a more general class of propositional logics is related to the existence of huge proofs in M→ that amounts to know whether PSPACE = NP or not. The re- lations between these computational complexity classes and the existence of huge proofs involve arbitrary proof systems, indeed. For example, NP = PSP ACE is the case, if and only if, for any M→ tautology there is a proof system that produces a polynomially sized proof of this tautology.
A theoretical study of arbitrary proof systems is out of scope of this article. However, studying particular proof systems for key logics, like M→ or classical logic, can shed some light on practical aspects of implementing propositional theorem provers from the efficiency and economy of storage point of view. M→ carries almost all the proof-theoretical and logical information to produce polynomially bounded proofs in well-behaved 2 propositional logics. Focusing investigations on M→ is worth of noticing.
There are many proof systems for M→.	The most well-known are struc- tural/analytic proof systems. Well-known systems are the Sequent Calculus [4], Natural Deduction [4,14] and Tableaux [1,16] based. These systems, mainly the first and the third kind, are quite good in providing means to produce proofs auto- matically. The backward chaining procedure, for example, if applied to a Sequent Calculus based proof system provides an automatic way to produce proofs. The problem with these proof procedures is when a decision on which rule to apply has to be made and how to deal with non-provable formulas when it is the case. With re- spect to this feature of dealing with invalid formulas, the literature on both systems, Sequent Calculus and Tableaux, provides methods that either produce a proof or a counter-model uniformly in a unique proof-procedure. Since CoPSPACE=PSPACE, providing a counter-model in M→ is so hard as to provide a proof. The size of the counter-model can be super-polynomial with respect to the formula. It is in- teresting to investigate how this is related to the size of proofs in M→, or at least to have a concrete evidence that huge proofs may be the case. Most well-known huge proofs in the literature are considered inside Classical Logic. They are so in Classical as well as in Minimal logic. Our intention is not only show huge proofs in M→. We could use the polynomial translations reported in [17] or [8] to generate a formula of the Pigeon-Hole principle from full Minimal Logic into M→. We know, from [9], that this formula has only super-polynomially sized proofs in Resolution, and hence in cut-free Sequent Calculus and normal Natural Deduction. It is hard to detect from these translations why they are huge in M→, since there is nothing specific to M→. Focusing on M→ is promising, since M→ has less combinatorial alternatives, less logical constants, less alternative deductive system. The genesis of huge proofs in M→ may shed some new light in propositional logic complexity. This is emphasized by the fact that the formulas shown here do not have huge proofs when considered Classical Reasoning. This article has the purpose of showing how the use of Classical Logic can improve the size of proofs obtained by an automatic proof procedure of the kind that is able to generate normal and cut-free derivations. Developers of theorem provers have to be aware of many aspects of the logic in

2 With sub-formula property

order to design an efficient system. Any information that can guide the designer is of some help. The number of copies of a formula in a proof can be a “bottleneck” for an efficient implementation. For saving memory an obvious solution would be the use of references instead of copies when representing proofs. The number of references is exponential, but references to formulas are smaller than formulas in most of the cases. This approach points out to the use of graphs (digraphs in fact) for representing proofs. There are a lot of developments done in this direction reported in the literature. Most of them are more semantically than implementation driven. Proof-nets [5] represents an approach that defends the use of graphs as the most adequate representation for proofs. We agree with that and we consider this a practical motivation for taking digraphs instead of trees for representing proofs [15]
It is worth to remark on an important relationship between the size of proofs in Hilbert systems and the size of proofs in Natural Deduction proofs as trees. A Hilbert system is formed by a set of axiom schemata and a set of inference rules. When we have inference rules with more than one premise, proofs may be represented as sequences or as trees. Basically, when dealing with trees a formula can appear more than once in the proof, if it is used more than once in it. When dealing with sequences, formulas are referenced instead of copied. An inference rule is applied by indicating reference to formulas already assumed in the proof. The naive mapping of sequences into trees may point us to an apparent grow on the size (number of formulas occurrences) in the proof. However, by means of a quite ingenuous mechanism, Krajicek[10] proved that, for every proof Π of α, in a Hilbert system for Classical Logic: size(Πtree) ≤ poly(size(Πseq)), where poly is a polynomial on one variable. As Natural Deduction can be seem as a Hilbert system with proofs represented as trees, Krajicek polynomial simulation of proofs as trees by proofs as sequences holds for Natural Deduction. The last thing to observed is that the rule of →-introduction is nothing more than the deduction theorem in Hilbert system. Again, the deduction theorem can be proved in a way that the proof of the conclusion has a size no greater than the proof of the premise. Thus, we can base our discussion on trees in Natural Deduction and carry it to any Hilbert system preserving conclusions modulo polynomial simulation.
In section 4 we introduce the formulas ϕn, 0 ≤ n. In section 5 we show that they have exponentially sized normal proofs in the usual Natural Deduction for M→. In the same section we show that this is a lower bound in M→. In classical propositional logic, these formulas have linear-sized proofs as it is shown in section 4. Sections 2 and 3 remind us the basics of purely implicational minimal and classical logics, respectively.
All the formal propositional proofs/derivations in this article are presented in Prawitz-style Natural Deduction (ND). The size of these normal proofs/derivations is polynomially simulated by cut-free Sequent Calculus (SC) and/or Tableaux. Thus, the lower bound shown here also applies to them.

The purely implicational minimal logic
The (purely) implicational minimal logic M→ is the fragment of minimal logic containing only the logical constant →. Its semantics is the intuitionistic Kripke semantics restricted to → only. Given a propositional language L, a M→ model is a structure ⟨U, ≤, V⟩, where U is a non-empty set (worlds), ≤ is a partial order relation on U and V is a function from U into the power set of L, such that if i, j ∈ U and i ≤ j then V(i) ⊆ V(j). Given a model, the satisfaction relationship |= between worlds, in the model, and formulas is defined as:
⟨U, ≤, V⟩ |=i p, p ∈ L, iff, p ∈ V(i)
⟨U, ≤, V⟩ |=i α1 → α2, iff, for every j ∈ U , such that i ≤ j, if ⟨U, ≤, V⟩ |=j α1
then ⟨U, ≤, V⟩ |=j α2.
Obs: In (full) minimal logic, ⊥ has no special meaning, so there is no item declaring that ⟨U, ≤, V⟩ |=i ⊥. We remind that M→ does not have the ⊥ in its language.
As usual a formula α is valid in a model M, namely M |= α, if and only if, it is satisfiable in every world i of the model, namely ∀i ∈ UM |=i α. A formula is a M→ tautology, if and only if, it is valid in every model. A formula is satisfiable in M→ if it is valid in a model M of M→. The problem of knowing whether a formula is satisfiable or not is trivial in M→. Every formula is satisfiable in the model ⟨{?}, ≤, V⟩, where ? is the only world, and p ∈ V(?), for every p. Thus, SAT is not an interesting problem in M→. The same cannot be told about knowing whether a formula is a M→ tautology or not.
It is known that Prawitz Natural Deduction system for minimal logic with only the →-rules (→-Elim and →-Intro below) is sound and complete for the M→ Kripke semantics. As a consequence of this, Gentzen’s LJ system [18] containing only right and left →-rules is also sound and complete. As it is well-known one of these rules is not invertible 3 . A naive proof-procedure based on backward chaining for M→, based only on this usual Gentzen sequent calculus is not possible. In the next section we present and discuss a main aspect of a Natural Deduction system for the purely implicational classical logic.
[α]
|

β
α → β
→-Intro
α		α → β β
→-Elim

Purely implicational classical logic
If we consider only the logical constant → we can distinguish the minimal provability from its classical counter-part. Peirce’s formula for example, namely ((A → B) →
A) → A, is not provable in minimal logic and it is provable in classical logic. In

3 A rule is invertible, iff, whenever the premises are valid the conclusion is valid and whenever any premise is invalid the conclusion is also invalid

[A]a
((A → B) → A) → A

→-I

[(((A → B) → A) → A) → B]c

	B	 a →-I
→-E
b

A → B	[((A → B) → A)]
	A	 b → −I
((A → B) → A) → A  cP − rule
((A → B) → A) → A
Figure 1. Proof of Peirce’s formula using the P -rule in K→
→-E

[12], it is discussed a Natural Deduction system for Purely implicational Classical logic (K→ ) with normalization procedure and polynomial translation to M→ on the basis of a Glyvenko-like theorem. In this section we summarize the main results in [12] that have to do with the examples discussed in this article.
The system presented in [12] is strongly based on Peirce’s rule. In fact, to prove Peirce’s formula it is enough to add the following rule (P -rule) to the Natural Deduction for M→.
[α → β]
|
 α  P -rule
Using this rule, it is easy to derive Peirce’s formula as it is shown in figure 1. Since the P -rule is not neither an introduction rule, nor an elimination rule,
it is specially considered. Permutation reduction, as Seldin’s reduction for the ⊥- classical rule in Natural Deduction, is taken as the main reduction step in obtaining a normal derivation from any derivation, as described in [12]. There a definition of a normal form, called P-normal form, is provided. This definition, shown below, uses the concept of branch in a derivation. A branch in a derivation Π is a sequence δ0,..., δk of formula occurrences in Π, such that, δ0 is a hypothesis, discharged or not. δk is a minor premise of an →-E rule or the conclusion of Π and, for each i = 0,...,k − 1, δi is the major premise of an →-E or the premise of an
→-introduction of a rule that has δi+1 as conclusion.
Definition 3.1 A derivation Π in K→ is in P-normal form, iff, for every branch in Π, there is no formula occurrence that is premise of an elimination rule and conclusion of an introduction rule, besides that, no P -rule conclusion in Π is premise of an →-E or an →-I application rule in this branch.
For example the derivation above of ((A → B) → A) → A is a P-normal derivation. The reduction on derivations, called permutation here, shown in figure 2, ensures that any derivation Π of α from Γ in K→ can be transformed in a derivation Πj, of α from Γ, having each application of a P -rule in Π discharging a formula of the form β → A, with A atomic. By iterated applications of the reduction in figure 2 we obtain atomic formulas as the right-hand sides of the implications discharged by any P -rule application.
A P-normal derivation/proof where each application of the P -rule discharges formulas of the form α → A, with A atomic, is said to be an atomically expanded

[β1]b	[β1 → β3]a
	β3	
	β2 → β3	 b





Figure 2. Reducing the degree of the right-hand side of the discharged formula in a P -rule app
P-normal derivation/proof, also called an AEP-normal derivation/proof. In [12] it is shown the following theorem:
Theorem 3.2 Every derivation Π of α from Γ= {γ1,..., γk} in K→ can be trans- formed into an AEP-normal derivation of α from Γ in K→ .
From the form of the branches in an AEP-normal derivation it is drawn the fol- lowing statement, which is also called a Glyvenko theorem, because of its similarity with the original Glyvenko correspondence between provability in classical and in intuitionistic logic. See [6] and [13] for an updated and detailed presentation.
Theorem 3.3 Let α be a purely implicational formula and {p1,..., pk} the set of propositional variables occurring in α. Thus, ▶K→ α, if and only if, ▶M→ (α → p1) → ((α → p2) ... ((α → pn) → α) .. .).
From the proof of the above theorem, in [12], we can conclude that:
Lemma 3.4 Let Π be an AEP-normal proof of α in K→ , such that, the size (number of formula occurrences) of Π is s, then the normal proof of (α → p1) → ((α → p2) ... ((α → pn) → α) .. .) in M→ is bounded by s2
The above lemma says that normal proofs in K→ are polynomially simulated in
M→.
Although K→ proves Peirce law, it is not a complete classical system. What it lacks has to do with the intuitionistic negation. In order to have a complete system we have to add the intuitionistic absurdity rule 4 . This system we call KI→ . In this system we can define the negation ¬α as α → ⊥.
 ⊥
β
There is a restricted form of the rule above, whenever we consider β atomic, that is, from ⊥ infer B, with B atomic. This restriction is not essential. Using the following transformation repeatedly we transform any proof of α in KI→ in a proof of α in KI→ using the atomic version of ex-falso-sequitur-quolibet, instead of its general version. This reduction to the atomic applications only is due to Prawitz (see [14]).

4 Also known by ex-falso-sequitur-quodlibet principle


Π
	⊥	
β1 → β2	transforms into
Π
 ⊥ 
	β2	
β1 → β2 →-I

The system including the intuitionistic absurdity rule, instead of the general one, is also complete and sound for purely implicational classical logic 5 . The system with atomic intuitionistic absurdity rule is a good help understanding how polynomially simulate KI→ in K→ . The following proposition is the basis of this polynomial simulation, since it deals with a polynomially bounded translation of formulas. This proposition is a variation on the translation that Ingebrigt Johansson define from intuitionistic logic into minimal logic.
Proposition 3.5 Let α be a formula in the language {→, ⊥}, such that {p1,..., pk} is the set of propositional variables occurring in α. If r /= pi, for each i, and α٨ is the formula (r → p1) → ((r → p2) ... ((r → pn) → α) .. .), then ▶KI→  α, if and only if, ▶K→ α٨.
The mentioned results imply that the existence of huge proofs in classical logic implies the existence of huge proofs in M→. This article, by means of material exposed in the next sections, investigates how some these huge, so to say super- polynomially bounded, proofs are and how the use of classical reasoning can cut off in some cases this super-polynomial lower-bound.
Needing exponentially many assumptions
In [3] we can find a discussion on the fact that when proving theorems in a logic weaker than classical logic, the need of using an assumption more than once has a strong influence on how complex is the proof procedure and consequently the decision procedure for this logic. There, we can find the formula ((((A → B) →
A) → A) → B) → B. Considering the proof systems of ND and CS mentioned in the previous section, this formula needs to use the assumption ((A → B) → A) →
A) → B at least twice in order to be proved in M→. Inspired by this example, we can define a class of formulas with no bounds on the use of assumptions. This shows that limiting the use of assumptions in an automatic proof-procedure for M→ is not an alternative that ensures completeness. In the sequel we define the class of formulas. Below you find a normal proof of ((((A → B) → A) → A) → B) → B. Note that it cannot be proved with less than the use of 2 assumptions (((A → B) →
A) → A) → B.
The following formula combines two instances of the formula mentioned above in order to have a formula that needs 4 times an assumption.
((((A → ξ) → A) → A) → ξ) → C	(1)
where ξ = (((D → C) → D) → D) → C.

5 Of course this system without Peirce’s rule is sound and complete for purely implicational intuitionistic logic

In figure 4 we show a normal derivation of this formula 1 above. We can see that it has 4 assumptions of ((A → ξ) → A) → A) → ξ). They are from the two assumption occurrences in the derivation Σ shown in figure 3, that is used twice in the proof in figure 4
[A]1
((A → ξ) → A) → A		(((A → ξ) → A) → A) → ξ ξ

A → ξ
1	[(A → ξ) → A]2
	A	 2
((A → ξ) → A) → A	(((A → ξ) → A) → A) → ξ


ξ

Figure 3. The derivation Σ that is used in figure 4

We can see how to use this pattern such that if it is repeated n-times we define a formula ϕn, such that, any normal proof of ϕn has to use an assumption at least 2n times, see section 5. Before we proceed with ϕn definition, we have to show that the need for repeating assumptions is not the case for classical propositional logic. Consider now that the logic is the purely implicational classical logic, K→ , instead of the purely implicational minimal logic. Taking K→ into account, we provide the proof of the formula 1 with only the use of one assumption, as shown in figure 5. This comes from the fact that (((D → C) → D) → D) is an instance of the implicational form of Peirce’s rule, so it is provable. From this proof and ξ = (((D → C) → D) → D) → C we prove C. ξ itself is provable by means of a proof of the Peirce’s formula ((A → ξ) → A) → A) and the (((A → ξ) → A) →
A) → ξ discharged to prove the desired formula. The purely implicational classical logic can be also seen in [7] where we can find a detailed presentation of the purely implicational classical logic with some proof-theoretic results in sequent calculus, instead of Natural Deduction, as in [12]. The use of classical logic can, in some cases, for example this case, turn proofs smaller.



[D]3
(((D → C) → D) → D)
[(((A → ξ) → A) → A) → ξ]5
Σ
ξ



	C	 3
D → C	[(D → C) → D]4
		D	 4 ((D → C) → D) → D

[(((A → ξ) → A) → A) → ξ]5
Σ
ξ



		C	 5 ((((A → ξ) → A) → A) → ξ) → C

Figure 4. Proof of the formula ξ2 in purely implicational minimal logic


No bounds for occurrence assumptions in M→
In this section we prove that for each n there isa formula ϕn, such that, any normal proof of ϕn has at least 2n occurrence assumptions of the same formula, that are




ΠP eirce2
((D → C) → D) → D
ΠP eirce1
((A → ξ) → A) → A	[(((A → ξ) → A) → A) → ξ]1 ξ


		C	 1 ((((A → ξ) → A) → A) → ξ) → C
Figure 5. Proof of the formula ξ2 in purely implicational classical logic
all of them discharged in only one introduction rule. The following proposition 5.4 shows that 2n is an upper bound by showing the normal proof that uses 2n assump- tions for proving ϕn. Theorem 5.5 shows that there is no normal proof for any of the ϕn, in M→, with less than 2n assumptions discharged. In the sequel we define ϕn. As it was already said in section 4, ϕn arises from an iteration process derived from the previous examples.
Definition 5.1 Let χ[X, Y ] = (((X → Y ) → X) → X) → Y . Using χ[X, Y ] we define recursively a family of formulas. Consider the propositional letters C and Di, i > 0. Let ξi, i > 0, be the formula:
ξ1 = χ[D1, C]	(2)
ξi+1 = χ[Di+1, ξi]	(3)
Using this family of formulas we define the formula ϕn, n > 0, such that, for any
i ≥ 0:
ϕi+1 = ξi+1 → C
We can observe that ϕ1 = ξ1 → C can be proved by using proof Σ (shown in figure 3), replacing ξ by C and A by D1, and applying an →-introduction as the last rule. The obtained proof has 2 occurrence assumptions of the formula ξ1. The proof of ϕ2 is the proof shown in figure 4, replacing ξ by ξ1, A by D2 and D by D1, resulting in the proof shown below.




[D1]3
(((D1 → C) → D1) → D1)
	C	 3
D1 → C
[(((D2 → ξ1) → D2)
→ D2) → ξ1]5
Σ
ξ1





[(D1 → C) → D1]4




[(((D2 → ξ1) → D2)
→ D ) → ξ ]5

2	1
	D1		Σ
4
((D1 → C) → D1) → D1	ξ1
		C	 5 ((((D2 → ξ1) → D2) → D2) → ξ1) → C

The following lemma will be used in the proof of proposition 5.4.
Lemma 5.2 In the formula ξi, i > 0, if we simultaneously replace C by ξ1, and for each k > 0, Dk by Dk+1, the resulting formula is χ[Di+1, ξi].
Proof This lemma is proved by induction on i. For ξ1 we observe that replacing C

by ξ1 and D1 by D2 in ξ1, the resulting formula is χ[D2, ξ1]. Assuming that for i > 0, replacing C by ξ1 and, for each k = 1,..., i, simultaneously replacing Di by Di+1 in ξi, yields χ[Di+1, ξi]. Observing that ξi+1 = χ[Di+1, ξi] and by inductive hypothesis, simultaneous replacing C by ξ1 and Dk by Dk+1 in ξi, k = 1, i, yields ξi+1. As Di+1 does not occur in ξi, finally replacing Di+1 by Di+2 in ξi+1 = χ[Di+1, ξi+1] yields χ[Di+2, ξi+1]. This proves the inductive step. 2	2
Another observation is that substitutions as the above shown in the lemma, if applied in a derivation Π in M→, do imply that the resulting tree is a valid derivation too. This fact is justified by observing that the replacements are always on atomic formulas and the rules of M→ do not have provisos to be unsatisfied as consequence of these replacements. Thus,we have the following fact.
Fact 5.3 If Π is a derivation of α from γ1,..., γl and a substitution S (on atomic formulas) is applied to Π then S(Π) is a derivation of S(α) from S(γ1),.	, S(γl).
Besides that, if Π is normal then S(Π) is normal too.
Proposition 5.4 For any n > 0, there is a normal proof of ϕn having 2n occur- rences of the same assumptions, that are discharged by the last rule of the proof.
Proof The proof proceeds by induction. The basis n = 1 is the proof Σ shown in figure 3. This proof is inside proof in figure 6 also, occurying as a sub-derivation of Π٨. Assuming that ϕi, i > 0 has a normal proof Πϕ having 2i occurrences of ξi discharged by its last inference rule. Thus, we have a normal derivation Π of C from 2i occurrences of ξi, remembering that ϕi = ξi → C. We argue that if we simultaneously replace C by ξ1, and for each k = 1,..., i, replace Dk by Dk+1, we will have, by lemma 5.2 and fact 5.3, a normal derivation of ξ1 from 2i occurrences of χ[Di+1, ξi]. Let us call this derivation Π٨. The following derivation (see figure 6) is a derivation of C from ((((Di+1 → ξi) → Di+1) → Di+1) → ξi) → C, i.e., it is a derivation of C from ξi+1, and hence, by an →-introduction application, we have a normal derivation of ϕi+1 discharging 2i + 2i = 2i+1 assumptions of the formula ξi+1. 2	2






[D1]3


(((D1 → C) → D1) → D1)
	C	 3
D1 → C


[(((Di+1 → ξi) → Di+1)
→ Di+1) → ξi]5
Πs
ξi









[(D1 → C) → D1]4






[(((Di+1 → ξi) → Di+1)
→ Di+1) → ξi]5



	D1		Πs
4
((D1 → C) → D1) → D1	ξi
		C	 5 ((((Di+1 → ξi) → Di+1) → Di+1) → ξi) → C


Figure 6. Proof of ϕi+1 in M→ with 2i+1 discharged assumptions of ξi+1

Theorem 5.5 shows that 2i is the lower bound for number of assumption occur-

rences of a sole formula in any normal proof of ϕi in M→.


Theorem 5.5 Any normal proof of ϕi in M→ has at least 2i assumption occur- rences of ξi.


Proof We prove that for any i, there is no normal proof of ϕi with less than 2i assumption occurrences of ξi. We first observe that ϕ1, i.e., ((((D1 → C) → D1) → D1) → C) → C is not provable with only one occurrence of ξ1 = (((D1 → C) → D1) → D1) → C). If this was the case we would have, from an analysis of the form of the normal proof of C from ξ1, that ((D1 → C) → D1) → D1 would be provable in M→, and this cannot be the case since this formula is only classically valid. A Kripke model with two worlds such that in the first world neither C nor D1 holds and in second D1 holds but not C falsifies (((D1 → C) → D1) → D1). That is, with


M = ⟨{?1, ?2}, {?1 ≤ ?1, ?1 ≤ ?2, ?2 ≤ ?2}, {V (?1)= ∅,V (?2)= {D1}}⟩


then M |= α٨i (D1 → C), i = 1, 2, so, M |= α٨i (D1 → C) → D1, i = 1, 2. Thus, we hava that M |= α٨1 ((D1 → C) → D1) → D1.
Consider that there are normal proofs of ϕi with less than 2i assumption occur- rences of ξi. So there is the least k (k > 0), such that, ϕk has a normal proof with less than 2k assumption occurrences of ξk. Let Σk be such proof. Since ϕk = ξk → C, this proof is as follows. We remember that every open assumption in Σk has the form ξk.

[ξk]l Σk
		C	 l ξk → C

Since ξk = χ[Dk, ξk−1] = (((Dk → ξk−1) → Dk) → Dk) → ξk−1, it has to be major premise of an →-elim rule. If this is not the case then ξk would be a minor premise of a →-elim rule having a major premise of the form ξk → β. This formula on its turn has to be sub-formula of the open assumption of this branch, for the derivation is normal and ξk → β can only be conclusion of an application of an
→-elim rule. Since the only open assumption in Σk is ξk itself, the case of ξk as minor premise is not possible. Thus, as ξk is a major premise, Σk has the following form, remembering how is ξk, showed in the first line of this paragraph.

Σj
(((Dk → ξk—1) → Dk) → Dk)	[(((Dk → ξk—1) → Dk) → Dk) → ξk—1]l
ξk—1
Σk
		C	 l ξk → C

Note that Σj is a sub-derivation of Σk and it must have ξk as open assumption too. It must have an open assumption, for (((Dk → ξk—1) → Dk) → Dk) is not provable in M→. As ξk is the only possible open formula in Σk, then Σj has ξk at least one occurrence of ξk open in it. It is very important to note that each occurrence of ξk in Σk has a companion derivation of the form Σj with ξk open in it. Thus, if we remove every Σj from Σk we end up with the following proof:

[ξk—1]l Σk—1
	C	 l ξk—1 → C
The proof above is a proof of ϕk—1 with less than 2k—1 assumption occurrences of ξk—1 discharged by the last rule. This is a consequence of the fact that we have removed at least one assumption of ξk when removing Σj. That is we have at least divided the amount of assumption occurrences of ξk by two. So, the resulting pruned derivation contradicts the fact that k is the least number holding this property, since it is a derivation of ξk—1 → C with less than 2k—1. 2	2
We have proved that any normal proof of ϕn has at least 2n assumption oc- currences of ξn. The size of ϕn (s(ϕn)) is the length of the string representing it in an alphabet Λ with more than one symbol. Whatever is the size of ϕn, any normal proof of it has at least 2n occurrences of a formula of size s(ϕn) − 2, since s(ξn)+2 = s(ϕn). Thus, we can affirm that the least size of any normal proof of ϕn is super-polynomially bounded when compared to the size of ϕ itself. Let Πn be any normal proof of ϕn, then the ratio s(Πn) is:

s(Πn) >
s(ϕn)
s(ξ) × 2n (s(ξ)+ 2)

Let us now consider this fact to estimate the size of a normal proof of ϕn on the basis of the size of n. In order to simplify the evaluation, we consider that the length of a formula is the amount of occurrences of propositional letters in it. The real size is linearly proportional to what we call here as length, since for each propositional there is at most one → symbol in ϕ. Parenthesis will be ignored in this evaluation. By the later discussion we can see that 2 × len(ϕ) ≥ s(ϕ). The analysis will be accomplished using length (len) to measure the size of strings.

The form of ϕn is ξn → C, the length of ϕ (len(ϕ)) is 1+ len(ξn). ξn is defined in a recurrent way by χ[Di, ξi—1], with ξ1 = ((D1 → C) → D1) → D1. As len(ξ1)=5 and len(ξi+1)=2 × len(ξi) + 3, we can deduce 6 that len(ξn)= 2n—1 × (5 + 3) − 3, and hence len(ϕn)= 2n—1 × (5 + 3) − 2.
From the previous discussion, we found out that the formulas ϕn are of super- polynomial size on n. In fact, the strings that represent them are huge on n. However, the minimal amount of occurrences of ξn in any normal proof of ϕn is not less than 2n, so we have that:
(2n) × (2n—1 × (5 + 3) − 2) < len(Πn)
for any normal proof Πn of ϕn. Finally we have
(2n) × (2n—1 × (5 + 3) − 2)	s(Πn)
(2n—1 × (5 + 3) − 3)	< s(ϕ )
and hence there is κ > 1, such that s(Πn) = κs(ϕn).
n

Discussing the compression power of Classical Logic
Here we discuss the normal proofs of ϕ in K→ and KI→ . We show that any normal proof of ϕn in KI→ or K→ is not super-polynomially bounded by the size of ϕn. The main reason for that is the fact that χ[Dk, ξk—1] = (((Dk → ξk—1) → Dk) → Dk) → ξk—1 has a normal proof of size k × η × s(ϕk), where η is a constant. As a matter of a clear presentation we show in figure 7 the proof in figure 5 adapted, and iterated, to our present discussion.



Πk−1
((Dk−1 → ξk−2) → Dk−1) → Dk−1
ξk−2
.
Πk
((Dk → ξk−1) → Dk) → Dk
ξk−1
[(((Dk → ξk−1) → Dk)
→ Dk) → ξk−1]1

Π1	.
((D1 → C) → D1) → D1	ξ1
		C	 1 ((((Dk → ξk−1) → Dk) → Dk) → ξk−1) → C



Remembering that
Figure 7. Proof of ϕk in purely KI→

ξ1 = (((D1 → C) → D1) → D1) → C


and that

ξk—1 = (((Dk—1 → ξk—2) → Dk—1) → Dk—1) → ξk—2



6 Use your favorite method to solve recurrence equations



[A]
	B → A	
(B → A) ∨ (A → B)	[((B → A) ∨ (A → B)) → B]
	B	
	A → B	
(B → A) ∨ (A → B)	[((B → A) ∨ (A → B)) → B]
	B	
(((B → A) ∨ (A → B)) → B) → B


Figure 8. Proof of Dummet’s formula needs at least two repeated assumptions




[A]
A ∨ ¬A	[(A ∨ ¬A) → ⊥]

 ⊥ 
  ¬A	
A ∨ ¬A	[(A ∨ ¬A) → ⊥]
	⊥	
((A ∨ ¬A) → ⊥) → ⊥ 


Figure 9. Proof of Tertium non-datur formula needs at least two repeated assumptions


The proofs Πi, i = 1, k, have all size 9 × (s(ξi)) + 3). This can be checked out by an inspection in the proof in figure 1, making A = Di and B = ξi. We can note that s(ξi) ≤ s(ξk), i = 1, k, and hence the size of the whole proof is upper bounded by k × 9 × (s(ξk)) + 3).
In this particular case K→ saves space in a larger amount than M→. We could think that this is a very particular situation. In fact this is not the case. Figures 9 and 8 are examples of proofs of classical tautologies that can be used to obtain similar classes of formulas with exponentially many assumptions need in normal proof. This time we have to use the full propositional minimal logic, that is, the minimal logic with the other logical constants {∧, ∨, ¬, ⊥}, the same regarding its classical counterpart. Thus, the formulas proved in these figures can be used to provide other examples of the compressing power obtained by the use of Classical reasoning. We will work out this conjecture on a forthcoming article.
We can generalize the situation discussed here. Let α be such that /▶M→ α and there are β and γ, such that, α ▶M→ β and γ, β ▶M→ α. We can conclude that
▶KI→ α, as shown in the right derivation below. Besides that, in the case that the left derivation has exponentially many assumptions of α → β, we conjecture that by a similar reasoning applied in the case of the class of formulas ϕn we can use KI→ to have a proof of (α → β) → β of polynomial size.



[γ]
|
α	[α → β] β
|
β′







[γ]
[γ]
|
 α	¬α 
 ⊥ 
¬γ
 ⊥ 
β
|
β′

γ → β′		
γ → β′

|
α	[α → β]
β


((α → β) → β
|
 α	¬α 
⊥

α


Conclusion
Taking into account that M→ is the hardest and most representative proposi- tional logic to define efficient proof-procedures, we show an example alerting for the fact that allowing unlimited use of assumptions is worth for any complete proof- procedure. This example runs in M→. We are not aware of a similar one running in classical logic. Classical propositional logic is more efficient than M→ if such exam- ple does not exist. Propositional logic complexity has a lot of conjectures, starting with the relations between the main complexity classes. This article has the sole purpose of providing an example where the exponential grow of proofs has nothing to do with disjunction and combinatorial principles like the Pigeon-Hole 7 . The class of formulas ϕn and other obtained in a similar way from classical tautologies are such examples.

Acknowledgments
The author would like to thank prof. Gilles Dowek for hearing and reading the initial ideas presented here and providing very good suggestions. We thank Jefferson dos Santos for the suggestions on improving the text.

References
E.W. Beth. Semantic Entailment and Formal Derivability. Mededelingen der Koninklijke Nederlandse Akademie van Wetenschappen: Afd. Letterkunde. Noord-Hollandsche Uitgevers Maatschappij, 1961.
Stephen A. Cook. The complexity of theorem-proving procedures. In Proceedings of the Third Annual ACM Symposium on Theory of Computing, STOC ’71, pages 151–158, New York, NY, USA, 1971. ACM. http://doi.acm.org/10.1145/800157.805047.

Gilles Dowek and Ying Jiang. Eigenvariables, bracketing and the decidability of positive minimal predicate logic. Theoretical Computer Science, 360(13):193 – 208, 2006. http://www.sciencedirect. com/science/article/pii/S030439750600257X.

7 The pigeon-hole principle was used to provide a super-polynomial lower bound for Robinson’s (proposi- tional) Resolution

G. Gentzen. Untersuchungen ber das logische schlieen i. Mathematische Zeitschrift, 39:176–210, 1935. See english version in [?], original version online in http://eudml.org/doc/168546.
Jean-Yves Girard. Proof-nets: The parallel syntax for proof-theory. In P. Agliano and A. Ursini, editors,
Logic and Algebra. Marcel Dekker, New York, 1996.
V. I. Glivenko. Sur quelques points de la logique de m. brouwer. Bull. Soc. Math. Belg., 15:183–185, 1929.
L. Gordeev. On cut elimination in the presence of peirce rule. Archiv fr mathematische Logik und Grundlagenforschung, 26:147–164, 1987.
Edward Hermann Haeusler. Propositional logics complexity and the sub-formula property. CoRR, cs/1401.8209v1, 2014. Also proceedings of DCM2014 workshop, Vienna Summer of Logic 2014, Vienna, july/2014, and http://arxiv.org/cs/1401.8209v1.
A. Haken. The intractability of resolution. Theoretical Computer Science, 39(2–3):297–308, 1985.
Jan Krajıˇcek. Lower bounds to the size of constant-depth propositional proofs. Journal of Symbolic Logic, 59(1):73–86, 1994.
Richard E. Ladner. The computational complexity of provability in systems of modal propositional logic. SIAM Journal on Computing, 6(3):467–480, 1977.
Luiz Carlos Pereira, Edward Hermann Haeusler, Vaston G. Costa, and Wagner Sanz. A new normalization strategy for the implicational fragment of classical propositional logic. Studia Logica, 96(1):95–108, 2010.
Luiz Carlos Pereira, Edward Hermann Haeusler, and Maria da Paz N. de Medeiros. Some results on fragments of propositional logic with classical negation. O Que Nos Faz Pensar, 23:105– 111, 2008. http://www.oquenosfazpensar.com/adm/uploads/artigo/alguns_resultados_sobre_ fragmentos_com_negacao_da_logica_classica/23_Alguns_resultados_sobre_fragmentos.pdf.
D. Prawitz. Natural deduction: a proof-theoretical study. PhD thesis, Almqvist & Wiksell, 1965.
Marcela Quispe-Cruz, Edward Hermann Haeusler, and Lew Gordeev. Proof-graphs for minimal implicational logic. In Proceedings 2013 International Workshop on Developments in Computational Models, volume 144 of EPTCS, pages 16–29, 2014.
R. M. Smullyan. First–Order Logic. Springer-Verlag, New York, 1968.
Richard Statman. Intuitionistic propositional logic is polynomial-space complete. Theoretical Computer Science, 9(1):67 – 72, 1979.
G. Takeuti. Proof Theory. Studies in logic and the foundations of mathematics. North-Holland, 1987.
