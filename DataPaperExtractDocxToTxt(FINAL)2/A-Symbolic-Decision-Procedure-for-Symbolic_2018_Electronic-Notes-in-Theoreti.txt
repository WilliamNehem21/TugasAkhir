Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 336 (2018) 79–99
www.elsevier.com/locate/entcs

A Symbolic Decision Procedure for Symbolic Alternating Finite Automata
Loris D’Antoni1	Zachary Kincaid2	Fang Wang1
1University of Wisconsin-Madison	2Princeton University

Abstract
We introduce Symbolic Alternating Finite Automata (s-AFA) as a succinct and decidable model for describ- ing sets of finite sequences over arbitrary alphabets. Boolean operations over s-AFAs have linear complexity, which contrasts the quadratic cost of intersection and union for non-alternating symbolic automata. Due to this succinctness, emptiness and equivalence checking are PSpace-hard. We introduce an algorithm for checking the equivalence of two s-AFAs based on bisimulation up to congruence. This algorithm exploits the power of SAT solvers to efficiently search the state space of the s-AFAs. We evaluate our decision procedure on two verification and security applications: 1) checking satisfiability of linear temporal logic
formulae over finite traces, and 2) checking equivalence of Boolean combinations of regular expressions. Our experiments show that our technique can be beneficial in both applications.
Keywords: Automata, decision procedures

Introduction
Programs that operate over sequences are used for text processing [1], program monitoring [17], and deep packet inspection [23]. Efficiently reasoning about these programs is crucial and these recent applications have renewed interest in automata theory, especially in the fields of security and programming languages [4,8,23]. De- spite the recent improvements, existing automata-based decision procedures are not as advanced as other decision procedures such as SMT solvers yet.
We illustrate the limitations of classic automata with the following spam de- tection example. Spam detection is a notoriously hard task and spam filters are continuously modified to handle new malicious behaviours and to relax overly re- strictive conditions. While machine learning is the typical choice for spam detection, many companies prefer using custom filters created using regular expressions. The number of filters can be very large and redundant expressions that cover already considered behaviours are often mistakenly added to the set of filters. Efficiently processing all such expressions can become complicated and it is therefore desirable to avoid adding redundant filters to the list of processed ones.

https://doi.org/10.1016/j.entcs.2018.03.017
1571-0661/© 2018 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).



Contains .org email Contains the word free Contains a Cyrillic character
.*@.*\.org free [U+0400U+04FF]

Fig. 1. Regexes forming a spam scenario.


Suppose that a spam filter is given as a set of regular expressions R = {r1,..., rn} such that a string is recognized by the spam filter R if it belongs to the language of each regular expression ri ∈ R (e.g., Fig. 1). When a new spam filter Rj =
{rj ,..., rj } is added to the set of all spam filters S, we want to see whether there
1	n
exists a spam filter Rjj that is already in S and that subsumes Rj. Similarly, if we
have a regular expression W describing known good inputs, we might want to check that none of the strings in W is classified as spam. We can perform these checks using automata operations, but in doing so, we face the following limitations:
The regular expressions operate over a large alphabet (216 characters), making classic automata operations impractical.
The subsumption check requires repeated Boolean automata operations, which can cause an exponential blow-up in the number of states.
Checking equivalence of non-deterministic automata is PSpace-complete.
In this paper, we present symbolic alternating ﬁnite automata together with a decision procedure for equivalence to address these three problems.
Symbolic alphabets: Symbolic Finite Automata (s-FA) [26,8], have been pro-
posed to address the problem of handling large alphabets. s-FAs are finite state
automata in which the alphabet is given as a Boolean algebra that may operate over an infinite domain, and transitions are labeled with first-order predicates over the elements of the algebra. Although strictly more expressive than finite-state au- tomata, s-FA are closed under Boolean operations and admit decidable equivalence, as long as it is decidable to check satisfiability of predicates in the alphabet algebra. Alternation: While s-FAs provide a way to cope with large alphabets, they have the same state complexities as classic finite automata. In particular, repeated s- FA intersections can result in s-FAs with exponentially many states. To solve this
problem, we propose Symbolic Alternating Finite Automata (s-AFAs). s-AFAs
add alternation to s-FAs by allowing transitions to contain Boolean formulae that describe the set of target states. For example, when an s-AFA is in state p and
[a—z]
reads a string w = a1 ... an, the transition p −−−→ q1 ∨ (q2 ∧ q3) specifies that w is
accepted from state p if a1 is a lower-case letter and the string a2 ... an is accepted from state q1 or it is accepted from both q2 and q3. Using alternation, s-AFAs obtain Boolean operations with linear complexity, which is in sharp contrast with the quadratic intersection and exponential complementation of s-FAs.
Equivalence via bisimulation up to: The succinctness of s-AFAs comes at a cost: equivalence and emptiness are PSpace-complete problems. In the case of s-FAs, emptiness has linear complexity while equivalence is also PSpace-complete. In this paper, we propose a symbolic decision procedure for checking equivalence

of two s-AFAs and show that the procedure is effective in practice. The algorithm extends the bisimulation up to congruence technique recently proposed by Bonchi and Pous [4] for solving the language equivalence problem for nondeterministic finite automata. The algorithm belongs to a family of techniques based on the principle that two configurations of an automaton recognize the same language if and only if there is a bisimulation relation that relates them. Hopcroft and Karp’s classic algo- rithm for checking equivalence of deterministic finite automata is a member of the family that employs a bisimulation up to technique [15,4]. Rather than computing a bisimulation relation (which may be quadratic in the number of configurations of the DFA), Hopcroft and Karp’s algorithm computes a relation R that is a bisim- ulation up to equivalence, in the sense that the equivalence relation generated by R is a bisimulation. Bisimulation up to congruence improves upon this technique by exploiting additional structure on the configurations of a nondeterministic au- tomaton (the configurations of the NFA are finite disjunctions of states and if (say) a1 R b1 and a2 R b2, then we may derive (a1 ∨ a2) R (b1 ∨ b2)).
We extend this technique in two ways. First, we show how the framework can be applied to alternating automata by exploiting the lattice structure on s- AFA configurations to compute a small relation that generates a bisimulation, and by using a propositional satisfiability solver to compute the congruence closure. Second, we extend the algorithm to symbolic alphabets by showing how to efficiently enumerate a set of representative characters, in a style reminiscent of the way that SAT solvers enumerate all satisfying assignments to a propositional formula.
We implemented our algorithm and evaluated it on a set of verification and secu- rity benchmarks. First, we used s-AFAs to check satisfiability of more than 10,000 LTL formulae appearing in [12]. Second, we used s-AFAs to check equivalence of Boolean combinations of complex regular expressions. Our experiments show that s-AFAs and our bisimulation technique often outperform existing techniques.
Contributions. In summary our contributions are:
Symbolic Alternating Finite Automata, s-AFAs, a model for describing lan- guages of strings operating over large or even infinite alphabets, for which Boolean operations have linear time complexity (Section 2).
An algorithm for checking equivalence of two s-AFAs, which integrates bisim- ulation up to congruence with propositional SAT solving (Section 3).
A modular, open-source implementation of s-AFAs and their algorithms, and
a comprehensive evaluation on more than 40,000 benchmarks (Section 4).

Symbolic alternating finite automata
This section gives a formal description of symbolic alternating finite automata (s- AFA). The two key features of s-AFAs are that (1) the alphabet is symbolic (as in a symbolic finite automaton), and (2) the automaton may make use of both existential and universal nondeterminism (as in an alternating finite automaton).
As in an s-FA, the symbolic alphabet of an s-AFA is manipulated algorithmi-

cally via an effective Boolean algebra. An effective Boolean algebra A has compo- nents (D, Ψ, [[ ]], ⊥, T, V, Λ, ч). D is a set of domain elements. Ψ is a set of predi- cates closed under the Boolean connectives and ⊥, T∈ Ψ. The denotation function [[ ]] : Ψ → 2D is such that, [⊥]] = ∅, [[T]] = D, for all ϕ, ψ ∈ Ψ, [ϕ V ψ]] = [[ϕ]] ∪ [[ψ]],
[[ϕ Λ ψ]] = [[ϕ]] ∩ [[ψ]], and [[чϕ]] = D \ [[ϕ]]. For ϕ ∈ Ψ, we write IsSat (ϕ) when
[[ϕ]] /= ∅ and say that ϕ is satisﬁable. In the following we will assume that IsSat is a computable function, that there is a function Witness(ϕ) that computes for any satisfiable predicate ϕ a character a ∈ D such that a ∈ [[ϕ ], and that for every domain element a ∈ D and predicate ϕ, it is decidable to check whether a ∈ [[ϕ]].
The following are examples of effective Boolean algebras.
2bvk is the powerset algebra whose domain is the finite set bvk, for some k > 0, consisting of all non-negative integers smaller than 2k, or equivalently, all k-bit bit- vectors. A predicate is represented by a BDD of depth k. The Boolean operations correspond to the BDD operations and ⊥ is the BDD representing the empty set.
SMTσ is the decision procedure for a theory (e.g., linear integer arithmetic) over a sort σ (e.g., the integers). Ψ is the set of all formulae ϕ(x) in that theory with one fixed free integer variable x. For example, a formula (x mod k)= 0, say divk, denotes the set of all numbers divisible by k. Then div 2 Λ div 3 denotes the set of numbers divisible by six.
Nondeterministic automata generalize deterministic automata by allowing a state to have multiple outgoing transitions labeled with the same character. A word is accepted by a nondeterministic automaton when some run leads to an ac- cepting state (i.e., choice is interpreted existentially ). One may naturally consider the dual interpretation of choice, wherein a word is accepted when all runs lead to an accepting state (i.e., choice is interpreted universally ). An alternating finite automaton supports both types of nondeterminism [5,6]. Nested combinations of existential and universal choices can be represented by positive Boolean formulae. Formally, for any set X, we use ¥+(X) to denote the set of positive Boolean formu- lae over X, quotiented by logical equivalence (that is, the set of Boolean formulae built from true, false, and the members of X using the binary connectives Λ and V, and where logically equivalent formulae are identified).


Definition 2.1 A symbolic alternating ﬁnite automaton (s-AFA) is a tuple M =
⟨A, Q, p0, F, Δ⟩ where A is an effective Boolean algebra, Q is a finite set of states, p0 ∈ ¥+(Q) represents M ’s initial state, F ⊆ Q is a set of accepting states, and Δ ⊆ Q × ΨA × ¥+(Q) is a finite set of transitions.


An s-AFA over an effective Boolean algebra A recognizes a language of
words over the set of characters DA, which we will define presently. Let M =
⟨A, Q,p , F, Δ⟩ be an s-AFA. We define a function L (·): ¥+(Q) → 2D∗ mapping
0	M	A
each positive Boolean formula to the language accepted by that formula to be the

least function (in pointwise inclusion ordering) that satisfies:

w ∈ LM (true)	always
w ∈ LM (false)	never
ϵ ∈ LM (x) ⇐⇒ x ∈ F
aw ∈ LM (x) ⇐⇒ ∃⟨x, ϕ, q⟩∈ Δ s.t. a ∈ [[ϕ]] Λ w ∈ LM (q)
w ∈ LM (p Λ q) ⇐⇒ w ∈ LM (p) Λ w ∈ LM (q)
w ∈ LM (p V q) ⇐⇒ w ∈ LM (p) V w ∈ LM (q)
Finally, we define the language L(M ) recognized by M as L(M ) , LM (p0).
Unsurprisingly, the relationship between s-AFAs and s-FAs is analogous to the relationship between AFAs and NFAs: s-AFAs and s-FAs recognize the same family of languages, but converting an s-AFA with n states to an s-FA can require up to 2n states. Interestingly, the symbolic alphabet is another source of complexity in the conversion from s-AFA to s-FA. Consider an s-AFA with two states Q = {x, y} and two outgoing transitions per state
Δ= {⟨x, ϕ1, x⟩, ⟨x, ϕ2, y⟩, ⟨y, ψ1, y⟩, ⟨y, ψ2, true⟩}

The states of the equivalent s-FA can be identified with the positive Boolean for- mulae over Q. The state x Λ y must have four outgoing transitions, one for each combination of the guards of x and y (ϕ1 Λψ1, ϕ1 Λψ2, ϕ2 Λψ1, and ϕ2 Λψ2). In gen- eral, for an s-AFA with n states each with m outgoing transitions, the equivalent s-FA can have states with up to mn outgoing transitions.

Boolean operations on s-AFAs
One of the critical features of s-AFAs is that Boolean operations have linear com- plexity in the number of states. For example, the language inclusion problem can be reduced in linear time to checking language equivalence—i.e., L(M ) ⊆ L(Mj) iff L(M ) ∪ L(Mj)= L(Mj). The constructions for s-AFA union, intersection, and complementation follow the standard ones for AFAs, with the exception that s-AFA complementation (like s-FA complementation) requires a preprocessing step. For the sake of completeness, we recall these constructions below.
Suppose that M = ⟨A, Q, p0, F, Δ⟩ and Mj = ⟨A, Qj, pj ,Fj, Δj⟩ are s-AFAs over the same effective Boolean algebra and (without loss of generality) disjoint state spaces. Their union and intersection are defined simply by:
M ∪ Mj , ⟨A,Q ∪ Qj, p0 V pj ,F ∪ Fj, Δ ∪ Δj⟩
M ∩ Mj , ⟨A,Q ∪ Qj, p0 Λ pj ,F ∪ Fj, Δ ∪ Δj⟩
(i.e., the set of states, set of final states, and transitions of the union/intersection s-AFAs are just the union of the component s-AFAs; they differ only in the initial state, which is either the disjunction (union) or conjunction (intersection) of the initial states of the components).

1 Procedure Normalize(M )
Input : s-AFA M = ⟨A, Q, p0, F, Δ⟩
Output: Equivalent normal s-AFA M’
2	Δj →∅ 
3	foreach x ∈ Q do
4	chars →T 
5	while IsSat(chars) do
6	a → Witness(chars)
7	p = false
8	class →T 
9	foreach ⟨x, ϕ, q⟩∈ Δ do
10	if a ∈ Jϕ) then
11	class → class Λ ϕ
12	p → p V q
13	else
14	class → class Λ чϕ
15	chars → chars Λ чclass
16	Add ⟨x, class, p⟩ to Δj
17	return ⟨A, Q, p0, F, Δj⟩
Algorithm 1: Normalization algorithm for s-AFA
The complement construction for an s-AFA M = ⟨A, Q, p0, F, Δ⟩ relies on M satisfying the property that for all states x ∈ Q, the set {Jϕ) : ∃p.⟨x, ϕ, p⟩ ∈ Δ} forms a partition of DA. An s-AFA that satisfies this condition is called normal. Any s-AFA can be converted into an equivalent normal s-AFA using the normalization procedure pictured in Algorithm 1. (The algorithm is similar to the one in [18] for computing all satisfiable assignments to a propositional formula, and the one in
[25] for computing satisfiable Boolean combinations of a set of predicates, and also the representative character enumeration algorithm in Section 3). Normalization may (in the worst case) cause an exponential blow-up in the number of outgoing transitions of any one state in an s-AFA. Note, however, that the exponential factor does not depend on the number of states.
Assuming that M is normal, its complement is constructed as M ,
⟨A, Q, p0,Q \ F, {⟨x, ϕ, p⟩ : ⟨x, ϕ, p⟩∈ Δ⟩, where · denotes the “De Morganization” transformation that replaces every Λ with V (and vice versa).

An algebraic view of s-AFA
This section provides an algebraic description of s-AFAs. We use this description in the next section to give a concise presentation of our equivalence checking technique. A bounded lattice L = ⟨L, ±, H, H, ⊥, T⟩ is a partially ordered set ⟨L, ±⟩ such that every finite set of elements has a least upper bound and greatest lower bound. For any pair of elements x, y ∈ L, we use xHy to denote their least upper bound and x H y to denote the greatest lower bound. The least element of the lattice (the least upper bound of the empty set) is denoted by ⊥ and the greatest (the greatest lower

bound of the empty set) by T. We say that L is distributive if for all a, b, c ∈ L, we have a H (b H c)= (a H b) H (a H c).
Our first example of a bounded lattice is the (distributive) bounded lattice of positive Boolean formulae. Operating (as we do) under the assumption that we do not distinguish between logically equivalent positive Boolean formulae, for any set X, ¥+(X) is a bounded lattice where the order is logical entailment, the least upper bound is disjunction, the greatest lower bound is conjunction, ⊥ is false, and T is true. A second important example is the Boolean lattice 2 , ⟨{0, 1}, ≤, V, Λ, 0, 1⟩ (which is also bounded and distributive).
Let X be a set. A model over X is a function m : X → 2 that assigns each x ∈ X a Boolean value. The model m can be extended to evaluate any positive Boolean formula by defining:
m(false) , 0	m(p Λ q) , m(p) Λ m(q)
m(true) , 1	m(p V q) , m(p) V m(q) .

Thus, we say that the model m : X → 2 extends uniquely to a lattice homomorphism
¥+(X) → 2. In fact, there is nothing special about the bounded lattice 2 in this regard: if L = ⟨L, H, H, ⊥, T⟩ is a bounded lattice, then any function f : X → L extends uniquely to a lattice homomorphism ¥+(X) → L. 1 In the following, our notation will not distinguish between a function f : X →L and its extension.
Let M = ⟨A, Q, p0, F, Δ⟩ be an s-AFA. The set F ⊆ Q of final states defines a model F : Q → 2 over Q as follows:

F (x) ,	1	if x ∈ F
0	otherwise .

Note that for any p ∈ ¥+(Q), we have F (p) = 1 if and only if LM (p) contains the empty word. Any character a ∈ DA can be associated with a transition function Δa : Q → ¥+(Q), where
Δa(x) , _{q : Eϕ ∈ ΨA.⟨x, ϕ, q⟩∈ Δ Λ a ∈ Jϕ)} .
Recall that since Δa is a function into a bounded lattice (namely ¥+(Q) itself) it extends uniquely to a lattice homomorphism ¥+(Q) → ¥+(Q). Similarly, any word w = a1...an ∈ D∗ can be associated with a transition function Δw : Q → ¥+(Q) where Δw , Δan ◦· · · ◦ Δa1 .
Finally observe that we can characterize the language recognized by an s-AFA
succinctly using the algebraic machinery described in this section: for any p ∈
¥+(Q), we have w ∈ LM (p) ⇐⇒ F (Δw(p))= 1.

1 Succinctly, B+(X) is the free bounded distributive lattice generated by X.

Equivalence checking for s-AFAs
This section describes an algorithm for checking whether two s-AFAs recognize the same language. Recently, Bonchi and Pous introduced the bisimulation up to congruence technique for solving the language equivalence problem for non- deterministic finite automata [4]. We extend this technique in two ways: (1) we show how the framework can be applied to alternating automata, using a proposi- tional satisfiability solver to compute congruence closure; (2) we give a technique for extending the technique to symbolic alphabets.
Bisimulation up to congruence
We will begin by recalling some of the details of bisimulation up to congruence, adapted to our setting of symbolic alternating finite automata.
Definition 3.1 Let M = ⟨A, Q, p0, F, Δ⟩ be an s-AFA, and let R ⊆ ¥+(Q) ×
¥+(Q) be a binary relation on positive Boolean formulae over M ’s states. We say that R is a bisimulation if for all p, q such that p R q, we have
Consistency : F (p)= F (q)
Compatibility : For all a ∈ DA, Δa(p) R Δa(q).
Consistency and compatibility are useful notions outside of the context of bisim- ulations, so we will provide more general definitions. For any relation R ⊆ X × X and any function f : X → X, we say that f is compatible with R if x R y im- plies f (x) R f (y). A function f : X → 2 is consistent with R if x R y implies f (x) = f (y). Clearly, compatible functions are closed under composition, and the composition of a compatible function with a consistent function is consistent.
The following proposition (adapted from known results for classical finite au- tomata [19,21]) states the soundness and completeness of using bisimulations to prove language equivalence for s-AFA.
Proposition 3.2 Let M = ⟨A, Q, p0, F, Δ⟩ be an s-AFA. For any p, q ∈ ¥+(Q),
we have LM (p)= LM (q) iff there exists a bisimulation R such that p R q.
We will now define bisimulation up to congruence for s-AFAs.
Definition 3.3 Let Q be a finite set and let R ⊆ ¥+(Q) × ¥+(Q) be a binary relation. The congruence closure of R, denoted ≡R, is the smallest congruence relation that contains R. That is, ≡R is the smallest reflexive, transitive, and symmetric relation that contains R and such that for all p1, p2, q1, q2 ∈ ¥+(Q) such that p1 ≡R q1 and p2 ≡R q2, we have p1 Λ p2 ≡R q1 Λ q2 and p1 V p2 ≡R q1 V q2.
Definition 3.4 Let M = ⟨A, Q, p0, F, Δ⟩ be an s-AFA, and let R ⊆ ¥+(Q) ×
¥+(Q) be a binary relation. We say that R is a bisimulation up to congruence if for all p, q such that p R q, we have
Consistency: F (p)= F (q)
Compatibility: For all a ∈ DA, Δa(p) ≡R Δa(q).

Bisimulation up to congruence allows us to solve language equivalence queries as follows: if R is a bisimulation up to congruence such that p R q, then p and q recognize the same language. This follows from Proposition 3.2 and the following:
Proposition 3.5 Let M = ⟨A, Q, p0, F, Δ⟩ be an s-AFA. Let R ⊆ ¥+(Q) ×¥+(Q) be a binary relation on positive Boolean formulae over M’s states. R is a bisimula- tion up to congruence if and only if ≡R is a bisimulation.
We delay the proof of this proposition to the next section, after we have devel- oped some technical machinery for checking whether a given relation is a bisimula- tion up to congruence.
Congruence checking
We now address an algorithmic challenge: how may one check whether a given relation is a bisimulation up to congruence? Generating the congruence closure ≡R explicitly is intractable, since the cardinality of ≡R may be double-exponentially larger than that of R. However, for the purpose of checking whether a relation R is a bisimulation up to congruence, we need only to be able to check membership within the congruence closure. Thus, we are interested in the CONGRUENCE problem, which is stated as follows: given a finite set Q, a finite relation R ⊆ ¥+(Q) ×¥+(Q), and two positive Boolean formulae p, q ∈ ¥+(Q), determine whether p ≡R q. In the following, we will show that the CONGRUENCE problem is NP-complete, but it can be solved in practice by exploiting propositional satisfiability solvers. Towards this end, we define the logical closure of a relation as follows:
Definition 3.6 Let Q be a finite set and let R ⊆ ¥+(Q) × ¥+(Q) be a binary relation. Define cl(R) as the logical closure of R as follows:
Φ(R) ,	p ⇐⇒ q
pRq
cl(R) , {⟨p, q⟩ : Φ(R) |= p ⇐⇒ q}.
Observe that for any R, p, and q, we have p cl(R) q if and only if Φ(R) Λ ч(p ⇐⇒ q) is unsatisfiable. Thus, membership in cl(R) reduces to a propositional satisfiability problem.
Note that every propositional model m : Q → 2 extends uniquely to a bounded lattice homomorphism ¥+(Q) → 2 (where for all p ∈ ¥+(Q), m(p)=1 ⇐⇒ m |=
p). It is easy to see that m is a model of Φ(R) if and only if m is consistent with R. Thus, we may read the definition of cl(R) as the set of all pairs ⟨p, q⟩ such that for every bounded lattice homomorphism m : ¥+(Q) → 2, if m that is consistent with R (i.e., m |= Φ), then we necessarily have m(p)= m(q) (i.e., m |= p ⇐⇒ q). That is, cl(R) is the largest relation such that every bounded lattice homomorphism that is consistent with R is also consistent with cl(R).
The question now is what is the relationship between the congruence closure and the logical closure. We now prove that the two closures are identical. First, a lemma:

Lemma 3.7 Let L = ⟨L, H, H, ⊥, T⟩ be a ﬁnite bounded lattice. For any two distinct elements a, b in L, there is a homomorphism f : L→ 2 such that f (a) /= f (b).
Proof. Without loss of generality, suppose that a /± b. Let c be a join-irreducible element of L such that c ± a and c /± b. The existence of such a c can be proved by contradiction: suppose there exists some a /± b such that there is no join-irreducible element c of L such that c ± a. Since L is finite, there exists a minimal (w.r.t. ±) such element a. By assumption, a is join-reducible so there exists d and dj such that d и a, dj и a, and d Hdj = a. It cannot be the case that both d ± b and dj ± b (if so, then d H dj ± b, but by construction we have a = d H dj /± b). Suppose without loss of generality that d /± b. By minimality of a, there is some join-irreducible element c ± d such that c /± b. Since d и a, we have c ± a and we are done.
Construct a function f : L → 2 by defining
f (e) ,	1	if c ± e
0	otherwise
One may check that f is a bounded lattice homomorphism with f (a) = 1 and
f (b)= 0.	2
Proposition 3.8 Let Q be a ﬁnite set and let R ⊆ ¥+(Q) × ¥+(Q) be a binary relation. Then cl(R) coincides with ≡R.
Proof. Clearly cl(R) is a congruence relation containing R, so ≡R is a subset of cl(R). It remains to show that cl(R) is a subset of ≡R, or equivalently that if p and q are not related by ≡R, then they are not related by cl(R).
Let p and q be such that p /≡R r. Then the equivalence classes [p] and [q]

are distinct in the quotient lattice ¥+(Q)/≡
. By Lemma 3.7, there is a bounded

lattice homomorphism f : ¥+(Q)/≡
→ 2 such that f ([p]) /= f ([q]). Then clearly

f |= Φ(R) (viewing f as a propositional model), but (since f ([p]) /= f ([q])), f |=
p ⇐⇒ q. Therefore, Φ(R) |= p ⇐⇒ q, and p and q are not related by cl(R).  2
Proposition 3.8 yields a simple candidate algorithm for the CONGRUENCE problem: simply check whether the pair of positive Boolean formulae belongs to the logical closure of a relation using a SAT solver. The following proposition states that we cannot hope for an asymptotically superior algorithm.
Proposition 3.9 CONGRUENCE is NP-complete.
Proof. Membership in NP follows immediately from Proposition 3.8. We prove NP-hardness of CONGRUENCE by giving a polytime reduction from SAT. The key insight is that the relation R can be used to axiomatize negation, so that arbitrary Boolean formulae can be encoded into positive Boolean formulae.
Let ϕ be a Boolean formula in conjunctive normal form over a set of propositional variables P . Form a new set of propositional variables
Q , P ∪ {p : p ∈ P}

consisting of the original propositional variables P plus a disjoint set of “barred” copies, intended to represent negative literals. Define a relation R ⊆ ¥+(Q)×¥+(Q) as follows:
R , {⟨p Λ p, false⟩ : p ∈ P}∪ {⟨p V p, true⟩ : p ∈ P}
чp with p. We
Let ϕ^ be the formula obtained by replacing every negative literal
/≡R false.	2
have that ϕ is satisfiable if and only if ϕ^
Finally, using the technical machinery we developed in this section, we prove
Proposition 3.5: R is a bisimulation up to congruence iff ≡R is a bisimulation.
Proof. Consistency: Suppose that p ≡R q. Since cl(R) coincides with ≡R, we have p cl(R) q, and thus Φ(R) |= p ⇐⇒ q. Since R is a bisimulation up to congruence, F is consistent with R, and thus F |= Φ(R) |= p ⇐⇒ q. Thus F (p)= F (q).
Compatibility: Towards the converse, suppose that there exist positive Boolean formulae p, q ∈ ¥+(Q) anda character a ∈ DA such that Δa(p) /≡R Δa(q), and show that p /≡R q.
Since Δa(p) /≡R Δa(q), and cl(R) coincides with ≡R, there exists a model m : Q → 2 such that m |= Φ(R) but m |= Δa(p) ⇐⇒ Δa(q). Since m(Δa(p)) /= m(Δa(q)), it is sufficient to show that m ◦ Δa is consistent with R (since if p and q can be distinguished by a homomorphism consistent with R, then it cannot be the case that p cl(R) q, and thus p /≡R q). Towards proving that m ◦ Δa is consistent with R, let r, s be such that r R s, and prove that m(Δa(r)) = m(Δa(s)). Since R is a bisimulation up to congruence, we have Δa(r) ≡R Δa(s). Since m is consistent with R, we have m |= Δa(r) ⇐⇒ Δa(s) and thus m(Δa(r)) = m(Δa(s)).	2
Equivalence algorithm
We will now show how the theory of bisimulation up to congruence can be leveraged in a decision procedure for s-AFA language equivalence. The algorithm addresses two challenges raised by bringing Bonchi and Pous’ NFA equivalence algorithm to bear on symbolic alternating finite automata: (1) how to efficiently check member- ship in the congruence closure of a relation, and (2) how to efficiently enumerate a sufficient finite set of characters on which to verify the bisimulation conditions.
The equivalence decision procedure is pictured in Algorithm 2. The idea is simple: given an s-AFA M = ⟨A, Q, r0, F, Δ⟩ and two positive Boolean formulae p0 and q0, the algorithm attempts to synthesize a bisimulation up to congruence R such that p0 R q0 or shows that no such R exists.
Checking congruence closure membership: The algorithm implicitly main- tains a relation R such that any bisimulation that contains ⟨p0, q0⟩ must contain
R. The congruence closure of R is represented using an incremental SAT solver. An incremental SAT solver s internally maintains a context formula (initially true) and supports two operations: s.add(ϕ) conjoins the constraint ϕ to s’s context, and s.isSat(ϕ) checks whether the conjunction of ϕ and s’s context is satisfiable. The congruence closure of R = {⟨p1, q1⟩,  , ⟨pn, qn⟩} is represented by a SAT solver with
context Φ(R) = (p1 ⇐⇒ q1) Λ· · · Λ (pn ⇐⇒ qn) (cf. Definition 3.6 and Propo- sition 3.8). We may add a pair ⟨p, q⟩ to the relation R by calling s.add(p ⇐⇒ q)

and we may check whether a given pair ⟨p, q⟩ belongs to ≡R by issuing the query
s.isSat(ч(p ⇐⇒ q)).
The relation R is initialized to the singleton set containing the pair of ⟨p0, q0⟩ of formulae for which we wish to decide equivalence (line 4). Recall that R is a bisimulation up to congruence if and only if it satisfies the consistency and com- patibility conditions given in Definition 3.4. Thus, if at any point the relation R contains a pair ⟨p, q⟩ such that F (p) /= F (q) (i.e., R fails the consistency condition), the algorithm returns false (lines 22-23), having proved that LM (p0) /= LM (q0). Towards the compatibility condition, the algorithm maintains a worklist such that every pair ⟨p, q⟩∈ R such that Δa(p) /≡R Δa(q) for some character a ∈ DA belongs to worklist. The algorithm returns true when worklist is empty (equivalently, when the consistency condition holds).
Enumeration of representative characters: Each iteration of the main loop (lines 5-26) removes a pair ⟨p, q⟩ from the worklist and adds pairs to R that are implied by the membership of ⟨p, q⟩ in R and the compatibility condition. A na¨ıve way to do this is to iterate over the alphabet DA, and for each character a ∈ DA add ⟨Δa(p), Δa(q)⟩ to R and worklist if Δa(p) /≡R Δa(q). However, iterating over the alphabet is not effective because the set of characters may be infinite.
The algorithm overcomes this problem by iterating over a finite set of represen- tative characters, such that if Δa(p) ≡R Δa(q) holds for all representative characters a then it holds for all characters. We may define a set of representative characters as a set of equivalence class representatives of a suitably chosen equivalence relation. Towards this end, for any set of states S ⊆ Q, we define an equivalence relation  S on the set of characters DA as follows:

a  S
b ⇐⇒	∀⟨x, ϕ, q⟩∈ Δ with x ∈ S.	.
a ∈ Jϕ) ⇐⇒ b ∈ Jϕ)

Intuitively, we have a S b if a and b are indistinguishable by transitions emanating from states in S. Observe that if S is the set of states that appear in p or q, then any set B containing one member of each equivalence class of  S is a valid choice for a representative set of characters:
B is finite: follows from the fact that Δ is finite.
B is representative: suppose Δb(p) ≡R Δb(q) for all b ∈ B, and let a ∈ DA – we must prove that Δa(p) ≡R Δa(q). Let c ∈ B such that a  S c. Observe that (by the choice of S and definitions of Δ· and S), we have Δa(p)= Δc(p) and Δa(q) = Δc(q). We have Δa(p) = Δc(p) ≡R Δc(q) = Δa(q) and thus Δa(p) ≡R Δa(q).
Algorithm 2 iterates over the set of representative characters (lines 7-26) by manipulating sets of characters symbolically via the effective Boolean algebra A. The enumeration is reminiscent of the way that AllSat solvers enumerate satisfying assignments to propositional formula [18]. The variable chars, initially T, holds a predicate representing the set of characters that remain to be processed. At each iteration of the loop, we select a character a ∈ Jchars) that has not yet been

1 Procedure IsEquivalent(M, p0, q0)
Input : s-AFA M = ⟨A, Q, p, F, Δ⟩
positive Boolean formulae p0, q0 ∈ ¥+(Q)
Output: true if LM (p0)= LM (q0), false otherwise
2	s → new solver
3	worklist → [(p0, q0)]
4	s.add(p0 ⇐⇒ q0)
5	while worklist is not empty do
6	Pick (p, q) off worklist
7	S → set of states in p or q
/* Jchars) is the set of characters that remain to be processed	*/
8	chars →T 
9	while IsSat(chars) do
10	a → Witness(chars)
/* Compute the transition function Δa and a predicate representing the equivalence class of a in  S.	*/
11	class → true
12	Δa → λx.false
13	for x ∈ S, ⟨x, ϕ, q⟩∈ Δ do
14	if a ∈ Jϕ) then
15	class → class Λ ϕ
16	Δa(x) → Δa(x) V q
17	else
18	class → class Λ чϕ
19	pj → Δa(p)
20	qj → Δa(q)
/* Remove a’s equivalence class from chars	*/
21	chars → chars Λ чclass
22	if F (pj) /= F (qj) then
23	return false
/* If pj /≡R qj, add ⟨pj, qj⟩ to R	*/
24	if s.isSat(ч(pj ⇐⇒ qj)) then
25	Add (pj, qj) to worklist
26	s.add(p ⇐⇒ q)
27	return true
Algorithm 2: Equivalence algorithm for s-AFAs
processed (line 10), and compute a predicate class representing its equivalence class in the relation S:
class ,  {ϕ : Ex, q.⟨x, ϕ, q⟩∈ Δ Λ a ∈ Jϕ)}Λ  {чϕ : Ex, q.⟨x, ϕ, q⟩∈ Δ Λ a ∈/ Jϕ)}.

We then remove every character in a’s equivalence class from the set chars by conjoining chars with the negation of class (line 21). This ensures that on the next

iteration of the loop, we choose a character that is not equivalent to any character seen so far (in the context of AllSat, чclass is sometimes called a blocking clause). Illustrative example: Let M = ⟨A, Q, p0, F, Δ⟩ be an s-AFA over the theory of linear integer arithmetic where there are five states Q = {v, w, x, y, z}, all states are final, and the transitions are as follows:


c≤0
v
c>0
c≤0



w −c−>→0
(y V x) Λ v	x −c−=→1
c/=1
y −−→
z −tr−u→e v

Assume that we want to prove that the state v is equivalent to the state w. The algorithm initializes the relation R to {⟨v, w⟩}, the worklist to [⟨v, w⟩], and enters the main loop:
(R = {⟨v, w⟩}, worklist = [⟨v, w⟩]) We pick ⟨v, w⟩ off the worklist, and enter the inner loop:
(R = {⟨v, w⟩}, worklist = [ ], chars = T) We compute a witness to the satisfiability of chars – this may be any integer, but let’s suppose that we choose 0. We compute the equivalence class of 0 to be class = c ≤ 0 and set chars → chars Λ ч(c ≤ 0). We add ⟨Δ0(v), Δ0(w)⟩ = ⟨x V y, z⟩ to R and the worklist.
(R = {⟨v, w⟩, ⟨x V y, z⟩}, worklist = [⟨x V y, z⟩], chars = ч(c ≤ 0)) We gen- erate 5 as a witness to satisfiability of chars. We compute the equivalence class of 5 to be class = c > 0 and set chars → chars Λ ч(c > 0). We find that
Δ5(v)= z Λ w ≡R (y V x) Λ v = Δ5(w)
and therefore, do not add ⟨Δ5(v), Δ5(w)⟩ to R or the worklist.
(R = {⟨v, w⟩, ⟨xVy, z⟩}, worklist = [⟨xVy, z⟩], chars = ч(c ≤ 0)Λч(c > 0)). We find that chars is unsatisfiable and exit the inner loop.
(R = {⟨v, w⟩, ⟨x V y, z⟩}, worklist = [⟨x V y, z⟩]) We pick ⟨x V y, z⟩ off the worklist, and enter the inner loop:
(R = {⟨v, w⟩, ⟨x V y, z⟩}, worklist = [ ], chars = T): we compute 1 as a witness of satisfiability of chars. We compute the equivalence class of 1 to be class = (c = 1) and set chars → chars Λ ч(c = 1). We find that
Δ1(x V y)= v V false ≡R v = Δ1(z)
and therefore do not add ⟨Δ1(x V y), Δ1(z)⟩ to R or the worklist.
(R = {⟨v, w⟩, ⟨x V y, z⟩}, worklist =[ ], chars = ч(c = 1)) We generate 2 as a witness to satisfiability of chars. We compute the equivalence class of 2 to be class = c /= 1 and set chars → chars Λ ч(c /= 1). We find that
Δ2(x V y)= false V w ≡R v = Δ2(z)
and therefore do not add ⟨Δ2(x V y), Δ2(z)⟩ to R or the worklist.
(R = {⟨v, w⟩, ⟨x V y, z⟩}, worklist =[ ], chars = ч(c = 1) Λ ч(c /= 1)). We find that chars is unsatisfiable and exit the inner loop.

(R = {⟨v, w⟩, ⟨x V y, z⟩}, worklist = [ ]) Since the worklist is empty, the algo- rithm terminates: R is a bisimulation up to congruence containing ⟨v, w⟩, so LM (v)= LM (w).

Implementation and evaluation
We implemented s-AFAs and their decision procedure in the Java symbolicau-
tomata library (open source and available at https://github.com/lorisdanto/ symbolicautomata). The implementation provides an interface for specifying cus- tom Boolean algebras for both the alphabet theory and the positive Boolean
formulae over the automaton states and it can be easily integrated with exter- nally specified alphabet theories. To represent the positive Boolean formulae over the automaton states we implemented two algebras: one which simply maintains the explicit Boolean representations of formulae (referred to as DAG in the ex- periments) and one which instead maintains a BDD corresponding to each for- mula. We use the JDDFactory implementation in JavaBDD as our BDD li- brary (http://javabdd.sourceforge.net). To check membership of formulae to the congruence closure we use the SAT solver Sat4j [2].
We implemented two simple optimizations for improving the performance of our decision procedure. First, whenever we construct an s-AFA, we remove all the states that are trivially non reachable from the initial state or that cannot reach a final state. Given a positive Boolean formula f ∈ ¥+(Q), let st(f ) ⊆ Q be the set of states appearing in f . Given an s-AFA M = ⟨A, Q, p0, F, Δ⟩, we construct a graph GM = ⟨V, E⟩ with set of vertices V = Q, and edges E = {⟨x, y⟩ : (x, ϕ, q) ∈ Δ Λ y ∈ st(q)}. We then remove from M all the states that are not reachable from one of the states s0 ∈ st(p0) in GM and all the states that do not have a path to some state s ∈ F in GM . In each positive Boolean formula of M we replace every removed state with false. The resulting s-AFA is equivalent to Mj.
Second, for the worklist data structure employed by Algorithm 2 we employ a priority queue, where the priority of a pair ⟨p, q⟩ is the sum of the sizes of p and
q. This heuristic leverages the intuition that smaller formulae have fewer successors and are also likely to generate better congruences (e.g., the pair ⟨x, y⟩ generates a larger congruence than ⟨x Λ z, y Λ z⟩). 2
We evaluate our algorithm through two experiments. First, we use s-AFAs to check satisfiability of the LTL formulae appearing in [12] using the semantics of LTL over finite traces from [11] (§ 4.1). Second, we use s-AFAs to check equivalence of Boolean combinations of regular expressions appearing in http://www.regexlib. com/ (§ 4.2). All experiments were run on an Intel Core i7 2.60GHz, 16GB RAM.


2 We have separately evaluated the use of a priority queue for our worklist and our tool also has imple- mentations for FIFO and LIFO. The use of a priority queue consistently outperforms the other heuristics. Concretely, on our benchmarks FIFO and LIFO time out approximately twice as often as the priority queue implementation. We will report data only about the priority queue implementation because it is consistently faster than the other two.



70
60
50
40
30
20
10
0
Random LTL: reverse-SFA - bisim-DAG
5



0






70
60
50
40
30
20
10
0
lift_2.ltl lift_3.ltl lift_4.ltl lift_5.ltl lift_6.ltl lift_7.ltl lift_8.ltl lift_9.ltl
−5

Random LTL: mona - bisim-DAG

5



0
0


−5

bisim−DAG	bisim−BDD	reverse−SFA	mona

Fig. 2. Satisfiability checking for LTL formulae. Non-random formulae on the left and random formulae from [7] on the right. On the right, each point is the difference (in seconds) between one of the two compared algorithms and bisim-DAG.
Satisﬁability checking for LTL over ﬁnite traces
Linear temporal logic (LTL) plays a prominent role in program verification. While the semantics of LTL is typically defined over infinite strings, recently there has been interest in interpreting LTL over finite traces [11]. We use LTL-f to refer to the interpretation of LTL over finite traces. Checking satisfiability of LTL-f formulae is a PSpace-complete problem, but there exists a linear time translation from LTL-f formulae to alternating automata [11]. Since this translation results in an alphabet of size exponential in the number of atomic proposition appearing in the formula, s-AFAs are a promising model for designing decision procedures for LTL-f. Using the translation proposed in [11] we apply our algorithm to checking satisfiability of LTL-f formulae—i.e., by checking equivalence to an empty automa- ton.
We consider three sets of LTL formulae: 1) counter contains 15 formulae de- scribing counters for which satisfiability is notoriously hard [20]. 2) lift contains 8 parametric formulae describing a lift system of increasing complexity [13]. 3) More than 10,000 random formulae appearing in [7]. These formulae have size varying between 10 and 100, and number of atomic propositions varying between 2 and 4. We set the timeout at 60 and 5 seconds for the non-random and random formulae respectively.
We use the translation from LTL-f to monadic second order logic (MSO)
from [11] to compare against Mona [14], a solver for MSO. 3 In LTL-f the alpha-

3 In an early version of this experiment we compared against the tool Alaska [12], which checks for

bet is the set of bitvectors of size n, where n is the number of atomic propositions appearing in the formula and each bit indicates whether one of the atomic proposi- tions is true or false. The constructed s-AFAs will therefore be over the theory of bit-vectors and we use BDDs to describe predicates in such a theory.
We  measure  the  run  times  1)  of  Mona  (mona);  2)  of  comput-
ing the deterministic automaton accepting the reverse language of the s-
AFA and checking its emptiness (reverse-SFA) 4 ; 3) of the bisimulation al- gorithm using a directed acyclic graph (i.e.,  hash-consed) representation of positive Boolean expressions (bisim-DAG); 4) of the bisimulation algo- rithm using BDDs to represent positive Boolean expressions (bisim-BDD). The results are depicted in Figure 2. In

the plots on the right, a point above 0
means that the bisimulation solver is faster than the other solver. Finally, the number of timeouts for the random formulae are shown on the right.
150

100

50

0


bisim−DAG  bisim−BDD  reverse−SFA	mona

Results: Mona outperforms the bisimulation on non-random formulae, but it times out for relatively small instances for which our solver does not. Mona is slower than our algorithm on 87% of the random instances and times out more often. The reverse-SFA algorithm also times out often and is in general slower than the bisim- ulation algorithm. Representing positive Boolean expressions using BDDs is slower and it incurs in more timeouts than those observed using the reverse-SFA algorithm. The slow performance of BDDs is due to the many substitution operations—a slow operation for BDDs—needed by the equivalence algorithm. This experiment illus- trates that s-AFAs and our bisimulation technique are a viable solution for checking satisfiability of LTL-f formulae.
Boolean combinations of regular expressions
Regular expressions are ubiquitous and their analysis is fundamental in many do- mains, from deep-packet inspection in networking [23] to static analysis of string- manipulating programs [1]. In these domains, classic automata techniques fall short because large alphabets and Boolean operations produce automata with large num- ber of states and transitions. In this experiment, we ask is our technique more efficient than existing automata techniques when analyzing Boolean combinations of regular expressions? We use unions of intervals to represent predicates in the alpha- bet theory; this representation naturally models character classes—e.g., [a-z0-9]. The ability to easily change the representation of the underlying alphabet illustrates the versatility of s-AFAs.

satisfiability of LTL-f formulae using a BDD-based variant of alternating automata. After observing that Mona consistently outperformed Alaska, we decided to only report the comparison against Mona. We do not compare against non-symbolic automata libraries as these would not support large alphabets. Moreover, most libraries only support NFAs [4], which would force us to choose a way to encode the LTL formulae into NFAs. We also do not compare against model checkers such as NuSMV and Spin, since they only support LTL over infinite traces.
4 The s-AFA to s-FA conversion is doubly exponential in the worst case (this bound is tight), but construct- ing an s-FA recognizing the reverse language of an s-AFA yields an automaton that has only exponential size.

We consider regular expressions from http://www.regexlib.com/, a site con- taining more than 3,000 crowd-sourced regular expressions for tasks such as email filtering, phone number detection, and URL detection. We isolate the first 75 regu- lar expressions for email filtering and consider Boolean combinations of them. For each experiment we set the timeout at 20 seconds.
Equivalence checking: We evaluate the performance of our algorithm on checking equivalence of intersected regular expressions (figure on the right). This exper- iment is inspired by the spam-filtering application de- scribed in the introduction. We identify sets of regular expressions {r1,..., rn} such that L(r1) ∩... ∩L(rn) /= ∅ and n ∈ {3, 4, 5}. Here L(r) denotes the set of strings accepted by r. We measure the time required to check whether L(r1) ∩ ... ∩ L(rn) = L(r1) ∩ ... ∩ L(rn+1). We only illustrate instances on which at least one solver does not timeout and, for each value of n, we generate the first 6,000 combinations, in lexicographic order. We compare our algorithm (bisim-DAG) against the clas- sic decision procedure based on finite automata intersec- tion and equivalence (SFAEq). Concretely, for each set of regular expressions we build the corresponding (non- alternating) symbolic finite automata (s-FAs), perform automata intersection, and then use a lazy version of
Hopcroft-Karp algorithm [15] to check the equivalence of the resulting automata
while lazily determinizing them on the fly. For a fair comparison we consider sym- bolic finite automata instead of classic automata, as the latter would suffer from the large alphabet size. In fact, the explicit alphabet implementation of NFA equiv- alence proposed by Bonchi and Pous [4], throws a stack overflow exception when handling the large alphabets required by regular expressions.
When measuring the running time of this procedure we consider the cumulative cost of all operations. For the bisimulation experiment, we take advantage of the fact that our algorithm can also check the equivalence of two configurations of the same s-AFA. In particular, instead of building two s-AFAs and checking whether they accept the same language, we only build one s-AFA and check the equivalence of the two state configurations corresponding to L(r1) ∩... ∩L(rn) and L(r1) ∩... ∩ L(rn) ∩ L(rn+1). Given a set of regular expressions {r1,..., rn+1}, let {A1,..., An} be the corresponding non-deterministic s-FAs (notice that an s-FA is also an s- AFA) with corresponding initial states {q1,..., qn}. After building the intersected
0	0
s-AFA A = A1 ∩ ... ∩ An+1 with initial state q1 Λ ... Λ qn+1, we check whether the
0	0
state q1 Λ ... Λ qn is equivalent to the state q1 Λ ... Λ qn+1.
0	0	0	0
The results are shown below. A point above the diagonal is an instance where
bisim-DAG is faster. The first two entries of Figure 6 show the number of instances on which each algorithm timed out.


Regular expressions #timeouts
600
500
400
300
200
100
0






Fig. 6. Timeout distribution for regular expression equivalence checks.
Forced equivalence checking: In the previous ex- periment almost all tuples return inequivalent as the	 result. To appreciate the cost of verifying equivalence
rather than refuting it, we perform the following ex- periment. For every tuple {r1,..., rn} (n ∈ {3, 4}) such that L(r1) ∩ ... ∩ L(rn) /= ∅, we measure the
time required to check whether L(r1) ∩ ... ∩ L(rn) =	 L(r1) ∩ ... ∩ L(rn) ∩ L(rn), where one of the regular ex- pressions is added twice. 5 We only illustrate instances
on which at least one solver does not timeout (figure on the right). The last two entries in Figure 6 show the number of timeouts for each algorithm.
Results: The two algorithms have orthogonal perfor- mances and neither of them strictly outperforms the other one. The bisimulation is faster than the s-FA al- gorithm on approximately 40% of the instances, but it times out on 809 (11%) fewer instances. This is mostly due to the prohibitive cost of computing the intersected
s-FA. This experiment shows that our algorithm is useful for analyzing regular ex- pressions and it will be a great addition to regular expression engines. Finally, we also measured how many states each algorithm explored in the forced equivalence experiment. The bisimulation procedure explored fewer states than the other algo- rithm 46% of the times. These are typically instances for which the bisimulation algorithm is the faster one.
Related work
Automata with predicates: The concept of automata with predicates was first
mentioned in [27]. s-FAs were then formally introduced in [26]. D’Antoni et al.

5 In our implementation, to make the comparison fair and make the computation of the bisimulation non- trivial, we create an isomorphic copy of the automaton for the last formula rather than re-using it. Thus, the bisimulation formula corresponding to the equivalence of the initial states has the shape q1 ∧ ... ∧ qn ⇐⇒
q1 ∧ ... ∧ qn ∧ q∗ , where q∗ is the start state of an automaton disjoint from the one for qn.
n	n

studied alternation for symbolic tree automata, but all their techniques are based on classic algorithms for eliminating alternation and reductions to non-alternating automata [10]. Our approach is different from the one in [10] as our equivalence procedure does not need to build the s-FA corresponding to an s-AFA. D’Antoni and Veanes also designed algorithms for computing forward bisimulations of non- deterministic s-FAs [9]. However, their algorithm does not use congruences and cannot handle alternation. The Mona implementation [16] provides decision proce- dures for monadic second-order logic, and it relies on a highly-optimized BDD-based representation for automata which has seen extensive engineering effort [16]. There- fore, the use of BDDs in the context of automata is not new, but is used here as an example of a Boolean algebra that seems particularly well suited for working with the alternating automata generated by LTL formulae.
Alternating automata: Alternation is a classic concept in computer science and and the notion of alternating automata dates back to the 80s [5,6]. Vardi recog- nized the potential of such a model in program verification, in spite of their high theoretical complexities [24]. Alaska was one of the first practical implementations of alternating automata [12]. In Alaska, the alphabet and the set of states are both represented using bit-vectors and this allows to model the search space using BDD.
While this representation is somewhat similar to ours, s-AFAs are more modu-
lar because they support arbitrary alphabets and alphabet representation (not just bit-vectors and BDDs) and arbitrary state representations (again not just BDDs). Alaska performs state-space reduction using antichains while checking AFA empti- ness. As shown by Bonchi and Pous [4], bisimulation up to congruence strictly subsumes antichain reduction.
Equivalence using bisimulation up to: The use of bisimulations to prove equiva- lence between languages of finite and infinite words has long been established [19,21]. Bisimulation up-to was introduced as a technique for simplifying bisimulation-based equivalence proofs for concurrent processes [22], and has since been studied exten- sively in the setting of concurrency theory, coalgebra, and formal language theory
— many references can be found in [3]. The paper that most relates to ours is by Bonchi and Pous [4], where the idea of bisimulation up to congruence is used to check equivalence and inclusion of non-deterministic finite state automata (NFAs). There are two main differences with the ideas we presented here. First, our work ex- tends bisimulation up to congruence to alternating finite automata. The extension is non-trivial: while Bonchi and Pous showed that for NFAs, membership within the congruence closure can be computed in polynomial time, we showed that for AFAs the problem is NP-complete, and gave an practical algorithm that leverages propo- sitional satisfiability solvers. Second, the techniques in [4] apply to NFAs operating over finite alphabets (and most of the presented examples operate over alphabets of size two). We showed how to extend the technique to symbolic alphabets using representative character enumeration. Our method can also be used to extend the NFA equivalence algorithm [4] to symbolic alphabets.

References
R. Alur, L. D’Antoni, and M. Raghothaman. Drex: A declarative language for efficiently evaluating regular string transformations. In POPL, pages 125–137, 2015.
D. L. Berre and A. Parrain. The sat4j library, release 2.2. JSAT, 7(2-3):59–6, 2010.
F. Bonchi, D. Petri¸san, D. Pous, and J. Rot. A general account of coinduction up-to. Acta Informatica, 54(2):127–190, 2017.
F. Bonchi and D. Pous. Checking NFA equivalence with bisimulations up to congruence. In POPL, pages 457–468, 2013.
J. A. Brzozowski and E. L. Leiss. On equations for regular languages, finite automata, and sequential networks. Theor. Comput. Sci., 10:19–35, 1980.
A. K. Chandra, D. C. Kozen, and L. J. Stockmeyer. Alternation. J. ACM, 28(1):114–133, Jan. 1981.
M. Daniele, F. Giunchiglia, and M. Y. Vardi. Improved automata generation for linear temporal logic. In CAV, pages 249–260, 1999.
L. D’Antoni and M. Veanes. Minimization of symbolic automata. In POPL, pages 541–553, 2014.
L. D’Antoni and M. Veanes. Forward bisimulations for nondeterministic symbolic finite automata. In
TACAS, 2017.
L. D’antoni, M. Veanes, B. Livshits, and D. Molnar. Fast: A transducer-based language for tree manipulation. ACM Trans. Program. Lang. Syst., 38(1):1:1–1:32, Oct. 2015.
G. De Giacomo and M. Y. Vardi. Linear temporal logic and linear dynamic logic on finite traces. In
IJCAI, pages 854–860, 2013.
M. De Wulf, L. Doyen, N. Maquet, and J. F. Raskin. Antichains: Alternative algorithms for LTL satisfiability and model-checking. In TACAS, pages 63–77, 2008.
A. Harding. Symbolic strategy synthesis for games with LTL winning conditions, Tech. Report 2005.
J. Henriksen, J. Jensen, M. Jørgensen, N. Klarlund, B. Paige, T. Rauhe, and A. Sandholm. Mona: Monadic second-order logic in practice. In TACAS, 1995.
J. E. Hopcroft and R. M. Karp. A linear algorithm for testing equivalence of finite automata. Technical report, Cornell University, 1971.
N. Klarlund, A. Møller, and M. I. Schwartzbach. MONA implementation secrets. IJFCS, 13(4):571– 586, 2002.
G. Le Guernic, A. Banerjee, T. Jensen, and D. A. Schmidt. Automata-based confidentiality monitoring. In Advances in Computer Science - ASIAN, pages 75–89, 2007.
K. L. McMillan. Applying SAT methods in unbounded symbolic model checking. In CAV, pages 250–264, 2002.
D. Park. Concurrency and automata on infinite sequences. In TCS, pages 167–183, 1981.
K. Y. Rozier and M. Y. Vardi. LTL satisfiability checking. In Model Checking Software: 14th International SPIN Workshop, pages 149–167, 2007.
J. J. M. M. Rutten. Automata and coinduction (an exercise in coalgebra). In CONCUR, pages 194–218, 1998.
D. Sangiorgi. On the bisimulation proof method. Mathematical Structures in Computer Science, 8(05):447–479, 1998.
R. Smith, C. Estan, S. Jha, and S. Kong. Deflating the big bang: Fast and scalable deep packet inspection with extended finite automata. In SIGCOMM, pages 207–218, 2008.
M. Y. Vardi. Alternating automata and program verification. In Computer Science Today: Recent Trends and Developments, pages 471–485. 1995.
M. Veanes, N. Bjørner, and L. De Moura. Symbolic automata constraint solving. In LPAR, pages 640–654, 2010.
M. Veanes, P. de Halleux, and N. Tillmann. Rex: Symbolic regular expression explorer. In ICST, pages 498–507, 2010.
B. W. Watson. Implementing and using finite automata toolkits. In Extended finite state models of language, pages 19–36, New York, NY, USA, 1999. Cambridge University Press.
