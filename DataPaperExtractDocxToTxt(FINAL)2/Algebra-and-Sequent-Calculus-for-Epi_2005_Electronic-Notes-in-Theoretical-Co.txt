Electronic Notes in Theoretical Computer Science 126 (2005) 27–52  
www.elsevier.com/locate/entcs


Algebra and Sequent Calculus for Epistemic Actions

Alexandru Baltag 1 ,2
Computing laboratory Oxford University Oxford, U.K.

Bob Coecke 3
Computing laboratory Oxford University Oxford, U.K.

Mehrnoosh Sadrzadeh4
Department of Philosophy Universit´e du Qu´ebec A` Montr´eal Montreal, Canada


Abstract
We introduce an algebraic approach to Dynamic Epistemic Logic. This approach has the advan- tage that: (i) its semantics is a transparent algebraic object with a minimal set of primitives from which most ingredients of Dynamic Epistemic Logic arise, (ii) it goes with the introduction of non-determinism, (iii) it naturally extends beyond boolean sets of propositions, up to intuition- istic and non-distributive situations, hence allowing to accommodate constructive computational, information-theoretic as well as non-classical physical settings, and (iv) introduces a structure on the actions, which now constitute a quantale. We also introduce a corresponding sequent calcu- lus (which extends Lambek calculus), in which propositions, actions as well as agents appear as resources in a resource-sensitive dynamic-epistemic logic.
Keywords: dynamic epistemic logic, quantale, module, resources.



1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.11.012

Introduction
Dynamic Epistemic Logic (DEL) is a PDL-style logic to reason about epistemic actions and updates in a multi-agent system. It focuses in particular on epis- temic programs, i.e. programs that update the information state of agents, and it has applications to modelling and reasoning about information-flow and information exchange between agents. This is a major problem in several fields such as secure communication where one has to deal with the privacy and authentication of communication protocols, Artiﬁcial Intelligence where agents are to be provided with reliable tools to reason about their environ- ment and each other’s knowledge, and e-commerce where agents need to have knowledge acquisition strategies over complex networks.
The standard approach to information flow in a multi-agent system has been presented in [9] but it does not present a formal description of epistemic programs and their updates. The first attempts to formalize such programs and updates were done by Plaza [22], Gerbrandy and Groeneveld [13], and Gerbrandy [11,12]. However, they only studied a restricted class of epistemic programs. A general notion of epistemic programs and updates for DEL was introduced in [4,5]. However, in this approach the underlying logic on propo- sitions is boolean. For computational purposes one might want to relax this to an intuitionistic setting, hence conceiving propositions as being structured in a Heyting algebra. On the other hand, continuous lattices are also models of partiality of knowledge [10], and are in general not distributive. Finally, ac- tual physical computational situations such as quantum computation require (at least) a non-boolean setting.
In this paper we generalize ‘boolean’ DEL by introducing the notion of an abstract epistemic system. This generalization goes hand-in-hand with the introduction of non-determinism for states and actions and brings algebraic clarity to the semantics. The particular algebraic object which we introduce is a refinement of previously used objects tailored to study concurrency in computer science [1,23] and the dynamics and interaction of physical systems [7]. Such an abstract epistemic system consists of a quantale Q of epistemic programs, a Q-right module M of epistemic propositions, and each agent is encoded by an appearance map i.e. an endomorphism of the (M, Q)-structure. We show that the boolean DEL of [5] is a concrete example of such an abstract

1 We thank S. Abramsky, A. Joyal, D. Pavlovic and I. Stubbe for valuable discussions.
M. S. thanks S. Abramsky and Oxford University Computer Laboratory for their hospitality and M. Marion for logistic support.
2 Email: baltag@comlab.ox.ac.uk
3 Email: coecke@comlab.ox.ac.uk
4 Email: sadrzadeh.mehrnoosh@courrier.uqam.ca


epistemic system. The axioms of the modal operators follow immediately from abstract properties of quantales and modules over them. Crucial notions of DEL are definable abstractly and some new notions emerge naturally. The passage to a non-boolean theory also provides a new insight into epistemic programs such as public announcement and, of a surprisingly different status, public refutation. We sketch an analysis of the muddy children puzzle and of a cryptographic attack in our setting and also provide a motivating example for the passage to a non-boolean theory. We also provide a corresponding sequent calculus in which sequents will typically look like
m1,..., q1,... , A1,... , mk,... , ql,... , An ▶ δ
where m1,... , mk are propositions, q1,... , ql are actions and A1,... An are agents which resolve into a single proposition or action δ. The fragment of the calculus restricted to actions is the Lambek calculus [19], hence resource sensitive.

Epistemic propositions and epistemic programs
In this section we slightly recast and enrich the Dynamic Epistemic Logic of
[5] in such a way that it enables a smooth passage to the algebraic setting to be introduced in Section 4. Part of this involves the introduction of non- determinism for both states and actions.

State models.
For a set of facts Φ and a finite set of agents A, a state model is a triple
S = (S, →A , µ)


where S is the set of states,
→A ⊆ S × S the accessibility relation for each

agent A ∈ A, and µ : S → P(Φ) the valuation map which encodes satisfaction s |= ϕ ⇔ ϕ ∈ µ(s). The “facts” ϕ ∈ Φ are simple, objectives features of the world (“objective” in the sense of non-epistemic, i.e. independent of the agents’ knowledge or beliefs), and the valuation map tell us what facts hold in a given state s ∈ S. Each accessibility relation can be repackaged as a map


f : S → P(S) :: s '→ f (s) := {t ∈ S | s →A
t} ,

called the appearance map of agent A. The significance of the appearance maps is as follows: if t ∈ fA(s) then, whenever agent A is in state s he considers


state t as a ‘possible world’. In other words, if the actual state of the system is s, agent A thinks t may be the actual state.
As an example, 5 consider two players A, B and a referee C. In front of everybody, the referee throws a fair coin, catches it in his palm and fully covers it, before anybody (including himself) can see on which side the coin has landed. There are two possible states here, state s in which ‘the coin lies Heads’ up (= H ∈ Φ), hence µ(s) = {H}, and state t in which the coin lies Tails up (= T ∈ Φ), hence µ(t)= {T }. We depict the state model Toss as
,Js¸˜:H `,\ ,r z,Jt¸˜:,T `,\ .
.,A,B,C .,

A,B,C	A,B,C
For every agent there are arrows between any two states (including identical states), which means that nobody knows the ‘real state’.
We can also consider a case in which agents B and C can see the face of the coin, but agent A cannot see it (although he knows that the others see it), so he is still uncertain if the coin is heads or tails. In this case only agent A has several arrows between states whereas agents B and C have only one arrow in each state, which means that if the coin is heads up they know it and similarly for tails up. Hence PToss gets depicted as
s,J¸˜':H `,\ ,r z,Jt¸˜',: `T,\ .
 , A	 ,
A,B,C	A,B,C

An epistemic proposition P over a state model S is a subset P of S, containing all the states at which the proposition is ‘true’. The maps µ and fA of the state model are extended to elements of P as follows
µ(P ) :=  {µ(s) | s ∈ P } ∈ P(Φ)    fA(P ) :=  {fA(s) | s ∈ P } ∈ P(S) .

Note that we have to use intersection and not union in defining µ(P ) since a fact is entailed by an epistemic proposition when it holds at all the states of the proposition. This makes the passage from P(S) to P(Φ) contravariant. In other words, the actual algebra of facts is P(Φ)op, that is, the complete boolean algebra P(Φ) where the order is reversed i.e. ϕ1 ≤op ϕ2 ⇔ ϕ1 ⊇ ϕ2. While facts are simple and non-epistemic, and thus cannot be altered by epistemic actions (see further), epistemic propositions can express complex features of the world, which may depend on the agents’ knowledge (and so may be changed by epistemic actions). However, notice that each fact ϕ ∈ Φ

5 For a more elaborated example of an authentication protocol we refer the reader to [2].


corresponds to an epistemic proposition Pϕ := {s ∈ S | ϕ ∈ µ(s)}, saying that the fact holds in the current state.
In the Toss model, H and T are facts expressing the heads up or tails up of the coin. The epistemic propositions that correspond to these facts are the states in which the fact holds. The epistemic propositions are ∅, {s}, {t}, {s, t} ⊆ 
{s, t}. We depict an epistemic proposition over a state model by double- circling the included states, hence

,Js¸˜:H `,\ ,r z,Jt¸˜:,T `,\
,J,Js¸˜¸˜:H ` `,\,\ ,r z,Jt¸˜:,T `,\
,Js¸˜:H `,\ ,r z,J,J¸˜t¸˜:,T ` `,\,\
,J,Js¸˜¸˜:H ` `,\,\ ,r z,J,J¸˜t¸˜:,T ` `,\,\

.,A,B,C

A,B,C
.,
A,B,C
  ,A,B,C
A,B,C
.,
A,B,C
.,A,B,C

A,B,C
 ,
A,B,C
 , A,B,C
A,B,C
 ,
A,B,C

represent the four epistemic propositions of Toss.
When a proposition P has exactly one state s ∈ P (i.e. P = {s} is a singleton), we shall use systematic ambiguity, identifying the proposition with the state and writing e.g. P = {P }.

Action models.
Given a state model S, an action model over S is a triple
Σ = (Σ, →A , µ)
similar to a state model except that we think of the elements of Σ as possible actions instead of possible states and the valuation µ : Σ → P(S) assigns to each action σ a precondition, i.e. a proposition µ(σ) definining the domain of applicability of σ: action σ can happen ina state s iff s ∈ µ(σ) ; e.g. a truthful announcement of a fact can only happen in those states where that fact holds. Note that since P(S) is boolean we can equivalently consider the states at which the action cannot take place . These states, which are the complements of the precondition of an action are denoted as Ker(σ) := S \ µ(σ) for each σ ∈ Σ. The effect of an action on states and appearance maps will be defined below in terms of an epistemic update product.
We introduce an action model over Toss. After catching the coin in his hand the referee might secretly take a peek at the coin before covering it while nobody notices this. The action model is now depicted as
J,˜¸σ` z,  A,B  z,J¸’τ ,,z

C	A,B,C
where σ stands for ‘cheating’ and τ for ‘nothing happens’ and µ(σ)= {s, t}. The action model can be refined when replacing σ by σH and σT where µ(σH) = {s} and µ(σT ) = {t}, specifying what the referee saw in case of deceit. Pictorially



A,B  zJ,’¸τ

C



A,B

B,C


An epistemic program π over an action model Σ is a subset π of Σ; the µ and
fA maps are both extended covariantly by continuity
µ(π) :=  {µ(σ) | σ ∈ π} ∈ P(S)  and  fA(π) :=  {fA(σ) | σ ∈ π} ∈ P(Σ) .
The union in the definition of µ maps for programs says that an epistemic program is applicable where at least one of its actions is applicable. This makes the Ker map follow contravariantly by boolean negation i.e. Ker(π) := S \ µ(π) or equivalently Ker(π) := {Ker(σ) | σ ∈ π}. Epistemic programs introduce non-determinism: whenever π1 ⊆ π2 then π2 is obtained from π1 by increasing nondeterminism; π = {σ1, σ2} stands for “either action σ1 or action σ2 takes place”.
In our example with actions σH , σT and τ the epistemic program {σH, σT } stands for the non-deterministic action σ, in the sense that the outcome of the toss can be either. We depict the program over an action by double-circling the including actions. Hence the picture of the program π = {σH, σT } over
is

A,B   ,J¸’τ

C



A,B

B,C

,JJ,σ¸˜˜¸'``T  z,,\
As in the case of states and propositions, we use systematic ambiguity to identify deterministic programs π = {σ} with their unique underlying action σ.

Update.
Given a state model S and an action model Σ over S we define their update
S⊗Σ :=	µ(σ)×{σ}	fA(s, σ) := (fA(s)×fA(σ)) ∩ (S⊗Σ)	µ(s, σ) := µ(s) .
σ∈Σ
In simpler terms we have S ⊗ Σ= {(s, σ) | s ∈ µ(σ),σ ∈ Σ} ⊆ S × Σ and also fA(s, σ) ⊆ fA(s)×fA(σ) that is (s', σ') ∈ fA(s, σ) iff s' ∈ fA(s) and σ' ∈ fA(σ). As it will become more explicit in the abstract algebra of next section, update is a structure preserving operation in the sense that it has no side effect on


the state model that it acts on. In our example, after the cheating action σH where the coin has lied Heads up, A and B think that nobody knows on which side the coin is lying. But they are wrong! The system after this action can be updated by taking the update product of the two models Toss and σH depicted above:

C



A,B


¸¸¸¸
¸¸¸

,J¸˜, `,\ 	,Jr¸˜ ` ,\
.,A,B,C ,
A,B,C	A,B,C
Note that in general S ⊗ Σ and S are not necessarily disjoint. 6
Definition 2.1 We define the update product of an epistemic proposition P
over S and an epistemic program π over	as the epistemic proposition
P ⊗ π :=	(µ(σ) ∩ P ) × {σ} ⊆ P × π over S ⊗	.
σ∈π
The proposition P ⊗ π provides the strongest postcondition for P with respect to epistemic program π. This means that if proposition P is true at the input of program π then P ⊗ π is the strongest proposition that is true at the output of π. It can be seen that P ⊗ π = ∅ iff P ∩ µ(π) = ∅, where ∅ is the falsum (i.e. the trivially false epistemic proposition over S).

Modalities.
We define the epistemic modality for each agent A ∈ A as the unary connective which assigns to proposition P ⊆ S over S another proposition
 AP := s ∈ S	fA(s) ⊆ P	over S.
We read AP as ‘agent A knows or believes P ’. 7
We define the dynamic modality for each epistemic program π over
as the unary connective which assigns to proposition P ⊆ S over S another proposition
[π]P := s ∈ S	{s}⊗ π ⊆ P	=   Q ∈ P(S)  Q ⊗ π ⊆ P	over S .

6 In fact later, the most important models we shall consider later (DEL models) are closed with respect to update product, i.e. S ⊗ Σ ⊆ S.
7 Taking either ‘knows’ or ‘beliefs’ depends on the context.


Note that (as mentioned before) some states s ∈ S can be themselves pairs of states and actions (s, σ) which make the above definition well defined. The proposition [π]P provides the weakest precondition for P with respect to the epistemic program π. This means that if proposition P is true at the output of program π then [π]P is the weakest proposition that should have been true before π.

Sequential composition.
The sequential composition Σ1 • Σ2 over S of two action models Σ1 and

Σ1•Σ2 := Σ1×Σ2	fA(σ1, σ2) := fA(σ1)×fA(σ2)	µ(σ1, σ2) := µ(σ1)∩[σ1]µ(σ2).


In simpler terms, (σ' , σ' ) ∈ fA(σ1, σ2) iff σ' ∈ fA(σ1) and σ'
∈ fA(σ2) and

1	2	1	2
also µ(σ1, σ2)= {s ∈ S | s ∈ µ(σ1),s ⊗ σ1 ∈ µ(σ2)}. Again note that Σ1 • Σ2
and Σ1 (or Σ2) are not necessarily disjoint. 8 The action model over a state model S contains an action skip in which nothing happens iff 9
skip = {skip}	µskip = S = TP (S)	fA(skip) = {skip} .
Notice the use of systematic ambiguity: we denoted with the same name (skip
) both the program skip and its only action. It is easy to see that skip is a unit, up to isomorphism, both for update product and sequential composition.
Definition 2.2 We define the sequential composition of two epistemic pro- gramΣs π1 oΣver	1 and π2 over	2 as the epistemic proposition π1•π2 := π1×π2

Concrete epistemic systems.
We now have all the tools to make the passage of DEL in the sense of
[5] to ‘concrete epistemic systems’ which we put forward as a stepping-stone towards ‘abstract epistemic systems’. A DEL model is essentially one that is closed under update product and sequential composition (and contains a skip), while a concrete epistemic system consists of all the epistemic propositions and all the epistemic programs of a DEL model:
Definition 2.3 A DEL model is a pair (S,	) where S is a state model and is an action model over S such that skip ∈ Σ, (S ⊗ Σ) ⊆ S and (Σ• Σ) ⊆ Σ.
Definition 2.4 Given a DEL model (S,	), a concrete epistemic system is the pair (P(S), P(Σ)) which goes equipped with valuation µ, appearance maps

8 In fact later we only consider models where Σ • Σ ⊆ Σ.
9 This action has been denoted as τ in the preceding examples.

{fA}A∈A and all other operations of the DEL model extended to P(S) and
P(Σ) as we showed before.

The algebra of programs and propositions
A sup-lattice L is a complete lattice with maps which preserve arbitrary joins as homomorphism. Recall that each sup-lattice also has arbitrary meets, namely
  ai =  {b ∈ L | ∀i, b ≤ ai}

for any A ⊆ L. Hence the designation ‘sup-lattice refers to the fact that we require structure-preserving maps only to preserve arbitrary joins (cf. the designations locales and frames for complete Heyting algebras [17]). We denote bottom and top of L by ⊥ and T respectively and define its set of atoms as
Atm(L) := {p ∈ L \ {⊥} | a ≤ p ⇒ a = ⊥}.
A lattice L is atomistic iff
∀a ∈ L, a =  {p ∈ Atm(L) | p ≤ a} .
Every sup-morphism f ∗ : L → M has a (unique) right Galois adjoint f∗
satisfying
f ∗(a) ≤ b
a ≤ f∗(b)
and can be explicitly given as
f∗ : M → L :: b '→  {a ∈ L | f ∗(a) ≤ b}.
The left Galois adjoint f ∗ moreover preserves arbitrary meets. We denote an adjoint pair by f ∗ E f∗. In computational terms, one can think of the left Galois adjoint f∗ as assigning weakest preconditions with respect to the program f ∗.
A quantale 10 is a sup-lattice Q equipped with a monoid structure (Q, •, 1) satisfying

a •   bi  =  (a • bi)	  ai • b =  (ai • b) .


10 The term ‘quantale’ was introduced in [21]. For a survey on quantales we refer to [24]. For insightful categorical perspectives on quantales and Q-modules we refer to [18] and [25].


Hence for all a ∈ Q the maps a • − : Q → Q and − • a : Q → Q preserve arbitrary joins and hence they have Galois adjoints (a • −) E (a \ −) and (−• a) E (−/a) explicitly given by
a \ b :=  {c ∈ Q | a • c ≤ b}	b/a :=  {c ∈ Q | c • a ≤ b}.

We refer to (a\−) and (−/a) as the residual operations. A quantale homomor- phism is both a sup-homomorphism and a monoid-homomorphism. Examples of quantales are: the set sup(L) of all sup-endomorphisms of a complete lattice L ordered pointwisely; the set of all relations from a set X to itself ordered by pointwise inclusion — this quantale is isomorphic to sup(P(X)); the powerset of any monoid with composition extended by continuity.
A Q-right module for a quantale Q is a sup-lattice M which goes equipped with a module action −⊗ − : M × Q → M, that is,
m ⊗ 1= m
m ⊗ (q1 • q2)= (m ⊗ q1) ⊗ q2
m ⊗ (  qi)=  (m ⊗ qi)	(  mi) ⊗ q =  (mi ⊗ q)

Again we have two right Galois adjoints − ⊗ q E [q]− and m ⊗ − E {m}−
where
[q]m :=  {m' ∈ M | m' ⊗ q ≤ m}	{m}m' :=  {q ∈ Q | m⊗ q ≤ m'}.
As for some examples, a quantale Q is a Q-right module over itself with composition as the tensor and a complete lattice L is a sup(L)-right module with function application as the tensor.
Definition 3.1 A system is a pair (M, Q) with Q a quantale and M a Q-right module [1].
A system is atomistic when both M and Q are atomistic and the following equations hold
m ∈ Atm(M ),q ∈ Atm(Q) =⇒ m ⊗ q ∈ Atm(M ) ∪ {⊥}
q1, q2 ∈ Atm(Q) =⇒ q1 • q2 ∈ Atm(Q) .
These conditions can be interpreted as the fact that ‘the atoms of both the quantale and the module behave deterministically’.
Proposition 3.2 i. Epistemic programs P(Σ) with as , sequential com- position as • and ‘skip’ as 1 form a quantale. 11 ii. Epistemic propositions

11 This construction is implicit in the relational composition of dynamic actions in [15].

P(S) with  as  and update product as ⊗ form a right P(Σ)-module 12 .
The pair (P(S), P(Σ)) is an atomistic system. The atoms of the module P(S) correspond to the states s ∈ S, while the atoms of the quantale P(Σ) correspond to the actions σ ∈ Σ.
Proposition 3.3 i.  The appearance maps fA : P(S) → P(S), and for all π ∈ Σ the maps − ⊗ π : P(S) → P(S) are all sup-homomorphisms. ii. The appearance maps fA : P(Σ) → P(Σ), and for all π ∈ Σ the maps π • −, − • π : P(Σ) → P(Σ) are quantale-homomorphisms. iii. For every epistemic proposition P ∈ P(S) and every epistemic program π ∈ P(Σ), we have
fA(P ⊗ π) ⊆ fA(P ) ⊗ fA(π) .
For every state (i.e. atomic proposition) s ∈ S and every action (i.e. atomic program) σ ∈ Σ we have that:
if s ⊗ σ /= ∅  then fA(s ⊗ σ)= fA(s) ⊗ fA(σ) .
The last property can be generalised by introducing a notion of coherence:
Definition 3.4 A pair (P, π) where P is an epistemic proposition and π is an epistemic program is coherent iff
∀s ∈ P, ∀σ ∈ π s ⊗ σ /= ∅
i.e. iff P ⊆ µ(σ) for every σ ∈ π. This means that proposition P ensures the possibility of all the actions subsumed by program π. An equivalent definition which doesn’t refer to states or actions is the following:
∀P ' ⊆ P, ∀π' ⊆ π (P ' ⊗ π' = ∅ ⇒ P ' = ∅ or π' = ∅) .
Proposition 3.5 If (P, π) is a coherent pair then we have
fA(P ⊗ π)= fA(P ) ⊗ fA(π) .
Proposition 3.6 i. For A ∈ A the right Galois adjoint to appearance f S(−): 

P(S) → P(S) is knowledge  S
A
— (=the epistemic modality). ii. For π ∈

P(Σ) the right Galois adjoint to update −⊗ π : P(S) → P(S) is the dynamic modality [π]−. iii. The right Galois adjoint to appearance f Σ(−) : P(Σ) → P(Σ) introduces an epistemic modality Σ− on actions. iv. The right Galois adjoint to left- and right-composition π • −, − • π : P(Σ) → P(Σ) introduce respectively weakest pre-speciﬁcation π\− and strongest post-speciﬁcation π/−,

12 By this construction it becomes clear that update is a structure preserving map on epis- temic propositions and has no side effects.


and the right Galois adjoint to P ⊗ − : P(Σ) → P(S) introduces {m}−, a variant on this. 13
Proof. All follows by construction and basic facts on sets, cartesian products and relations.	 

Abstract epistemic systems
The propositions of the previous section lead us to the following definitions:
Definition 4.1 A system-endomorphism (M, Q) → (M, Q) is a pair
f M : M → M , f Q : Q → Q
where f M is a sup-homomorphism, f Q is a quantale homomorphism and
f M (m ⊗ q) ≤ f M (m) ⊗ f Q(q)	(1) for all m ∈ M and q ∈ Q.
Definition 4.2 An (abstract) epistemic system is a tuple (M, Q, {fA}A∈A)
where (M, Q) is a system and {fA}A∈A are system-endomorphisms.

Interpretation.
The elements of the quantale Q are to be thought of as the epistemic pro- grams and its unit as skip, the elements of the module M are to be thought of as the epistemic propositions, or if one wants, the not necessarily deterministic states, the labels A ∈ A are the agents with the endomorphisms {fA}A∈A as their appearance maps. The kernel of a program q ∈ Q is
Ker(q) := {m ∈ M | m ⊗ q = ⊥}
and comprises the preconditions: it contains the epistemic propositions to which q cannot be applied. The stabilizer
Stab(Q) := {m ∈ M | ∀q ∈ Q, [q]m = m}

13 The residual π \− assigns to its argument δ the weakest program π \ δ which one has to effectuate after effectuating π such that the net effect is below δ. The residual −/π assigns to its argument δ the strongest program δ/π which one has to effectuate before effectuating π such that the net effect is below δ. The right Galois adjoint does {m}− assigns to its argument δ the weakest proposition {m}P before effectuating π which guarantees P after. For a discussion on pre- and post-specification we refer to [8,16].


comprises the facts: it consists of those epistemic propositions which are stable under epistemic actions. The satisfaction relation is included in the partial ordering of M: for a state m ∈ M and fact ϕ ∈ Stab(Q) we have m |= ϕ ⇔ m ≤ ϕ. All modalities and other right Galois adjoints discussed and introduced in Proposition 3.6 arise also here as right Galois adjoints and hence their interpretation still holds e.g. “knowledge  M is the adjoint to appearance
f M ”.

Nature of the modalities.
We identify the basic properties of the modalities.
Proposition 4.3 In any epistemic system we have


 M	M

'	M	M
'	m ≤ m'

A T = T	  (m ∧ m )=   m ∧   m
  M m ≤  M m' .

A	A

Proof: Since  M
is a right Galois adjoint it preserves arbitrary meets, that

is  M (
A
i mi)= 
i  M mi, and hence it preserves the empty meet and binary

meets, and is monotone.	 

Since all other modalities preserve arbitrary meets the same result holds for them and for all other right Galois adjoints. In an intuitionistic context where one might take M to be a frame (i.e. a (complete) Heyting algebra with sup-homomorphisms) we can internalize the partial order using the defining property of a Heyting algebra so we obtain
▶ m → m'
▶  M m →  M m' .
A	A
Hence in the special case that Q = {1} and A = {∗} we obtain the intu- itionistic modal logic IntK of [27]. We conclude that intuitionistic epistemic systems, that is epistemic systems for which M is a frame, generalize intu- itionistic modal logic to multiple agents and dynamics in terms of epistemic programs. If M is moreover a complete boolean algebra such as the powerset of Section 2 then Kripke’s axiom K follows i.e.
  M (m → m') → (  M m →  M m').
A	A	A
Diamonds and corresponding rules arise in that case by duality.

Learning.
The fact that eq(1) in definition 4.1 is an inequality expresses learning of agents. Some of the clauses of the appearance of an agent on an update


product might get eliminated from the left hand side of eq(1) simply because some of the sub-action of the program might not be applicable on some of the sub-states of the proposition. This implies that the agent learns something new as the result of update (left hand side is stronger than the right hand side).
We can also force the equality by introducing the notion of coherence:
Definition 4.4 A pair (m, q) where m ∈ M and q ∈ Q is coherent iff
∀m' ≤ m, ∀q' ≤ q (m' ⊗ q' = ⊥ ⇒ m' = ⊥ or q' = ⊥)
For example in an atomistic system, every atomic pair (m, q) ∈ Atm(M ) ×
Atm(Q) where m ∈/ ker(q) is coherent.
Definition 4.5 A strong epistemic system is a tuple (M, Q, {fA}A∈A) where (M, Q) is a system and for all coherent pairs (m, q) we have the following equality
f M (m ⊗ q)= f M (m) ⊗ f Q(q) .


Representation Theorems.
Theorem 4.6 Every atomistic strong epistemic system for which both M and Q are completely distributive boolean algebras can be represented as a concrete epistemic system.
Proof: It suffices to set S := Atm(M ), Σ := Atm(Q) and Φ := Stab(Q). The accessibility relations arise from the appearance maps, satisfaction from ϕ ∈ µ(s) ⇔ s ≤ ϕ for s ∈ S and ϕ ∈ Φ and preconditions from µ(σ) := S \ Ker(σ) for σ ∈ Σ.	 
Theorem 4.7 Every concrete epistemic system (P(S), P(Σ)) is an atomistic strong (abstract) epistemic system (M, Q, {fA}A∈A) .
Proof: By propositions 3.2, 3.3, and 3.5.	 

Some dynamic epistemic situations
For a given epistemic system (M, Q, fA)A∈A the following are some examples of some special epistemic programs that can be defined in the system. Note that Ker(q) =↓ ( Ker(q)), where ↓ a := {b ∈ L | b ≤ a}, and hence “being not in the precondition of q” exists as a proposition in M for all q ∈ Q.

Public refutation of the proposition m ∈ M is an epistemic program
q ∈ Q with {fA(q)}A∈A = q and Ker(q) =↓ m. We depict it as

A∈A
Private refutation to subgroup This is also a program that privately refutes a proposition m to the subgroup β of agents. Ker(q) is the same as before and {fA(q)}A∈β = q and {fA(q)}A∈A\β = 1. It is depicted as
J,˜¸,r¸~q/~` ,,z,	zJ,˜¸1` ,z,
.,A∈/β .,
A∈β	A∈A
Failure test of a proposition m is a program q that tests when m fails. It is a particular case of private refutation where m is refuted to an empty set of agents Ker(q) =↓ m and {fA(q)}A∈A = 1. Pictorially
J,r˜,¸¸~q/~` ,,z, A∈A zJ,˜¸1` ,z,
A∈A
Public announcement is also definable in our setting. However, while “being not in the precondition of q” is a proposition in M for all q ∈ Q, this is not the case for “being in the precondition of q”. To see this consider the lattice {⊥ ≤ a, b, c ≤ T} with q such that Ker(q) = 
{⊥, a} where in the language of Section 2 we have µ(q) = {b, c}, which can not be represented by a single element of M. The reason for this is that this lattice is non-boolean. Hence public announcement of the proposition m ∈ M is an epistemic program q ∈ Q for which fA(q) = q a nd for which  Ker(q) has a boolean complement (  Ker(q))c, satisfying
We now present some case studies. Given an epistemic system (M, Q, fA)A∈A on which we impose particular conditions which encode the desired state and action models.

Cheating.
Consider the ’cheating’ scenario of the first section where the set of agents is A = {A, B, C}. Recall that there are two possibilities in the state model Toss, s in which the coin is Heads up and t in which it is Tails up. We model this abstractly by assuming as given an epistemic system (M, Q), with s, t ∈ M and σH ∈ Q. The facts are encoded as stabilizers, i, e. we are given


propositions H, T ∈ Stab(Q). All these are assumed to satisfy the following conditions: fi(s) = fi(t) = s ∨ t for all i ∈ A s ≤ H, t ≤ T, H ∧ T = ⊥; the epistemic program σH ∈ Q has maps fA(σH )= fB(σH)=1 and fC(σH)= σH , and kernel Ker(σH) =↓ t. This program describes an instance of cheating where the coin is heads up. s ⊗ σH ∈ M is the proposition s after it is updated by σH .
Let us reason about this scenario, using our algebraic setting, e. to prove that s ⊗ σH ≤ CH. Indeed by {fA}A∈A being system homomorphisms and eq(1) we have
fA(s ⊗ σH) ≤ fA(s) ⊗ fA(σH )= (s ∨ t) ⊗ 1= s ∨ t, 
and the same goes for fB. On the other hand
fC(s ⊗ σH ) ≤ fC(s) ⊗ fC(σH )= (s ∨ t) ⊗ σH = (s ⊗ σH ) ∨ (t ⊗ σH)= s ⊗ σH
since t ∈ Ker(σH). We have s ≤ H iff s ⊗ σH ≤ H ⊗ σH and by the definition of Stab(Q) we get s ⊗ σH ≤ H. Thus fC(s ⊗ σH ) ≤ H and by adjunction we get s ⊗ σH ≤ CH which means after updating his initial state by taking a peek, the referee knows that the coin is heads up.
If the referee is honest he uncovers the coin without taking a peek. He then publicly refutes the ‘coin being tails’. The epistemic program in this case is the public refutation of proposition t where fA(q) = fB(q) = fC(q) = q and Ker(q) = {t}. It follows that s ⊗ q ≤  AH, and the same goes for B and C. Hence all the agents know that the coin is Heads up after the public refutation.

The muddy children puzzle.
We refer the reader for a detailed description of the general case of the muddy children puzzle to [9]. This general version has been encoded and as usual solved by induction in our algebraic setting in [6]. In this paper we treat the case of three children A, B, C playing in the mud with A and B having muddy foreheads. Their father publicly announces that at least one of them has mud on his forehead and asks once if they know that they are dirty. After they all simultaneously reply “No!” once, the muddy children A and B will know that they are muddy. This simple case has only one round (since the number of dirty children is 2), but the general case with k dirty children shall have k − 1 rounds of ”No!” replies.
As before, we model this by postulating as given an epistemic system (M, Q). The set of agents A includes children {A, B, C}. The module M includes all possible initial states sβ with β ⊆ A being those children that


are dirty. Since the children cannot see their own foreheads (which might be dirty or not) we have f M (sβ) = sβ\{i} ∨ sβ∪{i} for each child i. Let D∅ be the fact that no child has a dirty forehead and Di be the fact that child i has a dirty forehead, hence {D∅} ∪ {Di ∈ M | i ∈ A} ⊆ Stab(Q), and also sβ ≤ Di for all i ∈ β. Let q be a round of no answers of the 3 children, i.e. q is the public refutation of  ADA ∨  BDB ∨  CDC and hence Ker(q) = 
 ADA ∨ BDB ∨ CDC and fi(q)= q for each child i. Let q0 ∈ Q be the be father’s announcement that at least one child has mud on his forehead hence Ker(q0) =↓ D∅ and fi(q0)= q0 for each child i. We have to show that after the first round of refutation q each muddy child (e.g. A) knows that he is dirty, i.e. s{A,B} ≤ [q0 • q] ADA and similarly for child B. By adjunction on dynamic and epistemic modalities and module equation (m ⊗ q1) ⊗ q2 = m ⊗ (q1 • q2) we get
fA((s{A,B} ⊗ q0) ⊗ q) ≤ DA .	(2)
By the fA inequality (i.e. eq(1)) it suffices to show
fA(s{A,B} ⊗ q0) ⊗ fA(q) ≤ DA
Again by eq(1) and the assumption fA(q0)= q0
fA(s{A,B} ⊗ q0) ≤ fA(s{A,B}) ⊗ q0
update both sides by fA(q)= q
fA(s{A,B} ⊗ q0) ⊗ q ≤ (fA(s{A,B}) ⊗ q0) ⊗ q
So to prove eq(2) it suffices to show
(fA(s{A,B}) ⊗ q0) ⊗ q ≤ DA
Replacing fA by its value will get us
((s{A,B} ∨ s{B}) ⊗ q0) ⊗ q ≤ DA
hence
((s{A,B} ⊗ q0) ⊗ q) ∨ ((s{B} ⊗ q0) ⊗ q) ≤ DA .
The first disjunct is given by the assumptions s{A,B} ≤ DA and DA being a fact and thus stable under updates, i.e. (DA ⊗ q0) ⊗ q ≤ DA. For the other disjunct we shall show that s{B} ⊗ q0 ≤ BDB ∈ Ker(q) which gives us (s{B} ⊗ q0) ⊗ q = ⊥ and ⊥ ≤ DA. To see this use the adjunction to get fB(s{B} ⊗ q0) ≤ DB, by eq(1) it suffices to show fB(s{B}) ⊗ fB(q0) ≤ DB. Now replace fB with its values and get (s{B} ∨ s{A,B}) ⊗ q0 ≤ DB which is equal to

(s{B} ⊗ q0) ∨ (s{A,B} ⊗ q0) ≤ DB. This inequality holds since by assumption
s{B} ≤ DB and also s{A,B} ≤ DB. Hence the result follows.
Note that this proof can be straightforwardlly extended to the general case by induction on the number of dirty children.

A cryptographic attack.
Two agents A and B share a secret key so that they can send each other encrypted messages over some communication channel. The channel is not secure: some outsider C may interpret the messages or prevent them from being delivered (although he cannot read them because he does not have the key). Suppose the encryption method is publicly known but the key is secret. It is also known that A is the only one who knows an important secret for example if some fact P holds or not. Suppose now that A sends an encrypted message to B communicating the secret. B gets the message and he is convinced that it must be authentic. Now both A and B are convinced that they share the secret and that C doesn’t. However suppose that C notices two features of the specific encryption method: first that the shape of the encrypted message can show whether it contains a secret or it is just junk, second that without knowing the key or the content of the message he can modify the encrypted message to its opposite i.e. if it originally said P hold, it will now say that P does not hold. Now the outsider C will secretly intercept the message, change it appropriately and send it to B without knowing the secret. Now A and B mistakenly believe that they share the secret, while in fact B got the wrong secret instead! C has succeeded to manipulate their beliefs.
We can encode this situation in an epistemic system. The agents involved include {A, B, C}. Let s, t ∈ M satisfy s ≤ P and t # P . The only agent that knows if P holds or not is A thus fA(s)= s and similarly fA(t) = t. On the other hand B and C do not know this so fB(s)= fC(s)= fB(t)= fC(t)= s∨t. Call the message in which P holds P and the one in which it does not hold
P¯. The epistemic actions that correspond to the cryptographic attack are the
following: α in which the message P is intercepted, modified and sent to B, β in which the message P¯ is intercepted, modified and sent to B, α' in which A sends the message P to B, β' in which A sends the message P¯ to B, and finally γ which corresponds to sending a junk message. Thus
{α, β, α', β', γ} ⊆ Q and P, P¯ ∈ Stab(Q) and P ∧ P¯ = ⊥, P ∨ P¯ = T .
In actions α and β agent C is uncertain about which message P or P¯ has been sent so fC(α) = fC(β) = α ∨ β. On the other hand, agent A is sure that he has sent a message (either that P holds or that it doesn’t) to B and that B


has received exactly the same secret i.e. fA(α)= α' and fA(β)= β'. However if P has been sent, B has received P¯ so fB(α)= β' and the other way around fB(β)= α'. Furthermore
fA(α')= fB(α')= α' , fA(β')= fB(β')= β' , fC(α')= fC(β')= α' ∨ β' ∨ γ. 

C also considers possible that only a junk message has been sent and that is why he sees γ while in α' and β'. If a junk message has been sent, A and B are sure about it fA(γ)= fB(γ)= γ while C is unsure if it was a junk message or P or P¯, thus fC(γ)= α' ∨ β' ∨ γ. The kernel of each action is the states to
which the actions cannot be applied. Thus we encode
Ker(α)= Ker(α')= ↓ P¯ and Ker(β)= Ker(β')= ↓ P . 

The epistemic program α ∨ β expresses the action of communicating the secret P or P¯ in the above scenario. Now let us update the state s with the epistemic program α ∨ β and show that after update, if P holds, then A knows that B knows that P holds


Since this is equal to
s ⊗ (α ∨ β) ≤  A BP . 


(s ⊗ α) ∨ (s ⊗ β) ≤  A BP , 

and s ≤ P ∈ Ker(β), we get s ⊗ β = ⊥, so it suffices to show that
s ⊗ α ≤  A BP , 
but by adjunction fB(fA(s ⊗ α)) ≤ P . By eq(1) we get fA(s ⊗ α) ≤ fA(s) ⊗
fA(α), order preservation of fB will give us
fB(fA(s ⊗ α)) ≤ fB(fA(s) ⊗ fA(α)) ≤ fB(fA(s)) ⊗ fB(fA(α)).
Now it suffices to show
fB(fA(s)) ⊗ fB(fA(α)) ≤ P.

Replace the fA with its values and show fB(s) ⊗ fB(α') ≤ P , do the same for fB and get (s ∨ t) ⊗ α' ≤ P , hence (s ⊗ α') ∨ (t ⊗ α') ≤ P which is equal to (s ⊗ α') ≤ P since t ≤ P¯ ∈ Ker(α'). By the assumption s ≤ P we obtain s ⊗ α' ≤ P ⊗ α' which leads to s ⊗ α' ≤ P because P is a fact.


A non-boolean example.
An intuitive example of an epistemic system (M, Q, fA)A∈A where refuta- tions are first class citizens rather than announcements is the refutation of theories in scientific practice. Hence the underlying lattice M is naturally non-boolean. Let the elements of the module M be theories written in some logical language e.g. DEL; a theory being a consistent set of sentences closed under logical deduction. For obvious reasons negating a theory th ∈ M is in general itself not a theory — algebraically a theory should be conceived as a filter. The join in M is the intersection of the sentences belonging to the corresponding theories while the meet is the closure of their union. The quantale Q consists of experiments performed by (groups of) agents in order to check some testable consequences of theories. This experiment might be public or private, and some of the outsiders might be deluded into rejecting, misunderstanding or misinterpreting the outcome. 14 The appearance f M (m) of a theory to an agent can be thought of as the agent’s interpretation of the theory m, and similarly the appearance f Q(q) is the agent’s interpretation of the outcome of an experiment q. Following Popper’s conception, a positive result of an experiment cannot provide a proof of a theory but a negative one provides a falsification of the theory, hence we can refute it. For each such refutation r ∈ Q we have a kernel Ker(r) ∈ M which tells us which theories can be refuted, namely those which satisfy th ⊗ r = ⊥.

The sequent calculus of epistemic systems
We define the objects of our sequent calculus by mutual induction on two sets, the set of formulas denoted as m ∈ LM and the set of epistemic programs denoted as q ∈ LQ, respectively
m ::= ⊥ | T | p | s | m ∧ m | m ∨ m |  Am | fA(m) | [q]m | m ⊗ q q ::= ⊥ | 1 | σ | q • q | q ∨ q | fA(q)
where A is in the set A of agents, p is in the set Φ of facts, s is in a set VM of atomic propositional variables, and σ is in a set VQ of atomic action variables. We denote by LM the set of all m-formulas, LQ the set of all q-formulas, and A the set of agents. We have two kinds of sequents, M-sequents Γ ▶M δ where Γ ∈ (LM ∪ LQ ∪ A)∗ and δ ∈ LM , and Q-sequents Γ ▶Q δ where Γ ∈ (LQ ∪ A)∗ and δ ∈ LQ. To describe what these sequents mean, we extend the notation to two operations
−⊙ − : LM × (LM ∪ LQ ∪ A) → LM  and  −⊙ − : LQ × (LQ ∪ A) → LQ

14 E.g. arguments for Darwinism such as the discovery of fossils are interpreted by creation- ists as “the fossils have been put in place by God”.


by putting q ⊙ q' := q • q', m ⊙ A := fA(m), q ⊙ A := fA(q), m ⊙ q := m ⊗ q, and m ⊙ m' := m ∧ m'. For a sequent
Γ= (γ1, ··· , γn) ∈ (LM ∪ LQ ∪ A)∗ ∪ (LQ ∪ A)∗
we put  Γ := (((( ⊙ γ1) ⊙ γ2) ⊙ γ3) ··· ) ⊙ γn, where  is the top element of M for M-sequents, and the unit element of Q for Q-sequents. 15 Obviously we have
Γ ∈ (LM ∪ LQ ∪ A)∗ ⇒	Γ ∈ LM	and	Γ ∈ (LQ ∪ A)∗ ⇒	Γ ∈ LQ .
Define a satisfaction relation |= on LM as m |= m' ⇔ m ≤ m' and similarly on LQ as q |= q' ⇔ q ≤ q'. Now a sequent Γ ▶ δ (for either ▶M or ▶Q) is said to be valid iff Γ |= δ. We also allow sequents with empty consequents, denoted as Γ ▶ . We interpret such a sequent as being equivalent to Γ ▶ ⊥, or in other words  Γ= ⊥.

The meaning of a sequent.
The meaning of a sequent Γ ▶ δ is given by its corresponding satisfaction statement  Γ |= δ. To provide the reader with a way to “read out” our se- quents in natural language, we capture the intuitive meaning of an M-sequent (Q-sequents can be read in a similar way) Γ ▶M δ in the following inductive manner:
A, Γ ▶M δ means that agent A knows, or believes, that Γ ▶M δ holds. So this captures features of A’s own reasoning: the sequent Γ ▶M δ is accepted by A as a valid argument.
q, Γ ▶M δ means that, after action q happens, the sequent Γ ▶M δ will hold.
m, Γ ▶M δ means that, in context m (i.e. in any situation in which m is true), the sequent Γ ▶M δ must hold.
For instance, the sequent m, A, q, B, m' ▶M m'' can be read as: in context m, agent A believes that after action q agent B will believe that, in context m', proposition m'' must hold .
This reading shows that our sequent calculus expresses two forms of re- source sensitivity. One is the use-once form of linear logic [14] that comes from the quantale structure on epistemic programs. This, as will be seen later, is encoded in the Lambek calculus rules on Q-sequents. One could call these dynamic resources . The other form deals with epistemic resources : the re- sources available to each agent that enable him to reason in a certain way (i.e.

15 Note that the top element of M is the unit for  on M (i.e. ∧) and that the unit element


to deduct a result from some assumptions). These resources are encoded in the way the context appears to the agent in sequents, for instance Γ in the sequent Γ, A, Γ' ▶M δ is the context and hence the fA(Γ) is the resource that enables agent A to do the Γ' ▶M δ reasoning. Note that Γ' ▶M δ might not be a valid sequent in the context Γ, but it is valid in the context given by Γ’s appearance to agent A. To summerize, in our setting not only propositions, but also actions and agents are treated as resources (available or not for other actions or for reasoning of other agents).

Sequent rules.
The rules for identity, ⊥, and 1 (on the left) are the same for both M and
Q sequents. So in the following we drop the subscripts of ▶ where applicable:

The operational rules for M-sequents are


where ΓM ∈ L∗ , ΓQ ∈ L∗ , ΓA ∈ A∗, δ, δ' ∈ LM and if ΓM = (m1, ··· , mn)
M	Q
then ΓM ⊗ q := (m1 ⊗ q, ··· , mn ⊗ q).
The operational rules for Q-sequents consist of Lambek calculus rules for V, plus the following rules for • and fA

where δ, δ' ∈ LQ and for ΓQ = (q1, q2, ··· ) , fA(ΓQ)= fA(q1) • fA(q2) • ··· .
As structural rules we have two M-Weakenings, Q-Weakening, M-Contraction, and M-Exchange, respectively

two rules expressing Invariance of facts (under epistemic actions) (rules which can be seen as “Action Weakening’ and “Action Strengthening” in M-sequents)

where P ∈ Φ (the set of facts), and finally several restricted versions of the Cut Rule: propositional cut in M-sequents, action cut in Q sequents and action cut in mixed M — Q sequents 16

Theorem 6.1 (Completeness). The rules presented above are sound and complete with regard to the algebraic semantics given by epistemic systems.

16 We think these cuts are eliminable and are working on the Cut-Elimination theorem.

Proof (Sketch). Denote the equivalence relation created by logical conse- quence ▶E as ∼=.	We construct two Lindenbaum-Tarski algebras: M0 of
equivalence classes of M-formulas over ∼=M and Q0 of equivalence classes of
Q-formulas over =∼ . Using the sequent rules we first show that all the alge-
braic operations of epistemic systems V, fA, A, ⊗, [ ], • are well-defined over equivalence classes of formulas. We then show that (M0, Q0, {fA}A∈A) satisfies the finite versions of all the equations of an epistemic system. We embed this structure into an epistemic system (M, Q, {fA}A∈A) by taking M = Idl(M0) and Q = Idl(Q0) where e.g. Idl(M0) is the family of ideals over M0 with inclu- sion as order and intersection as meet. The rest of operations V, fA, ⊗, • are extended to ideals by applying them pointwise and then taking the downward closure. Finally we show that (M, Q, {fA}A∈A) forms an epistemic system and that (M0, Q0, {fA}A∈A) is faithfully embedded in it.	 

Conclusion and elaborations
We have developed an algebraic axiomatics in terms of a simple mathematical object: a sup-lattice M, which encodes states, epistemic propositions as well as facts; a quantale Q (acting on M) which encodes update by epistemic programs; and a family of endomorphisms of the (M, Q, M , Q, ⊗, •, 1)- structure encoding the agents in terms of their epistemic modalities. From this structure many useful other modalities arise, including dynamic modali- ties and residuals. This algebraic axiomatics generalizes Dynamic Epistemic Logic to non-boolean settings, while still capturing the same concepts. Fur- thermore it provides an algebraic way of dealing with epistemic scenarios such as the muddy children puzzle. We list some possible further elaborations on this line of thought.
We would like to develop a boolean version of the sequent calculus presented here for concrete epistemic systems and prove its completeness with regard to Kripke semantics. Such a development will lead to a more refined version of our representation Theorem 4.6 for a boolean dynamic epistemic logic.
In this paper, following dynamic epistemic logic, we dealt with the same update schema for all agents. This is a postulate of “uniform rationality” and it means that the mechanism for information update is the same for all agents. It makes sense, if not being necessary, to consider personalized updates, where each agent updates his information in a different way than other agents do. We think that such personalized updates could be better dealt with by moving to a categorical semantics. We are currently working on such semantics. It would also be interesting to compare our categorical approach with coalgebraic epistemic features which are currently studied

e.g. [3].
Part of the motivation of this work was a marriage of epistemics and resource- sensitivity [20]. Although we have introduced dynamic and epistemic re- sources in our setting, we would like to refine our logic and make it more resource-sensitive by relativizing our notion of “consequence” to “logical” actions available to agents. This will allow us to deal with classical resource sensitive problems such as the problem of logical omniscience.

References
S. Abramsky and S. Vickers, ‘Quantales, observational logic and process semantics’,
Mathematical Structures in Computer Science 3, 161-227, 1993.
A. Baltag, ‘Logics for communication: reasoning about information flow in dialogue games’, Second North American Summer School in Logic, Language, and Information, http:// www.indiana.edu/˜nasslli/program.html, Indiana University, 2003.
A. Baltag, ‘A coalgebraic semantics for epistemic programs’, Proceedings of Coalgebraic Methods in Computer Science 03, 2003.
A. Baltag, and L.S. Moss, ‘Logics for epistemic programs’, Synthese 139, 2004.
A. Baltag, L.S. Moss and S. Solecki, ‘The logic of public announcements, common knowledge and private suspicions’, CWI Technical Report SEN-R9922, 1999.
A. Baltag, B. Coecke, M. Sadrzadeh, ‘Epistemic actions as resources’ in Proceedings of Logics for	Resources,	Programs,	Processes (LRPP) workshop in LiCS 2004,http://www.er.uqam.ca/nobel/philmath/LicsWSPROC.pdf.

B. Coecke, D.J. Moore and I. Stubbe, ‘Quantaloids describing causation and propagation of physical properties’, Foundations of Physics Letters 14, 133-145, 2001.
E.W. Dijkstra, A Discipline of Programming, Prentice-Hall, 1976.
R. Fagin, J.Y. Halpern, Y. Moses and M.Y. Vardi, Reasoning about Knowledge, MIT Press, 1995.
G. Gierz, K.H. Hofmann, K. Keimel, J.D. Lawson, M.W. Mislove and D.S. Scott, A Compendium of Continuous Lattices, Springer-Verlag, 1980.
J. Gerbrandy, ‘Dynamic Epistemic Logic’, in L.S. Moss, et al (eds.) Logic, Language, and Information 2, Stanford University, CSLI Publication, 1999.
J. Gerbrandy, Bisimulation on Planet Kripke, Ph.D. dissertation, University of Amesterdam, 1999.
J. Gerbrandy, and W. Groenveld, ‘Reasoning about information change’, Journal of Logic, Language, and Information 6, 1997.
J-Y. Girard, ’Linear logic’, Theoretical Computer Science 50,1-102, 1987.
D. Harel, D. Kozen and J. Tiuryn, Dynamic Logic, MIT Press, 2000.
C.A.R. Hoare and Jifeng, HE, ‘The weakest prespecification’, Information Processing Letters
24, 127-132, 1987.
P.T. Johnstone, Stone Spaces, Cambridge University Press, 1982.
A. Joyal and M. Tierney, ‘An extension of the Galois theory of Grothendieck’, Memoirs of the American Mathematical Society 309, 1984.
J. Lambek, ‘The mathematics of sentence structure’, American Mathematics Monthly 65, 154- 169, 1958.
M. Marion and M. Sadrzadeh, ‘Reasoning about knowledge in linear logic: modalities and complexity’, D. Gabbay, S. Rahman, J.M. Torres and J.-P. Van Bendegem (eds.), Logic, Epistemology, and the Unity of Science, Kluwer, 2004.


C.J. Mulvey, &, Supplemento ai Rendiconti del Circolo Matematico di Palermo II, 99-104, 1986.
J. Plaza, ‘Logics of public communications’, Proceedings of 4th International Symposium on Methodologies for Intelligent Systems, 1989.
P. Resende, ‘Quantales and observational semantics’, B. Coecke, D.J. Moore and A. Wilce (eds.), Current Research in Operational Quantum Logic, Kluwer, 263-288, 2000.
K.I. Rosenthal, Quantales and their Applications, Pitman Research Notes in Mathematics Series 234, Longman, 1990.
I. Stubbe, Categorical Structures Enriched in a Quantaloid: Categories and Semicategories, Ph.D. Thesis, Universit´e Catholique de Louvain, 2003.
J. Van Benthem, ‘Logic in action’, Journal of Philosophical Logic 20, 225-263, 1989.
F. Wolter and M. Zakharyaschev, ‘The relation between intuitionistic and classical modal logics, Algebra and logic 36, 73-92, 1997.
