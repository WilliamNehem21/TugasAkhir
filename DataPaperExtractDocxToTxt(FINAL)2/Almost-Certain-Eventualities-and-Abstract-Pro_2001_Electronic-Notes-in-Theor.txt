Electronic Notes in Theoretical Computer Science 42 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume42.html 29 pages


Almost-Certain Eventualities and Abstract Probabilities in Quantitative Temporal Logic

Annabelle McIver 1
Programming Research Group University of Oxford Oxford OX1 3QD UK
anabel@comlab.ox.ac.uk 2
Carroll Morgan
Dept. of Engineering and Computer Science University of New South Wales
Sydney 2052 Australia
carrollm@cse.unsw.edu.au


Abstract
‘Almost-certain eventualities’ are liveness properties that hold with probability 1. ‘Abstract probabilities’ are probabilities in transition systems about which we know only that they are neither 0 nor 1.
Vardi [17] showed that almost-certain properties in linear temporal logic depend only on abstract probabilities, rather than on the probabilities’ precise values; we discuss the extent to which a similar result holds in quantitative temporal logic [9,10], and we show how to specialise the logic to those cases. The aim is to provide a simpler calculus than the full logic, one that is in a certain sense complete for proving almost-certain eventualities from abstract-probabilistic assumptions.
We consider briefly the complexity of the specialised logic.


Introduction
Liveness properties of ‘standard’, that is non-probabilistic transition systems rely only on the connectivity of the system (considered as a graph). The same is true in probabilistic systems, up to a point: ‘almost-certain eventualities’ depend only on ‘abstract probabilities’, not on precise probabilistic values.

1 McIver was supported by the UK’s EPSRC during this research.
2 From Feb. 2001: Dept. of Computing, Macquarie University, Sydney 2019 Australia.
◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


A typical eventuality is loop termination, for example, expressed in tempo- ral logic by the formula ✸[чG] where G is the loop guard; it is almost certain iff it occurs with probability 1. Over the state space {H, T} the ‘coin-flipping’ system
s:= H p⊕ s:= T ,
in which p⊕ represents probabilistic choice, satisfies both ✸[s=H] and ✸[s=T ] almost certainly: no matter where the system is started, the state s will evenually be H, and will eventually be T , provided 0 < p < 1.
An abstract probability is one which — like p above — is known only to be neither 0 nor 1: beyond that, its precise value is immaterial for the conclusions that are to be drawn.
In this paper we concentrate on our quantitative extension qMµ [9,10] of the modal µ-calculus [6]; the extension in many cases acts as a probabilistic µ-calculus or even as a probabilistic temporal logic. (It can go beyond those, however, dealing directly with more general aspects like expected complexity [7].)
Our principal contribution here is that the quantitative calculus can be specialised to a form of almost-certain eventualities and abstract probabili- ties, and that results are obtained that are similar to the ‘traditional’ proba- bilistic calculi: one does not need precise numeric values for the probabilistic transitions in the underlying system if one is interested only in almost-certain conclusions.
Our second contribution is to give a complexity bound for evaluation of almost certainties.
In the remainder of this section we describe the transition systems with which we will be concerned. Sections 2 and 3 review the existing calculi, in both their Boolean (traditional) and quantitative (our numeric extension) form; in Sections 4 and 5 we present our principal results. Complexity is considered in Section 7.
Standard transition systems and the µ-calculus
We say that a system is standard if it is not probabilistic or, if it is proba- bilistic, when its probabilities are all either 0 or 1. Standard transition sys- tems over a state space S support a modal µ-calculus [6] for reasoning about their behaviour; expressions in the calculus denote Boolean-valued predicates (equivalently subsets of S), which are sets of states that can be shown with the calculus to lead to certain behaviours of the transition system.
The transition system can be given as elements of a state-to-state relation 7 : if (s, s') ∈ 7 then moving from state s to state s' is a possible transition; and if both (s, s') and (s, s'') are in 7 , for s' /= s'', then in a move from s the choice between s' and s'' can be resolved either ‘demonically’ or ‘angelically’ depending on one’s application.
The µ-calculus can be specialised to a form of temporal logic by defining


// State space is Bool × N.
var b: Bool; n: N;

// Transition is ‘enabled’ only when b holds;
// otherwise it acts as skip.
b	→	b:= False 1/n2 ⊕ n:= n +1 

Fig. 1. A probabilistic transition system. 3
temporal operators, like eventually ✸ above, within the calculus and then using only those, in effect a subset of the full language.
Probabilistic transition systems and qMµ
Probabilistic transition systems support a ‘quantitative’ modal µ-calculus — which we call qMµ — whose expressions are real- rather than Boolean-valued over S; the expressions denote ‘expected values’ of random variables over prob- abilistic distributions on the state space. The transitions exhibit probabilistic nondeterminism as well as potentially the other two kinds.
As in the standard µ-calculus, temporal operators can be defined within
qMµ: the result is a quantitative temporal logic which we call qTL [9,10].
The standard µ-calculus embeds into qMµ by taking predicates, or their equivalent subsets, to the corresponding characteristic functions; as a conse- quence, standard temporal logic embeds similarly into qTL.
For example, consider the probabilistic system of Fig. 1. If b holds and n > 0, then b is eventually False only with probability 1/n — that is, the eventuality ✸[чb] depends on n’s initial value — and in qTL (details below) we would simply say that ✸[чb]= 1/n in all states that satisfy b ∧ n>0. Clearly the 1/n result depends on the precise value 1/n2 given in the transition: that is, the proof of ✸[чb]= 1/n in the calculus would involve quantitative reasoning based on that specific probability. (We give a proof in Sec. 3.2.)
On the other hand, in the probabilistic system

(1)
b	→	b:= False p⊕ n:= n +1 

чb is reached with probability 1, provided p is bounded away from zero. 4

3 We use a UNITY-like [2] pseudo-code to describe the transitions.
4 By “bounded away from zero” we mean that if we allow p to be some function p.(b, n) of
the state, then we require the existence of a fixed ε > 0 such that p.(b, n) ≥ ε for all b, n. When S is finite, however, it is sufficient to say “p is non-zero”; and if p is some constant (e.g., is 1/2), then “p is non-zero” is sufficient whether S is finite or not.
Note that in Fig. 1 the probability 1/n2 is everywhere non-zero, but it is not bounded away


We say in that case that eventually чb occurs almost certainly over abstract probability p and, given that p’s precise value is irrelevant for that conclusion, we could write the system (as Rao does for example [15])


(2)
b	→	b:= False | n:= n +1 ,

with the additional implication however that the probability is abstract for both alternatives — that is, the implicit p indicated by | is bounded away from both zero and one.
In the sequel we show that in qTL, at least for finite state spaces, the truth of almost-certain eventualities depends only on abstract probabilities, never on their precise values; and we show how to specialise the calculus so that it can act directly over transition systems described as at (2).

Summary of the µ-calculi
In this section we give a brief description of both the standard [6] and quan- titative [9,10] µ-calculi.

The standard calculus
Consider a transition system 7 : S ↔ S over a state space S. The stan- dard modal µ-calculus comprises (expressions denoting) predicates of the form shown in Fig. 2, allowing propositional operators, least- and greatest fixed- points, and an implicit ‘next-time’ reference ◦ to the effect of taking one step in 7 , with demonic resolution of any branching.
As an example, consider the transition system of Fig. 3. We have
a ∈ ◦{c, d, e}	one step from a is guaranteed to reach {c, d, e}.
a /∈ ◦{c, d}	one step from a might go to e.
a /∈ ◦{a}	one step from a cannot reach a at all.
b ∈ ◦{b}	no explicit step is interpreted as skip. As an illustration of conjunctivity (3) we have for example

≡	◦{b, c, d, e}.a ∧ ◦{c, d, e, f}.a .	by inspection of 7


from zero.

A standard µ-calculus expression E is of the form
P	predicate over S, typed S → Bool or equivalently PS
E op E	for propositional operators op
E	‘next-time’ E
µE	least fixed-point of predicate-to-predicate function E
νE	greatest fixed-point of predicate-to-predicate function E
Notes:
For state s in S and predicate E we write E.s for the value of E at s, and we say that s satisﬁes E , or E holds at s, whenever that value is True. When E is given explicitly as a subset S' of S, we can write s ∈ S' for S'.s.
In this paper we interpret the ◦ operator demonically with respect to the underlying transition system 7 , so that s satisfies ◦E precisely when for all s' we have (s, s') ∈7 ⇒ E.s'.
Predicate-to-predicate functions E are sometimes called predicate transform- ers. We apply µ and ν only to E that are ⇒-monotonic. Note that operator
is monotonic by construction.
The next-time operator ◦ is interpreted demonically, and is assumed (be- yond monotonicity) to satisfy the conjunctivity property

(3)
for all predicates P, Q.
◦(P ∧ Q)	≡	◦P ∧ ◦Q , 

Fig. 2. The standard modal µ-calculus
The transition system 7 is
s = a	→	s:= c ✷ s:= d ✷ s:= e . 
The state space S is {a, b, c, d, e, f}, and ✷ represents choice (interpreted de- monically by ◦). For convenience we write the system using a programming- language like syntax, in which for example s = a denotes the predicate {a} and s:= c denotes the single transition S × {c}.
The overall system is thus the relation 7 := {a}× {c, d, e}.
Fig. 3. Standard transition system
The quantitative calculus qMµ
Consider a probabilistic transition system over a state space S, this time of the form S → PS in which initial states are taken to sets (P) of distributions (·) over S. 5 (Discrete) distributions S over S are maps from S into the unit

5 Note for comparison with the standard case that S ↔ S is just S → PS, so that we have merely changed the final ‘set of points’ S to the set of discrete distributions S (into which S can be embedded).

A quantitative µ-calculus expression S is of the form
A	expectation over S, typed S → R≥
S op S	for R≥-closed operators op (extended pointwise)
S	‘next-time’ S
µE	least fixed-point of expectation transformer E
νE	greatest fixed-point of expectation transformer E
Notes:
For state s in S we write S.s for the value of S at s. For predicate P we write [P ] for its characteristic function, which embeds it into the quantitative model: thus [P ].s =1 iff s ∈ P .
The ◦ operator is interpreted over 7 , and we assume here that it is demonic and probabilistic so that expression ◦S is the least (over the demonic non- determinism) expected value (over the probabilistic nondeterminism) of S after the computational step. That is ◦S.s is the minimum over all distribu- tions D with (s, D) ∈7 of the expected value ExpDS of S over distribution D.
Note that the special case ◦[P ].s gives the (demonically least) probability that one step from s will reach a state satisfying P , since the probability assigned an event P by a (state) distribution is equal to the expected value of its characteristic function [P ] over that same distibution: thus ExpD[P ]= ProbDP .
We write $ for “is everywhere no more than”, and @, ≡ similarly.
Operator ◦ is assumed to satisfy the new property of sublinearity [12], that is
(4)	◦(aA + bB gc)	@	a(◦A)+ b(◦B) gc
where a, b, c ≥ 0 are scalars, juxtaposition is multiplication and A, B are expectations; truncated subtraction g is defined
x gy	:=	(x — y) H 0 with lower syntactic precedence than +.
Note that we write c both for the scalar and for the constant ‘everywhere-c’ function.
Fig. 4. The standard modal µ-calculus

interval [0, 1] of probabilities, and sum to 1 over the space.
The quantitative modal µ-calculus comprises R≥-valued functions of the form shown in Fig. 4, called expectations, and by analogy with the standard case we allow arithmetic operators, least- and greatest fixed-points, and an implicit reference ◦ to (the now demonic/probabilistic) 7 .

s = a	→	s:= c 2/3⊕ (s:= d✷s:= e)
The state space S is again {a, b, c, d, e, f}, and p⊕ represents probabilistic choice taking the left (resp. right) operand with probability p (resp. 1—p).
The transition system here is
{(a, ⟨0, 0, 2/3, 1/3, 0, 0⟩), (a, ⟨0, 0, 2/3, 0, 1/3, 0⟩)} ,
where ⟨· · ·⟩ lists the component probabilities of a discrete distribution over the space a ··· f .
Fig. 5. Probabilistic and demonic transition system
As an example, consider the transition system of Fig. 5. We have
{c, d, e}.a = 1	one step from a is guaranteed to reach {c, d, e}.
{c, d}.a = 2/3	when the probabilistic choice resolves to the right, the demonic choice will avoid d.
{a}.a = 0	one step from a cannot reach a at all.
{b}.b = 1	no explicit step is interpreted as skip.
(To avoid the clutter of [{c, d, e}] for example, we have omitted the embedding brackets [·] (see notes of Fig. 4) when they occur around set comprehensions.) For an illustration of sublinearity (Property 4, Fig. 4), consider the special case in which its scalars a, b, c are all 1.	We define x & y := x + y g 1, and note that sublinearity then gives us &-subdistribution through ◦: for all
expectations A, B we have
(5)	◦(A & B)	@	◦A & ◦B . 
Operator & is useful because it both generalises Boolean conjunction 6 and specialises sublinearity: it is our ‘best quantitative approximation’ to conjunc- tivity (3).
In the system of Fig. 4, because we have for example that {c} ≡ {c, d} &
{c, e}, we can check (5) by verifying that
{c}.a

Note that we have only an inequality, 7 whereas in the standard case (con- junctivity) we have equality.

6 That is, we have [P ] ∧[Q] ≡ [P ]& [Q] for all predicates P, Q.
7 The inequality is because ◦{c, d}.a ≡ ◦{c, e}.a ≡ 2/3 is true of other transition systems


Consequences of sublinearity include (by simple arithmetic [12, Sec. 7 pp. 340ff]) the following properties for all expectations A, B:
monotonicity If A $ B then ◦A $ ◦B.
feasibility ◦A $ HA.
scaling For c ≥ 0 we have ◦(cA) ≡ c(◦A).
bounded up-continuity Provided S is finite, the set of expectations A is up-directed and HA is bounded above, we have
◦(HA)	≡	(HA: A · ◦A) .
down-continuity Provided S is finite and the set of expectations A is down-directed, we have
◦(HA)	≡	(HA: A · ◦A) .

Specialisations to the temporal calculi
The modal calculi act as temporal calculi if one identifies specific types of expression for concepts like (among others) ‘eventually’, ‘always’ and ‘unless’ [4]. When based on the standard calculus, they give absolute (i.e., true or false) judgements; in the quantitative case, the judgements are probabilistic.
Standard temporal logic
We define some typical temporal operators in Fig. 6. The role of conjunctiv- ity (3) here is that it allows high-level proofs of temporal properties without referring directly to the underlying transition system. For example, one such property is the eventually-until lemma 8
P ✄ (P Λ Q) Λ ✸Q	$	✸(P Λ Q) ,
which states that if P holds up to and including a possible step at which Q holds, and Q eventually does hold, then in fact P Λ Q eventually holds. 9 We give the straightforward proof of that (Lem. A.1) as an example of the use of conjunctivity.
Quantitative temporal logic qTL
From here on we restrict our expectations to the range [0, 1] rather than R≥, using only operators for which [0, 1] is closed. (Note that feasibility above gives the closure of ◦ itself.)

over S as well; one of those is for example
s = a	→	s:= c 1/3⊕ (s:= d 1/2⊕ s:= e) ,
for which ◦{c}.a is in fact as low as 1/3. It can be shown that sublinearity gives the highest estimate possible under those general circumstances: it is only as “pessimistic” as necessary.
8 Compare the PSP lemma of UNITY [2].
9 Here for uniformity we use $ for ‘entails’, which is consistent with its quantitative defi-
nition since P ▶ Q iff [P ] $ [Q].


“eventually P ”
✸P	:=	(µX · P V ◦X)	If sufficiently many steps
are taken, then P will hold.

“always P ”
✷P	:=	(νX · P Λ ◦X)	No	matter	how	many
steps are taken P will continue to hold.

“P unless Q”
P ✄ Q  :=  (νX · Q V(P Λ ◦X))  No  matter  how  many
steps are taken, P will continue to hold, unless a state is reached in which Q holds.
We write “: =” for “is defined to be”.
Fig. 6. Definition of some standard temporal operators in the modal µ-calculus



“eventually A”	✸A	:=	(µX · A H ◦X) “always A”	 ✷A	:=	(νX · A H ◦X)
“A unless B”	A ✄ B	:=	(νX · B H (A H ◦X))
In qTL we restrict expectations to the range [0, 1] instead of R≥.
Fig. 7. Definition of the quantitative temporal operators for qTL in the quantitative modal µ-calculus


In the quantitative case, we define the temporal operators as in Fig. 7.
Consider “✸A” however: for general expectation A it is not helpful to interpret it as “the probability that eventually A is established”, because the meaning of “establish A” is itself unclear if A is a number. So what does ✸A mean? (Similar remarks apply of course to the other temporal operators.)
It can be shown that the special case ✸[P ] is indeed the probability of

eventually establishing P . 10 More generally [9] the expression ✸A is
the supremum, over all strategies that determine in each state whether to take another transition or to stop, of the expected value of A when the strategy says “stop”; the strategy “never stop” gives 0 by definition.
The situation with the other operators is similar. 11
Again (the generalisation of) conjunctivity plays an important role in high- level reasoning. Using &-subdistribution, for example, we can prove a gener- alisation of (6); it is the quantitative eventually-until lemma
A ✄ (A & B) & ✸B	$	✸(A & B) ,
which we prove as Lem. A.2.
As an example of probabilistic eventualities, we return to the system Fig. 1. We write out expectations as expressions over the program variables b, n, and calculate ✸[чb] directly (and unimaginatively) from the least-fixed-point limit implied by its definition (Fig. 7).
term 0:  0	⊥≡ 0

term 1:	[чb]	H	◦0	definition ✸: term k+1 = [чb] H ◦(term k)
≡	[чb]	◦0 ≡ 0 by feasibility

term 2:  [чb]  H  ◦[чb]
≡	[чb] H ([чb]	H	[b]/n2)	inspection of 7
≡	[чb]	H	[b]/n2

term 3:	[чb]	H	◦([чb] H [b]/n2)
≡	[чb]	H	[b](1/n2 + (1 — 1/n2)(1/(n + 1)2))
≡	[чb]	H	2[b]/n(n + 1)

term 4:	[чb]	H	◦([чb] H 2[b]/n(n + 1))
≡	[чb]	H	3[b]/n(n + 2)

.

10 As is usual, we mean by that probability the measure, in the Borel algebra of ‘cones’ within the tree of possible executions, of the set of paths along which P eventually occurs.
11 Again we have agreement with the standard case, since if P is guaranteed to hold even-
tually then the strategy “stop when P holds” will establish True; if P is not guaranteed to hold eventually then, given any strategy, demonic choice could force either a “stop” in a state where P is false or an infinite run, also giving False (by definition).


term k:	[чb]	H	(k — 1)[b]/n(n + k — 2) ,	induction
so that we have
✸[чb]
≡	terms ascending, so Hk agrees with limk→∞
limk→∞	[чb] H (k — 1)[b]/n(n + k — 2)
≡	[чb] H [b]/n	limk→∞ (k — 1)/(n + k — 2) = 1
≡	1/n if b else 1 .	arithmetic
That is, termination is certain if чb holds (at the start), and occurs with probability 1/n if it does not.

Abstract reasoning in qTL
We have now completed our review of the existing calculi, and turn to our present contribution.
At the end of Sec. 3, we gave a calculation of ◦[чb] for the system of Fig. 1.
In System (1) following it, a similar calculation would be 12



12 This heavy-handed ‘limit’ approach is not the only way to calculate ✸[чb] here: an alternative is to show from the definitions that
✸[чb]	≡	p + (1—p)✸[чb]
holds for this system, whence rearrangement and dividing by p gives us ✸[чb] ≡ 1. But the point about explicit treatment of p remains.



.
term ∞: [чb]	H	p Σ∞


(1—p)k [b] ,	induction

whence we conclude that ✸[чb] ≡ [чb] H p[b]/p ≡ 1 provided p is not 0.
Our aim is simply to show that in abstract systems like (1) it is possible to avoid explicit numeric calculations like the above.
The main technical result will be that the floor [·♩ and ceiling [·| operators can abstract from the ‘intermediate’ values lying strictly between 0 and 1: in finite state spaces we prove
[ ✸[P ] ♩	≡	[ [✸[P ]| ✄ [P ] ♩ ,
whose left-hand side is 1 if ✸[P ] is almost certain, and 0 otherwise; and the constructions [· ✄ ·♩ and [✸·| used in the right-hand side will be shown to depend only on abstract probabilities.
We begin with a general discussion.

‘Almost-certain’ is special for probabilistic systems
We place our work in context by recalling the following facts from finite-state Markov process theory, but in our notation. Let S be the finite state space.
Operator ◦ is a transition function over S. If we write state predicates P as {0, 1}-valued column vectors of height #S, then ◦ (if it contains no nondeterministic choice) can be seen as a Markov matrix, and ◦[P ] is post- multiplication of ◦ by the column vector representing P : each element
[P ].s of the product ◦[P ] gives the probability of reaching P from s. More generally, for expectation A as a column vector we have ◦A as post-
multiplication, and each element ◦A.s of the product gives the expected final value of A when taking a transition from s.
State s' is reachable from state s iff ◦n{s'}.s > 0 for some finite n (the number of transitions taken).
A subset P of S is closed (with respect to ◦) iff [P ] $ ◦[P ].
The probability of reaching P in one step from s — call it ◦1.P.s — is
[P ].s.
The probability of reaching P for the first time at the nth step, for n > 1, is ◦n.P := ◦([чP ] H ◦n−1.P ).
The probability of eventually reaching a subset P from state s, say ◦∞.P.s, is
Σ ◦n.P.s ,
n>0
which is also known as the ﬁrst-passage probability from s to P .
◦∞.{s}.s is the probability of eventual return to s.

In that notation we can state the following theorem for Markov processes:
Let ◦ represent a Markov matrix, let S be a finite state space and s a state; and let C be the set of reachable states from s. Then
◦∞.{s}.s =1 iff p[C] $ ◦∞.{s} for some p > 0. 13
The important thing to note about this result is that p is only specified to be greater than 0. Equivalently, only the connectivity of the Markov process is important, rather than the actual values of the probabilities — which is why the proof rule for ◦∞.{s}.s is so simple.
We regard the result as a form of completeness, because it states that the connectivity information is sufficient to establish the eventuality.
Our aim is to demonstrate that for probabilistic and demonic programs, a simpler calculus is all that is needed to prove (eventuality) properties with probability 1: as for standard programs only the “connectivity” of the program is important and not the actual probabilistic values. We will prove a similar completeness result for general eventuality properties. For many probabilistic programs that will provide a sufficient proof rule, since probability 1 (or not) is all that is of interest.
Other recent work on the special properties of “probability 1” events in pro- grams includes results of Rao [15], Pnueli/Zuck [13] and Hart/Sharir/Pnueli [16]. Their completeness results in some cases assume various kinds of fairness.
Relevant properties of our temporal operators
We concentrate on next-time ◦, eventually ✸ and unless ✄. The following properties can be proved directly from the operators’ definitions [10] or — in some cases — have been given above.
Lemma 4.1 Properties of next-time — For all expectations A, B,
(i) ◦A & ◦B $ ◦(A & B).
If A $ A', then ◦A $ ◦A'.
◦1 ≡ 1.
Lemma 4.2 Properties of eventually — For all expectations A, B,
A $ ✸A. 14
◦✸A $ ✸A.
If B H ◦A $ A, then ✸B $ A.
If A $ A', then ✸A $ ✸A'.

13 Note that p[C].s′ is just (p if s′ ∈ C else 0), so that — after applying both sides to
s′ — the inequality p[C] $ ◦∞.{s} says that for all s′ ∈ C the first-passage probability
∞.{s}.s′ from s′ to s is at least p.
14 Note how this follows from our intuitive ‘strategic’ explanation earlier of ✸A: since the
strategy “stop right now” is guaranteed to return at least A, the value of ✸A can never be less than that.

Lemma 4.3 Properties of unless — For all expectations A, B,
B $ A ✄ B $ A H B.
If C  $ B H (A H ◦C), then C $ A ✄ B.
A ✄ B ≡ B H (A H ◦(A ✄ B)).
If A $ A' and B $ B', then A ✄ B $ A' ✄ B'.
From these we have a form of completeness, based on the fact that the above properties determine the action of their respective operators.
Theorem 4.4 Standard completeness — If ◦, P,Q are interpreted over a ﬁ- nite state (standard) transition system, then the above properties are suﬃcient to calculate ✸[P ] and [P ] ✄ [Q] — only the transitions must be speciﬁed.
Although for probabilistic programs the same idea of finding the least solution to an equation remains valid (and is in that sense complete 15 ), even for finite-state programs discovering the actual real number values can still be rather tortuous, as we saw above. Indeed that is always going to be the case for non-(0-1) properties.
We desire a completeness property like Thm. 4.4 for abstract probabilistic programs — the idea is that if we only specify the transitions, merely indicat- ing when they are probabilistic, then we only need use standard techniques, without having to introduce all the complications of the full quantitative cal- culus.
Our first task is to show how to extract information “with probability 1”. From this point we assume that the transition system is probabilistic, and that the state space is finite. Recall our restriction in qTL to expectations that take values only in the unit interval [0, 1] rather than in the more general
range R≥.
Floor and ceiling for ‘almost certain’
Our principal tool will be the ceiling [·| and floor [·♩ operators (both taking expectations to expectations), defined
ceiling [A|.s := [A.s|, that is [A.s /= 0]
floor [A♩.s := [A.s♩, that is [A.s = 1]
With them we can write “almost certainly ✸[P ]” as [✸[P ]♩, and our aim is to calculate that from the ‘connectivity’ — the abstract probabilistic properties
— of ◦.
Floor and ceiling for the ‘connectivity’ of ◦
We also use ceiling and floor to extract the connectivity (rather than the particular values of) the probabilistic transitions . With them we define two

15 . . . provided we replace Lem. 4.1 Property (i) with full sublinearity.


‘derived’ transition operators, one converting probabilities to angelic choice, and the other converting them to demonic.
Definition 4.5 The angelic and demonic projections of ◦ are defined
angelic projection ◦aA := [◦A|
demonic projection ◦dA := [◦A♩
For example, if ◦[P ].s > 0 then there is a non-zero probabilistic transition from s into P , which revealed by the fact ◦a[P ].s = 1. That means for example that
(s:= H p⊕ s:= T )a	=	s:= H H s:= T ,
provided 0 < p < 1, where we are abusing notation to compare ◦a for the transition system on the left with ◦ for the system on the right. The operator H is angelic choice.
On the other hand ◦d[P ].s = 1 iff all the transitions from s (whether probabilistic or not) end up in P , so that we have
(s:= H p⊕ s:= T )d	=	s:= H H s:= T ,
again provided 0 < p < 1. Clearly ◦a and ◦d depend only on the connectivity, since they discard all numeric information; it is not difficult to show that they determine the connectivity. 16
Properties of ◦a and ◦d
Before proceeding to almost-eventually properties, we need the following tech- nical results for our connectivity operators.
Lemma 4.6 Some properties of ◦d — Projection ◦d in effect replaces prob- abilistic by demonic choice: it is conjunctive over predicates, monotonic in general, and distributes through greatest ﬁxed-points:
conjunctive ◦d([P ]& [Q])  ≡  ◦d[P ]& ◦d[Q].
monotonic If A $ A' then ◦dA $ ◦dA.
gfp-distributive If E.◦ is an expression containing the operator ◦, and F.◦d similarly, and they together satisfy [E.◦.X♩ ≡ F.◦d.[X♩ for all ex- pectations X, then
[νE.◦♩	≡	ν(F.◦d) .
Proof. Lemmas A.3 and A.5.	✷
Lemma 4.7 Some properties of ◦a — Projection ◦a in effect replaces proba- bilistic by angelic choice: it is monotonic, and distributes through least ﬁxed- points:
monotonic If A $ A' then ◦aA $ ◦aA'.

16 For a purely probabilistic or purely demonic system, either ◦a or ◦d would be sufficient on its own; only for a mixture of the two forms of choice does one need both operators.


lfp-distributive If E.◦ is an expression containing the operator ◦, and F.◦a similarly, and they together satisfy [E.◦.X| ≡ F.◦a.[X| for all ex- pectations X, then
[µE.◦|	≡	µ(F.◦a) .
Proof. Lemmas A.4 and A.6.	✷
Almost-certainly is related to connectivity
We can now show that some almost-certainly properties — though not yet the one we want — depend only on the connectivity of ◦, as captured by ◦a and
d.
Lemma 4.8 [A ✄ B♩ and [✸A| can be calculated from the connectivity ◦a,
d of ◦, and do not depend on the actual values of the probabilistic transitions.
Proof. A ✄ B is a greatest ﬁxed-point, and so the result follows from gfp- distribution of ◦d (Lem. 4.6) once we notice from Lem. A.3 that
[B H (A H ◦X)♩	≡	[B♩H ([A♩H ◦d[X♩) .
We treat ✸A similarly (lfp-distribution (Lem. 4.7) and Lem. A.4). 17    ✷
Unfortunately however, our aim is to calculate [✸A♩ (not [✸A|), and indeed [·♩ does not distribute through least fixed-points. For consider ◦ in- terpreted as
s:= H	1/2⊕	s:= T ,
and compare [✸{H}♩≡ 1 and (µX · [{H}♩H ◦dX) ≡ {H}.
it will turn out that we can reach [✸A♩ indirectly, via [✸· ·♩, at least when
A is standard; for that we begin with the following lemma:
Lemma 4.9 For all expectations A and transition systems ◦ we have
✸A	$	[✸A| ✄ A . 
Proof. We show that A H ◦([✸A| ✄ A) $ [✸A| ✄ A, which allows us to apply Property (iii) of Lem. 4.2:
A H ◦([✸A| ✄ A)	$	[✸A| ✄ A
iff    A H ◦([✸A| ✄ A)  $  A H ([✸A|H ◦([✸A| ✄ A))  definition ✄ iff   ◦([✸A| ✄ A)  $  [✸A|	arithmetic; A $ [✸A| (Lem. 4.2) iff     ◦([✸A| ✄ A)  $  [A|H [◦✸A|		definition ✸A; arithmetic
if	[✸A| ✄ A $ [✸A|H A $ [✸A| (Lemmas 4.2, 4.3); monotonicity ◦

17 With the obvious definitions we could write just
[A ✄ B♩ ≡ [A♩ ✄d [B♩  and  [✸A| ≡ ✸a[A| .


◦[✸A|	$	[◦✸A| ,
which is a consequence of Lem. A.4.	✷
Lem. 4.9 gives us trivially a connectivity-calculable upper bound on [✸A♩:

Lemma 4.10 Upper bound for almost-certain eventuality
[✸A♩	$	[[✸A| ✄ A♩ .
Proof. Lem. 4.9 and the monotonicity of [·♩.	✷
The right hand side is calculable from the connectivity of ◦, because by Lem. 4.8 we know that [✸A| is so calculable, and by Lem. 4.8 (again) so is [[✸A| ✄ A♩.
In the next section we show that we achieve equality when A is standard.

0-1 laws and temporal logic
In this section we show how the introduction of a 0-1 law (or axiom) is all that is needed to show that [✸[P ]♩ does indeed rely only on connectivity. 18 We gave an example of the 0-1 law for purely probabilistic programs; the idea has been extended to probabilistic/demonic programs [5,11] using the notation and ideas of temporal logic.
Lemma 5.1 0-1 Law — For any expectation A, predicate P and probability
p > 0, if p(A ✄ [P ]) $ ✸[P ] then in fact A ✄ [P ] $ ✸[P ].
Proof. The full proof — allowing demonic nondeterminism and possibly- aborting transitions — is beyond the scope of this paper; but it is a simple consequence of 0-1 results on the probabilistic treatment of loops [11, Lem. 6.1 p10]. As an illustration, however, we give a proof entirely in qTL (Thm. A.7) for the restricted case of non-demonic and terminating transitions.    ✷
The above law is valid for all state spaces: but for finite state spaces it has a much more compact formulation.
Lemma 5.2 0-1 Law (finite state spaces) — In ﬁnite state models, Lem. 5.1 is equivalent to
[✸[P ]| ✄ [P ]	$	✸[P ] .
Proof. Suppose the interpretation of ◦ is over a ﬁnite state space. That means that Lem. 5.1 is equivalent to the following, in which we have eliminated

18 It is only now that we must make some restrictions to predicates, rather than general expectations, which is why we write [P ] rather than A.



the abstract p. 19


if A ✄ [P ] $ [✸[P ]|	then	A ✄ [P ] $ ✸[P ]

We now show that (8) holds iff (9) holds.
implies (9) Suppose that A✄[P ] $ [✸[P ]|. It follows from Lem. 4.3
(ii) that A ✄ [P ] $ [✸[P ]| ✄ [P ], because
[P ] H ([✸[P ]|H ◦(A ✄ [P ])
@	[P ] H (A ✄ [P ] H ◦(A ✄ [P ])	assumption
≡	A ✄ [P ] ,	by cases on P.s
whence our assumption (8) gives us A ✄ [P ] $ ✸[P ], as desired overall.
implies (8) From Lems. 4.3(i) and 4.2(i) we have
[✸[P ]| ✄ [P ]	$	[✸[P ]|H [P ]	≡	[✸[P ]| ,
hence we have immediately from (9) that
[✸[P ]| ✄ [P ]	$	✸[P ] .
✷
Corollary 5.3 For ﬁnite models, ✸[P ] ≡ [✸[P ]| ✄ [P ].
Proof. In ﬁnite models we may use the second form Lem. 5.2 of the 0-1 law; the result then follows from Lemma 4.9.	✷
Cor. 5.3 is the key to showing that for probability-1 properties, connectivity is sufficient.
Theorem 5.4 Completeness for probability-1 eventualities — If ◦ is inter- preted over a ﬁnite-state probabilistic system, and P is a state predicate, then [✸[P ]♩ is determined by ◦a and ◦d, the probabilistic/demonic connectivity of
◦.
Proof. Cor. 5.3 gives us that ✸[P ] ≡ [✸[P ]| ✄ [P ], from which we have
[✸[P ]♩	≡	[[✸[P ]| ✄ [P ]♩ .
Since [· ✄ ·♩ and [✸·| depend only on the connectivity, the result follows. ✷

Example
Consider the abstract system
s:= H	|	s:= T ,

19 To see that (9) does not hold for infinite state spaces, consider this system over S := Z that defines a random walker on the integers:
s:= s +1	2/3⊕	s:= s — 1 .
Observe that [✸[s ≤ 0]|≡ 1 ≡ [s > 0] ✄ [s ≤ 0], but that ✸[s ≤ 0] is not equal to 1.

A qTL formula Φ is of the form
A	explicitly given numeric function over S, typed S → [0, 1] Φ H Φ	minimum, generalising Λ
Φ H Φ	maximum, generalising V
Φ	next-time
✸Φ	eventually
✷Φ	always Φ ✄ Φ	unless ,
and the interpretation of the formula is via the quantitative µ-calculus, as given earlier in Fig. 7. The formula is said to be almost certain at a state s of a given transition system if it evaluates to 1 at s.
Fig. 8. Quantitative temporal logic formulae and interpretation
where the “|” represents an abstract p⊕ with 0 < p < 1. The probabilistic connectivity is given by
angelic ◦a[P ] ≡ [P /≡ {}], because there is a non-zero probability of estab- lishing any non-empty predicate over {H, T}.
demonic ◦d[P ] ≡ [P ≡ {H, T}], because there is a non-zero probability of avoiding any non-total predicate over {H, T}.
Now we look at the almost-certain eventuality [✸{H}♩; we have


Complexity analysis
We now look briefly at the time-complexity of evaluating almost-certainties in qTL: the precise language and its interpretation is set out in Fig. 8; and our result is that the complexity of evaluating [Φ♩ over transition system
7 is linear in the number of temporal operators in Φ and in the number of transitions in 7 . We outline a proof of that in this section.
Throughout the following we will use the specific formula Φ0, defined
✸(A H (B ✄ ✷C)) ,
as a running example: we want to evaluate [Φ0♩.


“angelic-eventually A”	✸aA	:=	(µX · A H ◦aX) “demonic-always A”	 ✷dA	:=	(νX · A H ◦dX)
“A demonic-unless B”	A ✄d B	:=	(νX · B H (A H ◦dX))
These operators are analogues of the ∃◦, ∀✷ etc. of conventional (probabilistic) temporal logic.
Fig. 9. Angelic/demonic temporal operators
Propagate [·♩ inwards
Recalling Lem. 4.8, define angelic/demonic versions of the temporal operators as in Fig. 9. (Compare Fig. 7.)
To distribute [·♩ inwards we use the equalities set out in this lemma: 20
Lemma 7.1
[◦A♩≡ ◦d[A♩
[✸A♩≡ [✸[A♩♩
[✷A♩≡ ✷d[A♩
[A ✄ B♩≡ [A♩ ✄d [B♩
Proof. Only (12) needs comment. Its proof relies on the fact that ✸, like ◦, is semi-sublinear [8]; given that, its proof mimics that of Lem. A.3.
Note that we do not use ✸d (with the obvious deﬁnition) in this case, because we cannot: recall the remarks following Lem. 4.8.	✷
Using our lemma with Φ0, we have
[✸(A H (B ✄ ✷C))♩
≡ [ ✸([A♩ H [B♩ ✄d (✷d[C♩)) ♩ ,
in which all explicit expectations (A, B, C) have been made standard ([A♩,
[B♩, [C♩).
Convert ✸’s to standard operators
The procedure of the previous section eliminated all properly probabilistic modal operators, replacing them with demonic versions, except for ✸. To deal with ✸ we use our main result Cor. 5.3 which, combined with the above and Lem. 4.8, allows us to state that
[✸A♩	≡	(✸aA) ✄d A , 

20 Some of these have been defined/stated elsewhere in this report; we repeat them here for the convenience of having them all together.


provided A is standard. Since the inward propagation of the previous section has made all sub-formulae standard, indeed (15) applies: in the case of Φ0 we can continue
[ ✸([A♩ H [B♩ ✄d (✷d[C♩)) ♩
≡ (✸aX) ✄d X , 
where X := [A♩ H [B♩ ✄d (✷d[C♩).
We use the ‘where’-clause to remember that X has been duplicated, so that we need calculate it only once.
Evaluate [Φ♩
The two translations of the previous sections transform Φ into an expression containing only ◦d, ✸a, ✷d and ✄d. The number of those operators is no more than twice the number of operators in the original formula, provided the duplication inherent in (15) is properly noted. Thus our result will follow if we can establish that evaluation of each of those operators is linear in the size of the transition system. We discuss that briefly for each operator in turn; in each case A, B are standard.
dA — ◦d treats the system as entirely demonic. Examine all states, and select only those all of whose outgoing transitions lead into A.
✸aA — If the original system contains demonic (as well as probabilistic) choice, then the system will be treated as demonic/angelic by ✸a — that is, although the probabilistic choice is made angelic, the pure demonic choice is retained. The operational behaviour for each complete transition is a ‘first-stage’ demonic choice of ‘half-transition’ followed by a ‘second- stage’ angelic choice of half-transition.
Start with the set of states A, and for each of its states follow all second-stage angelic half-transitions back, colouring their sources; if the source was uncoloured, continue on to follow back the first-stage half- transition, decrementing the ‘first-stage transition count’ of its originating state (prepared beforehand).
Having done that for all of A, go over the transitions again this time deleting all second-stage transitions followed, and adding all states whose first-stage count has become zero, in that case deleting the first-stage transitions as well.
Continue the process until no states are added; each transition will have been followed at most a constant number of times (amortised).
✷dA — Treat it as A ✄d 0.
A ✄d B — ✄d treats the system as entirely demonic; we work with the complement. Start with the set of states чA Λ чB, and for each transition leading backwards from there:
if it leads into B, ignore it; and
if it leads into A Λ чB, add that state to the set.

In either case, delete the transition; and repeat the process with the added states, stopping the whole procedure when no new states are added. The result is the complement of the accumulated states; and in the process, each transition is considered at most once.
In the case of Φ0 we carry out four calculations from the above, two within
X and two outside it.

Conclusion
Abstract probabilities and 0-1 laws have long been recognised as important techniques for simplifying analysis in probabilistic systems. However the ten- dency has been to use formulations of those laws at the level of models [1,15,17] and not to integrate them formally as axioms of program logic, as is customary for other operational phenomena.
There are certainly difficulties in importing well-understood concepts di- rectly from probability theory to a computational context, due to the compli- cating factor of nonderterminism: it is not present in classical probability the- ory. Many of those difficulties can be resolved using the probabilistic version of Dijkstra/Hoare-style program logic [12] which is intended to deal naturally with nondeterminism, probability and their interaction. In addition temporal logic provides a framework for handling properties of infinite (repeated) execu- tions of programs — precisely the situation where 0-1 laws begin to bite. The resulting fragment of qMµ described in this paper, and used to define temporal operators, is thus ideal for studying probability, nondeterminism and 0-1 laws all together.
In qMµ we find, as in other works, that probabilistic choice when used specifically for “probability-1” properties can (to an extent) be interpreted angelically. But this is definitely not sound in all situations, and sometimes a demonic interpretation is necessary.
For example consider the formula [✸[s=2]♩ interpreted in the system de- fined by
s /=0  →  s:= 0 | s:= 1 | s:= 2 .
Recall that “|” stands for some p⊕ with 0 < p < 1.
A direct calculation shows that the probability of eventually reaching s=2 is strictly less than 1 (unless the system is initially in that state). But an angelic interpretation for | in [✸[s=2]♩ would give 1, and therefore must be unsound. To see that a demonic interpretation is also unsound consider the probability of eventually reaching s=0. Again a direct calulation shows that it is 1 irrespective of the initial state, whereas a demonic interpretation of | in the formula [✸[s=0]♩ gives 0 (except from s=0 initially).
Indeed finding an optimal balance between the two interpretations — in order to maintain soundness in all situations — is a major challenge. As we do, Rao [15] uses two interpretations of probabilistic choice, though he imposes

fairness on the execution sequences, which we do not. Others’ work (Hart et al. [5], Vardi [17] use similar ideas, but are model- rather than logic-based.
The emphaisis of our work has been to clarify exactly when each of the two interpretations of | is appropriate for the interpretation of temporal formulae in probabilstic systems. Granting the 0-1 law the status of a logical axiom proved to be critical in doing so.
To summarise, we have shown that the demonic interpretation goes with greatest fixed-points (“always” and “unless”) and “=1” probabilities , and that the angelic goes with least fixed points (“eventually”) and “> 0” prob- abilities, finally leaving the 0-1 law standing out as the key idea underlying their combination in “=1” eventually properties.
The second contribution of this work is the complexity of the model check- ing problem. The result sketched in Sec. 7 shows that for the logic corre- sponding to “worst case” probabilistic CTL the complexity is linear in the size of the formula and the size of the underlying transition system. That matches the best known complexity for nonprobabilistic CTL interpreted over nonprobabilistic transition systems [3].

References
Andrea Bianco and Luca de Alfaro.  Model checking of probabilistic and nondeterministic systems. In Foundations of Software Technology and Theoretical Computer Science, number 1026 in LNCS, pages 499–512, December 1995.
K. Mani Chandy and Jayadev Misra. Parallel Program Design — a Foundation. Addison-Wesley, 1988.
Rance Cleaveland and Bernhard Steffen. A linear-time model-checking algorithm for the alternation-free modal-µ calculus. In Proc. CAV, Aalborg, 1991.
E.A. Emerson. Temporal and modal logics. In Jan van Leeuwen, editor, Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics, pages 995–1072. Elsevier and MIT Press, 1990.
S. Hart, M. Sharir, and A. Pnueli. Termination of probabilistic concurrent programs. ACM Transactions on Programming Languages and Systems, 5:356– 380, 1983.
D. Kozen. Results on the propositional µ-calculus. Theoretical Computer Science, 27:333–354, 1983.
A.K. McIver. Quantitative program logic and counting rounds in probabilistic distributed algorithms. In Proc. 5th Intl. Workshop Arts ’99, number 1601 in LNCS, May 1999.


Annabelle McIver and Carroll Morgan. Demonic, angelic and unbounded probababilistic choices in sequential programs. Acta Informatica, to appear., 2000.
Carroll Morgan and Annabelle McIver. A probabilistic temporal calculus based on expectations. In Lindsay Groves and Steve Reeves, editors, Proc. Formal Methods Pacific ’97. Springer Verlag Singapore, July 1997. Available at [14].
Carroll Morgan and Annabelle McIver. An expectation-based model for probabilistic temporal logic. Logic Journal of the IGPL, 7(6):779–804, 1999.
C.C. Morgan.  Proof rules for probabilistic loops.  In He Jifeng, John Cooke, and Peter Wallis, editors, Proceedings of the BCS-FACS 7th Refinement Workshop, Workshops in Computing. Springer Verlag, July 1996. http://www.springer.co.uk/ewic/workshops/7RW.
C.C. Morgan, A.K. McIver, and K. Seidel. Probabilistic predicate transformers. ACM Transactions on Programming Languages and Systems, 18(3):325–353, May 1996.
A. Pnueli and L. Zuck. Probabilistic verification. Information and Computation, 103(1):1–29, March 1993.
PSG. Probabilistic Systems Group: Collected reports.
http://web.comlab.ox.ac.uk/oucl/research
/areas/probs/bibliography.html.
J.R. Rao. Reasoning about probabilistic parallel programs. ACM Transactions on Programming Languages and Systems, 16(3), May 1994.
M. Sharir, A. Pnueli, and S. Hart. Verification of probabilistic programs. SIAM Journal on Computing, 13(2):292–314, May 1984.
M.Y. Vardi. Automatic verification of probabilistic concurrent finite-state programs. In Proc. 26th IEEE Symp. on Foundations of Computer Science, pages 327–338, Portland, October 1985.

A	Proofs of lemmas
Lemma A.1 eventually-until — For all predicates P, Q we have
P ✄ (P Λ Q) Λ ✸Q	$	✸(P Λ Q) .
Proof. Let Ln and Rn be the nth terms respectively in the H-limits for the least ﬁxed-points ✸Q and ✸(P Λ Q). We show by induction that
P ✄ (P Λ Q) Λ Ln	$	Rn
for all n.
Base case: L0 ≡ R0 ≡ False.
Inductive case:
P ✄ (P Λ Q) Λ Ln+1




≡	(P Λ Q) V (P Λ ◦(P ✄ (P Λ Q)))
Λ	Q V ◦Ln
definitions ✄, ✸



≡	(P Λ Q) Λ (Q V ◦Ln)
V (P Λ ◦(P ✄ (P Λ Q))) Λ Q
V (P Λ ◦(P ✄ (P Λ Q))) Λ ◦Ln
propositional reasoning



$	P Λ Q
V P Λ Q
V ◦((P ✄ (P Λ Q)) Λ Ln)
propositional reasoning; conjunctivity (3)



$	P Λ Q
V ◦Rn
propositional reasoning; inductive hypothesis; monotonicity


≡	✸Rn+1 .	definition ✸
We complete the proof by observing that “(P ✄(P Λ Q)) Λ” distributes through
H-limits.	✷
Lemma A.2 probabilistic eventually-until — For all expectations A, B we have
A ✄ (A & B) & ✸B	$	✸(A & B) .
Proof. We follow the proof of Lem. A.1, but must be careful in two respects: ﬁrst, that we generalise Λ sometimes to H and sometimes to &; and second that
— unlike Λ — the operator & is not idempotent. It is associative, however.
Let Ln and Rn be the nth terms respectively in the H-limits for the least ﬁxed-points ✸B and ✸(A & B). We show by induction that
A ✄ (A & B) & Ln	$	Rn
for all n.
Base case: L0 ≡ R0 ≡ 0.
Inductive case:
A ✄ (A & B) & Ln+1


≡	(A & B) H (A H ◦(A ✄ (A & B)))
&	B H ◦Ln
definitions ✄, ✸



≡	(A & B) & (B H ◦Ln)
H (A H ◦(A ✄ (A & B))) & B
H (A H ◦(A ✄ (A & B))) & ◦Ln
arithmetic: H, H distribute through &



$	A & B
H A & B
H ◦((A ✄ (A & B)) & Ln)
arithmetic; &-subadditivity (5)



$	A & B
H ◦Rn
propositional reasoning; inductive hypothesis; monotonicity


≡	✸Rn+1 .	definition ✸
We complete the proof by observing that “(A✄ (A & B)) &” distributes through
H-limits.	✷
Lemma A.3 For all expectations A we have ◦dA ≡ ◦d[A♩.
Proof. We use sublinearity (Property 4 Fig. 4). For any n ≥ 0 we have by arithmetic that
(A.1)	[A♩	$	(n+1)A gn
and, because the state space S is ﬁnite, there is some (large enough) nA for which (A.1) is actually an equality. Now
d[A♩

The reverse inequality is immediate from monotonicity.	✷
Lemma A.4 For all expectations A we have ◦aA ≡ ◦a[A|.
Proof. Again we use sublinearity (as scaling and feasibility; see end Sec. 2.2). For any n ≥ 0 we have that
(A.2)	[A|	@	nA H 1
and, because the state space S is ﬁnite, there is some (large enough) nA for

which (A.2) is actually an equality. Now
a[A|
≡	[◦(nAA H 1)|	definition ◦a; choose nA large enough

The reverse inequality is immediate from monotonicity.	✷
Lemma A.5 If [J.X♩≡ G.[X♩ for all expectations X, then
[νJ♩	≡	νG .
Proof. Because [·♩ distributes through inﬁmum H, we prove by induction that
[Jn.1♩	≡	Gn.1 .
For the base case we require trivially that [J0.1♩≡ 1 ≡ G0.1. For the induction we have
[Jn+1.1♩

✷
Lemma A.6 If [J.X|≡ G.[X| for all expectations X, then
[µJ|	≡	µG .
Proof. Because [·| distributes through supremum H, we prove by induction that
[Jn.1|	≡	Gn.1 .
For that the proof is analogous to Lem. A.5.	✷
Theorem A.7 0-1 Law for deterministic/abort-free systems If for some prob- ability p satisfying 0 < p ≤ 1 we have

(A.3)
then in fact we have
(A.4)
p(I ✄ [чG])	$	✸[чG] ,

I ✄ [чG]	$	✸[чG] ,

provided ◦ is deterministic and terminating.

Proof. We rely on four main ideas, based on thinking of I as a loop invariant and G as the loop guard. The ﬁrst idea is that I ✄ [чG] is an invariant of any loop with guard G: if I ✄ [чG] holds 21 initially, then it continues to hold up to and including loop termination, the point at which чG is established.
The second idea is that invariance is preserved by scaling: if J is any invariant, then so is pJ for any scalar 0 ≤ p. That will tell us, from above, that p(I ✄ [чG]) is invariant too.
The third idea is that 1 — ✸[чG] is invariant also, provided the system is deterministic and terminating. Its being invariant says “if чG is not a guaranteed eventuality here, then taking a computational step won’t make it so”.
The fourth idea is that the sum of two invariants, provided that sum is well deﬁned in the sense of lying between 0 and 1, is also an invariant.
Combining all those, we will be able to show that the complicated expression
(A.5)	J	:=	p(I ✄ [чG])+ (1 — ✸[чG])
is an invariant; but from it we’ll conclude that
(A.6)	p(I ✄ [чG])	$	p(✸[чG]) ,
whence division by p will give us our desired conclusion (A.4). The only place we use our assumption (A.3) is to to note that it ensures (trivially) that J is well deﬁned (lies in [0, 1]); the only place we use p > 0 is in the division that takes us from (A.6) to (A.4).
We begin by noting that invariance of J conventionally means “if it holds now, then it continues to hold up until and including the step in which чG becomes true, if чG ever does become true”. That is, to say that J is invariant we require
(A.7)	J	$	J ✄ (J & [чG]) ,
where the extra J & ensures it remains true for the ﬁnal step (‘as the loop exits’). But (A.7) follows from the simpler

(A.8)
J & [G]	$	◦J ,

which is just the way one reasons about loop invariants: 22 to show that we calculate
(J & [чG]) H (J H ◦J )
@	(J & [чG]) H (J H (J & [G]))	assumption (A.8)
≡	J & [чG]	H	J & [G]	arithmetic
≡	J ,

21 We say “holds” even if I might not be standard: it assists the intuition when I is in fact standard; and the reasoning is sound in any case.
22 . . . because (A.8) just says “invariant J is preserved by executing the loop body while the
guard holds”.


whence we get (A.7) from Lem. 4.3 (ii). So we check that our particular J
(A.5) satisﬁes (A.8) by calculating
(p(I ✄ [чG])+ (1 — ✸[чG]))
≡	◦(p(I ✄ [чG])) + ◦1 — ◦✸[чG]	◦ deterministic

@	◦ scaling and abort-free; ◦✸[чG] $ ✸[чG]
p(◦(I ✄ [чG]))+1 — ✸[чG]
@	(I ✄ [чG])& [G] $ ◦(I ✄ [чG])
(p(I ✄ [чG])+1 — ✸[чG]) & [G] .
We have now shown that J satisﬁes (A.7).
To ﬁnish off, we put “&✸[чG]” on both sides of (A.7), and use Lem. A.2 to conclude by reasoning
J & ✸[чG]
$	J ✄ (J & [чG]) & ✸[чG]	from (A.7)
$	✸(J & [чG]) .	Lem. A.2
Now by arithmetic J & ✸[чG] is just p(I ✄ [чG]), and J & [чG] is just
p[чG] whence — using scaling of ✸ — we end up with (A.6), as required. ✷
