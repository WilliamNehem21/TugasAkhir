Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 342 (2019) 39–55
www.elsevier.com/locate/entcs


An Adaptive Algorithm for Rule Learning: Case Study and Preliminary Results
Renata Luiza Stangea,b,1,2 Paulo Roberto Massa Ceredab,3 João José Netob,4
a Federal University of Technology Guarapuava, Paraná, Brazil
b University of São Paulo, São Paulo, São Paulo, Brazil

Abstract
Problem partitioning strategies such as sequential covering are commonly used in rule learning algorithms, such that the task of finding a complete rule base is reduced to a sequence of subproblems. In this scenario, each solution to a subproblem consists of adding a single rule to the entire set. In this paper, we propose an alternative for rule learning based on the use of an adaptive formalism whose behavior is determined by a dynamic set of rules. Preliminary results yield a compact yet significantly comprehensible rule set, as well as an eﬃcient model representation, from raw data using adaptive techniques. To this end, we include further discussions regarding features and enhancements to be contemplated in future works.
Keywords: artificial intelligence, machine learning, rule learning, adaptivity, problem partitioning


Introduction
Machine learning is concerned about the construction of computer programs that automatically improve with experience [13]. Similarly, pattern recognition is inter- ested in the automatic discovery of regularities in data through computer algorithms and the later application of such regularities as decision making actions, such as dif- ferent data categorizations [3]. One of the well-known classification approaches in machine learning consists of extracting rules. These algorithms generally produce if-then classifiers, with a predictive performance comparable to other traditional classification approaches, such as decision trees and associative classification [22].

1 E-mail: rlgomes@utfpr.edu.br
2 E-mail: rlstange@usp.br
3 E-mail: paulo.cereda@usp.br
4 E-mail: jjneto@usp.br

https://doi.org/10.1016/j.entcs.2019.04.004
1571-0661/© 2019 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

A inductor method for rule classification applies an iterative process that covers a subset of training examples and then remove all examples covered by the rule from the training set. This process is repeated until there are no examples left to cover. The final rule set is the collection of rules learned at each iteration [9]. PRISM is one of the rule induction techniques which was developed in [4] and slightly enhanced by others, i.e. [8] and [19]. This algorithm employs separate-and-conquer strategy in knowledge discovery in which PRISM generates rules according to the class labels in the training dataset.
Adaptive technology refers to the use of techniques and devices which are ex- pected to react to given inputs by autonomously modifying their own behavior [14]. In a broad sense, computers learn when there is a behavioral change in order to better perform a specific task. Inspired by previous works on these areas [20,21], we demonstrate how learning systems can be dynamically adjusted by using adaptive techniques. A direct advantage on incorporating adaptivity in learning methods consists on covering a fundamental aspect of learning itself: the dynamic adaptation of a rule set based on interactions with the environment [15]. Additionally, use of adaptive technology tends to be more expressive than traditional methods [14].
This paper presents a hybrid approach to extracting rules from data using adap- tive concepts and supervised learning techniques, such as obtaining if-then rules from data. The approach is based on sequential covering strategies which involve problem decomposition: the task of finding a complete rule base is reduced to a se- quence of subproblems in which the solution to each subproblem is a single rule. The global solution gathers all partial solutions [9]. Additionally, the self-modification feature of adaptive rule-driven devices allows an iterative knowledge inspection, adding rules that improve predictions on the complete rule base and also replacing one or more rules in order to simplify the knowledge representation. Observe that algorithms AQ [12] and CN2 [5] implement this strategy.
Adaptive technology has been successfully used in pattern recognition and ma- chine learning. Pistori and Neto [16] propose a decision tree induction algorithm using adaptive techniques, combining syntactic and statistical strategies. In [17], Pistori presents an adaptive automaton as device for an automatic recognition pro- cess of sign language. Adaptive automata are also reported to be used in syntactic pattern recognition of shapes [6] and in construction of hybrid maps for robot nav- igation [11]. Other applications of adaptive techniques include skin cancer recogni- tion [10] and optical character recognition [7].

Theoretical framework
This section provides the theoretical framework needed for our proposal, covering the classification problem itself, rule-based systems and rule-driven adaptive devices.
Rule-based systems
Decision rules are widely used to represent knowledge obtained from data [2]. An
if-then rule has a simple construction; for instance, if an certain object swims and

has scales, then such object is a fish. Fig. 1 shows the structure of an rule. A rule-based system can be learned through a strategy known as divide and conquer. Rule-based methods are fundamental to expert systems in artificial intelligence, where classes can be characterized by general relationships among entities. Here we shall focus on a broad class of if-then rules for representing and learning such relationships. The general form of a if-then rule is P → Q or if P then Q, where P is a proposition that can contain a conjunction of n arbitrary attribute-value pairs, P = condition1 ∧ ... ∧ conditionn. It is important to observe that n is known as the rule length, and Q is the value of the categorical target attribute.

Rule
Fig. 1. Structure of an if-then rule.
According to Mitchell [13], a possible approach to learn sets of rules involves learning a decision tree through an induction algorithm, such as ID3 [18], followed by a translation of such tree to an equivalent set of rules. A decision tree can be mapped to a set of rules, transforming each branch into a rule, i.e, each path from the root to one leaf corresponds to a rule. Fig. 2 presents a hypothetical example of decision tree.

Fig. 2. Example of a decision tree. Each path from the root to a leaf can be written down as a conjunctive rule, composed of conditions defined by the decision nodes on the path.

The decision tree shown in Fig. 2 can be written down as the following decisions rule set:

Rule 1:
Rule 2:
Rule 3:
if x1 > 1 then class = a;
if x1 > 1 ∧ x1 < 10 then class = b;
if x1 > 1 ∧ x1 >= 10 then class = c;

As reported by [23], this approach produces rules that are unambiguous in the sense that the order they are executed does not matter. However, the rules are more complex than necessary. As we have just seen, we can obtain if-then rules by learning a decision tree and converting it to rules. Another approach covers the direct rule learning. Decision rules learning works similarly to a decision tree except

that the rule induction does a depth-first search and generates one rule at a time, whilst the decision tree induction does a breadth-first search and generates all paths simultaneously [1].
Sequential covering algorithms use a popular technique for learning rule sets based on the strategy of learning one rule at a time, removing the data it covers, then iterating this process [23]. The following steps show a sketch of how a general set covering algorithm works [2]:
Create a rule that covers some examples of a certain class and does not cover any examples of other classes,
remove covered examples from training data, and
if there are some examples not covered by any rule, go to step 1.
A prototypical sequential covering algorithm is described in Algorithm 1.

Algorithm 1 Sequential Covering algorithm
1: procedure Sequential covering (target attributes, attributes, examples, threshold ) 2:	learned rules → {}
3:	rule → Learn-one-rule()
4:	while Performance(rules, examples) ≤ threshold do
5:	learnedRules → learned rules + rule
6:		examples → examples − {examples correctly} 7:	end while
8:	return learned rules
 9: end procedure	

As reported by Mitchell [13], Learn-one-rule must return a single rule that covers at least some of the examples. Performance is a user-provided subroutine to evaluate the rule quality. This covering algorithm learns rules until it can no longer learn a rule whose performance is above the give threshold. Common evaluation functions include [13]:
Relative frequency. Let n denote the number of examples the rule matches and let nc denote the number of these that it classifies correctly. The relative frequency estimate of rule performance w is given by:


w = nc
n
(1)

m-estimate of accuracy.  This accuracy estimate is biased toward the default
accuracy expected for the rule. Let p be the prior probability that a randomly drawn example from the entire dataset will have the classification assigned by the rule. Let m be the weight, or equivalent number of examples for weighting this prior p. The m-estimate of rule accuracy is given by:


m = nc + mp e	n + m
(2)

Entropy. Entropy measures the uniformity of target function values for this set of examples. Let S be the set of examples that matches the rule preconditions. We

take the entropy negative so that better rules will have higher scores.
S = Σ pi log2 pi	(3)
i=1
where p is the probability that an event occurs and i is the index of the event.
Rule-driven adaptive devices
This subsection formally introduces the mathematical formalism proposed by José Neto [15]. Observe that the theory relies on an adaptive mechanism enclosing a non-adaptive rule-driven device, such that the latter may be enhanced in order to accommodate an adaptive behavior while preserving its integrity and original properties.
Definition 2.1 [rule-driven device] A rule-driven device is defined as ND = (C, NR, S, c0, A, NA), such that ND is a rule-driven device, C is the set of all possible configurations, c0 ∈ C is the initial configuration, S is the set of all possible input stimuli, ϵ ∈ S, A ⊆ C is the subset of all accepting configurations (respectively, F = C − A is the subset of all rejecting configurations), NA is the set of all possible output stimuli of ND as a side effect of rule applications, ϵ ∈ NA, and NR is the set of rules defining ND as a relation NR ⊆ C × S × C × NA.
Definition 2.2 [rule] A rule r ∈ NR is defined as r = (ci, s, cj, z), ci, cj ∈ C, s ∈ S and z ∈ NA, indicating that, as response to a stimulus s, r changes the current configuration ci to cj, processes s and generates z as output [15]. A rule r = (ci, s, cj, z) is said to be compatible with the current configuration c if and only if ci = c and s is either empty or equals the current input stimulus; in this case, the application of a rule r moves the device to a configuration cj, denoted by ci ⇒s cj, and adds z to the output stream.
Definition 2.3 [acceptance of an input stimuli stream by a rule-driven device] An input stimuli stream w = w1w2 ... wn, wk ∈ S − {ϵ}, k = 1,..., n, n ≥ 0, is accepted by a device ND when c0 ⇒w1 c1 ⇒w2 ... ⇒wn c (in short, c0 ⇒w c), and c ∈ A. Respectively, w is rejected by ND when c ∈ F . The language described by a rule-driven device ND is represented by L(ND )= {w ∈ S∗ | c0 ⇒w c, c ∈ A}.
Definition 2.4 [adaptive rule-driven device] A rule-driven device AD  = (ND 0, AM ), such that ND 0 is a device and AM is an adaptive mechanism, is said to be adaptive when, for all operation steps k ≥ 0 (k is the value of an internal counter T starting in zero and incremented by one each time a non-null adaptive action is executed), AD follows the behavior of an underlying device NDk until the start of an operation step k +1 triggered by a non-null adaptive action, modifying the current rule set; in short, the execution of a non-null adaptive action in an operation step k ≥ 0 makes the adaptive device AD evolve from an underlying device NDk to NDk+1.
Definition 2.5 [operation of an adaptive device] An adaptive device AD starts its operation in configuration c0, with the initial format defined as AD 0 =

(C0, AR0, S, c0, A, NA, BA, AA). In step k, an input stimulus move AD to the next configuration and starts the operation step k + 1 if and only if a non- adaptive rule is executed; thus, being the device AD in step k, with ADk = (Ck, ARk, S, ck, A, NA, BA, AA), the execution of a non-null adaptive action leads to ADk+1 = (Ck+1, ARk+1, S, ck+1, A, NA, BA, AA), in which AD = (ND 0, AM ) is an
adaptive device with a starting underlying device ND 0 and an adaptive mechanism AM , NDk is an underlying device of AD in an operation step k, NRk is the set of non-adaptive rules of NDk, Ck is the set of all possible configurations for ND in an operation step k, ck ∈ Ck is the starting configuration in an operation step k, S is the set of all possible input stimuli of AD , A ⊆ C is the subset of accepting configura- tions (respectively, F = C −A is the subset of rejecting configurations), BA and AA are sets of adaptive actions (both containing the null action, ϵ ∈ BA∩AA), NA, with ϵ ∈ NA, is the set of all output stimuli of AD as side effect of rule applications, ARk is the set of adaptive rules defined as a relation ARk ⊆ BA ×C ×S ×C ×NA ×AA, with AR0 defining the starting behavior of AD , AR is the set of all possible adaptive rules for AD , NR is the set of all possible underlying non-adaptive rules of AD , and AM is an adaptive mechanism, AM ⊆ BA×NR×AA, to be applied in an operation step k for each rule in NRk ⊆ NR.
Definition 2.6 [adaptive rules] Adaptive rules ar ∈ ARk are defined as ar = (ba, ci, s, cj, z, aa) indicating that, as response to an input stimulus s ∈ S, ar ini- tially executes the prior adaptive action ba ∈ BA; the execution of ba is canceled if this action removes ar from ARk; otherwise, the underlying non-adaptive rule nr = (ci, s, cj, z), nr ∈ NRk is applied and, finally, the post adaptive action aa ∈ AA is applied [15].
Definition 2.7 [adaptive function] Adaptive actions may be defined as abstractions named adaptive functions, similar to function calls in programming languages [15]. The specification of an adaptive function must include the following elements: (a) a symbolic name, (b) formal parameters which will refer to values supplied as argu- ments, (c) variables which will hold values of applications of elementary adaptive actions of inspection, (d) generators that refer to new value references on each usage, and (e) the body of the function itself.
Definition 2.8 [elementary adaptive actions] Three types of elementary actions are defined in order to perform tests on the rule set or modify existing rules, namely:
inspection: the elementary action does not modify the current rule set, but allows inspection on such set and querying rules that match a certain pattern. It employs the form ?⟨pattern⟩.
removal: the elementary action removes rules that match a certain pattern from the current rule set. It employs the form −⟨pattern⟩. If no rule matches the pattern, nothing is done.
insertion: the elementary action adds a rule that match a certain pattern to the rule set. It employs the form +⟨pattern⟩. If the rule already exists in the rule set, nothing is done.

Such elementary adaptive actions may be used in the body of an adaptive func- tion, including rule patterns that use formal parameters, variables and generators available in the function scope.
Fig. 3 presents the general concept of a set of rules enhanced with adaptive actions being mapped to adaptive functions. Note that B and A denote adaptive actions to be triggered before and after the rule application, respectively.


Adaptive rule-driven device
Adaptive functions








Fig. 3. Set of rules enhanced with adaptive actions being mapped to adaptive functions.

An adaptivity-based rule learning technique
Our approach for an adaptivity model is inspired on the sequential covering descrip- tion presented in Algorithm 1, with subtle yet significant differences. According to Algorithm 1, subroutine Learn-one-rule accepts a set of positive and negative training examples as input and returns as output a single rule that covers many of the positive examples and few of the negative ones. We propose a modification to this subroutine, such that it now returns different rules that cover both positive and negative examples (we have also renamed such subroutine to Learn-rules). We also treat the set of examples differently, such that Learn-rules is invoked on all available training examples. Additionally, it removes positive or negative examples completely covered by the rule it learns, according to some heuristic (i.e, whenever relative frequency is equal to 1).
The sequential covering strategy uses a greedy approach that takes the best local actions where it iteratively learns a single rule, so that each learned rule is added to the rule base. Generally, those rules being added in each iteration keep being part of the rule base until the end of the learning process. Thus, our proposal aims at modifying the sequential covering strategy, such that the new technique is able to review already learned rules through adaptive functions. In each step, it is possible to decide among three options:
add a new rule that improves the prediction capability of the rule base,

add the best rule that replaces one or more rules of the rule base, as an attempt to increase the prediction capability, or
the rule base it is not updated.
Algorithm 2 learns rules until all instances have been covered by the rule set, or there are no more attributes to be added.

Algorithm 2 Adaptive algorithm
1: procedure main(attributes, D ) 2:	learned rules → {}
3:	examples → D
4:	attributes → information-gain(attributes, D )
5:	while Performance(attributes, examples) ≤ threshold do
6:	candidate rules → {}
7:	learnedRules → Learn-rules()
8:		examples → examples − {correctly classified examples} 9:	end while
10:	return learned rules 11: end procedure
The main loop searches for a default rule Ri in a set of rules ARk. Default rule Ri is defined as Ri = P → Q (w)[Ai],i = 1 ... n, where [Ai], is an adaptive function and it is defined in Algorithm 3.

Algorithm 3 Adaptive Function Ai
1: procedure Ai(rj , P, Q,fr) 2:	−[P → Q(w)[Ai]]:
3:  +[rj (fr)[Ai]]:
4: end procedure

A possible approach to implement the
Learn-rules
subroutine - see Algo-

rithm 4, consists of organizing the hypothesis space search similarly to ID3 algo- rithm’s behavior [18], but restricting the search to the most promising tree branch at each step. Our approach uses a breadth-first search to construct the next rule. Since the rule consequent must be the given class (in this case, positive or nega- tive), only the antecedent needs to be constructed; this is achieved by starting with an empty antecedent and iteratively adding an attribute-value pair for all attribute values.

Algorithm 4 Procedure to learn rules
1: procedure Learn-rules(examples)
2:	canditate rules → get-candidates() 3:	while i =1 ≤| candidate rules | do 4:		rule → evaluate(rj )
5:
6:	if rule /= null then
7:	In this case, the performance of the rule is compared:
then do not anything
then apply the rule


8:	else
9:		A new rule [Ri : P → Q(fr)[An]] is added in ARk. 10:	end if
11:	end while
12:	return learned rules 13: end procedure
An evaluation function is used to rate candidate rules, called



evaluate(rj).

Each candidate rule rj is defined as rj = P → Q (fr), where fr is the calculated

frequency. This breadth-first search continues until the resulting rule is specific enough. The resulting classifier can contain three types of rules: (a) rules with 100% accuracy (higher rank), (b) rules with good accuracy (lower rank), i.e. < 100% and
> 50%, and (c) rules with poor accuracy (mean rank), i.e. <= 50%. When searching for an applicable rule, the algorithm goes over the rules in a topdown fashion starting with the primary rules (higher rank) until reaching rules with a poor rank. Whenever two or more rules have identical performance then the algorithm favors rules with the least number of terms in their P.

An illustrative example
This section presents a didactic example in order to illustrate the rule learning process through our adaptive algorithm. We have selected a well-known dataset proposed by [18], named Weather dataset 5 , described in Table 1. In general, the approach assumes that:
the algorithm obtains a dataset containing training examples as input (e.g, the ones described in Table 1),
the dataset consists of nominal attributes (e.g, the ones described in Table 2),
the attributes hold a predefined order (e.g, the ones described in Table 3), and
each instance is mapped to exactly one element from the set of positive and negative class labels.
Given requirement #4, we begin by considering classification problems using only two classes of interest.
In this case, the learner starts with a simple rule representation in which each P consists of a conjunction of constraints on the instance attributes. In particular, let each condition P be a vector of four constraints, referring to the values of attributes outlook, temperature, humidity and wind. For each attribute, the rule will either:
indicate with the wildcard symbol ? that any value is acceptable for this at- tribute, or
specify a single required value (e.g., sunny ) for the attribute.
First step through the loop
The frequency is calculated for each attribute value (outlook ). Then the relative frequency is computed for all candidate rules in the form P → Q (w).
According to Table 4, we can get a frequency table for outlook values. Based on the frequency tables, the relative frequency for each candidate rule can be calculated, as seen in Table 5. Each candidate rule is evaluated according to the current rule set in ARk. The achievement of this step is shown in Table 6.
This completes the first pass through the inner loop in the sequential covering algorithm. Since there is still one uncovered remaining instance, another step is

5  http://storm.cis.fordham.edu/ gweiss/data-mining/weka-data/weather.arff


Table 1 Weather dataset.


Table 2
Dataset attributes and their corresponding values.


performed in order to generate additional rules. After the first step the rule set AR5
is as seen in Table 7.
When the five candidate rules are chosen, rule R5 has the maximum relative frequency, i.e. w = 1. Since the maximum value is reached, the learning process for this rule is complete. So there is no need for adaptive functions to improve the rule performance. Also, all four instances with the attribute-value pair outlook = overcast are deleted from the training set.













Ordered attributes using information gain.











Frequency for attribute outlook.

Input	Relative frequency

r1 : (Sunny, ?, ?, ?) → Yes	fr = 0.4
r2 : (Sunny, ?, ?, ?) → No	fr = 0.6
r3 : (Rain, ?, ?, ?) → Yes	fr = 0.6
r4 : (Rain, ?, ?, ?) → No	fr = 0.4
r5 : (Overcast, ?, ?, ?) → Yes	fr = 1.0

Table 5
Candidate rules for attribute outlook.

Second step through the loop
The frequency is calculated for each attribute value (humidity). Then the relative frequency is computed for all candidate rules.
According to Table 8, we can obtain a frequency table for humidity values. Based on the frequency tables, the relative frequency for each candidate rule can be calcu- lated, as seen in Table 9. Each candidate rule is evaluated according to the current rule set ARk. The brief of such step is presented in Table 10.
After the second step, the rule set AR10 is as described in Table 11.
Similarly to the previous step, rules R1 and R2 have the maximum relative frequency, so the learning process for these rules is complete. All instances not covered by them are deleted from the training set. Observe that R4 and R6 are














our rule set, step 1.

























Table 8
Frequency for attributes outlook/humidity.

currently conflicting rules.
Third step through the loop.
The frequency is calculated for each attribute value (wind ). Then the relative fre- quency is computed for all candidate rules.
In accordance with Table 12, we can obtain a frequency table for humidity values. Based on the frequency tables, the relative frequency for each candidate rule can be calculated, as seen in Table 13. Each candidate rule is evaluated according to the current rule set ARk. This step is displayed in Table 14.
The resulting rule set AR13 is presented in Table 15. As all rules reached w = 1.0,



Input	Relative frequency

r1 : (Sunny, ?,High, ?) → No	fr = 1.0
r2 : (Sunny, ?,Normal, ?) → Yes	fr = 1.0
r3 : (Rain, ?,High, ?) → Yes	fr = 0.7
r4 : (Rain, ?,High, ?) → No	fr = 0.3
r5 : (Rain, ?,Normal, ?) → No	fr = 0.5
r6 : (Rain, ?,Normal, ?) → Yes	fr = 0.5

Table 9
Candidate rules for attribute humidity.


Table 10 Constructing our rule set, step 2.


Table 11
Rule set AR10 after step 2.


Table 12
Frequency for attributes outlook/humidity/wind.

Input	Relative frequency

r1 : (Rain, ?,High, False) → Yes	fr = 1.0
r2 : (Rain, ?, High, True) → No	fr = 1.0
r3 : (Rain, ?, Normal, False) → Yes	fr = 1.0
r4 : (Rain, ?,Normal,True) → No	fr = 1.0

Table 13
Candidate rules for attribute wind.

rj	evaluate(rj)	Action	Update ARk

r1   rule → R3	apply [A3] and R3 → r1   AR10 → AR11 r2   rule → null	add R7 → r2	AR11 → AR12 r3   rule → R6	apply [A6] and R6 → r3   AR12 → AR13 r4    rule → R4	apply [A4] and R4 → r4   AR13 → AR14

Table 14 Constructing our rule set, step 3.

that means that all samples from the training set (Table 1) are covered, and thus there is no need for another iteration.
The algorithm mainly focus on maximizing the rule accuracy, even when the discovered rules covers one sample from the training data. Further studies are needed regarding potential data overfit on large rule sets.

Final remarks
This paper presented an approach towards the definition of an adaptive learning algorithm for rule inference. Our approach is based on modifications of conventional sequential covering strategies in order to adapt acquired knowledge during the learn- ing process. Studies indicate that adaptive techniques confer a more adequate rule


Table 15 Set Rules AR13


set fitting. Additional advantages are noteworthy:
simplicity of rule generation, in which only a single performance measure is com- puted in order to decide the rule significance,
comprehensible rule set for decision making, specially for domains that require immediate interpretation, such as medical applications, and
compact and efficient model representation, such that the rule set growth or re- duction is dictated by calls to adaptive functions during construction time.
As a means to improve our proposal, as well as the current adaptive algorithm, we compiled a list of features and enhancements, as follows, to be contemplated in a near future:
Search space reduction for candidate rules. When considering large dimensional datasets, the numbers of candidate rules might significantly increase, and thus impose operational limits to certain applications. A potentially heuristic-based mechanism to reduce the search space might allow better handling of huge datasets.
Numerical attribute handling and support for noisy datasets. A dataset is said to be noisy when it contains incomplete attributes and missing values. An ap- proach to handle and potentially predict completeness of partial information might provide better model convergence. Additionally, the algorithm must offer a dis- cretization strategy for covering attributes in a continuous domain.
Resolution policy for conflicting rules. The algorithm must provide a policy for resolving conflicts in the rule set being constructed, e.g, by adopting class labels with the largest linked frequency as decision criterion.
Tiebreaker mechanism. The algorithm must provide a mechanism to decide whether a rule should be replaced by another, when both have the same fre- quencies.

Pruning support. As a means to avoid a rapid growth of nonessential candidate rules (leading to an inevitable combinatorial explosion), the algorithm must sup- port pruning methods in order to keep the rule set cardinality at an acceptable number.
We are working on comparative experiments with other sequential coverage al- gorithms, in order to verify the model accuracy. Prospectively, we aim at studying the algorithm adaptability when new examples are available, as well as certain cases in which missing values must be considered. However, preliminary results indicate a significant improvement in accuracy, as well as a more comprehensible rule set. Adaptivity poses as an interesting phenomenon to be explored in rule learning, as the rule set construction process potentially accommodates new contexts over time.

References
Alpaydin, E., “Introduction to Machine Learning,” Adaptive Computation and Machine Learning, MIT Press, 2014.
Berka, P. and J. Rauch, Machine learning and association rules, in: Proceedings of the 19th International Conference on Computational Statistics, 2010.
Bishop, C. M., “Pattern recognition and machine learning,” Springer, 2006, 1 edition.
Cendrowska, J., PRISM: An algorithm for inducing modular rules, International Journal of Man- Machine Studies 27 (1987), pp. 349–370.
Clark, P. and T. Niblett, The cn2 induction algorithm, Machine Learning 3 (1989), pp. 261–283.
Costa, E. R., A. R. Hirakawa and J. J. Neto, An adaptive alternative for syntactic pattern recognition, in: Proceeding of 3rd International Symposium on Robotics and Automation, ISRA 2002, 2002, pp. 409–413.
Doy, B. T. M., D. F. Souza and R. G. Jankauskas, Aocr: adaptive optical character recognition, in:
Quarto Workshop de Tecnologia Adaptativa – WTA 2010, 2010, pp. 50–54.
Elgibreen, H. A. and M. S. Aksoy, Rules-TL: a simple and improved rules algorithm for incomplete and large data, Journal of Theoretical and Applied Information Technology 47 (2013), pp. 28–40.
Fürnkranz, J., Separate-and-conquer rule learning, Artificial Intelligence Review 13 (1999), pp. 3–54.
Ganzeli, H. S., J. G. Bottesini, L. O. Paz and M. F. S. Ribeiro, Skan: Skin scanner, software para o reconhecimento de câncer de pele utilizando técnicas adaptativas, in: Quarto Workshop de Tecnologia Adaptativa – WTA 2010, 2010, pp. 22–28.
Hirakawa, A. R., A. M. Saraiva and C. E. Cugnasca, Autômatos adaptativos aplicados em automação e robótica, IEEE Latin America 5 (2007), pp. 539–543.
Michalski, R. S., On the quasi-minimal solution of the general covering problem, in: Proceedings of the 5th International Symposium on Information Processing, Bled, Yugoslavia, 1969, pp. 125—-128.
Mitchell, T., “Machine learning,” McGraw-Hill Science, 1997, 1 edition.
Neto, J. J., Solving complex problems with adaptive automata, in: S. Yu and A. Paun, editors, Implementation and Application of Automata 5th International Conference, Lecture Notes in Computer Science 2088, 2000.
Neto, J. J., Adaptive rule-driven devices: General formulation and case study, in: B. Watson and
D. Wood, editors, Implementation and Application of Automata 6th International Conference, Lecture Notes in Computer Science 2494, 2001, pp. 234–250.
Pistori, H. and J. J. Neto, Adaptree: Proposta de um algoritmo para indução de Árvores de decisão baseado em técnicas adaptativas, in: Anais da Conferência Latino Americana de Informática – CLEI 2002, 2002.
Pistori, H. and J. J. Neto, An experiment on handshape sign recognition using adaptive technology: Preliminary results, in: XVII Brazilian Symposium on Artiﬁcial Intelligence – SBIA 04, 2004.

Quinlan, J. R., Induction of decision trees, Machine Learning 1 (1986), pp. 81–106.
Stahl, F. and M. Bramer, Random prism: An alternative to random forests, in: Research and Development in Intelligent Systems XXVIII, Springer London, 2011 pp. 5–18.
Stange, R. L. and J. J. Neto, Applying adaptive technology in machine learning, IEEE Latin America
12 (2014), pp. 1298–1306.
Stange, R. L. and J. J. Neto, Learning decision rules using adaptive technologies: a hybrid approach based on sequential covering, Procedia Computer Science 109 (2017), pp. 1188–1193.
Thabtah, F., I. Qabajeh and F. Chiclana, Constrained dynamic rule induction learning, Expert Systems with Applications 63 (2016), pp. 74–85.
Witten, I. H., E. Frank and M. A. Hall, “Data Mining: Practical Machine Learning Tools and Techniques,” Morgan Kaufmann, 2011.
