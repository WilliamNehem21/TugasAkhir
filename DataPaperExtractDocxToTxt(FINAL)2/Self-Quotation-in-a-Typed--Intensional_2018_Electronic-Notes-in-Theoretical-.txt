Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 336 (2018) 207–222
www.elsevier.com/locate/entcs

Self-Quotation in a Typed, Intensional Lambda-Calculus
Barry Jay
Centre for Artificial Intelligence School of Software
University of Technology Sydney Sydney
Australia

Abstract
Intensional lambda-calculus adds intensional combinators to lambda-calculus to facilitate analysis. In par- ticular, they are used to factorise data structures and programs into their components, which can be used to convert abstractions into combinators. This paper shows how to type an intensional lambda-calculus using no more than the types of System F. Even the quotation function used to access program syntax can be defined and typed, as can its inverse: the calculus supports typed self-quotation. Thus, one may freely alternate between program analysis and program execution. Proofs of all results have been verified in Coq.
Keywords: lambda-calculus, combinators, self-interpretation, type theory

Introduction
The default implementation of a programming language is written in another, lower level, language in which programs can be analysed. In turn, this may prove to be an intermediate language that, through a sequence of translations, is eventually implemented in, say, machine code. To avoid this chain, it is routine to provide a self-interpreter (see [21,25,2,22,23] and [4,28,18] and [5,6,7]), in which the language is implemented in itself, and so can analyse its own programs. Thus program syntax has two interpretations in the calculus. The standard one yields a reducible term, with all possible evaluation strategies in play. The novel one is quotation which represents a program as a data structure, open to analysis. The simplest form of analysis merely unquotes the program, to recover the standard interpretation. More generally, analysis can be used to optimise, or to impose an evaluation strategy, before converting to an executable. Let us consider some of the desirable properties that quotation should satisfy.

1 Email:Barry.Jay@uts.edu.au

https://doi.org/10.1016/j.entcs.2018.03.024 1571-0661/© 2018 Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

First, there should be no limits on the nature of the analyses that can be done. It is not enough to support a single self-interpreter, or a small suite of analyses. For example, it should be possible to decide syntactic equality of programs, or to perform a dead-code analysis.
Second, opportunities for optimisation are maximized when the language is rep- resented by a confluent calculus, e.g. a λ-calculus [1], so that one is free to manip- ulate the evaluation strategy.
Third, the calculus should be typed. This provides a sanity check on the whole approach. In particular, it is common to model each stage of interpretation by rising one level in a type hierarchy. This is inherently difficult, and often limits the nature of the analyses that are possible. To put it another way, if the analysis is to be done in the source language, all of the usual arguments for typed programming languages also apply here.
Fourth, analysis should be dynamic, and not merely static. For example, in staged computation [27,9] the results from computation in one stage may be analysed in the next. More generally, this is required for dynamic program analysis. Despite its significance, this challenge is generally considered too hard in the context of self- interpretation, because it requires that quotation be definable within the language itself.
From the viewpoint of λ-calculus, it is not even clear that such self-quotation make sense. After all, quotation cannot act on reducible terms, since reduction changes the nature of the syntax produced by quotation. The solution is to identify programs with closed normal forms, whose reduction begins only when they are applied to arguments. Even in this restricted domain, however, the task is beyond pure λ-calculus because it is inherently extensional: there is no pure λ-term that can reveal the internal structure of closed normal λ-abstractions in a uniform manner. The solution is to add intensionality to the λ-calculus in the form of combinators that are able to query the internal structure of terms. The simplest such system is SF -calculus [16], whose factorisation operator F is able to expose the compo- nents of compound terms. Recent work [14] introduces the λSF -calculus, in which abstractions can be factored, just as combinators can. This paper continues this
development, to introduce an intensional λ-calculus that
is confluent
is strongly typed
defines program equality, and
defines self-quotation, and self-interpreters.
Despite this expressive power, the actual machinery is comparatively light- weight. The types are given by those of System F [10], with coercions used to represent type abstraction and instantiation. The terms are given by adding the following operators to the λ-calculus:
O ::= S | K | A | Y  | E | G | DS | DK | DA | DY | DE | DG .
The operators S and K are standard. The operator A is new, with reduction

rule AMNP −→ MNP . That is, A is a ternary identity operator: given three arguments it behaves as the identity. It could be defined in terms of S and K, but plays an important role in controlling evaluation, especially of fixpoints.
The fixpoint operator Y is not standard. Its reduction rule YM −→ M (AY M ) inserts a copy of A to prevent unwanted reductions. We could have added an operator I but instead let us define it as SKK since, for any P and Q we have SKPQ −→ KQ(P Q) −→ Q which shows that SKP is an identity function for any term P . Together, S, K, A and Y are the extensional operators, so called because they do not query the internal structure of their arguments. Their types are easily guessed from their reduction rules. The remaining operators are intensional; typing them is a little more of a challenge.
The operators E tests for equality of operators. Its principal type is
Ty[E]= ∀X.∀Y.∀Z.X → Y → Z → Z → Z
which is equivalent to ∀X.∀Y.X → Y → Bool where Bool is defined to be ∀Z.Z → Z → Z. Note that the operators being compared may have different types, so that, for example, ESK has the same type as its reduct KI.
The operator G is a variant of the factorisation operator from SF -calculus. Its sole reduction rule is
GMP −→ MP|[P  (P is factorable)
where P| and [P are the left and right components of P . If P is, say, SP1P2 then its components are SP1 and P2. The complete account of factorable forms is made more complicated by the need to factor abstractions. The term M in the rule must be sufficiently polymorphic to handle the components of P , no matter what their types prove to be. Hence the principal type of G is
Ty[G]= ∀X.∀Y.(∀Z.(Z → X) → Z → Y ) → X → Y .
Thus, if P : X in the rule above has components P1 : Z and P2 : Z → X then
MP1P2 : Y provided that M : ∀Z.(Z → X) → Z → Y ) → X → Y .
The remaining operators are the case operators corresponding to the basic op- erators we have already met. Each one has a pair of reduction rules. For example, we have
DS MNS −→ M
DS MNP −→ NP  (P /= S is factorable) .
It represents a pattern-matching function that maps S to M and applies N to anything else. Its type is
Ty[DS]= ∀X.Ty[S] → (∀Y.Y → Y ) → X → X
Note the use of the principal type of S in the principal type of DS. It is tempting to replace the family of case operators with a single operator D whose applications yield DS, etc. However, the type of D would require a means of referencing the principal types of the operators that excludes other types. While this is possible, it would require additions to the type system.
Factorisation supports a divide-and-conquer approach to program analysis that

is quite direct. For example, self-quotation can be described informally as a pattern- matching function that maps operators to themselves, and compounds of the form MN to A(quote M )(quote N ). As a term of the calculus, it is given by
quote = AY (λq.λp.Eppp(G(λx.λy.A(qx)(qy))p) .
This is a closed normal form, since the application of A blocks the reduction of the fixpoint operator Y until an argument has been supplied. E is used to check if p is an operator. If not then G is used to factorise p and recurse. Further, it has type
quote : ∀X.X → X . 
All proofs in the paper have been verified using the Coq proof assistant [3].
The structure of the paper is as follows. Section 1 is the introduction. Section 2 introduces the compounds. Section 3 introduces the reduction rules of the calculus. Section 4 introduces the types of the calculus. Section 5 shows how to define and type equality of programs. Section 6 defines quoting and unquoting. Section 7 discusses verification in Coq. Section 8 considers related work. Section 9 draws conclusions.

Factorable Forms
This section develops the machinery necessary to describe the reduction rules given in the next section. At issue is that the reduction rules for the intensional operators have side-conditions requiring that arguments be factorable forms, i.e. either oper- ators or compounds. The latter include some abstractions, whose right components are given by star abstraction. So the order of business will be: star abstraction; components; and then compounds.

Star Abstraction
The syntax of terms was given in Section 1. The star abstraction λ∗x.M of M with respect to x is defined by
λ∗x.x = I
λ∗x.y = Ky  (y /= x)
λ∗x.O = KO (O an operator) λ∗x.λy.M = A(λx.λ∗y.M ) λ∗x.MN = S(λx.M )(λx.N ) .
This definition modifies the traditional definition of λ∗x.M for combinators M (see, e.g. [11]) in two ways. First, when the body is an application MN the result uses λx.N instead of λ∗x.N . To see why this is necessary, consider λ∗x.S(KN1N2). Now S(KN1N2) is not a redex, so it is safe to separate S from KN1N2 but λ∗x.KN1N2 breaks the redex KN1N2. Thusa recursive call to λ∗x would here be unsafe. Second, there needs to bea rule for λ∗x when the body is an abstraction λy.M . The result is A(λx.λ∗y.M ) and not λ∗x.λ∗y.M since keeping track of information requires that only one abstraction is eliminated at a time, namely, the innermost one.

Here are some simple examples of star abstraction. In SKI-calculus, the λ- abstraction λx.λy.y can be represented by
λ∗x.λ∗y.y = λ∗x.I = KI
where λ∗ is used to convert abstractions into combinators in the traditional manner. In λSF -calculus, λx.λy.y is already a closed normal form. However, its factorisation will introduce λ∗x.λy.y which is calculated as follows:
λ∗x.λy.y = A(λx.λ∗y.y)= A(λx.I) .
This has eliminated the innermost abstraction, just like the first step in the calcu- lation of λ∗x.λ∗y.y in SKI-calculus. A second factorisation exposes
λ∗x.SKK = S(λx.SK)(λx.K) .
Further factorisation eliminates the remaining abstractions to produce the combi- nator
S(S(KS)(KK))(KK)
which when applied to terms M and N reduces to N , just like the original abstrac- tion. Of course, this does not take advantage of the standard optimisation, in which λ∗x.I takes advantage of the fact that x is not free in I to produce KI. Optimizing this has been addressed in λSF -calculus [14].
Components
For convenience, the definitions of components are given for arbitrary terms, whether they prove to be compounds or not.
The left component M| and right component [M of a term M are defined as follows

(λx.M )| = abs left
(MN )| = M
M| = KM  (otherwise)
[(MN ) = N
[(λx.M ) = λ∗x.M
[M = M  (otherwise.)

where abs left = I is used as the left component of an abstraction. The key point about abs left is that if it is the left component of an application IN then the application is a redex, and so will not prove to be a compound. In general, words in sans-serif, such as abs left may be used to name particular terms of the calculus, as well as the meta-variables M and N , etc. Perhaps surprisingly, the components of an operator O are defined to be KO and O. It will follow that GMO reduces to M (KO)O. If, as is usual, this is not desirable, then operators must be excluded by first using E to identify them, as in the example of quote introduced earlier.
Compounds
In combinatory calculi, the compounds are exactly the partially applied operators. For example, in SF -calculus, the compounds are all terms of the form SM or SMN or FM or FMN . These forms are compounds in λSF -calculus, too, as are all the other partially applied operators, such as those of the form KM and EM and DSM N . All other compounds will be abstractions λx.M whose decomposition is

Inductive status_val :=
| Reducible : status_val
| Lam : nat -> status_val	(* the active variable *)
| Active : nat -> status_val  (* the active variable *)
| Ternary_op (* S, A *)
| Binary_op0 (* K, 0 eager arguments *)
| Binary_op2 (* E, 2 eager arguments *)
| Binary_op1 (* G, 1 eager argument  *)
| Ternary_op1 (* DO *)
| Unary_op (* Y *)
| Lazy2 (* need two args *)
| Lazy1 (* need one arg *)
| Eager2 (* DOM *)
| Eager (* EO *)
.

Fig. 1. Status Values in Coq






safe because either M is already factorable, or outermost reduction in M awaits the instantiation of x.
In turn, this requires keeping track of which variables require values in order for head reduction to proceed, i.e. which variables are active in a term. More generally, every term has a status which keeps track of all the information needed to determine if a term is factorable or not. This is complicated by the interplay between free variables and the intensional operators, as the latter are eager in the arguments that they query. To avoid transcription errors and other issues, it seems safest to give the definitions exactly as it appears in the Coq implementation. The status values are given in Figure 1. Reducible indicates that there is a head reduction. Lam n denotes a λ-abstraction whose active variable has de Bruijn index n. Active n denotes a term whose active variable is n but is not an abstraction. Rather it, it is either the nth variable, or an application. The other status values are used to characterise the factorable forms in what should be a self-explanatory manner.
The definition of the status of terms is given in Figure 2. To save space, the program has been broken into three columns, to be read successively. For example, the second column begins with a case for App M1 M2 in the pattern-matching against M begun in the first column.
The status of an operator is one of Ternary op, Binary op0, Binary op2, Binary op1 or Ternary op1. Now a term is a compound if its status is one of Lazy2, Lazy1, Eager2 or Eager. It is factorable if it is a compound or an operator.
Although this is all hard to take in, it is worth noting that all closed, head normal forms of the pure λ-calculus are compounds. Here are some examples of compounds. The body of λx.xy has x active. The body of λx.λy.x has x active. The body of λx.λy.y is a compound. The body of λx.G is factorable. The body of λx.Gx is factorable. The body of λx.GMx has x active, since G is an intensional operator that needs to know the value of x to reduce. The body of λx.λy.GM (GNx) has x active. Exy has x active. EOy has y active. The status of E(SK)y is Reducible. It follows that if M is factorable and M −→ N then M| −→ N| and [M −→ [N . That is, no redexes are broken by taking components of factorable forms. To put



Fixpoint status (M: lamSF) := match M with
| Ref i => Active i
| Op Sop => Ternary op
| Op Aop => Ternary op
| Op Kop => Binary op0
| Op Eop => Binary op2
| Op Gop => Binary op1
| Op Uop => Binary op1
| Op Yop => Unary op
| Op	=> Ternary op1
| Abs M1 =>
match status M1 with
| Reducible => Reducible
| Lam 0 => Lazy1
| Lam (S n) => Lam n
| Active 0 => Lazy1
| Active (S n) => Lam n
|	=> Lazy1 end




| App M1 M2 =>
match status M1 with
| Reducible => Reducible
| Lam	=> Reducible
| Active n => Active n
| Ternary op => Lazy2
| Binary op0 => Lazy1
| Binary op2 =>
match status M2 with
| Reducible => Reducible
| Lam n => Active n
| Active n => Active n
| Ternary op
| Binary op0
| Binary op2
| Binary op1
| Ternary op1
| Unary op => Eager
|	=> Reducible end






| Binary op1 => Eager
| Ternary op1 => Eager2
| Unary op => Reducible
| Lazy2 => Lazy1
| Lazy1 => Reducible
| Eager2 => Eager
| Eager =>
match status M2 with
| Lam n => Active n
| Active n => Active n
|	=> Reducible end
end end


Fig. 2.  Term status in Coq


(λx.M )N −→ {N/x}M SMNP −→ MP (NP ) KMN −→ M
AMNP −→ MNP 
Y M −→ M (AY M )
EOO −→ K
EOP −→ KI	(P /= O is factorable)
EP −→ K(KI)  (P is a compound)
GMP −→ MP|[P (P is factorable)
DOM NO −→ M
DOM NP −→ NP	(P /= O is factorable)


Fig. 3. Reduction Rules

is another way, there is a derived reduction rule


(ξ)
M −→ N
λ∗x.M −→ λ∗x.N
(λx.M is factorable.)

More important from a formal point of view is that the side-conditions on the reduction rules be decidable. Here, the side-conditions will depend upon equality of operators with factorable forms, and on being a factorable form. The latter is given by a function in Coq, and so is guaranteed to terminate.

Reduction
The reduction rules of intensional λ-calculus are given in Figure 3. The correspond- ing congruence is also denoted by −→, whose reflexive, transitive closure is −→∗.

Basic Results
Theorem 3.1 (confluence lamSF red) Reduction in λSF-calculus is confluent.
The normal forms are defined to be the variables, operators, abstractions of normal forms, and applications MN in which M and N are both normal and the status of MN is not Reducible.
Theorem 3.2 ( irreducible iff normal) A term is irreducible if and only if it is a normal form.
A program is a closed normal form. If the goal is to analyse an open normal form, then it will be necessary to first bind all of its free variables.
Theorem 3.3 (programs are factorable) All programs are factorable forms.
Hence, any closed term of the form GMP must reduce. This is a form of progress result.

Unstar
As an example of the machinery in use, let us show how to reverse star abstraction, how to convert λ∗x.M to λx.M . The pattern-matching account is given by
let rec unstar x =
match x with
| O ⇒ O
| Ax ⇒ abs A unstar x
| Kx ⇒ abs K x
| Sxy ⇒ abs S x y 
where abs S = λg.λf.λx.gx(fx) and abs K = λx.λy.x and abs A = λu.λx.λy.u(x y). For example, the case | Kx ⇒ abs K x updates the operator K with the term abs K that has the same type. Similarly, S is updated by abs S and A by abs A. The corresponding term of the calculus is
unstar = AY (λu.G(DA (abs A u)(DK abs K (G(DS abs S I)))))
Theorem 3.4 (unstar star) The term unstar (λ∗x.M ) reduces to λx.M.

Extensionality
Mathematically, two functions f and g are extensionally equivalent if they have the same graph. For unary functions, this means that f x = g x for all x. In λ-calculi, extensionality is captured by adding the η-reduction rule
λx.f x −→ f  if x is not free in f .
When added to the basic λ-calculus, with just the β-rule, we get the λβη-calculus, which is confluent. Define =βη to be the equivalence relation on λ-calculus induced by β-reduction and η-reduction. Note, however, that adding the η-rule to λSF - calculus is unsound, as it changes the status of terms.

A more useful relation is obtained by excluding the rules for the intensional operators (in the second column of Figure 3), to get the equivalence relation ≡e. Define terms M and N to be extensionally equivalent if M ≡e N . For example, we have the following theorem.
Theorem 3.5 (star equiv abs) λ∗x.M ≡e λx.M for all terms M.
Typing
There are three key challenges to typing an intensional λ-calculus:
Type the factorisation operator, in this case G.
Factorise type abstractions and applications.
Type the equality operator E and the case operators.
In addressing these challenges we aim to keep the type system as simple as possible. First consider GMP of type T where P : U is factorable. There must be a type Z such that [P : Z and so P| : Z → U . Hence, M must have type (Z → U ) → Z → T .
Further, there is no way to determine the type Z in advance. Hence, M must be polymorphic, of quantified type ∀Z.(Z → U ) → Z → T so that
G : (∀Z.(Z → U ) → Z → T ) → U → T . 
More generally, we have
G : ∀X.∀Y.(∀Z.(Z → X) → Z → Y ) → X → Y.
The inherent need for polymorphism, and the quantification of type variables within a function type, means that neither simple types nor those of the Hindley-Milner system are expressive enough: the type system must be at least as expressive as System F. Indeed, this is enough.
Second, there is the challenge of representing type generalization and instanti- ation. In the original System F [10], these changes to the types are made explicit in the terms. For example, if t : T then ΛX.t : ∀X.T and then (ΛX.t)U : {U/X}T . However, if such operations are made explicit, then it is not clear how to factorise a type application of the form tU . In particular, if it is deemed to have components t and U then the type U must also be a term in its own right. This is an intriguing possibility, but would take us far beyond the simplicity of System F. Instead, let us make the type-level operations implicit, so that type coercions can modify the type of a term without change to the term itself. The basic machinery for doing this is already well known, but requires some small modifications for our purposes.
For example, consider a compound PQ : T where Q has type U and P has type U → T . Further, suppose the type is generalized to be PQ : ∀X.T . Now, we have Q : ∀X.U and so factorisation requires that P : (∀X.U ) → (∀X.T ). The solution is to perform the following coercions:
▶ P : U → T

▶ P : (∀X.U ) → T
(contravariance)

(generalization)

▶ P : ∀X.(∀X.U ) → T
▶ P : (∀X.U ) → (∀X.T )
(push).



Fig. 4. Type instantiation (≺) and pushing (≺≺)



Γ ▶ x : U

(x : U ∈ Γ)

Γ ▶ O : Ty[O]
Γ ▶ t : U → T  Γ ▶ u : U
Γ ▶ t u : T
Γ,x : U ▶ t : T


Γ ▶ λx.t : U → T

Γ ▶ t : T
Γ ▶ t : T ∗
T ≺ T ∗	Γ ▶ t : T
Γ ▶ t : T ∗
T ≺≺ T ∗	Γ ▶ t : T
Γ ▶ t : ∀X.T

(X /∈ Γ)

Fig. 5. Type Derivation
Ty[S]= ∀X.∀Y.∀Z.(X → Y → Z) → (X → Y ) → (X → Z)
Ty[K]= ∀X.∀Y.X → Y → X
Ty[A]= ∀X.∀Y.(X → Y ) → X → Y
Ty[Y ]= ∀X.(X → X) → X
Ty[E]= ∀X.∀Y.∀Z.X → Y → Z → Z → Z
Ty[G]= ∀X.∀Y.(∀Z.(Z → X) → Z → Y ) → X → Y
Ty[DO]	∀X.Ty[O] → (∀Y.Y → Y ) → X → X . 

Fig. 6. Operator Types
The first uses contravariance of function types and type variable instantiation. The second generalizes the type variable X. The third step is not quite standard, as it involves pushing a quantifier across a function type, using the rule,
∀X.(U → T ) ≺≺ U → ∀X.T	(X /∈ U )
where X is not free in U . The details of the rules for instantiation T ≺ T j a type T to a type T j, and for pushing T ≺≺ T j a type T to a type T j are given in Figure 4. Typing judgments are of the form Γ ▶ t : T where Γ is a context, and t is a term and T is a type. In turn, a context Γ is a collection of distinct term variables with types xi : Ui. The type derivation rules are given in Figure 5. All contexts therein are assumed to be well-formed. There is one derivation rule for each term form, plus three rules for implicitly manipulating types, by instantiation, pushing, or by generalizing from a type T to its quantification ∀X.T . All that remains is to type
the operators. Each operator O has a designated type Ty[O] as given in Figure 6.
The expressive power of type derivation is illustrated by the following theorems.
Theorem 4.1 (unstar type) unstar : ∀X.X → X.
Theorem 4.2 (reduction preserves derivation) If Γ ▶ t : T and t −→ tj then
Γ ▶ tj : T .
Proof. Consider (λx.t)u −→ {u/x}t. This preserves typing since substitution pre- serves typing. The rule for F applied to an abstraction preserves typing since star abstraction does. The other cases are routine.	2

Equality
The expressive power the overall approach is illustrated by a couple of key examples. This section presents an example of a query, namely equality. The next section considers some updates, namely quote and unquote.
It follows from Theorem 3.3 that equality can be decided by comparing opera- tors and compounds. The algorithm is as follows. Atomic equality is decided by E. Operators and compounds are never equal. Compounds are equal if their compo- nents are. Informally, equality is given by the following, nested pattern-matching function:
let rec equal x y =
match x with
| O ⇒ EOy
| x1x2 ⇒ match y with
| O ⇒ KI
| y1y2 ⇒ (equal x1 y1) (equal x2 y2) (KI) .
The corresponding term of the calculus is
equal = AY (λe.λx.λy.Exx(Exy)(G(λx1.λx2.Eyy(KI)(G(λy1.λy2.(ex1y1)(ex2y2)(KI))y))x)) .
Theorem 5.1 (equal type) equal has type Ty[E].
Theorem 5.2 (equal programs) equal M M −→∗ K for all programs M.
Theorem 5.3 (unequal programs) equal M N −→∗ KI for all distinct pro- grams M and N.
Proof. The proof is by induction on the rank of M , as defined in the Coq imple- mentation. The only case of interest arises when M is an abstraction and N is an application. Now the left component of N cannot be abs left since any application of abs left reduces, and so the left components of M and N cannot be equal.  2

Quoting and Unquoting
The account of quotation given in Section 1 is a slight simplification, since it does not begin with the meta-function for quotation, here called mquote. As a pattern- matching function mquote is given by
let rec mquote =
| O ⇒ O
| λx.M ⇒ A(mquote abs left)(mquote (λ∗x.M ))
| MN ⇒ A(mquote M )(mquote N ) .
Of course, abs left and λ∗x.M are the components of λx.M so that, from the view- point of factorisation, the second and third cases above can be handled by a single line of code. Consequently, we have the following theorems.
Theorem 6.1 (quote is definable) Quotation of programs is deﬁnable by quote.
Theorem 6.2 (quote type) quote has type ∀X.X → X.

Theorem confluence_lamSF_red Theorem irreducible_iff_normal Theorem programs_are_factorable Theorem unstar_star
Theorem star_equiv_abs Theorem unstar_type
Theorem reduction_preserves_derivation Theorem equal_type
Theorem equal_programs Theorem unequal_programs Theorem quote_is_definable Theorem quote_type
Theorem unquote_type Theorem unquote_quote

Fig. 7. Theorems verified in Coq


The latter theorem implies that no type information has been lost during quo- tation. The type is also very simple. However, using a quotation instead of the source program will not yield a type error. If this is a concern, the solution will be to make the system a little more complicated, e.g. by giving the operator A the type [X → Y ] → [X] → [Y ] where [T ] is a new type form, the expression type of T . This theorem also illustrates that the type ∀X.X → X supports many useful programs, including all database updates, and so is richer than a unit type. Thus, datatypes must be introduced separately to function types, just as is done in prac- tice. For example, given a type of natural numbers, it is routine to define a function
that computes the size of a program, or its G¨odel number.
The informal account of unquote is equally straightforward, being given by the pattern-matching function
let rec unquote =
| O ⇒ O
| A(quote abs left)N ⇒ unstar(unquote N )
| AMN ⇒ (unquote M )(unquote N ) .
There are two points of interest when unquoting a term of the form AMN . First, the generic equality (and, ultimately, E) is used to decide if unquote M is abs left. Second, DA is used to replace the application of A with an application of I.

Theorem 6.3 (unquote type) unquote has type ∀X.X → X.

Theorem 6.4 (unquote quote) For all programs M, unquote (quote M ) reduces to M.


Verification in Coq
All proofs in the paper have been verified using the Coq proof assistant [3], as sup- plied in the supplementary materials [15]. For ease of reference, the same theorem names are used in both places.

Related Work
Self-Interpretation
First, note that till now, no self-interpreter of any kind has supported self-quotation. The closest prior work concerns self-interpretation for typed, confluent calculi. Jay and Palsberg [18] created self-interpreters for a typed combinatory calculus based on SF -calculus. The lack of first-class λ-abstractions was its primary limitation, here overcome. Also, its approach to typing equality was more general than here, but at the cost of introducing some obscurity to the type system. By introducing case operators to handle updates, the system has been simplified without losing any of the motivating examples. The most recent work on typed self-interpretation is by Brown and Palsberg [5,6,7]. They construct typed self-interpreters for System Fω. This is a good example of the use of a type hierarchy in which the quotation of programs at one level at typed at the next level. By contrast, the system here has a flat type hierarchy.
Partial Evaluation
The identification of programs with closed normal forms suggests new approaches to partial evaluation of λ-calculi, both static and dynamic [20]. A running theme in the partial evaluation of typed languages is to eliminate the overheads associated with type tags [24] in the quest for Jones optimality [29,8]. The analogue of tags in our setting are the uses of A and abs left in the definition of quote. There is a minimal sense in which these carry type information, the same sense in which a λ does, but overall, the types barely figure in the representation. Perhaps the interpretation overhead can be completely eliminated by applying unquote so that, in this sense, Jones optimality will follow from this more general principle.
Staged Evaluation
Staged evaluation [27,9] allows each stage of program execution to analyse the syn- tax of subsequent stages. Since programs can now be identified with data structures, the divisions between stages are no longer fundamental, as one may quote and un- quote at leisure.
Higher-Order Abstract Syntax
Intensionality and quotation play a role in higher-order abstract syntax (see, e.g. [26]) but the relationship to intensional λ-calculus has yet to be explored.
Program Analysis
The above examples illustrate how analyses built from queries and updates can be performed upon closed normal forms, without the need for any meta-level operations such as quotation, and this in a language whose type system is completely standard. The question, then, is whether it is legitimate to identify the programs with the

closed normal forms. To completely resolve the issue will require the development of an actual programming language, as opposed to a calculus. Nevertheless, the evidence to hand is suggestive.
First consider the restriction to closed terms. This restriction will not be very controversial, but if open terms are of interest they can be handled by analyzing the closed terms obtained by abstracting with respect to the free variables. This reduces to the problem discussed above.
Now consider the restriction to normal forms, or strongly normalizing terms. It is instructive to compare with the extension of System F obtained by adding a fixpoint operator. In the standard account, any term containing an application of the fixpoint operator will have infinite reduction sequences. However, in System F extended with our A and Y we can define recursive functions that do not have infinite reduction sequences until applied to arguments. Indeed, by adding suitable intensional operators, it should be possible to support a generous class of queries and updates within a strongly normalising calculus, similar to the query calculus [13]. In this manner, a self-enactor may be a program, and so may be self-applied.
Foundations of Computing
This work continues the development of confluent calculi that are more expressive than λ-calculus, including pattern calculus [12,17,13], the combinatory calculus SF - calculus [16,18] and the untyped λSF -calculus [14]. The various pattern calculi support queries that are uniformly applied to arbitrary data structures, but not to λ-abstractions. The SF -calculus supports queries that are uniformly applied to arbitrary closed normal forms. The λSF -calculus extends this approach to a λ- calculus. It most clearly exposes the limitations of pure λ-calculus, its inability to support intensional computations as well as extensional ones. Since this conflicts with the traditional account of the nature of computation, we have been especially careful, by verifying the results in Coq [3], and pinpointing the source of the tradi- tional error, within conflicting accounts of λ-definability [19].
Conclusions
The great strength and weakness of λ-calculus is that is extensional. Hiding the body of a λ-abstraction supports the separation of concerns, supports modular program development, and allows for the representation of data structures as higher- order polymorphic functions in, say, System F. However, intensionality is central to program analysis: we must be able to look under the λ to analyse a program. All of the difficulties of self-interpretation in λ-calculus, especially as manifested in typed calculi, spring from this source.
It follows that the solution is to add intensionality from the beginning, starting with a factorisation operator, say G, so that programs can be analysed through a general divide-and-conquer approach. Typing introduces a delicate challenge: how to exploit type information obtained during analysis. Following the database approach, we restrict our attention to two sorts of analysis, queries and updates.

Queries are easily typed using the operator E, while updates are typed by using the case operator DO associated to each basic operator O. This approach has been illustrated by accounting for program equality (a query), and for the updates that quote and unquote programs.
All the theorems have been verified in Coq [15].
In this manner, all program analyses based on queries and updates can be typed, and this using no more than the types of System F. The ability to define quotation as a term, to support self-quotation, means that program analysis can be performed dynamically, without further ado.
Acknowledgment
Thanks to the anonymous referees for their helpful suggestions.

References
H. Barendregt. The Lambda Calculus: Its Syntax and Semantics. North Holland, 1984. revised edition.
H. Barendregt. Self-interpretations in lambda calculus. J. Functional Programming, 1(2):229–233, 1991.
B. Barras, S. Boutin, C. Cornes, J. Courant, J.-C. Filliˆatre, E. Gim´enez, H. Herbelin, G. Huet, C. Mun˜oz,
C. Murthy, C. Parent, C. Paulin-Mohring, A. Sa¨ıbi, and B. Werner. The Coq Proof Assistant Reference Manual : Version 6.1. Research Report RT-0203, INRIA, May 1997. URL https://hal.inria.fr/ inria-00069968. Projet COQ.
A. Berarducci and C. B¨ohm. A self-interpreter of lambda calculus having a normal form, pages 85–99. Springer Berlin Heidelberg, Berlin, Heidelberg, 1993. ISBN 978-3-540-47890-4.
M. Brown and J. Palsberg. Self-representation in girard’s system u. In Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL ’15, pages 471–484, New York, NY, USA, 2015. ACM. ISBN 978-1-4503-3300-9.
M. Brown and J. Palsberg. Breaking through the normalization barrier: A self-interpreter for f-omega. In Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL ’16, pages 5–17, New York, NY, USA, 2016. ACM. ISBN 978-1-4503-3549-2.
M. Brown and J. Palsberg. Typed self-evaluation via intensional type functions. In Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages, pages 415–428. ACM, 2017.
O. Danvy and P. E. Mart´ınez Lo´pez. Tagging, Encoding, and Jones Optimality, pages 335–347. Springer Berlin Heidelberg, Berlin, Heidelberg, 2003.
R. Davies and F. Pfenning. A modal analysis of staged computation. J. ACM, 48(3):555–604, May 2001. ISSN 0004-5411.
J.-Y. Girard, Y. Lafont, and P. Taylor. Proofs and Types. Tracts in Theoretical Computer Science. Cambridge University Press, 1989.
R. Hindley and J. Seldin. Introduction to Combinators and Lambda-calculus. Cambridge University Press, 1986.
B. Jay. The pattern calculus. ACM Transactions on Programming Languages and Systems (TOPLAS), 26(6):911–937, November 2004.
B. Jay. Pattern Calculus: Computing with Functions and Structures. Springer, 2009.
B. Jay. Programs as data structures in λSF-calculus. Electronic Notes in Theoretical Computer Science, 325:221 – 236, 2016a. ISSN 1571-0661. The Thirty-second Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXII).
B. Jay. Typed LambdaFactor Calculus repository of proofs in Coq, January 2017. https://github. com/Barry-Jay/typed-lambdaFactor.

B. Jay and T. Given-Wilson. A combinatory account of internal structure. Journal of Symbolic Logic, 76(3):807–826, 2011.
B. Jay and D. Kesner. First-class patterns. Journal of Functional Programming, 19(2):191–225, 2009.
B. Jay and J. Palsberg. Typed self-interpretation by pattern matching. In Proceedings of the 2011 ACM Sigplan International Conference on Functional Programming, pages 247–58, 2011.
B. Jay and J. Vergara. Conflicting accounts of λ-definability. Journal of Logical and Algebraic Methods in Programming, 87:1 – 3, 2017. ISSN 2352-2208.
N. Jones, C. Gomard, and P. Sestoft. Partial Evaluation and Automatic Program Generation. International Series in Computer Science. Prentice Hall International, 1993.
S. C. Kleene. λ -definability and recursiveness. Duke Math. J., 2(2):340–353, 06 1936.
T. Æ. Mogensen. Efficient self-interpretations in lambda calculus. Journal of Functional Programming, 2(3):345–363, 1992. See also DIKU Report D–128, Sep 2, 1994.
T. Æ. Mogensen. Linear-time self-interpretation of the pure lambda calculus. Higher-Order and Symbolic Computation, 13(3):217–237, 2000. ISSN 1573-0557.
E. Paˇsali, W. Taha, and T. Sheard. Tagless staged interpreters for typed languages. In Proceedings of the Seventh ACM SIGPLAN International Conference on Functional Programming, ICFP ’02, pages 218–229, New York, NY, USA, 2002. ACM. ISBN 1-58113-487-8.
J. C. Reynolds. Definitional interpreters for higher-order programming languages. In Proceedings of 25th ACM National Conference, pages 717–740. ACM Press, 1972. The paper later appeared in Higher-Order and Symbolic Computation.
C. Sch¨rmann, J. Despeyroux, and F. Pfenning. Primitive recursion for higher-order abstract syntax.
Theoretical Computer Science, 266(1):1 – 57, 2001. ISSN 0304-3975.
M. Shields, T. Sheard, and S. Peyton Jones. Dynamic typing as staged type inference. In Proceedings of the 25th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL ’98, pages 289–302, New York, NY, USA, 1998. ACM. ISBN 0-89791-979-3.
F. Song, Y. Xu, and Y. Qian. The self-reduction in lambda calculus. Theoretical Computer Science, 235(1):171 – 181, 2000. ISSN 0304-3975.
W. Taha, H. Makholm, and J. Hughes. Tag Elimination and Jones-Optimality. In Proceedings of the Seventh ACM SIGPLAN International Conference on Functional Programming, ICFP ’02, pages 257–275, Springer Berlin Heidelberg, Berlin, Heidelberg, 2002.
