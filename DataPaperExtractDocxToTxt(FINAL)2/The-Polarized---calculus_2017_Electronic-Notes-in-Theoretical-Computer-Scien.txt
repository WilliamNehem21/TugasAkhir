Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 332 (2017) 149–168
www.elsevier.com/locate/entcs
The Polarized λ-calculus
Jos´e Esp´ırito Santo1
Centro de Matem´atica Universidade do Minho Braga,Portugal

Abstract
A natural deduction system isomorphic to the focused sequent calculus for polarized intuitionistic logic is proposed. The system comes with a language of proof-terms, named polarized λ-calculus, whose reduction rules express simultaneously a normalization procedure and the isomorphic copy of the cut-elimination procedure pertaining to the focused sequent calculus. Noteworthy features of this natural deduction system are: how the polarity of a connective determines the style of its elimination rule; the existence of a proof- search strategy which is equivalent to focusing in the sequent calculus; the highly-disciplined organization of the syntax - even atoms have introduction, elimination and normalization rules. The polarized λ-calculus is a programming formalism close to call-by-push-value, but justified by its proof-theoretical pedigree.
Keywords: polarized logic, focusing, bidirectional natural deduction, general elimination rule, eta-expansion


Introduction
Focusing and polarity are two proof-theoretical ideas that originated in linear logic but were recognized to have ample impact in proof-theory at large. Focusing [1,10,13] is a disciplined strategy for bottom-up proof-search in the sequent calculus that tries to reduce to a minimum the non-determinism inherent in that process. Polarity is the feature of a logical connective when it has a well-determined behavior in focusing proof-search. Polarized versions of intuitionistic and classical logic can be given where the logical operations have such behavior, and where even polarity shifts are explicit [15].
Focusing in polarized logic is a “subsuming paradigm” of proof-search, capturing several focused systems and their search strategies [10,4]. But cut-elimination in polarized logic is also a “subsuming paradigm” of functional computation, capturing the traditional dichotomy call-by-value/call-by-name through the logic qua type

1 Email:jes@math.uminho.pt This research was financed by Portuguese Funds through FCT Fundac¸a˜o para a Ciˆencia e a Tecnologia, within the Project UID/MAT/00013/2013.

http://dx.doi.org/10.1016/j.entcs.2017.04.010
1571-0661/© 2017 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

system [15,2]. It is then quite natural to investigate the connection between the call-by-push-value (CBPV) paradigm [9] and polarized logic.
This paper will get to the point where such investigation is possible, in the intuitionistic setting. This involves several simultaneous tasks. First, we have to be ready to bridge the sequent calculus vs natural deduction divide, as the latter side is where programming notations more naturally live; second, in the spirit of the Curry-Howard correspondence, we have to equip the proof-systems with ap- propriate languages of proof-terms, preferably with a transparent computational interpretation; third, we have to keep track of dualities and symmetries so deeply explored by focusing, in an intuitionistic setting where they are concealed, more so in a natural deduction notation. Moreover, we need the correct methodology: we do not need to adhere to the dogma that every useful programming formalism can be reduced to proof-theory; rather, we will let proof-theory do its job, which is to produce standard systems, and after that judge the distance between such systems and those we would like to capture.
In this paper, starting from one of those standard objects, the focused se- quent calculus for polarized intuitionistic logic, we propose another, the polarized λ-calculus, or λ±, under which is a natural deduction system isomorphic to the sequent calculus we started from. This isomorphism works at all levels: deriva- tions, classes of derivations and their forms of judgment, reduction relations. As a result, we obtain a very interesting proof system, having a lot to say about always- hot topics in the theory of natural deduction: subformula property, proof-search, treatment of disjunction, general elimination rules [11,8,14,12]. Simultaneously, the polarized λ-calculus is an addition to the Curry-Howard correspondence: from it one can distill a variant of the CBPV calculus.
We start (section 2) with a review of focusing and polarity, as we present a sequent calculus named λ±. Section 3 is dedicated to the polarized λ-calculus λ±,
G	N
with some of its properties obtained in Section 4. The closing Section 5 discusses
the results.

A review of polarity and focusing
System λ± has positive and negative formulas, given by the following grammar:

(Positive formulas) P, Q ::= a+ | ↓ N | ⊥ | P ∨ Q
(Negative formulas) M, N ::= a− | ↑ P | P ⊃ N | N ∧ M

Here, a+ (resp. a−) ranges over positive (resp. negative) atoms. Polarity shifts are denoted by ↓ and ↑. A basic positive formula B is either a positive atom, a shift
↓ N , or ⊥. A composite negative formula C is a negative formula that is not an atom. The following definitions are useful:
(Formulas) A ::= P | N	(Right formulas) R ::= P | a−	(Left formulas) L ::= N | a+



 Γ =⇒ t : C  ·/Jump
Γ ▶ dlv(t): C


Γ ▶ [V : P ]

Γ ▶ ret(V ): P ·/FocusR
Γ,x : N [S : N ] ▶ A

Γ,x : N ▶ coret(x, S): A ·/FocusL


Γ =⇒ t : N	Γ[S : N ] ▶ A Cut−/·	Γ ▶ [V : P ]	Γ|p : P =⇒ A Cut+/·
Γ ▶ ⟨t|S⟩ : A	Γ ▶ ⟨V |p⟩ : A



Fig. 1. Typing rules of λ± - rules for stable sequents Γ ▶ e : A
The inference/typing rules of λ±, given in Figs. 1, 2 and 3, handle the following
sequents:
Γ ▶ [V : P ]	Γ =⇒ t : N	Γ[S : N ] ▶ A	Γ|p : P =⇒ A	Γ ▶ e : A .
A context Γ is a set of declarations x : L (hence either x : N or z : a+), where each variable x is declared at most once. Inference rules are doubly tagged as [tag1/tag2]. The first tag gives the usual name to the rule according to the top-down reading of it; the second tag gives a name according to the action the rule produces when applied bottom-up in the process of proof-search. If no tag is appropriate, we put ·. Proof-search. The first thing to do in order to understand this system is to strip all the term annotations, including the variables in declarations. Γ becomes
temporarily a multisets of left formulas and we get five forms of sequents:
Γ ▶ A - stable sequent
Γ ▶ [P ] - focus on the positive P in the r.h.s. of the sequent.
Γ =⇒ N - invert the negative N in the r.h.s. of the sequent.
Γ[N ] ▶ A - focus on the negative N in the l.h.s. of the sequent.
Γ|P =⇒ A - invert the positive P in the l.h.s. of the sequent.
Proof-search is defined in the subsystem where the cut-rules are omitted and pro- ceeds as follows. Given a stable sequent Γ ▶ A, an external decision is required, namely the choice of which formula of the sequent to focus on: either the positive P (if A = P ), or a negative N ∈ Γ (if a negative exists in Γ).
In the first case, the decomposition of P will produce either a positive atom or a negative M after the blur of the focus. In the former sub-case, one accepts the sequent, if the produced atom is in Γ, otherwise the search fails. In the latter sub-case, the process proceeds with the inversion of M . Right inversion collects on the r.h.s. either a negative atom, or a positive, which makes the sequent stable



Atom+/Accept+		Γ =⇒ t : N	 ↓R /BlurR

Γ,z : a+ ▶ [z : a+]	R
Γ ▶ [thunk(t) :↓ N ]



	Γ ▶ [V : Pi]	
∨R
Γ ▶ [ini(V ): P1 ∨ P2]
/ · (i = 1, 2)





Atom−/Accept−	Γ|p : P =⇒ A

↑ /Blur

Γ[nil : a−] ▶ a−	L
Γ[cothunk(p) :↑ P ] ▶ A	L	L



Γ ▶ [V : P ]	Γ[S : N ] ▶ A
⊃
/·	Γ[S : Ni] ▶ A
∧ / · (i = 1, 2)

Γ[V :: S : P ⊃ N ] ▶ A	L	Γ[i :: S : N1 ∧ N2] ▶ A	L



Fig. 2. Typing rules of λ± - rules for focusing sequents Γ ▶ [V : P ] and Γ[S : N ] ▶ A



Γ ▶ e : a−
Atom−/Collect−
	Γ ▶ e : P	 ↑
/Collect+

Γ =⇒ pe’ : a−	R	R	Γ =⇒ [e| :↑ P	R	R


Γ|p : P =⇒ N
Γ =⇒ λp : P ⊃ N
⊃ /·	Γ =⇒ t1 : N1	Γ =⇒ t2 : N2
R	Γ =⇒ ⟨t1, t2⟩ : N1 ∧ N2
∧R/·





Γ,z : a+ ▶ e : A	+
+	Γ,x : N ▶ e : A	−

Γ|z.e : a+ =⇒ A AtomL /CollectL
Γ|x.e :↓ N =⇒ A ↓L /CollectL





Γ|abort :⊥=⇒ A
⊥ /·	Γ|p1 : P1 =⇒ A	Γ|p2 : P2 =⇒ A ∨ /·
L	Γ|[p1, p2]: P1 ∨ P2 =⇒ A	L




Fig. 3. Typing rules of λ± - rules for inversion sequents Γ =⇒ t : N and Γ|p : P =⇒ A

again.
In the second case, the decomposition of N will produce either a negative atom or a positive Q after the blur of the focus. In the former sub-case, one accepts



(Values) V ::= z | thunk(t) | in1(V ) | in2(V ) (Terms) t ::= pe’ | [e|| λp | ⟨t1, t2⟩
(Co − values, aka spines) S ::= nil | cothunk(p) | V :: S | 1 :: S | 2 :: S
(Co − terms) p ::= z.e | x.e | [p1, p2] | abort
(Expressions) e ::= dlv(t) | ret(V ) | coret(x, S) | ⟨t|S⟩| ⟨V |p⟩

Fig. 4. Proof-terms for λ±

the sequent, if the produced atom is R, otherwise the search fails. In the latter sub-case, the process proceeds with the inversion of Q. Left inversion either stops if ⊥L is hit, or collects on the l.h.s. either a positive atom, or a negative, which makes the sequent stable again.
This pleasing symmetric picture is slightly disturbed by the fact that the r.h.s. for- mula A of the initial stable sequent may be a composite negative formula C. In this case, a third possibility for the search procedure exists: to jump directly to the inversion of C.
Why can’t the r.h.s. formula in Γ ▶ A, in Γ[N ] ▶ A, and in Γ|P =⇒ A be restricted to a right formula R? The reason is inference rule ⊃R in Fig. 3: the inversion sequent in the premiss has a negative r.h.s. formula, hence the stable sequents collected at the end of the left inversion phase may have a negative formula on the r.h.s., hence the same is true of left focusing sequents due to rule FocusL in Fig. 1 (for if the r.h.s. formula of sequents Γ[N ] ▶ A were restricted to R, we would be forced to jump whenever a stable sequent had a formula C in the r.h.s., even if there were a N in the l.h.s. to focus on).
A language of proof-terms. The syntax of the proof-terms of λ± is given in
Fig.4.
There are 5 syntactic classes because there are 5 kinds of sequents in the logical system. We assume two denumerable, disjoint sets of negative variables and positive variables, ranged over by x and z, respectively. In the case of Γ[S : N ] ▶ R, Γ|p : P =⇒ R or Γ ▶ e : R, we may think of R as a co-context (=r.h.s. context) with a single declaration, either of the default positive co-variable, say , with positive type, or of the default negative co-variable with atomic negative type. After comparing the typing rules Atom+ and Atom−, one has to recognize nil as the default negative
R	L
co-variable, whereas  is nowhere written. We may think that  has a unique,
implicit occurrence in each positive S, p, or e, while it has none in V , or t, or negative e.
We should look again at the system in Figs. 1, 2 and 3, now as a typing system, with all the term annotations put back. We think of values V and terms t as typed on the right, with a positive and a negative type respectively; and think of co- values S and co-terms p as co-typed on the left, with a negative and positive type,




Γ =⇒ t : N	Γ,x : N ▶ e : A
Γ ▶ [t/x]e : A
Γ ▶ e : P	Γ|p : P =⇒ A
Γ ▶ e[ \p]: A



Γ|p : P =⇒ N	Γ[S : N ] ▶ A
Γ|p@S : P =⇒ A
Γ ▶ e : N	Γ[S : N ] ▶ A


Γ ▶ e@S : A


Γ[Sj : Aj] ▶ N	Γ[S : N ] ▶ A
Γ[Sj@S : Aj] ▶ A

Fig. 5. Admissible typing rules for the syntactic operations of λ±








respectively. Expressions annotate stable sequents.
The duality between syntactic classes is also seen at their particular construc- tions. The values z and thunk(t) are dual to nil and cothunk(p), respectively. If we write pe’ and [e| as the co-bindings e.nil and e. , one sees the duality with the bindings z.e and x.e, respectively.
The constructors for the three connectives ∧, ∨, and ⊃ are pairing, injection and λ-abstraction, the latter in the unusual form λp, where p is a co-pairing of a number of “bodies” of the forms z.e, x.e or abort. Co-pairing is the destructor for
∨, while the negatives ∧ and ⊃ have a generic form of destruction, namely pushing the spine (with either a value V or a projection symbol 1, 2).
If we disregard the delivered term dlv(t) (which expresses the jump facility in- troduced in the proof-system), the four forms of an expression e come as two pairs of dual constructions. The duality between return and co-return is enhanced if we think of the former as ret(V, ). There is a positive cut ⟨V |p⟩ and a negative cut
⟨t|S⟩: the polarity of a cut is that of its cut-formula.
Derived syntax. There is an operation of negative substitution [t/x]e, in whose recursive definition the critical equation is [t/x]coret(x, S) = ⟨t|Sj⟩, where Sj = [t/x]S. Dually, there is a positive substitution e[ \p], in whose recursive definition the critical equation is ret(V )[ \p]= ⟨V |p⟩. The admissible typing rules are in Fig. 5.
We need a third operation p@S.  If S = nil, let p@S = p, e@S = e, and
Sj@S = Sj; otherwise, the co-term p@S, the expression e@S, and the spine Sj@S




⟨λp|V :: S⟩ → ⟨V |p@S⟩
⟨⟨t1, t2⟩|i :: S⟩ → ⟨ti|S⟩ (i = 1, 2)
⟨[e||cothunk(p)⟩ → e[ \p]
⟨pe’|nil⟩ → e
⟨ini(V )|[p1, p2]⟩ → ⟨V |pi⟩ (i = 1, 2)
⟨thunk(t)|x.e⟩ → [t/x]e
⟨z|zj.e⟩ → [z/zj]e

Fig. 6. Cut-elimination in λ±
are defined by simultaneous recursion on p and e and Sj:
abort@S = abort	(dlv(t))@S = ⟨t|S⟩
[p1, p2]@S = [p1@S, p2@S]		⟨V |p⟩@S = ⟨V |p@S⟩ (x.e)@S = x.(e@S)		 ⟨t|Sj⟩@S = ⟨t|Sj@S⟩ (z.e)@S = z.(e@S)	coret(x, Sj)@S = coret(x, Sj@S)
nil@S = S
cothunk(p)@S = cothunk(p@S) (V :: Sj)@S = V :: (Sj@S)
(i :: Sj)@S = i :: (Sj@S)
One inspects p or e or Sj, searching for a delivered term t that will create the cut
⟨t|S⟩.
Polarized cut-elimination. The cut-elimination rules are given in Fig.6. These rules are relations on expressions and generate, by compatible closure, one- step reduction relations denoted →. The fist four rules reduce negative cuts, the last three positive cuts. Notice that the reduction of a negative cut may generate a positive cut - this is already visible in the first rule. Every redex is a cut. In a typed expression, every cut is a redex, as typing forces the cuts to have the form of one of the displayed redexes. For instance, in a typed cut ⟨λp|S⟩, S has to have the form
V :: Sj, since this is the only form of S which is co-typed with an implication (in the left focus). So, a typed expression is cut-free iff is irreducible. Moreover, every cut is principal, as the cut-formula is introduced in both premisses, even when the cut- formula is atomic (a consequence of having inference/typing rules for introducing





 Γ =⇒ t : C  ·/Jump	Γ ▶ [V : P ]
Id+/Focus

Γ ▶ dlv(t): C
Γ ▶ ret(V ): P	U



Γ D H : a—

Γ ▶ ap(H): a—
Atom—/Accept—


Γ D H :↑ P	P = B1 ∨· · · ∨ Bn	(Γ|bi : Bi −→ A)i=1,··· ,n
Γ ▶ case ap(H, b , ··· ,b ): A	↑E /BICD
1	n

Γ ▶ [V : P ]	P = B1 ∨· · · ∨ Bn	(Γ|bi : Bi −→ A)i=1,··· ,n
Γ ▶ case val(V, b , ··· ,b ): A	+E/·
1	n


Fig. 7. Typing rules of λ± - rules for stable sequents Γ ▶ e : A

atoms both in the l.h.s. and r.h.s. of sequents).
The polarized λ-calculus
A natural deduction system for polarized intuitionistic logic. The infer- ence/typing rules of λ± are given in Figs. 7, 8 and 9. They handle the following
sequents:
Γ ▶ [V : P ]	Γ =⇒ t : N	Γ D H : N	Γ ▶ e : A .
A context Γ is again a set of declarations x : L (hence either x : N or z : a+), where each variable x is declared at most once. The inference rules of λ± are doubly tagged as [tag1/tag2]. The first tag gives a name to the rule according to the top-down reading of it; the second tag gives a name according to the action the rule produces in the process of proof-search to be introduced below. If no tag is appropriate, we put ·.
The first thing to do in order to understand this system is to concentrate on the logical side, omitting all term annotations, including the variables in declarations. Contexts Γ become temporarily multisets of left formulas (N or a+).
Recall that B ranges over basic positive formulas, that is, formulas of the forms a+, ↓ N or ⊥. Every positive formula is thus of the form B1 ∨ · · ·∨ Bn. Some inference rules have premisses of the form Γ|B −→ A. This is a derived form of sequent which is defined by case analysis of B:
Γ|a+ −→ A := Γ, a+ ▶ A	Γ|↓ N −→ A := Γ,N ▶ A	Γ| ⊥−→ A := true
(1)



Atom+/Accept+		Γ =⇒ t : N	 ↓I /BlurU

Γ,z : a+ ▶ [z : a+]	I
Γ ▶ [thunk(t) :↓ N ]


	Γ ▶ [V : Bk]	
∨ / · (n ≥ 2, 1 ≤ k ≤ n)
Γ ▶ [inn(V ): B1 ∨· · · ∨ Bn]	I





Γ,x : N D x : N
Id—/Focus	 Γ =⇒ t : N  − /·
Γ D hd(t): N



Γ D H : P ⊃ N	Γ ▶ [V : P ]
Γ D HV : N	⊃E
/·	Γ D H : N1 ∧ N2
Γ D Hi : Ni
∧E/ · (i = 1, 2)



Fig. 8. Typing rules of λ± - rules for focusing sequents Γ ▶ [V : P ] and Γ Q H : N



Γ ▶ e : a—
Atom—/Collect—
	Γ ▶ e : P	 ↑
/Collect+

Γ =⇒ pe’ : a—	I	U	Γ =⇒ [e| :↑ P	I	U

P = B1 ∨· · · ∨ Bn	(Γ|bi : Bi −→ N )i=1,··· ,n
Γ =⇒ λ(b , ··· ,b ): P ⊃ N	⊃I /·
1	n


Γ =⇒ t1 : N1	Γ =⇒ t2 : N2
Γ =⇒ ⟨t1, t2⟩ : N1 ∧ N2
∧I/·




Fig. 9. Typing rules of λ± - rules for inversion sequents Γ =⇒ t : N

The third equation of (1) means that we may erase premisses of the form Γ| ⊥−→ A. The first (resp. second) equation of (1) hides the elimination of positive atoms (resp. elimination of ↓). For example, the following is an instance of rule +E:
Γ ▶ [a+∨⊥∨↓ N ]	Γ, a+ ▶ A	Γ,N ▶ A
Γ ▶ A

In order to understand the top-down reading of the inference rules, let us forget temporarily the distinction between the various forms of sequents. The connectives
∧ and ⊃ have primitive introduction and elimination rules. The rules for ∧ and the

elimination rule for ⊃ are the easiest. Notice that the introduction rule for ⊃ has this familiar particular case:
Γ,M ▶ N
Γ =⇒↓ M ⊃ N
Also familiar is the introduction rule for ∨.
The up shift ↑ also has an introduction and an elimination rule, but the latter is complex, as it may involve the elimination of ∨ and of basic atomic positive formulas through the definition (1). This rule is similar to +E, which is a generic elimination rule for positive formulas. Dually, there is a generic introduction rule for negative formulas −I : while in +E we eliminate a focused positive, in −I we conclude a focused negative, that starts a downward focusing phase (see below for proof search in this system). The introduction rule for the down shift ↓ is primitive, while, again, its elimination rule is hidden in (1).
Since Γ contains formulas of the forms a+ or N , one has the axioms Atom+ and Id—. The latter starts a negative downward focus from an assumption, while its dual Id+ starts a positive upward focus from a conclusion. On the other hand, Atom+ belongs to a set of four rules for atoms, one of which is hidden in (1). As any former of negative formulas, negative atoms have an introduction rule Atom—; as the other base case of a negative formula (↑ P ), negative atoms have an elimination rule that ends a downward focusing phase.
There remains the single rule without first tag: as in sequent calculus, it is a jump facility only explainable through proof-search.
Normality. In a derivation of a stable sequent, a positive formula P is maximal (=conclusion of an introduction and main premiss of an elimination) iff P is the right focus of the main premiss of an instance of +E (because a derivation of Γ ▶ [P ] necessarily ends with an introduction, and no other elimination rule has a positive formula in the main premiss); and a negative formula N is maximal iff it is the
r.h.s. formula of an instance of −I (because every main premiss of an elimination has the form Γ D N ; no rule for deriving this kind of sequent, other than −I , is an introduction; and all rules for deriving the premiss of −I are introductions). These observation justify the following definition.
Definition 3.1 A derivation in λ± is said to be normal if it contains no occurrence of rules −I or +E (the generic rules).
Proposition 3.2 (Subformula property) (i) In a normal derivation of Γ ▶ [P ] (resp. Γ =⇒ N, Γ ▶ A) every formula is a subformula of P (resp. N, A) or of some formula in Γ.
(ii) In a normal derivation of Γ D N, every formula, including N, isa subformula of some formula in Γ.
Proof. By simultaneous induction on Γ ▶ [P ], Γ =⇒ N , Γ ▶ A, and Γ D N .	 
Proof search. We define a proof-search procedure for λ± which explains the
difference between the four forms of sequents:
Γ ▶ A - stable sequent



(Values) V ::= z | thunk(t) | inn(V )
−→
(Terms)  t ::= pe’ | [e|| λ b | ⟨t1, t2⟩
(Heads, hole expressions) H ::= x | HV | H1 | H2 | hd(t)
−→	−→
(Expressions) e ::= dlv(t) | ret(V ) | ap(H) | case ap(H, b ) | case val(V, b )

Fig. 10. Proof-terms for λ±

Γ ▶ [P ] - focus up on the positive P (in the r.h.s. of the sequent).
Γ =⇒ N - invert up the negative N (in the r.h.s. of the sequent).
Γ D N - focus down on the negative N (in the r.h.s. of the sequent).
As in sequent calculus, proof-search here is organized into phases of focusing and inversion, but all the “action” now happens in the r.h.s. of sequents. We now have upward (rather than right) and downward (rather than left) focusing and inversion. In the upward (resp. downward) phase, inference rules are applied bottom-up (resp. top-down). Proof-search is defined over normal derivations.
Given a stable sequent Γ ▶ A, one has to chose either to start upward focusing on the positive P (if A = P ), or downward focusing on a negative N ∈ Γ (if one such N exists).
In the first case, one proceeds exactly as in the right focusing phase of proof-search in sequent calculus.
In the second case, we suspend the bottom-up development of the given stable sequent, and turn to a phase of top-down application of inference rules. A negative formula N from Γ is chosen by rule FocusD to start the downward focusing. The decomposition of N through the elimination rules for ⊃ and ∧ will produce either a negative atom or some ↑ Q. In the former sub-case, one accepts the given stable sequent, if the produced atom is R, otherwise the search fails. In the latter sub-case, we return to the given stable sequent and proceed with the bottom- up application of BICD, which stands for downward blur-invert-collect. By this single rule, the downward focus ↑ Q is blurred, the positive Q inverted, positive atoms and negatives at the bottom of Q collected, and, for each of these, a new stable sequent created.
As in sequent calculus, this proof-search procedure is slightly extended: if A is some composite negative C, then the process may jump directly to the inversion of C.
A language of proof-terms. The syntax of the proof-terms of λ± is given in Fig.10. There are 4 syntactic classes in this language because there are 4 kinds of sequents in the logical system. One should now return to the system in Figs.7, 8 and 9 and put all the term annotations back. We have a typing system for this term language.

In λ±, basic co-terms b form a derived syntactic class defined by this grammar:
b ::= z.e | x.e | abort
Accordingly, there is a derived form of sequents Γ|b : B −→ A defined thus:







A co-term in λ±
Γ|z.e : a+ −→ A := Γ,z : a+ ▶ e : A Γ|x.e :↓ N −→ A := Γ,x : N ▶ e : A Γ|abort :⊥−→ A := true
−→

(2)


±

N is a vector b = b1, ··· , bn of basic co-terms. Notice that in λN
co-terms are not proof-terms per se (contrary to λ±). For instance, abort is just a symbol that may be used in the formation of λ-abstraction and case-expressions.
Relatively to the language of proof-terms of λ±, the novelty is the class of heads, which are series of “applications” starting from a negative variable x or a head term. Here “application” comprehends the usual application HV and also projections Hi, as the notation suggests. Hence ap(H) (which we may type when H has atomic type) is called “applicative” expression. If H has type ↑ P , we may type a negative
−→
case-expression case ap(H, b ). The other form of case expression is said positive.
Definition 3.3 An expression of λ± is normal if it contains no occurrence of hd or
case val.
Derived syntax. Applicative expressions and negative case-expressions may be uniformly given as [H]S, denoting the result of filling H in the hole of S, where S is a context (an expression with a hole) with two possible forms 2 :
−→
ap([ ]W1 ··· Wm)	case ap([ ]W1 ··· Wm, b ) .

Here each Wi is either a value V or a projection symbol 1, 2. Notice the hole of S expects an H, and this is why heads may also be called hole expressions. Such contexts are the spines of λ± and are inductively generated by
−→
S ::= ap([ ]) | case ap([ ], b ) | [[ ]V ]S| [[ ]1]S| [[ ]2]S	(3)
So, in order to generate spines 3 we fill holes of spines with [ ]V or [ ]i.
In addition to hole filling in spines, there are two other, somewhat relaxed, concepts of hole filling. The first is this: we define what it means to fill e of non- atomic negative type C in the hole of S, producing an expression denoted [e]]S, and

2 Notice we are diverging from the usual notation for hole-filling, which would be S[H]. A justification for the adopted notation is that the hole of S is at the left end of the expression.
3 The justification for the terminology “spines” will come later: the maps that connect λ± and λ± will
G	N
relate precisely spines in the former with “spines” in the latter.




Γ ▶ e : N	Γ[S : N ] −→ A
Γ ▶ [[e]]S : A
Γ|b : B −→ N	Γ[S : N ] ▶ A
Γ|b@S : B −→ A


Γ ▶ e : P	P = B1 ∨· · · ∨ Bn	(Γ|bi : Bi −→ A)i=1,··· ,n
Γ ▶ [[[e]]](b1, ··· , bn): A

Γ|b : Q −→ P	P = B1 ∨· · · ∨ Bn	(Γ|bi : Bi −→ A)i=1,··· ,n
j−→
Γ|b@ b : Q −→ A

Γ =⇒ t : N	Γ,x : N ▶ e : A
Γ ▶ [t/x]e : A

Fig. 11. Admissible typing rules for the syntactic operations of λ±
simultaneously we define the basic co-term b@S:
[[dlv(t)]]S = [hd(t)]S	abort@S = abort
−→	−→
[[case val(V, b )]]S = case val(V, ( b )@S)	(x.e)@S = x.([[e]]S)
−→	−→
[[case ap(H, b )]]S = case ap(H, ( b )@S)	(z.e)@S = z.([[e]]S)
where (b1, ··· , bn)@S = b1@S, ··· , bn@S. In the definition of [e]]S one searches e to find a delivered term dlv(t), and proceed with the ordinary filling of hd(t) in S. We extend the operations to the case where a— is the type of e and the co-type of S, by putting: [e]]ap([ ]) = e 4 and b@ap([ ]) = b. The admissible typing rules are

in Fig. 11.
−→	−→

The second relaxed concept of hole filling is [e]]] b , where we regard
−→
b as the

context case val([ ], b ), for which it is defined what it means to fill a value V . We
−→	−→
define the expression [e]]] b together with the basic co-term b@ b :


[[[ret
−→	−→
case val
abort
j−→
abort

[[[case ap
−→j  −→
case ap
−→j
j−→
j−→	−→

[[[case val
−→j  −→
case val
−→j
j−→
j−→	−→



j	j	j−→
j	j−→
j	j−→	−→

where (b1, ··· , bn)@
b = b1@
b , ··· , bn@
b . In the definition of [e]]] b one searches

e to find a returned value ret(V ), and proceed with the ordinary filling of V

4 We might have put [e]]ap([ ]) = ap(hd(pe’)) but we will see that e is a reduct of ap(hd(pe’)).




[ hd
−→
(λ b )
V ]S → case val
−→
(V, b @S)

 hd(⟨t1, t2⟩) i → hd(ti)	(i = 1, 2)
−→	−→
case ap(hd([e|), b ) → [[[e]]] b
ap(hd(pe’)) → e
case val(inn(V ), b1, ··· , bn) → case val(V, bk)	(n ≥ 2, 1 ≤ k ≤ n)
case val(thunk(t), x.e) → [t/x]e
case val(z, zj.e) → [z/zj]e

Fig. 12. Normalization in λ±

−→
in case val([ ], b ).	The case missing cases of e do not arise since the hole of

−→
case val([ ], b ) has positive type. Again the admissible typing rules are in Fig.
−→
11, where b = b1, ··· , bn.
Finally, there is an operation of negative substitution [t/x]e, in whose recursive definition the critical equation is [t/x]x = hd(t).
Polarized normalization. The normalization rules are given in Fig.12. These rules are relations on expressions, with the exception of the rule for ∧, which is a rule on heads, generating a relation on expressions through the property: H → Hj ⇒ [H]S → [Hj]S. Then, by compatible closure, one-step reduction relations, denoted →, are generated.
In the first four rules, a negative redex has the form [hd(t)]Sj, the last three rules reduce positive redexes, which are positive case-expressions. So, if an expression contains a redex, it is not normal. On the other hand, if a typed expression is not normal, then either it contains a positive case-expression (which has to have the form of a positive redex, as the three possible forms of a value are covered by the last three reduction rules), or it contains a negative redex (because the four possible forms of hd(t) are covered by the first four reduction rules, and typing forces hd(t) to occur as shown). So, a typed expression is normal iff it is irreducible. Moreover, each reduction rule eliminates a maximal formula (the type of t in hd(t) or the type
−→
of V in case val(V, b )). So, each reduction rule is a detour conversion rule.
The rule for ∧ is familiar and the easiest. The rule for ⊃ reduces an ordinary β-redex: a positive case-expression is created, where the first component is V , to be analyzed by the last three reduction rules. These either chose a component of
−→
a co-pair b indicated by an injection, or substitute a thunked term, or rename a
positive variable. The remaining two rules deal with the situation where the head term is a co-binding and their common idea is that (case)ap and hd cancel out.

Results
Isomorphism. Perhaps surprisingly, we prove that λ±and λ± are two views of the
G	N
same system. We profit from a technique that has matured for much simpler logics
[5,6].
Obviously one has to adjust the treatment of disjunction in λ± to match that of λ±: (i) One adopts an n-ary injection inn(V ); (ii) The right-introduction rule is
N	k
the same as the introduction rule in λ±; (iii) The left-introduction rule becomes
(Γ|bi : Bi =⇒ A)i=1,··· ,n

Γ|[b1, ··· , bn]: B1 ∨· · · ∨ Bn
=⇒ A ∨L/·

(iv) The reduction rule is now ⟨inn(V )|[b1, ··· , bn]⟩→ ⟨V |bk⟩. The key tools are maps Θ : λ± −→ λ± and Ψ : λ± −→ λ±:
G	N	N	G
For T = V, t, e ∈ λ±, we define the value (resp. term, expression) Θ(T ); for S ∈ λ± we define the expression Θ(H, S), given H. The definition is a simultaneous recursion on T and S.
For T = V, t, e ∈ λ±, we define the value (resp. term, expression) Ψ(T ); for H ∈ λ± we define the expression Ψ(H, S), given S. The definition is a simultaneous recursion on T and H.
Given that there are no co-terms in λ±, the translation of co-terms is done “on the
fly”: basic co-terms abort, z.e, x.e are translated homomorphically, while Θ([b1, ··· , bn]) = (Θ(b1), ··· , Θ(bn)) and Ψ(b1, ··· , bn) = [Ψ(b1), ··· , Ψ(bn)].
Values and terms are translated homomorphically; so are expressions which are returned values or delivered terms. The remaining clauses for expressions are:
Θ(coret(x, S)) = Θ(x, S)	Ψ(ap(H)) = Ψ(H, nil)
−→	−→
Θ(⟨t|S⟩) = Θ(hd(Θt), S)	Ψ(case ap(H, b )) = Ψ(H, cothunk(Ψ( b )))
−→	−→
Θ(⟨V |p⟩) = case val(ΘV, Θp)	Ψ(case val(V, b )) = ⟨ΨV |Ψ( b )⟩

The motor of the translations is the interplay between spines and heads. Given the parameter H (resp. S), Θ(H, S) (resp. Ψ(H, S)) is defined by recursion on S (resp. H) as follows:
Θ(H, nil) = ap(H)		Ψ(x, S) = coret(x, S) Θ(H, cothunk(p)) = case ap(H, Θp)	Ψ(hd(t), S) = ⟨Ψt|S⟩
Θ(H, V :: S) = Θ(HΘV, S)	Ψ(HV, S) = Ψ(H, ΨV :: S)
Θ(H, i :: S) = Θ(Hi, S)	Ψ(Hi, S) = Ψ(H, i :: S)
For T = V, t, e, maps Θ and Ψ preserve types. For H and S, typing is given in Fig.13.




Γ D H : N	Γ[S : N ] ▶ A
Γ ▶ Θ(H, S): A
Γ D H : N	Γ[S : N ] ▶ A
Γ ▶ Ψ(H, S): A



Fig. 13. Typing for Θ and Ψ
Theorem 4.1 (Bijection) Θ and Ψ are mutual inverses at the levels of values, terms, and expressions, that is: (i) ΘΨ(T ) = T with T = V, t, e in λ±; and (ii)
ΨΘ(Tj)= T j, with T j = V, t, e in λ±.
Proof. The statement (i) is proved together with (iii) ΘΨ(H, S) = Θ(H, S) for all S; the proof is by simultaneous induction of T and H in λ±. The statement
(ii) is proved together with (iv) ΨΘ(H, S) = Ψ(H, S) for all H; the proof is by simultaneous induction on T j and S in λ±.	 
The completeness of λ± follows: every intuitionistic theorem has a proof in the system (after being polarized to become a polarized formula) - insofar the same holds of λ± (completeness of focusing [13]) and thanks to the previous theorem.
In order to prove the isomorphism theorem below (Theorem 4.3), we need some preliminary work. We extend Θ and Ψ with maps of spines to spines:
Θ(nil) = ap([ ])	Ψ(ap([ ])) = nil
−→	−→
Θ(cothunk(p)) = case ap([ ], Θp)   Ψ(case ap([ ], b )) = cothunk(Ψ( b ))
Θ(V :: S) = [[ ]ΘV ]ΘS	Ψ([[ ]V ]S) = ΨV :: ΨS
Θ(i :: S) = [[ ]i]ΘS	Ψ([[ ]i]S) = i :: ΨS
It is an immediate consequence of Theorem 4.1 that ΨΘS = S and ΘΨS = S.
Having extended Θ to spines, it is very handy to express Θ(H, S) in terms of hole filling. Let S = ΘS. An easy induction on S establishes Θ(H, S)= [H]S, from which the equality Ψ(H, S)= Ψ([H]S) follows.
Next we see how Θ maps the various operations of substitution and hole filling.
Lemma 4.2
Θ([t/x]T )= [Θt/x]ΘT, for T = e, V, tj, b, p.
Θ(e[ \p]) = [[[Θe]]]Θp.
Θ(T @S)= (ΘT )@(ΘS), for T = b, p.
Θ([z/zj]T )= [z/zj]ΘT, for T = V, t, S, b, p, e.
Proof. (i) The statement is proved together with Θ([Θt/x]H, [t/x]S)= [Θt/x]Θ(H, S), for all H. The proof is by simultaneous induction on T and S. (ii) The statement
is proved together with: Θ(H, S[ \p]) = [[Θ(H, S)]]]Θp, for all H; and Θ(pj[ \p]) = Θ(pj)@jΘ(p); and Θ(b[ \p]) = Θ(b)@jΘ(p). The proof is by simultaneous induction

on e, S, pj and b. (iii) The statement is proved together with Θ(e@S)= [[Θe]]ΘS. The proof is by simultaneous induction on T and e. (iv) By simultaneous induction on T .	 
Using Theorem 4.1, it is immediate to obtain, from the preceding lemma, a simi-
−→	−→
lar lemma for Ψ. For instance, corresponding to (ii) we get Ψ([[e]]] b )= (Ψe)[ \Ψ b ].
Theorem 4.3 (Isomorphism) Θ and Ψ are mutually inverse maps between cut- elimination in λ± and normalization in λ±, that is: Let ρ =⊃, ∧, ↑, a—, ∨, ↓, a+ and
G	N
let →ρ denote either the reduction relation in λ± generated by rule ρ in Fig.6, or the reduction relation in λ± generated by rule ρ in Fig.12. Then, for T, T j either values, terms, or expressions:
T →ρ T j in λ± iff Θ(T ) →ρ Θ(Tj) in λ±.
G	N
T →ρ T j in λ± iff Ψ(T ) →ρ Ψ(Tj) in λ±.
N	G
Proof. The “if” statements follow from the “only if” statements and Theorem 4.1. Each “only if” statement is proved by induction on T →ρ T j, using Lemma 4.2 for Θ and the similar lemma for Ψ.	 
Negative identity and η-expansion. In the ordinary λ-calculus, a context T = λx.[ ]x might be called a η-expander for type A ⊃ B: given M of this type, T [M ] is the η-expansion of M , which is again a term of type A ⊃ B. We analyze this question in λ± because it is related to the question of negative identity : we know Γ,x : a— ▶ ap(x): a—, but is there an expression eN (x) (possibly depending on the negative type N ) such that Γ,x : N ▶ eN (x) : N , for all N ? We could call such expression the “generalized negative return”, by analogy with the fact Γ,z : a+ ▶ ret(z): a+.
Theorem 4.4 (Negative identity) For all N, there are contexts TN and EN , which are respectively a term and an expression with holes, holes which in both cases expect hole expressions of type N, such that the following rules are admissible: 5


	Γ D H : N	
Γ =⇒ TN [H]: N
  Γ D H : N	
Γ ▶ EN [H]: N


Proof. First, for a positive type P = B1 ∨· · ·∨ Bn, for B the k-th operand of this disjunction, we define the macros bB (a basic co-term) and BB,N (a basic co-term with 0, 1 or more holes expecting hole expressions of type P ⊃ N ) 6 :

B = a+ : bB = z.ret(inn(z))	BB,N = z.EN [[ ]inn(z)]
k	k
B =↓ M : bB = x.ret(inn(thunk(TM [x])))	BB,N = x.EN [[ ]inn(thunk(TM [x]))]
k	k
B =⊥ : bB = abort	BB,N = abort

5 Notice neither fN nor £N are spines. For these contexts, we resort to the usual hole-filling notation.
6 In these macros, if n = 1, inn(V ) is understood to be V .

TN is defined by recursion on N as follows:
N = a—	: TN = pap([ ])’
N =↑ P, with P = B1 ∨· · · ∨ Bn	: TN = [case ap([ ], bB1 , ··· , bBn )| N = N1 ∧ N2	: TN = ⟨TN1 [[ ]1], TN2 [[ ]2]⟩
N = P ⊃ Nj, with P = B1 ∨· · · ∨ Bn : TN = λ(BB ,N′ , ··· , BB ,N′ )
Finally, for N = a—, we put EN = ap([ ]) (which is TN with the outer p·’ removed); and, for N = C, we put EN = dlv(TN ). The typing of EN [H] is immediate from that of TN [H]. The typing of TN [H] is proved by induction on N . The case N =↑
j
P involves proving Γ|bBi  : Bi −→ P . The case N = P ⊃ N  involves proving
Γ|BB ,N′ [H]: Bi −→ Nj.	 
Given a negative type N : TN and EN are the η-expanders of N ; given t : N , the η-expansion of t is TN [hd(t)]; EN [x] is the generalized negative return for N , satisfying Γ,x : N ▶ EN [x]: N . We also obtain the elimination rule for ↓:
Γ ▶ [V :↓ N ]
↓E
Γ ▶ case val(V, x.EN [x]) : N
In terms of programming, as we will soon see, this is a destructor of thunk(t).
Call-by-push-value. In order to show the expressive power of λ±, we are going to simplify the system. Reading positive (resp. negative) types as value types (resp. computation types), and reading ↑ and ↓ as the type formers F and U , a variant of CBPV is obtained through the collapse of terms and expressions into a single class of computations E, annotating a form of sequents Γ H E : A that replaces the forms Γ =⇒ t : N and Γ ▶ e : A. A right type R is now either a— or ↑ P . The markers dlv(·), p·’ and [·|, which allowed to move between terms and expressions, no longer make sense, but the latter has to be merged with ret(V ) to become return(V ), corresponding to the introduction rule for ↑. In the definition of [e]]S, the clause for dlv(t) has to be replaced by [E]]S = [hd(E)]S, for E a λ-abstraction or a pair. The markers p·’ and [·| are erased from reduction rules. The η-expanders TN and EN collapse to a single one, denoted EN .

In the resulting system (call it λ±
) one easily defines variants of CBPV

constructors:
let z be zj.E := case val(z, zj.E)	E to −→

case ap(hd

−→
(E), b )

−→	−→
pm V as b := case val(V, b )	force(V ) := case val(V, x.EN [x])	(V :↓ N )
Variants of CBPV’s reduction rules become derivable. For instance:
−→	−→
return(V ) to b → case val(V, b )	force(thunk(E)) → EN [hd(E)]
The first of these rule executes positive return, extracting the value V of positive

type that the positive return return(·) carries, while the second executes negative return, giving to the negative return EN [·] the computation E of negative type N

it expects; in addition, we see that in λ±
forcing causes η-expansion.

Discussion
Let us summarize our contribution. We proposed a highly-disciplined system of nat- ural deduction for polarized intuitionistic logic, with several noteworthy features: a proof-search procedure equivalent to focusing; polarized atomic formulas with logical structure: introduction, elimination, normalization rules; elimination rules determined by polarity: a unique, general elimination rule for positive connectives, and dedicated, Gentzen-style, elimination rules for the negative connectives; all nor- malization rules are detour-conversion rules (no commuting conversions); a perfect equivalence with focused sequent calculus, which gives the ultimate justification for the system’s design. In addition, in the Curry-Howard spirit, the proof-system comes with a programming formalism, the polarized λ-calculus λ±, which is the key to understand the connection between focusing and CBPV, precisely because it is isomorphic to the focused sequent calculus λ±, but is a natural deduction syntax
like CBPV.
We regard the recapitulation of focusing in Section 2 as an improvement over
Simmons’ system [13] in some particular aspects. First, in the design of λ± we
were very careful to keep alive all the syntactic distinctions and dualities where

they exist.  That is why λ±
has five syntactic classes and corresponding judg-

ments, with Simmon’s class of terms being here decomposed into terms, co-terms and expressions. Such move is within the spirit of focusing and polarization, which aims at a maximally disciplined syntax, and pays off: λ± makes evident the duali- ties term/co-term, return/co-return, thunk/co-thunk, binding/co-binding, negative substitution/positive substitution. Second, we distinguished, for each inference rule, its inferential (top-down) role from its role in bottom-up proof-search. As a result of this careful design, we see that proof-search comprises, not only the main phases of focusing and inversion, separated by blurring, but also the actions of accepting and collecting with which the stage of inversion ends; and, on the inferential side, we discover that polarized atoms have logical structure, having their own introduction rules.
Even if we do not insist on the logic we treat here, it is difficult to find in the literature works covering the programme we set up in the third paragraph of Section
1. For instance, the natural deduction side of the story is absent in [15,13]; and, in [3], even if a natural deduction system for polarized intuitionistic linear logic is proposed, and connected to a focused sequent calculus from [4], the former was not designed to be the perfect reflection of the latter, nor is any proof-term language developed (the same can be said about the system for classical propositional logic in [7]).
Only in [2] a similarly comprehensive programme is found, and with the goal of studying the connection between polarized intuitionistic logic and CBPV. In op. cit

a natural deduction system is obtained as the type system of CBPV in bi-directional style; and a variant of the focused sequent calculus LJF [10] together with its λ- calculus is developed. We remark, using our notation, some of the many features of the latter that distinguish it from our λ±: a variable may be declared in a context Γ with a type of any polarity; spines annotate sequents Γ[S : N ] ▶ M , with a negative r.h.s. type; the reduction rule for ⊃ triggers an operation [V/x]t, which strikingly contrasts both with our reduction rule and our concepts of positive and negative substitution. The conclusion is drawn that LJF and CBPV “are the same language, up to the question of η-expansion”. The present paper may be seen as leading to a similar conclusion; but while op. cit gets there after a comparison of abstract machines that were previously associated with each calculus, we go through a careful proof-theoretical analysis that delivers the novel and important polarized λ-calculus.

References
Andreoli, J., Logic programming with focusing proofs in linear logic, Journal of Logic and Compututation 2 (1992), pp. 297–347.
Brock-Nannestad, T., N. Guenot and D. Gustafsson, Computation in focused intuitionistic logic, in:
Proceedings of PPDP’15 (2015), pp. 43–54.
Brock-Nannestad, T. and C. Schu¨rmann, Focused natural deduction, in: Proceedings of LPAR’10, Lecture Notes in Computer Science 6397 (2010), pp. 157–171.
Chaudhuri, K., F. Pfenning and G. Price, A logical characterization of forward and backward chaining in the inverse method, J. Autom. Reasoning 40 (2008), pp. 133–177.
Esp´ırito Santo, J., The λ-calculus and the unity of structural proof theory, Theory of Computing Systems 45 (2009), pp. 963–994.
Esp´ırito Santo, J., Towards a canonical classical natural deduction system, Ann. Pure Appl. Logic 164
(2013), pp. 618–650.
Ferrari, M. and C. Fiorentini, Proof-search in natural deduction calculus for classical propositional logic, in: H. de Nivelle, editor, Proceedings TABLEAUX 2015, Lecture Notes in Computer Science 9323 (2015), pp. 237–252.
Girard, J.-Y., Y. Lafont and P. Taylor, “Proofs and Types,” Cambridge University Press, 1989.
Levy, P. B., Call-by-push-value: Decomposing call-by-value and call-by-name, Higher-Order and Symbolic Computation 19 (2006), pp. 377–414.
Liang, C. and D. Miller, Focusing and polarization in linear, intuitionistic, and classical logic, Theoretical Computer Science 410 (2009), pp. 4747–4768.
Prawitz, D., “Natural Deduction. A Proof-Theoretical Study,” Almquist and Wiksell, Stockholm, 1965.
Sieg, W. and S. Cittadini, Normal natural deduction proofs (in non-classical logics), in: Mechanizing Mathematical Reasoning, Essays in Honor of J¨org H. Siekmann on the Occasion of His 60th Birthday, Lecture Notes in Computer Science 2605 (2005), pp. 169–191.
Simmons, R. J., Structural focalization, ACM Trans. Comput. Log. 15 (2014), pp. 21:1–21:33.
von Plato, J., Natural deduction with general elimination rules, Annals of Mathematical Logic 40
(2001), pp. 541–567.
Zeilberger, N., On the unity of duality, Ann. Pure Appl. Logic 153 (2008), pp. 66–96.
