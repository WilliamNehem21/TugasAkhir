Electronic Notes in Theoretical Computer Science 112 (2005) 113–129 
www.elsevier.com/locate/entcs


Automatic Analysis of a Non-Repudiation Protocol
Ruggero Lanotte 1
Dipartimento di Scienze della Cultura, Politiche e dell’Informazione, Universit`a dell’Insubria,
Via Valleggio 11, 22100 Como, Italy
Andrea Maggiolo-Schettini2	Angelo Troina 3
Dipartimento di Informatica, Universita` di Pisa, Via F. Buonarroti 2, 56127 Pisa, Italy

Abstract
We define a probabilistic model for the analysis of a Non-Repudiation protocol that guarantees fairness, without resorting to a trusted third party, by means of a probabilistic algorithm. By using the PRISM model checker, we estimate the probability for a malicious user to break the non-repudiation property, depending on various parameters of the protocol.
Keywords: Probabilistic model, non-repudiation protocol, crypto-protocol, probabilistic algorithm, fairness, PRISM model checker.


Introduction
Repudiation is defined as denial by one of the entities involved in a communi- cation of having participated in all or part of the communication. One speaks of repudiation of the origin if the originator of a message denies having sent the message, and of repudiation of receipt if the recipient of the message denies having received the message.

1 Email: ruggero.lanotte@uninsubria.it
2 Email: maggiolo@di.unipi.it
3 Email: troina@di.unipi.it



1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.01.020


Protocols have been defined which ensure non-repudiation by making use of a trusted third party in the communication. Protocols involving no third party have been proposed in fault-less scenarios. Markowitch and Roggeman [13] give a probabilistic protocol which achieves fair non-repudiation services with- out the need of a third party and without further assumptions. In particular, the probabilistic protocol is fair up to a given tolerance ε. This tolerance depends on the values chosen for various parameters of the protocol.
In [2], the protocol is described by means of a probabilistic process alge- bra and analyzed, in an untimed setting, through a notion of probabilistic weak bisimulation. In previous work [12] we have described the protocol by using Probabilistic Timed Systems and bisimulation for Probabilistic Timed Systems, in order to show fairness up to a given tolerance. In this paper we translate the Probabilistic Timed Systems modelling the protocol, into PRISM specifications [1], in order to estimate how the tolerance varies when the parameters of the protocol are varied.
In section 2 we describe the non-repudiation protocol, in section 3 we recall Probabilistic Timed Systems, in section 4 we use the Probabilistic Timed Systems to model the protocol, in section 5 we translate our model into PRISM specifications, in section 6 we show the results obtained by running the PRISM model checker.



A Probabilistic Non-Repudiation Protocol

In this section we describe a protocol that guarantees a non-repudiation service with a certain probability without resorting to a trusted third party [13]. In particular, such a probabilistic protocol is fair up to a given tolerance ε decided by the originator. Assume that an authentication phase precedes the protocol. We denote by SignE(M ) the encryption of message M under the private key of the entity E and with {M }K the encryption of M under the key K. Finally, we use t to denote a time stamp. The protocol can be described as follows (with the notation R → O : Msg we denote a message Msg sent by R and received by O):

1. R → O : SignR(request, R, O, t)
2. O → R : SignO({M }K, O, R, t) (= M1)
3. R → O : SignR(ack1)


4.
1−p O → R : SignO(Mr, O, R, t) (= Mi) R → O : SignR(acki)
goto step 4
p	O → R : SignO(K, O, R, t) (= Mn)
5.	R → O : SignR(ackn)
The recipient R starts the protocol by sending a signed, timestamped re- quest to the originator O. This sends to R the requested message M ciphered under the key K, and waits for the ack from R (acki represents the acknowl- edgment related to message Mi). At step 4 the originator makes a probabilistic choice according to p = ε. At step 4a (taken with probability 1 − p) O sends to R a random message Mr (i.e. a dummy key), receives the ack and returns to step 4, while at step 4b (taken with probability p) O sends to R the key K necessary to decrypt the message {M }K. Upon reception of the last ack (ackn), related to the message containing the key K, the originator terminates the protocol correctly. We suppose that each acki message carries the follow- ing semantics: ”R acknowledges having received message Mi from O”. This could be easily obtained, for instance, by assuming that each acki message contains an hash of message Mi.
Intuitively, the non-repudiation of origin is guaranteed by the messages M1 and Mn (signed with the private key of O), while the non repudiation of receipt is given by the last message SignR(ackn). If the protocol terminates after the delivery of the last ack, both parties obtain their expected informa- tion, and the protocol is fair. If the protocol terminates before sending the message containing the key K, then neither the originator nor the recipient obtains any valuable information, thus preserving fairness. A strategy for a dishonest recipient consists in guessing the last message containing the key K, verifying whether a received message contains the needed key and then blocking the transmission of the last ack. Therefore, for the success of the protocol, it is necessary that the ack messages are sent back immediatly. The originator decides a deadline for the reception of each ack, after which, if the ack is not received, the protocol is stopped. Obviously, the cryptosystem must be adequately chosen, in such a way that the time needed to verify a key, by deciphering the message, is longer than the transmission time of an ack message. Anyway, a malicious recipient can try to randomly guess the message containing the key K, and in this case the probability for the recip- ient of guessing the last message depends on the parameter p chosen by the

originator.

Probabilistic Timed System
We give a definition of Probabilistic Timed Systems as a subclass of Proba- bilistic Timed Automata [5,10,3,11], assuming discrete time domain. Let us assume a set X of integer variables, with a subset Y of variables called clocks. A valuation over X is a mapping v : X → Z assigning natural values to clocks and integer values to variables in X \ Y . For a valuation v and a time value t ∈ N, let v + t denote the valuation such that (v + t)(x) = v(x), for each integer variable x ∈ X \Y , and (v + t)(y)= v(y)+ t, for each clock y ∈ Y . The set of constraints over X, denoted Φ(X), is defined by the following grammar, where φ ranges over Φ(X), x ∈ X, c ∈ Z and ∼∈ {<, ≤, =, /=, >, ≥}:
φ ::= x ∼ c | φ ∧ φ | ¬φ | φ ∨ φ | true

We write v |= φ when the valuation v satisﬁes the constraint φ. Formally, v |= x ∼ c iff v(x) ∼ c, v |= φ1 ∧ φ2 iff v |= φ1 and v |= φ2, v |= ¬φ iff v /|= φ, v |= φ1 ∨ φ2 iff v |= φ1 or v |= φ2, and v |= true.
An assignment over X is a set of expressions either of the form x' = c or of the form x' = y + c, where x, y ∈ X and c ∈ Z.
With Ass(X) we denote the set of sets of assignments {x' = ρ1,... , x' =
ρn} such that xi ∈ X and xi /= xj, for any i /= j.
Let B ∈ Ass(X); with v[B] we denote the valuation resulting after the as- signments in B. More precisely, v[B](x)= c if x' = c is in B, v[B](x)= v(y)+c if x' = y + c is in B, and v[B](x)= v(x), otherwise.
A Probabilistic Timed System A is a tuple (Σ, X, Q, q0, δ, γ, π), where:
Σ is a finite alphabet of actions. With τ ∈ Σ we denote the silent or internal
action.
X is a finite set of variables with a subset Y of clocks.
Q is a finite set of states and q0 ∈ Q is the initial state.
δ ⊆ Q × Σ × Φ(X) × Ass(X) × Q is a finite set of transitions. With δ(q), we denote the set of transitions starting from state q. More precisely, δ(q)= {(q1, α, φ, B, q2) ∈ δ | q1 = q}.
γ is an interval function such that for each e = (q1, α, φ, B, q2) ∈ δ, it holds that γ(e) is a closed interval of naturals. With |γ(e)| we denote the natural value u − l + 1, where γ(e) = [l, u]. Intuitively, γ(e) represents an interval


of time within which the time t when the transition e will be performed is probabilistically chosen. It must also hold that the constraint φ is true during the interval γ(e).
π is a probability function such that for each state q and transition e ∈ δ(q), it holds that π(e)·  1  is the probability of performing the transition e from state q in a generic time t in γ(e). Hence, we have a uniform distribution
for time t, since for each time t ∈ γ(e) the probability is fixed to π(e) ·  1 .
Σ	|γ(e)|

A conﬁguration of A is a pair (q, v), where q ∈ Q is a state of A, and v is a valuation over X. The set of all the configurations of A is denoted with SA. There is a step from a configuration s1 = (q1, v1) to a configuration s2 =
(a,t)
(q2, v2) through action a ∈ Σ, after t ∈ N time units, written s1 −−→ s2, if there
is a transition e = (q1, a, φ, B, q2) ∈ δ such that (v1 + t) |= φ, v2 = (v1 + t)[B]

and t ∈ γ(e). With prob(s
(a,t) 1 −−→
s2) we denote the probability Σ

e∈E
  1 
|γ(e)|
(a,t)

where E is the set of transitions that could have triggered the step s1 −−→ s2,
namely the set {e = (q1, a, φ, B, q2) ∈ δ | (v1 + t) |= φ ∧ v2 = (v1 + t)[B] ∧ t ∈
γ(e)}.
If s is a configuration, then with Adm(s) we denote the set of steps
(a,t)
s
−−→ s . The configuration s is called terminal iff Adm(s)= ∅.
An execution fragment starting from s0 is a finite sequence of steps σ =

(a1 ,t1 )
s
(a2 ,t2 )
(a3 ,t3)
(ak,tk)

0 −−−→ s1
−−−→ s2
−−−→ ... −−−−→ sk such that s0, s1,... , sk ∈ SA,

a1, a2,... , ak ∈ Σ. We define last(σ) = sk, |σ| = k and σj the sequence of

(a1 ,t1 )
(a2 ,t2 )
(aj,tj )

steps s0 −−−→ s1 −−−→ ... −−−→ sj, where j ≤ k. Moreover we define the
following probability


P (σ)= 
, 1	if k =0 
(ak,tk)	.

,	k−1
prob(sk−1−−−−→sk)





The execution fragment σ is called maximal iff last(σ) is terminal. We denote with ExecFrag(s) the set of execution fragments starting from s.
An execution is either a maximal execution fragment or an infinite sequence
(a1 ,t1)	(a2 ,t2 )
s0 −−−→ s1 −−−→ .. ., where s0, s1 ... ∈ SA, a1, a2,... ∈ Σ. We denote with
Exec(s) the set of executions starting from s. Finally, let σ ↑ denote the set of executions σ' such that σ ≤prefix σ', where preﬁx is the usual prefix relation over sequences. Assuming the basic notions of probability theory (see


e.g. [7]), we define the probability space on the executions starting in a given configuration s ∈ SA as follows. Let Exec(s) be the set of executions starting in s, ExecFrag(s) be the set of execution fragments starting in s, and ΣF (s) be the smallest sigma field on Exec(S) that contains the basic cylinders σ ↑, where σ ∈ ExecFrag(s). The probability measure Prob is the unique measure on ΣF (s) such that Prob(σ ↑)= P (σ).

Parallel composition
Given two probabilistic timed systems A1 and A2, and given the set L = ΣA1 ∩ ΣA2 , where ΣAi is the set of actions of the system Ai, we define the parallel composition of A1 and A2, denoted A1||pA2, where p ∈ [0, 1]. Intuitively, p represents the different advancing speeds for the two systems. The set of states of A1||pA2 is given by the cartesian product of the states of the two systems A1 and A2. Given a state (r, q) of A1||pA2, the set of transitions starting from (r, q) is obtained by the following rules:
If from state r the system A1 has a transition e = (r, a, φ, B, r') with action a /∈ L and probability p', A1||pA2 has a transition ((r, q), a, φ, B, (r', q)) with probability p · p' and interval γ(e).
If from state q the system A2 has a transition e = (q, a, φ, B, q') with action a /∈ L and probability p', A1||pA2 has a transition ((r, q), a, φ, B, (r, q')) with probability (1 − p) · p' and interval γ(e).
If from state r the system A1 has a transition e = (r, a, φ1, B1, r') with action a ∈ L and probability p', and from state q the system A2 has a transition e' = (q, a, φ2, B2, q') with probability p'' and B1 ∪B2 ∈ Ass(X), then A1 and A2 synchronize and A1||pA2 has a transition ((r, q), a, φ1∧φ2, B1∪B2, (r', q')) with probability p · p' + (1 − p) · p'' and interval γ(e) ∩ γ(e').
When we omit parameter p from the composition operator we assume the two systems to have the same advancing speeds, and hence p equal to 1.

Modelling the Non-Repudiation Protocol with Prob- abilistic Timed Systems
In this section we use the model of Probabilistic Timed Systems to formally describe the protocol seen in section 2. When no constraint is put on a transi- tion we assume that it will be taken instantly. Moreover, if for the transition starting from a certain state q we omit probabilities, then the transitions with source q are equiprobable. Hence, if a state has only one transition e, then π(e) = 1, and, if a state has two transitions e and e', then π(e) = π(e')= 1.



 l:=0 ,,correctstop
,,ack ,,unf air	,,

x:=0) q0 (
q5 (	q4

) q6


<
stop
  aJd≤x≤AD  Jx>AD	 J

request
x>AD, x:=0
message, p
x := 0, l := 1

,v,	),m ,essage, 1 − p,,
q1	firstmes	q2	x := 0  q3

 J	  Jack, ad≤x≤AD  J

Fig. 1. Representation of Orig


We start with introducing the Probabilistic Timed Systems modelling an orig- inator and a recipient behaving correctly. The originator (figure 1) is always ready to start a communication by accepting a request, sending the first mes- sage containing M encrypted with K (action f irstmes) and receiving the first ack (see steps 1, 2 and 3 of the protocol in section 2). Then, in state q3, with probability 1 − p, it sends a random message reaching state q2 and, with prob- ability p, sends the last message containing K, sets the variable l to 1, and reaches state q4 (step 4 of the protocol). We do not model value passing, hence we simply call all these actions message. In state q2 the reception of the ack message is modelled by the input action ack, while the expiration of the dead- line (represented by the constant AD) is modelled by the action stop executed when the clock x assumes a value greater than AD. The fair termination of the protocol is reached when the originator receives the last ack (step 5 of the protocol) and performs the action correctstop. The protocol terminates in an unfair way if and only if the originator does not receive the ack related to the message containing K, and in such a case it executes the action unf air. The constants ad and AD used in the constraints of the ack transitions, represent an estimation of the minimum and maximum transmission delay of an ack message, respectively. In particular, we assume that an ack, sent within the net, will always arrive at destination in time t such that ad ≤ t ≤ AD.
We modeled the actions request, f irstmes, and message as instant ac- tions, since the time needed for the transmission of such messages in the network is not interesting in our analysis.
In figure 2, we show the system representing a recipient that behaves cor- rectly. The recipient starts the protocol by sending a request, receives the first message, sends the first ack and reaches state r3, from where, whenever it receives a message, it sends an ack back. The protocol terminates when the input action correctstop is executed.
The whole system representing the protocol is defined as Orig||HRecip, where originator and recipient synchronize through actions in the set L =
{request,firstmes, ack, message, correctstop}.



y := )0  ,,
,,message ’,,

r	r
 J	 ¬Jack
r
  J


ˆ  ad≤y≤AD

request
ack
ad≤y≤AD
correctstop

v
firstmes
),,  ,,

r1	r2	r5

 J	 J	 J

Fig. 2. Representation of HRecip


y := )0  ,,
,,	,,τ, q

),,won, l = 1),,

r0	r8	r4	r5	r7

 J	 < J
	
  Jdd ≤ y ≤ DD J	 J


request
 
correctstop 
messageˆ y := 0
  τ, 1 − q
 
τ
l =0 

,v,	,,  ,,	,v,

r1	firstmes) r2
ack
) r3
( ack	r6


 J	  Jad≤y≤AD  Jad≤y≤AD J

Fig. 3. Representation of MRecip


The protocol ends in a fair correct way when the action correctstop is performed, i.e. when the system reaches the state (q0, r5). In particular, if both participants behave correctly, the unfair behavior cannot be executed; instead, it is possible to find a malicious recipient that receives the expected information and denies sending the final ack.
In figure 3 we show the system representing a malicious recipient that maximizes the probability of guessing the last message of the protocol (we assume that it knows the probability distribution chosen by the originator). It follows a Bernoulli distribution with parameter q to decide either to send the ack message (transition τ from state r4 to state r6) or to try to compute M by employing the last received message (transition from state r4 to state r5). We assume that the time necessary to decipher the message is within the interval [dd, DD]. Note that if ad + dd < AD the recipient can send an ack even after failing to decipher the message (see transition from r5 to r6). So the originator should take care of the protocol parameters ad, AD, dd and
DD. State r7 represents, instead, the state reached by the malicious recipient when correctly guessing the last message. Since we set the variable l to1 when the originator sends the last message, the malicious recipient succeeds in its strategy when in state r5 such a variable has value 1 reaching the final state r7. On the other hand, if variable l has value 0, the malicious recipient goes to state r6, from which it tries to send the ack back.
The probability of executing the action unf air for the system Orig||HRecip
is equal to 0, while the probability of executing it for the system Orig||MRecip


is (as ad + dd > AD):
∞
z = p · q ·	((1 − p) · (1 − q))i =	.
1 − (1 − p) · (1 − q)
i=0
Given 0 < p ≤ 1 chosen by the originator and 0 < q ≤ 1, the maximum value for z is p, obtained by taking q = 1. The recipient model, which optimizes the probability of violating the fairness condition, is obtained by removing the transition labelled with τ from state r4 to state r6.
The case of slow networks
As we have seen the probability for the malicious user to break the protocol is always smaller than p, which is a parameter decided by the designer of the protocol. This happens, obviously, when the condition ad + dd > AD holds. In such a case, in fact, the malicious user could only try to decrypt the first message with the last received one as key (risking in this case to stop the protocol), or send an ack to the originator.
On the other hand, the condition above holds only if the time needed to send/receive an ack within the network is smaller than the time needed to decrypt a message within a given cryptosystem. Could we still use the protocol with a reasonable margin of risk in a network where the maximum acknowledgement delay time is bigger than the maximum decryption time, or in a network that is frequently subject to congestion? If the condition ad + dd > AD does not hold, in fact, the malicious user could try to send an ack to the originator even after trying to decrypt the last received message.
We are interested in analyzing how the probability of breaking the protocol fairness increases when operating with a network with a long round trip time (high values for parameter AD), and in networks that are frequently subject to congestions (high values for the length of the interval [ad, AD]).

The PRISM tool
PRISM [1] is a probabilistic model checker that allows modeling and analyz- ing systems which exhibit a probabilistic behavior. Given a description of the system to be modelled, PRISM constructs a probabilistic model that can be either a discrete-time Markov chain (DTMC), a Markov decision process (MDP), or a continuous-time Markov chain (CTMC) [9]. On the constructed model PRISM can check properties specified by using a temporal logic (PCTL for DTMCs and MDPs, and CSL for CTMCs).


A system in PRISM is composed of modules and variables. A module has local variables and its behavior is expressed by commands of the form:
[sym] g → λ1 : u1 + ··· + λn : un
where sym is the synchronization symbol, g is a guard on all the variables in the system, and ui is a set of updates on local variables. The constant λi is the probability of performing the update ui. Constraints can be of the form x ∼ c, where c is a natural and x a variable of the whole system. Updates are expressed by using primed variables; as an example x' = 0 represents the reset to 0 of variable x.
Since we used the model of DTMC, we use the PCTL specification lan- guage [8,6,4] to specify properties of systems.
The syntax of PCTL is given by the following grammar:
φ ::= true | f alse | a | φ ∧ φ | φ ∨ φ | ¬φ | P∼p[ψ]
ψ ::= Xφ | φU≤kφ | φU φ
where a is an atomic proposition, ∼∈ {<, ≤, ≥, >} is a relational operator,
p ∈ [0, 1] is a probability, and k is an integer.
An atomic proposition a is satisfied or not by a given state of a Proba- bilistic Timed System. Symbol X denotes the “next state operator”, symbol U denotes the “until” operator, and U≤k denotes the “bounded until” (i.e. within k steps) operator. Intuitively, φ1U φ2 is satisfied when the formula φ1 holds until φ2 holds; φ1U≤kφ2 is satisfied if φ2 becomes true within k steps. Moreover, P∼p[ψ] is satisfied by a given set of computations iff the overall probability p' of the computations satisfying ψ is such that p' ∼ p.

Modeling the Non-Repudiation Protocol in PRISM
In this section we show the PRISM description of the systems introduced in section 4, and the results of some properties verified on such models 4 .
Honest Recipient
In figure 4 we show the PRISM code of the modules representing the originator (Orig) and an honest recipient (HRecip). A third module (AckDel) is used for modelling the probability distribution of the variable t representing the acknowledgement delay. We decided to use a uniform probability distribution for the variable t. So, given the random variable t that can range in the

4 Tests are done on a 1,15GHz AMD Athlon PC with Linux OS and 512 MB of RAM.


interval [ad,AD], we have that:
∀k ∈ [ad, AD]	p(t = k)=	1	,
AD − ad +1 
where p(t = k) represents the probability that variable t assumes value k.
The constant p1 used in the Orig module represents the probability p used in the Probabilistic Timed System Orig seen in section 4.

































Fig. 4. Orig + HRecip
Given the above participants, the protocol always ends in a fair correct way. When the protocol ends in a fair way, the recipient state variable r assumes value 5. As a consequence, we can verify that the protocol always

ends in a fair way by simply checking the property:
P≥1[true U (r = 5)].
The model checking for the above property took 0,004 seconds, giving as result that the property is true in all the states of the model.

Malicious Recipient
In figure 5 we show the PRISM code of the modules representing the originator (Orig) and a malicious recipient (MRecip). As in the previous case, a third module (AckDel) is used for modelling the uniform probability distribution of the variable t representing the acknowledgement delay. Also the random variable x, used in the module MRecip and representing the time needed to decrypt a message, follows a uniform distribution with range [dd,DD]. The constant q1 used in the MRecip module represents the probability q used in the Probabilistic Timed System MRecip seen in section 4.

Experimental Results

Table 1


We studied the probability for a malicious user of breaking the fairness of the non-repudiation for several settings of our model parameters. More precisely in the settings set a, set b, set c and set d, we studied the probability of breaking the protocol fairness as a parameter of the value of q1, assuming various values for the constants ad, AD, dd, DD and p1 (see table 1). Since the malicious user’s state variable r assumes value 7 when it successfully gets its information without sending the last ack, the properties we used in order to estimate the probability of breaking the protocol fairness are of the form:
P≥v[true U (r = 7)].



















































Fig. 5. Orig + MRecip

So we can approximate to v the probability of breaking the protocol when the property P≥v[true U (r = 7)] is satisfied by the initial state of the model, and the property P≥v+ε[true U (r = 7)] is not, with ε a small value. The checking procedure of a property of the above type always took less then half a second. Figures 6, 7 and 8 show the probability of breaking the protocol fairness




0.1


0.095


0.09


0.085


0.08


0.075


0.07


0.065


0.06


0.055


0.05
0.2	0.3	0.4	0.5	0.6	0.7	0.8	0.9	1
q1
Fig. 6. Varying q1 in an ideal network.
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0.2	0.3	0.4	0.5	0.6	0.7	0.8	0.9	1
q1
Fig. 7. Varying q1 in slow networks.
as a function of q1 for the parameter settings in table 1.
In the set a setting, we have that ad+dd > AD. In such a case the malicious recipient could not send an ack after trying to decrypt the first message using the last received one as key, and so the probability of breaking the protocol fairness, shown in figure 6, is given by the formula   p1·q1   . As we have seen, the maximum value for this probability is represented by the parameter p1.
In the set b, set c and set d settings we have, instead, that ad + dd ≤ AD. With these three settings we propose a first analysis of the case of slow net- works described in section 4.1. In such a case, as can be seen from figures 7 and 8, we have that the probability of breaking the protocol fairness increases as q1 goes to 1 and reaches also values that are bigger than p1.
In the settings e,f,g, we studied the probability of breaking the protocol fairness as a parameter of the value of AD, assuming various values for the




0.0062


0.006


0.0058


0.0056


0.0054


0.0052


0.005


0.0048


0.0046



0.0044
0.2	0.3	0.4	0.5	0.6	0.7	0.8	0.9	1
q1

Fig. 8. Varying q1 in a slow network, given a low p1.

Table 2

constants ad, dd, DD and p1 (see Tab. 2).
Figure 9 shows the probability of breaking the protocol fairness as a func- tion of AD for the parameter settings in Table 2. In particular those settings model the case of “slow and congestioned network” described in section 4.1.


1


0.9


0.8


0.7


0.6


0.5


0.4


0.3


0.2


0.1


0
1	10	100	1000	10000	100000
AD
Fig. 9. Analysis of congestioned networks.


Obviously, as AD increases, also the probability of breaking the non-repudiation protocol increases. But, as it can be seen from figure 9, with a small value
of p1, the protocol could be reasonably used also in the case when the time needed to send an ack is bigger than the time needed to decrypt a message.

Conclusions
We have given a model of the non-repudiation protocol proposed by Markow- itch and Roggeman [13], and we studied the probability that the protocol achieves fair non-repudiation by varying parameters of the protocol. In par- ticular, we analyzed the case when the protocol is run in networks with a long round trip time.
An important implementation detail when constructing our PRISM models regards the choice of how the probabilistic time variable t is modeled. When it was reasonably feasible we simply listed all the possible values that t could assume. We did this for the cases modeled with the specifications given in set a, set b, set c and set d, expressing the list in the second transition of the AckDel modules. Since the parameter t assumed extremely large values in the tests involving the specifications of set e, set f and set g (according to the parameter AD), it was practically infeasible to list all the values that t could assume. However, since in these latter cases the time needed to decrypt a message is assumed to be in the interval [1, 4], the only interesting values for t are AD, AD − 1,... , AD − 3. For any other value of t contained in the interval [ad, AD − 4], the malicious user succeeds in its attempt to decrypt the message and then to send the ack (in this case, in fact, t + x is always equal or smaller than AD). For this reasons, we simply used the following transition in the module AckDel:
[] (a=1) -> u1*(AD-ad-3):(a’=2)&(t’=ad) +
+ u1:(a’=2)&(t’=AD-3) + u1:(a’=2)&(t’=AD-2) + u1:(a’=2)&(t’=AD-1) + u1:(a’=2)&(t’=AD);.
Hence, the first update (concerning all the cases when t ∈ [ad, AD − 4]) is taken with probability u1 ·(AD−ad −3), while all the other interesting updates are taken with probability u1.

References
PRISM URL: http://www.cs.bham.ac.uk/~dxp/prism .
A. Aldini, R. Gorrieri: Security Analysis of a Probabilistic Non-repudiation Protocol. Proc. of PAPM-PROBMIV ’02, LNCS 2399, 17–36, 2002.
R. Alur, C. Courcoubetis and D. L. Dill: Verifying Automata Speciﬁcations of Probabilistic Real-Time Systems. Real-Time:Theory in Practice, LNCS 600, 28–44, 1992.
C. Baier and M. Kwiatowska: Model Checking for a Probabilistic Branching Time Logic with Fairness. Distributed Computing 11(3), 125–155, 1998.


D. Beauquier: On Probabilistic Timed Automata Theoretical Computer Science 292, 65–84, 2003.
A. Bianco and L. de Alfaro: Model Checking of Probabilistic and Nondeterministic Systems. Proc. Int. Conference on Foundation of Software Technologies and Theoretical Computer Science, LNCS 1026, 499–513, 1995.
P. R. Halmos: Measure Theory. Springer-Verlag, 1950.
H. Hansson and B. Jonsson: A Logic for Reasoning About Time and Probability. Formal Aspects of Computing 6(5), 512–535, 1994.
M. Kwiatkowska: Model Checking for Probability and Time: From Theory to Practice. LICS’03, IEEE CS Press, 351–360, 2003.
M. Kwiatkowska, G. Norman, R. Segala, J. Sproston: Automatic Veriﬁcation of Real-time Systems with Discrete Probability Distribution. ARTS’99, LNCS 1601, 75–95, 1999.
M. Kwiatkowska, G. Norman, R. Segala, J. Sproston: Verifying Quantitative Properties of Continuous Probabilistic Real-Time Graphs. CONCUR’00, LNCS 1877, 123–137, 2000.
R. Lanotte, A. Maggiolo-Schettini, A. Troina: Weak Bisimulation for Probabilistic Timed Automata and Applications to Security. SEFM’03, IEEE CS Press, 34–43, 2003.
O. Markowitch, Y. Roggeman: Probabilistic Non-Repudiation without Trusted Third Party. 2nd Conference on Security in Communication Network, 1999.
