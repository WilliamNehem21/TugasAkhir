Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 349 (2020) 3–23
www.elsevier.com/locate/entcs

Multi-Objective Pareto Histogram Equalization
Federico Daumas-Ladouce1,3 Miguel Garc´ıa-Torres2,4 Jos´e Luis V´azquez Noguera1,5 Diego P. Pinto-Roa1,6 Horacio Legal-Ayala2,7

Abstract
Several histogram equalization methods focus on enhancing the contrast as one of their main objectives, but usually without considering the details of the input image. Other methods seek to keep the brightness while improving the contrast, causing distortion. Among the multi-objective algorithms, the classical optimization (a priori ) techniques are commonly used given their simplicity. One of the most representative method is the weighted sum of metrics used to enhance the contrast of an image. These type of techniques, beside just returning a single image, have problems related to the weight assignment for each selected metric. To avoid the pitfalls of the algorithms just mentioned, we propose a new method called MOPHE (Multi-
Objective Pareto Histogram Equalization) which is based on Multi-objective Particle Swarm Optimization (MOPSO) approach combining different metrics in a posteriori selection criteria context. The goal of this method is three-fold: (1) improve the contrast (2) without losing important details, (3) avoiding an excessive distortion. MOPHE, is a pure multi-objective optimization algorithm, consequently a set of trade- off optimal solutions are generated, thus providing alternative solutions to the decision-maker, allowing the selection of one or more resulting images, depending on the application needs. Experimental results indicate that MOPHE is a promising approach, as it calculates a set of trade-off optimal solutions that are better than the results obtained from representative algorithms from the state-of-the-art regarding visual quality and metrics measurement.
Keywords: Contrast Enhancement, Histogram Equalization, Multi-objective Optimization, MOPHE, PSO, SMPSO


Introduction
Contrast enhancement allows to increase the perception of objects in an image. This is obtained increasing the brightness difference between objects and their back-

1 Facultad Polit´ecnica, Universidad Nacional de Asunci´on, San Lorenzo, Paraguay
2 Universidad Pablo de Olavide, Spain
3 Email: fdaumas@intro.com.py
4 Email: mgarciat@upo.es
5 Email: jlvazquez@pol.una.py
6 Email: dpinto@pol.una.py
7 Email: hlegal@pol.una.py

https://doi.org/10.1016/j.entcs.2020.02.010
1571-0661/© 2020 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

ground. Contrast enhancement in digital images can be approached with different techniques. The histogram equalization technique (HE), is the most widely used because of its simplicity and effectiveness [1]. This technique redistributes the in- tensity levels of the input image to achieve an enhancement.
MOHE (Multi-Objective Histogram Equalization) [2] is a technique that pro- poses a transformation of the histogram using some restrictions that are optimized with a Particle Swarm Optimization (PSO) approach in a mono-objective optimiza- tion context.
This work proposes a method based on a multi-objective PSO (MOPSO) called MOPHE (Multi-Objective Pareto Histogram Equalization) that intends to use the transformation defined at MOHE to optimize the contrast, maintaining, wherever possible, the original details of the input image, using the entropy as a metric. MOPHE also tries to avoid a significant change or an excessive distortion in the resulting image using the Structural Similarity Index (SSIM) [3] to measure this.
The text is organized as follows: in Section II the introduction to the histogram equalization is exposed; Section III corresponds to the proposal; the experimental results are presented in Section IV, and finally Section V presents the conclusion and future work.

Histogram Equalization Approaches
The grayscale image histogram is the graphical representation of the distribution of the gray intensities. In other words, it is the number of pixels that each gray level has in the available gray range [4].
Histogram Equalization is a method that redistributes the image gray intensities in a uniform way to enhance the contrast. The algorithms that use the histogram equalization techniques can be categorized according to the histogram transforma- tion (global equalization [5] and local equalization [5]), the nature of the algorithm (deterministic [6] and stochastic [6]) and the type of optimization used (Mono- Objective [7] and Multi-Objective [8]).

Global equalization methods
These methods aim to redistribute the image pixels values across the available gray range, applying changes to the entire histogram and considering the complete image for a better visual quality. Cheng and Shi propose in [1] the most used global equalization method because of its simplicity and effectiveness on a variety of images. Other commonly used methods such as BBHE (Brightness-preserving Bi-Histogram Equalization) proposed by Kim [9], DSIHE (Dualistic Sub-Image His- togram Equalization), which is a variant of BBHE proposed by Wang et al. [10], BHE3PL (Bi-Histogram Equalization using Three Plateau Limits) proposed by Lim et al. [11], BHE2PL (Bi-Histogram Equalization using Two Plateau Limits) pro- posed by Aquino et al. [12] and MOHE proposed by Shanmugavadivu et al. [2] are categorized as global equalization methods.

Local equalization methods
These methods try to improve certain portions of an image while at the same time avoid changing those portions that have good contrast. The improvement is achieved by segmenting the image into two or more non-overlapping blocks to equal- ize them independently and finally join them with interpolation techniques. We can cite AHE (Adaptive Histogram Equalization) proposed by Pizer et al. [13], LEICE- PSO (Locally-Equalized Image Contrast Enhancement Using PSO-Tuned Sector Equalization) proposed by Kwok et al. [14], CLAHE (Contrast Limited Adaptive Histogram Equalization) proposed by Zuiderveld et al. [15], CLHE (Constrained Local Histogram Equalization) proposed by Hui Zhu et al. [16], CLAHE-PSO pro- posed by More et al. [17] and MOPSO-CLAHE (Parameter tuning of CLAHE based on multi-objective optimization to achieve different contrast levels in medical images) proposed by More et al. [18] among these type of methods.

Deterministic Algorithms
The deterministic algorithms are predictive, thus for the same input, the same output is always obtained. In this type of algorithms each cycle goes through the same sequence of steps. A mathematical function is a simple example of these type of algorithms [6]. Among the deterministic algorithms we can find HE, BBHE, DSIHE.

Stochastic Algorithms
Stochastic algorithms are those in which there is a changing sequence of events as time passes, thus there is some probabilistic factor during the transformation process causing randomness to it [6]. Among the stochastic algorithms we can find MOHE and PSO-CLAHE, since they use optimization metaheuristics where the output is not predictive due to the inclusion of random variables.

Mono-Objective Algorithms
The mono-objective algorithms are those that maximize or minimize a single de- fined objective [7]. Kwok et al. [14] developed a local equalization strategy with mechanisms to avoid the problems produced by the contrast enhancement called LEICE-PSO among these algoritms.

Multi-Objective Algorithms
Multi-Objective algorithms are those that simultaneously maximize or minimize multiple objective functions. The proposed objective functions can be optimized to combine them into one function, or an independent objective approach known as Multi-Objective Pareto algorithms could be applied [8]. Depending on how the op- timization and decision processes are combined, the resolution of a Multi-Objective problem can be divided into two important types:

Non Pareto
These a priori preference algorithms are Multi-Objective because they optimize sev- eral objectives simultaneously during the transformation process. The non Pareto algorithms use an aggregation function that combines the objectives into a single utility value, this is equivalent of turning the Multi-Objective problem into a Mono- Objective one to optimize this unified function. Among these the PSO-CLAHE and MOHE are found.
These type of algorithms present limitations on the optimization process, such as, the conversion of a Multi-Objective problem into a Mono-Objective one, does not assure that optimal compromise solutions will be found [19]. Also the Decision- Maker should collect precise previous information, to establish the ’weight’ for each objective, thus it has to be minimized into a Mono-Objective problem [20], making difficult to fin a solution that optimizes all objectives simultaneously.
The a priori preference techniques are the Weighted sum [21], the Perturba- tion method [21], the Min-Max method [22], the Goal programming [23] and the Lexicographic method [20]

Pareto
These algorithms with a posteriori preference are preferred because they treat the objective functions independently, where each one is independently maximized or minimized to obtain a set of compromise solutions called the Pareto set. In this context, the decision-maker chooses one or several solutions according to the com- promise criterion between the objective functions. MOPSO-CLAHE is a method that can be found among these algorithms.
Given the disadvantages of the Multi-objective Non Pareto, and the lack of Global Multi-Objective Pareto algorithms, MOPHE is proposed thus it overcomes the limitations of the Non Pareto approaches.

Histogram Equalization Problems
Histogram Equalization (HE) is one of the most popular methods for digital image enhancement, but it may not be adequate in electronic products such as televi- sions, digital cameras and video cameras due to the introduction of saturation and undesired effects in small visually important areas [24]. These saturation effects not only degrade the appearance of the image, but also lead to an information loss [25]. Excessive change to the brightness level introduced by HE also leads to an un- natural image enhancement, in other words, when the brightness level is increased excessively the image quality tends to significantly degrade [26].
Figure 1 exposes the problems caused by HE. Figure 1.a is the original image. Figure 1.b is the image after histogram equalization. Unwanted effects such as noise marked by red boxes can be seen in Figure 1.c, where the intensities of gray levels are very different in relation to the original image. The detail loss can also be appreciated in Figure 1.d. The circled hair details are lost after the applied enhancement. Therefore, preserving the details without introducing saturation is


	
(a) Women	(b) Equalized Women

(c) Saturation	(d) Information loss
Fig. 1. Example image with Equalization problems exposed.
important to preserve the quality of the image.
The global equalization method MOHE has shown good performance in contrast enhancement while maintaining brightness and image details so these constraints will be used in the proposal MOPHE, which will be explained in the next section.

Multi-objective Pareto Histogram Equalization
The Multi-objective Pareto Histogram Equalization (MOPHE) is an stochastic multi-objective Pareto algorithm that globally equalizes the histogram to maximize the contrast while keeping the details of the original image considering its structure, to return a set of trade-off optimal solutions.
The following subsections will explain the equalization process, the optimization and the problem formulation.

Threshold selection
The equalization process begins with a segmentation of the image into two sub- images, for individual treatment. The threshold is used to segment the histogram and is usually obtained by a simple and efficient segmentation technique, known as thresholding [27]. This technique separates the pixels of an image F , into two categories: a background sub-image Ff and a foreground sub-image Fo, to equalize them independently.
A variety of thresholding algorithms are known in the literature as the Otsu method [28] used by MOHE, the Huang method [29], the LI method [30], the Max- Entropy method [31], the Min-Error method [32], among others. MOPHE then,

given this variety, proposes to find an optimal segmentation threshold t adaptable to any type of image, so in this work, the threshold t will be added as an optimization variable.
MOPHE uses the proposed restrictions on MOHE [2], using the optimized t. The upper limit bounding procedure in both sub-images is used to avoid the dominating high probabilities when allocating the output dynamic range.
The equalization process of an image explained above is presented in the Algo- rithm 1, where an image F and the equation variables a, b, c, d and t are received to obtain an enhanced image FE. The threshold t is a new parameter added to the equalization process in comparison to [2], which will also be optimized according to the objective functions.
Algorithm 1 Data: An image, F with ’n’ pixels in the gray levels range of [X0, XL−1, a, b, c, d and t
Result: FE, equalized image.
function Equalize() {
Step 1: Segment F in a foreground sub-image Fo and in a background sub-image Ff based on the given threshold t.
Step 2: Compute the probability density functions Po(rk) and Pf (rk) for the foreground and background
sub-images respectively.
Step 3: Apply the restrictions a, b to the background sub-image Ff , Step 4: Apply the restrictions c, d to the foreground sub-image Fo, Step 5: Equalize the sub-images independently
Step 6: Join the equalized sub-images to obtain the output image given by: FE = F′ ∪ F′
f	o
Step 7: Return FE
}
Algorithm 1. Equalization



Multi-Objective Optimization
The necessity for a further exploration in order to obtain a variety of solutions to be presented to the decision-maker leads to proposing SMPSO (Speed constrained Multi-Objective PSO) [33] as a pure multi-objective optimization metaheuristic based on PSO and will be explained next.

SMPSO
Speed-constrained Multi-objective PSO (SMPSO) [34] is one of the metaheuristics that allow the Particle Swarm Optimization (PSO) algorithm to deal with multi- objective optimization problems. Coello et al. [19], define a multi-objective opti- mization problem as the search of a variables decision vector that satisfies certain constraints and optimizes a vector of objective functions.
The a posteriori selection criterion, used by the SMPSO, treats the objectives independently, where each objective is maximized or minimized simultaneously to obtain a set of solutions called Pareto set. Afterwards the decision-maker selects one or more solutions.
Formally, a multi-objective optimization problem seeks to find the vector S = [S1, ··· , Sn] that optimizes the vectorial function:
f (S)= [f1(S), f2(S), ··· , fN (S)]	(1)

where N is the number of objective functions fl(S), ∀l ∈ {1, ··· , N} and S = [S1,··· , Sn] is the vector or particle of decision variables.
An objective function fl, formulates the l-th objective function to optimize. The objective function associates each solution in the search space with a real value describing the quality or suitability of the solution.
Since there is more than one objective function to optimize, the notion of optimal solution changes because is typically difficult to find a solution S that simultaneously optimizes all objective functions f (S). Instead of this, this technique tries to find a set of approximate solutions that are simultaneously compromised [35].
SMPSO is based on population and contains a global repository in which each particle deposits its experience for each particle, generating a file with dominant positions (leaders archive), updated in each iteration to generate a Pareto Set.
The SMPSO approach applies a speed limitation scheme to expand the scanning capacity as well as to improve the convergence speed [34].
In order to control the particle’s velocity, instead of using upper and lower value parameters which limit the step size of velocity, SMPSO adopted a constriction coefficient seen in (2) obtained from the constriction factor χ developed by Clerc and Kennedy [36]:




where,
2
χ = 2 − ϕ − √ϕ2 − 4ϕ	(2)

ϕ = ⎧⎨c1 + c2 if	c1 + c2 > 4⎫⎬

(3)

⎩	0	fi	c1 + c2 ≤ 4⎭
Furthermore, a mechanism is introduced in such a way that the accumulated velocity of each variable j (in each particle i) is further bounded by means of the following velocity constriction:
⎧⎪ δj	if	V k > δj ⎫⎪

k i,j
= ⎨−δj

k
i,j
≤ −δj⎬
(4)


where,
⎪⎪⎩V k
otherwise
⎪⎪⎭


for:
δ = upperj − lowerj j	2
(5)

upperj is equal to the upper limit value for j, to optimize.
lowerj represents the lower value that can be set to j .
Summarizing, the velocity of the particles [34] are calculated according to the PSO velocity equation, the resulting velocity is then multiplied by the constriction factor and the resulting value is constrained using (4).

The leaders archive is updated by inserting the existing non-dominated particles and deleting the dominated ones in the process [33]. SMPSO uses weak dominance [34], thus Sa ≥ Sb (Sa dominates a Sb) only if:


fl(Sa) ≥ fl(Sb)	∀l ∈ {1, ··· , N} 
fl(Sa) > fl(Sb)	∃l ∈ {1, ··· , N} 
(6)

As the leaders archive is limited, when it gets full, SMPSO uses NSGA-II’s crowding distance [37] as an operator to maintain the diversity of the particles. This distance is calculated as the sum of distances for each particle and its immediate lower and upper particles considering each objective to evaluate [38], therefore the particles with larger crowding distance are assigned to the leaders archive instead of those with lower crowding distance.
The turbulence operator adopted by SMPSO is the polynomial mutation [39], where, given a solution Sa ∈ [w, z] with being [w, z] the range of values that a

variable of the particle can take. A mutated solution Sj
for a particular variable is

created from a uniformly random number u created in the range [0, 1] as follows:

Sj =  Sa + Qleft(Sa − w),	for	u ≤ 0.5

(7)


The parameters Qleft and Qright, are calculated as follows:
Qleft = (2u)1/(1+ηm) − 1,	for	u ≤ 0.5

Qright
=1 − (2(1 − u))1/(1+ηm),	for	u > 0.5	(8)

where ηm is a user-defined index parameter by default in the range [20, 100].
The polynomial mutation is used to explore in an aleatory way new portions of the search space. This operator is in charge of introducing new genetic material while searching for solutions [38].

Objective Functions
The objective functions are the metric figures that will be used to evaluate an equalized image.
Contrast
The primary objective function of the problem is to enhance the contrast of the image using a validated metric [40] for the measurement of the image, denoted by σ. This corresponds to the standard deviation of the pixels intensities and is defined according to:

,	1

M —1 N —1




where F is the image to be evaluated, Fij represents the intensity of the pixel in its position ij and n represents the number of pixels within the image, while μ(F ) is the mean brightness of F calculated as:

XL−1
μ(F )=	P (rk) × k	(10)
k=0

(a) σ = 47, 46	(b) σ = 73, 401	(c) σ = 84, 48
Fig. 2. Examples of Lena with different σ values.
The use of n − 1 in the calculation of σ is given by the correction proposed by Bessel [41]. This correction gains popularity in the modification of the formula where instead of using n, n− 1 is used, being n is the number of observations of that sample. In this way the statistical estimation of some formulas of the population standard deviation and the population variance is improved. In case of having an hypothetical image with n = 1 the value of σ is equal to 0.
The measurement of the contrast is not always enough to say that an image is improved, since details can be lost and distortion can be added, as shown in Figure 2.c, therefore a metric that measures the details of the original image is proposed in the evaluation.
Entropy
A content metric that indicates the richness of the details of the resulting image [42], denoted by H, the entropy measures how ’good’ the gray levels used to represent the image are, i.e., the closer the entropy value of a modified image is to the original the more details have been preserved. By maximizing the Entropy of an image, the contrast of it is also increased. The entropy function for an image F is:

XL−1
H(F )= −	P (ri) log2(P (ri))	(11)
i=0
P (ri) is the occurrence probability of the i-th intensity and XL—1 represents the highest possible intensity level for F .
Figure 3 shows that a very high entropy for an image does not quantify the amplification of the noise or the distortion, for this reason a new improvement evaluation metric is introduced.


	
(a) H = 7, 445	(b) H = 7, 967
Fig. 3. Examples for Lena image with different Entropy H values.
SSIM
The value of the Structural Similarity Index (SSIM) [43] depends on three factors: the brightness, the contrast, and the attributes that represent the structure of the objects, which are modeled as a correlation. The advantages of this method include its simplicity, portability, robustness, and low computational cost. However, it has an input dependence when measuring signal distortions. The structure comparison is composed by the covariance σ(F, FE) and the standard deviations σ(F ) and σ(FE), calculated with (9), between the input image F and the compared image FE.
The SSIM equation is defined as follows:


SSIM (F, FE
	(2μ(F )μ(FE )+ D1)(2σ(F, FE )+ D2)	
)= (μ(F )2 + μ(F )2 + D )(σ(F )2 + σ(F )2 + D )
(12)

where D1 and D2 are defined constants to avoid the instability of the results if the denominator of the equation tends to zero. D1 = (q1L)2 and D2 = (q2L)2. L is the dynamic range for the pixel values. For 8-bit grayscale images, typically L = 28 − 1, with q1 = 0.01 and q2 = 0.03 by default.
SSIM is used since, in addition to being widely accepted by human subjectivity [43], when its value is maximized, distortion is minimized. This allows measuring the detail preservation between two images. In the Figure 4 different images of Lena with their values of SSIM are exposed.

(a) SSIM =1	(b) SSIM = 0, 924	(c) SSIM = 0, 550	(d) SSIM = 0, 755
Fig. 4. Lena images with different SSIM values

Now that the objective functions have been defined, we proceed with the formu- lation of the problem and thereafter explain the operation of the proposed method.

Problem Formulation
Given the next elements of the problem;
F , input image with n pixels with a size of M of height and N of width
FE, the resulting image with n pixels, size M × N . It represents the enhanced image
(X0, XL—1), range of available gray levels, which are used to represent F and FE
(in this work defined for [0,255])
a, b, c, d, constraint variables to optimize for the equalization of the sub-images
t represents the selected segmentation threshold to be optimized
S, solution vector or SMPSO particle defined as: S = [a, b, c, d, t].
R is the solution space for the problem
H is the Entropy metric of an image
σ is the Contrast metric, measured by the standard deviation of an image
SSIM is the metric that measures the Structural Similarity Index between two images
Θ, leaders archive or Pareto set, container of the best resultant particles
ψ set of resulting images, generated by the particles Pareto set Θ,
the Pareto set is the group of solutions in the Θ leaders archive obtained after the simultaneous maximization of σ, H, and SSIM performed with SMPSO. This evaluation function is defined as:
maximize	f (S)	(13)
where f (S)= [f1(S), f2(S), f3(S)], FE = Equalize(F, S), equalized image obtained using the Algorithm 1, f1(S)= σ(FE), f2(S)= H(FE), f3(S)= SSIM (F, FE).
If a particle Sa is better than another Sb, ina Pareto context it is said that the first dominates the second or Sa ≥ Sb. This is defined by (6);
MOPHE Algorithm
The Algorithm 2 presents the Pseudo Code for MOPHE. The algorithm receives an input image F , and the SMPSO parameters.
First, the swarm is initialized (Step 1), which includes the position, velocity and the best individual (mejL) of the randomly generated particles with a uniform distribution. Then, the leaders archive is initialized (Step 2) with the non-dominated solutions of the swarm using the dominance defined in (6).
The main cycle of the algorithm is executed up to a maximum number of iter- ations k. The velocities and positions of the particles are first calculated (Steps 3 and 4) and a mutation operator is used to apply turbulence with a given probability (Step 5).
The inner cycle is executed for the evaluation of each particle Si, where τ is

the amount of particles in the swarm. Then, the equalization of the image F with the particle Si is done (Step 6) using the Algorithm 1. Then an evaluation is done to the obtained image FE according to the defined objective functions (Step 7), to afterwards update the leaders archive (Step 8) and the memory of the particle (Step 9).
Finally, the solution set Ψ is generated (Step 1) from the Θ leaders archive and returned (Step 11).
The Figure 5 presents the flow of the proposed MOPHE algorithm and the results obtained by MOPHE are presented in the next section.
Algorithm 2 Data: An image, F and the SMPSO parameters. Result: Images resulting set Ψ.
function MOPHE () {
Step 1: The swarm is initialized, with τ particles.
Step 2: The leaders archive Θ is initialized, with dominating particles.
for j = 1 to k do
Step 3: Compute Speed. Eq. (4) Step 4: Update particles position.
Step 5: Turbulence is applied to the particles. Eq. (7)
for i =1 to τ do
Step 6: FEi = Equalize(F, Si) Algorithm (1) Step 7: Evaluate FEi . Eq. (13)
Step 8: Update the leaders archive Θ.
Step 9: Update the memory of the particles.
Step 10: Generate the solution set Ψ. Step 11: Return the images set Ψ.
}
Algorithm 2. MOPHE


Experimental Results
A set of images, with different intensities and distributions that have different con- trast characteristics, was used to verify the effectiveness of the proposed method. This set includes thirty selected images from the USC-SIPI [44] database and the OPENi [45] search engine.
The following sub-sections present the execution environment, the obtained re- sults and their corresponding evaluation.

Execution Environment
MOPHE was implemented with JAVA as the main programming language. In addition, free libraries such as ImageJ [46] were used for SSIM metrics and image processing, and JMetal [47] for the implementation of the SMPSO.
The Table 2 presents the comparison of the different algorithms used for the evaluation and validity of the proposed algorithm. Each execution of MOHE and MOPHE algorithms involves a number of iterations for the meta-heuristic algorithm used. MOHE and MOPHE converges in 50 iterations according to their experimen- tal tests [2]. This conclusion was obtained evaluating the obtained Pareto Sets. The comparisons were performed with 30 executions for each algorithm. The size of the swarm was adopted by experimental tests and set to 100. The size L of the leaders

archive Θ for MOPHE was set to 100, this implies that at most in each execution MOPHE returns a set of 100 resulting images.
The Table 1 shows the default values defined for the SMPSO [34] parameters which are also used in the proposal, where the random function returns a random number with a uniform distribution that is selected at each iteration.
Table 1 SMPSO default values

Experiments were performed on a MacBook Pro, with a 2.2 GHz Intel Core i7 processor and 16 GB of RAM.
The execution time for MOHE with 50 iterations on average is 8.23 seconds while for MOPHE with 50 iterations the average is 37.39 seconds and for 600 iterations it’s 11.32 minutes. In MOPHE this time increases or decreases proportionally to the number of iterations established for processing. MOPHE is a multi-objective Pareto algorithm, so more iterations are required to converge thus taking more execution time in comparison to MOHE. At the same time it should be noted that MOPHE contains solutions obtained by the implemented algorithms in addition to offering a set of alternative solutions.
Pareto Front Evaluation Framework
In this section, we discuss how the quantitative quality of the Pareto Front is mea- sured.
Our goal is to maximize the objective functions σ, H and SSIM denoted by
fl where l corresponds to each objective function, l = 1, 2, 3, to reach an efficient
Table 2 Experimentation properties




Fig. 5. MOPHE flow diagram.

Pareto Front [48], where the search space is the container for all possible solutions to the problem. Each solution Si has a point y = f (Si) associated with that solution in the criteria space. For all points yi, it can be said that yi1 ≥ yi2 or that yi1 dominates yi2 when S1 ≥ S2 according to (6).
The subset of dominant points known as Pareto Front and denoted by Θ ⊆ Y 
is defined as:
Θ= {yi ∈Y : yj /≥ yi	∀yi ∈ Y}	(14)
In other words, the efficient Pareto Set is the set of non-dominated points, and is always non-empty. A dominated point is a sub-optimal option by definition, given that a point that achieves a greater value on each objective fl exists [48].
To evaluate the results of the Pareto Set, the hypervolume measurement was used. The hypervolume measures the volume of the dominated portion within the objective space according to a reference. The hypervolume metric possesses the necessary conformity to evaluate the dominance of a Pareto Front over another [49].
The greater the value of the hypervolume, the more dominant the set of points of the Pareto Front. This makes the hypervolume a reasonable metric to measure how efficient is a Pareto Front [48].
The box plots provide a general vision of the symmetry of the distribution of data as well as showing how the dispersion of the hypervolumes calculated in regards to the median. In Figure 6 the box diagrams of the hypervolumes for the Pirate, Lena and Elaine images are presented, where the whiskers, represented by the lines that extend from the box, reach the maximum and minimum values of the series.



Box plot for Pirate hypervolumes

Box plot for Elaine hypervolumes

Box plot for Lena hypervolumes
Fig. 6. Max, min, median and mean values for the calculated hipervolumes obtained after MOPHE execution for the images: Pirate, Elaine and Lena.

The line that crosses the box represents the median of the series and the mean or average is represented by a cross in the chart. The limits of the boxes represent the quartiles where the lower extreme of the box represents 25% of the data and the upper extreme represents 75% of the data facilitating in this way the analysis of the

information when detecting that 50% of the population is within the limits of the box.
The hypervolumes were obtained after 30 independent executions for each image, and calculated over 30 Pareto sets for each image. Figure 6 presents the evolution of the calculation of the hypervolume as it runs through 600 iterations. The calculated samples were taken every 50 iterations. The exposed values show that as a greater number of iterations is reached the variance between the limits of the boxes and the maximum and minimum values become defined, allowing the user to select an appropriate amount of iterations in order to obtain the best results. For example, in Figure 6.a for the Pirate image, it can be observed that with more iterations of execution of the algorithm onwards, the variance between maximum and minimum values is very small, thus, the algorithm converges and becomes stable. This is an important fact for the assignment of the parameter related to the quantity of itera- tions to execute in MOPHE. The Levene’s statistical test [50] was used to measure the change in the homogeneity of the dispersion metrics such as the variance, the standard deviation and the range of the analyzed data. According to the test of Levene, for the data shown in Figure 6.a the variance is stabilized at 100 iterations, for the Figure 6.b this happens at 250 iterations and for the Figure 6.c, MOPHE converges at 200 iterations.
Results
The set of obtained results was compared with algorithms such as HE, BBHE, BHE2PL, BHE3PL, DSIHE, CLAHE and MOHE to demonstrate the validity of MOPHE concerning contrast enhancement and image detail preservation according to the metrics used.
Figure 7 presents non-dominated solutions (images) of the Pareto Front for the Mammogram image, where each blue and green dot (the exposed images in green) represent the values of the metrics of each image resulting from MOPHE. In the upper right corner, represented by a red dot inside a cube, is the original image. The yellow dot represents an image returned by MOHE. The orange dot is the image returned by HE. It is worth highlighting that MOPHE contains the solutions returned by MOHE and HE. In the lower left corner an image returned by MOPHE that isn’t valid according to human appreciation is exposed. This result is due to the high contrast that the output image posses, fulfilling the necessary requirements to be included in the Pareto set.
These results allow us to appreciate that MOPHE can also be used for medical images where a medical professional could select an image according to the relevant necessity.
The experimental results for the F16 image are exposed in Figure 9 and Table 3, where different algorithms are used to compare with MOPHE. Images of MOPHE were taken from a Pareto Set from a run of MOPHE with 200 iterations. It is noticeable that global histogram equalization methods do not enhance the entropy due the treatment they make over the histogram.
Figure 9 present different results obtained by MOPHE where the contrast en-




Fig. 7. Pareto front for an execution of MOPHE for the Mammogram image with 200 iterations. In blue and green resulting points. In red the original image. In yellow a MOHE solution. In orange the HE solution is shown.
hancement is clearly noticeable. The higher values for Table 3 are set to bold to an easier appreciation of the reader.
Table 3
Values of objective functions for the F16 image


A subset of results is exposed in Figure 10 for the Giraffe image and the values obtained for these images in particular are exposed in Table 4. In the experiments with the proposed MOPHE technique, 300 iterations were used. These tests pro- duced a set of a hundred resulting images. In all cases the contrast of the original image is improved. The results vary according to the position of the particle S within the Pareto Set, which generates the image.
Table 4
Values of the objective functions for the Giraffe image for different algorithms

Figure 8 presents another example of equalization for the Pirate image with the MOPHE method, where the contrast enhancement is appreciated.

			

Pirate orig- inal image
Original histogram
Ecualized image
Histogram obtained with MOPHE

Fig. 8. Pirate original image and the equalized by MOPHE.

						

F16
original


(h) CLAHE
image
HE im- age


(i) MOPHE -
1 image
BBHE
image


(j) MOPHE -
2 image
DSIHE
image


(k) MOPHE -
3 image
 BHE2PL
image


(l) MOPHE -
4 image
 BHE3PL
image


(m) MOPHE -
5 image
MOHE
image

(n) MOPHE -
6 image

Fig. 9. Original, HE, MOHE and MOPHE applied to the F16 image.


			

Girrafe original image
HE image	(c) BBHE image	(d) DSIHE image


			
BHE2PL image	(f) BHE3PL image	(g) MOHE image	(h) CLAHE image

			

(i) MOPHE -1 im-
age
MOPHE-2 im-
age
MOPHE-3 im-
age
MOPHE -4 im-
age

Fig. 10. Giraffe HE, MOHE and MOPHE images applied to the Giraffe Image.
Conclusion and Future Work
In this paper a summary of the state-of-the-art of image enhancement algorithms is presented regarding histogram transformation, where we identify that multi- objective Pareto optimization is not used much. Additionally, a multi-objective Pareto algorithm named MOPHE and its mathematical formulation is presented. MOPHE was designed and developed to enhance the contrast of an image avoiding its excessive distortion, where a set of resulting solutions with contrast, entropy and similarity in relation of compromise is obtained.
As a future work the authors propose to study a selection criteria for the resulting images, in order to ease the selection of an image to the decision-maker. Also, carry out appropriate modifications of MOPHE in order to adapt it to color images.

References
HD Cheng and XJ Shi. A simple and effective histogram equalization approach to image enhancement.
Digital Signal Processing, 14(2):158–170, 2004.

P Shanmugavadivu and K Balasubramanian. Particle swarm optimized multi-objective histogram equalization for image enhancement. Optics & Laser Technology, 57:243–251, 2014.
Zhou Wang and Alan C Bovik. A universal image quality index. Signal Processing Letters, IEEE, 9(3):81–84, 2002.


Pulung Nurtantio Andono, I Purnama, and Mochamad Hariadi. Underwater image enhancement using adaptive filtering for enhanced sift-based image matching. Journal of Theoretical & Applied Information Technology, 52(3), 2013.
Shefali Gupta and Yadwinder Kaur. Review of different local and global contrast enhancement techniques for a digital image. International Journal of Computer Applications, 100(18):18–23, 2014.
Gilles Brassard, Paul Bratley, and Rafael Garcia-Bermejo. Fundamentos de algoritmia. Prentice Hall, 1997.
Andrzej J Osiadacz. Multiple criteria optimization; theory, computation, and application, ralph e. steuer, wiley series in probability and mathematical statistics-applied, wiley, 1986, no. of pages 546. Optimal Control Applications and Methods, 10(1):89–90, 1989.
R Timothy Marler and Jasbir S Arora. Survey of multi-objective optimization methods for engineering.
Structural and multidisciplinary optimization, 26(6):369–395, 2004.
Yeong-Taeg Kim.	Contrast enhancement using brightness preserving bi-histogram equalization.
Consumer Electronics, IEEE Transactions on, 43(1):1–8, 1997.
Yu Wang, Qian Chen, and Baeomin Zhang. Image enhancement based on equal area dualistic sub-image histogram equalization method. IEEE Transactions on Consumer Electronics, 45(1):68–75, 1999.
Chen Hee Ooi, Nicholas Sia Pik Kong, and Haidi Ibrahim. Bi-histogram equalization with a plateau limit for digital image enhancement. Consumer Electronics, IEEE Transactions on, 55(4):2072–2080, 2009.
Pabla B Aquino-Mor´ınigo, Freddy R Lugo-Sol´ıs, Diego P Pinto-Roa, Horacio Legal Ayala, and Jos´e Luis Va´zquez Noguera. Bi-histogram equalization using two plateau limits. Signal, Image and Video Processing, pages 1–8, 2016.
Stephen M Pizer, E Philip Amburn, John D Austin, Robert Cromartie, Ari Geselowitz, Trey Greer, Bart ter Haar Romeny, John B Zimmerman, and Karel Zuiderveld. Adaptive histogram equalization and its variations. Computer vision, graphics, and image processing, 39(3):355–368, 1987.
NM Kwok, D Wang, QP Ha, G Fang, and SY Chen. Locally-equalized image contrast enhancement using pso-tuned sectorized equalization. In Computational Intelligence in Image Processing, pages 21–36. Springer, 2013.
Karel Zuiderveld. Contrast limited adaptive histogram equalization. In Graphics gems IV, pages 474–485. Academic Press Professional, Inc., 1994.
Hui Zhu, Francis HY Chan, and Francis K Lam. Image contrast enhancement by constrained local histogram equalization. Computer vision and image understanding, 73(2):281–290, 1999.
Luis G More, Marcos Brizuela, Jose L Vazquez, Diego Pinto, and Horacio Legal. Multi-objective optimization based on parameter tuning of clahe to achieve different contrast levels in medical images.
Luis G More, Marcos A Brizuela, Horacio Legal Ayala, Diego P Pinto-Roa, and Jose Luis Vazquez Noguera. Parameter tuning of clahe based on multi-objective optimization to achieve different contrast levels in medical images. In Image Processing (ICIP), 2015 IEEE International Conference on, pages 4644–4648. IEEE, 2015.
Carlos A Coello Coello. An updated survey of evolutionary multiobjective optimization techniques: State of the art and future trends. In Proceedings of the Congress on Evolutionary Computation, volume 1, pages 3–13, 1999.
Ching-Lai Hwang and Kwangsun Yoon. Multiple attribute decision making: methods and applications a state-of-the-art survey, volume 186. Springer Science & Business Media, 2012.
Jared L Cohon. Multiobjective programming and planning. Courier Corporation, 2013.
Juhani Koski. Multicriterion optimization in structural design. Technical report, DTIC Document, 1981.
Ralph E Steuer. Multiple criteria optimization: theory, computation, and applications. Wiley, 1986.
Qing Wang and Rabab K Ward. Fast image/video contrast enhancement based on weighted thresholded histogram equalization. Consumer Electronics, IEEE Transactions on, 53(2):757–764, 2007.
Mohammad Abdullah-Al-Wadud, Md Hasanul Kabir, M Dewan, and Oksam Chae. A dynamic histogram equalization for image contrast enhancement. Consumer Electronics, IEEE Transactions on, 53(2):593–600, 2007.


Chen Hee Ooi, Ning Kong, Haidi Ibrahim, and D Chieh. Enhancement of color microscopic images using toboggan method. In Future Computer and Communication, 2009. ICFCC 2009. International Conference on, pages 203–205. IEEE, 2009.
Emmanuel C Ifeachor and Barrie W Jervis. Digital signal processing: a practical approach. Pearson Education, 2002.
Nobuyuki Otsu. A threshold selection method from gray-level histograms. Automatica, 11(285-296):23– 27, 1975.
Liang-Kai Huang and Mao-Jiun J Wang. Image thresholding by minimizing the measures of fuzziness.
Pattern recognition, 28(1):41–51, 1995.
Chun Hung Li and CK Lee. Minimum cross entropy thresholding. Pattern Recognition, 26(4):617–625, 1993.
Jagat Narain Kapur, Prasanna K Sahoo, and Andrew KC Wong. A new method for gray-level picture thresholding using the entropy of the histogram. Computer vision, graphics, and image processing, 29(3):273–285, 1985.
Josef Kittler and John Illingworth. Minimum error thresholding. Pattern recognition, 19(1):41–47, 1986.
CA Coello Coello and Maximino Salazar Lechuga. Mopso: A proposal for multiple objective particle swarm optimization. In Evolutionary Computation, 2002. CEC’02. Proceedings of the 2002 Congress on, volume 2, pages 1051–1056. IEEE, 2002.
Antonio J Nebro, Juan Jos´e Durillo, Jose Garcia-Nieto, C Coello, Francisco Luna, and Enrique Alba. Smpso: A new pso-based metaheuristic for multi-objective optimization. In Computational intelligence in miulti-criteria decision-making, 2009. mcdm’09. ieee symposium on, pages 66–73. IEEE, 2009.
Ju¨rgen Branke, Kalyanmoy Deb, Kaisa Miettinen, and Roman Slowin´ski. Multiobjective optimization: Interactive and evolutionary approaches, volume 5252. Springer, 2008.
Maurice Clerc and James Kennedy. The particle swarm-explosion, stability, and convergence in a multidimensional complex space. Evolutionary Computation, IEEE Transactions on, 6(1):58–73, 2002.
Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. A fast and elitist multiobjective genetic algorithm: Nsga-ii. IEEE transactions on evolutionary computation, 6(2):182– 197, 2002.
Christian Von Lu¨cken, Augusto Hermosilla, and Benjam´ın Bar´an. Algoritmos evolutivos para optimizaci´on multiobjetivo: un estudio comparativo en un ambiente paralelo as´ıncrono. In X Congreso Argentino de Ciencias de la Computaci´on, 2004.
Kalyanmoy Deb. Multi-objective optimization using evolutionary algorithms, volume 16. John Wiley & Sons, 2001.
Bernard Moulden, Linda F Gatley, et al. The standard deviation of luminance as a metric for contrast in random-dot images. Perception, 19(1):79–101, 1990.
John B Neville Kennedy, Adam M Chu Pulido, Mei Mei Alicia, Francisco Paniagua Bocanegra, et al.
Estad´ıstica para ciencias e ingenier´ıa. 1982.
Du-Yih Tsai, Yongbum Lee, and Eri Matsuyama. Information entropy measure for evaluation of image quality. Journal of digital imaging, 21(3):338–347, 2008.
Zhou Wang, Alan C Bovik, and Eero P Simoncelli. Structural approaches to image quality assessment.
Handbook of Image and Video Processing, 7:18, 2005.
Banco de datos de imagenes. signal and image processing institute - University of Southern California.
http://sipi.usc.edu/database/, 2016. En l´ınea. Acceso 09-2016.
Banco de datos de imagenes. openi biomedical image search engine. http://openi.nlm.nih.gov/, 2016. En l´ınea. Acceso 09-2016.
ImageJ. An open platform for scientific image analysis.
http://imagej.net/welcome, 2016. En l´ınea. Acceso 09-2016.
JMetal.
Framework for multi-objective optimization with metaheuristics. http://jmetal.sourceforge.net/, 2016. En l´ınea. Acceso 09-2016.
Amar Shah, AC UK, and Zoubin Ghahramani. Pareto frontier learning with expensive correlated objectives. In Proceedings of The 33rd International Conference on Machine Learning, pages 1919– 1927, 2016.
Eckart Zitzler, Lothar Thiele, Marco Laumanns, Carlos M Fonseca, and Viviane Grunert Da Fonseca. Performance assessment of multiobjective optimizers: an analysis and review. IEEE transactions on evolutionary computation, 7(2):117–132, 2003.
Brian B Schultz. Levene’s test for relative variation. Systematic Biology, 34(4):449–456, 1985.
