
ORIGINAL ARTICLE
RDEL: Restart Differential Evolution algorithm with Local Search Mutation for global numerical optimization

Ali Wagdy Mohamed *

Statistics Department, Faculty of Sciences, King Abdulaziz University, P.O. Box 80203, Jeddah 21589, Saudi Arabia Operations Research Department, Institute of Statistical Studies and Research, Cairo University, Giza, Egypt

Received 8 October 2013; revised 24 June 2014; accepted 21 July 2014
Available online 24 August 2014

Abstract In this paper, a novel version of Differential Evolution (DE) algorithm based on a couple of local search mutation and a restart mechanism for solving global numerical optimization prob- lems over continuous space is presented. The proposed algorithm is named as Restart Differential Evolution algorithm with Local Search Mutation (RDEL). In RDEL, inspired by Particle Swarm Optimization (PSO), a novel local mutation rule based on the position of the best and the worst individuals among the entire population of a particular generation is introduced. The novel local mutation scheme is joined with the basic mutation rule through a linear decreasing function. The proposed local mutation scheme is proven to enhance local search tendency of the basic DE and speed up the convergence. Furthermore, a restart mechanism based on random mutation scheme and a modified Breeder Genetic Algorithm (BGA) mutation scheme is combined to avoid stagnation and/or premature convergence. Additionally, an exponent increased crossover probability rule and a uniform scaling factors of DE are introduced to promote the diversity of the population and to improve the search process, respectively. The performance of RDEL is investigated and compared with basic differential evolution, and state-of-the-art parameter adaptive differential evolution variants. It is discovered that the proposed modifications significantly improve the performance of DE in terms of quality of solution, efficiency and robustness.
© 2014 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information,
Cairo University.




* Address: Statistics Department, Faculty of Sciences, King Abdulaziz University, P.O. Box 80203, Jeddah 21589, Saudi Arabia. Tel.: +966 556269723.
E-mail address: aliwagdy@gmail.com
Peer review under responsibility of Faculty of Computers and Information, Cairo University.
Introduction

Differential Evolution (DE), proposed by Storn and Price [1,2], is a stochastic population-based search method. It shows excellent capability in solving a wide range of optimization problems with different characteristics from several fields and many real-world application problems [3]. Similar to all other Evolutionary algorithms (EAs), the evolutionary process of


1110-8665 © 2014 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. http://dx.doi.org/10.1016/j.eij.2014.07.001



DE uses mutations, crossover and selection operators at each generation to reach the global optimum. The performance of DE basically depends on the mutation strategy, the crossover operator. Besides, The intrinsic control parameters (popula- tion size NP, scaling factor F, the crossover rate Cr) play a vital role in balancing the diversity of population and conver- gence speed of the algorithm. The advantages are simplicity of implementation, reliable, speed and robustness [3]. However, DE has many weaknesses as all other evolutionary search tech- niques. Generally, DE has a good global exploration ability that can reach the region of global optimum, but it is slow at exploitation of the solution [4]. Additionally, the parameters of DE are problem dependent and it is difficult to adjust them for different problems. Moreover, DE performance decreases as search space dimensionality increases [5]. Finally, the per- formance of DE deteriorates significantly when the problems of premature convergence and/or stagnation occur [5,6]. Con- sequently, researchers have suggested many techniques to improve the basic DE. From the literature [7], these proposed modifications, improvements and developments on DE focus on adjusting control parameters in an adaptive or self-adaptive manner while there are a few attempts in developing new mutations rule. In this paper, In order to overcome these draw- backs of DE, a restart DE with novel local search mutation is proposed, referred to as RDEL, for global numerical optimiza- tion. Therefore, this study develops a new local mutation strat- egy inspired by Particle swarm optimization (PSO) in DE to enhance the local exploitation tendency and to improve the convergence rate of the algorithm. In fact, in the global PSO
version, each particle learns from the personal best position
where f is the objective function, ~x is the decision vector con- sisting of variables, and aj and bj are the lower and upper bounds for each decision variable, respectively.
In simple DE, generally known as DE/rand/1/bin [1,9],
an  initial  random  population  consists  of  NP  vectors
X→i ; i	1; 2; ... ; NP, is generated within the boundaries.
These individuals are evolved by DE operators (mutation and crossover) to generate a trial vector. A comparison between the parent and its trial vector is then done to select the vector which should survive to the next generation [9]. DE steps are discussed below:

Initialization

In order to establish a starting point for the optimization process, an initial population must be created. Typically, each decision parameter in every vector of the initial population is assigned a randomly chosen value from the boundary constraints:
x0 = aj + randj · (bj — aj)	(2)
where randj denotes a uniformly distributed number between [0, 1], generating a new value for each decision parameter.

Mutation

At generation G, for each target vector xG, a mutant vector
vG+1 is generated according to the following:
vG+1 = xG + F * (xG — xG ); r1–r2–r3–i	(3)

i	r1
and the best position achieved so far by the whole population.
r2	r3

Similarly, the main idea of the proposed novel mutation is based on that each vector learns from the position of the best


with randomly chosen indices r1, r2, r3 e {1, 2, .. ., NP}. F is a
real number to control the amplification of the difference vec- tor (xG — xG ). According to Storn and Price [2], the range of F

particular generation. Additionally, an exponent increased crossover probability rule and a uniform scaling factors of DE are introduced to promote the diversity of the population and to improve the search process, respectively. Furthermore, a restart mechanism based on random mutation scheme and a modified Breeder Genetic Algorithm (BGA) mutation scheme is combined to avoid stagnation and/or premature conver- gence. Extensive numerical experiments and comparisons have been conducted in this paper on a set of 14 well-known high dimensional benchmark functions indicate that the proposed (RDEL) algorithm is superior and competitive with conven-
is in [0, 2]. If a component of a mutant vector violates search
space, then the value of this component is generated a new using (2) or new other repair method.

Crossover

There are two main crossover types, binomial and exponential. In the binomial crossover, the target vector is mixed with the mutated vector, using the following scheme, to yield the trial vector uG+1.
( vG+1; rand(j) 6 CR or j = randn(i);

tional DE and several state-of-the-art parameter adaptive
DE variants particularly in the case of high dimensional com- plex optimization problems. The rest of the paper is organized
uG+1 =
ij
xG; rand(j) > CR  and  j–randn(i);
(4)

as follows. In Section 2, the standard DE algorithm is intro- duced with a review of its operators and parameters. Next, in Section 3, the proposed algorithm is introduced. Section 4
where j = 1, 2, .. ., D, rand(j) e [0, 1] is the jth evaluation of a
uniform random generator number. CR e [0, 1] is the crossover rate, randn(i) e {1, 2, .. ., D} is a randomly chosen index which
ensures that uG+1 gets at least one element from vG+1; otherwise

computational results of testing benchmark functions and on	i	i

the comparison with other techniques are reported and dis- cusses the effectiveness of the proposed modifications. Finally, conclusions and future works are drawn in Section 5.

Differential evolution

To start with, a bound constrained global optimization prob- lem can be defined as follows [8]:
min f(~x);~x = [x1; x2;...; xD]; S.t.xj ∈ [aj; bj]; ∀j = 1; 2;...; D  (1)
no new parent vector would be produced and the population
would not alter.
In an exponential crossover, an integer value l is randomly chosen within the range {1, D}. This integer value acts as a starting point in ~xj;G, from where the crossover or exchange
of components with →V i;G+1 starts. Another integer value L
(denotes the number of components) is also chosen from the interval {1, D-l}. The trial vector (~ui;G+1) is created by inherit- ing the values of variables in locations l to l + L from Vi;G+1 and the remaining ones from the x^j;G.




Selection

DE adapts a greedy selection strategy. If and only if the trial vector uG+1 yields as good as or a better fitness function value
ble and multimodal objective functions, while a value of CR
between 0 and 0.2 when the objective function is separable. To avoid the seeming contradictions from the literature,
some techniques have been designed to adjust control param-

i
G	G+1
G+1
G	eters in adaptive or self-adaptive manner instead of trial-and-

than xi , then ui	is set to xi	. Otherwise, the old vector xi is
retained. The selection scheme is as follows (for a minimization problem):
  uG+1;  f(uG+1) 6 f(xG)
error procedure. A Fuzzy Adaptive Differential Evolution (FADE) algorithm was proposed by Liu and Lampinen [12]. They introduced fuzzy logic controllers to adjust crossover



i	xG;	otherwise
A detailed description of standard DE algorithm is given in Table 1.

DE literature review

Due to DE cons many researchers have proposed novel tech- niques to overcome these problems as well as improve its per- formance. Storn and Price [2] suggested that NP (population size) between 5D and 10D is preferred, while 0.5 is as a good initial value of F (mutation scaling factor). The effective value of F usually lies in a range between 0.4 and 1. As for the CR (crossover rate), an initial good choice of CR = 0.1; however, since a large CR often accelerates convergence, it is appropri- ate to first try CR as 0.9 or 1 in order to check if a quick solu- tion is possible. After many experimental analysis, Ga¨mperle et al. [10] recommended that a good choice for NP is between 3D and 8D, with F = 0.6 and CR lies in [0.3, 0.9]. Contrarily, Ronkkonen et al. [11] concluded that F = 0.9 is a good com- promise between convergence speed and convergence rate. Additionally, CR depends on the nature of the problem, so CR with a value between 0.9 and 1 is suitable for non-separa-

on a set of well known benchmark functions showed that the FADE Algorithm outperformed basic DE algorithm. Like- wise, Brest et al. [9] proposed an efficient technique, named jDE, for self-adapting control parameter settings by encoding the parameters into each individual and adapting them by means of evolution. The results showed that jDE is better than, or at least comparable to, the standard DE algorithm, (FADE) algorithm and other state-of-the-art algorithms when consider- ing the quality of the solutions obtained. Along the same line, Omran et al. [13] proposed a Self-adaptive Differential Evolu- tion (SDE) algorithm. In it, F was self-adapted using a muta- tion rule similar to the mutation operator in the basic DE. The experiments conducted showed that SDE generally outper- formed DE algorithms and other evolutionary algorithms.
Zaharie [14] introduced an adaptive DE (ADE) algorithm based on the idea of controlling the population diversity and implemented a multi-population approach. Qin et al. [15] introduced a self-adaptive differential evolution (SaDE). The main idea of SaDE is to simultaneously implement two muta- tion schemes: ‘‘DE/rand/1/bin’’ and ‘‘DE/best/2/bin’’ as well as adapt mutation and crossover parameters. The Performance of SaDE evaluated on a suite of 26 several benchmark prob- lems and it was compared with the conventional DE and three adaptive DE variants. The experimental results demonstrated that SaDE was able to obtain better quality solutions and had higher success rate.
Similarly, Zhang and Sanderson [16] introduced a new dif- ferential evolution (DE) algorithm, named JADE, to improve optimization performance by implementing a new mutation strategy ‘‘DE/current-to-pbest’’ with optional external archive and updating control parameters in an adaptive manner. Simulation results show that JADE was better than, or at least competitive to, other classic or adaptive DE algorithms, Particle swarm and other evolutionary algorithms from the literature in terms of convergence performance.
Recently, inspired by SaDE algorithm and motivated by the recent success of diverse self-adaptive DE approaches, Mallipeddi et al. [17] developed a self-adaptive DE, called EPSDE, based on ensemble approach. In EPSDE, a pool of distinct mutation strategies along with a pool of values for each control parameter coexists throughout the evolution pro- cess and competes to produce offspring. The performance of EPSDE was evaluated on a set of bound constrained problems and compared with conventional DE and other state-of-the-art parameter adaptive DE variants. The comparative results showed that EPSDE algorithm outperformed conventional DE and other state-of-the-art parameter adaptive DE variants in terms of solution quality and robustness.
Practically, it can be observed that the main modifications, improvements and developments on DE focus on adjusting control parameters in an adaptive or self-adaptive manner. However, a few enhancements have been implemented to modify the structure and/or mechanism of basic DE algorithm



or to propose new mutation rules so as to enhance the local and global search ability of DE and to overcome the problems of stagnation or premature convergence [5,18–32].

RDEL: Restart Differential Evolution algorithm with Local Search mechanism
Local search mechanism
In order to enhance the local search tendency, and to acceler- ate the convergence of DE technique, a new local mutation rule is proposed based on the position of the best and the worst individuals the entire population, respectively. It is worth men- tioning that the proposed mutation is inspired by the structure of PSO algorithm that mimics social-psychological principles such as flocks of birds, schools of fish and ant colonies. Briefly, in the global PSO version, each particle learns from the personal best position and the best position achieved so far by the whole population. Similarly, the main idea of the pro- posed novel mutation is based on that each vector learns from the position of the best and the worst individuals among the entire population of a particular generation. Simply, the new position of each mutant vector depends on the position of the best and worst vectors achieved so far by the whole population of a particular generation by following the same direction of the best and similarly by avoiding the direction of the worst. The modified mutation scheme is as follows:
mG+1 = xG + F1 · (xG  — x )+ F2 · (x  — x  )	(6)
strategy is greater than the probability of using new local muta- tion. However, at latter period, it biases to exploitation ten- dency because the probability of using the local mutation scheme is greater than the probability of using the basic muta- tion rule. As a result, through generations, both global explora- tion and local exploitation capabilities are executed. On the contrary, enhancing local search ability of DE may lead to pre- mature convergence or stagnation situations. Hence, a restart mechanism based on random mutation scheme and a modified Breeder Genetic Algorithm (BGA) mutation scheme [33] is combined to avoid both situations. In this mechanism, one of two mutation operators is performed based on a predefined probability.

Restart mechanism

A restart mechanism is applied for each solution vector that satisfies the following condition: if the difference between two successive objective function values for any vector except the best one at any generation is less than or equal to a prede- termined level d for predetermined allowable number of gener- ations K, then one of the above mentioned mutations is applied with equal probability of (0.5). This restart mechanism can be expressed as follows:
If  |fc — fp| 6 d  for K generations; then
If  (u(0; 1) P 0.5); then Apply Random Mutation	(10)




where xG is a random chosen vector and xG
and xG
are the

r1	best
worst
where fc and fp indicate current and previous objective function

best and worst vectors in the entire population, respectively.
The novel local mutation scheme is joined with the basic muta- tion rule through a linear decreasing function as follows:
If  u(0; 1) P  1 —  G   Then	(7)
mG+1 = xG + F1 · (xG  — x )+ F2 · (x  — x	)	(8)
values, respectively.
After many experiments, in order to make a comparison with other algorithms with all dimensions, it has been observed that d = E 06 and K = 25 generations are the best settings for these two parameters over all benchmark problems and these values seem to maintain the convergence rate as well as avoid

i	r1
Else
best	r1
r1	worst
stagnation and/or premature convergence in case they occur.
In this paper, these settings were fixed for all dimensions with-

vG+1 = xG + F3 · (xG — xG )	(9)
out tuning them to their optimal values that may attain good




where F1, F2, F3 are three uniform random variables, u(0, 1) returns a real number between 0 and 1 with uniform random probability distribution and G is the current generation num- ber, and GEN is the maximum number of generations. Obvi- ously, from mutation Eq. (6), it can be observed that the movement of the mutant vector is carried out in the direction of the best vector and in the opposite direction to the worst one. Thus, the directed perturbation in the proposed mutation resembles the concept of gradient as the difference vector is ori-
mance of the algorithm over all the benchmark problems.
Generally, in the random mutation, for a chosen vector xi at a particular generation, a uniform random integer number jrand between [1, D] is firstly generated and then a real number between (bj aj) is calculated. Then, the jrand value from the chosen vector is replaced by the new real number to form a new vector x'. The random mutation can be described as follows.
'	  aj + randj(bj — aj)  j = jrand

ented from the worst to the best vectors [34]. Consequently, the proposed directed mutation favors exploitation since all vectors
xj =	x
otherwise ∀j = 1; .. . ; D	(11)

of population are biased by the best direction but are perturbed by the different weights. As a result, the new mutation rule has better local search ability and faster convergence rate. Thus, Therefore, this process can easily reach the location of the glo- bal and/or local optimum in the search space when solve uni- modal and multimodal problems, respectively. In the proposed RDEL algorithm, both local mutation operator and basic mutation operator are selected based on a linear decreasing probability rule Eq. (7). In fact, it can be seen that, from Eq. (7), it favor global exploration at the beginning of the search process since the probability of using the basic mutation
Therefore, it can be deduced from the above equation that random mutation increases the diversity of the DE algorithm and decreases the risk of plunging into local point or any other point in the search space. In order to perform BGA mutation, as discussed by Mu¨hlenbein and Voosen [33], on a chosen vec- tor xi at a particular generation, a uniform random integer number jrand between [1, D] is first generated and then a real number between 0.1 (bj aj) a is calculated. Then, the jrand value from the chosen vector is replaced by the new real num-
ber to form a new vector x'i. The BGA mutation can be described as follows.

x' =  xj  0.1 · (bj — aj)· a  j = jrand

; ∀j = 1; ... ; D	(12)

small random numbers besides it still has an ability to jump

j	xj	otherwise

The + or sign is chosen with probability 0.5. a is com- puted from a distribution which prefers small values. This is realized as follows.
X15



to another point in the search space with large random num-
bers so as to increase the diversity of the population.
Practically, no vector is subject to both mutations in the same generation, and only one of the above two mutations can be applied with the probability of 0.5. However, both mutations can be performed in the same generation with two different vectors. Therefore, at any particular generation, the




Before mutation, we set ai = 0. Afterward, each ai is mutated to 1 with probability pa = 1/16. Only ak contributes to the sum as in Eq. (12). On average, there will be just one ak with value 1, say am, then a is given by a = 2—m. In this paper, the modified BGA mutation is given as follows:
Crossover scheme

Crossover (CR) reflects the probability with which the trial individual inherits the actual individual’s genes [34]. As a mat-
ter of fact, if Cr is high, this will increase the population diver-

x' =  xj  randj(bj — aj)· a  j = jrand
; ∀j = 1; .. . ; D	(14)
sity. Nevertheless, the convergence rate may decrease and/or

j	xj	otherwise

where the factor of 0.1 in Eq. (12) is replaced by a uniform random number in (0, 1], because the constant setting of
0.1 ● (bj — aj) is not suitable. However, the probabilistic setting of randj ● (bj — aj) enhances the local search capability with
the population may prematurely converge. On the other hand,
small values of Cr increase the possibility of stagnation and slow down the search process. Additionally, at the early stage of the search, the diversity of the population is large because the vectors in the population are completely different from each other and the variance of the whole population is large.






Therefore, Cr should take a small value in order to avoid the exceeding level of diversity that may result in premature convergence and slow convergence rate. Then, through generations, the variance of the population will decrease as the vectors in the population become similar. Thus, in order to advance diversity and increase the convergence speed, Cr should be a large value. Based on the above analysis and dis- cussion, and in order to balance between the diversity and the convergence rate or between global exploration ability and local exploitation tendency, a dynamic non-linear increased crossover probability scheme is proposed as follows:
functions f5–f14 are multimodal. However, the generalized Rosenbrock’s function f3 is a multimodal function when D > 3 [36]. These 14 test functions are dimension wise scal- able. Definitions of the Benchmark Problems are presented in Appendix A. The initialization ranges, the range of the search space, and the position of the global minimum for these 14 benchmark functions are presented in Table 3.

Algorithms for comparisons

In order to evaluate the benefits of the proposed modifications,

Cr = Cr

max
+ (Cr

min
— Crmax
)· (1 — G/GEN)	(15)
a comparison of RDEL with six state-of-the-art self-adaptive differential evolution algorithms is made. These approaches

where G is the current generation number, GEN is the maxi-
mum number of generations, Crmin and Crmax denote the min- imum and maximum value of the Cr, respectively, and k is a positive number. The optimal settings for these parameters are Crmin = 0.1, Crmax = 0.8 and k = 4. The algorithm starts at G = 0 with Crmin = 0.1 but as G increases toward GEN, the Cr increases to reach Crmax = 0.8. As can be seen from Eq. (15), Crmin = 0.1 is considered as a good initial rate in order to avoid high level of diversity in the early stage as discussed earlier and by Storn and Price [2]. Additionally, Crmax = 0.8 is the maximum value of crossover that can balance between exploration and exploitation. k is set to its mean value as it is observed, if it is approximately less than or equal to 1 or 2 then the diversity of the population deteriorates for some func- tions and it could cause stagnation. On the other hand, if it is nearly greater than 6 or 7 it could cause premature conver- gence as the diversity sharply increases. The mean value of 4 was thus selected for all dimensions as the default value with all benchmark problems. A detailed description of RDEL is given in Table 2.

Experiments and discussion

Benchmark functions

In order to evaluate the performance of the proposed algo- rithm (RDEL), 14 well-known benchmark test functions men- tioned in [5,35] are used. All these functions are minimization problems. Among the functions, f1–f4 are unimodal and
are SaDE [15], jDE [9], ADE [14], JADE [16], SDE [13] and
EPSDE [17]. The above benchmark functions f1 to f14 are tested in 10-dimensions (10-D), 30-dimensions (30-D) and 50-dimen- sions (50-D).The maximum number of function evaluations is set to 100,00 for 10D problems, 300,000 for 30D problems and 500,000 for 50D problems. The population size is set to 50 for all dimensions with all functions. For each problem, 30 independent runs are performed and statistical results are pro- vided including the mean and the standard deviation values. The performance of different algorithms is statistically com- pared with RDEL by statistical t-test with significance level of
0.05. Numerical values 1, 0, 1 (h values) represent that the RDEL is inferior to, equal to and superior to the algorithm with which it is compared, respectively. The experiments were car- ried out on an Intel (R) core i7 processor 1.6 GHz and 4 GB- RAM. RDEL algorithm is coded and realized in MATLAB.

Experimental results and discussions

The results (mean, standard deviation of the best-of-run errors and t-test results) of the comparisons are provided in Table 4 for 10-dimensions problems, Table 5 for 30-dimensions prob- lems and Table 6 for 50-dimensions problems. Note that the best-of-the-run  error  corresponds  to  absolute  difference
between the best-of-the-run value f(→xbest) and the actual opti-
mum f* of a particular objective function i.e. f →xbest  f* . The results provided by these approaches were directly taken from Ref. [17]. In Tables 4–6, results are compared in terms
of mean error and standard deviation. From the results, it






































can be clearly concluded that RDEL can perform better than other compared algorithms in most of the cases. From Table 4, it can be obviously seen that RDEL, SaDE and EPSDE exhibit better high quality results for all benchmark problems than jDE, ADE, SDE and JADE. From the t-test results, it can be observed that RDEL is inferior to, equal to, superior to compared algorithms in 2, 53 and 19 cases, respectively out of the total 84 cases. Thus, the RDEL is always either better or equal. Table 5 indicates that the RDEL algorithm is supe- rior to the SDE algorithm in all functions in terms of average and Standard deviation values. However, RDEL is surpassed by the SDE algorithm on function f10. Generally, the perfor- mance of RDEL algorithm is superior in most of the cases to SaDE, jDE, ADE and JADE algorithms, respectively. Finally, it can be observed that the performance of the RDEL and EPSDE algorithms are almost the same and they approx- imately achieved the same results in most of the functions. All in all, from the t-test results, it can be observed that RDEL is inferior to, equal to, superior to compared algorithms in 3, 44 and 41 cases, respectively out of the total 84 cases. Thus, the RDEL is almost either better or equal. According to Table 6, as the dimensionality of the problems increases from 10D to 50D, we can conclude that the performance of all other com- pared algorithms except RDEL and EPSDE deteriorates sig- nificantly. Therefore, it can be deduced that RDEL is superior to all algorithms and is competitive with EPSDE with high quality final solution with lower mean and standard devi- ation values. Moreover, the results show that the proposed RDEL algorithm outperforms EPSDE algorithm on the most difficult functions f4, f10 and f14 by remarkable difference.
From the t-test results, it is obvious that the RDEL are inferior to, equal to, superior to compared algorithms in 6, 22 and 56 cases, respectively out of the total 84 cases. Thus, the RDEL is almost either better or equal. In summary, our proposed RDEL approach can achieve better performance than all other competitive algorithms in terms of both the quality of the final solutions and robustness.

A parametric study on RDEL

In this section, in order to investigate the impact of the pro- posed modifications, some experiments are conducted. Two different versions of RDEL and conventional DE algorithm have been tested and compared against the proposed one.

Version 1: local mutation strategy is used without both the basic mutation scheme and the random and modified (BGA) mutations. (Denoted as RDEL-1.)
Version 2: local mutation strategy is combined with ran- dom and modified (BGA) mutations without using the basic mutation strategy. (Denoted as RDEL-2.)
Conventional DE: To investigate the gained advancement over the standard DE algorithm. DE/rand/1/bin strategy with (F = 0.5, CR = 0.9) is considered for comparison. These parameter settings are extensively used in the litera- ture [1,7,9]. (Denoted as DE.)

In order to evaluate the final solution quality, efficiency, convergence rate, and robustness produced by all algorithms, the performance of the two different versions of RDEL and






conventional DE algorithm are investigated based on the 50- dimensional functions. The parameters used are fixed as same as those in Section 4.2.
The overall comparison results of the RDEL algorithm against its versions and conventional DE algorithm are sum- marized in Table 7. Furthermore, in order to analyze the con- vergence behavior of each algorithm compared, the convergence characteristics in terms of the best fitness value of the median run of each algorithm for selected functions f3, f4, f6, f8, f10, f12 and f13–f14 with dimension 50 is illustrated in Fig. 1. Indeed, the presented results in Table 7 explain that the conventional DE only obtains better results on unimodal functions f1, f2, f4 and composition function f13 while it
completely fails on all multi-modal problems. Obviously, from the t-test results, it can be detected that RDEL is inferior to, equal to, superior to DE/rand/1/bin (F = 0.5, Cr = 0.9) in 2, 2 and 10 problems, respectively. Thus, the RDEL is much more efficient, robust and effective than DE/rand/1/bin (F = 0.5, Cr = 0.9) in finding high quality solution for real parameter optimization problems with dimensions 50. Accord- ingly, it can be deduced that the superiority, efficiency and the remarkable performance of the RDEL algorithm is due to the proposed modifications. On the other hand, concretely, it can be seen that the RDEL-1 algorithm significantly outperforms the conventional DE algorithm on functions (f3, f5–f8, f11, f12 and f14). Thus, it is worth mentioning that the RDEL-1




10	5
0	0

-10	-5

-20	-10


-30

0	1	2	3	4	5

-15

0	1	2	3	4	5

Number of Function Evaluations
(a) F1
x 105
Number of Function Evaluations
(e) F5
x 105



10

5

0

-5
5

0

-5

-10


-10

0	1	2	3	4	5

-15

0	1	2	3	4	5

Number of Functions Evaluations
(b) F2
x 105
Number of Function Evaluations
(f) F6
x 105


20	10

10	0

0	-10


-10

0	1	2	3	4	5
-20

0	1	2	3	4	5

Number of Function Evaluations
(c) F3
x 105
Number of Functions Evaluations
(g) F7
x 105


6	10

4	0

2	-10


0
0	1	2	3	4	5
-20

0	1	2	3	4	5

Number of Function Evaluations
(d) F4
x 105
Number of Function Evaluations
(h) F8
x 105

Figure 1	Convergence graph (median curves) of RDEL, RDEL-1, RDEL-2 and DE on 50-dimensional test functions f1–f14.



5

0

-5

-10
5

0

-5

-10


-15

0	1	2	3	4	5

-15

0	1	2	3	4	5





3.5

3

2.5

2
Number of Function Evaluations
(i) F9
x 105




20

0

-20
Number of Function Evaluations
F12
x 105


1.5

0	1	2	3	4	5

-40

0	1	2	3	4	5

Number of Function Evaluations
(j) F10
x 105
Number of Function Evaluations
F13
x 105


10	20

0	0

-10	-20


-20

0	1	2	3	4	5
-40

0	1	2	3	4	5

Number of Function Evaluations
(k) F11
x 105
Number of Function Evaluations
F14
x 105

Fig 1. (continued)


algorithm considerably improves the final solution quality. On the contrary, conventional DE algorithm has performed better than RDEL-1 on problem (f2, f4, f9 and f10). Besides, they exhi- bit equal performance on 2 functions (f1 and f13). Therefore, it is clearly observed that the proposed local mutation scheme with the proposed increased exponent crossover rule consider- ably balances the global exploration ability and local exploita- tion tendency for the majority of functions with different characteristics much more than standard DE algorithm, namely, DE/rand/1/bin strategy with (F = 0.5, Cr = 0.9). Indeed, from the t-test results, RDEL is inferior to, equal to, superior to RDEL-1 algorithm in 0, 6 and 8 problems, respec- tively. On the other hand, it can be seen that by embedding the random mutation and modified (BGA) mutation in RDEL-1 algorithm, extreme and ultimate improvement in the perfor- mance of RDEL-2 has been detected and achieved on func- tions (f2–f4, f9–f12 and f14). However, the joining of the random mutation and modified (BGA) mutation in RDEL-1 algorithm has a slight negative influence on the final solution quality and the convergence speed of RDEL-2 algorithm on functions (f1, f5–f8). Thus, from the t-test results, it can be observed that RDEL is inferior to, equal to, superior to RDEl-2 algorithm in 0, 9 and 5 problems, respectively. Conse- quently, RDEL algorithm is always either better or equal. Overall, it can be concluded that the excellent performance of the RDEL depends on the integration between its compo-
nents and it is superior to conventional DE, RDEL-1, RDEL-2. Additionally, the convergence graph in Fig. 1, illus- trates that RDEL, RDEL-1 and RDEL-2 algorithms converge to better or global solution faster than conventional DE, in presented cases with exception to function f4 where basic DE converges faster than all compared algorithms. Accordingly, the main benefits of the proposed modifications are the remarkable balance between the exploration capability and exploitation tendency through the optimization process that leads to superior performance with fast convergence speed and the extreme robustness over the entire range of benchmark functions which are the weak points of all evolutionary algorithms.

Conclusion and future work
In order to promote the exploitation capability and speed up the convergence during the evolutionary process of the conven- tional DE algorithm, a restart Differential Evolution algo- rithm with novel local search mutation strategy for solving global numerical optimization problems over continuous space is proposed in this paper. Inspired by PSO algorithm, the pro- posed algorithm introduces a novel local mutation rule based on the position of the best and the worst individuals among the entire population of a particular generation. The mutation rule is combined with the basic mutation strategy through a

linear decreasing probability rule. The proposed mutation rule
0	vutﬃ1ﬃﬃﬃﬃXﬃﬃDﬃﬃﬃﬃﬃﬃﬃﬃﬃ1
  1 XD	!

is shown to enhance the local search capabilities of the basic
DE and to increase the convergence speed. Additionally, an exponent increased crossover probability rule is utilized to bal-
f6(x)= —20 exp @—0.2


D
i=1
z2A — exp


D
i=1
cos(2pzi)

ance the global exploration and local exploitation. Further- more, a random mutation scheme and a modified Breeder Genetic Algorithm (BGA) mutation scheme are merged to
avoid stagnation and/or premature convergence. The proposed
+ 20 + e; z = M(x — o); cond(M)= 1; o
= [o1; o2; .. . ; oD] : the shifted global optimum
Shifted Griewank’s function

RDEL algorithm has been compared with 6 recent state-of- the-art parameter adaptive differential evolution variants over
D	2	D
f7 x)=	—	cos
  zi 
+ 1; z = x — o; o

a suite of 14 bound constrained numerical optimization prob-
(	i=1 4000
i=1
,ﬃiﬃ

lems. The experimental results and comparisons have shown that the RDEL algorithm performs better in unconstrained
optimization problems with different types, complexity and
= [o1; o2; .. . ; oD] : the shifted global optimum
Shifted rotated Griewank’s function

dimensionality; it performs better with regard to the search
D	2	D
f8 x)=	—	cos
  zi 
+ 1; z = M(x — o); cond(M)

process efficiency, the final solution quality, the convergence rate, and robustness, when compared with other algorithms.
(	i=1 4000

i=1
,ﬃiﬃ

Current research efforts focus on applying the algorithm to solve high dimensions or large scale global optimization prob- lems as well as solving practical engineering optimization problems and real world applications. Finally, it would be very



= 3; o = [o1; o2; .. . ; oD] : the shifted global optimum

Shifted Rastrigin’s function
XD





Appendix A



= [o1; o2; .. . ; oD] : the shifted global optimum
Shifted rotated Rastrigin’s function
XD




f1(x)= 
D


i=1
z2; z = x — o; o = [o1; o2; ... ; oD]
= 2; o = [o1; o2; ... ; oD] : the shifted global optimum

Shifted non-continuous Rastrigin’s function

: the shifted global optimum
Shifted Schwefel’s Problem 1.2

D
f11 (x)=	(zi — 10 cos(2pzi)+ 10); yi
i=1


f2(x)= 
D	i	2
mzj
 

; z = x — o; o = [o1; o2; .. . ; oD]
zi	| zi| < 1/2
=	round(2z )/2 | z | P 1/2

: the shifted global optimum
Rosenbrock’s function
D—1
for i = 1; 2; ... ; D; z = (x — o);
o = [o1; o2; ... ; oD] : the shifted global optimum
Schwefel’s function

f (x)= X(100(x2 — x	2	x — 1)2 )
		


Shifted Schwefel’s Problem 1.2 with noise in fitness
i=1
Composition function 1 (CF1) in [35]

D	i	2

f (x)= X(Xz ) (1 + 0.4|N(0; 1)|); z = x — o; o

 

The function f13(x) (CF1) is composed by using 10



= [o1; o2; .. . ; oD] : the shifted global optimum
Shifted Ackley’s function
Composition function 6 (CF6) in [35]
The function f14(x) (CF6) is composed by using 10 dif- ferent benchmark functions, i.e. 2 rotated Rastrigin’s

0	vuﬃ1ﬃﬃﬃﬃXﬃﬃDﬃﬃﬃﬃﬃﬃﬃﬃﬃ1
XD	!
functions, 2 rotated Weierstrass functions, 2 rotated Griewank’s functions, 2 rotated Ackley’s functions and

f5(x)= —20 exp @—0.2tD
+ 20 + e; z

i=1
z2A — exp

D
i=1
cos(2pzi)
rotated Sphere functions.
Where →o indicates the position of the shifted optima, M
is a rotation matrix, and cond (M) is the condition

= x — o; o = [o1; o2; ... ; oD] : the shifted global optimum

Shifted rotated Ackley’s function
number of the matrix.



References

Storn R, Price K. Differential evolution – a simple and efficient adaptive scheme for global optimization over continuous spaces. Technical Report TR-95-012, ICSI; 1995. <http://.icsi.berke- ley.edu/~storn/litera.html>.
Storn R, Price K. Differential evolution – a simple and efficient heuristic for global optimization over continuous spaces. J Global Optim 1997;11(4):341–59.
Price K, Storn R, Lampinen J. Differential evolution: a practical approach to global optimization. Heidelberg: Springer; 2005.
Noman N, Iba H. Accelerating differential evolution using an adaptive local search. IEEE Trans Evol Comput 2008;12(1): 107–25.
Das S, Abraham A, Chakraborty UK, Konar A. Differential evolution using a neighborhood based mutation operator. IEEE Trans Evol Comput 2009;13(3):526–53.
Lampinen J, Zelinka I. On stagnation of the differential evolution algorithm. In: Matousˇek R, Osˇmera P, editors. Proceedings of Mendel 2000, 6th international conference on soft computing; 2000. p. 76–83.
Das SS, Suganthan PN. Differential evolution: a survey of the state-of-the-art. IEEE Trans Evol Comput 2011;15(1):4–31.
Xu Y, Wang L, Li L. An effective hybrid algorithm based on simplex search and differential evolution for global optimization. In: International conference on intelligent computing; 2009.
p. 341–50.
Brest J, Greiner S, Bosˇkovic´B, Mernik M, zˇumer V. Self-adapting control parameters in differential evolution: a comparative study on numerical benchmark problems. IEEE Trans Evol Comput 2006;10(6):646–57.
Ga¨mperle R, Mu¨ller SD, Koumoutsakos P. A parameter study for differential evolution. In: Grmela A, Mastorakis NE, editors. Advances in intelligent systems, fuzzy systems, evolutionary computation. Interlaken, Switzerland: WSEAS Press; 2002.
p. 293–8.
Ro¨nkko¨nen J, Kukkonen S, Price KV. Real-parameter optimiza- tion with differential evolution. Proc IEEE cong evol comput, vol.
1. Washington, DC: IEEE Computer Society; 2005. p. 506–13.
Liu J, Lampinen J. A fuzzy adaptive differential evolution algorithm. Soft Comput 2005;9(6):448–62.
Omran MGH, Salman A, Engelbrecht AP. Self-adaptive differ- ential evolution, in: Computational intelligence and security, PT 1, proceedings lecture notes in artificial intelligence; 2005. p. 192–99.
Zaharie D. Control of population diversity and adaptation in differential evolution algorithms. In: Matousek R, Osmera P, editors. Proceedings of Mendel 2003, 9th international conference on soft computing; 2003, p. 41–6.
Qin AK, Huang VL, Suganthan PN. Differential evolution algorithm with strategy adaptation for global numerical optimi- zation. IEEE Trans Evol Comput 2009;13(2):398–417.
Zhang JQ, Sanderson AC. JADE: adaptive differential evolution with optional external archive. IEEE Trans Evol Comput 2009;13(5):945–58.
Mallipeddi R, Suganthan PN, Pan QK, Tasgetiren MF. Differ- ential evolution algorithm with ensemble of parameters and mutation strategies. Appl Soft Comput 2011;11(2):1679–96.
Fan HY, Lampinen J. A trigonometric mutation approach to differential evolution. J Global Optim 2003;27(1):105–29.
Das S, Konar A, Chakraborty UK. Two improved differential evolution schemes for faster global search. In: GECCO ‘05 Proceedings of the 2005 conference on Genetic and evolutionary computation; 2005. p. 991–8.
Kaelo P, Ali MM. A numerical study of some modified differ- ential evolution. Eur J Oper Res 2006;196(3):1176–84.
Price KV. An introduction to differential evolution. In: Corne D, Dorgio M, Glover F, editors. New ideas in optimization. London, UK: McGraw-Hill; 1999. p. 79–108.
Mohamed AW, Sabry HZ. Constrained optimization based on modified differential evolution algorithm. Inf Sci 2012;194: 171–208.
Liu G, Li Y, Nie X, Zheng H. A novel clustering-based differential evolution with 2 multi-parent crossovers for global optimization. Appl Soft Comput 2012;12(2):663–81.
Omran MGH, Engelbrecht AP, Salman A. Bare bones differential evolution. Eur J Oper Res 2009;196:128–39.
Piotrowski AP, Napiorkowski JJ, Kiczko A. Differential evolu- tion algorithm with separated groups for multi-dimensional optimization problems. Eur J Oper Res 2012;216:33–46.
Mohamed AW, Sabry HZ, Abd-Elaziz T. Real parameter optimization by an effective differential evolution algorithm. Egypt Inform J 2013;14:37–53.
Ali M, Siarry P, Pant M. An efficient differential evolution based algorithm for solving multi-objective optimization problems. Eur J Oper Res 2012;2012(217):404–16.
Islam SM, Das S, Ghosh S, Roy S, Suganthan PN. An adaptive differential evolution algorithm with novel mutation and cross- over strategies for global numerical optimization. IEEE Trans Syst Man Cybern Part B: Cybern 2012;42(2):482–500.
Elsayed S, Sarker R, Essam D. Self-adaptive differential evolution incorporating a heuristic mixing of operators. Comput Optim Appl 2012:1–20.
Elsayed S, Sarker R, Ray T. Parameters adaptation in differential evolution. In: IEEE congress on evolutionary computation, Brisbane; 2012b. p. 1–8.
Triguero I, Derrac J, Garci S, Herrera F. Integrating a differential evolution feature weighting scheme into prototype generation. Neurocomputing 2012;97:332–43.
Ali M, Pant M, Abraham A. Improving differential evolution algorithm by synergizing different improvement mechanisms. ACM Trans Auton Adapt Syst 2012;7(2):1–32.
Mu¨hlenbein H, Voosen DS. Predictive models for the breeder genetic algorithm – I. Continuous parameter optimization. Evol Comput 1993;1(1):25–49.
Feoktistov V. Differential evolution: in search of solutions. Berlin,
Germany: Springer-verlag; 2006.
Liang JJ, Suganthan PN, Deb K. Novel composition test functions for numerical global optimization. In: Proceedings of IEEE swarm intelligence symposium, Pasadena, CA; 2005.
p. 68–75.
Shang YW, Qiu YH. A note on the extended Rosenbrock function. Evol Comput 2006;14(1):119–26.
