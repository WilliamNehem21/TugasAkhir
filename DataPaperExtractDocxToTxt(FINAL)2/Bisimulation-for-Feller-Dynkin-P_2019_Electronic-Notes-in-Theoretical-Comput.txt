Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 347 (2019) 45–63
www.elsevier.com/locate/entcs
Bisimulation for Feller-Dynkin Processes
Linan Chen1
Department of Mathematics and Statistics McGill University
Montreal, Canada
Florence Clerc2 Prakash Panangaden3,4
School of Computer Science McGill University Montreal, Canada

Abstract
Bisimulation is a concept that captures behavioural equivalence. It has been studied extensively on nonprob- abilistic systems and on discrete-time Markov processes and on so-called continuous-time Markov chains. In the latter, time is continuous but the evolution still proceeds in jumps. We propose two definitions of bisimulation on continuous-time stochastic processes where the evolution is a flow through time. We show that they are equivalent and we show that when restricted to discrete-time, our concept of bisimula- tion encompasses the standard discrete-time concept. The concept we introduce is not a straightforward generalization of discrete-time concepts.
Keywords: Stochastic Processes, Markov Processes, continuous time, bisimulation, diffusion.


Introduction
Bisimulation [24,26,28] is a fundamental concept in the theory of transition systems capturing a strong notion of behavioural equivalence. In particular, it is a notion stronger than that of trace equivalence. Bisimulation has been widely studied for discrete time systems where transitions happen as steps, both on discrete [23] and continuous state spaces [3,11,25]. In all these types of systems a crucial ingredient of the definition of bisimulation is the ability to talk about the next step. Thus, the general format of the definition of bisimulation is that one has some property that

1 Email: linan.chen@mcgill.ca
2 Email: florence.clerc@mail.mcgill.ca
3 Email: prakash@cs.mcgill.ca
4 This research has been supported by a grant from NSERC.

https://doi.org/10.1016/j.entcs.2019.09.004
1571-0661/© 2019 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

must hold “now” (in the states being compared) and then one says that the relation is preserved in the next step.
Some attempts have been made to talk about continuous-time [14], but even in what are called continuous-time Markov chains there is a discrete notion of time step; it is only that there is a real-valued duration associated with each state that makes such systems continuous time. They are often called “jump processes” in the mathematical literature, see, for example, [27,31], a phrase that better captures the true nature of such processes.
Outside of computer science, there is a vast range of systems that involve true continuous-time evolution: deterministic systems governed by differential equations and stochastic systems governed by “noisy” differential equations called stochastic differential equations. These have been extensively studied for over a century since the pioneering work of Einstein [16] on Brownian motion. In the computer science literature there have been studies of very special systems that feature continuous time: timed automata [2] and hybrid systems [1]. In these systems the time evo- lution is assumed to be piecewise constant (timed automata) or piecewise smooth (hybrid automata) and bisimulation is defined without recourse to talking about the next step. However, a general formalism that covers processes like diffusion is not available as far as we are aware.
In this work we aim at a general theory of bisimulation for stochastic systems with true continuous-time evolution. We focus on a class of systems called Feller- Dynkin processes for which a good mathematical theory exists. These systems are the most general version of Markov processes defined on continuous state spaces and with continuous time evolution. Such systems encompass Brownian motion and its many variants.
The obvious extension of previous definitions of bisimulation on discrete Markov processes or on jump processes fail to provide a meaningful notion of behavioural equivalence as we will illustrate later on. It is a mistake to think that one can get a reasonably good understanding of such systems by considering suitable “limits” of discrete-time systems. Intuitively, the notion of bisimulation is sensitive to small changes that are not captured when taking the limit. It is true that, for example, Brownian motion can be seen as arising as a limit, in the sense of convergence in distribution, of a discrete random walk as both the discrete time unit and the step size go to zero. However, entirely new phenomena occur with the trajectories of the Brownian motion which are not understandable through the limiting process at least not in any naive sense: the probability of being at any single state x at a given time t is zero, but the probability of hitting x before a given time s is strictly positive.
To avoid those issues, we work with the set of trajectories of the system. A number of possible ways had to be explored and in the end the particular version we present here turned out to have the desired properties: (a) corresponds to our intuition in a number of examples and (b) correctly specializes to the discrete-time case.
Section 2 explains the mathematical background on Feller-Dynkin processes and

Brownian motion. In section 3, we show why a naive extension of previous definition of bisimulation does not work and we propose a new definition of bisimulation as an equivalence relation that we illustrate on a number of examples. In section 4, we give an equivalent definition of bisimulation as a cospan of morphisms extending the previous notion of span of “zig-zag” morphisms in the discrete-time case. In section 5, we show that our definition of bisimulation is coherent with the previous definition of bisimulation in discrete time. Much remains to be done, of course, as we describe in the concluding section. We will omit most proofs in this version, however, a full version is available at [7].
Background on Feller-Dynkin processes
We assume that basic concepts like topology, measure theory and basic concepts of probability on continuous spaces are well known; see, for example [5,15,25].
The basic arena for the action is a probability space.
Definition 2.1 A probability space is a triple (S, F,P ) where S is a space (usually some kind of topological space), F is a σ-algebra (usually its Borel algebra) and P is a probability measure on F.
Given a measurable space (X, Σ) a (sub)-Markov kernel is a map τ : X × Σ → [0, 1] which is measurable in its first argument, i.e. τ (·,A ∈ Σ) : X → R is mea- surable for any fixed A in Σ and for any fixed x ∈ X, τ (x, ·) is a (sub)probability measure. These kernels describe transition probability functions.
A crucial concept is that of a ﬁltration. They will play a central role in the description of a process.
Definition 2.2 A ﬁltration on a measurable space (Ω, F) is a nondecreasing family (Ft)t≥0 of sub-σ-algebras of F, i.e. Fs ⊆ Ft ⊆F for 0 ≤ s < t < ∞.
This concept is used to capture the idea that at time t what is “known” or “observed” about the process is encoded in the sub-σ-algebra Ft.
Definition 2.3 A stochastic process is a collection of random variables (Xt)0≤t<∞ on a measurable space (Ω, F) that take values in a second measurable space (S, S) called the state space. We say that a stochastic process is adapted to a filtration (Ft)t≥0 if for each t ≥ 0 we have Xt is Ft-measurable.
Note that a stochastic process is always adapted to the filtration (Gt)t≥0, where for each t ≥ 0, Gt is defined as the σ-algebra generated by all the random vari- ables {Xs|s ≤ t}. The filtration (Gt)t≥0 is also referred to as the natural filtration associated to (Xt)t≥0.
Before stating the definition of the continuous-time processes we will be inter- ested in, let us first start by recalling the definition of their discrete-time counter- parts.
Definition 2.4 A labelled Markov process (LMP) is a triple (X, Σ,τ ) where (X, Σ) is a measurable space and τ is a Markov kernel.

We will quickly review the theory of continuous-time processes on continuous state space; much of this material is adapted from “Diffusions, Markov Processes and Martingales, Volume I” by Rogers and Williams [27] and we use their nota- tions. Another useful source is “Functional analysis for probability and stochastic processes” by A. Bobrowski [6]. Let E be a locally compact Hausdorff space with countable base and let it be equipped with the Borel σ-algebra E = B(E). E∂ is the one-point compactification of E: E∂ = E  {∂}. The physical picture is that the added state, ∂, represents a point at infinity; we will view it as an absorbing state. We say that a continuous real-valued function f on E “vanishes at infinity” if for every ε > 0 there is a compact subset K ⊂ E such that ∀x ∈ E \ K we have
|f (x)|≤ ε. This space is a Banach space with the sup norm.
Definition 2.5 A semigroup of operators on any Banach space is a family of linear continuous (bounded) operators Tt indexed by t ∈ R≥0 such that
∀s, t ≥ 0, Ts ◦ Tt = Ts+t
and
T0 = I	(the identity).
The first equation above is called the semigroup property. The operators in a semigroup are continuous however there is a useful continuity property of the semigroup as a whole.
Definition 2.6 For X a Banach space, we say that a semigroup Tt : X → X is
strongly continuous if
x	X, lim Ttx = x
t↓0
which is equivalent to saying


x	X, lim
t↓0
 Ttx − x  → 0.

Definition 2.7 A Feller-Dynkin (FD) semigroup is a strongly continuous semi- group (Pˆt)t≥0 of linear operators on C0(E) (the space of continuous functions on E which vanish at infinity) satisfying the additional condition:
∀t ≥ 0	∀f ∈ C0(E), if	0 ≤ f ≤ 1, then	0 ≤ Pˆtf ≤ 1
The following important proposition relates these FD semigroups with Markov processes which allows one to see the connection with more familiar probabilistic transition systems.
Proposition 2.8 Given such an FD semigroup, it is possible to deﬁne a unique family of sub-Markov kernels (Pt)t≥0 : E ×E → [0, 1] such that for all t ≥ 0 and

f ∈ C0(E),
Pˆtf (x)= ∫

f (y)Pt(x, dy).

A very important ingredient in the theory is the space of trajectories of a FD process (FD semigroup) as a probability space. This space does not appear explic- itly in the study of labelled Markov processes but one does see it in the study of continuous-time Markov chains and jump processes.
Definition 2.9 We define a trajectory ω on E∂ to be a cadlag 5 function [0, ∞) →
E∂ such that if either ω(t−) := lims<t,s→t ω(s)= ∂ or ω(t)= ∂ then ∀u ≥ t, ω(u)= 
∂. We can extend ω to a map from [0, ∞] to E∂ by setting ω(∞)= ∂.
It is possible to associate to such an FD semigroup a canonical FD process. Let Ω be the set of trajectories ω : [0, ∞) → E∂.
Definition 2.10 The canonical FD process associated to the FD semigroup (Pˆt) is (Ω, G, (Gt)t≥0, (Xt)0≤t≤∞, (Px)x∈E )
where
Xt(ω)= ω(t)
G = σ(Xs | 0 ≤ s < ∞) 6 , Gt = σ(Xs | 0 ≤ s ≤ t)
given any probability measure μ on E∂, by the Kolmogorov extension theorem, there exists a unique probability measure Pμ on (Ω, G) such that for all n ∈ N, 0 ≤ t1 ≤ t2 ≤ ... ≤ tn and x0, x1, ..., xn in E∂,


Pμ(X0 ∈ dx0, Xt
∈ dx1, ..., Xt  ∈ dxn)= μ(dx0)P	(x0, dx1)...P
(xn−1, dxn) 7

1	n	t1
tn−tn−1



where P +∂
is the Markov kernel extending the Markov kernel Pt to E∂ by

P +∂(x, {∂})=1 − Pt(x, E) and P +∂(∂, {∂}) = 1. We set Px = Pδx .
This is the version of the system that will be most useful for us. In order to bring it more in line with the kind of transition systems that have hitherto been studied in the computer science literature we introduce a finite set of atomic propositions AP and such a FD process is equipped with a function obs : E → 2AP . This function is extended to a function obs : E∂ → 2AP  {∂} by setting obs(∂)= ∂.
Instead of following the dynamics of the system step by step as one does in a discrete system we have to study the behaviour of sets of trajectories. The crucial ingredient is the distribution Px which gives a measure on the space of trajectories for a system started at the point x.
Brownian motion as a FD process
Brownian motion is a stochastic process describing the irregular motion of a particle being buffeted by invisible molecules. Now its range of applicability extends far beyond its initial application [22]. The following definition is from [22].

5 By cadlag we mean right-continuous with left limits.
6 The σ-algebra G is the same as the one induced by the Skorohod metric, see theorem 16.6 of [4]
7 The dxi in this equation should be understood as infinitesimal volumes. This notation is standard in probabilities and should be understood by integrating it over measurable state sets Ci.

Definition 2.11 A standard one-dimensional Brownian motion is a Markov process adapted to the filtration (Ft)t≥0,
B = (Wt, Ft), 0 ≤ t < ∞
defined on a probability space (Ω, F,P ) with the properties
W0 = 0 almost surely,
for 0 ≤ s < t, Wt − Ws is independent of Fs and is normally distributed with mean 0 and variance t − s.
In this very special process, one can start at any place, there is an overall translation symmetry which makes calculations more tractable. In order to do any calculations we use the following fundamental formula: If the process is at x at time 0 then at time t the probability that it is in the (measurable) set D is given by

Pt(x, D)= ∫


y∈D
  1 
√2πt exp
(x	y)2
—	2t
dy.

The associated FD semigroup is the following: for f ∈ C0(R) and x ∈ R,


Pˆt(f )(x)= 
y
 f (y)
√2πt exp
(x	y)2


—	2t
dy.

Bisimulation
The concept of bisimulation is fundamental and its history is well documented [28]. We recall the definition of bisimulation on continuous state spaces with discrete time steps [11,25], we call it a DT-bisimulation to emphasize that it pertains to discrete- time systems. We consider LMPs equipped with a family of atomic propositions AP where A ∈ AP is interpreted on a specific LMP as a subset of the state space represented by its characteristic function χA.
Definition 3.1 Given an LMP (X, Σ, τ, (χA)A∈AP ), a DT-bisimulation R is an equivalence relation on X such that if xRy, then
for all A ∈ AP , χA(x)= χA(y)
for all R-closed sets C ∈ Σ (i.e. if z ∈ C and yRz, then y ∈ C), τ (x, C) = 
τ (y, C).
Naive approach
The key idea of bisimulation is that “what can be observed now is the same” and bisimulation is preserved by the evolution. In order to capture this we need two con- ditions: the first captures what is immediately observable and the second captures the idea that the evolution preserves bisimulation.
Consider the naive extension of bisimulation in discrete time: let R be an equiv- alence relation on the state space E such that whenever x R y (x, y ∈ E):

(initiation 1) obs(x)= obs(y), and
(induction 1) for all R-closed sets C in E , for all times t, Pt(x, C)= Pt(y, C) Let us illustrate on an example why this definition is not enough.
We consider the case of Brownian motion on the reals where there is a single
atomic proposition marking 0: obs(0) = 1 and obs(x)=0 for x /= 0. Intuitively, we would like that two states x and y are bisimilar if and only if |x| = |y| as the only symmetry that this system has is point reflection with respect to 0.
However, the two conditions (initiation 1) and (induction 1) are not strong enough to enforce that this equivalence relation is the greatest bisimulation.
Let us define the equivalence
R = (R∗ × R∗) ∪ {(0, 0)} where R∗ = R \ {0}.
This equivalence satisfies both conditions (induction 1) and (initiation 1). The last one follows directly from the definitions of R and obs.
For the induction condition, the only R-closed sets are ∅, {0}, R∗ and R, and for any state z /= 0 and time t ≥ 0, Pt(z, ∅)= Pt(z, {0})=0 and Pt(z, R∗)= Pt(z, R)= 1.
For the proof that our notion of bisimulation yields the expected greatest bisim- ulation, we refer the reader to section 3.4.
Deﬁnition
As we have just shown, unlike in the discrete-time case we cannot just say that the “next step” preserves the relation. Therefore we have to talk about the trajectories; but then we need to choose the right condition on sets of trajectories.
Definition 3.2 An equivalence relation R on the state space E is a bisimulation if whenever xRy, the following conditions are satisfied:
(initiation 1) obs(x)= obs(y), and
(induction 2) for all R-closed sets B in G, Px(B) = Py(B) where by R-closed, we mean that for all ω ∈ B if a trajectory ωj is such that for all time t ≥ 0, ω(t)Rωj(t), then ωj ∈ B.
Clearly equality is trivially a bisimulation, and furthermore, by definition of Px, condition (induction 2) implies (induction 1).
We have chosen to give names to the conditions. The reason for choosing those names will become clear in section 3.3.2.
Remark 3.3 Usually, for discrete time, instead of a single kernel τ , a labelled Markov process is a family of Markov kernels indexed by a family of actions. These actions correspond to the environment or the user acting on the process. The second condition of bisimulation is then stated on the corresponding Markov kernels for all actions. It is possible to do the same for continuous-time. We can consider a family of FD processes indexed by a set of actions. Condition (induction 2) is then stated

for all these actions. The remaining of this paper can also be adapted to several actions in a similar way.
Lemma 3.4 An equivalence relation R is a bisimulation if and only if whenever
xRy, the following conditions are satisﬁed:
(initiation 2) for all obs-closed sets B in G, Px(B)= Py(B) where by obs-closed, we mean that for all ω ∈ B if a trajectory ωj is such that obs ◦ ω = obs ◦ ωj, then ωj ∈ B.
(induction 2) for all R-closed sets B in G, Px(B)= Py(B).
Definition 3.5 Two states are bisimilar if there is a bisimulation that relates them.
Proposition 3.6 The relation “is bisimilar to” is the greatest bisimulation.
We now consider several examples and give their greatest bisimulation. Proving that an equivalence is the greatest bisimulation follows the following outline: first proving that the equivalence satisfies conditions (initiation 1) and (induction 2) (and hence it is a bisimulation), and then using (initiation 2) to prove that it is the greatest bisimulation possible.
Basic examples
Deterministic Drift
Consider a deterministic drift on the real line R with constant speed a ∈ R (i.e. in terms of random variable Xt = X0 + at). We consider two cases: with 0 as the only distinguished point and with all the integers distinguished from the other points.
With zero distinguished:
Consider the case when there is a single atomic proposition called obs, and
obs(x) = 1 if and only if x = 0.
Proposition 3.7 Two states x and y are bisimilar if and only if either ax > 0 and
ay > 0 or x = y.
Proof. Without loss of generality, we can assume that a > 0 (case a < 0 works in a similar fashion and case a = 0 is trivial). Denote R the corresponding relation.
Consider x and y such that xRy. We have to consider two cases:
If obs(x) = 1, this means that x = 0. The state 0 is only bisimilar to itself, which means that y = 0 and therefore obs(x)= obs(y).
If obs(x) = 0, this means that x /= 0. The state 0 is only bisimilar to itself, which means that y /= 0 and therefore obs(x)= obs(y).
Consider a measurable set B. First, for any z ∈ R, we denote ωz the trajectory
ωz(t)= z + at and note that Pz(B)= δB(ωz).
Consider an R-closed measurable set B. We want to show that Px(B)= Py(B).
For that, there are two cases to consider:
either x ≤ 0, in which case x = y since xRy and therefore Px(B)= Py(B),

or x > 0, in which case y > 0. In that case, for all t, ωx(t) > 0 and ωy(t) > 0 and in particular for all time t, ωx(t) R ωy(t). Since B is R-closed, ωx ∈ B if and only if ωy ∈ B.
This concludes the second part of the proof.
We now prove that this is the greatest such bisimulation. We are using condition (initiation 2) for that:
Consider x > 0 and y ≤ 0. For all t ≥ 0, ωx(t) /= 0, but ωy(−y/a) = 0. Define B = {ω | ω(−y/a) = 0}. This set is obs-closed but Px(B) = 0 and Py(B) = 1. These two states cannot be bisimilar.
Consider x, y ≤ 0.  Note that ωx(t) /= 0 for all t /= −x/a.  Define B =
{ω | ω(−y/a) = 0}. We have that Py(B) = 1 and the only way Px(B) = 1 is to have −x/a = −y/a, i.e. x = y. This concludes the proof.	2

With all integers distinguished:
We consider the case when there is a single atomic proposition and obs(x)=1 if and only if x ∈ Z. In this case two states x and y are bisimilar if and only if x − [x⊆ = y − [y⊆, i.e. x − y ∈ Z. This is intuitive and it is worth seeing that our definition captures this.
Fork
One could think that since trajectories are already included in the initiation con- dition (initiation 2), the additional induction condition is not necessary. However, this example illustrates the crucial role of the induction condition in the definition of bisimulation. It is an extension of the standard “vending machine” example in discrete time to our continuous-time setting and it shows that even the condition (induction 1) are enough to discriminate between states that (initiation 2) cannot distinguish.
The full depiction of this example can be found in the full version. Consider the following state space:

There are two atomic propositions (denoted P and Q on the diagram), that are satisfied by the final state of some of the branches. The process is a drift at a constant speed to the right. When it reaches a fork, it moves to either branch with probability 1/2 (and stops when he hits an atomic proposition).
The basic claim is that the states x0 and y0 cannot be bisimilar since states x1, x2, y1 cannot be bisimilar either. This is where condition (induction 2) is really important since the two states x0 and y0 have similar traces as they both satisfy

the condition (initiation 2).

Examples based on Brownian motion
Standard Brownian Motion
With zero distinguished:
Consider the case when there is a single atomic proposition and obs(x) = 1 if and only if x = 0.
Proposition 3.8 Two states x and y are bisimilar if and only if |x| = |y|.
Proof. First let us prove that R = {(x, y) | |x| = |y|} is a bisimulation.
Consider x R y, i.e. |x| = |y|. This means that x = 0 if and only if y = 0. In other terms, obs(x) = 1 if and only if obs(y) = 1 and hence obs(x)= obs(y).
Let now B be an R-closed measurable set of trajectories. This means that ω ∈ B if and only if −ω ∈ B since |ω(t)| = |−ω(t)| for all time t ≥ 0. And therefore Px(B)= P−x(−B)= P−x(B) where −B := {t '→ −ω(t) | ω ∈ B}.
There now remains to show that this is the greatest bisimulation. It can easily be seen that 0 and x /=0 since obs(0) /= obs(x).
Now Consider two different states x and y. We can define the set Bt = {ω | ∃s < t ω(s) = 0}. This set is obs-closed. It can also be expressed as Bt = T0−1([0, t)) where T0 is the hitting time for Brownian motion and we know that for any state
z,

Pz(B )=  2 ∫ ∞

e−s2/2ds


|z|  t
If |x| /= |y|, it is impossible to have that Px(Bt) = Py(Bt). This proves that no equivalence strictly bigger than R may satisfy (initiation 2).	2

With all integers distinguished:
Consider the case when there is a single atomic proposition and obs(x) = 1 if and only if x ∈ Z.
Proposition 3.9 Two states x and y are bisimilar if and only if x − [x⊆ = y − [y⊆
or ≥y|− y .
This is not trivial and requires a slightly delicate argument which we omit in this short version.

With an interval distinguished:
Consider the case when there is a single atomic proposition and obs(x) = 1 if and only if x ∈ [−1, 1].
Proposition 3.10 Two states x and y are bisimilar if and only if |x| = |y|.
This is also a calculation that requires explicit properties of Brownian motion and the use of Laplace transforms; we describe it in the full paper.

Brownian motion with drift
Consider a Brownian process with drift: Wtj = Wt + at (where Wt is the standard Brownian motion and a > 0, note that the case a < 0 is symmetric).

With zero distinguished:
Consider the case when there is a single atomic proposition and obs(x) = 1 if and only if x = 0.
Proposition 3.11 Two states x and y are bisimilar if and only if x = y.
Proof. As stated before, the equivalence where a state is only related to itself is a bisimlation.
Let us now show that this is the greatest bisimulation. Consider two different states x and y. Similarly to what we did for the standard Brownian motion, we can rule out the case where x =0 (and y /= 0) or y =0 (and x /= 0) by simply looking at the function obs.
We can define the set Bt = {ω | ∃s < t ω(s) = 0}. This set is obs-closed. It can also be expressed as Bt = T0—1([0, t)) where T0 is the hitting time for Brownian motion and we know that for any state z,

z	 |z| 
(z + as)2 




Since we have that for all t, Px(Bt)= Py(Bt), then we also have that for all s ≥ 0,


|x| exp
(x + as)2


2s
= |y| exp
(y + as)2

2s

Since x, y /= 0, we have that for all s, t ≥ 0,


(y + as)2
+
2s
(x + as)2
2s	= −
(y + at)2
+
2t
(x + at)2


2t

which is equivalent to (s − t)y2 = (s − t)x2. This means that in that case |x| = |y|. Going back to the original expression, we have that for all s ≥ 0, −(x + as)2 =
−(y + as)2 and therefore 2asx = 2asy. Since a /= 0, we get that x = y in order to have (initiation 2).	2

With all integers distinguished:
Consider the case when there is a single atomic proposition and obs(x) = 1 if and only if x ∈ Z.
Proposition 3.12 Two states x and y are bisimilar if and only if x−[x⊆ = y−[y⊆.
This is quite a long proof but interesting as it shows many of the complexities of dealing with continuous time. The proof is in the full paper.

With an interval distinguished:
Consider the case when there is a single atomic proposition and obs(x) = 1 if and only if x ∈ [−1, 1]. Here also we have the intuitive result but it requires some work to prove it.
Proposition 3.13 Two states x and y are bisimilar if and only if x = y.
Brownian motion with absorbing wall
Another usual variation on Brownian motion is to add boundaries and to consider that the process does not move anymore or dies once it has hit a boundary. Since all our previous examples involved probability distributions (as opposed to subproba- bilities), we will see the boundary as killing the process.
Absorption at 0:
Consider the case of Brownian motion with absorption at the origin and without any atomic proposition. The state space is R>0.
Proposition 3.14 Two states x and y are bisimilar if and only if x = y.
Proof. We know that equality is a bisimulation. Let us prove that it is the greatest. For all t ≥ 0, the set Bt = {ω | obs ◦ ω(t) = ∂} is obs-closed. Let us clarify the intuition behind that set Bt: it is the set of trajectories such that the process
following one of these trajectories is dead at time t.
For all state x ≥ 0,


x abs
(Bt)= Px(T0 < t)
 2  ∫ +∞

 



—z2/2

The only way Px
(Bt)= Py
(Bt) is therefore to have x = y.	2


Absorption at 0 and b:
Consider the case of Brownian motion with absorption at the origin and at b > 0 and without any atomic proposition. The state space is therefore (0, b).
Proposition 3.15 Two states x and y are bisimilar if and only if x = y or x =
b − y.
Absorption at 0 and 4b with atomic proposition at b:
In the full version of the paper, we also consider the case where the atomic proposition distinguishes a state that is in the middle of the state space. In the following case, we break that symmetry.
Consider the case of Brownian motion with absorption at the origin and at 4b > 0, so the state space is (0, 4b), and with a single atomic proposition such that obs(b)=1 and obs(x)=0 for x /= b. The proof can be found in the full version.
Proposition 3.16 Two states x and y are bisimilar if and only if x = y.

Feller-Dynkin cospan
The concept of bisimulation that we have discussed so far is defined between states of a process. One often wants to compare different processes with different state spaces. For this one needs to use functions that relate the state spaces of different processes. One does want to preserve the relational character of bisimulation. In the coalgebra literature one uses spans of so-called “zigzag” morphisms. In previous work [9] on (discrete-time) Markov processes people have considered cospans as this leads to a smoother theory. Intuitively, the difference is whether one thinks of an equivalence relation as a set of ordered pairs or as a collection of equivalence classes.
Feller-Dynkin homomorphism
This definition of bisimulation can easily be adapted to states in different Markov processes by constructing the disjoint union of the Markov processes.
The disjoint union of two Markov processes is defined as such: given two FD processes (Ej, Ej, (Pˆj ), (Pj), Ωj, Gj, (Px), obsj)j=1,2, we write i1 : E1 → E1  E2 and
i2 : E2 → E1  E2 for the two corresponding inclusions. The disjoint unions of the two FD processes is the process (E1  E2, E, (Pˆt), (Pt), Ω, G, (Px), obs) where:
the topology on E1 E2 is generated by the topologies on E1 and E2: an open set of E1 E2 is i1(O1) ∪ i2(O2) where O1 and O2 are opens of E1 and E2 respectively,
E is the Borel-algebra generated by this topology. It can also be expressed as the σ-algebra generated by {i1(C) | C ∈ E1} and {i2(C) | C ∈ E2},
for any state x ∈ E1 E2, any time t ≥ 0 and any function in C0(E1 E2), we define the semigroup:


Pˆtf (x)= 
ˆ1
t
Pˆ2f2(x2)	if x = i2(x2)

where fj : Ej	R is defined by fj(y)= f	ij(y). The semigroup Pˆt inherits
the desired properties from Pˆ1 and Pˆ2 for it to be a FD semigroup,
t	t
for any state x ∈ E1  E2, any time t ≥ 0 and any measurable set C ∈ E , the kernel can be made explicit as:
  P 1(x1, i—1(C))	if x = i1(x1)
t	2
for any state x ∈ E1  E2, we set
obs(x)=	obs1(x1)	if x = i1(x1)	, obs2(x2)	if x = i2(x2)
the set of trajectories on (E1  E2)∂ is denoted Ω. Note that a trajectory in Ω can switch between E1 and E2. The set Ω is equipped with a σ-algebra G as is

standard for FD processes. For a state x, we can give explicitly the probability distribution for B ∈ G:


Px(B)= 
1
Px2 (B2)	if x = i2(x2)

where Bj = {ω ∈ Ωj | ij ◦ ω ∈ B}. Note that for any x ∈ E1  E2, for any measurable set B ⊂ {ω ∈ Ω | ∃t1, t2 ω(t1) ∈ i1(E1) and ω(t2) ∈ i2(E2)}, P (B)= 0.
We can also make explicit what a bisimulation is in that context (we will omit to mention the inclusions i1 and i2 to be readable):
Definition 4.1 Given two FD processes (Ej, Ej, (Pˆj ), (Pj), Ωj, Gj, (Px), obsj)j=1,2,
a bisimulation between the two FDPs is an equivalence R on E1  E2 such that for
all xRy (x ∈ Ei, y ∈ Ej),
(initiation 1) obsi(x)= obsj(y), and
(induction 2) for all measurable R-closed sets B, Px(B ∩ Ωi)= Py(B ∩ Ωj).
This condition can also be stated as follows. For all sets B1 ∈ G1 and B2 ∈ G,
P (Bi)= P (Bj) if the two sets satisfy the following condition:
i	j

∀ωk ∈ Bk ∀ωl ∈ Ωl (∀t ≥ 0 ωk(t) R ωl(t)) ⇒ ωl ∈ Bl
In that formulation, Bk = B ∩ Ωk and the condition states that the set B is
R-closed in terms of the sets B1 and B2.
Note that R ∩ (Ej × Ej) is a bisimulation on (Ej, Ej, (Pj), (Px)). To proceed
with our cospan idea we need a functional version of bisimulation; we call these
Feller-Dynking homomorphisms or FD-homomorphisms for short.
Definition 4.2 A continuous function f : E → Ej is called a FD-homomorphism
if it satisfies the following conditions:
obs = obsj ◦ f ,
for all x ∈ E and for all measurable sets Bj ⊂ Ωj, Pf(x)(Bj) = Px(B) where
B = {ω ∈ Ω | f ◦ ω ∈ Bj}.
Note that if f and g are FD-homomorphisms, then so is g ◦ f .
Proposition 4.3 The equivalence relation R deﬁned on E  Ej as
R = {(x, y) ∈ E × E | f (x)= f (y)}∪ {(x, y), (y, x) | f (x)= y}
is a bisimulation on E.
The proof can be found in the full version. A nice consequence of this result is that the equivalence relation R defined on E as Rj = {(x, y) ∈ E × E | f (x)= f (y)} is a bisimulation on E.

Here is an example with one atomic proposition. Let M1 be the standard Brownian motion on the real line with obs1(x) = 1 if and only if x ∈ Z. Let M2 be the reflected Brownian motion on [0, 1] with obs2(x) = 1 if and only if x =0 or
1. Let M3 be the reflected Brownian motion on 0, 1 with obs3(x)=1 if and only
if x = 0. Let M4 be the standard Brownian motion on the circle of radius  1 (we
will identify points on the circle with the angle wrt the vertical) with obs4(x) = 1 if and only if x = 0.
We can define some natural mappings between these processes:








where








φ1 : [−π, π] → [0, 1/2]
θ '→ |θ|/2π φ2 : [0, 1] → [0, 1/2]


φ4
,7
M2
M1

z 
M4

z ,7φ1
M3

x '→ x	if x ≤ 1/2
x '→ 1 − x	otherwise
φ3 : R → [−π, π]
x '→ 2π|x − y|	where y ∈ Z such that |x − y|≤ 1/2
φ4 : R → [0, 1]
x '→ x − 2n	if ∃n ∈ Z 2n ≤ x < 2n +1 
x '→ 2n +2 − x	if ∃n ∈ Z 2n +1 ≤ x < 2n +2 
Note that the condition in the definition of φ3 means that y is the closest integer to x. All these mappings are FD-homomorphisms.
Deﬁnition of cospans
In this section, we are going to omit to mention actions since there are already many indices. However, it is simple to adapt this by adding actions whenever they are needed.
Definition 4.4 A FD-cospan is a cospan of FD-homomorphisms.
Theorem 4.5 The category with Feller-Dynkin processes as objects and FD- homomorphisms as morphisms has pushouts.
We omit this proof for the abstract.
This proves that FD-cospan corresponds to an equivalence relation. We have already showed how FD-homomorphisms (and hence FD-cospans) yield bisimula-

tions. The converse is also true as is stated next. The proof can be found in the full version.
Theorem 4.6 For all bisimulations R, there exists (f, g) a FD-cospan such that
for all x ∈ E1,y ∈ E2, x R y if and only if f (x)= g(y),
for all x, xj ∈ E1, x R xj if and only if f (x)= f (xj), and
for all y, yj ∈ E2, y R yj if and only if g(y)= g(yj).
We thus have the following correspondance between bisimulation and FD- cospans:
Theorem 4.7 Two states x and y are bisimilar if and only if there exists a FD- cospan (f, g) such that f (x)= g(y).
Comparison to discrete time bisimulation
The goal of this work is to extend the notion of bisimulation that exists in discrete time to a continuous-time setting. Therefore an important question is the following: do we get back the definition of bisimulation that existed in discrete time when we restrict Feller-Dynkin processes to (some kind of) discrete-time processes?
As we have seen, the case with a single action can be easily adapted to accom- modate several actions. We will therefore for the sake of readability not mention actions in this section.
Given an LMP (X, Σ, τ, (χA)A∈AP ) (there is a single action), we can always view it as a FD process where transitions happen at every time unit. Since the process has to remain memoryless, a state of the FD process is a pair of a state in X and a time explaining how long it has been since the last transition. For trajectories to be cadlag, that time is in [0, 1).
Formally, the state space of the FD procss is (E, E ) with E = X × [0, 1) and E =Σ ⊗ B([0, 1)) and the corresponding kernel is: for all x ∈ X and C ∈ E , t ≥ 0 and s ∈ [0, 1), Pt((x, s), C)= τ[t+s♩(x, Cj) where Cj = {z | (z, t + s − [t + s⊆) ∈ C} and for k ≥ 1,

τ0(x, Cj)= δC′ (x),	τ1(x, Cj)= τ (x, Cj)	and	τk+1(x, Cj)= ∫

We also define (obs(x, s))i = χAi (x) (where AP = {A1, A2, ...}).


y∈X

τ (x, dy)τk(y, Cj)

A DT-bisimulation (see definition 3.1) yields a bisimulation on the corresponding FD process.
Proposition 5.1 If the equivalence R is a DT-bisimulation, then the relation Rj
deﬁned as
Rj = {((x, s), (y, s)) | s ∈ [0, 1),x R y}
is a bisimulation in the sense of FD processes.
Going from bisimulation in the sense of FD processes to DT-bisimulation is not as direct and requires some further notions.

Definition 5.2 An equivalence R on the state space of an LMP viewed as a FD process is time-coherent if for all x, y in the state space of the LMP and for all 0 ≤ t < 1,
(x, t)R(y, t) ⇒ ∀s ∈ [0, 1) (x, s)R(y, s)
Given any equivalence R on the state space of an LMP viewed as a FD process, we define its time-coherent closure (denoted time(R)) as the smallest time-coherent equivalence containing R.
Proposition 5.3 If R is a bisimulation on an LMP viewed as a FD process, then so is time(R).
Theorem 5.4 If the equivalence R is a time-coherent bisimulation, then the rela- tion Rj deﬁned as
Rj = {(x, y) | ∃t ∈ [0, 1) such that ((x, t), (y, t)) ∈ R}
is a DT-bisimulation.
These results can be summed up in the following theorem relating bisimulation and DT-bisimulation.
Theorem 5.5 Two states x and y (in the LMP) are DT-bisimilar if and only if for all t ∈ [0, 1), the states (x, t) and (y, t) (in the Feller-Dynkin process) are bisimilar.
Conclusion
We have given two definitions of bisimulation, one as an equivalence relation and the other as a cospan of morphisms respecting the dynamics of the process. We have also studied many examples; the full version of this conference submission contains many more examples. It would be interesting to know if (and under what conditions) an equivalence satisfying conditions (initiation 2) and (induction 1) is a bisimulation.
However, there are many aspects to explore, as suggested by previous work on step-based systems. First of all is a quantitative description of bisimulation through the definition of some metrics on the state space. This was done in two ways.
Either through the definition of a set of [0, 1]-valued functions that can be viewed as experiments performed on the system (see [13,30]). We are hoping that this set could be obtained by looking at hitting times and occupation times.
Or as a fixed-point of some operators on metrics (see [30]). Such a fixed-point metric was defined on jump processes in [19,20]. It seems that some of the details in that work are possibly incorrect, so we hope to fix those details and to adapt similar ideas to our framework.
Another important and interesting question is that of approximations (see [12,10,8]) of our Markov processes. Here we will undoubtedly face new sub- tleties as we will have to cope with both spatial and temporal limits.

Finally, a fundamental result in this area is the logical characterization of bisim- ulation [29,21] which was also extended to the probabilistic case [11]. We hope to be able to provide such a logic for continuous-time processes based on the set of [0, 1]-valued functions used to obtain a bisimulation metric. A game interpretation of bisimulation could also be provided [18]. Perhaps some interesting insights could also come from nonstandard analysis [17] where there is also a notion of equiva- lence but one which is quite different from bisimulation. In that work the notion of adapted spaces is fundamental.

References
R. Alur, C. Courcoubetis, N. Halbwachs, T.A. Henzinger, P.-H. Ho, X. Nicollin, A. Olivero, J. Sifakis, and S. Yovine. The algorithmic analysis of hybrid systems. Theoretical Computer Science, 138:3–34, 1995.
R. Alur and D. Dill. A theory of timed automata. Theoretical Computer Science, 126:183–235, 1994.
R. Blute, J. Desharnais, A. Edalat, and P. Panangaden. Bisimulation for labelled Markov processes. In
Proceedings of the Twelfth IEEE Symposium On Logic In Computer Science, Warsaw, Poland., 1997.
P. Billingsley. Convergence of Probability Measures. Wiley Interscience, 2nd edition, 1999.
Patrick Billingsley. Probability and measure. John Wiley & Sons, 2008.
Adam Bobrowski. Functional analysis for probability and stochastic processes: an introduction. Cambridge University Press, 2005.
Linan Chen, Florence Clerc, and Prakash Panangaden. Bisimulation for Feller-Dynkin Processes. arXiv e-prints, page arXiv:1904.00976, Apr 2019.
Philippe Chaput, Vincent Danos, Prakash Panangaden, and Gordon Plotkin. Approximating Markov processes by averaging. J. ACM, 61(1):5:1–5:45, January 2014.
Vincent Danos, Jos´ee Desharnais, Fran¸cois Laviolette, and Prakash Panangaden. Bisimulation and cocongruence for probabilistic systems. Information and Computation, 204(4):503–523, 2006.
Vincent Danos, Jos´ee Desharnais, and Prakash Panangaden. Conditional expectation and the approximation of labelled Markov processes. In Roberto Amadio and Denis Lugiez, editors, CONCUR 2003 - Concurrency Theory, volume 2761 of Lecture Notes In Computer Science, pages 477–491. Springer-Verlag, 2003.
J. Desharnais, A. Edalat, and P. Panangaden. Bisimulation for labeled Markov processes. Information and Computation, 179(2):163–193, Dec 2002.
J. Desharnais, V. Gupta, R. Jagadeesan, and P. Panangaden. Approximating labeled Markov processes.
Information and Computation, 184(1):160–200, July 2003.
Jos´ee Desharnais, Vineet Gupta, Radhakrishnan Jagadeesan, and Prakash Panangaden. A metric for labelled Markov processes. Theoretical Computer Science, 318(3):323–354, June 2004.
Jos´ee Desharnais and Prakash Panangaden. Continuous stochastic logic characterizes bisimulation for continuous-time Markov processes. Journal of Logic and Algebraic Progamming, 56:99–115, 2003. Special issue on Probabilistic Techniques for the Design and Analysis of Systems.
R. M. Dudley. Real Analysis and Probability. Wadsworth and Brookes/Cole, 1989.
A. Einstein. The theory of the brownian movement. Ann. der Physik, 17:549, 1905.
Sergio Fajardo and H Jerome Keisler. Model theory of stochastic processes, volume 14 of Lecture Notes in Logic. Cambridge University Press, 2017.
Nathanael Fijalkow, Bartek Klin, and Prakash Panangaden. The expressiveness of probabilistic modal logic revisited. In Proceedings of the 44th International Colloquium on Automata Languages and Programming, 2017.


Vineet Gupta, Radhakrishnan Jagadeesan, and Prakash Panangaden. Approximate reasoning for real-time probabilistic processes. In The Quantitative Evaluation of Systems, First International Conference QEST04, pages 304–313. IEEE Press, 2004.
Vineet Gupta, Radha Jagadeesan, and Prakash Panangaden. Approximate reasoning for real-time probabilistic processes. Logical Methods in Computer Science, 2(1):paper 4, 2006.
Matthew Hennessy and Robin Milner. On observing nondeterminism and concurrency. In Jaco de Bakker and Jan van Leeuwen, editors, Automata, Languages and Programming, volume 85 of Lecture Notes in Computer Science, pages 299–309. Springer Berlin / Heidelberg, 1980.
Ioannis Karatzas and Steven Shreve. Brownian motion and stochastic calculus, volume 113. Springer Science and Business Media, 2012.
K. G. Larsen and A. Skou. Bisimulation through probablistic testing. Information and Computation, 94:1–28, 1991.
R. Milner. A Calculus for Communicating Systems, volume 92 of Lecture Notes in Computer Science. Springer-Verlag, 1980.
Prakash Panangaden. Labelled Markov Processes. Imperial College Press, 2009.
D. Park. Concurrency and automata on infinite sequences. In Proceedings of the 5th GI Conference on Theoretical Computer Science, number 104 in Lecture Notes In Computer Science, pages 167–183. Springer-Verlag, 1981.
L. Chris G. Rogers and David Williams. Diffusions, Markov processes and martingales: Volume 1. Foundations. Cambridge university press, 2nd edition, 2000.
Davide Sangiorgi. On the origins of bisimulation and coinduction. ACM Transactions on Programming Languages and Systems (TOPLAS), 31(4):15, 2009.
Johan van Benthem. Modal correspondence theory. PhD thesis, University of Amsterdam, 1976.
Franck van Breugel, Michael Mislove, Joel Ouaknine, and James Worrell. Domain theory, testing and simulation for labelled Markov processes. Theoretical Computer Science, 333(1-2):171–197, 2005.
W. Whitt. An Introduction to Stochastic-Process Limits and their Applications to Queues. Springer Series in Operations Research. Springer-Verlag, 2002.
