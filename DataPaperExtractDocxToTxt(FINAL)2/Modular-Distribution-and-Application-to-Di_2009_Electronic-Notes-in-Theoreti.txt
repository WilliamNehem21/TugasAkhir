

Electronic Notes in Theoretical Computer Science 238 (2009) 3–19
www.elsevier.com/locate/entcs

Modular Distribution and Application to Discrete Controller Synthesis
Gwenaël Delaval1
INRIA Grenoble Rhône-Alpes and University of Grenoble, POP ART project team, France

Abstract
This paper shows the application of the automatic distribution of synchronous reactive programs to the specific problem of discrete controller synthesis of complex reactive systems. Discrete controller synthesis is a formal method used to ensure properties on a flexible system which does not a priori verify them. However, this method is eﬃcient only on Boolean programs. More complex embedded systems, comprising complex data types and structures, cannot be addressed without abstraction means. We show how such abstractions can be obtained automatically using a type-directed projection operation. This operation allows then the safe recombination of the result of the synthesis with the original abstracted system, preserving the ensured properties.
Keywords: Discrete controller synthesis, automatic distribution, type systems


Introduction
Reactive embedded systems, due to their strong interaction with their environment, are intrinsically critical. The failure of such systems can involve serious human or ecological damages. For these reasons, there is a strong need of formal methods for the design of such systems, in order to ensure formal properties on them.
We address here the problem of ensuring properties by mean of an automatic method of transformation of the original program. Some of these methods cannot be applied on complex and general programs, unless performing a preliminary sep- aration of the program in two parts, one on which the automatic transformation is performed, and one with the other computations. This separation can be fastidious, and the recombination of the two parts raises safety and modularity issues. The contribution of this paper is to use an automatic type-directed distribution method to obtain on one hand an abstraction on which the transformation will be applied, and on the other hand the complementary of this abstraction, whose recombination

1 Email: Gwenael.Delaval@inria.fr

1571-0661/© 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.01.003




communication channels



Fig. 1. Automatic distribution for application of a transformation on part of a program.

with the transformed abstraction is safe and preserves the transformation. This work is based on [7], where a type-directed projection operation is defined in order to address the modular distribution of reactive programs, and consists of both an adaptation of this method and an illustration of its application towards a specific distribution problem, namely here separate compilation and analysis of centralized systems.
Figure 1 sums up this method: P is the original program distributed into P1 and P2. The transformation is applied on P2, giving the program P ', then re- combined safely with P1. We show the application of this method on a specific transformation, the discrete controller synthesis [2], whose goal is to ensure prop- erties on a partial design. This method allows the programming of both parts of a program, for example here the control part and the data part, in the very same language and in an integrated way, thus giving the programmer more control on the semantics of the written programs.
The properties we wish to address here are temporal logic properties like the evolution of values of inputs and outputs of the program during time. An example of such property can be expressed as “the event B will always occur after the event A”. These properties are commonly checked by the use of automatic tools (e.g., model-checking tools [10]), on a conservative abstraction of a fully designed system. Another approach lies in discrete controller synthesis (DCS) [17]: given a partially designed system and temporal properties, this method computes automatically a controller, actuating on the partial system, and ensuring the required properties. This method has shown its interest for embedded systems in [2].
However, this method is efficient only on a Boolean state-based abstraction of the system [13]. This abstraction can involve addition of inputs (e.g., Boolean values from comparison of scalar data) and masking of other ones. The use of this method also involves separate compilation of the state-based abstraction of the original system, thus exposing the final system to data or control consistency problems. Moreover, as current DCS algorithms apply only on global programs, the Boolean abstraction needs to be inlined.
We present here an automatic method allowing the generation, from a unique source program, of a Boolean state-based abstraction (named Boolean fragment here- after, on which we will perform the DCS to ensure the required properties), and a program performing the other data computations (named data fragment ). We show how our method allows the correct automatic recombination of the data fragment with the controlled Boolean fragment, once discrete controller synthesis has been performed on it. This separation of the Boolean and the data fragments also allows


Fig. 2. Example of discrete controller synthesis.

us to only inline the part on which the DCS is applied, thus keeping the origi- nal modularity structure of the initial program in the data part, thus allowing, for example, to use higher-order features in it.
This paper is organized as follows: Section 2 gives an overview of our method. Section 3 shows an application example. Section 4 presents the language used, Section 5 the type-directed projection operation, and Section 6 the application of DCS on the two obtained fragments. Finally, Section 7 discusses our method and presents some prospects.

Overview
Discrete controller synthesis operates on Boolean reactive systems, often expressed as automata. Temporal logic properties are then expressed as properties on the set of traces of these automata. Given a partial program P and a property Φ not satisfied a priori by P , the discrete controller synthesis computes a controller C, such that the synchronous composition of P and C is a program which satisfies Φ. The partial nature of a program is expressed by additional inputs named controllable inputs, whose values will be defined by the computed controller. This set of controllable inputs is denoted Ic, and therefore the discrete controller synthesis operation will be noted DCS(P, Ic, Φ). By opposition, actual inputs coming from the program

environment are called hereafter uncontrollable inputs and denoted Iu. and Supremica [1] are examples of DCS tools.
Sigali [13]

Figure 2 shows an example of discrete controller synthesis. Synchronous pro- grams are expressed as Mealy machine. The program P , on the left, has two uncontrollable inputs u1 and u2, and a controllable input c (underlined, as every controllable input in the following). This program is partially designed: in state A, with the input u2, two possibilities have been specified as correct by the programmer: staying in state A, or going to state C. Let assume now that, for safety reasons, we want to ensure that the state D will never be reached (expressed as the CTL formula Φ = ∀ ¬D). Then, the computation of DCS(P, {c}, Φ) produces the con- troller shown on the right of Figure 2, which gives, at occurrences of u2 in state A, the false value for the controllable input c. The result of the synchronous product of P and C is a program where, for any sequence of inputs u1 and u2, the state D is never reached.
Such methods can only be applied on Boolean state-based systems. Moreover,





x = last(x)+1 




x ≤ 0 ∧ c






x = last(x) − 1
automaton
| I -> do x = last x + 1
until (x >= 10) & c then D
| D -> do x = last x - 1 until (x <= 0) & c then I
end


Fig. 3. Mode automata example.
these methods are not very scalable: they cannot handle, without abstraction, more complex systems (e.g., mixing Boolean and numerical values). Two solution exists to alleviate these problems: a Boolean abstraction must either be extracted of the whole system, or it can be designed apart. The first solution can involve arbitrary complex manual work to obtain an abstraction, then the recombination of the controlled abstraction and the original system. This is why the second solution is considered in the framework of the design of embedded systems in computation/control layers [18]. This paradigm allows the design of embedded systems in terms of, on one hand, a computational layer, comprising the implementation of complex functional tasks like control law, signal processing; and on the other hand a control layer, purely reactive, allowing the schedule of the functional tasks.
Thus, these two parts can be separately designed and compiled, and specific analysis tools (model-checking or discrete controller synthesis) can be used for the reactive part. Another interest of this separation approach is to design modular reactive patterns, tested and formally checked once, and reusable for several designs. This approach has shown its interest for domain-specific approchs, like Orccad [3], where the Robot-tasks are such modular patterns, or the Nemo language [8].
However, this separate design can be problematic for the global simulation and analysis of the system. Furthermore, it yields a lack of modularity and flexibility of the control interface, especially in the case of use of domain-specific patterns, the approach commonly taken being specific code duplication and inlining. Mode automata [12], as well as further work on synchronous languages [6], has addressed such problem by adding automata as control structures in the dataflow languages Lustre [9] and Lucid Synchrone [5,16].
Figure 3 shows an example of mode automata, with its equivalent specification in Lucid Synchrone. This automaton is composed of two modes or states, one increasing the global variable x (named I), one decreasing it (D). The transition from I to D (resp. D to I) is taken when x ≥ 10 (resp. x ≤ 0), and the controllable input c is true (this allow the controller to inhibit the transition between the two modes).
These two complementary approaches, global simulation and analysis, and sep- arate compilation, can be both applied on the same system, by means of the appli- cation on dataflow languages extended with automata of an automatic distribution method, allowing us to obtain several fragments from a whole program, on which separate analysis and compilation can be applied, before safe recombination. Ap- plying this method for discrete controller synthesis, the goal would be to obtain two fragments, a Boolean abstraction on one hand, and the remaining computations on




x = last(x)+ 1	c2
x = last(x) − 1

c1 = u1 ∧ c	c2
c2 = u2 ∧ c
u1 = (x = 10)	u2 = (x = 0)

Fig. 4. Two fragments obtained from the program of Figure 3.

Iu 
bd
Ic 	u +


Ic

DCS(Pb, Ic, Φ)
Fig. 5. Distribution for application of discrete controller synthesis.
another. Figure 4 shows the application of this method on the automaton of Fig- ure 3. The Boolean fragment is shown on the left, and the remaining computations are performed by the automaton on the right. For the communication of values from one fragment to the other, u1 and u2 are added as outputs of the second automaton, and as uncontrollable inputs on the Boolean fragment. c1 and c2 are added con- versely to communicate the result of Boolean computations. In the following, we will keep the convention of calling u (resp. c) the channel communications from the data fragment to the Boolean fragment (resp. from the Boolean to the data fragment). The synchronous composition of these two automata is semantically equivalent with the automaton of Figure 3.
Figure 5 sums up our method. Once the two fragments Pb and Pd have been obtained from the original program P , the discrete controller synthesis can be per- formed on the Boolean fragment Pb, and the composition of this Boolean fragment with the computed controller C can then be safely composed with the other compu- tations obtained by the distribution. Idb and Ibd are respectively the set of communi- cation channels added from Pd to Pb (so as outputs of Pd and uncontrollable inputs of Pb), and the way back. The synchronous composition of the Boolean fragment with its controller is performed by plugging the inputs Iu and Idb as inputs of the controller, and the output of the controller as controllable inputs of the fragment.

Application
Figure 6 shows as illustrating example the programming of a pattern named task, representing a delayable task. This pattern is a higher-order node: its parameter f is the function to be executed by an instantiation of this task when it is active, req and stop are two Boolean requesting respectively the launch of the task and its end, and x is the input of f. The task is delayable because an input ok can delay it when it is requested. This input will be instantiated with controllable ones. The

outputs of this task are the output y of f, and a Boolean act, true when the task is actually active. The main node then contains two instantiations of this pattern. Programs are here written in the simplified syntax used further in Section 4. The concrete syntax of Lucid Synchrone can be seen in [16].



node task(f, req, ok, stop, x) = (y,act) where automaton
| Idle -> do
act = false and y = 0 
until (req & ok) then Active until (req & not ok) then Wait
| Wait -> do
act = false and y = 0 
until ok then Active
| Active -> do








act = false I
y =0 
stop
A






req ∧ ¬ok req ∧ ok






W act = false
y =0 

ok

act = true and y = f(x)
until stop then Idle end;

y1,act1 = task(f, (x1>0), ok1, (x1<0), x1) and y2,act2 = task(g, (x2>0), ok2, (x2<0), x2)
act = true
y = f(x)


Fig. 6. Example: delayable task pattern.




Performing a type-directed distribution allows for this distribution to be modular. Thus, one node will result in exactly one node on each fragment. In order to do this modular operation, the typing approach allows us to attach to each node the information about where its inputs and outputs are located (i.e., on which fragment they have been computed), and what fragment and what communication channels are involved by this node’s computation.
The result of the partition of this program is shown in Figures 7 and 8. On the Boolean fragment (Fig. 7), the node task has four additional outputs for each transition. Thus, as this node is instantiated twice in the main node, eight outputs c1 to c8 are added. The controller computed on this abstraction can, e.g., ensure that these two tasks will never be active at the same time (∀ ¬(act1 ∧ act2)).
The abstraction with other computations is given in Figure 8. The outputs added in the Boolean abstraction are here added as inputs, and new outputs are added, holding the values of comparisons (u1 to u4).
Both fragments comprise an automaton, whose states and transitions match with the original one. The targeted behaviour is a Boolean fragment computing transitions, and a data fragment receiving scheduling instructions under the form of triggered transitions between computing states. Unused values (f and x on the Boolean fragment, req, ok and stop on the data one) are replaced by the special value ().



node task(f, req, ok, stop, x) = ((),act,c1,c2,c3,c4) where automaton
| Idle -> do
act = false
and c1 = (req & ok)
and c2 = (req & not ok) until c1 then Active until c2 then Wait









act = false I










c2
W act = false

| Wait -> do
act = false and c3 = ok
until c3 then Active
| Active -> do
act = true and c4 = stop
until c4 then Idle end;

y1,act1,c1,c2,c3,c4 = task((), u1, ok1, u2, ())
and y2,act2,c5,c6,c7,c8 = task((), u3, ok2, u4, ())
c2 = (req ∧ ¬ok)
c1 = (req ∧ ok)	c1
c4
A
act = true
c4 = stop
c3 = ok

c3


Fig. 7. Boolean fragment of Figure 6.


node task(f, req, ok, stop, x, c1, c2, c3, c4)
= (y,()) where automaton
| Idle -> do y = 0 until c1 then Active until c2 then Wait
| Wait -> do y = 0 until c3 then Active
| Active -> do y = f(x) until c4 then Idle
end;











c2
y =0 I
c4	c1

A







W y =0 

c3

u1 = (x1>0)
and u2 = (x1<0)
and y1,act1 = task(f, (), (), (), x1, c1, c2, c3, c4) and u3 = (x2>0)
and u4 = (x2<0)
and y2,act2 = task(g, (), (), (), x2, c5, c6, c7, c8)
y = f(x)




The language
Fig. 8. Data fragment of Figure 6.

The language we consider is a dataflow language, extended with automata. It follows the following syntax:
P ::= d1; ... ;dn;D
::= node f (p)= e where D p ::= p, p | x
D ::= ϵ | p = e | p = x(e) | D and D | automaton S → h... S → h end
h ::= do D u 
u ::= until e then S u | ϵ
::= i | x | (e, e) | op(e, e) | e fby e

A program P is a sequence of node definitions, followed by a set of equations (the “main” of the program). A node definition d takes as input a pattern p, comprising

a sequence of uncontrollable inputs (x). Its output is an expression e, evaluated within the scope of a set of equations D.
Definitions D are either an empty definition ϵ, single equations defining patterns of variables (p = e), definitions naming the result of an application (p = x(e)), parallel declarations (D and D), or an automaton, composed of a sequence of states S defined by one handler h (automaton S → h... S → h end). An automaton handler is a definition followed by a sequence of transitions.
An expression e may be an immediate value (i), a variable (x), a pair construction (e, e), a binary combinatory operation (op(e, e), where op can be +, −,... ), an initialized delay (e fby e). The pair construction is left-associative, and thus we denote by e1,... , en the expression (... (e1, e2), e3),.. .), en).



Type-directed projection

The type system is adapted from [7]. It is extended with automata, and simplified to answer the specific problem of separate compilation of a program in two parts (i.e., two locations). The target architecture here is then composed of two “locations”, named Ab and Ad (Ab will be the Boolean fragment and Ad the data fragment), which are connected to each other in both directions.
Our type system associates to each expression and definition a spatial type, which expresses on which fragment (Boolean or data) this expression or definition is lo- cated or defined. For example, a value of spatial type bool at Ad is a Boolean value located (and then, usable) on the data fragment. The spatial type of a node tak- ing as input a Boolean, whose output is a Boolean, and which is only computable on the Boolean fragment without internal communication, will be of spatial type bool at Ab −⟨{Ab}/∅⟩→ bool at Ab. It is a type and effect system [19], as with its spatial type, we associate to each expression and definition the set of fragments, and the channels involved in its computation.
As a more complete example, the type of the node task of Figure 6 will carry the fact that it takes as input a node whose input, output, and computation are on Ad (the data fragment), three inputs on Ab (the Boolean fragment) and one on Ad, that its output is a pair whose first component is on Ad and its second one on Ab, and that the computation of task involves the two fragments Ab and Ad and four communication channels from Ab to Ad:

∀α. (α at Ad −⟨{Ad}/∅⟩→ int at Ad)
× bool at Ab × bool at Ab × bool at Ab × α at Ad 
−⟨{Ab, Ad}/T ⟩→ (int at Ad × bool at Ab)
where T = [A →c1 A ,A →c2 A ,A →c3 A ,A →c4 A ]
b	d	b	d	b	d	b	d

The syntax of spatial type expressions is:


σ ::= ∀α1,... , αn.∀δ1,... , δp.t
t ::= b | α | t at s | t −⟨l/T ⟩→ t | t × t
T ::= [A1 →c1 A' ,... ,A →cn A' ] if ∀i /= j, c


/= c
b ::= int | bool | ... s ::= Ab | Ad | δ
l ::= {s1,... , sn}

1	n	n	i	j
H ::= [x1 : σ1,... , xn : σn] if ∀i /= j, xi /= xj

H denotes spatial typing environments. We distinguish spatial type schemes (σ), which can be quantified, from simple spatial types (t). A simple spatial type can be either a stream base type (b, like integers, Booleans, ... ), a type variable (α), a located type (t at s), a node type (t −⟨l/T ⟩→ t), or a pair type (t × t). A location is either one of the two constant location Ab (for the Boolean fragment) and Ad (for the data fragment), or a location variable δ. l denotes sets of locations (hence limited here to subsets of {Ab, Ad}, or singleton {δ}).
A value of spatial type t at s is a value located on s. A value of spatial type t1 −⟨l/T ⟩→ t2 is a node whose input is of spatial type t1, whose output is of spatial type t2, and whose computation involves the set of locations l.
So as to allow, e.g., the instantiation of a type scheme of the form ∀α.α at s by the type int at s −⟨{s}/∅⟩→ int at s, we extend the equality relation between types. Thus, the following equalities stand:
(t1 × t2) at s = (t1 at s) × (t2 at s)
(t1 −⟨{s}/∅⟩→ t2) at s = (t1 at s) −⟨{s}/∅⟩→ (t2 at s) t at s at s = t at s


t1 = t'
t2 = t'
t1 = t'
t2 = t'

(t1 × t2)= (t' × t' )
t1 −⟨l/T ⟩→ t2 = t'
−⟨l/T ⟩→ t'

1	2	1	2
The notion of well-formed types is introduced, because one cannot associate a mean- ing to any type: e.g., the spacial type int at Ab at Ad cannot appear in the type system. A spatial type t is well-formed iff ∀t', s1, s2,t = t' at s1 at s2 ⇒ s1 = s2. Every type in the type system is assumed to be well-formed, and typing algorithms maintain this invariant during typing.
The instantiation mechanism is defined as follows:
t[t1/α1,... , tn/αn, s1/δ1,... , sp/δp] ≤ ∀α1 ... αn.∀δ1 ... δp.t

The generalization mechanism is restrained for the projection. We allow type schemes to comprise at most one location variable. In that case, the type scheme is of the form ∀α1 ... αn.∀δ.t at δ, and the projection consists in placing the value of this type on the two fragments.
We note respectively FLV(t) and FTV(t) the set of free location variables and free type variables of the type t. FLV and FTV are straightforwardly extended to typing environments. The generalization of t in typing environment H is noted

genH (t), defined as:

genH (t)= ∀α1,... , αn.∀δ1,... , δp.t where {α1,... , αn} = FTV(t) − FTV(H)
{δ1,... , δp} = FLV(t) − FLV(H)
p ≤ 1

The function locations(·) gives the set of locations involved in the spatial type given as argument. It is defined as:

locations(t1 × t2)	= locations(t1) ∪ locations(t2) locations(t1 −⟨l/T ⟩→ t2) = l
locations(t at s)	= {s}

This type system will also infer communication channels needed between the two fragments. A channel will be represented by added common variables between two fragments, i.e., added inputs on one side corresponding to added outputs on the other. Channels are named so as to be able to match these added variables in the two fragments.  Formally, a channel is a location pair associated with a
name, noted A1 →c  A2: c is the name of the channel, A1 its source location, and
A2 its destination location. c is the common variable representing a communication between the two fragments. The set of channel names is totally ordered, so as to keep consistency of inputs and outputs added, from the node definition to node instances. T denotes channels sequences, in which channel names are disjoints. (T, T ') denotes the concatenation of two channel sequences. dom(T ) is the set of channel names of T . For the sake of multiple instanciation of nodes, it is necessary to be able to rename channels, so as to keep these names disjoints in inferred channel sequences. Given two channel sets T and T ', we note T ' ∼= T the fact that T ' is equal to T modulo a renaming of its channels:
T ' ∼= T ⇔ T ' = T [c' /c1,... , c' /cn]	where dom(T )= {c1,... , cn}
1	n
and dom(T ')= {c' ,... , c' }
1	n

Then, from a channel sequence T , we denote by T ↑ s (resp., T ↓ s) the channel sequence extracted from T and which source (resp., destination) is s.



([s →c
∅↑ s = ∅
s2],T ) ↑ s = [s →c

s2], (T ↑ s)

([s1 →c
∅↓ s = ∅
s],T ) ↓ s = [s1 →c

s], (T ↓ s)

([s1 →c
s2],T ) ↑ s = (T ↑ s) iff s1 /= s
([s1 →c
s2],T ) ↓ s = (T ↓ s) iff s2 /= s


Finally, a program is typed and projected with the initial environment H0 = Hop, Hu, Hc, where Hop contains the types of the initially defined operations (Boolean operations being defined to be computed on Ab, and other on Ad), and Hu and Hc

respectively the types of the uncontrollable and controllable inputs.
⎡ · fby · : ∀α.∀δ.α at δ × α at δ −⟨{δ}/∅⟩→ α at δ,	⎤
fst · : ∀α, β.∀δ1, δ2.α at δ1 × β at δ2 −⟨{δ1, δ2}/∅⟩→ α at δ1, Hop =	snd · : ∀α, β.∀δ1, δ2.α at δ1 × β at δ2 −⟨{δ1, δ2}/∅⟩→ β at δ2, (and): bool at Ab × bool at Ab −⟨{Ab}/∅⟩→ bool at Ab,... 
(+) : int at Ad × int at Ad −⟨{Ad}/∅⟩→ int at Ad,... 
Hu = [xu1 : t1 at sn,... , xun : tn at sn] Hc = [xc1 : bool at Ab,... , xcp : bool at Ab]
We note Iu and Ic respectively the sets of uncontrollable and controllable inputs:
Iu = dom(Hu) and Ic = dom(Hc).
The type system defines a judgment H ▶ D : H'/l/T , meaning that in teh typing environment H, the definition D yields the typing environment H', and its computation involves the set of locations l, and the communication channels T . This type system defines a type directed projection operation, performed on a typed program. For the sake of brevity, we will detail here only the rules of this projection operation. The rules defining the type system can be found in appendix.
The projection of a definition D on a location s is noted H ▶ D : H'/l/T =s⇒ D', meaning that in the typing environment H, the definition D defines the environ- ment H', and its projection on s results in the new definition D'. l is the set of locations involved, and T is the set of communication channels (i.e., added inputs and outputs) needed for the execution of D. The set of locations involved is used for the suppression of unused definitions and expressions.
This projection operation is straightforwardly extended to programs. Projection
of expressions and transitions are noted respectively H ▶ e : t/l/T =s⇒ e'/D and
H ▶ u : l/T =s⇒ u'/D, where D is in both cases an additional definition of outputs for communications occurring within e or u.
The type system is given in Figures 9 and 10. An immediate value is located on any projected program (rule Imm). A projected variable results in itself iff it is located on the computed fragment (rule Inst).
The rules Comm-From and Comm-To define a subtyping mechanism for in- serting communications between the two fragments. An expression e of type t at s, which is a value entirely located on s, can be communicated to the other fragment s', and thus can be considered as being of type t at s'. The rule Comm-From defines a new communication channel as the value of e, and suppresses this expression in the projection. The rule Comm-To replaces this expression by this new communication channel. For example, this rule is applied, on the program of Figure 6, after the computation of (x1>0) on the data fragment. The channel added by this application
u1
is Ad → A .
The projection of a pair is the projection of its compounds, new definitions of these compounds being put in parallel (rule Pair). The projection of an equation involves computing the projection of the expression, and putting in parallel with the

projected equation the set of definitions of the communications channels (rule Def).
The rules Suppr-Expr and Suppr-Def allow the suppression of any expression on the fragment where no part of this expression is involved.
Projection of a node (rule Node) involves projecting its compounds, and then adding the communication channels used in these compounds as inputs and outputs of the resulting node, so as to allow multiple instantiations of this node : for exam- ple, c1 to c4 are added as outputs of the node task on the Boolean fragment (see Figure 7). The rules App-Keep and App-Suppr state that an application is kept iff the fragment computed appears in the set of fragments involved in the computation of the applied node. If it is kept, then the set of communication channels involved within this node are added as inputs and outputs of the application.
Figure 10 shows the rule for the projection of automata. The rules Trans-D and Trans-B state that an expression triggering a transition, once computed, must be located on the Boolean fragment. A communication channel is then added, from the Boolean fragment to the data one, holding the value of this expression (c1 to c4 on Figure 7). The projected transition holds then the expression composed only of the value of this channel. This channel is computed in the state where the transition can be triggered (rule Handler). Then, the projection of an automaton involves the projection of every handler (rule Automaton).
Given two programs P = d1; ... ;dn;D and P ' = d' ; ... ;d' ;D', we note P P '
1	p
the synchronous composition of P and P ', defined as:
(d1; ... ;dn;D)  (d' ; ... ;d' ;D')= d1; ... ;dn;d' ; ... ;d' ;(D and D')
1	p	1	p
The semantics of a program P is given by a relation noted Si ▶ P : So, meaning that, given the sequence of inputs Si = Ri .Ri ... ., the execution of the program
1	2
P results in the sequence of outputs So = Ro.Ro... ., where R denotes a reaction
1	2
environment, mapping names to instantaneous values. The semantics is taken from
[6] and not rewritten here.
The following property is a refinement of the result stated in [7]. It states that the composition of the two fragments obtained by projection has the same semantics as the original program.
Property 5.1 (Semantical equivalence) For all Si, So, P, H, H', l and T such

that Si ▶ P : So, H ▶
Si ▶ PA  PB : So.
P : H'/l/T
=⇒ PA and H ▶
P : H'/l/T
=⇒ PB, then

Application of Discrete Controller Synthesis
The formal properties to be ensured by the final program will be expressed as prop- erties on the sequence of outputs So. Given a CTL property Φ, we note P |= Φ the fact that the program P satisfies Φ. We only consider safety properties, i.e., properties of the form Φ= ∀ ϕ, ϕ being a predicate on reaction environments. For instance, the property of exclusivity of the two tasks in the program of Section 3 can be expressed as ∀  ϕ, with ϕ(R)= (R(act1)= false ∨ R(act2)= false).


t ≤ (H(x))	s ∈ locations(t)

(Imm) H ▶ i : b at s/{s}/∅ =s
(Inst)	s
i/є	H ▶ x : t/ locations(t)/∅ =⇒
x/є

H ▶ e : t at s/l/F =s	'

(Comm-From)
⇒ e /D
'	'	c  '  s	'

H ▶ e : t at s /l ∪ {s }/F, [s '→ s ] =⇒ ()/D and cn = e

'
H ▶ e : t at s/l/F =s	'

(Comm-To)
⇒ e /D
'

'	'	c  '  s
H ▶ e : t at s /l ∪ {s }/F, [s '→ s ] =⇒ cn/D
H ▶ e1 : t1/l1/F1 =s	'	1	H ▶ e2 : t2/l2/F2 =s	'	2

(Pair)
⇒ e1 /D
s	'  '
⇒ e2/D

H ▶ e1, e2 : t1 × t2/l1 ∪ l2/F1, F2 =⇒ e1, e2 /D1 and D2

(Suppr-Expr)
s /∈ l
s
(Suppr-Def)
s /∈ l
'	s

H ▶ e : t/l/F =⇒ ()/є	H ▶ D : H /l/F =⇒ є
H ▶ e : t1 × ... × tn/l/F =s	'

(Def)
⇒ e /D
H ▶ (x1,. .. , xn)= e : [t1/x1,. .., tn/xn]/l/F =⇒ x = e'
and D

H ▶ D1 : H1/l1/F1 =s	'	H ▶ D2 : H2/l2/F2 =s	'

(And)
s	'	'

H ▶ D1 and D2 : H1, H2/l1 ∪ l2/F1, F2 =⇒ D1 and D2

(Node)
H, x
: t ,H ▶ D : H /l /F =s
'
D	H, x
: t ,H ▶ e : t/l /F =s	'

i	i	1
1  1  1  ⇒
c	c
i	i	1
2  2  ⇒ e /De
c'	c'

(F ,F ) ↑ s = [s
1 s ,.. ., s →n s ]	(F ,F ) ↓ s = [s'
1 s,. .., s'
p s]

1  2	'→ 1
n	1 2
1 '→
p '→

H ▶ node ƒ (x1,. .. , xn)= e with D : [gen ((t1 × .. . × tn) −⟨l1/F1, F2⟩→ t)/ƒ ]/l1 ∪ l2/∅
H
=s	'
⇒ node ƒ (x1,.. ., xn, c1, ... , c' )= (e', c1,. .. , cn) with D' and De

(App-Keep)
s	'	s	'

H ▶ ƒ : t −⟨l1/F1⟩→ (t1 × .. . × tn)/l2/F2 =⇒ ƒ /D1	H ▶ e : t/l3/F3 =⇒ e /D2

s ∈ l
F ' ∼= F
F ' ↑ s = [s
c1 s ,.. ., s cn s ]	F ' ↓ s = [s'
'
1 s,. .., s'
c'
p s]

1	1	1	1
'→ 1
n	1	1 '→
'
p '→

H ▶ x = ƒ (e): [t1/x1,.. ., tn/xn]/l1 ∪ l2 ∪ l3/F1 , F2, F3
=s	'  '  '	'
⇒ (x1,. .., xn, c1,.. ., cn)= ƒ (e , c1 ,.. ., cp) and D1 and D2
(App-Suppr)
H ▶ ƒ : t −⟨l1/F1⟩→ (t1 × .. . × tn)/l2/F2 =s	'	1
⇒ ƒ /D
H ▶ e : t/l3/F3 =s	'	2	s /∈ l1	F ' ∼= F1
⇒ e /D	1
'	s
H ▶ p = ƒ (e): [t2/x]/l1 ∪ l2 ∪ l3/F1 , F2, F3 =⇒ D1 and D2

Fig. 9. Rules for the projection operation.

Definition 6.1 (Safety property satisfaction)
A sequence S = R1.R2	satisfies a property  ϕ (noted S |=  ϕ) iff ∀i, ϕ(Ri).
A program P satisfies a property ∀ ϕ (noted P |= ∀ ϕ) iff for all Si, So such that Si ▶ P : So, So |=  ϕ.
The following property states that safety properties are preserved by synchronous composition: given a synchronous program P satisfying a safety property Φ, any synchronous composition P P ' satisfies Φ. This result has been stated in [10].


H ▶ e : t at A /l1/F1 =Ad  '	1	H ▶ u : l2/F2 =Ad  '	2
(Trans-D) 	b	⇒ e /D	⇒ u /D 
H ▶ until e then S u : l1 ∪ l2/F1, F2, [A  c A ]


=Ad
b '→  d
'

⇒ until c then S u /D1 and D2
H ▶ e : t at A /l1/F1 =Ab  '	1	H ▶ u : l2/F2 =Ab  '	2
(Trans-B) 	b	⇒ e /D	⇒ u /D 
H ▶ until e then S u : l1 ∪ l2/F1, F2, [A  c A ]


=Ab
b '→  d
'

⇒ until cn then S u /c = e and D1 and D2
H ▶ D : H'/l1/F1 =s D1	H ▶ u : l2/F2 =s	'	2

(Handler)
⇒	⇒ u /D

'	s

H ▶ D u : H /l1 ∪ l2/F1, F2 =⇒ D1 and D2 u
∀i ∈ {1, ... , n},H ▶ hi : Hi/li/Fi =s h'


(Automaton)
l = l
1 ∪ .. . ∪ ln
F = F1,. .., Fn	H
⇒ i
merg (H1,. .. , Hn
'


H ▶ automaton S1 → h1 .. . Sn → hn end : H /l/F
=s	'	'
⇒ automaton S1 → h1 . .. Sn → hn end



Fig. 10. Rules for the projection operation (Automata).

Property 6.2 (Conservation of safety properties)
∀P, Φ,P ',P |=Φ ⇒ (P P ') |= Φ.
Definition 6.3 (Discrete controller synthesis) DCS is a partial function such that, given a program P , a set of controllable inputs Ic of P , and a safety property Φ, then if DCS(P, Ic, Φ) is defined, then (P  DCS(P, Ic, Φ)) |= Φ.
The following result is the formalization of the whole method. It states how, from a program P , a set of controllable inputs Ic, and a safety property Φ, a semantically compatible program P ' can be obtained, satisfying Φ. P and P ' are not strictly semantically equivalent, as Ic are inputs of P but local variables (defined by the controller) of P '. We will also define a similarity relation ≤I between programs as follows (where (R1.R2... .) \ I = (R1 \ I).(R2 \ I)  , and R \ I = R' iff dom(R')= 
dom(R) \ I and ∀x ∈ dom(R'), R'(x)= R(x)):
P ' ≤I P iff ∀Si , So, Si ▶ P ' : So ⇒ ∃Si, Si \ I = Si ∧ Si ▶ P : So
Theorem 6.4 For all P, I = Iu  Ic, Φ, let Pb, Pd, H,T,l such that H0 ▶ P :

H/l/T
A
=⇒ Pb and H0 ▶ P : H/l/T
A
=⇒ Pd, then if C = DCS(Pb, Ic, Φ) is de-

fined, then let P ' = (Pd  Pb  C), P ' ≤Ic P and P ' |= Φ.
Proof. From property 5.1, Pb  Pd is semantically equivalent with P . Then, for any program C whose output domain is I, (Pb  Pd  C) ≤I P .
Then, (Pb  Pd  DCS(Pb, Ic, Φ)) ≤I P .
By definition of DCS, (Pb  DCS(Pb, Ic, Φ)) |= Φ. Then from property 6.2, for all
P , (P Pb  DCS(Pb, Ic, Φ)) |= Φ. Then, (Pd  Pb  DCS(Pb, Ic, Φ)) |= Φ.	 

Discussion
We have shown an adaption of an automatic distribution method to allow the sepa- rate compilation and transformation of a program. This adaptation has been illus- trated on the specific program transformation of discrete controller synthesis. From an initial program, we have shown how to extract the Boolean and the data frag- ments, how to apply DCS on the Boolean fragment to ensure a safety property, and finally how to recombine by synchronous product the controlled Boolean fragment and the data fragment in such a way that the semantics of the resulting program is ensured to be a simulation refinement of the initial one.
Compared with [7], this article, besides being an application of this method, shows how it can be adapted towards the distribution of programs on an heteroge- neous architecture (i.e., whose computing resources does not all provide the same operations), instead of homogeneous ones, as targetted in this previous work. This adaptation consists, for the declaration of the architecture, to attach specific oper- ations to each declared location.
More generally, this example illustrates how a tool allowing co-design of different parts of programs, such as Orccad [3], Ptolemy [4], can integrate two approaches, the design by a unified language or paradigm allowing more control of the program semantics, and the separate compilation, program transformation or analysis. From this point of view, this work can be related to the different approaches of unification of different paradigms in one language (modes and dataflow in Mode automata [11], and its generalization in Lucid Synchrone [6]). The purpose of this work is to show how such language integrations does not stand as an obstacle for the further application of heterogeneous compilation paradigms. Such comparable distribution method has been applied for the design of multi-tier systems [15]: the functions are then annotated with the location where it is executed. We show here how these annotations can be integrated in a language, and how a type system can be used to infer the location of every value or expression.
The prospects of this work lies mainly in considering modular program trans- formations and analysis. From the point of view of the specific problem addressed here, controller synthesis for hierarchical systems has been studied in [14], and the interaction of this method with modular compilation should be studied. The interest of this method for other mixed models shall also be evaluated.

References
K. Akesson, Martin Fabian, Hugo Flordal, and Arash Vahidi. Supremica — a tool for verification and synthesis of discrete event supervisors. In Proc. of the 11th Mediterranean Conference on Control and Automation, Rhodos, Greece, 2003.
K. Altisen, A. Clodic, F. Maraninchi, and E. Rutten. Using controller synthesis to build property- enforcing layers. In European Symposium on Programming (ESOP), April 2003.
J.-J. Borrelly, E. Coste-Manière, B. Espiau, K. Kapellos, R. Pissard-Gibollet, D. Simon, and N. Turro. The Orccad architecture. Int. J. of Robotics Research, 17(4), 1998.
J. Buck, S. Ha, E. A. Lee, and D. G. Messerschmitt. Ptolemy: A framework for simulating and prototyping heterogenous systems. Int. Journal in Computer Simulation, 4(2):155–182, 1994.


P. Caspi and M. Pouzet. Synchronous Kahn networks. In ICFP ’96: Proceedings of the ﬁrst ACM SIGPLAN international conference on Functional programming, pages 226–238, New York, NY, USA, 1996. ACM Press.
J.-L. Colaço, B. Pagano, and M. Pouzet. A Conservative Extension of Synchronous Data-flow with State Machines. In ACM International Conference on Embedded Software (EMSOFT’05), Jersey city, New Jersey, USA, September 2005.
G. Delaval, A. Girault, and M. Pouzet. A type system for the automatic distribution of higher-order synchronous dataflow programs. Rapport de recherche INRIA n◦6378, November 2007.
G. Delaval and É. Rutten. A domain-specific language for multitask systems, applying discrete controller synthesis. EURASIP Journal on Embedded Systems, 2007:Article ID 84192, 17 pages, 2007.
N. Halbwachs, P. Caspi, P. Raymond, and D. Pilaud. The synchronous data-flow programming language Lustre. Proc. of the IEEE, 79(9):1305–1320, September 1991.
N. Halbwachs, F. Lagnier, and P. Raymond. Synchronous observers and the verification of reactive systems. In M. Nivat, C. Rattray, T. Rus, and G. Scollo, editors, Third Int. Conf. on Algebraic Methodology and Software Technology, AMAST’93, Twente, June 1993. Workshops in Computing, Springer Verlag.
F. Maraninchi and Y. Rémond. Mode-automata: About modes and states for reactive systems. In
European Symposium On Programming (ESOP), Lisbon (Portugal), March 1998. Springer verlag.
F. Maraninchi and Y. Rémond. Mode-automata: a new domain-specific construct for the development of safe critical systems. Science of Computer Programming, (46):219–254, 2003.
H. Marchand, P. Bournai, M. Le Borgne, and P. Le Guernic. Synthesis of discrete-event controllers based on the signal environment. Discrete Event Dynamic System: Theory and Applications, 10(4), October 2000.
H. Marchand and B. Gaudin. Supervisory control problems of hierarchical finite state machines. In
41th IEEE Conference on Decision and Control, Las Vegas, USA, December 2002.
M. Neubauer and P. Thiemann. From sequential programs to multi-tier applications by program transformation. In POPL ’05: Proceedings of the 32nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages, pages 221–232, New York, NY, USA, 2005. ACM Press.
M.	Pouzet.	Lucid	synchrone	v3,	release	and	reference	manual.
http://www.lri.fr/~pouzet/lucid-synchrone .
P. J. Ramadge and W. M. Wonham. Supervisory control of a class of discrete event processes. SIAM
J. Control Optim., 25(1):206–230, 1987.
É. Rutten. A framework for using discrete control synthesis in safe robotic programming and teleoperation. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA’2001), pages 4104–4109, Seoul, Korea, May 2001.
J.-P. Talpin and P. Jouvelot. Polymorphic type, region and effect inference. Journal of Functional Programming, 2(3), 1992.

A	Type system
(Imm) H ▶ i : b at s/{s}/∅


(Inst)
t ≤ (H(x))	s ∈ locations(t)


H ▶ x : t/ locations(t)/∅



H ▶ e : t at s/l/T
(Comm) H ▶ e : t at s'/l ∪ {s'}/T, [s →c

s']



(Pair)
H ▶ e1 : t1/l1/T1	H ▶ e2 : t2/l2/T2 H ▶ e1, e2 : t1 × t2/l1 ∪ l2/T1, T2



(Def)
H ▶ e : t1 × ... × tn/l/T


H ▶ (x1,... , xn)= e : [t1/x1,... , tn/xn]/l/T



(And)
H ▶ D1 : H1/l1/T1	H ▶ D2 : H2/l2/T2 H ▶ D1 and D2 : H1, H2/l1 ∪ l2/T1, T2

(Node)
H, xi : ti, H1 ▶ D : H1/l1/T1	H, xi : ti, H1 ▶ e : t/l2/T2 H ▶ node f (x1,... , xn)= e with D :
[genH ((t1 × ... × tn) −⟨l1/T1, T2⟩→ t)/f ]/l1 ∪ l2/∅
H ▶ f : t −⟨l1/T1⟩→ (t1 × ... × tn)/l2/T2sf '/D1
H ▶ e : t/l3/T3se'/D2	T ' ∼= T1

(App)
H ▶ x = f (e): [t1/x1,... , tn/xn
]/l1 ∪ l2 ∪ l3/T ', T2, T3



(Trans)
H ▶ e : t at Ab/l1/T1	H ▶ u : l2/T2


H ▶ until e then S u : l1 ∪ l2/T1, T2, [A →c A ]
H ▶ D : H'/l1/T1	H ▶ u : l2/T2

(Handler)


H ▶ D u : H'/l1 ∪ l2/T1, T2

i ∈ {1,... , n},H ▶ hi : Hi/li/Ti
l = l1 ∪ ... ∪ ln	T = T1,... , Tn	H' = merge(H1,... , Hn)

(Automaton)
H ▶ automaton S1 → h1 ... Sn → hn end : H'/l/T
