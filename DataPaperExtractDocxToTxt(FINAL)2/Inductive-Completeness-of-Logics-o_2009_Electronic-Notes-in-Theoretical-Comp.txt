

Electronic Notes in Theoretical Computer Science 228 (2009) 101–112
www.elsevier.com/locate/entcs
Inductive Completeness of Logics of Programs
Daniel Leivant
Indiana University, Bloomington

Abstract
We propose a new approach to delineating logics of programs, based directly on inductive definition of program semantics. The ingredients are elementary and well-known, but their fusion yields a simple yet powerful approach, surprisingly overlooked for decades.
The denotational semantics of a regular program can be construed as a relation, easily definable by structural induction on programs. Invoking the framework of canonical theories for (iterated) inductive definitions, we consider the first-order theory for program semantic, i.e. with the generative clauses as construction (introduction) rules, and their dual templates as deconstruction (elimination) rules.
We prove that Hoare’s logic is inductively complete, in the sense that a partial-correctness assertion is Hoare provable iff it is provable in the inductive theory (with deconstruction for formulas in the base vocabulary). Thus first-order automated theorem-proving can be applied directly to program verification.
Proceeding to program termination, we show that a total correctness assertion is valid iff it is provable in the inductive theory without any use of deconstruction. This is yet another take on the first-order nature of total correctness.
Keywords: Inductive definitions, program semantics, inductive completeness, Hoare logic


Introduction
Background
Logics of programs inherently exceed first-order logic, because program semantics is defined in terms of iterative processes. We can capture such definitions using second-order formulas [9], existential fixpoints [1], or explicit reference to the natural numbers (The Hungarian School), but not by a first-order theory. Consequently, the delineation of logics of programs cannot parallel the characterization of first-order logic by soundness and completeness for general (“uninterpreted”) validity.
The early attempts to refer instead to local completeness, i.e. completeness with
respect to one structure at a time, led to Cook’s Relative Completeness Theorem. However, notwithstanding the persistent centrality of Cook’s relative completeness
[2] in PL research, that notion has foundational and practical drawbacks [10]. For one, relative completeness fails to demarcate the boundaries of logics of programs:

1 leivant@cs.indiana.edu

1571-0661/© 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.12.119

there are, for example, proper extensions of Hoare’s Logic that are sound and rela- tively complete!
An alternative approach is to match logics of programs with formalisms for explicit reasoning about programs, such as second-order logic. A common objection to second-order logic, that it is non-axiomatizable for its intended semantics, is off the mark here. On the one hand there are natural deductive calculi for second-order logic, which are sound and complete for natural non-standard semantics (Henkin’s structures); on the other hand, the same objection applies to arithmetic! Indeed, it turns out that Hoare’s Logic matches second-order logic with first-order set- existence, and Dynamic Logic matches second-order logic with “computational”
(i.e. strict-Π1) set-existence [9,10].
Here we consider an approach dual to explicit second-order rendition of program semantics, namely an implicit but ﬁrst-order rendition. We consider the inductive definition of program semantics, and invoke the well-known framework of first-order theories for such definitions [7,8,4,12,5]. We show that Hoare’s Logic matches the inductive theory with deconstruction (i.e. induction) restricted to the base vocabu- lary. Also, the valid total correctness assertions match with the generative fragment of the inductive theory (i.e. with no deconstruction at all).
Since this approach is strictly first-order, it is particularly accessible conceptu- ally, expositorily, and for use of automated theorem proving tools. It also meshes generically with the long-standing tradition of defining program semantics induc- tively. As soon as an inductive definition is given for a programming language, we automatically obtain the corresponding first-order inductive-definition theory, and can tackle the question of completeness of a logic for that theory.
A match between Hoare’s logic and inductive theories was observed already by the Hungarian school of “nonstandard dynamic logic” (see e.g. [3,16]). However, the first-order theories they considered invoke the natural numbers as an auxiliary data- type. Our present approach calls for for no such extraneous data-types, and is more generic, in that it applies directly to all programming constructs with inductively defined semantics, even when they lack a simple iterative definition in terms of the natural numbers.

Guarded iterative programs
To focus on the essentials, we consider guarded iterative programs, i.e. regular pro- grams with tests and assignments as atomic actions. This provides a clean separa- tion between the basic programming concepts. The language is generic with respect to an underlying vocabulary V , consisting of a finite set of constant-, function- and relation-identifiers, assigned positive arities when appropriate.
As usual, V -assignments are expressions of the form x := t, where x is a vari- able and t a V -term. In addition to assignment, we use as atomic programs queries.
of the form ?ϕ, ϕ a first-order V -formula. In practice queries are restricted to quantifier-free formulas, but this makes no difference for our discussion. The regu- lar V -programs α, β, . . . are obtained from atomic programs by composition (α; β), union α ∪ β, and nondeterministic iteration (α∗).

Given a V -structure S, the operational semantics of programs is obvious. Recall (e.g. from [6]) that “while” programs are definable in terms of guarded iterative programs. Namely, a program if ϕ then α else β endif is rendered by (?ϕ; α) ∪ (?¬ϕ; ϕ); and while ϕ do α enddo is rendered by (?ϕ; α)∗; ?¬ϕ.
Inductive deﬁnition of program semantics
Generic methods for associating to a given collection of inductive (i.e. generative) definitions first-order inductive theories are well-known. The semantics of regular programs has a particularly simple form of inductive definition, using atomic pro- duction rules, i.e. natural-deduction inferences with atomic premises and conclusion, as follows.
For a list x = (x1,..., xn) of variables, let P[x] consists of the regular V -
programs with all assigned variables among x1 ... xn. Note that if α is such a program, then so are all its subprograms. Given a V -structure S, each program α ∈ P[x] defines a 2n-ary relation [α]]S on the universe |S| of S, that holds between a, b ∈ |S|n iff α has a complete execution that starts with x bound to a, and terminates with x bound to b.
For n ≥ 1, let Vˆ n be the expansion of the underlying vocabulary V with 2n-ary relational identifiers Mn for each α ∈ P[x]. The intent is that Mn denotes, in each
α	α
V -structure S, the relation [α]]n above. We omit n when in no danger of confusion. An inductive definition of [α]]n, uniform for all V -structures, is given by genera- tive clauses that can be rendered by following atomic rule-templates, which can be
construed as natural-deduction rules.


Assignment Test
Composition
Mx :=t(x, xi←t)	where xi←t is x1 ... xi−1, t, xi+1 ... xn ϕ[x]


M?ϕ(x, x)
Mβ(x, u)	Mγ(u, v)


Mβ;γ(x, v)


Branching
Mβ(x, v)


Mβ∪γ(x, v)
Mγ(x, v)


Mβ∪γ(x, v)


Iteration


Mβ∗ (x, x)
Mβ∗ (x, u)	Mβ∗ (u, v)


Mβ(x, v)


Expressing program properties
We refer to the language of first-order dynamic logic, DL, as e.g. in [6]. It is easy to see that, modulo the intended reading of the identifiers Mα, the expressive power of the Vˆ -formulas is identical to the expressive power of DL formulas over the base vocabulary V . To avoid clutter let us posit that all assigned-variables in programs
are among x1 ... xn, and that Vˆ stands for Vˆ n. Recall that in a DL formula ∀u ϕ 

the variable u cannot be among the assigned variables in ϕ, and we can therefore posit that no quantified variables are among x1 ... xn. 2
Each DL V -formula ϕ can be expressed as a Vˆ -formula ϕ , defined by structural recurrence on ϕ. For ϕ modal-free we take of course ϕ to be ϕ itself. If ϕ is [α]ϕ0, then ϕ is ∀v1 ... vn Mα(x, v) → {v/x}ϕ . Finally, we let  commute with the first-
order logical operations; that is: if ϕ is ϕ0 ∧ ϕ1 then ϕ is ϕ ∧ ϕ and similarly for
0	1
other connectives and the quantifiers.
Conversely, each Vˆ -formula ψ is expressible as a DL V -formula ψq, defined by structural recurrence on ψ. If ψ is a V -formula, we defined ψq to be ψ. If ψ is Mα(t, q) then ψq is x = t → ⟨α⟩(x = q). And q commutes with the first-order logical operations.
Observe that these interpretations are trivially sound in the following sense.
Theorem 1.1 For every V -structure S, if Sˆ is the Vˆ -expansion of S in which each Mα is interpreted as the denotational semantic of α, then for every DL V -formula ϕ, Sˆ |= ϕ ↔ ϕ , and for every Vˆ -formula ψ, Sˆ |= ψ ↔ ψq.
Corollary 1.2 S |= ϕ iff Sˆ |= ϕ .

The inductive theory of regular programs
The generative rules above, defining inductively program semantics, bound the in- terpretation of the relation-identifiers Mα from below. Bounding inductively gener- ated sets from above, namely as the minimal relations closed under the generative clauses, is a second-order condition which has no first-order axiomatization (except for degenerated cases). However, we can approximate that delineation as the mini- mal one among a given collection of deﬁnable relations. Namely, the deconstruction template for Mα states that Mα is contained in every definable relation closed under the generative rules for Mα. A familiar example is the deconstruction for the set N of natural numbers. With N as unary relational-identifier, the generative clauses are



N (0)	and yielding the Deconstruction template
ϕ[z]
N (x)


N (s(x))

N (x)	ϕ[0]
ϕ[x]
··· 
ϕ[sz]
(assumption ϕ[z] is discharged (i.e. closed)) (z not free in other open assumptions

that is, the natural-deduction rule of induction on N [15].
Analogously, the Deconstruction Rule for the iteration construct ∗ should
be

2 Note that an expression such as ∀x [x := 1](x = 1) is not a legal DL formula, whereas ∀x [y := x](y = x) is.




Mβ∗ (x, v)	ϕ[z, z]
ϕ[x, v]
ϕ[u, w]	Mβ(z, u)
··· 
ϕ[z, w]

(assumptions Mβ(z, u), ϕ[u, w] are discharged
z, w, u not free in other open assumptions)


The formula ϕ above is the eigen-formula of the inference. A related, more practical template is



Unfolding	Mβ∗ (x, v)
Mβ(u, w)
··· 
ψ[u] → ψ[w]



ψ[x] → ψ[v]

However, we have
Proposition 1.3 The schemas Deconstruction and Unfolding are equivalent.
Proof. Posit  the  Deconstruction schema,  and  assume the premises of
Unfolding. Then the three premises of Deconstruction hold with ϕ[x, y] taken
as ψ[x] →ψ[y]. We thus obtain ψ[x] →ψ[v], as required.
Conversely,  posit the Unfolding schema,  and assume the premises of
Deconstruction. Then the premises of Unfolding hold with ψ[y] taken to be
ϕ[x, y]. Thus Unfolding yields ψ[x] → ψ[v], establishing Deconstruction.	 

Note that deconstruction rules for the remaining program constructs are degen- erate, in the sense that they are equivalent to explicit definitions. For example, the Deconstruction of composition, combined with Composition Introduction yield an explicit definition of Mβ;γ. More generally, Mα can be explicitly defined in terms of components of α, for all non-loop programs α,
Mxi:=t(x, v) ↔ (vi = t[v] ∧  j/=i vj = xj).

M?χ(x, v) ↔ (χ ∧ v = x)

Mβ;γ(x, v) ↔ ∃u Mβ(x, u) ∧ Mγ(u, v)

Mβ∪γ(x, v) ↔ Mβ(x, v) ∨ Mγ(x, v)
We write Indn(Reg) for the inductive theory given by the universal closure of the formulas above. We omit the superscript n as well as Reg when in no danger of confusion. Two weaker theories are of interest. The Elementary inductive-theory, Ind0 has inductive-elimination restricted to first-order eigen-formulas. The Gen- erative Theory Gen is weaker yet, and has only the inductive-introduction rules, without inductive-elimination. Thus Gen is an inherently first-order theory, in that it does not have templates intended to approximate a second-order rule.

Partial correctness
Hoare Logic for regular programs
Recall that a partial correctness assertion (PCA) can be construed as a DL formula of the form ϕ → [α] ψ, abbreviated ϕ [α] ψ, where ϕ and ψ are (modal-free) first- order. In a partial-correctness logic the only modal formulas used are PCAs.
Given a vocabulary V and a V -theory T, the Hoare’s Logic (based on T) for reg- ular programs is the partial-correctness logic axiomatized by the following calculus H∗(T). Note that the first-order formulas used in H∗(T) may refer to vocabulary identifiers not appearing in T; in particular, even if T is empty, all first-order for- mulas are permissible. Let ▶ denote provability in first-order logic. The inference rules of H(T) are as follows.




Assignment
{t/x}ϕ [x := t] ϕ




Composition Branching Iteration Query Consequence
ψ [α] χ	χ [β] ϕ


ψ [α; β] ϕ
ψ [α] ϕ	ψ [β] ϕ ψ [α ∪ β] ϕ
ϕ [α] ϕ


ϕ [α∗] ϕ
T ▶ ψ ∧ χ→ϕ ψ[?χ]ϕ
T ▶ ψ' → ψ		ψ [α] ϕ	T ▶ ψ' → ψ ψ' [α] ϕ'

A formalism for reasoning about PCAs for guarded iterative programs is ob- tained by replacing the rules for Branching, Query, and Iteration by rules for the remaining program constructs of guarded iterative programs.


Inductive soundness of Hoare’s Logic
Clearly, Hoare logic is semantically sound. Only slightly less trivial is the observa- tion that it is sound for Ind0:
Theorem 2.1 If H∗(T) ▶ ψ [α] ϕ then T + Ind0 ▶ (ψ [α] ϕ) .
Proof. Straightforward induction on proofs in T + Ind0.

Consider, for example, Hoare’s Iteration Rule.  If ψ [α∗] ψ is provable in
H∗(T), then we posit by IH that
T + Ind0 ▶ ψ[x] ∧ Mα(x, v) → ψ[v] But then we indeed have, by the Unfolding Rule
T + Ind0 ▶ ϕ[x] ∧ Mα∗ (x, v) → ϕ[v]	 

A point of interest is that first-order proofs of T + Ind0 obtained in the proof of Theorem 2.1 do not use the generative (data introduction) rules of the inductive theory Ind. A dual observation holds for total correctness assertions (Theorem 3.1).

Approximating program semantics with ﬁnitely many instances
The second-order nature of the relations Mβ∗ is approximated by the first-order schema of Deconstruction. Moreover, any particular proof P of Ind0 uses, for each
∗
β , only finitely many instances of Deconstruction for Mβ∗ . We show here how this
can be used.
Let A be a finite collection of programs, with all assigned variables among x1 ... xn. Let Φ be a mapping that assigns to each β∗ ∈ A a finite set Φ(β) of 2n-ary first-order predicates λy, z ϕi. For α ∈ A, let MΦ be a first-order formula,
defined by induction on α, as follows.
For atomic α (assignment or test) MΦ is the explicit definition of Mα, as above.
MΦ (u, v) is ∃w MΦ(u, w) ∧ MΦ(w, v).
β;γ	β	γ
MΦ  (u, v) is MΦ(u, v) ∨ MΦ(u, v).
β∪γ	β	γ
MΦ (u, v) is

  { ClΦ[ϕ] → ϕ[u, v] | (λy, z. ϕ[y, z]) ∈ Φ(β∗) }

where ClΦ[ϕ] is
( ∀wϕΦ[w, w] ) ∧ ( ∀w, y, z ϕΦ[w, y] ∧ MΦ(y, z) → ϕΦ[w, z] ) 
Lemma 2.2 For α ∈ A and Φ as above, Ind ▶ Mα(u, v) → MΦ(u, v)
Proof. The proof is straightforward by (structural) induction on ϕ.	 
Fix A, Φ as above, and let ψ be a formula not using the variables w, y, z used in defining the predicates MΦ, and with all programs in A. We write ψΦ for the result of replacing in ψ each atomic subformula Mα(t, q) by the formula MΦ[t, q] defined
above.
Lemma 2.3 Suppose P is a proof in T + Ind of a formula ψ. Let Φ(β) be the set of eigen-formulas in P of Deconstruction for Mβ∗ . Then T ▶ ψΦ.

Proof. The Lemma, generalized from formulas ψ to sequents Γ ⇒ ψ, is proved by a straightforward induction on proofs.	 

Inductive completeness of Hoare’s Logic
Our main result about partial correctness logic is the completeness of Hoare’s Logic for the Elementary Inductive Theory Ind0. While this theorem easily implies Cook’s Relative Completeness Theorem, we cannot simply adapt Cook’s proof. If we could, then the proof would also apply to the full inductive theory Ind, for which the Theorem’s statement is false: there are PCAs provable in Ind that are not provable in Hoare’s Logic [10]. Thus, the proof of Theorem 2.1 must depend on the restriction of Deconstruction to first-order formulas.
Theorem 2.4 For all V -theories T, if T + Ind0 ▶ (ψ [α] ϕ) , then H∗(T) ▶
ψ [α] ϕ.
Proof. (Outline). The proof is by (structural) induction on α.
Suppose α is an assignment, say x1 := t. Then (ϕ[α]ψ) is

∀u, v. ϕ[u] ∧ v1 = t[u] ∧ 
i=2..k

vi = ui → ψ[v]

which trivially implies
ϕ[x] → ψ[t[x], x2 ... xk]
Since this formula is valid, it is first-order provable. But in H∗ we have
ψ[t[x], x2 ... xk] [α] ψ[x]
which combined with the formula above by the rule of Consequence yields ϕ[α]ψ.
α is ?χ. Then (ϕ[α]ψ) is
∀u, v. ϕ[u] ∧ χ[u] ∧ v = u → ψ[v]
and so T ▶Ind ϕ∧χ → ψ. Since this entailment is valid, we have T ▶L1 ϕ∧χ →
ψ, and so ϕ[α]ψ is obtained in H∗ by the Query Rule.
α is β; γ. Then (ϕ[α]ψ)  is
∀u, v. ϕ[u] ∧ ∃w. Mβ[u, w] ∧ Mγ[w, v] → ψ[v] Thus, we assume that Ind0 proves
Mβ[u, w] ∧ Mγ[w, v]  → (ϕ[u] →ψ[v])
By Lemma 2.3 there are expansions M' [u, w] and M' [w, v] of Mβ[u, w] and Mγ[w, v]
β	γ
respectively, such that
M' [u, w] ∧ M' [w, v]  → (ϕ[u] →ψ[v])
β	γ

Let

By Lemma 2.2 we have

χ[x]	≡	M' [x, v] → ψ[v]

Ind0, T  ▶	ϕ[u] ∧ Mβ[u, w] → χ[w],
so by IH H∗(T) proves ϕ[β]χ. By Lemma 2.2 we also have, in Ind0,
χ[w] ∧ Mγ[w, v] → ψ[v],

which by IH implies that H∗(T) proves χ[γ]ψ. Using the Composition Rule of
H∗ we obtain ϕ[α]ψ.
α is β ∪ γ. Then (ϕ[α]ψ)  is

∀u, v. ϕ[u] ∧ (Mβ[u, w] ∨ Mγ[w, v])  → ψ[v]

from which we have both (ϕ[β]ψ)  and (ϕ[γ]ψ) . By IH both ϕ[β]ψ and ϕ[γ]ψ
are provable in H∗(T), from which ϕ[α]ψ follows by the Branching Rule of H∗.
α is β∗. Then (ϕ[α]ψ) is
ϕ[u] ∧ Mβ∗ [u, v]  → ψ[v]

By Lemma 2.3 there is a finite set Ξ of first-order predicates such that, in first order logic,



Define
ϕ[u] ∧ M Ξ [u, v] → ψ[v]	(1)

χ[x]	≡df	∃w.ϕ[w] ∧ M Ξ [w, x]

By Lemma 2.2 we have ▶ Mβ[u, v] → M Ξ[u, v], so (1) implies
χ[u] ∧ Mβ[u, v] → χ[v]
which by IH implies that χ[β]χ is provable in H∗(T). Using the Iteration Rule of H∗, we get χ[β∗]χ.
But in first order logic we have ϕ[x] →χ[x], by taking w = x. Using the Rule of Consequence, we thus obtain ϕ[β∗]χ in H∗(T). On the other hand, by (1) we have χ[x] →ψ[x] in first order logic. So by the rule of Consequence we get ϕ[β∗]ψ.
 
A result related to Theorem 2.4 was proved by Ildiko Sain [16], who showed that “Floyd Method” is complete for truth in all structures where a predicate de- noting program-semantics satisfies “relational induction”. Sain’s treatment differs methodologically from our approach in several ways. First, it refers to Csirmaz’s abstract notion of “program” [3] which is based on first-order expressibility of pro- gram semantics within a structure, and on provable termination, two requirements

that offset the notion’s generality. This means that the relevance of results proved about Csirmaz’s programs to Hoare’s Logic, not only require a special adaptation, but are limited to terminating programs. Moreover, the approach of [3], while striv- ing for generality, is in fact limited to simple programming constructs, and requires an auxiliary machinery for expressing program semantics within the structures in hand.

Relative completeness
Relative completeness has been regarded as a canonical bill of health for proposed logics of imperative programs. A first point worth noting is that relative complete- ness is an immediate consequence of Theorem 2.4. If a V -structure S is expressive (in the sense of Cook) then each relation Mα is definable in S by some V -formula ξα. Fixing a program α with assigned variables among x1 ... xn, let Indξ be Indn with each Mβ replaced by ξβ . By Theorem 2.4, if T is a V -theory, and

T, Indξ ▶ ϕ[x] ∧ ξα[x, u] → ψ[v]	(2)
then T ▶H ϕ[α]ψ. Taking for T the complete first-order theory Th(S) of S, (2) is trivial, since the derived formula is an element of T, so Th(S) ▶H ϕ[α]ψ.
It thus appears that relative completeness is a “local projection” of inductive completeness, obtained when one examines individual structures rather than all structures, and further requires those structures to be expressive. Inductive com- pleteness is the more general and global property, and it applies to all structures, regardless of expressiveness.
Moreover, the inductive soundness and completeness of Hoare’s logic provides an exact delineation: adding PCAs to Hoare’s logic dashes inductive soundness, and eliminating a PCA would destroys inductive completeness. Delineation is most intuitive reading of “complete”: no proper extension of the logic is sound. This is what G¨odel’s Completeness Theorem does for classical first-order logic, Kripke’s for constructive logic, and Henkin’s for classical higher-order logic.  In contrast,
relative completeness fails to delineate Hoare’s logic: adding to Hoare’s logic H any valid PCA unprovable in H yields a proper extension H+ which is again sound and relatively complete. Since H+ is not a natural logic, it follows that relative- completeness fails to explain the naturalness of H.
Relative completeness also lacks the genericity of traditional completeness prop- erties. The completeness of classical first-order logic implies that for any first-order theory T, say the algebraic theory of fields, if T |= ϕ, then T ▶ ϕ. Similarly, in- ductive completeness implies that if T + Ind0 proves a PCA, then the that PCA is provable in H. Relative completeness has no such consequence.
Relative completeness throws in the towel not only regarding structures that are not expressive (and for which inductive completeness is unproblematic), but also for programming languages whose termination problem for finite structures is not decidable. In contrast, giving inductive definitions to the semantics of such programs is straightforward, albeit calling for auxiliary constructs (e.g. stacks). The

study of inductive completeness for such programming languages is therefore also possible, indeed straightforward. We shall pursue this elsewhere.
Total correctness and the Generative Theory
Recall that total-correctness assertions (TCA) (over a vocabulary V ) are DL for- mulas of the form ϕ → ⟨α⟩ψ, where ϕ and ψ are first-order V -formulas. It is well known that the validity of TCAs (in all V -structures!) is fundamentally a first-order property [14]. For example, there is a simple log-space transducer to transform a TCA τ to a first order formula ϕτ so that τ is valid iff ϕ is [11].
The inductive framework provides yet another take on the first-order nature of TCAs (compare [14,13,17]).
Theorem 3.1 Let V be a vocabulary, A TCA τ over V is valid iff τ is provable in Gen.
More generally, if T a V -theory, then T entails τ (i.e. τ is true in every model of T) iff T + Gen ▶ τ .
Proof. The validity of provable TCAs is trivial. Conversely, if a TCA τ is valid, then τ is true whenever each Mα is interpreted as the semantics of α. But because Mα appears positively in τ , the latter remains true if Mα is extended; thus only the closure conditions on the Mα’s matter.	 
Since the deconstruction template for an inductive definition is an approximation to a second-order axiom, it is of a rather different nature from the generative axioms. For one, it has infinitely many instances, and cannot be reduced to any finite number of them. Thus the subformula property (a consequence of cut-elimination by which every formula ϕ has a proof using only subformulas of ϕ) fails miserably. In contrast, the generative theory is truly first-order, with a finite number of axioms expressible as atomic inference rules.
Conclusion
Based on inductive definability as a generic framework for specifying program se- mantics, we proposed here canonical theories of inductive definability as the point of reference for proving completeness (and soundness) of logics of programs. We illustrated the framework by applying it to regular programs, and to Hoare’s logic for them. The completeness results we obtain are simple, direct, and completely general (no restriction to expressive structures).
The semantic of regular programs refers to states of bounded size n (the num- ber of assignable variables used), and so the semantics of programs is expressible as relations of arity 2n. Less elementary programming constructs, say recursive procedures with local variables, may require inductive definitions referring to aux- iliary data objects (such as lists), which is precisely what we have in mind. The effect of this would be particularly obvious for programming languages with un- decidable finite-structure halting, for which no relatively complete axiomatizations

exist: the auxiliary constructs take over program complexity; however, we can still define natural logics for such languages, and prove their inductive completeness.
Our first take on completeness for logics of programs, in [9], was based on second- order logic as a universal framework, with the expectation that first-order compre- hension corresponds to logics for PCAs, and comprehension for computation (i.e.
relational Π1) formulas corresponding to dynamic logic.  However, the situation
is more subtle. As manifested in [10], different forms of computational formulas correspond to different program constructs, and the second-order framework does not provide a silver bullet that applies to all constructs. The inductive framework studies here is therefore more appealing and generic: the programming construct in had guides directly the inductive definition, and once it does the match with a program logic is obtained.

References
Andreas Blass and Yuri Gurevich. The underlying logic of Hoare logic. Current Trends in Theoretical Computer Scienc, pages 409–436, 2001.
Stephen A. Cook. Soundness and completeness of an axiom system for program verification. SIAM J. Computing, 7(1):70–90, 1978.
L. Csirmaz. Programs and program verification in a general setting. Theoretical Computer Science, 16:199–210, 1981.
Solomon Feferman. Formal theories for transfinite iterations of generalized inductive definitions and some subsystems of analysis. In Intuitionism and Proof Theory, pages 303–326. North-Holland, Amsterdam, 1970.
Solomon Feferman and Wilfried Sieg. Iterated inductive definitions and subsystems of analysis. In Iterated Inductive Definitions and Subsystems of Analysis: Recent Proof-Theoreitc Studies, LNM 897, pages 16–77. Springer-Verlag, Berlin, 1981.
David Harel, Dexter Kozen, and Jerzy Tiuryn. Dynamic Logic. MIT Press, Cabridge, MA, 2000.
G. Kreisel. Generalized inductive definitions. Reports for the seminar on foundations of analysis, Stanford, Volume 1 §3, 1963.
G. Kreisel. Mathematical logic. In T. Saaty, editor, Lectures on Modern Mathematics, volume III, pages 95–195. John Wiley, New York, 1965.
Daniel Leivant. Logical and mathematical reasoning about imperative programs. In Conference Record of the Twelfth Annual Symposium on Principles of Programming Languages, pages 132–140, New York, 1985. ACM.
Daniel Leivant. Matching explicit and modal reasoning about programs: A proof theoretic delineation of dynamic logic. In Twenty-first Symposium on Logic in Computer Science (LiCS’06), pages 157–166, Washington, 2006. IEEE Computer Society Press.
Daniel Leivant. Reasoning in dynamic logic about program termination. In Pillars of Computer Science: Essays Dedicated to Boris (Boaz) Trakhtenbrot, LNCS vol. 4800, pages 394–409. Springer- Verlag, 2007.
Per Martin-L¨of. Hauptsatz for the intuitionistic theory of iterated inductive definitions. In J.E. Fenstad, editor, Proceedings of the Second Scandinavian Logic Symposium, pages 63–92, Amsterdam, 1971. North-Holland.
Albert Meyer and Joseph Halpern. Axiomatic definition of programming languages: a theoretical assessment. Journal of the ACM, 29:555–576, 1982.
Albert Meyer and John Mitchell. Termination assertions for recursive programs: completeness and axiomatic definability. Information and Control, 56:112–138, 1983.
D. Prawitz. Natural Deduction. Almqvist and Wiksell, Uppsala, 1965.
Ildiko Sain. An elementary proof for some semantic characterizations of nondeterministic Floyd-Hoare logic. Notre Dame Journal of Formal Logic, 30:563–573, 1989.
Peter H. Schmitt. Diamond formulas: A fragment of Dynamic Logic with recursive enumerable validity problem. Information and Computation, 61:147–158, 1984.
