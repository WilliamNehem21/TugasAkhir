

Electronic Notes in Theoretical Computer Science 263 (2010) 129–143
www.elsevier.com/locate/entcs

PobSAM: Policy-based Managing of Actors in Self-Adaptive Systems
Narges Khakpour1 , Saeed Jalili2
Tarbiat Modares University, Tehran, Iran
Carolyn Talcott3
SRI International, Menlo Park, California
Marjan Sirjani4
Reykjavk University, Reykjavk, Iceland University of Tehran and IPM, Tehran, Iran
MohammadReza Mousavi5
Eindhoven University of Technology, Eindhoven, The Netherlands

Abstract
In this paper, we present a formal model, named PobSAM (Policy-based Self-Adaptive Model), for develop- ing and modeling self-adaptive systems. In this model, policies are used as a mechanism to direct and adapt the behavior of self-adaptive systems. A PobSAM model consists of a set of self-managed modules(SMM). An SMM is a collection of autonomous managers and managed actors. Managed actors are dedicated to functional behavior while autonomous managers govern the behavior of managed actors by enforcing suit- able policies. To adapt SMM behavior in response to changes, policies governing an SMM are adjusted, i.e., dynamic policies are used to govern and adapt system behavior. We employ the combination of an algebraic formalism and an actor-based model to specify this model formally. Managers are modeled as meta-actors whose policies are described using an algebra. Managed actors are expressed by an actor model. Furthermore, we provide an operational semantics for PobSAM described using labeled transition systems.
Keywords: Adaptive systems, Policy-based Computing, Component-based Design, Algebra, Actor Models


1 Email: nkhakpour@modares.ac.ir
2 Email: sjalili@modares.ac.ir
3 Email: clt@cs.stanford.edu
4 Email: msirjani@ut.ac.ir
5 Email: m.r.mousavi@tue.nl

1571-0661© 2010 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2010.05.008

Introduction
Motivation Increasingly, software systems are subjected to adaptation at run-time due to changes in the operational environments and user requirements. Adapta- tion is classified into two broad categories [1]: structural adaptation and behavioral adaptation. While structural adaptation aims to adapt system behavior by changing system’s architecture, the behavioral adaptation focuses on modifying the function- alities of the computational entities.
There are several challenges in developing self-adaptive systems. Due to the fact that self-adaptive systems are often complex systems with a great degree of auton- omy, it is more difficult to ensure that a self-adaptive system behaves as intended and avoids undesirable behavior. Hence, one of the main concerns in developing self- adaptive systems is providing mechanisms to trust whether the system is operating
correctly, where formal methods can play a key role.
Zhang et al. [2] proposed a model-driven approach using Petri Nets for de- veloping adaptive systems. They also presented a model-checking approach for verification of adaptive system [3,4] in which an extension of LTL with ”adapt” operator was used to specify the adaptation requirements. In this work, system was modeled using a labeled transition system. Furthermore, authors in [5,6] used labeled transition systems at a low level of abstraction to model and verify embed- ded adaptive systems. Kulkarni et al. [7] proposed a theorem proving approach to verify the structural adaptation of adaptive systems.
Flexibility is another main concern to achieve adaptation. Since, hard-coded mechanisms make tuning and adapting long-run systems complicated, so we need methods for developing adaptive systems that provide a high degree of flexibility. All the proposed formal models hard-code the adaptation logic which leads to sys- tem’s inflexibility. Recently, the use of policies has been given attention as a rich mechanism to achieve flexibility in adaptive system. A policy is a rule describ- ing under which condition a specified subject must (can or cannot) do an action on a specific object. In [8,9,10,11,23], policies are used as a structural adaptation mechanism. Additionally, [12,13] proposed architectures for engineering autonomic computing systems that use policies for behavioral adaptations.
This paper In this paper, we propose a formal model called PobSAM (Policy- based Self-Adaptive Model) for developing and specifying self-adaptive systems that employs policies as the principal paradigm to govern and adapt system behavior. We model a self-adaptive system as a collection of interacting actors directed to achieve particular goals according to the predefined policies. A PobSAM model consists of a set of Self-Managed Modules(SMMs). An SMM is composed of a collection of autonomous managers and managed actors. Autonomous managers are meta-actors responsible for monitoring and handling events by enforcing suitable policies. Each manager adapts its policies dynamically in response to the changing circumstances according to adaptation policies. The behavior of managed actors is governed by managers, and cannot be directly controlled from outside.
PobSAM has a formal foundation that employs an integration of algebraic for-

malisms and Actor-based models. The computational (functional) model of Pob- SAM is based on actor-based models while an algebraic approach is proposed to specify policies of managers. Operational semantics of PobSAM is described with labeled transition systems. The proposed model is suitable for cases where the set of governing policies of each context is known in advance.
Contribution Formal methods are proposed for analysis of adaptive systems, mainly at the low levels of abstraction, and flexible policy-based approaches are proposed for designing adaptive systems without formal foundation. Here, we pro- pose a flexible policy-based approach with formal foundation to support modeling and verification of self-adaptive systems. Policies allow us to separate the rules that govern the behavioral choices of a system from the system functionality giving us a higher level of abstraction; so, we can change system behavior without changing the code or functionality of the system. We are also concerned about the adaptation strategy, to pass the adaptation phase safely and at the right moment. As an ex- ample, we are able to change and reason about the scheduling of jobs using policies independent of the system code. Although our approach can support both structural and behavioral adaptation, in this paper, we focus on the behavioral adaptation. The formal foundation, the modular model, and separation of adaptation rules will help us in developing rigorous analysis techniques.
Structure of the paper This paper is organized as follows. In Section 2 we introduce an example to illustrate our approach. Section 3 introduces the PobSAM model in brief. Sections 4 and 5 introduce the syntax and semantics of PobSAM, respectively. Section 6 presents related work and compares our approach with the existing approaches. In Section 7, we present our conclusions and plans for future work.

Smart Home
In a home automation system, sensors are devices that provide smart home with the physical properties of the environment by sensing the environment. In addition, actuators are physical devices that can change the state of the world in response to the sensed data by sensors. The system processes the data gathered by the sensors, then it activates the actuators to alter the user environment according to the predefined set of policies. Smart homes can have different features. Here, we take into account three features including: (1) The lighting control which allows lights to switch on/off automatically depending on several factors. In addition, the intensity of the lights placed in a room can be adjusted according to the predefined policies.
(2) Doors/Windows management that enable inhabitants to manage windows and doors automatically. In addition, if windows have blinds, these should be rolled up and down automatically too. (3) Heating control which allows inhabitants to adjust the heating of the house to their preferred value. The heating control will adjust itself automatically in order to save energy.
The smart home system is required to adapt its behavior according to the changes of the environment.  To this aim, we suppose that the system runs in

normal, vacation and fire modes and in each context it enforces various sets of policies to adapt to the current conditions. For the reason of space, here we only identify policies defined for lighting control module while the system runs in normal and fire modes as follows:

Defined policies in the normal mode
P1 Turn on the lights automatically when night begins.
P2 Whenever someone enters an empty room, the light setting must be set to default.
P3 When the room is reoccupied within T1 minutes after the last person has left the room, the last chosen light setting has to be reestablished.
P4 The system must turn the lights off, when the room is unoccupied.
Defined policies in the fire mode P1 Turn on the emergency light.
P2 Disconnect power outlets.
P3 When the fire is extinguished, turn off the emergency light.

Modeling Concepts of PobSAM
Self-Managed Module (SMM) is the policy-based building block of PobSAM. A PobSAM is composed of a set of SMMs. An SMM, in turn, may contain a number of SMMs structured hierarchically. An SMM is a set of actors which can manage their behavior autonomously according to predefined policies. PobSAM supports interactions of an SMM with the other SMMs in the model. To this aim, each SMM provides well-defined interfaces for interaction with other SMMs. In the smart home case study, we consider three SMMs including LightClModule, TempClModule and DWClModule to manage lighting, temperature and doors/windows respectively.
An SMM structure can be conceptualized as the composition of three layers illustrated in Figure 1.
Managed Actors Layer This layer is dedicated to the functional behavior of SMM and contains computational actors. Actors are governed by autonomous managers using policies to achieve predefined goals. Henceforth, we use the terms managed actors and actors interchangeably.
Autonomous Managers Layer Autonomous managers are meta-actors that can operate in different configurations. Each configuration consists of two classes of policies: governing policies, and adaptation policies. Using governing policies, the manager directs the behavior of actors by sending messages to them. Adap- tation policies are used to switch between different configurations to adapt the module behavior properly. Moreover, a manager may has its local variables too.
View Layer In PobSAM, each actor provides its required state information to the relevant managers. Not all aspects of the operational environment have di-








Fig. 1. The PobSAM Model

rect influence on the behavior of managers, the views provide only the required information for managers. The view layer is composed of views that provides a view or an abstraction of an actor’s state that is adequate for the managers’ needs. The distinction between the underlying computational environment and the required state information of actors makes analyzing managers much simpler.
Example 3.1 In our example, LightClModule module comprises an autonomous manager named LightMngr, two light actors (light1 and light2 ), an outlet actor and a number of views indicating the overall light intensity of room and the status of the lights.


PobSAM Syntax
Figure 2 shows a typical SMM containing manager meta-actors, views and actors, which we elaborate in the sequel.

Actors
The encapsulation of state and computation, and the asynchronous communication make actors a natural way to model distributed systems. Therefore, we use an actor- based model to specify the computational environment of a self-adaptive system. To this aim, an extension of Rebeca is used. Rebeca [14] is an actor-based language for modeling concurrent asynchronous systems which allows us to model the system as a set of reactive objects called rebecs interacting by message passing. Each rebec provides methods called message servers (msgsrv) which can be invoked by others. Each rebec has an unbounded buffer for coming messages, called queue. Furthermore, the rebecs’ state variables (statevars) are responsible of capturing the rebec state. The known rebecs of a rebec (Knownrebecs) denotes the rebecs to which it can send messages. In our extension, an actor can expose a number of its

SMM SMM1
Managers
Manager ManagerName1(InitialConfiguration11)
// definition of local variables Datatype var1;
// manager’s view
<ViewName11,..., ViewName1n>;
// definition of manager’s configurations in terms of
// their governing and adaptaion policies Configurations
ConfigurationName1={gp11,...,gp1m}<ap11|...|ap1n>;
.
.
.
EndC Policies
//Definition of governing policies(gps) GoverningPolicyName1: on eventi if condi do actionsi;
.
.
.
//Definition of adaptation policies(aps) AdaptationPolicyName1:
on eventj if condj switchto Configuration1 when condk priority Oj;
.
.
.
EndP EndM
// definition of other managers EndMS
Views
//definition of views Datatype1 ViewName1 as expr1; Datatype2 ViewName2 as expr2;
.
.
.
EndV Actors
//definition of actors reactiveclass Classname1() {
Knownrebecs{}
Statevars{ Public datatype v1;
Private datatype v2;} msgsrv initial() {}
msgsrv msgsrv1(){}
}
main {
...
Classname1 rebec1(...):(...);
...
}
EndA EndSMM
Fig. 2. The Typical Syntax of a PobSAM Model

state variables to the managers (Figure 2). The exposed state variables are used in the definition of views.
Example 4.1 In the LightClModule SMM, the managed layer comprises a set of light rebecs controlled by LightMngr. We consider a reactive class named Light to model the lights which contains setIntensity, switchOn and switchOff message servers as well as intensity and status state variables.

Views
In PobSAM, views are defined in terms of the public state variables of actors. A view variable could be an actual state variable, or a function or a predicate applied to state variables. Views enable managers not to be concerned about internal behavior

of actors and they provide an abstraction of actor’s state to managers.

Example 4.2 In the LightClModule SMM, the LightMngr does not require the exact values of the lights intensities and providing overall intensity as low, medium or high values is sufficient to decide. The overall intensity is defined based on the intensity statevar of the light rebecs as a view.

Managers
In our model, policies direct the system behavior, and adaptation is achieved by changing policies. A manager can be in various configurations enforcing different policy sets. As shown in Figure 2, a manager is defined in terms of its possible configurations, its view of the actor layer and its local variables.

Governing Policies
Whenever a manager receives an event, it identifies all the policies that are trig- gered by that event. For each of these policies, the policy condition is evaluated if one exists. If the condition evaluates to true, the action part of the triggered policy is requested to execute by instructing the relevant rebecs to perform actions through sending asynchronous messages. We express governing policies using a simple algebra as follows, in which P and Q indicate the policy sets:

P, Q d=ef P ∪ Q | P − Q | P ∩ Q | {p}|∅ 

P  Q means that intersection of policy sets P and Q is used to direct actors. P-Q reduces policy set P by eliminating all the policies in set Q. P  Q represents the union of P and Q governing the actors simultaneously. p denotes a policy set with the simple policy p as its member. P Q and P Q are commutative and associative.
A simple action policy p=[o,ε,ψ, α] consists of priority o, event ε , optional condition ψ and action α. In PobSAM, events are defined as the execution of a message server, sending a message to a rebec, creating new actor or holding a specific condition in the system. Actions can be composite or simple. A simple action is of the form r.l(υ) which denotes message l(υ) is sent to actor r and the special constant Q is the deadlock action. Composite actions are created by composing simple actions as follows:

α, β d=ef α → β | α  β | α + β | [ω?α : β] | r.l(υ) | Q

Thus a composite action can be the sequential (α	β) or parallel execution (α  β) of actions α and β. Also, an action can be chosen to execute non-deterministically(+). Term ([ω?α : β]) represents that action α is chosen to be executed if ω holds, else β will be chosen. + and	are commutative and associative.



Example 4.3 The governing policies of the lightMngr in the normal configuration are as follows, where night, occpd, rccpd and unoccpd denote events and c1, c2, d1 and d2 are arguments indicating the light intensity.
pn1 d=ef [1 , night, true, light1 .switchon()  light2 .switchon()]
pn2 d=ef [2 , occpd , true, light1 .setIntensity (d1 )  light2 .setIntensity (d2 )] pn3 d=ef [3 , rccpd , true, light1 .setIntensity (c1 )  light2 .setIntensity (c2 )] pn4 d=ef [4 , unoccpd , true, light1 .switchoff ()  light2 .switchoff ()]
Adaptation Policies
One of the main characteristics of a formal model to specify a self-adaptive system is considering adaptation semantics. To this end, we should deal with a number of issues such as ''the time at which an adaptation is performed in the system''
, ''the time at which the manager’s policies are modified'' , ''the time at which the enforcement of new policies begin after modifying policies'' or ''the ability to restricting the system behavior during adaptation''.
Whenever an event requiring adaptation occurs, relevant managers are informed. However, the adaptation cannot be done immediately and when the system reaches a safe state, the managers switch to the new configuration. Therefore, we introduce a new mode of operation named adaptation mode in which a manager runs before switching to the next configuration. While the manager is in the adaptation mode, it is likely that events occur which need to be handled by managers. To handle these cases, we introduce two kinds of adaptations named loose adaptation and strict adaptation. Under loose adaptation a manager enforces old policies, while under strict adaptation all events will be ignored until the manager exits the adap- tation mode and the system reaches a safe state. For example in our smart home example, when LightMngr is in the fire configuration and there is a request for the vacation mode, while fire has not been put out, it keeps enforcing policies of the fire configuration by switching to the loose adaptation mode. Also, when LightMngr is in the normal configuration, once fire is detected, it stops enforcing its current policies by switching to the strict adaptation mode.
A simple configuration C is defined as C d=ef ⟨P, A⟩ where P and A indicate
the governing policy set and the adaptation policy of C respectively. Adaptation policies are defined using an algebraic language as follows:

A d=ef [D♩ξ,δ,γ,λ,ϑ | A ⊕ A

in which D, ξ, δ , γ , λ and ϑ, respectively denote an event, an arbitrary configura- tion, the conditions of triggering adaptation, the conditions of applying adaptation, adaptation type (loose or strict) and the priority of adaptation policy. The sim- ple adaptation policy, D ξ,δ,γ,λ,ϑ, specifies when event ξ occurs and the triggering condition δ holds, if there is no other triggered adaptation policy with the higher

priority, the manager evolves to the strict or loose adaptation modes based on the value of λ. When the condition of applying adaptation γ becomes true, it will per- form adaptation. Adaptation policies of a manager is defined as the composition,
, of the simple adaptation policies. Here, composition of two policies means that those policies are potentially to be triggered.  is associative and commutative. D is defined as follows where ω is an arbitrary condition:
D, D' d=ef [ω?D : D'] | D D' | C
Terms [ω?D : D'] and D D' represent the conditional and non-deterministic choices, respectively. In the conditional choice, configuration D is chosen if ω holds, else D' will be chosen. Non-deterministic choice means that the choice between config- uration D or D' is made non-deterministically. This operator is associative and commutative.
Example 4.4 In our smart home example, there are three configurations including Cn, Cv and Cf . Formal specification of lightMngr ’s configurations are as follows in which pmj denotes policy j defined in mode Cm. vacReq, ﬁre, ﬁrePutout and comebackHome are events while isPutout , isCnfrmd and onVac are lightMngr ’s local variables. As an example, when the lightMngr is in the ﬁre mode and there is a request for going on vacation, while fire has net been put out, it can not switch to the Cv configuration.

Cn d=ef ⟨{pn1 , pn2 , pn3 , pn4 }, [Cf ♩fire,true,true,S,1 ⊕ [Cv ♩

vacReq,true,isCnfrmd,L,2 ⟩

Cf d=ef ⟨{pf1 , pf2 , pf3 }, [onVac?Cv : Cn ♩firePutout,true,true,L,1 ⊕ [Cv ♩vacRequest,true,isPutout,L,2 ⟩
Cv d=ef ⟨{pv1 , pv2 , pv3 , pv4 , p5 }, [Cf ♩fire,true,true,S,1 ⊕ [Cn ♩comebackHome,true,true,L,2 ⟩

Operational Semantics of PobSAM
Operational Semantics of Actors and Views
The operational semantics of our extension of Rebeca does not differ from that of Rebeca[14]. However, any changes in state of the rebecs used in the definition of views must be reflected to the views. Let I1, I2,..., In denote the defined views of SMM S and η denote the set of defined events that the managers are concerned with. The state of a view is determined by its current value that is modified by the related events occurring at the actor level. After execution of a message server, the changes of public state variables must be reflected in the views state, too. We specify the operational semantics of the view layer as a labeled transition system.
Let SB, AB and TB  SB  AB  SB be the set of states, the set of actions and the state transition relation of the transition system of the actor layer respectively. The state transition relation of the view layer TI  SI  AI  SI is defined based on TB, where SI and AI are the set of states and the set of actions of the view layer transition system respectively and SI = ⟨I1, I2, ..., In⟩. Suppose Ij(x1, x2, .., xm) denotes an arbitrary view defined on public state variables x1, x2, .., xm and Ij σs denotes the state of Ij , where its state variables are substituted with their cor-

responding values in state σs ∈'	SB.  For each triple ⟨σs, a, σt⟩ ∈ TB, we con-
sider an associated transition ⟨	⟩∈ T  where σ' = ⟨I |  ,I |σ , ..., I |σ ⟩ and
σt' = ⟨I1|σt , I2|σt , ..., In|σt ⟩ if and only if a∈ η or ∃Ik 1 ≤ k ≤ n ∧ Ik|σs /= Ik|σt , i.e.


σs−a→σt ∈ TB , (a ∈ η) ∨ (∃I .1≤k≤nIk|σ
σ' −a→ σ'
/= Ik|σt )


Operational Semantics of Managers
We use a labeled transition system to define the operational semantics of managers in which labels have two components. The first component indicates the activation condition of the transition while the second component denotes the action of the transition. Assume that M is a logical expression defined on state variables, the
transitions are of the form P (M,a) Q meaning “if M holds then P has an action a
leading to Q”. Henceforth, we−−d−en→ote a transition by P μ Q where μ = (M, a).


(NPE1) R={p|(p.ε∧p.ψ)=true}∧R/=∅
(NPE2) 	p∈R ∧ ∄q∈R(q.o>p.o)	

M∅C[ę]−(−ε−,τ→) [M]∅ C[√]
[M]∅ C[√]−−(T−,e−n−f(p−)→) [M]p  C[p.α]

∅	R
(NPE3)
R

[M]p C[a]−(−T−,a→) [M]p C[√]
R\p

R
[M]p C[α]−→μ [M]p C[α']
R
[M]p C[α]−→μ [M]p C[√]

(NPE4)	R	μ	R
(NPE5)	R	μ	R	√

[M]p C[α+β]−→[M]p C[α']	[M]p C[α+β]−→[M]p C[ ]

R

(NPE6)
R	R	R

(NPE7)

[M]p C[[ω?α:β]]−(−ω−,τ→) [M]p
C[α]
[M]p C[[ω?α:β]]−(−¬−ω−,τ→)
[M]p C[β]

[M]p C[α]−→μ [M]p C[α']	[M]p C[α]−→μ [M]p C[√]
[M]p C[α  β]−→[M]p C[α'  β]	[M]p C[α  β]−→[M]p C[β]
[M]p C[α]−→μ [M]p C[α']	[M]p C[α]−→μ [M]p C[√]
[M]p C[α→β]−→[M]p C[α'→β]	[M]p C[α→β]−→[M]p C[β]

R	R

(NPE12)
R	R

∅C[√]−(−T−,τ→) M∅C[ę]

Fig. 3. Rules of policy enforcement
The behavior of a manager depends on the mode in which it is running. A manager can run in different modes such as normal execution, adaptation and policy enforcement. To distinguish managers in different modes, we use different notations. Let [M]p C[α] indicate manager M in the enforcement mode in which,

C is the configuration in which M is running and C
R is the set of triggered policies to be enforced.
p is the current policy being enforced by M.
d=ef ⟨P, A⟩.

α is the action of a recent policy being executed by M.
M∅C[Q], |M|p C[α] and M∅C[Q] indicate M in the normal execution, loose
∅	R	∅

adaptation and strict adaptation modes respectively.

Policy enforcement semantics
Whenever an event is received by a manager, it identifies all the triggered policies with the policy condition evaluated to true. Then it enforces the identified policies based on their priorities. Once a manager enforces all the triggered policies, it evolves to normal mode. Figure 3 gives the rules of policy enforcement.
Using NPE1, the manager switches to the enforcement mode by identifying the triggered policies to be enforced. NPE2 places the action of a policy with the highest priority in the action part of the manager to be run and remove that
policy from the list of activated policies. NPE3 represents successful termination of executing the simple action a. √ is a special symbol which we use to represent
successful termination. NPE4, NPE5, NPE6 and NPE7 define the semantics of non-deterministic and conditional choices of actions. NPE8-11 are considered to apply sequential and parallel composition of actions. When there is no policy to be enforced, the manager will switch to the normal execution mode using NPE12.
As mentioned above, managers in loose adaptation mode are able to enforce policies. Therefore, all the rules introduced for the enforcement mode, except for NPE12, are applicable in loose adaptation mode too.

Policy adaptation semantics
For the sake of readability, we omit p, [α] and R symbols of managers in nor- mal execution and strict adaptation modes. Figure 4 shows rules for adaptation in strict mode in which B, A' and B' denote arbitrary adaptation policies. Further- more, F and D'' denote a simple adaptation policy and an arbitrary configuration, respectively.

(SA1) 	∄F ∈A(ϑ<F.ϑ ∧ F.δ=true)	
M⟨P,[D♩ξ,δ,γ,λ,ϑ⊕A⟩−−−−−−→  M  ⟨P,[D♩ξ,δ,γ,λ,ϑ⟩

(SA2)
(γ,adapt)	∅
M  ⟨P,[C♩ξ,δ,γ,λ,ϑ⟩−−−−−−→M∅ C[ę]
(SA3)
(T,τ )
M⟨P,A⊕B⟩	M⟨P,B⊕A⟩


(SA4)	M ⟨P,[D♩


ξ,δ,γ,λ,ϑ
⟩−→

M ⟨P,[D'♩

ξ,δ,γ,λ,ϑ⟩

M  ⟨P,[D D''♩	⟩−→μ 
M  ⟨P,[D'♩ξ,δ,γ,λ,ϑ⟩



(SA5)	M ⟨P,[D♩

ξ,δ,γ,λ,ϑ
⟩−→
M ⟨P,[D'♩
ξ,δ,γ,λ,ϑ⟩



(SA6)
M  ⟨P,[D'' D♩	⟩−→μ  
M  ⟨P,[D'♩ξ,δ,γ,λ,ϑ⟩


(SA7)
(ω,τ )
M  ⟨P,[ω?D:D'♩ξ,δ,γ,λ,ϑ⟩	M  ⟨P,[D♩ξ,δ,γ,λ,ϑ⟩


(¬ω,τ )
M  ⟨P,[ω?D:D'♩ξ,δ,γ,λ,ϑ⟩	M  ⟨P,[D'♩ξ,δ,γ,λ,ϑ⟩

Fig. 4. Rules of strict adaptation

SA1 states when an event occurs, a triggered adaptation policy with the highest priority is chosen to be applied. If the adaptation type of that policy is strict adaptation type, manager  switches to the strict adaptation mode. SA2 asserts that when the condition for applying the adaptation holds,  will evolve to the normal mode and run the simple configuration C. SA4, S5, SA6 and SA7 define the semantics of non-deterministic and conditional choices of configurations. Rules of
loose adaptation are identical to the strict adaptations rules except for SA1 which is as 	∄F∈A.(ϑ<F.ϑ ∧ F.δ=true)	 (LA1).
M⟨P,[D♩ξ,δ,γ,λ,ϑ⊕A⟩−−−−−−→|M|⟨P,[D♩ξ,δ,γ,λ,ϑ⟩

Discussion and Related Work
Flexibility of self-adaptive systems is realized by three different features including separation of concerns, computational reflection and component-based design [17]. We explain how PobSAM can address these requirements in the sequel.
PobSAM decouples the adaptation logic of an SMM from its business logic de- scribed at an abstract level using policies. Among the proposed formal approaches to model adaptive systems, [2,19,20] combine the adaptation logic into the busi- ness logics. In [3,6,18] the adaptation concerns have been separated; however, all the proposed formal models hard-code the adaptation logic which leads to system’s inflexibility. The proposed model permits us to direct/adapt system behavior by enforcing/modifying policies at an abstract level without re-coding actors and man- agers; thereby it leads to increasing system flexibility and scalability.
Computational reflection is the ability of a system to monitor and change its behavior subsequently. In PobSAM, managers monitor actor’s behavior through views and direct/adapt SMMs behavior. Policies provide us a high-level description of what we want without dealing with how to achieve it. Thus, using policies can be a suitable mechanism to determine if the goals were achieved using existing policy refinement techniques.
Furthermore, PobSAM uses SMM as a policy-based building block for a modu- lar model where each component is able to adapt its behavior autonomously. This notion makes PobSAM a suitable model to specify self-organizing and cooperating systems too. Although, in this paper we focused on behavioral adaptation, how- ever, PobSAM can support structural adaptation by joining/leaving an actor or an SMM to/from an SMM dynamically, which is an advantage over the most existing approaches that concentrate on one adaptation type. SMM notion is similar to Self-Managed Cell (SMC) notion proposed in [13] as a paradigm for engineering ubiquitous systems. In this work, an SMC consists of a set of components that constructs an autonomous management domain.
One of the main aspects of modeling a self-adaptive system is specifying adapta- tion requirements. To this aim, we introduced a two phases adaptation strategy to pass the adaptation phase safely. Upon receiving an adaptation event by a manager, it switches to the adaptation mode. Adaptation mode models transient states dur- ing adaptation. When the system reaches a safe state, the adaptation is completed by evolving the manager to the new configuration. We believe that the modular

nature of adaptation policies enables us to express adaptation requirements easily and at the high-level of abstraction.
As stated above, PobSAM has decoupled the adaptation layer from the func- tional layer. Thus, we can verify the adaptation layer independently from the actor layer provided that we have a labeled transition system modeling view behavior. This feature can decrease the complexity of verification procedure.
Dynamic adaptation is a very diverse area of research. While structural adapta- tion has been given strong attention in the research community(see [21]), fewer approaches tackle behavioral adaptation as we considered. Due to the lack of space, we restrict ourselves to present related work done on formal modeling of self-adaptive systems in addition to applying policy-based approaches in engineer- ing of self-adaptive systems.
Formal verification of adaptive systems is a young research area [22] and only a few research groups already focused on this topic. A model-driven approach was proposed for developing adaptive systems in [2]. In this approach, there are dif- ferent behavioral variants of a process modeled as Petri Nets. At each time, one Petri Net runs and reconfiguration is carried out by switching between various Petri Nets. In another work [3], they modeled a system as a set of steady-state programs among which the system switches. An extension of LTL with “adapt“ operator was used to specify adaptation requirements before, during and after adaptation [4]. Then, they use a model checking approach to verify the system. Kulkarni et al. [7] proposed an approach based on the concept of proof lattice to verify if a system is in a correct state during and after adaptation in terms of satisfying the transitional-invariants. Furthermore, Schneider et al. [5] presented a method to describe adaptation behavior at an abstract level. After deriving transition systems from a system description, they verify the system using model checking. In their later work [6], they proposed a framework for model-based development of adap- tive embedded systems using labeled transition systems. In this work, they verify different properties using theorem proving, model checking and specialized verifica- tion methods. [18] proposed a coordination protocol for distributed adaptation of the component-based systems and used Colored Petri Nets for formal verification. In our model, adaptation is performed by applying suitable policies in different contexts, which in nature differs from the proposed approaches.
Employing policies as a paradigm to adapt self-adaptive systems has been given considerable attention during recent years. Work in [8,9,10,11,23,25] used policies as the adaptation logic for structural adaptation, while we use policies as a mech- anism for governing as well as adapting system behavior. Furthermore, [23] used policies for a simple type of behavioral adaptation named parameterization, too.
[24] proposed an adaptive architecture for management of differentiated networks which performs adaptation by enabling/disabling a policy from a set of predefined QoS policies, but this architecture does not have formal foundation. Anthony [25] presents a policy definition language for autonomic computing systems in which the policies themselves can be modified dynamically to match environmental con- ditions. However, this work does not deal with modeling system and it is limited

to proposing an informal policy language.

Conclusions and Future Work
We proposed PobSAM as a formal model to develop self-adaptive systems which uses policies as the main mechanism to govern and adapt the system behavior. To this aim, we model a system as the composition of a set of autonomous components named SMMs. Each SMM contains two types of actors: managed actors that are dedicated to the functional layer of system and autonomous managers that coordi- nate actors to achieve the predefined goals using policies. This model integrates two formal methods including algebra and actor-based model to specify a system. Then, we presented the operational semantics of PobSAM by means of labeled transition systems.
There is much more research to pursue in the area of verification of self-adaptive systems. In this paper, we focused on formal modeling of self-adaptive systems. Verification of different properties of adaptation and functional layers of PobSAM models is an ongoing work. We are going to implement a tool to support our ap- proach too. As our model can support both behavioral and structural adaptations, our future researches will be concentrated on specifying structural adaptations. Ex- tending this model for modeling self-organizing systems in which managers need to coordinate together is considered as a future work, too.

References
C. Hofmeister, “Dynamic Reconfiguration, Ph.D. Thesis” in Computer Science Department, University of Maryland, College Park 1993.
J. Zhang and B. Cheng, “Model-Based Development of Dynamically Adaptive Software”, in Proceedings of International Conference on Software Engineering, 2006, pp. 371-380.
J. Zhang, H. J. Goldsby, and B. H. C. Cheng, “Modular verification of dynamically adaptive systems”, in the 8th ACM international conference on Aspect-oriented software development, Charlottesville, Virginia, 2009, pp. 161-172.
J. Zhang and B. H. C. Cheng, “Using temporal logic to specify adaptive program semantics”, Journal of Systems and Software, Architecting Dependable Systems, vol. 79, pp. 1361-1369, 2006.
K. Schneider, T. Schuele, and M. Trapp, “Verifying the adaptation behavior of embedded systems”, in Proceedings of the 2006 international workshop on Self-adaptation and self-managing systems, Shanghai, China, 2006, pp. 16 - 22.
R. Adler, I. Schaefer, T. Schuele, and E. Vecchie, “From Model-Based Design to Formal Verification of Adaptive Embedded Systems”, in Proceedings of International Conference on Formal Engineering Methods, 2007, pp. 76-95.
S. S. Kulkarni and K. N.Biyani, “Correctness of Component-Based Adaptation”, in Component-Based Software Engineering, 2004, pp. 48-58.
R. J. Anthony and C. Ekelin, “Policy-driven self-management for an automotive middleware”, in Proceedings of 1st International Workshop on Policy-Based Autonomic Computing Florida, USA, 2007.
C. Efstratiou, K. Cheverst, N. Davies, and A. Friday, “An Architecture for the Effective Support of Adaptive Context-Aware Applications”, in Proceedings of the 2nd International Conference in Mobile Data Management (MDM‘01), Hong Kong, 2001, pp. 15-26.
C. Efstratiou, K. Cheverst, N. Davies, and A. Friday, “Utilising the Event Calculus for Policy Driven Adaptation in Mobile Systems”, in Proceedings of the 3rd International Workshop on Policies for Distributed Systems and Networks, Monterey, California., 2002, pp. 13-24.


G. Phil and B. Lynne, “A Framework for Policy Driven Auto-adaptive Systems Using Dynamic Framed Aspects”, in Transactions on Aspect-Oriented Software Development II. vol. LNCS 4242, 2006, pp. 30- 65.
“Autonomic computing”, IBM Systems Journal, vol. 42, 2003.
M. Sloman and E. Lupu, “Engineering Policy-Based Ubiquitous Systems”, The Computer Journal, to appear, 2009.
M. Sirjani, A. Movaghar, A. Shali, and F. S. d. Boer, “Modeling and Verification of Reactive Systems using Rebeca”, Fundamenta Informaticae, vol. 63, pp. 385-410, 2004.
M. Sirjani, F. d. Boer, A. Movaghar, and A. Shali, “Extended Rebeca: A Component-Based Actor Language with Synchronous Message Passing”, in Proceedings of the Fifth International Conference on Application of Concurrency to System Design: IEEE Computer Society, 2005.
M. Mousavi, I. Phillips, M. A. Reniers, and I. Ulidowski, ”Semantics and expressiveness of ordered SOS,” Information and Computation, vol. 207, pp. 85-119, 2009.
P. K. McKinley, S. M. Sadjadi, E. P. Kasten, and B. H. C. Cheng, “A Taxonomy of Compositional Adaptation”, Michigan State University Technical Report MSU-CSE-04-17, 2004.
N. H. Kacem, A. H. Kacem, and K. Drira, “A Formal Model of a Multi-step Coordination Protocol for Self-adaptive Software Using Coloured Petri Nets”, International Journal of Computing and Information Sciences , 2009. To appear.
K. N. Biyani and S. S. Kulkarni, “Concurrency and Complexity in Verifying Dynamic Adaptation: A Case Study”, Michigan State University Technical Report MSU-CSE-05-21, August 2005.
M. Gudemann, F. Ortmeier, and W. Reif, “Safety and Dependability Analysis of Self-Adaptive Systems”, in the 2nd International Symposium on Leveraging Applications of Formal Methods, Verification and Validation, 2007, pp. 177-184.
J. S. Bradbury, J. R. Cordy, J. Dingel, and M. Wermelinger, “A survey of self-management in dynamic software architecture specifications”, in Proceedings of the International Workshop on Self-Manages Systems, Newport Beach, USA, 2004.
B. H. C. Cheng, H. Giese, P. Inverardi, J. Magee, and R. d. Lemos, “Software Engineering for Self- Adaptive Systems: A Research Road Map”, in Software Engineering for Self-Adaptive Systems 2008.
D. Pierre-Charles and L. Thomas, “Towards a Framework for Self-adaptive Component-Based Applications”, in Proceedings of Distributed Applications and Interoperable Systems. LNCS2893, 2003,
pp. 1-14.
L. Lymberopoulos, E. Lupu, and M. Sloman, “An Adaptive Policy Based Management Framework for Differentiated Services Networks”, in Proceedings of IEEE Workshop on Policies for Distributed Systems and Networks, Monterey, California, Los Alamitos, California, 2002, pp. 147-158.
R. J. Anthony, “Generic Support for Policy-Based Self-Adaptive Systems”, in Proceedings of the 17th International Conference on Database and Expert Systems Applications, 2006, pp. 108-113.
