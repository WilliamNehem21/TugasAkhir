Electronic Notes in Theoretical Computer Science 125 (2005) 115–147 
www.elsevier.com/locate/entcs


Issues in the Analysis of Proof-Search Strategies in Sequential Presentations of Logics

Tatjana Lutovac 1	James Harland2
School of Computer Science and Information Technology, RMIT University GPO Box 2476V, Melbourne, 3001, Australia

Abstract
Many proof search strategies can be expressed as restrictions on the order of application of the rules of the sequent calculus. Properties of these strategies are then shown by permutation arguments, such as showing that a given strategy is complete by transforming an arbitrary proof into one which obeys the strategy. Such analyses involve some very tedious manipulations of proofs, and are potentially overwhelming for humans. In this paper we investigate the development of systematic techniques for the analysis of sequent calculi. We show how a particular specification of inference rules leads to a detailed analysis of permutation properties for these rules, and we also investigate how to detect redundancies in proofs resulting from these rules.
Keywords: Proof search, affine logic, linear logic, loop detection.


Introduction
There have been a variety of proof-theoretic techniques used to design and analyze proof-search strategies for theorem proving and logic programming [2,1,6,7,10,15,20]. One lesson that can be drawn from these various approaches is that it is usually insufficient just to find a proof; mostly, once a proof is found, it is desirable to extract information from the proof, such as identify- ing which strategy or tactic lead to success, recognizing structures common to
1 Email: tlutovac@eunet.yu
2 Email: jah@cs.rmit.edu.au
1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2005.01.002


other proofs, finding all proofs or all essentially different proofs, generating an- swer substitutions, minimizing unnecessary parts of the proof, and recognizing unused formulae. Hence proof-search is not simply a matter of determining whether a given sequent is provable, but of providing the appropriate “con- textual” information about provability.
It is notable that many of the above analysis are all rather sophisticated and involve complex manipulations of proofs. Many are restricted to particular logic or classes of formulae. Almost all are designed for analysis on paper by a human and many of them are ripe for automation, being formally defined in precise detail, and yet somewhat overwhelming for humans.
In this paper we focus on the development of systematic techniques for the analysis of sequent proofs in order to extract useful information. In particular, we propose a more precise specification of sequent calculus inference rules that we use for the generalization and automation-oriented specification of the permutation process. Our work is motivated by the fact that there are some inference rules of interest which cannot be analyzed by the existing framework ([4,6,12]). One such situation is illustrated by the example below.


▶ φ℘ψ, Γ
▶ φ℘ψ, Γ, ?δ

Whilst this is a combination of the ℘ and contraction rules for linear logic, similar rules can be found in LM, a multiple-conclusioned system for intu- itionistic logic (see, for example, [22]) .
We also propose a mechanism for distinguishing between the necessary and unnecessary formulas in a proof. The mechanism is incorporated into the sequent rules and is independent of the search strategy used.
The results of our analysis can be implemented and utilized by means of an automated proof assistant. Our work is a contribution to a library of automatic support tools for extracting useful information about proofs in order to design and analyze proof-search strategies.
This paper is organized as follows. In Section 2 we discuss our motivations for using permutations as a tool for strategy analysis and for extending the existing framework. In Section 3 we give our specification of sequent calculus rules, and in Section 4 we show how this refined specification can be used to prove various properties of permutations. In Section 5 we address the issue of redundancy in proofs and in Section 6 we describe an algorithm for elimination of redundancies. Finally in Section 7 we present our conclusions.

Permutations and Strategy Analysis
Motivations
The permutation of two adjacent inference rules of a given proof is reversing their order in the proof but without disturbing the rest of the proof (the part above and below the inferences modulo duplication of some proof branches and renaming certain free variables) as a result of which we get an equivalent proof to the given one:


.
.
▶ a, c, d, Γ
.
.
▶ b, ∆
⊗
.
.
▶ c, d, a, Γ ℘	.

▶ c, d, a ⊗ b, Γ, ∆ ℘
▶ c℘d, a, Γ	▶ b, ∆ ⊗

▶ c℘d, a ⊗ b, Γ, ∆
.
.
⇐⇒	▶ c℘d, a ⊗ b, Γ, ∆
.
.

Results from permutation analyses have a strong influence on the design of
proof-search strategies. Many examples of such analyses can be found in the proof-search strategies defined in [2,1,6,7,10,15,20]. A key example of the relationship between the permutation properties and the execution model of the language is given by a comparison of Lygon[23] and Forum[16]; Lygon is
based on the search strategy that some permutations of right-hand side rules
will lead to a proof, whereas Forum is based on the search strategy that any permutation of right-hand rules will lead to a proof. Note that the strategy in question is defined by the restrictions placed on the order in which the
inference rules may be applied.
For such strategies, permutation properties can be used to show that for a given set of inference rules either a given search strategy will find all possible proofs, or to construct an example of a provable sequent which cannot be proved with the given strategy. Strategies which satisfy the constraint on the order of inference rules may then be amenable to further analysis, such as minimizing the amount of branching in the proof, or delaying certain choices until the optimum amount of information is available.
Here we give a brief overview of some applications of permutations for the analysis of particular logic programming strategies.

Generating equivalent proofs which obey different strategies
A logic program for which there are many proofs of the same goal (and hence there are goals which return the same answer substitution many times) is generally considered to be somewhat deficient. Different proofs are generally only considered interesting if they lead to different answers.


For example, consider the sequent p(a), ∀yq(y) → p(y),q(b) ▶ ∃xp(x) in intuition- istic logic. All uniform proofs 3 can be classified into two groups, depending on the answer substitution for x. A representative of each class is below (the others are variations, depending on the order of application of the rules →L, wL and ∀L).


p(b) ▶ p(b) Ax
q(b) ▶ q(b) Ax	p(a), p(b) ▶ p(b) wL
p(a) ▶ p(a) Ax

p(a), q(b) → p(b), q(b) ▶ p(b)	→ L
p(a), ∀yq(y) → p(y), q(b) ▶ p(b) ∀L
p(a), ∀yq(y) → p(y), q(b) ▶ ∃xp(x) ∃R
p(a), q(b) ▶ p(a) wL
p(a), ∀yq(y) → p(y), q(b) ▶ p(a) wL
p(a), ∀yq(y) → p(y), q(b) ▶ ∃xp(x) ∃R

Clearly, the question of finding all proofs which lead to different answers have some overlap with the question of finding all equivalent proofs modulo inference permutations. Since proofs from the same equivalence class lead to the same answer, it is sufficient to generate just one of them, which then will be representative for the whole class.
Note also that some non-uniform permutations may also be useful. In the first example above, the reasons for choosing x ← b are not obvious at the time the rule is applied:
.
.
p(a), ∀y q(y) → p(y), q(b) ▶ p(b)
p(a), ∀y q(y) → p(y), q(b) ▶ ∃xp(x) ∃R
This substitution arises from the formulas ∀yq(y) → p(y), q(b). If asked
by a user to explain why that substitution was generated, an implementation could choose to produce the permutation below, which is not uniform, but demonstrates the origin of the substitution more directly, as indicated by the step (∗).


q(b) ▶ q(b) Ax


p(b) ▶ p(b) Ax p(a), p(b) ▶ p(b) wL
p(a), p(b) ▶ ∃xp(x) ∃R

p(a), q(b) → p(b), q(b) ▶ ∃xp(x)	→ L
∀L	(∗)
p(a), ∀y q(y) → p(y), q(b) ▶ ∃xp(x)
3 A uniform proof [17] of a sequent P ▶ G means a goal-directed proof, in a sense that the goal G is decomposed uniformly, based only on its structure and without reference to the program P, until atomic goals are reached. The program is only consulted when atomic goals are to be proved.

Design of a new proof-search strategy

Permutation properties of the inference rules of a given logical fragment have a direct impact on defining efficient proof search strategies which deal with the order of inference rules. We explain this impact through the so-called “normal
proof” [6] strategy from linear logic. In fact, we illustrate many ideas through
examples from linear logic. Linear logic can be seen as a refinement of classical logic, in that there is a fragment of linear logic which has precisely the same properties as classical logic; at the same time however, linear logic contains features which are not present in classical logic. In essence, these features are due to removing the rules for contraction and weakening and re-introducing them in a controlled manner. Hence formulae have to be used exactly once in a linear proof. The unary connectives ? and ! allow a controlled application of weakening and contraction. Two different traditions for writing the sequent rule for classical conjunction result in two different conjunctions ⊗ and & and
in two different disjunctions ℘ and ⊕.
A particular search strategy typically imposes constraints on the choice of formula to be decomposed in the next step of the proof construction. These
constraints are based on the permutability of inference rules and reduces some sources of non-determinism during the proof construction. In a bottom-up proof construction (in which search starts at the root of the tree) this approach always first applies rules for which there is a “guarantee” that if the sequent
proof tree. For instance, consider the sequent ▶ A ⊗ B, C℘D, Γ. During proof is provable, there is a proof with that rule in that particular place in the construction we must have a complete strategy for selecting the next formula
to be decomposed. This selection is crucial for bottom-up proof construction. On the basis of the permutation results given in [6] we have the following table, where the case (t1, t2) in the table contains p iff inference t1 permutes
down over inference t2, and, np iff there exists a proof in which inferences t1
and t2 are not permutable.











Table 1.
As a consequence of np for the case (⊗, ℘) and p for the case (℘, ⊗), for any provable sequent ▶ A ⊗ B, C℘D, Γ there is a proof where ℘ is applied before (closer to the root than) the ⊗ rule, but not necessary the proof with ⊗ applied
before ℘.  For instance, the proof construction of the sequent ▶ a ⊗ b, a⊥℘b⊥
terminates successfully only when ℘ precedes ⊗:


▶ a, a⊥ Ax
▶ b, b⊥ Ax
	?	
▶ a, a⊥, b⊥	?
	?	
?	▶ b, a⊥, b⊥

▶ a ⊗ b, a⊥, b⊥	⊗
℘
▶ a, a⊥℘b⊥
℘	℘
▶ b	▶ a
℘
▶ b, a⊥℘b⊥

℘
▶ a ⊗ b, a⊥℘b⊥
▶ a ⊗ b, a⊥℘b⊥	⊗
▶ a ⊗ b, a⊥℘b⊥	⊗


while ina proof construction of the sequent ▶ a⊗b, a⊥℘?b⊥, b⊥,the order of applied rules does not matter:


▶ a, a⊥ Ax


▶ a, a⊥, ?b⊥ w?	▶ b, b⊥ Ax
▶ a ⊗ b, a⊥, ?b⊥, b⊥	⊗
℘
▶ a ⊗ b, a⊥℘?b⊥, b⊥
▶ a, a⊥ Ax


▶ a, a⊥, ?b⊥ w?
▶ a, a⊥℘?b⊥ ℘	▶ b, b⊥ Ax
▶ a ⊗ b, a⊥℘?b⊥, b⊥	⊗

Thus, in the proof construction of a sequent ▶ A ⊗ B, C℘D, Γ the choice to
decompose C℘D first has a greater chance to be successful i.e. to be the choice
that lead to a proof.

Completeness of some strategies
We explain this on a simplified version of “normal proof” strategy whose full version is given in [6]. Let assume that, in the logical fragment we consider, the sequents are one-sided: ▶ Γ . Γ is a multiset of goal formulas, denoted G
and defined by the following grammar:  G := A|G ⊗ G|G℘G|G ⊕ G|∀xG|∃xG|?G


The strategy is defined by the following algorithm:
If ▶ Γ contains a formula of the form ?F then ▶ Γ is the conclusion of w? rule else
if ▶ Γ contains a formula whose top-most connective is ℘ or ∀
then ▶ Γ is the conclusion of rule which introduces that particular formula
else ▶ Γ contains a formula whose top-most connective is ⊗ or ⊕ or ∃ and
▶ Γ is the conclusion of rule which introduces that particular formula

The completeness properties of the outlined strategy follow directly from the permutability properties of the concerned linear logic fragment, which are given in Table 1. Any proof, from this logical fragment, can be transformed, by permutations of its inferences, to a proof that obeys the given strategy:


▶ a, a⊥ Ax

▶ a, a⊥, ?b w?
▶ p(t), p⊥(t) Ax
▶ a, a⊥ Ax	▶ p(t), ∃yp⊥(y) ∃

▶ p(t), p⊥(t) Ax
℘
▶ a, a⊥℘?b
▶ p(t) ⊗ a, ∃yp⊥(y), a⊥	⊗

▶ p(t) ⊗ a, p⊥(t), ?b℘a⊥	⊗
▶ p(t) ⊗ a, ∃yp⊥(y), ?b℘a⊥ ∃
▶ ∀x(p(x) ⊗ a), ∃yp⊥(y), ?b℘a⊥ ∀	'−→

▶ p(t) ⊗ a, ∃yp⊥(y), ?b, a⊥ w?
℘
▶ p(t) ⊗ a, ∃yp⊥(y), ?b℘a⊥
▶ ∀x(p(x) ⊗ a), ∃yp⊥(y), ?b℘a⊥ ∀

The Existing Framework
The problem of permutation analysis is not new ([4,12,6]). In this subsection we give a brief description of the terminology and definitions given in [6].
The active formulae of an inference are the formulae which are present in the premise(s), but not in the conclusion. The principal formula of an
inference is the formula which is present in the conclusion, but not in the premise(s). Intuitively, the inference converts the active formulae into the principal formula.
When looking to permute the order of two inferences, it is necessary to check that the principal formula of the upper inference is not an active formula of the lower one. When this property occurs, the two inferences are said to
be in permutation position (Definition 3.1 of [6].) We will refer to this as GP permutation position.
For example, consider the two inferences below:

q ▶ p, q, r
℘R
q ▶ p, q℘r
¬p, q ▶ q℘r ¬L
¬p ⊗ q ▶ q℘r ⊗L	'−→
q ▶ p, q, r
¬p, q ▶ q, r ¬L
℘R
¬p, q ▶ q℘r
¬p ⊗ q ▶ q℘r ⊗L

In either inference, we have the following:


Note that in the left-hand subproof ¬L and ⊗L are not in permutation position, while ¬L and ℘R are in permutation position.
As illustrated by the following example, two adjacent rules in GP permu- tation position are not necessary permutable. In the left hand proof below the rules ? and ! are in GP permutation position but they are not permutable (the LL rule ! requires all non active formulae from the premise to be prefixed by !):

▶ A, B, ?∆


▶ A, ?B, ?∆ ?
▶!A, ?B, ?∆ !	/'−→
▶ A, B, ?∆
\/	!

Definition 2.1 ( Definition 3.2 of [6]) (inference permutability)
. D
.
I
An inference I is permutable over an inference J of a given proof J
iff they satisfy the conditions:
A.	I and J are in the permutation position;
B1.	J is applicable on the appropriate premise(s) of I;
.
.
B2.	The conclusion-sequent of J	can be a premise of I;
. D	. D
.	.
I	J
C.	Subproofs J	and I	have the same conclusion and the same
hypothesis modulo duplication of some of them and renaming certain free variables.
In the other cases, we say that I is not permutable over J.

Some Problems With the Existing Framework
The existing techniques for permutation analysis have been adapted to partic- ular sets of inference rules. There are many situations where the permutations can not be explained by the above definitions. In particular the above analysis of permutations via the notions of active and principal formulae is sometimes too coarse to capture when permutations are possible.
Also, the existing techniques are all designed for analysis on paper by a human and many of them are ripe for automation.  Our aim is to make


explicit and systematic permutation analysis of the existing sequent calculi and to generalize and extend the existing approach.
At first, it is our contention that a more refined syntax for sequent calculus rules is needed. There are some inference rules of interest which cannot be analyzed by the existing framework. Here we give a few examples.
Example 2.2 Consider the following rule from LJ as well as from a multiple- conclusioned LJ ([5]) calculus:
Γ, a,F ▶ G
Γ, a,a → F ▶ G → L

Clearly, we have the following:

But, what can be stated about the formula a? According to existing framework formula a is a context formula. But, it has a specific ’role’ which should not characterize any context formula. Namely, the occurrence of a in the premise of the rule → L is necessary for the rule application and hence, a cannot be neither omitted nor freely replaced with another formula.
Another possibility is to interpret the occurrences of formula a in the premise and in the conclusion as active and principal formula, respectively. Under such an interpretation, for example, in the derivation below, among formulae a → F1, a → F2 the choice of formula to be decomposed next will not be arbitrary. This means that some possible permutations cannot be detected: the rule instances are not in a permutation position as a is both a principal formula of the upper → L inference and an active formula of the lower → L inference.

.
.
Γ, a, F1 , F2 ▶ G


Γ, a,a → F1 , F2, ∆ ▶ G → L
Γ, a,a → F1,a → F2, ∆ ▶ G → L
.
.
.
.
Γ, a, F1 , F2 ▶ G


Γ, a, F1,a → F2, ∆ ▶ G → L
—	Γ, a,a → F1,a → F2, ∆ ▶ G → L
.
.

The intuition behind this is that a formula occurrence whose presence in a premise is necessary (but not sufficient) for the rule application, and which is copied unchanged into the conclusion should be considered and treated separately from the context, active and principal part of the rule. We call
such formulae quasi active formulae.
A similar situation appears in the following example from a triple-context


calculus TC [11] for intuitionistic linear logic with strong negation ILL∼ [11].


Example 2.3 Consider the rules:
α, Σ; Γ ; ∆ ▶ γ
 
δ, Σ; Γ ; ∆, ! ∼ α ∧ β ▶ γ

α, Σ; Γ ; ∼ α, ∆ ▶ γ
α, Σ; Γ ; ∆ ▶ γ	absorb2

where the rule * presents a mix of ∧L, sim!W, and ∼!move rules from TC 
calculus for ILL∼.
The formula α in the absorb2 rule cannot be considered as a context for-
mula, as it is necessary for the rule application. It cannot belong to the active or principal part either, since in the left derivation below, the permutation position (and hence the permutation) will not be identified:

.
.
ϕ, Σ; Γ ; ∼ ϕ, ∆ ▶ γ
ϕ, Σ; Γ ; ∆ ▶ γ	absorb2
ϕ, Σ; Γ ; ∆, ! ∼ ϕ ∧ β ▶ γ 
.
.
ϕ, Σ; Γ ; ∼ ϕ, ∆ ▶ γ
 
ϕ, Σ; Γ ; ∼ ϕ, ! ∼ ϕ ∧ β, ∆ ▶ γ
ϕ, Σ; Γ ; ∆, ! ∼ ϕ ∧ β ▶ γ	absorb2

Example 2.4 Consider now an example from a sequent calculus for the logic of bunched implications (BI) [19]. Let us replace the left implication −∗ L rule with the rule

 Γ1 ▶ φ	Γ2, a ▶ a	'
Γ1, Γ2,φ −∗ a ▶ a −∗ L
(According to Lemma 3.7.4 of [19] the sequent system resulting from this replacement is equivalent to the original one.) Only the analysis of the −∗ rule in quasi active terms (the occurrence of a in the succedent is a quasi
active formula) enables the identification and justification of the following permutation:
.	Γ2,a ▶ a Ax	Γ3,a ▶ a Ax
⎪	−∗ L
.	Γ1 ▶ ϕ	Γ2, Γ3,a −∗ a, a ▶ a	'

.	Ax
⎪ Γ1, Γ , Γ ,ϕ −∗ a, a −∗ a ▶ a	−∗ L

Γ1 ▶ ϕ	Γ2, a ▶ a
'
−∗ L
Ax	⎪

Γ1, Γ2,ϕ −∗ a ▶ a	Γ3, a ▶ a	'
Γ1, Γ2, Γ3,ϕ −∗ a, a −∗ a ▶ a	or
⎪	.
⎪	.	Ax

Γ1 ▶ ϕ  Γ2, Γ3,a −∗ a, a ▶ a
Γ1, Γ2, Γ3,ϕ −∗ a, a −∗ a ▶ a
'
−∗ L

Example 2.5 Consider now the rule ℘' , which is a combination of the ℘ and
w rules from linear logic, and the permutation below:





▶ φ, ψ, Γ	'
.
.
▶?A, ?A, B, Γ
.
.
▶?A, ?A, B, Γ	'

'	℘
▶ φ℘ ψ, Γ, ?δ
  ▶?A, B, Γ	 c?
x	▶?A, ?
'
A℘ B,
℘
Γ, ?A

schema-rule
'	℘
▶?A℘ B, Γ, ?A
'	c?
▶?A℘ B, Γ, ?A

position in the left subproof. The reason for this is that the formula ?A is at The rules c? and ℘ are permutable although they are not in a permutation the same time the active and principal formula of the c? rule and an active
formula of the ℘  rule.
'
Thus, in the left subproof above, the rule ℘ consumes formula ?A which
is a quasi active formula of the C? rule and as such is present in the premise
'
and available for the rule ℘ , after eventual inversion of the rules. Also, a very
important detail here is the ’restoration’ of formula ?A through the principal part of the ℘ rule. So, after the inversion, ?A is available again for the c?.
Let us now concentrate on the above ‘restoration’. Consider the current definition of a principal formula. Consider the current categorization and note the difference between the principal formula(e) of the rules shown in the following Table:

Note that among principal formulae of the rules W ?, ⊃R and ℘' there are formulae which are not result of a disappearance of some active formulae (?A, ?δ and ∆ respectively). It is our contention that such formulae should be distinguished from those principal formulae that are result of a conversion


of certain active formulas. We call such formulae extra formulae. An extra formula can be used in a permutation (as we have seen in the last example), to ‘restore’ some formula(e) being already consumed.
In the next example we point out another reason for distinguishing extra from ordinary principal formulae. Namely, some impossible permutations can be ’resolved’ if an admissible rule (a structural rule or an inversion) is allowed.
Example 2.6 Consider, once again, the rule
Γ ▶ φ ⊃ ψ
⊃R
Γ,φ ▶ ψ, ∆

from LM, a multiple-conclusioned sequent calculi for intuitionistic logic, given in [22], and the impossible permutation in the left-hand subproof below.
  A ▶ B  wR

	A ▶ B	 ⊃ R
▶ A ⊃ B, ∆,C 
A ▶ B, C
¬C, A ▶ B ¬L

¬C ▶ A ⊃ B, ∆ ¬L	~	¬C ▶ A ⊃ B, ∆ ⊃ R
Clearly, the rules on the left are not in the permutation position (the active
formula of the lower rule is a principal formula of the upper rule). An analysis of these situation in the terms of extra formulae gives the following:
Extra⊃R  = { ∆,C },	Active¬L = {C},	and Active¬L ⊆ Extra⊃R
The last relation indicates that impossible permutation can be overcome by inserting a weakening rule whose extra part is equal to Active¬L , as shown in the right subproof above.
It should also be noted that once we have quasi active formulae, this allows us to give a more natural (and arguably simpler) analysis of the contraction rule. Thus, for example, for the contraction rule (presented below in its form in linear logic) we will have the categorization as follows:

∆
|{z}
▶	?F
|{z}
,	?F
|{z}
,	Γ
|{z}

Context  active formula quasi active formula Context

∆
|{z}
▶	?F
|{z}
,	Γ	C?
|{z}

Context	quasi active formula Context
Thus the contraction rule now has one active and one quasi active formula, but no principal formula.

A Refined Structure of Sequent Rules
It is our contention that a more refined syntax for sequent calculus rules is needed, as it is proposed by the following definition (we assume, for simplicity, one-sided inference systems, i.e. that the antecedents are always empty):


Definition 3.1 The structure of sequent calculus inference rules:
An active formula of rule I is a formula in a premise that does not exist in the conclusion.
A quasi-active formula of an inference I is a formula occurrence whose pres- ence in a premise is necessary (but not sufficient) for the rule application, and which is copied unchanged into the conclusion of the rule. 4
A principal formula of rule I is a formula occurrence of a conclusion that does not exist in premise(s) and that is a result of the disappearance of some active formulae of I.
A formula occurrence in the conclusion of rule I, that does not exist in a premise and that is not a principal formula, is called an extra formula.
The active part (denoted by Ai ) and the quasi-active part (denoted by QAi )
I	I
of the i-th premise of an inference I are the (possibly empty) multisets
of its active and quasi-active formulae, respectively. The principal part (denoted by PI) and the extra part of an inference I (denoted by EI) are the (possibly empty) multisets of its principal and extra formulae, respectively. The context of the i-th premise of an inference I (denoted by Contexti ) is the (possibly empty) multiset - complement of its active and quasi-active
part.




The above definition is illustrated through examples, from linear logic, in the Table below:













4 We make an exception for the exchange rule. However, all of the examples used in this paper are for commutative logics, and hence we can consider antecedents and succedents as multisets, which obviates the need for this rule.


Note that we can categorise the binary rules according to how the contexts of the two rules are combined. We can identify multiplicative rules, where the context of each premise is copied unchanged into the conclusion (rules
premise and of the conclusion are identical (rule &). Note that there are also ⊗, mix, cut in above table), and strong additive rules, where the context of each weak additive rules where some part of the context of the premise and of the
conclusion are identical.



Some applications of the refined sequent structure

As discussed above, the existing permutation analysis techniques do not cover all possible situations. Also, they are too implicit from the automation point of view. The proposed finer specification of sequent rules allows the development of more precise and more general notions connected with permutation analysis of sequent rules.
In the rest of this section we develop a more detailed, generalized and automation-oriented specification of a permutation process.

Remark 4.1 In the considerations below for any two adjacent inferences I and J, whenever J is a binary rule and directly follows I we will con- sider, unless otherwise stated, that I is above the left (i.e. first) premise
▶ A1 , QA1 ,Context1 , of J.
J	J	J


A More Precise Speciﬁcation of Permutation Position

Definition 4.2 (weak and strong permutation position) Two inferences I and J of a given proof Π are:
in the weak permutation position iff:
J follows directly I in Π,
AJ , QAJ ⊆ ContextI, QAI 5
in the strong permutation position iff:
J follows directly I in Π,
If I is a unary rule then
AJ , QAJ ⊆ ContextI , QAI	and  (AJ /⊆ ContextI ) ⇒ (AJ \ContextI ⊆

EJ )
else
∃k ∈ {1, 2} AJ , QAJ ⊆ Contextk, QAk
and	(AJ /⊆ Contextk) ⇒

(AJ \Contextk
I	I	I
⊆ EJ )

The value k = 1 (respectively k = 2) corresponds to strong-left (respec-
tively strong-right) permutation position.
For example, in the first of the proofs below, the ⊗ and ℘ rules are in the weak permutation position only, because A℘, QA℘={a⊥, b⊥} ⊆ Context⊗, QA⊗=
{a⊥, b⊥, ?c} and the active formulae of the ℘ rule (formulae a⊥ and b⊥) belong
to different premises of the ⊗ rule. In the second proof, the active formulas of the ℘ rule belong to same premise of the ⊗ rule, and hence the rules are, at the same time, in the weak and strong permutation position.



▶ a, a⊥
▶ b, b⊥

▶?c, b, b⊥ w?
▶ a, a⊥
▶ b, b⊥

▶?c, b, b⊥ w?

▶ a ⊗ b, a⊥, ?c, b⊥ ⊗
℘
▶ b⊥℘a⊥,a ⊗ b, ?c weak perm pos. for ⊗ and ℘
▶ a ⊗ b, a⊥, ?c, b⊥ ⊗
℘
▶ b⊥℘?c, a ⊗ b, a⊥
strong and weak permutation pos. for ⊗ and ℘

The strong permutation position takes into account more carefully the
distribution of formulae from AJ , QAJ between the multiset ContextI, QAI . The requirement that AJ , QAJ ⊆ Contextk, QAk prevents the situation where active
I	I
and/or quasi-active formulae of J belong to different premises of I. Such a situation can not be “recognized” in the weak permutation position:
5 For a binary rule I ContextI (respectively QAI ) is the union of the Contextk (respectively
QAk) for each premise k.

i)	ii)	iii)

▶ a, a⊥
▶ b, b⊥
▶ a, a⊥
▶ b, b⊥	.

▶?c, b, b⊥ w?	.

▶ a ⊗ b, a⊥, b⊥ ⊗
℘
weak (/⇒ strong) ▶ a⊥℘b⊥,a ⊗ b not permutable rules
▶ a ⊗ b, a⊥, ?c, b⊥ ⊗
℘
▶ b⊥℘?c, a ⊗ b, a⊥ strong (⇒ weak) permutable rules
▶ A, B, C
▶ A, B, C ⊕ D ⊕
℘
strong (⇔ weak) permutable rules ▶ A℘B, C ⊕ D

The condition (AJ /⊆ Contextk) ⇒ (AJ \Contextk ⊆ EJ ) ensures that the situa-
I	I
tions in which quasi-active formula(s) of upper inference I, which has(have)
been “consumed” by lower J (i.e. used as the active formulae(s) for J) are acceptable (for the further permutation analysis) iff such formula(s) can be
restored again through the extra part EJ (in that way it(they) remains avail- able for I, after the eventual reversing of the order of I and J). As example, consider permutation from example 4 of subsection 2.3:


.
.
▶?A, ?A, B, Γ

▶?A, B, Γ	c?
.
.
▶?A, ?A, B, Γ	'
'	℘
▶?A, ?A℘ B, Γ, ?A

'	℘
▶?A℘ B, Γ, ?A	=⇒
'	c?
▶?A℘ B, Γ, ?A

We use the notion of strong permutation position as a precondition for fur-
ther checking of permutabilities of given rules. We could say that the notion of strong permutation position is dedicated to the analysis of possible permu- tations in a given proof i.e. when we have the concrete instances of a given inference rule. Recall that such permutations and inference movements in a
given proof are essential for rearranging proofs to satisfy particular strategies. It also helps us to detect other proofs of a given sequent which differ only in the order of inference rules.
The notion of weak permutation position is suitable for recognition of non- permutable rules in a given proof tree (in regard to part 3.  of Lemma 4.3
below), as well as for recognition of pairs of schema-rules which represent rules that can never be permutable.
The condition for GP permutation position corresponds to the condition AJ , QAJ ⊆ ContextI . In the absence of quasi-active formulae, the GP permu- tation position corresponds to the weak permutation position. Like the weak
permutation position, the GP permutation position is more suitable for per- mutation analysis on the level of given set of schema-rules than in the analysis of possible permutations directly in a given proof.
We can establish the following dependencies among the different permuta-


tion positions:
Lemma 4.3 For any two adjacent inference rules I and J of a given proof Π:
Strong permutation position ⇒ weak permutation position.
Weak permutation position /⇒ strong permutation position.
I is not in weak permutation position with J	⇒ I is not permutable over J.
GP permutation position ⇒ weak permutation position,
GP permutation position /⇒ strong permutation position,
weak permutation position /⇒ GP permutation position,
If QAJ = QAI = ∅ then weak permutation position e GP permutation position,
strong permutation position /⇒ GP permutation position.
Proof. 1., 4., 7.  obvious from Definitions 2.1 and 4.2;
see above examples;
corollary of 1.;
see example i) above;
, 8. see example 4 of subsection 2.3.	 
Hence in order to study possible permutations, we adopt the Definition 2.1 but with condition A. (’being in permutation position’) changed to As : I and J are in the ‘strong permutation position’.

Automating Permutations
We use the proposed characterisation of the structure of sequent calculi rules for the automated-oriented speciﬁcation of the permutation process. Here we outline some results which have been described in detail and proved formally in[13].
Our framework characterizes sets of inference rules, and is intended to be as general as possible. Whilst it is difficult to state with confidence that the permutation properties described here apply to arbitrary logical fragments, we believe that the classes of inference rules covered here includes all well- known sequent calculi and many lesser-known ones.
The active, quasi-active, principal and extra part of an inference rule are not changed by its permutation up or down, in a given proof. The context part of an inference can change during inference permutation. The appropriate changes in the context have been specified in detail.


Some “pre-conditions” for a permutation have been analysed in detail and restricted to particular parts of inference rules, with minimally sufficient tests.
Some dependencies between the ways of permuting rules and their generic properties and the characteristic of a given proof have been specified and proved. For example, the upward permutation of a strong-additive rule re- quires a set of particular conditions. Also, the form of the permutation result
depends on the generic properties of the rules in question and therefore can be determined independently of direct permutation.
We will explain some of our results on the example of a unary rule I and a strong-additive rule J :


▶ A1 ,
1
, Context
▶ A2 ,
2
, Context

 ▶ AI, QAI , ContextI	
J  QAJ	J
J  QAJ	J
J

▶ P , QA , Context , E  I
▶ P , QA1 , QA2 , Context , E

I	I	I
J	J	J	J




Proposition 4.4 After the permutation, the contexts of the permuted rules I
and J are changed as follows:

ContextI	:=	[ContextI , EJ]\A1 , PJ , QA2
J	J
ContextJ	:=	ContextJ \[PI, EI] ,  AI

Proof. Assuming the strong-left permutation position, the subproofs before and after the permutation would be respectively:


▶ AI,  QAI ,  ContextI

▶ PI;	QAI
| {z }
, ContextI , EI	I
|{z}

''	''	'	'
AJ ,QAJ ,qAI  AJ ,QAJ ,CI
|	{z	}


'	''

'	''	2	2

▶ AJ , AJ , QAJ , QAJ , PI, EI, CI, qAI	▶ AJ ,  QAJ ,  ContextJ

|{z}
1
J
|	{z	}
QA1
|	{z	}
ContextJ

1	2	J
▶ PJ , QAJ , QAJ , ContextJ ,	EJ
|{z}
''
AJ ,eJ




▶ AI ,	QAI,
| {z }
ContextI
|{z}

''	''	'	'
AJ ,QAJ ,qAI  AJ ,QAJ ,CI	2	2

|	{z	}
A1 , QA1 , AI ,CI,qAI
▶ AJ , QAJ , ContextJ

J	J
1	2	J

▶ PJ ,	QAJ
| {z }
'
, QAJ ,  qAI, AI, CI,	EJ
|{z}
''	''

QAJ ,QAJ	AJ ,eJ
|	{z	}

''	''	'	2
▶ AI , AJ , QAJ , qAI , QAJ , QAJ , CI, PJ , eJ
|	{z	}  |	{z	}
QAI	ContextI
▶ PI,  QAI,  ContextI,  EI,	I


The proof is straightforward from a simple inspection of distribution of formulae in the above subproofs.	 
Theorem 4.5 A unary rule I is permutable over a strong additive rule J iff they satisfy the conditions:
I and J are in the strong permutation position;
PI = ∅,	EI = AI;

The multiset	[ContextI , EJ]\A1 ,	PJ , QA2
can be (i.e. satisﬁes all

J	J
restrictions for) the context of rule I.
Proof. On the base of Proposition 4.4 and Definition 2.1, the following equiv- alences are straightforward:
i)  ⇐⇒ As
iii)  ⇐⇒  B2

As J is a strong additive rule, the context of the premisses must be identical. Thus, it must be: ContextJ = ContextJ \[PI, EI] , AI	⇐⇒	PI, EI = AI. As	PI ∩ AI = ∅,	we have	PI = ∅, EI = AI.

According to Proposition 4.4, after the permutation, the new context in the left premise of J would be ContextJ \[PI, EI] , AI.
The condition ii) PI = ∅,  EI = AI gives the following:
ContextJ \[PI, EI] , AI = ContextJ . That ensures the applicability of J on the appropriate premise(s) of I (condition B1 of Definition 2.1). The equality of the end-sequents (i.e. condition C of Definition 2.1) is trivially true (and can be checked directly).		 


For example, consider the & rule from linear logic, which is a strong addi- tive rule, and the cw rule, which is a combination of weakening and contrac- tion:
▶ φ, Σ	▶ ψ, Σ &	 ▶?F, ?F, ∆  cw

▶ φ&ψ, Σ
Consider the following transformation:

▶?C, ?C, A
cw
▶?C, A, ?C	▶ B, ?C, ?C
▶ A&B, ?C, ?C	&	=⇒
▶  ?F, ∆, G


▶ A, ?C, ?C	▶ B, ?C, ?C


▶ A&B, ?C, ?C	&
cw
▶?C, A&B, ?C


Note that instances of a rule which satisfy the condition ii) of Theorem 4.5 are actually redundant steps in a proof; in other words, all such potential permutations can be removed entirely from the proof. Note that in the above example, the cw rule is redundant (both before and after the permutation). Hence it is not necessary to permute these rules; we can simply eliminate the cw instance. If we adopt the strategy of “eliminate redundant steps in a
given proof prior to any other proof transformation”, then as a consequence of
Theorem 4.5, we come to the statement:
It is never possible to permute one of the unary rules over a strong-additive rule.
In other words, when such a combination is found, we should eliminate the redundant inference, rather than permute it.
As noted in Subection 4.2 of [6], there are some non-permutabilities which can be overcome by taking special cases into account. One such case is when the unary rule is not just above the left premise of the lower rule, but above both of them. The idea is to notice the subproof as shown on the left (if it exists) and to (try to) transform it into the right-hand subproof:

.	.
   .	β
γ1	γ2	I
.	.
.α  β .
γ	J

δ	J	'−→	δ	I

We call such permutations special permutations.
As example, consider the following special permutation from linear logic.

.
.
▶ A, C, D ℘
.
.
▶ B, C, D ℘
.
.
▶ A, C, D
.
.
▶ B, C, D
&

▶ A, C℘D
▶ B, C℘D
&
▶ A&B, C, D  ℘

▶ A&B, C℘D	=⇒	▶ A&B, C℘D


In the following theorem we give the necessary and sufficient conditions for a special-permutation.
Theorem 4.6 A unary rule I is special-permutable over a strong-additive rule
J in a subproof
.	.
   .	β
γ1	γ2	I
δ	J
iff they satisfy the conditions:
Each occurrence of I  is in the strong-permutation position with J ;
ContextJ \[PI, EI] ,	AI can be (i.e. satisﬁes all restrictions for) the context of rule J;

[ContextI , EJ]\A1 , PJ , QA2
can be the context of rule I;

J	J
ContextJ \[PIL, EIL ] , AIL	=	ContextJ \[PIR, EIR ] ,  AIR
where IL (respectively IR) denotes the occurrence of I in the left (respectively in the right) premise of J.
Proof. Similar to proof of Theorem 4.5.	 

Form of the permutation result
As mentioned above, the form of the permutation result can be determined independently of direct permutation in a given proof. For example, the per- mutation result for a binary rule J and a unary I can have, as shown below, different forms in regard to possible duplication of some proof branches or duplication of I. Let us denote their initial structure by F0 and possible forms
of permutation results respectively by F1, F2 and F3:


.	.
.	.
γ1  γ2
β	J
.
.
γ1	.
J	.
γ2
.
.
.	γ2
.	 I
γ1
.
.
γ1
β1 I
.
.
γ2
β2 I

Fo :
α	I	F1 :
α	J	F2 :
α	J	F3 :	α	J

The form of the permutation result can be determined in advance, before
the direct, final permutation. As a consequence of Theorem 4.5 we have the following assertion:
Theorem 4.7 If we eliminate redundant steps in a given proof prior to any other proof transformation (i.e. prior to any permutation), then a permutation of a strong additive rule J over a unary rule I results only in the permutation result of the form



.
.
γ1 β1 I
.
.
γ2 β2 I

α	J
The result is appropriate for a process such as adapting proofs to obey certain strategies, identifying cases where this is not possible, minimizing the amount of branching in the proof, delaying certain choices until the availability of an optimum amount of information, and controlling the degree of non- determinism (if possible, not to duplicate rules or branches with high level of non-determinism).

Inference permutability
The proposed structure of inference rules allows the specification of some connections between the structure of rules and their permutability properties. Thus, for example, the following theorem holds:
Theorem 4.8 Let J be a strong additive rule and I1 and I2 be unary rules. If rules I1 and I2 satisfy either of conditions:
PI1 = PI2 and QAI1 = QAI2
PI1 = ∅ and EI1 = PI2 and QAI1 = QAI2
then the rules Ik k ∈ {1, 2} and J are not permutable.
As an illustration consider the strong additive rule &R and the unary rules
w? and ?R from linear logic:

Γ ▶ A, ∆	Γ ▶ B, ∆ &	Γ ▶ ∆
Γ ▶ F, ∆
w?	?R

Γ ▶ A&B, ∆
Γ ▶?F, ∆
Γ ▶?F, ∆

Redundancy Analysis of Sequent Proofs
As we have seen, permutation of inferences can be used to ‘improve’ a given proof (or proof fragment). As shown by the analysis of Theorem 4.5, this can also involve removing redundant inferences. In this section we study how some other forms of redundancy may be removed from a proof.
Success in a proof search is not simply a matter of finding a proof, but of providing more information about provability. Parts of a constructive proof may be irrelevant to the actual computation which results. It is also obvious that a more efficient implementation of proof search strategies demands the finer control and management of the formulae involved in the proof-search.


We consider the problem of detection of unnecessary parts of a sequent proof and elimination of redundant formulae that does not alter the search strategy applied. There are several potential benefits of such knowledge. For the logic programming strategies this knowledge is particularly useful when composing programs (and hence proofs), for debugging purposes and also for teaching purposes. For a given search strategy, we may thus consider this work as an initial requirements analysis of the properties of proofs.
Below we briefly illustrate some ideas about detection and elimination of unused formulae and redundant parts of a proof through examples in linear logic.
For example, it is straightforward to find a proof of a sequent containing T, as such a sequent is an axiom in the linear sequent calculus. Consider the provable sequents p ▶ q, T and p ▶ p, T. For the first sequent there is no meaningful information that can be extracted from the proof, apart from the presence of T. For the later, T is clearly redundant, and hence it is useful to be able to deduce this.

Making use of past successful proof-search experience
Example 5.1 Let us consider the successful proof below. We denote by У
and G respectively the antecedent and succedent part of the sequent !s, r℘p ▶
`˛P¸x

(?r℘t) ℘ (((T⊗ p) ⊕ q) ⊗ s
`	˛¸	x



r ▶ r Ax

p ▶ p Ax	▶ T,t T
p ▶ p ⊗ T,t	⊗R



s ▶ s Ax
!s ▶ s !L


r℘p ▶?r, t, T⊗ p ?R r℘p ▶ r, t, T⊗ p	℘L
r℘p ▶?r, t, ((T⊗ p) ⊕ q) ⊕R
℘R
r℘p ▶?r℘t, ((T⊗ p) ⊕ q)
!s, r℘p ▶?r℘t, ((T⊗ p) ⊕ q) ⊗ s	⊗R
℘R

!s, r℘p ▶ (?r℘t) ℘ (((T⊗ p) ⊕ q) ⊗ s)
As t and q are unused subformulae, both can be omitted or replaced with
G : (?r ℘ t) ℘ (((T⊗ p) ⊕ q) ⊗s) as necessary parts of G, in that the search process another formula. Hence we may think of the underlined parts of the formula establishes that (?r℘ ((T⊗ p) ⊗ s)) succeeds, and hence deducing the success of
G. Furthermore, we can refine this process by omitting (redundant) constant
'
T as well as connective ?, resulting in the formula G  = r℘(p ⊗ s) . In this

'
way an analyser could find a formula G
'
such that both У ▶ G
'
and G ▶ G 

are provable. This may be thought of as calculating an interpolant formula


G' from У and G. Note that the transformation from G to G' does not alter the search strategy used, in that the order of application of the rules is not changed:

s ▶ s Ax
!s ▶ s !L

	
r ▶ r Ax	p ▶ p Ax r℘p ▶ r, p	℘L
!s, r℘p ▶ r, p ⊗ s	⊗R
℘R

!s, r℘p ▶ r℘ (p ⊗ s)
This formula G' can be thought of as a representative of a family of formulae
whose derivations, for the given formula У, will require no effort to establish.
For the above example, the obligatory part 6 of G is r℘ (p ⊗ s) while a general template for successful formulae based on G could be
( [?] r ℘[ F ] ) ℘ ( (( [T] ⊗ p) ⊕ [ Q]) ⊗ s )
where F and Q are arbitrary formulae, and [] denotes parts of the original formula G that can be omitted.
This knowledge allows later computations to make use of earlier work. So a proof-search strategy can retain the results of a previous successful search and to apply and combine them to a new situation.
Example 5.2 For a given proof, we distinguish unused formulae that can be freely eliminated from the proof and unused formulae whose elimination will cause the proof to ’crash’. For example, consider the proof Π on the left-hand
side below. (Sub)formulae p, q and s are unused, but only s can be freely
deleted from the proof while formulae p and q cannot be simultaneously eliminated.  Note that  p, q  and  s  are subformulae of the active formula
(?q℘?p) ⊕ s of the multiplicative rule ⊗R. Elimination of the whole formula (?q℘?p) ⊕ s will disable proof branching i.e. distribution of formulae across the multiplicative branches of the proof. Elimination of the subformula ?q℘?p will
also lead to the unprovable sequent (on the right-hand side below).
Π : 





t ▶ t Ax
r ▶ r Ax
r ▶?p, r ?wR

r ▶ ?q, ?p, r ?wR r ▶ ?q℘?p, r ℘R
r ▶ (?q℘?p) ⊕ s, r ⊕R



?	t ▶ t	r ▶ s, r

r, t ▶ t ⊗ ((?q℘?p) ⊕ s),r	⊗R


r, t ▶ t, r


r, t ▶ t ⊗ s, r

So, we have that p, q and s are unused and that p and q cannot be simul-
taneously eliminated from the proof. For each unused atom we have three possibilities:
6 i.e., the minimal information which must be present in G


to omit it from the proof;
to leave the atom unchanged and
to replace it with an arbitrary formula.
So proof Π can be thought of as a template for (32 − 1) · 3 proofs (i.e. some variations of the given proof) which can be generated by alterations of p, q and s. All that proofs do not alter the search strategy used, in that the order of application of the rules is not changed.

Reducing the amount of work that must be done
Let us illustrate how to take advantage of the detection of unused formulae in one branch during a proof construction.
Example 5.3 Detection of unused formulae of a subproof can reduce the branching factor at some search node and hence enables the search strategy to immediately terminate the proof-search with success. For example consider the following situation:
Π1
Γ1 ▶ A, ∆1  Γ1 ▶ B, ∆1

Γ1 ▶ A&B, ∆1	&R
.
.
Γ ▶ A&B, ∆
could conclude (without any examination) provability for the sequents Γ ▶ If A is unused in the subproof Π1 (and hence Γ1 ▶ ∆1 is provable), an analyser A, ∆ and Γ ▶ ∆ . Also, if B is similar enough to A, it could be concluded
(on the basis of possible replacement of A with formula B and hence without
examination of the right branch) that sequent Γ1 ▶ B, ∆1 is provable too.
Example 5.4 It is not uncommon that a given logical fragment is simply too weak to directly support a number of features that programmers de- mand. To solve this problem some logic programming systems provides extra- logical language features, such as module systems and the dynamic predicates assert/retract. A common use of dynamic predicates is to temporarily assert information needed for a proof. For instance, suppose that the proof below involves assert’ing the fact, say S, while solving the left branch.
Ax	Σ

, Γ,p ▶ p
, Γ ▶ F
Ax	Σ1
▶ F ⊃L

Γ,F ⊃ p ▶ p ∧ p	∧R


confronted with the equivalent subproofs (Σ and Σ1). The search strategy might If S is unused in the subproof Σ (and hence Γ ▶ F is provable) we are recognize this situation and terminate the proof construction with success at
the proof step denoted by ∗?∗ below. If the proof Σ1 is large then the savings may be considerable.


, Γ,p ▶ p
Ax	Σ
, Γ ▶ F
Γ,F ⊃ p ▶ p ∧ p
Ax	∗?∗
▶ F ⊃L
∧R


Automated detection of unused formulae

Related Work
The immediate inspiration for our algorithm was the work on labelled deduc- tion for resource distribution by Harland and Pym [9], and Harland [8]. Their work actually presents a characterization of a range of strategies for distribut- ing and selecting resources in linear sequent calculus proof-search. It is based on a sequent calculus annotated with Boolean constraints. Proof-search strate- gies are characterized by calculations of solutions of sets of Boolean equations generated by searches.
The idea used in [9,8], was to attach a Boolean expression to each formula in the proof, and to use the information thus recorded to keep track of the status of each formula, and in particular which choice of formula has been made. The values of Boolean expressions are typically defined by the leaves
of the proof (i.e. the axioms) and the choice of rules made in the construction
of the proof.
For example, appyling this technique [9,8], to Example 2.3 above gives the following labelling:
r[x1], t[x2 ] ▶ r[y1 ] Ax
r[x1], t[x2 ] ▶?p[z], s[z], r[y1] ?wR
r[x1], t[x2] ▶ ?q[z], ?p[z], s[z], r[y1] ?wR
℘R

r[x1], t[x2 ] ▶ t, r[y1] Ax
r[x1], t[x2 ] ▶ (?q℘?p)[z], s[z], r[y1 ]
r[x1 ], t[x2 ] ▶ (?q℘?p) ⊕ s, r[y ]  ⊕R

r, t ▶ t ⊗ ((?q℘?p) ⊕ s),r 
1
⊗R
'−→
y1 = 0, z = 1 
x1 = 0, x2 = 1 


r[1], t[0] ▶ r[1] Ax
r[1], t[0] ▶?p[1], s[0],r[1] ?wR
r[1], t[0] ▶ ?q[1], ?p[1], s[0],r[1] ?wR
℘R

r[0], t[1] ▶ t, r[0] Ax
r[1], t[0] ▶ (?q℘?p)[1], s[0],r[1]
r[1], t[0] ▶ (?q℘?p) ⊕ s, r[1]  ⊕R

'−→
r, t ▶ t ⊗ ((?q℘?p) ⊕ s),r	⊗R

Note that by the technique being developed in [9,8] we can detect that s is unused in the above proof by inspecting the value of the Boolean variable upon completion of the search, and noting that it is not set to 1. Thus, we cannot conclude that formulae ?p and ?q are not used, and that cannot be simultaneously eliminated from the proof.

Automated Partial Redundancy Elimination
We present an algorithm for partial elimination of redundant formulae (Algo- rithm PRE) from a given proof. Our intention is not to find all different proofs of a given sequent but to generate all the concrete simplifications which are instances of a generated proof. By partial elimination of redundant formulae we mean:
elimination independent of the search strategy used;
elimination which does not alter the search strategy applied;
no additional proof search i.e. redundant formulae remaining in the result- ing proof cannot be eliminated without additional proof search;
preserving the multiplicative branching structure of the proof.
Our technique is independent of proof-search strategy used and implies a comparison of sets of atoms from the root-sequent and from the leaves of a proof tree as well as supervision of (only) those formulae which in some sense ’preserve’ multiplicative branching of the proof.
We will briefly, informally explain our approach on the propositional frag- ment of linear logic excluding contraction and binary additive rules. These rules may be incorporated into what follows without much difficulty. Also, in the rest of this section we restrict our attention to detection and elimination of unused formulae that appear in the succedent only.
We will briefly, informally explain Algorithm PRE on the Example 2.3 above.
At first, the sequent to be proved has to be rectified so that dis- tinct occurrences of a same atom have distinct indices: r, t ▶ t1 ⊗
((?q℘?p)⊕s), r1. The set of atoms at the root sequent is A = {r, t, t1, q, p, s, r1}.
Keeping track of formulae being relevant for proof branching.


Our sequents assume the form


Ax1 , Ax2 , ... Axk  ▶ By1 , By2 , ... Byn
H,

1	2	k	1	2	n



elements are sets of formulae {F1, F2,... Fn}, n ≥ 1. As search proceeds, we where superscript labels x1,... xk, y1 ,... yn are variables and H is the set whose record in H only formulae which are occurred and relevant for the branching
on the current path.
On the successful completion of the search, each set from the H place the constraints on the elimination of the corresponding formulae: formulae recorded in the same set cannot be eliminated simultaneously in order to preserve proof branching.
We use superscripts to tag formulae which are currently recorded in H. Formulae recorded in the same set {F1, F2,... Fn} are labelled with the same
superscript. A formula already recorded will be replaced with its subformu- lae encountered (if any) during a search.
The tag  ϵ  denotes that there is no restriction on elimination of the
corresponding formula. At the beginning, all formulae of a sequent to be proved are labelled with ϵ.
Informally, the algorithm includes simultaneous (bottom-up) construction of a proof tree and maintaining of labels and set H.
Below we give the specification for those rules in linear logic which may
change the labels (of succedent’s formulae) and/or set H. All other rules propagate up labels and H unchanged. For simplicity, we only give one premise for the ⊗2R rule; to recover the full rule, we set i to 1 or 2 as appropriate, and replace φ with ψ.
Γ1 ▶ φw, ∆1  −H, {φw}	Γ2 ▶ ψy, ∆2  −H, {ψy}

Γ1, Γ2 ▶ (φ ⊗ ψ)c, ∆1, ∆2  −H 
⊗1R

Γs ▶ φzs, ∆s, ∆c	−H[{(φ1 ⊗ φ2)w, F1, ..., Fh} ← {φzs}]

s	s+2	s
Γ1, Γ2 ▶ (φ1 ⊗ φ2)w, ∆1, ∆2, ∆w, ∆w  −H 
⊗2R

3
Γ ▶ φc, ψc, ∆ −H 

Γ ▶ (φ℘ψ)c, ∆ −H 
4
℘1R

Γ ▶ φw, ψw, ∆  − H[{(φ℘ψ)w, F1, ..., Fh} ← {φw, ψw, F1, ..., Fh}]
w
℘2R

Γ ▶ (φ℘ψ) , ∆ −H 

Γ ▶ φc, ∆  −H 

Γ ▶ (φ ⊕ ψ)c, ∆  −H 

⊕1R

Γ ▶ φw, ∆  − H[{(φ ⊕ ψ)w, F1, ...Fh} ← {φw, F1, ...Fh}]
w

⊕2R

Γ ▶ (φ ⊕ ψ) , ∆ −H 



  Γ ▶ ∆ − H	
Γ ▶ ?φw, ∆ −H ?wR
Γ ▶ φw, ∆ − H, {φw}	Γ1,ψ ▶ ∆1  −H 
Γ, Γ1,φ −◦ ψ ▶ ∆, ∆1 −H	−◦ L

Γ,φ ▶ ψw, ∆  − H, {ψw}
c

−◦ 1R
Γ,φ ▶ ψy, ∆ −H 
w
−◦ 2R

Γ ▶ (φ −◦ ψ) , ∆ −H 
Γ ▶ (φ −◦ ψ) , ∆ −H 

where H[Ω ← Υ] denotes replacing of set Ω from list H with set Υ.
Note that for each application of a multiplicative rule the superscript labels of each active formula are assigned a fresh variable, reflecting the fact that neither of these formulae cannot be totally eliminated. Also the superscript variable of the principal formula must be assigned the value ϵ , in order to cancel the constraint valid for formula(e) being labelled with that variable.
Note that we will often identify an unlabelled formula φ with the labelled formula φє. It will always be possible to disambiguate such annotations from the context.
Thus, for the proof Π we have:
r ▶ r1	− {?qx, ?px} Ax
r ▶?px, r1	− {?qx, ?px} ?wR
r ▶ ?qx, ?px, r1	− {?qx, ?px} ?wR


t ▶ ty
{ty} Ax
r ▶ (?q℘?p)x, r1
r ▶ ((?q℘?p) ⊕ s)x, r1
— {(?q℘?p)x} ℘R
— {((?q℘?p) ⊕ s)x} ⊕R
⊗R

r, t ▶ t1 ⊗ ((?q℘?p) ⊕ s), r1	−· 
Calculation of unused atoms.
On the successful completion of the search, we calculate the set of atoms which appear in the axioms : U = {t, t1, r, r1}.
The difference of sets A and U determines all unused atoms: A\U =
{p, q, s}
Constraints on elimination of unused atoms i.e. formulae.
Among the sets recorded in H at the leaves of a proof tree, we exclude those sets which contain at least one formula with at least one atom from the set U. Each remaining set determines a set of formulae that cannot be eliminated simultaneously from the given proof. For the proof Π that is the set {?qx, ?px}.
Elimination of unused formulae.
According to the constraints generated in step 4, select atoms that can be deleted simultaneously from the proof. Delete every appearance of the selected atoms i.e. every appearance of (sub)formulae made up of the se- lected atoms. Delete any rule inferences in which at least one active formula
is deleted.


Example 6.1 For the sequent m ⊗ n, t, b ▶ (?p℘(m ⊗ n)) ⊗ (b℘?s), (?r ⊗ t)℘?l i.e. its ’rectification’ m1⊗n1, t1, b1 ▶ (?p℘(m⊗n))⊗(b℘?s), (?r⊗t)℘?l we have the following proof:
t ▶ tz1 − {?pw, (m ⊗ n)w}, {tz1} Ax

t ▶?pw, tz1 − {?pw, (m ⊗ n)w}, {tz1} wR	P
⊗1R

m1 ⊗ n1, t1 ▶ ?pw, (m ⊗ n)w, ?r ⊗ t, ?l  − {?pw, (m ⊗ n)w}
m ⊗ n ,t	▶ (?p℘(m ⊗ n))w, ?r ⊗ t, ?l  − {(?p℘(m ⊗ n))w} ℘R
1	1  1

m ⊗ n ,t 
▶ (?p℘(m ⊗ n))w, (?r ⊗ t)℘?l  − {(?p℘(m ⊗ n))w} ℘R  P

1	1  1
2 ⊗1R

m1 ⊗ n1, t1, b1 ▶ (?p℘(m ⊗ n)) ⊗ (b℘?s), (?r ⊗ t)℘?l −· 
where the proof P1 is as follows:

n ▶ nv2 − {?rz2}, {nv2} Ax

m ▶ mv1 − {?rz2}, {mv1} Ax
n ▶ nv2, ?rz2, ?l − {?rz2}, {nv2} wR
1	⊗2R

m1, n1 ▶ (m ⊗ n)w, ?rz2, ?l − {?pw, (m ⊗ n)w}, {?rz2}
⊗L
m1 ⊗ n1 ▶ (m ⊗ n)w, ?rz2, ?l − {?pw, (m ⊗ n)w}, {?rz2}
and the proof P2 is as follows:
b1 ▶ by  − {by, ?sy} Ax
b1 ▶ by, ?sy  − {by, ?sy} wR
b ▶ (b℘?s)y − {(b℘?s)y} ℘R
1

On the successful completion of the search we have the following ’calcula- tions’:


A = {m1, n1, t1, b1, p, m, n, b, s, r, t, l}	U = {m1, m, n1, n, t1, t, b, b1}

H = { {?pє, (m ⊗ n)є}, {tz1}, {rz2}, {mv1}, {nv2}, {by, ?sy} } 
The set U ’produces’ the following refinement H = { {rz2} }. So we have just the constraint that formula ?r cannot be eliminated from the proof. As A\U = {p, s, r, l}, atoms p, s and l can be freely eliminated.
It should be stressed that our technique can be easily extended to an arbi- trary set of sequent rules. It is envisaged that the results of this analysis can then be implemented and utilized by means of an automated proof assistant. Our technique is limited to sequent proofs and thereby differs from dead-code elimination in functional languages. Developing more general techniques for program slicing and dead-code elimination in advanced logic programming languages is research still in progress.

Conclusions and Future Work

We have discussed two issues in the analysis of search strategies in sequent systems: permutations and elimination of redundant formulae.
We have proposed a more detailed specification of inference rules, in order to enable a more precise analysis of their permutation properties. This analysis can be used, among others, to reduce the proof search space.
We have also shown how some sequent rules with constraints can be used to extract information about the necessary and unnecessary formulae in a proof. This knowledge can contribute, among others, to a further reduction of the search space. The proposed technique for the detection of unnecessary formulae is quite general and it can be applied more broadly than just linear logic calculi.
We may thus consider this work as an initial requirements analysis of the properties of proofs of interest to (logic programming, at least) proof-search strategies.
It is envisaged that the results of this analysis can then be implemented and utilized by means of an automated proof assistant such as Twelf [18,21], possibly in conjunction with constraint logic programming techniques [14].
Another topic of research is further reduction of redundancy in a proof search, such as loops triggered off by cyclic combinations of inference figures. It is well known that for many logics, backward proof search in the usual sequent calculi does not terminate in general.
Systems for preventing and detecting loops during a proof construction have been studied for a long time and many different approaches have been proposed. It is interesting to note that in spite of expansion of the proof systems based on (fragments of) resource sensitive logics (such as, for example, affine and linear logic) no loop detection mechanism (apart from the naive loop checker) has been developed or described in the literature.
We are interested in developing automated, strategy independent loop de- tection mechanisms for resource sensitive logics. Work is already underway on a terminating proof search mechanism for affine logics.




Acknowledgements

The authors are grateful to some anonymous referees for some very helpful comments on drafts of this paper.

References
J-M. Andreoli and R. Pareschi Logic programming with sequent systems: A linear Logic Approach., in P.Schr¨oder-Heister ed., Proceedings of Workshop to Extensions of Logic Programming 1-30, Tu¨bingen, 1989. Published by Springer-Verlag as Lecture Notes in Artificial
Intelligence 475.
J-M. Andreoli, Logic Programming with focusing proofs in linear logic, Journal of Logic and Computation, 2(3):297-347, 1992.
P. Armelin Programming with Bunched Implications, PhD Thesis, Queen Mary, University of London, 2002.
H.B. Curry, The Permutability of Rules in the Classical Inferential Calculus, Journal of Symbolic Logic 17:245-8, 1952.
R. Dyckhoff, Contraction-free Sequent Calculi for Intuitionistic Logic, The Journal of Symbolic Logic, Vol. 57(3):795-807, Sept. 1992.
D. Galmiche and G. Perrier, On proof normalisation in Linear Logic, Theoretical Computer Science 135:67-110, 1994.
J. Harland, A proof-theoretic Analysis of Goal-directed Provability, Journal of Logic and Computation 4(1):69-88, 1994.
J. Harland, An Algebraic Approach to Proof Search in Sequent Calculi, short paper presented at the International Joint Conference on Automated Reasoning, Siena, July, 2001.
J. Harland and D. Pym, Resource-distribution via Boolean constraints, ACM Transactions on Computational Logic 4(1)56-90 January, 2003.
J. Hodas and D. Miller, Logic programming in a Fragment of Intuitionistic Linear Logic, Journal of Information and Computation 110(2):327-365, 1994.
N. Kamide Sequent Calculi for Intuitionistic Linear Logic with Strong Negation, Logic Journal of the IGPL 10(6):653-687, 2002.
S.C. Kleene, Permutability of Inferences in Gentzen’s Calculi LK and LJ, Memoirs of the American Mathematical Society 10, 1952.
T. Lutovac and J. Harland, Towards the Automation of the Design of Logic Programming Languages, Technical Report TR-97-30, Department of Computer Science, RMIT University, 1997.
K. Marriot and P. Stuckey, Programming with Constraints, MIT Press, 1998.
D. Miller, A logical analysis of modules in logic programming, Journal of Logic Programming 6:79-108, 1989.
D. Miller, Forum: A multiple-conclusion speciﬁcation-logic, Theoretical Computer Science 165(1): 201-232, 1996.

D. Miller, G. Nadathur, F. Pfenning and A. Sˇˇcedrov, Uniform proofs as a Foundation for Logic Programming, Annals of Pure and Applied Logic 51, 1991.
F. Pfenning and C. Schu¨rmann, Twelf — a meta-logical framework for deductive systems, H. Ganzinger, editor, Proceedings of the 16th International Conference on Automated Deduction (CADE-16) 202–206, Trento, Italy, July 1999. Published by Springer-Verlag as Lecture Notes in Artificial Intelligence 1632.
D. Pym, The Semantics and Proof Theory of the Logic of Bunched Implications, Kluwer Applied Logic Series Volume 26, 2002.
D. Pym and J. Harland,A Uniform Proof-theoretic Investigation of Linear Logic Programming, Journal of Logic and Computation 4(2):175-207, 1994.



C. Schu¨rmann, Automating the Meta-Theory of Deductive Systems, PhD thesis, Carnegie- Mellon University, 2000.
L. Wallen, Automated Proof Search in Non-classical Logic, MIT Press, 1990.
M. Winikoff and J. Harland, Implementing the Linear Logic Programming Language Lygon, Proceedings of the International Logic Programming Symposium 66-80, Portland, December, 1995.
