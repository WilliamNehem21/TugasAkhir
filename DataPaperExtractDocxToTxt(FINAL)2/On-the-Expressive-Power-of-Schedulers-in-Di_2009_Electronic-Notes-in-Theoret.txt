

Electronic Notes in Theoretical Computer Science 253 (2009) 45–71
www.elsevier.com/locate/entcs

On the Expressive Power of Schedulers in Distributed Probabilistic Systems
Sergio Giro1 ,2	P. R. D’Argenio1 ,3
FaMAF, UNC – CONICET
C´ordoba, Argentina

Abstract
In this paper, we consider several subclasses of distributed schedulers and we investigate the ability of these subclasses to attain worst-case probabilities.
Based on previous work, we consider the class of distributed schedulers, and we prove that randomization adds no extra power to distributed schedulers when trying to attain the supremum probability of any measurable set, thus showing that the subclass of deterministic schedulers suffices to attain the worst-case probability. Traditional schedulers are a particular case of distributed schedulers. So, since our result holds for any measurable set, our proof generalizes the well-known result that randomization adds no extra power to schedulers when trying to maximize the probability of an ω-regular language. However, non-Markovian schedulers are needed to attain supremum probabilities in distributed systems.
We develop another class of schedulers (the strongly distributed schedulers) that restricts the nondetermin- ism concerning the order in which components execute. We compare this class against previous approaches in the same direction, showing that our definition is an important contribution. For this class, we show that randomized and non-Markovian schedulers are needed to attain worst-case probabilities.
We also discuss the subclass of finite-memory schedulers, showing the intractability of the model checking problem for these schedulers.
Keywords: probabilistic systems, distributed systems


Introduction
Markov decision processes (MDPs) are widely used in diverse fields ranging from ecology to computer science. They are useful to model and analyse systems in which both probabilistic and nondeterministic choices interact. MDPs can be automati- cally analysed using quantitative model checkers such as PRISM [13] or LiQuor [7]. Since MDPs involve nondeterminism, the model checking problem is to find out the lowest probability of reaching a goal under any possible resolution of the nondeterministic choices, a concrete instance being “the probability of arrival of

1 Supported by ANPCyT project PICT 26135 and CONICET project PIP 6391.
2 Email: sgiro@famaf.unc.edu.ar
3 Email: dargenio@famaf.unc.edu.ar

1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.10.005

a package is above the bound 0.95 no matter how the package is routed”. The resolution of such nondeterminism is given by the so called schedulers (called also adversaries or policies –see e.g. [1,16]) which choose an enabled transition for each path of the system.
The available tools for model checking as PRISM [13] or LiQuor [7] calculate the worst-case probability considering all schedulers. However, in distributed systems, some schedulers correspond to unrealistic resolutions of the nondeterminism (as we illustrate below) thus resulting in overly pessimistic worst-case probabilities. A restricted class of schedulers was proposed to cope with this problem in previous literature –see e.g. [9,6,5,8,10]. We call these schedulers distributed schedulers, since in these settings there is a local scheduler for each component and so the resolution of the nondeterminism is distributed among the different components.
In this paper, we investigate different subclasses of distributed schedulers in or- der to answer to which extent these subclasses are able to attain the worst-case probability. The subclasses we consider are strongly related to the development of techniques for MDP analysis. As an example, if the class of all schedulers is consid- ered, worst-case probabilities of reachability properties are attained by schedulers that are both Markovian –i.e. the decision is based on the current state of the execution, disregarding the previous history– and deterministic –i.e. the schedulers themselves have no probabilistic choices, see [1]. The existence of this subclass en- sures that the worst-case probability can be found by exhaustive search 4 . Hence, one may like to know to which extent these results hold in case the schedulers are restricted to be distributed.

Unrealistic worst cases and distributed schedulers
A scheduler is a function mapping paths to transitions (or, in the more general case, paths to distributions on transitions). Given that the execution up to some state s is known (namely, the history path), the scheduler “chooses” to perform one transition out of all transitions enabled in state s.
The following example illustrates the problem that motivates the introduction of distributed schedulers: a man tosses a coin and another one has to guess heads or tails. Figure 1 depicts the models of these men in terms of MDPs. Man T , who tosses the coin, has only one transition which represents the toss of the coin:

with probability 1
he moves to state headsT and with probability 1
he moves to

state tailsT . Instead, man G has two possible transitions, each one representing his choice: headsG or tailsG. An almighty scheduler for this system may let G guess the correct answer with probability 1 according to the following sequence: first, it lets T toss the coin, and then it chooses for G the transition leading to heads if T tossed a head or the transition leading to tails if T tossed a tail. Therefore, the supremum probability of guessing obtained by quantifying over these almighty schedulers is 1, even if T is a smart player that always hides the outcome until G reveals his choice. As a consequence, quantitative model checkers based on [1], though safe, yield an

4 Although more efficient methods exist [1]

initT	initG
headsT	tailsT	headsG	tailsG
T	G
Fig. 1. T tosses a coin and G has to guess

overestimation of the correct value. In this example, in which T and G do not share all information, we would like that the supremum probability of guessing (i.e., of reaching any of the states (headsT , headsG) or (tailsT , tailsG)) is 1 .
This observation is fundamental in distributed systems in which components share little information with each other, as well as in security protocols, where the possibility of information hiding is a fundamental assumption [3]. The phenomenon we illustrated has been first observed in [16] from the point of view of composi- tionality and studied in [8,9,6] in different settings. Distributed schedulers are also related to the partial-information policies of [8].
In order to avoid considering these unrealistic behaviours, distributed schedulers were proposed in previous literature. Local schedulers for each component of the system are defined in the usual way (that is, the choices are based on the complete history of the component) and distributed schedulers are defined to be the schedulers that can be obtained by composing these local schedulers. We remark that the “almighty” scheduler of the example would not be a valid scheduler in this new setting since the choice for G depends only on information which is external to (and not observable by) G. Then, a local scheduler for G takes the decision having no information about the actual state of T , and so the choice cannot be changed according to the outcome of T .
Roughly speaking, in previous literature there is no nondeterminism concerning the different interleavings in which the components execute (for a detailed com- parison see Sec. 5). If we allow interleaving nondeterminism, the schedulers can also be restricted to handle this nondeterminism in a realistic way. So, we moti- vate a restriction to distributed schedulers in this direction, and define the strongly distributed schedulers as the schedulers complying with such restriction.
Contributions. The definition of strongly distributed schedulers we provide is the first one to capture the notion of partial information in asynchronous distributed systems in a general way, as discussed in Sec. 5.
As the familiar reader would expect, we found that Markovian schedulers fail to attain worst-case probabilities. Surprisingly, when considering strongly distributed schedulers, we found examples in which deterministic strongly distributed sched- ulers do not attain worst-case probabilities, that is, the schedulers that choose a distribution on the available transitions are more powerful than the schedulers that choose a single transition.
However, as an interesting result, we proved that deterministic distributed sched- ulers attain worst-case probabilities for any measurable property. Since traditional schedulers for MDPs are a particular case of distributed schedulers (just consider


	
A generative structure with two transitions	A reactive structure with two transitions
Fig. 2. Reactive and generative structures
a distributed system having only one component) we conclude that deterministic traditional schedulers attain extreme probabilities for any measurable set. In the setting of MDPs, this result has been proven only for ω-regular sets —see, e.g. [1,16]. As pointed out in [2], the generalization to measurable sets (only for the particu- lar case of total information schedulers) can also be derived from very non-trivial results in Borel games [14]. Our proof is, however, much simpler and suited to the MDP setting (and also valid for distributed schedulers).
The model checking problem considering only distributed schedulers has been proven to be undecidable in general [10]. So, one may think that undecidability can be overcome by restricting the schedulers to have finite memory. In this case, an obvious question is how much memory the scheduler should have in order to accurately approximate the worst-case value. We show that the amount of memory needed to get an approximation of the worst-case value cannot be calculated. In addition, we show that nondeterministic schedulers are more powerful than deter- ministic schedulers given a fixed amount of memory. We also show that the problem of calculating the worst-case value among all Markovian distributed schedulers is NP-hard.
We expect these results and these examples to be useful for further developments on model checking of distributed probabilistic systems.

Interleaved Probabilistic Input/Output Automata
We present a framework based on the Switched PIOA [6] (see Sec. 5 for a detailed comparison). It uses reactive and generative structures (see [12,18]). For a finite set S, we denote by Dist(S) the set of all the probability distributions over the set S. Given a set ActLab of action labels and a set St of states, the set of generative tran- sitions TG on (St, ActLab) is Dist(St × ActLab), and the set TR of reactive transitions is Dist(St). A generative structure on (St, ActLab) is a function G : St → P(TG) and a reactive structure on (St, ActLab) is a function R : St × ActLab → P(TR). Figure 2 depicts an example of these structures. Generative transitions model both communication and state change. The component executing a generative transition chooses both a label a to output (the ! indicates that the label is output) and a new state s according to a given distribution. Reactive transitions specify how a component reacts to a given input (the ? represents input). Since the input is not chosen, reactive transitions are simply distributions on states.
In our framework, a system is obtained by composing several probabilistic I/O atoms. Each atom is a probabilistic automaton having reactive and generative transitions.
Definition 2.1 A probabilistic I/O atom is a 5-tuple (St, ActLab, G, R, init), where

St is a finite set of states, ActLab is a finite set of actions labels, and G (R, resp.) is a generative (reactive, resp.) structure on (St, ActLab). init ∈ St is the initial state. We require the atoms to be input-enabled, so R(s, a) /= ∅ for every s ∈ St, a ∈ ActLab.

An interleaved probabilistic I/O system P is a set Atoms(P ) of probabilistic I/O atoms A1, ··· , AN . The set of states of the system is i Sti, and the initial state of the system is init = (init1, ··· , initN ). We often write Sti to denote the set of states of an atom Ai and similarly for the other elements of the 5-tuple. In addition, we write TGi (TRi , resp.) for the set of generative (reactive, resp.) transitions on (Sti, ActLabi).
In order to define how the system evolves, we define compound transitions, which are the transitions performed by the system as a whole. In such compound tran- sitions, all the atoms having the same action label in their alphabet must syn- chronize and exactly one of them must participate with an output (generative) transition (thus modelling multicasting). Formally, a compound transition is a tu- ple (gi, a, rj1 , ··· , rjm ) (we require i /= jk and jk /= jk' for all k /= k') where gi is a generative transition in the atom Ai (the active atom), a ∈ ActLabi is an action label, the rjk are reactive transitions in the atoms Ajk (the reactive atoms) and
{Ai, Aj1 , ··· , Ajm } is equal to the set {Aj | a ∈ ActLabj}. We say that Ai, Aj1 ,
. .., Ajm are the atoms involved in the compound transition. A compound tran- sition (gi, a, rj1 , ··· , rjm ) is enabled in a given state (s1, ··· , sN ) if gi ∈ Gi(si) and rjk ∈ Rjk (sjk , a). The action label a of a compound transition c is indi- cated by label(c). The probability c(s, s') of reaching a state s' = (s'1, ··· , s'N )
from a state (s1, ··· , sN ) using a compound transition c = (gi, a, rj1 , ··· , rjm ) is
gi(s', a) ·  m  rj (s' ) if st = s't for every atom not involved in the transition.
Otherwise, c(s, s')= 0.
In order to ease some definitions, we introduce a fictitious “stutter” compound transition ς. Intuitively, this transition is executed iff the system has reached a state in which no atom is able to generate a transition. The probability ς(s, s') of reaching s' from s using ς is 1, if s = s', or 0, otherwise.
A path σ of P is a sequence s1.c1.s2.c2 ··· cn−1.sn where each si is a (com- pound) state and each ci is a compound transition such that ci is enabled in si and c(si, si+1) > 0. A path can be finite or infinite. For a finite path σ as before, the set of extensions (denoted by [σ]) contains all the infinite paths starting with σ. We define last(σ)= sn and len(σ)= n.
In the following, we suppose that input-enabled atoms A1,... , AN are given, and we are considering the system P comprising all the atoms Ai. We call this system “the compound system”. The states (paths, resp.) of the compound system are called global states (global paths, resp.) and the states (paths, resp.) of each atom are called local states (local paths, resp.).

Schedulers
The probability of a set of executions depends on how the nondeterminism is re- solved. A scheduler transforms a nondeterministic choice into a probabilistic choice by assigning probabilities to the available transitions. Given a system and a sched- uler, the probability of a set of executions is completely determined.
In the usual MDP setting, schedulers assign probabilities to the available tran- sitions taking into account the complete history of the system, and hence history- dependent schedulers are defined as functions mapping paths to distributions on transitions. As we have seen it may be unrealistic to assume that the schedulers are able to see the full history of all the components in the system. In the following, we define a restricted class of schedulers in order to avoid considering unrealistic behaviours.

Distributed schedulers
In a distributed setting as the one we are introducing, different kinds of nonde- terministic choices need to be resolved. An atom needs a corresponding output scheduler to choose the next generative transition. In addition, it may be the case that many reactive transitions are enabled for a single label in the same atom. Hence, for each atom we need an input scheduler in order to choose a reactive tran- sition for each previous history and for each label. Output and input schedulers are able to make their decisions based only on the local history of the atom. So, we need the notion of projection.
Given a path σ, the projection σ[i] of the path σ over an atom Ai is defined inductively as follows: (1) (init1, ··· , initN )[i]= initi , (2) σ.c.s[i]= σ[i] if Ai is not involved in c, and (3) σ.c.s[i]= σ[i] .label(c).πi(s), otherwise (where πi denotes the i-th projection of a tuple). The set of all the projections of paths over an atom Ai is denoted by Proji(P ). We say that these projections are the local paths of Ai.
An output scheduler for the atom Ai is a function Θi : Proji(P ) → Dist(TGi ) such that, if Gi(last(σ[i])) /= ∅ then Θi(σ[i])(g) > 0 =⇒ g ∈ Gi(last(σ[i])). An input scheduler for an atom Ai is a function Υi : Proji(P ) × ActLabi → Dist(TRi )
s.t. Υi(σ[i] , a)(r) > 0 =⇒ r ∈ Ri(last(σ[i]), a). Note that, if the output scheduler
Θi fixes a generative transition for a given local path σ, then the actions in the generative transition can be executed in every global path whose projection to i is σ, since we require the atoms to be input-enabled.
We still need to resolve the nondeterministic choice concerning the next atom to perform an output. An interleaving scheduler is a map that probabilisti- cally chooses an active atom for each (global) history. This atom will be the next to execute a generative transition (this transition, in turn, is chosen ac- cording to the output scheduler). Formally, an interleaving scheduler is a func- tion f : Paths(P ) → Dist({1, ··· ,N }) such that, if there exists i such that Gi(last(σ[i])) /= ∅ (that is, if there is some atom being able to generate a transition) then f(σ)(i) > 0 =⇒ Gi(last(σ[i])) /= ∅. Note that, even if interleaving schedulers are unrestricted, compound schedulers for the compound system are still restricted,

since the local schedulers can only see the portion of the history corresponding to the component.
A scheduler for the compound system is obtained by the appropriate composition of the interleaving scheduler and the output and input schedulers of each atom.
Definition 3.1 Given an interleaving scheduler f, input schedulers Υi and output schedulers Θi for each atom i, the distributed scheduler η obtained by composing f, Θi and Υi is defined as:

η(σ)(gi, a, rk , ··· , rk
)= f(σ)(i) · Θi(σ[i])(gi) ·  m
Υk (σ[kj] , a)(rk )

where Akj are all the atoms such that a ∈ ActLabkj .
Usually, schedulers are defined to map into distributions on transitions. How- ever, it may be the case that  c η(σ)(c) > 1 for a distributed scheduler η. This is because action labels are not chosen by the scheduler (they are chosen by the generative transition). However, for every label a,  {c|label(c)=a} η(σ)(c)= 1.
The probability of the sets of the form [σ] is inductively defined as follows: the
probability Prη([init]) of the extensions of the initial state is 1. If there exists i s.t. Gi(last(σ)) /= ∅, then the probability Prη([σ.c.s]) is Prη(σ) · η(σ)(c) · c(last(σ), s). If there is no such i, then the system cannot generate any transition. In this case, we let Prη([σ.c.s]) = Prη([σ]) if c = ς and s = last(σ), or 0 otherwise.
Note that, if c = (gi, a, rj1 , ··· , rjm ), then η(σ)(c) · c(s, s') is
f(σ)(i) · Θi(σ[i])(gi) ·  m  Υj (σ[jk] , a)(rj ) · gi(s', a) ·  m  rj (s' ) ,

which implies  c,s' η(σ)(c) · c(last(σ), s') = 1. This probability can be extended to the least σ-field containing all the sets of extensions in the standard way. We say that the sets in such σ-field are measurable. Given a measurable set S, we are interested in the value supη Prη(S). By calculating this amount it can be answered, for instance, whether or not “the probability of a package loss is less then 0.05 no matter how the package is routed”. This property, in particular, is what we call a reachability property : we are interested in the set of paths in which some states are reached (namely, the states in which the package has been lost). Given a set U of states, we denote by Prη(reach(U )) the probability of reaching any state in U .
Strongly distributed schedulers
Distributed schedulers model the fact that components can only look at their local history to choose the next transition to perform. However, under distributed sched- ulers, it is still possible that the hidden state of a component affects the behaviour of an unrelated group of components.
We explain how this leak of information occurs using atoms depicted in Fig. 3. Consider the system P having atoms T , Z, A, B. In this system, T is a process that tosses a coin. For the labels h! and t! corresponding to heads and tails, we have h!, t! /∈ ActLabZ ∪ ActLabA ∪ ActLabB. So, according to this model, T keeps


initT


headsT	tailsT

T
a?, b?

initZ


headsZ	tailsZ
Z

initA
a! 


A

initB
 b!


B

initAB


AB

Fig. 3. Motivating strongly distributed schedulers

the outcome as a secret (coins whose output are assumed to be secrets can be found in probabilistic security protocols such as the solution to the dining cryptographers problem, see [4]). Atom Z models an attacker trying to guess the outcome of the coin. Atoms A and B are two processes that Z is able to observe.
Consider the maximum probability that attacker Z guesses the outcome (i.e. the probability that a state of the form (headsT , headsZ, ··· ) or (tailsT , tailsZ, ··· ) is reached). Since the attacker is able to see only the actions of A and B (and these atoms cannot, in turn, see the outcome of T ) the attacker has no information about T , and so the maximum probability should be 1/2. Unfortunately, there exists a distributed scheduler that yields probability 1: the interleaving scheduler chooses T in the first place, and then it chooses either (A and then B) or (B and then A), according to the outcome of the probabilistic transition. Finally, the interleaving scheduler chooses Z. The order in which a! and b! were output is part of the local history of Z, so the output scheduler for Z can always choose the transition agreeing with the outcome of the coin.
Note that the leak of information arises from the fact that the interleaving scheduler can look at the complete history of the system. In the following we derive restrictions on interleaving schedulers that prevent the leak presented above. Then, strongly distributed schedulers are defined as distributed schedulers whose interleaving scheduler complies with such condition.
In the example above, the state of T affects the execution of atoms A and B. Distributed schedulers were defined in such a way that the state of an atom cannot affect the execution of another atom. Note that, if we regard A and B as a single component AB, we end up in a situation very similar to the one depicted in Fig. 1: in the case in which the coin lands heads AB chooses to perform the transition a!, while in the other case it chooses to perform the transition b!. In fact, if we consider the system P ' such that Atoms(P ')= {T, Z, AB}, no output scheduler for AB can be defined in such a way that the order of execution of a! and b! depends on the outcome of T (since the outcome of T does not affect the state of AB). Then, there is no distributed scheduler for P ' that can simulate the behaviour in P in which Z guesses all the time. Therefore, we would like that the new scheduler works just like distributed schedulers would do when A and B are considered as a single atom. Let P be a compound system containing atoms A and B. Let AB be a single atom representing the composition of A and B and P ' another compound system such that Atoms(P ') =	Atoms(P ) \ {A, B}	∪ {AB}. In general, we want to restrict to interleaving schedulers such that, for every distributed scheduler η on P

complying to such restriction, there is a distributed scheduler η' on P ' that defines the same probabilistic behaviour.
To motivate the restriction, consider a scheduler for the system P with T , A
and B in Fig. 3. Consider a distributed scheduler η whose interleaving scheduler complies f(init)= ( 1 T + 2 A+ 1B). We seek a restriction on f s.t. it is possible to find
2	6	6
a distributed scheduler for P ' containing atoms T and AB in Fig. 3. When AB is in
state (initA, initB), the output scheduler ΘAB chooses a distribution on {a!, b!}. To respect the choice of f in P , it must hold that ΘAB(initAB)(a!) = 2·ΘAB(initAB)(b!), since, according to f, the probability of executing a! is twice the probability of executing b!. Then,
ΘAB(initAB)(a!) = 2	and	ΘAB(initAB)(b!) = 1 .	(1)
Suppose (initT , initA, initB) →t! (headsT , initA, initB) in P . The corresponding path in
P ' is (initT , initAB) →t! (headsT , initAB). Call both these paths σheads (ambiguity is resolved according to whether it is used in the context of P or P ').
Since σheads [AB]= initAB = (initT , initAB)[AB], we have that
ΘAB((initT , initAB)[AB])(a!) = ΘAB(σheads [AB])(a!) = ΘAB(initAB)(a!) = 2
and similarly for b!. Therefore ΘAB(σheads [AB])(a!) = 2ΘAB(σheads [AB])(b!). This relation has to be maintained in P by f(σheads). That is, whichever is the probabilistic choice in f(σheads) w.r.t. other atoms, the relation f(σheads)(a!) = 2 · f(σheads )(b!) has to be maintained.
This suggests that, in the general case, for two executions that cannot be dis-
tinguished by any of the two atoms A and B, the relative probabilities of choosing A over B (or B over A) should be the same. Or better stated: conditioned to the fact that the choice is between atoms A and B, the probability should be the same in two executions that cannot be distinguished by any of the two atoms.
Formally, given any two atoms A, B of a system P , for all σ, σ' s.t. σ[A]= σ'[A] and σ[B]= σ'[B], it must hold that


f(σ)(A)
=
f(σ)(A)+ f(σ)(B)
f(σ')(A)
f(σ')(A)+ f(σ')(B)
(2)

provided that f(σ)(A)+ f(σ)(B) /=0 and f(σ')(A)+ f(σ')(B) /= 0.
Definition 3.2 A scheduler η is strongly distributed iff η is distributed and equa- tion (2) holds on the interleaving scheduler f that defines η. The set of strongly distributed schedulers of P is denoted by SDist(P ).
We emphasize that strongly distributed schedulers are useful depending on the particular model under consideration. In case we are analysing an agreement pro- tocol and each atom models an independent node in a network, then the order in which nodes A and B execute cannot depend on information not available to none of

them, and so strongly distributed schedulers give more realistic worst-case probabil- ities. However, in case the interleaving scheduler represents an entity that is able to look at the whole state of the atoms (for instance, if the atoms represent processes running on the same computer, and the interleaving scheduler plays the role of the kernel scheduler), then the restriction above may rule out valid behaviours, and so general distributed schedulers should be considered.
The following theorem is the generalization of the fact that, for every strongly distributed scheduler η on P = {T, Z, A, B} as in Fig. 3 there is a distributed scheduler η' on P ' = {T, Z, AB} that defines the same probabilistic behaviour.
Theorem 3.3 Let P be a system such that A, B ∈ Atoms(P ). Consider the system P ' such that Atoms(P ') = Atoms(P ) \ {A, B} ∪ {AB}, where AB is the usual cross-product of A and B (as in, for instance, [5, p. 99]). Then, for every strongly distributed scheduler η for P, there exists a strongly distributed scheduler η' for P ' yielding the same probability distribution on paths as η.
Proof. We show that the condition imposed to the interleaving scheduler is suffi- cient to define an output scheduler for AB. Let σAB be a local path on AB, and let σ be a global path σ such that σ[AB]= σAB. Define
f(σ)(A)
ΘAB(σAB)(gA)= f(σ)(A)+ f(σ)(B) ΘA(σ[A]) .
Note that the condition imposed to f ensures that the particular σ chosen is not relevant. Let f' be the interleaving scheduler for PAB such that f'(σ)(AB) = f(σ)(A)+ f(σ)(B) and f'(σ)(C) = f(σ)(C) for any other atom C. We have to prove that the scheduler η' for PAB obtained from f' as interleaving scheduler and ΘAB as output scheduler for AB yields the same behaviour as the original scheduler η for P . To see this, note that for a path σ, the probability assigned to a generative transition gA of A is pσ,gA = f(σ)(A) · ΘA(σ[A])(gA). Multiplying and dividing by f(σ)(A)+ f(σ)(B) yields


pσ,gA
= f(σ)(A) + f(σ)(B)		f(σ)(A)	 Θ
(f(σ)(A) + f(σ)(B))  A

(σ[A])(gA

)  ,

which equals to f'(σ)(AB) · ΘAB(σ[AB])(gA), that is, the probability of pσ,gA in η'. The same reasoning allows to conclude a similar equality if atom B is considered instead of A. The input, output, and interleaving schedulers do not change in all other cases.	 
One may wonder what happens if, instead of considering two atoms A and B in (2), two disjoint sets A, B of atoms are considered. The (apparently more general) condition on sets holds whenever condition (2) on atom holds.
Theorem 3.4 Let A = {A1, ··· , An}, B = {B1, ··· , Bm} be disjoint sets of atoms.

Then, if Eqn. 2 holds, then P
Pi I(σP)(Ai)
= P	Pi I(σ')(Ai)
holds

i I(σ)(Ai)+  j I(σ)(Bj )	i I(σ')(Ai)+Pj I(σ')(Bj )
whenever σ[A]= σ'[A] for all A ∈A ∪ B and Σi f(σ')(Ai)+ Σj f(σ')(Bj) /= 0.

Proof. By induction on n. We prove the base case n = 1 by induction on m. If m = 1, the statement becomes Eqn. 2. For the inductive step, we need a preliminary equality. Note that, if f(σ)(A) /= 0 and f(σ')(A) /= 0 in Eqn. 2, then simple arithmetic gives

f(σ)(B)


f(σ)(A)
f(σ')(B)
=
f(σ')(A)
.	(3)

The inductive step is

	f(σ)(A1)		f(σ')(A1)
f(σ)(A )+ Σ f(σ)(B ) = f(σ')(A )+ Σ f(σ')(B ) .

First, we prove the case f(σ)(A1) = 0. In this case, either f(σ)(Bj) = 0 for all j (in this case the condition f(σ)(A1)+  j f(σ)(Bj) /= 0 is false, then the equation is not required to hold) or f(σ')(A1) = 0. To see this, suppose towards the contradiction that f(σ')(A1) /= 0. Then, by Eqn. 2 it must be


	f(σ)(A1)	
=
f(σ)(A1)+ f(σ)(Bj∗ )
f(σ')(A1)
f(σ')(A1)+ f(σ')(Bj∗ )


where j∗ is an index such that f(σ)(Bj∗ ) > 0 (we don’t need f(σ')(Bj∗ ) /= 0, since f(σ')(A1) /= 0). So, since f(σ)(A1) = 0 then it must be f(σ')(A1)= 0, thus reaching a contradiction. Therefore, the inductive step holds in case f(σ)(Ai)= 0. If f(σ)(A1) /= 0, then either f(σ')(A1)=0 and f(σ')(Bj) = 0 for all j (and so the condition is not required to hold) or f(σ')(A1) /= 0, and so we can use Eqn. 3
in the following calculation.

I(σP)(A1)
I(σ)(A1)+ j I(σ)(Bj )
= {Arithmetics}

I(σ)(Bm ) +
I(σ)(A1)
= {Equation 3}

j=1	j
I(σ)(A1)

'	I(σ)(A1)+Pm−1 I(σ)(B )  −1
I(σ')(A1)	I(σ)(A1)
= {Inductive hypothesis}
'	I(σ')(A1)+Pm−1 I(σ')(B )  −1

I(σ')(A1)
= {Arithmetics}
'
I(σ')(A1)+Pj I(σ')(Bj )
I(σ')(A1)

Then, the statement holds for n = 1. For the remaining inductive step, we calculate:
P	Pi I(σP)(Ai)
i I(σ)(Ai)+  j I(σ)(Bj )
Pn−1 I(σ)(A )+I(σ)(An )

= Pn−1
i=1	P

=1  (σ)(Ai)+ (σ)(An)+
Pn−1 I(σ)(A )
j I(σ)(Bj )
	I(σ)(A )	

= Pn−1
i=1	P
+ Pn−1	P

i=1 I(σ)(Ai)+I(σ)(An)+
j I(σ)(Bj )
i=1 I(σ)(Ai)+I(σ)(An)+
j I(σ)(Bj )

= {Inductive hypothesis for {Ai}n−1, An ∪ {Bj}m }

Pn−1 I(σ')(A )
i=1
j=1
	I(σ)(A  )	

= Pn−1
i=1	P
+ Pn−1	P

i=1 I(σ')(Ai)+I(σ')(An)+
j I(σ')(Bj )
i=1 I(σ)(Ai)+I(σ)(An )+
j I(σ)(Bj )

= {Base case with {An}, {Bi}m
Pn−1 I(σ')(A )
∪ {Ai}n−1}


I(σ')(A  )

= Pn−1
i=1	P
+ Pn−1	P

i=1 I(σ')(Ai)+I(σ')(An)+
j I(σ')(Bj )
i=1 I(σ')(Ai)+I(σ')(An)+
j I(σ')(Bj )


Subclasses of distributed schedulers
Next, we discuss the expressive power of several subclasses of distributed schedulers.
Deterministic schedulers
We defined schedulers so that they map into distributions on transitions. We say that a scheduler is deterministic if all the choices in all the input (output, inter- leaving, resp.) schedulers choose a reactive transition (generative transition, atom, resp.) with probability 1. That is, Υi(σi, a)(ri) > 0 =⇒ Υi(σi, a)(ri) = 1 (and similarly for output and interleaving schedulers).
Given a deterministic output scheduler Θ we write Θ(σ) = g to indicate that Θ(σ)(g) = 1, and similarly for input and interleaving schedulers.
In the following, we investigate to which extent we can restrict to deterministic schedulers in order to get worst-case probabilities. Fortunately, for every system P , the class of deterministic distributed schedulers (denoted by DetDist(P )) is equally expressive as the class of all distributed schedulers (denoted by Dist(P )) if we aim to find the supremum (or infimum) probability of a given measurable set of infinite paths.
Theorem 4.1 For any set S of inﬁnite traces, S being measurable, we have that


sup
η∈DetDist(P )
Prη(S)=	sup
η∈Dist(P )
Prη(S)

The proof of this theorem is very long and so we split it in several lemmata.
First, we need some elements from probability theory. These definitions and the proofs not given here can be found at [17].
Definition 4.2 Given a set Σ, a semi-ring is a set S ⊆ P(Σ) complying:
∅∈ S,

A, B ∈S =⇒ A ∩ B ∈ S,
n i=1

Ai.

A ring is a set R⊆ P(Σ) complying:
∅∈ R,
A, B ∈R =⇒ A ∪ B ∈ S,
A, B ∈S =⇒ A \ B ∈ S.
The ring R(S) generated by a semi-ring S is the least ring containing S.
It can be proven that each element in the ring generated by a semi-ring S is of
the form  n	Ai with Ai ∈ S. The set of whose elements are all the sets [σ] forms
a semi-ring. In the following, we denote this semi-ring by S, while R denotes the ring generated by S.
The following lemma states that the probability of any measurable set can be approximated as the probability of a countable disjoint union of sets of extensions.
Lemma 4.3 Let Cω be the set
{ {Ai}i∞=1 | ∀i, j, i /= j • Ai ∈S ∧ Ai ∩ Aj = ∅} .
For every measurable set of inﬁnite paths S, we have

Prη(S)=	infU
Σ Prη(A) .

{C∈Cω |S⊆
A∈C A}
A∈C

Proof. An R-cover of a set S is a set {Bi}i∞=1 where Bi ∈R and S ⊆ n∞=1 Bi. Let P(S) be the set of all the R-covers of S. The probability of a measurable set S in the σ-algebra generated by the semi-ring S can be defined as


inf


Σ∞ Prη(B )


(see [17]). Given an R-cover {Bi} for S where each Bi is of the form  ni  Ai , we
define an element C in Cω as follows: A ∈ C iff A = Ai for some i,k and there is
k
i'	i	i'
no Ak' such that Ak ⊂ Ak' . Since our semi-ring is the set of extension sets, in the
construction of C we dropped the extensions [σ'] such that there exists [σ] with σ
being a prefix of σ'. Then, we have


Σ∞ Prη(B )= Σ∞
ni
Prη(Ai ) ≥
Σ Prη(A)

n=1
i=1 k=0
A∈C

In addition, C is an R-cover of S, since in the construction of C we only dropped sets of extensions included in other sets of extensions.
So, for each R-cover we found another R-cover in Cω yielding less or equal probability, thus completing the proof.	 

The following lemma concerns the infimum probability of “finite-horizon” prop-
erties of the form  n  [σi]. Note that the only choices affecting such probability
are the choices for the paths having length less than N = maxi{len(σi)}.

Lemma 4.4 For all sequences of ﬁnite paths {σi}n
such that [σi] ∩ [σj] = ∅ for

all i /= j, there exists a deterministic distributed scheduler ηd such that


Prηd


(  [σi]) =	inf
Prη(


  [σi]) .

i=1
η∈Dist(P )
i=1

Proof. Similarly as in Lemma 3 in [10], given any distributed scheduler η and any local path σ∗ we obtain a deterministic distributed scheduler det(η, σ∗) such that η chooses deterministically for σ∗ and det(η, σ∗) yields less probability than η.  In order to obtain the deterministic scheduler ηd, we successively trans- form η to choose deterministically for all the local paths whose length is less than N , where N = maxi{len(σi)}. That is, we consider the scheduler ηN = det(det(··· det(η, σ1), ··· ), σN ), where σ1 ··· σN are all the local paths whose length is less than N . Given the scheduler ηN , we consider each local path of length greater than or equal to N , and for these paths we define the new scheduler ηd to determin- istically choose a transition (the particular transition chosen is not relevant, since
the choices for paths of length greater than or equal to N do not affect the value of
ηd  n
The existence of such ηd ensures that the infimum quantifying over deterministic schedulers is less than or equal to the infimum quantifying over possibly nondeter- ministic schedulers. In addition, we conclude that there exists a scheduler yielding the infimum probability, since there are only finitely many combinations of deter- ministic choices for the paths of length less than N .
The only difference with respect to the proof in [10] is that the choices must be made deterministic for every local path and for every input and output scheduler. In addition, the choices must be made deterministic for the interleaving scheduler, by considering every global path.
In order to show that our input/output mechanism does not introduce any issue, we illustrate how to transform the choices for the input schedulers by mimicking the proof in [10]. In the proof, we manipulate finite paths. In order to do this, for a path σ = s1.c1. ··· .cn−1.sn we define σ(i) = si and σ⟨i⟩ = ci. In addition σ↓i= s1.c1 ··· ci−1.si, last(σ)= sn and len(σ)= n.
Let σ∗ be a path of an atom Ai and let a ∈ ActLabi. We show how to make the choice deterministic for the input scheduler of Ai when a occurs in σ∗. Let rσ∗ be
the set of all the paths in {σi}n	such that “a occurs in σ∗”, that is, there exists
kσ such that σ↓kσ [Ai]= σ∗ and label(σ⟨kσ⟩)= a. The probabilities of the paths in rσ∗ are the only ones to be changed, since we are only changing Υi(σ∗, a). So, we show only that, for this set, the scheduler in which the choice is deterministic yields a probability less than or equal to the probability yielded by the original scheduler.

Let Agσ
be the atom that generates the output a in σ↓kσ
and gσ be the corre-

sponding generative transition. Let rσ be the reactive transition executed by Aj

when a occurs in σ in the kσ-th step. We will focus on Υi(σ∗, a). The probability of a path σ in rσ∗ is Υi(σ∗, a) · rσ(σ(kσ + 1)) · Qσ, where

Qσ = Prη([σ↓k ]) · f(σ↓k )(Ag ) · Θg (σ↓k [gσ])(gσ)

·  w∈{1,··· ,m}\{i}
Υjw
(σ↓kσ
[jw] , a)(rσ )

gσ(πg
 
(σ(kσ + 1)), a)
rσ (πj

(σ(kσ + 1)))

len(σ)−1 η(σ↓t)(σ⟨t⟩) · σ⟨t⟩(σ(t), σ(t + 1))

Now, we calculate,


Σσ∈rσ∗
Prη([σ])

= {Definition of probabilities for extensions}
Σ	rσ( πi(σ(kσ + 1)) ) Υi(σ∗)(rσ) Qσ
= {Rearrange sums}

Σ  Σ Σ	σ
rσ( πi(σ(kσ + 1)) ) Υi(σ∗)(rσ) Qσ

= {Rearrange sums}
Σri Σs Σ{σ∈rσ∗ |rσ=ri∧πi(σ(kσ +1))=s} ri(s) Υi(σ∗)(ri) Qσ
= Σri Υi(σ∗)(ri) Σs ri(s) Σ{σ∈rσ∗ |rσ=ri∧πi(σ(kσ +1))=s} Qσ


Let

r∗ = arg min	ri(s)
ri

Qσ .

s
Since Σri Υi(σ∗)(ri)= 1, we have
{σ∈rσ∗ |rσ=ri∧πi(σ(kσ +1))=s}

Σ Prη([σ]) ≥ Σ r∗(s)	Σ

Qσ ,

σ∈rσ∗
s	{σ∈rσ∗ |rσ=r∗∧πi(σ(kσ +1))=s}

which is the probability using the scheduler det(η) that mimics η except for Υi. The input scheduler for Ai in det(η) chooses Υ'i(σ∗, a)(r∗)= 1.
The choices for the output schedulers can be made deterministic in an easier way (since labels need not be considered).
With respect to the interleaving scheduler, let σ∗ be a path of the system of length less than N . Let rσ∗ be the set of all the paths σi having σ∗ as suffix. Let k = len(σ∗). As before, for every σ ∈ rσ∗ , let gσ be the atom that performs an output in the k-th step, and gσ be the corresponding generative transition. Moreover, let aσ be the label after the k-th step in σ and let rj be the reactive transition executed

by Aj after the k-th step. Let

Qσ = Prη([σ↓k]) · 




w∈{1,··· ,m}




Υjw



(σ↓kσ



[jw] , a)(rjw )

·   w∈{1,··· ,m} rjw (πjw (σ(kσ + 1)))
·  len(σ)−1 η(σ↓t)(σ⟨t⟩) σ⟨t⟩(σ(t), σ(t + 1)) Then, we proceed similarly as before:

Σσ∈rσ∗
= Σ
Prη([σ])
f(σ∗)(Ag

) Θg

(σ↓k[gσ])(gσ) gσ(πA

(σ(k + 1)), aσ) Qσ

σ∈rσ∗	σ	σ	gσ
=
ΣAi Σσi,gi Σsi,a
Σ{σ∈rσ∗ |Agσ =Ai∧σ↓k[i]=σi∧πAi (σ(k+1))=si∧gσ=gi∧aσ=a}

f(σ∗)(Agσ
=
ΣAi Σσi,gi Σsi,a
) Θgσ
(σ↓k[Agσ
])(gσ) gσ(πA
(σ(k + 1)), aσ) Qσ

Σ{σ∈rσ∗ |Agσ =Ai∧σ↓k[i]=σi∧πAi (σ(k+1))=si∧gσ=gi∧aσ=a}
f(σ∗)(Ai)  Θgi (σ↓k[Ai])(gi) gi(πAi (s), a) Qσ
=
ΣAi f(σ∗)(Ai) Σσi,gi Θi(σi)(gi) Σsi,a gi(si, a)
Qσ
{σ∈rσ∗ |Agσ =Ai∧σ↓k[i]=σi∧πAgσ (σ(k+1))=si∧g  =gi∧aσ=a}
As before, we take
Ai∗ = arg min Σ Θi(σi)(gi) Σ gi(si, a)

i  i	i
Σ	Qσ

{σ∈rσ∗ |gσ=i∧σ↓k[i]=σi∧πgσ (σ(k+1))=si∧gσ=gi∧aσ=a}
and define f'(σ)= Ai∗ .	 
For convenience, sometimes we denote a deterministic scheduler η as a function mapping global paths to n-tuples of the form (gi, f1, ··· , fN ), where fj : ActLabj → TRj (recall Def. 2.1). Each n-tuple of the form (gi, f1, ··· , fi−1, fi+1, ··· , fN ) corre- sponds to several compound transitions: namely, there is one compound transition for each label in ActLabi. Given an n-tuple as before and a label a, we obtain the compound transition (gi, a, fr1 (a), ··· , frk (a)), where r1, ··· , rk are the atoms that

react to a. Concretely, if η is obtained by composing f, Θ1, ··· , ΘN , Υ1, ··· , ΥN we write η(σ) = (gi, f1, ··· , fi−1, fi+1, ··· , fN ) iff f(σ) = i and Θi(σ[i]) = gi and, for all a, j such that a ∈ ActLabj, we have Υj(σ[j] , a)= fj(a).
Note that a function η mapping histories to n-tuples is not necessarily a dis- tributed scheduler. In general, we call these functions arbitrary schedulers. Given an arbitrary scheduler η, η is a distributed scheduler iff for all i, σ, σ' s.t. σ[i]= σ'[i],
η(σ) = (gi, f1, ··· , fN ) implies that η(σ') is of the form (gi, f1' , ··· , fN' ) and
η(σ)= (gj, ··· , fi, ··· ) implies that η(σ') is of the form (gj' ' , ··· , fi, ··· ). Since we focus on distributed schedulers, schedulers are supposed to be distributed, except
when stated otherwise.
The following lemma concerns “infinite-horizon” properties of the form i∞=1[σi], and shows how to construct an optimal scheduler for such properties using optimal schedulers for the “finite-horizon” approximations of i∞=1[σi]. This optimal sched- uler will be used in the proof of Theorem 4.1. Our construction resembles the “limit construction” in [5, Sec. 4.3].
Lemma 4.5 For all sequences of ﬁnite paths {σi}i∞=1 such that [σi] ∩[σj]= ∅ let SN be the set {[σi] | len(σi) ≤ N }. If there exists a sequence {ηN }N∞=1 of deterministic schedulers such that, for all N,
PrηN (SN )= inf Prη(SN )
η

then there exists a deterministic arbitrary scheduler ηd such that (1) for all N
there exists N ' > N such that ηd(σ) = ηN' (σ) for all path σ s.t. len(σ) ≤ N and
(2) ηd = infη Prη(  i[σi]).
Proof. In order to construct ηd, we will construct a sequence of schedulers
{ηN }N∞=0. Then, we simply define ηd(σ) = ηlen(σ)(σ). The idea behind the con- struction of the schedulers ηN is that ηN must comply the following property: there

exists a sequence {ZN }∞
(the {·}∞
indicates that the sequence is indexed by i)

such that
i	i=1
i=1

ηN (σ)= η N (σ)	(4)
i

for all σ having length less than or equal to N , for all i.
The scheduler η0 is simply η1. The sequence {Z0} is the sequence {i}∞
. It

i	i=1
trivially complies with (4), since there are no paths of length 0 (init has length 1).
In order to construct the scheduler ηN from the scheduler ηN−1, we define sched- ulers ηN−1,Q, where Q is a set of paths of length N . In addition, each scheduler
ηN−1,Q has a corresponding sequence {ZN−1,Q}∞ . Once these schedulers are de-
i	i=1
fined, we define ηN = ηN−1,QN  and ZN = ZN−1,QN , where QN is the set of all
paths of length N . We will construct the schedulers ηN−1,Q in such a way that
ηN,Q(σ) = η N,Q (σ) for all σ such that σ ∈ Q or len(σ) ≤ N − 1. The scheduler
Zi
ηN,{} is ηN−1. Now, we show how to construct ηN,Q∪{σ∗} from ηN,Q.
We consider the sequence {η N,Q (σ∗)}i∞=1. In this sequence, at least one ele-
i
ment a∗ is repeated infinitely many times.  We let ηN,Q∪{σ∗}(σ∗) = a∗, and let

ZN,Q∪{σ∗} be the infinite subsequence of ZN,Q complying with η	∗ (σ∗)= a∗
ZN,Q∪{σ  }
(this infinite subsequence is ensured to exist since a∗ appears infinitely many times in {η N,Q (σ∗)}i∞=1).
i
Now, we prove the properties for ηd enounced in the theorem.
Given any N , we take any N ' in the sequence ZN such that N ' > N . So, the property for ηd is implied by the property (4) for ηN .

Suppose, towards a contradiction, that Prηd (  σ ) > inf Prη( 
i  i	η
i σi). Since

Prηd (  σ )= Σ Prη (σ ), there exists N such that
i  i	i	i

ηd	η 

Let N ' > N such that ηd(σ) = ηN' (σ) for all paths σ such that len(σ) ≤ N
(its existence is ensured by the previous property) and let ηinf be such that

Prηinf ( 
ηd   {[σ ] | len(σ ) ≤ N }) (its existence is ensured because

of (5)). Now, we reason

Prηd


(  {[σi] | len(σi) ≤ N })




In addition,
ηd
= PrηN' (  {[σi] | len(σi) ≤ N })
≤ PrηN' (  {[σi] | len(σi) ≤ N '}) .
(6)

> Prηinf (  σ )
i
≥ Prηinf ( {[σ ] | len(σ ) ≤ N '})
≥ {Optimality condition for ηN' (see theorem statement)} PrηN' ( {[σi] | len(σi) ≤ N '}) .
This contradicts (6).

The following lemma simply combines Lemma 4.4 and Lemma 4.5 in order to show that deterministic schedulers are sufficient to obtain the infimum probability of an “infinite-horizon” property as before.
Lemma 4.6 For all sequences of ﬁnite paths S = {σi}i∞=1 s.t.  [σi] ∩ [σj] = ∅
for all i /= j, there exists a deterministic distributed scheduler η∗ such that

Prη∗
(  {σ∈S}[σ]) = infη∈
Dist(P )
Prη( 
{σ∈S}[σ]).

Proof. For each n, Lemma 4.4 ensures the existence of a deterministic distributed scheduler ηn such that Prηn (  {σ∈S}[σ]) = infη∈Dist(P ) Prη(  {σ∈S|len(σ )≤n}[σ]) .

Then, Lemma 4.5 ensures the existence of an arbitrary scheduler ηd such that
ηd = inf Prη(	[σ]).
i
Now, we prove that this arbitrary scheduler is indeed distributed. Suppose, towards a contradiction, that there exist two paths σ, σ' and an atom Ai complying σ[i]= σ'[i] such that
ηd(σ)= (gi, f1, ··· , fN ) and ηd(σ')= (gi' , f1' , ··· , fN' ) with gi /= gi'. Or
ηd(σ)= (gj, ··· , fi, ··· ) and ηd(σ')= (gj' , ··· , fi', ··· ) with fi /= fi'.
Let M = max{len(σ), len(σ')}. Then, by Lemma 4.5 there exists M ' > M such that ηM' (σ) = ηd(σ) and ηM' (σ') = ηd(σ'). Therefore, ηM' would not be distributed, contradicting the hypothesis for the schedulers ηn.	 
Proof. [of Theorem 4.1] Given ϵ > 0, we will find a deterministic distributed ηd
η	ηd
such that supη∈Dist(P ) Pr (S) − Pr (S) < ϵ.
We use CS to denote the complement of the set S.
s
Let ηs be such that supη∈Dist(P ) Prη(S) −Prη (S) < ϵ/2. By Lemma 4.3 (applied
to the complement of CS), there exists a sequence {[σi]}i∞=1 of disjoint extensions sets such that (CS) ⊆  i[σi] and

ηs	ηs

By Lemma 4.6, there exists a deterministic distributed scheduler ηd such that
Prηd (  [σ ]) = inf	Prη(  [σ ]). In particular, Prηd (  [σ ]) ≤ Prη (  σ ).
i  i	η∈Dist(P )	i  i	i  i
Therefore, from (7) we have
ηd	ηs

Pr (	[σi]) − Pr
i
From which we obtain
(CS) < ϵ/2 .

1 − Prηd (C  [σ ]) − (1 −
Prηs
(S)) < ϵ/2 ,

i
this inequation being equivalent to
ηs	ηd

Since CS ⊆  [σ ] we have that C  [σ ] ⊆ S. So, Prηd (C  [σ ]) ≤	ηd
(8) we obtain Pr (S) − Pr (S) < ϵ/2. Then,

d	s	s	d
Pr (S)= sup Pr (S)	Pr (S)+ Pr (S)	Pr  (S) < ϵ/2+ ϵ/2= ϵ . 
η	η


Unfortunately, if in the statement of Theorem 4.1 we consider strongly distributed schedulers the same claim is false. Consider the example in Fig. 4. Atoms A, B




eA !

E
A	B	C






R
Fig. 4. Example showing that randomization adds power to strongly distributed schedulers

and C need to be “activated” by labels eA, eB and eC , respectively. The atom E tosses a coin and activates A, B and C if the output of the coin is l, or B and C if the output of the coin is r. The atom R “remembers” the order in which the other atoms execute. The objective of the scheduler is to reach some state in R marked with a smile. It is clear that any deterministic scheduler yields a probability of 0, 1/2 or 1. Let’s see if there exists a deterministic strongly distributed scheduler η reaching a smile with probability 1. In order to yield a probability of 1, η must reach a smile for both l and r. In order to succeed in case the first output is l, η must choose the transitions whose outputs are ea, eb and ec. Then, η should choose either a, b and c (in this order) or b, a and c. In order to succeed when r is chosen, η must choose the transitions whose outputs are eb and ec. Note that the projections of atoms A and B after r, eb and ec are the same as the projections after l, ea, eb and ec. Since b must be chosen before c in case the first output is l, and η is strongly distributed, then η must choose b before c in case the first output is r. After B, R should output w, and E should output eA. At this point, both A and C are activated, and the projections of these atoms are the same as in case the first output is l. Since η is strongly distributed and a must be chosen before c in case the first output is l, a must be chosen before c also when the first output is r. However, choosing a before c does not lead to a state marked with a smile. Hence, there is no deterministic strongly distributed scheduler yielding probability 1, and so the supremum quantifying over deterministic strongly distributed schedulers is 1/2. Nevertheless, consider the scheduler in which (1) If there is a transition enabled in E, then the transition in E is chosen (i.e. the interleaving scheduler chooses a Dirac distribution on E) (2) If there is a transition enabled in R, then the transition in R is chosen (note that it cannot be the case that there are transitions enabled in both E and R) (3) If there are neither transitions enabled in E nor in R, then the scheduler chooses uniformly among the transitions a, b and c. That is, if a, b and c are enabled, choose each one with probability 1/3, and, if b and c are enabled, choose each one with probability 1/2. This scheduler is strongly distributed, and yields a probability of 13/24 > 1/2. Therefore, this example shows that randomized choices add power to strongly distributed schedulers.

The same example can be used to show that there are systems for which deter- ministic strongly distributed schedulers cannot emulate the rate schedulers in [11] (rate schedulers yielding probabilities arbitrarily close to 13/24 can be obtained by replacing arbitrarily high rates for the Dirac distributions and equal rates for the uniform distributions).

On the (in)existence of a scheduler yielding the supremum probability
For traditional almighty schedulers, for every reachability property there exists a Markovian deterministic scheduler attaining the supremum probability. Consider the system comprising atoms T and G in Fig. 5 (initial states are enclosed in circles). For this system, we show that there is no distributed scheduler maximizing the probability of reaching sw. The behaviour of this system can be seen as a game: T tosses a coin without communicating the outcome to G, but communicating that the coin has been tossed (this is represented by t!). Atom T moves to state s2 once the coin lands tails. Atom G can stop the game. The aim of G is to stop the game only if the coin has landed tails at least once. If G outputs n, then the coin is tossed again and the game continues. If G believes that the coin has landed tails sometime before, then it outputs g. If T is in state s2 and G outputs g, then the objective state sw is reached. Otherwise, if T receives g in state s1, the undesirable state sl is reached. Let’s see what the supremum probability of reaching sw is. If G waits for one t before communicating g, then the probability of reaching sw is 1/2. However, G may be smarter and wait for two t’s, thus having a probability of 3/4. In general, waiting for k t’s yields a probability of 1 − (1/2)k. In addition, it is easy to see that there is no nondeterministic scheduler yielding probability 1. In conclusion, although the supremum is 1, there is no scheduler yielding such probability.

Finite-memory (and Markovian) schedulers
A scheduler is Markovian if it chooses the next transition according to the last state, regardless of the past history. In case traditional all-seing schedulers are considered, Markovian schedulers attain the supremum probability for reachability properties [1].
In our setting, one may think of two types of Markovian schedulers: a globally Markovian scheduler should comply η(σ)(c)= η(σ')(c) whenever last(σ)= last(σ'), while a locally Markovian scheduler should choose the same local transitions when- ever the local states coincide. In order to define locally Markovian schedulers, we say that an input scheduler is Markovian iff, for all a, r, it holds Υ(σ, a)(r)= Υ(σ', a)(r) whenever last(σ) = last(σ'). Similarly, Markovian output schedulers can be de- fined. An interleaving scheduler is Markovian iff f(σ)(A) = f(σ')(A) whenever last(σ) = last(σ'). We say that a scheduler is locally Markovian if it can be ob- tained by composing Markovian schedulers. Markovian schedulers are a particular case of a more general class: the N -Markovian schedulers. A scheduler is glob- ally N -Markovian if η(σ σ') = η(σ') for all σ' of length N . Note that globally Markovian schedulers coincide with globally 1-Markovian schedulers. Similarly, lo-

l!	0.01







T


n! t? g!
G




r!

A	B



s2	s2

'
B

Fig. 5. Atoms used in our examples
cally N -Markovian schedulers can be defined. A simple example shows that locally Markovian schedulers do not attain supremum probabilities. Consider the system comprising atoms A and B in Fig. 5. First, we consider deterministic schedulers. A deterministic locally Markovian scheduler must output the same label in every path. So, if we quantify over deterministic locally Markovian schedulers, the supre- mum probability of reaching a smile is 0. The supremum quantifying over locally Markovian schedulers is 0.25, and is obtained by the scheduler that chooses l! with probability 0.5 and r! with probability 0.5 for all σ. This implies that given a ﬁxed amount of memory N, randomization adds power to N-Markovian schedulers.
For the same example, note that globally Markovian schedulers obtain proba- bility 1. However, in the following we use atoms A and B' in Fig. 5 to show an unnatural aspect of globally Markovian schedulers. Again, the aim of the scheduler is to reach a smile. Consider any deterministic globally Markovian scheduler η. In the initial state (s, s0), atom A must output l. The label l must also be output in the path (s, s0).l!.(s, s0), since the scheduler is globally Markovian. Then, we have ΘA( (s.l!.s)) = l!. This implies that l is also output in the path (s, s0).l!.(s, s1). The same reasoning allows to conclude that ΘA(σ)= l! for every A-path σ. So, the existence of the loop in s0 implies that the choices of the scheduler should coincide for every path. In conclusion, although the system comprising atoms A and B is very similar to the system comprising atoms A, B', the power of globally Markovian schedulers is significantly different.
We say that a scheduler has local (global, resp.)  finite memory if it is locally (globally, resp.)  N -Markovian for some N .  We denote the lo- cal (global, resp.) finite-memory distributed schedulers of a system P by LFinMem(P ) (GFinMem(P ), resp.) and the deterministic finite-memory schedulers by DetLFinMem(P ) (DetGFinMem(P ), resp.) We illustrate the limitations of finite- memory schedulers using atom A in Fig. 5. Suppose that we are interested in the probability of the path having the sequence of labels lrlrrlrrr ··· , that is, each l is followed by a sequence of r’s, and the amount of r’s is exactly the previous amount plus 1. There are no finite-memory schedulers yielding probabilities arbitrarily close to 1 for this path. Intuitively, an optimal scheduler should remember how much r’s were in the previous sequence, and the amount of r’s grows arbitrarily. (Note that, since we are considering a single atom, local finite-memory schedulers and global finite-memory schedulers coincide.)
We have seen that locally Markovian schedulers cannot attain worst-case proba- bilities even for simple reachability properties, and we have seen that finite-memory schedulers do not attain optimal probabilities for every property. However, if we

consider only reachability properties, we obtain the following theorem.
Theorem 4.7  ∀U : supη∈Dist(P ) Prη(reach(U )) =supη∈DetLFinMem(P ) Prη(reach(U )) .
Proof. Given, ϵ > 0, let ηs be a scheduler such that supη Dist(P ) Prη(reach(U )) −
ηs
Pr (reach(U )) < ϵ/2. We denote the set of paths that reach some element in

U before the N -th step as reachN
ηs
(U ). Let N ∗
be such that Prηs
(reach(U )) −

Pr (reachN∗ (U )) < ϵ. The set reachN∗ can be written as a disjoint union of set
of extensions [σk] where the length of the σk is at most N ∗. Then, by Lemma 4.4,
we know that there exists a deterministic scheduler ηd yielding the supremum
probability for reachN∗ .	Let Θd, Υd and fd be the schedulers that define ηd.
i	i
Then, we can consider the (uniquely defined) N ∗-Markovian schedulers Θm, Υm
i	i
and fm that coincide with the schedulers for ηd upto the N ∗.	The sched-
uler ηm obtained by composing Θm, Υm and fm is N ∗-Markovian, and it holds
ηm	ηs i	i

supη∈Dist(P ) Pr
(reach(U )) − Pr (reach(U )) < ϵ.	 

The statement of Theorem 4.7 is false in case strongly distributed schedulers are considered: the example in Fig. 4 is also a counterexample for such a statement. Theorem 4.7 can also be contrasted with the fact that, given a fixed amount of memory, nondeterministic schedulers are needed.
The probabilistic model checking problem has been proven to be undecidable in case the schedulers are restricted to be distributed [10]. Theorem 4.7 shows that the problem is still undecidable if we restrict to finite-memory schedulers. Moreover, if we want to restrict to deterministic schedulers having at most N memory, the amount of memory N needed in order to get an accurate approximation of the probability cannot be calculated. Formally, let DetLFinMemN (P ) be the set of deterministic locally N -Markovian schedulers for P . Then:
Theorem 4.8 Given ϵ  >  0, there is no algorithm computing N  such that
supη∈Dist(P ) Prη(reach(U )) − supη∈DetLFinMem  (P ) Prη(reach(U )) < ϵ .
Proof. Suppose, towards a contradiction, that the problem is decidable. Since DetLFinMemN (P ) is finite, then there exists an algorithm to find a value r such that supη∈Dist(P ) Pr (reach(U )) − r < ϵ . Such algorithm simply computes N and then performs an exhaustive search on DetLFinMemN (P ) (note that DetLFinMemN (P ) is a finite set). However, the existence of such algorithm contradicts Theorem 1 in [10].	 
Since Theorem 1 in [10] holds also if we restrict to systems in which only one atom has generative transitions, we cannot compute N even under such restriction. Hence, the result holds also for strongly distribute schedulers.
Even if a reasonable bound for the memory of the schedulers can be calculated somehow, then the problem is still complex, as shown by the following theorem.
Theorem 4.9 For all
S ∈ {LFinMem1(P ), DetLFinMem1(P ), GFinMem1(P ), DetGFinMem1(P )} ,

the problem of computing supη∈S Prη(reach(U )) is NP-hard.
Proof. We reduce the 3SAT problem to the supremum reachability problem. The following reduction was suggested by Peter Niebert [15]. Let c1 ∧ c2 ∧··· ∧ cm be an instance of the 3SAT problem where each ci is a clause of the form l1 ∨ l2 ∨ l3 and
j	i	i	i
each li is a literal (it is either a variable vk or the negation ¬vk). We construct two
atoms C and V . Intuitively, C chooses a clause and a literal in the clause, and V chooses a variable and a value for this variable. Atoms C and V do not synchronize at all. The set of states of C is
{init, c1, ··· , cm, l1,... , l3 , ··· , l1 ,... , l3 } .
1	1	m	m
The set of states of V is
{init , (v1, Undef) , ··· , (vn, Undef) , (v1, True) , ··· , (vn, True) ,
(v1, False) , ··· , (vn, False)} .
In the initial state, atom C has enabled only one transition. Such a transition probabilistically chooses one of the clauses, and it outputs a label a not visible to
V . We write this generative transition as


1
c = m (a, c1) + ··· +
1
m (a, cm) .



In addition in each of the states ci there are transitions h1, h2, h3
leading to the

respective literals:

hj = 1(a, lj ) .
i	i	i

i	i
The generative structure of C is thus given by GC (init)= {c}, GC(ci)= {h1, h2, h3}
i	i	i
and GC(s)= {} for all other s. Note that a scheduler for C defines a set of literals
lj1 , ··· , ljm (one for each clause c ). Atom V chooses a variable probabilistically, and
1	m	j
then nondeterministically assigns a value to this variable. We write the transition
that chooses the variable as

1
v = n (b, (v1, Undef) ) + ··· +
1
n (b, (vn, Undef) ) .

The generative structure of V  assigns this transition to the initial state: GV (init) = {v}. For each state of the form (vk, Undef) we have two transitions Falsek = 1(b, (vk, False) ) and Truek = 1(b, (vk, True) ). Then, GV (vk, Undef) =
{Falsek, Truek}. Each output scheduler for V can be seen as a valuation for the set of variables. The set of states U is the set in which the value assigned to variable in V does not disagree with the literal chosen by C, that is,
U = {(lj, (vk, False)) | lj /= vk} ∪ {(lj, (vk, True)) | lj /= ¬vk} .
r	r	r	r

Therefore, sup Prη(reach(U )) = 1 iff there exist a set of literals lj1 , ··· , ljm
and

η	1	m
a valuation such that all the literals hold in the valuation (in other words, iff the

formula is satisfiable). Note that the number of states of the system comprising atoms C and V is polynomial in the number n of variables. Moreover, the system has no cycles, and so Markovian schedulers attain the supremum probability. Then, the problem is NP-hard.	 


Related work
Our definition of strongly distributed schedulers is an important contribution, since it exactly captures the restrictions that the lack of information imposes to sched- ulers in asynchronous settings. In previous frameworks, there are no nondetermin- istic choices concerning the interleaving. In [8], the components are not specified explicitly (then, there are no interleaving issues) and the schedulers are restricted by imposing the condition that they must observe only a portion of every state in the history. In [9] a step of the whole system is obtained by taking a step in ev- ery component (thus, no interleaving is needed). The main difference between our framework and the PIOA framework in [6] is the concept of interleaving scheduler. In contrast, in the framework presented in [6] the different components have only input and output local schedulers, and a token is used in order to decide the next component to perform an output. The interleaving among different components is not resolved by the schedulers, since the way in which the token is passed is spec- ified by the components. Note that, because of the internal nondeterminism, the choice of the next component to execute is still nondeterministic, since there may be different transitions passing the token to different components. However, since internal nondeterminism is resolved according to the local history, the choice of the next component to execute is based on the history of the component that passes the token. In [5] it is suggested that a fictitious arbiter component can be added in order to specify interleaving policies. The components pass the token to the arbiter and the arbiter selects one of the components to which the token is passed. Using this schema, the information used to choose the next component can be restricted simply by restricting the information available to the arbiter. Although this ap- proach is useful in order to keep some information hidden, such approach cannot be used to represent the restriction we impose to strongly distributed schedulers since, in our restriction, the lack of information depends on each pair of components and there is no information completely hidden. In [11], a mechanism is devised in such a way that the interleaving is determined using rates for each component, and these rates depend solely on the information available to the component.
The example used to show that Markovian schedulers cannot attain worst-case
probabilities resembles the well-known partially observable Markov decision pro- cesses (POMDPs). POMDPs are MDPs in which the scheduler cannot distinguish the states: for each state, a distribution on the possible observations is defined, and the scheduler chooses according to these observations. The way in which the information is hidden is a crucial difference with respect to PIOA, since the lack of information in PIOA is not “state based” but “transition based”: in the PIOA framework, an atom is not aware of a state change unless the atom has synchro-

nized in the transition leading to this state change. This difference suggests that care must be taken to translate results from the POMDP setting to the PIOA set- ting. Similarly, the hardness result in [8] is proved in a setting in which the lack of information is not necessarily a consequence of the existence of several components.

Acknowledgement
We would like to thank Peter Niebert for his help and Markus Rabe for proofreading and corrections.

References
A. Bianco and L. de Alfaro. Model checking of probabilistic and nondeterministic systems. In Proc. of FSTTCS 95, LNCS 1026, pages 288–299. Springer, 1995.
K. Chatterjee, R. Majumdar, and M. Jurdzinski. On Nash equilibria in stochastic games. In CSL ’04, pages 26–40, 2004.
Konstantinos Chatzikokolakis and Catuscia Palamidessi. A framework for analyzing probabilistic protocols and its application to the partial secrets exchange. Theor. Comput. Sci., 389(3):512–527, 2007.
D. Chaum. The dining cryptographers problem: Unconditional sender and recipient untraceability. J. Cryptology, 1(1):65–75, 1988.
L. Cheung. Reconciling Nondeterministic and Probabilistic Choices. PhD thesis, Radboud Universiteit Nijmegen, 2006.
L. Cheung, N. Lynch, R. Segala, and F. Vaandrager. Switched Probabilistic PIOA: Parallel composition via distributed scheduling. Theor. Comput. Sci., 365(1-2):83–108, 2006.
F. Ciesinski and C. Baier. LiQuor: A tool for qualitative and quantitative linear time analysis of reactive systems. In Proc. of QEST’06, pages 131–132. IEEE CS Press, 2006.
L. de Alfaro. The verification of probabilistic systems under memoryless partial-information policies is hard. In Proc. of PROBMIV 99, pages 19–32. University of Birmingham, 1999.
L. de Alfaro, T. A. Henzinger, and R. Jhala. Compositional methods for probabilistic systems. In Proc. of CONCUR 01, LNCS 2154, pages 351–365. Springer, 2001.
S. Giro and P. R. D’Argenio. Quantitative model checking revisited: neither decidable nor approximable. In Proc. of FORMATS’07, LNCS 4763, pages 179–194. Springer, 2007.
S. Giro and P.R. D’Argenio. On the verification of probabilistic I/O automata with unspecified rates. In SAC ’09: Proceedings of the 2009 ACM symposium on Applied Computing, pages 582–586, New York, NY, USA, 2009. ACM.
R.J. van Glabbeek, S.A. Smolka, and B. Steffen. Reactive, generative, and stratified models of probabilistic processes. Information and Computation, 121:59–80, 1995.
A. Hinton, M. Kwiatkowska, G. Norman, and D. Parker. PRISM: A tool for automatic verification of probabilistic systems. In Proc. of TACAS’06, LNCS 3920, pages 441–444. Springer, 2006.
D. A. Martin. Borel determinacy. Annals of Mathematics, 102(2):363–371, 1975.
Peter Niebert. Personal communication.
R. Segala. Modeling and Verification of Randomized Distributed Real-Time Systems. PhD thesis, Laboratory for Computer Science, MIT, 1995.
Noel Vaillant. probability.net. Probability tutorials on line. Tutorial 2.
S.-H. Wu, S. A. Smolka, and E. W. Stark. Composition and behaviors of probabilistic I/O automata.
Theor. Comput. Sci., 176(1-2):1–38, 1997.

Appendix
The following table summarizes some of the results in the paper. For each subclass, the table indicates whether or not the subclass attain the same optimal probability as the whole class. For example, the corresponding to “Distributed”, “Infinite Memory” and “Deterministic” indicates that deterministic
distributed schedulers are as powerful as distributed schedulers.

Deterministic	Nondeterministic

N -Markovian	×√	×√

Distributed	Finite memory	×/
∗	×/ ∗

Infinite memory	√	√†
N -Markovian	×	×

Strongly distributed	Finite memory	×
Infinite memory	×
∗: √ for reachability properties, × for general properties.
√×†

†: trivially true. This subclass is the class of all distributed (strongly distributed, resp.) schedulers.
