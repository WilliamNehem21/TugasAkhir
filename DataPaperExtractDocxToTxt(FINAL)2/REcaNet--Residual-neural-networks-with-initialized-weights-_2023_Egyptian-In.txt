Egyptian Informatics Journal 24 (2023) 100404








REcaNet: Residual neural networks with initialized weights and attention	 mechanism for image propagating in multimode optical fiber restoration
Weiyi Zhang a, Sikai Wang b, Haoyu Liu c, Chengyu Hu a,*, Yijun Zheng d, Xuesong Yan a
a School of Computer Science, China University of Geoscience, Wuhan 430074, China
b Department of Mechanical Engineering, Faculty of Engineering, The University of Hong Kong, 999077, Hong Kong
c Institute of Fluid Physics, CAEP, Mianyang, Sichuan 621900, China
d Amazon, Beijing 100025, China



A R T I C L E I N F O 

Keywords:
Neural network Image reconstruction Noise reduction Multi-mode fiber
Low-dimensional features
A B S T R A C T 

Training a neural network to reconstruct images from time-series waveforms obtained from fiber optic probes not only yields high-quality, content-aware images but can also acquire different types of images from lower quality training images. Image reconstruction, as an inverse problem, involves using collected signals and system models to retrieve desired images, encountering mathematical challenges like distortion and degradation. In this paper, we introduce REcaNet, a multi-mode fiber image restoration model based on an enhanced residual convolutional neural network (CNN). The network employs a symmetrical architecture that downscales the image before upscaling it for restoration, and it reconstructs the high-level semantic feature map generated by the encoder to the original image resolution. Additionally, we incorporate weight initialization, attention mechanisms, and residual connections to enhance the final restored feature map with more low-dimensional features and promote fusion of features from distinct layers. The algorithm performs well on three datasets collected by multi-mode fibers, namely Minist, Clothes, and Omiglot. Among them, various indicators such as SSIM have been signifi- cantly improved.





Introduction

Since the emergence of fiber optic technology, research and appli- cations in communication-related fields have been continuously evolving [1]. Typically, fiber optics transmit one-dimensional digital or analog signals. In the 1980 s, researchers began studying the impact of scattering media on imaging systems and discovered that scattering media itself can be imaged. Therefore, they explored how to use scat- tering media for imaging [2]. If fiber optics are viewed as a type of scattering media, single-fiber imaging and transmission of two- dimensional image information become feasible. Multi-mode fiber (MMF) allows multiple spatial modes to propagate simultaneously, thereby increasing transmission capacity. Single-fiber imaging technol- ogy has made significant progress in imaging mechanisms, imaging quality, and application research in the past decade [3], providing a new direction for the development of ultra-thin endoscopy in biomedical applications, with broad application prospects [4–6].
In a single-fiber imaging system, the light from the image passes
through all channels and exits the other end as a speckle formed by multiple spatial modes. The entire image reconstruction process requires considering the transmission matrix, phase field, and other factors of the fiber optic, resulting in a large computational workload and long computation time. Therefore, new algorithms are constantly being studied [7–8].
Image restoration technology is mainly proposed for the “degrada-
tion” during the imaging process, which mainly refers to the influence of
various factors on the imaging system. In the process of transmitting images using multimode fibers, two-dimensional spatial information is converted into one-dimensional time pulse stream using high inter- modulation dispersion, resulting in some loss of original semantic information.
Artificial intelligence is widely used in computer science and many other disciplines. Facing the problem of image restoration, the con- volutional neural network in artificial intelligence can obtain informa- tion from waveform graphs and train neural networks to reconstruct images from time waveforms. It can not only detect high-quality



* Corresponding author.
E-mail addresses: williamzhang@cug.edu.cn (W. Zhang), sikaiw@connect.hku.hk (S. Wang), liuhaoyu22@gscaep.ac.cn (H. Liu), huchengyu@cug.edu.cn (C. Hu), yanxs@cug.edu.cn (X. Yan).
https://doi.org/10.1016/j.eij.2023.100404
Received 19 July 2023; Accepted 21 September 2023
Available online 28 September 2023
1110-8665/© 2023 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Computers and Artificial Intelligence, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



content-aware images, but also different types of images in training images with slightly reduced quality. The original CNN network may not be able to restore some features of the image very well, so it is necessary to improve traditional methods. Previously, the UNet network is generally used as the main method of image restoration, but the tradi- tional UNet has low accuracy for complex image restoration problems, because the network may not be able to pay attention to the pixels that
need attention. This is also a major trend in the future of image pro- cessing [9–11].
Similar research has been done to apply deep learning to the task of
fiber optic transmission image restoration. Fan P et al. used pre-trained autoencoders to reconstruct images from multimode fiber imaging sys- tems [12]. Zhu C et al. achieved the same fidelity level as CNN in image reconstruction through a single hidden layer dense neural network [13].
Liu Z et al. used the U-Net architecture for image restoration [14].
Although there has been extensive research on multimode fiber transmission image restoration in the past few years, it is still a chal- lenging task due to the relatively complex operation of the physical instruments used for multimode fiber transmission and its special characteristics compared to other image restoration tasks. First, after the input image is transformed into a signal through a series of physical operations, some features of the original image may be lost due to compression. Some of the lost features will cause a lack of key infor- mation in two-dimensional image restoration, making it impossible to distinguish between two similar images [15]. Based on the challenges discussed above, this paper proposes a new neural network based on U- Net called REcaNet.
REcaNet can handle these challenges well. Based on the U-Net




Fig. 1. REcaNet Architecture: Each blue rectangular block represents a multi-channel feature map. Part I serves as the encoder of REcaNet, utilizing convolutional blocks and EcaAttention modules. Part III functions as the decoder of REcaNet, structured similarly to the U-Net decoder. However, unlike the original U-Net that only consists of Parts I and III, REcaNet incorporates an additional Part II to expand the receptive field while preserving detailed spatial information. Additionally, REcaNet features a horizontal residual connection between Parts I and III, effectively addressing the issue of vanishing gradients and facilitating neural network optimization. Each convolution layer is succeeded by a ReLU activation function, except for the final convolution layer which employs a sigmoid activation.



network, REcaNet adopts initialized weights, adds vertical skip con- nections for each convolution block in the network, and introduces EcaAttention mechanism modules in each downscaling or upscaling process, which makes the overall network perform well while remaining lightweight. Qilong Wang et al. designed this Efficient Channel Atten- tion module, by replacing the fully connected layer in the channel attention module with a one-dimensional convolutional layer, they realized a lightweight attention module [16]. Currently, REcaNet has achieved high accuracy and low time consumption in multiple bench- mark tests.

Method

Network architecture

The image data set obtained by the fiber optic probe is a two- dimensional waveform with a size of 20000*4096. Taking into ac- count the properties of the data set, REcaNet is designed to receive 64*64 sized images as input and store detailed spatial information. As shown in Fig. 1, REcaNet can be divided into three parts: I,II and III, which are encoder, center extension convolution and decoder. REcaNet uses a traditional convolutional network and adds an EcaAttention module to each downscaled convolution block. A convolutional block and an EcaAttention module are added together as decoders. For each
its input size will change, and its output size can be expressed as k = ψ(C), Where C is the size of the input image and k is the size of the attention module, with the change of downscaling or upscaling process,
convolution block in the corresponding EcaAttention module.
Considering the abstractness of two-dimensional waveform infor- mation and the ambiguity of features, adding lightweight attention module can effectively improve the ability of feature extraction [17].
In this paper, we aim to reconstruct waveform diagrams representing transmitted signals in optical fibers, with our primary focus being the time–frequency analysis of these waveforms. The features of interest
include specific waveform changes, such as rising/falling edges, in-
tensity, and power spectrum. By directly applying the convolution kernel, we can disregard the structure of these waveform changes in the entire waveform space, significantly reducing the unnecessary influence of feature position on weight allocation.
Furthermore, the center-extended convolution can be employed in a cascading manner to improve the performance of our method. The encoder section consists of five downscaling layers. When processing an image with dimensions of 64x64, the output feature map generated by the encoder measures 8x8.
In this case, REcaNet uses an expansion convolution layer with an expansion rate of 1,2 in the central part, so the feature points on the last central layer will see 64*64 points on the first central feature map, covering most of the first central feature map [18].

Building the network
In the encoder, we first consider incorporating an attention mecha- nism module following the pooling layer. This is because the pooling
have their own distinct significance.
At the bottom layer, issues of gradient explosion and vanishing gradients during the training process are addressed through adding jump connections in deeper layers [19–21].

Improvement
Weights initialization
The purpose of weight initialization is to prevent the output loss
gradient of the activation function in the middle layer from exploding or disappearing during the forward (forward) propagation of the deep neural network. For image restoration, it is important to determine which features of the waveform are important and need to be focused by the neural network. At the same time, the default initialization of the network is all 0 initialization, which is easy to make the gradient close to each other. In order to make the gradient have greater discrimination, so that different dimensions have different performances and show more features, the weight initialization is used, and the problem is solved [22].
Attention mechanism
In neural networks, attention is a technique designed to mimic
cognitive attention. This effect enhances some parts of the input data while reducing others, motivated by the idea that the network should pay more attention to smaller but important parts of the data. Learning which part of the data is more important than the other depends on the context, which is trained via gradient descent.
Traditional attention mechanisms, such as SENet (Squeeze-and- Excitation Network), usually focus on the relationship between channels and adjust the information in the feature map by weighting the chan- nels. In contrast, EcaAttention introduces a novel attention mechanism to focus attention inside the channel, thereby improving the represen- tation ability of the feature map.
The core idea of EcaAttention is to use the Global Average Pooling (GAP) operation to perform overall statistics on the features of each channel. By exchanging the channel features for location-independent global information, EcaAttention can capture the relationship and context information inside the channel. This enables the network to better understand the importance between different channels and improve the expressiveness of the feature map.
Let’s assume that the input image is of size W*H*C, where W is width
of image, H is height of image and C is the channel of image. Eca Attention is an attention mechanism that focuses on channels, inde- pendent of the size of the picture. When the number of input channels is C, the weights of channels in attention block can be computed as
ω = σ(f{W1 ,W2 }(g(X ) ) )	(1)
where × is the output of a convolutional block, X ∈ RW×H×C, GAP can be computed as

layer serves to gradually reduce the size of the representation space, thereby minimizing the number of parameters, memory usage, and
 1 	W,H
WH	i=1,j=1  ij
(2)

computational complexity within the network, ultimately controlling overfitting. This process is also referred to as downscaling or pooling operation, and the attention mechanism module can more effectively
Through GAP, the feature map is compressed, as in formula (3)
g(X )
× ×  ̅→ 1 × 1 ×
(3)

capture features of interest in the region.
In this study, we introduce the EcaAttention mechanism module to the pooling layer, which offers improved efficiency compared to general attention mechanism modules. This is due to the connection between
Parts I and III via jump-connected lines. In the original U-Net network,
By excitation and normalization, the weight vector of the feature is obtained, and the normalized weight and the original input feature map are multiplied channel by channel to generate the weighted feature map, as shown in formula (4)

the feature maps obtained from deeper layers exhibit a larger field of view, while shallow convolutions focus on texture features. The deeper
[W × H × C]*[1 × 1 × C⇀] = W × H × Ĉ
(4)

layers emphasize essential features, so both deep and shallow features	We take the clothing dataset as an example, as illustrated in Fig. 2.


image is 64*64.


3.2. Implementation details








	

Fig. 2. Comparison of images from the clothes dataset.

Consider the high-heeled shoes in the original image in Fig. 2(a); in comparison to ordinary flat shoes, the heel requires greater attention due to its significance in differentiating between flat shoes and high
In this study, we used three datasets to train our deep learning model for achieving high accuracy and generalization ability. These datasets were preprocessed and divided into three parts according to a 7:2:1 ratio: training set, validation set, and testing set.
Our goal was to train the model on the training set, fine-tune the model parameters based on the validation set, and evaluate the model performance using the testing set. During training, we fed the training set samples into the model in batches, performed forward propagation to obtain the current prediction value, compared it with the restored image label, and calculated the mean squared error (MSE) as the model loss value [27]. MSE is a common loss function for regression problems that effectively measures the difference between the model predicted value and the actual target value, the MSE function is shown as follows.

heels. By incorporating the attention mechanism module, the perfor-
1∑n
(f (x) — y )2	(5)

mance of the neural network can be effectively enhanced, and the focus on image features can be intensified [23–24]. The reconstructed image in Fig. 2(b) also demonstrates near-perfect recovery of the features.
However, note that in optical fiber transmission, the order of magnitude of images is very large-scale. Compared with the traditional attention mechanism, EcaAttention is more concise and efficient, requiring only one global average pooling operation, which has low computational cost and is suitable for large-scale image data. And considering a single image, EcaAttention can capture the importance and context information inside the channel, enhance the expression power of the feature map, and has better interpretability. The attention weight is directly learned from the feature map, which can explain the attention degree of the network to different channels.
Skip connections
As in the case of LSTM, recurrent neural networks, there are two
main reasons to add skip connections: the first is to avoid the problem of vanishing gradients, which makes it easier to optimize the neural network. The gating mechanism facilitates information flow across multiple layers, or mitigates the degradation (accuracy saturation) problem. Simply adding deeper structure to the model of will lead to other changes, such as loss fluctuation or vanishing gradient, which is a serious degradation phenomenon. Another point is that the edge of the feature map of larger size obtained by deconvolution is lack of infor- mation [25]. Every down-sampling and extracting features will inevi- tably lose some edge features, and the lost features cannot be recovered from up-sampling [26].
In optical fiber transmission image restoration problems, each feature is crucial, especially when the image size is small. The edge features convolved can be directly extracted via skip connections, serving as a reference during upscaling to enhance the image restoration quality. This approach also helps to avoid the issue of non-recoverable edge features following convolution.

Experiments

We used PyTorch as the deep learning framework. All datasets were trained on an Alibaba Cloud Server using an Nvidia P4 GPU.

Dataset

We tested our method on three classic datasets: digits, letters, and clothes. All three datasets consist of 20,000 4096-dimensional waveform images, which are respectively divided into 17,000 training images, 2,000 validation images, and 1,000 test images. The resolution of each
n  i=1
The MSE loss function mainly does the function of evaluating the
quality of recovery, guiding the optimization algorithm and comparing different algorithms. To optimize the model parameters, we chose the Adam optimizer [28]. Adam is an adaptive learning rate optimization algorithm that can automatically adjust the learning rate. Combined with the backpropagation (BP) algorithm [29], the model loss function can achieve fast and stable convergence during the training process. We set the initial learning rate to 1e-4, batch size to 16, and iterated for 200 epochs. The loss function curve during the training process is shown in the figure below. It can be seen that the model converged at epoch X and there was no gradient vanishing or exploding errors throughout the training process, indicating that our model effectively learned the hid- den features and patterns of the input waveform.


3.3. Result

The SSIM, PSNR and Fidelity metrics were used to compare the traditional UNet network with the REcaNet network proposed in this paper, and Table1,Table2 and Table3 shows that the REcaNet network outperforms the traditional UNet network in all three metrics [30]. The most traditional fully connected network has poor image restoration quality in SSIM and lower recovery quality in PSNR due to the impact of noise, which is also inferior to our REcaNet. In addition, the proposed REcaNet network leads the traditional fully connected layer and UNet in both structural similarity index and peak signal-to-noise ratio.
As shown in Fig. 3, REcaNet has better denoising effect, higher contrast, and clearer restored features for image restoration. This is because the REcaNet network uses the Eca lightweight attention mechanism module, which can effectively focus on the features of the image even in sparse and abstract two-dimensional waveform diagrams and avoid paying attention to irrelevant features, thus avoiding noise in the restored image.
In Fig. 4, we can see the convergence degree of the loss function of the two networks UNet and REcaNet on the three data, and it can be seen that the convergence result of our proposed REcaNet is significantly better than that of UNet.

Table 1
Performance data sets of clothes on three networks REcaNet, UNet and FC for three indexes of SSIM, PSNR and Fidelity.




Table 2
Performance data sets of digits on three networks REcaNet, UNet and FC for three indexes of SSIM, PSNR and Fidelity.


Table 3
Performance data sets of letters on three networks REcaNet, UNet and FC for three indexes of SSIM, PSNR and Fidelity.


Fig. 3. REcaNet and UNet restore effects on three data sets after input images.

Conclusion

This article proposes a convolutional neural network called REcaNet for image restoration in multi-mode fiber. REcaNet preserves detailed information while integrating multi-scale features in the central part by enlarging the receptive field, which can to some extent address the sparsity of the two-dimensional waveform features obtained from the fiber. The attention mechanism module allows for better focusing on the key features in scarce features. However, REcaNet still has issues with restoration accuracy, and we plan to conduct more research to address these problems in functionality.
In addition, although the proposed REcaNet architecture was initially designed for multi-mode fiber transmission image tasks, we expect it to be applicable to other image restoration tasks, and we plan to investigate this in future research.

CRediT authorship contribution statement

Weiyi Zhang: Conceptualization, Methodology, Software, Valida- tion, Formal analysis, Investigation, Resources, Data curation, Writing – original draft, Writing – review & editing. Sikai Wang: Conceptualiza-
tion, Methodology, Software, Validation, Formal analysis, Data cura-
tion, Visualization, Writing – review & editing. Haoyu Liu: Conceptualization, Formal analysis, Investigation, Resources, Writing – original draft. Chengyu Hu: Writing – review & editing, Supervision, Funding acquisition. Yijun Zheng: Investigation, Project administra-
tion. Xuesong Yan: Supervision.



Fig. 4. Comparison of convergence of Loss functions of UNet and REcaNet on different datasets.

Declaration of Competing Interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.



Acknowledgment

This research was supported in part by the NSF of China (Grant No. 62073300, U19112055). This paper has been subjected to Hubei Key Laboratory of Intelligent Geo-Information Processing, China University of Geosciences, Wuhan 430074, China

References

Sharma P, Pardeshi S, Arora RK, et al. A review of the development in the field of fiber optic communication systems[J]. Int J Emerging Tech Adv Eng 2013;3(5): 113–9.
Lawandy N M, Balachandran R M, Gomes A S L, et al. Laser action in strongly scattering media[J]. Nature, 1994, 368(6470): 436-438. Yoon S, Kim M, Jang M, et al. Deep optical imaging within complex scattering media[J]. Nature Reviews Physics, 2020, 2(3): 141-158.
Capon PK, Li J, Horsfall AJ, Yagoub S, Schartner EP, Khalid A, et al. A silk-based functionalization architecture for single fiber imaging and sensing[J]. Adv Funct Mater 2022;32(3).
Seibel EJ, Brown CM, Dominitz JA, Kimmey MB. Scanning single fiber endoscopy: a new platform technology for integrated laser imaging, diagnosis, and future
therapies[J]. Gastrointest Endosc Clin N Am 2008;18(3):467–78.
Seibel EJ, Smithwick QYJ. Unique features of optical scanning, single fiber
endoscopy[J]. Lasers in Surgery and Medicine: The Official Journal of the American Society for Laser Medicine and Surgery 2002;30(3):177–83.
Li J, Schartner E, Musolino S, Quirk BC, Kirk RW, Ebendorff-Heidepriem H, et al.
Miniaturized single-fiber-based needle probe for combined imaging and sensing in deep tissue[J]. Opt Lett 2018;43(8):1682.
Liu C, Deng L, Liu D, et al. Modeling of a single multimode fiber imaging system[J]. arXiv preprint arXiv:1607.07905, 2016.
Miida Y, Matsuura Y. All-optical photoacoustic imaging system using fiber ultrasound probe and hollow optical fiber bundle[J]. Opt Express 2013;21(19):
22023–33.
Rahmani B, Loterie D, Konstantinou G, Psaltis D, Moser C. Multimode optical fiber transmission with a deep learning network[J]. Light Sci Appl 2018;7(1).
Cohen, G., Afshar, S., Tapson, J. & Van Schaik, A. EMNIST: Extending MNIST to handwritten letters. In 2017 International Joint Conference on Neural Networks
(IJCNN) 2921–2926 (IEEE, 2017).
Li Y, et al. Image reconstruction using pre-trained autoencoder on multimode fiber imaging system. IEEE Photon Technol Lett 2020;32:779–82.
Fan P, Liu Y, Wang C, Zhang L. Multimodal fiber imaging system image
reconstruction using generative adversarial network. Optik 2021;237:166349.
Zhang Y, Yang S, Tian Y. Single-hidden-layer neural network for data reconstruction in compressed sensing. IET Signal Proc 2020;14(4):251–8.
Liu Z, Zhai G, Chen X, Wang Z, Wang J. Research on improved Unet convolutional
neural network for image restoration. J Phys Conf Ser 2018;1063(1):012075.
Lagovsky BA, Samokhin AB. Image restoration of two-dimensional signal sources with superresolution[C]//PIERS. Proceedings 2013.
Wang H, Xu B, Liu S, Liu C, Wang H. ECANet: Efficient channel attention for deep convolutional neural networks. In: In ProceedIngs of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition; 2020. p. 9627–36.
Liu Z, Wang L, Meng Y, He T, He S, Yang Y, et al. All-fiber high-speed image detection enabled by deep learning[J]. Nat Commun 2022;13(1).
Zhou L, Zhang C, Wu M. D-LinkNet: LinkNet with pretrained encoder and dilated convolution for high resolution satellite imagery road extraction[C]//Proceedings of the IEEE. Conference on Computer Vision and Pattern Recognition Workshops
2018::182–6.
Wu Z, Shen C, Van Den Hengel A. Wider or deeper: revisiting the resnet model for visual recognition[J]. Pattern Recogn 2019;90:119–33.
Zagoruyko S, Komodakis N. Wide residual networks[J]. arXiv preprint arXiv:
1605.07146, 2016.
Lee A, Geem ZW, Suh KD. Determination of optimal initial weights of an artificial neural network by using the harmony search algorithm: application to breakwater armor stones[J]. Appl Sci 2016;6(6):164.
Thimm G, Fiesler E. Neural network initialization[C]//From Natural to Artificial
Neural Computation: International Workshop on Artificial Neural Networks Malaga-Torremolinos, Spain, June 7–9, 1995 Proceedings 3. Springer Berlin
Heidelberg, 1995: 535-542.
Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[J]. Adv Neural Inf Proces Syst 2017;30.
Han K, Xiao A, Wu E, et al. Transformer in transformer[J]. Adv Neural Inf Proces Syst 2021;34:15908–19.
Drozdzal M, Vorontsov E, Chartrand G, et al. The importance of skip connections in
biomedical image segmentation[C]//International Workshop on Deep Learning in Medical Image Analysis, International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis. Springer, Cham, 2016: 179-187.
Cao Z, Fu C, Ye J, et al. Hift: Hierarchical feature transformer for aerial tracking
[C]//Proceedings of the IEEE/CVF. International Conference on Computer Vision 2021::15457–66.
Ko¨ksoy O. Multiresponse robust design: mean square error (MSE) criterion[J]. Appl
Math Comput 2006;175(2):1716–29.
Zhang Z. Improved adam optimizer for deep neural networks[C]//2018 IEEE/ACM 26th international symposium on quality of service (IWQoS). IEEE 2018:1–2.
Hecht-Nielsen R. Theory of the backpropagation neural network[M]//Neural
networks for perception. Academic Press 1992:65–93.
Sara U, Akter M, Uddin MS. Image quality assessment through FSIM, SSIM, MSE and PSNR—a comparative study[J]. J Computer Commun 2019;7(3):8–18.
