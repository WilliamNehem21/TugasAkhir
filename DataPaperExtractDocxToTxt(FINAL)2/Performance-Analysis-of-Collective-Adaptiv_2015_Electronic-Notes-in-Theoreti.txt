Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 318 (2015) 53–68
www.elsevier.com/locate/entcs

Performance Analysis of Collective Adaptive Behaviour in Time and Space
Cheng Feng1,2
School of Informatics University of Edinburgh Edinburgh, UK
Marco Gribaudo3
Dipartimento di Elettronica, Informazione e Bioingegneria Politecnico di Milano
Milan, Italy
Jane Hillston1,4
School of Informatics University of Edinburgh Edinburgh, UK

Abstract
Many systems, both natural and engineered, exhibit collective adaptive behaviour. Natural examples are swarming animals and insects, and man-made examples include swarm robots and sensor networks. Indeed many systems have both human and ICT-based agents in play, distributed over some geographical region: an informatics environment as defined by Milner. Over recent years there has been increased interest in modelling these systems in order to understand their dynamic behaviour. Here we consider the subsequent issue of how to define useful performance measures for such systems, based on consideration of a simple, intuitive example.
Keywords: Spatio-temporal modelling, performance modelling, collective adaptive behaviour


Introduction
Systems which exhibit collective behaviour have many interesting properties. Exam- ples from the natural world such as swarming animals and insects are often studied

1 This work is partially supported by the QUANTICOL project 600708.
2 Email: s1109873@sms.ed.ac.uk
3 Email: marco.gribaudo@polimi.it
4 Email: jane.hillston@ed.ac.uk

http://dx.doi.org/10.1016/j.entcs.2015.10.019
1571-0661/© 2015 The Authors. Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

for their emergent behaviour, patterns which become apparent at the population- level but which were not readily apparent from the described behaviour of individ- uals. In engineered systems this emergent behaviour constitutes the performance of the system.
Increasingly large-scale, geographically distributed ICT systems are being devel- oped to support human endeavour in a variety of ways. This can be considered to be the realisation of the informatics environment predicted by Milner and Weiser [10,13]. Such systems operate with human agents interacting almost transparently with computing elements. Examples include smart city applications such as smart transportation, smart grid and many modern automotive systems.
In such systems, their transparency and pervasiveness mean that it is perhaps more important than ever to investigate their behaviour from both a qualitative and quantitive point of view prior to deployment. Work is currently underway, for example in the QUANTICOL project [6] to develop modelling formalisms to capture the behaviour of these systems [5,9]. Here we start a complementary investigation into the types of measure that can be derived from spatio-temporal systems. Classic performance measures assume that there is a single locus of operation. When there is a (limited) spatial aspect to behaviour, state annotations are usually used to syntactically distinguish the different locations and regular performance measures are applied. We seek to take a more radical approach to support modelling in which space is modelled explicitly and exploited fully when characterising the behaviour of the system.
Leader and Follower Scenarios
We consider a simple scenario in which agents are moving in a two-dimensional grid, as shown in Figure 1. We assume that the grid is finite and that the boundaries are
Leader

Follwers

Leader’s path
















Fig. 1. The Leader-Follower scenario.

wrapped, meaning that essentially we are considering movement on a torus. Each agent moves one step at a time and at each step can move in any direction: north, east, south or west. We assume that there is one distinguished agent, the Leader who moves autonomously, performing a random walk over the grid. Any other agent is a Follower . The objective of a Follower is to mimic the movement of the Leader . However, there is a restriction that the Follower should keep a minimum distance dmin from the Leader and should definitely avoid collisions.
In the following we consider a number of scenarios of increasing complexity to illustrate our points. In particular, the model will be specified in PALOMA [5], a new process algebra that is designed for the modelling of spatially distributed collective and adaptive systems. Before describing the scenarios, we first give a brief introduction to PALOMA. For more details the interested reader is referred to [5].

PALOMA
PALOMA is novel stochastic process algebra that allows the expression of models representing systems comprised of populations of agents distributed over space. In PALOMA each agent is a finite state machine and the language is conservative in the sense that no agents are spawned or destroyed during the evolution of a model (although they can cease to change state). The language has a two level grammar:
X(l) ::= !(α, r).Xj(lj) | ?(α, p).Xj(lj) | X(l)+ X(l)
P ::= X(l) | P  P
Agents are parameterised by a location, here denoted by l. Agents can undertake two types of actions, spontaneous actions, denoted !(α, r), and induced actions, denoted ?(α, p). When an agent performs a spontaneous action, it does so with a given rate r, which is taken to be the parameter of an exponential distribution, where 1/r is the expected duration of the action. Spontaneous actions are broadcast to the entire system, and can induce change in any other agent which enables an induced action with the matching type α. An induced action has an associated probability p, which records the probability that the agent responds to a spontaneous action of the same type. In the style of the Calculus of Broadcasting Systems [11], this can be thought of as the probability that the agent listens as opposed to simply hearing. Alternative behaviours are represented by the standard choice operator,
+. A choice between spontaneous actions is resolved via the race policy, based on
their corresponding rates. We assume that there is never a choice between induced actions of the same type.
A model, P , consists of a number of agents composed in parallel. There is no direct communication between agents, for example in the style of shared actions in PEPA [7]. Instead, all communication/interaction is via spontaneous/induced actions. When an action is induced in an agent the extent of its impact is specified by a perception function, u(α, l, X, lj,Xj) where α is the action type, l and X are the location and state of the receiver agent whereas lj and Xj are the location and state of the sender agent. This is a further probability which, given the locations

of the two agents, their current states and action type involved, determines the likelihood that the induced action occurs. For example, the perception function might have value 1 when the two agents are within a communication radius r of each other, but a value of 0 whenever the distance between them is greater than r. Obviously this gives a rich set of possible styles of interaction, but note that each agent with an induced action chooses independently whether to respond or not.

Scenario 1: Passive Followers
In this scenario, we assume the Leader can either choose to take a rest with rate rrest, or to move a step along a random direction at the rate of rmv. Moreover, we use pn, ps, pw, pe to represent the probability to move north, south, west and east, respectively. Thus, the Leader agent can be described as follows:
L(x, y) ::= !(rest, rrest).L(x, y)+ !(n, rmvpn).L(x, y + 1)+ 
!(s, rmvps).L(x, y − 1) + !(w, rmvpw).L(x − 1, y)+ 
!(e, rmvpe).L(x + 1, y)
where !(rest, rrest) denotes the Leader taking a rest spontaneously at the rate of rrest, and when it does this, it remains in its current position. !(n, rmvpn) denotes the Leader moving a step north by doing an spontaneous action n at the rate of rmv × pn.
Furthermore, we assume the Follower can only move passively when the Leader
informs it to do so. Thus, we define the Follower agent as:
F (x, y) ::= ?(n, pl).F (x, y + 1) + ?(s, pl).F (x, y − 1) +
?(w, pl).F (x − 1, y)+ ?(e, pl).F (x + 1, y)
where the Follower agent can move a step in a direction via an induced action, and pl encodes the probability for the Follower to respond to the Leader ’s movement action which means that the Follower may not obey the command from the Leader with probability 1 − pl.
The perception functions for actions n, s, w and e are simply defined as:
u(n, l, X, lj,Xj)=1 
u(s, l, X, lj,Xj)=1 
u(w, l, X, lj,Xj)=1 
u(e, l, X, lj,Xj)=1 
which means that the Follower will definitely perceive the command from the
Leader .

Scenario 2: Active Followers
In this scenario, we allow the Follower to be a little bit smarter. More specifically, we introduce an internal Clock agent which allows the Follower to move actively instead of just listening to the Leader ’s command. The Clock agent is simply defined as:

Clock (x, y) ::= !(cn, rc).Clock (x, y)+ !(cs, rc).Clock (x, y)+ 
!(cw, rc).Clock (x, y)+ !(ce, rc).Clock (x, y)
which means that the Clock agent will perform each self-jump action cn, cs, cw and
ce spontaneously at the rate of rc.
Then, the Follower agent becomes:
F (x, y) ::= ?(n, pl).F (x, y + 1) + ?(s, pl).F (x, y − 1) +
?(w, pl).F (x − 1, y)+ ?(e, pl).F (x + 1, y)+ 
?(cn, pc).F (x, y + 1) + ?(cs, pc).F (x, y − 1) +
?(cw, pc).F (x − 1, y)+ ?(ce, pc).F (x + 1, y)
where pc encodes the probability for the Follower to listen to a clock instruction.
Then, we define the associated perception function for actions n and cn as:


⎪
u(n | cn, l, X, l ,X ) == ⎨
⎪
∧ dist(l.x, l.y + 1, L.x, L.y) > dmin)
∨((dist(l.x, l.y + 1, L.x, L.y) > dist(l.x, l.y, L.x, L.y)
∧ dist(l.x, l.y, L.x, L.y) < dmin))

⎪⎪⎩0	otherwise
which can be interpreted in the following way: the Follower will only perceive the n or cn action from the leader or the internal clock if a step north will let the Follower become closer to the Leader and the distance to the Leader is still larger than dmin (Figure 2a), or it will be farther from the Leader but the current distance to the Leader is less than dmin (Figure 2b). To save space, we will not show the perception functions for other actions as they are defined in a similar way.

a)	b)
Fig. 2. Behaviour of the follower: a) dist(l.x, l.y + 1, L.x, L.y) > dmin, b) dist(l.x, l.y + 1, L.x, L.y) < dmin.

Scenario 3: Multiple Followers
Here, we put multiple Follower s in the system in order to observe some interesting collective behaviour. We assume that Follower s always try to avoid bumping into each other. Thus, we add a simple protocol to Follower s by modifying the perception functions. For example, the perception functions for n and cn are modified as follows:


⎪
u(n | cn, l, X, lj,Xj) == ⎪⎪⎨
⎪
⎪
((dist(l.x, l.y + 1, L.x, L.y) < dist(l.x, l.y, L.x, L.y)
∧ dist(l.x, l.y + 1, L.x, L.y) > dmin)
∨((dist(l.x, l.y + 1, L.x, L.y) > dist(l.x, l.y, L.x, L.y)
∧ dist(l.x, l.y, L.x, L.y) < dmin)))

⎪⎩0	otherwise
where |F (l.x, l.y + 1)| denotes the number of Follower s in location (l.x, l.y + 1). This means that a Follower will only take a step north when there are no other Follower agents in that location. Again, we will not show the modified perception functions for other actions as they are changed in a similar way.

Performance Measures
Traditionally, performance measures derived from probability distributions can be broadly divided into three categories:
State-based: an expectation over the states of the system. In its simplest form this is the probability that a certain property holds (Boolean values attributed to states). Utilisation is an example of this type. But such measures can also be based on more meaningful values for states, such as queue length where the value for each state is the number of customers in a queue. When the probability distri- bution is the steady state distribution the derived values will the average values, where at other times they will be transient, based on the transient probability. When spatial information is also represented in the system, the states of interest may be those in which certain spatial conditions are satisfied. Thus we might think of a form of spatial utilisation, the percentage of time that a particular location or set of locations are occupied.
Rate-based: an expectation over the rates of the system. Typical examples are throughput, loss probabilities, collision probability etc. Essentially these are also calculated as expectations over the states but the rewards associated with the states are now the rate at which events occur within the given state. Again either the transient or the steady state probability distribution may be used in the calculation of the expectation. Here again spatial conditions may be used to

identify the states of interest. For example, a collision relies on the state condition that two agents are in the same location at the same time.
Time-based: an average time, or a probability distribution with respect to time with respect to some behaviour. The classic example is perhaps response time which, via Little’s Law can be expressed in terms of throughput (a rate-based measure) and average number (a state-based measure). For non steady state measures, a passage time calculation will usually be required.
It is reasonable to expect that in spatio-temporal systems we will also be able to define space-based measures, analogous to time-based ones, which are derived from state and rate-based ones.

Performance measures of the Leader-Follower Scenarios
When we come to measuring our leader-follower system there are multiple different dimensions to consider and we may choose to abstract one of more either through projection or by averaging.
The first dimension is state. This is the fundamental record of the behaviour of the system. We assume that the behaviour of the agents is characterised by random variables which range over the state space. In this simple example the agents do not have any logical state beyond their current position. But in general we can imagine that agents are also fulfilling some other role in addition to their motion and so they may have other characterisations of state, orthogonal to their location.
The second dimension is time. In the simplest performance analysis we consider the behaviour of a single system or agent with respect to time. This may be tran- sient or elapsed time, or abstract time, in the sense that consideration of steady state behaviour essentially removes the time dimension by assuming stationarity. In this dimension it makes sense to consider the rate at which events occur, the probability of an event occurring within a time bound, the cumulative probability of events, etc.
The third dimension for our systems is space. Here we do not have an abstraction equivalent to steady state, but we do have the possibility to take average values over all space; for example, this is often done in ecological models. If there are dif- ferent types of agents competing over space (e.g. predators and prey) the system may be characterised at a certain time by the total number of each type present disregarding spatial placement, even though interaction is location aware. This form of spatial abstraction, does not seem appealing from a performance per- spective, but is often carried out as a mathematical expediency as more detailed representation is computationally expensive or intractable.
The fourth dimension, for a collective system, is the population of individuals. Here we again typically make an abstraction by shifting to a count or proportion of individuals exhibiting certain characteristics rather than retaining full informa- tion about each individual. Thus we may wish to record the number of agents at

a given location at a given time, or calculate averages either with respect to time or with respect to location. Or we may consider the behaviour only at steady state when time is abstracted.
Finally, when we analyse our system through discrete event simulation we have a fifth dimension which is the instances or trajectories of our system on which measurements are based.
Basic measures
Here we are particularly interested in spatio-temporal properties that incorporate both the second and third dimension. The simplest way of doing this is to consider a measure over one dimension at all points in the other. At the state level we can define for any agent A, loc(A, t) be the location of A at time t as the projection of the spatial dimension onto the time dimension. Conversely, we can define visit(A, l) to be the set of time instants in which agent A was at location l. Measures loc and visit are complementary in the sense that:
t ∈ visit(A, l)	=⇒	loc(A, t)= l
and
loc(A, t)= l	=⇒	t ∈ visit(A, l)
Note that there is a big difference in the codomain of the two measures, since loc returns a single point in space, while visit is a relation that returns a set of locations. The difficulty lies in the fact that while an agent can only have one location at a time, it can be at that location multiple times. To define a simpler function we can for example restrict to the last visit or the first visit, and define ﬁrstVisit(A, l) = min{visit(A, l)} and lastVisit(A, l)= max{visit(A, l)}. This however might not be a proper function, since location l might not be visited by agent A in the considered scenario. An alternative would be define functions over the relation. For example, we can express the age of an agent with respect to a location,
age(A, l)= |visit(A, l)|
where for a relation R, |R| is the size of the relation. In effect, this counts the number of times that agent A has visited location l.
We can use simulation to derive a large number K of trajectories and use it to estimate the probability that any of the previous properties hold. We can regard this as projecting the measure onto the fifth dimension, the space of trajectories. For example, we can express the probability that an agent A was at location l at time t as:
ΣK 1(loc(A, t)= l ∈ traji)
P(A is in l@t)=   i=1	
K
and the probability that a location l is visited by agent A exactly n times as:
ΣK  1(age(A, l)= n ∈ traji)
P(A visits l exactly n times) =   i=1	
K

where 1(predicate) is an indicator function which has the value 1 when the predicate is true and the value 0 otherwise.
Figure 3 shows for every location l the probability of the leader being there at times t = 10, 100, 500s. In this case the leader performs a step in one of the four directions on average every 4s (rmv = 0.25) and never rests (rrest = 0). The four directions are all equally probable (pn = pe = ps = pw = 1/4). The grid is 50 × 50 and the leader starts in position (27, 27). The number of simulation runs used is K = 200, 000. Note that the distribution tends to a bivariate normal distribution centered in the initial position of the leader, with the variance that increases with time. This is natural since the leader moves according to a pure random walk in the four directions.


T = 10s

T = 100s

T = 500s



0.14
0.12
0.1

0.14
0.12
0.1
0.08


0.014
0.012
0.01

0.014
0.012
0.01
0.008


0.003
0.0025
0.002

0.003
0.002
0.002
0.001

pr. 0.08
0.06 pr. 0.008
0.006
pr. 0.0015
0.001

0.06
0.04
0.02
0


0



404550
253035
0.04
0.02
0
0.006
0.004
0.002
0


0



404550
253035
0.004
0.002
0
0.001
0.0005
0


0



404550
253035
0.000
0

5 10 15 20
x 25 30 35 40

45 50 0
101520	y
5 10 15 20
x 25 30 35 40

45 50 0
101520	y
5 10 15 20
x 25 30 35 40

45 50 0
101520	y


T = 10s	T = 100s	T = 500s

Fig. 3. Cell occupancy probability for the leader at different time instants.

Figure 4 shows the distribution of the age for four different locations l1 = (26, 26), l2 = (28, 28), l3 = (25, 25) and l4 = (24, 24). Since the leader starts at (27, 27), locations l1 and l2 are at the same distance. Since the movement of the leader is not biased in any direction, they are identical. Locations l3 and l4 are at increasing distance: as can be clearly seen, the probability of not entering that location n = 0 increases whilst the probability of entering it a larger number of times decreases with the distance from the initial position.
Let us now focus on the probability that a given location l is first/last visited by agent A at time t as:
ΣK  1([ﬁrst/last]Visit(A, l) ≤ t ∈ traji)
P(A first/last visits l@t)=   i=1	
K
This measure allows us to analyze another peculiarity: temporal distributions, when computed via simulation, are always affected by the finite duration of the considered trace. In particular, visit(A, l) will always correspond to the set of time instants in which location l was visited during the time horizon spanned by the simulation. If agent A will visit location l after the end of the simulation cycle, this will not be included into visit(A, l). Figure 5 shows the probability distribution of the time at which a fixed location l = (26, 26) is either first visited or last visited. Two different temporal horizon lengths are considered for the simulations. It is interesting to see that the first and last visit to a location tend to coincide at the end of the simulation


0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
0	2	4	6	8	10
n
Fig. 4. Distribution of age, the number of passages at different positions, for the leader starting at (27,27).

period: this occurs because if the agent passes over the target cell only once during the considered time horizon, we have ﬁrstVisit(A, l)= lastVisit(A, l). It can also be clearly seen that the distribution of the last passage time is a measure that clearly depends on the simulation interval, while the first passage time is less influenced, as long as the time horizon is large enough to allow the agent to reach the considered location.
0.6

0.5

0.4

0.3

0.2

0.1

0
0	200  400  600  800  1000 1200 1400 1600 1800 2000
t

Fig. 5. Distribution of the time of the first and the last visit to location (26, 26) for two different simulation horizons ST = 1000s and ST = 2000s.


Derived measures
From these basic measures we can construct more interesting ones such as distance,
dist:
dist(A1, A2, t)= loc(A1, t) − loc(A2, t) 

e.g. dist(F, L, t) is the distance between agent F and agent L at time t. Thus when we have a single follower we can plot dist(F, L, t) with respect to time to see how the distance between the follower and the leader evolves over time. Again, in a simulation study, the distance can be averaged across all the trajectories to have a global idea of the system behaviour. This is reported in Figure 6 for different behaviours of the leader and of the follower. In particular, both a random movement (Figure 6a) and a fixed route (Figure 6b) for the leader are considered, for different internal clock speed. In all cases, the follower always perceives the clock message, even if this is performed at a different rate (pc = 1). A very noisy channel is considered, with the probability of missing the direction message sent by the leader equal to 95% (pl = 0.05). The target minimum distance between the leader and the follower is 2.1. For the random walk case, the distance from the leader becomes too high only when the follower does not perform any action to catch the leader (rc = 0). When the clock is considered, the follower can always maintain a good distance from the leader for the two considered speeds of rc = 1/16 and rc = 5/32. This is because the random motion confines the leader to an area that is always relatively close to its initial position. For the follower it is enough to perform some infrequent check to catch up with the leader. If instead a fixed route is followed, the messages sent by the leader become of paramount importance. In this case, the follower is not able to catch up with the leader, unless it performs clock actions at a rate much larger than the speed at which the leader is moving.

16	60

14	50
12
40
10
30
8
20
6
4	10


2
0  200  400  600  800 1000 1200 1400 1600 1800 2000
t

0
0	50  100  150  200  250  300  350  400  450  500
t

b)
Fig. 6. Average distance between the leader and the follower for different clock rates: a) random walk,
leader with a predetermined route.
We also assume that we can detect collision. Two agents A1 and A2 are said to collide if there exists t such that loc(A1, t)= loc(A2, t). In the simple scenarios, 1 and 2, which have only a single follower, we are then interested in the cases where loc(F, t)= loc(L, t). Again, we can use simulation to calculate the probability of a collision at a particular time. We can estimate the probability of collision at time t as
ΣK  1(loc(F, t)= loc(L, t) ∈ traji)
P(collision@t)=   i=1	
K
This is shown in Figure 7 for the same cases considered before. For the random

movement, the case in which the follower does not perform any recovery action has a large hit probability at the beginning, and rapidly reduces with time. This however is caused by the fact that the leader tends to go far away from the follower thus reducing the hit probability. This is even more visible in the route based movement case, where the hit probability is zero due to the fact that the follower starts losing the leader from the beginning. In the other cases, it is clear that the hit probability converges to a limit value, that is a characteristic of the follower’s behaviour, and depends on his parameters. For the route based movement, this is observed only for the case in which the follower reacts at a very high speed, since that is the only one where it is able not to lose the leader.

0.025	0.0012



0.02
0.001



0.015


0.01


0.005

0.0008

0.0006

0.0004

0.0002



0
0  200 400 600 800 1000 1200 1400 1600 1800 2000
t
0
0  50  100 150 200 250 300 350 400 450 500
t

a)	b)
Fig. 7. Hit probability between the leader and the follower for different clock rates: a) random walk, b) leader with a route.

Collision may be generalised to being within the minimal distance dmin:
ΣK  1(dist(F, L, t) < dmin ∈ traji)
P(too close@t)=   i=1	
K
Figure 8 shows such probabilities for different values of dmin for the case with rc = 5/32. As can be seen, while the hit probability can be very low, by enlarging the distance, the probability of the follower being at the considered contour becomes more tangible.

Temporal distance measures
We could also calculate a temporal distance tdist between the agents at a specific location l, comparing their first visit times:


tdist(A1, A2, l)= ⎪⎨

∧ age(A2, l) > 0

⎪⎪⎩ +∞	otherwise


1	1


0.8	0.8


0.6	0.6


0.4	0.4


0.2	0.2


0
0  200  400  600  800 1000 1200 1400 1600 1800 2000
t
0
0	50  100  150  200  250  300  350  400  450  500
t

a)	b)
Fig. 8. Probability of the follower being within a given distance from the leader for: a) random walk, b) leader with a route.

Note that considered temporal distance is meaningful only if both agents have vis- ited location l. We have set the temporal distance to +∞ if either of the agents has not passed through the considered location.
When we consider trajectories, we can use the previous definition to compute characteristics with respect to space rather than time. For example, we can define the probability that the passage of two agents in a location l is too close in time as:
ΣK  1(tdist(F, L, l) < tmin ∈ traji)
P(too close@l)=   i=1	
K
where tmin is some minimal separation in time that we seek to enforce. Note that by definition of tdist, this probability will be zero if the both agents have not passed through l. Figure 9 shows the probability that the temporal distance is less than tmin = 5s, tmin = 10s and tmin = 15s, for the case with rc = 5/32 and random movement for all the locations l = (x, y) ∈ [21, 31]×[21, 31]. Although the maximum is in all cases for the initial location of the leader l = (27, 27), the shapes tend to be less symmetric as the threshold increases. This reflects the fact that the protocol tends to keep the initial displacement between the leader and the follower.


Tmin = 5s

Tmin = 10s

Tmin = 15s



0.008
0.007
0.006
0.005

0.008
0.007
0.006
0.005
0.004


0.03
0.025
0.02

0.03
0.025
0.02
0.015


0.06
0.05
0.04

0.06
0.05
0.04
0.03

pr. 0.004
0.003 pr. 0.015
0.01
pr.
0.03
0.02

0.003
0.002
0.001
0






22  24







26  28
30




30
28
24 26  y
22
0.002
0.001
0
0.01
0.005
0






22  24







26  28
30




30
28
24 26  y
22
0.005
0
0.02
0.01
0






22  24







26  28
30




30
28
24 26  y
22
0.01
0


tmin = 5s	tmin = 10s	tmin = 15s
Fig. 9. Probability that the temporal distance for the cells in the range [21, 31] × [21, 31] is less than the considered thresholds tmin.

Multiple followers
When we have multiple followers we can think of defining the same measures for each of the followers, but what we would really like is some measure that reflects the collective behaviour.
Thus thinking of the distance from the leader, when there are N followers we can define dˆist as the average distance at time t as follows:
N

1
dist(L, t)= N
Σ dist(Fi, L, t)
i=1

The problem with this is that it can have the same value for very different distri- butions of followers over space.
Instead we might think of some form of contours recording the number, or proportion of agents that are within increasing distances from a given location at a given time. Thus at time t, if there are N agents, the contour C(l, 1, t) would be defined as



and in general
1
C(l, 1, t)= 
N

1
C(l, n, t)= 
N
Σ 1(  loc(Ai, t) − l  ≤ 1)
i=1

Σ 1(  loc(Ai, t) − l  ≤ n)
i=1

In the specific case of the followers and the leader we can define


1
C(loc(L, t), n, t)= 
N
Σ 1(  loc(Fi, t) − loc(L, t)  ≤ n)
i=1

Figure 10 shows the contour values with 4 and 8 followers. As can be seen from the figure, in the simulation with 4 followers, followers are less likely to break the minimum distance but more likely to keep a good distance from the leader than in the simulation with 8 followers. This is because followers always try to avoid bumping into each other. Thus with more followers, the probability of not perceiving the movement action is also higher (see the perception function in Section 2.4).
Analogously we can think of time contours,

N	δ

1
C(t, δ, l)= 
N
Σ Σ 1(loc(Ai,t + j)= l)
i=1 j=0



or
1
C(t, δ, l)= 
N

Σ 1(loc(Ai,t + δ)= l)
i=1

depending on whether we consider the time contours cumulatively or not.



(a) n < dmin	(b) n > dmin
Fig. 10. The contour C(loc(L, t), n, t) with different number of followers, where dmin = 2.1
Conclusions and future work
In this paper we have made an initial study of the types of measures that it can be interesting to study in systems in which there are both temporal and spatial aspects of behaviour. These are important characteristics in many collective adaptive sys- tems (CAS), which are geographically distributed systems comprised of interacting but autonomous agents. We have illustrated the ideas with a simple leader-follower system studied in a number of different scenarios via simulation.
Whilst our example system is simple, it is sufficient to highlight the rich forms of information that can be derived from models of CAS, and it is easy to see how the measures we investigated could be adapted to real-life systems. For example, smart transportation systems are examples of CAS [12], where regulatory requirements impose spatial-temporal conditions. Bus operators are subject to the headway re- quirement on frequent routes, which can be regarded as a special case of our leader- follower scenario. Here the timetable would play the role of the leader whilst buses providing the service are the followers. The headway requirement imposes condi- tions on the spatial and temporal separation of the followers in order to ensure that there is a regular service for the users. In this case the behaviour of the leader is deterministic but the behaviour of the followers, the buses, is subject to stochastic factors, such as traffic and weather conditions as well as human interaction.
In future work we will investigate our identified measures further to see how well they match to the user and operator performance requirements for CAS. In the current work we have worked from first principles, assessing the data available from our simple scenario and the spatio-temporal measures that can be built. An alterna- tive approach would be to work with a spatio-temporal logic to define properties of interest. The use of temporal logic in the context of Markovian-based performance models is well-established [2] and supported by tools such as PRISM [8]. Spatial Logics have also been studied for many years [1] but to the best of our knowledge has yet to be applied in the quantitative context of CTMCs, although recent ap- plications include data verification for CAS [4]. There is little formal treatment of the combination of spatial and temporal logic although it has been considered in a informal way in the analysis of video sequences [3]. Here spatial until formulae

were interleaved with temporal until formulae to express conditions on the relative positions of objects in an image as time progressed. In quantified spatio-temporal logic we would seek to attribute a value to such properties, just as probabilities are associated to temporal properties expressed in CSL.

References
Aiello, M., I. Pratt-Hartmann and J. van Benthem, editors, “Handbook of Spatial Logics,” Springer, 2007.
Baier, C., B. R. Haverkort, H. Hermanns and J.-P. Katoen, Model-checking algorithms for continuous- time markov chains, IEEE Trans. Software Eng. 29 (2003), pp. 524–541.
Bimbo, A. D., E. Vicario and D. Zingoni, Symbolic description and visual querying of image sequences using spatio-temporal logic, IEEE Trans. Knowl. Data Eng. 7 (1995), pp. 609–622.
Ciancia, V., S. Gilmore, D. Latella, M. Loreti and M. Massink, Data verification for collective adaptive systems: spatial model-checking of vehicle location data, in: Proceedings of the 2nd FoCAS Workshop on Fundamentals of Collective Adaptive Systems, London, England, 2014, to appear.
Feng, C. and J. Hillston, PALOMA: A process algebra for located markovian agents, 11th International Conference on the Quantitative Evaluation of Systems (2014), to appear.
FET Proactive FOCAS Project 600708, QUANTICOL: A quantitative approach to management and design of collective and adaptive behaviours, www.quanticol.eu.
Hillston, J., “A Compositional Approach to Performance Modelling,” CUP, 2005.
Kwiatkowska, M. Z., G. Norman and D. Parker, PRISM 4.0: Verification of probabilistic real-time systems, in: Computer Aided Verification - 23rd International Conference, CAV 2011, Snowbird, UT, USA, July 14-20, 2011. Proceedings, Lecture Notes in Computer Science 6806 (2011), pp. 585–591.
Latella, D., M. Loreti, M. Massink and V. Senni, Stochastically timed predicate-based communication primitives for autonomic computing, Technical report, QUANTICOL project (2014).
Milner, R., “The Space and Motion of Communicating Agents,” Cambridge University Press, 2009.
Prasad, K., A calculus of broadcasting systems, Science of Computer Programming 25 (1995), pp. 285– 327.
Reijsbergen, D. and S. Gilmore, Formal punctuality analysis of frequent bus services using headway data, in: Proceedings of the 11th European Performance Engineering Workshop, Florence, Italy, 2014, to appear.
Weiser, M., The computer for the 21st century, Scientific American 265 (1991), pp. 94–104.
