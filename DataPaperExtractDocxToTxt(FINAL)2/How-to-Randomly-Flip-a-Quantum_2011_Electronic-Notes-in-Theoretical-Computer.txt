

Electronic Notes in Theoretical Computer Science 270 (1) (2011) 81–97
www.elsevier.com/locate/entcs
How to Randomly Flip a Quantum Bit
Keye Martin1
Center for High Assurance Computer Systems (Code 5540) Naval Research Laboratory, Washington, DC 20375.

Abstract
We show that an important class of quantum channels, the convex closure of the spin channels, can be algebraically represented by classical channels that have four inputs and four outputs. This result is used to develop an experimentally realizable scheme for randomly flipping qubits whose basis of preparation is unknown. This scheme can be used to interrupt, but not necessarily eradicate, any form of hidden communication based on quantum information. It can also be used to remove steganographic information embedded in quantum data.
Keywords: Quantum channel, spin channel, classical channel, steganography


Introduction
The ability to randomly flip classical bits is a fundamental operation with many uses. It can be used to interrupt undesirable communication [2], for instance, or to remove steganographic information hidden in data [3]. Each of these help to ensure the security of systems. The scheme for randomly flipping classical bits is as follows: given a bit, we toss a coin, and then based on the result of this coin toss, either flip the bit or leave it alone. This scheme eliminates any and all correlation between the information sent and the information received. As a result, transmitting information with bits that have been randomly flipped is impossible.
In the quantum case, interrupting communication is more difficult. A common misconception is that one can randomly flip quantum bits by applying the “bit flipping” operator √ε(ρ) = p · ρ + (1 − p) · σxρσx with p = 1/2. However, if the
|±⟩ = (|0⟩ ± |1⟩)/  2 basis is being used to represent information, then this has
no effect at all, since ε(|±⟩⟨±|) = |±⟩⟨±|. The states randomly flipped by ε when p = 1/2 are |0⟩ and |1⟩. Put another way, quantum bit flipping with p = 1/2 only has the effect we intend for it to have if we know the basis being used to represent

1 Email: keye.martin@nrl.navy.mil

1571-0661 Published by Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2011.01.008

information. Naturally, it is not realistic to assume that we can know the basis being used to represent information: infinitely many representations are possible. For instance, suppose that two parties share a private key obtained from QKD and that they then use this private key to randomly alternate between representations in the X = {|+⟩, |−⟩} and Z = {|0⟩, |1⟩} bases. Since each bit of information is equally likely to have been coded in either the X or Z basis, applying ε with p = 1/2 only results in 1/4 of the bits being flipped, when we intend to flip 1/2 of them.
So the question is: how do we randomly flip a quantum bit, assuming that we do not know the basis being used to represent information? Is this even possible? And if it is possible, we are not just looking for a mathematical solution, such as some operator that gives rise to the correct probability of error. Fundamentally, we are trying to identify a simple and inexpensive procedure that can be easily performed in a laboratory.
In this paper we show that it is possible to randomly flip quantum bits. The procedure we give is based on experimental operations that are routinely performed in laboratories today. Our path to the solution though is also of interest. The way we solve this problem is by establishing an isomorphism between a class of classical channels and a class of quantum channels. The existence of this isomorphism means that we can reason about certain quantum channels as though they were classical channels. Once we become aware of this, the ability to randomly flip quantum bits is a consequence of our ability to randomly flip classical bits. Moreover, the class of such quantum channels covered by our representation theorem includes most of the models currently used to describe noise: bit flipping, phase flipping, bit-phase flipping, depolarization and projective measurements. Thus, channels like these can be reasoned about as though they were classical channels having four inputs and four outputs. This provides additional evidence of the importance of algebraic structure [2] in information theory, whether it be classical or quantum.

The classical paradigm
A binary channel has two inputs (“0” and “1”) and two outputs (“0” and “1”). An input is sent through the channel to a receiver. Because of noise in the channel, what arrives may not necessarily be what the sender intended. The effect of noise on input data is modelled by a noise matrix u. If data is sent through the channel according to the distribution x, then the output is distributed as y = x · u. The noise matrix u is given by
a a¯
⎝b ¯b⎠
where a = P (0|0) is the probability of receiving 0 when 0 is sent and b = P (0|1) is the probability of receiving 0 when 1 is sent and x¯ := 1 − x for x ∈ [0, 1]. Thus, the noise matrix of a binary channel can be represented by a point (a, b) in the unit square [0, 1]2 and all points in the unit square represent the noise matrix of some binary channel.

We begin with the classical case to gain some intuition about properties of random bit flipping that might aid us in the quantum case. Two parties are com- municating, sending classical bits across a channel whose noise matrix is unknown to them. For a couple of a good reasons, it is reasonable to assume that they will send bits with equal probability. These reasons include:
Creating the appearance that their transmission of data is random i.e. that it is simply noise will help serve as a deterrent to those who might seek to interrupt (i.e., who would care about interrupting noise?)
Given that the matrix is unknown, the excellent result of Majani-Rumsey says that sending bits with equal probability will get them to within ninety-four per- cent of capacity.
Now when we say interrupt, we are talking about inserting a second channel with noise matrix (a, b) between the parties whose effect is to introduce a certain prob- ability of error. When data is transmitted according to (x, x¯), the probability of error achieved is xa¯ + x¯b. Since we are assuming the parties send bits with equal frequency, the probability of error we introduce 2 is
1	1	1	1
e(a, b)= 2 · a¯ + 2 · b = 2 − 2 (a − b)
Now assume that we would like to introduce a probability of error p = e(a, b). Then in order to interrupt communication as much as possible, we seek to minimize capacity
a¯H(b)−¯bH(a)	bH(a)−aH(b) 
			
where C(a, a) := 0 and H(x) = −x log2(x) − (1 − x) log2(1 − x) is the base two entropy, over the set of channels S = {(a, b): e(a, b)= p} which cause a probability of error equal to p. Because S is convex (being a line) and capacity is a convex function of the noise matrix, C assumes its minimum value at the midpoint (a, b) of S. Such a midpoint (a, b) satisfies a + b = 1. That is, we must use a binary symmetric channel whose capacity is then 1 − H(b)=1 − H(a). Let us point out two elementary but important facts:
Within the class of binary channels, the binary symmetric channels are exactly those which increase entropy i.e. H(x · u) ≥ H(x) for all x,
Within the class of binary symmetric channels, the only channel with capacity zero is ⊥ :=  1/2 1/2
Thus, on the assumption that all inputs are equally likely, the best way to interrupt communication is to inject ⊥ into the communication line: the unique entropy increasing channel of capacity zero, which corresponds to randomly flipping classical

2 Notice that the actual probability of error may be larger since we are only interested in what we introduce and ignore effects from the environment

bits. Ideally, one hopes to see these properties also reflected in the case of qubits, since each choice of basis defines a classical channel, as we will see in the next section. Though it seems a bit naive at first glance, we nevertheless now restrict our attention to entropy increasing channels on qubits.
Quantum channels
We begin with basic intuitions that help us relate qubit channels to classical binary channels. Let Δ2 denote the set of finite probability distributions over a two element set:
Δ2 := {(x, y) ∈ [0, 1]2 : x + y = 1}
The noise matrix u of a binary channel defines a function f : Δ2 → Δ2, given by f (x) = x · u, which maps an input distribution x ∈ Δ2 to an output distribution f (x) ∈ Δ2.
The fact that a binary channel operates on Δ2 is indicative of the fact that only two symbols are being sent and that we have chosen a particular and fixed way of representing these two symbols. By contrast, in the case of a quantum channel, there are an infinite number of ways to represent bits: each basis of the state space H2, a two dimensional complex Hilbert space, offers a different possible representation. Let us suppose that we choose a particular quantum representation for the classical bits ‘0’ and ‘1’, denoted by orthogonal unit vectors |0⟩ and |1⟩ in H2. In doing so, we are implicitly saying that we will use a quantum system to represent a classical bit. When the system is in state |0⟩, it represents the classical bit ‘0’; when in state
|1⟩, it represents the classical bit ‘1’. There is a subtle but relevant caveat here though.
Physically, states are equal “to within a phase factor.” So for example, the states
iθ
|0⟩, −|0⟩, i|0⟩, −i|0⟩,e  |0⟩ are all equivalent in the sense that quantum mechanics
makes the same predictions about a system in any one of these states. Mathemati- cally, though, we know that we cannot go around writing things like “|0⟩ = −|0⟩,” for the simple reason that in a vector space the only such element is the zero vector and the zero vector is not a unit vector. One way around this difficulty is to say that a ‘state’, specified by a unit vector |ψ⟩∈ H2, is mathematically represented by the operator f : H2 → H2 given by
f (u)= ⟨ψ|u⟩· |ψ⟩
The operator f takes as input a vector u and returns as output the vector |ψ⟩ multiplied by the complex number ⟨ψ|u⟩, which is the inner product of the vector u and the vector |ψ⟩. For this reason, the operator f is traditionally denoted f = |ψ⟩⟨ψ|. Such an operator is called a pure state since it refers to a state that the system can be in; pure states are the quantum analogues of e0 = (1, 0) and e1 = (0, 1) in Δ2, the latter of which we think of as the classical representation of the bits ‘0’ and ‘1’.
A classical binary channel f : Δ2 → Δ2 takes an input distribution to an output distribution. In a similar way, a qubit channel will map input distributions to output

distributions. But what is the quantum analogue of a distribution? Let us return to the classical case. Each distribution x ∈ Δ2 may be written
x = x0 · e0 + x1 · e1
i.e., as a convex sum of classical ‘pure’ states. The meaning of such an expression is that the system is in state e0 with probability x0 and in state e1 with probability x1. Thus, if a quantum system is in state |ψi⟩⟨ψi| with probability xi, a natural way to represent this ‘distribution’ is given by the operator
n
ρ =	xi · |ψi⟩⟨ψi|
i=1
Such an operator is called a density operator. A density operator is also called a mixed state. The set of all density operators on H2 is denoted by Ω2. Thus, in analogy with the classical case, a qubit channel will be a function of the form ε : Ω2 → Ω2. Specifically,
Definition 3.1 A qubit channel is a function ε : Ω2 → Ω2 that is convex linear and completely positive.
To say that ε is convex linear means that ε preserves convex sums i.e. sums of the form x · ρ + (1 − x) · σ. Complete positivity, defined in [4], is a condition which ensures that the definition of a qubit channel is compatible with natural intuitions about joint systems. For our purposes, there is no need to get lost in too many details of the Hilbert space formulation – very soon, we will represent qubit channels as mappings on the unit ball in Euclidean space.
Unitality
In the case of classical binary channels, the binary symmetric channels are the en- tropy increasing channels: they are exactly the channels f which preserve the uni- form distribution f (1/2, 1/2) = (1/2, 1/2). The von Neumann entropy of a density operator ρ is given by S(ρ)= −tr(ρ log(ρ)). In a similar way, the entropy increas- ing qubit channels are precisely those ε for which ε(I/2) = I/2. Such channels are called unital [4].
Definition 3.2 A qubit channel ε is unital if ε(I/2) = I/2.
Let us now consider several important examples of unital channels.
Example 3.3 Unitary channels. If U is a unitary operator on  2, then ε(ρ) = 
U ρU † is unital since UU† = I.
Example 3.4 Projective measurements. If {P0, P1} are projections with P0 + P1 =
I, then
ε(ρ)= P0ρP0 + P1ρP1
is a unital channel since P 2 = P0 and P 2 = P1.
0	1

Example 3.5 Convex sum and composition. If ε1 and ε2 are unital channels, then
ε1 ◦ ε2 and p · ε1 + (1 − p) · ε2 are unital for p ∈ [0, 1].
Using these three examples, we can construct many examples of unital channels. For instance, to construct the “bit-flipping” channel, we use the spin operator σx =
0 1
⎝	⎠, which is unitary, to define a unital channel εx. Next, the identity channel
1 0 
εI (ρ)= ρ is unital, so their convex sum
ε(ρ)= (1 − p)εI (ρ)+ p · εx(ρ)
is a unital channel. In a similar way, phase flipping, bit-phase flipping, the two- Pauli channel, phase damping (“decoherence”) and depolarization are also seen to be unital. Not all qubit channels are unital of course, amplitude damping is one well-known example.
The Bloch representation of unital channels
Every unital qubit channel can be represented by a linear mapping that takes the unit ball in three space into itself. Using this representation, the Bloch representa- tion, one is able to avoid many of the complications of the Hilbert space formulation, so we consider it now.
There is a 1-1 correspondence between density operators on a two dimensional state space and points on the unit ball B3 = {x ∈ R3 : |x| ≤ 1}: each density operator ρ : H → H can be written uniquely as
1 ⎛ 1+ rz rx − iry⎞

	

where r = (rx, ry, rz) ∈ R3 satisfies |r| =  r2 + r2 + r2 ≤ 1. The vector r ∈ B3 is
called the Bloch vector associated to ρ. Bloch vectors have a number of aesthetically pleasing properties.
If ρ and σ are density operators with respective Bloch vectors r and s, then
(i) the eigenvalues of ρ are (1 ± |r|)/2, (ii) the von Neumann entropy of ρ is Sρ = H((1 + |r|)/2) = H((1 − |r|)/2), where H : [0, 1] → [0, 1] is the base two Shannon entropy, (iii) if ρ and σ are pure states and r + s = 0, then ρ and σ are orthogonal, and thus form a basis for the state space; conversely, the Bloch vectors associated to a pair of orthogonal pure states form antipodal points on the sphere, (iv) the Bloch vector for a convex sum of mixed states is the convex sum of the Bloch vectors,
(v) the Bloch vector for the completely mixed state I/2 is 0 = (0, 0, 0) and (vi) tr(ρ · σ)= (1 + (r, s))/2, where (r, s) is the Euclidean inner product on R3.
Definition 3.6 For a qubit channel ε : Ω2 → Ω2, the mapping it induces on the Bloch sphere fε : B3 → B3 is called the Bloch representation of ε.

If ε is a qubit channel and fε is its Bloch representation, then (i) ε is unital iff fε(0) = 0, (ii) the function fε is convex linear, (iii) composition of quantum channels corresponds to composition of Bloch representations: for channels ε1, ε2, we have fε1◦ε2 = fε1 ◦ fε2 , (iv) convex sum of quantum channels corresponds to convex sum of Bloch representations: for channels ε1, ε2 and x ∈ [0, 1], we have fxε1+x¯ε2 = xfε1 + x¯fε2 .
To illustrate how these properties make it simple to calculate the Bloch repre- sentation of a qubit channel, let us return to the example of “bit flipping” ε(ρ) = (1 −p)εI (ρ)+ p· εx(ρ). The Bloch representation of εI is fεI (r)= r. Using the corre- spondence between density operators and Bloch vectors, we calculate directly that the Bloch representation of εx is fεx (rx, ry, rz)= (rx, −ry, −rz). Thus, by property
(iv) of Bloch representations,
fε(rx, ry, rz)= (1 − p)(rx, ry, rz)+ p(rx, −ry, −rz)= (rx, (1 − 2p)ry, (1 − 2p)rz)
If we set p = 1/2 in an attempt to randomly flip qubits, we see that states of the form (rx, 0, 0) are unchanged by this form of noise, which explains why “bit flipping” only removes all correlations when the basis used to represent information is known. Let us now turn to the case in which the representation is unknown.

Zero
In section 2, we saw that randomly flipping classical bits amounted to being able to construct the unique entropy increasing channel of capacity zero, ⊥. Specifically, the way we ‘construct’ ⊥ is by basing the decision on whether to flip a bit on the result of a coin toss. We now use this observation as a guide in approaching the more difficult problem of how to randomly flip a quantum bit.
Suppose Alice sends a qubit represented by ρ, that ρ suffers the effect of noise described by the quantum channel ε. Bob then receives ε(ρ) and performs a mea- surement in some basis {|0⟩, |1⟩}. The measurement operators in this case are the projections P0 = |0⟩⟨0| and P1 = |1⟩⟨1| and form a complete set since P0 + P1 = I. Thus, by standard quantum mechanics, the probability that Bob obtains the result 0 is
p0 = tr(P†P0 · ε(ρ))) = tr(P0P0 · ε(ρ)) = tr(P0 · ε(ρ)) while the probability that Bob obtains the result 1 is
p1 = tr(P†P1 · ε(ρ))) = tr(P1P1 · ε(ρ)) = tr(P1 · ε(ρ))
where we recall that projections satisfy P 2 = Pi. Now both projections P0 and
P1, being density operators, also have a Bloch vector associated with them, given by s and t, respectively. Thus, if r is the Bloch vector for ρ and fε is the Bloch representation of ε, then the probabilities p0 and p1 can be succinctly written as


p0 =
1+ (s, f (r))
2	&	p1 =
1+ (t, f (r)) 2

Further, since |0⟩ and |1⟩ form a basis for the state space, s + t = 0, which helps us see that p0 + p1 = 1. Thus, choosing any two density operators as inputs, we obtain a classical binary channel.
In the particular case that the two density operators chosen by Alice form a basis for the state space (perhaps different from the one that Bob measures in), the channel we get is binary symmetric and thus we see that shutting down all communication will require that all our probabilities be 1/2. That is, the Bloch representation fε will have to be zero, meaning that the channel should be ε(ρ)= I/2. From an experimental point of view, this information is useless – how do we force a system into the completely mixed state I/2? Put another way, how do we factor zero into a product of nontrivial, experimentally realizable operations? Surprisingly, the answer to the question can be found by examining the algebraic structure of classical channels.
The involution group in classical information theory
For a classical channel with n inputs and n outputs, the noise matrix u has n rows and n columns, each entry is a probability, and as with binary channels, each row sums to one. Thus, each (n, n) classical channel induces a function f : Δn → Δn given by f (x)= x · u where


Δn :=

x ∈ [0, 1]n :

Σi=1

xi = 1 

In particular, the (n, n) channel ⊥ is the matrix all of whose entries are 1/n,
⎛1/n ... 1/n⎞
⊥ := ⎜ .	. ⎟
⎝1/n ... 1/n⎠

It is the unique entropy increasing (n, n) channel with capacity zero.
With both classical and quantum channels, there is structure in common that we can formulate more abstractly – doing so not only helps us to think more clearly about channels, this more abstract stance is what ultimately enables us to solve the problem of randomly flipping quantum bits.
A monoid (M, ·, 1) is a set M with an associative binary operation · : M 2 → M such that 1 ∈ M is an identity: x · 1=1 · x = x for all x ∈ M . A group (G, ·, 1) is a monoid (G, ·, 1) in which every element has an inverse: (∀x ∈ G)(∃y ∈ G) xy = yx = 1. An algebra over the reals, also called a real algebra, is a vector space (A, +, 0) over the reals which is also a monoid (A, ·, 1) in such a way that multiplication · and addition + satisfy the kind of properties one would expect. To prevent getting lost in too many mathematical definitions, let us just give the main example of a real algebra that we are interested in: the algebra Mn(R) of n × n real matrices.

Our interest in these mathematical structures is that they can be used to iden- tify previously unknown similarities between classes of channels, both classical and quantum. A good starting point for a mathematical model of a “class of channels” is a convex monoid: a convex subset of a real algebra that is also a monoid. Noise matrices for (n, n) channels are closed under finite convex sums and composition, so they form a convex monoid. The same is true of the doubly stochastic classical channels, unital qubit channels, qubit channels and quantum channels in general.
Definition 4.1 An involution group is a monoid (M, ·, 1) in which x2 =1 for all
x ∈ M.
Notice that an involution group, while defined only to be a monoid, is in fact a group, since every element is its own inverse. In addition, such a group is commu- tative: since (xy)(yx) = 1, we see that yx must be the inverse of xy, but since xy is an involution, xy = yx.
By standard results in group theory (the classification of finite abelian groups),
any finite involution group G is isomorphic to Zn for some n ≥ 0 and thus is
determined (up to isomorphism) by the number of elements it contains (its order),
which must be a power of two.
Theorem 4.2 The class of (n, n) classical channels contains a copy of the involu- tion group of order n iff n = 2k for some integer k ≥ 1.
Proof. If k = 1, then the involution group is
G = ⎧⎨⎛0 1⎞ , ⎛1 0⎞⎫⎬
1	⎩⎝1 0⎠ ⎝0 1⎠⎭

This is the involution group of order 21. Now suppose we have the involution group
Gk of order 2k. Define Gk+1 by specifying its element in block form as
G	= ⎧⎨⎛0 g⎞ : g ∈ G ⎫⎬ ∪ ⎧⎨⎛g 0⎞ : g ∈ G ⎫⎬

k+1
⎩⎝g 0⎠
⎭	⎩⎝0 g⎠	⎭

where 0 refers to the 2k × 2k zero matrix. Since Gk contains 2k distinct elements, Gk+1 contains 2k + 2k = 2k+1 distinct elements. Furthermore, Gk+1 is closed under multiplication, which can be seen by considering the four possible forms of products that exist and recalling that Gk is closed under multiplication:

⎛g 0⎞
⎛h 0⎞
⎛gh 0 ⎞

⎝0 g
⎠ · ⎝	=


Gk+1
0 gh

⎛g 0⎞
⎛0 h⎞
⎛ 0 gh⎞

⎝0 g
⎠ · ⎝h 0
=
gh 0
⎠ ∈ Gk+1



⎛0 g⎞
⎛0 h⎞
⎛gh 0 ⎞

⎝g 0
⎠ · ⎝h 0
⎠ = ⎝
Gk+1
0 gh



⎛0 g⎞ ⎛h 0⎞
⎛ 0 gh⎞

⎝	⎠ · ⎝


⎠ = ⎝	⎠ ∈ Gk+1




Finally, setting h = g in the first and third expressions above, and recalling that each element of Gk is an involution, also shows that each element of Gk+1 is an involution.
Conversely, suppose that (n, n) contains a copy of the involution group of or- der n. Then by standard results in group theory (the classification of finite abelian groups), n must be a power of two since it is the order of a finite involution group. 2

The involution group Gn in (2n, 2n) can also be derived by taking repeated tensor products of matrices. Specifically, setting G1 = {flip,I} and then using Gn to define Gn+1 = {flip ⊗ g : g ∈ Gn}∪ {I ⊗ g : g ∈ Gn}.

Lemma 4.3 Let Gn = {fi :1 ≤ i ≤ n} be the involution group in (2n, 2n). Then


fi
2n
fi∈Gn
= ⊥∈ (2n, 2n)


and thus the elements of Gn are independent: for any two probability distributions
2n
x, y ∈ Δ ,

2n	2n
Σ xi · fi = Σ yi · fi =⇒ x = y.


Proof. Proof of the first property is by induction. For G1,

1	1	⎛1/2 1/2⎞
2 · flip + 2 · I = ⎝	⎠ = ⊥∈ (2, 2)

Assuming the property holds for Gn, we now prove it holds for Gn+1. We have

Σ	fi  = Σ



1	,gi 0 ⎞ + Σ



1	, 0 gi⎞






1 ,Σ gi/2n	0
⎞	1 ,
0	Σ gi/2n⎞

= 2 ⎝	Σ	n⎠ + 2 ⎝Σ
gi/2n	0	⎠

= 1 ,⊥ 0 ⎞ + 1 , 0 ⊥⎞
2 ⎝ 0 ⊥⎠	2 ⎝⊥ 0 ⎠

= ⊥∈ (2n+1, 2n+1)
This equation implies that the elements of Gn are independent. First, the only entries in fi ∈ Gn are either 0 or 1. Next, if some f ∈ Gn has a 1 in position (i, j) then all other members of Gn have a zero at position (i, j) – otherwise, the equation would be violated.	2
Definition 4.4 Let M be a ﬁnite monoid of order n within a real algebra. Its
convex closure is

⟨M⟩ =
n
i=1
xifi : x ∈ Δ
& fi ∈ M

Because M has only n elements, any convex sum with more than n terms can always be rewritten as having exactly n terms by adding probabilities. Similarly, a convex sum of less than n elements can be extended to one having exactly n elements by adjoining zeroes. Thus, ⟨M⟩ contains all finite convex sums formed with elements of M and is itself a convex set.
Next, if we fix a particular enumeration of the elements of M , say M = {f1,..., fn}, then any two elements x, y ∈ ⟨M⟩ can be written
n	n
x = Σ xifi	&	y = Σ yifi
The reason for this is that we can rearrange terms because addition is commutative (we will be more precise about this shortly). This is a useful trick to remember. For instance, to prove that ⟨M⟩ is a monoid we simply calculate

xy =
n
i=1
xifi
n
i=1
yifi
=
1≤i,j≤n
xiyjfifj =
kΣ=1
zkfk ∈ ⟨M⟩

where zk =	fifj =fk xixj. Notice that the fk in the rightmost sum range over all of M because some fi = 1. Thus, ⟨M⟩ is a convex monoid.
By Lemma 4.3, then, the elements of ⟨Gn⟩ are in one to one correspondence with Δ . This implies the existence of a ‘universal property’ possessed by classical channels:

Theorem 4.5 Let M be a convex monoid that contains a copy of the involution group of order n and G denote the involution group in (n, n). Then there is a function from ⟨G⟩ to M such that for all x, y ∈ ⟨G⟩ and p ∈ [0, 1] we have
ϕ(xy)= ϕ(x)ϕ(y) and
ϕ(px + (1 − p)y)= p ϕ(x)+ (1 − p)ϕ(y)
That is, there is a convex linear homomorphism ϕ : ⟨G⟩→ M.
Proof. First, let V  M denote the involution group of order n. Then because we know that G and V are both isomorphic to Zk with n = 2k, there is an isomorphism
θ : G → V . Define ϕ : ⟨G⟩→ M by
 Σn	Σ
		

	
The value assigned by ϕ belongs to M because M is a convex monoid. What must be proven though is that ϕ is a well-defined function. Suppose we have an element of ⟨G⟩ written in two different ways

n	n
Σ xifi = Σ yigi

For each fi there is some gj = fi. This defines a permutation σ : {1,..., n} → 
{1,..., n} such that gσ(i) = fi. Using the commutativity of addition,

n	n	n	n
Σ xifi = Σ yigi = Σ yσ(i)gσ(i) = Σ yσ(i)fi
and so by Lemma 4.3, xi = yσ(i), for all i. Thus,


n
ϕ
i=1

xifi


=
i=1
n
xiθ(fi)= 
i=1
n
yσ(i)θ(gσ(i))= 
i=1
yiθ(gi)= ϕ
n

i=1

yigi

where the third equality again uses commutativity of addition. This proves ϕ is well-defined.
Now let x, y ∈ ⟨G⟩ be two elements. As just seen, we can write
n	n
x = Σ xifi	&	y = Σ yifi

To show that ϕ is convex linear, we calculate
 Σn
	 	

for p ∈ [0, 1]. To see that ϕ is a homomorphism,

n	n
ϕ(xy)= Σ zkθ(fk)= Σ zkθ(fi)θ(fj)= ϕ(x)ϕ(y)


where xy = Σn
i=1
zkfk and zk = Σ
i=1 fifj =fk
xixj.	2

The proof of the last result actually shows that the statement of the theorem
remains true when G is any involution group that forms an independent set in ⟨G⟩. The consequences of this result for communication are quite profound: any time a collection of channels contains a copy of an involution group, we can study the convex closure of this involution group as though they were classical channels – even if the channels are in fact quantum. Let us now turn to the surprising usefulness of this idea.

How to factor zero in quantum information theory
The Pauli spin operators are {I, σx, σy, σz}, given by


1 0
⎝0 1⎠
0 1
σx	σy
1 0
0	i
⎝i 0 ⎠
1 0
σz
0 −1

Each is self adjoint and unitary, so they are all involutions: σ2 = I for all i ∈
{x, y, z}. Each spin operator defines a unital quantum channel given by
εi(ρ)= σiρσi
Here are the Bloch representations of these channels:


Definition 5.1 The involutions
,1 0	0 ⎞

,−1 0 0 ⎞

,−1 0 0⎞

sx := rx(π)=	−1 0
0 0 −1
are called the spin channels.
s := r (π)= 
0 0 −1
sz := rz(π)=	−1 0
0	0 1

The reason that sx, sy and sz are the Bloch representations of the unital channels corresponding to the spin operators {σx, σy, σz} is that e−iπσx/2 = −iσx, e−iπσy/2 =
−iσy, e−iπσz/2 = −iσz} and that Bloch representations do not depend on phases. In addition, sxsy = sz, sysz = sx and sxsz = sy, so that {I, sx, sy, sz} is the involution group of order four, usually called the Klein four group. Because the set of unital channels U is a convex monoid that contains a copy of the Klein four

group, Theorem 4.5 gives a convex linear homomorphism
ϕ : ⟨G⟩→U 
which sends ϕ(I) = I with G denoting the involution group in (4, 4). This ho- momorphism will now allow us to answer the question of how to randomly flip a quantum bit.
First, the channel ⊥∈ (4, 4) is an algebraic zero in the monoid ⟨G⟩, so e := ϕ(⊥) is an algebraic zero in the image of ϕ. Thus,
sx · e = e & sy · e = e
If we call v = e(r), this means that
(vx, −vy, −vz)= (vx, vy, vz) & (−vx, vy, −vz)= (vx, vy, vz) which means that e is the zero matrix in U . Thus, ϕ(⊥)= 0.
Let us now define x := ϕ−1(sx), y := ϕ−1(sy), z := ϕ−1(sz). By Prop. 4.3,




so we can conclude
1
1
⊥ = 4 (I + x + y + z)

1

0= ϕ(⊥)= 4 (ϕ(I)+ ϕ(x)+ ϕ(y)+ ϕ(z)) = 4 (I + sx + sy + sz).
That is, one way to flip a quantum bit is to randomly choose between the four types of unitary evolution represented by I, sx, sy, sz. We can say more than this though.
Because {I, x, y, z} is the involution group of order 4, we must have z = xy, so we can also write
⊥ = 1 (I + x + y + z)=  I + x   I + y 

and again using the fact that ϕ is a convex linear homomorphism, derive
0=  I + sx   I + sy 

That is, we can nontrivially factor zero into the product of two quantum channels. But what physical process do these two channels describe?
Experimental significance
In the last section, we obtained a nontrivial factorization of zero and did so without doing any quantum mechanics. In fact, all we had to do was work with (4, 4) classical channels. On the surface, this seems very encouraging. However, this

approach leaves open the possibility that the solution we have obtained is of no use experimentally. Let us now show that this is emphatically not the case.
Lemma 6.1 If x is an involution, then its average with the identity




is an idempotent. That is, f 2 = f.
f :=
I + x
2

Proof. We have
f 2 = I · I + I · x + x · I + x · x
4	4	4	4
I	x	x	I
=  +  +  + 
4	4	4	4
I + x
=
2
= f
which finishes the proof.	2


Thus, both of the channels
f := I + sx
2


& g := I + sy
2

are idempotents whose product is f ·g = 0. The canonical example of an idempotent quantum channel of course is a projective measurement since any complete set of projections {Pi} defines an idempotent quantum channel
ε(ρ)=	PiρPi
i
which describes the manner in which the state of the system evolves as a result of the measurement {Pi}. This intuition leads us to wonder if the idempotents f and g can be understood as projective measurements.
Proposition 6.2 The channel f = (I + sx)/2 is the Bloch representation of a measurement in the {|+⟩, |−⟩} basis, while g = (I +sy)/2 is the Bloch representation of a measurement in the {|0⟩, |1⟩} basis.
Proof. Let us first recall that the density operator ρ = |ψ⟩⟨ψ| associated with any qubit |ψ⟩ = a|0⟩ + b|1⟩ is
,|a|2  ab∗⎞	1 , 1+ rz rx − iry⎞

ρ = ⎝
a∗b |b|
2⎠ = 2 ⎝
rx + iry 1 − rz ⎠

where r = (rx, ry, rz) ∈ B3 is the Bloch vector associated to ρ. To prove the first statement, the quantum channel corresponding to a measurement in the {|+⟩, |−⟩} basis is
ε(ρ)= |+⟩⟨+|ρ|+⟩⟨+| + |−⟩⟨−|ρ|−⟩⟨−|
Writing ρ in terms of its Bloch vector (rx, ry, rz) and noting that
,1/2 1/2⎞	, 1/2 −1/2⎞
|+⟩⟨+| = ⎝	⎠	&	|−⟩⟨−| = ⎝	⎠


we calculate
1/2 1/2

ε(ρ)= 1 , 1 rx⎞
x
−1/2 1/2

which says that the Bloch representation of ε takes (rx, ry, rz) to (rx, 0, 0) i.e. it is the idempotent f .
For the second case, the channel which describes a measurement in the {|0⟩, |1⟩}
basis is


Using
ε(ρ)= |0⟩⟨0|ρ|0⟩⟨0| + |1⟩⟨1|ρ|1⟩⟨1|

,1 0⎞	,0 0⎞
|0⟩⟨0| = ⎝	⎠	&	|1⟩⟨1| = ⎝	⎠


we find that
0 0	0 1 
ε(ρ)= 1 ,1+ rz	0	⎞

2 ⎝	0	1 − rz⎠
where (rx, ry, rz) is the Bloch vector associated to ρ. This means g(rx, ry, rz) = (0, 0, rz) is the Bloch representation of a measurement in the {|0⟩, |1⟩} basis.	2

And so we have deriveda physical answer to the question “how do we randomly flip a quantum bit?” The answer: first measure the system in the X basis and then measure it in the Z basis, or vice-versa. These are operations that are routinely used in laboratories today. For instance, realizations of QKD (BB84) require them. Notice that this answer from a security standpoint is very different from saying “randomly choose one of the spin operators” for the simple fact that we must then confront the issue of how to randomly choose between spin operators. The result above – that zero can be factored as a product of measurements – is quite different. The problem of randomness is entirely left to Nature. All we have to do is perform two successive measurements and Nature provides the randomness for free: our actions are entirely deterministic. This factorization is possible because the representations of the spin operators are closed under multiplication. Another take on the factorization of zero is that it amounts to bit flipping with probability 1/2 followed by phase flipping with probability 1/2 (or vice-versa).

A mathematical aside
The homomorphism ϕ : ⟨G⟩ → U is an isomorphism onto its image, the convex closure of the spin channels. The reason is that the spin operators also form an independent set within their convex closure. This implies an isomorphism between
⟨G⟩, Im(ϕ) and Δ . Because Δ  forms a ‘domain’ in the sense of [2], it is then
possible to extend algebraic information theory to the important class of channels
⟨G⟩. Mysteriously, channels of exactly this type have also arisen in the analysis of spatial domain image steganography [3].
Summary
This paper makes contributions to three different areas:
In quantum security, it gives us an experimentally realizable method for randomly flipping qubits, which can be used to interrupt communication schemes or to remove steganographic messages from quantum data,
In information theory, it shows that some problems in quantum information can be solved by reasoning only about classical channels,
In group theory, it shows that the involution group can be constructed using channels from Shannon’s information theory, and establishes its significance in both classical and quantum communication
We find the interplay between these three areas fascinating.

References
E.E. Majani and H. Rumsey, Two results on binary-input discrete memoryless channels. Proceedings of the IEEE International Symposium on Information Theory, p.104–104, 1991.
K. Martin, I.S.Moskowitz and G. Allwein, Algebraic information theory for binary channels. Electronic Notes in Theoretical Computer Science, Vol. 158, MFPS 2006, Special Session on Security, p.289–306, 2006.
I.S. Moskowitz, P. A. Lafferty and F. Ahmed, On LSB spatial domain steganography and channel capacity. Naval Research Laboratory Memorandum Report, 2008.
M. Nielsen and I. Chuang, Quantum computation and quantum information. Cambridge University Press, 2000.
C. E. Shannon. A mathematical theory of communication. Bell Systems Technical Journal 27, 379–423 and 623–656, 1948.
