Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 319 (2015) 271–287
www.elsevier.com/locate/entcs

Sequential Algorithms for Unbounded Nondeterminism
J. Laird1
Department of Computer Science, University of Bath, UK

Abstract
We give extensional and intensional characterizations of higher-order functional programs with unbounded nondeterminism: as stable and monotone functions between the biorders of states of ordered concrete data structures, and as sequential algorithms (states of an exponential ocds) which compute them. Our fundamental result establishes that these representations are equivalent, by showing how to construct a unique sequential algorithm which computes a given stable and monotone function.
We illustrate by defining a denotational semantics for a functional language with countable nondeterminism (“fair PCF”), with an interpretation of fixpoints which allows this to be proved to be computationally adequate. We observe that our model contains functions which cannot be computed in fair PCF, by identifying a further property of the definable elements, and so show that it is not fully abstract.
Keywords: Sequential Algorithms, Nondeterminism, Fairness, Biorders


Introduction
This paper develops a model of higher-order computation with unbounded non- determinism. In this setting we may write programs which will always return a value but may take an unbounded number of steps to do so, corresponding to the notion of fairness [6]. A major challenge for capturing such programs is that they do not correspond to continuous functions, in general. In domain theory, this may be resolved by weakening the continuity properties required (e.g. to ω1-continuity [1]), although this admits many undefinable functions and leaves fewer principles with which to reason about program behaviour. A more intensional representation of programs (for example, as strategies in a games model) offers the possibility of studying unbounded nondeterminism in computation more directly, although tra- ditional representations of strategies as collections of finite sequences of moves are insufficient to capture the distinction between infinite interactions and finite, but unbounded ones [7].

1 Research supported by UK EPSRC grant EP/K037633/1

http://dx.doi.org/10.1016/j.entcs.2015.12.017
1571-0661/© 2015 The Author. Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

We take an approach which relates extensional and intensional representations of programs with unbounded nondeterminism: our main result is an equivalence be- tween stable and monotone functions and sequential algorithms on ordered concrete data structures. We show that these equivalent representations may be used to in- terpret a simple functional programming language with unbounded nondeterminism (fair PCF). We show that this model contains elements which are not definable as terms, leading to a failure of full abstraction and suggesting how it could be further refined.

Related Work
Our model is based on an intensional description of stable and monotone func- tions on biorders generated from ordered concrete data structures. Biorders, which combine some intensional information, in the form of the stable order, with the ex- tensional (Scott) order, were introduced by Berry [2]. In previous work, the author has shown that stable and continuous functions on biorders with a (extensionally) greatest element are (Milner-Vuillemin) sequential, and used them to construct mod- els of sequential languages such as the lazy λ-calculus [12], as well as λ-calculi with nondeterminism [11]. However, although these models technically carry information about program behaviour, they do not do so in a transparent way.
Concrete data structures were introduced by Kahn and Plotkin [9], as part of a definition of sequentiality for higher-order functionals, but the more intensional no- tion of sequential algorithm (a state of a “function-space” CDS) introduced by Berry and Curien [3] offers an appealing model of computation in its own right. On the one hand, concrete data structures correspond to a positional form of games, and sequential algorithms to positional strategies (see e.g. [8]). On the other, sequential algorithms may be related to purely extensional models: in the deterministic case, Cartwright, Curien and Felleisen [4] have established that they compute, and are equivalent to “observably sequential” functions; the author has given a more ab- stract representation of the latter as bistable functions on bistable biorders [12,10]. To interpret sequential, but nondeterministic programs (corresponding to sta- ble and monotone functions on Berry-style biorders, which are sequential, but not strongly sequential ) as sequential algorithms, we abandon the consistency condition on states (that any cell may be filled with at most one value). However, this also requires an ordering on cells and values (corresponding to game positions), to reflect the fact that (for example) any program which may diverge in response to a given argument may still diverge in response to an argument with a wider range of be- haviours. This notion of an ordered concrete data structure was introduced in [13] in which stable and continuous functions were shown to correspond to ﬁnite-branching sequential algorithms. Interestingly, the stable order on non-deterministic sequen- tial algorithms had been described by Roscoe [15] on processes in CSP — the “strong order” — in work approximately contemporaneous with the discoveries of bidomains and of sequential algorithms. Here, we extend the correspondence between stable functions and sequential algorithms to unbounded nondeterminism. This requires a new notion of ordinal-indexed interaction, to distinguish computations which are



Table 1
Operational Semantics for Fair PCF

infinite from those which are finite but unbounded.

PCF With Unbounded Nondeterminism
In order to illustrate the interaction between higher-order functions, recursion and unbounded nondeterminism, we introduce a programming language which combines them — an extension of PCF with natural number choice — for which we will give a denotational semantics. In other words, we add to the simply-typed λ-calculus over the single ground type nat, the following constants 2 :
Numerals 0 : nat and suc : nat → nat.
Conditional If0 : nat → nat → (nat → nat) → nat. 3
Fixpoints: Y : (T → T ) → T for each type T .
Error and Choice: T : nat and ? : nat.

Operational Semantics
The (small-step) reduction relation for closed terms is defined in Table 1. We study a must-testing semantics (unbounded choice is definable from bounded choice up to may-testing equivalence: a sequential algorithms semantics for the latter was presented in [13]). Define ⇓ (must-convergence) to be the least predicate on programs (closed terms of type nat) such that for any program M , if Mj ⇓ for all programs Mj such that M −→ Mj then M ⇓. (So, in particular, every numeral is must-convergent, and if M1 −→ M2 −→ ... −→ Mn −→ ... then none of the Mi are must-convergent.) Thus we may define must-approximation (.) and must- equivalence ( ) as the least precongruence and congruence on terms (respectively) such that if M . N or M  N then M ⇓ implies N ⇓. Clearly, . is a partial order on the  -equivalence classes of closed terms at each type.

2 Our denotational semantics can also interpret the catch operator of observably sequential PCF, but we omit this since our focus is not on full abstraction.
3 If its first argument evaluates to suc(n), this passes n to its third argument, so we may define pred :
nat → nat = λx.((If0 x) 0) λy.y.

Examples
Evidently, we may express bounded choice (up to must-equivalence) using countable choice — e.g. defining M or N = If0 ? then M else λx.N . But attempting to de- fine countable choice using bounded choice — e.g. as (Yλf.λx.(x or (f (suc x)))) 0
— will fail (evaluation may always take the right hand branch and so diverge).
To express (for example) the fair merge of infinite streams of objects of type T , the latter may be represented as objects of type nat → T (i.e. head(M ) = M 0, tail(M ) = λx.M (suc x) and M :: N = ((If0 y) M ) N . The fair merge function, merge : (nat → T ) → (nat → T ) → nat → T returns any interleaving of its arguments which includes all entries from both lists by alternately taking a non- empty initial segment of unbounded length from each stream.
(Yλfλxλuλv.If0 x then((f suc(?) v u)) else λy.head(u)::((f y tail(u) v))) ?
Conversely, we may express countable choice in terms of fair merge — e.g. by returning the position of the first zero in a fair merge of the stream of 1s with the stream of 0s:
(Yλf.λx.λy.If0 head(x) then y else (f tail(x) (suc(y)))) (merge (λx.0 )(λx.1)) 0
For each i ∈ N, define ?i : nat by ?0 =? and ?i+1 = suc?i. Then (we claim: proof via the denotational semantics is straightforward) ?i .?i+1 for each i ∈ N, and T is a .-least upper bound for the chain ⟨?i | i ∈ N⟩. This may be used to show that many first-order functions definable in fair PCF are not .-continuous. For example, λx.If0 x then 0 else Ω: nat → nat: If0 ?i then 0 else Ω diverges for all i, but If0 T then 0 else Ω converges.
Note that this example also shows that application is not .-continuous with re- spect to functions as well as arguments — i.e. λf.(f T) isa .-least upper bound for the chain of terms ⟨Mi = λf.(f ?i) | i ∈ ω⟩ but Mi λx.If0 x then 0 else Ω diverges for all i, whereas (λf.f T) λx.If0 x then 0 else Ω converges. This creates difficul- ties for defining well-behaved least fixed points for functions, which we will resolve semantically by working with the stable order, for which application is continuous with respect to functions (although not arguments).
Complete Biorders
We generalize the notion of biorder [2,5] to infinite meets (corresponding to infinite branching under a must-testing interpretation).
Definition 3.1 A complete biorder is a complete (meet) lattice (|D|, ±) with a second partial order ≤s on |D| such that:
If x ≤s y then x ± y.
⊥ ≤s x for all x ∈ D (where ⊥ = . D).
For any X, Y ⊆ D, if X ≤ Y (meaning: ∀x ∈ X∃y ∈ Y.x ≤ y ∧ ∀y ∈ Y.∃x ∈
X.x ≤s y) then . X ≤s . Y ).

We write ↑ X if X ⊆ |D| is bounded above in the stable order.
Lemma 3.2 If ↑ X then . X is the greatest lower bound for X in the stable order.
Proof. Supposing x ≤s y for all x ∈ X:
For any x ∈ X, X ≤s {x, y} and so . X ≤s x = .{x, y}.
If z ≤s x for all x ∈ X, then {z} ≤s X and so .{z} ≤s . X.
2
Definition 3.3 A function between biorders f : D → E is said to be monotone stable if it preserves both orders, and is conditionally multiplicative — i.e. if ↑ X,
then f (. X)= . f (X).
Let CB be the category in which objects are complete biorders and morphisms from D to E are monotone stable functions from D to E.
Proposition 3.4 CB is Cartesian closed.
Proof. Products are defined pointwise. The internal hom [D, E] is the lattice of

monotone stable functions (i.e. (. F )(x) = .
defined:

f∈F
f (x)), with the stable ordering

f ≤s g if for all x, y ∈ D, x ≤s y =⇒ f (x) ≤s g(y) and g(y)= f (y) H g(x).
2
Ordered Concrete Data Structures
A concrete data structure [9,3] consists of sets of cells, values and events (which are pairs of cells and values), and an enabling relation between events and cells. The idea is that each step of a sequential computation is represented as an event (the filling of a cell with a value), which may be dependent on some combination of previous events having occurred (as specified by the enabling relation). This may be considered as a two-player game between the environment, which may propose an enabled cell to be filled, and the program, which can then fill it with a value. Deterministic programs correspond to deterministic strategies for this game which specify a unique value for filling enabled cells. They are represented as states: sets of events which satisfy two conditions: consistency — every cell must be filled with a unique value — and safety — for every filled cell there is a finite chain of enablings of filled cells within the state, back to an “initial cell” which does not depend on any prior events. In order to model unbounded nondeterministic computation with must-testing we adapt this setting in the following ways:
Removing the consistency condition on states, so that a cell may be filled with multiple different values.
Placing an ordering on cells and values, (and thus events) and requiring states to be upwards closed under this ordering. This reflects the fact that (for example) the response of a function to an argument which is a nondeterministic choice of x and y must include all of its responses to both x and y.

Including a distinct element ⊥ — representing divergence — with which any cell may be filled (cf. the representation of divergence in the game semantics of must-testing in [7]).
Extending the safety condition to allow infinite chains of enabling events. (This captures the distinction between infinite interaction, and that which is finite but unbounded.)
Definition 4.1 A (filiform) ordered concrete data structure (ocds) A is a tuple (C(A),V (A), ▶A, E(A)) where C(A),V (A) (the cells and values of A) are partial orders not containing the distinguished element ⊥, E(A) ⊆ C(A) × V (A) is a set of events and ▶A⊆ (E(A) ∪ {∗}) × C(A) is a relation (enabling ) such that (c, v) ▶ cJ implies c < cJ.
We write E(A)⊥ for the partial order E(A) ∪ (C(A) × {⊥}), with (c, ⊥) ≤ (cJ, v) if
c ≤ cJ.
A simple example of an ocds, which we shall use to interpret the type of natural numbers, is N = ({c}, N, {(∗, c)}, {c}× N), which has a single initial cell which may be filled with any natural number value.
Definition 4.2 A proof of an event e is an ordinal sequence of events ⟨(cα, aα) | α ≤
κ⟩ such that eκ ≤ e and for α ≤ κ:
If α =0 then ∗▶ cα (c0 is initial),
If α = β +1 then eβ ▶ cα,

If α = W

β<α
β, then cα = W
cβ.

We write x ▶∗ e if there is a proof of e, all of the elements of which are in x.
Note that for any proof ⟨(cα, vα)| α ≤ κ⟩, if β < α ≤ κ then cβ < cα.
Definition 4.3 A state of an ocds A is a set of events x ⊆ E(A)⊥ satisfying:
Upwards Closure If e ∈ x and e ≤ eJ then eJ ∈ x.
Safety If e ∈ x then x ▶∗ e.
We write D(A) for the set of states of A. A state x is total if x ⊆ E(A) (i.e. no cell is filled with ⊥ in x).
Thus, the total states in D(N ) are in one-one correspondence with the subsets of N, and there is a single divergent state ⊥ = E(N )⊥. For a state x ∈ D(A), we define the following sets of cells (subsets of C(A)):
F (x)= {c ∈ C(A) | ∃a ∈ V (A)⊥.(c, a) ∈ x} — the set of ﬁlled cells of x.
En(x)= {c ∈ C(A) | x ▶∗ (c, ⊥)} — the set of enabled cells of x.
A(x)= En(x) − F (x) — the set of accessible cells of x.
If c ∈ En(x) and (c, a) ∈ E(A)⊥, we write x + (c, a) for the state x ∪ {e ∈
E(A)⊥ | (c, a) ≤ e}. We will also write x + (c, V ) for S	(x + (c, v)).

Ordered Concrete Data Structures as Complete Biorders
We now need to define extensional and stable orders on D(A), to obtain a complete biorder. Roughly speaking, states x and y should be in the stable order if and only if at any point x can either behave in the same way as y (i.e. fill an enabled cell with the same value) or else diverge. In deterministic sequential data structure models, in which divergence is represented implicitly by non-filling of cells, this is inclusion of states. In our model, which has explicit divergences and is saturated under the order on events, (reverse) inclusion is an extensional order (every event in y dominates an event in x), and we define the stable order as follows:
x ≤s y if and only if y ⊆ x and if (c, v) ∈ x then (c, v) ∈ y or (c, ⊥) ∈ x.
Esssentially, both of these orders were introduced by Roscoe (under the name of the deﬁnedness and strong orders) for process in the failures model of CSP [15] in which, of course, divergence is represented explicitly.
Proposition 4.4 For any OCDS A, (D(A), ⊇, ≤s) is a complete biorder.
Proof. Since any union of states satisfies the safety and up-closure conditions, (D(A), ⊇) is a complete (meet) lattice, (with least element ⊥A = S D(A)). By
definition, the stable order is contained within the extensional order. ⊥A ≤s x
for all x, since (c, v) ∈ ⊥A implies (c, ⊥) ∈ ⊥A. Suppose X ≤s Y : then for all (c, a) ∈ Y , there exists y ∈ Y with (c, a) ∈ y and hence x ∈ X with (c, a) ∈ x and
so (c, a) ∈ x ⊆ S X. Conversely, if (c, a) ∈ S X then there exists x ∈ X such that
(c, a) ∈ x, and y ∈ Y with x ≤s y, and so either x ∈ y ⊆ S Y , or (c, ⊥) ∈ x ⊆ S X. Hence S X ≤s S Y as required.	2
Note that if ↑ X then for all x, y ∈ X, if (c, v) ∈ x then either (c, ⊥) ∈ x or (c, v) ∈ y. Given C ⊆ En(x), let xC = Sc∈C (x + (c, ⊥)). The stable order may be characterized as follows.
Proposition 4.5 y ≤s x iff y = xC for some C ⊆ En(x).
Proof. Evidently, xC ≤s x, so it suffices to show that every element y ≤s x has this form. Let C = {c ∈ En(x) | (c, ⊥) ∈ y}, so that xc ⊆ y. We claim that y ⊆ xC: suppose (c, a) ∈ y, but (c, a) /∈ x. Let ⟨cα, vα | α < κ⟩ be a proof of (c, a) in y. Then there exists a least value α such that (cα, vα) /∈ x. So cα ∈ E(x), and (c, ⊥) ∈ y by stability and so cα ∈ C. Since cα ± c, (c, a) ∈ xC as required.	2
Sequential Algorithms
By Proposition 4.4, we may define a category OC in which objects are ordered concrete data structures and morphisms from A to B are monotone stable functions from D(A) to D(B). This has cartesian products, given by the disjoint union of ocds: (C1, V1, E1, ▶1) × (C2, V2, E2, ▶2) = (C1  C2, V1 ∪ V2, {(c.1, v) | (c, v) ∈
E1}∪ {(c.2, v) | (c, v) ∈ E2}, {(c.i, v), d.i) | ((c, v), d) ∈ Ei,i ∈ {1, 2}}.
The fully faithful (identity-on-morphisms) functor D : OC → CB which sends each ocds A to D(A) preserves products. So to establish Cartesian closure of OC it

suffices to define an exponent ocds A ⇒ B for each A, B, such that D(A ⇒ B) ∼= [D(A), D(B)] in CB. This is a key result, since it establishes that every monotone stable function between the biorder of states of an ocds is computed by a unique state of A ⇒ B or sequential algorithm.
We define the ordered concrete data structure A ⇒ B (cf. the analogous defini- tion of unordered concrete data structure [3]) as follows :
Cells A cell of A ⇒ B is given by a pair of a total state of A and a cell of B: C(A ⇒ B) = (D(A) ∩ P(E(A))) × C(B) — with (x, c) ≤ (xj, cj) if x ⊆ xj and c ≤ cj.
Values A value of A ⇒ B is either a cell from A or a value from B — the order being determined pointwise from that of V (B) and the dual of C(A):
V (A ⇒ B)= C(A)c  V (B) 4 .
Events A cell (x, c) of A ⇒ B may be ﬁlled with either a cell accessible from x in
A or a value in B which can fill c: E(A ⇒ B)= 
{((x, c), cj) | (x, c) ∈ C(A ⇒ B) ∧ cj ∈ A(x)}
∪{((x, c), v) | (x, c) ∈ C(A ⇒ B) ∧ (c, v) ∈ E(B)}.
Enabling The event ((x, c), cj) enables the cell (xj, c) if xj is obtained from x by filling cj:
The event ((x, c), v) enables the cell (x, cj) if (c, v) enables cj in B: ▶A⇒B
= {(((x, c), cj), (xj, c)) ∈ E(A ⇒ B) × C(A ⇒ B) | ∃V ⊆ V (A).xj = x + (cj,V )}
∪{(((x, c), v), (x, cj)) ∈ E(A ⇒ B) × C(A ⇒ B) | (c, v) ▶B cj}.
A sequential algorithm from A to B is a state of A ⇒ B.
Stable Functions from Sequential Algorithms
We need to establish that D(A ⇒ B) and [D(A), D(B)] are isomorphic in CB. We first show that every sequential algorithm σ ∈ D(A ⇒ B) computes a monotone stable function fun(σ) from D(A) to D(B). Given a state x, let fun(σ)(x)= 
{(c, a) ∈ E(B)⊥ | ∃xj ⊆ x.((xj, c), a) ∈ σ ∨ ∃cj.(cj, ⊥) ∈ x ∧ ((xj, c), cj) ∈ σ}
We need to show that fun(σ) is a well-defined, monotone stable function.
Lemma 5.1 For any x, fun(σ)(x) is a state.
Proof.
Upwards closure Suppose (cj, aj) ≥ (c, a) ∈ fun(σ)(x). If there exists xj ⊆ x with ((xj, c), a) ∈ σ then ((xj, cj), aj) ≥ ((xj, c), a) and so ((xj, cj), aj) ∈ σ and (cj, aj) ∈ fun(σ)(x).
If there exists (cjj, ⊥) ∈ x such that ((xj, c), cjj) ∈ σ then ((x, cj), cjj) ≥ ((xj, c), cjj) so ((xj, cj), cjj) ∈ σ and hence (cj, aj) ∈ fun(σ)(x).
Safety Suppose (c, a) ∈ fun(σ)(x). Then then there exists ((y, c), b) ∈ σ with
y ⊆ x, and a proof of (y, c) in σ which therefore restricts to a proof of c in f (y).

4 We will elide any explicit tagging, assuming that the sets of cells of A and values of B are disjoint.

2
Lemma 5.2 If ↑ X and (c, a) ∈ fun(σ)(S X) then either (c, a) ∈ X for all x ∈ X
or (c, ⊥) ∈ fun(σ)(xj) for some xj ∈ X.
Proof. If (c, a) ∈ fun(σ)(S X) then there exists an event e ∈ σ such that either e = ((w, c), a), where w ⊆ S X or e = ((w, c), cj), where w +(cj, ⊥) ⊆ S X. If w ⊆ x for every x ∈ X then in the first case (c, a) ∈ S fun(σ)(X), and in the second case
there exists xj ∈ X with w + (cj, ⊥) ⊆ xj and so (c, ⊥) ∈ fun(σ)(xj).
So suppose w /⊆ x for some x ∈ X. Fixing a proof of e in σ, let ej = ((wj, cj), aj) be the first element in this proof such that wj /⊆ x for some x ∈ X. Then there is
an immediately preceding event ((wjj, cj), cjj) such that wj = wjj + (cjj,V ) for some set of values V , including a value u such that (cjj, u) /∈ x. Because wj ⊆ S X, there
exists xj ∈ X with (cjj, u) ∈ xj. Since x ↑ xj, therefore (cjj, ⊥) ∈ xj, and hence
(cj, ⊥) ∈ fun(σ)(y). Since cj ± c, we have (c, ⊥) ∈ fun(σ)(xj) as required.	2
Proposition 5.3 For any sequential algorithm σ, fun(σ) is monotone stable.
Proof. Evidently, if x ⊇ y then fun(σ)(x) ⊇ fun(σ)(y). If x ≤s y, then f (x) ≤s
f (y): suppose (c, v) ∈ f (x) = f (x ∪ y) and so by Lemma 5.2, (c, v) ∈ f (y) or (c, ⊥) ∈ f (y). If ↑ X, then fun(σ)(S X)= S fun(σ)(X): if (c, a) ∈ fun(σ)(S X) then by Lemma 5.2, either (c, a) ∈ fun(σ)(x) for all x ∈ X, and so (c, a) ∈ S fun(σ)(X), or (c, a) ≥ (c, ⊥) ∈ S fun(σ)(X).	2
We now show that fun itself is a monotone stable function.
Lemma 5.4 If σ ≤s τ then fun(σ) ≤s fun(τ ).
Proof.
For all x, fun(σ)(x) ≤s fun(τ )(x). Suppose (c, v) ∈ fun(σ)(x) but (c, ⊥) /∈ fun(σ)(x). Then there exists xj ⊆ x with ((xj, c), v) ∈ σ and ((xj, c), ⊥) /∈ σ and so ((xj, c), v) ∈ τ and (c, v) ∈ fun(τ )(x) as required.
For all x ≤s y, fun(σ)(x)= fun(τ )(x) ∪ fun(σ)(y). Suppose (c, a) ∈ fun(σ)(x), we need to show that (c, a) ∈ fun(τ )(x) or (c, a) ∈ fun(σ)(y). By Proposition 5.3, if (c, a) /∈ fun(σ)(y), then (c, ⊥) ∈ fun(σ)(x), and so we may assume that a = ⊥.
So either there exists an event ((z, c), ⊥) ∈ σ with z ⊆ x or else there exists z + (cj, ⊥) ⊆ x such that ((z, c), cj) ∈ σ. But this latter case reduces to the first one, since either ((z, c), cj) ∈ τ (and so (c, ⊥) ∈ fun(τ )(x) and we are done), or else ((z, c), ⊥) ∈ σ.
Assuming (c, ⊥) /∈ fun(σ)(y), let P be a proof of ((z, c), ⊥) in σ, and let ((zj, cj), a) be the least element of P such that zj /⊆ y. Then there must be an im- mediately preceding event in P of the form ((zjj, cj), cjj), where zj = zjj + (cjj,V ) for some V , and hence zjj + (cjj, ⊥) ⊆ x, as ↑ {x, y}. If ((zjj, cj), cjj) ∈ τ then (c, ⊥) ∈ fun(τ )(x). Otherwise ((zjj, cj), ⊥) ∈ σ and so (cj, ⊥) ∈ fun(σ)(y), and so (c, ⊥) ∈ fun(σ)(y) as required.
2

Noting that for any set of states S ⊆ D(A ⇒ B), fun(S S) = S  fun(σ) by construction — i.e. fun is additive — we have shown that:
Proposition 5.5 fun : D(A ⇒ B) → [D(A), D(B)] is a monotone stable function.

Stable Functions and Sequentiality
Concrete data structures were introduced in order to give a description of sequen- tiality for higher-order functionals [9]. Essentially, a function between (the sets of states of) concrete data structures A and B is Kahn-Plotkin sequential if any argu- ment (state) x of A, and cell c of B which is filled in f (y) for some y which extends x, can be associated with a cell, accessible from x, which must be filled in any state z (which extends x) such that c is filled in f (z). However, in this original setting, divergence is represented implicitly, by not filling an enabled cell (rather than as an explicit divergence by filling a cell with ⊥), and inclusion of states corresponds to the stable order. Thus we translate this original definition of Kahn-Plotkin sequen- tiality to the current setting by (essentially) replacing the role of “accessible cell” with that of “cell filled with ⊥”, and “filled cell” with “enabled cell not filled with
⊥”. We define a partial order (≤) on total states (which plays the role of the stable
order in the original definition of Kahn-Plotkin sequentiality): x ≤ y if x ⊆ y and if c ∈ F (x) then (c, v) ∈ y implies (c, v) ∈ x.
Definition 5.6 A function f : D(A) → D(B) is explicitly sequential if whenever x, y are total states such that x ≤ y then for any event (c, v) ∈ f (y), either (c, v) ∈ f (x), or there exists cj ∈ A(x) ∩ F (y) such that if ↑ {x, z} and (cj, ⊥) ∈ z then (c, ⊥) ∈ f (z).
We will now show that all monotone stable functions are explicitly sequential.
Lemma 5.7 If x ≤ y then y ⊆ xA(x)∩F (y).
Proof. Suppose (c, v) ∈ y but (c, v) /∈ x. Let P be a proof of c in y, and (cj, vj) the least element of P which is not in x. Then cj is accessible (enabled but not filled) in x, as x ≤ y — i.e. cj ∈ A(x) ∩ F (y), so (c, v) ≥ (cj, ⊥) ∈ xA(x)∩F (y).	2
Proposition 5.8 Any monotone stable function from D(A) to D(B) is explicitly sequential.
Proof. Suppose x ≤ y and (c, v) ∈ f (y) but (c, v) /∈ f (x). Since y ⊆ xA(x)∩F (y), we have (c, v) ∈ f (xA(x)∩F (y)) and since f (xA(x)∩F (y)) ≤s f (x), we have (c, ⊥) ∈ f (xA(x)∩F (y)).
By conditional multiplicativity, f (xA(x)∩F (y))= Sc′∈A(x)∩F (y) f (x + (cj, ⊥)) and
so there is a cell cj ∈ A(x) ∩ F (y) such that (c, ⊥) ∈ f (x + (cj, ⊥)) as required. 2
We establish the converse — that every explicitly sequential function is mono- tone stable — by showing below that every explicitly sequential function from D(A) to D(B) is computed by a state of A ⇒ B, which corresponds via fun to a monotone stable function from D(A) to D(B).

Sequential Algorithms from Stable and Monotone Functions
We will use the sequentiality property to establish that fun : D(A ⇒ B) → [D(A), D(B)] is an isomorphism by defining its inverse, strat : [D(A), D(B)] → D(A ⇒ B). Given a monotone stable function f : D(A) → D(B), define strat(f ) ∈ D(A ⇒ B) to be the set of events:
{((x, c), a) ∈ C(A ⇒ B) × V (B)⊥ | (c, a) ∈ f (x)}
∪{((x, c), cj) ∈ C(A ⇒ B) × C(A) | (c, ⊥) ∈ f (x + (cj, ⊥))}
Lemma 5.9 strat(f ) is an upper set.
Proof. Suppose ((xj, cj), aj) ≥ ((x, c), a) ∈ strat(f ). If a, aj ∈ V (B)⊥ — i.e. (c, a) ∈
f (x)— then (cj, aj) ≥ (c, a) ∈ f (xj) ⊇ f (x), and so ((xj, cj), aj) ∈ strat(f ). If a, aj ∈ C(A), so that aj ≤ a and hence x +(a, ⊥) ⊆ xj +(aj, ⊥), then (c, ⊥) ∈ f (xj +(aj, ⊥)) and so ((xj, cj), aj) ∈ strat(f ) as required.	2
Lemma 5.10 strat(f ) satisﬁes the safety property.
Proof. We construct a proof of each event ((x, c), a) in strat(f ) using the explicit sequentiality property for f . Suppose a ∈ V (B)⊥ and fix a proof ⟨(cβ, vβ) | β ≤ λ⟩ of (c, a) in f (x).
For each ordinal α, we define:
A state xα ≤ x.
An ordinal κ(α) ≤ α
An event eα ∈ E(A ⇒ B) such that eα = ((xα, cκ(α), vκ(α)) or eα = ((xα, cκ(α)), cj) for some cj ∈ F (x).
such that if κ(α) < λ, then ⟨eγ | γ ≤ α⟩ is a proof of eα.
Let x0 = {} and κ(0) = 0,
For all α, if (cκ(α), vκ(α)) ∈ f (xα) then let eα = ((xα, cκ(α)), vκ(α)) and xα+1 = xα
and κ(α + 1) = min{λ, κ(α)+ 1}.
Otherwise, by the explicit sequentiality of f (Proposition 5.8) there is a cell
cj ∈ A(xj) ∩ F (x) such that (cκS(α), ⊥) ∈ f (xα + (cj, ⊥)) and so we may set

eα = ((xα, cκ(α)), cj), and xα+1 =
If α = S{β < α} then xα = S
{xα +(cj, v) | (cj, v) ∈ x} and κ(α + 1) = κ(α). xβ and κ(α)= S{κ(β) | β < α}.

Since κ(α) /= λ implies eα /= eβ for all β < α, there must be some (least) α (no greater than the cardinality of E(A ⇒ B)) such that κ(α)= λ and so ⟨ej | β ≤ α⟩ is a proof of ((x, c), a) in strat(f ). The case in which a is a cell in C(A) is similar.2
Proposition 5.11 For any monotone stable function f : D(A) → D(B), strat(f )
is a well-deﬁned state of A ⇒ B.
We now show that (fun, strat) are an isomorphism between D(A ⇒ B) and [D(A), D(B)]. Given a state x ∈ D(A), let xT be the upper closure of {(c, v) ∈ x | (c, ⊥) /∈ x}.
Lemma 5.12 xT is a well-deﬁned (total) state.

Proof. xT is by definition an upper set. For safety, suppose (c, v) ∈ x: for any event (cj, vj) in any proof of c, cj ≤ c and so if (cj, v) /∈ xT then (c, v) /∈ xT — i.e. if (c, v) ∈ x then any proof of c in x is a proof of c in xT.	2
By definition, if (c, v) ∈ x then either (c, ⊥) ∈ x or (c, v) ∈ xT — i.e. x ≤s xT.
Lemma 5.13 For any monotone stable function f : D(A) → D(B) and state x ∈
D(A): fun(strat(f ))(x)= f (x).
Proof. Suppose (c, a) ∈ fun(strat(f ))(x). Then either:
there exists a total y ⊆ x with ((y, c), a) ∈ strat(f ), and so (c, a) ∈ f (y) ⊆ f (x).
or there exists y ⊆ x with ((y, c), cj) ∈ strat(f ) and (cj, ⊥) ∈ x, and so (c, ⊥) ∈
f (y + (cj, ⊥)) ⊆ f (x).
For the converse, suppose (c, a) ∈ f (x). If (c, a) ∈ f (xT) then ((xT, c), a) ∈ strat(f ), and so (c, a) ∈ fun(strat(f ))(x) as required.
Otherwise (c, ⊥) ∈ f (x), and by the explicit sequentiality of f (Proposition 5.8), there exists cj ∈ A(xT) ∩F (y) such that (cj, ⊥) ∈ x and (c, ⊥) ∈ f (xT + (cj, ⊥)) and so ((xT, c), cj) ∈ strat(f ) and (c, a) ∈ fun(strat(f ))(x) as required.	2
Lemma 5.14 For all sequential algorithms σ ∈ D(A ⇒ B), strat(fun(σ)) = σ.
Proof. Suppose ((x, c), a) ∈ E(A ⇒ B)⊥. Then:
If a ∈ V (B)⊥ then ((x, c), a) ∈ σ if and only if (c, a) ∈ fun(σ)(x) if and only if ((x, c), a) ∈ strat(fun(σ)).
If a ∈ C(A) then ((x, c), a) ∈ σ if and only if (c, ⊥) ∈ fun(σ)(x + (cj, ⊥)) if and only if ((x, c), a) ∈ strat(fun(σ)).
2
Theorem 5.15 fun : [D(A), D(B)] → D(A ⇒ B) is an isomorphism, with inverse
strat : D(A ⇒ B) → [D(A), D(B)].
Denotational Semantics for Fair PCF
Types are interpreted as ordered concrete data structures: the type nat denotes the OCDS N of natural numbers and S → T the exponential OCDS [S]] ⇒ [[T ]]. Terms x1 : S1,..., xn : Sn ▶ M : T denote monotone stable functions from [S1]] ×... × [[Sn]] to [T ]]: T denotes the (constant function returning the) empty state and ? the state
{(c, i) | i ∈ N} in which the single cell is filled with every value (but not ⊥). There are evident functions denoted by suc and If0, and so it remains to show that the constant Y may be interpreted as a fixed point. By the Tarski-Knaster theorem, any monotone function f : D(A) → D(A) has a ±-least fixed point, since D(A) is a lattice under the extensional order. However, because function application is not continuous in the extensional order, we do not know how to prove that this fixed point delivers a computationally adequate model. Instead, we will show that fixed points may be constructed as stable least upper bounds of chains of approximants.

Definition 6.1 Say that an ocds is stably complete if for any stably directed set of states X (i.e. for all x, y ∈ X there exists z ∈ X with x, y ≤s z),  X is a stable least upper bound for X.
There are pathological examples of ocds in which this property fails, but we can show that it holds for every object denoting a PCF type (which is evident in the case of nat).
Proposition 6.2 If B is stably complete, then A ⇒ B is stably complete.
Proof. We show that the internal hom [D(A), D(B)] has suprema of stably directed sets, and hence so does D(A ⇒ B), and then observe that these are given by the intersection operation. Suppose F ⊆ [D(A), D(B)] is stably directed. For
any x ∈ D(A), {f (x) | f ∈ F} is stably directed, so we may define (W F )(x) = 
 {f (x) | f ∈ F}. This is evidently monotone with respect to the extensional and stable orders. To establish conditional multiplicativity, we need to show that if
↑ X then (W F )(. X) ⊆ .(W F )(X). Suppose e /∈ S	(W F )(x) and choose any
x ∈ X: there exists f ∈ F with e /∈ f (x). Now consider any y ∈ X: there exists
g ∈ F such that e /∈ g(y), and h ∈ F such that f, g ≤ h and so e /∈ h(x ∪ y) = 
h(x) ∪ h(y). Then f (x) ∪ f (y) = f (x ∪ y) = f (x) ∪ h(x ∪ y), and so e /∈ f (y). So

e /∈ S

x∈X
f (x)= f (. X) and hence e /∈ (W F )(. X) as required.
W

To show that	F is a stable upper bound for F , suppose f ∈ F . Then for all
x, f (x) ≤  {f (x) | f ∈ F} = (W F )(x), and if x ≤ y, f (x)=  {g(x) ∪ f (y) | g ∈
F H g ≥s f} =  {g(x) | g ∈ F ∧ g ≥s f}∪ f (y)= (W F )(x) H f (y).
To show that W F is a stably least upper bound, suppose h is a stable upper bound for F . If x ≤s y then for all f ∈ F , f (x)= h(x) H f (y) and so (W F )(x)= 
  {h(x) ∪ f (y) | f ∈ F} = h(x) H (W F )(y)
Finally, observe that strat(W F ) =  {strat(f ) | f ∈ F}, since ((x, c), v) ∈
 {strat(f ) | f ∈ F} if and only if for all f ∈ F , (c, v) ∈ f (x), if and only if ((x, c), v) ∈ W F , and similarly ((x, c), cj) ∈ {strat(f ) | f ∈ F} if and only if for all f ∈ F , (c, ⊥) ∈ f (x + (cj, ⊥)), if and only if ((x, c), cj) ∈ W F .	2
Proposition 6.3 If A is stably complete and f : D(A) → D(A) is monotone stable, then f has a ≤s-least ﬁxedpoint.
Proof. Define the chain of stable approximants fλ ∈ D(A) for each ordinal λ by:
fλ = ⊥, if λ = 0,
fλ = f (fκ), if λ = κ +1 

λ
κ<λ
fκ if λ = S	κ.

By the bounded cardinality of D(A) this has a stationary point, which is a ≤s-least fixed point for f .	2
Thus, we may define the denotation of Y : (T → T ) → T to be the ≤s-least fix- point of h : (T ⇒ T ) ⇒ T → (T ⇒ T ) ⇒ T such that h(x)(y)= fun(y)(fun(x)(y)).

Soundness
Straightforward analysis of the reduction rules establishes that: Lemma 6.4 For any reducible program M, [[M ]] ⊆ S{[[N ]] | M −→ N}. Proposition 6.5 If M ⇓ then [[M ]] /= ⊥.
Proof. By Lemma 6.4, if (c, ⊥) /∈ [[N ]] for all N such that M −→ N then (c, ⊥) /∈ [[M ]]. So by definition, the set of convergent programs is contained in {[[M ]] | (c, ⊥) /∈ [[M ]]}.	2
To prove the converse (computational adequacy), we define “approximation re- lations” in the style of Plotkin [14]: for each type T we define a relation T between elements of [T ] and closed terms of type T :
x  nat M if M /⇓ implies (c, ⊥) ∈ x and M −→∗ n implies (c, n) ∈ x.
f  S→T M if x S N implies f (x) T M N . Note that:
If M −→ N for some unique N such that e  nat N then e  nat M
If ⟨fα | α < λ⟩ is a stable chain of functions such that fα  S→T M for all α < λ 

then W

α<λ
fα  S→T M .

Lemma 6.6 [[Y]]  (T →T )→T Y
Proof. Suppose T = T1 → ... → Tk → nat. We show by ordinal induction that

hλ  (T ⇒T )⇒T Y for each λ — i.e. if, g  T ⇒T M and ei  T
(hλg) e1 ... ek  nat (YM ) N1 ... Nk.
For λ = 0, we have (hλg) e1 ... ek = ⊥  nat M N1 ... Nk.
Ni for 1 ≤ i ≤ k then

For λ = κ + 1,: by hypothesis hκ Œ Y, and so (hλ g) e1 ... ek = g (hκ g) e1 ... en = g (hκg) e1 ... en Œ M (YM ) N1 ... Nk −→ M (YM ) N1 ... Nk and so hλ Œ Y as required.

For λ = S

κ<λ
κ, we have hλ = W
hκ Œ [[M ] by stable chain closure.
2

We then define f : [[Γ ] → [[T ]]  Γ,T Γ ▶ M : T if Γ = x1 : S1,..., xn : Sn and
e1 S1 N1,..., en Sn Nn implies f (e1,..., en) T M [N1/x1,..., Nn/xn].
Proposition 6.7 (Adequacy) [[M ]] /= ⊥ implies M ⇓.
Proof. We prove that if Γ ▶ M : T then [M ]] Γ,T M by structural induction.	2
Hence, by a standard argument, our model is inequationally sound: if [M ]] ± [[N ]] then M . N .
Conclusions
We conclude by considering the completeness problem for our model. By adding
catch (a simple, non-local control operator which can distinguish between different

sequentializations of a function) to PCF with bounded nondeterminism [13] we can show that every ﬁnite branching nondeterministic sequential algorithm is the least upper bound of a chain of definable approximants and so prove that this model is fully abstract. The situation in fair PCF is more complicated: since continuity fails, we cannot reduce full abstraction to the ﬁnite deﬁnability property. Moreover, our model does not accurately reflect sequential testing of arguments with unbounded nondeterminism, as we can show by giving an example of a stable and monotone function which is not definable in fair PCF. Consider the function k : D(N ) → D(N ) such that:
k(x)= T, if x is finite,
k(x)= ⊥ if x = ⊥,
k(x) = 0, otherwise
This is monotone and stable, since x ≤s y in D(N ) implies x = y or x = ⊥. However, it cannot be computed in fair PCF, since verifying that x contains infinitely many values requires infinitely many computation steps. (The function g : D(N ) → D(N ) such that g(x) = T if x is finite, and g(x) = ⊥, otherwise, is definable as λx.(Yλf.λy.If0 (x < y) then T else (f x) suc(y)) 0.) We may prove that k is not definable in fair PCF by showing that all definable functions have the following property:
Definition 7.1 A stable function f : D → E is weakly co-continuous if for any downwards ±-directed set X, f (. X) ≤s . f (X).
The function h is not weakly co-continuous: let X be the set of finite states of
N — this is downwards ±-directed, but . X is infinite and so h(. X)=0 /≤s T =
. h(X). But we can show that all terms denote weakly co-continuous functions.
Lemma 7.2 Let F be a (upwards) ≤ -directed set of weakly co-continuous functions from D to E (which is stably complete). Then W F is weakly co-continuous.
Proof. (W F )(. X)= W{f (. X) | f ∈ F} ≤s W{. f (X) | f ∈ F}.	2
Proposition 7.3 Every term of fair PCF denotes a weakly co-continuous function.
Proof. For each type T , we define a predicate (hereditary weak co-continuity) on the states of [T ]], by induction, as follows:
Every x ∈ D([[N ]]) is hereditarily weakly co-continuous.
σ ∈ D([[S → T ]]) is hereditarily weakly co-continuous if fun(σ) is weakly co- continuous and for any hereditarily weakly co-continuous x ∈ D([[S]]), fun(σ)(x) ∈ D([[T ]]) is hereditarily weakly co-continuous.
We now show by structural induction that for any term x1 : S1,..., xn : Sn ▶ M : T , λx1 ... xn.M : S1 → ... → Sn → T is hereditarily weakly co-continuous (using Lemma 7.2 for the fixpoint combinator).	2
This is sufficient to show that our semantics is not fully abstract, independently of the absence of the catch operators (which are weakly co-continuous).

Proposition 7.4 The sequential algorithm semantics of fair PCF is not fully ab- stract.
Proof. Define bchoice : nat → nat = Yλf.λx.If0 x then T else λy.(y or f y) — this evaluates its argument and nondeterministically returns a bounded choice over all smaller values. Define let x =? in M to be If0 ? then M [0/x] else λy.M [suc(y)/x]
— i.e. nondeterministically choose a value and bind it to x in M . Now define M = λf.If0 (f ?) then (let x =? in f bchoice(x)) else (let x =? in f bchoice(x)) and N = λf.f ?. These terms (of type (nat → nat) → nat) are not equivalent in our model — they may be distinguished by application to strat(k): [M ]](strat(k)) = T, but [N ]](strat(k)) = 0 (applying k to [[?]] returns 0, but applying k to [bchoice(n)]]
returns T and so [M ]](strat(k)) returns .	k({i < n})= T.
However, M and N are observationally equivalent: Let L : nat → nat be any
closed term of fair PCF. Then by Proposition 7.3 L denotes (the sequential algorithm of) a weakly co-continuous function and so [L ?]] ≤s [[let x =? in L bchoice(x)]]. Thus either [L ?]] = ⊥, in which case [M L]] = ⊥ = [[N L]] or [[L ?]] = [[let x =
? in L bchoice(x)]], in which case [M L]] = [[If0 L ? then L ? else L ?]] = [[L ?]] = [[N L]]. Therefore by adequacy of our semantics, and the Context Lemma for PCF (which extends straightforwardly to fair PCF), M and N are observationally equiv- alent.	2

Further Directions
We have established a fundamental relationship between extensional and intensional representations of higher-order functional computation with unbounded nondeter- minism. Further study of this model may shed light on the debate over the relevance of the concept of fairness [6]. Questions posed more directly by our semantics in- clude:
Can the notion of weak co-continuity be completed to give a characterization of the sequential algorithms which are definable in fair PCF (with catch) ? (This will also require a characterization of the effectively computable nondeterministic sequential algorithms.)
Can we build a graph games model of unbounded non-determinism based on ordered concrete data structures ?

References
Apt, K. R. and G. D. Plotkin, Countable nondeterminism and random assignment, Journal of the ACM
33 (1986), pp. 724–767.
Berry, G., Stable models of typed λ-calculi, in: Proceedings of the 5th International Colloquium on Automata, Languages and Programming, number 62 in LNCS (1978), pp. 72–89.
Berry, G. and P.-L. Curien, Sequential algorithms on concrete data structures, Theoretical Computer Science 20 (1982), pp. 265–321.
Cartwright, R., P.-L. Curien and M. Felleisen, Fully abstract semantics for observably sequential languages, Information and Computation (1994).

Curien, P.-L., G. Winskel and G. Plotkin, Bistructures, bidomains and linear logic, in: Milner Festschrift
(1997).
Djikstra, E. W., “A Discipline of Programming,” Prentice-Hall, 1976.
Harmer, R. and G. McCusker, A fully abstract games semantics for finite non-determinism, in:
Proceedings of the Fourteenth Annual Symposium on Logic in Computer Science, LICS ’99 (1998).
Hyland, M. and A. Schalk, Games on graphs and sequentially realizable functionals, in: Proceedings of LICS ’02 (2002).
Kahn, G. and G. Plotkin, Concrete domains, Theoretical Computer Science B¨ohm Festschrift special issue (1993), first appeared as technical report 338 of INRIA-LABORIA, 1978.
Laird, J., Locally Boolean domains, Theoretical Computer Science 342 (2005), pp. 132–148.
Laird, J., Bidomains and full abstraction for countable non-determinism, in: Proceedings of FoSSaCS’06, number 3921 in LNCS (2006), pp. 352–366.
Laird, J., Bistability: A sequential domain theory, Logical Methods in Computer Science 3 (2007).
Laird, J., Nondeterministic sequential algorithms, in: Proceedings of CSL ’09, number 5771 in LNCS (2009).
Plotkin, G., Lectures on predomains and partial functions (1985), notes for a course given at the Center for the study of Language and Information, Stanford.
Roscoe, A. W., An Alternative order for the failures model, in Journal of Logic and Computation, 2(5):557–557, 1992.
