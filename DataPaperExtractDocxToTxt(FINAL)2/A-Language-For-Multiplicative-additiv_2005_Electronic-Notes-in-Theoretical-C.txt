Electronic Notes in Theoretical Computer Science 122 (2005) 23–65  
www.elsevier.com/locate/entcs


A Language For Multiplicative-additive Linear Logic 1
J.R.B. Cockett2	C.A. Pastro3
Department of Computer Science, University of Calgary 2500 University Drive NW, Calgary, Alberta, Canada T2N 1N4

Abstract
A term calculus for the proofs in multiplicative-additive linear logic is introduced and motivated as a programming language for channel based concurrency. The term calculus is proved complete for a semantics in linearly distributive categories with additives. It is also shown that proof equivalence is decidable by showing that the cut elimination rewrites supply a confluent rewriting system modulo equations.
Keywords: multiplicative-additive linear logic, linearly distributive categories, term logic, rewriting modulo equations, process semantics


Introduction
The main result of this paper is a decision procedure for the equality of proofs in the multiplicative-additive fragment of linear logic, where we consider this fragment to include all of the units. This is achieved by introducing a term logic, which is of independent interest, for this fragment of linear logic. Before introducing this term logic, however, it is perhaps worth sharing with the reader how we arrived at the language and why we think it is of some interest. The idea of having a term logic for linear logic is certainly not new. In fact, almost every researcher who has been heavily involved in trying to un-

1 Research partially supported by NSERC, Canada. Diagrams were produced with the XY-pic package of K. Rose and R. Moore and inferences with M. Tatsuya’s proof.sty.
2 Email: robin@cpsc.ucalgary.ca
3 Email: pastroc@cpsc.ucalgary.ca



1571-0661 © 2005 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.06.049


derstanding the proof theory of linear logic has found it necessary to invent 4 such a calculus. Perhaps the earliest attempts at term logics for monoidal categories were by Lambek [14] and Jay [12]. They realized that ordinary algebraic terms with no variable copying or elimination would do the trick. More sophisticated attempts followed which linked the term calculus to the proof theory of various fragments of linear logic, see, e.g., Abramsky [1] and Benton, Bierman, de Paiva, and Hyland [3].
An important component of Girard’s approach to linear logic [9] was the introduction of proof nets. These, of course, can also be regarded as a term logic in their own right and, indeed, in [4], were explicitly introduced as such. There, after straightening out Girard’s one-sided proof nets into a two-sided form, they were used as a basis for solving the coherence problem for the units. From the point of view of a term logic, however, there is something peculiar about these nets as their definition is not local: one has to check a global correctness criterion before one can conclude that the net is valid. This condition arises as, in checking that the net corresponds to a valid proof, one has to determine that there is a valid way of assigning “scopes” to the inference rules. That this can be expressed as a combinatoric condition on the nets was, of course, one of Girard’s key insights.
An interesting recent approach to providing a term logic was suggested by Koh and Ong [13]. They realized that the tricky rewiring conditions for the units which arose in [4] could be expressed directly and quite clearly with scope changing rules. The first author was very fortunate to have visited Koh and Ong in Oxford in 1996 and to have had a chance to discuss this term logic with them. He was, of course, particularly impressed by the fact that they had realized that this gave a natural term logic for linearly distributive categories. It was clear that they had a good idea. However, their term logic never found any strong resonance in the linear logic community. This was not really surprising: after all, the proof net technology and its correctness criterion had been invented precisely to remove the necessity of keeping track of scopes. The reintroduction of explicit scopes seemed like a step in the wrong direction and made the utility of such a logic rather difficult to sell. To make matters worse, the syntax of their term logic was concise to the point of being cryptic: for an outsider the terms did not invite any particular insight into their meaning.
While trying to sort out a process semantics for multiplicative-additive linear logic (with both the additive and multiplicative units) we found that

4 Inevitably sometimes the word “reinvent” should be used here. However, in defense of reinvention it should be said that, often, to reinvent is the only way to really understand these languages.


it was very useful to have a term logic to express the processes. The use of proof nets in linear logic makes it largely unnecessary to have a term logic for the multiplicative fragment. However, when one considers the multiplicatives together with the additives the value of a term logic becomes much more compelling. Even the minimalistic approach presented by Hughes and van Glabbeek in [11] cannot hide the fact that additive proof nets are complicated combinatoric structures which are hard to create in the way a programmer might create a program.
In order to produce such a term logic we took a very literal translation of the sequent calculus. When we showed this term logic to Robert Seely, and explained the intended process semantics, he suggested —while commenting ironically on the importance of appearances rather than content in certain academic circles— that we should try presenting it in a programming language style for processes. So we fiddled around with suitable keywords and produced such a language and were horrified to find that we actually liked the result! In particular, it had an immediate resonance with process programming which made the terms almost readable to programmers.
The point is that in presenting this term logic we are happy to claim almost no originality. In fact, we would suggest that the strength of the lan- guage is exactly that it has been plagiarized from a number of sources while slavishly following the sequent calculus. The scoping techniques should be quite recognizable from the term logic of Koh and Ong. Admittedly, we have unashamedly rearranged their terms to promote, following Robert’s excellent suggestion, a process reading. Finally, centre stage is the syntax for the ad- ditives which we were happy to simply borrow from the π-calculus following the lead of Bellin and Scott [2]. The result is a term calculus which has the feel of a programming language for processes.
Indeed, if you had been trying to put together a process language for channel based communication you might well have come up with a language which has at least these features. That the language is, in fact, the internal language for linearly distributive categories with additives should be, perhaps, of more than a passing interest.

Introduction to the term calculus
As far as we know there has not actually been a proposal for a term calculus for the multiplicative-additive fragment of linear logic. We should, therefore, mention that although we borrow techniques very happily from prior work there are some technical aspects which remain. For example, the proof that term normalization modulo equations works is, for this fragment, technically more challenging than in the purely multiplicative fragment (compare our


techniques to those in [13]). While it is not possible to include all the technical details in this paper the reader should be aware that many of these details are available from the second author’s master’s thesis [15]. The subject of this thesis was the complete additive fragment of linear logic 5 for which a full and faithful process semantics was provided. This paper is part of the continuation of that work, whose aim is to provide a full and faithful process semantics for the complete multiplicative and additive fragments of linear logic 6 .
A slight warning to linear logicians: we do not assume that we have a nega- tion in the logic. This may seem to be an enormous omission, however, those intimately familiar with the coherence issues of these settings will know that, in fact, negation is a distraction whose presence or absence is orthogonal to the real issues. If this sounds like a controversial statement to the reader then we should perhaps also quietly mention that the initial model does actually have negation (i.e., it is a ∗-autonomous category) even though no negation is mentioned: in other words, this aspect, for the initial model, comes along for the ride anyway. This remains true whenever the generating polycategory has negation. Thus, we are just being scrupulously abstract in our approach and are therefore working at the level of linearly distributive categories with additives.
The objective of this paper is to highlight the term calculus we are using and to thereby persuade you that it is quite reasonable to give a process reading to the proofs of this fragment of linear logic. To this end we start with an old example of Girard’s which involves obtaining a packet of Galois from a vending machine and show how to program it in our term logic.
We wish to describe the behavior of a vending machine which allows one to select either smokers chewing gum or, for those that cannot quite kick the habit, a packet of Galois cigarettes. The machine allows you to pay by inserting a one or two dollar coin. A packet of Galois costs two dollars while the gum only costs one dollar. There are four possible outcomes:
You have inserted a dollar and have requested gum: you get a pack of gum.
You have inserted a dollar and requested a packet of Galois: your dollar is returned.
You have inserted two dollars and requested some gum: you get a pack of gum and a dollar in change.

5 The complete additive fragment includes, in particular, the additive units which not surprisingly are more technically challenging to capture.
6 The complete multiplicative and additive fragment includes both the multiplicative units and the additive units. In particular, it should be mentioned we are fundamentally not assuming “mix”, thus the complications of handling the units in their full glory is present.


You have inserted two dollars and requested a packet of Galois: you get a packet of Galois.
This means we wish to produce a process which is the proof of the following sequent:

α : {1 : $1, 2 : $2}  {gal : T, gum : T} ▶
β : {a : GAL,b : GUM  {change : $1, nochange : T},c : $1}

The process starts with a single input channel α and a single output channel β. Each channel has an attached protocol for the interaction down that channel. The curly brackets denote coproduct types with components which are tagged: the names used for the tags are called “events” and are sent and received as messages along the channels. The tensor operation “− −” allows one to bundle channels together.
To model the functioning of the vending machine we need three functions which transmute our resources:
gal : $2 → GAL,  gum : $1 → GUM,  and  gumch : $2 → GUM  $1.
Thus, gal turns two dollars into a packet of Galois, gum turns one dollar into a stick of gum, and gumch turns two dollars into a stick of gum and one dollar of change. The fairness of the machine is guaranteed by the fact that
only these exchanges are allowed, e.g., we have to ensure that when the user inserts $2 and asks for cigarettes he will not be given gum and a dollar change instead.
This process may be written as follows:

split α as α1, α2 in input α1 of
| 1 '→ input α2 of
| gal '→ close α2 in
output c on β in α1 = β	% return dollar
| gum '→ close α2 in output b on β in
fork β as
| β1 with α1 '→ gum(α1; β1)	% return gum
| β2 with	'→ output nochange on β2 in end β2
| 2 '→ input α2 of
| gum '→ close α2 in
output a on β in gal(α1; β)	% return cig


| gum '→ close α2 in output b on β in
on γ plug
gumch(α2; γ)	% return gum with dollar
to
split γ as γ1, γ2 in fork β as
| β1 with γ1 '→ γ1 = β1
| β2 with γ2 '→ output change on β2 in γ2 = β2
Input channels which are tensored can be used by a single process as they come from independent sources: to communicate down the individual chan- nels one must split the channels. However, output channels when tensored together have to be treated completely differently: they can be dependent and so if they are used by the same process this may can cause deadlock or live- lock. Thus, to use such channels one must fork the current process into two independent processes. When one forks a process in this manner one must also decide which of the open communication channels will be attached to which of the subprocesses.
One can only close a channel when the type is a unit (T or ⊥). When it is an input channel one can simply close the channel T and when it is an output one can end the channel provided there are no other open channels.
The process above starts by splitting its one input channel α into two distinct channels. It then looks for an input event on the first channel: this is provided by the user inserting either $1 or $2 into the machine. Next the machine looks for input on the buttons. If the user has input $1 and asked for a packet of Galois then we return his coin by selecting case (c) and connecting the input channel with the coin resource directly to an output (so the coin is returned).
Let us consider what is perhaps the most complex case in the example: namely, when $2 is entered and the gum button is pressed. In this case we start by choosing case (b), then we want to transmute $2 into gum and $1 (which are sent along channel γ). Next we want to pass these things to the person using the machine so we split the resources. Here we have to fork as the user may use these channels in such a way as to make them dependent (for example he may always look for his change before he takes his gum). We then independently return his change and provide the gum in two different
processes. To provide the change we send an event change to indicate that
change is due and then pass the change down that channel.
Finally let us consider the case where $1 is provided and gum is selected. In this case we again have to fork the output into two processes one of which


returns the gum and the other of which handles the change. On the latter we indicate that no change is due by sending the event nochange: this gives a tensor unit channel on output which (provided that no channels are open) allows one to end the process.


Outline of this paper
The main formal result of the paper is that there is a decision procedure for this term logic. However, the fact that such a procedure exists is, we feel, a fairly standard observation and not as important as establishing the term logic itself. To establish the term logic we introduce it formally in Section 2. In fact, we introduce it in two different syntactic flavors: the programming syntax, as above, and a more succinct (and cryptic) representation to facilitate the technical arguments.
In Section 3 we introduce a rewriting system on terms. The rewrit- ing corresponds to the cut elimination procedure and proof equivalences for multiplicative-additive linear logic.
In Section 4 we show that the terms can be interpreted in any linearly distributive category with sums and products and, furthermore, form them- selves into the free representable polycategory with additives. By looking at the maps in this polycategory we obtain the corresponding free linearly dis- tributive category with additives. These results are an extension of the results in [15] and use similar techniques.
In Section 5 we discuss the proof of categorical cut elimination. This involves showing, in proof theoretic terms, that the cut elimination procedure terminates (which is well-known). However, it also involves showing the more demanding fact these rewrites are confluent modulo the equations introduced by the permuting conversions. Once one has categorical cut elimination the equality of proofs can be determined by using the equations alone: the fact that the system is decidable follows from the subformula property which limits the number of proofs and, thus, the number of terms in an equivalence class. This is a somewhat unsatisfactory state of affairs in which to leave things,
as it does not indicate the complexity of the decision procedure. It is possible to organize the decision procedure to be much more efficient. Unfortunately, even in this reorganization the procedure has some steps to accomplish which correspond to the classical rewiring problem discussed in [4] for the multi- plicatives. Thus, the complexity of this determination is dominated by the complexity of determining equality in the multiplicative fragment. The first author has conjectured (pessimistically) that this is exponential and this still remains an open problem.

,		 
A ▶ A (identity)

{Γ, Xi ▶ ∆}i∈I	{Γ ▶ Yi, ∆}i∈I

Γ,	Xi
i∈I
▶ ∆	(cotuple)
(tuple)
i
i∈I

 Γ, Xk ▶ ∆ 	 Γ ▶ Yk, ∆ 

Γ,	Xi
i∈I
▶ ∆ (projection)
(injection)
i
i∈I


Γ, {Xi}i∈I ▶ ∆
where k ∈ I, I /= ∅
Γ ▶ {Yi}i∈I, ∆

Γ,	Xi
i∈I
▶ ∆	(ltensor)
(rpar)
i
i∈I

{Γi, Xi ▶ ∆i}i∈I	{Γi ▶ Yi, ∆i}i∈I

Γ,	Xi
i∈I
▶ ∆	(lpar)
(rtensor)
i
i∈I

where Γ =	i Γi and ∆ =		i ∆i (	denotes disjoint union) Γ ▶ ∆,Z	Z, Γ' ▶ ∆'
Γ, Γ' ▶ ∆, ∆'	(cut)
  		J
Table 1 Multiplicative-additive linear logic

Term calculi for multiplicative-additive linear logic
In this section we introduce two term calculi for multiplicative-additive linear logic. We recall the sequent rules for the multiplicative and additive fragments of linear logic 7 in Table 1.
The additive fragment consists of the cotuple, tuple, projection, and injec- tion rules along with the identity and cut rules. The multiplicative fragment consists of the ltensor, rtensor, rpar, and lpar rules along with the identity and cut rules.
This presentation uses operations indexed by arbitrary (finite) sets. We will often write simply i (e.g.,  i Xi) or j and use it to mean i ∈ I and j ∈ J. Except in the injection and projection rules these index sets are allowed to be
empty: this gives the nullary rules. These nullary rules are usually presented

7 We are using the symbols + and × to refer to the categorical sum and product respectively, and the symbols  and  for the categorical tensor and cotensor respectively. Note then
that this conflicts with Girard’s notation in [9], but is consistent with [4].


separately as:
,		 
Γ, 0 ▶ ∆ (cotuple)	Γ ▶ 1, ∆ (tuple)
 Γ ▶ ∆  (ltensor)	 Γ ▶ ∆  (rpar)
Γ, T▶ ∆	Γ ▶ ⊥, ∆
⊥▶ (lpar)	▶T (rtensor)
  		J
We shall consider various augmentations of this basic logic:
The “initial logic” is the logic with no atoms. Notice this is still a non-trivial logic because of the symbols 0, 1, T, and ⊥. We shall denote this logic as CProc(∅).
The “pure logic” is the logic with an arbitrary set of atoms A: we shall denote this logic as CProc(A).
The “free logic” is the logic with an arbitrary set of atoms and an arbitrary set of non-logical axioms relating lists of atoms. For example, if f is a non- logical axiom relating A, B to C, D, this may be denoted as a poly-map or an inference, i.e., as

f : A, B → C, D	or	f :: A, B ▶ C, D
The atoms will be regarded as objects in a polycategory and the axioms as poly-maps in that polycategory (with the “essential cuts” being provided by composition). If the polycategory is denoted A, the resulting logic will
be denoted CProc(A).
If we think of the atoms of a pure logic as forming a discrete category (a category where the only maps are the identities), the free logic on this discrete category is just the “pure” logic. Each variant above therefore includes the previous variant, and as it is more general, we shall tend to only consider the free logic. It is worth noting that a simple inductive argument shows that the logic will have negation whenever the polycategory A has negation.

Formulas as protocols
The term representations are dependent on formulas annotated with “chan- nel names” and “events” which are derived from the process semantics view in which the formulas represent protocols. The reader interested in a more complete story is referred to [15].
Each formula is assigned a channel name, which we denote using Greek


letters, e.g., if X is a formula, α : X is a formula attached to channel α. A formula is just formula of linear logic (without negation) which is presented using a tagged notation:
if X is atomic then it is left as is.
X =	i Xi is tagged with events as {ai : Xi | i ∈ I}, where ai /= aj when
i /= j.
X =	i Xi is tagged with events as (ai : Xi | i ∈ I), where ai /= aj when
i /= j.
X =	i Xi is tagged with channel names as	i αi : Xi, where αi /= αj
when i /= j.
X =	i Xi is tagged as	i αi : Xi, where αi /= αj when i /= j.
For example, the linear logic formula (W +X) (Y Z) in this tagged notation might become:

α : {a : W, b : X}  β : (β1 : Y  β2 : Z)

The channel names occurring as the tags for the formulas in a sequent must be distinct as they are used as references. To simplify our term representation and to avoid channel name conversions we will use distinct channel names within the formulas as well. Furthermore, a convention we adopt is to assign implicit tags to multiplicatives: thus, α :  i Xi or α :  i Xi have implicitly
assigned their constituents the channel names αi, for i ∈ I.
We are now ready to introduce the term calculi. Two different syntaxes will be used to represent proofs in this system: a “programming language” syntax and a more succinct term representation. We begin with the programming syntax.

Programming language syntax
The programming syntax provides an explicit process reading for the proofs. Unfortunately, while this representation is quite intuitive, it is also rather verbose which is why we will introduce a more succinct representation in the next section.
The term formation rules for the programming language are given in Ta- ble 2. The language is self dual and so only half the rules are presented. To reduce the overload strain on colons we will use “::” to denote the term-type membership relation, e.g., t :: U ▶ V will mean that t is a term of type U ▶ V , where U (say) may be of the form a : X. Note also that we introduce special syntax (stop, close, and end) for the nullary cases.

,		 

α =A β :: α : A ▶ β : A
{fi :: Γ ▶ α : Xi, ∆}i
input α of |i ai '→ fi :: Γ ▶ α :	i ai : Xi, ∆
	f :: Γ ▶ α : Xk, ∆	
output ak on α in f :: Γ ▶ α :	i ai : Xi, ∆ where k ∈ I, I /= ∅
f :: Γ ▶ {αi : Xi}i, ∆
split α as (αi)i in f :: Γ ▶ α :	i αi : Xi, ∆
{fi :: Γi ▶ αi : Xi, ∆i}i
fork α as |i αi with Λ(Γi, ∆i) '→ fi :: Γ ▶ α :  i αi : Xi, ∆


f :: Γ ▶ ∆,γ : Z	g :: γ : Z, Γ' ▶ ∆'
on γ plug f to g :: Γ, Γ' ▶ ∆, ∆' Notation for nullary cases:

stop α :: Γ ▶ α : 1, ∆
f :: Γ ▶ ∆
close α in f :: Γ ▶ α : ⊥, ∆

end α :: ▶ α : T

  		J
Table 2
“Programming language” term formation rules

The notation Λ(Γ, ∆) represents the set of domain and codomain channels of the sequent, i.e., the set of channels tags of the formulas in the sequent. For example,

Λ(α1 : {a : W, b : X}, α2 : A, β : (Y  Z)) = {α1, α2, β}
Note that the operation Λ(−) does not extract any internal channel names. A non-logical axiom introduced as f : α1 : X1,..., αm : Xm → β1 :
Y1,..., βn : Yn will be represented by the term f (α1,... , αm; β1,... , βn). The


identity map on atoms, α : X → β : X, can then be represented using this notation as 1X(α; β), although we will prefer the notation α =X β. Two terms are channel equivalent if they are equivalent up to channel name conversion: clearly the renaming of channels does not affect the meaning of the terms.

Example 2.1 The following proof of the linear distribution map

 



α21 : B ▶ β1 : B
α1 : A ▶ β21 : A	α22 : C ▶ β22 : C


α1 : A, α22 : C ▶ β2 : A  C


α1 : A, α2 : B  C ▶ β1 : B, β2 : A  C α1 : A, α2 : B  C ▶ β : B  (A  C) α : A  (B  C) ▶ β : B  (A  C)
is represented in the programming syntax as follows:
split α as α1, α2 in split β as β1, β2 in
fork α2 as
| α21 with β1 '→ α21 =B β1
| α22 with α1, β2 '→ fork β2 as
| β21 with α1 in α1 =A β21
| β22 with α22 in α22 =C β22

Note that in view of the rewrites in Section 3 there are a number of equiv- alent presentations of this process.


A term calculus representation
In this section we introduce a more succinct representation for proofs which we call the term calculus representation. The term formation rules are given in Table 3; again only half the rules are presented.
In this representation (as well as in the programming language represen- tation) the notation does not directly indicate on which side of the turnstile an active channel sits. This can be inferred from the term and also by in- specting the type. However, it is sometimes useful to make this information more explicit and to do this we will indicate domain channels by an overarrow
pointing left, ←α−, and codomain channels by an overarrow pointing right, →−α .

Example 2.2 The following is the term calculus representation of the proof

,		 

α =A β :: α : A ▶ β : A
{fi :: Γ ▶ α : Xi, ∆}i
α{ai '→ fi}i :: Γ ▶ α :	i ai : Xi, ∆
	f :: Γ ▶ α : Xk, ∆	
α[ak]f :: Γ ▶ α :	i ai : Xi, ∆ where k ∈ I, I /= ∅
f :: Γ ▶ {αi : Xi}i, ∆
α⟨(αi)i '→ f ⟩ :: Γ ▶ α :	i αi : Xi, ∆
{fi :: Γi ▶ αi : Xi, ∆i}i
α⟨αi | Λ(Γi, ∆i) '→ fi⟩i :: Γ ▶ α :   i αi : Xi, ∆


f :: Γ ▶ ∆,γ : Z	g :: γ : Z, Γ' ▶ ∆'
f ;γ g :: Γ, Γ' ▶ ∆, ∆'

  		J
Table 3
Term calculus formation rules

found in Example 2.1 above:


  α21
|β1
'→ α21 =B β1

α⟨(α1, α2) '→ β⟨(β1, β2) '→ α2

α  |α ,β 

'→ β
  β21|α1 '→ α1 =A β21   ⟩⟩

22	1	2
2
β22|α22 '→ α22 =C β22


It is clear that the term calculus is more succinct and will be more conve- nient for manipulating the terms, accordingly we shall use this representation for the remainder of the paper.

Term rewrites and equivalences
Two terms f and g may be composed on a channel γ when γ is a codomain channel of f of type X and a domain channel of g of the same type. Further- more, γ must be the only channel name f and g have in common. That is, the two terms must be of the form f :: Γ1 → Γ2,γ : X and g :: γ : X, ∆1 → ∆2,


where γ is the only channel name in common. Composing these terms on γ
is denoted:
f ;γ g :: Γ1, ∆1 → Γ2, ∆2
The requirement that γ is the only channel name in common ensures that after composition all the channel names will be distinct. In general this means that in order to perform a composition there may be need to perform a channel name conversion to arrange that the two terms have this form.

Cut elimination rewrites
Composition is exactly the cut rule. Thus, the dynamics of composition cor- responds precisely to the cut elimination process. We describe the cut elim- ination rewrites below. As our term calculus does not distinguish between domain and codomain channels dual proof rewrites written as terms will be identical. However, we shall be careful to indicate how the inference rules give rise to each of the rewrites.
The set of unbound channels in a term t will be denoted Λ(t) and is the same as Λ(Γ, ∆) where t :: Γ ▶ ∆.
The rewrites are as follows:
Identity-sequent (sequent-identity):
f ;γ 1 =⇒ f

1;γ f =⇒ f
Cotuple-sequent (sequent-tuple), tuple-sequent (sequent-cotuple):
α{ai '→ fi}i;γ g =⇒ α{ai '→ fi;γ g}i

g;γ α{ai '→ fi}i =⇒ α{ai '→ g;γ fi}i
Injection-sequent  (sequent-projection),  projection-sequent  (sequent-injection):
α[a]f ;γ g =⇒ α[a](f ;γ g)

g;γ α[a]f =⇒ α[a](g;γ f )
Ltensor-sequent (sequent-rpar), rpar-sequent (sequent-ltensor):
α⟨(αi)i '→ f ⟩;γ g =⇒ α⟨(αi) '→ f ;γ g⟩

g;γ α⟨(αi)i '→ f ⟩ =⇒ α⟨(αi) '→ g;γ f ⟩
Lpar-sequent (sequent-rtensor), rtensor-sequent (sequent-lpar): here we sup- pose γ ∈ Λk.




α⟨αi

| Λi

'→ fi⟩i;γ
g =⇒ α	αi | Λi '→ fi
αk | (Λk ∪ Λ(g)) \ {γ} '→ fk;γ g




i/=k




g;γ

α⟨αi

| Λi

'→ fi⟩i
=⇒ α	αi | Λi '→ fi
αk | (Λk ∪ Λ(g)) \ {γ} '→ g;γ fk




i/=k

Injection-cotuple (tuple-projection):
γ[ak]f ;γ γ{ai '→ gi}i =⇒ f ;γ gk

γ{ai '→ gi}i;γ γ[ak]f =⇒ gk;γ f
Rtensor-ltensor (rpar-lpar):


γ⟨αi | Λi '→ fi⟩i∈{1,...,n};γ γ⟨(αi)i∈{1,...,n} '→ g⟩ =⇒
fn;αn (··· (f2;α2 (f1;α1 g)) ··· )

γ⟨(αi)i∈{1,...,n} '→ g⟩;γ γ⟨αi | Λi '→ fi⟩i∈{1,...,n} =⇒
((··· (g;αn fn) ··· );α2 f2);α1 f1
In order to obtain a normal form for sequent derivations, and hence terms, we would like to show that the cut elimination rewrites are Church-Rosser. However, this is easily seen to not be the case. Consider a derivation with a projection and an injection immediately above the cut:

	π	
 Γ1, Xk ▶ Γ2, Z 
Γ1,  i Xi ▶ Γ2,Z 

π'


  Z, ∆1 ▶ Yl, ∆2 
Z, ∆1 ▶ Σj Yj, ∆2

Γ1,	i Xi, ∆1 ▶ Γ2,	j Yj, ∆2
In this case one may apply the projection-sequent rewrite or the sequent- injection rewrite to reduce the derivation, but there seems to be no way in which to resolve this pair. This motivates the use of additional rewrites which will allow us to interchange these rules (and all the other critical pairs). These rewrites (which we are denoting by e===z) are called thpeermuting conver- sions and are as follows:
Cotuple-cotuple (tuple-tuple), cotuple-tuple interchange:
α{ai '→ β{bj '→ fij}j}i e===zβ{bj '→ α{ai '→ fij}i}j


Cotuple-injection (projection-tuple), cotuple-projection (injection-tuple) in- terchange:
α{ai '→ β[b]fi}i e===zβ[b]α{ai '→ fi}i
Cotuple-ltensor (rpar-tuple), cotuple-rpar (ltensor-tuple) interchange:
α{ai '→ β⟨(βj)j '→ fi⟩}i e===zβ⟨(βj)j '→ α{ai '→ fi}i⟩
Cotuple-rtensor (lpar-tuple), cotuple-lpar (rtensor-tuple) interchange: here we suppose α ∈ Λk.

α ⎧⎨ai
'→ β  βj|Λj '→ gj 
⎫⎬ e===zβ  βj|Λj '→ gj

⎩	βk|Λk '→ fi
j/=k⎭i
βk|Λk '→ α{ai '→ fi}i
j/=k

Injection-injection (projection-projection), injection-projection interchange:
α[a](β[b]f ) e===zβ[b](α[a]f )
Injection-ltensor (rpar-projection), injection-rpar (ltensor-projection) inter- change:
α[a]β⟨(βj)j '→ f ⟩ e===zβ⟨(βj)j '→ α[a]f ⟩
Injection-rtensor (lpar-projection), injection-lpar (rtensor-projection) inter- change: here we suppose α ∈ Λk.

α[a]β	βj | Λj '→ gj
βk | Λk '→ f
j/=k
e===zβ	βj | Λj '→ gj
βk | Λk '→ α[a]f




j/=k

Ltensor-ltensor (rpar-rpar), ltensor-rpar interchange:
α⟨(αi)i '→ β⟨(βj)j '→ f ⟩⟩ e===zβ⟨(βj)j '→ α⟨(αi)i '→ f ⟩⟩
Ltensor-rtensor (lpar-rpar), ltensor-lpar (rtensor-rpar) interchange:




α  (α )

'→ β  βj|Λj '→ gj

  e===z

i i
β |Λ
∪ (  {α }) '→ f


β	βj|Λj '→ gj
βk|Λk ∪ {α} '→ α⟨(αi)i '→ f ⟩
 


j/=k



Rtensor-rtensor (lpar-lpar), rtensor-lpar interchange: let Λ = {β}∪ Λk ∪
(  Λ' ) and Λ' = {α}∪ Λ' ' ∪ (  Λi).






α
αi|Λi '→ fi
  βj|Λ' '→ gj

e===z

αk|Λ '→ β
j
βk' |Λ' ' '→ h


j/=k'

i/=k


β



Polycategorical semantics
'
j

βk' |Λ' '→ α

αi|Λi '→ fi αk|Λk '→ h
i/=k
 


j/=k'

The reduction rules and the permuting conversions together define an equiv- alence relation (which we denote by ∼) on the derivations of a sequent. This allows us to form for each sequent a hom-set consisting of terms modulo this equivalence (based on a starting polycategory A). The cut operation then provides polycategorical composition.
This delivers a polycategory which we shall denote CProc(A). The purpose of this section is to prove that this polycategory has additives and is repre-
sentable. This amounts to saying that its maps 8 form a linearly distributive category with additives (see [6]).
Theorem 4.1 CProc(A) is a representable additive polycategory whose ob- jects are the formulas of the logic, and whose poly-maps are ∼-equivalence classes of derivations.
The fact that the terms modulo equivalence provide a polycategory is proved in Appendix C. The proof consists of providing identity maps and showing that cut is associative and satisfies the interchange law. Below we discuss the remaining structure:

Additives
Our next task is to establish that the polycategory CProc(A) has additives, i.e., poly-sums and poly-products. In a polycategory A an object  i Xi ∈ A is said to be the poly-sum (or poly-coproduct) of a family of objects Xi ∈ A, for i ∈ I, in case there is a natural bijective correspondence

8 By “map” we mean a poly-map with one domain and one codomain.


{fi :: Γ,α : Xi → ∆}i
α{fi}i :: Γ,α :	i Xi → ∆ where, by natural, it is meant that the equivalences
h;γ α{fi}i = α{h;γ fi}i	and	α{fi}i;γ h = α{fi;γ h}i

hold (when α /= γ). Poly-products in polycategories are (as might be expected) dual to poly-coproducts.
Proposition 4.2 CProc(A) has additives.
Proof. In order to establish that CProc(A) has finite sums and finite products it must be shown that the correspondences

{Γ,α : Xi → ∆}i	{Γ → β : Yj, ∆}j
and	 
Γ,α : Σi i : Xi → ∆	Γ → β :	j j : Yj, ∆
are bijective and natural.  We will prove the case for sums, products are
handled dually.
Suppose we have poly-maps t :: Γ,α :  i i : Xi → ∆ and si :: Γ,α : Xi → ∆, for i ∈ I. The collection of poly-maps {si}i can, via the cotupling derivation, be used to construct a poly-map
ψ({si}i) = α{i '→ si}i :: Γ,α :	i i : Xi → ∆
and t may be cut with α[k]1Xk :: Xi → α : Σi Xi, for k ∈ I, to get a poly-map

ϕk(t) = α[k]1Xk ;α t :: Γ, Xk → ∆
To prove that this correspondence is bijective we must establish both
ϕk(ψ({si}i)) = sk, for k ∈ I, and ψ({ϕi(t)}i) = t. The former follows from

ϕk(ψ({si}i)) = ϕk(α{i '→ si}i) = α[k]1Xk ;α α{i '→ si}i = 1Xk ;α sk = sk
and the latter from
ψ({ϕi(t)}i) = ψ(α[i]1Xi ;α t)= β{i '→ α[i]1Xi ;α t}i
= β{i '→ α[i]1Xi }i;α t
= 1ΣiXi ;α t
= t
It remains to show that this correspondence is natural, however, this fol- lows immediately from the rewrites (3) and (4).	 


Representability
A multi-map Γ −u→ X is said to represent Γ as input (cf. [10,5]), if cutting with u at X induces a natural bijection as follows:





Dually, a comulti-map Y
 Γ1, Γ, Γ2 → ∆ Γ1, X, Γ2 → ∆
−v→ Γ represents Γ as output, if cutting with v

at Y induces an analogous bijection. A polycategory is called representable
if each sequence of formulas is representable as input and as output.
Theorem 4.3 CProc(A) is representable.
Proof. We will prove that a bundle of channels {βi : Xi}i is represented as input by the following multi-map
α ⟨αi | βi '→ βi =Xi αi⟩ :: {βi : Xi}i → α :	i αi : Xi
The symmetry of the term calculus will then deliver representability. This means that we must show the correspondences


Γ, {αi : Xi}i → ∆
Γ → ∆

Γ,α :   α : X → ∆	and


Γ,α : T→ ∆


are bijective and natural.
The proof of the non-nullary case follows in a manner very similar to that of Proposition 4.2. Suppose we have poly-maps t :: Γ,α :  i αi : Xi → ∆ and s :: Γ, {αi : Xi}i → ∆. The poly-map s can, via the ltensor derivation,
be used to construct a poly-map
ψ(s) = α⟨(αi)i '→ s⟩ :: Γ,α :	i αi : Xi → ∆
and t may be cut with the representing multi-map to get a poly-map
ϕ(t) = α ⟨αi | βi '→ βi =Xi αi⟩i ;α t :: Γ, {αi : Xi}i → ∆
To prove that this correspondence is bijective we must establish both ϕ(ψ(s)) = s and ψ(ϕ(t)) = t. Suppose I = {1,..., n}. The former follows from

ϕ(ψ(s)) = ϕ(α⟨(αi)i '→ s⟩)
= α⟨αi | βi '→ βi =Xi αi⟩i;α α⟨(αi)i '→ s⟩)
= βn =Xn αn;αn (··· (β1 =X1 α1;α1 s) ··· )
= s


and the latter from
ψ(ϕ(t)) = ψ(β⟨βi | αi '→ αi =Xi βi⟩i;β t)
= α⟨(αi)i '→ β⟨βi | αi '→ αi =Xi βi⟩i;β t⟩
= α⟨(αi)i '→ β⟨βi | αi '→ αi =Xi βi⟩i⟩;β t
= 1N Xi ;β t
= t

To establish the nullary case suppose we have poly-maps t :: Γ,α : T → ∆ and s :: Γ → ∆, and define
ψ(s) = α⟨() '→ s⟩	and	ϕ(t) = α⟨ ⟩;α t
To see that it is again a bijection observe
ϕ(ψ(s)) = ϕ(α⟨() '→ s⟩) = α⟨ ⟩;α α⟨() '→ s⟩ = s
and
ψ(ϕ(t)) = ψ(β⟨ ⟩;β t) = α⟨() '→ β⟨ ⟩;β t⟩ = α⟨() '→ β⟨ ⟩⟩;β t = 1T;β t = t

It is left to show that the correspondence is natural, however, this follows immediately from the rewrites (7) and (8).	 

The free additive linearly distributive category
The goal of this section is to prove:
Theorem 4.4 CProc(A) is the free representable polycategory with additives generated by the polycategory A.
As any linearly distributive category with additives generates a polycate- gory with additives, an immediate corollary of this is:
Corollary 4.5 The maps of CProc(A) form the free linearly distributive cat- egory with additives generated by the polycategory A.
Note that this is the usual (categorical) notion of freeness.
In order to prove this theorem we must show that in any representable polycategory with additives the identities (1)–(24) must hold.
It is routine to show (see [15]) that a polycategory has poly-sums if and only if it has a cotupling operation which is distributive on the non-sum channel, and injections which when cut against a cotuple on the sum channel delivers the appropriate component of the cotuple, and finally it satisfies “surjective


pairing” which is the requirement that the cotuple of the injections is the identity.
Now observe that the injection term α[a]f can be translated as f ; bk where bk :: Xk → i Xi, for k ∈ I. This is a valid identification as there is a reduction of derivations



Γ ▶ Xk, ∆
Σ
 Xk ▶ Xk 
Xk ▶ Σi Xk
 

 Γ ▶ Xk, ∆ 
=⇒	Γ ▶ Σ X , ∆

The term calculus identities for the additives express precisely the require- ments described above with the exception of surjective pairing. However, recall that this is implicit in the term calculus from the manner in which the identity map for the coproduct is defined.
The only remaining difficulty is to translate the “forking” construct of the term logic. Suppose I = {1,..., n} for n ≥ 1, then in any repre- sentable polycategory we may translate the poly-map α⟨αi | Λi '→ fi⟩i as fn;αn (... (f1;α2 r) .. .) where r is the representing multi-map.
1N Xi

	fn	
i

i Xi ▶	i Xi

Γn ▶ Xn, ∆n
f


{Xi}i ▶r  i Xi

	1	
Γ1 ▶ X1, ∆1
	·· ·	
X , Γ , ··· , Γ ▶	X , ∆ , ··· , ∆ Γ ▶  i Xi, ∆

The identities are now an easy consequence. In particular, (9), (10), (13), and (14) are a direct consequence of the translation of “forking” described above.

The decision procedure
Cut elimination seen as a term rewriting supplies a way of rewriting the terms (in the initial calculus) to remove the cut completely. In CProc(A) it allows the cuts to be moved into the underlying polycategory A. This relies on the following routine but nonetheless technical observation which also delivers a
“categorical cut elimination” theorem as the equality of proofs (as determined by the equalities above) is now guaranteed to be maintained by the elimination procedure.
Theorem 5.1 In CProc(A):
The rewriting on poly-maps given by (1)–(14) terminates.


The rewriting on poly-maps given by (1)–(14) is confluent modulo the permuting conversions (15)–(24).
The proof is presented in some detail in Appendix B. The argument in- volves resolving all the critical pairs (rewriting against rewriting and rewriting against permuting conversion) modulo the permuting conversions. To show that the rewriting terminates in forms which are equivalent with respect to the permuting conversions involves showing that the resolution of each critical pair always reduces the cost of the frontier. This does involve some subtlety as the nullary additive permuting conversions can produce some apparently non-reducing steps. However, somewhat surprisingly, a very basic multiset measure of cut heights applied carefully does suffice for the whole argument to go through quite smoothly.
The effect of this theorem is to provide a decision procedure modulo the decidability of the underlying polycategory A. The rewriting normalizes terms by moving the cut into the non-logical axioms. The equivalence of terms is then determined by the decision procedure in A and the permuting conver- sions. The subformula property delivered by cut elimination ensures that there are only finitely many proofs which do not involve cut (excluding how the non-logical steps are filled). This means that, in principal, in order to de- cide the equality of two terms one can simply search all the terms equivalent by permuting conversions to one of the proofs for a term equivalent to the other. Two terms are equivalent when the proof structure of the two terms match exactly and the non-logical steps which correspond are equivalent. This observation is sufficient to establish the following formal result:
Corollary 5.2 The equivalence of proofs in CProc(A) is decidable whenever the equivalence of proofs in A is decidable.
Recall that all discrete polycategories and free polycategories (including those with negation) are decidable so that there is a ready source of decidable polycategories.
Of course, the procedure proposed is highly inefficient and we wish to finish the paper with some remarks on how one can make it more efficient. In order to decide the equality of two terms it is worth putting one term aside as a template. However, it is also sensible to ensure that this term has all tensor/par splitting done first and then all the tupling/cotupling. This structure can always be pulled up to the root of the term whenever an active multiplicative or additive type is present. This leaves the tensor/par forking and the injections/projections. The latter can be pulled up in a similar manner to [7]. Pulling up a forking to match a template term which starts with such is more complex: this is exactly where the complexity of rewirings (due to


the multiplicative units) in the purely multiplicative fragment bites. The complexity of solving this step remains an open question.

References
Abramsky, S., Computational interpretations of linear logic, Theoretical Computer Science 111
(1993), pp. 3–57.
Bellin, G. and P.J. Scott, On the π-calculus and linear logic, Theoretical Computer Science
135 (1994), pp. 11–65. Also at
urlhttp://www.csi.uottawa.ca/∼phil/.
Benton, N., G. Bierman, V. de Paiva and M. Hyland, A term calculus for intuitionistic linear logic, in: M. Bezem and J. F. Groote, editors, Proc. Intl. Conference on Typed Lambda Calculi and Applications, Lecture Notes in Computer Science 664 (1993), pp. 75–90.
Blute, R.F., J.R.B. Cockett, R.A.G. Seely and T.H. Trimble, Natural deduction and coherence for weakly distributive categories, Journal of Pure and Applied Algebra 3 (1996), pp. 229–296. Also at http://www.math.mcgill.ca/rags/ .
Cockett, J.R.B., J. Koslowski and R.A.G. Seely, Morphisms and modules for poly-bicategories, Theory and Applications of Categories 11 (2003), pp. 15–74.
Cockett, J.R.B. and R.A.G. Seely, Linearly distributive functors, Journal of Pure and Applied Algebra 143 (1999), pp. 155–203. Also at http://www.math.mcgill.ca/rags/ .
Cockett, J.R.B. and R.A.G. Seely, Finite sum-product logic, Theory and Applications of Categories 8 (2001), pp. 63–99.
Dershowitz, N. and Z. Manna, Proving termination with multiset orderings, Communications of the ACM 22 (1979), pp. 465–476.
Girard, J.-Y., Linear logic, Theoretical Computer Science 50 (1987), pp. 1–102. Also at
http://iml.univ-mrs.fr/{$\sim$}girard/ .
Hermida, C., Representable multicategories, Advances in Mathematics 151 (2000), pp. 164–225. Also at http://maggie.cs.queensu.ca/chermida/ .
Hughes, D. and R. van Glabbeek, Proof nets for unit-free multiplicative-additive linear logic (extended abstract), in: Proc. IEEE symposium on Logic in Computer Science (2003). Also at http://boole.stanford.edu/$\sim$dominic/ .
Jay, B., Languages for monoidal categories, Journal of Pure and Applied Algebra 59 (1989),
pp. 61–85.
Koh, T.W. and C.-H.L. Ong, Type theories for autonomous and ∗-autonomous categories:
I. Types theories and rewrite systems II. Internal languages and coherence theorems (1998). Available at http://users.comlab.ox.ac.uk/luke.ong/ .
Lambek, J., Multicategories revisited, in: J. Gray and A. Scedrov, editors, Categories in Computer Science and Logic: Proc. of the Joint Summer Research Conference, American Mathematical Society, 1989 pp. 217–239.
Pastro, C.A., “ΣΠ-Polycategories, additive Linear Logic, and process semantics,” Master’s thesis,	University	of	Calgary	(2004).	Available	at http://www.cpsc.ucalgary.ca/{$\sim$}pastroc/ .

The units
The way in which the cut elimination procedure handles the reductions and permuting conversions when the index sets are empty can be quite subtle. In the case of ltensor or rpar, however, it is very straightforward, however the other cases are quite tricky. To clarify this, in this section we make these special cases explicit.
The annotated nullary versions of the inference rules are:
,	 

α{} :: Γ,α : 0 ▶ ∆ (cotuple)	α{} :: Γ ▶ α : 1, ∆ (tuple)
	f :: Γ ▶ ∆			f :: Γ ▶ ∆	
(ltensor)	(rpar)
α⟨() '→ f ⟩ :: Γ,α : T▶ ∆	α⟨() '→ f ⟩ :: Γ ▶ α : ⊥, ∆
(lpar)	(rtensor)
α⟨⟩ :: α : ⊥▶	α⟨⟩ :: ▶ α : T

  		J
In the cotuple and tuple rules the notation is ambiguous as one cannot derive the context from the terms. To correct this we shall write the terms above as α{ }Γ▶∆. An important observation is that the nullary rtensor and nullary lpar rules may only be applied if there are no other “active” chan- nels present. Considering this, there are three (non-dual) reductions that are relevant to this setting corresponding to the rewrites (3), (7), and (13). The reduction (9) is not relevant to this setting as it will reduced to (13). Given a term f :: γ : X, ∆1 ▶ ∆2 the reductions are as follows:

(3) α{ }Γ1▶Γ2,γ:X ;γ f =⇒ α{ }Γ1,∆1▶Γ2 ,∆2

(7)	α⟨() '→ g⟩ ;γ f =⇒ α⟨() '→ g;γ f ⟩

(13) γ⟨⟩ ;γ γ⟨() '→ f ⟩ =⇒ f

With the interchange rules the typing of the term will determine which interchanges are allowed to take place. For example, consider (23), the ltensor- rtensor identity:


α (α )
'→ β  βj|Λj '→gj
  e==zβ βj|Λj '→gj

i i	β |Λ
∪ ( {α }) '→f
β |Λ
∪ {α} '→α⟨(α )
'→f ⟩

On the left-hand side the only time the nullary rtensor rule may be applied


is if	i{αi} = ∅ and no other channels are “active”. This corresponds to the term
α⟨() '→ β⟨ ⟩⟩ :: α : T▶ β : T
However, on the right-hand side the nullary rtensor rule will never apply as the channel α is still “active”. Thus, in this case, these rules may not be interchanged. If only the ltensor is empty (on channel α) then the rules may freely be interchanged.
Considering the typing of the terms this leaves 13 permuting conversion: three versions of (15) (corresponding to the cases when only I = ∅, only J = ∅, and both I = J = ∅), (16), three variants of (17), (18) (when I = ∅), (20), three variants of (22), and finally (23) (when I = ∅). Fortunately, the form of the rewrites are quite similar, and so we present only the three variants of (15), (20), and (23). For simplicity we assume that α is a domain channel and β is a codomain channel. Here we drop the typing on the term and indicate to the right in brackets.




(23) α	() '→ β	βj |Λj '→gj
βk|Λk '→f
j/=k
e===zβ	βj|Λj '→gj
βk|Λk ∪ {α} '→α⟨() '→f ⟩
j/=k

Proof of cut elimination and the Church-Rosser prop-
erty
In this appendix we show that the cut elimination procedure terminates and that the rewrite system induced by the cut elimination rewrites and the per- muting conversion has the Church-Rosser property. We begin by proving that cut elimination is a terminating procedure.
Remark B.1 The number of rewritings in our system motivates the use of a “generalized” system of rewritings which help to reduce this number. Let α(f ) denote any of the morphisms
α{ai '→ fi}i,	α[a]f,	α⟨(αi) '→ f ⟩,	α⟨αi | Λi '→ fi⟩i


Then α(f );γ g =⇒ α(f ;γ g) will be used respectively to denote:

α{a '→ f } ; g  (3)   α{a '→ f ; g}
α[a]f ; g  (5)   α[a](f ; g)
α⟨(α ) '→ f ⟩; g  (7)   α⟨(α ) '→ f ; g⟩


α⟨αi

| Λi

'→ fi⟩i;γ
g	(9)	α	αi | Λi '→ fi
αk | Λk ∪ Λ(g) \ {γ} '→ fk;γ g
 


i/=k

Dually g;γ α(f )α(g;γ f ) will denote any of the rewrites (4), (6), (7), or (10). The rewrites (11) and (13) (and their duals) may be represented as γ(f );γ γ(g)f ;γ g and the permuting conversions (15) through (24) may be represented as α(β(f ))β(α(f )).

The cut measure on terms
The purpose of this section is to show that the cut elimination procedure terminates. To this end we define a bag of cut heights and show that the bag is strictly reduced on each of the cut elimination rewrites.
We begin by defining the multiset ordering of Dershowitz and Manna [8]. Let (S, >) be a partially-ordered set, and let M(S) denote the multisets (or bags) over S. For M, N ∈ M(S), M > N (“>” is called the multiset (or bag) ordering), if there are multisets X, Y ∈ M(S), where ∅ /= X ⊆ M, such
that
N = (M\X) ∪ Y	and	(∀y ∈ Y )(∃x ∈ X) x > y
where ∪ here is the multiset union.
For example,
[3] > [2, 2, 2, 1],	[7, 3] > [7],	[5, 2] > [5, 1]
Recall from [8] that if (S, >) is a total order then M(S) is a total order. To see this consider M, N ∈ M(S).  To determine whether M > N sort
the elements of both M and N and then compare the two sorted sequences lexicographically.
We now define the height of a term as:
hgt[a] = 1 when a is an atomic map (or an identity)
hgt[α{ai '→ fi}i∈I] = 1 + max{hgt[fi] | i ∈ I}
hgt[α[ak] · f ] = 1 + hgt[f ]


hgt[α⟨(αi)i∈I '→ f ⟩] = 1 + hgt[f ]
hgt[α⟨αi | Ωi '→ fi⟩i∈I] = 1 +	i∈I hgt[fi]
hgt[f ; g] = hgt[f ]+ hgt[g]
The height of a cut is defined simply as its height, e.g., cuthgt[f ; g] = hgt[f ; g]. Define a function Λ : T → bag(N) which takes a term to its bag of cut heights.
Proposition B.2
If t1  t2 then Λ(t1) > Λ(t2).
If t	(a) t and (a) is an interchange which does not involve the nullary cotuple or tuple then Λ(t1) = Λ(t2).
Proof. We begin with the proof of part (i). There are three properties that must be shown: hgt[t1] ≥ hgt[t2], the height of each non-principal cut does not increase, and the height of any cut produced from the principal cut is strictly less than the height of the principal cut.
A simple examination of the rewrites will confirm that if t1 =⇒ t2 then hgt[t1] ≥ hgt[t2]:


(1), dually (2)	hgt[f ; 1] = hgt[f ]+ hgt[1] > hgt[f ]




(3), dually (4)
hgt[α{ai '→ fi}i∈I;γ g] = hgt[α{ai '→ fi}i∈I]+ hgt[g]
= 1 + max{hgt[fi] | i ∈ I} + hgt[g]
= 1 + max{hgt[fi]+ hgt[g] | i ∈ I}
= hgt[α{ai '→ fi;γ g}i∈I]


If I = ∅ then

hgt[α{ };γ g] = hgt[α{ }]+ hgt[g] > hgt[α{ }]




(5), dually (6)
hgt[α[ak]f ;γ g] = hgt[α[ak]f ]+ hgt[g]
= 1 + hgt[f ]+ hgt[g]
= hgt[α[ak](f ;γ g)]





(7), dually (8)
hgt[α⟨(αi)i∈I '→ f ⟩;γ g] = hgt[α⟨(αi)i∈I '→ f ⟩ + hgt[g]
= 1 + hgt[f ]+ hgt[g]
= hgt[α⟨(αi)i∈I '→ f ;γ g⟩



(9), dually (10)

hgt[α⟨αi | Ωi '→ fi⟩i∈I;γ g] = hgt[α⟨αi | Ωi '→ fi⟩i∈I]+ hgt[g]
= 1 +	hgt[fi]+ hgt[fk]+ hgt[g]
k/=i∈I

= hgt  α	αi | Ωi '→ fi
αk | Ωk '→ fk;γ g
	⎤


k/=i∈I


(11), dually (12)
hgt[γ[ak]f ;γ γ{ai '→ gi}i∈I] = hgt[γ[ak]f ]+ hgt[γ{ai '→ gi}i∈I]
= 1 + hgt[f ]+1+ max{hgt[gi] | i ∈ I}
> hgt[f ]+ max{hgt[gi] | i ∈ I}
≥ hgt[f ]+ hgt[gk]
= hgt[f ;γ gk]


(13), dually (14)
hgt[γ⟨αi|Ωi '→ fi⟩i;γ γ⟨(αi)i '→ g⟩] = hgt[γ⟨αi|Ωi '→ fi⟩i]+ hgt[α⟨(αi)i '→ g⟩]
= 1 + Σ hgt[fi]+1+ hgt[g]

>	hgt[fi]+ hgt[g]
i
= hgt [fn;αn (··· (f2;α2 (f1;α1 g)) ··· )]
If I = ∅ then
hgt[γ⟨ ⟩i;γ γ⟨() '→ g⟩] = hgt[γ⟨ ⟩i]+ hgt[γ⟨() '→ g⟩]
= 1 +1+ hgt[g]
> hgt[g]


Moreover, this implies that cuts below and cuts above the redex will not increase their cut height on a rewriting.
Finally, consider the principal cut of the reduction. Rewrite (1) (dually
(2)) removes a cut and so strictly reduces the bag of cut heights. It is an easy observation that (5), (7), (9), and (11) (and their duals) each replace a cut with one of lesser height, and that (3) and (13) (and their duals) replace a cut with zero or more cuts of lesser height. Thus applying any of the rewrites strictly reduces the bag.
We now prove part (ii). For the equations (15), (16), (17), and (18) we as- sume that the index sets are non-empty. This then implies that the commuting conversions are all of the form α(β(f )) and thus

hgt[α(β(f ))] = 1 + hgt[β(f )] = 1 +1+ hgt[f ] = hgt[β(α(f ))]

which proves that the height does not change across these (non-empty cotuple and tuple) interchanges.	 
To see that the height is not invariant across the empty cotuple (dually the tuple) rule recall one of the nullary versions of the rewrite (15):

α{} e===zβ{bj '→ α{ }}j

The height on the left-hand side is one, while on the right-hand side the height is two.

Proof of the Church-Rosser property
In this section we present a proof of the Church-Rosser property for mor- phisms. We wish to show that given any two morphisms related by a series of reductions and permuting conversions
t1  t2  t3 	···		 tn−2  tn−1  tn

there is an alternative way of arranging the reductions and permuting con- versions so that t1 and tn can be reduced to terms which are related by the permuting conversions alone. That is, we wish to show that there is a conver- gence of the following form:

t1	tn
	
'	∗	t'


When the rewriting system terminates (in the appropriate sense) this al- lows the decision procedure for the equality of ΣΠ-terms to be reduced to the decision procedure for the permuting conversions (see Section 5). In order to test the equality of two terms, one can rewrite both terms into a reduced form (one from which there are no further reductions), and these will be equal if and only if the two reduced forms are equivalent through the permuting conversions alone. In the current situation the reduction process is, of course, the cut-elimination procedure.
Following [7] we say a rewrite system is locally confluent modulo equa- tions if any (one step) divergence of the following form


t0
 
t1	t2
t0
or	
t1	t2

(where “  ” denotes a reduction and “t1  t2 ” an equation) has a con- vergence, respectively, of the form




t1







t'
t1
t2
and
t2

'
2


t'

where the new arrow “  ” indicates either an equality or a reduction in the indicated direction.
This gives:
Proposition B.3 Suppose (N, R, E) is a rewriting system with the equations equipped with a well-ordered measure on the rewrite arrows such that the mea- sure of the divergences is strictly greater than the measure of the convergences then the system is confluent modulo equations if and only if it is locally con- fluent modulo equations.
Proof. If the system is confluent modulo equations it is certainly locally con- fluent modulo equations. Conversely suppose we have a chain of reductions, equations, and expansions. We may associate with it the bag of measures of the arrows of the sequence.
The idea will be to show that replacing any local divergence in this chain by a local confluence will result in a new chain whose bag measure is strictly smaller. However, this can be seen by inspection as we are removing the arrows


associated with the divergence and replacing them with the arrows associated with the convergence. The measure on the arrows associated with the diver- gence is strictly greater then that of the measure on the arrows associated with the convergence.
Thus, each rewriting reduces the measure and, therefore, any sequence of rewriting on such a chain must terminate. However, it can only terminate when there are no local divergences to resolve. This then implies that the end result must be a confluence modulo equations.	 


Resolving critical pairs locally
The proof of Church-Rosser involves examining all the possible critical pairs involving reductions or reductions and conversions, and showing that they are all of the form shown above and that they may be resolved in the way shown above. It then must be shown that there is some measure on the arrows which decreases when replacing a divergence with a convergences. This will then suffice to show that our system is locally confluent modulo equations, so that by Proposition B.3, it is confluent modulo equations. The rewrites
(1)–(12) are the “reductions” and the commuting conversions (13)–(24) are the “equations”. The resolutions of the critical pairs will be presented using the “generalized” rewrites (see Remark B.1). For the additive rewrites see [15] where they have been written out in detail.
The reductions are as follows. Note that these reductions assume that all index sets are non-empty. The reductions when the index set is empty are handled separately below.
Reduction diagram 0: 1; 1  (1) 
(2)
Reduction diagram 1: Substitute (3), (5), (7), or (9) for (a) to get the
reduction diagrams for (1)–(3), (1)–(5), (1)–(7), and (1)–(9).

α(f );γ 1
	

α(f )
α{(1)}
α(f ;γ 1)


Substituting the dual rewrites in the mirror image of the diagram above give the dual reduction diagrams.
Reduction diagram 2: each row in the table corresponds to the resolution


of the critical pair (a)–(b).






α(f );γ β(g)

	

α(f ;γ β(g))

α((b))

α(β(f ;γ g))






(c)
β(α(f );γ g)

β((a))

β(α(f ;γ g))







Reduction diagram 3: each row in the table corresponds to the resolution of the critical pair (a)–(b).


α(β(f ));γ g
	

α(β(f );γ g)



α((c))
β(α(f ));γ g

(c)

β(α(f );γ g)


β((a))

α(β(f ;γ g))	(d)	β(α(f ;γ g))


Reduction diagram 4: each row in the table corresponds to the resolution


of the critical pair (a)–(b).

α(γ(f ));γ β(g)
	

α(γ(f );γ β(g))





α((c))
γ(α(f ));γ β(g)

(c)

β(γ(α(f ));γ g)

β((b);1)

β(α(γ(f ));γ g)


β((a))

α(β(γ(f );γ g))	(d)	β(α(γ(f );γ g))

where w ∈ {15, 16, 17, 18}, x ∈ {16, 19, 20, 21}, y ∈ {17, 20, 22, 23}, and
z ∈ {18, 21, 23, 24}. This means that there are 64 reductions that fit this general case!
Reduction diagram 5: each row in the table corresponds to the resolution of the critical pair (a)–(b).



γ(α(f ));γ γ(g)
	

α(f );γ g
(c')
α(γ(f ));γ γ(g)

(c)



α(γ(f );γ
g)  α(γ(f );
α((a))
γ(g))




where x+, y∗ means zero or one application of the rewrite (x) and zero or more applications of the rewrite (y).


This may be a good time for a concrete example. Suppose (a, b, c, c') = (13, 21, 5, (5+, 6∗)), i ∈ {1,..., n}, and α ∈ Ωk. The reduction diagram for this case is:


γ	γi | Ωi '→fi
γk | Ωk '→α[a]fk
;γ γ⟨(γi)i
'→g⟩

i/=k
fn;γn (··· (α[a]fk;γk (··· (f1;γ g) ··· )) ··· )	α[a]γ⟨γi | Ωi '→fi⟩i;γ γ⟨(γi)i '→g⟩
(5)


fn;γn (··· (α[a](fk;γk (··· (f1;γ g) ··· ))) ··· )
(5)

(6)∗
α[a](fn;γn (··· (fk;γk (··· (f1;γ g) ··· ))) ··· )  α[a](γ⟨γi | Ωi '→fi⟩i;γ γ⟨(γi)i '→g⟩)
Reduction diagram 6: each row in the table corresponds to the resolution
of the critical pair (a)–(b).



γ(f );γ γ(β(g))
	

f ;γ β(g)
(c')
γ(f );γ β(γ(g))

(c)



β(f ;γ
g)  β(γ(f );
β((a))
γ(g))




where x+, y∗ means zero or one application of the rewrite (x) and zero or more applications of the rewrite (y).
We now explore the cases when the index sets may be empty. For the empty ltensor (dually rpar) rule the rewrites fit the cases above. The cases for the empty cotuple (dually tuple) and rtensor (dually lpar) however do not. We start by first examining what happens to the reduction diagrams for the


case of the empty cotuple (dually tuple).
Reduction diagram 1:  α{ }	 (1)  α{} 
Reduction diagram 2: there are two (non-dual) cases corresponding to only I = ∅ and both I = J = ∅. Each row in the table corresponds to the resolution of the critical pair (3)–(a).

α{ };γ β(g)

α{}	β(α{ };γ g)
	
β(α{ })

Dual to the above diagram is the nullary reductions for β. If both α and β
have empty index sets:

α{ };γ β{} 

α{}	β{} 

Reduction diagram 3: there are three cases. The first we describe is when both I = J = ∅. The resolution is as follows:

α{ };γ g
α{}	β{ };γ g
	
β{} 

The two remaining cases corresponding to whether the apex (of the re- duction diagram) starts with α{} or with β(α{ }). Each row in the table corresponds to the resolution of the critical pair (3)–(b) in the reduction


diagram on the left and (a)–(b) in the reduction diagram on the right.

α{ };γ g	β(α{ });γ g
			

α{} 
(a)

β(α{ })






β((3))
β(α{ });γ g
(a)

β(α{ };γ g)
β(α{ };γ g)
β((3))

β(α{ })






(b)
α{ };γ g
(3)

α{} 

Reduction diagram 4: The channel α is non-empty and if channel γ is empty the reduction diagram is identical.
Reduction diagram 5: each row in the table corresponds to the resolution of the critical pair (a)–(b).

γ(α{ });γ γ(g)
α{ };γ g	α{ };γ γ(g)

α{} 

where 3+, 4∗ means zero or one application of the rewrite (3) and zero or more applications of the rewrite (4).
Reduction diagram 6: each row in the table corresponds to the resolution of the critical pair (a)–(b).

γ(f );γ γ(β{ })
f ;γ β{}	γ(f );γ β{} 

β{} 

where 4∗ means zero or more applications of the rewrite (4).
We now examine what happens to the reduction diagrams for the case of the empty rtensor (dually lpar). Due to the typing constraints the only reduction diagrams that need be considered are 1 and 6.


Reduction diagram 1: α⟨ ⟩	 (1)  α⟨⟩ 
(13)
Reduction diagram 6: each row in the table corresponds to the resolution of the critical pair (13)–(a).

γ⟨ ⟩;γ γ⟨() '→ β(g)⟩
β(g)	γ⟨ ⟩;γ β(γ⟨() '→ g⟩)

β(γ⟨ ⟩;γ γ⟨() '→ g⟩)

The measure on the rewriting arrows
We define a measure λ : A → bag(N) on the rewriting arrows as follows:
if t1   x  t2 then λ(x) = min{Λ(t1), Λ(t2)}
if t1	x	t2 then λ(x) = max{Λ(t1), Λ(t2)} where Λ(t) is the bag of cut heights of t.
A quick examination of the reduction diagrams now confirms that this
measure will decrease when we replace a divergence with a convergence.
This completes the proof of the proposition:
Proposition B.4 CProc(A) under the rewrites (1)–(14) is confluent modulo the equations (15)–(24).

Proof that CProc(A) is a polycategory
In order to show that CProc(A) is a polycategory three properties must be satisfied:
CProc(A) must have identity maps which behave in the correct manner,
composition in CProc(A) must be associative, and
composition in CProc(A) must satisfy the interchange law. We prove each in turn.
Lemma C.1 The identity acts as a neutral element with respect to composi- tion. That is, given terms of the form
f :: Γ → ∆,γ : X	and	1X :: γ : X → δ : X


we have f ;γ 1X = f (up to renaming channels), and dually, given terms of the form
1X :: γ : X → δ : X	and	f :: δ : X, Γ → ∆
we have 1X;δ f = f (Upton renaming channels).
Proof. We shall suppose the identity is on the left; duality covers the other case. The case where f is the identity is clearly true. So suppose f is of the form α(f ), where α /= γ. If α(f ) is a tuple or rtensor with I = ∅ then α(f );γ 1X will reduce to α{} or δ⟨⟩ respectively. Otherwise, any rewrite applied to α(f );γ 1X will move the identity in α(f ;γ 1X) moving the cut onto a smaller term from which we may apply the inductive hypothesis. Thus, the only cases we must explore is when the term f operates on γ at the top level.
The proof will proceed by structure induction on the term γ(f ). Without loss of generality we may assume that f is cut free.
The base case is a cut with an atomic identity: here the cut-elimination step removes the identity and the result is immediate.
f = γ{ai '→ fi}i∈I. There are two cases to consider corresponding to I = ∅
and I /= ∅. In the first case 1X = δ{} and by rewrite (4) this reduces to δ{ }. In the second case we have X =  i ai : Xi and 1X = δ{ai '→ γ[ai]1Xi }i.
This gives

γ{ai '→ fi}i;γ δ{ai '→ γ[ai]1Xi }i =⇒ δ{ai '→ γ{ai '→ fi}i;γ γ[ai]1Xi }i
=⇒ δ{ai '→ fi;γ 1Xi }i

which moves the composition onto smaller terms. Applying the inductive hypothesis now gives the desired result.


gives
i	i


γ[ak]f ';γ γ{ai '→ δ[ai]1X }i =⇒ f ';γ δ[ak]1X

=⇒ δ[ak](f ';γ 1X )

which moves the composition onto a smaller term. Applying the inductive hypothesis now gives the desired result.
f = γ⟨(γi) i '→ f '⟩. In this case X =  i γi : Xi (in f and the domain of 1X
	



γ⟨(γi)i '→ f '⟩;γ δ⟨(δi)i '→ γ⟨γi | δi '→ 1X ⟩i⟩
=⇒ δ⟨(δi)i '→ γ⟨(γi)i '→ f '⟩;γ γ⟨γi | δi '→ 1X ⟩i⟩
=⇒ δ⟨(δi)i '→ (··· (f ';γ 1X ) ··· );γ 1X ⟩
which moves the composition onto smaller terms. Applying the inductive hypothesis now gives the desired result.
f = γ⟨γi | Ωi '→ fi⟩i∈I. There are two cases to consider corresponding to I = ∅ and I /= ∅. In the first case 1X = γ⟨() '→ δ⟨⟩ which by (13) reduces to δ⟨ ⟩. In the second case we have X =  i γi : Xi (in f and the domain of

γi '→ 1Xi ⟩i⟩. In this case suppose I = {1,..., n}. This gives
γ⟨γi | Ωi '→ fi⟩i;γ γ⟨(γi)i '→ δ⟨δi | γi '→ 1Xi ⟩i⟩
=⇒ fn;γn (··· (f1;γ1 δ⟨δi | γi '→ 1Xi ⟩i) ··· )
=⇒ δ⟨δi | Ωi '→ fi;γi 1Xi ⟩i
which moves the composition onto smaller terms. Applying the inductive hypothesis now gives the desired result.
This now completes the proof that the identity acts as a neutral element with respect to composition in this system.	 
Lemma C.2 Cut satisﬁes the associative law. That is, given terms of the form
f :: Γ1 → Γ2,γ : X	g :: γ : X, ∆1 → ∆2,δ : Y	h :: δ : Y, Φ1 → Φ2
the composites (f ;γ g);δ h and f ;γ (g;δ h) are ∼-equivalent.
Proof. The proof proceeds by structural induction on f , g, and h; without loss of generality we may assume that f , g, and h are cut free. Recall that if two terms are ∼-equivalent then they must be related through the permuting conversions alone. Without explicitly mentioning where, duality will be used to reduce the number of cases presented. To show that the composites are
∼-equivalent we will make use of the generalized rewrites. Additionally, the notation
f ; g; h  ;l  (f ; g); h	and	f ; g; h  ;r  f ; (g; h) will be used to indicate the two possible composites of f ;γ g;δ h.

If f = 1X equivalent.
then 1 ; g; h   ;l   g;
h shows that the composites are ∼-

Suppose now that f is of the form α(f ), where α /= γ. If α(f ) is a tuple or rtensor with I = ∅ then f ;γ g;δ h will respectively reduce to α{} or β⟨⟩ 


(where β is the codomain channel of h). If I /= ∅ then in following reduction diagram

α(f );γ g;δ h

α(f ;γ g);δ h	α(f );γ (g;δ h)

;	;
α((f ;γ g);δ h)	∗	α(f ;γ (g;δ h))

the composites are moved onto smaller terms, which by induction are satisfy the associative law, and hence, both composites are ~-equivalent.
It remains to examine the case where f is of the form γ(f ). There are two cases corresponding to whether g is of the form β(g), where β /= γ and β /= δ, or γ(g). (The dual rewrites will suffice for the β = δ case.) In the first case if β(g) = β{} then both composites will reduce to β{ }. Note the β(g) /= β⟨⟩ as both composites are defined. So suppose that β(g) /= β{ }. The following reduction diagram shows that both composites are ~-equivalent (by induction):

γ(f );γ β(g);δ h

β(γ(f );γ g);δ h	γ(f );γ β(g;δ h)

;	;
β((γ(f );γ g);δ h)	∗	β(γ(f );γ (g;δ h))

In the second case (β = γ) there is no need to generalize as there are only two (non-dual) rewrites (which also has the benefit of providing a “concrete” example). The first is when the left-hand side composite is the rewrite (11):


γ{a '→ f } ; γ[a ]g; h 	;l	
(fk;γ g);δ h


;r	∗
γ{ai '→ fi}i;γ γ[ak](g;δ h)	;	fk;γ (g;δ h)


The second case is when the left-hand side composite is the rewrite (13).
In this case assume that I = {1,..., n}:

α⟨α | Ω '→ f ⟩ ; γ⟨(γ ) '→ g⟩; h 	;l	 (f ;	(··· (f ;	g) ··· )); h


;r	∗

α⟨αi | Ωi '→ fi⟩i;γ γ⟨(γi) '→ g;δ h⟩   ;	(fn;γn (··· (f1;γ1 (g;δ h)) ··· ))

If all of f , g, and h are atomic then composition is associative as it must be associative in the underlying polycategory. If some of f , g, and h are atomic a quick check of the possibilities will show that one ends up with a case similar to one of the cases above.
Thus, composition is associative.	 
Lemma C.3 Cut satisﬁes the interchange property. That is, given terms of the form
f :: Γ1 → γ : X, Γ2,δ : Y   g :: ∆1,γ : X → ∆2   h :: δ : Y, Φ1 → Φ2

the composites (f ;γ g);δ h and (f ;δ h);γ g are ~-equivalent. Dually, given se- quents of the form
f :: Γ1 → Γ2,γ : X   g :: ∆1 → δ : Y, ∆2   h :: γ : X, Φ1,δ : Y → Φ2

the composites f ;γ (g;δ h) and g;δ (f ;γ h) are ~-equivalent.
Proof. The proof proceeds by structural induction on f , g, and h; without loss of generality we may assume that f , g, and h are cut free. Without explicitly mentioning where, duality will be used to reduce the number of cases presented. In the following
f ; g; h   ;g  (f ; g); h	and	f ; g; h   ;h  (f ; h); g

will be used respectively to indicate composing first with g and composing first with h.
Notice that f may not be 1X as it requires at least two codomain channels. So suppose that f is of the form α(f ). If f = α{} then both composites will reduce to α{ }. The term f may not be the empty rtensor since, as noted above, it requires at least two codomain channels. If I /= ∅ then in the


reduction diagram

α(f );γ g;δ h

α(f ;γ g);δ h	α(f ;δ h);γ g

;	;
α((f ;γ g);δ h)	∗	α((f ;δ h);γ g)

the composites are moved onto smaller terms, which by induction satisfy the interchange law, and hence, both composites are ~-equivalent.
It remains to examine the case where f is of the form γ(f ). There are two cases corresponding to whether g is of the form β(g), where β /= γ and β /= δ, or γ(g). (The dual rewrites will suffice for the β = δ case.) In the first case if β(g) = β{} then both composites will reduce to β{ }. If β(g) = β⟨⟩ (empty lpar) then both composites will reduce to f ;δ h.
Now suppose that β(g) is not a nullary operation. The following reduction diagram shows that both composites are ~-equivalent (by induction):

γ(f );γ β(g);δ h

β(γ(f );γ g);δ h	γ(f ;δ h);γ β(g)

;	;
β((γ(f );γ g);δ h)	∗	β(γ(f ;δ h);γ g)

In the second case (β = γ) there is only one possible choice: composition with g is an application of the rewrite (11). Explicitly,


γ{a '→ f } ; γ[a ]g; h 	;l	
(fk;γ g);δ h


;h	∗
γ{ai '→ fi;δ h}i;γ γ[ak]g	;	(fk;δ h);γ g

which shows that the composites are ~-equivalent.
If all of f , g, and h are atomic then composition satisfies the interchange law as it must satisfy the interchange law in the underlying polycategory. If


some of f , g, and h are atomic a quick check of the possibilities will show that one ends up with a case similar to one of the cases above.
Thus, composition satisfies the interchange law.	 
