	Electronic Notes in Theoretical Computer Science 188 (2007) 117–142	
www.elsevier.com/locate/entcs

Equivalence of Two Formal Semantics for Functional Logic Programs 1
F.J. Lo´pez-Fraguas2 J. Rodr´ıguez-Hortala´2
J. S´anchez-Hern´andez2
Departamento de Sistemas Informa´ticos y Computacio´n Universidad Complutense de Madrid
Madrid, Spain

Abstract
A distinctive feature of modern functional logic languages like Toy or Curry is the possibility of programming non-strict and non-deterministic functions with call-time choice semantics. For almost ten years the CRWL framework [6,7] has been the only formal setting covering all these semantic aspects. But recently [1] an alternative proposal has appeared, focusing more on operational aspects. In this work we investigate the relation between both approaches, which is far from being obvious due to the wide gap between both descriptions, even at syntactical level.
Keywords: Functional logic programming, equivalence of semantics


Introduction
In its origin functional logic programming (FLP) did not consider non-deterministic functions (see [8] for a survey of that era). Inspired in those ancestors and in Hussmann’s work [12], the CRWL framework [6,7] was proposed in 1996 as a formal basis for FLP having as main notion that of non-strict non-deterministic function with call-time choice semantics. At the operational level, modern FLP has been mostly influenced by the notions of definitional trees [2] and needed narrowing [3].
Both approaches –CRWL and needed narrowing– coexist with success in the development of FLP (see [15,9] for recent respective surveys). It is tacitly accepted in the FLP community that they essentially speak of the same ‘programming stuff’, realized by systems like Curry [11] or Toy [14], but up to now they remain techni- cally disconnected. One of the reasons has been that the formal setting for needed

1 Work partially supported by the Spanish projects TIN2005-09207-C03-03 (MERIT-FORMS-UCM) and S-0505/TIC/0407 (PROMESAS-CAM).
2 Email: {fraguas,jaime}@sip.ucm.es, jrodrigu@fdi.ucm.es

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.05.042

narrowing is classical rewriting, that is known to be unsound for call-time choice, which requires sharing.
But recently [1] a new operational formal description of FLP has been proposed, coping with narrowing, residuation, laziness, non-determinism and sharing, for a language called here FLC for its proximity to Flat Curry [10].
There is a long distance in the formal aspects of the two approaches, each one having its own merit: CRWL provides a concise and clear way for giving logical semantics to programs, with a high level of abstraction and a syntax close to the user, while FLC and its semantics are closer to computations and concrete imple- mentations with details about variable bindings representation.
The goal of our work is to relate both approaches in a technically precise manner. In this way, some known or future results obtained for one of them could be applied to the other.
The rest of the paper is organized as follows. Sections 2 and 3 present the essentials of CRWL and FLC needed to relate them. Section 4 sets some restrictions assumed in our work and gives an overview of the structure of our results. Section
5 relates CRWL to CRWLF LC, a new intermediate formal description introduced as a bridge between CRWL and FLC. Section 6 is the main part of the work and studies the relation between CRWLF LC and FLC. Section 7 gives some conclusions.
Some lengthy or of secondary interest proofs have been moved to an appendix.

The CRWL Framework: a Summary
We assume a signature Σ = CS∪FS, where CS (FS) is a set of constructor symbols (defined function symbols) each of them with an associated arity; we sometimes write CSn (FSn resp.) to denote the set of constructor (function) symbols of arity
n. As usual notations write c, d . . . for constructors, f, g . . . for functions and x, y . . .
for variables taken from a numerable set V.
The set of expressions Exp is defined as usual: e ::= x | h(e1,..., en), where h ∈ CSn ∪ FSn and e1,..., en ∈ Exp. The set CTerm of constructed terms (or c-terms) is defined analogously but with h restricted to CS, i.e., function symbols are not allowed. The intended meaning is that Exp stands for evaluable expressions while CTerm are data terms. We will also use the extended signature Σ⊥ = Σ ∪
{⊥}, where ⊥ is a new constant (0-arity constructor) that stands for the undeﬁned
value. Over this signature we build the sets Exp⊥ and CTerm⊥ in the natural way. The set CSubst (CSubst⊥ resp.) stands for substitutions or mappings from V to CTerm (CTerm⊥ resp.). Both kinds of substitutions will be written as θ, σ . . .. The notation σθ denotes the composition of substitutions in the usual way. The notation o stands for tuples of any of the previous syntactic constructions.
The original CRWL logic in [6,7] introduced strict equality as a built-in con- straint and program rules optionally contain a sequence of equalities as condition. Within this work, as FLC does not consider built-in equality, we restrict the class of programs. Then a CRWL-program P is a set of rules of the form: f (t) = e, where f ∈ FSn, t is a linear (without multiple occurrences of the same variable) n-tuple



Fig. 1. Rules of CRWL

of c-terms and e ∈ Exp. We write Pf for the set of rules defining f .
Rules of CRWL (without equality) are presented in Figure 1. Rule (B) al- lows any expression to be undefined or not evaluated (non-strict semantics). Rule (Red) is a proper reduction rule: for evaluating a function call it uses a compatible program-rule, performs parameter passing (by means of a substitution θ) and then reduces the body. This logic proves approximation or reduction statements of the form e → t, where e ∈ Exp⊥ and t ∈ CTerm⊥. Given a program P, the denotation
of an expression e with respect to CRWL is defined as [e]]P	= {t | e → t}.
Example 2.1 Consider the following CRWL-program P, where 0, 1 are constant data constructors:
coin	=	0	repeat(x)	=	x:repeat(x)

coin	=	1	heads(x:y:xs)	=	(x,y)
Notice that P is non-confluent (because of the rules for coin) and non-terminating (because of the rules for repeat).
Figure 2 shows a CRWL-derivation for heads(repeat(coin)) → (0, 0). Observe that in the derivation there is only one reduction statement for coin (namely coin → 0), and the obtained value 0 is then shared in the whole derivation, as corresponds to call-time choice. In alternative derivations, coin could have been reduced to 1 (or to ⊥). As a result, the denotation of heads(repeat(coin)) results to be

[[heads(repeat(coin))]]P	= {(0, 0), (1, 1), (⊥, 0), (0, ⊥), (⊥, 1), (1, ⊥), (⊥, ⊥), ⊥}

but (1, 0) and (0, 1) do not belong to that denotation, since they cannot be obtained by call-time choice.
Notice also that non-strict semantics and lazy evaluation are reflected in the derivation by the statements involving ⊥; all of them come from the statement repeat(coin) →⊥, indicating that the value of repeat(coin) is actually not needed for the whole computation.
We stress the fact that the CRWL-calculus is not an operational mechanism for executing programs, but a way of describing the logic of programs. As operational procedures the CRWL framework comes with various lazy narrowing-based goal- solving calculi not considered in this paper.



Fig. 2. A CRWL-derivation
The FLC Language and its Natural Semantics
The language FLC considered in [1] is a convenient –although somehow low-level– format to which functional logic programs like those of Curry or Toy can be trans- formed (not in a unique manner). This transformation embeds important aspects of the operational procedure of FLP languages, like are definitional trees and inductive sequentiality.
The syntax of FLC is given in Fig. 3. Notice that each function symbol f has exactly one definition rule f (x1,..., xn) = e with distinct variables x1,..., xn as
formal parameters. All non-determinism is expressed by the use of or choices in right-hand sides and also all pattern matching has been moved to right-hand sides by means of nesting of (f)case expressions. Let bindings are a convenient way to
achieve sharing.


Fig. 3. Syntax for FLC programs

An additional normalization step over programs is assumed in [1]. In normalized expressions each constructor or function symbol appears applied only to distinct variables. This can be achieved via let-bindings. The normalization of e is written as e∗. Notice that any CRWL-expression e is also a FLC-expression, and therefore we can speak of its normalization e∗.
In [1] two operational semantics for FLC are given: a natural (big-step) seman- tics in the style of Launchbury’s semantics [13] for lazy evaluation (with sharing) for functional programming, and a small step semantics. CRWL itself being a big-step semantics, it seems more adequate to compare it to the natural semantics of [1],

which is shown 3 in Fig. 4. It consists of a set of rules for a relation Γ : e ⇓ Δ : v, indicating that one of the possible evaluations of e ends up with the head normal form (variable or constructor rooted) v. Γ, Δ are heaps consisting of bindings x '→ e for variables. An initial configuration has the form [] : e.

Fig. 4. Natural Semantics for FLC

Example 3.1 The program P of 2.1, written as normalized FLC-program, would become:
repeat(x)	=	let y = repeat(x) in x:y heads(x)	=	case x of
{x1:ys → case ys of {x2:xs → (x1, x2) }}
coin	=	0 or 1
Now, trying to find a FLC-derivation analogous to the CRWL one in Figure 2, we must first normalize the expression e ≡ heads(repeat(coin)), giving e∗ ≡ let l = (let c = coin in repeat(c)) in heads(l), and consider FLC-derivations with initial configuration [] : e∗. Now, we cannot expect to derive in FLC any reduction from e∗ to (0, 0), neither with the form [] : e∗ ⇓ Δ : (0, 0) (since the value (0, 0) is not normalized) nor with the form [] : e∗ ⇓ Δ : (x, x) with Δ(x) = 0 (since FLC only expresses reduction up to head normal form). Figure 5 contains a fragment of a FLC-derivation for [ ] : e∗ ⇓ Δ: (c1, c1), where Δ = [l1 '→ c1 : y1, c1 '→ coin, y1 '→ c1 : y2, y2 '→ repeat(c1)]. Notice that Δ(c1) = coin, but there is no way of reducing coin to 0 inside Δ. In Section 6 we will introduce an extension ⇓Ctx of ⇓ which is able to reduce to any depth and for which it will hold [ ] : e∗ ⇓Ctx Δ: (c1, c1) for some Δ with Δ(c1) = 0.

CRWL vs. FLC: Working Plan
In order to establish the relation between CRWL and FLC (in Section 6) we first adapt CRWL to the syntax of FLC. For this purpose we introduce the rewriting

3 The rule Guess of [1] is skipped due to some restrictions to be imposed in the next section.


Fig. 5. Fragment of a FLC-derivation
logic CRWLF LC as a variant of CRWL with specific rules for managing let, or and
case expressions.


Fig. 6. Proof’s plan
The relation between CRWL and FLC is established through this intermediate logic. The working plan is sketched in Figure 6. Given a pair program/expression in CRWL we transform them into FLC-syntax and study the semantic equivalence of both versions of CRWL (Theorems 5.2 and 5.4). Then we focus on the equivalence of FLC with respect to CRWLF LC in a common syntax context (Theorems 6.2 and 6.12). FLC and CRWL are very different frameworks from the syntactical and the semantical points of view. The advantage of splitting the problem is that on one hand both versions of CRWL are very close from the point of view of semantics;

on the other hand CRWLF LC and FLC share the same syntax. The syntactic transformation and its correctness will be explained in Sect. 5.1.
There are important differences between FLC and CRWLF LC that complicates the task of relating them. The heaps used in FLC for storing variable bindings have not any (explicit) correspondence in CRWL. Another important difference is that the first one obtains head normal forms for expressions, while the second is able to
obtain any value of the denotation of an expression (in particular a normal form if it exists).
Differences do not end here. There are still two important points that enforces us to take some decisions: (1) FLC performs narrowing while CRWL is a pure
rewriting relation. In this paper we address this inconvenience by considering only the rewriting fragment of FLC. Narrowing acts in FLC either due to the presence of logical variables in expressions to evaluate or because of the use of extra variables in
program rules (those not appearing in left-hand sides). So we can isolate the rewrit- ing fragment by excluding this kind of variables throughout this work. Therefore, we assume that programs do not have extra variables and that expressions to be
reduced are ground. (2) The other difference stems from the fact that FLC allows
recursive let constructions. Since there is not a well established consensus about the semantics of such constructions in a non-deterministic context, and furthermore they cannot be introduced in the transformation of CRWL-programs, we exclude recursive let’s from the language in this work. In absence of recursive let ’s it is not difficult to see that a let with multiple variable bindings may be expressed as a sequence of nested let’s, each with a unique binding. For simplicity and without loss of generality we will consider only this kind of let’s. We assume from now on that programs and expressions fulfil the conditions imposed in (1) and (2).

The proof calculus CRWLFLC
The rewriting logic CRWLF LC preserves the main features of CRWL from a seman- tical point of view, but it uses the FLC-syntax for expressions and programs. In particular it allows let, case and or constructs, but like CRWL it proves statements of the form e → t where t ∈ CTerm⊥.
Rules of CRWLF LC are presented in Figure 7. The first three ones (B), (RR) and (DC) are directly incorporated from CRWL. Rules (Case), (Or) and (Let) have also a clear reading. Finally, rule (Red) is a simplified version of the corre- sponding rule in CRWL, as now we can guarantee that any function call in a deriva- tion only use c-terms as arguments. This is easy to check: the initial expression to reduce is in normalized form (arguments are all variables) and the substitutions applied by the calculus (in rules (Red), (Case) and (Let)) can only introduce c-terms. Given a program P the denotation of an expression e with respect to
CRWLF LC is defined as [e]]P	= {t | e → t}.
Example 5.1 Consider again the program P of Example 2.1, written in FLC- syntax as in Example 3.1. Figure 8 shows a fragment of a CRWLF LC-derivation for let l = (let c = coin in repeat(c)) in heads(l) → (0, 0).



Fig. 7. Rules of CRWLFLC


Fig. 8. A CRWLFLC -derivation


Relation between CRWLF LC and CRWL
We obtain here an equivalence result for CRWLF LC and CRWL. A skeleton of the proof is given in the zoomed part of Fig 6. It is based on a program transformation from CRWL-syntax (user syntax) to FLC-syntax. A similar translation is assumed but not made explicit in [1]. For technical convenience we split the transformation into two parts: first, and still within CRWL-syntax, we transform P into another

program P' which is inductively sequential ([2,9]), except for a function or defined by the two rules X orY=X and X orY= Y. The function or concentrates all the non-sequentiality (hence, all the indeterminism) of functions in right-hand sides. We speak of ‘inductively sequential with or’ (ISor) programs. Alternatively, programs can be transformed into overlapping inductively sequential format (see [9]), where a function might have several rules with the same left-hand side (as happens with the rules of or). Both formats are easily interchangeable. Such kind of transformations are well-known in functional logic programming. In the CRWL setting, a particular transformation has been proposed in [16], where it is proved the following result:
Theorem 5.2 Let P be a CRWL-program and e ∈ Exp⊥ a CRWL-expression.
Then [[e]]P	= [[e]]P '	where P' is the IS	transformed program of P.
or
Now, to transform ISor programs into normalized FLC-syntax can be done by simply mimicking the inductive structure of function definitions by means of (pos- sibly nested) case expressions.
The following algorithm performs it. It proceeds with each function f defined in the program, and works on a set of program rules (initially Pf , the whole set of rules for f ) and a linear call-pattern f (t1,..., tn) (initially the pattern f (X1,..., Xn)) which is compatible with the rules, i.e., the call-pattern subsumes the left-hand side of all the rules.
Definition 5.3 [FLC-transformation] Let P be an ISor CRWL-program.
Transformation of sets of rules. Let Q = {(f (t1) → e1),..., (f (tn) → en)} be a set of rules for a function f in P (Q ⊆ Pf ) and f (s) a pattern compatible with Q (i.e., it subsumes the left-hand side of all the rules in Q). The expression Δ(Q,f (s)) is defined according to the following (exhaustive, due to inductive sequentiality) possibilities:
There is an inductive position (if several, choose any) in f (s) wrt Q, i.e., a position u occupied by a variable X in (f (s)) and by constructor symbols c1,..., ck in the left-hand sides of rules of Q. For each i ∈ {1,..., k} we write
Qci for the set of rules in Q having the constructor ci at position u, and sci for
s[X/ci(Y )], where Y are fresh variables. Then
Δ(Q,f (s)) = case X of {c1 → Δ(Qc1 ,f (sc1 )); ... ; ck → Δ(Qck ,f (sck ))}
There is no inductive position in f (s) wrt Q. It should be the case that
Q = {f (s) = e}. Then: Δ(Q,f (s)) = e∗, where e∗ is the normalization of e (see sect. 3).
Transformation of whole programs. The (normalized) FLC-transformation of P is
Pˆ =   {f (X) = Δ(Pf ,f (X))}
f∈FS 

We give in Fig. 9 an example of the two program transformation steps (first to ISor, then to FLC). Notice that the final FLC-program does not contain rules for or, since it is included in the syntax of FLC, and there is a specific rule governing its semantics in the CRWLF LC-calculus.



Constructor symbols: 0∈ CS0, s∈ CS1
Source CRWL-program
f(0,Y) = s(Y) f(X,0) = X
f(s(X),s(Y)) = s(f(X,Y))

Transformed normalized FLC-program
f(X,Y) = f1(X,Y) or f2(X,Y)
f1(X,Y) = case X of {  0 → s(Y);
Transformed ISor CRWL-program f(X,Y) = f1(X,Y) or f2(X,Y) f1(0,Y) = s(Y)
f1(s(X),s(Y)) = s(f(X,Y))
f2(X,0) = X
X or Y = X	X or Y = Y 

s(X1) → case Y of { s(Y1) →  let U=f(X1,Y1)
in s(U)} } 
f2(X,Y) = case Y of {0 → X}

Fig. 9. Transformation from CRWL to FLC syntax
The following equivalence result states the correctness of the transformation.

Theorem 5.4 Let P be an ISor CRWL-program, Pˆ
its FLC-transformation, e ∈

Exp⊥ a CRWL-expression, and e∗ its FLC-normalization. Then


[[e]]P
∗ Pˆ
CRW LFLC

Relation between CRWLFLC and FLC
We start by introducing some preliminary notions to establish the relation between both formalisms. A heap Γ is a valid heap if it reachable in a computation, i.e, [] : e ⇓ Γ : v for some e, v. We write dom(Γ) for the set of variables bound in Γ.
We need to express pairs heap/expression of the FLC formalism as CRWL- expressions in order to relate computations with respect to both approaches. Notice that as recursive bindings are not allowed in heaps it is always possible to order the heap Γ = [x1 '→ e1,..., xn '→ en] in such a way that ei does not depend on any xj with j >= i. Then it makes sense to obtain a CRWL-expression from a pair heap/expression as:
ligs([x1 '→ e1,..., xn '→ en], e) =def let {x1 = e1} in... let {xn = en} in e
With this transformation we can define:
Definition 6.1 [CRWLF LC-denotation of a pair heap/expression] Given an FLC- program P and a pair (Γ, e), where Γ is a valid heap and e is a FLC-expression, we define the denotation of the pair with respect to CRWLF LC as


P
CRW LFLC
=def [[ligs(Γ, e)]]P

This is in fact the set of terms {t |P ▶CRW LFLC ligs(Γ, e) → t}.
We will usually omit the reference to the program P and the calculus CRWLF LC when they are clear by the context, and write simply [[Γ, e]]. Notice that ligs([], e) = e and therefore [[], e]] = [[e]], for any e.

The shell of a FLC-expression e, denoted by |e|, is a partial term that represents the constructed part of the expression e and it is formally defined in Figure 10.

Fig. 10. Shell of an FLC expression

As an example of the previous notions consider the heap Γ4 = [l1 → c1 : y1, c1 → coin, y1 → repeat(c1)] of Figure 5. It is clearly a valid heap as it is produced in a FLC-derivation and dom(Γ4) = {l1, c1, y1}. We can reorder it as
'  = [c1 → coin, y1 → repeat(c1), l1 → c1 : y1] and obtain ligs(Γ' , (c1, c1)) =
let {c1 = coin} in let {y1 = repeat(c1)} in let {l1 = c1 : y1} in (c1, c1). The shell
of this expression is (⊥, ⊥) and using the CRWLF LC calculus it is easy to see that [[Γ, (c1, c1)]] = {⊥, (⊥, ⊥), (0, ⊥), (1, ⊥), (⊥, 0), (⊥, 1), (0, 0), (1, 1)}.

Completeness of CRWL wrt FLC
The next theorem is the main result of this subsection and shows that any FLC- derivation for a pair heap/expression is captured by a CRWLF LC-derivation of the corresponding CRWLF LC-expression.
Theorem 6.2 If Γ : e ⇓ Δ : v, then [[Δ, v]] ⊆ [[Γ, e]].
Its proof becomes easy with the aid of some auxiliary results. The first one shows that if the information about some variables in a heap is refined in another heap, then this refinement is extended to any expression containing those variables. Here, the concept of reﬁnement is interpreted in terms of CRWLF LC denotations.
Lemma 6.3 If [[Δ, x]] ⊆ [[Γ, x]], for all x ∈ var(e), then [[Δ, e]] ⊆ [[Γ, e]].
The next result splits the completeness Theorem 6.2 into two properties: (H) shows what happens to heaps under a FLC-derivation, while (R) relates the results of the computation.
Theorem 6.4 If Γ : e ⇓ Δ : v, then:
(H) [[Δ, x]] ⊆ [[Γ, x]], for all x ∈ dom(Γ) (R) [[Δ, v]] ⊆ [[Δ, e]]
The completeness of CRWLF LC with respect to FLC is not restricted to the expressions involved in a concrete FLC-derivation, but it is applicable to any ex- pression whose variables appear in the initial heap of the FLC-derivation (notice that these variables will also appear in further heaps of the derivation). The next corollary shows this idea by strengthening part (H) of the previous theorem:
Corollary 6.5 (H’) If Γ : e ⇓ Δ : v, then [[Δ, e']] ⊆ [[Γ, e']], for all e' with var(e') ⊆
dom(Γ).
Now the proof of Theorem 6.2 becomes easy:

Proof. (Theorem 6.2) Assume Γ : e ⇓ Δ : v. Then, by property (R) of Theorem 6.4 we have [Δ, v]] ⊆ [[Δ, e]], and by Corollary 6.5 (H’) we have [[Δ, e]] ⊆ [[Γ, e]], because it must happen that var(e) ⊆ dom(Γ), since the FLC-derivation has succeeded. But then [[Δ, v]] ⊆ [[Γ, e]].	 
Now, Theorem 6.2 allows to obtain results relating FLC with the original CRWL
(instead of CRWLF LC).
Corollary 6.6 Let P be a CRWL-program, Pˆ  its FLC-transformation, e a

CRWL-expression, and e∗ its normalization. Then Pˆ
▶F LC [] : e∗ ⇓ Δ : v im-

plies |ligs(Δ, v)|∈ [[e]]P	.
Proof. Assume Pˆ ▶F LC [] : e∗ ⇓ Δ : v. By Theorem 6.2, we have then [[Δ, v]] ⊆

[[[], e∗]]. Besides, as ∀e ∈ Exp⊥ we have |e| ∈ [[e]]CRW L

FLC
(it can be easily proved

by induction on the structure of the expressions), then |ligs(Δ, v)| ∈ [[Δ, v]] so

|ligs(Δ, v)| ∈ [[[], e∗]] ≡ [[e∗]]Pˆ
FLC
. And now chaining theorems 5.2 and 5.4 we

get |ligs(Δ, v)|∈ [[e]]P	.	 
As we have pointed out in Section 4 one mayor difference of FLC with respect to CRWL it that the first one only provides head normal forms for the expressions to reduce, while CRWL allows to obtain any approximation to the denotation of such expressions. Nevertheless FLC can be enforced to provide a normal form for an expression by introducing an auxiliary function in the program. This is better seen with an example. Consider again the program of Example 2 and the expression heads(repeat(coin)). For checking if this expression (the corresponding normalized one) is reducible to the normal form (0, 0) in FLC, we can enlarge the program with the following predicate (i.e, true-valued function):
aux (0,0) = true
and then evaluate the expression aux(heads(repeat(coin))) to the head normal form true. This technique can be generalized to obtain any approximation for a given expression, even partial approximations. For example for obtaining the value (0, ⊥) for the previous example we could define aux’ (0,x) = true.
This idea motivates the relevance of the following result stating that CRWL is complete with respect to true-valued FLC-reductions, which could otherwise seem too particular as to be interesting.
Corollary 6.7 Let P be a CRWL-program, Pˆ  its FLC-transformation, e a

CRWL-expression, and e∗ its normalization. Then Pˆ implies P ▶CRW L e → true.
▶F LC [] : e∗ ⇓ Δ : true

Proof. By Corollary 6.6 |ligs(Δ, true)| ∈ [[e]], but |ligs(Δ, true)| = true, i.e. e →
true.	 

Completeness of FLC wrt CRWL
To prove completeness of FLC with respect to CRWLF LC, i.e., that the result of any derivation in CRWL can be obtained also in FLC, we face again the problem

that F LC stops evaluation at head normal forms. At this point, the considerations we made to justify Corollary 6.7 do not help for a technical proof. To overcome the problem we add to the set of rules defining the FLC-reduction relation ⇓ a new rule to continue evaluation inside heaps, namely the rule (Contx) in figure 11. We write ⇓Ctx for this new relation – clearly an extension of ⇓ – that goes beyond head normal forms.

Fig. 11. The rule Contx

Example 6.8 Consider again the program P and expression e∗ ≡ let l = (let c =
coin in repeat(c)) in heads(l) of Example 3.1 (page 5). Using the extended relation
⇓Ctx the evaluation for e∗ expressed by the FLC-derivation in Figure 5 (page 6) can be continued to obtain the value (0, 0), in the sense that we can build a derivation for [ ] : e∗ ⇓Ctx Δ' : (c1, c1) where Δ' verifies Δ'(c1) = 0. All what is needed is to replace the sub-derivation
Δ: (c1, c1) ⇓ Δ: (c1, c1) V al

in the upper right corner of the derivation of Figure 5 by the following one using the (Contxt) rule:
Δ:0 ⇓Ctx Δ:0 V al
Δ: coin ⇓Ctx Δ:0 F un
Δ: c  ⇓Ctx Δ' :0  V arExp  Δ' :(c ,c ) ⇓Ctx Δ' :(c ,c ) V al
1	1  1	1  1
Δ: (c ,c ) ⇓Ctx Δ' :(c ,c )	Contxt


where
1  1	1  1

Δ ≡ [l1 '→ c1 : y1, c1 '→ coin, y1 '→ c1 : y2, y2 '→ repeat(c1)] Δ' ≡ [l1 '→ c1 : y1, c1 '→ 0, y1 '→ c1 : y2, y2 '→ repeat(c1)]
and then propagate the result Δ' : (c1, c1) through the derivation down to the root, that will become [ ] : e∗ ⇓Ctx Δ' :(c1, c1).
It can be shown (see the appendix) that the relation ⇓Ctx still satisfies Theorem
6.4. This, together to the fact that ∃Δ such that Γ : e ⇓ Δ : c(x) iff ∃Δ' such that Γ : e ⇓Ctx Δ' : c(x) are enough to justify using this extended relation along the proofs.

We define also a variation of CRWLF LC whose proofs are more similar to those for F LC, and call it NCRWLF LC. This calculus is defined by replacing the rules (DF) and (CASE) in Figure 7 by those in Figure 12. There is a close relation



Fig. 12. The new rules for NCRW LFLC

between CRWLF LC and NCRWLF LC, which can be easily proved by induction on the size of the proofs:
Theorem 6.9 P ▶CRW LFLC e → t ⇔ P ▶NCRW LFLC e → t, for any e ∈ Exp⊥,t ∈
CTerm⊥.
We remark that ⊥’s are not present in F LC. As ⊥ might occur in the premises of the CRWL-proofs, we consider in F LC a new constant ⊥ which can only appear in the heap or expression of the goal, but never in the program rules. The point here is that ⊥ is a fresh constant and so it does not match any pattern of a case expression present in the program rules.
Besides, since no ⊥ is introduced by the rules of the FLC-calculus, adding ⊥
to the signature does not allow to obtain new reductions for totally defined (i.e., without ⊥) expressions and heaps, as the following easily provable result states:
Lemma 6.10 Let e, Γ be totally deﬁned. Then Γ : e ⇓⊥ Δ : v ⇔ Γ : e ⇓ Δ : v, where ⇓⊥ is the extension of ⇓ adding ⊥ to the signature as a constant.
In the following we will not indicate if we are considering ⊥ as part of the signature, as it has been shown irrelevant.
A few more concepts must be introduced before presenting and proving the main results of the subsection:
Hyponormalization: We say that a F LC expression e is hyponormalized iff all the arguments of each constructor or function symbol belong to CTerm⊥.
Approximation order for F LC: The approximation ordering e ± e' for FLC- expressions (with ⊥) is the least partial order satisfying the properties in Figure
13. The way in which the ordering will be used makes unnecessary to consider the case of let expressions.




Fig. 13. Approximation order for FLC

Our main result concerning the completeness of F LC with respect to CRWLF LC
is:
Theorem 6.11 If e ∈ Exp⊥ is hyponormalized and t ∈ CTerm⊥, then:

P ▶CRW L	e → c(t) implies [] : e∗ ⇓ Δ : c(x), for some Δ, x.

P ▶CRW L

FLC
e → t, t /=⊥ implies [] : e∗ ⇓Ctx Δ : t' for some Δ, t' such that

|ligs(Δ, t')|± t
The first part a) states that FLC is able to obtain the outer constructor of the result of a CRWLF LC-derivation. Part b), which is stronger, says that not only the outer constructor, but the whole result of a CRWLF LC-derivation is covered by a FLC, if the information implicit in the heap is taken into account by means of the function ligs.
To prove the previous result we first obtain a similar one for the auxiliary calculus
NCRWLF LC:
Theorem 6.12 If e ∈ Exp⊥ is hyponormalized and P ▶NCRW LFLC  e → t with
t /=⊥, then [] : e∗ ⇓Ctx Δ : t' for some Δ, t' such that |ligs(Δ, t')|± t
Now we can prove Theorem 6.11 as follows:
Proof. Assume P ▶CRW LFLC e → t. Then by Theorem 6.9 we have P ▶NCRW LFLC
e → t. Now, since t /=⊥, by Theorem 6.12 we have [] : e∗ ⇓Ctx Δ : t' such that
|ligs(Δ, t')| ± t. Furthermore, if t = c(t) then |ligs(Δ, t')| ± t implies t' = c(x), as t' cannot be a variable because then it should be a logical variable and those are forbidden in our setting. But then [] : e∗ ⇓Ctx Δ : c(x) implies ∃Δ' such that [] : e∗ ⇓ Δ' : c(x).	 
An important tool to prove Theorem 6.12 is the monotonicity Lemma 6.13 below, based upon the following notions:
c-unravelling: The c-unravelling of a heap Γ, cU nrav(Γ), is defined in figure 14. Informally it results of flattening the lets and dereferencing the bindings of vari- ables to c-terms while not for other terms, keeping then the sharing information.

Fig. 14. cUnravelling of a heap

Approximation ordering over heaps: we define the relation ±h as: Γ1 ±h Γ2 iff dom(Γ2) ⊆ dom(Γ1) and Δ1[x] ± Δ2[x], for all x ∈ dom(Γ2), where Δi = cU nrav(Γi)
Approximation ordering over heap-expression pairs: we write also ±h for the following relation: Γ1 : e1 ±h Γ2 : e2 iff Γ1  [x '→ e1] ±h Γ2  [x '→ e2], where x is a fresh variable.
Lemma 6.13 (Monotonicity Lemma) If Γ1 ±h Γ2, Γ1 : e1 ±h Γ2 : e2 and Γ2 : e2 ⇓Ctx Δ2 : v2 with v2 /=⊥, then Γ1 : e1 ⇓Ctx Δ1 : v1 for some Δ1, v1 such that Δ1 ±h Δ2, Δ1 : v1 ±h Δ2 : v2.

Then Γ1 ±h Γ2 expresses that Γ1 can get more results than Γ2 for a given expression. We remark that the condition v2 /=⊥ in Lemma 6.13 is crucial, as we can see in the following counterexample: [x '→ loop] : x ±h [x '→⊥] : x and [x '→⊥] : x ⇓Ctx [x '→⊥] :⊥ but there is no successful derivation for [x '→ loop] : x, if loop = loop is the defining rule for loop.
Example 6.14 Given P = {head(l) = case l of {x : xs → x}, cOne(X) =
case x of{c(y) → case y of {1 → true}}} and:

Γ1 ≡ [l '→ let x = c(u) in x : xs, xs '→⊥,u '→ 1] ; cUnrav(Γ1)= [l '→ c(1) :⊥,x '→ c(1), xs '→⊥,u '→ 1]
Γ2 ≡ [l '→ x : xs, x '→ c(u), xs '→⊥,u '→⊥]	; cUnrav(Γ2)= [l '→ c(⊥) :⊥,x '→ c(⊥), xs '→⊥,u '→⊥]
so Γ1 ±h Γ2 and Γ1 : head(l) ±h Γ2 : head(l). Then we have:

Γ2 : head(l) ⇓Ctx Γ2 : c(u)
Γ1 : head(l) ⇓Ctx [l '→ x1 : xs, x1 '→ c(u), xs '→⊥,u '→ 1] : c(u) Γ2 : let y = head(l) in cOne(y)	the proof for this goal fails
Γ1 : let y = head(l) in cOne(y) ⇓Ctx [l '→ x1 : xs, x1 '→ c(u), xs '→⊥,u '→ 1, y1 '→ c(u)] : true

As Γ1 ±h Γ2 it can get a greater result for any expression that gets a result with Γ2, and even it can get results with expressions for which Γ2 gets no result.
Our final result of this section relates FLC with the original CRWL again:

Corollary 6.15 Let P be a CRWL-program,
Pˆ its FLC-transformation, e a

CRWL-expression, and e∗ its normalization. Then:

P ▶CRW L e → t, t /=⊥ implies Pˆ
|ligs(Δ, t')|± t.
▶F LC [] : e∗ ⇓Ctx Δ : t' such that

P ▶CRW L e → true implies Pˆ ▶F LC [] : e∗ ⇓ Δ : true.
Proof.
Suppose P ▶CRW L e → t with t /=⊥. Then chaining theorems 5.2 and 5.4 we

get Pˆ ▶CRW L

FLC
e∗ → t, and by Theorem 6.11 we get [] : e∗ ⇓Ctx Δ : t' such

that |ligs(Δ, t')|± t.
This is consequence of a). As true /=⊥, by a) we get [] : e∗ ⇓Ctx Δ : t' such that
|ligs(Δ, t')| ± true, which implies t' = true as t' cannot be a variable because then it should be a logical variable and those are forbidden in our setting. But then [] : e∗ ⇓Ctx Δ : true implies ∃Δ' such that [] : e∗ ⇓ Δ' : true.
 
Joining together Corollary 6.7 and part b) of Corollary 6.15, we obtain the follow- ing remarkable result of equivalence of CRWL and FLC for true-valued reductions:

Theorem 6.16 Let P be a CRWL-program,
Pˆ its FLC-transformation, e a

CRWL-expression, and e∗ its normalization. Then:
P ▶CRW L e → true ⇔ Pˆ ▶F LC [] : e∗ ⇓ Δ : true

Conclusions and Future Work
In this paper we study the relationship between CRWL [6,7] and FLC [1], two formal semantic descriptions of first order functional logic programming with call-time choice semantics for non-deterministic functions. The long distance between these two settings, even at syntactical level, discourages any direct proof of equivalence. Instead, we have chosen FLC as common language, to which CRWL can be adapted by means of a program transformation and a new CRWLF LC proof calculus for the resulting FLC-programs. The program transformation itself is not very novel, although its formulation here is original, but the CRWLF LC calculus and its relation to the original are indeed novel and could be useful for future works.
The most important and involved part of the paper establishes the relation between the CRWLF LC logic and the natural semantics given to FLC in [1]. We give an equivalence result for ground expressions and for the class of FLC-programs not having recursive let bindings nor extra variables. We think that this restricted case is interesting in itself, as a non-trivial technical basis for future generalizations. Furthermore the importance of the restrictions is somehow alleviated by the fact that extra variables have been proved [5,4] to be eliminable from programs, and recursive let’s do not appear in the translation of CRWL-programs to FLC-syntax. Still, dropping the imposed restrictions is of course desirable, and we hope to do it in the next future.
We did not expect proofs to be easy. Despite of that, we are a bit surprised by the great difficulties we have encountered, even with the imposed restrictions over expressions and programs. This suggests to look for new insights, not only at the level of the proofs but also in the sense of finding new alternative semantical descriptions of functional logic programs.

Acknowledgement
We thank Michael Hanus for useful comments clarifying some aspects of the FLC- semantics.

References
E. Albert, M. Hanus, F. Huch, J. Oliver, and G. Vidal. Operational semantics for declarative multi- paradigm languages. Journal of Symbolic Computation, 40(1):795–829, 2005.

S. Antoy. Definitional trees. In Proc. 13th Algebraic and Logic Programming (ALP’92), pages 143–157. Springer LNCS 632, 1992.
S. Antoy, R. Echahed, and M. Hanus. A needed narrowing strategy. In Proc. ACM Symposium on Principles of Programming Languages (POPL’94), pages 268–279. ACM Press, 1994.
S. Antoy and M. Hanus. Overlapping rules and logic variables in functional logic programs. In Proc.
Int. Conf. on Logic Programming (ICLP’06), Springer LNCS 4079, pp. 87–101, 2006
J. de Dios Castro, F.J. L´opez-Fraguas. Extra Variables Can Be Eliminated from Functional Logic Programs. ENTCS (this volume).


J. C. Gonza´lez-Moreno, T. Hortal´a-Gonz´alez, F. L´opez-Fraguas, and M. Rodr´ıguez-Artalejo. A rewriting logic for declarative programming. In Proc. European Symposium on Programming (ESOP’96), pages 156–172. Springer LNCS 1058, 1996.
J. C. Gonz´alez-Moreno, T. Hortal´a-Gonz´alez, F. Lo´pez-Fraguas, and M. Rodr´ıguez-Artalejo. An approach to declarative programming based on a rewriting logic. Journal of Logic Programming, 40(1):47–87, 1999.
M. Hanus. The integration of functions into logic programming: A survey. Journal of Logic Programming, 19-20:583–628, 1994. Special issue ‘Ten Years of Logic Programming’.
M. Hanus. Functional logic programming: From theory to Curry. Technical report, Christian-Albrechts- Universit¨at Kiel, 2005.
M. Hanus and C. Prehofer. Higher-order narrowing with definitional trees. Journal of Functional Programming, 9(1):33–75, 1999.
M. Hanus (ed.).	Curry: An integrated functional logic language (version 0.8.2).	Available at
http://www.informatik.uni-kiel.de/~curry/report.html, March 2006.
H. Hussmann. Non-deterministic algebraic specifications and non-confluent term rewriting. Journal of Logic Programming, 12:237–255, 1992.
J. Launchbury. A natural semantics for lazy evaluation. In Proc. ACM Symposium on Principles of Programming Languages (POPL’93), pages 144–154. ACM Press, 1993.
F. L´opez-Fraguas and J. S´anchez-Hern´andez. T OY: A multiparadigm declarative system. In Proc. Rewriting Techniques and Applications (RTA’99), pages 244–247. Springer LNCS 1631, 1999.
M. Rodr´ıguez-Artalejo. Functional and constraint logic programming. In Revised Lectures of the International Summer School CCL’99, pages 202–270. Springer LNCS 2002, 2001.
J. S´anchez-Hern´andez. Una aproximacio´n al fallo constructivo en programaci´on declarativa multiparadigma. PhD thesis, DSIP-UCM, June 2004.

Appendix A: Proofs
In order to clarify the proofs, some extra notation is introduced:
deps(Γ, e): This is the set of variables in dom(Γ) such that e depends on them, directly or indirectly. It can be defined as deps(Γ, e) = var(e) ∪ {x | y ∈ deps(Γ, e) ∧ x ∈ deps(Γ, Γ[y])}. Note that for every variable x we have x ∈ deps(Γ, x).
subs(Γ): Given a heap Γ, subs(Γ) is the set of all substitutions under the variables in dom(Γ), that we get evaluating this heap. If we order the bindings in Γ in a way such that Γ = [x1 '→ e1,..., xn '→ en] and each ei could depend on xj iff j < i, then we define subs([x1 '→ e1,..., xn '→ en]) =def {[xi/ti,..., xn/tn] | ligs([x1 '→
e1,..., xn '→ en], (x1,..., xn)) → (t1,..., tn)}.
Note that for any Γ, subs(Γ) ⊆ CSubst⊥, because every ti is in the right side of a CRWLLET -derivation.
Additionally, in the remainder of this section we will suppose that we are working with FLC-programs and FLC-expressions to which the following additional trans- formation has been applied,
case e of {pk '→ ek} ‹→ let {x = e} in case x of {pk '→ ek}

being x a fresh variable and e not a variable (in case e is a variable the trans- formation leaves the expression untouched).  Once this transformation has been

applied, as all the substitutions made in FLC are from variables to variables, we can state that this transformation persists in the calculus. Furthermore, if the calculus succeeds for a case expression like that, we can state that x is defined in the heap, because x is always demanded to compute the case expression.

Proof. [For Theorem 5.4, page 10](Sketch) We prove the inclusion [e]]P	⊆

[[eˆ]]Pˆ
FLC
(resp.  [e]]P
⊇ [[eˆ]]Pˆ
FLC
) by induction over the depth of the

CRWL-derivation (resp. CRWLF LC-derivation) of an arbitrary arrow e → t (resp.

eˆ → t), with t ∈ [[e]]P
(resp. t ∈ [[eˆ]]Pˆ
FLC
).	 

Before proving Theorem 6.4 some auxiliary lemmas are needed:
Lemma 8.1 (Ligs) ligs(Γ, e) → t iff ∃σ ∈ subs(Γ) such that eσ → t. In other words, t ∈ [[Γ, e]] iff ∃σ ∈ sus(Γ) such that σe → t.
Lemma 8.2 ∀ Γ, x. [[Γ[x '→ e], e]] = [[Γ[x '→ e], x]]
Lemma 8.3 Domains of heaps grow during computations, that is: Γ : e ⇓ Δ : v ⇒
dom(Γ) ⊆ dom(Δ).
Lemma 8.4 ∀ Γ,x such that Γ[x] = c(y) then for all FLC-derivation of the form Γ : e ⇓ Δ : v it happens that Δ[x] = c(y). Bindings to returning values remain in all the heaps that follow in the computation.
Lemma 8.5 ∀ Γ, x, e, e1 such that x /∈ deps(Γ, e), then [[Γ[x '→ e1], e]] = [[Γ, e]].
Lemma 8.6 ∀ Γ, x, e1, e2,e such that Γ is a valid heap, x /∈ dom(Γ) and x /∈ var(e1) ∪ var(e2), then ([[Γ, e1]] ⊆ [[Γ, e2]]) implies ([[Γ[x '→ e1], y]] ⊆ [[Γ[x '→ e2], y]]), ∀y ∈ dom(Γ) ∪ {x}.
Lemma 8.7 For every valid heap Γ and every case-expression of the form case  c(yn) of {pk '→ ek} such that pi = c(xn), if we deﬁne the substitution ρ = [xn/yn] then [[Γ, eiρ]] ⊆ [[Γ, case c(yn) of {pk '→ ek}]]
Lemma 8.8 ∀ Γ, Δ, x,v such that Γ : x ⇓ Δ : v it happens that Δ[x] = v.
These are the proofs for those lemmas:
Proof. [For Lemma 8.4](Sketch) Using Lemma 8.3 we know that there must be a binding for x, all that is left is ensuring that this binding never changes. The only way a binding for a variable changes is through the rule VarExp, but this rule cannot be applied if e is constructor-rooted, and that is the case because e = c(y), so the binding for x remains the same.	 
Proof. [For Lemma 8.5](Sketch) To prove this statement we use Lemma 8.1 (Ligs) and realize that the substitution σ can give ⊥ for x, and for every variable y such that y /∈ deps(Γ, e), so we can get the same result in [[Γ[x '→ e1], e]] as in [[Γ, e]]. 
Proof. [For Lemma 8.6] There are two possibilities:

y ∈ dom(Γ): Then x /∈ deps(Γ, y) because Γ is a valid heap and so no binding in Γ can depend on x, since this variable is not in the heap and free variables are forbidden. So [[Γ[x '→ e1], y]] =Lemma8.5 [[Γ, y]] =Lemma8.5 [[Γ[x '→ e2], y]]
y = x: Then x /∈ deps(Γ, e1) ∪ deps(Γ, e2) because x /∈ var(e1) ∪ var(e2) and x /∈ dom(Γ). So [[Γ[x '→ e1], x]] =Lemma8.2 [[Γ[x '→ e1], e1]] =Lemma8.5
[[Γ, e1]] ⊆hypothesis [[Γ, e2]] =Lemma8.5 [[Γ[x '→ e2], e2]] =Lemma8.2 [[Γ[x '→ e2], x]]
 
Proof. [For Lemma 8.7] If we have that ligs(Γ, eiρ) → t then ∃σ ∈ subs(Γ) such that eiρσ → t. Now if we prove (case c(yn) of {pk '→ ek})σ → t we should be done because then ligs(Γ, case c(yn) of {pk '→ ek}) → t. Let us see that derivation:


  	(1)
(c(yn))σ ≡ c(ynσ) → c(ynσ)


eiσ|(V ar\{xn})[xn/ynσ] ≡ eiρσ → t
(2)

(case c(yn) of {pk '→ ek})σ → t	CASE
: As σ ∈ subs(Γ) then σ ∈ CSubsts⊥ and so c(ynσ) ∈ CTerm⊥. But then it is easy to prove that c(ynσ) → c(ynσ) by (DC) and (B).
: When applying a substitution to a case expression the variables of the patterns are bounded, that is why we must exclude {xn} from the domain of σ when applying it to ei. All that is left is proving that eiρσ ≡ eiσ|(V ar\{xn})[xn/ynσ], we do it by showing that ∀z ∈ vars(ei), zρσ = zσ|(V ar\{xn})γ, where γ = [xn/ynσ], by a case distinction:

z ∈ {xn}: For example z = xi. Then xiρσ = yiσ, and xiσ|(V ar\{xn})γ = xiγ = yiσ.
z /∈ {xn}: Then zρσ = zσ, and zσ|(V ar\{xn})γ = zσγ = zσ, because all the variables that could come from a substitution in sus(Γ) are variables from Γ, and dom(Γ) ∩ {xn} = ∅. We can state this intersection is empty because all the variables in Γ are introduced by the Let rule of FLC and so are fresh, and no substitution over a case expression can change the variables in its patterns, because those are bounded variables.
 
Proof. [For Lemma 8.8] We can check this very easily looking at the rules VarCons and VarExp of FLC: these are the only rules applicable for that derivation and they keep this property.	 
Now we are ready to prove Theorem 6.4:
Proof. [For Theorem 6.4, page 11] By induction of the structure of FLC- derivations:

Notation: IHHi means applying the induction hypothesis for the property H over the i-th premise of the rule Select. IHRi means the same but for the property R.
Base:
VarCons

H: It follows trivially because we have only one heap.
R: [[Γ[x '→ t], t]] =Lemma 8.2 [[Γ[x '→ t], x]], so this condition is fulfilled also.
Val
H: It follows trivially because we have only one heap.
R: It follows trivially because we have only one heap and one expression to reduce.
Inductive step:
VarExp
R: [[Δ[x '→ v], v]] =Lemma 8.2 [[Δ[x '→ v], x]], so this condition is fulfilled.
H: The heap Δ in the premise must fulfil Δ[x] = e, because Δ is one of the results obtained during the calculation of e. If the binding for x had changed in any heap during this calculation, that should be because x had been consulted to calculate e and so e depends on x. That should mean we have a recursive binding and this is forbidden, hence Δ ≡ Δ'  [x '→ e], in other words, Δ ≡ Δ[x '→ e].

Now we want to prove this property: (P 1) ≡ ∀y ∈ dom(Δ[x '→ v]), [[Δ[x '→ v], y]] ⊆ [[Δ[x '→ e], y]]. Applying Lemma 8.6 all we have to prove to have (P1) is that [[Δ', v]] ⊆ [[Δ', e]], and we can prove that in the following way:

[[Δ', v]]	⊆	[[Δ', e]]
 Lemma 8.5	 Lemma 
[[Δ, v]]	⊆IHR	[[Δ, e]]
We are sure we can apply Lemma 8.5 because of the absence of re- cursive bindings that forces e and v to be independent from x.

So we have (P1), and we have also dom(Γ[x '→ e]) ⊆ dom(Δ[x '→ v]) by Lemma 8.3, hence we have ∀y ∈ dom(Γ[x '→ e]), [[Δ[x '→ v], y]] ⊆ [[Δ, y]] (because Δ ≡ Δ[x '→ e]). Applying the H part of the induction hypothesis we have ∀y ∈ dom(Γ[x '→ e]), [[Δ, y]] ⊆ [[Γ[x '→ e], y]], so H follows by transitivity of subsets.
Select
H: ∀x ∈ dom(Γ), [[Θ, x]] ⊆ [[Δ, x]] (by IHH2 as dom(Γ) ⊆ dom(Δ) by Lemma
8.3) ⊆ [[Γ, x]] (by IHH1 ), so the property holds.
R: Following the assumptions in Section 4 we can suppose that e is a variable,
x for example. So we want to prove [[Θ, v]] ⊆ [[Θ, case x of {pk '→ ek}]]. We have:
[[Θ, v]] ⊆IHR2 [[Θ, ρ(ei)]] ⊆Lemma 8.7 [[Θ, case c(yn) of {pk '→ ek}]]
So all we need to prove is that [[Θ, c(yn)]] ⊆ [[Θ, x]] to get [[Θ, case c(yn) of
{pk '→ ek}]] ⊆ [[Θ, case x of {pk '→ ek} ]. To do that we apply Lemma 8.8

to the first premise to obtain that Δ[x] = c(yn), and with this and Lemma
8.4 we get that Θ[x] = c(yn). So Θ ≡ Θ[x '→ c(yn)], hence by Lemma 8.2 [[Θ, c(yn)]] = [[Θ, x]]: the property holds.
Fun
H: It follows by induction hypothesis.
R: We want to prove that [Δ, v]] ⊆ [[(Δ,f (xn)]], that is, (ligs(Δ, v) → t) im- plies (ligs(Δ,f (xn)) → t). By HIR, ligs(Δ, v) → t implies ligs(Δ, eρ) → t, so by Lemma 8.1 ∃σ ∈ sus(Δ) such that eρσ → t. If we can prove that (f (xn))σ → t then by Lemma 8.1 we would have ligs(Δ,f (xn)) → t and so R would be proved. That derivation should look like this:

e[yn/xnσ] → t

(f (xn
))σ ≡ f ((xn


)σ) → t DF with f (yn) = e ∈P 



If θ = [yn/xnσ], as free variables in e must be in {yn}, eθ ≡ eρσ if ∀yi ∈
{yn}, yiθ = yiρσ, and that happens because yiθ =def of θ xiσ =def of ρ
yiρσ. So eθ ≡ eρσ and as eρσ → t then eθ → t, thus R holds.
Or
H: It follows by induction hypothesis.
R: We want to prove that [Δ, v]] ⊆ [[(Δ, e1 or e2)]], that is, (ligs(Δ, v) → t) implies (ligs(Δ, e1 or e2) → t). As ligs(Δ, v) → t then by IHR we get that for ej ∈ {e1, e2} used in the premise then ligs(Δ, ej) → t, so by Lemma
8.1 ∃σ ∈ subs(Δ) such that ejσ → t. So:

σ(ej) → t
σ(e1 or e2) ≡ σ(e1) or σ(e2) → t OR
ligs(Δ, e1 or e2) → t	Lemma 8.1

Let
H: It follows by induction hypothesis, because dom(Γ[yk '→ ρ(ek)]) ⊃ dom(Γ), since we get Γ[yk '→ ρ(ek)] adding bindings for fresh variables to Γ, and because ∀x ∈ dom(Γ), Γ[yk '→ ρ(ek)][x] = Γ[x]. So we get H applying Lemma 8.5 to every variable in dom(Γ).
R: It follows by induction hypothesis since except for renaming:

ligs(Γ[yk '→ ekρ], eρ) ≡renaming ligs(Γ, let {xk = ek} in e)


Proof. [For Theorem 6.4 extended to ⇓Ctx] All that is left is proving the case for (Contx):
(H) We know that ∀x ∈ dom(Γ), [[Θ, x]] ⊆ [[Δ, x ] by the second IH, as dom(Γ) ⊆
dom(Δ) by Lemma 8.3. But by the first IH, [[Δ, x]] ⊆ [[Γ, x]], so [[Θ, x]] ⊆ [[Γ, x]].
(R) By the second IH, [[Θ, v]] ⊆ [[Θ, e]]
 

Proof. [For Theorem 6.12, page 15] By induction on the size of the NCRWLF LC
proof in the hypothesis:
ok because the hypothesis fails
(RR) ok because the hypothesis fails as in this case x is free
(DC) There are two possibilities
n = 0: Then the hypothesis is




but
c → c DC

[] : c ⇓Ctx [] : c V al

As |ligs([] : c)| = |c| = c ± c, we are done
n > 0:  The hypothesis is c(t1,..., tn) → c(t' ,..., t' ), so c(t1,..., tn) ±
1	n
c(t' ,..., t' ) (easy to prove). Given c(t1,..., tn) no ti can be a variable because
1	n
in that case it would be free, so (c(t1,..., tn))∗ = let xi = t∗ in c(xi)

Lemma 8.9
∀t ∈ CTerm⊥, |t∗| = t
This lemma is very easy to prove by induction on the structure of a CTerm.
Then:
[x '→ t∗] : c(x ) ⇓Ctx [x '→ t∗] : c(x ) V al
	i	i	i	i	i	i	 Let (*)
[] : let xi = t∗ in c(xi) ⇓Ctx [xi '→ t∗] : c(xi)
i	i

(∗): n times, ignoring variable names refreshing As |ligs([xi '→ t∗], c(xi))| = |(c(t1,..., tn))∗| =

Lemma 8.9

c(t1,..., tn) ±

c(t' ,..., t' ).
1	n

(DFN) By hypothesis t /=⊥, then there are two possibilities
n = 0: The hypothesis is


e → t
f → t
DFN , with (f = e) ∈P 

As e is part of the program then e∗ = e, so by IH [] : e ⇓Ctx Δ : t' such that
|ligs(Δ, t')|± t. But then:





n > 0: The hypothesis is
[] : e ⇓Ctx Δ : t'

[] : f∗ ≡ f ⇓Ctx Δ : t' F un






let xi = ti in e[yi/xi] → t f (ti) → t

DFN , with (f (yi) = e) ∈P 




As e is part of the program then e∗ = e, so (let xi = ti in e[yi/xi])∗ ≡
let xi = t∗ in e[yi/xi], and by IH:

[x '→ t∗] : e[y /x ] ⇓Ctx Δ : t'
i	 Let (*) [] : let xi = t∗ in e[yi/xi] ⇓Ctx Δ : t'

(∗): n times, ignoring variable names refreshing
such that |ligs(Δ, t')|. Given f (t1,..., tn) no ti can be a variable because in that case it would be free, so (f (t1,..., tn))∗ = let xi = t∗ in f (xi), but then:

[ xi '→ t∗] : e[yi/xi] ⇓Ctx Δ : t'
F un
[x '→ t∗] : f (x ) ⇓Ctx Δ : t'
i	 Let (*) [] : let xi = t∗ in f (xi) ⇓Ctx Δ : t'

(∗): n times, ignoring variable names refreshing
(CASEN) We will use the following lemma in the proof for this case:
Lemma 8.10 (e[x/y])∗ = e∗[x/y]
which can be easily proved by induction on the structure of the expressions.


By hypothesis t /=⊥, supposed:


	
e → c(t)	let yi = ti in ei[xi/yi] → t case e of {pk → ek}→ t



CASEN with pi = c(x)



The case for x = ∅ is very easy, we will concentrate on the other. As c(t) /=⊥, by IH [] : e∗ ⇓Ctx Δ : c(y) such that |ligs(Δ, c(y))| ± c(t). Applying the second IH, as (ei[xi/yi])∗ = e∗[xi/yi] by Lemma 8.10, we get:

[yi '→ t∗] : e∗[xi/yi] ⇓Ctx Θ : t'
Let (*)
[] : let yi = t∗ in e∗[xi/yi] ⇓Ctx Θ : t'
i	i
(∗): n times, ignoring variable names refreshing
such that |ligs(Θ, t')| ± t, so t' /=⊥, as t /=⊥. Now, as |ligs(Δ, c(y))| ± c(t) we can infer that Δ ±h [yi '→ t∗] and Δ : e∗[xi/yi] ±h [yi '→ t∗] : e∗[xi/yi]. So by
i	i	i	i

Lemma 6.13, Δ : e∗[xi/yi] ⇓Ctx Θ2 : t' such that Θ2 ±h Θ and Θ2 : t'
±h Θ : t',

i	2	2
so |ligs(Θ2, t' )|± |ligs(Θ, t')|± t. But then:

[] : e∗ ⇓Ctx Δ : c(y)	Δ : e∗[xi/yi] ⇓Ctx Θ2 : t'
[] : case e∗ of {pk → e∗} ⇓Ctx Θ2 : t'
Select

k	2
(OR) ok by IH
(Let) We will use the following lemma in the proof for this case:

Lemma 8.11
[] : e ⇓Ctx Δ : v =⇒ [x '→ e] : x ⇓Ctx Δ[x '→ v] : v, if x does not appear in e
which can be easily proved by a case distinction over e. By hypothesis t /=⊥, supposed:
e1 → t1	e2[x/t1] → t
let {x = e1} in e2 → t Let
By IH1, [] : e∗ ⇓Ctx Δ : t' such that |ligs(Δ, t' )| ± t1, so by Lemma 8.11 we
1	1	1
have [x '→ e∗] : x ⇓Ctx Δ[x '→ t' ] : t' as x cannot appear in e1 because no
1	1	1
recursive lets are allowed.
By IH2, [] : (e2[x/t1])∗ ⇓Ctx Θ : t' such that |ligs(Θ, t')|± t. But, as [x '→ t∗] ±h
[] and [x '→ t∗] : e∗ ±h [] : (e2[x/t1])∗, then by Lemma 6.13, [x '→ t∗] : e∗ ⇓Ctx
1	2	1	2
Θ2 : t' such that Θ2 ±h Θ and Θ2 : t' ±h Θ : t', so |ligs(Θ2, t' )|± |ligs(Θ, t')|± 
2	2	2
t. Then, as t /=⊥ it must happen t' /=⊥. On the other hand, as |ligs(Δ, t' )|± t1
we can infer that Δ[x '→ t' ] ±h [x '→ t∗] and Δ[x '→ t' ] : e∗ ±h [x '→ t∗] : e∗.
1	1	1	2	1	2

Then by Lemma 6.13 Δ[x '→ t' ] : e∗
⇓Ctx Θ3 : t'
such that Θ3 ±h Θ2 and

1	2	3
Θ3 : t' ±h Θ2 : t' , so |ligs(Θ3, t' )|± |ligs(Θ2, t' )|± t.
3	2	3	2
Now we are ready to chain those results and assemble the desired derivation:
	IH1 as above	 		IH2 as above	 [x '→ e∗] : x ⇓Ctx Δ[x '→ t' ] : t'		Δ[x '→ t' ] : e∗ ⇓Ctx Θ3 : t'

1	1	1	1	2
3 Contx

[	∗] : ∗  Ctx Θ : '
1	2	3	 Let, ignoring refreshing
[] : let {x = e∗} in e∗ ⇓Ctx Θ3 : t'
1	2	3

Proof. [For Lemma 6.13, page 15 (Sketch)] The proof proceeds by induction over the size of Γ2 : e2 ⇓Ctx Δ2 : v2. The most difficult case is when e2 = x and we apply the rule (VarExp), then the derivation takes the shape:
Γ2 : Γ2[x] ⇓Ctx Δ2 : v2

Γ : x ⇓Ctx Δ [x '→ v ] : V
V arExp

2	2	2	2
The problem here is that in general Γ2 : x and Γ2 : Γ2[x] are incomparable (see for example [x '→ coin] : x and [x '→ coin] : coin). This is desirable as Γ2[x] can be a function call for example, and then its replication changes the amount of sharing. To overcome this problem we use this alternative rule:
Γ\deps(Γ,x) : Γ[x] ⇓Ctx Δ : v



Γ : x ⇓Ctx Δ  (Γ|deps(Γ,x))[x '→ v] : v
V arExp'

where Γ\D represents the heap we get from Γ without the bindings for the variables in D, Γ|D represents the restriction of Γ to the domain D and deps(Γ, x) are the set of variables depending on x in Γ, including x itself. We claim that no interesting result is lost by using this alternative rule.  Then,

as Γ1 : e1 ±h Γ2 : x by hypothesis, and Γ2 : x ±h Γ2\deps(Γ2,x) : Γ2[x], then Γ1 : e1 ±h Γ2\deps(Γ ,x) : Γ2[x] and by IH we get Γ1 : e1 ⇓Ctx Δ2 : e2 such that Δ1 ±h Δ2 and Δ1 : v1 ±h Δ2 : v2. But, as Γ1 ±h Γ2 implies dom(Γ2) ⊆ dom(Γ1), and taking into account that dom(Γ1) ⊆ dom(Δ1) (by Lemma 8.3), assuming
Δ1|deps(Γ2,x) = Γ1|deps(Γ2,x) ±h Γ2|deps(Γ2,x) then Δ1 ±h Δ2 (Γ2|deps(Γ2,x))[x '→ v2] and Δ1 : v1 ±h Δ2  (Γ2|deps(Γ2,x))[x '→ v2] : v2.

Another important case is the one for (Contx), then the derivation takes the shape:

Γ2 : xi ⇓Ctx Δ2 : vi	Δ2 : e2 ⇓Ctx Θ2 : v2
		2	 Contx with xi ∈ dom(Γ2) Γ2 : e2 ⇓Ctx Θ2 : v2
The interesting case is when vi2 /=⊥. As Γ1 ±h Γ2 then xi ∈ dom(Γ1) and then it
can be shown that Γ1 : xi ±h Γ2 : xi, so by the first IH we get Γ1 : xi ⇓Ctx Δ1 : vi
1
such that Δ1 ±h Δ2 and Δ1 : vi1 ±h Δ2 : vi2 . So we claim that Δ1 : e1 ±h Δ2 : e2, but then by the second IH we get Δ1 : e1 ⇓Ctx Θ1 : v1 such that Θ1 ±h Θ2 and Θ1 : v1 ±h Θ2 : v2. Now we are ready to chain the following derivation:

Γ1 : xi ⇓Ctx Δ1 : vi	Δ1 : e1 ⇓Ctx Θ1 : v1

Γ1 : e1
⇓Ctx Θ1
: v1
Contx

 
