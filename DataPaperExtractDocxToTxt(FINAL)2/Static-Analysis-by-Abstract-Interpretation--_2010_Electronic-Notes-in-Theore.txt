

Electronic Notes in Theoretical Computer Science 267 (2010) 73–87
www.elsevier.com/locate/entcs

Static Analysis by Abstract Interpretation: A Mathematical Programming Approach
Eric Goubaulta,2,1, St´ephane Le Rouxb,3, Jeremy Lecontec,4,
Leo Libertib,5 and Fabrizio Marinellid,6
a CEA Saclay, France
b LIX, E´cole Polytechnique, 91128 Palaiseau, France
c Dep. Info., ENS, 45 rue d’Ulm, 75005 Paris, France
d DIIGA, Univ. Politecnica delle Marche, Ancona, Italy

Abstract
Static analysis of a computer program by abstract interpretation helps prove behavioural properties of the program. Programs are defined by means of a forward collecting semantics function relating the values of the program variables during the execution of the program. The least fixed point of the semantics function is a program invariants providing useful information about the program’s behaviour. Mathematical Programming is a formal language for describing and solving optimization problems expressed in very general terms. This paper establishes a link between the two disciplines by providing a mathematical program that models the problem of finding the least fixed point of a semantics function. Although we limit the discussion to integer affine arithmetic semantics in the interval domain, the flexibility and power of mathematical programming tools have the potential for enriching static analysis considerably.
Keywords: Guaranteed smallest code invariant, constraints, bilinear MINLP, policy iteration, branch-and-bound.


Introduction
Static Analysis by Abstract Interpretation (SAAI) was introduced by Cousot and Cousot in [9] and [10], and further developed, e.g., in [11]. It is widely used in static

1 We thank David Monniaux and Nicolas Halbwachs for many enlightening discussions and precious sug- gestions. This work was partially supported by grants: ˆIle-de-France research council (post-doctoral fellow- ship), System@tic consortium (“EDONA” project), ANR 07-JCJC-0151 “Ars”, ANR 08-SEGI-023 “Asopt”, Digiteo Emergence “Paso”.
2 Email: eric.goubault@cea.fr
3 Email: leroux@lix.polytechnique.fr
4 Email: jeremy.leconte1@ens.fr
5 Email: liberti@lix.polytechnique.fr
6 Email: marinelli@diiga.univpm.it


1571-0661 © 2010 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2010.09.007

analysis of imperative programs to approximate the behaviour of a program, for in- stance in terms of its variable environments. Given a program, one builds a forward collecting semantics function expressing statically how the environments at a given control point depend dynamically on other control points. This function has a least fixed point (lfp), which is the “best” information that the function may give about the program. Usual methods to compute the lfp range from increasing sequences of under-approximations (relying on Kleene fixed point theorem), decreasing sequences of over-approximations (relying on Tarski fixed point theorem), or both methods combined (relying on widening). The Policy Iteration (PI) method was introduced on the interval domain in [7], further developed in [1] and extended to other (re- lational) domains in [12,2]. PI computes the lfp when the semantics function is non-expansive in the sup norm, and a fixed point otherwise. Another PI method on intervals was described in [14] and later generalized to relational domains in [15].
Computing the lfp of the semantics function is quite naturally an optimization problem. Mathematical Programming (MP) is a declarative language that describes the solution of very general optimization problems [26]. An MP consists of a set of parameters (encoding the problem input prior to the solution process), a set of decision variables x ∈ Rn (encoding the problem output after the solution process), an objective function f : Rn → R, a set of equality and/or inequality constraints g(x) ≤ 0 with g : Rn → Rm, a set of variable bounds xL ≤ x ≤ xU and a set of inte- grality constraints ∀j ∈ Z xj ∈ Z [19]. MPs are categorised according to the nature of the solution as: Linear Programs (LPs), Nonlinear Programs (NLPs), Mixed- Integer Linear Programs (MILPs), Mixed-Integer Nonlinear Programs (MINLPs), each category having dedicated solution algorithms.
We study the following decision problem.
Static Analysis by Abstract Interpretation Problem (SAAIP). Given a program written in the language P (defined in Sect. 2) does its semantics function (defined in Sect. 3.1) have a finite lfp?
SAAIP is actually a problem schema, because it can be parametrized by the type of abstraction used to overapproximate the concrete program semantics. This paper aims to establish a strong link between SAAI and MP by formalizing the search for the lfp by means of a MP formulation. When the semantics function only in- cludes integer convex arithmetic, the MP turns out to be a MINLP with convex objective and constraints, which can always be solved to optimality in worst-case ex- ponential time [4]. For semantics functions including continuous and/or nonconvex arithmetic, the resulting MINLP can be solved to ε-approximation using the spatial Branch-and-Bound (sBB) algorithm [3]. The MP standard toolbox also includes several practically efficient heuristic methods [5,21] which find non-optimal but fea- sible solutions: in the present setting, these correspond to fixed points without guarantee of minimality, which may provide useful information about the program. The flexibility of MP can hardly be underestimated: variable relations, for example, simply give rise to additional constraints which can just be adjoined to the current MP formulation.
We set the framework by exemplifying the use of MP in SAAI limited to a

very classical setting: interval domains with integer affine arithmetic. Although a particular case of the corresponding SAAIP was recently shown to be in P [13], whereas our MP is solved by a worst-case exponential time Branch-and-Bound (BB) algorithm, one of the restrictions of the polynomial algorithm proposed in [13] is that all intersections must involve a constant interval, whereas our MP need not necessarily be restricted in this sense. In other words, the MP can naturally take into account variable relations arising from test conditions. We define an imperative programming language (Sect. 2) and its forward-collecting interval domain seman- tics function (Sect. 3) inductively. This enables the inductive definition of the MP (Sect. 4), and the proof that the semantics function has a finite lfp if and only if the MP has a solution (Sect. 5). We also test the practical applicability of the proposed methodology using the well-known CPLEX solver [17] (Sect. 7).
We remark that MP techniques were sometimes used in SAAI [23,8,6,14]; more precisely, LP technology was used as an operator within two extensions of PI-type algorithms to relational domains [12,15]. However, to the best of our knowledge, modelling fixed point equations by means of MP is new.

A basic programming language
The programming language P is defined inductively below. Its arithmetic expres- sions involve constants in C (including the integers and included in the real num- bers), variables in V = {v1,..., vn}, multiplications of a constant by a variable, and additions of two variables. Programs in P and instructions in I are defined by (mu- tual) induction. There are only four basic instructions, namely an instruction that does nothing, the classic assignment, if-then-else branching, and the while loop.
E	::=	C | V | C ∗ E | E + E
T	::=	C ≤ V | V ≤ C | C < V | V < C | V ≤ V | V < V
I	::=	skip | V ← E | if T {P} {P} | while T {P}
P	::=	I | IP 
We remark that P-programs are structurally finite objects. The language P is not convenient for actual, large-scale programming but it allows simulating other classical branching and looping, complex tests and so on. Furthermore, its simple definition keeps the proofs and explanations at a reasonable complexity level.
Control points. Although the notion of control point is not needed here, it may help intuition. In an alternative definition of the programming language above, the control points could lie in the places corresponding to the stars below.
I	::=	skip	|	V ← E	|
if T { P} { P}	|	while  T { P} 
Program size. The notion of size will help define functions involving programs and instructions, e.g. semantics functions and corresponding MPs. The size of programs and instructions is defined below (definitions on the right). The size of a program corresponds to the number of control points that one may want to put in

the program (definitions in the center).
|I P|	=	|I P|	d=ef
|skip|	=	|skip  |	d=ef
|v ← expr|	=	|v ← expr  |	d=ef
|if test {P} {Q}|	=	|if test { P} { Q}  |	d=ef
|while test {P}|	=	|while  test { P}  |	d=ef


|I| + |P |
1
1
|P | + |Q| +3 
|P | +3 

Abstract interpretation
This paper uses a well-known lattice already used in [10] for abstract interpretation: a subset of Cn is abstracted into (i.e. approximated by) the smallest Cartesian box including the subset. When dealing with environments of program variables, let B be the set of the (environment) boxes: B contains the empty set and the Cartesian products I1 × · · · × In where the Ii are non-empty intervals in C. Moreover, let IL (resp. IU ) be the lower (resp. upper) endpoint of interval Ii. We slightly abuse
i	i
notation of Cartesian products and their elements for readability purposes. The following notation is used to modify a box along one given dimension.
Definition 3.1 Let b be in B and z be an interval in C. b[i ← z] stands for b1 ×
··· × bi−1 × z × bi+1 ×· · · × bn where bi is the i-th projection of b.
The following functions are shorthands that help relate box-based approxima- tions of variable environments before and after branching according to a test.
Definition 3.2 Below T and F are functions that are typed in B × T → B.





T(b, vj ≤ vi) def
=
=
=
=
b[i ← bi ∩ [bL, +∞) ][j ← bj ∩ (−∞, bU ]] 

=	j	i
F(b, vi < vj ) def b[i ← bi ∩ [bL, +∞) ][j ← bj ∩ (−∞, bU ]] 
=	j	i
Given an expression expr in E and an environment box b in B, the possible values that expr may take when the variable environment lies in b constitute an interval defined on expr below.
Definition 3.3 (Evaluation of expressions) Let b be in B and expr in E. If b
is empty, so is [[expr]]b. Otherwise [[expr]]b is deﬁned by induction on expr.

[[c]]b	d=ef [[c ∗ expr]]b	d=ef [[expr + expr ]]b	d=ef
[c, c]	[v ]]b d=ef b
c ∗ [[expr]]b = {c ∗ y | y ∈ [[expr]]b}
[expr1]]b + [[expr2]]b = {y1 + y2 | yi ∈ [[expri]]b}


Inductive deﬁnition of a forward collecting semantics function
Given a program P in P and an instruction I in I, the semantic functions FP of
P and FI of I are typed as FP : B → B|P | → B|P | and FI : B → B|I| → B|I|

respectively. The right-hand part of the types, i.e. B|·| → B|·|, corresponds to the usual definition of the semantics function. The left-hand part of the types, i.e. the stand-alone B, corresponds to an environment box that the program’s execution may start with. Using this box parameter allows programs and instructions with free variables to be meaningful and to have associated semantics functions. This is useful when defining these functions inductively on programs and instructions.
Definition 3.4 (Upper bound operators) We deﬁne the upper bounding oper-
ator ∪B in B and an asymmetric union ∪B (which is useful for the while loop):


x ∪B y d=ef
\ z	x ∪B y d=ef ( ∅	if x = ∅


The semantics function is defined below by induction on programs and instruc- tions. For the sake of readability, we may write FP (b)(X) instead of FP (b, X) for every P , b, and X in the definition and in the sequel. Also, in the definition expr and test are meta-variables for expressions in E and tests in T. The while-loop invokes the asymmetric union ∪B . It is relevant since the execution of a program may exit a while-loop only after performing the entrance test.
Definition 3.5 (Forward collecting semantics function)
∀b ∈ B Fskip(b) : B → B  s.t. x '→ b
∀b ∈ B FIP (b) : B|I| × B|P | → B|I| × B|P |  s.t. X, Y '→ FI (b, X), FP (X|I|,Y )
∀b ∈ B Fvi←expr(b) : B → B  s.t. x '→ b[i ← [[expr]]b]
∀b ∈ B Fif test {R} {S}(b) : B × B|R| × B × B|S| × B → B × B|R| × B × B|S| × B
x, X, y, Y, z '→ T(b, test), FR(x, X), F(b, test), FS(y, Y ), X|R| ∪B Y|S|
∀b ∈ B Fwhile test {R}(b) : B × B × B|R| × B → B × B × B|R| × B
x, y, Y, z '→ b ∪B Y|R|, T(x, test), FR(y, Y ), F(x, test).
The function FP (b) is an increasing self-map in the complete lattice of environment boxes ⟨B, ⊆, ∪B, ∩⟩|P |, so by Tarski’s fixed point theorem [25] FP (b) has a lfp which is included in every post-fixed point of FP (b).
Mathematical programming
We assume in the following that the distance between two different elements in C is greater than a given ϵ > 0. So any vj < vi (resp. vi < vj) can be replaced with vj + ϵ ≤ vi (resp. vi ≤ vj + ϵ) in P-programs. To each box b ∈ B we associate a triplet (e, l, u) ∈ {0, 1}× Rn × Rn, where b = [l(b)1, u(b)1] ×· · ·× [l(b)n, u(b)n] and e = 0 iff b is empty.
The constraints SB(b, e) force the bounds of b to 0 when the binary decision variable e is 0.

SB(b, e)	=
  1≤i≤n	(1 − e)ui = 0	∧	(1 − e)li = 0.

The constraint Incl(b, b', e), active only when e = 1, compares the bounds of b' and the bounds of b.

Incl(b, b', e)	d=ef
eu ≤ e u'
∧	e l' ≤ el .

The constraints UI(b1, b2, b3) model the statement if vj ≤ vi {b1 ... } {b2 ... } b3, where the bj are environment boxes at key control points. Intuitively, they say that b3 is empty iff both b1 and b2 are empty, otherwise b3 includes the box-wise union b1 ∪B b2; e1, e2 deactivate the constraints when b1, b2 are empty, so that the bounds of the empty box (i.e. 0) should not interfere with meaningful bounds in further constraints. To compute the exact box-wise union, equality must hold instead of loose inclusion. This will however be enforced by the objective function direction.

UI(b1, b2, b3)	d=ef
e3 = e1 + e2 − e1e2 ∧ SB(b3, e3) ∧
Incl(b1, b3, e1) ∧ Incl(b2, b3, e2).

The constraints UW(b1, b2, b3) model the statement while b3 vj ≤ vi {b2 ... }b1. Intuitively, they say that b1 is empty if b3 is empty, in which case b3 is set to empty; otherwise, if b2 is non-empty, its bounds are taken into account; the bounds of b1 may always be taken into account since b1 is empty if b3 is empty.

UW(b1, b2, b3)	d=ef
e3 ≥ e1 ∧ SB(b3, e3) ∧
Incl(b1, b3, 1) ∧ Incl(b2, b3, e2).

The constraints Id(b, b', I) enforce b' = b (when b' is non-empty) on all components not included in I.

Id(b, b', I)	d=ef
  j∈/I
u' = e'u
∧ l' = e'l .

The constraints Empty(e, e', x, y) set e' to 0 if e = 0 or x − y < 0 and otherwise to 1 (used to define intersection).

Empty(e, e', x, y)	d=ef
e' ≤ e	∧	0 ≤ e'(x − y)	∧
0 ≤ e(1 − e')(y − ϵ − x).

The constraints ConstInter(b, bs, bf , c, i) disjoin the i-th interval component of b into bs, bf , assigned respectively to the success (s) and failure (f ) of the test c ≤ vi; Id constraints manage the other components, the Empty constraints manage emptiness, and the last constraints set the bounds in a correlated manner, i.e. the bounds of bs involve bf and conversely.

ConstInter(b, bs, bf , c, i)	d=ef
Id(b, bs, {i})	∧	Id(b, bf , {i})	∧
Empty(e, es, ui, c)	∧	Empty(e, ef ,c − ϵ, li)	∧
us = esui	∧	ls = (1 − ef )li + esef c	∧
i	i
lf = ef li	∧	uf = (1 − es)ui + esef (c − ϵ).
i	i

Similarly, the constraints Inter(b, bs, bf , j, i) disjoins the i-th and j-th interval com- ponents of b into bs, bf , assigned respectively to the success (s) and failure (f ) of the test vj ≤ vi.

Inter(b, bs, bf , j, i)	d=ef
Id(b, bs, {i, j})	∧	Id(b, bf , {i, j})	∧
Empty(e, esi, ui, lj)	∧	Empty(e, efi, lj, li)	∧ Empty(e, esj, ui, lj)	 ∧	 Empty(e, efj, uj − ϵ, ui)	∧ us = esiui	∧	ls = (1 − efi)li + esiefilj	∧
i	i
lf = efili	∧	uf = (1 − esi)ui + efiesi(lj − ϵ)	∧
i	i
ls = esjlj	∧	us = (1 − efj)uj + esjefjui	∧
j	j
uf = efjuj	∧	lf = (1 − esj)lj + efjesj(ui + ϵ).
j	j


The following express how environment boxes are transformed by assignment state- ments. Let b be in B and expr in E; L(b, expr) and U(b, expr) are defined by induction on expr.
L(b, c),	U(b, c)	d=ef	e(b)c,	e(b)c
def
L(b, vj),	U(b, vj)	=	l(b) ,	u(b)
L(b, c ∗ expr), U(b, c ∗ expr)	d=ef	c ∗ L(b, expr), c ∗ U(b, expr)	if	0 ≤ c
L(b, c ∗ expr), U(b, c ∗ expr)	d=ef	c ∗ U(b, expr), c ∗ L(b, expr)	if	c < 0

L(b, expr1 + expr2)
U(b, expr1 + expr2)
d=ef	L(b, expr )+ L(b, expr )
d=ef	U(b, expr )+ U(b, expr )

Assign(b, b', i, expr)	d=ef	e' = e ∧ u' = U(b, expr) ∧ l' = L(b, expr).
i	i

Inductive deﬁnition of a mathematical program
For all programs or instructions P/I (i.e. P in P or I in I), for all environment boxes b, the constraints CP/I (b) and the objective function OP/I are defined inductively below.
Definition 4.1 (Objective and constraints)
Oskip, Ovi←expr :	B → C  s.t. x '→ 0
For all P, I, R, S :	OIP :	B|I| × B|P | → C s.t. (X, Y ) '→ OI (X)+ OP (Y )
Oif test {R} {S} : B × B|R| × B × B|S| × B → C  s.t.
(x, X, y, Y, z) '→ OR(X) + OS (Y )+ P (u(z)i − l(z)i)
1≤i≤n
Owhile test {R} :	B × B × B|R| × B → C  s.t.

(x, y, Y, z) '→ OR(Y )+ P
(u(x)i − l(x)i)

1≤i≤n

Cskip(b):	B → {0, 1}  s.t. x '→ e(x)= e(b)∧
1≤i≤n u(x)i = u(b)i ∧ l(x)i = l(b)i
Cvi←expr(b):	B → {0, 1} s.t. x '→ Id(b, x, {i}) ∧ Assign(b, x, i, expr)
For all P, I :	CIP : B|I| × B|P | → {0, 1} s.t. (X, Y ) '→ CI (X) ∧ CP (X|I|,Y )
If I = if c ≤ vi {R} {S} (resp. vi ≤ c {R} {S} ):
CI (b): B × B|R| × B × B|S| × B → {0, 1} s.t.
(x, X, y, Y, z) '→ CR(x, X) ∧ CS (y, Y ) ∧ UI(X|R|, Y|S|, z) ∧
ConstInter(b, x, y, c, i) (resp. ConstInter(b, y, x, c + є, i))
If I = if vj ≤ vi {R} {S}:
CI (b): B × B|R| × B × B|S| × B → {0, 1} s.t. (x, X, y, Y, z) '→ CR(x, X) ∧ CS (y, Y ) ∧
UI(X|R|, Y|S|, z) ∧ Inter(b, x, y, j, i)
If I = while c ≤ vi {R} (resp. while vi ≤ c {R} ):
CI (b): B × B × B|R| × B → {0, 1} s.t.(x, y, Y, z) '→ CR(y, Y ) ∧ UW(b, Y|R|, x) ∧
ConstInter(x, y, z, c, i) (resp. ConstInter(x, z, y, c + є, i))
If I = while vj ≤ vi {R}:
CI (b): B × B × B|R| × B → {0, 1} s.t. (x, y, Y, z) '→ CR(y, Y ) ∧ UW(b, Y|R|, x) ∧
Inter(x, y, z, j, i).
Let P ∈ P ∪ I and b ∈ B.	A vector X ∈ B|P | is a unique solution of the MP MP (OP , C0, CP (b)), where the constraints C0 : B → {0, 1} are s.t. x '→
  1≤i≤n l(x)i ≤ u(x)i, if it is the only vector satisfying the constraints and minimiz-
def
ing the objective: MP (b, X) = C (b, X) ∧ ∀Y, CP (b, Y ) ⇒ OP (Y ) ≤ OP (X) ⇒
Y = X.
Example 4.2 Let P be the program int x = 1; while (x < 100) x = x+1;. Then the corresponding MP is as follows (in this case we need only employ two binary variables e3, e5 controlling emptiness on the different test outputs, the others being
fixed to 1). We minimize Σ5	(uk − lk) such that: ∀k ≤ 5 uk ≥ lk (bound
consistency constraints C0), l1 = 1 ∧ u1 = 1 (Assign for x=1), l2 ≤ l1 ∧ u2 ≥
u1 ∧l2 ≤ l4 ∧u2 ≥ u4 (Incl constraints), l4 = l3 +1 ∧u4 = u3 +1 (Assign for x=x+1), (1−e3)(l2−100) ≥ 0∧e3(99−l2) ≥ 0∧e5(u2−100) ≥ 0∧(1−e5)(99−u2) ≥ 0 (Empty constraints), u5 = e5u2∧l5 = (1−e3)l2+100e3e5∧l3 = e3l2∧u3 = (1−e5)u2+99e5e3 (ConstInter for x<100). This nonlinear MINLP was solved using Couenne [3] to find the (guaranteed) lfp ([1, 1], [1, 100], [1, 99], [2, 100], [100, 100]). Notice no widening operator was ever used, and no variable was artificially bounded to arbitrary large constants.

Correspondence between the semantics function and the mathematical program
We list some lemmata relating semantics function and MP, which prove that the MP characterizes the lfp.
Lemma 5.1 b /= ∅	⇒	[[expr]]b = [L(b, expr), U(b, expr)] Proof by induction on expressions.
Lemma 5.2 Cvi←expr(b, x)	⇔	x = b[i ← [[expr]]b]

Proof by double implication. For each implication consider cases on emptyness of b
and use Lemma 5.1.
Lemma 5.3 UI(x, y, z)	⇔	x ∪B y ⊆ z ∧ (x = ∅∧ y = ∅ ⇒ z = ∅). Lemma 5.4 UW(x, y, z)		⇔		x ∪B y ⊆ z ∧ (x = ∅∧ y = ∅ ⇒ z = ∅). Proofs of the two above lemmata by case splitting.
Lemma 5.5 ConstInter(b, x, y, c, i) ⇔ x = T(b, c ≤ vi) ∧ y = F(b, c ≤ vi).
Lemma 5.6 Inter(b, x, y, j, i) ⇔ x = T(b, vj ≤ vi) ∧ y = F(b, vj ≤ vi).
Again, proofs of the two above lemmata by double implication and case split on emp- tyness of b. For the non-empty case, one may case split along u(b)i < c, c ≤ l(b)i, and l(b)i < c ≤ u(b)i.
Every fixed point of a semantics function complies with the corresponding con- straints.
Lemma 5.7 ∀P/I, b, X	FP/I (b, X) = X ⇒ CP/I (b, X).
We define vector inclusion as follows:

X ⊆ Y
d=ef	∀i, X ⊆ Y

X ⊂ Y
d=ef	X ⊆ Y ∧ X /= Y

Every vector satisfying the constraints of the MP is a post-fixed point of the corre- sponding semantics function.
Lemma 5.8 ∀P/I, b, X  CP/I (b, X) ⇒ FP/I (b, X) ⊆ X.
The objective OP/I is (weakly) increasing.
Lemma 5.9 X ⊆ X'  ⇒  OP/I (X) ≤ OP/I (X').
Proof by induction on programs and instructions, notice that OP/I only involves sums of upper bounds minus lower bounds.
The objective is strongly increasing on vectors satisfying the same constraints.
Lemma 5.10 ∀P/I, b, X  CP/I (b, X) ∧ CP/I (b, X') ∧ X ⊂ X' ⇒
OP/I (X) < OP/I (X').
The lfp of the forward-collecting semantics function of a program is the unique solution of the MP associated with the program.
Theorem 5.11 FP (b, X) = X ∧ (FP (b, Y ) = Y ⇒ X ⊆ Y ) ⇒ MP (b, X).


Policy Iteration algorithm in the MP setting
The products eiej between binary variables appearing for some i, j in the MP of Sect. 4 can all be reformulated exactly as follows: replace eiej by an added binary variable eij, and adjoin the constraints eij ≤ ei, eij ≤ ej, eij ≥ ei + ej − 1. This is also called “Fortet’s reformulation”, see [20], p. 178. After this reformulation, the

MP has the following bilinear structure:
min{wT(x, e) | h(x) ≤ 0 ∧ eT(g(x) − x) ≤ 0 ∧ (1 − e)T(g'(x) − x) ≤ 0},	(1)
where x = (l, u) is a vector of continuous decision variables, w is a constant vector encoding the (linear) interval width objective, h, g, g' are affine forms, and e ∈
{0, 1}p are binary decision variables. A policy in this setting is an assignment of
binary values to the binary variable vector e. It appears clear from (1) that policies determine whether g(x) ≤ x or g'(x) ≤ x, where both g, g' are affine forms. The PI algorithm can be re-cast in the MP setting as follows.
Let e∗ be an initial (feasible) policy
Let e ← e∗ in (1), yielding a LP
Value determination: solve the LP to obtain a solution x∗
Let e¯ ← e∗
Policy improvement:
∀i ≤ p (e∗ = 1 ∧ gi(x∗) > g'(x∗) ⇒ e¯i ← 0)
i	i
∀i ≤ p (e∗ = 0 ∧ gi(x∗) < g'(x∗) ⇒ e¯i ← 1)
i	i
If e¯ = e∗ then terminate with fixed point x∗
Set e∗ ← e¯ and repeat from Step ii.
Thus, the PI algorithm performs a local search on the e-space of (1), whereas the algorithms mentioned in Sect. 7 explore the entirety of the e-space, thereby always finding the guaranteed lfp. By comparison, a known sufficient condition for PI methods to find a guaranteed lfp is that the semantics function should be non-expansive in the sup norm [7].
Solving the mathematical program
Given a program P , the constraints CP of the associated MP are generated in linear time w.r.t. the size |P | of the program. These constraints involve O(|P|) binary variables. There are 2O(|P|) possible assignments for these variables. Fixing the binary variables to one of these assignments yields an LP, which can be solved in polynomial time in the size of the instance [18] (LP methods can also certify infeasibility and unboundedness). If for all possible assignments the LP has no solution, it means that the lfp of FP is not finite. Otherwise, any finite solution is a post-fixed point of FP by Lemma 5.8. The lfp is one of the post-fixed points according to Theorem 5.11, and it is the smallest of them according to Tarski [25]. The practical complexity of the proposed algorithm for solving SAAIP is likely to be close to its worst-case complexity bound (exponential), and is thus only useful to improve the best known complexity bound so far for SAAIP (Kleene’s iteration with no widening takes infinite time; the method proposed in [22] runs in doubly exponential time).
We can use MP methodology to derive a practically applicable algorithm for solving a slightly modified SAAIP. By assuming an arbitrary large bound on the

variable values (this is akin to imposing that all boxes are in a large pre-determined box, similarly to what is done in widening), we are able to reformulate exactly ([20], p. 179) all products between decision variables occurring in the MP to a linear form, yielding a MILP which we solve using the BB based solver CPLEX 11 [17] on a 2.4GHz Intel Xeon CPU with 8GB RAM. Notice that for most practical cases, the large bound need not be arbitrary, as automatic range reduction techniques for MILP can help considerably [24].
Based on the above analysis, we implemented a C parser (recognizing a subset of C which is sufficiently rich to be Turing-equivalent) that outputs the corresponding MP. Our testbed consists of several (small) C programs 7 with integer affine arith- metic: some minimal ones for validation purposes (short), some longer ones (long) generated randomly, three instances using arrays and functions and the subway code from [16] with the random() call commented out and nbtrains set to 10. We compared our results to those obtained by a prototype implementation of the PI algorithm [7]; in both approaches, T was set to the interval [—5000, 5000]. In Table 1 we report: instance name, lines of code, total number of variables (arrays of length n counting as n variables), seconds of user CPU, lfp statistics (sum of the widths of all intervals | · |, number of T intervals |T|, sum of widths of non-T intervals
|чT|). In all tests we obtained fixed points of width equal to or smaller than those obtained by PI, thus validating the approach.

Table 1
Comparison of MP and PI methods. Instances are marked ‘-’ whenever the program could not be analyzed because of parsing limitations (arrays, functions) in our prototype PI implementation.


Conclusion
We exhibited a mathematical program modelling the problem of finding the lfp of the semantic function of a program with integer affine arithmetic, and proceeded to show that this yields a practically viable method for computing lfps of programs. By this example we wish to emphasize the usefulness that the standard mathemat- ical programming toolbox has in the field of static analysis by abstract interpre- tation. Future work will extend the MP approach to work with different domains

7  http://www.lix.polytechnique.fr/~liberti/nsad10-instances.zip

(specifically, relational domains); we shall also employ other methods, such as pol- icy iteration, as upper bounding procedures within the standard Branch-and-Bound approach used to solve Problem (1).

References
Adje, A., S. Gaubert and E. Goubault, Computing the smallest fixed point of nonexpansive mappings arising in game theory and static analysis of programs (2008), presented at MTNS 2008, also arXiv.org:0806.1160.
Adj´e, A., S. Gaubert and E. Goubault, Coupling policy iteration with semi-definite relaxation to compute accurate numerical invariants in static analysis, in: A. Gordon, editor, European Symposium on Programming (2010), pp. 23–42.
Belotti, P., J. Lee, L. Liberti, F. Margot and A. W¨achter, Branching and bounds tightening techniques for non-convex MINLP, Optimization Methods and Software 24 (2009), pp. 597–634.
Bonami, P., L. Biegler, A. Conn, G. Cornu´ejols, I. Grossmann, C. Laird, J. Lee, A. Lodi, F. Margot,
N. Sawaya and A. W¨achter, An algorithmic framework for convex mixed integer nonlinear programs, Technical Report RC23771, IBM Corporation (2005).
Bonami, P., G. Cornu´ejols, A. Lodi and F. Margot, A feasibility pump for mixed integer nonlinear programs, Mathematical Programming 119 (2009).
Col´on, M., S. Sankaranarayanan and H. Sipma, Linear invariant generation using non-linear constraint solving, in: W. Hunt, editor, Computer Aided Verification, LNCS 2725 (2003), pp. 420–432.
Costan, A., S. Gaubert, E. Goubault, M. Martel and S. Putot, A policy iteration algorithm for computing fixed points in static analysis of programs, in: K. Etessami and S. Rajamani, editors, Computer Aided Verification, LNCS 3576 (2005), pp. 462–475.
Cousot, P., Proving program invariance and termination by parametric abstraction, Lagrangian relaxation and semidefinite programming, in: R. Cousot, editor, Verification, Model Checking and Abstract Interpretation, LNCS 3385 (2005), pp. 17–19.
Cousot, P. and R. Cousot, Static determination of dynamic properties of programs, in: Proceedings of the Second International Symposium on Programming (1976), pp. 106–130.
Cousot, P. and R. Cousot, Abstract interpretation: A unified lattice model for static analysis of programs by construction of approximations of fixed points, Principles of Programming Languages 4 (1977),
pp. 238–252.
Cousot, P. and R. Cousot, Abstract interpretation frameworks, Journal of Logic and Computation 2
(1992), pp. 511–547.
Gaubert, S., E. Goubault, A. Taly and S. Zennou, Static analysis by policy iteration on relational domains, in: R. D. Nicola, editor, European Symposium on Programming, LNCS 4421 (2007), pp. 237–252.
Gawlitza, T., J. Leroux, J. Reineke, H. Seidl, G. Sutre and R. Wilhelm, Polynomial precise interval analysis revisited, in: S. Albers, H. Alt and S. N¨aher, editors, Festschrift Mehlhorn, Lecture Notes in Computer Science 5760 (2009), pp. 422–437.
Gawlitza, T. and H. Seidl, Precise fixpoint computation through strategy iteration, in: R. D. Nicola, editor, European Symposium on Programming, LNCS 4421 (2007), pp. 300–315.
Gawlitza, T. and H. Seidl, Precise relational invariants through strategy iteration, in: J. Duparc and
T. Henzinger, editors, Computer Science Logic, 2007, pp. 23–40.
Halbwachs, N., Y.-E. Proy and P. Roumanoff, Verification of real-time systems using linear relation analysis, Formal Methods in System Design 11 (1997), pp. 157–185.
ILOG, “ILOG CPLEX 11.0 User’s Manual,” ILOG S.A., Gentilly, France (2008).
Karmarkar, N., A new polynomial time algorithm for linear programming, Combinatorica 4 (1984),
pp. 373–395.
Liberti, L., Reformulations in mathematical programming: Definitions and systematics, RAIRO-RO
43 (2009), pp. 55–86.


Liberti, L., S. Cafieri and F. Tarissan, Reformulations in mathematical programming: A computational approach, in: A. Abraham, A.-E. Hassanien, P. Siarry and A. Engelbrecht, editors, Foundations of Computational Intelligence Vol. 3, number 203 in Studies in Computational Intelligence, Springer, Berlin, 2009 pp. 153–234.
Liberti, L., N. Mladenovi´c and G. Nannicini, A good recipe for solving MINLPs, in: V. Maniezzo,
T. Stu¨tzle and S. Voß, editors, Hybridizing metaheuristics and mathematical programming, Annals of Information Systems 10 (2009), pp. 231–244.
Monniaux, D., Automatic modular abstractions for linear constraints, in: Principles of programming languages, ACM (2009), pp. 140–151.
Sankaranarayanan, S., H. Sipma and Z. Manna, Scalable analysis of linear systems using mathematical programming, in: R. Cousot, editor, Verification, Model Checking and Abstract Interpretation, LNCS 3385 (2005), pp. 25–41.
Savelsbergh, M., Preprocessing and probing techniques for mixed integer programming problems, INFORMS Journal on Computing 6 (1994), pp. 445–454.
Tarski, A., A lattice-theoretical fixpoint theorem and its applications, Pacific Journal of Mathematics 5
(1955), pp. 285–309.
Williams, H., “Model Building in Mathematical Programming,” Wiley, Chichester, 1999, 4th edition.

Appendix: Proofs
Lemma 5.7 ∀P/I, b, X	FP/I (b, X) = X ⇒ CP/I (b, X).
Proof. By induction on P/I. (Induction hypotheses are assumed implicitly.) Case P = I: trivial. Case P = I Q: assume FP (b, X, Y ) = (X, Y ). So by Defini- tion 3.5, X and Y are fixed points of FI (b) and FQ(X|I|) respectively, so CI (b, X) and CQ(X|I|,Y ) by induction hypothesis, so CP (b, X, Y ) by Definition 4.1. Case P = skip: if FP (b, x) = x then x = b by Definition 3.5, then CP (b, x) by Def- inition 4.1. Case I = vi ← expr: assume FI (b, x) = x. So x = b[i ← [[expr]]b] by Definition 3.5, so CI (b, x) by Lemma 5.2. Case I = if test {R} {S}: as- sume FI (b, x, X, y, Y, z) = (x, X, y, Y, z).  So by Definition 3.5, x = T(b, test), y = F(b, test), X and Y are fixed points of FR(x) and FS(y) respectively, and z = X|R| ∪B Y|S|. So CR(x, X) and CS(y, Y ) by induction hypothesis and UI(X|R|, Y|S|, z) by Lemma 5.3. For constant tests, assume that test is c ≤ vi (since the other case is similar). So ConstInter(b, x, y, c, i) by Lemma 5.5. For non-constant tests, by Lemma 5.6 we have Inter(b, x, y, j, i). Therefore CI (b, X, Y, z) by Definition 4.1. Case I = while test {R}: assume FI (b, x, y, Y, z) = (x, y, Y, z). So by Definition 3.5, x = b ∪B Y|R|, y = T(x, test), Y = FR(y, Y ), and z = F(x, test). So CR(y, Y ) by induction hypothesis and UW(b, Y|R|, x) by Lemma 5.4. For constant tests, assume test is c ≤ vi (since the other case is similar), so ConstInter(x, y, z, c, i) by Lemma 5.5; for non-constant tests, Inter(x, y, z, j, i) by Lemma 5.6. Therefore CI (b, x, Y, z) by Definition 4.1.	□
Lemma 5.8 ∀P/I, b, X  CP/I (b, X) ⇒ FP/I (b, X) ⊆ X.
Proof. By induction on P/I. (Induction hypotheses are assumed implicitly.) Case P = I: trivial. Case P = I Q: assume CP (b, X, Y ). So CI (b, X) and CQ(X|I|,Y ) by Definition 4.1, so we have FI (b, X) ⊆ X and FQ(X|I|,Y ) ⊆ Y by induction hypothesis, so FP (b, X, Y ) ⊆ (X, Y ) by Definition 3.5. Case P = skip: if CP (b, x) then x = b By Definition 4.1, so FP (b, x) = x by Definition 3.5. Case I = vi ← expr:

assume CI (b, x). So x = b[i ← [[expr]]b] by Lemma 5.2, so FI (b, X) = X by Defini- tion 3.5. Case I = if test {R} {S}: constant tests: assume test is c ≤ vi (since the other case is similar). Assume CI (b, x, X, y, Y, z). So by Definition 4.1, CR(x, X) and CS(y, Y ) and ConstInter(b, x, y, c, i) and UI(X|R|, Y|S|, z). So x = T(b, test) and y = F(b, test) by Lemma 5.5. Non-constant tests: CR(x, X) and CS(y, Y ) and Inter(b, x, y, j, i) and UI(X|R|, Y|S|, z). So x = T(b, test) and y = F(b, test) by Lemma 5.6. Also FR(x, X) ⊆ X and FS(y, Y ) ⊆ Y by induction hypothesis and X|R| ∪B Y|S| ⊆ z by Lemma 5.3. Therefore FI (b, x, X, y, Y, z) ⊆ (x, X, y, Y, z) by Definition 3.5. Case I = while test {R}: constant tests: assume test is c ≤ vi (since the other case is similar). Assume CI (b, x, y, Y, z). So by Definition 4.1, CR(y, Y ) and UW(b, Y|R|, x) and ConstInter(x, y, z, c, i). So y = T(x, test) and z = F(x, test) by Lemma 5.5. Non-constant tests: CR(x, X) and CS(y, Y ) and Inter(b, x, y, j, i) and UI(X|R|, Y|S|, z). Also FR(y, Y ) ⊆ Y by induction hypothesis and b ∪B Y|R| ⊆ x by Lemma 5.4. Therefore FI (b, x, y, Y, z) ⊆ (x, y, Y, z) by Definition 3.5.	□
Lemma 5.9 ∀P/I, b, X  CP/I (b, X)∧CP/I (b, X')∧X ⊂ X' ⇒ OP/I (X) < OP/I (X').
Proof. By induction on P/I. (Induction hypotheses are assumed implicitly.) Case P = I: trivial. Case P = I Q: assume CP (b, X, Y ) and CP (b, X',Y ') and (X, Y ) ⊂ (X',Y '). So by Definition 4.1, CI (b, X) and CQ(X|I|,Y ) (resp. with the prime). Also OI (X) ≤ OI (X') and OQ(Y ) ≤ OQ(Y ') by Lemma 5.9 and assumption. If X ⊂ X' then OI (X) < OI (X') by induction hypothesis. If X = X' then Y ⊂ Y ', then OQ(Y ) < OQ(Y ') by induction hypothesis. In both cases OP (X, Y ) < OP (X',Y ') by Definition 4.1. Case P = skip: if CP (b, x) and CP (b, x') then x = b = x' by Definition 4.1. Case I = vi ← expr: assume CI (b, x) and CI (b, x') and x ⊂ x'. So x = x' by Definition 4.1 and Lemma 5.2. Case I = if test {R} {S}: constant test: assume test is c ≤ vi (since the other case is similar). Assume CI (b, x, X, y, Y, z) and CI (b, x',X', y',Y ', z') and (x, X, y, Y, z) ⊂ (x',X', y',Y ', z'). So by Definition 4.1, we have CR(x, X), CS(y, Y ), and ConstInter(b, x, y, c, i) (resp. with the prime). So x' = x by Lemma 5.5 applied twice, hence CR(x, X) and CR(x, X') (resp. with y and Y ). Also OR(X) ≤ OR(X') and OS(Y ) ≤ OS(Y ') by Lemma 5.9 and assumption,

and, further,
1≤i≤n
(u(z)i — l(z)i) ≤
1≤i≤n
(u(z')i — l(z')i) by assumption. If X ⊂ X'

(resp. Y ⊂ Y ') then OR(X) < OR(X') (resp. OS(Y ) < OS(Y ')) by induction hypothesis. If X = X' and Y = Y ', then z ⊂ z' by assumption, so z' /= ∅, so

z /= ∅ by Definition 4.1 and Lemma 5.3, so
1≤i≤n
(u(z)i — l(z)i) <
1≤i≤n
(u(z')i —

l(z')i). In any case OP (x, X, y, Y, z) < OP (x',X', y',Y ', z') by Definition 4.1. The argument for non-constant tests is similar. Case I = while test {R}: constant tests: assume test is c ≤ vi (since the other case is similar). Assume CI (b, x, y, Y, z) and CI (b, x', y',Y ', z') and (x, y, Y, z) ⊂ (x', y',Y ', z'). So by Definition 4.1, we have CR(y, Y ) and UW(b, Y|R|, x) (resp. with the prime). By assumption OR(Y ) ≤
OR(Y ') and	(u(x)i — l(x)i) ≤	(u(x')i — l(x')i). If Y ⊂ Y ' then OR(Y ) <
1≤i≤n	1≤i≤n
OR(Y ') by induction hypothesis.  Now assume Y  = Y '.  So UW(b, Y|R|, x) and
UW(b, Y|R|, x'). If x ⊂ x' then x' /= ∅, then x /= ∅ by Lemma 5.4, then	(u(x)i —
1≤i≤n

l(x)i) <
1≤i≤n
(u(x')i — l(x')i), then OI (x, Y, z) < OI (x',Y ', z').  If x = x' then

y = y' and z = z' by Lemma 5.5, contradiction. In any case OI (x, y, Y, z) < OI (x', y',Y ', z') by Definition 4.1. The argument for non-constant tests is similar.□
Theorem 5.10 FP (b, X) = X ∧ (FP (b, Y ) = Y ⇒ X ⊆ Y ) ⇒ MP (b, X).
Proof. Let X be the lfp of FP (b). By Lemma 5.7, CP (b, X). Assume Y such that CP (b, Y ) and OP (Y ) ≤ OP (X). By Lemma 5.8, Y is a post-fixed point of FP (b), so X ⊆ Y by Tarski [25], so Y = X by contraposition of Lemma 5.10 and assumption OP (Y ) ≤ OP (X).	□
