	Electronic Notes in Theoretical Computer Science 174 (2007) 109–125	
www.elsevier.com/locate/entcs

A Formalization of Strong Normalization for Simply-Typed Lambda-Calculus and
System F
Kevin Donnelly1 ,2 and Hongwei Xi1 ,3
Computer Science Department, Boston University Boston, USA

Abstract
We formalize in the logical framework ATS/LF a proof based on Tait’s method that establishes the simply- typed lambda-calculus being strongly normalizing. In this formalization, we employ higher-order abstract syntax to encode lambda-terms and an inductive datatype to encode the reducibility predicate in Tait’s method. The resulting proof is particularly simple and clean when compared to previously formalized ones. Also, we mention briefly how a proof based on Girard’s method can be formalized in a similar fashion that establishes System F being strongly normalizing.
Keywords: Logical frameworks, Normalization, Tait’s method, Logical relations, Reducibility candidates, HOAS, ATS/LF


Introduction
ATS/LF [4] is a logical framework rooted in the Applied Type System [15] and is a pure total fragment of the programming language ATS. It uses a restricted form of dependent types in which types may only be indexed by terms drawn from limited domains in which equality is decidable (and can also be effectively reasoned about). ATS/LF supports the use of higher-order abstract syntax (HOAS) [9] to encode object languages. The use of HOAS, in which object variables are identified with metavariables and β-reduction models substitution, leads to particularly simple and elegant encodings. The combination of a limited type-index language and a powerful proof language, as found in ATS/LF, allows for inductive proofs of metatheorems over full higher-order abstract syntax to be directly encoded as total

1 The work is partly funded by NSF grant CCR-0229480
2 Email: kevind@cs.bu.edu
3 Email: hwxi@cs.bu.edu

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.01.021

recursive functions. The use of inductive datatypes with negative occurrences allows for the encoding of the reducibility predicate.
In this paper, we formalize a proof of strong normalization of the simply typed lambda-calculus (STLC) using Tait’s method, closely following the one in [7]. On one hand, we use HOAS to encode lambda-terms, obviating the need for explicitly manipulating substitution on such terms. On the other hand, we use first-order abstract syntax (FOAS) to encode typing derivations in STLC, which conveniently supports inductive reasoning on typing derivations.
To our knowledge this is the first formalized (or mechanized) proof of strong nor- malization using Tait’s method for an object language defined with HOAS. When compared to other formalized proofs of strong normalization in the literature, the brevity of our formalized proof and its closeness to the concise and elegant proof in [7] yield some concrete evidence in support of the effectiveness of the represen- tation of STLC in ATS/LF. To further strengthen this claim, we also discuss the extension to the case of System F, formalizing a proof of strong normalization of System F based on Girard’s notion of reducibility candidates [6]. We expect that the techniques developed here can also allow for the formalization of other proofs by logical relations while still being able to take advantage of HOAS.

ATS/LF
ATS/LF is split into two main parts: the language of types and type indices (called the statics), and the language of proofs (called the dynamics). The statics is basi- cally simply-typed lambda-calculus with constants (but no recursion), and terms in the statics are referred to as static terms and types in the statics are referred to as sorts. There are three important built-in base sorts:
prop : A sort for static terms which represent types of proofs.
(... , -1, 0, 1,... : int) and for addition (+ : (int, int) → int) and subtraction • int : A sort for static integer terms. There are constants for each integer (- : (int, int) → int).
(true, false : bool) and equality and inequality on integers (=,< : (int, int) → • bool : A sort for static boolean conditions. There are constants for truth values bool).
Static constants may take multiple arguments. Equality in the statics is basically β-conversion plus Presburger arithmetic, and it is decided by converting to βη long normal form and then using a decision procedure for integer (in)equalities (after mapping boolean terms to integer terms).
The dynamics is a dependently typed language with well-founded recursion, exhaustive case-analysis and inductive datatypes. Termination is checked using a programmer-supplied metric, which is a tuple of static terms representing natu- ral numbers and decreasing in each recursive call according to the standard lex- icographic ordering. Please see [13] for more details on this style of termination checking. Case coverage is checked by requiring that any unlisted cases introduce



Syntax:

terms		t ∈ tm ::= x | λx.t | t1 t2 | c types		 τ ∈ tp ::= B | τ1 → τ2 contexts	Γ ∈ ctx ::= ·| Γ,x : τ
Fig. 1. Syntax for Simply-typed λ-calculus

assumptions that allow false to be proven [14]. In the concrete syntax, a proof (function) declaration looks like:

prfun proofName {x1:stx1, ..., xn:stxn} .<m1, ..., mk>.
(p1:T1, ..., pl:Tl) : [y1:sty1, ..., ym:stym] T = ...
This declaration is for a total recursive function called proofName (prfun is a keyword for introducing proof functions) with the type:
∀x1 : stx1,... , ∀xn : stxn.(T1,... , Tl) → ∃y1 : sty1,... , ∃ym : stym.T
This type signature consists of four parts. First, there are n static parameters xi of
sorts stx i, enclosed in curly braces (think of these as universally quantified). Sec- ond, there is a metric, enclosed in .< and >., which is a k-tuple of static terms representing natural numbers and may contain x1,... , xn. Third, there are l dy- namic parameters pi with types Ti that may contain x1,... , xn. Fourth, there is the return type which consists of m existentially quantified static variables yi of sorts
sty i and a type T which may contain x1,... , xn, y1,... , ym. In the case where the declared function proofName is not recursive, we may also use the keyword prfn and give no metric. Please see [4,5] for some examples of proofs formed in ATS/LF.

Encoding the Object Language
Syntax
The object language for which we prove strong normalization is STLC with a con- stant c and a base type B. The syntax of the language is shown in Figure 1. We
will encode the syntax in the statics using HOAS. In order to do so we declare a static sort for each syntactic category. We begin with a sort, tm, with constructors for each term constructor of the object language:
TMlam : (tm → tm) → tm	TMapp : (tm, tm) → tm	TMcst : tm
Object variables are encoded as metavariables. The constant TMcst is only used
in the formalization as a placeholder when recursing under lambda binders. Object
functions are represented by functions in the statics, and this allows us to model substitution in the object language with application in the metalanguage. The terms




Reduction: t1 −→ t2
t −→ t'

(REDlam)
  t1 −→ t'
(REDapp1)

λx.t −→ λx.t'
	t2 −→ t'
(REDapp2)
t1 t2 −→ t' t2

(REDapp3)

t1 t2 −→ t1 t'
(λx.t1) t2 −→ t1[t2/x]

Fig. 2. Reduction rules for λ-calculus
of the object language are encoded in the statics with the function ·’ defined by:
 x’ = x	 c’ = TMcst
 λx.t’ = TMlam(λx. t’)	 t1 t2’ = TMapp( t1’, t2’)
This is a compositional bijection between terms of the object language with up to
n free variables and static terms of sort tm with up to n free variables.
To encode types we declare a sort tp, with constructors for each type constructor of the object language:
TPbas : tp	TPfun : (tp, tp) → tp
In some encodings with HOAS, there is no explicit representation of contexts in the
representation of typing judgments, but instead the context of the metalanguage is utilized. Such higher-order representations of the typing judgment, as often used in Twelf [10], benefit from inheriting substitution on typings from the metalan- guage, and so do not need a typing substitution lemma. On the other hand, the use of explicit contexts allows for a first-order representation of typing derivations. This, along with the separation between statics and dynamics, allows us to prove metatheorems directly, using total recursive functions, while still taking advantage of HOAS for object syntax. The inconvenience of having to prove substitution on typing derivations is minor, and not pervasive as issues involving binders in the syntax are. In fact, we do not ever need to make use of substitution on typing
derivations in the proof of strong normalization. Contexts, of sort ctx, are repre- sented by lists of pairs of a tm and a tp:
CTXnil : ctx	CTXcons : (tm, tp, ctx) → ctx
We may sometimes abbreviate CTXcons(t,T,G) as (t, T ) :: G. Really this sort
represents explicitly typed substitutions. A term of sort ctx only represents a well- formed context if its tm subterms are all distinct metavariables. We will return to this issue when we encode typing derivations.

Reduction

tion, t −→ t', is encoded as a datatype with type constructor RED : (tm, tm, int) → The rules for small-step reduction for pure λ-calculus are shown in Figure 2. Reduc- prop (where the third index measures the size of the derivation) and one term con-
structor to encode each rule in Figure 2. The most interesting rules are REDlam




Type formation: ▶ τ type
▶ B type (TPbas)
▶ τ1 type ▶ τ2 type
▶ τ1 → τ2 type	(TPfun)

Typing: Γ ▶ t : τ
(x : τ ) ∈ Γ  ▶ τ type
Γ ▶ x : τ	(DERvar)

Γ,x : τ1 ▶ t : τ2	▶ τ1 type (DERlam)	Γ ▶ t1 : τ1 → τ2	Γ ▶ t2 : τ1
(DERapp)

Γ ▶ λx.t : τ1 → τ2	Γ ▶ t1 t2 : τ2
Fig. 3. Typing rules for Simply-typed λ-calculus
and REDapp3 which correspond to the dynamic term constructors:
REDlam : ∀f : tm → tm.∀f ' : tm → tm.∀n : nat.
(∀x : tm. RED(f x, f ' x, n)) → RED(TMlam f, TMlam f ',n + 1)
REDapp3 : ∀f : tm → tm.∀t : tm. RED(TMapp(TMlam f, t),f t, 0)
Since the rules themselves are first order, adequacy follows from the fact that the higher-order syntax in the type indices correspond to the right terms. The most
structor (∀x : tm. RED(f x, f ' x, n)) and the fact that application in the statics interesting rule is REDlam: from the quantification in the argument of the con- models substitution, we can see that f x and f ' x represent lambda-terms with x
being free and that TMlam f and TMlam f ' represent these same terms with x
bound by a lambda.

Type Assignment

context lookup relation (x : τ ) ∈ Γ. For this we use a datatype with type constructor The rules for typing judgments are shown in Figure 3. We begin by defining the INCTX : (tm, tp, ctx, int) → prop, where INCTX(t, T, G, n) means that (t, T ) is at the nth index in G (abbreviated as (t, T ) ∈n G), and two term constructors which correspond to the rules:

(INCTXone)
(t, T ) ∈0 ((t, T ) :: G)
(t, T ) ∈n G
(t, T ) ∈n+1 ((t′,T ′) :: G) (INCTXshi)

Note that if INCTX(t, T, G, n) is inhabited, its member is unique and isomorphic
to n (since it is a non-branching tree of depth n).

We encode the judgment ▶ τ type with a datatype, where the type constructor is TP : (tp, int) → prop and the term constructors represent the following rules (where we write ▶n T type for TP(T, n)):
▶n1 T1 type ▶n2 T2 type

▶0 TPbas type (TPbas)
(TPfun)
▶n +n +1 TPfun(T1, T2) type

While the constructors of this type have the same names as terms of sort tp, there
is no ambiguity because dynamic terms are strictly separated from static terms. The type TP(T, n) contains a single element which is isomorphic to T if the size of T is n. The size index is used to provide a metric to support induction on the

Encoded Typing: G ▶n t : T
(t, T ) ∈n G	▶ T type
G ▶0 t : T	(DERvar)
▶ T1 type	(∀x. (x, T1) :: G ▶n f x : T2)

G ▶n+1 TMlam f : TPfun(T1, T2)
G ▶n1 t1 : TPfun(T1, T2)	G ▶n2 t2 : T1 G ▶n1+n2+1 TMapp(t1, t2): T2
(DERlam)
(DERapp)



Fig. 4. Encoded Typing Rules


structure of types. For convenience, we define TP0(T ) ≡ ∃n : nat. TP(T, n) (which we abbreviate as ▶ T type).
The encoding of the typing judgment Γ ▶ t : τ is a dependent datatype, DER : (ctx, tm, tp, int) → prop, where the last index is a measure of the size of the typing
G ▶n t : T abbreviates DER(G, t, T, n)). The typing rule for variables is encoded derivation. The constructors correspond to the inference rules in Figure 4 (where by the term constructor:
DERvar : ∀G : ctx.∀t : tm.∀T : tp.∀n : nat. (INCTX(t, T, G, n), TP0 T ) → DER(G, t, T, 0)
The context is represented as a list, so the variable lookup identifies the index in the
list that corresponds to the given variable. The typing rule for lambda-abstraction is encoded by the following constructor:
DERlam : ∀G : ctx.∀f : tm → tm.∀T1 : tp.∀T2 : tp.∀n : nat.∀l : nat. (TP0 T1, ∀x : tm. DER(CTXcons(x, T1, G),f x, T2, n)) → DER(G, TMlam f, TPfun(T1, T2),n + 1)
(∀x.DER(CTXcons(x, T1, G),f x, T2, n)) guarantees that x is a metavariable not Note that the quantification over x in the second argument of this constructor occurring in G and thus CTXcons(x, T1, G) is a well-formed context if G is. The
typing rule for application is encoded by the following constructor:

DERapp : ∀G : ctx.∀t1 : tm.∀t2 : tm.∀T1 : tp.∀T2 : tp.∀n1 : nat.∀n2 : nat. (DER(G, t1, TPfun(T1, T2), n1), DER(G, t2, T1, n2)) → DER(G, TMapp(t1, t2), T2, n1 + n2 + 1)
For convenience we also define DER0(G, t, T ) ≡ ∃n : nat. DER(G, t, T, n). This representation for typing derivations is quite interesting. The dynamic terms inhab-
iting the datatype DER0(G, t, T ) are isomorphic to simply-typed lambda-terms of Church-style in which variables are represented as de Bruijn indices. The context G
is a typed substitution, which we can decompose into a substitution Θ = ⟨t1,... , tm⟩ (which maps the ith variable to ti for 1 ≤ i ≤ m) and a context Γ = ⟨T1,... , Tm⟩. if we have derivations of ▶ ti : Ti (for 1 ≤ i ≤ m) then we can form a derivation of The datatype DER0(G, t, T ) really represents a hypothetical judgment saying that
▶ t : T . As long as Θ is a list of distinct meta-variables (say ⟨x1, ..., xm⟩), this is
an adequate encoding of the usual typing judgment x1 : T1, ..., xm : Tm ▶ t : T . We can guarantee that a context is well-formed in this way when it is empty or when

it appears in a derivation that is a sub-derivation of one with an empty context. We are able to prove strong normalization for terms typed in the empty context and, since reduction under lambda is allowed, this implies strong normalization for terms containing free variables as well.

Strong Normalization Proof
In this section, we formalize a proof of strong normalization of STLC based on Tait’s method [12]. The formalized proof is nearly identical to the one in [7], with the only exception that we use the constant c in some places where the proof in [7] uses a variable. The cause for this exception directly results from HOAS being chosen for representing lambda-terms (and thus making it difficult to manipulate object variables). The proofs for the final few lemmas and strong normalization theorem are given in Appendix A and the entire proof can be found on-line:
http://www.cs.bu.edu/∼hwxi/ATS/EXAMPLE/LF/STLC-SN-hoas.dats
n, written SNn(t), if for all t' such that t −→ t' we have SNn' (t') for some natural Definition 4.1 [Strong Normalization] A term t is strongly normalizing with bound number n' < n (i.e. all reduction sequences starting from t have length at most
A term t is strongly normalizing, written SN0(t), if there is some n such that
SNn(t).
SNn(t) is encoded using a dependent datatype with type constructor SN : (tm, int) →
prop and one term constructor of the same name:
SN : ∀t : tm.∀n : nat.(∀t' : tm.RED0(t, t') → ∃n' < n. SN(t', n')) → SN(t, n) We encode SN0(t) by defining SN0(t) ≡ ∃n : nat. SN(t, n). Strong normalization is closed under forward and backward reduction.
Lemma 4.2 If SNn(t) and t −→ t' then SNn' (t') for some n' < n.
Proof. This follows directly from the definition of SNn(t).	 
The ATS/LF proof for this lemma is given as follows:
prfn forwardSN {t:tm, t’:tm, n:nat}
(sn: SN(t, n), red: RED0(t, t’)) : [n’:nat | n’ < n] SN(t’, n’) = let prval SN (fsn) = sn in fsn red end
The keyword prval here is similar to the keyword val in ML.
Lemma 4.3 If for all t', t −→ t' implies SN0(t'), then SN0(t).
Proof. For any t there are a finite number of t' such that t −→ t'. For each of these t' we have SNn' (t') for some n'. If we take n to be one plus the maximum of
these n' (which exists because there are only finitely many) then we have SNn(t) so
SN0(t).	 
This is an obvious consequence of the definition of SN0 and the fact that each term has a finite number of different reducts, and formalizing it in ATS/LF is entirely

uninspiring (as the argument is purely set-theoretic). So we use the keyword dynprf
to introduce it as an unproven lemma:
dynprf backwardSN : {t:tm} ({t’:tm} RED0 (t, t’) -> SN0 t’) -> SN0 t
This is the only unproven lemma in the entire formalization.
Attempting to directly prove strong normalization of well-typed terms by induc- tion on typing derivations does not work because the induction hypothesis is not strong enough to handle application terms. In order to make the proof go through, we strengthen the induction hypothesis using the notion of reducibility, introduced by Tait [12].

Definition 4.4 [Reducibility] A lambda-term t is reducible at a type τ , written
Rτ (t), if:
τ is a base type (that is, B in our case) and SN0(t), or
τ is τ1 → τ2 and for all t', Rτ1 (t') implies Rτ2 (t t').
It should be emphasized that Rτ (t) does not necessarily imply that t can be assigned
the type τ . As a matter of fact, we have RB(ω) for ω = λx.xx according to the definition. Also, it is clear that we cannot have RB→B(ω) as it would otherwise imply RB(ωω), which is a contradiction since ωω is not normalizing.
The definition in ATS/LF uses a dependent datatype with type constructor
R : (tm, tp) → prop and two term constructors: Rbas : ∀t : tm. SN0 t → R(t, TPbas) Rfun : ∀t : tm.∀T1 : tp.∀T2 : tp.
(∀t1 : tm.R(t1, T1) → R(TMapp(t, t1), T2)) → R(t, TPfun(T1, T2))
This is not a positive datatype because there is a negative occurrence of R in the
function case. However, this definition is still well-founded because the tp index is structurally decreasing in all recursive occurrences (both positive and negative).
This allows us to view the datatype as being built up inductively in levels stratified by the tp index. In particular, this means that when we are building the level corresponding to TPfun(T1, T2), the levels corresponding to T1 and T2 are already complete and thus the set of functions from level T1 to level T2 (which are the possible arguments of Rfun) is also complete.
We begin by proving some important properties of the reducibility predicate.
We first define neutral terms as follows.

Definition 4.5 [Neutrality] A term is neutral if it is either the constant c or an application of the form t t'.
This is defined in ATS/LF as a dependent datatype with type constructor NEU :
tm → prop and term constructors:
NEUcst : NEU(TMcst)	NEUapp : ∀t : tm.∀t′ : tm. NEU(TMapp(t, t′))

We can now state and prove four important properties of reducibility, which are given the names CR 1-4 in [7]:
CR 1: If Rτ (t) then SN0(t),
CR 2: If Rτ (t) and t −→ t' then Rτ (t'),
CR 3: If t is neutral and for all t', t −→ t' implies Rτ (t'), then Rτ (t), and
CR 4: Rτ (c) for any τ , which is a special case of CR 3.
We first prove CR 2 on its own, and then prove CR 1, 3 and 4 simultaneously.
Lemma 4.6 (CR 2) Proof. By induction on τ :
case: τ = B, so we have SN0(t). By closure of strong normalization under forward reduction (Lemma 4.2) we have SN0(t'), so RB(t').
case: τ = τ1 → τ2, so for all t1, Rτ1 (t1) implies Rτ2 (t t1). Fix any t1 such that Rτ1 (t1), then we have Rτ2 (t t1) and since t t1 −→ t' t1, by induction hypothesis, we have Rτ2 (t' t1). Therefore Rτ1→τ2 (t').

The proof is encoded in ATS/LF as follows:
prfun cr2 {t:tm, t’:tm, T:tp, n:nat} .<n>.
(tp: TP (T, n), r: R(t, T), rd : RED0(t, t’)): R(t’, T) =
case* r of // [case*] indicates exhaustive pattern matching
| Rbas (sn) => Rbas (forwardSN (sn, rd))
| Rfun{_, T1, _} (fr) => let prval TPfun (_, tp2) = tp
in
Rfun(lam {t1:tm} (r:R(t1,T1)) => cr2(tp2, fr r, REDapp1 rd))
end
This proof function is a fairly straightforward encoding of the argument, taking the extra argument of type TP(T, n) to provide a termination metric. The proof has a slightly unusual feature: the Rfun case binds the static argument T1 in order to be able to provide the type for the lambda-bound variable r.
Lemma 4.7 (CR 1, 3, 4)
Proof. We prove CR 1, CR 3, CR 4, in that order, by induction on τ . The argument for CR 3 makes use of a nested induction, and CR 4 follows directly from CR 3 at each level.
case: τ = B. Reducibility at base types is just strong normalization.
CR 1: Direct from the definition of RB(·).
CR 3: By Lemma 4.3.
case: τ = τ1 → τ2.
CR 1: Let t be a term with Rτ1 →τ2 (t). By CR 4 induction hypothesis, Rτ1 (c),

therefore Rτ2 (t c). By CR 1 induction hypothesis t c is SN and any reduction of t induces a reduction of t c, so t is SN.
CR 3: Let t be neutral such that for all t' with t −→ t' we have Rτ1 →τ2 (t'). Let
t1 be a term such that Rτ1 (t1), we need to show Rτ2 (t t1). By CR 1 induction
hypothesis we know SNn(t1) for some n and we continue by nested induction on
n. t t1 is neutral, so if we show that all terms that it reduces to are reducible, then we can use CR 1 induction hypothesis to conclude Rτ2 (t t1). Suppose
t t1 −→ t2:
case: t2 = t' t1, with t −→ t'. We know Rτ1 →τ2 (t') and Rτ1 (t1), so we have
Rτ2 (t' t1).
case: t2 = t t' with t1 −→ t' . By CR 2 induction hypothesis Rτ1 (t' ), and by
1	1	1
Lemma 4.2, SNn' (t' ) for some n' < n, so by induction Rτ2 (t t' ).
1	1
These are the only possibilities because t is neutral.


The full ATS/LF proof of this is omitted for brevity; it consists of 4 mutually recursive proof functions:
cr1 : ∀t : tm.∀T : tp.∀n : nat. (TP(T, n), R(t, T )) → SN0(t)
cr3 : ∀t : tm.∀T : tp.∀n : nat. (NEU(t), TP(T, n), ∀t′. RED0(t, t′) → R(t′,T )) → R(t, T )
cr3a : ∀t : tm.∀t1 : tm.∀T1 : tp.∀T2 : tp.∀m : nat.∀n1 : nat.∀n2 : nat.
(TP(T1, n1), TP(T2, n2), NEU(t), R(t1, T1), SN(t1, m),
∀t′. RED0(t, t′) → R(t′, TPfun(T1, T2))) → R(TMapp(t, t1),T 2)
cr4 : ∀T : tp.∀n : nat. TP(T, n) → R(TMcst,T )
Each of these functions takes arguments of the form TP(T, n) in order to provide
a metric that corresponds to structural recursion on T . The auxiliary lemma cr3a performs the inner induction on the length of the strong normalization bound of t1, which is provided by its argument of type SN(t1, m).
Lemma 4.8 If for all reducible t at type τ1, Rτ2 (t1[t/x]), then Rτ1→τ2 (λx.t1).

Proof. Assume Rτ1 (t). By CR 1, we know there is n1 such that SNn1 (t1[c/x]) (and therefore SNn1 (t1)) and n2 such that SNn2 (t). We now proceed by induction on
n1 + n2 to prove that Rτ2 ((λx.t1) t). We will show that (λx.t1) t −→ t' implies
Rτ2 (t') for every t'. There are three possibilities.
(λx.t1) t reduces to t1[t/x], which is reducible by the hypothesis of the lemma.
(λx.t1) t reduces to (λx.t1) t' with t −→ t'. By CR 2, Rτ1 (t') and by Lemma 4.2 there is n' < n with SNn' (t'), and thus we have Rτ2 ((λx.t1) t') by induction.
(λx.t1) t reduces to (λx.t' ) t with t1 −→ t' . By CR 2, t' [t/x] is reducible for any
1	1	1
reducible t and the strong normalization bound of (λx.t' ) is less than (λx.t1). So
(λx.t' ) t is reducible by induction.
Note that (λx.t1) t is neutral. By CR 3, we have Rτ2 ((λx.t1) t). Since Rτ2 ((λx.t1) t) holds for every t satisfying Rτ1 (t), we have Rτ1 →τ2 (λx.t1) by definition.	 

The formalization of this proof in ATS/LF is a total recursive function with the type:
absSound : ∀f : tm → tm.∀T1 : tp.∀T2 : tp.
(TP0(T1), TP0(T2), ∀t : tm.R(t, T1) → R(f t, T2)) →
R(TMlam f, TPfun(T1, T2))
The proof closely follows the informal one given above, taking additonal arguments of types TP0(T1) and TP0(T2), which are needed in calls to cr2 and cr3. It also makes a call to the proof function reduceFun to perform the inner induction on the sum of the normalization bounds (n1 + n2 in the informal proof).
t, with a typing Γ ▶ t : T and a substitution Θ such that for x ∈ dom(Γ), Θ(x) is Now we can prove the main reducibility lemma which states that, given a term reducible at type Γ(x), then t[Θ], the result of applying Θ to t, is reducible at type
T .

Lemma 4.9 Let t be a term with x1 : τ1,... , xn : τn ▶ t : τ. If t1,... , tn are terms such that Rτi (ti) (for 1 ≤ i ≤ n) then Rτ (t[t1/x1,... , tn/xn]).
Proof. By induction on the derivation of x1 : τ1,... , xn : τn ▶ t : τ . We write t[t/x] for t[t1/x1,... , tn/xn].
t = xi: Then t[t/x]= ti and τ = τi and by hypothesis Rτi (ti).
t = t' t'': Then, by induction hypothesis, Rτ'→τ (t'[t/x]) and Rτ' (t''[t/x]). By the definition of Rτ ((t'[t/x]) (t''[t/x])) and (t'[t/x]) (t''[t/x]) = (t' t'')[t/x].
is of the form τ '' → τ '. Fix t'' such that Rτ'' (t''). By induction hypothesis, t = λx.t': (assume x is fresh with respect to x1,... , xn and t1,... , tn) Then τ Rτ' (t'[t/x, t''/x]). By Lemma 4.8, Rτ''→τ ' (λx.t'[t/x]), and by the freshness of x,
(λx.t'[t/x]) = (λx.t')[t/x].

When we prove this lemma in ATS/LF, the higher-order encoding buys us quite a bit over a first-order encoding. Because of HOAS, we do not have to think about freshness of variables nor do we have to explicitly prove that the substitution com- mutes with the lambda binding when handling the lambda case. Lemma 4.9 is encoded in ATS/LF as a total function, which we omit for brevity:
reduceLemma : ∀G : ctx.∀t : tm.∀T : tp.∀n : nat. (DER(G, t, T, n), RS0(G)) → R(t, T ) Note that RS0(G) is a datatype that associates with each (ti, Ti) in G, a proof of the reducibility predicate R(ti, Ti). Also note that we take advantage of the
representation of contexts as typed substitutions to state the lemma. It is now a simple matter to prove strong normalization for closed terms using Lemma 4.9 and CR 1.
normalize : ∀t : tm.∀T : tp. DER0(CTXnil, t,T ) → SN0(t)
It is easy to see that this implies strong normalization for terms containing free
variables as well, because any reduction on a term with free variables corresponds to a reduction in the closed term formed by abstracting these variables.

Strong Normalization for System F
We have also formalized a proof of strong normalization for (the Curry-style version of) System F, which can be found on-line:
http://www.cs.bu.edu/∼hwxi/ATS/EXAMPLE/LF/F-SN-hoas.dats
The terms and reduction rules for the language are the same as for STLC. The types of System F are given by:
τ ::= α | τ1 → τ2 | ∀α.τ
The types are encoded with a first-order representation using de Bruijn indices:
TPvar : int → tp	TPfun : (tp, tp) → tp	TPall : tp → tp
This representation means that we have to spend a great deal of effort proving
lemmas about renumbering and substitution. However, we do not know if it is possible to prove strong normalization using a higher-order representation for types.
We extend the type well-formedness judgment ▶ τ type to include a context: Δ ▶ τ type, and list the new rules as follows:

  α ∈ Δ	 (TPvar)	Δ ▶ τ1 type  Δ ▶ τ2 type (TPfun)	Δ,α ▶ τ type
(TPall)

Δ ▶ α type
Δ ▶ τ1 → τ2 type
Δ ▶ ∀α. τ type

Typing judgments are extended to include the extra context and there are also two
additional typing rules for handing type abstraction and application:

Δ, α;Γ ▶ t : τ
Δ; Γ ▶ t : ∀α.τ
Δ; Γ ▶ t : ∀α.τ	Δ ▶ τ1 type
(DERtabs)	(DERtapp)
Δ; Γ ▶ t : τ [τ1/α]

where DERtabs has the side condition that α is not free in Γ.
The approach of directly defining reducibility does not work for System F be- cause we cannot make the argument that the datatype representing reducibility is inductive on the tp index. For this reason we need to generalize to reducibility
code predicates as static terms of sort tm → prop (we define rc ≡ tm → prop for candidates which are all the predicates satisfying CR 1, CR 2 and CR 3. We en- convenience) and we define propositions:
CR1(R) ≡ ∀t : tm. R(t) → SN0(t)
CR2(R) ≡ ∀t : tm.∀t' : tm. (R(t), RED0(t, t')) → R(t')
CR3(R) ≡ ∀t : tm. (NEU(t), ∀t' : tm.RED0(t, t') → R(t')) → R(t)
RC(R)  ≡ (CR1(R), CR2(R), CR3(R))
Strong normalization (SN0) is defined just as before. It is straightforward to show
that SN0 meets the three conditions:
sn is rc : RC(SN0)
As a consequence of CR3, any reducibility candidate holds for the constant:
cr cst : ∀R : rc. RC(R) → R(TMcst)
The crux of the reducibility candidates is to define interpretations for types as
reducibility candidates and to show that whenever a term t can be given a type τ , it is in the reducibility candidate that interprets τ . The fact that a term is strongly

normalizing if it is in a reducibility candidate gives us the final result.
In order to interpret types as candidates, we define the arrow and universal quantification constructors for reducibility candidates:
RCFUN0(R1, R2)(t) ≡ ∀t1 : tm. R1(t1) → R2(TMapp(t, t1))
RCALL0(RF )(t) ≡ ∀R : rc. RC(R) → (RF (R))(t)
And we prove that these constructors preserve candidates:
rcfun is rc : ∀R1 : rc.∀R2 : rc. (RC(R1), RC(R2)) → RC(RCFUN0(R1, R2))
rcall is rc : ∀RF : rc → rc. (∀R : rc.RC(R) → RC(RF (R))) → RC(RCALL0(RF ))
It is an important property that the typing rule for lambda is sound with respect
to the arrow on candidates:
abs lemma : ∀R1 : rc.∀R2 : rc.∀f : tm → tm.
(RC(R1), RC(R2), ∀t : tm. R1(t) → R2(f t)) → RCFUN0(R1, R2)(TMlamf )
To provide a context for parameters in reducibility candidates, we define the sort
rcs for lists of reducibility candidates:
RCSnil : rcs	RCScons : (rc, rcs) → rcs
with type constructor RCSI : (rcs, rc, int) → prop and term constructors: In order to lookup parameters in the list we use a datatype (similar to INCTX)
RCSIone : ∀R : rc.∀C : rcs. RCSI(RCScons(R, C), R, 0)
RCSIshi : ∀R : rc.∀R′ : rc.∀C : rcs.∀n : nat.
RCSI(C, R, n) → RCSI(RCScons(R′,C), R,n + 1)
tor DER : (rcs, ctx, tm, tp, int) → prop. Only the length of the rcs term matters in We actually use rcs to represent Δ in typing derivations, which have type construc- derivations (the actual predicates in the list are not reflected in the dynamic rep-
resentation), and derivations with an empty Γ and any Δ are adequately encoded. The use of rcs in DER (rather than simply a natural number bound on the indices) makes some of the lemmas easier to state.
Next, we define the interpretation of types as reducibility candidates with pa-
(rcs,  tp,  rc,  int)   →   prop,   and   term   constructors: rameters.  For this, we use a dependent datatype with type constructor TPI :
TPIvar : ∀C : rcs.∀T : tp.∀R : rc.∀n : nat. RCSI(C, R, n) → TPI(C, TPvar n, R, 0)
TPIfun : ∀C : rcs.∀T1 : tp.∀T2 : tp.∀R1 : rc.∀R2 : rc.∀n1 : nat.∀n2 : nat.
(TPI(C, T1, R1, n1), TPI(C, T2, R2, n2)) →
TPI(C, TPfun(T1, T2), RCFUN0(R1, R2), n1 + n2 + 1)
TPIall : ∀C : rcs.∀T : tp.∀RF : rc → rc.∀n : nat.
(∀R : rc.TPI(RCScons(R, C),T, RF (R), n)) →
TPI(C, TPall(T ), RCALL0(RF ),n + 1)
For convenience we define TPI0(C, T, R) ≡ ∃n : nat.TPI(C, T, R, n). In order to prove that the interpretation of a type is a reducibility candidate if all the free
(rcs, int) → prop such that RCS(C, n) is a sequence of proofs of RC(R) for each R variables are interpreted by reducibility candidates, we introduce a datatype RCS :

in C. We can then prove the desired lemma:
tpi is rc : ∀C : rcs.∀T : tp.∀R : rc.∀n : nat. (RCS0 C, TPI(C, T, R, n)) → RC(R)
where RCS0(C) ≡ ∃n : nat.RCS(C, n).
The last major lemma we need is a substitution lemma on interpretations of
types, which we omit for brevity. In order to state the main lemma, we need to define an environment mapping terms to proofs showing that the terms in the
appropriate candidates. For this we use the datatype ETA : (rcs, ctx, int) → prop
where ETA(C, G, m) is a sequence of pairs of (TPI0(C, T, R), R(t)) for each (t, T )
in G. The main lemma is:
der rc lemma : ∀G : ctx.∀t : tm.∀T : tp.∀n : nat.∀C : rcs.∀m : nat.
(DER(C, G, t, T, n), ETA(C, G, m), RCS0 C) →
∃R : rc. (TPI0(C, T, R), R(t))
The proof of this lemma is quite involved, mostly due to manipulations of de Bruijn
indices. The final theorem is then easy to prove:
der sn : ∀t : tm.∀T : tp.DER0(RCSnil, CTXnil, t,T ) → SN0(t)
This simply means that every well-typed expression in System F is strongly nor-
malizing.



Related Work

There have been several formalizations of proofs of normalization for STLC in the past. Abel [1] encodes a proof of weak normalization for STLC in Twelf. As in our proof, the object language is represented using HOAS. However, normaliza- tion is proved using an inductive characterization of the weakly normalizing terms, following Joachimski and Matthes [8], rather than Tait’s method of reducibility predicates. Sarnat and Schu¨rmann [11] have recently given a proof of weak normal- ization directly in Twelf using a logical relation. They encode minimal first-order logic which is then used in the definition of the logical relation. It is not clear whether their technique would allow a similar encoding of strong normalization. Berger, Berghofer, Letouzy and Schwichtenberg [3] give proofs of strong normal- ization for STLC using Tait’s method in three systems: Isabelle/HOL, Coq, and Minilog. They also analyze the programs that can be extracted from the formal proofs. However, the formalizations described all make use of first-order represen- tations (using either de Bruijn indices or names for variables) rather than HOAS and also start from a large number of unproven axioms (eleven).
Strong normalization for System F has previously been formalized by Altenkirch [2] using the Lego system. His formalization uses the de Bruijn encoding for both terms and types, and because of this, is significantly longer and more complicated than our proof. Even though our formalization contains full proof terms, rather than tactic-based scripts, it is shorter by about a factor of two.

Conclusion
We have presented formalizations of proofs of strong normalization for STLC and System F which use HOAS and Tait’s and Girard’s methods (respectively). The unique features of ATS/LF (in particular the separation between statics and dynam- ics) allow for the encoding of powerful logical relations arguments over the simple and elegant language encodings enabled by HOAS. In these proofs we found that HOAS made it much easier to deal with the mundane details of naming and sub- stitution, which often take the majority of the effort in first-order encoding. 4 As a result, we are able to define the syntax and semantics of STLC and prove strong normalization as described, all in less than 300 lines of commented ATS/LF code! For System F, the proof is likewise short, under 900 lines.

References
Abel, A., Weak normalization for the simply-typed lambda-calculus in Twelf, in: Logical Frameworks and Metalanguages (LFM 04), IJCAR, Cork, Ireland, 2004.
Altenkirch, T., A Formalization of the Strong Normalization Proof for System F in LEGO, in:
M. Bezem and J. F. Groote, editors, Proceedings of the International Conference on Typed Lambda Calculi and Applications (1993), pp. 13–28.
Berger, U., S. Berghofer, P. Letouzey and H. Schwichtenberg, Program extraction from normalization proofs, Studia Logica (2005), special issue, to appear.
Chen, C. and H. Xi, Combining Programming with Theorem Proving, in: Proceedings of the Tenth ACM SIGPLAN International Conference on Functional Programming, Tallinn, Estonia, 2005, pp. 66–77.
Donnelly, K. and H. Xi, Combining higher-order abstract syntax with first-order abstract syntax in ATS, in: MERLIN ’05: Proceedings of the 3rd ACM SIGPLAN workshop on Mechanized reasoning about languages with variable binding (2005), pp. 58–63.
Girard, J.-Y., Une Extension de l’Interpr´etation de Go¨del a` l’Analyse, et son Application a`
l’E´limination des Coupures dans l’Analyse et la Th´eorie des Types, in: J. E. Fenstad, editor, Proceedings of the Second Scandinavian Logic Symposium, Studies in Logic and the Foundations of Mathematics 63 (1971), pp. 63–92.
Girard, J.-Y., Y. Lafont and P. Taylor, “Proofs and Types,” Cambridge Tracts in Theoretical Computer Science 7, Cambridge University Press, Cambridge, England, 1989, xi+176 pp.
Joachimski, F. and R. Matthes, Short proofs of normalization for the simply-typed lambda-calculus, permutative conversions and Go¨del’s T, Arch. Math. Log. 42 (2003), pp. 59–87.
Pfenning, F. and C. Elliott, Higher-order abstract syntax, in: Proceedings of the ACM SIGPLAN ’88 Symposium on Language Design and Implementation, Atlanta, Georgia, 1988, pp. 199–208.
Pfenning, F. and C. Schu¨rmann, System description: Twelf - a meta-logical framework for deductive systems, in: H. Ganzinger, editor, Proceedings of the 16th International Conference on Automated Deduction (CADE-16) (1999), pp. 202–206.
Sarnat, J. and C. Schu¨rmann, On the Representation of Logical Relations, Yale University Technical Report, YaleU/DCS/TR1362 (2006).
Tait, W. W., Intensional Interpretations of Functionals of Finite Type I, Journal of Symbolic Logic 32
(1967), pp. 198–212.

4 Actually, we have also formalized a strong normalization proof of STLC that uses FOAS to represent lambda-terms:
http://www.cs.bu.edu/∼  hwxi/ATS/EXAMPLE/LF/STLC-SN-foas.dats
There are several unproven lemmas in this formalization, which can certainly be finished but require some effort on handling substitution that is uninspiring and tedious.

Xi, H., Dependent Types for Program Termination Verification, Journal of Higher-Order and Symbolic Computation 15 (2002), pp. 91–132.

Xi, H., Dependently Typed Pattern Matching, Journal of Universal Computer Science 9 (2003), pp. 851– 872.
Xi, H., Applied Type System (2005), available at:
http://www.cs.bu.edu/∼ hwxi/ATS .

A	Appendix: ATS/LF proof of final lemmas and theo- rem
...
// application reducibility lemma prfun reduceFun
{f:tm->tm, t:tm, T1:tp, T2:tp, n1:nat, n2:nat} .<n1+n2>. (tp1: TP0 T1, tp2: TP0 T2,
sn1: SN(TMlam f, n1), sn2:SN(t, n2), r1:R(t, T1),
fr2: {t:tm} R(t, T1) -> R(f t, T2)): R(TMapp(TMlam f, t), T2) = let
prval r1’ = fr2 r1
prfn fr {t’:tm} (red:RED0(TMapp(TMlam f, t), t’)) : R(t’, T2) = case* red of
| REDapp1(red’) => let
prval REDlam {f, f’,_} fred’ = red’
prfn fr2’ {t:tm} (r: R(t, T1)): R(f’ t, T2) = cr2(tp2, fr2 r, fred’{t})
in
reduceFun(tp1, tp2, forwardSN(sn1, red’), sn2, r1, fr2’)
end
| REDapp2(red’) =>
reduceFun(tp1, tp2, sn1, forwardSN(sn2, red’), cr2(tp1, r1, red’), fr2)
| REDapp3() => r1’
in
cr3(NEUapp, tp2, fr)
end
// the abstraction rule is sound with respect to redicible terms prfn absSound {f:tm->tm, T1:tp, T2:tp}
(tp1: TP0 T1, tp2: TP0 T2,
frr : {t:tm} R(t, T1) -> R(f t, T2)) : R(TMlam f, TPfun(T1, T2)) = let
prfn fr {t:tm} (rt: R(t, T1)) : R(TMapp(TMlam f, t), T2) = let
prval snt = cr1(tp1, rt)
prval snf = lamSN(cr1 (tp2, frr {TMcst} (cr4 tp1)))
in
reduceFun (tp1, tp2, snf, snt, rt, frr)
end
in
Rfun(fr)
end
// pick specified reducibility predicate from the sequence prfun rGet {t:tm, T:tp, G:ctx, n:nat} .<n>.
(i:INCTX(t,T,G,n),rs: RS0(G)) : R(t,T) = case* i of
| INCTXone() => (case* rs of RScons(r,_) => r)

| INCTXshi i => (case* rs of RScons(_,rs) => rGet(i, rs))
// The assigned type can be extracted from a derivation
prfun der2tp {G:ctx, t:tm, T:tp, n:nat} .<n>. (der: DER(G,t,T,n)): TP0 T = case* der of
| DERvar (_, tp) => tp
| DERlam (tp1, derf) => let prval tp2 = der2tp derf in TPfun (tp1,tp2) end
| DERapp (der1, der2) => let prval TPfun (_, tp2) = der2tp der1 in tp2 end
// main lemma
prfun reduceLemma {G:ctx, t:tm, T:tp, n:nat} .<n>. (der: DER(G,t,T,n), rs: RS0 G): R (t, T) =
case* der of
| DERvar (i,_) => rGet (i, rs)
| DERlam {_,f,T1,T2,_} (_, derf) => let
prval TPfun{T1, T2, s1, s2} (tp1, tp2) = der2tp der prfn gr {t:tm} (r: R(t,T1)): R(f t, T2) = let
prval rs’ = RScons (r, rs)
prval r’ = reduceLemma (derf{t}, rs’) in
r’ end
prfn fr {t:tm} (r: R(t,T1))
: R(TMapp(TMlam f, t), T2) = let
prval lamf_red = absSound(tp1, tp2, gr) prval Rfun(red_imp) = lamf_red
in
red_imp r end
in
Rfun fr
end
| DERapp (der1, der2) => let
prval r1 = reduceLemma(der1, rs) prval Rfun fr = r1
prval r2 = reduceLemma(der2, rs)
in
fr r2
end
// all typable terms are reducible
prfn reduce {t:tm, T:tp} (der: DER0 (CTXnil,t,T)): R (t,T) = reduceLemma(der, RSnil())
// the final theorem
prfn normalize {t:tm, T:tp} (der: DER0 (CTXnil,t,T)): SN0 t = cr1(der2tp der, reduce der)
