Electronic Notes in Theoretical Computer Science 206 (2008) 75–90	
www.elsevier.com/locate/entcs

Comparing CSP and SAT Solvers for Polynomial Constraints in Termination Provers
Salvador Lucas and Rafael Navarro-Marset 1,2
Departamento de Sistemas Informa´ticos y Computacio´n Universidad Polit´ecnica de Valencia
Valencia, Spain

Abstract
Proofs of termination in term rewriting involve solving constraints between terms coming from (parts of) the rules of the term rewriting system. A common way to deal with such constraints in termination tools is treating them as polynomial constraints. Several recent works develop connections between these problems and more standard constraint solving problems for which well-known and efficient techniques apply. In particular, SAT techniques are receiving increasing attention in the field. The main idea is encoding polynomial constraints as propositional constraints which can (hopefully) be efficiently managed by using state-of-the-art SAT solvers. We have recently developed an algorithm for solving constraints in finite (small) domains of coefficients which are appropriate for termination tools. This algorithm benefits from the use of a specialized representation of the elements in the domain and the corresponding polynomials which permits using efficient arithmetics and constraint propagation techniques. In this paper we discuss these approaches, compare them from an experimental point of view, and point to possible improvements.
Keywords: Polynomial interpretations, term rewriting, program analysis, termination.

Introduction
Proofs of termination in term rewriting involve solving constraints between terms s and t coming from (parts of) the rules of the Term Rewriting System (TRS [18,20]). For instance, in proofs of termination using the dependency pairs approach [2], given a rewrite rule l  r of a TRS  , we get dependency pairs l   s for all subterms s of r which are rooted by a defined symbol 3 ; the notation t for a given term t means that the root symbol f of t is marked thus becoming f (often just capitalized: F ).

1 This work has been partially supported by the EU (FEDER) and the Spanish MEC, under grants TIN 2004-7943-C04-02 and HA 2006-0007, and the Generalitat Valenciana under grant GV06/285. Rafael Navarro-Marset was partially supported by the Spanish MEC under FPU grant AP2006-026.
2 Email: {slucas,rnavarro}@dsic.upv.es
3 A symbol f is said to be defined in a TRS R if R contains a rule f (l1,..., lk) → r.

1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.03.076

Example 1.1 Consider the following TRS R from [2, Example 1]:
minus(x,0) -> x
minus(s(x),s(y)) -> minus(x,y)
quot(0,s(y)) -> 0
quot(s(x),s(y)) -> s(quot(minus(x,y),s(y)))
This TRS contains three dependency pairs:
MINUS(s(x),s(y)) -> MINUS(x,y)
QUOT(s(x),s(y)) -> QUOT(minus(x,y),s(y))
QUOT(s(x),s(y)) -> MINUS(x,y)

The dependency pairs conform a new TRS DP( ) which (together with ) deter- mines the so-called dependency chains. The absence of infinite dependency chains characterize termination of . The dependency pairs can be presented as a depen- dency graph (DG), where the absence of infinite chains can be analyzed by consid- ering the cycles in the graph.

Example 1.2 Consider the TRS R in Example 1.1. There are two cycles in the dependency graph: {5} and {6}.

Basically, given a cycle in the dependency graph, we require l  r for all rules in the TRS  , u  v for all dependency pairs in C and u > v for at least one dependency pair u  v  C. Here,  is a quasi-ordering on terms and > is a well-founded ordering.

Example 1.3 Consider the TRS  in Example 1.1 and the cycle C = 6 (see Example 1.2): QUOT(s(x),s(y)) -> QUOT(minus(x,y),s(y)). In order to prove termination of we have to find a reduction pair ( , >) which satisfies the following constraints:

minus(x,0) ≥ x minus(s(x),s(y)) ≥ minus(x,y)
quot(0,s(y)) ≥ 0
quot(s(x),s(y)) ≥ s(quot(minus(x,y),s(y)))
QUOT(s(x),s(y)) > QUOT(minus(x,y),s(y))

Many termination tools (AProVE [7], CiME 2.02 [3], mu-term [1,14], TTT [11],...) use polynomials as a principal ingredient to achieve termination proofs. In this setting, each k-ary symbol f ∈ F is given a parametric polynomial [f ] like, e.g., akxk + ··· + a1x1 + a0.

Example 1.4 Consider the constraints in Example 1.3. The following (parametric)

polynomials are given to the symbols:


[0] = a0 [s](X) = s1X + s0
[minus](X, Y ) = m1X + m2Y + m0 [quot](X, Y ) = q1X + q2Y + q0 [QUOT](X, Y ) = q1' X + q2' Y + q0'

Constraints s  t and s > t are treated as polynomial constraints Ps,t  0 and Ps,t > 0, respectively, where Ps,t = [s] [t] is the polynomial obtained from terms s and t by interpreting them as polynomials [s] and [t], see [4,15] for further details.

Example 1.5 The first constraint in Example 1.3 is translated into the polynomial constraint:
(m1 − 1)x + m2a0 + m0 ≥ 0

Variables in terms s and t (e.g., x in the first constraint in Example 1.3) become universally quantified numeric variables in polynomial constraints Ps,t   0 (e.g., x in Example 1.5). In contrast, the parametric coefficients become existentially quantiﬁed variables (e.g., a0, m0, m1, and m2 in Example 1.5). The use of non- negative numbers as interpretation domains and well-known positiveness criteria like Hong and Jakuˇs’ [12] allows us to center the attention on solving existential constraints where all variables correspond to parametric coefficients.

Example 1.6 According to [4,15] and also [12], we have to solve the following (conjuntion of) polynomial constraints:


a0m2 + m0 ≥ 0
m1 − 1 ≥ 0
m1s0 + m2s0 ≥ 0
m1s1 − m1 ≥ 0
m2s1 − m2 ≥ 0
a0q1 + q2s0 + q0 − a0 ≥ 0
q2s1 ≥ 0


q1s0 + q2s0 + q0 − m0q1s1 − q2s0s1 − q0s1 − s0 ≥ 0
q1s1 − m1q1s1 ≥ 0
q2s1 − m2q1s1 − q2s1s1 ≥ 0
q1' s0 − m0q1' > 0
q1' s1 − m1q1' ≥ 0
−m2q1' ≥ 0
Note that the variables which have to be solved here are the coefficients of the parametric polynomials in Example 1.4. The previous set of constraints is sound regarding DG-based termination proofs (i.e., its satisfaction implies that the cycle is harmless) provided that all such variables/parametric coefficients take non-negative values, see [4,15] for a justification of this claim.
Now, the termination problem is just a standard constraint solving problem which can be treated by using standard algorithms and techniques.

Solving polynomial constraints in termination provers
Constraints like those showed in Example 1.6 are expected to be solved on a suit- able domain of coefficients because the intended meaning of the targetted variables is to serve as particular coefficients of parametric interpretations like in Example
1.4. In principle, such coefficients could be taken from any subset real algebraic
numbers 4 [16]. Rational, integer, and natural numbers are well-known examples of real algebraic numbers. In practice, all termination tools restrict (as default or unique option) the usable coefficients to small domains like  0, 1 ,  0, 1, 2 , or 0, 1 , 1, 2 . In [16] we have proposed an efficient algorithm for solving polynomial constraints over small domains of powers of 2. Note that the aforementioned small (and widely used) domains of coefficients are covered by the algorithm. The al- gorithm efficiently handles polynomial expressions involving numbers having quite
different arithmetical treatment: 0, 1, 2, 1 , √2, √1 , etc.

2	2
A recent paper by Fuhs et al. proposes the use of SAT techniques for solving polynomial constraints in termination provers [5]. Fuhs et al.’s (extensive) bench- marks show that, indeed, using D = 0, 1 as the domain for coefficients in poly- nomial interpretations is already a very powerful option in comparison to bigger
domains. The information in Table 1 has been taken from [5]. It corresponds to the benchmarks performed with the new version of AProVE which implements a SAT- based solver for polynomial constraints (AProVE-SAT). The termination problems come from the 2006 Termination Problem Data Base (TPDB, version 3.2) 5 . 865
examples were considered. Three different ranges for coefficients were considered,

4 A real number x ∈ R is said to be algebraic if it satisfies an equation xn + an−1xn−1 + ··· + a1x + a0 = 0, of finite degree n where ai ∈ Q for 0 ≤ i ≤ n − 1.
5 see http://www.lri.fr/~marche/tpdb/


Table 1
AProVE-SAT benchmarks
corresponding to N1 = {0, 1}, N2 = {0, 1, 2}, and N3 = {0, 1, 2, 3}.
Table 1 shows that AProVE-SAT increments the ratio of solved examples in 0, 7% when using coefficients from N2 instead of N1, but the time for achieving the proofs is duplicated!
Thus, specifically considering the (small) domain N1 to obtain an efficient solver on this particular domain still makes sense. We have addressed this task in different ways which we discuss in the remainder of the paper. Our research is motivated by the following questions:
Should termination tools use existing translations of polynomial constraints into propositional formulas and then a state-of-the-art SAT solver? Which one?
Is it better to treat them as true polynomial constraints using CSP-like tech- niques?
How to select the appropriate technique or tool? How (where) to put them into the sequence of techniques of an ‘expert’?
Solving polynomial constraints over small domains
We have developed an algorithm to solve existential polynomial constraints over ﬁnite subsets of appropriate real numbers [16]. The algorithm takes benefit from a suitable choice of domains for the coefficients and an appropriate representation of the polynomial constraints which permit both fast arithmetic and the use a number of techniques for safely avoiding a complete exploration of the search space.

Finite domains of powers of 2
The algorithm works for subsets D of rational numbers (actually powers of 2):
D ⊆ Dm = {0}∪ {±(2i) | i ∈ Z, 0 ≤ |i| ≤ m} for m ∈ N or square roots of powers
i	+
of 2: D ⊆ Dm = {0}∪ {±(22 ) | i ∈ Z, 0 ≤ |i| ≤ 2m}. We write Dm if we restrict
the attention to non-negative numbers.  In particular, D+ = {0, 2−1, 20, 21} =
0, 1 , 1, 2 includes the non-negative coefficients used (by default) in all currently available termination tools (nowadays, mu-term is the only tool which supports the use of rational coefficients like 1 = 2−1).
Restricting the attention to such kind of domains allows us reducing the costs of polynomial arithmetics, see [16] for details.

Polynomial constraints
We deal with constraints for polynomials P Z[X1,..., Xn], where X1,..., Xn are variables ranging on D. We actually deal with P under the form P = (V, M, N, K) for sets of variables V and polynomials M, N N[X1,..., Xn] and K Z, i.e., we represent P by considering the variables V appearing in P , the positive monomials m M on one side, the negative monomials n N , and the constant coefficient K (which can be positive, negative or null): P = M  N + K. Let Pol be the set of
polynomials as above.
Constraints are sets C  Pol  weak, strict of pairs (P, cond) where cond indicates how the (basic) constraint c = (P, cond) compares P to 0: in a weak (P ≥ 0) or strict (P > 0) way.
Example 2.1 The constraint (1) in Example 1.6 is represented as follows: (({a0, m2, m0}, {a0m2, m0}, ∅, 0), weak)
Let V ar(P )   X ,..., X  be the set of variables occurring in P and V ar(C) = 
 (P,cond)∈C V ar(P ) be the set of variables in C. A solution σ of C is a map- ping σ : V ar(C) → D such that (σ(P ), cond) holds for all (P, cond) ∈ C, i.e., P (σ(X1),..., σ(Xm)) ≥ 0 (resp. P (σ(X1),..., σ(Xm)) > 0) if cond = weak (resp. cond = strict) and V ar(P ) = {X1,..., Xm}.

Constraint propagation
The constraint solving algorithm makes extensive use of partial evaluation of poly- nomials P w.r.t. one of its variables for doing constraint propagation. For instance, given P (X1, X2,..., Xn) and d	D, we could need to obtain P1,d(X2,..., Xn) = P (d, X2,..., Xn).	This involves the partial evaluation of each monomial m =
cXα1 ··· Xαn  in P and the reconfiguration of the obtained polynomial as a tuple
(V, M, N, K).
An important aspect of the algorithm is performing frequent partial checkings of the constraints in order to cut the search space. This means that we are often able to conclude the truth or falsity of a basic constraint c = (P, cond) with variables without instantiating any variable in P . A (three valued) predicate checkCS per- forms this task. checkCS(c) returns either true if c is definitely true, or false if c is definitely false, or ?? otherwise. According to the representation P = (V, M, N, K), and since we use domains D of non-negative numbers, we have the following cases (here expressed in logical form for saving space):
M ≡ 0 ∧ K < 0 ⇒ P /≥ 0 ∧ P /> 0.
N ≡ 0 ∧ K > 0 ⇒ P ≥ 0 ∧ P > 0.
N ≡ 0 ∧ K = 0 ⇒ P ≥ 0.
M ≡ 0 ∧ K = 0 ⇒ P /> 0.
here M ≡ 0 means that M is identically null.

Example 2.2 By using rule iii above we can remove (or definitely replace by True) constraints (1), (3), and (7) in Example 1.6.
Let β be the maximum element of D. Then, for all x1,..., xn ∈ D,
K − N (β, ..., β) ≤ P (x1,..., xn), and
P (x1,..., xn) ≤ M (β, ..., β)+ K
This leads to the following:
M (β, ..., β)+ K < 0 ⇒ P /≥ 0 ∧ P /> 0.
K − N (β, ..., β) > 0 ⇒ P ≥ 0 ∧ P > 0.
K − N (β, ..., β) ≥ 0 ⇒ P ≥ 0.
M (β, ..., β)+ K = 0 ⇒ P /> 0.
In particular, if β = 1 = 20, then we can easily compute M (β, ..., β) + K and K N (β, ..., β)+K by just adding the coefficients of the corresponding monomials, and then adding (or substracting from) the constant K.

The algorithm
We describe our algorithm by means of two mutually recursive functions solveCS
and solveCSvar. The initial call is solveCS(D, [], [], C).
solveCS(D, V, pSol, C) performs an initial checking of all basic constraints (P, cond) in the constraint C by using checkCS. If all constraints are true, then a singleton containing a pair (V, pSol) consisting of the list of previously visited variables V and the list pSol of partial solutions for these variables is returned. A partial solution is just a list d1,..., dk of values which correspond to the current list of visited variables x1,..., xk, i.e., xi  di will be a binding of the final solution of the constraint. When the final solution is returned, vari- ables x which were not instantiated receive a binding x '→ d for an arbitrary d ∈ D (typically x '→ 0).
solveCSvar(D, V, pSol, C) tries values d D on a variable xi occurring in a constraint c = (P, cond) in C. The instantiation of xi with a value d yields a new constraint ci,d = (Pi,d, cond) consisting of the partial evaluation Pi,d of P with d on the variable xi and the same condition cond. The constraint ci,d is checked by using checkCS and if the inconsistency of ci,d is shown, then d is discarded as a possible value for solving c on xi. Otherwise, the variable xi is recorded as ‘visited’ and the value d which permits to make progress is registered in the list of tuples which are partial solutions. Also, each constraint in C  c is partially evaluated w.r.t. xi and d as above and a new problem Ci,d is raised. If ci,d is found true, then the constraint solving process continues with Ci,d. If nothing can be said about ci,d, then the constraint solving process continues with {ci,d}∪ Ci,d.
The complete description of the two functions is in Figure 1.




solveCSvar(D, V, pSol, {c}∪ C)
if CDP ol = CDfail then ∅
else  (c,d)∈CDunknown solveCS(D, xi : V, d : pSol, {c}∪ C(d))
∪  (c,d)∈CDtrue solveCS(D, xi : V, d : pSol, C(d))
where
(P, cond) = c
(X ∪ {xi}, _, _, _) = P
CDP ol = {((pEval(P, i, d), cond), d) | d ∈ D}
CDfail = {(c, _) ∈ CDP ol | checkCS(c) = false} CDtrue = {(c, _) ∈ CDP ol | checkCS(c) = true} CDunknown = {(c, d) ∈ CDP ol | checkCS(c) =??} C(d) = {pEvalCS(c, xi, d) | c ∈ C}




solveCS(D, V, pSol, C)
if Cfail /= ∅ then ∅
else if CnoT rue = ∅ then {(V, pSol)}
else solveCSvar(D, V, pSol, C')
where
CnoT rue = {c ∈ C | checkCS(c) /= true}
Cfail = {c ∈ CnoT rue | checkCS(c) = false} C' = {c ∈ CnoT rue | checkCS(c) =??}


Fig. 1. Constraint solving algorithm

Solving constraints over N1
In this section we investigate how to improve the previous algorithm to obtain better performance when a domain N1 = {0, 1} considered.

τ (K ≥ 0) = True,	if K ≥ 0 τ (K ≥ 0) = False,		if K < 0 τ (K > 0) = True,	if K > 0 τ (K > 0) = False,		if K ≤ 0
τ (cX1 ... Xn + Q ≥ 0) =    1≤i≤n ¬Xi  ∧ τ (rmMX1,...,Xn (Q) ≥ 0)  ∨
   1≤i≤n Xi ∧ τ (rmVX1,...,Xn (Q)+ c ≥ 0) 
τ (cX1 ... Xn + Q > 0) =    1≤i≤n ¬Xi  ∧ τ (rmMX1,...,Xn (Q) > 0)  ∨
   1≤i≤n Xi ∧ τ (rmVX1,...,Xn (Q)+ c > 0) τ (C ∧ C') = τ (C) ∧ τ (C')
Fig. 2. SAT encoding of polynomial constraints over N1
Simplifying the polynomial representation
Since variables in the considered polynomials range on N1 and for all x  N1 and all n > 0 we have xn = x, when considering the representation of a polynomial P , we can replace monomials m = cXα1 ··· Xαn in P by m’ = cXβ1 ··· Xβn where
βi = 1 if αi = 0 and βi = 0 if αi = 0. Then, we add all coefficients of monomials of the same degree β1,..., βn to obtain a single one and proceed like that to obtain a simpler representation P ' of P .
Example 3.1 The polynomial constraint (10) in Example 1.6 would be trans- formed into
(10')  − m2q1s1 ≥ 0

SAT-solving for constraints over N1
When considering polynomial constraints over N1, the arithmetics on N1 become very close to boolean operations when 0 is interpreted as False and 1 as True, respectively. In particular, the product of values in N1 correspond to conjunction. Following this intuition, we have developed a simple encoding of polynomial con- straints as propositional formulas.
The translation function τ is given in Figure 2, where Q is a polynomial, c and K are numeric constants (with c /= 0), X1,..., Xn are variables (ranging on N1), rmMX1,...,Xn (P ) removes all monomials in P which include all variables X1,..., Xn, and rmVX1,...,Xn (P ) removes from P all occurrences of variables in X1,..., Xn.
According to the discussion in Section 3.1, we also assume that we only have to deal with polynomials consisting of monomials like cX1  Xn (i.e., without any power greater than 1).
Example 3.2 Consider the constraint (9) in Example 1.6. It is translated into a

propositional formula as follows:

τ (q1s1 − m1q1s1 ≥ 0)
= ((¬q1 ∨ ¬s1) ∧ τ (0 ≥ 0)) ∨ ((q1 ∧ s1) ∧ τ (−m1 +1 ≥ 0))
= ((¬q1 ∨ ¬s1) ∧ True) ∨ ((q1 ∧ s1) ∧ τ (−m1 +1 ≥ 0)) Since we have:
τ (−m1 +1 ≥ 0) = (¬m1 ∧ τ (1 ≥ 0)) ∨ (m1 ∧ τ (0 ≥ 0))
= (¬m1 ∧ True) ∨ (m1 ∧ True)
⇔ ¬m1 ∨ m1
⇔ True

we conclude:
τ (q1s1 − m1q1s1 ≥ 0)
= ((¬q1 ∨ ¬s1) ∧ True) ∨ ((q1 ∧ s1) ∧ ((¬m1 ∧ True) ∨ (m1 ∧ True)))
⇔ (¬q1 ∨ ¬s1) ∨ (q1 ∧ s1)
⇔ (¬q1 ∨ ¬s1) ∨¬ (¬q1 ∨ ¬s1)
⇔ True

In order to obtain a propositional formula in CNF format, we call an external module implementing the algorithm in [19].

Benchmarks for N1
We have compared the behavior of mu-term when different polynomial constraint solving engines are used to prove termination of programs and the domain of coef- ficients is N1:
mu-term-SD uses the constraint solving algorithm in Section 2 together with the improvements described in Section 3.1.
mu-term-SAT uses the translation of polynomial constraints into propositional formulas described in Section 3.2 and then uses MiniSat 6 to obtain a solution.
mu-term-ApSAT uses an external module implementing the SAT-based con- straint solving algorithm described in [5] and implemented as part of AProVE, and which also uses MiniSat for solving the generated propositional constraints.
mu-term-CiME uses CiME as an external module implementing the constraint solving algorithm described in [4].

6  http://www.cs.chalmers.se/Cs/Research/FormalMethods/MiniSat/MiniSat.html



Table 2 Different solvers for N1

Table 3 Different time-outs for N1

We have considered the 952 examples in the ‘Standard’ TRS subcategory of the 2007 Termination Competition 7 which are part of the 2007 Termination Problem Data Base (TPDB, version 4.0) 8 . The tools were executed under OS Linux Ubuntu 4.1.1- 13ubuntu5, on a Intel Core 2 CPU at 2.13 GHz and 1 GByte of primary memory. Complete information about all benchmarks in the paper can be found here:
http://www.dsic.upv.es/~rnavarro/prole07/benchmarks
Table 2 summarizes the proofs obtained by the different versions of mu-term. Row ‘# YES’ indicates the number of successful proofs; row ‘# ??’ indicates the number of unsuccessful proofs; and row ‘# TOs’ indicates the number of unfinished proofs interrupted by the time-out of 60 seconds. Rows ‘YES Av. T.’/ ‘?? Av. T.’ indicate the average time of successful/unsuccessful proofs (in seconds).
Remark 3.3 Note that, although mu-term-SAT directly implements the encoding described in Section 3.2, it still performs two calls to external tools (the CNF converter and MiniSat). Similarly, mu-term-ApSAT actually performs two external calls (one to AProVE’s SAT-solving engine which then calls to MiniSat). In this sense, we believe that comparing our SAT-encoding and Fuhs et al.’s one through mu-term-SAT and mu-term-ApSAT is fair in our experimental setting.

Different time-outs.
Tools for proving termination do not use a single technique for proving termination. Termination provers rather proceed stepwise by following some particular sequence

7 http://www.lri.fr/~marche/termination-competition/2007
8 http://www.lri.fr/~marche/tpdb



Table 4 Different solvers for N2

Table 5 Different time-outs for N2

of several techniques which are given ‘partial’ time-outs which are a (small) fraction of the global time-out.

Remark 3.4 Nowadays, the termination expert implemented in
mu-term
per-

forms the proofs according to a sequence of 10 different techniques among which we try different kinds of polynomial interpretations and different bounds for the coefficients. The global time-out is equitatively distributed among the different techniques. Hence, a global time-out of 60 s. amounts at each technique to have at most six seconds to obtain a proof.
Thus, we have also considered the behavior of the four solvers when different time- outs (below 60 seconds) are considered. Table 3 shows our results for N1.

Solving constraints over bigger domains
In this section we report on the performance of the constraint solving methods when bigger domains are used. First, N2 = 0, 1, 2 is considered for solving the polyno- mial constraints. We have used the same collection of examples, but mu-term-SAT is not considered anymore for obvious reasons. Table 4 summarize our results for N2. Let’s briefly consider the performance of the constraint solving methods when N5 = 0, 1, 2, 3, 4, 5 is considered for solving the polynomial constraints. Since N5 cannot be expressed as a subset of powers of 2, we cannot properly use mu-term-


Table 6 Different solvers for N5

Table 7 Different time-outs for N5

SD. However, it is very easy to use the algorithm in Section 2.4 together with a generalized arithmetical treatment of the numeric domains by just using the stan- dard arithmetic operations (addition, product, power) instead of relying on binary shiftings as in [16]. This easily leads to a generalization of the original algorithm. We call mu-term-GSD the new version of mu-term which implements such a gen- eralized version of the algorithm described in Section 2. Table 6 summarize our results for N5.

Remark 4.1 Note that mu-term-(G)SD directly implements the algorithm de-
scribed in Section 2 (without any external call) whereas mu-term-ApSAT still
performs two external calls, and mu-term-CiME performs one external call (to
CiME). This has to be taken into account to provide a fair interpretation of the benchmarks.

Analysis of benchmarks
In order to answer the questions posed at the end of Section 1.1, we need to classify the existing choices according to their suitability. On the basis of our experience in the development of tools for proving termination, we believe that the following concrete criteria are appropriate to make this selection:

Take the more successful technique, i.e., having the bigger ‘# YES’. This seems to require few justification.
Among equally successful techniques, take the ones which are complete re- garding the implemented technique, i.e., ‘??’ answers actually mean that the considered technique does not work on the considered problem 9 .
Among complete techniques, take the ones having the bigger ‘# ??’. This permits switching to a different technique more often.
Among techniques having the same ‘# ??’, take the ones having lesser average time for ?? answers. This permits a fast switching to a different technique, thus saving time from the assigned time slot.
According to this, we conclude the following.
The results in Tables 2 and 3 show that our encoding of polynomial constraints over N1 as propositional formulas and the use of state-of-the-art SAT solvers (e.g., MiniSat) seems to be the best way to deal with such kind of constraints when N1 is the domain of coefficients.
Benchmarks in Table 2 also show that our SAT-encoding of polynomial con- straints over N1 is better (in practice) than [5] when used with N1: although both of them succeed on the same number of examples, mu-term-SAT has
a bigger ‘# ??’. Furthermore, mu-term-SAT is 2.52 = 3.8 times faster than
mu-term-ApSAT in giving a positive answer and 5.41 = 3.0 times faster in
giving a negative answer. According to Table 3, the differences are even more
important when small time-outs are used.
Benchmarks in Tables 4 and 6 show that mu-term-ApSAT exhibits the best be- havior over N2 and N5. Furthermore, since the running conditions of mu-term- (G)SD, mu-term-ApSAT, and mu-term-CiME are quite different (see Re- mark 4.1), the detailed analysis of Tables 5 and 7 shows that, indeed, the external use of the SAT-based constraint solving algorithm reported in [5] is better than the direct use of the algorithms in [4,16] for domains of natural numbers like N2 or N5. Actually, regarding [4] our benchmarks provide an independent confirmation of a similar claim in [5].
Finally, we note that, although Ni Nj whenever i < j, the number of successful proofs with Nj is not bigger than with Ni (in general). This is due to dealing with a bigger search space in the presence of time-outs. Actually, except for mu-term-ApSAT in the transition from N1 to N2, in all cases the use of the same solver leads to loosing successful proofs when the upper bound for coefficients increases. Furthermore, since there are examples requiring the use of Nj instead of Ni, the number of ‘lost’ proofs when moving from Ni to Nj for some i < j is actually bigger than suggested by our numbers. This means that first considering the smallest domains is better than a direct attempt on a bigger but ‘heavier’ domain of coefficients.

9 All tools considered here, except mu-term-CiME, are complete in this sense.

Summarizing, we can say that, among the considered techniques, our new SAT en- coding for constrains over N1 is the choice for constraint solving over N1; otherwise the SAT-based solver in [5] should be used when domains of natural numbers are considered (even as an external tool). Finally, the algorithm in [16] is appropriate for constraint solving over domains of rational coefficients.
An automatic ‘termination expert’ implementing the corresponding techniques should combine them accordingly starting with N1, then N2, etc.

Conclusions
We have developed an efficient encoding of polynomial constraints over N1 = 0, 1 as propositional formulas which (in our benchmarks) is almost four times faster than the recent SAT-based algorithm by Fuhs et al. [5] when applied to solve poly- nomial constraints over N1. We have also generalized the algorithm in [16] to deal with arbitrary non-negative numbers. We have investigated the use of different constraint-solving algorithms for the efficient generation of polynomial interpreta- tions in termination provers. We have considered CSP-based solvers like the ones described in [4,16] and SAT-based solvers like the recent proposal in [5] and the new one introduced in this paper. We have implemented or connected (implementations of) the different algorithms as part of the tool mu-term.
The benchmarks for mu-term-SD (and even for mu-term-GSD) suggest that, in comparison to similar polynomial constraint solvers like the one reported in [4], it performs quite well. But the algorithm described in [16] can still benefit from some usual heuristics coming from the CSP area which have not been considered yet. Also, the SAT-encodings discussed here (both our new proposal in Section 3.2 and also [5]) do not take into account more sophisticated SAT frameworks like SMT (SAT modulo theories, see, e.g., [17]) which seem to be a natural choice for polynomial constraints. Furthermore, since the main goal of the algorithm in [16] is providing an efficient way to deal with polynomial constraints over rational (or even real algebraic) numbers, an interesting open problem is how to encode polynomial constraints over such more general domains using SAT/SMT techniques. These are interesting subjects for future work.

Acknowledgement
We thank Ju¨rgen Giesl and Peter Schneider-Kamp for providing an executable ver- sion of the SAT-based polynomial constraint solving engine implemented in AProVE- SAT [5]. We also thank Ju¨rgen Giesl, Carsten Fuhs, and Peter Schneider-Kamp for many valuable discussions regarding the topic of this paper.

References
B. Alarc´on, R. Guti´errez, J. Iborra, and S. Lucas. Proving Termination of Context-Sensitive Rewriting with MU-TERM. Electronic Notes in Theoretical Computer Science, 188:105-115, 2007.


T. Arts and J. Giesl. Termination of Term Rewriting Using Dependency Pairs. Theoretical Computer Science, 236:133-178, 2000.
E. Contejean and C. March´e, B. Monate and X. Urbain. Proving termination of rewriting with CiME. In A. Rubio, editor, Proc. of 6th International Workshop on Termination, WST’03, pages 71-73, Technical Report DSIC II/15/03, Valencia, Spain, 2003. Available at http://cime.lri.fr.
E. Contejean, C. March´e, A.-P. Tom´as, and X. Urbain. Mechanically proving termination using polynomial interpretations. Journal of Automated Reasoning, 34(4):325-363, 2006.
C. Fuhs, J. Giesl, A. Middeldorp, P. Schneider-Kamp, R. Thiemann, and H. Zankl. SAT Solving for Termination Analysis with Polynomial Interpretations. In J. Marques-Silva and K.A. Sakallah, editors, Proc. of the 10th International Conference on Theory and Applications of Satisfiability Testing, SAT’07, LNCS 4501:340-354, Springer-Verlag, Berlin, 2007.
J. Giesl, T. Arts, and E. Ohlebusch Modular Termination Proofs for Rewriting Using Dependency Pairs. Journal of Symbolic Computation 34(1):21-58, 2002.
J. Giesl, P. Schneider-Kamp, and R. Thiemann. AProVE 1.2: Automatic Termination Proofs in the Dependency Pair Framework. In U. Furbach and N. Shankar, editors, Proc. of Third International Joint Conference on Automated Reasoning, IJCAR’06, LNAI 4130:281-286, Springer-Verlag, Berlin, 2006. Available at http://aprove.informatik.rwth-aachen.de.
J. Giesl, S. Swiderski, P. Schneider-Kamp, and R. Thiemann. Automated Termination Analysis for Haskell: From Term Rewriting to Programming Languages. In F. Pfenning, editor, Proc of the 18th International Conference on Rewriting Techniques and Applications, RTA’06, LNCS 4098:297-312, Springer Verlag, Berlin, 2006.
J. Giesl, R. Thiemann, and P. Schneider-Kamp. The Dependency Pair Framework: Combining Techniques for Automated Termination Proofs. In F. Baader and A. Voronkov, editors Proc. of 11th International Conference on Logic for Programming, Artificial Intelligence, and Reasoning, LPAR’04, LNCS 3452:301-331, Springer-Verlag, Berlin, 2004.
J. Giesl, R. Thiemann, P. Schneider-Kamp, and S. Falke. Mechanizing and Improving Dependency Pairs. Journal of Automated Reasoning, 37(3):155-203, Springer-Verlag, 2006.
N. Hirokawa and A. Middeldorp. Tyrolean termination tool: Techniques and features. Information and Computation, 205:474-511, 2007.
H. Hong and D. Jakuˇs. Testing Positiveness of Polynomials. Journal of Automated Reasoning 21:23-38, 1998.
D.S. Lankford. On proving term rewriting systems are noetherian. Technical Report, Louisiana Technological University, Ruston, LA, 1979.
S. Lucas. MU-TERM: A Tool for Proving Termination of Context-Sensitive Rewriting In V. van Oostrom, editor, Proc. of 15h International Conference on Rewriting Techniques and Applications, RTA’04, LNCS 3091:200-209, Springer-Verlag, Berlin, 2004. Available: http://zenon.dsic.upv.es/ muterm.
S. Lucas. Polynomials over the reals in proofs of termination: from theory to practice. RAIRO Theoretical Informatics and Applications, 39(3):547-586, 2005.
S. Lucas. Practical use of polynomials over the reals in proofs of termination. In Proc. of 9th International Symposium on Principles and Practice of Declarative Programming, PPDP’07, pages 39-50, ACM Press, 2007.
R. Nieuwenhuis, A. Oliveras, and C. Tinelli. Solving SAT and SAT Modulo Theories: from an Abstract Davis-Putnam-Longemann-Loveland Procedure to DPLL(T). Journal of the ACM, 53(6):937-977, 2006.
E. Ohlebusch. Advanced Topics in Term Rewriting. Springer-Verlag, Berlin, 2002.
D. Sheridan. The Optimality of a Fast CNF Conversion and its use with SAT. In Proc. of 7th International Conference on Theory and Applications of Satisfiability Testing, SAT’04, 2004.
TeReSe, editor, Term Rewriting Systems, Cambridge University Press, 2003.
