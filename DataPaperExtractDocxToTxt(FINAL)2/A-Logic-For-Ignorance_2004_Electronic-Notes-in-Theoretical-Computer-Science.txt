Electronic Notes in Theoretical Computer Science 85 No. 2 (2004)
URL: http://www.elsevier.nl/locate/entcs/volume85.html  17 pages


A Logic For Ignorance

Wiebe van der Hoek
Department of Computer Science University of Liverpool Liverpool L69 7ZF, UK
wiebe@csc.liv.ac.uk

Alessio Lomuscio
Department of Computer Science King’s College London London WC2R 2LS, UK alessio@dcs.kcl.ac.uk


Abstract
We introduce and motivate a non-standard multi-modal logic to represent and rea- son about ignorance in Multi-Agent Systems. We argue that in Multi-agent systems being able to reason about what agents ignore is just as important as being able to reason about what agents know. We show a sound and complete axiomatisation for the logic. We investigate its applicability by restating the feasibility condition for the FIPA communication primitive of inform.


As we know, there are known knowns; there are things we know that we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns — the ones we don’t know we don’t know.
Donald Rumsfeld (US Secretary of State for Defence)

Introduction
Following Dennet’s influential work [5] MAS are traditionally modelled by tak- ing an intentional stance. This amounts to ascribing notions such as knowl- edge, beliefs, desires, intentions etc. to agents in order to model, and specify their behaviour. Concepts such as knowledge, beliefs, are not easy to model
by means of first order logic. On the one hand they are referentially opaque, on the other they require a formalism in which operators can be arbitrarily

1 This work was supported by the Nuffield Foundation grant NAL/00690/G.
◯c 2004 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


nested one into another. It has long been argued that modal logic provides a possible solution for these problems. Indeed, many of the most important and widely used approaches to model Multi-Agent Systems (MAS) are now based on various modal logics [1].
A considerable amount of research has gone in the past 20 years into ex- ploring the formalisations of concepts such as knowledge and beliefs in MAS. Many of the most successful theories we now have (such as the area of epis- temic logic, variations of the BDI model, etc.) are based on earlier work in AI, or philosophical logic. For example, the foundations of the modern use of epistemic logic (such as the one proposed in [6]) can be found in the work of Hintikka and Aumann of the 1950s. The basis for the BDI work ([16,17]) take inspiration from the work of Bratman, and Cohen [2], [4]. This is not to say that work in MAS theories consists simply in a rediscovery exercise of previously explored ideas. The theories as they are used now are considerably more refined than they were at the time, and they are now integrated with specification and verification techniques from software engineering (witness recent progress in verification of MAS theories [9,15].
Still, while it is encouraging that the field of MAS has taken inspiration from successful theories first appeared elsewhere, it would be interesting to see whether MAS call for the use of previously unexplored concepts. One way this may happen in MAS theories is for a logic arising directly from MAS studies, and applications. In this paper we argue that this may be the case for the concept of ignorance.
Consider the typical scenario in Agent Communication Languages in which one agent queries another for information, perhaps by using the FIPA con- struct of query-if. Assuming honesty, the agent will reply it is unable to answer
the query if it is ignorant about the value of the information it is being asked.
Indeed, in a model where full cooperation is assumed, the fact that it is actu- ally ignorant about the value of what it is being asked may be a precondition for a negative answer of an agent. Consider a similar example in which agents are exchanging data over a channel on which an intruder may be listening.
A desirable property of the interaction is that the state of ignorance of the
intruder with respect to the content of the messages is preserved. We argue that in these and other examples a key property that we want to reason about is states of ignorance. Note that by ignorance we do not mean the mere lack of knowledge, but something stronger. When an agent does not know a fact
p, it may be that it does not know p, because in fact it knows that ¬p. For instance, by using the usual properties of knowledge in MAS in a particular example it is true to say that an agent does not know that the printer is con- nected, because in fact it knows that printer is not connected. We would not call ignorance this simple lack of knowledge. By state of ignorance about ϕ
in the following we shall refer to a mental state in which the agent is unsure about the truth value of ϕ. So, not only the agent does not know the truth value of ϕ but also that of ¬ϕ.


The reader acquainted with the epistemic logic literature will note that it is possible to express this concept in epistemic logic by stipulating that one agent is ignorant about ϕ if it does not know ϕ and it does not know ¬ϕ. We argue that this is cumbersome to express in many interesting examples. For instance, the reader may try and express the concept of one agent being ignorant about the ignorance of another agent:
¬Ki(¬Kjϕ ∧ ¬Kj¬ϕ) ∧ ¬Ki¬(¬Kjϕ ∧ Kj¬ϕ)
This constitutes a typical notion in use in security when the recipient of a message is reasoning about whether or not the intruder has been able to de- code the content of the message. The above looks unnecessarily complicated. Further, this complexity makes it difficult to investigate what properties ig- norance should have. For example, if an agent is ignorant about ϕ should it be ignorant about its ignorance? Still, ignorance must be related to epis- temic states — when an agent is ignorant about ϕ, intuitively it is because it contemplates some alternatives in which ϕ is true, and others in which it is false.
What we do in this paper is to build upon these very simple observations. We aim at defining ignorance as a first class citizen, investigate its properties and explore a logic that is able to represent this concept formally. Technically this will be done by means of modal logic. We shall be using a syntax that allows for a modal operator to express the notion of ignorance of an agent with respect to a formula. Semantically we shall be using the standard possible worlds epistemic interpretation — the satisfaction definition for the operator of ignorance will obviously need to be introduced. We try and provide an in-depth analysis of the logic by giving a completeness result, and we apply this analysis to a concrete example from the literature.
The rest of this paper is organised as follows. In Sections 2 and 3 we give a formal account of ignorance, establishing some of its properties. In Section 4, we investigate a richer framework where ignorance is paired with the classical operator for knowledge. In Section 5 we show how the operator of ignorance can be used to simplify the semantic definition of the communication act of inform as defined in FIPA semantics. We conclude in Section 6.

Ignorance: Language and Semantics
We assume familiarity with basic concepts of modal logic. We refer the reader to [1] for details. We base our discussion on the monomodal case.

Syntax
We use a very simple mono-modal language LI defined as follows in BNF:

ϕ ::= p | ¬ϕ | ϕ ∧ ϕ | Iϕ


Other propositional operators can be defined as standard, and are to be read as usual. A formula Iϕ is to be read as ‘the agent is ignorant about ϕ’, i.e., he is not aware of whether or not ϕ is true. As an example the formula Iϕ → ¬IIϕ is to be read as “If the agent is ignorant about ϕ, then it is not ignorant about it being ignorant about ϕ”.
We ground our discussion on classically minded agents, so we assume that statements cannot both be true or false at the same time. So, to anticipate semantical considerations made clear below, the agent in order to be ignorant about ϕ will have to conceive at least two epistemic alternatives, one in which ϕ is true, and one in which ϕ is false.
In our concept of ignorance we do not intend to capture degrees of igno- rance with respect to a formula. There is a whole spectrum of concepts that seem worth exploring. On the one side we have agents which have absolutely no information about a fact, so are in a way “truly ignorant” about it. On the other side of the spectrum we have agents which may regard a fact to be a lot more likely to be true (or false) but still contemplate the possibility of the fact being false. In our formalism we shall not be able to differentiate be- tween these. This, and various variants of probabilistic reasoning seem worth exploring, but are left for future work.

Semantics
We use standard possible worlds semantics to give an interpretation to the language above. A model will be built on a set of epistemic alternatives (or worlds), and a relation built on these. Intuitively, like in standard modal epistemic logic, we consider two epistemic alternatives to be related if up to the agent’s information they may both be models of the real situation.
Definition 2.1 [Frames, Models, and Satisfaction] A Kripke Frame F = (W, R) is a tuple where W is a set of epistemic alternatives for the agent, and R ⊆ W × W is an accessibility relation. A Kripke Model M = (F, π), is a tuple where F is a Kripke frame and π : P → 2W is an interpretation for a set of propositional variables P .
Given a model M and a formula ϕ, we say that ϕ is true in M at world
w, written M, w |= ϕ if:
M, w |= p if w ∈ π(P ),
M, w |= ¬ϕ if it is not the case that M, w |= ϕ,
M, w |= ϕ ∧ ψ if M, w |= ϕ and M, w |= ψ,
M, w |= Iϕ if there exist w', w'' such that
Rww', Rww'', M, w' |= ϕ, and M, w'' |= ¬ϕ.
A formula ϕ is valid , written |= ϕ, if it is true in every world in every model. We write F, w |= ϕ to represent M, w |= ϕ where M is an arbitrary model whose underlaying frame is F .


We assume the standard definitions for metalogical properties such as ax- iomatisation, completeness, etc. We refer to [1] for details.
Lemma 2.2 The following formulas are valid on the class of arbitrary Kripke models.
A1  Iϕ ↔ I¬ϕ
A2  I(ϕ ∧ ψ) → (Iϕ ∨ Iψ)
Proof. We prove A1 here; for A2, we refer to Lemma 3.1. Consider an arbi- trary model M. Assume M, w |= Iϕ. Then there must be two points w', w'' such that Rww', Rww'' and M, w' |= ϕ, M, w'' |= ¬ϕ. But then by definition this means that M, w |= I¬ϕ.	✷
The properties above seem rather reasonable for ignorance. Axiom A1 says that being ignorant about ϕ is logically equivalent to being ignorant about ¬ϕ. Since by ignorance we mean no definite information about the truth of the object of ignorance, intuitively this is correct.
Property A2 is maybe best understood in its contrapositive form (¬Iϕ ∧
¬Iψ) → ¬I(ϕ ∧ ψ). If an agent is neither ignorant about ϕ, nor about ψ it is surely not ignorant about the conjunction ϕ ∧ ψ. This also seems reasonable.

A Logic for Ignorance
In this section we aim at presenting a completeness result (Theorem 3.10) for a logic of ignorance. In order to do this we need some preliminary results.

Preliminary remarks
Axiom A2 regulates how to distribute I over a boolean connective. Similarly, note that the following is also valid.
I(ϕ → ψ) → Iϕ ∨ Iψ
As a proof, note that I(ϕ → ψ) ≡ I¬(ϕ → ψ) ≡ I(ϕ∧¬ψ). Also, I(ϕ∧¬ψ) →
(Iϕ ∨ I¬q), the latter being equivalent to Iϕ ∨ Iψ.
I(ϕ ∨ ψ) → (Iϕ ∨ Iψ)
Since negation and implication (or, for that matter, negation and disjunc-
tion) are functionally complete, we can generalise (1) and (2) into the following lemma:
Lemma 3.1 Let A ⊆ P be a set of propositional atoms, and b(A) be a Boolean function on A. Then there exist literals l1 ... lk over A, such that I(b(A)) → i≤k I(li) is valid.
Proof. First write b(A) in conjunctive normal form i di, where every di is a disjunction of literals over A. Observe, by A2, that I(  i di) →  i I(di). Now


note that I(di1 V ··· V dik ) → (Idi1 V ··· V Idik ), where every dij is a literal
i	i
over A.	✷

Corollary 3.2 Let A ⊆ P be a set of propositional atoms, and b(A) be Boolean function on A. Then
|= I(b(A)) →   I(a)
a∈A

Corollary 3.2 states that, in order to be ignorant about a complex formula, one must be ignorant about one of its atoms. Again, this corresponds to our intuition.
Let us now turn our attention to possible inference rules for a system of ignorance. We begin by observing that the following is sound.
from ▶ ϕ, infer ▶ чIϕ
Indeed, this corresponds to the intuition that an agent cannot be igno- rant about propositional tautologies, and formulas following from them. Note the rule above is related to the commonly accepted rule of necessitation in epistemic logic that states that the agent knows all propositional tautologies.
A more complex inference rule that can also be shown to be sound is the following.
▶ (ψ1 → χ) л (χ → ψ2) ⇒ ▶ чIχ → (чIψ1 V чIψ2)
In fact, note that rule (3) follows from rule (4) when чIT is a validity (like it is in our case) by taking ψ1 = ψ2 = ϕ and χ = T. It is easy to see that Equation 4 provides for a sound inference rule for the semantics described above. It says that if an agent is not ignorant about an interpolant χ for a stronger ψ1 and a weaker ψ2, that it cannot be ignorant about both the ψi’s. If the agent is not ignorant about χ, it either thinks χ is true (in which case it also should consider ψ2 as being true), or that χ is false (in which case it
should be convinced of ψ1’s falsity as well).



A Complete System for Ignorance
We now present a system that we can show to be complete with respect to the semantics above.

Definition 3.3 The modal system Ig for ignorance is defined as follows:


I0	All instances of propositional tautologies
I1	Iϕ ↔ Iчϕ
I2	I(ϕ л ψ) → (Iϕ V Iψ)
I3	(чIϕ л I(α1 л ϕ)) л чI(ϕ → ψ) л I(α2 л (ϕ → ψ))
→ (чIψ л I(α1 л ψ))
I4	 (чIψ л Iα) → (I(α л ψ) V I(α л чψ)) RI	▶Ig ϕ ⇒ ▶Ig чIϕ л (Iα → I(α л ϕ)) MP	Modus Ponens
Sub	Substitution of equivalences
Observation 1 Before we prove soundness of Ig, we make the following re- mark about occurrences in axiom I3 of the form чIϕ л I(α л ϕ). If such a formula is true, either the agent is sure about the truth value of ϕ, or of чϕ. Moreover, the truth of I(α л ϕ) implies that the agent regards as possible an αлϕ-world 2 , which is both a ϕ- and an α-world. But this then implies that all the agents’ conceivable worlds verify ϕ. Therefore the agent is sure about the value of ϕ. But I(αл ϕ) also implies that the agent considers a ч(αл ϕ)-world possible, which is also a (чα V чϕ)-world. But since all the conceivable worlds verified ϕ, this implies that the agent considers one world possible in which чα is true. This, together with the fact that an α-world was an alternative to the agent, gives us that the agent is ignorant about α, but knows that ϕ.
Lemma 3.4 (Soundness) The system Ig is sound with respect to the class of arbitrary Kripke models.
Proof. Validity of I1 has been argued in the previous section. For I2, first note that this is equivalent to чIϕ л I(ψ л ϕ) → Iψ. Consider any model M. Suppose that M, w |= (чIϕ л I(ψ л ϕ)). By the argument given in Observation 1, we know then that all successors of w verify ϕ. Since I(ϕ л ψ) holds at w we must also have Iψ there.
We prove I3 and the inference rule RI. For I3, as before, suppose we have a state for which M, w |= (чIϕ л I(α1 л ϕ)) л чI(ϕ → ψ) л I(α2 л (ϕ → ψ)). чIϕ is true in w when all R-successors of w either satisfy ϕ or чϕ. Since I(α1 л ϕ) is also true at w, we know that w must have at least an (α1 л ϕ)- successor u. These two statements together imply that all successors of w verify ϕ. Moreover, we know that w has a (чα1 л ϕ)-successor v. The same line of reasoning applied to M, w |= чI(ϕ → ψ) л I(α2 л (ϕ → ψ)) gives us that all successors of w satisfy ψ. Hence, there is no чψ-successor of w, which gives M, w |= чIψ. Moreover, in u we have α1 лψ, and in v, чα1 лψ; therefore M, w |= I(α1 л ψ).

2 A world w is an α-world if α is true at w in the model under consideration.


To prove the soundness of RI, suppose |= ϕ. Then there cannot be a world w with a чϕ-successor, so |= чIϕ. Moreover, let w be an arbitrary world in an arbitrary model M for which M, w |= Iα. Since ϕ is true in all worlds, we get that w has a successor u for which M, u |= (α л ϕ) and a successor v with M, v |= (чα л ϕ), implying M, v |= ч(α л ϕ). Thus, we have M, w |= Iα → I(α л ϕ).
We begin by noting that the following is a theorem of Ig.
Lemma 3.5 We have that ▶Ig Cb, where Cb is defined as:
Cb	(чIγ1 л I(δ1 л γ1)) л (чIγ2 л I(δ2 л γ2))
→ I(δ2 л (γ1 л γ2))
Proof. Note that γ1 → (γ2 → (γ1 л γ2)) is a theorem (*). Furthermore, let us assume the antecedent of Cb (**). We use the rule MP implicitly.
1  ▶ γ1 → (γ2 → (γ1 л γ2))	(∗)
чIγ1 л I(δ1 л γ1) л чIγ2 л I(δ2 л γ2)	(∗∗)
чI(γ1 → (γ2 → (γ1 л γ2))) л
Iδ2 → I(δ2 л (γ1 → (γ2 → (γ1 л γ2))))	RI, 1
чIγ1 л I(δ1 л γ1)л
чI(γ1 → (γ2 → (γ1 л γ2)))	2, 3
(чIγ2 л I(δ2 л γ2)) → Iδ2	I0, I2
Iδ2	2, 5
I(δ2 л (γ1 → (γ2 → (γ1 л γ2))))	6, 3
I(δ1 л (γ2 → (γ1 л γ2)))	I3, 4, 5, 7 (see below)
чI(γ2 → (γ1 л γ2))	I3, 4, 5, 7 (see below)
чIγ2 л I(δ2 л γ2) л чI(γ2 → (γ1 л γ2))	2, 9
I(δ2 л (γ1 л γ2))	I3, 8, 9, 10 (see below) In steps 8 and 9, the instances from I3 to be chosen are ϕ ::= γ1, α1 ::= δ1, α2 ::= δ2,ψ ::= γ2 → (γ1 л γ2). In the last step, choose the following: α2 ::= δ1,ψ ::= γ1 л γ2,ϕ ::= γ2, α1 ::= δ2.
Note that it can be proven that the disjunctive conclusion in I4 is in fact exclusive.
In order to show completeness we build maximal consistent sets of formulas and show that the canonical model for the logic Ig can be built on these. Although the canonical model construction will be non-standard, much of the background definitions that we use are standard. In particular we assume the usual definitions for logical consistency, and maximal consistent sets. We refer to [1] for details. Since we only refer to system Ig in this section we shall refer


to consistency to mean Ig-consistency.
Lemma 3.6 Let Γ be a maximal consistent set, containing some formula Iα. Then the set Kα(Γ) = {ψ | чIψ, I(α л ψ) ∈ Γ} has the following properties:
If чIψ ∈ Γ, then either ψ ∈ Kα(Γ) or чψ ∈ Kα(Γ);
Kα(Γ) ∪ {β} is consistent, for every Iβ ∈ Γ.
Proof. Note that Iα ∈ Γ, and consider Kα(Γ) as defined above.
Suppose чIψ ∈ Γ. Then by axiom I4 and the maximality of Γ, we have either I(ψ л ϕ) ∈ Γ, or I(чψ л ϕ) ∈ Γ. Hence, by construction of Kα(Γ), we are done.
To arrive at a contradiction, suppose that for some β with Iβ ∈ Γ, Kα(Γ) ∪ {β} is inconsistent. So, ▶ (ψ1 л ··· л ψn) → чβ, with ψi ∈ Kα(Γ),i = 1,... , n. Let us first write Ψ for (ψ1 л ··· л ψn). Then, by RI we have ▶ чI(Ψ → чβ) and ▶ Iα → I(α л (Ψ → чβ)). Since Iα ∈ Γ. Then by maximal consistency we have that:
чI(Ψ → чβ) л I(α л (Ψ → чβ)) ∈ Γ
In order to apply MP and axiom I3 to this, we need to prove that:
чIΨ л I(α л Ψ) ∈ Γ
Indeed this follows from property Cb. Let Ψk = (ψ1 л ... ψk). So Ψ = Ψn. We prove by induction on k that for all k ≤ n, чΨk ∈ Γ and I(α л Ψk) ∈ Γ. For k = 1, we know that both чψ1 ∈ Γ and I(α л ψ1) ∈ Γ (by construction of Γ).  Now let k < n and suppose that чΨk ∈ Γ (i) and I(α л Ψk) ∈ Γ
(ii). By construction of Γ we also have чIψk+1 ∈ Γ (iii) and I(α л ψk+1) ∈ Γ
(iv). Therefore by applying Cb we to the four statements to derive that I(α л Ψk+1) ∈ Γ (Note that Ψk+1 = Ψk л ψk+1). To see that also чΨk+1 ∈ Γ, for a contradiction suppose that Ψk+1 ∈ Γ. Axiom I2 would then yield that either Ψk ∈ Γ or ψk+1 ∈ Γ; the first conclusion is contradictory with the induction hypothesis, and the second with our conclusion (iii). This proves Ψk+1 ∈ Γ.
Now, using (6), (5), and axiom I3 we can conclude
чIчβ л I(α л чβ) ∈ Γ.
So чIчβ ∈ Γ, and, by axiom I1, чIβ ∈ Γ.  But since by assumption
Iβ ∈ Γ, Γ is inconsistent, contrary to the hypothesis. Therefore Kα(Γ) is consistent.	✷
Lemma 3.7 The set Kα(Γ) = {ψ | чIψ, I(α л ψ) ∈ Γ} is independent of the choice of α: if Iα1, Iα2 ∈ Γ, then Kα1 (Γ) = Kα2 (Γ).
Proof. Suppose Iα1, Iα2 ∈ Γ, and that чIψ, I(α1 л ψ) ∈ Γ.  From this, it follows that чIψ л Iα1 л I(α1 л ψ) ∈ Γ (1).  It remains to show that I(α2 л ψ) ∈ Γ. Suppose not; then, by maximal consistency ч(I(α2 л ϕ)) ∈ Γ. But чIψ ∈ Γ, Iα2 ∈ Γ, so by I4 and some calculations, I(α2 л чψ) ∈ Γ. Then


by I1 we have that чIчψ л Iα2 л I(α2 л чψ) ∈ Γ (2). We can now apply Cb to (1) and (2), giving I(α1 л (ψ л чψ)) ∈ Γ, which implies I⊥∈ Γ, By I1 this gives IT ∈ Γ. But ▶ T, so T ∈ Γ. So by rule RI, we have чIT ∈ Γ, which
would make Γ inconsistent.	✷
Observe now that since system Ig is consistent (this follows immediately from the soundness theorem), the existence of maximal consistent sets is guar- anteed by Lindembaum’s Lemma. So, for any Ig-consistent set of formulas there exists at least a maximal extension that properly includes the elements of the set. To prove completeness we now define a rather ad-hoc canonical model, as follows.
Definition 3.8 [Canonical Model] The canonical model MC = (W C, RC, πC) for the logic Ig is defined as follows:
WC is the set of all maximal Ig-consistent sets of formulas (denoted as Σ, ∆, Γ .. .).
RC ⊆ WC × WC is defined by RcΓΣ if Σ ≥ Kα(Γ) for some Iα ∈ Γ.
p ∈ π(Γ) if p ∈ Γ.
Note that in the canonical model, every world Γ has either no successors (if there is no Iα ∈ Γ), or at least two successors (if Iα ∈ Γ, then also Iчα ∈ Γ, and, according to Lemma 3.6 part b) together with Lindembaum’s Lemma, there are at least two successors Σ1 ≥ Kα(Γ) ∪ {α} and Σ2 ≥ Kα(Γ) ∪ {чα}).
Lemma 3.9 (Truth-Lemma) For all formulas ϕ, and all Ig-maximal con- sistent sets Γ, we have:
Mc, Γ |= ϕ e ϕ ∈ Γ
Proof. We prove the above by induction on the structure of ϕ. We leave to the reader to verify the basic propositional connectives. We prove the induction hypothesis for the case of Iϕ, from this the lemma is proved.
Mc, Γ |= Iψ e Iψ ∈ Γ.
From left to right: suppose that Mc, Γ |= Iψ. By the truth-definition of I, there exist Γ1 and Γ2, with RcΓΓ1 and RcΓΓ2, such that Mc, Γ1 |= ψ and Mc, Γ2 |= чψ. Hence by induction hypothesis we have ψ ∈ Γ1, чψ ∈ Γ2. For a contradiction suppose that Iψ /∈ Γ. Then, by the maximal consistency
of Γ, чIψ ∈ Γ.  So чIчψ ∈ Γ by axiom I1.  But under our hypothesis Γ has successors, so by definition there exists an α : Iα ∈ Γ. Then by axiom I4, either I(α л ψ) ∈ Γ or I(α л чψ) ∈ Γ. But this would imply that
either ψ ∈ Kα(Γ) or чψ ∈ Kα(Γ). But Γ1 ≥ Kα(Γ), Γ2 ≥ Kα(Γ), and the first possibility contradicts RcΓΓ2 (since чψ ∈ Γ2), and the second RcΓΓ1 (sinceψ ∈ Γ1).
From right to left. By contradiction, suppose that Iψ ∈ Γ and Mc, Γ |= Iψ. Then by the truth definitions all Rc-successors of Γ would satisfy either ψ or чψ, hence by induction they either contain ψ, or чψ. Suppose all Rc successors of Γ contain ψ. Since Iψ ∈ Γ, by axiom I1, we also have Iчψ ∈ Γ. By Lemma


3.7, Kα(Γ) ∪ {чψ} would then be consistent. But then, by construction of Rc, there should be a maximal consistent set Σ ≥ Kα(Γ) with чψ ∈ Σ and RcΓΣ. However,this would mean that we found a Rc successor of Γ containing both ψ and чψ, which leads to a contradiction. The other case can similarly be argued. So we can conclude that Mc, Γ |= Iψ.
Theorem 3.10 (Completeness) Given system Ig, for any formula ϕ we have the following: ▶Ig ϕ if and only if |= ϕ.
Proof. Soundness was shown in Lemma 3.4. Completeness follows in the usual way from the Truth-Lemma: suppose that /▶ ϕ, then чϕ is Ig-consistent, giving a Ig-maximal consistent set Γ with чϕ ∈ Γ. By Lemma 3.9 then, we have Mc, Γ |= чϕ, so that |= ϕ.	✷
Note that the completeness result above applies to the general class of Kripke frames. This contrasts with system K being the standard system to axiomatise arbitrary frames for a standard modality.

Ignorance and Knowledge
Now that we have a result for a basic system for ignorance we can ask the question of how this relates to what is known already in epistemic logic [6]. Af- ter all the semantics that we have used is based on the one for epistemic logic: we regard two points as related if the agent considers the two as epistemically indistinguishable. What we have done so far amounts to using this semantic concept to express ignorance as opposed to knowledge. But since intuitively it must be possible to build a correspondence between the two concepts, the curious reader must then be left wondering whether ignorance can in fact be precisely expressed in terms of knowledge. Crucially, one must consider the question of whether one could have ultimately proven Theorem 3.10 by a care- ful translation of epistemic operators from the usual modal systems used for epistemic logic such as S5. We explore this and other questions in the rest of this section.
Let us first ask the question of whether our ignorance operator can in fact be expressed in terms of knowledge, not just by using the semantics as we have done but also syntactically. We have taken being ignorant about ϕ to mean that the agent conceives two opposite alternatives for ϕ. In the usual epistemic language this not just implies, but is semantically equivalent to saying that the agent does not know ϕ, and does not know чϕ (an alternative definition would come from exploiting Kϕ ≡ чIϕ л ϕ, but this would assume reflexivity of the epistemic relations as will become clearer later on):
Iϕ ≡ (чKϕ л чKчϕ).
We have been unable to prove a completeness result simply by using this equivalence. Indeed, surprisingly little is known about logics for modalities that are defined from others, the only constructions available resulting from


work in algebraic modal logic. One may try coding epistemic axioms for K in view of the definition above to deduce properties for I but this attempt is hindered with technical difficulties. Even if this exercise were to be successful, we would be left with a logic for I that assumes S5 as the underlaying model for K. S5 is often a good model for knowledge, but at other times it is useful to consider weaker models. In the way we proceeded we have made no assumption on the properties of the underlaying relations between points, and the resulting framework is a rather weak one. Indeed, we believe this to be a good feature of the logic — we have a rather weak system to begin with and we can add more properties to it if required. Given this one can define a logic for both K and I by taking the standard satisfaction definition for both operators.
We also point out that K cannot be defined in terms of I. Consider the frames of Figure 1; note that, by induction, for all formulas ϕ in the language for ignorance LI, we have
F1, w1 |= ϕ iff F2, w2 |= ϕ iff F3, w3 |= ϕ
Indeed, note that for every wi (i ≤ 3), no Iϕ can be true: the agent considers too few alternatives possible to have any doubt whatsoever. From this, it immediately follows that K cannot be defined in terms of I, since we have for instance F3, w3 |= K⊥, but F1, w1 |= K⊥. In other words: K can distinguish between frames that I cannot.

Nested Ignorance
We now analyse the consequences of considering additional properties for the accessibility relations, thereby producing stronger systems then Ig. Let us start with transitive relations; these define positively introspective agents (in the sense of the knowledge they have, i.e., agents whose knowledge satisfies axiom 4: Kϕ → KKϕ holds). By definition a positively introspective agent cannot be ignorant about what it knows. In fact we would have the axiom:

I4	чIψ → чIчIψ.
Note that axiom I4 is, in the context of Ig equivalent to IIψ → Iψ.
Can an agent be ignorant about one’s ignorance? Clearly, a negatively introspective agent cannot be. This would suggest the validity of the axiom:

I5	Iψ → чIIψ.
In line with epistemic logic we would expect properties I4 and I5 to impose transitivity and Euclidicity, respectively, on the canonical model. Let us first note that I4 is indeed true on transitive models.
Lemma 4.1 F4 |= I4, where F4 is the class of transitive frames.
Proof. Consider an arbitrary model built on an arbitrary frame, and suppose


M, w |= IчIψ, or, equivalently, M, w |= IIψ. Then there are u and v for which Rwu, Rwv and M, u |= Iψ and M, v |= чIψ. The former implies that there are u1 and u2 with Ruu1, Ruu2 and M, u1 |= ψ, M, u2 |= чψ. Since R is transitive, we have Rwu1, Rwu2, and hence M, w |= Iψ.	✷

However, it is illustrative to see that the converse does not hold: validity of I4 on a frame does not guarantee transitivity. Consider the frame with three worlds w, u, v, such that Rwu and Ruv. In w, for no formula ψ, Iψ is true (since w has only one successor). Hence, I4 is valid in w, a point in a non- transitive frame. As for I5 and Euclidicity, one can do a similar analysis: I5 is valid on all Euclidean frames, but validity of I5 does not force the underlying frame to be Euclidean.
One way to proceed to achieve completeness results for stronger systems then Ig is to start from the semantic properties and see whether there are formulas that correspond to transitivity and Euclidicity. Here, we can use the insight of Section 3.2, i.e., that we can interpret чIϕ л Iα л I(α л ϕ) as чKα л чKчα л Kϕ. To give an indication of the kind of axiomatisations that one would have by doing so, we show the result for transitivity.

Lemma 4.2 Consider the following axiom scheme:
G4	Iα → [(чIϕ л I(ϕ л α)) →
чI(чIϕ л I(α л ϕ)) л I(чIϕ л I(ϕ л α) л α)]
Then, Ig ∪{G4} is sound and complete with respect to transitive models.

Proof. We show that the canonical model is transitive. Completeness fol- lows by standard consideration; soundness can routinely be checked. Sup- pose RcΓ∆ and Rc∆Σ. Since Γ has successor, there must be some Iα ∈ Γ. Suppose ϕ ∈ K(Γ): to prove that ϕ ∈ Σ. By definition of K(Γ), we have (чIϕ л I(ϕ л α)) ∈ Γ. By G4, we conclude that чI(чIϕ л I(α л ϕ)), I(чIϕ л I(ϕ л α) л α) ∈ Γ. By definition of K(Γ) then, чIϕ л I(α л ϕ) ∈ K(Γ) and hence чIϕ л I(α л ϕ) ∈ ∆. By A4, we have Iα ∈ ∆, hence ϕ ∈ K(∆), and thus ϕ ∈ Σ.	✷

We leave axiomatisations of other classes of frames for further work.
We conclude by stressing that we are using a modal logic quite dissimilar to the one that the reader may be familiar with. For example we have that reflexivity is not definable by means of operator I only. This can be checked by using Figure 1 again: were reflexivity definable with the LI-formula ψ,
then we would have F2, w2 |= ψ. However, we already observed that then also
F1, w1 |= ψ, which would imply that F1 is reflexive as well, at w1, which it obviously is not.




		

Fig. 1. Three worlds without any ignorance
Another look at FIPA’s feasibility precondition
Logic is used in MAS and AI in a variety of topics ranging from negotiation to specification of behaviour. Of particular interest is the role that theories of beliefs and intention play in the area of communication languages. It has been argued long ago that one possible way to give a semantics to the speech act inform in agent communication languages is by means of pre-conditions and post-conditions. In particular, let us consider FIPA’s pre-condition (called “feasibility condition” in [7]) for an inform speech act < i, inf orm(j, ϕ) >, i.e., an act in which agent i informs agent j of the formula ϕ. The feasibility condition is given as:
Biϕ л чBi(Bifjϕ V U ifjϕ)
There are three different operators at play here. B stands for “belief”. Bif stands for “believe whether”. U if stands for “uncertain whether”. All these are indexed with the agent for which they are referred to. So the formula above is read as: “agent i believes that ϕ, and it is not the case that agent i believes that either agent j believes whether or not ϕ is the case, or that agent j is uncertain about ϕ”. The last term in the original formulation is meant to have a fuzzy interpretation of the kind “j suspects ϕ may be true but he is not sure about it.”.
FIPA’s specification does not define formally the way these operators are to be interpreted. In the following we try to do this by using the formal machinery of this paper. Roughly speaking, the above makes two requirements.
Agent i believes ϕ.
Agent i believes that agent j is not aware of the truth value of ϕ.
1) is a sincerity condition - the agent would not send false information without violating its specification. 2) requires that agents are not sending in- formation that they believe is redundant. Given the difficulties of expressing formally the notion of being biased towards ϕ we do not incorporate it into our reading. This model is best suited for cooperative systems where benev- olent agents aim at distributing correct information. We do recognise our translation above may be simply an approximation of what is intended in the specification; but given that the semantics of the operators of Bif and U if is not given, this could still prove beneficial. In this interpretation, the feasibility precondition above can be formally expressed in the logical language of this


paper as:
Biϕ л BiIjϕ
In the above B is a KD45 operator defined like knowledge, but for which the relation does not enjoy reflexivity, and I is the operator built on the same relation, and discussed in this paper. While this attempt does not incorporate the operator of uncertainty, the above does seem to capture the intuition of FIPA’s specifiers, and its semantics can be given formally by using the machinery of this paper — something that is currently not possible to do for any precondition of FIPA’s speech acts. Completeness results for logics in which interaction between the two operators occur can now be investigated.

Conclusions
We have argued that the concept of an agent being ignorant is worth investi- gating further, and suggested examples from MAS as to why this is the case. We showed that this analysis can be carried out independently from the com- monly adopted logics for knowledge. Semantic definitions for a non-standard modal operator, and completeness results have been presented. We would contend that the technical results of the paper offer some insights into the possibility of expressing other operators that are not defined on the set of accessible points as it is traditionally done in mainstream modal logic.
Some technical questions are still left open at this stage. As we have seen in Figure 1 there may be frames that satisfy the same formulas but are not bisimilar. It would be interesting to study what technical concept is relevant here for this notion. Since our language is in many respects similar to that of
graded modalities (cf. [10]), the notion of generalised n-bisimulation introduced
there might provide a hint to find such a similarity. From a purely epistemic logic point of view, the connection with logics for only knowing ([8]) seems promising. The idea of saying that an agent only knows ϕ is that he knows ϕ and all of its consequences (Kiψ1, if ▶ ϕ → ψ1), but he is ignorant about any stronger formula Iψ2, if ▶ ψ2 → ϕ.
More broadly we feel there is much scope for further work with respect to connections to specific MAS areas. One avenue we like to investigate is the application of this work to MAS security. The formalisms resulting from the refinements of BAN logic [3] are concerned with proving that particular protocols are secure, i.e., that any intruder would not be able to decrypt the
messages being exchanged. In the language of this paper this means that its state of ignorance is an invariant in the execution. BAN logic in its standard form suffer from the lack of semantics and is purely an axiomatic system. Maybe the machinery of this paper can be used to solve this problem.
The semantics of the speech act inform presented above seems also a promising area for further development. Irrespective of whether the particular translation given here captures the actual intuition of FIPA’s specifiers, the


operator of ignorance seems to be a useful ingredient for a definition that can actually be interpreted on a formal semantics. The interest here is not purely theoretical — having a clear semantics is an essential ingredient to move to compliance testing and verification [18]. This is something that is lacking in all FIPA’s implementations at present.

References
P. Blackburn, M. de Rijke, and Y. Venema. Modal logic. Cambridge University Press, 2001.
M. E. Bratman. What is intention? In P. R. Cohen, J. L. Morgan, and M. E. Pollack, editors, Intentions in Communication, pages 15–32. The MIT Press: Cambridge, MA, 1990.
M. Burrows, M. Abadi, and R. Needham. A logic of authentication. ACM Transactions on Computer Systems, 8(1):18–36, Feb. 1990.
P. R. Cohen and H. J. Levesque. Intention is choice with commitment. Artificial Intelligence, 42(2-3):213–261, Mar. 1990.
D. Dennet. The Intentional Stance. MIT Press, 1987.
R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. Reasoning About Knowledge. MIT Press, 1995.
FIPA: Foundation for intelligent physical agents. http://www.fipa.org.
J. Halpern. Theory of knowledge and ignorance for many agents. Journal of Logic and Computation, 7(1):79–108, 1997.
W. van der Hoek and M. Wooldridge. Model checking knowledge and time. In SPIN 2002 – Proceedings of the Ninth International SPIN Workshop on Model Checking of Software, Grenoble, France, April 2002.
W. van der Hoek. On the semantics of graded modalities. Journal of Applied Non Classical Logics, 2(1):81–123, 1992.
W. van der Hoek and E. Thijsse. A general approach to multi-agent minimal knowledge: with tools and samples. Studia Logica, 72(1):61–84, 2002.
G. E. Hughes and M. J. Cresswell.	A New Introduction to Modal Logic. Routledge, New York, 1996.
A. Lomuscio. Knowledge Sharing among Ideal Agents. PhD thesis, School of Computer Science, University of Birmingham, Birmingham, UK, June 1999.
J.-J. C. Meyer and W. van der Hoek. Epistemic Logic for AI and Computer Science, volume 41 of Cambridge Tracts in Theoretical Computer Science. Cambridge University Press, 1995.


W. Penczek and A. Lomuscio. Verifying Epistemic Properties of multi-agent systems via model checking. Fundamenta Informaticae, volume 55(2), 2002.
A. S. Rao and M. P. Georgeff. Modeling rational agents within a BDI- architecture. In J. Allen, R. Fikes, and E. Sandewall, editors, Proceedings of the 2nd International Conference on Principles of Knowledge Representation and Reasoning, pages 473–484. Morgan Kaufmann Publishers, Apr. 1991.
A. S. Rao and M. P. Georgeff. Decision procedures for BDI logics. Journal of Logic and Computation, 8(3):293–343, June 1998.
M. Wooldridge. Semantic issues in the verification of agent communication languages. Journal of Autonomous Agents and Multi-Agent Systems, 3(1):9— 31, February 200.
