

Electronic Notes in Theoretical Computer Science 272 (2011) 3–17
www.elsevier.com/locate/entcs

Stochastic Semantics of Signaling as a Composition of Agent-view Automata
Heinz Koeppl2 Tatjana Petrov3
School of Communication and Computer Sciences Ecole Polytechnique Federale de Lausanne (EPFL) Lausanne, Switzerland

Abstract
In this paper we present a formalism based on stochastic automata to describe the stochastic dynamics of signal transduction networks that are specified by rule-sets. Our formalism gives a modular description of the underlying stochastic process, in the sense that it is a composition of smaller units, agent-views. The view of an agent is an automaton that identifies all local modification changes of that agent (internal state modifications, binding and unbinding), but also those of interacting agents, which are tested within the
same rule. We show how to represent the generator matrix of the underlying Markov process of the whole rule-set as Kronecker sums of the rate matrices belonging to individual view-automata. In the absence of birth the automata are finite, since the number of different contexts in which one agent can appear in a rule-set is finite. We illustrate the framework by an example that is related to cellular signaling events.
Keywords: Cell signaling, Continuous-time Markov chain, Stochastic automata composition


Introduction
Internal dependencies of multi-site posttranslational modifications [21,17] and con- formational changes [4,18] of signaling proteins, reflect the rich internal logic of proteins and invite the formalization of this logic through an agent automaton. Consider for instance the protein interaction network driving circadian oscillations in cyanobacteria. The central hexameric KaiC protein undergoes cycles of hypo- phosphorylated and hyper-phosphorylated states [14,13], where the sequence of phosphorylation of the two residues of every protein subunit is strictly controlled [15]. Moreover, it is believed that the KaiC hexamer changes conformation upon

1 Heinz Koeppl acknowledges the support from the Swiss National Science Foundation, grant no. 200020- 117975/1. Tatjana Petrov acknowledges the support from SystemsX.ch, the Swiss Initiative in Systems Biology.
2 Email: heinz.koeppl@epfl.ch
3 Email: tatjana.petrov@epfl.ch

1571-0661 © 2011 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2011.04.002

hyper-phosphorylation. See Fig. 1 for a schematic of the cyclic process that is con- trolled by two modulator proteins KaiA and KaiB. Such modification events are uni-molecular events and can thus be well encapsulated into an internal logic of a protein. Bi-molecular events, such as modulator binding, can be considered as in- puts to this state automata. The construction of individual protein-automata also










Fig. 1. Internal logic of a multimeric protein. The simplified scheme captures the basic cyclic transitions that the hexameric circadian clock protein KaiC undergoes. Hyperphosporylation (black-filled subunits) induces a conformational change from an allosteric tensed (⃝) to a relaxed ( ) state – as for instance proposed in [20]. Binding of modulator proteins can be considered as input to this state automaton.

holds promise to directly uncover the effective degrees of freedom of the interacting protein ensemble. Recently, much progress has been made to determine the effective state-space dimension and the corresponding generalized states of such ensembles. The thread started with [2,5], where a linear projection of the species-based state- space is constructed, allowing for a self-consistent description of the dynamics on a lower dimensional state-space. The generalization of this approach to the automatic reduction of the differential semantics of any rule-based specification is done in [8]. The accompanying stochastic version of this reduction is given in [10]. All these approaches have in common that they start out by a description of the concrete, large state-space, which is then reduced through projection or aggregation methods. In our case, the description already is given in a symbolic, implicit form. We take a bottom-up approach and observe the effective degrees of freedom of each agent and construct its local state-space accordingly. Taking an agent-centric perspec- tive the degrees of freedom are all the different contexts the agent is involved in – agent views (although other definitions of views are available [6]). Thus, besides the above agent-centric modularization that encapsulates the agent’s internal logic, the approach yields a direct constructing of the reduced state-space. Consider the example shown in Fig. 2 that conveys the basic idea. It involves a scaffold protein that can simultaneously and independently bind two other proteins. Considering the rules in Fig. 2 we can determine what contexts the agent A encounters. Its views give rise to the set of states {A(b), A(ba.B)}× {A(xu), A(xp)}. We represent its views using a stochastic automaton and then couple the view-automata of different agents to automata network [16]. Such networks can sometimes be cast into a represen- tation as superposed generalized stochastic Petri-nets (GSPN) [12] - a collection of Petri-subnets that share transitions but no places. The case of example Fig. 2 is illustrated in Fig. 3, where the stochastic automaton is shown for the case of a single copy number per agent and the Petri-net representation for an arbitrary marking is given. We recognize that due to the independence between binding and


R1 :	A(b), B(a) −~7− A(b1), B(a1)
R2 :	C(b), B(c) −~7− C(b1), B(c1)
R3 :	A(xu) −~7− A(xp)
R3 :	C(yu) −~7− C(yp)
Fig. 2. Scaffold protein B recruits independently the proteins A and C (left). For the sake of illustration we assume that the latter two are phosphorylated and dephosphorylated spontaneously. Kappa syntax [7] to express this interactions (right).
modification the view-automaton in Fig. 3 can be constructed as automata product of two smaller automata obtained from their respective rules R1 and R3. In this ex- ample, the view-automata states are equivalent to the states expressed in fragments obtained by [10]. Mapping a rule-based specification to a network of stochastic au-

Fig. 3. Stochastic view-automata network for agent A and partially shown for agent B (left); drawn for one copy number per agent. Only transitions with the same label across different automata are synchro- nized.Corresponding Petri-net representation where view-nets share transitions but no places.
tomata allows one to use the compositional methods developed for such networks [3]. Furthermore, we can exploit the compositional structure to obtain an expression for the generator matrix of the network’s continuous-time Markov chain involving the Kronecker sums of the generator matrices of the individual automata [16,3]. The first use of stochastic automata networks to describe stochastic chemical kinetics can be found in [22]. The work considers a species-based state-space and associates a counter automaton with each species.
The remaining part of the work is organized as follows. In Section 2, the site graphs and their encoding as a valuation over a set of Boolean variables is presented. The encoding is inspired by how the site-graphs are defined in Kappa [7]. Section 3 continues the formalism by defining a rule and a rule-based system. Each rule-based system accompanied with the initial conditions is assigned the (continuous-time) stochastic semantics by the interpreted labelled transition system (referred to as ILTS from now on). Furthermore, agent-view and population-view projections are defined.
The main result is stated in Section 4, where we propose when and how the ILTS of a rule-based system can be represented as a composition of smaller ILTS,

each corresponding to a subset of rules. The decomposition criterion is derived by analysing the set of variables that appear in each rule. Based on that agent- centred compositional approach Section 5 makes use of the explicit construction of the Markov chain generator available for stochastic automata networks. The procedure is outlined using the simple scaffolding example of Fig. 2. Conclusions are drawn in Section 6.
A simple agent-based framework
We build a formalism on the rule-based language Kappa [7]. The main data struc- ture which we use to describe the structure of the protein network, and to encode the reaction mixture are site graphs. Whereas standard graphs are a pair structure defined by a set of nodes and a set of edges formed over pairs of nodes, site-graphs have a slightly richer structure: each node is defined by (i) its name, (ii) a set of sites with internal state, and (iii) a set of binding sites of that node; The edges are then established, not between the node names, but between a pair of binding sites, each belonging to a different node.
Definition 2.1 (Site graph) Consider a set of agent names A and a set of site names S. Site graph is a pair G = (V, E ) where the set of nodes are triples of an agent name, the set of its internal and the set of its binding sites, ie
V ⊆ {(A, Σint, Σl) | A ∈ A; Σint, Σl ⊆ 2E}, and edges are pairs of sites:
E ⊆ {((A, s), (Aj, sj)) | (A, Σint, Σl), (Aj, Σintj, Σj) ∈ V,s ∈ Σl, sj ∈ Σj}.
l	l
Having a node (A, Σint, Σl), the collection of sites of the agent A, ie Σint ∪ Σl, is sometimes referred to as the interface of agent A, and is denoted Σ(A). When we model the protein interaction network with a site graph, a set of agents A represents a set of protein names and a set of sites S denotes the different relevant amino acid residues of the protein. The site graph which summarizes the protein names and their possible bindings in a model of a protein network we call a contact map (CM in further text).
Example 2.2 (Fig.2 revisited) The contact map is a site graph (V, E ) with agent names A  =  {A, B, C} and site names S  =  {a, b, c, x, y};  Set of nodes is V = {(A, {x}, {b}), (B, ∅, {a, c}), (C, {y}, {b})}, and edges E =
{((A, b), (B, a)), ((B, c), (C, b))}.
Moreover, given the contact map and agents’ multiplicities n : A→ N0, we define the full contact map as a site graph where each agent name A ∈ A is instantiated n(A) times, so that each copy of the agent is identified by a number in its subscript – copies are assigned names A1,..., An(A). Bonds are generated between any (Ai, s) and (Aj , sj) such that the bond existed between (A, s) and (Aj, sj) in the contact map. Formally, a full CM over a CM (V, E ) with agent names A and S is a site

graph (Vj, Ej) with agent names Aj and site names S, such that Aj = {Ai | A ∈ A,i = 1, .., n(A)}, and
if (A, Σint, Σl) ∈ V, then (Ai, Σint, Σl) ∈ Vj, for i = 1,..., n(A) and the set of edges Ej is such that if ((A, s), (Aj, sj)) ∈ E , then
((Ai, s), (Aj , s)) ∈ Ej for all i = 1,..., n(A), j = 1,..., n(Aj).
Example 2.3 (Fig.2 revisited) For n(A)  =  1, n(B)  =  2, n(C)  =  1, we get the full contact map (Vj, Ej), where Aj  =  {A1, B1, B2, C1}, and Vj  = {(A1, {x}, {b}), (B1, ∅, {a, c}), (B2, ∅, {a, c}), (C1, {y}, {b})}, and Ej  =
{((A1, b), (B1, a)), ((A1, b), (B2, a)), ((B1, c), (C1, b))((B2, c), (C1, b))}.
If we model a protein interaction network, we need to represent a reaction mix- ture at a certain time point. A full contact map is a summary of which sites appear on which agent, but it does not tell us what is the value of the internal state; More- over, the bonds specified in the site graph are potentially formed, but they may or may not exist in a reaction mixture. In other words, given a site graph, there are several mixtures which correspond to that site graph, depending on the internal states of internal sites, and depending on which bonds are present in the mixture. For simplicity we assume that the internal states can take exactly two values and we assign a set of Boolean variables to a full contact map, such that one valuation of these variables encodes a reaction mixture. One variable is spent per each agent’s site, and one variable is spent per each edge:
V ar(U,£) ∼= {(A, s) | (A, Σint, Σl) ∈V and s ∈ Σint ∪ Σl}∪ E.

Each of the site variables is represented by a letter a with the corresponding agent– site name combination in its subscript. We use letter b indexed by the bond descrip- tion for the binding variables. The set of variables which refer to agent A ∈ A we denote by V arA. Any valuation of the variables from the set V ar(U′,£′) to Boolean values sets the internal states of agents to a value ‘on’ or ‘off’, and the bond variables respectively.
Given the full CM (Vj, Ej) which is derived from the CM (V, E ), and agents’ mul- tiplicities n : A→ N0, we observe the set of variables V ar(U′,£′) and the valuations
V al(U′,£′) = {x | x : V ar(U′,£′) → {0, 1}}.
Example 2.4 (Ex.2 revisited). Let us set n(A)= 1, n(B)=2 and n(C)= 1. We have that
V ar = {a(A1,x), a(A1,b), a(B1,a), a(B1,c), a(B2,a), a(B2,c), a(C1,b), a(C1,y),
b((A1,b),(B1,a)), b((A1,b),(B2,a)), b((B1,c),(C1,b)), b((B2,c),(C1,b))}.

The state x1 = (0, 1, 1, 1, 0, 0, 1, 1; 1, 0, 1, 0) represents the mixture shown in Fig. 5b).


	
Fig. 4. a) A full contact map for Ex.2 and agent multiplicities n(A) = 1, n(B) = 2, and n(C) = 1; b) One reaction mixture corresponding to the state x1 = (0, 1, 1, 1, 0, 0, 1, 1; 1, 0, 1, 0) ∈ V al. An internal state being set to 1 (ie x(b(C1 ,y)) = 1) is marked by highlighting the circle which represents this internal state in green colour.
However, not all valuations will describe one valid reaction mixture. Firstly, there can be no two bonds stemming from one site of identified agent’s site: for any node (Ai, Σint, Σl) ∈ Vj, and its binding site s ∈ Σl, there can be at maximum one bond established from the site (Ai, s). Secondly, the existence of the bond, let’s say ((Ai, b), (Bj, a)) ∈E will be reflected in the valuation doubly: the variable b((Ai,b),(Bj,a)) will be set to 1, but as well, the variables a(Ai,b) and a(Bj,a) will be set to 1. The valuations which describe one valid reaction mixture we call ‘well-defined’.

Definition 2.5 (Well-deﬁned valuation) The valuation x ∈ V al is well-defined if
Ai∈A′,s∈E |{(Ai, s) such that   A′∈A,s′∈E x(b((Ai,s),(A′ ,s′)))= 1}| ≤ 1, and
x(b((A,s),(A′,s′))) = 1 if and only if x(a(A,s))=1 and x(a(A′,s))= 1.
Example 2.6 (Ex.2 revisited) The valuation x2 = (0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1) is not well-defined because b((B2,c),(C1,b)) = 1, but a(B2,c) = 0. Moreover, the valuation x3 = (0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1) is neither well-defined because there are two bonds stemming from the site (C1, b).
One may wonder why we encode each bond two times, in the sense that the existence of the bond ((Ai, s), (Aj , sj)) can be concluded from a(A ,s) = a(A′ ,s′) = 1.
j	i	j
Let us go back to the Ex. 2, and assume that we have two copies of agent A,
and two copies of agent B, ie n(A) = n(B) = 2, and that there are all bound, ie x(a(A1,b))= x(a(A2,b))= x(a(B1,a))= x(a(B2,a)) = 1. However, we may have either bonds between A1, B1 and A2 and B2, or between A1, B2, and A2, B1. We use the bond variables b((A1,b),(B1,a)),.. ., to avoid this ambiguity.
Rule-based model
The transformation kernel for the ensemble of agents that we observe is defined by a set of rules. A rule is defined over the set of variables which correspond to a contact map (V, E ), ie V ar(U,£), and it consists of the left-hand-side (lhs in further text) and the right-hand-side (rhs in further text), which are propositional formulae over the variables from the set V ar(U,£). We will think of a rule in the following way: the left-hand-side of the rule, α, defines the precondition for the event to occur. The right-hand-side, αd, defines an update of the valuation, which is a finite composition of the following atomic operations: (i) ‘switch’ of an internal state variable, ie

α ≡ ¬a(A,s) and αd ≡ a(A,s), (ii) change of a pair of variables from free to bound state or vice versa (binding/unbinding), ie α ≡ ¬a(A,s) ∧¬a(A′,s′) ∧¬b((A,s),(A′,s′)) and αd ≡ a(A,s) ∧ a(A′,s′) ∧ b((A,s),(A′,s′)). We restrict to the case where there is no birth, nor deletion of an agent. We also assume that there is at maximum one occurence of the same agent name in a rule. Note that both these constraints are a restriction with respect to the Kappa language – Kappa does support more occurences of the same agent name in one rule. The set of variables appearing in rule R, we denote by V arR.
Definition 3.1 (Rule) Consider the set of propositional formulae P over variables
V ar(U,£) (denoted also P(U,£)), generated by the grammar p ≡ 0 | 1 | a ∈ V ar(U,£) |
¬p | p ∧ p. We denote by V arp the set of variables that occur in proposition p, and the satisfaction region of formula p by Jp) = {x | x |= p}. A rule is a triple (α, αd; k) ∈P × P × R0, such that V arα = V arαd .
We remark that the rules are defined over the contact map, and the agents’ multiplicities are not mentioned. We observe the set of variables V ar(U′,£′) over the full CM (Vj, Ej) which is derived from the CM (V, E ), and agents’ multiplicities n : A→ N0. Each rule over the variables V ar(U,£) generates a set of rules over the variables V ar(U′,£′), where the agents’ identifiers are specified: instead of a single rule R, we observe a family of rules {RidA=i}A∈A;i∈{1,...,n(A)}, where each agent A is assigned a unique identifier idA ∈ {1,..., n(A)}. Such set of rules we call identiﬁed rules, and we denote Rid.
Example 3.2 (Ex.2 revisited). The rules described in Fig.5 rewritten in this frame- work are
(R1) ¬a(A,b), ¬a(B,a), ¬b(A,b),(B,a) → a(A,b), a(B,a), b(A,b),(B,a)
(R2) ¬a(C,b), ¬a(B,c), ¬b(C,b),(B,c) → a(C,b), a(B,c), b(C,b),(B,c)
(R3) ¬a(A,x) → a(A,x)
(R4) ¬a(C,y) → a(C,y),

where we write a rule r = (α, αd; k) in the form α → αd (we do not write rates where it is not necessary for the illustration purpose). Setting the agent multiplic- ities on n(A) = 1, n(B) = 2 and n(C) = 1, the rule (R1) has the following two instantiations:
(R1idA=1,idB =1) ¬a(A ,b), ¬a(B ,a), ¬b(A ,b),(B ,a) → a(A ,b), a(B ,a), b(A ,b),(B ,a)
(R1idA=1,idB =2) ¬a(A ,b), ¬a(B ,a), ¬b(A ,b),(B ,a) → a(A ,b), a(B ,a), b(A ,b),(B ,a).

Definition 3.3 (Rule-based system) A rule-based system B = (V, E, n, R, p0) over the set of agents A and set of sites S is defined by (i) a full contact map (Vj, Ej) over the contact map (V, E ) and initial agent multiplicities n : A→ N0, (iii) a set of rules R = {R1,..., Rm} defined over the contact map (V, E ), (iv) an initial mixture expressed by the proposition p0 ∈ P(U,£). A set of rules is well-deﬁned if each of the rules is well-defined.

We will define the semantics of a rule-based system by the transition system with a countable state space. Each state is assigned one or several reaction mix- tures, expressed by a propositional formula over variables V ar(U′,£′); Transitions are labelled by the name of the rule which defines it.
Definition 3.4 (Labelled transition system) A labelled transition system is a tuple
M = (S, L, δ, S0), where
S is a set of states,
L is a set of labels,
δ : S × L → S is a transition function that maps a state and a label to another state,
S0 ⊆ S is the set of initial states,

A trace of M of length k is a sequence s0
l1,t1
→ s1
→	→ s

k−1
lk,tk
sk
∈ S × (L ×

R × S)k, such that δ(sj−1, lj)= sj, j = 0, 1,...,k and s0 ∈ S0.
Definition 3.5 (Interpreted labelled transition system – ILTS) Given a labelled transition system M = (S, L, δ, S0), a set of variables V ar, and set V al of well- defined valuations over these variables, each state is interpreted by a set of valua- tions, given by L : S → 2V al. Such a system we call an interpreted LTS, and we denote by ML. We say that the ILTS ML is well-deﬁned, if for all s, sj ∈ S we have that L(s) ∩ L(sj) = ∅, i.e. the valuation sets assigned to different states must be disjoint.

The cylinder of traces r = s0
l1,I1
→ s1
→	→ sk−1
lk,Ik
sk
∈ S × (L × IR × S)k

denotes a set of all traces which start by the given sequence of k transitions, and
each transition happens within the interval of time indicated on the arrow. The

initial distribution is such that, if s ∈ S0, then π0(s) =  1 
(we use notation |·| 

to denote the cardinality of a set), and otherwise π0(s) = 0. The probability of the cylinder of traces r is given by the expression


π(r)= π0(s0) ·



j =1
a(sj−1, lj, sj) a(sj−1)

·  e−a(sj−1)·inf(Ii) − e−a(sj−1)·sup(Ii)  ,


where a(sj−1, lj, sj) is the activity of the transition from state sj−1 to state sj via label lj and within Ij interval of time, which will be specified depending on the set of rules which the ILTS models.. The total activity of state sj−1 is a sum a(sj−1)=  {a(sj−1, lj, sj) | lj ∈ L, sj ∈ S}.
Given a rule-based system B, we interpret its semantics by assigning it the ILTS ML. Then we say that ML models the rule-based system, written ML |= B. Roughly speaking, we relate each state of the ILTS with the interpretation, so that the assigned valuations describe the reaction mixture, either by identifying each of the agents, or at a certain level of abstraction. Moreover, the transitions are labelled by the rule which enables the transition. The origin of the transition is the state whose interpretation satisfies the left-hand-side of the rule, and the activity is

proportional to the rate of that rule.
Definition 3.6 (Full ILTS which models the rule-based system) Given a rule-based system B = (V, E, n, R, p0) defined over the set of agent types A and set of sites S. We construct the ILTS ML that has as many states as many valuations there are in the set V al(U′,£′), and each state is interpreted with a set with exactly one valuation. Such an ILTS is well-defined, since the intersection between any two satisfaction sets is trivially empty. The initial states are the states whose valuation satisfies Jp0) 4 . The set of labels is the set of identified rules. The transition is labeled with R between the states s such that L(s)= {x} and sj, such that L(sj)= {xj} if and only if x and xj are such that x ∈ Jα) and xj ∈ Jαd), and they evaluate all the variables that are not mentioned in the rule R to the same value; Moreover, the activity is given by a(s,j Rj, sj) = k(R). If this holds for all rules R ≡ (α, αd; k) ∈ Rid, then we say that the transition system M = (S, L, δ, S0) models the set of rules Rid in interpretation L, written ML |= Rid.
Such an ILTS has dynamics which coincides to the standard way of defining stochastic chemical kinetics over a continuous-time Markov chain [11],[1], [9].

Example 3.7 (Fig.2 revisited) There are 36 different well-formed valuations of the variables for this example: there are 9 ways to set the bonds: one where there are no bonds, four different valuations which encode for a mixture with one bond, and four different valuations which encode for mixtures with two bonds. Moreover, any of these configurations may be encoded with in four different ways, depending on the values of internal states of A1 and C1, ie the valuations of variables a(A1,s) and a(C1,s). This makes in total (1 + 4 + 4) · 4 = 36.

Definition 3.8 (Agent-view) Given a rule-based system B = (V, E, n, R, p0) defined over the set of agent types A and set of sites S, let RA be the subset of rules R, such that for all R ∈ RA, it holds that V arR ∩ V arA /= ∅. The full ILTS over the subset of rules RA we call the agent-view of agent A.
We acknowledge that, due to the fact that the rule-set is closed under permuting the identifiers of the agents, we may define a population-based ILTS which models the rule-based system.
Definition 3.9 (Population-based ILTS which models the rule-based system) Given a rule-based system B = (V, E, n, R, p0) defined over the set of agent types A and set of sites S. We construct the ILTS ML that has as many states as many valuations there are in the set V al(U′,£′) partitioned by the equivalence relation ∼⊆ V al(U′,£′) × V al(U′,£′), which identifies all the states up to the permutation over the identifiers



4 note that p0 is defined over the set of variables V arV,E , whereas the valuations assigned to states are over the variables V arV',E' . We think of it along the lines of how the propositions which appear in rules are instantiated when agent multiplicities are given;




b)



Fig. 5. (a) Representation of a view of agent A for the set of rules Y = {R1, R2}; (b) Population-based ILTS which models rule R1 in Ex.2.
of agents of the same type:
x ∼ xj if there exists a permutation
σ : {1,..., n(A)}A∈A → {1,..., n(A)}A∈A such that
for all i, x(a(A ,s))= xj(a(σ(A ),s)).
We set S ≡ V al/~. Each state is assigned a set of valuations which belong to this equivalence class. Let us denote by [x, α] the number of different instantiations of identifiers of variables in V arα, such that x |= αid 5 . The set of labels is the set of rules without identifiers, ie L = R. Two states x1~, x2~ ∈ V al/~ are connected by a label R that corresponds to the rule R ≡ (α, αd; k), if and only if the representative of the class x1~ satisfies the left-hand-side condition of the rule R, and the rate assigned to the label R ∈R is equal to k(R) · [x1, α].
Example 3.10 (Fig.2   revisited)   Let   us   observe   the   valuations
x   =	a(A1,x) b((A1,b),(B1,a)) b((B2,c),(C1,b)) a(C1,y)  ,   and   xj	=
0	1	1	1
⎛

a(A1,x) b((A1,b),(B2,a)) b((B1,c),(C1,b)) a(C1,y)⎞

6 . It holds that x ∼ xj, because we

⎝	0	1	⎛	1	1	⎠

A1 B1 B2 C1⎞
have a permutation σ	, such that x(a

) = x(a

) for all

⎝A1 B2 B1 C1⎠
(Ai,s)
(σ(Ai),s)

A ∈ A, and i = 1,..., n(A). The equivalence class whose representative is x and xj can be described as ‘one dimer consisting of agents A and B and one dimer consisting of agents B and C’. If this state is named s, then we assign it the interpretation sets L(s) = {x, xj}. There are 20 states in the population-based ILTS which models the system in the example – there are 5 ways to set the bonds: one where there are no bonds, two different valuations which encode for a mixture with one bond (either a complex is formed between agents of type A

5 Think of having a rule were α ≡ чa(A,x) and agents A1 and A2; then the cardinality [x, α] may be 0, 1 or 2, depending on how many A’s are free.
6 we do not mention each agent’s bond variables, since it is clear from context

and B, or between agents of type B and C), and two different valuations which encode for mixtures with two bonds (either one trimer with A, B and C, and one B is free, or two dimers are formed and no B is free). This observation leads to the ’population-based’ semantics of the agent ensemble, which is the standard description.
Model decomposition
The state space of a full ILTS which models the rule-based system grows proportion- ally to the number of variables over its full contact map, which grows combinatorialy in the number of agents and the complexity of their interfaces. We propose to define it as a composition of smaller ILTS. We start by an ILTS which models each rule separately, and then we define a composition operator over them. In other words, we decompose the ILTS as a standard product of the set of smaler ILTS.
Definition 4.1 (Cross-product of two ILTS) Given two ILTS: M1,L1 = (S1, L1, δ1, S01 ), with a set of variables V ar1, valuations V al1 and an interpreta- tion over states L1, and M2,L2 = (S2, L2, δ2, S02 ), with V ar2 and V al2 and L2, such that L1 ∩ L2 = ∅, and V ar1 ∩ V ar2 = ∅. We define the product ML = (S, L, δ, S0), written ML = M1,L1 × M2,L2 in the following way:
S = S1 × S2,
L = L1 ∪ L2,
δ((s1, s2), l)= (δ1(s1, l), δ2(s2, l)), for any l ∈ L,
(s1, s2) ∈ S0 iff s1 ∈ S01 and s2 ∈ S02 (i.e. S0 = S01 × S02 ).
Moreover, we set V ar = V ar1 ∪ V ar2, and we interpret the pair of states by the intersection of valuation sets of each of them:
L((s1, s2)) = L1(s1) ∩ L2(s2).
We can also see the ILTS M1,L1 (resp. M1,L1 ) as a projection of the ILTS ML to the set of variables V ar1 (resp. V ar2), and we may write M1,L1 = ML|V ar1 .
The only constraint for two ILTS to be composed by a cross-product is that they are defined over the mutually disjoint sets of variables and mutally disjoint sets of labels.
Proposition 4.2 (Decomposing ILTS) Given a rule-based system B  = (V, E, n, R, p0) defined over the set of agent types A and set of sites S. Let ML be the full ILTS which models Rid. If we can partition the set of rules into classes R1,. . . ,Rm, such that R = R1 ∪ ... ∪ Rm, and each two classes have mutually disjoint sets of variables, then ML can be decomposed in the following form:
m
ML =	MiLi ,
i=1
id
where for all i = 1,... m, the ILTS Mi,Li models R .


	

ML|V arR	ML|V arR
Fig. 6. Decomposition: ML = ML|V arR1 × ML|V arR2 × ML|V arR3 × ML|V arR4 .
Example 4.3 (Fig.2 revisited) The sets of variables which appear in each of

the rules are V ar idA=1,idB =1
1
= {a(A1,b), a(B1,a), b((A1,b),(B1,a))}, V ar idA=1,idB =2 =
1

{a(A1,b), a(B2,a), b((A1,b),(B2,a))},  V ar  idB =1,idC =1
2
=  {a(B1,c), a(C1,b), b((B1,c),(C1,b))},

V ar idB =1,idC =1
2
=	{a(B1,c), a(C1,b), b((B1,c),(C1,b))},	V ar idA=1
3
=	{a(A1,x)},

V ar idC =1 4
= {aC1,y}. Not all of them are mutually disjoint, but we can group

the sets of variables into the following disjoint classes: V arR1 = V ar idA=1,idB =1 ∪
1
V arRidA=1,idB =2 , V arR2 = V arRidB =1,idC =1 ∪ V arRidB =2,idC =1 , V arR3 = V arRidA=1 ,
1	2	1	3
V arR4 = V ar idC =1 .
4
We build the four ILTS which models each of these classes of variables: ML1 |=
{RidA=1,idB =1, RidA=1,idB =2}, and similarly ML , ML , ML . The ILTS ML which
1	1	2	3	4
models the rules Rid is the following composition:


ML = ML1 × ML2 × ML3 × ML4 .
ML is well-defined ILTS, and its projections are ML1 = ML|V arR


, ML2 = ML|V arR ,

ML3 = ML|V arR
, and ML4 = ML|V arR .

Constructing the generator
If we equip the ILTS that models a rule-based system with a stochastic semantics according to a continuous-time Markov chain, each ILTS that models a single rule can be thought of as a stochastic automaton and the composition thereof as a stochastic automata network. We introduce the construction of the generator by revisiting the example discussed in Fig. 2. Analyzing the rule-set and considering Proposition 4.2 we conclude that the variable sets are disjoint and we showed the network of four ILTS projections in Fig. 6 for the case n(A)= n(C) = 1, and n(B)= 

2. We compose the generator matrix Q of the network of stochastic automata out of elementary matrices that are derived from the individual automata. Consider a network composed of ILTS {M1,..., Mm}. Each ILTS Mi is characterized by a set of transitions labeled from the set Li. For instance, for the network in Fig. 6
we have L1 = {RidA=1,idB=1, RidA=1,idB=2, R−idA=1,idB=1, R−idA=1,idB=2}. For each
1	1	1	1
automaton Mi and label l ∈ Li, we define an elementary rate matrix Ei, the element
Ei(j, k) of which denotes the rate of exiting state j to state k by transition l in automaton Mi. Finally, to ensure zero row-sum of the generator we design a matrix Di = diag(Eie), with unit vector e. According to [16,3] the generator can then be
l	l
expressed as

m	m
Q =  Σ Ei −  Σ Di
l	l
i=1 l∈Li	i=1 l∈Li
where we use the symbol ⊕ to denote the Kronecker sum [19]. The composition includes only the Kronecker sum, which is known to correspond to the classical composition of independent continuous-time Markov chains. We restrict to the case of independent ILTS (there are no synchronized transitions between the small automata), so the part which involves the Kronecker product operator does not appear in the expression.
Example 5.1 (Fig.2  revisited)  Going  back  to  Fig.  6  and  exem-
1
plify	the	construction	for	the	projection	ML|V arR	we	have	L	=
{RidA=1,idB=1, RidA=1,idB=2, R−idA=1,idB=1, R−idA=1,idB=2}	with	state	space
1	1	1	1
S = {s1, s2, s3}. The elementary matrices then become


EM1
=  0 k1 0 ,	EM1
=  0 0 k1 ,



and


EM1

0 0 0
=	k− 0 0  ,	E 1

=  0 0 0  ,

−idA=1,idB =2
1
with Ei = I for l ∈/ Li.
1
0 0 0
−idA=1,idB =2
1
k− 0 0 

Let us discuss another example, where we review the construction proposed in Section 4. Consider a kinase K can that bind a substrate S and phosphorylate its two modification sites s2 and s3 independently. In Kappa syntax that is to say


c+
R :	K(k ), S(s ) −~1
K(k1), S(s1)

1	1	1  7−
—
1
c+

R  :	K(k1), S(s1, su) −~2  K(k1), S(s1, sp)
(1)

2	1	1	7−	1	1	2
2
c+
R  :	K(k1), S(s1, su) −~3  K(k1), S(s1, sp).
3	1	1	7−	1	1	3
3

Starting out with considering the sets of variables which appear in each of the rules R1, R2 and R3, since they are all having non-empty mutual intersection, we cannot apply the decomposition of the ILTS which models all the rules, proposed in Prop. 4.2. Consequently, the agent-views of each of the agents expose and determine the complete interface of every agent, which equivalent to saying that the views are fully specified species. The effective degrees of freedom of this system, taking aside mass-conservation relations, is thus equal to the number of distinct reachable species.


Conclusions
The paper proposes a natural approach to describe the stochastic interactions of highly structured molecular agents. Each agent is associated a stochastic automa- ton, which describes the degrees of freedom, views of that agent. It allows for a bottom-up construction of the effective state-space. This modular representation comes at an expense: the product formulation overapproximates the reachable state space – however not the dimension of it. Naturally, the approach gets more appeal, the more local transitions per automaton there are, i.e., the richer the internal logic of an agent becomes.
We showed how to represent the generator matrix of the underlying Markov process of the whole rule-set as Kronecker sums of the rate matrices belonging to individual view-automata. The decomposition criterion is derived by analysing the set of variables that appear in each rule. One can understand the intuition behind the decomposition principle as taking advantage of the statistical independence of certain events. In reference to the rule-set of (1), we discuss in the following a future research direction, which promises further decomposition. Namely, to utilize the weaker notion of conditional independence to construct state spaces of reduced dimension. The two modification sites s2 and s3 in (1) are not statistically inde- pendent, i.e., the joint probability Pr(s2, s3) cannot be factorized. However, condi- tioning on the state s1 the events become independent. Using the product rule for conditional probabilities we have the identity Pr(s2, s3|s1)= Pr(s2|s3, s1)Pr(s3|s1). Independence means that conditioning the state s2 on s3 and s1 is the same as just conditioning on s1 alone. Thus, we have Pr(s2, s3|s1) = Pr(s2|s1)Pr(s3|s1). Let us consider a coarse-grained fragmentation that does not enumerate the site states s2 and s3 but just the site state s1. Then the reconstruction problem is, whether given Pr(s1) we can reconstruct the joint Pr(s2, s3, s1). Accounting for the dependency structure at hand, we have Pr(s2, s3, s1) = Pr(s2|s1)Pr(s3|s1)Pr(s1) and we are left with defining the two conditional distributions. The number of such modification events follow a Poission law. Thus, the modification states s2 and s3 can be recovered from knowing s1. Clearly, in situation where the substrate S in
(1) has multiple independent phosphorylation sites, the presented decomposition
would be exponentially larger than the one which exploits conditional, and not full independence.

References
Baier, C., B. Haverkort, H. Hermanns and J.-P. Katoen, Model-checking algorithms for continuous-time Markov chains, IEEE Transactions on Software Engineering 29 (2003), p. 2003.
Borisov, N. M., N. I. Markevich, J. B. Hoek and B. N. Kholodenko, Signaling through receptors and scaffolds: Independent interactions reduce combinatorial complexity, Biophys J 89 (2005), pp. 951—966.
Buchholz, P. and P. Kemper, Kronecker based matrix representations for large Markov models, in:
Validation of Stochastic Systems, Lecture Notes in Computer Science 2925, 2004, pp. 256—295.
Changeux, J.-P. and S. J. Edelstein, Allosteric mechanisms of signal transduction, Science 308 (2005),
pp. 1424–1428.
Conzelmann, H., J. Saez-Rodriguez, T. Sauter, B. N. Kholodenko and E. D. Gilles, A domain oriented approach to the reduction of combinatorial complexity in signal transduction networks, BMC Syst Biol 7 (2006).
Danos, V., J. Feret, W. Fontana and J. Krivine, Abstract interpretation of cellular signalling networks,
, 4905, 2008, pp. 42–58.
Danos, V. and C. Laneve, Core formal molecular biology, Theoretical Computer Science 325 (2003),
pp. 69–110.
Feret, J., V. Danos, J. Krivine, R. Harmer and W. Fontana, Internal coarse-graining of molecular systems, Proc. Natl. Acad. Sci. USA 106 (2009), pp. 6453–6458.
Feret, J., T. A. Henzinger, H. Koeppl and T. Petrov, Lumpability abstractions of rule-based systems, MeCBIC (2010), pp. 142–161.
Feret, J., H. Koeppl and T. Petrov, Stochastic fragments: A framework for the exact reduction of the stochastic semantics of rule-based models, International Journal of Software and Informatics in press (2010).
Gillespie, D. T., Exact stochastic simulation of coupled chemical reactions, J Phys Chem 81 (1977),
pp. 2340–2361.
Kemper, P., Numerical analysis of superposed GSPNs, IEEE T Software Eng 9 (1996), pp. 615–628.
Mori, T., D. R. Willams, M. O. Bryne, X. Qin, M. Egli, H. S. Mchaourab, P. L. Stewart and C. H. Johnson, Elucidating the ticking of an in vitro circadian clockwork, PLoS Biol 5 (2007), pp. 841–853.
Nakajima, M., K. Imai, H. Ito, T. Nishiwaki, Y. Murayama, H. Iwasaki, T. Oyama and T. Kondo, Reconstitution of circadian oscillation of cyanobacterial KaiC phosphorylation in vitro, Science 308 (2005), pp. 414–415.
Nishiwaki, T., Y. Satomi, Y. Kitayama, K. Terauchi, R. Kiyohara, T. Takao and T. Kondo, A sequential program of dual phosphorylation of KaiC as a basis for circadian rhythm in cyanobacteria, EMBO J 26 (2007), pp. 4029–4037.
Plateau, B., On the stochastic structure of parallelism and synchronization models for distributed algorithms, , 13, 1985, pp. 147–154.
Salazar, C. and T. H¨ofer, Multisite protein phosphorylation - from molecular mechanisms to kinetic models, FEBS J 276 (2009), pp. 3177–3198.
Smock, R. G. and L. M. Gierasch, Sending signals dynamically, Science 324 (2009), pp. 198–203.
Van Loan, C. F., The ubiquitous kronecker product, Comput Appl Math 123 (2000), pp. 85–100.
van Zon, J. S., D. K. Lubensky, P. R. H. Altena and P. Rein ten Wolde, An allosteric model of circadian KaiC phosphorylation, Proc Natl Acad Sci USA 104 (2007), pp. 7420–7425.
Walsh, C. T., “Posttranslation Modification of Proteins: Expanding Nature’s Inventory,” Roberts and Co. Publisher, 2006.
Wolf, V., Modelling of biochemical reactions by stochastic automata networks, Electron. Notes Theor. Comput. Sci. 171 (2007), pp. 197–208.
