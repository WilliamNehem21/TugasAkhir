 Electronic Notes in Theoretical Computer Science 99 (2004) 111–126 
www.elsevier.com/locate/entcs




Applying Generalized Non Deducibility on Compositions (GNDC) Approach
in Dependability

S. Gnesi, G. Lenzini 1
Istituto di Scienze e Tecnologie Informatiche - C.N.R. Via G. Moruzzi 1, I-56100 Pisa, Italy

F. Martinelli 2
Istituto di Informatica e Telematica - C.N.R. Via G. Moruzzi 1, I-56100 Pisa, Italy


Abstract
This paper presents a framework where dependable systems can be uniformly modeled and de- pendable properties analyzed within the Generalized Non Deducibility on Compositions (GNDC ), a scheme that has been profitably used in definition and analysis of security properties. Precisely, our framework requires a systems to be modelled using a formal calculus, here the CCS process algebra, where both the failing behaviour of the system and the related fault-recovering procedures are also explicitly described. An environment able to inject any fault in the system is then defined as a separated component. The parallel composition between the system and the environment represents our scenario of analysis, where some fault tolerance property (e.g., fail stop, safe and silent) are studied as instances of GNDC properties. By using different instances of GNDC we are able to argue about the availability of effective methodologies of analysis, and on the possibility of applying compositional techniques.
Keywords: Dependability, Fault Tolerance, Security, Non Interference, Formal Verification.



1 Email: {stefania.gnesi, gabriele.lenzini}@isti.cnr.it
2 Email: fabio.martinelli@iit.cnr.it


1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.02.005

Introduction
This paper exploits relationships between mechanisms for dependability anal- ysis and those for security in a formal framework. More precisely it shows how fault tolerance analysis mechanisms can benefit of recent results in security analysis.
First ideas about a relationship between security analysis strategies and mechanisms of dependability analysis can be found in [14,15,10,21,22,25]. For example in a seminal paper [25], Weber found analogies between fault- tolerance specifications and non-interference [8] definitions. He also argued that the formal verification of fault tolerance faces with similar problems and benefits of same solutions as verification of security does. Analogies between non-interferences approaches in security and safety analysis can be found in [22]. Additional efforts in exploiting fault tolerant approaches for security analysis can be found for example in [7], where it is shown that fault toler- ance and integrity analysis can be both based on a non-interference notion. In [12], non-interference analysis has been shown to be similar to verification of open systems, i.e., when one needs to verify a system w.r.t. whatever possible execution environment (also named as robustness). Remarkably, the idea of applying dependability methodologies in security had been discussed by Meadows in [14], where she also argued that security analysis might be improved by incorporating techniques typical of reliability formal verification. On the other hand, Meadows and McLean also claim, in [15], that the use of emerging results in security analysis could enrich the taxonomy of fault prevention and removal strategies.
Anyway, as previous works seem to show, for long time security had ap- peared a restricted paradigm w.r.t the variety of approaches available in de- pendability. Most of the discussions in the literature have been based more on finding intuitions for security starting from the dependability background and experiences than the opposite. Along the last decade security has been studied in so deep details that contributions of security theory into dependability can be now more than in the past. For example we think that the non-interference notion, widely used in security analysis (e.g., see [4,3,13,20,24]), could be re- viewed in the dependability framework by considering the analysis techniques developed so far, for non-interference, in the security area.
Following this direction this paper intends to inquire about the application of the Generalized Non-Deducibility on Compositions (for short, GNDC ) for the analysis of dependable systems, with particular attention to fault tolerant ones. GNDC was first introduced in [6] as a framework where a family of security properties could be uniformly expressed and verified. It has never been applied to dependability so far. Anyway GNDC finds its roots in non-

interference analysis, whose intuitions has been claimed to share common ideas with some fault tolerance analysis strategies (e.g., see [7,23]). Generally speaking a GNDC property has the following form:


P satisfies GNDC α(P )
iff ∀X ∈ Env : (P  X) a α(P )	(1)

Informally it means that a system P enjoys GNDC α(P ) if and only if P shows,
w.r.t. a certain behavioral relation a, the same behaviour of α(P ). This must be true even if P is composed, by the parallel operator  , with any environment
X. Property (1) is parametric in a, a relation among processes representing the notion of “observation” and in α(P ), a specification which describes the expected behaviour of system P .
In this paper we will show how such a GNDC formulation can be exploited for expressing safety properties peculiar of the dependability analysis: fail stop, fail safe, fail silent. It constitutes a step towards a formal classification of dependable properties, similarly as it happened in security [5]. Moreover we will show how some of the theoretical results of GNDC , (e.g., compositional reasoning) originally stated for security analysis (e.g., see [5]), can be re-stated and re-used in the analysis of dependability.
The paper is organized as follows. Section 2 describes how a fault tolerant system may be modeled in CCS following a uniform modeling style. Section 3 introduces and explains the GNDC characterization of fault tolerance. Sec- tion 4 provides intuition about how properties, such as fail stop, silent, and safe can be expressed in the GNDC scheme. Section 5 discusses the problem of analyzing dependability. It shows how a GNDC characterization of fault tol- erance properties using trace-based behavioral equivalences, will enjoy some appealing properties in analysis such as effectiveness of analysis procedures and compositionality. Section 6 concludes the paper.

Modeling Fault Tolerant Systems
To model a system we will use a process algebra. Here we refer to the CCS [16], but our framework is completely general and it can be easily restated for other process algebras as well (e.g., , CSP [9] or π-calculus [19]).

CCS background
The CCS language assumes a set of communication actions to represent emit- ted signals or received ones. The special symbol τ is used to model any, unobservable to the environment, internal action. Assuming a set L of com- munication labels, Act = L∪ L is the set of visible actions (i.e., , actions and

co-actions), and Act τ = Act ∪ {τ } denotes the full set of possible communi- cation actions. We let a, b to range over Act τ . In summary the syntax of the language defining all CCS processes is the following grammar:
P, Q ::= 0	|	a.P	|	P + Q	|	P  Q	|	P \L	|	P [f ]	|	A
Informally 0 is the process that does not perform any action; a.P is the ac- tion prefix operator; P + Q can, non deterministically, choose between the behaviour the process P or that of the process Q;  is the parallel operator; P \L is the action restriction operator, meaning that the labels a ∈ L can only be performed within a communication. P [f ] is the re-labelling operator, renaming each label a into f (a). Finally we assume that every process iden- tifier A has a defining equation of the form A = P . The semantics of CCS is given operationally over labeled transition systems (see [16]), whose transi-
tion relation → defines the usual concept of derivation in one step: P →a  P '
means that process P , by executing action a ∈ Act τ , evolves in one step in the
process P ', while we write P →a  to underline that P can perform action a to
evolve in some process. We will write →∗ the transitive and reflexive closure

of  a∈Act τ
→a . In the following we will let Der(P )= {P '|P →
P '}, Sort(P )

is the set of labels used by P , and EF = {X : Sort(X) ⊆F ∪ {τ }}, where F
is a set of actions.
Specifying Fault Tolerant Systems
Using process algebras it is possible to provide a uniform framework for spec- ifying fault tolerant systems. For example in [1,2], a variant of the CCS was used to model a system, its failing behavior, its recovery strategies and its fault assumptions (i.e., assumption on the occurrences of faults); fault toler- ant properties expressed as logic formulas are verified on a finite state model of the system through model checking.
Here we will follow a similar modeling approach, but differently from [1,2] we will not require any specific fault assumption to be explicitly described in the formal model of the system. In fact we are mainly interested in evaluating the system behaviour in a general and unspecified faulty environment. In other words we look at the fault tolerant analysis as the analysis of an open system [13] acting in an environment which is potentially able to induce any fault in the system.
In the following, when talking about formal models of fault tolerant sys- tems, we will refer to the definitions below:
A system model is a CCS process P describing the behaviour of the system through the execution of actions. It is generally a parallel composition of sub-processes, each modeling sub-components of the system, communicating

each other. 
A failing system model is a CCS process PF , obtained by extending the process P with the possibility of executing particular external actions from a set F of possible fault actions. After each fault action, the relative failure mode is also specified in PF for example, by describing the behaviour induced by the occurrence of the fault. 
A fault tolerant (candidate) system model is a CCS process P # obtained by adding to PF some processes realizing error-recover strategies in accor- dance to some fault tolerant design strategy (e.g., copies of component, triple modular redundancy, voting etc.). In general the application of fault
tolerance techniques in modeling leads to a process P # which may be de-
scribed in the CCS notation as:
P # = (P (1)  ···  P (n)  Q) \A 
F	F	F

where (a) P (1) ... P (n) are n copies of P
composed together (b) Q is a

process representing additional components or an error detection module,
(c) A = {a1, ··· , an}, ai /∈ F, are the labels of synchronization actions between P (i)’s and Q. 
Occurrences of faults are induced by a fault-injector process FF , that causes faults to happen. It interacts with P # exactly through f ∈F actions. 
Previous definitions converge into the following scenario for fault tolerance analysis, where a system model and a fault injector are composed together:
scenario = (PF #  FF )\F	(2)
It is worth to remark that in (2) fault actions are hidden i.e., restricted. This implies that PF and FF have to synchronize on fault events. As a con- sequence faults are considered internal (i.e., not observable) actions of the failing systems. This means that our analysis lies at the abstraction level
where what it is really observable is only the (eventually faulty) behaviour of a system, but not the single occurrence of a fault. Thus in our framework, roughly speaking, fault tolerance means that faults cannot interfere with the normal observable behavior of the system.
Note that, differently from other approaches (e.g., [1]), we assume the faulty behavior is described in the system PF #, rather than also in the fault injector FF . This is the technical trick to encode fault tolerance analysis as non-interference analysis and, eventually, as the GNDC one.
Example 2.1 As a classic example, we will give a CCS model of a simple fault tolerant system. The basic component is a module Battery which naively

returns one slot of energy when it receives a request. For sake of conciseness we will write our example in a value passing style CCS, which is known to be a shortcut for CCS [16]. The actions get and ret are used to communicate module inputs and outputs:
Battery = get.ret(1).Battery
In modeling the corresponding failing module we assume that the battery, after having received a request, may crash and non-deterministically produce either a valid energy slot (1) or an invalid energy slot (0):
Batteryf = get.
(ret(1).Batteryf
+f. Σx∈{0,1}(ret(x).Batteryf ))
In accordance to our modeling framework, the fault is assumed to be caused by a special fault action f triggered by the environment. A fault tolerant battery may be, for example, designed by using redundancy with two batteries, with the additional modules of a splitter Splitter , and a controller Controller . We require the splitter to deliver the energy request to each of the two redundant instances, respectively Battery (1) and Battery (2), while we require the collec- tor to avoid an overloaded production of energy by absorbing the eventually additional slot. Formally, the two instances of the battery, and their faulty version are, for i ∈ {1, 2}:
Battery (i) d=ef Battery [get /get, ret /ret]
Battery (i) d=ef Battery [get /get, ret /ret]
f	f	i	i
The splitter and the controller are, for example, the following processes:
Splitter = get.get1.get2.ack.Splitter
Controller = ret1(x1).ret2(x2).if x1 then ret(x1).ack.Controller else ret(x2).ack.Controller
Note the action ack required for synchronizing the splitter and the con- troller. A resulting fault tolerant model of the battery Battery f #, may be obtained, for example, by inserting a single faulty module in the redundant solution (see also Figure 1):
Battery # d=ef (Splitter  Battery 1 
Battery 2  Controller ) \ {get , get ret1, ret2, ack}
f	1	2








get






ƒ
Fig. 1. The flow diagram of Battery f #. Internal action are in brackets.
The resulting scenario for the analysis of fault tolerance is the following:
scenario = (Batteryƒ #  Fƒ ) \ {f }

Fault Tolerance Characterization in GNDC
This section reports GNDC basic ideas and explains how fault tolerance prop- erties can be expressed within the GNDC scheme. From Section 1 we already know that a GNDC property has the following general form:


P satisfies GNDC α(P )
iff ∀X ∈ Env : (P  X) a α(P )

This scheme is general enough to implement a wide class of security prop- erty definitions. In fact for example, more specific security properties such as the Bisimulation-based Non Deducibility on Compositions (BNDC ), and the Trace Equivalence-based Non Deducibility on Compositions [3], can be subsumed as GNDC properties.
A first step required for instantiating GNDC in fault tolerance is to specify what P and Env are in this context. The former is a process P # obtained following the uniform modeling framework introduced in Section 2. The latter is the environment of all fault injectors (e.g., our fault assumption models), that is the set of CCS processes whose alphabet of actions is in F. Formally Env = EF = {X | Sort (X) ⊆F ∪ {τ }}. Then the general GNDC scheme we
propose for fault tolerance, is then the following:
Definition 3.1 [Fault Tolerance Characterisation in GNDC ]


P satisfies GNDC α(P )
iff ∀FF ∈ EF : (P #
FF ) \F a α(P #)	(3)

Let us observe that the clear separation between the system model and the environment made in (2) of Section 2 will allow us to leave FF unspecified

and to range it over EF .
Moreover the instantiation of GNDC in fault tolerance requires α(PF ) to be suitable in expressing some basic property of fault tolerance (e.g., fail safe, fail silent, fail stop). Finally we are interested in understanding what families of equivalences a can be suitable for the analysis of such properties. This
will be argument of the following sections, where we will write P instead of P # when no explicit reference to the specification framework of Section 2 is required.

Fault Tolerance Properties as Instances of GNDC
In this section we provide intuitions about how to express some interesting fault tolerance property within the GNDC scheme. Generally speaking prop- erties are modeled via a modified version α(P ), of P , representing the expected behavior P . For example if we assume a fail stop property, α(P ) has to ex- press a modified behavior of P in which any occurrence of a fault necessarily brings to a system stop. We assume that if P is a finite state processes, α(P ) must be finite state as well.
Fail Stop A model of a system P # is expected to be fail stop when in case of fault it switches in a stop state, eventually after having performed some internal actions. Intuitively α(P #) is the process whose expanded expres- sion (i.e., the tree obtained by unfolding the process term by applying the
expansion law [16]) is obtained by the one of PF by substituting every fault action (and relative sub-tree), with a silent action followed by the process
0. For example, referring to our example, we have that:
αstop(Batteryƒ ) = get.(ret(1).Batteryƒ + τ.0)
Fail Safe A model of a system P # is expected to be fail safe if in case of fault it switches in a safe state. In this case α(P #) is the process whose expanded expression is obtained from the one of PF by substituting every fault action (and relative sub-tree) with a silent action followed by some “safe behaviour” (e.g., a shutdown). For example we have that:
αsaƒe(Battery ƒ ) = get.(ret(1).Batteryƒ + τ.Psaƒe) where Psaƒe models a particular “safe” behavior.
Fail Silent A model of a system P # is expected to be fail silent if a fault is ignored. In this case the expanded expression of α(P #) is the one obtained from the one of PF after having substituted every fault action (and relative sub-tree) with a silent action followed by the subtree modeling the non-
failing behavior. In other words every fault occurrences and any successive

failing behaviors are replace by a silent action. For example we have:
αsilent(P ) = get.(ret(1).Batteryƒ + τ.Batteryƒ )
Fault tolerance A model of a system P # is expected to be fault tolerant if
its behaviour is observationally equal to the behaviour of the module that does not fail at all. In this case then αƒt(P #) = P # \ F, that is the fault
F	F
tolerant systems that can never execute any fault action.
Fault Tolerance Analysis Strategies in GNDC
This section provides deeper details about the analysis of fault tolerance in the GNDC scheme.
Weak Bisimulation in GNDC for Fault Tolerance
We can use weak bisimulation to verify a system model P # to be fault tolerant,
w.r.t. the fault tolerant properties previously described in term of α(P #). In fact, in case an external observer cannot see τ actions, a natural way of considering that two processes are equivalent is abstracting these actions from their behaviour while preserving the branching structure of the processes. Let
us consider the following relation between CCS terms: P =τ⇒ P ' if P −τ→ P ',

α
and P
' if
τ	α	τ
P '. We recall from [17] the definition of

=⇒ P	P −→∗−→−→∗
weak bisimulation (i.e., observational) between processes requiring that two
bisimilar processes are able to simulate each other step by step:
Definition 5.1 A symmetric relation B on E× E is a weak bisimulation if for each (P, Q) ∈B and for each a ∈ Act τ :

if P −a→ P ' then ∃Q' : Q =⇒a
Q' and (P ', Q') ∈B 

Two processes P and Q are bisimilar (written P ≈bisim Q) if a bisimulation B
exists such that (P, Q) ∈ B.
Weak bisimulation resorts to be useful to detect most of the safety prop- erties we have so far defined, namely fail safe, fail silent, fail stop and fault tolerance (expressed by, resp., αstop, αsilent, αsaƒe and αƒt). Some liveness prop- erties (e.g., deadlock freedom) may be caught too.
Moreover let us observe that the GNDC ’s instance where a is ≈bisim, and where α(P ) is αƒt(P #)= P # \F (i.e., exactly the “fault-tolerance” property),
F	F
is the BNDC re-stated in our fault tolerance framework. In fact

αft(P #)	#	#

P satisfies GNDC ≈
F
bisim
iff ∀FF ∈ EF : (PF 
FF ) \F ≈bisim PF
\F	(4)

and we remind the following
Definition 5.2 [[3]] P is BNDC iff ∀X ∈ EF : (P F X) ≈bisim P \F 
Proposition 5.3 ([6]) P is BNDC if and only if P is GNDC P \F  .
As a final observation let us discuss that BNDC is not compositional w.r.t. parallel composition (see [12]), that is from P, P ' ∈ BNDC it cannot be de- duced that P  P ' ∈ BNDC . This could be an undesirable properties in analysis. Anyway there are bisimulation based-equivalences that are compo- sitional (e.g., see SBSNNI in [3]) that implied BNDC , so that they could be used to prove sufficient condition for fault tolerance, and the formulation of fault-tolerance given in (4) results attractive from this point of view.
The use of SBSNNI is not the only way to obtain compositionality in anal- ysis. Alternative strategies for it may be obtained using different observational equivalence than weak bisimulation relation in (3) as we are explaining in the Section 5.2.2.

Other observational relations in GNDC for Fault Tolerance
Weak bisimulation resorts to be useful to detect most of the properties defined so far. Anyway let observe that in a practical situation we expect that many systems will be fault tolerant when weaker condition are satisfied. Generally it may be not a problem that one can deduce the existence of faults, so long the system behaviour response to those faults is “good enough”. For example, the definition of fault tolerance given in (4) seems too strong and prevents the observer to deduce that any faults have occurred. Out of deadlock detection, for the all safety properties defined in this paper the ability to distinguish the branching structures is not required or necessary, or even dangerous: in fact safety properties, that informally can be read [11] like “nothing bad can hap- pen”, require to be satisfied independently the (branching) path conducting to a fault. This makes us to resort to weak form of observational equivalences, such as trace equivalence and simulation that will also have, within GNDC theory, positive effect on compositionality and on avoiding the universal quan- tification of fault injectors over the faulty environment. In the following we will write P F Q as a shortcut for (P  Q) \F, and we will refer to a generic
α( ) function. Obviously the results will also hold for all α( )’s of our.
Most General (Faulty) Environment
The possibility of avoiding universal quantifier in expression (3) is based on the following theory about pre-congruences. We will say that a is a pre-congruence
w.r.t. F if for every P, P ', X, ∈ EF if P a P ' then P  F X a P '  F X. The

following results hold for pre-congruences:
Proposition 5.4 ([6]) Let be a a pre-congruence w.r.t.  F . If there exists a process Top ∈ EF such that for every process X ∈ EF we have X a Top, then:
P ∈ GNDC α(P ) iff (P F Top) a α(P )
In particular, if the hypothesis of the proposition above holds then it is sufficient to check that α(P ) is satisfied when P is composed with the most general environment, Top. In our fault tolerance analysis context it would permit to make only one single check, in order to prove that a fault tolerance property holds in every fault scenario. We have also the following corollary for the congruence induced by a:
Corollary 5.5 ([6]) Let a to be a pre-congruence w.r.t.  F and let da be deﬁned as a ∩ a−1. If there exist two processes Bot, Top ∈ EF such that for every process X ∈ EF we have Bot aX a Top then


P ∈ GNDC α
iff (P F Bot) da (P F Top) da α(P )

We show that whenever we are interested in properties based on the notion of trace equivalence, Proposition 5.4 and Corollary 5.5 hold.	Let
a
a = a1 ... an ∈ Act ∗ be a sequence of actions. We write P	' if and

only if there exists P ,... ,P 
∈E such that P  a1
a2	=a⇒n
P . Let be

1	n	=⇒ P1 =⇒ ...	n
F (P )= {a ∈ Act ∗ : ∃P ',P	a	'  the set of traces associated to a process
=⇒ P }
P . We have:
Definition 5.6 Let P and Q be two processes. Moreover Q can execute all the traces of P (written P ≤trace Q) if and only if F (P ) ⊆ F (Q). P and Q are said trace equivalent (written P ≈trace Q) if and only if F (P )= F (Q).
It is easy to prove that ≤trace is a pre-congruence with respect to the CCS operators.
Proposition 5.7 ≤trace is a pre-congruence w.r.t.  F
Proof. By reasoning of transition rules structures.	 
In addition we can prove the existence of the most general (failing) envi- ronment, and provide its description. Let us consider the following process:
TopF = Σ f.TopF + f.TopF	(5)
ƒ ∈F
It is easy to demonstrate that:

Proposition 5.8 If X ∈ EF then X ≤trace TopF .
Proof. By induction on the length of the traces generated by X.	 
So we have proved that there exists a most general environment with re- spect to ≤trace. A similar conclusion can be obtained when the following simulation relation is considered:
Definition 5.9 [[18]] Let S a binary relation on E × E.  Then S is said a

simulation if for each (P, Q) ∈ S and for each a ∈ Act τ
there exists Q' such that Q =a⇒ Q' and (P ', Q') ∈ S.
, if P
a
−→ P
' then

We write Q ≤sim P if there exists a simulation S such that (P, Q) ∈ S. It is easy to prove that ≤sim is a pre-congruence with respect to the CCS operators, admitting the same most general environment in (5).
Proposition 5.10 The following results hold
≤sim is a pre-congruence w.r.t.  F
if X ∈ EF then X ≤sim TopF .
Proof. (1) by reasoning of transition rules structures; (2) by induction on the length of the traces generated by X.	 
As a conclusion, when ≤trace and ≤sim are used as process relations, to check that P satisfies GNDC properties can be carried out only against the “most general (faulty) environment”, for example by running some existing tool for non-interference [12].
Compositional Analysis of Fault Tolerance
This section illustrates that, when ≤trace and ≤sim are used as process equiva- lences in our analysis scheme, compositional proof rules for establishing that a system enjoys GNDC can be applied. Compositionality is a desirable property in verification to infer a global fault tolerance exploiting local fault tolerance results. Let us show it with a simple example, obtained by extending exam- ple 2.1 with the following processes
Torch = get.ret(x).[if x =1 then flash else no flash].0
S	d=ef (Torch  Batteryƒ #) \ {get, ret}
representing the behaviour of a flashing torch Torch using the fault tolerant energizer of Example 2.1. The energizer is expected to furnish one units of energy, even in case of fault. The flashing torch Torch emits a flash action whenever it receives exactly one unit of energy, no flash otherwise. What

an observer watching at the system S, obtained by composing the torch and the energizer, expects is to see only flash actions. (Recall that the system Batteryƒ # provides only ret(1).) This safety properties can be formalized as:


S ∈ GNDC α(S)
iff ∀Fƒ
∈ Eƒ : S
 ƒ Fƒ
≤sim
α(S) = flash.0

where the ≤sim relation has been used. In this case the expected behaviour (given through α(S)) is that one unit of energy is furnished (and so one flash is observed). It is easy to convince us that the given specification of the system enjoys our safety property. Let us now consider a system Sn obtained by composing (in parallel) n instances of the system S and a similar safety property, on the Sn, that reflects the question “only at most n flashes are observed”. In our scheme this is equivalent to prove that:


Sn ∈ GNDC α(S)n
iff ∀Fƒ
∈ Eƒ : Sn
 ƒ Fƒ
≤sim
α(S)n d=ef α(S)	...	α(S)
`	˛¸	x




Compositionality would made the previous statement true, for any fixed n, without the needs of any additional check. In the following we prove that it is really the case when ≤trace or ≤sim are used. The following results hold:


Proposition 5.11 Let P1
for i = 1, 2. Then
and P2
be two processes such that Pi
α(Pi)
≤trace

P1
P1
α(P1) α(P2)
2	≤trace
 P ∈ GNDC α(P1 ) α(P2 )

Proof. Exploiting the existence of the most general environment Top, and the fact that ≤trace (resp.≤sim) is a pre-congruence.	 

A final discussion about the applicability of compositionality must be done. We have affirmed that using the results of this section, global fault tolerance can be deduced from local fault tolerance. Here with local fault tolerance we intend the property enjoyed by the formal specifications of sub-systems which are required to be fault tolerant by their own. With global fault tolerance we intend the property enjoyed by the specification of a system which is obtained by the composition of such sub-systems without the adjoint of any other global modules, such as a voter. Obviously we do not expect compositionality hold in such cases. This discussion would merit to be better developed, but being far from the scope of this paper we leave it for future works.

Conclusions
In this paper we have shown how to formalize fault tolerance within the GNDC framework i.e., a general scheme for expressing security properties in a process algebra context.
Once characterized as GNDC property, fault tolerance can benefit of vari- ous of theoretical results and analysis techniques. Those results and strategies are peculiar of the research background in security analysis. Specifically when either a trace or a simulation relations are used to characterized fault tol- erance properties, the GNDC theory assures efficient analysis procedures to exist. Specifically it benefits both of a static characterization (which gets rid off the universal quantification over all the possible fault scenarios), and of compositionality proofs. Another advantage of our uniform characterization is the possibility to compare dependability properties as done for the secu- rity ones in the GNDC framework. Potentially, this could be a preliminary step towards a formal and uniform taxonomy of dependability and security properties.
Anyway the general contribution of this paper aims to be wider. In fact by this work we intend to sustain the trend that watches at security as a research field whose applications in dependability analysis are still emerging. This is with greatest reason true if one considers the great deal of results around security recently appeared in the literature. We leave as a future work to extend our study over the characterization of other dependability properties. Acknowledgements. All the authors thank anonymous referees for their useful suggestions that have contributed to improve the overall presentation of the work. Gnesi and Lenzini are partially supported by the MIUR-CNR project SP4 and MIUR project MEFISTO. Martinelli is supported by MIUR project “Tools, techniques and methodologies for the information society” and
MIUR project MEFISTO.

References
C. Bernardeschi, A. Fantechi, and S. Gnesi. Model checking fault tolerant systems. Software Testing, Verification and Reliability, 12:1–25, November 2002.
C. Bernardeschi, A. Fantechi, and L. Simoncini. Formally verifying fault tolerant system designs. The Computer Journal, 3(43):191–205, 2000.
R. Focardi and R. Gorrieri. A classification of security properties. Journal of Computer Security, 3(1):5–33, 1995.
R. Focardi, R. Gorrieri, and F. Martinelli. Non interference for the analysis of cryptographic protocols. In Proc. of the 27th Colloquium in Automata, Languages and Programming, pages 354–372, 2000.


R. Focardi, R. Gorrieri, and F. Martinelli. Classification of security properties – part ii: Network security. In R. Gorrieri and R. Focardi, editors, Foundations of Security Analysis and Design II, volume 2946 of LNCS, pages 139–185. Springer-Verlag, 2004. FOSAD 2001/2002 Tutorial Lectures.
R. Focardi and F. Martinelli. A uniform approach for the definition of security properties. In Proc. of Congress on Formal Methods (FM’99), volume 1708 of Lectures Notes in Computer Science, pages 794–813. Springer-Verlag, 1999.
S. N. Foley. External consistency and the verification of security protocols. In Proc. of the 6th International Workshop on Security of Protocols, volume 1550 of Lecture Notes in Computer Science, pages 28–33. Springer-Verlag, 1998.
J. Goguen and J. Meseguer. Security policy and security models. In Proc. of IEEE Symposium in Security and Privacy. IEEE Computer Society Press, 1978.
C. A. R. Hoare. Communicating Sequential Processes. Prentice-Hall, Englewood Cliffs, NJ, 1985.
E. Johnsson, L. Stromberg, and S. Lindskog. On the functional relation between security and dependability impairment. In Proc. of the New Security Paradigms Workshop, Ontario, Canada, 1999.
L. Lamport. What good is temporal logic. In R. E. Manson, editor, Proc. of the IFIP Congress on Information Processing, pages 657–668, Amsterdam, 1983. North Holland.
F. Martinelli. Partial model checking and theorem proving for ensuring security properties. In Proc. of the 11th IEEE Computer Security Foundation Workshop, pages 44–52. IEEE, Computer Society, 1998.
F. Martinelli. Analysis of security protocols as open systems. Theoretical Computer Science, 1(290):1057–1106, 2003.
C. Meadows. Applying the dependability paradigm to computer security. In Proc. of the New Security Paradigms Workshop, pages 75–81, 1996.
C. Meadows and J. McLean. Security and dependability: Then and now. In Proc. of the Workshop on Computer Security, Dependability, and Assurance: From Needs to Solutions, pages 166–70. Los Alamitos, CA, USA : IEEE Comput. Soc, 1999, 1998.
R. Milner. Communication and Concurrency. International Series in Computer Science. Prentice Hall, 1989.
R. Milner. Operational and algebraic semantics of concurrent processes. In J. van Leewen, editor, Handbook of Theoretical Computer Science, volume B: Formal Models and Semantics, chapter 19, pages 1201–1242. The MIT Press, New York, N.Y., 1990.
R. Milner. Communication and Mobile systems: the π-calculus. Cambridge University Press, 1999.
R. Milner, J. Parrow, and D. Walker. A calculus of mobile processes. Information and Computation, 100(1):1–77, 1992.
A. W. Roscoe, J. P. C. Wookcock, and L. Wulf. Non-interference through determinism. Journal of Computer Security, 1(4):27–54, 1996.
J. Rushby. Critical system properties: Survey and taxonomy. Reliability Engineering and System Safety, 43(2):189–219, 1994.
J. Rushby. Partitioning for safety and security: Requirements, mechanisms, and assurance. Technical Report CR-1999-209347, NASA Langley Research Center, June 1999.
J. Rushby. Security, safety and partitioning. In Proc. of the International Symposium on Software Security (ISSS 2003), Tokyo, Japan, November 4-6, 2003, 2003. to appear in Lecture Notes on Computer Science.


A. Simpson, J. Woodcock, and J. Davis. Safety through security. In Proc. of the 9th International Workshop on Software Specification and Design, April 16-18, 1998, Ise-Shima (Isobe), Japan, pages 18–23. IEEE Computer Society, 1998.
D. G. Weber. Formal specification of fault tolerance and its relation to computer security.
ACM SIGSOFT Software Engineering Notes, 14(3):273–277, 1989.
