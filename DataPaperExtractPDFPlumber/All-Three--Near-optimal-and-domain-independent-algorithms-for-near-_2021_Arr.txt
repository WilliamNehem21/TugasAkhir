Array11(2021)100070
ContentslistsavailableatScienceDirect
Array
journalhomepage:www.elsevier.com/journals/array/2590-0056/open-access-journal
All-Three: Near-optimal and domain-independent algorithms for
near-duplicate detection
Aziz Fellah
SchoolofComputerScienceandInformationSystems,NorthwestMissouriStateUniversity,Maryville,MO,64468,USA
A R T I C L E I N F O A B S T R A C T
Keywords: In this paper, we propose a general domain-independent approach called Merge-Filter Representative-based
Near-duplicatedetection Clustering (Merge(cid:1)Filter(cid:1)RC) for detecting near-duplicate records within a single and across multiple data
Near-duplicates sources. Subsequently, we develop three near-optimal classes of algorithms: constant threshold (CT) variable
Approximateduplicates
threshold(VT)andfunctionthreshold(FT),whichwecollectivelycallAll(cid:1)Threealgorithms.Merge(cid:1)Filter(cid:1)RC
Clustering
andAll(cid:1)Threemoldthebasisofthiswork.Merge(cid:1)Filter(cid:1)RCworksrecursively inthespiritofdivide-merge
Dataminingapplicationsanddiscovery
fashion for distilling locally and globally near-duplicates as hierarchical clusters along with their prototype
Datacleaning
representatives.Eachclusterischaracterizedbyoneormorerepresentativeswhichareinturnrefineddynami-
cally.Representativesareusedforfurthersimilaritycomparisonstoreducethenumberofpairwisecomparisons
andconsequentlythesearchspace.Inaddition,wesegregatetheresultsofthecomparisonsbylabelswhichwe
refer to as very similar, similar, or not similar. We complement All(cid:1)Three algorithms by a more thorough
reexaminationoftheoriginalwell-tunedfeaturesoftheseminalworkofMonge-Elkan's(ME)algorithmwhichwe
circumventedbyanaffinevariantoftheSmith-Waterman's(SW)similaritymeasure.
Usingbothreal-worldbenchmarksandsyntheticallygenerateddatasets,weperformedseveralexperiments
andextensiveanalysistoshowthatAll(cid:1)ThreealgorithmswhicharerootedintheMerge(cid:1)Filter(cid:1)RCapproach
significantlyoutperformMonge-Elkan'salgorithmintermsofaccuracyindetectingnear-duplicates.Inaddition,
All(cid:1)ThreealgorithmsareasefficientintermsofcomputationsasMonge-Elkan'salgorithm.
1. Introduction schemes,aswellastheintegrationofmultiplesdatasourcesintoasingle
dataset.Ingeneralindatacleaning,near-duplicatesmayexistwithina
The problem of identifying whether multiple representations of a single source, whereas in data integration near-duplicates may exist
real-worldentityorobjectarethesamehasbeenoriginallydefinedby withinoracrossvariousdatasources.However,bothcaseshavethesame
NewCombeetal.[1].Sincethen,thislong-standingproblemhasbeen commongoal,detectingnear-duplicatesandtheclosenessofsimilarity
studiedextensivelyincomputerscienceandrelatedfieldsundervarious amongentitiesinalargecollectionaccuratelyandefficiently.Thatis,to
namesusingamultiplicityofterminology;justtoname,recordlinkage determinewhichrecords/objectsinthesameordifferentdatabasesrefer
[2,3] in the statistics community, approximate matching [4] in infor- tothesameunderlyingreal-worldentity.
mation retrieval,entity resolution [5], object identification [6] in ma- For example, consider the following references that have been
chinelearning,merge/purge[4,7,8]andnear-duplicatedetection[9–18] recordedatthreedifferentcolleges,“JeffDavidUllmanStanfordUniver-
indatabasesandalgorithms.Inlargeandvariousdatabases,amajortask sity,Dept.ofComputerScience”;“JeffreyD.UllmanComputerScienceDept.,
inadatacleaningprocessisidentifyingsetsofrecordsthatareseman- StanfordUniv.,CA,USA”;“J.D.Ullman,DepartmentofComputerScience,
ticallyduplicatesofeachother,butnotsyntacticallyidentical.Suchtype StanfordUniversity,USA”.Allthethreereferencesrefertothesamein-
of duplicate records are also referred to as similar, approximate or dividual,eventhoughtheyarequitedifferentifbyte-by-bytecompari-
near-duplicates in research literature. In the context of this paper, we sonsareused.Itisoftenthecasethatdataindifferentrepositorieshold
adoptthelastterminology,thatis,near-duplicates.Themostcommon informationregardingidenticalentities,butmightbestoredindifferent
variationsinrepresentingthesameentity(i.e.,records,objects)witha formatsandschemeswhichmayresultinapossibledatainconsistency
multitudeofrepresentationscanprimarilyarisefromtypographicaler- andnonconformity.Oneexamplewouldbeidentifyingauthorsandci-
rors, misspellings, missing data, and differences in abbreviations and tations in a bibliography database such as DBLP, CompuScience, and
E-mailaddress:afellah@nwmissouri.edu.
https://doi.org/10.1016/j.array.2021.100070
Received20February2021;Receivedinrevisedform5May2021;Accepted12May2021
Availableonline27May2021
2590-0056/©2021TheAuthor(s).PublishedbyElsevierInc.ThisisanopenaccessarticleundertheCCBYlicense(http://creativecommons.org/licenses/by/4.0/).A.Fellah Array11(2021)100070
CiteSeer.Severalalgorithms,inparticulardomain-dependent,forquan- insightsandmulti-dimensionalinformationfrombusiness,financial(i.e.,
tifyingthedegreeofsimilaritieshavereceivedparticularattentionina creditcards),andhealthcaredata.Acomprehensiveevaluationandan
wide range of applications, including web search engines and mining, umbrella of techniques have been investigated. A common factor be-
medicalandcensusdata,plagiarismandspams,mailinglistdeduplica- tween these algorithms is they cannot guarantee finding all near-
tion,andimagedatabase.Asubstantialbodyofresearchhasbeencon- duplicates and also cannot guarantee the accuracy. Vogal et al. [35]
ductedinaspectrumofdomains,seeforexample[19–28]. provided an annealing standard to evaluate near-duplicate detection
results. In other words, the accuracy and completeness of duplicates
2. Backgroundandrelatedwork shouldconvergeincrementallyandinterativelytoagoldorsilverstan-
dardthatdefineswhichrecordsrepresentthesamereal-worldentities.
Naive near-duplicate detection methods which are based on Near-duplicate detection algorithms mainly focus on effectiveness
comparing every pair of records become intractable in the context of and efficiency, but not on scalability which has been addressed by
huge data collections such as social networks. For example, Facebook Naumannetal.[36],whoassignappropriatesimilaritymeasurestoat-
withover2.97billionactiveusersworldwide,resultsinmorethan2.45 tributesbasedontheirsemantics.Forinstance,namesofpersonsshould
(cid:3) 1019 comparisons. Several methodologies and solutions have been becompareddifferentlythanemailaddresseseventhoughtheybelongto
proposedinresearchtoreducethetotalcomputationalcostandimprove thesamestringdatatype.Overall,mostofthesemethodsrequireagood
the accuracy. In a stand-alone literature review, a variety of blocking understandingoftheapplicationdomainandasuperviseduserinterac-
methods which are based on the selection of a key (blocking key) for tion for refining and adjusting parameters such as distance functions,
generatingsubsetsofpotentialnearduplicateshavebeeninvestigatedin windowsize,andthresholds.
research [5,11,29]. The main focus of these methods is that records The most predominant domain-independent algorithm for near-
havingthesamekeyvalueshouldbeaddedtothesameblockandlabeled duplicate detection is that of Monge-Elkan (ME) [4,14]. This seminal
aspotentialnear-duplicatesforfurtheranalysis.JaroandWinkler[3,24, workisbasedonstretchingadequatelytheSNM'sslidingwindow[8]that
30]extendedthekey-basedapproachbyusingexpressionswithmultiple holdsafixednumberofrecordsetsandgroupingrecordsintoclusters.
keys which increases the accuracy and reduces the number of false Monge-Elkan'salgorithmhasamuchmoreimprovedefficiencyover
matches and false misses. Such keys can be adjusted interactively by many duplication methods including the SNM algorithm, but has the
trial-and-erroranalysistoachievethebestresults.However,theprocess samedetectionaccuracyastheSNMandperformsevenfarbetterthana
of finding a perfect key is often difficult and requires good domain large number of other algorithms in terms of time and accuracy. In
knowledge.Otherrelatedblockingcriteriabasedonapplications’char- addition,aspectrumofsimilarityanddistancemeasures,highlydepen-
acteristics (i.e., medical, census, bibliography data) are also used as a dentontheapplicationdomain,havebeeninvestigatedintheliterature
first-steppreprocessingtoidentifyinitialblocking.Ingeneral,blocking and are certainly not a new area of research. They range from fairly
algorithmsareoflowtimecomplexity,butwithseveraldrawbacks.For simple schemes to more complex well-tuned edit distances. The most
example,recordswithminortypographicalerrorsorsimplemisspelling prominentclassofcharacter-basedmetricsknownaseditdistancesare
areclusteredindifferentblocks.IthasbeenobservedinRefs.[23,24] Levenshtien,Jaro-Winkler,andSmith-Watermansimilaritymeasures[3,
that40–70%ofthematchesarefoundinthefirstblockingpass.Bythe 30,37]. One extension to the Levenshtein distance is the
fourthblockingpass,0.0001%ofthepairsareactuallyduplicates.These Needleman-Wunsch [38], which additionally allows variable sub-
results show that the proportions of pairs that were duplicates in suc- stitution'scostfordifferentcharacters.Thatis,itprovidesamappingfor
cessive blocking criteria fell at an exponential rate. A well-known each pair of symbols(i.e., characters) from the alphabet to some cost.
duplicatedetectionframeworkknownassortedneighborhoodmethod Other effective similarity measures, token-based and hybrid metrics,
(SNM)wasproposedbyHernandezandStolfo[8,31]andisbasedonthat have been also investigated in the literature, for example, Jaccard,
near-duplicatestendtolocalizeintheneighborhood.Thealgorithmuses n-grams, Cosine, Monge-Elkan, and natural language processing tech-
blocking to sort all records based on a sorting key and then slides niques(i.e.,TF-IDF)similaritymeasures.Similaritymetricsrangefrom
sequentiallyawindowoffixedsize(slidingwindow)overthesortedre- fairlysimpleschemestomorecomplexwell-tunededitdistances,seefor
cords. The window uses the blocking scheme by including all records example,[11,13,37,38].
withsimilarkeys(lexicallynearbykeys)inthesamewindow.Allrecords
withineachslidingwindowareconsideredaspotentialnear-duplicates 3. Contributions
andthencomparedwitheachother,however,thewindowsizeisdiffi-
culttoset.Overall,theslidingwindowisamorerobustapproachthan Weproposeanewgeneralizeddomain-independentframeworkand
othertechniquesinimprovingthenear-duplicatedetectionaccuracy,but subsequently three classes of algorithms for detecting near-duplicates
itislikelytofailingroupingsimilarrecordsoutsidethewindowsizeif among entities within one or more attributes in large database sets.
substantial typographical errors occurs in the first characters of the These algorithms are synthetically complemented by near-duplicate
sortingkey.Moreover,thereis substantialresearchthathasbeenpro- generatoralgorithm(NDG).Intherestofthepaper,werefertosucha
posed as an umbrella for SNM where blocking has been empirically framework as Merge-Filter Representative-based Clustering (Mer-
evaluated on differentdomains anddatasets. Some ofthese extended ge(cid:1)Filter(cid:1)RC)andtosuchasetofalgorithmsasconstantthreshold(CT),
variationsofSNMandblockingapproachesoutperformthebasicSNM variablethreshold(VT),andfunctionthresholds(FT),respectively.For
andblockingapproachesintermsofreducingthecomplexitycostand convenience,wecollectivelyrefertothesethreealgorithmsasAll(cid:1)Three
improvingtheaccuracy.Forinstance,Yanetal.[7]proposedanadaptive algorithmsandtoaspecificalgorithmbyitsconventionalname,either
variantscheme of SNM for record linkageby adjustingthe size of the CT, VT, or FT. In addition, we integrate an efficient synthetic near-
sliding window dynamically during the execution time to build duplicate generator algorithm (NDG) into All(cid:1)Three algorithms. The
non-overlappingblocks,butithasbeenconfirmedthattheirworkdidnot NDGalgorithmiscapableofscalinguptogeneratealgorithmicallytensof
outperformtheoriginalSNM.Othercomplicatednear-duplicateidenti- millions of synthetic records. One of our aim here is to capture and
fication techniques such as q-gram, iterative blocking, overlapping modifythefullpowerofMonge-Elkan(ME)[4,14]andSmith-Waterman
blocking,multipleblocking,token-based,learningprocess,anddomain (SW) [37] algorithms in the context of our work. That is, Mer-
knowledge, with some assumptions on the entities have been investi- ge(cid:1)Filter(cid:1)RC is a domain-independent approach that combines the
gatedintheliterature,justtonamefew[5,25,32–34]. token-based of Monge-Elkan and the character-based internal of
Furthermore,withrapidadvancesinbigdatacomputingandwebera, Smith-Waterman similarity function, both of which we modified and
near-duplicatedetectionresearchisexpandinginmanywaystoindustry augmented with a well-tuned affine parameterization. Still, this is not
applications such as managing massive documents, and extracting enough to solve the quality and complexity of our approach due to
2A.Fellah Array11(2021)100070
anomalies which are associated with the transitivity relation and 4. EffectivenessofMonge-ElkanandSmith-Watermanalgorithms
thresholdchoices.Thus,wesegregatetheresultsofthecomparisonsby
labels which we refer to as very similar, similar, or not similar, and In this paper, we focus on the Smith-Waterman (SW) edit distance
furthermore minimize an objective function without the user's inter- [37] that was originally developed for identifying common molecular
vention.Eachconstructedclusterhasoneormorerepresentativeswhich subsequences, like DNA or proteins. Two strings x and y may not be
aredynamicallycomputedtomeasuretheprototypicalityofeachrecord entirelysimilarbutcontainregions,perhapsinthemiddle,thatexhibit
inthecluster.Therecordcomparisonisperformedwithonlyrepresen- highsimilarity.Findingsuchapairofregions,onefromeachofthetwo
tativesratherthanwithallrecordsinthecluster.Thus,recordsdonot strings,isreferredtoasalocalalignment.TheSmith-Watermanalgorithm
havetobecomparedtoallotherrecords,buttoonlyclusterrepresen- findsthelocalalignmentbetweentwostringswiththemaximumpossible
tativeswhichareconsideredforsubsequentcomparisons.Weintroduce score usinga dynamicapproachthat runsin O(|x||y|) time.The main
clusterrepresentativeswhichretainthemostrelevantsyntacticandse- limitationofSWisitplacesheavierpenalties(i.e.,highercost)onmis-
mantics features of the records in the cluster. The idea behind this matchesinthemiddleofstringsratherthanatthebeginningandtheend
approachisthatclusterrepresentativesreducethetotalnumberofrecord ofstrings.Thismaycreateaproblemwhentheerrorsareinthemiddleof
comparisons,withoutreducingsubstantiallytheaccuracyofthedupli- thestrings.Inthisregardandinordertoeliminatethisinconvenience,
catedetectionprocess. we primarily consider the Monge-Elkan's methodology [14,26], a
Clusters’ representatives are dynamically distilled and accurately well-tuned matching methodology normalized in the interval ½0;1(cid:4),
achievedthroughoutasetofcomparisonfunctions,verysimilar,similar, allowingadditionalparameters,andintroducesgapsinthealignmentof
ornotsimilar,andthresholdsettings,constant,variable,orfunction.The twostrings.MuchofthepoweroftheMonge-Elkan'salgorithmisdueto
numberofsimilaritycomparisonsisreducedfromO(n2)toO(nm),where itsabilitytoincludesequencesofnon-matchingcharacters,gaps(affine
mandandnarethenumberofrepresentativesandrecords,respectively gaps),inthealignmentoftwostrings.Inourwork,weaddthegapcostas
andm≪n,misalwaysindependentofn,butdependentontheclassof another variant of the Smith-Waterman (SW) algorithm that offers a
the algorithm. Each of these algorithms has a different impact when solutiontotheaboveproblemandotherrelatedduplicatedetectionis-
runningonasetofthresholds,aconstant,variable,orfunction.Allal- sues.Byaddingacost,weextendthetwoextraeditoperations,starting
gorithmsareimplementedinCþþandusethesamedatasettomakefair gapandextendinggap.
comparisons.Werananextensiveexperimentalstudyusingseveralreal Ingeneralandforinstance,thegappenaltydenotedbycost(gap)¼s
benchmarks and algorithmically generated synthetic data. We do not þe(cid:3)l,wheresistheaffinecostofstartingagapinanalignment,eisthe
assume any specific structure in the data nor rely on any information costofextendingagap,andlisthelengthofagapinthealignmentoftwo
available in the source data. That is, data has not been standardized, strings.Usuallyaffinegappenalizesgapextensionlessthangapopening
preprocessed,nortransformed,andsyntacticaswellassemanticerrors (e < s) thus we decrease the penalty for contiguous mismatched sub-
remain as potential errors in the data. Experimental implementations stringsbyusingasinglelonggapovermanyshortgaps.Sincethedif-
show the Merge(cid:1)Filter(cid:1)RC detection approach greatly reduces the ferences between near-duplicate records often arise because of many
numberofcomparisonsandtheprecisionachievesavalueofnearly1.0,a abbreviations or extra-string insertions and omissions, the affine-gap
precision which is close to the optimal outperforming consistently the modelproducesabettersimilarityandmoreaccurateresultsthanmost
seminalworkofMonge-Elkan. theothereditdistancemetrics.Moreover,theaffine-gapalgorithmper-
Ourproposedsetofalgorithmsdonotpresumeaspecificapplication forms well to detect similarities when records have minor syntactical
domain,butincontrasttheyaretunedtowardanydomain-independent differences, including typographical errors, abbreviations, and trunca-
applications. Monge-Elkan's (ME) algorithm is relatively domain- tions.Infact,theMonge-Elkan'salgorithmapproximatesthesolutionto
independentwiththepurposeofintegratingandmatchingwebscienti- the optimal assignment problem in combinatorial optimization. This
ficpapersfrommultiplesources,typicallyanalphanumericdomainclass. approximation is a reasonable trade-off between accuracy and
TheparametersusedinMEaremappedtosuchaclassofapplications complexity.
withonlyarestrictedpossibilityoftuningthethresholdvaluestoprovide Insum,Monge-Elkan'scomplexityisquadraticinnumberoftokens
abetteraccuracy.Inaddition,theheuristicmethodofMEminimizesthe andonecandefinetheMonge-Elkan'smeasureovertwotextstringsthat
numberofpairwiserecordcomparisonswithpotentialrecordduplicates containseveraltokensas:
andintegratessomekeyconceptssuchastheminimumedit-distanceof
SW. 1
Xjxj
MongeElkanðx;yÞ¼ maxsimðx½i(cid:4);y½i(cid:4)Þ
Therestofthepaperisorganizedasfollows.Section3reviewsand jxj
i¼1
j¼1;jyj
summarizesthe effectiveness of Monge-Elkanand Smith-Watermanal-
gorithms.Section4addressesthemetricmeasuresusedindetectingnear- where|x|and|y|arethenumberoftokensinxandy,respectivelyand
duplicates. Section 5 explains how to calculate and choose between sim(x,y)isaninternalsimilarityfunctiontomeasurethesimilaritybe-
precision and recall using F-measure. The choice, adjustment, and tweentwoindividualtokens.
thresholdtuningaredefinedinthissection. In the paper, we adopt a modified version of the Smith-Waterman
Section6proposesthemerge-filterclusterrepresentativeframework similarityeditdistanceasinter-tokensimilaritymeasure.Formally,let
which addresses the details of the accuracy performance using cluster c(xi,yi)denotethecostoftheeditdistancethatalignsithcharacterof
representativesthroughoutprecisionandrecallmetrics.Section7pro- stringxtojthcharacterofstringy.ThentheSWalgorithmcomputesa
videsafullyalgorithmictechniqueandpresentsthreedifferentdomain- costmatrixMthatrepresentsamaximum-coststringalignmentbythe
independentalgorithms,constant,variable,andfunctionthresholdsfor followingrecurrencerulebasedonMonge-Elkan'salgorithm[4].
detecting near-duplicates, all of them under the umbrella of 8 (cid:2) (cid:3)
Mer Ig ne S(cid:1) eF ci tl it oe nr(cid:1) 8R ,C w.
epresentathoroughexperimentalevaluationofour
>>>><M Mð ði i(cid:1) (cid:1)1 1; ;j jÞ(cid:1) þ1 eÞþc x i;y j
ifalignði(cid:1)1;j(cid:1)1Þends in a gap
ta ep rp mro sa oc fh aca cn ud racc yom anp dar ee ffit ch ie ene cf yfe wct ii tv he tn he ess seo mf inA al ll(cid:1) wT oh rr ke oe fa Mlg oo nr git eh -Em lks ai nn
.
Mði;jÞ¼max >>>>:MM ðð ii ;(cid:1) j(cid:1)1; 1j ÞÞ þþ es ii ff aa ll ii gg nn ðð ii (cid:1)(cid:1) 11 ;; jj (cid:1)(cid:1) 11 ÞÞ ee nn dd ss ii nn aa gm aa ptch
Weusedbenchmarkdataaswellassyntheticdatatomeetspecificcon- Mði;j(cid:1)1Þþs ifalignði(cid:1)1;j(cid:1)1Þends in a match
ditionsthatarenotavailableinexistingrealdata.Syntheticdatahasbeen
generatedusingthenear-duplicategenerator(NDG)algorithm.Section9 5. Metricmeasuresandthresholdeffects
concludes the paper with potential and future research directions. In
Similarityreferstoameasureoflikenessbetweentwoobjects(i.e.,
addition,weprovideanappendixtomakeourpaperselfcontained.
3A.Fellah Array11(2021)100070
records,entities);andthedissimilaritybetweentwoobjectsisrefereed representatives which retain the most relevant syntactic and semantics
toasadistance.Wedefinearecordasasetoftokensdrawnfromafinite featuresoftherecordsintheclusterwherecomparisonstakeplacewith
universeU.Letnbethenumberofreal-worldentitiesoverapluralityof clusterrepresentatives,insteadofallrecords,thusthesearchspacecan
largedatabasesthatconsistofrecordsR
n
¼r 1;r 2;…;r n,wherealarge bereducedwiththeimprovementofbothtrueanddeclaredsubspaces.In
numberofriarepotentialnear-duplicates.WedenotebyD ¼ D1;D2; otherwords,thereductionoffalsepositivesandinparticularfalseneg-
…;Ddthesetofproblemdomains. atives have an impact on the accuracy. A high recall means no false
Similarityanddistancemeasuresareoftennormalizedintherange missesandindicateshighaccuracyoftheduplicatedetectionresults.A
½0;1(cid:4),and½0;∞(cid:4)or½0;some distance(cid:4),respectively.Formally,wedefine high reduction ratio achieves an even more effective search space
asimilarityanddistancemeasuresasfollows: reduction.Ahighprecisionmeansfewfalsematchesandhastheopposite
effectthanrecall.Theothermetricmeasure,reductionratiointherange
Definition 5.1. A similarity measure is a non-negative function sim:
of½0;1(cid:4),isdefinedas1-(declaredduplicates/alltuplepairs).Thesimi-
D1 (cid:3) D2 →[0,1],suchthatsim(r1,r2)¼0ifr1andr2areleastsimilar
laritythresholdlineinFig.1ensuresatrade-offamongrecall,precision
andsim(r1,r2)¼1ifr1andr2areidentical.(D1mightbeequaltoD2).
andreductionratio.Ifweshiftthesimilaritythresholdline(similarity
Definition 5.2. A distance measure is a non-negative function dist: threshold1)totheright,consequentlymoretuplepairswillberejected
D1 (cid:3) D2 → [0, 1], such that dist(r1, r2) ¼ 0 if r1 and r2 are exactly andincreasethereductionratioandprecision.Thisrejectionwouldul-
similaroridentical,anddist(r1,r2)¼1ifr1andr2arenotsimilar. timately lead to decrease the recall metric. If we shift the similarity
thresholdlinetotheleftthentheoppositetrade-offeffectbetweenrecall,
Thesearchspacefordetectingnear-duplicatescanbereducedunder
precision,andreductionratiowilltakeplace.Similarlyandinthesame
theassumptiontherelation“isduplicateof”or“issimilarto”,istransitive.
fashion, shifting the similarity threshold line (similarity threshold 2)
However, the theory of transitivity is not always flawless in practice
wouldhaveaneffectontrueandfalsepositives.
becauseofthepropagationoferrorsasexplainedearlier.Duplicatere-
Relationsbetweenthresholdsimilaritymetricsandaccuracyarean
cordstendtobesparselydistributedoveralargedatabasespaceandthe
important part of the near-duplication detection process. Different
propagationoferrors is statisticallyinsignificant [26]. Thecomplexity
thresholdsettingandparametertuning(i.e.,distancefunctions,window
andevaluationmeasurestoassessanear-duplicaterecordalgorithmthat
size)havebeenusedtoclassifywhetherapairofrecordsisaduplicateor
have been addressed are the efficiency and accuracy. Accuracy is
a non-duplicate. Several experiments have been conducted and cutoff
considered the most important quality assessment dimension in
thresholdsforaspecificapplicationdomainwithitsowncharacteristics,
near-duplicatealgorithms,anditismeasuredintermsoftwoprominent
oftenmanuallyconfigured,haveshowntoachievethe“best”precision,
measures, precision and recall. The other related measure is F-measure
recallandF-measurevalues.Thecutoffvalueofthethresholdalongwith
whichdeterminestheharmonicmeanoftheprecisionandrecallvalues.
otherkeytuningparameterscanbeverytimeconsumingasthesearch
Thegoalofourevaluationistofindthebestmetricsintermsofquality
spacecangrowexhaustivelyandevenexponentially,whichnecessitates
andeffectivenesswithrespecttodifferentdomain-independentdatasets.
someformsofthresholdoptimization[35,39,40].
Weclassifyeachvaluepairofcomparisonsasverysimilar,similar,ornot
similar since errors may occur during the process of detecting
6. Merge-FilterRepresentative-basedClustering:Anear-optimal
near-duplicates.Forcompleteness,asitisillustratedinFig.1,wedivide
domain-independentapproach
thesearchspaceintosubspacesanddenotebytruepositivesallcandidate
pairsthatarecorrectlydeclaredtobeduplicates(i.e.,expectedmatches),
Similarinspirittodivideandmergemethodologyforclustering[41],
andfalsepositivesallcandidatepairsthatareincorrectlydeclaredtobe
Merge-Filter Representative-based Clustering (Merge(cid:1)Filter(cid:1)RC) com-
duplicateswhileinfacttheymaynotbeduplicates(i.e.,thereshouldnot
binesatop-downdividephasewithabottom-upmergephaseinahier-
beamatch).
archicalschemeasdescribedinsubsequentsections.Merge(cid:1)Filter(cid:1)RCis
Similarly,truenegativesarepairsthatarecorrectlyrecognizedasnot
made of two trees, a top-down and bottom-up tree, annotated with
beingduplicates(i.e.,expectedmismatch),andfalsenegativesarepairs
clusterrecords.Merge(cid:1)Filter(cid:1)RCismainlygearedtowardstheneedsof
thatarenotdeclaredtobeduplicateswhileinfacttheyare(i.e.,there
detectingnear-duplicateswithaprovisionofformingthebestpossible
shouldbeamatch).Themetricprecisionmeasuresthefractionofcorrect
near-optimal clusters of records by integrating a variant of Smith-Wa-
duplicatesoverthetotalnumberofrecordpairsclassifiedasduplicates
terman's and Monge-Elkan's algorithms into the detection approach.
by the algorithm. The metric recall measures the fraction of records
Importantly,weareonlyinterestedinunconstrainedalgorithms,rather
correctly clustered over the total number of duplicates. A high recall
than adopting any standard clustering algorithm. That is, there is no
means no false misses and a high precision means few false matches;
preliminaryassumptionofrationalitytochoosethenumberofclustersas
thus, there is a trade-off between high recall and high precision. The
inputorotherdomainspecificparameters.LetCdenotetheinitialcluster
othermeasurewewanttointroduceisthereductionratio,whichisthe
containing n records in R , and d denote the depth of a node in the
relativereductioninthenumberofpairstobecompared.Thismeansa n
top-downclustertreeTwhoseroot(C;n)isatd¼0andinternalnodes
searchspacereductionstrategyisneededinordertoreducethenumber
ofrecordcomparisons.Asaconsequence,weintroduceprototypecluster
are(C i,nb),whereCiandnbrefertothenameoftheclusterandthe
numberofrecordsinC ,respectivelyasillustratedinFig.2.Thedivide
i
phase of Merge(cid:1)Filter(cid:1)RC recursively splits the collection of records
intotwoequalhalvesateachlevelofTandconstructsthetreeTonthe
basisoftheserecords.Thenear-duplicatedetectionprocessstartswith
the data set of the initial cluster C that is expected to contain
near-duplicaterecords.Westarttheconstructionattherootwithnre-
cordsandend-upattheleaflevelwithonesinglerecordpercluster,(C ,
l
1)(Fig.2).Thenumberoftimesthesplitisdoneisexactlyequaltothe
heightofthetreeT,O(logn),becausethesizeoftheclustersdecreases
approximatelybyhalfateachlevelofTwhichisdefinedasfollows:
Definition6.1. Atop-downclustertreeTisafullbinarytreesuchthat
(i)thenodesofTaresubclustersofC(ii)everyinternalnodeofThastwo
subclusterofrecords,eachofsizen/2d,(iii)everyleafofTisasubcluster
Fig. 1. Similarity threshold factors and tradeoff between prominent mea- ofrecordsofsizeone;(iv)therootnodeofTistheclusterCthatconsists
suremetrics.
4A.Fellah Array11(2021)100070
Fig.2. Constructionofatop-downclustertreeT.
ofnrecords. similarityscore.LetsuchasetofclusterrepresentativesdenotedbyR^ i ¼
diviL de et pℂ h¼ aseC .E1 a; cC hi2 n; t… er; nC aln nb oe deth oe fs Tet iso af sc ulu bs st ee trs ofo tf hT ep dr ao tadu sc ee td reb cy ort dh se
.
ff o^r ri1 a;^r fii2 x;… ed;^r i.ijg(cid:4) (cid:4) (cid:4)C, ^1 i(cid:4) (cid:4) (cid:4)(cid:5) ¼j k(cid:5) al nw dh (cid:4) (cid:4) (cid:4)e R^re i(cid:4) (cid:4) (cid:4)l ¼ind l,ic wa hte es reth le in su mm ub ce hr lo ef ssre tp hr ae nse kn .ta Et viv ere ys
TheleftandrightchildrenofanodeC i formsapartitionoftheparent generatedithclusterC^ ,representedasanodeinT^ ,hasasetofnear-
s tru ec eh tt hh ea nt∣ fC ori∣¼ ann y= t2 wd oan cd lu1 st(cid:5) ersi, wi(cid:5) en ha( vF eig. ei2 t) h. eL re CtTb ⊂e Cato op r-d Cown ⊂c Clust oe rr duplicatesandclusterrei
presentativesreferredtoasfr ijgk j¼1andf^r ijgl j¼1,
i j j i
C i \ C j ¼∅,i6¼j,1(cid:5)i,j(cid:5)n. respectively. The results of detecting near-duplicates, however, may
become sensitive to the initial selection of representatives. Initially,
StartingattheleavesofT,thebottom-upmergingphaseisapplied
Merge(cid:1)Filter(cid:1)RCusesonerecordasaclusterrepresentative,thenrep-
recursivelytoeachnodeofTtowardstherootenablingtheconstruction
^ resentative(s) might be subsequently updated, either by retaining the
of a new tree of clusters whose root is T as depicted in Fig. 3. To
accomplishthis,thenear-optimalclusterofaninteriornodeC^
inthe
sameonesoriterativelyre-computingandre-assigningnewrepresenta-
i tives. In addition, Merge(cid:1)Filter(cid:1)RC enforces transitivity between re-
^
treeTisobtainedbymerginganddistillingdynamicallythenear-optimal
cords in a cluster
C^
. Each remaining record is compared to the
clustersoftheleftandrightchildrenofC^
i.TheresultofclusteringTisa representatives and
plai
ced in the cluster of the closest representative.
partitionC^
¼
C^ 1;C^ 2;…;C^ qwhereoneormoreC^ iarethenodesofT^
, Theideabehindthisapproachisthatclusterrepresentativesreducethe
referredtoasnear-optimalduplicatetree,i(cid:5)qandq≪n(qismuchless totalnumberofrecordcomparisons,withoutreducingsubstantiallythe
thann).Thevalueofqisnotknowninadvanceandisindependentofn. accuracy of the duplicate detection process. The number of similarity
At the beginning of the Merge(cid:1)Filter(cid:1)RC bottom-up phase, we comparisonstobeconsideredisreducedfromO(n2)toO(nm),wherem
initializethesetofleafclustersofT^ withthesetofleafclustersofT.Then, andandnarethenumberofrepresentativesandrecords,respectively.m
weapplyahierarchicalagglomerativeclusteringtotheleafclustersby
≪nandmisalwaysindependentofn,butdependentontheclassofthe
bringingtheleavesuptotherootlevelbylevel,andnear-optimizingthe algorithm(constant,variable,orfunction).
objective function locally at each iteration when two clusters are ThecornerstonepropertyofMerge(cid:1)Filter(cid:1)RCisbasedonthechoice
comparedandeventuallymerged.Thechoiceoftheobjectivefunction of the appropriate objective function g and its parameters. We are
uses the dynamic programming of SW algorithm refined by different interestedinfindinglocallytheoptimalclusteringateachlevelofT^ ,and
parametersasitwillbeexplainedinthenextsections.Eachconstructed alsofindinggloballythenear-optimalclusteringattherootcreatedby
clusterC^
hasoneormoreclusterrepresentativesthataredynamically
theMerge(cid:1)Filter(cid:1)RCmergephase.Thatis,gshouldguaranteetofind
i
computedtomeasuretheprototypicalityofeachrecordinthecluster. the optimal local alignment, OPTðAÞ, and quantifies the similarity in
The record comparison is performed with only representatives rather termsofahigh-scoringalignmentA.Thatis,wemaximizetheobjective
thanwithallrecordsinthecluster.Consequently,recordsdonothaveto functiongbyassigningascoreforeachalignmentobtainedbytheSW
becomparedtoallothersbutonlyclusterrepresentativesareconsidered
algorithm.LetΣ*denotethesetoffinitewordsoveranalphabetΣandx
forsubsequentcomparisons.Thatis,ifagivenrecordisnotsimilartoa
¼x1…xp,y¼y1…yqwherex,y2Σ*.Thestatespaceofallalignmentsof
record(s) in a set of cluster representatives then it will not match the
xandyisthemappingg:ð〈x;y〉Þ7!Z,thesetofintegers.Theoptimal
otherrecordmembersofthecluster.Ingeneral,Merge(cid:1)Filter(cid:1)RCtakes
localalignmentscoreofthesubsequencesx1…xpandy1…yqisobtained
as parameters two unordered pairs of clusters
(C^
,
C^
), and their
bymaximizinggamongallalignments.Thatis,
i j
^ ^
wre hsp ee thc eti rve (Cc ^lu ,st C^er )re ap rr ees ve en ryta st ii mve ils a( rR
,
si, imR ij l) arw oh rer ne o1
t
s(cid:5) imi, ilj a(cid:5)
r
bn y,th fie nn dir ne gtu tr hn es g 0ð〈x;y〉Þ¼m Aax gð〈x;y〉Þ
i j
optimal local alignment using the SW algorithm with the maximum
^
Fig.3. Vizualizationofanear-optimalduplicateclustertreeT.
5A.Fellah Array11(2021)100070
OPTðAÞ¼argmaxgð〈x;y〉Þ cluster. However, (r1, r3) and (r2, r3) would be non-duplicates. Now,
A consideranewrecordr4addedtoR 3withsim(r1,r4)¼0.75,sim(r2,r4)¼
Let.
0.88,andsim(r3,r4)¼0.96.Then,(r2,r4)and(r1,r4)areclassifiedas
C^ andC^ betheleftandrightchildrenofaninternalnodeC^ inT^
.
near-duplicatedandnon-duplicated,respectively.However,due tothe
l r anomalyinthetransitivityrelationandthenon-appropriatechoiceofthe
tL he etN noE dA eR C(cid:1)
^
O usP iT ngDU iPT cR luEE stð eC^ rs;i aÞ sb se tat th ee dn re ea cr u-o rrp et nim tlyal indu tp hl eic fa ot le los wub in-t gre te hefo or
-
t nh er ae rs -h do ul pd l, icth ate ep sa ai lr tho of ure gc hor thd es, re(r1 w, er4 re)a nn od t.( Tr2 h, ir s3) i, sw anou il md pb oe rtr ae ncl ta nss oi tfi ee td ha as
t
rem.Thespaceofnear-opticalsolutionsisrepresentedinadatastructure. shouldlargelyfosterthechoiceofappropriatethresholdsforlargerdata
Thatis,atreethatcanbeefficientlyusedtofindnear-optimalsolutions sets. With our proposed approach, the results of the comparisons are
that satisfy the optimal local alignment. Near-optimal and recursively segregatedbylabelsreferredtoasverysimilar,similar,ornotsimilar;
constructed bottom-up subtrees,
DUPTREEðC^;
iÞ, facilitate the re-
andthequalityandaccuracyoftheclassificationisfurtherimprovedby
optimization(i.e.,tuning)intheobjectfunctiongtosatisfytheproper- finding near-optimal or sub-optimal thresholds to identify more accu-
tiesandaccomplishthenear-optimalitysolution.Thus,eachsubtreeof ratelyduplicaterecordsbyminimizingtheobjectivefunctionwithoutthe
thenodeC^ usingiclusters,DUPTREEðC^;iÞ,transparentlyrepresentsthe usersintervention.WiththisviewpointandbasedontheSWalgorithm,
space of near-optimal solutions and how each subtree relates to each
westartcomputingtheoptimalclusteringfortheleafnodesandthenfind
other.Weproposethefollowingtheoremwhichformallyandcompactly thenear-optimalclustering,relativelytotheoptimallocalalignment,for
describes the near-optimal detection solution along with the corre- any internalnode. That is, at the end of the SW algorithm during the
spondingobjectivefunctiong.Weexploretheclusteringmethodologyof merge phase, NEAR(cid:1)OPT DUPTREEðT^ Þ gives the almost optimal clus-
[41]furtherandformallyintroduce near-optimalduplicationtreeof a tering.Weconsidertwoupperandlowerboundthresholdvalues,θ land
node C^ using i cluster defined as NEAR(cid:1)OPT DUPTREEðC^; iÞ. The θ u,whichareextensivelystudiedindomainindependentlargedatabases.
BothboundswhicharerootedintheseminalMonge-Elkan'salgorithm
objective function values of each alignment obtained by the SW algo-
^ have shown effectiveness as they become core standard thresholds in
rithmguaranteetheoptimallocalalignmentacrossallsubtreesofT.
researchliterature[39,40,42]andinalmosteveryapproximateduplicate
Theorem6.1. NEAR(cid:1)OPT DUPTREEðC^;iÞ ¼ detectionalgorithm.Thetwoupperandlowerboundthresholdvalues
(cid:5)
aremainlygovernedbytheprobabilityoferrorsforfindingoptimalre-
C^
(cid:6) (cid:7) (cid:6) (cid:7) if i¼1 cordalignments.Thus,wesetthesemanticsimilaritythresholdparam-
NEAR(cid:1)OPT DUPTREE C^ l;j [NEAR(cid:1)OPT DUPTREE C^ r;i(cid:1)j if i>1 eterforwhichtworecordsareconsideredsemanticallysimilartoθ u.In
thesamewayassemanticallysimilarrecords,wesetthenon-similarity
where
thresholdtoθ l.
(cid:6) (cid:6) (cid:7) (cid:6) (cid:7)(cid:7) We set θ u to 0.7 and θ l to 0.5 for declaring two records as near-
j¼argming NEAR(cid:1)OPT C^ ;j [NEAR(cid:1)OPT C^ ;i(cid:1)j duplicate and non-duplicate, respectively. θ (cid:5) θ l produces loose simi-
1(cid:5)j<i DUPTREE l DUPTREE r larity(notsimilar),θ(cid:6)θ uproduceshighsimilarity(verysimilar),andifθ
fallsbetweenthesevaluesitisregardedasaregularsimilarity(similar).
Proof.Weproceedbyinductiononi.Thebasecasehandlesallclusters
LetC^ landC^ rbetheleftandrightchildrenofaninternalnodeC^
whose
ofT^ .Thatis,allinitialclustersC^ 1;C^ 2;…;C^
q withasinglerepresen-
clusterrepresentativeisR^ .WedenotebyR^
l
andR^
r theleftandright
tativethatisgeneratedinthedividephase.Startingattheleaves,thefirst clusterrepresentativechildrenofR^ .AsaconsequenceofTheorem6.1,
optimalclustersareoriginatedfromtheSWalgorithm.Iftworecordsare westatethefollowingresult.
i sn imt ih lae r,sa am nde ifcl nu ost te tr heth ye an reth de isy sia mre ilac ro .nsidered to be near duplicate or Corollary6.1. NEAR(cid:1)OPT DUPTREEðR^;iÞ ¼
(cid:5)
Fortheinductioncase,wecannowassumetheclaimistrueforalli,1 R^ (cid:6) (cid:7) (cid:6) (cid:7) if i¼1
<i<n.Letinode(T^ )beaninternalnodeofT^ ,andT^ 1andT^
2theleftand
NEAR(cid:1)OPT
DUPTREE
R^ l;j [NEAR(cid:1)OPT
DUPTREE
R^ r;i(cid:1)j if i>1
^
rightsubtreesrecursivelybuildfromtheleafclustersofT,respectively.
Withoutlossofgenerality,defineC^ l andC^ r tobetheclusterswhose where
1 1
rootisT^ 1;andC^ 2l andC^ 2r betheclustersrootedintherightsubtreeT^
2, j¼argmingðNEAR(cid:1)OPT
(cid:6)
R^
;j(cid:7)
[NEAR(cid:1)OPT
(cid:6)
R^
;i(cid:1)j(cid:7)(cid:7)
orderedasðC^ 1l;C^ 1r Þ;ðC^ 2l;C^ 2r Þ.Denoteby(R^ 1l;R^ 1r )and(R^ 2l;R^ 2r ), 1(cid:5)j<i DUPTREE l DUPTREE r
thesetofclusterrepresentativesof(C^ l;C^ r )and(C^ l;C^ r
),respec-
1 1 2 (cid:4) 2 (cid:4)
tively (cid:4).Le (cid:4)tR^ 1l ¼R^ 1l [R^ 1r andR^ 2r ¼R^ 2l [R^ 2r suchthat(cid:4) (cid:4)R^ il(cid:4) (cid:4)¼p>1
and (cid:4) (cid:4)R^ ir(cid:4) (cid:4) ¼ q>1, for i ¼ 1, 2. That is, a cluster has more than one 7. Competitivealgorithms
representativewhichis usedforsubsequentcomparisons. Importantly,
Weintroducethreeclassesofalgorithmsfromdifferentperspectives,
representativeclusteringreducesthetotalnumberofrecordcomparisons
a constant threshold (CT), a variable threshold (VT), and a function
substantiallyandfurthermorerepresentativesareboundedbytwosim-
threshold (FT) algorithm, collectively referred to as All(cid:1)Three algo-
ilarity threshold values, θ u and θ l. Keeping this potential of multiple rithms.Eachofthesealgorithmshasadifferentimpactwhenrunningon
cluster representatives,
C^ l¼C^ 1l [C^ 1r
and
C^
r ¼
C^ 2l
[
C^ 2r
. For variousbenchmarksandsyntheticdatasets.
convenience,letR^ 1l ¼f^rl 1;1;^rl 1;2;…;^rl 1;pgandR^ 2l ¼f^rl 2;1;^rl 2;2;…;^rl 2;pg.
SimilarlyR^ 1r andR^ 2r aredefined.Iftworecords(i.e.,representatives) 7.1. Constantthreshold(CT)algorithm
areinthesameclusterthentheyareconsideredtobenear-duplicatesor
^
exactlysimilar,andifnottheyaredissimilar.Forinstance,letR 3¼fr 1; Weusethesame ^notatio ^nsinlinewithSection6.LetTbethebottom-
r 2;r 3gbethesetofrecordstobecomparedandtheinitialgoodthreshold upclustertree,andT 1andT 2theleftandrightsubtreesrecursivelybuild
chosen is in the interval ½0:83⋯0:90(cid:4). Assume we have the following fromtheleafclustersofT^ ,respectively.Assumen,thenumberofrecords,
similarities:sim(r1,r2)¼0.88,sim(r1,r3)¼0.72,andsim(r2,r3)¼0.80. isapowerof2forthesakeofconvenience.Theoutputoftheapproxi-
Then,(r1,r2)areclassifiedasnear-duplicatesandassignedtothesame mateduplicateSWmergephaseisapartitionofclustersC^ ¼ C^ 1;C^ 2;…;
6A.Fellah Array11(2021)100070
C^ ,whereeachC^ isanodeofT^
andqisunknowninadvance.Without
Algorithm1(continued)
q i
lossofgenerality,letassumeC^ 1l andC^ 1r betheclusterswhoserootT^
1;
3:Compare(C^ 1l ,C^ 2l )\(⊳\)comparisonofC^ 1l withC^ 2l
and
C^ l
and
C^ r
be the clusters rooted in the right subtree
T^
of
T^
,
4:if(C^ 1l ,C^ 2l )areverysimilarthen
orde Tr he ed2 pa rs ocðC e^ d1 ul r;2 eC^ C1 Or NÞ; Sð TC A^ NT2l T;C H^ R2 Er SÞ H.
OLD(C^ 1l;C^ 2l
)inalgorithm1is2
based
65 7:: :RC R^^ e nn m ee ww ov ←← eC R^^M 12e llr \g (e ⊳\( )C^ cl1 ul s, tC e^ r2 rl e)
p.←rep.ofC^ 1l
on the idea of the Merge(cid:1)Filter(cid:1)RC approach which compares and 8:endif
subsequentlyupdatestwogivenclusters,eitherbymergingthemintoa 9:ifC^ 1l ,C^ 2l aresimilarthen
newclusterandremovingoneoftheoriginalcluster.Moreover,theal- 10:R^
new
←Merge(C^ 1l ,C^ 2l
)
gorithmiterativelyrecomputesandreassignsnewrepresentatives.Each 11:RemoveC^ 2l
r ce loc so er sd ti rs ec po rem sep na tr ae td ivt eo .t Th he ere np ur mes be en rt oa fti cv oe msa pn ad risp ola nc se id srin edt uh ce ec dlu frs ote mro Of (t nh 2e
)
12:R^ new←R^ 1l[R^ 2l\(⊳\)clusterrep.←rep.ofC^ 1l [rep.ofC^ 2l
13:endif
toO(mn),wherereducedmandnarethenumberofrepresentativesand 14:if(C^ 1l ,C^ 2l
)arenotsimilarthen
records,respectively(mismuchsmallerthann). 15:nooperation
16:endif
7.2. Variablethreshold(VT)algorithm 17:Gotostep1andcompare(C^ 1l ,C^ 2r )
18:Gotostep1andcompare(C^ 1r ,C^ 2l
)
In procedure VARIABLE THRESHOLD (C^ 1l;C^ 2l ) in algorithm 1, each 19:Gotostep1andcompare(C^ 1r ,C^ 2r )
clusterhasonlyonerepresentativeandonlyonevariablethresholdvalue
20:return(R^ 1l;R^ 2l)\(⊳\)returnsclusterrepresentatives
isconsidered,startingatθ 1¼0.5.Inlinewiththeapproximateduplicate 21:endprocedure
SWalgorithm,thevariablethresholdalgorithm(VT)comparesclusters 1:procedureVARIABLETHRESHOLD(C^ 1,C^ 2)\(⊳\)VTalgorithm
fromtheleftsubtreewithclustersfromrightsubtree.Thatis,wecompare 2:CompareandfindSWof^r1and^r2\(⊳\)atstartθ 1,θ 2are0.5forC^ 1,C^
2
C^ 1l with C^ 2l and C^ 2r , then we compare C^ 1r with C^ 2l and C^ 2r . 3 4: :i if f( (S θ 1W >> θ 2θ )1 to hr e( nSW>θ 2)then
W cluit sh teo ru Ct ^l 1os hs asof
^r
1ge an se ara rl ei cty ordan rd epf ro er sea nlg tao tr ii vt ehm anic ds θi 1m ap sli aci tt hy r, ew she ola ds .s Su im me
-
65 :: RM ee mrg oe
ve(C^
C^1
2,C^
2)
sil ta ar ri tt ,y c, luC^ st2 erh sa hs a^r v2 ea os na err ee cc oo rr dd ar nep dr te hs een tt ha rt eiv she oa ldnd vaθ l2 ueas θ 1a it sh sr ee tsh tool 0d .. 5.At 7 8 9: : :θ eS 1 net d←re ifpr ðe θs 1e þnt Sa Wtiv Þ=e 2← \(⊳^r \1 )u\( p⊳ d\) atu ep θd 1aterepresentativeto^r1
10:if(θ 2(cid:6)θ 1)then
7.3. Functionthreshold(FT)algorithm 11:Merge(C^ 1,C^ 2)
12:RemoveC^
1
Inthisthirdcategoryofalgorithmseachclusterhasmorethanone 13:Setrepresentative← ^r2\(⊳\)updaterepresentativeto^r2
representative.Furthermore, two variablethreshold values areconsid-
14:θ
2
← ðθ 2þSWÞ=2
ered,anupperboundvalueθ u¼0.7,andacalculatedthresholdvalueθ c. 1 15 6: :e en lsd eif
In line with the approximate duplicate SW algorithm, the function 17:C^ 1andC^
2arenotsimilar
threshold algorithm (FT) compares clusters from the left subtree with 18:nooperation
clustersfromrightsubtree.Thatis,wecompareC^ l withC^ l andC^ r
,
19:endif
1 2 2 20:endprocedure
thenwecompareC^ r withC^ l andC^ r .Inaddition,wecompareC^ r
witheveryclusterin1 thesecon2 dhalfsu2
btree.
1 1:procedureFUNCTIONTHRESHOLD(C^ 1l;C^ 2l )\(⊳\)FTalgorithm
maxTh Se Wfu >nc θtion (lC inO eM sPAR 4E ð aC^ nd1;C^ 52 )Þ
.
sh To hw es oth the ev rer ty ws oimi cl aa sr ec s,ase siw mh ile an
r
2 3: :F Suin pd pom sa ex mS aW xSb Wet iw se be en twC^ ee1 nl a Cn ^d 1le av ne dry C^cl 2u rsterinT^ 2
bi( nθ el a su(cid:5) sa bm sm tie ta umx teaS dnu W n be y(cid:5) r. liLθ niu en) sea s 4n 4 ad nan dno d 5ts 5 ii nm in ti hl ta h er e f( ufm u na n cx c tit oiS o nW n CC H< O ECMθ KPl -) A S, R Ic MEa I( Ln C A^a R1l ITs ; Yo C^ ðb C2e ^)t 1sr h ;e Co ^a ut 2e l Þd d
,
64 75 :: ::i R RMf e ee( m pm r rg o ea e vx see(C nS ^ C t^W a1 t1l i, l> vC e^θ ←2u r) ) rt eh pe rn
esentativeofC^ 2r
respectively.Inthesameway,lines11and12shouldbesubstitutedby 8:endif
lines4and5.Forthecaseofnosimilarity,lines4and5inthefunction 9:if(θ c(cid:5)maxSW<θ u)then
COMPAREðC^ 1;C^
2Þshouldbesubstitutedbylines7and8inthefunction
10:Merge(C^ 1l ,C^ 2r
)
CHECK-SIMILARITYðC^ 1;C^ 2Þ. 1 11 2: :R Re em pro ev see nC t^ at2 ir
ve←Unionofrepresentatives
Inthesamewaylines11and12shouldbesubstitutedbylines7and
13:endif
8.LetR^ 1andR^ 2beth(cid:4)ese(cid:4)toftheclu(cid:4)ster(cid:4)representativesofC^ 1andC^ 2, 14:if(maxSW<COMPUTE(θ c)then
respectivelysuchthat(cid:4) (cid:4)R^ 1(cid:4) (cid:4)¼pand(cid:4) (cid:4)R^ 2(cid:4) (cid:4) ¼q,wherep,q(cid:6)1.Foralgo- 1 15 6: :en no dop iferation
rithmicconvenience,letassumethatq(cid:6)p.LetR^ 1¼f^r 1igp i¼1andR^ 2¼ 17:endprocedure
f v^r a2 lj ug eq j¼1 mb ae xt Sh Wec rl eu fs et re srr toep tr he esen vata luti eve rs eto uf rnC^ e1 da bn yd tC h^ e2, Sr me is tp he -c Wti av te el ry m.T anh ne 1 2: :f Cu on mc pti ao rn eaC nO dMP fiA nR dE( SC^ W1; oC f^ ^r2 1) 1\ w(⊳ i\ t) hv ee ar cy hsi fm ^r2i jl ga q jr ¼1case
3:FindmaxSW;m←max SW
algorithm. 4:ifatanytime(max SW>θ u)then
5:(C^ 1,C^
2)areverysimilar
Algorithm1 6:StopandreturnmaxSW
All(cid:1)ThreeAlgorithms. 7:endif
8:if(max SW<θ u)then
21 :: pIn ri ot cia el diz ua rt eio Cn O: NST Tw ANo Tc Tlu Hs Rt Ee Sr HOle LDaf (Cr ^ec 1o l;r Cd ^s 2( lC )\(l, ⊳C \)Cl)
Talgorithm
1
19
0
1:
:
:C iFo fim
n
adp ta amr ne
a
yxa tSn imWd e;fi sn
(t
md
ar
aS
t
xW
w
Sio
t
Whf^r
m
>12
a
θxw u)Sit tWh hee
e
na qc uh alf^r to2jg mq j¼1
(continuedonnextcolumn) (continuedonnextpage)
7A.Fellah Array11(2021)100070
(cid:6) (cid:6) (cid:7) (cid:6) (cid:7)(cid:7)
Algorithm1(continued) j¼argming NEAR(cid:1)OPT C^l;j [NEAR(cid:1)OPT C^r;i(cid:1)j
12:(C^ 1,C^ 2)areverysimilar 1(cid:5)j<i DUPTREE 2 DUPTREE 2
13:StopandreturnmaxSW
14:endif
8. Evaluationmetricsandexperiments
15:endif
16:endfunction
8.1. Evaluationmetrics
1:functionCOMPUTE(θ c)
2:t←0.3(1(cid:1)θ u)\(⊳\)θ u:Monge-Elkan'sthreshold
3:x←thenumberofrepresentativeinC^ 2r (cid:1)1 The main goal of this experimental evaluation is to compare the
4:Letm←minimum(x,maximumnumberofallowedrepresentatives) performanceintermsofaccuracyandeffectivenessofallfouralgorithms
5:D←t/(maximumnumberofallowedrepresentatives) coveredinthiswork,ME,CT,VT,andFTalgorithms.Weadoptthepu-
6:θ c←2(cid:3)t(cid:1)m(cid:3)D
rity,inversepurity,andF-measuremetricsforourextensiveevaluation.
87 :: ere nt dur fn unθ cc
tion
DenotebyC^
¼
C^ 1;C^ 2;…;C^
qthesetofthetrueactualclusterswhere
1:functionCHECKSIMILARITY(C^ 1;C^ 2)\(⊳\)Checkdegreeofsimilarity:\(⊳\)very werefertoeachC^ iasaclassandletC¼ C 1;C 2;…;C kbethesetof
similar,similar,notsimilar near-duplicateclusterstobeevaluatedbytheSWalgorithm.Thenthe
2 3: :i (f C^(m 1,a Cx ^ 2S )W ar> evθ eu r) yth sie mn
ilar
p dr ee fic nis ei don a, sP foðC l^ loi w;C s:jÞandrecallRðC^ i;C jÞofC^ i withrespecttoC j are
4:endif
65 7 8:: : :i e i(f fC n^( (dm m1, ia afCx x^ 2S S)W War(cid:5) <esθ θiu lm )) i ta l han erd n(max SW(cid:6)θ l)then P(cid:6) C^ i;C j(cid:7) ¼(cid:4) (cid:4) (cid:4)C^ (cid:4) (cid:4)i C\ jC (cid:4) (cid:4) j(cid:4) (cid:4) (cid:4) and R(cid:6) C^ i;C j(cid:7) ¼(cid:4) (cid:4) (cid:4)C^ (cid:4) (cid:4) (cid:4)i C^\ iC (cid:4) (cid:4)
(cid:4)
j(cid:4) (cid:4) (cid:4)
9:(C^ 1,C^
2)arenotsimilar
10:endif where PðC^ i;C jÞ ¼ RðC j;C^ iÞ. Let n^ be the total number of clustered
11:endfunction
entities,includingnear-duplicates,purityisformulatedbytheweighted
1:functionCOMPARELEFT-RIGHTSUBTREES(C^ 1l;ðC^ 2l;C^ 2r Þ) averageofthemaximumprecisionvaluesachievedbytheclustersonone
2:FindmaxSWbetweenC^ 1l andeveryclusterinT^ 2\(⊳\)similartofunctionCOMPARE ofC^ j:
3
4
5:
:
:iS Mfu e(p
m
rp gao exs (e
CS
^m
W
1a
l
,x
>
CS ^θW
2u r)
)i ts hb ee ntweenC^ 1l andC^ 2r
fPurityg¼X j¼k
1
(cid:4)
(cid:4)C
^nj(cid:4)
(cid:4) m i¼aq 1x P(cid:6) C^ i;C j(cid:7)
6:RemoveC^ 1l
7:Representative←representativeofC^ 2r However,inversepurityconsiderstheclusterwithmaximumrecallfor
8:endif eachclassC^
,anditisobtainedbytakingtheweightedaverageofthe
9:if(θ c(cid:5)maxSW<θ u)then maximumreci
allvalues
11 1 110 2 3:: : :RM R ene ee m p dr rg o iee fv see(C n^ C t^ a1 t2l i, r vC e^ ←2r ) Unionofrepresentatives Inverse Purity¼X i¼q
1
(cid:4) (cid:4) (cid:4)C^ i(cid:4) (cid:4) (cid:4)^n m j¼ak 1x R(cid:8) C^ i;C j(cid:9)
14:if(maxSW<θ c)then
15:donothing Thevaluesofthepurityandinversepuritymetricsarewithintherangeof
16:endif 0–1.Thehigherpuritythebetteristheinversepurity.Puritypenalizes
17:endfunction
clusteringnoise(i.e.,duplicates)inacluster,whichmeansgroupingre-
cordsincorrectly,butitdoesnotrewardgroupingrecordsfromthesame
Withoutlossofgenerality,letassumeC^ l andC^ r
betheclusters
C^
j.Ifeveryclustercontainsonlyonerecord,themaximumpurityis1.
whose root
T^
1; and
C^ 2l
and
C^ 2r
be the
cl1
usters
ro1
oted in the right
wHo ow ule dve pr e, nr ae liv ze ers si pn lg ittt ih ne gr ro el ce oro df sC^ bea lon nd gC in, gth toat this ei sn av me erse clup su tr ei rty C^(C i; nC^ to)
subtreeT^ 2ofT^ ,orderedasðC^ 1l;C^ 1r Þ;ðC^ 2l;C^ 2r
Þ.
differentclusters.Inotherwords,inversepurityrewardsgroupingj
near-
AsaresultofTheorem6.1,westatethefollowingresults: duplicatestogether,butitdoesnotpenalizenoisyrecordsfromdifferent
Corollary7.1.NEAR(cid:1)OPT DUPTREEðC^ 1l;iÞ ¼ C^ j.Inasimilarwaytoprecisionandrecall,thereisatradeoffrelation-
8 shipbetweeninversepurityandpurity.Inversepurityrewardsgrouping
<C^ 1l
(cid:6) (cid:7) (cid:6) (cid:7) if i¼1 near-duplicatesandthemaximuminversepurityisachievedbyputting
:NEAR(cid:1)OPT
DUPTREE
C^l 2;j [NEAR(cid:1)OPT
DUPTREE
C^r 2;i(cid:1)j if i>1 allrecordsinonesinglecluster.ForeachclassC^ i,theF-measureofthat
classis:
(cid:6) (cid:7) (cid:6) (cid:7)
where (cid:6) (cid:7) 2(cid:3)P C^ ;C (cid:3)R C^ ;C
(cid:6) (cid:6) (cid:7) (cid:6) (cid:7)(cid:7) F C^ ;C ¼mak x (cid:6) i (cid:7)j (cid:6) i (cid:7)j
j¼argming NEAR(cid:1)OPT DUPTREE C^l 2;j [NEAR(cid:1)OPT DUPTREE C^r 2;i(cid:1)j i j j¼1 P C^ i;C j þR C^ i;C j
1(cid:5)j<i
TheF-measure,acombinationofpurityandinversepurity,isintherange
Corollary7.2.NEAR(cid:1)OPT DUPTREEðC^ 1r;iÞ¼
of ½0;1(cid:4) and a higher F-measure indicates a better clustering. The F-
8 measure, is in the range of ½0;1(cid:4), indicates a better clustering. The F-
<C^ 1r
(cid:6) (cid:7) (cid:6) (cid:7)
if i¼1
measureoftheclustering[35,36]whichcomputestheweightedaverage
:NEAR(cid:1)OPT C^l;j [NEAR(cid:1)OPT C^r;i(cid:1)j if i>1 ofmaximalF-measurevaluesisdefinedas:
DUPTREE 2 DUPTREE 2
where
8A.Fellah Array11(2021)100070
(cid:4) (cid:4)
F(cid:1)measure¼Xq F(cid:6)
C^ i;C
j(cid:7)(cid:4) (cid:4)
(cid:4)
(cid:4)
(cid:4)C C^
^i(cid:4)
(cid:4)
(cid:4)(cid:4) (cid:4) T Da eb tel ce ti1
onofnear-duplicatesinvotinglist1datasets.
i¼1 Votinglists List1RealDataSet255 Average
Runs run1 run2 run3 Avg
8.2. Experimentsanddatasets
NDGnear-duplicates 1058 947 1002 1002
Realdata&NDGnear-duplicates 1313 1202 1257 1257
Although ME and All(cid:1)Three algorithms are provably correct, but MEnear-duplicates 1142 1003 1078 1074
verifyingtheaccuracyofanimplementationisachallengingtask.With CTnear-duplicates 1054 987 1056 1032
no prepossessing steps, all these algorithms are implemented in Cþþ. VTnear-duplicates 1098 988 1003 1029
FTnear-duplicates 1064 968 998 1010
Theexperimentswerecarriedoutonseveralpubliclyavailablerealdata
setswhichcoveraspectrumofdifferentdatacharacteristicsandsizes.We
haveusedfourdifferentdatasetsinourexperiments.Threerealdatasets
fromvarioussourcesoftenusedinrelatedresearch,andthefourthlarge Table2
data set was generated synthetically (artificially) using the near- Detectionofnear-duplicatesinvotinglist2datasets.
duplicate generator (NDG) algorithm as described below. NDG gener- Votinglists List2RealDataSet975 Average
atestenofmillionsofnear-duplicatesforeachsetofrealdata. Runs run1 run2 run3 Avg
Algorithm2Near-DuplicateGenerator(NDG)Algorithm N ReD aG ldn ae ta ar- &du Np Dlic Gat ne es
ar-duplicates
1 28 85 37
2
1 29 80 71
6
1 28 84 10
5
1 28 86 46
1
MEnear-duplicates 1633 1818 1702 1717
1:Removearandomnumberofcharactersfromthedatasetrecord CTnear-duplicates 1793 1877 1823 1831
2:Replacearandomnumberofcharacterswithothers VTnear-duplicates 1859 1856 1803 1839
3:Flipthefirstandlastattributes(i.e.,flipthefirstandlastnamesinthelists) FTnear-duplicates 1855 1902 1857 1871
4:Duplicatearandomcharacter.Thismightbedonetomorethanonecharacter
5:Abbreviaterandomly-Keepthefirstcharacterbutthismightbeduplicatedor
removedasabove
Table3
Detectionofnear-duplicatesinCoradatasets.
Weranourexperimentsonfourcategoriesofdatasetasfollows. CoraDataSet CoraRealDataSet:21,152 Average
Voting1WeusedthelistofregistrarvotersinBritishColumbiaasour
Runs run1 run2 run3 Avg
originalsmalldatasetwithnoduplicates.Theoriginaltotalnumberof
NDGnear-duplicates 9320 12,754 10,487 10,853
recordsinthevotinglistis225and975records.Thenwecomplement
Realdata&NDGnear-duplicates 30,472 33,906 31,639 32,005
each of the two original voting data sets with a set of near-duplicates
MEnear-duplicates 11,412 11,674 10,078 11,054
generatedbytheNDGalgorithm.Additionally,weaugmentedandtop-
CTnear-duplicates 9234 12,657 10,456 10,782
pedthevotingdatasetto1977and3745references,respectively. VTnear-duplicates 9341 12,788 10,501 10,876
Cora2 Cora data set contains bibliographic records and citations in FTnear-duplicates 9289 12,768 10,485 10,847
scientificpapersclassifiedinseveralclasses.Thecoracitationdataset,
whichconsistsofadatasetoforiginalreferencesandresearchpapers,is
often used in the duplicate detection community. Additionally, we Table4
augmentedandtoppedthecoradatasetto21,152referencesand32,005, Detectionofnear-duplicatesinDBLPdatasets.
asubstantiallargerdatasetforourexperiments. DBLPDataSet DBLPRealDataSet:43,935 Average
DBLP3 DBLP is the bibliography database for computer science re-
Runs run1 run2 run3 Avg
cordsfromtheDBLPwebsite.Eachrecordisaconcatenationofauthor
NDGnear-duplicates 21,134 19,345 18,376 19,618
names(s),titleofthepublication,somekeywords,anabbreviatedrefer-
Realdata&NDGnear-duplicates 65,069 63,280 62,311 63,553
enceformatcitation(i.e.,journal,book,editor).Itconsistsof43,935real
MEnear-duplicates 22,160 20,018 19,102 20,426
objects,bothforrelationalandXMLdata.Additionallyandforourex- CTnear-duplicates 21,203 19,177 18,723 19,643
periments,weaugmentedthedatasetto63,553references. VTnear-duplicates 21,119 19,256 18,303 19,559
Synthetic4Thenear-duplicategeneratoralgorithm(NDG)iscapable FTnear-duplicates 21,147 19,257 18,362 19,589
ofalgorithmicallygeneratingtensofmillionsofsyntheticrecordsfroma
setororiginalrecords.Forinstance,thevoting,coraandDBLPdatasets
have been scaled up and topped by tens of thousands of records. The Table5
syntheticdatasetof573,879hasbeenaugmentedandtoppedbyNDGto Detectionofnear-duplicatesinSyntheticdatasets.
anaverageof352.992records,foranaveragetotalof926.871records SyntheticDataSet SyntheticDataSet:573,879 Average
overthreeruns.
We generated a random number (0–8) of near-duplicates for each
Runs run1 run2 run3 Avg
recordusingtheNDGalgorithmforthevotingandDBLPdatasets,anda NDGnear-duplicates 344,516 364,890 349,571 352.992
Realdata&NDGnear-duplicates 918,395 938,769 923,450 926.871
randomnumber(9–20)forthecoradataset.Finally,allgeneratednear-
MEnear-duplicates 348,602 361,768 352,459 354.276
duplicatesasexplainedaboveintheNDGalgorithmareappendedtothe
CTnear-duplicates 342,823 363,239 348,697 351.586
originaldatasetfile.Moreover,werantheNDGalgorithmthreetimes, VTnear-duplicates 343,945 363,885 348,880 352.236
foreachoriginalrealdata,togeneratethreedifferentsetsofdata(see FTnear-duplicates 344,323 364,299 349,105 352.575
Tables1-6).
8.3. Votinglistsdatasetsanalysis
First,weconsiderasmallsetofrecordsextractedfromthevotinglist1
1 http://ww.rootsweb.ancestry.com/canbc.vote898/votea.html. and list2 of 255 and 975 individuals, respectively. Then we ran three
2 http://www.cs.umass.eduandmccallum/code-data.html. timestheNDGalgorithmonthevotinglistswhereeachrunhasgenerated
3 http://www.informatik.uni-trier.de/ley/db/. alargerlistofnear-duplicates.Forinstance,run1generated1058near-
4 Algorithm2:Thenear-duplicategenerator(NDG)algorithm.
9A.Fellah Array11(2021)100070
Table6 (Figs.3and4inAppendix).However,theMEalgorithmisfarbehind
ME,CT,VTandFTalgorithms:Performanceevaluationofpurity,inversepurity withanaverageof808(4.12%)falsenegatives.
andF-measure.
Dataset near-duplicates Purity Inverse F-measure 8.5. Syntheticdatasetanalysis
Performance Purity
Anotherimportantobservationisthatthetuningparametersthatwe
VotingList1 ME 0.893 0.839 0.702 inserted in both ME and SW algorithms overall added some extra sig-
CT 0.986 0.913 0.956
nificantaccuracytothenear-duplicatedetection.Forinstance,andover
VT 0.980 0.952 0.968
FT 0.996 0.998 0.997 the926,871syntheticdataset(Table5,Figure5inAppendix).All(cid:1)Three
VotingList2 ME 0.812 0.907 0.821 algorithmsdetectedonly860(0.092%)falsenegatives.Thatis, anac-
CT 0.965 0.988 0.929 curacy of 99.90%. The ME algorithm performed also quite well over
VT 0.989 0.995 0.967
926,871syntheticlarge-sizeddatasetwith1284(0.14%)falsenegative,
FT 0.996 0.899 0.998
Cora ME 0.925 0.97 0.890 that is, an accuracy of 99.86%. Overall, ME and CT algorithms had
CT 0.968 0.988 0.929 missedtoidentifyaverysmallnumberoffalsepositives.Thatis,0.14%
VT 0.986 0.992 0.943 and0.15%over926,871records.OntheDBLPdataset,All(cid:1)Threeal-
FT 0.978 0.993 0.998 gorithms, in particular VT and FT algorithms, outperform the ME
DBLP ME 0.815 0.934 0.867
algorithm.
CT 0.978 0.988 0.932
VT 0.996 0.985 0.985
FT 0.999 0.979 0.998 8.6. Performanceevalution:purity,inversepurityandF-measure
Synthetic ME 0.945 0.957 0.921
CT 0.937 0.986 0.959
Withanextensiveexperimentalanalysis,the purity,inverseandF-
VT 0.964 0.983 0.994
FT 0.982 0.990 0.991 measureachievedavalueofnearly1.0,aprecisionwhichoutperforms
the seminal work of Monge-Elkan. For instance, in the ME algorithm
which is based on Jaro-Winkler's metric and using the attribute name
duplicatesforatotalof1313records.Thatis,theoriginalrealvotinglist1 provided by DBLP, the maximum F-measure is at threshold 0.8 and
hasbeentoppedby1058near-duplicates(Table1).Similarly,theorig- robustupto0.9.Theprecisiondropssteadilybelow0.8duetomanyfalse
inal real voting list2 has been topped by 1857 for a total of 2832 positives.However,withthesamealgorithmbasedonSmith-Waterman's
(Table2). metric,themaximumF-measureisatthreshold0.9andtheSWprecision
BothtablesshowtheresultsoftheNDGalgorithmonthevotinglists iswithintheinterval½0:9⋯1:0(cid:4)duetoprefixesandsuffixeswhichare
overthreeruns.Wecarriedouttheexperimentsbyrunningthefoural- ignored in some references. For the same algorithm and for different
gorithms,ME,CT,VT,andFTonthetotalnumberofrecords.Thereal metrics (i.e., Jaro-Winkler, Smith-Waterman, Levenshtein), the perfor-
dataistoppedbyduplicatesgeneratedbyNDG(4throwofTables1and
manceintermsofF-measure,precisionandrecallarequitedifferentifwe
2). Then we checked whether these algorithms identify the near- consideronlytheattributeaffiliationintheexperiment(Table6,Figure6
duplicates accurately. ME and All(cid:1)Three algorithms performed more thruFigure10inAppendix).Asneeded,thenearoptimalthresholdwas
orlessaccuratelyonsmalldatasetsizes(1257and2841votingrecords) notevaluatedonlyonce,butreevaluatedandreconfiguredifnecessaryas
becauseofthesmallamountofnoiseaddedtothedataset.Forinstance, records are added to clusters as illustrated in the set of figures in
onsmall-sizeddatasuchaslist2,CTandVTalgorithmsshowanaccuracy
appendix.
of98.34%ontheaveragewith31falsepositives((1831/1866þ1839/
1866)/2 ¼ 98.34%). However, FT algorithm's accuracy is 100.27% 9. Conclusion
wheretheextra0.27%representsfewfalsenegativesontheaveragein
list2(Figs.1and2inAppendix).TheMEalgorithmaccuracyis92.02%
In this paper, we have introduced a near-duplication detection
with149falsepositives.Still,theMEaccuracyisbehindtheperformance
frameworkbyimprovingMonge-Elkan'salgorithmandalsoincludingan
ofAll(cid:1)ThreeAlgorithms. affinevariantoftheSmith-Waterman'salgorithmtoreducethenumber
ofrecordcomparisons.Wehaveinvestigatedandimplementedafamily
8.4. CoraandDBLPdatasetsanalysis of algorithms – constant threshold (CT), variable threshold (VT) and
functionthreshold(FT)whicharecollectivelyreferredtoasAll(cid:1)Three
Ontheothertypes,medium-andlarge-sizeddata,All(cid:1)Threealgo- algorithms, all based on the merge-filter cluster representatives Mer-
rithmsconsistentlyoutperformedtheMEalgorithmintermsofaccuracy. ge(cid:1)Filter(cid:1)RCapproach.Ourexperimentswithreal-worldandgenerated
Onthenegativeside,theMEalgorithmadded2092falsenegativesin data sets have shown substantial gains in accuracy and potential effi-
run1,butconvergedto201falsenegativesontheaverageduetoread- ciency to detect near-duplicates in very large data sets and across
justing the threshold to 0.8 setby the algorithm(Fig.3 inAppendix). differentdomains.
Overall,theMEalgorithmaddedanextra1.85%offalsenegativesover Aswehavepredictedinthisinvestigation,theperformanceofMonge-
the 32,005 records (Table 3). The Merge(cid:1)Filter(cid:1)RC paradigm com- Elkan's algorithm which is mainly evaluated by the number of near-
plementedbythecomparisonandconstructionofclusterrepresentatives duplicateswithintheircorrectclusterswouldnotbeasgoodandaccu-
are very noticeable with a high similarity threshold which helped to rateasexpected.Thisisduetoseveralflawsinthealgorithm,including
improve the accuracy of All(cid:1)Three algorithms (Table 3, Fig. 3 in Ap- priorityqueueandunionsetstructures,recordcomparisonalgorithms,
pendix).ThishasbeenshownintheFTalgorithmwithonlyanaverageof restricted clustering methods, and other parameters. The Mer-
6 false positives (99.95% of accuracy) on the cora data set of 32,005 ge(cid:1)Filter(cid:1)RCapproach,complementedwiththe threeclasses ofalgo-
records. Furthermore, the FT algorithm added only 29 false positives rithmsachievesavalueofnearly1.0,aprecisionwhichisnearlyperfect
(99.85 of accuracy) on the DBLP data set of 63,553 records (Table 4, andoutperformstheseminalworkofMonge-Elkan.Ineachrunofthe
Figure4inAppendix).TheperformanceofAll(cid:1)Threealgorithmsisthe experiment, the major evaluation metric is the accuracy measured in
most substantial on DBLP with an average of 63,553 records where termsofnear-duplicateclusters.Theeffectofimperfectionintermsof
merging and filtering clusters’ representatives is accurately achieved numberofclustersandaccuracyisreflectedinclustermiss-classification
throughoutthesimilarityvariableandfunctionthresholds.Inparticular, with increasing dataset sizesin Monge-Elkan's algorithm.All of these
theVTandFTalgorithmsfalselydetectedanaverageofonly59and29 affecttheprecision,recall,andF-measuremetrics.Webelievethatthe
falsepositives,respectively.Thatis,anaccuracyof99.70%and99.86% cutoff and optimization values of threshold with other key tuning
10A.Fellah Array11(2021)100070
parameters throughout semi-supervised machine learning will signifi- followinga2012collaborativeworkshopledbyHarvardUniversityand
cantlyimprovethequalityoftheaccuracyandeffectivenessofdetecting the Wellcome Trust, with input from researchers, the International
near-duplicateclusters.Thisisbeinginvestigatedasthelikelydirection CommitteeofMedicalJournalEditors(ICMJE)andpublishers,including
andoutlookofourcurrentresearch. Elsevier,representedbyCellPress.
Acronyms Declarationofcompetinginterest
Merge(cid:1)Filter(cid:1)RC Merge-FilterRepresentative-basedClustering The authors declare that they have no known competing financial
CT ConstantThreshold interestsorpersonalrelationshipsthatcouldhaveappearedtoinfluence
VT VariableThreshold theworkreportedinthispaper.
FT FunctionThreshold
All(cid:1)Three ConstantThreshold,VariableThreshold,FunctionThreshold Acknowledgments
ME Monge-Elkan
SW Smith-Waterman IacknowledgethecollaborationofDr.MaamirAllaouawhocollab-
SNM SortedNeighborhoodMethod orated with me on several interrelated published papers. He is now
NDG Near-duplicateGenerator retired from the Dept. of Computer Science, University of Sharjah,
OPTðAÞ OptimalLocalAlignmentðAÞ SharjahUAE.Iwouldalsoliketothanktwograduatestudents,Sepideh
NEAR(cid:1)OPT DUPTREEðC^;iÞ near-optimalduplicatesubtreeforthenode PashamiandServehGhaderi,whospentoneentiretermcarryingoutthe
C^
usingiclusters
experimentsandprogrammingpartsreportedinthispaper.Ialsothank
ProfessorsA.ElmagarmidandV.Verykiosforprovidingmewithsomeof
theoriginalbenchmarkdatasets.
Creditauthorstatement
Appendix
CRediT (Contributor Roles Taxonomy) was introduced with the
intention of recognizing individual author contributions, reducing
authorshipdisputesandfacilitatingcollaboration.Theideacameabout
Fig.1. Votinglist1dataset:Trueduplicatesvs.ME,CT,VT,andFTAlgorithms
Fig.2. Votinglist2dataset:Trueduplicatesvs.ME,CT,VT,andFTAlgorithms
11A.Fellah Array11(2021)100070
Fig.3. Coradataset:Trueduplicatesvs.ME,CT,VT,andFTAlgorithms.
Fig.4. DBLPdataset:Trueduplicatesvs.ME,CT,VT,andFTAlgorithms.
Fig.5. Syntheticdataset:Optimalduplicatesvs.ME,CT,VT,andFTAlgorithms
12A.Fellah Array11(2021)100070
Fig.6. Votinglist1dataset:Optimalmeasuresvs.ME,CT,VT,andFTmeasures
Fig.7. Votinglist2dataset:Optimalduplicatesvs.ME,CT,VT,andFTmeasures
Fig.8. Coredataset:Optimalduplicatesvs.ME,CT,VT,andFTmeasures
13A.Fellah Array11(2021)100070
Fig.9. DBLPdataset:Optimalduplicatesvs.ME,CT,VT,andFTmeasures
Fig.10. Syntheticdataset:Optimalduplicatesvs.ME,CT,VT,andFTmeasures
[6] WeisM,NaumannF,BrosyF.Aduplicatedetectionbenchmarkforxml(and
relational)data.In:ProceedingsoftheSIGMODinter.Workshoponinformation
References qualityforinformationsystems.IQIS);2004.p.10–9.
[7] YanS,LeeD,KanM,GilesL.Adaptivesortedneighborhoodmethodsforefficient
[1] NewcombeH,KennedyJ,AxfordS,JamesA.Automaticlinkageofvitalrecords. recordlinkage.In:Proceedingsofthe7thACM/IEEE-CSjointconf.onDigital
JSci1959;130(3881):954–9. libraries;2007.p.185–94.
[2] ChristenP.Asurveyofindexingtechniquesforscalablerecordlinkageand [8] HernandezM,StolfoS.Themerge/purgeproblemforlargedatabases.In:
deduplication.IEEETransactionsonKnowledgeandDataEngineering(TKDE2012; ProceedingsoftheACMSIGMODinternationalconferenceonmanagementofdata;
24(9):1537–55. 1995.p.127–38.
[3] JaroM.Advancesinrecord-linkagemethodologyasappliedtomatching.JAmStat [9] PapenbrockT,NaumannF,HeiseA.Progressiveduplicatedetection.IEEETrans
Assoc1989;84(406):414–20. KnowlDataEng2018;27(5).1316–132.
[4] MongeA.Adaptivedetectionofapproximatelyduplicatedatabaserecordsandthe [10] DraisbachU,NaumannF.Onchoosingthresholdsforduplicatedetection.In:
databaseintegrationapproachtoinformationdiscovery.Ph.D.thesis,Ph.D.Thesis. Proceedingsofthe18thinternationalconferenceoninformationquality.ICIQ);
SanDiego:Dept.ofComp.Sci.andEng.,Univ.ofCalifornia;1997.
2013.p.37–45.
[5] WhangS,MenestrinaD,KoutrikaG,TheobaldM,Garcia-MolinaH.Entity [11] ElmagarmidA,IpeirotisP,VerykiosV.Duplicaterecorddetection:asurvey.IEEE
resolutionwithiterativeblocking.In:ProceedingsoftheACMinternational
TransKnowlDataEng2007;19(1):1–16.
conferenceonmanagementofdata.SIGMOD);2009.p.219–32. [12] ChenQ,ZobelJ,VerspoorK.Duplicates,redundanciesandinconsistenciesinthe
primarynucleotidedatabases:adescriptivestudy,JounalofBiologicaldatabases
andcuration.2017.p.2–16.https://doi.org/10.1093/database/baw163.
14A.Fellah Array11(2021)100070
[13] XiaoC,WangW,LinX,YuJ,WangG.Efficientsimilarityjoinsfornear-duplicate [28] ThyagharajanKK,KalaiarasiG.Areviewonnear-duplicatedetectionofimages
detection.ACMTransDatabaseSyst2011;36(3):15–41. usingcomputervisiontechniques.ArchComputMethodsEng2021;28:897–916.
[14] MongeA,ElkanC.Domain-independentalgorithmfordetectingapproximately [29] DraisbachU,NaumannF,SzottS,WonnebergO.Adaptivewindowsforduplicate
duplicatedatabaserecords.In:ProceedingsoftheACMSIGMODworkshopon detection.In:ProceedingsoftheIEEE28thinternationalconferenceondata
researchissuesondataminingandknowledgediscovery.DMKD);1997.p.23–9. engineering.ICDE);2012.p.1073–83.
[15] FellahA,MaamirA.Adomainindependentmethodologyfornear-duplicate [30] JaroM.Probabilisticlinkageoflargepublic.JournalofStatisticsinMedicine1995;
detection.In:Proceedingsoftheinternationalconferenceonappliedcomputing, 84(406):414–20.
madridSpain;2012.p.139–46. [31] HernandezM,StolfoS.Real-worlddataisdirty:datacleansingandthemerge/
[16] NavarraG.Aguidedtourtoapproximatestringmatching.ACMComputSurv2001; purgeproblem.DataMinKnowlDiscov1998;2(1):9–37.
33(1):31–88. [32] KopckeH,RahmE.Frameworksforentitymatching:acomparison.DataKnowlEng
[17] D.Moreira,al,Imageprovenanceanalysisatscale,IEEETransImageProcess27 2010;69(2):197–210.
(12). [33] PapadakisG,SvirskyJ,GalA,PalpanasT.Comparativeanalysisofapproximate
[18] FellahA,MaamirA.Near-optimaldomainindependentapproachfordetecting blockingtechniquesforentityresolution.In:ProceedingsoftheVLDBendowment.
duplicates.In:Proceedingsofthe19thinternationalconferenceondatamining, PVLDB);2016.p.684–95.
multimediaandimageprocessing.ParisFrance;2017.p.2633–42. [34] PapadakisG,AlexiouG,PapastefanatosG,KoutrikaG.Schema-agnosticvsschema-
[19] BharambeD,JainS,JainA.Asurvey:detectionofduplicaterecord.International basedconfigurationsforblockingmethodsonhomogeneousdata.In:Proceedings
JournalofEmergingTechnologyandAdvancedEngineering2012;2(11):298–307. oftheVLDBendowment.PVLDB);2015.p.312–23.
[20] Hassanian-esfahaniR,KargarMj.Sectionalminhashfornear-duplicatedetection. [35] VogelT,HeiseA,DraisbachU,LangeD,NaumannF.Reachforgold:anannealing
ExpertSystAppl2018;99(1):203–12. standardtoevaluateduplicateselectionresults.ACMJournalofDataand
[21] HerschelM,NaumannF,SzottS,TaubertM.Scalableiterativegraphduplicate InformationQuality2014;5:1–22.
detection.IEEETransKnowlDataEng2012;4(11).2294–2108. [36] VogelT,NaumannF.Instance-based“one-to-some”assignmentofsimilarity
[22] NaumannF,HerschelM.Anintroductiontoduplicatedetection.SynthesisLectures measurestoattributes.In:Proceedingsoftheinternationalconferenceon
onDataManagement2010;2(1):1–87. cooperativeinformationsystems.CoopIS);2011.412–0420.
[23] WinklerW.Overviewofrecordlinkageandcurrentresearchdirections.AStatistical [37] SmithT,WatermanM.Identificationofcommonmolecularsubsequences.JMol
ResearchDivision,U.S.CensusBureau;2006.p.1–44. Biol1981;147.195–107.
[24] WinklerW.Approximatestringcomparatorsearchstrategiesforverylarge [38] NeedlemanS,WunschC.Generalmethodapplicabletothesearchforsimilaritiesin
administrativelists,AStatisticalResearchReportSeries(Statistics2005-02).U.S. theaminoacidsequenceoftwoproteins.JMolBiol1970;48:443–53.
CensusBureau;2005.p.1–9.02. [39] DeepaK,RangarajanR,SelviM.Automaticthresholdselectionusingpsoforga
[25] BaxterR,ChristenP,ChurchesT.Acomparisonoffastblockingmethodsforrecord basedduplicaterecorddetection.IntJComputAppl2013;62(4):181–7.
linkage.In:ProceedingsoftheACMSIGKDDworkshopondataCleaning,Record [40] dosSantosJ,HeuserA,MoreiraV,WivesL.Automaticthresholdestimationfordata
linkage,andobjectconsolidation;2003.p.25–8. matchingapplications.InfSci2011;181(13):2685–99.
[26] MongeA.Matchingalgorithmswithinaduplicatedetectionsystem.IEEEData [41] ChengD,KannanR,VempalaS,WangG.Adivide-and-mergemethodologyfor
EngineeringBulletin2000;23(4):14–20. clustering.ACMTransDatabaseSyst2006;31(4):1499–525.
[27] YandrapallyR,StoccoA,MesbahA.Near-duplicatedetectioninwebappmodel [42] LiM,WangH,LiJ,GaoH.Efficientduplicaterecorddetectionbasedonsimilarity
inference.In:ProceedingsoftheACM/IEEE42ndinternationalconferenceon estimation.In:Proceedingsofthe11thinter.Conf.onWeb-pageandInformation
softwareengineering;2020.p.186–97. Management(WAIM);2010.p.595–607.
15