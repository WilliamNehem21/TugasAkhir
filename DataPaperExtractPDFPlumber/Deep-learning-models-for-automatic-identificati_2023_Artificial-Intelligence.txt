ArtificialIntelligenceinAgriculture7(2023)1–12
ContentslistsavailableatScienceDirect
Artificial Intelligence in Agriculture
journal homepage: http://www.keaipublishing.com/en/journals/artificial-
intelligence-in-agriculture/
Deep learning models for automatic identification
of plant-parasitic nematode
NabilaHusnaShabrinaa,⁎ ,RyukinArantaLikaa,SiwiIndartib
aDepartmentofComputerEngineering,UniversitasMultimediaNusantara,Jl.ScientiaBoulevard,Tangerang15111,Indonesia
bDepartmentofPlantProtection,FacultyofAgriculture,UniversitasGadjahMada,Jl.Flora,Bulaksumur,Yogyakarta55581,Indonesia
a r t i c l e i n f o a b s t r a c t
Articlehistory: Plant-parasiticnematodescausevariousdiseasesthatcanbefataltotheinfectedplants.Itcauseslossestothe
Received29July2022 agriculturalindustry,suchascropfailureandpoorcropquality.Developinganaccuratenematodeclassification
Receivedinrevisedform21October2022 systemisvitalforpestidentificationandcontrol.DeeplearningclassificationtechniquescanhelpspeedupNem-
Accepted30December2022 atodeidentificationasitcanperformtasksdirectlyfromimages.Inthepresentstudy,fourstate-of-the-artdeep
Availableonline4January2023 learningmodels(ResNet101v2,CoAtNet-0,Effi-cientNetV2B0,andEfficientNetV2M)wereevaluatedinplant-
parasiticnematodeclassificationfrommicroscopicimage.Themodelsweretrainedusingacombinationof
Keywords:
threedifferentoptimizers(Adam,SGD,danRMSProp)andseveraldataaugmentationwithimagetransforma-
Augmentations
Classifications tions,suchasimageflip,blurring,noiseaddition,brightness,andcontrastadjustment.Theperformanceofthe
Deeplearning trainedmodelswasvaried.Regardingtestaccuracy,EfficientNetV2B0andEfficientNetV2MusingRMSPropand
Nematode brightnessaugmentationgivethebestresultof97.94%However,theoverallperformanceofEfficientNetV2M
Optimization wassuperior,with98.66%meanclassaccuracy,97.99%F1score,98.26%averageprecision,and97.94%average
recall.
©2023TheAuthors.PublishingservicesbyElsevierB.V.onbehalfofKeAiCommunicationsCo.,Ltd.Thisisanopen
accessarticleundertheCCBY-NC-NDlicense(http://creativecommons.org/licenses/by-nc-nd/4.0/).
1.Introduction observationandclassificationofplantparasiticnematodeisessential
forpestidentificationandcontrol.Therefore,thedevelopmentofauto-
Nematodesareoneofthelivingthingswithveryabundantanddi- maticimage-basedmethodscapableofidentifyingnematodesquickly
versespecies(Abadetal.,2008).Fromthe26,000typesofnematodes andreliablyisrequired.
identified,thereareover4100plant-parasiticnematodes(Jonesetal., Implementingdeeplearningtechniquesinimage-basedclassifica-
2013).Plant-parasiticnematodesaremicroorganismsthatcauseexten- tionbecameanalternativeforspeedingupthenematode'sidentifica-
sivedamageandsubstantialcropyieldlosses(DeandElsen,2007).They tionprocess,asitissuitablefordetectingdiscriminativenematodes
willcontinuetothreatenagriculturalproductionsincetheyarefound featuresandhandlinglargespecimens.Variousdeeplearningclassifica-
andinfectvariousplants,includingfoodcrops,horticulture,andestate. tiontechniquesarereadilyavailable(e.g.,KerasandTensorFlow)and
Estimationoftheworld'seconomiccroplossescausedbyparasiticnem- areeasytoimplement.Thedeeplearningtechniquesarealsoproven
atodesmayreach80billionUSD.InIndonesia,nematodesproblemsin- torecognizepestsanddiseases,suchasinleaves,withhighaccuracy
creaseyearlysincethemostdestructiveplant-parasiticnematodeson byprovidingsufficientdata(Lietal.,2021).
potato,Globoderarostochiensis,wasfound(Indartietal.,2004)and ConvolutionalNeuralNetworks(CNN)viatransferlearningwere
fallowed their distribution become wider in potato growing areas. implementedformulti-cropleafdiseaseimageclassification.Thispro-
Newspeciesofplantparasiticnematodeswerealsofoundinrice,garlic, posedresearchhasachievedaccuracyforgrapeandtomatoleafdisease
andpotato(Ajrietal.,2021;Indartietal.,2018;Mutala'liahetal.,2018). classificationby98.40%and95.71%,respectively(PaymodeandMalode,
Plantparasiticnematodesaretinylifeformsvaryinginsizeand 2022).DataaugmentationandextensionofdeeplearningVGG-16pre-
shape.Duetotheirlittlemeasureandtheassortmentofgenera,itbe- trainednetworkmodelwereappliedforthemulti-pestclassificationof
comeschallengingtodistinguishwhichsortsareshowninaspecific Indonesianmangoleavesimage.Theoverallaccuracyachievedfrom
test.Thecurrentstrategymaybeaconventionalonewhichistime- thosetrainingis73%onthevalidationdatasetand76%forthetesting
consuming and helpless to error. Improvement technique for data(Kusrinietal.,2020).ImprovedCNNwasbuiltforthereal-timede-
tectionofappleleafdiseases.Usingadatasetof26,377imagesofdis-
⁎ Correspondingauthor. eased apple leaves, the implementation of INAR-SSD (SSD with
E-mailaddress:nabila.husna@umn.ac.id(N.H.Shabrina). Inception module and Rainbow concatenation) gave a detection
https://doi.org/10.1016/j.aiia.2022.12.002
2589-7217/©2023TheAuthors.PublishingservicesbyElsevierB.V.onbehalfofKeAiCommunicationsCo.,Ltd.ThisisanopenaccessarticleundertheCCBY-NC-NDlicense(http://
creativecommons.org/licenses/by-nc-nd/4.0/).N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
performanceof78.80%mAPonthedataset(Jiangetal.,2019).Thecor- modelusingseveralaugmentationandoptimizerfunctioncombina-
relationeffectofseveraloptimizationtechniquesonCNNperformance tions.Theresultwasrecordedandanalyzedbasedonthemetricperfor-
forolivediseaseclassificationwasalsoobserved.Itwasfoundthatthe mance.Thebestperformanceisthendeployedasaweb-basedsystem.
highestrateintheexperimentwithoutdataaugmentationwas92.59%
(Raouhietal.,2022). 2.2.Nematodesdataset
Thereareseveralworksimplementedfornematodesclassification
usingdeeplearning.Xceptionmodelsweretrainedwithdifferentinitial 2.2.1.Datacollection
conditionsonthedatasetofvariousstagesofnematodes(bothjuvenile Allnematodeswerecollectedfromaninfectedagriculturalplantin
and adult). It is found that the model with pretrained weights on Indonesiatogathertherequiredpictures.Nematodeswereisolated
ImageNet performed the best compared to random weight and no fromplantrootandrhizospheresoilandthenproceededtothespeci-
weightinitialization.However,duetohardwarelimitations,theauthors menforfurtherobservation.First,soilsampleswereextractedfornem-
couldnottrainbetterbutheaviermodels,andtheimagesinthedataset atodes presence utilizing the adjusted Whitehead Tray method.
lackvariation(Uhlemannetal.,2020).Anotherresearchfocusedonin- Nematodesextractionsfromrootsampleswerecutinto1mmpieces;
creasingtheavailabilityofnematodesdatasetstothepublicwhilepro- atthatpointwerelaidonthechannelpaperonthenylonscreenbol-
vidingspeciesrecognitionbenchmarksbytestingmultiplestate-of-the- steredbythealteredbucket,allowingwatertojointheroottests.The
artdeeplearningmodelsonthedataset.Thedatasetconsistsof2769 nematodesswimmingouttothewaterwerecollectedonthetubesto
nematodes samples classified manually into 19 classes. From this assistbothmorphologicalperceptions.Theplungingwasatroomtem-
benchmark,itisfoundthattheResNetfamilymodelhasthehighest peraturefor24h.ThismethodalludedtoWhiteheadPlateMethod
performanceintermsofaccuracy(Lietal.,2021).Anewproposed (Southey,1986)withadjustment.Beforefurtherobservation,nema-
CNNmodel,definedasNemaNet,wasusedtoidentifyanewdataset todeswerekilled,andfixedwithcooledFormalinAceticAcid(FAA)re-
fornematodessoybeancropinBrazil.TheNemaNetmodelreached ferred to (Southey, 1986). Finally, the nematodes morphological
96.99%accuracy,whilethebestfoldwas98.03%(Abadeetal.,2022). charactersofeachgenuswereobservedusingalightmicroscopeOlym-
Previousresearchdoesnotincludemanyothernematodesspecies pusCX31withamagnificationof40–1000.Theimagewascaptured
commonlyfoundinIndonesia.Thisresearchprovidesdatathatcontains withopticalconnectedwiththemicroscopeandlaptop.
these species and assesses the performance of a state-of-the-art Datasetconsistsof957nematodesamplesthatwereclassifiedinto
deeplearningmodelforuseinIndonesia.Thispapercomparesfour 11classifications.Thisdatasetrepresentsnematodescommonlyfound
state-of-the-art deep learning models (ResNet101v2, CoAtNet-0, inIndonesiansoil.Table1showssomestatisticsofnematodesgenus
EfficientNetV2B0,andEfficientNetV2M)trainedonnematodesdataset distributioninthedataset.Asshowninthegiventable,thegenusdistri-
speciescommonlyfoundinIndonesiansoil.Dataaugmentationwas butionisdiverse.Genuswithlessthan65imagesaccountsfor45%ofthe
employedtodetermineifimagetransformationcanfurtherincrease wholeclass.Thishappenedduetothelimitednematodesdistribution
theaccuracyofthetestedmodels.Theeffectofseveraloptimizerfunc- areaandonlyaspecifichostthatcoulddevelopthenematode.Fig.2
tionswasalsoobservedontheperformanceresult.Thecontributions presentssamplenematodesimagesfromthedataset.
ofthepaperarelistedasfollows:
2.2.2.Datapreprocessing
• Tobuildanadditionalimagedatasetforspeciesofnematodescom-
Obtainedsamplesarethenpreprocessedwithasimilarmethodused
monlyfoundinIndonesia
forpreviouswork(Luetal.,2021).Sampleswerecroppedbasedon
• Toprovidemodelbenchmarkcomparisonforrealclassificationsys-
edgedetectioninanattempttoequalizewhichregionsthenematodes
temimplementation
specimenexistsintheimage.Thisalsoreducesredundantinformation
• To implement 4 state-of-the-art deep learning techniques
bycuttingemptyspaces.Sampleswereconvertedintograyscaleimages
(ResNet101v2,CoAtNet-0,EfficientNetV2B0,andEfficientNetV2M)
sinceclassificationissolelybasedonmorphologicalfeaturesofthesam-
formulti-classclassificationofplant-parasiticnematodes
ples.Allimagesarethenresizedto224×224tofittheinputsizeofall
• To evaluate the performance of 4 state-of-the-art deep learning
testedmodels.ThedatapreprocessingstepsareshowninFig.3.
modelswithrespecttodataaugmentationandoptimizerfunction
• Todesignanddevelopawebapplicationtoclassifyplant-parasitic
2.2.3.Dataaugmentationprocess
nematodes
Dataaugmentationprocessesoftenincreaseimagediversityina
datasetbyapplyingimagemanipulationtechniquesorsynthetically
creatingnewdata.Thisprocessaimstoincreasegeneralization,prevent
Thestructureofthispaperisorganizedasfollows.Section2presents modeloverfittingtothetrainingdatasetandleadtobetterperformance
MaterialsandMethod,startingwiththedatasetsandthendescribing (ShortenandKhoshgoftaar,2019).Commonmanipulationtechniques
theimplementeddeeplearningarchitecture.Section3presentsthede- appliedindataaugmentationprocessesincludeimagetransformation
tailedResultandDiscussiononthecomparisonof4state-of-the-art byflipping,rotation,translation,noiseaddition,blurring,changein
deeplearningmodelsformulti-classclassificationofplant-parasitic brightness,contrast,andothercolorspacetransformations.Thiswillin-
nematodes.Finally,inSection4,thepaperconcludeswitharemarkon creasethediscriminativefeatureofeachclassthatmodelneedstolearn
themodelcomparisonandsomeperspectiveforfuturework. tonotoverfit.Imagemanipulationtechniquesneedtobechosenbased
onthenatureofthesample,assomeimagetransformationscanresult
2.Materialsandmethods incontextuallyincorrectdatathatdoesnotreflectthenatureofthe
realspecimen.Withthecorrectaugmentationtechniques,modelper-
2.1.Proposedresearch formancecanbeimproved,especiallyonthedatasetwithimbalanced
classdistribution.However,theaugmentationprocessincreasesthe
TheschematicinFig.1showsanoverviewworkflowformulti-class timeitrequiredtotrainthemodelasitincreasesthesizeofthedataset.
plant-parasiticnematodesclassification.Initially,plant-parasiticnema- Imagetransformationtechniquesalsoaffectmodelaccuracy,assome
todesdatasetiscollectedandclassifiedintoseveralclasses.Datapre- techniquesdecreasemodelaccuracy(Shijieetal.,2017).
processingwasappliedtothedatasetusingedgedetection,cropping, Thisresearchappliedaugmentationonthefly(onlineaugmenta-
andconvertingintograyscale.Imageflip,noiseaddition,imageblurring, tion)toincreasedatadiversity.Imagemanipulationtechniquesused
brighteningandcontrastareappliedinsingleaugmentationtoenhance are flipping (horizontally and vertically), noise addition, blurring,
thesizeofthedataset.Thephotosarethenusedasinputtotrainthe change in brightness, and change in contrast. Some manipulation
2N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
Fig.1.Researchworkflow.
techniquessuchastranslationandrotationwerenotchosenduetothe 3. Imageblurringisperformedbyapplyingagaussianfilterwithaker-
concernthataugmentationresultscouldhideimportantdiscriminative nelsizeof{3×3}andstandarddeviationvalueof1.Thisisapplied
featuresofthesample,whichcandecreasemodelaccuracy.Thefollow- randomlywithaprobabilityof50%oneachsample.
inglistdescribestheappliedimageaugmentation. 4. Changeinbrightnessisappliedbytheincreaseofbrightnesswith
brightnessparameterofrandomvaluefrom0to0.3
1. Imageflipisappliedrandomlyonimagesinthedataset,andthe
5. Changeincontrastisappliedbyincreaseofcontrastwithcontrastpa-
fliptypeischosenrandomlyaswell,whethernoflipisapplied,the
rameterofrandomvaluefrom0to3.
horizontalflipisapplied,theverticalflipisapplied,orbothflipsare
applied.
2. Noiseadditionisperformedbyaddingwhitegaussiannoisetothe Thedatasetsandtheiraugmentedvariationsarethenusedtotrain
imagesamplewithameanvalueof0andastandarddeviationof themodels.Inevaluatingthemodelperformance,thedatasetissplit
0.15.Thisisappliedrandomlywithaprobabilityof50%oneachsample. intoatrainingset,validationset,andtestsetwitharatioof80:10:10.
Tosummarize,thedatasetconsistsof957nematodessamplewith11
classifications,splitinto766,96,and95fortraining,validation,and
Table1
Nematodegenusdistributioninthedataset. test respectively. Note that augmentation processes are performed
onlyonthetrainingsetofthedataset.
Genus No.ofsamples
GenusCriconema 3
GenusCriconemoides 103
2.3.Deeplearningarchitecture
GenusHelicotylenchus 135
GenusHemicycliophora 6
GenusHirschmanniella 130 Nematodesclassificationsareperformedusingseveralstate-of-the-
GenusHoplolaimus 151 artmodelsintermsofimageclassificationproblems,namelyResNetV2,
GenusMeloidogyne 211 CoAtNet,andEfficientNetV2.Modelfamiliesarechosenbasedontheir
GenusPratylenchus 116
GenusRadopholus 12
performanceonImageClassificationonImageNetBenchmark(Keras,
GenusTrichodorus 30 2021;Stojnicetal.,2022).Basedonhardwarelimitationsandthesize
GenusXiphinema 60 ofdatasetsusedintheexperiments,aspecificvariantofmodelsapplied
Total 957 areResNet101V2,CoAtNet-0,EfficientNetV2B0,andEfficientNetV2M.
3N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
(a) Genus Criconema (b) Genus Criconemoides (c) Genus Helicotylenchus
(d) Genus Hemicycliophora (e) Genus Hirsmaniella (f) Genus Hoplolaimus
(g) Genus Meloidogyne (h) Genus Pratylenchus (i) Genus Radopholus
(j) Genus Trichodorus (k) Genus Xiphinema
Fig.2.Sampleofplant-parasiticnematodesusedinthisstudy
2.3.1.Residualnetworks
TheoriginalResidualNetworks(ResNet)architectureisaCNNbased
on VGG architecture that employs residual learning in its building
blocksbyaddingshortcutconnectionsthatskipsoneormorelayers.
This alleviates the degradation problem that VGG architecture has
whenadeepermodelisused(Heetal.,2016a).TheResNetV2istheim-
provedversionofResNetarchitecturethatimprovesthespeedofdata
propagationoneachresidualblockbyutilizingidentitymappingas
Fig.3.Datapre-processingflowchart. the skip connections and after-addition activation. This eases
4N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
Fig.4.ResNet101V2networkarchitecture.
optimizationlosscomparedtothebaselineResNetandimprovesthe
regularizationofthemodels.SeveralvariationsoftheResNetmodels,
basedonthenumberoflayersinsidethenetwork,areResNetV2–50,
ResNetV2–101,andResNetV2–1522(Heetal.,2016b).TheResNet
modelnetworkarchitectureimplantedinthispaperispresentedin
Fig.4.
2.3.2.Convolutionandattentionnetworks
TheConvolutionandAttentionNetworks(CoAtNet)architectureisa
familyofhybridmodelsthatcombinesCNNandTransformerarchitec-
turetoachievebettergeneralizationandlargercapacity.Transformer
architectureswithaself-attentionmechanismhaveahighermodelca- Fig.6.EfficientNetV2B0networkarchitecture.
pacitythatcanbenefitfromlargerandmorediversedatasets,mean-
while,convolutionalarchitectureshaveabettergeneralizationand
faster-converging speed. This architecture consists of 5 stages (1 improvedevenfurtherbyemployingFused-MBConv.Thespecificcom-
convolutionallayer,2MBConvlayers,and2transformerlayers),with
binationofMBConvandFused-MBConvusedinthenetworkimproves
differentpropertiesdependingonthemodelvariant.Themainvariation
trainingspeedanddecreasesthemodelsize.Thenewandimproved
of the CoAtNet model consists of 5 basic variations (CoAtNet-0 to modelsarethencalledEfficientNetV2,whichwithaspecifictraining
CoAtNet-4) and 3 variations with different block parameters method,canachieve5×–11×faster-convergingspeedcomparedto
(CoAtNet-5toCoAtNet-7)(Daietal.,2021).TheCoAtNetnetworkarchi-
otherstate-of-the-artmodelswithupto6×smallerinsize(Tanand
tectureispresentedinFig.5. Le,2021).EfficientNetV2implementedinthisresearchwasB0andM
version.EficcientNetV2B0hasbettertrade-offonaccuracyandFLOPs,
2.3.3.EfficientNet whileEfficientNetV2MreducesparameterandFLOPsbutrunfasterin
ThebaselineEfficientNetarchitectureisbasedonanewscaling trainingandinferencecomparedtotheV1-B7version(TanandLe,
methodforincreasingmodelcapacitybyscalingthedimensionsof 2021).TheappliedEfficientNetV2B0andEfficientNetV2Mnetworkar-
width,depth,andresolutionofthemodelusingasimplecompoundco- chitectureinthisresearcharepresentedinFig.6andFig.7,respectively.
efficient(TanandLe,2019).NeuralArchitectureSearch(NAS)isthen
usedtodesignanewbaselinemodelusingMBConvblocksandscaleit
usingthecompoundcoefficienttocreateEfficientNet(Elskenetal., 2.3.4.Proposedclassificationnetworks
2019).Thisnewfamilyofmodelsachievestate-of-the-artperformance The weights of each model are preserved from the pre-trained
onImageNetdatasetwhilehavingafarsmallermodelandfastercon- model based on ImageNet dataset, with its ImageNet classification
verging speed (Tan and Le, 2019). This family of models are then headlayerremoved.Featureextractionvectorsofeachmodelarethen
Fig.5.CoAtNetnetworkarchitecture.
5N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
(SoftMax),batchsizeof32,andsameoptimizerparameters(learning
rateof0.001forAdamandRMSprop,0.01forSGD;themomentumof
0forSGDandRMSprop;abetavalueof0.9–0.999forAdam),input
sizeof224x224x3,andsparsecross-entropylossfunctionformulti-
labelclassificationproblem.Thetrainingepochwassetto100.
2.3.6.Evaluationmetrics
Severalevaluationmetricswereemployedinthisexperiment.Test
Accuracyisusedtoevaluatetheaverageaccuracyofthemodelover
allimagesonthetestset.TheF1-scoremetricisaclassificationevalua-
tionmetricbasedontheharmonicmeanofprecision,andrecallisoften
usedwhentheclassdistributioninthedatasetisimbalanced.Weighted
F1-scoremetricwasusedtoevaluatetheimbalanceddatasets.Average
precisionandrecallwererecordedfordatacompleteness.Theformula
fortestaccuracy,F1score,averageprecisionandrecallaregivenin
Eqs.(1)–(4),respectively(Alsaggafetal.,2020).
TPþTN
TestAccuracy¼ ð1Þ
TPþTNþFPþFN
TP
Precision¼ ð2Þ
TPþFP
Fig.7.EfficientNetV2Mnetworkarchitecture.
TP
Recall¼ ð3Þ
TPþFN
connectedtoadenselayerwithSoft-Maxactivationtoperformclassifi- 2xPrecisionxRecall
F1score¼ ð4Þ
cation,withclasscountadjustedtothedatasetused,whichis11genus PrecisionþRecall
classifications.TheproposedclassificationlayerisdepictedinFig.8.
whereTP–TruePositive;FP–FalsePositive;TN–TrueNegative;FN–
FalseNegative.Anotherevaluationmetricappliedinthisexperiment
2.3.5.Optimizationtechniques isMeanClassAccuracy(Dikeretal.,2019;Toğaçaretal.,2021).Itisused
Threedifferentoptimizerswereusedinthetrainingprocesstode- toevaluatetheaccuracyofeachclassthatcouldindicateifthemodel
terminethebestoptimizerforeachtypeofmodelandwhetherarchi- learnsdiscriminativefeaturesofeachclasscomparedtoothermodels.
tecture or dataset diversity affects the optimizers' use. This also TheformulaisgiveninEq.(5)
minimizeunfairadvantageofsomemodelincaseofhyperparameter
fits the exactrequirementof a specific model-dataset combination MeanClassAccuracy¼1 ∑c 1 ∑ni ai ð5Þ
thatcanachievebetterperformance.Optimizersthatwereusedinthe c i¼1n i j¼1 j
experimentsareAdam,SGD,andRMSprop.Adamischosenbasedon
itsfavorableperformancecomparedtootheroptimizationmethod,as wherecisthenumberofclasses(11classesfornematodesgenus),n iis
ittendstoworkwellinpractice(KingmaandBa,2014).SGDischosen thenumberoftheimageini−thclass,a jiistheaccuracyforimage
torepresentgradientdescentoptimizersandisoftenusedtoproduce numberj−thini−thclass.
thestate-of-the-artresultsinsomedeeplearningresearch.SGDalso
produce better generalization performance (Zhou et al., 2020). 2.3.7.Systemimplementation
RMSpropwaschosenasitissuitableforoptimizingnon-stationary Code implementation of each model is achieved using Keras
andnon-convexproblems(Sunetal.,2020). (Chollet,2015)andTensorFlowlibrarythatprovidesfullybuiltmodels
For consistency, each model will be trained using the same withpretrainedweightsonImageNetdataset.Modeltrainingandinfer-
hyperparametervalue,includingthesameactivationfordenselayer encewillbeperformedontheGoogleColabNotebook(ProVersion),
whichhasaminimumspecificationofNVIDIAP100orT4asGPU,mem-
oryupto25GB,andCPUXeonProcessor@2.3GHzbasedonavailability.
3.Resultanddiscussion
3.1.Modelperformancewithaugmentation
Fig. 9 present the sample data augmentation of the Genus
Trichodorus using image augmentation method. Each model was
trained with the specified hyperparameter and optimizers on the
datasets augmented with an image transformation technique. The
datasetisusedtogaugetheperformanceofNematodescommonly
foundinIndonesiansoil.Modelperformancesonthetestdatasetare
thencomparedtothemodel'sbaseperformanceonthedatasetwithout
augmentation.
Table2presentsResNet101V2modelperformanceusingaugmenta-
tion.The“%Test”columnistheaccuracyofthemodelclassificationre-
sults on the test dataset. The test dataset represents data that the
Fig.8.Proposedmodelclassificationlayer. modelhasneverseenbefore.TheResNet101v2modeltrainedwithan
6N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
TheEfficientNetV2B0modeltrainedwithaugmentationmostlyde-
creasedperformance,asshowninTable4.Thehighestaccuracyof
97.94%isobtainedwithbrightnessaugmentationusingRMSpropopti-
mizer,whereasthelowestaccuracyof65.98%isobtainedwiththecon-
trastaugmentationusingSGDastheoptimizer.
TheimpactofaugmentationonEfficientNetV2B0%TestAccuracyis
presentedinFig.10c.Theincreasingtestaccuracyby1.03%occurred
whenthemodelappliedRMSPropwithbrightnessaugmentation.An-
othermethodleadstoadecreaseinthe%testaccuracyfrom4.12%to
30.93%.
TheEfficientNetV2Mmodeltrainedwithaugmentationmostlyde-
creased performance, as seen in Table 5. The highest accuracy of
97.94%isobtainedfromthemodelwhichappliedbrightnessaugmenta-
tionandRMSpropoptimizer.Thelowestaccuracyof76.29%isobtained
withthenoiseaugmentationdatasetusingSGDastheoptimizer.
TheimpactofaugmentationonEfficientNetV2M%TestAccuracyis
presented in Fig. 10d. The result is similar to EfficientNetV2B0 in
Fig.9.SampledataoftheGenusTrichodorusspecimenresultingfromimageaugmenta-
Fig.10cbutwithalowerrange.Theincreasing%testaccuracyof6.19%
tion.
occurredwhenthemodelappliedRMSPropwithbrightnessaugmenta-
tion.Anothermethodtendstogivelowerresultsinthe%testaccuracy,
rangingfrom1.03%to21.65%.
augmentationdatasetresultedinvaryingperformancechanges.The
Applyingaugmentationtothedatasetresultedinamorevariedper-
highestaccuracyof93.81%isobtainedwhentrainedwithoutanyaug-
formances change. Notable performance improvements are on the
mentation,usingSGDoptimizer,whereasusingRMSpropoptimizerre-
ResNet101v2 and CoAtNet-0 model with RMSprop optimizer and
sultedinthelowestaccuracyoutofallmodelcombinations,withan
CoAtNet-0withAdamoptimizer.Nevertheless,itshouldbenotedthat
accuracyof18.56%.
ResNet101v2withRMSprophasterriblebaseperformancecompared
Fig.10ashowstheimpactofaugmentationonResNet101V2%Test
tootheroptimizers(18.56%withRMSprop,comparedto88.66%with
Accuracy compared to the normal dataset. Using Adam Optimizer,
Adamand93.81%withSGD).
GaussianBlurAugmentationtendstoimproveaccuracy.Theaugmenta-
The best test accuracy is achieved by the EfficientNetV2B0 and
tionmethodimplementedusingSGDOptimizerleadstodecreasing
EfficientNetV2MmodelwithRMSpropoptimizer,trainedonthedataset
13.4%to43.4in%testaccuracy,whileapplyingRMSPropOptimizerin-
withbrightnessaugmentation.Thiscombinationachieved97.94%accu-
creasesthe%testaccuracyfrom3.09%to14.43%.
racy.TheCoAtNetfamilyscoredonaveragelowertestaccuracydiffer-
TheCoAtNet-0modeltrainedwithanaugmentationdatasetresulted
encethanothermodels,indicatinghighergeneralizationcapability
insmallperformanceincreasesandvaryingperformancedecreases,as
towardsaugmenteddatathanotherfamilymodels.
seeninTable3.Thehighestaccuracyof96.91%isachievedwiththenormal
Basedontheobtaineddata,itcanbeobservedthatthereisastrong
datasetusingSGDoptimizer,whilethelowestaccuracyof70.10%isob-
relationshipbetweenusingspecificimagemanipulationtechniqueas
tainedwiththecontrastaugmentationdatasetusingRMSpropoptimizer.
anaugmentationmethodandthecombinationofthemodel-optimizer
TheimpactofaugmentationonCoAtNet-0%TestAccuracyisgivenin
thatwoulddetermineitsperformance.Choiceofaugmentationmethod,
Fig.10b.UsingAdamOptimizer,FlipandGaussianNoisedecreasesthe
optimizers,andparametersareessentialinachievingthebestresulta
accuracywhileanotheraugmentationtendstoimproveaccuracyby
modelcanperform.
1%to5.12%.TheaugmentationmethodimplementedusingSGDOpti-
mizerleadstodecreasing5.15%to13.4%in%testaccuracy.RMSPropOp-
3.2.Augmentationmethodimpactonmodelperformance
timizerappliedwithBrightnessandGaussianBlurincreasedthe%test
accuracyby5.15%and4.12%,respectively,whileotheraugmentations
3.2.1.Flipaugmentation
decreasedthe%testaccuracy.
Fromthedatagathered,11outof12modelstrainedontheflip
datasetshowadecreaseinmodelaccuracy.Thisispresumablydueto
Table2
therelativelysmalldatasetsizecausingthedatatohaveasimilarorien-
ResultsobtainedfromResNetV2–101Model.
tationdistribution.Allmodelfamilieshaveuptotenmillionparameters.
Optimizer Data %Test Mean F1 Average Average Therefore,themodelisnotonlyperformingclassificationbasedonthe
augment accuracy class score precision recall
discriminatoryfeaturesofeachgenusbutalsobasedonasimilarorien-
accuracy
tationbetweeneachclassification.Addingdatawithdifferentorienta-
Adam Normal 88.66% 0.7662 0.882 0.8955 0.8866 tions causes the model to be unable to classify data based on
Flip 77.32% 0.7715 0.7743 0.8048 0.7732 orientationanddecreasesperformance.Thisindicatesmodelsoverfit
Brightness 87.63% 0.9097 0.8758 0.8877 0.8763
Contrast 81.44% 0.7996 0.8151 0.8294 0.8144 thedata'senvironmentalaspect,suchasdata acquisitionmethods,
GaussianBlur 89.69% 0.8148 0.8948 0.9051 0.8969 ratherthaneachgenus'discriminativefeatures.
GaussianNoise 86.60% 0.8697 0.8641 0.8727 0.866 ObservationoftheperformanceofResNet101v2usingAdamopti-
SGD Normal 93.81% 0.9329 0.9375 0.9398 0.9381 mizer,visualizationoftheclassificationlayeractivationoftheGenus
Flip 69.07% 0.4808 0.6863 0.7065 0.6907
Xiphinema class shows the discriminatory orientation of the class.
Brightness 80.41% 0.6813 0.7929 0.7925 0.8041
Contrast 62.89% 0.5768 0.6311 0.6485 0.6289 Whentrainedonthedatasetwithoutaugmentation(normaldataset),
GaussianBlur 50.52% 0.4774 0.5139 0.5508 0.5052 thevisualizationshowstheshapescommonlyfoundintheGenusspec-
GaussianNoise 68.04% 0.752 0.6848 0.766 0.6804 imen.However,whenitwastrainedusingflipaugmentation,thelayer
RMSprop Normal 18.56% 0.0909 0.0581 0.0344 0.1856
activationareawasnotasclearasthenormaldataset,asseeninFig.11.
Flip 21.65% 0.1 0.0771 0.0469 0.2165
Brightness 32.99% 0.2529 0.2972 0.326 0.3299 Thisshowsthataccordingtothemodel,importantfeaturesofthegenus
Contrast 22.68% 0.1 0.0846 0.052 0.2268 arealignedinthatspecificway.Inthedataset,theGenusXiphinema
GaussianBlur 24.74% 0.1026 0.1063 0.0677 0.2474 datadoeshavesomeorientationasdescribedintheactivationproperty
GaussianNoise 22.68% 0.087 0.0877 0.0543 0.2268
ofthemodelwiththenormaldataset.
7N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
(a) ResNet101V2 (b) CoAtNet-0
(c) EfficientNetV2B0 (d) EfficientNetV2M
Fig.10.Impactofaugmentationmethodon%testaccuracy.
OnlytheResNet101v2withRMSpropoptimizergothigheraccuracy 3.2.2.Brightnessaugmentation
intermsofperformanceimprovement.However,thisincreaseinaccu- Applyingbrightnessaugmentationresultedinvaryingperformances
racycanbeattributedtotheimpactofusingRMSpropasanoptimizer foreachmodel-optimizercombination.Thisaugmentationcauseda
onResNet101v2modelinsteadoftheaugmentationitselfbecauseall smallchangeinaccuracyformodelswithAdamoptimizer(±1%change
otherresultsofthismodel-optimizercombinationresultinunsatisfac- inaccuracy)andanincreaseinthemodelwithRMSpropoptimizer
toryaccuracies. (+5.15%to+14.43%).Still,itshowedadecreaseinmodelswithSGD
Table3 Table4
ResultsobtainedfromCoAtNet-0Model. ResultsobtainedfromEfficientNetV2B0Model.
Optimizer Data %Test Mean F1 Average Average Optimizer Data %Test Mean F1 Average Average
augment accuracy class score precision recall augment accuracy class Score precision recall
accuracy accuracy
Adam Normal 85.60% 0.694 0.8576 0.8547 0.866 Adam Normal 94.85% 0.9709 0.9486 0.9507 0.9485
Flip 83.51% 0.8072 0.8418 0.8637 0.8351 Flip 78.35% 0.7335 0.7727 0.7833 0.7835
Brightness 86.60% 0.8893 0.8639 0.8823 0.866 Brightness 91.75% 0.8315 0.9137 0.9201 0.9175
Contrast 87.63% 0.7987 0.8798 0.897 0.8763 Contrast 87.63% 0.8212 0.8793 0.8979 0.8763
GaussianBlur 90.72% 0.9244 0.9056 0.9147 0.9072 GaussianBlur 72.16% 0.6657 0.7178 0.8044 0.7216
GaussianNoise 84.54% 0.8186 0.8455 0.8739 0.8454 GaussianNoise 80.41% 0.7338 0.8006 0.8184 0.8041
SGD Normal 96.91% 0.9747 0.9691 0.9697 0.9691 SGD Normal 96.91% 0.9755 0.9691 0.9724 0.9691
Flip 90.72% 0.8209 0.9007 0.9047 0.9072 Flip 79.38% 0.8203 0.7941 0.8017 0.7938
Brightness 86.60% 0.8805 0.8664 0.8793 0.866 Brightness 81.44% 0.753 0.8114 0.8406 0.8144
Contrast 91.75% 0.939 0.9162 0.9255 0.9175 Contrast 65.98% 0.5918 0.6576 0.6946 0.6598
GaussianBlur 89.69% 0.8924 0.8965 0.9078 0.8969 GaussianBlur 70.10% 0.6266 0.6983 0.7085 0.701
GaussianNoise 83.51% 0.8286 0.8428 0.8808 0.8351 GaussianNoise 74.23% 0.7482 0.7355 0.7512 0.7423
RMSprop Normal 85.57% 0.7899 0.8562 0.8661 0.8557 RMSprop Normal 96.91% 0.9744 0.9689 0.9731 0.9691
Flip 75.26% 0.8027 0.7533 0.7676 0.7526 Flip 84.54% 0.8662 0.8421 0.868 0.8454
Brightness 90.72% 0.9014 0.9029 0.9158 0.9072 Brightness 97.94% 0.8923 0.9747 0.9716 0.9794
Contrast 70.10% 0.7625 0.7021 0.7186 0.701 Contrast 92.78% 0.952 0.9272 0.9293 0.9278
GaussianBlur 89.69% 0.8399 0.8889 0.8919 0.8969 GaussianBlur 92.78% 0.8102 0.9168 0.9256 0.9278
GaussianNoise 84.54% 0.8663 0.8453 0.8549 0.8454 GaussianNoise 81.44% 0.8748 0.8014 0.8763 0.8144
8N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
Table5 augmentationprocess,whichaffectsthestrengthoftheblurringand
ResultsobtainedfromEfficientNetV2MModel. thesizeofthegaussianfilterkernelused.
Optimizer Data %Test Mean F1 Average Average
augment accuracy class score precision recall 3.2.5.Gaussiannoiseaugmentation
accuracy Applying Gaussian noise augmentation to the dataset results in
Adam Normal 92.78% 0.9397 0.9289 0.9351 0.9278 decreased accuracy. An increase in accuracy only occurs on the
Flip 82.47% 0.712 0.8175 0.8164 0.8247 ResNet101v2withtheRMSpropoptimizer.Thedecreaseinaccuracyis
Brightness 91.75% 0.9247 0.9222 0.932 0.9175 moresignificantcomparedtoothertypesofaugmentations.Thisis
Contrast 88.66% 0.8012 0.8852 0.9008 0.8866
presumablyduetotheadditionofnoisecoversthediscriminatorychar-
GaussianBlur 91.75% 0.8867 0.9143 0.9249 0.9175
GaussianNoise 92.78% 0.9459 0.9275 0.9342 0.9278 acteristicsofeachNematodesclass,aswellastheselectionofparame-
SGD Normal 89.69% 0.8704 0.8953 0.9049 0.8969 tersfromtheaugmentationprocess.Withtheresolutionused(224×
Flip 76.29% 0.6979 0.7613 0.7807 0.7629 224),theadditionofnoiseisconsideredineffectiveinincreasingthe
Brightness 69.07% 0.5759 0.6891 0.7164 0.6907
model'saccuracy.
Contrast 68.04% 0.5661 0.6713 0.7081 0.6804
GaussianBlur 69.07% 0.622 0.6764 0.7086 0.6907
GaussianNoise 67.01% 0.6278 0.6692 0.7015 0.6701 3.2.6.Optimizerimpactonmodelperformance
RMSprop Normal 91.75% 0.9178 0.9183 0.9309 0.9175 Itshouldbenotedthatinthisresearch,eachoptimizerbetween
Flip 87.63% 0.875 0.8668 0.8843 0.8763 modelsusesthesamehyperparameters,alearningrateof0.001for
Brightness 97.94% 0.9861 0.9799 0.9826 0.9794
AdamandRMSprop,and0.01forSGD;momentumvalueof0forSGD
Contrast 91.75% 0.9107 0.9159 0.9232 0.9175
GaussianBlur 91.75% 0.9136 0.9168 0.9217 0.9175
andRMSprop;abetavalueof0.9–0.999forAdam;epsilonvalueof1e-
GaussianNoise 84.54% 0.8319 0.841 0.8787 0.8454 07forAdamandRMSprop;andarhovalueof0.9forRMSprop.Param-
etervalueselectionisbasedonthegeneralusageofeachoptimizer,and
someofthemarethedefaultparametervaluesfromtheTensorFlowli-
optimizer(−10.31%to−20.62%).Brightnessaugmentationtendsto
brary.Usingdifferentparametervaluesimpactsthemodel'sperfor-
improvemodelperformanceordecreaselessaccuracycomparedto
manceinlearningessentialfeaturesfromthedataset.Basedondata
otheraugmentationmethods.Theincreaseisduetothedataset'shigh
observation,severalrelationswereobtainedbetweentheselectionof
brightnessvariationbetweenspecimens.
theoptimizerandthemodelused.
3.2.3.Contrastaugmentation 3.2.7.Adamoptimizer
Usingcontrastaugmentationonthedatasetresultedindecreased ThemodelperformancesusingAdamoptimizerresultedinareason-
modelaccuracy.Only2outof12observeddatahavehigheraccuracy ablyhighaverageaccuracyforallmodels.Adamoptimizerisconsidered
than their normal data counterpart, namely ResNet101v2 with excellentforachievingsatisfactoryresultswithoutadjustingtheopti-
RMSpropandCoAtNet-0withAdamoptimizer.Basedonobservations, mizerparameterstomatchthemodelused.
increasingcontrasttoomuchwillresultincontextuallyincorrectNem-
atodesimages,i.e.,Nematodesimagesthatcannotbeobtainedfrom 3.2.8.SGDoptimizer
real-worldphotos.Theincreasingincontrastwillalsoincreasetheclar- ModelperformancesusingSGDoptimizerresultinvaryingaccuracy.
ityofsomefeaturesofspecimensthatarenotdiscriminatorybetween IntheCoAtNetmodelresults,theSGDoptimizerproducesthehighest
Genus.Thiscould causethemodel tolearnirrelevantfeaturesofa accuracycomparedtootheroptimizersonthedatasetwithoutaugmen-
Genus. tation.However,modelswiththeSGDoptimizersignificantlydecrease
accuracy when using augmented datasets, for example, in the
ResNet101v2andEfficientNetv2Mmodels.Thisispresumablybecause
3.2.4.Gaussianbluraugmentation
theparametersuseddonotmatchtheaugmenteddata.Thedecrease
Imageblurringwithgaussianblurisexpectedtohelpmodelslearn
inperformancewhenusingaugmentationdatashowsthatSGDopti-
aboutthegeneralmorphologicalcharacteristicsofeachGenusofNem-
mizer is more sensitive to changes in the dataset. SGD optimizer
atodes.Augmentationofgaussianblurcausedsomemodel-optimizer
demandsmorefine-tuningonitsparameterstoachievehighperfor-
combinationstohaveincreasedaccuracy.Basedonobservations,the
mancebasedonthemodelanddatasetused.
processofimageblurringinthedatasetproducesthevariationsneeded
bythemodeltostudythefeaturesofthetargetclassnematodes.This
3.2.9.RMSPropoptimizer
may be due to the selection of parameter values in the dataset
The use of the RMSprop optimizer produces different accuracy
foreachmodel.IntheResNet101v2model,theresultsobtainedare
inferior.However,theEfficientNetV2Mmodelobtainedsatisfactoryre-
sultsandhasoneofthehighestaccuraciesinthedataset.Observations
show this is caused by the parameter values used. In the original
EfficientNetV2study,state-of-the-artperformancewasachievedusing
theRMSpropoptimizerbutwithdifferentparameters(TanandLe,
2021).WhiletrainingtheResNet101v2model,itstrainingandvalida-
tionlossvaluefluctuatedsignificantly.Basedonresearchby(Verma
etal.,2021),althoughwithdifferentproblems,resultsoftheResNet50
modelusingasmallerlearningratevalueof0.0001gotbetteraccuracy
thanusingalearningratevalueof0.0004.Thisindicatesthatthelearn-
ing rate value used is too high for this model, as in research,
ResNet101v2istrainedusingalearningratevalueof0.001.
Basedonresearchby(Choietal.,2019),generaloptimizerslike
Adamshouldnotproduceworseresultsthanspecializedoptimizers
likeSGDandotheroptimizervariations.Adamoptimizerandother
Fig. 11. Comparison of classification layer activation visualization against “Genus
Xiphinema”classonResnet101V2modelwithoutaugmentation(left)andwithimage adaptivegradientmethodshaveperformancecomparabletoSGDor
reversalaugmentation(right). momentumwithproperparametersettings(Choietal.,2019).The
9N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
conclusionobtainedfromoptimizerimpactonthemodelperformance RMSPropandbrightnessaugmentation;CoAtNet-0usingSGDwithout
isthatit'sbettertouseanoptimizerthatiseasytouse.Besides,param- augmentation, EfficientNetV2B0 using SGD without augmentation;
eterfine-tuningwhichmatchestheproblemtobesolvedwillproduce andEfficientNeTV2B0usingRMSPropwithoutaugmentation.Themetric
thebestperformance. performanceforeachmodelispresentedinFig.12.Allmodelshave
similar performance in all metrics, except mean class accuracy for
3.3.Thetop5models EffiencientNetV2B0usingRMSPropandbrightnessaugmentation.How-
ever,themeanclassaccuracyisstillacceptableasitishigherthan85%.
Allmodelperformancedataarethensortedtodeterminethebest Itcanbeconcludedthatthesimultaneoususeofvarioustypesof
combinationofthemodel,optimizer,andaugmentation.Remember augmentation does not always increase the model's performance.
that the model's performanceobtained from thetestmay differin Somemodelsachievehighaccuracyusingaugmentationorwithout
real-worldapplications.Becausetheamountofdataforeachclassin augmentation.Inthiscase,augmentationisusedmoretovarydatacol-
thedatasetisnotbalanced,themodelwiththehighesttestaccuracy lectionconditions,i.e.,microscopeilluminationlevel,specimenorienta-
doesnotalwayshavethehighestmeanclassaccuracy.Ahighermean tion,orblurryphoto.However,intheaspectofNematodesmorphology,
classaccuracyvaluecanbeinterpretedasabettermodel'scapability theaugmentationuseddidnotsignificantlyincreasethevariationinthe
tolearnallclassfeaturesthanothermodels. morphologicalcharacteristicsofeachclass.Theseaugmentationscan-
Thetop-5modelsbasedon%testaccuracyare:EfficientNetV2M notimprovethemodel'sabilitytogeneralizeclassificationproblems
usingRMSPropandbrightnessaugmentation;EfficientNetV2B0using basedonthemorphologyofeachclass.
Fig.12.Metricscomparisonfromthefive-bestperformingmodels,rankedbasedontheaccuracyofthetestdataset.
10N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
Fig.13.Homescreenofweb-basedapplicationforautomaticidentificationofplant-parasiticnematodes.
In addition, simultaneous image transformations can hide the pest genus. The web-based for automatic identification of plant-
importantfeaturesstudiedinaclass. parasiticnematodescanbeassessedathttps://nematode-classifier.
herokuapp.com/.
Usingthisproposedapproach,plant-parasiticnematodescanbe
3.4.ModelIntegrationinwebapplications
identifiedfasterandmorereliable.Asexplainedinthepreviouspara-
graph,thesystemonlyneedsfivesecondstogivetheresultofidentifi-
Todeploythewebapptobeaccessibletootherpeople,Heroku
cationswithanaccuracyreachofupto97.94%.Thesystem'slimitation
app, a cloud-based platforms was used. Following the result in
Fig.12,EfficientNetV2,bothB0andMversionshavethehighestac- isthatitcanonlyrecognizethenematodesinperfectandundamaged
conditions,asthedatasetonlyrepresentsthoseconditions.However,
curacyof97.94%.Althoughthemodelshavesimilarperformance,
themodelsizewasverydistinctive.TheEfficientNetV2B0modelis futureresearchwillbeconductedtomeetothers'circumstances.
around25MBinsizewhileEfficientNetV2B0is200MB.Toreduce
theoperationalcost,EfficientNetV2B0wasselectedforintegration 4.Conclusion
as the web platform. The implementation of the user interface
screensispresentedinFig.13andFig.14.Thecloud-basedwebde- Anovelplant-parasiticnematodesimagedatasetwasbuiltforspe-
ploymentofthemodelhasresultedintheinferencetimearound cies of nematodes commonly found in Indonesia. The feasibility of
5sfortheclassificationoftheinputimageandprovidesaresultof deep learning models for plant-parasitic classifications, namely
Fig.14.Sampleresultofweb-basedapplicationforautomaticidentificationofplant-parasiticnematodes.
11N.H.Shabrina,R.A.LikaandS.Indarti ArtificialIntelligenceinAgriculture7(2023)1–12
ResNet101V2,CoAtNet-0,EfficientNetV2B0andEfficientNetV2Mwere Dai,Z.,Liu,H.,Le,Q.V.,Tan,M.,2021.CoAtNet:MarryingConvolutionandAttentionforAll
explored.Deeplearningtechniquesinimage-basedclassificationare DataSizes. https://doi.org/10.48550/arXiv.2106.04803.
De,W.D.,Elsen,A.,2007.Challengesintropicalplantnematology.Annu.Rev.Phytopathol.
promisingandadvancetheautomationofthenematodeidentification 45,457–485.https://doi.org/10.1146/annurev.phyto.45.062806.094438.
process.Thisworkdemonstratedthecapabilityofusingdeeplearning Diker,A.,Comert,Z.,Avci,E.,Togacar,M.,Ergen,B.,2019.Anovelapplicationbasedon
spectrogramandconvolutionalneuralnetworkforECGclassification.20191stInter-
models to identify plant-parasitic nematodes commonly found in
nationalInformaticsandSoftwareEngineeringConference(UBMYK).IEEE,pp.1–6
Indonesiansoil.Theperformanceofeachofthetestedmodelsobtained https://doi.org/10.1109/UBMYK48245.2019.8965506.
satisfactoryresults.Theexemplaryperformanceforeachmodelresults Elsken,T.,Metzen,J.H.,Hutter,F.,2019.Neuralarchitecturesearch:asurvey.J.Mach.
from combining several optimizer functions (Adam, SGD, and
Learn.Res.20,1997–2017.https://doi.org/10.48550/arXiv.1808.05377.
He,K.,Zhang,X.,Ren,S.,Sun,J.,2016a.Deepresiduallearningforimagerecognition.IEEE
RSMProp)andtheaugmentationprocess(Flip,Brightness,Contrast, ConferenceonComputerVisionandPatternRecognition(CVPR).IEEE,pp.770–778
GaussianBlur,andGaussianNoise).Basedontheselectedmodelvari- https://doi.org/10.1109/CVPR.2016.90.
ants(ResNet101v2,CoAtNet0,EfficientNetV2B0,andEfficientNetV2M), He,K.,Zhang,X.,Ren,S.,Sun,J.,2016b.Identitymappingsindeepresidualnetworks.
ComputerVision–ECCV2016.SpringerInternationalPublishing,pp.630–645
theEfficientNetV2B0andEfficientNetV2Mmodelsachievedthebest
https://doi.org/10.1007/978-3-319-46493-0_38.
performanceonthedatasetused,withthehighestaccuracyof97.94%. Indarti,S.,Bambang,R.T.P.,MulyadiB.,Triman,2004.Firstrecordofpotatocystnematode
BothofthebestmodelswereimplementedusingRMSPropoptimizer globoderarostochiensisinIndonesia.Australas.PlantPathol.33,325.https://doi.org/
andbrightnessaugmentation.Thefinalcontributionprovidesaninte- 10.1071/AP04018.
Indarti,S.,Wibowo,A.,Subandiyah,S.,Ajri,M.,2018.Firstrecord:astemandbulbplant
grated deep learning model as a web-based application that parasiticnematodeatgarlicareaCentretemanggung,centraljava,Indonesiawith
Indonesia'sprospectiveagriculturistscanusedirectly.Furtherworkis speciesreferencetoditylenchusdipsaci.JurnalPerlindunganTanamanIndonesia
22,233.https://doi.org/10.22146/jpti.35321.
stillneededtoimprovemodelaccuracyandreliability.Futurework
Jiang,P.,Chen,Y.,Liu,B.,He,D.,Liang,C.,2019.Real-timedetectionofappleleafdiseases
willfocusonthefollowing: usingdeeplearningapproachbasedonimprovedconvolutionalneuralnetworks.
IEEEAccess7,59069–59080.https://doi.org/10.1109/ACCESS.2019.2914929.
• Furtherdevelopmentofthenematodesdatasettocopewithunperfect Jones,J.T.,Haegeman,A.,Danchin,E.G.J.,Gaur,H.S.,Helder,J.,Jones,M.G.K.,Kikuchi,T.,
conditionsofnematodeimagesandexpandtonon-parasiticnematodes Manzanilla-López,R.,Palomares-Rius,J.E.,Wesemael,W.M.L.,Perry,R.N.,2013.Top
• Investigateotherdeeplearningmodelstoimprovetheperformanceof 10plant-parasiticnematodesinmolecularplantpathology.Mol.PlantPathol.14,
946–961.https://doi.org/10.1111/mpp.12057.
multi-classnematodesidentification
Keras,2021.KerasApplications[WWWDocument].URLhttps://keras.io/api/applications/
(accessed2.1.22).
Kingma,D.P.,Ba,J.,2014.Adam:AMethodforStochasticOptimization. https://doi.org/
CRediTauthorshipcontributionstatement 10.48550/arXiv.1412.6980.
Kusrini,K.,Suputa,S.,Setyanto,A.,Agastya,I.M.A.,Priantoro,H.,Chandramouli,K.,
Izquierdo,E.,2020.Dataaugmentationforautomatedpestclassificationinmango
NabilaHusnaShabrina:Conceptualization,Methodology,Formal
farms.Comput.Electron.Agric.179,105842.https://doi.org/10.1016/j.compag.2020.
analysis,Visualization,Writing–originaldraft,Projectadministration,
105842.
Funding acquisition. Ryukin Aranta Lika: Software, Investigation, Li,L.,Zhang,S.,Wang,B.,2021.Plantdiseasedetectionandclassificationbydeeplearning
Datacuration,Writing–originaldraft.SiwiIndarti:Resources,Valida- —areview.IEEEAccess9,56683–56698.https://doi.org/10.1109/ACCESS.2021.
3069646.
tion,Writing–originaldraft.
Lu,X.,Wang,Y.,Fung,S.,Qing,X.,2021.I-nema:ABiologicalImageDatasetforNematode
Recognition. https://doi.org/10.48550/arXiv.2103.08335.
Declarationofcompetinginterest
Mutala’liah,M.,Indarti,S.,Wibowo,A.,2018.Shortcommunication:theprevalenceand
species of root-knot nematode which infect on potato seed in central java,
Indonesia.Biodivers.J.20,11–16.https://doi.org/10.13057/biodiv/d200102.
Theauthorsdeclarethattheyhavenoknowncompetingfinancial Paymode,A.S.,Malode,V.B.,2022.Transferlearningformulti-cropleafdiseaseimage
interests or personal relationships that could have appeared to
classificationusingconvolutionalneuralnetworkvgg.Artif.Intell.Agric.6,23–33.
influencetheworkreportedinthispaper. https://doi.org/10.1016/j.aiia.2021.12.002.
Raouhi,E.M.,Lachgar,M.,Hrimech,H.,Kartit,A.,2022.Optimizationtechniquesindeep
convolutionalneuronalnetworksappliedtoolivediseasesclassification.Artif.Intell.
Acknowledgments Agric.6,77–89.https://doi.org/10.1016/j.aiia.2022.06.001.
Shijie,J.,Ping,W.,Peiyi,J.,Siping,H.,2017.Researchondataaugmentationforimageclas-
sificationbasedonconvolutionneuralnetworks.2017ChineseAutomationCongress
WewouldliketothankRinaMaharani,S.P.,M.Scwhohelpustocol- (CAC).IEEE,pp.4165–4170https://doi.org/10.1109/CAC.2017.8243510.
lectandpreparenematodesdataset.Wewouldalsoliketoacknowledge Shorten,C.,Khoshgoftaar,T.M.,2019.Asurveyonimagedataaugmentationfordeep
learning.J.BigData6,60.https://doi.org/10.1186/s40537-019-0197-0.
thesupportgivenbyUniversitasMultimediaNusantaraduringthisstudy.
Southey,J.,1986.LaboratoryMethodsforWorkwithPlantandSoilNematodes.Her
Majesty’sStationaryOffice,London.
References Stojnic,R.,Taylor,R.,Kardas,M.,ElvisCucurull,G.,2022.ImageClassificationonImagenet
[WWWDocument].URLhttps://paperswithcode.com/sota/image-classification-on-
Abad,P.,Gouzy,J.,Aury,J.-M.,Castagnone-Sereno,P.,Danchin,E.G.J.,Deleury,E.,Perfus- imagenet(accessed2.1.22).
Barbeoch,L.,Anthouard,V.,Artiguenave,F.,Blok,V.C.,Caillaud,M.-C.,Coutinho, Sun,S.,Cao,Z.,Zhu,H.,Zhao,J.,2020.Asurveyofoptimizationmethodsfromamachine
P.M., Dasilva, C., de Luca, F., Deau, F., Esquibet, M., Flutre, T., Goldstone, J.V., learningperspective.IEEETrans.Cybern.50,3668–3681.https://doi.org/10.1109/
Hamamouch,N.,Hewezi,T.,Jaillon,O.,Jubin,C.,Leonetti,P.,Magliano,M.,Maier, TCYB.2019.2950779.
T.R.,Markov,G.V.,McVeigh,P.,Pesole,G.,Poulain,J.,Robinson-Rechavi,M.,Sallet, Tan,M.,Le,Q.V.,2019.Efficientnet:RethinkingModelScalingforConvolutionalNeural
E.,Ségurens,B.,Steinbach,D.,Tytgat,T.,Ugarte,E.,vanGhelder,C.,Veronico,P., Networks. https://doi.org/10.48550/arXiv.1905.11946.
Baum,T.J.,Blaxter,M.,Bleve-Zacheo,T.,Davis,E.L.,Ewbank,J.J.,Favery,B.,Grenier, Tan,M.,Le,Q.V.,2021.Efficientnetv2:SmallerModelsandFasterTraining. https://doi.
E.,Henrissat,B.,Jones,J.T.,Laudet,V.,Maule,A.G.,Quesneville,H.,Rosso,M.-N., org/10.48550/arXiv.2104.00298.
Schiex,T.,Smant,G.,Weissenbach,J.,Wincker,P.,2008.Genomesequenceofthe Toğaçar,M.,Ergen,B.,Cömert,Z.,2021.Tumortypedetectioninbrainmrimagesofthe
metazoanplant-parasiticnematodeMeloidogyneincognita.Nat.Biotechnol.26, deepmodeldevelopedusinghypercolumntechnique,attentionmodules,andresid-
909–915.https://doi.org/10.1038/nbt.1482. ualblocks.Med.Biol.Eng.Comput.59,57–70.https://doi.org/10.1007/s11517-020-
Abade,A.,Porto,L.F.,Ferreira,P.A.,deBarrosVidal,F.,2022.NemaNet:aconvolutional 02290-x.
neuralnetworkmodelforidentificationofsoybeannematodes.Biosyst.Eng.213, Uhlemann,J.,Cawley,O.,Kakouli-Duarte,T.,2020.Nematodeidentificationusingartificial
39–62.https://doi.org/10.1016/j.biosystemseng.2021.11.016. neuralnetworks.InternationalConferenceonDeepLearningTheoryandApplica-
Ajri,M.,Indarti,S.,Soffan,A.,Huu,N.N.,2021.Morphologicalandphylogeneticcharacter- tions.SCITEPRESS-ScienceandTechnologyPublications,pp.13–22https://doi.org/
isticsofditylenchusdipsaciamonggarlicplants.JordanJ.Biol.Sci.14,769–773. 10.5220/0009776600130022.
https://doi.org/10.54319/jjbs/140418. Verma,P.,Tripathi,V.,Pant,B.,2021.Comparisonofdifferentoptimizersimplementedon
Alsaggaf,W.,Cömert,Z.,Nour,M.,Polat,K.,Brdesee,H.,Toğaçar,M.,2020.Predictingfetal thedeeplearningarchitecturesforCOVID-19classification.Mater.Today:Proc.46,
hypoxiausingcommonspatialpatternandmachinelearningfromcardiotocography 11098–11102.https://doi.org/10.1016/j.matpr.2021.02.244.
signals.Appl.Acoust.167,107429.https://doi.org/10.1016/j.apacoust.2020.107429. Zhou,P.,Feng,J.,Ma,C.,Xiong,C.,Hoi,S.,E.W,2020.TowardsTheoreticallyUnderstand-
Choi,D.,Shallue,C.J.,Nado,Z.,Lee,J.,Maddison,C.J.,Dahl,G.E.,2019.OnEmpiricalCompar- ingWhySGDGeneralizesbetterthanAdaminDeepLearning. https://doi.org/10.
isonsofOptimizersforDeepLearning. https://doi.org/10.48550/arXiv.1910.05446. 48550/arXiv.2010.05627.
Chollet,F.,2015.Keras:DeepLearningforHumans[WWWDocument].URLhttps://
github.com/keras-team/keras(accessed2.1.22).
12