Abstract Crowdsourcing has become a promising paradigm for solving tasks that are beyond the capabilities of machines alone via outsourcing tasks to online crowds of people. Both requesters and workers in crowdsourcing systems confront a flood of data coming along with the vast amount of tasks. Fast, on-the-fly recommendation of tasks to workers and workers to requesters is becoming critical for crowdsourcing systems. Traditional recommendation algorithms such as collaborative filtering no longer work satisfactorily because of the unprecedented data flow and the on-the-fly nat- ure of the tasks in crowdsourcing systems. A pressing need for real-time recommendations has emerged in crowdsourcing systems: on the one hand, workers want effective recommendation of the top-k most suitable tasks with regard to their skills and preferences, and on the other hand, requesters want reliable recommendation of the top-k best workers for their tasks in terms of work- ers’ qualifications and accountability. In this article, we propose two real-time recommendation algorithms for crowdsourcing systems: (1) TOP-K-T that computes the top-k most suitable tasks for a given worker and (2) TOP-K-W that computes the top-k best workers to a requester with regard to a given task. Experimental study has shown the efficacy of both algorithms.

human activities, especially those related to scientific explo- ration and technological applications is now producing and consuming large scales of data. Google estimated that every two days in 2010 the world generated as much data as the sum it generated up to 2003 [1]. This phenomenon has brought a great challenge to the technological society and to the vast users who often do not find the desired information within an acceptable time frame. In crowdsourcing systems, users

(both requesters and workers) confront exactly the same prob- lem to which a feasible solution is thorough real-time1 recom- mendation. For many applications, recommendation is a personalized filter, used to either predict the interestingness of an item (a prediction problem), or to identify a set of items that are interesting to a user (a top-k recommendation problem) [2,3]. Effective recommendation plays a critical role in such web-based systems and benefits users in multiple ways, discov- ering relevant information, reducing waiting time, and increas- ing productivity, to name a few. Many of the leading e- commerce platforms such as Amazon and Netflix have already adopted recommendation systems in their systems and demon- strated the great value of effective recommendation.

Current recommendation systems are based on two main approaches, i.e., content filtering and collaborative filtering. As their names indicate, the content filtering approach relies on the content of the items and the users’ profiles to identify the best matches. On the other hand, the collaborative filtering approach relies on the relationships among the items and the correlations among the users to draw new hidden, interesting relationships between the items and the users. These approaches have been showing their successes in many applica- tions, mostly online e-commerce systems.

However, when it comes to recommending tasks on crowd- sourcing platforms such as AMT (Amazon Mechanical Turk), these traditional recommendation approaches do not fit well. In other words, they would not be sufficiently efficient any- more when they are used for task recommendations in crowd- sourcing systems. Before making detailed explanation, let’s review the basics of crowdsourcing. In recent years, crowd- sourcing has become a popular paradigm for accomplishing tasks by outsourcing them to online crowds of people. Crowd- sourcing systems (usually built as online platforms) originated from the idea of leveraging human abilities on solving prob- lems and accomplishing tasks that machines alone cannot do well. Crowdsourcing has many different definitions [4], each emphasizing different aspects: the nature of the collaboration, the types of the target problems, the motivations of the crowd members, and the types of incentives [5]. The definition in [6] is concise and popular: ‘‘crowdsourcing is an online, distributed problem-solving and production model”. Crowdsourcing sys- tems may be categorized into four types [7] based on whether the workers’ contributions are convergent or not and whether they are homogeneous or heterogeneous. In the rest of this article, our discussion is not limited to any particular type of crowdsourcing systems. Even though we use AMT (a crowd processing system) for illustration, the algorithms we present in this article are suitable for any type of crowdsourcing sys- tems as long as the systems provide task categories or the tasks can be categorized.

We inspect the characteristics of the tasks in crowd- sourcing systems as compared to the items/products in e-commerce markets, and the differences of the workers’ interests in tasks vs. the users’ interests in items/prod- ucts. The products in e-commerce markets are usually offered as completed items to be purchased by online users, whereas the tasks in crowdsourcing systems are posted activities that are yet to be completed by online workers. We incorporate a key mechanism, i.e., cate- gories of tasks, into our recommendation approach that significantly accelerates the recommendation procedure.

approaches. In Section 3, we present our new recommendation algorithms: TOP-K-T and TOP-K-W. In Section 4, we show and discuss our experimental results. In Section 5, we comment on related works and make comparisons with ours. Section 6 concludes the article.

The content filtering approach recommends items to a user based upon the description of the items and the profile of the user’s interests [9]. A profile is created for each user and for each product/item. The user profile can be simply a collection of the user’s historical ratings on purchased items. The product profile is a set of keywords representing the product. Similari- ties between user profiles and product profiles are computed. Products with high similarities will be recommended to the corresponding users. Obviously, the approach does not have cold start problem. The problems this approach may face include the following: (1) some items may not be easily described using content keywords; (2) distinct items may share the same set of features described by the same keywords; (3) profile information is not always available; and (4) poor per- formance scalability.

The collaborative filtering approach is probably the most successful and popular approach used in recommendation sys- tems [3]. Comparing to content filtering, the collaborative fil- tering approach relies only on the user’s past behavior. This approach identifies hidden user-products relationships by ana- lyzing the relationships among users and the correlations among products [10,9,3]. One remarkable advantage of this general approach is that it usually generates pretty accurate results because the learned user-product relationships implic- itly incorporate many subtle aspects that are hard to be explic- itly profiled. The approach notoriously suffers from the cold start problem because it relies on collected historical informa- tion that new users/products do not yet have. Another equally remarkable drawback of this approach at the current status is its high runtime complexity, which is typically polynomial w.r.

t. both the number of users and the number of items, which both can be huge in future crowdsourcing systems. Therefore, in principle this attractive approach will not result in real-time recommendation which is very much needed by future, very- large-scale crowdsourcing systems. The approach has evolved into two different methods as follows.

The user-based collaborative filtering method recommends to a user the products that have already been liked by like- minded peers of the user. It consists of two steps [3]. First, a user’s historical information is used to identify a neighborhood of people who in the past have exhibited similar behavior, e.g., purchased similar products. Second, the identified neighbor- hood is analyzed to figure out new products that may be liked by the user. We furnish additional details of the user-based col- laborative filtering method in Supplementary Table 1.

of items, and may be executed offline. The second phase com- bines and compares the computed similarity scores to deter- mine the most similar items to the items that have been purchased in the past by the user. We provide more details of the item-based collaborative filtering method in Supplemen- tary Table 1. To build the model, the algorithm takes O(m2n) time [10], where m is the number of items and n is the number of operations needed to compute the similarity between every

on predefined filter categories” [11]. Furthermore, the text clas- sification system can be improved with the help of human (online crowd) annotators involved into the training process where different learning techniques can be combined such as ensemble learning and active learning [12]. Categories as an effective mediation mechanism introduced in our algorithms are mainly to boost the recommendation performance and the quality of completed tasks. Other researchers [13] have reported that the worker’s perspective is a crucial factor to be considered in crowdsourcing systems.

We may generally consider the top-k task recommendation as computation of a restricted 1-to-K mapping from workers to tasks, and, in reverse, the top-k worker recommendation as computation of a restricted 1-to-K mapping from tasks to workers. In order to efficiently compute these mappings, we design commensurate data structures to facilitate the computa- tion process. These data structures are described below.

{w1; w2; .. . ; wm}, where each element wj points to an array of n categories, {c1; c2; ... ; cn}, which each is paired with the worker’s matching score si;j (to be defined shortly) with the cor- responding category (as illustrated in Fig. 1(b)). A matching score si;j measures the historical performance, preference, and

sorted in non-increasing order of the workers’ matching scores, si;j (1 6 i 6 n). Expression Wj → Ci quickly retrieves the matching score of the ith most preferable task category of worker wj. For example, W1 → C1 gives the matching score of the first most preferable category of worker w1. The W → C data structure is illustrated in Fig. 1(b) using some randomly set matching scores.

In the above discussion, we forward referenced the metric term, matching score, which is yet to be defined below. For a given work Wj (i.e., the jth worker) and a task category Ci (i.e., the ith category), the worker’s matching score with the tasks of this category is defined by the following equation:

Our TOP-K-T was designed with the assumption that, in a crowdsourcing system, at any given time, there is a huge list of available tasks ({t1; t2; ... ; ts}) of which each belongs to cer- tain categories, and a huge list of online workers which each

the total number of completed tasks by the worker in all cate- gories. Profile–Category Similarity is a cosine similarity between a worker’s profile pj (e.g., expertise, certificates, hon- ors, etc.) and the category description ci. It is worth to note that this score is computed offline after worker registration and recomputed every time the worker’s profile is updated. The vector-space model is used where the profile and category are represented by their keywords (h keywords as in Eq. 4).

As the popularity and scale (including both the numbers of tasks and workers) of crowdsourcing systems keep increasing, workers tend to spend more time on finding proper tasks matching their skills and interests than on the tasks themselves [15,8]. The motive of our work is to help workers to instantly find best matching tasks and to help requesters to quickly iden- tify the best workers for their tasks at hand. Our first algo- rithm, TOP-K-T, was thus designed to make recommendation of the top-k most suitable tasks for a worker at real-time speed.

worker with this category is fetched into SCtarget ;Windex (line 5). The algorithm then evaluates category Ctarget to select some available tasks from that category. The number of tasks to be selected from Ctarget is the result of cascade rounding (to be explained shortly via an example) of the product of the worker’s normalized matching score with the category and the parameter k (line 6). Herein, two cases need to be differen-

yet to be identified is passed to the next iteration (line 8). (ii) The number of available tasks in Ctarget → T is more than needed. In this case, the algorithm randomly selects numselected + passtonext tasks from Ctarget → T and adds them to output list L (line 11). An illustrative example is shown in Supplementary Table 2, furnished with explanations.

every time a worker completes a task. Therefore, our approach adopts periodic batch update on these scores and the arrays as we assume that each time when a worker completes one task, the affect on the worker’s matching score is marginal. This approach may not satisfy the need of the workers who want the recommendation system to recommend tasks that are sim- ilar to their recently chosen and completed ones [13]. This is an issue of trade-off between performance and accuracy of recom- mendations. A possible solution would be to offer ‘‘instant score update” as a user controllable function in the interface. Alternatively, the system may be set to automatically adjust the update pace based on explicit feedback from workers regarding their satisfaction with the recommendations made by the system to them. This information ought to be integrated into the profiles of the workers and used in the future toward more personalized recommendation. The above ideas have not been reflected in our current algorithm.

The TOP-K-W algorithm is described in Algorithm 2. The algorithm iterates through the categories of a given task, i.e., list TaskCat (starting at line 3 in Algorithm 2). During each iteration, the next category index is fetched from list TaskCat into variable Ctarget, and the associated category weight is fetched into variable Cweight (lines 4 and 5, respec- tively). The number of workers selected from Ctarget is decided by the product of the category’s weight Cweight and the param- eter k after applying cascade rounding (line 6). Similar to algo- rithm TOP-K-T, two specific cases need to be separately addressed, of which the deliberation is omitted due to analo- gous disposition.

In summary, the TOP-K-W algorithm takes O(k + k) run- time, where k is the number of categories that a given task belongs to and k is the number of workers to be recommended for the task. It is evident that both k and k are usually small numbers in real-world scenarios. Our TOP-K-W algorithm is able to obtain real-time performance (in less than a millisecond per our experiments, to be detailed shortly), regardless of the potentially huge volume of data flow typically found in crowd- sourcing systems. The TOP-K-W algorithm adopts an incre- mental recommendation strategy to bring down the possible delay of task completion to the minimum. Similar to algorithm TOP-K-T, this algorithm also assumes offline batch update on workers’ matching scores and resorting of the worker list under each category in order to deliver real-time performance.

50 (i.e., to recommend top 50 tasks to each worker). As expected, the times taken accordingly increase when k increases from 20 to 50. The performance plots show basically constant performance with regard to varied dataset sizes and our explanation for the performance data is basically the same as with the cases of smaller k values. The only thing we would like to point out herein is that when k is 50, which is pretty large in real-world scenarios, our TOP-K-T algorithm remains extremely efficient, taking up to only a couple of milliseconds in our experiments.

Analytically, the running time of our TOP-K-T algorithm is affected only by a and k which are typically very small num- bers, regardless of the data sizes (the numbers of workers, tasks, etc.). Our experimental study confirms the validness and the constant time performance of our algorithm.

belong to 1 category, 4 categories, 7 categories, 3 categories, and 10 categories. Fig. 3 shows the performance plots of TOP-K-W with regard to the above assumptions. It can be easily observed from Fig. 3 that the running times are basically constant in terms of dataset sizes, affected only by parameters k and k (both in practice are very small numbers). It can also be observed that the sizes of the datasets do not have notice- able influence on the running time of the algorithm as the time plots all appear to be constant plots with regard to varied data- set sizes.

Our argument for effective, real-time recommendation of top-k tasks and top-k workers in crowdsourcing systems is not alone. Ipeirotis [15] examined the task posting and comple- tion activities on AMT, and concluded that AMT is a heavy- tailed market, i.e., it has a heavy-tailed distribution of both the completion time and posting time, as illustrated in Supple- mentary Fig. 1, where the number of tasks arrived on Novem-

ber 10th, 2013 reached 50,000, followed by 400,000 on the next day. The tasks in crowdsourcing systems include micro-tasks, particularly on AMT, that have very short life spans, e.g., from minutes (if not seconds) to hours. These unique features of crowdsourcing systems, i.e., huge flow of tasks with very short life spans, make traditional recommendation algorithms inap- plicable simply because they were not designed and are unable to deliver the desired real-time recommendation performance by most crowdsourcing systems.

[17] assumes that there is a set of categories predefined; and any task posted by a requester can be categorized into one of those categories. The algorithm recommends to a worker a list of tasks sorted according to the worker’s preferences and the acceptance tendency of the worker’s completed tasks by the requesters. Comparing to our work, this approach has the following limitations: (1) limited scalability since it iterates through all available tasks in all categories (which can be enor- mous) every time a worker logs into the system and needs to updates the worker’s scores every time s/he completes a task and (2) this approach has the cold-start problem.

The same group extended their algorithm in [18]. In the extended version, a worker-task matrix is used where each entry in the matrix has a value from 1 to 5. The main goal of this approach is to predict the missing values in the worker-task matrix. This approach employs matrix factoriza- tion technique to understand the worker’s preference on the tasks. Comparing to our work, this approach has the following concerns: (1) this approach may still suffer from scalability issues since it records all interactions between all the workers and the system, and yet, its matrix is expanding rapidly which makes the relearning of the matrix much harder to handle and

With the increased popularity and scales, crowdsourcing sys- tems involve a flood of data which could leave the workers and requesters at dismay when they (as workers) are trying to find suitable tasks to work on or (as requesters) to find the best workers for their tasks. Therefore, making the good recommendation on the fly has become critical to these sys- tems. In this article, we revealed our insight into the essential difference between the tasks in crowdsourcing systems and the products/items in e-commerce markets, and the difference between a buyer’s interest in products/items and a worker’s interest in tasks. Our insight inspired us to bring up categories as a key mediation mechanism between workers and tasks, which has been proven an highly effective means in our effort toward designing extremely scalable and efficient recommen- dation algorithms for crowdsourcing systems. Our effort has resulted in two novel algorithms, TOP-K-T (computing the top-k most suitable tasks to recommend to a worker) and TOP-K-W (computing the top-k best workers to recommend

to a task requester). Both algorithms demonstrate superb (real-time) performance — make valid recommendations in just a few milliseconds regardless of dataset sizes, which explains the great scalability and efficiency of our algorithms. Besides categories as a general mediation mechanism, our var- ious data structures (illustrated in Fig. 1(a)–(c)) provide instru- mental support to the implementation of our approaches. These data structures absorb a major part of the intrinsic com- plexities of the recommendation problems, and render us suc- cinct algorithms with great efficiency and scalability. We have done extensive experimental study of our algorithms with syn- thesized datasets because no suitable real dataset is available for our study. We did not do horizontal comparison with related algorithms in the experimental study as our algorithms are quite different in nature from all other related algorithms, and are evidently superb to them, which makes equal-footing empirical comparison with them less interesting and unnecessary.

