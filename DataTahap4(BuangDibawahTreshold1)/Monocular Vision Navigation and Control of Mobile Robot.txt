recognitionmodule, stop line recognitionmodule, zebra crossing recognitionmodule, obstacle sensing module, control module and communication module.The system utilizes multi-threading technology to collaborate different modules in the same control cycle and automatic state machine to switch different control modes.Experimental results show that the robotcan accomplishautonomous cruise task on the predetermined routeand operate stablywhen it is in a good lighting conditions.

Compared to intelligent vehicles,small intelligent mobile robotics has many different characteristics,such as low image stability, low control precision,different waysof turning,narrow angle of shooting due tolow camera height.Therefore, itneeds higher accuracy ofenvironmental awareness, collaboration of multi-sensor and self- control technology. In application of environment exploring and cruise task, small intelligent mobile robot canplay a better role.

In this paper, the autonomous vision navigation system is developed onthe small mobile robot platform, Adept MobileRobots PT 3-AT.Our vision navigation robot is designed for known outdoors routes.It can travel along the edges of the unstructured roads and the lane lines of the structured roads. It will turn when recognizing a special signs or zebra crossing.Section 2 introduces the design framework of the whole system.Section 3 gives a brief introduction of visionrecognitionmodule.Section 4elaborates the control module and strategy.Experiment results are given in section 5.And the conclusion and future work are discussed in section 6.

In the system,there are many states which compose a finite state machine (FSM)[1]. In state of straight traveling, turning and road finding,the system uses different well-designed strategies and rules to control the robot behaviorbased according to the road number.Manual control mode is automatically entered when system go into the stop state. In that state,people can send commands to control the robot how to walkthrough the upper machine client.

We designed two different road-edge detection algorithms for unstructured road[2]. One is color-based threshold segmentation algorithm,to deal with the situation of high color contrastbetween road and non-road area.The other is a grayscale-based extension algorithm of Otsu[3], to deal with the situation that the road and non-road area boundaries are not obvious.Wedesigned another color-based threshold segmentation algorithm for structured road, to recognize the lane lines.Afterrecognizing correct traveling path and calculating by inverse affine transformation, the algorithm above will give final results, the distance deviation and the angle deviation at the current position.

In order to improve the accuracy of the turning andadapt to the complex environment, we specifically designed ahigh-contrastsign for our vision navigation system, whichis composed ofyellow and black. The signs are placed in fixed positions of the turning area and maintain the same height to mark the accurate turning point. By using the HSV color threshold segmentation, edge detection, RANSAC[4] ellipse fitting and misrecognition filtering, the recognition algorithm can identify the turning signs outdoors. And it will give a turning signal to system when the detected signs in images reach a predetermined size. Thenthe system will go into the turning state from a straight traveling state at the predetermined turning points.

Since onlyusing monocular camera, the vision algorithmsmaymakeslight deviations when estimating distance. It will lead continuous adjusted in corrective processof straight travelling.The robot outdoors walking and turning in differential waywill makegreat influence on image stabilitybecause of the friction between wheels and ground. Moreover,false detectionsof vision recognition algorithmsoften appearin complex outdoor environment. All these factors present challenges of robotcontrol strategy design to us.

The robot has its own global coordinate system.When the robot starts, itis on the origin of coordinates and face to the x-axis positive direction, 90degrees counterclockwise is the y-axis positive direction. The range of angleis 0 to 180degreesin the first and the second quadrant and-180 to 0degreesin the third and fourth quadrant. In short, in the positive x direction, it is 0 degree. Clockwise is negative and counterclockwise is positive. As the same way, the angle deviation, which is defined as the angle betweencorrect direction and current direction, will in range of 0 to 180 degrees clockwise, and range of -180 to 0degrees counterclockwise.

The distance deviation is defined as vertical distancebetween the center point of the robot and the correct path line. When facing the correct direction, the distance deviation of the robot in the correct path line is 0. The left side is positive and the right side is negative.

We obtain the distance deviation and angle deviation advantage from the vision algorithms and pose estimation, which are referredin chapter 2.And the two parameters are used as the input fuzzy parameters.The fuzzy sets of them both are {NB, NM, NS, PS, PM, PB}.

The fuzzy membership of angular velocity is shown as following. Horizontal axis represents the angular velocity of robot (degrees/s).The vertical axis represents the value of membership. Whenangular velocityis greater than 11degrees/s or less than -11degrees/s, the value of fuzzymembership is 0. These cases are out of the range of the fuzzy controller. Because ofrobot control accuracy itself, it canjustutilizethe discrete formulation for defuzzification calculation.

Considering the robot travel behaviors features when human controlling, we summarized the following fuzzy control rules. The fuzzy inference synthesize rule is maximum - minimum rule. And defuzzification directly utilizes the max criterion method (MC)[6]. The blank means that angular velocity is calculated by using the original linear equation in these situations.

After defuzzification, we add the following additional rule:(|Œ∏| > Œ∏m AND œâ√óŒ∏ > 0) ‚Üí œâ = 0. This rule can limitangular velocity when correction of distance deviation,in order to eliminatethe excessive rotation phenomenon. In experiments, we set ùúÉùëö = 10.

In every cycle,the system will compared the deviation data from inertial navigationwith the one fromvision navigation. If the difference between the two data is obvious, that is to say, distance deviationgreater than 800mm or angle deviation more than 17degrees with distance deviation less than 343mm, the system will accept the data frominertial navigation; otherwise use the vision navigation data.The above-mentioned values can be adjusted.

Because of vibration caused by friction when the robot is turning, the image recognition algorithms tend to result more false detections or misses.Wedonot focus ondesigning a precise solution to turning recognition andcontrolling. So wejust usethe signs which referred in Chapter 3 to mark the fixed turning point. Thenwe set turning angle and distance before and after turning in every turn,which are estimatedfrom experiments.

The path-finding strategies strategy is applied after turning, at the beginning at each road. Every time after turning, the robot will search along the current direction in an  45degrees angle range. The correct direction should deviate from the current direction within a certain angular.

We used the robot simulator to do the ideal test which compared the control effect before and after adding fuzzy controller.The distance deviation and angle deviation are given completely correctfor each control cycleand start correction at same distance deviation. From the ideal result, we can find a decrease in the oscillation of correction and overshooting. The whole correction process became relatively steady. In the practical experiments, these advantages play a very important role to enhance the stability and accuracy and prevent the robot from significantS-shape walking.

We hold a two-month practical adjustment and experiment on 6 predeterminedcontinuousroads in a natural environment. The overall distance of the 6 roads is over 360m. Two of them are structural road where the robot walked along the center lane lines of the roads and turned at every zebra crossing. The other four roads are not structural roads where the robot went along the curb and turn at every sign. The monocular color camera is Sony EVI-D100P. The control cycle period is set to 1s and a = 1, Œ≤ = 0.2, Œ≥ = 8, a = 15, b = 0.05 in the linear equations. The average success rate on every road is over 95%, with over 98% in fourof the six. The total success rate of continuous walking on the six roads is more than 80%, which reach the expectation for this experiment.

This research combines the technology of computer vision, pattern recognition, fuzzy control, etc. and realizes an intellectual visual navigation on a small robot platform. Based on the limited states, it manages the traveling condition of the robot, collaborating simultaneously others modules and underwent an experiment on six roads of known conditions. The experiments show that fuzzy controller and inertia navigation can well reduce the instability of the vision navigation. And mainly through well-designed vision navigation,small mobile robot can accomplish the task of automatic cruising in good lighting conditions on both structured and unstructured outdoor roads.

In the process of walking straight, the occasional corrections of the robot present continuous oscillations. Reasons are: 1) Although the fuzzy controller will stable the angular velocity at a certain value, the blurred image during turning will still cause an increase of errors in the visual navigation; 2) The ground fiction of the four wheels of the robot are different. We should enhance the tolerance for this situation in the controlling strategy or develop new algorithms in terms of image stability. Also we should do more research for precise turning strategy in the future. Finally,we will gradually try to run our vision navigation and control system in unknown environment.

