In seafood processing industries, control measures are adopted to ensure the safety and quality of products. Various quality assurance standards exist to guarantee the safety and quality of goods. Some of them are International Organization for Standardization (ISO), Hazard Analysis Critical Control Point (HACCP), Quality Management Program (QMP), Total Quality Management (TQM), etc. [3]. So the adoption of

proper quality control systems is mandatory in any seafood organization that deals with food processing and distribution. Seafood exporters in developing countries have experienced serious problems complying with progressively stricter food safety and quality requirements for importers. So the author proposed ONTO SQAM, a knowledge-based model to ensure the quality of the seafood.

Knowledge-Based Systems are expert systems that utilize Artificial Intelligence (AI) techniques to generate knowledge from the data, analyze the data and convert it into meaningful information, thereby acting as a human expert. Ontologies propose an efficient knowledge representation technique in Artificial Intelligence systems. Ontologies provide sound rea- soning systems. The definition of ontology follows as a ‘‘for- mal, explicit specification of a shared conceptualization” [1]. Ontologies were developed in AI to facilitate knowledge shar- ing and reuse [2]. Ontologies provide a formal semantics for the description of many concepts involved in the domain and relations between these concepts [6]. The knowledge base of the proposed model contains information about the seafood, details of the test parameters, values, etc. It is implemented using different ontologies. The ontologies analyze the quality test results, and a better, and detailed quality report is gener- ated automatically by the system.

The rest of the paper is organized as follows: Section 2 com- prises of the materials and methods. The section describes the design of ontologies, analysis of quality test parameter values, and the proposed algorithms. Section 3 includes results and discussions. It illustrates the data sets used, the performance of the algorithms on the selected data sets and the values of performance metrics. Section 4 presents the conclusion which is followed by references.

Ontologies define the semantics of the concepts identified in a domain. There is no single method to develop an ontology. This research follows the approach proposed by Noy and McGuinness in the development of ontologies [4]. Many inter- esting ontologies are available on the web in different domains, particularly in the medical domain. Such ontologies enable information sharing, and other applications reuse them. But in seafood domain, no relevant ontologies exist. So the ontolo- gies used in the proposed model are developed from scratch.

The parent classes in Seafood ontology are the central con- cepts in the domain such as product types, fish categories, country of export and type of tests. Country, Fish, Product, Test, etc., are the main classes of the ontology. Each of these main classes consists of different subclasses according to their types. The main fish categories included in the ontology are Bony Fish, Cephalopods, Crustaceans, Molluscs, and Scombridae. The various seafood under each category is the instances of the particular class. For example, the instances of Cephalopods are Cuttlefish, Octopus, Squid, etc. Fig. 2 shows Cephalopods class and its individuals (instances).

Fig. 3 shows the taxonomy of Test Specifications Ontology. It contains the test standards of seafood and sanitation items such as water, ice and salt used during the seafood processing. Quality Checking tests are of two types – Internal Test and External Test. The specifications are different for internal tests and external tests. External-Test and Internal-Test are the two sub-classes of the Test-Specification ontology. Under each of these classes, we have subclasses to represent sanitation item and  seafood  item.  Internal-Test-Non-Food  and  Internal-

Test-Spec-Raw-AllCountries and Test-Spec-Uncooked- Frozen are the two primary classes of Internal-Test-Seafood class. For each category of raw seafood, the test specifications are independent of the country of export. So the five subclasses of Test-Spec-Raw-AllCountries represent the test specifications of five categories of seafood included in Seafood ontology. But

Fig. 4 shows the proposed model to analyze the test parameter values. Initially, the laboratory technologist conducts tests (organoleptic, microbiological and chemical) as usual, and the sample results are input to the proposed model. The model generates a product test file (owl file) that contains the test parameters and the results of each sample. It produces a new file for each test sample, which contains the test parameters and the obtained parameter values.

Before checking the values with the test standards stored in the Test Specifications ontology, the comparison algorithm (Analysis I) analyzes the parameter values. This checking does ensure that the obtained values are in the acceptable range. Data store update algorithm updates the acceptable values for a particular test in the data store. The permitted value for each test item is computed by the data store update algo- rithm using ontology data and Test Specifications ontology. These values are stored in the Data Store, making it available for fast retrieval. The comparison algorithm compares the cur- rent test values with the values retrieved from the data store. If the values are not in the permissible range, the laboratory tech- nologists provide necessary alerts.

The test quality standards for validation are implemented using Semantic Web Rule Language (SWRL) [7]. Fig. 5 shows the rule in SWRL to validate the Molluscs. The microbiologi- cal tests check the presence of ‘TPC’, ‘Vibrio Cholera’, ‘Vibrio-Parahaemolyticus’, ‘E-Coli’ and ‘Staphylococcus-Aur eus’ in molluscs. Organoleptic factors are ten in number, listed from 6 through 15 in Table 1. Paralytic shellfish poisoning (PSP) and Diarrhetic Shellfish Poisoning (DSP) are two major biotoxins associated with shellfishes such as clams, mussels and oysters. These 19 parameters determine the overall quality of the raw material. The technologist compares the values obtained with the tolerance limit. The acceptance/rejection of

The Test Specifications ontology stores the microbiological, chemical and organoleptic test standards (min_value and max_- value). So these test standards are available only during the Analysis phase. Also due to scalability issues of ontology, it is time-consuming to every time retrieve the test standards directly from the ontology. So a data store update algorithm is proposed to compute the permitted value for each test item. The above algorithm stores the updated min_value and max_value of each test in the data store, making it available for fast retrieval. When the laboratory technologist inputs the value, a comparison algorithm retrieves the permitted range of the concerned test from the data store. The comparison algorithm checks whether the value entered by the user is within the allowable range, by comparing the test input value with min_value and max_value available in the data store.

Table 2 shows the proposed Data Store Update algorithm. The purpose of this algorithm is to update the data store with an acceptable minimum and maximum value for each test. In the beginning, the algorithm retrieves the corresponding past test values from the ontology. Then the algorithm removes the duplicates and sorts the values. The next step is to set a

minimum value and a maximum value. The Test Specifications ontology outputs the standard test limits (min and max) of the concerned test. The algorithm compares the minimum of the past test values with the standard minimum limit retrieved from the ontology and accordingly sets the min_value. Similarly, it sets the max_value. The algorithm also computes the variance of the test values. In the end, it updates the computed values min_value, max_value, and the variance in the data store. This algorithm is executed periodically as per the system settings so that the data store contains the updated values.

Table 3 shows the proposed comparison algorithm. The pur- pose of this algorithm is to ensure the validity of the test pro- cedures and the accuracy of the values obtained. So this comparison is not made with the standard limits of the test. Instead, the comparison algorithm checks the test values with the values in the data store. The algorithm retrieves the min_value and max_value of the current test from the data store and compares with the current_value. If the current_value is within the permissible range, it means that the values are known. Otherwise, the algorithm checks the range of variation of the test values from the data store values. For this, it com- putes the range and standard deviation. The algorithm retrieves the variance stored in the data store and calculates the standard deviation. Next step is to identify the severity of the error. If the current_value is lesser than the min_value, the  algorithm  checks  whether  it  is  also  smaller  than

or can repeat the test. Similarly, if the current_value is greater than the max_value, the algorithm checks further as mentioned above and generates concerned alerts. Once we have a large number of test values and their reports in the data store, the comparison algorithm gets a collection of test values so that it can set the min_value and max_value. So the accuracy of the comparison algorithm is increased as more data accumu- late in the data store.

The data sets used are taken from different seafood companies in Kerala, India, which exports seafood and seafood products to all around the world. The Marine Product Export Develop- ment Authority of India (MPEDA) validated the data sets. The data sets consist of details of seafood purchased from var- ious landing centers. It includes the purchase date, seafood type, landing center code, quantity, importer details, microbi- ological, chemical, organoleptic test details and details of sea- food exports to different countries. The experiment used three datasets of seafood families namely, Bony Fish, Cephalopods, and Molluscs. Each family includes different types of seafood, and each group contains valid and invalid data.

For Bony Fish dataset, the algorithm identified 37 test sam- ples correctly as true positives and ten samples as true nega- tives. It wrongly lists two valid test samples as having problems in the test values. The algorithm incorrectly outputs three invalid test samples as within the allowable limit.

For Molluscs data set, the algorithm correctly outputs 15 test samples as known values. The algorithm correctly recog- nized 3 test samples as ‘probable error’ or ‘unacceptable value’. One sample whose test value was in the acceptable range was output wrongly as ‘probable error’. The number of samples whose test values were outside the range identified as ‘known value’ is 2.

The paper presents the initial phase of a proposed model ONTO SQAM, an ontology-based model to ensure the quality of seafood. Two algorithms are proposed to check the param- eter values at the initial stage. It helps to understand about any errors or quality issues at the beginning. The Data Store Update algorithm updates the acceptable minimum and maximum value of a test in the data store. The Comparison algorithm compares the new test values with these updated val- ues to ensure that the test values are in the acceptable range. Later, the actual comparison of the test values with the test standards stored in the ontology is performed. The perfor- mance metrics such as precision, recall, and accuracy are used to evaluate the performance of the model. The experimental results obtained on the datasets show that all the three measures achieved good results.

P.V. Vinu, P.C. Sherimon, K. Reshmy, Modeling of test specifications of raw materials in seafood ontology using semantic web rule language (SWRL), in: Proceedings of the 2015 International Conference on Advanced Research in Computer Science Engineering & Technology (ICARCSET 2015), ACM, 2015.

