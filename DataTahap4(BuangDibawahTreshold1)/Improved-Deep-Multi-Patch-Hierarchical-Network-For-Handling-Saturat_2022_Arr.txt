Motion blurring is a process of degradation of the image due to different conditions for example camera shake, relative motion between the camera and object, depth variations (Few to mention) during image capturing. The process of generating a sharp image by removing blur from a degraded image is called Image Deblurring. Image deblurring is the most basic step yet very important in computer vision applications. The blurring process is mathematically modeled as

problem to be addressed [1‚Äì11]. When the image is captured in low light conditions with extended exposure time, a bright spot in the image will be saturated by clipping pixel intensity to its maximum value [12]. These saturated pixels violate the linear blur model assumed by many existing algorithms and such pixels cause noticeable ringing artifacts in deblurred images as shown in Fig. 1. The blurred images with saturated pixels are modeled as [13],

layers lose high-frequency components. Because of these mistakes, it is hard for the network to figure out which features are the best, which leads to ringing effects and bad deblurring Fig. 2. To address this issue, we present Improved DMPHN, whose performance is higher compared to current state-of-the-art deblurring methods. Our contributions are summarized below:

We avoid learning abstract features and blurring fine image struc- tures by using 1X1 sized filters instead of 3X3 sized filters in the proposed network model. It also reduces the number of model pa- rameters and increases the network‚Äôs nonlinearity. The model is more general and better at deblurring after being trained with synthetic and real-world images with various types and levels of blur and saturation. The experimental results show the clear benefits of the proposed Improved DMPHN (Name IDMPHN) model in handling saturated pixels effectively in motion deblurring with a significant reduction in ringing artifacts and support deblurring of 720-pixels images in real-time (at 30 frames per second). The paper contributes a brief framework of the associated effort of inception modules and Deep Multi-Patch Hierar- chical Network in Section 3. The implementation method containing the reformed basic model and the overall architectural structure of the network is described in Section 4. Estimation of our experimental results, aiming at investigating qualitative and quantitative estimations

In recent years, the conventional deblurring methods have concen- trated on three main features, i.e., probabilistic noise model [1,15, 16,29], strong priors of natural images [2,3,30,31], and estimation of blur kernel [17,32‚Äì34]. Recently, learning-based approaches (CNNs) are evolved tremendously in the image deblurring process due to their self-learning capabilities, computational speed, and robustness. Some stages in the conventional methods are replaced with learning-based methods [35‚Äì37], and some techniques completely avoid blur kernel estimation by learning an end-to-end mapping [4,18,38].

Image deblurring falls into two groups based on the knowledge of the blur kernel. The first group is non-blind deblurring [13,15,19,27], where the blur kernel is known and the solution is a purely inverse problem. The second group is blind deblurring [1‚Äì3,5‚Äì7,10,14‚Äì17,21, 26,29‚Äì33,38], where there is no clue of blur type and this method is more accurate but ill-posed. Statistical and learning methods are

and decoder to capture the nonlinear properties of saturated pixels and blur. Outline of the modifications made to the basic encoder‚Äìdecoder architecture is explained in this section alongside the overall architec- ture of the proposed network. In this work, the modified network design is primarily founded on a method called Deep Multi-Patch Hierarchical Network [11].

Network-in-Network (NIN) is a method suggested by [46] shown in Fig. 4 to improve the representational capabilities of neural networks. The NIN act as a micro neural network that enhances the discrimination ability of inlier and outlier (more complex structures of saturated pix- els) properties for local patches within the receptive field. In traditional CNN, the convolutional filter is a generalized linear model (GLM) that goes along with a nonlinear activation function to scan the input.

When the samples of latent concepts are not linearly separable then the linear CNN cannot abstract the good representations. The Conventional CNN is designed in such a way that the model can abstract the good representations by utilizing a set of over-complete filters to capture all the variations of the latent concepts. But the utilization of numerous filters for this purpose may put additional load on subsequent layers. In CNN, the higher-level layer map to the larger regions of the input image by combining the lower-level concepts from each local patch. Hence it is required to make good abstraction at lower levels to make higher levels work better. With these advantages of NIN as a micro neural network is combined into existing Convolution Neural Network architecture in hunt of better abstractions for all the levels of features. Inspired by ‚Äò‚ÄòNetwork-in-Network‚Äô‚Äô for classification tasks, the existing DMPHN modeled with conventional CNN layers is modified by intro- ducing micro neural networks to capture the nonlinear properties of saturated pixels and motion blur to achieve improved image deblurring results with less computational complexity.

in the deeper layers lose high-frequency components.Third, it is unable to capture the appropriate local information of blur around saturation regions since the blur model is non-linear around the saturation regions represented in Eq. (2).This loss of information due to the inability of framework introduces prominent ringing artifacts and limits deblurring performance shown in Fig. 2.

The architecture of our IDMPHN network is shown in Fig. 5. Every stage of the architecture comprises one encoder with fifteen convolu- tional layers, six residual links, and six Rectified Linear Units (ReLU). Every encoder will follow by one decoder whose architecture is similar to the layers of the encoder except deconvolution layers are introduced to generate deblurred images in place two convolution layers. The architectural difference between the proposed DMPHN design in [11] and our IDMPHN architecture is shown in red.

This section highlights that our network design is constructed on the model proposed by [11]. The complete structure of our IDMPHN design is shown in Fig. 6. Following the similar approach, the blurry input image is equally divided into Four, Two, and One patch(es) from level-Three to level-One, correspondingly, as shown in Fig. 6. The intermediate feature map of each patch at each level is achieved from the corresponding encoder. At each level, the features extracted are different with more depth at lower levels, the information at all the levels is gated to the highest level. Hence, the top level contains all the information received from the lower levels, the residual links help in providing the information at the upper levels. It is important to note that each feature map of every patch is of the same size for convolutional operations from the lower level to the higher level of the

cally been used as feature detectors in classification tasks. However, stacking multiple convolutional layers on top of each other endows the network with the ability to abstract details in deeper layers [48]. Although this property is useful for classification and other similar tasks, it is not suitable for image deblurring because finer details of an image must be preserved for a good reconstruction. To extract all of the necessary features from the image, simply having large number filters of the same size is not enough. Inspired from inception [46] layers

to encoder ùê∏2 is the sum of ùëÉ3,ùëó and ùê¥2,ùëó , and the output of ùê∏2 i.e. ùêµ2,ùëó Next, the process will shift to the succeeding level i.e. level 2. The input is added with ùêµ‚àó . The output of encoder ùê∏2 is,

/ig. 5. Layer configurations for proposed (a) decoder and (b) encoder architectures. The difference in architecture between [11] and ours is noted in red. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)

the cropped photos are fed into each level‚Äôs inputs. The batch size has been set at six. The weights are optimized using Adam optimizer for 2 epochs. The initial learning rate is set to 0.0001 and the decay rate to 0.1. The image is normalized to the range [0, 1], and then 0.5 is subtracted. Due to CPU memory constraints, the deepest Stacking model trained and evaluated is (1-2-4).

This section assesses the proposed system‚Äôs performance on both synthetic and real-world images and compares it to current state-of- the-art systems. We compare our method to state-of-the-art algorithms by running large numerical tests on two benchmark datasets with saturated pixels [18,28]. Then, to demonstrate the usefulness of our approach, we use some hard real-world instances with large saturated regions.

trained our model with 100 pairs of randomly chosen images out of 3214 pairs, due to hardware limitations. Our method tested on synthetically blurred images of varied blur types and compared with the existing DMPHN [11] model trained with 2103 image pairs, where our model showed better results in handling different blur types with and without additional saturation both quantitative and qualitatively since the model can learn and capture the blur along with saturation regions at initial stages, shown in Fig. 7 and Table 1. Our IDMPHN model outperforms the existing DMPHN model for all blur types, but somewhat worse for motion blur, because the DMPHN model is ex- clusively trained and tailored to deal with motion blur using a bigger training set [18]. Even with a low training set, our model handles motion blur comparably well to DMPHN, and training with a larger dataset would improve deblurring quality, as shown in Section 5.2.2.

Disc blur + saturation + noise. Disc kernel with radius 7 shown in Fig. 10(a) is applied on sharp images first, then each pixel intensities are multiplied by scale factor 1.3, finally, Gaussian noise with zero mean and Variance of 0.05 is added.

Synthetic uniform blur+ saturation + noise:. The sharp image is blurred by convolving with one particular uniform blur kernel out of 4 uniform blur kernels provided in dataset [28] shown in Fig. 10(c), then each pixel intensities are multiplied by scale factor 1.3, finally, Gaussian noise with zero mean and Variance of 0.05 is added.

27 clean images mentioned in Section 5.2.2 and tested with chal- lenging examples with abundant saturated pixels chosen from the literature, consolidated by [28] which includes Non-Uniform and Real blurred images. Table 5 shows the quantitative results of our model for non-uniform blur inputs. Fig. 13 represents deblurred images of Non-Uniform blurred input. Fig. 14 represents the deblurred images of naturally blurred input images. The state-of-the-art approaches [2, 11,15‚Äì20,22,24,26] are less effective due to the side effects caused by saturated pixels, and their deblurred results contain ringing artifacts, and some features are not recovered properly, as it is visible in Fig. 13 & 14 .

Compared to the previous DMPHN model [11], the suggested model reduced the time cost by around 1%. For 100 epochs with a batch size of six, the time cost is estimated for both models using GoPro and Lai‚Äôs dataset. Thus, the present DMPHN model has already been demonstrated to be several times quicker than the other techniques. Aside from DMPHN, our approach performs far better than any other method. To compensate for the lower time cost, our model features 62.7% less trainable parameters than the previous DMPHN model [11]. Table 2

duced at the beginning and end stages of each decoder and encoder, respectively, though there is a lack of local features in narrower grids. Furthermore, the IDMPHN performance can be improved by stacking many network models horizontally rather than vertically, as demon- strated in Fig. 15. The model‚Äôs performance can be improved further by training the network using a suitable data set and fine-tuning network parameters.

Gong Dong, Yang Jie, Liu Lingqiao, Zhang Yanning, Reid Ian, Shen Chunhua, et al. From motion blur to motion flow: A deep learning solution for removing heterogeneous motion blur. In: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017. p. 2319‚Äì28.

