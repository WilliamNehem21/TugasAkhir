To reduce the instability of discrete prompts, we propose a novel method P-Tuning that em- ploys trainable continuous prompt embeddings in concatenation with discrete prompts. Specifically, given a discrete prompt as the input, P-Tuning con- catenates continuous prompt embeddings with the discrete prompt tokens and feeds them as the input to the language model. The continuous prompts are updated by backpropagation to optimize the task objective. The intuition is that continuous prompts incorporate a certain degree of learnability into the input, which may learn to offset the effects of mi-

In the area of NLU, a few concurrent methods were proposed based on continuous prompts, fo- cusing on improving knowledge probing (Qin and Eisner, 2021; Zhong et al., 2021). Lester et al. (2021) showed that with large pretrained models, only tuning continuous prompts with a frozen lan-

In this paper, we present a method P-Tuning that uses continuous prompts in concatenation with dis- crete prompts. P-Tuning improves performance and stabilizes training for pretrained language model adaptation. P-Tuning is effective with both tuned and frozen language models under both the few-shot and fully-supervised setings.

