Abstract Embedded systems consist of one or more processing units which are completely encap- sulated by the devices under their control, and they often have stringent timing constraints associ- ated with their functional specification. Previous research has considered the performance of different types of task scheduling algorithm and developed associated timing analysis techniques for such systems. Although preemptive scheduling techniques have traditionally been favored, rapid increases in processor speeds combined with improved insights into the behavior of non-preemptive scheduling techniques have seen an increased interest in their use for real-time applications such as multimedia, automation and control. However when non-preemptive scheduling techniques are employed there is a potential lack of error confinement should any timing errors occur in individual software tasks. In this paper, the focus is upon adding fault tolerance in systems using non- preemptive deadline-driven scheduling. Schedulability conditions are derived for fault-tolerant peri- odic and sporadic task sets experiencing bounded error arrivals under non-preemptive deadline scheduling. A timing analysis algorithm is presented based upon these conditions and its run- time properties are studied. Computational experiments show it to be highly efficient in terms of run-time complexity and competitive ratio when compared to previous approaches.

preemptive optimal scheduling algorithm on a uniprocessor can also be scheduled by its non-idling, non-preemptive coun- terpart if the processor is speeded up by a factor which is no more than a simple linear function of the timing requirements (and is usually quite small for realistic applications) [1,2]. Since timing requirements are typically fixed by application con- straints and processor speeds are much faster than one or two decades ago, this has renewed interest in non-preemptive and limited-preemptive scheduling on low cost microcontroller and microprocessor platforms [1–5]. For embedded real-time applications such as multimedia, automation and control, increases in hardware parallelism (such as multicore proces- sors, DMA, programmable ADCs/DACs and dedicated com- munication controllers) also favor the use of non-preemptive scheduling as the workload on the host CPU can be consider- ably reduced. Such applications are the focus of this paper.

[4] and Nasri and Fohler [5]. The results demonstrated by Abugchem et al. [1] and Thekkilakattil1 et al. [2] are directly applicable to the npEDF scheduler. Since very efficient run- time implementations (with effectively O(1) CPU overheads) are relatively straightforward to create [13], npEDF becomes the focus of the current paper.

Unless evasive action is taken when a task fails, program flow will never be returned to the scheduler; the entire system will effectively ‘freeze’ indefinitely, or at least until the problem is cleared. Such a situation is depicted in Fig. 1 for two peri- odic tasks s1 and s2, both having a period and relative deadline of 50 ms. Supposing that task s1 fails during its third invoca- tion (at t = 105), then both tasks will miss their deadlines indefinitely; or at least until the situation is detected and recovered.

Timeline breaks such as that depicted above are especially problematic in real-time control systems. Physical processes such as chemical reactors, aircraft and nuclear power plant are open-loop unstable, and the automatic control of such sys- tems is safety-critical in nature as interruptions of the provided control service may lead to hazardous physical conditions [15]. Even with open loop stable systems, interruptions of control services can lead to deleterious or degraded performance because of the effect of introducing large time delays and jitters in the feedback loop [16]. Considering that experimental stud- ies employing fault-injection have reported that approximately 58% of faults injected into a representative real-time operating system and its application tasks resulted in either complete sys- tem failures or multiple task ‘crashes’ [17], adding fault toler- ance into npEDF would seem to be advisory. Fault-tolerance in this context refers to fault detection and recovery and also temporal redundancy, i.e., indirectly detecting a fault (caused by an error) through its effect on the execution time of a task, recovering the state of the CPU and attempting re-execution of the failed task at some appropriate future point in time.

from a computational study which provide an evaluation of the relative effectiveness of the proposed techniques in com- parison with previous works. The remainder of this paper is organized as follows. Section 2 reviews some relevant previous work in the area of fault tolerant real-time scheduling. Sec- tion 3 presents the system and error models while Section 4 derives the schedulability analysis. Section 5 presents the com- putational simulation results. Section 6 concludes the paper and presents some areas for future work.

A watchdog timer is arguably the simplest approach for error detection and correction in a computer system [18,19]. How- ever the use of a watchdog can have several drawbacks with respect to a real-time control system, as outlined in Short and Sheikh [24]. Previous work has therefore considered more elaborate error/fault detection and recovery means for task failures for a variety of non-preemptively scheduled systems: the key related works are now elaborated.

Overload detection and recovery has also been investigated with respect to fully preemptive scheduling. As outlined by the survey paper of Gardner and Liu [25], these techniques typi- cally rely upon the detection of a task exceeding its execution budget and the application of corrective action. An effective solution for preemptive EDF lies in the Constant Bandwidth Server (CBS) [26], which for the case of real-time control sys- tems typically involves the dynamic elongation of the period(s) of the offending task(s) to maintain a constant utilization. The CBS, however, cannot deal with timeline breaks such as that depicted in Fig. 1. Although each of these schemes may be applied (to a certain extent) within the framework of npEDF, to the knowledge of the current author no schedulability con- ditions for the general case of fault-tolerant npEDF scheduling of recurring tasks under bounded error arrivals have previ- ously been described. This is aimed to be addressed in the next section.

In which pi is the task period (minimum inter-arrival time), ci is the (worst-case) computation requirement of the task, di is the task (relative) deadline. Each invocation of a task is called a job. When a job of task i becomes ready at time t, its absolute deadline is set at time t + di and the scheduling algorithm must allocate ci units of CPU time to process the job in the interval [t, t + di); otherwise, a deadline miss will occur. Jobs are scheduled according to the npEDF scheduling policy, in which the ready job with the earliest (absolute) deadline is selected to be run to completion. Ties between ready jobs shar- ing a common deadline are broken arbitrarily but consistently, typically by lowest task index. An executing job is said to be blocking another job, if this ready job has an earlier deadline and is waiting for the current job to complete before it can exe- cute on the processor; note that in a fully preemptive system, the blocking task would have been preempted (suspended, paused) by the arrival of the blocked job. Under the npEDF scheduling policy, a job can be blocked if and only if it is invoked subsequently to the blocking job being selected for execution.

The quantity h(t) is the processor demand function, represent- ing the worst-case execution requirement of jobs with release time and deadline in the interval [0, t). The quantity b(t) is the blocking function, representing the worst-case blocking due to non-preemption that a job may experience in the inter- val [0, t). See, for example, Refs. [1,11,12] for details of the derivations of these functions.

In the current context, a job error can be defined as an incor- rect state arising during the computation of a job (arising due to electromagnetic inference or other disturbances); a job fault is the inability of a job to function in a correct manner (due to the manifestation of an error or a software defect); and a job failure is a loss of service where the required computational results cannot be delivered on-time due to faults. The paper is concerned with temporal effects of errors and defects upon system timing. The terms job error, job fault and job failure will be used interchangeably on occasion; it should be taken that this refers to a job which has exceeded its assumed worst-case execution time. In this paper, it is assumed that job failures occur intermittently due to transient errors (EMI) and/or particle strikes. Any transient upset affecting the CPU (and its constituent components or peripheral devices) can potentially lead to control-flow or data errors occurring, which leads to job faults and failures – these job- level faults and failures will ultimately lead to timing failures (deadline misses). Previous estimates of bit corruption proba- bility in an IC arrange from ≈10—9 to 10—7 bit failures per hour, varying upon altitude [27]. Other types of failure may also occur intermittently (pseudo-randomly) due to interac- tions between sensor signals and other inputs and latent soft- ware defects, see for example [19,24]. The arrival of errors (or the encountering of software defects) leading to timing faults and failures of jobs is therefore considered sporadic in nature, in the sense that the occurrence of two consecutive job failures is always separated by at least pf time units. In other words, suppose that the last job failure affecting the sys- tem occurred at time t1 (with probability k), then the probabil- ity of a job failure occurring at some time t2 > t1 is either k if

[24], assumption (iv) requires that control be returned to the npEDF scheduler upon completion of a fault handler. This is very beneficial from the perspective of schedulability as will be described in the next Section. The schedulability guarantees that will be developed ensure that all jobs generated by all tasks will meet their deadlines in an environment in which error arrivals are repetitive (sporadic), but are bounded in the sense that they are separated by at least pf time units. In the absence of any empirical data or specific knowledge regarding the error separation pf, one may look to practical guidelines that have been developed within industry. For industrial measurement and process control systems, Electro- magnetic Compatibility (EMC) testing according to IEC 61000-4-4 requires a system to be able to tolerate short bursts of interference (of duration ≈15 ms) with a repetition period of 300 ms. Therefore, setting pf = 300 ms and cf = 15 ms (in addition to the time actually required for any additional fault recovery mechanisms) seems a practical choice for most types of industrial embedded systems.

Observation 2. Under npEDF, considering a job with a dead- line at t = d and a single error occurs in the interval [b(d), d), then the worst-case behavior is induced when the eligible job with the largest execution time fails. Under the npEDF scheduling policy, jobs which are eligible for execution in the interval [b(d), d) are those which are generated by tasks satisfy- ing the relationship di 6 d. h

failures (with each job having a short execution time) may not necessarily be as severe as the manifestation of only a sin- gle job failure (having a comparatively longer job execution time). In addition, there are situations in which the absence of blocking due to non-preemption can lead to worse failure behaviors that with blocking present; such a case may occur if more failures can be packed into the interval [0, d) than [b (d), d) and b(d) is less than the largest execution time of the eli- gible jobs in [b(d), d). Another complicating factor is that if a failure is detected immediately, then this may have the effect of inserting a preemption point in the schedule, which may reduce run-time blocking (although the worst-case blocking is clearly not effected). As such, although the exact categoriza- tion of the worst-case behavior could potentially be obtained, this may require consideration of an excessive number of situ- ations and would be very difficult to compute. However, it is relatively easy to use the observations above to calculate a safe upper bound on the worst-case failure workload, which is pre- sented in the following Lemma:

always greater than or equal to the actual number of error arri- vals, regardless of whether blocking is present or not. As it was assumed that an error arrival will cause the executing job to fail, and since any task with a relative deadline at or before t generates jobs which are eligible for execution in the interval [0, t), taking the largest execution time among those tasks sat- isfying the relationship di 6 t gives an upper bound on the exe- cution time of the largest valid job executed; hence adding this value to the worst-case execution time of the fault handler cf gives the worst-case computational demand due to any single error arrival. The function f(t) in Eq. (4) multiplies this upper bound on the number of error arrivals (and hence job failures) by an upper bound on the worst-case computational demand of any single job failure; it must therefore upper bound the cumulative computational demand due to failed job executions regardless of the presence or absence of blocking or the actual arrival pattern of any valid set of errors. h

Proof. Lemma 1 has established the validity of the upper bound f(t), and it is straightforward to see that whether the summation of the processor demand h(t), non-preemptive blocking b(t) and the upper bound on workload due to failed job executions f(t) is always less than or equal to the CPU time available then the tasks will be schedulable. Condition (8) is sufficient to ensure that the CPU is not overloaded during the course of its lifetime (in the limit as t ? ∞), as we have from (7) that job failures will in effect manifest as a sporadic task requiring a fraction of the CPU utilization proportional to no more than uf. Thus it remains to verify that no deadlines will be missed in some initial portion of the schedule under worst-case assumptions, and to show that the test interval for this can be bounded by the proposed value of tmax to com- plete the proof. We have that for t P max{di — pi}, it holds that t P di — pi 6i and hence t — di P — pi 6i. Inspecting the individual terms of the processor demand function (Eq. (2)) for each task we have that

Condition (9) needs to be evaluated only at values of t cor- responding to absolute job deadlines within the interval [dmin, tmax) [11]. If the CPU utilization U' is bounded to be less than some small fixed constant c, the worst-case complexity of eval- uating the conditions of Theorem 1 is pseudo-polynomial with run-time O(n max{pi — di}), which follows from Theorem 3.1 in Stankovic et al. [11]. In the case where U' is exactly equal to unity, then the complexity of deciding schedulability can become exponential as the condition of (9) is required to be checked over the least common multiple (lcm) of the task periods/inter-arrivals. Since for many real-world task sets the CPU utilization can be bounded below the value of some con- stant close to unity (e.g. c = 0.999), the schedulability test can be made to be very efficient. In fact, for implicit deadline task sets the categorization of the run-time complexity can be fur- ther improved as will now be shown:

Even in cases of relatively high CPU utilization the bound on the number of absolute deadlines given by Eq. (17) is useful. For example when c = 0.999, not more than 2000n deadlines ever need checking. This is in contrast to methods proposed by Mosse and Melham [20] and Hughes and Pont [23], in which evaluation of schedulability surmounts to checking over the task hyper-period. The following example illustrates this efficiency gain.

Using the technique proposed by Mosse and Melham [20], it would have to be determined whether the equivalent aperiodic jobs generated by the periodic tasks over the system lifetime can be accommodated, by executing the LTH algorithm (with npEDF as the underlying rule for ordering the priority queue) for each and every new job occurring in L which represents the planning cycle (hyper-period) of the schedule. The length of L corresponds to the least common multiple of the task periods, which in this case is equal to 1320 and therefore ≈240 applications of LTH are required to verify schedulability of the tasks. Using the basic TTC scheduler technique with ‘task guardians’ [23] requires a number of checks exactly equal to the length of L (1320) to carry out a schedulability analysis. However, note that the tasks are not

an efficient mechanism to add fault-tolerance to npEDF with efficiently verifiable schedulability conditions. The analysis and illustrative example in the previous Section gave a promis- ing indication of the suitability of the proposed method in this respect; computational experiments using randomly generated representative task sets will be used to give further evidence in this respect. Specifically, the competitive ratio and analysis complexity will be investigated in more depth. First, the methodology employed to generate the task parameters and the design of the experiment is described.

(5)) to reflect that a failed task is immediately re-inserted into the head of the FIFO queue when using the ‘task guardian’ technique. Note that to maximize the chance of schedulability, ‘tick overruns’ were assumed allowed in this case for reasons discussed in Short [10]. Results are also reported for the mea- sure of competitive ratio of the proposed technique with the technique described by Mosse and Melham [20] using the LTH algorithm with npEDF, with the caveat that the results presented may not be full accurate, due to the complexity of the analysis; in most cases the CPU running time was pro- hibitive. Instead, this measure was accurately estimated based on a limited range of examples with tractable running time. To obtain further insight into algorithm complexity as compared to other methods, the ratio of the length of the testing interval (tmax) given by (10) with the duration of the synchronous

In order to further investigate the sub-optimality of the modified TTC approach, an investigation was made of the parameters that influence the achieved competitive ratio. The competitive ratio was calculated (as a percentage) for each configuration of number of tasks and CPU utilization U'. Fig. 3 shows the obtained ratios for these two indices.

From the figure it is apparent that the competitive ratio varies considerably with changes to these parameters. The competitive ratio approaches 90% when 5 tasks are present with utilization U' = 0.6, but decreases to 50% in a close to linear fashion as the CPU utilization increases. Increasing the number of tasks for a given CPU utilization leads to a dra- matic (exponential) drop in the competitive ratio. For 20 or more tasks and utilization of 0.8 or greater, the competitive ratio remained below the 5% level. These data give additional supporting evidence that the goal of creating a simple and flex- ible approach for adding fault tolerance to npEDF has been achieved, in that the technique has a good competitive schedul- ing ratio and comparatively low analysis complexity.

Non-preemptive scheduling techniques can provide a simple and attractive option for meeting real-time constraints in embedded systems. In this paper, the fault-tolerant npEDF scheduling of periodic and sporadic tasks has been studied. Schedulability analysis techniques for task sets experiencing bounded sporadic error arrivals have been developed, and have been shown to provide an efficiency improvement over previous methods in terms of competitive ratio and/or analysis complexity. In conclusion, the proposed technique may be of interest to developers of fault-tolerant, non-preemptive embed- ded systems which may be exposed to interference and errors. Further work will concentrate upon better categorizations of the fault load, the application of probabilistic schedulability guarantees and extensions to multiprocessor environments, extending techniques such as those proposed in Andrei et al. [29].

