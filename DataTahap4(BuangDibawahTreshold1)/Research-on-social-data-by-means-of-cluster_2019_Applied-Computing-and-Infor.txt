One possible way to identify categories among these families and to gain insight on the most important factors for this division is the analysis of social data regarding these families by cluster analysis and data mining techniques. Data mining is a process of discovery of useful information and hidden patterns in databases, widely used in recent research in various fields such as food science [3,4,26,27], agriculture [28,29], social media [2,17], business and customer management [30], sports [6] and others. However, the analysis of social data sets present some challenges derived from the manner in which they are gathered and stored. Social data sets

Data mining refers to the process of automatic discovery of use- ful information in large databases [35]. Data mining techniques merge machine learning, statistical calculation, linear algebra and mathematic optimization concepts in order to uncover hidden pat- terns in data. Machine learning is a fundamental procedure for data mining processes as it generates smart algorithms capable of dis- covering patterns and information in data bases automatically, which aid decision making [5].

Due to the nature of social data and the way they are usually obtained and stored, the application of clustering techniques on this kind of data proves challenging. Research on social data is usually conducted through the use of structured forms which bring a num- ber of questions to be answered by the members of the observed population. Once collected, these data are stored in spreadsheets or plain text. The conversion of these files to data matrixes usually generates columns of mixed types, including numeric, categoric and ordinal variables. Moreover, fields that are not filled are mapped into null values, which represent obstacles for data analysis.

In this study, we used the Silhouette method [33] to estimate the best number of natural clusters within the data set. Silhouette is a graphical display method for clustering algorithms. Each clus- ter is represented by a silhouette which is designed based on sim- ilarity and dissimilarity between the samples. The silhouette shows which samples are well placed in the clusters and which samples are floating between two or more clusters. The entire par- tition is shown in a single plot as a combination of silhouettes which allows visualization of the quality of the clusters. The best number of clusters can be estimated by computing the average weigth of the silhouettes designed for a range of partitions with different numbers of clusters.

The clustering algorithm selected was the PAM [24], an exten- sion of the K-means algorithm. K-means is an antique clustering algorithm which is still very popular due to its speed, efficiency and simplicity [22]. This method searches for k centers within the data set which minimizes the total sum of the squared dis- tances between each sample and its nearest center. The K-means is executed in the following steps:

The dissimilarity matrix which PAM algorithm receives as input parameter can be computed using the Daisy function detailed by [24]. This function accepts mixed data types, including numeric, categoric, ordinal, symmetric and asymmetric binary values, which is useful for the data set we analyze in this study. In order to handle mixed variables, Daisy uses the Gower dissimilarity coefficient [14]. Each variable is normalized by dividing each value by the range of values of the corresponding variable, after the subtraction of the minimum value. Thereafter, the variable will be scaled to [0,1]. Null values are discarded from the calculation.

In addition to cluster analysis, data mining also offers techniques to perform predictive analyses called classification. Classification models implement supervised learning, in which a certain information represented by a class label of an unknown sample can be predicted based on previous observation of labeled samples. These labeled samples are also called training set. The final product of supervised  learning is a  classifier that is

values, for the variable represented by the node. Leaf nodes store the class labels, the final point of the classification. Whenever a new test sample is analyzed, each one of the variables are ques- tioned, following a preexisting path along the tree until a leaf node is reached and its corresponding class label is set as the class label predicted for the analyzed sample. The recursive Hunt algorithm is one of the most commonly used algorithms for building decision

Another advantage of decision trees is the ease of visualization and interpretation. The decision rules exposed on the paths allow us to generate hypotheses regarding the individual influence of each variable in the classification process. Therefore, although they are used primarily as classification models, in this study we employ decision trees in order to interpret the clustering results and visualize which variables are the most relevant to the separa- tion of the clusters [25,35].

mance can be improved by systematic adjustments in the weigth values w1; w2; ... ; wn. The MLP has hidden layers between the initial layer and output layer which works with backpropagation: the pre- diction errors obtained during the training phase are backpropa-

Artificial neural networks are inspired in the cognitive system and neurological functions of the human brain, simulating its neu- ron and links. A neuron has a filament called axon which connects to another neuron through dendrites, and the connection point is called synapse. Similarly, a classification model based on artificial neural networks is composed of interconnected nodes [35]. In this

Feature selection is a data mining process which aims for the removal of feature variables which are considered unimportant of the classification. In general, we say that a feature is considered important for the analysis if it is relevant and irredundant [9]. A variable is considered redundant when it presents high depen- dence to the other variables and the information contained in it can be expressed by a fewer number of these variables. A variable is considered irrelevant when the information it contains does not contribute to generate hypotheses regarding the samples with relation to their class labels. The removal of such variables can

subset S, rcf is the average correlation between the features and the class label, and rff is the average intercorrelation between the features. Irrelevant features present low value for rcf and redundant features present high value for rff , and both cases lead to a mini- mization of the Ms value. Finally, the feature subset which achieved the highest merit is selected as the best feature subset.

Given the 64 families from Cluster 1 which have this income, 48 families (21% of the total of families of Cluster 1) are charac- terized by minimum food security index. On the other hand, in Cluster 2, 173 families (69% of the total of families associated to Cluster 2) have income from social security lower than R$5598 and food security index higher than the minimum. Therefore, in the few cases where a family from Cluster 1 has relatively low income from social security, it is likely that its food security index is also minimum. Moreover, the majority of families from Cluster 2 have income from social security lower than the fam- ilies from Cluster 1, however, they present higher food security index overall.

Around 70% of the families associated to Cluster 1 do give sup- port to other families. Considering the remaining 30% families that do not give support, 13% have relatively high income from social security, but are characterized by the minimum access index (FS_2), and 11% have relatively low income from social security and minimum food security index. For Cluster 2, we can see that, considering the 43 families who have income from social security higher than R$5598, 32 of them did not give sup- port the other families. Therefore, we can conclude that families associated to Cluster 1 usually gave support to other families.

Overall, the majority of families from Cluster 1 receive income from social security higher than the families in Cluster 2, and gave support to other families even in the rare cases where they show lower income from social security and minimum food security index. When families of this cluster did not gave support, they pre- sent a minimum access index. As discussed previously, the major- ity of families from Barbalha (60% of the analyzed families) and Parambu (56%) belong to this cluster.

families, even in the rare cases where the families presented lower income from social security and a in minimum value of food secu- rity. When families of the cluster did not give support to others, they present a minimum access index. Most of the analyzed fami- lies from Barbalha and Parambu belong to this cluster. On the other hand, families from Cluster 2 receive less income from social secu- rity, but they have a higher access index when the income from social security is higher. These families also have a higher food security index, even when the income from social security is low. Most of the analyzed families from Boa Viagem, Guaraciaba do Norte, Itarema and Limoeiro do Norte are associated with this cluster.

Also, working with categorical values is one of the major chal- lenges for data mining researches. We expect, for future works, to improve the processability of our data set, either by standardiz- ing our variables to numeric values only, changing the data collec- tion method (i.e., replace the common surveys) or by employing forthcoming clustering and classification techniques in the data mining literature that can handle categorical variables.

