having difficulties in adapting to new threats [3,4]. Furthermore, the actual security and reliability threats develop over time within complex processes in which minor vulnerabilities (e.g., software bugs, weak separation of authenticated spaces) combine with human/operator er- rors (e.g., credentials leaks) into major problems that are challenging to detect in its early formation stages [5]. Hence, the investigation of security threats is still largely manual [6] or is being addressed with strongly specialized domain-specific techniques to reduce false positives [7,8]. The behavior of entities is often encoded into a mathe- matical model that might be hard to manipulate, abstract, or complex, making it hard to respond to the security threats adequately [9].

process model or how a bottleneck activity results in the final delays of a service/product. Moreover, it is designed to discover, monitor, and enhance processes by extracting knowledge from event data (i.e., event logs). Process mining has already proven successful in many domains, aiding with challenging tasks such as fraud detection [15], robotic process automation [16], or learning analytics [17]. Furthermore, pro- cess mining became also favored in governing safety-critical processes, such as in healthcare, where it supports critical hospital processes and patient treatment [18]. In [19], it is explained why process mining can be beneficial for advanced analysis and provides several use cases of it in different fields.

The evidence-based benefits and capabilities of process mining in similar domains such as software engineering [20] and confidential- ity [21] make it a promising candidate to address the challenges in cybersecurity and software reliability analysis — using its techniques, we might be able to more effectively detect unexpected behavior [22], identify issues [23], detect deviations [24], or verify whether the system conforms to the designed process [25]. Furthermore, it might have the capability to offer an overview of alerts in the system, detect malware in a system, detect frauds, verify the user behavior, or identify software bugs. This brings new opportunities of process mining to ad- vance the state of research in the cybersecurity and software-reliability situations with uncertainty about the actual processes underlying run- time system behavior, which needs to be reconstructed based on the observed events in the system.

This paper aims to enhance researchers’ efforts in cybersecurity and software reliability areas via an overview of research approaches using process mining for the purpose of cybersecurity and software reliability in various domains and for various tasks. The papers are grouped by their application domain to give insight into the current progress of process-mining usage in each one of them. We identify the techniques that are used for this purpose, together with their properties, and discuss possible research directions for further progress in this area. It is an enhancement to our previous study [26], which was limited in scope to the cybersecurity area. The rationale behind the inclusion of the software reliability into the systematic literature review is the observation of relative closeness, overlap in techniques, and similar goals of those two fields when conducting the original review. For this reason, we aim to explore the broader scope, as the techniques might support each other based on the overlap. Furthermore, the combined study should provide greater insight into the field for researchers as well.

The remainder of this paper is structured as follows. Section 2 con- tains a background of process mining. Section 3 provides an overview of existing literature reviews on process mining in other areas. Then, in Section 4, we formulate the research questions and describe our methodology. The usage of process mining to ensure cybersecurity is then detailed in Section 5, followed by Section 6, which focuses on the application of process mining for software reliability. The results of the review and the answers to our research questions are in Section 7. Section 8 discusses the threats to the validity of our review. Finally, Section 9 concludes the paper.

Process mining techniques have proved to be very successful in (1) process discovery, which aims to find a descriptive model of the under- lying process from event logs, (2) conformance checking, i.e., monitoring and inspecting whether the real execution of the process conforms to the corresponding designed (or discovered) reference process model, and (3) process enhancement, which improves and enriches a process model based on the related event data [10].

Several publications have performed a literature review on the usage of process mining. These reviews are typically domain-specific, with healthcare [41,42] and education [43] being the most popu- lar domains. In [18], Garcia et al. employed a general multi-domain systematic literature review to map the applications of process min- ing. They identified 19 application domains of process mining and sorted them by the number of published papers. For the top six areas, i.e., healthcare, ICT, manufacturing, education, finance, and logistics, they described the main contribution of process mining. As the se- curity was placed in eighth place among the domains, the detail of its contributions was not discussed. Moreover, reliability has not been considered at all.

Within the healthcare domain, Kurniati et al. [41] performed a liter- ature review of process mining usage in oncology. Moreover, Williams et al. [42] reviewed the application of process mining in primary care, and Yang and Su [44] reviewed the studies on process mining techniques for clinical pathways. Lastly, Rojas et al. [45] performed a more general literature review about the applications of process mining in the healthcare domain.

present events. The goal is to identify those commonly utilized for cy- bersecurity and software reliability, those that are not, and those rarely considered. Comparing results from the first two research questions with the typical process mining research trends can provide valuable insights. Concretely, the focus is placed on the used technique, target

be found in the review by Leitner and Rinderle-Ma [46], which fo- cuses on security in Process-Aware Information Systems (PAIS), where process mining is however only one of many methods considered. Moreover, as the review covered results from 1993 to 2012, many recent approaches are missing. In [47], Kelemen provided an overview of the usage of process mining for security in the public sector domain, published between 2000 and 2016. Based on this review, the author provides a set of topics that are dominant in the identified research papers, together with challenges and future research directions. The paper, however, only considers the public sector domain (explicitly in its inclusion criteria). Hence, our work, which is an enhancement to our previous study [26], which was limited in scope to the cybersecurity area, continues this research path with a broader study, including more recent publications and a wider spectrum of domains.

Moving away from surveys focusing on process mining, there are many surveys on specific aspects of cybersecurity or software relia- bility. However, they tend to focus on particular domains or tech- niques [48–51]. Also, an overview of existing surveys in cybersecu- rity [52] does not include focus on process mining.

With the missing comprehensive systematic literature review of process mining usage for cybersecurity and software reliability, it is hard to understand where and how the process mining could help the researchers and practitioners. The focus on process mining applications for these tasks in different research directions is an important aspect to consider. Moreover, none of the existing reviews covers the application of process mining in software reliability, which makes the systematic literature review presented in this paper a valuable complement of the current state of the art.

The goal of this study is to review recent research in cybersecurity and software reliability that employs process mining. To this end, we formulate a strategy to guide this study, based on the Kitchenham and Charters guidelines for systematic literature reviews [53]. This includes a digital library search for current literature, snowballing, and manual searching. Within the review, we first consider the cybersecurity and software reliability separately and merge them in later stages. Our review methodology is visualized in Fig. 1, together with the results of each conducted search and processing stage. See Table 1 for a summary of the review protocol containing the number of publications.

Primary collection To establish a base collection of papers, we searched in several digital libraries, specifically IEEE Xplore,1 Elsevier ScienceDirect,2 Springer Link,3 ACM Digital Library,4 Web of Science,5 and Scopus.6 The search was limited to the recent research over the last six years, from 2014 to 2020. Furthermore, we only considered papers written in English.

The search was divided into two parts. One for the cybersecurity and one for software reliability. The reason for this decision is that while both domains share many similar goals, their communities might differ. Regardless of the division, the results of the searches are combined in the subsequent stages of our review method, so that we take advantage of the differences as well as synergies. The search string used to search the digital libraries is in Listing 1 for cybersecurity and Listing 2 for software reliability.

Each filtering step was done by a different researcher. In case of any doubts, the paper was marked and discussed by two more researchers to reach the consensus. To further avoid bias in filtering, a sample of 10% papers filtered out in the first phase was revived by another researcher. Snowballing The last stage is the snowballing, which includes papers referred by papers kept after the second step of filtering. Each snowballed paper was considered in terms of inclusion and exclu- sion criteria, and within the 2014-to-2020 limit, and English-written

Cybersecurity classification. We classified papers that consider cybersecurity into clusters representing the found research directions based on the keywords used in their title, abstract, and possibly full text if ambiguous. The identified research directions and their keywords are security of Industrial Control Systems (ICS, SCADA, smart grids), security of smartphones (mobile, phone, Android), web-application se- curity (web, information system, website), network traffic security (DNS, IDS), attack inspection (attack inspection, identification, extraction, ob- servation), outlier user behavior (outlier, behavior ) and fraud detection (fraud detection).

Reliability classification. For the reliability classification, we used the same principle as with the cybersecurity part of the literature review. The papers were classified based on the keywords used in their title and abstract. If the direction was not explicitly specified, we looked into a broader context of the paper at hand. The identified direction and the keywords used for their classification The identified directions and the keywords used for their classification are the quality assurance (bug, defect, testing ) and error detection (failure, error, runtime, monitoring, auditing ).

Table 2 contains all the reviewed research papers. It shows in which research directions the process mining approach is applied, the main target period of the analysis, used type of process mining (process discovery, conformance checking, process enhancement), and whether the proposed technique requires expert knowledge which might affect its usability. It also contains information about the type of model anal- ysis: whether it is performed manually or automatically. Additionally, Table 3 contains the use cases of process mining usage in found papers.

Industrial control systems (ICS) are present in critical domains like manufacturing, transportation, and energy sector, where they are responsible for production, monitoring, and control. Naturally, security in these domains is vital as successful attacks could cause significant money loss, physical damage, or injury. The domains are often paired with the term critical infrastructures, emphasizing extensive need for dependability.

Specifically, Bernardi et al. [54] studied the detection of anomalous behavior in energy usage from smart meter readings. They classify the readings based on the expert knowledge into several levels. Then, they use process mining for discovering the behavior of customers over time by looking at how the levels of energy usage were changing. They performed process discovery for several periods with the same length. The output is a sequence of time-evolving graphs over a bigger period. Therefore, in this sequence, they can compare the graphs with each other and find anomalous periods with potential security implications. Two similarity measures were used, i.e., the Hamming distance and cosine similarity [84].

In addition to process discovery, Myers et al. [85] applied the conformance checking method in their work. They firstly investigate the suitability of process-mining discovery algorithms for the detection of cyberattacks in industrial control systems. To this end, they compare five algorithms by the ability to create a usable model, the accuracy and the simplicity of it. Then, with conformance checking, they evaluate the most suitable process discovery algorithm by comparing the number of detected anomalous cases, trace fitness, and time. As a result, they suggest that the Inductive Miner with perfect fitness is the most suitable algorithm in this regard. Based on this paper, in their later work [55], they introduced a method for identifying anomalies in ICS and SCADA

Surprisingly, not many work was found in this direction. All iden- tified approaches utilize automatic analysis of past events, but the techniques and use cases widely differ. It is evident that process mining is indeed helpful in this direction. However, the coverage is currently lacking. Future research in this direction could either improve current use cases or extend the usage of process mining for other use cases.

Smartphones are ubiquitous devices operating in a unique context close to end-users, with security issues impacting users’ privacy (data leaks) or financial implications (credit card theft). The process min- ing approaches in this regard focus, similarly to ICS direction [54], on malware detection [56,57] by comparing discovered models. In addition, detection specific attacks are approached by conformance checking [58].

The approach for malware detection and phylogeny analysis in smartphone applications was proposed by Bernardi et al. [56]. It ap- plies the process mining on systems call traces to characterize the application behavior. The authors defined Syscalls Execution Finger- print (SEF), which contains the behavioral model. This behavioral model is a set of declarative constraints between system calls rep- resented by the Declare declarative constraint language [86]. SEF is used as a fingerprint for malware detection, so to detect malware, they compute SEFs of known malware families. These SEFs are then compared to the SEF of the examined application. This approach can recognize malicious behavior based on this comparison. It was eval- uated on a dataset of 1200 infected applications across ten malware

families. It was also proven that it could be used in phylogeny tracking because it could identify variants of the same malware family. They also performed the evaluation on the transformed dataset, where they did current anti-malware obfuscations. Their approach greatly reduced the number of false negatives in this case.

Phylogenic analysis and malware family detection were also per- formed by Cimino et al. [57]. In this work, process discovery was used to obtain temporal logic formulae which were used in formal model verification. Each path of the discovered process model is transformed into a temporal logic formula. This approach was also evaluated and confirmed to offer an effective solution for this problem in smartphone applications.

The process data from activity logs of Android devices were also used by process mining analysis by Hluchy and Habala [58], who applied conformance checking in addition to process discovery. From the phone logs, they chose OS-generated information about specific performed actions, browser history, and network connection log. Then, they performed an attack in which the user activated a malicious URL, which resulted in downloading personal user data via a known vul- nerability, and its discovered model. The used conformance checking technique considers this process model for the offline detection of that attack from examined smartphone logs. This approach raised many false positives, which they concluded is caused because of the simplicity of the attack and the low quality of Android logs.

All the approaches within this direction deal with the automatic analysis of past events. Notably, there is an interesting usage of the declarative approach in two approaches [56,57], which can be at- tributed to diverse options in smartphone usage. This is further sup- ported by the third work [58], where the focused model covers mali- cious usage instead of more traditional non-malicious. It is shown that process mining neatly exploits the available data but the number of approaches is surprisingly low given the wide range of available data discussed in the papers.

In this direction, the focus is put on network traffic data, one of the prime data sources for security analysis. For process mining, there is a dominance of process discovery techniques in found papers. It is usually paired with the manual analysis where the discovered visualized model is analyzed by an assigned expert [22,59]. Notably, one approach performs real-time process discovery for the visualization of a global attack model and conformance checking for the attack classification [60].

Bustos-Jiménez et al. [22] proposed an approach for the detection of unexpected behavior in DNS operations. Their focus is on the detection of a spam attack on DNS servers. From DNS logs, the method builds event logs that are compatible with process mining. They visually compared the discovered model from a dataset with included spam attacks and a dataset without them. Based on this comparison, they were able to identify this type of attack.

Another approach that used visual analysis was proposed by Al- varenga et al. [59], who applied the process mining discovery tech- nique on logs of alerts from Intrusion Detection Systems to create visual models. Complex and large event logs are clustered using hierarchical clustering to provide better user-friendly visualization. This method should help with the manual evaluation of raised alerts from Intru- sion Detection Systems. They performed a case study of the proposed approach on an alert dataset from a university.

The approach of Coltelese et al. [60] is the only one in this category that performs analysis in real-time. They aim to filter the amount of IoT attacks that need to be handled by security operators, while at the same time providing them the global attack model that updates automatically using online process discovery. The filtering is done by conformance checking that outputs the fitness of an incoming attack trace with the global attack model. If the fitness value is low, which means that this attack is new, then the attack is sent to the security operator for inspection. In their approach, they assume that as input, they have traces of attacks, so they do not deal with the attack detection.

Prevalently, manual analysis on discovered models is employed in network-traffic security direction. A possible explanation is that the network traffic is complicated, and therefore cognitive skills for the process analysis are required or because the research in this area is still immature. On the other hand, one approach [60] performs automated analysis of the models in real-time, further including conformance checking. This result alone shows the possibilities in the network traffic area and should motivate further research focusing on different attack types and protocols with automation in mind.

In [62], the authors proposed the approach for detecting abnor- mal user behavior in social network websites to prevent cybercrime. Firstly, they discover a model for normal user behavior using genetic process mining. Then, they identify the abnormal behavior of users by conformance checking. They performed a case study on the Facebook community.

Compagna et al. [61] proposed a tool named Aegis that improves the security of web applications by enforcing security policies. This tool uses process mining to discover workflow models of the target application. These models are obtained from sets of user actions that occurred while interacting with web applications. Therefore, there is a need to simulate real users’ foreseen behavior first. After the process discovery, the user of this tool can also specify other policies,

like authorization constraints. The model is then transferred into a reachability graph that represents all possible valid executions of the web application workflow. Using this method, a run-time monitor is synthesized. This monitor is used by a proxy between the user and web application. Based on its output, the proxy either forwards the user requests to the application or drop them.

The security of web applications, specifically web information sys- tems, was also considered in work by Bernardi et al. [63], who pro- posed a method for improving the security of these systems. This approach utilizes process mining and model-driven engineering. First, they specify the system behavior with Unified Modeling Language, from which they automatically generate a formal model. At the same time, they preprocess the obtained logs of the system to get the event logs, which can be used by process mining techniques. To identify devia- tions, they use ProM [87] visualizations. Those deviations were filtered, and based on the output of the fuzzy mining discovery technique [33], they could be classified as an attack or the new behavior. The classifier, in this case, is the HTTP request code. This method was applied to a web information system for managing the publications.

Similarly to the previous work, Zerbino et al. [24] proposed a process mining methodology in which they manually detect deviations. In this case, it was used for audits information systems, and they used the Disco tool [88]. First, they discovered a process model from historical data. Using Disco, this model can be automatically enriched with other perspectives, like time or organizational perspective. With this tool’s visualizations, they manually detected several deviations in a case study. They mentioned process mining advantages over other audit approaches, like better depth of analysis, broader scope, and easier automation.

Web-application security direction contains several approaches, all utilizing process discovery but often combined with other techniques. Remarkably, there is greater utilization of process enhancement [24, 63], mainly regarding the time perspective, but only for manual anal- ysis. This direction shows a wide variety of process mining usage for cybersecurity, prompting to utilize the ideas for different domains.

Viticchie et al. [64] used process mining for the investigation of the process of the attacks on a small application with different levels of protection, which was performed as an experiment. Every participant filled the report in which their attack strategy was described. These texts were annotated, and process discovery was used on the traces of annotations. The discovered model was used to find out the attack process, the differences between successful and unsuccessful attack processes, and whether this process was influenced by the level of protection used in the application software.

Attacks were also inspected by Macak et al. [66], but a the different point of view. This work is focused on the unintentional insider attack vector identification. Process discovery is used on the event logs pro- duced by the simulation games platform which simulate the working environment for players.

The other approach in this domain is aiming for the inspection and detection of ransomware. Bahrani and Bidgly [65] created event logs from harmless applications and ransomware families. Those logs contained three types of registry events. Then, for each software, they discovered a process model, and from each process model, they ex- tracted the frequencies of each transition. These data then can be used by a classification algorithm to identify ransomware in the application software. Thanks to this, no expert knowledge is required to use this approach.

For the attack inspection, all found approaches analyzed attacks in the past using process discovery. Automatic analysis was performed in one work [65] but without any expert knowledge. This might indicate that it might be hard to transfer the expert knowledge into the auto- matic system for process-aware analysis of attacks. Future research in this direction could tackle the problem with expert knowledge transfer.

The outlier user behavior detection is motivated by finding suspi- cious user activities, which could be malicious in nature. The found approaches can be divided into two main categories: approaches that take advantage of expert knowledge [9,67–69], and approaches that do not need expert knowledge [23]. In those research approaches that do not incorporate expert knowledge, we can see two main methods. Either they are focused on security as their primary goal [23], or their focus is to filter outliers for a better process model [89,90]. Note that the latter is not included in our literature review as their primary focus is not cybersecurity.

The exploration of process mining potential for security was per- formed in multiple approaches. Genga and Zannone [9] designed a methodology for behavior analysis using process mining and applied it to a real event log, while Macak et al. [67] focused on the process mining behavior analysis of insiders in organizations. Both approaches present a set of challenges of a process mining application for security based on their experience, e.g., dealing with the data collection, pre- processing, and selection of the proper features and technique for the analysis.

Li et al. [68] proposed an online token-based monitoring framework for process interaction between collaborative sub-processes in different departments. Based on the business requirements, it ensures the process security by detecting the outer tampering of the data, for example, through the Internet. In this framework, they use a strategy based on the pre-checking of inputs and the post-checking of outputs of tasks. To mine a global interaction process model, they use Interorganizational Workflow, which is based on Workflow net. It can represent a global

A conformance checking technique was also employed in a proposed method by Salnitri et al. [70] to identify the security deviations in process executions. This approach is implemented in the loan manage- ment process of a financial institute. It aims to automatically analyze process executions and identify deviations from a previously defined process model using conformance checking. Then, it determines which deviations are security-critical, based on predefined security policies, and visualize them. For the definition of business processes and security policies, they use the SecBPMN2 modeling language. However, to realize the conformance checking step, they convert the process model to the Petri net notation. After this step, the discovered deviations are transformed back to the SecBPMN2 modeling language. Their approach is fully supported by an extended version of the STS-Tool, which is a software that helps in maintaining a high level of security in socio-technical systems [91].

A system for online analysis was also presented by Talamo and Arcieri [69]. It is used for the operational support of distributed busi- ness processes, which handle sensitive data and require a high level of security, with real-time compliance checking. This system uses Vali- dation Trees to process the data, detect anomalies, and create reports. The automated process validation and troubleshooting functionality are integrated with IT service desk operations. So, in this case, the security is not improved by detecting undesired behavior, but by reducing the

There are several papers that are detecting the outliers in the processes. However, in this literature review, we exclude those that do not have the security as their primary goal in their proposed approach. Alizadeh et al. [23] proposed an auditing approach that combines data and process perspectives to detect non-conforming user behavior with conformance checking. This approach can identify the previously undiscovered deviations.

In this direction, conformance checking is prevalent, emphasiz- ing its effectiveness in outlier behavior detection. Additionally, all approaches except one [23] use expert knowledge for the analysis. Remarkably, there is a wide variety of use cases and techniques, despite this research direction being the largest one found. We speculate that the cause is that user behavior can be very unpredictable, forming a complex process, but at the same time, it can be very harmful in cybersecurity. This variability indicates a potential for future research as the methods are not stale yet.

Fraud detection is a specific research direction aiming to detect false pretenses of entities. Typical examples are unusual processes, violating a rule or policy. The found approaches utilizing process mining in the cybersecurity context tend to employ conformance checking with expert knowledge.

Fazzinga et al. [92] proposed a method for online and offline classification of event log traces as potential security breaches. They create a security breach model, which is used later in conformance checking. In their work, they are trying to solve the problem with the mapping between high-level and low-level operations. It is important in this scenario because they claim that security breach models are typically described as high-level activities, but log traces are typically performed as low-level operations. They used a probabilistic approach in the created model and the following conformance checking. In their following paper [93], they proposed a classification framework that combines their previous work [92], a model-driven method with an example-driven classification. In a model-driven approach, a security breach model is created, and incoming traces are classified based on conformance checking. In the example-driven approach, a set of previously labeled traces is used for later classification. This approach was experimentally validated in their next paper [71].

Security breaches were also the aim of the work of Böhmer and Rinderle-Ma [72], who proposed an anomaly detection strategy in process execution events to prevent not only security breaches but also frauds. They include the control flow, time, and resource per- spective into one anomaly detection approach. They try to detect point, contextual, and collective anomalies. They also try dealing with unexpected events that might not indicate an anomaly. They propose to construct a likelihood graph, which represents the likelihood of the expected execution of events. Firstly, they create a basic likelihood graph with activities and their probabilities. Then they extend it with other perspectives. For detecting the anomaly, they compare the likeli- hood of the currently executing event with the likelihood of recorded comparable events based on the likelihood graph.

Baader and Krcmar [74] were also using process mining for fraud detection. Specifically, they present a method for reducing the number of false positives in this detection. They combine the red-flag approach and process mining for identification and visualization of possible undesired process instances. Potential frauds are identified and then visualized with the fuzzy miner. Their approach was compared to two other approaches, and they got a lower number of false positives. However, they detected over half fewer frauds than one chosen variant. They discuss that process mining gives several other advantages to a classical red flag approach, such as easier dashboard analysis and visualization.

In particular, Huda et al. [73] proposed a method for the identifi- cation of process-based frauds in a credit application. After discovering a process model, they perform conformance checking analysis to check how many events were skipped. Additionally, they also perform analy- ses from different angles, like performance, segregation of duty, and role analysis. Furthermore, they proposed ten attributes that can be used as an output of the log analysis. Based on the occurrences of violations in these attributes, the type of fraud can be obtained.

In this research direction, there is a clear motivation for easing the manual analysis and automation. Indeed, all approaches but one employed automated conformance checking. The remaining approach introduced a method for reducing the number of detected false posi- tives, making it easier for the person to analyze the rest manually [74]. Remarkably, the prevalent approach is the creation of a custom algo- rithm which is then used in the analysis itself. This fact might be caused by the specificity and variability of frauds that might exist, encouraging a further investigation in the area.

The most significant observation regarding the use of process min- ing for software reliability is a notable sparsity of research papers. It is despite the fact that the field was pointed out as appealing to study further [94]. The literature review also found an interesting trend concerning reliability-focused studies. The reliability is more frequently approached in processes involving humans [95], than critical software. Regarding the use cases of the reviewed papers, it is interesting that the majority of them focused on finding bugs or errors in general and not explicitly tackling the reliability of software systems. Also, the mod- els are primarily analyzed automatically. The reason for this approach is partly because the process mining techniques in the reviewed papers

In the classification of the papers, two main directions can be spotted, which divides them roughly in accordance with the software lifecycle, i.e. pre- and post-deployment. The dominant class is focusing on activities after the deployment like monitoring or maintenance. In comparison, the less frequent one is aiming to support quality assurance before the software is rolled out. Papers aimed at reliability in different contexts are very often focused on the human side of the issue, not software reliability as such, so they are not included in our literature review.

Table 2 contains all the identified research papers. It shows the direction in which the process mining is situated, the used process mining technique (process discovery, conformance checking, process enhancement), the main target period of the analysis, and whether the proposed technique needs expert knowledge. It also contains informa- tion about the type of model analysis: whether it is performed manually or automatically.

Error detection is the most prevalent domain when it comes to the application of process mining for software reliability. The prevalence might be caused by the fact that in the case of software reliability, au- thors seem to focus on generic methods and frameworks [80,82], with- out strict application-domain focus. On the other hand, some trends like service-oriented architectures [81], adaptive middleware [25], blockchain [83], or cloud [78], can be seen. Generally, the error de- tection direction is concerned with runtime behavior analysis to detect bugs in the implementation [25] or assisting the deployment [78], maintenance [79], and monitoring [82].

Service orientation is a topic of interest by van der Werf and Verbeek [81], who present the application of process mining for con- tinuous auditing of service behavior. The aim is to monitor violations of security requirements in support of configuration management. To this end, the authors present a tool that analyzes event logs from executions across the service landscape using semantic process mining, which combines process mining with semantic web techniques. A key concept is enabling relations between elements in the event log and other elements using annotation rules. The tool utilizes process mining to check conformance to defined constants. Concretely, reliability and security-related constraints are discussed.

Software design and runtime behavior, albeit in the case of adap- tive middleware, is considered by Rosa et al. [25], who presents a solution for its implementation and execution. Besides covering the basic requirements of adaptive middleware systems, the authors in- clude techniques for verification of their implementation. The process mining is used for runtime verification of behavioral properties of an implemented adaptive middleware system. The behavior is verified by conformance checking against its specification in LTL. In the case of undesired behavior, the proposed solution automatically creates and executes an adaptation that mitigates the issue. Thus, making the system more robust.

Detection of application failures is the topic of highly detailed work by Pecchia et al. [80]. The proposed approach consists of multiple steps that utilize different methods of process mining. The main ingredient of the approach is the application logs. Those are firstly used to construct a reference model capturing normal behavior using process discovery. Subsequently, the logs are used, possibly in real-time, for conformance checking against the reference model to discover failures in the application. The work is highly detailed in both implementation and evaluation. Furthermore, it considers the presence of noise in application logs.

Applications of process mining in the field of software maintenance are explored by Gupta [79]. The author presents four applications of process mining assisting in improving various processes. Concretely, management of software projects, ticket resolution, and software bug detection. The latter is highly relevant for increasing the overall reli- ability of the software at hand. In this case, two models are obtained by performing process-discovery algorithms based on execution logs — the current stable and the new software versions. The models are then compared for differences. However, the paper does not go into much detail about the actual technique used and serves more as an outline for future work.

The work by Xu et al. [78] presents an error detection method aimed at sporadic operations like software deployment. The specific use case presented in the paper is a rolling upgrade in a cloud environment. In order to achieve accurate detection, the method first creates a process model of the operation from regular, un-anomalous logs using process discovery. Afterward, the conformance checking is used as part of the analysis to determine if the process is running correctly. Here, process mining is just one step in a more sophisticated analysis.

Resilience monitoring of executable business processes, with the focus on time, is discussed by Zahoransky et al. [82]. The authors present a mathematical framework to define the notion of resilience in workflows. The main idea is to automatically extract the probability distribution of time characteristics of a given workflow. Process mining is used to obtain the time information from an event log, which is then used to calculate the probability distributions. The approach can be utilized to predict and monitor the resilience indicators of the executed workflow, possibly enacting timely countermeasures if the levels drop. Auditing, specifically aimed at blockchain smart contracts, is a focus of the work by Corradini et al. [83]. The authors devised a method that extracts the transaction logs, cluster them by the sender to create an event log in XES format, discovers a model, and analyzes it. Process mining, concretely the process discovery technique, is used in the third phase to generate three candidate models using different

algorithms. Out of the models, only one is chosen based on the quality characteristics. The resulting model is then used in the last step to find discrepancies with the specification. The conformance is assessed manually, with the hints to use model checking techniques.

In summary, the process mining techniques utilized for error de- tection focus on either analyzing the runtime behavior and providing assistance during operations. Overall, the trend inclines towards au- tomation, which seems to be the primary motivation apart from taking advantage of process events. In this regard, comparing previous and current behavior is a very appealing usage of process mining employed by [78,80]. Another trend is to use process mining to continuously check defined nominal behavior, as used by [25,81,82]. Still, the cover- age of application domains, leaving many possibilities for future work. Furthermore, while several approaches utilized artifacts from opera- tions, the area is not fully explored, for instance, cloud provisioning or continuous integration. Possible process mining utilization in software operations is provided by [79], but most presented cases are out of the scope for this review.

The topics in the quality assurance direction could be summarized as aiding the developers with software reliability before deployment. It focuses on identifying issues before the software is put into production. In this direction, both direct (validation and verification) and indirect (QA process) support is relevant. Papers within this typically aim at giving hints and pinpointing bugs [77] or outright generation of test cases [76]. The human-centric development aids, like [96] focusing on agile development, were only considered if the software product itself was part of the consideration.

Service-oriented design, namely the service substitution and its behavior, are explored by Sahl and van der Aalst [75]. The authors present a formal model that is describing the service behavior, as well as formal methods and an algorithm that enables correct substitution. The correctness is checked in both design-time and runtime. Process mining, more precisely conformance checking, is utilized in the former and is applied to ensure that the implementation of a service conforms to a contract and modeled behavior. Therefore, process mining aiding in bug detection and, as a consequence making the service implemen- tation more reliable. It is important to note that the method is focusing solely on functional behavior, not considering the non-functional one. The practically oriented work by Rubin et al. [77] outlines the possibilities of process mining applied to software projects. Here, the authors demonstrated two distinct use cases focusing on the analysis of software system using process discovery. In the context of this review, the first case is particularly interesting as it aims at detecting software defects during acceptance testing. The discovered model based on the software system logs is presented as a way for developers to pinpoint

Process mining principles are used by Lübke [76] for generating encapsulated bundles to contain and replicate a failure in a business process management system, outside of the production environment. The bundles, called Replication Test Cases, contain an isolated unit test that enables the reproduction of the failure without any dependen- cies. Therefore, developers can fix the issue more efficiently. For the generation of the bundles, the author proposed a specialized algorithm based on a process mining approach that utilizes both event logs and the reference process model.

A common trend in quality-assurance research direction utilizing process mining is to either minimize the introduction of bugs into soft- ware [75] or to diagnose them [76,77]. While quality assurance con- sists of many processes generating artifacts, they are not explored from a process mining perspective. For example, code reviews or analyzing changes in the codebase leaves space for future work. Furthermore, providing the developers with various process models could assist in software understanding and diagnosis, as proposed by [77].

Within our review, we have identified 35 approaches employing process mining in cybersecurity or software reliability, which we have structured according to the direction of the research problem they are addressing. These include the security of industrial control systems, security of smartphone devices, web-application security, network traf- fic security, attack inspection, outlier user behavior, fraud detection, error detection, and quality assurance. Although this division is by no means perfect, it gives a useful understanding at what research problems the process mining is directed in terms of cybersecurity and software reliability.

In the case of cybersecurity, the most popular research approaches (with the highest number of publications) were targeting general di- rection towards either detection of outlier user behavior or frauds. The next most popular direction was the cybersecurity of network elements, namely focusing on the applications related to networking in connection with websites, information systems, and other technologies that primarily communicate through networks. The research in the remaining directions is rather sparse.

The most popular research direction in the case of software relia- bility is the error detection. In this case, process mining is typically utilized to monitor runtime behavior in search of errors or abnormal behavior. Curiously, in the quality assurance research direction, the utilization is very similar, however focusing on aiding the development of the systems, rather than its operation and maintenance. Indeed, some outlier approaches can be found, like generating test cases. Overall, in software reliability, process mining is primarily used in a very narrow sense to detect faults, errors, and failures. The usage for analysis of reliability attributes is, barring one paper, unexplored.

Surprisingly, we did not discover a holistic approach combining both fields, as stressed by [2]. However, the work by van der Werf and Verbeek [81] contains features of both fields. For the rest of the papers, there are some significant similarities where researchers took analogous approaches across the fields. The most significant overlap lies in detecting various anomalous or undesired behavior, which shares a similar impact while having different root causes. Indeed, utilizing process mining to analyze behavior is a major strength of process mining. Additionally, process mining is utilized for inspection and diagnosis across the fields, focusing on attacks and errors, respectively. This hints towards similar techniques for general faults regardless of cause.

On the other hand, we noticed some differences regarding the use of process mining between the two fields. First and foremost, cyber- security seems to be more popular with more than twice the number of papers compared to software reliability. Furthermore, we found out that the application domains (e.g., smart grids, mobile devices, finan- cial systems) in the cybersecurity field are more diverse. In contrast, the distinguishing factor within software reliability is technology or platform.

Domains that are generally dominant in process mining fields in the general process mining realm were surprisingly not found among the results. Those domains include healthcare, manufacturing, education, finance, and logistics. Thus, we assume that in these domains, even though they are generally popular, the process mining techniques have not yet been properly explored for the purpose of cybersecurity or software reliability. Alternatively, they could be employing general domain non-specific techniques and thus not published mentioning a particular domain.

An exception to the claim is a paper, removed from the results due to the exclusion criterion on full paper. The work is dealing with software reliability in the healthcare domain. It is a short, workshop paper presenting potential filed and future research focus [97].

Regarding the analysis, the majority of the papers analyze the obtained model automatically, partly because the process mining tech- nique is very often used as a part of a more sophisticated method [57, 65]. It seems as automation is a motivation of numerous approaches [25,60,78]. However, there exist papers that utilize only manual anal- ysis based on the discovered model. In this case, the goal is to employ visual analytics to discover unexpected anomalies [22,59], or the pa- per [83] that presents an early stage of research where the analysis is not yet automated.

Specific techniques used in found approaches are in Table 4. From all 35 found approaches, seven papers do not specify all process mining techniques they use and six use their own custom algorithm. Only three from the specified techniques used declarative process mining approach.

The most popular technique for process discovery is fuzzy miner [33]. We assume that the reason is that it is configurable technique that can deal with unstructured processes and generate simplified process models, which is very desirable in cybersecurity and soft- ware reliability. However, similar technique with same advantages, heuristic miner [32], is not so popular. We think it is because of user- friendly analytical tools that support process discovery using fuzzy algorithm, e.g., Disco (which was used in the majority of found ap- proaches utilizing fuzzy miner). Some newer approaches used Python library PM4Py [100], created in 2019, which might indicate more

Research gaps and possible research directions can be observed in multiple aspects. First, there is a gap in the usage of process mining in cybersecurity and software reliability in several domains that otherwise do utilize process mining (for other applications), like healthcare, man- ufacturing, education, and logistics. Although we found some research papers focused on these areas, they were dealing with safety-critical processes involving humans and not computer systems [98,99], or just presented upcoming research direction [97]. Secondly, we detected a substantial untapped potential in the application of process mining within a larger context of cybersecurity and software reliability. Areas such as availability, robustness, or resilience are rather unexplored with respect to process mining, although they are implied in literature or applied in a non-IT field. In summary, and based on the found papers, we see a great potential of process mining for cybersecurity and software reliability. Daunting future directions could utilize the good practice from non-IT areas, where faults, anomalies, safety, or robustness of a process is evaluated.

Other possible research directions stem from how the process min- ing analysis is performed in the found papers, their motivation, and goals. For example, a frequent topic is a real-time analysis, where process mining is an ideal candidate. However, the existing approaches are almost always static and based on past events. Future work might improve this and focus more on real-time events, allowing for timely insights into possible cybersecurity and software reliability issues. Fre- quently also, the application of process mining is motivated by au- tomation or easing the manual analytical work. In this sense, we see a strong potential in automated detection and evaluation of non- standard, malicious, or faulting behavior of computer systems.

Finally, as the number of publications is very sparse, there are likely many uninvestigated use cases of process mining in cybersecurity and software reliability. Some of the use cases are pointed out in the discussion of respective research directions. Prime examples include analysis of software changes and behavior, as well as supporting the diagnosis of software issues (both malicious and non-malicious). It may be especially worthy of considering the process mining in critical infrastructures, as they need to be highly reliable and have a strong defense against cyberattacks, which might take advantage of seemingly minor vulnerabilities, yet combined into malicious processes. The pro- cess mining might be valuable in the analysis and diagnostics of already running or legacy systems. Specifically, the streaming-based process mining techniques [101,102] can be used in this regard.

For the evaluation of threats to validity, we followed the strategy by Zhou et al. [103] for systematic literature reviews. In this section, we assess the potential threats to validity and discuss the precautions that we used to mitigate them through our review. Concretely, the threats are grouped into four categories, i.e., construct, internal, external, and conclusion validity.

We chose six popular digital libraries that are believed to cover the majority of high-quality publications to establish a base collection of papers. To obtain as many papers as possible, we also used snowballing to reduce the possibility of missing relevant approaches. Furthermore, we divided the search and reasoning into two parts because the commu- nities of cybersecurity and software reliability might differ. Regardless of the division, the results of the searches have been combined and deduplicated for subsequent stages.

We divided the filtering of papers into multiple phases. Each phase was performed by a different researcher. In case of any doubts, the paper is marked and discussed with two more researchers to reach the consensus. To further avoid bias in filtering, a sample of 10%

papers filtered out in the first phase was double-checked by another researcher. In this review, we formulated a strategy to guide the re- view, which is based on the existing guideline for systematic literature reviews [53]. In the reliability search, we included all popular terms which are connected to the reliability and software dependability.

The search is limited to the up-to-date papers over the last six years, from 2014 to 2020. The primary motivation for the restriction to this period is to focus on the most recent research and applications. Secon- darily, we expected the more mature approaches among these recent publications. Lastly, the lower bound, the year 2014, also corresponds to a local peak in the number of publications within the Dimensions8 dataset, showing a slight change of trend.

To ensure the correctness of the extracted data, we formulated the strategy of this literature review and established categories of interest which had to be described for each relevant research paper. The popularity of identified domains was also cross-checked with more general reviews on process mining. Moreover, the interpretation of the data was extensively discussed. Despite our systematic approach, some trends, patterns, and research gaps could have been missed in the review. On the other hand, we believe that the value of the provided summary in this work is not primarily in the research gaps, but in overview of the existing body of knowledge in applying process mining in the area of cybersecurity and software reliability. In this way, we believe we can facilitate the understanding of what attempts exist so that it is easier for the reader to see where they can build on what is existing and where they need to start building their approach from scratch.

reliability. Primarily, we would encourage the research community to deeper investigate the domain of critical information infrastructures, which might benefit significantly from more advanced cybersecurity and software reliability techniques. The real-time analysis of systems has a strong potential to utilize the advantages of process mining techniques. Furthermore, it would be indeed beneficial in the advanced detection and prevention of cyberattacks and incidents, enhancing it with a process-oriented approach.

Yen T-F, Oprea A, Onarlioglu K, Leetham T, Robertson W, Juels A, Kirda E. Beehive: Large-scale log analysis for detecting suspicious activity in enterprise networks. In: Proceedings of the 29th annual computer security applica- tions conference. Acsac ’13, New York, NY, USA: Association for Computing Machinery; 2013, p. 199–208. http://dx.doi.org/10.1145/2523649.2523670.

Senator TE, Goldberg HG, Memory A, Young WT, Rees B, Pierce R, et al. Detecting insider threats in a real corporate database of computer usage activity. In Proceedings of the 19th acm sigkdd international conference on knowledge discovery and data mining, 2013, p. 1393–401.

Geyer-Klingeberg J, Nakladal J, Baldauf F, Veit F. Process mining and robotic process automation: A perfect match. In Proceedings of the dissertation award, demonstration, and industrial track at bpm 2018 co-located with 16th interna- tional conference on business process management (bpm 2018), Sydney, Australia, September 9-14, 2018, 2018, p. 124–31.

Švábenský V, Vykopal J, Čeleda P. What are cybersecurity education papers about? A systematic literature review of SIGCSE and ITiCSE conferences. In: Proceedings of the 51st acm technical symposium on computer science education. New York, NY, USA: Association for Computing Machinery; 2020,

Buhnova B, Chren S, Fabriková L. Failure data collection for reliability predic- tion models: A survey. In: Proceedings of the 10th international acm sigsoft conference on quality of software architectures. Qosa ’14, New York, NY, USA: Association for Computing Machinery; 2014, p. 83–92. http://dx.doi.org/10. 1145/2602576.2602586.

Compagna L, dos Santos DR, Ponta SE, Ranise S. Aegis: Automatic enforcement of security policies in workflow-driven web applications. In: Proceedings of the seventh acm on conference on data and application security and privacy. Codaspy ’17, New York, NY, USA: ACM; 2017, p. 321–8. http://dx.doi.org/10. 1145/3029806.3029813.

Macak M, Kruzikova A, Daubner L, Buhnova B. Simulation games platform for unintentional perpetrator attack vector identification. In: Proceedings of the ieee/acm 42nd international conference on software engineering workshops. Icsew’20, New York, NY, USA: Association for Computing Machinery; 2020, p. 222—229. http://dx.doi.org/10.1145/3387940.3391475.

Rubin VA, Mitsyuk AA, Lomazova IA, van der Aalst WMP. Process mining can be applied to software too!. In: Proceedings of the 8th acm/ieee international symposium on empirical software engineering and measurement. Esem ’14, New York, NY, USA: Association for Computing Machinery; 2014, http://dx.doi.org/ 10.1145/2652524.2652583.

Aalst Wvd. Big software on the run: In vivo software analytics based on process mining (keynote). In: Proceedings of the 2015 international conference on software and system process. Icssp 2015, New York, NY, USA: Association for Computing Machinery; 2015, p. 1–5. http://dx.doi.org/10.1145/2785592. 2785593.

