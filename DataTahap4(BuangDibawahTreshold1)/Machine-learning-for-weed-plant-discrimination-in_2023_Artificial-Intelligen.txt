features. The features included the shape and structure definition of the plants. The database was formed from seedling growth to two true leaves. Color images were taken from individual seedings. A plastic dif- fuser was used to prevent image overexposure. The images were then categorized using template matching, where each species was discrim- inated against based on template deformation against the optimal fit. Fig. 5 shows the model applied on weed images.

Ahmed et al. (2012) used the feature vector of shape, color, and mo- ment. An ML model was validated with 224 images consisting of chilli, pigweed, marsh herb, lamb's quarters, cogon grass, and bur cucumber. The authors noted that the method was dependent on a large number of images to ensure a more robust model. They also noted that plant holes and image noise affected the model.

Previous studies by other researchers have employed the reflection of light from plants to identify their types. This feature operates based on the color or spectral reflectance exhibited by the leaves. Remarkably, this technique can effectively identify the plant type even when there is partial occlusion of the plant. The unique cellular characteristics of a leaf lead to distinct responses when exposed to specific wavelengths of elec- tromagnetic waves. For example, there is a significant difference in NIR reflectance between dicotyledonous and monocotyledonous plants (Kim and Reid, 2006). Moreover, other than NIR, some authors have used visible waveband spectrum and water absorption waveband spec- trum as features (Kim and Reid, 2006; Hatfield and Pinter, 1993).

Woebbecke et al., 1995 proposed the use of color features in stan- dard color slide images to discriminate weeds from the soil. Light reflected from the leaves of the plants were captured and used for clas- sification based on the reflectance wavelength in red, NIR, green, and blue. Their system classified leaves from soybeans, giant foxtail, ivy leaf, morning-glory, and velvetleaf. Reflectances from the other edges of the leaves were used to compute mean, variance, and skewness which were used to determine the type of plant. They experimented with the classifier by either including or excluding leaf orientation in

the classifier. It was found that by excluding leaf orientation features, the classifier managed to obtain a higher classification rate than when including leaf orientation. The researchers also concluded that color im- ages could distinguish between plants and the background but were not sufficient to determine the plant species. It was noted that this tech- nique was affected by leaf orientation as the reflected wavelength changes with the orientation of the leaf.

Another example of using spectral feature for classifying carrots, cabbage, and weeds can be found in Hemming and Rath (2001). The classifier was based on weighted fuzzy classification. It was shown that color features could discriminate plants from the soil, and the clas- sifier showed an improvement in terms of classification accuracy when color features were used in addition to morphology features. Their method resulted in good classification rates depending on the growth and density of the weeds. They noted that this technique is susceptible to occluded leaves.

Spectral features have also been used in Feyaerts and Van Gool (2001). In particular, blue-NIR spectral was observed to discriminate sugar beet plants from weeds. It cannot be denied that crop and weed exhibit comparable spectral signatures. Therefore, Object-Based Image Analysis (OBIA) techniques can improve classification results (De Castro et al., 2018). OBIA works by segmenting images into clusters of neighboring pixels with similar spectral values, referred to as “objects.”

Texture features are defined as a collection of metrics used to quan- tify the apparent texture of an image. The texture provides information on the spatial arrangements of pixels in a region or the entire image. The metrics represent properties such as coarseness, smoothness, and regularity (Bakhshipour et al., 2017).

A texture may be considered as clusters of similarities in an image. There are four types of texture, namely statistical features, structural features, model-based features, and transformation-based features. Sta- tistical features involve calculating the local features of each point in the image, obtaining a collection of statistical data from the distribution of local features, and evaluating the spatial distribution of grey values. Sta- tistical moments are computed through the image or the region's inten- sity histogram, and the extracted information are sets of statistics that provide properties such as skewness, flatness, and contrast. The Grey Level Co-occurrence Matrix (GLCM) is a common approach for obtaining statistical characteristics (Haralick et al., 1973).

The structural texture is primarily described as a collection of well- defined texture components. The structural texture is defined by the characteristics and placement rules of texture components. Structural textures are rarely utilized in agricultural applications since they can only represent highly regular textures. The texture image is represented as a linear combination of a probability model or a collection of basis functions for model-based textures, and the model coefficients are uti- lized as texture features (Rallabandi and Sett, 2005).

Model-based texture characteristics, such as structural texture, are rarely utilized in the literature for plant recognition. The converted fea- tures are retrieved by converting the image into a new space where the coordinate system has a near interpretation of texture characteristics. For transformation-based features, curve and wavelet transformation are two commonly utilized transformation techniques (López- Granados, 2011). These transformations are typically carried out before the feature extraction process. The Fourier transform method is rarely utilized because of the lack of spatial location. Several wavelet families, including Haar and Gabor, have been utilized to detect specific novel characteristics that are difficult to describe in the spatial domain. Gabor filters improve spatial positioning approaches and have been uti- lized in a wide range of weed and crop recognition applications.

portions. GLCM was calculated based on the virtual signal following the Gabor filter, followed by a collection of GLCM-based features. In an- other study, Kumar and Prema (2016) used rotation-invariant wavelet features for weed identification. For acquiring these characteristics, the radon transform approach was used. It substantially lowered the number of characteristics and identified images in a variety of directions rapidly. The impact of rotation on the input and output images might be shown through Radon transform. The wavelet function was then used to split the Radon transform output into distinct sub-bands, and the tex- tural characteristics, such as energy and uniformity of each sub-band, were calculated. Curvelet transform decomposes the image at multiple sizes and angles, making feature extraction easier.

The authors in Ahmed et al. (2011) proposed an automated weed classification with LBP-based template matching. The study evaluated the feasibility of using LBP-based texture patterns to classify weed im- ages into broadleaf and grass categories. This is to note that the classifi- cation is of the entire image rather than pixel-level classification (i.e., classify the whole image rather than pixel-level labelling). The im- ages used were colored images comprised of 100 broadleafs and 100 grass weeds samples. LBP features were extracted from the images and were trained with two classifiers. The authors concluded that the rotation invariant LBP had strong discriminative abilities, given the correct parameter setting was chosen for LBP.

In the follow-up work, the authors in Ahmed et al. (2014) proposed using local pattern-based texture descriptors, which includes LBP for the classification of broadleaf and grass weeds. Again, the classification was of the entire image rather than pixel-level classification. The re- searchers experimented with three local texture operators with varying parameter configurations. From their findings, rotation invariant local patterns could provide stable performance in the presence of orienta- tion variations, illumination variations, image noise, and lower memory and computational cost compared with wavelet methods. The desirable characteristics saved considerable computational power as no prepro- cessing was needed for illumination normalisation and data augmenta- tion in terms of orientation. It showed that that LBP was able to achieve robust performance in uncontrolled natural environment.

The authors in Le et al. (2019) studied on combining multiple LBP features with a classifier to classify canola, corn maize, and radish. The images used were in a lab controlled environment, where only individ- ual plant species were captured at a given time without including other species. Similar to the previous, the classification was of the entire image rather than pixel-level classification. The authors suggested that in plant classification, the accuracy metric itself was not a sufficient in- dicator to determine its acceptable performance for plant classification. They suggested that the Precision, Recall, and F1-score metrics were suitable to validate the performance of the model for plant classification. From their findings, it was noticed that when visualising the texture fea- ture distribution, corn leaves' texture features were distinct compared to leaves of canola and radish. Their results showed that combining LBP features could achieve accuracy greater than 91% for corn, canola,

The authors in Samarajeewa et al. (2018) examined the identifica- tion of flower patches in the aerial images using two techniques, namely LBP classification and CIELAB color space threshold classification. In the paper, LBP set pixel intensity thresholds based on the surrounding envi- ronment, allowing high-intensity values to be displayed, effectively dis- tinguishing the plants from the background. The CIELAB threshold algorithm determined a threshold value for each RGB channel based on the histogram. Then, in both approaches, erosion was used to elimi- nate any remaining noise.

ML-based classifiers are coupled with various features to increase the accuracy of the system for precision agriculture. These traditional methods, once again, require to be designed on hand crafted features and are highly depended on the image quality, pre-processing, and learning algorithms. Advantages of ML-based techniques are advocated on grounds of small sample sizes required to train the system and low requirements on graphics processing units, thus, making agricultural machinery and equipment inexpensive. Traditional ML methods could give efficient performance in research, given the soil conditions and illu- mination remain the same throughout. These conditions make the real- time applications difficult to be implemented.

In this subsection, we elaborate several ML classification algorithms that are commonly used for crop/weed discrimination task, such as k- Nearest Neighbor (KNN) (Ahmad et al., 2011), Artificial Neural Net- works (ANNs) (Jeon et al., 2011), decision trees (Goel et al., 2003), and Support Vector Machine (SVM) (Shahbudin et al., 2017; Le et al., 2019). KNN belongs to a non-parametric algorithm, i.e., it does not have the knowledge of the data distribution (lazy learner). It works by calculating the distance (similarity) of a new data sample with its k neighbours. Following that, the new data sample will be classified to

ANN is an ML algorithm that is designed to mimic the principle of human brain. An ANN consists of layers of linked artificial neurons. The fundamental ANN structure is known as a perceptron. A perceptron works by receiving input signals, weighting and summing them. Subse- quently, it passes the sum to a nonlinear activation function to produce the output. ANN is trained to adjust the weights that minimize the dif- ference between the target output and the resulted output. The backpropagation algorithm is usually used to optimize the weights.

SVM is considered as a linear classifier. Suppose that we have two classes, SVM creates a hyperplane that optimally separates the two clas- ses. For multiclass classification problem, we can extend the concept by using Error-Correcting Output Coding (ECOC) with either One vs. All (OVA), One vs. One (OVO), Dense Random (DR), or Sparse Random (SR) configuration (Wong et al., 2021). If the data samples are not dis- tributed linearly, a kernel approach, such as the Radial Basis Function (RBF), can be employed to increase the dimension.

A decision tree is supervised ML algorithm with tree-like structure that can be used for both classification and regression. A decision tree consists of a root node, splitting nodes, branch/sub-tree nodes, decision nodes, and terminal nodes. Several algorithms have been used for build- ing the decision tree. In general, entropy measure is used to find the appropriate feature to split the data at each node of the tree.

Ensemble learning methods employ social learning behaviours like those observed in human social interactions, such as working in a group, receiving peer feedback, and voting before deciding. Working in a group allows each member to have various perspectives and repre- sentations of the data, which aids in getting a more reliable prediction (Kuncheva, 2014). As a result, ensemble learning approaches are intended to increase the prediction performance of a particular statisti- cal learner or model by combining basic base learners. An interesting characteristic of ensemble learning is that it encourages diversity among simple base learners (Bishop, 2006). Individual learners create independent errors; therefore, diversity would minimize the error gen- erated by the learners. There are several techniques for building an en- semble model. However, it has been discovered that utilizing various learning sets increases variety within the ensemble (Torres Sospedra et al., 2011).

While the notion of combining classifiers is not new, research into various combination techniques, features, classifiers, and innovative ap- plications is still ongoing. The authors in Fumera and Roli (2005) offered a theoretical and experimental study of linear combiners for multi- classifier models. Their study focused on basic and weighted averaging at the categorization decision level. The research revealed that the out- put of linear combinations was affected by the accuracy and correlation of the individual classifiers. Weighted averaging outperformed basic av- eraging, according to the data. Weight optimization for classifiers was still an unresolved issue. The authors suggested that future studies might involve the use of metaheuristic optimization techniques.

The authors in Kittler et al. (1998) presented a theoretical structure for classifier combinations that is universal. While the authors focused on ensembles with unique feature sets, in their comparable work (Kittler, 1998), both unique and common characteristics were investi- gated. It was created as a mathematical framework using the sum and product rules. The rules serve as the foundation for others, such as max- imum, minimum, median, and majority voting. Moreover, the authors ran extensive tests on the handwritten digits dataset. The sum rule outperformed other rules despite their most stringent assumptions. It demonstrates that the prediction error have a considerably less impact on the sum rule; hence, the theoretical paradigm established is consis- tent with their previous experimental results.

In the study of Torres-Sospedra and Nebot (2014), the authors utilized an ensemble of NN classifiers combined with noisy statistical characteristics of HSL (hue, saturation, brightness) color images in orange groves to classify weeds. Their implementation included boosting techniques and was tested on 130 images of orange trees with weeds, resulting in a good classification accuracy. The authors discovered that the ensemble is appropriate for weed detection with noisy characteristics. The authors in Ahmad et al. (2018) uti- lized AdaBoost with Nave Bayes, a boosted ensemble technique com- bined with statistical visual characteristics, to categorize wide and grass weed images in another study. Their technique correctly iden- tified 250 images with a classification accuracy ranging from 94.72% to 98.40%. The authors discovered that utilising ensemble techniques improved overall accuracy by 4.7% compared to using simply an individual classifier in difficult classification tasks such as weed classification.

uncertainty is not a novel concept. Around 200 years ago, Laplace offi- cially stated that he had demonstrated that the correct combination of two probabilistic techniques would produce better results than com- pared to only one (Laplace, 1820). Numerous methods have been devel- oped with the ensemble technique in combining various models, including aggregation, combination, committee, and fusion (Drucker et al., 1994; Lam and Suen, 1995; Kittler et al., 1998; Polikar et al., 2008).

DL algorithms use a large number of images to train and validate for recognition and classification. With further progress in computational power as well as the availability of data, DL algorithms have gained pop- ularity due to their capability to extract multidimensional and multiscale spatially essential information of crops and weeds using Convolutional Neural Networks (CNNs) (Dyrmann et al., 2016). The basis of CNN is a stack of convolutional layers which basically perform filtering process (Albawi et al., 2017). Each convolutional layer accepts input data, transform as required and transfers them to the next layer. The convolutional operation finally helps in simplifying the data for bet- ter processing and feature extraction.

In specific tasks like image classification and object detection and recognition, DL algorithms possess many advantages over conventional learning approaches. The disadvantages of the conventional human in- tervened feature extraction methods are usually overcome by its capa- bility of enhanced data expression by automated feature extraction. Recently, a lot of research articles on DL-based weed detection and clas- sification have been published.

As implicitly mentioned in the previous section, there are two types of weed-crop discrimiation approaches that are investigated: pixel- level (or pixel-wise) and image-wise classifications. This subsection mainly focuses on pixel-wise classification. In the pixel-wise classifica- tion, each pixel in an image is segmented and marked as weed or crop pixel. Pixel-wise approaches offer the advantage of being able to esti- mate the yield of each individual pixel. In applications that specifically require this level of information, using a pixel-wise implementation would be advantageous.

The authors in Di Cicco et al. (2017) used a pixel-wise classification CNN model SegNet. The SegNet model uses an encoder-decoder net- work structure and the fully connected layer is a softmax layer which enables pixel classification. The author used a synthetic dataset gener- ated by procedural generative model with real world plant textures in a virtual environment to train the classification model. The method was able to reduce efforts on manual pixel annotation of real world im- ages by a human. The synthetic dataset was used to train SegNet for crop-weed pixel classification and was able to achieve per-class average accuracy of 91.3%.

The authors in Haug and Ostermann (2015) proposed a plant classi- fication model without the use of segmentation. Often, in the agricul- ture field, crop and weeds grow too close together and overlapping is a common occurrence. Thus, the authors proposed the use of a Random Forest classifier with statistical features to classify pixels rather than segments. The classification of pixels eliminated the challenges which were associated with segmentation methods such as overlapping and complex background. The classifier was used to estimate the spatial pixel location based on features of overlapping neighborhood pixels. The model was further spatially smoothed with Markov Random Field. A sample of the prediction from this model is shown in Fig. 6. The model was able to achieve an average classification accuracy of 85.9% in the CWFID benchmark dataset on binary classification.

and color indices, were compared. In Sa et al. (2018), the authors pro- posed a method for dense semantic weed categorization using multi- spectral Micro Aerial Vehicle (MAV) images. In particular, the authors employed SegNet, a recently designed encoder-decoder cascaded CNN, to infer dense semantic classes in sugar beet and weed datasets.

In Bah et al. (2018), UAV images were collected and an attempt was made to classify into crop/weed pixels. Instead of manual annotation of pixels which is time consuming, the authors proposed an unsupervised approach. The procedure contains multiple steps. First, crop rows were detected to identify inter-row weeds. Inter-row weeds formed the training dataset in the second phase which was to distinguish from the weed. CNNs on this dataset were used to build a model which was able to detect the crop and the weeds in the images. The results ob- tained were comparable to those of traditional supervised training data labeling, with differences in accuracy of 1.5% in the spinach field and 6% in the bean field when compared with supervised approach (hand annotation).

Another category of DL algorithms is Recurrent Neural Networks (RNNs) (Hochreiter and Schmidhuber, 1997; Verma and Dubey, 2021). The feedback loop available in RNNs allows them to perform as an expert forecasting machine rather than recognition by CNNs. The networks try to make an influence of previous inputs in current inputs and outputs, which helps in increasing the overall performance. They provide a pixel-level classification for all the multispectral images avail- able. The generator in the network works in creating photo-realistic im- ages, aiming for extra training data.

Acquiring crop/weed images using UAV is not an easy task. Fortu- nately, there exist various public domain datasets that enable re- searchers to explore implementation of ML algorithm. We also divide the datasets into two types: segmentation and annotation. Due to the morphology of the plants, pixel-wise classification is more complex as they are mostly in green spectrum. Most of these datasets provide a logical mask to indicate if the referred pixel is weed or crop category.

For pixel-based implementation, dataset normally consist of several High Definition (HD) images in the order of 20–100 as the images can be divided into smaller sections for evaluations/training. For the annota- tion type, the object plants are segmented using green index. Subse- quently, the entire image can be categorized as either weed or crop. This category normally carries more images as most implementation applies some forms of DL approach such as CNN. The summary of the datasets is shown in Table 3.

The problem of identifying background from vegetation (crop or weed) is much more straightforward. However, this still presents a challenge. Agricultural scenes often have cluttered and textured back- grounds, which can interfere with the accurate segmentation of weed and crop regions. Shadows, soil variations, and other artifacts can ob- scure plant boundaries. Environmental conditions, such as soil type, hu- midity, and temperature, can affect plant appearances. Models trained in one environment may not generalize well to different conditions.

The key challenge in crop-weed classification for annotation- based techniques is the construction of the classification model and the optimization of the model parameters. The classifier model, like any other image classification issue, is created for specific applica- tions, and its parameters must be fine-tuned and optimized. Classi- fier optimization necessitates the use of several algorithms in order to attain a high classification rate while minimizing false positives and data overfitting.

Pixel-wise segmentation for weed–crop discrimination is also a challenging task. The most apparent is the high expense of resources and computation. Each pixel must be identified to either a crop or a weed pixel, which is a difficult task. This also has an impact on the anno- tation task for each pixel, which may result in incorrect annotation. It is also worth noting that the majority of agriculture segmentation takes use of UAV datasets. It is evident that weed pixels would be substan- tially smaller than crop pixels. This is known as a class imbalance situa- tion in machine learning. Models may become biassed in favour of the dominant class (crops), resulting in poor weed segmentation. Finally, we see that some weeds, in terms of color, texture, and shape, strongly resemble certain crops. Therefore, distinguishing between these visu- ally similar classes becomes challenging, especially when the plants are in early growth stages.

One essential to encouraging development is the use of edge devices rather than offline or cloud-based alternatives. High quality images can be difficult to create and store. The majority of the ideas presented here are computationally demanding and unsuitable for edge devices. More research work using techniques with reduced computation complexity or low energy consumption, such as FPGA-based approaches, may be in- cluded. Because the majority of these systems are linked to the Internet of Things (IoT), edge devices can further optimize data transmission and reduce the number of data packets delivered.

Various techniques employing ML have been investigated in this paper. We present an overview of crop and weed recognition or dis- criminating algorithms. The biggest problem is how the technology is used, followed by the ways used owing to crop and weed morphology. As a result, determining which techniques are preferable on a “apple-to- apple” basis is extremely challenging. In this regard, stakeholders may consider implementing ways that are most comparable in order to ben- efit from proven outcomes. We expect that this paper may give a com- plete overview of crop-weed detection in Agriculture 5.0 point of view.

Mróz, M., Sobieraj, A., 2004. Comparison of several vegetation indices calculated on the basis of a seasonal spot xs time series, and their suitability for land cover and agricul- tural crop identification. Technical Report. University of Warmia and Mazury in Olsz- tyn.

