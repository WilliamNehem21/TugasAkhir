Moreover, computer vision has recently played a vital role in en- abling the digital world to interact with the physical world. In general, the technology exploits cameras coupled with computer, rather than the human eyes, to identify, track, and estimate targets for image pro- cessing. It plays a critical role in technology by powering object detec- tion, classification, and tracking of objects in all domains. Recently, smart agriculture tasks (Neupane and Baysal-Gurel, 2021) that include plant ailment detection, weed detection, crop yield prediction, identifi- cation of plant species, are achieved through computer vision technology.

UAVs are recently taking up considerably space in research domain so as to make the industry less labor-intensive. Applications of com- puter vision to drone technology makes it be able to interpret and inter- act with surroundings, including buildings, trees, and diverse terrain. The use of data from UAVs for farming applications has been gaining an enormous popularity in both research and industry. Compared to human-based monitoring, UAV is considered to be cheaper and more convenient with shorter inspection time needed. The optimal control of the UAV in the presence of obstacles is commendable, which is a crit- ical factor while working with two crop rows.

In general, weeds hinder the movement of irrigation water, disrupt the process of applying pesticides, and serve as a breeding ground for pathogens. Thus, weed detection and control play a vital role in overall crop productivity and farming expenses. Effective weed control plays a crucial role in agriculture by minimizing crop yields, dramatically esca- lating production costs, negatively impacting crops, and significantly compromising product quality. Note that weeds compete with produc- tive crops for essential resources such as water, nutrients, and light, thereby diminishing overall agricultural output.

Traditional weed management methods include chemical means i.e., uniform application of herbicides throughout the field using me- chanical means or physical elimination. The former method leads to the overuse of chemicals as the weed spatial density varies across the field which ends up in environmental apprehension and formation of herbicide-resistant weeds. The latter results in labor intensive farming methods in turn causing a steep increase in production cost. The above issues can be solved by applying concept of Site-Specific Weed Management (SSWM) (Lati et al., 2021). SSWM involves detection of patches of weeds across the field and carrying out spot spraying or me- chanical removal ways which can be broadly classified into two catego- ries: 1) prescription maps-based methods (De Castro et al., 2018) where the areas of weed emergence are detected to focus the application of weedicide, and 2) real time monitoring method (Xu et al., 2018) that simultaneously detects and controls weeds by spraying weedicide on the spot.

Existing techniques for image processing provide extremely promis- ing outcomes under optimal imaging conditions, even though they can be quite challenging under real time conditions. The overlap of plant leaves and weeds at different stages of growth makes them synony- mous to each other. In addition, the leaves are often occluded, discol- ored or damaged by undesired materials which alter the morphological as well as spectral characters of the leaves. As the light- ing conditions change during different times in a day, the shadows formed by the plant canopy and the solar inclination can directly impact the colour of vegetation. Furthermore, different plant growth stages also result in variations of the morphological, textural, and spectral attri- butes to leaves.

This paper focuses on the discrimination between crop and weed using ML approaches. Note that traditional image processing techniques like Hough transform can also be used to discriminate crop and weed (Bah et al., 2017). However, these approaches are not of our interest. In- stead, we commonly use image processing techniques to extract the features like color, shape, etc. to be fed to the ML algorithms. The effi- ciency of these methods mostly depends on the manually designed fea- tures and have high dependence on image acquisition methods, pre- processing methods, and the standard of features extracted. Earlier studies in this category primarily used color co-occurrence matrix- based texture analysis for images (Chang et al., 2012). With

On the other hand, a hyperspectral sensor may provide hundreds or thousands of bands. A MicroHyperspec sensor which captures images using 325 bands in the visible band and NIR band was used in Lu et al. (2019). In the paper, it is also said that hyperspectral images were in limited supply. In terms of the vegetation properties estimation, the au- thors concluded that hyperspectral images produced a comparable per- formance compared with the multispectral images.

The quality of captured images is influenced by various environmen- tal factors, including lighting conditions (such as day time, night time, and shadows) and humidity levels (wet vs dry crops) (Jakubczyk et al., 2023). In Manea and Calin (2015), it has been clearly proved that illumination conditions plays an important role for determining the quality of the images. High light intensity leads to a loss of informa- tion, while low light intensity introduces dark current noise. Further- more, the quality of images captured using line-scan method is affected by the attitude and position changes of the UAV (Xue et al., 2021).

According to the bands, VIs can be categorized into VIs without infra- red channels (RGB) and with infrared channels (RGB + NIR/MIR). Ac- cording to the method of obtaining the mathematical formula, VIs can be categorized into first and second generation (Bannari et al., 1995). First generation VIs are obtained using empirical method without

Ahmed et al. (2012) used the feature vector of shape, color, and mo- ment. An ML model was validated with 224 images consisting of chilli, pigweed, marsh herb, lamb's quarters, cogon grass, and bur cucumber. The authors noted that the method was dependent on a large number of images to ensure a more robust model. They also noted that plant holes and image noise affected the model.

Previous studies by other researchers have employed the reflection of light from plants to identify their types. This feature operates based on the color or spectral reflectance exhibited by the leaves. Remarkably, this technique can effectively identify the plant type even when there is partial occlusion of the plant. The unique cellular characteristics of a leaf lead to distinct responses when exposed to specific wavelengths of elec- tromagnetic waves. For example, there is a significant difference in NIR reflectance between dicotyledonous and monocotyledonous plants (Kim and Reid, 2006). Moreover, other than NIR, some authors have used visible waveband spectrum and water absorption waveband spec- trum as features (Kim and Reid, 2006; Hatfield and Pinter, 1993).

Woebbecke et al., 1995 proposed the use of color features in stan- dard color slide images to discriminate weeds from the soil. Light reflected from the leaves of the plants were captured and used for clas- sification based on the reflectance wavelength in red, NIR, green, and blue. Their system classified leaves from soybeans, giant foxtail, ivy leaf, morning-glory, and velvetleaf. Reflectances from the other edges of the leaves were used to compute mean, variance, and skewness which were used to determine the type of plant. They experimented with the classifier by either including or excluding leaf orientation in

the classifier. It was found that by excluding leaf orientation features, the classifier managed to obtain a higher classification rate than when including leaf orientation. The researchers also concluded that color im- ages could distinguish between plants and the background but were not sufficient to determine the plant species. It was noted that this tech- nique was affected by leaf orientation as the reflected wavelength changes with the orientation of the leaf.

Another example of using spectral feature for classifying carrots, cabbage, and weeds can be found in Hemming and Rath (2001). The classifier was based on weighted fuzzy classification. It was shown that color features could discriminate plants from the soil, and the clas- sifier showed an improvement in terms of classification accuracy when color features were used in addition to morphology features. Their method resulted in good classification rates depending on the growth and density of the weeds. They noted that this technique is susceptible to occluded leaves.

Texture features are defined as a collection of metrics used to quan- tify the apparent texture of an image. The texture provides information on the spatial arrangements of pixels in a region or the entire image. The metrics represent properties such as coarseness, smoothness, and regularity (Bakhshipour et al., 2017).

A texture may be considered as clusters of similarities in an image. There are four types of texture, namely statistical features, structural features, model-based features, and transformation-based features. Sta- tistical features involve calculating the local features of each point in the image, obtaining a collection of statistical data from the distribution of local features, and evaluating the spatial distribution of grey values. Sta- tistical moments are computed through the image or the region's inten- sity histogram, and the extracted information are sets of statistics that provide properties such as skewness, flatness, and contrast. The Grey Level Co-occurrence Matrix (GLCM) is a common approach for obtaining statistical characteristics (Haralick et al., 1973).

The structural texture is primarily described as a collection of well- defined texture components. The structural texture is defined by the characteristics and placement rules of texture components. Structural textures are rarely utilized in agricultural applications since they can only represent highly regular textures. The texture image is represented as a linear combination of a probability model or a collection of basis functions for model-based textures, and the model coefficients are uti- lized as texture features (Rallabandi and Sett, 2005).

portions. GLCM was calculated based on the virtual signal following the Gabor filter, followed by a collection of GLCM-based features. In an- other study, Kumar and Prema (2016) used rotation-invariant wavelet features for weed identification. For acquiring these characteristics, the radon transform approach was used. It substantially lowered the number of characteristics and identified images in a variety of directions rapidly. The impact of rotation on the input and output images might be shown through Radon transform. The wavelet function was then used to split the Radon transform output into distinct sub-bands, and the tex- tural characteristics, such as energy and uniformity of each sub-band, were calculated. Curvelet transform decomposes the image at multiple sizes and angles, making feature extraction easier.

The authors in Ahmed et al. (2011) proposed an automated weed classification with LBP-based template matching. The study evaluated the feasibility of using LBP-based texture patterns to classify weed im- ages into broadleaf and grass categories. This is to note that the classifi- cation is of the entire image rather than pixel-level classification (i.e., classify the whole image rather than pixel-level labelling). The im- ages used were colored images comprised of 100 broadleafs and 100 grass weeds samples. LBP features were extracted from the images and were trained with two classifiers. The authors concluded that the rotation invariant LBP had strong discriminative abilities, given the correct parameter setting was chosen for LBP.

The authors in Samarajeewa et al. (2018) examined the identifica- tion of flower patches in the aerial images using two techniques, namely LBP classification and CIELAB color space threshold classification. In the paper, LBP set pixel intensity thresholds based on the surrounding envi- ronment, allowing high-intensity values to be displayed, effectively dis- tinguishing the plants from the background. The CIELAB threshold algorithm determined a threshold value for each RGB channel based on the histogram. Then, in both approaches, erosion was used to elimi- nate any remaining noise.

In this subsection, we elaborate several ML classification algorithms that are commonly used for crop/weed discrimination task, such as k- Nearest Neighbor (KNN) (Ahmad et al., 2011), Artificial Neural Net- works (ANNs) (Jeon et al., 2011), decision trees (Goel et al., 2003), and Support Vector Machine (SVM) (Shahbudin et al., 2017; Le et al., 2019). KNN belongs to a non-parametric algorithm, i.e., it does not have the knowledge of the data distribution (lazy learner). It works by calculating the distance (similarity) of a new data sample with its k neighbours. Following that, the new data sample will be classified to

ANN is an ML algorithm that is designed to mimic the principle of human brain. An ANN consists of layers of linked artificial neurons. The fundamental ANN structure is known as a perceptron. A perceptron works by receiving input signals, weighting and summing them. Subse- quently, it passes the sum to a nonlinear activation function to produce the output. ANN is trained to adjust the weights that minimize the dif- ference between the target output and the resulted output. The backpropagation algorithm is usually used to optimize the weights.

A decision tree is supervised ML algorithm with tree-like structure that can be used for both classification and regression. A decision tree consists of a root node, splitting nodes, branch/sub-tree nodes, decision nodes, and terminal nodes. Several algorithms have been used for build- ing the decision tree. In general, entropy measure is used to find the appropriate feature to split the data at each node of the tree.

Ensemble learning methods employ social learning behaviours like those observed in human social interactions, such as working in a group, receiving peer feedback, and voting before deciding. Working in a group allows each member to have various perspectives and repre- sentations of the data, which aids in getting a more reliable prediction (Kuncheva, 2014). As a result, ensemble learning approaches are intended to increase the prediction performance of a particular statisti- cal learner or model by combining basic base learners. An interesting characteristic of ensemble learning is that it encourages diversity among simple base learners (Bishop, 2006). Individual learners create independent errors; therefore, diversity would minimize the error gen- erated by the learners. There are several techniques for building an en- semble model. However, it has been discovered that utilizing various learning sets increases variety within the ensemble (Torres Sospedra et al., 2011).

While the notion of combining classifiers is not new, research into various combination techniques, features, classifiers, and innovative ap- plications is still ongoing. The authors in Fumera and Roli (2005) offered a theoretical and experimental study of linear combiners for multi- classifier models. Their study focused on basic and weighted averaging at the categorization decision level. The research revealed that the out- put of linear combinations was affected by the accuracy and correlation of the individual classifiers. Weighted averaging outperformed basic av- eraging, according to the data. Weight optimization for classifiers was still an unresolved issue. The authors suggested that future studies might involve the use of metaheuristic optimization techniques.

The authors in Kittler et al. (1998) presented a theoretical structure for classifier combinations that is universal. While the authors focused on ensembles with unique feature sets, in their comparable work (Kittler, 1998), both unique and common characteristics were investi- gated. It was created as a mathematical framework using the sum and product rules. The rules serve as the foundation for others, such as max- imum, minimum, median, and majority voting. Moreover, the authors ran extensive tests on the handwritten digits dataset. The sum rule outperformed other rules despite their most stringent assumptions. It demonstrates that the prediction error have a considerably less impact on the sum rule; hence, the theoretical paradigm established is consis- tent with their previous experimental results.

In the study of Torres-Sospedra and Nebot (2014), the authors utilized an ensemble of NN classifiers combined with noisy statistical characteristics of HSL (hue, saturation, brightness) color images in orange groves to classify weeds. Their implementation included boosting techniques and was tested on 130 images of orange trees with weeds, resulting in a good classification accuracy. The authors discovered that the ensemble is appropriate for weed detection with noisy characteristics. The authors in Ahmad et al. (2018) uti- lized AdaBoost with Nave Bayes, a boosted ensemble technique com- bined with statistical visual characteristics, to categorize wide and grass weed images in another study. Their technique correctly iden- tified 250 images with a classification accuracy ranging from 94.72% to 98.40%. The authors discovered that utilising ensemble techniques improved overall accuracy by 4.7% compared to using simply an individual classifier in difficult classification tasks such as weed classification.

uncertainty is not a novel concept. Around 200 years ago, Laplace offi- cially stated that he had demonstrated that the correct combination of two probabilistic techniques would produce better results than com- pared to only one (Laplace, 1820). Numerous methods have been devel- oped with the ensemble technique in combining various models, including aggregation, combination, committee, and fusion (Drucker et al., 1994; Lam and Suen, 1995; Kittler et al., 1998; Polikar et al., 2008).

In specific tasks like image classification and object detection and recognition, DL algorithms possess many advantages over conventional learning approaches. The disadvantages of the conventional human in- tervened feature extraction methods are usually overcome by its capa- bility of enhanced data expression by automated feature extraction. Recently, a lot of research articles on DL-based weed detection and clas- sification have been published.

The authors in Di Cicco et al. (2017) used a pixel-wise classification CNN model SegNet. The SegNet model uses an encoder-decoder net- work structure and the fully connected layer is a softmax layer which enables pixel classification. The author used a synthetic dataset gener- ated by procedural generative model with real world plant textures in a virtual environment to train the classification model. The method was able to reduce efforts on manual pixel annotation of real world im- ages by a human. The synthetic dataset was used to train SegNet for crop-weed pixel classification and was able to achieve per-class average accuracy of 91.3%.

and color indices, were compared. In Sa et al. (2018), the authors pro- posed a method for dense semantic weed categorization using multi- spectral Micro Aerial Vehicle (MAV) images. In particular, the authors employed SegNet, a recently designed encoder-decoder cascaded CNN, to infer dense semantic classes in sugar beet and weed datasets.

In Bah et al. (2018), UAV images were collected and an attempt was made to classify into crop/weed pixels. Instead of manual annotation of pixels which is time consuming, the authors proposed an unsupervised approach. The procedure contains multiple steps. First, crop rows were detected to identify inter-row weeds. Inter-row weeds formed the training dataset in the second phase which was to distinguish from the weed. CNNs on this dataset were used to build a model which was able to detect the crop and the weeds in the images. The results ob- tained were comparable to those of traditional supervised training data labeling, with differences in accuracy of 1.5% in the spinach field and 6% in the bean field when compared with supervised approach (hand annotation).

Another category of DL algorithms is Recurrent Neural Networks (RNNs) (Hochreiter and Schmidhuber, 1997; Verma and Dubey, 2021). The feedback loop available in RNNs allows them to perform as an expert forecasting machine rather than recognition by CNNs. The networks try to make an influence of previous inputs in current inputs and outputs, which helps in increasing the overall performance. They provide a pixel-level classification for all the multispectral images avail- able. The generator in the network works in creating photo-realistic im- ages, aiming for extra training data.

Acquiring crop/weed images using UAV is not an easy task. Fortu- nately, there exist various public domain datasets that enable re- searchers to explore implementation of ML algorithm. We also divide the datasets into two types: segmentation and annotation. Due to the morphology of the plants, pixel-wise classification is more complex as they are mostly in green spectrum. Most of these datasets provide a logical mask to indicate if the referred pixel is weed or crop category.

The problem of identifying background from vegetation (crop or weed) is much more straightforward. However, this still presents a challenge. Agricultural scenes often have cluttered and textured back- grounds, which can interfere with the accurate segmentation of weed and crop regions. Shadows, soil variations, and other artifacts can ob- scure plant boundaries. Environmental conditions, such as soil type, hu- midity, and temperature, can affect plant appearances. Models trained in one environment may not generalize well to different conditions.

The key challenge in crop-weed classification for annotation- based techniques is the construction of the classification model and the optimization of the model parameters. The classifier model, like any other image classification issue, is created for specific applica- tions, and its parameters must be fine-tuned and optimized. Classi- fier optimization necessitates the use of several algorithms in order to attain a high classification rate while minimizing false positives and data overfitting.

