Modeling or approximating high dimensional, computationally-expensive problems faces an exponentially increasing difficulty, the “curse of dimensionality”. This paper proposes a new form of high dimensional model representation (HDMR) by utilizing the support vector regression (SVR), termed as adaptive SVR-HMDR, to conquer this dilemma. The proposed model could reveal explicit correlations among different input variables of the underlying function which is unknown or expensive for computation. Taking advantage of HDMR's hierarchical structure, it could alleviate the exponential increasing difficulty, and gain satisfying accuracy with small set of samples by SVR. Numerical examples of different dimensionality are given to illustrate the principle, procedure and performance of SVR-HDMR.

In many science and engineering areas, computation tools such as computational fluid dynamics and finite element analysis are frequently applied to solve practical design problems. These problems are usually hard to handle due to their unaffordable computation cost. So metamodeling technique which approximates the original model was developed to reduce the computation cost. The process of constructing a metamodel is called metamodeling (Wang and Shan, 2007). In the past decades metamodeling techniques such as RBF, polynomial regression and Kriging had been successfully applied. However, these techniques are facing with a lot of challenges which mainly come from high dimensionality of problems. The computational cost of metamodel increases exponentially with the growing of dimensionality of underlying problems, and this phenomenon is publicly known as “curse of dimensionality”.

This paper is organized as follows; Section 2 introduces theoretical bases including HDMR and SVR. Section 3 proposed the new adaptive SVR-HDMR method. In section 4, the proposed SVR-HDMR method was tested by two nonlinear problems. Summary are given in section 5.

HDMR provides a hierarchical, correlated function expansion of a mathematical structure of the response and terms of this structure could be evaluated independently. The very essence of HDMR(Rabitz and Alis, 1999; Li et al.,, 2001; Rabitz and Alis, 1999;Rabitz,2003) is that, from the point of the output/response, the order of the functional correlations between the statistically independent variables will vanish rapidly (Chowdhury and Rao, 2009). It is because that for most well-defined physical systems, only lower order correlations of the input variables are expected to have a significant effect on the overall response (Rabitz and Alis, 1999). This is where HDMR can reduce computational scale of mapping relationships between input variables and output/response of high dimensional, complex systems.

where f0 is a constant value representing the zeroth-order component function or the average value of f(x). The function fi(xi) is a first order component term representing the contribution of variable xi alone to the output/response f(x), and its' linearity depends on the essential of the physical model. The function fi,j(xi,xj)is a second order component term expressing co-operative contribution of variable xi and variable xj to the output/response f(x). And the last term f1,2,…,N (x1,x2,…xN) represents any residual dependence of all the variables worked together in a co-operative way to act on the output/response f(x).

After properly constructing and expressing all of the component functions in Eq.(1), we can constitute HDMR with these component functions, and replace the original computational-expensive way in calculating the ouput/response f(x). The maximum number of component functions of the HDMR expansion is 2N (N is the dimensionality of variable vector x). As it is mentioned previously that for the most well-defined physical systems, higher order correlation can be neglected (Rabitz et al., 1999), and only lower order component functions are left, this would greatly improve the convergence speed while keeping an acceptable accuracy of the result. A few of computational studies (Wang et al., 1999) have shown that the HDMR expansions up to second-order are often sufficient to describe realistic systems.

Apparently the highest order of the cut-HDMR expansion has an influence on the computation cost of the cut-HDMR. A lot of metamodeling methods have been developed under the frame of the cut-HDMR, but some accompanying sampling method is still not available. In this work, we use the SVR to construct the component functions of HDMR.

Support vector machine (SVM) was first introduced by Vapnik(Vapnik, 1995) for classification of problems. It aims to explore the optimal hyper-plane by solving a linearly constrained quadratic programming problem. Then SVM has been extended to solve nonlinear regression approximation problems with the introduction of -insensitive loss function, which is named as support vector regression (SVR). The SVR method can approximate the underlying functions with a small subset of sample points while assuring a tolerance of epsilon band. Details of SVR are available in (Vapnik, 1995). And we can get the nonlinear SVR model in Eq. (7).

In the metamodeling processes, characteristics and structures of the underlying function might be unknown, especially for black-box problems. Traditional metamodeling methods do not present satisfactory efficiency while providing approving accuracy. The new SVR-HDMR takes the advantage of the hierarchical structure of HDMR and utilizes SVR to construct component functions of the HDMR.

Eq.(12) presents the structure of SVR-HDMR, where correlation among the input variables in the underlying functions is presented with a finite number of terms. The new method can approximate underlying functions with any kind of characteristics in the global input variable space. Now that in many occasions, a HDMR expansion up to second order would be sufficient to describe the original model, SVR-HDMR can be truncated as follows;

Check the linearity of the first order component function ƒi (xi ) constructed in step 2. If ƒi (xi ) goes through the cut point c, it is considered as linear, and the construction of the i-th function is completed. Otherwise, select a value that is different from the values chosen previously along the i-th axis, and reconstruct the i-th function using SVR. Then a new random value along the i-th axis is used to test the convergence of the constructed function, if the function is converged, terminate the i-th function construction. Otherwise, conduct step 3 until all first order functions are converged.

Compared with traditional metamodeling method like polynomial regression (PR), Kriging (KG) and RBF, the adaptive SVR-HDMR method has been tested with a three dimensional function and a ten dimensional function as table1. We firstly construct two second order adaptive SVR-HDMR models for the two test functions, and then construct PR, KG and RBF models for the two test functions. Finally we use another 9 and 30 samples which are generated by Latin hypercube method to test those constructed models respectively. Performances of these methods are evaluated by relative absolute error

For both two functions, we use a three-order polynomial kernel for SVR, and there are three sampled values on each axis. Computation results are shown in table 2. Number of function evaluations relates to the cost of constructing a metamodel. In 3-D problem, although SVR-HDMR model is a little less accurate than the PR model, it is computationally more efficient. It is also seen that the proposed method is much more accurate than the KG model and RBF model, while requiring the same computation effort. In the 10-D problem, SVR-HDMR model is more accurate than the other models, and it also needs less computation effort, which confines that the proposed adaptive SVR-HDMR method is cost-effective compared with traditional techniques for high dimensional problems. Through these two problems, it shows that the proposed adaptive SVR-HDMR method is very effective in dealing with high dimensional problems.

This paper proposes a new HDMR metamodel construction method, which combined the hierarchical structure of HDMR and the explicitly of SVR. The SVR-HDMR metamodeling technique could automatically reveal an explicit expression of the underlying function and correlations among the input variables; it needs no prior information about the underlying function. The selection of the cut-point does not influence accuracy of the constructed model. By inheriting HDMR's hierarchical structure and reusing of sampled values, the proposed method can greatly reduce the computation cost, while ensuring the accuracy of the results. We have successfully applied adaptive SVR-HDMR to the ZK5540 machine tool structure optimization design for Wuhan Heavy Machine Tool Group. Future work would be concentrated on developing proper sampling method and more applications in engineering practice.

