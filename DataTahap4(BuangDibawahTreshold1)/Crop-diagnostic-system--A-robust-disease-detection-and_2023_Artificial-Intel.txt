4.0 system. It consists of six concepts: Consumer Product, Ambient Envi- ronment, Contextual Data, Production System, Product Quality, and Pro- duction Facility. In this study, two classes, ‘Consumer Product’ and ‘Product Quality’ are used for knowledge extraction. The ‘Consumer Product’ class provides an abstract view of the type, growth status,

attributes related to pathology (crop diseases, causes, and the ways and means by which these can be managed or controlled) and morphol- ogy (canopy dimensions such as area, length, width, etc.). Four crops: lettuce, basil, parsley, and spinach, are considered in this study. Their growth conditions and morphological and pathological attributes stored as instances of the respective classes are extracted once the crop and disease are classified. Fig. 5 shows the hierarchical architecture of the ‘Consumer Product’ and ‘Product Quality’ classes with their instances for the ‘Basil’ crop in Protégé6 (an open-source ontology editor and framework developed at Stanford University) environment.

The trained model of the crop disease detection system is then saved and deployed on a cloud-based application built on Streamlit. The ontol- ogy model ‘AquaONT’ is also deployed on application, and relevant clas- ses are integrated with the final disease detection model through Owlready2 library. The layout of the application is shown in Fig. 6. It consists of two user inputs ‘Select Model’ and ‘Upload Image’. ‘Select Model’ provides an option to select the model as per requirement, which in this study are ‘Crop Classification’ referring to phase 1, ‘Disease or No Disease’ referring to phase 2, and ‘Disease Type, causes and Treat- ments’ referring to phase 3 of the proposed disease detection system.

After model selection, an image is uploaded which is used by all the models. Once the disease is detected and classified, the causes and treat- ments of the disease are extracted from the ontology model automati- cally and displayed on the application panel. This kind of information is useful as it will allow agricultural practitioners to determine the causes of diseases and take precautionary steps in the early stages to avoid crop wastage and economic loss.

This section presents the results of experiments performed in the current research work. First, the performance evaluation of deep learn- ing models in three phases of the disease detection system is discussed. Next, the trained and validated system is tested on new data. In the end, the significance of the complete system is presented.

The performance of the classification model in phase 1 is evalu- ated using a validation dataset. For this phase, there are four classes to be classified, namely lettuce, basil, spinach, and parsley. The distri- bution of labeled images in the validation set for this model is shown in Table 3.

The performance of the model is presented in the form of a confu- sion matrix (CM) shown in Fig. 7. The overall accuracy, precision, recall, and F-measure are computed by using the respective formulae, follow- ing common metrics for the performance of deep learning models in the literature (Khan et al., 2022). The computed metrics are summarized in Table 4.

The classification model in phase 1 has achieved an overall accuracy of 95.83%, average precision of 96.25%, average recall of 96%, and aver- age F1-score of 96.25%. As noted in Table 4, the performance metrics of the ‘spinach’ class are lower than the other classes. Most model con- fusion comes in between spinach, basil, and lettuce leaves, particularly during the initial stages of their growth cycle.

The classification model in phase 2 has achieved an overall accuracy of 94.13%, average precision of 94%, average recall of 94%, and average F1-score of 93.6%. It can be observed from the CM in Fig. 8 that the model is also prone to confusion in distinguishing between some of the classes. For instance, six examples of LD (Lettuce-Diseased) are clas- sified among LH (1), BD (1), SH (2), and SD (2). This might be due to a lack of clarity in identifying leaf patterns and diseased spots.

Finally, the performance of selected models for the detection phase (phase 3) is evaluated using a validation dataset. For this phase, there are six different diseases that models have to detect in crop leaves. These six diseases and their distribution in the validation dataset are given in Table 7.

The performance evaluations of models in three phases have shown that detection models are not as straightforward as classification models. This is because an image consists of many objects which belong to either the same class or different classes. Hence, three things must be verified during evaluation, including object class, bounding box (object location), and confidence.

detection speed of 52.8 FPS (frames per second) is faster than Faster- RCNN with a detection speed of 43.2 FPS. Moreover, it is also observed that YOLOv5s accurately detect objects of varying sizes with little to no overlapping boxes. All the comparisons between the two detection models show that YOLOv5s have a clear advantage in terms of accuracy and run speed. Therefore, in this study, YOLOv5s is used for developing the disease detection system.

After training and validation, the final crop disease detection system with YOLOv5s is tested using the test set containing new images. The system has shown promising results by effectively classifying and de- tecting the diseases in specified crops, which shows the system's ro- bustness in terms of dealing with a variety of objects having different shapes, patterns, textures, and colors. Fig. 9 shows examples where the system has accurately classified the crop and detected the diseased

and healthy spots in crop leaves. Images in the first row of Fig. 9 are the results from three phases of the disease detection system for the Lettuce crop, which is suffering from Bacterial Leaf Spot disease. Similarly, row 2 and row 3 are the results from three phases of the system showing Spin- ach and Parsley, respectively, and the diseases they are suffering from, such as Downy Mildew and Septoria Leaf Spot disease respectively.

The final crop disease detection system is then deployed on a cloud- based application developed in section 3.5. Fig. 6 shows the layout of the application. The ontology model discussed in section 3.4 is also inte- grated with the final system to build a complete real-time crop diagnos- tic system. The images are acquired wirelessly from the aquaponics facility through an interface developed on the Google Cloud Platform

by the authors in previous work (Abbasi et al., 2022b). The images are stored in a folder to be used by the crop diagnostic system. Once the crop type and its disease are identified, the causes and treatments are automatically extracted from the ontology model and displayed on the application panel. For instance, Fig. 6 shows an example of working crop diagnostic system for parsley crops. The disease detected by the system after image uploading is Septoria Leaf Spot. The crop diagnostic system extracts the knowledge about potential causes and general treatments of this disease from AquaONT. The primary causes of Septoria Leaf Spot in Parsley could be high humidity level, infected seeds, leaf wetness, etc. This disease could also be caused due to irregu- lar variations in air temperature. The potential preventive measures and treatments suggested by the system for this disease include:

maintaining optimal humidity and temperature levels in accordance with Parsley crop and indoor aquaponics environment throughout the growth cycle, treating seeds before germination with hot water or Clorox bleach, using conventional fungicides if the disease is spread out in multiple plants. Downy Mildew disease is one of the most com- mon diseases observed in different crops (McGrath, 2021). In the greenhouse or indoor farming environment, the potential causes of this disease are the same irrespective of crop type, which includes: high humidity, cool temperatures, infected seeds, and leaf wetness (Margaret Tuttle McGrath, 2021). Therefore, the methods to treat Downy Mildew in lettuce, basil, and spinach are also similar. This means that the classification of Downy Mildew disease with respect to crop type does not impact the results related to disease treatments. De- spite this independence, it is still significant to perform the classification of Downy Mildew for each crop individually as its symptoms for three crops, lettuce, basil, and parsley, change later in the growth cycle. This might cause confusion for the detector to distinguish Downy Mildew from other diseases. For instance, the lettuce tissue affected with Downy Mildew eventually turns brown in later stages and these symp- toms are similar to the Bacterial Leaf Spot symptom in lettuce, and both diseases have different treatment methods.

and treatments of diseases. Moreover, this study will also promote the introduction of new implementations, such as research on the complex relationship between dynamic parameters (environmental and water) and diseases in aquaponics farms and self-adapting farms in case of dis- ease detection. These smart technologies in the aquaponics system will reduce crop wastage and ensure both economic and environmental benefits.

For future work, the system will be extended to include other leafy green crops. Moreover, the dataset will also be extended, and more real-field images will be incorporated. Moreover, a mobile application will be constructed, reducing the latency, and providing data privacy, which normally occurs in cloud-based systems.

R. Abbasi: Conceptualization, Methodology, Software, Validation, Formal analysis, Visualization, Investigation, Data curation, Writing – original draft, Writing – review & editing. P. Martinez: Conceptualiza- tion, Methodology, Visualization, Writing – review & editing, Supervision. R. Ahmad: Supervision, Funding acquisition, Project administration, Writing – review & editing.

