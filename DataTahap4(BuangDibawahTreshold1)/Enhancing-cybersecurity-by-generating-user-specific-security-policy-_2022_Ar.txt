It is challenging to model human‚Äìmachine interactions, because of the complexity of human behavior and the broad set of knowl- edge requirements. Although, we chose a specific knowledge base, it is still challenging to model and examine every aspect of a users security-related behavior that is relevant to device securement, pass- word generation, proactive awareness, and updating. To model users behavior across the different aspects of SeBIS, we applied principles of decomposition inherited from software/systems engineering to ar- chitect the structure of the model. the architecture of the model is as shown in Fig. 2.

The architecture modeling the representation of knowledge about the security behavior includes different levels of abstractions, in order to ease the debugging, increase readability/maintainability and lessen the complexity. We decomposed the structure into different sorts of se- curity services on multiple layers, starting from (1) as the highest level of abstraction and ending with (3) as the lowest level of abstraction. By doing so, we eliminate a fair bit of confusion around which security aspect we employed for a specific SeBIS dimension.

Layer (1) is the most abstract of the four security service check layers. It assimilates the SeBIS concepts: device securement, pass- word generation, proactive awareness, and updating that are specified by Egelman and Peer. These correspond to the highest level of representation of the security task that needs to be executed.

Although, there are several approaches that can be used to model user behavior such as, Markov chains, architectural representations, we selected formal method based approach. We decided that the most appropriate method of representing user behavior is through the use of a Finite-State Automata (FSA) [22] because it allows us to perform automated analysis early in the design phase, which would empower us to reason about the logical representations of the user‚Äôs behavior to evaluate alternative design options in case there were profound implications. It also allows graphical representation to visualize user‚Äôs behavior easily. It enables the use of well-defined tools too.

In order to choose the correct platform for the purpose of de- signing and checking satisfiability with formal verification the formal model of user‚Äôs behavior, several formalisms such as NuXMV [23], Uppaal [24], PVS [25], and Z3 [26] were considered carefully. We chose Uppaal [27,28][24], due to its ability to model timing aspects that are critical for cybersecurity, as well as, its ability to generate and visualize counterexamples. Uppaal represents models as timed automata, and Uppaal formalism supports model checking networked timed automata using temporal logics. This modeling paradigm allows the execution of requirements as temporal logic queries to check the satisfaction of relevant safety properties exhaustively. We next describe the timed automata formalism used by Uppaal.

We define a clock valuation as a function ùë¢ ‚à∂ ùê∂ ‚Üí R‚â•0 from the set of clocks to the non-negative reals. Let Rùê∂ be the set of all clock valuations. Let ùë¢0(ùë•) = 0 for all ùë• ‚àà ùê∂. If we consider guards and

To conduct the experiments the first step involved the experimental setup, which involved the modeling of the selected security behaviors in timed automata 6.1. Once the models were developed, the next step involved conducting the experiments (6.2) to label good and bad security behaviors.

The design of our models were guided by the capability to for- mally check the existence of good and bad user security behaviors (as measured by instruments taken from academic literature) in TCTL. Sections 6.1.1 to 6.1.4 will present a further illustration of why and how we chose the most critical matters within different security settings that are parts of device securement, password generation, proactive aware- ness, and updating. Using behavioral measurement scales in existing literature, we set up a selection of examples separating good decisions from poor ones.

In this work, we perform the data collection manually to show the concept, but the details of instrumentation (or data collection imple- mentation) will vary based upon organizations and their Zero Trust solutions, devices, policies, and procedures. There are also different proposed solutions for implementing Zero Trust policy decisions, and any data collection or measurement of user security behavior will need to interact with the specific Zero Trust solution. Zero Trust solutions notionally include a policy enforcement point and a policy engine. Typically data needed for a security decision is collected by the policy enforcement point and sent to the policy engine for review. Organi- zations could add data collection agents to include end-user security behaviors according to their specific implementations and policies. Our method allows organizations that embrace a Zero Trust philosophy to generate context specific security policies that can be automatically verified for correctness and completion. Future work will be required to add user specific security behavioral data to existing data that is fed to the policy engine. Zero Trust environments are typically envisioned to have a policy engine analyzing network, application, device, and data access policies and determining a decision in an access context. Some examples include using network or host security data including MAC addresses identifiers, Internet Protocol (IP) addresses identifiers, security access tokens, session tokens, process event data, packet in- spection data, running process data, threat intelligence data, device specific data such as installed application inventories, configuration settings, security relevant settings, and much more.

conducted in 2017, 28% of American mobile phone users reported that they do not use PIN codes or any other security feature to ac- cess their smartphones [32]. This matter of security is a lot more critical in the work environment. Because for instance, if some employees are working outside the workplace using portable devices (e.g., laptops, tablets, or smartphones) as their primary work computer, they could leave the device unprotected in some places as in a hotel room or a car. By doing so, if their device is stolen, it is already unlocked, and the company‚Äôs data would be in the hand of an unauthorized individual. Most organizations require this control for devices holding their data, but it may be hard to monitor and enforce across all ecosystems and devices.

Passwords are a perennial problem in cybersecurity. Much advice is given, and policies are enforced, but still the problem of weak passwords is constantly growing. Setting a maximum password age is one of the traditional techniques for maintaining proper password hygiene. It requires users to change their passwords in a periodic manner, typically between 30 and 90 days [36]. Some might argue that scheduled changes make the passwords harder

for users to remember, and thus more likely to be stored inse- curely. Users are adjusting and developing coping mechanisms to overcome this burden by making some alterations to their current passwords. We included this rule to our set of specifications to show an example of the criteria that can be included in the knowledge base.

People want to protect their personal information, but they are not willing to pay a little more effort for it. The biggest ex- ample of this is that despite the continuous security warnings that alert users about the use of weak passwords and the serious consequences that result from such behavior, they still use short and easy-to-remember passwords. According to the Psychology of the Password Report, 47% of people who participate in the study declared that they prefer to choose easy passwords because they are afraid of forgetting them [37]. Martin et al. (2012) illustrate that guessing a password through a brute-force attack is most likely unsuccessful against long and complicated passwords that contain capital and small letters, digits, and symbols. They mention that cracking a complicated password with lengths of 4, 8, or 16 characters would take approximately 81 s, 210 years, and 1.4 quintillion years, respectively [38]. According to Mad- dox and Moschetto (2019), when users assign a password for some account, they should maintain an adequate length, avoid well-known character substitutions, and use a variety of letters, numbers, and special characters [39]. We thought that the length of a password is necessary to look at to identify those whose accounts are vulnerable to password attacks.

With so many accounts to handle and keep track of, it can be tempting for users to use one password across them all and bring themselves some peace of mind; users might live to regret it. Re-using the same password for multiple sites carries more risk than writing down separate passwords on a piece of paper. If individuals decided to assign one password for their different ac- counts, they would allow attackers to compromise other accounts that use the same password [40]. The struggle with password protection is that the majority of end-users acknowledge the risk and the consequences of password re-use; yet, 35% of them ignore this knowledge in favor of remembering their easy and famil- iar passwords [37]. We chose to cover this aspect of password generation because, in the worst-case scenario, the resulting risk is not limited to the end-users but extends to the workplaces and coworkers if they re-use the work password for some other personal account.

There is no doubt that the interest in cybersecurity is growing and expanding, making people more educated and cautious about online information sharing, fake e-commerce sites, scams, and security threats. There is always a ‚Äò‚Äòbut‚Äô‚Äô in this imperfect world because there is a significant number of people who lack digital security awareness and education, which in turn affect their ability to recognize threats even if there were apparent signs. End-users would not be able to protect themselves from identity theft if they were unable to spot a sign of spyware on their device, recognize a social engineering attempt, identify phishing or spoofing email, or any other elusive activities. According to Verizon‚Äôs Data Breach Investigations Report (DBIR) (2019), the phishing attack was one of the leading causes of data breaches. It was a contributing factor in 32% of confirmed data exposures, and 78% of cyber-espionage incidents [41]. On account of this, we stressed the importance of spotting early warning signs by investigating the users‚Äô ability to recognize and avoid phishing scams before it is too late.

In ‚Äò‚ÄòIf You See Something, Say Something¬Æ‚Äô‚Äô national campaign, which raises public awareness of the indicators of terrorism- related crime, we are encouraged to report the authorities if something does not seem quite right to keep ourselves and our communities safe [42]. It is exactly the case in organizations‚Äô environments; reporting possible security incidents can save valu- able crucial time in the early stages of breach detection [43]. If employees know about cyberattack types and how they look and occur, they are more likely to notice unauthorized changes that have taken place on their systems. They probably would be more confident and willing to reach out to the IT department. Lack of cybersecurity awareness, training, and vigilance, and miscommunication between employees and the IT team would make the former hesitate and question themselves whether they have caught something real or not. The idea of including this area of interest to our research is to model whether users are truly not educated enough, or they are just too reckless to report such urgent matter.

Identifying, determining, and handling risks to the confidential- ity, integrity, and availability of an organizations‚Äô assets is a top-notch priority. Security policies and procedures are part of the hierarchy of any organizations‚Äô management control to maintain the security of sensitive data, the most critical asset, from the complex and ever-evolving threat landscape. One of the biggest concerns for any organization is how to protect data from its employees [44]. Security policies and guidelines are put in place to draw a line for employees between what is acceptable and unacceptable to do when they interact with the information sys- tem. The problem lies in the employees‚Äô non-compliance [45]. According to Mutlaq et al. (2016), non-compliant behavior can be

categorized as: first, deviant behavior that is driven by intentional or planned desire to harm the organization entity. Second, neg- ligent behavior that is intended to go against security policy but with no malicious intent to cause harm. Third, ignorant behavior that steams from unawareness due to a lack of cybersecurity knowledge and training. After identifying these different inter- pretations of security policy violations, we modeled end-users‚Äô adherence to security policy, as it aids the process of identifying the right policy actions to impose against a specific user.

Security-related software updates are one of the single most im- portant security protection tools that end-users should pay more attention to and ensure that they are being installed on a regular periodic schedule. There are several options for the operating system and application updates that end-users can configure, such as how updates are downloaded and installed (i.e., automatically or manually) on their devices. Most modern software systems are set to download and install security and other essential updates automatically without the need for humans to make decisions. In contrast, the manual update allows users to gain better control over their devices by choosing which update to install and when. There is no certain position where we can say that one mechanism is better and safer than the other because it all depends on users‚Äô behaviors regarding this matter. It may come to mind that the automatic mechanism appears as a more responsible selection. Still, the manual update is responsible as well in case end-users ensure that their systems are up-to-date as soon as a new update is available. We chose including users‚Äô preferences of the updating mechanism to observe the different behaviors.

Even though some software updates and patches are released to address security bugs that have been discovered in previously installed software, some end-users avoid or delay the installation because they consider that these incremental updates are just useless technical additions [46]. Herein lies the risk for those users who download and install updates manually after they were available a while ago. We discern from this that delaying the installations of the latest updates and patches creates windows of opportunities for malicious individuals to exploit open security vulnerabilities on the users‚Äô devices [47]. Thus we investigated further in characterizing and modeling the negligent behavior of users against timely updates.

Software developers have unremittingly endeavored to improve security by excluding the user role from the software update cycle. They found that user intervention remains a must because some updates require a device reboot to allow changes to take effect [48]. There are operating systems, such as Microsoft Win- dows, developed to alert users if a reboot is required after updates are installed. In this case, the system shows up a notification pop- up that a reboot will occur within a while (i.e., usually 10 min).

Users are given the option either to reboot the device immediately or to postpone for an additional specific time. If users chose to postpone, the warning dialog would appear again with the same options [48]. Users delay the rebooting task because they might have some pressing matters that keep them from rebooting for a couple of hours. The decision to postpone rebooting more than once could negatively impact the security of the device because, for the computer system, the update installation is not completed. We observed this aspect of updating to draw the attention of negligent and unaware users to the importance of immediate reboot if required.

In this section, we model several test cases with different security behaviors, as Finite-State Automata (FSA). For each separate test case, we generate a set of user-specific linear-time properties. We then clas- sify the behavior as good or bad based on the results of the reachability analysis. Once the behavior is classified we generate the relevant security permissions such as, Strict, Moderate and Least restrictive.

We seek to analyze users‚Äô behaviors in order to make a careful analysis and draw out their poor security decisions that have a signifi- cant impact on the security system. To ultimately achieve our goal, we designed six test cases that cover as much as possible of different se- curity behaviors exhibited by users in real-world scenarios that revolve around device securement, password generation, proactive awareness, and updating. For each test case, we represent the user‚Äôs behavior as a state-transition graph using the Uppaal tool,1 manually generate user-specific linear-time properties, apply reachability analysis, identify good and bad security behaviors and generate user-specific policy. In this section, we demonstrate one example of these test cases as an illustration of our formal method-based approach.

In order to have reliable test cases, we had to make several as- sumptions and predictions of how some users might behave and make security-related decisions. In one test case, we created a scenario with a user named Tom, who works as a Data Entry Specialist at a network marketing company. Tom is assigned a laptop to perform duties directly related to the business of the company and to allow him to work remotely and outside of regular working hours. On this basis, the com- pany requires him to be responsible and take reasonable precautions to protect and maintain the laptop and its content. For this research, we are focusing on capturing Tom‚Äôs security behavior rather than his system role. Fig. 4 represents the state-transition graph of Tom‚Äôs security-related behavior. All the other models can be found at https:

In the previous section, we have successfully managed to model the user‚Äôs security-related behavior through the modeling graphs of Finite- State Automata (FSA). We made Tom exhibit different good and poor security behaviors regarding device securement, password generation, proactive awareness, and updating. In order to automatically analyze Tom‚Äôs behavior, we needed to create linear-time properties manually, which are generated specifically for Tom. In Fig. 5, we generated the properties we needed to check based on properties identified previously specified in Section 4. We are generating these properties in order to distinguish the aspects where Tom has failed to apply proper security practices.

Reachability analysis with model checking is a verification procedure for models that are designed based on the state-transition concept. According to Kong et al. (2015), reachability analysis is a technique used in a state-transition system in order to find out the type and number of states which can be accessed through a particular system model [49]. Reachability analysis allows formal analysis for validation, verification, and checking performance metrics, explained as follows:

Among these procedures, we are checking the satisfiability of our specifications (i.e., properties) in any, some, or all states of user‚Äôs be- havior model. According to Eleftherakis et al. (2001), ‚Äò‚ÄòA model checker takes a model and a property as inputs and outputs either a claim that the property is true or a counterexample falsifying the property.‚Äô‚Äô [50]. In this research, we favored reachability analysis over other methods such as graph matching approach because it provides the opportunity to intensely and automatically check all possible paths to check the satisfaction of security properties while being computationally less expensive than graph matching.

For the set of combined linear-time security properties shown in Fig. 5, we applied reachability analysis using Uppaal to see which prop- erties were satisfied and which were not. The results of this procedure, allow us to examine Tom‚Äôs behavior and identify his security weak- nesses. We identified through two examples of reachability analysis results in Uppaal, where Tom enabled manual updating and did not install the new updates within the first day of their release.

Uppaal executes reachability analysis and checks whether a state is reachable either with Breadth-First Search (BFS) or Depth-First Search (DFS) algorithms for traversing graphs, respectively. We chose Breadth- First Search (BFS) to check the satisfaction of our reachability proper- ties (i.e., security properties) in users‚Äô state-transition graphs because it allows traversing a graph with ease.

After the execution of the experiments we were able to check the satisfiability of the properties and then associate labels with user specific security behaviors. According to those labels we were able to generate and define a set of policies to be imposed on specific users based on the satisfaction of poor or good security behavior found from model checking. The type of policies to be enforced depends on the users‚Äô decisions that represent their adherence to the rules set, which we established for each security aspect highlighted in this research: De- vice Securement (DS), Password Generation (PG), Proactive Awareness (PA), and Updating (U). We assign each security aspect one of three standardized policy types that we drafted as follows:

levels of abstraction to represent the knowledge about the potential behaviors. This abstracted representation of security behaviors allowed us to create the required knowledge base as finite state automata and it also allows for scalability, as while checking the satisfiability you are checking one level at a time instead of including all the levels at once. Once modeled, it enabled automated reasoning to check the sat- isfiability of good or bad security behaviors exhibited by users. As a result, using our framework user specific security related policies can be generated. As the policy generation was algorithmic the policy generation can be an automated process for zero trust environment to

We verified 90 properties for six test cases that were generated. The properties were executed on a 64 bit Mac, each property proved within 6‚Äì18 s. This higher level reasoning can lead to the generation of parameters to monitor for individual users to capture the user specific behaviors.

We were able to provide a solution that supports the concept of Zero Trust by eliminating the trust, that all users act responsibly. Most importantly, we achieved success in answering the research ques- tion ‚Äò‚ÄòHow to automatically identify users security practices and then generate security policy after observing and analyzing security behav- iors, especially security-related decisions, exhibited by end-users in an environment with Zero Trust assumptions?‚Äô‚Äô In our approach, Finite- State Automata supported modeling user security behavior. It allowed showing how a user could transition from safe to unsafe state based on making some specific decisions. TCTL language was used to generate linear-time properties, and thus, with reachability analysis we could check the satisfaction of the security behavior. After observing security behavior and analyzing security behavior, the appropriate policy was assigned to address security gaps caused by specific user.

So the policy can be read as follows: For Tom the policy engine should implement least restrictive policy (r) wherever, device securement and password generation are required, as he has shown good behavior in implementing these security behaviors. Whereas, a strict policy (s) needs to be implemented for proactive awareness, such as by sending more alerts or warnings as, Tom has shown weak behavior in spotting security threats. Finally, moderate policy (m) should be implemented in regards to updates, such as when to send alerts or when to implement specific actions that need to be taken if updates are not installed within a timeline.

Arwa AlQadheeb: Acquisition of data, Analysis and/or interpre- tation of data, Writing ‚Äì original draft. Siddhartha Bhattacharyya: Conception and design of study, Analysis and/or interpretation of data, Writing ‚Äì original draft, Revising the manuscript critically for important intellectual content. Samuel Perl: Conception and design of study, Writing ‚Äì original draft, Revising the manuscript critically for important intellectual content.

Halevi T, Memon N, Lewis J, Kumaraguru P, Arora S, Dagar N, et al. Cultural and psychological factors in cyber-security. In: IiWAS ‚Äô16 proceedings of the 18th international conference on information integration and web-based applications and services. New York, NY: ACM; 2016, p. 318‚Äì24. http://dx.doi.org/10.1145/ 3011141.3011165.

Moura LD, Bj√∏rner N. Z3: An efficient SMT solver. In: Proceedings of the theory and practice of software, 14th international conference on tools and algorithms for the construction and analysis of systems. TACAS‚Äô08/ETAPS‚Äô08, Berlin: Heidelberg: Springer-Verlag; 2008, p. 337‚Äì40, http://dl.acm.org/citation. cfm?id=1792734.1792766.

Albayram Y, Khan MMH, Jensen T, Nguyen N. ‚Äò‚Äò...Better to use a lock screen than to worry about saving a few seconds of time‚Äô‚Äô: Effect of fear appeal in the context of smartphone locking behavior‚Äô‚Äô. In: Proceedings of the thirteenth symposium on usable privacy and security. Berkeley, CA: USENIX; 2017, p. 49‚Äì63.

Sarabi A, Zhu Z, Xiao C, Liu M, Dumitras T. Patch me if you can: A study on the effects of individual user behavior on the end-host vulnerability state. In: 18th International conference on passive and active network measurement. Cham, Switzerland: Springer; 2017, p. 113‚Äì25. http://dx.doi.org/10.1007/978- 3-319-54328-4_9.

