Abstract Despite the evolution and enhancements that mobile devices have experienced, they are still considered as limited computing devices. Today, users become more demanding and expect to execute computational intensive applications on their smartphone devices. Therefore, Mobile Cloud Computing (MCC) integrates mobile computing and Cloud Computing (CC) in order to extend capabilities of mobile devices using offloading techniques. Computation offloading tackles limita- tions of Smart Mobile Devices (SMDs) such as limited battery lifetime, limited processing capabil- ities, and limited storage capacity by offloading the execution and workload to other rich systems with better performance and resources. This paper presents the current offloading frameworks, computation offloading techniques, and analyzes them along with their main critical issues. In addi- tion, it explores different important parameters based on which the frameworks are implemented such as offloading method and level of partitioning. Finally, it summarizes the issues in offloading frameworks in the MCC domain that requires further research.

The main goal of CC is to allow IT departments to focus on their businesses and projects instead of just taking care of their data centers and keeping them working [2,18,20]. CC is a new concept that aims to provide computational resources as ser- vices in a quick manner, on demand, and paying as per usage. The CC paradigm is presented in three cloud delivery models: Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), and Software-as-a-Service (SaaS) as shown in Fig. 1. According to Gartner [3], CC will have in 2016 a Global Com- pounded Annual Growth Rate (CAGR) of IaaS: 41%, PaaS: 26.6% and SaaS: 17.4%.

Recently, user preferences for computing have changed because of the latest developments and enhancements in mobile computing technologies. Several reports and studies have presented the importance of MCC and its impact on mobile clients and enterprises. For instance, and according to a recent study by ABI Research, more than 240 million busi- ness will use cloud services through mobile devices by 2015 and this will push the revenue of the MCC to $5.2 billion [11]. Moreover, the usage of smartphones has increased rapidly in various domains, including enterprise, management of infor- mation systems, gaming, e-learning, entertainment, gaming, and health care. Although the predictions that mobile devices will be dominating the future computing devices, mobile devices along with their applications are still restricted by some limitations such as the battery life, processor potential, and the memory capacity of the SMDs [31]. Nowadays, modern mobile devices have sufficient resources such as fast proces- sors, large memory, and sharp screens. However, it is still

Currently, there are several works and research in CC that aim at enhancing the computing capabilities of resource- constrained mobile client devices by providing mobile clients access to cloud infrastructures, software, and computing ser- vices. For example, Amazon web services are used to protect and save clients’ personal data via their Simple Storage Service (S3) [23]. In addition, there are several frameworks that allow to process data intensive tasks remotely on cloud servers. For instance, the ASM computation offloading framework [6] showed that computation offloading helped to reduce the energy consumption cost of mobile devices by 33%, and the turnaround time of the application by 45% [30].

This paper is organized as follows: Section 2 explains the essential background concepts and terminology, including CC, the MCC concept, and computation offloading. Section 3 presents the offloading approaches. A comparison between the different offloading frameworks and their critical issues is dis- cussed in Section 4. Section 5 highlights general issues and challenges in computation offloading for MCC. Finally, Sec- tion 6 gives a summary and points to future work.

(1) enormous computing resources available on demand, (2) payment for use as needed and on a short-term basis (storage by the day and release them as needed), and (3) simplified IT management and maintenance capabilities [1]. CC provides cli- ents with different applications as services via the Internet. As examples of public CC we can list Windows Azure and Ama- zon Web Services (AWS). Windows Azure is an open and flex- ible cloud platform which provides several services to develop,

deploy and run web applications and services in cloud data centers [33]. AWS, which is considered as an example of a pub- lic computing tool, provides users with two models: infrastruc- ture as a service and software as a service. These services allow the user to use virtualized resources in cloud data centers [23]. Computational clouds implement a variety of service models in order to use them in different computing visions [4].

Fig. 2 shows the general view of MCC which is composed of three main parts: the mobile device, wireless communication means, and a cloud infrastructure that contains data centers. These latter provide storage services, processing, and security mechanisms for both the cloud environment and mobile devices.

Computation offloading is the task of sending computation intensive application components to a remote server. Recently, a number of computation offloading frameworks have been proposed with several approaches for applications on mobile devices. These applications are partitioned at different granu- larity levels and the components are sent (offloaded) to remote servers for remote execution in order to extend and enhance the SMD’s capabilities. However, the computation offloading mechanisms are still facing several challenges.

The potential of mobile offloading mainly depends on the mobile network technologies such as cellular and WiFi. They determine the viability of mobile offloading. Today, the WiFi technology is able to provide high bandwidth connections. However, the data transmission using the cellular network requires a considerable amount of energy from the mobile device as opposed to a WiFi network.

Fig. 3 illustrates the environment that supports computa- tion offloading. In this overview, the mobile device decides to offload method B to a cloud server or a powerful machine. The cloud here provides the virtual computation resources to run the offloaded components. The powerful machine can be a server or cluster in a computing center, or a computing grid, or a virtual server in the cloud. Fig. 41 shows the number of published papers since 2004 citing the word ‘‘Offloading”

and ‘‘Computation”. Most of the research works tackling data offloading have the goal to store data in remote large reposito- ries. It can be seen in Fig. 4 that the research work citing ‘‘com- putation offloading” and ‘‘data offloading” is increasing progressively.

As it is known, the battery life of mobile devices and the limited processors’ capabilities remain key limiting factors in the design of mobile applications. Today, the demand for resource intensive applications such as 3D video games and voice recognition is increasing day by day. To close this gap between the users demand and the mobile devices limitations, research studies have been exploring computation offloading in MCC to bring the power of cloud computing to the other- wise limited mobile devices capacity.

The first step is application partitioning which is very impor- tant for computation offloading. It divides the application into offloadable and non-offloadable components meaning which components to retain on the mobile device and which to migrate to the cloud server. The decision whether a component is offloadable can be taken based on different information. The

programmer can annotate application components for exam- ple through a special API as offloadable. Compute intensive parts that are candidates for offloading can be identified also by source code analysis in combination with performance pre- diction or via application profiling. If the partitioning is done at design time, both techniques have a limited accuracy since they do not take the real execution context into account, when the application is run.

The preparation step performs all actions required for offload- able components to enable their use in mobile applications. This includes the selection of a remote server, the transfer and installation of the code, as the start of proxy processes that receive and execute tasks on behalf of the SMD. Besides the transfer of the code, also data might be transferred to prepare for the remote execution.

The offloading decision is the final step before remote execu- tion is started for offloadable components. Whether an installed remote component is used in the SMD application or not depends typically on the execution context. If the deci- sion is taken at runtime, more precise information is available, for example, the SMD might even not have a wireless connec- tion or the energy consumption for transferring the data for the remote execution might simply be too high. Whenever the situation changes, the offloading can be adapted. Such a runtime decision induces some overhead that typically is not present if the decision is taken at design time.

According to when the decision is taken to offload computation on a remote server, we can distinguish two types of offloading frameworks. The first class is static offloading frameworks. Here all the presented steps are performed at design time, before the application is started on the mobile device. The other classes are dynamic offloading frameworks. In those frame- works, at least the final decision whether to offload a computa- tion is taken at runtime. The other two steps can be executed at design or runtime. For example, a framework that is based on user annotations of offloadable components and on pre- installation of the components on a remote server will be called a dynamic offloading framework, if it decides at runtime whether it is better to offload computation or not.

Frameworks based on code offloading offload intensive application components by invoking a remote procedure call (RPC) using annotations, special compilation or binary modi- fication. Whereas in virtual machine cloning, the mobile devi- ce’s full image is captured and stored on the cloud server. During offloading, the mobile’s execution is suspended and transferred to the VM clone in the cloud.

This section introduces different existing offloading frame- works. For each of the frameworks we identify the approaches used in the three steps introduced in the previous section. At the end of the section, the different frameworks will be com- pared with respect to their most important properties.

The partitioning step in this framework combines static program analysis with program profiling to produce a set of offloadable components while meeting some constraints, such as methods that use mobile sensors should be executed locally. The framework uses thread level granularity for partitioning of applications. The role of static analysis is to discover con- straints on possible migration points while profiling aims to build a cost model for offloading and execution. Partitioning and integration of the applications are performed at the appli- cation level.

At runtime, the offloading decision is taken and threads are migrated from the mobile device to the clone in the cloud. In CloneCloud, threads must be suspended, all states of the threads must be transferred to the server, and then threads resume on the server in order to offload computation. The framework is based on VM instance migration to the cloud server. Fig. 6 shows the CloneCloud execution model. Initially, a duplicate of the smartphone’s software is created in the cloud. The state of the smartphone and the clone is synchro- nized periodically or on-demand. After the execution of off- loaded components, results from the execution on the clone are reintegrated back into the smartphone state. CloneCloud employs dynamic offloading.

In CloneCloud framework, the distributed execution goes through several steps as follows. When the user tries to run a partitioned application, the framework looks in a database of pre-computed partitions for current execution conditions (such as available network bandwidth and cloud resources). The result of the verification is a partition configuration file. The partition is loaded by the application binary which instru- ments the selected methods with migration. On the mobile device, once the execution of the process reaches a migration point, the running thread is suspended and its state is wrapped and shipped to a synchronized clone. In this clone, the thread state is instantiated into a new thread with the same stack and

reachable heap objects, and then resumed. On the cloud server, when the migrated thread reaches a re-integration point, it is suspended, packaged, and then shipped back to the mobile device. Finally, the received packaged thread is merged into the state of the original process in the mobile device.

MAUI [8] is a framework that considers energy saving on smartphones as the main objective function for the offloading process. MAUI is a highly dynamic offloading framework because of a continuous profiling process. The framework hides the complexity of a remote execution from the mobile user and gives the impression as if the entire application is being executed on the mobile device.

MAUI profiler evaluates it for its energy-saving potential and profiles the device and the network to obtain the status information. Then, the MAUI solver works on the results pro- vided by the profiler and determines the destination where the method will be remotely executed; the proxy is responsible for control and data transfer between the server and the smart- phone. On the server side, the profiler and the server proxy perform similar roles as their client-side counterparts. The MAUI controller is responsible for authentication and resource allocation for incoming requests [8].

The authors presents different experiments in order to com- pare the energy consumption of running three applications(- face recognition, chess, and video) standalone on the smartphone versus using MAUI for remote execution to ser- vers that are located elsewhere. The face recognition applica- tion can achieve strong energy savings when using MAUI. On the one hand, the results of the conducted experiments showed that the energy consumed when offloading code using 3G is 2.5 times higher than offloading code to a close server. On the other hand, the energy savings for both video and chess game are less strong but they are still important; when offload- ing to a close server, MAUI saves 45% for chess and 27% energy for the video game.

Satyanarayanan et al. suggest in [29] a VM based cloudlet framework. A cloudlet can be defined as a hosting environ- ment for offloaded tasks that is deployed to remote resources, as different as individual servers or parallel systems. Cloudlets are virtual-machine (VM) based on support scalability, mobil- ity, and elasticity. They are located in single-hop nearness to mobile devices.

In the preparation step, the framework requires the cloning of the mobile device application processing environment to a remote host. It offloads the entire application using VM as the offloading mechanism and more precisely it uses a tech- nique called dynamic VM synthesis. The VM would encapsu- late and separate the guest software from the cloudlet’s host software. The mobile device serves as a thin client providing only the user interface, whereas the actual application process- ing is performed on the cloudlet infrastructure.

As Fig. 8 illustrates, cloudlets are widely distributed Inter- net infrastructure components whose storage resources and computing cycles can be exploited by nearby mobile devices while avoiding the long latency which is available for accessing distant cloud resources. These cloudlets would be situated in common areas, such as coffee shops, so that mobile devices can connect and work as a thin client.

Fig. 9 depicts the cloudlet architecture. Cloudlets are dis- coverable, and located in single-hop proximity of mobile devices. The main elements of the architecture are Cloudlet Host and Mobile Client. A Discovery Service is a component running in the cloudlet host and publishes cloudlet metadata. The cloudlet metadata (e.g. IP address and port to connect

to the cloudlet) are used by the mobile client to specify the suit- able cloudlet for computation offloading. Once the cloudlet is determined for offload, the mobile client sends the application code and the application metadata to the cloudlet server. The cloudlet server deploys the application code in the guest VM. Once the deployment is done, the execution of the application is launched.

We can take a scenario where the user must execute a com- putation intensive application. At runtime, the application dis- covers a nearby cloudlet and offloads the computation intensive mobile application [15]. However, because of loss of network connectivity, the mobile application can find a dif- ferent cloudlet and run the application in a short time.

Sharing the same concern but from a different perspective, Qian et al. present in [28] a system that monitors application and device status and that automatically decides where the code should be executed. The goal of Jade was to maximize the benefits of energy-aware computation offloading for mobile applications while minimizing the burden on develop- ers to build such an application.

The offloading decision is taken at runtime to decide where the code should be executed. Jade supports two types of ser- vers: (1) Android servers and (2) Non-Android servers running operating systems such as Windows and Linux. Non-Android servers must have Java installed in order to support Jade. Jade’s runtime engine runs as a Java program on a non- Android server.

Fig. 10 presents an overview of the Jade framework. The mobile device that offloads computation is called the client. The device that executes the offloaded code is called the server. Mobile applications contain remote tasks which can be off- loaded to the server. The Jade runtime engine automatically decides where to execute remote tasks and initiates distributed execution.

Profiling: In order to make correct offloading decisions, the framework should have updated information concerning the status of the application and the device. Application profiling is the process of collecting information about pro- grams, such as energy consumption, data size, execution time, and memory usage. Similarly, device profiling collects information about devices status, such as battery level, CPU usage, and wireless connection.

loaded components; (3) send data between the mobile device and the remote server; (4) follow status of remote execution; and (5) save information related to all connected devices (e.g., connection speed, hardware configuration). Optimization: The framework determines an optimized offloading approach to reduce energy consumption and enhance application’s performance.

In order to check the amount of energy that Jade can save for mobile device, authors run face detection application on a mobile device. The application performs face detection on 50 pictures with size of each less than 200 KB. Results showed that Jade reduces the power consumption for face detection application. Average power consumption was decreased by 34%.

Zhao et al. present in [38] the mirror server framework that uses Telecommunication Service Provider (TSP) based remote services. A TSP is a type of communication service provider which provides voice communication services such as landline telephone services. Mirror server extends capabilities of smart- phones by providing three different types of services: computa- tion offloading, security, and storage. Mirror server is a powerful server which retains VM templates for different mobile device platforms.

In the preparation step, a new VM instance is created. This VM is called mobile mirror and the mirror server takes care of managing and deploying the mobile mirrors on a computing infrastructure in the telecom network. Applications are exe- cuted in the mirror VM instances and results are returned to the SMD. The framework employs an optimized mechanism for offloading.

The Mirror Server architecture is presented in Fig. 12. On the SMD side, a client synchronization module (Syn-Client) is deployed within the SMD operating system (OS) to collect SMD input data and transmit them to the mirror server for synchronization. On the server side, in order to keep mirrors and smartphones synchronized, the synchronization module (Syn-Server) updates mirrors according to the data provided by Syn-Client and the Traffic Monitor module which monitors network traffic between the smartphone and the IP network.

Kemp et al. present in [19] the Cuckoo framework for compu- tation offloading for smartphones. This framework offloads mobile device applications onto a cloud server using a Java stub model. Cuckoo’s objectives were to enhance mobile’s per- formance and reduce battery usage. The framework integrates the Eclipse development tool with the open source Android framework.

As a preparation, the framework requires the developer to write offloadable methods twice - one for local computations and one for remote computations. For this purpose, a pro- gramming model is made available to application developers. This programming model is used for dropped connection, sup- ports local and remote execution, and combines all codes in a single package so the user will have a compatible remote implementation.

Cuckoo is a dynamic offloading framework as it takes the offloading decision at runtime and offloads the well-defined components of the application. In case the remote resources are not reachable (i.e. network connection is not available) then the application can be executed on local resources (the mobile device).

Xia et al. present in [36] a computation offloading framework called Phone2Cloud. The objective was to improve energy effi- ciency of smartphones and improve the application’s perfor- mance. Unlike the previous frameworks, authors focus on conducting a fully quantitative analysis on energy saving of the system by conducting application experiments and scenario experiments.

The framework can offload the whole or part of an applica- tion to a cloud server. The prototype of Phone2Cloud is imple- mented for Android and Hadoop environment (to serve as a cloud). It consists of several components, including an offload- ing decision engine, a local execution manager, a bandwidth monitor, a resource monitor, an execution time predictor, a remote execution manager, and an offloading proxy that links the offloading decision engine to remote execution manager.

First, average execution time and user’s delay-tolerance threshold are compared. If user’s delay-tolerance threshold is smaller than average execution time then the application is off- loaded to the cloud. Otherwise, the decision engine checks whether power consumption to run the application on the cloud is greater than power consumption to run the applica- tion on the SMD. If it is the case, the application is executed locally. Otherwise, the application is offloaded to the cloud.

Offloading decision engine: It is the core component of Pho- ne2Cloud. Offloading decision engine decides whether to offload the application’s components from the mobile device to the cloud server. When it decides to run the appli- cation locally, it invokes local execution manager to execute the application. Otherwise, it invokes the offloading proxy to offload computation to the cloud.

The authors examine how the energy consumption and exe- cution time of applications will be affected. The evaluated applications are word count, path finder, and sort application. The framework saves energy and improves applications’ per- formance and users’ experience of smartphones.

For instance, face finder application costs more energy on smartphone than on a cloud server and the difference between the two costs gets bigger as input grows. The reason behind this is because data transmission costs less energy than running the application locally. Moreover, the energy consumption in smartphones grows faster than that on the cloud server. Thus, face finder application should be offloaded to cloud.

Annotation is one of the important attributes in partition- ing step. It can be seen as a metadata added to the source code. The current partitioning algorithms used in the offloading frameworks can be categorized as (a) automatic and (b) manual.

Manual annotation is performed by the programmers at the design phase. It requires examining the scope of the compo- nents of the application at design time. Programmers annotate the components of the application at different granularity such as classes and methods [8,32].

We can notice that some frameworks offload the entire application while other frameworks split the application into its components. Concerning the offloading mechanism, some frameworks encapsulate the offloaded components into a VM or create a VM with exactly the same hardware/software specifications. Other frameworks focus on the code mechanism to offload intensive components. For the annotation attribute, some frameworks use manual annotation while others use automatic one except Phone2Cloud framework which follows a semi-automatic way. Decision offloading is the main attri- bute of the different offloading frameworks. Some frameworks take the offloading decision at runtime based on a program profiling and program analysis while others take the decision during design or compile time using programmers’ annotations and some estimations. A static offloading decision could not adapt to fluctuating network conditions efficiently and depends on programmers’ decision. A dynamic offloading decision incurs overhead as it is continuously performed to obtain the latest information.

It can be seen from the presented frameworks that they use different approaches to offload intensive tasks to remote cloud servers. However, none of them use or adopt containers tech- nology such as Linux Containers (LXC). LXC is attracting researchers these days as a lightweight alternative to full machine virtualization such as the common known hypervisors such as KVM or Xen. Recently, research suggests that applica- tions running in containers can achieve approximately same speed in memory, processing and also network throughput as if they were running on a physical machine [41]. LXC is con- sidered as an OS level virtualization where each container has its own environment called a namespace where specific pro- cesses are running and isolated from the rest of the system. The usage of containers instead of VM will be a good idea since it is lighter than VM.

One of the challenges in the current computation offloading frameworks is the diversity and heterogeneity of smartphone architectures and operating systems. This diversity is seen in the following example: MAUI [8] is an offloading framework which is applicable for the .Net framework whereas Mirror Server [38] is a framework which is compatible with the Android platform. A consistent access to cloud services is expected wherein SMDs are enabled to access cloud comput- ing services regardless of the installed operating system or the used hardware. A standardized offloading framework for different smartphone platforms is still a challenging issue in the MCC field.

Security of data transmission is an important concern in cloud based application processing. Security and privacy are two cru- cial concepts that need to be maintained during the offloading process. These concepts can be addressed from different angles: (1) Mobile device, (2) cloud data centers, and (3) during data transmission over the network. Besides all the technolo- gies, there is a great increase in the variety of sophisticated attacks on mobile phones which are the main targets for attackers. Regarding the security in the cloud data centers, threats are basically related to the transmission of data between the different nodes over the network. Thus, high levels of security are expected by both the mobile clients and the cloud providers. In the current frameworks [10,12], binary transfer of the application code at runtime is continually sub- jected to security threats. Despite the available solutions, strong measures and a secure environment are required for the three entities of MCC model.

In [39], the authors focus on optimizing tasks and compu- tations, and they explore secure offloading of applicable linear programming (LP) computations. In this paper, authors build their work based on the decomposition of the LP computation offloading into public LP solvers running on the cloud and pri- vate LP parameters owned by the customer. To achieve an effi- cient and validate results, the authors focus on the fundamental duality theorem of LP computation and come up with the essential conditions that must satisfied by correct results. Bugiel et al. present in [40] an architecture for secure outsourcing of data and arbitrary computations to an untrusted commodity cloud. The architecture proposed in their approach consists of two clouds (twins): a trusted cloud and a commodity cloud.

The security threat is advancing in a quick manner more than we can keep up with it. Security techniques need to enhance and progress constantly to meet new changes and new offered services. Thus, it is no longer possible to define a security system that would solve all the security threats at once.

In MCC, mobility is one of the most important attributes of SMDs. This is because freedom of movement and autonomy of communication during the consumption of mobile cloud services, are crucial criteria for users’ satisfaction. However, there are some constraints that prevent the achievement of seamless connectivity and uninterrupted access to cloud ser- vices while on the move. As mobile users move, data exchange rates and network bandwidth may vary. Moreover, users may lose their connection while sending or receiving data; there- fore, offloading approaches should be provided with suitable fault-tolerant strategies in order to resend the lost components, minimize the response time, and reduce the energy consump- tion of mobile devices. It should be noted that the guarantee of a successful execution of offloaded applications is very cru- cial for mobile users.

The available computation offloading frameworks still need to be automated. This will help the offloading process to be per- formed in a seamless fashion while discovering the surrounded environment [5,9,14]. The achievement of such automation is not an easy task as it needs the implementation of a protocol dedicated to finding and discovering services depending on the current context and its constraints.

Using cloud infrastructure resources imposes financial charges on the end-users, who are required to pay according to the Ser- vice Level Agreement (SLA) agreed on with the cloud vendor serving them. Generally, the operations of content offloading and data transfer between cloud providers incur additional costs on end-users. Therefore, economic factors should be taken into consideration while making the offloading decisions.

(2) mobile cloud computing, and (3) computation offloading. More specifically, it presents existing frameworks for computa- tion offloading along with the various techniques used to enhance the capabilities of smartphone devices based on the available cloud resources. The paper investigates the different issues in current offloading frameworks and highlights chal- lenges that still obstruct these frameworks in MCC. Moreover, the paper shows the different approaches that are used by the frameworks to achieve offloading. Some of these approaches use static offloading while others employ dynamic offloading. Even though there exist a variety of approaches, all of them target the same objective which is the improvement of the smartphone device capabilities by saving energy, reducing response time, or minimizing the execution cost.

We notice that current offloading frameworks are still fac- ing some challenges and difficulties. For instance, lack of stan- dard architectures. This shortage leads to more complications while developing and managing a proposed framework. Finally, it is important to come up with a lightweight paradigm or model that will help to overcome the difficulties and mini- mizing efforts while developing, deploying, and managing an offloading framework.

