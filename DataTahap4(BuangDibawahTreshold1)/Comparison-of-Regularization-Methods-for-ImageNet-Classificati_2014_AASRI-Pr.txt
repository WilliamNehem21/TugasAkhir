Large and Deep Convolutional Neural Networks achieve good results in image classification tasks, but they need methods to prevent overfitting. In this paper we compare performance of different regularization techniques on ImageNet Large Scale Visual Recognition Challenge 2013. We show empirically that Dropout works better than DropConnect on ImageNet dataset.

Visual object recognition is one of the most challenging problems in Computer Vision, especially in large scale and realistic settings, with high resolution images and thousands of object categories. Until recently neural networks were not widely used for this task, because they need a lot of labeled data and computational power to train. Now, with the advance of fast GPUs and big labeled image datasets, they can be used efficiently, and, moreover, they can beat other methods. Neural networks potentially have fairly large learning

capacity, which can be controlled by the number and size of layers, so they can adapt to very big problems. Best results can be obtained with deep neural networks, because depth is essential for learning good internal representations of input data. Large neural networks suffer from the problem of overfitting, so there is a need for powerful regularization techniques like data augmentation (Krizhevsky et al., 2012), Dropout (Hinton et al., 2012) or recently introduced DropConnect (Wan et al., 2013). Another way to improve performance of neural networks is inserting some prior knowledge like awareness of 2D structure of input data. One type of such networks is Convolutional Neural Networks. Because of their structure they have fewer learnable parameters than standard fully-connected neural networks, so they are easier to train and less suffer from overfitting.

The specific contribution of this paper is comparing performance of DropConnect (which, to our knowledge, was evaluated only on small datasets) and Dropout and improved Data Augmentation in large scale settings - on ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013). We started with architecture close to proposed by (Krizhevsky et al., 2012), which is a winner of ILSVRC2012, and explored how it works with other regularization methods instead of Dropout. Also we proposed several ways to improve results.

ImageNet dataset has over 15 million labeled high resolution images of 22,000 categories. Annual competition called the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) uses a subset of ImageNet with 1.2 million variable-resolution labeled images of 1000 categories. There are also 50,000 labeled images used for validation and 100,000 unlabeled images used for testing. Two error rates are reported: top-1 and top-5, where the top-5 error rate is the fraction of test images for which the correct label is not among the five labels considered most probable by the model. Winner’s result of ILSVRC2012 is 16.4% top-5 error for 5 averaged CNNs (18.2% top-5 error for single CNN). Winner’s result of ILSVRC2013 is 11.7% top-5 error.

Later, as a part of data augmentation method, we cropped random patches of size 224x224x3 from this central patch. Data preprocessing was done on the CPU, while in parallel performing training on GPU, so it didn’t take much computation time. We didn’t use PCA in contrast with (Krizhevsky et al., 2012).

Introduced by (Hinton et al., 2012), this method is now very popular. It consists of setting to zero the output of each hidden neuron in chosen layer with some probability (usually 50%), and is proven to be very effective in reducing overfitting. We trained one of our networks with Dropout on 6’s and 7’s fully-connected layers with probability of 50%.

Recently introduced by (Wan et al., 2013), this method is very new. To our knowledge, it was used only on small datasets, and performed good, but not always better than Dropout. It consists of setting to zero not the outputs of neurons, but weights (See Fig. 3) in chosen layer with some probability (usually 50%). We decided to compare its performance on large dataset like ILSVRC2013 and trained second of our networks with DropConnect on 6’s and 7’s fully-connected layers with probability of 50%.

Instead of just cropping and randomly horizontally flipping patches, we decided to try more sophisticated data augmentation technique – random scaling and rotation. Sadly, we didn’t get improvement from this technique – error rate only increased. We think that it is because our network is too small, and we need larger neural network to use this technique efficiently.

After we trained three neural networks, we used them to classify validation and testing parts of the dataset. To get better results, we used multiview testing technique, proposed by (Krizhevsky et al., 2012), which consists of averaging predictions of 10 patches for every classified image: 4 corner patches, central patch and their horizontal reflections. Also we averaged predictions of two our best networks. Our results are presented in Table 1.

Our results show that Dropout regularization works better than DropConnect for ImageNet classification task. Also we discovered that our network was too small, and for getting better results we need to use larger network with better regularization techniques. We think that results can be improved by using new methods like DropPart (Tomczak, 2013), standout (Ba and Frey, 2013), maxout (Goodfellow et al., 2013), Stochastic Pooling (Zeiler and Fergus, 2013b), DLSVM (Tang, 2013), Lp Units (Gulcehre et al., 2013) or channel-out (Wang and Jaja, 2013) and some data augmentation techniques.

