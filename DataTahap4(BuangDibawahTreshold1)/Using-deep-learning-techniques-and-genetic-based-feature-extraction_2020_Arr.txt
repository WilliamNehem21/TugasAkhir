Biometric systems have several vulnerable points that can be exploited by a hacker to gain unauthorized access to a system. One vulnerable point, and the focus of this work, is the acceptance of pre- sentation attacks. Biometric-based presentation attacks are primarily focused on gaining access to a counterfeit biometric sample and imple- menting the same biometric to illegally gain access to secured data. Although biometric authentication strengthens security protocols through unique feature extraction, presenting a biometric sample of

learning based mitigation techniques is given. With promising results from deep learning techniques in image classification, similar findings in spoofing detection and mitigation are favorable. The scope of this review explores mitigation techniques for facial biometrics, excluding tech- niques designed generally for image classification.

steps, a novel feature extraction technique to mitigate the effects of presentation attacks is contributed. With the proliferation of deepfakes [36,37] in media, this technqiue should provide insight on the GAN technique often used. In combination with GEFE, the generated feature extractors will also provide insight on which biometric features on the samples has the higher discriminative capabilities with its optimize di- mensions and displacement. The remainder of this work follows with a literature review of popular techniques for mitigatigating presentation attacks. This is followed by our methodology, experiments, and results. Lastly, we have our discussion and future direction.

Presentation attacks are the presentation of impersonated human characteristics to the biometric capture subsystem. This is done to spoof biometric recognition to illegally gain access to the biometric system. Print photo attacks, 3-D masks, and image regeneration have all been used to successfully gain access to biometric systems [17]. A 2D face system with no anti-spoofing measures can be easily spoofed by pre- sentation attacks. Multimodal systems are suggested in scenarios with high probabilities of spoof attacks. Unfortunately, a biometric system with several modes may not need all modalities to be spoofed to compromise the entire multimodal system [22]. Multimodal biometrics has shown to improve the performance of biometric systems, though they are often expensive, and they can also increase the number of vulnera- bilities that can be exploited by an intruder [22]. The next section of this chapter will be an overview of some texture-based presentation attack

for each SDBM is 256. Once the features are trained and concatenated, a SVM classifier is trained for two-class classification. The proposed algo- rithm showed significant advances in retouching detection. Experiments yield a high of 55.7% classification accuracy for existing makeup detection algorithm, with the proposed algorithm achieving nearly 87% classification accuracy on the same dataset. Additionally, experiments showed that the improvements in classification accuracy were attributed to the supervised DBM and SVM classification [18].

With this review we identified a few similarities in the mitigation techniques. The textured based methods are often used in combination in with deep learning techniques. Deep learning based techniques showed significant improvement from baseline in classification accuracies for spoofing attacks. We also found similarities in the preprocessing of bio- metric samples before the use of the techniques. Although we can iden- tify the periocular region as a strength in biometric recognition, gaps exist in finding the distinct features in the periocular region that mitigate spoofing attacks.

In this section, we provide an overview of our proposed methodology including a novel deep learning approach to generate a synthetic (spoofing) dataset. We will then address the feature extraction tech- niques for biometric recognition. This research proposes to contribute empirical findings in improving biometric recognition against presenta- tion attacks using deep learning techniques.

Traditionally, GEFE is applied on a simulation of a biometric identi- fication system. To simulate this, K biometric images are collected from N different individuals. One image per individual will represent a biometric sample being identified and the K-1 images of all N individuals represents the database of known individuals. A GEFE FE is applied on every image and feature vectors (FVs) are created for each. Each FV that is to be identified is compared to the database of FVs and the most similar match is considered the identity of the unknown FV. If there is a mismatch, the fitness of the FE is penalized. With this scheme, there are N*(N*(K-1)) comparisons made.

The fitness is based on the number of correct matches between in- stances, so the best fitness occurs when discriminating features are extracted from each instance. The more discriminating the features, the more likely that the resulting FVs from the same individuals will have a better similarity score than FVs from different individuals. The GEFEmany scheme, proposed in Jenkins et al. [15], compares every instance in a dataset into every other instance. The instances involved do not change from the dataset used by the traditional GEFE method, but the number of comparisons is now (N*K)*((N*K)-1). The number of comparisons is now greater, thus allowing for a more complex environment to evolve FEs in. Though the number of instances has not changed, the increase of instance comparisons results in FEs that have a superior identification performance.

architecture as a data augmentation technique to generate a spoofing dataset. The generated spoofing dataset will be tested for its quality and used in the GEFE technique to generate improved feature extractors that can mitigate presentation attacks. Similar to the combination of BSIF and 2D Ceptrum [24], the GEFE technique has been used previously to optimize LBP FEs to mitigate replay attacks with high biometric recog- nition accuracy. The proposed GEFE technique will be optimized to mitigate synthetic images. The GEFE FEs also will provide insight on which biometric features have the higher discriminative capabilities as GEFE optimizes the dimensions and displacement of FEs on the biometric sample.

First we test the quality of the images generated by the DCGAN technique. The spoofing samples will be added to the gallery set of a simple LBP-3x3 identification system. An LBP 3x3 system means that images are split into three rows and three columns of even sized regions where features are extracted from each region and concatenated to form the feature vector for an image. The identification and verification ac- curacies will be recorded and compared, that with the original dataset and the spoofing datasets as well. These results will show us the quality of DCGAN generated samples and the power of Generative Adversarial Networks. Next, we will use the spoofing datasets for training with the GEFE technique to generate improved feature extractors. During this process, the GEFE technique will not only be looking for distinct features for periocular recognition, but also features to mitigate presentation at- tacks. GEFE uses the Estimation of Distribution Algorithm (EDA) [31] as the GEC with 250 function evaluations with a population size of 20 candidates FEs.

the evolutionary process. By doubling the error value for matching sub- jects with a DCGAN generated samples, the evolved feature extractors are less likely to match a presentation attack over real subjects. This is pro- posed to optimize the anti-spoofing fitness of the generated feature ex- tractors. This is also shown in the pseudocode below.

The identification performance will be presented using Cumulative Match Characteristic (CMC) curves. As each probe sample is compared against all gallery samples, the resulting scores are sorted and ranked. This determines the True Positive Identification Rate (TPIR); the rank at which a true match occurs. CMC curves plot the TPIR against ranks. The verification performance will be presented using Receiver Operator Characteristic (ROC) curves. As each probe sample is compared against all gallery samples, the True Accept Rate (TAR) and False Accept Rate (FAR) of subjects are calculated at multiple thresholds. TAR is the mea- sure of likelihood that the biometric security system will correctly ver- ifies a true claim of identity. The FAR is the measure of likelihood a system incorrectly accepts an access attempt by an unauthorized user. The TAR and FAR are stated as the ratio of the number of true and false acceptances divided by the number of identification attempts.

(eye corners) are keys to identification and presentation attack mitiga- tion. The generated FEs favor the lateral and medial canthus over using the entire eye area. The malar fold is the defined groove extending from the lateral canthus. The nasojungal crease is also a defined groove in the lower lid fold, between the medial canthus and the nose [34]. The nasofacial sulcus is covered by both GEFE FEs, but more significantly on the outside dataset; instead of the entire nose. It seems the natural light in the iPhone5-outside datasets exposes the periocular features better for discriminative capabilities. These areas could all be outlining features used to mitigate presentation attacks with synthetic images.

In this paper, we apply a data augmentation technique with GANs to generate comparative synthetic (spoofing) dataset. We trained the syn- thetic images using GAN and created spoofing datasets. The GEFE tech- nique is then used in combination with the GANs to generate improved anti-spoofing feature extractors optimized in an attempt to mitigate presentation attacks. The combination of GEFE and GANs is used to

nition datasets [38]. The UBI dataset uses images taken from a profes- sional camera, the Canon EOS 5D (12.8 MP). The UBI dataset also has 15 periocular samples per subject. With an increase of samples, the DCGAN generated samples should be more accurate. With higher quality syn- thetic samples, the GEFE experiments should increase the quality of discriminative feature extraction.

This research is based upon work supported by the Army Research Office (Contract No. W911NF-15-1-0524) and National Science Foun- dation (Award Number:1900187). Any opinions, findings, and conclu- sions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of Army Research Of- fice and National Science Foundation.

