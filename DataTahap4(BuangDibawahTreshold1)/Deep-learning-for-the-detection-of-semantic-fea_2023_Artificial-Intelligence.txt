This paper can be compared with two categories of related work. On the one hand, a significant body of work in the deep learning commu- nity addresses questions of regression from images, image segmenta- tion or detection of objects. However, these tools have rarely been applied to support the wood processing industry. On the other hand, we identified a number of works applied specifically to wood imagery, either using traditional imaging techniques on planks or trunks or X- ray tomography.

A deep learning architecture is defined as a multi-layers stack of basic modules which have the ability to learn to transform their input to improve the representation selectivity and invariance (LeCun et al., 2015). In the computer vision field, many deep learning architectures have evolved over the last few years. In particular, architectures based

the input and creates diversity in the data. If correctly calibrated, data augmentation can improve generalization and performance of the train- ing model (Shorten and Khoshgoftaar, 2019; Perez and Wang, 2017). In Computer vision, image augmentation has become a common implicit regularization approach to prevent overfitting (poor generalization) and generally enhances performances.

on Convolutional Neural Networks (CNNs) such as VGG, Residual net- work (ResNet), MobileNets and EfficientNet (Simonyan and Zisserman, 2015; He et al., 2016; Howard et al., 2017; Tan and Le, 2019) are developed to solve problems in different domains or use- cases and have significantly driven the performance of vision tasks based on their rich representation power. This led to the advent of more complex neural network such as (Liu et al., 2022) and those based on attention such as Vision Transformer (ViT), Data-Efficient Image Transformers (DeiT) and Swin Transformer (Dosovitskiy et al., 2021; Touvron et al., 2021; Liu et al., 2021).

Instead of proposing a new architecture, we have exploited the knowledge of a set of already existing convolutional neural network ar- chitectures (see 2.1.1) that have performed excellently on several image tasks. The choice of convolution networks is driven by the fact that our task consists on performing regression on images. For our work, we use ResNet-34 (He et al., 2016) which is a variant of the residual neural net- work with a total of 34 layers, the advantage of this architecture is that it offers a good combination of number of parameters and performance, and has proven its performance on image classification tasks. Another reason for exploiting the residual network architecture is the possibility of feeding images of different sizes from those with which they are trained thanks to global average pooling layer,1 which computes the av- erage value over the spatial dimensions of each features then feeded di- rectly to the softmax activation. This is considered a crucial part to do transfer learning, which help us to achieve high performance on a net- work using very few epochs. The ResNet-34 network contains 21.2 mil- lion of trainable parameters.

images, and several end-to-end trainable neural networks mentioned in (2.1.1) with a regression head can be trained on this task. Knot detec- tion can be either formulated as a segmentation task or object detection task, and there exists also a variety of end-to-end trainable neural net- works in the computer vision community for solving this task. Contour estimation, on the other hand, can be addressed in several ways. One approach is to cast the contour estimation as tree segmentation where the task is to predict all the pixels belonging to the tree, hence a binary semantic segmentation task from which U-Net, Faster-RCNN, and any semantic segmentation neural network can be applied. That first ap-

ularization, we tested some data augmentation strategies (see 2.1.3) and early stopping to prevent overfitting. To ensure that the augmenta- tion of these images is achievable with reasonable memory usage and speed, we used an open source library, Albumentations (Buslaev et al., 2020). The images are normalized between the values [0, 1]. We trained the network with the convolutional part pretrained on ImageNet, the first convolutional layer2 being randomly initialized using the He normal strategy and the linear layer is randomly initialized using the default pytorch strategy with both the weights and biases sampled

output that is not necessarily a closed curve as expected for a contour predictor. A second approach relies on end-to-end trainable predictors outputting a closed curve. This is not straightforward to design a train- able neural network for outputting a closed curve, but recent works on differentiable active contours follow that track (Marcos et al., 2018). This is a recently proposed approach which has the benefit to output a closed curve, by constraint, but that we did not explore yet in this paper.

For the data augmentation (seen in subsection 2.1.3), after testing several ones, we selected the following relevant transformations: shift, scale, color augmentation (saturation, brightness, contrast), random horizontal and vertical flipping, and rotations. We used the augmenta- tion only with the training data. At the end, we did some experiments that consist of augmenting test data to evaluate the robustness of the model. The random seed of the data augmentation is fixed for reproducibility.

The entire data preprocessing, the network models involved in the experiment, as well as the network training, were programmed in Py- thon and Pytorch (Paszke et al., 2019) with Nvidia CUDA.6 The center detection task was conducted for 40 epochs, The segmentation tasks (contour and knots) were conducted for 100 epochs per model.

(MAE) as a metric to measures the quality of the predictor. For segmen- tation tasks (contour and knots), we evaluate the Dice coefficient (Dice), Accuracy and Mean Intersection Over Union (mean IoU). We denoted y as final prediction and y the true value to be predicted. For the segmen- tation tasks, we denote TP, TN, FP, FN respectively the number of true positives, true negatives, false positives and false negatives between y and y. All the evaluation metrics adopted in our experiments could be formulated as follows:

prediction of tree semantic features in X-ray images. The proposed methods include three end-to-end pipelines that perform respec- tively the tree centerline regression, the contours and knots seg- mentations. The different results obtained have demonstrated the efficiency of this methodology and mainly its robustness on new unseen samples, which supports the relevance of deep learning based approaches for these tasks. These results also highlighted the generalization capacity of the models on different species with various shapes and sizes, despite the limited number of annotated data.

