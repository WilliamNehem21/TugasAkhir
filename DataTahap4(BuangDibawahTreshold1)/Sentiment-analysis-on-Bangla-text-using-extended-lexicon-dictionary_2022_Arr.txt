the Bangla text for predicting opinions. In this paper, we combine rule- based with lexicon dictionary approach and several hybrid DL models to predict the text sentiment from Bangla text. The key contributions of our article include (i) the implementation of a rule based algorithm BTSC [5] for generating score from the text automatically with the help of categorical weighted lexicon data dictionary (LDD), (ii) Aggregation of our proposed BTSC polarity with our input text corpus and building a word embedding model (Word2Vec) in three dimensional space [128d, 200d, 300d] for learning representation in order to fit and train on DL models, and (iii) Developing several combinations of hybrid novel DL models of long short term memory network (LSTM) known as hierarchical attention based LSTM (HAN-LSTM), Dynamic routing based capsule neural network with Bi LSTM (D-CAPSNET-BiLSTM) and bidirectional encoder representations from Transformers (BERT) LSTM with customized proper training and setting hyperparameter tuning factors. Our paper is structured as follows: Section 2 provides a survey of SA using DL. Section 3 discusses the methodology of our research work which includes a text preprocessing mechanism to fit the data in the neural network model. In Section 4, a description is provided for the detailed experiments of the proposed models. Section 5 shows the per- formance results of the proposed model and compares the results with the existing research. Finally, Section 6 provides concluding remarks.

In this section, we sketch out the available methods with taxonomy which explore the influences on the several DL architectures and discuss how those methods are enhancing to operate in SA. In the interdisci- plinary domain of NLP, sentiment classification was portrayed in [6], described a connection between subjectivity detection and polarity classification. In [7], authors showed a neural probabilistic model for learning simultaneously a consecutive representation of words and a probabilistic function to the word sequences. A simple one layer based convolutional neural network (CNN) approach is given in [7] to conduct sensitivity analysis on the text. Artificial neural network (ANN) does not work in large scale of inputs; however, CNN or Hybrid based CNN i.e., Dynamic CNN (DCNN) [8], Very Deep CNN (VDCNN) [9],

variable-size convolutional filters i.e., (MVCNN) [10] model can do much better. DCNN uses a dynamic K-max polling and a global pooling operation over the text sequence, while VDCNN and MVCNN use differ- ent dimension of word embeddings on multiple filter sizes respectively in character and text level. Recurrent Neural Network (RNN) is efficient in doing words or sentences as an unseen input on the network by prop- agating weight matrices over the time steps [11]. As RNN has problem of vanishing gradient descent, gradient explosion and lack of back prop- agation, those are mitigated in a modified version of RNN such as Long

Short Term Memory Network (LSTM) [12], Bi-Directional LSTM [13], Asymmetric Convolutional Bidirectional LSTM (AC_Bi-LSTM) [14], Re- current Convolutional Neural Network (RCNN) [15], Gated Recurrent Unit (GRU) [16]. Hierarchical Attention Network (HAN) based mecha- nism [17] on Bi-GRU [18] and LSTM [19] are also applied for document text classification because it works on between the hidden (encoder and decoder) layer to give weighted sum all features fed as an input. A recent NLP task, Transfer Neural Network BERT is published by the Google researchers [20], which learns contextual relation from words or text is also applied for SA [21].

the core word as annotated polarity with sentence or phrase sentiment strength. In [33,34] authors build a sentiment detection mechanism from tweets by using sentiment lexicon and according with a linguistic rule-based approach [35]. To the best of our knowledge, SA using categorical weighted LDD and rule-based algorithm BTSC in Bangla text with comprehensive DL approaches is not used yet.

Fig. 1 shows the pictorial representation of our full approach. The construction of LDD and BTSC algorithm is taken form a study [5]. Although we will not deep dive into the core details like mathematical description and construction of the neural network architecture, we will summarize our approach of of the neural network model used in our experiment.

In classification of text or images data augmentation technique is used for improving the performance of DL models. In our experi- ment, we have used lexicon data dictionary (LDD) from our previous work [5]. We have done prerequisite preprocessing part in building LDD from dataset. It includes like noise reduction, substitute words in lexicon, words shuffling mainly used for short text which is mostly related to data sampling analysis [36]. BTSC is used for detecting score from large text that is why we do not need any hybrid data augmen- tation method for generalization our text. By doing word shifting in sentence that increases the data in training samples. We have used categorical aspect-based dataset (cricket) [37] that means a comment

According to this paper [5] we preprocess our data by removing stop words, unnecessary characters, performing tokenization, stem- ming, parts of speech (pos) tagging operation. We have collected data from Github repository [38] and used cricket dataset for conducting our experiment. However, in order to represent the text into neural network, we used a tensor-based matrix representation of the cor- pus (review) with its polarity together. For comparing to other text representation mechanisms, this sparse dense matrix takes less mem- ory for fitting in neural network. We employ the Tensorflow neural network libraries simultaneously with Keras [39] for preprocessing our data. We use Keras tools tokenizer, text_to_sequences [40] and pad_sequences [41].

We tokenize the words of our training data for keeping a maximum number of words, text_to_sequences method to map the tokenized words in our vocabulary in a numeric representation. Then we find a maximum length (maxlen) of the text over encoded sequences. Finally, the resulted encoded sequences need to be the same length (maxlen value) by following pad_sequences approach. Extra 0’s will be padded if the sequence is longer than the encoded sequence. Finally, the output of tensor data shape is [iconpusLength, jmaxlen], where indexes i and j denote as row and column, respectively. For example, Table 1 shows the full demonstration of data preprocessing for neural network training.

The difference in our attention-based neural network data pre- processing [39] is dividing each sentence as sequence followed by sentence piece tokenization. This sequence is encoded as a numerical vector representation. We find the maximum length (maxSentLen) of each raw text sentence piece tokenization [40] for specifying out our tensor data array length for training purposes. We count the maximum sequence length (maxSeqLen) in every sequence for padding over data. We padded over the sequence into extra 0’s if the sequence is longer rather than the encoded sequence [41]. Finally, the output of tensor data shape is three dimensional [iconpusLength, jmaxSentLen, kmaxSeqLen], where indexes i, j, k denote respectively as row, column, height. Here Table 2 shows the whole process for attention-based mechanism data preprocessing in training on neural network approach.

For preprocessing on Transformer neural network BERT, there are some special tokens in pre-trained language model. In our experiment, we used Bangla Bert base form huggingface library [42,43], a PyTorch version to preprocess our text for learning in transformer encoder network. The special tokens are showed in Table 3. [CLS] tokens are at the beginning of the sentence, [SEP] tokens are at the ending of the sentence and [PAD] tokens are to pad and truncate the sentence in maximum length of sentence in the corpus. First, we tokenize the sentence text using the transformer package BertTokenizer [44]. We use the encode_plus [45] function to generate token_ids, then convert_ids

practicable in deep neural network model which captures the semantic relations between words by calculating the co-occurrence of words in a given corpus. It contains two models: a continuous bag of word (CBoW) [46] and Skip-Gram (SG) [47]. The procedure of CBoW model is to portend the current or target word from the neighboring co- occurrence word, whereas SG model portends the entire context word from the target word. The basic difference on these two models is that, in each target–context pair, a newly annotation is considered in SG model whereas the entire context as one annotation is considered in CBoW model. As our training data is relatively small, we work on SG algorithm to represent words in n-dimensional vector space. We build

CNN is a type of feed-forward neural network in the field of com- puter vision that consists of convolutional, pooling and fully connected layers. For text classification, raw text must be represented as a vector in the input layer (followed by Table 1). After a series of convolutional stacked with multiple filters and pooling operation, the model has an activation function in the neural network. Our experiment uses a simple CNN for classifying text because it can extract the features from global information with the help of a convolutional layer. We add an embedding layer with vocabulary size, maximum input length of the text, embedding size and a weight of embedded matrix with 128d. Then we apply a learning sequence on to our vocabulary by using a convolutional 1D layer with 300 filters, kernel(k) size of 5(k

learn the weights for applying in the neighboring words in tensor input data. For effectively operating in the learning rate, we use a SpatialDropout1D parameter with 0.5, which drops the 1D feature from the embedding layer. To eliminate the overfitting problem, we use a Dropout regularization technique with 0.5. As our CNN model is sequential, we add batch normalization layer for learning efficiently from previous output layers. Finally, we add a dense layer with Sigmoid activation function because we are doing a trinary-based classification.

with 49 filter size and convolutional 1D with (64*50) size. A flatten fully-connected layer is added with a hidden layer. Dropout layer is used before the independent weights with 50 neurons having ReLU activation layer. Finally, each neuron from the fully connected dense layer is fed as output to the sigmoid layer with three neurons.

Difference form DCNN we have used a three dimensional word em- bedding layer [128D, 200D, 300D] having with ZeroPadding1D(filter_ size -1, filter_size -1) add on three convolution1D layer with filter iteration as 3, 4, 5 sizes and GlobalMaxPool1D except k-max pooling layer. After three iterations, we get three layers (Layer_1, Layer_2, Layer_3) concatenated. This flatten the merge layer with l2(0.01) reg- ularization, dropout of 0.5 and finally attach a three dense neurons of fully connected output with sigmoid activation.

RNN is a feed forward neural network for sequence modeling and data in which the output depends on the previous state. It maintains new state information during iteration over the sequence of elements and feed back to the previous layer to capture the correlation between current and previous time step. In our experiment, we use a simple RNN with 32 layers. At some timestamp, the previous input is fetched from the previous hidden layer and feed back to the current input of the current hidden layer. A SpatialDropout with 0.4 is plugged on the previous RNN layer. After the RNN layer, we add a BatchNormalization, Dropout with 0.4 and GlobalMaxPool1D sequentially. Finally a three connected layer with sigmoid activation function is added to the Dense layer.

information need to update or ignore. The forget gate decides what part of the information needs to be removed from the previous cell state of the previous hidden layer. The output gate concatenates the input with sigmoid layer and decides what part of the current cell state through a tanh function and multiplies it. Our LSTM model consists of 32 unit hidden layers and Unlike RNN, at some timestamp, the

Bi-LSTM follows LSTM architecture, except it works on inputs in two ways one is left to right (capturing Forward Context), and the other is right to left (capturing backward context). It detects the feature from both past and the future context in sequential modeling. Same as our previous LSTM network, we use LSTM of 32 units in a bidirectional way, having a dropout of 0.2 and recurrent_dropout of 0.1. In the Bi- LSTM network, there are two states to resolve both contextual relations in left to right (Forward) and right to left (Backward). At each times- tamp, each hidden layer output is produced along with memory cell state and pass it to a convolutional1D layer of 64 filters of kernel_size of 4 and the rest of the network is followed by the previous LSTM network.

AC_Bi-LSTM layer is a hybrid model combination of CNN and LSTM approach. In our sentiment classification, we applied that hybrid model. In our experiment, we use a 128D word embedding layer, which iterated over with convolution1D layer with 100 filter size, kernel_size of 2 with ReLU activation layer along with another convolution1D layer of 100 filters and 30, 40, 50, 60 sizes of the kernel with ReLU activation layer. This is called asymmetric because of having different kernel sizes on the same filter and activation layer unit. Then these two different layers of conv1d are merged, and the input (xt, xt+1, xt+2 . . ., xt+n) is passed to the LSTM layer of 32 units and the rest is followed by the previous LSTM network.

Another Hybrid model we used for sentiment classification is com- posed of four blocks with 32 units of LSTM layer with multiple recur- rent convolutional units (conv1D). We applied four conv1D having with filter size of 100, kernel size of 2 and activated with tanh layer and each conv1D layers connected with each LSTM layer. This layer block is sequentially connected with another block layer. A flatten with 50 neurons, ReLU activation layer is forwarded from Bi-LSTM block. Then, it is finally attached with three dense neurons of fully connected output with a sigmoid activation function.

Similar architecture of LSTM where GRU consists of only two gates: update and reset gate and having a memory of only one state, which is a hidden state without considering a separate cell like LSTM. From a series of sequential inputs, update gate helps to learn long-term dependencies and to determine what amount of information from the previous hidden state needs to forward. Whereas reset gate is super- vised to learn short-term dependencies and to generate how much information needs to forget. Same as the LSTM network, we use a GRU layer of 32 units. After GRU memory, we add a convolutional1D layer with 65 filter size, kernel_size of 5 and having a golort_uniform regularization of kernel_initializer. Then sequentially add a Global- AveragePooling1D and GlobalMaxPooling1D layer. Finally, these are concatenated with three neurons of the dense sigmoid layer activation function.

of 0.2 and recurrent_dropout of 0.1. As similar form Bi-LSTM, Bi-GRU network has two states to resolve both contextual relations in left to right (Forward) and right to left (Backward) except maintaining no cell state mechanism. At time stamp, each hidden layer output is produced and pass it to a convolutional1D layer of 64 filters of kernel_size of 4 and the rest of the network is followed by the previous GRU network.

Attention mechanism has been designed to increase the RNN model’s ability to produce better representations of a corpus and capture long- term dependencies at a low computational cost. This mechanism is applied to deploy the model to focus or attend over the important part of a text rather than encoding the full sentence length. The main objective of the attention mechanism is to identify each hidden state’s significance and provide a weighted sum of all the features matrix fed as input. Our experiment uses a Hierarchical Attention neural network (HAN) to conduct our SA in Bangla text.

The previous model in this methodology works on only sentence- level encoding; however, HAN work on two level encoder networks i.e., word and sentence encoders. It formulates the text as a hierarchical structure on word and sentence level attention in order to capture compositional features, hierarchical dependencies from a sequence of input as well as it contributes to the polarity of a text. A document is

spitted by a number of sentences and each sentence word are tokenized to transform into a vector, and then these vectors are used as an input matrix in the neural network. Authors [12] proposed a hierarchical attention-based structure for word and sentence encoder. The word encoder propagates the information from the hidden layers on the word level attention and forwards it to the sentence encoder. Then this information is processed by the sentence encoder hidden layers, and the output probabilities are predicted at the final layer through by the sentence attention layer. Here the sentence structure is formulated by the word attention layer by adding appropriate weights with the help of individual linear hidden layer, and sentence attention layer summa- rized the alignment of the sentence by extracting the relevant context of each sentence which classifies the document. The preprocessing of our text encoding sequence is followed by Table 2. The context can be achieved by a bidirectional RNN model. We use a Bi-LSTM in our HAN mechanism, shown in Fig. 2.

Capsule neural network is a group of neural network which solve the invariant of local feature problem of CNN pooling or max-pooling operations by providing vector output capsules especially in dynamic routing algorithms. The computational complexity i.e., reducing matrix dimension, intercepts the various features, is captured by the pooling operation while losing a lot of data based on spatial relationships; however, without changing each feature. Again, CNN does not capture the hierarchical relationship between the local and global features. With the help of dynamic routing, it establishes the connection on spatial relationships between entities by mapping nonlinear vectors. This mapping transmits the capsule from lower level to upper level by iterating a number of routing loops based on a weight coupling coefficient. The weights coupling coefficient determines the leaning representation of which lower-level capsule will be forwarded to the upper level capsule layer. It also detects the similarity between vectors which also predict the lower and upper-level layer capsule. In our

scaling) the output vector (vj). By using this activation function, the output vector (vj) direction will not fluctuate if this vector length has more than 1. Then this higher level capsule vector (vj) is activated by the LeakyReLU function and finally densed by three neuron output classification. The full process is demonstrated on Fig. 3

Transformer belongs to an encoder–decoder architecture model hav- ing attention mechanisms [49] that are used for transfer learning in the field of machine translation as well as in NLP task and also leverage with long term dependencies finer than as a replacement of other conventional sequential model i.e., RNN, LSTM, GRU etc. In transfer learning, a model is trained on huge unlabeled content corpora uti- lizing self-supervised learning, and this pretrained model is negligibly balanced during fine tuning on a particular NLP task [50]. It is also more potential in training the model by removing the sequential de- pendencies of the past tokens. BERT recently developed by Google [20], an encoder based transformer architecture for language modeling that is used for dynamic embedding in NLP task which consider the both current and previous token on both left and right in a bidirectional way. As a contextual model, Bert generates a representation of each word which is based on every other sentence; however, in static em- bedding i.e., Word2Vec model generates a single word embedding representation for each word in vocabulary.

In our sentiment classification, we use a BERT-BASE model with number of 12 transformer blocks, 768 hidden layers and 12 attention heads to generate contextualized embeddings. The input layer of BERT is a vector of sequence token along with special tokens showed in Table 3. As, LSTM reads text input sequentially, whereas BERT takes the entire tokenization of words at once. In our experiment, we build as sentiment classifier by using huggingface library to fine-tune with pretrained BERT model [42] on the upper layer of LSTM, showed in Fig. 4. From this library, we install the transformer version as 3.0 and load the BERT classifier and tokenizer for input processing.

tokenizer and that tokens converted into token_ids and with atten- tion_mask showed in Table 4. BERT uses a self-attention mechanism over the input sequences, showed in Fig. 4 which predefines the trans- former for keeping pace with the relevant words from the inputs. In attention block of BERT transformer, it generates each attention head (ATHi) as a multi-headed self-attention from the input sequences (x1,x2,x3, . . . , xi). This sequence (xi) is multiplied with three weight

After construction of those models, we compile each model with our word embedding matrix [128D, 200D, 300D] as per requirement by setting the parameter loss function as categorical_crossentropy and optimizer as adam at a learning rate on different point shown in Table 5. Table 5 shows the summarization of our different parameters on each model. After compiling the model, we fit the model with our training and validation data having batch size of 256 with 50 epochs except using batch size of 16 with 50 epoch in BERT-LSTM model.

We conducted a total of fourteen experiments to offer a reasonable comparison of recent DL algorithms and traditional methods. Table 6 shows the experimental results of each individual model which is obtained by setting the optimal values for each parameter in the model through trial and error. As for the sentiment classification, different models outperformed on different learning rate (lr) parameters to achieve outstanding results. From these results, researchers can identify which is perfect for their sentiment classification task in the Bangla low resourced dataset.

recall, and 79.86% F1-score. VDCNN and MVCNN both are complex models than CNN and DCNN because of using three dimensional (D) [128D, 200D, 300D] word embedding layers. CNN achieves 74.50% accuracy which is better than the 73.49% accuracy of CNN model.

It is shown in Fig. 5(i.a) that at about 20 epochs, CNN model achieves the highest testing accuracy; whereas as shown in Fig. 5(i.c), DCNN decreases testing accuracy from point 25 epochs. It is shown in Fig. 5(ii.a) and (ii.c) that MVCNN and VDCNN models have huge deflection between training and testing accuracy because of having a

high dependency on using a multichannel layer with different iteration filters [filter kernel size = 3, 4, 5]. Here, MVCNN uses two dimensional [128D, 200D] and VDCNN uses three dimensional [128D, 200D, 300D] word embedding layers. We keep the dropout rate at 0.5 on each layer but we change kernel size when variable size of zero padding1D is added for performing spatial dimension to the output.

When we add a number of nodes in the layer in our model, the capacity increases that means accuracy, precision, and recall increase. As our training data is small, our model is pretty small; however, increasing model layers can drive to a more precise model. If more training data are given in the model, the larger the model should be. In our experiment, multilayer perception of CNN is applied in DCNN, VDCNN and MVCNN models; as there is no bound to use a specific number of layers so this stacked layer is susceptible to generalize our model better. By adding continuous layers of convolution and pooling operation in CNN, it might lose spatial information on classifying data.

Sequential models such as RNN and RCNN both achieved similar test accuracy of 73.83%; however, RNN achieved 78.88% precision which is greater than that of RCNN. Besides in preserving LSTM and Bi-LSTM, where Bi-LSTM model performs well on cricket dataset having optimal accuracy of 78.14%. However, LSTM model performs well with a testing precision of 78.53% that is greater than BiLSTM model.

As GRU intends in the last hidden state to represent the sentence which means modeling the whole sentence causes neglecting main key parts of words, this might result in the incorrect prediction. From Table 6, while learning rate is so high in GRU and Bi-GRU models, training and testing accuracy, precision are not getting higher than LSTM and Bi-LSTM models. At most 75.84% accuracy is achieved on LSTM model with an average 71% precision, recall and F1-score values. GRU limits the stream of data just like LSTM unit; however, except utilizing a memory unit in this case LSTM model performs well on this dataset. For this reason, we applied LSTM model as hybrid layer on attention, capsule and BERT based models.

In Fig. 5(v.c) and (vi.a), both GRU based models have similar cures with respect to testing accuracy of 75.84% and 75.17%. Bi-GRU model intersects on about at epoch point 5 and 35 that means it has both bi-directional dependency to co-relate words in text.

The attention level in word and along with sentence increases the model accuracy with respect to other CNN, RNN type models. Calculation of attention vector which is co-related to word and sentence level that determines the less content for constructing the document representation. The main advantage of Capsule module is to resolve the max pooling level conversion for feature extractions that means the im- provement of CNN and RNN type models. Because losing the informa- tion in polling layers might cause in lesgs accuracy. Again, augmenting the compositional capsule network with k-clustering mechanism will improve the classification accuracy of our HAN-LSTM model.

= 1e-5) producing maximum accuracy of 84.18%, precision of 86.45% from other models. We add a LSTM layer on pre-trained BERT model, which amplifies the core advancement in classification accuracy over embedding models. That means BERT is in fact more able to represent semantic and syntactic features. This language model representation achieves substantial improvements over other models at a state of art result compared to Word2Vec model.

Next, we compare our work with other existing deep learning and machine learning methods. Table 7 compares our work with others in terms of accuracy. In [23], authors achieved 55% accuracy with three category sentiments on above nine thousand social comments and in [22], authors showed 82.42% accuracy on four thousand movie review dataset in two category sentiments in LSTM network, whereas our LSTM model achieves 74.16% accuracy. Similarly in [24,54] LSTM network achieved 65.97% and 46.80% accuracy, respectively, in [32] attention-based LSTM (A-LSTM) achieved 65.97% accuracy; however, our hierarchical attention-based LSTM (HAN-LSTM) achieved 78.52%

Deep Learning model complexity implies to investigate the gener- alization capability and limitation of neural networks on the training process. Our hybrid DL models are hyper-parameterized but it has very little effect on model complexity [55]. Model complexity indicates how the neural network model expresses its behavior on distribution function or activation function [56], prevents overfitting on by adding L1, L2 regularization to the loss function [57] and the amplification coefficient (wij) which is defined by the multilayer perception of hidden neurons. Selecting an activation function i.e., ReLU, Sigmoid, tanh in network hidden layers which is an active module for learning and computing complex task by taking piecewise nonlinear transforma- tion to the input. Pooling function such GlobalAverage Maxpooling1D, GlobalMaxpool1D with the use of variation of filter size on feature maps is needed to reduce fixed size vectors. However, the size of the DL model impacts on model complexity i.e., number of filters, kernel size,

hidden neurons, dropout rate, depth and width efficiency of model, training and testing time also. This is partially noted in Table 5. In our work, we have limited our experiment in detecting accuracy of SA in Bangla text with the help of LDD and BTSC. In future, we will evaluate the complexity of our deep learning algorithms.

In this paper, we investigated the most noteworthy work on sen- timent analysis on cricket reviews as a low resourced Bangla dataset using various deep learning architectures. This empirical study is an initial dive on lexicon dictionary-based approach on neural network mechanism. We measured the performance of our work based on accuracy, precision, recall and F1 score. Firstly, we developed a lexicon- based approach and used the BTSC algorithm to detect polarity from preprocessed text from our previous work. Then we implemented the popular basic learning models i.e., CNN, DCNN, MVCNN, VDCNN, RNN, RCNN, LSTM, Bi-LSTM, AC_Bi-LSTM, GRU, Bi-GRU, HAN-LSTM,

D-CAPSNET-Bi-LSTM, BERT-LSTM with setting as a customized and fine-tuned with hyperparameters on individual models. We found that LSTM had given better results over CNN and RNN type models. Then we used attention, capsule, transformer-based mechanism by adding LSTM layer, and the results showed significant improvement, which is indeed effective in the sentiment classification effect. By using atten- tion, capsule mechanism, we proposed some hybrid DL models, termed as HAN-LSTM and D-CAPSNET-Bi-LSTM along with semantic learning representations (word2vec) having excellent performance in terms of accuracy, precision, recall and F1-score. Finally, a hybrid model termed as BERT-LSTM was used for the classification task, and it surpasses others in terms of accuracy and precision.

This LDD dataset will be useful for future research. Bangla cricket review dataset is relatively small with respect to benchmark dataset and there is lack of enough large training corpus in Bangla domain, this is the main drawbacks in sentiment analysis tasks in Bangla. We have identified trinary polarity in cricket reviews since this dataset is not properly balanced data; so, using balanced data for each polar- ity in training process might enhance accuracy of prediction results. Because increasing the amount of training data can assist to promote the accuracy of prediction results. We could not use a well pretrained model due to lack of hardware resources, so in the future, we developed a large corpus and trained it with various parameters or layers with a tuned model and showing individual model with confusion matrix. Despite the fact that we gained satisfactory result, it still has a scope for further improvement. In the future, we will conduct our research using

memory augmented network. This will be done by combining external memory of neural network and other transformer models i.e., ALBERT, ELECTRA, RoBERT, DistilBERT along with multilayer, and also hybrid capsule and multi headed attention layer-based models with other word embedding learning representation mechanism such as Glove, fastText, etc. We will design a graph neural network to capture internal and external graph structures of NLP. Finally, this research work will contribute in the improvement of emotional sentiment analysis on Bangla domain corpus.

Nitish Ranjan Bhowmik: Conception and design of study, Acquisi- tion of data, Analysis and/or interpretation of data, Writing – original draft, Writing – review & editing. Mohammad Arifuzzaman: Concep- tion and design of study, Writing – review & editing. M. Rubaiyat Hossain Mondal: Conception and design of study, Writing – review & editing.

Yang Zichao, Yang Diyi, Dyer Chris, He Xiaodong, Smola Alex, Hovy Eduard. Hierarchical attention networks for document classification. In: Proceedings of the 2016 conference of the north American chapter of the association for computational linguistics: human language technologies. 2016. p. 1480–9.

Reckman Hilke, Baird Cheyanne, Crawford Jean, Crowell Richard, Micciulla Lin- nea, Sethi Saratendu, et al. teragram: Rule-based detection of sentiment phrases using sas sentiment analysis. In: Second joint conference on lexical and compu- tational semantics (* SEM), volume 2: proceedings of the seventh international workshop on semantic evaluation (SemEval 2013). 2013. p. 513–9.

Nitish Ranjan Bhowmik was born in Bangladesh. He received the B.Sc.(Honors) degree in Computer Science & Engineering (CSE) from Dhaka University (DU), at Dhaka, Bangladesh. He is currently pursuing the master’s degree in Information and Communication Technology(ICT) with the Bangladesh University of Engineering and Technology (BUET). His research interests include data mining, text mining, natural language processing, machine learning and deep learning.

