Due to advancements in technology, many integrated circuits are fabricated to develop an artificial system that could perform "intelligent" tasks similar to those performed by the human brain. Many of them use off-chip learning method either by analog hardware or massively by parallel computers. This proposed work is about a trainable neural chip using Field Programmable Gate Array (FPGA) as this helps in learning capability by exploiting the inherent parallelism of neural network. By this fast prototyping is possible for real-time applications, such as speech recognition, speech synthesis, image processing, pattern recognition and classification. In this work on-chip learning method is designed for standard benchmark XOR problem using back propagation based multilayer perceptron and is implemented in VIRTEX-E FPGA using VHDL. The design works at 5.332 MHz and the total gate count is 4, 73,237.

One of the emerging applications of Very Large Scale of Integration (VLSI) is standalone neural network chip. This stand alone neural network chip could surpass the capabilities of conventional computer-based pattern recognition systems and they are used in pattern classification, data processing, electrical load forecasting, power control systems, quantitative weather forecasting, games development, optimization problems etc. [1]. Artificial Neural Networks (ANNs) are powerful tool for modeling especially when underlying data relationship is unknown. It offers a completely different approach to solve the real-time problems and they are known as sixth generation of computing techniques [2].

Most of the existing neural network applications in commercial use are normally developed by software and sequentially simulated on a general-purpose processor [3]. This is the easiest but least favoured method, as the time taken for training is long. It is suitable for the networks which need not to be adapted to new data and used only for investing the capability of modeling the network [4]. However, there is some specific real- time application such as streaming video compression, bioinformatics which demands high volume adaptive real-time processing and learning of large non-linear dataset within a stipulated time [5]. Therefore, it necessitates the design of neural network hardware with truly parallel processing capabilities and reconfigurability for future extendable applications [6]. This can be achieved by on-chip learning method. It is a desirable method since it develops a way to make a stand-alone neural network chips. In on-chip learning method, hardware keeps itself ready to fix the architecture depending on the weight, to obtain the required performance by taking the full advantage of their inherent parallelism and runs faster in the order of magnitude than software simulation [7].

This paper aims at the design of on-chip learning Multilayer Perceptron (MLP) based neural network with Back Propagation (BP) algorithm for learning to solve XOR problem. Section 1.1 reviews the architecture and Section 1.2 describes the learning algorithm of neural network. Section 2 deals with the implementation of on- chip learning followed by discussion of results.

Multilayer perceptron is one of the widely used universal approximator and is suitable to solve the non- linear separable problem [10]. Architectural parameters such as the number of inputs per neuron, weights, activation function, synaptic interconnection and number of layers are to be specified in ANN structure as they play significant role while learning [11]. Logical XOR function has two inputs and one output based upon which MLP is structured as in Fig 1.The ANN topology requires solving a non-linearly separable

The main objective of learning is to achieve good generalization that is able to predict the output values that are associated with a given input value [12]. The back propagation method is a supervised learning algorithm that is widely used for training the multilayer perceptron. It adjusts the weight values that are calculated from input-output mappings and minimize the error between the correct output value and target value. It iteratively computes the values of weight using gradient descent algorithm [10]. For the MLP with input vector xi, output vector yj the weight is calculated by gradient descent rule and is given by (1)

where wi,j=  j xi,j which is called as magnitude of weight updates. If the output is correct (t=y) the weights are not changed (wi,j =0) otherwise the weights wi are updated. This training process is repeated until the output error signal falls below a predetermined threshold value or Mean Squared Error (MSE).

As the logical XOR problem is used to benchmark the learning ability of ANN, this work utilizes on-chip propagation learning algorithm for solving XOR using VIRTEX FPGA. Fig 2 shows the complete BP algorithm implementation module. Forward pass is controlled by forward phase controller and backward pass of the learning process is controlled by backward phase controller. Global controller is used to synchronize the all modules.

Each neuron in all layers is stimulated simultaneously and forwards the output to next layer. Finally the output is produced at the output layer by applying the activation function to calculate the value of weighted sum. This final output is given to the error calculation module to find MSE. Error comparison module of global controller is used for checking the condition of learning. If the error value is greater than the threshold value, global controller sends enabling signal to backward phase controller. The backward phase of BP algorithm consists of two main important phase

At first gradient value of output neuron is calculated and back propagated to previous hidden layer for its gradient calculation. After the gradient calculation, weight updating process takes place simultaneously for each layer and every weight of neuron. The new updated value is stored in RAM for future use. Thus completion of weight updating process indicates one complete training set and these two stages are repeated for all other input patterns until the network is sufficiently trained.

-E using Xilin14.5 ISE. Once the design is completed, the top module is synthesized and verified for its timing and functionality. The Fig 3 & Fig 4 illustrates the training phase of the neural network in forward and backward pass respectively. From the figure it can be noted that the weight updating process is completed according to the error calculated in forward phase. The MSE ensures that the network is sufficiently trained. The resource utilization is given in the Table 1.

FPGA retains a high degree of flexibility for device reconfiguration and reduces the hardware development cycle. The proposed work is coded using VHDL and successfully simulated in MODELSIM 6.3f simulator and implemented in VIRTEX E FPGA using XILINX ISE 14.5 ISE. This work sustains the internal parallelism of artificial neural network and the design works at 0.6053315 μs. The design have utilised 87% of LUTs and 98% of slices. The result showcase the suitability of enhancing the MLP architecture with back propagation learning that can suit for real-time applications. Future work will be focused on designing the complex ANN to solve real-time problems.

