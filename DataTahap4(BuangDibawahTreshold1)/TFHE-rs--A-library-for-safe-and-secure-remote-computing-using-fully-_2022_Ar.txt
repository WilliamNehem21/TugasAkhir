TFHE-rs supports creating keys of different security levels. Choosing pa-rameters for encryption schemes based on LWE is complicated, as choosing a parameter set with incompatible values might lead to an insecure or slow sys-tem. Our implementation currently supports the two parameter-sets defined in TFHE-c, which have estimated security levels of 80-bit and 128-bit, known as bit security [28]. However, the key size is not directly proportional to the secu-rity level, as in AES, where a security level of 128-bit equates to a 128 bits key size. In TFHE, a security level of 128-bit equates to a ~ 24 MB bootstrapping key [29]. The default parameter set in our library is the 128-bit security version as cryptographers do recommend 128-bit security to be safe until theo- retically the year 2090 [28].

All data structures that might need to be transmitted are serializable and deserializable, using the Rust package Serde.3 Serde designs seri- alization and deserialization so that any data structure that implements one of two traits can be serialized or deserialized to one of the tens of different serialization for-mats supported. This is unlike the TFHE li- brary, where serialization of data can only be done through specific functions for reading and writing files and streams. These functions are somewhat limited and do not allow the developer to specify the serial- ization format. In TFHE-rs, a macro allows deriving the implementation automatically, such as (line 3 highlights derive macro):

TFHE-lib provides several different FFT processors, including FFTW, which claims to be the fastest free FFT implementation available.6 TFHE-rs uses the RustFFT crate, which does not currently use any Single Instruction, Multiple Data (SIMD) instructions, only pure Rust, and therefore cannot use FFTW. To factor out potential unrelated perfor- mance benefits that stem from the usage of FFTW, TFHE-lib is linked with the Nayuki project’s portable C implemen-tation.7 Furthermore,

The bootstrapping procedure takes an LWE sample as input, along with an output message encoded in the message space and the boot- strapping keys. As shown in Fig. 1, the average execution time of a single bootstrapping procedure is 1.1937 s, significantly higher than the implementation of the original paper taking around 53 ms on similar hardware [29] and improved work leading to around 13 ms [25].

However, the TFHE affords some optimizations we have not imple- mented in TFHE-rs. Firstly, it uses the Lagrange half-complex repre- sentation, which reduces the number of multiplications required in the bootstrapping procedure by nearly a third. It also reduces the number of external products required, the expensive operation performed in the bootstrapping procedure. Secondly, the original implementation uses FFT processors based on SIMD instruction sets such as AVX, providing large speedups. The outliers observed in the figure are, similarly to the outliers in the decryption and encryption procedures, likely related to interactions with other processes using the CPU. As most of the samples fall in a near-identical spot, it is reasonable to assume most results will lie in this range. Additionally, this procedure is deterministic and was benchmarked using the same inputs, so we assume that the outliers can

Fig. 2. The execution time of the bootstrapping operation in our imple- mentation with and without the polynomial multiplication based on FFT. The Na¨ıve red region marks the n¨aıve implementation of the polynomial multipli- cation, while the FFT blue region marks the optimized version.

Finally, we also performed the benchmark of the TFHE library with all their optimizations included. We use their spqlios FFT processor with the FMA instruction set extensions and achieved an execution time of 14.771 ms. This number is similar to their findings, but should not be compared directly to ours as it implements several more optimizations.

under conditions that make it challenging to solve. Thus, it is good to use as proof that a par-ticular system can solve problems in the domain of SMPC. The problem has several solutions, with techniques ranging from oblivious transfer methods [31], private set intersections with HE [32] to FHE.

We start by producing the binary decomposition of the two values. We use two 32-bit signed integers for this purpose. For each of the values, we decompose them into bytes in big-endian order, then decompose those into the individual bits. We use big-endian as we implemented the circuits we use to work on big-endian values. Then each bit is individually encrypted with our TFHE implementation. This results in two pairs of 32 ciphertexts representing the encryption of the two values. In a multi-key setup, the two parties perform these actions separately after completing a key-exchange protocol. Note that our implementation of the TFHE scheme does not support multi-key setups as we based it on an implementation that also did not support it. However, supporting it would only necessitate adding a key combina- tion step that scales linearly with the number of parties.

Next, we evaluate and compare the performance of TFHE-rs with and with-out the use of SGX. We repeat each experiment 25 times, timing only the relevant sections. Running with 80-bit security, TFHE-rs with SGX finished with an arithmetic mean of 90.504 s and a standard de- viation of 0.602 86 s while the FHE-only version finished in 116.08 s and a standard deviation of 2.3548 s. These results indicate that TFHE-rs is approximately 28% faster with SGX.

There is known overhead associated with SGX memory encryption and pag-ing. However, we explain the performance improvement be- tween the two ver-sions of TFHE-rs by how an SGX enclave handles memory. For this, we profiled our non SGX program using the 128-bit security parameter set, which is the one that uses most memory, with the memory profiler for Linux.8 The observed memory usage over time is

shown in Fig. 3, while the rate of allocations of deallocations are shown in Fig. 3b and c. From the figures we can see that the program constantly consumes around 100 MiB of memory, and has a rate of allocations and deallocations of about 100 000 per second.

cantly im-pacts performance. The hybrid program executes roughly 72.5% slower, and the FHE only using dlmalloc for allocation is 71.7% slower than the ones with 80-bit security. As mentioned, this is because ciphertexts in the TFHE scheme grow substantially in size with increased security and thus increases the required computation. As for the per- formance difference with and without SGX, the ex-ecution time differ- ence of only 3% is low. Thus, a user would benefit from using the SGX version, which covers the integrity weaknesses of the FHE.

Why the SGX version is faster than the program using only FHE is un- clear. However, the standard deviations measured for the FHE-only version are higher, as seen in Fig. 4, which implies that the perfor- mances could be more similar than they appear. Another reason could be because of automatic frequency scaling of the CPU. However, turning this off yielded the same re-sults. We witnessed no other behavior, including syscalls, that could explain the performance differences. The syscalls mostly consisted of memory alloca-tion calls, which are handled by the enclave memory manager. Our program is single-threaded; it does not use any SIMD instructions, nor include randomness during the measured execution times. If we are to speculate, the performance gain might be a result of the SGX SDK optimizing some situations that are normally not possible to optimize, due to the complexity of the OS and process interactions.

Drucker and Gueron [35] state that most secure cloud database so- lutions tend to provide confidentiality and integrity of data by using either a TEE or HE. They show that combining a TEE and using HE is feasible and does not need to rely on the TEE for confidentiality pur- poses. They compare their work to CryptDB [36] and MrCrypt [37], which both use Partially Homomorphic En-cryption (PHE), but lack integrity security for both code and data. Drucker and Gueron combine the PHE scheme Paillier [38] and SGX, where SGX pro-vides integrity of code and data (in addition to some confidentiality guarantees, side-channel attacks aside). The Paillier cryptosystem ensures data is private and provides confidentiality, even within the enclave. The combination allows the system to place less trust in Intel, as the Paillier cryptosystem guarantees confidentiality for the encrypted data while allowing some computations. In their experiments, they only experience

TEEFHE [40] is an example of combining FHE with SGX by per- forming the bootstrapping step within SGX. They use the BGV [27] scheme implemented in Simple Encrypted Arithmetic Library (SEAL) and modify the library to run within SGX. They distribute the work across several nodes, where some nodes process the ciphertexts using homomorphic operations in untrusted environ-ments. When nodes require the bootstrapping procedure, they transmit them to a node with the SEAL library running within SGX. SGX enclaves perform encryption and decryption, preserving data and code integrity and confidential-ity, as they do not consider side-channel attacks. Decrypting and encrypting a ciphertext removes the encoded noise and refreshes the ciphertext, effectively doing the same as a bootstrapping operation, but at a lower cost. As the un-trusted compute servers perform computations on the encrypted data, they do not preserve data integrity in the case of an attack.

problems re-lated to side-channel attacks and cloud hosted computa- tions. Chen et al. [41] propose a software framework that detects side-channel attacks by a privileged attacker, such as a malicious or virus-infected OS. Some types of side-channel attacks that exploit access-pattern information leakage can be protected against using techniques such as ORAM [8]. ORAM can be seen as a compiler that transforms memory accesses of a program into a program where the distribu-tion of memory accesses differs (is independent) from the original program while preserving the semantics of the program. Path ORAM [42] improves upon reg-ular ORAM and has a low space over- head and in some cases, asymptotically improved performance compared to earlier work. Circuit ORAM [43] further improves the techniques and gives an implementation with a complexity near the theoretical lower-bound.

ZeroTrace [44] is an example of oblivious primitives in action. Se- curity is strengthened against access-pattern side-channel attacks in SGX using a block-level memory controller to hide access patterns. Both Path ORAM and Circuit ORAM are implemented and gave in some situations only a logarithmic over-head in bandwidth costs between enclave code and ORAM servers. ZeroTrace mitigates considerable weaknesses in SGX as it protects against shared resource and page-fault related attacks by converting programs into oblivious represen-tations. Another example of oblivious memory primitives in SGX is Oblix [45], an oblivious search index. The authors introduce something they call doubly-oblivious tech- niques, as it ensures that accesses to external servers as well as the

The CacheOut [6] attack exploits the fact that hardware-cache that is flushed and overwritten can still be recovered. CacheOut can even selectively choose parts of data to leak with relatively high efficiency, unlike previous attacks where the attacker could only observe the leaked data the CPU enclave was currently accessing. This attack requires hardware fixes and proves once again that SGX enclaves do not fully protect the confidentiality of data and code in enclaves, and that other protective measures are required. SGAxe [47] exploits the CacheOut

We evaluated the performance characteristics of TFHE-rs with and without an SGX enclave and found that the performance overhead is negligible. The evaluation showed that using TFHE-rs with SGX is 3% faster than a version of TFHE-rs without SGX. This result is not in line with what we conjectured, which was that TFHE-rs with SGX should be slower. Based on our experience, we conjecture that specific memory management implementations particularly affects performance. The

the dlmalloc allocator used by the Fortanix Rust EDP in the SGX setup. As such, a system with a similar setup to ours should emphasize low memory usage and experiment with different allocators to ensure that they stay within the memory limits imposed by SGX. However, the measured stan-dard deviation does account for most of the performance difference, and the benchmarks themselves take long enough for this discrepancy to be due to envi-ronmental factors in our experimental setup (i.e., due to system load). Overall, this is a positive result, as our hybrid solution is both more secure and faster.

