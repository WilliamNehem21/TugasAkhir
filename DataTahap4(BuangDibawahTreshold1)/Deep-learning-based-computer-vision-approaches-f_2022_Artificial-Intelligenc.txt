For this study, we have collected more than 100 research papers from scientific databases, including PubMed, Web of Science, and Scopus, in the area of deep learning-based computer vision. Further, we investigated all these works that leveraged deep learning-based computer vision technologies to address key agriculture tasks such as plant health monitoring, disease and weed identification, irrigation management, soil analysis, livestock management, yield estimation, etc. The main objective of this study is to evaluate the penetration of deep learning-based computer vision approaches in key agricultural problems, and this review is intended to be useful to agriculture re- searchers as well as general computer vision researchers who are inter- ested in the application of computer vision solutions to automate and solve potential agricultural problems. The practical implications of these technologies along with major challenges in implementing large-scale applications were also constructively pointed out in this study.

Computer vision possesses dual and interrelated goals. In biological science, computer vision aims to represent the human visual system using computational models, and in the engineering perspective, com- puter vision attempts to create autonomous systems that can do tasks that often human visual systems cannot perform (Huang, 1993). Com- puter vision imparts visual capability to machines through cameras, data, models, and algorithms rather than retinas and the visual cortex. Optical character recognition (OCR) technology and intelligent charac- ter recognition were some major tasks that employed computer vision to accomplish tasks such as document and invoice processing, vehicle plate detection, etc. In the early stages of computer vision research, the main focus was to build algorithms to detect edges, curves, corners,

Convolutional neural network-based deep learning architectures are popular for computer vision tasks like image classification. A convolutional neural network is a type of neural network architecture that takes input images and extracts relevant features to efficiently identify and classify images. CNN uses labels to perform convolutions and generate feature maps. The introduction of imageNet dataset that contained millions of tagged images had laid a foundation and benchmark for building advanced computer vision-based models (Kriegeskorte and Golan, 2019; Miikkulainen et al., 2019; Yoo, 2015). LeNet-5 was one of the earliest CNN proposed by Yann LeCun (LeCun

et al., 1998), led to the development of various CNN models (Fig. 3). In 2012, AlexNet architecture (Krizhevsky et al., 2012a) was found prom- ising for image recognition, and numerous new architectures such as VGGNet (Simonyan and Zisserman, 2015), ResNet (He et al., 2015), etc. were also introduced by researchers, reducing the error rate and im- proving the performance. Image segmentation approaches are quite useful for understanding what an image consists of, by dividing the im- ages into several segments. Image segmentation creates a pixel- oriented mask for each object present inside the image. This eases the image processing tasks as the important segments alone can be consid- ered for processing tasks.

The image classification mainly identifies the class, a specific image belongs to. The image classification approach is often not successful when there are multiple objects in the same image. Object detection aims to detect the location of objects in the image/video. Object detection task comprises two major components; class information and location in- formation. The location information is described by bounding boxes around the target object. Object detection architectures such as YOLO (You Only Look Once) (Redmon et al., 2016), SSD (Single Shot Multibox Detector) (Liu et al., 2016), Faster-RCNN (Region Convolutional Net- works) (Ren et al., 2016) are widely used for object detection and auto- mation across different domains including agriculture.

A generative adversarial network (GAN) is a special type of neural network used for unsupervised learning. GAN is an approach to genera- tive modeling that can learn to mimic a given distribution of data. These models effectively reduce the data into its fundamental properties or generate new data points with varied properties. The application of GANs has achieved state-of-the-art performance in many image generation tasks, such as text-to-image synthesis (Xu et al., 2017), super-resolution (Ledig et al., 2017), and image-to-image translation

The commercial seed industry is focused on the supply of the right quality seeds to the farmers at the right time in the right quantity. Filter- ing out low-quality of seeds from high-quality ones, is not only labori- ous, but it requires sophisticated equipments, infrastructure, and time (Kannur et al., 2011). The testing of seeds for their quality can indeed gain momentum by the use of computer vision technology which can extract the morphological information of different seed lots and grade it according to the internationally prescribed quality standards (Bao and Bambil, 2021). The different seed testing modules are likely to ad- dress their physical purity, genetic purity, seed health, vigour, patterns of deterioration etc., which in general may indeed cover the physical or visually attributable characters such as the seed length, shape, size, visual impairments, and presence of foreign bodies which can indeed be captured by the advanced computer vision technology (Granitto et al., 2005).

Taheri-Garavand et al. (2021) developed models for automatic identifi- cation of chickpea varieties using seed images in the visible spectrum. A modified VGG16 model was used for the identification purpose. As sorting high-quality seeds are vital for increasing yield in the breeding industry, Zhao et al. (2021) employed seven different computer vision models to accurately detect and identify surface defects. MobileNet-V2 model had shown excellent detection accuracy for the soybean dataset. There are numerous such studies done by various researchers and the seed industry is hugely getting benefited from advanced computer vi- sion models, achieving a higher level of automation capabilities. Some of the studies in this area are precisely summarized Table 1.

crop productivity (Kushwaha et al., 2022; Suchithra and Pai, 2020). Tra- ditional soil texture analysis entails taking soil samples and bringing them to a laboratory, where they are dried, crushed, and sieved before being used. For coarse textured or sandy soils, sieving is the most typical laboratory analytical method, while for smaller textured particles, a hy- drometer or pipette approach based on sedimentation theory is used (Kushwaha et al., 2022; Sudarsan et al., 2016).

With the advancement of image processing power and the develop- ment of image acquisition (e.g., cameras) systems in recent years, com- puter vision-based image analysis approaches have gotten a lot of interest in a lot of sectors, including soil science. This method collects soil images (dynamic or static) with cameras and then uses simple com- puter programmes to classify and categorise them (Fig. 7). For example, after matching textural patterns, the size of the soil particles might be estimated straight from the image. In several investigations, various image analysis-based computer vision approaches were tried.

Haralick et al. (1973) attempted to classify images received from an ae- rial or satellite source using entropy and angular moment-based tex- tural classification. Since then, the grey level co-occurrence matrix (GLCM) and its analogues have been used in a variety of remote sensing applications (Dell’Acqua and Gamba, 2003; Kuplich et al., 2005). How- ever, the greatest resolution satellite can only provide a maximum res- olution of 10 m/square pixel, which is insufficient to understand soil particle sizes. Riese and Keller (2019a) implemented three 1- dimensional (1D) convolutional neural networks: the LucasCNN, the LucasResNet and the LucasCoordConv. In addition, for the classification problem at hand, the study tweaks two existing 1D CNN techniques and compares the CNN techniques against a random forest classifier to see how well they do. Thereby, study uses the LUCAS topsoil dataset, which is freely available. The CNN method with the least amount of depth turns out to be the most effective classifier. In terms of average ac- curacy, the LucasCoordConv has the best results.

Similarly, Zhang et al. (Zhang et al., 2003) proposed a soil texture classification system that uses the wavelet transform approach to dis- tinguish between different types of soil. Wavelet transform, which is a strong image and signal analysis method due to its multi-resolution ca- pabilities, is used to extract features. A set of training instances is used to create a maximum likelihood (ML) classifier. This method of ML

Similarly, Chang and Lin (Chang and Lin, 2018) developed a compact intelligent agricultural machine which is capable of autonomous weeding and variable watering on the cultivated ground, using a combi- nation of computer vision and multitasking. The system classifies the plants and weeds in real-time so that it can weed and water while main- taining an average herbicidal rate of 90% and a deep soil moisture level of 80%. This strategy has a lot of potential because it allows for not only multitasking integration but also resource utilization in its entirety.

With the advancement in computer vision and deep learning, new promising solutions for identifying overall health status of the plants were introduced. The intelligent decision support system for identifying crop diseases (Fig. 8), water stress, and nutrient deficiencies would lead to timely control of the panic situations and eradicating the huge losses, ultimately leading to improved plant quality.

Plant stress induced by biotic and abiotic factors is expressed in the plant canopy as multiple symptoms. In case of water stress, the plant closes stomata and delays photosynthesis and transpiration activities indicating colour changes in the leaf and temperature (Nilsson, 1995). Similarly, nutrient deficiencies-related symptoms are typically visible in leaves color and texture (Xu et al., 2011). Image analysis can detect these changes in a pattern quite effectively. Deep learning-based com- puter vision approaches are viable solutions in addressing timely dis- ease identification and avoiding consultation of human experts. The availability of a large number of public image datasets such as PlantVillage (Hughes and Salathe, 2016), PlantDoc (Singh et al., 2020) have proliferated the research in the area of disease identification and many works have taken encouraging steps towards disease-free agri- culture (Hassan and Maji, 2022; Ji and Wu, 2022; Nagasubramanian et al., 2019).

Weeds are among the major factors that affect agricultural produc- tion negatively. With the focus on improving agricultural productivity, it is evident that more and more chemicals are being dumped into the environment with the aim of managing the weed growth. But for im- proving the productivity, it also requires the optimum utilization of re- sources which can only be achieved by the precise spraying on weeds. The traditional robotic weeders generally function by detecting crop row patterns and they do not rely on crop recognition for the weeding operation. If the weed density and population are large, they may ob- scure the row pattern leading to reduced efficiency of the weeders.

Computer vision approaches come to rescue at this point by accurately identifying the objects as precise spraying of weeds depends on the ac- curate identification and location of weeds. Recently, several studies were carried out by researchers on adaptability of computer vision tech- nology for the agronomic classification of plant species at the field level, viz the classification of crops from weeds, off types etc. (Sau and Ucchesu, 2019; Sau et al., 2018; Subeesh et al., 2022). Detailed applica- tion of the same in the automatic identification of plant species based on the leaf recognition pattern has been proposed for preserving and cataloguing plant species (Putzu et al., 2016) along with the botanical characterization of germplasm (Lo Bianco et al., 2017). Methods of achieving weed detection at the field level mainly include the utilization of computer vision technology using the traditional image processing and deep learning. When, the conventional methods of computer vision are used, extracting the different features such as colour, shape, texture

etc., and combining them with the machine learning methods such as the SVM becomes necessary. But with the improvement in computing power, the deep learning algorithms can beneficially extract multidi- mensional and multi-scale spatial and semantic feature information of weeds through AlexNet, VGGNet, ResNet, etc due to their enhanced ca- pability for image data expression thereby avoiding the disadvantages of traditional methods of feature extraction. The application of deep learning in agronomic classification of plant species has gained momen- tum after the outbreak of CNN and AlexNet (Krizhevsky et al., 2012b). Hall et al. (2015) have utilized the CNN architecture in classifying leaves of 32 species of crops and weeds by capturing nearly 1900 images of the same.

Utilization of CNN architecture in the classification and differentia- tion of weeds from different species of wheat, sugarbeet, corn, soybean, sunflower, etc. has been proposed by Kussul et al. (2017), while the modified version of VGG16 for the classification of barley, grass, oil crops and weeds have been proposed by Mortensen et al. (2016).

investigations relied on data collection using unmanned aerial vehicles to accurately detect and count the cattle (Andrew et al., 2019; Chamoso et al., 2014; Rahnemoonfar et al., 2019; Rivas et al., 2018). Such detection and counting approach problems, in general, have adopted either CNN-based probability heat map generation on the loca- tion of the animals or generation of bounding boxes for detection of the animals. An improved Yolo model called ‘FLYOLOv3’ (FilterLayer YOLOv3) based on Filter layer was introduced by Jiang et al. (2019) to ensure accurate detection of key parts of dairy cows. The performance of this approach was superior to the Faster-RCNN and Yolov3 algorithms.

Early and accurate yield estimation is essential for farmers and other stakeholders in making strategic decisions on post-harvest planning, policy-making and crop management (Al-Gaadi et al., 2016; Chlingaryan et al., 2018; Wei et al., 2020). Some of the studies underline that yield estimation using deep learning-based computer vision on ae- rial images is superior to traditional approaches. In a study conducted by Yang et al. (2019) rice grain yield from low-altitude remote sensing data was used to estimate the rice grain yield using convolutional neural net- works. The models were trained on both RGB and multispectral images collected by UAV, and results showed that the CNN trained on these im- ages outperformed the VIs-based traditional regression models for grain yield estimation at the ripening stage.

Despite being late for digitization, the agriculture sector has finally seen good momentum for the practical implementation of several arti- ficial intelligence applications, including deep learning-based computer vision approaches. Computer vision-powered disease identification ap- plications merge the expertise of genetic resources and artificial intelli- gence, allowing farmers and extension workers to act quickly and rescue the crop. This disease detecting computer vision-enabled soft- ware is also being installed inside greenhouses, drones, and other equipment to identify the issues and provide a faster response in taking preventive measures. Advancement in computer vision technology has been used by agricultural startups for building solutions that assist farmers in harvesting, plant health monitoring, pest-weed control, etc. For pesticide application, blue river technology (Blue river technology) developed a see and spray’ technology that works based on camera

inputs and computer vision algorithms. The algorithm can distinguish weeds from plants and perform targeted pesticide applications. The startup, cromai (Cromai) developed AI-driven land and crop diagnostic information. They provide a technological solution for georeferenced identification of weeds in the sugarcane field using advanced artificial intelligence approaches. Harvesting robots are widely used in open field conditions, integrating with machine visions and achieving im- proved precision. Harvest CROO robotics (Harvest croo robotics) devel- oped a fully autonomous harvester, employing a harvester-mounted LIDAR system to avoid collisions and accurate navigation. The computer vision system scans each berry on the plant and determines the ripeness and health before harvesting. ‘Plantix’, the crop damage diagnosis mo- bile application (Plantix) developed by German startup PEAT (Progres- sive Environmental and Agricultural Technologies), uses deep learning and computer vision to help farmers to combat pests and diseases (Goncharov et al., 2018; Tibbetts, 2018). The application’s functionality enables the end-user to upload crop images and get guidance on the dis- ease affected, symptom descriptions, treatment information, preventive measures, etc. With the same objective of identifying a large number of plant diseases, other applications such as Agrio (Agrio) were also

introduced to the farming community. Several technology-driven solu- tions were introduced into precision livestock farming to ensure opti- mal health and output of animals also. The technology startup Cainthus (Cainthus) offers a computer vision-driven AI system for dairy farmers to monitor their cows and send timely alerts and reports via associated applications. Smart cameras are deployed to watch over the activities of the cows to provide the right amount of feed available on a timely basis. Similar to this, Piguard (Piguard), an innovative live- stock management software, leverages deep learning-based computer vision approach to monitor the health status and behavioral patterns of animals.

Deep learning for computer vision, the spearhead of artificial intelli- gence, is perhaps one of the most promising technologies for meeting the ever-growing food demand. Several intractable problems in agricul- ture are being solved with the support of DL-computer vision. However, high innovation capability always comes along with some challenges. One major challenge in computer vision using deep learning includes the requirement of massive processing power, and most deep learning applications are data-intensive. A possible solution to this is the adop- tion of cloud-based solutions that offer auto-scaling, load balancing, eas- ier maintenance, and high availability features. However, cloud solutions limit real-time processing due to the latency in access and re- trieval of the data from the cloud. The increased cost of immense data processing and privacy issues are also other concerns. Advanced edge devices with accelerators are capable of analyzing real-time video in- puts and providing inferences in near real-time. Deployment of the computer vision solutions in edge devices can reduce the latency limita- tions. Sophisticated computer vision models in a variety of agricultural

In fruit yield estimation systems, this is a major concern and causes sharp declination in the overall accuracy of the system. Varying illumi- nation conditions and extraction of data from complex overlapped and textured backgrounds also make the computer vision task challeng- ing. In real-time video applications, performance in terms of detection speed and accuracy are crucial for detecting objects in motion. Research in computer vision is growing at a faster pace in the agriculture domain. Building a robust computer vision system requires quality data genera- tion, transfer, and processing. The system should have adequate security to block attacks. Heterogeneity of resources involved in CV solutions in- troduces a lot of security concerns, such as data integrity, privacy issues,

reliability, etc. As these solutions integrate several digital technologies starting from the internet, IoT, cloud computing or edge computing, and wireless sensor networks, the system should accommodate security features for all these technologies and ensure data and device integrity, data accuracy, and availability. From land preparation to harvesting, dif- ferent stakeholders are leveraging new ways to improve the ability to derive insights from images, object detection and tracking, etc. Deep learning - computer vision models will undoubtedly continue to expand and become more innovative and intelligent, handling more complex computations in agriculture with utmost precision. Above all, for obtaining efficient and desirable outputs, strong business cases with the capability to scale on a larger scale is necessary.

The surge of deep learning coupled with computer vision over the past few years has brought automation capabilities to traditional agri- culture practices. In this paper, we have extensively discussed the role of deep learning-based computer vision in different agriculture applica- tions. More specifically, the paper emphasizes seven different applica- tion areas such as seed quality analysis, soil analysis, irrigation management, plant health analysis, weed management, livestock man- agement, and yield estimation. Review of the application of deep learn- ing particularly, the assessment and planning of water resources revealed that the water sector would continue to embrace deep learning at an accelerated rate, and it will play a significant role in the future of water-related research and the wide range of application areas. Tech- nologies powered by deep learning have created a myriad of application and research opportunities that have the potential to change hydrolog- ical science and workflow. Recent advances in deep learning-assisted

Goncharov, P, Ososkov, G, Nechaevskiy, A, Uzhinskiy, A, Nestsiarenia, I, 2018. Disease De- tection on the Plant Leaves by Deep Learning. In: Kryzhanovsky, Boris, Dunin- Barkowski, Witali, Redko, Vladimir, Tiumentsev, Yury (Eds.), Advances in Neural Computation, Machine Learning, and Cognitive Research II. Springer, pp. 151–159.

You, J., Li, X., Low, M., Lobell, D., Ermon, S., 2017. Deep Gaussian process for crop yield pre- diction based on remote sensing data. Proceedings of the Thirty-First AAAI Confer- ence on Artificial Intelligence, AAAI’17. AAAI Press, San Francisco, California, USA,

