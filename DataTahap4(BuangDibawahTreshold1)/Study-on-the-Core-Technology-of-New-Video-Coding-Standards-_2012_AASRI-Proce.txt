We introduce briefly the basic principle of the standardized coding/decoding H.264/AVC . We have analyzed and studied in detail the core technology of H.264/AVC standard, including motion estimation and motion compensation, forecasts in a frame and between the frames, integer transform and quantization analysis, entropy coding methods, deblock filter, new photographic image type, aspect-oriented IP and wireless environment, etc. The H.264/AVC standard has solved the contradiction between the image quality and the coding efficiency, its effect is obvious, but many advantages acquired exchange for the sacrifice of computing complexity, therefore, to achieve greater coding efficiency will be the next studying emphasis at the same time of reducing the computing complexity.

In the output bit stream of the encoder, the basic unit of data is the sentence element. Each sentence element consists of several bits, it represents a particular physical meaning, for example, Macroblock type, Quantitative Parameters, etc. The syntax represents the structure of syntax element, the semantic illustrates the specific meaning of semantic element. All the video encoder standards formulate the work flow of encoder/decoder by defining the syntax and semantic.

The biggest difference of hierarchical structure in H.264/AVC is to have cancelled sequence layer and image layer, most of syntax elements originally belonging to series and image head are drifted out to form two layers of reference set including sequence and picture, the rest is put into the area layer. The new adding syntax elements on the area layer identify the numbers of parameter sets, each area carries its own basic information including the number of picture, size and so on. In encoding, H.264/AVC formulates that these independence data units such as parameter sets and area should be put into a group as complete as possible to transmit.

The parameter sets are an independent data unit, not dependent on other syntax elements out of the parameter sets. The parameter sets are only cited when the syntax elements of area layer need them, and a parameter set do not correspond to a specific image or sequence, the same sequence of parameter set can be cited by several sequences of image parameter sets. Similarly, the same image parameter set can be cited by several images.

Takes advantage of the relevance of time domain. The relevance of time domain lies in those continuous image blocks, which makes it need to encode those differentials in coding time. Generally we take advantage of the relevance of time domain through motion estimation and motion compensation. A pixel block derives motion vectors from a preceding frame encoded or a few of preceding frame in search of the relevant pixels, but the motion vectors in encoding/decoding end are used to forecast the current pixel block.

Makes use of the airspace redundancy of residual error. After motion estimation, the encoding end only needs the encoding residual error, namely encodes the difference between the current block and corresponding forecasting block. The encoding process includes the following steps: transformation, quantization, scanning output and entropy encoding.

Other techniques. Besides those we have just described, H.264/AVC also includes: oversampling relationship between traditional chromaticity data and luminous intensity data of 4:2:0; block motion vector; motion vector surpassing the image edge; size partition of transformation block; graded quantization; I, P and B image type, etc.

Firstly, H.264/AVC has adopted the macro block partitions and sub-partitions methods of different sizes and shapes. The luminous intensity value of a macro block of 16×16 can be divided in accordance with unit 16×16, 16×8, 8×16 or 8×8, but if the unit of 8×8 was selected, it can be sub-divided in accordance with unit 8×8, 8×4, 4×8 or 4×4.

The preceding video encoder standards all adopted the inter prediction method, however only the intra encoding image was called I image. The I image transforms the numerical value of pixel block directly, the treatment results will have a large number of redundant information contained in I image to low compressing efficiency. H.264/AVC adopted a new intra prediction model employing the correlation of adjacent pixel based on the same nature possibly owned by the adjacent pixel.

We can forecast by the left of the current pixel block and the top pixels (encoded the reconstructed pixels), only encode the differentials between the actual value and forecasting value, so we can use as few bit number as possible to express the pixel block information of intra encoding. The luminous intensity value in the standard of H.264/AVC has 9 kinds of 4×4 block and 4 kinds of 16×16 block intra prediction models, however 4 kinds of chromaticity models of 8×8 are the same as 4 kinds of luminous intensity models of 16×16.

was selected, it can be further divided into 4 sub-regions of 8×8, 8×4, 4×8 and 4×4.Each contains its own motion vectors, each motion vector and selected region information must be transmitted by encoding. Therefore, when a large region was selected, the data quantity describing motion vectors and selected regions decreased, but the residual error after motion compensation will increase; when a little region was selected, the residual error will decrease, the prediction became more accurate, but the data quantity describing motion vectors and selected regions increased. A large region is fit for reflecting the homogeneous part between the frames, a little region is fit for describing the detail part between the frames.

H.264/AVC uses the integer transform similar to the Discrete Cosine Transform (DCT) of 4×4 to transform the residual result of motion estimation and intra prediction from the time domain to the frequency domain, all operators use integer algorithm, the transform core is mainly addition and shift. In the whole process of transform and quantization, H.264/AVC only carries out the integer algorithm of 16bit and a multiplication operation, not the floating-point transform similar to MPEG-2 and MPEG-4. Therefore, H.264/AVC has a series of virtues such as good effect and fast computation (only the addition and shift operators), its inverse transform process without mismatch problems. Meanwhile, the transformation of block size from 8×8 to 4×4 can lessen the block effect and ringing effect. Although the preceding standards of video encoding/decoding took advantage of the quantization principle to compress the code, the quantization of H.264/AVC has its uniqueness, here, the quantization is a very important step for data compression.

Where Z is quantizing value, Y is input coefficient value, Qstep is quantifying step. The quantifying step has 52 kinds, the quantitative parameter (QP) decides the quantifying step of each macro block. QP increases 1, accordingly the quantifying step increases 12.5%, in the preceding standards Qstep increases a constant every time. Sometimes the quantization of luminous intensity coefficient is very rough, however the chromatic aberration signals in the quantization process adopted a more delicate quantifying step, the fidelity of chromatic aberration signals became better than the luminous intensity coefficient. Due to putting the transformation and quantifying together, the operations of compressing the code were reduced effectively.

H.264/AVC used 2 kinds of entropy coding method, namely the combination of CAVLC(Context-based Adaptive Variable Length Coding)and UVLC(Universal Variable Length Coding), CABAC(Context- based Adaptive Binary Arithmetic Coding). The preceding standards adopted UVLC, all symbols of UVLC all used a code table derived from a statistical probability distribution model. Although it is simple, may have the following fault: probability distributions may not be very fit for reality; probability distributions are still; the correlation of symbol is neglected, conditional probabilities are not made used of; code words must have integral units of bit. These shortcoming affect the compressing effect of UVLC on middle and high compression rate

One of the encoding characteristics based on block lies in its block structure. The quantization errors of pixel value of block boundary form the block effect which affects the subjective quality of image due to the block reconstruction. In order to eliminate the block effect and improve the subjective and objective quality of decoding image and to provide better reference image, the deblock effect filter based on content is introduced. When the difference between the images at the block boundary is little, the filter is used to smooth this difference, if the image characteristics at the boundary are obvious, the filter is not used. Therefore, it can weaken the influence of block effect and avoid straining off the image contents, and at the same time the bit rate in the same subjective quality is reduced 5%~10%.

After the code stream contains SP slice and SI slice, the decoder can transfer quickly between the code streams which have similar contents but different code rate, at the same time supports the random access and quick playback model. SP slice uses the Inter Prediction method to realize the transformation between the image streams of different code rate by changing the size of quantizing values. SI slice is a best slice similar to SP when SI slice can not uses the Inter Prediction method due to transmission errors.

The function of H.264/AVC is divided into two layers: the Video Encoding Layer and the Network Abstraction Layer. The Video Coding Layer (VCL) accomplish the effective description for the video content, the Network Abstraction Layer (NAL) accomplish the packed transmission of video data on different networks. Therefore, VCL and NAL separately complete the tasks of high encoding efficiency and network friendship.VCL data is the output video data sequence after the encoder compresses the code.

NAL is responsible for using the segmentation format of low-level network to encapsulate the VCL data, including the framing, signaling of logical channels, timing information utilization and sequence ending signal, etc. For example, NAL supports the video transmission format in the circuit switching channel, the video transmission format on the Internet utilizing RTP/UDP/IP. NAL contains its own head information, segment structure information and real load information, namely the top VCL data (If the data partitioning technology was adapted, the data might consist of a few parts). The hierarchical structures are shown in Fig 4.

The inter image refresh is used to complete the time synchronization of H.264/AVC video flow in order to resist transmitting errors, the slice structured coding supports the space synchronization. The video data in a picture provides some resynchronization point after error code.

In addition, the inter macro block refresh and multi-reference macro block permission encoder can not only consider the encoding efficiency but also be adapted to the characteristics of different transmitting channels. Besides it is adapted to the channel code rate utilizing the change of quantization pace, H.264/AVC deals with the change of channel code rate utilizing the data partitioning method.

In wireless communications applications, we can support the maximum bit rate change of wireless channel by change the quantization precision or space/time resolution of each frame. However, in the situation of multi-broadcasting, it is impossible to demand the encoder in response to all kinds of changing bit rates. Therefore, H.264/AVC adopted the SP frame of stream switching to take the place of hierarchical encoding, other than the Fine Granular Scalability approach employed by MPEG-4 (low efficiency).

Due to the results of using a lot of new technologies, the H.264/AVC standards in all aspects such as system structure and efficiency are superior to the preceding video encoding standards. In the same image quality, the H.264/AVC algorithm saves 50% or so code rate in terms of preceding standards such as H.263 or MPEG-4. At the same time, it has a strong error resilience property to adapt itself to the video transmission of wireless channel with a high packet loss rate and serious disturbance. So H.264/AVC supports the hierarchical encoding transmission in different network resources, achieves a steady image quality and can be adapted to the video transmission between different networks.

In the video application domain, the image quality and encoding efficiency always are a dilemma. The encoding efficiency of H.264/AVC standards is improved because its entropy coding technology adopted the encoding of CAVLC and CABAC, successes to solve the problem. But the price of the superior performance of H.264/AVC is that the computing complexity increased greatly. It is estimated that the computing complexity of encoding is about three times as large as H.263, the computing complexity of encoding is about two times as large as H.263. At the same time of reducing the complexity, to achieve greater efficiency of encoding will be the next priority of study.

