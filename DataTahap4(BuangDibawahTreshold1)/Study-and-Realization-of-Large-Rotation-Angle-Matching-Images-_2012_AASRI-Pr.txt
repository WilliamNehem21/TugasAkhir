Combining the advantages of SIFT charateristic matching and pyramid image matching, this paper aims to solve the matching problem of automatic rotation with large rotation angle in aerial photographing. To start with, match the images at the highest pyramid level with SIFT characteristic matching method. Then use the RANSAC algorithm to combine the results from SIFT method. Before matching, predict the initial location of the matching points by using the estimated rotation angle and then make rotation compensation of the matching window images. Last, validate the method by carrying out an aerial digital imagery with large rotation of a certain area.

Matching images with large rotation angle has not gained much attention in the field of aerial photogrammetry, but it is vastly investigated in the computer vision and medial image matching. Ullah proposes a direction code based matching method, but it needs to know approximate value of rotation angle, and the speed is somewhat slow. Tasi uses the ring-projection transformation to overcome the rotation effect, but there are relatively large matching bias in results. Suzuki proposes a method that firstly extracts edge

using Canny edge detector and then performs Hough transform on the resulting binary image to estimate rotation angle. Xu Jianbin takes the Zernike moments as the similarity measure, and introduces genetic algorithm to match remote sensing images. But on the whole, the above mentioned methods are not suitable for the aerial image matching due to lack of universality and robustness. In recent years, a new SIFT feature operator has been proposed, which can effectively adapt itself to a variety of image transformation, maintaining invariance to the image rotation and scaling the brightness changes. But it has the shortcoming of low match success rate and high computing time, so directly applied to the aerial image matching, it will be time-consuming and lack of uniformity of point distribution.

Firstly, image pyramid is generated for each images. Secondly, the rotation angles between the reference image and the searching images are estimated using the SIFT feature matching results. Thirdly, feature points are uniformly extracted by Förstner operator in the overlapping area, and the NCC image matching algorithm is followed to search conjugate points. The difference between this process and the traditional one lies in that the rotation angle is introduced in the matching process to make correction to the conjugate point' approximate position and the grey information of matching window. Also, the relative orientation with connection condition is incorporated into each level of pyramid image matching to remove the remaining wrong matches

The SIFT feature extraction and matching is only performed in the highest pyramid image level. It does not attempt to find plenty of accurate conjugate point pairs. Instead, the SIFT feature matching is to establish a coarse coordinate relationship between the images with large rotation angle. With the strategy in this paper, the shortcoming of large computation burden and low speed of SIFT feature matching will be reduced to a large degree, as the image in the highest pyramid level is usually small, needing comparatively little computation.

After these four steps, the keypoints are considered as the feature points, and the keypoints descriptors as the feature to be used. And the Euclidean distance between feature vectors is taken as the similarity measure. If the ratio of the nearest distance to the less nearest distance is less than the given threshold (0.7 in this paper), feature vector with the nearest distance is accepted as the conjugate point.

The discrepancies between the remaining candidate points' coordinates and those derived by the affine transformation model are calculated for each SIFT feature pair. If the discrepancy is less than the given threshold, the corresponding SIFT feature pair is regarded as the correct matching, that is the interior point pair; otherwise it is regarded as the wrong matching, that is the outlier pair. And finally the ratio of outlier point pairs to the total point pairs  is computed.

For the prediction of the conjugate points' initial position, at the highest pyramid image level, affine transformation coefficients are directly used to calculate the coordinate of initial position. At other pyramid image levels, for the correct matching point at higher pyramid level, just projecting it to the current pyramid level will be all right. But for those points fail to obtain the correct matching points, the neighboring successfully matched points' parallax information is taken advantage to derive its initial position. It should be noted that the effect of rotation angle on the parallax should be considered during the initial position prediction.

Due to the disadvantage factors, such as geometric distortion and repetitive texture, there are maybe several peaks when using NCC as the similarity measure to search conjugate points. At the same time, the point corresponding to the highest peak is not necessarily the truth, so certain constraints should be introduced in order to eliminate the wrong matching results. And in this paper, the relative orientation with model conjunction condition is utilized, through integrating the iteration weighting strategy, the matching point with wrong vertical and horizontal parallax can be automatically identified and deleted.

where vi is the residual of the ith observation, ri is its corresponding redundant observation component, ˆ0 is the unit weight mean error, and n is the total number of the observations. The threshold for the vertical and horizontal parallax is set to 1 and 1.5 times pixel size of the current pyramid image level.

The test data is a set of gray valued aerial digital images covering the Badaling area in the city of Beijing. Due to the large overlap up to 88%, the rotation angle between these large overlapping images is relatively small, and cause little affect on the traditional matching algorithm. But after analyzing the results of image bundle adjustment, it has been found that the orientation angle of some images are comparatively large, and the maximum value for phi, omega and kappa angle is 8° 8° 24° respectively. The main reason for these large orientation angles is that the photograph is taken by the small helicopter, which is influenced a lot by the air at the exposure. To evaluate the matching method proposed in this paper, two triples of aerial images are chosen, in each group large rotation angle exists.

For each group, the middle image is taken as the reference image, in the area overlapping by all three images about 1000 feature points are extracted for matching. The searching window size is set to 35×35 pixels, matching window size is set to 13×13 pixels, and the threshold for NCC is 0.6. The matching result is shown in fig. 2.

Two sets of test images covering the suburbs both have rich texture. However, due to air effect to the non- sealed small aircraft taking photograph at low altitude, the rotation angle is large for some images. For group of image 61-63-65, the  is 12.7°  19.2° and 1.0° respectively, and for group of image 30-28-26, the  is

2.1° -5.7° and 1°. It can be seen that, for the first group, the largest rotation angel is between the middle and right image, that is 18.2°, and for the second group, 7.8°.When large rotation angle between matching images exists, for the traditional matching method, using initial parallax to predict initial position of conjugate points at highest pyramid level will swing away from its true position. Also for matching at other pyramid levels, it will fail to make use of neighbor successful matched point's parallax to predict the initial position of conjugate points for failure matching points at higher levels, and image rotation will lead to calculated value of NCC below the threshold. These will finally cause that the traditional method does not have a high match success rate, even no match out points at all. The greater the rotation angle is, the more serious this phenomenon will be, which contributes to the facts that the second group image has better results than the first group image for matching with traditional method. By the method in this paper, through SIFT feature

matching at highest level, the rotation angel between images can be accurately estimated, which is then used to carry out the initial position prediction and image window compensation. These will guarantee the accurate initial position and the validity of correlation coefficient calculation, and as a result, the match success rate is enhanced. Figure 3b is feature points of some area in image 63, figure 3a is the conjugate points matched by the traditional method, and figure 5c is the matching results of our method. ○ denotes the successful matching points, × the wrong matching points.

This paper aims to solve the matching problem of automatic rotation with large rotation angle in aerial photographing. To start with, match the images at the highest pyramid level with SIFT characteristic matching method. Then use the RANSAC algorithm to combine the results from SIFT method. Before matching, predict the initial location of the matching points by using the estimated rotation angle and then make rotation compensation of the matching window images. Last, validate the method by carrying out an experiment on an aerial digital imagery with large rotation of a certain area.

