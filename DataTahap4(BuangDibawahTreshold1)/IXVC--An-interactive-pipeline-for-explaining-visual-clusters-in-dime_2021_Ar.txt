In machine learning, dimensionality reduction (DR) techniques are designed to reduce the number of features of the original high- dimensional (HD) data. Reducing the number of features to, e.g., two dimensions, provides low-dimensional (LD) data that can be visually presented to users. DR techniques are used in many different fields. For instance, multidimensional scaling (MDS) [1] is used in psychology to explore data or validate hypotheses [2,3] (e.g., see Koch et al. [4]). Principal component analysis (PCA) [5] is another famous technique that can produce visualizations if the first components are kept.

In order to present IXVC, Section 2 reviews the explanation of DR visualizations through dimensions and clusters. Section 3.1 motivates the need for the explanation of visual clusters. Section 3 then introduces IXVC. Section 4 presents the tool that implements IXVC, as well as examples of use. A user-based experiment has been conducted for evaluating the pipeline and the tool, and is presented in Section 6. A discussion on the limitations of IXVC is presented in Section 6.4. Directions for future work are proposed in Section 8 and Section 9 concludes the paper.

In the case of nonlinear DR (NLDR), the contribution of each HD fea- ture to the reduced dimensions is, most of the time, not given through parameters, which makes NLDR mappings hard to interpret [20]. For transferring biplots to the NLDR case, Coimbra et al. make uniform perturbations in the values of each HD feature, while setting the unperturbed HD features to their mean value [21]. By doing so, they obtain curved axes representing the tendencies of HD features in the 2D plot. Following the same idea, Cavallo and Demiralp propose to draw prolines for each point and each feature of interest in a scatter plot [22]. A proline is drawn in LD by creating new samples by varying the value of a feature of interest, while all others are fixed, and then by computing the projection of all generated samples to LD. The proline corresponds to the line that connects the projection in 2D of all created samples.

Coimbra et al. also present axis legends for NLDR, based on their curved biplot axes [21]. They define the height of the bars correspond- ing to the contributions of the HD features to the reduced dimensions by a combination of how parallel the projected curve is to each scatter plot axis, and of how linear the curve is.

Turkay et al. [23] developed an interactive analysis of DR dimen- sions using dual views of the instances and of the HD features. The idea is to select instances that are then used to compute a scatter plot in which the points are features from the HD space and where the dimensions are chosen statistics. Users can then choose points in this scatter plot, i.e. HD features, which are then the features used to compute a new DR visualization of the instances.

The two visualizations are linked to one another as selecting elements in one visualization is reflected on the other visualization (e.g., points representing the features selected on one visualization are used to compute a new visualization of the instances). While the works of Turkay et al. and Yuan et al. allow users to have a sense of the impact of the original features on a DR visualization of instances, they do not provide an approximation of the DR mapping that uses the HD features to build the two dimensions of the visualization.

One recent example of such a combination is Clustrophile 2 [31], which lets users select the DR technique and the clustering algorithm applied in HD in order to visualize HD clusters. Some explanations about the HD clusters are provided alongside visualizations, such as the importance of each feature in each cluster under the form of a heatmap and a decision tree predicting the HD clusters with the HD features. While Clustrophile 2 has some connection with our work, it is designed to explain clustering algorithms applied on the HD data, while our problem is the explanation of the HD-to -2D mapping through the visual clusters produced by the DR method used. Again, the key distinction being that the 2D visual clusters do not necessarily correspond to

When the visual clusters are identified, an explanation of these clusters can be provided. Most of the time, the explanation is provided by experts (e.g., Lebel et al. [32]). This makes the name clusters task subjective [2]. One drawback of this approach is the extra knowledge experts may inject during the explanation that does not come from the data used to generate the visualization. Furthermore, even if they do not inject extra knowledge (e.g., by restricting their explanation to the original HD features), it is still difficult for a user to explain how the HD features are combined to form clusters in 2D.

da Silva et al. propose to rank HD features according to an euclidean ranking and a variance ranking [39]. For each instance in the dataset, a set of neighbors is chosen by the user in LD and the euclidean distance between each instance and their LD neighbors is computed for each HD feature. The visualization is then colored by following the top ranked HD features in the different neighborhoods.

After automatically detecting clusters using a grid in LD, Kandogan proposes to rank HD features by labeling each cluster according to a score associated to each HD feature [40]. This score is computed for each automatically detected LD cluster and for each HD feature as a linear combination of measures on properties of the LD cluster (e.g., its density). The weights of the linear combinations, i.e. the importance of the properties, are set by the user.

Rauber et al. propose to let the user select a group of instances and a ranking of HD features is provided following a discrimination criterion (i.e. how individual HD features explain the separation of selected instances from the rest) or a coherence criterion (i.e. how the compactness of the selected instances are explained by individual HD features) [42]. However, the HD features are not combined for the explanation.

Parisot et al. use an evolutionary algorithm in order to find the dataset preprocessing that leads to a new dataset for which a clustering result is easier to interpret [43]. In order to find such a new dataset, the objective of the evolutionary algorithm is to find a small decision tree that is used to explain the clustering of the preprocessed dataset, while having a clustering on the preprocessed dataset that is as similar as possible to the clustering on the original dataset.

van Ham et al. consider a scatter plot made from two HD features and use a decision tree to explain a selection of instances in the scatter plot by using HD features that are not used in the scatter plot [44]. Their decision tree is a binary classification tree that has the task of explaining the selected instances versus all others, which does not address the issue of explaining visual clusters in DR visualizations.

the first component of a PCA on user-selected points in order to know the main HD features that describe the selected points. However, (i) this selection has no link with the projection, as it explains the HD points in- stead of how the HD points are projected in LD, and (ii) the explanation is linear because of the PCA, while the projection is nonlinear. In order to take into account these limits, another tool that considers polylines is proposed in t-viSNE. The idea is to draw lines in the visualization and then rank the HD features according to how they explain, for each LD dimension, the order of the LD points on the polylines. Concerning the problem we address in our work, the shortcomings of this tool are that (i) the dimensions are explained instead of the clusters and (ii) the relative importance of the HD features is known, but not how they are combined to explain the dimensions.

The idea of generating a DT from a user selection of clusters in a scatter plot, as done in this work, was previously considered by Ware et al. [49]. In our work, however, instead of representing two HD features, the scatter plot is the result of a DR process and the DT is used to approximate the DR mapping. Moreover, the decision tree of Ware et al. is built manually by defining splits through the scatter plot, whereas it is automatically generated from the selection of clusters in our method.

NLDR visualizations are used without any clue about the mapping between the visualization and the original features that were used to generate it. In order to introduce the importance of explaining this mapping through visual clusters, Section 3.1 presents some challenges related to the state-of-the-art neighborhood preservation techniques. Section 3.2 then proposes answers to the challenges discussed in Sec- tions 2.2 and 3.1. Section 3.3 builds on the proposed answers and presents IXVC, a machine learning pipeline that helps data analysts to explain DR visualizations through visual clusters.

A first issue, mentioned in Section 2.2, is the intuitive explanation of clusters. This issue arises when data analysts use their intuition to explain clusters that are made of errors from the DR algorithm. Having access to objective reasons behind visual clusters, based on the HD features, would help data analysts to overcome this issue of intuitive assessment.

The issue [MC] is about the role of DR errors in cluster explanations. In this case, having a feedback on DR errors may help data analysts to explain the mapping. Indeed, if individual errors, for each instance in 2D, are provided to data analysts, it would be possible to decide whether to discard or not some instances during the visual analysis. This issue is important, since the presence of instances erroneously placed in visual clusters because of DR errors can mislead the analyst. The issue [DNE], related to the absence of meaning of the visualiza- tion dimensions, forces the use of the visual cluster to understand the HD-to -2D mapping. When dimensions can be explained, like with MDS visualizations, techniques can be used to approximate the mapping between the original features and the dimensions of the visualization. However, when explaining the visualization dimensions do not make

features of X, the HD data, are the criteria on which the decisions in the decision tree are made. As mentioned in Section 2.2, one can note that decision trees can be used to explain HD clusters (see, e.g., [43,53,54]). However, our task is different because the goal is not to cluster data in HD, but to understand a given DR visualization through its 2D visual clusters. Therefore, we propose to understand the visualization by interactively querying the meaning of visual clusters of interest.

The IXVC interface is implemented as a web application running on a Python web server. The visuals were developed in Javascript using the D3.js library [56]. The Python web server handles the execution of the machine learning algorithms, such as the decision tree, using scikit-learn [57]. For the evaluation of IXVC, visualizations generated

When the user is finished selecting visual clusters, a decision tree generated from the cluster selection is displayed under the scatter plot. The decision tree attempts to predict the cluster of each selected instance using the HD features. The representation of the decision tree shows the features selected to build the tree as well as the entropy (named impurity in the leaves of the decision tree). The entropy char-

The prediction for each instance is shown in a second scatter plot in the upper right part of the interface. Whereas the decision tree gives the number of incorrect predictions in each leaf, this scatter plot makes it possible to identify the incorrectly predicted instances in question. The instances are colored according to their predicted cluster and are shaped as a dot if the prediction is consistent with the user selection, and as a cross otherwise. The level of confidence of the predictions made by the decision tree is denoted by the opacity of the points on the scatter plot. Again, instances can be filtered out according to a threshold defined by the user on the minimal confidence provided by the DT.

Based on the DT and the scatter plot showing the predictions, the user can reflect on the explanations and draw a new cluster selection. In turn, he can cycle through the visual cluster explanation pipeline again by generating a new DT with new selected visual clusters. This iterative process is repeated until the user feels that he has a sufficient understanding of the visualization.

cluster groups the instances that gravitate around the dense center and forms the green cluster. After having refined the visual clusters as such, the data analyst learns that, indeed, this difficult-to-understand visualization is the representation of different clusters in the HD space. The data analyst conclusion enlightened by the decision tree is that the red cluster corresponds to the neighborhoods with a high rate of criminality, by opposition to the neighborhoods in the blue and green clusters. The blue cluster corresponds to neighborhoods with a low rate of criminality, with a percentage of the land which is residential lower than 57.5%, with few industries nearby, and with houses having an average number of rooms strictly lower than 8. In other words, the blue cluster correspond to city centers with residences and rental businesses. The green cluster contains instances that are variations of the ones in the blue cluster. Indeed, any neighborhood being more residential, with more industries or with bigger dwellings is in the green cluster.

For each dataset, 50 instances were randomly sampled. The goal of the evaluation was to evaluate the IXVC pipeline rather than the interface developed to implement it. The participants would have been confronted to a barrier not related to the pipeline, which would have thus tweaked the evaluation results. Showing more than 50 instances at once would hinder the readability of the scatter plot and sampling is one technique commonly suggested to tackle such visual clutter issues [59].

During the development of the IXVC interface, early feedback has been sought from two researchers that are non-experts, but knowledge- able, in machine learning and information visualization. Their profile was sought to fit a profile of users who would have enough knowledge to use the tool, but not enough to compensate the potential flaws of the interface with their knowledge. The goal of this preliminary feedback was to detect usability flaws in the interface before the evaluation.

The objective of the evaluation is to measure whether IXVC helps to conduct an analysis of a DR visualization, and if so, with more objectivity. As a tool supporting analysis through a DR visualization and decision trees, IXVC is destined to users knowledgeable of these techniques. 16 students (13 males and 3 females) following a graduate- level data science program in which DR and decision trees are taught were recruited. The age of the participants ranged from 20 to 53 years (two participants are older students resuming their studies), with a

Most participants intuitively followed the pipeline to get explana- tions about visual clusters. However, some usages of the IXVC interface that differed from how participants were expected to apply the pipeline were observed. First, the analysis process was more exploratory than expected. The pipeline describes an iterative process in which a se- lection of clusters is refined by adjusting the manual clustering. How- ever, a few participants tended to try many different cluster selections instead of iteratively refining one.

used to compute the SUS score. Lewis and Sauro [68] showed that the data gathered through the SUS can also be used to reliably derive a learnability score that can be interpreted in the same way as the SUS score. It measures the extent to which an interface enables its users to learn how to use it. The learnability score is computed by considering the fourth and tenth items of the questionnaire. For the IXVC interface, the score stands at 78, very close to the SUS score, which indicates that it has a good learnability.

The evaluation results and open fields in the questionnaire allow considering future directions to improve IXVC. A first future work is the development of IXVC for making it an educational tool. As mentioned in Section 6, IXVC is destined to users knowledgeable on DR and decision trees. However, several participants pointed out that the use of IXVC, in fact, needs little knowledge of these techniques. Since the participants are students following a data science program, they are

Another future work can be identified following the observation of P11 described in Section 6.3.1. P11 used IXVC for checking if a feature he had in mind played a role in the visual cluster separation. Based on this use, the IXVC interface could propose all features as clickable buttons, which would show how the selected feature would make it possible to separate the visual clusters. In the IXVC pipeline, this corresponds to providing all possible decision trees with only one decision node. This feature can also be added before the use of decision trees, by coloring the instances in the visualization according to a selected HD feature. This pre-exploration step can indicate to the analyst how to manually cluster the 2D instances in step 2 of IXVC.

Finally, an analysis of the use of IXVC to compare DR techniques can be performed. Using, e.g., synthetic datasets, one would be able to check how hard it is to explain visualizations from particular DR techniques based on different conditions. Such a condition can be that the DR technique projects distinct visual clusters that are in fact controlled to be intertwined in HD, or the opposite.

In this paper, we proposed an interactive machine learning pipeline called IXVC (for Interactive eXplanation of Visual Clusters). The pipeline provides explanations of visual clusters manually selected by a data an- alyst in a dimensionality reduction (DR) visualization. The explanatory feedback on the manually selected clusters is provided by a decision tree whose decisions are based on the high-dimensional (HD) features. Interactively, the data analyst can thus select clusters in the visual- ization and receive an explanation of the selected clusters through a decision tree. IXVC is a need for data analysts [29] and handles a task that is called discover relation between visual pattern and original dimensions [11].

IXVC was implemented as a web application for its evaluation. The results of the evaluation suggest that using the proposed interactive pipeline helps users to explain how visual clusters in a DR visualization are related to the HD features that have been used to create the visualization, even when the mapping between the high and the low dimensions is not provided. It is also suggested by the evaluation results that the usefulness of the pipeline does not depend on the prior knowledge the analyst has on the dataset.

The authors want to thank the participants of the experiment for their time, as well as for the interesting discussions on the pipeline and its implementation. We also acknowledge our two colleagues, Laurent Evrard and Gonzague Yernaux, who kindly agreed to take part in the preliminary evaluation. We also are grateful for all the interesting comments of Reviewer 1 on the content and the form of the paper. The authors also thank the European Regional Development Fund (ERDF) for their financial support through the Wal-e-Cities LIV project with award number [ETR121200003138].

Antoine Clarinval received a master degree in computer science in 2017 from the University of Namur, Belgium. He is currently pursuing the PhD degree at the University of Namur. His research interests include smart city education, citizen participation in smart cities, and how public displays and information visualization can support it. In this regard, he is especially interested in traffic data visualization and open data.

Bruno Dumas received his PhD in 2010 from the University of Fribourg, Switzerland. His PhD thesis focused on the creation of multimodal interfaces, following three axes: software architectures, modeling languages and multimodal fusion algorithms. He then worked for three and a half years at the Vrije Universiteit Brussel as a post-doc. His research areas focus on human-machine interaction, mul- timodal interfaces and more broadly on how the expansion of computing in everyday life influences usage.

