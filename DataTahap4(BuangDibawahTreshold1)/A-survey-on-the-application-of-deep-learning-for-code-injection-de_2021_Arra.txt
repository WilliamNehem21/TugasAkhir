Yan et al. [26] presented a Hybrid Deep Learning Network (HDLN), a more efficient model, based on the approach by Xiao et al. (X [72]. In addition to the already existing features in the dataset, Xiao et al. suggest to extracts the new features from the Abstract Syntax Tree of JavaScript in hybrid applications through the feature space generation and feature selection.

The feature selection process can be manual or automated. Manually they can be selected via trial and error, while automatically, the features can be selected using Recursive Feature Elimination, LassoCV, etc. In 2019 [36], proposed a deep learning approach as a viable strategy to design a mobile traffic classifiers based on automatically-extracted fea- tures, able to cope with the encrypted traffic, and reflecting their com- plex traffic patterns. For example:

With the features already extracted and dimensionally reduced (e.g., using principle component analysis, Kmeans clustering, etc.), a smaller neural network can be used, to analyse the patterns faster, without the need to detect any new features. For example [67], use the principal component analysis (PCA) as a form of preprocessing for Support Vector Machines (SVM). With a smaller dataset, the bigger neural networks will not train as effectively due to insufficient samples. The CICIDS2017 dataset contains sessions described in 78 features, however, PCA can reduce the number of values down to 10 (principal components) without a feasible loss in accuracy [63]. Gao et al. [69] use PCA for the experi- ments with NSL-KDD.

Conversion of values like IP addresses can be another cornerstone. The intuitive conversion of IPv4 into a decimal value, and further di- vision by 10 power 10, would not work as intended. For example, 192.168.1.1 would be into 3232235777, and 192.167.1.1 into 3232170241. Once scaled between 0 and 1, those two decimal values are very close to each other, even though they represent different sub- networks, and the neural network may not be able to notice any difference.

used to convert the HTTP parameters into numeric attributes. These attributes are supplied for the Classifier as features (length of parameters and the number of keywords). The keywords contain words and symbols in the SQL statements, like commas, equal signs, quotation marks, “SELECT”, “UNION” and so on. There are three types of keywords ac-

The research by Uwagbole et al. [21] uses a combination of data composed of the extracted dictionary wordlist with words and unique SQL tokens extracted from the MSSQL reserved keywords. The dataset items are labelled based on the exhibition of the SQLIA types charac- teristics which are: the presence of the SQL tokens in the injection point, disjointed text, single quotes, semicolons, comments, hex, etc. The data set items labelling is represented in the binary values of 0 (SQL negative) or 1(SQL negative).

Abdulhammed et al. [63] use their equation to re-scale the features in the dataset based on the minimum and maximum values of each feature. Some features in the original dataset vary between [0, 1] while other features vary between [0,∞). Therefore, these features are nor-

Data can be enhanced with additional knowledge. For example, words can be converted into a single value in a specific range and special symbols into values in a completely different, more recognizable range, artificially increasing the difference between the groups (or classes) of values. Furthermore, additional values may be added for the classifica- tion to establish a new sequence of values.

Incorrect encoding may result in misrepresentation of data for the Machine Learning algorithm to correlate features. Typically, simple conversion of payload symbols or values into charcode is an intuitive choice. However, for the code injection detection, this approach may give results close to random (50–60% accuracy of models). We have also

There is a variety of methods on the network data visualisation, that can be used to generate static images, and then further use various automated tools (e.g., imgaug22, AutoAugment [4], K-correct [5]) and image augmentation techniques presented in the surveys by Shorten and Khoshgoftaar [76] and Mikolajckzyk and Grochowski [77] to further improve the detection rates.

Automated approach. As oppose to the manual tool development of encoding methods, it is always possible to use the already existing methods of parcing data from the raw files to numeric sequences. For example, several parsers for the SQL dialects were used by Ref. [61] to obtain a parse tree. As stated by Bockermann et al. [30], the basic idea of Buehrer et al. [61] is to detect SQL injection attacks by means of changes in a queries syntax tree. Usually complex parsers are automatically generated based on a given grammar description using tools such as yacc, antlr or javacc. However, those parsers did not provide a satisfac- tory numeric sequence, and had to be further vectorised.

Translation of natural language into commands, images, lines of code, and samples for the dataset has been researched since the early days of programming languages. To illustrate the mechanism in the context of the survey, we have studied the SQL query as an example. The approach of the natural language translation into SQL queries can be potentially abused by attackers to bypass filtering.

Cai et al. [25] outlined a method of the Natural language conversion into the SQL queries using CNN and RNN, as well as provided techniques for preprocessing and postprocessing of the input data. Alternatively, a sequence-to-sequence model can be used for semantic preprocessing (C. [78], (L [79–81].

ing. Liang et al. [82] used masking for symbolic parsing by storing key-variable pairs in the memory. Masking presented by Cai et al. [25] supports more complex operations, covering both short-term and long-term dependencies. Moreover, the authors emphasize that the grammar structure of SQL is known to be more complicated than the logical forms used in semantic parsing.

It is our understanding that to ensure maximum efficiency the full preprocessing cycle should be respected. This cycle is suggested based on our previous research in the respective area [27]. To maximise the performance efficiency of machine learning for the code injection detection, we propose six stages of Pretreatment, three stages of Feature-based preprocessing, and three stages of Encoding-based pre- processing. This approach, however, can be also applied to all other cyber security methods in general. Revealing the present inconsistencies and to harmonise the preprocessing methodology, we map the existing approaches against our proposed classification to identify the gaps.

As per the assessment, Feature-based preprocessing is the most rep- resented stage. Feature extraction is mentioned in 100% of the analysed works, while shuffling of the dataset is the least mentioned substage. Cleaning, Unification, and Encoding Transformation are mentioned in 85% of the methods, followed closely by Feature Engineering in 80%. The remaining stages and substages are mentioned in less than a half of the analysed publications.

Based on the selected academic publications, the survey explored the existing approaches to the applications of machine learning for the detection of code injection attacks, with special attention to deep learning. We identified at least 13 different methods of code injection detection using various types of machine learning. Deep learning is observed being the most used approach.

The stages of machine learning for intrusion detection have been further revised and least researched have been identified. The findings confirm that the scarcity of the datasets remains one of the biggest and most common challenges for the adoption of machine learning in cyber security. The findings also revealed that data preprocessing being one of the most critical stages in machine learning, lacks consistency in the approaches in the context of code injection attack detection.

The suggested classification of a full preprocessing cycle for the code injection detection will result in the harmonisation of the approaches to this stage and will improve the accuracy and performance of the machine-learning-based Intrusion Detection Systems. The proposed consecutive stages of data preprocessing can be further used by machine learning researchers and practitioners for other cyber security needs, such as network traffic analysis and intrusion detection. And finally, the presented classification will allow to better understand the role of deep learning in the code injection attack detection process in machine- learning-based Intrusion Detection Systems.

Buehrer Gregory T, Weide Bruce W, Sivilotti Paolo AG. Using parse tree validation to prevent SQL injection attacks. In Proceedings of the 5th international Workshop on software Engineering and middleware - sem ’05, vol. 106. New York, New York, USA: ACM Press; 2005. https://doi.org/10.1145/1108473.1108496.

Raja M Chithik, Munir Ahmed Rabbani M. Combined analysis of support vector machine and principle component analysis for IDS. In: Proceedings of the international conference on communication and electronics systems, ICCES 2016. Institute of Electrical and Electronics Engineers Inc; 2016. https://doi.org/ 10.1109/CESYS.2016.7889868.

Xiao Xi, Yan Ruibo, Ye Runguo, Li Qing, Peng Sancheng, Jiang Yong. Detection and prevention of code injection attacks on HTML5-based apps. In: Proceedings - 2015 3rd international conference on advanced cloud and big data. Institute of Electrical and Electronics Engineers Inc; 2016. https://doi.org/10.1109/CBD.2015.48. CBD

