One of the expected advantages of CS exploration using deep neural networks (DNNs) in so-called deep GMs is their potential for abstracting from a given structural context and generate and explore CS not based on structural similarity alone but instead based on multiple parameters that are relevant for endpoints to be optimized [15,16]. In essence, this is also the central question of the inverse QSAR/QSPR problem [17– 20] and is one of the drawing powers of applying advanced artificial in- telligence (AI) methods to the exploration of CS. Architectures of DNNs do not incorporate any chemical knowledge, all of which has to be ac- quired during training and is encoded in the learnable parameters of the network. However, this aspect also makes it harder to assess whether a trained DNN fulfills these expectations. This perspective extends a pre- vious review on CS exploration methodologies [21] by additionally fo- cusing on the problem of assessing and validating CS covered by GMs.

between more traditional fragment-based methods and deep learning methods can be observed. In fragment-based methods, fragments repre- sent chemically sound substructures and recombinations and modifica- tions are chemically meaningful. In this case, the molecular represen- tation itself (SMILES-based or graph-based) plays a minor role because the ways these representations are manipulated are based on the un- derlying chemistry of the molecules. Deep learning models are agnostic of the semantics of the chosen representation and manipulation occurs on a purely syntactical level. A central step in the training of DNNs is to learn the grammar and rules of the representation so that valid representations can be generated. Furthermore, typical patterns in rep- resentations can be learned, which form syntactical “building blocks” of newly generated molecules and thus characterize the generated CS. However, if a DNN only learns the syntactical rules of a representation, generation of molecules will be dominated by the similarity of the repre- sentation, which only imperfectly correlates with molecular similarity. A recent study has shown indeed, that while deep GMs can successfully learn the grammar of a representation from relatively small training sets, larger sets might be required to more properly reflect physicochemical properties of the reference training set [22].

linear character-based representations. Although several deep GMs uti- lizing molecular graphs directly for input and output have been devel- oped in recent years [23–26], language-based representations form the basis of most popular models. This is unsurprising as the rapid develop- ment of DNN architectures in recent years has been especially successful in signal processing and natural language processing [27].

The SMILES notation [6] is the most popular linear notation for chemical structures. It possesses a relatively simple grammar where parenthesized expressions are used to represent acyclic compounds. Ad- ditionally, matching numbers associated with pairs of atoms indicate bonds completing rings (see Fig. 1). It is the representation of choice for most generative DNN models to date. In one of the early publications using generative DNNs, Gómez-Bombarelli et al. [15] showed that DNNs can accurately learn the grammar of SMILES and can generate a high percentage of valid SMILES. However, training of the model essentially failed, when the grammatically much more complex InChI line notation

A single molecule can have many different SMILES notations. The no- tation is determined by the starting atom corresponding to the first token of the SMILES string and the order in which the atoms of the molecules are traversed in a depth-first traversal. Thus, the same molecule can have widely varying SMILES representations (see Fig. 1). While canoni- calization algorithms, which assign priorities to the atoms of a molecule based on the molecular topology, can be used to obtain a unique rep- resentation for a molecule it is still unavoidable that some structurally similar molecules have significantly different canonical SMILES repre- sentations. Generally, it can be stated that similar SMILES represent sim- ilar molecules while the converse might only be true to a limited extent. This issue can be addressed during training of the models by augment- ing the training set by randomizing or enumerating all possible SMILES representations of a molecule. A number of studies have shown that this has a positive effect on the performance [22,29,30].

Given the reasonable assumption that the more complex the repre- sentation, the harder it will be for a deep GM to generate valid rep- resentation, variations and alternatives to the SMILES notation have been developed aimed at making it easier to generate valid representa- tions. The DeepSMILES notation [31] is a grammatical simplification of SMILES that does not require matching parentheses or correctly paired numbers for cyclic bonds (see Fig. 1). While this notation has not been widely adopted, studies have shown that the use of DeepSMILES can make it easier for a GM to generate valid representations although im- provements were not considered major [22].

Fig. 1. Molecular representations. For thalidomide, several linear representations are shown. Canonical and three randomized SMILES were generated using RDKit (https://www.rdkit.org). DeepSMILES and SELFIES were determined on the basis of the SMILES representations. Due to their length only one randomized SELFIES is shown.

(see Fig. 1). This ensures that any GM generating SELFIES, will, by de- sign only produce valid molecules. In SELFIES, symbols have to be in- terpreted in a context-dependent manner, e.g., the same symbol can in- dicate a specific element, the size of a sidechain, or the size of a ring. The complex semantics of SELFIES has the effect that small changes in the syntax can lead to structurally highly dissimilar molecules. Thus, while a model based on SELFIES would generate only valid represen- tations it might be much harder to learn structural properties from a reference CS with the goal of expanding it. This observation has been confirmed showing that indeed SELFIES-based GMs will generate 100% valid molecular representations, however the CS covered tends to differ more strongly from a reference training set regarding metrics character- izing structural and physicochemical properties [22].

Approaches from machine learning and utilization of optimization algorithms have been incorporated in GMs for CS exploration that pre- date the rise of deep learning in chemoinformatics [12]. Most common among these are fragment-based methods relying on fragment recom- binations [33–38] that can be either explored combinatorially or using single or multi-parameter optimization strategies [39,40]. These meth- ods typically employ probabilistic methods with the aim to generate chemically reasonable molecules and optimize these with respect to one or more endpoints.

Popular probabilistic methods used in fragment-based GMs include genetic or evolutionary optimization algorithms (GAs) [38–43], ant colony optimization [44], Markov chains [35], or Monte-Carlo tree search [43]. By design, all these methods are well suited for focused or goal directed CS exploration campaigns because their iterative proba- bilistic nature can guide exploration towards CS with favorable prop- erties as part of a single or multi-objective optimization strategy. Fragment-based de novo design methods are not limited to exploration of local CS and can also be adopted for generic sampling of CS [38] putting the emphasis on exploring reasonable synthetically accessible CS where the distribution of generated molecules mimics that of a reference set to which the models are adapted.

By design, fragment-based methods (and the grammar-based ChemGE method) incorporate basic chemical knowledge so that the generated output consists of correct chemical structures following ba- sic valence rules and is directed toward chemically reasonable CS. In DNNs however, these aspects need to be learned during training. First, a model needs to learn to generate syntactically valid molecular repre- sentations, and, second, the molecules generated should properly reflect the reference CS on which the model was trained. These goals are not strictly separable during training. Initial training of DNNs requires rel- atively large data sets. Retraining techniques like transfer learning or reinforcement learning can be used to direct the CS of a DNN towards a specific region of interest, e.g., molecules showing favorable proper- ties or specific bioactivities, for which only small amounts of data are available.

erative networks have been suggested based on this principle [46–51]. Frequently, however, RNNs are used as modules in other DNN architec- tures. E.g., the learned hidden states of RNNs can be used as the basis for encoding molecules in a so-called latent space as part of variational autoencoders (VAEs) [15,29]. They have also been used as generators in GANs [54] or autoencoder-based GANs [55–57] instead of more con- ventional convolutional neural networks.

two DNNs (See Fig. 2b), one to encode the representation as a latent vec- tor and one to decode the latent vector, recreating the original represen- tation (or an alternative representation for the same molecule [29]). The latent space is a relatively low-dimensional mostly non-redundant vec- tor space. Because the projection mapping of molecules into this space has to be learned and is not predefined by the architecture it is possible to train autoencoders in such a way that neighborhoods in latent space reflect similarities of properties or biological activities of interest. Thus, sampling from neighborhoods of molecules in latent space can be used to sample novel molecules with similar properties thus expanding the local CS [15,16,29,58,59].

A GAN consists of two components, a generator and a discriminator [27]. Based on a trainable probability distribution, the generator will generate molecular representations while the discriminator will classify a representation as either “real” or “fake” aiming to distinguish “real” molecular representations from a reference training set from “fake” ones produced by the generator (see Fig. 2c). The two networks have op- posite goals, hence the name “adversarial”; while the discriminator’s task is to accurately distinguish real from generated samples, the gen- erator’s goal is to make this task as hard as possible for the discrimi- nator. The generator and discriminator network are trained simultane- ously, and learning is achieved by the competitive nature of the pro- cess. While different GAN architectures have been proposed for CS ex- ploration [54,60], for instance using RNNs as generators [54], they are also often combined with autoencoders in what are known as adversarial autoencoders (AAEs). Here, a generator samples from the latent space of the autoencoder while a discriminator distinguishes real from fake latent vectors. Independent of the discriminator, the decoder is used to generate the molecular representation from the latent vector [55–57,61] (see Fig. 2d).

sentations can be modified during training, they can also be tuned to reflect similarities of chemical properties of interest. Gómez-Bombarelli et al. [15] and Colby et al. [16] modified the loss function of the VAE to include regression errors with respect to molecular properties in order to control latent space representations and allow optimization of such properties in latent space. In AAEs, the distribution of molecules in la- tent representation is controlled directly by the discriminator, which has been shown to improve the continuity of latent space representations [66]. Polykovskiy et al. [56] and Hong et al. [61] combined molecular representations with molecular properties resulting in latent space rep- resentations that allow conditional generation of molecules with desired properties. Here, latent space of molecular representation is trained to be independent of specific molecular properties while the decoder is augmented with a property vector to generate molecules with desired properties.

The nature of DNNs precludes easy interpretation, which makes it hard to rationalize how CS is covered by deep GMs. Generative DNN models like VAEs, AAEs, or GANs sample from a continuous latent space. They are trained with the goal that neighborhoods in latent space represent meaningful neighborhoods in generated CS characterized by continuity with respect to structural changes and/or with respect to physicochemical or biological properties. Contrast this with fragment- based methods using randomization to compose, combine, and recom- bine fragments. By design, such methods can, for instance, mimic the frequency of fragments or functional groups from a reference set and ensure that generated molecules share similar structural features. The obvious limitation here is that fragment-based models might be too con- servative in their approach and explore CS based on structural similarity alone. While deep GMs are not restricted in this way, they have to ac- quire all their chemical knowledge by training, which is an additional challenge in generating CS that reflects structural and physicochemical properties of a reference set. This aspect, combined with their opaque nature makes validation and assessment of generated CS a central aspect of building successful models. Several recent publications have focused on assessing and benchmarking the CSs generated by fragment-based and deep GMs [22,67,68].

uniqueness of generated molecules. These quantities can be easily cal- culated from a reference set and a sample of generated molecules. The validity criterion assesses to what extent a GM generates valid repre- sentations of chemically sound structures. In some sense, validity by itself can be considered the least crucial of these aspects. The validity of a molecule can be easily checked with respect to syntactic correctness of the chosen representation and the adherence to basic chemical rules regarding atomic valencies and bond orders. Thus, as long as a GM pro- duces a significant fraction of valid molecules, invalid representations can be easily filtered out, which could still result in a model that reason- ably samples CS albeit in a less eﬃcient manner. Nevertheless, validity is an important indicator of successful training, as it shows that a model can learn the syntax and grammar of a representation, which can be con- sidered a prerequisite for learning the chemistry and properties of the CS to be represented by the model. Validity has been demonstrated to correlate well with improved performance while training on increasing data set sizes [22].

in a sample of N molecules one can expect to see ca. 37% duplicates. The training set size usually represents a tiny fraction of the targeted CS so that ideally the fraction of novel molecules exceeds 99%. Low novelty can be a sign of overfitting, and low uniqueness can indicate a mode collapse. Mode collapse describes a lack of diversity of gener- ated molecules and can be ascribed to a concentration of the probability distribution around a few molecules. While a GM should aim to maxi- mize these metrics, its potential to do so might be limited if the size of the targeted CS is small; for instance when exploring CS around specific scaffolds [69].

GMs were used to sample one billion compounds each and the best re- sulting models achieved a coverage of 39%. Following the argument above, a coverage of about 63% would be the theoretically best perfor- mance that could be expected assuming perfect coverage and identical probabilities for each molecule. Given that the GMs also generated a significant portion of molecules not covered by GDB-13 this indicated that the GMs are indeed able to cover a significant part of the whole GDB-13.

While validity, novelty, and uniqueness can confirm that a GM will indeed explore novel CS, these metrics are not suﬃcient to characterize it regarding relevant biological and physicochemical properties. Beyond purely random sampling of CS, the envisioned utility of GMs lies in their ability to generate novel compounds having properties that are charac- terized by a reference set used for training either directly or as part of re- training to focus the covered CS. The ability of GMs to adequately cover the targeted CS can be assessed by comparing the property distributions of the training set molecules and the sampled molecules. For practical applications this approach is limited to properties that can be easily com- puted. These include simple descriptors like molecular weight or atom composition, topological descriptors like the Bertz topological complex- ity [71], or physicochemical properties like the octanol-water partition coeﬃcient logP(O/W) for which computational models exist [22,67,68] but also extends to more complex descriptors like the synthetic acces- sibility score [10] and the quantitative estimate of drug-likeness [11]. The similarity between reference and sample distributions is quantified using metrics like the Kullback–Leibler divergence, the Jensen–Shannon distance or the Wasserstein distance [22]. Structural similarity can be assessed based on scaffold and fragment distributions [68] and on Tan- imoto similarities of structural fingerprints [22,67,68] and can also be used to detect issues like mode collapse or strong biases in the trained models.

how representative a CS is with respect to structure and physicochem- ical properties, they do not address biological properties. The Fréchet ChemNet Distance (FCD) [72] has been developed with this in mind. The concept was inspired by the Fréchet inception distance [73]. How- ever, instead of relying on the Inception v3 [74] network for image clas- sification, it relies on a DNN, termed ChemNet, that has been trained to predict bioactivities of molecules for more than 6000 assays. The acti- vations of the neurons of the final hidden layer of the network encode the relevant features for the predictions of the output layer. For a set of molecules the distribution of these activations are modeled as a multi- variate Gaussian distribution. The distributions of a reference set of real molecules and a sample of generated molecules are compared using the Fréchet distance. While the quality of this distance will be limited by the accuracy of ChemNet and the quality and generality of the assay data, the concept is very elegant for the assessment of the biological relevance of a CS.

Under the assumption that larger training data sets should be able to improve the performance of GMs, Skinnider et al. [22] studied the correlation between the metrics discussed here and training set size. The found a very high correlation between validity and training set size (using SMILES). FCD also showed high correlation, while most struc- tural and physicochemical descriptors showed good to satisfactory cor- relations. While smaller training sets were suﬃcient to generate valid representations at a reasonable rate, other metrics improved signifi- cantly with larger training sets. This indicated that it was easier for GMs to learn the syntax of the representations, but more information was required to accurately reflect the CS of the reference sets. Somewhat counter-intuitively, training set sizes were only slightly correlated with uniqueness and negatively correlated with novelty. A possible explana- tion might be that a GM that only learned the grammar and is not (yet) restricted by the properties of the reference space might be less likely to reproduce training molecules while generating unique molecules at a similar level.

Analyzing latent space representations can yield insights into how similarity is perceived by a deep GM. For instance, in Ref. [55] the rela- tionship between neighborhoods in latent space and structural similar- ity of exemplary compounds was investigated. A more recent approach used generative topographic mapping to map the latent space of an au- toencoder onto two dimensions [75], which the authors then used to construct an activity map of adenosine A2a receptors visualizing how these active compounds were distributed in latent space.

In Ref. [76], input saliency maps of SMILES were used to aid the interpretability of the generative process. Input saliency maps assign a score to each token indicating its relevance for the next token to be generated. Mapping the tokens to molecular structures then makes it possible to interpret them in a chemical context.

Cho K, van Merrienboer B, Gulcehre C, et al. Learning phrase representations us- ing RNN encoder–decoder for statistical machine translation. In: Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). Association for Computational Linguistics; 2014. p. 1724–34.

