Abstract The ‘‘near-repeat” effect is a well-known criminological phenomenon in which the occur- rence of a crime incident gives rise to a temporary elevation of crime risk within close physical prox- imity to an initial incident. Adopting a social network perspective, we instead define a near repeat in terms of geodesic distance within a criminal social network, rather than spatial distance. Specifi- cally, we report a statistical analysis of repeat effects in arrest data for Chicago during the years 2003–2012. We divide the arrest data into two sets (violent crimes and other crimes) and, for each set, we compare the distributions of time intervals between repeat incidents to theoretical distribu- tions in which repeat incidents occur only by chance. We first consider the case of the same arrestee participating in repeat incidents (‘‘exact repeats”) and then extend the analysis to evaluate repeat risks of those arrestees near one another in the social network. We observe repeat effects that dimin- ish as a function of geodesic distance and time interval, and we estimate typical time scales for repeat crimes in Chicago.

Criminological studies have shown that crime is not uniformly distributed among victims, arrestees and places, with repeat crimes playing a fundamental role [5]. In fact, about half of all crimes in the United States are committed by repeat arrest- ees [19]. Moreover, some reports [4] have suggested a high degree of overlap between victim and arrestee populations, and research has already demonstrated that victims of per- sonal or property crimes and of gun violence experience ele- vated crime risks within months of an instigating incident [8,16]. Thus, it is reasonable to expect the same effect to exist

In the field of criminology there is a well-known phe- nomenon known as the near-repeat effect, which refers to a tendency for crime risk to be temporarily increased within the near vicinity of recent crime incidents (i.e., incidents that have taken place nearby in both space and time; e.g., [10,20]). In this paper, we hypothesize the existence of a different kind of near-repeat effect, in which we modify the definition of ‘‘near” to refer not to geographical relationships among crime incidents, but rather to crime-related interpersonal rela- tionships among the individuals involved in these incidents. We measure the notion of interpersonal distance by using the well-established concept of ‘‘degrees of separation,” which is known technically as geodesic distance. In this paper we define geodesic distance in a criminal social network as follows: If Person A and Person B have been arrested previously in con- nection with the same crime incident (co-arrested), they are said to have one degree of separation. If, in turn, Person C has been co-arrested with Person B, then Person C is said to be separated from Person A by two degrees, and so on. Thus, we hypothesize that a crime incident involving Person A, will temporarily increase the crime risk for individuals such as Persons B and C, who are near Person A in this specific sense that we have defined. Later we show that the hypothesized effect does indeed

The immediate motivation for our study is to inform an ongo- ing collaborative effort between the Chicago Police Department and our research team at the Illinois Institute of Technology. In this initiative, we have successfully developed and deployed prediction algorithms that estimate the risk of future violence for persons with extensive criminal records. We anticipate that our prediction algorithms will be enhanced by exploiting the probabilistic relationship, if it exists, that would be implied by the aforementioned interpersonal near-repeat effect. Thus, the present work not only informs our fundamental understanding of crime behavior, but is also expected to have practical implica- tions for the prediction of crime, which is a rapidly emerging field [18]. We next review basic concepts of the near-repeat effect and social networks so as to place our work in context.

Repeat crimes may occur for various reasons, including event dependence linked to the psyche, actions, and environ- ment of arrestees [10], with some facet of the arrestee’s previous experience increasing the chances of participation in a subsequent incident, with the possibility of the effect spreading to others in the same environment and social groups as the original arrestee [16]. With victims and arrestees tending to belong to similar populations, event dependence suggests the formation of crime patterns establishing positive feedback, eventually escalating into situations involving an excess of dangerous persons or groups, and areas of high crime density. Effective policing strategies would identify these situations as they are forming, thus ceasing the spread of further crime.

Rengert [20] investigated repeat effects in shootings in Philadelphia, PA, using a modification of a standard Knox test [12]. Short et al. [22] showed that repeat effects exist among burglaries in Long Beach, CA, and further showed that these effects decrease with distance in space and time.

Social networks have recently been used to investigate the influence that an individual has on his peers [16,17]. There are many reasons to suspect the spreading of repeat effects in a criminal social network. First, many violent crimes are dri- ven by emotions created by social relationships and thus occur between persons who know one another [9]. Second, condi- tions favoring the participation in crime incidents are spread through peer influence [7]. Third, physical objects such as drugs or weapons are usually dispersed through interpersonal connections, implying that the illegal selling and use of these objects also occur through these connections [6].

For the remainder of this paper, we will present repeat anal- yses on crimes that occurred in Chicago, IL, during the years 2003–2012, by integrating statistical techniques with a social network perspective. Unlike previous repeat studies that have been concerned with spatial locations and geographical dis- tances of crime incidents, we will focus on arrestees and rela- tionships among arrestees. Each incident in our dataset includes a unique identification number for each arrestee tak- ing part in a crime incident, the date of the incident and the type of crime. Of particular interest to police is the behavior of violent criminals [4], so we divide our data into two mutu- ally exclusive datasets – one containing only violent crimes and the other containing all other crimes – and we perform analyses on the two datasets separately. We refer to these data- sets as the violent dataset and the non-violent dataset, respec- tively. The former consists of 6630 arrestees, while the latter consists of 941,029 arrestees.

Through the construction and analysis of social networks and application of statistical techniques, this paper aims to dis- cover patterns by repeat arrestees in Chicago. In Section 1 we use a Poisson model to describe the situation in which events are independent of one another and occur only by chance, referring to this as the null model. We describe and apply our counting technique to test our datasets against the null model, and show that Chicago’s exact-repeat incidents are not due to chance alone. We describe the social network in Section 2, where we measure the spread of repeat effects through the network by keeping track of the geodesic distance between incidents – that is, the network separation of the two arrestees – and applying well-established spatiotemporal descriptive statistics. We show that repeat effects in our data diminish with time and geodesic distance. We conclude the paper with a summary and discussion.

If there were no repeat effects, an individual’s participation in a crime incident would be statistically independent of partici- pation in other crime incidents. This model is contradictory to the existence of repeat effects and will serve as our null hypothesis. Moreover, an arrestee cannot participate in simul- taneous criminal incidents, as such incidents would simply be thought of as a single event. Independence of the incidents implies a Poisson process [21], as reviewed next.

In this section we describe the methodologies used to test for event dependence. For our finite-length data, we employed a moving-window counting method [22] that produces a distri- bution of the observed wait time s, which can be compared to the null distribution in Eq. (2) to test for the presence of event dependence. We applied this method to our violent and non-violent datasets separately.

will not allow sufficient data for the opportunity to disprove the null hypothesis. One extreme is to choose smax as the length of the study’s time frame. In this case, all of the data fall within the buffer period and are discarded. The other extreme, smax = 0, only allows for measurements of s = 0 nothing lar- ger. For our study, we choose smax = 104 weeks (two years,

The counting scheme with smax 104 weeks, applied to a single arrestee, is illustrated by way of an example timeline in Fig. 1, in Supplementary material. The first incident occurs 212 weeks into the study period, and an observation is con- ducted to determine whether a repeat incident occurs within the following 104 weeks. In this example, a repeat incident has  indeed  occurred,  so  the  time  interval  s  96 (308 212 96) is recorded, and the analysis continues through the timeline. The next incident to occur is the one fol- lowing 308 weeks; this was the repeat incident for the previous measurement and is now a potential instigating incident. Again, an observation is made, but this time a repeat incident does not occur within the time window of smax 104 weeks. The analysis continues up to the incident occurring 413 weeks into the study, and it is observed that two later incidents fall within the time window. Since we are counting inter-arrival times of a possible Poisson process, we use the first of these two events, and the time interval s 7 (420 413  7) is added to the record. The buffer period begins after week 416; any possible instigating incident during this period cannot be checked for secondary incidents over the entire time win- dow, and so no further observations are made.

incident by incident for every arrestee in the dataset. The records of s are combined into one master record, and the numbers of observations are summed across all arrestees, yielding the total number of observations N0. We applied this method to the violent and non-violent datasets separately; a graph of the respective histograms is shown in Fig. 2, in Sup- plementary material. For the violent dataset, we made a total

First consider the violent dataset and the upper histogram in Fig. 2, containing N0 4975 observations. Normalizing the histogram to obtain a probability distribution yields the solid blue line in the upper graph of Fig. 3, in Supplementary mate- rial. By summing the probabilities, we see that about 8% of all violent crimes are followed by an exact repeat occurring within 104 weeks of the instigating incident. Next, we determined the least-squares fit of Eq. (2) to the observed data to estimate the rate parameter. For the violent dataset, the least-squares esti- mate of k was found to be ^k = 6.989 × 10—4. The function

is shown as the dashed red curve in the upper graph of Fig. 3. We applied the same procedure to the non-violent histogram with N0  261, 006 observations. Its probability distribution is shown in the bottom of Fig. 3 along with its best-fit curve, determined to have ^k 6.400 10—3. Again, summation of the probabilities reveals that 50% of non-violent crimes are fol-

To test the validity of the exponential distribution in Eq. (2) as a model of our Chicago repeat data, we use the well-known Kolmogorov–Smirnov (K–S) goodness-of-fit test [14,11], the basic premise of which is to compare the observed cumulative distribution function (CDF) with the CDF of the assumed null distribution. If the maximum discrepancy between the observed and null CDFs is larger than a specific confidence threshold for a given sample size, the null distribution is deemed an unacceptable model of the data. On the other hand, if the discrepancy is less than the threshold, the null distribu- tion cannot be rejected.

In this study each arrestee in a dataset defines a node hav- ing a unique label within the social network. For purposes of anonymization, we refer to each arrestee using a unique inter- nal record (IR) number. When two or more subjects are arrested as part of the same incident, their respective nodes become connected in the social network. The edge connecting this pair of nodes forms on the day the incident occurred; thus, the social network is constantly evolving. The network is an undirected graph, as there is an inherent symmetry between co-arrestees: if IR1 is arrested with IR2, then IR2 is arrested with IR1. For simplicity in this initial investigation, the edges are unweighted (two subjects are either connected or not, and no connection strength is assigned to the edge that connects them). Although our network is dynamic, unweighted, and undirected, the analysis to follow can readily be adapted to other types of networks.

Although we will separately analyze the repeat behavior of violent and non-violent crimes, we use a single, common social network for all arrestees. We measure the separation between two subjects in the social network using the geodesic distance between their nodes, i.e., the minimum number of edges that must be traversed to move between the nodes. It should be

dataset, the observed CDF, F(s), and the null CDF, F(s), for s 6 104, as well as the maximum difference DN0 between the two. Our violent dataset yielded a K–S test statistic of 0.0251, which is greater than the confidence threshold of 0.019, and so we can reject the null hypothesis that violent inci-

0.003. It should be noted that one cannot infer conclusions about the precise value of s for which DN0 occurs (which may not even be unique); the test can only reject the null hypothesis and does not provide insight as to the time frame of elevated repeat risk. However, finding a s for which

we used the first four years (208 weeks) of data as an initial network setup, or ‘‘burn-in” period, during which the network evolves without taking measurements. This is to ensure that the measurements are taken from a network in steady state. In the example in Fig. 5, after the burn-in period, IR1 is arrested in week 209, and his immediate neighbor in the net- work, IR2, is arrested in week 245. Thus we obtain a measure- ment  of  the  wait  time  between  arrests  of  s  36

245 209  36 , indicated in Fig. 5 with a blue line connect- ing the two incidents. The next arrest occurs in week 212, again involving IR1, after which the soonest arrest of IR2 is again in week 245. Therefore the next measurement of wait time is s 33 (245 212 33). Now the arrest of IR2 in week 245 becomes the instigating incident for the arrest of IR1 in week 275, and s = 30 is recorded (275 — 245 = 30). Both of the sub-

An absence of network data for IR1 and IR2 in week 275 indicates that the two arrests are related to separate crime inci- dents (as is the case for the two arrests in week 201). This is significant because we keep track of the elapsed time since the two were linked and allow the link to expire if this time exceeds four years. By removing connections that become ‘‘stale” after several years, we maintain a network with relevant relationships. A link may be renewed should the subjects be arrested together again. In the present example, IR1 and IR2 are linked in week 100 and the link is never renewed. Thus, their link expires in week 308, shown as a vertical dashed line in the figure, and no measurements are taken beyond that time. By choosing an expiration time equal in duration to that of the net- work burn-in time, the network temporal window is held con- stant in duration; it is never longer or shorter than four years.

In the traditional spatial case, the point density ~k is usually chosen as the average number of points per unit area. Doing so gives the researcher a meaningful and convenient way to quantify the spatial clustering relative to that expected by a Poisson process. However, as explained earlier, there is no rea- son to believe our data follow a Poisson process; however, analogous to the spatial case, we can still define ~k as a rate esti- mated as N divided by the total number of subjects divided by the total number of weeks in the study.

In the context of near repeats, the summation in Eq. (3) is simply a count of the number of pairs of arrests occurring exactly s weeks apart involving subjects separated by geodesic distance n. We have already performed this count; it is Nn pn s . Therefore, we can express the O-ring statistic in Eq. (3) as

simultaneity. If independent events are allowed to occur simul- taneously, then the time intervals between events will not be exponentially distributed [21]. Nevertheless, statistical testing of our observed distributions can be done using Monte Carlo simulations to estimate a null distribution.

We calculated both statistics using our observed distributions, and in order to compare the statistics to those under the null hypothesis, we performed Monte Carlo simulations in which the dates of the subject-date 2-tuples are randomly permuted. Reshuffling the date data is a common strategy in this situation when the null distribution is unknown. Originally applied in Besag and Diggle [3], this strategy was also implemented in Ratcliffe and Rengert [20] to evaluate near-repeat shooting patterns in the city of Philadelphia, PA.

different questions. For example, if we hypothesize that near-repeat effects only last for a certain duration and then ‘‘expire,” and the accumulating nature of the K statistic should identify the time at which the effect expires. In this case, we would expect elevated K statistics at short time intervals and moderate K statistics falling within confidence intervals at lar- ger time intervals. The O-ring is more of an instantaneous met- ric identifying specific times of heightened near-repeat risk. An elevated O-ring statistic at, say, s 4 weeks would imply clus- tering of near-repeat incidents four weeks after instigating inci- dents and does not confound with the O-ring statistics at larger values of s. Both statistics are of interest to us; therefore we consider both in our analysis.

hypothesis, we randomly permute the dates of all arrests while holding the subjects fixed, and, with the new data, calculate and plot the O-ring and K statistics. This process is repeated for 95 random permutations for the sake of constructing a 95% confidence envelope, also plotted in Fig. 6. Randomly permuting the dates has the effect of observing how O-ring and K statistics would appear should there be no spatiotempo- ral relationships [20].

Next we consider the non-violent dataset for which we con- ducted the same analysis as for the violent dataset. The results are shown in Fig. 7, in Supplementary material. For n  1, 2, the figure shows that the O-ring statistic falls outside of the

The above pioneering approach of fusing the O-ring and K statistics with a social network analysis provides knowledge of the temporary influence one has on his peers within the net- work. This influence may be described by the strength of the influence – that is, the maximum geodesic distance for which the influence is observed – and its persistence, i.e., for how long, temporally, the influence is observed.

Since the O-ring statistic is, as explained previously, a mea- sure of instantaneous effect, it provides insight concerning the time scales of repeat incidents in our Chicago datasets. For instance, the O-ring statistic is elevated for our violent dataset during roughly the first 25 weeks for n 1, indicating (possibly for the reasons outlined in the introduction) an increased chance of a violent repeat crime occurring within about six months of an initial violent crime for subjects directly con- nected in the network. During this time, we observe 58% more repeat incidents than expected by chance. The K statistic reaches a maximum separation from its confidence envelope during this time period before it begins to approach and finally penetrates the envelope at about 90 weeks. Thus the total num- ber of violent repeat crimes separated by less than 90 weeks is more than what would be expected by chance alone.

A similar argument can be made for the violent n  2 case in which the O-ring statistic in Fig. 6 implies an elevated prob- ability of violent repeat crimes occurring within just two months of an initial violent crime. During this time, we observe 70% more repeat incidents than expected by chance. The K statistic demonstrates an elevation in the total number of vio- lent repeat crimes separated by less than 80 weeks. Finally, our results for n 3 and n 4 (n 4 not shown in the figure) demonstrate no statistically significant violent near-repeat effects; thus the concept of ‘‘near” for violent crimes may be limited to arrested individuals within two degrees of network separation.

The K statistics in Fig. 7 show a near-repeat effect which decreases in both time and network space. For n 1 neigh- bors, more near-repeat crimes are observed within 22 weeks of instigating incidents than would be expected by chance; however, this time frame decreases as subjects become further separated. For example, there are more repeat crimes than expected only for the first 20 weeks for n  2, 10 weeks for n  3, and 8 weeks for n  4, and the number of crimes are as expected for n  5 and n  6 (n  6 not shown in the fig-

ure). During these time frames, we see 10.47% more crimes than expected for n  1, 4.91% for n  2, 3.06% for n  3, and 2.96% for n  4. The K statistics show repeat effects at n  3 and n  4 while the O-ring statistics do not. This is

This paper demonstrates conclusively that an individual’s crime risk increases for a period of roughly 25 weeks (about 6 months) following a crime involving a person within two or less degrees of separation from an individual involved in that crime. To make practical use of this finding, we are cur- rently in the process of revising our prediction model by including new variables pertaining to first- and second-degree connections, as well as a weighting function that gives greater emphasis to the effect of recent crime incidents, as opposed to those in the more distant past. In addition to the practical sig- nificance for our current project, the findings of this paper pro- vide us with fundamental insights about patterns of crime and its temporal and interpersonal behavior, for both violent and non-violent crime types.

In this work, to test for the presence of a social-network near-repeat effect, we conducted statistical analyses of arrest data to measure exact-repeat and near-repeat effects within Chicago’s criminal social network for both violent and non- violent crimes. For exact-repeats, we modeled the situation in which arrests are independent of one another as a Poisson process, and therefore inter-arrival times were compared to an exponential distribution. We selected the distribution’s rate parameter to minimize the residual sum of squares and quan- tify the goodness-of-fit using the popular K–S test. The K–S test rejects the null hypothesis of independence for both of our datasets with 95% confidence.

incident. With the network in place, we recorded the time intervals between repeat incidents, this time keeping track of ‘‘distances”, or the degree separation between graph nodes. By recording these geodesic distances, we allowed for the sep- arate examination of temporal and spatial effects using Rip- ley’s K and O-ring statistics. In order to compare these statistics to those of a null distribution of no dependence among incidents (across time and geodesic distance), we ran- domly permuted arrest dates and then recalculated the test statistics. The results showed elevated repeat effects that decrease over time and geodesic distance within the network. For violent crimes in particular, we have observed that the near-repeat effect extends to neighbors separated by a geodesic network distance of n		2, with the effect most prominent for neighbors of n	1. Further, we have seen that this effect expires at most 25 weeks after an instigating crime. Therefore, when considering the role one individual’s crime plays on the risk of a second individual, we must only concern ourselves with crimes from n	1 and n	2 neighbors, from at most 25 weeks ago. As explained earlier, these findings will inform future predictive models for identifying individuals at high risk

This project was supported by Award No. 2011-IJ-CX-K014, awarded by the National Institute of Justice, Office of Justice Programs, U.S. Department of Justice. The opinions, findings, and conclusions or recommendations expressed in this publica- tion are those of the authors and do not necessarily reflect those of the Department of Justice.

