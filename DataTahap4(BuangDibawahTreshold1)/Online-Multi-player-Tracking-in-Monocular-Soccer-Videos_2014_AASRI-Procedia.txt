The tracking of players in monocular soccer videos is a challenging task because of numerous difficulties that can occur especially in TV broadcasts, such as camera motions, severe occlusion of players, or inhomogeneous lightning conditions. We propose a new robust method for multi-player tracking, which is based on finding local maxima on a confidence map. This map represents an ensemble of visual evidences, such as colors of the team outfits, responses of a HOG human detector, and grass regions in images. This combination of features allows for a robust online tracking procedure that does not require any further information about the camera calibration or other user input. In the evaluation using four representative datasets, our algorithm shows remarkable accuracy and outperforms a state-of-the-art pedestrian tracker.

In human tracking, the tracking-by-detection approach is widely used for multi-target tracking (see i.e. [2], [3]). Human detectors often show low accuracy and poor computational performance for small objects, while in soccer videos, especially in low-resolution records and wide-angle scenes, player heights of 40 pixels and less are quite common. In contrast, kernel-based approaches, such as the mean-shift tracking [4], often require an initialization of the templates and risk drifting away, due to object-specific template adaption.

In principle, our approach is similar, but we use soccer-specific knowledge to automatically detect players without an exhaustive sliding-window approach. Our observation model is partially based on the ideas of ASPOGAMO [6], but incorporates more universal features, such as the HOG detector, and does not need any human-guided initialization. It is similar to the method proposed by [7], which is, however, a stand-alone player detection and does not incorporate tracking information over time.

Player positions. In our approach, the position of a player 𝑝𝑖 is modeled within an image 𝐼𝑡 at time 𝑡 using an axis-aligned bounding box 𝐵𝑖 ≔ {(𝑥, 𝑦) ∈ ℕ2 | (𝑥𝑖 ≤ 𝑥 < 𝑥𝑖 + w𝑖) 𝖠 (𝑦𝑖 ≤ 𝑦 < 𝑦𝑖 + ℎ𝑖)}, where (𝑥𝑖, 𝑦𝑖) is the upper-left corner and w𝑖 and ℎ𝑖 are width and height, respectively. A bounding box describes the extent of a player in the image and in our method the aspect ratio is fixed to w𝑖 ≔ 0.41ℎ𝑖 (see [8]).

Unsupervised generation of color templates. According to the FIFA rules [10], the colors of the jerseys have to be chosen so that the players from different teams, the referees, and the goal keepers are all pairwise distinguishable. We make use of this fact by initially determining color templates for each type of outfit, based on color histograms.

𝑑𝑚𝑖𝑛 ∶= mini𝑑𝐻(ℎ𝑖, 𝑜(ℎ𝑖)) and the maximum distance as 𝑑𝑚𝑎𝑥 ∶= maxi𝑑𝐻(ℎ𝑖, 𝑜(ℎ𝑖)). With the threshold parameters 𝑡𝑚𝑖𝑛 and 𝑡𝑚𝑎𝑥 , our decision criterion is (𝑑𝑚𝑖𝑛 ≤ 𝑡𝑚𝑖𝑛 ) 𝖠 (𝑑𝑚𝑎𝑥 ≤ 𝑡𝑚𝑎𝑥 ). During tracking each tracked bounding box is assigned to the outfit class with nearest distance 𝑑𝐵 at the moment of detection.

HOG-based human detection. We trained a human detector based on histograms of oriented gradients (HOG) according to [12] with some slight modifications to their default detector. We use a 64×128 pixels detection window with a human size of 41×100 pixels (see [8]). To allow for an efficient calculation, we do not apply a Gaussian spatial window during the accumulation of the histograms. To avoid soccer-specific overfitting, the classifier is trained using the INRIA pedestrian data set [12].

HOG-based evidence. We use a human detector, trained as described in section 2. A resized sub-image with size of 64×128 pixels is generated for each bounding box 𝐵˜𝑡, so that the height of the bounding box corresponds to 100 pixels in the sub-image, the sub-image has the same center point as the bounding box, and the aspect ratio of the pixels remains unchanged. This sub-image is used to perform a classification of the human detector. The result of the classifier is a decision value 𝑑𝐷(𝐵˜𝑡) ∈ ℝ, which is mapped using the

Maximization of the confidence. For every new time step, we search for positions with a local maximum on the confidence map near the Kalman predictions. To keep the number of calculations low, we propose a simple greedy heuristic: we iteratively optimize the confidence with respect to the positions of the bounding boxes, while their sizes and the region 𝑅𝑡 remain fixed, thus for 𝑛𝑡 bounding boxes, we have 2𝑛𝑡 variables. In

current position and determine the position with the highest confidence value. If this value is higher than the value at the current position, the iteration continues, starting at the best position. Otherwise, the iteration stops with the current position as the result. Usually, our efficient greedy approach stops after 2-3 iterations and shows, however, satisfactory results.

Measurement of object size. Mainly due to perspective projection the size of a player in the image depends on the image position. To enforce consistency, we normalize the sizes of the predicted bounding boxes before the maximization step. For this purpose, we fit a linear model using a least-squares approach, where the height ℎ is the dependent and the coordinate 𝑦 is the independent variable. Afterwards, the height of each bounding box is adapted according to this model and the width is determined by w ≔ 0.41ℎ (see [8]).

We perform multi-target tracking by applying a single-target Kalman filter [1] for each tracked bounding box. A new measurement is generated by an optimization step with respect to the confidence map using the Kalman prediction as the starting position. The detection of new and lost targets is performed with the help of deterministic heuristics, which are guided by the confidence map.

foreground region 𝐹0 with an appropriate orientation and aspect ratio as single player candidates. In the neighborhood of each candidate, we perform a sliding-window human detection with a scale space which depends on the size of the candidate region. The positive detections are used to fit our linear size model. The human detection is repeated in the neighborhood of all connected components of 𝐹0 with a restricted scale space depending on the position of the region in the image. Again, the positive detections are used to fit the size model and to estimate the team histograms (see section 2). These detections are the starting point for the first maximization step resulting in the initial player positions.

w3 ≔ 0.05, w4 ≔ 1.0, w5 ≔ 0.5, w6 ≔ 0.05, 𝑡𝑙𝑜𝑠𝑠 ≔ 0.35, and 𝑡𝑑𝑒𝑡𝑒𝑐𝑡 ∶= 0.7. We evaluate our system with the help of MOTA and MOTP [13] and use manually annotated ground truth of the following video sequences:

Ground-truth and tracked bounding boxes are fixed to an aspect ratio 0.41:1 as proposed in [8]. Some annotated targets that are outside the field (like coaches and linesman), as well as ground-truth bounding boxes that are cropped by the image boundaries, are added to an ignore list, i.e. they don’t need to be matched, but it is not an error if they are matched.

Our baseline is the publicly available tracker of Zhang et al. [5], which achieves state-of-the-art tracking results on pedestrian tracking datasets. We used the standard parameter values which come with the source code, except the HOG_DETECT_FRAME_RATIO, which we set to 2 for BL and ISSIA, and to 3 for GH and VS allowing to detect small players. As the detector of this tracking procedure generates a lot of false positive detections in the audience area, we ignore all its tracked objects outside our field hull 𝐻𝑡 at time 𝑡.

Figure 2: MOTA (top row) and MOTP (bottom row) results (in dependence of the overlap threshold) of the proposed tracking procedure in comparison with the procedure of Zhang et al. [5]. Results are given for each data set (GH, BL, ISSIA, VS) from left to right.

We proposed an unsupervised online 2D tracking procedure for players in monocular soccer videos that applies an efficient determination of local maxima in a confidence map. This map is based on a robust combination of soccer-specific (grass color), match-specific (team outfit colors) and general (HOG detector) image features. Avoiding a time-consuming sliding-window approach our system allows for a fast player tracking that in addition does not require any further input, such as user input or camera parameters. Our tracking results achieve high accuracy and outperform a state-of-the-art pedestrian tracker.

