The network is composed of an interconnected system of perceptrons that act as basic information-processing units. Fig. 3c displays a percep- tron in more detail. The perceptron algorithm consists of four parts: (i) input values, (ii) weights and a bias, (iii) a weighted sum, and (iv) an

typically overcomes the vanishing gradient problem [81]. ReLU outputs the input directly if it is positive; otherwise, it will output zero. ReLU has become the gold standard activation function for many types of DNNs because models that use it are easier to train and often achieves better performance [82].

For any type of problem, the DNN architecture needs to be specified before training. Untrained DNNs are created as "ignorant" systems, and it is only through exposure to the data, that their ignorance slowly de- creases. The main way to measure such learning is by monitoring the error produced by the network each time it makes a prediction. Mech- anistically, the signal of the input data moves forward through the pre- specified network towards the output layer and then backpropagates in- formation about the error measured with a loss function, at which point the neuron connection weights are updated [83]. The propagation and backpropagation (Fig. 3e) are repeated several times, according to the specified number of epochs, a hyperparameter that defines the number of times (i.e., interactions) the error will backpropagate through the net- work [84]. An epoch is made up of one or more batches, where a part of the dataset is used to train the neural network. Therefore, to train a DNN is to maximize an objective function by optimizing the weights and biases of each neuron [67,83].

Fig. 3. Learning process based on DNNs. (a) Performance of ML vs. DL models with respect to the amount of data; (b) Architecture of a typical Feedforward Neural Network (FNN); (c) Perceptron model; (d) Frequently used activation function; (e) Forward propagation and backpropagation of error in typical DNNs.

The fully connected FNN (Fig. 3b) is the most common architecture of DNNs. In this network, the information moves in a single direction, from the input layer to the output layer, without loops or backward con- nections [85]. Already, the RNNs were designed to identify patterns in sequential data, such as Simplified Molecular Input Line Entry Speci-

fication (SMILES) strings. Although they are still the most used repre- sentations in RNNs, SMILES have no mechanisms to ensure that strings are valid with respect to physical principles and syntax. In view of this, SELF-referencing Embedded Strings (SELFIES) have been suggested as a chemically more intuitive alternative, as every combination of symbols in its alphabet maps to a chemically valid graph [88]. The RNN archi- tecture (Fig. 4a) has three types of layers: the input layer X0, the hidden

previous states, meaning that the same input could produce a different output depending on previous inputs in the series [102]. However, a default RNN (Fig. 4b) is unable to capture temporal dependencies that extend to more than a limited number of time steps (long-term depen- dencies). Therefore, Long-Short-Term Memory (LSTM) [89] and Gated Recurrent Unit (GRU) [90] networks specifically address this limitation. Compared to the default RNN (Fig. 4b), the cell state of LSTM (Fig. 4c) architecture, introduced by Hochreiter and Schmidhuber [89], offers a solution for vanishing/exploding gradients by preserving and

from ‚Ñéùë°‚àí1 that needs to be passed along to the next state ‚Ñéùë° . In contrast, new state is just a copy of the old state, i.e., the amount of information the reset gate controls how much of the ‚Ñéùë°‚àí1 needs to be neglected [92].

Among GCNN representations, geometric DL approaches have been employed for predicting the binding conformations of ligands to pro- tein targets. Concretely, the model learns based on distance likelihood which is tailor-made for each ligand-target pair. In the first step, the neural network extracts a pool of mesh (i.e., collection of nodes, edges, and faces) which defines the shapes of the molecular surfaces of bind- ing sites. In a similar way, ligands are represented as a two-dimensional undirected graph, where atoms and bonds are represented by nodes and edges, respectively. Both the target mesh and the ligand graph are pro- cessed by independent residual GCNNs. In the following step, the pro- cessed features from the protein targets and ligands are concatenated using a mixture density network to model the interaction of the ligands with the targets [99].

To tackle the challenges of multi-target drug design, numerous ef- forts are being made in the DL field to develop multi-task models. Multi- task learning (MTL) is an inductive transfer approach in which multiple tasks (e.g., targets) are simultaneously learned by a shared model. Such an approach is particularly interesting since MTL-DNNs can explore rep- resentations learned across different tasks and boost the performance of tasks with fewer training examples [100,101]. Previous studies suggest that MTL can offer a strong improvement in predictive performance over single-task methods [102]. According to Rodr√≠guez P√©rez and Bajorath [75], MTL models provided incremental advantages for predicting the most challenging biological properties. When MTL models were evalu- ated on tasks that share chemical information, the obtained results were generally superior to single-task learning (STL) models. In cases where STL model accuracy was limited, the largest relative performance gains of MTL models were observed [75].

There are several approaches for optimizing and calibrating MTL models. Existing works often focus on developing aggregated loss func- tions adapted to sparse data as a way to learn multiple tasks at once. Different loss weighing mechanisms may be used to aid MTL optimiza- tion, such as adding weights to the individual loss functions to prevent a task with more data from dominating the optimization [103].

Most existing MTL models are based on sharing parameters across hidden layers. The parameter-sharing mechanisms in MTL are divided into four categories: (i) hard parameter sharing [104], (ii) soft param- eter sharing [104], (iii) hierarchical sharing [105,106], and (iv) sparse sharing [107,108]. In hard parameter sharing, the hidden layers of the neural network are shared while keeping some task-specific output lay- ers. Sharing most of the layers for the related tasks reduces the chances of overfitting, but when tasks conflict, the learning is easily affected by negative transferring, which is harmful to the model performance [104]. The soft parameter sharing mechanism has independent param- eters and subnet for each task, but their information can be mutually learned. The approach regularizes the distance between the parameters of the individual subnets to the overall training objective to encourage similar model parameters between the different tasks [104]. The hier- archical sharing considers the progressive relationship between tasks, which means that a task may be a subtask of another one, thus placing them on different network layers [104‚Äì106]. On the other hand, the hi- erarchical sharing mechanism may be a complex problem that relies on prior knowledge of task relations [104,109]. The sparse sharing mech- anism automatically extracts subnets for each task based on the idea of the lottery ticket hypothesis. The obtained subnets are overlapped and trained in parallel [107,108].

This app has an intuitive user interface, in which the user may draw a compound of interest or directly submit the SMILES string of a queried chemical structure to prediction. Given the verified generalizability of KinomeX, Li and coworkers [111] then performed a comprehensive in silico analysis of diverse compounds with unknown kinase activity pro- files (Fig. 5a). Importantly, the experimental validation of the predicted spectrum shows significant agreement with the experimental data, sug- gesting that KinomeX can be used to discover multi-target kinase in- hibitors [111].

Computational de novo design is an eÔ¨Écient approach to create new molecular structures with desired multi-target profiles at a very low cost and in a time-eÔ¨Écient manner. The increase in the use of DL for de novo design has motivated the generation of platforms such as Molecular Sets (MOSES) [112], REINVENT v.2.0 [113], and GuacaMol [114] to

Inspired by this opportunity, deep generative modeling techniques have been used as emergent de novo design approaches in the early stages of drug discovery, yielding the autonomous ability to which au- tomatically design new multi-target drug candidates [115]. The devel- opment of generative models typically involves a two-step process. Ini- tially, a generative network is trained to generate syntactically plausi- ble structures using a benchmarking dataset of representative structures. Then, the model is fine-tuned to generate only compounds with the de- sired properties. Fine-tuning of the generative model is either carried out using transfer or reinforcement learning (Fig. 5b) [116,117]. Whereas early works used transfer learning to bias the generation task by using a focused dataset of compounds with the desired properties [118,119], it is now common to couple the generation task to a reinforcement learn- ing algorithm, which uses a supervised model to provide property-based feedback to the generative model [119,120]. By interactively exposing the generative model to fine-tuning, it learns common features and then updates its structural outputs to increasingly meet desired properties. Recently, Blaschke and Bajorath [119] developed an approach to create

million bioactive compounds from ChEMBL [122]. Initially, the authors compiled a set of experimentally confirmed no-target (inactive), single- target, and multi-target compounds in the SMILES format. Then, a ran- dom selection of 1000 multi-target compounds was used to fine-tuning the REINVENT generative model via transfer learning (Fig. 5b). After fine-tuning, a decision tree ensemble classifier systematically showed a clear tendency of the generative model to create multi-target com- pounds (26.6% of the newly generated compounds), while decreasing the likelihood of producing single- or no-target compounds. Taken to- gether, these findings indicate that generative models can be adopted for de novo multi-target compound design [119].

Fig. 5. Examples of automated deep learning (DL) systems explored in multi-target drug discovery. (a) The workflow of KinomeX, a web application for the prediction of multi-target kinase inhibitors; (b) Fine-tuning REINVENT generative neural network for the de novo design of multi‚Äëtarget compounds; and (c) Automated de novo design and optimization of multi-target lead compounds with antipsychotic activity through the integration of a deep generative network and a multi-task deep neural network (MTL-DNNs).

compounds. This generative model was pre-trained using RNN with two stacked LSTM layers by a large set of drug-like compounds in the SMILES format. Then, the pre-trained model was fine-tuned using a small library of compounds with experimental data against the D1 , D2 , 5-HT1A , and 5 HT2A receptors. In parallel, an MTL-DNNs using ECFP4 (Fig. 5c) finger- prints as inputs was employed to develop a regression model for predict- ing the activity of generated compounds in the context of the D1, D2, 5- HT1A , and 5 HT2A receptors [123]. During this process, a transfer learn-

ing strategy was then employed to learn the general features (weights) from a larger dataset of compounds with known pKi values, and ap- ply them to a smaller dataset of compounds with defined pIC50 and pEC50 values, through fine-tuning. In each epoch, the generated chemi- cal structures were interactively evaluated by the MTL-DNNs model and further screened based on various criteria, including drug-likeness and synthetic accessibility [123]. High-ranking compounds were then sam- pled to boost the training set for the next iteration. Importantly, this

The drug discovery literature is riddled with MOO approaches to address multi-target optimization problems. Despite many of which are labeled ‚Äúmulti-objective‚Äù, the line between multi- and single-objective molecular optimization is quite blurred [124,125]. The MOO refers to finding the optimal solution values of more than one desired target. The motivation for using the MOO is that optimization requires trivial equations, which simplifies the problem [125]. The equation of the MOO problem is defined as follows:

lack of de novo design studies based on the Pareto front. Apparently, the main example in this field is DrugEx v.2.0, presented by Liu et al. [127]. The work consists of an LSTM cell-based deep generative network and a pool of ML predictors for estimating the activity towards the targets (A1 AR and A2AAR) and one anti-target (hERG) [127]. Both the gener- ative model and the predictors were pre-trained in advance and then interplayed under a reinforcement learning framework. During the in- teraction loop, the generative model creates a batch of SMILES-based molecules, whereas the scores provided by the predictors were used to construct Pareto ranks of the generated molecules [127]. The final re- ward of each SMILES is calculated based on the Pareto ranking with the non-dominated sorting genetic algorithm (NSGA-II) [128]. At the end of this process, the framework was able to generate a large percentage of valid SMILES with a predicted selectivity profile towards multiple targets, offering the potential of high eÔ¨Écacy and low toxicity [127].

A MOO task always begins with some statement of desired proper- ties. First, the chemical and biological properties must be converted to mathematical objectives. If more than one objective exists, they must ei- ther be treated with an appropriate multi-objective formulation [124]. In this section, we explore two of these MOO formulations in detail, namely scalarization and Pareto method. An in-depth discussion of MOO methods in drug discovery is provided by Former and Coley [124].

and their similarity at different levels of biology. Chemical Checker di- vides data into five levels of increasing complexity. The drug is often a compound (chemistry) that interacts with one or several protein re- ceptors (targets), triggering perturbations of biological pathways (net- works) and eliciting phenotypic, cell-based assays (cells), which can then be translated into their clinical outcomes (clinics). The authors showed that these signatures can aid drug discovery tasks, including target identification and library characterization.

Finding new molecules with a desired biological activity is a labori- ous task. At the beginning of the SARS-CoV-2 outbreak [130], in an open collaboration to find ‚Äúold drugs‚Äù against SARS-CoV-2 we employed the PHAARM MatchMaker¬Æ InsilicAll‚Äôs software, which used groundbreak- ing polypharmacology technology to set up the ‚Äúmolecular and biolog- ical signature‚Äù patterns, an approach that could bridge chemistry and biology in the long and diÔ¨Écult road of drug discovery. They showed AI tools capable of presenting the complex relationships between the chemical substance with molecular targets, cells and/or organs. This could create a more complete understanding of the ‚Äúmulti-biological profile‚Äù caused by the drug analyzed in response to a disease.

dominance is there to differentiate the non-dominated and dominated solutions. The goodness of a solution is determined by dominance. A solution is called non-dominated if none of the objective functions can be improved without being detrimental to at least one other objective. The dominated solution is usually achieved when an objective function can be improved without reducing the remaining objective functions [124,125].

Fig. 6. Deep learning systems explored in multi-target drug discovery. (a) Using imatinib, a marketed multikinase inhibitor, as template for the evaluation of the "molecular and biological signature" patterns by PHAARM MatchMaker¬Æ; (b) scaffold hopping for the target (template) compound using the de novo drug design with 3D Shape-Based Generative Modeling to obtain the AI-generated compounds (a-n) (Figure S1) with similar shape and pharmacophore features; (c) determination of the 3D shape and electrostatic similarities (ESP-Sim Carbo) for the design of similar compounds; (d) generation of the ‚Äúmolecular and biological signature‚Äù patterns for new designed compounds with predicted multikinase inhibition. The compounds share a rather large common substructure.

imatinib as a template for PHAARM MatchMaker to evaluate its molec- ular and biological signature. Then, we used the de novo Drug Design with Shape-Based Generative Modeling, in which 3D spatial information is incorporated in two major phases: (i) a shape variational autoencoder employing CNNs encodes the compound representation, and (ii) a mix of CNNs and LSTM networks create SMILES strings. In Fig. 6, one can see a visual representation of the procedure. With the new approach, which uses autoencoders and captioning networks to vary molecules starting from a single volumetric representation, using the imatinib template, compounds were generated by AI (Figure S1a-n) with similar shape and pharmacophore features.

neural networks for atomic/bond properties. This allows the calculation of high-quality RESPs and shape scores for any given structure query giv- ing an accurate prediction on whether it will have desirable sweet spot properties [131‚Äì133]. Finally, we generated the ‚Äúmolecular and biolog- ical signature‚Äù patterns for newly designed compounds with predicted multikinase inhibition (Figure S2). The compounds share a rather large common substructure. Importantly, all compounds activated more than 10 kinases models with strong binding aÔ¨Énity and IC50. We showed compound with high MB signature and 3D Shape and ESP similarities.

The shape and electrostatic properties of molecules are what deter- mine how similar two different substances can be. Learning from past drug discovery experiences, these characteristics should therefore play a major role in determining which comparison method is used. Some- times, it is hard to reach the desired complex effect with one, one drug (even considering magic shotgun drugs). In this case, combining the drugs with different mechanisms of action and/or hitting a variety of selected targets could serve as an alternative approach. The application of such approaches in the discovery of synergistic drug combinations against SARS-CoV-2 has been reviewed elsewhere.

Historically, the discovery of new chemical entities with multi-target profile has been a huge challenge. Methodologically, the activity of these compounds needs to be simultaneously optimized toward several tar- gets with dissimilar binding pockets. However, intuitively finding hid- den structural patterns in chemical accessible space of multi-target com- pounds is quite diÔ¨Écult. To overcome this challenge, ML and DL tools stand out as cutting-edge decision support systems to optimize research pipelines and revolutionize multi-target drug discovery. Such AI systems are able to identify and learn from complex structural patterns and to design new molecular structures with desired multi-target profiles at a very low cost and in a time-eÔ¨Écient manner. However, many of these techniques are currently being evaluated in the context of prospective drug discovery. Thus, only a limited number of studies present experi- mental validation results. In this paper, we have highlighted some stud- ies showing encouraging experimental results inspired by an automated design of multi-target compounds using deep generative networks and MTL-DNNs. Full development of these tools will require project-oriented interdisciplinary teams that closely integrate data science, synthesis, and biological evaluation to guide the next generation of multi-target drugs.

Li YH, Wang PP, Li XX, Yu CY, Yang H, Zhou J, et al. The human kinome targeted by fda approved multi-target drugs and combination products: a comparative study from the drug-target interaction network perspective. Zou Q, editor. PLoS ONE 2016;11:e0165737. doi:10.1371/journal.pone.0165737.

Schultheis B, Folprecht G, Kuhlmann J, Ehrenberg R, Hacker UT, K√∂hne CH, et al. Regorafenib in combination with folfox or folfiri as first- or second-line treat- ment of colorectal cancer: results of a multicenter, phase ib study. Ann. Oncol. 2013;24:1560‚Äì7. doi:10.1093/annonc/mdt056.

Wilhelm SM, Dumas J, Adnane L, Lynch M, Carter CA, Sch√ºtz G, et al. Regorafenib (BAY 73-4506): a new oral multikinase inhibitor of angiogenic, stromal and onco- genic receptor tyrosine kinases with potent preclinical antitumor activity. Int. J. Cancer 2011;129:245‚Äì55. doi:10.1002/ijc.25864.

Li D, Hu J, Zhang L, Li L, Yin Q, Shi J, et al. Deep Learning and Machine Intelli- gence: New Computational Modeling Techniques for Discovery of the Combination Rules and Pharmacodynamic Characteristics of Traditional Chinese Medicine. Eur J Pharmacol 2022;933:175260. doi:10.1016/j.ejphar.2022.175260.

Hashimoto K, Xiong C, Tsuruoka Y, Socher R. A joint many-task model: growing a neural network for multiple nlp tasks. In: Proceedings of the 2017 conference on empirical methods in natural language processing. Stroudsburg, PA, USA: Associa- tion for Computational Linguistics; 2017. p. 1923‚Äì33. doi:10.18653/v1/D17-1206.

