The task likely fail for the mismatching between the computer’s ability and the consume of the task which have been assigned for the computer, along with the sum of the computers in the cluster becoming larger and larger, even though the Internet can share the resources, yet the computers differ greatly. And then it is a tough problem how to apart and management them. The paper gives a way to solve it, whose main purpose is to separate the computers into different groups in which the computers are the most similar by the calculating following the Fuzzy theory. The value of the weighted value is modifiable, which following the characters of the computer can affect the Fuzzy set as you want.

In reality, most of time, machine is idle, resulting in a significant waste of computing power. When using the Task Manager under Windows or other tools under Linux platforms (such as top, xload ) to observe the CPU, we will find the common utilization of the CPU is just among 1 to 2 percent. In fact, if there are more computers, the waste will be intensified. In a department that includes 300 computers, the idle rate of CPU is amazing. However, these sectors still need powerful servers to be used to compile or simulation. Sometimes this situation will be exacerbated, because with the increase of users, more than one even if the 8 CPU servers, nor can the full load duty of landing to another free server because users rarely change their habits to log in another server. If you can take advantage of the existing computing resources and idle CPU utilization, or allow the migration of load on the server smartly, it will be a very happy thing [1] [2].

In recent years, grid [4] technology with the compatibility of heterogeneous resources become the research focus of the industry, providing a new theoretical and technical support for us to build heterogeneous clusters. The computer's CPU, memory, disk, network parameters vary on INTRANET, so the system formed by connecting them together simply is not a cluster. They must be Clustered and divided into logical computer clusters of different calculation types, and then allocate computing tasks. In order to effectively divide clusters, we proposed the study and implementation of fuzzy -based cluster model (Fuzzy-based Cluster Model) which have practical significance in integration of existing idle computing resources to be a computing device.

②MEMORY, ③Net Adapter: NIC, ĺI / O: the hard disk read and write speeds, ➄NET: network bandwidth. Of course, there are other very important parameters, the model is not sensitive about the number of parameters by the same treatment. Similarly, the dimension of parameters in this model is not sensitive as long as the dimension of the same parameters can be unified. The impact of the dimensionless can be eliminated through the standardization of data in clustering analysis.

The parallel and serial attribute of computing tasks essentially determines the application efficiency of the cluster. The operating efficiency of each node is the computing essence of the node. Therefore, when fuzzy clustering, the parameters of one or several key attributes corresponding to a task is very important given relatively large weights, so that the impact of the attribute parameters with large weights for similarity is relatively large, the division of cluster can be based on the characteristics of the task, and adapt to the task.

Suppose Cluster computers are classified based on the domain U = {X1, X2, ... Xn}.The performance of each computer by m attributes parameter(in this paper m = 5), Xi = (x1, x2, ... xm) (i = 1,2, ... n) (in this paper①x1: CPU ② x2:MEMORY, ③ x3: Net Adapter,ĺx4:I / O,➄x5:NET),so, we get the raw data matrix is:

Five attribute parameters of computers in clusters have different dimensions.in order to compare different dimensions, you need to do appropriate transformation. Different dimensions according to the requirements of fuzzy matrix to make the data compression to interval [0,1]. This paper discusses only two kinds of transformation (translation standard deviation of the transform, pan range transformation), and more transformations, you can refer to[3].

With the fuzzy similarity matrix (3.3.2) is not enough, it is because there is no transitivity, such as the similarity between computer is greater than or equal to α counted as a class, then when rij≥α and rjk≥α may not be there rik≥α, that is, when Xi, Xj similar and Xj, Xk similar, Xi and Xk are not necessarily similar. so, calculating the equivalent of closure R(denoted as R*) on the basis of (2.3.2)will be useful. Solving the Transitive Closure based on the fuzzy similarity matrix clustering is just one clustering method, and other more clustering methods can be found in [3].

The fuzzy relation matrix R based on five (or more) property parameters between computers is often a fuzzy similarity matrix, and not necessarily a fuzzy equivalent matrix. Therefore, computers are classified by the equivalent matrix, and we usually take transitive closure method to construct the transitive closure R* = t(R), and then clustering on the basis of the R* (this method). After a series of non-identity transform in the process of construct R *, the inevitable increase of some factors that do not belong to R results in the clustering distortion. The more times of the non-identity transform, the greater the distortion of likelihood .In this approach, in order to pursue the transformation, we use R* instead of R to do clustering. Although the principle is not perfect, the method is simple, and tests confirmed the classification results are better, so this method can be used in practice.

We use F statistic to determine the value of α which can adapt to a general computing tasks, and also a good method to determine α. The larger the F value, the greater the difference between classes. the greater the distance between classes, the better the classification. for more discussion, refer to[3].

(Where k1 = k2 = k3 = k4= k5 = 0.2, if the similarity is too small, it does not make sense, so the coordinate origin moved to 0.9, the specific move to where depending on the application, here according to the values of the last 30 sample computers).

It can be drawn from the definition formula that Q represents the degree of the final clustering results. when α increases, the clustering degree of (Q) value decreases; when α decreases, the value of the clustering degree of (Q) increases. Threshold (α) is equivalent to the harsh requirements for clustering, When the threshold is increased, it indicates that the harsh degree of clustering. The higher the similarity requirements, the lower the degree of clustering.

(Computer using the serial number, self-group: the computer serial number to be a group alone)According to the classification results, we can easily find, with the weight of CPU gradually reduce, degree of CPU concern is getting smaller and smaller. for example, in the first category, when the CPU's weight 0.8, only 1,4, when it reduced to 0.4, 2,3,7,8,9 is added in. It can be seen even if there are some differences on the CPU, but considering the other factors, it is quite similar. When it reduce to 0, without considering the CPU, the addition to the number of the computer which other aspects are similar will be more, and CPU is somewhat similar, but the other four areas are not very similar is excluded. So that by adjusting the weights will be able to better control the properties of interest.

(Computer using the serial number, self-group: the computer serial number to be a group alone)It can be seen that the cluster will be increased when clustering threshold increases, and the number of self-group is also increased, So that the characteristics of each computer in the cluster will be even more distinctive, and the internal similarity of each cluster will be more closer, the granularity of the cluster smaller that forms very similar cluster. Small clusters formed with a larger threshold can not be separated when clustering with a smaller threshold. experiments verify the theoretical results.

