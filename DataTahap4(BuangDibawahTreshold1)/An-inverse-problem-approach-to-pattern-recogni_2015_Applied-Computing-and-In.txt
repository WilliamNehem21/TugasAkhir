Abstract Many works have shown strong connections between learning and regularization techniques for ill-posed inverse problems. A careful analysis shows that a rigorous connection between learning and regularization for inverse prob- lem is not straightforward. In this study, pattern recognition will be viewed as an ill-posed inverse problem and applications of methods from the theory of inverse problems to pattern recognition are studied. A new learning algorithm derived from a well-known regularization model is generated and applied to the task of reconstruction of an inhomogeneous object as pattern recognition. Particu- larly, it is demonstrated that pattern recognition can be reformulated in terms of inverse problems defined by a Riesz-type kernel. This reformulation can be employed to design a learning algorithm based on a numerical solution of a sys- tem of linear equations. Finally, numerical experiments have been carried out with synthetic experimental data considering a reasonable level of noise. Good recoveries have been achieved with this methodology, and the results of these simulations are compatible with the existing methods. The comparison results show that the Regularization-based learning algorithm (RBA) obtains a promis- ing performance on the majority of the test problems. In prospects, this method can be used for the creation of automated systems for diagnostics, testing, and

With the advent of high-speed computers and artificial intelligence techniques, this modeling problem underwent a metamorphosis and emerged as a machine learning problem (Bauer et al., 2007; Gdawiec and Domanska, 2011). Tikhonov and Lanweber regularized that learning algorithms have recently received an increasing interest due to both theoretical and computational motivations (Abru- kov et al., 2006; Kurkova, 2012; Tiknonov and Arsenin, 1977). Fractal, optimiza- tion, and a two-dimensional functional relational model have been used as a feature in several pattern recognition methods (Chang et al., 2010; Lo Gerfo et al., 2008; Noureddine, in press). Considerable attention is currently being de- voted to new possibilities of using artificial neural networks (ANN) in view of their increasing importance for solving the problem of automated reconstruction of the inner structure of an object. Accompanying algorithms that effectively quantify uncertainties, deal with ill-posedness, and fully take the nonlinear model into account are needed Therefore, it is necessary to both look for possible ways to improve the classical learning algorithms already existent in the literature, and to identify new methods which can compete with the traditional ones in speed, robustness, and quality of results.

In this paper, starting from a reformulation of the pattern recognition as an in- verse problem, we introduce an alternative learning algorithm derived by a well- known regularization method. We use a Riesz-type kernel to solve classification tasks by transforming the geometry of input space by embedding them into higher dimensional, inner product spaces, and introducing a regularization method which adds to the derived integral equation a new term, called stabilizer, which penalizes undesired input/output functions. We split the problem into a simpler, ill-posed problem (an integral equation with a Riesz-type kernel) and a well-posed problem. In this way, we isolate and better control the propagation of errors due to the ill-posedness (Noureddine, in press). Then we show that this reformulation can be employed to design a learning algorithm based upon a numerical solution of a system of linear equations.

The rest of the paper is organized as follows: The next Section describes our model and justifies its use. In Section 3, we formulate the proposed regularized learning algorithm. Section IV presents main simulation results. We compare our Regularization-based Algorithm (RBA) with the Support Vector Machine (SVM) and Semanteme-based Support Vector Machine (SSVM) in Section 5. Finally, we conclude the paper with a summary of the work in Section VI.

Now it is clear that if we take any B(x) e L2(Xk) which is continuous, then there is no r1 e L2(X) such that Ar1 = B. So the existence requirement of the well- posedness is violated. Therefore the Eq. (2.1) is ill-posed.

show the solution r1(a) and its convergence to the solution B when a→0, provided r1 exists and the uniqueness for the original Eq. (2.1). Now we need to prove the existence of the solution r1(a) and its convergence to the solution f when a→0, provided r1 exists and is unique.

Let us denote ‘real object’ by rt, and ‘computed object’ by rc. To test the meth- od numerically, it is necessary to generate ‘B(x)’ in the integral Eq. (2.1). We do this by specifying r and evaluating the integral numerically. Once we have the numerical values of B(x), we use these as our data and recover the pattern inside the required region. The steps of test calculation are:

where xi’s are characteristic functions of unknown objects, and r0 = ½ and rI =1 (Fig. 3). In the case of smooth surface (i), the numerical calculations have shown that when rt is a smooth polynomial, the reconstruction is a very good approximation of rc (Fig. 2).

tion: simply, a = 10—7 and a = 10—10. We provided the cross sections of rt and rc. In case (ii), we used two different regularization parameters for our reconstruc- The proposed model was able to distinguish the objects. We observed that the

Equation (2.7) involves main parameters that must be adjusted for greatest effi- ciency: the regularization parameter and the number of grid points. Looking at the reconstructions, the numerical experiments described above have shown that the reconstructed surface is smooth and close to the true surface. The reconstruction was usually a fair representation of the shape of the r.

In this section, misclassification rate (Li and Wang, 2009) is used to evaluate the efficiency of our algorithm. Misclassification rate refers to the ratio of the number of misclassified exemplars to the total number of exemplars in the dataset. The ratio is computed using the Formulation (5.3). Correspondingly, the classification accuracy is determined by the Formulation (5.2).

Experiments are performed on the purely syntactic datasets from the UCI ma- chine learning repository (UCI, 1998). We compare our Regularization-based Algorithm (RBA) with the Support Vector Machine (SVM) and Semanteme-based Support Vector Machine (SSVM) in the Table 2. In each test, all patterns with missing attribute values are initially removed. Continuous Dataset (CDS), Discon- tinuous Dataset I (DDS-I), and Discontinuous Dataset II (DDS-II) have their fixed real and computed pattern sets. The 9% outliers existing in DDS-II’s training patterns are identified, and the dataset is classified as unbalanced. The continuous

A number of classification algorithms depend on the similarity or dissimilarity of exemplars, such as Euclidean distance and inner production, among others. How- ever, majority of these algorithms only process continuous-attributed data, not discontinuous data. Discontinuous data (surface in our examples) are extreme, having disordered and unbalanced distribution.

For parameter selection and optimization, regularized learning algorithm faces the problem of selecting parameter a. In many algorithms, the standardization of the selection method for a is rarely performed (Han and Zhao, 2009). The heuristic method or some optimization algorithm is used to select a. In this study, the heuristic method is used in each experiment to standardize datasets. Table 1 shows the relationship between classification accuracy and the value a in the RBA algorithm.

The implementation of the proposed algorithm shows that the method is reasonably accurate for the reconstruction of two objects, using artificially gener- ated data whose distributions are known. We have seen, both theoretically and experimentally, that pattern classification can be viewed as an ill-posed, inverse problem to which a method of regularization may be applied. As shown in Table 2, our proposed regularized learning algorithm has already shown promising perfor- mance in comparison with the state-of-the-art approaches, such as Support Vector Machines (SVMs), on benchmark datasets and real-life test problems.

introduce a new learning algorithm. On one front, improvements have to be done both on the algorithm (different regularizer properties must be investigated) and the applications (non-homogeneous 3-D object recognition). More detailed work is needed to improve the effectiveness of the numerics in general. In addition, the answer to exactly how sensitive the method is to moderate amounts of noise is an open question.

