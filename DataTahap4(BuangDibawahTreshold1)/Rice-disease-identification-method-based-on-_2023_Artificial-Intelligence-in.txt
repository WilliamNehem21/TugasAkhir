machines and hyperspectral technology to identify early sugar beet dis- eases, with an accuracy rate of 97% for distinguishing healthy sugar beet from diseased leaves. Wang et al. (2019) extracted color, shape, and tex- ture features of fungal diseases such as powdery mildew, rust, and leaf spots on wheat leaves and used support vector machines to classify and identify them. (Majumdar et al., 2015) used fuzzy c-means cluster- ing algorithm to extract 25 disease features of wheat leaves and classi- fied them using an artificial neural network to determine whether wheat was infected. Traditional machine learning relies on manually generated specific features, which results in low recognition efficiency. Remote sensing methods have achieved certain research results in crop stress monitoring, but lack spectral specificity of diseases, which may encounter uncertainty issues in monitoring. With the continuous development of big data and deep learning research, plant phenotype research based on deep learning methods provides a new means for crop disease recognition and has achieved significant results in crop monitoring and management.

identification models. Statistical analysis showed that the ResNet50 and SVM classification models had higher recognition accuracy than the other models. (Waheed et al., 2020) proposed an optimized dense convolutional neural network called DenseNet, which achieved an accu- racy of 98.06% and had fewer parameters and computation time than similar CNNs. (Da Costa et al., 2020) studied external defects in toma- toes and compared them with transfer learning training, showing that the ResNet18 model was the best. In peanut variety identification,

which further decreased to 13, 20, 16, and 14 after integrating the CBAM module. Notably, the CBAM module significantly improved rec- ognition of sesame spot disease. By combining the BiGRU module to ex- tract advanced features, misclassification rates were further reduced to 7, 8, 5, and 9 respectively. The results demonstrate the effectiveness of using RNNs to process features of rice diseases, thereby enhancing the performance of the CNNs.

This paper proposed an improved CNN for extracting features of rice diseases by combining Inception and ResNet theories. The network ad- dresses the high misidentification rate by incorporating information about the rice disease images and their surrounding context. The improved CNN also includes CBAM module for more precise feature extraction. Additionally, BiGRU was introduced to recognize the

relationships between stress image features, deepening the model's understanding of the images and the structural characteristics of rice diseases. The effectiveness of the proposed model is demonstrated through experiments, which show higher accuracy and lower cost compared to other models. However, the current dataset still has limita- tions, with only four types of rice disease samples. To address this, future work will focus on collecting more comprehensive real-field samples and improving the model structure to increase its generaliza- tion ability in complex scenarios.

