Now a day’s the rate of information growth is expanding expo- nentially in the World Wide Web, which creates information over- load problem. One solution to this problem is shortening of information, called text summarization (TS). Text summarization is the process of creating shorter version of original text without losing main contents [1] called summary. The summary provides a quick guide to create interest on information, helps in making decision on document whether it is readable or not as well as it is served as a time saver for users [2]. The way in which summary is generated either is an extraction or an abstraction method [3,4].

Extraction based summaries are generated by selecting the impor- tant portions of the original text. Whereas, abstraction based sum- maries requires linguistic analysis to construct new sentences from the original text [5,6]. Based on dimension, extraction based sum- maries can be categorized into two ways i.e., generic or query dependent [7]. Generic summary reflects the major content of the documents without any additional information. But, Query- dependent summary focuses on the information expressed in the given queries [8,9].

Number of documents considered for generating summary, can classify the summarization problem as single document or multi- document summarization [10,11]. When a document is condensed into a shorter version, it is called single document summarization, whereas condensing a set of documents into a summary is called multi-document summarization. Therefore, summarization of multiple documents can be considered as an extension of summa- rization of single document [12]. In multi-document summariza- tion, search space is larger compared to single document summarization, which makes it more challenging for extracting important sentences. In that context, multi-document summariza- tion can be considered as an optimization problem with the objec- tive  of  producing  optimal  summary  containing  informative

sentences of the original documents. Nature inspired optimization based approaches are the suitable choices to address this optimiza- tion problem. In literature several meta heuristic techniques such as particle swarm optimization (PSO), differential evolution (DE), harmony search (HS), Cuckoo search (CS) and genetic algorithm (GA) are applied in single or multi-document summarization.

Being inspired by the application of Cuckoo search in other opti- mization problems [13–34], in this study a novel Cuckoo search algorithm based summarizer is presented for multi-document summarization. Though single document using Cuckoo search algorithm is present in literature [35] but, multi-document sum- marizer using Cuckoo search is new to this area. Further the model is also compared with Particle Swarm Optimization based summa- rizer and Cat Swarm Optimization based summarizer. The perfor- mance of such models are analyzed over DUC datasets with respect to few summary evaluation metrics such as ROUGE score, inter sentence similarity and readability metric. These evaluation metrics are considered to validate the non-redundancy, cohesive- ness and readability of the generated summary.

The structure of paper is organized as follows. Section 2 briefly describes the related works on text summarization problem using global optimization techniques. Section 3 introduces the proposed extractive summarization model. Section 4 presents Cuckoo search based summarizer for solving summarization problem. Next, Sec- tion 5 details the numeric calculation for objective function, Sec- tion 6 elaborates on experiments and result analysis and finally Section 7 addresses the conclusions.

algorithm. The CS algorithm shows a significant improvement result than other algorithms. A new biodiesel engine have devel- oped by Wong et al. [16] to achieve fewer emissions, low fuel cost and wide operating range of engine using Cuckoo search algorithm. The CS algorithm is compared with PSO algorithm and the result shows that CS is similar to PSO bur with less user defend parameters.

For minimization of power loss and maximization of voltage magnitude, reconfiguration network methodologies using CS algo- rithm have proposed by Nguyen and Truong [17]. The radial topol- ogy of network is maintained by CS algorithm, which is compared with PSO and other compared methods in literature and the result of CS is more noticeable. A combinatorial optimization approach using Cuckoo search algorithm [18] have introduced to minimize possible number of test cases by considering the combination of inputs for detecting defects. Here Cuckoo search algorithm is used to create optimized combinatorial test set. Along with these engi- neering applications, many other recent applications of Cuckoo Search algorithm are listed in Table 1.

Though various optimization algorithms were proposed in past, but application of Cuckoo search algorithm for developing summa- rizer is very few in the area of text summarization. Mirshojaei and Masoomi [35] has already addressed summarization problem using Cuckoo search algorithm. But it is applied only for single doc- ument summarization. Here, summarization result of Cuckoo search algorithm is compared with the summarization result of particle swarm optimization algorithm, bacterial foraging opti- mization algorithm and word summarizer in terms of F-score. Among all cases, the F-score of Cuckoo search algorithm is showing comparatively better than the other results.

Multi-document summarization is an automatic process to cre- ate a concise and comprehensive document, called summary from multiple documents. The entire procedure of multi-document summarization is divided into three steps such as preprocessing, input representation and summary representation. The overview of summarization system is shown in Fig. 1. Input to the summa-

rization system is multiple documents such as D1, D2, .. ., DN. The documents are initially preprocessed, and the result is gone through input representation and summary representation to extract final summary. The detail of summarization process is dis- cussed in the following subsections.

In this section the preprocessed data presented in word form is used to calculate weight (sum of term frequencies) for each sen- tence known as sentence informative score. The sentence informa- tive score, represented as weight of sentence is further entered as input to the optimization algorithm for implementation. The details of input representation is discussed in Fig. 3.

The objective of summary representation is generating sum- mary of document sets containing useful information. Through the optimal sentence selection process, the important sentences representing summary is selected by comparing the sentence informative score obtained through optimization algorithm with respect to a pre specified threshold value (see Fig. 4).

Cuckoo search (CS) is one of latest meta heuristic algorithm, inspired by the species of bird called the Cuckoo. Cuckoos are fas- cinating birds because of their aggressive reproduction strategy and beautiful sounds, they can make [54–56]. The mature Cuckoos lay their eggs in the nests of other host birds or species [57]. The nest containing each egg represents a solution, and each Cuckoo can lay only one egg that represents new and potentially better solution. The standard Cuckoo search algorithm can be described by three idealized rules: 1) One egg is laid by each Cuckoo in a ran- dom nest represents a solution sets; 2) The best eggs contained in the nests will carry over to the next generation; 3) The number of available nests is fixed, and a host bird can discovered an alien egg

For implementation point of view, CS algorithm can use the simplest form where each nest has only a single egg. In this case there is no distinction between egg, nest or Cuckoo, as each nest corresponds to one egg which also represents one Cuckoo. The algorithm can be extended to more complicated cases in which each nest has multiple eggs representing a set of solutions.

Step 1: Collect a set of multiple documents M, where M = {D1, D2,.. ., DN}. Each Di represents individual document of set M. Length of each Di is represented in terms of number of sentences, which vary from document to document.

respect to term tk. tfjk is the term frequency (i.e. number of times the term tk occurred in sentence Sj, nk denotes the number of sen- tences in which tk appears. The term log (n/nk) is referred as inverse sentence frequency used in vector space model for sentence retrieval.

Step14: Compute the fitness function for the new nests obtained. Step15. Based on the fitness values, record the best performing nests in the current population set. Which are then compared with the best nest obtained until current generation, and replace current best by previous best nest.

coverage, cohesion and readability of the summary. The first term evaluates content coverage of the summary. A summary contains a set of relevant sentences, which covers the main content of docu- ment set. The main content of document is reflected by the highest weighted sentence or center of the each document. Therefore the content coverage of summary is represented as:

O = {O1, O2,.. ., On} of document sets and Oi is weighted average of sentences of each document. Similarity between Si and O (specified in Eq. (4)) is evaluated to measure importance of the sentences. Higher similarity values correspond to high content coverage.

This section conduct experiments to test proposed summarization system empirically. The MDSCSA is compared with CSOS and PSOS multi-document summarizer with respect to two years of DUC data- sets. All the summarizer models are implemented in MATLAB Version 2014a) in a system with Window 7 operating system. After obtaining the simulation result, the analysis of summary result has been carried out using ROUGE tool in terms of ROUGE score.

The open bench mark datasets from DUC (Document Under- standing Conference) are used for the evaluation of text extraction result. Table 2 provides a short description of DUC data sets. By the step of data preprocessing, less significant words or stop words from the original documents are removed by comparing with the available stop word list in net and the terms are stemmed using the most common stemmer in English called Porter’s stemmer.

The summary performance has been evaluated by using ROUGE-N with two N values such as ROUGE-1 and ROUGE-2 met- rics. These matrices are highly correlated with the human judg- ments. ROUGE-1 measures the overlap of unigrams between the system summary and the manual summaries created by human while ROUGE-2 compares the overlap of bigrams [43]. The ROUGE-N evaluation is done based on content coverage, cohesive- ness and text readability of summary. A model providing higher ROUGE metric indicates higher similarity of the generated sum- mary with respect to the original document sets. Though the ROUGE-N value is represented in terms of three different metrics such as precision, recall and F-measure value, F-measure is assumed to have more significance for selection of a summary. In this study the model selection is done based on the best F-measure of the ROUGE-N values. Table 4 shows the statistical analysis in term of worst, mean and best of F-measure of ROUGE-1 and ROUGE-2 evaluation metrics observed for the PSOS, CSOS and MDSCSA algorithm on DUC 2006 and DUC 2007 docu- ment set respectively. The evaluation metrics are observed for

Furthermore, sensitivity, positive predictive value (PPV) and summary accuracy (Summaryacc) are used for summary evaluation. The sensitivity, PPV and Summaryacc of summary are evaluated based on the outcomes of candidate summary (Candidatesum), ref- erence summary (Referencesum), true sentences (Truesen) and least significant sentences (LSsen). The summary which is generated by our proposed summarizer is called candidate summary. Whereas, the summary is refer for an evaluation, called reference summary. In both the summary, the common sentences are referred as true sentences. But the sentences, neither in Candidatesum nor in Referencesum is called LSsen. Sensitivity, PPV and Summaryacc are calculated using the following equations.

This experiment involves readability of summary, which means ‘‘how easily materials can be read and understood? This depends on several factors including the average length of sentences, the number of new words contained, and the grammatical complexity of the language used in a passage” [61]. Readability can be calcu- lated by the formula discussed in Table 7. Readability is estimated in terms of the number of years of education one needs to have to comprehend that text [62]. The higher value of readability metric supports easy reading and understanding of generated summary whereas lower value creates difficulty in reading and understand- ing of the summary. The readability score of three different sum- marizers for DUC 2006 dataset and DUC 2007 dataset is shown in Figs. 6 and 7 respectively. From the analysis, it is clearly observed that, for DUC 2006 dataset MDSCSA is providing better readability score with respect to FKGL, FOG, SMOG and ARI metrics compared to PSOS and CSOS and for CL metric all the three summa- rizers are producing almost same result. For DUC 2007 dataset

This paper focuses on a Cuckoo search based multi-document summarizer to create a generic extractive summary. The summa- rizer is also compared with particle swarm optimization based summarizer and cat swarm optimization based summarizer. The performance of all discussed summarizers are evaluated in terms of ROUGE score, inter sentence similarity and readability metric to validate non-redundancy, cohesiveness and readability of the summary respectively on a benchmark dataset called as Document Understanding Conference datasets in three experiments. Observa- tion 1 and 2 discusses non-redundancy and cohesiveness of sum- mary, where in most of the cases Cuckoo search based model is showing better ROUGE score. Similarly in readability test discussed in observation 3, MDSCSA is also showing better readable score of the summary in Figs. 6 and 7 compared to PSOS & CSOS based model. From the above observations, it can be concluded that the performance of MDSCSA is significantly better than the CSOS and PSOS algorithm in summary generation.

Controlling of evolutionary algorithm parameters are purely data dependent in the experiment of any application. As Cuckoo search algorithm is an evolutionary approach, thus the limitation of this approach is its controlling parameters. Therefore more sys- tematic approach of parameter setting will be explored in our future work. The performance of this approach can also be exam- ined using other competent nature inspired algorithms.

C.Y. Lin, E. Hovy, Automatic evaluation of summaries using n-gram co- occurrence statistics, in: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, Association for Computational Linguistics, 2003, May, pp. 71–78.

