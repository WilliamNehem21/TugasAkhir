An object tracking algorithm based on SURF is presented in this paper. Interest points are detected by SURF detector in reference region which is located in the first frame manually. In the following sequences, the SURF feature points are extracted in a larger window which is selected as test region. In the matching stage, we calculate the Euclidean distance between the descriptor vectors of interest points in the test image and ones in the reference image. The proposed algorithm is implemented on an embedded platform with TI's DM6446 high performance processor. The experimental results show that our system implements a real-time tracking with robustness against appearance variations, scale change, and cluttered scenes.

Ta, D.-N. et al. propose an SURF based method to track the object in video[8], and SURF descriptor is used to optimize similarity search of interest points. The experimental result shows that the algorithm of SURF features extracting has smaller calculation and faster than SIFT.

The remainder of this paper is organized as follows. In Section 2, SURF features matching algorithm is introduced. We describe our hardware design for tracking system In Section 3. In Section 4, experiments are presented and we conclude the paper in Section 5.

The steps of SURF algorithm contain three sections: interest points detecting, interest points describing and interest points matching. Interest points detecting uses a detector based on Hessian matrix, its stability and repeatability outperforms the existing state-of-the-art, e.g. a detector based on Harris. Interest points describing uses Haar wavelet[9] to reduce the computational cost and enhance the robustness. The Block filtering to generate the second order Gaussian filtering approximately and the integral image to accelerate convolution, reduce the computational complexity and increases speed.

Integral image is a feature representation method for original image. As it's shown in Fig.1, the dark region represents the integral value of the point(x, y), which is the sum of pixels in the dark region. Calculating the integration of original image I(x, y), the integral image IΣ(x, y) will be obtained, where I(x, y) is the pixel value of the point(x, y) [10].

According to SURF algorithm, interest points are detected at different scales, expecially for the reason that similarity searching often depends on their comparison in images where they are detected at different scales[6].Generally, scale spaces are usually implemented as an image pyramid. In SRUF, block filters are used to approximate the Gaussian kernel, and the computational cost is independent of its size, which is critical for speed.

Weighting box filters' approximation [11]for the second order Gaussian partial derivative in x- direction, y- direction and xy- direction, as shown in Fig.2, are denoted by Dxx, Dyy, Dxy In Fig.3, white regions are positive, grey regions are zero and black regions are negative, respectively. To establish properly scale spaces for photometric change, box filters at different scales are required.

The SURF descriptor is extracted by two steps: find a dominant orientation according to the circular region around the interest point and construct a square region along the dominant orientation for getting the descriptive information. The square regions are split up into 4*4 sub-regions. For each sub-region, we weight Haar wavelet responses with a Gaussian (σ=3.3s) in vertical and horizontal direction (denoted by dy and dx) at the interest point. Aiming at being invariant to rotation, |dy| and |dx| are summed up and denoted by Σ|dy|, Σ|dx|

In the proposed tracking hardware system is described as Fig.3. From the Fig.3, we can know that analogy video is preprocessed firstly by amplifier, filter and clamp operation. Then the video is converted to digital signal by A/D at 8-bit resolution. In our system, the chipset DM6446 is chosen as the digital signal processor (DSP), which includes two core chipset: DSP and ARM. DSP runs object tracking module and gets the object displacement information. Meanwhile, ARM runs the control and GUI (Graph User Interface) module which can receive command from other system and show all video. CPLD run the system logic control module and FPGA run image pre-processing module which has higher processing speed than DSP.

We first implement a pedestrian track and the experimental results as Fig.4 shown, where (a), (b), (c), (d) are the track results at frame 15, 30, 50, 78, respectively. As the experiment shows, our system can keep high detection accuracy when object appearance variation and scale change occur.

Fig.5 shows the results of plane tracking, and (a), (b), (c), (d) are the track results at frame 215, 286, 323, 389, respectively. The background of scene is complicated compared to one in Fig.5. In the following sequences, the object has rotation, illumination changes and view variation, and our system implements a steady tracking due to robustness of the SURF descriptor. However, as the (d) shown, the mismatch occurs when the corresponding interest points disappear in the test image due to occlusion. Aim at influence of occlusion in term of robustness, we will improve the algorithm in the next work.

In this paper, we proposed a SURE based object tracking algorithm, in which interest points in the defined object are matched between consecutive frames by calculating the Euclidean distance between their descriptor vectors. We calculate the barycenter of the interest points as the candidate match displacement, which increase the detector's repeatability. We implement the proposed algorithm on an embedded platform with TI's DM6446 high performance processor. The experimental results show our system implements a real-time tracking with robustness against appearance variations, scale change, and cluttered scenes

