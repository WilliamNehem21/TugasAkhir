DBN, is presented as the state of the art of ANN in their traditional forms with network topologies built from layers of neuron models but with more advanced learning mechanics and deeper architec- ture, without modeling the detailed biological phenomena consti- tuting human intelligence. Maintaining a high-level abstraction of the biological modeling, results in simpler mathematical models for DBN compared to CA. On the other hand, CA represents the shift towards incorporating more biologically inspired structures than DBN, like cortical columns and inhibiting and strengthening learn- ing rules, as outlined by Edelman and Mountcastle’s work [7].

The structure of the paper is such that Section 2 summarizes the history of ANN while Sections 3 and 4 review the fundamental con- cepts and learning schemes of DBN and CA, respectively. Section 5 derives both algorithms’ theoretical computational complexity. Finally, Section 6 presents an empirical comparison on classifica- tion tasks before concluding with closing remarks in Section 7.

i.e. they start the same general-purpose function but become spe- cialized with training [12]. While dendrites are the site of reception of synaptic inputs, axons convey electrical signals over long dis- tances. Inputs to neurons cause a slow potential change in the state of the neuron; its characteristics are determined by the membrane capacitance and resistance allowing temporal summation [13].

Studies showed that the organization of the cortex can be regarded as an association of columnar units [14,15], each column being a group of nodes sharing the same properties. Learning in the human brain is mainly performed using plastic connections, repeated exposures and firing and inhibition of neurons. In a sim- plified manner, information flowing in the cortex causes connec- tions in the brain to become active, over time, with repeated exposures these connections are strengthened creating a represen- tation of the information processed in the brain. Moreover, inhibi- tion of neurons - physically defined as prohibiting neurons from firing - partly account for the forgetting process [16].

At a nodal level, ANN started with the simplified McCulloch- Pitts neural model (1943) [17], which was composed of a basic summation unit with a deterministic binary activation function. Successors added complexity with every iteration. At the level of activation functions, linear, sigmoid, and Gaussian functions came into use. Outputs were no longer restricted to real values and extended to the complex domain. Deterministic models gave way to stochastic neurons and spiking neurons which simulated ionic exchanges. All these additions were made to achieve more sophis- ticated learning models.

Successive iterations incrementally improved on their prede- cessors’ shortcomings and promised higher levels of intelligence, a claim that was made partially feasible due to the hardware’s improved computational capabilities [25] and due to the develop- ment of faster and more efficient training and learning algorithms. Learning mechanics, whether supervised (back propagation) or unsupervised (feed forward algorithms), matured in parallel and allowed for better performance in a varied set of specific tasks. Nonetheless, the compound effect of the innovation targeting all aspects of these shallow networks was not enough to capture true human intelligence while large computational needs throttled the progress of deeper networks.

The early 2000s saw a resurgence in ANN research due to increased processing power and the introduction of more effi- cient training algorithms which made training deep architec- tures feasible. Hinton et al.’s greedy training algorithm [2] simplified the training procedure of Boltzmann machines while deep stacking networks broke down training to the constitut- ing blocks of the deep network to reduce the computational burden. Furthermore, Schmidhuber’s long short-term memory architecture [28] allowed the training of deeper recurrent neu- ral networks. While these architectures do not borrow biologi- cal properties from the brain beyond the neuron, deep architectures with neural network topologies that adhere more faithfully to neuro-scientific theories of the human brain’s topology are gaining traction in the connectionist community due in part to the momentum achieved in computational neuroscience.

One of the major and most relevant contributions in that field was made by Edelman and Mountcastle [7]. Their findings lead to a shift from positioning simplified neuron models as fundamen- tal functional units of an architecture to elevating that role to cor- tical columns, collections of cells characterized by common feed- forward connections and strong inhibitory inter connections. This provided a biologically feasible mechanism for learning and form- ing invariant representations of sensory patterns that earlier ANN did not.

Additionally, two supplementary discoveries were believed to be key in emulating human intelligence. The first was the sus- pected existence of a common computational algorithm in the neocortex [12]. This algorithm is pervasive throughout these regions irrespective of the underlying mental faculty. Whether the task is visual, auditory, olfactory, or other, the brain seems to deal with sensory information in very similar ways. The sec- ond was the hierarchical structure of the human neocortex [12]. The brain’s regions are hierarchically connected so that the bidirectional flow of information merges into more complex representations with every layer, further abstracting the sensory stimuli.

DNN are deeper extensions of shallow ANN architectures that are composed of a simplified mathematical model of the biological neuron but do not aim to faithfully model the human brain as do CA or some other ML approaches. DNN are based on the Neocogni- tron, a biologically inspired image processing model [32], that attempt to realize strong AI models through hierarchical abstrac- tion of knowledge. Information representation is learned as data propagates through the network, shallower layers learn low-level statistical features while deeper layers build on these features to learn more abstract and complex representations. Lacking clear skills for logical inferences, DNN need more morphing to be able to integrate abstract knowledge in a human manner. Recurrent and convolutional neural networks, first introduced in the 1980s, can be considered predecessors of DNN and were trained using back-propagation which has been available since 1974.

RBM, first known as Harmonium by [50], are two-layer net- works where only inter-layer neuron connections are allowed. They are a special case of Boltzmann machines (BM) which allow both inter and intra-layer connections. RBM’s neurons form two disjoint sets (as indicated in Fig. 1 by the black boxes), satisfying the definition of bipartite graphs. Thus, training RBM is less com- plex and faster. The neuron connections in RBM may be directed or undirected; in the latter case, the network forms an auto- associative memory which is characterized by bi-directional infor- mation flow due to feedback connections [2].

DBN are stacked directed RBMs, except for the first RBM which contains undirected connections, as shown in Fig. 1. This network architecture significantly reduces the training complexity and makes deep learning feasible. Focusing on two layers of the net- work, the weighted edges connecting the various neurons are

While DBN is a type of deep ANN, back-propagation fails to pro- duce a suitable model that performs well on training and testing data due to DBN’s architectural characteristics [2]. This has been attributed to the ‘‘explaining away” phenomenon. Explaining away, also known as Berkson’s paradox or selection bias, renders the commonly held assumption of layer independence invalid and consequently adds complexity to the inference process. The hidden nodes become anti-correlated because their extremely

CD estimates the log-likelihood gradient using a j Gibbs sampling steps which is typically set to 1. The optimal weight vector is obtained by maximizing the objective function in (1) through gra- dient descent [52]. CD’s pseudo-code is summarized in Table 2.

After iteratively learning the weights of the network, the up- down algorithm [2] fine-tunes the network weights. This algorithm is a supervised variant of the wake-sleep algorithm that uses CD to modify the network weights. The wake-sleep algorithm [60] is an unsupervised algorithm used to train neural networks in two phases: the ‘‘wake” phase is applied on the feed-forward path to compute the weights and the ‘‘sleep” phase is applied on the feed- back path. The up-down algorithm, described in Table 3, is applied to network to reduce under-fitting which is commonly observed in greedily-trained networks.

A simple and efficient layer-wise training algorithm was pro- posed for DBN by Hinton et al. in 2006 [2]. It trains the layers sequentially and greedily by tying the weights of unlearned layers, using CD to learn the weights of a single layer and iterating until all layers are trained. Tying the weights not only allows us to use RBM’s training algorithm but also eliminates the ‘‘explaining away” phenomenon. Then, the network weights are fine-tuned using a two-pass ‘‘up-down” algorithm.

CA are a deep artificial neural network model, which borrows several concepts and aspects from the human brain. The main inspiration is drawn from the findings of Edelman and Mountcastle [15,7], which state that the brain is composed of cortical columns arranged in six layers. He also uses the concept of strengthening and inhibiting to build a computational training algorithm capable of extracting meaningful information from the sensory input and creating invariant representations of patterns. Further description of the CA model and its biologically plausible aspects can be found in [61,51,62].

A typical CA network consists of an association of columns grouped in layers or levels. A column is a collection of neurons associated with the same stimulus, as shown in Fig. 2. Hence, CA can be considered as a three-level hierarchy structure. The neu- rons, like in other neural network architectures, use an activation

(9) is the result of the nonlinear activation function f (.) in (10) in response to the weighted sum of the input connections while the output of the column is the sum of the outputs of the column’s neurons. T is a constant (across layers) tolerance parameter empir- ically selected and the nonlinear activation function emulates the brain’s observed nonlinear activity.

The network is assumed to be initially fully connected with ran- dom weak weights (with absolute values less than 0.1). This is a common ‘‘blank slate” approach to ensure that the network is not initially biased to any specific pattern. As learning proceeds, these weights are incrementally updated so that the connectivity of the network is modified. All weights that fall to zero represent disabled connections. Therefore, an initially fully connected net- work is not necessarily preserved.

The first stage in training a cortical network aims at creating input-specific representations via random firing and repeated exposure. An input propagating through the levels of the network causes certain columns to fire (i.e. generate a threshold crossing response) based on initially random weights. This activation is then reinforced by strengthening the active columns’ weights and inhibiting neighboring ones. Repeated exposure or batch

ing process is shown in Fig. 3. The top row shows the firing scheme (blue squares represent active columns) obtained after the feedfor- ward propagation of two variations of the same pattern as well as the desired firing scheme (average activation obtained based on all variations of this pattern in the training set). The middle and bot- tom rows show a succession of training epochs (for pattern 1 and 2 respectively) in which the error signal is generated at the top level and stable activations are formed from top to bottom. One can see that at convergence both instances are represented with the same firing scheme in the network.

two aspects of the computational complexity: memory and com- putations. While the required memory storage depends on the number of non-zero weights in the network, the number of com- putations depends on the non-zero weights and the adopted acti- vation function. Comparing CA to DBN, the more computationally demanding network is data specific since each problem would result in a different number of non-zero weights. We empirically compare the network sizes in the next section.

The number of floating point operations required to compute the summation depends on the number of input connections of a neuron. Assuming there are m connections, m multiplications and m additions (including the bias term) are required, which is of the order of O(m2). For an input layer neuron, m is equal to the number of features in the input vector. For a hidden layer neu- ron, m is at most equal to the number of neurons in the previous layer.

Computing the Gaussian activation function, described by (17), requires m multiplications and m(m — 1) additions to compute the magnitude term, where m represents the dimen- sionality of the vector xi and is equivalent to the number of input connections of a neuron. Dividing by the standard devi- ation requires 3 additional multiplication operations. In addi- tion, the calculation of an exponential, estimated using the Taylor series expansion with approximately 10 terms, requires approximately 81 operations. In total, m2(m — 1)+ 81 opera- tions are required.

In summary, the overall computational cost of DBN and CA depends on the architecture of the network: the number of layers and the number of neurons per layer which affect the number of connections. The activation function can be fixed for both DBN and CA. Sigmoid is a common activation function used in both algorithms. After training, some of these connections will have a weight of zero. Based on the previous sections, we notice that for a fixed network architecture, CA will have less non-zero weights due to the pruning algorithm. However, the depth of the best net- works for each algorithm vary based on the data. six-layer archi-

described in Table 7. The datasets contained real-valued features. A 4-fold cross validation was adopted, i.e. each database is ran- domly divided into 4 sets where 3 sets (or 75% of the data samples) are used in training and 1 set is used in testing. The results are averaged over four runs where each set is used for testing once

The term synaptic pruning refers to the procedure by which synaptic connections are terminated during the early ages of mammals’ lives [65]. Starting with approximately 86 8 billion neurons at birth, the human brain quintuples its size until adoles- cence after which the volume of synaptic connection decreases again [66]. This process of pruning is mainly thought of as the byproduct of learning. While the total number of neurons

machine with Intel Core i5. The DBN library is a set of Matlab func- tions modified from [75]; it was run on an Intel Core i7 processor machine. Multiple network architectures, summarized in Table 8, were tested on the datasets. The number of neurons for the hidden layers are displayed only. The input layer’s neurons are equal to the number of features and the output layer’s neurons are equal to the number of classes. The chosen architectures can be grouped into

The training of a cortical network bears several resemblances to the synaptic pruning procedure: starting with a fully connected structure, the network goes through an unsupervised phase where connections are pruned through inhibition leaving only ‘‘signifi- cant” ones. In more accurate terms, the strengthening of firing col- umns ensures the establishment of selective connections while inhibition prunes irrelevant connections. This process plays a cru- cial role not only in extracting meaningful characteristics of the input stimuli but also in avoiding overfitting due to the especially complex structure of a cortical network. This is further demon- strated in the number of non-zero weights in different network architectures as shown in our theoretical and empirical analysis: the number of ‘‘alive” connections decreases with the increase of parameters, hence a minimal effect on performance as shown in our experiments. This property of CA’s structure and training is not shared with DBN.

one of three sets based on the pattern of hidden layer neurons: net- works with an equal number of neurons in all hidden layers, net- works with an increasing (doubling) number of neurons as the layer depth increases and networks with a decreasing (halving) number of neurons as the layer depth increases. Furthermore, the number of hidden layers is increased from 2 to 6 hidden layers. For the results reported in Table 9, DBN’s unsupervised training and fine-tuning algorithms were each run for 50 epochs and the batch size was set to 10. The second column indicates the number of col- umns per layer for CA (there were 20 neurons per column) and the

network. The threshold is not set to a fixed value since the weights range of weights varies based on the input data, i.e. for some data- sets all the weights might be less than this set threshold even though this threshold might be very small. Furthermore, the threshold is not set to zero since some weights will not exactly zero but significantly smaller than the other weights in the net- work and their contribution is insignificant. The classification

DBN exhibit high connectivity for most datasets on various net- work sizes. Therefore, Hinton et al.’s greedy training algorithm does not eliminate a large number of connections resulting in an almost fully connected graph. This is evident in the experimental results reported in Table 9 which reports the percentage of non-

zero weights in a DBN network to be around 90%. Unlike DBN, CA generally results in a sparsely connected network, evident by the low percentage of non-zero weights obtained after training; CA networks had less than 50% of their connections in tact com- pared to almost 90% for DBN. Furthermore, we notice that CA’s connectivity tends to decrease as the network size increases which implies that if certain data does not require a large network, CA’s training algorithm will reduce the number of connections to pro- duce a sparsely connected network. For example, connectivity per- centage decreases from 98.7% to 40.8% for MNIST when increasing the network architecture from a two-hidden layer network to a six-layer architecture.

The DBN code randomly reorders and divides the data into mini batches. While training, each mini batch is loaded into memory and used to update the weights of the network connections. Increasing the size of a batch meant loading a larger chunk of data into memory. This renders training slower if the chunk was too large to fit into memory. However, decreasing the batch size meant more memory transfers per epoch and therefore, increasing train- ing time. On the other hand, CA does not randomly reorder and divide the data into mini batches. Therefore, the network is exposed to the data in the order it was presented. Theoretically, reordering or dividing the data has no effect on the performance of the algorithm as all patterns are employed and must achieve a stable activation.

there is a statistical significance between CA and DBN on all data- bases; the p-value was less than 5%. Furthermore, the Nemenyi post hoc [78] was performed once a significant difference was observed, to rank the algorithms. The rankings revealed that CA outperformed DBN on most databases except for Skin Segmenta- tion, as shown in Fig. 4. The critical distance is summarized in Table 10.

