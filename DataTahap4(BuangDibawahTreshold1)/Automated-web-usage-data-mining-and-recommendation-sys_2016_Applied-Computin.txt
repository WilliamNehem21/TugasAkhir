Abstract The major problem of many on-line web sites is the presentation of many choices to the client at a time; this usually results to strenuous and time consuming task in finding the right product or information on the site. In this work, we present a study of automatic web usage data mining and recommenda- tion system based on current user behavior through his/her click stream data on the newly developed Really Simple Syndication (RSS) reader website, in order to provide relevant information to the individual without explicitly asking for it. The K-Nearest-Neighbor (KNN) classification method has been trained to be used on-line and in Real-Time to identify clients/visitors click stream data, matching it to a particular user group and recommend a tailored browsing option that meet the need of the specific user at a particular time. To achieve this, web users RSS address file was extracted, cleansed, formatted and grouped into meaningful session and data mart was developed. Our result shows that the K-Nearest Neighbor classifier is transparent, consistent, straightforward, simple

The term web mining was believed to have first came to be in 1996 by Etzioni in his paper titled ‘‘The World Wide Web: Quagmire or Gold mine’’ and since then attention of researchers world over has been shifted to this important research area [26]. In recent years, there has been an explosive growth in the number of researches in the area of web mining, specifically of web usage mining. According to Federico and Pier [9], over 400 papers have been published on web mining since the early paper published in 1990s.

The Really Simple Syndication (RSS) reader website was developed for the pur- pose of reading dailies news on-line across the Globe, but lack ways of identifying client navigation pattern and cannot provide satisfactory Real-Time response to the client needs, so, finding the appropriate news becomes time consuming which makes the benefit of on-line services to become limited. The study aimed at design- ing and developing an automatic, online, Real-Time web usage data mining and recommendation system based on data mart technology. The system is able to observe users/clients navigation behavior by acting upon the user’s click stream data on the RSS reader web site, so as to recommend a unique set of objects that satisfies the need of an active user in a Real-Time, online basis. The user access and navigation pattern model are extracted from the historical access data recorded in the user’s RSS address URL file, using appropriate data mining techniques.

To achieve this, the web users RSS address URL file was extracted, cleansed, formatted and grouped into meaningful session for data mining analysis, data mart was developed, this is as a result of the fact that the raw URL file extracted is not well structured to be used directly for data mining [19]. In designing the data mart, the process of URL data acquisition and model extraction was imple- mented using database management software specifically the Structured Query Language, MySQL 2008 [20]. The process of the development of the automatic Real-Time web usage mining and recommendation application was done by adopting the Java programming language with NetBeans as the editor and com- piler [21]. The MATLAB software was used for interpretation and graphical pre- sentation of the result obtained [17]. A thorough presentation of the experimental result was done in order to assist the site designer and administra- tor to improve the content and impressiveness of the said RSS reader site. Fig. 1 showing the architecture of the overall system can be seen in Supplementary material.

Data mining system can be classified using different criteria. Jiawei and Micheline [13], identified these criteria as kind of database mined, kind of knowledge mined, type of technique utilized and according to type of application adapted. Federico and Pier [9], stated further that in web usage data mining task, different techniques can be adopted, but the issue is how to determine which technique is most appro- priate for the problem at hand. A multiple approach or an integrated technique that combines the benefits of a number of individual approaches can be adopted by a comprehensive data mining system [28]. [13,15,16], stated that there are dif- ferent techniques for data classification which includes; decision tree classifier, Bayesian classifier, K-Nearest Neighbor classifier, and rule base classifier. In our work, the K-Nearest Neighbor classification method was adopted.

Decision tree: The use of classification and regression tree (CART) was adopted by Amartya and Kundan [1] in their work. In constructing a decision tree, they applied both the gini index(g) and entropy value (ei) as the splitting indexes, the model was experimented with a given set of values, different sets of results were obtained for both the outlook, humidity, windy, Temp, and Time for execution. The result of the experiment shows that the best splitting attribute in each case was found to be outlook with the same order of splitting attributes for both indices.

The SOM model: Self Organizing Map (SOM) or Kohonen neural network model was explored by Xuejuu et al. [30], in their work, to model customers nav- igation behavior. The model was used to create clusters of queries based on user session as extracted from web log with each cluster representing a class of users with similar characteristics, in order to find the web links or product of interest to a current user on a Real-Time basis. The experimental result of the SOM model performance was compared with that of K-Means model, and the SOM model was found to outperform the K-Means model with value of correlation co-efficient of SOM model scoring twice that of K-means result.

Bayesian classifier model: Decision rule and Bayesian network, support vector machine and classification tree techniques were used by Rivas et al. [27], to model accidents and incidents in two companies in order to identify the cause of accident. Data were collected through interview and modeled. The experimental result was compared with statistics techniques, which shows that the Bayesian network and the other methods applied are more superior than the statistics technique. Rivas et al. [27], stated further that the Bayesian/K2 network is of advantage as it allows what-if analysis on data, which make the data to be deeply explored.

In theory, Bayesian classifier is said to have minimum error rate in comparison with all other classifier but in practice this is not always the case, due to inaccuracy in assumptions made for its use, such as class conditional independency and the lack of available probability data which is usually not the case when using KNN method. The K-Nearest Neighbor (KNN): Many researchers have attempted to use K- Nearest Neighbor classifier for pattern recognition and classification in which a specific test tuple is compared with a set of training tuples that are similar to it. [12], in their own work introduced the theory of fuzzy set into K-Nearest Neighbor technique to develop a fuzzy version of the algorithm. The result of com- paring the fuzzy version with the Crisp version shows that the fuzzy algorithm dom- inates its counterpart in terms of low error rate. In the work of [11]. The K-Nearest Neighbor algorithm was used alongside with five other classification methods to combine mining of web server logs and web contents for classifying users’ navigation pattern and predict users’ future request. The result shows that the KNN outper- formed three of the other algorithms, while two of them performed uniformly. It was also observed that KNN archives the highest F-Score and A(c) on the training set among the six algorithms. [25], as well adopted the KNN classifier to predict pro- tein cellular localization site. The result of the test using stratified crossvalidation shows the KNN classifier to perform better than the other methods which includes

The K-Nearest Neighbor (K-NN) algorithm is one of the simplest methods for solving classification problems; it often yields competitive results and has signifi- cant advantages over several other data mining methods. Our work is therefore based on the need to establish a flexible, transparent, consistent straightforward, simple to understand and easy to implement approach. This is achieved through the application of K-Nearest Neighbor technique, which we have tested and proved to be able to overcome some of the problems associated with other avail- able algorithms. It is able to achieve these by the following:

Available published literature makes it clear that though web based recommenda- tion systems are increasingly common, there still available many problem areas calling for solutions. The fact is that most existing works lack scalability and capa- bility when dealing with on-line, Real-Time search driven web sites, more so, the recommendation quality and accuracy of some are doubtful, since they mostly relied on historical information based on clients’ previous visit to the site, rather than his immediate requirement. Some recommendation systems as well, create a lot of bottleneck through system computing load when handling scaled web site at peak visiting time thereby slowing down the recommendation process.

This section presents detail description of the realization and implementation of web usage data mining system. The presentation of the application of the pro- posed methodology for the analysis of users’ RSS address file of the RSS reader website was showcased. We have developed an online, Real-Time recommenda- tion expert system that can assist the web designer and administrator to improve the content, presentation and impressiveness of their website by recommending a unique set of objects that satisfies the need of active user based on the user’s cur- rent click stream.

(iii) web client [9]. In this study, the web server source was chosen for the fact that it is the richest and most common data source, more so, it can be used to collect large amount of information from the log files and databases they represent. The user profile information, the access and navigation pattern or model are extracted from the historical access data recorded in the RSS reader site, users’ address data- base. The data are so voluminous as it contains so many detailed information such as date, time in which activities occur, saver’s name, IP address, user name, pass- word, dailies name, required feed, news headlines, and contents, as recorded in the database file. In fact, the original document is about 5285 pages.

Data pre-processing: In the original database file extracted, not all the informa- tion are valid for web usage data mining, we only need entries that contain rele- vant information. The original file is usually made up of text files that contains large volume of information concerning queries made to the web server in which in most instance contains irrelevant, incomplete and misleading information for mining purpose [30,11]. Resul and Ibrahim [26], described data preprocessing as the cleansing, formatting and grouping of web log files into meaningful session for the sole aim of utilizing it for web usage mining.

Data cleansing: Data cleansing is the stage in which irrelevant/noisy entries are eliminated from the log file [18]. For this work the following operations were car- ried out: (i) Removal of entries with ‘‘Error’’ or ‘‘Failure’’ status. (ii) Removal of requests executed by automated programs such as some access records that are automatically generated by the search engine agent from access log file and prox- ies. (iii) Identification and removal of request for picture files associated with request for a page and request include Java scripts (.js), and style sheet file (iv) Removal of entries with unsuccessful HTTP status code, etc.

Data mart development: Two crown corporation [29], explained that data mart is a logical subset of data warehouse. If the data warehouse DBMS can support more resources, that will be required of the data mining operation, otherwise a separate data mining database will be required. Since the raw log file is usually not a good starting point for data mining operation, the development of a data mart of log data is required for the data mining operation. In this work a separate data mart of users’ RSS address URL was developed using relational database Management software MySQL [20,19].

There is need for a mechanism to distinguish different users so as to analyze users access behavior [11]. Transaction identification is meant to create meaningful clus- ters of references for each user. Xuejuu et al. [30], stated that a user navigation behavior can be represented as a series of click operations by the user in time sequence, usually call click stream, which can further be divided into units of click descriptions usually referred to as session or visit.

Session identification: According to [30,11], a session can be described as a group of activities carried out by a user from the user’s entrance into the web site up to the time the user left the site. It is a collection of user clicks to a single web server [4]. Session identification is the process of partitioning the log entries into sessions after data cleansing operation [18,3]. In order to achieve this Xuejuu et al. [30], suggested the use of cookies to identify individual users, so as to get a series of clicks within a time interval for an identified user. One session can be made up of two clicks, if the time interval between them is less than a specific per- iod [4,5].

Pattern discovery is the key process of web mining which includes grouping of users based on similarities in their profile and search behavior. There are different web usage data mining techniques and algorithms that can be adopted for pattern discovery and recommendation, which includes, path analysis, clustering, and associate rule. In our work, we have experimented with the K-Nearest Neighbor classification technique as described in Section 3.2 in order to observe and analyze user behavior pattern and click stream from the pre-process to web log stage and to recommend a unique set of object that satisfies the need of an active user, based on the users’ current click stream.

Pattern analysis is the final stage in web usage mining which is aimed at extracting interesting rules, pattern or statistics from the result of pattern discovery phase, by eliminating irrelevant rules or statistics. The pattern analysis stage provides the tool for the transformation of information into knowledge. We have incorporated an SQL language to develop a data mart using MySQL DBMS software specifi- cally created for web usage mining purpose in order to store the result of our work [16]. The data mart is populated from raw users RSS address URL file of the RSS reader’s site that contains some basic fields needed; our experiment result is pre- sented in Section 4.

The problem at hand is a classification problem, therefore the K-Nearest Neighbor method of data mining is ideal. The objective of the system is to create a mapping, a model or hypothesis between a given set of documents and class label. This mapping was later to be used to determine the class of a given Test(unknown or unlabeled) documents [31]. The K-Nearest Neighbor model is the simplest and most straightforward for class prediction, it is the most popular similarity or distance based text and web usage classification and recommendation model [31].

According to Leif [14], a non-parametric method of pattern classification popularly known as K-Nearest Neighbor rule was believed to have been first introduced by Fix and Hodges in 1951, in an unpublished US Air Force School of Aviation Medicine report. The method however, did not gain popularity until the 1960s with the availability of more computing power, since then it has become widely used in pattern recognition and classification [13]. K-Nearest Neighbor could be described as learning by analogy, it is learnt by comparing a specific test tuple with a set of training tuples that are similar to it. It is classified based on the class of their closest neighbors, most often, more than one neighbor is taken into consideration hence, the name K-Nearest Neighbor (K-NN), the ‘‘K’’ indicates the number of neighbors taken into account in determining the class [13]. The K-NN algorithm has been adopted by statisticians as a machine learning approach for over 50 years now [31]. The K-NN is often referred to as ‘‘Lazy learner’’ in the sense that it simply stores the given training tuples and waits until it is given a test tuple, then performs generalization so as to classify the tuple based on similarities or distance to the stored training tuples. It is also called ‘‘instance based learner’’. The lazy learner or instance based learner does less work when presented with training tuples and more work during classification and prediction, therefore makes it computational expensive, unlike the eager learners that when given a training tuple construct a classification model before receiving the test tuple to classify, it is therefore very ready and eager to classify any unseen tuples. [13,31,1]. [13,14], stated that the K-NN error is bounded above twice the Baye’s error rate.

Let Xi be an input tuple with p features (xi1, xi2, .. ., xip) Let n be the total number of input tuples (i = 1, 2, .. ., n) Let p be the total number of features (j = 1, 2, .. ., p)

Eq. (3.2) is applicable to numeric attribute, in which we take the difference between each corresponding values of attributes tuple x1 and x2, square the result and add them all together then get the square root of the accumulated result this gives us the distance between the two points x1 and x2 [13,14]. In order to prevent attributes with initially large ranges from outweighing attributes with initial smaller ranges, there is a need to normalize values of each attributes before applying Eq. (3.2).

A categorical attribute is a nonnumeric attribute such as color and object name. To calculate the distance, we simply compare the corresponding values of the attri- butes in tuple x1 with that of x2, if the values are the same, then the difference is taken to be zero(0), otherwise the difference is taken to be one(1). For instance, if two users, x1 and x2 click stream on the RSS reader site is both sport news cate- gory, then the difference is zero(0), but if tuple x1 is sport and tuple x2 is politics, then the difference is taken to be one(1) [13].

In reality, the value of K is usually odd numbers, ie. K = 1, K = 3, K = 5, etc. this is obvious in order to avoid ties [14]. K = 1 rule is mostly referred to as the nearest neighbor classification rule. The value of K (Number of neighbor) can be deter- mined by using a test set to determine the classification error rate, by experiment- ing with different values of K, starting with K = 1, then the K value with minimum error rate is selected [13]. Jiawei and Micheline [13], stated further that the larger the training tuple, the larger the value of K. Zdravko and Daniel [31], in their work, experimented with different values of up to K = 19, with and without dis- tance weighting on a set of document collections, the experiment was run with a complete set of 671 attributes and concluded that a small set of relevant attributes works better than all attributes, that the experiment works perfect with K = 1, and K = 3 and with little improvement in K = 5. So, if K approaches infinity, the error rate approaches that of Baye’s error rate [13]. Zdravko and Daniel [31], further stated that 1-NN makes a better prediction using single instance how- ever large the training set is, but under the assumption that there is no noise and all attributes are equally important for classification.

In our work, we adopted 5 as the maximum value of K. We simply applied the distance weighted K-NN approach, in which we experimented for different values of K on our sample data, starting from K = 1, up to K = 9. We discovered that the experiment works better with K = 1, K = 3 and with little accuracy at K = 5, so, we selected K = 5, which gives us the minimum error rate. The algorithm for the K-Nearest Neighbor classifier model is shown in Fig. 2, in Supplementary material.

Example 1. Let us consider the RSS reader sites’ client click stream as a vector with three(3) attributes: Daily name News category and Added required feed type, with users represented by X1, X2, X3, X4, .. ., X11 as the class labels as shown in Table 1. Assuming the class of user X3 is unknown.

Remember, for a categorical attribute as in Table 1, the difference (x11, x31) can be computed by simply compare the corresponding value of the attributes in tuple x1 with that of x3 as explained previously. If the values are the same then the differ- ence is taken to be zero(0), otherwise, the difference is taken to be one(1). So, for (x1,1 and x3,1) ie. (CNN news and Punch ng), the difference is 1, for (x12 and x32) ie. (World and Politics) the difference is 1, likewise for (x13 and x33) ie., (www.*- world and www.*politics) the difference is 1 as well, therefore,

Repeating the same process in our example for all other tuple x2, x4, .. ., x11, the result of these calculation produced a stream of data as shown in Table 2, which shows the users sorted by their Euclidean distance to the user x3 to be classified. The 1-NN approach simply picks the user with minimum distance to x3, (the first one from the top of the list) and uses it’s class label ‘‘politics’’ to predict the class of x3, therefore recommends similar news headlines of ‘‘Politics’’ as in

In example 1, 3-NN will as well classify ‘‘Politics’’ because it is the majority label in the top three classes. However, distance weighted K-NN can be helpful in determining the class a given test tuple belong, whenever there seems to be a ties [31]. For instance, the distance weighted 5-NN will simply add the distance for class politics as in our example in Table 2 and compare it with that of Entertainment whichever is greater is selected. i.e. 1.000000000 + 1.000000000 + 1.000000000 + 1.141421356 = 4.141421356 while that of enter-

tainment is 1.141421356 thus, weight of ‘‘politics’’ > ’’Entertainment’’ Then the 5-NN will as well classify user x3 as ‘‘Politics’’ because it has higher weight than entertainment. The distance weighted K-NN allows the algorithm to use more or even all instances instead of one instance as in 1-NN.

This section evaluates our system by applying the result of the experiment con- ducted. The result was presented and analyzed in order to evaluate the quality of our recommendation system based on K-Nearest Neighbor classification model. In the previous section we established that a class with minimum distance to the test tuple will be predicted for 1-NN or in case ties exist, the weighted dis- tance predict a class with greater weighted distance as in 5-NN in example 1 and recommendation will be made based on this, for user with unknown class.

Software was developed with Java NetBeans programming language and MySQL DBMS was used in creating the data mart in order to implement our model using K-NN method. The sample interface from the automated on-line Real-Time recommendation system developed for the purpose, indicating the active user’s click stream, a dialog box presenting his requested news headlines and a message box presenting Real-Time recommendation to the user based on his current request is shown in Fig. 3 in Supplementary material and the source code in Java NetBeans programming language for the system is also available as part of Supplementary material.

The K-Nearest Neighbor classifier predicts the class label with class Ci for which Ci = {x  Cp; d(x,xi) 6 d(x,xm), i #m} for the unknown user class ie., the 1-NN classification simply picks the user with minimum distance to users X3 and X7 as the case may be (ie. The first user from the top of the list), in Table 2 for user X3 and Table 3 for user X7 respectively and use their class labels to predict the class of X3 and X7 respectively, therefore, recommend similar news headline of politics for user X3 as in user X9 class from Table 2 and Sports for user X7 as in user X8 class from Table 3 as shown in Fig. 4, Figs. 5 and 6 respectively. Figs. 5 and 6 can be found in Supplementary material.

We have conducted experiments on our designed experimental system. The data set used in the system is the RSS user access database for a two months period, which was extracted, pre-processed and grouped into meaningful sessions and data mart was developed. The K-Nearest Neighbor classification technique was used to investigate the URL information of the RSS users’ address database of the RSS reader site as stored in the data mart created. Evaluating sample testing

session, the results are presented and analyzed. The results of our experiment indi- cate that the adoption of K-Nearest Neighbor model can lead to more accurate recommendation that outperformed other classification algorithms. In most cases the precision rate or quality of recommendation is equal to or better than 70%, this means that over 70% of news recommended to a client will be in line with his immediate requirement, making support to the browsing process more gen- uine, rather than a simple reminder of what the user was interested in on his pre- vious visit to the site as seen in path analysis technique.

