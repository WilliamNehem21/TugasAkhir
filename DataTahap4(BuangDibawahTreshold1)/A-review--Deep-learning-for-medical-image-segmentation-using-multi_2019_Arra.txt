learning-based networks learn a complex and abstract hierarchical feature representation for image data to overcome the difficulty of manual feature design. Second, deep learning-based networks can pre- sent the complex relationships between different modalities by using the hierarchical network layer, such as the layer-level fusion strategy. Third, the image transform and fusion strategy in the conventional fusion strategy can be jointly generated by training a deep learning model, in this way some potential deep learning network architectures can be investigated for designing an effective image fusion strategy. Therefore, the deep learning-based method has a great potential to produce better fusion results than conventional methods.

Choosing an effective deep learning fusion strategy is still an impor- tant issue. In 2013–2018 BraTS Challenge, all the methods applied the input-level fusion to directly integrate the different MR images in the input space, which is simple and can remain the intrinsic image feature and allow the method to focus on the subsequent segmentation network architecture designs, such as multi-task, multi-view, multi-scale and GAN-based strategies. While the strategy just concatenates the modalities in the input space, but it does not exploit the relationships among the different modalities. For layer-level fusion, with the dense connection among the layers, the fusion strategy often takes the DenseNet as the basic network. The connection among the different layers can capture complex relationships between modalities, which can help the segmen- tation network learn more valuable information and achieve better per- formance than directly integrating different modalities in the input space. For decision-level fusion strategy, it can achieve better perfor- mance compared to the input-level fusion, because each modality is employed to train a single network to learn independent feature repre- sentation, while this requires much memory and computational time. Compared the last two fusion strategies, the layer fusion strategy seems better, since the dense connection among the layers can exploit more complex and complementary information to enhance the network training, while the decision-level fusion only learns the independent feature representation in single modality. Since the results of the three fusion strategies are not obtained from the same data, their comparison in terms of performance is difficult. Methodologically, each strategy has its advantages and disadvantages.

Mendrik AM, Vincken KL, Kuijf HJ, Breeuwer M, Bouvy WH, De Bresser J, Alansary A, De Bruijne M, Carass A, El-Baz A, et al. Mrbrains challenge: online evaluation framework for brain image segmentation in 3t mri scans. Comput Intell Neurosci 2015;2015:1.

Kamnitsas K, Bai W, Ferrante E, McDonagh S, Sinclair M, Pawlowski N, Rajchl M, Lee M, Kainz B, Rueckert D, et al. Ensembles of multiple models and architectures for robust brain tumour segmentation. In: International MICCAI brainlesion workshop. Springer; 2017. p. 450–62.

Sudre CH, Li W, Vercauteren T, Ourselin S, Cardoso MJ. Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations. In: Deep learning in medical image analysis and multimodal learning for clinical decision support. Springer; 2017. p. 240–8.

