Deep learning techniques, in their most basic form, combine vari- ous forms of sophisticated artificial intelligence with machine learning models. These models employ a number of different levels of abstraction in order to construct hierarchical representations of the data [20–22]. For instance, artificial neural networks can be used to construct the hi- erarchical representation [22,23]. To put it another way, deep learning techniques are computer programs that resolve the best predictions by employing artificial neural networks that include several layers, as op-

posed to employing artificial neural networks that only employ a single individual layer [22]. Deep learning algorithms have achieved a broad variety of applications in drug design and discovery [9,21]. These ap- proaches are based on the most advanced computer technologies now available, such as general-purpose computing performed on graphics processing units. There is an enormous need to employ software tools in deep learning frameworks for various drug development tasks [2] in order to address the demanding challenges we face today in the field of drug design and discovery. These challenges are presented in the form of complex problems that must be solved. To be more specific, deep learn- ing frameworks are utilized in order to serve as tools in order to ful- fill the applications of drug design and discovery, such as molecular de novo design, dimension reduction of single-cell data in pre-clinical devel- opment, compound property and activity prediction, reaction analysis, synthesis prediction, and biological image analysis [1]. These applica- tions include molecular de novo design, dimension reduction of single- cell data in pre-clinical development, reaction analysis, synthesis pre- diction, and biological image analysis.

An up-and-coming method known as the generative adversarial net- work (GAN) architecture [24] has been garnering a growing amount of interest in both the fields of artificial intelligence and machine learn- ing research as a result of recent developments in deep learning frame- works. To begin, the GAN architecture has a significant potential to be utilized in a wide variety of applications, including the creation and dis- covery of new drugs, the analysis of photos and videos, the translation of language, and other areas [25–28]. In addition, the implementation of the GAN architecture has been making a contribution to the study on drug design and discovery. Recent years have seen a broad range of important research investigations for the design and discovery of new drugs, such as molecular de novo design, which took into account the GAN architecture [2,9]. For instance, GAN-based frameworks such as the deep adversarial autoencoder structure have been used to design and find new drugs for anticancer therapy by utilizing chemical and biological datasets [29,30]. This has been accomplished by combining the two types of data. In addition, the deep adversarial variational au- toencoder structure has been shown to successfully complete the task of dimensionality reduction for single-cell RNA sequencing data in the preclinical stage of the drug development pipeline [28]. This is a re- markably intriguing example for a number of reasons, not the least of which is the fact that it fulfills the task. In the following sections, we will elaborate on the intricacies of several GAN-based frameworks that are used in drug design and discovery. Some examples of these frameworks include the deep adversarial autoencoder and the deep adversarial vari- ational autoencoder structures.

on three major categories in terms of drug design and discovery [31– 35]. These categories are molecular de novo design, dimension reduction of single-cell data in preclinical development, and de novo peptide and protein design. All of these research studies are presented within the context of GAN-based frameworks [36,37]. Because, to the best of our knowledge, there may not be many studies in drug design and discovery that use the GAN-based frameworks for other applications at the time of the submission of this paper, we primarily focus on these three ap- plications employing a broad variety of the GAN-based frameworks. In light of this, the biological and/or therapeutic implications stemming from these three key sectors might potentially serve as a platform for future study in the design and discovery of drugs utilizing GAN-based frameworks [38–41]. In addition to this, we describe the restrictions that were placed on these research investigations and provide a sum- mary of a debate regarding the future diﬃculties and directions. This review does not support the full set of related research studies that were reported in the literature [42–44]; however, it does describe a synthesis of those studies that have the potential to significantly influence public and population health-oriented applications in drug design and discov- ery using GAN-based frameworks in the relatively near to intermediate future.

designed to emulate that of the human mind through learning from the surrounding environment and/or experiences. When working on ma- chine learning, there are three focuses of the model: the class of the task, the factor by which the performance must be improved by, and the source of the overall experience [45]. Using these three factors, ma- chine learning models have the optimization goal of minimizing their learning error through the use of a variety of algorithms such as gra- dient descent and backpropagation. Gradient descent looks at the error curve that the model generates compared to what it should be outputting and finds the right parameters for the model that minimizes the error. These algorithms have been applied in a very broad range of environ- ments consisting of, but not limited to: computer vision, entertainment, spacecraft engineering, finance, and computational biology [45].

putting a discrete number of classes or regression outputting a continu- ous value or set of values [46]. For example, a machine learning model such as linear regression classifying a given image as containing a cat or a dog would first need to be separately shown images of a cat and a dog to learn the features within the images to then compare to the features of a new image. For regression, a model could be trained on the previous sales of a company to then create a numerical prediction to forecast future sales and growth of the next year.

Unsupervised learning uses unlabeled data clusters and creates asso- ciations among the data points in order to identify any similarities and sequences of repeating patterns among the data [47]. For example, if a company wants to segment its customer base into a range of clients from low to high priority, then it would use an unsupervised learning model such as a gaussian mixture model to market its product towards a certain customer segment in a given season. Another important use of unsupervised learning is to prepare an unlabeled dataset for a supervised learning task which is a hybrid task called self-supervised learning.

Both supervised and unsupervised learning involves the optimiza- tion of each model’s parameters, their weights, and other hyperparam- eters, in order to minimize the error the model produces. However, re- inforcement learning involves training a model that interacts with its environment in order to maximize a reward. The reinforcement agent is rewarded for desirable behaviors, such as an autonomous agent being able to walk properly, and is punished for undesirable behaviors such as the agent falling [48].

Deep learning is defined as a multi-layered learning module, referred to as a neural network. A neural network is composed of non-linear modules, transferring and converting the information between its lay- ers. These non-linear modules are called activations which, similarly to a biological neuron’s activation potential, determines how strongly infor- mation passes through the network. The activations in a neural network are determined by activation functions, which are subsequently deter- mined as a parameter in the system [49]. Backpropagation is the popular process of training neural networks by defining a function, and using the hill-climbing technique to optimize performance on a set task. This op- timization calculates the mathematical gradient of a loss function with respect to the neural network’s other weights. Backpropagation has be- come very popular due to its simplistic implementation, and the ability to train non-linear networks of arbitrary connectivity [50].

One of the first known works of artificial intelligence takes place in the late eighteenth century, with the creation of ǣThe Turkǥ, an au- tomated chess-playing machine that would be able to compete against its opponents [51]. It would not be for over 150 years, until 1942, that one can see another example of AI, ǣThe Bombeǥ. Alan Turning created ǣThe Bombeǥ, an electromechanical device, to aid the British in break- ing German codes towards the end of World War II. From this point, the beginning of computation, and thus, AI took off [52]. In 1950, Alan Turing published the ǣTuring Testǥ, which is detailed in the definition of AI, as seen above [53]. Six years later, the ǣbeginning of AI springǥ occurred at the Dartmouth Summer Research Project on Artificial In- telligence (DSRPAI). This project lasted over the course of eight weeks, with the final goal being to gather researchers and create an area that focuses on building machines that simulate the human experience.

Upon the end of the project, it was considered a success within the world of artificial intelligence [54]. Soon after this, the machine learn- ing program ǣperceptronǥ was created in 1958, in the Cornell Aero- nautical Laboratory. This program was originally designed as an image recognition service, but is now used as an algorithm for binary classi- fiers; binary classifiers determine whether an input belongs to a specific class [55]. Five years later, in 1963, Feigenbaum and Feldman published ǣComputers and Thoughtǥ, which describes the internal workings of AI programs at a fairly basic level. This publication was influential in spreading the word about artificial intelligence. Following this, it took another 35 years for any other significant impacts to be made within the field [56]. In 1998, researchers were able to develop a revolution- ary new way of using trainable filters to learn patterns from images.

ing a significant quantity of knowledge required to treat complicated clinical issues. The advancement of medical artificial intelligence has been linked to the creation of AI algorithms designed to assist doctors in the formulation of a diagnosis, the formulation of treatment decisions, and the prediction of results. They are intended to aid healthcare staff with activities that require the processing of data and expertise in their daily jobs. Deep neural networks (DNNs), Unets, fuzzy expert systems, evolutionary computation, and hybrid intelligent systems are examples of such systems.

AI has the potential to fundamentally alter medicine in the next few years. The field of medical AI has advanced significantly in just a few years since the first landmark demonstrations of medical AI algorithms that were able to diagnose a disease from medical pictures at the level of specialists. Today, while the medical AI community navigates the diﬃcult ethical, technological, and human-centered obstacles necessary for safe and successful translation, the deployment of medical AI systems in everyday clinical care represents a significant but largely unrealized potential.

Despite the fact that AI systems have frequently been proven to be successful in a wide range of retrospective medical investigations, only a small number of AI tools have been applied to medical practices. Critics argue that AI systems may be less beneficial in practice than retrospec- tive data would suggest; systems may be too sluggish or diﬃcult to be effective in real-world medical settings, or unexpected issues may occur from the way humans and AIs interact. Furthermore, retrospective in silico datasets is subjected to intensive filtering and cleaning, making them less representative of real-world medical practice.

Recent guidelines, such as AI-specific extensions to the SPIRIT and CONSORT guidelines, as well as upcoming guidelines like STARD-AI, may help standardize medical AI reporting, including clinical trial pro- tocols and results, making it easier for the community to share findings and rigorously investigate the utility of medical AI17,18. Some AI sys- tems have progressed from testing to implementation in recent years, gaining administrative backing and resolving regulatory diﬃculties. The Centers for Medicare and Medicaid Services, which oversees public in- surance payment fees, has made AI more accessible in clinical settings by enabling funding for the use of two particular AI systems for medical image diagnosis.

Furthermore, a 2020 research discovered that the US Food and Drug Administration (FDA) is rapidly approving AI goods, notably machine learning. These advancements primarily take the form of FDA clear- ances, which require devices to achieve a lower regulatory threshold than full-fledged approvals, but they do pave the way for AI/ML sys- tems to be utilized in genuine clinical situations. It should be noted that the datasets utilized for these regulatory approvals are frequently made up of retroactive, single-institution data that is mainly unpublished and deemed proprietary. Stronger requirements for reporting openness and validation, as well as evidence of influence on clinical outcomes, will be essential to develop confidence in medical AI systems.

Significant advances in pathology, mostly through the use of whole- slide imaging, have been made in identifying malignancies and offering novel disease insights. Models have successfully identified regions of in- terest within slides, possibly speeding up diagnostic operations. Aside from this practical impact, deep neural networks have been trained to distinguish the main tumor origin and find structural variations or driver mutations, delivering benefits that outperform expert pathologist evalu- ations. Furthermore, when compared to conventional grading and histo- logical Through subtyping, AI has been demonstrated to produce more accurate survival forecasts for a wide variety of cancer types. Such re- search has shown how AI may improve the eﬃciency, accuracy, and utility of pathology diagnosis.

cancer. Deep learning has been used to predict if colonic lesions are cancerous, with results equivalent to those of competent endoscopists. Furthermore, because polyps and other potential indicators of illness are usually overlooked during the exam, artificial intelligence (AI) technolo- gies have been created to aid endoscopists. Such technologies have been demonstrated to increase endoscopists’ capacity to identify anomalies, potentially boosting sensitivity and making colonoscopy a more reliable diagnostic tool.

to distinguish the real samples from those generated by the generator. The optimization goal of the generator is to maximize the probability of the discriminator detecting its generated samples as true, which is when the discriminator makes a mistake, and the goal of the discriminator is to correctly classify the generated samples between the true data and the fake data generated by the generator. Training is stopped when the generated samples from the generator can’t be distinguished from the real samples by the discriminator.

One of the biggest inspirations for GANs came from deep Boltzman machines that likewise utilized two separate processes running at the same time while training which included a positive and negative phase [59]. The positive phase loaded in data and made it more likely, and the negative phase drew samples and made them less likely. Through iterative training, the distribution of the samples becomes closer to the distribution the model represents. The parameters of the model are up- dated at the same time as new samples are being generated. However, it was found that deep Boltzman machines lacked the capability to scale past the greyscale MNIST digits dataset, and for example, were unable to generate color image samples in a timely manner. This is caused by the negative phase being unable to keep up with the speed of the posi- tive phase generating samples which prevents deep Boltzman machines from converging to a useful state.

As for training the generator, it must be alternated as the discrim- inator trains. The generator’s loss comes from the penalization of the discriminator correctly classifying its generated sample as fake. As back- propagation flows from the output of the discriminator through the dis- criminator itself, it then additionally will flow into the generator so that the generator’s weights will be updated without changing the discrimi- nator’s weights. Then in the next epoch, backpropagation flows through the discriminator and the discriminator’s weights are updated while keeping the generator’s weights constant. This process repeats until the discriminator’s performance becomes 50% accurate which indicates that the generator is able to generate realistic samples of the data that the discriminator can’t tell between the fake, generated samples and the real ones.

GANs have been used in many different applications, but most no- tably in the generation of new, artificial faces. This can then be used to create videos of famous figures that are completely artificially generated but are realistically looking to fool the human eye. In the wrong hands, GANs can be used to create and promote fake news with artificially generated content about real people, otherwise known as deepfakes, to potentially be used to destroy the reputations of said people. Thus, it’s vital that this powerful deep learning technology be used responsibly for the good of humanity.

plausible data, and the discriminator distinguishes between what part of the data is real or fake. The generator uses the feedback from the dis- criminator to update its weights and biases in order to generate data that can better fool the discriminator by looking more real. The discrimina- tor will then begin to perform worse on the data and will have to update itself to perform better. After this, the generator will be able to use the feedback from the new discriminator to better improve its own data generation. This cycle continues until convergence. For image genera- tion applications, the discriminator is typically a Convolutions Neural Network (CNN) and is able to adapt to the underlying distribution of data. It will perform a binary classification to distinguish between the real and the generated data.

After Goodfellow et al published the Generative Adversarial Nets pa- per, the Deep Learning research community became amazed at how ef- ficiently higher-quality samples were generated. Soon after, Mirza et al modified the GAN architecture by feeding the input data into both the discriminator and generator, and created the Conditional GAN (CGAN) [65]. The CGAN allows you to dictate what type of data should be gen- erated with a condition based on class labels or any modality. In applica- tion, this can be used to identify which parts of the road are important for an autonomous driving vehicle to avoid that were not part of the original training environment, or what sections of a brain scan are signs of a disease external to the current experiment (Fig. 3).

A year later, Denton et al combined the CGAN with a Laplacian pyra- mid to break up the generation of images through multiple CNNs into successive refinements [66]. The Laplacian GAN (LapGAN) was the first GAN architecture to be able to generate high-resolution images by first generating images at a low resolution and then scaling to successive higher resolutions. This was done by taking the difference between the generated images and their blurred counterparts to produce a learnable filter.

A few months later, Radford et al were trying to integrate the CNN architecture, previously used in supervised learning, into the unsuper- vised learning goal of GANs in order to better suit computer vision tasks. They solved their issues of scaling the CNN architectures with GANs by replacing all of the pooling layers with strided and fractional strided convolutional layers [67]. Additionally, the fully connected layers that typically connected the final convolutional layers to the output neurons are removed. The generator takes in input samples and generates con- volutional filters from which the discriminator deconvolves the filters into an image and classifies the generated image. This is called a Deep Convolutional GAN (DCGAN), and what makes this architecture unique is its simplicity and ability to show the connection between certain fil- ters and specific objects those filters learned in a dataset with purity. The simplicity allows for fewer points of error and easier manipulation of the semantic qualities of generated samples. In practice, DCGANs was able to generate much more realistic images of faces than previous ar- chitectures and started to get attention in the media for their application of generating new videos with faces of famous figures known as deep- fakes. DCGAN became a backbone used for many more variants being created in the following years, which created a Cambrian explosion of new GAN architectures being created.

book researchers. It became famous due to its ability to train with- out requiring balanced training of the generator and discriminator as well as reducing the mode-dropping issue found in previous GAN ar- chitectures [68]. In the WGAN, the discriminator is able to be com- pletely trained to its optimal and provides a loss directly to the gener- ator, so as the discriminator increases its accuracy it provides higher quality gradients to train the generator with. As the generator neural network’s architectures vary, WGANs were found to be more robust than GANs [68]. The researchers also created a new metric, the Wasser- stein estimate, that describes the generator’s convergence and quality of the generated samples, which when graphed against the number of training iterations is useful for model debugging and hyperparameter tuning.

Interpretability has always been an important goal when creating and using Deep Learning models, and one such variant of GANs fo- cuses on learning interpretable and meaningful representations of the data through applying feature representational learning [69]. The In- formation Maximizing Generative Adversarial Network (InfoGAN) is a completely unsupervised learning model that is known for its ease of training, and its interpretable results that prove to be crucial in appli- cations and competitive with representations from supervised learning models. InfoGAN was able to uncover and represent writing styles from digit shapes in the MNIST dataset, poses from 3D rendered images when lit, background digits from the central digit on the SVHN dataset, and hairstyles and emotions on the CelebA face dataset.

Researchers from UC Berkeley found a solution to the image-to- image translation task, where a new image is generated that is a mod- ification of the original image, and created the CycleGAN model. The biggest issue with training a GAN for image translation is that a large dataset of original images and their desired modified versions are ex- tremely expensive to create and often don’t exist. CycleGAN instead trains two discriminator and generator models by using cycle consis- tency to have the first generator learn the original images and generate the modified versions which are then learned by the second generator to generate new images as close to the original as possible [70]. An ad- ditional loss metric is a difference between the generated original image from the second generator and the original image which guides the gen- erators toward generating translated images. One of the most impactful applications of this methodology is style transfer where the modified image is of the same style as the original. For example, an image of a dog can be style transferred with a Van Gogh painting to have Cycle- GAN generate a new image of the same dog as Van Gogh would have painted.

Researchers from Google created the famous Transformer architec- ture that connects the encoder, the generator, and the decoder, the dis- criminator, through an attention mechanism [72]. An attention mech- anism looks for the most relevant parts of a dataset through using a weighted combination of input vectors with the most relevant input vectors granted the highest weights. This same architecture was then applied to a convolutional based GAN model called the Self-Attention Generative Adversarial Network (SAGAN) [73]. SAGANs are able to gen- erate data with details across the entire high resolution feature map as opposed to previous models only generating data with details in local points from lower resolution representations of the data. With SAGANs being attention-driven from utilizing the self attention architecture in both the generator and discriminator, they are able to converge must faster than other GAN architectures and achieve state of the art results with the ImageNet dataset [73].

For example, imagine that the Generator creates images that are clas- sified as real by the Discriminator 25% of the time. Therefore, the Gen- erator has a 25% accuracy, and the Discriminator has a 75% accuracy. Now imagine that the Generator improves itself with feedback from the Discriminator, so that the Generator is now 80% accurate. Therefore, the Discriminator must be 20% accurate. In other words, the Generator has improved by 55%, and therefore, the Discriminator must have lost 55% points of accuracy.

However, this poses a problem for creating a loss function for a GAN. If we try to only maximize the performance of the Generator, the best course of action would be to have the Discriminator perform poorly, and vice versa. In 4.1.1, future variants of GANs discussed all tweaked their equations to minimize this situation from occurring (Table 1).

the body the effects would target. This style of medical practice has now become outdated in the modern world as different technologies such as computing has allowed researchers to gain knowledge on how to iden- tify on specific targets in the body in order to study their effectiveness. It constitutes computational and experimental research that is under- gone in order to identify potential new drugs to address certain medical conditions. The process of drug discovery is an arduous and resource- intensive one [102], and GANs may have applications in streamlining it [94,103–106].

used to help resolve are the issues involving the heavy cost and over- all time for drug research, but one issue that has come up for GANs itself involves the limitation when working to explore some regions of chemical space. We previously referenced how GANs work better than other traditional methods as well as newer deep learning when it comes to chemical space, but innovations in GANs look to expand and solve this shortcoming of not having complete access to chemical space. A fully quantum GAN could accelerate the training process for GANs, as well as offer better training samples which could allow more exploration of chemical space but lacks the ability to process over two dimensions [109]. In the future, a fully quantum GAN could be viable and success- ful, but more innovation in the technology is currently needed. In the

meantime, a paper proposing a qubit-eﬃcient quantum GAN mechanism with a hybrid generator and classical discriminator as a tool in drug re- search. Due to requiring less qubits, complex simulation would still be the main function of this model while requiring around 20% less train- ing time and being more successful in searching chemical space [109]. Mode collapse is again an issue with this model. Even with the swifter training, mode collapse can still occur meaning the GAN learns one as- pect of the data quite well, but not all the data is being properly learned causing incomplete training. The results of this model showed a 98% reduction in generator parameters and created the expected benefits of the hybrid system with quicker data learning as well as more success-

ful chemical searching. The reduction of parameters allows for much swifter training and simpler methods of hyperparameter tuning (Fig. 4). GANs are being seen to have applications in de novo peptide and pro- tein design, a process through which new peptides and proteins are dis- covered. This process entails generating new chemical entities that fit a set of constraints using computational algorithms. Hence, the chemical entities can be generated without a starting template from the begin- ning, reflecting the meaning of the phrase de novo [110]. As summa- rized by Lin et al, [109], there have been many studies done regarding the applications of GAN-based approaches in de novo peptide and pro- tein design. Sabban and Markovsky [111] proposed that the LSTM-GAN (Long Short-Term Memory Generative Adversarial Network) structure was able to generate new helical protein backbone topologies. While the LSTM-GAN structure had originally been devised for applications in Natural Language Processing, this group of researchers was able to find uses for it in generating protein backbone topologies with features

Lin et al continue to describe another group of researchers, Karimi et al. [112] who investigated the gcWGAN (guided conditional Wasser- stein General Adversarial Network) structure and its applications in pep- tide folding. This conditional Wasserstein GAN structure is derived from the Wasserstein GAN [68] with gradient penalty. The Wasserstein GAN, as proposed by Arjovsky et al., is a type of GAN architecture which uses

Another GAN structure, Feedback-GAN, was shown by Gupta and Zou [116] to be able to generate antimicrobial peptides with desirable properties. This structure consists of a GAN and differentiable neural network analyzer. This differentiable neural network analyzer is a pre- diction algorithm that determines if a gene sequence is able to encode a peptide. The analyzer and the GAN architecture are connected through a feedback-loop training mechanism which allows the generative module to create valid sequences. In each epoch, the generative module pro- duces many sequences, which then receive a score from the differen- tiable analyzer. The sequence with the highest score is then passed as input to the discriminative module. The discriminative module receives both real inputs and fake inputs(in the form of the generated sequences) then differentiates between the two types of inputs.

A research used GANS with adaptive training data for drug discover. During the training period, the model saved new and valid compounds it generates. The training data then updated using a replacement tech- nique that may be either directed or random. The technique was re- peated when the training resumes. The findings suggest that this method can counteract the decline in new molecules created by a normal GAN during training. In addition, using recombination between created com- pounds and training data to boost novel molecule discovery. By includ- ing replacement and recombination into the training process, GANs may be used for larger drug discovery searches[107].

Researchers have also found applications of GANS in regards to molecular de novo design as well as de novo protein and peptide design. Guimaraes et al. [117] proposed the ORGAN(Objective-Reinforced Gen- erative Adversarial Networks) structure, a structure combining the GAN with reinforcement learning. More specifically, the structure consists of a Sequence GAN model and the recurrent neural network model. The discriminative module is implemented as the convolutional neural net- work model and the generative module is the recurrent neural network model. Guimaraes et al. found that the ORGAN structure was suﬃciently able to generate new molecular compounds with preferred properties through a drug development pipeline. Furthermore, the ORGAN struc- ture was able to do so with better results than just a recurrent neural network model or a GAN model alone.

ful of a drug being researched [118]. Deep learning models can work to identify drugs which have high aﬃnity when binding to specific dis- ease proteins, which is beneficial for drug discovery as it expedites the process for researchers. The strength of GANs in this area comes from advantages in both speed and cost. Other machine learning models in the past have been able to accomplish similar predictive ability, but GANs require less manual input as well as need less expensive costs for building their training data due to the reusing of parts of the generator and discriminator networks as feature extractors.

A study on maximizing the effectiveness of GANs in this area used three elements: a feature extractor for protein compound, a feature ex- tractor for protein sequence, and a regressor for aﬃnity value prediction [118]. In the first round of training, the fake samples are generated by the generator of the GAN and both the fake as well as real samples are put into the discriminator. The discriminator will then work to clas- sify the samples as real or fake so that the generator can create more realistic protein sequences and compounds, which are labeled by the discriminator. In the second round, labeled protein sequences are used to train the regressor to minimize its loss and create optimal model pa- rameters. These parameters can then be used in a feature extracting model and a regression model [118]. Results from using these models showed that GANs can perform as well if not better than previously used learning-based models with the added factor of GANs training on freely unlabeled data and coming at a lower cost by guiding biological experiments. These newly created models by the GAN help create the beneficial protein sequences which can help biologists in targeting the needed cell receptors in drug discovery. The main downside in results was GANs poor performance when dealing with very small data sets, but this can be offset by regularization techniques to train GANs.

GANs are being used to create synthetic DNA sequences that code for proteins of varying lengths. One study used the feedback-loop process to generate synthetic genes that code for antimicrobial peptides and to optimize synthetic genes for the secondary structure of the peptides they produce. A number of measures show that the proteins created by GAN have desired physicochemical characteristics [116].

Fig. 6. Several successful uses of machine learning in various phases of the drug development pipeline in pharmaceutical companies have been documented. These applications may be found in a number of different places. A conceptual map on the experimental and computational methodologies that are applied to the drug discovery process [119], together with a schematic explanation of the drug discovery process that is overlaid with the related computational approaches. There is no particular hierarchy to the order in which the terminologies are listed on any of the colored tracks.

target and guide the administration of drugs to the target area which would resolve the high drug concentration. There are many techniques to accomplish this including rudimentary methods such as direct appli- cation to the affected area, or more complex techniques utilizing normal pH values, temperatures, or magnetic fields. Yet, the most versatile drug targeting technique is achieved by using a unique vector molecule. Vec- tor molecules are ligands that have an increased aﬃnity towards an area of interest. The potential benefits include highly configurable drug de- livery, which allows for higher loading capacity, customizable size, and customizable permeability [125].

Utilizing computational predictions of drug targeting interactions (DTI) is a challenge today. Currently, DTIs are primarily based upon supervised machine learning with known label information. This cre- ates an expensive and time-consuming process. One solution is a semi- supervised generative adversarial network (GANs) based method to pre- dict binding aﬃnity. By the use of computational methods and machine learning, the drug development process can be considerably accelerated and save excessive costs [118].

are made of a feature representation modular from GANs. The third part is a regressor, made up of a Convolutional Neural Network (CNN), which predicts the aﬃnity value. To train this model, it must undergo two processes. The first of which is training the feature extractors in the context of GANs. The GAN begins to generate fake samples starting with a given noise distribution. It is then compared to a real provided sam- ple to discriminate the real data from the fake generated data. As this

continues, the discriminator maps the inputs utilizing a feature space by a local feature extractor. This local feature extractor promotes sample classification, which learns the difference between real and fake pro- teins and SIMILES. After the first round is completed, the local feature extractor will be used as the feature representation of the new model. The second round is to build upon the regressor. This uses the feature extractor from the first round along with the labeled data to train the

regressor to minimize the last function, leading to optimal model param- eters. Now, this can be used with drugs that are represented as SMILES strings and protein sequences that are represented as a string of ASCII letters, which are amino acids [118]. Allowing for the input to be in the form of a string allows for the discriminator to learn the latent fea- tures of those sequences. Ian Goodfellow et al suggest a minimax game

The convolutional regression model conducts convolution operations with kernel size 4 to create feature maps of the input data. The dimen- sions of the convolution layers are 16x4, 32x4, and 48x4. The output layer is a linear function that obtains the continuous value. This is on a network that is trained to decrease the loss of function defined by the

The endocannabinoid system is made up of two main subtypes: CB1 and CB2 receptors. The first is commonly found in the central nervous system while the second is mainly concentrated in hematopoietic cells and the immune system. It has been proven that the first type of re- ceptor shows the potential to treat anxiety, drug addiction, and even motor control, while the second type of receptor has the potential to alleviate inflammatory pain, osteoporosis, and autoimmune disorders. This being said, the cannabinoid system can be diﬃcult to target when it is dispersed throughout the whole body. This is the reason why devel- oping small molecular drugs capable of targeting types of CB receptors is essential for the medical treatment of various diseases [114] (Figs. 9 and 10).

In order to target these cannabinoid receptors, a study utilized a deep convolutional generative adversarial Network (DCGAN) model for de novo designing target-specific compounds [114]. de novo is one of two strategies for identifying the compounds of a specific target. In this study, four types of targets, or fingerprints, were used to describe the small molecules with different structural features: ECFP6, MACCS, AtomPair Count, and AtomPair. A convolutional neural network (CNN) was the architecture for the deep learning model used in this study. It was first built using the four aforementioned types of targets as input data. Then it was applied to the discriminator of the DCGAN. Afterward, the generator was created through reverse convolution. This strategy minimizes the discriminative and generative loss simultaneously [114].

input with the label of zero. The discriminator chooses between these fingerprints and the authentic data which is labeled as one. The sec- ond step is minimizing the generative loss. Here the discriminator is not trainable and the generative loss is recorded to show how well the gen- erator fools the discriminator. The learning epochs were 50, 100, and 200, while the batch size was 128. When comparing the different CNN architectures, the LeNet-5-based architecture and the Atompair finger- prints performed the best. Based on the ROC curves, this duo attained the highest AUC score across each test set for both types of receptors, CB1 and CB2 [114]. This is the optimum combination using the first as the generation for the discriminator and the second as the input data. This strategy lets the machine produce fingerprints of a potential target- specific compound without any effort from the user.

The study does point out two concerns regarding the GAN architec- ture. The first challenge is to optimize both the discriminator and the generator simultaneously. However, this instability can lead to a gradi- ent favoring one over the other. This could result in an improved score for D, but not G, or vice versa. Secondly, there can only be a restrictive set of outcomes to be generated, also known as mode collapse. With the restrictive set, the generator can only produce one type of outcome or a small sample. Only a limited chemical space is to be covered as well as a lack of structural diversity.

In 2019, people realized how time consuming and expensive the tra- ditional drug discovery process was. On average, it takes about ten to fifteen years and billions of US dollars for a drug to reach the FDA, at which point it may be accepted or rejected. In drug discovery, drugs are created to find two specific proteins, which gives rise to the importance of a computational drug discovery system to protect the binding aﬃn- ity, also known as drug-target interaction prediction (DTI). The binding aﬃnity can be represented with multiple terms, some being the inhi- bition constant, the dissociation constant, changes in free energy mea- sures, half maximal inhibitory constant, half maximal activity concen- tration, KIBA score, and SCORES used in STITCH database [126].

This study proposes a DeepGLSTM model, using a graph convolu- tional network block to pass the drug compound data using power graph representation and bidirectional-LSTM to capture the topological infor- mation to achieve state-of-the-art results in the neural drug repurposing domain [126]. As many other papers have focused on one-dimensional CNN models, this model is LSTM since existing literature proves it per- forms better. Most GAN models convert drug compound data into string representations, which is not ideal for computational purposes. It may lead to the exclusion of topological information of the molecules them- selves, which causes a decrease in performance and power production. Deep-GLSTM consists of two functional models. One captures the topological information from the drug molecules while the second one captures the sequential information from the specific protein structure. It has been shown through previous papers that Graph DTA and DeepGS using graphical representation to embed the drug compounds and one- hot representation for protein structures improved the model perfor- mance and prediction [126]. This study continued with this idea by representing each drug compound by it’s related SMILES notation. This notation represents a compound as a graph of the interaction between each atom. A node feature was a set of atomic features adapted from DeepChem. A node represented a multi-dimensional binary feature vec-

tor. Each feature vector demonstrated five pieces of information includ- ing the atom symbol, the number of adjacent atoms, the implicit valence of the atom, the number of adjacent hydrogen’s, and whether that item is an aromatic structure. The SMILES data was later converted to a molec- ular graph representation which helped extract the required atomic fea- tures.

based off of the interaction of each node with its adjacent node [126]. This is why a GCN was used, due to the fact that it is strong enough to produce important feature representations, which are capable of cap- turing the connectedness relationship between nodes of the graph. This model consisted of three blocks. The first had a stack of three GCN layers. The second had a stack of two GCN layers. The final block had a sin- gle GCN layer. The first equation is the overcome degree normalization of the adjacent representation. The output is the normalized adjacency representation.

These strategies are also being implemented in the healthcare sector, where they have the potential to significantly improve precision and per- sonalized medicine [161] when combined with the drug development process. To further improve clinical trial outcomes and the process of deciding if a patient is qualified for a study, ML has been applied to Omics and EHR data [162] as well as other real-world biomarkers. A recent study, for instance, showed that deep neural networks (DNNs) are a highly competitive way for autonomously collecting useful infor- mation from electronic health data for the goal of disease detection and classification [163]. For prognosis prediction, research has shown that machine learning models embedded in EHRs can outperform more tra- ditional approaches. Applying machine learning to the data now being created by sensors and wearables can help us better understand the dis- ease and develop treatments, especially in neurosciences [164]. For ex- ample, Gkotsis et al. [165] classified mental health disorders using un- structured data from social media using DL algorithms. This is a diﬃcult problem for standard ML methods to solve.

The length of the protein sequence was set to one thousand for all datasets. The hidden vector representation of each layer was one hun- dred and twenty eight while the fixed number input mode features was seventy eight. The final hidden vector representation of the first block with set the three hundred and twelve. The dropout probability rate was set to 0.2. Due to the fact of it being a regression model, the mean squared error (MSE) was used as the loss function evaluation. Finally, all experiments were trained to one thousand epochs. The results sug- gested that the third block of the GCN contributed the most in model performance [126]. Most often, the structure of a drug dose does not consist of many shortest paths that exceed a distance of three or more, therefore it can be concluded that increasing the exponent to be on 3 would not lead to any significant changes.

The application of ML methods and the latest advancements in DL of- fers a multitude of potential to boost productivity throughout the drug research and development pipeline. As a consequence of this, in the coming years, we anticipate seeing an increase in the number of appli- cations within the industry that target clearly defined challenges. ML algorithms are going to systematically generate improved outputs, and new and interesting applications are expected to follow suit as a result of this. This is because the available data is getting “bigger,” at least in the sense of covering the relevant variability of the entire data space in a more comprehensive manner, and because computers are becoming increasingly more powerful. This has been demonstrated quite clearly in the sections that came before it. In those sections, we talked about some machine learning applications for target identification and validation, drug design and development, biomarker identification, and pathology

In any event, researchers should treat ML results as only hypotheses or intriguing jumping-off points for further investigation. Though comple- mentary tests validating the ML result will aid in establishing confidence in methodologies and outputs, regulatory bodies have not yet provided guidance on how they feel about ML’s lack of interpretability in clinical settings. The lack of interpretability of the approaches, however, makes it harder to debug these methods when they fail in unexpected ways on fresh, unexplored data sets, even if the trust issue is resolved.

Because ML outputs are largely dependent on the initial values or weights of the network parameters or even the order in which train- ing examples are presented to the network, all of which are normally chosen at random, repeatability is another key problem for neural net- works. Should we expect the network to consistently choose the same illness target when fed the same expression data? Would the medication structure always be the same that ML suggested? Various techniques have produced different prognostic biomarkers for breast cancer based on molecular expression characteristics [166], illustrating that this lack of repeatability is particularly troublesome for biomarker identification. The fact that several ML approaches can provide divergent outcomes raises doubts about the widespread use of these techniques. It has been suggested that there are ways to address both the interpretability and repeatability issues. It is common for these to include employing a more involved or time-consuming technique or averaging the output of mul- tiple network models, although this may be viewed as doing little more than adding yet another possible outcome to the pool (Tables 5 and 6). Large amounts of high-quality, accurate, and human-curated data for training and developing ML models are also vital to consider. The com- plexity of the data type and the question to be answered determines the requirements for the amounts and accuracy sought. As a result, the cost of creating these data sets can add up quickly. Possible approaches to satisfying these data needs include pre-competitive consortia of phar- maceutical corporations and academic institutions employing suitable data standards and equipped with the requisite operational and open

data frameworks. Drug discovery relies on a wide variety of data kinds, many of which are far from exhaustive. One example is that not all protein folds and structures are fully understood, and the data space is only partially covered. Therefore, even if significant progress has been made, applications in which these structures are projected are not yet as good as in other fields. For small molecule synthesis, where the com- plete chemical space is unknown, this holds true as well for reaction prediction.

Data curation is essential for sharing information that may be used again, yet it can be costly due to the expertise and time involved. There is a fine line between the computational abilities and in-depth biological and domain experience needed for the task of biological curation, which entails extracting biological material from the scientific literature and integrating it into a database.114 Increased access to high-quality data already available in the public domain may be possible through coor- dinated efforts to create common data resources and metadata (labels). Metadata from unsuccessful as well as successful drug discovery initia- tives are included since they can be used to build techniques to predict and identify aspects that can help lower attrition rates. Large data re- sources of company bioactive data sets of experimental substances and historical clinical trial data require significantly greater pre-competitive collaboration.

Another area where ML models fall short is in making predictions about new paradigms. ML models can only make predictions within the constraints of the training data, as this is the very foundation of the field. For instance, in medicinal chemistry, classical approaches are likely nec- essary for the design of molecules with different modes of action such as macrocycles, protein–protein interaction inhibitors, or PROTACs.

Machine learning (ML) algorithms, particularly DL techniques, have made AI practical for use in business and daily life. The analysis of omics and imaging data, in particular, has seen the immediate effects of ML approaches’ expansion into the drug research and healthcare sectors. Speech recognition, natural language processing, computer vision, and other applications have all seen success with ML algorithms. Among the most frequent examples of such devices are Internet-connected “smart assistants,” which may now routinely relay health-related infor- mation through the transmission of voice recordings and visuals. Med- ical decision-making on therapeutic benefits, clinical biomarkers, and adverse effects may be greatly aided by ML techniques applied to data acquired from such a conglomeration of Internet-enabled technologies combined with biological data.

Searching chemical space for required functions can be greatly aided by generative machine learning models like GANs. It is diﬃcult to fore- tell the binding aﬃnity between medication and its target during the drug discovery process. The labeled data upon which supervised systems rely is both costly and challenging to acquire on a large scale, making these approaches impractical for widespread use. We discuss how GANs can be used to train representations from raw sequence data of proteins and medicines, and how convolutional regression can be used to predict the aﬃnity.

concerns about the veracity and reproducibility of findings. As a means of avoiding potential pitfalls, understanding the current state-of-the-art of research reproducibility in computational drug discovery is crucial. This will guarantee that the underlying work is of high quality and will withstand the reproduction of the described methodology by the exter- nal research group. In this overview, we looked at the various methods

like a snowball. Policies enacted in recent years by funding agencies and publishers favor data and code sharing, which is further facili- tated by third-party platforms (e.g. Authorea, Code Ocean, Jupyter note- book, Manuscripts.io, etc.) that further enhance reproducibility by trans- forming online manuscripts and codes from static files waiting to be downloaded into “living” codes and documents that can be dynamically edited and executed in real-time.

In conclusion, we have tried to describe the wide variety of prob- lems encountered by the predictive modeling community as it performs its mission to create and distribute effective and trustworthy computa- tional tools for the pharmaceutical industry. Evidence presented herein demonstrates the importance of close collaboration among researchers working at the front lines of drug discovery, those responsible for in- termediate data modeling, and the administrators and programmers in the back oﬃces. There has to be a better knowledge of these concerns and a shared terminology in order to optimize their impact, yet these groups encounter challenges that are very distinct in nature. Given the scope of the disciplines at play, this is no easy feat. Data modelers, tool developers, and administrators should keep in mind that their tools will be used by front-line scientists in a constantly changing work environ- ment, as we point out. Due to its fluid nature, it may not always align with the recommendations of the data science community (i.e. due to ever-changing needs).

Therefore, it’s important to recognize that model developer may disagree with the developer community on the best approach. For in- stance, while user-derived descriptors (such as experimental data or non-standard 3D computational models) could be ideal, they can be challenging to include swiftly into QSAR models. On the other hand, it is possible that interpretability is more important than raw predictive performance when choosing a predictive model. Because selection re- quirements are typically driven by statistical considerations rather than the needs of the end user, the latter types of models may not exist in automated solutions in now prevalent modeling workflows.

Transparency in implementations and easy access to validate the analyses are both benefits of open source. It might be challenging to maintain track of the various analysis tools and settings while dealing with data and modeling. As a result, drug discovery workflow solutions are becoming increasingly popular. They aid in producing more trust- worthy multi-step computations, as well as in establishing a trail of ev- idence and making results easy to reproduce. Common Workflow Lan- guage is one example of an initiative seeking to standardize and promote interoperability among workflow specification languages.

The usage of public or shared computing infrastructures (HPC/Cloud) is necessitated by the ever-increasing amounts of data, but this introduces a new layer of complexity for computational reproducibility. The usage of virtual machines and software containers has made it possible for all data analysis tools to be used across differ- ent platforms. High levels of automation and, by extension, increased repeatability, are possible when workflow systems are integrated with the container and virtual machine infrastructure. For example, when deploying models as networked services, virtual infrastructure and containers allow for more dependable and reproducible service delivery.

Yang D, Xiong T, Xu D, Huang Q, Liu D, Zhou SK, Xu Z, Park J, Chen M, Tran TD, et al. Automatic vertebra labeling in large-scale 3D CT using deep image-to-image network with message passing and sparsity regularization. In: International con- ference on information processing in medical imaging. Springer; 2017. p. 633–44.

Ledig C, Theis L, Huszár F, Caballero J, Cunningham A, Acosta A, Aitken A, Te- jani A, Totz J, Wang Z, et al. Photo-realistic single image super-resolution using a generative adversarial network. In: Proceedings of the IEEE conference on com- puter vision and pattern recognition; 2017. p. 4681–90.

