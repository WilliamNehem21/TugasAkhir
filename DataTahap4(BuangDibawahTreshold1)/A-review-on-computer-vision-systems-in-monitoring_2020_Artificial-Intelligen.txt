This study will present a brief discussion on some of the popular DL architectures, i.e., Convolutional Neural Networks (CNNs), Recurrent and Recursive Neural Networks, and Pretrained Unsupervised Net- works. Generally, each architecture has a specific appropriate area of ap- plication, and some are already pre-trained to provide accurate classification in particular domains (Kamilaris and Prenafeta-Boldú, 2018; Pan and Yang, 2010). The popular platforms for development

ResNets, also known as Deep Residual Networks, presented a solu- tion to solve complex problems in CNNs as the network becomes deeper (vanishing gradients) (Balduzzi et al., 2017). ResNet consists of a series of residual modules (layers), and each layer is a function set to be per- formed on an input with the gradient signal capable of feedback to ear- lier layers via shortcut connections (Balduzzi et al., 2017; He et al., 2016;

Kawaguchi and Bengio, 2019). ResNets have the advantages of being more accurate and require less weight in some cases and being highly modular. Additionally, they can be designed to determine how deep a network can be. The main disadvantages of ResNets are that for a deeper network, the detection of errors becomes difficult. Additionally, if the network is too shallow, the learning might be very inefficient.

The Xception stands for extreme inception. Consider that in a tradi- tional convolutional network, convolutional layers seek out correlations across both depth and space. While in Inception, a 1 × 1 convolution is used to project an original input into numerous separate, smaller input spaces. From each input space, different types of filters are applied to manipulate those smaller 3D blocks of data. However, in Xception, in- stead of partitioning the input data into several compressed primitives, the spatial correlations for each output channel is mapped separately, then performs a 1 × 1 depth-wise convolution to capture cross- channel correlations (Chollet, 2017). This operation can be referred to as depth-wise-separable-convolution, i.e., spatial convolution done in- dependently for each channel, followed by a point-wise convolution (1 × 1 convolution across channels) (Chollet, 2017).

and Zisserman, 2014). The MobileNet is essentially a rationalized ver- sion of the Xception architecture optimized for mobile applications. The SqueezeNet is powerful DL architecture that's efficient in low band- width platforms. It is based on a CNN architecture but with 50 times fewer parameters than AlexNet and maintains AlexNet-level accuracy on ImageNet (Iandola et al., 2016). The CapsNet, a multi-layer capsule system, is an advanced variation of CNNs that deepens in terms of nesting or internal structure (Sabour et al., 2017). It's mainly used for accurate image recognition tasks because it is robust to geometric dis- tortions and transformations. Thus, it can exceptionally handle orienta- tions, rotations, and translations.

Recursive neural networks have a return loop to feed the network into itself. This allows for the identification of input data constituents and their relationships through a binary tree structure and shared- weight matrix (Hosseini et al., 2020). Recursive neural networks are characterized by a top-down propagation method and a bottom-up feed-forward method. There are two main types of Recursive neural networks, i.e., supervised recursive neural tensor (applied in computer vision) and the semi-supervised recursive autoencoder (applied in sen- tence deconstruction). The main advantage of Recursive neural net- works over RNNs is that they can capture long-term dependencies efficiently. However, Recursive neural networks suffer from substantial

The LSTM is a special RNN that applies recurrent edges as a solution to the vanishing gradient problem. LSTM use memory cell to hold infor- mation and a set of gates (input, forget, and output gates) to indicate the status of the memory cell (Sundermeyer et al., 2015, 2012). The con- tents of the memory cell are modified by the input and forget gates con- ditions at each time step. The input gate selects the new information that should be added to the cell state. The forget gate selects which in- formation should be discarded from the cell state. The output state se- lects relevant information from the cell state as the output.

PUNs are DL models whose hidden layers are trained by unsuper- vised learning to achieve an accurate fitting of the dataset. The layers are trained (unsupervised learning algorithm) independently sequen- tially, such that the input of a layer is the previously trained layer. The whole model is then fine-tuned using supervised learning after each layer has been pre-trained. Types of PUNs include Generative Adversar- ial Networks (GAN), Autoencoder, and Deep Belief Networks (DBNs).

GANs involve the training of two DL models (the generator and the discriminator) simultaneously that compete with each other. The gen- erator creates new instances by modeling a transform function during training. In comparison, the discriminator classifies if an instance origi- nates from the generator or the training data, while the former maxi- mizes the final classification error while the later minimizes the error between the generated data and the training data. Thus, the two net- works are referred to as adversaries. Hence, the whole network im- proves with each iteration during training. GANs are widely applied in computer vision, especially in image generation and also in speech, prose, and music because of GANs ability to mimic any distribution of data in any domain (Hosseini et al., 2020).

GANs have the advantage that it requires no deterministic bias, un- like the variational encoders, they allow for efficient training of models in a semi-supervised setting. However, the main drawbacks of GANs are that the performance of the generator and discriminator are crucial in the success of GAN, and the whole model fails if one system (generator and discriminator) fails. Additionally, training GAN is computationally expensive with high training time due to the two-model training.

DBNs are an extensive layered network structured by connecting several smaller unsupervised neural networks. A DBM is composed of Belief Net and the Restricted Boltzmann Machine (RBM) (Hosseini et al., 2020). Belief Net is composed of connected layers (binary unit layers), each assigned a weight function (layer-by-layer learning). The

probability of the binary outcome depends on the weight factor and the bias inputs. RBM is a stochastic RNN designed on the principles of energy-based models (EBMs) (Haque and Neubert, 2020; Hosseini et al., 2020). Learning is performed by minimization of the energy func- tion, and prediction is achieved by determining the values of residual variables that minimize the energy based on observed variables. The RBM consists of one input layer and one hidden layer without an output layer. Another type of RBM is the Deep Boltzmann Machine (DBM), characterized by undirected connections. Hence, DBM is robust in han- dling certainty due to noisy inputs.

Image pre-processing is performed before the image is fed as an input to the DL model. Image resizing is the most common image pre- processing procedure for the image to adapt to the DL model require- ments. In the deep regression network (AlexNet and ReLU activation function), Fang et al. (2020) resized the input image to 960 × 540 from 1920 × 1080 resolution. Similarly, Zhuang and Zhang (2019) per- formed a resizing operation to have a 512 × 512 input image resolution. In a comparative analysis between Faster R-CNN and YOLO v3 in recog- nition and classification of broiler droppings, Wang et al. (2019b) resized images from 5760 × 3240 resolution.

Data labeling which involve the creation of bounding boxes is an- other vital pre-processing procedure. Data labeling is often performed manually to reference the ground truth by a bounding box. Labeling software such as LabelImg (Windows-based) is applied to draw the bounding boxes and extract their co-ordinate locations. Ground truth labeling is a vital step in classification tasks as it provides a basis for per- formance evaluation of the proposed detector (Zhuang and Zhang, 2019). The procedures mentioned above are the main techniques that have been applied in poultry monitoring DL modeling systems. Other pre-processing operations include image segmentation to highlight the ROI hence, facilitating the learning process as performed by Fang

DL models need a lot of training data to achieve an appropriate con- vergence for better recognition accuracy while at the same time, avoiding over-fitting. Therefore, data augmentation technique is per- formed to expand the training data by a dynamic transformation of the data without changing their classification. If k is the number of aug- mentation techniques applied, then the total number of images used in training will be (k + 1)-fold of the original dataset. Additionally, the image transformation effectively increases the training set without the need to store a large augmented training set. Table 8 presents the data augmentation techniques applied in the DL data processing.

Several studies have applied DL models in poultry monitoring sys- tems ranging from behavior classification, tracking, sick birds' detection, to droppings classification. Pu et al. (2018) developed a CNN detector to classify chicken flock behaviors at the feeders using color and depth im- ages (two parameter-sharing CNNs). His network consisted of three convolutional layers, each with a rectified linear unit (ReLU) activation function, a max-pooling layer with a local response normalization step. The system achieved an accuracy of 99.17% in the chicken behavior classification. A Faster R-CNN chicken activity detector combined with the temperature-humidity index (THI) was used to monitor heat stress in chicken (Lin et al., 2018). The detector applied the Zeiler and Fergus network (Zeiler and Fergus, 2014) as the base CNN. The chicken move- ment was determined by tracking the chicken location between subse- quent frames using the minimum distance matching and color feature matching techniques. As already mentioned, the detection speed of

normalization (LRN) layer and a pooling layer for max-pooling between the 1st and 2nd layer and between the 2nd and 3rd layers effectively prevents overfitting. This technique achieved a mixed tracking perfor- mance evaluation of 0.730 at a processing speed of 30.53 fps.

studies have applied other modeling techniques. The transfer function (TF) represents the relationship between the input and the output sig- nals of a control system for all possible input values. The parameters of a TF model can be estimated using several estimation techniques such as least squares (LS), state variable filters approach, instrument variable approach, generalized Poisson moment functions approach, etc. However, due to noise, the model parameters become asymptoti- cally biased when LS is applied. Therefore, Leroy et al. (2006) applied a simplified refined instrumental variable (SRIV) to estimate TF model parameters from an optimal shape posture parameters (ellipse shape

tioned, feature extraction engineering is an arduous task. Therefore, Zaninelli et al. (2018) performed bird recognition from a shape classifi- cation point of view. A normalized cross-correlation was performed be- tween a processed image and a template to detect multiple nest

was no simple association between acceleration and velocity, kinematic features with a bird's GS. Therefore, Nääs et al. (2018) allowed for con- tradictions within a degree of certainty in the estimation of broiler chicken GS using the kinematic features by applying inconsistency- tolerant, Paraconsistent logic.

Several studies have introduced chicken weighing systems based on computer vision based on 2D (Amraei et al., 2017b; De Wet et al., 2003; Mollah et al., 2010) and 3D (Mortensen et al., 2016) images. The basic principle of machine vision-based weighing systems is the correlation of image object shape geometric features to animal weight or volume. This is theoretically simple but quite challenging in a real farm environ- ment. As already mentioned, firstly, the bird's body must be segmented from the background (ROI extraction). Secondly, the chicken's body segmented from the image is to be presented by describing characteris- tics (feature extraction). Thirdly, these describing characteristics are correlated to the bodyweight by a mathematical model.

Poultry weight estimation systems are mainly challenged by varia- tion of ambient lighting conditions and the localization of a bird when in a flock condition. To address the problem of variable light conditions, the solution would be the use of illuminant invariant cameras and flex- ible image sensors in the farm environment. IR-based depth cameras such as the Microsoft Kinect have been applied in weight estimation by Mortensen et al. (2016). However, IR depth cameras are sensitive to sunlight, thus, limiting their application to an indoor environment. However, illuminant invariant visual light-based cameras (Jansen-van Vuuren et al., 2016) are readily available in the market they haven't been applied in poultry monitoring systems. Providing a controlled lighting environment for visual light-based sensors can be another solu- tion, although it's challenging if not infeasible due to farm structure, size, and other complexities. Therefore, the potential research and de- velopment area could be to provide a controlled illumination in the farm environment for image acquisition in farmhouses and the use of il- luminant invariant cameras.

drance to lameness detection systems in birds. Additionally, as much as kinematic posture trackers have yielded positive results, more re- search should be undertaken in the development of automated body position trackers without the use of markers (non-intrusive and non- invasive systems). Moreover, the applicable camera position in a real farm environment is still a challenge. Overhead camera positions are most preferred, i.e., non-invasive. Aydin (2017a) and Aydin (2017b) ap- plied overhead depth and RGB images, respectively. However, as al- ready mentioned, IR depth sensors are susceptible to sunlight, hence, limited to indoor applications or would limit the operation time of the system if it is installed in an outdoor environment. Additionally, RGB cameras are associated with visual light-based sensor errors.

Furthermore, these experiments were conducted in a controlled en- vironment, whereby the birds' movements were restricted. Therefore, further research should focus on lameness detection of chickens in a flock setting such that occlusion problems and dynamic movements are considered. Lastly, lameness in chicken is affected by several factors. However, the easiest to control from a stockman perspective are the en- vironmental factors such as illumination, bedding, ventilation, and stocking density. Therefore, more research should focus on the opti- mum environmental conditions for chicken regarding lameness.

According to Welfare-Quality® (2009), the health condition of a bird is a vital indicator of good welfare practice. The term being healthy can be characterized by the absence of a disease, whereby disease is any condition that causes a deviation from normal activities and functions. Poultry disease occurs due to the interaction between the birds, the en- vironment, and the infection agent (non-infectious and infectious). In- fectious agents include viruses, bacteria, fungi, and parasites, while non-infectious agents include chemical and physical toxins and

Tracking of poultry is an essential parameter in the assessment of be- havioral (types of activities) and physical (lameness and health) indica- tors in poultry welfare. There is a need to automatically record the behavior and movement of birds continuously for welfare monitoring purpose and behavior phenotyping. Noldus and Jansen (2004) catego- rized automated video tracking systems as analog and digital video tracking systems. Analog systems detected high peaks in the voltage of a video signal, i.e., regions of high contrast between the bird and

background. However, these systems could only track one bird in a ded- icated experiment set up unit with restricted illumination and back- ground conditions. Digital systems allowed for pattern recognition techniques to be applied to image frames for the quantitative measure- ment of the birds. However, this system is limited by the computational speed and the complexity of the underlying software.

The discipline that is closely related to animal welfare is the animal behavior and is considered as behavioral indicators in welfare assess- ment. In a good welfare condition, the animals should be able to express their natural behavior patterns due to no or minimal stress. However, studies have reported the difficulty in differentiating between standard physiological stress and productive indicators of stress, and at times contradicted each other (Marıa et al., 2004). Additionally, sampling techniques or direct observation are invasive despite being the initial point for the development, validation, and implementation of non- invasive automated behavioral systems. Nevertheless, several poultry

behavior detection systems with illumination invariancy, factors in the background complexity, overlapping, and occlusion problems. The ap- plication of improved YOLO v3 has solved these problems, referred to as the YOLO v3-dense model (Tian et al., 2019), whereby DenseNet is used to process feature layers with compromised images (low resolu- tion, occluded objects). Similarly, the speed and performance of the real-time YOLO v3 system can be improved by extending the detection scale and down-sampling of feature fusion target detection layer (Ju et al., 2019). The mentioned improvements haven't been applied in chicken monitoring CNN-based systems. Therefore, more research should be performed to improve the performance of real-time detection models.

Animal activity is highly associated with behavior levels, GS, and health. In computer vision systems, activity is measured as percentage pixel change over the total area coverage over a period of time, i.e., the higher the activity levels, the higher the difference in pixel values. EthoVision XT and eYeNamic are software that can directly

tribution monitoring at drinking and feeding areas (Guo et al., 2020), ef- fect of feeder types (Neves et al., 2015), type of light illuminance (Kristensen et al., 2007), backpack (Stadig et al., 2018) on bird's behav- ior have also been presented regarding activity and behavior monitor- ing. However, animal behavior is a complex bio-response to both internal and external stimuli. Therefore, more research should be di- rected towards the drivers of behavioral responses such as pen con- struction designs and materials and structures inside the pen as well as health and micro-environment.

Much success has been achieved in animal monitoring systems. However, there exist several challenging factors for real farm applica- tions (occlusion, lighting condition, etc.). Several studies have presented possible solutions. These studies presented good results in dedicated environments, hence, compromised a robustness and generalization ability of these systems. DL approaches have great potential. However, they require a vast amount of labeled dataset as an image dataset with ground truth annotations, and samples are of great significance in model development and for testing of algorithms.

Generally, appropriate image processing algorithms in computer vi- sion are essential for the poultry monitoring in the farm environment for precise localization of birds. This will be pivotal in the monitoring of several bioprocesses and bio-responses and also provide a solution to occlusion problems. Even though several challenges still exist, more researches are being performed to improve the monitoring systems in poultry.

