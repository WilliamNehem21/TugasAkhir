Hence, this study aimed to develop cotton segmentation algorithms for natural illumination conditions such that with single threshold value in an algorithm, cotton boll can be detected in morning, afternoon or evening time with minimum errors and evaluate them based on image processing time and segmentation accuracy. For this, four new methods of cotton segmentation were introduced in addition to other existing methods (Jin-shuai et al., 2011; Li et al., 2020; Li et al., 2016a; Wang et al., 2008) which can be used for cotton harvesting robots to recognize cotton bolls. After analyzing four color spaces, RGB and YCbCr color spaces were used for cotton segmentation in natural light conditions, optimum thresholds were selected and morphological opening and closing operations were performed to remove noises and holes in the segmented binary image. The performance of proposed algorithms was evaluated in terms of hits rate, false positive, false neg- ative, processing time, sensitivity, specificity, and accuracy.

The cotton bolls can be detected easily based on their color features. The commonly popular color space models for feature segmentation from color images includes the RGB (Lurstwut and Pornpanomchai, 2017; Tewari et al., 2020), the HSV (Yang et al., 2015), the L*a*b (Hu

et al., 2015; Zhao et al., 2016a), and the YCbCr (Jin-shuai et al., 2011) color models. The selection of a proper color space model is very crucial for the successful detection of the particular object from the given color images. In past, various researchers have implemented different color

In this study, two-color space models, i.e., RGB and YCbCr were se- lected and further utilized for developing in-field cotton detection algo- rithms. In past, many researchers used RGB (Bulanon et al., 2002b; Ji et al., 2016; Xiang et al., 2011; Xu and Ying, 2004; Zhao et al., 2005) and YCbCr (Moallem et al., 2017; Sabzi et al., 2020, 2017) color space models to extract the region of interest using color thresholding seg- mentation in different agricultural applications. A total of four image processing algorithms were developed, out of which, three algorithms

Where, T is the threshold value of chromatic aberration, and f (x, y) is the value of the pixel (x, y) in the final binary image obtained after im- plementation of the color thresholding technique. In the binary image, the white color portion (the pixel value is 1) represents the cotton bolls, and the black color portion (the pixel value is 0) represents the back- ground, i.e., stem and leaves.

The selection of appropriate threshold values is very crucial for proper segmentation of input images and successful recognition of the cotton bolls using the proposed algorithms. In past, many researchers used various threshold methods for the segmentation of region of inter- est from an image (Bulanon et al., 2002b; Hamuda et al., 2017; Hu et al., 2015; Ireri et al., 2019; Montalvo et al., 2013; Singh, 2019; Tsai and Tseng, 2012; Vitzrabin and Edan, 2016; Yang et al., 2015). In this study, the color thresholding method was applied to segment images and recognize cotton bolls.

Ground truth images are the ones in which regions of interest (ROI) are segmented using a more accurate method as compare to propose method. Hu et al. (2015) compared their proposed automatic segmen- tation algorithm for bananas with the manually segmented bananas re- gion, which acts as ground truth in their study. Tsai and Tseng (2012) compared the accuracy of their proposed color detection method with the traditional color detection method based on HSL color space. Bachche and Oka (2013) obtained ground truth distance data by manu- ally measuring the distance for the accuracy testing of depth coordinate in their study.

In this study, two approaches were used to evaluate the perfor- mance of the proposed algorithms. In the first approach, true detected cotton (TDC), false detected cotton (FDC), and missed cotton (MC) were counted. True detected cotton (TDC) indicates an object in the seg- mented image which is recognized as cotton boll when it is a cotton boll.

Where TP is the cotton's pixels predicted by the algorithm correctly. TN is the background's pixels predicated by the algorithm correctly. FP is the background's pixels predicted by the algorithm incorrectly as cot- ton's pixels. And, FN is the cotton's pixels predicted by algorithm incor- rectly as background's pixels.

