As transductive inference makes full use of the distribution information of unlabeled samples, so compared with traditional inductive inference, it is always more precise. For the question that transductive support vector machine algorithm (TSVM) is with a low classification precision and an unstable learning performance, in this paper, a transductive support vector machine algorithm based on spectral clustering (TSVMSC) is proposed. Firstly, the algorithm utilizes spectral clustering algorithm to divide the unlabeled samples into several clusters, then labels them with the same class, finally makes transductive inference on the mixed data set composed by both labeled and unlabeled samples. It is not necessary to estimate the ration of the positive samples to the negative samples, so the stability can be improved largely. Meanwhile, the prior distribution information of the unlabeled samples can further be extracted, so the classification precision can be improved effectively. The experiments show that TSVMSC exhibits a superiority over TSVM both at the stable performance and classification precision.

and it is the most practical and youngest part. Currently SVM develops constantly. Although traditional SVM can deal with high-dimensional, non-linear and small sample data set, it solves a more complex problem in the classification process of finite samples. Thus it obeyed the following basic principle that when we solved a given problem, we should avoid to solve a more general problem in the middle process. Based on this idea, Vapnic proposed a transductive thought (Gammerman et al., 1998) and present a transductive support vector machine algorithm which can improve the performance of classifier effectively.

This article is a further study on transductive learning, trying to find a more common transductive learning algorithm than the existing methods. According to the inherent characteristics of support vector machine classification, this article design a transductive support vector machine algorithm based on spectral clustering (Shi and Malik, 2000). The present classifier first uses spectral clustering to cluster the similar non-label samples based on the good results of spectral clustering. Then it marks all the samples in the same cluster with the same label. Finally the classifier uses transductive learning method to do classification. As this method uses spectral clustering to mine the effective priori distribution information of the unlabeled samples, so it can effectively improving the performance of the transductive support vector machine algorithm.

Section 2 introduces the idea of transductive learning and described the transductive support vector machine classification algorithm presented by Joachims (Joachims, 1999). Based on the characteristics of traditional support vector machine classifiers and the good result of spectral clustering, we present a transductive support vector machine learning algorithm based on spectral clustering and give the detailed processes of the algorithm. In Section 4, we give the experimental results and make a detailed analysis. In Section 5, we conclude the whole paper and point out that further research directions and ideas.

In general, the exact solution of this problem requires a search of 2k cases in sample set, which is an NP problem. For a small number of samples, this process can be completed. For a large number of unlabeled samples, however, it is necessary to use a variety of approximate optimization algorithm to obtain the solution. Currently, the most important outcome in this respect is Transductive Support Vector Machine (TSVM)

Step 3: Retrain the support vector machine over all the examples. For the newly yielded classifier, switch labels of one pair of different-labeled unlabeled examples using a certain rule to make the value of the objective function in (1) decrease as much as possible. This step is repeated until no pair of examples satisfying the switching condition is found.

TSVM algorithm uses a simple method to estimate the value of N, which is to estimate the proportion of samples with positive labels to all the unlabeled samples according to the proportion of samples with positive labels to all the labeled samples. However, when the number of samples with labels is small, the method is difficult to estimate a more accurate value of N. Once the pre-set value of N is quite different from the actual number of samples with positive labels, the performance of the TSVM algorithm will become very unstable, and moreover the classification accuracy of the algorithm can not be assured effectively.

The basic though of TSVMSC is as follows. First of all, cluster the similar unlabeled sample effectively according to the good clustering performance of spectral clustering. Then mark all the samples in the same cluster with the same label. Finally learn with transductive support vector machine on all the labeled and unlabeled samples, which is to find a solution of optimization problem (1). Below we present the detailed steps of TSVMSC.

In order to test the performance of TSVMSC proposed in this paper, we make an experiment on the Reuters newswire data sets, the Reuters-21578. The dataset comes from Reuters newswire in 1987, which is a typical text classification dataset (Joachims, 2001). Our experimental data is obtained by adapting Joachimsâ€™s pre- treated data set.

In all experiments, the training set is composed by 5 positive labeled samples and 5 negative labeled samples. For TSVM algorithm, select different number of unlabeled samples to test the performance of TSVM algorithm in different data distributions of unlabeled samples. For TSVMSC algorithm, set k=3,5,7 in the spectral clustering algorithm. In all the experiments, we use the same test set that contains 300 positive labeled samples and 300 negative labeled samples. Table 1 shows the learning results of TSVM algorithm and TSVMSC algorithm when k=5, and Table 2 shows the learning results of TSVMSC algorithm when k=3,5,7, respectively.

Table 1 shows that the TSVM algorithm is not very stable, because for TSVM algorithm the number of positive labeled samples, N, in the unlabeled samples set must be artificially specified. However, the value N is often difficult to make a reasonable estimate. If N is estimated accurately, the accuracy of the TSVM algorithm is relatively high, but if N is not estimated very accurately, the performance of the algorithm can be greatly affected. However TSVMSC algorithm does not need to estimate the values of N, so the stability of TSVMSC algorithm is greatly improved compared to TSVM algorithm. As TSVMSC algorithm uses spectral clustering algorithm to cluster similar samples, and marks them with the same label, so actually this algorithm use the priori distribution information of unlabeled samples effectively, so the algorithm can reach a higher level accuracy.

It can be shown from Table 2 that with the increase of k, the running time of TSVMSC algorithm becomes longer, which is very easy to understand as the transductive support vector machine learning algorithm needs to solve the optimization problem (1). With the increase of k, the accuracy of TSVMSC algorithm on the test set can be increased. This is mainly because the optimization problem can be solved more accurately with the increase of k, so the generalization ability of the algorithm is increased, and correspondingly the accuracy on the test set can be improved.

The algorithm avoids initially estimating the ratio of positive labeled samples and negative labeled samples in the unlabeled sample set. Moreover, the spectral clustering algorithm can mine the priori distribution information of the unlabeled samples effectively. The experimental results show that TSVMSC algorithm can achieve a good effect on stability and accuracy.

This project is supported by the National Natural Science Foundation of China (Nos. 60873037,61073041,61073043), the Natural Science Foundation of Heilongjiang Province of China (No. F200901), Harbin Outstanding Academic Leader Foundation of Heilongjiang Province of China (No. 2011RFXXG015), and Specialized Research Fund for the Doctoral Program of Higher Education of China (No. 20112304110011).

