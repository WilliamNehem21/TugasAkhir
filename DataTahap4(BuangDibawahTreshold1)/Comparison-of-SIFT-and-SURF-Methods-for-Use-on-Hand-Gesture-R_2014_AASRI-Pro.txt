In this paper a comparison between two popular feature extraction methods is presented. Scale-invariant feature transform (or SIFT) is the first method. The Speeded up robust features (or SURF) is presented as second. These two methods are tested on set of depth maps. Ten defined gestures of left hand are in these depth maps. The Microsoft Kinect camera is used for capturing the images [1]. The Support vector machine (or SVM) is used as classification method. The results are accuracy of SVM prediction on selected images.

Gesture recognition is one of the directions in the non verbal machine-human communication. Non verbal communication can be useful in many life situations (e.i. in situations where human can’t use speech). Several methods were publicized on topic of gesture recognition [2][3][4]. Many of them focus on feature extraction from color image of hand and classification as next step. For this, it is important to get the most accurate

feature vectors. The most common used local visual descriptors are SIFT and SURF [5]. The theory about these descriptors as well as experiment description is presented in first chapter of this paper. The results of this experiment are shown next and conclusion at last.

In this experiment the database of depth images is created. SIFT and SURF are applied on images of this database. Resulted feature vectors are divided in to train set and test set. For creation of SVM model the train set is used in process called training. Next the test set is used for prediction. Results are prediction accuracies of all tested images for SIFT and SURF.

Scale invariant feature transform is one of the mostly used local visual descriptors. The method works in two steps. Detection of feature point as the first step. Feature description as the second step. At the beginning of procedure the computing of gradient magnitudes and orientations of pixels are computed. This is done in neighborhood of key point by using the scale of the point. This will make choice on what Gaussian kernel will be used for blur the image. Feature vector is combination computed from the orientation of histograms within the sub-regions around the feature point. The feature vector is normalized at least. For more information about SIFT see [6].

Where L is the convolution of the Gaussian second order derivation of image at point X(x,y) in scale σ and similarly for Lxy and Lyy. For the classification the maxim and minim of the function the discriminant value is used. The description starts by constructing the window around detected feature point. Orientation of the window is same as reproducible orientation. From pixel in this region the resulted feature vector is calculated. For more information about SURF see [7].

Support vector machine as part of the model based classifiers uses model for prediction. This model is created in procedure called training. Model represents each class as pattern in vector space. Each feature vector is represented as point in feature space. In Fig. 1 only two dimensions are shown for simplicity. Class A is represented as pattern of gray dots in fig and class B as green dots.

Separation line is searched in training process. The wider gap between two closes point to line the better train process. It is seen on fig that line p2 represents better train process as line p1 because the gap of line p2 the v2 is bigger as gap v1 of line p1. If two patterns can’t be linearly separated, the kernel method is used. This will transform vector in to higher dimension space in which they are separable. This process will allow classification of multiple classes [mata6]. In this experiment the RBF kernel method is used. For more information about SVM see [8].

Capturing the color image of hand, its followed segmentation can take significant calculation time as well as processing power. Some methods for segmentation aim for color of skin, as to detect the region of hand. Results of such process can vary by the light condition or color tone of a particular person. Microsoft Kinect camera has the advantage that it uses infrared spectrum of light. As such it is invariant to light conditions and color of skin. Kinect system can track parts of detected human body.

Table 1 contains performance matrix for descriptor SIFT and Table 2 contains data for descriptor SURF. Each field in this matrix contains the sum of pictures of class represented by its column number, to be recognized as class represented by row number. For example, in Table 1 for row 8, that is for input images of class 8, two pictures were wrong recognized as pictures of class 1 and forty-eight pictures were recognized as pictures of class 8.

From results it is clear that the invariance to rotation of SIFT descriptor is a disadvantage here. Some hand gestures, mainly 1 and 5, wave similar shape and occurs as one, only in different orientation. For human mind it is clear that gesture represented by class 1 has different interpretation that of class 5. Another major error occurs for class 7 and 2. On both pictures the shape of hand is not the same but it is very similar shape.

For SURF (table 2) the results are similar to the SIFT method. The error occurs in classes with too similar shape, such as pictures of class 2 and class 7. Another error occurs for classes with the same shape but with rotation as pictures of class 4 and class 10.

