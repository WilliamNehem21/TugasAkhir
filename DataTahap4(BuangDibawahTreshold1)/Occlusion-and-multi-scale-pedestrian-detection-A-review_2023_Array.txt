Pedestrian detection has a wide range of application prospects in many fields such as unmanned driving, intelligent monitoring, robot, etc., and has always been a hot issue in the field of computer vision. In recent years, with the development of deep learning and the proposal of many large pedestrian data sets, pedestrian detection technology has also made great progress, and the detection accuracy and detection speed have been significantly improved. However, the performance of the most advanced pedestrian detection methods is still far behind that of human beings, especially when there is occlusion and scale change, the detection accuracy decreases signif- icantly. Occlusion and scale problems are the key problems to be solved in pedestrian detection. The purpose of this paper is to discuss the research progress of pedestrian detection. Firstly, this paper explores the research

calculates the confidence of all bounding boxes in the regression. At the same time, multiple convolution layers with different scales are gener- ated in the convolution layer to detect multi-scale objects and improve the detection accuracy. Ross Girshick et al. [20] introduced Convolu- tional Neural Network (CNN) into the field of object detection for the first time in 2014, and proposed R-CNN by combining CNN with tradi- tional machine learning methods. R-CNN uses selective search to obtain as many pre-selected boxes as possible, uses CNN network to extract features instead of manually designed features for the first time, and uses multiple SVM classifiers for classification and regression. Then in 2015, Ross Girshick [21] designed a Region Proposal Network (RPN) to replace the selective search in R-CNN, and selected Softmax classifier to replace multiple SVM classifiers, which greatly improved the detection performance. With the rapid development of deep learning technology, many researchers have proposed many detection methods with better performance, such as Faster RCNN [22], MSCNN [23], YOLOv4 [24], CSP [25], SAF-RCNN [26] and other methods based on R-CNN. Although hand-designed features are effective in simple cases, their generalization ability is weak and it is difficult to obtain high-level se- mantic information. Deep features obtain feature representations based on the learning of a large number of samples, which can be learned end-to-end, with strong robustness and better generalization ability. In recent years, pedestrian detection has gradually evolved from hand-crafted features to deep features.

Multiple gestures of pedestrian object: Pedestrian objects are both rigid and flexible and pedestrians may present a wide variety of postures, such as stationary, standing, squatting, bending, or walking. In addition, the appearance of pedestrians are all dressed differently, in various colors and styles. These variations pose a great challenge to current pedestrian detection. How to design a pedestrian detection method that is not affected by changes in pedestrian posture and clothing appearance is a challenge that needs to be solved for pedestrian detection nowadays.

Weather and low-lighting: Rain, snow, fog, haze, dust storms and other phenomena seriously reduce the clarity of photos, the reduced visibility of the pedestrian object and the blurred con- tours severely limit the performance of pedestrian detection. At night when the light intensity is low, the pedestrian images have higher gray values, lack of color information, and increased interference information. Also low light conditions generally use infrared images, which have low resolution, contain less pedes- trian information, and have blurred pedestrian object outlines. These problems seriously affect the accuracy of pedestrian detection. How to solve the problem of pedestrian object

Occlusion: Occlusion in pedestrian detection is divided into two main categories: One is intra-class occlusion between pedes- trians, and the other is inter-class occlusion of pedestrian objects by other objects. The mutual occlusion between pedestrians brings a lot of interference information, which may lead to false detection and affects detection performance. When the pedes- trian object is obscured by other objects, the structure of the pedestrian is incomplete and the information of the pedestrian object is missing, which can easily produce missed detection and reduce the accuracy of pedestrian detection.

Multi-scale pedestrian: Different distances of pedestrian objects from the camera will bring different spatial scales of pedestrians, there may be multiple pedestrians at different scales in the same image. This has caused a significant negative impact on pedes- trian detection. Large-scale pedestrians have richer information for better detection. But small-scale pedestrians tend to have lower pixels, blurred appearance and contours, contain less valid information, which easily misses detection and seriously affects the accuracy of pedestrian detection. It is a great challenge to accurately detect pedestrian objects at different scales.

Real-time detection: The application of pedestrian detection in automatic driving, intelligent monitoring, etc. has high re- quirements for detection speed and needs to be able to detect in real time. With the development of deep learning, the pedestrian detection model is becoming more and more complex. While the detection accuracy is improved, it also brings a lot of calculations, which reduces the detection speed of pedestrian detection. How to achieve real-time detection while improving the accuracy of pedestrian detection is a great challenge in the field of pedestrian detection.

Faced with many challenges, pedestrian detection, although a cate- gory of general object detection, can still be studied as an independent problem. In recent years, in order to improve the detection accuracy and detection speed of pedestrian detection, researchers have proposed many new detection methods with better performance. This paper dis- cusses and explores the research status of pedestrian detection from 2019 to 2022, summarizes commonly used pedestrian data sets and evaluation indicators, and focuses on the analysis of occlusion and scale problems and corresponding solutions of pedestrian detection.

Although the earliest hand-made features such as HOG, Hear, LBP and LUV are no longer so excellent with the development of pedestrian detection technology, they also provide ideas and innovative inspiration for later researchers. Over the past 19 years, researchers have designed many new feature descriptors with better performance. Wenshu Li [30] et al. designed eHOG feature by enhancing the contrast of HOG feature in order to balance the speed and accuracy of pedestrian detection. Ritesh Kumar Mishra [31] reduces the redundant information of HSG by adding a feature selection module to reduce the feature size and improve the calculation speed. Ming Yang [32]et al. proposed a Feature

[41] et al. proposed F-CSP network. F-CSP introduces FPN and BFP to improve the original feature fusion module. FPN can reduce the number of channels of the feature map, and BFP fuses multiple feature maps into a feature map, reducing other parameters. Based on the original YOLOv3 network model, Jingwei Cao [42] et al. improved the multi-scale bounding box prediction based on receptive field and introduced the Soft-NMS algorithm, which improved the performance of the detection algorithm in various complex scenes. Haohui Lv [43] et al. proposed YOLOv5-AC based on YOLOv5s, introduced L1 regularization in BN layer to remove networks with small impact factors to reduce model size and improve speed, introduced CEM module to extract more features and used two attention modules CxAM and CnAM to filter useless fea- tures. Correct the position offset to improve the accuracy. Wei Liu [44] et al. designed the Progressive Localization Fitting (ALF) module, which

uses a series of predictors to gradually convolutional evolve the default anchor box of SSD. Residual learning and multi-scale context coding are combined to improve the accuracy of localization and enhance the prediction ability. Mahmoud Saeidi [45] et al. designed a DM-PPP pedestrian detection model based on the estimation of different parts. The improved SSD is used to generate initial candidates and expand the region with safety boundaries, and the pedestrian proposal is divided into nine parts and evaluated independently. Chintakindi Balaram

(MRGAN) to generate high-resolution images from low-resolution im- ages for multi-resolution pedestrian detection, introducing a novel perceptual loss. Peijia Yu [53] et al. performed quality assessment by fusing multi-channel visual features and proposed a new reduction Adjustment module (RA). RA can improve the connection between feature channels and enhance the features with less information. Zebin Lin [54] et al. proposed an example Guided Contrastive learning (EGCL) model, which learns a feature transformation module through contras- tive learning, projects the initial feature space into a new feature space, minimizes the semantic distance between pedestrians to eliminate the appearance diversity of pedestrians, and maximizes the semantic dis- tance between pedestrians and the background. Han Xie [55] et al. designed a deformable convolution with an attention module to sample from non-rigid locations and extract attention feature maps with context information.

The Caltech dataset was published by Caltech in 2009. It is mainly captured by a car camera running normally in a regular traffic scene. The video is about 10 h long and has about 250 k frames, which contains 350,000 bounding boxes and 2300 pedestrian annotations. And the annotations include bounding boxes and correspondences for different occlusion levels.

Average precision AP is one of the commonly used indicators in the detection field. Generally, the performance of the model is dynamically evaluated by plotting the Precious-Recall(P-R) curve, where the abscissa is the recall rate and the ordinate is the accuracy rate. Their calculations can be shown in (1) and (2). Where TP (True Positive) predicts positive samples and the prediction is correct. The closer this metric is to the annotated number of pedestrians in the validation set, the higher detection rate of the detector is indicated. FP (False Positive) predicts a positive sample but is wrong. This index reflects the false detection rate, and the lower the false detection rate, the better. FN (False Negative) The prediction result is negative samples but the prediction result is wrong, this index reflects the missed detection rate, the smaller the

The log-average Miss Rate(MR) is an indicator to describe the miss rate in the detection results. False Positive Per Image(FPPI) describes the average false detection rate per image. Their calculations can be shown in (5) and (6). The MR-FPPI curve is similar to the P-R curve used for

local receptive field, the convolution is replaced by dilated convolution and the step size of the convolution is reduced in the backbone of FPN. Chen Zhang [66] et al. proposed a multi-scale pedestrian detector. The detector fuses pooled features with different resolutions and context information in the fully connected layer to make full use of their unique

The attention mechanism can find the correlation between the original data and highlight some important features. The introduction of the attention mechanism in pedestrian detection can better fuse different features and improve the robustness of pedestrian detection at different scales. In 2019, Zhichang Chen [68] et al. believed that the competitive attention module can be used to improve the hard negative samples and multi-scale problems of pedestrian detection, and the competitive attention module helps the network architecture to obtain

blocks to obtain more mutual information between features, and in- troduces a feature aggregation module to combine high-level features and low-level features. Yuzhe He [83] et al. proposed a multi-scale feature balance enhancement network. The network extends a bottom-up short-circuit path to improve the utilization of low-level feature information, designs a feature balance module to obtain the same amount of semantic information from different resolutions, and uses a feature enhancement module to expand the receptive field to retain more information. The method proposed by REN J makes good

Zhou is not effective for small-scale pedestrian detection with height less than 40 pixels. The method proposed by Yanwei Pang only considers the similarity between reconstructed pedestrians and large-scale pedes- trians, and ignores the dissimilarity between reconstructed background and large-scale pedestrians. The method proposed by Jialian Wu is a general component, which can be effectively applied to other detectors with backbone networks.

Some researchers have improved the robustness of multi-scale pedestrian detection through multi-scale detection. In 2021, Hexiang Zhang [88] et al. proposed YOLOv3-Z based on the Retinex algorithm and the improved YOLOv3 algorithm. The Retinex algorithm is used as a preprocessing algorithm to improve the brightness and contrast of pe- destrians, and the YOLOv3 algorithm is improved by adding multiple scale detection. In 2022, Chintakindi Balaram Murthy [89] et al. pro- posed a lightweight real-time detection algorithm (EfficientLiteSet), which introduced a three-scale transformer prediction head (TPH) in Tiny-YOLOv4 to replace the original detection head, which could

correspond to certain body parts, and the occlusion situation can be represented as a specific combination of body parts. Therefore, a channel attention mechanism was designed to obtain a more efficient representation of occluded pedestrians. In 2022, Jiali Ding [98] et al. proposed a head-aware pedestrian detection network (HAPNet) based on the structural relationship between the human body and the head. HAPNet detects both the head and the body of pedestrians, and proposes a head-side affinity module to represent the association between the head and the body. Ameen Abdelmutalab [99] et al. proposed a multi-branch pedestrian detection algorithm (MB-CSP), which used four

Some researchers use context information to supplement the features of occluded pedestrians to better represent occluded pedestrians and improve the robustness of occluded pedestrian detection. In 2019, Chi Fei [100] et al. proposed Context-aware feature Learning (CAFL). CAFL uses the pixel-level context embedding module to integrate the context information of multiple surrounding regions into the feature layer, improving the discrimination ability of the detector and enhancing the robustness to occlusion. Wittawin Susutti [101] et al. believe that local information is as important as global information, and propose a multi-channel pedestrian detection method based on appearance. The complete image is divided into multiple regions, and the features of each region are extracted and analyzed. ACF and uLBP features are used to hierarchically combine to represent pedestrians. In 2020, Zhaoqing Li

[102] et al. proposed the SCN model by combining segmentation ideas and context information. SCN uses segmentation to obtain pedestrian contours to generate more accurate pedestrian information and uses LSTM for information exchange. Sheping Zhai [103] et al. proposed FCF R-CNN, which adopts a progressive cascade strategy in the backbone network to extract features from different layers for fusion, and the feature information of shallow layers is utilized. A multi-layer LSTM module is also designed to extract the global context information of the

image. In 2022, Hangzhi Jiang [104] et al. proposed the SMPD pedes- trian detector, designed a semantic integration module, independently of the CSP detector, used the semantic context of urban scenes for detection, and fused the output of CSP detector and semantic integration module as the final detection result. Zhenxing Liu [105] et al. proposed a global context-aware feature extraction module, which can combine context information with local and global pedestrian characteristics. At the same time, a visual feature enhancement module was designed to introduce unblocked upper body information into the network to

can be improved by enhancing features, so that the detector can detect the occlusion form more easily. Some researchers enhance the occluded pedestrian features by feature fusion. In 2020, the feature learning model CircleNet proposed by Tianliang Zhang [110] et al., uses multiple top-down and bottom-up paths to reciprocally fuse features. The top-down path can strengthen semantic information and the bottom-up path can expand the receptive field and combine contextual informa- tion. And the instance decomposition training strategy is used to detect pedestrian instances with different occlusions in each cycle. In 2021,

Some other researchers enhance occluded pedestrian features by attention and improving feature extraction networks. In 2020, Ruihong Yin [116] et al. proposed the DA-Net network. In order to better deal with occlusion and highlight the unoccluded part of the pedestrian, DA-Net uses CWAM to weight each channel feature, and uses GAM to supplement the global information for the occluded part. Tengtao Zou

[117] et al. proposed an Attention Guided Neural network model (AGNN) to deal with occlusion. AGNN is actually a pedestrian classifi- cation model, and the most important thing is that the attention guid- ance network weights the local features to enhance the features. In 2021, Xiaotao Shao [118] et al. proposed an occluded pedestrian detection algorithm (MFPN). MFPN designs a new feature extraction network DFR, which can effectively enhance the semantic information and con- tour of occluded pedestrians while reducing the computational complexity. Jin Xie [119] et al. introduced a Local Spatial Co-occurrence (PSC) module based on Faster R-CNN. The PSC module can obtain the intra-part and inter-part spatial co-occurrence of different body parts through  graph  convolution  to  enhance  the  body  part  feature

problem. The first center prediction branch downweights the occluded part around the center of the occluded pedestrian according to the de- gree of occlusion. The second center prediction branch integrates the pedestrian occlusion ratio into the Gaussian mask of center ground truth. Zhuowei Wang [129] et al. proposed a multi-branch detection network based on triggered attention (MBDN). MBDN predicts the center points of the upper, middle and lower pedestrian respectively

In addition to the methods introduced in the previous sections, some other researchers have proposed new occluded pedestrian detection methods. In 2019, some researchers generated saliency maps to elimi- nate background interference on occluded pedestrians to improve detection accuracy. Inyong Yun [130] et al. used saliency and bounding box alignment for pedestrian detection. The model uses saliency to eliminate false positives such as trees, knots FCN and CAM to improve the resolution of the confidence map and successfully recall missing body parts. Wei Wei [131] et al. used MobileNet for detection and positioning to balance detection speed and detection accuracy, intro- duced binocular depth information to reduce the influence of clutters,

Dollar P, Tu Z, Perona P, et al. Integral channel features. In: Proceedings of the 2009 20th British machine vision conference, BMVC 2009, september 7, 2009 - september 10, 2009,. London, United kingdom, F: British Machine Vision Association, BMVA; 2009 [C].

Redmon J, Divvala S, Girshick R, et al. You only look once: unified, real-time object detection. In: Proceedings of the 29th IEEE conference on computer vision and pattern recognition, CVPR 2016, June 26, 2016 - July 1, 2016, Las Vegas, NV, United States, F. IEEE Computer Society; 2016 [C].

Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation. In: Proceedings of the 27th IEEE conference on computer vision and pattern recognition, CVPR 2014, June 23, 2014 - June 28, 2014, columbus, OH, United States, F. IEEE Computer Society; 2014 [C].

Geiger A, Lenz P, Urtasun R. Are we ready for autonomous driving? the KITTI vision benchmark suite. In: Proceedings of the 2012 IEEE conference on computer vision and pattern recognition, CVPR 2012, June 16, 2012 - June 21, 2012, providence, RI, United States, F. IEEE Computer Society; 2012 [C].

Zhang S, Benenson R, Schiele B. CityPersons: a diverse dataset for pedestrian detection. In: Proceedings of the 30th IEEE conference on computer vision and pattern recognition, CVPR 2017, July 21, 2017 - July 26, 2017, Honolulu, HI, United States, F. Institute of Electrical and Electronics Engineers Inc; 2017 [C].

Li W, Ruan M, Guo X, et al. A novel architecture of pedestrian detection. In: Proceedings of the IEEE int conf on parallel and Distributed processing with applications, big data and cloud computing, sustainable computing and communications, social computing and networking (ISPA/BDCloud/SocialCom/ SustainCom), Xiamen, PEOPLES R China, F Dec 16-18; 2019 [C].

Overett G, Petersson L, Brewer N, et al. A new pedestrian dataset for supervised learning; proceedings of the 2008 IEEE Intelligent Vehicles Symposium, IV, June 4, 2008 - June 6, 2008. Eindhoven, Netherlands, F: Institute of Electrical and Electronics Engineers Inc; 2008 [C].

Ess A, Leibe B, Van Gool L. Depth and appearance for mobile scene analysis. In: Proceedings of the 2007 IEEE 11th international conference on computer vision, ICCV, October 14, 2007 - October 21, 2007, Rio de Janeiro, Brazil, F. Institute of Electrical and Electronics Engineers Inc; 2007 [C].

Wang J, Li H, Yin S, et al. Research on improved pedestrian detection algorithm based on convolutional neural network. In: Proceedings of the IEEE int congr on cybermat/12th IEEE int conf on cyber, phys and social comp (CPSCom)/15th IEEE int conf on green computing and communications (GreenCom)/12th IEEE int conf on internet of things (iThings)/5th IEEE int conf on smart data, Atlanta, GA, F Jul 14-17; 2019 [C].

