Abstract Designing an efficient Distributed Database System (DDBS) is considered as one of the most challenging problems because of multiple interdependent factors which are affecting its perfor- mance. Allocation and fragmentation are two processes which their efficiency and correctness influ- ence the performance of DDBS. Therefore, efficient data fragmentation and allocation of fragments across the network sites are considered as an important research area in distributed database design. This paper presents an approach which simultaneously fragments data vertically and allocates the fragments to appropriate sites across the network. Bond Energy Algorithm (BEA) is applied with a better affinity measure that improves the generated clusters of attributes. The algorithm simultane- ously generates clusters of attributes, calculates the cost of allocating each cluster to each site and allocates each cluster to the most appropriate site. Results show more efficient clustering and allo- cation which gives better performance.

Allocation. Fragmentation tries to split data into fragments, which should be allocated to sites over the network in the allo- cation stage. The process of fragmentation falls into two cate- gories: Vertical Fragmentation and Horizontal Fragmentation. Vertical Fragmentation (VF) is partitioning relation R into disjoint sets of smaller relations while Horizon- tal Fragmentation (HF) is partitioning relation R into disjoint tuples. The allocation problem involves finding the optimal distribution of fragmentation to set F on site set S. There are four data allocation strategies applicable in a distributed rela- tional database: centralized, fragmentation (partition), full replication, and partial replication (selective) [10]. When data is allocated, it might either be replicated or maintained as a single copy. So, fragment allocation can be either non- redundant or redundant. Under a non-redundant allocation

There are two general approaches toward solving the parti- tioning problem. One is to find the efficient solution by consid- ering some of the constraints. In Hoffer [13] the storage capacity and retrieval cost constraints are the role factors. Each of these factors is weighted based on their amount of effect. The objective was to minimize the value of overall cost. The weights are calculated using linear programming approach so that the sum of the weights is equal to 1.

[6] is a methodology for the design of distributed object data- bases that includes an analysis phase to indicate the most ade- quate fragmentation technique, a horizontal class fragmentation algorithm, and a vertical class fragmentation algorithm. The analysis phase is responsible for driving the choice between the horizontal and the vertical partitioning techniques, or even the combination of both, in order to assist distribution designers in the fragmentation phase of object databases. Baiao et al. [8] presents a three phased methodology for the design of distributed database that contains analysis phase, horizontal fragmentation algorithm phase, and vertical class fragmentation phase. The method illustrated in Abuelya- man [7] experimentally shows that moving an attribute that is

Allocation and fragmentation are interdependent problems where solving them simultaneously is difficult but results in bet- ter performance of applications. To the best of our knowledge, BEA is not applied to simultaneous fragmentation and alloca- tion. Since in vertical partitioning attributes which are usually accessed together are placed in one fragment, defining a precise measure of togetherness is critical. BEA uses affinity of attri- butes to create clusters of attributes, which are the most similar. It starts with Attribute Usage (AU) and Query Access (QA) matrices generates Attribute Affinity matrix (AFF) and finally creates Clustered Affinity matrix (CA) by positioning and re- positioning columns and rows of attributes. The affinity mea- sure is too simple. The proposed affinity measure in BEA is basi- cally based on simultaneous access of attribute Ai and attribute

After generating AFF using the described affinity measure, clusters of attributes are created using the split function. The Split(AFF) takes as input the AFF matrix, permutes its rows and columns, and generates a CA matrix. The permutation is done in such a way to maximize the following global measure.

is the number of columns already placed in CA and try to place them in the remaining i + 1 positions in the CA. Choose the placement that makes the greatest contribution to the global affinity measure described above. Continue this until no more columns remain to be placed.

Since the clustering result of BEA is the split border between two sets of attributes, BEA does not work efficiently for larger databases. Therefore, we need a better approach to identify more partitioning candidates. As we infer similarity of two attributes when they have concurrent occurrence in a query, concurrent absence of them for the same query could also be considered as a weighted measure of similarity. Fur-

database play a key role in the performance of a distributed DB. Distance Matrix (DM) is the asymmetric square matrix that reflects these costs which can be minimized using the method described in Bentley and Dittman [25]. Multiplying DM in QA generates a new matrix in which the influence of communication costs between sites and query access per site is considered simultaneously and since DM is minimized dis- tance matrix then the resulted matrix will be the Minimized Query Access (MQA) matrix.

and n10 have less positive effect on similarity in comparison to n11. Furthermore, it can be inferred that w1 should be greater than w2. The approaches to calculate the value of each weight are dependent on the structure and definition of the table and their relations in the database. Gower and Legendre measure [11] and Rogers and Tanimoto measure [22] are some methods to calculate values of weights. Each of the weights is calculated considering the structure and definition of the data- base and queries. The structure of the database gives us some information regarding to the relations of different attributes.

The variable coef in the denominator is reflecting the effect of n01 and n10. There are four different possibilities. When n01 > 0 and n10 = 0, it indicates that for two attributes of Ai and Aj, all queries which access Ai do not access Aj. This

means that these attributes have some level of similarity. As a result the Sij should get greater values so the weighted mea- sure in the denominator, w2, should be negative. This is shown in Lines 12 and 13 of Algorithm 2. The same is for the case in

and n10 are greater than 0. This condition means Ai and Aj do not have the same behavior upon different queries which are accessing them. This has negative effect on the similarity, so the weighted measure in the denominator, w2, should be positive. This is shown in Line 15. After calculating the AFF matrix, the algorithm calls the split function which we described in Section 2 and creates clusters of attribute.

In order to estimate the amount of improvement and correct- ness of our algorithm, we applied both the classic BEA and our algorithm on database of Terminal Management System (TMS). TMS is a server which is connected to stores’ (or super- markets’) terminal with a unique serial number. Depending on the terminal it can download or update terminal information or operating system. Since stores are located in different places, TMS can obviously work better with distributed data- base. Each terminal has a unique serial number, one task is defined for each terminal group. These tasks contain one or more files which can be associated to a group of terminals. Each Terminal, group of terminal and task has one table. A simple schema of tables and their relations is illustrated in Fig. 4. After reviewing the transactions, eight most frequent transactions and considering the relations of tables in TMS, eight attributes (illustrated in Table 2) for distributing in seven sites were selected.

The AU, QA, and DM matrices are as shown in Figs. 1–3. The query access input for both algorithms were MQA. The weights w1 and w2 in our algorithm were set to 0.7 and 0.3, respectively. The resulted clustering tree for each algorithm is shown in Fig. 5. As it can be observed, both algorithms behave the same until the fourth iteration. The classic BEA separates attribute number 2 and puts attributes number 3, 4, 1, and 7 in a cluster. On the other hand the modified algorithm separates attribute number 4 and clusters attributes number 2, 1, 3, and

7. Considering the conditions applied in our algorithm, the coef and Sij are calculated and illustrated in Table 3. It is obvi- ous that A4 is less similar to other attributes than A2 therefore it has been separated correctly. We can conclude that the new algorithm considers better measure and clusters the attributes much better.

Distributed databases reduce cost of update and retrieval of information and increase performance and availability, but the design of DDBMS is more complicated than designing cen- tralized database. One of the major challenges which greatly affects DDBS performance is fragmentation and allocation of fragments to sites. Allocation and fragmentation can logi- cally be merged and done simultaneously. In this paper we proposed a method that merges vertical fragmentation and allocation. To achieve this goal we applied Bond Energy Algo- rithm with a modified affinity measure in a hierarchical process and simultaneously calculated the cost of data allocation for each site and assigned fragment to the appropriate site. The use of the hierarchical process resulted in clustering sets of more similar attributes and better data fragmentation. On the other hand, by performing simultaneous cost calculation we took interdependency of data fragmentation and allocation into account.

