/ig. 12. (Table D) A text-based PDF page in our testbench with potentially problematic columns highlighted with boxes (red). (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)

precision and recall in the specific way mandated by ICDAR. For every cell within a table, ‘‘adjacency relations’’ defined by ICDAR, are found with its nearest horizontal and vertical neighbors. In order to get precision and recall, the adjacency relations are compared with the ground truth. Precision and recall are computed for each document then the average is taken across all the documents.

To compare Tablext to the other papers, the same method to cal- culate precision and recall is used. It should be noted that both Deep- DeSRT and TableNet fine tune their networks by training on the re- maining ICDAR dataset. In order to prove its ability to extract data from tables in general formats, Tablext does not use any ICDAR data to train with. The results comparing the different methods can be found in Table 3. Tablext has both the highest precision and overall F1-Score out of the methods.

/ig. 13. (Table D) Tablext’s final output in CSV format. Boxes (red) are showing the correct handling of problematic cells. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)

/ig. 14. (Table D) Tabula’s final output in CSV format. Boxes (red) are showing the incorrect handling of problematic cells. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)

output. Both have a high accuracy when reproducing the cells’ contents, though Tabula is simply reading text provided to it, while Tablext is using OCR. One issue with the Tablext output is that Tesseract appears to not recognize the plus–minus character. Tabula also did not perfectly print the data within the cells, despite reading straight from the PDF. The minus character could not be recognized by Tabula. This problem appears because this PDF is using an abnormal character instead of the standard ASCII symbol.

Several severe structural errors appear in Tabula’s output and these errors have been highlighted in Fig. 14. Looking back at the original image in Fig. 12, it becomes clear what caused these errors. The cells ‘‘A Grade’’ and ‘‘B Grade’’ overlap both the columns beginning with ‘‘Typ’’ and ‘‘Max’’. Errors like this are common for conventional text-based extractors [30]. Tablext meanwhile, with its dynamic threshold ratio, easily separates these two columns then merges the split ‘‘A Grade’’ and ‘‘B Grade’’ cells back into a single cell.

The highlighted cells in Fig. 14 emphasize the importance of ac- curate cell location identification. Even with clever post-processing, it would be impossible to tell which column the merged cells with a single piece of data belong to. For instance, looking at the row beginning with ‘‘Transition noise’’, there is no way to know if the data belongs to the ‘‘Typ’’ or ‘‘Max’’ column.

This paper introduces a novel, general approach for table extraction. By utilizing both deep learning and computer vision techniques, the neural network can focus its attention on complex problems, while allowing more conventional methods to handle the simpler tasks. This focus allows Tablext to beat competing state-of-the-art neural-network- based table extraction methods as well as a popular open-source tool that requires table meta-data.

This material is based on research sponsored by Air Force Re- search Laboratory (AFRL), United States and Defense Advanced Re- search Projects Agency (DARPA), United States under agreement num- ber FA8650-18-2-7844. The U.S. Government is authorized to repro- duce and distribute reprints for Governmental purposes notwithstand- ing any copyright notation thereon.

Schreiber S, Agne S, Wolf I, Dengel A, Ahmed S. Deepdesrt: Deep learning for detection and structure recognition of tables in document images. In: 2017 14th IAPR international conference on document analysis and recognition (ICDAR), Vol. 1. IEEE; 2017, p. 1162–7.

Technology (SUT), Tehran, Iran, in 2017. He Also received the M.S. degree in electrical engineering and computer science in 2020 from University of Michigan, Ann Arbor, MI. He is currently working toward the Ph.D. degree at University of Michigan, Ann Arbor, MI. His research interests include circuit design automation, machine learning, software development and computer architecture.

Zineb Benameur-El Youbi received the B.Sc. and M.S degree in Computer Networks and Multimedia Communication from the University of Grenoble, France, in 2009. She Also received the M.S. degree in Computer Science and Engineering in 2020 from University of Michigan, Ann Arbor, MI. Her research interests include reliable software development and Machine Learning.

Shuyan Yu was born in Shenzhen, China, in 1999. She received the B.Sc. major degree in computer science and in mathematics from University of Michigan, Ann Arbor, MI, in 2020. She is currently working toward the M.S. degree in computer and information sciences at University of Pennsylvania, PA. Her research interests include data mining, natural language processing, information extraction and machine learning.

Ronald Dreslinski received the BSE degrees both in electrical engineering and com- puter engineering, and the MSE and PhD degrees in computer science and engineering from the University of Michigan, Ann Arbor, Michigan. He is currently an assistant professor of computer science and engineering with the University of Michigan. His research focuses on architectures that enable emerging low-power circuit techniques.

