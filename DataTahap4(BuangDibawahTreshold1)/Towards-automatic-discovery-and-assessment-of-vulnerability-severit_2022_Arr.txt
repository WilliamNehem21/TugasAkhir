NVD builds upon the information included in CVE entries to pro- vide an enhanced information for each entry, such as severity scores (calculated based on CVSS standard) and impact ratings. NVD converts the unstructured CVE data into structured JSON (or JavaScript Object Notation) or XML (or Extensible Markup Language) formats [6]. As part of its enhanced information, NVD also provides advanced searching features such as by OS, by vendor name, by product name, by version number, and by vulnerability type and severity. Among these extra fea- tures, affected product names and versions have matching string entries in CPE entries. Vulnerability category features are provided in Common Weakness Enumeration (CWE) [32] repository, which abstracts the observed faults and flaws into common groups of vulnerabilities with additional information about expected effects, behaviors, and further implementation details. The vulnerability severity score is calculated following the CVSS version 3 and version 2 standards.

SecurityFocus is a widely used vulnerability database and also features a security news portal [13]. Even though this database is shut down in January 2021, still its historical reports are applicable to validate our experimental analysis. Besides vulnerability descriptions, SecurityFocus also addresses whether a vulnerability has a PoC exploit. Note that SecurityFocus is not dependent upon CVE data sources [23]. Actually, a BugTraq vulnerability report may refer to several CVE vulnerability instances. A statistic analysis by Fang et al. highlight that although the amount of vulnerabilities reported in SecurityFocus is less than the number of vulnerabilities found in NVD, the fraction of exploited vulnerabilities in SecurityFocus (37.008%) is much higher than the proportion in NVD (6.676%) [13]. They also observe that the vulnerability reports in SecurityFocus contain higher coverage and more reference significance in predictive cybersecurity analysis, lead- ing to their experiment results where SecurityFocus performs well than NVD under an actual environment.

tively. NVD assigns CVSS V3 base scores 9.8, 8.8, and 7.7 to these three disclosed vulnerabilities. Yet, ICS-CERT and the vendor Siemens [34] assign the same CVSS V3 base scores to CVE-2019-6581 and CVE- 2019-6582, but a different score 8.8 to CVE-2019-6580. The inconsis- tency of CVE-2019-6580 scores is due to different views on the metric of whether privileges are required to exploit this vulnerability. Here we compare the discussion section in SecurityFocus and the descrip- tion section of one vulnerability instance CVE-2019-6580 in NVD or CVE. We observe that the summary given by SecurityFocus highlights vulnerability types and potential threats targeting the vulnerability, while NVD emphasizes the affected products and the impact of the vulnerability.

SecurityFocus discussion: “Siemens Siveillance VMS is prone to multiple authorization-bypass vulnerabilities. Attackers can exploit these issues to bypass certain security restrictions and perform certain unauthorized actions. This may aid in further attacks. These issues have been fixed in Siveillance VMS 2017 R2 v11.2a, 2018 R1 v12.1a, 2018 R2 v12.2a, 2018 R3 v12.3a, and 2019 R1 v13.1a.”

has been identified in Siveillance VMS 2017 R2 (All versions < • NVD description (the same as CVE description): “A vulnerability V11.2a), Siveillance VMS 2018 R1 (All versions < V12.1a), Siveil- lance VMS 2018 R2 (All versions < V12.2a), Siveillance VMS 2018 R3 (All versions < V12.3a), Siveillance VMS 2019 R1 (All versions

Finally, Shodan is a data source mainly targeting CPS or IoT (refer- ring to Internet of Things) security, including SCADA (referring to Su- pervisory Control and Data Acquisition) [35]. CPS and IoT systems in- clude devices like webcams, routers, and servers. Relevant information like ports and vulnerabilities of these devices can be fetched through Shodan website or Shodan API (referring to Application Programming Interface). Interestingly, these are currently internet-connected devices, sending (public) live data from different locations across the World. Unlike NVD, where vulnerability reports are published, Shodan crawls IP addresses, made available on device respective websites and APIs. Returned data from Shodan can be cross-referenced with NVD for vulnerability analysis [36].

The Forum for Incident Response and Security Teams or FIRST initiated the development of the CVSS calculator while reporting cy- bersecurity incidents. The current CVSS Version 3 follows a sequence of three versions of the CVSS index calculator. Vulnerabilities are first assigned a unique identifier and their severity is rated by combining CVSS property metrics. CVSS score involves three groups of proper- ties. The Base group describe static properties that are not subject to temporal or deployment environments. In contrast, the Temporal and Environmental groups of properties are respectively describing score variations across time or deployment contexts. However, we emphasize base score properties in this research and consider the latest version of CVSS base properties, that is Version 3 or V3. These base properties are further grouped under three classifications, namely exploitability

This can be illustrated briefly by the vulnerability instance CVE- 2021-37172 for example. This vulnerability instance affects Siemens PLC (or Programmable Logic-Controller) product running SIMATIC S7- 1200 CPU family with firmware version number 4.5.0 (or the vulner- able component), by allowing a threat agent to bypass authentication and download arbitrary programs to this PLC (or the vulnerable CPS asset). This vulnerability has a CVSS version 3 base score of 7.5, which is further composed of an exploitability score of 3.9 as well as an impact score of 3.6.

This property quantifies the likelihood as well as the effort and intri- cacy to be invested for exploiting a component that would be exposed to a given vulnerability. Hence, this property combines the following metrics: AttackVector (AV), AttackComplexity (AC), PrivilegesRequired (PR) and UserInteraction (UI). The Attack Vector metric measures the likelihood for an attack scenario targeting the component to occur through this vulnerability. The effort that needs to be invested may vary across these scenarios, quantified as part of the Attack Complexity met- ric. Along the path of an attack scenario, some credentials or privileges may be required. The level of these requirements is measured by the Privileges Required metric, for an agent with authority to be granted access to the component. And, the level of participation that is expected in order to exploit and compromised the vulnerable component is measured by the User Interaction metric.

Relying upon NVD scores alone as the model training ground can bring bias in vulnerability assessment [6,7]. This is because a small percentage of score records in NVD is assumed to have errors due to the manual scoring process [12]. Besides statistical vulnerability patterns mined from CVE reports, other data sources like vendors and third- party security analyzers (e.g., ICS CERT and MSRC) provide different perspectives for vulnerability scoring. We set up a majority voting [37] module using Python whereby the score that the majority of data

The classification of CVSS measurements into class labels calibrates severity scores from property attributes. A high label of AttackComplex- ity (AC) for example, pertains to the attribute value of 0.44, and 0.77 attribute score pertains to low label. These numerical values are use in the CVSS calculation process.

are marked as REJECT are removed from further consideration. A cor- pus of CVSS V2 reports is set up by excluding reports that are not scored under CVSS V2. 148 803 vulnerability reports are subsequently filtered out, which are then correlated against trusted sources of data like ICS- CERT(asserted by cybersecurity experts). Manufacturer data sources are also used to resolve disparate scores. The proposed ML model uses these scores as ground truths for training purposes. Following the same approach, reports that are not rated under CVSS V3 are taken out to set up 75 265 instances of CVSS V3 corpus data. CVSS V3 scored reports are fewer from 2015 and earlier, with a total of 4 958 reports.

Python package pipeline in Scikit-learn library has been used to implement the machine-learning pipeline including features extrac- tion and other data processes. Severity scores from different CVSS versions are thus transformed in a streamlined way. Processing NVD vulnerability reports’ data starts from tokenisation and subsequent feature extractions using CountVectorizer [46] and TdidfTransforer [47] utilities. Subsequently, TF–IDF (referring to Term Frequency–Inverse Document Frequency) values are calculated, to generate a TF–IDF ma- trix from word features. Train_test_split procedure is used to randomly divide data records into training (75%) and testing (25%) datasets, following a random distribution.

Machine learning classifiers classify new vulnerability reports within predicted severity patterns. The results obtained from our case studies use LogisticRegression (LR) classifier, besides a 5-fold stratified cross- validation applied to the CVSS training dataset to reduce overfitting occurrences. CVSS classifier prediction performances for the testing datasets are illustrated in Table 1. CVSS V3 metric classifications reach an overall higher performance than CVSS V2 counterparts. However, the larger set of metrics offsets the CVSS V3 error rate.

In this validation experiment, we crawl vulnerability reports from SecurityFocus and map the reports to the corresponding CVE indexes. This step is done in December 2020, before SecurityFocus’s shut down in January 2021. Yet, our proposed methods are still valid in the aspect that utilizing multiple vulnerability data sources enriches the features and may enhance the performance of the classification models. These external descriptive reports are added as text features together with NVD reports for model training. The results are also listed in Table 1. We observe that by adding more text features, the performance of our CVSS scorer improves.

Vulnerabilities in CPS infrastructure are assessed to enumerate and rank their severity to prevent threat-induced anomalies, or intrusion attempts [1,2]. Here we present a vulnerability analysis case study of several prominent CPS components. This case study is composed of three main steps. First, we query and filter CPS relevant vulnerabilities from online cybersecurity data sources. Then, we compute the CVSS V3 base scores and corresponding vectors for retrieved vulnerability instances. Finally, we perform an analysis to explore the statistical patterns of existing CPS vulnerabilities.

We evaluate our streamlined vulnerability-severity scoring mech- anism through vulnerability analysis practices on several prominent CPSs such as PLCs, RTUs (or Remote Terminal Units), MTUs (or Master Terminal Units) and HMIs (or Human Machine Interfaces). A PLC is a crucial CPS asset that controls industrial devices to keep production processes in order. A RTU transmits telemetry data from sensing devices that are associated with physical power components to a MTU system. Finally, a HMI is either a standalone device or embedded commu- nication interface to visualize and monitor MTU activities and RTU information flow [2].

Using a Python script, we retrieve CPS-relevant vulnerability in- stances from multiple online cybersecurity data sources, including NVD, vendor websites, ICS CERT, and SecurityFocus. In addition, we employ Shodan query APIs to obtain vulnerability instances. The retrieval workflow is illustrated in Fig. 3. Following this vulnerability retrieval workflow, we further added a query-keywords generator and a CPS vulnerability filter, as illustrated in Fig. 5.

Using the proposed retrieval and filter workflow, we extracted vulnerable component entities from CVE vulnerability reports using an open-source NER (referring to Named Entity Recognition) model [50], as illustrated in Fig. 5. We then map these retrieved entities with the CPE as well as vendor websites to generate a list of terms related to these components. We retrieved vendor information for each extracted CPS vulnerability instance using NER and correlated against the CPE database. To do so, we obtained vendor HTML links from CVE ref- erence maps, based on which we crawl the vendor websites fetching CPS vulnerability related data. This step aims at reconciling potential inconsistent product names. Finally, these terms are combined with the corresponding component versions of interest, that are then used as tags to query vulnerability instances from public vulnerability data sources. We also conducted manual checks on CPS-related vendor metadata, and optimized our search engine outcomes to detect hidden metadata for each vendor, in order to decrease possible false negatives.

More specifically, the query generating process is composed of three major steps and presented in Fig. 6. Note that we only show the processing details for CPE to ensure readability, although we process data extracted from CPE, as well as NVD and vendor reports.

In the last step, we allow manual check and query selection to decrease possible false positives based on other keywords that distinguish them from CPS-related concepts. If we adopt one of the query tags and use CPE-based query, the correlated database would return vulnerability instances that share the same CPE metadata. If we find that all the generated query tags are not correct, we switch to report- or vendor-based query and retrieve reports that contain the system configuration information string.

We first investigate in Shodan database to extract product names, versions and vendors of industrial PLC, RTU, MTU and HMI equip- ments. The reason we started with Shodan investigation is that Shodan contains open ports of connected ICS devices nearly in real time. It also covers the most commonly used CPS-based CI equipments, and therefore provides actual device names, versions and vendors for our case study analysis. For example, using PLC as the query tag, we gather products like Mitsubishi Q PLC. We use these 4 lists of CI product features as input for our query generator to generate queries for our correlated database.

By querying NVD, we obtain respectively 257, 445, 107, and 258 vulnerability reports related to PLC, RTU, MTU and HMI. These re- trieved 1067 CPS related vulnerabilities extend till November 3, 2021. Note that some vulnerabilities appear in more than one type of CPS components. One example is the vulnerability instance CVE-2019-0708 appearing in both PLC and HMI vulnerability groups. We removed duplicated vulnerabilities and kept 870 instances in the analysis corpus when we need to assess general CPS vulnerability features.

We further analyze these identified CPS vulnerabilities to get their CVSS V2 and V3 scores assigned by NVD. All of these CPS vulnerabili- ties are assigned CVSS V2 scores and relevant labels like V2 access vec- tor. In contrast, 319 (71.69%) RTU vulnerabilities, 121 (47.08%) PLC

vulnerabilities, 47 (43.93%) MTU vulnerabilities, and 121 (46.90%) HMI vulnerabilities are not assigned CVSS V3 scores. We conduct an in- vestigation of the CVSS V2 labels assigned by NVD to our retrieved CPS vulnerabilities. Table 2 lists the exploitability and impact distributions of these vulnerability instances under CVSS V2 metrics. Vulnerabilities exist in the four types of CPS show similar distributions in terms of access vector, access complexity, authentication, and availability impact. There is a higher probability that exploiting PLC vulnerabilities may bring lower confidentiality impact, but higher availability impact. Generally, CPS vulnerabilities have higher exploitability compared to the overall reported vulnerabilities, especially in terms of required authentication and complexity of such exploits.

M580 PLCs from Schneider Electric. Vulnerable Modicon PLCs employ Schneider Electric UMAS protocol that operates over the Modbus pro- tocol which lacks encryption and proper authentication mechanisms. This vulnerability allows spoofing attacks to happen against the Mod- bus communication between the PLC controller and the EcoStruxure software in the engineering workstation.

Another common weakness in CPS devices is improper memory access control that allow read or write operations of memory locations, which may cause out-of-bounds read and/or write. One example of such vulnerabilities is CVE-2020-15782 that exemplifies weakness of improper operation restrictions within the bounds of a memory buffer (or cwe119). This vulnerability has been identified in a list of Siemens SIMATIC firmware, which allows attackers with network access and download rights to a PLC to bypass existing protections in the PLC, such as PLC sandbox, and obtain read–write memory access remotely while staying undetected. A PLC sandbox refers to a protected area of memory where engineering code could run.

We distinguish some specific CPS manufacturers or vendor vulner- abilities reported by Schneider Electric SE, Siemens AG, and Mitsubishi. More specifically, we discovered 29 vulnerabilities from Schneider Elec- tric SE products and 39 vulnerabilities from Siemens AG products. We also identified 12 vulnerabilities from Mitsubishi. We also observe some frequently published products that are affected by CI vulnerabilities.

One typical example is OpenSSL that appears in 120 CPS vulnerability instances. OpenSSL [53] is a library implementing the SSL/TLS pro- tocol. SSL (referring to secure sockets layer) is the old name of TLS (referring to transport layer security). We also found 51 vulnerability instances related to Simatic PLCs and HMIs developed by Siemens AG.

As we discussed earlier, more than 57% of extracted CPS vul- nerability instances are not scored under the CVSS V3 mechanism. The scoring system shown in Section 4 is used to compute scores for these vulnerabilities, in order to bridge the gap of missing CVSS V3 information. We also calculate CVSS V3 scores for the vulnerabilities with inconsistent scores assigned. We design this re-computation step considering two factors, (i) CVSS V3 is only applied to vulnerabilities disclosed within and after 2015 in some data sources like NVD, and

(ii) inconsistent scores are provided by multiple score sources. Subse- quently, the diversity of their sub-scores is inspected to reflect CVSS V3 metric scores through property vectors evaluations. Exploitability, Scope and Impact base metric attributes for CPS vulnerabilities are contrasted against actual values and illustrated in Table 3.

Column CPS). Column 8 (or Column CVE) shows the overall rate of published CVE reports that have assigned CVSS V3 scores, by dividing the vulnerabilities with certain labeled measurement (e.g., Network) against all the disclosed vulnerabilities till November 3, 2021. By doing so, we show how the significant characteristics of CPS vulnerabilities diverge when considering different cybersecurity data sources.

Discovering and evaluating vulnerabilities in CPS networks are both crucial and challenging processes. We proposed to raise the efficiency of vulnerability-severity scoring systems following CVSS standards, to rate the severity of a reported vulnerability instance. Our approach reconciles inconsistent vulnerability severity scores that are contributed from different cybersecurity analysers, and also decrease potential con- flicts resulting from various CVSS mechanisms. We employed majority

voting technique to decide the score of inconsistent reports for the same vulnerabilities in different cybersecurity repositories. We then used these compatible vulnerability instances as ground truth to train a machine-learning model as a scoring basis. The performance of the proposed model is shown to obtain high accuracy and micro F1-score thresholds compared to similar studies. A case study involving CPS vulnerability reports from multiple repositories is illustrated to vali- date the proposed vulnerability assessment model. A query-filter logic is used to customize retrieved vulnerability instances. The outcomes are contrasted against reported CVE instances to further analyze the characteristics of CPS vulnerabilities. The results of our case study also indicate that vulnerability patterns are diverse when relying on different cybersecurity data sources, which may mislead cybersecurity decision making in the perspective of patch prioritization or budget allocation. And hence, a vulnerability analysis approach that correlates multiple data sources is necessary to enhance further cybersecurity awareness.

The proposed research can be further extended by adjusting the majority voting tie while involving experts’ supervision in the assess- ment loop. This approach includes security experts to provide some startup settings, along with computational intelligence techniques to adjust these settings dynamically. Another possible future direction involves arithmetic means of different scores to weigh several sources, to evaluate the reliability of scores provided from these sources. Finally, we plan to investigate the correlations between vulnerability severity with the attack surface of the system on which the vulnerability assess- ment is applied. This last planned work is also closely related to the environmental property of CVSS metrics.

