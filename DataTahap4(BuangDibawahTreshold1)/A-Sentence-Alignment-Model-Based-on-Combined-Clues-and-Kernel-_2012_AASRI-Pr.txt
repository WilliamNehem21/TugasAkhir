A sentence alignment model based on combined clues and Kernel Extensional Matrix Matching (KEMM) method is proposed. In this model, a similarity matrix for sentence aligning is formed by the similarities of bilingual sentences calculated by the combined clues, such as lexicon, morphology, length and special symbols, etc.; then this similarity matrix is used to construct a select matrix for sentence aligning; finally, obtains the sentence alignments by KEMM. Experimental results illustrated that our model outperforms over the Gale’s system on handling any types of sentence alignments, with 30% total sentence alignment error rate decreasing.

In various fields of research on natural language processing, the importance of bilingual corpus is more and more obvious. Different applications call for aligned bilingual corpus of different granularities and corresponding technology, which includes article, paragraph, sentence, phrase and word level. Sentence level aligned bilingual corpus is indispensable to example based machine translation.

To the translations needed to have sentence alignment for Chinese text C and Japanese text J, we assume that the number of C is m and to be expressed as C=CS1CS2…CSm , the number of J is n and to be expressed as J=JS1JS2…JSn. The similarities of all bilingual sentences calculated by the combined clues included lexicon, morphology and length. Results by each approach are summed up after multiplied by different weights and then plus special symbols similarity to be the final similarity between Chinese and Japanese sentences. The formula to calculate similarity of Chinese sentence CSh and Japanese sentence JSk:

Numbers (such as 1978, 03, 24, etc.), English characters (such as China, Henry, etc.), quotation marks and brackets are used to calculate the similarity of Chinese and Japanese special characters. The maximum value of special characters’ similarity (SValue) is set as 0.2. When CSh and JSk have the same special characters, SValue(CSh,JSk) is added 0.05, and it’s added to 0.2 for max. It is a supplement for the similarity calculating of SimDict,SimMorph and SimLength.

Multi-alignment penalty factor is to deal with alignment conflict. For an instance, when aligned conflicts happen and judge if the style is 1-2 or the two aligned 1-1 and 0-1, we need to calculate the similarity of these three kinds and then multiply the corresponding penalty factor. Then we can compare their similarity modified.

Table 3 shows the distributionof all kinds of alignment style in our test set and corpus. We can see that the distribution of our test set is approaching the distribution of our corpus. So our test set is representative, it can represent the test result of our corpus.

differences from reference (it’s worse than the results in reference). So the data is not faith to Gale system. We use the better experimental results from Gale shown in reference. As shown in table 3, the distribution of our test set is approaching the test set in Gale. So this comparison is faithful.

Test set in Gale includes some rare alignment and they don’t appeared in our test set. Since the experiental results in Gale show that the error rate of processing the styles is 100%, the difference cannot make effects. So the comparison is sloped to Baseline.

On all kinds of alignment styles our system always has a lower error rate than Gale system. The error rate of our system is 2.3% and Gale is 3.5%. The exprimental results and analysis above fully prove the effectiveness of our calculating model.

