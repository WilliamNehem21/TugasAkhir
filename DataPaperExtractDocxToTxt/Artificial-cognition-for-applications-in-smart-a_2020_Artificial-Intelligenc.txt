Artificial Intelligence in Agriculture 4 (2020) 81–95









Artificial cognition for applications in smart agriculture: A comprehensive review
Misbah Pathan a, Nivedita Patel b, Hiteshri Yagnik c, Manan Shah d,⁎
a Department of Computer Engineering, Silver Oak College of Engineering and Technology, Ahmedabad, Gujarat, India
b Department of Computer Engineering, Nirma University Ahmedabad, Gujarat, India
c Guj Info Petro Limited (GIPL), Gandhinagar, Gujarat, India
d Department of Chemical Engineering, School of Technology, Pandit Deendayal Petroleum University, Gandhinagar, Gujarat, India



a r t i c l e	i n f o 

Article history:
Received 26 June 2019
Received in revised form 6 June 2020
Accepted 6 June 2020
Available online 10 June 2020

Keywords:
Artificial intelligence Diseased
Agriculture Precision farming Phenotyping
a b s t r a c t 

Agriculture contributes to 6.4% of the entire world's economic production. In at least nine countries of the world, agriculture is the dominant sector of the economy. Agriculture not only provides the fuel for billions of people but also employment opportunities to a large number of people. The agricultural industries are seeking innovative approaches for improving crop yielding because of unpredictable climatic changes, the rapid increase in popula- tion growth and food security concerns. Thus, artificial intelligence in agriculture also called “Agriculture Intelli- gence” is progressively emerging as a part of the industry's technological revolution. The aim of this paper is to review various applications of agriculture intelligence such as precision farming, disease detection, and crop phe- notyping with the help of numerous tools such as machine learning, deep learning, image processing, artificial neural network, deep learning, convolution neural network, Wireless Sensor Network (WSN) technology, wire- less communication, robotics, Internet of Things (IoT), different genetic algorithms, fuzzy logic and computer vi- sion to name a few. With the help of these technologies, the use of the colossal volume of chemicals can be used reduced, which would result in reduced expenditure improved soil fertility along with elevated productivity.
© 2020 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).




Contents




Introduction

One of the key features that distinguish humans, from everything else in the world is intelligence (Pivoto et al., 2018). An approach to

* Corresponding author.
E-mail address: manan.shah@spt.pdpu.ac.in (M. Shah).



make a computer, a robot, or any machine think the way human thinks and resolve problems is Artificial Intelligence (Sukhadia et al., 2020; Shah et al., 2020a, 2020b; Kundalia et al., 2020). In the words of Professor McCarthy, artificial intelligence is “the science and engineering of making intelligent machines, especially intelligent computer programs”. Basic ‘AI’ has existed for decades, via rules-based programs that deliver rudimentary displays of ‘intelligence’ in specific contexts. Progress, however, has been


https://doi.org/10.1016/j.aiia.2020.06.001
2589-7217/© 2020 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).



limited – because algorithms to tackle many real-world problems are too complex for people to program by hand (Parekh et al., 2020; Patel et al., 2020a, 2020b; Shah et al., 2019a, 2019b, 2019c). What if difficulty could be transferred of making complex predictions, the data optimisation and feature specification, from the programmer to the program? This is the promise of modern artificial intelligence. A consciousness towards emerg- ing problems, along witha pressing desire to embed artificial intelligence in larger applications led to the development of reactive artificial intelli- gent systems (Agre and Chapman, 1987; Brooks, 1986; Firby, 1987; Garvey and Lesser, 1994).
Machine learning is a sub-set of Artificial Intelligence, where advances are rapid and significant (Kakkad et al., 2019). Problems too complex for humans to solve are tackled by Machine Learning by shifting the burden of decision-making to the algorithm (Shah et al., 2020a, 2020b; Patel et al., 2020a, 2020b; Panchiwala and Shah, 2020; Talaviya et al., 2020). As AI pioneer Arthur Samuel wrote in 1959, machine learning is the ‘field of study that gives computers the ability to learn without being ex- plicitly programmed’. The goal of Machine learning is to develop a predic- tion engine for a particular use case by writing a program for every type of object needed to identify (Gavhale and Gawande, 2014; Jani et al., 2019; Patel et al., 2020a, 2020b). To solve the problem of writing particular pro- gram for every object to be identified, Deep Learning crossed the thresh- old. Deep learning is the sub-set of Machine learning which saves the time and efforts of a programmer needed to undertake the tasks of feature specification or optimisation (Jha et al., 2019; Gandhi et al., 2020; Ahir et al., 2020). Deep learning has revolutionised the world of artificial intel- ligence. Artificial Neural Network is powerful yet very flexible deep learn- ing, with three layer i.e., input layer, output layer and multiple layers- called ‘deep neural network’. Biological nervous system, such as brain, in- spired ANN as information-processing paradigm to process information (Sladojevic et al., 2016; Pandya et al., 2020). Using this process, with in- creasing effectiveness we can now:
Process images
Translate between languages in real-time
Use speech to control devices
Predict how genetic variation will effect DNA transcription
Precision agriculture
Crop phenotyping and analysis
Detect tumours in medical images; and more.

According to (FAO, 2017), world population growth is slowing down, in some regions population will continue to expand beyond 2050 and even into the next century as more people live in cities than in rural areas, and this discrepancy is projected to increase as population grows. Agriculture feeds the world and the population of the world is in- creasing rapidly (Shah et al., 2018a, 2018b; Shah et al., 2019a, 2019b). In 2019, world population is 7.7 billion and by 2050, the population will witness an increase by 2 billion, resulting in a total world population of 9 billion. The environmental strain that is being put on the planet by growing population and industries, including agriculture, is leading to runway global warming. Various egregious activities cause land deg- radation which results in deterioration in quality of crops; chemical run- off is contributing to dead zones and threatening sea life. Thus, the application of artificial intelligence to agriculture could be very impor- tant in providing potential answers to solve major issues such as pest and disease infestation, inadequate application of chemicals, improper drainage and irrigation, weed control and yield prediction to name a few (Bannerjee et al., 2018; Adamides et al., 2014). Complex interaction of soil, seed and agro chemicals are the outcome of agricultural product.

Precision farming

Precision farming is all about the phrase “Right Place, Right Time, and Right Product”. Precision farming replaces the repetitive and labour inten- sive part of farming with more accurate and controlled techniques than
conventional ones. In 2017, Pivoto et al. (2018), viewed smart farming (SF) as the incorporation of communication technology into machinery equipment as well as sensors to use in agricultural production systems (Pedersen et al., 2008; Ahmed et al., 2016). According to Gibbons (2000) and Waheed et al. (2006), advanced information processing technology for timely in-season crop management like variable rate technology, air- borne and satellite remote sensing, multispectral and hyperspectral ground-based, computer modelling, global positioning systems (GPS), geographic information systems (GIS) are innovative system approaches on which precision agriculture is based. According to Cox (2002), applica- tions of livestock production as well as the spatially-variable field opera- tions made possible by satellite Global Positioning System (GPS), are included under the general heading of precision agriculture (or Precision Farming).Ullah et al. (2017) discussed precision agriculture which collects diverse data, integrates several technologies and effectively analyse to im- prove production efficiency simultaneously minimises the cost. Yandun et al. (2017) described Precision horticulture as the way to improve prof- itability and productivity in the utilization of assets, hence accomplishing this objective under the various difficulties faced by agribusiness essen- tially because of atmosphere changes, land debasement, accessibility of farmable land, lack of work power and expanding costs. Due to reduced equipment costs, increased computational power and increasing interest in non-destructive food assessment methods, image processing and com- puter vision has grown in recent years in agriculture (Mahajan et al., 2015; Patrício and Rieder, 2018).
Ullah et al. (2017) aimed to review agricultural challenges, different methods of precision agriculture based on artificial intelligence and ma- chine learning and future directions. According to the survey, there were technologies useful for precision farming such as GPS/GNSS, mo- bile devices, robotics, driverless tractor, irrigation, Unmanned Arial Ve- hicle (UAV), Internet Of Things (IoT), sensors, variable rate seeding, weather modelling. Data collection, analysis of data, managing decisions and farming are four main phases of precision farming. Since last two decades, for precision farming, new technologies have been developed based on artificial intelligence such as Artificial Neutral Networks (ANNs) and fuzzy logic controllers for regulation of temperature and humidity in artificially conditioned greenhouses. Also, Khanna and Kaur (2019), presented detailed review considering IOT as the back- bone in the field of precision farming.
The process of classification is also of vital importance to the precision
farming process. Noguchi et al. (1998)used the Generic Algorithm (GA) optimized fuzzy logic during field operations to classify crops. In the entire soybean growth period, it was noticed that results were accurate. After segmenting out the weed, for estimation purposes of the height and width of the soybean, ANN was used (Heckmann et al., 2017).
Similarly, Neural Networks and Fuzzy Logic application in the classi- fication of crops for crop mapping is useful as it ultimately allows the crop water requirement to be determined. (Murmu and Biswas, 2015). Fuzzy Logic can further be used for grading crop produce such as apples (Kavdir and Guyer, 2003), tomatoes (Dorado et al., 2016), let- tuce, cauliflower (Ureña et al., 2001) and even mangoes (Teoh et al., 2013). Such processes consist of the image capturing or inputting infor- mation, feature extraction, and then classification and/or grading (Naganur et al., 2012). Based on parameters such as size, shape (Mustafa et al., 2009), colour, aroma, etc. the final grading of the crop is done on a scale such as on a range of 1–10. Similarly, the grading of date trees based on the condition and output that they are likely to give can also be done in order to help farmers utilise their resources cor- rectly (Mazloumzadeh et al., 2009).
Autonomous mobile robots are also tools used in precision agricul- ture for various different tasks as shown in (Fig. 1). Autonomous robots have the capability of adapting and learning which is essential to agri- culture which is a dynamic process (Hagras et al., 2002). Most autono- mous robots have sensors for input information which is then processed by the control unit. The robot control system may be based on fuzzy logic (Hagras et al., 2000). Robots can be used for inspection




Fig. 1. Autonomous mobile robots used in precision agriculture Figure (a): Robotic Phenotyping (Bao et al., 2019). (b): Agricultural robot (Ball et al., 2016). (c) Strawberry harvesting Robot (Xiong et al., 2020). (d) Autonomous Robot (e) Robotic Apple Harvester (Silwal et al., 2017). (f) Autonomous Agriculture Robot “Vinebot” (Hajjaj et al., 2018). (g) Agriculture Robot Use In Field (Beachar et al., 2016). (h) Weed Removing Robot (Pire et al., 2019) (i) Autonomous Agriculture Robot “BoniRob” (Biber et al., 2012) (j) Agricultual Vehicle Robot (Galati et al., 2017).
(k) Agriculture Robot (Duckett et al., 2018). (l) Agriculture spraying robot (Adamides et al., 2014).

and treatment of plants by inbuilt gripper systems and eye-hand sys- tems. (Acaccia et al., 2003). Some other widely used robot applications are weed picking (Slaughter et al., 2008) and robotic weed control (Lee et al., 1999) which is based on a machine vision system and in- cludes a precision chemical application system. This seems to be largely beneficial as hand weed control is an extremely drudging and inefficient task that increases human labour. In addition to this, robots are used for crop phenotypic to assess the health of plants. Although different robots make the use of different navigation systems, they are generally guided by a combination of GPS and a human-operated laptop as it moves be- tween rows of plants. Similarly, progress is being made in the use of ro- bots for the harvesting of crops such as apples, grapes, etc.
Waheed et al. (2006) investigated the potential of hyperspectral re- mote sensing data to provide better crop management information. Hyperspectral Image processing can be used for all kinds of new and ef- ficient agriculture purposes (Teke et al., 2013) such as leaf nitrogen accumulation(Wei et al., 2008), nitrogen deficiency, invasive weed spe- cies (Goel et al., 2003), invasive pests like the leafhopper (Prabhakar et al., 2011), estimation of vegetation parameters.
Such as leaf area index (LAI) (Liu et al., 2016), detection of disease in plants (Zhang et al., 2003) and more.
In 2006, Waheed, et al., investigated that to classify hyperspectral data of experimental corn plots into categories of water stress, presence of weeds and nitrogen application rates classification and regression trees (CART), decision tree algorithm was used. The classification
accuracy was 96% for the irrigation factor, 83% for the nitrogen, and 100% for the weed control strategies, was obtained with the spectra at the early growth stage and single-factor analysis. Based on results it was concluded that CART decision tree approach was an effective tool for solving hyperspectral tree problem such as allowing us to obtain full data as well as helps to take up a decision by describing risk in all the possible categories. Furthermore to classify hyperspectral data deci- sion trees along with ANN (Goel et al., 2003) or Support Vector Ma- chines (Mercier and Lennon, 2013) are both methods that will work alternatively for pattern recognition in hyperspectral data.
Aqeel-ur-Rehman et al. (2014) reviewed WSN technology and their applications in different aspects of agriculture, the need of wireless sen- sors in agriculture and reported existing system frameworks in the ag- riculture domain. The main objective of the authors was to use sensors and network successfully to get numerous benefits to solve agriculture domain problems. According to the review carried out, it was concluded that major concerns were that solutions were too complex, costly, the generalised solution was lacking for various problems.
Keshtgari and Deljoo (2012) used Wireless Sensor Networks (WSNs) for precision agriculture in 2011. WSN are usually used for collecting, storing and sharing sensed data. The aim is to take controlled decisions on the root of sensing real-time data of climatology and other environmental properties. To report the design, construction, and test- ing of a distributed infield WSN, a remote monitoring control, grid to- pologies, was the main objective. The outcome was a drastic reduction



in cost and improved quality agricultural production and precision irri- gation on combining applications of precision agriculture and WSN.
Hakkim et al. (2016), aimed to increase economic returns as well as reduce the energy input and environmental impacts of agriculture through precision farming. Tools and equipment used were Global Posi- tioning System (GPS), sensor technologies, geographic information system (GIS), grid soil sampling and variable- rate fertilizer (VRT) appli- cation, crop management, soil and plant sensors, rate controllers, preci- sion irrigation and in pressurized systems, software, yield monitor and precision farming on arable land, precision farming within the fruits, vegetables and viticulture sectors, precision livestock farming. At last, it was concluded how well and quickly the knowledge need to guide new technologies can be found in the factor on which success of preci- sion farming depends (Pire et al., 2019).

Disease detection in plants

Plants are highly prone to disease as they are exposed to the outer environment, therefore the prevention and control of disease is a must. Current crop conditions and susceptibility to infection are factors on which the rate of spread of disease depends (Lucas et al., 1992 and Camargoa and Smith, 2009; Gulve et al., 2015). The key to prevent the losses in the yield and quantity in the agricultural products is identifica- tion of the plant diseases (Khirade and Patil, 2015). Coloured spots or streaks that can occur on the leaves, stems and seeds of the plant are range of symptoms when plant becomes diseased. Consequently, rapid identification of disease remains difficult in many parts of the world. Advances in computer vision by deep learning have paved the way for smartphone-assisted disease diagnosis. Oversized work of watching in huge farms of crops, and detecting symptoms of disease at early stage is extremely tedious, thus automated techniques are ben- eficial. Bashish et al. (2011) studied that to reply on expert's naked eye observation to detect and classify disease is expensive, particularly in developing countries. Therefore it was aimed to use image processing based software solution for automatic detection and classification of plant leaf diseases.
Patil and Kumar (2011) aimed to provide various advanced methods to study plant diseases/traits using image processing to increase throughput and reduce cost arising from human experts in detecting the plant disease. To detect diseased leaf, stem, fruit, to quantify area af- fected by disease, to find shape of affected area, to determine colour of affected area, to determine size and shape of fruits, etc. image process- ing is useful. Manual analysis scenario, shifting the rate-limiting step to image acquisition can be expanded beyond its feasibility study with the help of automation of image analysis experiments (Spalding and Miller, 2013).
A number of algorithms and methods may be used for classification and detection of disease through computer vision. Deep Convolutional Neural Networks were used (Ferentinos, 2018) reaching a 99.53% success rate in identifying the corresponding disease and plant. Neural networks have also worked for detection of diseases in crops such as rice (Phadikar and Sil, 2008). K- means algorithm (Mehra et al., 2016), Principal compo- nent analysis (PCA), the coefficient of variation (CV) (Schor et al., 2016), Support Vector Machines (SVM) (Bhange and Hingoliwala, 2015) are also some other alternative and in some cases more efficient model basis. In an example study, K-means clustering for classification into two groups: healthy and infected followed by support vector machines (SVM) provided better results rather than ANN. (Omrani et al., 2014).
Bashir and Sharma (2012) used colour and texture to recognize and classify different agriculture/horticulture whose combinational feature proved to be effective way of disease detection in plants. Using methods like K-mean clustering, Bayes classifier colour and texture analysis was used for detection in Malus domestica.
A system was developed with the help of networked cameras, sen- sors, and a machine learning algorithm by Israeli start-up Prospera to monitor crops and warn farmers as soon as plant is sick (Castro and
New, 2016). Golhani et al. (2018) used available neutral network tech- niques to process hyperspectral data which have special emphasis on plant disease detection. Moshou et al. (2004) used neural networks and more specifically multi-layered perceptron's to automatically de- tect yellow rust in wheat. Classification performance increased from 95% to more than 99% using total of 5137 leaf spectra for evaluation with the help of ANN technology.
Modern methods for plant disease detection include combining spec- troscopic and imaging techniques with an autonomous agricultural vehi- cle that can provide information on disease detection at early stages to control the spread of plant diseases (Sankaran et al., 2010). Molecular methodology and profile based techniques are also available. However, imaging and spectrographic techniques are preferred in cases of visible symptoms, take minutes to give results, and can be handled remotely. The aim for performing fusion of data from both hyper-spectral and multi-spectral fluorescence imaging was early detection of disease before visible symptoms and it allowed discrimination from healthy plants with 94.5% accuracy. (Moshou et al., 2005). Hyper-spectral imaging is a tech- nique that applies a wide spectrum of light to each pixel and this light striking the pixels is broken down into spectras and analysed to provide information. As in the case of citrus greening, if thermal infrared spectral reflectance data is collected for both healthy and diseased plants the re- flectance values for both differ and hence, classification occurs in this manner according to the reflectance of each in particular regions (Fig. 2). Similarly, techniques such as fluorescence imaging are also used in which the samples give off a very bright fluorescent light or emission light which is studied in contrast to black backgrounds (Fig. 3). In contrast, Infrared thermal imaging detects the temperature information in crops.
Rangarajan et al. (2018) obtained dataset of images of tomato leaves (6 diseases and a healthy class) from PlantVillage for classification of to- mato crop disease (Fig. 2). Two deep learning based architectures namely AlexNet and VGG16 (Visual Geometry Group) net was used and dataset obtained from PlantVillage was provided as input. Accuracy noted of classification of 13,262 images were 97.29% for VGG16 (Visual Geometry Group) net and 97.49% for AlexNet. Models performance was evaluated on the basis of number of images, setting mini-batch sizes and varying the weight and bias learning weight. It was seen that number of images had a significant impact on the performance of the models. Fur- ther, it was seen that VGG16 net dropped accuracy when weight and bias learning rate increase. In terms of computational load, good accu- racy was provided by AlexNet with minimum execution time compared to the deep VGG16 net.
Machine Vision-based approaches allow non-destructive detection of plant disease at early stages in the development process (Backhaus et al., 2011). The process begins with the stage of sample preparation and image acquisition. Then, evaluation, trait identification, and ranking is conducted followed by classifier development which uses SVM meth- odology in most cases (Chung et al., 2016). This machine vision process was used for the detection or recognition of diseases in crops such as rice (Chung et al., 2016), chili-pepper (Ataş et al., 2012), and papaya (Habib et al., 2018) with accuracies 87.9%, 87.50%, 90.15% respectively. Pydipati et al. (2006) aimed to visually differentiate between com- mon citrus diseases using individual leaf colour-texture features by ex- ploring image processing techniques. Machine based-vision approach to detect citrus disease was the main objection of research. Colour co- occurrence method was used to determine whether texture based hue, saturation, and intensity (HSI) colour features in aggregation with statistical classification algorithms was to be used to identify dis- eased and normal citrus leaves under laboratory conditions. The out- come observed was by using SAS discriminant analysis variable sets was reduced and potential classification accuracies was evaluated. The classification accuracies achieved by SAS discriminant analysis, was above 81% on all data models when intensity feature was used, above 95.8% when hue and saturation features was used alone but 100% accu- racies were achieved on using HIS features. The analysis concluded that to classify citrus disease leaves while examining under controlled




Fig. 2. Platforms for plant disease detection (a): Hyperspectral and chlorophyll fluorescence imaging (Bauriegel and Herppich, 2014). (b): Hyperspectral imaging system for disease scanning on banana plants. (Ochoa et al., 2016). (c): hyperspectral imaging: from the lab to the field (Mahlein et al., 2017). (d): Infrared and Thermal imaging for citrus greening detection (Sankaran et al., 2013).




Fig. 3. Different imaging techniques used for plant disease detection. (a–d) Disease Detection using Imaging (e–f): Plant disease detection by hyperspectral imaging (Mahlein et al., 2017). (g–h)Disease Detection using Hyperspectral Imaging (i-j) (Mahlein et al., 2019). (k–l) Spectroscopy and thermal imaging Source: (Omrani et al., 2014).



laboratory lighting conditions, such methods can be used. Similar tech- nique for disease detection in chilly plant through leaf image and data processing was adapted by Husin et al. (2012). It is considered as one the most effective and fastest method for disease detection in chilly plant and simultaneously it lowers the production cost of the mainte- nance and produce high quality of chili.
An algorithm for image segmentation technique as well as the clas- sification of plant leaf disease was presented by Singh and Misra (2017) with survey on different disease classification technique that can be used for plant leaf disease detection. The Genetic algorithm which gen- erates solutions for optimization was used for image segmentation which plays an important role to detect disease in plant leaf disease.
Different samples of plants like banana leaf with early scorch disease (Fig. 4), lemon leaf with sunburn disease, rose and bean leaves with bac- terial disease and bean leaf with fungal disease were taken as input whose output were segmented images classified into different plant dis- ease. Artificial Neural Network, Bayes Classifier, Fuzzy Logic and Hybrid algorithms can be further used to improve recognition rate in classifica- tion process.

Crop phenotyping

All the observable characteristics of an organism that result from the interaction of its genotype (total genetic inheritance) with the
environment can be defined as phenotyping. Characteristics may include behavioural properties, biochemical properties, colour, shape and size. Plant statistical acquisition, analysis, and systematic application remain insufficient (Guo et al., 2017; Singh et al., 2016). According to Walter et al. (2015) quantitative description of the plant's ontogenetical, physio- logical, and anatomical and biochemical properties are plant phenotyping (Zhu et al., 2011; Jay et al., 2015). Further, enormous amount of processes, functions, and structures which are changing during growth and develop- ment characterizes the phenotype. For breeding, cultivar adoption, geno- mics, and phenomics study, efficient evaluation of crop phenotypes is a prerequisite (Liu et al., 2015; Naik et al., 2017).
Improvement in yield is the primary objective and problem in plant breeding. Dee and French (2015) aimed to propose an automated system based on computer vision which could perform detection and measure- ments from an image without human intervention, as a result, we can ob- tain high throughput with more accuracy in less time and even less expensive than traditional methods. According to Coppens et al. (2017) robotized picture investigation strategies permit substantial increments in the throughput of characteristics estimations, in this manner counter- ing the supposed phenotyping bottleneck, which considers phenotypic estimations the rate-restricting element in the practical examination of explicit genotypes or the evaluation of phenotype execution in plant rear- ing. Therefore, the effectiveness of new phenotyping and genotyping techniques should be evaluated with additional genetic gain for yield




Fig. 4. Disease In Plants (a–b) Banana leaf Disease. (c–d) Rose leaf Disease. (e) Beans leaf fungal Disease.



that can be obtained by implementation of new techniques, where cost- benefit should be evaluated on the relation to the speed and cost of the additional genetic gain (van Eeuwijk et al., 2019, Fig. 5.
In crop phenotypic, the collection of information in an extremely ef- ficient way in terms of both space and time is required which is why it is necessary to have a sturdy sensor system. Bai et al. (2016) showed up a system comprised of five sensors i.e. ultrasonic distance sensors, ther- mal infrared radiometers, NDVI sensors, portable spectrometers, and RGB web cameras for high throughput phenotyping in plant breeding. These multiple sensors were used to measure crop canopy traits from field plot, a GPS was used to geo-reference the sensor measurements and to collect simultaneous environment details two environmental sensors (a solar radiation sensor and air temperature/relative humidity sensor) were integrated. The results obtained from the soybean and wheat field with the help of sensor system performance were satisfac- tory and robust in the field tests. Characteristics of the temporal dynam- ics of these traits were obtained by plotting sensor-based traits as a function of time. Hence it was concluded that, to collect field-based high throughput plant phenotyping data, sensor system could be pow- erful tool for plant breeders.
Hyperspectral imaging and non-imaging sensors are alternative valuable tools which can be used for obtaining information related to both quantitative and qualitative aspects of resistance in plants towards plants (Kuska et al., 2015). Four different kinds of hyperspectral sensor technologies are available: push broom scanner, whisk broom scanner, filter-based sensor and non-imaging sensor and each one of these tech- nologies have their advantages based on application. They may be ap- plied for the phenotyping of disease resistance in crops (Mahlein et al., 2019). Moreover, algorithms like Support Vector Machines coupled with Simplex Volume Maximization are used for the analysis (Thomas et al., 2018). Support Vectors Machine is the most popular Machine Learning approach used for stress phenotyping. (Singh et al., 2015) However, more understanding of the process may enable application K means clustering, Artificial Neural Networks (ANN), Gaussian Mixture Models, etc. more efficiently.
One of the major challenges that are faced with the application of this system in phenotyping is the lack of large amounts of data. The ca- pacity of photosynthesis which is one of the most important factors of plant metabolism can be predicted using leaf reflection spectra. Analysis of a diverse array of leaf spectra revealed major ranges of wavelengths in which leaf reflectance was highly correlated which provides potential to make efficient prediction models. Prediction models are designed using a number of technologies such as Partial Least Square Regression (PLSR) which is used to reduce the number of features and Neural Net- works which accounts for the nonlinearity that PLSR does not.
A range of sensors can be integrated with the UAV platforms (Sankaran et al., 2015a, 2015b). The sensors are based on spectral inter- actions between the object and the electromagnetic spectrum. An ex- ample of this is reflectance in visible and infrared regions at the time of flight. These sensors are used to measure response of plants to both biotic and abiotic stress. Examples of stress are water stress, plant nutri- ent deficiency stress, and heat stress (Vanegas et al., 2018).
UAS-friendly sensors are important because they allow efficient in- formation fusion. This is demonstrated by the fusion of RGB, multispec- tral and thermal data to estimate soybean (Glycine max) biochemical parameters like chlorophyll content, nitrogen concentration, and Leaf Area Index (LAI) (Maimaitijiang et al., 2017). In the model, spectral in- dices/features were combined to predict crop parameters using Partial Least Squares Regression (PLSR), Support Vector Regression (SVR), and Extreme Learning Machine based Regression (ELR) techniques.
Another study that proves aerial techniques are adequate for pheno- typing is the use of multispectral imaging collected with UAVs which were investigated for evaluation of seedling emergence and spring stand of three winter wheat classes in Washington. (Sankaran et al., 2015a, 2015b) The result was a Strong Pearson's correlation coefficient of 0.87 between the ground-truth and aerial image-based emergence.
Besides this, autonomous ground-based vehicles are also platforms for crop phenotyping such as a robot that is capable of measurement of plant stalk strength and gathering phenotypic data with an array of non-contact sensors (Mueller-Sim et al., 2017). Another platform is tower- based phenotyping (Naito et al., 2017). An architecture that con- sists of a combination of two platforms: an autonomous ground vehicle (Vinobot) and a mobile observation tower (Vinoculer) (Shafiekhani et al., 2017). This system is advantageous in the sense that the ground vehicle could collect data from individual plants, while the observation tower could provide an overview of an entire field, identifying specific plants for further inspection by the Vinobot. Remote sensing and field- based platforms are yet other alternatives. (Deery et al., 2014). The dif- ferent platforms are depicted in Fig. 6.
The Clustering of crop phenotyping by means of hyperspectral sig- natures using artificial neutral networks was focused by Seiffert et al. (2010). Under different environmental and nutritional conditions, the quantitative evaluation of number of genetically different tobacco vari- eties (Nicotianatabacum) grown were described. Artificial neural net- works were used to analyse the measured hyperspectral signatures. All spatial images were reconstructed and calculated as well, according to the colour cluster membership of each pixel, in order to get an appro- priate result. The obtained results were compared in relation to the fea- tures. Hence it concludes feasibility of hyperspectral imaging with subsequent neutral networks based image analysis.




Fig. 5. Crop phenotyping process (a) Computation for phenotyping diagram (Shakoor et al., 2017) (b) Image acquisition for phenotyping. (Coppens et al., 2017)



Fig. 6. Different sensor platforms for crop phenotyping: Figure (a) robotic field platform source: (Virlet et al., 2017). (b) Robotic platform (Shafiekhani et al., 2017) Robotic platform (c) Ground based platform (Mueller-Sim et al., 2017). (d) Robotic platform with artificial vision source: (Benet et al., 2018) (e) Ground based platform (Zhang et al., 2016) (f) Robotic platform (Atefi et al., 2019). (g) Robotic based platform (Busemeyer et al., 2010) (h) UAV platform source: (Garrido et al., 2019)
(i) Robotic platform (Atkinson et al., 2019) (j) Robotic platform (Vijayarangan et al., 2018) (k) Robotic platform (Goggin et al., 2015) (l) Robotic platform (Araus et al., 2014).

Liu et al. (2015) reviewed crop phenotyping under three condi- tions. The first was with the help of high-throughput phenotyping technique in controlled environments, for example, green houses or specially designed platforms. Some of the sensing techniques for high throughput Phenotyping include RGB, 3D Laser Scanning, Multi and hyperspectral Imaging, Fluorescent Sensing, and Thermal IR Cameras (Shakoor et al., 2017). Light detection and ranging (LiDAR) is an alternative remote sensing technology capable of ac- quiring three-dimensional (3D) data accurately. It has its potential in application to crop Phenotyping and has been successfully used for 3D high-throughput crop phenotyping (Guo et al., 2017).
The second was through phenotypic strengthening test under semi-controlled an environment such as lodge, drought and disease resistance. The third technique was multi-environmental traits (MET) in uncontrolled environments, according to farmer's cultural practices crop plants are managed in it Liu et al., 2015. This paper is aimed at reviewing research on and the applications of phenotyping techniques as well as proposing methods for MET improvement. Analysis of test resulted that for unbalanced data the MET analytical methods should be adapted. Therefore, it was concluded that there is urgency of research on methods and tools for test design and analy- sis, phenotypic acquisition and management to provide support for the establishment of reliable crop cultivar MET system, improve- ment of testing efficiency and reliability as well as reduction of risk in the selection and introduction of cultivars.
Ubbens and Stavness (2017) introduced Deep Plant Phenomics tool which provides pre-trained neural networks for common plant phenotyping activities, besides this it can be easy to train models, hence it can be used by plant scientists for their personal applica- tions. Image based phenotyping tasks were performed with three benchmark to measure its effectiveness; leaf counting task, mutant classification and age regression tasks.
Reynolds et al. (2019) presented the trade-off between invest- ment and manpower costs by reviewing cost-effective imaging de- vices and environmental sensors. In recent years due to decreasing cost of equipment such as low-cost environmental sensors (Deery et al., 2014) or smartphone embedded mobile imaging sensors (Rousseau et al., 2015), the concept of “affordable phenotyping” or “cost effective phenotyping” has developed rapidly. Certainly, to capture image- and sensor- based crop performance datasets in greenhouses and in the fields- cost effective phenotyping approach have been utilized. Major costs arise from plant handling and man- power; total costs per plant/microplot, hand-held or robotized ground vehicles; the cost of vehicles carrying sensors represents only 5–26% of the total costs, these conclusions are context- dependent, in particular for labour cost, the quantitative demand of phenotyping and the number of days available for phenotypic measurements due to climatic constraints. Hence, the structure of costs in various real-world scenarios was discussed in this review paper.
Bolger et al. (2017) attempted to highlight analysis of plant ge- nomes, describing current problems along with how plant genomes can be best leveraged in union with high throughput phenotyping to accelerate selective breeding. In the process of genome assembly, annotation and linking to phenotypic plant data necessary tools are listed in detail.
Paez-Garcia et al. (2015) aimed to improve root traits and pheno- typing strategies. The idea of a combination of phenotypic root screening approaches was proposed which ultimately focussed on higher yields in rain-fed systems by establishing a relation between young root systems for rapid root screening in the laboratory or greenhouse. The proposed strategies here can help to incorporate “root breeding” which would result in sustainable agricultural sys- tems worldwide.
Thus, different techniques are discussed and cost-effectiveness is reviewed for better growth as well as quality (Table 1).
Future scope

Artificial intelligence gives agronomists a weapon against cereal-hungry bugs, provides the solution to various problems like foliar diseases and nutrient deficiencies to name a few. Based on the research reviews, the most popular applications of Artificial Intelligence in agri- culture appear to fall into categories such as Agricultural Robots i.e., companies are developing and programming autonomous robots to handle essential agricultural tasks such as harvesting crops at a higher volume and faster pace than human labourers, crop and soil monitoring in which companies are leveraging computer vision and Deep-Learning algorithms to process data captured by drones and/or software-based technology to monitor crop and soil health, Image Based Predictive Analytics where machine learning models are being developed to examine huge volumes of data generated every day on historical weather pattern, soil reports, new research, rainfall, pest infestation, images from Drones and cameras which provide strong in- sights to improve crop yield, Disease detection in which pre-processing of image takes place to ensure that leaf images are seg- mented into areas like background, non-diseased part and diseased part. The diseased part is then cropped and sent to remote labs for fur- ther diagnosis. It also helps in pest identification, nutrient deficiency recognition and more. Crop readiness identification: Images of different crops under white/UV-A light are captured to determine how ripe the green fruits are. Farmers can create different levels of readiness based on the crop/fruit category and add them into separate stacks before sending them to the market. Field management: Using high-definition images from drone, real-time estimates can be made during cultivation period by creating a field map and identifying areas where crops require water, fertilizer or pesticides. This helps in resource optimization to a huge extent. From detecting pests to predicting what crops will deliver the best returns, artificial intelligence can help humanity confront one of its biggest challenges: feeding an additional 2 billion people by 2052, even as climate change disrupts growing seasons, turns arable land into deserts and floods once-fertile deltas with seawater.

Conclusion

Industries in the agricultural sector are facing challenges, such as crop yielding, soil and plant health, weeds and disease can be addressed with the help of artificial intelligence-driven technologies. With the help of tools available efficiency can also be improved drastically. It can be inferred from the studies with the support of precision farming more pragmatic farming can take place using scientific approaches such as remote sensing, GPS, data analytics etc. which helps in improv- ing agricultural yield and reduce potential environmental risk. Besides this, with the help of image recognition software, artificial neural net- work and many other tools disease can be detected in the plant at an early stage. Due to disease detection at early stage crop's health can be monitored and productivity with high quality can be obtained with minimum or negligible loss. Artificial intelligence in agriculture can also solve problems such as scarcity of resources as well as labour be solved at large extent. Traditional methods require labours for acquiring crop traits such as plant height, leaf colour, leaf area index, chlorophyll content, biomass and yield, which consumes a lot of time. With the help of different techniques discussed, fast and non-destructive high throughput phenotyping would take place with the advantage of flexi- ble and convenient operation, on-demand access to data and spatial res- olution. This paper is an endeavour to give a thought of automation in agriculture to improve crop quality with productivity, and with mini- mum efforts and time.

Authors contribution

All the authors make a substantial contribution in this manuscript. MP, NP, HY, and MS participated in drafting the manuscript. MP, NP,


Table 1
Summary of artificial intelligence technologies used in various sub processes for precision agriculture.



Table 1 (continued)


Sr no.

Crop or fruit name	Topic	Technology	Results/description	Limitations/future scope	Reference


application.	to represent knowledge visually and more descriptive is main advantage.

9	Carrot seedlings	Weed and crop discrimination using image analysis and artificial intelligence methods.
Digital imaging (image analysis), neural network
To develop and compare plant morphology on one side and training neural network on other side to distinguish seedlings of specific crop and weeds from one another.
Main disadvantage of plant morphology is that individual clusters should be analysed using time consuming method besides this the isolation of an entire plant is also not guaranteed. Whereas neural network gives accuracy at least as good as the image analysis method, with an advantage of flexibility with less human intervention were initial training session is needed.
Aitkenhead et al. (2003)

Fruits (mango, grape, pomegranate), vegetables (beans, bengal gram, soybean, sunflower, tomato), commercial crops (chili, cotton, sugarcane), cereals (wheat, maize)






























Grain crops (maize, rice, wheat, soybean and barley)
Image processing Based Detection of Fungal Diseases in Plants



































Computer vision and artificial intelligence in precision agriculture for grain crops: A systematic review
Computer vision technique using image processing algorithms.

































Computer vision combined with artificial intelligence algorithms
The main objective is to detect, to identify and accurately compute the primary symptoms of fungal disease. The proposed image processing methods for fungal disease detection are as follows:


Fruit crops: segmentation k-means clustering, feature
selection texture, classifiers ANN, nearest neighbour
Vegetable crops: segmenta- tion Chan-vase, feature selection local binary patterns, SVM (Support Vec- tor Machine) classifiers, k-
-nearest neighbour
Commercial crops: segmen- tation grab-cut, feature selection wavelet based, classifiers mahalnobis distance, PNN (Probabilistic Neural Network)
Cereal crops: segmentation k-means clustering, canny edge detector, feature selec- tion (colour, shape, texture, colour texture), radon trans- form (RT), classifiers SVM, nearest neighbour
Presents 25 selected papers systematic assessment for the proficient production of grains to recognize the applicability of computer vision in agriculture. Computer vision would help to lessen complexity and cost in the gluten-containing grains classification from images.
Plan an architecture to remotely monitor the general symptoms in crop for early disease detection using modern technologies with high variability in outdoor conditions.
































GPU (Graphics Processing Unit) and advanced artificial intelligence methods alike DBN (Deep Belief Networks) can be exploited to construct robust methods of computer vision, useful for precision agriculture.
Pujari et al. (2015)





































Patrício and Rieder (2018)

Grape plant	Real time Grape leaf disease detection
Image processing, Artificial Neural Network (ANN)
Developed the automated techniques using image processing vision-based detection algorithm for identifying as well as classifying five diseases (Black rot, Downy mildew, powdery mildew, normal and leaf roll first) which effect plants. The developed algorithm classified and identified the disease with accuracy of 92.94%.
N/A	Kakade and Ahire,
2015

Cucumber plant	Research on Cucumber Downy Mildew Detection System based on SVM Classification Algorithm
Machine vision system and image processing
Total 320 samples were there in which 280 were training samples and other 40 were test samples; distinguished by SVM algorithm. The correctness obtained of cucumber downy
Automatic identification in agriculture have many anomalies like slow recognition, low accuracy, and weak adaptability to illumination and handful recognition methods. Its
Zhou et al., 2015


(continued on next page)


Table 1 (continued)


Sr no.

Crop or fruit name	Topic	Technology	Results/description	Limitations/future scope	Reference





N/A	Machine learning (ML) approaches for crop yield prediction and nitrogen status estimation in precision agriculture: A review










Rice plant	Computer Vision Based Approach to Detect Rice Leaf Diseases using Texture and Colour Descriptors
















Rice plant	Measurement of disease severity of Rice crop using machine learning and computational intelligence




Sensing technologies and Machine learning techniques











Computer vision, gray level
co-occurrence matrix (GLCM), artificial neural network (ANN)












Fuzzy logic with k-means segmentation and machine vision tool technique
mildew detection peaked up to 90%.

This review aimed to illustrate the potential of various machine learning techniques in the domain of precision agriculture to efficaciously handle tasks.
Various machine learning techniques used are
Back-propagation Neural Networks, combination of Convolution Neural Networks with Gaussian Processes,
M5-Prime regression trees, Least Squares SVM, Fuzzy cognitive Map (FCM)
Automatic disease detection computer vision based system was developed to detect disease in rice plants which includes three types of feature extraction; diseased area of the leaf, textural descriptors using gray level co-occurrence matrix (GLCM) and colour moments. To select relevant features and remove redundant ones, genetic algorithm feature based selection was employed which generates 14-D feature vector to reduce the complexity. As a result, accuracy of classification algorithms artificial
The proposed automated system implied about 86.35% accuracy.
practical implementation will take large amount of time and efforts.
In future it was expected to be more optimized, combination of multiple ML and signal processing techniques into hybrid systems and dynamic combination of stationary and mobile equipment for optimal data collection.







As a result, accuracy of classification algorithms artificial neural network (ANN) and support vector machine (SVM) were 92.5% and 87.5% respectively.













The study in the future might consider large data set as well as more type of diseases.




Chlingaryan et al., 2018















Ghyar and Birajdar, 2017


















Sethy et al., 2017





HY and MS wrote the main manuscript, all the authors discussed the re- sults and implication on the manuscript at all stages.
Acknowledgements

The authors are grateful to Department of Computer Engineering, Nirma University, Guj. Info Petro Limited (GIPL), Department of Chem- ical Engineering, School of Technology, Pandit Deendayal Petroleum University, and Silver Oak College for Engineering and Technology for the permission to publish this research.

Availability of data and material

All relevant data and material are presented in the main paper.

Funding

Not Applicable.

Consent for publication

Not applicable.

Ethics approval and consent to participate

Not applicable.
Declaration competing interest

The authors declare that they have no competing interests.

References

Acaccia, G.M., Michelini, R.C., Molfino, R.M., Razzoli, R.P., 2003. Mobile robots in green- house cultivation: inspection and treatment of plants. Proc. of ASER 2003, 1st Interna- tional Workshop on Advances in Service Robotics, 13–15 March. ISBN: 3-8167-6268- 9 Bardolino, Italy.
Adamides, G., Katsanos, C., Christou, G., Xenos, M., Papadavid, G., Hadzilacos, T., 2014. User interface considerations for telerobotics: the case of an agricultural robot sprayer. Second International Conference on Remote Sensing and Geoinformation of the Envi- ronment (RSCy2014). https://doi.org/10.1117/12.2068318.
Agre, P.E., Chapman, D., 1987. Pengi: an implementation of a theory of activity. Proceed- ings of the Sixth National Conference on Artificial Intelligence, pp. 268–272.
Ahir, K., Govani, K., Gajera, R., Shah, M., 2020. Application on virtual reality for enhanced education learning, military training and sports. Augmented Human Research 5, 7 (2020).
Ahmed, H., Juraimi, A.S., Hamdani, S.M., 2016. Introduction to robotics agriculture in pest control: a review. Pertanika Journal of Scholarly Research Reviews. 2 (2), 80–93.
Aitkenhead, M.J., Dalgetty, I.A., Mullins, C.E., McDonald, A.J.S., Strachan, N.J.C., 2003. Weed and crop discrimination using image analysis and artificial intelligence methods. Comput. Electron. Agric. 39, 157–171.
Aqeel-ur-Rehman, Abbasi, A.Z., Islam, N., Shaikh, Z.A., 2014. A review of wireless sensors and networks’ applications in agriculture. Computer Standards & Interfaces 36 (2), 263–270. https://doi.org/10.1016/j.csi.2011.03.004.
Araus, Luis, José, Cairns, J.E., 2014. Field high-throughput phenotyping: the new crop breeding frontier. Trends in Plant Science 19 (1), 52–61 (Luis, Araus, Jose, Kefauver, Shawn, & C, et al. (2018). Translating high-throughput phenotyping into genetic gain. Trends in plant science).

Ataş, M., Yardimci, Y., Temizel, A., 2012. A new approach to aflatoxin detection in chili pepper by machine vision. Comput. Electron. Agric. 87, 129–141.
Atefi, A., Ge, Y., Pitla, S., Schable, J., 2019. In vivo human-like robotic phenotyping of leaf traits in maize and sorghum in greenhouse. Computers and Electronics in Agriculture 163 (Aug 2019).
Atkinson, J.A., Pound, M.P., Bennett, M.J., Wells, D.M., 2019. Uncovering the hidden half of plants using new advances in root phenotyping. Curr. Opin. Biotechnol. 55, 1–8.
Backhaus, A., Bollenbeck, F., Seiffert, U., 2011. Robust classification of the nutrition state in crop plants by hyperspectral imaging and artificial neural networks. 2011 3rd Work- shop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS). https://doi.org/10.1109/whispers.2011.6080898.
Bai, G., Ge, Y., Hussain, W., Baenziger, P.S., Graef, G., 2016. A multi-sensor system for high throughput field phenotyping in soybean and wheat breeding. Computers and Elec- tronics in Agriculture 128, 181–192.
Ball, D., Upcroft, B., Wyeth, G., Corke, P., English, A., Ross, P., et al., 2016. Vision-based ob- stacle detection and navigation for an agricultural robot. Journal of Field Robotics 33 (8), 1107–1130.
Bannerjee, G., Sarkar, U., Das, S., Ghosh, I., 2018. Artificial intelligence in agriculture: a lit- erature survey. International Journal of Scientific Research in Computer Science Ap- plications and Management Studies 7 (3), 1–6.
Bao, Y., Tang, L., Breitzman, M.W., Fernandez, M.G.S., Schnable, P.S., 2019. Field-based ro- botic phenotyping of sorghum plant architecture using stereo vision. Journal of Field Robotics 36 (2), 397–415.
Bashir, S., Sharma, N., 2012. Remote area plant disease detection using image processing.
IOSR Journal of Electronics and Communication Engineering. 2 (6), 31–34.
Bashish, D.A., Braik, M., Bani-Ahmad, S., 2011. Detection and classification of leaf diseases using K-means-based segmentation and neural-networks-based classification. Inf. Technol. J. 10 (2), 267–275.
Bauriegel, E., Herppich, W., 2014. Hyperspectral and chlorophyll fluorescence imaging for early detection of plant diseases, with special reference to fusarium spec. Infections on wheat. Agriculture 4 (1), 32–57.
Bhange, M., Hingoliwala, H.A., 2014. Smart farming: Pomegranate disease detection using image processing. Procedia Computer Science 58, 280–288. https://doi.org/10.1016/j. procs.2015.08.022.
Beachar, et al., 2016. Bechar, A., & Vigneault, Clément. (2016). Agricultural robots for field operations: concepts and components. Biosyst. Eng. 149, 94–111.
Mahlein, A.-K., Kuska, M.T., Thomas, S., Bohnenkamp, D., Alisaac, E., Behmann, J., Wahabzada, M., Kersting, K., 2017. Plant disease detection by hyperspectral imaging: from the labto the field. Adv. Anim. Biosci. 8 (02), 238–243. https://doi.org/10.1017/ s2040470017001248.
Benet, B., Dubos, C., Maupas, F., Malatesta, G., Lenain, R., 2018. Development of autono- mous robotic platforms for sugar beet crop phenotyping using artificial vision. AGENG Conference.
Biber, P., Weiss, U., Dorna, M., Albert, A., 2012. Navigation System of the Autonomous Ag- ricultural Robot “BoniRob”*.
Bolger, M., Schwacke, R., Gundlach, H., Schmutzer, T., Chen, J., Arend, D., Oppermann, M., Weise, S., Lange, M., Fiorani, F., Spannagl, M., Scholzc, U., Klaus, M., Usadela, B., 2017. From plant genomes to phenotypes. J. Biotechnol. 261, 46–52.
Brooks, R.A., 1986. A robust layered control system for a mobile robot. IEEE Journal of Ro- botics and Automation RA-2 (1), 14–23.
Busemeyer, R. Klose, Linz, A., Thiel, M., Tilneac, M., Wunder, E., Ruckelshausen, A., 2010. Agro-Sensor Systems for Outdoor Plant Phenotyping Platforms in Low and High Den- sity Crop Field Plots.
Camargoa, A., Smith, J.S., 2009. An image-processing based algorithm to automatically identify plant disease visual symptoms. Biosyst. Eng. 102, 9–21.
Castro, D., New, J., 2016. The promise of artificial intelligence. Center for Data Innovation 1–48.
Chlingaryan, A., Sukkarieh, S., Whelan, B., 2018. Machine learning approaches for crop yield prediction and nitrogen status estimation in precision agriculture: a review. Comput. Electron. Agric. 151, 61–69.
Chung, C.-L., Huang, K.-J., Chen, S.-Y., Lai, M.-H., Chen, Y.-C., Kuo, Y.-F., 2016. Detecting Bakanae disease in rice seedlings by machine vision. Comput. Electron. Agric. 121, 404–411.
Coppens, F., Wuyts, N., Inzé, D., Dhondt, S., 2017. Unlocking the potential of plant pheno- typing data through integration and data-driven approaches. Current Opinion in Sys- tems Biology 4, 58–63.
Cox, S., 2002. Information technology: the global key to precision agriculture and sustain- ability. Comput. Electron. Agric. 36 (2–3), 93–111.
Dee, H., French, A., 2015. From image processing to computer vision: plant imaging grows up. Funct. Plant Biol. 42 (5), iii. https://doi.org/10.1071/fpv42n5_fo.
Deery, D., Jimenez-Berni, J., Jones, H., Sirault, X., Furbank, R., 2014. Proximal remote sens- ing buggies and potential applications for field-based phenotyping. Agronomy 4 (3), 349–379. https://doi.org/10.3390/agronomy4030349.
Dorado, L.C., Aguila, J.I.C., Caldo, R.B., 2016. Smart farm: automated classifying and grading system of tomatoes using fuzzy logic. Laguna Journal of Engineering and Computer Studies. 3 (3), 64–72.
Duckett, T., Pearson, S., Blackmore, S., Grieve, B., Chen, W.H., Cielniak, G., et al., 2018. Ag- ricultural Robotics: The Future of Robotic Agriculture.
FAO, 2017. The Future of Food and Agriculture Trends and Challenges. Food and Agricul- ture Organization of the United Nations, pp. 1–180.
Ferentinos, K.P., 2018. Deep learning models for plant disease detection and diagnosis.
Comput. Electron. Agric. 145, 311–318.
Firby, R.J., 1987. An investigation into reactive planning in complex domains. Proceedings of the Sixth National Conference on Artificial Intelligence, pp. 202–206.
Galati, R., Reina, G., Messina, A., Gentile, A., 2017. Survey and navigation in agricultural en- vironments using robotic technologies. IEEE International Conference on Advanced Video & Signal Based Surveillance. IEEE.
Gandhi, M., Kamdar, J., Shah, M., 2020. Preprocessing of non-symmetrical images for edge detection. Augment Hum Res 5, 10. https://doi.org/10.1007/s41133-019-0030-5.
Garrido, Francisco José Ostos, Castro, A.I.D., Torres-Sánchez, Jorge, Pistón, Fernando, Peña- Barragán, José M., 2019. High-throughput phenotyping of bioethanol potential in ce- reals using uav-based multi-spectral imagery. Front. Plant Sci. 10, 948.
Garvey, A., Lesser, V., 1994. A survey of research in deliberative real-time artificial intelli- gence. Real-Time Systems. 6, 317–347.
Gavhale, K.R., Gawande, U., 2014. An overview of the research on plant leaves disease de- tection using image processing techniques. IOSR Journal of Computer Engineering. 16 (1), 10–16.
Ghyar, B.S., Birajdar, G.K., 2017. Computer vision based approach to detect rice leaf dis- eases using texture and color descriptors. 2017 International Conference on Inventive Computing and Informatics (ICICI). https://doi.org/10.1109/icici.2017.8365305.
Gibbons, T., 2000. Turning a Farm Art into Science—An Overview Ofprecision Farming.
URL. http://www.precisionfarming.com.
Goel, P., Prasher, S., Landry, J., Patel, R., Bonnell, R., Viau, A., Miller, J., 2003. Potential of air- borne hyperspectral remote sensing to detect nitrogen deficiency and weed infesta- tion in corn. Comput. Electron. Agric. 38 (2), 99–124. https://doi.org/10.1016/s0168- 1699(02)00138-2.
Goggin, Fiona L., Lorence, Argelia, Topp, Christopher N., 2015. Applying high-throughput phenotyping to plant–insect interactions: picturing more resistant crops. Current Opinion in Insect Science 9, 69–76.
Golhani, K., Balasundram, S.K., Vadamalai, G., Pradhan, B., 2018. A review of neural net- works in plant disease detection using hyperspectral data. Information Processing in Agriculture 5, 354–371.
Gulve, P.P., Tambe, S.S., Pandey, M.A., Kanse, S.S., 2015. Leaf disease detection of cotton plant using image processing techniques. IOSR Journal of Electronics and Communi- cation Engineering. 50–54.
Guo, D., Juan, J., Chang, L., Zhang, J., Huang, D., 2017. Discrimination of plant root zone water status in greenhouse production based on phenotyping and machine learning techniques. Sci. Rep. 7 (1). https://doi.org/10.1038/s41598-017-08235-z.
Habib, M.T., Majumder, A., Jakaria, A.Z.M., Akter, M., Uddin, M.S., Ahmed, F., 2018. Ma- chine vision based papaya disease recognition. Journal of King Saud University - Com- puter and Information Sciences 32 (3), 300–309.
Hagras, H., Callaghan, V., Colley, M., 2000. Online learning of the sensors fuzzy member- ship functions in autonomous mobile robots. Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065). https://doi.org/10.1109/robot.2000.845161/.
Hagras, H., Colley, M., Callaghan, V., Carr-West, M., 2002. Auton. Robot. 13 (1), 37–52. Hajjaj, et al., 2018. Hajjaj, S. S. H., & Sahari, K. S. M. (2016). Review of agriculture robotics:
Practicality and feasibility. 2016 IEEE International Symposium on Robotics and Intel- ligent Sensors (IRIS). IEEE.
Hakkim, V.M.A., Joseph, E.A., Gokul, A.J.A., Mufeedha, K., 2016. Precision farming: the fu- ture of Indian agriculture. Journal of Applied Biology & Biotechnology 4 (6), 068–072. Heckmann, D., Schlüter, U., Weber, A.P.M., 2017. Machine learning techniques for predicting crop photosynthetic capacity from leaf reflectance spectra. Mol. Plant 10
(6), 878–890.
Husin, Z.B., Aziz, A.H.B.A., MdShakaff, A.Y.B., Farook, R.B.S.M., 2012. Feasibility study on plant chili disease detection using image processing techniques. 2012 Third Interna- tional Conference on Intelligent Systems Modelling and Simulation, pp. 291–296.
Jani, K., Chaudhuri, M., Patel, H., Shah, M., 2019. Machine learning in films: an approach towards automation in film censoring. J. of Data, Inf. and Manag. 2019. https://doi. org/10.1007/s42488-019-00016-9.
Jay, S., Rabatel, G., Hadoux, X., Moura, D., Gorretta, N., 2015. In-field crop row phenotyping from 3D modeling performed using structure from motion. Comput. Electron. Agric. 110, 70–77.
Jha, K., Doshi, A., Patel, P., Shah, M., 2019. A comprehensive review on automation in ag- riculture using artificial intelligence. Artificial Intelligence in Agriculture. 2, 1–12.
Kakade, N.R., Ahire, D.D., 2015. Real time grape leaf disease detection. International Jour- nal of Advanced Research and Innovative Research in Education 1 (4), 598–610.
Kakkad, V., Patel, M., Shah, M., 2019. Biometric authentication and image encryption for image security in cloud framework. Multiscale and Multidiscip. Model. Exp. and Des., 1–16 https://doi.org/10.1007/s41939-019-00049-y.
Kavdir, Ismail, Guyer, Daniel E., August 2003. Apple grading using fuzzy logic. Turkish Journal of Agriculture and Forestry 2003 27 (6), 375–382.
Keshtgari, M., Deljoo, A., 2012. A wireless sensor network solution for precision agricul- ture based on ZigBee technology. Wirel. Sens. Netw. 4, 25–30.
Khanna, A., Kaur, S., 2019. Evolution of internet of things (IoT) and its significant impact in the field of precision agriculture. Comput. Electron. Agric. 157, 218–231.
Khirade, S.D., Patil, A.B., 2015. Plant disease detection using image processing. 2015 Inter- national Conference on Computing Communication Control and Automation. IEEE Computer Society, pp. 768–771.
Kundalia, K., Patel, Y., Shah, M., 2020. Multi-label movie genre detection from a movie poster using knowledge transfer learning. Augment Hum Res 5, 11 (2020). https:// doi.org/10.1007/s41133-019-0029-y.
Kuska, M., Wahabzada, M., Leucker, M., Dehne, H.-W., Kersting, K., Oerke, E.C., Steiner, U., Mahlein, A.K., 2015. Hyperspectral phenotyping on the microscopic scale: towards automated characterization of plant-pathogen interactions. Plant Methods 11 (1). https://doi.org/10.1186/s13007-015-0073-7.
Lee, W.S., Slaughter, D.C., Giles, D.K., 1999. Robotic weed control system for tomatoes.
Precis. Agric. 1, 95–113. https://doi.org/10.1023/A:1009977903204.
Liu, Z., Zhang, F., Ma, Q., An, D., Li, L., Zhang, X., Zhu, D., Li, S., 2015. Advances in crop phe- notyping and multi-environment trials. Front. Agr. Sci. Eng. 2 (1), 28–37.

Liu, K., Zhou, Q., Wu, W., Xia, T., Tang, H., 2016. Estimating the crop leaf area index using hyperspectral remote sensing. J. Integr. Agric. 15 (2), 475–491.
Lucas, B.G., Campbell, C.L., Lucas, L.T., 1992. Introduction to Plant Diseases: Identification and Management. Van NostrandReinhold, U.S.
Mahajan, S., Das, A., Sardana, H.K., 2015. Image acquisition techniques for assessment of legume quality. Trends Food Sci. Technol. 42 (2), 116–133. https://doi.org/10.1016/ j.tifs.2015.01.001.
Mahlein, A.-K., Kuska, M.T., Thomas, S., Wahabzada, M., Behmann, J., Rascher, U., Kersting, K., 2019. Quantitative and qualitative phenotyping of disease resistance of crops by hyperspectral sensors: seamless interlocking of phytopathology, sensors, and ma- chine learning is needed! Curr. Opin. Plant Biol. 50, 156–162.
Maimaitijiang, M., Ghulam, A., Sidike, P., Hartling, S., Maimaitiyiming, M., Peterson, K., Shavers, E., Fishman, J., Peterson, J., Kadam, S., Burken, J., Fritschi, F., 2017. Unmanned aerial system (UAS)-based phenotyping of soybean using multi-sensor data fusion and extreme learning machine. ISPRS J. Photogramm. Remote Sens. 134, 43–58.
Mazloumzadeh, S.M., Shamsi, M., Nezamabadi-pour, H., 2009. Fuzzy logic to classify date palm trees based on some physical properties related to precision agriculture. Precis. Agric. 11 (3), 258–273.
Mehra, T., Kumar, V., Gupta, P., 2016. Maturity and disease detection in tomato using computer vision. 2016 Fourth International Conference on Parallel, Distributed and Grid Computing (PDGC). https://doi.org/10.1109/pdgc.2016.7913228.
Mercier, G., Lennon, M., 2013. Support vector machines for hyperspectral image classifica- tion with spectral-based kernels. IGARSS 2003. 2003 IEEE International Geoscience and Remote Sensing Symposium. Proceedings (IEEE Cat. No.03CH37477). https:// doi.org/10.1109/igarss.2003.1293752.
Moshou, D., Bravo, C., West, J., Wahlen, S., McCartney, A., Ramon, H., 2004. Automatic de- tection of ‘yellow rust’ in wheat using reflectance measurements and neural net- works. Comput. Electron. Agric. 44, 173–188.
Moshou, D., Bravo, C., Oberti, R., West, J., Bodria, L., McCartney, A., Ramon, H., 2005. Plant disease detection based on data fusion of hyper-spectral and multi-spectral fluores- cence imaging using Kohonen maps. Real-Time Imaging 11 (2), 75–83.
Mueller-Sim, T., Jenkins, M., Abel, J., Kantor, G., 2017. The Robotanist: a ground-based ag- ricultural robot for high-throughput crop phenotyping. 2017 IEEE International Con- ference on Robotics and Automation (ICRA). https://doi.org/10.1109/ icra.2017.7989418.
Murmu, S., Biswas, S., 2015. Application of fuzzy logic and neural network in crop classi-
fication: a review. Aquatic Procedia 4, 1203–1210.
Mustafa, Nur Badariah Ahmad, Ahmed, Syed Khaleel, Ali, Zaipatimah, Yit, Wong Bing, Abidin, Aidil Azwin Zainul, Sharrif, Zainul Abidin Md, 2009. Agricultural produce sorting and grading using support vector machines and fuzzy logic. 2009 IEEE Inter- national Conference on Signal and Image Processing Applications. https://doi.org/ 10.1109/icsipa.2009.5478684.
Naganur, H.G., Sannakki, S.S., Rajpurohit, V.S., Arunkumar, R., 2012. Fruits sorting and grading using fuzzy logic. Int. J. Adv. Res. Comput. Eng. Technol. 1 (6), 117–122.
Naik, H.S., Zhang, J., Lofquist, A., Assefa, T., Sarkar, S., Ackerman, D., ... Ganapathysubramanian, B., 2017. A real-time phenotyping framework using ma- chine learning for plant stress severity rating in soybean. Plant Methods 13 (1). https://doi.org/10.1186/s13007-017-0173-7.
Naito, H., Ogawa, S., Valencia, M.O., Mohri, H., Urano, Y., Hosoi, F., ... Omasa, K., 2017. Es- timating rice yield related traits and quantitative trait loci analysis under different ni- trogen treatments using a simple tower-based field phenotyping system with modified single-lens reflex cameras. ISPRS Journal of Photogrammetry and Remote Sensing 125, 50–62.
Noguchi, N., Reid, J.F., Zhang, Q., Tian, L.F., 1998. Vision intelligence for precision farming using fuzzy logic optimized genetic algorithm and artificial neural network. ASAE Paper 983034. St. Joseph, MI.
Ochoa, D., Cevallos, J., Vargas, G., Criollo, R., Bayona, O., 2016. Hyperspectral imaging sys- tem for disease scanning on banana plants. Spie Commercial + Scientific Sensing & Imaging.
Omrani, E., Khoshnevisan, B., Shamshirband, S., Saboohi, H., Anuar, N.B., Nasir, M.H.N.M., 2014. Potential of radial basis function-based support vector regression for apple dis- ease detection. Measurement 55, 512–519.
Paez-Garcia, A., Motes, C.M., Scheible, W., Chen, R., Blancaflor, E.B., Monteros, M.J., 2015. Root traits and phenotyping strategies for plant improvement. Plants. 4, 334–355.
Panchiwala, S., Shah, M., 2020. A comprehensive study on critical security issues and chal- lenges of the IoT world. J. of Data, Inf. and Manag. https://doi.org/10.1007/s42488- 020-00030-2.
Pandya, R., Nadiadwala, S., Shah, R., Shah, M., 2020. Buildout of methodology for meticu- lous diagnosis of K-complex in EEG for aiding the detection of Alzheimer’s by artificial intelligence. Augmented Human Research https://link.springer.com/article/10.1007/ s41133-019-0021-6.
Papageorgioua, E.I., Markinos, A.T., Gemtos, T.A., 2011. Fuzzy cognitive map based ap- proach for predicting yield in cotton crop production as a basis for decision support system in precision agriculture application. Appl. Soft Comput. 11, 3643–3657.
Parekh, V., Shah, D., Shah, M., 2020. Fatigue detection using artificial intelligence frame- work. Augmented Human Research 5 (2020), 5.
Patel, D., Shah, Y., Thakkar, N., Shah, K., Shah, M., 2020a. Implementation of artificial intel- ligence techniques for cancer detection. Augmented Human Research 5 (1). https:// doi.org/10.1007/s41133-019-0024-3.
Patel, H., Prajapati, D., Mahida, D., Shah, M., 2020b. Transforming petroleum downstream sector through big data: a holistic review. J Petrol Explor Prod Technol 2020. https:// doi.org/10.1007/s13202-020-00889-2.
Patil, J.K., Kumar, R., 2011. Advances in image processing for detection of plant diseases.
J. Adv. Bioinforma. Appl. Res. 2 (2), 135–141.
Patrício, D.I., Rieder, R., 2018. Computer vision and artificial intelligence in precision agri- culture for grain crops: a systematic review. Comput. Electron. Agric. 153, 69–81.
Pedersen, S.M., Fountas, S., Blackmore, S., 2008. Agricultural robots–applications and eco- nomic perspectives. In: Takahashi, Y. (Ed.), Service Robot Applications. InTech, Rijeka, Croatia, pp. 369–382.
Phadikar, S., Sil, J., 2008. Rice disease identification using pattern recognition techniques. 2008 11th International Conference on Computer and Information Technology. https://doi.org/10.1109/iccitechn.2008.4803079.
Pire, T., Mujica, M., Civera, J., Kofman, E., 2019. The Rosario dataset: multisensor data for localization and mapping in agricultural environments. The International Journal of Robotics Research 27836491984143. https://doi.org/10.1177/0278364919841437.
Pivoto, D., Waquil, P.D., Talamini, E., Finocchio, C.P.S., Dalla Corte, V.F., de Vargas Mores, G., 2018. Scientific development of smart farming technologies and their application in Brazil. Information Processing in Agriculture 5 (1), 21–32. https://doi.org/10.1016/j. inpa.2017.12.002.
Prabhakar, M., Prasad, Y.G., Thirupathi, M., Sreedevi, G., Dharajothi, B., Venkateswarlu, B., 2011. Use of ground based hyperspectral remote sensing for detection of stress in cotton caused by leafhopper (Hemiptera: Cicadellidae). Comput. Electron. Agric. 79 (2), 189–198.
Pujari, J.D., Yakkundimath, R., Byadgi, A.S., 2015. Image processing based detection of fun- gal diseases in plants. Procedia Computer Science 46, 1802–1808.
Pydipati, R., Burks, T.F., Lee, W.S., 2006. Identification of citrus disease using color texture features and discriminant analysis. Comput. Electron. Agric. 52, 49–59.
Rangarajan, A.K., Purushothaman, R., Ramesh, A., 2018. Tomato crop disease classification using pre-trained deep learning algorithm. Procedia Computer Science 133, 1040–1047.
Reynolds, D., Baret, F., Welcker, C., Bostrom, A., Ball, J., Cellini, F., Lorence, A., Chawade, A., Khafif, M., Noshita, K., Mueller-Linowi, M., Zhoua, J., Tardieu, F., 2019. What is cost- efficient phenotyping? Optimizing costs for different scenarios. Plant Science. 282, 14–22.
Rousseau, D., Dee, H., Pridmore, T., 2015. Imaging methods for pheno-typing of plant traits. In: Kumar, J., Pratap, A., Kumar, S. (Eds.), Phenomics in Crop Plants: Trends, Op- tions and Limitations. Springer, Berlin, pp. 61–74.
Sankaran, S., Mishra, A., Ehsani, R., Davis, C., 2010. A review of advanced techniques for detecting plant diseases. Comput. Electron. Agric. 72 (1), 1–13.
Sankaran, S., Maja, J., Buchanon, S., Ehsani, R., 2013. Huanglongbing (Citrus Greening) de- tection using visible, near infrared and thermal imaging techniques. Sensors 13 (2), 2117–2130.
Sankaran, S., Khot, L.R., Carter, A.H., 2015a. Field-based crop phenotyping: multispectral aerial imaging for evaluation of winter wheat emergence and spring stand. Comput. Electron. Agric. 118, 372–379.
Sankaran, S., Khot, L.R., Espinoza, C.Z., Jarolmasjed, S., Sathuvalli, V.R., Vandemark, G.J., Miklase, P.N., Carterf, A.H., Pumphrey, M.O., Knowles, N.R., Pavek, M.J., 2015b. Low-al- titude, high-resolution aerial imaging systems for row and field crop phenotyping: a review. Eur. J. Agron. 70, 112–123. https://doi.org/10.1016/j.eja.2015.07.004.
Schor, N., Bechar, A., Ignat, T., Dombrovsky, A., Elad, Y., Berman, S., 2016. Robotic disease detection in greenhouses: combined detection of powdery mildew and tomato spot- ted wilt virus. IEEE Robotics and Automation Letters 1 (1), 354–360.
Seiffert, U., Bollenbeck, F., Mock, H.-P., Matros, A., 2010. Clustering of crop phenotypes by means of hyperspectral signatures using artificial neural networks. 2010 2nd Work- shop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing. https://doi.org/10.1109/whispers.2010.5594947.
Sethy, P.K., Negi, B., Barpanda, N.K., Behera, S.K., Rath, A.K., 2017. Measurement of disease severity of rice crop using machine learning and computational intelligence. SpringerBriefs in Applied Sciences and Technology 1–11.
Shafiekhani, A., Kadam, S., Fritschi, F., DeSouza, G., 2017. Vinobot and vinoculer: two ro- botic platforms for high-throughput field phenotyping. Sensors 17 (12), 214. https://doi.org/10.3390/s17010214.
Shah, M., Vaidya, D., Sircar, A., 2018a. Using Monte Carlo simulation to estimate geo- thermal resource in Dholera geothermal field, Gujarat, India. Multiscale and Multidiscip. Model. Exp. Des. 2018. https://doi.org/10.1007/s41939-018-0008-x.
Shah, M., Sircar, A., Shaikh, N., Patel, K., Thakar, V., Sharma, D., Sarkar, P., Vaidya, D., 2018b. Groundwater analysis of dholera geothermal field, Gujarat, India for suitable applica- tions. Groundw. Sustain. Dev. 7, 143–156.
Shah, G., Shah, A., Shah, M., 2019a. Panacea of challenges in real-world application of big data analytics in healthcare sector. Data, Inf. and Manag., 1–10 https://doi.org/ 10.1007/s42488-019-00010-1.
Shah, M., Sircar, A., Shaikh, N., Patel, K., Sharma, S., Vaidya, D., 2019b. Comprehensive geo- chemical/hydrochemical and geo-thermometry analysis of Unai geothermal field, Gujarat, India. ActaGeochim 38, 145. https://doi.org/10.1007/s11631-018-0291-6.
Shah, M., Sircar, A., Varsada, R., Vaishnani, S., Savaliya, U., Faldu, M., Vaidya, D., Bhattacharya, P., 2019c. Assessment of geothermal water quality for industrial and ir- rigation purposes in the Unai geothermal field, Gujarat, India. Groundwater for Sus- tainable Development 8, 59–68.
Shah, D., Dixit, R., Shah, A., Shah, P., Shah, M., 2020a. A comprehensive analysis regarding several breakthroughs based on computer intelligence targeting various syndromes. Augment Hum Res 5, 14 (2020). https://doi.org/10.1007/s41133-020-00033-z.
Shah, K., Patel, H., Sanghvi, D., Shah, M., 2020b. A comparative analysis of logistic regres- sion, random Forest and KNN models for the text classification. Augment Hum Res 5, 12 (2020). https://doi.org/10.1007/s41133-020-00032-0.
Shakoor, N., Lee, S., Mockler, T.C., 2017. High throughput phenotyping to accelerate crop breeding and monitoring of diseases in the field. Curr. Opin. Plant Biol. 38, 184–192. Silwal, A., Davidson, J.R., Karkee, M., Mo, C., Zhang, Q., Lewis, K.M., 2017. Design, integra- tion, and field evaluation of a robotic apple harvester. Journal of Field Robotics 34 (6),
1140–1159.
Singh, V., Misra, A.K., 2017. Detection of plant leaf diseases using image segmentation and soft computing techniques. Information Processing in Agriculture 4 (1), 41–49.

Singh, V., Varsha, Misra, A.K., 2015. Detection of unhealthy region of plant leaves using image processing and genetic algorithm. International Conference on Advances in Computer Engineering and Applications.
Singh, A., Ganapathysubramanian, B., Singh, A.K., Sarkar, S., 2016. Machine learning for high-throughput stress phenotyping in plants. Trends Plant Sci. 21 (2), 110–124.
Sladojevic, S., Arsenovic, M., Anderla, A., Culibrk, D., Stefanovic, D., 2016. Deep neural net- works based recognition of plant diseases by leaf image classification. Computational Intelligence and Neuroscience, 1–11 https://doi.org/10.1155/2016/3289801.
Slaughter, D.C., Giles, D.K., Downey, D., 2008. Autonomous robotic weed control systems: a review. Comput. Electron. Agric. 61 (1), 63–78.
Spalding, E.P., Miller, N.D., 2013. Image analysis is driving a renaissance in growth mea- surement. Curr. Opin. Plant Biol. 16, 100–104.
Sukhadia, A., Upadhyay, K., Gundeti, M., Shah, S., Shah, M., 2020. Optimization of smart traffic governance system using artificial intelligence. Augment Hum Res 5, 13 (2020). https://doi.org/10.1007/s41133-020-00035-x.
Talaviya, T., Shah, D., Patel, N., Yagnik, H., Shah, M., 2020. Implementation of artificial in- telligence in agriculture for optimisation of irrigation and application of pesticides and herbicides. Artificial Intelligence in Agriculture https://doi.org/10.1016/j. aiia.2020.04.002.
Teke, M., Deveci, H.S., Haliloglu, O., Gurbuz, S.Z., Sakarya, U., 2013. A short survey of hyperspectral remote sensing applications in agriculture. 2013 6th International Con- ference on Recent Advances in Space Technologies (RAST). https://doi.org/10.1109/ rast.2013.6581194.
Teoh, Y.K., Abu Hasan, S., Sauddin Sa Duddin, S., 2013. Automated mango fruit grading system using fuzzy logic. J. Agric. Sci. 6 (1). https://doi.org/10.5539/jas.v6n1p41.
Thomas, S., Behmann, J., Steier, A., Kraska, T., Muller, O., Rascher, U., Mahlein, A.-K., 2018. Quantitative assessment of disease severity and rating of barley cultivars based on hyperspectral imaging in a non-invasive, automated phenotyping platform. Plant Methods 14 (1). https://doi.org/10.1186/s13007-018-0313-8.
Ubbens, J.R., Stavness, I., 2017. Deep plant phenomics: a deep learning platform for com- plex plant phenotyping tasks. Front. Plant Sci. 8. https://doi.org/10.3389/ fpls.2017.01190.
Ullah, A., Ahmad, J., Muhammad, K., Lee, M.Y., 2017. A survey on precision agriculture: technologies and challenges. The 3rd International Conference on Next Generation Computing(ICNGC2017b), pp. 1–3.
Ureña, R., Rodrìguez, F., Berenguel, M., 2001. A machine vision system for seeds quality evaluation using fuzzy logic. Comput. Electron. Agric. 32 (1), 1–20.
van Eeuwijk, F.A., Bustos-Korts, D., Millet, E.J., Boera, M.P., Kruijer, W., Thompson, A., Malosetti, M., Iwata, H., Quiroz, R., Kuppe, C., Muller, O., Blazakis, K.N., Yug, K., Tardieu, F., Chapman, S.C., 2019. Modelling strategies for assessing and increasing the effectiveness of new phenotyping techniques in plant breeding. Plant Sci. 282, 23–39.
Vanegas, F., Bratanov, D., Weiss, J., Powell, K., Gonzalez, F., 2018. Multi and hyperspectral UAV remote sensing: grapevine phylloxera detection in vineyards. 2018 IEEE Aero- space Conference. https://doi.org/10.1109/aero.2018.8396450.
Vijayarangan, S., Sodhi, P., Kini, P., Bourne, J., Wettergreen, D., 2018. High-Throughput Ro- botic Phenotyping of Energy Sorghum Crops. Field and Service Robotics.
Virlet, N., Sabermanesh, K., Sadeghitehran, P., Hawkesford, M.J., 2017. Field scanalyzer: an automated robotic field phenotyping platform for detailed crop monitoring. Func- tional Plant Biology 44.
Waheed, T., Bonnell, R.B., Prasher, S.O., Paulet, E., 2006. Measuring performance in preci- sion agriculture: CART—A decision tree approach. Agriculture Water Management 84, 173–185.
Walter, A., Liebisch, F., Hund, A., 2015. Plant phenotyping: from bean weighing to image analysis. Plant Methods 11, 14.
Wei, F., Yan, Z., Yongchao, T., Weixing, C., Xia, Y., Yingxue, L., 2008. Monitoring leaf nitro- gen accumulation in wheat with hyper-spectral remote sensing. Acta Ecol. Sin. 28 (1), 23–32.
Xiong, Y., Ge, Y., Grimstad, L., From, P.J., 2020. An autonomous strawberry-harvesting robot: design, development, integration, and field evaluation. Journal of Field Robot- ics 37 (2).
Yandun, F., Reina, G., Torres, M., Kantor, G., Cheein, F.A., 2017. IEEE/ASME Transactions on Mechatronics. pp. 1–11.
Zhang, M., Qin, Z., Liu, X., Ustin, S.L., 2003. Detection of stress in tomatoes induced by late blight disease in California, USA, using hyperspectral remote sensing. Int. J. Appl. Earth Obs. Geoinf. 4 (4), 295–310.
Zhang, Chongyuan, et al., 2016. 3D robotic system development for high-throughput crop phenotyping. IFAC-Papers OnLine 49 (16), 242–247.
Zhou, B., Xu, J., Zhao, J., Li, A., Xia, Q., 2015. Research on cucumber downy mildew detec- tion system based on SVM classification algorithm. 3rd International Conference on Material, Mechanical and Manufacturing Engineering, pp. 1681–1684.
Zhu, J., Ingram, P.A., Benfey, P.N., Elich, T., 2011. From lab to field, new approaches to phe- notyping root system architecture. Curr. Opin. Plant Biol. 14 (3), 310–317.
