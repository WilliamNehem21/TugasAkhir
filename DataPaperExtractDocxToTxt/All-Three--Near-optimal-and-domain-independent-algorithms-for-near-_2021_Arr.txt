Array 11 (2021) 100070

		




All-Three: Near-optimal and domain-independent algorithms for near-duplicate detection
Aziz Fellah
School of Computer Science and Information Systems, Northwest Missouri State University, Maryville, MO, 64468, USA



A R T I C L E I N F O


Keywords:
Near-duplicate detection Near-duplicates Approximate duplicates Clustering
Data mining applications and discovery Data cleaning
A B S T R A C T

In this paper, we propose a general domain-independent approach called Merge-Filter Representative-based Clustering (Merge—Filter—RC) for detecting near-duplicate records within a single and across multiple data sources. Subsequently, we develop three near-optimal classes of algorithms: constant threshold (CT) variable threshold (VT) and function threshold (FT), which we collectively call All—Three algorithms. Merge—Filter—RC and All—Three mold the basis of this work. Merge—Filter—RC works recursively in the spirit of divide-merge fashion for distilling locally and globally near-duplicates as hierarchical clusters along with their prototype representatives. Each cluster is characterized by one or more representatives which are in turn refined dynami- cally. Representatives are used for further similarity comparisons to reduce the number of pairwise comparisons and consequently the search space. In addition, we segregate the results of the comparisons by labels which we refer to as very similar, similar, or not similar. We complement All—Three algorithms by a more thorough reexamination of the original well-tuned features of the seminal work of Monge-Elkan's (ME) algorithm which we circumvented by an affine variant of the Smith-Waterman's (SW) similarity measure.
Using both real-world benchmarks and synthetically generated data sets, we performed several experiments and extensive analysis to show that All—Three algorithms which are rooted in the Merge—Filter—RC approach significantly outperform Monge-Elkan's algorithm in terms of accuracy in detecting near-duplicates. In addition, All—Three algorithms are as efficient in terms of computations as Monge-Elkan's algorithm.





Introduction

The problem of identifying whether multiple representations of a real-world entity or object are the same has been originally defined by NewCombe et al. [1]. Since then, this long-standing problem has been studied extensively in computer science and related fields under various names using a multiplicity of terminology; just to name, record linkage [2,3] in the statistics community, approximate matching [4] in infor- mation retrieval, entity resolution [5], object identification [6] in ma- chine learning, merge/purge [4,7,8] and near-duplicate detection [9–18] in databases and algorithms. In large and various databases, a major task in a data cleaning process is identifying sets of records that are seman- tically duplicates of each other, but not syntactically identical. Such type of duplicate records are also referred to as similar, approximate or near-duplicates in research literature. In the context of this paper, we adopt the last terminology, that is, near-duplicates. The most common variations in representing the same entity (i.e., records, objects) with a multitude of representations can primarily arise from typographical er- rors, misspellings, missing data, and differences in abbreviations and
schemes, as well as the integration of multiples data sources into a single data set. In general in data cleaning, near-duplicates may exist within a single source, whereas in data integration near-duplicates may exist within or across various data sources. However, both cases have the same common goal, detecting near-duplicates and the closeness of similarity among entities in a large collection accurately and efficiently. That is, to determine which records/objects in the same or different databases refer to the same underlying real-world entity.
For example, consider the following references that have been recorded at three different colleges, “Jeff David Ullman Stanford Univer- sity, Dept. of Computer Science”; “Jeffrey D. Ullman Computer Science Dept., Stanford Univ., CA, USA”; “J. D. Ullman, Department of Computer Science, Stanford University, USA”. All the three references refer to the same in- dividual, even though they are quite different if byte-by-byte compari- sons are used. It is often the case that data in different repositories hold information regarding identical entities, but might be stored in different formats and schemes which may result in a possible data inconsistency and nonconformity. One example would be identifying authors and ci- tations in a bibliography database such as DBLP, CompuScience, and


E-mail address: afellah@nwmissouri.edu. https://doi.org/10.1016/j.array.2021.100070
Received 20 February 2021; Received in revised form 5 May 2021; Accepted 12 May 2021
Available online 27 May 2021
2590-0056/© 2021 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).


CiteSeer. Several algorithms, in particular domain-dependent, for quan- tifying the degree of similarities have received particular attention in a wide range of applications, including web search engines and mining, medical and census data, plagiarism and spams, mailing list deduplica- tion, and image database. A substantial body of research has been con- ducted in a spectrum of domains, see for example [19–28].

Background and related work

Naive near-duplicate detection methods which are based on comparing every pair of records become intractable in the context of huge data collections such as social networks. For example, Facebook with over 2.97 billion active users worldwide, results in more than 2.45
× 1019 comparisons. Several methodologies and solutions have been proposed in research to reduce the total computational cost and improve the accuracy. In a stand-alone literature review, a variety of blocking methods which are based on the selection of a key (blocking key) for generating subsets of potential near duplicates have been investigated in research [5,11,29]. The main focus of these methods is that records having the same key value should be added to the same block and labeled as potential near-duplicates for further analysis. Jaro and Winkler [3,24, 30] extended the key-based approach by using expressions with multiple keys which increases the accuracy and reduces the number of false matches and false misses. Such keys can be adjusted interactively by trial-and-error analysis to achieve the best results. However, the process of finding a perfect key is often difficult and requires good domain knowledge. Other related blocking criteria based on applications’ char- acteristics (i.e., medical, census, bibliography data) are also used as a first-step preprocessing to identify initial blocking. In general, blocking algorithms are of low time complexity, but with several drawbacks. For example, records with minor typographical errors or simple misspelling are clustered in different blocks. It has been observed in Refs. [23,24] that 40–70% of the matches are found in the first blocking pass. By the fourth blocking pass, 0.0001% of the pairs are actually duplicates. These results show that the proportions of pairs that were duplicates in suc- cessive blocking criteria fell at an exponential rate. A well-known duplicate detection framework known as sorted neighborhood method (SNM) was proposed by Hernandez and Stolfo [8,31] and is based on that near-duplicates tend to localize in the neighborhood. The algorithm uses blocking to sort all records based on a sorting key and then slides sequentially a window of fixed size (sliding window) over the sorted re- cords. The window uses the blocking scheme by including all records with similar keys (lexically nearby keys) in the same window. All records within each sliding window are considered as potential near-duplicates and then compared with each other, however, the window size is diffi- cult to set. Overall, the sliding window is a more robust approach than other techniques in improving the near-duplicate detection accuracy, but it is likely to fail in grouping similar records outside the window size if substantial typographical errors occurs in the first characters of the sorting key. Moreover, there is substantial research that has been pro- posed as an umbrella for SNM where blocking has been empirically evaluated on different domains and data sets. Some of these extended variations of SNM and blocking approaches outperform the basic SNM and blocking approaches in terms of reducing the complexity cost and improving the accuracy. For instance, Yan et al. [7] proposed an adaptive variant scheme of SNM for record linkage by adjusting the size of the sliding window dynamically during the execution time to build non-overlapping blocks, but it has been confirmed that their work did not outperform the original SNM. Other complicated near-duplicate identi- fication techniques such as q-gram, iterative blocking, overlapping blocking, multiple blocking, token-based, learning process, and domain knowledge, with some assumptions on the entities have been investi- gated in the literature, just to name few [5,25,32–34].
Furthermore, with rapid advances in big data computing and web era,
near-duplicate detection research is expanding in many ways to industry applications such as managing massive documents, and extracting

insights and multi-dimensional information from business, financial (i.e., credit cards), and healthcare data. A comprehensive evaluation and an umbrella of techniques have been investigated. A common factor be- tween these algorithms is they cannot guarantee finding all near- duplicates and also cannot guarantee the accuracy. Vogal et al. [35] provided an annealing standard to evaluate near-duplicate detection results. In other words, the accuracy and completeness of duplicates should converge incrementally and interatively to a gold or silver stan- dard that defines which records represent the same real-world entities.
Near-duplicate detection algorithms mainly focus on effectiveness and efficiency, but not on scalability which has been addressed by Naumann et al. [36], who assign appropriate similarity measures to at- tributes based on their semantics. For instance, names of persons should be compared differently than email addresses even though they belong to the same string data type. Overall, most of these methods require a good understanding of the application domain and a supervised user interac- tion for refining and adjusting parameters such as distance functions, window size, and thresholds.
The most predominant domain-independent algorithm for near- duplicate detection is that of Monge-Elkan (ME) [4,14]. This seminal work is based on stretching adequately the SNM's sliding window [8] that holds a fixed number of record sets and grouping records into clusters.
Monge-Elkan's algorithm has a much more improved efficiency over many duplication methods including the SNM algorithm, but has the same detection accuracy as the SNM and performs even far better than a large number of other algorithms in terms of time and accuracy. In addition, a spectrum of similarity and distance measures, highly depen- dent on the application domain, have been investigated in the literature and are certainly not a new area of research. They range from fairly simple schemes to more complex well-tuned edit distances. The most prominent class of character-based metrics known as edit distances are Levenshtien, Jaro-Winkler, and Smith-Waterman similarity measures [3, 30,37]. One extension to the Levenshtein distance is the Needleman-Wunsch [38], which additionally allows variable sub- stitution's cost for different characters. That is, it provides a mapping for each pair of symbols (i.e., characters) from the alphabet to some cost. Other effective similarity measures, token-based and hybrid metrics, have been also investigated in the literature, for example, Jaccard, n-grams, Cosine, Monge-Elkan, and natural language processing tech- niques (i.e., TF-IDF) similarity measures. Similarity metrics range from fairly simple schemes to more complex well-tuned edit distances, see for example, [11,13,37,38].

Contributions

We propose a new generalized domain-independent framework and subsequently three classes of algorithms for detecting near-duplicates among entities within one or more attributes in large database sets. These algorithms are synthetically complemented by near-duplicate
generator algorithm (NDG). In the rest of the paper, we refer to such a
framework as Merge-Filter Representative-based Clustering (Mer- ge—Filter—RC) and to such a set of algorithms as constant threshold (CT), variable threshold (VT), and function thresholds (FT), respectively. For convenience, we collectively refer to these three algorithms as All—Three algorithms and to a specific algorithm by its conventional name, either CT, VT, or FT. In addition, we integrate an efficient synthetic near- duplicate generator algorithm (NDG) into All—Three algorithms. The
NDG algorithm is capable of scaling up to generate algorithmically tens of
millions of synthetic records. One of our aim here is to capture and modify the full power of Monge-Elkan (ME) [4,14] and Smith-Waterman (SW) [37] algorithms in the context of our work. That is, Mer- ge—Filter—RC is a domain-independent approach that combines the token-based of Monge-Elkan and the character-based internal of Smith-Waterman similarity function, both of which we modified and augmented with a well-tuned affine parameterization. Still, this is not enough to solve the quality and complexity of our approach due to



anomalies which are associated with the transitivity relation and threshold choices. Thus, we segregate the results of the comparisons by labels which we refer to as very similar, similar, or not similar, and furthermore minimize an objective function without the user's inter- vention. Each constructed cluster has one or more representatives which are dynamically computed to measure the prototypicality of each record in the cluster. The record comparison is performed with only represen- tatives rather than with all records in the cluster. Thus, records do not have to be compared to all other records, but to only cluster represen- tatives which are considered for subsequent comparisons. We introduce cluster representatives which retain the most relevant syntactic and se- mantics features of the records in the cluster. The idea behind this approach is that cluster representatives reduce the total number of record comparisons, without reducing substantially the accuracy of the dupli- cate detection process.
Clusters’ representatives are dynamically distilled and accurately achieved throughout a set of comparison functions, very similar, similar, or not similar, and threshold settings, constant, variable, or function. The number of similarity comparisons is reduced from O(n2) to O(nm), where m and and n are the number of representatives and records, respectively and m ≪ n, m is always independent of n, but dependent on the class of the algorithm. Each of these algorithms has a different impact when running on a set of thresholds, a constant, variable, or function. All al- gorithms are implemented in C++ and use the same data set to make fair comparisons. We ran an extensive experimental study using several real benchmarks and algorithmically generated synthetic data. We do not assume any specific structure in the data nor rely on any information available in the source data. That is, data has not been standardized, preprocessed, nor transformed, and syntactic as well as semantic errors remain as potential errors in the data. Experimental implementations show the Merge—Filter—RC detection approach greatly reduces the number of comparisons and the precision achieves a value of nearly 1.0, a precision which is close to the optimal outperforming consistently the seminal work of Monge-Elkan.
Our proposed set of algorithms do not presume a specific application domain, but in contrast they are tuned toward any domain-independent applications. Monge-Elkan's (ME) algorithm is relatively domain- independent with the purpose of integrating and matching web scienti- fic papers from multiple sources, typically an alphanumeric domain class. The parameters used in ME are mapped to such a class of applications with only a restricted possibility of tuning the threshold values to provide a better accuracy. In addition, the heuristic method of ME minimizes the number of pairwise record comparisons with potential record duplicates and integrates some key concepts such as the minimum edit-distance of SW.
The rest of the paper is organized as follows. Section 3 reviews and summarizes the effectiveness of Monge-Elkan and Smith-Waterman al- gorithms. Section 4 addresses the metric measures used in detecting near- duplicates. Section 5 explains how to calculate and choose between precision and recall using F-measure. The choice, adjustment, and threshold tuning are defined in this section.
Section 6 proposes the merge-filter cluster representative framework which addresses the details of the accuracy performance using cluster representatives throughout precision and recall metrics. Section 7 pro- vides a fully algorithmic technique and presents three different domain- independent algorithms, constant, variable, and function thresholds for detecting near-duplicates, all of them under the umbrella of Merge—Filter—RC.
Effectiveness of Monge-Elkan and Smith-Waterman algorithms

In this paper, we focus on the Smith-Waterman (SW) edit distance
[37] that was originally developed for identifying common molecular subsequences, like DNA or proteins. Two strings x and y may not be entirely similar but contain regions, perhaps in the middle, that exhibit high similarity. Finding such a pair of regions, one from each of the two strings, is referred to as a local alignment. The Smith-Waterman algorithm finds the local alignment between two strings with the maximum possible score using a dynamic approach that runs in O(|x||y|) time. The main limitation of SW is it places heavier penalties (i.e., higher cost) on mis- matches in the middle of strings rather than at the beginning and the end of strings. This may create a problem when the errors are in the middle of the strings. In this regard and in order to eliminate this inconvenience, we primarily consider the Monge-Elkan's methodology [14,26], a
well-tuned matching methodology normalized in the interval [0; 1],
allowing additional parameters, and introduces gaps in the alignment of two strings. Much of the power of the Monge-Elkan's algorithm is due to its ability to include sequences of non-matching characters, gaps (affine gaps), in the alignment of two strings. In our work, we add the gap cost as another variant of the Smith-Waterman (SW) algorithm that offers a solution to the above problem and other related duplicate detection is- sues. By adding a cost, we extend the two extra edit operations, starting gap and extending gap.
In general and for instance, the gap penalty denoted by cost(gap) = s
+ e × l, where s is the affine cost of starting a gap in an alignment, e is the cost of extending a gap, and l is the length of a gap in the alignment of two
strings. Usually affine gap penalizes gap extension less than gap opening (e < s) thus we decrease the penalty for contiguous mismatched sub- strings by using a single long gap over many short gaps. Since the dif-
ferences between near-duplicate records often arise because of many abbreviations or extra-string insertions and omissions, the affine-gap model produces a better similarity and more accurate results than most the other edit distance metrics. Moreover, the affine-gap algorithm per- forms well to detect similarities when records have minor syntactical differences, including typographical errors, abbreviations, and trunca- tions. In fact, the Monge-Elkan's algorithm approximates the solution to the optimal assignment problem in combinatorial optimization. This approximation is a reasonable trade-off between accuracy and complexity.
In sum, Monge-Elkan's complexity is quadratic in number of tokens and one can define the Monge-Elkan's measure over two text strings that contain several tokens as:

MongeElkan x; y   1    max sim x i ; y i
|x| i=1  j=1;|y|

where |x| and |y| are the number of tokens in x and y, respectively and sim(x, y) is an internal similarity function to measure the similarity be- tween two individual tokens.
In the paper, we adopt a modified version of the Smith-Waterman similarity edit distance as inter-token similarity measure. Formally, let c(xi, yi) denote the cost of the edit distance that aligns ith character of string x to jth character of string y. Then the SW algorithm computes a cost matrix M that represents a maximum-cost string alignment by the following recurrence rule based on Monge-Elkan's algorithm [4].
8>M(i—1;j—1)+c xi;yj 

In Section 8, we present a thorough experimental evaluation of our
approach and compare the effectiveness of All—Three algorithms in terms of accuracy and efficiency with the seminal work of Monge-Elkan. We used benchmark data as well as synthetic data to meet specific con-
ditions that are not available in existing real data. Synthetic data has been
M(i;j)=
M(i—1;j)+e	if align(i—1;j—1) ends in a gap
M(i—1;j)+s	if align(i—1;j—1) ends in a match
M(i;j—1)+e	if align(i—1;j—1) ends in a gap
:M(i;j—1)+s	if align(i—1;j—1) ends in a match

generated using the near-duplicate generator (NDG) algorithm. Section 9 concludes the paper with potential and future research directions. In addition, we provide an appendix to make our paper self contained.
Metric measures and threshold effects

Similarity refers to a measure of likeness between two objects (i.e.,



records, entities); and the dissimilarity between two objects is refereed to as a distance. We define a record as a set of tokens drawn from a finite universe C. Let n be the number of real-world entities over a plurality of
large databases that consist of records Rn = r1; r2; …; rn, where a large
number of ri are potential near-duplicates. We denote by Ð = Ð1; Ð2;
…; Ðd the set of problem domains.
Similarity and distance measures are often normalized in the range [0; 1], and [0; ∞] or [0; some distance], respectively. Formally, we define a similarity and distance measures as follows:
Definition 5.1. A similarity measure is a non-negative function sim: Ð1 × Ð2 → [0,1], such that sim(r1, r2) = 0 if r1 and r2 are least similar and sim(r1, r2) = 1 if r1 and r2 are identical. (Ð1 might be equal to Ð2).
Definition 5.2. A distance measure is a non-negative function dist: Ð1 × Ð2 → [0, 1], such that dist(r1, r2) = 0 if r1 and r2 are exactly similar or identical, and dist(r1, r2) = 1 if r1 and r2 are not similar.
The search space for detecting near-duplicates can be reduced under the assumption the relation “is duplicate of” or “is similar to”, is transitive. However, the theory of transitivity is not always flawless in practice because of the propagation of errors as explained earlier. Duplicate re- cords tend to be sparsely distributed over a large database space and the propagation of errors is statistically insignificant [26]. The complexity and evaluation measures to assess a near-duplicate record algorithm that have been addressed are the efficiency and accuracy. Accuracy is considered the most important quality assessment dimension in near-duplicate algorithms, and it is measured in terms of two prominent measures, precision and recall. The other related measure is F-measure which determines the harmonic mean of the precision and recall values. The goal of our evaluation is to find the best metrics in terms of quality and effectiveness with respect to different domain-independent data sets. We classify each value pair of comparisons as very similar, similar, or not similar since errors may occur during the process of detecting near-duplicates. For completeness, as it is illustrated in Fig. 1, we divide the search space into subspaces and denote by true positives all candidate pairs that are correctly declared to be duplicates (i.e., expected matches), and false positives all candidate pairs that are incorrectly declared to be duplicates while in fact they may not be duplicates (i.e., there should not be a match).
Similarly, true negatives are pairs that are correctly recognized as not
being duplicates (i.e., expected mismatch), and false negatives are pairs that are not declared to be duplicates while in fact they are (i.e., there should be a match). The metric precision measures the fraction of correct duplicates over the total number of record pairs classified as duplicates by the algorithm. The metric recall measures the fraction of records correctly clustered over the total number of duplicates. A high recall means no false misses and a high precision means few false matches; thus, there is a trade-off between high recall and high precision. The other measure we want to introduce is the reduction ratio, which is the relative reduction in the number of pairs to be compared. This means a search space reduction strategy is needed in order to reduce the number of record comparisons. As a consequence, we introduce prototype cluster

Fig. 1. Similarity threshold factors and tradeoff between prominent mea- sure metrics.
representatives which retain the most relevant syntactic and semantics features of the records in the cluster where comparisons take place with cluster representatives, instead of all records, thus the search space can be reduced with the improvement of both true and declared subspaces. In other words, the reduction of false positives and in particular false neg- atives have an impact on the accuracy. A high recall means no false misses and indicates high accuracy of the duplicate detection results. A high reduction ratio achieves an even more effective search space reduction. A high precision means few false matches and has the opposite
effect than recall. The other metric measure, reduction ratio in the range of [0; 1], is defined as 1 - (declared duplicates/all tuple pairs). The simi- larity threshold line in Fig. 1 ensures a trade-off among recall, precision and reduction ratio. If we shift the similarity threshold line (similarity
threshold 1) to the right, consequently more tuple pairs will be rejected and increase the reduction ratio and precision. This rejection would ul- timately lead to decrease the recall metric. If we shift the similarity threshold line to the left then the opposite trade-off effect between recall, precision, and reduction ratio will take place. Similarly and in the same fashion, shifting the similarity threshold line (similarity threshold 2) would have an effect on true and false positives.
Relations between threshold similarity metrics and accuracy are an important part of the near-duplication detection process. Different threshold setting and parameter tuning (i.e., distance functions, window size) have been used to classify whether a pair of records is a duplicate or a non-duplicate. Several experiments have been conducted and cutoff thresholds for a specific application domain with its own characteristics, often manually configured, have shown to achieve the “best” precision, recall and F-measure values. The cutoff value of the threshold along with other key tuning parameters can be very time consuming as the search space can grow exhaustively and even exponentially, which necessitates some forms of threshold optimization [35,39,40].

Merge-Filter Representative-based Clustering: A near-optimal domain-independent approach

Similar in spirit to divide and merge methodology for clustering [41], Merge-Filter Representative-based Clustering (Merge—Filter—RC) com- bines a top-down divide phase with a bottom-up merge phase in a hier- archical scheme as described in subsequent sections. Merge—Filter—RC is made of two trees, a top-down and bottom-up tree, annotated with cluster records. Merge—Filter—RC is mainly geared towards the needs of detecting near-duplicates with a provision of forming the best possible near-optimal clusters of records by integrating a variant of Smith-Wa- terman's and Monge-Elkan's algorithms into the detection approach. Importantly, we are only interested in unconstrained algorithms, rather than adopting any standard clustering algorithm. That is, there is no preliminary assumption of rationality to choose the number of clusters as input or other domain specific parameters. Let C denote the initial cluster
containing n records in Rn, and d denote the depth of a node in the
top-down cluster tree T whose root (C; n) is at d = 0 and internal nodes are (C i, nb), where Ci and nb refer to the name of the cluster and the
number of records in C i, respectively as illustrated in Fig. 2. The divide phase of Merge—Filter—RC recursively splits the collection of records into two equal halves at each level of T and constructs the tree T on the basis of these records. The near-duplicate detection process starts with the data set of the initial cluster C that is expected to contain near-duplicate records. We start the construction at the root with n re- cords and end-up at the leaf level with one single record per cluster, (C l, 1) (Fig. 2). The number of times the split is done is exactly equal to the height of the tree T, O(log n), because the size of the clusters decreases approximately by half at each level of T which is defined as follows:
Definition 6.1.  A top-down cluster tree T is a full binary tree such that
(i) the nodes of T are subclusters of C (ii) every internal node of T has two subcluster of records, each of size n/2d, (iii) every leaf of T is a subcluster of records of size one; (iv) the root node of T is the cluster C that consists




Fig. 2. Construction of a top-down cluster tree T.


of n records. Let ℂ = C

1; C 2; …; C n


be the set of clusters of T produced by the
similarity score. Let such a set of cluster representatives denoted by 1^ i =
{^ri1;^ri2;…;^rij}, 1 ≤ j ≤ l where l indicates the number of representatives
for a fixed i. ^	k and ^	l, where l is much less than k. Every

i	i 
such that∣ C i∣= n/2d and 1 ≤ i, i ≤ n (Fig. 2). Let T be a top-down cluster	k	l

tree then for any two clusters we have either C i ⊂ C j or C j ⊂ C i or
C i ∩ C j = ∅, i /= j, 1 ≤ i, j ≤ n.
Starting at the leaves of T, the bottom-up merging phase is applied recursively to each node of T towards the root enabling the construction of a new tree of clusters whose root is T^ as depicted in Fig. 3. To accomplish this, the near-optimal cluster of an interior node C^ i in the tree T^ is obtained by merging and distilling dynamically the near-optimal clusters of the left and right children of C^ i . The result of clustering T is a partition C^ = C^ 1; C^ 2; …; C^ q where one or more C^ i are the nodes of T^,
referred to as near-optimal duplicate tree, i ≤ q and q ≪ n (q is much less
than n). The value of q is not known in advance and is independent of n. At the beginning of the Merge—Filter—RC bottom-up phase, we initialize the set of leaf clusters of T^ with the set of leaf clusters of T. Then, we apply a hierarchical agglomerative clustering to the leaf clusters by bringing the leaves up to the root level by level, and near-optimizing the objective function locally at each iteration when two clusters are compared and eventually merged. The choice of the objective function uses the dynamic programming of SW algorithm refined by different parameters as it will be explained in the next sections. Each constructed cluster C^ i has one or more cluster representatives that are dynamically computed to measure the prototypicality of each record in the cluster. The record comparison is performed with only representatives rather than with all records in the cluster. Consequently, records do not have to be compared to all others but only cluster representatives are considered for subsequent comparisons. That is, if a given record is not similar to a record(s) in a set of cluster representatives then it will not match the other record members of the cluster. In general, Merge—Filter—RC takes as parameters two unordered pairs of clusters (C^ i , C^ j ), and their respective cluster representatives (1^ i , 1^ j ) where 1 ≤ i, j ≤ n, then returns whether (C^ i , C^ j ) are very similar, similar or not similar by finding the optimal local alignment using the SW algorithm with the maximum
duplicates and cluster representatives referred to as {rij}j=1 and {^rij}j=1, respectively. The results of detecting near-duplicates, however, may become sensitive to the initial selection of representatives. Initially, Merge—Filter—RC uses one record as a cluster representative, then rep- resentative(s) might be subsequently updated, either by retaining the same ones or iteratively re-computing and re-assigning new representa- tives. In addition, Merge—Filter—RC enforces transitivity between re- cords in a cluster C^ i . Each remaining record is compared to the representatives and placed in the cluster of the closest representative. The idea behind this approach is that cluster representatives reduce the total number of record comparisons, without reducing substantially the accuracy of the duplicate detection process. The number of similarity comparisons to be considered is reduced from O(n2) to O(nm), where m and and n are the number of representatives and records, respectively. m
≪ n and m is always independent of n, but dependent on the class of the algorithm (constant, variable, or function).
The cornerstone property of Merge—Filter—RC is based on the choice of the appropriate objective function g and its parameters. We are interested in finding locally the optimal clustering at each level of T^, and also finding globally the near-optimal clustering at the root created by the Merge—Filter—RC merge phase. That is, g should guarantee to find
the optimal local alignment, OPT(A), and quantifies the similarity in
terms of a high-scoring alignment A. That is, we maximize the objective function g by assigning a score for each alignment obtained by the SW algorithm. Let Σ* denote the set of finite words over an alphabet Σ and x
= x1…xp, y = y1…yq where x, y ∈ Σ*. The state space of all alignments of
x and y is the mapping g: (〈x; y〉) '→ Z, the set of integers. The optimal local alignment score of the subsequences x1…xp and y1…yq is obtained by maximizing g among all alignments. That is,
g0(〈x; y〉)= max g(〈x; y〉)
A




Fig. 3. Vizualization of a near-optimal duplicate cluster tree T^.



OPT(A) = argmaxg(〈x; y〉)
A

Let.
C^ l and C^ r be the left and right children of an internal node C^ in T^. Let NEAR — OPTDUPTREE(C^ ; i) be the near-optimal duplicate sub-tree for the node C^ using i clusters as stated recurrently in the following theo- rem. The space of near-optical solutions is represented in a data structure. That is, a tree that can be efficiently used to find near-optimal solutions that satisfy the optimal local alignment. Near-optimal and recursively constructed bottom-up subtrees, DUPTREE(C^ ; i), facilitate the re- optimization (i.e., tuning) in the object function g to satisfy the proper- ties and accomplish the near-optimality solution. Thus, each subtree of the node C^ using i clusters, DUPTREE(C^ ;i), transparently represents the space of near-optimal solutions and how each subtree relates to each other. We propose the following theorem which formally and compactly describes the near-optimal detection solution along with the corre- sponding objective function g. We explore the clustering methodology of
[41] further and formally introduce near-optimal duplication tree of a node C^ using i cluster defined as NEAR — OPTDUPTREE(C^ ; i). The objective function values of each alignment obtained by the SW algo- rithm guarantee the optimal local alignment across all subtrees of T^.
Theorem 6.1.  NEAR — OPTDUPTREE(C^ ; i) = 
cluster. However, (r1, r3) and (r2, r3) would be non-duplicates. Now, consider a new record r4 added to R3 with sim(r1, r4) = 0.75, sim(r2, r4) = 0.88, and sim(r3, r4) = 0.96. Then, (r2, r4) and (r1, r4) are classified as
near-duplicated and non-duplicated, respectively. However, due to the anomaly in the transitivity relation and the non-appropriate choice of the threshold, the pair of records, (r1, r4) and (r2, r3), would be reclassified as near-duplicates although there were not. This is an important note that should largely foster the choice of appropriate thresholds for larger data sets. With our proposed approach, the results of the comparisons are segregated by labels referred to as very similar, similar, or not similar; and the quality and accuracy of the classification is further improved by finding near-optimal or sub-optimal thresholds to identify more accu- rately duplicate records by minimizing the objective function without the users intervention. With this viewpoint and based on the SW algorithm, we start computing the optimal clustering for the leaf nodes and then find the near-optimal clustering, relatively to the optimal local alignment, for any internal node. That is, at the end of the SW algorithm during the merge phase, NEAR — OPTDUPTREE(T^) gives the almost optimal clus- tering. We consider two upper and lower bound threshold values, θl and θu, which are extensively studied in domain independent large databases. Both bounds which are rooted in the seminal Monge-Elkan's algorithm have shown effectiveness as they become core standard thresholds in research literature [39,40,42] and in almost every approximate duplicate detection algorithm. The two upper and lower bound threshold values
are mainly governed by the probability of errors for finding optimal re-

C^
NEAR — OPTDUPTREE

where
C^ l ; j
∪ NEAR — OPTDUPTREE
 C^ r ; i — j
if i = 1 if i > 1
cord alignments. Thus, we set the semantic similarity threshold param- eter for which two records are considered semantically similar to θu. In the same way as semantically similar records, we set the non-similarity threshold to θl.
We set θu to 0.7 and θl to 0.5 for declaring two records as near-

j=argming NEAR—OPTDUPTREE C^ l ;j ∪NEAR—OPTDUPTREE C^ r ;i—j 


Proof. We proceed by induction on i. The base case handles all clusters of T^. That is, all initial clusters C^ 1; C^ 2; …; C^ q with a single represen- tative that is generated in the divide phase. Starting at the leaves, the first optimal clusters are originated from the SW algorithm. If two records are in the same cluster then they are considered to be near duplicate or similar, and if not they are dissimilar.
duplicate and non-duplicate, respectively. θ ≤ θl produces loose simi- larity (not similar), θ ≥θu produces high similarity (very similar), and if θ falls between these values it is regarded as a regular similarity (similar). Let C^ l and C^ r be the left and right children of an internal node C^ whose cluster representative is 1^ . We denote by 1^ l and 1^ r the left and right cluster representative children of 1^ . As a consequence of Theorem 6.1, we state the following result.
Corollary 6.1.  NEAR — OPTDUPTREE(1^ ; i) = 

For the induction case, we can now assume the claim is true for all i, 1
< i < n. Let inode(T^) be an internal node of T^, and T^1 and T^2 the left and right subtrees recursively build from the leaf clusters of T^, respectively. Without loss of generality, define C^ 1l and C^ 1r to be the clusters whose
1^
NEAR — OPTDUPTREE

where

 1^ l ; j

∪ NEAR — OPTDUPTREE

1^ r ; i — j
if i = 1 if i > 1

root is T^1; and C^ 2 l and C^ 2 r be the clusters rooted in the right subtree T^2,
j = argmin g(NEAR— OPT
 1^ ;j ∪NEAR— OPT
 1^ ;i — j 

ordered as (C^ 1 ; C^ 1 ); (C^ 2 ; C^ 2 ). Denote by (1^ 1 ; 1^ 1 ) and (1^ 2 ; 1^ 2 ),
the set of cluster representatives of (C^ 1l ; C^ 1r ) and (C^ 2 l ; C^ 2 r ), respec-
≤j<i

tively. Let 1^ 1l = 1^ 1l ∪ 1^ 1r and 1^ 2 r = 1^ 2 l ∪ 1^ 2 such that 1^ i = p > 1

r		 

repre sent ative which is used for subsequent comparisons. Importantly, representative clustering reduces the total number of record comparisons substantially and furthermore representatives are bounded by two sim- ilarity threshold values, θu and θl. Keeping this potential of multiple
l	r	l	rcluster representatives, C^ = C^ ∪ C^  and C^ = C^ ∪ C^ . For

Competitive algorithms

We introduce three classes of algorithms from different perspectives, a constant threshold (CT), a variable threshold (VT), and a function threshold (FT) algorithm, collectively referred to as All—Three algo- rithms. Each of these algorithms has a different impact when running on various benchmarks and synthetic data sets.

convenience, let 1^ 1l = {^rl
l
1;2
; …; ^rl1;p} and 1^
2l = {^rl
l
2;2
; …; ^rl
2;p }.

Similarly 1^ 1r and 1^ 2 r are defined. If two records (i.e., representatives) are in the same cluster then they are considered to be near-duplicates or exactly similar, and if not they are dissimilar. For instance, let R3 = {r1;
r2; r3} be the set of records to be compared and the initial good threshold chosen is in the interval [0.83⋯0.90]. Assume we have the following
similarities: sim(r1, r2) = 0.88, sim(r1, r3) = 0.72, and sim(r2, r3) = 0.80. Then, (r1, r2) are classified as near-duplicates and assigned to the same
Constant threshold (CT) algorithm

We use the same notations in line with Section 6. Let T^ be the bottom- up cluster tree, and T^1 and T^2 the left and right subtrees recursively build from the leaf clusters of T^, respectively. Assume n, the number of records, is a power of 2 for the sake of convenience. The output of the approxi- mate duplicate SW merge phase is a partition of clusters C^ = C^ 1;C^ 2;…;

C^ q , where each C^ i is a node of T^ and q is unknown in advance. Without

Algorithm 1 (continued )



loss of generality, let assume C^
^ l	^ r
1l and C^
1r be the clusters whose root T^1;
3: Compare (C^ 1 l , C^ 2 l ) \(⊳\) comparison of C^ 1 l with C^ 2 l
4: if (C^ 1 l , C^ 2 l ) are very similar then

and C 2
and C 2 be the clusters rooted in the right subtree T^2 of T^,	l	l

ordered as (C^ 1l ; C^ 1r ); (C^ 2 l ; C^ 2 r ).
The procedure CONSTANT THRESHOLD (C^ 1l ; C^ 2 l ) in algorithm 1 is based on the idea of the Merge—Filter—RC approach which compares and subsequently updates two given clusters, either by merging them into a new cluster and removing one of the original cluster. Moreover, the al- gorithm iteratively recomputes and reassigns new representatives. Each
record is compared to the representatives and placed in the cluster of the
5: C^ new ← Merge (C^ 1 , C^ 2 ) 6: Remove C^ 2 l
7: 1^ new ← 1^ 1 l \(⊳\) cluster rep. ← rep. of C^ 1 l
8: end if
9: if C^ 1 l , C^ 2 l are similar then 10: 1^ new ← Merge (C^ 1 l , C^ 2 l ) 11: Remove C^ 2 l
12: 1^  ← ^ l  ^ l \(⊳














^ l	^ l

closest representative. The number of comparisons is reduced from O(n2) to O(mn), where reduced m and n are the number of representatives and records, respectively (m is much smaller than n).

Variable threshold (VT) algorithm
new  11 ∪ 12	\) cluster rep. ← rep. of C 1 ∪ rep. of C 2
13: end if
14: if (C^ 1 l , C^ 2 l ) are not similar then
15: no operation
16: end if
17: Goto step 1 and compare (C^ 1 l , C^ 2 r ) 18: Goto step 1 and compare (C^ 1 r , C^ 2 l )

In procedure V
^ l  ^ l
19: Goto step 1 and compare (C^ 1 r , C^ 2 r )

ARIABLE THRESHOLD (C 1 ; C 2 ) in algorithm 1, each
cluster has only one representative and only one variable threshold value is considered, starting at θ1 = 0.5. In line with the approximate duplicate SW algorithm, the variable threshold algorithm (VT) compares clusters from the left subtree with clusters from right subtree. That is, we compare

20: return ( ^ 1 l ^ 2 l )\(⊳\) returns cluster representatives 21: end procedure

1: procedure VARIABLE THRESHOLD (C^ 1 , C^ 2 ) \(⊳\) VT algorithm
2: Compare and find SW of ^r1 and ^r2 \(⊳\) at start θ1, θ2 are 0.5 for C^ 1 , C^ 2

C^ 1
l with C^
2l and C^
2r , then we compare C^
1r with C^
2l and C^
2 r .
3: if (SW > θ1 or (SW > θ2 ) then
4: if (θ1 > θ2) then

Without loss of generality and for algorithmic simplicity, we assume cluster C^ 1 has ^r1 as a record representative and θ1 as a threshold. Sim- ilarity, C^ 2 has ^r2 as a record representative and θ2 as a threshold. At start, clusters have one record and the threshold value θ1 is set to 0.5.

Function threshold (FT) algorithm

In this third category of algorithms each cluster has more than one representative. Furthermore, two variable threshold values are consid- ered, an upper bound value θu = 0.7, and a calculated threshold value θc. In line with the approximate duplicate SW algorithm, the function threshold algorithm (FT) compares clusters from the left subtree with clusters from right subtree. That is, we compare C^ 1l with C^ 2 l and C^ 2 r ,
5: Merge (C^ 1 , C^ 2 )
6: Remove C^ 2
7: Set representative ← ^r1 \(⊳\) update representative to ^r1 8: θ1 ← (θ1 +SW)/2 \(⊳\) update θ1
9: end if
10: if (θ2 ≥θ1) then
11: Merge (C^ 1 , C^ 2 )
12: Remove C^ 1
13: Set representative ← ^r2 \(⊳\) update representative to ^r2 14: θ2 ← (θ2 + SW)/2
15: end if
16: else
17: C^ 1 and C^ 2 are not similar 18: no operation
19: end if
20: end procedure

then we compare C^
1r with C^
2l and C^
2r . In addition, we compare C^
r		
1	1: procedure FUNCTION THRESHOLD (C^ 1 l ; C^ 2 l ) \(⊳\) FT algorithm

with every cluster in the second half subtree.	l

The function COMPARE (C^ 1; C^ 2) shows the very similar case when max SW > θu (lines 4 and 5). The other two cases, similar (θl ≤ max SW ≤ θu) and not similar (max SW < θl), can also be treated
in a same manner. Lines 4 and 5 in the function COMPARE (C^ 1;C^ 2) should be substituted by lines 4 and 5 in the function CHECK-SIMILARITY (C^ 1;C^ 2), respectively. In the same way, lines 11 and 12 should be substituted by lines 4 and 5. For the case of no similarity, lines 4 and 5 in the function
2: Find max SW between C^ 1 and every cluster in T^2 3: Suppose maxSW is between C^ 1 l and C^ 2 r
4: if (max SW > θu ) then
5: Merge (C^ 1 l , C^ 2 r ) 6: Remove C^ 1 l
7: Representative ← representative of C^ 2 r
8: end if
9: if (θc ≤ max SW < θu ) then

COMPARE (C^ 1; C^ 2) should be substituted by lines 7 and 8 in the function
10: Merge (C^ 1 l , C^ 2 r ) 11: Remove ^ r

Check-Similarity (C^ 1; C^ 2).
In the same way lines 11 and 12 should be substituted by lines 7 and
Let 1^ 1 and 1^ 2 be the set of the cluster representatives of C^ 1 and C^ 2, respectively such that 1^  = p and 1^	= q, where p, q ≥ 1. For algo-
C 2
12: Representative ← Union of representatives 13: end if
14: if (max SW < COMPUTE(θc) then
15: no operation
16: end if

rithmic convenience, let assume that q ≥ p. Let 1^ 1 = {^r1i}p
and 1^ 2 =
17: end procedure

i=1		

{^r2j}q
be the cluster representatives of C^ 1 and C^ 2, respectively. The
1: function COMPARE (C^ 1 ; C^ 2 ) \(⊳\) very similar case 2: Compare and find SW of ^r11 with each {^r2j }q

value max SW refers to the value returned by the Smith-Watermann
algorithm.

Algorithm 1
All — Three Algorithms.
3: Find max SW; m ← max SW
4: if at any time (max SW > θu ) then
5: (C^ 1 , C^ 2 ) are very similar 6: Stop and return max SW 7: end if
8: if (max SW < θu ) then
j=1



1: Initialization: Two cluster leaf records (C l, C l)
2: procedure CONSTANT THRESHOLD (C^ 1 l ; C^ 2 l ) \(⊳\) CT algorithm
(continued on next column)
9: Compare and find SW of ^r12 with each {^r2j }q 10: Find maxSW; start with max SW equal to m 11: if at any time (max SW > θu ) then
(continued on next page)


Algorithm 1 (continued )

j=argming NEAR—OPT
 C^ l ;j ∪NEAR—OPT
 C^ r ;i—j 



12: (C^ 1 , C^ 2 ) are very similar 13: Stop and return max SW
1≤j<i
DUPTREE	2
DUPTREE	2

14: end if
15: end if
16: end function

1: function COMPUTE (θc)
2: t ← 0.3 (1 —θu) \(⊳\) θu: Monge-Elkan's threshold 3: x ← the number of representative in C^ 2 r — 1
4: Let m ← minimum(x, maximum number of allowed representatives) 5: D ← t/(maximum number of allowed representatives)
6: θc ← 2 × t — m × D 7: return θc
8: end function
1: function CHECK SIMILARITY (C^ 1 ; C^ 2 ) \(⊳\) Check degree of similarity: \(⊳\) very similar, similar, not similar
2: if (max SW > θu ) then
3: (C^ 1 , C^ 2 ) are very similar 4: end if
Evaluation metrics and experiments

Evaluation metrics

The main goal of this experimental evaluation is to compare the performance in terms of accuracy and effectiveness of all four algorithms covered in this work, ME, CT, VT, and FT algorithms. We adopt the pu- rity, inverse purity, and F-measure metrics for our extensive evaluation. Denote by C^ = C^ 1; C^ 2; …; C^ q the set of the true actual clusters where we refer to each C^ i as a class and let C = C 1; C 2; …; C k be the set of
near-duplicate clusters to be evaluated by the SW algorithm. Then the
precision, P(C^ i ; C j) and recall R(C^ i ; C j) of C^ i with respect to C j are defined as follows:

5: if (max SW ≤ θu ) and (max SW ≥ θl) then
6: (C^ 1 , C^ 2 ) are similar

	 C^ i ∩ C j 

	 C^ i ∩ C j 


8: if (max SW < θl) then	i
9: (C^ 1 , C^ 2 ) are not similar

10: end if
11: end function


1: function COMPARE LEFT-RIGHT SUBTREES (C^ 1 l ; (C^ 2 l ; C^ 2 r ))
2: Find max SW between C^ 1 l and every cluster in T^2 \(⊳\) similar to function COMPARE 3: Suppose max SW is between C^ 1 l and C^ 2 r
4: if (max SW > θu ) then
5: Merge (C 1 , C 2 )
6: Remove C^ 1 l
7: Representative ← representative of C^ 2 r
8: end if
9: if (θc ≤ max SW < θu ) then
10: Merge (C^ 1 l , C^ 2 r )
r
where P(C^ i ; C j) = R(C j; C^ i ). Let n^ be the total number of clustered entities, including near-duplicates, purity is formulated by the weighted average of the maximum precision values achieved by the clusters on one of C^ j :
C j	q	^
j=1  ^n	i=1

However, inverse purity considers the cluster with maximum recall for each class C^ i , and it is obtained by taking the weighted average of the maximum recall values

11: Remove C^ 2
k


13: end if
14: if (max SW < θc ) then

i=1
i	j=1	i

15: do nothing
16: end if
17: end function



Without loss of generality, let assume C^






1l and C^






1r be the clusters
The values of the purity and inverse purity metrics are within the range of 0–1. The higher purity the better is the inverse purity. Purity penalizes clustering noise (i.e., duplicates) in a cluster, which means grouping re- cords incorrectly, but it does not reward grouping records from the same C^ j . If every cluster contains only one record, the maximum purity is 1.
However, reversing the role of C^ and C, that is inverse purity (C; C^ )

whose root T^1; and C^ 2 l and C^ 2 r be the clusters rooted in the right

subtree T^2 of T^, ordered as (C^ 1l ; C^ 1r ); (C^ 2 l ; C^ 2 r ).
As a result of Theorem 6.1, we state the following results:
Corollary 7.1. NEAR — OPTDUPTREE(C^ 1l ; i) = 
would penalize splitting records belonging to the same cluster C^ j into different clusters. In other words, inverse purity rewards grouping near- duplicates together, but it does not penalize noisy records from different C^ j . In a similar way to precision and recall, there is a tradeoff relation-
ship between inverse purity and purity. Inverse purity rewards grouping

8< C^
l
1	if i = 1
near-duplicates and the maximum inverse purity is achieved by putting

: NEAR — OPT
 C^ l ; j ∪ NEAR — OPT
 C^ r ; i — j  if i > 1
all records in one single cluster. For each class C^ i , the F-measure of that



where
DUPTREE	2
DUPTREE	2
class is:
 
k 2 × P C^ i ; C j × R C^ i ; C j 

j=argming NEAR—OPTDUPTREE
 C^ l ;j
∪NEAR—OPTDUPTREE
 C^ r
;i—j
F C^ i ; C j
= max
j=1
P C^
i; C j 
+ R C^
i; C j 

1≤j<i
Corollary 7.2. NEAR—OPTDUPTREE
(C^ 1
; i)= 
The F-measure, a combination of purity and inverse purity, is in the range of [0; 1] and a higher F-measure indicates a better clustering. The F-

8< C^
r
1	if i = 1
measure, is in the range of [0; 1], indicates a better clustering. The F-
measure of the clustering [35,36] which computes the weighted average

: NEAR — OPT
 C^ l ; j ∪ NEAR — OPT
 C^ r ; i — j  if i > 1
of maximal F-measure values is defined as:

where



X	^	 C i 
Table 1
Detection of near-duplicates in voting list1 data sets.

F — measure =
F C i; C j


 C^ 

i=1


Experiments and data sets

Although ME and All—Three algorithms are provably correct, but verifying the accuracy of an implementation is a challenging task. With no prepossessing steps, all these algorithms are implemented in C++. The experiments were carried out on several publicly available real data sets which cover a spectrum of different data characteristics and sizes. We have used four different data sets in our experiments. Three real data sets from various sources often used in related research, and the fourth large data set was generated synthetically (artificially) using the near-
duplicate generator (NDG) algorithm as described below. NDG gener-
ates ten of millions of near-duplicates for each set of real data.

Algorithm 2Near-Duplicate Generator (NDG) Algorithm
Voting lists	List1 Real Data Set 255	Average

		
Runs	run1	run2	run3	Avg




Table 2
Detection of near-duplicates in voting list2 data sets.


Voting lists	List2 Real Data Set 975	Average



1: Remove a random number of characters from the data set record 2: Replace a random number of characters with others
3: Flip the first and last attributes (i.e., flip the first and last names in the lists) 4: Duplicate a random character. This might be done to more than one character 5: Abbreviate randomly - Keep the first character but this might be duplicated or
removed as above
		Table 3
Detection of near-duplicates in Cora data sets.

We ran our experiments on four categories of data set as follows.


Cora Data Set	Cora Real Data Set: 21,152	Average

Voting1 We used the list of registrar voters in British Columbia as our original small data set with no duplicates. The original total number of


Runs	run1

run2

run3


Avg

records in the voting list is 225 and 975 records. Then we complement each of the two original voting data sets with a set of near-duplicates generated by the NDG algorithm. Additionally, we augmented and top-
ped the voting data set to 1977 and 3745 references, respectively.
Cora2 Cora data set contains bibliographic records and citations in scientific papers classified in several classes. The cora citation data set, which consists of a data set of original references and research papers, is often used in the duplicate detection community. Additionally, we augmented and topped the cora data set to 21,152 references and 32,005, a substantial larger data set for our experiments.
NDG near-duplicates	9320	12,754	10,487	10,853
Real data & NDG near-duplicates	30,472	33,906	31,639	32,005
ME near-duplicates	11,412	11,674	10,078	11,054
CT near-duplicates	9234	12,657	10,456	10,782
VT near-duplicates	9341	12,788	10,501	10,876
FT near-duplicates	9289	12,768	10,485	10,847





Table 4
Detection of near-duplicates in DBLP data sets.


DBLP Data Set	DBLP Real Data Set: 43,935	Average

DBLP3 DBLP is the bibliography database for computer science re- cords from the DBLP web site. Each record is a concatenation of author


Runs	run1
run2
run3


Avg

names(s), title of the publication, some keywords, an abbreviated refer- ence format citation (i.e., journal, book, editor). It consists of 43,935 real objects, both for relational and XML data. Additionally and for our ex- periments, we augmented the data set to 63,553 references.
Synthetic4 The near-duplicate generator algorithm (NDG) is capable
of algorithmically generating tens of millions of synthetic records from a set or original records. For instance, the voting, cora and DBLP data sets have been scaled up and topped by tens of thousands of records. The
synthetic data set of 573,879 has been augmented and topped by NDG to
an average of 352.992 records, for an average total of 926.871 records over three runs.
We generated a random number (0–8) of near-duplicates for each record using the NDG algorithm for the voting and DBLP data sets, and a random number (9–20) for the cora data set. Finally, all generated near- duplicates as explained above in the NDG algorithm are appended to the original data set file. Moreover, we ran the NDG algorithm three times,
for each original real data, to generate three different sets of data (see Tables 1-6).


1 http://ww.rootsweb.ancestry.com/canbc.vote898/votea.html.
2 http://www.cs.umass.edu and mccallum/code-data.html.
3 http://www.informatik.uni-trier.de/ley/db/.
4 Algorithm 2: The near-duplicate generator (NDG) algorithm.
NDG near-duplicates	21,134	19,345	18,376	19,618
Real data & NDG near-duplicates	65,069	63,280	62,311	63,553
ME near-duplicates	22,160	20,018	19,102	20,426
CT near-duplicates	21,203	19,177	18,723	19,643
VT near-duplicates	21,119	19,256	18,303	19,559
FT near-duplicates	21,147	19,257	18,362	19,589





Table 5
Detection of near-duplicates in Synthetic data sets.


Synthetic Data Set	Synthetic Data Set: 573,879	Average



Voting lists data sets analysis

First, we consider a small set of records extracted from the voting list1
and list2 of 255 and 975 individuals, respectively. Then we ran three times the NDG algorithm on the voting lists where each run has generated a larger list of near-duplicates. For instance, run1 generated 1058 near-



Table 6
ME, CT, VT and FT algorithms: Performance evaluation of purity, inverse purity and F-measure.


duplicates for a total of 1313 records. That is, the original real voting list1 has been topped by 1058 near-duplicates (Table 1). Similarly, the orig- inal real voting list2 has been topped by 1857 for a total of 2832 (Table 2).
Both tables show the results of the NDG algorithm on the voting lists
over three runs. We carried out the experiments by running the four al- gorithms, ME, CT, VT, and FT on the total number of records. The real
data is topped by duplicates generated by NDG (4th row of Tables 1 and
2). Then we checked whether these algorithms identify the near- duplicates accurately. ME and All—Three algorithms performed more or less accurately on small data set sizes (1257 and 2841 voting records) because of the small amount of noise added to the data set. For instance, on small-sized data such as list2, CT and VT algorithms show an accuracy of 98.34% on the average with 31 false positives ((1831/1866 + 1839/ 1866)/2 = 98.34%). However, FT algorithm's accuracy is 100.27% where the extra 0.27% represents few false negatives on the average in list2 (Figs. 1 and 2 in Appendix). The ME algorithm accuracy is 92.02% with 149 false positives. Still, the ME accuracy is behind the performance of All—Three Algorithms.

Cora and DBLP data sets analysis

On the other types, medium- and large-sized data, All—Three algo- rithms consistently outperformed the ME algorithm in terms of accuracy. On the negative side, the ME algorithm added 2092 false negatives in run1, but converged to 201 false negatives on the average due to read- justing the threshold to 0.8 set by the algorithm (Fig. 3 in Appendix). Overall, the ME algorithm added an extra 1.85% of false negatives over the 32,005 records (Table 3). The Merge—Filter—RC paradigm com- plemented by the comparison and construction of cluster representatives are very noticeable with a high similarity threshold which helped to improve the accuracy of All—Three algorithms (Table 3, Fig. 3 in Ap- pendix). This has been shown in the FT algorithm with only an average of 6 false positives (99.95% of accuracy) on the cora data set of 32,005 records. Furthermore, the FT algorithm added only 29 false positives (99.85 of accuracy) on the DBLP data set of 63,553 records (Table 4, Figure 4 in Appendix). The performance of All—Three algorithms is the most substantial on DBLP with an average of 63,553 records where merging and filtering clusters’ representatives is accurately achieved throughout the similarity variable and function thresholds. In particular, the VT and FT algorithms falsely detected an average of only 59 and 29 false positives, respectively. That is, an accuracy of 99.70% and 99.86%
(Figs. 3 and 4 in Appendix). However, the ME algorithm is far behind with an average of 808 (4.12%) false negatives.

Synthetic data set analysis

Another important observation is that the tuning parameters that we inserted in both ME and SW algorithms overall added some extra sig- nificant accuracy to the near-duplicate detection. For instance, and over the 926,871 synthetic data set (Table 5, Figure 5 in Appendix). All—Three algorithms detected only 860 (0.092%) false negatives. That is, an ac- curacy of 99.90%. The ME algorithm performed also quite well over 926,871 synthetic large-sized data set with 1284 (0.14%) false negative, that is, an accuracy of 99.86%. Overall, ME and CT algorithms had missed to identify a very small number of false positives. That is, 0.14% and 0.15% over 926,871 records. On the DBLP data set, All—Three al- gorithms, in particular VT and FT algorithms, outperform the ME algorithm.

Performance evalution: purity, inverse purity and F-measure

With an extensive experimental analysis, the purity, inverse and F- measure achieved a value of nearly 1.0, a precision which outperforms the seminal work of Monge-Elkan. For instance, in the ME algorithm which is based on Jaro-Winkler's metric and using the attribute name provided by DBLP, the maximum F-measure is at threshold 0.8 and robust up to 0.9. The precision drops steadily below 0.8 due to many false positives. However, with the same algorithm based on Smith-Waterman's metric, the maximum F-measure is at threshold 0.9 and the SW precision
is within the interval [0.9⋯1.0] due to prefixes and suffixes which are
ignored in some references. For the same algorithm and for different metrics (i.e., Jaro-Winkler, Smith-Waterman, Levenshtein), the perfor- mance in terms of F-measure, precision and recall are quite different if we consider only the attribute affiliation in the experiment (Table 6, Figure 6 thru Figure 10 in Appendix). As needed, the near optimal threshold was not evaluated only once, but reevaluated and reconfigured if necessary as records are added to clusters as illustrated in the set of figures in appendix.

Conclusion

In this paper, we have introduced a near-duplication detection framework by improving Monge-Elkan's algorithm and also including an affine variant of the Smith-Waterman's algorithm to reduce the number of record comparisons. We have investigated and implemented a family of algorithms – constant threshold (CT), variable threshold (VT) and function threshold (FT) which are collectively referred to as All—Three algorithms, all based on the merge-filter cluster representatives Mer- ge—Filter—RC approach. Our experiments with real-world and generated data sets have shown substantial gains in accuracy and potential effi- ciency to detect near-duplicates in very large data sets and across different domains.
As we have predicted in this investigation, the performance of Monge- Elkan's algorithm which is mainly evaluated by the number of near- duplicates within their correct clusters would not be as good and accu- rate as expected. This is due to several flaws in the algorithm, including priority queue and union set structures, record comparison algorithms, restricted clustering methods, and other parameters. The Mer- ge—Filter—RC approach, complemented with the three classes of algo- rithms achieves a value of nearly 1.0, a precision which is nearly perfect and outperforms the seminal work of Monge-Elkan. In each run of the experiment, the major evaluation metric is the accuracy measured in terms of near-duplicate clusters. The effect of imperfection in terms of number of clusters and accuracy is reflected in cluster miss-classification with increasing data set sizes in Monge-Elkan's algorithm. All of these affect the precision, recall, and F-measure metrics. We believe that the cutoff and optimization values of threshold with other key tuning


parameters throughout semi-supervised machine learning will signifi- cantly improve the quality of the accuracy and effectiveness of detecting near-duplicate clusters. This is being investigated as the likely direction and outlook of our current research.

Acronyms

Merge—Filter—RC Merge-Filter Representative-based Clustering CT	Constant Threshold
VT	Variable Threshold
FT	Function Threshold
All—Three Constant Threshold, Variable Threshold, Function Threshold ME	Monge-Elkan
SW	Smith-Waterman
SNM	Sorted Neighborhood Method NDG	Near-duplicate Generator OPT(A) Optimal Local Alignment (A)
NEAR — OPTDUPTREE(C^ ; i) near-optimal duplicate subtree for the node
C^ using i clusters

Credit author statement

CRediT (Contributor Roles Taxonomy) was introduced with the intention of recognizing individual author contributions, reducing authorship disputes and facilitating collaboration. The idea came about

following a 2012 collaborative workshop led by Harvard University and the Wellcome Trust, with input from researchers, the International Committee of Medical Journal Editors (ICMJE) and publishers, including Elsevier, represented by Cell Press.

Declaration of competing interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

Acknowledgments

I acknowledge the collaboration of Dr. Maamir Allaoua who collab- orated with me on several interrelated published papers. He is now retired from the Dept. of Computer Science, University of Sharjah, Sharjah UAE. I would also like to thank two graduate students, Sepideh Pashami and Serveh Ghaderi, who spent one entire term carrying out the experiments and programming parts reported in this paper. I also thank Professors A. Elmagarmid and V. Verykios for providing me with some of the original benchmark data sets.

Appendix


 	


Fig. 1. Voting list1 data set: True duplicates vs. ME, CT, VT, and FT Algorithms






Fig. 2. Voting list2 data set: True duplicates vs. ME, CT, VT, and FT Algorithms


  


Fig. 3. Cora data set: True duplicates vs. ME, CT, VT, and FT Algorithms.





Fig. 4. DBLP data set: True duplicates vs. ME, CT, VT, and FT Algorithms.






Fig. 5. Synthetic data set: Optimal duplicates vs. ME, CT, VT, and FT Algorithms


			


Fig. 6. Voting list1 data set: Optimal measures vs. ME, CT, VT, and FT measures





Fig. 7. Voting list2 data set: Optimal duplicates vs. ME, CT, VT, and FT measures






Fig. 8. Core data set: Optimal duplicates vs. ME, CT, VT, and FT measures


			


Fig. 9. DBLP data set: Optimal duplicates vs. ME, CT, VT, and FT measures






Fig. 10. Synthetic data set: Optimal duplicates vs. ME, CT, VT, and FT measures







References

Newcombe H, Kennedy J, Axford S, James A. Automatic linkage of vital records. J Sci 1959;130(3881):954–9.
Christen P. A survey of indexing techniques for scalable record linkage and deduplication. IEEE Transactions on Knowledge and Data Engineering (TKDE 2012; 24(9):1537–55.
Jaro M. Advances in record-linkage methodology as applied to matching. J Am Stat Assoc 1989;84(406):414–20.
Monge A. Adaptive detection of approximately duplicate database records and the database integration approach to information discovery. Ph.D. thesis, Ph.D. Thesis. San Diego: Dept. of Comp. Sci. and Eng., Univ. of California; 1997.
Whang S, Menestrina D, Koutrika G, Theobald M, Garcia-Molina H. Entity resolution with iterative blocking. In: Proceedings of the ACM international conference on management of data. SIGMOD); 2009. p. 219–32.
Weis M, Naumann F, Brosy F. A duplicate detection benchmark for xml (and relational) data. In: Proceedings of the SIGMOD inter. Workshop on information quality for information systems. IQIS); 2004. p. 10–9.
Yan S, Lee D, Kan M, Giles L. Adaptive sorted neighborhood methods for efficient record linkage. In: Proceedings of the 7th ACM/IEEE-CS joint conf. on Digital libraries; 2007. p. 185–94.
Hernandez M, Stolfo S. The merge/purge problem for large databases. In: Proceedings of the ACM SIGMOD international conference on management of data; 1995. p. 127–38.
Papenbrock T, Naumann F, Heise A. Progressive duplicate detection. IEEE Trans Knowl Data Eng 2018;27(5). 1316–132.
Draisbach U, Naumann F. On choosing thresholds for duplicate detection. In: Proceedings of the 18th international conference on information quality. ICIQ); 2013. p. 37–45.
Elmagarmid A, Ipeirotis P, Verykios V. Duplicate record detection: a survey. IEEE Trans Knowl Data Eng 2007;19(1):1–16.
Chen Q, Zobel J, Verspoor K. Duplicates, redundancies and inconsistencies in the primary nucleotide databases: a descriptive study, Jounal of Biological databases and curation. 2017. p. 2–16. https://doi.org/10.1093/database/baw163.



Xiao C, Wang W, Lin X, Yu J, Wang G. Efficient similarity joins for near-duplicate detection. ACM Trans Database Syst 2011;36(3):15–41.
Monge A, Elkan C. Domain-independent algorithm for detecting approximately duplicate database records. In: Proceedings of the ACM SIGMOD workshop on research issues on data mining and knowledge discovery. DMKD); 1997. p. 23–9.
Fellah A, Maamir A. A domain independent methodology for near-duplicate detection. In: Proceedings of the international conference on applied computing, madrid Spain; 2012. p. 139–46.
Navarra G. A guided tour to approximate string matching. ACM Comput Surv 2001; 33(1):31–88.
D. Moreira, al, Image provenance analysis at scale, IEEE Trans Image Process 27 (12).
Fellah A, Maamir A. Near-optimal domain independent approach for detecting duplicates. In: Proceedings of the 19th international conference on data mining, multimedia and image processing. Paris France; 2017. p. 2633–42.
Bharambe D, Jain S, Jain A. A survey: detection of duplicate record. International Journal of Emerging Technology and Advanced Engineering 2012;2(11):298–307.
Hassanian-esfahani R, Kargar Mj. Sectional minhash for near-duplicate detection. Expert Syst Appl 2018;99(1):203–12.
Herschel M, Naumann F, Szott S, Taubert M. Scalable iterative graph duplicate detection. IEEE Trans Knowl Data Eng 2012;4(11). 2294–2108.
Naumann F, Herschel M. An introduction to duplicate detection. Synthesis Lectures on Data Management 2010;2(1):1–87.
Winkler W. Overview of record linkage and current research directions. A Statistical Research Division, U.S. Census Bureau; 2006. p. 1–44.
Winkler W. Approximate string comparator search strategies for very large administrative lists, A Statistical Research Report Series (Statistics 2005-02). U.S. Census Bureau; 2005. p. 1–9. 02.
Baxter R, Christen P, Churches T. A comparison of fast blocking methods for record linkage. In: Proceedings of the ACM SIGKDD workshop on data Cleaning,Record linkage, and object consolidation; 2003. p. 25–8.
Monge A. Matching algorithms within a duplicate detection system. IEEE Data Engineering Bulletin 2000;23(4):14–20.
Yandrapally R, Stocco A, Mesbah A. Near-duplicate detection in web app model inference. In: Proceedings of the ACM/IEEE 42nd international conference on software engineering; 2020. p. 186–97.
Thyagharajan KK, Kalaiarasi G. A review on near-duplicate detection of images using computer vision techniques. Arch Comput Methods Eng 2021;28:897–916.
Draisbach U, Naumann F, Szott S, Wonneberg O. Adaptive windows for duplicate detection. In: Proceedings of the IEEE 28th international conference on data engineering. ICDE); 2012. p. 1073–83.
Jaro M. Probabilistic linkage of large public. Journal of Statistics in Medicine 1995; 84(406):414–20.
Hernandez M, Stolfo S. Real-world data is dirty: data cleansing and the merge/ purge problem. Data Min Knowl Discov 1998;2(1):9–37.
Kopcke H, Rahm E. Frameworks for entity matching: a comparison. Data Knowl Eng 2010;69(2):197–210.
Papadakis G, Svirsky J, Gal A, Palpanas T. Comparative analysis of approximate blocking techniques for entity resolution. In: Proceedings of the VLDB endowment. PVLDB); 2016. p. 684–95.
Papadakis G, Alexiou G, Papastefanatos G, Koutrika G. Schema-agnostic vs schema- based configurations for blocking methods on homogeneous data. In: Proceedings of the VLDB endowment. PVLDB); 2015. p. 312–23.
Vogel T, Heise A, Draisbach U, Lange D, Naumann F. Reach for gold: an annealing standard to evaluate duplicate selection results. ACM Journal of Data and Information Quality 2014;5:1–22.
Vogel T, Naumann F. Instance-based “one-to-some” assignment of similarity measures to attributes. In: Proceedings of the international conference on cooperative information systems. CoopIS); 2011. 412–0420.
Smith T, Waterman M. Identification of common molecular subsequences. J Mol Biol 1981;147. 195–107.
Needleman S, Wunsch C. General method applicable to the search for similarities in the amino acid sequence of two proteins. J Mol Biol 1970;48:443–53.
Deepa K, Rangarajan R, Selvi M. Automatic threshold selection using pso for ga based duplicate record detection. Int J Comput Appl 2013;62(4):181–7.
dos Santos J, Heuser A, Moreira V, Wives L. Automatic threshold estimation for data matching applications. Inf Sci 2011;181(13):2685–99.
Cheng D, Kannan R, Vempala S, Wang G. A divide-and-merge methodology for clustering. ACM Trans Database Syst 2006;31(4):1499–525.
Li M, Wang H, Li J, Gao H. Efficient duplicate record detection based on similarity estimation. In: Proceedings of the 11th inter. Conf. on Web-page and Information Management (WAIM); 2010. p. 595–607.
