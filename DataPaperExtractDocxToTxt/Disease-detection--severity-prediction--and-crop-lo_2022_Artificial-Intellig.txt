Artificial Intelligence in Agriculture 6 (2022) 276–291











Disease detection, severity prediction, and crop loss estimation in MaizeCrop using deep learning
Nidhi Kundu a, Geeta Rani a,⁎, Vijaypal Singh Dhaka a, Kalpit Gupta a, Siddaiah Chandra Nayaka b,
Eugenio Vocaturo c,d, Ester Zumpano c,d
a Department of Computer and Communication Engineering, Manipal University Jaipur, Jaipur, India.
b ICAR DOS in Biotechnology, University of Mysore Manasagangotri, Mysore 570005, India
c DIMES (Department of Computer Engineering, Modeling, Electronics and Systems), University of Calabria, Italy
d Nanotec, Italian National Research Council, 87036 Rende, CS, Italy



a r t i c l e	i n f o


Article history:
Received 26 July 2022
Received in revised form 13 November 2022 Accepted 13 November 2022
Available online 17 November 2022


Keywords: Disease detection Crop loss Severity
Deep learning Maize
a b s t r a c t

The increasing gap between the demand and productivity of maize crop is a point of concern for the food indus- try, and farmers. Its' susceptibility to diseases such as Turcicum Leaf Blight, and Rust is a major cause for reducing its production. Manual detection, and classification of these diseases, calculation of disease severity, and crop loss estimation is a time-consuming task. Also, it requires expertise in disease detection. Thus, there is a need to find an alternative for automatic disease detection, severity prediction, and crop loss estimation. The promising re- sults of machine learning, and deep learning algorithms in pattern recognition, object detection, and data analysis motivate researchers to employ these techniques for disease detection, classification, and crop loss estimation in maize crop. The research works available in literature, have proven their potential in automatic disease detection using machine learning, and deep learning models. But, there is a lack none of these works a reliable and real-life labelled dataset for training these models. Also, none of the existing works focus on severity prediction, and crop loss estimation. The authors in this manuscript collect the real-life dataset labelled by plant pathologists. They propose a deep learning-based framework for pre-processing of dataset, automatic disease detection, severity prediction, and crop loss estimation. It uses the K-Means clustering algorithm for extracting the region of interest. Next, they employ the customized deep learning model ‘MaizeNet’ for disease detection, severity prediction, and crop loss estimation. The model reports the highest accuracy of 98.50%. Also, the authors perform the feature vi- sualization using the Grad-CAM. Now, the proposed model is integrated with a web application to provide a user- friendly interface. The efficacy of the model in extracting the relevant features, a smaller number of parameters, low training time, high accuracy favors its importance as an assisting tool for plant pathology experts.The copy- right for the associated web application ‘Maize-Disease-Detector’ is filed with diary number: 17006/2021-CO/ SW.
© 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).





Introduction

Different varieties of maize crop such as corn, sweet corn, popcorn and baby corn are source of human and poultry feed (Modi, 2014). Maize is a preferred energy cereal, therefore approximately 47% of the maize yield in India is used as poultry feed (Panda et al., 2013), 13% as


* Corresponding author.
E-mail addresses: kundu.nidhi1990@gmail.com (N. Kundu), geetachhikara@gmail.com (G. Rani), vijaypalsingh.dhaka@jaipur.manipal.edu (V.S. Dhaka), kalpitgupta369@gmail.com (K. Gupta), moonnayak@gmail.com
(S.C. Nayaka), e.vocaturo@dimes.unical.it (E. Vocaturo), e.zumpano@dimes.unical.it (E. Zumpano).
livestock feed and 12% to meet the human food demand. Further, 12% of the maize yield is used for industrial purposes. Maize is helpful in im- proving the digestive health and reducing the risk of chronic diseases such as cardiovascular disease, diabetes and obesity (Sheng et al., 2018). Thus, its' demand is increasing among the populace.
To meet the demands, nearly 1147.7 million Metric Tons (MT) of maize is produced across 170 countries on an area of 193.7 million ha. Its average productivity across the globe is reported as 5.75 t/ha. But, the productivity in India is reported as 3070 kg/ha, which is much lower than the global average productivity of 5920 kg/ha (Alla Singh et al., 2019). The water, and nutrient requirements of maize is 80–90% lesser than widely grown crops such as rice, and wheat (Timsina et al., 2010). This reduces its cost of production. The low cost of production, capacity to adapt in a wide range of environment conditions, and


https://doi.org/10.1016/j.aiia.2022.11.002
2589-7217/© 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/).



myriad uses make the maize a prime driver of the global agricultural economy.
The diseases, such as Turcicum Leaf Blight (TLB) or Northern Corn Leaf Blight (NCLB), Polysora rust, Charcoal rot, Common rust and Sor- ghum downy mildew, cause a huge loss in the productivity of maize crop (Smith, 1988; Taylor et al., 2008). Therefore, it has become an ur- gent requirement to detect these diseases at an early stage. Also, there is a strong need to predict the crop loss due to these diseases. The man- ual disease detection by plant pathologists based on the visual symp- toms is not effective before onset of symptoms. Further, there is a requirement of laboratory tests for crop sample analysis and calculation of disease severity. The manual disease detection and laboratory tests are expensive and time-consuming. Also, these methods are less effec- tive in early disease prediction, disease severity prediction, and crop loss estimation. This has raised the demand for automating the disease detection, severity prediction, and crop loss estimation.
The potential of Deep Learning (DL) and Machine learning (ML) techniques in healthcare (Cao et al., 2020; Pradhan et al., 2020; Bedi and Gole, 2021; Kundu et al., 2021), image processing (Wang et al., 2019; Singh et al., 2020; Kundu et al., 2021), data analysis (Agarwal et al., 2020; Rani and Agarwal, 2020), pattern recognition (Hijazi et al., 2015), behavior analysis (Luque et al., 2020), and object detection (Chen et al., 2017; Lee et al., 2020; Oza et al., 2021) etc. motivated us to employ these techniques for early disease prediction, disease severity detection, and crop loss estimation in maize crop.
In this research, we develop a DL based framework “Early Maize Dis- ease Detector and Evaluator” (EMDDE) for early prediction of TLB, Rust, and multiple diseases in the same plant of maize crop. Here, multiple diseases labelled as ‘multidisease’ represents the occurrence of both TLB, and Rust on the same leaf of the plant. We focus on causing agents of diseases, symptoms in terms of leaf colour and shape of infected re- gions, stage of infection and favorable conditions for occurrence of these diseases as shown in Table 1.
The proposed architecture has potential to accurately classify the healthy and maize plants infected with TLB, Rust and multiple diseases. It also has competence to detect the severity of identified disease. Fur- ther, it is effective in assessing the number of infected plants and area of infection in the diseased plants present in a farmland. Based on this assessment, we can predict the severity of TLB and Rust (Bock et al., 2010) on a 1 to 9 normalized scale designed by pathology scientists of ICAR Ludhiana (Hooda et al., 2018). In this scale, (0) denotes the lowest degree of severity, whereas (9) indicates the highest severity of disease. The crop loss of 100% is assumed if a plant is infected with multiple dis- eases. The efficacy of the proposed architecture is validated by the plant pathologists from ICAR-Mysore involved in this research. They manu- ally visualized the segmented region of interest, diseased area calcu- lated, and severity predicted on the rating scale. Based on the results, they validated the performance of the model. The overview of the pro- posed approach is shown in Fig. 1, and its' key contributions are listed below.

Collection of maize crop dataset in close supervision of the maize pathologist.
Developing the novel deep learning architecture for disease predic- tion.
Minimizing training time for the devised deep learning model.
Calculating the Diseased Leaf Area of the infected plants
Predicting disease severity using a normalized scale.
Developing an intelligent system for disease prediction and crop loss estimation.


Related works

The study of literature related to segmentation, disease recognition, classification, severity prediction, and crop loss estimation is presented in this section.
Segmentation is the first step for disease detection. It is important to segment the Region of Interest (ROI) from the input images. The authors (Ma et al., 2009) reviewed various segmentation techniques based on threshold, pattern recognition and on deformable models. In these techniques, threshold is either decided manually or auto- matically based on edge, region, and hybrid one. The authors claimed that the Laplacian and canny edge detection techniques are most widely used for image segmentation (Al-amri, et al, 2010). The Laplacian technique is used to find the dark and light side of an edge, whereas canny is used to isolate noise before edges, and deter- mine critical values for threshold.
The authors (Khan et al., 2019) applied the strong correlation-based method for segmentation of apple leaves. They optimized the results by fusion of Expectation Maximization (EM) technique. But this method is suitable only for the segmentation of small spots of infection. Thus, it leaves a scope for improvement. A team of researchers (Usha Kumari et al., 2019) employed K-means algorithm and improved the correct- ness of segmentation. But, they could not enhance the accuracy of clas- sification.
Next, the authors (Dechant et al., 2017) demonstrated a DL based system for identification of maize plants infected with northern leaf blight. For the experiments, they used a dataset comprising 1796 maize images (nlb_annotated_public_2016_Maize dataset, 2016). They trained three Convolutional Neural Network (CNN) models on collected dataset, classified them into diseased and non-diseased categories, and generated heat maps. Their model achieved the accuracy of 97.8%. But its large memory requirement is a hinderance in its real-life use. For extending the real-life applicability of disease detection, the au- thors (Mishra et al., 2020) used mobile or drone camera to capture the images and forwarded to Raspberry pi 3b + module. They de- ployed the Intel Movidius Neural Compute Stick (NCSDK) over Rasp- berry pi. Then, they applied a pretrained deep CNN model to detect the disease and reported the average accuracy of 98.40%. Following the similar line of research, the authors (Chen et al., 2020) presented a lightweight network for recognizing eight types of diseases in maize crop. They developed a Mobile-DANet based on the DenseNet model (Huang et al., 2017) to minimize the memory requirements. Their model achieved the average accuracy of 98.50%, and 95.86% re- spectively. But the network is inefficient in classification of images with complex background.
To address the issue of complex background, the authors (Lv et al., 2020) proposed a DL based novel network for maize feature enhance- ment under complex environment. Its feature enhancement capacity removes the noise from the images using Retinex and wavelet-based method. They developed a DMS-Robust AlexNet model (Krizhevsky,


Table 1
Indicative parameters of Maize Leaf Diseases.





Fig. 1. Overview of proposed approach.


2010) that reported the highest accuracy of 98.62%. Although, this method eliminates the need to select the specific features, it is time con- suming process to train the model with such enhancement. The authors (Agarwal and Sharma, 2021) followed the research carried out by (Chen et al., 2020) and proposed a system to identify nine classes of maize dis- eases. They focused on removal of background noise using Enhanced CNN model. Their model gave the accuracy of 95.69% on the plantvillage dataset (PlantVillage dataset, 2018). Similarly, the authors (Zhang et al., 2018) proposed the improved CNN models for identification of eight types of diseases in maize crop. They employed modified GoogleNet and Cifar10 models, and achieved the accuracy of 98.9%, and 98.8% re- spectively. Further, a group of researchers (Sun et al., 2020) observed that classification accuracy degrades when DL based classification models are applied on images captured in high light intensity. To re- solve this challenge, they employed an improved Retinex algorithm and gave an accuracy of 91.83% for detection of NCLB disease in maize crop. To further improve the classification accuracy on a real-life dataset, the authors (Haque et al., 2022)proposed a DL-based approach for disease detection. They used digital images of maize crop captured from land of Indian Council of Agricultural Research-All India Coordi- nated Research Project (ICAR (AICRP-Mysore center)), Ludhiana. They reduced the noise of dataset using brightness enhancement techniques. They reported the accuracy of 95.99% using Inception-v3 model. But the increase in training parameters increased the computation time.
The researchers (Ramamurthy, 2019) worked in another dimension
of disease detection. They developed an IoT and DL-based system for sensing the environmental parameters such as temperature, humidity, soil moisture, and pH for the rice crop. Based on the collected parame- ters, and images of crop plants, they predicted the crop disease and no- tified the farmers. Their tool may prove useful in reducing the crop loss and improving the crop yield. The crop loss is directly determined by the severity of disease. Thus, the authors (Bock et al., 2010) discussed hyperspectral imaging and image analysis techniques for calculating disease severity in plants. They claimed that hyperspectral way is ex- pensive due to need of a large amount of data and storage space. They also highlighted that severity assessment can be less time intensive if it is automated using DL and ML techniques. To work in the same line of research, the authors (Prabhakar et al., 2020) applied ResNet101 model on plantvillage dataset and classified it into mild, moderate and severe classes. The model gave an accuracy of 94.60%. Another team of researchers (Wang et al., 2017) measured the severity of diseases in
apple leaves using pretrained DL models viz. VGG-16, VGG-19 (Simonyan and Zisserman, 2015), Inception-v3 (Szegedy et al., 2016), and ResNet50 (He et al., 2016). They claimed that the VGG-16 model outperformed other models with the accuracy of 90.4%.
It is evident from the above discussion that several researchers fo- cused on segmentation and crop disease identification using deep CNN. But a few of them worked on maize crop for automatic severity measurement and crop loss estimation. Moreover, none of the above- mentioned approaches provide a complete system for data collection, data pre-processing, disease identification, severity prediction, diseased area visualization, and crop loss estimation in maize crop. Also, the models proposed in literature have low accuracy, large number of train- able parameters, high computation cost, and long training time. More- over, there is a lack of visualization of features involved in disease prediction. These challenges refrain the use of these models for real- life predictions. Thus, none of the existing models have been evaluated on real-life datasets. To fill the above identified gaps, the authors in this manuscript propose a novel framework integrated with a web applica- tion for collecting the dataset, labelling and validation of dataset by the plant pathology experts, segmentation of diseased area, classification of dataset into healthy, TLB, Rust, and multiple disease classes. The frame- work includes a mechanism for severity prediction, and crop loss esti- mation. Further, it employs GradCam for visualizing the infected regions involved in decision making.

Material and methods

In this section, we describe the detailed architecture and working of the proposed framework Early Maize Disease Detector and Evaluator (EMDDE). The architecture of EMDDE is shown in Fig. 2. The framework is involved in image acquisition, pre-processing, classification, and crop loss assessment. The details of these activities are discussed subsequently.

Dataset acquisition

In the farmland of Indian Council of Agricultural Research- All India Coordinated Research Project (ICAR (AICRP- Mysore center)), the maize crop infected with TLB, and Rust was grown purposefully by the plant pathology scientists involved in this research. Next, the leaf im- ages of the plants infected with TLB, Rust and multidisease were




Fig. 2. The architecture of “Early Maize Disease Detector and Evaluator”.


captured in close supervision of the plant pathology expert. Based on the visible symptoms shown in Table 1, the experts identified the dis- eased plants of maize. Further, the dataset comprising 2996 images was prepared. The sample images of the dataset are shown in Fig. 3.
Next, the collected dataset has been split into training and testing datasets on the basis of trial and error mechanism as discussed in (Xu and Goodacre, 2018). To prevent the problem of data leakage, the im- ages of different classes namely Healthy, TLB, Rust, and Multidisease were distributed in such a way that one image is a part of either training, or test dataset. Also, it is ensured that multiple copies of the same im- ages are not a part of training, and test datasets. The training dataset is used only to train the model while the test dataset is used to evaluate and compare the performance of different model architectures.
Now, the authors of this manuscript experimented with the training and testing datasets in the ratios 70:30, 75:25 and 80:20, respectively. They observed that the model performed the minimum misclassifica- tions when 80% of the total dataset was used for training and 20% for testing. Thus, they considered 80% dataset comprising 2460 images, for training the model and 20% dataset comprising 536 images for test- ing. The number of images in each class are shown in Table 2.

Dataset preparation

The leaf images were captured in the high intensity of bright sun- light. Therefore, these images have noisy background, which may affect the performance of the model. We also observed that these leaf images
vary in the Region of Interest (ROI) comprising leaf and the background region. The pixel values for the leaf and background regions of an image are different. In a coloured image, the pixel value is zero for a black pixel, 255 for a white pixel, and between 0 and 255 for any colour other than black and white. These pixels can be easily grouped together based on similarities in their values. To divide an image into its foreground and background, the authors employed an unsupervised clustering ap- proach ‘K-Means’ with pre-set the value of K as 2. Further, it has been observed that the leaf area is larger than the background region in some samples and vice-versa. Thus, we calculated the number of black and non-black pixels in an image by using inbuilt functions of open CV, and NumPy libraries (Harris et al., 2020) as shown in eqs. (1), and (2) for calculating the number of white pixels, and black pixels respectively.

Whitepixels = np.sum(img == 255)	(1)

Blackpixels=np.sum(img == 0)	(2)

Black pixels represent the background region whereas non-black pixels represent the leaf area. Simultaneously, the pixels encountered in region of infection are also transformed to white pixels. This avoids the inclusion of ROI in the background region. Then, we applied K- means (Usha Kumari et al., 2019) algorithm for segmentation of leaf image into two clusters namely ROI and background region. In case the sample images have Larger Leaf Area (LLA) than their background




Fig. 3. Sample dataset.



Table 2
Size of training and testing datasets.



region, then the algorithm selects a cluster with LLA. On the contrary, if a sample has Smaller Leaf Area (SLA) than its background region, then the algorithm chooses a cluster with SLA. In both the cases, leaf area consti- tutes the ROI. Thus, the background region is removed from the sample image. This strategy is demonstrated in Fig. 4.

Architecture

In this section, the authors demonstrate the architecture of DL based model MaizeNet developed for multi-class classification of dataset com- prising images of maize leaves into four classes viz. healthy, TLB, Rust and multidisease. The model comprises of nine convolution layers and three max pooling layers as shown in Fig. 5. The authors applied Batch Normalization (BN) at second, fifth and eighth convolutional layers to standardize the model's deep layers. This reduces Internal Covariate Shift (ICS) (Ioffe and Szegedy, 2015). Also, BN provides the flexibility in choosing the activation function and learning rate. Further, they em- ployed the activation function at third, fourth, sixth and ninth convolutional layers. The last convolution layer is followed by the flatten and dense layer. This combination is important for multidimen- sional data stacking. Dense layer alone does not support multidimen- sional data stacking. Therefore, a flatten layer is embedded between convolutional and dense layer to convert multidimensional input in 1- D and to provide correct predictions (Kurtulmuş, 2020).

Training details

The proposed model MaizeNet is trained on the Kaggle platform which provides 13 GB RAM, 15.9 GB GPU, and 19.6 GB disk space for a continuous session of 30 h per week (Kaggle Server, 2017).
The model MaizeNet is trained using the dataset comprising 2460 images of leaves of maize infected with TLB, Rust or multidisease. Its hyperparameters are fine-tuned as discussed in the subsequent sub-


Fig. 4. Dataset preparation strategy.
section. Also, the pre-training of the proposed model is performed using the ImageNet dataset (Lab, 2017) and the impact of transfer learn- ing on its performance is illustrated in the result section. The same dataset was used for training the pre-trained MaizeNet model, non- pre-trained MaizeNet model and state-of-the-art models viz. VGG-16, VGG-19 (Simonyan and Zisserman, 2015), Inception-v3 (Szegedy, et al., 2019). Then, the performance of the proposed model was com- pared with the above-mentioned state-of-the-art models.

Fine-tuning of training parameters

The softmax activation function, Adam optimizer and categorical cross entropy loss was employed for training the model MaizeNet. The learning rate of 0.001 was pre-set and it is multiplied with 0.9 after every epoch when model completed its training for ten epochs. The learning rate was decided based on the experiments conducted in refer- ence (Prechelt, 2012), and the set of experiments conducted in this re- search with varying learning rates of 0.01, 0.001+ 0.0001, 0.001* 0.9 and 0.001–0.0001. The impact of these learning rates on the value of loss function is demonstrated in Fig. 7. It is evident from the results shown in Fig. 6 that among all the above-stated values of learning rate, the loss function decreases more smoothly at the learning rate of
0.001. Thus, the authors used this value of loss function for further ex- periments.
Next, the choice of the optimum loss function is made by employing different loss functions viz. mean squared logarithmic error, mean squared error, Mean absolute error, kullback leibler divergence and bi- nary cross entropy. It is obvious from the results shown in Fig. 7 that the model converges smoothly when binary cross entropy loss function is employed. Therefore, the authors employed this loss function for fur- ther experiments.

Evaluation metrics

The performance of the Early Maize Disease Detector and Evaluator (EMDDE) was evaluated in terms of confusion matrix, precision, recall, F1 score, accuracy and disease severity scale. These metrics are defined from eq. (3) through eq. (15), by taking clues from the reference (Simonyan and Zisserman, 2015).
Confusion Matrix for multiclass classification: This is the tabular rep- resentation of the number of correctly and incorrectly classified samples into each labelled class as shown in Table 3. The sample confusion ma- trix for showing the correct and incorrect classifications to the healthy, TLB, rust and multidisease are shown in Table 3. Here, TPHH, TPRR, TPTT, and TPMM are the number of correctly classified samples of healthy leaves, rust, TLB, and multidisease, respectively. Similarly, FHR, FHM, FHT denotes samples belongs to rust, multidisease and TLB class respec- tively, but are classified to healthy class. Similarly, FRH, FRM, FRT denotes samples belongs to healthy, multidisease and TLB class respec- tively, but are classified to rust class. Similarly, FMH, FMR, and FMT denotes samples belongs to healthy, rust and TLB class respectively, but are clas- sified to the multidisease class. Similarly, FTH, FTR, FTM denotes samples belongs to healthy, rust and multidisease class respectively, but are classified to TLB class.
Precision: This is the measure of correctly predicted samples to a particular class from the total number of samples classified to that class. For example, PrecisionHealthy is the ratio of number of correctly predicted healthy leaf images to that of total number of images predicted to the healthy class. Its definition is shown in eq.
(3). Similarly, PrecisionRust is the number of correctly predicted samples of rust to that of total number of samples predicted in the rust class as defined in eq. (4). By following the same notation, PrecisionTLB is defined as the number of correctly predicted samples of TLB to that of total number of samples predicted to the TLB class, as shown in eq. (5). Similarly, Precisionmultidisease is the




Fig. 5. Architecture of ‘MaizeNet’ model.


ratio of number of correctly predicted samples of multidisease class to that of total number of samples predicted to the multidisease class, as defined in eq. (6). The average precision as defined in eq.
(7) is the average of the precision calculated for each class from eqs. (3) to eq. (6).
Average Precision
PrecisionHealthy + PrecisionRust + PrecisionTLB + PrecisionMultidisease
=	4	(7)


Recall: This is the ratio of the correctly predicted samples of a class to that of total number of samples of that class. For example,

PrecisionHealthy
	TPHH	
= TPHH + FRH + FTH + FMH
(3)
RecallHealthy as defined in eq. (8), is the ratio of correctly classified samples of the healthy class to that of total number of samples of the healthy class. The recall of Rust, TLB and multidisease is also de-

PrecisionRust = 	TPRR	
TPRR + FHR + FTR + FMR

PrecisionTLB = 	TPTT	
TPTT + FHT + FRT + FMT
(4)


(5)
fined on a similar notion from eq. (9) to eq. (11). Average Recall as defined in eq. (12), is the average of the Recall calculated for all the four classes.

PrecisionMultidisease = 	TPMM		(6)
TPMM + FHM + FRM + FTM
RecallHealthy = 	TPHH	
TPHH + FHR + FHT + FHM

RecallRust = 	TPRR	
TPRR + FRH + FRT + FRM
(8)


(9)








Fig. 6. Learning rate comparison (a) Learning rates: 0.01, 0.001+ 0.0001 and 0.001* 0.9; (b) Learning rate: 0.001–0.0001.




Fig. 7. Comparison of Loss Functions.


RecallTLB = 	TPTT	
TPTT + FTH + FTR + FTM

	TPMM	

(10)

Disease Severity Scale: In this manuscript, the authors used the se- verity scale designed by the plant pathologist working at ICAR, (Indian Institute of Maize Research, 2015) and (Hooda et al., 2018). It is the 0 to

RecallMultidisease = TPMM + FMH + FMR + FMT	(11)

Average Recall
RecallHealthy + RecallRust + RecallTLB + RecallMultidisease
=	4	(12)



F1 score: This is the weighted average of precision and recall. The formula to calculate the F1 score is given in eq. (13).
9 rating scale to represent the disease severity of TLB, and rust diseases based on the visual symptoms of the disease. Rating ‘0’ denotes the min- imum severity, and rating ‘9’ denotes the maximum severity. The plant pathology experts involved in this research manually analyzed the se- verity predicted in this research, and validated the level of disease se- verity according to the severity scale. The ratings are assigned based on the ratio of Diseased Leaf Area (DLA) and Total Leaf Area (TLA). The scales for TLB, and Rust are shown in Figs. 9, and 10 respectively. An image showing <10% infected region, indicates the minimum sever- ity. It may cause the minimum crop loss. Whereas >80% region infected with one disease, indicates the maximum severity. It may cause the
maximum crop loss. Also, the leaves infected with multiple diseases

F1 = 2. precision.recall
precision + recall
(13)
are considered highly susceptible irrespective of the infected area. Such leaves are rated with the maximum rating.
Next, referring the formula given by Mckinney in 1923, and the se- verity predicted using the rating scale formulated for TLB and rust, the

Average accuracy: It is the measure of the degree of correctness of the classification. It can be calculated using the formula given in eq. (14).
degree of disease severity is estimated by following the eq. (15). Here, the conversion of rating scale to disease index or percentage is essential f\scale90%or parametric statistics.




Accuracy = TPHH + TPRR + TPTT + TPMM


(14)
Disease Severity (%)
=

(∑Sum of all rating)


× 100	(15)


Total dataset	(Total number of rating × maximum disease rating)


Degree of Infected Region: The % of infected region is calculated by performing the experiments with the labelled dataset. The dataset of each class is divided into Red [R], Blue [B] and Green [G] channels. The range of values of these channels is observed for each class. Fur- thermore, using the range, the following mechanism given in Fig. 8 is introduced.
Results

In this section, the authors present the experimental results ob- tained on employing the MaizeNet, VGG-19, VGG-16, Inception ResNet V2, Inception V3, and ResNet-50 models on the dataset collected and prepared as a part of this research. They trained these models on the



Table 3
Sample confusion matrix.



Actual Label









Fig. 8. K-means disease classification.




Fig. 9. TLB scale.



Fig. 10. Rust scale.


2460 images in a batch size of 32 for 100 epochs. The authors employed binary cross entropy loss function based on the analysis presented in Fig. 7. They used the pre-set learning rate of 0.001 as illustrated in Fig. 6.

Impact of pre-processing on the performance of the classifier

The authors pre-processed the images and segment the ROI from all leaves using K-means. Samples of extracting ROI from leaves infected with TLB and Rust are shown in Figs. 11, and 12 respectively. The region of infection is highlighted with blue colour in the extracted ROI. The seg- mentation used as a pre-processing technique extracts the region of in- terest i.e leaf area. Therefore, it allows the DL model to extract features only from the ROI. This minimizes the interference of irrelevant features in decision making. Hence, it improves the accuracy of disease predic- tion, and reliability of the DL model.
After pre-processing, the performance of MaizeNet was evaluated. The confusion matrices obtained without employing pre-processing, and with pre-processing are shown in Tables 4, and 5 respectively. It is noticeable from the results shown in these tables that the number of false positive decreases when the MaizeNet model is applied on the
ROI extracted by pre-processing. Thus, pre-processing improves the classification accuracy of MaizeNet model.
Further, the trends of loss functions reported by the MaizeNet model with pre-processing, and without pre-processing are demonstrated in Figs. 13. It is observable from the graphs that the MaizeNet model re- ports lower value of loss function after pre-processing. Also, the de- crease in loss function is smoother when the model is applied on ROI extracted by pre-processing.


Classification and clustering

To further validate the performance of the proposed model MaizeNet, we applied unsupervised K-Means clustering technique on the classified images. The clustering technique recognize the clusters of healthy, TLB, rust and multidisease classes based on the similarity of pixel values. It assigns a label to each image using the function ‘kmeans.labels’ (Khairnar and Goje, 2020). The label is important to identify the cluster to which an image belongs. We considered k as 144 rather than 4 to find the clusters based on multiple orientations of




Fig. 11. Extracting ROI from Leaves infected with TLB Disease.




Fig. 12. Extracting ROI from Leaves infected with Rust Disease.



Table 4
Confusion matrix of'maizenet’ with preprocessing.
Actual Label



an image. Here, the trained model scans an image from various orienta- tions and divide them into clusters.
We also conducted a similar set of experiments by employing MaizeNet, VGG-16, VGG-19, Inception V3, InceptionResNet-v2 and ResNet-50 models as shown in Table 6. The results obtained are demon- strated from Figs. 14 to 19.


Precision
The values of precision reported by MaizeNet, and above-mentioned state-of-the-art models on the dataset comprising 536 images are dem- onstrated in Fig. 14. It is apparent from the figure that VGG-19 model re- ported the highest value of average precision as 99.82% on the pre- processed dataset and 99.56% without pre-processing. Pre-processing feebly improved the precision by 0.26%. Next, Inception ResNet-v2 model reported the highest values of precision as 95.30% before pre- processing and 99.82% after pre-processing. Here, an improvement of 04.52% is observed in the value of precision. The proposed MaizeNet model reported the precision of 95.85% without pre-processing, and 98.87% after pre-processing. The precision reported by MaizeNet model is equivalent to ResNet-v2 model after pre-processing. An im- provement of 3.02% in the value of average precision is observed on employing pre-processing.



Table 5
Confusion matrix of'maizenet’ without preprocessing.
Actual Label
Recall
It is evident from the results shown in Fig. 15 that the VGG-19 and Inception ResNet-v2 reported highest recall of 99% after pre- processing. Further, analysis shows an increment of 0.37% and 3.84% in the values of recall reported when these are applied on pre- processed dataset. Whereas, the proposed model MaizeNet gave the av- erage recall of 95.31% and reported no change on the pre-processed dataset.

F1-score
To further validate the quality of classification, we calculated the values of F1 score as demonstrated in Fig. 16. VGG-19 and Inception ResNet-50 reported highest F1-score of 99.40% after pre-processing. It is obvious from the Figure that pre-processing shows an increment in the values of F1 score. The increment reported as 0.31% and 4.18% in the F1-score reported by VGG-19 and Inception ResNet-50 respectively. The proposed model reported the F1 score of 97.13% which is equivalent to VGG-19 model.

Average accuracy
For assessing the correctness of classification, we calculated the values of average accuracy of all the above-mentioned models. These values are demonstrated in Fig. 17. It is evident from the figure that VGG-19 and Inception ResNet-50 reported the highest average accuracy of 99.81%. Whereas, the proposed model MaizeNet reported a slightly lower value of average accuracy as 98.50%.

Computation cost
Although, the values of precision, recall, F1-score and accuracy re- ported by the model MaizeNet are slightly lower than VGG-19, its train- ing time is much lower than state-of-the-art models mentioned above


Fig. 13. MaizeNet: trend of loss function with preprocessing.


Table 6
Evaluation metrics with and without preprocessing.

Model	Before preprocessing	After preprocessing


as shown in Fig. 18. It is clear from the results shown in Fig. 19 that MaizeNet has 1,55,956 training parameters that are significantly lesser than 5,43,86,786 parameters extracted by Inception ResNet-v2 model. Therefore, there is a significant decrease of 140 s in training time of MaizeNet.

Grad-Cam
diseases in the dataset prepared in this manuscript. The calculations for severity of TLB, and rust is shown in eqs. (14), and (15) respectively. It is evident from the results calculated in eqs. (16), and (17) that maize crop studied in this manuscript is more affected by rust than TLB. The severity for rust is reported as 82.13%, whereas for TLB, it is reported as 57.48%.

It is difficult for the plant pathologists to rely on the classification re- sults reported by a computer vision based model. Therefore, it is neces- sary to visualize the features involved in decision making. We employed the  Gradient-weighted  Class  Activation  Mapping  (Grad-CAM)
Severity of TLB (%) = 5158
997 × 9

Severity of Rust (%) =  6934
× 100 = 57.48%	(16)


× 100 = 82.13%	(17)

(Selvaraju et al., 2020) for visualization of features involved in classify- ing images to four classes viz. healthy, rust, TLB and multidisease on pre- processed as well as non-pre-processed dataset as shown in Figs. 20-21. To plot the Grad-CAM, the model uses the gradients of the last layer of CNN model. It is evident from the Grad-CAM shown in Figs. 20 and 21



4.4. Crop loss estimation

8442 × 9

that the features are visible with more clear boundaries when the models are employed on pre-processed dataset. Further, it is evident from the figures that the proposed model’ MaizeNet’ is efficient in mark- ing the maximum regions of infection in a given sample. It clearly distin- guishes the features of healthy, TLB, rust, and multidisease. Hence, it proves the reliability of the model in classification.

Disease severity

Merely detecting and classifying diseases is not sufficient to prevent and estimate the crop loss. Therefore, we extended the research work and calculated the disease severity in maize crop. For this purpose, we used 1 to 9 rating scale to mark the severity of TLB, rust, and multidisease in maize crop. The scale is designed by plant pathologists, ICAR, maize, Ludhiana(Hooda et al., 2018). Using the scale, we calcu- lated the percentage of disease severity for TLB and rust as shown in Table 7 and 8 respectively. Further, by following the definition of disease severity presented in eq. (13), we calculated the severity of TLB, and rust
Estimation of crop loss is important to maintain a balance between the demand, and supply of a crop. This is also significant in regulating the price of a crop. Thus, we worked for estimating the crop loss in maize crop. In this study, we used the maize dataset comprising 2996 images. This dataset contains 938 images of maize plants infected by rust and 976 infected by TLB. Following the recommendations of plant pathologists, we used rating scale for predicting percentage of crop loss. We recorded the number of leaves with disease severity in the range of 1 to 5 rating, and 6 to 9 rating on the rating scale. Leaves which report the severity in the range of 1 to 5 rating cause the crop loss of approximately 40%. Whereas, the leaves with rating 6 to 9 cause >50% crop loss. The leaves infected with multidisease are consid- ered the cause for 100% crop loss. Further details for the crop loss esti- mation are illustrated in Table 9. The estimated crop loss is validated by the plant pathologists involved in this research. The estimation of crop loss is validated based on the results reported for the disease de- tection, classification, visualization of infected regions, and severity calculated.


	

Fig. 14. Average Precision of different models.	Fig. 15. Average Recall of different models.


	

Fig. 16. F1-score of different models.

Fig. 18. Training time of different models.



Web application

To develop a one-point solution from disease detection to crop loss estimation, we integrated the proposed framework with an interactive and user-friendly web application. The web application provides an op- tion to choose the input image and submit it. The uploaded original image and its corresponding mask generated by K-means mask will be displayed on screen. Next, the image is sent to the proposed DL based model MaizeNet that classifies it to one of the four classes viz. TLB, rust, multidisease or healthy. Next, the model detects the infected region and calculate the area affected. Based on the area of infection, it provides a rating to mark the disease severity and estimates the crop loss. The final white image is the area infected. The work flow of the web application is demonstrated in Fig. 22.

Discussion

In this section, the authors present the inferences deduced from the experimental results obtained by employing the MaizeNet, VGG-16, VGG-19, ResNet-50, Inception-v3, and Inception ResNet-v2 models. The number of layers in MaizeNet is decided by conducting the experi- ments and analyzing the performance of the models with different net- work depths. It was observed that the model with nine convolution layers outperformed the models with five through eleven convolutions.
Our study uses a dataset of 2996 images captured from the farmland of ICAR -AICRP, Mysore. The diseased crops were grown intentionally for carrying out the research work and labelled by plant pathologists. The images are labelled as Healthy, TLB, rust, or multidisease.
In this research, the authors worked on the most ubiquitous foliar diseases of maize crop namely TLB and rust. They applied pre-


Fig. 17. Accuracy of different models.

processing as a proviso, for better recognition of the disease spots using K-means algorithm. Here, k is set to ‘2’ for segmenting the back- ground and region of interest from the images. The authors also applied edge detection for detecting the infected area and separating the leaf and background regions. But, in many cases, it was observed that back- ground had the same colour scheme as of leaf. So, no combination of RGB could distinguish background from leaf. Thus, the authors decided to employ K-means algorithm for distinguishing images based on the difference in area occupied by ROI and background. Then, segmented dataset classified using supervised approach viz. K-means and unsuper- vised approaches viz. MaizeNet, VGG-16, VGG-19, Resnet-50, Inception- v3 and InceptionResNet-v2. This classified data is clustered in four clas- ses namely TLB, rust, multidisease and healthy.
It is apparent from the results shown in Fig. 17 that the pre- processed versions of VGG-19 and Inception ResNet-v2 give the highest average accuracy. Whereas the non-pre-processed version of Inception ResNet-v2 reported the minimum value of average accuracy. Also, the unsupervised classification using K-means shows the least accuracy. The pre-processing of these models leads to increase of 2.43% in the av- erage accuracy. This proves that the above-mentioned deep networks require pre-processing of vast dataset for training. In contrast with, the models viz. ResNet-50 reports a decrease in accuracy after pre- processing. Similarly, a low impact of 0.18% is observed on the average accuracy MaizeNet by applying pre-processing.
It is inferred from the above discussion that the unsupervised learning shows the least average accuracy and deeper networks show a low impact of pre-processing as compared to shallow neural networks.



Fig. 19. Training parameters of different models.









Table 7
TLB: disease severity calculation.
Table 9
Crop loss prediction.



997	5158




Further, the trends of the precision, recall, and F1 measures of the above-stated models are demonstrated in Figs. 14 to 16. It is evident from Fig. 15 that the pre-processed VGG-19 and Inception ResNet-v2 models reported the highest precision of 99.82%. In contrast, the non- pre-processed VGG-19 and Inception ResNet-v2 reported 0.26% and 4.52% lower precision than pre-processed models. In contrast, ResNet- 50 and K-means reported 0.22%, 2.12% decrease in precision after pre-processing. The small variation in the precision of all the pre- processed versions of the above-stated models implies that these models are efficient in recognizing the relevant instances of each class from the input test dataset. The discussion proves that the pre- processing helps to discriminate the irrelevant features and improves the performance.
Further analysis of results shown in Fig. 15 reveals that pre- processed VGG-19 and Inception ResNet-v2 models reported 99% recall. The pre-processed Inception ResNet-v2 reported 4.84% increase in recall than non-pre-processed. The other models viz. ResNet-50, Inception-v3, and MaizeNet reported lower values of recall, as shown in Fig. 15.
Further, it is evident from the F1-score shown in Fig. 16 that the pre- processed VGG-19 and Inception ResNet-v2 models reported the highest F1-score of 99.40%. There is a hike of 2.02% from non-pre- processed Inception ResNet-v2 model. Simultaneously, it is observed that the models ResNet-50, Inception-v3 and MaizeNet reported the de- crease of 1.02% and increase of 0.16% and 1.48% respectively in the values after pre-processing.
Furthermore, it is coherent from the Grad-Cam plotted in Figs. 20, and 21 that the pre-processed MaizeNet model is effective in classifying healthy, rust, TLB and multidisease.
However, the MaizeNet model shows the comparable values of aver- age accuracy, precision, recall, and F1 score with the state-of-the-art models, there is a significant decrease in the number of trainable param- eters and training time. It is noticeable from Fig. 19 that the MaizeNet model has the minimum number of trainable parameters. Further, it is evident from the training time presented in Fig. 18 that the MaizeNet model requires a minimum training time of 140 s through 20 epochs.
Apart from disease detection in maize, the proposed framework does the assessment of disease severity by predicting Disease Leaf Area (DLA). It also estimates the crop loss based on the severity scale de- signed by maize plant pathologist, ICAR, Ludhiana, as shown in Figs. 9, and 10. Disease severity of 57.48%, 82.13% was reported for TLB and rust respectively. These results were validated by experts from ICAR.


Table 8
Rust: disease severity calculation.

This is obvious from the above discussion and experimental results reported that the framework reports higher accuracy than approaches proposed in literature. The authors applied state-of the-art models viz. ResNet-101(Prabhakar et al., 2020), VGG-16 (Wang et al., 2017), En- hanced CNN (Agarwal and Sharma, 2021) and GoogleNet (Zhang et al., 2018) on the dataset comprising maize crop images and reported the average accuracy of 90.4%, 94.6%, and 95.12%, and 98.9% respec- tively. Furthermore, the authors in literature calculated severity at an early, middle, and end stage. But, none of them calculated the severity on the normalized scale designed by plant pathologists. Also, they did not predict the percentage of diseased leaf area, and estimated crop loss in maize crop. Moreover, no research work was found in which the results of DL based system were validated by the plant pathology ex- perts and integrated with a user-friendly web application.

Conclusions

In this manuscript, the authors achieved the objective of automating the disease detection, classification, severity calculation, and crop loss


Fig. 22. Workflow of the web application.



estimation for the maize crop. They collected the real-life dataset com- prising images of healthy maize crop and crop infected with TLB, rust, and multidisease.
The authors pre-processed the collected dataset by applying K- Means algorithm. Further, they applied both supervised and unsuper- vised algorithms on pre-processed, and non-pre-processed dataset for classifying images to all the four classes mentioned above. The authors trained K-means (Khairnar and Goje, 2020), VGG-19 (Simonyan and Zisserman, 2015), ResNet-50 (He et al., 2016), Inception-v3 (Szegedy et al., 2016), finetuned VGG-16 models (Wang et al., 2017), and the pro- posed DL model MaizeNet, on a dataset comprising 2460 images. These images include four classes namely healthy, TLB, rust and multidisease. Among all the above-stated models, MaizeNet reported the highest ac- curacy of 98.50% on the testing dataset comprising 536 images.
Furthermore, the proposed model has lowest number of parameters as 1,55,956. Therefore, its training time is minimum of all the above- stated models. This model completes 20 epochs of training in merely 140 s. Moreover, its efficacy in calculating the diseased leaf area, severity prediction, and crop loss estimation prove its supremacy over the re- search works proposed in the literature. Further, the model is integrated with a web-application for its real-life use as a disease prediction assisting tool. Although, the proposed framework is efficient in classify- ing maize crop into TLB, rust, multidisease, and healthy classes, predicting the disease severity, and estimating the crop loss, there is a scope of making the predictions based on soil parameters, atmospheric conditions, and genomics of plants, and disease-causing agents. Also, the framework can be generalized for crop loss estimation of any crop.

Funding

This work was supported by the Department of Informatics, Model- ing, Electronics and Systems (DIMES), University of Calabria [Grant/ Award Number: SIMPATICO_ZUMPANO].

Author statement

All authors have equally contributed in conducting this research and preparing the manuscript.

Declaration of Competing Interest

The authors declare no conflict of interest.

Acknowledgments

The authors world like to thank “The Indian Council of Agricultural Research” (ICAR), Mysore branch for collection of the dataset for exper- iments and evaluating the efficacy of the framework. The authors also acknowledge Manipal University Jaipur for providing the computing re- sources required to conduct the experiments involved in this research.

References

Agarwal, M., Rani, G., Dhaka, V.S., 2020. Optimized contrast enhancement for tumor de- tection. Int. J. Imaging Syst. Technol. 30, 687–703. https://doi.org/10.1002/ima.22408. Agarwal, R., Sharma, H., 2021. Enhanced Convolutional Neural Network (ECNN) for Maize
Leaf Diseases. pp. 297–307.
Al-amri, S.S., Kalyankar, N.V., S.D, K, 2010. Image segmentation by using edge detection.
Int. J. Comput. Sci. Eng. 2, 804–807.
Alla Singh, S.B., Jat, Suby Sumit Kumar Aggarwal B.S., Das, Shanti Bamboriya Santosh Kumar Abhijit, 2019. ICAR-IIMR Annual Report..
Bedi, P., Gole, P., 2021. Plant disease detection using hybrid model based on convolutional autoencoder and convolutional neural network. Artif. Intell. Agric. 5, 90–101. https:// doi.org/10.1016/j.aiia.2021.05.002.
Bock, C.H., Poole, G.H., Parker, P.E., Gottwald, T.R., 2010. Plant disease severity estimated visually, by digital photography and image analysis, and by hyperspectral imaging. CRC. Crit. Rev. Plant Sci. 29, 59–107. https://doi.org/10.1080/07352681003617285.
Cao, P., Li, X., Mao, K., Lu, F., Ning, G., Fang, L., et al., 2020. A novel data augmentation method to enhance deep neural networks for detection of atrial fibrillation. Biomed. Signal Process. Control 56, 101675. https://doi.org/10.1016/j.bspc.2019.101675.
Chen, J., Wang, W., Zhang, D., Zeb, A., Nanehkaran, Y.A., 2020. Attention Embedded Light- weight Network for Maize Disease Recognition, pp 1–13 https://doi.org/10.1111/ppa. 13322.
Chen, S.W., Shivakumar, S.S., Dcunha, S., Das, J., Okon, E., Qu, C., et al., 2017. Counting apples and oranges with deep learning: a data-driven approach. IEEE Robot. Autom. Lett. 2, 781–788. https://doi.org/10.1109/LRA.2017.2651944.
Dechant, C., Wiesner-hanks, T., Chen, S., Stewart, E.L., Gore, M.A., Nelson, R.J., et al., 2017. Automated identification of northern leaf blight-infected maize plants from field im- agery using deep learning. Phytopathology 107 (11), 1–26.
Haque, M.A., Marwaha, S., Deb, C.K., Nigam, S., Arora, A., Hooda, K.S., et al., 2022. Deep learning-based approach for identification of diseases of maize crop. Sci. Rep. 12. https://doi.org/10.1038/s41598-022-10140-z.
Harris, C.R., Millman, K.J., van der Walt, et al., 2020. Array programming with NumPy.
Nature 585, 357–362. https://doi.org/10.1038/s41586-020-2649-2.
He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. 2016-Decem, pp. 770–778 https://doi.org/10.1109/CVPR.2016.90.
Hijazi, S., Kumar, R., Rowen, C., 2015. Using convolutional neural networks for image recognition. Cadence. https://doi.org/10.2458/azu_js_rc.55.16783.
Hooda, K.S., Bagaria, P.K., Khokhar, Mukesh, Kaur, Harleen, Rakshit, S., 2018. Mass Screening Techniques for Resistance to Maize Diseases.
Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., 2017. Densely connected convolutional networks. Proc. - 30th IEEE Conf. Comput. Vis. Pattern recognition, CVPR 2017 2017-Janua, pp. 2261–2269 https://doi.org/10.1109/CVPR.2017.243.
Indian Institute of Maize Research. Available at: https://iimr.icar.gov.in/world-maze- scenario/.
Ioffe, S., Szegedy, C., 2015. Batch normalization: accelerating deep network training by reducing internal covariate shift. International Conference on Machine Learning,
pp. 448–456.
Kaggle Server. Available at: https://www.kaggle.com/getting-started/44318.
Khairnar, Khushal, Goje, Nitin, 2020. Image Processing Based Approach for Diseases Detection and Diagnosis on Cotton Plant Leaf. Techno-Societal 2018. Springer 1,
pp. 55–65 https://doi.org/10.1007/978-3-030-16848-3_6.
Khan, M.A., Lali, M.I.U., Sharif, M., Javed, K., Aurangzeb, K., Haider, S.I., et al., 2019. An optimized method for segmentation and classification of apple diseases based on strong correlation and genetic algorithm based feature selection. IEEE Access 7, 46261–46277. https://doi.org/10.1109/ACCESS.2019.2908040.
Krizhevsky, Alex, 2010. ImageNet Classification with Deep Convolutional Neural Networks, pp 1–1432 https://doi.org/10.1201/9781420010749.
Kundu, N., Rani, G., Dhaka, V.S., Gupta, K., Nayak, S.C., Verma, S., et al., 2021. Iot and inter- pretable machine learning based framework for disease prediction in pearl millet. Sensors 21, 1–23. https://doi.org/10.3390/s21165386.
Kurtulmuş, F., 2020. Identification of sunflower seeds with deep convolutional neural networks. J. Food Meas. Charact. https://doi.org/10.1007/s11694-020-00707-7.
Lab, S. Vision and Pronceton University, 2017. ImageNet Dataset. Available at: http:// image-net.org [Accessed October 2, 2020].
Lee, S.H., Goëau, H., Bonnet, P., Joly, A., 2020. New perspectives on plant disease character- ization based on deep learning. Comput. Electron. Agric. 170, 105220. https://doi.org/ 10.1016/j.compag.2020.105220.
Luque, F., Hupont, I., Tabik, S., Herrera, F., 2020. Revisiting crowd behaviour analysis through deep learning : Taxonomy, anomaly detection, crowd emotions, datasets, opportunities and prospects. Inf. Fusion 64, 318–335. https://doi.org/10.1016/j. inffus.2020.07.008.
Lv, M., Zhou, G., He, M., Zhang, W., Hu, Y., Chen, A., 2020. Maize Leaf Disease Identification Based on Feature Enhancement and DMS-Robust Alexnet. p. 8.
Ma, Z., Tavares, J.M.R.S., Jorge, R.M.N., 2009. A review on the current segmentation algorithms for medicalimages. IMAGAPP 2009 - Proc. 1st Int. Conf. Comput. Imaging Theory Appl., pp. 135–140 https://doi.org/10.5220/0001793501350140
Mishra, S., Sachan, R., Rajpal, D., 2020. Deep convolutional neural network based detec- tion system for real-time Corn Plant disease recognition. Procedia Comput. Sci. 167, 2003–2010. https://doi.org/10.1016/j.procs.2020.03.236.
Modi, Ajay, 2014. Maize Production Growing faster in India on Higher Demand. BusinessToday.in Available at: https://www.businesstoday.in/magazine/features/ cargill-india-ceo-siraz-chaudhury-maize/story/205721.html.
nlb_annotated_public_2016_Maize dataset. Available at: https://bisque.cyverse.org/ client_service/view?resource=https://bisque.cyverse.org/data_service/00-  4Vcp37UZhQmfcVzBQ2JBhk.
Oza, M.G., Rani, G., Dhaka, V.S., 2021. Glaucoma detection using convolutional neural networks. Handbook of Research on Disease Prediction Through Data Analytics and Machine Learning (IGI Global), pp. 1–7.
Panda, A.K., Prakash, B., Rao, S.V.R., Sunder, G.S., 2013. Utilisation of High Quality Protein Maize in poultry. 69, pp. 877–888. https://doi.org/10.1017/S0043933913000871.
PlantVillage Dataset. Available at: https://www.kaggle.com/emmarex/plantdisease.
Prabhakar, M., Purushothaman, R., Awasthi, D.P., 2020. Deep learning based assessment of disease severity for early blight in tomato crop. Multimed. Tools Appl. 79, 28773–28784. https://doi.org/10.1007/s11042-020-09461-w.
Pradhan, N., Rani, G., Dhaka, V.S., Poonia, R.C., 2020. Diabetes prediction using artificial neural network. Deep Learn. Tech. Biomed. Heal. Inform. 327–339.
Prechelt, L., 2012. Early Stopping - But When? 7700. Springer, Berlin, Heidelb, pp. 53–67. https://doi.org/10.1007/978-3-642-35289-8_5
Ramamurthy, K., 2019. Electronic Monitoring and Disease Diagnosis of oryza Sativa Crops through an IoT Enabled Embedded System Feature Ranking of Spatial Domain Features for Efficient Characterization of Stroke Lesions View Project Low Power Real Time GPS Tracking Enabled with RTOS and Serverless Architecture View Project. Rani, G., Agarwal, M., 2020. Contrast enhancement using optimum threshold selection.
Int. J. Softw. Innov. 8, 96–118. https://doi.org/10.4018/IJSI.2020070107.



Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., 2020. Grad-CAM: visual explanations from deep networks via gradient-based localization. Int.
J. Comput. Vis. 128, 336–359. https://doi.org/10.1007/s11263-019-01228-7.
Sheng, S., Li, T., Liu, R., 2018. Food science and human wellness corn phytochemicals and their health benefits. Food Sci. Human Wellness 7, 185–195. https://doi.org/10.1016/ j.fshw.2018.09.003.
Simonyan, K., Zisserman, A., 2015. Very deep convolutional networks for large-scale image recognition. 3rd Int. Conf. Learn. Represent. ICLR 2015 - Conf. Track Proc.,
pp. 1–14
Singh, V., Sharma, N., Singh, S., 2020. A review of imaging techniques for plant disease detection. Artif. Intell. Agric. 4, 229–242. https://doi.org/10.1016/j.aiia.2020.10.002.
Smith, D.R., 1988. Diseases of Corn.
Sun, J.U.N., Yang, Y.U., He, X., Wu, X., 2020. Northern maize leaf blight detection under complex field environment based on deep learning. IEEE Access 8, 33679–33688. https://doi.org/10.1109/ACCESS.2020.2973658.
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., 2016. Rethinking the inception architecture for computer vision. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. 2016-Decem, pp. 2818–2826 https://doi.org/10.1109/CVPR.2016.308.
Szegedy, Christian, Liu, Wei, Jia, Yangqing, Pierre Sermanet, S.R., 2019. Going deeper with convolutions. Des. Track. Knowl. Manag. Metrics, 163–182 https://doi.org/10.1108/ 978-1-78973-723-320191012.
Taylor, P., Payak, M.M., Sharma, R.C., 2008. Maize Diseases and Approaches to their Man- agement in India. pp. 37–41.
Timsina, J., Jat, M.L., Majumdar, K., 2010. Rice-maize systems of South Asia: current status, future prospects and research priorities for nutrient management. Plant Soil 335, 65–82. https://doi.org/10.1007/s11104-010-0418-y.
Usha Kumari, C., Jeevan Prasad, S., Mounika, G., 2019. Leaf disease detection: feature ex- traction with k-means clustering and classification with ANN. Proc. 3rd Int. Conf. Comput. Methodol. Commun. 2019. ICCMC, pp. 1095–1098. https://doi.org/10. 1109/ICCMC.2019.8819750.
Wang, G., Sun, Y., Wang, J., 2017. Automatic image-based plant disease severity estima- tion using deep learning. Comput. Intell. Neurosci. 2017. https://doi.org/10.1155/ 2017/2917536.
Wang, J., Li, M., Zhang, J., Zeng, W., Yang, X., 2019. DCNN Transfer Learning and Multi- model Integration for Disease and Weed Identification. 2, pp. 492–504. https://doi. org/10.1007/978-981-13-9917-6.
Xu, Y., Goodacre, R., 2018. On splitting training and validation set: a comparative study of cross-validation, bootstrap and systematic sampling for estimating the generalization performance of supervised learning. J. Anal. Test. 2, 249–262. https://doi.org/10.1007/ s41664-018-0068-2.
Zhang, X., Qiao, Y., Meng, F., Fan, C., Zhang, M., 2018. Identification of maize leaf diseases using improved deep convolutional neural networks. IEEE Access 6, 30370–30377. https://doi.org/10.1109/ACCESS.2018.2844405.
