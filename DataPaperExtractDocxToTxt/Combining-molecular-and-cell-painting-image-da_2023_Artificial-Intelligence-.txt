Artificial Intelligence in the Life Sciences 3 (2023) 100060

		


Research Article
Combining molecular and cell painting image data for mechanism of action prediction
Guangyan Tiana,1, Philip J Harrisona,1,‚àó, Akshai P Sreenivasana,b, Jordi Carreras-Puigverta,
Ola Spjuth a
a Department of Pharmaceutical Biosciences, Uppsala University, Sweden
b Department of Medical Sciences, Uppsala University, Sweden


a r t i c l e	i n f o	a b s t r a c t

	

Keywords:
Bioinformatics
Convolutional neural networks Cheminformatics
Deep learning Machine learning
The mechanism of action (MoA) of a compound describes the biological interaction through which it produces a pharmacological effect. Multiple data sources can be used for the purpose of predicting MoA, including com- pound structural information, and various assays, such as those based on cell morphology, transcriptomics and metabolomics. In the present study we explored the benefits and potential additive/synergistic effects of com- bining structural information, in the form of Morgan fingerprints, and morphological information, in the form of five-channel Cell Painting image data. For a set of 10 well represented MoA classes, we compared the perfor- mance of deep learning models trained on the two datasets separately versus a model trained on both datasets simultaneously. On a held-out test set we obtained a macro-averaged F1 score of 0.58 when training on only the structural data, 0.81 when training on only the image data, and 0.92 when training on both together. Thus indicating clear additive/synergistic effects and highlighting the benefit of integrating multiple data sources for MoA prediction.





Introduction

Mechanism of action (MoA) refers to the biological interaction through which a potentially therapeutic small-molecule compound pro- duces a pharmacological effect, such as the specific proteins that the compound targets and the pathways that it modulates. Uncovering the MoA of a compound, although a significant challenge in chemical bi- ology [1], provides extremely useful information for lead compounds prior to clinical trials and for identifying possible toxicity or side-effects [2].
A variety of different data sources can be used to capture infor- mation on a compounds MoA, including structural information from the compound, gene expression from transcriptomics data, protein in- formation from proteomics data, and metabolic enzyme activity from metabolomics data [2]. Recently, cell morphology data from high- content imaging has proven useful for this task [3]. A significant benefit of microscopy based image assays is that they can be scaled to high- throughput much more easily and less expensively than transcriptomics and metabolomics based assays [4]. Cell imaging also provides infor- mation at the single-cell resolution as opposed to condensing the output down to measures of population averages [5]. In terms of throughput
and eÔ¨Éciency the L1000 [6] gene expression assay is perhaps currently the only feasible alternative to image-based assays [7] for large scale data generation to sustain predictive modeling.
Microscopy imaging can be used to capture the changes in cell morphology that arise when a cell culture is treated with a chemi- cal compound [2]. The Cell Painting assay uses fluorescent dyes to paint the cells in multi-well plates as "richly as possible" to illuminate morphological changes in eight broadly relevant organelles and cellu- lar sub-compartments (nuclei, mitochondria, cytoskeleton, Golgi appa- ratus, plasma membrane, cytoplasmic RNA, nucleoli and endoplasmic reticulum) using six fluorescent dyes imaged in five channels [7].
A comparative study for library enrichment reported better predic- tive power for High-throughput screening performance using Cell Paint- ing as opposed to L1000 gene expression profiling [8]. Whereas, for pre- dicting MoA, Way et al. [9] found that L1000 outperformed Cell Paint- ing, but that there was complementarity, i.e. some MoAs were better predicted by one of the assays compared to the other. A related study by Lapins and Spjuth [10] compared Cell Painting, L1000 and chemical structure based predictors, and found MoA classes that were predicted better by each of the three predictors relative to the other two, support- ing the idea of a likely benefit through combining these different data


‚àó Corresponding author.
E-mail addresses: philip.harrison@farmbio.uu.se (P.J. Harrison), ola.spjuth@farmbio.uu.se (O. Spjuth).
1 These authors contributed equally to this work.

https://doi.org/10.1016/j.ailsci.2023.100060
Received 8 December 2022; Received in revised form 5 January 2023; Accepted 30 January 2023
Available online 17 February 2023
2667-3185/¬© 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/)



sources. Another study predicting MoA [11], based on data from the ExCAPE database, which compared models built using image based fea- tures to those built using chemical structure descriptors, provided fur- ther support for the complementarity of these two data types, whereby the models performed somewhat differently at an individual class level. Besides comparing models built using different types of data it is also possible to combine the datasets and analyze them simultaneously to search for additive or synergistic effects. For predicting cytotoxicity and proliferation Seal et al. [12] compared Random Forest models us- ing Cell Painting image based features, molecular fingerprints, and com- bining both data sources. They found that the models based on image features outperformed those based on molecular fingerprints, but the combined models performed best in ten out of twelve cases. Another study predicting the bio-activity of approximately 16,000 compounds [13], found that models based on features derived from Cell Painting images outperformed those based on chemical structure profiles from graph convolutional networks (GCNs, [14]), but that the fusion of the
two datasets gave a gain in performance.
Most traditional image analysis pipelines, including those mentioned above, first extract morphological features from the fluorescence stained images, including measures of size, shape, intensity and texture from the labeled cellular compartments, most often using the CellProfiler
[15] software package, and subsequently apply machine learning meth- ods to the extracted features for the predictive task at hand [16]. These methods require an accurate segmentation algorithm to identify the cel- lular compartments prior to feature extraction. However, when convolu- tional neural networks (CNNs) are used on the raw images, features are extracted in an automatic data-driven fashion, circumventing the need for cell segmentation and potentially providing better predictive per- formance [3,17]. For instance, Hofmarcher et al. [18] found that CNNs trained on Cell Painting image data, for predicting activity labels for over 10,000 compounds, performed significantly better than fully con- nected neural networks trained on pre-computed image features. The flexibility of the architectural choices for neural networks also provides a simple means of combining multiple data sources into the same mod- eling framework [19].
In the work presented in this manuscript we first compared a variety of traditional machine learning and deep learning models for the predic- tion of MoA based on chemical structure data for up to 20 MoA classes. Subsequently, based on a set of 10 MoA classes, we compared the per- formance of the best deep learning model at the compound structural level to a state-of-the-art CNN trained on Cell Painting image data for the same set of compounds. We selected the best deep learning based compound structure model so that we could finally train a joint model for the MoA prediction based on utilizing both structural and image data as input. Example Cell Painting images for the 10 MoA classes can be seen in Fig. 1. To the best of our knowledge our work represents the first combination of five channel Cell Painting image data and molecular fin- gerprint data trained in an end-to-end fashion to predict MoA, wherein the raw images, as opposed to features derived from the images, were used as input to the models.

Materials and methods
Data Molecular data
Molecular data (Corsello et al. [20]), in the form of SMILES strings collected and processed by the Broad Institute, was used in this study. The cleansed dataset contains approximately 5500 compounds covering 1300 MoA classes, but most MoAs have very few compounds associated with them. The number of compounds that each MoA has is shown in Fig. 2. As our models should perform well at the compound level, namely to predict the MoA for unseen compounds, we used a subset of the data, the top 20 MoAs (i.e. the 20 MoAs having the most compounds associ- ated with them).
Image data
The 5-channel Cell Painting image data was produced by the Phar- maceutical Bioinformatics Research Group at Uppsala University. We selected image data from 10 well-represented MoAs (MoAs that we pre- sumed would be reasonably distinguishable and that had a suÔ¨Écient number of compounds associated with them). The ten MoAs were AT-
Pase inhibitors (ATPase-i, number of compounds, ùëõ = 18); Aurora ki-
nase inhibitors (AuroraK-i, ùëõ = 20); HDAC inhibitors (HDAC-i, ùëõ = 33); HSP inhibitors (HSP-i, ùëõ = 24); JAK inhibitors (JAK-i, ùëõ = 21); PARP inhibitors (PARP-i, ùëõ = 21); protein synthesis inhibitors (Prot.Synth.- i, ùëõ = 23); retinoid receptor agonists (Ret.Rec.Ag, ùëõ = 19); topoiso- merase inhibitors (Topo.-i, ùëõ = 32); and tubulin polymerization in- hibitors (Tub.Pol.-i, ùëõ = 20). In total we had 12,582 images for 231 com-
pounds. The compounds were administered to U2OS cells in 384 well plates at a dose of 10 micro-molar. Images at a resolution of 2160 x 2160 pixels were taken across 9 sites in each well and each compound was replicated 6 times. The compounds were distributed across 18 plates using PLAID (Plate Layouts using Artificial Intelligence Design, [21]).

Data preprocessing for models based on molecular data
We explored usin multi-layer perceptrons (MLPs), graph convolu- tional networks (GCNs), convolutional neural networks (CNNs), long short-term memory networks (LSTMs, with and without data augmen- tation), and traditional machine learning algorithms (those operating on tabular data) to predict MoA, and we pre-processed the data for each model. See the Modeling section below for further details on the models explored.
For the MLP and traditional machine learning algorithms, we used Morgan Fingerprints as input. Since SMILES strings are sequential they cannot be processed directly by these models. We used the RDKit pack- age [22] to generate the Morgan fingerprints (binary vectors, 2048 bits) [23]. For the GCN, which requires the adjacency matrix and the node matrix as input, we applied Spektral [24] and NetworkX packages
[25] to convert the SMILES strings into graphs. For the CNN we gener- ated the feature matrix for each SMILES string based on the approach of Hirohara et al. [26]. Initially, we selected 42 chemical features to prepare the feature matrix of each SMILES string based on the selected chemical features. Secondly, due to the blank parts of the feature ma- trix resulting from inconsistent lengths of the SMILES, we applied zero padding to maintain uniform dimensions of the feature matrix. For the recurrent neural network, the LSTM, we utilized SMILES pair encoding
[27] to tokenize the chemical structure data, so we obtained a series of numbers (tokens) representing the SMILES. Similarly to the CNN case, we also used zero padding to ensure that the lengths of all tokens were identical.

Data preprocessing for models based on image data
The 5 channels in the Cell Painting image data were standardized to remove plate-level effects based on the mean and standard deviation of the pixel intensities in the control DMSO wells in each plate. The images were resized from their original dimension down to 256 x 256 pixels. A quality control run on the data to detect saturation and blur in the images found no saturation issues (such as fibers across the field of view) but did detect some blurred images. However, given that a common data augmentation strategy for deep learning models is to purposefully blur the images we decided not to remove these blurred images from the dataset.

Data augmentation and data splitting
Data augmentation generates additional data based on the existing data and improves the generalizability of models. For the image based models we used flipping, 90 degree rotations and shift scale rotations to augment the data. However, for the compound structure based models data augmentation was only possible for the LSTM. As the LSTM is a sequence-based model that requires tokens as input, data augmentation


















































































Fig. 1. Example Cell Painting images for the 10 MoA classes and the DMSO data used for standardization. The row titles give the compound names for the selected images with the MoA abbreviation in parenthesis, where i stands for inhibitor and Ag for agonist.




Fig. 2. Histogram representing the compound counts per MoA for different binning intervals. Note that the range of the interval for the final bin is larger than the others.


is feasible as slightly different tokens can be produced by randomized SMILES [28].
For splitting the data at the compound-level into training, valida- tion and test sets we used stratification based on the proportion of com- pounds for each MoA. We split out 10% of the data for the final held-
Table 1
F1 scores on the test set for the main three models explored for predicting the 10 selected MoAs. MLP used the chemical structure data, EÔ¨ÉcientNet used the image data, and the Global model (see Fig. 3) used both data formats. The results are based on the averages across the five shuÔ¨Ñes of the training and validation data.

out test set. Stratified splitting for the remaining data was performed 	
nine times (nine shuÔ¨Ñes) for the SMILES data in the initial comparison and five times (five shuÔ¨Ñes) for the image data and the corresponding SMILES subset. In each case 80% of the data was used for training and 10% for validation.

Modeling


Compound structure based models
We explored the following deep learning models for the prediction of MoA using chemical structure data: MLP, GCN, CNN, and LSTM with and without data augmentation. For the deep learning models we de- termined the optimal architectures and parameters through model ex- ploration and parameter tuning on the validation sets. The MLP is a basic artificial neural network [29] that includes fully connected input, hidden, and output layers. Our MLP model contained one input layer,
one hidden layer with dropout (ùëù = 0.85), and one final prediction layer.
GCNs are a subset of GNNs [30] that can process non-Euclidean data,
such as graphs with nodes and edges [14]. Our GCN model included input layers for the adjacency matrix and the node matrix followed by
three convolution layers with dropout (ùëù = 0.5), one global attention
one convolution layer, one max pooling layer with dropout (ùëù = 0.8), one pooling layer and one final prediction layer. Our CNN model contained flattening layer with dropout (ùëù = 0.8), and one final prediction layer.
layer, a dropout layer (ùëù = 0.96) and a final prediction layer. For the Our LSTM model included an embedding layer, a bidirectional LSTM
LSTM with data augmentation, we adjusted the degree of augmentation to ensure that each MoA had approximately 1000 SMILES in the aug- mented training set.
We used the Adam optimizer [31], sparse categorical cross-entropy as the loss function, and validation loss as the metric for early stopping. To accommodate for imbalance of classes we applied class weighting in the loss functions to train the models.
We also explored machine learning algorithms that operate on tab- ular data (in contrast to the deep neural networks described above). The more traditional machine learning models have shown compet- itive performance with deep learning models when dataset sizes are relatively small [32]. For instance, Jiang et al. [33] showed that four descriptor-based models outperformed four graph-based models on sev- eral benchmark datasets. We examined five individual machine learning algorithms and four ensemble algorithms. The individual algorithms in- cluded random forests [34], light gradient boosting machines [35], cat boost [36], k-nearest neighbors classifiers [37], and logistic regression [38]. The ensemble algorithms included bagging [39], stacking [40],
voting [41], and adaboost [42].

Cell morphology based model
We applied the state-of-the-art CNN model EÔ¨ÉcientNet [43] to pre- dict MoA based on the 5-channel Cell Painting image data. EÔ¨ÉcientNet applies a compound scaling method to adjust width, depth, and resolu-








tion simultaneously, achieving competitive performance in image-based tasks with less training time and fewer parameters. We adopted the EÔ¨ÉcientNetB1 architecture and used the AdamW optimizer [44] with weighted sparse categorical cross entropy as the loss function.

Global model
For our global model trained on the data for the 10 selected MoA classes, we integrated the MLP (our best performing deep learning model based on the compound structure data) and EÔ¨ÉcientNet (for the image data). The models were first trained separately and then combined and their weights finetuned. The architecture of our global model is shown in Fig. 3.

Results

Summaries of the performance of the traditional and deep learning models for the compound structure based models for the 20 MoA subsets are shown in Fig. 4. These figures present the average F1 scores across the nine shuÔ¨Ñes of the training and validation data as well as the results of randomization tests performed to assess the level of significance in the performance differences. We applied Bonferroni corrections [45] to the p-values to account for the fact that we were performing several compar- isons. The performances of the traditional machine learning algorithms were all quite comparable, however there were larger differences for the deep learning models compared. The best performing deep learning model was the MLP and the worst was the CNN; we note that the MLP performed on par with the best traditional machine learning models.
Test set F1 scores for the 10 selected MoAs (averaged across five shuf- fles of the training and validation data) comparing the MLP, trained on the compound structure data, EÔ¨ÉcientNet, trained on the Cell Paint- ing image data, and the global model, trained on both data sources are shown in Table 1. Our test set contained 24 compounds. This test set was the same for each of the shuÔ¨Ñes of the training and validation data. For the MLP the F1 scores were very variable across the MoA classes, ranging from 0.08 for the JAK inhibitor test compounds to 1.00 for the Retinoid




Fig. 3. The architecture of the global model with two input paths, one for the Cell Painting image data and one for the chemical structure data.


Fig. 4. A). Comparison of macro-averaged F1 scores on the test set of the traditional machine learning models for the top 20 MoAs (i.e. the MoAs that were best represented in the data in terms of the number of compounds they had). B). Comparison of macro-averaged F1 scores on the test set of the deep learning models for the top 20 MoAs. C). Randomization test with Bonferroni correction of macro-averaged F1 scores on the test set of top 20 MoAs. The results are based on the averages across the nine shuÔ¨Ñes of the training and validation data.


receptor agonist compounds. For EÔ¨ÉcientNet the results were somewhat more stable, ranging from 0.48 for the Aurora kinase inhibitors to 0.98 for both the Protein synthesis inhibitors and the Retinoid receptor ag- onists. For the global model the results were even more stable, rang- ing from 0.68 for the ATPase inhibitors to 1.00 for the Retinoid recep- tor agonists. Our global model, achieving a macro-averaged F1 score of 0.92, revealed a clear additive/synergistic effect with an increase in F1 score of 0.11. The three different models were all significantly different from one another at the 5% significance-level based on randomization
tests with Bonferroni corrected p-values. The predictive performance of the models for each of the test compounds is summarized in Table S1 (Supplementary materials). We also show this comparison graphically in Fig. 5 in which we have highlighted the compounds NKP-1339 and amonafide, showing a very pronounced synergistic effect.
In light of the high variability in the test performances for the MLP fitting to the compound structure data we further explored the structural properties of the compounds in our dataset using DataWarrior [46]. The compounds‚Äô SMILES strings were used as input to DataWarrior and for




Fig. 5. Comparison of the prediction rates for the three models for each compound: A). MLP, trained solely on the chemical structure data, versus the Global model, trained on both the chemical structure and Cell Painting image data; B). EÔ¨ÉcientNet, trained solely on the image data, versus the Global model; C). EÔ¨ÉcientNet versus MLP; D). ‚ÄôGOOD‚Äô cluster contained compounds that possessed a prediction rate above 0.97 in panels A-C. The compounds NKP-1339 and amonafide have been highlighted in green boxes in panels A-C as they showed a greater synergistic effect than the other compounds. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)


the analyses we performed we used the default parameter settings. In Figure S1A (Supplementary materials) we show a neighborhood anal- ysis where compounds with at least one structurally similar neighbor have connecting lines. These structurally connected compounds are iso- lated in Figure S1B (Supplementary materials) and their compound ID numbers are shown. The names for these compounds and their SMILES strings are available on our GitHub repository (see Data and code avail- ability). Although the groupings tend to show compounds belonging to the same MoA class, there are several unconnected compounds. In Fig- ure S2 (Supplementary materials) we show the distributions for the com- pounds, grouped by their MoA classes, for a variety of physico-chemical properties predicted by DataWarrior. We also highlight in this figure the six test set compounds that were poorly predicted by our MLP model (see Table S1 in the Supplementary materials). From this we can see that in some cases these poorly predicted compounds have physico-chemical properties in the tails of the distributions for their MoA classes. This is most evident for the property cLogS, a measure of aqueous solubil-
ity. The two JAK inhibitor compounds in our test set (curcumol and CEP-33779), both of which were predicted poorly, are each at opposite extremes of the distribution for cLogS. The compounds NMS-873, NKP- 1339 and CYT-997 were also the least soluble for their MoA classes.

Discussion

We have introduced a novel and eÔ¨Écient approach for MoA pre- diction, which combines both Cell Painting image data and chemical structure data (in the form of Morgan fingerprints). Similarly to the study predicting cytotoxicity and proliferation [12] mentioned earlier we found that image based models outperformed those based on Mor- gan fingerprints and that integrating both data sources further boosted the performance. However, Lapins and Spjuth [10] found that chemical structure based models for MoA prediction were generally better than either L1000 or Cell Painting based models (note however that they used features derived from the images as opposed to the raw images them-



selves as model input). Chemical structure data (such as that obtained from Morgan fingerprints) can suffer from "Activity Cliffs", whereby a small change in structure can result in a large difference in bio-activity, highlighting the need to supplement chemical structure data with addi- tional sources of information [2], such as the Cell Painting image data used in the current study.
It should be noted that the Cell Painting assay was performed on a single cancer cell line (U2OS). Although performing MoA and target identification studies using cancer cell lines as proxy is well-accepted [47,48], there is the possibility that using a different cancer (or non- cancer) cell line, could yield slightly different results. Nevertheless, given that the experiment was executed in a controlled manner, and that all cells were treated equally, we are confident in the robustness of our results.
Similarly, the drug screen in this study was performed at 10uM for all compounds. This is a concentration typically used in drug screens to ensure a cellular response. However, given that the compounds in this work could have different potency, a dose response would have perhaps aided a more accurate identification of the compounds‚Äô activity.
Due to data limitations our test set had only two to four compounds per MoA. The test-level predictive performance under such conditions may suffer if by chance any of these compounds happened to be outliers for their class. Based on our compound level analysis using DataWarrior it appears that this may have been the case for our two JAK inhibitor test compounds, thus potentially explaining the low F1 score for the MLP for this MoA.
However, a few compounds were better predicted by the chemical structure based model, relative to the image based model. Perhaps the main disadvantage of image data such as Cell Painting is that not all compounds will necessarily produce a morphological change or the mor- phological effects may be very subtly and potentially masked by unac- counted for technical variations within and between plates during image capturing [2]. However, in the current study, to reduce potential bias caused by positional effects in the micro-well plates, the compounds and controls were distributed over the plates using PLAID and we standard- ized the images across the plates based on the control/DMSO wells. It is also possible that the compound does produce a morphological change but not in any of the cellular compartments or organelles captured using the Cell Painting assay. Another possibility is that the dose applied was not suÔ¨Écient to produce a morphological change.
Concerning the traditional machine learning methods we explored for the chemical structure data, the ensemble methods outperformed the individual methods. Similarly, when combining a model based on mul- tiple inputs, with separate modeling paths that come together to make a final prediction, we can potentially achieve better results than the mod- els built on just one of the data categories. In this study, we showed this type of additive/synergistic effect by combining MLP for chemical structure data and EÔ¨ÉcientNet for image data for MoA prediction.
Although it was somewhat surprising that for our models based on only the chemical descriptors, the simplest deep learning architecture, the MLP, outperformed the more complex networks architectures ex- plored, a similar result has been obtained in a previous study [49] per- forming drug target prediction on a large benchmark dataset from the ChEMBL database. In our MLP architecture, we used an unconvention- ally high dropout rate to alleviate the overfitting problem as a result of the scarcity of chemical structure data. We also tested other possi- ble architectures, such as reducing the dropout rate and increasing the number of hidden layers, with fewer neurons in each layer. However, these modifications did not improve the model performance.
It should also be mentioned that the purpose of the current study was to compare the accuracy of models trained on morphological and structural data, and that the domain of the models hence limit their applicability outside of this scope (i.e. for making predictions when a test compound‚Äôs MoA does not belong to any of those on which the model was trained). This is due to the fact that the predictions of neural network models are neither probabilistic nor well-calibrated [50], and
will always make a prediction of the most likely class even if all classes should be predicted with low probability. We are currently developing methods to fill these gaps using what we refer to as Predictive Target Profiles (PTP) using well-calibrated conformal predictors [51,52].
Predicting the MoA of a compound can benefit greatly from the inter- action of multiple sources of data [2]. Various studies [9,10,13,53] have shown that image and transcriptomics assays contain both overlapping and distinct cell state information. Thus, an even better predictive model than our final one could potentially be achieved with the additional inte- gration of transcriptomics data. Further, other types of chemical struc- ture representations such as 3D descriptors could be explored. In the present study, for the image based model and the combined model, we used a set of ten well represented MoA classes and a widely established 2D descriptor for representing chemistry. In future work we will explore the predictive ability of these models across a wider range of classes whilst accounting for potential polypharmacological effects. Again the conformal prediction method mentioned above will likely prove useful for this purpose. Contrary to previous belief, polypharmacology, where a compound concurrently engages with multiple targets or processes, is the rule rather than the exception in biology [19].

Conclusions

In this work we explored the fusion of chemical structure and cell morphology data for the purpose of mechanism of action prediction. To the best of our knowledge our work represents the first combination of molecular fingerprint data and five-channel fluorescence Cell Painting image data, trained using deep learning in an end-to-end fashion, to pre- dict mechanism of action. Furthermore, for improved model flexibility and performance, we used the raw input images, as opposed to featured derived from them, as input to the models. We found a clear and signifi- cant improvement in predictive performance for models trained on both input types simultaneously, as opposed to in isolation, with an increase in F1 score of 0.11, highlighting the benefit of combining data sources for mechanism of action prediction.

Data and code availability

The image data to accompany this paper has been uploaded to Figshare (https://doi.org/10.17044/scilifelab.21378906). The python code to accompany the paper is available on GitHub (https://github. com/pharmbio/CP-Chem-MoA). Also in the GitHub repository is the csv file compound_list_10_MoAs which gives the compound names, their SMILES strings and their reference ID numbers (1:231) used in our anal- yses.

Funding

This project was supported by the Swedish Research Council (grants 2020-03731 and 2020-01865), FORMAS (grant 2018-00924),
the Swedish Foundation for Strategic Research (grant BD15-0008SB16- 0046), and the Swedish strategic research program eSSENCE.
Data availability

Links to the data and code are provided at the end of our paper.

Acknowledgments

This project was supported by the Swedish Research Council (grants 2020-03731 and 2020-01865),FORMAS (grant 2018-00924),
the Swedish Foundation for Strategic Research (grant BD15-0008SB16- 0046), and the Swedish strategic research program eSSENCE. We also thank Jonne Rietdijk and Polina Georgiev for performing the Cell Paint- ing assay and Anders Larsson for IT infrastructure assistance.



Supplementary material

Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.ailsci.2023.100060.

References

Hight SK, Clark TN, Kurita KL, McMillan EA, Bray W, Shaikh AF, Haeckl FPJ, Carnevale-Neto F, La S, Lohith A, et al. High-throughput functional annota- tion of natural products by integrated activity profiling. BioRxiv 2022:748129. doi:10.1101/748129.
Trapotsi M-A, Hosseini-Gerami L, Bender A. Computational analyses of mechanism of action (MoA): data, methods and integration. RSC Chem Biol 2022;3(2):170‚Äì200.
Kensert A, Harrison PJ, Spjuth O. Transfer learning with deep convolutional neural networks for classifying cellular morphological changes. SLAS Discov Adv Life Sci R&D 2019;24(4):466‚Äì75.
Caicedo JC, Singh S, Carpenter AE. Applications in image-based profiling of pertur- bations. Curr Opin Biotechnol 2016;39:134‚Äì42.
Feng Y, Mitchison TJ, Bender A, Young DW, Tallarico JA. Multi-parameter pheno- typic profiling: using cellular effects to characterize small-molecule compounds. Nat Rev Drug Discov 2009;8(7):567‚Äì78.
Peck D, Crawford ED, Ross KN, Stegmaier K, Golub TR, Lamb J. A method for high-
-throughput gene expression signature analysis. Genome Biol 2006;7(7):1‚Äì6.
Bray M-A, Singh S, Han H, Davis CT, Borgeson B, Hartland C, et al. Cell painting, a high-content image-based assay for morphological profiling using multiplexed fluo- rescent dyes. Nat Protoc 2016;11(9):1757‚Äì74.
Wawer MJ, Li K, Gustafsdottir SM, Ljosa V, Bodycombe NE, Marton MA, et al. Toward performance-diverse small-molecule libraries for cell-based pheno- typic screening using multiplexed high-dimensional profiling. Proc Natl Acad Sci 2014;111(30):10911‚Äì16.
Way GP, Natoli T, Adeboye A, Litichevskiy L, Yang AX, Lu X, Caicedo J, Ci- mini BA, Karhohs K, Logan DJ, et al. Morphology and gene expression profil- ing provide complementary information for mapping cell state. bioRxiv 2021. doi:10.1101/2021.10.21.465335.
Lapins M, Spjuth O. Evaluation of gene expression and phenotypic profiling data as quantitative descriptors for predicting drug targets and mechanisms of action. Biorxiv 2019:580654. doi:10.1101/580654.
Trapotsi M-A, Mervin LH, Afzal AM, Sturm N, Engkvist O, Barrett IP, et al. Compari- son of chemical structure and cell morphology information for multitask bioactivity predictions. J Chem Inf Model 2021;61(3):1444‚Äì56.
Seal S, Yang H, Vollmers L, Bender A. Comparison of cellular morphological de- scriptors and molecular fingerprints for the prediction of cytotoxicity-and prolifera- tion-related assays. Chem Res Toxicol 2021;34(2):422‚Äì37.
Moshkov N, Becker T, Yang K, Horvath P, Dancik V, Wagner BK, Clemons PA, Singh S, Carpenter AE, Caicedo JC. Predicting compound activity from phenotypic profiles and chemical structures. bioRxiv 2022:2020‚Äì112. doi:10.1101/2020.12.15.422887.
Scarselli F, Gori M, Tsoi AC, Hagenbuchner M, Monfardini G. The graph neural network model. IEEE Trans Neural Netw 2008;20(1):61‚Äì80.
Carpenter AE, Jones TR, Lamprecht MR, Clarke C, Kang IH, Friman O, et al. Cell- Profiler: image analysis software for identifying and quantifying cell phenotypes. Genome Biol 2006;7(10):1‚Äì11.
Grys BT, Lo DS, Sahin N, Kraus OZ, Morris Q, Boone C, et al. Machine learning and computer vision approaches for phenotypic profiling. J Cell Biol 2017;216(1):65‚Äì71.
Gupta A, Harrison PJ, Wieslander H, Pielawski N, Kartasalo K, Partel G, Solorzano L, Suveer A, Klemm AH, Spjuth O, et al. Deep learning in image cytometry: a review. Cytometry Part A 2019;95(4):366‚Äì80.
Hofmarcher M, Rumetshofer E, Clevert D-A, Hochreiter S, Klambauer G. Accurate prediction of biological assays with high-throughput microscopy images and convo- lutional networks. J Chem Inf Model 2019;59(3):1163‚Äì71.
Chandrasekaran SN, Ceulemans H, Boyd JD, Carpenter AE. Image-based profiling for drug discovery: due for a machine-learning upgrade? Nat Rev Drug Discov 2021;20(2):145‚Äì59.
Corsello SM, Bittker JA, Liu Z, Gould J, McCarren P, Hirschman JE, et al. The drug repurposing hub: a next-generation drug library and information resource. Nat Med 2017;23(4):405‚Äì8.
Rodr√≠guez MAF, Carreras-Puigvert J, Spjuth O. Designing microplate layouts using artificial intelligence. bioRxiv 2022. doi:10.1101/2022.03.31.486595.
Landrum G. Rdkit documentation. Release 2013;1(1‚Äì79):4.
Cereto-Massagu√© A, Ojeda MJ, Valls C, Mulero M, Garcia-Vallv√© S, Pujadas G. Molec- ular fingerprint similarity search in virtual screening. Methods 2015;71:58‚Äì63.
Grattarola D, Alippi C. Graph neural networks in TensorFlow and keras with spektral [application notes]. IEEE Comput Intell Mag 2021;16(1):99‚Äì106.
Kaur M, Kaur H. Implementation of enhanced graph layout algorithm for visualizing social network data using NetworkX library. Int J Adv ResComput Sci 2017;8(3).
Hirohara M, Saito Y, Koda Y, Sato K, Sakakibara Y. Convolutional neural network based on SMILES representation of compounds for detecting chemical motif. BMC Bioinformatics 2018;19(19):83‚Äì94.
Li X, Fourches D. SMILES pair encoding: a data-driven substructure tokenization algorithm for deep learning. J Chem Inf Model 2021;61(4):1560‚Äì9.
Bjerrum E.J. Smiles enumeration as data augmentation for neural network modeling of molecules. arXiv preprint arXiv:1703.07076 2017.
Murtagh F. Multilayer perceptrons for classification and regression. Neurocomputing 1991;2(5-6):183‚Äì97.
Kipf T.N., Welling M.. Semi-supervised classification with graph convolutional net- works. arXiv preprint arXiv:1609.02907 2016.
Kingma D.P., Ba J. Adam: a method for stochastic optimization. arXiv preprint arXiv:1412.6980 2014.
Wang P, Fan E, Wang P. Comparative analysis of image classification algorithms based on traditional machine learning and deep learning. Pattern Recognit Lett 2021;141:61‚Äì7.
Jiang D, Wu Z, Hsieh C-Y, Chen G, Liao B, Wang Z, et al. Could graph neural networks learn better molecular representation for drug discovery? A comparison study of descriptor-based and graph-based models. J Cheminform 2021;13(1):1‚Äì23.
Breiman L. Random forests. Mach Learn 2001;45(1):5‚Äì32.
Ke G, Meng Q, Finley T, Wang T, Chen W, Ma W, et al. LightGBM: a highly eÔ¨Écient gradient boosting decision tree. Adv Neural Inf Process Syst 2017;30.
Prokhorenkova L, Gusev G, Vorobev A, Dorogush AV, Gulin A. CatBoost: unbiased boosting with categorical features. Adv Neural Inf Process Syst 2018;31.
Keller JM, Gray MR, Givens JA. A fuzzy k-nearest neighbor algorithm. IEEE Trans Syst Man Cybern 1985(4):580‚Äì5.
LaValley MP. Logistic regression. Circulation 2008;117(18):2395‚Äì9.
Breiman L. Bagging predictors. Mach Learn 1996;24(2):123‚Äì40.
Pavlyshenko B. Using stacking approaches for machine learning models. In: 2018 IEEE Second international conference on data stream mining & processing (DSMP). IEEE; 2018. p. 255‚Äì8.
Dietterich TG. Ensemble methods in machine learning. In: International workshop on multiple classifier systems. Springer; 2000. p. 1‚Äì15.
Schapire RE. Explaining adaboost. In: Empirical inference. Springer; 2013. p. 37‚Äì52.
Tan M, Le Q. EÔ¨ÉcientNet: rethinking model scaling for convolutional neural net- works. In: International conference on machine learning. PMLR; 2019. p. 6105‚Äì14.
Loshchilov I., Hutter F.. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 2017.
Bland JM, Altman DG. Multiple significance tests: the Bonferroni method. BMJ 1995;310(6973):170.
Sander T, Freyss J, von Korff M, Rufener C. DataWarrior: an open-source program for chemistry aware data visualization and analysis. J Chem Inf Model 2015;55(2):460‚Äì
73. doi:10.1021/ci500588j.
Lin A, Giuliano CJ, Palladino A, John KM, Abramowicz C, Yuan ML, et al. Off-target toxicity is a common mechanism of action of cancer drugs undergoing clinical trials. Sci Transl Med 2019;11(509):eaaw8412. doi:10.1126/scitranslmed.aaw8412.
Gon»∫alves E, Segura-Cabrera A, Pacini C, Picco G, Behan FM, Jaaks P, et al. Drug mechanism-of-action discovery through the integration of pharmacological and CRISPR screens. Mol Syst Biol 2020;16(7):e9405. doi:10.15252/msb.20199405.
Mayr A, Klambauer G, Unterthiner T, Steijaert M, Wegner JK, Ceulemans H, et al. Large-scale comparison of machine learning methods for drug target prediction on chEMBL. Chem Sci 2018;9(24):5441‚Äì51.
Wieslander H, Harrison PJ, Skogberg G, Jackson S, Frid»®n M, Karlsson J, et al. Deep learning with conformal prediction for hierarchical analysis of large-scale whole-slide tissue images. IEEE J Biomed Health Inform 2021;25(2):371‚Äì80. doi:10.1109/JBHI.2020.2996300.
Lampa S, Alvarsson J, Arvidsson Mc Shane S, Berg A, Ahlberg E, Spjuth O. Predict- ing off-target binding profiles with confidence using conformal prediction. Front Pharmacol 2018;9. doi:10.3389/fphar.2018.01256.
Vovk V, Gammerman A, Shafer G. Algorithmic learning in a random world. 1st ed. Springer Publishing Company, Incorporated; 2010. ISBN 1441934715, 9781441934710
Haghighi M, Singh S, Caicedo JC, Carpenter AE. High-dimensional gene expression and morphology profiles of cells across 28,000 genetic and chemical perturbations. bioRxiv 2021. doi:10.1101/2021.09.08.459417.
