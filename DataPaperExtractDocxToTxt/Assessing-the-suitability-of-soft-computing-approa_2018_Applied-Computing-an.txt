Applied Computing and Informatics 14 (2018) 214–224







Original Article
Assessing the suitability of soft computing approaches for forest fires prediction
Samaher Al_Janabi a, Ibrahim Al_Shourbaji b,⇑, Mahdi A. Salman a
a Department of Computer Science, Faculty of Science for Women (SCIW), University of Babylon, Iraq
b Department of Computer Network, Faculty of Computer Science and Information System, University of Jazan, Jazan, Saudi Arabia



a r t i c l e  i n f o


Article history:
Received 5 May 2017
Revised 7 September 2017
Accepted 16 September 2017
Available online 20 September 2017


Keywords:
Forest fires Soft computing Prediction
Principle component analysis Particle swarm optimization Cascade correlation network
Multilayer perceptron neural network Polynomial neural networks
Radial basis function Support vector machine
a b s t r a c t 

Forest fires present one of the main causes of environmental hazards that have many negative results in different aspect of life. Therefore, early prediction, fast detection and rapid action are the key elements for controlling such phenomenon and saving lives. Through this work, 517 different entries were selected at different times for montesinho natural park (MNP) in Portugal to determine the best predictor that has the ability to detect forest fires, The principle component analysis (PCA) was applied to find the critical patterns and particle swarm optimization (PSO) technique was used to segment the fire regions (clus- ters). In the next stage, five soft computing (SC) Techniques based on neural network were used in par- allel to identify the best technique that would potentially give more accurate and optimum results in predicting of forest fires, these techniques namely; cascade correlation network (CCN), multilayer percep- tron neural network (MPNN), polynomial neural network (PNN), radial basis function (RBF) and support vector machine (SVM) In the final stage, the predictors and their performance were evaluated based on five quality measures including root mean squared error (RMSE), mean squared error (MSE), relative absolute error (RAE), mean absolute error (MAE) and information gain (IG). The results indicate that SVM technique was more effective and efficient than the RBF, MPNN, PNN and CCN predictors. The results also show that the SVM algorithm provides more precise predictions compared with other predictors with small estimation error. The obtained results confirm that the SVM improves the prediction accuracy and suitable for forest fires prediction compared to other methods.
© 2017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an
open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).





Introduction

Forest fires is one of the most important environmental risks that have several negative influences in different aspect of life such as economic, natural environment and health [38]. However, early detection, fast prediction and rapid actions can play an essential role in controlling and saving lives from forest fires danger and their negative consequences.
According to Zadeh [66], soft computing (SC) is a collection of advanced computing methodologies, which aim to accomplish

* Corresponding author.
E-mail addresses: samaher@uobabylon.edu.iq (S. Al_Janabi), alshourbajiibrahim@ gmail.com (I. Al_Shourbaji), mahdi.salman@uobabylon.edu.iq (M.A. Salman).
Peer review under responsibility of King Saud University.

robustness, tractability, total low cost and better solution for a problem under investigation. This makes SC widely used tech- niques in solving complex problems in many different applications
[14] and appropriate techniques selection is the first step to solve any problem in real scenarios [29]. These techniques can be typi- cally divided into two groups: hard and soft computing. Fig. 1 shows the problem solving technologies and their classifications.
During the last years, several works have proved that SC tech- niques play a vital role in monitoring of forest fires [4,37,43]. In another works, SC was used to discover and predict valuable infor- mation about the relationships between variables for forest fires occurrence [1,17,44] and for estimating burned areas under future climate conditions [3,9,60]. Several recent papers have also focused on SC techniques applied to forest fires prediction [5,13,18,27,45,50,65].
Recently, many approaches have adopted artificial neural net- work (ANN) to improve forest fires detection in early stages. Bis- quert et al. [10] investigated the potential of ANN and logistic regression to estimate forest fire danger. The results of this work indicated that good classification accuracy achieved by ANN


https://doi.org/10.1016/j.aci.2017.09.006
2210-8327/© 2017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).




Fig. 1. Taxonomy of problem solving technologies.


technique. Similar results confirmed by the work of [24]. In another work, Maeda et al. [36] employed ANN to identify the areas of high risks of forest fires in Brazil. Their results showed that the ANN approach detects forest fires efficiently. A set of different learning parameters require to be identified in ANN including learning rate, hidden layers number and the nodes number in the hidden layer [48]. A huge number of training iterations may influ- ence to over-train, and therefore, they could affect the accuracy of the prediction model [8].
A wide range of studies have reported for the adaptation of sup- port vector machine SVM) [34,49,61,67] and they found that the SVM achieved good results and it is able to effectively predict for- est fire. This is because SVM does not require determining proba- bilities before analysis and therefore, makes the method more preferable.
This paper aims to investigate the performance of five SC tech- niques to determine the best and suitable predictor for forest fires. These methods include cascade correlation network (CCN), multi- layer perceptron neural network (MPNN), polynomial neural net- work (PNN), radial basis function (RBF) and support vector machine (SVM). To attain this goal, 517 different entries were selected at different times for montesinho natural park (MNP) dataset. The principle component analysis (PCA) was applied to find the critical patterns and particle swarm optimization (PSO) technique was used to segment the fire regions (clusters). The resulted data from PCA and PSO methods will be used as inputs in these predictors. The performance of these techniques will be evaluated based on five quality measures, which include root mean squared error (RMSE), mean squared error (MSE), relative absolute error (RAE), mean absolute error (MAE) and information gain (IG). The results from this work will assist and provide additional aids for systems operators to effectively monitor their system.

Material and methods

Forest fires detection require deployment a number of sensors scattered over a large area. The main function of these sensors is to collect various meteorological data such as moisture, pressure, temperature and humidity that can be used by the systems opera- tors to take proper actions [26]. To infuse the gathered information from the different sensors and get meaningful information poses a significant challenge to the systems operators. These problems involve, finding the hidden patterns, reduce superfluous informa- tion and generate effective rules from the data [6,11]. This chal-
lenge would have been easier if the system has the ability to predict the state of the system based on the previously obtained values. For this, there is a prime importance to have an appropriate method, which can define the data easily according to the fire information. Fig. 2 illustrates the details of the study workflow.
From the above figure, the first phase is to preprocess the data- set. For this purpose, the principle component analysis (PCA) and particle swarm optimization (PSO) techniques were used to find the critical features and to segment the fire regions (clusters) respectively. Then, five predictors were applied to identify the best and suitable predictor that has the ability to predict forest fires. The final phase is to evaluate the predictors’ performance based on five quality measures.




Fig. 2. Workflow process.



Case study and data collection

The montesinho natural park (MNP) was selected as a case study, which is located in the northeast of Portugal. Fig. 3 shows the geographical view of the park. The meteorological dataset was collected from the period of January 2000 to December which has an average temperature of 6–12 degree Celsius 2003. The data obtained from UCI machine learning repository, which have 517 different entries taken at different times. The input features consist of 12 attributes included under spatial and temporal components, fire weather index (FWI) component and weather conditions. The output feature represents the total burnt area. Data collection details can be founded in [16,54]. Several recent papers have used
The swarm position in a D space of the ith particle can be pre- sented by:
Xi = {XI1; Xi2; ·· · Xid}	(2)
Each particle maintains a memory of its previous best position.
The best swarm position is given by:
Pgbest = {Pg1; Pg2; ··· Pgd}	(3)
As well as velocity of each particle can be represented
Vi = {Vi1; Vi2; ·· · Vid}	(4)
A particle velocity should be updated and the following equa- tion can be used

montesinho dataset in their works for forest fires prediction [15,23,25,30,46,57,62].
Vid = wvid + c1r1(pid
xid)+ c2r2(pgd
xid)	(5)


Principle component analysis (PCA)

PCA is one of the most wildly used dimension reduction method, which is often applied to identify patterns in datasets of higher dimensions [28]. In PCA, a group of p-associated variables is transformed into a smaller set principal components (PCs) which can be used to find the dependences and associations that exist between variables in a compact manner. The PCA removes unimportant information from the variables and keeps the variation presents in the original dataset. PCA transforms the data variables for diagonalizing estimation of a covariance matrix xp; p = 1; 2; ··· ; I; xp ∈ RN which can be given by:
i
where c1, c2 parameters are constants and r1, r2 are random num- bers within 0–1. pid is the best local solution of the ith particle for the iteration number up to the ith iteration. The best global solution of all particles is pgd. The ‘‘inertia weight” w controls the effect of the previous velocity of the particle on its current one. If the value of w is greater than 1, then the particle favored searching over exploitation, else w is less than 1, the particle gave more impor- tance to the current best positions.

Cascade correlation network (CCN)

CCN [21] is a supervised learning architecture that constructs a near multi-layer network topology with a high level of accuracy. CCN network structure holds no hidden nodes and each input con-
nected to each output with an adjustable weight corresponding to

C = 1 XxjxT
(1)
each connection. When the network is incapable to build a correla-

I i=1



Particle swarm optimization (PSO)

PSO [33] is a widely used optimization technique to find opti-
tion between the input and output, a hidden unit is added to the network from a pool of candidate units. The process continues until the error in the output units reaches to an acceptable level [52]. The output units are trained to reduce the familiar sum-squared error measure

mal solutions in various applications [7,31,51,64]. Each candidate solution termed as particle that holds the previous path coordinate when it has the best results. Every particle has its own position,
E	1	y
2 O;P
top 2	(6)

velocity and best solution. The PSO method can be presented as follows:
where yop is the observed value of output o for the training pattern
p. The target output is top. E is minimized by gradient descent using




Fig. 3. Map of Portugal illustrating the location of montesinho natural park.


 @E 	y
@woi	p

top)f ' Iip	(7)

2.8. Support vector machine (SVM)

SVM [58] algorithm is commonly employed to solve classifica-

where f' represents derivative of the activation function of the out- put unit for pattern p. Iip is the value of hidden unit i. woi presents the weight connecting input i to output unit o [47].

Multilayer perceptron neural network (MPNN)

MPNNis a widely used feed forward networks due to its clear architecture, fast operation, easy to implement and its capability to solve complex classification problems [32,55]. The MPNN net- work includes three main layers: input, hidden and output. These layers are used for data input, data transmitting and data output respectively. The hidden layer function is to pass the results to the output layer [22,40]. The output of each neuron can be written as
tion and regression problems. It performs the classification by sep- arating the data into two categories to determine the output and construct N-dimensional hyperplane. The main reason behind using SVM lies in dealing and addressing various nonlinear issues, flexible use of kernel functions to increase the ability to convert data from some high dimensional space. The results of the higher dimensional space are similar to the results in dimensional input space. The SVM algorithm is considered as an alternative technique for polynomial, radial basis function and multi-layer perceptron classifiers, the weights of the network are found and used to solve a quadratic programming problem with linear constraints. SVM aims to find the hyperplanes that have high generalization ability by separating the training data without errors and developing a robust and effective solution. The SVM classifier tries to minimize the following function

y	f X w x 
8	1	X	→	X

	


where yi represents the input that a single node j receives. The func- tion f can be a simple threshold, sigmoidor hyperbolic tangent func- tion. The weights between the nodes i and j is denoted by wij.. xi represents the output from node i.

Polynomial neural networks (PNNs)

PNN is based on group method of data handling (GMDH) that uses a class of polynomials named partial descriptions (PDs). By picking the polynomial order between these numerous types of available forms and the most essential input variables, the best PDs can be obtained based on choosing the nodes of each layer and producing additional layers until the best performance is
where the number of training data is and /i, i = 1 ··· n are the non- negative numbers such that the derivatives of Lp to /i are zero, /i are called the Lagrange multipliers, while the hyperplane is defined by Lagrangian function Lp, the vectors w~ and constant b.

2.9. Quality measures

The following quality measures were selected in the perfor- mance evaluation of CCN, MPNN, PNNs, RBF and SVM models.

Root mean squared error (RMSE):
sﬃPﬃﬃﬃﬃﬃnﬃﬃﬃﬃﬃ(ﬃﬃyﬃﬃiﬃﬃﬃ—ﬃﬃﬃﬃﬃyﬃﬃ'ﬃﬃiﬃ)ﬃﬃ2ﬃﬃ


Mean squared error (MSE):

y — f (x1; x2; ·· · xn)	(9)
The estimated output yˆ can be read as
MSE =
n i=1
(yi — y'i)2
n	(14)

^	● Relative absolute error (RAE):

y^ = f(x1; x2; ·· · ; xn)
Pn |yi — y'|



k1	k1k2
k1k2k3

Mean absolute error (MAE):

where ck’s refer to the coefficients of the optimized model [42].

Radial basis function (RBF)

RBF neural network has a feed forward structure that contains
Pn |yi — y' |


where n is the number of data rows, yi presents the actual target value of record i and y' is the predicted target value of record i.
Information gain (IG)

an input layer, a single hidden and an output layer [12]. Whereas
Entropy (p ; p ·· · p ) = —Xp log p

the hidden layers collects the data from the input layers and pass
them to the Gaussian transfer function to transform and regulate
1  2	n
i	2 i
i=1 n

the data nonlinearly. The function responses are then linearly merged to create the data of the output layer. RBF is widely applied in several applications such as system control, time series predic- tion, dynamic system problems and data classification because of its ability to forecast the behavior directly from input and output data [19,35,63]. RBF network tries to minimize the following error function (training error)
Information Attribute		FreSubAttribute	 Entropy
i=1 Total Number of Records
InformationGain (IG) = IBS — IAS
(17)
where IBS refers to the information before splitting and IAS indi- cates to the information after splitting [2].


k  p

E	1	e2 t	11
2 t=1 j=1
where ej(t), is the error of each output unit [39].
Results and discussion
To apply the SC techniques, a program was developed using python programming language. Python is an environment for



machine learning, text mining and business analysis. It is also widely used for research and education.

Used data

The collected meteorological dataset have 517 different entries were taken at different points of time and 13 input features are preprocessed thoroughly. The preprocessing phase was executed according to the following steps:

Preprocess of the dataset
In this stage, description features are converted into numerical using Min-Max normalization technique. This was done by extract- ing the input features from the dataset and preprocessing them. The normalized value, ei for variable E in the ith row can be com- puted as:
The value of the correlation that is greater than 0.8 is consid- ered as a strong value while the ones less than 0.5 is contemplated as a weak value. The values depend on the data from one dataset to another and all other features have a strong correlation to each other except in RH column as shown in Table 1.
In this work, the correlation was only used as an initial process to find associations between the features. It was found that RH has a weak correlation with other variables. The PSO method was used to cluster the data without RH column and the resulted data were employed as inputs to the predictors. However, both the computa- tional cost and the generated error are increased in the predictors remarkably. For this reason, we decide to apply PCA technique to optimize the selection of the most correlated variables in the dataset.

Find the eigenvalues and eigenvectors among features
Based on the eigenvalue criterion, each component should

Normalized(ei) =  ei — Emin 
Emax — Emin
(18)
explain at least one variable’s worth of the variability, and there- fore only components with eigenvalues >1 should be selected.

where Emin presents the minimum value for variable E while Emax represents the maximum value for variable E [53]. The procedure of normalization and coding are as follows:

Normalization. The data value can be scaled by using Min- Max method and the Linear transformation (L') of the original input ranged to a newly specified data range.
L' = [(Lmin)/(max — min)] * (max' — min')+ min'	(19)
where min is the old minimum value, min' is new minimum, max is old maximum, max' is new maximum.
/or example, consider an old data that ranged from [0–100], we obtain an equation to migrate the data to range from [5–10].

L' = [(L — 0)/(100 — 0)] ⁄ (10 — 5) + 5 L' = [L/100] ⁄ 5+5
L' = (L/20) + 5
Let L = 0 Then L' = 5 
If L = 10 Then L' = (1/2) + 5 = (1 + 10)/2 = 5.5


Coding (Convert linguistic terms to numeric form). To encode the attributes of linguistic variable (e.g. day and month), the fol- lowing procedure was used

Create: The repetition table by determining the repetition times for each linguistic term.
Rearrange: The table by making the large value repeated in the
Every eigenvector has a corresponding eigenvalue and for the pro- portion of variance criterion, the analysis simply selects the com- ponents one by one until the desired proportion of variability is achieved. The minimum communality criterion states that enough components should be extracted, so that the communalities for each of these variables exceed a certain threshold, for example 50%. The maximum number of components that should be extracted is just prior to where the scree plot begins to straighten out into a horizontal line. The following illustrates the PCA pseu- docode that was used to find eigenvalues and eigenvectors.

PCA procedure Input: Process dataset
Output: Principal Components (PC)-database
Step1: Compute standardized data matrix Z = [Z1, Z2, ··· , Zm]
based on Zi = (Xi — li )/rii from the original dataset Step 2:
Compute eigenvalues
let B be an m × m matrix and I be m × m identity matrix (diagonal matrix with 1's on the diagonal) then
the scalars (numbers of dimension 1 × 1) k1, k2, ··· , km are said to be the eigenvalues of B if they
satisfy |B — kI| = 0
Step 3: Compute eigenvectors
let B be an m × m matrix and k be an eigenvalues of B then
nonzero m × 1 vector e is said to be an eigenvector of B if Be
= ke.
Step 4: Compute ith PC, the ith PC of the standardized data matrix Z = [Z1, Z2, ··· , Zm] is given by Yi = eTiZ
End procedure

middle and the lower one in the right and left. This process was		
repeated until the minimum repetition becomes at most left and most right.
Assign: Code for each linguistic term depending on its new order

in the repetition table.

Find the correlation measures
The main goal from this step is to find the correlation between the features which represent the most important variables in the dataset. Table 1 provides the correlation among these features using the following:
The obtained eigenvalues, eigenvectors and cumulative variability of the dataset are presented. Table 2 provides the eigenvalues, while the eigenvectors among the features are summarized in Table 3. The variance of components is shown in Fig. 4.
Based on the results from the PCA method and for the purpose of improving the accuracy and speed up the models generation process, all the variables will be used in the next phase since there
is a strong correlation between all variables in the MNP collected

N	xy —	x	y
pNﬃﬃﬃﬃ(ﬃﬃPﬃﬃﬃﬃﬃﬃxﬃﬃ2ﬃﬃ)ﬃﬃ — (P x)2 qNﬃﬃﬃﬃ(ﬃﬃPﬃﬃﬃﬃﬃﬃyﬃﬃ2ﬃﬃﬃ)ﬃﬃ—ﬃﬃﬃﬃﬃ(ﬃﬃPﬃﬃﬃﬃﬃﬃyﬃﬃ)ﬃﬃ2ﬃﬃ
(20)
dataset.

Apply PSO technique

where N present the vector size and —1 6 r 6 1, the positive sign (+) denotes to positive correlation and the negative sign (—) refers to negative correlation.
The PSO method is used to divide the correlated data after using the PCA method into clusters, so that items in the same group are as similar as possible and items in different groups are as dissimilar


Table 1
Correlation among the features.




Table 2
Eigenvalues among the different features.

C. V. = Cumulative Variability.



Table 3
Eigenvectors among the features.




3.5
3
2.5
2
1.5
1
0.5
0
Screen plot













F1	F2	F3	F4	F5	F6	F7	F8	F9	F10	F11	F12	F13
Axis

100

80

60

40

20

0


Fig. 4. The variance of components.


as possible. The PSO selects the best seeds for each cluster where each of them has 13 values and each value represents a feature.
In order to get the shortest and largest distances between clusters, weights were given to each cluster and the traditional
Euclidean distance between the seeds and clusters was computed. Tables 4and 5 provide the initial and final values of centroid classes. Five optimal groups were generated by the PSO method and the final centroid classes are provided in Table 6.


Table 4
Initial centroid classes.



Table 5
Final centroid classes.



Table 6
Distance between the centroid classes.



Apply the predictors

The parameters for each predictor used in this work were selected using trial and error method which can be a fundamental technique in problem solving and obtaining knowledge. To evalu- ate the predictors and their performance based on the 5 quality measures were used in this paper, the dataset was split into two parts: 50% of the data were used for training phase while the remaining data were utilized for the testing phase.

RBF network
The main parameters of this predictor include: the number of neurons = 100, the minimum radius = 0.01, the maximum radius
= 519.669, the minimum Lambda = 0.01328, the maximum Lambda
= 9.95337 and Regularization Lambda for final weights = 6.3458e—005 after 14 iterations.

Multilayer perceptron NN
The main parameters of this predictor include: the number of inputs = 12, the number of layers = 3 (1 hidden), hidden layer 1 neurons: search from 2 to 20, the hidden layer activation function is logistic, the output layer activation function is linear, the min. weight of hidden layer = —3.636e—001, the max. Weight of hidden
layer = 3.409e—001; the min. weight of output layer = 9.638e—005,
and the max. Weight of output layer = 1.358e—001.
Support vector machine (SVM)
The main parameters of this predictor include: the kernel func- tion is radial basis function (RBF), the Epsilon = 0.001, C = 84.1830278, Gamma = 3800.28665 and =6.4728203.


Polynomial neural network
The main parameters of this predictor include: activation kernel function = Gaussian (one variable) y = p1 + p2 ⁄ exp (—((x1 — p3)
^2)/p4),	p1 = 31.30268,	p2 = —27.3003,	p3 = 1.137834,
p4 = 6.307772 and output area = 31.30268–27.3003 ⁄ exp (—((temp + 1.137834)^2)/6.307772)


Cascade correlation network
The main parameters of this predictor include: the minimum neurons in hidden layer is 0, the maximum neurons in hidden layer is 50, the hidden neuron kernel are sigmoid and Gaussian func- tions, the output neuron kernel function: Sigmoid, the number of neurons in input layer = 12, the number of neurons in hidden layer = 2 (Sigmoid neurons = 1 and Gaussian neurons = 1), the
minimum weight in hidden layer = —25.040615, the maximum
weight in hidden layer = 13.892605, the number of neurons in out- put layer = 1, the minimum weight in output layer = —0.217332 and the maximum weight in output layer = 0.150124.




Table 7
Comparison among different predictors based on the quality measures.





Fig. 5. Evaluation the predictors based on the quality measures, (a)–(d) and (e). Comparison between predictors and the quality measures.




Fig. 5 (continued)


Fig. 6. Predicted values of burnt area based on the best predictor (SVM).


Performance analysis

The results in Table 7 show that SVM predicts fire probability well. A comparison of SVM results with other predictors reveals that the SVM outperforms the RBF, MPNN, PNN and CCN predic- tors. SVM has the smallest RMSE of 54.0, MSE of 2926.4, RAE of 10.5, and MAE of 2.656 and the highest IG of 2.656 in the testing stage. In general, the results indicate that SVM has the best predic- tion ability for forest fire compared to other selected SC methods. Results of the five SC for forest fires prediction based on each statistical measure are shown in Fig. 5. According to the bar charts, the SVM has achieved the highest gain in (e) with minimal error in (a, b, c and d). Therefore, the SVM algorithm is the best predictor and it has the capability to effectively predict forest fires compared to other predictors. Similar results were obtained by the work of [16,61]. The difference between the expected and actual values
for the MNP dataset that generated by the best predictor SVM tech- niques provided in Fig. 6. Green color represents the predicted val- ues while the black color presents the actual values.


4. Conclusion

In this article, several SC techniques were applied on MNP data- set to determine the effective predictor that would potentially give more accurate results for forest fires. The PCA was used to capture the correlation between features and PSO technique was applied to find the number of clusters existing in the resulted data after using the PCA technique. In the next stage, the obtained clustered data was used as inputs in the SC techniques. The quality measures used in this work make it obvious that SVM attained best results with a high level of accuracy compared to other methods. The findings in



this study would assist and provide additional aids for systems operators’ to monitor their system effectively.

References

W. Aertsen, V. Kint, J. Van Orshoven, K. Ozkan, B. Muys, Performance of modelling techniques for the prediction of forest site index: a case study for pine and cedar in the Taurus mountains. Turkey XIII World Forestry Congress, 2009, pp. 18–23.
A.M. Al-Bakary, H.A. Samaher, Data construction using genetic programming method to handle data scarcity problem, Int. J. Adv. Comput. Technol. (2010).
G. Amatulli, A. Camia, J. San-Miguel-Ayanz, Estimating future burned areas under changing climate in the EU-Mediterranean countries, Sci. Total Environ. 450 (2013) 209–222.
V.D. Anezakis, K. Demertzis, L. Iliadis, S. Spartalis, A hybrid soft computing approach producing robust forest fire risk indices, in: IFIP International Conference on Artificial Intelligence Applications and Innovations, Springer International Publishing, 2016, pp. 191–203.
T. Artés, A. Cencerrado, A. Cortés, T. Margalef, Time aware genetic algorithm for forest fire propagation prediction: exploiting multi-core platforms, Concurrency and Computation: Practice and Experience, 2016.
Y.E. Aslan, I. Korpeoglu, Ö. Ulusoy, A framework for use of wireless sensor networks in forest fire detection and monitoring, Comput. Environ. Urban Syst. 36 (6) (2012) 614–625.
E. Assareh, M.A. Behrang, M.R. Assari, A. Ghanbarzadeh, Application of PSO (particle swarm optimization) and GA (genetic algorithm) techniques on demand estimation of oil in Iran, Energy 35 (12) (2010) 5223–5229.
I. Basheer, A. Hajmeer, M, Artificial neural networks: fundamentals computing design and application, J. Microbiol. Methods 43 (1) (2000) 3–31.
J. Bedia, S. Herrera, A. Camia, J.M. Moreno, J.M. Gutiérrez, Forest fire danger projections in the Mediterranean using ENSEMBLES regional climate change scenarios, Climatic Change 122 (1–2) (2014) 185–199.
M. Bisquert, E. Caselles, J.M. Sánchez, V. Caselles, Application of artificial neural networks and logistic regression to the prediction of forest fire danger in Galicia using MODIS data, Int. J. Wildland Fire 21 (8) (2012) 1025–1029.
K. Bouabdellah, H. Noureddine, S. Larbi, Using wireless sensor networks for reliable forest fires detection, Proc. Comput. Sci. 19 (2013) 794–801.
D.S. Broomhead, D. Lowe, Radial basis functions, multi-variable functional interpolation and adaptive networks (No. RSRE-MEMO-4148). Royal signals and radar establishment Malvern (United Kingdom), 1988.
D.T. Bui, Q.T. Bui, Q.P. Nguyen, B. Pradhan, H. Nampak, P.T. Trinh, A hybrid artificial intelligence approach using GIS-based neural-fuzzy inference system and particle swarm optimization for forest fire susceptibility modeling at a tropical area, Agric. For. Meteorol. 233 (2017) 32–44.
D.K. Chaturvedi, Soft Computing: Techniques and Its Applications in Electrical Engineering, Springer, 2008.
T. Cheng, J. Wang, Integrated spatio-temporal data mining for forest fire prediction, Trans. GIS 12 (5) (2008) 591–611.
P. Cortez, A.D.J.R. Morais, A data mining approach to predict forest fires using meteorological data, in: Proceedings of the 13th Portuguese Conference on Artificial Intelligence (EPIA) Guimarães Portugal, 2007, pp. 512–523.
A. De Angelis, C. Ricotta, M. Conedera, G.B. Pezzatti, Modelling the meteorological forest fire niche in heterogeneous pyrologic conditions, PloS one 10 (2) (2015) e0116875.
M. Denham, A. Cortés, T. Margalef, E. Luque, Applying a dynamic data driven genetic algorithm to improve forest fire spread prediction, in: International Conference on Computational Science, Springer Berlin Heidelberg, 2008, pp. 36–45.
H. Du, N. Zhang, Time series prediction using evolving radial basis function networks with new encoding scheme, Neurocomputing 71 (7) (2008) 1388–
1400.
S.E. Fahlman, C. Lebiere, The cascade-correlation learning architecture, Gardner (1990).
M.W. Gardner, S.R. Dorling, Artificial neural networks (the multilayer perceptron)—a review of applications in the atmospheric sciences, Atmos. Environ. 32 (14) (1998) 2627–2636.
A. Felber, P. Bartelt, The use of the Nearest Neighbour Method to predict forest fires, Proceedings of 4th International Workshop on Remote Sensing and GIS Applications to Forest Fire Management: Innovative Concepts and Methods in Fire Danger Estimation, Ghent, Belgium, 2003.
Y.J. Goldarag, A. Mohammadzadeh, A.S. Ardakani, Fire risk assessment using neural network and logistic regression, J. Indian Soc. Rem. Sens. (2016) 1–10.
J. Han, K. Ryu, K. Chi, Y. Yeon, Statistics based predictive geo-spatial data mining: forest fire hazardous area mapping application, Web Technol. Appl. (2003), 602-602.
M. Hefeeda, M. Bagheri, Forest fire modeling and early detection using wireless sensor networks, Ad Hoc & Sensor Wireless Networks 7 (3–4) (2009) 169–224.
H. Hong, S.A. Naghibi, M.M. Dashtpagerdi, H.R. Pourghasemi, W. Chen, A comparative assessment between linear and quadratic discriminant analyses (LDA-QDA) with frequency ratio and weights-of-evidence models for forest fire susceptibility mapping in China, Arab. J. Geosci. 10 (7) (2017) 167.
H. Hotelling, Analysis of a complex of statistical variables into principal components, J. Educ. Psychol. 24 (6) (1933) 417–441.
S. Hussein Ali, Designing a Software for Classifying Objects for Air Photos & Satellite Images using Soft Computing M.Sc. Thesis, Babylon University, 2005.
S. Jain, M.P.S. Bhatia, Performance investigation of support vector regression using meteorological data, Int. J. Database Theory Appl. 6 (4) (2013) 109–118.
M. Jiang, Y.P. Luo, S.Y. Yang, Stochastic convergence analysis and parameter selection of the standard particle swarm optimization algorithm, Inform. Process. Lett. 102 (1) (2007) 8–16.
T. Kavzoglu, P.M. Mather, The use of backpropagating artificial neural networks in land cover classification, Int. J. Rem. Sens. 24 (23) (2003) 4907–
4938.
J. Kennedy, R. Eberhart, Particle swarm optimization, Proceedings of IEEE International Conference on Neural Networks (1995) 1942–1948.
B.C. Ko, K.H. Cheong, J.Y. Nam, Fire detection based on vision sensor and support vector machines, Fire Saf. J. 44 (3) (2009) 322–329.
J. Liu, Radial Basis Function (RBF) Neural Network Control for Mechanical Systems: Design, Analysis and Matlab Simulation, Springer Science & Business Media, 2013.
E.E. Maeda, A.R. Formaggio, Y.E. Shimabukuro, G.F.B. Arcoverde, M.C. Hansen, Predicting forest fire in the Brazilian Amazon using MODIS imagery and artificial neural networks, Int. J. Appl. Earth Obs. Geoinf. 11 (4) (2009) 265–
272.
E. Mahdipour, C. Dadkhah, Automatic fire detection based on soft computing techniques: review from 2000 to 2010, Artif. Intell. Rev. 42 (4) (2014) 895–
934.
A.G. Motazeh, E.F. Ashtiani, R. Baniasadi, F.M. Choobar, Rating and mapping fire hazard in the hardwood Hyrcanian forests using GIS and expert choice software, Acknowledgement to Reviewers of the Manuscripts Submitted to Forestry Ideas in 2013, p. 141.
R. Neruda, P. Kudová, Learning methods for radial basis function networks, Future Gener. Comput. Syst. 21 (7) (2005) 1131–1142.
S.N. Og˘ ulata, C. S ahin, R. Erol, Neural network-based computer-aided diagnosis in classification of primary generalized epilepsy by EEG signals, J. Med. Syst. 33
(2) (2009) 107–112.
S.K. Oh, W. Pedrycz, The design of self-organizing polynomial neural networks, Inf. Sci. 141 (3) (2002) 237–258.
S.K. Oh, W. Pedrycz, B.J. Park, Polynomial neural networks architecture: analysis and design, Comput. Electr. Eng. 29 (6) (2003) 703–725.
J.A. Olivas, Forest fire prediction and management using soft computing, in: Proceedings of the International Conference on Industrial Informatics (INDIN), 2003, pp. 338–344.
S. Oliveira, F. Oehler, J. San-Miguel-Ayanz, A. Camia, J.M. Pereira, Modeling spatial patterns of fire occurrence in Mediterranean Europe using Multiple Regression and Random Forest, Ecol. Manage. 275 (2012) 117–129.
A.M. Özbayog˘ lu, R. Bozer, Estimation of the burned area in forest fires using computational intelligence techniques, Proc. Comput. Sci. 12 (2012) 282–287.
K.S.N. Prasad, S. Ramakrishna, An autonomous forest fire detection system based on spatial data mining and fuzzy logic, Int. J. Comput. Sci. Network Secur. 8 (12) (2008) 49–55.
D.E. Rumelhart, G.E. Hinton, R.J. Williams, Learning internal representations by error propagation (No. ICS-8506), California Univ San Diego La Jolla Inst for Cognitive Science, 1985.
Y. Safi, A. Bouroumi, Prediction of forest fires using artificial neural networks, Appl. Math. Sci. 7 (6) (2013) 271–286.
G.E. Sakr, I.H. Elhajj, G. Mitri, Efficient forest fire occurrence prediction for developing countries using two weather parameters, Eng. Appl. Artif. Intell. 24
(5) (2011) 888–894.
O. Satir, S. Berberoglu, C. Donmez, in: Mapping Regional Forest Fire Probability Using Artificial Neural Network Model in a Mediterranean Forest Ecosystem, Geomatics, Natural Hazards and Risk, 2015, pp. 1–14.
M. Shourian, S.J. Mousavi, A. Tahershamsi, Basin-wide water resources planning by integrating PSO algorithm and MODSIM, Water Resourc. Manage. 22 (10) (2008) 1347–1366.
J.K. Spoerre, Application of the cascade correlation algorithm (CCA) to bearing fault classification problems, Comput. Ind. 32 (3) (1997) 295–304.
J.J. Storer, Computational Intelligence and Data Mining Techniques Using the Fire Data Set (MS Thesis), Bowling Green State University.
J. Storer, R. Green, PSO trained Neural Networks for predicting forest fire size: a comparison of implementation and performance, in: Neural Networks (IJCNN), 2016 International Joint Conference on, 2016, pp. 676–683.
A. Subasi, EEG signal classification using wavelet feature extraction and a mixture of expert model, Expert Syst. Appl. 32 (4) (2007) 1084–1093.
C.E. Van Wagner, P. Forest, Development and Structure of the Canadian Forest FireWeather Index System, For. Serv., Forestry Tech. Rep, in Can, 1987.
V.N. Vapnik, The Nature of Statistical Learning, Theory Springer-Verlag, New York, USA, 1995.
A.M. West, S. Kumar, C.S. Jarnevich, Regional modeling of large wildfires under current and potential future climates in Colorado and Wyoming, USA, Climatic Change 134 (4) (2016) 565–577.
D.W. Xie, S.L. Shi, Prediction for burned area of forest fires based on SVM model, in: Applied Mechanics and Materials, vol. 513, Trans Tech Publications, 2014, pp. 4084–4089.
L. Yang, C.W. Dawson, M.R. Brown, M. Gell, Neural network and GA approaches for dwelling fire occurrence prediction, Knowl. – Based Syst. 19 (4) (2006) 213–219.



H. Yu, T. Xie, S. Paszczynski, B.M. Wilamowski, Advantages of radial basis function networks for dynamic system design, IEEE Trans. Industr. Electron. 58
(12) (2011) 5438–5450.
T. Yu, L. Wang, X. Han, Y. Liu, L. Zhang, Swarm Intelligence Optimization Algorithms and Their Application. WHICEB 2015 Proceedings, 2015, p. 3.
C. Yuan, Y. Zhang, Z. Liu, A survey on technologies for automatic forest fire monitoring detection and fighting using unmanned aerial vehicles and remote sensing techniques, Can. J. Forest Res. 45 (7) (2015) 783–792.
L.A. Zadeh, Soft computing and fuzzy logic, IEEE Software 11 (6) (1994) 48.
J. Zhao, Z. Zhang, S. Han, C. Qu, Z. Yuan, D. Zhang, SVM based forest fire detection using static and dynamic features, Computer Sci. Inform. Syst. 8 (3) (2011) 821–841.
L. Zjavka, Wind speed forecast correction models using polynomial neural networks, Renew. Energy 83 (2015) 998–1006.
