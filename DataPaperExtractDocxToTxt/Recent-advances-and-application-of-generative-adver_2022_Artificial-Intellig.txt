Artificial Intelligence in the Life Sciences 2 (2022) 100045

		


Review
Recent advances and application of generative adversarial networks in drug discovery, development, and targeting
Satvik Tripathi a,âˆ—, Alisha Isabelle Augustinb, Adam Dunlop c, Rithvik Sukumaran a,
Suhani Dheer c, Alex Zavalnya, Owen Haslam c, Thomas Austind, Jacob Donchez e,
Pushpendra Kumar Tripathi f, Edward Kima
a College of Computing and Informatics Drexel University Philadelphia, PA 19104 USA
b College of Engineering Drexel University Philadelphia, USA
c College of Arts and Sciences Drexel University Philadelphia, PA 19104 USA
d College of Engineering Drexel University Philadelphia, PA 19104 USA
e College of Biomedcial Engineering Drexel University Philadelphia, PA 19104 USA
f Institute of Pharmaceutical Sciences University of Lucknow Lucknow, India


a r t i c l e	i n f o	a b s t r a c t

	

Keywords:
Generative adversarial networks Machine learning
Artificial intelligence Pharmacology
Drug discovery Drug targeting
A rising amount of research demonstrates that artificial intelligence and machine learning approaches can provide an essential basis for the drug design and discovery process. Deep learning algorithms are being developed in response to recent advances in computer technology as part of the creation of therapeutically relevant medications for the treatment of a variety of ailments. In this review, we focus on the most recent advances in the areas of drug design and discovery research employing generative deep learning methodologies such as generative adversarial network (GAN) frameworks. To begin, we examine drug design and discovery studies that use several GAN methodologies to evaluate one key application, such as molecular de novo design in drug design and discovery. Furthermore, we discuss many GAN models for dimension reduction of single-cell data at the preclinical stage of the drug development pipeline. We also show various experiments in de novo peptide and protein creation utilizing GAN frameworks. Furthermore, we discuss the limits of past drug design and discovery research employing GAN models. Finally, we give a discussion on future research prospects and obstacles.





Introduction

In recent years, researchers have made remarkable strides in the interconnected domains of artificial intelligence, machine learning, as well as drug design and discovery [1â€“4]. The purpose of artificial intel- ligence and machine learning approaches in the field of drug design and discovery is to develop data-driven algorithms that, in general, can help facilitate various stages of the drug development pipeline, such as drug target prediction, drug screening, and discovery, pre-clinical trials, and clinical trials [2,5,6]. The most recent developments in artificial intel- ligence and machine learning technologies, in particular, deep learning algorithms [7,8], have revealed their potentially exciting possibilities in relation to drug design and discovery [1â€“10,12â€“14]. For example, in the preclinical stage of the drug development pipeline, deep learn- ing approaches such as deep variational autoencoder [15] have been used to conduct the dimension reduction task of single-cell data for cell- specific biomarker discovery using single-cell RNA sequencing (scRNA-
âˆ— Corresponding author.
E-mail address: st3263@drexel.edu (S. Tripathi).
seq) techniques [16,17]. In this way, single-cell data for cell-specific biomarker discovery have been simplified. In addition, the synthesis of new chemical structures through the use of deep variational autoen- coder during the drug screening and discovery stage is yet another fasci- nating example of the application of deep learning methodologies [18]. Because of this, it has been hypothesized that deep learning techniques will play a crucial part in the future of drug design and discovery. This is due to the fact that the relevant applications of these approaches include a wide range of facets related to drug design and discovery [3,19].
Deep learning techniques, in their most basic form, combine vari- ous forms of sophisticated artificial intelligence with machine learning models. These models employ a number of different levels of abstraction in order to construct hierarchical representations of the data [20â€“22]. For instance, artificial neural networks can be used to construct the hi- erarchical representation [22,23]. To put it another way, deep learning techniques are computer programs that resolve the best predictions by employing artificial neural networks that include several layers, as op-


https://doi.org/10.1016/j.ailsci.2022.100045
Received 31 July 2022; Received in revised form 16 October 2022; Accepted 25 October 2022
Available online 31 October 2022
2667-3185/Â© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)



posed to employing artificial neural networks that only employ a single individual layer [22]. Deep learning algorithms have achieved a broad variety of applications in drug design and discovery [9,21]. These ap- proaches are based on the most advanced computer technologies now available, such as general-purpose computing performed on graphics processing units. There is an enormous need to employ software tools in deep learning frameworks for various drug development tasks [2] in order to address the demanding challenges we face today in the field of drug design and discovery. These challenges are presented in the form of complex problems that must be solved. To be more specific, deep learn- ing frameworks are utilized in order to serve as tools in order to ful- fill the applications of drug design and discovery, such as molecular de novo design, dimension reduction of single-cell data in pre-clinical devel- opment, compound property and activity prediction, reaction analysis, synthesis prediction, and biological image analysis [1]. These applica- tions include molecular de novo design, dimension reduction of single- cell data in pre-clinical development, reaction analysis, synthesis pre- diction, and biological image analysis.
An up-and-coming method known as the generative adversarial net- work (GAN) architecture [24] has been garnering a growing amount of interest in both the fields of artificial intelligence and machine learn- ing research as a result of recent developments in deep learning frame- works. To begin, the GAN architecture has a significant potential to be utilized in a wide variety of applications, including the creation and dis- covery of new drugs, the analysis of photos and videos, the translation of language, and other areas [25â€“28]. In addition, the implementation of the GAN architecture has been making a contribution to the study on drug design and discovery. Recent years have seen a broad range of important research investigations for the design and discovery of new drugs, such as molecular de novo design, which took into account the GAN architecture [2,9]. For instance, GAN-based frameworks such as the deep adversarial autoencoder structure have been used to design and find new drugs for anticancer therapy by utilizing chemical and biological datasets [29,30]. This has been accomplished by combining the two types of data. In addition, the deep adversarial variational au- toencoder structure has been shown to successfully complete the task of dimensionality reduction for single-cell RNA sequencing data in the preclinical stage of the drug development pipeline [28]. This is a re- markably intriguing example for a number of reasons, not the least of which is the fact that it fulfills the task. In the following sections, we will elaborate on the intricacies of several GAN-based frameworks that are used in drug design and discovery. Some examples of these frameworks include the deep adversarial autoencoder and the deep adversarial vari- ational autoencoder structures.
In this article, we review a variety of research studies that are focused
on three major categories in terms of drug design and discovery [31â€“ 35]. These categories are molecular de novo design, dimension reduction of single-cell data in preclinical development, and de novo peptide and protein design. All of these research studies are presented within the context of GAN-based frameworks [36,37]. Because, to the best of our knowledge, there may not be many studies in drug design and discovery that use the GAN-based frameworks for other applications at the time of the submission of this paper, we primarily focus on these three ap- plications employing a broad variety of the GAN-based frameworks. In light of this, the biological and/or therapeutic implications stemming from these three key sectors might potentially serve as a platform for future study in the design and discovery of drugs utilizing GAN-based frameworks [38â€“41]. In addition to this, we describe the restrictions that were placed on these research investigations and provide a sum- mary of a debate regarding the future diï¬ƒculties and directions. This review does not support the full set of related research studies that were reported in the literature [42â€“44]; however, it does describe a synthesis of those studies that have the potential to significantly influence public and population health-oriented applications in drug design and discov- ery using GAN-based frameworks in the relatively near to intermediate future.



Fig. 1. Key Components of Artificial Intelligence and Useful Outcomes in Drug and Molecular Modeling.



Artificial intelligence

Artificial intelligence (AI) is described as a scientific and engineer- ing subject concerned with the computational understanding of what is usually referred to as â€œintelligent behavior,â€ as well as the production of artifacts that display such behavior. Through his syllogisms, Aristotle endeavored to systematize â€˜proper thinkingâ€™ (logic) (three-part deduc- tive reasoning). Much of the work in the modern age was inspired by this, and early research on the workings of the mind contributed to the development of modern logical reasoning. Artificial intelligence systems are programs that allow computers to work in ways that make people appear intelligent. Alan Turing (1950), a British mathematician, was a pioneer of contemporary computer science and artificial intelligence. He characterized intelligent behavior in a computer as the ability to do cognitive activities at the level of a person. This became known as the â€˜Turing testâ€™ later on. Researchers have been investigating the pos- sible uses of intelligent approaches in every aspect of medicine since the mid-twentieth century. Gunn initially researched the application of AI technology in the field of surgery in 1976, when he investigated the potential of detecting severe abdominal discomfort with computer anal- ysis. Medical AI has experienced a boom in interest during the previous two decades (Fig. 1).
Machine Learning is defined as an assortment of complex algorithms
designed to emulate that of the human mind through learning from the surrounding environment and/or experiences. When working on ma- chine learning, there are three focuses of the model: the class of the task, the factor by which the performance must be improved by, and the source of the overall experience [45]. Using these three factors, ma- chine learning models have the optimization goal of minimizing their learning error through the use of a variety of algorithms such as gra- dient descent and backpropagation. Gradient descent looks at the error curve that the model generates compared to what it should be outputting and finds the right parameters for the model that minimizes the error. These algorithms have been applied in a very broad range of environ- ments consisting of, but not limited to: computer vision, entertainment, spacecraft engineering, finance, and computational biology [45].
There are three main types of machine learning to discuss: super- vised, unsupervised, and reinforcement learning. Supervised learning is trained on labeled data, and is used to make predictions on new data given. The predictions can come in the form of classification with out-



putting a discrete number of classes or regression outputting a continu- ous value or set of values [46]. For example, a machine learning model such as linear regression classifying a given image as containing a cat or a dog would first need to be separately shown images of a cat and a dog to learn the features within the images to then compare to the features of a new image. For regression, a model could be trained on the previous sales of a company to then create a numerical prediction to forecast future sales and growth of the next year.
Unsupervised learning uses unlabeled data clusters and creates asso- ciations among the data points in order to identify any similarities and sequences of repeating patterns among the data [47]. For example, if a company wants to segment its customer base into a range of clients from low to high priority, then it would use an unsupervised learning model such as a gaussian mixture model to market its product towards a certain customer segment in a given season. Another important use of unsupervised learning is to prepare an unlabeled dataset for a supervised learning task which is a hybrid task called self-supervised learning.
Both supervised and unsupervised learning involves the optimiza- tion of each modelâ€™s parameters, their weights, and other hyperparam- eters, in order to minimize the error the model produces. However, re- inforcement learning involves training a model that interacts with its environment in order to maximize a reward. The reinforcement agent is rewarded for desirable behaviors, such as an autonomous agent being able to walk properly, and is punished for undesirable behaviors such as the agent falling [48].
Deep learning is defined as a multi-layered learning module, referred to as a neural network. A neural network is composed of non-linear modules, transferring and converting the information between its lay- ers. These non-linear modules are called activations which, similarly to a biological neuronâ€™s activation potential, determines how strongly infor- mation passes through the network. The activations in a neural network are determined by activation functions, which are subsequently deter- mined as a parameter in the system [49]. Backpropagation is the popular process of training neural networks by defining a function, and using the hill-climbing technique to optimize performance on a set task. This op- timization calculates the mathematical gradient of a loss function with respect to the neural networkâ€™s other weights. Backpropagation has be- come very popular due to its simplistic implementation, and the ability to train non-linear networks of arbitrary connectivity [50].
One of the first known works of artificial intelligence takes place in the late eighteenth century, with the creation of Ç£The TurkÇ¥, an au- tomated chess-playing machine that would be able to compete against its opponents [51]. It would not be for over 150 years, until 1942, that one can see another example of AI, Ç£The BombeÇ¥. Alan Turning created Ç£The BombeÇ¥, an electromechanical device, to aid the British in break- ing German codes towards the end of World War II. From this point, the beginning of computation, and thus, AI took off [52]. In 1950, Alan Turing published the Ç£Turing TestÇ¥, which is detailed in the definition of AI, as seen above [53]. Six years later, the Ç£beginning of AI springÇ¥ occurred at the Dartmouth Summer Research Project on Artificial In- telligence (DSRPAI). This project lasted over the course of eight weeks, with the final goal being to gather researchers and create an area that focuses on building machines that simulate the human experience.
Upon the end of the project, it was considered a success within the world of artificial intelligence [54]. Soon after this, the machine learn- ing program Ç£perceptronÇ¥ was created in 1958, in the Cornell Aero- nautical Laboratory. This program was originally designed as an image recognition service, but is now used as an algorithm for binary classi- fiers; binary classifiers determine whether an input belongs to a specific class [55]. Five years later, in 1963, Feigenbaum and Feldman published Ç£Computers and ThoughtÇ¥, which describes the internal workings of AI programs at a fairly basic level. This publication was influential in spreading the word about artificial intelligence. Following this, it took another 35 years for any other significant impacts to be made within the field [56]. In 1998, researchers were able to develop a revolution- ary new way of using trainable filters to learn patterns from images.
This program, coined the Convolutional Neural Network (CNN), allows AI to work much easier with image recognition, ending any possible interference from pixel resolution [57].
This concept of a CNN was further developed, as in 2012 the winner of the ImageNet Large Scale Visual Recognition Challenge was a pro- gram called AlexNet. This program used a deep convolutional neural network to win, achieving a model error of only 15.3 percent. Another revolutionary concept utilized within this program was that AlexNet uti- lized GPUs during training to show modern-day AI models can become more powerful with the inclusion of GPUs [58]. Then, two years later in 2014, Ian Goodfellow created the GAN, a type of machine learning in which the goal is: given a training set, the program can create new data with the overall same statistics as the old learning set. GANs have since been used in fashion, art, and advertising, science, video games, and is the underlying process that is used to generate deepfakes, which are often applied within medicine [59]. The following year, Google cre- ated the AlphaGo system, which is an artificial neural network that plays the board game Ç£GoÇ¥. This program utilizes a Monte Carlo tree search algorithm to find its moves based on previously acquired knowledge. The newest version of AlphaGo is currently ranked as the best player in the world at Ç£GoÇ¥ [60]. Google then continued its work in neural net- works into 2017 to improve the accuracy of their language translations. This approach uses a constant number of model parameters, leading to a much simpler process than any previous iteration [61]. Googleâ€™s efforts with AI do not end there, as in 2021, Google DeepMind created the pro- gram AlphaFold, which was a key component in determining the shape of a 3D protein. On top of this, it outperformed 100 other research teams in a protein structure prediction challenge, showing how influential this new age of AI can be [62] (Fig. 2).
The challenge of modern medicine is obtaining, evaluating, and us-
ing a significant quantity of knowledge required to treat complicated clinical issues. The advancement of medical artificial intelligence has been linked to the creation of AI algorithms designed to assist doctors in the formulation of a diagnosis, the formulation of treatment decisions, and the prediction of results. They are intended to aid healthcare staff with activities that require the processing of data and expertise in their daily jobs. Deep neural networks (DNNs), Unets, fuzzy expert systems, evolutionary computation, and hybrid intelligent systems are examples of such systems.
AI has the potential to fundamentally alter medicine in the next few years. The field of medical AI has advanced significantly in just a few years since the first landmark demonstrations of medical AI algorithms that were able to diagnose a disease from medical pictures at the level of specialists. Today, while the medical AI community navigates the diï¬ƒcult ethical, technological, and human-centered obstacles necessary for safe and successful translation, the deployment of medical AI systems in everyday clinical care represents a significant but largely unrealized potential.

Recent progress in the application of AI in medicine

Despite the fact that AI systems have frequently been proven to be successful in a wide range of retrospective medical investigations, only a small number of AI tools have been applied to medical practices. Critics argue that AI systems may be less beneficial in practice than retrospec- tive data would suggest; systems may be too sluggish or diï¬ƒcult to be effective in real-world medical settings, or unexpected issues may occur from the way humans and AIs interact. Furthermore, retrospective in silico datasets is subjected to intensive filtering and cleaning, making them less representative of real-world medical practice.
RCTs and prospective studies help bridge the gap between theory and practice by more thoroughly establishing that AI models can have a quantifiable, beneficial impact when used in real-world healthcare set- tings. RCTs have recently been conducted to assess the use of AI systems in healthcare. Aside from accuracy, a range of additional criteria has been employed to assess AIâ€™s value, offering a comprehensive picture




Fig. 2. Applications of Artificial Intelligence in Healthcare [63].


of its influence on medical systems (9â€“13). An RCT evaluating an AI system for managing insulin doses, for example, tracked the number of time patients spent within the target glucose range; a study evaluating a monitoring system for intraoperative hypotension tracked the aver- age duration of hypotension episodes; a system that flagged cases of in- tracranial hemorrhage for human review was judged on its turnaround time.
Recent guidelines, such as AI-specific extensions to the SPIRIT and CONSORT guidelines, as well as upcoming guidelines like STARD-AI, may help standardize medical AI reporting, including clinical trial pro- tocols and results, making it easier for the community to share findings and rigorously investigate the utility of medical AI17,18. Some AI sys- tems have progressed from testing to implementation in recent years, gaining administrative backing and resolving regulatory diï¬ƒculties. The Centers for Medicare and Medicaid Services, which oversees public in- surance payment fees, has made AI more accessible in clinical settings by enabling funding for the use of two particular AI systems for medical image diagnosis.
Furthermore, a 2020 research discovered that the US Food and Drug Administration (FDA) is rapidly approving AI goods, notably machine learning. These advancements primarily take the form of FDA clear- ances, which require devices to achieve a lower regulatory threshold than full-fledged approvals, but they do pave the way for AI/ML sys- tems to be utilized in genuine clinical situations. It should be noted that the datasets utilized for these regulatory approvals are frequently made up of retroactive, single-institution data that is mainly unpublished and deemed proprietary. Stronger requirements for reporting openness and validation, as well as evidence of influence on clinical outcomes, will be essential to develop confidence in medical AI systems.
Significant advances in pathology, mostly through the use of whole- slide imaging, have been made in identifying malignancies and offering novel disease insights. Models have successfully identified regions of in- terest within slides, possibly speeding up diagnostic operations. Aside from this practical impact, deep neural networks have been trained to distinguish the main tumor origin and find structural variations or driver mutations, delivering benefits that outperform expert pathologist evalu- ations. Furthermore, when compared to conventional grading and histo- logical Through subtyping, AI has been demonstrated to produce more accurate survival forecasts for a wide variety of cancer types. Such re- search has shown how AI may improve the eï¬ƒciency, accuracy, and utility of pathology diagnosis.
cancer. Deep learning has been used to predict if colonic lesions are cancerous, with results equivalent to those of competent endoscopists. Furthermore, because polyps and other potential indicators of illness are usually overlooked during the exam, artificial intelligence (AI) technolo- gies have been created to aid endoscopists. Such technologies have been demonstrated to increase endoscopistsâ€™ capacity to identify anomalies, potentially boosting sensitivity and making colonoscopy a more reliable diagnostic tool.
Deep learning models have been widely used in ophthalmology, with significant progress toward deployment. In addition to evaluating model effectiveness, research has looked into the human impact of such models on healthcare systems.
One study used human observation and interviews to assess how an AI system for eye disease screening influences patient experience and medical workflows. Other studies have investigated the financial impact of AI in the ophthalmology field, discovering that semi-automated or completely automated AI screening may provide cost savings in some situations, such as the identification of diabetic retinopathy.
Rise of GANs

Definition

tures the probability distribution ğ‘(ğ‘‹) of some sample data ğ‘‹ by match- Generative modeling is an unsupervised learning technique that cap-
ing the probability distribution of our model to the probability distribu-
approximation of the function ğ‘(ğ‘‹) that models the probability distri- tion of the sample data. The two main ways this is done is by learning an
bution through density estimation. The second technique involves sim- ilarly learning a probability distribution to generate new data samples
ğ‘‹Ì‚ that is compared to the actual data ğ‘‹. Either way, modeling a proba-
bility distribution becomes increasingly complex as different data types
such as images and text typically have high dimensional distributions that become diï¬ƒcult to model. That said, generative models are capa- ble of uncovering the underlying features of a dataset in a completely unsupervised way.
Generative models can also be applied to classification such as its architecture in the Naive Bayes Classifier, the generative model learns
the joint probability distribution ğ‘(ğ‘‹, ğ‘Œ ) of the input ğ‘‹ and the label ğ‘Œ
by using Bayeâ€™s Theorem to calculate ğ‘(ğ‘Œ ğ‘‹) [64].
Where  ğ‘(ğ‘Œ |ğ‘‹) is found through:

Deep learning has also advanced in gastroenterology, particularly in
terms of enhancing colonoscopy, a critical test for detecting colorectal
ğ‘(ğ‘Œ |ğ‘‹) = ğ‘(ğ‘‹|ğ‘Œ )ğ‘(ğ‘Œ )
(1)



is to then use the calculated ğ‘(ğ‘Œ |ğ‘‹) to predict the most likely label ğ‘Œ The goal of a generative classifier such as the Naive Bayes Classifier


Over ğ‘ instances, the equation becomes:
1 âˆ‘

uses conditional probability to find ğ‘(ğ‘Œ ğ‘‹), but instead does so through looking for a direct mapping from ğ‘‹ to the data labels ğ‘Œ [64]. The key
difference between discriminative and generating modeling is that in- stead of modeling the conditional probability of the data and generating new samples, the goal of discriminative modeling is to separate one class from another by creating decision boundaries. Logistic Regression is an example of a discriminative model that uses a decision boundary in the form of a line to separate the data into two parts for binary classifica- tion and outputs the probability of a data point belonging to one of two classes.
In a study comparing discriminative and generative models used for
classification tasks on various datasets from the University of California
Where âˆ‡ğ¿ is calculated and the hyperparameters of the generator and
these expressions, ğ‘¦Ì‚ is not a constant, and is the output of an activation discriminator are adjusted accordingly to minimize the loss function. In function ğ‘¦Ì‚ = ğ‘(ğ‘§) where ğ‘(ğ‘§) would typically be the ReLU or sigmoid activation functions ğ‘…ğ‘’ğ¿ğ‘ˆ (ğ‘§) = max(0, ğ‘§) and ğœ(ğ‘§) = 1âˆ’ respectively.
work, we define a function ğ‘§(ğ‘¤, ğ‘¥, ğ‘) = ğ‘¤ğ‘¥ + ğ‘ that outputs the activa- Within each neuron and each weight in the discriminator neural net-
tion of that particular neuron. In practice, the weights and biases are vectorized. In order for gradient descent to be performed, the gradient of the loss function with respect to the weights are computed via the chain rule:

Irvine Machine Learning Repository, A. Ng et al found that discrimina-
ğœ•ğ¿(ğ‘¦Ì‚, ğ‘¦) = ğœ•ğ¿(ğ‘¦Ì‚, ğ‘¦) ğœ•ğ‘(ğ‘§) ğœ•ğ‘§
(4)

tive models such as logistic regression tend to have lower errors after
ğœ•ğ‘¤
ğœ•ğ‘(ğ‘§)
ğœ•ğ‘§
ğœ•ğ‘¤

training is complete but generative models such as Naive Bayes tend to converge much faster and result in shorter training times [64]. Would
Where the gradient of the loss function with respect to the activation function is calculated as follows:

it be possible to avoid having to deal with the tradeoff of both types
ğœ•ğ¿(ğ‘¦Ì‚ = ğ‘(ğ‘§), ğ‘¦) = âˆ’ ğ‘¦
+  1 âˆ’ ğ‘¦
(5)

of models by combining the efforts of both of these distinct styles? The
ğœ•ğ‘¦Ì‚
ğ‘(ğ‘§)
1 âˆ’ ğ‘(ğ‘§)

need for a hybrid model arises from attempting to model data with com- plex distributions. Modeling a distribution directly is often impossible
and the gradient of the activation function with respect to the weights is

since approximating the distributions of advanced data types such as
ğœ•ğ‘§ =  ğœ• (
+ ) =

images, audio and text involves too many probabilistic computations to
scale with larger amounts of data [59].
ğœ•ğ‘¤
ğ‘¤ğ‘¥  ğ‘
ğœ•ğ‘¥
ğ‘¥	(6)

In 2014, Deep Learning researcher Ian Goodfellow et al created a rev- olutionary new unsupervised learning model, the Generative Adversar-
which results in for whatever activation function ğ‘(ğ‘§) is chosen
ğœ•ğ¿(ğ‘¦Ì‚, ğ‘¦) = (âˆ’  ğ‘¦  +  1 âˆ’ ğ‘¦  ) ğœ•ğ‘(ğ‘§) ğ‘¥	(7)

ial Network (GAN), that involves a generative model competing against
ğœ•ğ‘¤
ğ‘(ğ‘§)
1 âˆ’ ğ‘(ğ‘§)
ğœ•ğ‘§

a discriminative model as adversaries to produce new data samples that canâ€™t be distinguished from the training data [59]. When random noise,
a simple distribution to model, is passed through a multilayer percep-
weights of the discriminator using ğœ‚  as the learning rate. and is then finally used in the gradient descent algorithm to update the

tron, the generator learns the transformation from the random noise distribution to the target data distribution. The discriminator is trained
ğ‘¤ = ğ‘¤ âˆ’ ğœ‚ ğœ•ğ¿(ğ‘¦Ì‚, ğ‘¦)
ğœ•ğ‘¤
(8)

to distinguish the real samples from those generated by the generator. The optimization goal of the generator is to maximize the probability of the discriminator detecting its generated samples as true, which is when the discriminator makes a mistake, and the goal of the discriminator is to correctly classify the generated samples between the true data and the fake data generated by the generator. Training is stopped when the generated samples from the generator canâ€™t be distinguished from the real samples by the discriminator.
One of the biggest inspirations for GANs came from deep Boltzman machines that likewise utilized two separate processes running at the same time while training which included a positive and negative phase [59]. The positive phase loaded in data and made it more likely, and the negative phase drew samples and made them less likely. Through iterative training, the distribution of the samples becomes closer to the distribution the model represents. The parameters of the model are up- dated at the same time as new samples are being generated. However, it was found that deep Boltzman machines lacked the capability to scale past the greyscale MNIST digits dataset, and for example, were unable to generate color image samples in a timely manner. This is caused by the negative phase being unable to keep up with the speed of the posi- tive phase generating samples which prevents deep Boltzman machines from converging to a useful state.
Since multilayer perceptrons are used for the discriminative and gen- erative models, both models can be trained using backpropagation and are typically trained with dropout regularization [59]. For the discrim-
entropy loss function is used with the true label ğ‘¦ and the predicted label inator, since itâ€™s being trained as a classification task, the binary cross
ğ‘¦Ì‚:
ğ¿(ğ‘¦Ì‚, ğ‘¦) = âˆ’ğ‘¦ğ‘™ğ‘œğ‘”(ğ‘¦Ì‚) âˆ’ (1 âˆ’ ğ‘¦)ğ‘™ğ‘œğ‘”(1 âˆ’ ğ‘¦Ì‚)	(2)
As for training the generator, it must be alternated as the discrim- inator trains. The generatorâ€™s loss comes from the penalization of the discriminator correctly classifying its generated sample as fake. As back- propagation flows from the output of the discriminator through the dis- criminator itself, it then additionally will flow into the generator so that the generatorâ€™s weights will be updated without changing the discrimi- natorâ€™s weights. Then in the next epoch, backpropagation flows through the discriminator and the discriminatorâ€™s weights are updated while keeping the generatorâ€™s weights constant. This process repeats until the discriminatorâ€™s performance becomes 50% accurate which indicates that the generator is able to generate realistic samples of the data that the discriminator canâ€™t tell between the fake, generated samples and the real ones.
Itâ€™s important to note that the discriminator portion of the GAN model has been applied to more broad classification problems with mul- tiple classes as opposed to only determining if itâ€™s real or fake. Using semi-supervised learning results in an ability to train with far fewer training labels than previous and faster convergence.
GANs have been used in many different applications, but most no- tably in the generation of new, artificial faces. This can then be used to create videos of famous figures that are completely artificially generated but are realistically looking to fool the human eye. In the wrong hands, GANs can be used to create and promote fake news with artificially generated content about real people, otherwise known as deepfakes, to potentially be used to destroy the reputations of said people. Thus, itâ€™s vital that this powerful deep learning technology be used responsibly for the good of humanity.

Architecture
Generative Adversarial Networks (GANs) are comprised of two neu- ral networks: Generator and Discriminator. The generator generates



plausible data, and the discriminator distinguishes between what part of the data is real or fake. The generator uses the feedback from the dis- criminator to update its weights and biases in order to generate data that can better fool the discriminator by looking more real. The discrimina- tor will then begin to perform worse on the data and will have to update itself to perform better. After this, the generator will be able to use the feedback from the new discriminator to better improve its own data generation. This cycle continues until convergence. For image genera- tion applications, the discriminator is typically a Convolutions Neural Network (CNN) and is able to adapt to the underlying distribution of data. It will perform a binary classification to distinguish between the real and the generated data.
After Goodfellow et al published the Generative Adversarial Nets pa- per, the Deep Learning research community became amazed at how ef- ficiently higher-quality samples were generated. Soon after, Mirza et al modified the GAN architecture by feeding the input data into both the discriminator and generator, and created the Conditional GAN (CGAN) [65]. The CGAN allows you to dictate what type of data should be gen- erated with a condition based on class labels or any modality. In applica- tion, this can be used to identify which parts of the road are important for an autonomous driving vehicle to avoid that were not part of the original training environment, or what sections of a brain scan are signs of a disease external to the current experiment (Fig. 3).
A year later, Denton et al combined the CGAN with a Laplacian pyra- mid to break up the generation of images through multiple CNNs into successive refinements [66]. The Laplacian GAN (LapGAN) was the first GAN architecture to be able to generate high-resolution images by first generating images at a low resolution and then scaling to successive higher resolutions. This was done by taking the difference between the generated images and their blurred counterparts to produce a learnable filter.
A few months later, Radford et al were trying to integrate the CNN architecture, previously used in supervised learning, into the unsuper- vised learning goal of GANs in order to better suit computer vision tasks. They solved their issues of scaling the CNN architectures with GANs by replacing all of the pooling layers with strided and fractional strided convolutional layers [67]. Additionally, the fully connected layers that typically connected the final convolutional layers to the output neurons are removed. The generator takes in input samples and generates con- volutional filters from which the discriminator deconvolves the filters into an image and classifies the generated image. This is called a Deep Convolutional GAN (DCGAN), and what makes this architecture unique is its simplicity and ability to show the connection between certain fil- ters and specific objects those filters learned in a dataset with purity. The simplicity allows for fewer points of error and easier manipulation of the semantic qualities of generated samples. In practice, DCGANs was able to generate much more realistic images of faces than previous ar- chitectures and started to get attention in the media for their application of generating new videos with faces of famous figures known as deep- fakes. DCGAN became a backbone used for many more variants being created in the following years, which created a Cambrian explosion of new GAN architectures being created.
One such model was the Wasserstein GAN (WGAN) created by Face-
book researchers. It became famous due to its ability to train with- out requiring balanced training of the generator and discriminator as well as reducing the mode-dropping issue found in previous GAN ar- chitectures [68]. In the WGAN, the discriminator is able to be com- pletely trained to its optimal and provides a loss directly to the gener- ator, so as the discriminator increases its accuracy it provides higher quality gradients to train the generator with. As the generator neural networkâ€™s architectures vary, WGANs were found to be more robust than GANs [68]. The researchers also created a new metric, the Wasser- stein estimate, that describes the generatorâ€™s convergence and quality of the generated samples, which when graphed against the number of training iterations is useful for model debugging and hyperparameter tuning.
Interpretability has always been an important goal when creating and using Deep Learning models, and one such variant of GANs fo- cuses on learning interpretable and meaningful representations of the data through applying feature representational learning [69]. The In- formation Maximizing Generative Adversarial Network (InfoGAN) is a completely unsupervised learning model that is known for its ease of training, and its interpretable results that prove to be crucial in appli- cations and competitive with representations from supervised learning models. InfoGAN was able to uncover and represent writing styles from digit shapes in the MNIST dataset, poses from 3D rendered images when lit, background digits from the central digit on the SVHN dataset, and hairstyles and emotions on the CelebA face dataset.
Researchers from UC Berkeley found a solution to the image-to- image translation task, where a new image is generated that is a mod- ification of the original image, and created the CycleGAN model. The biggest issue with training a GAN for image translation is that a large dataset of original images and their desired modified versions are ex- tremely expensive to create and often donâ€™t exist. CycleGAN instead trains two discriminator and generator models by using cycle consis- tency to have the first generator learn the original images and generate the modified versions which are then learned by the second generator to generate new images as close to the original as possible [70]. An ad- ditional loss metric is a difference between the generated original image from the second generator and the original image which guides the gen- erators toward generating translated images. One of the most impactful applications of this methodology is style transfer where the modified image is of the same style as the original. For example, an image of a dog can be style transferred with a Van Gogh painting to have Cycle- GAN generate a new image of the same dog as Van Gogh would have painted.
Researchers at Nvidia further utilized style transfer techniques to cre- ate the StyleGAN model that automatically learns high-level attributes and stochastic variation in images, the â€œstylesâ€, that allow the genera- tor to create new images with scale-specific control with better inter- polation properties and better latent variable disentanglement [71]. In practice, this allows for the significantly higher quality and more real- istic generation of human faces as the â€œstylesâ€ learned by the generator are the unique characteristics of the images of human faces from the training dataset.
Researchers from Google created the famous Transformer architec- ture that connects the encoder, the generator, and the decoder, the dis- criminator, through an attention mechanism [72]. An attention mech- anism looks for the most relevant parts of a dataset through using a weighted combination of input vectors with the most relevant input vectors granted the highest weights. This same architecture was then applied to a convolutional based GAN model called the Self-Attention Generative Adversarial Network (SAGAN) [73]. SAGANs are able to gen- erate data with details across the entire high resolution feature map as opposed to previous models only generating data with details in local points from lower resolution representations of the data. With SAGANs being attention-driven from utilizing the self attention architecture in both the generator and discriminator, they are able to converge must faster than other GAN architectures and achieve state of the art results with the ImageNet dataset [73].
Ultimately, all of these GAN architectures mentioned show how fast the field of Deep Learning has been developing in recent years, and how the vast usecases of GANs have allowed them to become one of the most impactful Deep Learning models in recent times.

Mathematics
We define the Discriminator as function D(x), which determines the probability of an input x being a real piece of data as opposed to one generated by the Generator. We also define the Generator as function G(z), which generates a piece of data based on input z.
We train the function G(z) to fool the Discriminator by training it to minimize the value of log(1 - D(G(z))). Note that as D(G(z)) gets larger




Fig. 3. Backpropagation in Discriminator and Generator Training [11].


(indicating that the discriminator believes a piece of generated data is real), log(1 - D(G(z))) gets smaller. Simultaneously, we train the function D(x) to assign the correct labels to both the real data and the samples from G.
Therefore, the loss function of a generative adversarial network can be modeled as the following:
min max ğ‘‰ (ğ·, ğº) = ğ”¼ğ‘¥âˆ¼ğ‘data (ğ‘¥)[log ğ·(ğ‘¥)] + ğ”¼ğ‘§âˆ¼ğ‘ğ‘§ (ğ‘§)[log(1 âˆ’ ğ·(ğº(ğ‘§))]   (9)
The interplay between the Generator and Discriminator can be modeled mathematically as a zero-sum game, a situation where one partyâ€™s im- provement is always equal to the otherâ€™s loss - in other words, the gains and losses of each party always sums to zero.
For example, imagine that the Generator creates images that are clas- sified as real by the Discriminator 25% of the time. Therefore, the Gen- erator has a 25% accuracy, and the Discriminator has a 75% accuracy. Now imagine that the Generator improves itself with feedback from the Discriminator, so that the Generator is now 80% accurate. Therefore, the Discriminator must be 20% accurate. In other words, the Generator has improved by 55%, and therefore, the Discriminator must have lost 55% points of accuracy.
However, this poses a problem for creating a loss function for a GAN. If we try to only maximize the performance of the Generator, the best course of action would be to have the Discriminator perform poorly, and vice versa. In 4.1.1, future variants of GANs discussed all tweaked their equations to minimize this situation from occurring (Table 1).

Applications of GANs

General Adversarial Networks have found a range of applications, helping to overturn and accelerate innovation in industries ranging from video prediction to realistic photograph generation and medicine.
For our review we focus on the drug discovery and development based applications of GANs [44,74â€“78].

Drug discovery

Drug discovery is the process in which new medications are discov- ered. Traditionally, drug discovery worked in a very counter-intuitive way to what we see today. Chemists would study the effects of different remedies without a biological target in mind, meaning they hypothe- sized some chemicals would have effects and they tested to see where in


Table 1
Summary of Popular GAN Variants.



the body the effects would target. This style of medical practice has now become outdated in the modern world as different technologies such as computing has allowed researchers to gain knowledge on how to iden- tify on specific targets in the body in order to study their effectiveness. It constitutes computational and experimental research that is under- gone in order to identify potential new drugs to address certain medical conditions. The process of drug discovery is an arduous and resource- intensive one [102], and GANs may have applications in streamlining it [94,103â€“106].
An area that makes GANs an exceptionally strong tool in drug re- search is how it can be used in searching for new molecules. An issue with the traditional method of drug discovery involved an inability to exhaustively cover all possible outcomes in a chemical space, which is a concept in chemistry referring to the property space of all chemical compounds bound by a given set of conditions and principles. What this means is there are so many possible molecules that it is not feasible for a researcher to find the best options when looking between similar com- pounds which might have comparable, yet slightly contrasting, effects as a drug. It should be noted that GANs are not perfect in the field of chemical space, but they are more successful here than any competing method. This is where GANs strive, as deep learning models can be con- structed to help find compounds with desired functionality [107,108]. Different biological models such as evolutionary data, diversity algo- rithms, and population trends can be used to create training data for the GANs. Once the GAN is and trained on those types of data, two main re- sults are produced. Firstly, there are several new drug variations which can then be tested for their functionality and have their side effects min- imized. Secondly, this production allows the GANs to expand or update its generated variations and constantly improve within the constraints of the chemical effect the researcher is seeking during the training pro- cess. However, an issue with this method is mode collapse, which causes the generator to only produce samples closely related to a tiny subset of its training data. To combat this, a study done by Blanchard et al con- stantly updated the training data and recombined during replacement [107]. This minimization of the core weakness for the use of GANs in this area shows massive future potential for the future in accelerating drug discovery (Table 2).
Two of the issues in relation to drug research that GANs are being
used to help resolve are the issues involving the heavy cost and over- all time for drug research, but one issue that has come up for GANs itself involves the limitation when working to explore some regions of chemical space. We previously referenced how GANs work better than other traditional methods as well as newer deep learning when it comes to chemical space, but innovations in GANs look to expand and solve this shortcoming of not having complete access to chemical space. A fully quantum GAN could accelerate the training process for GANs, as well as offer better training samples which could allow more exploration of chemical space but lacks the ability to process over two dimensions [109]. In the future, a fully quantum GAN could be viable and success- ful, but more innovation in the technology is currently needed. In the
Table 2
Summary of Most Popular Applications of GANs.





meantime, a paper proposing a qubit-eï¬ƒcient quantum GAN mechanism with a hybrid generator and classical discriminator as a tool in drug re- search. Due to requiring less qubits, complex simulation would still be the main function of this model while requiring around 20% less train- ing time and being more successful in searching chemical space [109]. Mode collapse is again an issue with this model. Even with the swifter training, mode collapse can still occur meaning the GAN learns one as- pect of the data quite well, but not all the data is being properly learned causing incomplete training. The results of this model showed a 98% reduction in generator parameters and created the expected benefits of the hybrid system with quicker data learning as well as more success-




Fig. 4. A Timeline Depicting the Major Advances Leading Up to GANs and Development in Drug Discover.


ful chemical searching. The reduction of parameters allows for much swifter training and simpler methods of hyperparameter tuning (Fig. 4). GANs are being seen to have applications in de novo peptide and pro- tein design, a process through which new peptides and proteins are dis- covered. This process entails generating new chemical entities that fit a set of constraints using computational algorithms. Hence, the chemical entities can be generated without a starting template from the begin- ning, reflecting the meaning of the phrase de novo [110]. As summa- rized by Lin et al, [109], there have been many studies done regarding the applications of GAN-based approaches in de novo peptide and pro- tein design. Sabban and Markovsky [111] proposed that the LSTM-GAN (Long Short-Term Memory Generative Adversarial Network) structure was able to generate new helical protein backbone topologies. While the LSTM-GAN structure had originally been devised for applications in Natural Language Processing, this group of researchers was able to find uses for it in generating protein backbone topologies with features
beneficial for protein design.
Lin et al continue to describe another group of researchers, Karimi et al. [112] who investigated the gcWGAN (guided conditional Wasser- stein General Adversarial Network) structure and its applications in pep- tide folding. This conditional Wasserstein GAN structure is derived from the Wasserstein GAN [68] with gradient penalty. The Wasserstein GAN, as proposed by Arjovsky et al., is a type of GAN architecture which uses
the Earth-Mover distance rather than the Jensen-Shannon divergence of a traditional GAN. gcWGAN builds upon a conditional Wasserstein GAN using an oracle. The conditional GAN generates sequences, and the oracle predicts a fold for each sequence. Each predicted fold serves as feedback for the generative module. Furthermore, Lin et al. outline two separate groups of researchers who looked into the DCGAN(Deep Convolutional Generative Adversarial Network) structure and its appli- cations in drug discovery. One group, Anand and Huang [113] found that it can be applied to generate new protein structures. Both the gen- erative and discriminative modules were implemented using a convo- lutional network structure, a structure traditionally used in computer vision tasks. Another group, Bian et al. [114] proposed that the DCGAN could be used to generate target-specific compounds for cannabinoids through the use of developed convolutional neural network frameworks such as LeNet-5. Thus, both groups of researchers found applications of the DCGAN structure in de novo peptide and protein design in drug de- sign through the implementation of the generative and discriminative modules using a convolutional neural network structure (Fig. 5).
Another example of a GAN-based structureâ€™s relevance to drug de- sign is in the promulgation of the GANDALF(Generative Adversarial Net- work Drug-tArget Ligand Fructifier) framework. This framework, im- plemented by Rossetto and Zhou [115], was able to generate a peptide highly similar to FDA approved drugs for a given target. The GANDALF




Fig. 5. An Example of Vanilla GAN Architecture for Molecule Development.


framework also uses the DCGAN structure, using a five-layer convo- lutional neural network for the generative and discriminative network modules.
Another GAN structure, Feedback-GAN, was shown by Gupta and Zou [116] to be able to generate antimicrobial peptides with desirable properties. This structure consists of a GAN and differentiable neural network analyzer. This differentiable neural network analyzer is a pre- diction algorithm that determines if a gene sequence is able to encode a peptide. The analyzer and the GAN architecture are connected through a feedback-loop training mechanism which allows the generative module to create valid sequences. In each epoch, the generative module pro- duces many sequences, which then receive a score from the differen- tiable analyzer. The sequence with the highest score is then passed as input to the discriminative module. The discriminative module receives both real inputs and fake inputs(in the form of the generated sequences) then differentiates between the two types of inputs.
A research used GANS with adaptive training data for drug discover. During the training period, the model saved new and valid compounds it generates. The training data then updated using a replacement tech- nique that may be either directed or random. The technique was re- peated when the training resumes. The findings suggest that this method can counteract the decline in new molecules created by a normal GAN during training. In addition, using recombination between created com- pounds and training data to boost novel molecule discovery. By includ- ing replacement and recombination into the training process, GANs may be used for larger drug discovery searches[107].
Researchers have also found applications of GANS in regards to molecular de novo design as well as de novo protein and peptide design. Guimaraes et al. [117] proposed the ORGAN(Objective-Reinforced Gen- erative Adversarial Networks) structure, a structure combining the GAN with reinforcement learning. More specifically, the structure consists of a Sequence GAN model and the recurrent neural network model. The discriminative module is implemented as the convolutional neural net- work model and the generative module is the recurrent neural network model. Guimaraes et al. found that the ORGAN structure was suï¬ƒciently able to generate new molecular compounds with preferred properties through a drug development pipeline. Furthermore, the ORGAN struc- ture was able to do so with better results than just a recurrent neural network model or a GAN model alone.
Drug development

With the traditional method of drug discovery, it was said how it pre- viously was diï¬ƒcult to specifically target areas in the body in research, which prompted researchers to work backwards in testing remedies with previously unknown effects. Along with other modern methods, this is a key area in which GANs look to improve research in drug discovery. GANs can be used to predict binding aï¬ƒnity, and therefore the success-
ful of a drug being researched [118]. Deep learning models can work to identify drugs which have high aï¬ƒnity when binding to specific dis- ease proteins, which is beneficial for drug discovery as it expedites the process for researchers. The strength of GANs in this area comes from advantages in both speed and cost. Other machine learning models in the past have been able to accomplish similar predictive ability, but GANs require less manual input as well as need less expensive costs for building their training data due to the reusing of parts of the generator and discriminator networks as feature extractors.
A study on maximizing the effectiveness of GANs in this area used three elements: a feature extractor for protein compound, a feature ex- tractor for protein sequence, and a regressor for aï¬ƒnity value prediction [118]. In the first round of training, the fake samples are generated by the generator of the GAN and both the fake as well as real samples are put into the discriminator. The discriminator will then work to clas- sify the samples as real or fake so that the generator can create more realistic protein sequences and compounds, which are labeled by the discriminator. In the second round, labeled protein sequences are used to train the regressor to minimize its loss and create optimal model pa- rameters. These parameters can then be used in a feature extracting model and a regression model [118]. Results from using these models showed that GANs can perform as well if not better than previously used learning-based models with the added factor of GANs training on freely unlabeled data and coming at a lower cost by guiding biological experiments. These newly created models by the GAN help create the beneficial protein sequences which can help biologists in targeting the needed cell receptors in drug discovery. The main downside in results was GANs poor performance when dealing with very small data sets, but this can be offset by regularization techniques to train GANs.


Biomolecular

GANs are being used to create synthetic DNA sequences that code for proteins of varying lengths. One study used the feedback-loop process to generate synthetic genes that code for antimicrobial peptides and to optimize synthetic genes for the secondary structure of the peptides they produce. A number of measures show that the proteins created by GAN have desired physicochemical characteristics [116].
DL models are used to learn the nonlinear probability distribution between molecular chemical structures and their biological and phar- macological characteristics from enormous data sets, and then execute in silico creation of de novo molecules with desired features in the lab- oratory [120â€“122].
For example, a QSAR methodology is defined by an ML application and/or statistical approach to uncover empirical connections where the biological activity (or any other attribute of interest) for molecules is stated in terms of estimated molecular descriptors.




Fig. 6. Several successful uses of machine learning in various phases of the drug development pipeline in pharmaceutical companies have been documented. These applications may be found in a number of different places. A conceptual map on the experimental and computational methodologies that are applied to the drug discovery process [119], together with a schematic explanation of the drug discovery process that is overlaid with the related computational approaches. There is no particular hierarchy to the order in which the terminologies are listed on any of the colored tracks.



SBDND and LBDND are the two most extensively used computational methodologies for designing new drugs based on structural and ligand- based principles, respectively. X-ray structures or relatively realistic ho- mology models of the intended targets are required for SBDND in order to create ligands, which are then assembled from atoms or fragments in order to suit the necessary pocket [123,124].
DruGAN employs fingerprints to describe molecules, and utilizes Tanimoto resemblance to assess how similar the created molecules are to the original data, In the end, DruGAN had a superior ability to gener- ate chemical fingerprints and a greater capability to analyse extremely huge data sets of molecules than its competitors.
Itâ€™s also worth noting that VAE and AAE work well with fingerprints and other chemical structure representations as well. Various forms of generative adversarial autoencoder models were used in inverse QSAR to build new chemical structures (Figs. 6, 7, 8).

Targeting

The current issue with systemic drug administration is the need for a high concentration of a drug to achieve a therapeutic concentration in the site of action. However, the use of high concentrations can cause unnecessary adverse side effects. To combat this, drug targeting aims to
target and guide the administration of drugs to the target area which would resolve the high drug concentration. There are many techniques to accomplish this including rudimentary methods such as direct appli- cation to the affected area, or more complex techniques utilizing normal pH values, temperatures, or magnetic fields. Yet, the most versatile drug targeting technique is achieved by using a unique vector molecule. Vec- tor molecules are ligands that have an increased aï¬ƒnity towards an area of interest. The potential benefits include highly configurable drug de- livery, which allows for higher loading capacity, customizable size, and customizable permeability [125].
Utilizing computational predictions of drug targeting interactions (DTI) is a challenge today. Currently, DTIs are primarily based upon supervised machine learning with known label information. This cre- ates an expensive and time-consuming process. One solution is a semi- supervised generative adversarial network (GANs) based method to pre- dict binding aï¬ƒnity. By the use of computational methods and machine learning, the drug development process can be considerably accelerated and save excessive costs [118].
The model proposed in this paper, GANs DTA, contains three parts: two feature extractors and a regressor [118]. The first feature extractor is for the protein sequences while the second one is for SMILES strings, which is a simplified molecular input line entry system. These strings


Fig. 7. Zhao et alâ€™s pipeline involving two GANs, one for generat- ing protein sequences and the other for SMILE sequences [118].




















Fig. 8. A graph based analysis to represent the relation and application of different deep learning techniques to molecular data and tasks.


are made of a feature representation modular from GANs. The third part is a regressor, made up of a Convolutional Neural Network (CNN), which predicts the aï¬ƒnity value. To train this model, it must undergo two processes. The first of which is training the feature extractors in the context of GANs. The GAN begins to generate fake samples starting with a given noise distribution. It is then compared to a real provided sam- ple to discriminate the real data from the fake generated data. As this
continues, the discriminator maps the inputs utilizing a feature space by a local feature extractor. This local feature extractor promotes sample classification, which learns the difference between real and fake pro- teins and SIMILES. After the first round is completed, the local feature extractor will be used as the feature representation of the new model. The second round is to build upon the regressor. This uses the feature extractor from the first round along with the labeled data to train the



regressor to minimize the last function, leading to optimal model param- eters. Now, this can be used with drugs that are represented as SMILES strings and protein sequences that are represented as a string of ASCII letters, which are amino acids [118]. Allowing for the input to be in the form of a string allows for the discriminator to learn the latent fea- tures of those sequences. Ian Goodfellow et al suggest a minimax game
to train GANs [64]. The generator ğº creates fake samples from the gen-
erator distribution ğ‘ƒğº by transforming the noise variable ğ‘§ âˆ¼ ğ‘ƒğ‘›ğ‘œğ‘–ğ‘ ğ‘’ (ğ‘§) into a sample ğº(ğ‘§). ğ‘ƒğº is then compared to the real sample distribu- tion ğ‘ƒğ‘‘ğ‘ğ‘¡ğ‘ . Equation (9) describes the loss function that is iteratively run
when training a GAN [118].
tecture consists of the feature extractor (ğ¹ (ğ‘¥; ğœ™ğ‘“ )) and a sigmoid classi- The discriminator network used in the drug targeting aï¬ƒnity archi- fication layer with weight vector ğœ“1 [118].
The convolutional regression model conducts convolution operations with kernel size 4 to create feature maps of the input data. The dimen- sions of the convolution layers are 16x4, 32x4, and 48x4. The output layer is a linear function that obtains the continuous value. This is on a network that is trained to decrease the loss of function defined by the
mean square error (MSE) between the depth values ğ‘¦ğ‘˜ and the predicted
outputs of the network ğ‘ğ‘˜ .
ğ‘›
ğ‘€ğ‘†ğ¸(ğ‘ , ğ‘¦ ) =   (ğ‘ âˆ’ ğ‘¦ )2	(10)
ğ‘› ğ‘˜=1
The results of this experiment were compared to state-of-the-art drug-target binding aï¬ƒnity prediction models using the Davis and Kiba data sets, eighty percent of which were used as training samples whereas the other 20 percent were used for testing. The MSE and the concor- dance index (CI) were later compared to evaluate the models [118]. CI evaluates the performance of the models that output continuous val- ues. In both data sets, Davis and Kiba, DeepDTA outperforms with the best CI (0.886 and 0.863) and the best MSE (0.261 and 0.194). The best performance GANsDTA exhibited was 0.866 for the second dataset CI. Overall, GANsDTA exhibits similarities in performance to DeepDTA, however, has slightly a lower CI score (0.881 to 0.886) and a slightly higher MSE with 0.015. The likely conclusion is the insuï¬ƒcient size of a data set that only included 442 proteins, 68 compounds, and 30,056 interactions were too limited [118]. Although this model is not meant for small data sets, employing the techniques of training GANs should be continued to enhance the adaptability of GANs on a larger scale.
The endocannabinoid system is made up of two main subtypes: CB1 and CB2 receptors. The first is commonly found in the central nervous system while the second is mainly concentrated in hematopoietic cells and the immune system. It has been proven that the first type of re- ceptor shows the potential to treat anxiety, drug addiction, and even motor control, while the second type of receptor has the potential to alleviate inflammatory pain, osteoporosis, and autoimmune disorders. This being said, the cannabinoid system can be diï¬ƒcult to target when it is dispersed throughout the whole body. This is the reason why devel- oping small molecular drugs capable of targeting types of CB receptors is essential for the medical treatment of various diseases [114] (Figs. 9 and 10).
In order to target these cannabinoid receptors, a study utilized a deep convolutional generative adversarial Network (DCGAN) model for de novo designing target-specific compounds [114]. de novo is one of two strategies for identifying the compounds of a specific target. In this study, four types of targets, or fingerprints, were used to describe the small molecules with different structural features: ECFP6, MACCS, AtomPair Count, and AtomPair. A convolutional neural network (CNN) was the architecture for the deep learning model used in this study. It was first built using the four aforementioned types of targets as input data. Then it was applied to the discriminator of the DCGAN. Afterward, the generator was created through reverse convolution. This strategy minimizes the discriminative and generative loss simultaneously [114].
The label data used was from their previous machine learning project on cannabinoid receptors. The activity cut-off was set to 100 nM to dis-
tinguish active from inactive compounds. The cut-off value was set to
0.8 since no pair of compounds had a cut-off larger than that. Then 80% of the data set was used for training while the latter 20% was used for testing [114]. This was split between the four fingerprints. The dcGAN
had a composition of two deep neural networks, the generator ğº and
the discriminator ğ·. As ğº undergoes reverse convolutional processes to
prints, ğ· is trained to discriminate the data, using the preferred CNN capture the data of distribution resulting in the fake molecular finger-
architecture to detect whether it is real or not [114].
Training the model is a two-step procedure. The first step is training
tive ligand fingerprints. ğº then creates fingerprints based on the noise the discriminator to minimize the discriminative laws based on the ac-
input with the label of zero. The discriminator chooses between these fingerprints and the authentic data which is labeled as one. The sec- ond step is minimizing the generative loss. Here the discriminator is not trainable and the generative loss is recorded to show how well the gen- erator fools the discriminator. The learning epochs were 50, 100, and 200, while the batch size was 128. When comparing the different CNN architectures, the LeNet-5-based architecture and the Atompair finger- prints performed the best. Based on the ROC curves, this duo attained the highest AUC score across each test set for both types of receptors, CB1 and CB2 [114]. This is the optimum combination using the first as the generation for the discriminator and the second as the input data. This strategy lets the machine produce fingerprints of a potential target- specific compound without any effort from the user.
The study does point out two concerns regarding the GAN architec- ture. The first challenge is to optimize both the discriminator and the generator simultaneously. However, this instability can lead to a gradi- ent favoring one over the other. This could result in an improved score for D, but not G, or vice versa. Secondly, there can only be a restrictive set of outcomes to be generated, also known as mode collapse. With the restrictive set, the generator can only produce one type of outcome or a small sample. Only a limited chemical space is to be covered as well as a lack of structural diversity.
In 2019, people realized how time consuming and expensive the tra- ditional drug discovery process was. On average, it takes about ten to fifteen years and billions of US dollars for a drug to reach the FDA, at which point it may be accepted or rejected. In drug discovery, drugs are created to find two specific proteins, which gives rise to the importance of a computational drug discovery system to protect the binding aï¬ƒn- ity, also known as drug-target interaction prediction (DTI). The binding aï¬ƒnity can be represented with multiple terms, some being the inhi- bition constant, the dissociation constant, changes in free energy mea- sures, half maximal inhibitory constant, half maximal activity concen- tration, KIBA score, and SCORES used in STITCH database [126].
This study proposes a DeepGLSTM model, using a graph convolu- tional network block to pass the drug compound data using power graph representation and bidirectional-LSTM to capture the topological infor- mation to achieve state-of-the-art results in the neural drug repurposing domain [126]. As many other papers have focused on one-dimensional CNN models, this model is LSTM since existing literature proves it per- forms better. Most GAN models convert drug compound data into string representations, which is not ideal for computational purposes. It may lead to the exclusion of topological information of the molecules them- selves, which causes a decrease in performance and power production. Deep-GLSTM consists of two functional models. One captures the topological information from the drug molecules while the second one captures the sequential information from the specific protein structure. It has been shown through previous papers that Graph DTA and DeepGS using graphical representation to embed the drug compounds and one- hot representation for protein structures improved the model perfor- mance and prediction [126]. This study continued with this idea by representing each drug compound by itâ€™s related SMILES notation. This notation represents a compound as a graph of the interaction between each atom. A node feature was a set of atomic features adapted from DeepChem. A node represented a multi-dimensional binary feature vec-





Fig. 9. Modified and Applied CNN architectures used as the GAN generators and discriminators [114].



Fig. 10. DCGAN generator and discriminator used for molecular compound fingerprint generation [114].



tor. Each feature vector demonstrated five pieces of information includ- ing the atom symbol, the number of adjacent atoms, the implicit valence of the atom, the number of adjacent hydrogenâ€™s, and whether that item is an aromatic structure. The SMILES data was later converted to a molec- ular graph representation which helped extract the required atomic fea- tures.
Every amino acid was mapped to the english letter based off the
ded representation, where ğ‘‘ğ‘ is the dimension of the protein sequence protein sequence being a string of ASCII characters. Then the embed-
ters ğ‘ = [ğ‘1 , ğ‘2 , â€¦ ğ‘ğ‘› ] of length n. The prediction of the aï¬ƒnity score was embeddings to a Bi-LSTM layer, captures the relationship of the charac-
based off of the interaction of each node with its adjacent node [126]. This is why a GCN was used, due to the fact that it is strong enough to produce important feature representations, which are capable of cap- turing the connectedness relationship between nodes of the graph. This model consisted of three blocks. The first had a stack of three GCN layers. The second had a stack of two GCN layers. The final block had a sin- gle GCN layer. The first equation is the overcome degree normalization of the adjacent representation. The output is the normalized adjacency representation.
for disease diagnosis and therapy prognosis in the clinic (Tables 3 and 4).
These strategies are also being implemented in the healthcare sector, where they have the potential to significantly improve precision and per- sonalized medicine [161] when combined with the drug development process. To further improve clinical trial outcomes and the process of deciding if a patient is qualified for a study, ML has been applied to Omics and EHR data [162] as well as other real-world biomarkers. A recent study, for instance, showed that deep neural networks (DNNs) are a highly competitive way for autonomously collecting useful infor- mation from electronic health data for the goal of disease detection and classification [163]. For prognosis prediction, research has shown that machine learning models embedded in EHRs can outperform more tra- ditional approaches. Applying machine learning to the data now being created by sensors and wearables can help us better understand the dis- ease and develop treatments, especially in neurosciences [164]. For ex- ample, Gkotsis et al. [165] classified mental health disorders using un- structured data from social media using DL algorithms. This is a diï¬ƒcult problem for standard ML methods to solve.
Lack of interpretability, or the inability to provide a credible answer

ğ´ğ‘›ğ‘œğ‘Ÿğ‘š = ğ·
1
2 ğ´ğ·
1
2	(11)
of how the trained neural network comes to the outcome, is a common problem with deep-trained neural networks. Even in cases where neural

weight, ğ» ğ‘– = ğ‘‹ is the ğ‘–th layer output represented by the sigmoid as a The next equation makes the first block workable. W is the trainable
non linear activation function:
ğ» ğ‘– = ğœ(ğ´ğ‘›ğ‘œğ‘Ÿğ‘š ğ» (ğ‘–âˆ’1) ğ‘Š (ğ‘–âˆ’1) )	(12)
The second block is the square representation of the first equation.
The same thing can be said for the equation that makes it workable.
2	â€²âˆ’ 1  2  â€²âˆ’ 1
networks outperform human specialists, a lack of interpretability could pose problems for researchers, regulators, doctors, and patients if the system is used to detect a condition based on medical imagery, like melanoma, for example. Can we expect patients to place more faith in the ML diagnosis than they would in a human doctorâ€™s opinion? Much less dramatically, a comparable problem may arise when design- ing drugs. Would a pharmaceutical company put its faith in a neural net- work to select a tiny chemical for its portfolio and fund its advancement

ğ´ğ‘›ğ‘œğ‘Ÿğ‘š = ğ·
2 ğ´ ğ·
2	(13)
in the clinic if the network couldnâ€™t explain its reasoning behind the selection? Further, if chemicals have been developed by computer algo-

ğ» â€²ğ‘– = ğœ(ğ´2
ğ» â€²(ğ‘–âˆ’1) ğ‘Š â€²(ğ‘–âˆ’1) )	(14)
rithms, there may be inventorship concerns while applying for patents.

ğ‘’	ğ‘›ğ‘œğ‘Ÿğ‘š  ğ‘’
Similarly the same can be said for the third block as seen in the above equations (Fig. 11).
The length of the protein sequence was set to one thousand for all datasets. The hidden vector representation of each layer was one hun- dred and twenty eight while the fixed number input mode features was seventy eight. The final hidden vector representation of the first block with set the three hundred and twelve. The dropout probability rate was set to 0.2. Due to the fact of it being a regression model, the mean squared error (MSE) was used as the loss function evaluation. Finally, all experiments were trained to one thousand epochs. The results sug- gested that the third block of the GCN contributed the most in model performance [126]. Most often, the structure of a drug dose does not consist of many shortest paths that exceed a distance of three or more, therefore it can be concluded that increasing the exponent to be on 3 would not lead to any significant changes.

Outlook

The application of ML methods and the latest advancements in DL of- fers a multitude of potential to boost productivity throughout the drug research and development pipeline. As a consequence of this, in the coming years, we anticipate seeing an increase in the number of appli- cations within the industry that target clearly defined challenges. ML algorithms are going to systematically generate improved outputs, and new and interesting applications are expected to follow suit as a result of this. This is because the available data is getting â€œbigger,â€ at least in the sense of covering the relevant variability of the entire data space in a more comprehensive manner, and because computers are becoming increasingly more powerful. This has been demonstrated quite clearly in the sections that came before it. In those sections, we talked about some machine learning applications for target identification and validation, drug design and development, biomarker identification, and pathology
In any event, researchers should treat ML results as only hypotheses or intriguing jumping-off points for further investigation. Though comple- mentary tests validating the ML result will aid in establishing confidence in methodologies and outputs, regulatory bodies have not yet provided guidance on how they feel about MLâ€™s lack of interpretability in clinical settings. The lack of interpretability of the approaches, however, makes it harder to debug these methods when they fail in unexpected ways on fresh, unexplored data sets, even if the trust issue is resolved.
Because ML outputs are largely dependent on the initial values or weights of the network parameters or even the order in which train- ing examples are presented to the network, all of which are normally chosen at random, repeatability is another key problem for neural net- works. Should we expect the network to consistently choose the same illness target when fed the same expression data? Would the medication structure always be the same that ML suggested? Various techniques have produced different prognostic biomarkers for breast cancer based on molecular expression characteristics [166], illustrating that this lack of repeatability is particularly troublesome for biomarker identification. The fact that several ML approaches can provide divergent outcomes raises doubts about the widespread use of these techniques. It has been suggested that there are ways to address both the interpretability and repeatability issues. It is common for these to include employing a more involved or time-consuming technique or averaging the output of mul- tiple network models, although this may be viewed as doing little more than adding yet another possible outcome to the pool (Tables 5 and 6). Large amounts of high-quality, accurate, and human-curated data for training and developing ML models are also vital to consider. The com- plexity of the data type and the question to be answered determines the requirements for the amounts and accuracy sought. As a result, the cost of creating these data sets can add up quickly. Possible approaches to satisfying these data needs include pre-competitive consortia of phar- maceutical corporations and academic institutions employing suitable data standards and equipped with the requisite operational and open






Fig. 11. Model Architecture of DeepGLSTM [126].


Table 3
State of the Art Application of GANs in Drug and Molecular Design.



Table 4
Examples of commonly used molecular representations.



data frameworks. Drug discovery relies on a wide variety of data kinds, many of which are far from exhaustive. One example is that not all protein folds and structures are fully understood, and the data space is only partially covered. Therefore, even if significant progress has been made, applications in which these structures are projected are not yet as good as in other fields. For small molecule synthesis, where the com- plete chemical space is unknown, this holds true as well for reaction prediction.
Data curation is essential for sharing information that may be used again, yet it can be costly due to the expertise and time involved. There is a fine line between the computational abilities and in-depth biological and domain experience needed for the task of biological curation, which entails extracting biological material from the scientific literature and integrating it into a database.114 Increased access to high-quality data already available in the public domain may be possible through coor- dinated efforts to create common data resources and metadata (labels). Metadata from unsuccessful as well as successful drug discovery initia- tives are included since they can be used to build techniques to predict and identify aspects that can help lower attrition rates. Large data re- sources of company bioactive data sets of experimental substances and historical clinical trial data require significantly greater pre-competitive collaboration.
Another area where ML models fall short is in making predictions about new paradigms. ML models can only make predictions within the constraints of the training data, as this is the very foundation of the field. For instance, in medicinal chemistry, classical approaches are likely nec- essary for the design of molecules with different modes of action such as macrocycles, proteinâ€“protein interaction inhibitors, or PROTACs.
Machine learning (ML) algorithms, particularly DL techniques, have made AI practical for use in business and daily life. The analysis of omics and imaging data, in particular, has seen the immediate effects of ML approachesâ€™ expansion into the drug research and healthcare sectors. Speech recognition, natural language processing, computer vision, and other applications have all seen success with ML algorithms. Among the most frequent examples of such devices are Internet-connected â€œsmart assistants,â€ which may now routinely relay health-related infor- mation through the transmission of voice recordings and visuals. Med- ical decision-making on therapeutic benefits, clinical biomarkers, and adverse effects may be greatly aided by ML techniques applied to data acquired from such a conglomeration of Internet-enabled technologies combined with biological data.

Conclusion

Searching chemical space for required functions can be greatly aided by generative machine learning models like GANs. It is diï¬ƒcult to fore- tell the binding aï¬ƒnity between medication and its target during the drug discovery process. The labeled data upon which supervised systems rely is both costly and challenging to acquire on a large scale, making these approaches impractical for widespread use. We discuss how GANs can be used to train representations from raw sequence data of proteins and medicines, and how convolutional regression can be used to predict the aï¬ƒnity.
Innovations in the many omics fields have ushered in a new era of big data for the drug discovery industry. Such massive amounts of data present exciting prospects for advancing life sciences, but they also raise


Table 5
Well established cheminformatics databases available for drug discovery.


Table 6
Commonly used cheminformatics and machine learning packages.



concerns about the veracity and reproducibility of findings. As a means of avoiding potential pitfalls, understanding the current state-of-the-art of research reproducibility in computational drug discovery is crucial. This will guarantee that the underlying work is of high quality and will withstand the reproduction of the described methodology by the exter- nal research group. In this overview, we looked at the various methods
and tools available for achieving reproducibility in computational drug development initiatives.
Computational drug development is expected to advance thanks to the developing culture of sharing the underlying data and scripts re- ported in research articles. This will allow for a new and useful knowl- edge base to be progressively created on top of its predecessors, much



like a snowball. Policies enacted in recent years by funding agencies and publishers favor data and code sharing, which is further facili- tated by third-party platforms (e.g. Authorea, Code Ocean, Jupyter note- book, Manuscripts.io, etc.) that further enhance reproducibility by trans- forming online manuscripts and codes from static files waiting to be downloaded into â€œlivingâ€ codes and documents that can be dynamically edited and executed in real-time.
In conclusion, we have tried to describe the wide variety of prob- lems encountered by the predictive modeling community as it performs its mission to create and distribute effective and trustworthy computa- tional tools for the pharmaceutical industry. Evidence presented herein demonstrates the importance of close collaboration among researchers working at the front lines of drug discovery, those responsible for in- termediate data modeling, and the administrators and programmers in the back oï¬ƒces. There has to be a better knowledge of these concerns and a shared terminology in order to optimize their impact, yet these groups encounter challenges that are very distinct in nature. Given the scope of the disciplines at play, this is no easy feat. Data modelers, tool developers, and administrators should keep in mind that their tools will be used by front-line scientists in a constantly changing work environ- ment, as we point out. Due to its fluid nature, it may not always align with the recommendations of the data science community (i.e. due to ever-changing needs).
Therefore, itâ€™s important to recognize that model developer may disagree with the developer community on the best approach. For in- stance, while user-derived descriptors (such as experimental data or non-standard 3D computational models) could be ideal, they can be challenging to include swiftly into QSAR models. On the other hand, it is possible that interpretability is more important than raw predictive performance when choosing a predictive model. Because selection re- quirements are typically driven by statistical considerations rather than the needs of the end user, the latter types of models may not exist in automated solutions in now prevalent modeling workflows.
Transparency in implementations and easy access to validate the analyses are both benefits of open source. It might be challenging to maintain track of the various analysis tools and settings while dealing with data and modeling. As a result, drug discovery workflow solutions are becoming increasingly popular. They aid in producing more trust- worthy multi-step computations, as well as in establishing a trail of ev- idence and making results easy to reproduce. Common Workflow Lan- guage is one example of an initiative seeking to standardize and promote interoperability among workflow specification languages.
The usage of public or shared computing infrastructures (HPC/Cloud) is necessitated by the ever-increasing amounts of data, but this introduces a new layer of complexity for computational reproducibility. The usage of virtual machines and software containers has made it possible for all data analysis tools to be used across differ- ent platforms. High levels of automation and, by extension, increased repeatability, are possible when workflow systems are integrated with the container and virtual machine infrastructure. For example, when deploying models as networked services, virtual infrastructure and containers allow for more dependable and reproducible service delivery.

Declaration of Competing Interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

Acknowledgment

We would like to acknowledge Drexel Society of Artificial Intelli- gence for its contributions and support for this research.
Supplementary material

Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.ailsci.2022.100045.


References

Chen H, Engkvist O, Wang Y, Olivecrona M, Blaschke T. The rise of deep learning in drug discovery. Drug Discov Today 2018;23(6):1241â€“50.
Vamathevan J, Clark D, Czodrowski P, Dunham I, Ferran E, Lee G, et al. Appli- cations of machine learning in drug discovery and development. Nat Rev Drug Discovery 2019;18(6):463â€“77.
Hessler G, Baringhaus K-H. Artificial intelligence in drug design. Molecules 2018;23(10):2520.
Butler KT, Davies DW, Cartwright H, Isayev O, Walsh A. Machine learning for molecular and materials science. Nature 2018;559(7715):547â€“55.
Segler MHS, Preuss M, Waller MP. Planning chemical syntheses with deep neural networks and symbolic AI. Nature 2018;555(7698):604â€“10.
Baskin II, Winkler D, Tetko IV. A renaissance of neural networks in drug discovery. Expert Opin Drug Discov 2016;11(8):785â€“95.
LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015;521(7553):436â€“44.
Hinton G. Deep learningâ€“a technology with the potential to transform health care. JAMA 2018;320(11):1101â€“2.
Jing Y, Bian Y, Hu Z, Wang L, Xie X-QS. Deep learning for drug design: an artificial intelligence paradigm for drug discovery in the big data era. AAPS J 2018;20(3):1â€“10.
Rifaioglu AS, Atas H, Martin MJ, Cetin-Atalay R, Atalay V, DoÄŸan T. Recent ap- plications of deep learning and machine intelligence on in silico drug discovery: methods, tools and databases. Brief Bioinformatics 2019;20(5):1878â€“912.
Google Developers, The discriminator and generator, 2021, https://www.developers.google.com/machine-learning/gan/discriminator
Goh GB, Hodas NO, Vishnu A. Deep learning for computational chemistry. J Com- put Chem 2017;38(16):1291â€“307.
Mamoshina P, Vieira A, Putin E, Zhavoronkov A. Applications of deep learning in biomedicine. Mol Pharm 2016;13(5):1445â€“54.
Ekins S. The next era: deep learning in pharmaceutical research. Pharm Res 2016;33(11):2594â€“603.
Kingma D.P., Welling M.. Auto-encoding variational bayes. arXiv preprint arXiv:131261142013;.
Ding J, Condon A, Shah SP. Interpretable dimensionality reduction of single cell transcriptome data with deep generative models. Nat Commun 2018;9(1):1â€“13.
Wang D, Gu J. Vasc: dimension reduction and visualization of single-cell rna-seq data by deep variational autoencoder. Genomics Proteomic Bioinform 2018;16(5):320â€“31.
Blaschke T, Olivecrona M, Engkvist O, Bajorath J, Chen H. Application of genera- tive autoencoder in de novo molecular design. Mol Inform 2018;37(1â€“2):1700123.
Ghasemi F, Mehridehnavi A, Perez-Garrido A, Perez-Sanchez H. Neural network and deep-learning algorithms used in QSAR studies: merits and drawbacks. Drug Discov Today 2018;23(10):1784â€“90.
Ching T, Himmelstein DS, Beaulieu-Jones BK, Kalinin AA, Do BT, Way GP, et al. Opportunities and obstacles for deep learning in biology and medicine. J R Soc Interface 2018;15(141):20170387.
Dana D, Gadhiya SV, St Surin LG, Li D, Naaz F, Ali Q, Paka L, Yamin MA, Narayan M, Goldberg ID, et al. Deep learning in drug discovery and medicine; scratching the surface. Molecules 2018;23(9):2384.
Lin E, Kuo P-H, Liu Y-L, Yu YW-Y, Yang AC, Tsai S-J. A deep learning approach for predicting antidepressant response in major depression using clinical and genetic biomarkers. Front Psychiatry 2018;9:290.
Lin E, Tsai S-J. Machine learning in neural networks. In: Frontiers in psychiatry. Springer; 2019. p. 127â€“37.
Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, et al. Generative adversarial nets. Adv Neural Inf Process Syst 2014;27.
Zhao H, Li H, Maurer-Stroh S, Cheng L. Synthesizing retinal and neuronal images with generative adversarial nets. Med Image Anal 2018;49:14â€“26.
Hu B, Tang Y, Eric I, Chang C, Fan Y, Lai M, et al. Unsupervised learning for cel- l-level visual representation in histopathology images with generative adversarial networks. IEEE J Biomed Health Inform 2018;23(3):1316â€“28.
Mardani M, Gong E, Cheng JY, Vasanawala SS, Zaharchuk G, Xing L, et al. Deep generative adversarial neural networks for compressive sensing MRI. IEEE Trans Med Imaging 2018;38(1):167â€“79.
Lin E, Mukherjee S, Kannan S. A deep adversarial variational autoencoder model for dimensionality reduction in single-cell RNA sequencing analysis. BMC Bioinfor- matics 2020;21(1):1â€“11.
Kadurin A, Aliper A, Kazennov A, Mamoshina P, Vanhaelen Q, Khrabrov K, et al. The cornucopia of meaningful leads: applying deep adversarial autoencoders for new molecule development in oncology. Oncotarget 2017;8(7):10883.
Kadurin A, Nikolenko S, Khrabrov K, Aliper A, Zhavoronkov A. DruGAN: an advanced generative adversarial autoencoder model for de novo genera- tion of new molecules with desired molecular properties in silico. Mol Pharm 2017;14(9):3098â€“104.
Alqahtani H, Kavakli-Thorne M, Kumar G. Applications of generative ad- versarial networks (GANs): an updated review. Arch Comput Methods Eng 2021;28(2):525â€“52.



Lan L, You L, Zhang Z, Fan Z, Zhao W, Zeng N, et al. Generative adversar- ial networks and its applications in biomedical informatics. Front Public Health 2020;8:164.
Gulrajani I, Ahmed F, Arjovsky M, Dumoulin V, Courville AC. Improved training of wasserstein GANs. Adv Neural Inf Process Syst 2017;30.
Mirza M., Osindero S.. Conditional generative adversarial nets. arXiv preprint arXiv:141117842014a;.
Makhzani A., Shlens J., Jaitly N., Goodfellow I., Frey B.. Adversarial autoencoders. arXiv preprint arXiv:1511056442015;.
Rezende DJ, Mohamed S, Wierstra D. Stochastic backpropagation and approximate inference in deep generative models. In: International conference on machine learn- ing. PMLR; 2014. p. 1278â€“86.
Guimaraes G.L., Sanchez-Lengeling B., Outeiral C., Farias P.L.C., Aspuru-Guzik A.. Objective-reinforced generative adversarial networks (ORGAN) for sequence gen- eration models. arXiv preprint arXiv:170510843
Sanchez-Lengeling B., Outeiral C., Guimaraes G.L., Aspuru-Guzik A.. Optimizing distributions over molecular space. an objective-reinforced generative adversarial network for inverse-design chemistry (ORGANIC)2017a;.
Putin E, Asadulaev A, Ivanenkov Y, Aladinskiy V, Sanchez-Lengeling B, Aspu- ru-Guzik A, et al. Reinforced adversarial neural computer for de novo molecular design. J Chem Inf Model 2018;58(6):1194â€“204.
Putin E, Asadulaev A, Vanhaelen Q, Ivanenkov Y, Aladinskaya AV, Aliper A, et al. Adversarial threshold neural computer for molecular de novo design. Mol Pharm 2018;15(10):4386â€“97.
Polykovskiy D, Zhebrak A, Vetrov D, Ivanenkov Y, Aladinskiy V, Mamoshina P, et al. Entangled conditional adversarial autoencoder for de novo drug discovery. Mol Pharm 2018;15(10):4398â€“405.
De Cao N., Kipf T.. MolGAN: an implicit generative model for small molecular graphs. arXiv preprint arXiv:1805119732018;.
Guarino M., Shah A., Rivas P.. DiPol-GAN: generating molecular graphs adversar- ially with relational differentiable pooling2017;.
Prykhodko O, Johansson SV, Kotsias P-C, ArÃºs-Pous J, Bjerrum EJ, Engkvist O, et al. A de novo molecular generation method using latent vector based generative adversarial network. J Cheminform 2019;11(1):1â€“13.
Mitchell TM. Machine learning. McGraw-Hill Education; 1997.
Aha D.W. Kibler D. Albert M.K.. Instance-based learning algorithms1991;.
Barlow HB. Unsupervised learning. Neural Comput 1989;1(3):295â€“311. doi:10.1162/neco.1989.1.3.295. https://www.direct.mit.edu/neco/article-pdf/1/ 3/295/811863/neco.1989.1.3.295.pdf
Kaelbling LP, Littman ML, Moore AW. Reinforcement learning: a survey. CoRR 1996. cs.AI/9605103, https://www.arxiv.org/abs/cs/9605103
LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015;521(7553):436â€“44.
Chauvin Y, Rumelhart DE. Backpropagation: theory, architectures, and applica- tions. Psychology Press; 2013.
Geoghegan BD. Orientalism and informatics: alterity from the chess-playing turk to Amazonâ€™s mechanical turk. Ex-position 2020(43):45.
Carter F. The turing bombe. Bletchley Park Trust; 2008.
French RM. The turing test: the first 50 years. Trends Cogn Sci 2000;4(3):115â€“22.
Howard J. Artificial intelligence: implications for the future of work. Am J Ind Med 2019;62(11):917â€“26.
Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychol Rev 1958;65(6):386.
Sharples M, Hogg D, Hutchinson C, Torrance S, Young D. Computers and thought: a practical introduction to artificial intelligence. The MIT Press; 1989.
LeCun Y, Bottou L, Bengio Y, Haffner P. Gradient-based learning applied to docu- ment recognition. Proc IEEE 1998;86(11):2278â€“324.
Krizhevsky A, Sutskever I, Hinton GE. ImageNet classification with deep convolu- tional neural networks. Adv Neural Inf Process Syst 2012;25.
Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y. Generative adversarial nets. Advances in neu- ral information processing systems, vol 27. Curran Associates, Inc; 2014. https://www.proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494   c97b1afccf3-Paper.pdf
Chen JX. The evolution of computing: alphago. Comput Sci Eng 2016;18(4):4â€“7. doi:10.1109/MCSE.2016.74.
Johnson M, Schuster M, Le QV, Krikun M, Wu Y, Chen Z, et al. Googleâ€™s multi- lingual neural machine translation system: enabling zero-shot translation. CoRR 2016. http://www.arxiv.org/abs/1611.04558
Jumper J, Evans R, Pritzel A, Green T, Figurnov M, Ronneberger O, Tunyasuvu- nakool K, Bates R, Å½Ã­dek A, Potapenko A, et al. Highly accurate protein structure prediction with AlphaFold. Nature 2021;596(7873):583â€“9.
Mak K-K, Pichika MR. Artificial intelligence in drug development: present status and future prospects. Drug Discov Today 2019;24(3):773â€“80.
Ng A, Jordan M. On discriminative vs. generative classifiers: a compar- ison of logistic regression and naive bayes. Advances in neural infor- mation processing systems, vol 14. MIT Press; 2001. https://proceedings. neurips.cc/paper/2001/file/7b7a53e239400a13bd6be6c91c4f6c4e-Paper.pdf
Mirza M, Osindero S. Conditional generative adversarial nets. CoRR 2014. http://arxiv.org/abs/1411.1784
Denton EL, Chintala S, Szlam A, Fergus R. Deep generative image mod- els using a laplacian pyramid of adversarial networks. CoRR 2015. http://arxiv.org/abs/1506.05751
Radford A., Metz L., Chintala S.. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511064342015;.
Arjovsky M, Chintala S, Bottou L. Wasserstein generative adversarial networks. In: International conference on machine learning. PMLR; 2017. p. 214â€“23.
Chen X, Duan Y, Houthooft R, Schulman J, Sutskever I, Abbeel P. InfoGAN: inter- pretable representation learning by information maximizing generative adversarial nets. CoRR 2016. http://arxiv.org/abs/1606.03657
Zhu J-Y, Park T, Isola P, Efros AA. Unpaired image-to-image translation using cy- cle-consistent adversarial networks. In: Proceedings of the IEEE international con- ference on computer vision; 2017. p. 2223â€“32.
Karras T, Laine S, Aila T. A style-based generator architecture for generative adver- sarial networks. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition; 2019. p. 4401â€“10.
Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polo- sukhin I. Attention is all you need. CoRR 2017. arXiv preprint arXiv:1706.03762.
Zhang H, Goodfellow I, Metaxas D, Odena A. Self-attention generative adver- sarial networks. In: International conference on machine learning. PMLR; 2019.
p. 7354â€“63.
Maziarka L, Pocha A, Kaczmarczyk J, Rataj K, Danel T, WarchoÅ‚ M. Mol-cycleGAN: a generative model for molecular optimization. J Cheminform 2020;12(1):1â€“18.
MÃ©ndez-Lucio O, Baillif B, Clevert D-A, RouquiÃ© D, Wichard J. De novo generation of hit-like molecules from gene expression signatures using artificial intelligence. Nat Commun 2020;11(1):1â€“10.
Lipton ZC, Berkowitz J, Elkan C. A critical review of recurrent neural networks for sequence learning. arXiv preprint arXiv:150600019 2015.
Martinez-Mayorga K, Madariaga-Mazon A, Medina-Franco JL, Maggiora G. The im- pact of chemoinformatics on drug discovery in the pharmaceutical industry. Expert Opin Drug Discov 2020;15(3):293â€“306.
Weininger D. Smiles, a chemical language and information system. 1. Introduction to methodology and encoding rules. J Chem Inf Comput Sci 1988;28(1):31â€“6.
Tran L, Yin X, Liu X. Disentangled representation learning GAN for pose-invariant face recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition; 2017. p. 1415â€“24.
Yin W., Fu Y., Sigal L., Xue X.. Semi-latent GAN: learning to generate and modify facial images from attributes. arXiv preprint arXiv:1704021662017.
Larsen ABL, SÃ¸nderby SK, Larochelle H, Winther O. Autoencoding beyond pixels using a learned similarity metric. In: International conference on machine learning. PMLR; 2016. p. 1558â€“66.
Zhang Z, Song Y, Qi H. Age progression/regression by conditional adversarial au- toencoder. In: Proceedings of the IEEE conference on computer vision and pattern recognition; 2017. p. 5810â€“18.
Wu H, Zheng S, Zhang J, Huang K. GP-GAN: towards realistic high-resolution image blending. In: Proceedings of the 27th ACM international conference on multimedia; 2019. p. 2487â€“95.
Zhu J-Y, Park T, Isola P, Efros AA. Unpaired image-to-image translation using cy- cle-consistent adversarial networks. In: Proceedings of the IEEE international con- ference on computer vision; 2017. p. 2223â€“32.
Kim T, Cha M, Kim H, Lee JK, Kim J. Learning to discover cross-domain rela- tions with generative adversarial networks. In: International conference on ma- chine learning. PMLR; 2017. p. 1857â€“65.
Wang Y, Wu L. Beyond low-rank representations: orthogonal clustering basis recon- struction with optimized graph structure for multi-view spectral clustering. Neural Netw 2018;103:1â€“8.
Liu M-Y, Tuzel O. Coupled generative adversarial networks. Adv Neural Inf Process Syst 2016;29.
Yang D, Xiong T, Xu D, Huang Q, Liu D, Zhou SK, Xu Z, Park J, Chen M, Tran TD, et al. Automatic vertebra labeling in large-scale 3D CT using deep image-to-image network with message passing and sparsity regularization. In: International con- ference on information processing in medical imaging. Springer; 2017. p. 633â€“44.
Xue Y, Xu T, Zhang H, Long LR, Huang X. SegAN: adversarial network with multi-s- cale l1 loss for medical image segmentation. Neuroinformatics 2018;16(3):383â€“92.
Mogren O.. C-RNN-GAN: continuous recurrent neural networks with adversarial training. arXiv preprint arXiv:1611099042016;.
Yu H-X, Wu A, Zheng W-S. Cross-view asymmetric metric learning for unsupervised person re-identification. In: Proceedings of the IEEE international conference on computer vision; 2017. p. 994â€“1002.
Li D, Chen X, Zhang Z, Huang K. Learning deep context-aware features over body and latent parts for person re-identification. In: Proceedings of the IEEE conference on computer vision and pattern recognition; 2017. p. 384â€“93.
Li J, Liang X, Wei Y, Xu T, Feng J, Yan S. Perceptual generative adversarial networks for small object detection. In: Proceedings of the IEEE conference on computer vision and pattern recognition; 2017. p. 1222â€“30.
Bjerrum EJ, Sattarov B. Improving chemical autoencoder latent space and molecu- lar de novo generation diversity with heteroencoders. Biomolecules 2018;8(4):131.
Zhou S., Xiao T., Yang Y., Feng D., He Q., He W.. GeneGAN: learning ob- ject transfiguration and attribute subspace from unpaired data. arXiv preprint arXiv:1705049322017.
Qian X, Fu Y, Xiang T, Wang W, Qiu J, Wu Y, Jiang Y-G, Xue X. Pose-normal- ized image generation for person re-identification. In: Proceedings of the European conference on computer vision (ECCV); 2018. p. 650â€“67.
Liu J., Li W., Pei H., Wang Y., Qu F., Qu Y., Chen Y.. Identity preserving generative adversarial network for cross-domain person re-identification. IEEE Access2019; 7:114021â€“114032.
Ledig C, Theis L, HuszÃ¡r F, Caballero J, Cunningham A, Acosta A, Aitken A, Te- jani A, Totz J, Wang Z, et al. Photo-realistic single image super-resolution using a generative adversarial network. In: Proceedings of the IEEE conference on com- puter vision and pattern recognition; 2017. p. 4681â€“90.



Tulyakov S, Liu M-Y, Yang X, Kautz J. MoCoGAN: decomposing motion and content for video generation. In: Proceedings of the IEEE conference on computer vision and pattern recognition; 2018. p. 1526â€“35.
Walker J, Marino K, Gupta A, Hebert M. The pose knows: video forecasting by generating pose futures. In: Proceedings of the IEEE international conference on computer vision; 2017. p. 3332â€“41.
Vondrick C, Pirsiavash H, Torralba A. Generating videos with scene dynamics. Adv Neural Inf Process Syst 2016;29.
Zhou S.-F., Zhong W.-Z.. Drug design and discovery: principles and applications. 2017.
Goh G.B., Siegel C., Vishnu A., Hodas N.O., Baker N.. Chemception: a deep neural network with minimal chemistry knowledge matches the performance of expert- developed QSAR/QSPR models. arXiv preprint arXiv:1706066892017b;.
You J, Liu B, Ying Z, Pande V, Leskovec J. Graph convolutional policy network for goal-directed molecular graph generation. Adv Neural Inf Process Syst 2018;31.
Durant JL, Leland BA, Henry DR, Nourse JG. Reoptimization of MDL keys for use in drug discovery. J Chem Inf Comput Sci 2002;42(6):1273â€“80.
Sterling T, Irwin JJ. Zinc 15â€“ligand discovery for everyone. J Chem Inf Model 2015;55(11):2324â€“37.
Blanchard AE, Stanley C, Bhowmik D. Using GANs with adaptive training data to search for new molecules. J Cheminform 2021;13(1):1â€“8.
Simonovsky M, Komodakis N. GraphVAE: towards generation of small graphs using variational autoencoders. In: International conference on artificial neural networks. Springer; 2018. p. 412â€“22.
Lin E, Lin C-H, Lane H-Y. Relevant applications of generative adversarial networks in drug design and discovery: molecular de novo design, dimensionality reduction, and de novo peptide and protein design. Molecules 2020;25(14):3250.
Mouchlis VD, Afantitis A, Serra A, Fratello M, Papadiamantis AG, Aidinis V, et al. Advances in de novo drug design: from conventional to machine learning methods. Int J Mol Sci 2021;22(4):1676.
Sabban S., Markovsky M.. RamaNet: computational de novo helical protein back- bone design using a long short-term memory generative adversarial neural network [version 1; peer review: 1 not]2020;.
Karimi M, Zhu S, Cao Y, Shen Y. De novo protein design for novel folds us- ing guided conditional wasserstein generative adversarial networks (gcWGAN). bioRxiv 2019:769919.
Anand N, Huang P. Generative modeling for protein structures. Adv Neural Inf Process Syst 2018;31.
Bian Y, Wang J, Jun JJ, Xie X-Q. Deep convolutional generative adversarial network (dcGAN) models for screening and design of small molecules targeting cannabinoid receptors. Mol Pharm 2019;16(11):4451â€“60.
Rossetto AM, Zhou W. GANDALF: a prototype of a GAN-based peptide design method. In: Proceedings of the 10th ACM international conference on bioinfor- matics, computational biology and health informatics; 2019. p. 61â€“6.
Gupta A., Zou J.. Feedback GAN (FBGAN) for DNA: a novel feedback-loop archi- tecture for optimizing protein functions. arXiv preprint arXiv:1804016942018;.
Guimaraes G.L., Sanchez-Lengeling B., Outeiral C., Farias P.L.C., Aspuru-Guzik A.. Objective-reinforced generative adversarial networks (ORGAN) for sequence gen- eration models. arXiv preprint arXiv:170510843
Zhao L, Wang J, Pang L, Liu Y, Zhang J. GANsDTA: predicting drug-target binding aï¬ƒnity using GANs. Front Genet 2020:1243.
Nantasenamat C.. Conceptual map of computational drug discovery [CC-BY]. 2019.
Chen H, Engkvist O, Wang Y, Olivecrona M, Blaschke T. The rise of deep learning in drug discovery. Drug Discov Today 2018;23(6):1241â€“50.
Zhavoronkov A.. Artificial intelligence for drug discovery, biomarker development, and generation of novel chemistry. 2018.
Sanchez-Lengeling B, Aspuru-Guzik A. Inverse molecular design using machine learning: generative models for matter engineering. Science 2018;361(6400):360â€“5.
Kuhn B, Guba W, Hert J, Banner D, Bissantz C, Ceccarelli S, et al. A real-world per- spective on molecular design: miniperspective. J Med Chem 2016;59(9):4087â€“102.
Vanhaelen Q, Lin Y-C, Zhavoronkov A. The advent of generative chemistry. ACS Med Chem Lett 2020;11(8):1496â€“505.
Torchilin VP. Drug targeting. Eur J Pharm Sci 2000;11:S81â€“91.
Mukherjee S., Ghosh M., Basuchowdhuri P.. Deep graph convolutional network and LSTM based approach for predicting drug-target binding aï¬ƒnity. arXiv preprint arXiv:2201068722022;.
Polykovskiy D, Zhebrak A, Vetrov D, Ivanenkov Y, Aladinskiy V, Mamoshina P, et al. Entangled conditional adversarial autoencoder for de novo drug discovery. Mol Pharm 2018;15(10):4398â€“405.
Prykhodko O, Johansson SV, Kotsias P-C, ArÃºs-Pous J, Bjerrum EJ, Engkvist O, et al. A de novo molecular generation method using latent vector based generative adversarial network. J Cheminform 2019;11(1):1â€“13.
Kadurin A, Aliper A, Kazennov A, Mamoshina P, Vanhaelen Q, Khrabrov K, et al. The cornucopia of meaningful leads: applying deep adversarial autoencoders for new molecule development in oncology. Oncotarget 2017;8(7):10883.
Kadurin A, Nikolenko S, Khrabrov K, Aliper A, Zhavoronkov A. DruGAN: an advanced generative adversarial autoencoder model for de novo genera- tion of new molecules with desired molecular properties in silico. Mol Pharm 2017;14(9):3098â€“104.
Sanchez-Lengeling B., Outeiral C., Guimaraes G.L., Aspuru-Guzik A.. Optimizing distributions over molecular space. an objective-reinforced generative adversarial network for inverse-design chemistry (ORGANIC)2017b;.
Putin E, Asadulaev A, Ivanenkov Y, Aladinskiy V, Sanchez-Lengeling B, Aspu- ru-Guzik A, et al. Reinforced adversarial neural computer for de novo molecular design. J Chem Inf Model 2018;58(6):1194â€“204.
Weininger D. Smiles, a chemical language and information system. 1. Introduction to methodology and encoding rules. J Chem Inf Comput Sci 1988;28(1):31â€“6.
Heller SR, McNaught A, Pletnev I, Stein S, Tchekhovskoi D. InChi, the IUPAC in- ternational chemical identifier. J Cheminform 2015;7(1):1â€“34.
Durant JL, Leland BA, Henry DR, Nourse JG. Reoptimization of MDL keys for use in drug discovery. J Chem Inf Comput Sci 2002;42(6):1273â€“80.
Rogers D, Hahn M. Extended-connectivity fingerprints. J Chem Inf Model 2010;50(5):742â€“54.
Glen RC, Bender A, Arnby CH, Carlsson L, Boyer S, Smith J. Circular fingerprints: flexible molecular descriptors with applications from physical chemistry to ADME. IDrugs 2006;9(3):199.
Hert J, Willett P, Wilton DJ, Acklin P, Azzaoui K, Jacoby E, et al. Comparison of fingerprint-based methods for virtual screening using multiple bioactive reference structures. J Chem Inf Comput Sci 2004;44(3):1177â€“85.
PÃ©rez-Nueno VI, Rabal O, Borrell JI, TeixidÃ³ J. APIF: a new interaction fingerprint based on atom pairs and its application to virtual screening. J Chem Inf Model 2009;49(5):1245â€“60.
Apweiler R, Bairoch A, Wu CH, Barker WC, Boeckmann B, Ferro S, et al. UniProt: the universal protein knowledgebase. Nucleic Acids Res 2004;32(suppl_1):D115â€“19.
Berman HM, Westbrook J, Feng Z, Gilliland G, Bhat TN, Weissig H, et al. The protein data bank. Nucleic Acids Res 2000;28(1):235â€“42.
Wang R, Fang X, Lu Y, Yang C-Y, Wang S. The PDBbind database: methodologies and updates. J Med Chem 2005;48(12):4111â€“19.
Kim S, Thiessen PA, Bolton EE, Chen J, Fu G, Gindulyte A, et al. PubChem substance and compound databases. Nucleic Acids Res 2016;44(D1):D1202â€“13.
Gaulton A, Hersey A, Nowotka M, Bento AP, Chambers J, Mendez D, et al. The chEMBL database in 2017. Nucleic Acids Res 2017;45(D1):D945â€“54.
Papadatos G, Davies M, Dedman N, Chambers J, Gaulton A, Siddle J, et al. SurechEMBL: a large-scale, chemically annotated patent document database. Nu- cleic Acids Res 2016;44(D1):D1220â€“8.
Gilson MK, Liu T, Baitaluk M, Nicola G, Hwang L, Chong J. BindingDB in 2015: a public database for medicinal chemistry, computational chemistry and systems pharmacology. Nucleic Acids Res 2016;44(D1):D1045â€“53.
Wishart DS, Feunang YD, Guo AC, Lo EJ, Marcu A, Grant JR, et al. Drug- bank 5.0: a major update to the drugbank database for 2018. Nucleic Acids Res 2018;46(D1):D1074â€“82.
Irwin JJ, Shoichet BK. Zinc- a free database of commercially available compounds for virtual screening. J Chem Inf Model 2005;45(1):177â€“82.
Huang Z, Mou L, Shen Q, Lu S, Li C, Liu X, et al. ASD v2. 0: updated con- tent and novel features focusing on allosteric regulation. Nucleic Acids Res 2014;42(D1):D510â€“16.
Ruddigkeit L, Van Deursen R, Blum LC, Reymond J-L. Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17. J Chem Inf Model 2012;52(11):2864â€“75.
Landrum	G..	Rdkit:	Open-source	cheminformatics	soft- ware2016;https://www.github.com/rdkit/rdkit/releases/tag/Release_2016_09_4.
Oâ€™Boyle NM, Banck M, James CA, Morley C, Vandermeersch T, Hutchison GR. Open babel: an open chemical toolbox. J Cheminform 2011;3(1):1â€“14.
Willighagen EL, Mayfield JW, Alvarsson J, Berg A, Carlsson L, Jeliazkova N, et al. The chemistry development kit (CDK) v2. 0: atom typing, depiction, molecular formulas, and substructure searching. J Cheminform 2017;9(1):1â€“19.
Arabie P., Baier N.D., Critchley C.F., Keynes M.. Studies in classification, data anal- ysis, and knowledge organization2006;.
Irving G, Isard M, et al. {TensorFlow}: a system for {Large-Scale} machine learn- [155] Abadi M, Barham P, Chen J, Chen Z, Davis A, Dean J, Devin M, Ghemawat S,
ing. In: 12th USENIX symposium on operating systems design and implementation (OSDI 16); 2016. p. 265â€“83.
Etaati L. Deep learning tools with cognitive toolkit (CNTK). In: Machine learning with microsoft technologies. Springer; 2019. p. 287â€“302.
Al-Rfou R, Alain G, Almahairi A, Angermueller C, Bahdanau D, Ballas N, et al. Theano: a python framework for fast computation of mathematical expressions. arXiv e-prints 2016:1605.
Paszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G, et al. Pytorch: an imperative style, high-performance deep learning library. Adv Neural Inf Process Syst 2019;32.
Ketkar N. Introduction to keras. In: Deep learning with Python. Springer; 2017.
p. 97â€“111.
Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al. Scik- it-learn: machine learning in python. J Mach Learn Res 2011;12:2825â€“30.
Norgeot B, Glicksberg BS, Butte AJ. A call for deep-learning healthcare. Nat Med 2019;25(1):14â€“15.
Esteva A, Robicquet A, Ramsundar B, Kuleshov V, DePristo M, Chou K, et al. A guide to deep learning in healthcare. Nat Med 2019;25(1):24â€“9.
Yang Z, Huang Y, Jiang Y, Sun Y, Zhang Y-J, Luo P. Clinical assistant diagno- sis for electronic medical record based on convolutional neural network. Sci Rep 2018;8(1):1â€“9.
Mohr DC, Zhang M, Schueller SM. Personal sensing: understanding mental health using ubiquitous sensors and machine learning. Annu Rev Clin Psychol 2017;13:23.
Gkotsis G, Oellrich A, Velupillai S, Liakata M, Hubbard TJP, Dobson RJB, et al. Characterisation of mental health conditions in social media using informed deep learning. Sci Rep 2017;7(1):1â€“11.
Koscielny S. Why most gene expression signatures of tumors have not been useful in the clinic. Sci Transl Med 2010;2(14). 14ps2â€“14ps2
