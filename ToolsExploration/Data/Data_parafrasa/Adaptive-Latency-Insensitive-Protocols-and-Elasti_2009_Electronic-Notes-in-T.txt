In this section, we present an overview of two approaches that we will refer to as ALIP and ECEE hereafter. We direct interested readers to the original papers for a full examination of their characteristics. ALIP and ECEE differ sufficiently from their static counterparts, LIP and EC(see), to warrant a detailed analysis of their advantages and disadvantages.

While we did not conduct a power evaluation, it is possible that ECEE consumes less power than ALIP while delivering the same level of performance, due to potentially more frequent clock-gating events induced by antitokens. However, it is also plausible that the additional (potentially lengthy) wires and supplementary control logic in ECEE contribute more to power consumption compared to local counters in ALIP. Further research is required to clarify this issue.

This discussion underscores the difficulty in establishing general guidelines for the superior applicability of one protocol over the other. In specific cases, such as those presented in the subsequent two sections, the performance superiority of ALIP becomes evident. Section 5 will demonstrate that analyzing the combined impact of multiple conditions, emulated through a set of benchmarks, complicates the evaluation.

In this section, we showcase instances where we observed penalties that impact ECEE in comparison to ALIP, using straightforward and easily understandable examples. The first example pertains to the classic case of reconvergent fanout, in which the output of a block is directed to two (or more) branches with differing latencies. The second example is representative of the category of issues that arise when state-holding blocks are involved.

It is worth noting that such issues in static protocols can be resolved with additional buffers or buffer sizing. However, adaptive protocols may depend on more intricate data-related interactions among various system components that cannot be as effectively modeled and optimized. Furthermore, such optimizations could be substantially costlier in terms of hardware or optimization time.

We implemented ALIP and ECEE versions of a simplified DLX in behavioral VHDL, which allows for the adjustment of parameters such as the mix of instructions, the percentage of data dependency, and the option to send instruction bursts (e.g., many consecutive pipelined multiplication operations followed by many addition operations). With this setup, we were able to collect numerous insightful data and compare the behavior of ALIP and ECEE in a reasonably complex yet controllable example.

In both cases of data dependency and independence, we varied the percentage of instructions utilizing the pipelined unit from 0% to 100% in increments of 10%. In this experiment, the latency of the pipelined unit was set to 3, while the multicycle unit was not used (execution latency of all instructions was 0 or 3 cycles). We first discuss the results in the extreme scenarios (0% and 100%) and then examine the intermediate ones.

The preceding noteworthy DLX case illustrates some of the points made in the previous sections regarding the greater potential for performance in the ALIP case. However, this does not preclude the possibility of superior performance by ECEE in specific cases. Complex interactions among blocks in a topology with a larger number of components might favor the ECEE case, as highlighted in the next section.