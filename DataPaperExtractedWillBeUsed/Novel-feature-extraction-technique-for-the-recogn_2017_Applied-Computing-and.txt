ORIGINAL ARTICLE
Novel feature extraction technique for the
recognition of handwritten digits
Abdelhak Boukharouba a,*, Abdelhak Bennia b
a Faculte´ des Sciences et de la technologie, De´partement d’Electronique et de Te´le´communications, Universite´ 8 Mai 1945 Guelma, BP
401, Guelma 24000, Algeria
b Faculte´ des Sciences de la Technologie, De´partement d’Electronique, Universite´ Constantine 1, Algeria
Received 15 December 2014; revised 1 May 2015; accepted 17 May 2015
Available online 27 May 2015
KEYWORDS
Feature extraction;
Feature selection;
Digit recognition;
Support vector machine
Abstract
This paper presents an efﬁcient handwritten digit recognition system based on support
vector machines (SVM). A novel feature set based on transition information in the vertical and hor-
izontal directions of a digit image combined with the famous Freeman chain code is proposed. The
main advantage of this feature extraction algorithm is that it does not require any normalization of
digits. These features are very simple to implement compared to other methods. We evaluated our
scheme on 80,000 handwritten samples of Persian numerals and we have achieved very promising
results.
� 2015 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is
an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
1. Introduction
The recognition of handwritten script is a difﬁcult task due to
the different handwriting qualities and styles that are subject to
inter-writer and intra-writer variations. Many recognition sys-
tems in many applications have been proposed in recent years
where higher recognition accuracy is always desired. Typically,
the recognition systems are adapted to speciﬁc applications to
achieve better performance. They can be divided into three
main steps: preprocessing step, feature extraction and selection
step, and classiﬁcation and veriﬁcation step. Handwritten digit
recognition problem can be seen as a subtask of the optical
character recognition (OCR) problem. Unconstrained hand-
written digit recognition has been applied to recognize
amounts written on checks for banks or zip codes on envelopes
for postal services, etc.
This paper focuses on feature extraction and classiﬁcation.
The performance of a classiﬁer can rely as much on the quality
of the features as on the classiﬁer itself. A good set of features
should represent characteristics that are particular for one
class and be as invariant as possible to changes within this class
[1]. Commonly used features in character recognition are:
invariant moments [2], projections [3], zoning feature [4], Four-
ier descriptors [5], and contour direction histogram [6]. A fea-
ture set made to feed a classiﬁer can be a mixture of such
features.
While handwritten Latin digits recognition has been exten-
sively investigated [7–10] through various techniques, little
* Corresponding author. Tel.: +213 777 08 32 32; fax: +213 37 20 72
68.
E-mail address: boukharouba_abdelhak@hotmail.com (A. Boukhar-
ouba).
Peer review under responsibility of King Saud University.
Production and hosting by Elsevier
Applied Computing and Informatics (2017) 13, 19–26
Saudi Computer Society, King Saud University
Applied Computing and Informatics
(http://computer.org.sa)
www.ksu.edu.sa
www.sciencedirect.com
http://dx.doi.org/10.1016/j.aci.2015.05.001
2210-8327 � 2015 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
work has been done for Arabic/Farsi digit recognition. Direc-
tion histograms using segmented characters from words in the
CEDAR database [11] and transition information from the
background to the foreground pixels in the vertical and hori-
zontal directions of a character image [12] have been investi-
gated. Later, feature extraction techniques generating local
and global features were proposed [13] wherein local features
were obtained from sub-images of the character including fore-
ground pixel density information and directional information.
The global features measured the fraction of the character
appearing below the word baseline and the characters’
width/height ratio. Furthermore, gradient features have been
proposed for handwritten character recognition [14,15] where
Awaidah and Mahmoud combined them with structural and
concavity features for the recognition of Arabic (Indian)
numerals using hidden Markov models (HMM) [16].
A probabilistic neural network (PNN) approach for the
recognition of the handwritten Indian numerals [17] based
on the center of gravity and a set of vectors to the boundary
points of the digit has been presented however Montazer
et al. [18] proposed a holistic approach using neuro-fuzzy
inference engine to recognize the Farsi numeral characters.
Finally, Impedovo et al. introduced a genetic algorithm based
clustering approach using zoning features [19] whereas an
adaptive zoning techniques for handwritten digit recognition
are presented [20,21] where the features are extracted accord-
ing to an optimal zoning distribution. The experimental tests
show the effectiveness of the latter with respect to traditional
approaches for zoning design.
The literature details many high accuracy recognition sys-
tems for handwritten Farsi digit database [22] used in our
research. While an efﬁcient feature set based on modiﬁed con-
tour chain code has been proposed in [23], two types of feature
sets based on modiﬁed chain-code direction frequencies in the
contour pixels of input image and modiﬁed transition features
have been presented [24]. A support vector machine (SVM) is
proposed as classiﬁer to recognize Persian isolated digits.
Besides, combinational methods for improving the recognition
rate of multi-class classiﬁers using confusion matrix and
Genetic Algorithms have been proposed [25,26]. From the lit-
erature survey of the existing feature extraction techniques for
character/digit recognition, most of them need digit normaliza-
tion and consequently cannot preserve the shape of the input
image for feature extraction step, which could react negatively
to the recognition phase. For that reason, the main contribu-
tion of this work focuses on novel feature extraction approach
where the digit image does not require any normalization.
This paper is broken down into ﬁve sections. Section 2
provides details on the feature extraction and selection tech-
niques. Section 3 deals with the classiﬁers used for the recog-
nition
purpose,
experimental
results
are
discussed
in
Section 4, and ﬁnally Section 5 presents some conclusions
and perspectives.
2. Feature extraction and selection
In this section, we describe two feature extraction techniques
that are investigated in this work. The ﬁrst is the chain code
histogram (CCH) [27], which is developed to simply describe
statistically the boundary of each digit’s image. To eliminate
the effect of contour direction distortion caused by digit image
normalization, we compute the feature vector without normal-
izing digit image. Finally, we normalize feature vector by mak-
ing its module equal to one. The second feature extraction
technique builds on the white–black transition information
in the vertical and horizontal directions of a digit image. Each
transition feature is characterized by the area deﬁned by the
corresponding transition and normalized by dividing it by
the whole digit’s area.
The ﬁrst feature set is the chain code histogram (CCH),
which is a statistical measure for the directionality of the con-
tour of a digit. In this work, we measure the slope between two
successive points, which would give the angle made by the line
joining them and the x-axis. Then the set of possible slopes is
(0�, 45�, 90�, 135�), which are identical to the directions (180�,
225�, 270� and 315�). Thus, the directions between two succes-
sive pixels are encoded as 0, 1, 2 and 3 direction codes, respec-
tively as shown in Fig. 1. Consequently, one of four direction
codes is assigned to each two connected pixels.
The Canny algorithm is more robust to noise and more
likely to detect true weak edges but some digit samples are with
bad qualities so that after applying canny operator some
redundant pixels are remained, which affect the contour fol-
lowing, these pixels should be removed. The redundant pixel
removal process is based on the condition that every contour
pixel can only have two 8-connected pixels around it. If there
is a pixel which has more than two 8-connected pixels around
it, the redundant pixels must be detected and removed. An
example of redundant pixel removal process is shown in
Fig. 2 where pixel 2 is a redundant one and must be removed.
After removing redundant pixels, the contour becomes of unit
thickness and consequently, we ﬁnd that only 4 possible seg-
ments exist in the contour structure, which are considered as
basic segments consisting of two pixels. Consequently, the fea-
ture extraction process is independent of the tracing direction.
To extract features from digit contour, we employ a his-
togram of the 4-chain code directions. The 4-bin histogram
of chain code directions is computed where each bin represents
the frequency of the one direction.
First, the smallest bounding box enclosing the digit contour
is computed. If any of the number of rows or columns of the
bounding box is not a multiple of 3, one or two rows/columns
of zeros should be added. If only one row of zeros is to be
added then it will be added on the right side of the image. If
two rows of zeros are to be added then each one must be on
one side and similarly for columns. Consequently, the image
can be divided into 3 � 3 zones of equal area. The tracing pro-
cess starts from the end point on the contour element, search-
ing for the next nonzero pixel in any direction until end point is
1
2
0
3
Fig. 1
Diagram of the 4-chain code directions.
20
A. Boukharouba, A. Bennia
reached. The remaining contour elements are traced in the
same way.
Fig. 3 shows an example of chain code histogram of the
contour points of the middle-left and top-right zones of the
digit ٣.
Afterward, the contour feature vector composed of 9 � 4
(36) components is normalized as follow.
fi ¼ hi
khik ;
i ¼ 1; 2; . . . ; 36
ð1Þ
where hi is the ith bin of the tangent histogram of the whole
digit, fi is the ith component of the feature vector f, which is
between 0 and 1, and k k is the 2-norm. Thus, kfk ¼ 1. Conse-
quently, these features are a translation and scale invariant
contour descriptors and they are independent of the way a con-
tour is traced.
The second set, which is used as complementary description
of digits, is based on the white–black transition information in
the vertical and horizontal directions of a digit image. This
technique is an extension of that presented in [28] where the
transition description is based on the length of the transitions.
However, this technique is based on the areas between these
transitions and the bounding box of the digit as region
descriptors.
Each transition feature is calculated as the ratio between
the area deﬁned by each transition type and the whole digit’s
area. The area is computed as the number of pixels between
the left/top boundary of the bounding box of the digit image
and the digit’s edge deﬁned by the transition location in the
horizontal/vertical direction.
fhk ¼ hak
w � h ; fvk ¼ vak
w � h for k ¼ 1; 2 and fh3 ¼
P
kP3hak
w � h
;
fv3 ¼
P
kP3vak
w � h
:
where hak and vak are the areas of the regions deﬁned by the
edge of the kth transition in the horizontal and vertical direc-
tion, respectively. w and h are the width and the height of the
digit image.
In the horizontal direction, the bounding box of each digit
is divided horizontally in two equal parts. For each part, the
three transition features are calculated in the horizontal direc-
tion. In the vertical direction, the three transition features are
evaluated on the whole digit.
Fig. 4 shows an example of the different areas made by the
white–black transitions of the digit ۸. In the horizontal direc-
tion we have only tow transition types of each part: the area
formed by the ﬁrst transition is at the left side of each part,
the area formed by the second transition is at the right side
of each part, and as we have not a third transition, the corre-
sponding area is equal to zero.
In the vertical direction we have only one transition: the
corresponding area is at the bottom side of the digit; and as
we have only one transition, the second and third area is equal
to zero.
Finally, relative area feature is calculated with respect to
pre-ﬁxed area (w0 � h0): ratio = w � h/w0 � h0 where w and h
are the width and the height of the digit image respectively.
In this work the pre-ﬁxed area w0 � h0 is equal to 2000.
As a result, we obtain a feature vector of 46 components
per digit.
Feature selection aims to reduce the dimensionality of the
feature space for classiﬁcation by selecting the most informa-
tive features. The most informative features are the ones that
best separate the different classes. Feature selection has been
used previously for many applications, yielding higher speed
and reduced computational cost for the classiﬁcation process.
One way to evaluate the pertinence of the extracted features
is to calculate the discriminative power of each feature. In
order to select the most discriminative features, we adopt the
Fisher criteria, which compute directly the discriminative
power Dk of each feature k as follow [29]:
Dk ¼ 1
r2
k
; where r2
k ¼
X
C
i¼1
pðwiÞr2
ik
ð2Þ
where C is the number of classes, p(wi) is a prior probability of
class wi, and rik is the variance of feature k according to the
class i. These parameters are estimated from the training
dataset.
The features must be ordered in the descending order in
terms of their discriminative powers in order to select the most
4
3
2
1
Fig. 2
The redundant pixel removal principle: pixel 2 is a
redundant pixel and must be removed.
Fig. 3
Chain code histogram of the contour points of the middle-left and top-right zones of the digit ٣.
Novel feature extraction technique
21
pertinent features. There is no theoretical criterion to calculate
the threshold that separates the pertinent features from the
redundant ones. The threshold is then determined with the
help of many experiments by undertaking trainings on the
selected features. Finally, we retain the threshold that provides
the best performance in terms of recognition rate.
3. Support vector machines
SVM is a classiﬁer derived from statistical learning theory ﬁrst
presented by Boser et al. [30]. SVMs were introduced in [31] as
learning machines with capacity control for regression and bin-
ary classiﬁcation problems. It has also been proved to be very
successful in many other applications such as handwritten digit
recognition, image classiﬁcation, face detection, object detec-
tion, and text classiﬁcation. In the case of classiﬁcation,
SVM try to ﬁnd an optimal hyperplane that correctly classiﬁes
data points by separating the points of two classes as much as
possible. For the linearly separable case, the support vector
algorithm simply looks for the separating hyperplane with lar-
gest margin. This can be formulated as follows: suppose that
all the training data satisfy the following constraints:
xT
i w þ b P þ1 for yi ¼ þ1 and xT
i w þ b 6 �1 for yi ¼ �1.
Then the hyperplane ðxTw þ bÞ separates the data if and only
if:
yiðxT
i w þ bÞ P 1;
8i:
ð3Þ
The optimal separating hyperplane is a margin classiﬁer
whose output is given by:
fðxÞ ¼ signðxTw þ bÞ
ð4Þ
where x is the input pattern, w is the weights vector, and b is
the bias. The bias and the weights are computed by maximiz-
ing the margin 1=kwk subject to the constraint that the N train-
ing patterns are well classiﬁed and outside the margin:
min 1
2 kwk2
s:t: yiðxT
i w þ bÞ P 1;
i ¼ 1; . . . ; N:
ð5Þ
with yi 2 f�1; 1g representing the label of the training pattern
xi. The solution corresponds to the saddle point of the primal
Lagrangian:
Lp ¼ 1
2 kwk2 �
X
N
i¼1
ai½yiðxT
i w þ bÞ � 1�
ð6Þ
where the ai are the Lagrange multipliers. This problem leads
to the maximization of the dual Lagrangian with respect to ai:
LD ¼
X
N
i¼1
ai � 1
2
X
N
i;j
aiajyiyjðxT
i xjÞ
s:t: ai P 0;
i ¼ 1; . . . ; N;
X
N
i¼1
aiyi ¼ 0
ð7Þ
This is a standard quadratic problem, where a global max-
imum ai can always be found and w can be recovered as:
w ¼
X
N
i¼1
aiyixi
ð8Þ
Many of ai are zero, which implies that w is a linear combi-
nation of a small number of data. The set of elements xi with
non-zero ai are called support vectors.
Then, the resulting separating rule is:
fðxÞ ¼ sign
X
support vectors
yiaiðxT
i xÞ þ b
 
!
ð9Þ
The SVs are the training patterns that lie on the margin
boundaries. An advantage of this algorithm is its sparsity since
only a small subset of the training examples are used to com-
pute the output of the classiﬁer. Fig. 5 represents a binary clas-
siﬁcation problem where ﬁlled circles and squares are the
training data while hollow circles and triangles are the testing
data.
In case of such separating hyperplane does not exist, we
introduce a set of slack variables ni to allow points inside the
margin during the training.
min 1
2 kwk2 þ C
X
N
i¼1
ni
s:t: yiðxT
i w þ bÞ P 1 � ni;
i ¼ 1; . . . ; N:
ð10Þ
where penalty parameter C is used to tune the trade-off
between the classiﬁcation errors and the maximization of the
margin. The formulation (6) is often called soft margin
Fig. 4
Example of the different areas made by the white–black
transitions of the digit ۸.
Fig. 5
Linear separating hyperplanes for the separable case:
ﬁlled circles and squares are the support vectors.
22
A. Boukharouba, A. Bennia
SVM. This new formulation leads to the same dual problem
but with box constraints on the Lagrange multipliers:
0 6 ai 6 C;
i ¼ 1; . . . ; N;
ð11Þ
The tuning of the hyperparameter C is a delicate task. A
common method is to perform a grid search, i.e. to test many
values of C and estimate for each the generalization error.
This approach is valid whenever the set of points of the two
classes are linearly separable. Nevertheless in real data this is
usually not the case. In order to work with non-linear decision
boundaries the key idea is to transform xi to a higher dimen-
sion space using a transformation function, so that in this
new space the samples can be linearly separable. SVM solve
these problems using kernels. One only has to calculate the
inner products of the vectors in the feature space via the kernel
function K(�, �). This is the kernel trick that allows the con-
struction of a decision function that is nonlinear in the input
space but equivalent to a linear decision function in the feature
space:
fðxÞ ¼ sign
X
support vectors
yiaiKðxi; xÞ þ b
 
!
ð12Þ
where K(xi,x) stands for the kernel function. Typical kernel
functions are:
RBF (Gaussian) kernel: Kðxi; xÞ ¼ exp � kx�xik2
2r2
�
�
.
Sigmoid kernel Kðxi; xÞ ¼ tanhðcðxTxiÞ þ cÞ:
Polynomial kernel Kðxi; xÞ ¼ ðc xTxi þ cÞ
d:
There are two common methods to solve a multi-class
problem with binary classiﬁers such as SVMs: one-against all
(or one-vs-rest) and one-against-one. In the one-against-all
scheme, a classiﬁer is built for each class and assigned to the
separation of this class from the others. For the one against-
one method, a classiﬁer is built for every pair of classes to sep-
arate the classes two by two. Another approach to the recog-
nition of n different digits is to use a single n-class SVM
instead of n binary SVM subclassiﬁers with the one-against-
all method, thus solving a single constrained optimization
problem.
4. Experiments and results
In this section we present the experimental results to illustrate
the beneﬁts of the chain code histogram combined with the
transition features in digit recognition ﬁeld. We evaluate our
method on a large handwritten dataset of Farsi digits, named
‘‘Hoda” [22]. This dataset consists of ten digit classes from 0 to
9 (۰۱۲۳۴۵۶۷۸۹). For experimental results, 80,000 handwritten
samples are considered; 6000 samples per class for training and
2000 samples per class for testing. Fig. 6 shows some digit sam-
ples extracted from the used database with different styles and
qualities.
Firstly, Canny operator is used for digit contour extraction
then the bonding box of each digit contour is divided into nine
equal zones. Within each zone the redundant pixels is removed
and the contribution of the 4-chain codes are counted in the
corresponding histograms. The transition features are calcu-
lated as shown above: in the horizontal direction, the bound-
ing box of each digit is divided horizontally in two equal
parts. For each part, the transition features are calculated in
the horizontal direction. In the vertical direction, the transition
features are evaluated on the whole digit. Finally, relative area
is calculated. The used feature vector is equal to 10.f, where f is
the vector of the 46 features.
Secondly, the proposed architecture of SVM based classiﬁer
is composed of ten one-against-all SVMs. The classiﬁer struc-
tures were empirically set as follows. The RBF kernel is used
where the variance parameter r is equal to 1 (r = 1) and the
hyperparameter C is equal to 100 (C = 100).
Table 1 shows the details of misrecognition and recognition
accuracy of each digit where the recognition accuracy of
98.48% is obtained on the whole test set (20,000 samples). It
may be noted that out of 305 misrecognized samples, 183
(60%) samples belong to {۲, ٣, ۴} group and 122 (40%)
samples belong to the remaining digits. Thus, the major mis-
recognized digits are among 2, 3 and 4 digits. To improve
the recognition accuracy, we use a scheme similar to one intro-
duced in [24]. We utilize a classiﬁer composed of seven one-
against-all SVMs where {۰, ۱} and {۲, ٣, ۴} represent two
separate classes as shown, in Fig. 7. After that, we use one
against-all SVM to separate the combined {۰,۱} class. For
the recognition of digits ۲, ٣, ۴, we also use twice one-
against-all SVM.
Fig. 7 illustrates the recognition system where arrow
weights represent the number of the misrecognized digits of
each class. Out of a total of 20,000 digits in the testing set,
there are 291 digits that are not successfully recognized. Con-
sequently, we obtain 98.55%, which showed slight improve-
ment when compared with the ﬁrst scheme. Note that we
have got an accuracy of 100% on the training samples
(60,000 samples) and also an accuracy of 100% when the train-
ing is made on the whole dataset (80,000 samples).
Fig. 6
Digit samples of handwritten Farsi digits [22], (a) different qualities, (b) different styles.
Novel feature extraction technique
23
The performances of most of the works available for Per-
sian numerals are presented in [23–26] where detailed compar-
isons with recent published works are discussed. Table 2 shows
a comparison with the most excellent existing works, that are
to the best of our knowledge the only works in the literature
that deal with Farsi digits composing Hoda dataset.
From Table 2 it is clear that the highest recognition rate is
99.02% [24] when 196 features are used for training. In our
work, we reached an interesting recognition rate of 98.55%
with only 46 features.
The second experiment investigates the performance of
SVM classiﬁer based on the reduced feature sets.
In order to yield higher speeds and reduced computational
cost for the classiﬁcation process, we choose to reduce the
number of features involved in the training and testing stages
of SVM.
Table 3 illustrates the individual discriminative power of
each feature. The ﬁrst column represents the discriminative
powers of the features extracted from transitions and the rela-
tive area respecting the order described in the transition feature
procedure. The discriminative powers of CCH features are pre-
sented in a 3 � 3 grid with 4 values in each cell matching the
corresponding image region. The threshold value of discrimi-
native powers used to select the pertinent primitives must be
determined by practical tests. First, the primitives have been
ranked in descending order of their discriminative powers.
The threshold is then determined by undertaking trainings
on the selected features. We retain the threshold that provides
the best performance in terms of recognition rate.
Table 4 shows the best results obtained for different num-
bers of selected features using the SVM classiﬁer with the same
parameters used above (r = 1 and C = 100).
The ﬁrst column represents the value of threshold of the
discriminative power, second column represents the number
of selected features, and the last column represents the recog-
nition rate achieved on the test data set.
The highest recognition rate achieved here is 98.46% using
40 features and 98.44% using only 36 features, which are
slightly less than the rate obtained with the 46 features. It is
then sufﬁcient to retain only the 36 primitives whose discrimi-
native powers are the most pertinent.
Moreover, the discriminative powers help us to analyze the
pertinence of the different features. From Table 3, among the
10 less pertinent features there are only two from the transition
features and the remaining are from the CCH features. We can
also notice that the most pertinent feature is the area made by
the second transition of the low part in the horizontal direction
with discriminative power of 0.8217, which prove the perti-
nence of the transition features.
The best performance/complexity is obtained with an SVM
classiﬁer (r = 1 and C = 100) using 36 primitives, which is
more efﬁcient than the system trained on 106 primitives [25].
Fig. 7
Recognition scheme: arrow weights represent the number
of the misrecognized digits.
Table 1
Misrecognition and recognition accuracy of the ten
digits.
Number
(Farsi)
Number of misclassiﬁed
digits
Recognition accuracy
(%) (test)
0
14
99.30
1
7
99.65
2
42
97.90
3
109
94.55
4
32
98.40
5
15
99.25
6
30
98.50
7
20
99.00
8
4
99.80
9
32
98.40
Table 2
Comparisons to other systems in the literature.
Algorithms
Number
of features
Dataset size
Accuracy(%)
Train
Test
Train
Test
[23]
196
60,000
20,000
99.99
98.71
[23]
196
80,000
–
99.37
–
[24]
196
60,000
20,000
99.99
99.02
[25]
106
60,000
10,000
–
98.89
[26]
106
40,000
20,000
–
97.12
Proposed algorithm
46
60,000
20,000
100
98.55
46
80,000
–
100
–
Table 3
Discriminative powers of 46 used features.
Transition features
Chain code histogram features
0.1553
0.1241
0.2023
0.1667
0.2092
0.1926
0.1504
0.1824
0.2671
0.1769
0.1732
0.1679
0.3647
0.1887
0.1704
0.3490
0.8217
0.2135
0.1553
0.2145
0.2760
0.1451
0.1562
0.2129
0.3711
0.2191
0.1251
0.3142
0.3879
0.3249
0.1668
0.1790
0.1391
0.2594
0.3810
0.1755
0.2024
0.1415
0.1901
0.2491
0.2287
0.1318
0.2347
0.2178
0.1849
0.2302
Table 4
Effect of the size of the feature vector on the
recognition rate.
Threshold of
discriminative power
Number of selected
features
Recognition
rate (%)
0.1500
40
98.46
0.1600
36
98.44
24
A. Boukharouba, A. Bennia
Moreover, it is important to note that the architecture of a
classiﬁer, by reducing its size, requires less storage capacity
for its parameters.
We can augment the feature space using some structural
features to efﬁciently remove some confusion and to achieve
best results but the main purpose of this work is to demon-
strate the efﬁciency of these new features.
The most noticeable improvement is that a 100% recogni-
tion rate is achieved in the training phases for all digits
(60,000 and 80,000 samples), which is better than all of those
presented in the literature. We believe that our results are very
competitive and quite promising since we used only 36 simple
features.
As we have achieved a rate of 100% on training datasets,
then we can achieve a higher accuracy rate if we train SVM
classiﬁers on appropriate support vectors, because the general-
ization property of an SVM does not depend on all the training
data, but only support vectors.
Finally, we can see from the results that the achieved accu-
racy is due to the discriminatory power of features and the
regression capabilities of SVM classiﬁers.
5. Conclusion
This paper presents a system for the recognition of the hand-
written Persian numerals that could be used for automatic
reading of numerical amounts of checks. The main contribu-
tion of this work focuses on feature extraction where a novel
feature set based on transition information in the vertical
and horizontal directions of a digit image combined with the
well-known chain code histogram (CCH) is discussed and
compared with others in the literature. The classiﬁcation sys-
tem is based on SVM, which is considered one of the most
powerful classiﬁcation techniques and is now widely used in
many pattern recognition applications. The results of our
experiments show that feature selection procedure reduces
the dimensionality of the feature space without affecting the
performance of the classiﬁer where the system can maintain
high performance with less computational complexity compar-
ing to the systems in the literature.
From experimental results, it is evident that our system
resulted good performance. We noted that most of misclassi-
ﬁed samples were from classes of ۲, ٣, and ۴, which are
similar in shapes where their recognition is sometimes difﬁcult
even for human being.
Among the most important advantages of this feature
extraction algorithm; it does not require any normalization
of digits where the most of the published works need digit nor-
malization, which degrade the image quality. These features
are also very simple to implement compared to other methods.
It is obvious that to improve the performance of proposed
system further, we need to investigate more on sources of
errors. Potential features other than the presented ones may
exist. In future, we plan to use some structural features like
concavity analysis which may remove some of confusions
among similar classes.
Concerning the SVM classiﬁers, the tuning of the hyperpa-
rameter C is a delicate task. We are sure that the RBF kernel
parameters (r and C) used in our experiments are not the best
choices and are not implemented optimally because we have
tried only a few experiments to choose them. Thus, we can
improve the performance of the system by testing many values
of these parameters and estimate for each the generalization
error.
Finally, because we have achieved a rate of 100% on train-
ing datasets then as perspective we will try to train automati-
cally SVM classiﬁers on the support vector set that represent
the more delicate examples instead of the whole training set
to achieve higher recognition accuracy.
References
[1] F. Lauer, C.Y. Suen, G. Bloch, A trainable feature extractor for
handwritten digit recognition, Pattern Recogn. 40 (2007) 1816–
1824.
[2] C.H. The, R.T. Chin, On image analysis by the methods of
moments, IEEE Trans. Pattern Anal. Mach. Intell. 10 (1988)
496–513.
[3] A.L. Koerich, Unconstrained handwritten character recognition
using different classiﬁcation strategies, in: Proceedings of
International Workshop on Artiﬁcial Neural Networks in
Pattern Recognition, 2003.
[4] L.S. Oliveira, R. Sabourin, F. Bortolozzi, C.Y. Suen, Automatic
recognition of handwritten numerical strings: a recognition and
veriﬁcation strategy, IEEE Trans. Pattern Recogn. Mach. Intell.
24 (11) (2002) 1438–1454.
[5] H. Kauppinen, T. Seppanen, M. Pietikamen, An experimental
comparison of autoregressive and Fourier-based descriptors in
2D shape classiﬁcation, IEEE Trans. Pattern Anal. Mach. Intell.
17 (1995) 207–210.
[6] K.M. Mohiuddin, J. Mao, A comprehensive study of different
classiﬁers
for
handprinted
character
recognition,
Pattern
Recogn. (1994) 437–448.
[7] X.X. Niu, C.Y. Suen, A novel hybrid CNN–SVM classiﬁer for
recognizing handwritten digits, Pattern Recogn. 45 (2012) 1318–
1325.
[8] Z. Man, K. Lee, D. Wang, Z. Cao, S. Khoo, An optimal weight
learning machine for handwritten digit image recognition, Signal
Process. 93 (2013) 1624–1638.
[9] E. Mohebi, A. Bagirov, A convolutional recursive modiﬁed self
organizing map for handwritten digits recognition, Neural
Netw. 60 (2014) 104–118.
[10] M. Hanmandlu, O.V. Ramana Murthy, Fuzzy model based
recognition of handwritten numerals, Pattern Recogn. 40 (2007)
1840–1854.
[11] H. Yamada, Y. Nakano, Cursive handwritten word recognition
using multiple segmentation determined by contour analysis,
IECE Trans. Inform. Syst. E79-D (1996) 464–470.
[12] P.D. Gader, M. Mohamed, I.H. Chiang, Handwritten word
recognition with character and inter-character neural networks,
IEEE Trans. Syst. Man Cybern. Part B: Cybern. 27 (1997) 158–
164.
[13] F. Camastra, A. Vinciarelli, Combining neural gas and learning
vector
quantization
for
cursive
character
recognition,
Neurocomputing 51 (2003) 147–159.
[14] C.L. Liu, Normalization-cooperated gradient feature extraction
for handwritten character recognition, IEEE Trans. Pattern
Anal. Mach. Intell. 29 (8) (2007).
[15] C.L. Liu, C.Y. Suen, A new benchmark on the recognition of
handwritten Bangla and Farsi numeral characters, Pattern
Recogn. 42 (2009) 3287–3295.
[16] S.M. Awaidah, S.A. Mahmoud, A multiple feature/resolution
scheme to Arabic (Indian) numerals recognition using hidden
Markov models, Signal Process. 89 (2009) 1176–1184.
[17] F.A. Al-Omari, O. Al-Jarrah, Handwritten Indian numerals
recognition system using probabilistic neural networks, Adv
Eng. Inform. 18 (2004) 9–16.
Novel feature extraction technique
25
[18] G.A. Montazer, H.Q. Saremi, V. Khatibi, A neuro-fuzzy
inference engine for Farsi numeral characters recognition,
Expert Syst. Appl. 37 (9) (2010) 6327–6337.
[19] S. Impedovo, F.M. Mangini, G. Pirlo, A genetic algorithm
based clustering approach for improving off-line handwritten
digit classiﬁcation, in: International Conference on Information
Science, Signal Processing and their Applications (ISSPA), 2012.
[20] S. Impedovo, F.M. Mangini, G. Pirlo, A new adaptive zoning
technique for handwritten digit recognition, in: ICIAP, 2013.
[21] F.M. Mangini, G. Pirlo, Adaptive zoning design by supervised
learning using multi-objective optimization, Int. J. Comput.
Intell. Appl. 13 (01) (2014).
[22] H. Khosravi, E. Kabir, Introducing a very large dataset of
handwritten Farsi digits and a study on the variety of
handwriting styles, Pattern Recogn. Lett. 28 (10) (2007) 1133–
1141.
[23] A. Alaei, U. Pal, P. Nagabhushan, Using modiﬁed contour
features and SVM based classiﬁer for the recognition of Persian/
Arabic handwritten numerals, in: 7th Int. Conf. on Advances in
Pattern Recognition, 2009 ‘a’, pp. 391–394.
[24] A. Alaei, P. Nagabhushan, U. Pal, Fine classiﬁcation of
unconstrained
handwritten
Persian/Arabic
numerals
by
removing confusion amongst similar classes, in: 10th Int.
Conf. on Document Analysis and Recognition, 2009 ‘b’.
[25] H. Parvin, H. Alizadeh, B. Minaei-Bidgoli, M. Analoui, A
scalable method for improving the performance of classiﬁers in
multiclass applications by pairwise classiﬁers and GA, in: 4th
Int.
Conf.
on
Networked
Computing
and
Advanced
Information Management, 2008.
[26] H. Parvin, H. Alizadeh, M. Moshki, B. Minaei-Bidgoli, N.
Mozayani, Divide & conquer classiﬁcation and optimization by
genetic algorithm, In: 3rd Int. Conf. on Convergence and
Hybrid Information Technology, N., 2008.
[27] J. Iivarinen, A. Visa, Shape recognition of irregular objects, in:
David P. Casasent (Ed.), Intelligent Robots and Computer
Vision
XV:
Algorithms,
Techniques,
Active
Vision,
and
Materials Handling, SPIE 2904, 1996, pp. 25–32.
[28] A. Boukharouba, A. Bennia, Recognition of handwritten Arabic
literal amounts using a hybrid approach, Cogn. Comput. 3 (2)
(2011) 382–393.
[29] K. Fukunaga, Introduction to Statistical Pattern Recognition,
Academic Press, 1990.
[30] B.E., Boser, I.M. Guyon, V.N. Vapnik, A training algorithm for
optimal margin classiﬁers, in: 5th Annual Workshop on
Computational Learning Theory, 1992, pp. 144–152.
[31] V.N. Vapnik, The Nature of Statistical Learning Theory,
Springer, New York, 1995.
26
A. Boukharouba, A. Bennia
