Feature aggregation for nutrient deﬁciency identiﬁcation in chili based on
machine learning
Deffa Rahadiyan a, Sri Hartati a,⁎, Wahyono a, Andri Prima Nugroho b
a Department of Computer Science and Electronics, Universitas Gadjah Mada (UGM), Yogyakarta, Indonesia
b Department of Agricultural and Biosystems Engineering, Universitas Gadjah Mada (UGM), Yogyakarta, Indonesia
a b s t r a c t
a r t i c l e
i n f o
Article history:
Received 18 July 2022
Received in revised form 5 April 2023
Accepted 25 April 2023
Available online 28 April 2023
Macronutrient deﬁciency inhibits the growth and development of chili plants. One of the non-destructive
methods that plays a role in processing plant image data based on speciﬁc characteristics is computer vision.
This study uses 5166 image data after augmentation process for six plant health conditions. But the analysis of
one feature cannot represent plant health condition. Therefore, a careful combination of features is required.
This study combines three types of features with HSV and RGB for color, GLCM and LBP for texture, and Hu mo-
ments and centroid distance for shapes. Each feature and its combination are trained and tested using the same
MLP architecture. The combination of RGB, GLCM, Hu moments, and Distance of centroid features results the best
performance. In addition, this study compares the MLP architecture used with previous studies such as SVM, Ran-
dom Forest Technique, Naive Bayes, and CNN. CNN produced the best performance, followed by SVM and MLP,
with accuracy reaching 97.76%, 90.55% and 89.70%, respectively. Although MLP has lower accuracy than CNN,
the model for identifying plant health conditions has a reasonably good success rate to be applied in a simple ag-
ricultural environment.
© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open
access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
Keywords:
Feature Combination
Multi-Layer Perceptron
Classiﬁer
Nutrient deﬁciency
1. Introduction
Lack of macronutrient or micronutrient is one of the causes for the
number of chili production being lower than consumption in
Indonesia (Bahtiar et al., 2020; Chen and Wang, 2019). Macronutrients
include N, P, K, Ca, Mg, S (1000 mg/kg dry matter), and micronutrients
include Iron, Mn, Zn, Cu, Cl, B, and Mo (100 mg/kg dry matter)
(Wulandhari et al., 2019; Tran et al., 2019). Chili plants that lack macro-
nutrients show visual characteristics on the leaves, such as changes in
color, shape, and leaf texture (Taujuddin et al., 2020; Tran et al., 2019;
daSilva et al., 2019; N and Saju, 2018; Shah et al., 2018). Nevertheless,
identifying nutrient deﬁciency is difﬁcult for ordinary farmers because
several nutrients show similar characteristics (Sinha and Shekhawat,
2020; Watchareeruetai et al., 2018; Harjoko et al., 2019).
Two methods for identifying nutrient deﬁciencies in plants are de-
structive and non-destructive. One of the destructive methods is labora-
tory testing, but the risk of error is more signiﬁcant due to human error
(Harjoko et al., 2019). Digital image processing with machine learning is
a non-destructive method that gives more objective results (Kamelia
et al., 2020; Myo Han and Watchareeruetai, 2020). Many studies iden-
tify macronutrient deﬁciencies based on plant images, especially leave
images. Several studies used RGB images of leaves of tomatoes, chilies,
cucumbers, and others (Bahtiar et al., 2020; Lewis and Espineli, 2020;
Jose et al., 2021; Shah et al., 2018). The rule-based method analyzes
RGB leaf color information in statistical values, but their model cannot
handle high data dimensions (Latte et al., 2017; Latte and Shidnal,
2016; Halim et al., 2021). Several studies have used machine learning
to identify macronutrient deﬁciencies in plants. The Backpropogation-
Artiﬁcial Neural Network (BP-ANN) model with a diagnostic rate of
97.5%, using hyperspectral image (Shi et al., 2021). In addition, the com-
parison of K-Nearest Neighbor (KNN) with other methods such as J48,
Naive Bayes, Partial Least Square (PLS), Classiﬁcation and Regression
Tree (CART), and Classiﬁcation Tree (CT). The highest accuracy is
86.52% for the KNN method (Kumar et al., 2015, 2021). Other studies
use logistic regression, Support Vector Machine (SVM), and Multi
Layer Perceptron (MLP) to identify nutrient deﬁciency of black gram
plants (Rahadiyan et al., 2022a). MLP performs better with 88.33% accu-
racy than logistic regression and SVM (Myo Han and Watchareeruetai,
2020). Then, another classiﬁer method, such as Naive Bayes and Ran-
dom Forest Technique (RFT) (Siedliska et al., 2021; Vassallo-Barco
et al., 2017). However, the success of the identiﬁcation model is not
only based on the machine learning method used, but also on the com-
bination of features analyzed.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
⁎ Corresponding authors.
E-mail addresses: deffa.rahadiyan@mail.ugm.ac.id (D. Rahadiyan), shartati@ugm.ac.id
(S. Hartati), wahyo@ugm.ac.id (Wahyono), andrew@ugm.ac.id (A.P. Nugroho).
https://doi.org/10.1016/j.aiia.2023.04.001
2589-7217/© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http://
creativecommons.org/licenses/by-nc-nd/4.0/).
Contents lists available at ScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage: http://www.keaipublishing.com/en/journals/artificial-
intelligence-in-agriculture/
Several studies have tried to use certain features and their combina-
tion to identify macronutrient deﬁciencies. Research (Drdsh et al., 2021)
compares YGB and the percentage of RGB value using ANN, and RGB
shows the best accuracy. In addition, HSV and RGB values can be used
(Qur'ania et al., 2020; Mashumah et al., 2018). The Gray-Level Co-
occurrence matrix (GLCM) method extracts the color and texture infor-
mation with four different angles (Sosa et al., 2019; Sabri et al., 2020;
Vassallo-Barco et al., 2017). Another method for texture is Local Binary
Pattern (LBP), but in (Tan et al., 2021)’s study, GLCM is more suitable
than LBP for their data. Another extraction method is shape feature ex-
traction using canny and Sobel edge detection (Qur'ania et al., 2020),
but research (Lukic et al., 2017) utilizes statistical characteristics of Hu
moments from binary leaf image. Not only using one feature, Combining
features is important in identifying macronutrient deﬁciencies
(Jeyalakshmi and Radha, 2017; Rahadiyan et al., 2022b). In several re-
searches, the combination of the features improves the result, such as
a combination of RGB statistics values and Sobel edge (Wulandhari
et al., 2019; Wang et al., 2021b), the combination of GLCM, hue, and
color histogram to analyze maize plants (Sabri et al., 2020). Then, the
combination of RGB values and texture value of the leaves (Merchant
et al., 2018) and the descriptors Blurred Shape Model (BSM) and
GLCM to extract shape and texture characteristics in coffee leaves im-
ages (Vassallo-Barco et al., 2017). Another study uses K-means Cluster-
ing based on texture characteristics with RGB values in the image
(Merchant et al., 2018). However, the resulting accuracy is still low
due to the limited features used (Yan et al., 2019). However, most
studies' feature combinations cannot always improve the accuracy
(Qur'ania et al., 2020). The classiﬁcation model using RGB color extrac-
tion produces 70.25% of accuracy, and Sobel edge detection produces
59.52% accuracy (Qur'ania et al., 2020). Nevertheless, the combination
of RGB and Sobel edge produces lower accuracy than RGB only. It is
about 65.36% of accuracy.
Deep learning, especially Convolutional Neural Network (CNN), is
becoming a popular classiﬁcation method today. However, the CNN
method uses an automatic feature extraction feature, so it is challenging
to analyze the effect of features combination on the results obtained
(Buzzy et al., 2020; Khew et al., 2021). In (Senan et al., 2020), the
study compares CNN with other machine learning such as ANN, MLP,
and SVM. CNN shows the best result because the convolutional layer
learns multi features such as color or texture images (Senan et al.,
2020). However, in (Watchareeruetai et al., 2018), CNN produces an
accuracy of less than 60% because the deﬁciency classes have similar
characteristics. In another study, (Wang et al., 2021a) performs data
augmentation until each class has the same amount of data. Deep
learning with an augmentation process increases the accuracy up
to 5% (Guerrero et al., 2021; Wang et al., 2021a; Myo Han and
Watchareeruetai, 2020). In (Jiang et al., 2020), the study compares the
results of processing with segmentation and without segmentation.
The result is that image segmentation shows better results than without
segmentation.
This study aims to classify six chili plant health conditions using the
combination of shape, texture, and color features. Chili in Indonesia is
usually grown in an uncontrolled lighting conditions. The use of one fea-
ture such as color has a great risk of identiﬁcation errors because of the
lighting condition. So, the proposed study varies several features for nutri-
ent deﬁciency identiﬁcation. A careful feature selection was carried out to
produce an accurate model that robust in the uncontrolled lighting condi-
tion. Some features considered are the leaves' color, shape, and texture.
Several other machine learning and deep learning methods, such as
MLP, SVM, Naive Bayes, RFT, and CNN were tested to compare the perfor-
mance models in our data. The contributions of this paper are as follows.
a. Perform features combination (color, texture, and shape of the chili
leaves image) that can be used to identify plant conditions.
b. Find a suitable MLP architecture based on the combination of these
three features.
c. The data used is in-House dataset.
2. Materials and methods
This study identiﬁed six chili plant conditions using digital image
processing based on single leaf image data. There are several stages
for identiﬁcation, namely image acquisition, segmentation, image aug-
mentation, feature extraction, and identiﬁcation tasks. Fig. 1 shows the
identiﬁcation workﬂow design.
2.1. Leaf data and nutrient status
The initial stage in the identiﬁcation process is the collection of
image data. The dataset used in this case was collected from the hydro-
ponics chili plant in Sleman, Special Region of Yogyakarta, Indonesia.
The hydroponics used is a Nutrient Film Technique (NFT) system. The
six plant health conditions observed were Healthy, Calcium, Magne-
sium, Sulfur, Magnesium-Sulfur, and multi-deﬁciency. The characteris-
tics of each plant's health condition are summarized in Table 1. The
initial condition of hydroponic plants is a healthy plant. The data collec-
tion scenario is described as follows:
a Some chili plants suitable to the criteria can grow and develop in an
NFT hydroponic system until six weeks after planting. All plants
have the same Health condition as shown on Fig. 2(g).
b This study combines nutrients using various single compound fertil-
izers according to the criteria for plant needs. Based on (Singh et al.,
2019), the need for chili plants in the juvenile phase is shown in
Table 2 and Table 3. The reduction of certain single compound fertil-
izers is calculated to obtain a nutrient solution with a certain macro-
nutrient deﬁciency.
c 7 selected plants were sampled in a hydroponic environment by
providing macronutrients based on certain levels. The level used in
this study consists of 5 levels. Each level is a dose reduction of mac-
ronutrient types by 10%, 30%, 50%, 70%, and 90%. The content of these
macronutrients is maintained for seven days to observe visible visual
characteristics properly.
d This study validated the data with agricultural experts to ascertain
the visual characteristics of the emerging leaves. If appropriate,
chili plant data is acquired.
e The leaf acquired is a single leaf sample that represent the plant's
condition.
Visual changes in the leaves are captured using the camera sensor
with HD 1080 resolution on a certain background. RGB image camera
works like the human eye which is sensitive to RGB light bands. A sam-
ple of six classes of data is shown in Fig. 2. The result is obtained many
data in speciﬁc classes as shown in Table 4, where AAug is data after
augmentation and BAug is data before augmentation.
2.2. Preprocessing, segmentation, and augmentation process
This study uses two types of preprocessing to improve image quality.
The ﬁrst is resizing the image to a size of 512 ⋅ 512. While the second is
to apply Histogram Equalization (HE) (Abdul et al., 2015). Image acqui-
sition takes place in a natural environment so that the lighting varies. HE
is applied to reduce the impact of lighting on the resulting image.
Eq. (1) and (2) are formula to do HE, where cdf is a normalization func-
tion. Then, intensity transformation of the input image rk to sk is where L
is the number of possible intensities and nrj is the number of pixels of
level rj.
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
78
cdf j
ð Þ ¼ ∑
k
j¼0
nrj
n
ð1Þ
sk ¼ T rk
ð
Þ ¼ round cdf rk
ð
Þ � L � 1
ð
Þ
ð
Þ
ð2Þ
Segmentation is the process of separating an object from the back-
ground. Histogram equalization results will be segmented to separate
objects from complex backgrounds using the thresholding method
(Vassallo-Barco et al., 2017). Thresholding is a segmentation method
based on certain pixel values. The HE results were converted to a LAB
color model in this study. LAB was chosen because it proved suitable
for primary colors, including leaf color. The lower threshold value
used is 122 and the upper limit is 245. The a∗ channel on the LAB is
used. Several morphological operations such as erosion and dilation
are used to cover some holes formed. The results of the morphological
operations are performed bitwisenot for the masking process of HE im-
ages and binary images.
Data augmentation is a process to multiply data (Guerrero et al.,
2021). In several studies, data augmentation has proven to improve
the model performance (Guerrero et al., 2021; Kuznichov et al., 2019).
The data is reproduced through speciﬁc modiﬁcation processes. In this
study, the data augmentation for the training set is executed by several
behaviors, namely rotation, shear, zoom, and brightness. Rotation was
Fig. 1. Stages of identiﬁcation of macronutrient deﬁciencies in chili plants.
Table 1
The visual characteristics of nutrient deﬁciency.
Plant Condition
Characteristics of the leaves
Color
Shape
Texture
Part of the plant
Healthy
Green
Ellipse
Smooth
Overall
(\\Ca)
Healthy Green
Misshapen
Curling leaf tip
Top
(\\Mg)
Necrosis (cell injury), interveinal chlorosis
Ellipse/ Misshapen
Smooth
Bottom
(\\S)
Turning brown on the edge of the leaf
Ellipse/ Misshapen
Smooth/ Curling leaf tip
Bottom
(-MgS)
Necrosis (cell injury), interveinal chlorosis, turning brown on the edge of the leaf
Ellipse/ Misshapen
Smooth/ Curling leaf tip
Bottom
(−Multi)
Multi characteristics
Ellipse/ Misshapen
Smooth/ Curling leaf tip
Top/Bottom
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
79
chosen because this model is expected to be used in real environments
with irregular leaf positions. In addition, shear and zoom are applied so
that the model can cope with the problem of different data acquisition
distances. The identiﬁcation system is designed to be applied to a real
environment, so the model must be able to overcome different lighting
problems. Therefore, data augmentation also considers brightness be-
havior. The augmentation data in this study uses Keras tools with a ro-
tational parameter range of 40, a shear range of 0.2, a zoom range of
0.2, and a brightness range of 0.5 to 1.5. Each data is augmented into 8
data. The image resolution was reduced to 500 × 500 pixels before the
augmentation process.
2.3. Feature extraction
The feature extraction helps retrieve information such as color, tex-
ture, shape, geometry, and others from the chili leave image. Some stud-
ies only analyze one feature, but other studies combine them. This study
compares two-color feature extraction methods using statistical value
of the RGB and HSV color models. The RGB and HSV leaf color features
are helpful features that have been widely used. Color model conversion
from RGB to HSV aims to limit the size and type of color space. Then, the
texture feature extraction methods compared are LBP and GLCM. The
shape feature extraction used is the value of Hu moments and statistical
characteristics of the centroid distance in the binary image. Table 5
shows the number of features for each method. The feature combination
cannot always improve the performance of the model. Therefore, the se-
lection of features combination must be conducted to obtain an accurate
classiﬁcation.
2.3.1. Color feature extraction
The HSV and RGB color spaces are robust for color extraction fea-
tures (Latte et al., 2017; Latte and Shidnal, 2016). They analyze the sta-
tistical characteristics such as mean, standard deviation, and skewness
on each channel in the color model as shown in Eq. (3)–(5). Where μ
is Mean, σ is Standard Deviation, Skewness is image dimension based
i-th pixel, M is the total number of j-th, and N is value of the j-th pixel
of the image at the i-th color channel. In (Qur'ania et al., 2020; Drdsh
et al., 2021), RGB produces a high accuracy. However, in (Latte et al.,
2017) HSV is robust for macronutrient identiﬁcation. Therefore, this
study looks for HSV or RGB feature extraction features that are suitable
for our chili plant data. This study extracted the red, green, and blue
color component of the RGB image and extracted hue, saturation, and
value of the HSV image.
μ ¼ 1
MN ∑
M
i¼1
∑
N
j¼1
Iij
� �
ð3Þ
σ ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
MN ∑
M
i¼1
∑
N
j¼1
Iij � μ
�
�2
2
s
ð4Þ
Skewness ¼
1
MN ∑
M
i¼1
∑
N
j¼1
Iij � μ
�
�3
�
�
=σ 3
 
!
ð5Þ
2.3.2. Texture feature extraction
The texture is a feature that can be used to identify macronutrient
deﬁciencies. In this study, the class that clearly shows the visual charac-
teristics of the textural features is Calcium. If the research only uses
color, then the class labelled Calcium will be challenging to identify be-
cause it has color characteristics that are very similar to healthy. In this
study, the texture feature extraction method uses two different
methods, namely GLCM and LBP. GLCM has been used for texture fea-
ture extraction in cases (Sabri et al., 2020; Tan et al., 2021) and give
good results. Meanwhile, LBP was tested in case (Kumar et al., 2020).
GLCM is obtained by calculating the probability of the adjacency re-
lationship between two pixels at a certain distance and angle orienta-
tion (Widodo et al., 2018). After obtaining the co-occurrence matrix,
the observed image's statistical characteristics can be calculated. GLCM
statistical features include Contrast, Correlation, ASM, IDM, and Entropy
for four angles (0∘, 45∘, 90∘, and 135∘) and one distance (1 pixel) as
shown in Eq. (6)–(10). Where GLCM(i,j) is the distribution of joint prob-
abilities of a pixel pair, one with gray level i and the other with gray level
j. The number of rows and columns of the GLCM matrix depends on the
gray level of an image. L is the number of gray levels used minus 1 for
computation. The gray level value (grayscale) of an image between 0
and 255. The symbols μi′, μj′, σi′, σj′ are means and standard deviations
of the marginal distributions associated with GLCM(i,j).
ASM ¼ ∑
L
i¼1
∑
L
j¼1
GLCM i, j
ð
Þ
ð
Þ2
ð6Þ
Contrast ¼ ∑
L
n¼1
n2
∑
ji � j
j¼n
GLCM i, j
ð
Þ
ð
Þ2
(
)
ð7Þ
IDM ¼ ∑
L
i¼1
∑
L
j¼1
GLCM i, j
ð
Þ
ð
Þ2
1 þ i � j
ð
Þ2
ð8Þ
Entropy ¼ ∑
L
i¼1
∑
L
j¼1
GLCM i, j
ð
Þ log GLCM i, j
ð
Þ
ð
Þ
ð
Þ
ð9Þ
Correlation ¼
∑
L
i¼1∑
L
j¼1 i; j
ð
Þ GLCM i; j
ð
Þ−μ0
iμ0
j
�
�
σ0
iσ0
j
; where
μ0
i ¼
X
L
i¼1
X
L
j¼1
i � GLCM i; j
ð
Þ;
μ0
j ¼
X
L
i¼1
X
L
j¼1
j � GLCM i; j
ð
Þ;
σ 0
i ¼
X
L
i¼1
X
L
j¼1
GLCM i; j
ð
Þ i−μ0
i
�
�2
σ 0
j ¼
X
L
i¼1
X
L
j¼1
GLCM i; j
ð
Þ j−μ0
i
�
�2
ð10Þ
LBP is a feature extraction method of binary images. In (Kumar et al.,
2020) proves that LBP can solve the problem of rotation on objects ac-
cording to the data used in this study. For the LBP, we selected the uni-
form pattern and set the value of bins to 10. Thus, this study extracted
Table 2
Chili plant nutritional requirements.
Compound
PPM
Compound
PPM
%N-NO3
180.0
%Cl
0.0
%N-NH4
7.2
%Fe
1.72
%P2O5
48.0
%B
0.23
%K2O
225.0
%Cu
0.37
%CaO
170.3
%Zn
0.38
%MgO
40.0
%Mn
0.34
%Na
0.0
%Mo
0.06
%SO3
32.5
Table 3
Amount of compound requirement for 10 Liters nutrient solution.
Substance name
Formula
Amount (grams)
Magnesium Sulfate
MgSO4, 7H2O
2.5
Calcium Nitrate
5Ca(NO3)2.NH4NO3.10H20
6.55
Potassium Nitrate
KNO3
5.22
Meroke VITAFLEX
Fe, Mn, Zn, Cu, B, Mo
0.23
Meroke MAP
N, P2O5
1.11
Meroke MKP
P2O5, K2O
0.82
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
80
ten texture features with the LBP method. The LBP intensity value is cal-
culated for such a speciﬁed center pixel gray color by comparing it to its
nearest neighbors, as seen in Eq. (11). Where gc corresponds to the
value of the center pixel, gp to the value of the eight surrounding
pixels, P is the total number of involved neighbors, R is the radius of
the neighborhood, and function f1(x).
LBPP;R ¼
X
p−1
p¼0
2p � f 1 gp − gc
�
�
;
where
f 1 x
ð Þ ¼
1;
x≥0
0;
else
�
ð11Þ
2.3.3. Shape feature extraction
There is a change in leaf shape in plants that lack macronutrients, es-
pecially leaf edges. Leaves can be more rounded or even irregular. This
study uses the moment to determine the centroid point of an object.
The centroid or the center moment of an object is (x′, y′) shown in
Eq. (12), where Mij is x and y coordinate of the i-th location cross the vol-
ume of goods moved to or from i-th location.
x′ ¼ M10
M00
,
y′ ¼ M01
M00
,
where :
Mij ¼ ∑
x ∑
y xiyjI x, y
ð
Þ
ð12Þ
However, this study presents two different approaches in processing
data from the centroid point, such as:
a. The centroid point is used to produce moment invariant. Using
moment
invariants,
feature
extraction
of
shape
produced
seven-moment invariant values that are not sensitive to translation,
scale change, and rotation (Kumar et al., 2020). The seven moment
invariant values are shown in Eq. (14)–(20). H1 is the ﬁrst moment
invariant, H2 is the second moment invariant, and others, where μij
in Eq. (13) is means value of distribution I(x,y).
μij ¼
X
x
X
y
ðx−x0
Þi y−y0
ð
ÞjI x; y
ð
Þ;
where :
ð13Þ
H1 ¼ μ20 þ μ02
ð14Þ
H2 ¼ μ20 � μ02
ð
Þ2 þ 4μ2
11
ð15Þ
H3 ¼ μ30 � 3μ12
ð
Þ2 þ 3 μ21 � μ03
ð
Þ2
ð16Þ
H4 ¼ μ30 þ μ12
ð
Þ2 þ μ21 þ μ03
ð
Þ2
ð17Þ
H5 ¼ μ30 � 3μ12
ð
Þ μ30 þ μ12
ð
Þ
ðμ30 þ μ12
Þ2 � 3 μ21 þ μ03
ð
Þ2
h
i
ð3μ21 � μ03
Þ μ21 þ μ03
ð
Þ 3 μ30 þ μ12
ð
Þ2 � μ21 þ μ03
ð
Þ2i
h
ð18Þ
H6 ¼ μ20 � μ02
ð
Þ
ðμ30 þ μ12
Þ2 � μ21 þ μ03
ð
Þ2i
þ 4μ11 μ30 þ 3μ12
ð
Þ μ21 þ μ03
ð
Þ
h
ð19Þ
H7 ¼ 3μ21 � μ03
ð
Þ μ30 þ μ12
ð
Þ
ðμ30 þ μ12
Þ2 � 3 μ21 þ μ03
ð
Þ2
h
i
�
ðμ30 � 3μ12
Þ μ21 þ μ03
ð
Þ
h
3 μ30 þ μ12
ð
Þ2 � μ21 þ μ03
ð
Þ2i
ð20Þ
Fig. 2. Sample chili plant leaf images condition, (a) Healthy, (b) Calcium, (c) Magnesium, (d) Sulfur, (e) Magnesium-Sulfur, (f) Multi-deﬁciency, (g) Hydroponics plant.
Table 4
Data used in this study.
Plant condition
Total data
Training data
Testing data
BAug
Aaug
Healthy (complete nutrient)
98
68
612
30
Calcium (\\Ca)
101
71
639
30
Magnesium (\\Mg)
100
70
630
30
Sulfur (\\S)
96
66
594
30
Magnesium-Sulfur (Mg\\S)
102
72
648
30
Multi deﬁciency (more than 2)
97
67
603
30
Table 5
The number of features.
Type of features
Method
Number of features
Color
HSV Color model
9
RGB Color model
9
Texture
Statistics feature of GLCM
24
Local Binary Pattern (LBP)
10
Shape
Hu moments
7
Distance of centroid
5
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
81
b. The distance between the centroid and each edge pixel is obtained
by calculating the Euclidean distance. Then, the distance is visual-
ized, and the statistical value is sought from the data for each dis-
tance to the centroid. The features obtained from this stage are
statistical features such as mean, min, max, median, and average.
2.4. Identiﬁcation model
To classify the six classes of chili plant condition, MLP architecture is
used. MLP is an artiﬁcial neural network that includes at least three
layers of neuron nodes, namely the input layer, the output layer and
one or more hidden layers. Except for the input neuron, each node
uses a different nonlinear activation than the linear perceptron. Fig. 3
shows the MLP architecture used.
The number of input neurons corresponds to the number of features
value used. This study looks for a suitable number of nodes and hidden
layers based on the three features combination. In the decision layer,
this study uses six nodes which represent six classes of plant health con-
ditions using One-hot encoding output representation. The rectiﬁed
linear unit (ReLU), is used as the activation function. In mathematical
form, Y = ϕ(wx + b), where w is the weight, x denotes as the vectors
of input, b is the value of bias and ϕ is the nonlinear activation.
This study uses the MLP architecture model in (Myo Han and
Watchareeruetai, 2020) against our data to analyze the combination
of three features. In (Myo Han and Watchareeruetai, 2020), the research
use two hidden layers with 2048 and 512 nodes. The suitable learning
rate is 0.002 with the Adam optimizer. After the best combination of
the three features is obtained, this study tries to ﬁnd the best MLP archi-
tecture based on our data. This study varies the number of hidden
layers, the number of nodes, the learning rate, and the epochs to pro-
duce an accurate model based on a combination of three features,
namely color, texture, and leaf shape.
This study also compares the best MLP architecture based on the
experiment with other previous work, such as Naive Bayes, RFT, and
SVM. Naive Bayes is used on (Vassallo-Barco et al., 2017) with cer-
tain parameters, and RFT is used (Sonobe et al., 2020). SVM effec-
tively solves local minima and high dimension problems (Sonobe
et al., 2020). SVM has several kernels, and (Xu et al., 2020) uses the
Gaussian Radial Basis Function (RBF) kernel. In this method, two
hyperparameters, the C regularization parameter and gamma value
Fig. 3. The multi layer perceptron architecture.
Fig. 4. Comparison of original image and Histogram Equalization result.
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
82
are set to generate a classiﬁcation model. For C, a high score may re-
sult in over-ﬁtting due to a high penalty for non-separable points,
whereas a low value may result in under-ﬁtting. The value deﬁnition
of the range of a single training instance of Kernel RBF ﬁts our data
with hyperparameter values of gamma of 0.0001, C of 100, and the
decision function shape using One vs One classiﬁer (OvO). OvO is
used as a multi-class strategy to train models. In addition, this
study also tries other SVM kernel such as the Linear kernel (Myo
Han and Watchareeruetai, 2020).
2.5. Performance measurement
The parameters used to measure the success of identifying macronu-
trient deﬁciencies in plants in this study were accuracy, precision, and
recall. The measurement of model performance accuracy is chosen to
determine the model's ability to detect all objects correctly. Precision
is chosen because several macronutrients exhibit very similar character-
istics that the system must distinguish between them. If the system
cannot tell the difference, the wrong solution can occur, causing the
plant to die. The recall refers to the ratio of correctly predicted positive
observations to all the actual class observations (Xu et al., 2020). The
equations used to calculate accuracy, sensitivity, and speciﬁcity are
shown in Eq. (21) − (23), where TP is the number of true positive, TN
is true negative, FP is false positive, and FN is false negative.
Accuracy ¼
TP þ TN
TP þ TN þ FP þ FN � 100%
ð21Þ
Precision ¼
TP
TP þ FP � 100%
ð22Þ
Recall ¼
TP
TP þ FN � 100%
ð23Þ
3. Result and discussion
Chili plant data were collected in natural environments, so the light-
ing condition varied. To ﬁx this problem, this study uses HE. Fig. 4 shows
the result of histogram equalization. To separate the object from back-
ground, the segmentation process is used. This research uses the
Fig. 5. Result of (a) segmentation, (b) data augmentation process.
Fig. 6. Histogram of each RGB and HSV color spaces in Calcium and Multi-deﬁciency data classes.
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
83
colorspace segmentation method on channel a* of the CIELAB image.
The approach is to choose a small sample region for each color and to
calculate each sample region's average color in a ∗ space. Based on ob-
servations, channel a ∗ can distinguish object information from the back-
ground well, with a range of 122 and 245. However, some noises such as
holes can be removed by applied the morphological operations. The re-
sult of segmentation is shown in Fig. 5(a). In addition, to increase the
model's accuracy, the augmentation process is applied with the results
shown by Fig. 5(b).
This study performs a combination of colors, shapes, and textures.
For color feature, statistical feature of HSV and RGB are compared.
RGB was chosen because research (Qur'ania et al., 2020) is the feature
that produces the best performance, while HSV was chosen because in
other studies, it can produce the best performance as well. HSV has
more complex components to represent object features in more detail.
Fig. 6 shows the different characteristics of the two classes. In the
green channel of RGB, the Calcium class shows a frequency range from
[0, 1400] for intensity level 25 to 185, while unhealthy leaves in the fre-
quency range [0, 1350] for intensity level [10, 135]. In the V channel of
the HSV histogram, the peak value for the intensity of the highest fre-
quency of Calcium and Multi-deﬁciency is around 3000.
This study compares the GLCM and LBP methods for texture feature
extraction, while the Hu moments value and the edge distance to the
centroid for shape feature extraction. GLCM is a second-order feature
extraction where the matrix describes the neighbor relationship be-
tween pixels in an image in various directions and local distances. The
relationship between class and one of the GLCM features can be seen
in Fig. 7. Meanwhile, LBP is a texture extraction feature that is consid-
ered invariant to lighting and rotation. The Hu moments value for
shape feature extraction consists of seven values that identify the char-
acteristics of a digital image object. These values are independent of
translation, rotation, and scaling. At the same time, the other shape ex-
traction feature used is the statistical feature of each edge pixel distance
to the centroid. It refers to the visual characteristics of chili leaves that
have wavy edges if there is a lack of macronutrient Calcium, multi-
deﬁciency, and others. Therefore, the distance of each leaf edge pixel
to the centroid is considered capable of representing the shape features
of the leaf. Fig. 8 shows the effect of the pixel distance from the edge to
the centroid in different classes. According to Fig. 8 below, healthy ex-
hibits a visual feature that is not smooth/tortuous. This study applies
to resizing pixel data into 100 ⋅ 100, so that the distance of each edge
pixel point looks far. It causes the visualization to be noisier, coupled
with the elliptical leaf shape and tends to be round. Meanwhile, the cal-
cium data shows less noise because the leaf shape is not round.
There are four experimental in this study. The ﬁrst experiment com-
pares each feature's performance against six chili health condition data
classes. The second is the comparison of the feature combination perfor-
mance. The third experiment compares several MLP hyperparameters
against the combination of the three best features obtained from the
previous experiment. While the fourth experiment is a comparison of
the results of the third experiment with several previous studies.
3.1. Comparison of single feature performance
Before combining features, this study analyzes the abilities of each
feature. The MLP architecture in (Myo Han and Watchareeruetai,
2020) is used to determine the features' performance. In addition, this
study also analyzes the effect of the data augmentation stage in the re-
sulting identiﬁcation model. A summary of experiments related to the
capabilities of each feature is shown in Table 6.
There are three types of features analyzed: color, texture, and shape
features. This study compares the statistical characteristics of RGB and
HSV images for color, LBP and GLCM features for textures, and statistical
characteristics of the edge pixel distance to centroid and Hu moments
for shape characteristics. For color characteristics, the results are in ac-
cordance with (Qur'ania et al., 2020) that RGB data in this study produce
higher accuracy, precision, and recall values than HSV with an accuracy
of 66.28% compared to HSV, which is 49.56%. GLCM produces higher
performance than LBP for texture characteristics, which is 50.74%. It is
because of LBP describes the texture locally. As for the shape character-
istics, statistical characteristics from the edge pixel distance to the cen-
troid resulted in a higher performance of 41.43%.
Furthermore, this study analyzes the augmentation stage's effect on
each resulting feature's performance. The result is that augmentation on
crop images can increase accuracy by more than 10%, such as RGB fea-
tures, from 66.28% to 80.00%. This result corresponds with the research
(Guerrero et al., 2021; Wang et al., 2021a). After augmentation, RGB
and GLCM feature performance remains higher than HSV and LBP. How-
ever, different results were obtained on the shape characteristics. The fea-
tures of Hu moments obtained higher results than the statistical
characteristics of the edge pixel distance data set to the centroid. After
the augmentation process, features that produce more than 60% accuracy
on augmented data are used on a combination of two and three features.
3.2. Comparison of feature combination
The second experiment is to combine different features. The architec-
ture used is MLP by (Myo Han and Watchareeruetai, 2020), same as the
previous experiment. Table 7 shows the results of these combinations.
This study performs a combination of two features and three fea-
tures. A combination of two features is applied to the data before
Fig. 7. An example of data visualization in GLCM features.
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
84
augmentation with a combination of color+texture, color + shape, and
texture + shape. The combination of RGB color and GLCM texture pro-
duces the highest accuracy, which is 76.13%, compared to the combina-
tion of the other two characteristics. In the combination of three
features experiment, RGB, GLCM, and Hu moments produces the higher
accuracy than combination of RGB, GLCM, and distance of centroid. This
is not in line with the results of previous combinations where the dis-
tance of centroid results a higher accuracy than Hu moments feature.
In addition, this study also did a combination of 3 features by combining
the distance of centroid feature and Hu moments feature. The result was
beyond our expectations where the combination accuracy is greater,
which is 84.77%.
This study also tries to compare the results of the combination of
three data features without augmentation and with augmentation.
The result is that data with augmentation yields higher accuracy, ac-
cording to the previous experiments. The results of the augmentation
of the three-feature combination data produce accuracy that is not
much different. The combination of RGB, GLCM, and Hu moments pro-
duces an accuracy of 86.35%, while RGB, GLCM, and distance of centroid
produces an accuracy of 86.21%. But, the combination of RGB, GLCM, Hu,
and distance of centroid produced the highest accuracy, which is
87.47%. Because of this, we decided to use this combination in the
next experiment.
3.3. Comparison of MLP hyperparameter
This study tries to compare the combination of MLP hyper-
parameters, such as the number of learning rates and epochs. The
number of hidden layers used is three. Based on previous experiments
Fig. 8. The distance between edge pixels to the centroid visualization of: (a) Healthy and (b) Ca.
Table 6
The performance of single feature with augmentation and without augmentation.
Feature
No.
Method
Total
Accuracy
(%)
Precision
(%)
Recall
(%)
noAug
Color
1
RGB
9
66.28
69.83
65.04
2
HSV
9
49.56
51.13
49.33
Texture
3
LBP
10
40.85
43.36
40.45
4
GLCM
24
50.74
55.43
50.25
Shape
5
Distance of
centroid
5
41.43
54.29
37.68
6
Hu moments
7
34.84
33.93
33.42
Aug
Color
7
RGB
9
80.00
81.08
81.86
8
HSV
9
71.57
72.52
71.35
Texture
9
LBP
10
54.83
58.66
56.36
10
GLCM
24
61.38
64.77
63.25
Shape
11
Distance of
centroid
5
66.21
64.32
68.14
12
Hu moments
7
70.53
69.44
71.09
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
85
as shown on Table 8, the number of nodes are 2048, 1024, and 512. The
result of hyperparameter shows on Table 9.
The third experiment was carried out by varying the learning rate
value from 2 to 0.0001 with a ﬁxed epoch value of 200. The value of
0.0001 was chosen because the resulting performance trend decreased
at that value. Based on the experimental results, the highest perfor-
mance was produced by a learning rate of 0.002, with each accuracy,
precision, and recall value of 89.70%, 90.62%, and 89.17%. In comparison,
the lowest performance is generated by the learning rate with a value of
2. In training using the Adam optimizer, the learning rate value regu-
lates the number of updates made to the weight value of w. If the learn-
ing rate value is decrease, the error function will decrease. However, a
learning rate that is too small can cause the performance of training
model decreases, as shown by the experiment. After obtaining the ap-
propriate learning rate, this study also looks for the appropriate epoch
value based on the previous MLP architecture. The epoch value varied
from 100 to 400. The epochs value stopped varying at 400 because
the performance trend had declined at that number. Based on the
experimental results, the highest model performance is produced by
the MLP architecture with an epoch value of 300. The resulting accuracy,
precision, and recall values are 89.70%, 90.62%, and 89.17%, respectively.
The greater the iteration value, the more learning is generated. How-
ever, an epoch value that is too large can result in an overﬁtting
model. Therefore, the correct learning rate and epoch values must be
obtained so that the resulting model performs well.
3.4. Comparison of the MLP in this study with previous study
In the fourth experiment, this study compares the combination of
three features with several types of classiﬁers. For the MLP method, this
study compares the architecture in (Myo Han and Watchareeruetai,
2020) in the existing data with the best MLP architecture based on this
study. The MLP architecture in this study uses three hidden layers with
2048, 1024, and 512 nodes respectively and an output layer with three
nodes. The architecture uses Rectiﬁed Linear Unit (ReLU) as an activation
function and 300 for epochs. This study uses the cross-entropy category as
a loss function because the problem is multi-classiﬁcation. The study uses
Adam as solver (Shi et al., 2019), with a learning rate of 0.002. The result is
that the (Myo Han and Watchareeruetai, 2020) architecture produces a
relatively high accuracy of 87.47%, but the MLP architecture in this
study produces a greater accuracy of 89.18%. In addition, this study com-
pares two SVM kernels: the RBF kernel and the linear kernel. Where C is 1
and gamma is 1, the linear kernel can produce an accuracy of 90.55%. In
Table 7
The performance of feature combination with augmentation and without augmentation.
Feature
No.
Method
Total
Accuracy(%)
Precision(%)
Recall(%)
noAug
Color+Texture
1
RGB + GLCM
33
76.13
75.42
73.21
2
HSV + GLCM
33
72.38
76.10
68.36
Color+Shape
3
RGB + Hu
16
68.87
72.53
71.33
4
RGB + Distance of centroid
14
70.29
70.00
70.18
Texture+Shape
5
GLCM + Hu
31
57.73
51.88
60.25
6
GLCM + Distance of centroid
29
63.12
67.35
65.23
Color+Texture+Shape
7
RGB + GLCM + Hu
40
83.27
83.14
81.32
8
RGB + GLCM + Centroid
38
78.26
72.63
77.32
9
HSV + GLCM + Hu
40
74.14
68.39
71.43
10
HSV + GLCM + Centroid
38
78.26
72.63
77.32
11
RGB + GLCM + Hu + Centroid
45
84.77
85.21
84.62
Aug
Color+Texture
1
RGB + GLCM
33
80.04
85.48
82.36
2
HSV + GLCM
33
80.75
82.84
81.28
Color+Shape
3
RGB + Hu
16
82.73
83.13
83.87
4
RGB + Distance of centroid
14
77.85
78.05
76.57
3
HSV + Hu
16
65.80
70.64
65.76
4
HSV + Distance of centroid
14
70.65
69.93
70.23
Texture+Shape
5
GLCM + Hu
31
62.46
66.25
64.81
6
GLCM + Distance of centroid
29
70.58
71.66
70.41
Color+Texture+Shape
7
RGB + GLCM + Hu
40
86.35
88.14
86.52
8
RGB + GLCM + Centroid
38
86.21
87.67
84.93
9
RGB + GLCM + Hu + Centroid
40
87.47
88.93
87.16
Table 8
The number of hidden layer and node experiment.
HL1
HL2
HL3
Accuracy(%)
Precision(%)
Recall(%)
4096
–
–
85.50
85.93
86.11
2048
–
–
83.74
84.97
84.64
1024
–
–
81.43
83.88
82.32
512
–
–
80.87
82.62
81.04
256
–
–
80.25
82.19
80.83
128
–
–
73.73
77.10
74.48
4096
4096
–
82.17
84.62
83.86
2048
2048
–
86.58
87.37
87.97
2048
1024
–
84.94
86.80
84.54
2048
512
–
84.32
85.75
85.39
2048
256
–
84.83
85.45
84.61
2048
128
–
79.27
81.49
80.55
2048
2048
2048
78.48
80.33
78.18
2048
2048
1024
86.26
87.40
86.62
2048
2048
512
85.60
86.81
85.28
2048
2048
256
84.78
84.43
84.20
2048
1024
1024
85.52
87.26
85.29
2048
1024
512
87.42
88.70
87.98
2048
1024
256
85.14
87.21
85.37
2048
512
512
86.08
87.37
86.24
2048
512
256
82.84
84.49
83.63
2048
256
256
85.15
86.72
85.46
2048
256
128
80.71
84.06
82.58
Table 9
Tuning hyperparameter in MLP architecture.
LR
Epochs
Accuracy(%)
Precision(%)
Recall(%)
2
200
20.72
23.12
17.20
2
200
21.13
18.10
17.47
0.1
200
33.25
20.54
27.65
0.05
200
35.81
33.26
34.16
0.001
200
86.74
88.86
86.93
0.002
200
87.91
88.12
88.33
0.003
200
82.26
84.57
83.10
0.005
200
81.72
84.13
83.27
0.0001
200
77.83
82.80
76.54
0.002
100
86.11
88.45
87.32
0.002
250
87.34
88.39
87.76
0.002
300
89.70
90.62
89.17
0.002
350
87.25
88.14
87.32
0.002
400
85.85
86.77
85.81
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
86
contrast, the RBF kernel requires parameter tuning with a signiﬁcant
value to produce high accuracy, 100 for C and the gamma value of
0.001. The linear kernel separates the data based on a ﬁrm line. Then,
SVM can handle non-linear data based on the kernel. This is in accordance
with the results of experiments in research (N and Saju, 2018). Besides
MLP and SVM, this study also tries to compare other classiﬁers, such as
Naive Bayes and RFT, but their accuracy is not higher than SVM and
MLP. This study also compares machine learning methods with CNN
(Cevallos et al., 2020). CNN produces the highest accuracy, which is
equal to 97.76%. However, CNN has a higher complexity than MLP. The
confusion matrix of the proposed MLP architecture and linear SVM kernel
is shown in Fig. 9(a) and Fig. 9(b). While the training and validation
graphs from CNN are shown in the Fig. 10. The performance comparison
shown on Table 10.
The highest overall accuracy is generated by the CNN method, while
the second is the SVM linear kernel, and the third is MLP. SVM produces
higher accuracy in detecting Mg, S, Mg\\S, and Multi-deﬁciency classes.
However, the MLP architecture in this study yielded higher precision for
Healthy and Ca classes. Example of testing data against to the proposed
method show on Fig. 11. Even though it is lower, the training time re-
quired for MLP is relatively less compared to CNN and SVM linear ker-
nel. It is caused by optimize the C regularization and parameter which
means that performing a grid search will usually take more time in SVM.
Several cases cannot be adequately identiﬁed in the macronutrient
deﬁciency identiﬁcation system. The ﬁrst is healthy, Calcium, and Sulfur.
For Calcium, the lack of macronutrient at low levels only gave a slight
impact in the form of differences in texture, while sulfur at low levels
Fig. 9. Confusion matrix of nutrient deﬁciency identiﬁcation using The MLP and SVM.
Fig. 10. CNN result.
Table 10
Comparison of accuracy, precision, and recall with a previous work.
Feature
Method
Accuracy
(%)
Precision
(%)
Recall
(%)
RGB + GLCM + Hu moments+
Distance of centroid
MLP [26]
87.47
88.93
87.16
MLP (Results of
this study)
89.70
90.62
89.17
SVM (Linear
kernel) [26]
90.55
90.34
89.90
SVM (RBF
kernel) [50]
82.37
84.58
83.82
Naive Bayes [44]
70.66
68.72
70.16
RFT [36]
63.25
64.33
64.65
Automatic feature extraction
CNN [4]
97.76
93.21
96.95
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
87
only gave a black color change at the base of the leaves. Therefore, even
though a combination of 3 characteristics has been carried out, the de-
veloped model can still give incorrect identiﬁcation results. In addition,
there are conditions of overlapping characteristics such as Mg, S, and
Mg\\S. So, the identiﬁcation model cannot recognize them correctly
in certain cases, especially if the Mg\\S is still at a low level.
4. Conclusion
Determining nutrient deﬁciencies in chili plants can be done using
machine learning and deep learning approaches. This study compares
the combination of several features. The combination of the leaves
color, texture, and shape has been proven to increase the model's accu-
racy. The best feature combination is generated by RGB, GLCM, Hu, and
distance of centroid. The features combined in the augmented data re-
sults produce the best performance using a 0.002 of learning rate and
300 epochs with 89.70% of accuracy. This study compares the MLP ar-
chitecture with several machine learning in the previous study. The re-
sult is that SVM produces the best performance with 90.55% of accuracy.
Although SVM linear kernel produces higher accuracy than MLP, MLP in
this study still has a high success rate. So it can be concluded that the
two models can be recommended to identify plant health conditions.
MLP in this study proved to be better at identifying plant conditions in
the form of Calcium and Sulfur than linear SVM kernels. In addition,
augmented data has been shown to improve accuracy by more than
3%. In addition, this study also compares machine learning with deep
learning, such as CNN. CNN is proven to produce higher performance
compared to machine learning. However, CNN has a high complexity
compared to ordinary machine learning. The model for identifying
plant health conditions can be applied to the agricultural environment.
One example is the intelligent hydroponic farming system. In addition
to monitoring and controlling agricultural environmental conditions,
farmers can also embed our model to monitor plant health regularly
and provide nutrient solutions based on plant conditions. To support
precision agriculture, we will focus on a model that can identify the
type of macronutrient deﬁciency and estimate the percentage of deﬁ-
ciency in the future.
CRediT authorship contribution statement
Deffa Rahadiyan: Conceptualization, Methodology, Software,
Validation, Formal analysis, Investigation, Writing – original draft, Writing
– review & editing, Visualization. Sri Hartati: Conceptualization, Method-
ology, Validation, Writing – review & editing, Formal analysis, Investiga-
tion, Visualization, Supervision, Project administration. Wahyono:
Conceptualization, Methodology, Validation, Writing – review & editing,
Visualization, Project administration. Andri Prima Nugroho: Conceptuali-
zation, Methodology, Validation, Writing – review & editing, Visualization.
Fig. 11. Examples of some test data results against proposed models.
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
88
Declaration of Competing Interest
The authors declare that they have no known competing ﬁnancial
interests or personal relationships that could have appeared to inﬂu-
ence the work reported in this paper.
Acknowledgements
This research was funded by the Directorate of Research and Com-
munity Service, Deputy for Strengthening Research and Development,
Ministry of Research, Technology/National Research and Innovation
Agency of the Republic of Indonesia in the PMDSU program with grant
ID 018/E5/PG.02.00. PT/2022 and 1773/UN1/DITLIT/Dit -Lit/PT.01.03/
2022.
References
Abdul, M., Radhi, H., Musa, A., Al-Hsniue, O., 2015. Enhancement of the captured images
under different lighting conditions using histogram equalization method. Intern.
J. Latest Res. Sci. Technol. ISSN 3, 25–28.
Bahtiar, A.R., Pranowo Santoso, A.J., Juhariah, J., 2020. Deep learning detected nutrient de-
ﬁciency in chili plant. 2020 8th International Conference on Information and Commu-
nication Technology (ICoICT), pp. 1–4. https://doi.org/10.1109/ICoICT49345.2020.
9166224.
Buzzy, M., Thesma, V., Davoodi, M., Velni, J.M., 2020. Real-time plant leaf counting using
deep object detection networks. Sensors (Switzerland) 20, 1–14. https://doi.org/10.
3390/s20236896.
Cevallos, C., Ponce, H., Moya-Albor, E., Brieva, J., 2020. Vision-based analysis on leaves of
tomato crops for classifying nutrient deﬁciency using convolutional neural networks.
2020 International Joint Conference on Neural Networks (IJCNN), pp. 1–7. https://doi.
org/10.1109/IJCNN48605.2020.9207615.
Chen, Z., Wang, X., 2019. Model for estimation of total nitrogen content in sandalwood
leaves based on nonlinear mixed effects and dummy variables using multispectral
images. Chemom. Intell. Lab. Syst. 195, 103874. https://doi.org/10.1016/j.chemolab.
2019.103874.
daSilva, M.P.S., Mendonc Freitas, M.S., CesarSantos, P., de Carvalho, A.J.C., Jorge, T.S., 2019.
Capsicum annuum var. annuum under macronutrients and boron deﬁciencies: leaf
content and visual symptoms. J. Plant Nutr. 42, 417–427. https://doi.org/10.1080/
01904167.2018.1544255.
Drdsh, J., Eleyan, D., Eleyan, A., 2021. A prediction olive diseases using machine learning
models, decision tree and Naïve Bayes models. J. Theor. Appl. Inf. Technol. 99,
4231–4240.
Guerrero, R., Renteros, B., Castañeda, R., Villanueva, A., Belupú, I., 2021. Detection of nutri-
ent deﬁciencies in banana plants using deep learning. 2021 IEEE International Confer-
ence on Automation/XXIV Congress of the Chilean Association of Automatic Control
(ICA-ACCA), pp. 1–7. https://doi.org/10.1109/ICAACCA51523.2021.9465311.
Halim, N.H.N.A., Husin, Z.H., Qadir, T.O., 2021. Brown spot disease severity level detection
using binary-RGB image masking. (IJACSA). Int. J. Adv. Comput. Sci. Appl. 12,
548–553. https://doi.org/10.14569/IJACSA.2021.0120962.
Harjoko, A., Prahara, A., Supardi, T.W., Candradewi, I., Pulungan, R., Hartati, S., 2019. Image
processing approach for grading tobacco leaf based on color and quality. Intern.
J. Smart Sens. Intell. Syst. 12, 1–10. https://doi.org/10.21307/ijssis-2019-010.
Jeyalakshmi, S., Radha, R., 2017. A review on diagnosis of nutrient deﬁciency symptoms in
plant leaf image using digital image processing. ICTACT J. Image Video Proces. 7,
1515–1524. https://doi.org/10.21917/ijivp.2017.0216.
Jiang, F., Lu, Y., Chen, Y., Cai, D., Li, G., 2020. Image recognition of four rice leaf diseases
based on deep learning and support vector machine. Comput. Electron. Agric. 179,
105824. https://doi.org/10.1016/j.compag.2020.105824.
Jose, A., Nandagopalan, S., Ubalanka, V., Viswanath, D., 2021. Detection and classiﬁcation
of nutrient deﬁciencies in plants using machine learning. J. Phys. Conf. Ser. 1850,
012050. https://doi.org/10.1088/1742-6596/1850/1/012050.
Kamelia, L., Rahman, T.K.B.A., Saragih, H., Haerani, R., 2020. The comprehensive review on
detection of macro nutrients deﬁciency in plants based on the image processing tech-
nique. Proceedings - 2020 6th International Conference on Wireless and Telematics,
ICWT 2020, pp. 7–10. https://doi.org/10.1109/ICWT50448.2020.9243623.
Khew, C.Y., Teow, Y.Q., Lau, E.T., Hwang, S.S., Bong, C.H., Lee, N.K., 2021. Evaluation of deep
learning for image-based black pepper disease and nutrient deﬁciency classiﬁcation.
2021 2nd International Conference on Artiﬁcial Intelligence and Data Sciences
(AiDAS), pp. 1–6. https://doi.org/10.1109/AiDAS53897.2021.9574346.
Kumar, A., Patidar, V., Khazanachi, D., Saini, P., 2015. An approach to improve classiﬁca-
tion accuracy of leaf images using dorsal and ventral features. Int. J. Adv. Comput.
Sci. Appl. 6. https://doi.org/10.14569/ijacsa.2015.060917.
Kumar, S., A.G.T, Sreekumar, K., 2020. Classiﬁcation of rice leaf spot disease using local bi-
nary patterns. Intern. J. Innov. Technol. Expl. Eng. 9, 510–512. https://doi.org/10.
35940/ijitee.f3866.049620.
Kumar, S., Jain, A., Shukla, A.P., Singh, S., Raja, R., Rani, S., Harshitha, G., Alzain, M.A.,
Masud, M., 2021. A comparative analysis of machine learning algorithms for detec-
tion of organic and nonorganic cotton diseases. Math. Probl. Eng. 2021. https://doi.
org/10.1155/2021/1790171.
Kuznichov, D., Zvirin, A., Honen, Y., Kimmel, R., 2019. Data augmentation for leaf segmen-
tation and counting tasks in rosette plants. IEEE/CVF Conference on Computer Vision
and Pattern Recognition Workshops (CVPRW), Long Beach, CA, USA, 2019, pp. 2580-
2589, doi: 10.1109/CVPRW.2019.00314.
Latte, M.V., Shidnal, S., 2016. Multiple nutrient deﬁciency detection in paddy leaf images
using color and pattern analysis. International Conference on Communication and
Signal Processing, ICCSP 2016, pp. 1247–1250. https://doi.org/10.1109/ICCSP.2016.
7754352.
Latte, M.V., Shidnal, S., Anami, B.S., 2017. Rule based approach to determine nutrient de-
ﬁciency in Paddy leaf images. Intern. J. Agric. Technol. 13, 227–245.
Lewis, K.P., Espineli, J.D., 2020. Classiﬁcation and detection of nutritional deﬁciencies in
coffee plants using image processing and convolutional neural network (Cnn). Int.
J. Sci. Technol. Res. 9, 2076–2081.
Lukic, M., Tuba, E., Tuba, M., 2017. Leaf recognition algorithm using support vector ma-
chine with Hu moments and local binary patterns. SAMI 2017 - IEEE 15th Interna-
tional Symposium on Applied Machine Intelligence and Informatics, Proceedings,
pp. 485–490. https://doi.org/10.1109/SAMI.2017.7880358.
Mashumah, S., Rivai, M., Irfansyah, A.N., 2018. Nutrient Film Technique based Hydroponic
System Using Fuzzy Logic Control. Proceeding – 2018 International Seminar on Intel-
ligent Technology and Its Application. 2018. ISITIA, pp. 387–390. https://doi.org/10.
1109/ISITIA.2018.8711201.
Merchant, M., Paradkar, V., Khanna, M., Gokhale, S., 2018. Mango Leaf Deﬁciency Detec-
tion Using Digital Image Processing and Machine Learning. 2018 3rd International
Conference for Convergence in Technology, I2CT 2018. pp. 1–3. https://doi.org/10.
1109/I2CT.2018.8529755.
Myo Han, K.A., Watchareeruetai, U., 2020. Black gram plant nutrient deﬁciency classiﬁca-
tion in combined images using convolutional neural network. 2020 8th International
Electrical Engineering Congress, iEECON 2020. https://doi.org/10.1109/iEECON48109.
2020.229562.
N, L, Saju, K.K., 2018. Classiﬁcation of macronutrient deﬁciencies in maize plant using ma-
chine learning. Intern. J. Elect. Comput. Eng. (IJECE) 8, 4197–4203. https://doi.org/10.
11591/ijece.v8i6.pp4197-4203.
Qur’ania, A., Harsani, P., Triastinurmiatiningsih, T., Wulandhari, L.A., Gunawan, A.A.S.,
2020. Color extraction and edge detection of nutrient deﬁciencies in cucumber leaves
using artiﬁcial neural networks. CommIT (Commun. Inform. Technol.) J. 14, 23.
https://doi.org/10.21512/commit.v14i1.5952.
Rahadiyan, D., Hartati, S., Wahyono, Nugroho, A.P, 2022a. An overview of identiﬁcation
and estimation nutrient on plant leaves image using machine learning. J. Theor.
Appl. Inf. Technol. 100.
Rahadiyan, D., Hartati, S., Wahyono, Nugroho, A.P, 2022b. Design of an intelligent hydro-
ponics system to identify macronutrient deﬁciencies in chili. Int. J. Adv. Comput. Sci.
Appl. 13. https://doi.org/10.14569/IJACSA.2022.0130117.
Sabri, N., Kassim, N.S., Ibrahim, S., Roslan, R., Mangshor, N.N.A., Ibrahim, Z., 2020. Nutrient
deﬁciency detection in maize (Zea mays L.) leaves using image processing. IAES In-
tern. J. Artif. Intell. 9, 304–309. https://doi.org/10.11591/ijai.v9.i2.pp304-309.
Senan, N., Aamir, M., Ibrahim, R., Taujuddin, N.S., Muda, W.H., 2020. An efﬁcient
convolutional neural network for paddy leaf disease and pest classiﬁcation. Int.
J. Adv. Comput. Sci. Appl. 11, 116–122. https://doi.org/10.14569/IJACSA.2020.
0110716.
Shah, A., Gupta, P., Ajgar, Y.M., 2018. Macro-Nutrient Deﬁciency Identiﬁcation in Plants
Using Image Processing and Machine Learning. 2018 3rd International Conference
for Convergence in Technology, I2CT 2018, pp. 1–4. https://doi.org/10.1109/I2CT.
2018.8529789.
Shi, J., Wang, Y., Li, Z., Huang, X., Shen, T., Zou, X., 2021. Characterization of invisible symp-
toms caused by early phosphorus deﬁciency in cucumber plants using near-infrared
hyperspectral imaging technology. Spectrochim. Acta A Mol. Biomol. Spectrosc.,
120540. https://doi.org/10.1016/j.saa.2021.120540.
Shi, W., van de Zedde, R., Jiang, H., Kootstra, G., 2019. Plant-part segmentation using deep
learning and multi-view vision. Biosyst. Eng. 187, 81–95. https://doi.org/10.1016/j.
biosystemseng.2019.08.014.
Siedliska, A., Baranowski, P., Pastuszka-Woźniak, J., Zubik, M., Krzyszczak, J., 2021. Identi-
ﬁcation of plant leaf phosphorus content at different growth stages based on
hyperspectral reﬂectance. BMC Plant Biol. 21, 1–17. https://doi.org/10.1186/s12870-
020-02807-4.
Singh, H., Dunn, B.L., Payton, M., Brandenberger, L., 2019. Selection of fertilizer and culti-
var of sweet pepper and eggplant for hydroponic production. agronomy 433, 1–11.
https://doi.org/10.3390/rs12193265.
Sinha, A., Shekhawat, R.S., 2020. Olive spot disease detection and classiﬁcation using anal-
ysis of leaf image textures. Proc. Comp. Sci. 167, 2328–2336. https://doi.org/10.1016/
j.procs.2020.03.285.
Sonobe, R., Yamashita, H., Mihara, H., Morita, A., Ikka, T., 2020. Estimation of leaf chloro-
phyll a, b and carotenoid contents and their ratios using hyperspectral reﬂectance.
Remote Sens. 12, 1–19. https://doi.org/10.3390/agronomy9080433.
Sosa, J., Ramírez, J., Vives, L., Kemper, G., 2019. An algorithm for detection of nutritional
deﬁciencies from digital images of coffee leaves based on descriptors and neural net-
works. 2019 22nd Symposium on Image, Signal Processing and Artiﬁcial Vision,
STSIVA 2019 - Conference Proceedings, pp. 3–7. https://doi.org/10.1109/STSIVA.
2019.8730286.
Tan, L., Lu, J., Jiang, H., 2021. Tomato leaf diseases classiﬁcation based on leaf images: a
comparison between classical machine learning and deep learning methods.
AgriEngineering 3, 542–558. https://doi.org/10.3390/agriengineering3030035.
Taujuddin, N.S., Mazlan, A.I., Ibrahim, R., Sari, S., Ghani, A.R., Senan, N., Muda, W.H., 2020.
Detection of plant disease on leaves using blobs detection and statistical analysis. Int.
J. Adv. Comput. Sci. Appl. 11, 407–411. https://doi.org/10.14569/IJACSA.2020.
0110852.
Tran, T.T., Choi, J.W., Le, T.T.H., Kim, J.W., 2019. A comparative study of deep CNN in fore-
casting and classifying the macronutrient deﬁciencies on development of tomato
plant. Appl. Sci. (Switzerl.) 9. https://doi.org/10.3390/app9081601.
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
89
Vassallo-Barco, M., Vives-Garnique, L., Tuesta-Monteza, V., Mejía-Cabrera, H.I., Toledo,
R.Y., 2017. Automatic detection of nutritional deﬁciencies in coffee tree leaves
through shape and texture descriptors. J. Digit. Inf. Manag. 15, 7–18.
Wang, C., Ye, Y., Tian, Y., Yu, Z., 2021a. Classiﬁcation of nutrient deﬁciency in rice based on
CNN model with Reinforcement Learning augmentation. Proceedings - 2021 Interna-
tional Symposium on Artiﬁcial Intelligence and its Application on Media. 2021.
ISAIAM, pp. 107–111. https://doi.org/10.1109/ISAIAM53259.2021.00029.
Wang, Q., Mao, X., Jiang, X., Pei, D., Shao, X., 2021b. Digital image processing technology
under backpropagation neural network and KMeans clustering algorithm on nitrogen
utilization rate of Chinese cabbages. PLoS One 16, 1–24. https://doi.org/10.1371/jour-
nal.pone.0248923.
Watchareeruetai, U., Noinongyao, P., Wattanapaiboonsuk, C., Khantiviriya, P., Duangsrisai,
S., 2018. Identiﬁcation of plant nutrient deﬁciencies using ConvolutionalNeuralNetworks.
iEECON 2018-6th International Electrical Engineering Congress, pp. 2018–2021. https://
doi.org/10.1109/IEECON.2018.8712217.
Widodo, R., Widodo, A.W., Supriyanto, A., 2018. Pemanfaatan Ciri Gray Level Co-
Occurrence Matrix (GLCM) Citra Buah Jeruk Keprok (Citrus reticulata Blanco)
untuk Klasiﬁkasi Mutu. J. Pengemb. Teknol. Inform. Ilmu Komput. 2, 5769–5776.
Wulandhari, L.A., Gunawan, A.A.S., Qurania, A., Harsani, P., Triastinurmiatiningsih,
Tarawan, Hermawan, R.F., 2019. Plant nutrient deﬁciency detection using deep
convolutional neural network. ICIC Expr. Lett. 13, 971–977. https://doi.org/10.
24507/icicel.13.10.971.
Xu, Z., Guo, X., Zhu, A., He, X., Zhao, X., Han, Y., Subedi, R., 2020. Using deep convolutional
neural networks for image-based diagnosis of nutrient deﬁciencies in rice. Comput.
Intell. Neurosci. https://doi.org/10.1155/2020/7307252.
Yan, X., Wen, L., Gao, L., Perez-Cisneros, M., 2019. A fast and effective image preprocessing
method for hot round steel surface. Math. Probl. Eng. 2019. https://doi.org/10.1155/
2019/9457826.
D. Rahadiyan, S. Hartati, Wahyono et al.
Artiﬁcial Intelligence in Agriculture 8 (2023) 77–90
90
