Array 14 (2022) 100182
Available online 11 May 2022
2590-0056/© 2022 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
Contents lists available at ScienceDirect
Array
journal homepage: www.elsevier.com/locate/array
Improving novelty detection using the reconstructions of nearest neighbours
Michael Mesarcik a,∗, Elena Ranguelova b, Albert-Jan Boonstra c, Rob V. van Nieuwpoort a,b
a University of Amsterdam, Science Park 904, Amsterdam, 1098XH, The Netherlands
b eScience Center, Science Park 140, Amsterdam, 1098XG, The Netherlands
c ASTRON, the Netherlands Institute for Radio Astronomy, Oude Hoogeveensedijk 4, Dwingeloo, 7991PD, The Netherlands
A R T I C L E
I N F O
Keywords:
Anomaly detection
Autoencoders
Semi-supervised learning
A B S T R A C T
We show that using nearest neighbours in the latent space of autoencoders (AE) significantly improves
performance of semi-supervised novelty detection in both single and multi-class contexts. Autoencoding
methods detect novelty by learning to differentiate between the non-novel training class(es) and all other
unseen classes. Our method harnesses a combination of the reconstructions of the nearest neighbours and the
latent-neighbour distances of a given input’s latent representation. We demonstrate that our nearest-latent-
neighbours (NLN) algorithm is memory and time efficient, does not require significant data augmentation,
nor is reliant on pretrained networks. Furthermore, we show that the NLN-algorithm is easily applicable
to multiple datasets without modification. Additionally, the proposed algorithm is agnostic to autoencoder
architecture and reconstruction error method. We validate our method across several standard datasets for a
variety of different autoencoding architectures such as vanilla, adversarial and variational autoencoders using
either reconstruction, residual or feature consistent losses. The results show that the NLN algorithm grants up
to a 17% increase in Area Under the Receiver Operating Characteristics (AUROC) curve performance for the
multi-class case and 8% for single-class novelty detection.
1. Introduction
Novelty detection is an important field of research as identifying
previously unknown behaviours in systems is critical for their main-
tenance and smooth operation. It is the procedure in which a model
is able to identify new classes of data that it has not been exposed to
before. Novelty detection is a far-reaching topic having been applied
extensively in fields such as manufacturing [1], cyber-security [2],
biomedical analysis [3,4], astronomy [5] and many more [6].
Novelty, anomaly, outlier, abnormality and out-of-distribution
(OOD) detection are closely related topics [7]. The distinction be-
tween them is vague across variety of literature studies [3,8–11].
For clarity purposes, we consider novelty detection to be the over-
arching paradigm, since it makes contextual sense to have novel
abnormalities/anomalies/outliers but the converse does not apply.
Approaches for novelty and anomaly detection can be divided into
a number of categories [6,12–14]. In this work we exclusively focus
on autoencoder-based novelty detection. As it offers a data agnostic
method that does not rely on significant data augmentation [15],
finding negative samples [16,17] or pretraining on large labelled
datasets [18] such as ImageNet [19].
Autoencoders (AEs) are widely used as novelty detectors [8–10,20–
25]. The underlying mechanism that governs the AE’s detection abili-
ties is that they are firstly trained on data without abnormal, anomalous
∗ Corresponding author.
E-mail address: m.mesarcik@uva.nl (M. Mesarcik).
or outlying samples. Then, during inference, the AE is exposed to novel
samples which result in higher errors thus enabling novelty detection.
Methods such as mean-square-error (MSE) [22], residual error [3],
structural-similarity (SSIM) [26] or feature consistency [27] are used
to calculate the pixel-wise difference.
A common problem with using autoencoding methods for novelty
detection is that AEs can generalise to unseen classes thereby perform-
ing poorly as novelty detectors [28]. In [9], this issue is addressed
by placing a classifier in the training path of a multi-discriminator
based autoencoder, which results in a fairly complicated and costly
training procedure. On the contrary, we propose the Nearest-Latent-
Neighbours (NLN) algorithm which uses the reconstructions of the
nearest-neighbours in the latent space of autoencoders in-order to
combat the aforementioned generalisation problem.
Unlike existing nearest neighbours methods [29], our NLN algo-
rithm uses both the reconstruction error between a given sample and its
neighbours in the latent space as well as the average latent-distance to
its neighbours. Fig. 1 illustrates how a vanilla autoencoder generalises
to reconstruct unseen samples whereas the reconstructions of an input’s
nearest-latent-neighbours more closely resemble the non-novel training
set thereby offering improved novelty detection.
https://doi.org/10.1016/j.array.2022.100182
Received 4 February 2022; Received in revised form 2 May 2022; Accepted 3 May 2022
Array 14 (2022) 100182
2
M. Mesarcik et al.
Fig. 1. Comparison between the MSE and the Nearest-Latent-Neighbours (NLN) based error using a vanilla AE. The top row shows an AE trained on the non-anomalous screw
images of the MVTec-AD dataset, with the anomaly in the input circled in red, and the bottom row illustrates an AE trained on all MNIST digits except for ‘‘2’’. The first column
is the input to the AE, the second is the AE’s output and the following two columns show the reconstructions of the input’s NLNs. The final two columns show the difference
between the MSE and the NLN-based error, where in this work maximising the error on novel classes effectively performs novelty detection. It is clear that the AE learns to
reconstruct unseen classes whereas the reconstructions of the NLNs do not.
(For interpretation of the references to colour in this figure legend, the reader is referred to the web
version of this article.)
We evaluate the proposed method using the novelty detection
framework described in [30] and prove its effectiveness in a two-
stage testing strategy. Firstly by comparing different architecture’s
performance with and without the use of our NLN algorithm. Secondly
we compare our best performing model with the current state-of-the-art
AEs. We show that NLN is competitive with the state-of-the-art methods
across a number of datasets.
In summary, the main contributions of this paper are: (1) a novel
nearest-neighbour based algorithm that harnesses the reconstruction
error of a given sample’s nearest-latent-neighbours and their latent-
neighbour distances. (2) The formulation of the NLN algorithm applied
to a variety of autoencoding architectures using several different error
calculation methods. (3) Improved performance to the state-of-the-art
autoencoders using NLN, a fairly simple, cheap and intuitive method,
across a number of standard datasets.
2. Background and related work
In novelty, anomaly, outlier, abnormality and OOD detection one
or more of the following steps are required for the detection of a
novel, anomalous or outlying sample: (1) a model of the distribution
of the (non-anomalous/non-novel) data. (2) A suitable measure of
fitness describing whether a given sample lies within the modelled
distribution. (3) A decision rule to determine whether the measure is
above or below a threshold [13].
A critical distinction among all related work is whether supervised,
semi-supervised, or unsupervised methods have been used [31]. Su-
pervised methods typically relate more strongly to anomaly detection
scenarios, where both the normal and anomalous data classes are
known a-priori [13]. However, supervision is not applicable in many
settings, as anomalous classes are either underrepresented or just not
known [13]. In the unsupervised setup, we have no a-priori information
if the available data contains normal or abnormal samples [31].
Semi-supervised methods are the most common in practice, as nor-
mal (non-anomalous, non-novel) data is most easily collected from most
systems [6]. In this case, models are designed to represent the expected
operating conditions of a system and any deviations from that are
considered novel. These deviations may, in some cases, be considered
anomalous, however this is dependent on the context of operation [7].
For the remainder of the paper we focus on semi-supervised methods,
where we designate particular classes of a dataset as novel and all other
as expected.
2.1. Reconstruction based novelty detection
Semi-supervised reconstruction based methods leverage the fact that
a model trained on the normal data cannot suitably reconstruct novel
samples. In effect, the difference between the input and reconstructed
output can be used as a novelty detector. Autoencoders (AE) are com-
monly used for reconstruction based novelty and anomaly detection [8–
10,20–25]. They operate by jointly learning latent representations and
reconstructions of the training data. Once trained, a reconstruction
error can be calculated between the input sample and the model’s
decoded output. These models achieve improved performance when
regularising the latent space [21] using variational AEs (VAE) [32] or
adversarial losses [33].
It has been demonstrated that reconstruction-error based meth-
ods alone are not particularly robust to noise, changing backgrounds
and viewing angles [7]. In generative autoencoding models such as
VAEs, reconstruction probability or attention-mechanisms are used
to improve performance [21,25,34]. Furthermore Generative Adver-
sarial Networks (GANs) [35] are used for reconstruction-error based
anomaly detection [3,36,37]. Here the residual error is calculated as
the difference between the training and generated images using their
intermediate representations provided by the discriminator. More re-
cently, self-supervised learning (SSL) has been applied to AEs and offers
improved performance in novelty detection by using in-painting [23]
or position prediction [38] pretext tasks.
In our work we use the reconstructions of a given sample’s la-
tent neighbours in conjunction with their latent-distances. We show
that this offers performance increases across a variety of architectures
and datasets. Additionally, we utilise several autoencoding models
and show that the NLN algorithm offers performance improvements
irrespective of architecture.
2.2. Statistical methods
Statistical methods typically focus on modelling a distribution of
inliers through learning their distribution parameters [10]. In effect,
all expected/normal sample should lie in high density regions of the
distribution, while outliers should have a low probability under the
learnt distribution. Works such as One-class SVM [39], KNN [31] and
isolation forests [40] have been shown to be suitable anomaly detectors
applied in this context.
Furthermore, [30] demonstrates that using discriminative measures
in the latent space of AEs improves accuracy over reconstruction error.
Here, discriminative novelty measures such as One-class SVM and Local
Outlier Factor (LOF) [41] are applied to the latent space of AEs.
Array 14 (2022) 100182
3
M. Mesarcik et al.
In our work, we propose a hybrid approach, where we combine a
nearest neighbours based approach, that is typically used in distance-
based anomaly detection, with a reconstruction error-based approach.
This is done by considering the reconstruction error between neigh-
bouring points in the latent space with some input query that may
be novel or not. We show that our work enables robustness and
improvements to existing state-of-the-art research.
2.3. Single and mutli-class novelty detection
In the context of deep learning, one-class (single-class) novelty de-
tection [9,10,42–45] is the paradigm where a single class is considered
normal and all other classes are novel. In practice, a model is trained
on a dataset consisting of only a single class and during inference the
novelty detector is exposed to all classes and should identify all unseen
classes as novel.
For multi-class novelty detection, multiple classes are considered
inliers and a single class is considered novel [8,20,27,36]. This is
an inherently more challenging evaluation framework as the model
should be able to generalise to multiple classes and still be capa-
ble of detecting novel samples. In this work we evaluate our NLN-
enabled models in both a Multiple-Inlier-Single-Outlier (MISO) and
Single-Inlier-Multiple-Outlier (SIMO) contexts as defined by [30].
3. NLN: Nearest Latent Neighbours
Here we present our novelty detection framework for autoencoders.
We show that using a simple addition to existing autoencoding architec-
tures we can significantly increase their novelty detection performance.
3.1. Motivation
In [9,28] the generalisation problem of autoencoders when used for
one-class novelty detection is described. They show that when an AE is
trained on the relatively complex 8-class from the MNIST dataset [46],
the AE is able to implicitly learn the representations of digit classes such
as the 1, 3, 6 and 7. In effect, reconstruction-based novelty detectors are
prone to misidentify these implicitly learnt classes.
In order to solve this problem, [9] propose placing a classifier in
the training path of a multi-discriminator-based AE to decrease the
training signal for the reconstructions of implicitly learnt novel classes.
Conversely, we show that if we consider both the distance to, and the
reconstruction of, a given sample’s nearest latent neighbours we can
effectively mitigate this issue, as demonstrated in Fig. 1. In addition
to the improved performance over [9,28] shown in Table 4 we find
that the AE-backbones of our NLN algorithm have significantly better
training stability and are less prone to mode-collapse [47].
Furthermore, we motivate our focus on AEs for novelty detection as
they are applicable to a variety of datasets without significant augmen-
tation [15,17], do not need pretraining on large labelled datasets [18,
48] and require far fewer network parameters [49]. Additionally, their
structure provides segmentation maps for free without the need of
many small patches [38] that result in a significantly more expensive
KNN search1 or additional networks for segmentation [15].
3.2. Problem formulation and approach
Considering an autoencoding model with encoder, 𝑓, and decoder,
𝑔, then
𝑓(𝐱; 𝜃𝑓 ) = 𝐳,
𝑓(𝐱; 𝜃𝑓 ) ∶ R𝑝 → R𝑙
(1)
1 In [38] 2 KNN searches are performed on patches sizes of 32 and 64,
whereas we only need a single lookup for patches of size 128.
where 𝐱 is the input, 𝐳 is the input’s latent representation and 𝜃𝑓 are
the parameters of the encoder. Additionally, R𝑝 is the 𝑝-dimensional
image-space and R𝑙 is the 𝑙-dimensional latent-space. Now consider the
decoder with an input, 𝐳, and a reconstructed output ̂𝐱 such that
𝑔(𝐳; 𝜃𝑔) = ̂𝐱,
𝑔(𝐳; 𝜃𝑔) ∶ R𝑙 → R𝑝
(2)
where 𝜃𝑔 are the decoder’s parameters, such that the decoder maps
from the 𝑙-dimensional latent space to the 𝑝-dimensional image space.
The encoder and decoder pair is trained in an end-to-end manner
using a loss function such as Mean-Square-Error (MSE) or Binary-Cross-
Entropy(BCE). Once trained, the AE’s novelty score (𝜂) is computed for
the 𝑖th sample using
𝜂 =
1
𝑁𝑀
𝑁
∑ 𝑀
∑
|𝐱𝑖[𝑛, 𝑚] − ̂𝐱𝑖[𝑛, 𝑚]|
(3)
where 𝑛 and 𝑚 are the pixel-indexes for an image of size 𝑁×𝑀. This
score is typically thresholded in order to determine whether a sample
is novel and the threshold is calculated using AUROC-based methods
that are explained in more detail in Section 4.
In order to motivate our use of nearest-neighbours to solve the
generalisation problem of AEs, we assume that the high-dimensional
training data is concentrated on a low-dimensional data manifold in
𝑙 that we attempt to learn using an autoencoder [50]. The learnt
manifold is illustrated in Fig. 2. Here we demonstrate that closely-
connected regions on the learnt manifold contain points similar to
non-anomalous inputs and dissimilar to those which are novel. We
exploit this fact to improve the anomaly score robustness by including
the nearest-latent neighbours into the reconstruction error. This is done
by including the neighbours of the 𝑖th test sample in the latent space
R𝑙 in the calculation of the novelty score (𝜂nln). Such that
𝜂nln =
𝛼
𝐾𝑁𝑀
𝐾
∑ 𝑁
∑ 𝑀
∑
|𝐱𝑖[𝑛, 𝑚] − 𝑔(𝐳𝑘
𝑖 ; 𝜃𝑔)[𝑛, 𝑚]|
+1 − 𝛼
𝐾
𝐾
∑
|𝐳𝑖 − 𝐳𝑘
𝑖 |
(4)
where 𝑘 is the neighbour index such that 𝐳𝑘
𝑖 is 𝐳𝑖’s nearest neigh-
bours in the latent space. 𝐾 is the maximum number of latent neigh-
bours and 𝛼 is the hyper-parameter (∈ [0, 1]) used to tune the contribu-
tion of latent-space and image-space based distances respectively.
It must be noted that Eq. (4) shows the critical difference be-
tween [18,29] and our work. We propose using the reconstruction error
in the image space, R𝑝, whereas earlier work only use the difference of
extracted feature vectors in R𝑙. We find that there is additional infor-
mation that can be leveraged for novelty detection in the image space
of autoencoding methods, this is shown experimentally by the results
in Tables 3 and 4. Furthermore, for purposes of anomaly segmentation
as in done in the MVTec-AD dataset [18] the latent space error cannot
give pixel-level segmentation maps whereas the NLN-algorithm can.
3.2.1. Discriminative considerations
Discriminative autoencoding models use discriminators in the train-
ing of autoencoders. This is done to either improve the realism of the
AE’s outputs or to regularise the latent space to a prior distribution. In
this work we focus on the former case. Given a discriminator 𝑑𝐱, trained
on inputs 𝐱 and ̂𝐱 = 𝑔(𝐳; 𝜃𝑔) then
𝑑𝐱(𝐱; 𝜃𝑑𝐱) ∶ R𝑚 → [0, 1].
(5)
Where the discriminator on 𝐱 maps between the image space and
a value on the interval between 0 and 1. It returns 0 or 1 based
on whether the sample 𝐱 is taken from the training set or if it is
generated by the decoder, 𝑔. The discriminator’s training objective is
stated as [35]
disc = E[log(𝑑𝐱(𝐱))] + E[log(1 − 𝑑𝐱(̂𝐱))]
(6)
In addition to improving the regularisation, discriminators can also be
used for novelty detection. Novelty is calculated through the difference
Array 14 (2022) 100182
4
M. Mesarcik et al.
Fig. 2. Illustration of the learnt MNIST data manifold trained without the class of 1’s
(the class of 1’s are novel). The closely-connected regions of the novel class of 1’s
contain dissimilar digits resembling 7 and 9 whereas the non-novel classes consisting
of 0 and 7 do not.
between the representations of a sample 𝐱𝑖, and its respective decoded
output ̂𝐱𝑖, from an intermediate layer, 𝑞, of 𝑑𝐱. This is also referred to
as the residual error [3] and we include the nearest-latent-neighbours
by
𝜂res = 𝛼
𝐻𝐾
𝐻
∑ 𝐾
∑
|𝑞(𝐱𝑖)[ℎ] − 𝑞(𝑔(𝐳𝑘
𝑖 ; 𝜃𝑔))[ℎ]|
+1 − 𝛼
𝐾
𝐾
∑
|𝐳𝑖 − 𝐳𝑘
𝑖 |
(7)
where ℎ in an index of the output from an intermediate layer 𝑞 with
size 𝐻.
3.2.2. Feature consistency
It has been shown in [8] that adding an additional encoder in the
training path of the autoencoder improves performance. This paradigm
is referred to as feature consistency [27] and can be integrated in our
nearest-latent-neighbours method by
𝜂con = 𝛼
𝐿𝐾
𝐿
∑ 𝐾
∑
|𝑓(𝐱𝑖; 𝜃𝑓 )[𝑙] − 𝑓con(̂𝐱𝑘
𝑖 ; 𝜃𝑓con)[𝑙]|
+1 − 𝛼
𝐾
𝐾
∑
|𝐳𝑖 − 𝐳𝑘
𝑖 |.
(8)
Where 𝑓con is the additional encoder that takes ̂𝐱 as an input, with
parameters, 𝜃𝑓con. Furthermore, 𝐿 is the latent space dimensionality,
which is maintained between the first encoder, 𝑓, and the second
encoder, 𝑓con and is indexed by 𝑙. The encoder is trained jointly with
the rest of the discriminative autoencoder as described in [8].
3.3. The NLN algorithm
Our work concerns the integration of the NLN technique into ex-
isting autoencoding models. For this reason we explain three different
modes of operation for three different novelty scores. In the first case,
a vanilla autoencoding model is used with a standard reconstruction
error, as shown in Eq. (4). The second uses the autoencoding architec-
ture in [8] and the feature consistency error in Eq. (8). Finally, the third
makes use of a discriminative autoencoding architecture and use of the
residual error in Eq. (7).
In all cases, an autoencoding model is first trained on a dataset with
some novel class(es) removed. During testing, a sample is randomly
chosen (which may be novel or not) and is input into the encoder. Then
the nearest neighbours of the encoded sample are found in the latent
space generated by the training data. This process is represented by the
left-most half of Fig. 3.
In the first mode of operation, the error is computed between
the test sample and both the decodings and positions of its latent-
neighbours in the non-novel latent space. Whereas when discriminative
methods are used, the error is computed between the intermediate
representation from the discriminator 𝑑𝐱 of the test sample and all its
decoded latent neighbours in the training data. In the feature-consistent
case, the error is computed between the encoding via 𝑓con of the given
sample and all its nearest-latent-neighbours in the training data. In
Fig. 3 these three operations are represented by the ⋆ operator.
When performing novelty detection, one of the three methods’
errors are aggregated over all neighbours and normalised after which
they are added to the aggregated and normalised latent-neighbour
distance vector. Then they are thresholded to result in an anomaly score
and a segmentation map. The threshold is determined by the AUROC
method described in Section 4. This methodology is illustrated in the
right half of Fig. 3.
4. Experiments
We evaluate our method2 experimentally in both multi-class and
single-class novelty detection contexts as outlined in [30]. Further-
more, we compare our best performing NLN-enabled autoencoder using
both pixel-level and image-level anomaly detection metrics on the
MVTec-AD dataset with state-of-the-art autoencoders.
4.1. Evaluation methodology
To measure the performance of the NLN-enabled models, they are
trained multiple times on a specific dataset, each time removing a
different class or classes from the training set, thereby testing the
novelty detection performance on every class present in a given dataset.
We do this according to [30], such that both the single-class or Single-
Inlier-Multiple-Outlier (SIMO) and the multi-class or Multiple-Inliers-
Single-Outlier (MISO) performance are evaluated.
We use the Area Under the Receiver Operating Characteristic (AU-
ROC) score to evaluate and compare the performance of the NLN-
algorithm. The AUROC metric measures the area under the ROC curve
of true positive rates and false positive rates for different threshold
values. Furthermore, we evaluate the per-pixel detection performance
of our NLN-enabled models using Intersection over Union (IoU) score.
The IoU metric is a measure of the overlap between the predicted
regions and their corresponding ground-truth.
We limit our evaluation to only autoencoders as we find comparison
with methods that rely on SSL [16,38,51], pretrained feature extrac-
tors [16,51–53] or computationally expensive inference [38] are not
easily comparable on AUCROC alone across multiple datasets. It has
been well documented that using pretrained feature extractors and
SSL losses result in improved performance. However, they typically
require orders of magnitude more parameters [49], and are not easily
applicable across datasets or evaluation strategies. Furthermore, we
regard the simplicity of AEs a crucial attribute. This is in contrast
with the significant augmentation found in [15] and the challenge of
applying patch-dependent methods [38] to different datasets of varying
resolutions and anomaly types.
4.2. Datasets
We evaluate our work on four different datasets, namely MNIST
[46], CIFAR-10 [54], Fashion-MNIST [55] and MVTec-AD [24]. MNIST
2 Source code available at: https://github.com/mesarcik/NLN.
Array 14 (2022) 100182
5
M. Mesarcik et al.
Fig. 3. An illustration of our NLN algorithm, with three different samples from MNIST used as inputs to an autoencoding model, trained without the class of 1’s (i.e., 1’s are
novel). Each of the three input’s latent representations are found and their nearest neighbours (relative to the training set) are computed. The ⋆ represents the chosen error
calculation operator. Finally, the error is thresholded and the residual-error maps and novelty scores are produced.
Fig. 4. Pixel-level anomaly detection using NLN for four different MVTec-AD classes in the textures (top) and objects (bottom) categories.
is a dataset consisting of 28 × 28 × 1 handwritten digits between 0 and
9. The complexity of the dataset is low and therefore our method per-
forms best on it. Similarly, Fashion-MNIST is composed of 28 × 28 × 1
images of different types of articles of clothing. This dataset is used as
an intermediary difficulty, between MNIST and CIFAR-10. CIFAR-10 is
an object recognition dataset consisting of 32 × 32 × 3 images of 10
different classes. It is the most challenging dataset for novelty detection
as each of the semantic classes may appear at different scales, viewing
angles and have changing backgrounds [7]. The MVTec-AD dataset
is an industrial anomaly detection dataset consisting of 15 different
classes in 2 categories — objects and textures. The 10 object classes
contain regularly positioned objects photographed in high resolution
from the same viewing angle and the 5 texture classes contain repet-
itive patterns. For training on the MVTec-AD dataset we follow the
augmentation scheme proposed in [24], where random rotations and
crops are applied to the dataset that is broken into 128 × 128 patches.
For more details about the dataset’s composition and the augmentation
performed see [24] (see Table 2).
4.3. Model and parameter selection
In order to evaluate our work across a number of different datasets
we adapt our models accordingly. We adopt autoencoding the architec-
ture specified in [24] for the evaluation of the NLN algorithm on the
MVTec-AD dataset. For MNIST, CIFAR-10 and F-MNIST we modify a
LeNet [56] based autoencoding architecture. The encoder consists of 3
Table 1
Mean MISO AUROC percentage increase using NLN.
AE
AAE
VAE
AE-res
AE-con
MNIST
9.80%
17.65%
11.65%
10.13%
14.18%
CIFAR-10
6.92%
7.41%
1.29%
7.30%
6.68%
F-MNIST
11.52%
9.53%
10.31%
11.95%
11.52%
Table 2
Mean SIMO AUROC percentage increase using NLN.
AE
AAE
VAE
AE-res
AE-con
MNIST
3.45%
4.92%
3.99%
3.47%
4.21%
CIFAR-10
7.65%
8.81%
6.36%
6.89%
8.02%
F-MNIST
5.66%
5.12%
5.31%
5.65%
3.49%
convolutional layers and the decoder has 3 transposed-convolutional
layers. A base number of filters of 32 is used for the AE and is
increased or decreased on each subsequent layer by a factor of 2. We
use ReLU activations for all models and they are trained for 50 epochs
using ADAM [57] with a learning rate of 1 × 10−4. The image-based
discriminators 𝑑𝐱 use the same architecture as the encoder, except the
final layer, which is a dense layer with a sigmoid activation. The latent
discriminator for the AAE consists of 3 dense layers with Leaky ReLU
activations and a dropout rate of 0.3. The base layer size is 64 and is
increased by a factor of 2 for each subsequent layer. Furthermore, we
Array 14 (2022) 100182
6
M. Mesarcik et al.
Table 3
Mean MISO novelty detection AUROC, bold is best.
Model
MNIST
CIFAR-10
F-MNIST
GANomaly [8]
0.753
0.532
0.679
Skip-GAN [20]
0.492
0.629
0.515
OC-GAN [9]
0.683
0.510
0.678
VAE [21]
0.515
0.497
0.521
AnoGAN [3]
0.632
0.434
0.510
EGBAD [36]
0.656
0.496
0.500
DKNN [18]
0.791
0.714
0.746
Ours
0.921
0.560
0.763
Table 4
Mean SIMO novelty detection AUROC, bold is best.
Model
MNIST
CIFAR-10
F-MNIST
MVTec-AD
GANomaly [8]
0.965
0.695
0.906
0.762
OC-GAN [9]
0.975
0.657
0.924
0.756
AnoGAN [3]
0.912
0.618
0.817
0.600
LFD [28]
0.977
–
0.927
0.777
CBiGAN [37]
–
–
–
0.770
CAVGA-D𝑢 [34]
0.986
0.737
0.885
–
DKNNa [18]
0.917
0.890
0.938
0.750
Ours
0.974
0.658
0.941
0.783
aWe use the authors implementation for all datasets other than MVTec-AD, here we
use our own Tensorflow-based implementation.
treat the maximum number of neighbours, 𝐾, the latent dimensionality,
𝐿, and the NLN contribution, 𝛼, as hyper-parameters of our algorithm.
4.4. Results
We evaluate the performance increase of the NLN algorithm for a
variety of autoencoding models across a number of different datasets in
both the MISO-context in Table 1 and SIMO-context in Table 2. Here
the best performing reconstruction error-based AUROC is compared
with the best performing NLN-enabled model for each architecture. The
NLN-based AEs achieve a performance increase between 17% and 1%
across the three MISO-datasets and 8% and 3% for the SIMO-case. We
suspect the low performance gains in the SIMO-case of the NLN-enabled
AEs are due there being fewer latent neighbours to select from, thereby
reducing performance.
In Table 3 we present the MISO-based class-averaged AUROC com-
parison of autoencoding models. For MNIST, the optimal configuration
is a feature consistent AE with 𝐾 = 2, 𝐿 = 32 and 𝛼 = 1.0, for
CIFAR-10 we use the discriminative AE when 𝐾 = 1, 𝐿 = 32 and
𝛼 = 0.5. Finally for F-MNIST, we use a discriminative AE when 𝐾 = 1,
𝐿𝐷 = 64 and 𝛼 = 0.9. Here we see that the NLN-algorithm gives
significant performance increases for MNIST and F-MNIST, even above
the pretrained ResNet-50 proposed by [18]. Furthermore, we see that
OCGAN [9] is not performant in a MISO context, this indicates that our
NLN algorithm may offer a more robust solution to the generalisability
problem in AEs. We show that AEs do not perform particularly well on
CIFAR-10. This is expected, as images from the same class in contain
substantially different pixel-level information. For example the aero-
plane class contains images of both the cockpit of a grounded Boeing
747 as well a fighter-jet photographed from the side-view in mid-flight.
In effect, the MSE between non-novel images in the same class, can be
greater than novel images thereby reducing the efficacy of MSE based
novelty detectors on CIFAR-10.
We present the class-averaged AUROC scores for the SIMO-based
evaluation in Table 4. Here the optimal method for MNIST is a dis-
criminative AE, with 𝐿𝐷 = 128, 𝐾 = 3 and 𝛼 = 1.0 and for CIFAR-10
we find the optimal method to be a vanilla AE with 𝐿𝐷 = 256, 𝐾 = 1
and 𝛼 = 0.75. Furthermore, we find the best performing method on
F-MNIST to be a VAE with 𝐿𝐷 = 32, 𝐾 = 3 and 𝛼 = 0.9. For the
MVTec-AD dataset we use a discriminative AE with 𝐿𝐷 = 128, 𝐾 = 1
and 𝛼 = 0.8. It is clear that the attention guided VAE (CAVAGA) [34]
Fig. 5. Vanilla Autoencoder AUROC sensitivity to number of neighbours and latent
dimensions in SIMO-context for 𝛼 = 0.8.
method performs best on MNIST whereas DKNN [18] on CIFAR-10.
However, it is evident that the NLN-enabled autoencoding models offer
increased performance over existing autoencoding and ResNet-based
architectures for both the F-MNIST and MVTec-AD datasets in the SIMO
context.
In Fig. 5 we show the effect of varying 𝐿 and 𝐾 on AUROC scores for
vanilla AE in the SIMO context when 𝛼 = 0.8. For F-MNIST and MNIST
a maximum AUROC score is found for 𝐿 = 128 and 𝐾 > 3, whereas for
CIFAR-10 the optimal is found when 𝐿 = 256 and 𝐾 = 1. Finally it is
shown that the vanilla AE offers best image-based AUROC performance
when 𝐿 = 256 and 𝐾 = 3.
We evaluate the pixel-level anomaly detection performance in
Table 5, and illustrate the model outputs in Fig. 4 of both texture
and object classes. In all cases we use a vanilla AE with 𝐾
= 1,
𝐿 = 128 and 𝛼 = 0.6. It is clear that the NLN-enabled AE demonstrates
performance increases in the object classes of MVTec-AD. However, this
is not the case for the texture classes. We suspect that this is due to
our NLN-enabled AE not being able to distinguish between different
texture-patches. This behaviour is similarly demonstrated in [24], and
we believe that this is an inherent weakness of standard autoencoding
architectures.
Array 14 (2022) 100182
7
M. Mesarcik et al.
Fig. 6. AUROC and IoU sensitivity to varying 𝛼 of the NLN-enabled autoencoding models applied to the MVTec-AD dataset.
Table 5
Pixel-based novelty detection (Segmentation) AUROC score for autoencoding models,
where bold is best.
Class
AE-L2 [24] AE-SSIM [24] SMAI L2 [23]
VE-VAE [25] Ours
Textures
Carpet
0.59
0.87
0.88
0.78
0.82
Grid
0.90
0.94
0.97
0.73
0.86
Leather
0.75
0.78
0.86
0.95
0.85
Tile
0.51
0.59
0.62
0.80
0.51
Wood
0.73
0.73
0.80
0.77
0.72
Mean
0.70
0.78
0.83
0.81
0.75
Objects
Bottle
0.86
0.93
0.86
0.87
0.95
Cable
0.86
0.82
0.92
0.90
0.90
Capsule
0.88
0.94
0.93
0.74
0.94
Hazelnut
0.95
0.97
0.97
0.98
0.98
Metal nut
0.86
0.89
0.92
0.94
0.88
Pill
0.85
0.91
0.92
0.83
0.92
Screw
0.96
0.96
0.96
0.97
0.97
Toothbrush 0.93
0.92
0.96
0.94
0.97
Transistor
0.86
0.90
0.85
0.93
0.85
Zipper
0.77
0.88
0.9
0.78
0.96
Mean
0.88
0.91
0.92
0.89
0.93
In Fig. 6 we illustrate the effect on varying alpha for the NLN-
enabled autoencoding models used for the MVTec-AD dataset. Here
it is demonstrated, that the NLN-based model obtain optimal AUROC
segmentation-performance when 0.25
<
𝛼
<
0.8, whereas to op-
timal AUROC detection-performance occurs when 𝛼 > 0.6. Finally
we illustrate that the optimal IoU value is obtained at 𝛼
=
0.8,
thus demonstrating the benefit of including the reconstructions of
nearest-neighbours in the calculation of the anomaly score.
4.5. Time and memory efficiency
The NLN-algorithm requires a forward pass through an encoder,
a KNN search of the latent-space generated by the training samples,
and a forward pass of a given point’s nearest neighbours through a
decoder. We evaluate the models on a Nvidia T4, where a forward pass
of a single image from the MVTec-AD dataset takes 7.41 ms for the
encoder and 9.63 ms for the decoder. In comparison, a ResNet50 used
in [18,58,59] requires 43.3 ms for a forward pass of a single image.
This means that our method is between 1.3× and 2.5× more efficient
for a forward pass, depending on the architecture used.
For the KNN search we use a k-d tree implementation of the KNN
search, which has a inference time complexity of (𝐾𝐿 log 𝑁). Where
𝐾 is the number of neighbours, 𝐿 is the latent dimensionality and 𝑁 is
the number of points in the training set. In the case of the NLN-enabled
models presented in this work, we find a latent dimensionality of 128
sufficient, whereas the ResNet50 in [18] uses 2048 dimensional latent
space. This means that our work offers a 16× reduction in KNN search
inference time in comparison with [18].
Finally, our method has comparable storage requirements as other
AE based models [49] in terms of number of trainable parameters.
Table 6
MISO AUROC performance of AE-con for different losses terms when 𝐾 = 2, 𝐿 = 32
and 𝛼 = 0.9.
Dataset
recon
NLN
con
total
MNIST
0.778
0.822
0.913
0.921
FMNIST
0.669
0.702
0.719
0.738
CIFAR-10
0.511
0.513
0.551
0.553
Fig. 7. MSE Loss and SIMO-based AUROC on the 0-class of MNIST for a vanilla AE
with 𝛼 = 0.8, 𝐿 = 128 and 𝐾 = 5.
For comparison, the AE-con model used for MVTec-AD has 1.79 mil-
lion parameters, whereas the ResNet-50 from [18] has 25.58 million
parameters. The only storage-based overhead of the NLN-algorithm is
the requirement of amortising the embeddings of the training set as
suggested in [18]. In the case of the bottle-class of the MVTec-AD
dataset, there is an additional storage requirement of 6.85 MB3
5. Ablation study
The AUROC performance of the NLN-algorithm is demonstrated in
Table 6 when the loss function varied. The term in the first column,
recon, represents the standard reconstruction error given by Eq. (3)
and NLN shows the NLN-based reconstruction loss given in the first
half of Eq. (4). con represents the feature consistent adaption given by
the first half of Eq. (8) and total is equivalent to the score obtained
from Eq. (8). It can be seen that through the utilisation of all terms in
NLN-loss formulation we obtain optimal performance.
In Fig. 7 we illustrate the MSE loss and the SIMO-based novelty
detection performance of a vanilla AE trained without the class of
0’s (i.e. the 0-class is novel). Here we see that within the specified
50 training epochs, the MSE converges to 0.075 whilst the AUROC
converges to approximately 0.99.
3 209 images × 16 × 4 augmented patches × 128 latent dimensions ×
32 bits = 6.85 MB of additional memory.
Array 14 (2022) 100182
8
M. Mesarcik et al.
6. Discussion and conclusions
Autoencoders learn to generalise to unseen classes which is a
problem when they are used for novelty detection. In this work,
we demonstrate that when the reconstructions of a model’s nearest-
latent-neighbours are harnessed we can more effectively and efficiently
mitigate this problem in comparison with the state-of-the-art. This is
achieved through a fairly simple algorithm that is agnostic to both
the AE’s architecture and its error method. We experimentally prove
that the addition of the NLN algorithm consistently yields performance
increases for various autoencoding architectures and various datasets
and is competitive with the state-of-the-art autoencoding models. This
is achieved without complex augmentation, using pretrained networks
or computationally expensive inference. We note that the complexity
of CIFAR-10 and the texture classes of MVTec-AD result in modest
performance, but we expect this can be solved using more robust error
functions or using SSL to obtain even better latent representations.
CRediT authorship contribution statement
Michael Mesarcik: Conceptualisation, Methodology, Software, Data
curation, Writing – original draft, Visualisation, Investigation, Valida-
tion. Elena Ranguelova: Supervision, Methodology, Validation, Writ-
ing – review & editing, Funding acquisition. Albert-Jan Boonstra: Su-
pervision, Methodology, Validation, Writing – review & editing, Fund-
ing acquisition. Rob V. van Nieuwpoort: Supervision, Methodology,
Validation, Writing – review & editing.
Acknowledgements
This work is part of the Perspectief research programme Efficient
Deep Learning (EDL), which is financed by the Dutch Research Council
(NWO) domain Applied and Engineering Sciences (TTW).
References
[1] Kim Dongil, Kang Pilsung, Cho Sungzoon, Lee Hyoung Joo, Doh Seungy-
ong. Machine learning-based novelty detection for faulty wafer detection in
semiconductor manufacturing. Expert Syst Appl 2012;39(4):4075–83.
[2] Xu Haowen, Chen Wenxiao, Zhao Nengwen, Li Zeyan, Bu Jiahao, Li Zhihan,
Liu Ying, Zhao Youjian, Pei Dan, Feng Yang, Chen Jie, Wang Zhaogang,
Qiao Honglin. Unsupervised anomaly detection via variational auto-encoder for
seasonal KPIs in web applications. In: The web conference 2018 - proceedings
of the world wide web conference, WWW 2018, Vol. 2. 2018, p. 187–96.
[3] Schlegl Thomas, Seeböck Philipp, Waldstein Sebastian M, Schmidt-Erfurth Ur-
sula, Langs Georg. Unsupervised anomaly detection with generative adversarial
networks to guide marker discovery. In: Lecture notes in computer science
(including subseries lecture notes in artificial intelligence and lecture notes in
bioinformatics). LNCS, vol. 10265, 2017, p. 146–7.
[4] Baur Christoph, Wiestler Benedikt, Albarqouni Shadi, Navab Nassir. Deep autoen-
coding models for unsupervised anomaly segmentation in brain MR images. In:
Crimi Alessandro, Bakas Spyridon, Kuijf Hugo, Keyvan Farahani, Reyes Mauricio,
van Walsum The, editors. Brainlesion: Glioma, multiple sclerosis, stroke and
traumatic brain injuries. Springer International Publishing; 2019, p. 161–9.
[5] Margalef-Bentabol Berta, Huertas-Company Marc, Charnock Tom, Margalef-
Bentabol
Carla,
Bernardi
Mariangela,
Dubois
Yohan,
Storey-Fisher
Kate,
Zanisi Lorenzo. Detecting outliers in astronomical images with deep generative
networks.. Mon Not R Astron Soc 2020;000(0000).
[6] Markou Markos, Singh Sameer. Novelty detection: a review. Signal Process
2003;83(12):2499–521.
[7] Ahmed Faruk, Courville Aaron. Detecting semantic anomalies. 2019.
[8] Akcay Samet, Atapour-Abarghouei Amir, Breckon Toby P. GANomaly: Semi-
supervised anomaly detection via adversarial training. In: Computer vision –
ACCV 2018. Springer International Publishing; 2019, p. 622–37.
[9] Perera Pramuditha, Nallapati Ramesh, Xiang Bing. OCGAN: One-class novelty
detection using gans with constrained latent representations. In: Proceedings
of the IEEE computer society conference on computer vision and pattern
recognition; 2019, p. 2893–901.
[10] Pidhorskyi Stanislav, Almohsen Ranya, Adjeroh Donald A, Doretto Gianfranco.
Generative probabilistic novelty detection with adversarial autoencoders. Adv
Neural Inf Process Syst 2018;(NeurIPS):6822–33.
[11] Khan Shehroz S, Madden Michael G. A survey of recent trends in one class
classification. In: Lecture notes in computer science (including subseries lecture
notes in artificial intelligence and lecture notes in bioinformatics). LNAI, vol.
6206, 2010, p. 188–97.
[12] Sipple John. Interpretable, multidimensional, multimodal anomaly detection with
negative sampling for detection of device failure. 2020.
[13] Chandola Varun, Banerjee Arindam, Kumar Vipin. Anomaly detection. ACM
Comput Surv 2009;41(3):1–58.
[14] Chalapathy Raghavendra, Chawla Sanjay. Deep learning for anomaly detection:
A survey. 2019, p. 1–50.
[15] Li
Chun-Liang,
Sohn
Kihyuk,
Yoon
Jinsung,
Pfister
Tomas.
CutPaste:
Self-supervised learning for anomaly detection and localization. 2021.
[16] Sohn Kihyuk, Li Chun-Liang, Yoon Jinsung, Jin Minho, Pfister Tomas. Learning
and evaluating representations for deep one-class classification. 2020, p. 1–32.
[17] Fei Ye, Huang Chaoqin, Jinkun Cao, Li Maosen, Zhang Ya, Lu Cewu. At-
tribute restoration framework for anomaly detection. IEEE Trans Multimed
2020;(April):1–14.
[18] Bergman Liron, Cohen Niv, Hoshen Yedid. Deep nearest neighbor anomaly
detection. 2020.
[19] Fei-Fei L, Deng J, Li K. ImageNet: Constructing a large-scale image database. J
Vis 2010;9(8):1037.
[20] Akcay Samet, Atapour-Abarghouei Amir, Breckon Toby P. Skip-GANomaly: Skip
connected and adversarially trained encoder-decoder anomaly detection. In:
Proceedings of the international joint conference on neural networks, Vol.
2019-July; 2019.
[21] An Jinwon, Sungzoon Cho. Variational autoencoder based anomaly detection
using reconstruction probability. Spec Lect IE 2015;20(6).
[22] Larsen
Anders
Boesen
Lindbo,
Sønderby
Søren
Kaae,
Larochelle
Hugo,
Winther Ole. Autoencoding beyond pixels using a learned similarity metric. In:
33rd international conference on machine learning, ICML 2016, Vol. 4. 2016, p.
2341–9.
[23] Li Zhenyu. Superpixel masking and inpainting for self-supervised anomaly
detection. Bmvc 2020.
[24] Bergmann Paul, Fauser Michael, Sattlegger David, Steger Carsten. MVTec AD
— A comprehensive real-world dataset for unsupervised anomaly detection. In:
2019 IEEE/CVF conference on computer vision and pattern recognition (CVPR).
IEEE; 2019, p. 9584–92.
[25] Liu Wenqian, Li Runze, Zheng Meng, Karanam Srikrishna, Wu Ziyan, Bhanu Bir,
Radke Richard J, Camps Octavia. Towards visually explaining variational au-
toencoders. In: 2020 IEEE/CVF conference on computer vision and pattern
recognition (CVPR). IEEE; 2020, p. 8639–48.
[26] Bergmann Paul, Löwe Sindy, Fauser Michael, Sattlegger David, Steger Carsten.
Improving unsupervised defect segmentation by applying structural similarity
to autoencoders. In: VISIGRAPP 2019 - Proceedings of the 14th international
joint conference on computer vision, imaging and computer graphics theory and
applications, Vol. 5; 2019, p. 372–80.
[27] Lee Wei-Yu, Wang Yu-Chiang Frank. Learning disentangled feature representa-
tions for anomaly detection. In: 2020 IEEE international conference on image
processing (ICIP). IEEE; 2020, p. 2156–60.
[28] Hong Eungi, Choe Yoonsik. Latent feature decentralization loss for one-class
anomaly detection. IEEE Access 2020;8:165658–69.
[29] Guo Jia, Liu Guannan, Zuo Yuan, Wu Junjie. An anomaly detection framework
based on autoencoder and nearest neighbor. In: 2018 15th international confer-
ence on service systems and service management, ICSSSM 2018. IEEE; 2018, p.
1–6.
[30] Burlina Philippe, Joshi Neil, Wang I Jeng. Where’s wally now? Deep generative
and discriminative embeddings for novelty detection. In: Proceedings of the IEEE
computer society conference on computer vision and pattern recognition, Vol.
2019-June; 2019, p. 11499–508.
[31] Gu Xiaoyi, Akoglu Leman, Rinaldo Alessandro. Statistical analysis of near-
est neighbor methods for anomaly detection. Adv Neural Inf Process Syst
2019;32(NeurIPS):1–11.
[32] Kingma Diederik P, Welling Max. Auto-encoding variational Bayes. 2013, p.
1–14, ArXiv e-prints, (Ml).
[33] Makhzani Alireza, Shlens Jonathon, Jaitly Navdeep, Goodfellow Ian, Frey Bren-
dan. Adversarial autoencoders. 2015.
[34] Venkataramanan Shashanka, Peng Kuan Chuan, Singh Rajat Vikram, Maha-
lanobis Abhijit. Attention guided anomaly localization in images. In: Lecture
notes in computer science (including subseries lecture notes in artificial in-
telligence and lecture notes in bioinformatics). LNCS, vol. 12362, 2020, p.
485–503.
[35] Goodfellow
Ian
J,
Pouget-Abadie
Jean,
Mirza
Mehdi,
Xu
Bing,
Warde-
Farley
David,
Ozair
Sherjil,
Courville
Aaron,
Bengio
Yoshua.
Generative
adversarial nets. Adv Neural Inf Process Syst 2014;3(January):2672–80.
[36] Zenati Houssam, Foo Chuan Sheng, Lecouat Bruno, Manek Gaurav, Chan-
drasekhar Vijay Ramaseshan. Efficient GAN-based anomaly detection. 2018.
[37] Carrara Fabio, Amato Giuseppe, Brombin Luca, Falchi Fabrizio, Gennaro Claudio.
Combining GANs and AutoEncoders for efficient anomaly detection. 2021, p.
3939–46.
Array 14 (2022) 100182
9
M. Mesarcik et al.
[38] Yi Jihun, Yoon Sungroh. Patch SVDD: Patch-level SVDD for anomaly detection
and segmentation. 2020, p. 1–16, ArXiv.
[39] Erfani Sarah M, Rajasegarar Sutharshan, Karunasekera Shanika, Leckie Christo-
pher.
High-dimensional
and
large-scale
anomaly
detection
using
a
linear
one-class SVM with deep learning. Pattern Recognit 2016;58:121–34.
[40] Tony Liu Fei, Ming Ting Kai, Zhou Zhi-Hua. Isolation forest. In: ICDM. 2008.
[41] Breunig Markus M, Kriegel Hans-Peter, Ng Raymond T, Sander Jörg. LOF. ACM
SIGMOD Record 2000;29(2):93–104.
[42] Abati Davide, Porrello Angelo, Calderara Simone, Cucchiara Rita. Latent space
autoregression for novelty detection. In: Proceedings of the IEEE computer
society conference on computer vision and pattern recognition, Vol. 2019-June;
2019, p. 481–90.
[43] Sabokrou Mohammad, Khalooei Mohammad, Fathy Mahmood, Adeli Ehsan.
Adversarially learned one-class classifier for novelty detection. In: Proceedings
of the IEEE computer society conference on computer vision and pattern
recognition; 2018, p. 3379–88.
[44] Khan Shehroz S, Madden Michael G. One-class classification: taxonomy of study
and review of techniques. Knowl Eng Rev 2014;29(3):345–74.
[45] Zenati Houssam, Romain Manon, Foo Chuan Sheng, Lecouat Bruno, Chan-
drasekhar Vijay. Adversarially learned anomaly detection. In: Proceedings - IEEE
international conference on data mining, ICDM; 2018, p. 727–36.
[46] LeCun Yann, Cortes Corinna, Burges CJ. MNIST handwritten digit database. ATT
Labs 2010;2.
[47] Saxena Divya, Cao Jiannong. Generative adversarial networks (GANs). ACM
Comput Surv 2021;54(3):1–42.
[48] Reiss
Tal,
Cohen
Niv,
Bergman
Liron,
Hoshen
Yedid.
PANDA:
ADapting
pretrained features for anomaly detection and segmentation. 2020.
[49] Bergmann Paul, Batzner Kilian, Fauser Michael, Sattlegger David, Steger Carsten.
The MVTec anomaly detection dataset: A comprehensive real-world dataset for
unsupervised anomaly detection. Int J Comput Vis 2021;129(4):1038–59.
[50] Goodfellow Ian, Bengio Yoshua, Courville Aaron. Deep learning. The MIT Press;
2016.
[51] Chen Yuanhong, Tian Yu, Pang Guansong, Carneiro Gustavo. Unsupervised
anomaly detection with multi-scale interpolated Gaussian descriptors. 2021.
[52] Hendrycks Dan, Mazeika Mantas, Dietterich Thomas. Deep anomaly detection
with outlier exposure. 2018, p. 1–18.
[53] Tack Jihoon, Mo Sangwoo, Jeong Jongheon, Shin Jinwoo. CSI: Novelty detection
via contrastive learning on distributionally shifted instances. (NeurIPS). 2020.
[54] Krizhevsky A. Learning multiple layers of features from tiny images. Technical
report, 2009.
[55] Xiao Han, Rasul Kashif, Vollgraf Roland. Fashion-MNIST: a novel image dataset
for benchmarking machine learning algorithms. 2017, p. 1–6.
[56] Lecun Yann, Bottou Le’on, Bengio Yoshua, Haffner Parick. Gradient-based
learning applied to document recognition. Proc IEEE 1998;86(11):2278–324.
[57] Kingma Diederik P, Ba Jimmy Lei. Adam: A method for stochastic optimization.
In: 3rd international conference on learning representations, ICLR 2015 -
conference track proceedings. 2015, p. 1–15.
[58] Bergmann Paul, Fauser Michael, Sattlegger David, Steger Carsten. Uninformed
students: Student-teacher anomaly detection with discriminative latent embed-
dings. In: Proceedings of the IEEE computer society conference on computer
vision and pattern recognition; 2020, p. 4182–91.
[59] Perera Pramuditha, Patel Vishal M. Deep transfer learning for multiple class
novelty detection. In: Proceedings of the IEEE computer society conference on
computer vision and pattern recognition; 2019, p. 11536–44.
