Application of artiﬁcial intelligence for separation of live and dead
rainbow trout ﬁsh eggs
Abbas Rohani a,⁎, Morteza Taki b, Ghasem Bahrami a
a Department of Biosystems Engineering, Faculty of Agriculture, Ferdowsi University of Mashhad, Mashhad, Iran
b Department of Agricultural Machinery and Mechanization, Agricultural Sciences and Natural Resources University of Khuzestan, Mollasani, Iran
a b s t r a c t
a r t i c l e
i n f o
Article history:
Received 23 January 2019
Received in revised form 20 March 2019
Accepted 21 March 2019
Available online 25 March 2019
In this study a visual machine technology-based intelligent system was developed and evaluated for separation
and recognizing the alive and dead eggs of rainbow trout ﬁsh. The features derived from imagery processing of
alive and dead eggs were used as the decision-making variables in the classiﬁer. Multi-layer Perceptron neural
network (MLP) and Support Vector Machine (SVM) models were used as the classiﬁers. With paired t-test, 10
effective features were selected from 15 features for classiﬁcation. The k-fold cross validation method was
used for better evaluation the classiﬁers. By changing the size of the training data set from 80% to 20%, the clas-
siﬁer ability and stability were evaluated. The results showed that in the training phase, all the mean values of the
statistical indices for MLP and SVM classiﬁcations were complete for all categories (100% of the classiﬁcation was
predicted correctly). Also, in the test phase, the performance indicators of both classiﬁers were very satisfactory
(the average accuracy was 99.45%). Therefore, it is possible to use both classiﬁers with certainty for separation the
rainbow trout ﬁsh eggs.
© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open
access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
Keywords:
Rainbow trout
Fish egg
K-fold cross validation
Machine vision system
1. Introduction
In Iran and some of other countries, healthy ﬁsh eggs are separated
from the unhealthy ones traditionally and manually. Now, this method
is used in many ﬁsh farms. But in some ﬁsh egg production centers, the
eggs were separated by semi-automatically methods. This method is
constrained by low speed, low accuracy and high cost. These big disad-
vantages have increased the efforts to build a more accurate device by
image processing method to solve the problems and improve the efﬁ-
ciency. Machine vision system includes a camera for taking a picture
and also a computer with efﬁcient software and hardware and lighting
system. The quality of the images depends on the light conditions at the
time of shooting. So if this factor is better, more accurate processing re-
sults will be achieved (Du and Sun, 2004). In this method, images pro-
cessing needs the new tools for smart grids to process the images in
shorter time with the high level of conﬁdence. The network is based
on the general trainings to acquire data and it can be implemented for
other data (Mitchell et al., 1996). Color and texture are useful features
that can be extracted from the images. Color is regarded as a low-level
feature. This feature can be extracted from the homogeneous images
and parts of objects in the image (Kim and Hong, 2009). The histological
features play a very important role in the classiﬁcation of pattern. The
best algorithms for texture feature are GLCM (Gray-Level Co-
Occurrence Matrix) (Sengur, 2008). Since counting the number of ﬁsh
by hand is difﬁcult and also the possibility of error is high, a system
based on the image processing in different places and conditions was
designed (Zion et al., 2006). The system can count the number of ﬁshes.
The algorithm can work with 98% accuracy. In another study, a commer-
cial software was designed to count the ﬁsh eggs (Friedland et al., 2005).
The images were taken from ﬁsh eggs. By algorithm dilation erosion,
seven geometric and dimensional features were extracted and ﬁnally
the ﬁsh eggs were counted properly. Kunrui et al. (2015), built an egg
grading machine (Kunrui et al., 2015). In this system, images were
taken when the eggs moved by a typical rails. Then, the images were
processed to drive their features such as morphological and color char-
acteristics. Six features were extracted from color space. The procedure
speed was 5400 eggs per hour. Experimental results showed that preci-
sion of this system was approximately 90%. In another research, image
processing techniques was applied for analysis the silkworm eggs
(Kiratiratanapruk et al., 2014). This technique could detect objects and
types of eggs. The experiment was conducted in Thailand Sericulture
Center. The authors extracted 60 samples from seven kinds of silkworm
eggs. Color properties in RGB, HSV, LAB and YUV domains were ex-
tracted. Silkworm eggs processing speed was up to 140 eggs per second.
Precision of this system was approximately 90%. Omid et al. (2013), de-
signed a technique based on machine vision and neural network to
grade the eggs (Omid et al., 2013). This system could detect some fea-
tures such as blood clots and egg shell cracking. Color characteristics
were extracted from HSV space. Fuzzy inference system was used for
Artiﬁcial Intelligence in Agriculture 1 (2019) 27–34
⁎ Corresponding author.
E-mail address: arohani@um.ac.ir (A. Rohani).
https://doi.org/10.1016/j.aiia.2019.03.002
2589-7217/© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://
creativecommons.org/licenses/by-nc-nd/4.0/).
Contents lists available at ScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage: http://www.keaipublishing.com/en/journals/artificial-
intelligence-in-agriculture/
griding. Precision of this system was 95%, 94.5% and 98% for the size,
crack and fracture, respectively. In another study, Soltani and Omid
(2015), designed a system based on electrochemical impedance spec-
troscopy technique and machine vision (Soltani and Omid, 2015). This
method was based on the variations of dielectric properties. In this sys-
tem, when the eggs were put into the sensor, dielectric properties were
changed. The eggs were graded on the basis of some characteristics such
as mass, thickness and length. The separation technique involves the Ar-
tiﬁcial Neural Network (ANN), Bayesian Network (BN), Decision Trees
(DT) and Support Vector Machine (SVM). All these methods had a
good precision. In a research, applied machine vision systems were pro-
posed to detect and identify the sardine eggs (Powell et al., 2003). On-
line imaging system was used for detecting and counting the ﬁsh eggs
included lamps, ﬂow cells, pumps and computer with suitable hardware
and software for image processing. Some features such as size, shape
and shadow were extracted. These characteristics were used as the in-
puts in the regression tree algorithms. With this system, 9987 sardine
eggs were counted. Results showed that SVM is a very useful technique
for pattern recognition and distinguishing the two groups. Today, appli-
cation of SVM and ANN as powerful algorithms for distinguish between
the two groups is quite common (Robotham et al., 2010; Cortes and
Vapnik, 1995). In the ﬁelds of ecological and biological applications,
SVM is better than ANN (Morris et al., 2001). Some of researchers
used these methods for the ecological and biological subject. Hu et al.
(2012), used SVM and ANN technique for the separation of common
sardine ﬁsh and jack mackerel in south-central Chile (Hu et al., 2012).
The extracted features such as morphological, bathymetric, energetica
and positional were used for classiﬁcation the two species. The results
showed that this method had 89.5% conﬁdence for the ﬁsh classiﬁcation.
To help Chinese ﬁshermen and diagnose ﬁsh diseases, Storbeck and Dan
developed a method (Storbeck and Daan, 2001). In this system, at the
ﬁrst step, the ﬁshes were taken on the rail. Then images captured
from ﬁshes by smartphones. Some characteristics such as width, length,
textural properties and statistical properties of wavelet transform were
extracted. Multi class SVM was used for grouping the ﬁsh species. The
results showed that the best method for diagnosing the diseases of
ﬁsh was the extracting properties of the color in the HSV space and
use of one-against-one algorithm in SVM. In another study, two
methods including pattern recognition and near infrared was combined
for classifying the freshness of egg (Zhao et al., 2010). For classiﬁcation,
support vector machine data description (SVDD) was used. In this re-
search, the range of spectra for egg was 10–4000 cm−1. For examination
of the classiﬁcation method, some methods like k-Nearest Neighbors
(KNN), ANN and SVM were used. At last, SVDD had the best results. Pre-
cision of this system was approximately 93.3%. The results showed that
this method was an excellent way for solving similar problems.
The above literatures showed that little research was done for sepa-
ration and identiﬁcation the ﬁsh eggs especially in Iran. So, the present
study was aimed to develop a visual machine for separation the alive
and dead ﬁsh eggs. The images were categorized with two classiﬁers:
SVM and MLP. The results of this research can be useful for food engi-
neers to construct an accurate device for solve this problem.
2. Materials and methods
2.1. Image acquisition and features extraction
In this research, images were captured with a Canon Digital Asus 500
VHS. Since the ﬁsh eggs were small, the size of images was selected as
280 × 280 pixels. After several image capturing, the camera was ﬁxed
at 40 cm above the plate containing the samples. After analysis of im-
ages, the quality of the ﬁsh eggs was determined. The texture and
color features were derived from image processing. This process con-
sists of two stages:
1. Image processing technique including:
• Capturing the images of ﬁsh eggs.
• Resize the images to 280 × 280 pixels.
• Convert the images from RGB to LAB (for color features).
• Convert images from RGB to GRAY (for texture features).
• Labeling the each object.
2. Feature extraction. In this section, color and texture features were ex-
tracted from each labeled. Features of the ﬁsh egg are including the
contrast, correlation, energy, homogeneity, LBP (mean and standard
deviation) and LAB (mean, standard deviation and range) values.
These features were used for separating the ﬁsh eggs. Fig. 1 shows
the original and converted image of a sample egg.
2.1.1. Color features
In this section, at ﬁrst, backgrounds of the images were omitted.
After that, it was needed a color space that was not affected by imaging
instrument and condition. RGB color space dos not have this condition.
So, LAB color space was used. Unlike the RGB, this system is similar to
the human eye. Also, it is not affected by the instrument (Shaﬁee
et al., 2014). In this space, L is the equivalent to brightness and A has
an unlimited amount (the positive values represent the red and the neg-
ative values are green). The positive value of B is equal to yellow and the
negative is equal to blue. In the literatures, most food industry re-
searchers use LAB space frequently. For each space of LAB, three statis-
tical properties and nine color features were extracted.
Mean is the average of statistical factor or central tendency. Standard
deviation (Std) is used to determine the amount of the data dispersion
and ﬁnally, range is the span between the largest and smallest value
(Zion et al., 2006).
2.1.2. Texture's features
Another aspect of analysis is the extraction of features from texture.
For this stage, the images were converted from color to gray. After that,
for extract the texture features, functions GLCM and LBP were applied.
In this method, the images were converted into a two dimensional ma-
trix as a GLCM, where each element was the probability of getting color
intensity i and j in the neighborhood of the distance d and the angle θ
(00, 450, 900, 1350). Finally, by using the function, the features were ex-
tracted. Before calculating the function on the co-occurrence matrix,
each element of the matrix should be normalized. Data were normal-
ized by dividing each element by the total numbers of considered pixels
pairs. Haralick and Shanmugam (1973) used co-occurrence matrix for
the ﬁrst time to extract texture features of images to troubleshoot
grapefruit (Haralick and Shanmugam, 1973). However, the closer the
amount of pixels to each other, the more concentrated the main diago-
nal matrix and as compared to a simple histogram of pixels in the loca-
tion information, location data are lost and only the frequency of pixel
Nomenclature
MLP
Multi-layer Perceptron
SVM
Support Vector Machine
GLCM
Gray-Level Co-Occurrence Matrix
MSE
mean of the squared error
Trainbr
Bayesian regularization back-propagation
Trainlm
Levenberg–Marquardt back-propagation
ANN
Artiﬁcial Neural Network
BN
Bayesian Network
DT
Decision Trees
KNN
k-Nearest Neighbors
SVDD
Support Vector Machine Data Description
CI
conﬁdence interval
28
A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27–34
gray values is calculated and locations of the pixel matrix are
considered.
In this research, energy is a measurement of image homogeneity. Be-
cause the homogeneous gray level is low, the values are squared (Gong
et al., 1992). Contrast is the local variations in the pixels of an image. Dif-
ference between the brightest whites and deepest blacks in an image is
deﬁned as contrast. If the difference between these two factors is high,
the value of the factors become high and then the quality of the image
will increase. Homogeneity is deﬁned as the combination of the ele-
ments, parts and characters of the image. Correlation is the linear de-
pendence of gray levels in neighboring pixels or certain parts of the
image. If the same gray level is high, it implies that the correlation be-
tween them is high (Broomhead and Lowe, 1988). In this study, 100 im-
ages were derived from both alive and dead eggs. Fifteen features were
extracted from each image as shown in Table 1.
2.2. MLP classiﬁer
Multilayer perception (MLP) neural network with back propagation
algorithm was used to classify the ﬁsh eggs. MLP neural network is a
classiﬁer method and composed of at least three layers (Fig. 2). The
ﬁrst layer is the input layer whose size is equivalent to the number of
features intended for the classiﬁcation. There is a weight equivalent to
each input. The hidden layer is formed by some neurons. The present re-
search, evaluated 3, 5, …, 13 neurons in hidden layer. The number of
neurons in hidden layer at most cases, found out by trial and error
(Abutaleb, 1991). The output layer was supposed to include two neu-
rons since the objective of the present study was to classify ﬁsh eggs
of alive eggs with optimum output [1 0] and dead ones with optimum
output [0 1]. The transfer function of output layer was sigmoid type.
Two functions, sigmoid and hyperbolic tangent, were evaluated as
transfer function for the hidden layer as below:
out ¼
1
1 þ e−∑Fiwijþb
ð1Þ
out ¼
2
1 þ e−∑2Fiwijþb −1
ð2Þ
where, Fi, b and wij denote ith input, bias and weight of jth neuron,
respectively.
Fig. 1. The original and converted image (A and B) of a sample egg.
Table 1
Features derived from the images of ﬁsh eggs.
Feature
Symbol
Feature
Symbol
Feature
Symbol
Feature
Symbol
Contrast
F1
Mean local binary pattern
F5
Range (in the space L)
F9
Std (in the space B)
F13
Correlation
F2
Standard deviation of local binary pattern
F6
Mean (in the space A)
F10
Range (in the space b).
F14
Energy
F3
Mean (in the space L)
F7
Range (in the space A)
F11
Range (in the space B).
F15
Homogeneity
F4
Std (in the space L)
F8
Mean (in the space B)
F12
–
Fig. 2. MLP classiﬁer with three inputs and two outputs.
29
A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27–34
The optimum weights and biases in MLP classiﬁer were derived by
training functions. In this research, two functions were used: Bayesian
regularization back-propagation (Trainbr) and Levenberg–Marquardt
back-propagation (Trainlm), for the training and optimization of
network weights. Mean of the squared error (MSE) criterion was used
as the optimization index for MLP network performance:
mse ¼ 1
n
X
n
i¼1
ðTi−Pi
Þ2
ð3Þ
where, Ti and Pi represent target and predicted class, respectively. After
each training cycle, the weights of network were updated to reach min-
imize MSE (Ripley, 2007).
2.3. SVM classiﬁer
Support Vector Machine (SVM) is a classiﬁer based on statistical
learning. It uses two strategies of keeping empirical risk at a constant
value and minimizing conﬁdence interval (CI) (Vapnik, 2013). The
Fig. 3. Linear SVM classiﬁer.
Fig. 4. Flow chart of the present research.
Table 2
Comparison of means for the features.
Feature
Mean
p-Value
Feature
Mean
p-Value
Class I
Class II
Class I
Class II
F1
13,344.3
13,088.0
0.00⁎
F9
18.809
13.195
0.00⁎
F2
0.0018
−0.0006
0.16ns
F10
23.674
5.334
0.00⁎
F3
0.00001
0.00001
0.35ns
F11
1.4971
1.1556
0.00⁎
F4
0.03376
0.03351
0.00⁎
F12
20.043
14.434
0.00⁎
F5
16.2205
16.2205
0.09ns
F13
51.947
36.226
0.00⁎
F6
35.178
28.989
0.00⁎
F14
1.2642
1.0425
0.01⁎
F7
69.622
59.303
0.00⁎
F15
18.465
16.913
0.08ns
F8
0.8563
0.7860
0.213ns
⁎ Signiﬁcant at 0.01 level.
ns Not signiﬁcant.
30
A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27–34
main idea of SVM is to apply a hyperplane to separate the input patterns
into two classes. Fig. 3 shows the SVM classiﬁer with a linear hyper-
plane. As it was mentioned, in this research, two-class classiﬁcation
problem were examined.
The patterns derived from the processing of ﬁsh egg images have an
N-dimensional feature vector. The value y ∈ {−1,+1} is deﬁned for each
input vector f as:
f ¼
ff1; f2; f3; …; fm
g∈RN
ð4Þ
And for a linear SVM classiﬁer:
f f
ð Þ ¼ f:w
ð
Þ þ b
ð5Þ
where w ∈ RN and b ∈ R. The training dataset was deﬁned as:
ðy1; f1
Þ; …; yl; fl
ð
Þ; yi∈ −1; 1
f
g
ð6Þ
It can be assumed that the training set is linearly separable, whereas
the following inequalities hold valid for all members of training set:
w:fi þ b≥1 if yi ¼ 1
w:fi þ b≤−1 if yi ¼ −1
�
ð7Þ
The optimum hyperplane is unique and is derived during training
phase in order to obtain the highest margin. MATLAB 2016b software
package was used to develop SVM and MLP models. Fig. 4 shows the
total procedure of the work.
2.4. Performance assessment of SVM and MLP classiﬁers
To evaluate the performance of the model, some criteria have been
used from the literature. In this research the following criteria used to
evaluate the classiﬁers based on the number of patterns recognized cor-
rectly (TP), rejected correctly (TN) and also the number of patterns rec-
ognized incorrectly (FP) or rejected incorrectly (FN) as the following
equations:
Accuracy %
ð
Þ ¼
TP þ TN
TP þ TN þ FP þ FN � 100
ð8Þ
Precision %
ð
Þ ¼
TP
TP þ FP � 100
ð9Þ
Sensitivity %
ð
Þ ¼
TP
TP þ FN � 100
ð10Þ
F−score %
ð
Þ ¼ 2 � Sensitivity � Precision
Sensitivity þ Precision
� 100
ð11Þ
Specificity %
ð
Þ ¼
TN
TN þ FP � 100
ð12Þ
AUC ¼ 1
2 �
TP
TP þ FN þ
TN
TN þ FP
�
�
ð13Þ
YI ¼ Sensitivity− 1−Specificity
ð
Þ
ð14Þ
Table 3
The results of statistical indexes for MLP classiﬁer.
Nn
TF
Trainlm
Trainbr
Train phase
Test phase
Train phase
Test Phase
Accuracy
Precision
Accuracy
Precision
Accuracy
Precision
Accuracy
Precision
3
logsig
99.99 ± 0.06
99.99 ± 0.12
99.45 ± 1.04
99.00 ± 2.01
99.99 ± 0.06
99.99 ± 0.12
99.65 ± 0.89
99.25 ± 1.79
tansig
99.38 ± 0.08
99.97 ± 0.16
99.59 ± 0.93
99.19 ± 1.85
100 ± 0.00
100 ± 0.00
99.35 ± 1.10
98.87 ± 2.20
5
logsig
99.96 ± 0.14
99.93 ± 0.29
99.56 ± 1.05
99.10 ± 1.93
99.53 ± 0.98
99.05 ± 1.97
99.53 ± 0.98
99.05 ± 1.97
tansig
99.96 ± 0.32
99.98 ± 0.18
99.28 ± 1.14
98.60 ± 2.26
100 ± 0.00
100 ± 0.00
99.40 ± 1.07
98.80 ± 2.14
7
logsig
99.98 ± 0.10
99.96 ± 0.21
99.30 ± 1.12
98.80 ± 2.14
100 ± 0.00
100 ± 0.00
99.66 ± 0.89
99.25 ± 1.79
tansig
99.99 ± 0.06
99.99 ± 0.13
99.42 ± 1.05
98.85 ± 2.11
100 ± 0.00
100 ± 0.00
99.48 ± 1.02
98.95 ± 2.04
9
logsig
99.98 ± 0.12
99.95 ± 0.25
99.38 ± 1.08
98.75 ± 2.18
100 ± 0.00
100 ± 0.00
99.40 ± 0.89
98.80 ± 2.14
tansig
99.96 ± 0.15
99.93 ± 0.29
99.58 ± 0.94
99.15 ± 1.88
99.99 ± 0.06
98.75 ± 0.12
99.72 ± 0.78
99.45 ± 1.57
11
logsig
99.99 ± 0.06
99.99 ± 0.12
99.48 ± 1.00
99.00 ± 2.00
100 ± 0.00
100 ± 0.00
99.62 ± 0.89
99.25 ± 1.79
tansig
99.99 ± 0.06
99.99 ± 0.12
99.50 ± 1.02
99.05 ± 1.97
100 ± 0.00
100 ± 0.00
99.62 ± 0.89
99.25 ± 1.79
13
logsig
99.98 ± 0.10
99.96 ± 0.21
99.48 ± 1.02
98.95 ± 2.05
100 ± 0.00
100 ± 0.00
99.50 ± 1.00
99.00 ± 2.01
tansig
99.96 ± 0.15
99.92 ± 0.29
99.42 ± 1.05
99.15 ± 1.88
100 ± 0.00
100 ± 0.00
99.62 ± 0.89
99.25 ± 1.79
Table 4
The results of sensitivity analysis for MLP classiﬁer.
Train phase
Test phase
Accuracy
Precision
Accuracy
Precision
All
100 ± 0.00
100 ± 0.00
99.66 ± 0.89
99.25 ± 1.79
All except F1
100 ± 0.00
100 ± 0.00
99.65 ± 0.86
99.30 ± 1.30
All except F4
99.25 ± 1.05
99.72 ± 0.79
97.00 ± 2.31
97.60 ± 3.23
All except F6
100 ± 0.00
100 ± 0.00
99.65 ± 0.87
99.30 ± 1.75
All except F7
100 ± 0.00
100 ± 0.00
99.20 ± 1.17
98.40 ± 2.35
All except F9
99.96 ± 0.15
99.92 ± 0.29
99.40 ± 1.07
99.00 ± 2.02
All except F10
99.98 ± 0.12
99.95 ± 0.25
99.65 ± 0.87
99.30 ± 1.75
All except F11
100 ± 0.00
100 ± 0.00
99.60 ± 0.92
99.20 ± 1.85
Al except F12
100 ± 0.00
100 ± 0.00
99.60 ± 0.92
99.20 ± 1.85
All except F13
100 ± 0.00
100 ± 0.00
99.35 ± 1.10
98.70 ± 2.21
All except F14
100 ± 0.00
100 ± 0.00
99.65 ± 0.87
99.30 ± 1.75
F4F9F10
100 ± 0.00
100 ± 0.00
99.45 ± 1.04
98.89 ± 2.07
Table 5
The performance of MLP classiﬁer at three phases (train, test and total).
Accuracy
Precision
Sensitivity
F-score
Speciﬁcity
AUC
YI
Train
Min
100
100
100
100
100
1
1
Max
100
100
100
100
100
1
1
Mean
100
100
100
100
100
1
1
std
0
0
0
0
0
0
0
Test
Min
97.50
95.00
100
97.44
95.24
0.98
0.95
Max
100
100
100
100
100
1
1
Mean
99.45
98.90
100
99.44
98.95
0.99
0.99
std
1.04
2.08
0
1.06
1.98
0.01
0.01
Total
Min
99.50
99.00
100
99.49
99.00
0.99
0.99
Max
100
100
100
100
100
1
1
Mean
99.45
99.78
100
99.89
98.95
0.99
0.99
Std
0.20
0.42
0
0.20
1.98
0.00
0.00
31
A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27–34
3. Results and discussion
3.1. Feature selection
The number of features can be reduced to minimize the calculations
and increase the classiﬁcation speed. In this research, paired t-test was
applied for statistical comparison. In this method, the features showing
insigniﬁcant differences between alive and dead egg classes are re-
moved from the set of features (Table 2). As it can show, there are no
signiﬁcant differences (p-value N0.05) in ﬁve features (F2, F3, F5, F8,
and F15) between two classes at the 5% level. The lack of signiﬁcant dif-
ferences between the features of two classes conﬁrms that these two
classes cannot be distinguished by these features. So other 10 features
were selected for classiﬁcation.
3.2. MLP classiﬁer
MLP neural network is used as an intelligent method to separate
the ﬁsh eggs. Ten selected features (Table 2) were included as the
inputs of the MLP model. Table 3 shows the means and standard de-
viations of two performance features of the classiﬁers (accuracy and
precision) at the train and test phases. The values in Table 3 were
derived from 100 different datasets for train and test by 5-fold
cross validation method with 20 replications. Two training algo-
rithms (Trainlm and Trainbr) and two transformation functions
(logsig and tansig) were used for the neurons of the hidden layer.
Also, the number of neurons in the hidden layer was changed from
3 to 13. The value of standard deviation was unequal to zero because
the network performance at the train and test phases depended on
the datasets selected for the train phase. As it can be observed, the
best result in training algorithm (Trainlm) at both training and
test phases was derived by tansig transformation function at 11
neurons in the hidden layer. The performance comparison of two
training algorithms revealed that the Trainbr algorithm is better
Fig. 5. Dispersion of two classes of alive and dead eggs based on the three selected
variables.
100
100
99.57
99.15
95
96
97
98
99
100
101
Accuracy
Precision
(a)
Train
Test
99.48
98.96
99.57
99.15
95
96
97
98
99
100
101
Accuracy
Precision
(b)
Train
Test
100
100
99.57
99.15
95
96
97
98
99
100
101
Accuracy
Precision
(c)
Train
Test
100
100
99.57
99.15
95
96
97
98
99
100
101
Accuracy
Precision
(d)
Train
Test
Fig. 6. Results of SVM based on four types of kernel function: (a: RBF), (b: linear), (c: poly2) and (d: poly3).
Table 6
The performance of SVM-rbf classiﬁer at train, test and total phases.
Accuracy
Precision
Sensitivity
F-score
Speciﬁcity
AUC
YI
Train
Min
100
100
100
100
100
1
1
Max
100
100
100
100
100
1
1
Mean
100
100
100
100
100
1
1
std
0
0
0
0
0
0
0
Test
Min
97.5
95
100
97.47
95.23
0.98
0.95
Max
100
100
100
100
100
1
1
Mean
99.57
99.15
100
99.56
99.19
0.99
0.99
std
0.94
1.88
0
0.96
1.79
0.00
0.00
Total
Min
99.5
99
100
99.49
99.49
0.99
0.99
Max
100
100
100
100
100
1
1
Mean
99.92
99.83
100
99.91
99.91
0.99
0.99
std
0.18
0.37
0
0.18
0.37
0.00
0.00
32
A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27–34
than Trainlm at train phase because its recognition error was zero in
most cases and its results were better than Trainlm at test phase.
The best performance of Trainbr was observed by seven neurons
(in the hidden layer) with logsig transformation function. So, the
Trainbr algorithm led to a better result than Trainlm with lower
number of neurons.
3.2.1. Sensitivity analysis
At the ﬁrst step, 10 features that could effectively separate alive and
dead ﬁsh eggs were selected by statistical comparison. Then, the most
appropriate training algorithm and transformation function of neurons
in the hidden layer and their number was selected for MLP neural net-
work. At this step, the sensitivity analysis was carried out to determine
the most sensitive features (Table 4). In this table, MLP performance is
shown after the removal of the ten features (one-by-one) at the train
and test phases. If the removal of a feature had a negative impact on
the performance of the classiﬁer, it would be considered as a highly im-
portant feature for the separation of the two classes (alive and dead
eggs). So, three variables (F4, F9 and F10) were selected as the most im-
portant and effective features in the separation of ﬁsh eggs because their
exclusion from the inputs, affected the performance of the classiﬁer as
compared to the inclusion of all ten features.
Table 5 shows the minimum, mean and standard deviation of the
performance parameters for MLP neural network at train, test and
whole phases for 100 various datasets of 5-fold cross validation method.
In this section, MLP was trained by three inputs selected at sensitivity
analysis step. The results of training phase showed that MLP classiﬁer
could perfectly separate the alive and dead ﬁsh eggs by the three se-
lected features. Also the results of test phase showed that MLP had a
good performance at this phase, too. In total, mean precision of MLP
neural network was found to be 99.45%.
Fig. 5 shows the features dispersion of alive and dead ﬁsh egg classes.
Accordingly, these two classes were highly separable based on the three
selected variables.
3.3. SVM classiﬁer
In the present study, SVM model was used as another classiﬁer. Ac-
cording to the results of Table 4, three features (F4, F9 and F10) were se-
lected as the inputs of SVM. One important parameter that inﬂuences
the performance of SVM is the kernel function type. Means and standard
deviations of accuracy and precision at train and test phases are shown
for different types of kernel functions including linear, second-order
polynomial (poly2), third-order polynomial (poly3) and radial basis
function (rbf) (Fig. 6). The results showed that rbf function type has
the better performance than other function types. However, all the
three functions of rbf, poly2 and poly3 had similar mean results, but
standard deviation of rbf was lower than the other two types. Thus,
rbf was more stable and had the better generalizability. In this analysis,
linear function had the weakest performance. So, the separation of the
classes needs a non-linear function.
Table 6 shows some descriptive statistical features of SVM-rbf per-
formance parameters at three phases of train, test, and total for 100 dif-
ferent datasets of 5-fold cross validation. Similar to MLP, the results of
training phase of SVM-rbf was derived with 100% precision for all
datasets. Furthermore, results of test phase conﬁrmed the capability of
SVM. SVM results were highly similar to MLP (Table 5). So, both classi-
ﬁers were found to be equally capable for recognition and separation of
alive and dead ﬁsh eggs.
3.4. Evaluation of data size on the classiﬁer performance
To evaluate the capability and generalizability of two classiﬁers,
i.e. MLP and SVM, different sizes of datasets were used for training.
So, 80, 60, 40 and 20% of all data were randomly devoted to training
set and the rest was proportionately used for test section. So, the
models with large (80%) to small (20%) sizes of training set were
evaluated. For the evaluation, the same 100 datasets selected by 5-
fold method with 20 replications were used and the mean and stan-
dard deviation of the performance parameters were estimated at
train and test phases (Table 7). Results of train phase showed that
both classiﬁers had perfect capability because their error was zero
at train phase. The results of test phase showed that larger size of
test set will decrease the total error of prediction and no signiﬁcant
differences were observed between SVM and MLP. So, it can be con-
cluding that both SVM and MLP have high capability in separating
alive and dead eggs.
4. Conclusion and recommendation
In this paper, 15 features were selected out of 200 images of alive
and dead eggs of rainbow trout ﬁsh by image processing technique. Be-
tween them, 10 features were chosen as the effective ones by statistical
comparison of two classes. The 5-fold cross validation technique was
used with 20 replications to evaluate the performance of MLP and
SVM models. The results showed that the best choice for the classiﬁca-
tion for the ﬁsh eggs was MLP with Trainbr training algorithm and
seven neurons with logsig transformation function in hidden layer.
The results of MLP sensitivity analysis showed that with three features
(F4, F9 and F10), almost 100% classiﬁcations could be achieved. The
same features were used by SVM classiﬁcation. The rbf type was applied
as a kernel function for SVM. The results of SVM classiﬁcation showed
insigniﬁcant differences between MLP and SVM classiﬁers. Finally, the
generalizability of two classiﬁers was assessed by reducing the size of
Table 7
Evaluation of MLP and SVM with different sizes in training set.
Classiﬁer
Accuracy
Precision
Sensitivity
F-score
Speciﬁcity
AUC
YI
Train
80
MLP
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
1 ± 0.00
1 ± 0.00
SVM
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
1 ± 0.00
1 ± 0.00
60
MLP
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
1 ± 0.00
1 ± 0.00
SVM
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
1 ± 0.00
1 ± 0.00
40
MLP
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
1 ± 0.00
1 ± 0.00
SVM
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
1 ± 0.00
1 ± 0.00
20
MLP
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
1 ± 0.00
1 ± 0.00
SVM
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
100 ± 0.0
1 ± 0.00
1 ± 0.00
Test
20
MLP
99.45 ± 1.04
98.90 ± 2.08
100 ± 0.0
99.44 ± 1.06
98.95 ± 1.98
0.99 ± 0.01
0.99 ± 0.01
SVM
99.58 ± 0.94
99.15 ± 1.89
100 ± 0.0
99.56 ± 0.97
99.19 ± 1.80
0.99 ± 0.01
0.99 ± 0.02
40
MLP
99.53 ± 0.61
99.05 ± 1.22
100 ± 0.0
99.52 ± 0.62
99.07 ± 1.19
0.99 ± 0.01
0.99 ± 0.01
SVM
99.53 ± 0.61
99.05 ± 1.22
100 ± 0.0
99.52 ± 0.62
99.07 ± 1.19
0.99 ± 0.01
0.99 ± 0.01
60
MLP
99.57 ± 0.42
99.13 ± 0.84
100 ± 0.0
99.56 ± 0.42
99.15 ± 0.82
1.00 ± 0.00
0.99 ± 0.01
SVM
99.56 ± 0.42
99.13 ± 0.84
99.98 ± 0.16
99.55 ± 0.42
99.15 ± 0.82
0.99 ± 0.00
0.99 ± 0.00
80
MLP
99.49 ± 0.25
98.99 ± 0.49
100 ± 0.0
99.49 ± 0.25
99.00 ± 0.49
1.00 ± 0.0
0.99 ± 0.00
SVM
99.49 ± 0.26
99.00 ± 0.50
99.98 ± 0.24
99.48 ± 0.26
99.01 ± 0.50
0.99 ± 0.00
0.99 ± 0.01
33
A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27–34
training set. The results showed that both classiﬁers had the equally
high capability. Finally, the proposed method can play an effective role
in separating the alive and dead ﬁsh eggs. Some recommendations are
below:
1. Extracting some of the properties such as the volume and weight of
each ﬁsh egg can lead to a stronger algorithm design.
2. Designing an algorithm based on a large amount of ﬁsh and not one-
on-one can play a signiﬁcant role in the speed of the separating.
3. The design of an algorithm that does not require the removal of eggs
from water and can eliminate the noise of water in the photos should
be considered in the next researches.
Acknowledgments
Financial supports from the Ferdowsi University of Mashhad and Ag-
ricultural Sciences and Natural Resources University of Khuzestan, are
highly appreciated.
References
Abutaleb, A.S., 1991. A neural network for the estimation of forces acting on radar targets.
Neural Netw. 4 (5), 667–678.
Broomhead, D.S., Lowe, D., 1988. Radial Basis Functions, Multi-variable Functional Inter-
polation and Adaptive Networks (Retrieved from).
Cortes, C., Vapnik, V., 1995. Support-vector networks. Mach. Learn. 20 (3), 273–297.
Du, C.-J., Sun, D.-W., 2004. Recent developments in the applications of image processing
techniques for food quality evaluation. Trends Food Sci. Technol. 15 (5), 230–249.
Friedland, K., Ama-Abasi, D., Manning, M., Clarke, L., Kligys, G., Chambers, R., 2005. Auto-
mated egg counting and sizing from scanned images: rapid sample processing and
large data volumes for fecundity estimates. J. Sea Res. 54 (4), 307–316.
Gong, P., Marceau, D.J., Howarth, P.J., 1992. A comparison of spatial feature extraction al-
gorithms for land-use classiﬁcation with SPOT HRV data. Remote Sens. Environ. 40
(2), 137–151.
Haralick, R.M., Shanmugam, K., 1973. Textural features for image classiﬁcation. IEEE Trans.
Syst. Man Cybern. 3 (6), 610–621.
Hu, J., Li, D., Duan, Q., Han, Y., Chen, G., Si, X., 2012. Fish species classiﬁcation by color, tex-
ture and multi-class support vector machine using computer vision. Comput. Elec-
tron. Agric. 88, 133–140.
Kim, J.-S., Hong, K.-S., 2009. Color–texture segmentation using unsupervised graph cuts.
Pattern Recogn. 42 (5), 735–750.
Kiratiratanapruk, K., Watcharapinchai, N., Methasate, I., Sinthupinyo, W., 2014. Silkworm
Eggs Detection and Classiﬁcation Using Image Analysis (Paper presented at the Com-
puter Science and Engineering Conference (ICSEC), 2014 International).
Kunrui, X., Xi, L., Qiaohua, W., Meihu, M., 2015. Online automatic grading of salted eggs
based on machine vision. Int. J. Agric. Biol. Eng. 8 (1), 35–41.
Mitchell, R.S., Sherlock, R.A., Smith, L.A., 1996. An investigation into the use of machine
learning for determining oestrus in cows. Comput. Electron. Agric. 15 (3), 195–213.
Morris, C.W., Autret, A., Boddy, L., 2001. Support vector machines for identifying organ-
isms—a comparison with strongly partitioned radial basis function networks. Ecol.
Model. 146 (1), 57–67.
Omid, M., Soltani, M., Dehrouyeh, M.H., Mohtasebi, S.S., Ahmadi, H., 2013. An expert egg
grading system based on machine vision and artiﬁcial intelligence techniques. J. Food
Eng. 118 (1), 70–77.
Powell, J., Krotosky, S., Ochoa, B., Checkley, D., Cosman, P., 2003. Detection and Identiﬁca-
tion of Sardine Eggs at Sea Using a Machine Vision System Oceans 2003. Celebrating
the Past… Teaming Toward the Future (IEEE Cat. No. 03CH37492).
Ripley, B.D., 2007. Pattern Recognition and Neural Networks. Cambridge University Press.
Robotham, H., Bosch, P., Gutiérrez-Estrada, J.C., Castillo, J., Pulido-Calvo, I., 2010. Acoustic
identiﬁcation of small pelagic ﬁsh species in Chile using support vector machines and
neural networks. Fish. Res. 102 (1), 115–122.
Sengur, A., 2008. Wavelet transform and adaptive neuro-fuzzy inference system for color
texture classiﬁcation. Expert Syst. Appl. 34 (3), 2120–2128.
Shaﬁee, S., Minaei, S., Moghaddam-Charkari, N., Barzegar, M., 2014. Honey characteriza-
tion using computer vision system and artiﬁcial neural networks. Food Chem. 159,
143–150.
Soltani, M., Omid, M., 2015. Detection of poultry egg freshness by dielectric spectroscopy
and machine learning techniques. LWT Food Sci. Technol. 62 (2), 1034–1042.
Storbeck, F., Daan, B., 2001. Fish species recognition using computer vision and a neural
network. Fish. Res. 51 (1), 11–15.
Vapnik, V., 2013. The Nature of Statistical Learning Theory. Springer Science & Business
Media.
Zhao, J., Lin, H., Chen, Q., Huang, X., Sun, Z., Zhou, F., 2010. Identiﬁcation of egg's freshness
using NIR and support vector data description. J. Food Eng. 98 (4), 408–414.
Zion, B., Doitch, N., Ostrovsky, V., Alchanatis, V., Segev, R., Barki, A., Karplus, I., 2006. Orna-
mental Fish Fry Counting by Image Processing. Agricultural Research Organization,
Bet Dagan.
34
A. Rohani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 27–34
