ArtiÔ¨Åcial Intelligence in the Life Sciences 3 (2023) 100060 
Contents lists available at ScienceDirect 
ArtiÔ¨Åcial Intelligence in the Life Sciences 
journal homepage: www.elsevier.com/locate/ailsci 
Research Article 
Combining molecular and cell painting image data for mechanism of action 
prediction 
Guangyan Tian a , 1 , Philip J Harrison a , 1 , ‚àó , Akshai P Sreenivasan a , b , Jordi Carreras-Puigvert a , 
Ola Spjuth a 
a Department of Pharmaceutical Biosciences, Uppsala University, Sweden 
b Department of Medical Sciences, Uppsala University, Sweden 
a r t i c l e 
i n f o 
Keywords: 
Bioinformatics 
Convolutional neural networks 
Cheminformatics 
Deep learning 
Machine learning 
a b s t r a c t 
The mechanism of action (MoA) of a compound describes the biological interaction through which it produces 
a pharmacological eÔ¨Äect. Multiple data sources can be used for the purpose of predicting MoA, including com- 
pound structural information, and various assays, such as those based on cell morphology, transcriptomics and 
metabolomics. In the present study we explored the beneÔ¨Åts and potential additive/synergistic eÔ¨Äects of com- 
bining structural information, in the form of Morgan Ô¨Ångerprints, and morphological information, in the form 
of Ô¨Åve-channel Cell Painting image data. For a set of 10 well represented MoA classes, we compared the perfor- 
mance of deep learning models trained on the two datasets separately versus a model trained on both datasets 
simultaneously. On a held-out test set we obtained a macro-averaged F1 score of 0.58 when training on only 
the structural data, 0.81 when training on only the image data, and 0.92 when training on both together. Thus 
indicating clear additive/synergistic eÔ¨Äects and highlighting the beneÔ¨Åt of integrating multiple data sources for 
MoA prediction. 
Introduction 
Mechanism of action (MoA) refers to the biological interaction 
through which a potentially therapeutic small-molecule compound pro- 
duces a pharmacological eÔ¨Äect, such as the speciÔ¨Åc proteins that the 
compound targets and the pathways that it modulates. Uncovering the 
MoA of a compound, although a signiÔ¨Åcant challenge in chemical bi- 
ology [1] , provides extremely useful information for lead compounds 
prior to clinical trials and for identifying possible toxicity or side-eÔ¨Äects 
[2] . 
A variety of diÔ¨Äerent data sources can be used to capture infor- 
mation on a compounds MoA, including structural information from 
the compound, gene expression from transcriptomics data, protein in- 
formation from proteomics data, and metabolic enzyme activity from 
metabolomics data [2] . Recently, cell morphology data from high- 
content imaging has proven useful for this task [3] . A signiÔ¨Åcant beneÔ¨Åt 
of microscopy based image assays is that they can be scaled to high- 
throughput much more easily and less expensively than transcriptomics 
and metabolomics based assays [4] . Cell imaging also provides infor- 
mation at the single-cell resolution as opposed to condensing the output 
down to measures of population averages [5] . In terms of throughput 
‚àó Corresponding author. 
E-mail addresses: philip.harrison@farmbio.uu.se (P.J. Harrison), ola.spjuth@farmbio.uu.se (O. Spjuth) . 
1 These authors contributed equally to this work. 
and eÔ¨Éciency the L1000 [6] gene expression assay is perhaps currently 
the only feasible alternative to image-based assays [7] for large scale 
data generation to sustain predictive modeling. 
Microscopy imaging can be used to capture the changes in cell 
morphology that arise when a cell culture is treated with a chemi- 
cal compound [2] . The Cell Painting assay uses Ô¨Çuorescent dyes to 
paint the cells in multi-well plates as "richly as possible" to illuminate 
morphological changes in eight broadly relevant organelles and cellu- 
lar sub-compartments (nuclei, mitochondria, cytoskeleton, Golgi appa- 
ratus, plasma membrane, cytoplasmic RNA, nucleoli and endoplasmic 
reticulum) using six Ô¨Çuorescent dyes imaged in Ô¨Åve channels [7] . 
A comparative study for library enrichment reported better predic- 
tive power for High-throughput screening performance using Cell Paint- 
ing as opposed to L1000 gene expression proÔ¨Åling [8] . Whereas, for pre- 
dicting MoA, Way et al. [9] found that L1000 outperformed Cell Paint- 
ing, but that there was complementarity, i.e. some MoAs were better 
predicted by one of the assays compared to the other. A related study 
by Lapins and Spjuth [10] compared Cell Painting, L1000 and chemical 
structure based predictors, and found MoA classes that were predicted 
better by each of the three predictors relative to the other two, support- 
ing the idea of a likely beneÔ¨Åt through combining these diÔ¨Äerent data 
https://doi.org/10.1016/j.ailsci.2023.100060 
Received 8 December 2022; Received in revised form 5 January 2023; Accepted 30 January 2023 
Available online 17 February 2023 
2667-3185/¬© 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) 
G. Tian, P.J. Harrison, A.P. Sreenivasan et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 3 (2023) 100060 
sources. Another study predicting MoA [11] , based on data from the 
ExCAPE database, which compared models built using image based fea- 
tures to those built using chemical structure descriptors, provided fur- 
ther support for the complementarity of these two data types, whereby 
the models performed somewhat diÔ¨Äerently at an individual class level. 
Besides comparing models built using diÔ¨Äerent types of data it is 
also possible to combine the datasets and analyze them simultaneously 
to search for additive or synergistic eÔ¨Äects. For predicting cytotoxicity 
and proliferation Seal et al. [12] compared Random Forest models us- 
ing Cell Painting image based features, molecular Ô¨Ångerprints, and com- 
bining both data sources. They found that the models based on image 
features outperformed those based on molecular Ô¨Ångerprints, but the 
combined models performed best in ten out of twelve cases. Another 
study predicting the bio-activity of approximately 16,000 compounds 
[13] , found that models based on features derived from Cell Painting 
images outperformed those based on chemical structure proÔ¨Åles from 
graph convolutional networks (GCNs, [14] ), but that the fusion of the 
two datasets gave a gain in performance. 
Most traditional image analysis pipelines, including those mentioned 
above, Ô¨Årst extract morphological features from the Ô¨Çuorescence stained 
images, including measures of size, shape, intensity and texture from 
the labeled cellular compartments, most often using the CellProÔ¨Åler 
[15] software package, and subsequently apply machine learning meth- 
ods to the extracted features for the predictive task at hand [16] . These 
methods require an accurate segmentation algorithm to identify the cel- 
lular compartments prior to feature extraction. However, when convolu- 
tional neural networks (CNNs) are used on the raw images, features are 
extracted in an automatic data-driven fashion, circumventing the need 
for cell segmentation and potentially providing better predictive per- 
formance [3,17] . For instance, Hofmarcher et al. [18] found that CNNs 
trained on Cell Painting image data, for predicting activity labels for 
over 10,000 compounds, performed signiÔ¨Åcantly better than fully con- 
nected neural networks trained on pre-computed image features. The 
Ô¨Çexibility of the architectural choices for neural networks also provides 
a simple means of combining multiple data sources into the same mod- 
eling framework [19] . 
In the work presented in this manuscript we Ô¨Årst compared a variety 
of traditional machine learning and deep learning models for the predic- 
tion of MoA based on chemical structure data for up to 20 MoA classes. 
Subsequently, based on a set of 10 MoA classes, we compared the per- 
formance of the best deep learning model at the compound structural 
level to a state-of-the-art CNN trained on Cell Painting image data for 
the same set of compounds. We selected the best deep learning based 
compound structure model so that we could Ô¨Ånally train a joint model 
for the MoA prediction based on utilizing both structural and image data 
as input. Example Cell Painting images for the 10 MoA classes can be 
seen in Fig. 1 . To the best of our knowledge our work represents the Ô¨Årst 
combination of Ô¨Åve channel Cell Painting image data and molecular Ô¨Ån- 
gerprint data trained in an end-to-end fashion to predict MoA, wherein 
the raw images, as opposed to features derived from the images, were 
used as input to the models. 
Materials and methods 
Data 
Molecular data 
Molecular data (Corsello et al. [20] ), in the form of SMILES strings 
collected and processed by the Broad Institute, was used in this study. 
The cleansed dataset contains approximately 5500 compounds covering 
1300 MoA classes, but most MoAs have very few compounds associated 
with them. The number of compounds that each MoA has is shown in 
Fig. 2 . As our models should perform well at the compound level, namely 
to predict the MoA for unseen compounds, we used a subset of the data, 
the top 20 MoAs (i.e. the 20 MoAs having the most compounds associ- 
ated with them). 
Image data 
The 5-channel Cell Painting image data was produced by the Phar- 
maceutical Bioinformatics Research Group at Uppsala University. We 
selected image data from 10 well-represented MoAs (MoAs that we pre- 
sumed would be reasonably distinguishable and that had a suÔ¨Écient 
number of compounds associated with them). The ten MoAs were AT- 
Pase inhibitors (ATPase-i, number of compounds, ùëõ = 18 ); Aurora ki- 
nase inhibitors (AuroraK-i, ùëõ = 20 ); HDAC inhibitors (HDAC-i, ùëõ = 33 ); 
HSP inhibitors (HSP-i, ùëõ = 24 ); JAK inhibitors (JAK-i, ùëõ = 21 ); PARP 
inhibitors (PARP-i, ùëõ = 21 ); protein synthesis inhibitors (Prot.Synth.- 
i, ùëõ = 23 ); retinoid receptor agonists (Ret.Rec.Ag, ùëõ = 19 ); topoiso- 
merase inhibitors (Topo.-i, ùëõ = 32 ); and tubulin polymerization in- 
hibitors (Tub.Pol.-i, ùëõ = 20 ). In total we had 12,582 images for 231 com- 
pounds. The compounds were administered to U2OS cells in 384 well 
plates at a dose of 10 micro-molar. Images at a resolution of 2160 x 
2160 pixels were taken across 9 sites in each well and each compound 
was replicated 6 times. The compounds were distributed across 18 plates 
using PLAID (Plate Layouts using ArtiÔ¨Åcial Intelligence Design, [21] ). 
Data preprocessing for models based on molecular data 
We explored usin multi-layer perceptrons (MLPs), graph convolu- 
tional networks (GCNs), convolutional neural networks (CNNs), long 
short-term memory networks (LSTMs, with and without data augmen- 
tation), and traditional machine learning algorithms (those operating 
on tabular data) to predict MoA, and we pre-processed the data for each 
model. See the Modeling section below for further details on the models 
explored. 
For the MLP and traditional machine learning algorithms, we used 
Morgan Fingerprints as input. Since SMILES strings are sequential they 
cannot be processed directly by these models. We used the RDKit pack- 
age [22] to generate the Morgan Ô¨Ångerprints (binary vectors, 2048 
bits) [23] . For the GCN, which requires the adjacency matrix and the 
node matrix as input, we applied Spektral [24] and NetworkX packages 
[25] to convert the SMILES strings into graphs. For the CNN we gener- 
ated the feature matrix for each SMILES string based on the approach 
of Hirohara et al. [26] . Initially, we selected 42 chemical features to 
prepare the feature matrix of each SMILES string based on the selected 
chemical features. Secondly, due to the blank parts of the feature ma- 
trix resulting from inconsistent lengths of the SMILES, we applied zero 
padding to maintain uniform dimensions of the feature matrix. For the 
recurrent neural network, the LSTM, we utilized SMILES pair encoding 
[27] to tokenize the chemical structure data, so we obtained a series of 
numbers (tokens) representing the SMILES. Similarly to the CNN case, 
we also used zero padding to ensure that the lengths of all tokens were 
identical. 
Data preprocessing for models based on image data 
The 5 channels in the Cell Painting image data were standardized to 
remove plate-level eÔ¨Äects based on the mean and standard deviation of 
the pixel intensities in the control DMSO wells in each plate. The images 
were resized from their original dimension down to 256 x 256 pixels. 
A quality control run on the data to detect saturation and blur in the 
images found no saturation issues (such as Ô¨Åbers across the Ô¨Åeld of view) 
but did detect some blurred images. However, given that a common data 
augmentation strategy for deep learning models is to purposefully blur 
the images we decided not to remove these blurred images from the 
dataset. 
Data augmentation and data splitting 
Data augmentation generates additional data based on the existing 
data and improves the generalizability of models. For the image based 
models we used Ô¨Çipping, 90 degree rotations and shift scale rotations to 
augment the data. However, for the compound structure based models 
data augmentation was only possible for the LSTM. As the LSTM is a 
sequence-based model that requires tokens as input, data augmentation 
2 
G. Tian, P.J. Harrison, A.P. Sreenivasan et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 3 (2023) 100060 
Fig. 1. Example Cell Painting images for the 10 MoA classes and the DMSO data used for standardization. The row titles give the compound names for the selected 
images with the MoA abbreviation in parenthesis, where i stands for inhibitor and Ag for agonist. 
3 
G. Tian, P.J. Harrison, A.P. Sreenivasan et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 3 (2023) 100060 
Fig. 2. Histogram representing the compound counts per MoA for diÔ¨Äerent binning intervals. Note that the range of the interval for the Ô¨Ånal bin is larger than the 
others. 
is feasible as slightly diÔ¨Äerent tokens can be produced by randomized 
SMILES [28] . 
For splitting the data at the compound-level into training, valida- 
tion and test sets we used stratiÔ¨Åcation based on the proportion of com- 
pounds for each MoA. We split out 10% of the data for the Ô¨Ånal held- 
out test set. StratiÔ¨Åed splitting for the remaining data was performed 
nine times (nine shuÔ¨Ñes) for the SMILES data in the initial comparison 
and Ô¨Åve times (Ô¨Åve shuÔ¨Ñes) for the image data and the corresponding 
SMILES subset. In each case 80% of the data was used for training and 
10% for validation. 
Modeling 
Compound structure based models 
We explored the following deep learning models for the prediction 
of MoA using chemical structure data: MLP, GCN, CNN, and LSTM with 
and without data augmentation. For the deep learning models we de- 
termined the optimal architectures and parameters through model ex- 
ploration and parameter tuning on the validation sets. The MLP is a 
basic artiÔ¨Åcial neural network [29] that includes fully connected input, 
hidden, and output layers. Our MLP model contained one input layer, 
one hidden layer with dropout ( ùëù = 0 . 85 ), and one Ô¨Ånal prediction layer. 
GCNs are a subset of GNNs [30] that can process non-Euclidean data, 
such as graphs with nodes and edges [14] . Our GCN model included 
input layers for the adjacency matrix and the node matrix followed by 
three convolution layers with dropout ( ùëù = 0 . 5 ), one global attention 
pooling layer and one Ô¨Ånal prediction layer. Our CNN model contained 
one convolution layer, one max pooling layer with dropout ( ùëù = 0 . 8 ), one 
Ô¨Çattening layer with dropout ( ùëù = 0 . 8 ), and one Ô¨Ånal prediction layer. 
Our LSTM model included an embedding layer, a bidirectional LSTM 
layer, a dropout layer ( ùëù = 0 . 96 ) and a Ô¨Ånal prediction layer. For the 
LSTM with data augmentation, we adjusted the degree of augmentation 
to ensure that each MoA had approximately 1000 SMILES in the aug- 
mented training set. 
We used the Adam optimizer [31] , sparse categorical cross-entropy 
as the loss function, and validation loss as the metric for early stopping. 
To accommodate for imbalance of classes we applied class weighting in 
the loss functions to train the models. 
We also explored machine learning algorithms that operate on tab- 
ular data (in contrast to the deep neural networks described above). 
The more traditional machine learning models have shown compet- 
itive performance with deep learning models when dataset sizes are 
relatively small [32] . For instance, Jiang et al. [33] showed that four 
descriptor-based models outperformed four graph-based models on sev- 
eral benchmark datasets. We examined Ô¨Åve individual machine learning 
algorithms and four ensemble algorithms. The individual algorithms in- 
cluded random forests [34] , light gradient boosting machines [35] , cat 
boost [36] , k-nearest neighbors classiÔ¨Åers [37] , and logistic regression 
[38] . The ensemble algorithms included bagging [39] , stacking [40] , 
voting [41] , and adaboost [42] . 
Cell morphology based model 
We applied the state-of-the-art CNN model EÔ¨ÉcientNet [43] to pre- 
dict MoA based on the 5-channel Cell Painting image data. EÔ¨ÉcientNet 
applies a compound scaling method to adjust width, depth, and resolu- 
Table 1 
F1 scores on the test set for the main three models explored for predicting the 
10 selected MoAs. MLP used the chemical structure data, EÔ¨ÉcientNet used the 
image data, and the Global model (see Fig. 3 ) used both data formats. The results 
are based on the averages across the Ô¨Åve shuÔ¨Ñes of the training and validation 
data. 
MLP 
EÔ¨ÉcientNet 
Global model 
ATPase-i 
0.64 
0.58 
0.68 
AuroraK-i 
0.55 
0.48 
0.71 
HDAC-i 
0.98 
0.89 
0.99 
HSP-i 
0.45 
0.83 
0.95 
JAK-i 
0.08 
0.85 
0.94 
PARP-i 
0.51 
0.96 
0.98 
Prot.Synth.-i 
0.54 
0.98 
0.99 
Ret.Rec.Ag 
1.00 
0.98 
1.00 
Topo.-i 
0.68 
0.64 
0.97 
Tub.Pol.-i 
0.37 
0.92 
0.97 
Accuracy 
0.62 
0.81 
0.93 
Macro average F1 
0.58 
0.81 
0.92 
Weighted average F1 
0.61 
0.81 
0.93 
tion simultaneously, achieving competitive performance in image-based 
tasks with less training time and fewer parameters. We adopted the 
EÔ¨ÉcientNetB1 architecture and used the AdamW optimizer [44] with 
weighted sparse categorical cross entropy as the loss function. 
Global model 
For our global model trained on the data for the 10 selected MoA 
classes, we integrated the MLP (our best performing deep learning model 
based on the compound structure data) and EÔ¨ÉcientNet (for the image 
data). The models were Ô¨Årst trained separately and then combined and 
their weights Ô¨Ånetuned. The architecture of our global model is shown 
in Fig. 3 . 
Results 
Summaries of the performance of the traditional and deep learning 
models for the compound structure based models for the 20 MoA subsets 
are shown in Fig. 4 . These Ô¨Ågures present the average F1 scores across 
the nine shuÔ¨Ñes of the training and validation data as well as the results 
of randomization tests performed to assess the level of signiÔ¨Åcance in the 
performance diÔ¨Äerences. We applied Bonferroni corrections [45] to the 
p-values to account for the fact that we were performing several compar- 
isons. The performances of the traditional machine learning algorithms 
were all quite comparable, however there were larger diÔ¨Äerences for 
the deep learning models compared. The best performing deep learning 
model was the MLP and the worst was the CNN; we note that the MLP 
performed on par with the best traditional machine learning models. 
Test set F1 scores for the 10 selected MoAs (averaged across Ô¨Åve shuf- 
Ô¨Çes of the training and validation data) comparing the MLP, trained on 
the compound structure data, EÔ¨ÉcientNet, trained on the Cell Paint- 
ing image data, and the global model, trained on both data sources are 
shown in Table 1 . Our test set contained 24 compounds. This test set was 
the same for each of the shuÔ¨Ñes of the training and validation data. For 
the MLP the F1 scores were very variable across the MoA classes, ranging 
from 0.08 for the JAK inhibitor test compounds to 1.00 for the Retinoid 
4 
G. Tian, P.J. Harrison, A.P. Sreenivasan et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 3 (2023) 100060 
Fig. 3. The architecture of the global model with two input paths, one for the Cell Painting image data and one for the chemical structure data. 
Fig. 4. A). Comparison of macro-averaged F1 scores on the test set of the traditional machine learning models for the top 20 MoAs (i.e. the MoAs that were best 
represented in the data in terms of the number of compounds they had). B). Comparison of macro-averaged F1 scores on the test set of the deep learning models 
for the top 20 MoAs. C). Randomization test with Bonferroni correction of macro-averaged F1 scores on the test set of top 20 MoAs. The results are based on the 
averages across the nine shuÔ¨Ñes of the training and validation data. 
receptor agonist compounds. For EÔ¨ÉcientNet the results were somewhat 
more stable, ranging from 0.48 for the Aurora kinase inhibitors to 0.98 
for both the Protein synthesis inhibitors and the Retinoid receptor ag- 
onists. For the global model the results were even more stable, rang- 
ing from 0.68 for the ATPase inhibitors to 1.00 for the Retinoid recep- 
tor agonists. Our global model, achieving a macro-averaged F1 score of 
0.92, revealed a clear additive/synergistic eÔ¨Äect with an increase in F1 
score of 0.11. The three diÔ¨Äerent models were all signiÔ¨Åcantly diÔ¨Äerent 
from one another at the 5% signiÔ¨Åcance-level based on randomization 
tests with Bonferroni corrected p-values. The predictive performance of 
the models for each of the test compounds is summarized in Table S1 
(Supplementary materials). We also show this comparison graphically 
in Fig. 5 in which we have highlighted the compounds NKP-1339 and 
amonaÔ¨Åde, showing a very pronounced synergistic eÔ¨Äect. 
In light of the high variability in the test performances for the MLP 
Ô¨Åtting to the compound structure data we further explored the structural 
properties of the compounds in our dataset using DataWarrior [46] . The 
compounds‚Äô SMILES strings were used as input to DataWarrior and for 
5 
G. Tian, P.J. Harrison, A.P. Sreenivasan et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 3 (2023) 100060 
Fig. 5. Comparison of the prediction rates for the three models for each compound: A). MLP, trained solely on the chemical structure data, versus the Global model, 
trained on both the chemical structure and Cell Painting image data; B). EÔ¨ÉcientNet, trained solely on the image data, versus the Global model; C). EÔ¨ÉcientNet 
versus MLP; D). ‚ÄôGOOD‚Äô cluster contained compounds that possessed a prediction rate above 0.97 in panels A-C. The compounds NKP-1339 and amonaÔ¨Åde have 
been highlighted in green boxes in panels A-C as they showed a greater synergistic eÔ¨Äect than the other compounds. (For interpretation of the references to colour 
in this Ô¨Ågure legend, the reader is referred to the web version of this article.) 
the analyses we performed we used the default parameter settings. In 
Figure S1A (Supplementary materials) we show a neighborhood anal- 
ysis where compounds with at least one structurally similar neighbor 
have connecting lines. These structurally connected compounds are iso- 
lated in Figure S1B (Supplementary materials) and their compound ID 
numbers are shown. The names for these compounds and their SMILES 
strings are available on our GitHub repository (see Data and code avail- 
ability). Although the groupings tend to show compounds belonging to 
the same MoA class, there are several unconnected compounds. In Fig- 
ure S2 (Supplementary materials) we show the distributions for the com- 
pounds, grouped by their MoA classes, for a variety of physico-chemical 
properties predicted by DataWarrior. We also highlight in this Ô¨Ågure the 
six test set compounds that were poorly predicted by our MLP model (see 
Table S1 in the Supplementary materials). From this we can see that in 
some cases these poorly predicted compounds have physico-chemical 
properties in the tails of the distributions for their MoA classes. This 
is most evident for the property cLogS, a measure of aqueous solubil- 
ity. The two JAK inhibitor compounds in our test set (curcumol and 
CEP-33779), both of which were predicted poorly, are each at opposite 
extremes of the distribution for cLogS. The compounds NMS-873, NKP- 
1339 and CYT-997 were also the least soluble for their MoA classes. 
Discussion 
We have introduced a novel and eÔ¨Écient approach for MoA pre- 
diction, which combines both Cell Painting image data and chemical 
structure data (in the form of Morgan Ô¨Ångerprints). Similarly to the 
study predicting cytotoxicity and proliferation [12] mentioned earlier 
we found that image based models outperformed those based on Mor- 
gan Ô¨Ångerprints and that integrating both data sources further boosted 
the performance. However, Lapins and Spjuth [10] found that chemical 
structure based models for MoA prediction were generally better than 
either L1000 or Cell Painting based models (note however that they used 
features derived from the images as opposed to the raw images them- 
6 
G. Tian, P.J. Harrison, A.P. Sreenivasan et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 3 (2023) 100060 
selves as model input). Chemical structure data (such as that obtained 
from Morgan Ô¨Ångerprints) can suÔ¨Äer from "Activity CliÔ¨Äs", whereby a 
small change in structure can result in a large diÔ¨Äerence in bio-activity, 
highlighting the need to supplement chemical structure data with addi- 
tional sources of information [2] , such as the Cell Painting image data 
used in the current study. 
It should be noted that the Cell Painting assay was performed on 
a single cancer cell line (U2OS). Although performing MoA and target 
identiÔ¨Åcation studies using cancer cell lines as proxy is well-accepted 
[47,48] , there is the possibility that using a diÔ¨Äerent cancer (or non- 
cancer) cell line, could yield slightly diÔ¨Äerent results. Nevertheless, 
given that the experiment was executed in a controlled manner, and 
that all cells were treated equally, we are conÔ¨Ådent in the robustness of 
our results. 
Similarly, the drug screen in this study was performed at 10uM for 
all compounds. This is a concentration typically used in drug screens to 
ensure a cellular response. However, given that the compounds in this 
work could have diÔ¨Äerent potency, a dose response would have perhaps 
aided a more accurate identiÔ¨Åcation of the compounds‚Äô activity. 
Due to data limitations our test set had only two to four compounds 
per MoA. The test-level predictive performance under such conditions 
may suÔ¨Äer if by chance any of these compounds happened to be outliers 
for their class. Based on our compound level analysis using DataWarrior 
it appears that this may have been the case for our two JAK inhibitor test 
compounds, thus potentially explaining the low F1 score for the MLP for 
this MoA. 
However, a few compounds were better predicted by the chemical 
structure based model, relative to the image based model. Perhaps the 
main disadvantage of image data such as Cell Painting is that not all 
compounds will necessarily produce a morphological change or the mor- 
phological eÔ¨Äects may be very subtly and potentially masked by unac- 
counted for technical variations within and between plates during image 
capturing [2] . However, in the current study, to reduce potential bias 
caused by positional eÔ¨Äects in the micro-well plates, the compounds and 
controls were distributed over the plates using PLAID and we standard- 
ized the images across the plates based on the control/DMSO wells. It is 
also possible that the compound does produce a morphological change 
but not in any of the cellular compartments or organelles captured using 
the Cell Painting assay. Another possibility is that the dose applied was 
not suÔ¨Écient to produce a morphological change. 
Concerning the traditional machine learning methods we explored 
for the chemical structure data, the ensemble methods outperformed the 
individual methods. Similarly, when combining a model based on mul- 
tiple inputs, with separate modeling paths that come together to make a 
Ô¨Ånal prediction, we can potentially achieve better results than the mod- 
els built on just one of the data categories. In this study, we showed 
this type of additive/synergistic eÔ¨Äect by combining MLP for chemical 
structure data and EÔ¨ÉcientNet for image data for MoA prediction. 
Although it was somewhat surprising that for our models based on 
only the chemical descriptors, the simplest deep learning architecture, 
the MLP, outperformed the more complex networks architectures ex- 
plored, a similar result has been obtained in a previous study [49] per- 
forming drug target prediction on a large benchmark dataset from the 
ChEMBL database. In our MLP architecture, we used an unconvention- 
ally high dropout rate to alleviate the overÔ¨Åtting problem as a result 
of the scarcity of chemical structure data. We also tested other possi- 
ble architectures, such as reducing the dropout rate and increasing the 
number of hidden layers, with fewer neurons in each layer. However, 
these modiÔ¨Åcations did not improve the model performance. 
It should also be mentioned that the purpose of the current study 
was to compare the accuracy of models trained on morphological and 
structural data, and that the domain of the models hence limit their 
applicability outside of this scope (i.e. for making predictions when a 
test compound‚Äôs MoA does not belong to any of those on which the 
model was trained). This is due to the fact that the predictions of neural 
network models are neither probabilistic nor well-calibrated [50] , and 
will always make a prediction of the most likely class even if all classes 
should be predicted with low probability. We are currently developing 
methods to Ô¨Åll these gaps using what we refer to as Predictive Target 
ProÔ¨Åles (PTP) using well-calibrated conformal predictors [51,52] . 
Predicting the MoA of a compound can beneÔ¨Åt greatly from the inter- 
action of multiple sources of data [2] . Various studies [9,10,13,53] have 
shown that image and transcriptomics assays contain both overlapping 
and distinct cell state information. Thus, an even better predictive model 
than our Ô¨Ånal one could potentially be achieved with the additional inte- 
gration of transcriptomics data. Further, other types of chemical struc- 
ture representations such as 3D descriptors could be explored. In the 
present study, for the image based model and the combined model, we 
used a set of ten well represented MoA classes and a widely established 
2D descriptor for representing chemistry. In future work we will explore 
the predictive ability of these models across a wider range of classes 
whilst accounting for potential polypharmacological eÔ¨Äects. Again the 
conformal prediction method mentioned above will likely prove useful 
for this purpose. Contrary to previous belief, polypharmacology, where 
a compound concurrently engages with multiple targets or processes, is 
the rule rather than the exception in biology [19] . 
Conclusions 
In this work we explored the fusion of chemical structure and cell 
morphology data for the purpose of mechanism of action prediction. To 
the best of our knowledge our work represents the Ô¨Årst combination of 
molecular Ô¨Ångerprint data and Ô¨Åve-channel Ô¨Çuorescence Cell Painting 
image data, trained using deep learning in an end-to-end fashion, to pre- 
dict mechanism of action. Furthermore, for improved model Ô¨Çexibility 
and performance, we used the raw input images, as opposed to featured 
derived from them, as input to the models. We found a clear and signiÔ¨Å- 
cant improvement in predictive performance for models trained on both 
input types simultaneously, as opposed to in isolation, with an increase 
in F1 score of 0.11, highlighting the beneÔ¨Åt of combining data sources 
for mechanism of action prediction. 
Data and code availability 
The image data to accompany this paper has been uploaded to 
Figshare ( https://doi.org/10.17044/scilifelab.21378906 ). The python 
code to accompany the paper is available on GitHub ( https://github. 
com/pharmbio/CP- Chem- MoA ). Also in the GitHub repository is the 
csv Ô¨Åle compound_list_10_MoAs which gives the compound names, their 
SMILES strings and their reference ID numbers (1:231) used in our anal- 
yses. 
Funding 
This project was supported by the Swedish Research Council 
(grants 2020-03731 and 2020-01865), FORMAS (grant 2018-00924), 
the Swedish Foundation for Strategic Research (grant BD15-0008SB16- 
0046), and the Swedish strategic research program eSSENCE. 
Data availability 
Links to the data and code are provided at the end of our paper. 
Acknowledgments 
This project was supported by the Swedish Research Council 
(grants 2020-03731 and 2020-01865), FORMAS (grant 2018-00924 ), 
the Swedish Foundation for Strategic Research (grant BD15-0008SB16- 
0046), and the Swedish strategic research program eSSENCE. We also 
thank Jonne Rietdijk and Polina Georgiev for performing the Cell Paint- 
ing assay and Anders Larsson for IT infrastructure assistance. 
7 
G. Tian, P.J. Harrison, A.P. Sreenivasan et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 3 (2023) 100060 
Supplementary material 
Supplementary material associated with this article can be found, in 
the online version, at doi: 10.1016/j.ailsci.2023.100060 . 
References 
[1] Hight SK, Clark TN, Kurita KL, McMillan EA, Bray W, Shaikh AF, Haeckl FPJ, 
Carnevale-Neto F, La S, Lohith A, et al. High-throughput functional annota- 
tion of natural products by integrated activity proÔ¨Åling. BioRxiv 2022:748129. 
doi: 10.1101/748129 . 
[2] Trapotsi M-A, Hosseini-Gerami L, Bender A. Computational analyses of mechanism 
of action (MoA): data, methods and integration. RSC Chem Biol 2022;3(2):170‚Äì200 . 
[3] Kensert A, Harrison PJ, Spjuth O. Transfer learning with deep convolutional neural 
networks for classifying cellular morphological changes. SLAS Discov Adv Life Sci 
R&D 2019;24(4):466‚Äì75 . 
[4] Caicedo JC, Singh S, Carpenter AE. Applications in image-based proÔ¨Åling of pertur- 
bations. Curr Opin Biotechnol 2016;39:134‚Äì42 . 
[5] Feng Y, Mitchison TJ, Bender A, Young DW, Tallarico JA. Multi-parameter pheno- 
typic proÔ¨Åling: using cellular eÔ¨Äects to characterize small-molecule compounds. Nat 
Rev Drug Discov 2009;8(7):567‚Äì78 . 
[6] Peck D, Crawford ED, Ross KN, Stegmaier K, Golub TR, Lamb J. A method for high- 
-throughput gene expression signature analysis. Genome Biol 2006;7(7):1‚Äì6 . 
[7] Bray M-A, Singh S, Han H, Davis CT, Borgeson B, Hartland C, et al. Cell painting, a 
high-content image-based assay for morphological proÔ¨Åling using multiplexed Ô¨Çuo- 
rescent dyes. Nat Protoc 2016;11(9):1757‚Äì74 . 
[8] Wawer MJ, Li K, Gustafsdottir SM, Ljosa V, Bodycombe NE, Marton MA, 
et al. Toward performance-diverse small-molecule libraries for cell-based pheno- 
typic screening using multiplexed high-dimensional proÔ¨Åling. Proc Natl Acad Sci 
2014;111(30):10911‚Äì16 . 
[9] Way GP, Natoli T, Adeboye A, Litichevskiy L, Yang AX, Lu X, Caicedo J, Ci- 
mini BA, Karhohs K, Logan DJ, et al. Morphology and gene expression proÔ¨Ål- 
ing provide complementary information for mapping cell state. bioRxiv 2021. 
doi: 10.1101/2021.10.21.465335 . 
[10] Lapins M, Spjuth O. Evaluation of gene expression and phenotypic proÔ¨Åling data 
as quantitative descriptors for predicting drug targets and mechanisms of action. 
Biorxiv 2019:580654. doi: 10.1101/580654 . 
[11] Trapotsi M-A, Mervin LH, Afzal AM, Sturm N, Engkvist O, Barrett IP, et al. Compari- 
son of chemical structure and cell morphology information for multitask bioactivity 
predictions. J Chem Inf Model 2021;61(3):1444‚Äì56 . 
[12] Seal S, Yang H, Vollmers L, Bender A. Comparison of cellular morphological de- 
scriptors and molecular Ô¨Ångerprints for the prediction of cytotoxicity-and prolifera- 
tion-related assays. Chem Res Toxicol 2021;34(2):422‚Äì37 . 
[13] Moshkov N, Becker T, Yang K, Horvath P, Dancik V, Wagner BK, Clemons PA, 
Singh S, Carpenter AE, Caicedo JC. Predicting compound activity from 
phenotypic proÔ¨Åles and chemical structures. bioRxiv 2022:2020‚Äì112. 
doi: 10.1101/2020.12.15.422887 . 
[14] Scarselli F, Gori M, Tsoi AC, Hagenbuchner M, Monfardini G. The graph neural 
network model. IEEE Trans Neural Netw 2008;20(1):61‚Äì80 . 
[15] Carpenter AE, Jones TR, Lamprecht MR, Clarke C, Kang IH, Friman O, et al. Cell- 
ProÔ¨Åler: image analysis software for identifying and quantifying cell phenotypes. 
Genome Biol 2006;7(10):1‚Äì11 . 
[16] Grys BT, Lo DS, Sahin N, Kraus OZ, Morris Q, Boone C, et al. Machine learning and 
computer vision approaches for phenotypic proÔ¨Åling. J Cell Biol 2017;216(1):65‚Äì71 . 
[17] Gupta A, Harrison PJ, Wieslander H, Pielawski N, Kartasalo K, Partel G, Solorzano L, 
Suveer A, Klemm AH, Spjuth O, et al. Deep learning in image cytometry: a review. 
Cytometry Part A 2019;95(4):366‚Äì80 . 
[18] Hofmarcher M, Rumetshofer E, Clevert D-A, Hochreiter S, Klambauer G. Accurate 
prediction of biological assays with high-throughput microscopy images and convo- 
lutional networks. J Chem Inf Model 2019;59(3):1163‚Äì71 . 
[19] Chandrasekaran SN, Ceulemans H, Boyd JD, Carpenter AE. Image-based proÔ¨Åling 
for drug discovery: due for a machine-learning upgrade? Nat Rev Drug Discov 
2021;20(2):145‚Äì59 . 
[20] Corsello SM, Bittker JA, Liu Z, Gould J, McCarren P, Hirschman JE, et al. The drug 
repurposing hub: a next-generation drug library and information resource. Nat Med 
2017;23(4):405‚Äì8 . 
[21] Rodr√≠guez MAF, Carreras-Puigvert J, Spjuth O. Designing microplate layouts using 
artiÔ¨Åcial intelligence. bioRxiv 2022. doi: 10.1101/2022.03.31.486595 . 
[22] Landrum G. Rdkit documentation. Release 2013;1(1‚Äì79):4 . 
[23] Cereto-Massagu√© A, Ojeda MJ, Valls C, Mulero M, Garcia-Vallv√© S, Pujadas G. Molec- 
ular Ô¨Ångerprint similarity search in virtual screening. Methods 2015;71:58‚Äì63 . 
[24] Grattarola D, Alippi C. Graph neural networks in TensorFlow and keras with spektral 
[application notes]. IEEE Comput Intell Mag 2021;16(1):99‚Äì106 . 
[25] Kaur M, Kaur H. Implementation of enhanced graph layout algorithm for visualizing 
social network data using NetworkX library. Int J Adv ResComput Sci 2017;8(3) . 
[26] Hirohara M, Saito Y, Koda Y, Sato K, Sakakibara Y. Convolutional neural network 
based on SMILES representation of compounds for detecting chemical motif. BMC 
Bioinformatics 2018;19(19):83‚Äì94 . 
[27] Li X, Fourches D. SMILES pair encoding: a data-driven substructure tokenization 
algorithm for deep learning. J Chem Inf Model 2021;61(4):1560‚Äì9 . 
[28] Bjerrum E.J. Smiles enumeration as data augmentation for neural network modeling 
of molecules. arXiv preprint arXiv: 1703.07076 2017. 
[29] Murtagh F. Multilayer perceptrons for classiÔ¨Åcation and regression. Neurocomputing 
1991;2(5-6):183‚Äì97 . 
[30] Kipf T.N., Welling M.. Semi-supervised classiÔ¨Åcation with graph convolutional net- 
works. arXiv preprint arXiv: 1609.02907 2016. 
[31] Kingma D.P., Ba J. Adam: a method for stochastic optimization. arXiv preprint 
arXiv: 1412.6980 2014. 
[32] Wang P, Fan E, Wang P. Comparative analysis of image classiÔ¨Åcation algorithms 
based on traditional machine learning and deep learning. Pattern Recognit Lett 
2021;141:61‚Äì7 . 
[33] Jiang D, Wu Z, Hsieh C-Y, Chen G, Liao B, Wang Z, et al. Could graph neural networks 
learn better molecular representation for drug discovery? A comparison study of 
descriptor-based and graph-based models. J Cheminform 2021;13(1):1‚Äì23 . 
[34] Breiman L. Random forests. Mach Learn 2001;45(1):5‚Äì32 . 
[35] Ke G, Meng Q, Finley T, Wang T, Chen W, Ma W, et al. LightGBM: a highly eÔ¨Écient 
gradient boosting decision tree. Adv Neural Inf Process Syst 2017;30 . 
[36] Prokhorenkova L, Gusev G, Vorobev A, Dorogush AV, Gulin A. CatBoost: unbiased 
boosting with categorical features. Adv Neural Inf Process Syst 2018;31 . 
[37] Keller JM, Gray MR, Givens JA. A fuzzy k-nearest neighbor algorithm. IEEE Trans 
Syst Man Cybern 1985(4):580‚Äì5 . 
[38] LaValley MP. Logistic regression. Circulation 2008;117(18):2395‚Äì9 . 
[39] Breiman L. Bagging predictors. Mach Learn 1996;24(2):123‚Äì40 . 
[40] Pavlyshenko B. Using stacking approaches for machine learning models. In: 2018 
IEEE Second international conference on data stream mining & processing (DSMP). 
IEEE; 2018. p. 255‚Äì8 . 
[41] Dietterich TG. Ensemble methods in machine learning. In: International workshop 
on multiple classiÔ¨Åer systems. Springer; 2000. p. 1‚Äì15 . 
[42] Schapire RE. Explaining adaboost. In: Empirical inference. Springer; 2013. p. 37‚Äì52 . 
[43] Tan M, Le Q. EÔ¨ÉcientNet: rethinking model scaling for convolutional neural net- 
works. In: International conference on machine learning. PMLR; 2019. p. 6105‚Äì14 . 
[44] Loshchilov I., Hutter F.. Decoupled weight decay regularization. arXiv preprint 
arXiv: 1711.05101 2017. 
[45] Bland JM, Altman DG. Multiple signiÔ¨Åcance tests: the Bonferroni method. BMJ 
1995;310(6973):170 . 
[46] Sander T, Freyss J, von KorÔ¨Ä M, Rufener C. DataWarrior: an open-source program for 
chemistry aware data visualization and analysis. J Chem Inf Model 2015;55(2):460‚Äì
73. doi: 10.1021/ci500588j . 
[47] Lin A, Giuliano CJ, Palladino A, John KM, Abramowicz C, Yuan ML, et al. OÔ¨Ä-target 
toxicity is a common mechanism of action of cancer drugs undergoing clinical trials. 
Sci Transl Med 2019;11(509):eaaw8412. doi: 10.1126/scitranslmed.aaw8412 . 
[48] Gon »∫ alves E, Segura-Cabrera A, Pacini C, Picco G, Behan FM, Jaaks P, et al. 
Drug mechanism-of-action discovery through the integration of pharmacological and 
CRISPR screens. Mol Syst Biol 2020;16(7):e9405. doi: 10.15252/msb.20199405 . 
[49] Mayr A, Klambauer G, Unterthiner T, Steijaert M, Wegner JK, Ceulemans H, et al. 
Large-scale comparison of machine learning methods for drug target prediction on 
chEMBL. Chem Sci 2018;9(24):5441‚Äì51 . 
[50] Wieslander H, Harrison PJ, Skogberg G, Jackson S, Frid »® n M, Karlsson J, et al. 
Deep learning with conformal prediction for hierarchical analysis of large-scale 
whole-slide tissue images. IEEE J Biomed Health Inform 2021;25(2):371‚Äì80. 
doi: 10.1109/JBHI.2020.2996300 . 
[51] Lampa S, Alvarsson J, Arvidsson Mc Shane S, Berg A, Ahlberg E, Spjuth O. Predict- 
ing oÔ¨Ä-target binding proÔ¨Åles with conÔ¨Ådence using conformal prediction. Front 
Pharmacol 2018;9. doi: 10.3389/fphar.2018.01256 . 
[52] Vovk V, Gammerman A, Shafer G. Algorithmic learning in a random world. 
1st ed. Springer Publishing Company, Incorporated; 2010 . ISBN 1441934715, 
9781441934710 
[53] Haghighi M, Singh S, Caicedo JC, Carpenter AE. High-dimensional gene expression 
and morphology proÔ¨Åles of cells across 28,000 genetic and chemical perturbations. 
bioRxiv 2021. doi: 10.1101/2021.09.08.459417 . 
8 
