ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Contents lists available at ScienceDirect 
ArtiÔ¨Åcial Intelligence in the Life Sciences 
journal homepage: www.elsevier.com/locate/ailsci 
Research Article 
ClassiÔ¨Åcation of JAK1 Inhibitors and SAR Research by Machine Learning 
Methods 
Zhenwu Yang 1 , Yujia Tian 1 , Yue Kong 3 , Yushan Zhu 2 , Aixia Yan 1 , ‚àó 
1 State Key Laboratory of Chemical Resource Engineering, Department of Pharmaceutical Engineering, P.O. Box 53, Beijing University of Chemical Technology, 15 
BeiSanHuan East Road, Beijing 100029, P. R. China 
2 National Energy R&D Center for BioreÔ¨Ånery, College of Life Science and Technology, Beijing University of Chemical Technology, Beijing 100029, P. R China 
3 Hyper-Dimension Insight Pharmaceuticals Ltd. Room 511, Block A, No. 2 C, DongSanHuan North Road, ChaoYang District, Beijing, P. R. China 
a r t i c l e 
i n f o 
Keywords: 
Deep neural networks (DNN) 
Janus kinase 1 (JAK1) inhibitor 
Molecular modeling 
Structure-activity relationship 
Substructure analysis 
a b s t r a c t 
Janus kinase 1 (JAK1) is a key regulator of gene transcription, inhibition of JAK1 is an intervention for many 
diseases including rheumatoid arthritis and Crohn‚Äôs disease. In this study, we collected a dataset containing 
2982 JAK1 inhibitors, characterized molecules by MACCS Ô¨Ångerprints and Morgan Ô¨Ångerprints. We used support 
vector machine (SVM), decision tree (DT), random forest (RF) and extreme gradient boosting tree (XGBoost) 
algorithms to build 16 traditional machine learning classiÔ¨Åcation models. Additionally, we utilized deep neural 
networks (DNN) to develop four deep learning models. The best model (Model 3B) built by RF and Morgan 
Ô¨Ångerprints achieved the accuracy (ACC) of 93.6% and Mathews correlation coeÔ¨Écient (MCC) of 0.87 on the 
test set. Furthermore, we made structure‚Äìactivity relationship (SAR) analyses for JAK1 inhibitors, based on the 
output from the random forest models. After analyzing the important keys of two types of Ô¨Ångerprints, it was 
observed that some substructures such as pyrazole, pyrrolotriazolopyrimidine and pyrazolopyrimidine appeared 
frequently in highly active JAK1 inhibitors. 
Introduction 
The JAK family proteins, as non-receptor protein tyrosine kinases, 
play a vital role in both immune cells and hematopoietic cells. They are 
also involved in cell growth, survival, development and diÔ¨Äerentiation 
[1] . To date, four members of this family have been identiÔ¨Åed (JAK1, 
JAK2, JAK3 and TYK2) [2 , 3] , which transduce signaling from cytokine 
receptors by phosphorylation and subsequent activation of signal trans- 
ducers and activators of transcription (STATs) [1] . The JAK/STAT signal 
pathway regulated by JAKs is a key regulator of gene transcription and 
it is also known to be activated by more than Ô¨Åfty diÔ¨Äerent cytokines 
receptors, receiving signals from pro-inÔ¨Çammatory cytokines, inÔ¨Çam- 
matory cytokines, hematopoietic cell growth factors and metabolic cy- 
tokines. Depending on the cytokines receptor that get activated, diÔ¨Äer- 
ent JAK/STAT pathways get stimulated [4] . Consequently, JAK inhibi- 
tion has been proposed as a potential therapeutic intervention for vari- 
ous myeloproliferative and inÔ¨Çammatory diseases, including myelopro- 
liferative neoplasms (MPNs), rheumatoid arthritis (RA), psoriasis and in- 
Ô¨Çammatory bowel disease (IBD) [5] . In addition, some researchers have 
suggested that persistent activation of JAK1, JAK2 and STAT3 causes 
the proliferation of cancer cell lines [6] . Biochemical and genetic stud- 
ies have shown that JAK1 is the most broadly used JAK. In vitro studies 
‚àó Corresponding author. 
E-mail address: yanax@mail.buct.edu.cn (A. Yan) . 
using JAK1-deÔ¨Åcient cells demonstrated its critical role in the signal 
transduction mediated by type I and type II IFN (e.g.IFN- ùõº/ ùõΩ and IFN- ùõæ) 
as well as IL-10. Moreover, JAK1 is involved in signaling downstream of 
cytokines that utilize the ùõæc receptor subunit including IL-2, IL-4, IL-7, 
IL-9, IL-15 and IL-21 and regulates a key group of pro-inÔ¨Çammatory cy- 
tokines, including IL-6 and others that utilize the gp130 subunit such as 
IL-11, leukemia inhibitory factor (LIF), oncostatin M (OSM), ciliary neu- 
rotrophic factor and G-CSF [7 , 8] . Therefore, it is important to develop 
new eÔ¨Äective JAK1 inhibitors for the treatment of certain inÔ¨Çamma- 
tions, autoimmune diseases and cancer. 
As shown in Table 1 , the US Food and Drug Administration (FDA) 
approved Ruxolitinib in 2011, 2014 and 2019 for the treatment of 
intermediate/high-risk myeloÔ¨Åbrosis (MF) [9] , hydroxyurea (HU) in- 
suÔ¨Éciency or intolerable polycythemia vera (PV) [10] and steroid- 
refractory (SR) acute graft-versus-host disease (GVHD) [11] , EMA ap- 
proved it for the treatment of PV in 2015. Phase III trials based on Rux- 
olitinib in the treatment of atopic dermatitis (AD) [12] have also been 
carried out in North America and Europe. Tofacitinib is a pan-JAK in- 
hibitor that was Ô¨Årst used to treat rheumatoid arthritis (RA) [13] . It 
has been approved successively in the United States and Japan, and 
is currently recognized all over the world. Recently, Tofacitinib has 
been approved for the treatment of Psoriatic arthritis (PsA) [14] by 
various international regulatory authorities, including the FDA, EMA, 
https://doi.org/10.1016/j.ailsci.2022.100039 
Received 11 April 2022; Received in revised form 2 June 2022; Accepted 6 June 2022 
Available online 8 June 2022 
2667-3185/¬© 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Table 1 
Approved drugs of JAK1 and promising JAK1 inhibitors under clinical trials. 
Drug a 
Structure b 
Status c 
Diseases d 
Ruxolitinib (INC424) 
FDA Approved 
FDA Approved, EU Approved 
FDA Approved 
Phase III 
MF [9] 
PV [10] 
GVDH [11] 
AD [12] 
Tofacitinib (CP690,550) 
FDA Approved, Japan Approved 
FDA Approved, EMA Approved, NICE Approved 
Phase III 
Phase III 
RA [13] 
PsA [14] 
UC [15] 
AS [16] 
Baricitinib (INCB28050) 
FDA Approved, EMA Approved 
Phase II 
RA [17 , 18] 
SLE [26] 
Upadacitinib (ABT494) 
FDA Approved, EMA Approved 
RA [19 , 20] 
Filgotinib (GLPG0634) 
EU Approved, Japan Approved 
Phases III 
RA [21] 
UC [22] 
Itacitinib (INCB039110) 
Phase I 
Phase II 
aGVHD [23] 
cHL [24] 
PF-06700841 
Phase II 
Psoriasis [25] 
Solcitinib (GSK2586184) ‚àó 
Phase II 
SLE [27] 
( continued on next page ) 
2 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Table 1 ( continued ) 
Drug a 
Structure b 
Status c 
Diseases d 
PF-04965842 
Phase III 
AD [28] 
aThe name of the drug, ‚àó means that the drug has been stopped for further development. 
bStructural formula of the drug. 
cThe development stage of the drug. FDA: US Food and Drug Administration; EMA: European Medicines Agency; EU: European Union; NICE: UK 
National Institute of Health and Clinical Excellence. 
dGVHD: graft-versus-host disease; aGVHD: acute graft-versus-host disease; RA: rheumatoid arthritis; AA: alopecia areata; UC: ulcerative colitis; AD: 
atopic dermatitis; SLE: systemic lupus erythematosus; cHL: classical Hodgkin lymphoma; MF: MyeloÔ¨Åbrosis; PV: polycythemia vera; PsA: Psoriatic 
arthritis; AS: ankylosing spondylitis. 
and UK National Institute of Health and Clinical Excellence (NICE). 
At the same time, Phase III trials for ulcerative colitis (UC) [15] and 
ankylosing spondylitis (AS) [16] are in progress. In addition to Tofac- 
itinib, Baricitinib, Upadacitinib and Filgotinib have been approved for 
the treatment of RA [17‚Äì21] in the United States, the European Union 
and Japan. Moreover, Baricitinib, Filgotinib, Itacitinib, Solcitinib, PF- 
06700841 and PF-04965842 are undergoing clinical Phase I to Phase 
III trials, and their indications include UC [22] , acute graft-versus-host 
disease (aGVHD) [23] , classic Hodgkin‚Äôs lymphoma (cHL) [24] , Psori- 
asis [25] , SLE [26 , 27] and AD [28] . However, the failure of a trial of 
Solcitinib on SLE led to a halt in clinical trials. 
The exploration of structure-activity relationship (SAR) is one of the 
most important tasks in medicinal chemistry. SAR analysis provides a 
basis for key structural features to determine molecular activity, and also 
provides a basis for screening clinically-oriented candidate molecules 
[29] . Quantitative structure-activity relationship (QSAR) is a chemical 
data analysis method that predicts molecular properties by establishing 
a linear or non-linear relationship between the descriptors calculated 
from molecular structures and the biological activity values of these 
molecules [30] . Some machine learning (ML) methods were applied to 
construct SAR and QSAR models, such as decision tree (DT) [31] , ran- 
dom forest (RF) [32] , support vector machine (SVM) [33] , extreme gra- 
dient boosting (XGBoost) [34] , and artiÔ¨Åcial neural networks (ANNs) 
[35] . Molecular descriptors were used to characterize the physical and 
chemical properties or structural characteristics of compounds. In mod- 
eling, diÔ¨Äerent descriptors needed to be tried to achieve the best eÔ¨Äect 
of the model. 
Several published computational works on JAK1 inhibitors provided 
analysis of the structural requirements of the selected series for JAK1 
inhibitory activity. Sarithamol et al. [36] . collected 100 pyrazole deriva- 
tives, established a 3D-QSAR comparison model of JAK1 and JAK2, Q 2 
of 0.8243 and 0.6917 were obtained on the test set. Itteboina et al. 
[37] established a 3D-QSAR model of 30 imidazopyrrolopyridine deriva- 
tives, and evaluated the performance of the model with 13 molecules as 
a test set. 
The q loo 2 of 0.504, r ncv 2 of 0.948, and the r pred 2 of 0.52 were ob- 
tained for the CoMFA model; The q loo 
2 of 0.518, r ncv 
2 of 0.951, and 
the r pred 2 of 0.53 obtained for the CoMSIA model. Subsequently, the 
team established a 3D-QSAR model of 60 JAK1 inhibitor molecules [7] , 
and veriÔ¨Åed the model with 25 molecules. In the end, Q 2 of 0.525 and 
0.534, r pred 2 of 0.52 and 0.54 were obtained. Keretsu et al. [4] con- 
ducted a 3D-QSAR study on 51 pyrrolopyrimidin-4-amine derivatives 
and established a ligand-based CoMFA model (Q 2 = 0.5, R 2 = 0.96) and 
a receptor-based CoMFA model (Q 2 = 0.78, R 2 = 0.98). All of the above 
works are based on small data set to build a model. In this work, we 
build our models on a data set fo 2982 inhibitors, the largest data set to 
date. 
The purpose of this study is to construct JAK1 inhibitor 
highly/weakly activity classiÔ¨Åcation models, then analyze its structure- 
activity relationship. Five machine learning algorithms including sup- 
port vector machine (SVM), decision tree (DT), random forest (RF), ex- 
treme gradient boosting (XGBoost) and deep learning algorithm (DNN) 
[38] were used to establish classiÔ¨Åcation models of JAK1 inhibitors. 
MACCS molecular Ô¨Ångerprints [39] and Morgan molecular Ô¨Ångerprints 
[40] were used to characterize the molecular structures during mod- 
eling. Additionally, a SAR analysis of important Ô¨Ångerprints was per- 
formed to identify important sub-structural features of highly active 
JAK1 inhibitors. 
Materials and methods 
Dataset 
We collected information of JAK1 inhibitors from three databases of 
CHEMBL [41] , Reaxys [42] , sciÔ¨Ånder [43] and 65 pieces of literature 
[44‚Äì108] . The biological activity of each inhibitor is characterized by 
IC 50 . 
We checked the inhibitors (enzymatic method to measure activity, 
and the receptor was homo sapiens single protein) downloaded from the 
database one by one, and then we removed duplicate data to construct 
the JAK1 inhibitor dataset. 
For the above dataset, the IC 50 values of these inhibitors ranged from 
0.07 nM to 50000 nM. We referenced three studies to deÔ¨Åne compounds 
[6 , 109 , 110] . We deleted the compounds with IC 50 values between 50 
nM and 100 nM, then deÔ¨Åned compounds with IC 50 less than 50 nM 
as highly active, and compounds with IC 50 greater than 100 nM as 
weakly active. As a result, the whole dataset was composed of 2982 
JAK1 inhibitors, including 1712 highly active and 1270 weakly active 
inhibitors. The whole dataset is shown in JAK1_dataset.csv in the Sup- 
plementary materials. 
Splitting the dataset into a training set and a test set 
We used two methods to divide the dataset into a training set and a 
test set. (1) random splitting: we utilized the random split function in 
scikit-learn [111] module of Python to split the dataset into a training 
set contained 2236 inhibitors (1279 highly active and 957 weakly active 
inhibitors) and a test set with 746 inhibitors (433 highly active and 313 
weakly active inhibitors). (2) self-organizing map (SOM) [112] : we used 
SOM to split 2982 inhibitors by the SONNIA software [113] , the detailed 
process according to the following steps: 
(I) The inhibitors in each neuron were split separately. 
(II) For highly active neurons and weakly active neurons, if there is 
only one inhibitor in the neuron, then this inhibitor was assigned 
3 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Figure 1. SOM clustering results (36 ‚àó 54), the input are 166-bit MACCS de- 
scriptors. Highly active inhibitors, which are represented with red; weakly ac- 
tive inhibitors, which are represented with blue; conÔ¨Çict neurons accommodate 
both highly active inhibitors and weakly active inhibitors, and represented with 
black. 
into the training set; if there were two inhibitors in the neuron, 
then one of them was randomly split into the training set, the 
other was split into the test set; if there were three inhibitors 
in the neuron, then two inhibitors were randomly split into the 
training set and one was split into the test set; when the number 
of inhibitors in the neuron was greater than or equal to four, 
the part which can be divisible by four was split at a ratio of 
3:1, the remaining part was processed according to the above 
steps. 
(III) For conÔ¨Çicting neurons, we individually split the highly active 
inhibitors and weakly active inhibitors according to the second 
step. 
Through the above process of SOM splitting, we obtained a training 
set with 2219 inhibitors (highly: weakly = 1277: 942), and a test set 
containing 763 inhibitors (highly: weakly = 435: 328). The distribution 
of SOM result is shown in Figure 1 . 
Molecular Ô¨Ångerprint 
Molecular Ô¨Ångerprinting is a molecular characterization method that 
transforms a molecular structure into a bitstream by judging whether the 
molecule has a speciÔ¨Åc substructure. In this study, we used two types of 
molecular Ô¨Ångerprints, MACCS (166 bits) and Morgan Ô¨Ångerprint (4096 
bits) to characterize molecular structures, both of which were calculated 
by the RDKit [114] toolkit in Python. 
Extended connection Ô¨Ångerprints (ECFPs) were a kind of Morgan Ô¨Ån- 
gerprints, which were ring Ô¨Ångerprints based on the ECFP algorithm (a 
variant of the Morgan algorithm) [40] . According to diÔ¨Äerent needs, 
by changing the radius and bits, Morgan Ô¨Ångerprints can theoretically 
characterize molecules of any size and any number of molecular fea- 
tures. As the radius and bits increase, the eÔ¨Äective information con- 
tained in Morgan Ô¨Ångerprints will gradually increase. However, as the 
number of bits increase, Morgan Ô¨Ångerprints will become very redun- 
dant sparse matrices (most of the information is 0). Therefore, it is nec- 
essary to select the appropriate radius and bits according to molecules 
with diÔ¨Äerent characteristics. This feature of Morgan Ô¨Ångerprints pro- 
vides a high degree of freedom for Ô¨Ångerprint analysis. In this study, 
we calculated 4096-bit Morgan Ô¨Ångerprints with a radius of four. For 
Figure 2. (a) Fingerprint analysis process; (b) Tree graph, take the root node 
as an example: ‚ÄòMorgan 1772 < = 0.5‚Äô means to determine whether molecules 
in the next node contain the Morgan 1772 key, ‚ÄòTrue‚Äô means molecules in the 
next node do not contain the Morgan 1772 key and ‚ÄòFalse‚Äô means molecules 
in the next node contain the Morgan 1772 key; ‚ÄòGini‚Äô represents Gini index, 
which determines the split of the tree; ‚ÄòSamples‚Äô represents the number of data 
that meet the judgment conditions; The left number in ‚ÄòValues‚Äô represents the 
number of weakly activity molecules, the right number in ‚ÄòValues‚Äô represents 
the number of high activity molecules. 
the two molecular Ô¨Ångerprints, we calculated the variance on each bit, 
then removed bits with variance less than the average variance. The 
purpose was to avoid invalid information due to too consistent infor- 
mation on a certain position. The Ô¨Ånal molecular Ô¨Ångerprints used for 
modeling were 80 bits (MACCS) and 958 bits (Morgan Ô¨Ångerprints), 
respectively. 
Method of Ô¨Ångerprint analysis 
In order to analyze the descriptors more accurately, we used all 
the compounds to train the model, calculated the information entropy 
[31] of each descriptor according to the RF model and ranked the impor- 
tance of each descriptor. Additionally, we visualized the decision tree 
model using sklearn.tree.export_graphviz [111] , and analyzed the Ô¨Ån- 
gerprints on important leaf nodes in the tree graph. The process and 
the tree graph are shown in Figure 2 . The color of the nodes in the 
Figure 2 represents the purity of the compounds. The more weakly ac- 
tive compounds inside a node, the closer the color is to a cool tone; 
Conversely, the more highly active compounds inside a node, the closer 
the color is to a warmer tone We performed SAR analysis on each de- 
scriptor based on the ranking results as we did in our previous work 
[115] . We only focus on some Ô¨Ångerprints with the highest impor- 
tance. For a leaf node at an end, we Ô¨Årst determined the path be- 
tween it and the root node, and then determined the presence or ab- 
sence of Ô¨Ångerprints represented by each passing node along the path. 
According to these information, the compounds in the leaf node can 
be obtained from the dataset. Based on the Ô¨Ångerprints of these com- 
pounds, we summarized their scaÔ¨Äolds and found representative com- 
pounds among them. These scaÔ¨Äolds were composed of diÔ¨Äerent com- 
bined form of the same Ô¨Ångerprints may have diÔ¨Äerent eÔ¨Äects on the 
biological activity of the compounds. Descriptor importance ranking re- 
sults of the top 80 MACCS Ô¨Ångerprints and top the 100 Morgan Ô¨Ån- 
gerprints are displayed in Table S1 and Table S2 in the Supplementary 
materials. 
Chemical Diversity 
To evaluate the chemical diversity of the dataset, We calculated 
the SlogP and molecular weight of all compounds, The SlogP distribu- 
4 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Figure 3. Visualization of SlogP and molecular weight for all compounds. The 
darker the color, the denser the compound distribution in the area. 
tion of these molecules was between -0.07 and 7.44, and the molec- 
ular weight distribution was between 184.24 and 671.80. The visual- 
ization results are shown in Figure 3 . The wide distribution of these 
two properties also indicated the expansive chemical space of our 
dataset. 
We measured the diversity by Murcko ScaÔ¨Äold of our dataset. Mur- 
cko ScaÔ¨Äold is an eÔ¨Äect way of gathering together common scaÔ¨Äolds and 
can be really useful to check for diversity and for clustering. We obtained 
the main scaÔ¨Äold of each molecule in our dataset by removing its side 
chains (any nonring, nonlinker atoms are deÔ¨Åned as side chain atoms) 
[116] . Then, we obtained the Murcko scaÔ¨Äold by using the MurckoScaf- 
fold module in RDKit [114] . As a result, there were 1057 main scaÔ¨Äolds 
and 485 Generic Murcko scaÔ¨Äolds in our dataset (listed in Ô¨Åles named 
‚ÄúMain_ScaÔ¨Äold.csv ‚Äù, and ‚ÄúGeneric_Murcko_ScaÔ¨Äold.csv ‚Äù in supplemen- 
tary materials). These observation can illustrate the chemical diversity 
of our dataset. 
In addition, we calculated the Tanimoto index [117] between the 
compounds in the training and test sets divided by each method based 
on ECFPs of length 1024. The Tanimoto index is shown in formula (1), 
and the histogram of the calculation results is shown in Figure 4 . where 
ùëâ ùëñ and ùëâ ùëó are the descriptors describing the two molecular features, re- 
spectively. 
ùëá ùëéùëõùëñ (ùëâ ùëñ , ùëâ ùëó 
) = 
|||ùëâ ùëñ ‚à© ùëâ ùëó |||
||ùëâ ùëñ || + |||ùëâ ùëó ||| ‚àí |||ùëâ ùëñ ‚à© ùëâ ùëó |||
(1) 
The Tanimoto index represents the similarity of two sets, It can be 
seen from Figure 4 that the Tanimoto similarity of the compounds in 
the training set and the test set divided by the random method or the 
SOM method are all concentrated in the range of less than 0.6, account- 
ing for 98.25% and 98.19, respectively. The similarity of compounds in 
the training set and test set divided by this method is very low. There- 
fore, it is objective to evaluate the model performance according to the 
prediction on test set. 
Machine learning algorithms 
The algorithms involved in this research include: support vector ma- 
chine (SVM), decision tree (DT), random forest (RF), extreme gradient 
boosting tree (XGBoost) and deep neural networks (DNN) were used to 
build classiÔ¨Åcation models. 
Figure 4. Frequency histogram of Tanimoto index of compounds between train- 
ing set and test set based on ECFPs Ô¨Ångerprints. (a) Frequency histogram of 
Tanimoto index of compounds between training set and test set under random 
method, (b) Frequency histogram of Tanimoto index of compounds between 
training set and test set under SOM method. The percentages represent the fre- 
quency of Tanimoto index with Tanimoto index greater than 0.6 and less than 
0.6, respectively. 
Decision tree 
A decision tree (DT) is a tree structure in which each internal node 
represents a test on an attribute, each branch represented a test output, 
each leaf node represented a category. Training a decision tree includes 
two processes: the growth phase and the pruning phase. The set splitting 
criteria for the growth phase are shown in formulas (2) and (3) 31 : 
ùê∫ùëñùëõùëñ = 
ùêæ 
‚àë
ùëò =1 
ÃÇùëù ùëò 
(1 ‚àí ÃÇùëù ùëò 
)
(2) 
ùê∂ùëüùëúùë†ùë† ùëíùëõùë°ùëüùëúùëùùë¶ = 
ùêæ 
‚àë
ùëò =1 
ÃÇùëù ùëò ùëôùëúùëî ÃÇùëù ùëò 
(3) 
Formula (2) is the Gini index, and formula (3) is the cross-entropy 
index, where ÃÇùëù ùëò is the fraction of samples of each class ùëò associated to 
a given subset ùëÜ ùëñ . 
Œ± = 
ùëíùëüùëü (ùëá ùëñ +1 , ùëã ‚Ä≤) ‚àí ùëíùëüùëü (ùëá ùëñ , ùëã ‚Ä≤)
ùëô ùëíùëéùë£ùëíùë† (ùëá ùëñ 
) ‚àí ùëô ùëíùëéùë£ùëíùë† (ùëá ùëñ +1 
)
(4) 
Formula (4) [31] is the pruning criterion, where ùëíùëüùëü ( ùëá , ùëã ‚Ä≤) is the 
error rate of tree ùëá on the set of observations ùëã ‚Ä≤, ùëôùëíùëéùë£ùëíùë† ( ùëá ) is the number 
5 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
of leaves of tree ùëá . After the evaluation of all the collapsed sub-trees 
of ùëá ùëñ , the sub-tree that gets the lowest value of ùõº is taken as ùëá ùëñ +1 . ùõº
is the complexity parameter. In this study, the parameters that the DT 
algorithm needs to be optimized are criterion, max_features, max_depth , 
and max_leaf_nodes . We used the grid optimization method to Ô¨Ånd the 
optimal parameter combination in the four-dimensional space. 
Random forest 
Random forest (RF) is an ensemble method based on bagging [118] . 
It randomly builds and integrates multiple decision tree to create a for- 
est structure. In order to classify the dataset, each decision tree is given 
a classiÔ¨Åcation, the score of each tree is calculated to make the Ô¨Ånal de- 
cision. The process was repeated many times and the Ô¨Ånal prediction is 
a function of each prediction derived from diÔ¨Äerent constituent decision 
tree [32] . In this study, the parameters that need to be optimized for the 
RF algorithm are criterion, max_features, max_depth, max_leaf_nodes and 
n_estimators . We used the grid optimization method to Ô¨Ånd the optimal 
parameter combination in the Ô¨Åve-dimensional space. 
Support vector machine 
Support vector machine (SVM) used sum function to transform data 
into high-dimensional space and established the optimal separation hy- 
perplane [33] . 
ùêæ (ùë• 1 , ùë• 2 
) = ùúô(ùë• 1 
)ùëá ùúô(ùë• 2 
)
(5) 
ùêø ùëù = 1 
2 
‚Äñ‚Äñ ‚Éóùë§ ‚Äñ‚Äñ ‚àí 
ùë° 
‚àë
ùëñ =1 
ùõºùëñ ùë¶ ùëñ 
( ‚Éóùë§ ‚ãÖ ‚Éóùë• ùëñ + ùëè )+ 
ùë° 
‚àë
ùëñ =1 
ùõºùëñ 
(6) 
The kernel function K was expressed as Formula (5), which accepts 
two parameters, used a speciÔ¨Åc mapping for the parameters, and then 
returns their dot product value. Suppose ùë• 1 and ùë• 2 be two data points, 
ùúô is a mapping [119] . Formula (6) represents the hyperplane deÔ¨Åned 
by ‚Éóùë§ and the constant ùëè , where t is the number of training examples, 
ùõºùëñ , i = 1,‚Ä¶, t , are non-negative numbers, so that the derivative of ùêø ùëù to 
ùõºùëñ is zero, ùõºùëñ is the Lagrange multiplier and ùêø ùëù is called the Lagrangian 
[120] . In this research, the hyperparameters C and gamma of SVM were 
determined by the grid optimization method. 
Extreme gradient boosting 
XGBoost is an algorithm optimization of the gradient boosting deci- 
sion tree, which can greatly improve the computing performance. These 
optimizations include new tree learning algorithms for processing sparse 
data; a theoretically justiÔ¨Åed weighted quantile sketch procedure en- 
ables handling instance weights in approximate tree learning. In ad- 
dition, parallel and distributed computing greatly improved the learn- 
ing speed. More importantly, XGBoost utilizes out-of-core calculations 
to greatly increase the number of data calculations [34] . However, too 
many adjustable parameters caused XGBoost to require more comput- 
ing power during the optimization process. In this study, the parame- 
ters that needed to be optimized were gamma, n_estimators, max_depth, 
min_child_weight, subsample, colsample_bytree, reg_alpha , and learning_rate . 
We adopted a step-by-step optimization strategy, Ô¨Årst optimized the Ô¨Årst 
four parameters, and then optimized the last four parameters. 
Deep neural network 
ArtiÔ¨Åcial Neural Networks (ANN) deal with complex problems by 
imitating the neural structure of the brain. They are systems that can 
modify their internal structure according to functional goals, and are 
particularly suitable for solving non-linear problems [35] . A deep neu- 
ral network (DNN) is a neural network with multiple hidden layers. It 
continuously updates its internal parameters through the backpropaga- 
tion algorithm [38] . Due to the more complex network structure, DNN 
has a better Ô¨Åtting eÔ¨Äect than ANN [38] . Therefore, it has been widely 
used in many Ô¨Åelds in recent years. 
In our research, DNN was built using the pytorch [121] toolkit 
in python, model evaluation was performed using the scikit-learn 
[111] toolkit, and the matplotlib [122] toolkit was used for drawing. 
We built four DNN models based on two split methods and two types 
of descriptors. For the two types of descriptors, we used diÔ¨Äerent net- 
work structures due to diÔ¨Äerent inputs. We added a regularization layer 
and Relu activation function between every two hidden layers. The reg- 
ularization layer can eÔ¨Äectively prevent overÔ¨Åtting. The Relu function 
can prevent the gradient from disappearing and speed up the training 
process. When outputting, used sigmoid as the activation function. The 
sigmoid function has a relatively good eÔ¨Äect in binary classiÔ¨Åcation 
problems. In each model training process, we trained in two stages, each 
stage used a diÔ¨Äerent optimizer and loss function, used the batch train- 
ing method, and always keeps each batch containing 25 compounds. 
The Ô¨Årst stage used the Adam optimizer, BCE loss function and relatively 
large learning rate. The Adam optimizer was computationally eÔ¨Écient, 
suitable for large-scale data and parameter scenarios. The optimal model 
was found from the Ô¨Årst stage, it was reloaded for the second stage train- 
ing. We can reduce the learning rate or keep it unchanged, depending 
on the degree of convergence of the model. In the second stage, we used 
the SGD optimizer to speed up the training process. Finally, we selected 
the best model from the second stage of training. The network structures 
of all models are shown in Fig. S1 to S4 in the Supplementary materials. 
Model evaluation index 
The model evaluation indicators used in this study were: accuracy 
(ACC), Matthews correlation coeÔ¨Écient (MCC), sensitivity (SE), speci- 
Ô¨Åcity (SP), their calculation methods were as formula (7-10). 
ACC = 
ùëá ùëÉ + ùëá ùëÅ 
ùëá ùëÉ + ùëá ùëÅ + ùêπ ùëÉ + ùêπ ùëÅ 
(7) 
MCC = 
ùëá ùëÉ ‚àó ùëá ùëÅ ‚àí ùêπ ùëÉ ‚àó ùêπ ùëÅ 
‚àö
( ùëá ùëÉ + ùêπ ùëÉ ) ( ùëá ùëÉ + ùêπ ùëÅ ) ( ùëá ùëÅ + ùêπ ùëÉ ) ( ùëá ùëÅ + ùêπ ùëÅ ) 
(8) 
SE = 
ùëá ùëÉ 
ùëá ùëÉ + ùêπ ùëÅ 
(9) 
SP = 
ùëá ùëÅ 
ùëá ùëÅ + ùêπ ùëÉ 
(10) 
Here TP is true positive, TN is true negative, FP is false posi- 
tive, FN is false negative. triple cross-validation (3-CV), Ô¨Åve-fold cross- 
validation (5-CV), ten-fold cross-validation (10-CV), leave-one-out val- 
idation (LOO) and ROC curve are also used as evaluation indicators in 
the training process. 
Results and discussion 
Results and performances of machine learning models 
Based on the two types of molecular Ô¨Ångerprints, two training/test 
set splitting methods, and four traditional machine learning algorithm, 
16 classiÔ¨Åcation models were built: four SVM models (models 1A, 1B, 
1C, 1D), four DT models (models 2A, 2B, 2C, 2D), four RF models (mod- 
els 3A, 3B, 3C, 3D), four XGB models (models 4A, 4B, 4C, 4D). The op- 
timal parameters for all models are displayed in Table S3 to S6 in the 
Supplementary materials. 
As shown in Table 2 , all models had ACC and MCC values above 
84.6% and 0.68 on the test set, respectively. Except for DT models, SVM, 
RF, and XGB algorithms performed comparable well on the bioactivity 
prediction. Comparing with those three algorithms, DT models showed 
relatively poorer performances. The slightly weak Ô¨Åtting and generaliza- 
tion ability of the DT algorithm is due to the following two limitations: 
the decision boundary of DT can only be parallel to the coordinate axis; 
DT would be particularly sensitive to individual data. The ROC curves 
6 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Table 2 
Performances of classiÔ¨Åcation models which were developed by traditional machine learning algorithms (SVM, DT, RF, and XGB). 
Training set 
Test set 
Model ID 
Algorithm 
Training/Test set a 
Descriptor 
ACC(%) 
3-CV(%) b 
5-CV(%) b 
10-CV(%) b 
LOO(%) c 
MCC 
ACC(%) 
SE(%) d 
SP(%) d 
MCC 
Model 1A 
SVM 
2219/763 
MACCS 
96.7 
90.5 
91.3 
91.4 
91.5 
0.93 
92.7 
94.7 
89.9 
0.85 
Model 1B 
Morgan 
97.8 
92.3 
92.8 
93.1 
92.8 
0.95 
93.6 
95.9 
90.5 
0.87 
Model 1C 
2236/746 
MACCS 
97.0 
91.1 
91.6 
92.1 
92.2 
0.94 
91.8 
92.8 
90.4 
0.83 
Model 1D 
Morgan 
96.7 
92.8 
93.2 
93.5 
93.6 
0.93 
92.1 
93.1 
90.7 
0.84 
Model 2A 
DT 
2219/763 
MACCS 
90.9 
86.8 
87.0 
87.9 
87.6 
0.82 
87.8 
87.8 
87.8 
0.75 
Model 2B 
Morgan 
94.4 
90.0 
90.0 
91.6 
91.0 
0.88 
91.5 
92.9 
89.6 
0.83 
Model 2C 
2236/746 
MACCS 
91.8 
87.3 
87.3 
88.6 
88.6 
0.83 
84.6 
87.3 
80.8 
0.68 
Model 2D 
Morgan 
94.9 
91.0 
91.8 
92.7 
92.3 
0.89 
89.8 
91.2 
87.9 
0.79 
Model 3A 
RF 
2219/763 
MACCS 
93.4 
89.0 
89.3 
90.3 
90.0 
0.87 
91.2 
92.2 
89.9 
0.82 
Model 3B 
Morgan 
94.9 
92.2 
92.5 
92.7 
91.9 
0.89 
93.6 
95.6 
90.9 
0.87 
Model 3C 
2236/746 
MACCS 
94.6 
90.4 
90.4 
90.7 
90.7 
0.89 
89.1 
90.8 
86.9 
0.78 
Model 3D 
Morgan 
94.7 
92.3 
92.4 
93.2 
92.6 
0.89 
91.2 
92.6 
89.1 
0.82 
Model 4A 
XGB 
2219/763 
MACCS 
97.5 
90.3 
90.8 
91.4 
90.8 
0.95 
92.4 
94.9 
89.0 
0.84 
Model 4B 
Morgan 
95.4 
91.7 
92.2 
92.7 
92.2 
0.95 
93.3 
95.4 
90.5 
0.86 
Model 4C 
2236/746 
MACCS 
97.4 
90.4 
91.1 
91.8 
92.0 
0.95 
90.2 
92.6 
87.0 
0.80 
Model 4D 
Morgan 
97.3 
92.5 
92.6 
93.2 
92.4 
0.94 
92.0 
93.8 
89.5 
0.83 
a The number of JAK1 inhibitors in the training set or test set. ‚Äú2219/763 ‚Äù represents the highly active/ weakly active inhibitor sets obtained by SOM splitting 
method; ‚Äú2236/746 ‚Äù represents the highly active/ weakly active inhibitor sets obtained by random splitting method. 
b k-fold cross validation, k = 3, 5, 10. 
c leave-one-out veriÔ¨Åcation. 
d SE: sensitivity; SP: speciÔ¨Åcity. 
Table 3 
Performances of DNN models. 
Training set 
Test set 
Model ID 
Training/Test set a 
Descriptor 
ACC(%) 
SE(%) b 
SP(%) b 
MCC 
ACC(%) 
SE(%) b 
SP(%) b 
MCC 
Model 5A 
2219/763 
MACCS 
97.61 
96.6 
98.4 
0.95 
93.1 
90.2 
95.2 
0.86 
Model 5B 
Morgan 
98.56 
99 
98.2 
0.97 
94.5 
92.7 
95.9 
0.89 
Model 5C 
2236/746 
MACCS 
97.72 
96.8 
98.4 
0.95 
91.6 
90.1 
92.6 
0.83 
Model 5D 
Morgan 
97.45 
96.3 
98.3 
0.95 
92.8 
89.5 
95.2 
0.85 
a The number of JAK1 inhibitors in the training set or test set. ‚Äú2219/763 ‚Äù represents the highly active/ weakly active 
inhibitor sets obtained by SOM splitting method; ‚Äú2236/746 ‚Äù represents the highly active/ weakly active inhibitor sets 
obtained by random splitting method. 
b SE: sensitivity; SP: speciÔ¨Åcity. 
of all models are displayed in Fig. S5 to S8 in the Supplementary ma- 
terials. The AUC values of all traditional machine learning models are 
above 0.88. 
From the perspective of molecular characterization, all models built 
with Morgan Ô¨Ångerprints performed better than those built with MACCS 
on the test set, indicating that Morgan Ô¨Ångerprints were more suit- 
able for our dataset. For the strategy of splitting dataset, all models 
based on training/test set splitting by SOM method performed better 
than those by the random splitting method on the test set, which ver- 
iÔ¨Åed the rationality of the dataset constructed by the SOM splitting 
method. 
Table 3 shows the performance of the four models constructed using 
DNN algorithm. Among them, Model 5A constructed by MACCS Ô¨Ån- 
gerprints and SOM splitting method; Model 5B constructed by Morgan 
Ô¨Ångerprints and SOM splitting method; Model 5C constructed by MACCS 
Ô¨Ångerprints and random splitting method; Model 5D constructed by 
Morgan Ô¨Ångerprints and random splitting method. The ROC curves of 
all DNN models are shown in Fig. S9 and the learning curves of them 
are shown in Fig. S10 to S13 in the Supplementary materials. The AUC 
values of all DNN models are above 0.96. 
In order to measure the excellence of the models, we used statistical 
tests to quantify the performance diÔ¨Äerences between the models. De- 
long test [123] was used to compare the diÔ¨Äerences between two mod- 
els‚Äô AUC values. To control the family-wise error rate (FWER) [124] due 
to the multiple pairwise comparisons, we used the false discovery rate 
(FDR) correction [125] to adjust p values for multiple pairwise com- 
Table 4 
The p values between Model 3B and other 19 models by using multiple pairwise 
statistical test. 
Model 1 (I) 
Model 2 (J) 
AUC (I) a 
AUC (J) 
p value b 
p value (adj) c 
Model 3B 
Model 2C 
0.9845 
0.8824 
> 0.0001 
> 0.0001 
Model 3B 
Model 2A 
0.9845 
0.924 
> 0.0001 
> 0.0001 
Model 3B 
Model 2B 
0.9845 
0.9615 
> 0.0001 
> 0.0001 
Model 3B 
Model 2D 
0.9845 
0.927 
> 0.0001 
> 0.0001 
Model 3B 
Model 3C 
0.9845 
0.9562 
0.0003 
0.0012 
Model 3B 
Model 3A 
0.9845 
0.9723 
0.0007 
0.0023 
Model 3B 
Model 5C 
0.9845 
0.9619 
0.0026 
0.0070 
Model 3B 
Model 5A 
0.9845 
0.9723 
0.0032 
0.0075 
Model 3B 
Model 4A 
0.9845 
0.9751 
0.0048 
0.0102 
Model 3B 
Model 1A 
0.9845 
0.9742 
0.0054 
0.0102 
Model 3B 
Model 1C 
0.9845 
0.9652 
0.0078 
0.0135 
Model 3B 
Model 4C 
0.9845 
0.967 
0.0097 
0.0153 
Model 3B 
Model 5D 
0.9845 
0.9688 
0.0232 
0.0339 
Model 3B 
Model 3D 
0.9845 
0.9694 
0.0301 
0.0408 
Model 3B 
Model 1D 
0.9845 
0.9716 
0.0532 
0.0674 
Model 3B 
Model 4D 
0.9845 
0.9718 
0.0564 
0.0669 
Model 3B 
Model 1B 
0.9845 
0.9824 
0.4548 
0.5083 
Model 3B 
Model 5B 
0.9845 
0.9829 
0.5681 
0.5997 
Model 3B 
Model 4B 
0.9845 
0.9852 
0.6585 
0.6585 
a AUC (I) is the AUC value of Model 1 (I), AUC (J) is the AUC value of Model 
1 (J) ; 
b p value based on Delong test; 
c Adjusted p value based on FDR correction. 
7 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Table 5 
MACCS Ô¨Ångerprint key and sub-structure analysis. 
Classes 
MACCS key a 
Highly/ Weakly b 
Examples of MACCS key c 
Representative substructures d 
Representative compounds e 
Class 1 
MACCS129(1), 
MACCS155(1), 
MACCS94(1), 
MACCS118(1) 
1144/117 
MACCS129 
ACH2AACH2A 
Itacitinib 
IC 50 < = 5 nM 
MACCS155 
A!CH2!A 
MACCS94 
QN 
MACCS118 
ACH2CH2A > 1 
Class 2 
MACCS129(1), 
MACCS155(1), 
MACCS94(0), 
MACCS42(1) 
147/46 
MACCS42 
F 
Molecule 2960 
IC 50 = 0.07 nM 
Class 3 
MACCS129(1), 
MACCS155(0), 
MACCS70(1), 
MACCS138(0) 
33/2 
MACCS129 
ACH2AACH2A 
Molecule 628 
IC 50 = 2.2 nM 
MACCS70 
QNQ 
MACCS138 
QCH2A > 1 
Class 4 
MACCS129(0), 
MACCS52(1), 
MACCS111(1), 
20/517 
MACCS52 
NN 
Molecule 115 
IC 50 = 6833 nM 
MACCS111 
NACH2A 
a (1) Represents that the molecule contained this MACCS key, (0) Represents that the molecule did not contain this MACCS key. 
b The ratio of the number of highly active inhibitors and weakly active inhibitors in this class of inhibitors. 
c In the MACCS key examples listed, the red is the matched structure, the bottom line was the SMARTS corresponding to the structure, and the meaning of the 
symbols involved: 
A : Any valid periodic table element symbol; Q : Hetero atoms; any non-C or non-H atom; ! : Chain or non-ring bond; ! before a bond type speciÔ¨Åes chain bond. 
d The MACCS key pair corresponded to the partial substructure in the inhibitor, and the red was the matched structure. 
e Representative molecules in this class of inhibitors, red was the matched substructure. 
8 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Table 6 
Morgan Ô¨Ångerprint key and sub-structure analysis. 
Groups 
Morgan 
Ô¨Ångerprint 
Keys a 
Subgroups 
Highly/ 
Weakly b 
Corresponding 
substructure c 
Representative scaÔ¨Äold c 
Typical compound d 
Group 1 
Morgan1772(0), 
Morgan2895(1), 
Morgan4078(1) 
353/1 
Morgan 1772 
Itacitinib 
IC 50 < = 5 nM 
Morgan 2895 
Morgan 4078 
Group 2 
Morgan1772(0), 
Morgan2895(0), 
Morgan1357(1), 
Morgan2722(1) 
Subgroups 2A 
358/1 
Morgan 1357 
Morgan 2722 
Baricitinib 
IC 50 = 4 nM 
Subgroups 2B 
10/3 
Tofacitinib 
IC 50 = 1.6 nM 
Subgroups 2C 
6/0 
Molecule 1373 
IC 50 = 0.5 nM 
Subgroups 2D 
72/3 
Molecule 2797 
IC 50 = 0.11 nM 
Subgroups 2E 
13/0 
Molecule 2922 
IC 50 = 0.85 nM 
( continued on next page ) 
9 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Table 6 ( continued ) 
Groups 
Morgan 
Ô¨Ångerprint 
Keys a 
Subgroups 
Highly/ 
Weakly b 
Corresponding 
substructure c 
Representative scaÔ¨Äold c 
Typical compound d 
Group 3 
Morgan1772(0), 
Morgan2895(0), 
Morgan1357(1), 
Morgan2722(0) 
Subgroups 3A 
104/31 
Molecule 2960 
IC 50 = 0.07 nM 
Subgroups 3B 
294/20 
Molecule 2791 
IC 50 = 0.16 nM 
Subgroups 3C 
75/15 
Molecule 2848 
IC 50 = 1.44 nM 
Subgroups 3D 
26/4 
Molecule 2280 
IC 50 = 3 nM 
Subgroups 3E 
30/0 
Molecule 2177 
IC 50 < 20 nM 
Subgroups 3F 
37/0 
Molecule 2913 
IC 50 = 0.42 nM 
Subgroups 3G 
3/13 
Molecule 476 
IC 50 = 8820 nM 
( continued on next page ) 
10 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Table 6 ( continued ) 
Groups 
Morgan 
Ô¨Ångerprint 
Keys a 
Subgroups 
Highly/ 
Weakly b 
Corresponding 
substructure c 
Representative scaÔ¨Äold c 
Typical compound d 
Group 4 
Morgan1772(1), 
Morgan3091(1), 
Morgan2962(0), 
Morgan2481(0) 
12/415 
Morgan 3091 
Morgan 2962 
Molecule 1209 
IC 50 = 8303 nM 
Morgan 2481 
a (1) Represents that the molecule contained the corresponding Morgan key structure; (0) Represents that the molecule did not contain the corresponding Morgan 
key structure. 
b The ratio of the number of highly active inhibitors to weakly active inhibitors in the sub-category. 
c ‚àó Represents any atom or group. 
d The number behind ‚ÄòMolecule‚Äô represents the ID of the molecule in our JAK1 inhibitors dataset. The JAK1 inhibitor dataset was displayed in JAK1_dataset.csv in 
the Supplementary materials. 
parisons. When p < 0.05, the diÔ¨Äerence between two AUC values is 
thought to be signiÔ¨Åcant at the 95% level. We calculated p-values across 
all models and found that model 3B had the largest number of signif- 
icant diÔ¨Äerences from the other models. The results of multiple pair- 
wise comparisons between Model 3B and other 19 models are shown 
in Table 4 . 
It can be seen from Table 4 that there are signiÔ¨Åcant diÔ¨Äerences be- 
tween Model 3B and Model 2C, Model 2A, Model 2B, Model 2D, Model 
3C, Model 3A, Model 5C, Model 5A, Model 4A, Model 1A, Model 1C, 
Model 4C, Model 5D, Model 3D, and Model 3B is statistically supe- 
rior to these models. Although there are diÔ¨Äerences with Model 1D, 
Model 4D, Model 1B, Model 5B and Model 4B, it is not statistically 
signiÔ¨Åcant. 
Analysis of MACCS Ô¨Ångerprints 
Each MACCS key corresponds to a segment of SMARTS [126] . 
SMARTS was an abstract deÔ¨Ånition. It matches the corresponding struc- 
ture through speciÔ¨Åc rules. A segment of SMARTS may match multiple 
diÔ¨Äerent substructures, the same structure may also correspond to dif- 
ferent SMARTS. Each letter in SMARTS has a diÔ¨Äerent meaning. For 
example, ‚ÄòA‚Äô represents any valid periodic table element symbol, ‚ÄòQ‚Äô 
represents a hetero atom, then ‚ÄòQNQ‚Äô means that there are two hetero 
atoms bond to the same nitrogen atom. Table 5 lists some examples of 
substructures corresponding to SMARTS. 
We calculated a MACCS Ô¨Ångerprint with a length of 166 bits for 
each inhibitor. We deleted the bits with a variance less than the aver- 
age variance, Ô¨Ånally used a MACCS Ô¨Ångerprint with a length of 80 bits 
to build models. The top 80 MACCS Ô¨Ångerprints are shown in Table 
S1 in the Supplementary materials. In the analysis, we found that the 
combination of diÔ¨Äerent important MACCS keys forms some important 
molecules with special scaÔ¨Äold features, which had an obvious activity 
possibility. The important MACCS keys were further divided into four 
classes which are summarized in Table 5 . 
In Class 1, all molecules contain MACCS129, MACCS155, MACCS94 
and MACCS118. MACCS129 and MACCS118 correspond to a variety 
of cyclic structures; MACCS155 corresponds to some chain structures; 
MACCS94 corresponds to pyrazole, pyrrolotriazolopyrimidine, pyra- 
zolopyrimidine and other structures with adjacent heteroatoms. There 
were 1261 inhibitors with the above characteristics, of which 1144 were 
highly active and 117 were weakly active. As shown in Table 5 , Itaci- 
tinib hits all the above characteristics. 
Class 2 contained MACCS129, MACCS155 and MACCS42 but did not 
contain MACCS94, which made them all contain Ô¨Çuorine atoms and 
cyclic structures but no adjacent non-carbon atoms. There were a total 
of 193 of these inhibitors, highly: weakly active inhibitors = 147: 46. 
Class 3 contained MACCS129 and MACCS70, but did not con- 
tain MACCS155 and MACCS138. These inhibitors all contained six- 
membered aliphatic rings, but there were no heteroatoms in the 
aliphatic ring and no aliphatic chain structure. In addition, they 
contained three consecutive nitrogen atom structures, which made 
them all contain pyrrolotriazolopyrimidine. A total of 35 inhibitors 
meet the above characteristics, 33 of which were weakly active 
inhibitors. 
There were 537 inhibitors in Class 4, and only 20 of them were 
highly active inhibitors, the others are weakly active inhibitors. These 
inhibitors all contained MACCS52, MACCS111 and MACCS116, which 
meant that they had a structure with two consecutive nitrogen atoms 
and did not have an alicyclic structure with more than Ô¨Åve-element. 
Analysis of Morgan Ô¨Ångerprints 
In this study, we set the radius of the Morgan Ô¨Ångerprint to 4 and 
the length to 4096 bits, we screened the Ô¨Ångerprints to remove the bits 
whose variance was less than the average variance. Finally, 958 bits 
were reserved. According to the importance of the random forest model 
of all inhibitors, we listed the top 100 uniquely meaningful Morgan keys 
in Table S2 in the Supplementary materials. 
Among these keys, the top ranking one contributes more to the model 
than the other ones in the behind. Subsequently, we analyzed some com- 
mon scaÔ¨Äold structures with obvious regularities. As shown in Table 6 , 
Group 1 (354 inhibitors) included Morgan2895 and Morgan4078 keys, 
yet excluded Morgan1772 keys. Among them, 353 compounds were 
highly active inhibitors and only one was weakly active. These inhibitors 
were analogs of Itacitinib and had an obvious common scaÔ¨Äold struc- 
ture. 
Group 2 (466 inhibitors) contained Morgan1357 and Morgan2722 
keys, without Morgan1772 and Morgan2895 keys. These inhibitors 
11 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
Figure 5. Interaction between Tofacitinib (CP-690, 550) and JAK1 (PDB ID: 
3EYG). 
would be divided into Ô¨Åve subgroups. Subgroup 2A was composed of 
359 Baricitinib analogs inhibitors, almost all inhibitors were highly ac- 
tive except one molecule with weak inhibition; There were 13 Tofac- 
itinib analogs inhibitors in Subgroup 2B, of which 10 were highly ac- 
tive and three were weakly active; six highly active inhibitors formed 
Subgroup 2C; Subgroup 2D contained 72 highly active inhibitors and 
three weakly active inhibitors; 13 highly active inhibitors constituted 
Subgroup 2E. 
A total of 652 inhibitors in Group 3 contained Morgan1357 keys 
and did not contain Morgan1772, Morgan2895, and Morgan2772 keys. 
They were divided into seven subgroups. Among them, Subgroup 3A 
contained 104 highly active inhibitors and 31 weakly active inhibitors. 
Subgroup 3B(294 highly active inhibitors and 20 weakly active in- 
hibitors), Subgroup 3C(75 highly active inhibitors and 15 weakly active 
inhibitors) and Subgroup 3F(all of 37 inhibitors were highly active) had 
the same scaÔ¨Äold structure as Subgroup 2D, Subgroup 2B and Subgroup 
3E in Group 2, but none of them contained a cyano structure. There were 
30 inhibitors in Subgroup 3D, among them, 26 inhibitors were highly 
active and four inhibitors were weakly active. There were 16 inhibitors 
in Subgroup 3G, most of which were weakly active inhibitors. The high- 
weak activity ratios and corresponding sub-structures of all subgroups 
were shown in Table 6 . 
As shown in Table 6 , Group 4 accommodated a total of 427 in- 
hibitors. The inhibitors contained Morgan1772 and Morgan3091 keys 
but did not contain Morgan2962 and Morgan2481 keys. Among them, 
415 inhibitors were weakly active molecules, the unfavorable substruc- 
tures may reduce their activities. 
Interaction between the inhibitor and JAK1 receptor 
The interaction between Tofacitinib (CP-690, 550) and JAK1 (PDB 
ID: 3EYG) [127] was shown in Figure 5 . It can be seen from Figure 5 , 
Leu959, Phe958, Lys908 and Asp1021 are key residues of JAK1, since 
they develop direct interaction with Tofacitinib. The pyrrolopyrimidine 
group of the Tofacitinib generated the hydrogen bond with Leu959 and 
Phe958, which was consistent with the Morgan Ô¨Ångerprint analysis re- 
sult, corresponding to Morgan1357 ( Table 6 ); Tofacitinib is well ac- 
commodated in the JAK1 active site, change to this: located in and 
near the polar pocket containing Asp1021 and Lys90, Asp1021 and 
Lys90 form H-bonding interaction with carbon and nitrogen atoms 
of methyl cyanide group, respectively. This was consistent with the 
results of MACCS Ô¨Ångerprint analysis and Morgan Ô¨Ångerprint anal- 
ysis, corresponding to MACCS155 and Morgan2722 ( Table 6 ), indi- 
cating that our analysis of Ô¨Ångerprint descriptors was accurate and 
reliable. 
Conclusions 
In this study, several well-performed classiÔ¨Åcation models for distin- 
guishing highly/weakly active JAK1 inhibitors were developed based 
on a dataset of 2982 JAK1 inhibitors. We used MACCS and Morgan Ô¨Ån- 
gerprints to characterize molecules, then split the dataset into a train- 
ing/test set by using SOM and random methods. We constructed classi- 
Ô¨Åcation models with SVM, DT, RF, XGBoost and DNN. The average ACC 
and MCC values of the traditional machine learning algorithm models 
reached 84.6% and 0.68 on the test set. Model 3B, built on Morgan Ô¨Ån- 
gerprints using the RF algorithm, is statistically signiÔ¨Åcantly better than 
Model 3B and other 15 models, ACC of 93.6% and MCC of 0.87 were 
achieved on the test set. The classiÔ¨Åcation models developed in the cur- 
rent work can be utilized to predict the bioactivities of JAK1 inhibitors. 
Furthermore, We ranked the importance of the MACCS and Mor- 
gan Ô¨Ångerprints descriptors based on the RF models. We detected that 
the pyrazole group, the pyrrolotriazolopyrimidine group and the pyra- 
zolopyrimidine group appeared frequently in highly active JAK1 in- 
hibitors yet barely showed up in weak inhibitors. These observations 
may provide valuable clues for the design of potent JAK1 inhibitors. 
Authors‚Äô contributions 
ZWY implemented the method and evaluated the models, YJT, YK 
performed the analysis. AXY and YSZ provided the main idea of this 
work. All authors read and approved the Ô¨Ånal manuscript. 
Declaration of Competing Interest 
The authors declare that they have no conÔ¨Çict of interest. 
Acknowledgements 
This work was supported by ‚ÄòChemical Grid Project‚Äô of Beijing Uni- 
versity of Chemical Technology. We thank Molecular Networks GmbH, 
Erlangen, Germany, for providing the programs SONNIA. 
Funding 
YZ acknowledged the support from ‚Äúthe Fundamental Research 
Funds for the Central Universities, Beijing University of Chemical Tech- 
nology (No: JD2103) ‚Äù. 
Supplementary materials 
Supplementary material associated with this article can be found, in 
the online version, at doi: 10.1016/j.ailsci.2022.100039 . 
References 
[1] Kumar N, Kuang L, Villa R, Kumar P, Mishra J. Mediators InÔ¨Çamm 
2021;2021:6618924 . 
[2] Daoud S, Taha MO. J Mol Graph Model 2020;99:107615 . 
[3] Jisha RS, Aswathy L, Masand VH, Gajbhiye JM, Shibi IG. In Silico Pharmacol 
2017;5:9 . 
[4] Keretsu S, Bhujbal SP, Cho SJ. J Biomol Struct Dyn 2021;39:753‚Äì65 . 
[5] Bajusz D, Ferenczy GG, Keseru GM. J Mol Graph Model 2016;70:275‚Äì83 . 
[6] Jasuja H, Chadha N, Kaur M, Silakari O. SAR QSAR Environ Res 2014;25:617‚Äì36 . 
[7] Itteboina R, Ballu S, Sivan SK, Manga V. J Recept Signal Transduct Res 
2017;37:453‚Äì69 . 
12 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
[8] Spinelli FR, Colbert RA, Gadina M. Rheumatology (Oxford) 2021;60:ii3‚Äìii10 . 
[9] Mascarenhas J, HoÔ¨Äman R. Clin Cancer Res 2012;18:3008‚Äì14 . 
[10] Cherington CC, Gowin KL, Mesa RA. Expert Opinion on Orphan Drugs 
2015;3:1085‚Äì96 . 
[11] Ali H, Salhotra A, Modi B, Nakamura R. Expert Rev Clin Immunol 2020;16:347‚Äì59 . 
[12] Gong X, Chen X, Kuligowski ME, Liu X, Liu X, Cimino E, McGee R, Yeleswaram S. 
Am J Clin Dermatol 2021;22:555‚Äì66 . 
[13] Yamaoka K. Expert Rev Clin Immunol 2019;15:577‚Äì88 . 
[14] Abdulrahim H, Sharlala H, Adebajo AO. Expert Opin Pharmacother 
2019;20:1953‚Äì60 . 
[15] Colombel JF, Osterman MT, Thorpe AJ, Salese L, Nduaka CI, Zhang H, Lawendy N, 
Friedman GS, Quirk D, Su C, Reinisch W. Clin Gastroenterol Hepatol 2020. 
doi: 10.1016/j.cgh.2020.10.004 . 
[16] Deodhar A, Sliwinska-Stanczyk P, Xu H, Baraliakos X, Gensler LS, Fleishaker D, 
Wang L, Wu J, Menon S, Wang C, Dina O, Fallon L, Kanik KS, van der Heijde D. 
Ann Rheum Dis 2021;80:1004‚Äì13 . 
[17] Mogul A, Corsi K, McAuliÔ¨Äe L. Ann Pharmacother 2019;53:947‚Äì53 . 
[18] Markham A. Drugs 2017;77:697‚Äì704 . 
[19] Duggan S, Keam SJ. Drugs 2019;79:1819‚Äì28 . 
[20] Tanaka Y. Mod Rheumatol 2020;30:779‚Äì87 . 
[21] Dhillon S, Keam SJ. Drugs 2020;80:1987‚Äì97 . 
[22] Peyrin-Biroulet L, Loftus Jr EV, Hibi T, Birchwood C, Yun C, Zhao S, Liu X, Rogler G, 
Danese S, Colombel JF, Feagan B. Journal of Crohn‚Äôs and Colitis 2021;15:S395‚Äì6 . 
[23] Schroeder MA, Khoury HJ, Jagasia M, Ali H, Schiller GJ, Staser K, Choi J, Gehrs L, 
Arbushites MC, Yan Y, Langmuir P, Srinivas N, Pratta M, Perales MA, Chen YB, 
Meyers G, DiPersio JF. Blood Adv 2020;4:1656‚Äì69 . 
[24] Svoboda J, Barta S, Nasta S, Landsburg D, Gerson J, Ruella M, Waite T, King C, 
Emanuel SA, Ballard H, Schuster S. Hematological Oncology 2019;37:573‚Äì4 . 
[25] Forman SB, Pariser DM, Poulin Y, Vincent MS, Gilbert SA, Kieras EM, Qiu R, Yu D, 
Papacharalambous J, Tehlirian C, Peeva E. J Invest Dermatol 2020;140:2359‚Äì70 . 
[26] Kubo S, Nakayamada S, Tanaka Y. Expert Rev Clin Immunol 2019;15:693‚Äì700 . 
[27] You H, Xu D, Zhao J, Li J, Wang Q, Tian X, Li M, Zeng X. Clin Rev Allergy Immunol 
2020;59:334‚Äì51 . 
[28] Crowley EL, Nezamololama N, Papp K, Gooderham MJ. Expert Rev Clin Immunol 
2020;16:955‚Äì62 . 
[29] Stumpfe D, Bajorath J. MedChemComm 2016;7:1045‚Äì55 . 
[30] Muratov EN, Bajorath J, Sheridan RP, Tetko IV, Filimonov D, Poroikov V, Oprea TI, 
Baskin II, Varnek A, Roitberg A, Isayev O, Curtarolo S, Fourches D, Cohen Y, As- 
puru-Guzik A, Winkler DA, AgraÔ¨Åotis D, Cherkasov A, Tropsha A. Chem Soc Rev 
2020;49:3525‚Äì64 . 
[31] Fratello M, Tagliaferri R. Decision Trees and Random Forests. Oxford: Academic 
Press; 2019 . 
[32] Wassan JT, Wang H, Zheng H. Machine Learning in Bioinformatics. Oxford: Aca- 
demic Press; 2019 . 
[33] Qi J, Liang X, Xu R. Comput Intell Neurosci 2018;2018:1018789 . 
[34] Chen T, Guestrin C. presented in part at the Proceedings of the 22nd ACM SIGKDD 
International Conference on Knowledge Discovery and Data Mining. California, 
USA: San Francisco; 2016 . 
[35] Grossi E, Buscema M. Eur J Gastroenterol Hepatol 2007;19:1046‚Äì54 . 
[36] Sarithamol S, Pushpa VL, Divya V, Manoj KB. Chem Biol Drug Des 2020;95:503‚Äì19 . 
[37] Itteboina R, Ballu S, Sivan SK, Manga V. Comput Biol Chem 2016;64:33‚Äì46 . 
[38] Guarascio M, Manco G, Ritacco E. Deep Learning. Oxford: Academic Press; 2019 . 
[39] Sliwoski G, Kothiwale S, Meiler J, Lowe EW. Pharmacological Reviews 
2014;66:334‚Äì95 . 
[40] Rogers D, Hahn M. J Chem Inf Model 2010;50:742‚Äì54 . 
[41] Davies M, Nowotka M, Papadatos G, Dedman N, Gaulton A, Atkinson F, Bellis L, 
Overington JP. Nucleic Acids Research 2015;43:W612‚Äì20 . 
[42] Reaxys Database, https://www.reaxys.com, (accessed 5.10, 2022). 
[43] Gabrielson SW. Journal of the Medical Library Association 2018:106 . 
[44] Yin Y, Chen CJ, Yu RN, Shu L, Wang ZJ, Zhang TT, Zhang DY. Bioorg Chem 
2020;98:103720 . 
[45] Su Q, Banks E, Bebernitz G, Bell K, Borenstein CF, Chen H, Chuaqui CE, Deng N, 
Ferguson AD, Kawatkar S, Grimster NP, Ruston L, Lyne PD, Read JA, Peng X, Pei X, 
Fawell S, Tang Z, Throner S, Vasbinder MM, Wang H, Winter-Holt J, Woessner R, 
Wu A, Yang W, Zinda M, Kettle JG. J Med Chem 2020;63:4517‚Äì27 . 
[46] Yin Y, Chen CJ, Yu RN, Shu L, Zhang TT, Zhang DY. Bioorg Med Chem 
2019;27:1562‚Äì76 . 
[47] Yu RN, Chen CJ, Shu L, Yin Y, Wang ZJ, Zhang TT, Zhang DY. Bioorg Med Chem 
2019;27:1646‚Äì57 . 
[48] Liang X, Zang J, Li X, Tang S, Huang M, Geng M, Chou CJ, Li C, Cao Y, Xu W, Liu H, 
Zhang Y. J Med Chem 2019;62:3898‚Äì923 . 
[49] Calbet M, Ramis I, Calama E, Carreno C, Paris S, Maldonado M, Orellana A, Calaf E, 
Pauta M, De Alba J, Bach J, Miralpeix M. J Pharmacol Exp Ther 2019;370:137‚Äì47 . 
[50] Bach J, Eastwood P, Gonzalez J, Gomez E, Alonso JA, Fonquerna S, Lozoya E, 
Orellana A, Maldonado M, Calaf E, Alberti J, Perez J, Andres A, Prats N, Car- 
reno C, Calama E, De Alba J, Calbet M, Miralpeix M, Ramis I. J Med Chem 
2019;62:9045‚Äì60 . 
[51] Wrobleski ST, Moslin R, Lin S, Zhang Y, Spergel S, Kempson J, Tokarski JS, Str- 
nad J, Zupa-Fernandez A, Cheng L, Shuster D, Gillooly K, Yang X, Heimrich E, McIn- 
tyre KW, Chaudhry C, Khan J, Ruzanov M, Tredup J, Mulligan D, Xie D, Sun H, 
Huang C, D‚ÄôArienzo C, Aranibar N, Chiney M, Chimalakonda A, Pitts WJ, Lom- 
bardo L, Carter PH, Burke JR, Weinstein DS. J Med Chem 2019;62:8973‚Äì95 . 
[52] Fensome A, Ambler CM, Arnold E, Banker ME, Brown MF, Chrencik J, Clark JD, 
Dowty ME, Efremov IV, Flick A, Gerstenberger BS, Gopalsamy A, Hayward MM, 
Hegen M, Hollingshead BD, Jussif J, Knafels JD, Limburg DC, Lin D, Lin TH, 
Pierce BS, Saiah E, Sharma R, Symanowicz PT, Telliez JB, Trujillo JI, Vaj- 
dos FF, Vincent F, Wan ZK, Xing L, Yang X, Yang X, Zhang L. J Med Chem 
2018;61:8597‚Äì612 . 
[53] Nakajima Y, Aoyama N, Takahashi F, Sasaki H, Hatanaka K, Moritomo A, In- 
ami M, Ito M, Nakamura K, Nakamori F, Inoue T, Shirakami S. Bioorg Med Chem 
2016;24:4711‚Äì22 . 
[54] Nakajima Y, Tojo T, Morita M, Hatanaka K, Shirakami S, Tanaka A, Sasaki H, 
Nakai K, Mukoyoshi K, Hamaguchi H, Takahashi F, Moritomo A, Higashi Y, In- 
oue T. Chem Pharm Bull (Tokyo) 2015;63:341‚Äì53 . 
[55] Yeleswaram K, Smith P, Hollis F. Gregory, US Pat. 2020(A1):WO2020132210 . 
[56] Brown Matthew F, Fensome A, Gerstenberger Brian S, Hayward Matthew M, Owen 
Dafydd R, Vajdos F, Xing Li H. US Pat. 2018(A1):WO2019034973 . 
[57] Van Der Plas S, Mammoliti O, Martina S, Claes P, Coti G, Annoot D, L√ìPez Ramos M, 
Galien R, Amantini D, Brys R. BE Pat. 2019(A1):WO2019076716 . 
[58] Nakamura M, Yamanaka H, Mitsuya M, Harada T. JP Pat. 2018(A1):EP3330271 
EP3330271 (A4) . 
[59] Nilsson K, √ÖStrand A, Berggren A, Johansson J, Lepist√ñ M, Kawatkar S, Su Q, 
Kettle J. SE Pat. 2018(A1):WO2018134213 . 
[60] Xi N, Li X, Li M, Zhang T, Hu H, Wu Y. CN Pat. 2018(A1):WO2018169700 . 
[61] Menet Christel Jeanne M, Mammoliti O, Quinton E, Joannesse Caroline Mar- 
tine A-M, De Blieck A, Blanc J. BE Pat. 2015(A1):WO2017012647 . 
[62] Fensome A, Gopalsamy A, Gerstenberger Brian S, Efremov Ivan V, Wan Z-K, 
Pierce B, Telliez J-B, Trujillo John I, Zhang L, Xing L. US Pat. 2015(B2):US9663526 
US2016052930 (A1) . 
[63] Menet Christel Jeanne M, Mammoliti O, Blanc J, Orsulic M, Roscic M. BE Pat. 
2015(B2):US9440929 US2015203455 (A1) . 
[64] Nakamura M, Yamanaka H, Shibata K, Mitsuya M, Harada T. JP Pat. 
2015(A1):WO2015119126 . 
[65] Li YUNL, Zhuo J, Qian D-Q, Mei S, Cao G, Pan Y, Li Q, Jia Z. US Pat. 
2014(A1):WO2014186706 . 
[66] Menet C, Schmitt B, Geney R, Doyle K, Peach J, Palmer N, Jones G, Hardy D, 
DuÔ¨Äy J. BE Pat. 2013(A1):WO2013117649 . 
[67] Rodgers James D, Shepard S, Zhu W, Shao L, Glenn J. US Pat. 
2013(A1):WO2013173720 . 
[68] Rodgers James D, Zhu W, Glenn J. US Pat. 2012(A1):WO2012068440 . 
[69] Rodgers James D, Zhu W, Shao L, Glenn J. WO2012068450 (A1). US Pat. 2012 . 
[70] Paul REastwood, Rodriguez JGonzalez, Castillo EGomez, Bach Tana J. ES Pat. 
2012(A1):WO2012160030 . 
[71] James DRodgers, Li YUNL, Shepard S, Wang H. US Pat. 2011(A1):WO2011028685 . 
[72] Paul REastwood, Gonzalez Rodriguez J, Bach Tana J, Lluis MPages Santa- 
cana, Taltavull Moll J, Juan FCaturla Javaloyes, Victor GMatassa. ES Pat. 
2010(A1):WO2011076419 . 
[73] Bach Tana J, Pages Santacana Lluis M, Taltavull Moll J, Eastwood Paul R, Gonzalez 
Rodrigues J, Giulio Matassa V. ES Pat. 2011(A1):WO2011101161 . 
[74] Boys Mark L, Burgess Laurence E, Groneberg Robert D, Harvey Darren M, 
Huang L, Kercher T, Kraser Christopher F, Laird E, Tarlton E, Zhao Q. US Pat. 
2011(A1):WO2011130146 . 
[75] Paul REastwood, Rodriguez JGonzalez, Castillo EGomez, Bach Tana J. ES Pat. 
2011(A1):WO2011157397 . 
[76] Menet Christel Jeanne M, Jouannigot N, Blanc J, Van Rompaey Luc Juliaan C, 
Fletcher Stephen R. BE Pat. 2009(A1):WO2010010186 . 
[77] Combs Andrew P, Sparks Richard B, Yue Eddy W, Feng H, Bower Michael J, Zhu W. 
US Pat. 2009(B2):US8871753 US2009286778 (A1) . 
[78] Rodgers James D, Shepard S, Li YUNL, Zhou J, Liu P, Meloni D, Xia M. US Pat. 
2009(A1):WO2009114512 . 
[79] Bourke David G, Bu X, Burns Christopher J, Cuzzupe Anthony N, Feutrill 
John T, Nero Tracy L, Blannin Beata M, Zeng J, Gaynor Shaun P. AU Pat. 
2008(A1):WO2008092199 . 
[80] Malerich JP, Lam JS, Hart B, Fine RM, Klebansky B, Tanga MJ, D‚ÄôAndrea A. Bioorg 
Med Chem Lett 2010;20:7454‚Äì7 . 
[81] Flanagan ME, Blumenkopf TA, Brissette WH, Brown MF, Casavant JM, Shang-Poa C, 
Doty JL, Elliott EA, Fisher MB, Hines M, Kent C, Kudlacz EM, Lillie BM, Magnu- 
son KS, McCurdy SP, Munchhof MJ, Perry BD, Sawyer PS, Strelevitz TJ, Subra- 
manyam C, Sun J, Whipple DA, Changelian PS. J Med Chem 2010;53:8468‚Äì84 . 
[82] Schenkel LB, Huang X, Cheng A, Deak HL, Doherty E, Emkey R, Gu Y, Gunaydin H, 
Kim JL, Lee J, Loberg R, Olivieri P, Pistillo J, Tang J, Wan Q, Wang HL, Wang SW, 
Wells MC, Wu B, Yu V, Liu L, Geuns-Meyer S. J Med Chem 2011;54:8440‚Äì50 . 
[83] Dugan BJ, Gingrich DE, Mesaros EF, Milkiewicz KL, Curry MA, Zulli AL, Do- 
brzanski P, SerdikoÔ¨Ä C, Jan M, Angeles TS, Albom MS, Mason JL, Aimone LD, 
Meyer SL, Huang Z, Wells-Knecht KJ, Ator MA, Ruggeri BA, Dorsey BD. J Med 
Chem 2012;55:5243‚Äì54 . 
[84] Yang J, Wang LJ, Liu JJ, Zhong L, Zheng RL, Xu Y, Ji P, Zhang CH, Wang WJ, 
Lin XD, Li LL, Wei YQ, Yang SY. J Med Chem 2012;55:10685‚Äì99 . 
[85] Yamagishi H, Shirakami S, Nakajima Y, Tanaka A, Takahashi F, Hamaguchi H, 
Hatanaka K, Moritomo A, Inami M, Higashi Y, Inoue T. Bioorg Med Chem 
2015;23:4846‚Äì59 . 
[86] Nakajima Y, Inoue T, Nakai K, Mukoyoshi K, Hamaguchi H, Hatanaka K, Sasaki H, 
Tanaka A, Takahashi F, Kunikawa S, Usuda H, Moritomo A, Higashi Y, Inami M, 
Shirakami S. Bioorg Med Chem 2015;23:4871‚Äì83 . 
[87] Vasbinder MM, Alimzhanov M, Augustin M, Bebernitz G, Bell K, Chuaqui C, Dee- 
gan T, Ferguson AD, Goodwin K, Huszar D, Kawatkar A, Kawatkar S, Read J, Shi J, 
Steinbacher S, Steuber H, Su Q, Toader D, Wang H, Woessner R, Wu A, Ye M, 
Zinda M. Bioorg Med Chem Lett 2016;26:60‚Äì7 . 
[88] Reddy MV, Akula B, Jatiani S, Vasquez-Del Carpio R, Billa VK, Mallireddigari MR, 
Cosenza SC, Venkata Subbaiah DR, Bharathi EV, Pallela VR, Ramkumar P, Jain R, 
Aggarwal AK, Reddy EP. Bioorg Med Chem 2016;24:521‚Äì44 . 
13 
Z. Yang, Y. Tian, Y. Kong et al. 
ArtiÔ¨Åcial Intelligence in the Life Sciences 2 (2022) 100039 
[89] Katoh T, Takai T, Yukawa T, Tsukamoto T, Watanabe E, Mototani H, Arita T, 
Hayashi H, Nakagawa H, Klein MG, Zou H, Sang BC, Snell G, Nakada Y. Bioorg 
Med Chem 2016;24:2466‚Äì75 . 
[90] Liang X, Huang Y, Zang J, Gao Q, Wang B, Xu W, Zhang Y. Bioorg Med Chem 
2016;24:2660‚Äì72 . 
[91] Vazquez ML, Kaila N, Strohbach JW, Trzupek JD, Brown MF, Flanagan ME, Mit- 
ton-Fry MJ, Johnson TA, TenBrink RE, Arnold EP, Basak A, Heasley SE, Kwon S, 
Langille J, Parikh MD, GriÔ¨Én SH, Casavant JM, Duclos BA, Fenwick AE, Harris TM, 
Han S, Caspers N, Dowty ME, Yang X, Banker ME, Hegen M, Symanowicz PT, Li L, 
Wang L, Lin TH, Jussif J, Clark JD, Telliez JB, Robinson RP, Unwalla R. J Med 
Chem 2018;61:1130‚Äì52 . 
[92] Yao L, Mustafa N, Tan EC, Poulsen A, Singh P, Duong-Thi MD, Lee JXT, Ramanu- 
julu PM, Chng WJ, Yen JJY, Ohlson S, Dymock BW. J Med Chem 2017;60:8336‚Äì57 . 
[93] Grimster NP, Anderson E, Alimzhanov M, Bebernitz G, Bell K, Chuaqui C, Dee- 
gan T, Ferguson AD, Gero T, Harsch A, Huszar D, Kawatkar A, Kettle JG, Lyne P, 
Read JA, Rivard Costa C, Ruston L, Schroeder P, Shi J, Su Q, Throner S, Toader D, 
Vasbinder M, Woessner R, Wang H, Wu A, Ye M, Zheng W, Zinda M. J Med Chem 
2018;61:5235‚Äì44 . 
[94] Yin Y, Chen CJ, Yu RN, Wang ZJ, Zhang TT, Zhang DY. Bioorg Med Chem 
2018;26:4774‚Äì86 . 
[95] Hamaguchi H, Amano Y, Moritomo A, Shirakami S, Nakajima Y, Nakai K, No- 
mura N, Ito M, Higashi Y, Inoue T. Bioorg Med Chem 2018;26:4971‚Äì83 . 
[96] Wagner J, von Matt P, Sedrani R, Albert R, Cooke N, Ehrhardt C, Geiser M, Rum- 
mel G, Stark W, Strauss A, Cowan-Jacob SW, Beerli C, Weckbecker G, Evenou JP, 
Zenke G, Cottens S. J Med Chem 2009;52:6193‚Äì6 . 
[97] Huang T, Xue CHUB, Wang A, Kong Ling Q, Ye Hai F, Yao W, Rodgers James D, 
Shepard S, Wang H, Shao L, Li HUIY, Li Q. US Pat. 2011(B2):US8765734 
US2011224190 (A1) . 
[98] Menet Christel Jeanne M, Smits Koen K. US Pat. 2011(B2):US8563545 
US2012142678 (A1) . 
[99] Menet Christel Jeanne M, Blanc J. US Pat. 2010(B2):US8796457 US2010331359 
(A1) . 
[100] Hayashi K, Watanabe T, Toyama K, Kamon J, Minami M, Uni M, Nasu M. JP Pat. 
2012(B2):US9216999 US2014200344 (A1) . 
[101] Su WEIG, Deng W, Li J, Ji J. CN Pat. 2013(B2):US9346810 US2013210831 (A1) . 
[102] Ma H, Filip Sorin V. US Pat. 2010(B2):US8592415 US2011071149 (A1) . 
[103] Promo Michele A, Xie J, Acker Brad A, Hartmann Susan J, Wolfson Sergey G, 
Huang H-C, Jacobsen Eric J. US Pat. 2011(B2):US8633206 US2011136765 (A1) . 
[104] Takahashi K, Watanabe T, Hayashi K, Kurihara K, Nakamura T, Yamamoto A, 
Nishimura T, Kamiyama T, Hidaka Y. JP Pat. 2015(B2):US9475813 US2015368245 
(A1) . 
[105] Combs Andrew P, Sparks Richard B, Yue Eddy Wai T, Feng H, Bower Michael J, 
Zhu W. US Pat. 2010(B2):US8765727 US2010190804 (A1); US2011251215 (A9) . 
[106] Allen S, Andrews Steven W, Condroski Kevin R, Haas J, Huang L, Jiang Y, Kercher T, 
Seo J. US Pat. 2010(B2):US8791123 US2012108568 (A1) . 
[107] Wang W, Diao Y, Li W, Luo Y, Yang T, Zhao Y, Qi T, Xu F, Ma X, Ge H, 
Liang Y, Zhao Z, Liang X, Wang R, Zhu L, Li H, Xu Y. Bioorg Med Chem Lett 
2019;29:1507‚Äì13 . 
[108] Qi C, Tsui H, Zeng Q, Yang Z, Zhang X. CN Pat. 2020(A1):WO2020211839 . 
[109] Gade DR, Kunala P, Raavi D, Reddy PK, Prasad RV. J Recept Signal Transduct Res 
2015;35:189‚Äì201 . 
[110] Dhanachandra Singh K, Karthikeyan M, Kirubakaran P, Nagamani S. J Mol Graph 
Model 2011;30:186‚Äì97 . 
[111] Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blon- 
del M, M√ºller A, Nothman J, Louppe G. Journal of Machine Learning Research 
2011;12:2825‚Äì30 . 
[112] Kohonen T. The Basic SOM. Berlin, Heidelberg: Springer Berlin Heidelberg; 2001 . 
[113] SONNIA, https://www.mn-am.com/products/sonnia , (accessed 5.10, 2022). 
[114] RDKit 2020.03; Open-Source Cheminformatics Software, CA, USA: San Francisco; 
2018. http://www.rdkit.org, (accessed 5.10, 2022) . 
[115] Wang H, Qin Z, Yan A. Mol Divers 2021;25:1597‚Äì616 . 
[116] Bemis GW, Murcko MA. J Med Chem 1996;39:2887‚Äì93 . 
[117] Willett P. Mol Inform 2014;33:403‚Äì13 . 
[118] Breiman L. Machine Learning 1996;24:123‚Äì40 . 
[119] Chauhan VK, Dahiya K, Sharma A. ArtiÔ¨Åcial Intelligence Review 2018;52:803‚Äì55 . 
[120] Wu X, Kumar V, Quinlan JRoss, Ghosh J, Yang Q, Motoda H, McLachlan GJ, Ng A, 
Liu B, Yu PS, Zhou Z-H, Steinbach M, Hand DJ, Steinberg D. Knowledge and Infor- 
mation Systems 2007;14:1‚Äì37 . 
[121] Pytorch, https://github.com/pytorch/pytorch , (accessed 5.10, 2022). 
[122] Matplotlib, https://matplotlib.org/ , (accessed 5.10, 2022). 
[123] DeLong ER, DeLong DM, Clarke-Pearson DL. Biometrics 1988:44 . 
[124] Nicholls A. J Comput Aided Mol Des 2016;30:103‚Äì26 . 
[125] Benjamini Y, Hochberg Y. Journal of the Royal Statistical Society: Series B (Method- 
ological) 1995;57:289‚Äì300 . 
[126] Daylight Theory Manual (2006) SMARTS - A Language for Describing Molecular 
Patterns, https://www.ics.uci.edu/ ‚àºdock/manuals/DaylightTheoryManual/theory 
.smarts.html, (accessed 5.10, 2022). 
[127] Williams NK, Bamert RS, Patel O, Wang C, Walden PM, Wilks AF, Fantino E, 
Rossjohn J, Lucet IS. J Mol Biol 2009;387:219‚Äì32 . 
14 
