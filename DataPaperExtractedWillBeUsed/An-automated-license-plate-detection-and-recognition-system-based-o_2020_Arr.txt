An automated license plate detection and recognition system based on
wavelet decomposition and CNN
Ibtissam Slimani *, Abdelmoghit Zaarane, Wahban Al Okaishi, Issam Atouf, Abdellatif Hamdoun
LTI Lab, Department of Physics, Faculty of Sciences Ben M’Sik, Hassan II University Of Casablanca, Morocco
A R T I C L E I N F O
Keywords:
Image processing
License plate detection
Character recognition
Wavlet transform
Vertical edges
Local entropy
Connected component
CNN
A B S T R A C T
The License Plate detection and recognition (LPDR) is a challenging task that plays a signiﬁcant role in intelligent
transportation systems (ITS). Where it could be used as a core in various applications, such as security, trafﬁc
control, and electronic payment systems (e.g. freeway toll payment and parking fee payment). A variety of al-
gorithms are developed for this work and each one has advantages and disadvantages for extracting plates in
images under different circumstances. However, the complexity of some methods requires a high calculation cost
and this could be time-consuming. In the current paper, a simple and efﬁcient method is proposed to tackle the
issue of license plate detection and character recognition. The license plate is detected ﬁrst based on the two-
dimensional wavelet transform to extract the vertical edges of the input image. The high density of vertical
edges is computed ﬁrst to detect the potential areas of the license plate. Then these potential areas are veriﬁed by
using a plate/non-plate CNN classiﬁer. After the license plate is detected, the characters are segmented by using a
simple method that is based on the empty distance between the characters. Finally, these character candidates are
classiﬁed by training another CNN classiﬁer. The experiments were done on vehicles that carry Moroccan license
plates and showed high accuracy, where the results obtained go up to 99.43% in term of localization and 98.9% in
term of recognition. Besides, the efﬁciency and the high accuracy of the proposed method were proved by per-
forming a comparison with other works from the literature on different datasets. All processes of the proposed
method were implemented on a Hardware Processor System (HPS) located in a VEEK-MT2S provided by
TERASIC.
I. Introduction
Year after year, trafﬁc problems are increasing rapidly due to rapid
urban development and increasing car ownership. Trafﬁc congestion,
trafﬁc violations, stealing cars, and fugitive criminals impose big chal-
lenges on trafﬁc management systems. Several systems are developed to
solve these problems such as self-driving systems [1], Trafﬁc surveillance
systems [2,3], Tracking vehicle systems and Vehicle speed detection
systems [4,5]. License plate detection and character recognition (LPDR)
is one of the most important topics in intelligent infrastructure systems,
like electronic payment systems (for tolls, parking, and public trans-
portation). The LPDR system is an image processing technology used to
identify vehicles using their license plate to help the trafﬁc management
department for monitoring purposes. Usually, a license plate detection
and character recognition (LPDR) system has mainly three phases. The
ﬁrst phase is image pre-processing, once the image is captured further
processing of the image is carried out like converting the image from a
color space to another, resizing the image resolution, and removing
noises. The second phase is license plate localization, the region of in-
terest is detected based on some license plate characteristics and image
features. The ﬁnal phase is the optical character recognition, this phase is
considered the most crucial step because it helps to read the plate number
and identify the vehicle.
To detect license plates, various methods have been proposed based
on image processing. The most common proposed methods include some
image features such as color information [6–8], edges information and,
Abbreviations: LPDR, License Plate Detection and Recognition; LP, License Plate; ITS, Intelligent Transportation Systems; 2D-WD, two dimensional wavelet
decomposition; CTC, connectionist temporal classiﬁcation; CCA, connected component analysis; CNN, Convolutional neural network; HPS, Hardware Processor
System; SVM, support vector machine; AdaBoost, Adaptive boosting; FPGA, Field Programmable Gate Arrays; AC, access control; LE, trafﬁc law enforcement; RP, road
patrol.
* Corresponding author.
E-mail addresses: ibtissamslimani7@gmail.com (I. Slimani), z.abdelmoghit@gmail.com (A. Zaarane).
Contents lists available at ScienceDirect
Array
journal homepage: www.elsevier.com/journals/array/2590-0056/open-access-journal
https://doi.org/10.1016/j.array.2020.100040
Received 1 May 2020; Received in revised form 26 August 2020; Accepted 27 August 2020
Available online 3 September 2020
2590-0056/© 2020 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
Array 8 (2020) 100040
textures information [9,10]. Jia et al. [11], relied on three features to
extract the candidate of license plate (LP), rectangularity, aspect ratio,
and edge density. They ﬁrst used the mean shift to ﬁlter and segment
color images into candidate regions, then they utilized Mahalanobis
classiﬁer to classify license plate candidates and non-license plate can-
didates based on the three features mentioned previously. Davis et al.
[12], used vertical edges features to localize the LP. They ﬁrst convert the
color image into a gray image, then they use an adaptive thresholding
technique to binarize the image, after that they used an algorithm called
vertical edges detection algorithm (VEDA) to extract the vertical edges
and ﬁnally, they use the highlighting desired details (HDD) algorithm for
highlighting the license plate area. Ashtari et al. [8] proposed a modiﬁed
template matching technique to localize the LP based on color informa-
tion. They detect the LP based on ﬁnding a blue rectangle that appears on
the side of an Iranian and some European license plates and then they
cropped the LP in the same direction as that of the width of the blue pixel.
Other methods are relied on combining multiple methods to localize the
LP to increase the precision rate. Rashedi et al. [13] relied on four
methods to locate the LP, including an edge-based method, a method
based on cascade classiﬁers, and local binary pattern (LBP) features, a
color-based method, and a contrast-based method.
To recognize the characters of the LP, two processes should be done.
The ﬁrst process includes character segmentation and the second one
includes character classiﬁcation, where the segmented characters should
be classiﬁed into 36 classes (26 capital letters and 10 digits). Several
classiﬁers are used in the ﬁeld of license plate recognition such as support
vector machine (SVM), Adaptive boosting (AdaBoost) and Convolutional
neural network (CNN). In Ref. [14], the characters are segmented ﬁrst by
using different treatments including 2D convolution, morphological
operation, and some equations for region segmentation. Then a feature
selection is applied by using entropy to select the most relevant features.
Finally, these features are classiﬁed through SVM for character recogni-
tion. In Ref. [15] they ﬁrst calibrate the LP tilt, and then they use the
projection method to segment the characters. Finally, they based on the
back-propagation neural network to recognize each character. In
Ref. [16], they proposed two different methods, the ﬁrst one performs the
character segmentation ﬁrst and then character recognition. The other
one is character string recognition, all characters are recognized in the
license plate one-off. In the ﬁrst proposition, the cropped candidate li-
cense plate is binarized ﬁrst to increases the image contrast. Then, the
characters are segmented by applying the connected component algo-
rithm and classiﬁed by using CNN classiﬁer. In the second proposition,
the features are extracted ﬁrst by using a pre-trained 9-layer CNN model,
then a sequence labeling is applied by using bidirectional-RNNs, and
ﬁnally, sequence decoding is performed by applying connectionist tem-
poral classiﬁcation (CTC).
Although there is a lot of research on the license plate detection and
recognition, most of the proposed methods have some restrictions and
perform well only under certain predeﬁned conditions. Some common
restrictions include illumination problems, complex scenes and the
presence of blur or distortions on the license plate. Moreover, the
toughness of this task resides in the huge variety of characters shapes,
like different fonts, forms sizes and colors of each character through the
different license plates in each country.
The goal of this paper is to establish a low-cost, highly efﬁcient
automatic vehicle license plate detection and recognition system. The
idea presented in this paper is divided into two stages: license plate
localization and character recognition. In the ﬁrst stage, the license plate
regions are extracted from the input image. The potential license plates
are extracted based on vertical edges where the high density of these
edges is inside the LP. To extract the vertical edges from the input image,
we have used the two-dimensional wavelet decomposition (2D-WD). The
2D-WD divides the image into four sub-bands where the vertical edges
are in one of these sub-bands. After getting the vertical edges, we extract
the license plate candidates by looking for the high density of vertical
edges. Finally, to verify the correctness of these candidates, a plate/non-
plate CNN classiﬁer is trained to remove the false positive. In the second
stage, the separating columns between the characters are extracted to
segment the license plate characters and to generate the segmented
candidates. Finally, these character candidates are classiﬁed by training
another CNN classiﬁer.
This paper is organized as follows: In Section II, the license plate
detection process is detailed. Section III presents the character recogni-
tion process in detail. Experimental evaluations are presented in Section
IV. Finally, Section V concludes the paper.
II. Proposed method
1. License plate detection
License plate detection is a very important step in the proposed
method, where its efﬁciency plays a big role in the detection and
recognition of license plate characters. The principle of this step is to look
for the potential license plate locations in the input image (zones of in-
terest) then verify these locations as a license plate or not. In our prop-
osition, we have based on vertical edges to detect the potential license
plate candidates. First, the 2D-WD is used to extract the vertical edges.
Then, the high density of the vertical edges is calculated to detect the
potential license plate candidates. These candidates are then classiﬁed by
training a plate/non-plate CNN classiﬁer to remove the false positive.
1.1. License plate candidates
For license plate detection, the license plate candidates need to be
generated ﬁrst. To extract the regions where it could be the license plate,
we have based on extracting the vertical edges of the input image
(Fig. 2(a)). The horizontal and vertical edges are one of the best features
that can be extracted in the image processing domain. However, in this
paper, we focus just on the vertical edges which the high density of the
vertical edges in a vehicle is inside the license plate because of the shape
of the license plate characters. To extract these features, the two-
dimensional wavelet transform [17] is applied after converting the
input image to a gray level.
1.1.1. Two-dimensional wavelet decomposition
The 2D-WD [18] divides an image into four sub-bands as shown in
Fig. 1, each sub-band contains different information of the original
image. Three sub-bands for detail coefﬁcients “vertical detail, horizontal
Fig. 1. Sub-bands of 2D-WD.
I. Slimani et al.
Array 8 (2020) 100040
2
detail and diagonal detail” and the fourth sub-band for the approxima-
tion coefﬁcients. Detail coefﬁcients represent the high frequency of the
input image, approximation coefﬁcients represent the low frequency.
Therefore, in this paper, we take just the vertical detail (Fig. 2(b)) which
represents the vertical edges of the input image.
1.1.2. High vertical edge density extraction
To extract the high vertical edge density areas, we have based on
calculating the maximum entropy areas. The entropy is a measure of
disorder or randomness of a system, it measures the degree of disorder or
uncertainty associated with a random variable. Therefore, the area where
the entropy is maximum returns to the areas where there is a high vertical
edge density. Entropy is usually calculated from an image using Shannon
entropy, where the probability distribution could be easily estimated
from image histogram [19]. The entropy formula is given as follows (1):
E ¼ �
X
L
1
pk log2pk
(1)
with a color value (index k ¼ 1, …, L) that occurs with a probability pk.
Where pk contains the normalized histogram counts. In this paper, we
calculate the local entropy of the grayscale image, where each pixel of the
resulted image contains the entropy value of the 9-by-9 neighborhood
around the corresponding pixel in the input image.
After computing the locale entropy, the resulted image (Fig. 2(c)) is
converted to a binary image (Fig. 2(d)) by using a predeﬁned threshold K
to deﬁne the areas that have the maximum entropy (2).
(2)
where Pi is the new pixel and Xi is the value of each pixel of the image
after computing the local entropy.
Unfortunately, in the binary image, we ﬁnd some noisy holes and
some broken areas where the region of interest might be divided into two
regions. To solve this problem, a morphological operation is used. The
closing operation (dilation followed by erosion) is performed to recover
these holes.
To extract the regions of interest, the connected component analysis
(CCA) is applied. The connected component analysis is an important task
used in several image processing domains to detect linked regions in
binary images. The principle of this method is based on a crossing win-
dow that crosses the entire input image from the left to the right from the
top to the bottom. The algorithm.1 illustrates the whole technique used
to generate the CCA. Therefore, based on the length, the height, and
coordinates of each connected component, the bounding box is drawn.
Based on the area, the small and the big bounding box are eliminated.
The area is the number of white pixels in each connected component and
the length and the height are computed from the minimum and the
maximum coordinates of each connected component along the vertical
and the horizontal axes. Fig. 2(e) shows the image resulted after applying
the CCA and drawing bounding box.
Algorithm.1
- Let Im denotes the input image having size LxC
- For y 1 to C do
- For x 1 to L do
� If Im (x,y) ¼ 1 do
� Scan pixels around Im (x,y).
� When all pixels around are black, a new label is assigned to Im (x,y).
� If one of the pixels around is white, its label is assigned to Im (x,y).
� If more than one of the pixels around are white, one of their labels is assigned to Im
(x,y) and the other labels are taken as notes.
- Each pixel’s label and its corresponding labels in the note are mixed and considered
as one label.
- Each connected component is represented by a label.
1.2. License plate veriﬁcation
To verify the license plate candidates, The CNN classiﬁer is trained, to
represent the image for classiﬁcation of a license plate and non-license
plate, with positive samples of gray-scale license plates that are taken
from diverse countries. Some positive samples are cropped from real
images, and some negative samples are set up by images of some general
text strings as well as some images of rectangles. Finally, the images that
are classiﬁed as license plate (see Fig. 2(f)) are fed to the next step.
Fig. 2. Following steps for license plate detection (a) the input grayscale image; (b) the vertical detail of 2D-DW; (c) the image after applying the entropy area al-
gorithm; (d) image binarized; (e) the extracted connected component; (f) the result after CNN classiﬁer.
I. Slimani et al.
Array 8 (2020) 100040
3
Convolutional neural network (CNN) is a special architecture of
artiﬁcial neural networks and the best performing model to classify im-
ages. It is divided into two main parts, Convolutional layers and fully
connected layers. The convolutional layer is the building block of CNN, it
is responsible for features extraction from images by applying convolu-
tion ﬁltering operations. However, the fully connected layers are
responsible for the prediction part. With one or more fully connected
layers that are fed by the output of the convolution layers the prediction
part is done. The CNN computes the score of each class using the features
extracted from the previous layers. However, training convolutional
neural networks are very expensive because they require a signiﬁcant
amount of data and resources in training. Therefore, there are several
open-source pre-trained models like Inception-v3, ResNet-50, and
VGG16 which are the most utilized [20].
In this paper, we have based on the Inception-v3 model that is a
model formed by Google. This model is formed on about 1.2 million
images per 1000 categories which represent classes of objects from our
daily life. This model consists of 42 layers, which are considered as
symmetric and asymmetric blocks, including convolutional, average
pooling, max pooling, dropouts, and fully connected layers. We have
chosen the inception v3 model because it performs well in terms of
precision and does not require a lot of calculation in the processing phase,
which makes it much easier to use this system on average performance
computers. In addition, this model is highly recommended by most data
scientists.
2. License plate recognition
After the localization, the license plates are cropped from their orig-
inal image and classiﬁed. Then they go through the recognition process
for classifying and recognizing their letters and numbers. Where the
principle of this step is to look for the characters candidates in the
detected license plate then match them with the characters. In the pro-
posed method, the empty lines between the characters are detected to
segment the license plate characters and generate the segmented candi-
dates. Then, these segmented candidates are classiﬁed by training CNN
classiﬁer to recognize the license plate characters.
2.1. License plate segmentation
The license plate characters are generally separated and each char-
acter is far from the other character by the same distance. Based on this
separation space, the characters have been segmented in this work. The
idea is to scan the detected license plate vertically, column by column
from top to the bottom and compute the number of black pixels in each
column. If the number of successive black pixels in the column reaches
more than a predeﬁned value of black pixels, we consider this column as
a part of a character then we move directly to the next column to reduce
the computational cost. Otherwise, the column is saved as a potential
separating column and the black pixels of this column are considered as
noise. All potential separating columns segmenting the license plate
image are printed in red color as shown in Fig. 3(b). Successive potential
separating columns are considered as a separating distance between the
characters and the average value is considered as the separating column
as shown in Fig. 3(c). Fig. 3 shows an example of a segmented license
plate.
2.2. Characters recognition
The characters, after the segmentation, are cropped from their license
plate image by using the separating columns. To recognize these char-
acters, another 42-class CNN classiﬁer is trained, 10 digits, 26 upper
letters plus 6 Arabic letters. In our work, we have used Moroccan license
plates to test the performance of our system, for this reason, the Arabic
characters used in Moroccan license plates are treated too (Fig. 4). The
open-source pre-trained CNN model Inception-v3, formed by Google, is
used to classify these characters.
III. Results and discussion
The proposed system was implemented using Cþþ and OpenCV on
1.2 GHz Dual-core ARM Cortex-A9 (HPS) that runs under LXDE desktop
with 1.0 GB memory DDR3. The HPS is located in a VEEKMT2S that is
composed of DE10 standard FPGA and the MTLC2 module provided by
TERASIC.
1. Datasets
Two experiments have been done to test the performance of the
proposed detection and recognition system. The ﬁrst experiment was
done on Moroccan License Plates using real trafﬁc video sequences
collected from different situations in different lighting conditions. As
Fig. 3. License plate segmentation; (a) the input image; (b) segmentation col-
umns; (c) ﬁnal segmentation.
Fig. 4. Some examples of character templates.
Table 1
The experimental conditions.
Scenes
Highways, urban roadways
Weather
Sunny, foggy, shady
Time
Day and night time
Camera specs
2160p/30fps video
License plate sizes and designe
Different sizes with single row
Vehicle colors
Different colors
I. Slimani et al.
Array 8 (2020) 100040
4
shown in Table 1, we have three video sequences corresponding to
different situations. The ﬁrst sequence was taken on the highways in
normal daylight conditions. The second one was taken on urban road-
ways. In contrast, the third one was recorded during the night. The
experimental conditions of the collected sequences are described in
Table 1.
The second experiment was done using the Caltech cars dataset
(Rear) [21] and the AOLP dataset. The Caltech cars dataset consists of
126 images with a resolution of 890 � 592 pixels taken during the day
from complex outside scenes, each of which contains only one vehicle.
The second dataset, the application-oriented license plate (AOLP), in-
cludes 2049 images of vehicles. It is categorized into three subsets: access
control (AC), trafﬁc law enforcement (LE), and road patrol (RP) that are
available in Ref. [22].
For the classiﬁcation, we have used a pre-trained CNN model, so that
we do not need a large training dataset for successful classiﬁcation. For
license plate detection, the ﬁrst CNN model was re-trained using 200
license plate images and 200 non-license plate images that were cropped
by ourselves from Caltech [21] and AOLP [22] datasets. For license plate
recognition, about 600 images of cropped characters from the Caltech
and AOLP datasets and some images of Arabic letters taken from images
of Moroccan cars, as well as about 600 samples of non-characters from
different scenes under different conditions, are used to re-train the sec-
ond CNN model.
2. Performance metrics
To evaluate the proposed system’s effectiveness, three different
testing cases using Moroccan car video sequences from several scenes at
different conditions are used. The license plate detection accuracies and
the character recognition accuracies of this evaluation were recorded and
listed in Table 2.
For the rating Criteria, the proposed system is evaluated by calcu-
lating the accuracy of the detection and the recognition which is deﬁned
as the number of correctly detected license plates divided by the number
of correctly detected plus the number of incorrectly detected.
Accuracy ¼
true positive
true positive þ false positive
The results listed in Table 2 show that the proposed method gives
high accuracy for the three sequences and conﬁrms that it can effectively
detect the license plate and recognize its characters in different situa-
tions. Detection accuracy goes up to 98.4% and recognition accuracy
goes up to 98.9% in some cases. Fig. 5 shows some results of the detection
and recognition process of Moroccan license plates.
3. Evaluation results
3.1. Evaluation of license plate detection
For license plate detection, the performance has been evaluated using
three methods to compare our work with. Rashedi et al. [13] have been
detecting the license plate based on combining four methods, the
Contrast-based method, Color-based method, Edge-based method, and a
method uses cascade classiﬁers and local binary pattern (LBP). Yuan et al.
[23] have based their work on connecting the high-density regions in the
binary edge image using a novel line density ﬁlter to localize license
plates. Davis et al. [12] have been detecting the license plates based on
Table 2
License plate detection and character recognition accuracies.
Video Sequences
Detection accuracy (%)
Recognition accuracy (%)
1
98.4
98.9
2
96.23
98.5
3
97.4
97.9
Fig. 5. Some results of the localization and recognition of Moroccan license plates.
Table 3
Evaluation results of the license plate detection.
Methods
Detection Accuracy (%)
Yuan et al. [23]
91.27
Rashedi et al. [13]
93.32
Davis et al. [12]
88.05
Proposed method
96.72
I. Slimani et al.
Array 8 (2020) 100040
5
detecting vertical edges using the VEDA algorithm. Table 3 shows the
result of the comparison between these methods and our proposed
method using the Caltech cars dataset. Furthermore, according to
Table 3, the comparison shows that our proposed method gives high
accuracy and efﬁciently detect the license plate and outperforms the
other methods in terms of detection accuracy which achieves a detection
rate of 96.72% and a 3.4% improvement over the best method proposed
by Rashedi et al. [13].
There are many reasons for this improvement in the results of the
proposed method. For example, the features extracted using 2D-WD
(vertical details) are very important and signiﬁcantly improve the accu-
racy of the results of the proposed method instead of using an ordinary
edge detector which helps to reduce the false detection rate and also to
reduce the processing time. Unlike other methods, they rely only on
binarization to extract features. Besides, the use of the entropy function
helps a lot to detect potential regions more than the other proven algo-
rithm. This combination of useful algorithms reduces the error rate and
improves the generated true candidates. Also, the classiﬁcation of these
generated candidates using CNN classiﬁer is one of the main reasons that
improved accuracy.
Some examples of the license plate detection results using the Caltech
cars dataset are shown in Fig. 6.
3.2. Evaluation of character recognition
For character recognition, our work has been compared with Hui Li
et al. [16] using the AOLP dataset. Hui Li et al. [16] have used a recog-
nition technique, which treats the license plate characters as an unseg-
mented sequence, and trained 36-class convolutional neural network
(CNN) to recognize the characters. The comparison data listed in Table 4
shows that the proposed method accuracy is slightly better than the other
method. Some examples of the license plates recognition results for the
AOLP dataset are shown in Fig. 7.
Fig. 6. Some results of the detection process performed on the Caltech dataset.
Table 4
Evaluation results of the character recognition process.
Methods
Accuracy (%)
AC
LE
RP
Hui Li et al. [16]
97.84
97.27
95.57
Proposed method
98,03
97,9
96,11
Fig. 7. Some results of the recognition process performed on the AOLP dataset.
I. Slimani et al.
Array 8 (2020) 100040
6
IV. Conclusion
A license plate detection and recognition system is proposed in this
paper. The proposed system included two stages: the license plate
detection stage and the character recognition stage. In the ﬁrst stage, the
license plate candidates are generated based on vertical edges to detect
the potential license plate candidates. First, the 2D-WD is used to extract
the vertical edges. Then, the high-density areas of the vertical edges are
extracted by calculating the maximum entropy areas to detect the po-
tential license plate candidates. These candidates are then classiﬁed by
training a plate/non-plate CNN classiﬁer to remove the false positive. In
the second stage, the characters are segmented ﬁrst by detecting the
empty lines between the characters then these segmented candidates are
classiﬁed by training 42-class CNN classiﬁer to recognize the license plate
characters. The proposed system was tested ﬁrst on Moroccan cars using
three collected videos in different situations and it gives very encour-
aging results where the high accuracy has gotten is 98,36% in term of
detection and 98,9% in term of recognition. Thus, a comparative study
has done using different works from the literature and shows that our
work outperforms the other works. The comparative study of the license
plate localization process was done on the Caltech dataset and shows the
performance of our work. For character recognition, the comparative
study was done on the AOLP dataset and also gives satisfying results. The
experiment results are satisﬁed and encouraging and show the efﬁciency
of the proposed system.
Declaration of competing interest
The authors declare that they have no known competing ﬁnancial
interests or personal relationships that could have appeared to inﬂuence
the work reported in this paper.
Author Contribution Statement
Ibtissam
Slimani:
Conceptualization,
Methodology,
Resources,
Software, Formal analysis, Writing - Original Draft, Writing - Review &
Editing. Abdelmoghit Zaarane: Methodology, Software, Formal anal-
ysis, Writing - Original Draft, Writing - Review & Editing. Wahban Al
Okaishi: Investigation, Resources, Writing - Review & Editing. Issam
Atouf: Validation, Visualization, Supervision. Abdellatif Hamdoun:
Validation, Visualization, Supervision.
Funding
We have no funding resources.
Availability of data and materials
The data used to support the ﬁndings of this study are included within
the article [21,22]. Please contact author for more requests.
Acknowledgments
Thanks to all those who have suggested and given guidance for this
article.
References
[1] Zaarane A, Slimani I, Hamdoun A, Atouf I. Real-Time vehicle detection using cross-
correlation and 2D-DWT for feature extraction. J. Electr. Comput. Eng. 2019:1–9.
https://doi.org/10.1155/2019/6375176. Jan. 2019.
[2] Slimani I, Zaarane A, Hamdoun A, Atouf I. Trafﬁc surveillance system for vehicle
detection using discrete wavelet transform. J Theor Appl Inf Technol 2018;96(17):
5905–17.
[3] AL Okaishi W, Zaarane A, Slimani I, Atouf I, Benrabh M. Vehicular queue length
measurement based on edge detection and vehicle feature extraction. J Theor Appl
Inf Technol 2019;97(5):1595–603.
[4] Zaarane A, Slimani I, Hamdoun A, Atouf I. “Vehicle to vehicle distance
measurement for self-driving systems. In: 2019 6th international conference on
control, decision and information technologies. CoDIT; 2019. https://doi.org/
10.1109/CoDIT.2019.8820572. 2019.
[5] Zaarane A, Slimani I, Al Okaishi W, Atouf I, Hamdoun A. Distance measurement
system for autonomous vehicles using stereo camera. Array Jan. 2020:100016.
https://doi.org/10.1016/J.ARRAY.2020.100016.
[6] Shi X, Zhao W, Shen Y. Automatic license plate recognition system based on color
image processing. Lect Notes Comput Sci 2005;3483(IV):1159–68. https://doi.org/
10.1007/11424925_121.
[7] Dun J, Zhang S, Ye X, Zhang Y. Chinese license plate localization in multi-lane with
complex background based on concomitant colors. IEEE Intell. Transp. Syst. Mag.
Sep. 2015;7(3):51–61. https://doi.org/10.1109/MITS.2015.2412146.
[8] Ashtari AH, Nordin MJ, Fathy M. An Iranian license plate recognition system based
on color features. IEEE Trans Intell Transport Syst 2014;15(4):1690–705. https://
doi.org/10.1109/TITS.2014.2304515.
[9] Zheng D, Zhao Y, Wang J. An efﬁcient method of license plate location. Pattern
Recogn Lett Nov. 2005;26(15):2431–8. https://doi.org/10.1016/
j.patrec.2005.04.014.
[10] Deb K, Chae HU, Jo KH. Vehicle license plate detection method based on sliding
concentric windows and histogram. J Comput 2009;4(8):771–7. https://doi.org/
10.4304/jcp.4.8.771-777.
[11] Jia W, Zhang H, He X, Piccardi M. “Mean shift for accurate license plate
localization,” in IEEE Conference on Intelligent Transportation Systems. Proceedings,
ITSC 2005;2005:566–71. https://doi.org/10.1109/ITSC.2005.1520110.
[12] Davis AM, Arunvinodh C, Arathy Menon NP. “Automatic license plate detection
using vertical edge detection method. In: ICIIECS 2015 - 2015 IEEE international
conference on innovations in information, embedded and communication systems;
Aug. 2015. https://doi.org/10.1109/ICIIECS.2015.7193073.
[13] Rashedi E, Nezamabadi-pour H. A hierarchical algorithm for vehicle license plate
localization. Multimed Tool Appl Jan. 2018;77(2):2771–90. https://doi.org/
10.1007/s11042-017-4429-z.
[14] Khan MA, Sharif M, Javed MY, Akram T, Yasmin M, Saba T. License number plate
recognition system using entropy-based features selection approach with SVM. IET
Image Process Feb. 2018;12(2):200–9. https://doi.org/10.1049/iet-ipr.2017.0368.
[15] Hung KM, Hsieh CT. A real-time mobile vehicle license plate detection and
recognition. Tamkang J Sci Eng 2010. https://doi.org/10.6180/jase.2010.13.4.09.
[16] Li H, Wang P, You M, Shen C. Reading car license plates using deep neural
networks. Image Vis Comput 2018. https://doi.org/10.1016/j.imavis.2018.02.002.
[17] Daubechies I. The wavelet transform, time-frequency localization and signal
analysis. IEEE Trans Inf Theor 1990. https://doi.org/10.1109/18.57199.
[18] Slimani I, Zaarane A, Hamdoun A. Convolution algorithm for implementing 2D
discrete wavelet transform on the FPGA. In: Proceedings of IEEE/ACS international
conference on computer systems and applications. AICCSA; 2016. https://doi.org/
10.1109/AICCSA.2016.7945831.
[19] Silva LEV, Filho ACSS, Fazan VPS, Felipe JC, Murta LO. Two-dimensional sample
entropy: assessing image texture through irregularity. Biomed. Phys. Eng. Express
2016. https://doi.org/10.1088/2057-1976/2/4/045002.
[20] Nogueira K, Penatti OAB, dos Santos JA. Towards better exploiting convolutional
neural networks for remote sensing scene classiﬁcation. Pattern Recognit.; 2017.
https://doi.org/10.1016/j.patcog.2016.07.001.
[21] “The Caltech Database (Computational Vision at California Institute of Technology,
Pasadena),.” http://www.vision.caltech.edu/archive.html.
[22] Hsu GS, Chen JC, Chung YZ. Application-oriented license plate recognition. IEEE
Trans Veh Technol 2013. https://doi.org/10.1109/TVT.2012.2226218.
[23] Yuan Y, Zou W, Zhao Y, Wang X, Hu X, Komodakis N. A robust and efﬁcient
approach to license plate detection. IEEE Trans Image Process 2017. https://
doi.org/10.1109/TIP.2016.2631901.
I. Slimani et al.
Array 8 (2020) 100040
7
