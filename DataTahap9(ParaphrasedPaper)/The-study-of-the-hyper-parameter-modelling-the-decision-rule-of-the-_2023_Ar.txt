This academic paper discusses the trade-off that exists between caution and informativeness in classifiers that predict multiple classes. It compares the cautious yet uninformative nature of classifiers that predict the entire set of candidate classes with the precise yet non-cautious nature of classifiers that predict only a single class. It examines how set-valued classifiers such as the ndc and eclair classifiers manage this trade-off, specifically through the utility function implemented in their decision steps.

The paper aims to study the impact of a parameter on the performance of these classifiers, and provide recommendations for selecting the parameter value in classification tasks. Experimental results on simulated and fashion MNIST data are presented to illustrate the influence of the selected hyper-parameter value on classifier predictions when faced with unusual samples.

The paper is organized as follows: 
- Section two provides a recap of the decision step in the eclair and ndc classifiers, as well as the measures of set-valued classification performances. 
- Section three examines the expected utility functions introduced in the decision step of the two classifiers. 
- Section four presents the experimental results, including the performances of the ndc and eclair classifiers using generated data and fashion MNIST data, as well as the control of prediction numbers according to the proposed techniques.

The paper also discusses the computational complexity associated with conformal prediction and the eclair classifier, and the challenges these pose. While conformal prediction calculates non-conformity scores using the nearest neighbors of the calibration or test samples in the training data, the eclair classifier has high computational complexity due to its representation of imprecision in the data.

Furthermore, the paper investigates the function used in the decision step of the two set-valued classifiers and the predicted subsets based on the hyperparameter. It also proposes practical methods for controlling the size of predicted subsets in machine learning applications. Through its recommendations, the paper aims to help decision-makers better control the size of predictions and make machine learning methods more reliable, especially when dealing with imperfect data.