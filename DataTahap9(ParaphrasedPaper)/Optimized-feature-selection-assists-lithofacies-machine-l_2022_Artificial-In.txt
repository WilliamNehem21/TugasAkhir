The identification of lithofacies in wellbores plays a crucial role in reservoir characterization. There is extensive use of recorded well-log datasets in classifying lithofacies for both clastic (Rider, 1990) and carbonate (Stowe and Hock, 1988) reservoirs. This method is effective when lithofacies are easily distinguishable in both core and well-log terms, and when there is lateral extent across the reservoir, homogeneity, and sufficient diversity of well-log features. However, additional geological information may be necessary when some of these requirements are not met.

Feature selection in lithofacies analysis is important for its effectiveness and accuracy. While a trial-and-error approach can be used for a small number of features, it becomes inefficient and unreliable as the number of available features increases. Feature selection becomes an NP-hard combinatorial challenge as the number of possible feature combinations grows exponentially with the available features. Therefore, the use of optimizers for comprehensive feature selection is more effective.

Reducing the number of features can enhance the efficiency of some machine learning models. Various machine learning algorithms, such as neural networks, support vector classification, k-nearest neighbor, optimized data matching, and tree-ensemble methods, are used for well-log-based lithofacies prediction.

Specific geological factors are not used to define or control the selected log attributes. The attributes selected are generic and can be applied to any log curve that shows fluctuations in its absolute values versus depth related to the physical rock properties, such as gamma-ray, bulk density, and acoustic well logs. It is observed that these attributes can provide useful complementary information to the raw log values for lithofacies analysis.

Feature selection is necessary to determine the least influential variables from the potentially influential well-log variables. Multiple machine learning models, such as adaptive boosting, decision tree, logistic regression, random forest, support vector regression, and extreme gradient boosting, have been widely applied to lithofacies classification studies.

After establishing hyperparameters, it is important to determine the appropriate splits of data records for the training and validation dataset. A multi-k-fold cross-validation technique is conducted to identify the appropriate splits. Feature selections with seven to ten available features achieve high prediction accuracies. Different machine learning models perform differently in lithofacies classification, with slight differences in error and accuracy performances.

Calculating well-log attributes and using optimizers to select features from the recorded well logs substantially improves lithofacies classification performance. However, there are opportunities to further improve lithofacies prediction accuracy, such as by expanding the suite of well logs, evaluating alternative well-log attributes, and incorporating additional mathematical attributes of the sparse recorded well-log suite.

In summary, this study emphasizes the importance of feature selection and the application of machine learning models for lithofacies classification based on well-log data, while also exploring potential avenues for further improvement in prediction accuracy.