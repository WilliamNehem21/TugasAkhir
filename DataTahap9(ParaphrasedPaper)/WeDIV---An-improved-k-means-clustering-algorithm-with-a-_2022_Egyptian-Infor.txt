The determination of appropriate distance metrics and optimal cluster numbers are significant concerns in cluster analysis. In this study, an enhanced k-means clustering algorithm incorporating a weighted distance (ep dis) and a novel internal validation index (wediv) was proposed. The ep dis was formulated to effectively capture both global spatial correlation and local variable trends in high-dimensional space by considering the relative contribution between Euclidean and Pearson distances with a weighted strategy. Additionally, a new internal validation index (rch) was developed to automatically estimate the optimal number of clusters by drawing inspiration from the calinski-harabasz (ch) index and analysis of variance. Mathematical analysis and validation on simulated datasets confirmed the reliability of ep dis, while the effectiveness of rch was demonstrated on four simulated datasets with different properties. Furthermore, the clustering performance of wediv was compared with 12 prevailing clustering algorithms across 16 UCI datasets, with the results indicating that wediv outperforms the others regardless of specifying the number of clusters.

The choice of similarity metrics (distance) is pivotal in clustering, with the default use of euclidean distance in most clustering algorithms. Wu and Yang introduced a new similarity metric in c-means clustering to overcome the limitations of the euclidean norm and developed two new clustering algorithms, ahcm and afcm. Additionally, the km-m+ algorithm utilizes the mahalanobis distance for clustering, aiming to direct clusters towards roughly elliptical shapes. The imwk-means algorithm, employing a weighted Minkowski distance, has the capability to address the drawbacks of k-means in defending against noisy features. The optimization of means algorithm derived a new distance metric, s-distance, with the s-divergence and used it in k-means, although the algorithm requires the specific number of clusters as a parameter. Meng et al. defined a new similarity metric in k-means to capture differences in trend characteristics between data points by considering the importance of derivative information.

In addition to internal validation indices, some clustering algorithms have the ability to automatically determine the number of clusters. For instance, x-means extends k-means by making local decisions for cluster centroids in each iteration of k-means and employs bayes information criterion or akaike information criterion to split itself for better clustering, although it is still affected by the initialization problem. The r-em algorithm, based on the gaussian mixture model, is a robust em clustering algorithm that addresses the sensitivity of em to initial values. The c-fs algorithm determines cluster centroids by locating density peaks using a heuristic, assuming that cluster centroids are characterized by higher density than their neighbors and by a relatively large distance from points with higher densities.

The choice of distance metric in hierarchical clustering algorithms, particularly the Minkowski distance, plays a crucial role in detecting clusters with shapes other than spherical. Additionally, determining appropriate parameters such as "p" and "b" is essential. The rl-fcm algorithm introduces an entropy penalty term to adjust the bias of fuzziness index, creating a robust learning-based model to find the optimal number of clusters, although it does not allow the provision of the number of clusters.

The work was supported by various research grants, including the National Natural Science Foundation of China and the Natural Science Foundation of Hunan Province, among others. Zheming Yuan, the principal investigator and director, holds a Ph.D. in agroecology and is a professor at Hunan Agricultural University. Zhijun Dai, an assistant professor at the Hunan Agricultural University, received a Ph.D. in bioinformatics and is actively involved in research related to feature extraction, dimension reduction, support vector classification, and regression, with applications to biological big data.