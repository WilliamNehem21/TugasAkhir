The application of semantic dependency analysis (SDA) in natural language processing (NLP) is extensive. This paper presents an integrated approach using multiple classifiers for SDA of Chinese. A naive Bayesian classifier, a decision tree, and a maximum entropy classifier are combined using a majority voting scheme. A portion of the Penn Chinese Treebank was manually annotated with semantic dependency structure, and the three classifiers were trained on the same data. The proposed approach achieved an 86% accuracy in experimentation, demonstrating promise for semantic dependency analysis of Chinese.

While research on semantic parsing using statistical and machine learning methods has been extensive for European languages, such as English, relatively less has been done for Chinese due to the lack of publicly available semantically annotated corpora. Existing corpora, like the Sinica Treebank by Gan and Wong and the 1,000,000-word scale corpora by Li et al., have limitations. Limited research has been conducted on partial semantic information assignment and semantic role labeling (SRL) for Chinese.

The paper describes dependency grammar and SDA, particularly in the context of Chinese, and explains how SDA builds a dependency tree to determine semantic relationships between words based on dependency links. A large annotated corpus with semantic knowledge was created by Li et al. using dependency grammar structure, but automating semantic information tagging remains an ongoing research goal.

The paper also highlights differences between SRL and SDA, emphasizing that SRL focuses solely on the main verb of the sentence, while SDA considers the entire sentence and any related words or chunks with a dependency link. The integration of multiple classifiers through a majority voting approach is found to be more effective than using a single classifier.

The paper outlines the following sections: a description of dependency grammar and SDA, related work in SDA, an overview of the integrated multi-classifier approach and the individual classifiers, information about the semantic tag set and the corpus, experimental results, and concluding remarks with potential future work.

The use of a simple majority voting approach is shown to outperform a probabilistic selection method and the individual classifiers. The paper also provides detailed explanations about the Naive Bayesian classifier and maximum entropy modeling, as well as the use of semantic dependency relation tag set imported from Hownet, a Chinese thesaurus.

The experimental work involved manual annotation of a portion of the Penn Chinese Treebank with headwords and semantic relations according to dependency grammar, resulting in 27,000 words with 24,487 semantic relations. The multi-classifier approach combining naive Bayesian, decision tree, and maximum entropy classifiers yielded improved results compared to individual classifiers.

Based on the promising results, the paper outlines future work, including enlarging the corpus, exploring new classifiers such as support vector machines, and investigating new features and combining classifiers using different feature sets in the multi-classifier approach.