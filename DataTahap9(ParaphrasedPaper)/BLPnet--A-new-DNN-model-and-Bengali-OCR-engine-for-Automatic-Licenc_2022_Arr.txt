al-shemarry and colleagues enhanced vlp detection accuracy by addressing environmental artefacts such as poor-contrast and noisy images caused by foggy, distortion, and dusty conditions. They achieved this by using a binary descriptor with contrast enhancement, but their proposed system was limited to real-time application due to poor frame rate and higher computational cost. Zou et al. proposed a bi-LSTM model to tackle motion artefacts, such as blurry input images, which resulted in a lower accuracy of 79.55%. Another recent development, the YOLOv4 model, employs object bounding-box detection for ALPR systems and can localize VLPS with high accuracy and frame rate.

Curvelet coefficients of an original image and its morphologically changed copies were used to train a model for recognizing twenty popular Bengali fonts. This approach resulted in an overall recognition accuracy of 96.8%. Hasnat et al. attempted to introduce Bengali script in Tesseract OCR, enabling Tesseract to learn new languages or alphabets with training.

Rabby et al. introduced a 13-layer CNN model, bornonet, for Bengali character recognition. Despite its relatively higher accuracy, the model's applications to an ALPR system have not been studied. In response to the potential gap in ALPR systems for Bengali VLPs, the authors developed a real-time end-to-end DNN-based model called BLPNet.

The VLP detection model is fed with curvelet coefficients and the coordinates of the bounding box, followed by phases for detecting and extracting the VLP contour, as well as for character localization and recognition. This method reduces computational cost and improves accuracy and reliability for real-time applications.

The model includes an average pooling layer, fully connected dense layers, and dropout layers to identify objects and generate bounding box coordinates. It was pre-trained with over fourteen million images from the ImageNet dataset, allowing it to categorize images into over 1000 different classes with transfer learning ability.

The model was trained with a dataset of 1500 training and 300 validation images. From real-world video footage taken in Dhaka, Bangladesh, VLPs were detected with reasonably high accuracy, even amidst varying road conditions and high traffic congestion. The training involved 6000 iterations and utilized early stopping to reduce training duration.

Character recognition was treated as an object-recognition problem and consisted of a total of 5 convolutional 2D layers with associated max-pooling and dropout layers. The model also incorporated deblurring filters and intensity inhomogeneity invariant segmentation for character recognition.

The paper reviewed models by Li et al., Hendry & Chen, Zou et al., and Onim et al. The complexity of the models was analyzed, and the results were discussed with a focus on vehicle detection, VLP detection, and OCR and word-mapping.