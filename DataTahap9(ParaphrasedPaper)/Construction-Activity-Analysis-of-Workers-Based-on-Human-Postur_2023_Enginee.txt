Several existing approaches for worker activity recognition suffer from limitations, such as the inability to correlate activities with specific workers and the computational intensity of raw image-based systems. Furthermore, many vision-based systems rely on processing substantial amounts of video data, making real-time performance a challenge. To address these issues, this paper introduces a novel vision-based activity recognition framework that utilizes an ordinary camera to capture video input and automatically analyze worker behavior. The framework employs a lightweight pose estimation network to extract human key point information from the video, followed by a multitarget tracking algorithm to associate workers with their key points and achieve continuous frame association. Additionally, multilayer fully connected (FC) neural networks and stacked long short-term memory (LSTM) are used for action recognition and construction efficiency analysis. Experimental validation using videos from actual construction sites demonstrates the effectiveness of the proposed framework in monitoring worker activities and analyzing construction efficiency. This approach offers a promising solution for handling the complex task of analyzing construction worker activities and efficiency by leveraging 2D pose information obtained from video feeds.