In practical terms, developers of mathematical tools can choose to either eliminate ambiguity by employing a rigid yet unambiguous grammar, or they can opt for utilizing heuristics. In this paper, we briefly outline the advantages and disadvantages of the former approach in section 2, but the focus of our study is on the latter. Additionally, we specifically address ambiguity in formulas, even though more complex forms of ambiguity, such as in commands applied to ambiguous arguments, are also possible. The primary challenge is the concrete possibility that heuristics may fail to correctly interpret the intended meaning of the formula components, leading to three problematic scenarios that present challenging user interface issues.

Subsequently, we explore how the user interface of the matita system handles disambiguation. To the best of our knowledge, this is the first paper to present such a user interface. Over the past two years, the current user interface has evolved from the previous whelp interface, aiming to address issues faced by users in critical situations. Examples of such situations include instances where users spend significant time combatting the system or when the system consistently selects incorrect interpretations. Notably, there have been no recent reports of users facing critical situations for an extended period.

A comprehensive evaluation involving a group of users exposed to alternative interfaces has not been pursued due to a significant challenge: the experiment cannot be replicated in the same conditions over time without users accumulating knowledge, which would bias the results. Therefore, we propose utilizing spatial replication by involving a large and diverse group of users. However, our current user group is highly non-homogeneous, and certain individuals, such as developers who are familiar with the disambiguation algorithm or inadequately trained students, may not provide valuable insights. One referee has suggested an alternative evaluation approach unaffected by these concerns: an analysis of the user interface based on a human-computer interaction usability framework.

In summary, we have endeavored to impart practical value in this paper by detailing our unsuccessful prior experiments and elucidating the reasons for their failures. Although this does not conclusively demonstrate the efficacy of the current interface or its incapacity for improvement, the unsuccessful experiments serve as a valuable guide to common pitfalls to avoid.

In section 2, we present further justifications for addressing mathematical ambiguity, and in section 3, we delineate several sources of ambiguity in mathematics. Subsequently, in section 4, we provide background information on how ambiguity is managed in matita and whelp. The subsequent three sections describe the behavior of the matita user interface in the previously discussed scenarios, with conclusions presented in section 8.

Furthermore, replacing standard notation with an unambiguous one offers a distinct advantage from the user's perspective: both the system and the human interpreter attribute the same meaning to every component of the formula. Consequently, if the formula is accepted, it is unequivocally the intended one; conversely, if an error is indicated, the error is clearly meaningful.

In conclusion, the choice between standard language and a custom one is often dictated by the specific usage scenario of the tool. In numerous situations, only the former option is feasible. For instance, when employing theorem provers for educational purposes, it is essential to adhere to the exact notation used in the classroom to gain acceptance from mathematical educators and students. Another motivating example pertains to mathematical tools utilized for exploring or utilizing portions of an unknown mathematical library, where deviating from traditional mathematical notation precludes the querying of the library's content involving formulas. Our work on mathematical disambiguation was initially spurred by the development of the whelp search engine, which facilitates the search for theorems whose conclusions are instances or generalizations of given formulas. Notably, the disparity between the user interfaces of whelp and matita is driven by the different user interaction scenarios of the two tools.

Interpretations generated in one pass are all characterized by a criterion of adherence to the aliases. Subsequent passes employ progressively looser criteria, resembling interpretations for formulas recently input by the user. We currently use five sequential passes, with each pass attempted only after the preceding ones failed to produce a valid interpretation. We provide examples to illustrate the necessity of each pass.

When multiple correct interpretations are generated in the same pass, they are ranked equally. The user interface must therefore gather sufficient information from the user to select the correct interpretation among those ranked highest, or, when required, among all rankings. This is detailed in section 6. In scenarios where only one interpretation is maximally ranked, the system avoids user interaction but risks selecting the wrong interpretation. Hence, similar to the first scenario, it is crucial for the user interface to offer non-intrusive feedback on the interpretation assigned to formulas, as discussed in section 5.

To efficiently integrate the detection of spurious errors in our disambiguation algorithms, we rely on benchmarks that demonstrate its effectiveness in reducing the average number of errors presented to the user. Subsequently, a lightweight user interface is employed to present any remaining non-spurious errors, potentially arranged according to passes, and to display spurious errors upon request, although false positives are rare. This is the subject of section 7.

Given the overloaded nature of mathematical notation and the automatic selection of interpretations by the system, it is crucial to provide feedback to the user on how formulas are interpreted. We believe that hyperlinking each symbol, constant, and notation to its semantic definition is adequate feedback, already implemented in the matita theorem prover and helm/mowgli web interfaces. Alternatively, the traditional practice of adorning symbols with explicit interpretations could be employed, as was previously implemented in an early version of the helm/mowgli web interfaces and is intended for integration into the matita interface. However, instead of a global application, this would be locally implemented for selected formulas, as recommended by a referee.

When the system cannot determine the intended maximally ranked interpretation, a tree of discriminating questions among interpretations is computed. Each node in the tree signifies a multiple-answer question about the meaning of a symbol, with possible answers derived from the meanings employed in the set of correct interpretations. The effectiveness of this approach, particularly in scenarios where the library content is unknown, has been observed, such as in instances where students are unaware of the organizational structure of the standard matita library and inadvertently omit necessary scripts. Moreover, the explicit aliases automatically inserted by the system alleviate the need to search for lemmas in the library when scripts are executed again.

Matita currently incorporates the new interface presented in the paper, and plans are in place to apply a modified version of the new user interface to whelp. The primary distinction between the two implementations lies in the use of aliases to rank interpretations. In an interactive theorem prover, the system can discern when a user transitions to a different topic; however, a search engine merely responds to a sequence of queries that may or may not be related. Consequently, users should have more explicit control over the management of aliases to discard them and commence a new session of queries without the influence of previous disambiguation choices.

As outlined in the introduction, validating the system and alternative interface variants posed particular complexity, as a large group of users with uniform skills formalizing the same content in parallel was not feasible. Furthermore, having the same user redo the same formalization yielded biased results due to enhanced user understanding and altered mistake patterns. Therefore, assessing the user experience across different formalizations was deemed impractical. A practical alternative, suggested by a referee, involves evaluating the system using a usability framework, a venture we intend to pursue in the future. As of now, the main evidence of the efficacy of our work lies in the current satisfaction levels of our users, compared to their dissatisfaction with previous interface versions where disambiguation often proved to be a significant obstacle due to user interface issues. This has no longer been the case since the implementation of the interfaces described in sections 6 and 7.