Prior approaches to single image dehazing with learning-based methods focused solely on using clear images to train the dehazing network, overlooking valuable information present in the datasets such as hazy images, media transmission maps, and atmospheric light values. In response, this study introduces a local feature residual network (LFR-Net) designed to enhance the quality of dehazed images by fully leveraging the information available in the training dataset. The LFR-Net employs a backbone structure consisting of feature residual blocks and an adaptive feature fusion model. Furthermore, to preserve fine details in the dehazed images, an adaptive feature fusion model is devised to effectively blend shallow and deep features at each scale of the encoder and decoder. Empirical evaluations demonstrate that the performance of LFR-Net surpasses that of existing state-of-the-art methods. 

While previous learning-based image dehazing methods have enhanced network performance by increasing the layers of the dehazing network, this has also led to increased computational resource requirements. However, these methods have not fully utilized the transmission maps and atmospheric light values available in the dehazing training datasets. Most existing dehazing methods follow an encoder-decoder structure, wherein the encoder extracts main features from the hazy image and the decoder restores a clear image. However, many network encoders have shallow layers at different scales, resulting in the loss of details in the clear image during restoration. The proposed LFR-Net addresses this issue by incorporating a feature residual block and an adaptive feature fusion model to preserve shallow and deep features and improve the preservation of details in the dehazed results.

The paper is structured as follows: Section 2 discusses related work on image dehazing, Section 3 systematically describes the proposed approach and its components, Section 4 presents comparative experiments with state-of-the-art methods and ablation experiments, and finally, Section 5 provides a summary and outlines future research.

The loss function of LFR-Net is comprised of L1 loss, perceptual loss, and haze loss. The L1 loss and perceptual loss have been shown to perform well in image restoration tasks, and are chosen to optimize LFR-Net. Additionally, the proposed haze loss leverages input hazy images and the haze-loss image to supervise the training process of the neural network.

To evaluate the dehazing ability of LFR-Net, the paper presents experiment settings, comparison experiments with seven state-of-the-art methods, and ablation experiments to demonstrate the effectiveness of the architecture of LFR-Net. The ablation study assesses the usefulness of each module, including the feature residual block, adaptive feature fusion model, and haze loss, to prove the structural superiority of LFR-Net.

In summary, this study introduces a local feature residual network for single image dehazing that fully utilizes information available in the training dataset to improve dehazing quality. The proposed LFR-Net structure, including the feature residual block and adaptive feature fusion model, enhances the capability to extract deep features and preserve details in the dehazed images. A haze loss is also incorporated to guide the training process by leveraging information from haze-free images, hazy images, transmission maps, and atmospheric light values. Extended experiments demonstrate the superiority of LFR-Net, both qualitatively and quantitatively, and ablation experiments further highlight the usefulness of the LFR-Net structure. Furthermore, the study identifies the limitation of existing dehazing methods which poorly process real-world images and proposes future research on unsupervised image dehazing to address this issue.