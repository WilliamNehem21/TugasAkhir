The second iteration of the Rewrite Engines Competition (REC) was featured as part of the 7th Workshop on Rewriting Logic and its Applications (WRLA 2008). In this round, five systems—ASF+SDF, Maude, Stratego/XT, TermWare, and Tom—participated. This paper outlines the competition's organization, conduct, main results, and conclusions.

The first rewrite engines competition aimed to assess the feasibility of such a competition and gauge community interest. Building off the interest generated, the second edition involved more systems and a broader set of problems. Results, conclusions, and future challenges from the competition are presented in this paper. The initial competition focused on efficiency, specifically speed, memory management, and built-in usage. Only two systems, ASF+SDF (represented by Mark van den Brand) and Maude (represented by Steven Eker), participated. The competition entailed compiling a set of test examples using features supported by both systems, written in a mathematical and intuitive notation and translated by an independent researcher with input from the developers.

The selection of participating engines prompted discussions on the varying system types and difficulties in comparison. Four categories of problems—unconditional rewriting, conditional rewriting, rewriting modulo, and context-sensitive rewriting with local strategies—were identified, including classical rewriting problems suitable for each class of rewriting systems.

To address differing system capabilities in defining languages and transformations, a simple rewriting language called REC was created. The competition proposed writing programs to transform problems in REC syntax to the syntax of the corresponding tools, with the aim of simplifying handling of small programs. While not all participants were able to provide translators for their systems, those from Maude, Stratego/XT, and Tom were made available. Comparisons between the translators revealed differing implementation approaches and the need for more time to accomplish this task.

Due to the heterogeneous nature of the participating systems and an expanded scope of the competition, an in-depth analysis of all results was not possible. Instead, specific highlights of the competition were emphasized. Maude's optimizations enabled superior performance in certain tests, in contrast to automatically generated ones where the Tom compiler outperformed. Stratego/XT encountered challenges in handling some tests.