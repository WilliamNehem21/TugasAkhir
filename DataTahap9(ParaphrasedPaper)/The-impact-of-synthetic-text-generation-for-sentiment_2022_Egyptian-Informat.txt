The remaining sections of the paper are structured as follows. Section 2 provides a review of pertinent literature related to text generation and sentiment analysis. Section 3 outlines the methodology, covering details regarding datasets, preprocessing techniques, text generation model architectures, and evaluation metrics. Section 4 delves into the key findings from various text generation models and sentiment analysis experiments conducted on both original and balanced datasets. Lastly, Section 5 presents the conclusions drawn from the study and outlines potential future research directions.

The paper also includes findings related to Bleu score calculations. The black dotted line signifies the division between the pre-training and adversarial training phases. The pre-training phase involves training the initial generator, while the adversarial training phase focuses on strengthening the pre-trained generator to enhance the quality and diversity of the generated text.

Section 3.4 details the usage of Bleu scores with n=2, 3, 4, and 5 for both Sentigan and Catgan across the CR23K and CR100K datasets. Higher Bleu scores indicate that the generated text closely resembles the original. The analysis reveals that Sentigan experiences a gradient vanishing problem on both datasets, leading to a lack of diversity in the generated text and repetitive generation of the same sentence. Based on these findings, Catgan is selected to generate reviews, which are then used to balance the original datasets.

Furthermore, the study demonstrates that implementing Catgan results in an improvement of the minority class representation by 2.79% and 9.208% for the CR23K and CR100K datasets, respectively. In the future, the research can be expanded to explore more sophisticated text generation models such as GPT-3 and more complex sentiment analysis models in order to develop more robust and versatile models.