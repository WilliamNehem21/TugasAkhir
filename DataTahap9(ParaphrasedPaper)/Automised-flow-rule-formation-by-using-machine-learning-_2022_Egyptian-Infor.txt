The aforementioned academic paper discusses the challenges associated with static principle forming and dynamic rule shaping in software-defined networks, highlighting the tedious and troublesome nature of the process. To address these issues, the paper proposes a reinforcement learning-based method aimed at enhancing rule management at the controller side, thereby avoiding bottlenecks and improving efficiency. This is achieved by automating the rule generation process, allowing the controller to generate rules based on past experiences.

The paper is structured as follows: Section 2 outlines the details of software-defined networks and their relationship with machine learning-based rule generation. Section 3 delves into related work and the problem at hand. Section 4 describes the proposed rule formation agent design as well as its development steps, while Section 5 presents the experimental results. The paper concludes by discussing future directions for research.

The application layer, which provides services to the controller, is positioned at the top of the SDN. It creates flow rules for network packets, serving as the foundation for packet scheduling. Equipped with information about network applications and network topology, the application layer monitors the network's state and communicates with the control layer using control messages. The controller, also known as the brain of the network, is the central component of the SDN and is connected to the application layer. The control plane, consisting of the controller and the infrastructure, communicates with the data plane (i.e., the switches) via southbound APIs, dictating how the switches handle network flow.

The authors in The authors of previous work in the context of rule formation emphasized dynamic flow rules in SDNs. Their research focused on increasing the flow of SDNs by enabling switches to create their own flow entries, thereby enhancing network data processing efficiency. The proposed strategy allows switches to form rules locally, leading to improved traffic flow within the network. The research presented three distinct procedures for implementing this strategy, with the authors claiming that it enhances SDN network efficiency. This work serves as an extended version of OpenFlow.

To evaluate the performance of the proposed reinforcement learning-based method, the researchers conducted simulations using the OpenDaylight controller and Mininet tools, with an Ubuntu platform installed on a virtual environment using VirtualBox. They benchmarked the proposed approach against classical SDN implementations, considering factors such as throughput, packet loss, and flow insertion delay.

Packet loss often occurs when a flow rule is missing, resulting in increased network latency. To address this, the authors developed a model trained based on past rules, effectively automating the process of dealing with issues at the switch level. Leveraging reinforcement learning and past rules provided by the application layer, the model was trained to minimize the impact of problems in the software-defined environment.

While this approach has gained popularity in the realm of technology, it also has its drawbacks that need to be addressed. The research targeted a fundamental issue in traditional software-defined networks – the management of flow rules – and proposed a methodology using reinforcement learning to automatically form flow rules, addressing problems related to missing rules and security threats. The results of the research indicate that this approach can contribute to the improvement of the software-defined networking environment. The authors also note the potential of using supervised learning techniques in the future for auto rule formation.

Overall, the paper aims to contribute to the intelligent software-defined networking environment by addressing concerns such as network latency and missing flow rules. It also lays the groundwork for future research involving other machine learning algorithms to address software-defined networking challenges.

