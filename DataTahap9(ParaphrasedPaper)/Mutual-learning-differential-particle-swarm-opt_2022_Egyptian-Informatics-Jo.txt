Particle swarm optimization (PSO) is a widely used optimization technique that relies on basic mathematical operations to achieve fast convergence and high performance. Since its introduction in 1995, numerous variants of PSO have been developed, leading to significant improvements in its performance. However, most existing PSO variants are only effective for specific types of optimization problems and struggle to deliver high performance across various problem domains.

The integration of differential evolution (DE) and PSO algorithms has garnered attention in the evolutionary computation community due to the potential for developing high-performance hybrid algorithms. This paper proposes a mutual learning strategy for hybridizing DE and PSO, along with the introduction of an elite mutation to expedite the convergence speed of the DE subswarm. The study entails a comprehensive review of related works, followed by the presentation of the methodology and experimental results.

In the proposed mutual learning strategy, the DE and PSO subswarms operate concurrently, exchanging elite information to enhance the quality of the population. The position vector of the PSO subswarm is utilized for DE mutation, hastening the response of the DE subswarm. Additionally, an elite DE mutation is employed to accelerate the convergence speed of the DE subswarm.

The performance of the proposed hybrid algorithm (MLDE-PSO) is compared with seven peer algorithms, encompassing state-of-the-art PSO and DE variants. Experimental results demonstrate the superior convergence speed of MLDE-PSO on several benchmark functions, outperforming other algorithms in terms of accuracy and convergence speed. MLDE-PSO exhibits enhanced performance on different types of functions, demonstrating advantages over existing algorithms, particularly in handling unimodal and multimodal functions.

Furthermore, the integration of DE and PSO in MLDE-PSO is found to enhance the algorithm's performance on complex and rotated functions, showing minimal sensitivity to rotation transformation compared to its counterparts. However, the algorithm's performance on penalty functions is relatively weaker. Future research will focus on extending MLDE-PSO to constraint test functions and real-life optimization problems.