This paper provides an overview of recent advancements in global optimization. The authors have curated a substantial number of references that exemplify the current breadth and depth of computational methodologies and theoretical findings related to nonconvex optimization problems. The paper is divided into sections that cover heuristic and exact approaches to optimization. Additionally, it outlines the origin of the discipline, discusses the survival and revival of certain approaches, and explores the application of optimization techniques in the context of machine learning.

The paper presents a survey of heuristic computational approaches published in recent literature, particularly after the publication of a book by Locatelli and Schoen in 2013. It also delves into recent literature on structured optimization problems that can be solved using exact procedures, as well as computational aspects and resources for finding test problems and solvers. The concluding remarks address recent developments related to the main operations of branch-and-cut approaches, highlighting the use of geometric forms and interval arithmetic for poorly structured problems.

The authors discuss the use of machine learning-guided optimization methods in the field of chemical physics, citing specific examples. Furthermore, they mention a paper that addresses the absence of local optima when using a quadratic loss in training deep neural networks, providing insight into the success of local optimization algorithms in this context. The section concludes by referencing the availability of polynomial-time approximation schemes for problems lacking a polynomial-time solution algorithm.

The paper also explores the application of mixed second-order cone programming-semidefinite programming relaxations for bounding optimization problems, highlighting their trade-offs in terms of computational efficiency and solution quality. Additionally, it mentions alternative representations of sum-of-squares polynomials and discusses the results of computational experiments on various test problems and solvers. The outcomes indicate that no single method dominates the others across different problem subclasses.

Finally, the paper discusses the challenges of molecular conformation problems in global optimization and proposes guidelines for fair comparisons between different solvers. It also highlights the opportunities for benchmarking solvers through platforms such as the CEC competitions and the Comparing Continuous Optimizers (COCO) platform at GECCO-BBOB workshops.