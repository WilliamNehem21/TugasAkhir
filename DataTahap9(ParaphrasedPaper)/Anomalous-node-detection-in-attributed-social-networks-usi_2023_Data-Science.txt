Anomaly detection often seeks to identify abnormalities in order to gain a deeper understanding of the underlying data distribution. Attributed networks, which contain various user characteristics and connections between users, offer a rich source of information for such analysis (Khan and Haroon, 2022a). The detection of anomalies in attributed networks, which involves identifying nodes significantly dissimilar from the rest, has gained significant attention due to the increasing prevalence of such data structures in practical applications such as social networks, protein data analysis, and financial services. This method has been applied in diverse areas, including the detection of social spammers, financial fraud, and intrusions.

Conventional machine learning algorithms like supervised anomaly detection approaches face challenges when the data is imbalanced, impacting their ability to achieve satisfactory results (Khan and Haroon, 2022b). As obtaining labeled anomalies can be prohibitively expensive, unsupervised anomaly detection methods have been developed. Unsupervised techniques often classify the least fitting examples as outliers on the assumption that the rest of the data is typical. With the advent of neural networks, various techniques inspired by neural networks, specifically autoencoders, have advanced anomaly detection methods. Autoencoders, particularly those incorporating variational inference, have improved the systematic performance of anomaly detection by relying on reconstruction probability instead of reconstruction error (Kingma and Welling, 2014).

The regularization of latent codes, which ensures they conform to a predetermined distribution of the underlying data, has emerged as a common solution for addressing the issue of unsatisfactory representation resulting from sparse and noisy graph data. Recent progress has been made in learning robust latent representations using generative adversarial-based frameworks.

This study introduces the adversarial regularized dual graph VAE, an unsupervised method for detecting unknown anomalies in datasets, particularly in social networks. The proposed model addresses data nonlinearity and network sparsity by employing dual VAEs. In addition to embedding structural information and attributes into a vector representation, the dual VAEs are used as generators for creating fake nodes. Adversarial training is employed to ensure that the latent codes adhere to a predetermined Gaussian or uniform distribution.

Effective anomaly detection offers significant contributions to the field of data science and management by enhancing decision-making, enabling early detection, reducing risks, improving operational efficiency, optimizing resource allocation, and facilitating prompt responses to emerging issues.

The remainder of the paper is organized as follows: Section 4 introduces the proposed anomaly detection methodology, Section 5 compares and contrasts assessment measures to demonstrate the practical efficacy of the proposed methods, and Section 6 concludes the paper.

This study presents a valuable theoretical contribution by combining a GAN with a pair of VAEs to detect anomalies in real-world networks. The proposed model demonstrates a nuanced understanding of anomaly detection, particularly in the context of real-world applications such as online marketplaces and social media networks, highlighting its potential impact on safety and fraud prevention.

Theoretical models and practical strategies should be tailored to fit the specific characteristics of each dataset, as demonstrated in the study's nuanced analysis of the Enron dataset. This underscores the importance of flexibility in data science projects and the need for context-specific investigation.

Furthermore, the study emphasizes the significance of regularizing latent codes in anomaly detection models and suggests implications for management practice, including the emphasis on reliable data and the use of adversarial training to safeguard data-driven applications.

In conclusion, the study highlights the relevance of reliable anomaly detection, the value of high-quality data, and the need for flexibility when dealing with complex real-world data problems, offering useful insights for data science management practices.

The proposed method was evaluated on three different datasets: blogcatalog, flickr, and enron, and experimental findings demonstrate the effectiveness of the proposed model compared to standard approaches. The study suggests potential for achieving state-of-the-art performance for anomaly detection on high-dimensional, complex datasets by employing GAN models.