In the past ten years, there has been an increasing emphasis on incorporating self-adaptivity into the design of modern information and communication systems. This trend, evident in concepts such as intelligent systems, cyber-physical systems, internet of things, and self-aware computing systems, represents a shift in systems engineering towards configurations of distributed autonomous subsystems that dynamically integrate into an overarching system constellation and autonomously adapt their behavior in response to changing situations. Throughout this article, we use the term "self-adaptive and self-organizing (SASO) systems" to refer to systems with the capability to independently adjust their behavior and their structural integration in collaboration with other subsystems.

The paper discusses the foundational system model for SASO systems, outlining the authors' assumptions and reviewing related work. Section 3 presents a method for measuring the stability of adaptation behavior, which is subsequently analyzed experimentally in Section 4. The article concludes in Section 5 by summarizing the findings and offering insights into future research directions.

In this context, a SASO system is defined as a collection of autonomous subsystems that can adapt their behavior based on their awareness of internal and external conditions. The article also assumes that each subsystem interacts with other entities, such as hardware, software, humans, and the physical world, collectively referred to as the environment of the system. The system boundary delineates the interface between the system and its environment.

While there have been a limited number of contributions focusing on general metrics to evaluate the cost and benefits of self-adaptation in distributed autonomous subsystems, previous work has explored metrics such as the relationship between working and adaptation time, subsystem availability for task processing, and overall system performance. However, there has been a lack of emphasis on the degree of adaptation, the stability of adaptations, and the framework for balancing potential performance improvements of individual component systems with potential negative impacts on macro-level behavior.

Kinoshita introduces a measure as an indicator for detecting unusual activity changes in distributed multi-agent systems, defining the activity factor and the variance of fluctuation of the activity factor. The activity factor is determined based on the classification of each agent as active or inactive, with the total number of agents and the number of active agents at a given time influencing its calculation. Kinoshita's measure proves to be applicable even in environments with significant noise, although its performance in identifying major events may diminish compared to scenarios with less noise.