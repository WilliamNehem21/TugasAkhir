Enabling rapid data update propagation from row-based to column-based data stores is critical for supporting real-time analytics, as the latency of data update propagation directly impacts the freshness of analytical data. The process of data update propagation can be broken down into three key steps: transferring the data update from row-based to column-based data stores, converting the data format from row-based to column-based, and integrating delta updates into the column-based data store. HTAP databases aim to optimize one or more of these steps in order to enhance the freshness of analytical data. For example, TiDB retains only the committed change log and eliminates redundant information before translating it.

HTAP databases are significantly lacking in micro-benchmarking due to the absence of open-source micro-benchmarking tools. In this study, we develop and implement a micro-benchmark to investigate the differences between micro-benchmarking and macro-benchmarking. Our benchmark specifically focuses on the state-of-the-art HTAP benchmark, OLXPBench, as a point of comparison. Micro-benchmarking is more suitable for evaluating real-time analytics as it carefully controls the rate at which fresh data is generated and the granularity of fresh data access. Micro-benchmark queries typically involve single statements, such as calculating the number of rows within a specified range for analytical queries. This illustrates that the computational intensity of analytical queries can be managed by adjusting their computational scope.

To avoid lengthy turnaround times for delta updates, we deploy transactional and analytical instances on the same server. Other HTAP databases handle online transactions and analytical queries on separate servers to prevent performance interference. This section delves into how HTAP databases achieve real-time analytics and performance isolation.

Well-known distributed HTAP databases such as SingleStore and OceanBase both utilize unified storage to facilitate online transactions and analytical queries. OceanBase demonstrates notable proficiency in resource isolation. Additionally, PolarDB-IMCI also provides effective resource isolation for transactional and analytical queries.

The CH-Benchmark encompasses both online transactions and analytical queries. The OLTP workloads align with the TPC-C transactions, including new-order, payment, order-status, delivery, and stock-level transactions. The default percentages for these transactions are 44%, 44%, 4%, 4%, and 4% respectively. Within the CH-Benchmark, order-status and stock-level are read-only transactions, while the remaining three are update-intensive transactions. Furthermore, the benchmark includes 22 analytical queries derived from the TPC-H benchmark, which retain the majority of business semantics but are adjusted based on the CH-Benchmark schema.

The CBTR benchmark offers four online read-update transactions, three online read-only transactions, and four online analytical queries. CBTR utilizes actual business data rather than synthetic data generated by data generators. However, it is not widely recognized due to its closed-source nature.

Transactions in FiBenchmark are exclusively read-only, and 80% of online transactions in Tabenchmark are also read-only. Additionally, both benchmarks include increased analytical queries and hybrid transactions based on semantically consistent schemas. The analytical queries encompass complex analytical statements such as aggregation and multi-join. The hybrid transactions involve integrating analytical statements into online transactions, with read-only hybrid transactions constituting 60%, 20%, and 40% of the SuBenchmark, FiBenchmark, and Tabenchmark, respectively.

Hattrick encompasses both online transactions and analytical queries and offers three online transactions akin to the TPC-C benchmark. The transactional workloads consist of 48% new-order, 48% payment, and 4% count order transactions. The new-order and payment transactions are update-intensive, while the count order transaction is read-only.

The Adapt and HAP benchmarks provide an abstraction of basic HTAP operations, although they feature a limited number of typical HTAP workloads and are not open-source. It is essential for micro-benchmarks to encompass a variety of scan queries, including point queries, small-range queries, and large-range queries, to optimize the indexing of HTAP databases. Furthermore, micro-benchmarks should ensure that read and write operations access the same columns to evaluate the data update propagation capability effectively.

The server node is equipped with two Intel Xeon E5-2699v4@2.20 GHz CPUs, 128 GB memory, and two 2TB SSDs, while the client node features two Intel Xeon E5645@2.40 GHz CPUs, 48 GB memory, and eight 2TB HDDs. Both the server and client run on the Ubuntu 20.04 version and are connected via a 10 Gbps Ethernet network.

This paper provides a comprehensive overview of HTAP database strategies for enhancing performance isolation and real-time analytics. Furthermore, it compares state-of-the-art and best-practice HTAP benchmarks in terms of schema model, workloads, and evaluation metrics. The CBTR, OLXPBench, Hattrick, Adapt, and HAP benchmarks all utilize semantically consistent schemas. OLXPBench is innovative in that it implements a hybrid transaction that executes an analytical statement within an online transaction, while Hattrick contributes the throughput frontier and freshness metrics.