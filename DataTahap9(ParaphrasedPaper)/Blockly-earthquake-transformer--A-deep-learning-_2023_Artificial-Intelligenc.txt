Validation involves testing a model against data not used during training before creating a final phase picker model. Typically, 20% of the dataset is retained and excluded from the training set. The model's performance on this validation set indicates its potential to accurately predict phases when faced with independent seismic data. Based on the validation results, the trained model may be approved, adjusted, or rejected. The validation stage should not be time-consuming, but if the model is rejected, the project returns to the training stage to revise the architecture and parameters. This iterative training and validation process continues until a satisfactory model is achieved.

Experimental results demonstrated that this approach leads to faster model convergence during training. Users can select default p and s pickers for phase picker channels or choose additional channel identifiers (e.g., p, pg, pn, s, sg, sn) if these labels are available in the training metadata (i.e., catalog picks). The output channels are automatically rewritten based on these selections by the software. Alternatively, users can use the default p and s labels as surrogates for other binary labels, such as blasts and natural earthquakes, to initiate training a new model for discriminating anthropogenic and natural events.

The paper presents the review of p and s arrival times taken from the nedb catalog at station cn.btb for a magnitude 2.0 event on 2015-01-02 at an epicentral distance of 78 km.

The use and development of deep learning (DL) models in seismology are steadily increasing. The software provides a user-friendly platform for a wider range of users, including those without machine learning or coding experience, to explore DL pickers. It eliminates the need for in-house computational power and addresses other technical concerns. The software is expected to enhance model performance and reduce the magnitude of completeness of existing seismic catalogs. Similar packages can be designed for other seismological tasks, including those in exploration seismology, where fine-tuning pre-trained models with synthetic data is more common due to the scarcity of large-scale labeled training datasets. The software can also be used for discriminating between natural earthquakes and anthropogenic events, with separate training datasets developed for each event type. It is practical for students to understand deep learning applications and is convenient for researchers.

The research was funded by a discovery grant (RGPIN-201803752) from the Natural Science and Engineering Research Council of Canada (PA). The authors express their gratitude to Stephen Crane, Laurel Sinclair, two anonymous reviewers, and the editor for their feedback on this manuscript. This is NRCan publication number 20220610.