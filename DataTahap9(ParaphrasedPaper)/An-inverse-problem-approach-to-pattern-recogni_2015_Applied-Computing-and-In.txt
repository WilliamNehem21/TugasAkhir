Advancements in high-speed computers and artificial intelligence techniques have transformed the modeling problem into a machine learning problem. Recent interest in learning algorithms has been driven by both theoretical and computational motivations, with the utilization of fractal, optimization, and a two-dimensional functional relational model in pattern recognition methods. There is a focus on exploring the potential of using artificial neural networks (ANN) for the automated reconstruction of an object's inner structure, necessitating accompanying algorithms that can effectively quantify uncertainties, address ill-posedness, and account for nonlinear models. It is essential to seek ways to enhance existing classical learning algorithms and identify new methods that can rival traditional ones in terms of speed, robustness, and result quality.

The paper is organized as follows: the next section elucidates the model and justifies its usage, while Section 3 formulates the proposed regularized learning algorithm. Section IV presents the main simulation results, and Section V compares the regularization-based algorithm (RBA) with the support vector machine (SVM) and semanteme-based support vector machine (SSVM). The paper is concluded with a summary of the work in Section VI.

The efficiency of the algorithm is evaluated using the misclassification rate, which represents the ratio of misclassified exemplars to the total number of exemplars in the dataset. Classification accuracy is determined correspondingly. Many classification algorithms are reliant on exemplar similarity or dissimilarity, such as Euclidean distance and inner production, but most only process continuous-attributed data, excluding discontinuous data like surfaces due to their extreme, disordered, and unbalanced distribution.

Introducing a new learning algorithm requires improvements on both the algorithm itself (exploring different regularizer properties) and its applications (such as non-homogeneous 3D object recognition). Further work is needed to enhance the numerical effectiveness in general, and the sensitivity of the method to moderate levels of noise remains an open question.