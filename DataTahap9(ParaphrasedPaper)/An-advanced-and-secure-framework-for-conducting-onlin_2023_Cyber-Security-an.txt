Cluskey et al. explored methods for conducting proctored online exams, focusing on preventing cheating by students. They recommended strategies such as scheduling exams at a specific time, using respondus lockdown browser, and verifying student identification. Tejra et al.

In the context of online exams, sescp-f outlines a system to create a database and use a paraphrasing tool to check for plagiarism in answer scripts. The tool employs techniques such as synonym usage, altering grammatical structure, and changing parts of speech. It also utilizes semantic-based, grammar-based, and clustering methods to detect plagiarism.

Additionally, sescp-g defines plagiarism and outlines procedures to address scripts with significant instances of plagiarism. Answer scripts with a high plagiarism percentage are flagged for inspection and action by the teacher.

The authors also proposed an automated system for online test administration, where candidates must complete the test within a specified time frame. The system generates real-time reports and expedites result processing. For long-answer questions, the system verifies and calculates responses, and test results are communicated to candidates through email or a website.

In the context of challenges faced by countries like Bangladesh in establishing effective e-learning systems during the COVID-19 pandemic, the authors proposed leveraging artificial intelligence, blockchain, RDP, and smart login systems to mitigate the limitations of online exams. They presented an AI-based blockchain framework aimed at securing online examination systems, with the expectation that it will significantly contribute to the advancement of e-learning, enabling teachers to conduct exams with the same integrity as in physical classrooms.