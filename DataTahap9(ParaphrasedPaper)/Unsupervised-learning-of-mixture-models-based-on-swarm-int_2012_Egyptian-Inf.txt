This paper introduces a novel algorithm designed for unsupervised learning of finite mixture models (FMMs) from data sets with missing values. The algorithm addresses the local optima issue associated with the expectation-maximization (EM) algorithm by integrating EM with particle swarm optimization (PSO). Furthermore, it overcomes biased estimation caused by overlapping clusters when estimating missing values in the input data set by integrating locally-tuned general regression neural networks with an optimal completion strategy (OCS). A comparative analysis demonstrates the superior performance of the proposed algorithm over commonly used methods in the literature for unsupervised learning of FMM parameters, particularly in clustering incomplete data sets generated from overlapping clusters with varying sizes.

The paper discusses the challenges associated with existing modified EM algorithms in learning FMM parameters, such as sensitivity to outliers, class overlap in the data space, and biased representation of data classes. To address these issues, a new algorithm is proposed that is less susceptible to the learning problems of the EM algorithm under these conditions. The paper is structured as follows: Section 2 presents the proposed algorithm, Section 3 shares the results of a comparison study evaluating the algorithm's performance, and Section 4 discusses these results. Finally, conclusions are presented in Section 5.

One of the main steps of the proposed algorithm involves linearly scaling the values of each feature in the input data set to the interval [0, 1]. This scaling process mitigates the impact of varying unit scales on different features, essential for identifying the true cluster structure and the contribution of each feature to this structure. Additionally, the algorithm is less constrained by weakly correlated data, and it leverages the use of general regression neural networks with local tuning to overcome limitations of the EM algorithm with small data sets containing outliers, overlapping clusters, or substantial differences in cluster sizes. The algorithm also ensures accurate estimation of missing values and FMM parameters, particularly when clusters in the data set overlap and differ in size.

The paper further discusses the process of estimating missing values using different methods such as unconditional mean imputation and nearest neighbor imputation. It also describes the comparison study using three data sets with missing values at different rates in selected features. The study evaluates algorithms based on their mis-classification error (MCE) through clustering results and the true classification of the data feature vectors.

Overall, the proposed algorithm, referred to as the polgrem algorithm, is shown to address the local optima problem of the EM algorithm and the bias problem in estimating missing values when dealing with input data sets containing overlapping clusters. Comparative evaluations highlight the superiority of the polgrem algorithm over other methods when handling data sets with outliers, overlapping clusters, or varying cluster sizes. These methods include the lgrem algorithm, the mem algorithm, the grem algorithm, and the common EM algorithm, in addition to the unconditional mean imputation method (menem) and the nearest neighbor imputation method (nnem) for estimating missing values in the input data set.