This academic paper investigates reversible speculative computing in large-scale parallel computing as a dynamic linear feedback control system model and assesses its performance in terms of time and cost savings compared to traditional forward computing. The paper utilizes an analogy of vehicular travel under dynamic, delayed route information to illustrate the concept. The objective is to aid in determining the optimal computational approach by predicting potential time and cost savings or losses under varying environments represented by different parameters and probability distribution functions, including gaussian, exponential, and log-normal distributions.

The discussion focuses on the need for a runtime controller to dynamically make decisions on when and to what extent speculative execution should be allowed, emphasizing the importance of an online control system to dynamically regulate speculative forays. The paper presents an approach based on a model-based control system design that is independent of specific applications. Different stochastic distributions for the main runtime dynamics are explored, and their effectiveness is analyzed in synthetic experiments. The study examines the problem in terms of two competing objectives: time to completion and total cost for completion, taking representative parameter values to gain initial insights into the efficacy of the approach.

The concept of reversible computing is likened to reversible speculative driving, where the idea of awaiting a route determination corresponds to the processor's correct computational path, while the speculative foray represents the processor's alternative path taken to avoid blocking computation. The paper also introduces a state and execution time duration model, along with the consideration of various probability distributions for reverse computation time, such as gaussian, exponential, or lognormal distributions.

The paper proceeds to compare different scenarios based on the developed technique, demonstrating how strategy selection is influenced by factors such as time savings and processing cost savings. The study suggests that the approach can be used to predict the performance of different strategies based on the application environment, with inputs including processing speed, probability distributions, and additional fuel cost, and outputs providing predicted time and processing cost savings. The discussion concludes by highlighting the potential implementation of the developed technique in parallel processing platforms to accelerate speculative computational forays per unit time and to predict the performance of strategies.