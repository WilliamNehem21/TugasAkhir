The use of RFID technology in the healthcare industry has expanded due to its improved functionality, affordability, reliability, and ease of use. However, the data captured by RFID readers can lead to a substantial volume of data redundancy, false positive readings, and false negative readings based on the timestamp. The presence of such "dirty data" is a major obstacle to the widespread adoption of RFID technology in healthcare. It is crucial to clean the collected data effectively before storing it in a warehouse in order to provide reliable data for RFID applications.

Various approaches, including physical, middleware, and deferred methods, have been employed to address these data anomalies, but they have limitations. The integration of middleware and deferred approaches can lead to the development of a robust RFID system. In this paper, we introduce algorithms based on a hybrid approach that have been tested in a healthcare environment using RFID, with a focus on predicting and removing false positive readings, false negative readings, and redundant data. The experimental evaluation demonstrates that our data cleansing methods effectively and accurately remove errors in RFID data. Ultimately, our planned data cleaning technique has the potential to reduce healthcare costs, streamline business processes, optimize patient identification, and enhance patient safety.

RFID technology utilizes radio communication between tags and readers for automatic item identification in a networked environment, resulting in a large volume of data being generated. However, the raw data from RFID readers is often plagued by issues such as data duplication, false positive readings, and false negative readings, necessitating the need for data cleaning before its application. In the healthcare sector, where there is a focus on cost containment and improving patient care, addressing these data quality issues is critical.

RFID readers periodically emit RF signals within their range, and when a tag within that range receives the signals, it responds with unique identifier code, timestamp, and location ID information. False positive readings occur when an RFID reader unintentionally detects tags that should not be within its range, potentially leading to inaccurate data. Additionally, duplicate readings can occur due to the spatial overlap of multiple readers, resulting in reader-level duplication, or from an RFID reader repeatedly capturing the same object, leading to data-level duplication. Our proposed approach aims to predict and clean such duplication using middleware techniques, thereby enhancing the quality of the stored RFID data. We also define rules and time bounds for tag-location combinations to further improve data quality and reduce redundancy in RFID data streams.