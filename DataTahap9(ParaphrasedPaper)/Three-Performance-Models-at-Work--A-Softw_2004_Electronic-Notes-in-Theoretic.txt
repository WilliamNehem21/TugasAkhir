The validation of software performance in the early stages of the development process is a critical issue in the design of complex software systems. However, the amount of time and effort currently dedicated to this task in software development is insufficient to prevent the occurrence of performance defects, which are often difficult to identify and address later in the development process. This inadequacy is attributed to both the pressure to bring products to market quickly and the lack of specialized skills within development teams.

Software architecture serves as an abstraction of a system that can facilitate the validation and predictive analysis of system performance. Various notations and languages are available for representing software architectures from a performance perspective. This paper focuses on performance considerations in software architectures and examines different notations for performance modeling from the viewpoint of software designers. The objective of the paper is to speculate on the descriptive capabilities of three commonly used performance model notations and their suitability for providing feedback at the architectural design level through a simple case study.

With the increasing complexity and size of modern distributed software systems, the need for tools to support design decisions has become a critical issue. Irrespective of the software development process, decisions made in the early design phases can significantly impact software development and the quality of the final product. Therefore, inaccurate decisions early on may result in costly rework, potentially affecting the entire software system.

At the architectural level, techniques for generating alternatives can impact either system components or the communication between them. The focus is on techniques that closely affect the components and their workload, falling into three categories: splitting, merging, and duplication.

Merging involves distributing the set of services provided by an underloaded component across existing components, while duplication entails creating one or more new occurrences of the same component. The paper presents a case study of an XML translator system and discusses various performance model notations, including SPA, GSPN, and QN, and their implications for software designers.

SPA and GSPN are extensions of process algebra (PA) and Petri net (PN), respectively, introducing features to model timing and probabilistic aspects of software systems. The paper assumes readers are familiar with the basics of PA, PN, and QN and discusses the specific considerations and tools for each model notation.

The paper does not compare the model notations in terms of their evaluation processes, as this is beyond its scope. The complexity of model evaluation processes can significantly differ and may introduce approximation errors in the index values. Furthermore, the complexity of different model notations may increase as the system architecture becomes more complicated.

The experiment presented in the paper is motivated by previous work in the field of software performance and software architectures. The aim is to assess the suitability of three performance model notations (and their variants) to support software designers. However, the paper does not intend to make general assessments in this field based on the reported results, due to the limitations of the case study and the experimental setting. Instead, it aims to lay the groundwork for further significant experiments in this direction.

Finally, the paper stresses the need for future research to focus on automating and engineering existing approaches for performance analysis, as well as developing user-friendly frameworks to conduct the analysis, with a focus on integrating standard behavioral modeling with performance model generation.