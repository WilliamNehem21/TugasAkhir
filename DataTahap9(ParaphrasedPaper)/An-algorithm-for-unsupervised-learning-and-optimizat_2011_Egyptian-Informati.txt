This paper presents an algorithm that combines unsupervised learning with the optimization of finite mixture models (FMM). The algorithm aims to minimize the mutual information among components of the FMM while reducing the likelihood of the FMM to fit the input data. The proposed algorithm's performance is compared with other algorithms in the literature, and results demonstrate its superiority, particularly with sparsely distributed or overlapped cluster data sets.

The paper introduces an algorithm for determining both the number of components in the FMM and its parameters in order to fit input data sets that may be sparsely distributed or contain overlapped clusters. The proposed algorithm minimizes the mutual information among components of the FMM while minimizing the reduction in the likelihood of the FMM to fit the input data. The paper is organized as follows: Section 2 presents the algorithm for integrating unsupervised learning and FMM optimization for data sets with sparsely distributed or overlapped clusters. Section 3 compares the proposed algorithm with other algorithms such as MI, MML, and BIC based on their clustering results and the determination of FMM components. Section 4 presents the conclusions.

The proposed algorithm, TUMI, is less sensitive to the number of mixture parameters and can handle sparse data sets more accurately than penalized-likelihood criteria algorithms. Additionally, tuning the mutual information theory allows the TUMI algorithm to fit data sets generated from overlapped clusters. The mutual information is utilized as a measure to evaluate the clustering results obtained by the algorithm.

The TUMI algorithm outperforms the MI algorithm with all data sets for several reasons. Firstly, removing the smallest component with positive mutual information minimally reduces the model's fit to the data, whereas the MI algorithm removes the component with the maximum positive mutual information. Secondly, the TUMI algorithm is less likely to be biased due to the sparse distribution of feature vectors in the data space. Lastly, using the likelihood function allows the TUMI algorithm to estimate the number of mixture components accurately when the data set is generated from partially overlapped clusters, which is not provided by the MI algorithm.