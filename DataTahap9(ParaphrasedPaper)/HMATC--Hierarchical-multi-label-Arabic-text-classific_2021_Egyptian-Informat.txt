Multi-label classification (MLC) can be categorized into two types: flat and hierarchical. In flat classification, a predefined set of labels is classified without considering the hierarchical relationship between the labels. On the other hand, hierarchical multi-label classification (HMC) allows for the concurrent assignment of multiple labels to a single instance, with these labels structured in a hierarchy. HMC presents a more complex classification problem compared to flat classification, as it requires the classification algorithm to take into account the hierarchical relationships between labels and predict multiple labels for the same instance.

In flat classification, a problem transformation (PT) or algorithm adaptation technique can be used. The PT technique involves transforming the MLC problem into single-label problems, after which a traditional single-label classification algorithm is used for classification. Algorithm adaptation techniques, on the other hand, entail adapting single-label classification algorithms to directly address the MLC problem. Examples of PT techniques include binary relevance (BR), classifier chains (CC), and ranking by pairwise comparison (RPC), while examples of algorithm adaptation techniques include multi-label lazy learning (ML-KNN) and multi-label decision tree (ML-DT) algorithms.

In HMC, a hierarchical structure is considered for the multi-labels, and the output of the classification algorithm is a set of labels structured in a hierarchy. Hierarchical multi-label problems are typically classified as a tree-hierarchy or a directed acyclic graph (DAG). The classification algorithms proposed for HMC are more adept at handling large sets of labels compared to those proposed for flat classification.

Several studies have been conducted to investigate MLC and HMC problems in the context of Arabic text classification. Ahmed et al. studied binary and multi-class classification transformation methods using several multi-label classifiers, focusing on Arabic news articles. Shehab et al. investigated multi-label classifiers such as random forest, decision tree, and k-nearest neighbor for Arabic news articles. Al-Salemi et al. conducted an in-depth comparison of common MLC algorithms and algorithm adaptation techniques using the RTA News dataset, a multi-label Arabic dataset of news articles. Elnagar et al. introduced new Arabic datasets for single-label and multi-label text classification tasks and compared several deep learning models' effectiveness using these datasets.

To address the lack of publicly available multi-labeled Arabic datasets, this study used a raw hierarchical multilabel Arabic dataset taken from a previous study for experimentation.

This paper investigates applying the HOMER algorithm, an effective hierarchical multi-label classifier, to a domain with a large set of labels. The HOMER algorithm employs a divide-and-conquer approach to efficiently handle MLC problems with a large number of labels by constructing a tree-shaped hierarchy of simpler MLC problems.

The researchers intend to extend this work in the future by investigating the HOMER algorithm with other multi-label classifiers and applying different structured methods for selecting the number of clusters in the clustering algorithm. Furthermore, they plan to explore the use of principal component analysis (PCA) for feature selection and incorporate word embedding techniques for text representation and preprocessing.

Moreover, the authors' future work aims to give more attention to the preprocessing phase by employing word embedding techniques as text representation methods, applying different stemming algorithms, and preparing a list of Arabic human names for easy removal during the stop word removal phase.

Lastly, the paper concludes with brief biographical information about the authors: Nawal Aljedani, Reem Alotaibi, and Mounira Taileb, detailing their respective educational backgrounds and research interests.