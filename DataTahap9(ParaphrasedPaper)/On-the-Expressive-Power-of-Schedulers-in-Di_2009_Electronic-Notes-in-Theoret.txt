We introduce a new category of schedulers, termed strongly distributed schedulers, which constrain the non-determinism associated with the order of component execution. This paper compares this class with previously proposed approaches in this direction, highlighting the significance of our definition. Our analysis demonstrates that randomized and non-Markovian schedulers are necessary to achieve worst-case probabilities within this class.

This finding holds paramount importance in scenarios involving distributed systems where components have limited information exchange, as well as in security protocols where information concealment is a foundational assumption. The observed phenomenon, initially examined from a compositional viewpoint, has been studied in various settings, as documented in [8,9,6]. Furthermore, distributed schedulers are linked to partial-information policies.

In contrast to existing literature, our proposed strongly distributed schedulers address non-determinism associated with component execution order, offering a realistic approach to handle this non-determinism. We argue for the necessity of this restriction and specifically define strongly distributed schedulers as those that adhere to this constraint.

The general model checking problem, considering solely distributed schedulers, is proven to be undecidable. While one might consider overcoming this by limiting schedulers to finite memory, we establish that determining the exact amount of memory required to accurately approximate the worst-case value is impractical. Additionally, we demonstrate that nondeterministic schedulers are more powerful than deterministic schedulers within a fixed memory allocation. Moreover, we prove that calculating the worst-case value among all markovian distributed schedulers is NP-hard.

The probability of a set of executions depends on the resolution of non-determinism by a scheduler. A scheduler transforms non-deterministic choices into probabilistic choices by assigning probabilities to available transitions. Given a system and a scheduler, the probability of a set of executions is entirely determined.

In the typical Markov Decision Process (MDP) setting, schedulers assign probabilities to available transitions based on the complete system history. However, considering that schedulers may not have access to the full history of all system components, we propose a restricted class of schedulers to avoid unrealistic behaviors.

In our distributed setting, diverse non-deterministic choices must be resolved. Each atom requires an output scheduler to select the next generative transition, and potentially multiple reactive transitions may be enabled for a single label within the same atom, necessitating an input scheduler for each atom to choose a reactive transition for each previous history and label. Output and input schedulers base their decisions solely on the local history of the atom, leading to the notion of projection.

The possibility of information leakage arises from interleaving schedulers having access to the complete system history. We subsequently establish restrictions on interleaving schedulers to prevent this leakage and formally define strongly distributed schedulers as distributed schedulers whose interleaving scheduler adheres to this condition.

The problem of probabilistic model checking remains undecidable when schedulers are restricted to distributed ones, as evidenced by theorem 4.7. This result holds true even if we restrict the schedulers to finite memory. Furthermore, the calculation of the required memory for accurate probabilistic approximation remains unattainable for deterministic schedulers with at most n memory. Formally, let detlfinmemn(p) represent the set of deterministic locally n-markovian schedulers for p. Then, atoms c and v.

Overall, our work sheds light on the complexities and challenges associated with distributed schedulers, emphasizing the need for realistic and feasible approaches in addressing non-determinism and probabilistic choices within distributed systems.