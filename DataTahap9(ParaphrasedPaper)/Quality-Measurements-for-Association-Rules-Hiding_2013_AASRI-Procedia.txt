Data mining technologies have been widely utilized to assist individuals in making informed decisions and achieving financial gains since their emergence. However, some of the knowledge extracted through data mining may be sensitive, potentially leading to the disclosure of confidential information and resulting in significant privacy concerns. In response to this challenge, privacy preserving data mining has emerged as a novel area of research within the field of data mining, focusing on the analysis of privacy-related implications.

Privacy preserving data mining aims to safeguard sensitive information by altering the original database in a manner that obfuscates sensitive knowledge while minimizing the impact on non-sensitive data. One key area of emphasis is association rule hiding, which involves the creation of a sanitized database that retains non-sensitive association rules, denoted as r-sanitized, while concealing sensitive association rules, denoted as r-sensitive. This process is carried out in such a way that the resulting sanitized database, d-sanitized, aligns with predefined minimum support and confidence thresholds.

The strategies employed in this context are rooted in theorem 1, which posits that if an association rule such as a{i-left}{iright} is hidden, then all association rules such as a{i-left} b{i-right}(b) are also hidden. To accomplish this, the transactions containing{i-left, i-right} need to be examined, and adjustments are made to either increase the occurrences of item i-left to boost the support of the left-hand side or decrease the occurrences of item i-right to diminish the support of the right-hand side. This process of transforming the database is iterated until satisfactory quality measures are achieved.