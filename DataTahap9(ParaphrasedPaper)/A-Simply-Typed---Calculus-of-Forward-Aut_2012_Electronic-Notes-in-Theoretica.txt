Automatic Differentiation (AD) is a robust method for computing derivatives of functions defined by programming languages. Unlike divided differences, AD-generated derivative values are not subject to approximation errors, and compared to symbolic differentiation, AD is capable of handling highly complex code and offers robust computational complexity guarantees. While there are numerous AD systems available in the form of libraries and code pre-processors, the majority of these systems are built on imperative programming languages such as Fortran and C/C++. However, the concept of AD is most naturally suited for a functional programming language, where the differentiation operator serves as a quintessential example of a higher-order function. Despite extensive research and the proliferation of AD implementations, there remains a lack of clear semantics for AD in the context of first-class functions, which hinders its integration into functional programming. Siskind and Pearlmutter highlight the challenges of extending a functional programming language with AD operators, particularly in addressing the complexities associated with AD of higher-order functions.

Siskind, J. M., and B. A. Pearlmutter. "Using polyvariant union-free flow analysis to compile a higher-order functional programming language with a first-class derivative operator to efficient Fortran-like code." Technical Report TR-ECE-08-01, School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA (2008).