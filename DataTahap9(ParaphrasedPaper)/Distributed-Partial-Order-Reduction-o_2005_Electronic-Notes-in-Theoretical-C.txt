The issue of state space explosion presents a significant challenge in formally verifying concurrent systems. Recent years have seen the development of various techniques aimed at addressing this problem, two of which are of particular interest in this context: partial order reduction and distributed memory state exploration. While the former seeks to simplify the problem by reducing it to a smaller scale, the latter aims to expand computational capabilities to tackle the same issue. In this paper, we propose a combined approach using these two techniques and introduce a distributed memory algorithm for partial order reduction.

Concurrent systems involve the cooperation and communication of multiple systems simultaneously. These systems often demonstrate an extremely large number of possible behaviors due to the overwhelming number of potential interactions between components and the numerous race conditions that may arise. Model checking based on the exploration of state space is a common method used to ensure that all possible behaviors of the system align with a given property.

Distributed methods address the problem of state explosion by distributing the state space across multiple workstations in a network, with the aim of enhancing computational power, particularly in terms of random access memory, by creating a powerful parallel computer in the form of a network or cluster of workstations. These workstations communicate through a message passing interface and collectively explore the entire state space. There is substantial interest in developing distributed verification tools, and previous works have explored a combination of symbolic model checking and distribution.

In the distributed computation scenario, we assume a network of collaborating nodes (workstations or computers) with no shared global memory. Communication between the nodes occurs solely through message passing. The state transition system is divided into parts, with each node handling one part.

In the event that a state s is fully explored, each successor s' of state s is added to a set called waiting. If the owner of s' differs from the owner of s, a message is sent to the owner of s' to handle the successor. The depth-first search then backtracks from state s.

Following the conclusion of the depth-first search, all incoming messages are processed. A state is selected from the waiting set, and a new depth-first search is initiated from that state. This process is repeated until the waiting set is empty. Once the waiting set is empty and there are no pending messages, the node goes into an idle state. If all nodes are idle and there are no pending messages, the algorithm terminates.

In terms of proof, the computation without the heuristic examines each state and all of its outgoing edges exactly once. Additionally, the maintenance of incoming messages takes time O(e in). When the heuristic is employed, a state and its outgoing edges are re-examined each time its history changes. Since history monotonically increases, the maximum number of re-examinations is at most p.

We experimented with our algorithm in the context of the mutual exclusion problem, parametrized by the number n of processes (denoted as pa(n)), as well as models corresponding to the token ring algorithm (tra(n)), the alternating bit protocol (abp(n)), and the simple. The algorithm, implemented in the Spin model checker, is referred to as "spin." We also generated the reduced state transition system using our "fdfs" algorithm, an abbreviation for fragmented depth-first search.

Compared to existing approaches, our proposed algorithm can achieve greater reduction by considering not only singleton ample sets and by employing a less conservative cycle closing condition. Additionally, the algorithm for generating the reduced state space can be seamlessly combined with distributed LTL model checking algorithms, enabling the simultaneous generation and verification for correctness with respect to a given LTL property. However, we have only conducted experimental scalability and reduction effectiveness tests for our algorithm to date, and evaluating its effectiveness in full LTL model checking remains a topic for future work.