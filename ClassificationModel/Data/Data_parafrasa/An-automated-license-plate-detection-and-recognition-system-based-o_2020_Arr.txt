Year after year, the increasingly rapid growth of urban areas and the rising number of vehicles have led to a significant increase in traffic issues. These problems encompass traffic congestion, traffic violations, vehicle theft, and the escape of criminals, all of which pose major challenges to traffic management systems. Various systems have been created to address these issues, including self-driving technology, traffic surveillance systems, vehicle tracking systems, and vehicle speed detection systems. License plate detection and character recognition (LPDR) is particularly crucial in the realm of intelligent infrastructure systems, such as electronic payment systems for tolls, parking, and public transportation. LPDR involves using image processing technology to identify vehicles by their license plates, aiding traffic management departments in monitoring activities. Typically, an LPDR system consists of three main stages: image pre-processing, license plate localization, and optical character recognition.

While extensive research has been conducted on license plate detection and recognition, many proposed methods are limited in their effectiveness under specific conditions. Common limitations include issues related to illumination, complex scenes, and the presence of blur or distortions on license plates. Furthermore, the complexity of this task is compounded by the wide variety of character shapes, fonts, sizes, and colors found on license plates across different countries.

The objective of this study is to develop a cost-effective and highly efficient automatic vehicle license plate detection and recognition system. The proposed system is divided into two stages: license plate localization and character recognition. In the first stage, potential license plate regions are extracted from input images based on the density of vertical edges within the plates. A two-dimensional wavelet decomposition method is employed to extract the vertical edges from the input image, followed by the removal of false positives through the use of a plate/non-plate CNN classifier. In the second stage, the characters on the license plate are segmented and then classified using another CNN classifier.

The effectiveness of the license plate detection in the proposed method is crucial for accurately recognizing the characters. The approach relies on identifying potential license plate locations in the input image while verifying these regions as license plates. This involves utilizing vertical edges to detect potential license plate candidates, followed by the classification of these candidates using a plate/non-plate CNN classifier.

To extract areas with high vertical edge density, the method leverages the calculation of maximum entropy areas. Entropy, a measure of disorder, is used to identify areas with a high density of vertical edges. However, noisy holes and broken areas in the binary image required the use of morphological operations to correct these issues.

Following the localization, the recognized license plates are cropped and classified before undergoing the character recognition process. The segmentation of the characters is achieved by detecting the empty lines between the characters, and the segmented candidates are then classified using a CNN classifier.

In the proposed method, a pre-trained CNN model is utilized for classification, thus minimizing the need for a large training dataset. The first CNN model for license plate detection was retrained using 200 license plate images and 200 non-license plate images, while the second CNN model for license plate recognition was retrained using approximately 600 images of cropped characters and non-characters from various datasets.

The performance of the license plate detection was evaluated using three methods for comparison. The proposed method outperformed other approaches by reducing processing time, relying solely on binarization for feature extraction, and effectively utilizing the entropy function to detect potential regions. The combination of these algorithms resulted in a reduced error rate and improved accuracy.

The study was conducted by Ibtissam Slimani, Abdelmoghit Zaarane, Wahban Al Okaishi, Issam Atouf, and Abdellatif Hamdoun, who were responsible for various aspects of conceptualization, methodology, software development, data analysis, and manuscript preparation.