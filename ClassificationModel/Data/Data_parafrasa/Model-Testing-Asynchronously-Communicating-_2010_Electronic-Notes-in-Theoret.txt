Systematic testing is crucial for ensuring the reliability and quality of software and systems, and a variety of testing approaches and frameworks have been proposed and utilized. The application of formal methods and program language theory has enhanced the formal and systematic discipline of testing, as evidenced by the growing interest in model-based testing. In our previous work, we presented a formal approach for black-box specification-based testing of asynchronously communicating components in open environments within the context of Creol, an object-oriented modeling language for distributed systems.

Object-orientation is the preferred approach for open distributed systems, and asynchronous communication is advantageous for decoupling the caller and callee, but it also presents challenges in verifying and testing models due to communication delays leading to non-determinism and state space explosion.

We conducted experiments using the implementation discussed previously to demonstrate the effectiveness of our approach in reducing resource consumption when testing asynchronously communicating objects. The experiments showed that using AC rewriting can significantly reduce time and the number of rewrites, although the effects on the state space were less clear.

Additionally, we formalized a concurrent object-oriented language and a behavioral specification language for testing and validation of asynchronously communicating objects. Our approach enables the precise scheduling of input and testing of internal synchronization properties, and experimental case studies showed that using AC rewriting allows for the coverage of more extensive test cases.

The paper also describes compositional analysis through combining components with specifications, as well as the use of VeriSoft for bounded model checking and partial order reduction to improve analysis efficiency. However, the object interaction model, shared variables, and the use of assumptions and Hoare logic for specifications differ from our approach.

Furthermore, assumptions are employed to drive individual components for unit testing, and LTSs are utilized to model the behavior of components. An interesting feature of other work is the techniques for automatically generating the assumptions needed for a component to hold a specific property, which is not present in our approach.