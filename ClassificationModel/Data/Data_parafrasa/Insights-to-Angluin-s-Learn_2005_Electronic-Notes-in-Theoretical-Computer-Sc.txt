Angluin developed a notable algorithm for learning devices, and we have implemented it straightforwardly to gain more practical insights. We further analyzed its performance on randomly generated and real-world examples, focusing on the impact of alphabet size and the number of states on the required number of membership queries. Additionally, we implemented and analyzed an optimized version for learning prefix-closed regular languages. However, memory consumption posed a major obstacle when attempting to learn large examples.

Various approaches, including code generation and model-based test generation, assume the availability of a formal model of the system under study. To overcome these limitations and reduce manual effort in generating formal models, we propose developing techniques for more automated support.

This construction yields a minimal deterministic finite automaton (DFA) accepting language L, and every minimal DFA is shown to be isomorphic to the constructed one. We examined six transition systems of CCS processes, such as buffers, vending machines, schedulers, and mutual exclusion protocols, and learned minimized DFA representations of the given protocols.

However, we encountered difficulties in learning larger protocols, such as parameterized schedulers, the jobshop, and an ATM protocol, due to the lack of a good algorithm for finding counterexamples and insufficient memory for the ATM protocol.

Based on our experiences, we found that random prefix-closed automata are harder to learn compared to completely randomly generated automata. For our random examples, the number of membership queries can be described as roughly linear in the number of transitions, whereas membership queries for prefix-closed examples are approximately quadratic in transitions.

Delving deeper into the domain of prefix-closed automata, we discovered that it is possible to reduce the number of membership queries by using an optimization specifically designed for these automata. This optimization considerably reduces the number of membership queries, with a reduction of about 20% for randomly generated prefix-closed automata.

When applying the optimization to real-world examples, we observed a more significant reduction of about 60% in membership queries. Comparing the result of learning real-world examples with randomly generated prefix-closed examples of the same size, we found better performance for the real-world examples, especially with the optimization. This suggests that our real-world examples may have a more suitable structure for learning, offering potential for further optimization of the learning process.