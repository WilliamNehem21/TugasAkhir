{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8a5c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import fasttext\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20dca3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# mengambil model word embedding yang digunakan\n",
    "model = fasttext.load_model(\"/Users/williamnehemia/Documents/Skripsi/Fastext_model/SetelahPembagianData/model_cbow_fasttext_10.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50a5b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method untuk ubah text menjadi array of words\n",
    "def change_text_to_array_of_words(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe2ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method untuk ubah dokumen ke array\n",
    "def change_text_to_array_number(array_of_words):\n",
    "    # ubah kata menjadi angka\n",
    "    converted_words = []\n",
    "    for word in array_of_words:\n",
    "        wv = model.get_word_vector(word)\n",
    "        converted_words.append(wv)\n",
    "    \n",
    "    # ubah ke numpy array\n",
    "    converted_words = np.array(converted_words)\n",
    "    avg_array = np.mean(converted_words, axis=0)\n",
    "    return avg_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85fa933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method untuk ubah semua file yang ada di directory menjadi data yang siap untuk masuk model LR\n",
    "def convert_dir_to_input_data(directory):\n",
    "    files_name = os.listdir(directory)\n",
    "    list_files = []\n",
    "    result_array = []\n",
    "\n",
    "    # buang file DS_Store\n",
    "    for file in files_name:\n",
    "        if '.DS_Store' not in file:\n",
    "            list_files.append(file)\n",
    "\n",
    "    for file in list_files:\n",
    "        with open(directory + '/' + file, 'r') as fileNow:\n",
    "            content = fileNow.read()\n",
    "            array_words = change_text_to_array_of_words(content)\n",
    "            avg_array = change_text_to_array_number(array_words)\n",
    "            if avg_array.shape[0] != 30:\n",
    "                print(avg_array.shape)\n",
    "            result_array.append(avg_array)\n",
    "    result_array = np.array(result_array)\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb67a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat data dan labelnya untuk masuk ke model\n",
    "dir_asli = '/Users/williamnehemia/Documents/Skripsi/TugasAkhir/ClassificationModel/Data/Data_asli'\n",
    "x_asli = convert_dir_to_input_data(dir_asli)\n",
    "\n",
    "dir_paraphrased = '/Users/williamnehemia/Documents/Skripsi/TugasAkhir/ClassificationModel/Data/Data_parafrasa'\n",
    "x_paraphrased = convert_dir_to_input_data(dir_paraphrased)\n",
    "\n",
    "x = np.concatenate((x_asli, x_paraphrased), axis=0)\n",
    "\n",
    "zeros_array = np.zeros((1000, 1))  # Create a 3x3 array of zeros\n",
    "ones_array = np.ones((1000, 1)) \n",
    "\n",
    "y = np.concatenate((zeros_array, ones_array), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23e863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data train dan test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ce19a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamnehemia/anaconda3/envs/spyder_anaconda_skripsi/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/williamnehemia/anaconda3/envs/spyder_anaconda_skripsi/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# membuat model LR dan melatihnya\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=1, max_iter=100, fit_intercept=True, random_state=0, n_jobs=10)\n",
    "model = model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09cccf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8033333333333333\n"
     ]
    }
   ],
   "source": [
    "# prediksi model LR dan evaluasi\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "score = model.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79bce99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model menggunakan pickle\n",
    "filename = 'model_lr_testing.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8022e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755dd64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
