Artificial Intelligence in Agriculture 6 (2022) 176–188











Automatic marker-free registration of single tree point-cloud data based on rotating projection
Xiuxian Xu a, Pei Wang a,⁎, Xiaozheng Gan a, Jingqian Sun a, Yaxin Li a, Li Zhang a, Qing Zhang a, Mei Zhou b,
Yinghui Zhao c, Xinwei Li a
a School of Science, Beijing Forestry University, Beijing 100083, China
b Key Laboratory of Quantitative Remote Sensing Information Technology, Academy of Opto-Electronics, Beijing 100094, China
c Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China



a r t i c l e	i n f o


Article history:
Received 21 February 2022
Received in revised form 18 August 2022 Accepted 19 September 2022
Available online 21 September 2022


Keywords:
Coarse registration Feature-point matching Fine registration
Multi-station tree point cloud Point-cloud registration
a b s t r a c t

Point-cloud data acquired using a terrestrial laser scanner play an important role in digital forestry research. Mul- tiple scans are generally used to overcome occlusion effects and obtain complete tree structural information. However, the placement of artificial reflectors in a forest with complex terrain for marker-based registration is time-consuming and difficult. In this study, an automatic coarse-to-fine method for the registration of point- cloud data from multiple scans of a single tree was proposed. In coarse registration, point clouds produced by each scan are projected onto a spherical surface to generate a series of two-dimensional (2D) images, which are used to estimate the initial positions of multiple scans. Corresponding feature-point pairs are then extracted from these series of 2D images. In fine registration, point-cloud data slicing and fitting methods are used to ex- tract corresponding central stem and branch centers for use as tie points to calculate fine transformation param- eters. To evaluate the accuracy of registration results, we propose a model of error evaluation via calculating the distances between center points from corresponding branches in adjacent scans. For accurate evaluation, we con- ducted experiments on two simulated trees and six real-world trees. Average registration errors of the proposed method were 0.026 m around on simulated tree point clouds, and 0.049 m around on real-world tree point clouds.
© 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).





Introduction

Three-dimensional (3D) geometric information describing trees is very important in many research fields for processes such as biomass estimation, forest inventory, forest management, and urban environ- ment modeling (Dubayah and Drake, 2000; Hopkinson et al., 2004; Popescu, 2007; Popescu et al., 2003; Wulder et al., 2008). Some valid methods used to acquire tree structure information include traditional field measurement, photography, and laser scanning. Field measure- ment is effective, but fine manual measurement is very labor- intensive and time-consuming. Close-range photogrammetry (CRP) method is an emerging and potential solution to get 3D information. CRP can compute a series of overlapped tree images to generate 3D point cloud, which can be used to estimate tree diameters (Mokroš et al., 2018) and volumes (Marzulli et al., 2020). Due to the lower accu- racy, CRP is considered as an low-cost alternative to laser scanning. For trees with complex structures and dense foliage, the point cloud

* Corresponding author.
E-mail address: wangpei@bjfu.edu.cn (P. Wang).
generation efficiency and accuracy of CRP will decrease. However, as an active direct measurement method, laser scanning can acquire tree structures fast and accurately, although it is also limited by the hard- ware cost and low mobility.
In recent years, the performance of 3D laser scanner is increasing, while the cost and volume are decreasing. More laser scanners have been widely applied to acquire 3D tree information for different types of experiments. Terrestrial laser scanner (TLS)-based methods have been developed to construct 3D models of trees for data extraction (Dassot et al., 2011; Henning and Radtke, 2006; Pfeifer et al., 2004; Raumonen et al., 2013; Thies⁎ et al., 2004). Due to the geometric com- plexity of trees, TLS methods result in occlusion effects in each scan. This limitation leads to partial observation and incomplete structural in- formation, which greatly increases the difficulty of fully reconstructing trees within a single scan. Reconstruction based on multiple scans is an efficient complementary method to mitigate occlusion effects and facili- tate the full reconstruction of trees. Multiple-scan approaches produce point clouds from different scans that lie within different coordinate systems. Thus, multiple scans must be transformed to a common coordi- nate system via a registration procedure (Guiyun Zhou et al., 2014).


https://doi.org/10.1016/j.aiia.2022.09.005
2589-7217/© 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/).



Point-cloud registration methods can be categorized into two classes: marker-based and marker-free registrations. Marker-based reg- istration relies on artificial markers that are manually placed at the scene and manual or automatic recognition of these markers in different scans to establish correspondences (Bienert and Maas, 2009; Hilker et al., 2012). The markers are often reflective and can have various shapes (e.g., circular, cylindrical, or spherical). Based on corresponding point pairs extracted by identifying the same markers in adjacent scans, the relative transformation matrix between overlapping areas in multiple scans can be calculated by many commercial software pack- ages to complete the registration procedure.Marker-based registration is accurate and reliable but has many limitations. In complex environ- ments, artificial markers can be difficult to place, and marker-based reg- istration is often time-consuming in the field (Pfeifer et al., 2004).
By contrast, marker-free registration attempts to automatically
merge two or more scans directly without using artificial markers. Re- searchers using marker-free methods often focus on extracting natural geometric features (e.g., points, lines, and surfaces) from the scans (Böhm and Becker, 2007; Brenner et al., 2008). These features are uti- lized to extract tie points during registration. In forestry scenes, ground surface points, stem centers, and skeletons can be extracted to establish correspondence between multiple scans (Aschoff and Spiecker, 2004; Henning and Radtke, 2008a). The iterative closest point (ICP) algorithm and its variants are commonly used methods for marker-free registra- tion.(Besl and McKay, 1992; Rusinkiewicz and Levoy, 2001). The ICP al- gorithm starts with two scans and an initial guess for relative rigid-body transformation; an iterative approach is then applied to refine the trans- formation by alternately establishing correspondence. Due to sensitivity to the initial position and the large computational cost of multiple iter- ations, ICP methods are often used in fine registration processes. An- other important registration method is the four-point congruent set (4PCS), which extracts coplanar four-point sets from approximately congruent scans to complete global registration (Aiger et al., 2008). Without the requirement of assumptions about initial alignment, 4PCS can establish reliable corresponding sets within a limited number of tri- als and is robust against noise and low-overlap scans.
In forest scenes, the complex geometric distribution of branches and large number of leaf points pose a challenge to maker-free registration of tree point-cloud data (Bailey and Ochoa, 2018). Because we cannot guarantee the simultaneous acquisition of multiple scans, natural ele- ments (e.g., wind, sun, and animals) will introduce inconsistencies in overlapping parts among multiple scans. In most situations, leaf points will interfere with accurate registration; a few methods have been pro- posed to solve this problem. (Henning and Radtke, 2008a, 2008b) achieved forestry scenes registration based on tie points estimated from ground surfaces and stem centers in range images. The process of extracting tree stems in the method is not free of manual steps. (Bucksch and Khoshelham, 2013) applied localized registration using a skeletonization method to detect correspondences between branch segments in multiple scans. However, this approach relied on roughly registered tree point-cloud data prior to fine registration. (Guiyun Zhou et al., 2014) applied a skeleton extraction method to a rough auto- matic registration procedure—based on the extracted skeleton, the ini- tial translation vector and rotation angle were estimated using root point positions, distances between branch segments, and a mapping cost function between skeletons. By minimizing the mapping cost function, the transformation parameter was further refined in fine registration.
Recently, (Zhang et al., 2016) proposed a coarse-to-fine strategy to
address the difficulty of forestry scene registration. In coarse registra- tion, a backsighting orientation procedure is used to calculate transfor- mation parameters instead of placing artificial reflectors. Based on the initial values, stem-center locations are extracted as tie points to refine the rigid-body transformation for fine registration. The coarse-to-fine strategy improves the robustness and accuracy of forest scene registra- tion, but also has several limitations. First, coarse registration requires



Fig. 1. Simulated point clouds for trees (a) and (b). Green, red, and blue points indicate scans 1, 2, and 3, respectively.




manual placement of backsighting reflectors, which can be difficult to apply in complex environments. Second, due to the features of stem- fitting methods, fine registration cannot guarantee high registration ac- curacy in the vertical direction, especially for bent trunks whose cross sections cannot be treated as circles; the stem-fitting approach fails in such situations.
The registration of single-tree point-cloud data without reflectors remains a challenge. Unlike multiple tree registration in a forest scene, where the spatial relationship between trees can be useful information, geometrical structure is the only information that can be used in marker-free registration of single-tree point-cloud data.
The objective of this study was to develop a fully automatic marker-free registration algorithm with high registration accuracy. A coarse-to-fine registration strategy was adopted to align point clouds with bad initial positions without reference points in a


Table 1
The characteristics of RIEGL VZ-400 scanner.

Technical parameters


The farthest distance measurement	600 m
(natural object reflectivity≥90%) The scanning rate (points / second)	300,000 (emission),
125,000 (reception)
The scanning range	−40° ∼ 60°(vertical) 0° ∼ 360°(horizontal)
Laser divergence	0.3 mrad
Connection	LAN / WLAN, wireless data transmission






Fig. 2. Workflow of the coarse-to-fine registration procedure.


stepwise manner. In our coarse registration, each 3D point cloud was projected onto a sphere to generate a series of 2D projection images for the extraction of feature-point pairs, whose spatial information can be used to estimate the transformation matrix for the coarse reg- istration of multiple scans. Sliced point-cloud data were then used to estimate the centers of trunks and branches using fitting methods. The estimated centers were used as tie points to perform fine registration.

Experimental data

Eight groups of tree point clouds were used to test the proposed method in the experiments. Among them, there are two simulated
trees and six real trees. Each tree is composed of three point clouds scanned from three different viewpoints.
Two simulated trees have simpler and defined geometric structures, which are simulated using the scanning geometric and less noise with- out leaf interference (Fig. 1). Simulated tree point clouds are useful for analyzing the advantages and limitations of our method.
Given that tree structures in nature scenes are more complex than that of simulated trees, the verification of our method on real-world tree point clouds is important. In the study, six trees in the campus of Beijing Forestry University were scanned to obtain the groups of real- world tree point clouds. Data collection was conducted using a RIEGL
VZ − 400 TLS scanner (RIEGL Laser Measurement Systems GmbH,
3580 Horn, Austria), whose characteristics are shown in Table 1. Each




Fig. 3. The point-cloud projection model. P′ is the projection of point P on the spherical surface. E is the foot of the perpendicular line from P′ to the X-Y plane. α is the angle between OE and the x-axis. β is the angle between OP' and the X-Y plane.






Fig. 4. Sample image generated via projection.



group of tree point clouds contains three scans scanned from different positions with the vertical and horizontal scanning angular resolution of 0.02°. To facilitate the processing and analysis, the small branches and noisy leaf points were filtered out manually.

Methodology

In our proposed method, the registration procedure comprises two parts: coarse and fine registration. The objective of the coarse-to-fine strategy is to transform coordinates from target points to reference points in a stepwise manner. In coarse registration, a rough transforma- tion matrix is calculated to transform the target points into a position that is close to the reference points. Based on the close relative positions of the two point sets, more information can be used to achieve an accu- rate transformation towards the reference points in fine registration. In
both steps, rigid-body transformation is determined by translation and rotation parameters. The registration procedure is described by follow- ing equations:
ptcoarse = Rcoarse ⋅ pttar + Tcoarse

ptref = Rfine ⋅ ptcoarse + Tfine	(1)

Where pttar and ptref are points in the target and reference scans, respectively; R is the rotation matrix; and T is the translation vector.
In coarse registration, our method simplifies the 3d point matching problem into a 2d point matching problem by projecting from the 3D point cloud to 2D images. The matched points are estimated using feature-point-matching algorithms on images generated by projection. These matched points are then used to estimate the rough transformation. In fine registration, point-cloud slicing and fitting methods are used to extract corresponding trunk and branch centers, which function as tie points to calculate the fine transformation parameters. The workflow is
illustrated in Fig. 2.
We also proposed a simple model in this section to evaluate the re- sults of registration, which can help to compare the coarse registration, fine registration and ICP registration using the above-mentioned simu- lated tree point clouds and real-world tree point clouds.

Coarse registration

Point-cloud projection
We established a point-cloud projection model to convert 3D point clouds to 2D images. The tree point-cloud is projected onto a sphere centered at the origin of the coordinate system, where the scanner is lo- cated. The projection was then used to generate an image on the spher- ical surface. The model is shown in Fig. 3.
Each point projected onto the sphere corresponds to a pair of angles, α and β (Fig. 3), which are used to determine the pixel coordinates of each point and generate corresponding images.
In the model, each set of pixel coordinates corresponds to a pair of intervals [αl, αh] and [βl, βh] for angles α and β respectively. The pixel coordinates of a point is determined by which pair of intervals its corresponding angles α and β lie in. Each point is allocated a pixel coordinate in this manner. The minimum steps of angle α and β are equal to the horizontal and vertical angular step widths of the TLS in- strument, denoted φ and ϕ, respectively. In this study, each pixel in the image covered a region of 2φ and 2ϕ in the horizontal and vertical directions, respectively, which reduced the impact of discontinuous scanning points. The projected image has a size of m × n, where the values of m and n are calculated using the following equations:




Fig. 5. Generation of image sequences.




Fig. 6. Sliced points from a tree point-cloud. Q3, Q2, and Q1 are quartiles of tree height.


m = |(α max — α min )/2φ + 2r1|
n = |(β max — β min )/2ϕ + 2r2|	(2)
where αmin, αmax, βmin, and βmax are the minimum and maximum values of α and β of all points, respectively; and r1 and r2 are pixels forming a border around the image, which ensures that the size of the image satisfies our demands.
For any point P with corresponding angles αp and βp, the pixel
As shown in Fig. 4, Aij (i = 1, 2, …, m – 2r; j = 1, 2, …, n – 2r2) is a pixel that corresponds to a pair of angle intervals. For example:

A11 : ([αmin, αmin + Δα), [βmin, βmin + Δβ)), A12
: ([αmin + Δα, αmin + 2Δα), [βmin, βmin + Δβ)), .. . , A1m — 2r1
: ([αmax — Δα, αmax), [βmin, βmin + Δβ))

A21 : ([αmin, αmin + Δα),[βmin + Δβ, βmin + 2Δβ)), A31
: ([αmin, αmin + Δα),[βmin + 2Δβ, βmin + 3Δβ)), …, An−2r 1

coordinates (x, y) can be calculated as follows:
: ([α

min, α

min
+ Δα),[β

max
− Δβ, β
2
max))

x = (αp — α min )/2φ + r1
y = (βp — β min )/2ϕ + r2	(3)
As a result, each scanning point corresponds to a certain set of pixel coordinates, and each pixel may have several corresponding points. The image generated via projection is a binary image. Pixels with and without corresponding scanning points are set to values of 0 and 255, respectively.

Generation of image sequences
According to the projection method, projected images of the same object may differ due to differences among viewpoints. In our model, the projection viewpoint is determined by the position of the scanner. Due to occlusion, some valuable tree structural information will be lost in the process of projection. Thus, two scans with different view- points may be similar in 3D space, but their projected images may differ greatly, which can be an obstacle in identifying corresponding points between scans.




Fig. 7. Separation results. (a) Overview. (b) Close-up view of the connected part (within green rectangular box). (c) Close-up view of nine adjacent points in the connected part. Blue, yellow, and green points correspond to the angle pairs (α, β), (α + Δα, β), and (α + Δα, β + Δβ), respectively.



To solve this problem, we continuously rotated the tree point-cloud in 3D space prior to projection, which is equivalent to continually changing the viewpoint. In the rotation step, the mean values x, y of the X and Y coordinates of all points in the scan were first calculated. We then continuously rotated the points by a certain degree around the axis, which is perpendicular to the xy plane and passes through the point (x, y, 0). As a result, a sequence of images was generated for each scan (Fig. 5).
The number of rotations required is determined by the number of scans n and the rotation degree θ. In our experiments, the rotation de- gree θ was typically 10° and the rotation number was  720 (rotation ob-
tained from —360 to 360).
The feature point matching algorithm should be applied on the pair of images with similar shapes that can reflect the overlapping areas be- tween adjacent scans. To find the similar image pairs, we calculated the similarity of every two images between the two image sequences and selected the pairs of high similarity. The method of similarity calculation is based on the idea of the image hashing algorithm which constructs fingerprints that uniquely identifies the content of the images. (Venkatesan et al., 2000). A simple code was utilized to construct the fingerprints of binary images, in which pixel value 255 corresponds to 1 in the code, and pixel value 0 corresponds to 0. The hamming distance between the codes of the images were calculated to estimate their similarity.

n	n	The key points in three pairs of similar images from adjacent

Feature-point matching
Due to the lack of detailed texture information available in binary images, we used the ORB (oriented FAST and rotated BRIEF) algorithm to detect and match feature points (Rublee et al., 2011). This method is faster and more suitable for less complicated images than methods such as the SURF (speeded up robust feature) or SIFT (scale invariant feature transform) algorithms (Bay et al., 2006; Lowe, 2004). The com- bination of the oriented FAST key point detector and rotated BRIEF de- scriptor makes the ORB algorithm scale- and rotation-invariant.
scans were extracted and described using ORB. In each image pair, we selected the k(k ≥4) pairs of matching points with the highest scores.

Transformation calculations
Once the matching points in images were determined, we were able to map the points to their corresponding 3D points in the tree point- cloud. First, we determined the intervals, [αl, αh] and [βl, βh], of each matching point based on its pixel coordinates. All scanning points





Fig. 8. Complete simulated tree point-clouds for the experiment. (a) Simulated tree A. (b) Simulated tree B. Red, sliced branch parts. (c) Cross-sections of branches at a given height in a well-registered tree point-cloud. (d) Cross-sections of branches at a given height in a poorly registered tree point-cloud.






Fig. 9. Slicing results for one branch. (a) Three sliced layers of branch B in simulated tree B. Red and blue points indicate scans 1 and 2, respectively. (b) Corresponding center-point extraction results for the three sliced layers of branch B. D1, D2, D3 indicate distances be- tween the pairs of corresponding points.
with a corresponding pair of angles (α, β) within these intervals were then extracted. The central point O among the extracted points was calculated and used as the tie point in 3D space. After obtaining more than four pairs of tie points in adjacent scans, a rough rigid-body trans- formation matrix between scans was calculated using singular-value decomposition (SVD) (Challis, 1995).


Fine registration

Coarse registration roughly aligns the postures of adjacent scans and provides a better initial position for subsequent fine registration. How- ever, obvious dislocation and separation remain between adjacent scans after coarse registration. Therefore, it is necessary to improve the transformation matrix in fine registration. The fine registration process includes three parts: point-cloud slicing, point separation, and circle and cylinder fitting.

Point-cloud slicing
Qualified tie points are the basis for the calculation of accurate transformation parameters in fine registration. For a single scan of a single tree, the point cloud is incomplete, and it is difficult to find tie points directly based on tree structure. In our method, we sliced points from the stem and branch parts of the tree and extracted the center points of stems and branches for use as tie points by applying circle- and cylinder-fitting methods to the sliced points. We sliced the points at quartiles of tree height and obtained three layers of points. Each layer was sliced to a thickness of 10 cm (Fig. 6).
Different slicing heights result in differences in the number, distribu- tion, and relative position of the sliced points in the layer. Points in lower layers are generally all extracted from the stem. However, most points in high layers are extracted from branches. The stem is usually




Fig. 10. Feature-point matching results. (a) Results of scan 2 to scan 1 for simulated tree A. (b) results of scan 3 to scan 1 for simulated tree A. (c) Results of scan 2 to scan 1 for simulated tree
B. (d) Results of scan 3 to scan 1 for simulated tree B.



perpendicular to the ground and its horizontal cross section is roughly treated as a circle. Thus, the center of the stem can be estimated via cir- cle fitting. Branches are often at an oblique angle to the stem and their horizontal sections are similar to ellipsoids. Given that the geometric structure of branches in 3D space is similar to that of cylinders, we used a cylinder-fitting method to estimate the center points of the branches.

Point separation
Every sliced-point layer contains several arcs of points corre- sponding to branches and the stem. Before applying fitting methods, we should first separate these arcs of points. Because the angular step of the TLS is fixed, whether two points are consecutive can be judged from the distance between their corresponding angles α and β (Fig. 3). Based on the horizontal and vertical angular step widths—φ and ϕ—of the TLS instrument, we separated the points by judging their connectivity (Bu and Wang, 2016). The points in an arc are consecutive, and the distance between the angles—Δα and Δβ— corresponding to each pair of adjacent points should equal φ and ϕ, respectively, under ideal conditions (Fig. 7c). Because discontinuity can be caused by scanning errors or unusual tree structures, we determined the consecutive nature of two points by comparing Δα and Δβ to 3φ and 3ϕ, respectively. By examining distances between



Fig. 11. Coarse registration results. (a) Registration result between scan 2 and scan 1 for simulated tree A. (b) Registration results between scan 3 and scan 1 added to results from (a). (c) Registration results between scan 2 and scan 1 for simulated tree B.
(d) Registration results between scan 3 and scan 1 added to results from (c). Green, red, and blue points indicate scans 1, 2, and 3, respectively.
points, the method identified all connected areas and separated all sliced-point arcs (Fig. 7).

Circle and cylinder fitting
Among the three sliced layers, the lowest layer usually contains only one arc, corresponding to the stem. For the stem section, the circle- center position (X0, Y0) was extracted as the center of the stem by applying the Taubin method (Taubin, 1991).
For sections of branches in higher layers, we determined center points by cylindrical fitting based on the least squares method (Shakarji, 1998). In the fitted cylinder, we obtained the direction vector of the central axis (a, b, c), a starting point on the axis (x0, y0, z0), and radius R.
The axis of the branches could describe the tree to some extent (Eysn et al., 2013). Thus, the starting point and a point one distance unit away from it in the positive direction of the axis were used as tie points. The positive direction of the axis was defined as the direction in which the Z coordinate of the point increases. For stem points, the center of the fitted circle was regarded as a tie point.


Fig. 12. Fine registration results. (a) Registration results between scan 2 and scan 1 for sim- ulated tree A. (b) Registration results between scan 3 and scan 1 added to results from (a).
(c) Registration results between scan 2 and scan 1 for simulated tree B. (d) Registration re- sults between scan 3 and scan 1 added to results from (c). Green, red, and blue points in- dicate scans 1, 2, and 3, respectively.



As a result, we obtained a group of corresponding tie points with po- sitions at different positions in the tree based on the search of nearest
neighbour. Based on these tie points, transformation parameters were
facilitate the estimation of registration error between adjacent scans, as follows:

calculated for fine adjustment in fine registration.
d = d1 + d2 + d3⋯ + dn
n
(8)

Accuracy evaluation method

To evaluate our registration results, we developed an simple evalua- tion model to quantitatively estimate registration accuracy. Point clouds of simulated Trees A and B contained many branch parts (Fig. 8). Accu- rate registration would align corresponding branches between adjacent scans; the cross-section of a branch in a well-registered tree should be an ellipse or a circle. However, poor registration often results in branches that appear to be aligned correctly, but have cross-sections composed of several separate arcs. Thus, the alignment accuracy of cor- responding branches between adjacent scans can be used to evaluate registration accuracy.
In our evaluation model, we extracted corresponding branches be- tween adjacent scans to calculate registration error. For each pair of cor- responding branches, we sliced three pairs of layers from the bottom, middle, and top of the corresponding branches. Points in these layers were used for cylinder fitting to estimate their center axes. By extracting points with the same z-values on the corresponding axes of each layer pair, we obtained three pairs of corresponding center points (Fig. 9). Calculating the distances between these pairs of center points can

Where d1, d2, …, dn are the distances of corresponding center points, n is the number of pairs of corresponding points, and average distance d is treated as registration error.

Experimental results

Since two kinds of tree point clouds were used in the experiment, the results were demonstrated separately. And the results of coarse reg- istration, fine registration and ICP registration were evaluated using the proposed evaluation model in 3.3 subsection.

Results of simulated tree point clouds

Coarse registration
As shown in Fig. 1, each simulated tree was composed of three scans. In the registration procedure, the local coordinate system of the first scan of each simulated tree was used as a reference coordinate system, and the registration order was scan 2 to scan 1, and scan 3 to scan 1.
Similar image pairs between image sequences from adjacent scans were matched; the results of feature-point matching for two simulated





Fig. 13. Registration accuracy for simulated tree A. (a) Registration accuracy for scan 2 to scan 1. (b) Registration accuracy for scan 3 to scan 1.




Fig. 14. Registration accuracy for simulated tree B. (a) Registration accuracy for scan 2 to scan 1. (b) Registration accuracy of scan 3 to scan 1.


trees are shown in Fig. 10. In each group of adjacent scans, three similar image pairs were selected for application of the ORB algorithm; 15 matching points were obtained.
The coarse registration results are shown in Fig. 11. Corresponding stems and branches between adjacent scans of both simulated trees were either crisscrossed or separate after coarse registration; i.e., not ac- curately aligned. Although registration errors cannot be ignored, coarse registration correctly matched corresponding stems and branches be- tween adjacent scans and transformed the target scan to a good initial position for fine registration. Coarse registration is also completely automatic and marker-free, which expands the potential fields for its application.

Fine registration
Based on target-scan initial positions, the center points of corre- sponding stems and branches between adjacent scans were extracted as tie points to achieve better alignment in fine registration. Fine regis- tration results for the two simulated trees are shown in Fig. 12. The re- sults indicate that contours of the stem and branches were complete and that a complete simulated tree could be composed from three scans. Alignment between adjacent scans was more accurate after fine registration.
Because multiple layers at different heights are sliced to facilitate the extraction of corresponding tie points, fine registration not only en- hances the accuracy of coarse registration, but also achieves better alignment of branch and stem parts between adjacent scans than fine registration via stem-center fitting methods.
Evaluating registration results
To evaluate the registration accuracy of the two simulated trees, all corresponding branches between adjacent scans were extracted to calculate the corresponding center points and their distances. Branch section numbers for simulated trees A and B are shown in Fig. 8a and b. In our practice, absolutely unreasonable registration results got when we registering the tree point clouds directly with the ICP algorithm. Due to the high computational demand for the initial positions of adjacent scans, the ICP algorithm was only used in fine registration stage for comparison to ensure that the compari- son was meaningful. The accuracy results of the coarse registration, fine registration and ICP registration for each simulated tree are shown in Figs. 13 and 14.
These results demonstrate that fine registration errors were much smaller than those of coarse registration and that smaller fluctuations occurred among registration errors for branches. The ICP algorithm largely depends on the initial position of the point clouds, especially for adjacent scans with low-overlap areas. In most situations in our ex- periments, the ICP method exhibited no clear improvement compared with coarse registration, and registration errors even increased after ICP fine registration. However, when coarse registration accuracy was relatively high, ICP fine registration enhanced registration accuracy, as shown by the registration results of scan 2 to scan 1 for simulated tree B (Fig. 14a).
To evaluate the error quantitatively, Table 2 shows the calculated mean registration errors of coarse registration, fine registration and ICP registration. The average coarse registration error is about 0.204



m, and the average fine registration error is about 0.026 m. Meanwhile, the the average registration error of ICP is about 0.187 m, which is more seven times of the proposed method.

Results of real-tree point clouds

Six group of real-world tree point clouds were processed using the proposed method. The results of coarse registration and fine registration are shown in Fig. 15. In each sub-figure, the coarse registration result is on the left, and the fine registration result is on the right. Three point clouds scanned from different viewpoints are demonstrated in red, green and blue colors respectively. Apparently, the results of fine registra- tion are better than coarse registration, especially at the part of branches. To evaluate the registration accuracy, corresponding branches be- tween adjacent scans were extracted out to calculate the registration error in each group based on previous evaluation model. The mean ac- curacy errors of the coarse and fine registrations for each group were
shown in Table 3.
As shown in Table 3, the average coarse registration error is about 0.325 m, and the average fine registration error is about
0.049 m. Both coarse and fine registration errors of real-world tree point clouds are larger than that of simulated trees. But the errors are still acceptable for a marker-free registration method of tree point clouds.

Discussion

Verification of feature-point matching

In the proposed algorithm, coarse registration provided the initial position of the point cloud, which played an important role in the suc- cess of fine registration. In coarse registration, the matching accuracy of similar images determines tie-point quality and directly affects coarse-registration accuracy. However, due to the lack of texture infor- mation in binary images, wrong matching points cannot be avoided in feature-point matching (Fig. 11).
With fewer pairs of matching points, the impact of wrong matching points on the estimation of the transformation matrix between adjacent scans is greater. To enhance matching accuracy, verification of point pairs is performed to eliminate bad matches. Each pair of points (P1, P2) corresponds to a pair of intervals of angles α and β, which corresponds to the 3D space σ1, σ2. In a correct matching-point pair, the relative position of σ1 in the tree point-cloud PC1 is roughly equivalent to the relative position of σ2 in the tree point-cloud PC2. Given that the tree is composed of different parts in the vertical direction and can be roughly divided into the crown, limb, and stem from top to bottom, the correct matching-point pair should be in the same part of the tree. For example, a point in the crown should be matched to a point in the crown. Thus, the correctness of matching- point pairs can be verified by comparing their corresponding intervals of angle β, which indicate their position in the vertical direction.
Suppose that each pair of matching points corresponds to the inter- vals [β1k, β1k + 2ϕ] and [β2k, β2k + 2ϕ] (k = 1, 2, …, 15), where 15 is the number of pairs of matching points to be checked. We can then calculate


Table 2
The errors of registration of simulated tree A and simulated tree B.

Note:2–1 means the registration order “Scan 2 to Scan 1”, 3–1 means the registration order “Scan 3 to Scan 1”.


the distance dk =| β1k – β2k | and obtain the mean value dk and standard deviation σd of dk. A point pair whose dk value is not within

	
 dk — σd, dk + σd will be excluded as a bad pair from potential matching points.


Fig. 15. Registration results of six trees. The registration order is scan 2 to scan 1, scan 3 to scan 1. In each sub-figure, the left one is the coarse registration result, and the right one is the fine registration result. Green, red, and blue points indicate scans 1, 2, and 3, respec- tively. (a) Tree1. (b) Tree2. (c) Tree3. (d) Tree4. (e) Tree5. (f) Tree6.














Fig. 15 (continued).



Improvement of point separation

The separation of fine-registration sliced points can be influenced by tree structure. In this study, points were sliced at quartiles of tree height. Fig. 16. shows an example in which parts of the stem and branches are close at these specific heights. Due to the small distances between branches at height Q2, the sliced points of different branches intersected. Our method these considered intersected sliced points as a single connected part. Therefore, the corresponding sliced points could not be correctly separated (Fig. 16b).
One method to improve our approach is to verify the correctness of separated parts. Points in rectangle S2 in Fig. 16b contained three arcs, which roughly compose an arc with the largest radius among all arcs. In most single trees, the thickness of stems and branches tends to de- crease as height increases, such that lower parts of the stem or branches are often thick and higher parts are thinner. Therefore, the radius of a lower part of a stem or branch should be larger than that of a higher part. According to this rule, we can verify the correctness of a separated part by checking its corresponding radius after fitting. For example, by applying a fitting method, we obtained radius r1 of the separated part shown in Fig. 16c and radius r2 of separated part S2 in Fig. 16b. As r2 was larger than r1 r1, S2 was considered an incorrect result and was excluded from further registration procedures.

Limitations of the proposed method

Three limitations need to be considered and studied further for the proposed method. First, the rotation of large amount of points is

Table 3
The registration errors of the tree point clouds.

Fig. 16. Point-cloud slicing and separation results. (a) Point-slicing results. Q1, Q2, and Q3 are quartiles of tree height. (b) Separation of points sliced at Q2. (c) Separation of points sliced at Q1.



time-consuming. In our proposed method, tree point clouds were rotated continuously in 3D space prior to projection to improve the possibility of detecting similar image pairs from the corresponding images in adjacent scans. The number and degree of rotations should be further optimized to reduce redundancy. Second, feature-point- matching results were not stable, especially for trees with complex geometric structures. When there are many asymmetric structures in a tree, the extraction of sufficient correct matching-point pairs will be challenging. Third, the fine registration will be affected by branch characteristics. Slim tree branches, high branch density and more horizontal branch direction may increase the difficulty of accu- rate circle fitting and cylinder fitting, which will result in the decrease of registration accuracy.

Conclusion

Tree point cloud registration is fundamental and important to for- estry research and tree structure analysis. The study proposed an auto- matic registration method that uses a coarse-to-fine strategy to register multiple scans of a single tree without the aid of artificial reflectors. The proposed method is verified as a feasible and effective automatic regis- tration method using two simulated and six real tree point clouds. The automated and marker-free registration method provides a new way to assist the tree structure analysis.
In the future work, we will concentrate on improving the matching accuracy of tie points, and accelerating the pipeline by further optimiz- ing the matrix computations of rotation process. Meanwhile, we will also make efforts to increase the robustness of the method, and try to apply the method to handle more complicated geometric tree struc- tures in natural scenes.

CRediT authorship contribution statement

Xiuxian Xu: Conceptualization, Methodology, Validation, Software, Visualization, Writing – original draft, Writing – review & editing. Pei Wang: Conceptualization, Methodology, Validation, Software, Visuali- zation, Writing – original draft, Writing – review & editing. Xiaozheng Gan: Data curation, Investigation. Jingqian Sun: Writing – review & editing. Yaxin Li: Data curation, Investigation. Li Zhang: Resources. Qing Zhang: Resources. Mei Zhou: Resources. Yinghui Zhao: Re- sources. Xinwei Li: Data curation, Investigation.



Declaration of Competing Interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influ- ence the work reported in this paper.

Acknowledgments

This research is funded by the Fundamental Research Funds for the Central Universities (No.2021ZY92), National Students' innovation and entrepreneurship training program (No. 201710022076) and the State Scholarship Fund from China Scholarship Council (CSC No. 201806515050).

References
Aiger, D., Mitra, N.J., Cohen-Or, D., 2008. 4-points Congruent Sets for Robust Pairwise Sur- face Registration. ACM SIGGRAPH 2008 papers on - SIGGRAPH ’08 27, 1. https://doi. org/10.1145/1399504.1360684.
Aschoff, T., Spiecker, H., 2004. Algorithms for the automatic detection of trees in laser scanner data. Int. Arch. Photogramm. Remote. Sens. Spat. Inf. Sci. 36, W2.
Bailey, B.N., Ochoa, M.H., 2018. Semi-direct tree reconstruction using terrestrial LiDAR point cloud data. Remote Sens. Environ. 208, 133–144. https://doi.org/10.1016/j.rse. 2018.02.013.
Bay, H., Tuytelaars, T., Van Gool, L., 2006. Surf: speeded up robust features. Eur. Conf.
Comp. Vision. 404–417.
Besl, P.J., McKay, N.D., 1992. Method for registration of 3-D shapes. Sensor Fusion IV: Con- trol Paradigms and Data Structures, pp. 586–606.
Bienert, A., Maas, H.-G., 2009. Methods for the automatic geometric registration of terres- trial laser scanner point clouds in forest stands. ISPRS Int. Arch. Photogramm. Rem. Sens. Spat. Inf. Sci 93–98.
Böhm, J., Becker, S., 2007. Automatic marker-free registration of terrestrial laser scans using reflectance, in. Proceedings of the 8th Conference on Optical 3D Measurement Techniques, Zurich, Switzerland, pp. 9–12.
Brenner, C., Dold, C., Ripperda, N., 2008. Coarse orientation of terrestrial laser scans in urban environments. ISPRS J. Photogramm. Remote Sens. 63, 4–18. https://doi.org/ 10.1016/j.isprsjprs.2007.05.002.
Bu, G., Wang, P., 2016. Adaptive circle-ellipse fitting method for estimating tree diameter based on single terrestrial laser scanning. J. Appl. Remote. Sens. 10, 26040.
Bucksch, A., Khoshelham, K., 2013. Localized registration of point clouds of botanic trees. IEEE Geosci. Remote Sens. Lett. 10, 631–635. https://doi.org/10.1109/LGRS.2012. 2216251.
Challis, J.H., 1995. A procedure for determining rigid body transformation parameters.
J. Biomech. 28, 733–737.
Dassot, M., Constant, T., Fournier, M., 2011. The use of terrestrial LiDAR technology in for- est science: application fields, benefits and challenges. Ann. For. Sci. 68, 959–974.
Dubayah, R.O., Drake, J.B., 2000. Lidar remote sensing for forestry. J. For. 98, 44–46.
Eysn, L., Pfeifer, N., Ressl, C., Hollaus, M., Grafl, A., Morsdorf, F., 2013. A practical approach for extracting tree models in forest environments based on equirectangular projec- tions of terrestrial laser scans. Remote Sens. 5, 5424–5448. https://doi.org/10.3390/ rs5115424.
Henning, J.G., Radtke, P.J., 2006. Detailed stem measurements of standing trees from ground-based scanning lidar. For. Sci. 52, 67–80.
Henning, Jason G., Radtke, P.J., 2008a. Multiview range-image registration for forested scenes using explicitly-matched tie points estimated from natural surfaces. ISPRS
J. Photogramm. Remote Sens. 63, 68–83. https://doi.org/10.1016/j.isprsjprs.2007.07. 006.
Henning, Jason G., Radtke, P.J., 2008b. Multiview range-image registration for forested scenes using explicitly-matched tie points estimated from natural surfaces. ISPRS
J. Photogramm. Remote Sens. 63, 68–83.
Hilker, T., Coops, N.C., Culvenor, D.S., Newnham, G., Wulder, M.A., Bater, C.W., Siggins, A., 2012. A simple technique for co-registration of terrestrial LiDAR observations for for- estry applications. Remote Sens. Lett. 3, 239–247. https://doi.org/10.1080/01431161. 2011.565815.
Hopkinson, C., Chasmer, L., Young-Pow, C., Treitz, P., 2004. Assessing forest metrics with a ground-based scanning lidar. Can. J. For. Res. 34, 573–583.
Lowe, D.G., 2004. Distinctive image features from scale-invariant keypoints. Int. J. Comput.
Vis. 60, 91–110.
Marzulli, M.I., Raumonen, P., Greco, R., Persia, M., Tartarino, P., 2020. Estimating tree stem diameters and volume from smartphone photogrammetric point clouds. Forestry (Lond). https://doi.org/10.1093/forestry/cpz067.
Mokroš, M., Liang, X., Surový, P., Valent, P., Čerňava, J., Chudý, F., Tunák, D., Saloň, Š., Merganič, J., 2018. Evaluation of close-range photogrammetry image collection methods for estimating tree diameters. ISPRS Int. J. Geo Inf. 7. https://doi.org/10. 3390/ijgi7030093.
Pfeifer, N., Gorte, B., Winterhalder, D., Sensing, R., Range, C., 2004. Automatic Reconstruc- tion of Single Trees from TLS Date 1–6.
Popescu, S.C., 2007. Estimating biomass of individual pine trees using airborne lidar. Bio- mass Bioenergy 31, 646–655.
Popescu, S.C., Wynne, R.H., Nelson, R.F., 2003. Measuring individual tree crown diameter with lidar and assessing its influence on estimating forest volume and biomass. Can.
J. Remote. Sens. 29, 564–577.
Raumonen, P., Kaasalainen, M., Markku, Å., Kaasalainen, S., Kaartinen, H., Vastaranta, M., Holopainen, M., Disney, M., Lewis, P., 2013. Fast automatic precision tree models from terrestrial laser scanner data. Remote Sens. 5, 491–520. https://doi.org/10. 3390/rs5020491.
Rublee, E., Rabaud, V., Konolige, K., Bradski, G.R., 2011. ORB: An efficient alternative to SIFT or SURF. ICCV, p. 2.
Rusinkiewicz, S., Levoy, M., 2001. Efficient variants of the ICP algorithm. 3dim,
pp. 145–152.
Shakarji, C.M., 1998. Least-squares fitting algorithms of the NIST algorithm testing system.
J. Res. Nat. Inst. Stand. Technol. 103, 633.
Taubin, G., 1991. Estimation of planar curves, surfaces, and nonplanar space curves de- fined by implicit equations with applications to edge and range image segmentation. IEEE Trans. Pattern Anal. Machine Intell. 1115–1138.
Thies*, M., Pfeifer, N., Winterhalder, D., Gorte, B.G.H., 2004. Three-dimensional recon- struction of stems for assessment of taper, sweep and lean based on laser scanning of standing trees. Scand. J. For. Res. 19, 571–581.
Venkatesan, R., Koon, S.-., Jakubowski, M.H., Moulin, P., 2000. Robust image hashing. Pro- ceedings 2000 International Conference on Image Processing (Cat. No.00CH37101), Vancouver, BC, Canada. vol. 3, pp. 664–666. https://doi.org/10.1109/ICIP.2000. 899541.
Wulder, M.A., Bater, C.W., Coops, N.C., Hilker, T., White, J.C., 2008. The role of LiDAR in sus- tainable forest management. For. Chron. 84, 807–826.
Zhang, W., Chen, Y., Wang, H., Chen, M., Wang, X., Yan, G., 2016. Efficient registration of terrestrial LiDAR scans using a coarse-to-fine strategy for forestry applications. Agric. For. Meteorol. 225, 8–23. https://doi.org/10.1016/j.agrformet.2016.05.005.
Zhou, Guiyun, Wang, Bin, Zhou, Ji, 2014. Automatic registration of tree point clouds from terrestrial LiDAR scanning for reconstructing the ground scene of vegetated surfaces. IEEE Geosci. Remote Sens. Lett. 11, 1654–1658. https://doi.org/10.1109/lgrs.2014. 2314179.
