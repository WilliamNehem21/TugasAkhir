Applied Computing and Informatics 15 (2019) 172–181








Semi-supervised soft margin consistency based multi-view maximum entropy discrimination
Changming Zhu a,⇑, Zhe Wang b
a College of Information Engineering, Shanghai Maritime University, Shanghai 201306, PR China
b College of Information Science and Engineering, East China University of Science and Technology, Shanghai 200237, PR China



a r t i c l e  i n f o


Article history:
Received 16 August 2017
Revised 6 October 2017
Accepted 20 October 2017
Available online 14 August 2018


Keywords:
Semi-supervised multi-view learning Multi-view maximum entropy discrimination
Soft margin consistency
a b s t r a c t 

Multi-view maximum entropy discrimination (MVMED) and alternative MVMED (AMVMED) are pro- posed as extensions of maximum entropy discrimination (MED). In MVMED and AMVMED, they use hard margin consistency principle that the decision of margin parameter is related to classifier parameter directly. While the decision always be indirectly in practice, thus soft margin consistency based multi- view maximum entropy discrimination (SMVMED) has been proposed. But it is found that SMVMED is only adaptive to supervised problems. In this paper, we extend the model of SMVMED to the semi- supervised problems and develop a semi-supervised SMVMED (SSMVMED). Related experiments on multi-view data sets from different aspects have validated the effectiveness of SSMVMED theoretically and empirically. From the experiments, it is found that (1) compared with SMVMED, the average test accuracy of SSMVMED has a 2% enhancement; (2) SSMVMED costs more training time than SMVMED and the extra time is not more than 10%; (3) in terms of the generation of additional unlabeled instances, ‘mid’ strategy has a better test accuracy than ‘self’ and taking all instances to get the center brings a better test accuracy as well; (4) with SSMVMED, the applications to estimation problem and regression problem will be more feasible.
© 2018 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an
open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).





Introduction

Background

Multi-view data set is composed of instances with multiple views and each view consists of multiple features. A corresponding feature group is made up of these features. Take a video data set as an example, suppose this data set consists of multiple videos and each video appears in multiple different forms including visual, audio, and text. Then we treat each form as a view of a video. More- over, each view has several features, for example, text view can be described by text color, text size, text content and color, size, con- tent form a feature group of text view. In order to process those

* Corresponding author.
E-mail addresses: cmzhu@shmtu.edu.cn (C. Zhu), wangzhe@ecust.edu.cn (Z. Wang).
Peer review under responsibility of King Saud University.
multi-view data sets, many multi-view learning machines are pro- posed as below.

pre-fusion methods: multiple kernel learning (MKL) [1], cen- tered alignment-based MKL algorithms (CABMKL) [2], sim- ple MKL method (SMKL) [3], group Lasso-based MKL method (GLMKL) [4], localized MKL (LMKL) [5].
late-fusion methods: robust late fusion method (RLF) [6].
subspace approaches: multi-view linear discriminant analy- sis (MV-LDA) [7], multi-view canonical correlation analysis (MV-CCA) [8], multi-view locality preserving projections (MV-LPP) [9].
disagreement-based methods: co-training [10], confident co-training with data editing (CoTrade) [11], co-regularized Laplacian SVM (Co-Lap) [12].

But these learning machines always neglect to consider uncer- tainties over model parameters and then maximum entropy dis- crimination (MED) [13] has been developed to consider this issue and learn a discriminative classifier. In MED, it learns a distribution p H over classifier parameter H and this is contrast to the tradi- tional learning machines. In terms of traditional learning machines,



https://doi.org/10.1016/j.aci.2017.10.004
2210-8327/© 2018 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



they only find a single classifier parameter p(H) of the discriminant function L(H) (e.g., L(Xt|H)= hT Xt + b; H = {h; b}). While MED obtains a joint distribution p(H; c) over H and margin parameters
c by minimizing its relative entropy with respect to some prior tar- get distribution p0(H; c) under certain large margin constraints, MED marginalizes out c to obtain p H [14].
Although MED considers the uncertainties over model parame- ters, its applicable scope limits to single-view problem. Thus multi- view maximum entropy discrimination (MVMED) [15] and alter- native MVMED (AMVMED) [16] are developed to extend the model of MED to multi-view problems. MVMED and AMVMED exploit multiple views in a different style called margin consistency and enforce the margins from two views to be identical. In other words, they adopt the hard margin consistency while have no ability to process large data sets. So soft margin consistency based multi- view maximum entropy discrimination (SMVMED) [17] has been proposed. Different from MVMED and AMVMED, SMVMED achieves ‘soft’ margin consistency by utilizing the sum of two KL
divergences KL(p(c)||q(c)) and KL(q(c)||p(c)) in the objective func-
tion, where p c and q c are the posteriors of two view margins, respectively. By balancing all involved terms in the objective func- tion, SMVMED is more flexible.
While SMVMED is only feasible for supervised problems, i.e., the used instances are labeled. Indeed, most real-world multi- view data sets consist of labeled and unlabeled instances and they are named semi-supervised data sets. In order to process semi- supervised data sets, semi-supervised learning machines have been developed and introduced in many applications [18–24]. In terms of the applications of MED, there also exist some related learning machines for semi-supervised problems, for example, semi-supervised multi-sensor classification via consensus-based multi-view maximum entropy discrimination [25], semi- supervised learning via generalized maximum entropy [26], and semi-supervised multi-task learning via self-training and maxi- mum entropy discrimination [27]. But these learning machines do not consider soft margin and we find that soft margin has its special physical meaning. As [17] said, if one view corresponds to
one special sub-learning machine, its parameters include classifier parameter H and margin parameter c. If the decision of c is related to H directly, we define it as hard margin consistency while if the decision is not directly, we call it as soft margin consistency. For
soft margin consistency, [17] has also validated that the decision of c is more flexible and the performance and the conduction of a learning machine is much better and fast.


Proposal and trouble

Thus, in this paper, we still adopt soft margin consistency and apply it to semi-supervised problems and then propose the semi- supervised soft margin consistency based multi-view maximum entropy discrimination (SSMVMED). But during the process of SSMVMED, there is a potential trouble when the data sets consist of few labeled instances and many unlabeled ones. As we know, compared with unlabeled instances, labeled ones can provide more useful discriminant information while in real-world applications, most data sets consist of few labeled instances and many unlabeled ones and labeling instances is a high-cost task. Thus, for traditional semi-supervised problems, the performances of learning machines are sensitive to the data sets. In order to enhance the performance of a learning machine, a widely used and feasible method is gener- ating additional unlabeled instances with the original labeled or unlabeled ones and combining all instances together. These addi- tional unlabeled instances will possess some discriminant informa- tion derived from the original labeled and unlabeled instances. Here, Universum learning [28] is such a kind of method. For
Universum learning, it aims to create additional unlabeled instances (also called Universum instances or Universum set) and incorporates priori knowledge which is introduced in the form of additional unlabeled instances into the learning process [29]. By Universum learning, the performance of a traditional learning machine can be boosted. Now Universum learning has been grad- ually spread into different applications [30–34] and some related methods are also developed including Universum support vector machine (U-SVM) [35] and self-Universum support vector machine (SUSVM) [36]. So for our SSMVMED, we also adopt Universum learning to add useful discriminant information.
But for these Universum-based learning machines, there still exists two key problems. First one is that when generating Univer- sum set, the weights of views and features which play different discriminant roles are always neglected. Second one is that when generating the additional unlabeled instances, traditional Universum-based learning machines only adopt labeled or unla- beled instances for generation. In order to solve the first problem, we adopt weighted multi-view clustering (WMVC) [37] which is a multi-view clustering method and can find the optimal cluster assignment. With WMVC, the weights of views and features can be gotten. For the second problem, we try to design some schemes and adopt both labeled and unlabeled instances to generate the additional unlabeled instances.

Novelty and practical applications

The novelty of the proposed SSMVMED is given below.
First, compared with some semi-supervised learning machines with MED, SSMVMED adopts the soft margin and inherits the advantages of soft margin consistency which makes the decision of margin parameters be more flexible and the performance and the conduction of a learning machine be much better and faster.
Second, SSMVMED extends the model of SMVMED to semi- supervised problems and this enlarges the applicable scope of MED.
Third, during the procedure of SSMVMED, it improves the Universum learning methods, and when generating the additional unlabeled instances, the weights of views and features will be con- sidered and both labeled and unlabeled instances are used for the generation.
The practical applications of SSMVMED can include estimation problems, regression problem, classification problems and so on. In our work, we will adopt some related experiments to show the effectiveness of our proposed SSMVMED in these applications.

Framework

The rest of this paper is organized as below. Related work about MED is given in Section 2. Description of SSMVMED is given in Sec- tion 3. Experiments are given in Section 4. The conclusions are given in Section 5.

Related work

Since our SSMVMED is the extension of SMVMED and SMVMED is different from MVMED and AMVMED, thus we will review MVMED, AMVMED, and SMVMED here.

MVMED

MVMED was proposed as an extension of MED to the multi- view learning setting and it considers a joint distribution p(H1; H2) over the view 1 classifier parameter H1 and view 2 clas- sifier parameter H2. Using the augmented joint distribution



p(H1; H2; c), the model of MVMED is given in Eq. (1) [15] where 1 6 t 6 N. In this model, L1(X1|H1) and L2(X2|H2) are discriminant functions from two views, respectively. yt is the class label of tth
labeled instance Xt and its margin parameter is ct . X1 and X2 are
the additional unlabeled instances. Third, apply the original labeled, unlabeled, and the generated additional unlabeled instances into the model of SSMVMED.

t	t

the representations of Xt in the first and second views, respectively. With MVMED, multi-view feature selection, multi-view multi-task learning, multi-view structure learning, and some other problems can be solved well.
minp(H1 ;H2 ;c) KL(p(H1; H2; c)||p0(H1; H2; c))	(1)
( R	1
1. Obtain the weights of views and features
In order to obtain the weights of views and features, we adopt WMVC for help. Suppose there is a multi-view data set consisting of   N   instances   represented   by   V   views,   i.e., v = {X1; X2; ... ; XV ; ... ; X1 ; X2 ; ... ; XV } where Xv ∈ Rdv is the repre-

R p(H ; H ; c)[y L (X2|H )— c ]dH dH dc P 0
i
v	v  v	v

2.2. AMVMED
Different from MVMED, AMVMED considers two separate dis- tributions p(H1) over H1 and p(H2) over H2 and balances KL diver-
and v can be represented as v X1; X2; ... ; Xv ; ... ; XV—1; XV . Then according to the notion of WMVC, we try to obtain the weights of views and the weights of features for each view. Let weight of each view be xv where v = 1; 2; ... ; V and weight for the lth feature of
vth view is sv where l = 1; 2; .. . ; dv . Here, each weight should not

gences of their augmented distributions with respect to the
be less than zero. Furthermore, PV  xv = 1 and for each view

in Eq. (2) [16] and 1	t
N q is a coefficient.
Xv ; Pd
sv = 1. Then according to the notion of WMVC, the whole

minp1 (H1 ;c);p2 (H2 ;c)qKL(p1(H1; c)||p0(H1; c))	(2)
+ (1 — q)KL(p2(H2; c)||p0 (H2; c))
8>< R p(H1; c)[ytL1(X1|H1)— c ]dH1dc P 0
number of clusters be M; k denote the index of clusters, and dik denote the belonging of the instance Xi, if instance Xi belongs to kth cluster, then dik = 1, otherwise, dik = 0. For any instance

R	t	t	Xi ; PM
dik = 1. The objective function of WMVC is given in Eq. (4).

>: R p(H1; c)dH1 = R p(H2; c)dH2


min		M ik

v V 1  v V 1	eH	(4)

As [17] said, for both MVMED and AMVMED, they exploit the multiple views in a different style called margin consistency which
M
k=1
s.t.	V
dik = 1;  6i;  dik ∈ {0; 1}
xv = 1;  xv P 0

Moreover, the margins are related to the parameters H
and H
>: Pdv sv = 1;  6v;  sv P 0

directly and those margins are named as hard margins. Although
MVMED and AMVMED have provided state-of-the-art multi-view
In this function, eH = PV
(xv )p PN PM
dik||diag(sv )(Xv — mv )||2 +

learning performance, hard margin requirement is somewhat too strong to fulfill in many cases. For example, all positive margins can lead to the same label prediction in binary classifications.
b V 1||sv ||2 ; sv = {sv ; sv ; ... ; sv }, and diag(sv ) represents the diagonal matrix where other elements in this matrix are zeros.
N	v
Moreover, mv =   i=1 ik i  is the cluster center of kth cluster in the

k	N
i=1 ik

2.3. SMVMED

SMVMED is different from MVMED and AMVMED due to the margin of SMVMED is soft. SMVMED achieves margin consistency by minimizing the KL-divergence between the posteriors of margin parameters from two views. Then a trade-off parameter balancing large margin and margin consistency is also introduced to make the model more flexible. The model of SMVMED is given below.
Here, p(H) or q(H) is a distribution over H and p(H1; H2) is a joint
distribution over H1 and H2. The parameter a is a parameter play-
ing the trade-off role of balancing large margin and soft margin consistency. Compared with MVMED and AMVMED, SMVMED is
vth view. Furthermore, b V ||sv ||2 is used to control the sparsity of the feature weight vectors s ; v so as to avoid the situation that
only a few features are selected in getting a very small but mean- ingless objective value. The parameters p and b are the exponential and balancing parameters, which are selected according to the pri-
ori knowledge of data so as to help controlling the sparsity of the view weight vector x = {x1; x2; ... ; xV } and the feature weight vectors sv ; v = 1; 2; ... ; V respectively.
Then with WMVC, xv can be updated by Eq. (5) and sv can be
updated by Eq. (6) until the computations of xv and sv be conver-
gent or the iteration times is up to a maximum number. In these
2

equations,  Dv = PN PM  dik diag(s )(X — m )	and Bv = b+

ing machine with SMVMED is much better and faster.
(xv )p PN PM
dik(Xv — mv 2 where (H) represents the lth element


min

KL(p(H )||p (H )) + KL(q(H )||q (H ))	(3)
of (H).
i=1
k=1	i
k )l	l

+ (1 — a)KL(p(c)||p0(c))+ (1 — a)KL(q(c)||q0(c))
xv = 	1	
p > 1	(5)

+ aKL(p(c)||q(c)) + aKL(q(c)||p(c))
PV  Dv 1/(p—1)

( R p
c y L X1
c d	dc P 0

u=1 Du
 

s.t.
(H1;
R
)[ t 1(
t |H1)— t ] H1


1; v = argminuDu





Semi-supervised Soft Margin Consistency based Multi-view
sv = 	1	

6l	(6)


Our proposed SSMVMED consists of three steps. First, compute the weights of views and features by WMVC [37]. Second, generate


m=1 Bv
Finally, we can get the optimal or final x and sv and the weights of views and features are also gotten.



3.2. Approaches of generating additional unlabeled instances

After we get the weights of views and features, we will adopt Universum learning to generate the additional unlabeled instances (i.e., Universum instances or Universum set). In our paper, the gen- eration approaches used are given in Table 1. From this table, it is
or unlabeled instance. Eq. (7) shows the model of SSMVMED. In this model, 1 6 t 6 N; 1 6 i 6 L; p(H) (q(H)) is a distribution over H and p(H1; H2) (q(H1; H2)) is a joint distribution over H1 and H2. a is still a parameter playing the trade-off role of balancing large margin and soft margin consistency. H1 (H2) is the view 1
(2) classifier parameter. c is the margin parameter.

found that each approach has a code with the form ‘A-B-C’. ‘A’ has
minp
c q	c KL(p(H1)||p (H1)) + KL(q(H2)||q (H2))	(7)

‘near’, ‘far’. ‘C’ has two choices, ‘mid’ and ‘self’. For ‘A’, ‘all’ (‘unla- beled’, ‘labeled’) represents that one computes the midpoint of all (unlabeled, labeled) instances as a center. For ‘B’, ‘all’, ‘near’, and ‘far’ represent that one uses all instances, K instances which locates nearest from the center, and K instances which locates far- thest from the center as selected instances respectively. For ‘C’, ‘mid’ represents one takes the midpoint of a selected instance and the center to construct Universum set while ‘self’ represents Universum set consists of the selected instances themselves. We




s.t.
+ (1 — a)KL(p(c)||p0(c))+ (1 — a)KL(q(c)||q0(c))
+ aKL(p(c)||q(c)) + aKL(q(c)||p(c))
p(H1; c)[yt L1(X1|H1)— ct ]dH1dc P 0
>< R q(H2; c)[ytL2(X2|H2)— ct ]dH2dc P 0

q(H2; c)[L2(U2|H2)— ci ]dH2dc P 0
In order to optimize Eq. (7), we use an iterative scheme for find-

take U_ 1—2 as the example. In this approach, we first to compute the mean of all instances as a center, then we select K instances which locates nearest from this center, finally take the midpoint of a selected instance and the center to construct Universum set.
For all approaches used here, when we compute midpoint or distance, the weights of views and features should be used. Con-
ing a solution to Eq. (7) which is similar with the one given in [17]. In the mth iteration, we successively update p(m)(H1; c) and q(m) H2; c by solving the following two problems (Eqs. (8) and
(9)) and before the solution, we choose some initial value for q(0) H2; c with q0 H2; c and this makes Eq. (8) be a standard MED problem.

cretely speaking, if there are two instances, X1 = {X1; X2; .. . ; XV }
p(m)(H ; c)= argmin
KL(p(m)(H )||p (H ))	(8)

and X2 = {X ; X ; .. . ; XV }. The weights of views are x1; x2 ; ... ; xV
KL p	p
KL p	q

2  2	2
v
+ (1 — a)  ( (m)(c)|| 0(c)) + a
( (m)(c)|| (m—1)(c))

and the weights of features are s

where v = 1; 2; ... ; V and	( R	1

	

PV  x Pdv (sv (Xv +Xv ) )

is PV
x Pdv
2
(sv (Xv — Xv 2

where (H)

represents the lth ele-
q(m)(H2; c)= argminq(m) H c KL(q(m)(H2)||q0(H2))	(9)

v=1  v
l=1  l	1
2 )l )	l
+ (1 — a)KL(q(m)(c)||q0 (c)) + aKL(q(m)(c)||p(m)(c))

ment of (H).
s.t.( R
q(m)(H2; c)[yt L2(X2|H2)— ct ]dH2dc P 0

Solution of SSMVMED
Once we generate additional unlabeled instances, we will apply
q(m)(H2; c)[L2(U2|H2)— ci ]dH2dc P 0
The Lagrangian of Eq. (8) can be written as

them along with the original labeled and unlabeled instances into
L	Z p(m)
log p(m)(H1) d	10

the model of SSMVMED. For convenience, we adopt a binary-view	=
(H1)
p0(H1)
H1	(  )

data set for example. For a data set with more than two views, we
can divide it into several binary-view problems, and for each binary-view problem, a sub model of SSMVMED is gotten and they
+ (1 — a) Z
p(m)
p(m)(c)
0
Z p(m)
p(m) c
(c)log q(m—1)(c) dc

can be integrated together and get the final model for multi-view data sets.
Suppose for a binary-view data sets, there are N (here N is dif-
— Xt=1 Z
X Z
p(m)(H1; c)k(m)[yt L1(X1|H1)— ct ]dH1dc

instances) labeled instances {X1; X2; yt} and L unlabeled instances
i=1
1;i	i	i

t	t	Z
p(m)(H ; c)

i	i	t	t
p (H )[p (c)]1—a[q(m—1)(c)]a

represents the first (or second) view of the tth labeled instance
Xt and yt is its class label. For U1 (U2), it represents the first (or sec-
X Z	m
0	1	0
m	1



model of SSMVMED adds the constraint of unlabeled instances and the parameter c = {cj } where j = 1; 2; ... ; N; N + 1; ... ; N + L.
t=1
— X Z

p(m)(H1; c)/(m)[L1(U1|H1)— ci ]dH1dc

Namely, SSMVMED considers the margin constraint of each labeled
i=1
1;i	i




Table 1
The codes of used Universum set construction ways.

Code	Way	Code	Way	Code	Way

U_ 1—1	all-all-mid
U_ 1—2	all-near-mid
U_ 1—3	all-far-mid
U_ 1—4	all-near-self
U_ 1—5	all-far-self
U_ 2—1	unlabeled-all-mid
U_ 2—2	unlabeled-near-mid
U_ 2—3	unlabeled-far-mid
U_ 2—4	unlabeled-near-self
U_ 2—5	unlabeled-far-self
U_ 3—1	labeled-all-mid
U_ 3—2	labeled-near-mid
U_ 3—3	labeled-far-mid
U_ 3—4	labeled-near-self
U_ 3—5	labeled-far-self






where k(m) = {k(m)} and /(m) = {/(m)} are sets of nonnegative Lagrange multipliers, one for each classification constraint. Then we take the partial derivative of Eq. (10) with respect to
p(m) H1; c , set it to be zero and get the solution of p(m) H1; c as
below.
cretely speaking, (a) for each data set, we run the compared learn- ing machine for 10 times and 70% instances for each data set are chosen in random for training and the remaining are chosen for test. In the training set, we randomly choose 30% as the labeled instances while the left 70% are treated as unlabeled instances;
(b) for SSMVMED, (b-1) when we compute the weights of views

p(m)(H1; c)= 	1	 p (H1)[p (c)]1—a[qm—1(c)]
(	)
(11)
and features, the setting can be referred to [37], i.e., exponential parameter p is selected from the set {1; 2; ... ; 30} and balancing

ePN  k(m)[y L (X1|H )—c ]+PL  /(m)[L (U1|H )—c ]
parameter b is initialized to be 0.1, the cluster number equals to
 	

(m)  (m)
and sv =  1  ; 6l = 1; 2; ... ; dv ; 6v = 1; 2; ... ; V ; (b-2) when we gener-

where Z1 (k1 ) is the normalization constant and e is the exponen-
l	dv

tial operation. According to [17] said, k(m) is set by finding the unique maximum of the following concave objective function.
J(m)(k(m))= —logZ(m)(k(m))	(12)
ate the additional unlabeled instances, the used approaches can refer to Table 1. In terms of the number of instances which locates farthest or nearest from the center K is selected from the set
{1; ..; Ne—max} where Ne—max = Nt — Nmax. Nt is the total number of

1	1	1	1
Then for Eq. (9), we adopt the same analysis and obtain the solution of q(m)(H2; c) as below.
training instances and Nmax is the number of instances from largest training class. For example, a training data set consists of three classes, one has 100 instances, another has 120 instances, and


q(m)
1
(H2; c)= Z(m)(k(m)) q0 (H2)[q0 (c)]
1—a[p
(c)]a
(13)
the third has 140 instances, then Ne—max = 220; (b-3) since we have given the solution of p(H1) and q(H2) and furthermore, we also

ePN  k(m)[y L (X2|H )—c ]+PL
/(m)[L (U2|H )—c ]

t=1 2;t
t 2  t  2 t
i=1 2;i  2  i  2	i
p(H1) and q(H2), thus it is found that the key of solution is the
expressions of L1(X1|H1) and L2(X2|H2). In our practical experi-

where k(m) = {k(m)} and /(m) = {/(m)} are another sets of nonnega-
tive Lagrange multipliers. Like k(m); k(m) is set by finding the unique maximum of the following concave objective function.
J(m)(k(m))= —logZ(m)(k(m))	(14)
ments, we adopt linear classifier assumptions, i.e., L1(X1|H1)= hT X1 + b1 and L2(X2|H2)= hT X2 + b2. Furthermore, in our  experiments,  we  refer  to  [17]  and  suppose  that
p0 (H1; c) = p0 (H1)p0 (c)= p0 (h1)p0 (b1)p0 (c)   and   q0 (H2; c) = 

2	2	2	2
q0 (H2)q0 (c)= q0 (h2)q0 (b2)q0 (c) where p0 (h1) and q0 (h2) are satis-

As [17] said, after each iteration, we calculate the relative error between values of Eq. (12) from two successively iterations and that of Eq. (14), respectively, and utilize them for determining con- vergence. When the relative errors
fied with Gaussian distributions with mean 0 and standard devia- tion I; p0(b1) and q0(b2) are set to non-informative Gaussian distributions, and p0 (c)= Q p0 (ct ) Q p0 (ci ) and q0 (c) = Q q0 (ct )

(m)
(m)
(m—1)
(m—1)
Q	,cﬃﬃﬃﬃ


—(1—ct )

,ﬃﬃﬃﬃ e— 2 (1	which are Gaussian priors with mean 1 that encour-

and
ages  large  margins  where  c  is  selected  from  the  set

1  2	15

J(m) (m)	J(m—1) (m—1)
J(m—1)(k(m—1))	(16)
2 ; 2 ; ... ; 2
to be0.001.
}. Finally, for SSMVMED, the tolerance s is initialized

are both less than some tolerance s, the iteration ends and finally we can get the optimal p(H1) and q(H2). Then for a test instance Xr = {X1; X2}, we can use y^1 = sign R p(H1)L1(X1|H1)dH1  to get
Comparison for test accuracy

First, we will show the effectiveness of the proposed SSMVMED

the  class  label  of  Xr  from  the  first  view  while y^2 = sign  p(H2)L2(X2|H2)dH2 is used to compute the class label of  Xr  from  the  second  view.  Finally,  we  can  use
y^ = sign x1 R p(H1)L1(X1|H1)dH1 + x2 R p(H2)L2(X2|H2)dH2   to
that SMVMED outperforms MED, MVMED, and AMVMED [17] and the effectiveness of MED-related learning machines have also been validated compared with the traditional multi-view learning machines due to MED-related learning machines consider the

get the class label of Xr in the whole sample space without consider-
ing the view spaces where x1 and x2 are the weights of views respectively.

Experiments

In order to validate that SSMVMED has a better performance, we conduct our experiments on five parts. They are (1) comparison for test accuracy, (2) comparison for training time and computa- tional complexity, (3) comparison between different additional unlabeled instances generation approaches in terms of test accu- racy and training time, (4) application to estimation problem, and (5) application to regression problem.
The used data sets and compared learning machines are given in related experimental contents and we will show the common experimental settings and the setting for our SSMVMED. Con-
pared learning machine is SMVMED here. Experimental setting of SMVMED can be referred to the one of SSMVMED (see (b-3)) since the parameters of SSMVMED include the ones of SMVMED. More- over, the used data sets are six multi-view data sets Course, Cite- seer, Cora, WebKB, NewsGroup, and Reuters. Information of them is summarized in Table 2 where C represents the class number.
(1) Course data set [10] is used to describe web pages and we want to predict whether the given web page is a course page or not; (2) Citeseer and Cora data sets both consist of 4 views and we choose view content and cites here [38]; (3) WebKB data set consists of web pages collected from four universities: Cornell, Texas, Wiscon- sin and Washington which have 5 categories, i.e., student, project, course, stuff and faculty. Data in WebKB are described with two views: content and citation. We treat WebKB in four separate data sets grouped by universities [39]; (4) NewsGroup data set [40] is of six groups extracted from the 20-Newsgroup dataset, i.e., M2, M5,


Table 2
Brief data set description.



M10, NG1, NG2, NG3. Every group contains 10 data sets, and we choose the first set for all six groups in our experiments (see Table 2). For each data set, there are three views, Partitioning Around Methods, Supervised Mutual Information, and Unsuper- vised Mutual Information; (5) In terms of Reuters, it is the abbre- viation of Reuters RCV1/RCV2 Multilingual and this data set consists of machine translated documents which are written in five different languages [41,42]. These five languages are English (EN), French (FR), German (GR), Italian (IT), and Spanish (SP). Each lan- guage is treated as a view of this Reuters data set and each docu- ment can be translated from one language to another language. For this data set, the documents are also categorized into six differ- ent topics, i.e., six classes. They are C15, CCAT, E21, ECAT, GCAT, M11.
Table 3 shows the related experimental results about the com- parison for test accuracy between SSMVMED and SMVMED. From this table, it is found that the proposed SSMVMED outperforms SMVMED in average since on 12 data sets, SSMVMED has a better performance. The average accuracy of SSMVMED has a 2%


Table 3
Test accuracies (average value ± std.) compared with SMVMED. Last row list the win/ tie/lose counts of SSMVMED on all data sets with t-test against SMVMED at significance level 95%. The best performance on each data set is in bold. (H) indicates the sig-value with paired t-test.
enhancement. Moreover, from the standard deviation values, it is found that the performance of SSMVMED is more stable than SMVMED.
Furthermore, in order to validate the difference between SSMVMED and SMVMED is significant, we adopt paired t-test
[45] (paired t-test is different from t-test) and Nemenyi statistical test [46] for quantitative evaluation analysis. Paired t-test is used to analyze if the differences between two compared learning machines on one data set are significant or not. Then for Nemenyi statistical test, it is used to analyze if the differences between two compared learning machines on multiple data sets are significant or not. Nemenyi is different from another famous test, i.e., Fried- man statistical test which is used to analyze if the differences between all compared learning machines on multiple data sets are significant or not. Since the number of compared learning machines here is two, thus we adopt Nemenyi statistical test rather than Friedman statistical test. In generally, the differences always indicate the ones in test accuracy. Thus, here we conduct quantita- tive evaluation analysis in terms of test accuracy.

For paired t-test [45], we use sig-value to represent the sig- nificant differences of test accuracy. When sig-value is less than 0.05, it indicates that the compared two learning machines have a significant difference in the test accuracy on one data set. Furthermore, the difference is more signifi- cant when the sig-value is smaller. According to Table 3, we use H indicates the sig-value with the comparison between SSMVMED and SMVMED. From the table, we find that the difference between SSMVMED and SMVMED is sig- nificant in average.
For Nemenyi statistical test, the performance of two learning machines on all data sets is significantly different if the cor- responding average ranks differ by at least the critical difference
rkﬃﬃﬃ(ﬃﬃkﬃﬃﬃ+ﬃﬃﬃﬃﬃ1ﬃﬃﬃ)ﬃﬃ




where critical value qa is given in Table 4, N is the number of data sets, k is the number of learning machines.





According to Table 3, the average rank of SSMVMED 1.1429 is while the one of SMVMED is 1.8571. Then for Nemenyi statistical test, if a = 0.05, the critical value q0.05 is 1.960 (see Table 4) and
the corresponding CD is 1 960 2·(2+1)  0 5238. Under such a case,
6·14
since 1.1429 0.5238 1.6667 < 1.8571, so the difference between the average rank of SSMVMED and the one of SMVMED is significant. When a = 0.10, the critical value q0.10 is 1.645 (see
Table 4) and the corresponding CD is 1 645 2·(2+1)  0 4396. Under
6·14
such a case, since 1.1429  0.4396  1.5825 < 1.8571, so we get the similar conclusion.
In other words, with paired t-test and Nemenyi statistical test, we can validate the effectiveness of SSMVMED from the quantita-
plexity is O(NdV ). For ‘B’, if we select ‘near’ or ‘far’, the computational complexity is O N N 1 dV /2 ; if we select ‘all’, we can omit the related computational complexity. For ‘C’, if we select  ‘mid’,  the  computational  complexity  is  O(KdV ) or
O N L dV which depends on the selection of ‘B’ and K is the number of selected instances; if we select ‘self’, we can also omit the related computational complexity. As a result, the total compu-
tational complexity of the second step is [min{O(LdV ), O(NdV )},
max O N  L dV  O N N  1 dV /2  O KdV , 2O N  L dV  .
For the third step, the computational complexity is similar with the one of SMVMED. In this step, the computational complexity of
SSMVMED is O N	U 2 while the one of SMVMED is O N	L 2 . Totally speaking, the computational complexity of SSMVMED is

tive evaluation analysis aspect.
O(VM(N + L)((dv 2	2dv )) + O(dM(N + L)) + [min{O(LdV ), O(NdV )},

) +
max{O((N + L)	O(N(N — 1)dV /2)+ O(KdV ), 2O((N + L)dV )}]+

Comparison for training time and computational complexity

Here, we still adopt SMVMED for comparison about the training time and computational complexity. As we know, compared with SMVMED, our proposed SSMVMED has to generate additional unlabeled instances. Thus SSMVMED has to cost more training time theoretically and Table 5 validates that. From this table, we
can find that SSMVMED costs more training time than SMVMED.
dV )+ 
O((N + U)2) and compared with SMVMED, the extra computational
complexity is O(VM(N + L)((dv 2 + 2dv )) + O(dM(N + L))+ [min{O(LdV ), O(NdV )}, max{O((N + L)dV ) + O(N(N — 1)dV /2)+
O KdV , 2O N  L dV	O N  U 2  O N  L 2 . From this result, it looks like that our proposed SSMVMED seems to cost more training  time,  but  compared  with  O((N + U)2)  and
O((N + L) ),O(VM(N + L)((d   2d )) + O(dM(N + L))+[min{O(LdV ),

But the extra time is not more than 10% which is acceptable for us. In other words, we can achieve better test accuracy with only
O(NdV )}, max{O((N + L)dV
) +
)+ O(N(N — 1)dV /2)+ O(KdV ), 2O((N + L)

a little extra time with SSMVMED adopted.
In order to validate the higher training time, we give the com- putational complexity of them theoretically. As we know, in SSMVMED, it consists of three steps. So here, we will discuss the computational complexities for different steps. For convenience, we let the number of labeled instances be N, the number of original unlabeled instances be L, the number of additional unlabeled instances be U.
For the first step, the computation focuses on xv and sv . In
terms of xv, its computational complexity depends on Dv and
the computational complexity of Dv is O(M(N + L)((dv 2  2dv )).
dV )}] won’t influence too much due to N + U and N + L is always
much larger than d, V , M, K.
Now according to the theoretical analysis about computational complexity, we can also validate the conclusion derived from this experimental item that with SSMVMED adopted, we can achieve better test accuracy with only a little extra time.

Comparison between different additional unlabeled instances generation approaches in terms of test accuracy and training time
Here, we will discuss the difference between additional unla- beled instances generation approaches which are given in Table 1

In terms of sv
)Bv+which

l , its computational complexity depends on  l
computational complexity is O(M(N + L)). Thus, for the first step, the	computational	complexity	is	O(VM(N + L)((dv 2
2dv )) + O(dM(N + L)) where d = PV  dv , M is the number of clus-
in terms of test accuracy and training time. Figs. 1 and 2 show the test accuracy and training time of different approaches given in Table 1 on the used data sets. In these figures, orders in ‘Approaches in Table 1’ represent the approaches in Table 1, i.e.,
								


O(VM(N + L)((dv )2 + 2dv )) + O(dM(N + L)), we can select the lar- gest dv and in fact, this selection won’t influence too much.
For the second step, the computational complexity consists of three parts. For ‘A’, if we select ‘all’, the computational complexity is O((N + L)dV ); if we select ‘unlabeled’, the computational com- plexity is O(LdV ); if we select ‘labeled’, the computational com-


Table 5
Comparison about average training time (in seconds).

9-U_ 2—4, 10-U_ 2—5, 11-U_ 3—1, 12-U_ 3—2 , 13-U_ 3—3 , 14-U_ 3—4, and 15-U_ 3—5.
Then from these figures, it is found that different additional unla- beled instances generation approaches bring different perfor- mances. We find that for U_ 1—x (x = 1, 2, 3, 4, 5) approaches, they can get better test accuracies compared with the U_ y—x approaches
where x  1, 2, 3, 4, 5 and y  2, 3 in average. Moreover, we find
that take ‘mid’ strategy for experiments has a better test accuracy than ‘self’. In terms of training time, approaches with taking all instances as the center bring longer training time due to all instances rather than labeled or unlabeled instances are used to compute the center.

Application to estimation problem

Here, we apply our SSMVMED to estimation problem so as to validate its effectiveness. The estimation problem discussed here aims to forecast the demographic trends which has also been dis- cussed in [43]. For the forecast, USs Census population data is used. In the experiments, we predict the demographic distribution in the year 2010 based on the historical data in years 2000 and 2006. The prediction is then compared with the actual Census data in the year 2010. This setting is same as the one in [43]. In [43], the authors conducted the estimation experiments with three stages





1
0.9
0.8
0.7
0.6
0.5
test accuracy comparison

0.4 1	2	3	4	5	6	7	8	9	10	11	12	13	14	15
1

0.9

0.8

0.7

0.6

0.5 1	2	3	4	5	6	7	8	9	10	11	12	13	14	15
Approaches in Table 1

Fig. 1. Comparison between different additional unlabeled instances generation approaches in terms of test accuracy.





300

250

200

150

100
120


100

80

60
training time comparison

200
180
160
140
120
100
80
4

3

2

1

0

1  2  3  4  5  6  7  8  9 10 11 12 13 14 15  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
Approaches in Table 1	Approaches in Table 1

Fig. 2. Comparison between different additional unlabeled instances generation approaches in terms of training time.


and showed the experimental results with 12 figures, while since the limitation of paper length, we won’t show all the results. For convenience, we will only show the average difference between the estimation and the real values of age in year 2010. SMVMED and the proposed method in [43] (we call it EDT) are used for com- parison. Fig. 3 shows the related experiments. From this figure, it is found that compared with SMVMED and EDT, the predicted age distribution of our SSMVMED can accord with the real age distribu- tion to a large extent.

Application to regression problem

Here, we apply SSMVMED to regression problem. The regres- sion problem discussed here aims to estimate full joint distribu- tions from incomplete information which has also been discussed in [44]. In [44], authors proposed generalized cross entropy model (GCEM) and estimated the distribution of Singapore household profile (http://www.singstat.gov.sg) with the joint probability dis- tribution of the household dwelling type (HD), household size (HS) and home ownership (HO) measures. In those experiments, authors conducted the experiments on three different cases: (1) pure entropy with constraints, (2) minimum discrimination infor- mation without constraints, and (3) minimum discrimination information with constraints. Moreover, authors adopted (a) accu-
racy heat maps to compare the accuracy of the three cases, (b) KullbackCLeibler (KL) distance to compare the estimated joint dis- tribution and the observed one, and (c) Linfoots measures to com- pare a wide range of spatiotemporal signals from brain waves to human dynamics. For accuracy heat maps, if the estimated heat map is close to the true heat map, we say the estimation is better. For KL distance, the smaller the KL distance between any two dis- tributions is, the closer are their profiles. For Linfoots measures, it has three indexes, C measures the relative structural content, F looks at the fidelity or peak alignment, and Q reflects the correla- tion quality [44]. If these three indexes are more closer to 1, then we say the estimated distribution is more closer to the true distri- bution. From those experiments, it was found that case 1 and case 2 had comparable performance and case 3 had a best performance. In our experiments, for the limitation of paper length, we won’t conduct all experiments given in [44]. We will only adopt GCEM and SSMVMED for comparison on the Singapore household profile when case 3 is considered. In order to show the results clearly, we combine the results of accuracy heat maps (here, the differences between estimated heat maps and the true ones are given), KL dis- tance, and Linfoots measures together and only show that whether SSMVMED brings a better performance or not. Table 6 shows the results in a simple manner. From this table, it is found that with SSMVMED, the error of estimation is decreased and the difference


5 x 106	difference between the estimation and the real values of age in year 2010 4.5
4
3.5
3
2.5
2
1.5
1
0.5
0	10	20	30	40	50	60	70	80	90	100
age

Fig. 3. The predicted age distribution of US population for the year 2010 based on the population data in the years 2000 and 2006 with SSMVMED, SMVMED, and EDT used.


Table 6
Comparison between GCEM and SSMVMED on Singapore household profile with minimum discrimination information with constraints in terms of the results of heat maps, KL distance, and Linfoots measures.
SMVMED, the average test accuracy of SSMVMED has a 2% enhancement; (2) SSMVMED costs more training time than SMVMED and the extra time is not more than 10% which is accept-

	   able for us; (3) in terms of the generation of additional unlabeled
instances, ‘mid’ strategy has a better test accuracy than ‘self’ and taking all instances to get the center brings a better test accuracy as well; (4) with SSMVMED, the applications to estimation prob- lem and regression problem will be more feasible.

Acknowledgment


between the estimated distribution and the true distribution is more smaller. In other words, SSMVMED brings a better regression performance.


Conclusions

Traditional multi-view learning machines do not consider the uncertainties over model parameters. Thus maximum entropy dis- crimination (MED) and its extended versions multi-view maxi- mum entropy discrimination (MVMED) and alternative MVMED (AMVMED) are developed for this issue. While for processing multi-view data sets, they only use the hard margin consistency
principle that the decision of margin parameter c is related to clas-
sifier parameter H directly. As we know, the decision always be indirectly in practice. So soft margin consistency based multi- view maximum entropy discrimination (SMVMED) has been pro- posed. Although related experiments have validated the effective- ness of SMVMED, it is only adaptive to supervised problems. Indeed, in real-world, most data sets are semi-supervised, namely, the data sets consist of labeled instances and unlabeled instances. So this paper extends the model of SMVMED to the semi- supervised problems and develop a semi-supervised SMVMED (SSMVMED). Furthermore, in order to get more useful discriminant information, we propose some schemes to generate more addi- tional unlabeled instances. Moreover, these generated additional unlabeled instances will also be used in the model of SSMVMED along with the original labeled and unlabeled instances so that the performance of a learning machine can be boosted. Related experiments on multi-view data sets from different aspects have validated the effectiveness of SSMVMED theoretically and empiri- cally. From the experiments, it is found that (1) compared with
This work is supported by (1) Natural Science Foundation of Shanghai – China under Grant No. 16ZR1414500 (2) National Nat- ural Science Foundation of China – China under Grant Nos. 61602296, 41701523, 51575336 and the authors would like to thank their supports.

References

R. Bach, G.R. Lanckriet, M.I. Jordan, Multiple kernel learning, conic duality, and the SMO algorithm, in: Proceedings of the 21st International Conference on Machine Learning, 2004, pp. 6–13.
C. Cortes, M. Mohri, A. Rostamizadeh, Two-stage learning kernel algorithms, in: Proceedings of the 27th International Conference on Machine Learning, 2010, pp. 239–246.
A. Rakotomamonjy, F. Bach, S. Canu, Y. Grandvalet, SimpleMKL, J. Mach. Learn. Res. 9 (2008) 2491–2521.
M. Kloft, U. Brefeld, S. Sonnenburg, A. Zien, Non-sparse Regularization and Efficient Training with Multiple Kernels, 2010. Available from: arxiv preprint
<arXiv:1003.0079>.
M. Gönen, E. Alpaydin, Localized multiple kernel learning, in: Proceeding of the 25th International Conference on Machine Learning, 2008, pp. 352–359.
G. Ye, D. Liu, I.H. Jhuo, S.F. Chang, Robust late fusion with rank minimization, in: Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2012, pp. 3021–3028.
A. Iosifidis, A. Tefas, N. Nikolaidis, I. Pitas, Multi-view human movement recognition based on fuzzy distances and linear discriminant analysis, Comput. Vis. Image Underst. 116 (3) (2012) 347–360.
J. Rupnik, J. Shawe-Taylor, Multi-view canonical correlation analysis, in: Proceeding of Slovenian KDD Conference on Data Mining Data Warehouses, 2010, pp. 1–4.
X. Yin, Q. Huang, X. Chen, Multiple view locality preserving projections with pairwise constraints, Commun. Syst. Inform. Technol. 100 (2011) 859–866.
A. Blum, T. Mitchell, Combining labeled and unlabeled data with co-training, in: Eleventh Conference on Computational Learning Theory, 1998, pp. 92–100.
M.L. Zhang, Z.H. Zhou, Cotrade: confident co-training with data editing, IEEE Trans. Syst., Man, Cybernet., Part B: Cybernet. 41 (6) (2011) 1612–1626.
V. Sindhwani, P. Niyogi, M. Belkin, A co-regularization approach to semi- supervised learning with multiple views, in: Proceeding of ICML workshop on Learning With Multiple Views, 2005, pp. 74–79.



T. Jaakkola, M. Meila, T. Jebara, Maximum entropy discrimination, Adv. Neural Inform. Process. Syst. 12 (2000) 470–476.
T. Jebara, Machine Learning: Discriminative and Generative, Kluwer Academic, 2004.
S.L. Sun, G.Q. Chao, Multi-view maximum entropy discrimination, in: Proceedings of the 23rd International Joint Conference on Artificial Intelligence, 2013, pp. 1706–1712.
G.Q. Chao, S.L. Sun, Alternative multiview maximum entropy discrimination, IEEE Trans. Neural Networks Learn. Syst. 99 (2015) 1–12.
L. Mao, S.L. Sun, Soft margin consistency based scalable multi-view maximum entropy discrimination, in: Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, 2016, pp. 1839–1845.
G. Tzortzis, A. Likas, Kernel-based weighted multi-view clustering, in: 2012 IEEE 12th International Conference on Data Mining, 2012, pp. 675–684.
S.L. Sun, Q.J. Zhang, Multiple-view multiple-learner semi-supervised learning, Neural Process. Lett. 34 (2011) 229–240.
M.Q. Deng, C. Wang, Q.F. Chen, Human gait recognition based on deterministic learning through multiple views fusion, Pattern Recogn. Lett. 78 (C) (2016) 56– 63.
F. Wu, X.Y. Jing, X.G. You, D. Yue, R.M. Hu, J.Y. Yang, Multi-view low-rank dictionary learning for image classification, Pattern Recogn. 50 (2016) 143– 154.
S.H. Zhu, X. Sun, D.L. jin, Multi-view semi-supervised learning for image classification, Neurocomputing 208 (2016) 136–142.
H.Y. Wang, X. Wang, J. Zheng, J.R. Deller, H.Y. Peng, L.Q. Zhu, W.G. Chen, X.L. Li,
R.J. Liu, H.J. Bao, Video object matching across multiple non-overlapping camera views based on multi-feature fusion and incremental learning, Pattern Recogn. 47 (12) (2014) 3841–3851.
R. Sheikhpour, M.A. Sarram, S. Gharaghani, M.A.Z. Chahooki, A survey on semi- supervised feature selection methods, Pattern Recogn. 64 (2017) 141–158.
T.P. Xie, N.M. Nasrabadi, I.A.O. Hero, Semi-supervised multi-sensor classification via consensus-based multi-view maximum entropy discrimination, in: IEEE International Conference on Acoustics, Speech and Signal Processing, 2015, pp. 1936–1940.
A.N. Erkan, Y. Altun, Y.W. Teh, M. Titterington, Semi-supervised learning via generalized maximum entropy, in: International Conference on Artificial Intelligence and Statistics, 2010, pp. 209–216.
G.Q. Chao, S.L. Sun, Semi-supervised multitask learning via self-training and maximum entropy discrimination, in: Neural Information Processing, Springer Berlin/Heidelberg, 2012.
V. Vapnik, S. Kotz, Estimation of Dependences based on Empirical Data, Springer, 1982.
V. Cherkassky, W.Y. Dai, Empirical study of the Universum SVM learning for high-dimensional data, Lect. Notes Comput. Sci. 5768 (2009) 932–941.
D. Zhang, J. Wang, L. Si, Document clustering with Universum, in: International Conference on Research and Development in Information Retrieval, 2011, pp. 873–882.
B. Peng, G. Qian, Y.Q. Ma, View-invariant pose recognition using multilinear analysis and the Universum, Adv. Visual Comput. 5359 (2008) 581–591.
C. Shen, P. Wang, F. Shen, H. Wang, Uboost: boosting with the Universum, IEEE Trans. Pattern Anal. Mach. Intell. 34 (4) (2012) 825–832.
X.H. Chen, S.C. Chen, H. Xue, Universum linear discriminant analysis, Electron. Lett. 48 (22) (2012) 1407–1409.
Z. Wang, Y.J. Zhu, W.W. Liu, Z.H. Chen, D.Q. Gao, Multi-view learning with Universum, Knowl.-Based Syst. 70 (2014) 376–391.
J. Weston, R. Collobert, F. Sinz, L. Bottou, V. Vapnik, Inference with the Universum, in: The 23rd International Conference on Machine Learning, 2006,
pp. 1009–1016.
D.L. Liu, Y.J. Tian, R.F. Bie, Y. Shi, Self-Universum support vector machine, Pers. Ubiquit. Comput. 18 (2014) 1813–1819.
Y.M. Xu, C.D. Wang, J.H. Lai, Weighted multi-view clustering with feature selection, Pattern Recogn. 53 (2016) 25–35.
P. Sen, G.M. Namata, M. Bilgic, L. Getoor, B. Gallagher, T. Eliassi-Rad, Collective classification in network data, AI Mag. 29 (3) (2008) 93–106.
H.J. Ye, D.C. Zhan, Y. Miao, Y. Jiang, Z.H. Zhou, Rank consistency based multi- view learning: a privacy-preserving approach, in: ACM International on Conference on Information and Knowledge Management, 2015, pp. 991-1000.
G. Bisson, C. Grimal, Co-clustering of multi-view datasets: a parallelizable approach, in: Proceedings of the IEEE 12th International Conference on Data Mining, 2012, pp. 828-833.
M.R. Amini, N. Usunier, C.Goutte, Learning from multiple partially observed viewsan application to multilingual text categorization, in: Neural Information Processing Systems (NIPS), 2009, pp. 28–36.
http://multilingreuters.iit.nrc.ca/ReutersMultiLingualMultiView.htm.
G.Q. Li, D.X. Zhao, Y. Xu, S.H. Kuo, H.Y. Xu, N. Hu, G.S. Zhao, C. Monterola, Entropy based modelling for estimating demographic trends, Plos One 10.9 (2015) e0137324.
H.Y. Xu, S.H. Kuo, G.Q. Li, E.F.T. Legara, D.X. Zhao, C.P. Monterola, Generalized Cross Entropy Method for estimating joint distribution from incomplete information, Physica A 453 (2016) 162–172.
V.N. Vapnik, Statistical Learning Theory, Wiley Interscience Press, New York, 1998.
J. Demsar, Statistical comparisons of classifiers over multiple data sets, J. Mach. Learn. Res. 7 (2006) 1–30.
