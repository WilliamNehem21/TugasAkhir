Artificial Intelligence in Agriculture 4 (2020) 162–171











Corn ear test using SIFT-based panoramic photography and machine vision technology
Xinyi Zhang, Jiexin Liu, Huaibo Song ⁎
College of Mechanical and Electronic Engineering, Northwest A&F University, Yangling 712100, Shaanxi, China
Key Laboratory of Agricultural Internet of Things, Ministry of Agriculture and Rural Affairs, Yangling 712100, Shaanxi, China Shaanxi Key Laboratory of Agricultural Information Perception and Intelligent Service, Yangling, Shaanxi 712100, China



a r t i c l e	i n f o


Article history:
Received 10 May 2020
Received in revised form 6 September 2020 Accepted 6 September 2020
Available online 9 September 2020


Keywords:
Corn ear
Panoramic photography Image segmentation Image stitching
Image rectification
a b s t r a c t

Corn ear test is important to modern corn breeding. The test indexes mainly include lengths, radiuses, rows and numbers of corn ears and the kernels they bear, which can benefit the study on breeding new and fine corn va- rieties. These corn traits are often collected by traditional manual measurement, which is difficult to meet the needs of high throughput corn ear test. In this study, image sequences of corn ear samples were captured by building a panoramic photography collecting system. And then, to get the lengths and radiuses indexes, the corn area images were processed based on Lab color space and adaptive threshold segmentation. The sequence images were then matched and the panoramic image of a corn surface were extracted using Scale-invariant fea- ture transform (SIFT). Finally, by using Exponential transformation (ETR) and Sobel-Hough algorithm, ears and rows indexes were acquired. Test results showed that the accuracy of the radiuses and lengths were 93.84% and 94.53%, respectively. Meanwhile, the accuracy of kernels and rows indexes were 98.12% and 96.14%, which were 4.03% and 7.25% higher than that of common mosaiced panoramic image. And the accuracy of kernel area and length-width ratio were 95.36% and 97.42%, respectively. All the results showed that the proposed method can be used for corn ear test effectively.
© 2020 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).





Introduction

Corn, an important food crop, is a valuable source of multiple foods and industrial products (Timsina et al., 2010; Talaviya et al., 2020). In 2019, global corn yield is expected to be 1.106 billion tons, and the corn cultivated area in China has reached 0.65 billion hectares. It is an urgent task to make good usage of limited cultivated area to achieve good quality and high yield of corn (Yang et al., 2006; Shiferaw and Tesfaye, 2006). Using genetic breeding technology to improve the corn ear test (lengths, radiuses, rows and numbers of corn ears, and the kernels) is an important way of modern corn breeding (Cao et al., 2011; Zhao et al., 2009). It is also the foundation of analyzing reasonable yield structure of corn in different conditions and cultivating fine varie- ties. Traditional manual measurement (Wu et al., 2016) mainly depends on hiring lots of workers to calculate and measure corns at present, which is time-consuming and subjective. Owing to the low efficiency and the high cost of traditional manual measurement, researchers are turning to use machine vision technology for the detection and analysis of corn (Zayas et al., 1990; Jin and Tang, 2010; Jiang et al., 2019; Ireri

* Corresponding author at: College of Mechanical and Electronic Engineering, Northwest A&F University, Yangling 712100, Shaanxi, China.
E-mail address: songhuaibo@nwsuaf.edu.cn (H. Song).
et al., 2019; Xia et al., 2019), but there are only few methods for nonde- structive measurement of corn ear (Liu et al., 2015). The technology of corn test based on machine vision and panoramic photography has be- come an attracting trend of high throughput corn farming and has attracted increasing attention.
The objective of this study was to realize the detection of corn ear using panoramic image analysis by building a panoramic photography collecting system. The lengths and radiuses indexes were calculated ac- cording to the rotation angle of the device and the ear radiuses of each image sequence, and the ears and rows indexes were got using the SIFT-based panoramic image.

Related works

The nondestructive measurement of corn ear test methods can be roughly divided into two categories according to the usage of ear im- ages: corn ear test based on side-view images and corn ear test based on panoramic image.
The corn ear test based on side-view image can be classified accord- ing to the number of ear images, that is the phenotypic calculation method of single and multiple images. In the research based on single image, Miller et al. (2016) used Fourier transform sliding window to an- alyze the average size of kernels in the ears, and the Bayesian analysis


https://doi.org/10.1016/j.aiia.2020.09.001
2589-7217/© 2020 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).



was applied to calculate the geometric characteristics of the long and short axes and contours of the ears. The results showed that the average accuracy of each index was above 90.00%. Zhou et al. (2015) obtained the 3D phenotypic parameters of corns through two-dimensional imag- ing, and combined the color characteristics of corns and the biological laws of corns to establish the model. The average measurement speed of the test system was 32.30 kernels/min. The zero-error rate of ear rows and kernels per row was above 93.00%. When using multiple im- ages for corn ear test, Wang et al. (2014) presented an automatic 3D re- construction method of corn ear surface with binocular stereo vision under multiple side-view images, each point cloud from different views was stitched, and the results showed that the volume of the 3D reconstructed corn ear has no significant difference from the manual measured value. It took about 3 h for each corn to complete 3D recon- struction. Grift et al., 2017 calculated the number of kernels using ma- chine vision technology. By inferring the number of artificially calculated rows and the number of ear rows in a single row in the arbi- trarily selected mid-cylindrical middle section, the total number of ear nucleus after peeling was estimated. Although this method required sufficient human interaction, it was simple to operate and an error from −7.67% to +8.60% was got in 23 kernels of corns. In terms of corn ear image acquisition, although the single phenotype calculation method is more efficient, it is easy to cause inaccurate measurement re- sults and poor stability due to incomplete surface information of the whole ear. As for the multiple phenotype calculation method, it can im- prove the accuracy but the complexity of the algorithm is high due to the redundant information on the corn ear surface.
Panoramic photography is mainly a comprehensive image of the ob-
ject. Panoramic photos are generally obtained by a panoramic camera with a rotatable lens, but the hardware equipment is expensive and hard to operate. In recent years, to composite panoramic photography with image sequences shooting by ordinary imaging devices has be- come the tendency (Szeliski, 1996; Brown and Lowe, 2007; Yu and Jungpil, 2010; Laraqui et al., 2017). For corn ear test using panoramic images, Wang et al. (2013) rotated the corn ear in a fixed angle interval in order to capture image sequences. Then SIFT algorithm was carried out to extract image feature points. Then the points were matched up in the neighboring images, and the relative motion between the two im- ages can be described by homography. According to the motion direc- tion, when the consistency detection was performed and the outliers were excluded, the two images were registered to the same coordinate system. The dynamic programming method was used to find a seam- line, and the redundancy regions in the two images along the seam- line were cut to get a fused image. This method consumed about 30s for each corn ear. Experimental results showed that under the condition
of a significant level of α = 0.05, there was no significant difference be- tween the method and manual measurement, but the gray value transi- tion phenomenon still existed in some areas of the panorama and the method had much higher complexity. Based on a vertically fixed indus- trial camera, Du et al. (2018) collected an image dataset of single corn ear consisting of side-view images in different positions, the smallest area of the center distortion of the corn ear was extracted, and the pan- oramic image of the ear surface was stitched. The system image acquisi- tion efficiency was 12 kernels/min, and phenotypic calculation efficiency is 4 kernels/min. The results showed that the accuracy of the length and the number of rows could reach 99.00% and 98.89%, re- spectively. But the number of sequence images was too large and the panoramic images stitched had an obvious dislocation, which would af- fect the follow-up test work.


Materials and methods

The capturing device of panoramic image

In order to obtain the side-view images of a single corn ear, and to shoot around the ear in a fixed sequence, in this study, a stepping motor and a single-chip microcomputer were selected as the main con- trol components for capturing the sequence images of corn. The captur- ing device was shown in Fig. 1. The 51 single-chip microcomputer was used to generate a 1000 Hz pulse signal with a fixed frequency of fn and the signal was inputted as the pulse signal terminal of a 42-type stepping motor, thereby generating a rotation with an angle θ to drive a fixed frame to rotate the corn ear. The step angle θ of the 42-type stepping motor was related to the natural step angle of the motor and the open and shut status of the dial switch on the driver. After calcula- tion, the step angle used in this study was 0.1125°. On this basis, the 51 single-chip microcomputer was used to generate a pulse signal with a frequency fn = 160 Hz, which was the input to the driver's signal port, so that the stepping motor can rotate 18°. Therefore, 20 sequence images can be obtained.
The digital camera used in this research was NIKON-D90 and the
maximum pixel resolution was 4288 × 2848 pixel. The server platform was configured as an Intel® Core (TM) i5-6300 HQ with 8GB running memory, 1 TB hard drive capacity, and the operating system was Win- dows 10 and the programming environment was MATLAB. In terms of device design, a 51 single-chip microcomputers and a 42-type stepping motor were selected to design a corn ear image acquisition device. Among them, the stepping angle of the 42-type stepping motor was 1.8°, the step angle accuracy was ±5%, the maximum radial runout




Fig. 1. Systems consist of the capturing system.




Fig. 2. Image sequences of corn ear samples.


was 0.02 mm and the maximum axial runout was 0.08 mm under 450 g load.
As shown in Fig. 1, a corn ear is fixed on the bracket. When the angel 18° was set by the 51 single-chip microcomputer and the 42-type stepping motor, the corn ear was rotated and one image was captured by the camera. After a whole rotation of 360°, 20 sequence images were obtained for one corn ear and the following operation can be car- ried out.


Materials

In order to verify the performance of the proposed method, 5 differ- ent varieties (Zheng Dan 958, Xian Yu 335, Zheng Da 12, Qin Long 14, Zhong Ke 11), and 10 corn ears were selected. They were air-dried and completely ripe when capturing images. And they were stored in normal temperature between 25 °C and 28 °C. Some corn ears were prone to worm eggs due to their own characteristics, and the diseased area can be easily identified on image sequences of corn ear. Due to the diversity of the selected samples, the parameters of the algorithm needed to be adjusted to enhance the robustness of the algorithm. A part of the sequence images was shown in Fig. 2, it consisted 10 corn ear images in the same angle. As can be seen from Fig. 2, the corn ears were always irregular cylinders, the kernels were arranged unevenly, and the axial direction was not a fixed line. Meanwhile, the size and shape of the selected samples were different, and the kernels of some samples were deteriorated or missing. Furthermore, due to the limita- tion of shooting conditions, there were irrelevant backgrounds and shadows in sequence images, which needed to be removed in subse- quent operations. These problems made it difficult for corn ear test.
In order to check the quality of subsequent panoramic image stitching, a label paper printed with tick marks and cosine curves was designed in this study as shown in Fig. 3. If the cosine curve on the label paper in the panoramic image was complete and continuous, the panoramic image was considered to basically meet the requirements
of the test. When the ear was wrapped by the label paper around a cir- cle, the conversion relationship between the pixel and the actual dis- tance in the image can be found. After measurement and calculation, a unit length on the label paper was 0.45 cm, which corresponded to a pixel distance of 92 pixels in the image. In the subsequent algorithm test, the actual value of each test index of the corn ear was obtained through the conversion of pixels and distances, and compared with the manually tested results to show the performance of the proposed algorithm.



Method

Sequence image processing using lab color space
Color images obtained in natural environments are easily affected by natural light, occlusion, and shadows, so they are more sensitive to brightness. However, images in the Lab color space are less affected by such interference, and the main color of the image sequences of corn area is yellow. It is easier to distinguish the ear area from background by using the Lab color space. Therefore, the segmentation of kernels based on Lab color space was selected. As the RGB color space can't be directly converted to the Lab color space (León et al., 2006), the RGB color space should be converted to the XYZ color space first, which pro- vided necessary conditions for subsequent segmentation of the corn area.
The converted image in Lab color space was shown in Fig. 4(a). The main color of the corn area in the image sequences was yellow, and it was within the variation range of the b-component of the Lab color space, as shown in Fig. 4(b). It can be seen that the gray value of the corn ear area in the image was high, which met the requirements of threshold segmentation, the segmented image was shown in Fig. 4(c). And then the connected domain analysis using the largest circumscribed rectangle as the calibration area laid the foundation of the corn area.




Fig. 3. Label paper with tick marks.




Fig. 4. Grayscale by extracting b-component and plotting the corn area in Lab color space. (a) Corn ear in Lab color space (b) image of target in b-component (c) segmented binary image.


The results showed that the proposed method can well extract the corn area in the image sequences and calibrate it. Assuming that the short side length of the largest circumscribed rectangle is m and the long side length is n, the ear radius and length were determined by Eq. (1).

P	P
mi	n
As shown in Fig. 5, the ear O at point A is the initial state. According to the scroll direction shown in Fig. 5, the rolling distance l1 reaches the po- sition O′ after the rolling distance l1, and the points B and C coincide. The rolling distance l1 should be equal to the arc length l2 of the AB segment.
Considering the corn ear was an irregular cylinder, the calculation of the rolling distance l1 satisfies Eq. (2).
l ≈ r1 + r2 × θ	2

∑ 2	∑ i	1	2	( )

R =  i=1   , H =  i=1 
(1)

P	P
To obtain the panoramic image of the corn ear surface, image se-
quences of the corn ear in each rolling direction were shoot, then the

where i represents the number of image sequences of corn ear, R repre- sents the radius of the corn ear, H represents the length of the corn ear, and P represents the number of image sequences of corn ear.

Determining and matching of key areas of corn ear image sequences After obtaining image sequences of corn ear, it was necessary to de- termine the key area due to the redundant information of adjacent im- ages. In this way can the characteristic part of this image being cropped, which was different from other images. The determination of the key area was related to the ear radius and ear rotation angle calculated by this image. Assuming that the corn ear radius obtained at the current moment is r1, and after the rotation angle θ, the calculated ear radius is r2. If the corn ear was a regular cylinder, the state of the rotation on the fixing device can be equivalent to the ear rolling on the plane. The
key areas of each image were intercepted, and all the key areas were or- derly matched on an image plane. The central axis of the key area was also the central axis of the corn ear image sequences, which was se- lected as the vertical centerline of the image, and the distance between the central axes of adjacent key areas is the distance Li after the rolling angle θ on the plane, as shown in Eq. (3).
Li≈ ri + ri+1 × θ	(3)

where i corresponds to the order of the image sequence acquisition.
The width of the key area was related to the distance between the adjacent image at the front and back, and the central axis of the key area at that time, as shown in Eq. (4).

rolling angle was the rotation angle θ, and the rolling distance was the arc length when the ear rotated.
wi = Li + Li−1
(4)


where wi is the width of the key area for the specified image.
Due to the peculiarity of shooting image sequences of the corn ear, that was to take a total of p image sequences around the angle of the whole interval of the corn ear. The relationship satisfies Lp and w1 was shown in Eq. (5).

Lp≈ rp + r1 × θ, w1 = L1 + LP

(5)

2	2	2

In conclusion, the determination of corn ear's key area was to con- firm a rectangular region rect. The coordinate relationship satisfying the image sequences of the area was shown in Eq. (6).
recti : col − Li−1, 0, wi, row	(6)








Fig. 5. Corn rotating on horizontal plane.
Among them, col and row are the width and height of the image se- quences of corn ear and the unit is pixel. The first two components of the coordinates refer to the coordinates of the upper left corner of the rect- angular area, and the last two components are the width and height of



the rectangular area. Using only the small area closest to the camera can effectively avoid deformation in other areas, and using the intercepted small area is for more stitching accuracy. As shown in Fig. 6, the image was cropped according to the coordinate relationship of Eq. (6), and the corresponding key area image could be obtained.
After obtaining all the key area images of the corn ear image se- quences, a simple horizontally stitching operation was conducted. By stitching the images of all the key areas in order, the panoramic image can be synthesized as shown in Fig. 7. And the partly zoomed result of the panoramic image Fig. 7(a) is shown in Fig. 7(b). The corn ear in Fig. 7 is manually stitched with a label paper printed with a cosine curve on the label paper in advance, so that the quality of the panoramic image can be observed more intuitively. Because corn ear is an irregular cylinder and has the characteristics of radial distortion (Du et al., 2016), there are obvious stitching marks in the panoramic image and the image of adjacent key areas still has information redundancy, which will defi- nitely affect the corn ear test. Therefore, on the basis of existing work, it was necessary to conduct operations for image rectification using the information redundancy of adjacent key area images to make the key area image more consistent, which can reduce the error of subsequent test work.

Image rectification based on SIFT algorithm
After the key area image was cropped and the horizontal stitching was used to synthesize the panoramic image, there are still problems of redundant information and obvious stitching marks as shown in Fig. 8(a). The image rectification algorithm based on SIFT algorithm can be used to adjust the image according to the positions of image matching points in adjacent key areas, which can ensure the needs of high-precision test with the corrected panoramic image of the corn ear surface.
SIFT algorithm can be used to detect and describe parts of the fea- tures in images, find extreme points on spatial scales, and extract their position, scale, and rotation invariants. Then the image data was trans- formed into scale-invariant coordinates based on the local features (Lowe, 1999). The SIFT algorithm mainly includes detecting scale space extremes, determining the direction of key points, generating SIFT feature vectors, and feature matching (Lowe, 2004).



Fig. 7. Result of panoramic image of corn surface. (a) Panoramic image of corn ear surface
(b) result of partly zoomed corn ear surface.



When all the feature points of the image were extracted, the mis- matched points of the corn ear sequence images were deleted and the feature points registration between the key areas was completed. The image with matching points based on SIFT algorithm is shown in Fig. 8(b). The image with choosing points based on SIFT algorithm is shown in Fig. 8(c). And the obtained matching points laid the founda- tion for subsequent image rectification.

Image shifting based on matched point coordinates
The coordinate information of all different groups of matching points in the panorama was recorded in Fig. 8(c). The distance of two adjacent key area images shifting horizontally was determined. That was to cal- culate the difference between the coordinates of the matching points in the same group, as shown in Eq. (7).

dyi = yi −yi '	(7)

where yi and yi′ are the coordinates of the matched points in the adja- cent key area images before and after the moment, respectively, and dyi is the distance between yi and yi′. As shown in Eq. (8), K represents the number of matched pairs in the same group and i ≤ K. Then, the rel- ative displacement of the two adjacent key area images in the direction of the positive y-axis satisfies Eq. (8).


K
∑ dyi
Dy =  i=1	
K


(8)


Assuming that there are P images in the key area of the corn ear, there are P-1 groups of Dy, and the relative displacement of the first image in the sequence is 0. The displacement of the image relative to the first image at the subsequent time satisfies Eq. (9).





Fig. 6. Plotting and cropping the key area. (a) Plotting the key area (b) result of cropping.
dis_yj =

j−1
∑ Dyi
i=1

1<j≤P
(9)





Fig. 8. Corn matching and choosing based on SIFT algorithm. (a) Panoramic image of corn ear surface. (b) Matching feature points based on SIFT algorithm. (c) Choosing feature points based on SIFT algorithm.


Then the maximum value of dis_y was found, which was recorded as
U. The key area image with the maximum displacement dis_y was regarded as the base point, and the relative distance of each image as Dis_y was calculated, which also represents the height of the filled area above each image. The filling pixels are 0, and Dis_y satisfies Eq. (10).
8>< U	j = 1
as possible, and to reduce the information redundancy in the middle area. Therefore, the horizontally shifting of the images of the key area needed to be completed. Assuming that among the same group of matching points in K pairs, the coordinates of each matching point were known, and the coordinate value of the slit in the two images is the width wa of the first image. Taking the origin of first image sequence as the original coordinate, the width wc of the cropping area satisfies
Eq. (12).

Dis_yj =

j−1
∣ ∑ Dyi
i=1
!−U∣ 1<j≤P
(10)


K
∑(wa−xi)


K
∑(xi'−wa)

wc =  i=1	 +  i=1	
(12)

Similarly, the minimum value of dis_y was recorded as U′, and the	K	K

relative distance of each image to the key area image was Dis_y′ whose displacement dis_y was the minimum value, which also repre- sents the height of the filled area below the image. The filling pixels are 0 and satisfies Eq. (11).
8>< −U'	j = 1
among them, xi and xi′ are the abscissa values of the matching points of the first and second image sequences.
The coordinate information of the cropped area was set to rectc. The coordinate relationship satisfied by the cropped area was shown in Eq. (13).

>:  i=1	i
	
∑(wa−xi)
6	7


In summary, shifting the key area image vertically was to calculate the height of each key area image filling the area above or below
c  64 a	K	c  c 75

which is Dis_y or Dis_y′, and then the corresponding area was filled with 0 pixels to ensure that the matched points on the same horizontal line.
The information redundancy of the adjacent images was not reduced after the key area images were shifted vertically according to the coor- dinate of the matched points, but the matched points were corrected to a horizontal line. In order to further improve the accuracy of pano- rama stitching, it was necessary to crop the key area images. The objec- tive of this operation was to make the matched points coincide as much
among them, Hc is the image height of two adjacent key area images af- ter being shifting vertically. Then the coordinate information of the cropped area was applied to all the key area images of a single corn ear. The final panoramic image of the corn ear surface after shifting ver- tically and horizontally were shown in Fig. 9(a) and (b), respectively. After processing, the kernels' areas in the image were basically at the same horizontal line, and there was no vertical dislocation. The cosine curve of the label paper was more continuous and the information re- dundancy of the adjacent key areas was reduced, which lays the




Fig. 9. Panoramic of corn surface after shifting the key area image. (a) Panoramic image of corn ear surface after shifting vertically. (b) Panoramic image of corn ear surface after shifting horizontally.




Fig. 10. Extracting corn zone about corn ear test. (a) Panoramic image of corn ear surface. (b) Grayscale of corn ear area. (c) Binary image of corn ear surface and plotting the connective kernels.


foundation for the further usage of panoramic images to complete the corn ear test.


Panoramic mosaic corn ear test using computer vision
Calculating corn kernel number based on ETR


There is an irrelevant background from the corn ear in the panorama as shown in Fig. 10(a), and it is necessary to remove the background for extracting the ear area. Based on the Lab color space transformation, the b-component was extracted. The irrelevant background was basically eliminated in the grayscale image, and the ear area related to the test was retained as shown in Fig. 10(b).
In the grayscale of the corn ear, the pixel value of the removed irrel- evant background part is 0, and the number of pixels in this part is too large. If the adaptive Otsu algorithm was used directly, the calculation of the optimal segmentation threshold will be affected. Therefore, it is necessary to set the number of pixels, which has the pixel value of zero, to zero, and then perform Otsu to obtain a binary image of corn ear surface. Based on the analysis of connected domains, it was found that there are more kernels adhesion phenomena in the binary image of kernels surface obtained by the segmentation method, which will af- fect the calculation of kernels indexes and reduce the accuracy of corn ear test. As shown in Fig. 10(c), a binary image of corn surface was ana- lyzed and the results of connected domain analysis were performed. The adhesive kernels were drawn by a red rectangular frame.
In this research, the kernels synthesized from 10 corn ears were con- nected after the segmentation, and the number of connected kernels varied, which had an effect on the counting of kernels. The reason for connected kernels was that the grayscale values in the kernels area and the kernels gap were similar. Therefore, in order to further reduce the adhesive kernels, a grayscale transformation on the original corn ear area was performed to increase the contrast between the area and the gap, and used for further segmentation.
The grayscale transformation was a direct and basic spatial domain image processing method in image enhancement technology, which can improve the image quality and make the image much easier to un- derstand. ETR is also called Gamma transform, which can enhance dif- ferent gray intervals through different gamma coefficient values. In order to increase the contrast between the kernels and the gap between kernels, the brightness of the kernels gap area should be compressed to make the kernels easier to distinguish. In this research, gamma =2 was selected to expand the high luminance area (kernels area), and to com- press the low luminance area (the gap between kernels), and increase the image details to segment the kernels. The enhanced image of Fig. 10(a) was shown in Fig. 11.
To prevent the background of the original corn ear area image from participating in grayscale transformation, in this study, the distribution probability Ek of each gray level was calculated based on the image of the corn ear area. If there was a probability g, when Ek < g and the cor- responding gray level was fa, then determined [0, fa] as the background area; when Ek < 1-g and the corresponding gray level was fb, then the area with the gray range [fa,fb] was used as the input area for the gray- scale transformation. In this way can the irrelevant background from the grayscale transformation being avoided.
Adaptive Otsu was performed on the panoramic image of the corn ear surface after grayscale transformation, and then the structural ele- ment with a template size of 10 × 10 pixel was used to perform mathe- matical morphological open operation on the segmented image to remove noise areas. The connected domain analysis was performed to remove the small area with a connected domain area <1000 pixels. When the kernels area at the edge of the image was removed, a binary image of corn ear surface can be obtained as shown in Fig. 12. The


Fig. 11. Result of corn ear surface after exponential transformation.





Fig. 12. Binary image of corn ear surface and plotting the connective kernels after ETR.


number of connective areas plotted by the red rectangular frame are significantly reduced but not completely removed.
Although the binary image of corn ear surfaces obtained by grayscale transformation cannot completely remove the connective kernels, the connective area was reduced and the number of connective kernels were basically <2 kernels. As it is not accurate to directly counting the kernels, the area and width ratio of all kernels in each connected com- ponent were recorded through connected components analysis, and the adhesive areas were processed by a predetermined threshold, and after counting the kernels in the non-adhesion area, the number of ker- nels in the adhesion area was accumulated, thereby the final kernels number can be obtained.
Calculating the number of ear rows based on Sobel operator and Hough transform

Sobel operator is one of the most important operators for image edge detection (Chaple and Daruwala, 2014; Xu et al., 2017). It is simple and effective and suitable for detecting edge information of images with simple texture. Due to the single target in the panoramic image of the corn ear surface and the obvious gray scale changes between the ear rows, Sobel operator was applied to realize edge extraction of the ear rows.
For detecting the number of ear rows, the x-axis direction difference operator Gx was selected to convolve with the panoramic image to ex- tract the edges of the ear rows. Fig. 13(a) shows the result of the convo- lution of the Sobel x-axis direction difference operator and the panoramic image followed by a binarization operation.
Hough transform can use the duality of points and lines to change a given curve in the original image space into a point in the Hough param- eter space through a functional expression, so as to identify the geomet- ric shape in the image. The morphological dilation operation of Fig. 13
(a) was carried out, so that the broken pixel rows of straight pixel units were connected, and then the points in the image were mapped to the Hough parameter space. The detected lines of corn ear surface were shown in Fig. 13(b), and the number of lines nlines can be calculated.

Results and analysis

Corn ear radius and length

In this study, 10 ear corn samples were used for corn test. They were labeled from 1 to 10, which were number 1 to 2 for Zheng Dan 958, number 3 to 4 for Xian Yu 335, number 5 to 6 for Zheng Da 12, number 7 to 8 for Qin Long 14 and number 9 to 10 for Zhong Ke 11. For the corn ear radius and length, the results of artificial and algorithmic tests were compared using the 10 ear corn samples.
The method of extracting corn ear area based on Lab color space transform can calculate the length and width of the largest circumscribed rectangle in sequence images of a single corn. The aver- age length of the rectangle's short side was twice the corn ear radius, and the average length of the rectangle's long side was twice the corn




Fig. 13. Calculating the number of ear rows. (a) Binary image after Sobel edge detection in x-axis direction. (b) Results of lines detection based on Hough transform.


Table 1
Experiment results of computing corn ear radius and length (mm).



ear length. Based on the results of artificial test, the accuracy of corn ear based on algorithm was calculated. Experimental results of radius and length are shown in Table 1. The results showed that the accuracy of the algorithm for measuring the ear radius was 93.84%, and the accuracy of the algorithm for ear length was 94.53%.
correction it was 96.14%, with an increase of 7.25%. And the standard de- viation was 1.2806.
Table 3 shows the results of computing the kernels area and length- width ratio. The kernels area of manual test is the average of 100 kernel sample areas of one corn ear. And the kernel area for algorithm test is




Table 2
Experiment results of computing the number of kernels and rows.

Ear number	The number of kernels	The number of rows


Number of kernels and rows

As for the number of kernels and rows, it was mainly to compare the test accuracy of the commonly used panoramic algorithm and the SIFT- based feature matching algorithm to record the kernels area and length- width ratio of the sample. Among them, simple stitching referred to the operation of cropping and stitching without expanding the width of the cropped region of the sequence images.
Table 2 shows the results of computing the number of kernels and rows. As for the number of kernels, the accuracy of the simple stitching test was 94.09%. After correction, it was 98.12%, with an increase of 4.03%. And the standard deviation was 90.942. As for the number of rows, the accuracy of the simple stitching test was 88.89%. After
the median of all connected domain areas in the binary image. The man- ual test of the length-width ratio is based on manual measurement and the algorithm test of the length-width ratio is the median of the length- width ratios of the largest circumscribed rectangles of all connected do- mains in the binary image. The results showed that the accuracy of the algorithm for kernel area was 95.36%, and the accuracy of the algorithm for length-width ratio was 97.42%.

Conclusion

A total of 10 corn ears samples of 5 different varieties were used for test. The image sequences of corn ears were used for simple stitching. After shifting transformation, a SIFT-based panoramic image of the




Table 3
Results of computing kernel area and length-width ratio.




corn ear surface was obtained. Image segmentation and connected do- main analysis were performed to calculate the final indexes of the test. The results showed that based on the artificial test data, the accu- racy of the corn ear radius was 93.84%, and the accuracy of length was 94.53%. The accuracy of the number of kernels was 98.12%, and the ac- curacy of rows was 94.53%, with an increase of 4.03% and 7.25% com- pared with the simple stitching panoramic images method. And the accuracy of the algorithm for kernel area was 95.36%, and the accuracy of the algorithm for length-width ratio was 97.42%. Except the loading and rotating time of corn ears, the capture time of one corn ear was about 20s for 18 images each corn. The adaptive Otsu combining ETR and the SIFT-based panoramic image are used for the high-precision corn ear test and have made a great improvement. Meanwhile, as the SIFT algorithm and adaptive Otsu based on ETR was time-consuming, the generation of panoramic image usually consumed within 15 s. The result indicated the method had higher accuracy rate for corn ear test, showing that the proposed algorithm was feasible for corn ear test.
In addition, the types and numbers of samples used in this paper were limited, so more samples should be used for validating the pro- posed algorithm.


Declaration of competing interest

All the authors declared that they have no conflicts for publishing the paper.

Acknowledgment

This work was supported by the National Key Research and Develop- ment Program of China (2019YFD1002401) and the National High Technology Research and Development Program of China (863 Pro- gram) (No. 2013AA10230402). The authors would like to thank all of the authors cited in this article and the anonymous referees for their helpful comments and suggestions.

References
Brown, M., Lowe, D.G., 2007. Automatic panoramic image stitching using invariant fea- tures. Int. J. Comput. Vis. 74 (1), 59–73.
Cao, J., Ran, Y., Guo, J., 2011. The design and realization of corn test system. Journal of Changchun Normal University: Natural Science 30 (4), 38–41.
Chaple, G., Daruwala, R.D., 2014. Design of Sobel Operator Based Image Edge Detection Al- gorithm on FPGA. International Conference on Communications & Signal Processing, IEEE.
Du, J., Guo, X., Wang, C., Xiao, B., 2016. Computation method of phenotypic parameters based on distribution map of kernels for corn ears. Transactions of the Chinese Soci- ety of Agricultural Engineering (Transactions of the CSAE), 32(13):168–176.
Du, J., Guo, X., Wang, C., Xiao, B., 2018. Assembly line variety test method and system for corn ears based on panoramic surface image. Transactions of the Chinese Society of Agricultural Engineering (Transactions of the CSAE) 34 (13), 195–202.
Grift, T.E., Zhao, W., Momin, M.A., Zhang, Y., Bohn, M.O., 2017. Semi-automated, machine vision based maize kernel counting on the ear. Biosyst. Eng. 164, 171–180.
Ireri, D., Belal, E., Okinda, C., Makange, N., Ji, C., 2019. A computer vision system for defect discrimination and grading in tomatoes using machine learning and image process- ing. Artificial Intelligence in Agriculture 2, 28–37.
Jiang, B., He, J., Yang, S., Fu, H., Li, T., Song, H., He, D., 2019. Fusion of machine vision tech- nology and alexnet-cnns deep learning network for the detection of postharvest apple pesticide residues. Artificial Intelligence in Agriculture 1, 1–8.
Jin, J., Tang, L., 2010. Corn plant sensing using real-time stereo vision. Journal of Field Ro- botics 26 (6–7), 591–608.
Laraqui, A., Saaidi, A., Satori, K., 2017. Msip: multi-scale image pre-processing method ap- plied in image mosaic. Multimedia Tools & Applications 77 (6), 7517–7537.
León, Katherine, Mery, D., Pedreschi, F., León, Jorge, 2006. Color measurement in l*a*b* units from rgb digital images. Food Res. Int. 39 (10), 1084–1091.
Liu, C., Chen, B., Zhang, X., Wang, Q., Yang, X., 2015. Dynamic detection of corn seeds for directional precision seeding. Transactions of the Chinese Society for Agricultural Ma- chinery 46 (9), 47–54.
Lowe, D.G., 1999. Object recognition from scale-invariant keypoints. Proc. INT'l Cnof.
Conputer Vision 1999.
Lowe, D., 2004. Distinctive image features from scale-invariant keypoints. Int. J. Comput.
Vis. 20, 91–110.
Miller, N.D., Haase, N.J., Lee, J., Kaeppler, S.M., De Leon, N., Spalding, E.P., 2016. A robust, high-throughput method for computing maize ear, cob, and kernel attributes auto- matically from images. Plant J. 89 (1), 169–178.
Shiferaw, F., Tesfaye, Z., 2006. Adoption of improved maize varieties in Southern Ethiopia: factors and strategy options. Food Policy 31 (5), 442–457.
Szeliski, R., 1996. Video mosaics for virtual environments. IEEE Comput. Graph. Appl. 16 (2), 22–30.
Talaviya, T., Shah, D., Patel, N., Yagnik, H., Shah, M., 2020. Implementation of artificial in- telligence in agriculture for optimisation of irrigation and application of pesticides and herbicides. Artificial Intelligence in Agriculture 4, 58–73.
Timsina, J., Jat, M.L., Majumdar, K., 2010. Rice-maize systems of south Asia: current status, future prospects and research priorities for nutrient management. Plant & Soil 335 (1–2), 65–82.
Wang, C., Guo, X., Wu, S., Xiao, B., Du, J., 2013. Investigate maize ear traits using machine vision with panoramic photography. Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering 29 (24), 155–162.
Wang, C., Guo, X., Wu, S., Xiao, B., Du, J., 2014. Three dimensional reconstruction of maize ear based on computer vision. Nongye Jixie Xuebao/Transactions of the Chinese Soci- ety of Agricultural Machinery 45 (9) (274-279 and 253).
Wu, G., Chen, X., Xie, J., Zheng, Y., Tan, J., 2016. Design and Experiment of Automatic Va- riety Test System for Corn Ear (Transactions of the Chinese Society for Agricultural Machinery).
Xia, Y., Xu, Y., Li, J., Zhang, C., Fan, S., 2019. Recent advances in emerging techniques for non-destructive detection of seed viability: a review. Artificial Intelligence in Agricul- ture 1, 35–47.
Xu, B., Liu, L., Wu, X., 2017. A new method and simulation of image edge detection based on sobel operator and FPGA design. Boletin Tecnico/Technical Bulletin 55 (11), 285–292.
Yang, G., Li, X., Wang, C., Luo, X., 2006. Study on Effects of Plant Densities on the Yield and the Related Characters of Maize Hybrids (Acta Agriculturae Boreali-Occidentalis Sinica).
Yu, T., Jungpil, S., 2010. De-ghosting for image stitching with automatic content- awareness, International Conference on Pattern Recognition. IEEE 23 (26), 26–27.
Zayas, L., Converse, H., Steele, J., 1990. Discrimination of whole from broken corn kernels with image analysis. Transactions of the ASAE 33 (5), 1642–1646.
Zhao, C., Han, Z., Yang, J., Li, N., Liang, G., 2009. Study on application of image process in ear traits for DUS testing in maize. Entia Agricultura Sinica 42(11).
Zhou, J., Ma, Q., Zhu, D., Guo, H., Wang, Y., Zhang, X., Li, S., Liu, Z., 2015. Measurement method for yield component traits of maize based on machine vision. Transactions of the Chinese Society of Agricultural Engineering 31 (3), 221–227.
