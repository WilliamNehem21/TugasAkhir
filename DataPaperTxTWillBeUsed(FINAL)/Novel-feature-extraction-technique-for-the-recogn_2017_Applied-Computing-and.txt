



ORIGINAL ARTICLE
Novel feature extraction technique for the recognition of handwritten digits

Abdelhak Boukharouba a,*, Abdelhak Bennia b

a Faculte´ des Sciences et de la technologie, De´partement d’Electronique et de Te´le´communications, Universite´ 8 Mai 1945 Guelma, BP 401, Guelma 24000, Algeria
b Faculte´ des Sciences de la Technologie, De´partement d’Electronique, Universite´ Constantine 1, Algeria

Received 15 December 2014; revised 1 May 2015; accepted 17 May 2015
Available online 27 May 2015

Abstract This paper presents an efficient handwritten digit recognition system based on support vector machines (SVM). A novel feature set based on transition information in the vertical and hor- izontal directions of a digit image combined with the famous Freeman chain code is proposed. The main advantage of this feature extraction algorithm is that it does not require any normalization of digits. These features are very simple to implement compared to other methods. We evaluated our scheme on 80,000 handwritten samples of Persian numerals and we have achieved very promising results.
© 2015 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is
an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



Introduction

The recognition of handwritten script is a difficult task due to the different handwriting qualities and styles that are subject to inter-writer and intra-writer variations. Many recognition sys- tems in many applications have been proposed in recent years where higher recognition accuracy is always desired. Typically, the recognition systems are adapted to specific applications to achieve better performance. They can be divided into three

* Corresponding author. Tel.: +213 777 08 32 32; fax: +213 37 20 72
68.
E-mail address: boukharouba_abdelhak@hotmail.com (A. Boukhar- ouba).
Peer review under responsibility of King Saud University.
main steps: preprocessing step, feature extraction and selection step, and classification and verification step. Handwritten digit recognition problem can be seen as a subtask of the optical character recognition (OCR) problem. Unconstrained hand- written digit recognition has been applied to recognize amounts written on checks for banks or zip codes on envelopes for postal services, etc.
This paper focuses on feature extraction and classification. The performance of a classifier can rely as much on the quality of the features as on the classifier itself. A good set of features should represent characteristics that are particular for one class and be as invariant as possible to changes within this class [1]. Commonly used features in character recognition are: invariant moments [2], projections [3], zoning feature [4], Four- ier descriptors [5], and contour direction histogram [6]. A fea- ture set made to feed a classifier can be a mixture of such features.
While handwritten Latin digits recognition has been exten- sively investigated [7–10] through various techniques, little

http://dx.doi.org/10.1016/j.aci.2015.05.001
2210-8327 © 2015 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

work has been done for Arabic/Farsi digit recognition. Direc- tion histograms using segmented characters from words in the CEDAR database [11] and transition information from the background to the foreground pixels in the vertical and hori- zontal directions of a character image [12] have been investi- gated. Later, feature extraction techniques generating local and global features were proposed [13] wherein local features were obtained from sub-images of the character including fore- ground pixel density information and directional information. The global features measured the fraction of the character appearing below the word baseline and the characters’ width/height ratio. Furthermore, gradient features have been proposed for handwritten character recognition [14,15] where Awaidah and Mahmoud combined them with structural and concavity features for the recognition of Arabic (Indian) numerals using hidden Markov models (HMM) [16].
A probabilistic neural network (PNN) approach for the recognition of the handwritten Indian numerals [17] based on the center of gravity and a set of vectors to the boundary points of the digit has been presented however Montazer et al. [18] proposed a holistic approach using neuro-fuzzy inference engine to recognize the Farsi numeral characters. Finally, Impedovo et al. introduced a genetic algorithm based clustering approach using zoning features [19] whereas an adaptive zoning techniques for handwritten digit recognition are presented [20,21] where the features are extracted accord- ing to an optimal zoning distribution. The experimental tests show the effectiveness of the latter with respect to traditional approaches for zoning design.
The literature details many high accuracy recognition sys- tems for handwritten Farsi digit database [22] used in our research. While an efficient feature set based on modified con- tour chain code has been proposed in [23], two types of feature sets based on modified chain-code direction frequencies in the contour pixels of input image and modified transition features have been presented [24]. A support vector machine (SVM) is proposed as classifier to recognize Persian isolated digits. Besides, combinational methods for improving the recognition rate of multi-class classifiers using confusion matrix and Genetic Algorithms have been proposed [25,26]. From the lit- erature survey of the existing feature extraction techniques for character/digit recognition, most of them need digit normaliza- tion and consequently cannot preserve the shape of the input image for feature extraction step, which could react negatively to the recognition phase. For that reason, the main contribu- tion of this work focuses on novel feature extraction approach where the digit image does not require any normalization.
This paper is broken down into five sections. Section 2 provides details on the feature extraction and selection tech- niques. Section 3 deals with the classifiers used for the recog- nition purpose, experimental results are discussed in Section 4, and finally Section 5 presents some conclusions and perspectives.

Feature extraction and selection

In this section, we describe two feature extraction techniques that are investigated in this work. The first is the chain code histogram (CCH) [27], which is developed to simply describe statistically the boundary of each digit’s image. To eliminate the effect of contour direction distortion caused by digit image
normalization, we compute the feature vector without normal- izing digit image. Finally, we normalize feature vector by mak- ing its module equal to one. The second feature extraction technique builds on the white–black transition information in the vertical and horizontal directions of a digit image. Each transition feature is characterized by the area defined by the corresponding transition and normalized by dividing it by the whole digit’s area.
The first feature set is the chain code histogram (CCH), which is a statistical measure for the directionality of the con- tour of a digit. In this work, we measure the slope between two successive points, which would give the angle made by the line joining them and the x-axis. Then the set of possible slopes is
(0°, 45°, 90°, 135°), which are identical to the directions (180°, 225°, 270° and 315°). Thus, the directions between two succes-
sive pixels are encoded as 0, 1, 2 and 3 direction codes, respec- tively as shown in Fig. 1. Consequently, one of four direction codes is assigned to each two connected pixels.
The Canny algorithm is more robust to noise and more likely to detect true weak edges but some digit samples are with bad qualities so that after applying canny operator some redundant pixels are remained, which affect the contour fol- lowing, these pixels should be removed. The redundant pixel removal process is based on the condition that every contour pixel can only have two 8-connected pixels around it. If there is a pixel which has more than two 8-connected pixels around it, the redundant pixels must be detected and removed. An example of redundant pixel removal process is shown in Fig. 2 where pixel 2 is a redundant one and must be removed. After removing redundant pixels, the contour becomes of unit thickness and consequently, we find that only 4 possible seg- ments exist in the contour structure, which are considered as basic segments consisting of two pixels. Consequently, the fea- ture extraction process is independent of the tracing direction. To extract features from digit contour, we employ a his- togram of the 4-chain code directions. The 4-bin histogram of chain code directions is computed where each bin represents
the frequency of the one direction.
First, the smallest bounding box enclosing the digit contour is computed. If any of the number of rows or columns of the bounding box is not a multiple of 3, one or two rows/columns of zeros should be added. If only one row of zeros is to be added then it will be added on the right side of the image. If two rows of zeros are to be added then each one must be on one side and similarly for columns. Consequently, the image can be divided into 3 × 3 zones of equal area. The tracing pro- cess starts from the end point on the contour element, search- ing for the next nonzero pixel in any direction until end point is


Fig. 1	Diagram of the 4-chain code directions.


Fig. 2 The redundant pixel removal principle: pixel 2 is a redundant pixel and must be removed.

reached. The remaining contour elements are traced in the same way.
Fig. 3 shows an example of chain code histogram of the contour points of the middle-left and top-right zones of the digit ٣.
Afterward, the contour feature vector composed of 9 × 4
(36) components is normalized as follow.
f = hi  ;  i = 1; 2; ... ; 36	(1)

where hi is the ith bin of the tangent histogram of the whole digit, fi is the ith component of the feature vector f, which is between 0 and 1, and   is the 2-norm. Thus,  f  = 1. Conse- quently, these features are a translation and scale invariant contour descriptors and they are independent of the way a con- tour is traced.
The second set, which is used as complementary description of digits, is based on the white–black transition information in the vertical and horizontal directions of a digit image. This technique is an extension of that presented in [28] where the transition description is based on the length of the transitions. However, this technique is based on the areas between these transitions and the bounding box of the digit as region descriptors.
Each transition feature is calculated as the ratio between
the area defined by each transition type and the whole digit’s area. The area is computed as the number of pixels between
where hak and vak are the areas of the regions defined by the edge of the kth transition in the horizontal and vertical direc- tion, respectively. w and h are the width and the height of the digit image.
In the horizontal direction, the bounding box of each digit is divided horizontally in two equal parts. For each part, the three transition features are calculated in the horizontal direc- tion. In the vertical direction, the three transition features are evaluated on the whole digit.
Fig. 4 shows an example of the different areas made by the white–black transitions of the digit ۸. In the horizontal direc- tion we have only tow transition types of each part: the area formed by the first transition is at the left side of each part, the area formed by the second transition is at the right side of each part, and as we have not a third transition, the corre- sponding area is equal to zero.
In the vertical direction we have only one transition: the corresponding area is at the bottom side of the digit; and as we have only one transition, the second and third area is equal to zero.
Finally, relative area feature is calculated with respect to pre-fixed area (w0 · h0): ratio = w · h/w0 · h0 where w and h are the width and the height of the digit image respectively. In this work the pre-fixed area w0 · h0 is equal to 2000.
As a result, we obtain a feature vector of 46 components per digit.
Feature selection aims to reduce the dimensionality of the feature space for classification by selecting the most informa- tive features. The most informative features are the ones that best separate the different classes. Feature selection has been used previously for many applications, yielding higher speed and reduced computational cost for the classification process.
One way to evaluate the pertinence of the extracted features is to calculate the discriminative power of each feature. In order to select the most discriminative features, we adopt the Fisher criteria, which compute directly the discriminative power Dk of each feature k as follow [29]:
C

the left/top boundary of the bounding box of the digit image



D =  1 ; where r2 = Xp(w )r2
(2)

horizontal/vertical direction.
where C is the number of classes, p(wi) is a prior probability of

fhk
 hak 
= w · h ; fvk
 vak 
= w · h for k = 1; 2 and fh3
=	kP3hak ;
w · h
class wi, and rik is the variance of feature k according to the class i. These parameters are estimated from the training

fv3 =
kP3 vak .
w · h
dataset.
The features must be ordered in the descending order in terms of their discriminative powers in order to select the most


 
Fig. 3	Chain code histogram of the contour points of the middle-left and top-right zones of the digit ٣.

1	2
Lp =	w  —	ai[y (xTw + b)— 1]	(6)
i  i
i=1
where the ai are the Lagrange multipliers. This problem leads to the maximization of the dual Lagrangian with respect to ai:


N
LD =

ai —
1 XN

aiajy y (xTxj)


i=1
2 i,j
i j  i



s.t. ai P 0,	i = 1, .. . , N,
N
aiyi = 0

(7)


Fig. 4	Example of the different areas made by the white–black transitions of the digit ۸.




i=1
This is a standard quadratic problem, where a global max- imum ai can always be found and w can be recovered as:
XN
	



the threshold that separates the pertinent features from the
redundant ones. The threshold is then determined with the help of many experiments by undertaking trainings on the selected features. Finally, we retain the threshold that provides the best performance in terms of recognition rate.


Many of ai are zero, which implies that w is a linear combi- nation of a small number of data. The set of elements xi with non-zero ai are called support vectors.
Then, the resulting separating rule is:
f(x)= sign	X	y ai(xTx)+ b!	(9)




SVM is a classifier derived from statistical learning theory first presented by Boser et al. [30]. SVMs were introduced in [31] as learning machines with capacity control for regression and bin- ary classification problems. It has also been proved to be very successful in many other applications such as handwritten digit recognition, image classification, face detection, object detec- tion, and text classification. In the case of classification, SVM try to find an optimal hyperplane that correctly classifies data points by separating the points of two classes as much as possible. For the linearly separable case, the support vector
The SVs are the training patterns that lie on the margin boundaries. An advantage of this algorithm is its sparsity since only a small subset of the training examples are used to com- pute the output of the classifier. Fig. 5 represents a binary clas- sification problem where filled circles and squares are the training data while hollow circles and triangles are the testing data.
In case of such separating hyperplane does not exist, we introduce a set of slack variables ni to allow points inside the margin during the training.

algorithm simply looks for the separating hyperplane with lar- gest margin. This can be formulated as follows: suppose that
all the training data satisfy the following constraints:
1	2
min	w
2
N
+ C	ni
i=1

T	T	s.t. y (xTw + b) P 1 — ni,	i = 1, ... , N.	(10)
xi w + b P +1 for yi = +1 and xi w + b 6 —1 for yi = —1.	i  i

Then the hyperplane (xTw + b) separates the data if and only if:
y (xTw + b) P 1,	6i.	(3)
where penalty parameter C is used to tune the trade-off between the classification errors and the maximization of the margin. The formulation (6) is often called soft margin

i  i
The optimal separating hyperplane is a margin classifier
whose output is given by:
f(x)= sign(xTw + b)	(4)
where x is the input pattern, w is the weights vector, and b is the bias. The bias and the weights are computed by maximiz- ing the margin 1/  w  subject to the constraint that the N train- ing patterns are well classified and outside the margin:

1	2
min	w

(5)

s.t. y (xTw + b) P 1,	i = 1, ... , N.
i  i

with yi ∈ {—1, 1} representing the label of the training pattern
xi. The solution corresponds to the saddle point of the primal Lagrangian:

Fig. 5	Linear separating hyperplanes for the separable case: filled circles and squares are the support vectors.



Fig. 6	Digit samples of handwritten Farsi digits [22], (a) different qualities, (b) different styles.


SVM. This new formulation leads to the same dual problem but with box constraints on the Lagrange multipliers:
0 6 ai 6 C,  i = 1, .. . , N,	(11)
The tuning of the hyperparameter C is a delicate task. A common method is to perform a grid search, i.e. to test many values of C and estimate for each the generalization error.
This approach is valid whenever the set of points of the two classes are linearly separable. Nevertheless in real data this is usually not the case. In order to work with non-linear decision boundaries the key idea is to transform xi to a higher dimen- sion space using a transformation function, so that in this new space the samples can be linearly separable. SVM solve these problems using kernels. One only has to calculate the inner products of the vectors in the feature space via the kernel function K(·, ·). This is the kernel trick that allows the con- struction of a decision function that is nonlinear in the input space but equivalent to a linear decision function in the feature space:
‘‘Hoda” [22]. This dataset consists of ten digit classes from 0 to 9 (۰۱۲۳۴۵۶۷۸۹). For experimental results, 80,000 handwritten samples are considered; 6000 samples per class for training and 2000 samples per class for testing. Fig. 6 shows some digit sam- ples extracted from the used database with different styles and qualities.
Firstly, Canny operator is used for digit contour extraction then the bonding box of each digit contour is divided into nine equal zones. Within each zone the redundant pixels is removed and the contribution of the 4-chain codes are counted in the corresponding histograms. The transition features are calcu- lated as shown above: in the horizontal direction, the bound- ing box of each digit is divided horizontally in two equal parts. For each part, the transition features are calculated in the horizontal direction. In the vertical direction, the transition features are evaluated on the whole digit. Finally, relative area is calculated. The used feature vector is equal to 10.f, where f is the vector of the 46 features.
Secondly, the proposed architecture of SVM based classifier


f(x)= sign
X	yiaiK(xi, x)+ b!

(12)
is composed of ten one-against-all SVMs. The classifier struc- tures were empirically set as follows. The RBF kernel is used

support vectors

where K(xi, x) stands for the kernel function. Typical kernel functions are:
RBF (Gaussian) kernel: K(x , x)= exp — x—xi 2 .
where the variance parameter r is equal to 1 (r = 1) and the
hyperparameter C is equal to 100 (C = 100).
Table 1 shows the details of misrecognition and recognition accuracy of each digit where the recognition accuracy of

i
Sigmoid kernel K(xi, x)= tanh(c(xTxi)+ c).
Polynomial kernel K(x , x)= (c xTx + c)d.
2r2
98.48% is obtained on the whole test set (20,000 samples). It
may be noted that out of 305 misrecognized samples, 183 (60%) samples belong to {۲, ٣, ۴} group and 122 (40%)

There are two common methods to solve a multi-class problem with binary classifiers such as SVMs: one-against all (or one-vs-rest) and one-against-one. In the one-against-all scheme, a classifier is built for each class and assigned to the separation of this class from the others. For the one against- one method, a classifier is built for every pair of classes to sep- arate the classes two by two. Another approach to the recog- nition of n different digits is to use a single n-class SVM instead of n binary SVM subclassifiers with the one-against- all method, thus solving a single constrained optimization problem.

Experiments and results

In this section we present the experimental results to illustrate the benefits of the chain code histogram combined with the transition features in digit recognition field. We evaluate our method on a large handwritten dataset of Farsi digits, named
samples belong to the remaining digits. Thus, the major mis-
recognized digits are among 2, 3 and 4 digits. To improve the recognition accuracy, we use a scheme similar to one intro- duced in [24]. We utilize a classifier composed of seven one- against-all SVMs where {۰, ۱} and {۲, ٣, ۴} represent two separate classes as shown, in Fig. 7. After that, we use one against-all SVM to separate the combined {۰,۱} class. For the recognition of digits ۲, ٣, ۴, we also use twice one- against-all SVM.
Fig. 7 illustrates the recognition system where arrow weights represent the number of the misrecognized digits of each class. Out of a total of 20,000 digits in the testing set, there are 291 digits that are not successfully recognized. Con- sequently, we obtain 98.55%, which showed slight improve- ment when compared with the first scheme. Note that we have got an accuracy of 100% on the training samples (60,000 samples) and also an accuracy of 100% when the train- ing is made on the whole dataset (80,000 samples).









Fig. 7	Recognition scheme: arrow weights represent the number of the misrecognized digits.

The performances of most of the works available for Per- sian numerals are presented in [23–26] where detailed compar- isons with recent published works are discussed. Table 2 shows a comparison with the most excellent existing works, that are to the best of our knowledge the only works in the literature that deal with Farsi digits composing Hoda dataset.
From Table 2 it is clear that the highest recognition rate is 99.02% [24] when 196 features are used for training. In our work, we reached an interesting recognition rate of 98.55% with only 46 features.
The second experiment investigates the performance of SVM classifier based on the reduced feature sets.
In order to yield higher speeds and reduced computational cost for the classification process, we choose to reduce the number of features involved in the training and testing stages of SVM.



Table 3 illustrates the individual discriminative power of each feature. The first column represents the discriminative powers of the features extracted from transitions and the rela- tive area respecting the order described in the transition feature procedure. The discriminative powers of CCH features are pre- sented in a 3 × 3 grid with 4 values in each cell matching the corresponding image region. The threshold value of discrimi- native powers used to select the pertinent primitives must be determined by practical tests. First, the primitives have been ranked in descending order of their discriminative powers. The threshold is then determined by undertaking trainings on the selected features. We retain the threshold that provides the best performance in terms of recognition rate.
Table 4 shows the best results obtained for different num- bers of selected features using the SVM classifier with the same parameters used above (r = 1 and C = 100).
The first column represents the value of threshold of the discriminative power, second column represents the number of selected features, and the last column represents the recog- nition rate achieved on the test data set.
The highest recognition rate achieved here is 98.46% using
40 features and 98.44% using only 36 features, which are slightly less than the rate obtained with the 46 features. It is then sufficient to retain only the 36 primitives whose discrimi- native powers are the most pertinent.
Moreover, the discriminative powers help us to analyze the pertinence of the different features. From Table 3, among the 10 less pertinent features there are only two from the transition features and the remaining are from the CCH features. We can also notice that the most pertinent feature is the area made by the second transition of the low part in the horizontal direction with discriminative power of 0.8217, which prove the perti- nence of the transition features.
The best performance/complexity is obtained with an SVM classifier (r = 1 and C = 100) using 36 primitives, which is more efficient than the system trained on 106 primitives [25].





Moreover, it is important to note that the architecture of a classifier, by reducing its size, requires less storage capacity for its parameters.
We can augment the feature space using some structural features to efficiently remove some confusion and to achieve best results but the main purpose of this work is to demon- strate the efficiency of these new features.
The most noticeable improvement is that a 100% recogni- tion rate is achieved in the training phases for all digits (60,000 and 80,000 samples), which is better than all of those presented in the literature. We believe that our results are very competitive and quite promising since we used only 36 simple features.
As we have achieved a rate of 100% on training datasets, then we can achieve a higher accuracy rate if we train SVM classifiers on appropriate support vectors, because the general- ization property of an SVM does not depend on all the training data, but only support vectors.
Finally, we can see from the results that the achieved accu- racy is due to the discriminatory power of features and the regression capabilities of SVM classifiers.

Conclusion

This paper presents a system for the recognition of the hand- written Persian numerals that could be used for automatic reading of numerical amounts of checks. The main contribu- tion of this work focuses on feature extraction where a novel feature set based on transition information in the vertical and horizontal directions of a digit image combined with the well-known chain code histogram (CCH) is discussed and compared with others in the literature. The classification sys- tem is based on SVM, which is considered one of the most powerful classification techniques and is now widely used in many pattern recognition applications. The results of our experiments show that feature selection procedure reduces the dimensionality of the feature space without affecting the performance of the classifier where the system can maintain high performance with less computational complexity compar- ing to the systems in the literature.
From experimental results, it is evident that our system resulted good performance. We noted that most of misclassi- fied samples were from classes of ۲, ٣, and ۴, which are similar in shapes where their recognition is sometimes difficult even for human being.
Among the most important advantages of this feature extraction algorithm; it does not require any normalization of digits where the most of the published works need digit nor- malization, which degrade the image quality. These features are also very simple to implement compared to other methods. It is obvious that to improve the performance of proposed system further, we need to investigate more on sources of errors. Potential features other than the presented ones may exist. In future, we plan to use some structural features like concavity analysis which may remove some of confusions
among similar classes.
Concerning the SVM classifiers, the tuning of the hyperpa- rameter C is a delicate task. We are sure that the RBF kernel parameters (r and C) used in our experiments are not the best choices and are not implemented optimally because we have tried only a few experiments to choose them. Thus, we can
improve the performance of the system by testing many values of these parameters and estimate for each the generalization error.
Finally, because we have achieved a rate of 100% on train- ing datasets then as perspective we will try to train automati- cally SVM classifiers on the support vector set that represent the more delicate examples instead of the whole training set to achieve higher recognition accuracy.

References

F. Lauer, C.Y. Suen, G. Bloch, A trainable feature extractor for handwritten digit recognition, Pattern Recogn. 40 (2007) 1816–
1824.
C.H. The, R.T. Chin, On image analysis by the methods of moments, IEEE Trans. Pattern Anal. Mach. Intell. 10 (1988) 496–513.
A.L. Koerich, Unconstrained handwritten character recognition using different classification strategies, in: Proceedings of International Workshop on Artificial Neural Networks in Pattern Recognition, 2003.
L.S. Oliveira, R. Sabourin, F. Bortolozzi, C.Y. Suen, Automatic recognition of handwritten numerical strings: a recognition and verification strategy, IEEE Trans. Pattern Recogn. Mach. Intell. 24 (11) (2002) 1438–1454.
H. Kauppinen, T. Seppanen, M. Pietikamen, An experimental comparison of autoregressive and Fourier-based descriptors in 2D shape classification, IEEE Trans. Pattern Anal. Mach. Intell. 17 (1995) 207–210.
K.M. Mohiuddin, J. Mao, A comprehensive study of different classifiers for handprinted character recognition, Pattern Recogn. (1994) 437–448.
X.X. Niu, C.Y. Suen, A novel hybrid CNN–SVM classifier for recognizing handwritten digits, Pattern Recogn. 45 (2012) 1318–
1325.
Z. Man, K. Lee, D. Wang, Z. Cao, S. Khoo, An optimal weight learning machine for handwritten digit image recognition, Signal Process. 93 (2013) 1624–1638.
E. Mohebi, A. Bagirov, A convolutional recursive modified self organizing map for handwritten digits recognition, Neural Netw. 60 (2014) 104–118.
M. Hanmandlu, O.V. Ramana Murthy, Fuzzy model based recognition of handwritten numerals, Pattern Recogn. 40 (2007) 1840–1854.
H. Yamada, Y. Nakano, Cursive handwritten word recognition using multiple segmentation determined by contour analysis, IECE Trans. Inform. Syst. E79-D (1996) 464–470.
P.D. Gader, M. Mohamed, I.H. Chiang, Handwritten word recognition with character and inter-character neural networks, IEEE Trans. Syst. Man Cybern. Part B: Cybern. 27 (1997) 158– 164.
F. Camastra, A. Vinciarelli, Combining neural gas and learning vector quantization for cursive character recognition, Neurocomputing 51 (2003) 147–159.
C.L. Liu, Normalization-cooperated gradient feature extraction for handwritten character recognition, IEEE Trans. Pattern Anal. Mach. Intell. 29 (8) (2007).
C.L. Liu, C.Y. Suen, A new benchmark on the recognition of handwritten Bangla and Farsi numeral characters, Pattern Recogn. 42 (2009) 3287–3295.
S.M. Awaidah, S.A. Mahmoud, A multiple feature/resolution scheme to Arabic (Indian) numerals recognition using hidden Markov models, Signal Process. 89 (2009) 1176–1184.
F.A. Al-Omari, O. Al-Jarrah, Handwritten Indian numerals recognition system using probabilistic neural networks, Adv Eng. Inform. 18 (2004) 9–16.

G.A. Montazer, H.Q. Saremi, V. Khatibi, A neuro-fuzzy inference engine for Farsi numeral characters recognition, Expert Syst. Appl. 37 (9) (2010) 6327–6337.
S. Impedovo, F.M. Mangini, G. Pirlo, A genetic algorithm based clustering approach for improving off-line handwritten digit classification, in: International Conference on Information Science, Signal Processing and their Applications (ISSPA), 2012.
S. Impedovo, F.M. Mangini, G. Pirlo, A new adaptive zoning technique for handwritten digit recognition, in: ICIAP, 2013.
F.M. Mangini, G. Pirlo, Adaptive zoning design by supervised learning using multi-objective optimization, Int. J. Comput. Intell. Appl. 13 (01) (2014).
H. Khosravi, E. Kabir, Introducing a very large dataset of handwritten Farsi digits and a study on the variety of handwriting styles, Pattern Recogn. Lett. 28 (10) (2007) 1133–
1141.
A. Alaei, U. Pal, P. Nagabhushan, Using modified contour features and SVM based classifier for the recognition of Persian/ Arabic handwritten numerals, in: 7th Int. Conf. on Advances in Pattern Recognition, 2009 ‘a’, pp. 391–394.
A. Alaei, P. Nagabhushan, U. Pal, Fine classification of unconstrained handwritten Persian/Arabic numerals by removing confusion amongst similar classes, in: 10th Int. Conf. on Document Analysis and Recognition, 2009 ‘b’.
H. Parvin, H. Alizadeh, B. Minaei-Bidgoli, M. Analoui, A scalable method for improving the performance of classifiers in multiclass applications by pairwise classifiers and GA, in: 4th Int. Conf. on Networked Computing and Advanced Information Management, 2008.
H. Parvin, H. Alizadeh, M. Moshki, B. Minaei-Bidgoli, N. Mozayani, Divide & conquer classification and optimization by genetic algorithm, In: 3rd Int. Conf. on Convergence and Hybrid Information Technology, N., 2008.
J. Iivarinen, A. Visa, Shape recognition of irregular objects, in: David P. Casasent (Ed.), Intelligent Robots and Computer Vision XV: Algorithms, Techniques, Active Vision, and Materials Handling, SPIE 2904, 1996, pp. 25–32.
A. Boukharouba, A. Bennia, Recognition of handwritten Arabic literal amounts using a hybrid approach, Cogn. Comput. 3 (2) (2011) 382–393.
K. Fukunaga, Introduction to Statistical Pattern Recognition, Academic Press, 1990.
B.E., Boser, I.M. Guyon, V.N. Vapnik, A training algorithm for optimal margin classifiers, in: 5th Annual Workshop on Computational Learning Theory, 1992, pp. 144–152.
V.N. Vapnik, The Nature of Statistical Learning Theory, Springer, New York, 1995.
