Available online at www.sciencedirect.com
ScienceDirect

AASRI Procedia 4 (2013) 261 – 267


2013 AASRI Conference on Intelligent Systems and Control
Colorization by Example Using Dual-Tree Complex Wavelet Transform and Jseg
Zahid Ali a*, S.A.M Gilania*
a National University of Computer and Emerging Sciences, Lahore,Pakistan



Abstract

A novel and automated way to colorize gray images by giving an example color image is being proposed. Both images are partially segmented using unsupervised segmentation JSeg. Proposed methodology controls merging of segments in JSeg by analyzing histogram of gray image. Maximum fitting square patches are extracted from each segment in linear time. Some square patches are discarded to avoid error. Gray image and color image segments are matched using Dual Tree Complex Wavelet Transform. Colors between matched segments are transferred using simple mean and standard deviation. Remaining image is colorized using optimization. Experimental results performed show the advantage of automation.

© 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license.
Selection and/or peer review under responsibility of American Applied Science Research Institute

Keywords:Colorization; DT-CWT; texture matching; JSeg; automated;


1.	Introduction

Colorization is adding colors to gray scale images. It is used for enhancing old grayscale photos, marking regions of interest in medical images, enhancing electron microscopic images and satellite images. It can also be used for re-coloring or modifying color images for getting visually pleasant results.
Despite progress in the field it is a tedious job because a lot of human effort is required. Colorization can be

* a E-mail address: ranazahid@gmail.com, asif.gilani@nu.edu.pk











2212-6716 © 2013 The Authors. Published by Elsevier B.V. Open access under CC BY-NC-ND license. Selection and/or peer review under responsibility of American Applied Science Research Institute doi:10.1016/j.aasri.2013.10.039


done by providing example images or by providing color markers on image. Both of these schools of thoughts have merits and demerits. Reinhard[1] showed that color of an image can be transferred to other image using histogram based techniques in perceptually uniform color space lab. Reinhard transfer colors at global level by transferring distribution of one image into other. Welsh [2] transfers color at local level using simple mean and standard deviation. Simple mean and standard deviation are not enough to colorize images correctly. He suggested an interactive approach based on texture synthesis. Irony [4] uses example image for color transfer. This image is supplied along with a partially segmented image. By learning this segmentation target image is segmented. Yao Xiang [6] suggested in which there can be multisource images but target image is chromatic for multi-source transfer.
A novel way to colorize images in which user is not required to provide segmented image or interaction is being proposed. Target image is still gray image and visually pleasant results are obtained and compared with earlier approaches.

Background

Complex Dual Tree Wavelet Transform

Wavelets are being used as an efficient tool in texture based image retrievals. Kingsbury [7] suggested Complex Wavelets (CW) because these are shift invariant which means texture features are more robust to translation in images. Complex Wavelets can distinguish between -45 and 45 lines using dual tree at each scale using one tree for real coefficients and other for complex coefficient. A complex wavelet can be represented as
(1)
where  and  are real valued wavelets.
JSeg- An Unsupervised Segmentation

JSeg is unsupervised segmentation framework for natural images and gives good results on grayscale images [8]. First an image is quantized to 16 levels using Peer Group Filtering (PGF) [9]. Each level represents a class thus forming a class map. Let Z be a set of all points on this maps such that    .The value of z is its coordinates i.e.   . Let N be the total points in class map. Mean m can be calculated as follow,

m 	z


A J-image is calculated as follow
where is total variance and  is mean of variance of each class,

(2)

2
ST 	| z  m |

Higher value of J called mountains indicates edge and low value called valley indicate centre area of a region. A different size windows (starting from 65x65 to 9x9) operation is performed forming a multi-resolution


image called J-image. Lowest windows size is 9x9 called scale 1. Highest is 65x65 called scales 4. From lowest J values, a region growing method is used to segment the image. Valley points are determined in a region below a threshold. Threshold is determined as follow.
From lowest J values, a region growing method is used to segment the image. Valley points are determined in a region below a threshold. Threshold is determined as follow.
(3)
where  are mean and variance of J values of a region. Finally, this results in over-segmented regions. Regions with similar intensity are merged. Regions with Euclidean distance below a threshold are merged. The optimum threshold used is 0.4. This works well for color images. For gray images it is used adaptively after analyzing peaks in a histogram explained in section 3.1.

Proposed approach

An algorithm for colorization in which source image is color and target image is a gray scale image is being presented. Segmentation of natural images is subjective and task dependent. But when a similar image is provided the target image can be matched to source image with reasonable accuracy. The color image can be segmented by keeping color and texture coherency to maximum accuracy with above mentioned approach JSeg [8] . The gray image is segmented using the same approach except adaptive region merging explained in sub-section 3.1. The main steps of proposed algorithm are as follows:
Step 1: Source and target images are subjected to unsupervised segmentation; Step 2: Find maximum fitting square in each segment of both images;
Step 3: Extract features from each square by performing CWT;
Step 4: Only feature vectors of color image and gray image square are matched which are above 15x15 sizes;
Step 5: Transfer color between matching color square to matched segment of gray image using mean and standard deviation;
Step 6: Remaining pixels are colorized using optimization technique.

Segmenting Source and Target Image

The color image is segmented using default scale parameters used in JSeg. Threshold for merging phase used is 0.4. For gray scale image adaptive merging based on histogram analysis is used. Histogram of an image shows distribution of an image. A peak is defined as maxima between two low points [11]. Highest peaks represent major areas of interest in an image. If N is total pixels in an image and  is total number of pixels between two minima. Then percentage of area  of a peak with respect to whole image can be determined as follow:


(4)
Let K represent the count of percentage area of peaks,
 )



Peaks which represents below 5% of an image are ignored. If K is greater than 4 then a scale of 0.3 is used for merging otherwise a scale of 0.4 is used. For 0.3 means areas of interest are many and should be left unmerged.

Finding a Maximum Fitting Box

Once the image is segmented into different segments, every segment is of irregular shape. Comparison of these irregular segments will not yield correct match. So a square patch, representative of that segment, is

extracted from each segment
using existing technique. Suppose S
represents
a single segmented area

converted to binary image. A scan line algorithm is used on binary converted segment S. Maximum fitting box can be determined as follow:
Start from bottom right corner of S;
Move towards left, row by row;
If pixel value is one then look for right pixel, bottom pixel and down diagonal pixel. Find minimum value in all of three and add one in that

S (r, c) =
1	1
  min( S (r, c + 1), S (r + 1, c), S (r + 1, c + 1)) + 1
(5)

r = h-1 c = w-1
Where h and w are height and width of image.


Square starts from maximum value of S and at position of max(S). Its size is    .

Feature Extractions

Feature vector for each square patch is calculated by applying Complex Wavelet at two scales and six orientations. 12 real and 12 imaginary sub-bands are got along with 2 real and 2 imaginary approximation sub-bands. By taking the magnitude of both real and imaginary coefficients and approximation and detailed bands 14 sub-bands are received. Mean and standard deviation is calculated as suggested by Kingsbury [7].
This feature vector extraction is applied on gray square patches and at color patches after conversion to gray scale. These feature vectors are store for later matching. Feature vectors for color image square patches are taken above 20. The reason is that for small square patches mismatch rate can increase.

Matching of Segmented Regions between Source and Target Image

Once the feature vectors are calculated a square patch representing a segment in gray image is picked. Distance of its feature vector with other feature vectors representing color image square patch is calculated. Let q be the feature vector of a query gray patch and be feature vectors of M reference color patches. The distance metric betweenMquery template image q and  used is given below
f i - q

D ( f , q ) =  i =1	
(6)

i	M
 f i + q
The color patch with mii=n1imum distance is the match for the whole gray segment.

Colorization

After the match of gray segment is found from color square patches that color square patches is used for colorizing the whole gray segment of image. Colors are transferred based on mean and standard deviation suggested by Welsh [2]. This process is repeated for all gray segments whose size patch is above 15. This will leave some small gray segments in image. Colors for these gray areas are determined using optimization [3]. All colored pixels are considered known variables (scribbles) and remaining gray pixels are considered unknown variables. Image is converted into YUV color space. Let r be a center pixel and s be its neighbors. A constraint is imposed that neighboring pixels should have similar colors if their intensities(Y) are similar.



  
where  is affinity function it tells how similar intensities are.
(7)


  
If a color at pixel r i.e U(r), is known, the color value U(s) of its neighbours s will be weighted average of . Similarly V channel of YUV color space can be determined. Now the remaining image is fully colorized.

Results


Proposed approach is applied on images used by landmark papers of Irony. Similar results are achieved

without any user
interaction.
For Irony a
segmented
image has to
supply while Welsh uses swatches.

Although minor artifacts (for small patches left unmatched) are introduced sometimes but advantage of no interaction is achieved after the similar image has been supplied.

Conclusion


A novel and
automated
colorization
procedure for example images is proposed.	State-of-the-art

techniques of image processing are used to achieve this. texture matching and segmentation techniques.
The process can be improved by incorporating better



References
Reinhard E, Ashikhmin M, Gooch B. et al. “Color transfer between images”. IEEE Transaction on
Computer Graphics andApplications, pp: 34-40, 2001.
Welsh T, Ashikhmin M and Mueller K. “Transferring Color to Greyscale Images”. In Proceedings of
ACM SIGGRAPH’02, San Antonio, USA, pp: 277-280, 2002.
A. Levin, D. Lischinski and Y. Weiss. “Colorization using optimization”, ACM Trans. Graph, pp: 689-
694, 2004.
R. Irony1, D. Cohen-Or1, and D. Lischinski2 “Colorization by Example”, Eurographics Symposium on
Rendering (2005).
Xiaodi Hou Liqing Zhang “Color Conceptualization” MM’07, September 23–28, 2007, Augsburg,
Bavaria, Germany.
Yao Xiang1, Beiji Zou1, Hui Wang2, Hong Li1, Zheng Xie1 “MULTI-SOURCE COLOR TRANSFER
FOR NATURAL IMAGES” ICIP-2008 IEEE.
Kingsbury, N.G. The Dual Tree Complex Wavelet Transform: a new efficient tool for image restoration
and enhancement. Proc. European Signal Processing Conf., pp319-322,Spetempber 1998.


Y. Deng and B. S. Manjunath, “Unsupervised segmentation of colour- texture regions in images and video”, IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 23, no. 8, pp. 800-810, August 2001.
Y. Deng, S.Kenney, M.S.Moore and B. S.Manjunath, "Peer group filtering and perceptual color image quantization", Proc. IEEE International Symposium on Circuits and Systems VLSI , (ISCAS'99), Orlando, FL, vol 4, pp.21-4 , June 1999
De Silva, D. V. S., et al. "Adaptive sharpening of depth maps for 3D-TV."Electronics Letters 46.23 (2010): 1546-1548.
