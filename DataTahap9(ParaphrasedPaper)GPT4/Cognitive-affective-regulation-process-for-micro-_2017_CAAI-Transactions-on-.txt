In this article, researchers delve into the process through which emotional states evolve, noting that such changes are influenced by the emotional states of interactive entities. Initially, cognitive reasoning and the detection of micro-expressions underpin the process for amending affective computations. Moreover, the authors introduce threshold and attenuation functions to measure the variability in emotions. In practical settings, the robot's own emotional state along with external factors are quantified to calculate the transition probabilities.

To further the model, they integrate the Gaussian cloud distribution to estimate the likelihood of shifts in emotional states. The findings indicate that the model can adeptly manage emotional states within human-computer interaction, enhancing the robot's interaction quality. Their model aligns with psychological research and provides robots with the capability to transcend mechanical emotional responses.

Briefly discussing micro-expressions, these are brief involuntary facial movements that reveal suppressed emotions, first noted by Haggard and Isaacs in 1966, and later defined by Ekman and Friesen in 1969.

The researchers touch upon cognitive modeling as a standard for personal information processing and a key component in cognitive reasoning, which helps anticipate emotional state changes based on the interplay of human and environmental factors.

They address emotion regulation, distinguishing between antecedent-focused techniques that happen before emotional responses form, and response-focused strategies that occur after emotions have emerged, as described by Gross's process model of emotion regulation incorporating cognitive reappraisal and suppression.

For each primary emotion, the activation threshold (M) and saturation threshold (N) are specified. Stimuli below M do not trigger robot behaviors, while those above M activate emotional responses. Emotional intensity does not constantly peak but instead varies, with robots able to switch among differing emotional states. To model this transition, Gaussian cloud distribution is applied.

The researchers also mention robots may avoid specific people or situations as an emotional strategy, and due to the low intensity of facial muscle movement in micro-expressions, robotic emotional expressions are subtle.

Lastly, the paper includes brief bios for Jing Han, a doctoral candidate at the University of Science and Technology Beijing specializing in pattern recognition and affective computing, and Zhiliang Wang, a professor with extensive publications, whose research encompasses artificial psychology, the Internet of Things, and service robotics.