The paper describes a novel system designed to stabilize aerial surveillance videos captured by unmanned aerial vehicles (UAVs), which aims to mitigate unwanted camera motion caused by the UAVs' movements. This system relies on tracking keypoints identified using the Scale Invariant Feature Transform (SIFT) method to model the motion between successive frames as an affine transformation. The motion disturbance is then filtered out using a combination of a Kalman filter and a median filter, leading to smoother and more stable footage.

The authors categorize video stabilization techniques into optical, mechanical, electronic, and digital approaches, focusing on the digital approach, which is a form of image pre-processing involving global motion estimation, motion smoothing, and motion compensation. Among these, accurately estimating global motion is both critical and challenging.

The stabilization process begins by extracting SIFT keypoints from consecutive frames and matching them to estimate the motion between frames, represented by an affine transformation. To address the issue of identifying which keypoints correspond to camera motion rather than moving objects within the frame, a threshold is applied to exclude vectors associated with fast-moving objects. The remaining vectors are then used to construct the transformation matrix that describes the movement of the camera. The authors use a simplified two-dimensional affine transformation model with four parameters to describe this motion.

The proposed system's performance is validated through experiments with actual UAV-captured videos, showing impressive results. Looking ahead, the researchers plan to refine their motion estimation techniques by incorporating optical flow measurements into their local motion detection process.