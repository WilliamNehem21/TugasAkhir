This paper provides an overview of Visual Simultaneous Localization and Mapping (VSLAM), a technique vital to the Augmented Reality (AR) experience that enriches the real world by adding virtual objects. VSLAM enables the identification of the user's position and the structure of the environment around them (both known as localization and mapping, respectively). The paper categorizes recent VSLAM algorithms and explores their applications in AR, mapping, navigation, and localization from technical and historical points of view.

VSLAM methods utilize images to navigate and map environments, a more cost-effective approach than using traditional SLAM sensors such as GPS or LiDAR. Modern cameras are not only affordable but can also capture extensive information about the environment such as color and texture. VSLAM has seen application across various fields, including the control of robots and vehicles for land, air, underwater, and even in medical endoscopy.

There are three fundamental types of VSLAM based on the camera used: monocular, stereo, and RGB-D. Stereo SLAM, being a multi-camera approach, offers better trajectory resolution and versatility compared to RGB-D SLAM, which is more effective indoors due to sensitivity to sunlight.

Visual SLAM's core concept is pivotal in robotics and mobile technology, such as smartphones, where detailed and real-time mapping of an environment is required. VSLAM involves capturing images and processing them to estimate the position of the camera and create maps of the environment. The reliability and accuracy of VSLAM surpass traditional odometry, as it corrects accumulated errors through loop closure mechanisms.

The paper also analyzes different VSLAM algorithms like ORB-SLAM, which optimizes real-time performance in various environments and uses features such as automatic relocalization and loop closure. Denser approaches like DTAM forgo feature matching for pixel-wise tracking to create comprehensive maps. Other notable algorithms include DynaSLAM, which can handle dynamic scenarios, and ORB-SLAM2, suitable for a range of cameras and capable of localizing within pre-built maps.

For evaluation, datasets like the KITTI are used, providing a diverse range of sensor data for traffic scenarios. Crucial for evaluating VSLAM performance are metrics such as Absolute Trajectory Error (ATE), which measures global trajectory consistency.

In summary, this paper emphasizes the importance of VSLAM in modern applications and robotics, identifies and evaluates various algorithms, and discusses methodologies for assessing their performance, noting that ORB-SLAM stands out particularly in monocular settings, while stereo and depth-sensor-based approaches have their respective strengths and limitations.