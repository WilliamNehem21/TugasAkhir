The paper presents a method for dynamic software composition in scientific computing, traditionally considered too performance-intensive for such flexibility. However, the authors argue that dynamic software composition can actually enhance performance when coupled with dynamic architectures and task graph scheduling.

Scientific computing faces challenges in efficiently distributing computations across machine grids. Discovering optimal distribution is NP-hard, impacting, the application’s effectiveness or even its possibility of execution.

The proposed dynamic service infrastructure targets high-performance applications, inspired by multiple computer science domains such as parallel program optimization, dynamic architectures, and software composition. Initially developed for the LOIS space antenna's IT infrastructure, this infrastructure handles high-throughput data parallel applications, which may take sensor data or other applications' outputs as input.

Assuming a High Performance Fortran-like data-parallel program model, the authors presume all programs operate on a unified composite array whose input size remains constant, implying a fixed output size as well.

Task graph creation is program oblivious, depending on the problem size, and the height of a task within it is determined by the longest path from any task with no incoming edges.

Optimal task scheduling is known to be NP-hard, yet the authors argue that heuristics they have contributed to could approximate the ideal schedule closely.

The dynamic aspect enables modification of the IT infrastructure through the addition or removal of applications. However, while task graphs are easily reused, schedules may not be, since optimal scheduling of individual task graphs doesn’t guarantee optimality in the composed system.

Components in this model are malleable tasks, and the infrastructure uses pre-computed mapping for these tasks when deploying on IT systems. Event management also plays a role in handling both external and internal events via a coordinator, blending system-level coordination.

The paper's main contribution is its novel infrastructure that supports dynamic changes, high-performance computing, and precomputed responses to potential architectural changes. The system architecture is optimized in parallel with ongoing operations, deploying optimized systems quickly when events trigger changes and pre-emptively preparing for future system generations.