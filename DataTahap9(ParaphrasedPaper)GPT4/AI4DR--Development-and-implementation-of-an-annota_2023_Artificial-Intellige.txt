High-throughput screening (HTS) is a primary method used in drug discovery for identifying promising compounds. Recent advancements have led to more elaborate screening models, such as quantitative HTS, and the use of additional assays to confirm hits. This evolution has resulted in an increased volume of complex dose-response data from not only HTS but also techniques like phage display, yeast display, and fluorescence-activated cell sorting (FACS). The reliability of dose-response curves (DRCs), crucial for assessing compound potency, can be influenced by screening conditions, protocols, assay quality, and the compounds themselves. Traditional curve-fitting algorithms used in the automatic analysis of DRCs can be compromised by outliers or technical artifacts, necessitating manual oversight to decide on the fate of a compound in the research pipeline. However, visual inspection of the curves is resource-intensive, expertise-dependent, and can introduce variability into the analysis, particularly when the data volume is large.

Distortions in DRCs can arise due to a variety of factors, ranging from compound properties (like aggregation or toxicity) to assay specifics and protocol issues, which may cause interference. Although the "PAINS" (pan-assay interference compounds) concept has been proposed to spot structural features linked to assay artefacts, DRCs of PAINS compounds don't always exhibit abnormalities, highlighting the complexity of analyzing these curves.

In response to these challenges, we've adopted a machine learning (ML) approach, using convolutional neural networks (CNNs), to classify DRCs. Despite CNNs not being the most intuitive choice for such analysis, they offer advantages, including robustness to variations in data, like differing numbers of doses or missing data points. Our CNN model is designed to capture the general shape of DRCs while being less affected by outliers.

We compared the model's performance to expert annotations across consensus and non-consensus datasets. The model performed well, with higher accuracy in the consensus dataset, but it also showed promise in identifying borderline cases where experts disagreed. We've provided the tools developed on GitHub, including models, scripts, and Jupyter notebooks for the analysis of the Tox21 dataset.

For HTS practitioners, the AI4DR plugin's primary advantages are speed and consistency. It enables efficient review of similar curves and application of uniform adjustments, ensuring consistent final annotations. It also helps to identify compound profiles that could be related to the underlying biology of the assay, which is beneficial for complex compounds identified in cellular screenings. This process could further enhance the understanding of structure-activity relationships by highlighting interference issues or rescuing unique compounds that might otherwise be overlooked.

In conclusion, we've pioneered the application of deep learning for classifying DRCs from HTS experiments. Our approach has proven effective in enabling more rapid and consistent categorization of large sets of DRCs. AI4DR could serve as a tool for improving data quality in ML prediction models and in collaborative settings, helping standardize initial evaluations before expert validation.