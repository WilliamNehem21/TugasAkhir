In recent times, a variety of re-identification (re-id) methods have been developed for video surveillance, generally falling into two main categories: feature representation and matching strategy. Feature representation emphasizes the creation of robust visual descriptions of individuals, often using color and texture, which is challenging due to typically low-resolution RGB images in surveillance contexts. In matching strategy, significant research has been dedicated to metric learning and ranking methods, with metric learning showing promising results.

However, these approaches can underperform in varying environments because they often rely on offline learning that doesn't adjust to new scenes with different lighting, camera angles, or backgrounds. Additionally, combining many features to assess person similarity may lead to error build-up and unnecessary computational expense.

To address these issues, this paper proposes an effective online re-id framework. It argues that face images, though harder to capture (e.g., when people face away from the camera), provide more reliable identification than body images, which are typically easier to capture. The system thus considers face and body information as complementary.

The proposed online framework first learns a metric model using offline labeled data, then uses face data to continuously update this model online. Feature similarities are combined using a "feature funnel model" that accounts for feature reliability.

The paper is organized into sections discussing related work, detailing the proposed method (feature extraction, online metric update, and feature funnel model), reporting experiment results comparing the method against current benchmarks, and concluding the findings.

Multi-modal biometric systems are favored over single-biometric methods due to the former's reliability, especially in varying conditions like lighting changes. Multi-modal systems usually either fuse features at a feature level (often disregarding feature reliability) or at a score level; this work's feature funnel model belongs to score-fusing approaches.

The authors adopt P-N learning, a semi-supervised method using both labeled and unlabeled data to train classifiers, to use clear face images for improving the metric model in real-time. To update the metric model, the system trains with labeled data, then uses online data to adjust the model according to face verification results, constantly improving adaptability to new conditions.

Persons are characterized using appearance and geometric features obtained from skeletal information. Features resistant to pose and illumination variation are extracted around skeletal joints. Skeletal Local Ternary Pattern (SLTP) histograms, an enhancement of Local Binary Pattern (LBP) insensitive to noise, are used.

This work demonstrates that face information, with its distinctiveness in identification tasks, helps online metric models significantly adjust to new environments. The proposed online update strategy proves more flexible than offline methods, as evidenced by tests on varied datasets. The paper concludes with acknowledgements of support from various Chinese research funding agencies.