This paper introduces a method that addresses the challenge of matching aerial images with significant rotational differences by combining SIFT (Scale-Invariant Feature Transform) feature matching with pyramid image matching and RANSAC (Random Sample Consensus) algorithm refinement. Initially, a coarse alignment of the images is performed using SIFT matching at the highest level of the image pyramid, which reduces computational demands.

Following the initial SIFT matching, the preliminary matching points' positions are predicted considering the estimated rotation angle, and rotation adjustments are applied to the matching window images. To assess the correctness of SIFT feature pair matches, the discrepancy between candidate points and those expected from an affine transformation model is calculated. Matches within a certain threshold are considered inliers, while those outside are deemed outliers.

For points that fail to match correctly at higher pyramid levels, the method uses nearby successfully matched points to predict their initial positions. The potential issue of multiple peaks in the Normalized Cross-Correlation (NCC) used for matching, often due to repetitive textures or geometric distortions, is addressed by imposing constraints based on relative orientation and introducing an iterative weighting strategy, which helps eliminate incorrect matches.

The efficacy of the proposed method is demonstrated through an experiment involving aerial imagery with a large rotation of a specific region. The approach outlined in the paper aims to improve upon existing methods that require approximate knowledge of the rotation angle or suffer from slow processing times and biases in matching results.