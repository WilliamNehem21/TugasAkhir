Our article is structured into several parts. Section 2 reviews prior research on the detection and prevention of suicidal behavior. Section 3 describes our methodology, which includes data collection, pre-processing, feature engineering, and the training of machine learning models. Section 4 discusses our findings, while Section 5 compares our research with existing studies. Section 6 summarizes our conclusions and potential future research directions.

Mbarek et al. constructed a model to detect profiles at risk of suicide by employing features encompassing linguistic, emotional, facial, timing, and public aspects. They further applied various machine learning techniques with a diverse feature set, such as emotional cues and account characteristics, showing promise in identifying at-risk users, evidenced by tests on individuals who had committed suicide.

Our literature review suggests that minimal research has been conducted on using data mining to predict and prevent suicidal tendencies on social media. One challenge is data scarcity due to privacy and ethical concerns. Previous studies have generally utilized typical feature extraction for binary classification. In contrast, our study collected a substantial corpus of data on suicidal content through Twitter and Reddit APIs and focused on a sophisticated feature extraction technique. Three machine-learning algorithms were then trained to categorize tweets into three levels of distress, as detailed in Section 3.

Social media data tends to be noisy, requiring methods such as tokenization, stop-word removal, and lemmatization to clean the data for machine learning use. Additionally, suicidal expression often lacks clear linguistic patterns, prompting us to engineer features designed to distinguish between varying degrees of distress. Our model uses features where the connection between topics is represented by line thickness â€“ the more overlap in words across topics, the thicker the connection.

We approached suicidal ideation detection as a multi-class machine learning issue, training our model on a dataset with only text titles and labels, employing support vector machine, random forest, and extreme gradient boosting algorithms. Five-fold cross-validation was used to enhance model robustness.

Our analysis of precision and recall balance, particularly with imbalanced datasets, emphasizes the importance of the F1 score in mitigating the disproportionate influence of true negatives and ensuring false positives and false negatives are weighted appropriately.

Binary and multi-class models we developed could be transformed into a digital solution, providing automated intervention messaging and allowing users to consult mental health experts anonymously, combatting the associated social stigma. User feedback on these messages would offer insights to refine the prediction model further.