The academic paper discusses the need for an analysis of dialogue games within multi-agent systems that addresses the handling of epistemic modalities. The paper highlights the problems of inconsistent and biased information in communication between agents. It defines locutions (utterances) as inconsistent if their content contradicts other locutions or is contradictory within itself. Bias is present when an agent leans more towards believing or disbelieving a statement based on the evidence available.

Unlike agents that revise their beliefs to avoid inconsistencies, the agents discussed in this paper do not avoid them. This approach is enabled by employing a multi-valued logic, allowing focus on the semantics of exchanging inconsistent and biased information. The goal is to manage such information in dialogue games effectively. This is achieved by integrating truth values from bilattice structures into the dialogue game, allowing the representation of an agent's cognitive state as a collection of multi-valued logical theories.

To illustrate these concepts practically, a fictional dialogue from "Sesame Street" is used. Here, Elmo's inquiry about playing outside results in inconsistent information being provided by Oscar, showing no belief revision occurs. The dialogue showcases how biased and inconsistent information appears in interactions and the necessity for a formal method to handle it.

The remainder of the article is laid out methodically: Section 2 introduces the formalization of inconsistent and biased information using bilattice structures, followed by the description of a multi-valued logic based on these structures. Section 3 details the multi-valued logic-based dialogue game. The example dialogue from "Sesame Street" is formalized and analyzed to validate the game's rules. The article concludes with Section 5, which likely includes a summary of findings and suggestions for future research.

Through a set of examples, the paper ultimately seeks to demonstrate how agents can manage the addition of inconsistent information monotonically, that is, without necessitating revisions to their belief system. Additionally, it examines the different roles belief statements may play in dialogue based on the cognitive states of the agents. A belief statement could serve as a partial, overinformative, or minimal answer, depending on its relevance to the desires and beliefs of the recipient agent.

The paper thus contributes to the theoretical understanding of dialogue management in multi-agent systems, particularly focused on scenarios where agents must navigate through, and act upon, the biased and inconsistent information without conventional aversion to such information.