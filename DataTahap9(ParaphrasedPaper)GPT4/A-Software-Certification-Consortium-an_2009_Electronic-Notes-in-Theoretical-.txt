Significant efforts have been dedicated to improving the quality and reliability of real-time software systems to minimize the risk of failures that could endanger the public. This has involved research into rigorous methods involving mathematical specifications, verification, and validation. Although these techniques are showing potential in enhancing software quality, it remains uncertain for software practitioners how these theoretical approaches realistically represent embedded systems and their application to practical, industry-level systems. There is ongoing debate about the real-world utility of some formal methods, which may seem more suited to academic contexts than actual industrial use.

In contrast, both the industry and regulatory bodies are recognizing that traditional practices, which rely on compliance with development processes and extensive testing, are insufficient in assuring system properties to an acceptable degree.

For those in the industry and regulatory roles, the advice is to: adopt formal methods, technologies, and principles known for effectiveness; create comprehensive dependability cases considering security; avoid over-reliance on processes and tests for dependability; insist on transparency and responsibility; and base certifications on scrutiny and analysis of dependability claims and their supporting evidence.

For the academic and educational community, the guidance is to: put more focus on dependability in software professional and researcher education; invest in basic research aimed at elevating the dependability of software-inclusive systems, with an emphasis on producing tangible evidence of dependability.