The second iteration of the Rewrite Engines Competition (REC) was hosted during the 7th Workshop on Rewriting Logic and its Applications (WRLA 2008), featuring five different systems: ASF+SDF, Maude, Stratego/XT, Termware, and Tom. This paper provides an overview of the competition's organization, methodology, and the primary outcomes and takeaways.

The inaugural REC aimed to gauge the feasibility and interest in such an event, spurring continued efforts due to the positive response. This subsequent edition included more participants and a broader array of challenges, focused on evaluating system efficiency in terms of speed, memory use, and built-in functionalities. ASF+SDF and Maude were the sole contestants in the initial competition, represented by Mark van den Brand and Steven Eker respectively, contributing to a suite of test examples tailored to each system's capabilities.

Discussing the best practices for the competition, the diverse nature of the entries—from compilers to interpreters, general-purpose to specialized systems—presented comparison difficulties. For instance, ASF+SDF excels at parsing, ASF+SDF along with Stratego and Tom are adept at program transformation, Maude specializes in rewriting modulo, Tom augments Java, and Termware is a rule-processing engine designed for Java incorporation.

The competition was structured around four categories of problems, ranging from unconditional to context-sensitive rewriting, and included timeless computational tasks such as calculating Fibonacci numbers and sorting algorithms, as well as more complex examples, like theorem provers and XML transformations.

In an innovative move, a simple rewriting language called REC was developed for the contest, aiming to equalize the starting point and assess the ability of systems to convert standard REC format problems into their respective syntaxes. However, not all participants managed to create such converters due to time constraints. The resulting translators from Maude, Stratego/XT, and Tom varied significantly in their implementation and did not allow for straightforward comparative analysis.

In the end, although a comprehensive evaluation of all results wasn't possible due to the varied nature of the systems, some performance observations were noted. Notably, Maude's optimizations allowed it to surpass other systems in specific benchmarks, while the Tom compiler demonstrated significant speed when dealing with automatically generated codes. Stratego/XT, however, faced certain issues in handling the tests.

Overall, while the competition illuminated some strengths and areas for improvement among the systems, further efforts are needed to more conclusively assess their capabilities across a wider range of tasks.