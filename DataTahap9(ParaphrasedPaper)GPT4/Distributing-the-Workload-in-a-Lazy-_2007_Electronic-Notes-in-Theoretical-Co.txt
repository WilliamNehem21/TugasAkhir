Automated theorem proving (ATP) plays a critical role in designing dependable software systems by automatically resolving proof obligations. Recently, advancements in the integration of Boolean satisfiability and decision procedures for decidable first-order logic theories, known as the lazy approach, have enhanced the efficiency of proving these obligations. This paper introduces the first documented effort to create a distributed variant of lazy theorem proving across a network of computers. This approach aims to utilize available processing power more effectively and prevent automated reasoning from becoming a bottleneck in formal method applications. Experimental results support the feasibility and advantages of this distributed method.

In tackling the verification of complex software, formal verification tools encounter significant challenges. Verifying whether a system meets a specific property often becomes the slowest step in any formal design process. A common strategy involves abstracting the system conservatively and checking if the property holds; if so, the original system also satisfies the property. If not, refinement is needed. The abstract model is adjusted to include more detail, and the property is rechecked. This loop of abstraction, checking, and refinement continues until an outcome is reached or resources are expended. Modern model checking tools exemplify this verification technique.

Developing a heterogeneous, distributed system is demanding in both design and implementation. The ToolBus provides an effective solution for building robust distributed systems. It employs a process algebra to define protocols between various components and uses a uniform data type called ATerms for communication and representing logic formulas. Key information is supplied for comprehending how the components of Harvey can be distributed and connected via the ToolBus.

In operation, a master tool (M) can issue new assignments for unsatisfiability checks by a slave first-order reasoning tool (S), which then begins the task upon initialization and alerts M. The slave tools conduct asynchronous verifications, with M being responsible for creating and distributing new assignments to previously connected slaves.

The distributed version of Harvey was implemented and tested on a small workstation network. The paper discusses two experiments: Firstly, various methods for selecting assignments are explored since this significantly influences the efficiency of verification by affecting how much the propositional formula is pruned. Secondly, the speed-up with the distributed Harvey relative to the number of slave tools is reported.

Several strategies were developed for choosing assignments within the propositional abstraction of a formula, particularly for Binary Decision Diagrams (BDDs), which distributed Harvey relies upon. Different approaches, including random, zigzag, and alternating traversal of the BDDs, were tested to see their impact on performance.

Results varied due to the asynchronous nature of the slave results, potentially causing the master to dispatch different assignments in subsequent iterations. Across repeated verifications, average values were reported to represent the variety of dispatched branches with different numbers of slaves and assignment strategies.

Notably, super-linear speedups were occasionally observed in experiments, particularly with the random approach, where a proof of unsatisfiability for an assignment could prune a substantial part of the search tree. These speedups are associated with formulas where the unsatisfiability is influenced by a small subset of atoms.

To facilitate communication and synchronization between tools, a protocol was developed, along with various workload distribution strategies. Experiments validated the distributed approach, demonstrating on average a meaningful speedup. Of the strategies investigated, the random assignment choice approach proved to be the most effective.