In this paper, the authors present a technique that integrates object segmentation with low-level features to create semantic primitives that provide a higher level description of video content. The method focuses on summarizing video shots by automatically extracting key frames that represent new events. It begins by designating the first frame of a shot as a key frame and then segments each subsequent frame to identify salient objects.

The approach includes both position- and shape-based criteria to eliminate irrelevant objects. By establishing many-to-many relationships between objects in the current and previous key frames, the system determines whether the frame signifies a new event. This process enables on-the-fly summarization of a shot, capturing relevant events as they occur. The method aims to preserve the essence of the shot with minimal data, even if the camera revisits previously seen areas.

The authors describe a proposed system for key frame extraction that relies on detecting shot boundaries and object-based events. By partitioning the input video into shots, key frames are selected on-the-fly, detecting significant events marked by the appearance or disappearance of salient objects. Employing a fuzzy coarse region segmentation technique, the first frame of a shot is processed for salient objects and becomes the initial key frame.

The system prioritizes recent key frames and only considers a frame as a key frame if it has new objects appearing or existing ones disappearing. This avoids redundancy by excluding temporary object appearances and occlusions from defining new events and helps identify repetitive events without analyzing too many frames. The object-based event detection process continues frame-by-frame until the shot ends, comparing each frame to both previous key frames in the current shot and those from prior shots.

The paper details this process and provides experimental results in Section 3 that validate the method's effectiveness using standard metrics.