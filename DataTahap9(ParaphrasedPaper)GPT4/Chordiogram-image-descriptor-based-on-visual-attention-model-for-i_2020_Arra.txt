This study introduces a novel shape-based approach to image retrieval that separates an image's foreground and background to minimize their mutual influence on feature representation. The Otsu method is used for segmentation, with the saliency map and edge map then clearly defined for both the foreground and background. Salient edges are identified using a selective visual attention model, which speeds up feature computation. A new image descriptor, an autocorrelation-based chordiogram, is computed for both the foreground and background and combined hierarchically, resulting in a descriptor rich in geometric texture, structure, and spatial information. Compared to conventional methods, this novel descriptor shows superior performance in content-based image retrieval as evidenced by extensive testing on various image datasets, where it achieved satisfactory precision and recall values.

The study distinguishes between global approaches, which are efficient but lack local spatial information, and local approaches, which provide detailed feature computation and overcome the limitations of global methods. Shape is a key component of image recognition and matching, and this work builds upon prior shape-based methods. The proposed algorithm is robust, considering more salient edges to capture rich textual and structural information, with enhanced accuracy validated across several image databases compared to state-of-art methods that often fail to capture relevant features. Although the proposed method is computationally more intensive, its increased retrieval accuracy justifies the higher cost. Future research may explore weighting contour-based details during feature matching to further improve performance.