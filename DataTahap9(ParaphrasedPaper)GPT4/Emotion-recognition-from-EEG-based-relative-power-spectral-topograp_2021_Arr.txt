This study discusses the use of different stimuli in emotion research, highlighting the effectiveness of movie clips, which combine audio and visual elements, over other forms like music or verbal commands. The experiment uses Chinese movie clips, appropriate for the native Chinese participants, and categorizes them into positive, negative, and neutral emotions, with each clip lasting four minutes.

The study introduces a Convolutional Neural Network (CNN) for emotion classification based on Electroencephalography (EEG) signals. A CNN is a machine learning model that learns to classify data, such as images or videos, by automatically optimizing the weight parameters to reduce classification error. This model includes an input layer, multiple hidden layers, and an output layer. The CNN described uses batch normalization between the convolutional layer and the ReLU (Rectified Linear Unit) activation function to improve training speed and reduce initialization sensitivity. The ReLU activation is favored due to its computational efficiency.

EEG data corresponding to the three emotional states (positive, negative, and neutral) from participants were used as input for the CNN. Participants provided 15 trials for each emotional state. The CNN structure was optimized through trial and error, and performance was assessed using MATLAB. The process includes two sets of convolutional, batch normalization, ReLU, and pooling layers.

The CNN achieved high classification accuracies when compared with other methods applied to a reference dataset known as SEED. Utilizing 25% of the data for training and 75% for testing, the CNN reached accuracies of approximately 89.056% (±4.32), and with a 50-50 data split for training and testing, accuracies rose to about 94.63% (±3.68). These results suggest that the proposed CNN model could be effectively applied to other types of EEG signal classification in future research.