This paper presents a new algorithm for detecting moving objects in video using sparse representation and an adaptive dictionary. The process begins by compressing the image to lessen data redundancy and required bandwidth. An initial dictionary is created with compressed sensing (CS) measurements and sparse basis elements, which is subsequently refined using the K-SVD algorithm to achieve the sparsest representation possible. The approach also accounts for the similarity between dictionary elements to further reduce redundancy. Whether an object has entered the scene is determined using selective reconstruction based on sparse coefficients, lowering the computational load for real-time applications. The moving object is separated from the background using robust Principal Component Pursuit (PCP), which exploits the fact that video frames typically consist of a static, low-rank background and a sparse, dynamic foreground. Testing the method demonstrated that it can significantly reduce data redundancy and bandwidth requirements while maintaining effective detection performance. The paper provides a detailed experimental setup, using 100 frames formed as a matrix to build the background model and describing training sample size, compression rates, and the number of training iterations for the initial dictionary.