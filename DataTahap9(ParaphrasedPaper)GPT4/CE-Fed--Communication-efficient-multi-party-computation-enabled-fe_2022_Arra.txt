The academic paper discusses the development of a novel federated learning framework named "CE-Fed," which provides a mechanism for multiple parties to collaboratively train machine learning models without revealing their private datasets. Although federated learning safeguards raw data, there still exists a risk of extracting sensitive information from the communal models. To mitigate this, Secure Multi-Party Computation (MPC) is used to safely aggregate locally-trained models. The drawback of this approach is that it entails significant communication overhead and scalability challenges in decentralized systems.

The paper's authors propose CE-Fed, which uses a hierarchical approach to reduce communication costs by forming a Model Aggregation Committee from a smaller subset of participants. They only share model updates within this committee rather than with all participants, which enhances scalability and communication efficiency. By grouping clients that are geographically close and electing leaders to form the core committee, CE-Fed efficiently aggregates local models into a global one, preserving privacy without sacrificing accuracy or scalability.

Experiments carried out using the CE-Fed prototype on MNIST, CIFAR-10, and Fashion-MNIST datasets demonstrate the efficacy of the framework. Despite reducing the communication overhead, CE-Fed achieves comparable accuracy to centralized learning and significantly outperforms local training models. Therefore, CE-Fed strikes a balance between high model accuracy and communication efficiency while maintaining privacy.

The paper also includes background information and related work on federated learning and secure MPC, as well as a detailed description and performance evaluation of the CE-Fed framework. The authors, Renuga Kanagavelu, Qingsong Wei, and Zengxiang Li, bring together expertise from academia and industry to advance the field of privacy-preserving machine learning models and decentralized training solutions.