Xia, Pan, and Qin (2014) developed a technique for organizing photos in a photo album by clustering faces using spectral and similarity features, combining it with minimum cost flow and clustering. This method was designed to group images containing identical individuals, particularly useful for personal photo collections but less so for differentiating between family and non-family images.

Qin, Tan, and Chen (2015) introduced a kinship verification process that examines the triangular relationship among parents and their child. They utilized a relative symmetric bilinear model to assess similarities and included spatial information to boost accuracy, though the method’s effectiveness is dependent on the success of the recognition process.

Robinson et al. (2018) focused on identifying familial relationships through visual kinship recognition using advanced deep learning techniques, including face verification, clustering, and enhanced baseline measures. Their approach utilized multimodal labeling to refine the annotation of family photographs, albeit it wasn’t designed to handle non-family photos.

Wang et al. (2015, 2017) suggested identifying family photos by leveraging geometric and appearance cues, which differentiate between pictures by identifying facial points and constructing polygons to study geometric features. The technique involves kinship estimation and uses k-means clustering to form a codebook for differentiating family from non-family images using SVM classification. Nonetheless, the method could fail when people's heights don’t follow a family hierarchy or when non-family members resemble a family-like arrangement.

The discussion highlighted that while several approaches tackle kinship verification using facial analysis, they may struggle with images containing diverse emotions, poses, and activities. Previous family and non-family classification methods predominantly relied on facial information, which may not suffice in complex backgrounds with open scenes typical in non-family photos. Therefore, the paper calls for an innovative method to classify family and non-family photos accurately.

The paper introduced a new approach that combines spatial features and angles to capture the geometric structure of facial regions, along with fractional entropy to extract texture details of both facial and background regions. These features form a vector passed through a Convolutional Neural Network (CNN) to address the complexities described above.

The key contributions of this work include the pioneering exploration of spatial and angle features to ascertain spatial and directional coherence, and the novel use of fractional entropy for texture analysis. The methodology scales features such as distances and angles between facial points to maximize the distinction between family and non-family images, acknowledging that family photos tend to display higher facial similarity.

Incorporating a background textures analysis using Tsallis fractional entropy addresses previous methods' shortcomings. An online CNN classifier was used for classification supported by 10-fold cross-validation.

Comparative experiments showed superiority to two state-of-the-art methods, confirming the effectiveness of combining spatial, angle, and fractional entropy features for this classification task. However, limitations exist when images share similar structures or textures regardless of the family or non-family context.

In summary, the paper proposes a cutting-edge method for classifying family and non-family photos using new geometric and texture features, acknowledging limitations and areas for future enhancement. Moreover, it emphasizes the role of both facial and background analysis in achieving accurate classification outcomes.