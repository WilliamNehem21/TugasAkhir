The emergence of Intel's asymmetric performance multicore products is anticipated to expand the application of AMPs (Asymmetric Multiprocessor Systems) in various domains. Understanding their performance characteristics is crucial for software development and optimization. In this paper, the authors refer to the high-performance cores as P-cores and the energy-efficient cores as E-cores.

The authors discuss how superlinear speedup, a scenario where the addition of computing resources leads to disproportionately large improvements in performance, can occur in situations with large problem sizes. They explain this using the concept of memory-bounded speedup, noting that when a problem is distributed across more nodes, not only is the computation spread out, but so is the associated memory use, which can alleviate memory bottlenecks and boost speed beyond linear expectations. The paper questions if similar superlinear speedup events could occur for compute-bounded workloads.

The research introduces a heterogeneity model that can effectively capture superlinear speedups but may not handle sublinear speedup cases as well. Sublinear speedups occur when increases in computing resources lead to less than proportional performance improvements and can happen when baseline performance is measured using the fastest CPU alone.

The paper contends that existing laws that describe speedup do not accurately reflect the performance of AMPs. It suggests that superlinear speedup may be observed when code previously run on slower cores benefits from additional faster cores, whereas sublinear speedup may arise when the fastest CPU determines serial execution time.

The authors point out that work-stealing has been proposed as a solution to unfair workload distribution in dynamic heterogeneous distributed systems, but its implementation in shared memory systems like AMPs has not been thoroughly investigated. This could be a promising area for performance optimization because work-stealing in shared memory systems does not incur the same communication overheads as in distributed systems.

Previous research has shown that heterogeneous multicore processors perform better on multithreaded workloads than homogenous cores, as determined by weighted speedup metrics. However, this paper focuses on fair work distribution among the E-cores and P-cores in a multi-threaded environment, arguing for a performance-based distribution where faster cores handle more parallel workload.

At the operating system level, threads are ensured fair CPU time, but user-level mechanisms are needed for efficient multicore utilization. The paper stresses the requirement for user-level load balancing to improve the performance of multithreaded applications, such as employing a work-stealing mechanism.

The paper presents performance evaluation results for an experiment conducted on an Intel Core i5 1240P processor, which features an asymmetric multicore architecture, combining P-cores (based on Golden Cove microarchitecture) with E-cores (based on Gracemont microarchitecture). The study explores different scenarios of thread assignment to either E-cores or P-cores first to analyze scalability differences.

Utilizing the Linux CPU affinity library, the benchmarks set up different CPU assignment strategies and measure performance. A Python script is used for data collection and to set environment variables controlling the number of worker threads.

In conclusion, the paper presents evidence that the work-stealing strategy is effective in AMPs. Results suggest that work-stealing prevents performance drops associated with asymmetric workload distribution and does not cause a reduction in nominal Instructions Per Cycle (IPC) on P-cores, showing that the Intel Core i5 1240P manages its asymmetric performance efficiently.