The rest of this paper is organized in the following way: Section 2 reviews prior research and pertinent background information. Section 3 outlines our research method and experimental setup. Section 4 discusses our findings regarding timing of platform-independent instructions, while Section 5 contrasts these findings with those obtained by using the RDTSC assembly instruction. The paper concludes with Section 6, summarizing our work and suggesting future research directions.

We have utilized standard statistical methods to model the quantization effect, allowing for precise timing measurement despite the use of low-resolution clocks. Lilja demonstrated the utilization of Bernoulli trials for precise timing, Beilner modeled event timing, and Danzig and colleagues devised a hardware micro-timer for timing code execution on Sun workstations.

However, there's limited research concerning bytecode timing. Herder et al. reported on timing Java bytecode without detailing their methodology, and Wong et al. developed a bytecode timing measurement method that relies on native methods and is not platform-independent.

Peuto and others, along with companies like Intel and IBM, have worked towards creating models for timing machine-level instruction execution.

Albert and colleagues proposed a Java bytecode cost analysis framework involving the transformation of bytecode structures and the inference of cost relationships. This was subsequently applied to Java programs with various operations.

Stark et al. suggested dividing the JVM into distinct sub-machines, each capable of executing certain instruction sets. We adopt a similar approach, focusing on the JVM's core instruction set to better understand Java application-JVM interactions. Specifically, we look at timing for the 137 imperative JVM instructions.

Our method stays platform-independent by using standard Java timing methods, particularly System.currentTimeMillis, due to its precision and accuracy, as System.nanoTime doesn't ensure exact nanosecond precision. Java timing classes were created using the Bytecode Engineering Library (BCEL).

Our experiments were conducted on a Rocks Linux cluster of 100 nodes, each with a 1.13GHz Intel Pentium III dual-core processor, 1GB RAM, and 512KB cache, operating on CentOS and the Sun Java Runtime Environment.

We performed cluster analysis to identify instruction groups with similar timings to simplify timing models. A trade-off exists between the granularity of grouping and the accuracy of instruction timings.

We have developed a platform-independent technique for timing Java bytecode instructions, taking into account timer overhead. We've categorized imperative instruction execution times, clustered instructions based on these times, and compared our method with RDTSC timing. We estimate Java instruction execution times statistically, highlighting a subset of instructions with significantly slower execution times. Our clustering technique allows grouping within a set granularity level, and we've found a strong positive correlation between our timing results and those from RDTSC timings, despite a tendency to underestimate execution times by about 23%.

Future work involves assessing the impact of processor pipelines and cache miss rates on instruction timings, performing experiments across various platforms and JVMs, and incorporating our findings into extended JVM instruction timing models and application execution time predictions.