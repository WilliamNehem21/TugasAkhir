Advancements in information technology necessitate accessible document resources to enable theme discovery and information retrieval. Text clustering technology has thus emerged, offering a crucial component of natural language processing and has achieved significant success in the grouping of documents. Challenges in text clustering include dealing with synonyms, near-synonyms, and other language-specific nuances. This paper investigates the use of Latent Semantic Indexing (LSI) to address these linguistic challenges and enhance document clustering performance.

The study utilizes a dataset named TANCORPV 1.0 from the Chinese Academy of Sciences, contributed by Dr. Tan Songbo, along with a text classification corpus from Sogou Lab. For the experiments, 12 categories comprising 2,400 texts were selected from TANCORPV 1.0, followed by a subsample of 1,000 texts across 9 categories from the Sogou Lab corpus. The dataset is referred to as the Chinese Academy of Science Corpus 1, where text sizes range from 1KB to 14.7KB. Additionally, 3,000 texts spanning 60 smaller categories were selected as the Chinese Academy of Science Corpus 2.

This research posits that the transfer number of features in LSI significantly impacts its performance. Higher transfer numbers may introduce erroneous feature co-occurrence data, which can distort feature similarity and, consequently, the effectiveness of LSI. To mitigate this issue, the paper suggests a pre-processing step using Document Frequency (DF) for feature selection, aiming to limit the feature transfer number and thus reduce spurious co-occurrences. The DF method filters features across the document collection based on their distribution frequency. Future studies will focus on feature selection methods leveraging conditional entropy to improve the relationship between features.