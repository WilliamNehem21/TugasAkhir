This academic paper discusses the application of deep learning, specifically deep neural networks (DNNs), to geophysical problems such as the inversion of dispersion curves and full waveform inversion (FWI). The authors point out the limitations of conventional methods in capturing energy information from Rayleigh waves, which is strongly dependent on underground stratigraphy.

The paper mentions that the velocity of Rayleigh waves is primarily influenced by the shear wave velocity and layer thickness in the subsurface. Modal analysis of Rayleigh waves may encounter complications as higher modes may interfere with the fundamental mode. Ideally, the inversion or prediction algorithm would utilize the entire frequency-wave number (f-k) or frequency-velocity-phase (fvph) gather rather than just selecting dispersion curves, which is what FWI aims to do. However, FWI is challenging and computationally expensive, particularly with elastic FWI for noisy land seismic data.

As such, the authors explore whether deep neural networks could provide a solution between traditional dispersion curve inversion and FWI. Deep learning is effective when there is a large amount of supervised data, but it can struggle with small datasets. Here, transfer learning is presented as an approach to utilize knowledge from one domain (like image classification with ImageNet) and apply it to another (geophysical data analysis).

The authors employ data augmentation techniques, such as random cropping and rotations, to artificially enlarge the training dataset and improve the model's generalization capabilities. These techniques simulate different scenarios that the model might encounter, helping it to avoid overfitting to specific patterns in the seismic data.

Moreover, the paper addresses difficulties models have generalizing to data outside their training distribution, a problem that's particularly acute in geophysical applications where it isn't feasible to cover all potential variations of input data. The authors introduce architectural modifications, like providing bounding information about the ranges of P-wave (vp) and S-wave (vs) velocities, to improve the network's ability to map trends and predict accurately even when faced with out-of-distribution samples.

The underlying architecture for the neural network is based on a modified ResNet18, with additional components to encode prior knowledge about vp and vs ranges. This knowledge is represented in two separate meta-architectures, each consisting of a linear layer, a batch normalization layer, and a ReLU activation. These are then concatenated with the output from the main CNN architecture and passed to final layers for predicting vp and vs.

The paper details how the network is trained and used for domain adaptation, where perturbations and shifts are included during training to make the model robust to variations during inference. The performance of the constrained network (with bounds on vp and vs) is compared to that of an unconstrained network, showing improved agreement with actual subsurface velocities measured by uphole tests.