Title: Enhancing Learning in Program Visualization with Automated Question Generation

Abstract:
Prior studies indicate that student engagement through interactive activities is more crucial than the specific content presented in visualizations for effective learning. Prediction-oriented questions have proven to engage students with visualizations, thereby aiding their learning process. Capitalizing on this, we propose the integration of automatic question generation into the program visualization tool Jeliot 3. This paper details the methodology for embedding question generation into Jeliot 3's existing framework and presents examples of potential questions derived from visualization data. We also discuss possible future implementations and research directions.

Introduction:
Studies by Hundhausen and others suggest that student participation and interaction within educational visualizations are more influential for learning than the visualization content itself. This research investigates engagement levels, their classification (engagement taxonomy), and the impact on learning associated with algorithm and program visualizations. Engaging students through prediction questions (responding level 3) enhances their educational experience and problem-solving skills. Based on these findings, we recommend implementing an automatic question generator in Jeliot 3 to further improve these outcomes.

Jeliot 3 Overview:
Jeliot 3 is a visualization system for Java program execution, aimed to facilitate introductory programming education. It illustrates both data and control flows and has proven particularly beneficial for average performers, without negatively impacting other learners. With the inclusion of automatic question generation, the tool could allow for customization based on specific variables or conceptual areas within a program, tailoring the educational experience to the student's performance, similar to other systems like Problets and Wadein.

Related Work:
Problets generate exercises from templates that are independent of programming language, focusing on specific concepts such as loops and pointers. In contrast, Jeliot 3's questions can be tied to both code and visualization, offering a broader range of question types and accommodating dynamic execution aspects through user input. While Problets support multiple languages, Jeliot 3 currently supports only Java but could expand to others with additional interpreters. Similarly, Wadein II focuses on expression evaluation in C, with tasks centered on simulating this process.

Future Directions:
Further research will focus on implementing the proposed question types and assessing their usability. We aim to explore the impact of question answering on both individual and collaborative learning environments for programming education. By varying levels of engagement, we can evaluate their effect on learning outcomes and collaboration. Additionally, different question formats, such as those related to data flow, control flow, or a combination, will be tested for their educational benefits. Lastly, we plan to incorporate these features into distance education, using them as part of a comprehensive assessment.

Conclusion:
The research underscores the importance of interactive engagement in educational visualizations and posits that automatic question generation can significantly enhance the learning of programming concepts through tools like Jeliot 3. Pending further development and study, this could represent a major advancement in computer science education both in classroom settings and online platforms.