The paper presents a software approach for identifying suitable landing zones for small UAVs using a single onboard camera and machine learning algorithms. A two-phase processing strategy is introduced. The first phase employs a method based on textural similarity to pinpoint potential landing sites. In the second phase, these candidates are further refined and assessed through machine learning algorithms, providing the UAV with emergency landing options. The software framework is designed to be flexible, permitting the integration of custom algorithms for improved results. This approach has demonstrated potential utility and efficiency.

Previous research on vision-based autonomous landing site selection has focused on systems using single onboard cameras, employing three primary strategies. The first method is not detailed in the paraphrasing. The second method calculates a potential landing zone by analyzing geographic features of the terrain using a mathematical model that maps the real-world terrain to the image plane, based on two separate images of the same area. The third involves classifying terrain based on textural features and uses optical flow to compute depth information, distinguishing safe and unsafe areas and identifying potential hazards.

The processing begins by quickly locating all potential landing areas in the initial image(s), a necessary step due to the time-consuming nature of running elaborate algorithms on entire images. It then proceeds to evaluate and rank these potential sites based on their suitability as landing zones.

The implementation is described as follows: a point is randomly selected in the image; a square is generated around this point at a predefined size; the textural features within the square are calculated; the square is enlarged and features recalculated; the similarity of feature sets is determined; if similarity exceeds a certain threshold, the process repeats with the larger square; otherwise, the last square is taken as the result.

The software is implemented using OpenCV and C language on a Mac Pro laptop, processing video at 40 frames per second and making determinations after four effective frames. However, landing area detection isn't guaranteed, as the classifier might reject all candidates, yielding no output.

The paper details the autonomous landing area identification system for a camera-equipped UAV, discussing the concept, principles, procedures, and implementation. The scheme must handle various machine learning algorithms cohesively. Although a na√Øve Bayes classifier was initially used to identify landing areas, other approaches, such as fuzzy logic or artificial neural networks, might also be effective.