The paper discusses challenges in machine learning, particularly in the field of neural networks (NNs), and presents a novel technique to improve the performance of supervised NNs when applied to real-world data. While NNs trained on synthetic data often underperform on real data due to differences in data distribution, NNs trained on real data are limited by the accuracy of human or algorithmically generated labels. To address these limitations, the paper recommends creating synthetic data that is as realistic as possible for NN training.

The process of adapting a model trained on one data domain (source) to perform well on another (target) is known as domain adaptation. The paper describes a need for domain adaptation techniques that project the source and target data onto a common space, aligning their distributions. This alignment uses neural network embeddings to minimize the distance between these distributions, employing techniques such as optimal transport and cycle generative adversarial networks (GANs).

The paper proposes a method tailored for waveform data, such as seismic or ultrasound data, which often presents high-dimensional challenges. The authors focus on supervised learning where the vertical axis of the input data is considered non-essential in absolute terms, only in the relative relationship between events. The method assumes no labels for the target (real) data, making transfer learning inapplicable. Instead, unsupervised machine learning techniques for domain adaptation are proposed, relying on the assumption that synthetic data generation faithfully represents the true physical behavior of the application object.

The domain adaptation technique includes preprocessing steps, such as cross-correlation with a reference trace and convolution with autocorrelated noise, to align the synthetic and real data sets' signal-to-noise ratios (SNRs). These steps are summarized in two algorithms to be applied during training and inference stages, with transformations efficiently performed in the Fourier domain. The network is initialized and ensemble averaging is used to reduce output noise.

The approach was tested on a microseismic source identification problem, using a training dataset of shot gathers derived from random subsurface models. The cross-correlation step not only balances contributions from synthetic and real data but also introduces new features that enhance the training data set, aiding the NN to identify correct labels.

In conclusion, the paper presents a preconditioning technique that incorporates features from real data into the synthetic training set without compromising its predictive features, improving the NN's performance on real-world data. The work was supported by discussions with various academics and data provided by MicroSeismic Inc., Newfield Exploration Mid-Continent Inc., and CGG, with additional support from KAUST and the Seismic Wave Analysis Group (SWAG).