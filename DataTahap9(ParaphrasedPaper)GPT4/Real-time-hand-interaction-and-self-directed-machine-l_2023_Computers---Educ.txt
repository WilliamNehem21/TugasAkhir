The integration of Extended Reality (XR) in education is increasingly popular for creating immersive learning environments, especially in science and engineering. Immersive learning, facilitated by powerful XR interactions and advancements in artificial intelligence, is promoting interactive and self-directed education. This paper introduces a new method that employs machine learning agents to enable interactive, kinesthetic learning with real-time hand interactions within virtual worlds. Specifically, the study utilizes a chemistry case example, with usability evaluations from 15 experts and 2 subject specialists, leveraging the NASA Task Load Index for cognitive load assessment and the Technology Acceptance Model to gauge perceived usability and utility.

Expert reviewers indicated that self-directed learning through trained agents could enhance technical skill acquisition. Additionally, controller-free hand interactions have shown to boost motivation for hands-on learning in virtual labs, suggesting a promising new research direction where machine-learning-enhanced agents can serve dual roles as instructors and evaluators.

Various studies have highlighted XR's potential in providing rich, interactive learning experiences in STEM education, allowing learners to encounter real-world phenomena in safe and regulated settings. Nonetheless, there is further potential to explore XR technologies in under-resourced and remote learning environments and to advance the integration of intelligent agents for more autonomous and supportive personal learning experiences. This research addresses the gap in utilizing real-time hand interactions for kinesthetic learning and autonomous learning in immersive environments.

Evaluations are critical when introducing new technologies to ensure they align with learning objectives and provide positive user experiences. This study's evaluations focused on the learning goal of understanding basic chemical reactions, considering learning gain, cognitive load, and user confidence. The results support the notion that machine learning can facilitate self-directed learning in immersive environments, with users experiencing low cognitive workloads, enabling better task performance and problem-solving.

The integration of AI or machine learning agents in immersive learning can create personalized and captivating learning environments. Despite ethical and data privacy concerns and the balance needed between automation and human interaction, AI agents could serve as virtual mentors in immersive learning environments, enhancing the learning process by guiding, correcting, and providing expert advice.

Limitations of this research include the need for extensive end-user testing and comparisons with traditional learning approaches, hinting at future studies involving actual students and considering design, ethical, and privacy issues.

In conclusion, XR technologies offer exciting prospects in STEM education as pedagogical tools. This study sheds light on the possibility of scaling effective XR learning implementations and highlights the potential of machine learning agents as interactive guides in immersive learning. Future work may incorporate multi-sensory haptic technologies for enhanced realism, aligned with developments in robotics where trained agents execute actions based on virtual training. This innovative pedagogical strategy could redefine immersive learning, with virtual agents becoming educators and assessors in various disciplines beyond the STEM focus of the current paper.