The pure untyped lambda calculus is a fundamental part of computer science education. It is often included in various courses such as computability, where it is presented as a classic model for computation; in semantics, as a basis for denotational semantics; in functional programming, as the quintessential simple functional language; and in programming language theory to show the power of a minimalistic, universal language capable of encoding arithmetic, data structures, and recursive functions using techniques like these:

A free variable acts similarly to a data constructor, as seen in languages like Standard ML or Haskell, which can be seen as an uninterpreted function symbol. When a free variable appears as a function (for example, x e2), the argument expression e2 should be reduced in a call-by-value context but not in a call-by-name context. This reflects the behavior of constructors in strict languages like ML (strict) and non-strict languages like Haskell (non-strict).

To trace the reduction process in lambda calculus, the reduction functions are tweaked to include an additional context argument and employ an extended substitution function that applies the context to the redex before reduction. Specifically taking the call-by-name reduction as an example, the reduction function accumulates the context as it delves into the term by combining the context with an appropriate constructor.

For research purposes, being able to perform lambda calculus reductions one step at a time is advantageous. This can be achieved in the metalinguistic setting provided by Standard ML using side effects. This involves using a context function to count the number of reductions and setting a step limit before beginning the evaluation. Once the limit is reached, the process raises an exception, which is then handled to output the result thus far. Subsequent reduction function invocations increase the step limit to simulate step-by-step reduction.

The paper outlines a straightforward method to demonstrate lambda calculus reductions, describing various reduction strategies through big-step operational semantics, implementing reductions with basic functions in Standard ML, and augmenting the process with contexts to produce a reduction trace. The methodology can be adapted to other reduction strategies that are defined in big-step operational semantics. Extending this approach to lazy evaluation, whether through graph reduction or with an explicit heap, is primarily complicated by the need to visualize the evolving graph or heap state.