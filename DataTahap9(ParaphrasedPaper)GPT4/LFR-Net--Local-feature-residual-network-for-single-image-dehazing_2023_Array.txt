Prior research in image dehazing using learning-based methods focused largely on training their dehazing networks with only clear images and overlooked the potential use of additional data like hazy images, transmission maps, and atmospheric light information available in training datasets. In response, we present a novel Local Feature Residual Network (LFR-Net) designed to enhance the quality of dehazed images by leveraging all available information in the training set. The LFR-Net architecture is founded on a feature residual block and an adaptive feature fusion model. Moreover, to retain more image detail, we crafted an adaptive feature fusion model that intelligently blends shallow and deep feature layers within the encoder-decoder structure of the network. Comprehensive tests demonstrate that LFR-Net achieves superior results when compared to current top-performing methods.

Existing datasets for dehazing not only contain hazy images and their clear counterparts but also provide transmission maps and atmospheric light data. While prior methods endeavored to boost dehazing network performance by adding more layers, thereby requiring greater computational resources, these methods did not exploit transmission maps and atmospheric light values during the training process.

Most current dehazing techniques feature an encoder-decoder setup where the encoder extracts key image characteristics, and the decoder reconstructs a clear image. However, standard encoders typically have shallow layers for each scale, extracting only surface-level features and thus losing finer details in the restored image. For example, the GFN encoder fails to extract in-depth features across all scales, leading to lost details in dehazing results.

This paper is structured as follows: Section 2 reviews related work in image dehazing. Section 3 thoroughly describes our proposed approach and its components. Section 4 provides experimental comparisons of LFR-Net with state-of-the-art methods and includes ablation studies. Section 5 concludes the paper and offers directions for future research.

The LFR-Net employs two types of feature blocks, "double-conv" and "FR block," containing shallow and deep features, respectively. Regular skip connections in the network would typically cause the loss of shallow features from the encoder in the resulting dehazed image. To address this, we introduce an adaptive feature fusion module that merges feature maps from both types of blocks adaptively, preserving shallow feature details and enhancing the network's overall capability.

Concerning loss functions, LFR-Net utilizes a combination of L1 loss, perceptual loss, and a novel haze loss. Both L1 and perceptual loss have shown efficacy in image restoration tasks, hence their selection for LFR-Net optimizations. Furthermore, haze loss is designed to incorporate the hazy input image, medium transmission maps, and atmospheric light values into the training process, using the networkâ€™s output and these elements to construct an image that guides further optimization of network parameters.

We evaluated the dehazing capabilities of LFR-Net through a series of experiments, comparing it against seven top methods to validate the proposed approach. Additionally, ablation studies were conducted to confirm the effectiveness of LFR-Net's architecture. These studies consisted of sequential integration of different network modules using the U-Net with L1 and perceptual loss as the baseline.

This study introduced the Local Feature Residual Network for single image dehazing, utilizing a full breadth of available information in the training dataset. The network architecture was designed to increase the depth of feature extraction and preserve more image detail through an inventive feature fusion model and a carefully chosen loss function inclusive of haze-specific losses. Extensive experiments verified the advantages of LFR-Net both qualitatively and quantitatively, and ablation studies highlighted the structural benefits of the network. Recognizing the limitations of learning-based methods that rely on synthetic datasets when applied to real-world images, we propose future work to explore unsupervised learning approaches in image dehazing.
