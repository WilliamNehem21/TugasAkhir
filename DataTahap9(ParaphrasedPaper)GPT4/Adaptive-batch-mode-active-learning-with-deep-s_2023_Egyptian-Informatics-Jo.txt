Due to the difficulty of obtaining supervised data, many active learning algorithms have been developed to identify the most significant data from an unlabeled pool. These algorithms generally select one example at a time for the oracle to label, repeating the process until a set accuracy or labeling budget is reached. With limited labeling budgets, the strategy used to choose instances is critical, with diversity being a key consideration alongside informativeness to prevent wasting efforts on labeling homogenous data.

This paper introduces a novel batch mode active learning algorithm designed to improve classifier performance when labeled data are scarce and expensive. The challenges include establishing a better measure for instance similarity and a strategy to select informative and diverse instances. The proposed adaptive batch mode active learning (BMAL) method uses deep neural networks for learning these similarities and balancing exploration (gaining new information) and exploitation (reducing redundancy).

A convolutional neural network (CNN) classifies instances, and the second-to-last layer provides the representations for instance features. To enhance training model accuracy and similarity measurement, these features are mapped to a new space, an approach not previously explored.

The new active learning algorithm aims to reduce manual annotation workload and maintain network accuracy. Diverse techniques and frameworks from previous research have been incorporated. The CNN used effectively trains on small datasets, even facing challenges like overfitting. The training process adjusts to reduce redundancy and balance exploration and exploitation strategically, with the algorithm evolving as the labeled dataset grows. These strategies are rigorously compared with baseline methods.

The authors evaluate their framework using the MNIST dataset, choosing a well-established seven-layer neural network for classification. The results suggest that the proposed method outperforms previous algorithms by leveraging deep neural networks for feature extraction and similarity assessment, ultimately enhancing the diversity of the actively selected data pool.