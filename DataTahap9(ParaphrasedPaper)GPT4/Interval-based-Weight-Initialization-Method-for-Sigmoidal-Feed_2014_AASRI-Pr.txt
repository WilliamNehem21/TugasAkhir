The paper discusses the significance of initial weight selection in the training of sigmoidal feedforward artificial neural networks, where weights are typically initialized with small random values within the same range. The paper suggests a new weight initialization method where weights connecting the input layer to the hidden layer are randomly assigned from distinct intervals for each hidden node. The training is conducted using the resilient backpropagation algorithm.

For the training, 200 input data sets are created via uniform random sampling from the input domain of the target function and the respective outputs are computed to form the training set. To assess the network's generalization, a test set with 1000 data points is generated.

The proposed weight initialization method showed that the networks achieved lower error rates on unseen data, pointing to improved generalization. This is confirmed by the generalization experiments, where the ratio of the best error results from conventional random initialization to the proposed method ranged from 1.08 to 2.71 across various tasks, indicating the proposed method roughly halves the error on average.

The paper proposes a specific distribution strategy for the initial weights and thresholds from input to hidden layers in sigmoidal feedforward artificial neural networks, asserting that the proposed method enables networks to reach deeper error function minima, generalize more effectively, and train more rapidly, as demonstrated in six function approximation tasks.