This paper introduces a novel algorithm designed to enhance unsupervised learning through the optimization of finite mixture models (FMM). This algorithm stands out by aiming to diminish the mutual information among the components of the FMM while maintaining a high likelihood of accurately fitting the input data. The approach is beneficial for data that are either sparsely distributed or generated from overlapping clusters. A comparative analysis with existing algorithms, such as MI, MML, and BIC, demonstrates the superior performance of the proposed approach in clustering input data and determining the appropriate number of FMM components.

The paper is laid out as follows: Section 2 introduces the new algorithm that combines unsupervised learning with FMM optimization, specifically for challenging data sets. Section 3 compares this new algorithm to others based on clustering outcomes and the determination of FMM components. Section 4 presents conclusions and the criteria for algorithm selection, emphasizing that the new TUMI algorithm is robust against changes in the number of data features and excels at handling sparse data sets. Additionally, the paper explores how mutual information theory is adjusted within the TUMI algorithm to better fit data sets with overlapping clusters.

The concept of mutual information is employed as a measure of the quality of clustering results by comparing them to the actual classifications of the data set. The Normalized Mutual Information (NMI) indicator reaches its maximum when clustering perfectly matches the true data classes, serving as an unbiased metric for assessing varying clustering outcomes.

The paper argues that the proposed algorithm performs better than the MI algorithm for various data sets, primarily because it selectively removes mixture components that minimally impact the overall model fit, in contrast to the MI algorithm's method of deleting the component with the highest mutual information. Additionally, the new algorithm can more accurately estimate the number of mixture components, particularly in data sets constituted by partially overlapping clusters, unlike the MI algorithm which tends to underestimate in such scenarios. The findings suggest that although computationally less efficient, the proposed algorithm offers significant accuracy gains, making it a preferable choice in practice.