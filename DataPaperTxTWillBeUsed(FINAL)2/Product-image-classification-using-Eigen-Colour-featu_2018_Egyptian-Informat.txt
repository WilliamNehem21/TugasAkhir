Egyptian Informatics Journal 19 (2018) 83–100








Full length article
Product image classification using Eigen Colour feature with ensemble machine learning
S.A. Oyewole, O.O. Olugbara ⇑
ICT and Society Research Group, Durban University of Technology, P.O. Box 1334, Durban 4000, South Africa



a r t i c l e  i n f o 

Article history:
Received 11 September 2016
Revised 30 June 2017
Accepted 23 October 2017
Available online 1 November 2017

Keywords:
E-commerce Eigenvector Ensemble Neural network
Recommendation Support vector
a b s t r a c t 

The plethora of e-commerce products within the last few years has become a serious challenge for shop- pers when searching for relevant product information. This has consequently led to the emergence of a recommendation assistant technology that has the capability to discover relevant shopping products that meet the preferences of a user. Classification is a machine learning technique that could assist in creating dynamic user profiles, increase scalability and ultimately improve recommendation accuracy. However, heterogeneity, limited content analysis and high dimensionality of available e-commerce datasets make product classification a difficult problem. In this present study, we propose an enhanced product image classification architecture which has data acquisition pre-processing, feature extraction, dimensionality reduction and ensemble of machine learning methods as components. Core amongst these components is the Eigenvector based fusion algorithm that is meant to obtain dimensionality reduced Eigen Colour feature from the histogram of oriented gradient based colour image representative features. The ensem- bles of Artificial neural network and Support vector machine were trained with the Eigen Colour feature to classify product images acquired from the PI100 corpus into 100 classes and their classification accu- racies were compared. We have obtained a state-of-the-art classification accuracy of 87.2% with the arti- ficial neural network ensemble which is an impressive result when compared to existing results reported by other authors who have utilised the PI100 corpus.
© 2017 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo
University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/
licenses/by-nc-nd/4.0/).





Introduction

The adoption of e-commerce in modern times has led to higher profitability for merchants and brought more satisfaction to con- sumers [1–4]. This has also impacted positively on the economy of countries worldwide by improving Gross Domestic Product (GDP). The PricewaterhouseCoopers (PwC) in South Africa has reported that user online retail shopping sales surpassed a trillion Rand (South Africa currency) for the first time in history, which has increased to 1.46 trillion Rand in 2016 [5]. In addition, the same

* Corresponding author.
E-mail addresses: 21242711@DUT4life.ac.za (S.A. Oyewole), oludayoo@dut.ac.za (O.O. Olugbara).
Peer review under responsibility of Faculty of Computers and Information, Cairo University.
source reported that because of the global surge in e-commerce, the collective GDP of Africa continent is expected to rise by US
$1trillion by the year 2020, which is up from US$1.6 trillion in 2010. Moreover, the Economist Intelligence Unit (EIU) has fore- casted a real GDP growth of 4.9% from 2012 to 2016 for the African continent, which is well above the average global growth [5,6]. E-commerce is playing a key role in the global economic growth and the need to keep satisfying customers cannot be over empha- sized. However, abundance of e-commerce information in recent years has become a serious challenge for shoppers, because of the inherent difficulty in information discovery. This has led to the emergence of recommendation systems to assist a user in the information discovery. A content-based image recommendation system is an application that uses image features to filter informa- tion from all the available sources and displays the appropriate information based on personal preferences that are kept in the user profile [7,8]. The origin of recommendation systems can be traced to methods in cognitive science, management science, approxima- tion theory and information retrieval, which have since been applied in various human endeavours.



https://doi.org/10.1016/j.eij.2017.10.002
1110-8665/© 2017 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



In the e-commerce application domain, many methods and principles have been applied to implement recommendation sys- tems of which classification methods have been identified as an important component. Product classification, which involves the association of classes with related products from a large number of merchants, is one of the most important processing tasks of content-based recommendation systems. Apart from user profiling [9,10], classification methods have been found useful in many recommendation applications such as product image retrieval [11–13], product taxonomy browsing [14], increase scalability
[15] and improve overall recommendation accuracy.
Meanwhile, most of the accuracies reported on product classifi- cation studies rely heavily on text tagging, which is a traditional product data representation method [16–18]. However, product classification based on text tagging is plagued with several hiccups such as overlapping text across product classes [19,20], labour intensiveness [21], discrepancy in vocabulary usage [22], spelling error [23] and undescriptive nature of texts [20,24]. While incre- mental improvement can be achieved by trying new methods that exploit textual features [19,21], current research efforts have shifted focus to image based product classification models with diverse applications in various fields of life [24–26]. According to the pattern recognition theory, feature extraction and feature recognition methods play major roles in the classification process. As accuracy is one of the common assessments of performances, several researchers in the recommendation domain have carried out interesting studies to enhance the performance of product classification.
In contrast to text tagging, image based product classification involves the use of images for product representation and classification model. The high dimensionality of extracting image features, limited content analysis, artefacts, inhomogeneity and other nuance factors often inhibit image-based classification per- formance [10,16,27]. A significant volume of researches have been channelled towards this direction, nevertheless, the number of image-classes investigated and accuracies reported still leave much to be desired for real-time applications. In acknowledging the complexity of these problems, an initial attempt is made to solve a simpler sub-problem of image content-based recommenda- tion by proposing enhanced product image classification architec- ture. Among the core algorithms used in the proposed architecture is the ensembles of artificial neural network trained with the Eigen-based colour features. The propose architecture is used to classify product images into 100 classes.
Specifically, effort in this work is channelled toward actualising an effective image-based classification model that majorly relies on an ensemble of Artificial neural network (ANN) and potential of efficient Eigen-based image feature representation. The extrac- tion of colour product features from a product image is performed using the Histogram of Oriented Gradient (HOG) and Uniform Lin- ear Binary Pattern (ULBP) feature extraction methods. The Eigen- based algorithm is then applied to extract a dimensionality reduced product image features. We applied data partitioning (cross validation) scheme that splits the initial data into training, validation and testing subsets in the proportion of 70%:15%: 15% (70% of the dataset is used for training the network, while 15% each of the remaining datasets is used for validation and testing), were experimentally explored on the PI100 categorization data set [28]. We chose this database because it has been widely used in e- commerce research for product image classification [25,26,29,30] and it is freely available for research purpose.
The overarching objective of the study at hand is to generate an efficient image-based classification model that can be used to deli- ver an effective user-centric categorical preferences or be inte- grated  with  any  conventional  recommendation  system  to
improve its quality. In realising this singular objective, four differ- ent experiments were performed to establish the appropriateness of the product image classification models for the proposed archi- tecture. This paper makes three major contributions enunciated as follows:

Propose an Eigen-based product image feature extraction algorithm that delivers an effective product image representation for large product classes. The results of this method can serve as an image segmentation approach in e-commerce applications such as recommender systems to resolve inherent limited content analysis problem.
The final classification model obtained from this work can be easily integrated with any other decision supporting appli- cations in e-commerce domain to improve its quality.
The proposed Eigen-based product image feature extraction algorithm is evaluated quantitatively on experimental images acquired from publicly available product images using the standard accuracy and mean squared error metrics.

This work further stresses the fact that an ensemble of machine learning classifiers gives better results than any classifier used in isolation. The rest of this paper is structured as follows. In Section 2, relevant literature is discussed. Section 3 describes in detail our proposed architecture as well as materials and methods. Then we describe the experiments carried out to validate the performance of the various methods for the tasks of product image classification in Section 4. In section 5 discussions of results are presented. The paper is finally concluded in section 6 by giving a brief discussion about the future directions.


Literature review

Image feature extraction and classification methods are two important tasks in the recognition process. Artificial neural net- work (ANN) and Support vector machine (SVM) are two popular classifiers that have been applied to e-commerce product image classification and decision supporting tasks with some degree of success. Specifically, ANNs have the ability to model nonlinear relationships between a set of input variables in the user profile and corresponding preferences of the user. Large number of pro- duct data often caused overfitting when an ANN is integrated with any e-commerce applications [31,32] such as recommendation systems. To overcome this overfitting problem, cross-validation is considered to be one of the most effective methods to ensure over- fitting does not occur [31,32]. Here, available data is usually parti- tioned into three sets which are training, testing and validation. The training set is used to adjust the connection weights, the test- ing set is used to check the performance of the network at various stages of learning and training is stopped once the error in the test- ing set increases. The validation set is used to evaluate the perfor- mance of the model once training has been successfully accomplished [32]. This partitioning-based cross validation can be accomplished in recommendation systems using time, item rat- ing (which can come in the form of user preferences expressed in numeral or product-item feature), categorization and user- stratification [31,33].
Many authors have integrated ANN-classifier with image content-based approaches to improve product image recognition. In Bonnet [34], an object recognition pipeline for e-commerce products was developed using a combination of convolutional neu- ral nets (Deep Learning) and natural language processing (NLP). In his work 85%, 86% and 86% classification accuracy was realised



with image, text and a hybrid of both respectively on 10 classes. The researcher finally achieved 94% classification accuracy by using transfer learning and fine-tuning with neural networks. However, the number of 10 classes considered is still very limited. Other researchers [31,32,34,35] have adopted various cross valida- tion techniques to address the overfitting problem in order to improve classification accuracy and prediction of user preferences. In [35], a new cross-validation technique was proposed to evaluate the quality of recommender systems. Besides splitting the initial data into training and testing subsets, their work splits the attri- bute description of the dataset into hidden and visible parts. The new cross validation was performed on traditional user-based and item-based recommender algorithms which were applied to the Movie Lens dataset. Likewise, Berka et al. [36] have used ANN to build URL recommendation systems for web navigation. They implemented a content-independent system based exclu- sively on trails – that is associating pairs of domain names with the number of people who traversed them. In order to do so effec- tively, they used feed-forward multilayer perceptron trained with the backpropagation algorithm. In Hsu et al. [37], ANN was used to combine the input from several recommendation modules or data sources. Specifically, the researchers build a TV recommender by importing data from four different sources which are user pro- files and stereotypes, viewing communities, program metadata and viewing context. They use the back-propagation algorithm to train a three-layered neural network. In the same view, Christakou and Stafylopatis [38] built a hybrid content-based collaborative filter- ing recommendation system. The content-based recommender is implemented using three neural networks per user, each of them corresponding to one of the following features: ‘‘kinds”, ‘‘stars” and ‘‘synopsis”. They trained the ANN using the resilient backprop- agation method. Vassiliou et al. [39], proposed an approach that uses ANN to recognize implicit patterns between user profiles and items of interest which are then further enhanced by collabo- rative filtering to personalize suggestions.
To further improve image based product classification accu- racy, many researchers have investigated the technique of com- bining the predictions of multiple classifiers which is known as ensemble learning [40]. Ensemble learning has been reported to be effective in many application areas such as facial expression recognition [41], Bioinformatics [42,43], hyperspectral image processing [44], big text corpora and object detection [45]. Exper- imental results have shown that the use of ensemble learning often produces better performance than any individual classifier in isolation. An explicit example of this in recommendation system is the work in [46], in which ensemble learning methods were used for music recommendation. In addition, Freund et al.
[47] presented an algorithm called RankBoost to combine user preferences to produce movie recommendations in a collabora- tive filtering setting.
Likewise, many researchers have used an SVM classifier to achieve image based classification. In [29], the authors have uti- lised image tagging technique with Support Vector Machine (SVM) and bag of visual word classifier to achieve classification accuracies between 66% and 98% for problems with 2–3 classes. Jia et al. [24] used the same 2–3 classes by Tomasik et al. [29] with SVM to realize an improvement of about 1–4% in classification accuracy. Jia et al. [48] proposed an automatic fast online product classification algorithm with class specific descriptor and SVM. The authors reported an accuracy of 84% for 30 product classes. Zhang and Sha [25] adopted the SVM classifier combined with Pyramid Histograms of Oriented Gradients (PHOG) features that were extracted from the PI100 dataset to implement product image clas- sification. They reported average accuracies of 74.5% and 94.5% in
5–50 training samples respectively. Moreover, Jia et al. [24] com- pared two Direct SVMs and two layers-SVMs stacking on 94 classes to report an overall accuracy of 81.2% and 79.1% respectively. Using the same data set, Oyewole et al. [26] proposed a strategy for image based product classification that exploits Multiple Kernel Learning (MKL) to automatically classify product images in five dif- ferent colour models into 100 product classes. It was reported in the study that the proposed MKL-LaRBF classifier constantly per- formed better than other conventional single kernel SVM with average classification accuracy of 83.5%. However, the architecture relied on large feature dimension of 243 vector size for HOG. In Jia et al. [49], the combination of base classifiers was proposed, which was trained with complimentary features. According to the authors, combining the classifiers improved the overall accuracy to 86.9%, which was designated as state-of-the-art classification accuracy. Jia et al. [50] proposed an automatic product image clas- sification scheme using two layers of SVM classifiers. They achieved a slightly improved accuracy of 83.4% for the PI100 public product dataset over their earlier work [51]. Apparently, some of the foregoing research efforts have led to significant improvements in the performance of product classification methods. However, the reviewed studies (except in [26,49,51]) considered limited number of product classes that ranges between 2 and 52. Generally, the reported accuracies in the literature for image based product clas- sification still leave much to be desired. Hence, the current study was inspired by the critical need to develop a more elaborate and accurate image based product classification model that can be integrated with recommendation systems in order to improve its quality.

Materials and methods

The proposed image-based product classification architecture is as shown in Fig.1, which is an extension of the architecture pre- sented by Oyewole et al. [26]. The extension of the previous archi- tecture was motivated by the need to reduce its complexity through feature dimensionality reduction and to improve classifi- cation accuracy through ensembles of classifiers. The components of the proposed architecture as shown in Fig.1 are exhaustively described in this section.

Dataset

The first block in the proposed architecture as shown in Fig. 1 involves the acquisition of experimental dataset such as the PI100 corpus [28]. The corpus contains ten thousand low resolu- tion colour images of e-commerce products that are grouped into
100 classes. Each image contains the dominant object in rela- tively stable forms, which is exactly the way product images normally appear on e-commerce websites such as Amazon.com, Jumia.com, eBay, Web.com and Volusion. Fig. 2 shows 80 selected sample images from ten classes in the PI100 dataset. These classes are baby shoe, jacket, nutrition, cowboy-hat, earring, flower, can, helmet, hiking backpack and briefcase. The items in each class are similar in shape and appearance, but with little variation in the colour content. However, there is a wide differ- ence between product images across the different classes in term of their shapes and sizes of their semantic features. Considering the need to avoid the curse of dimensionality that may occur in the event of the sparse number of instances per image class, we collected 20 image samples per class for each of the 100 classes in the corpus that culminates in 2000 colour images of e-commerce products.











































Fig. 1. Enhanced image based product classification architecture.




Fig. 2. Selected product images from PI100 dataset.



Pre-processing

Image pre-processing shown in the second block in the pro- posed architecture in Fig.1 is the technique of enhancing images prior to computational processing. In most image analysis, pre- processing module frequently forms the first step after the acquisi- tion of images [52]. The processing transforms an input image into a new image that is fundamentally similar to the input image, but may differ in certain aspects. Examples of pre-processing opera- tions include resizing, masking, segmentation, normalization, reflection removal and noise removal.
In this work, pre-processing operations that were applied on the selected product images are image resizing and noise filtering. To achieve image resizing, all images were standardized in size of
300 × 300 pixels. To get a smooth output from the product images,
the resized images must go through the filtering process. This fil-
tering stage is highly imperative because many image based prob- lems are heavily influenced by noise. An image pixel is considered noisy if its value is much different from other values in its neigh- bourhood [52]. Failure to take specific measure against noisy data may lead to poor classification performance [53–55]. We imple- mented noise filtering for the proposed architecture in this study by applying an existing method called median filter on each of the three channels of the colour images separately [52,56,57].

Feature extraction

The third block in Fig. 1 contains the feature extraction compo- nent of the proposed architecture. It is well established that accu- racy of product image classification largely depends on the discriminatory potency of the extracted features. In fact, the best classifier may fail to achieve accurate recognition if poor features are used [58]. In digital image processing, colour, shape and texture are important primitive features for product description. Existing feature extraction algorithms in the literature for this primitive feature includes the Scale Invariant Feature Transform (SIFT) [59], Speeded-Up Robust Feature (SURF) [60], Histogram of Ori- ented Gradient (HOG) [61], Local Binary Pattern (LBP) [62,63], Bin- ary Statistical Image Feature (BSIF) [64], Gabor filter [65] and Principal Component Analysis (PCA) [66]. Amongst these algo- rithms, the HOG and LBP along with its variant Uniform LBP (ULBP) have proven to be highly successful in various tasks such as object classification [67], human behaviour recognition [68], face recogni- tion [69], pedestrian recognition [70] and Bioinformatics [43] to mention just a few.
Specifically, among static texture descriptors, LBP and its vari- ants [62,63] are famous in the field of image processing and com- puter vision because of their computational simplicity [68,71]. The ULBP in particular is stable and less prone to artefacts making the number of labels significantly fewer and offering appreciable esti- mation and statistical robustness. Likewise, HOG has recorded attractive properties like better invariance to illumination and is particularly described in the literature to be a strong method for extraction of shape, appearance and texture features [61,63,71,72]. Consequently, HOG has become a popular descriptor for content based image recognition. HOG and ULBP algorithms were selected to extract colour features in this study based on these attractive properties and reputations gained over time from the literature [61,68,71,73]. In this study, we computed ULBP for each channel of the colour input image to obtain a cube of
59 × 3 dimensions per image. Likewise, we applied 3 × 3 blocks
81  × 3  elements  from  each  colour  product  image. of cells and 9 bins to generate a compact HOG feature vector of
To further improve on the spatial alignment of the image, a 3D
colour model is integrated. The RGB colour model was selected
based on its superior performance over other colour models as reported in [26,74]. Dimensionally reduced feature vectors have been reported in the literature to produce an improved perfor- mance in classifiers [64,69,75,76]. In particular, because of the low dimensions of some genomic images, in their effort to reduce dimensions of feature vectors, Adetiba and Olugbara [75] applied
minimum dimensions of 2 × 2 block of cells and 9 bins to generate
a compact HOG genomic feature vector of 36 elements from a
greyscale image. Hence, we developed a simple dimensionality reduction algorithm based on the Eigenvector principle to reduce
the cHOG feature of dimension 81 × 3 and cULBP of dimension 59 × 3 to 81 and 59 most dominant principal component element feature vectors respectively. We discontinued with the last step of
the widely used PCA, which is the projection of eigenvector. This becomes necessary because accuracy results obtained with the projected features [66] on the experimental dataset of this study are lower than its eigenvector counterpart.

Eigen Colour feature

A colour image often generates high dimensional feature vec- tors and it is well known that high-dimensional vectors will increase  the  computational  complexity  with  no  substantial
improvement in performance. Therefore, N × 3 colour map can
be processed further to achieve better performance can be pro-
cessed further to achieve better performance. This is in essence to eliminate the curse of dimensionality [77,78], which conse- quently reduces the computational complexity of the pattern clas- sifier in the image based classification architecture [79].
In this paper, we have applied eigenvector-based algorithm to extract colour features from the Nx3 colour features that were obtained using colour image descriptors. The essence of the method relies on the potential of Eigen decomposition among others, to correlate even artefact corrupted features. This is a departure from conventional dimensionality reduction strategies using PCA, which operate directly on digitized raw images and the projected eigenvector [66]. In this study the following steps were carried out to compute the Eigen Colour feature (ECF) of an Nx3 feature matrix extracted from a given colour image.
Step 1: The mean ux of N × 3 feature matrix represented as X is
first computed for M = 3 as:
XN
n=1
Step 2: The elements of the matrix X are mean centred by sub-
tracting the mean computed in Step 1 for each of the elements as follows:
X(i; j)= X(i; j)— lx  for i = 1; 2; .. . ; N;  j = 1; 2; 3	(2)
The subtraction of the mean at this stage is highly important
because it ensures that the first component of the feature matrix indicates the direction of maximum variance [80].
Step 3: The covariance matrix of the matrix X computed in Step
is obtained to derive an N x N square matrix as follows:
X(i; j)X(i; j)T
A(i; j)=	N — 1	for i = 1; 2; ... ; N;  j = 1; 2; 3	(3)
The covariance matrix is computed at this stage so as to appo- sitely capture the variance and linear correlation of the elements in the N x 3 colour feature matrix.
Step 4: Now from step 3 the eigenvalue problem can be defined
as follows. Given an N x N covariance matrix A, find all vectors Y in N space such that:
(A — kIN)Y = 0N	(4)


where k represents constant values called eigenvalues, which is the diagonal elements and Y is the associated eigenvectors. The above equations capture the relationship between the square matrix, eigenvalues and the corresponding eigenvector. The equation is a homogeneous equation that has a non-trivial solution if and only if Y is a non-zero vector. Consequently, the non-zero vector Y that satisfies Eq. (4) can be deduced by resolving

One of the most commonly used feed-forward network topolo- gies is the Multilayer Perceptron (MLP) because it possesses all the aforementioned capabilities of a feed-forward ANN [88,89]. Based on these, MLP is the neural network classifier adopted for this study. Primarily, MLP-ANN topology comprises of input, hidden and output layers that usually contain a varying number of neu- rons based on the structure of the training data set and expected


a1;1 — k		a1;2	···	a1;N a2;1	a2;2 — k ···	a2;N
· · ·	· · ·	···	·· ·
 = 0	(5)
 
level of accuracy. The training dataset for MLP usually consists of a set of features (xp, tp) where p represents the number of ele- ments in the feature vector; xp is the input feature vector while tp is the corresponding target vector. For the cHOG-ECF and

aN;1	aN;2	··· aN;N — k 
Similar to what is done in [81], the eigenvalues k are computed
as the roots of the characteristic polynomial function of order N in
Eq. (5). These values k1; k2; ... ; kN sorted in descending order gives us the components in order of significance alongside with its cor- responding eigenvector Y [80,81]. In the square matrix A the eigen- vector associated with the smallest eigenvalue represents the least variance while the eigenvector with the highest eigenvalue repre- sents the greatest variance [82] of the extracted feature data. This expresses the most significant relationship between the data dimensions and serves as the most dominant principal component of the product image data set.
In this work, we taped from these unique properties of eigen- vector. As such, the eigenvector that is associated with the largest eigenvalue in the covariance matrix A is what represents the Eigen Colour feature (ECF) that is used in the proposed work. In this study, the ECF that was computed from the cHOG and cULBP fea- tures are named cHOG-ECF and cULBP-ECF respectively. These fea- tures were transmitted to the final block in the proposed architecture (Fig. 1) to train the selected classifiers.

Product classification

In order to realize the objective of classifying product images as shown in our proposed architecture (Fig. 1), we formulated the
were associated with a finite number of known classes as (xi; yi), task as a multi-class classification problem in which similar images where xi ∈ ffin is the ith product image and yi ∈ {1;   ; k} is the
ith class label. This classification process is a mapping from the
set of input variables xi to a set of output variables, which are the class labels yi . The goal of any supervised multiclass classifica- tion algorithm is to classify an unseen image I as belonging to one class out of all the existing k image classes using the feature vector
obtained from the image I. In this work, two popular classifiers which are ANN and SVM were experimentally compared to solve the product image classification task.
An ANN is an interconnected group of artificial neurons that uses computational models to simulate the structure and function of biological nervous system [83,84]. The pattern of the intercon- nections between the input neurons and propagation of data is called the network topology of artificial neural network. The two main types of ANN topologies are the feedforward and recurrent networks. The flow of data in a feedforward neural network is in a forward direction from input neurons to the output neurons with no feedback of connections, but recurrent networks contain feed- back connections. It has been mentioned in many research based on the feed-forward ANN application that the topology of the net- work is able to approximate complex nonlinear mappings, it con- tains highly parallel, deals with noisy data and provides a model for problems which classic parametric techniques are unable to handle [85]. Furthermore, feed-forward ANN possesses the intrin- sic generalization ability that enabled it to identify and respond to patterns that are similar but not identical to the ones they have been trained [86,87].
cULBP-ECF feature vectors in this study, the values of p are 81 and 59 respectively. Based on the dimensions of these features, the MLP-ANN to be trained with cHOG-ECF requires 81 neurons in the input layer, while the network to be trained with cULBP- ECF requires 59 neurons in the input layer. The required number of hidden layers and associated number of neurons per hidden layer of MLP-ANN vary based on the nature of the problem being solved and are usually determined with proper experimentations [90]. The experiments we performed to determine appropriate numbers of neurons in the hidden layer for the MLP-ANN in the current study is described in Section 4.
The tp for each of the 100 classes in this study was encoded using one-per-class coding method [91,92] as illustrated in Table 1. As shown in the Table, each class target vector contains 100 ele- ments with 1 in the position of the class number and 0 s in other positions. Since each output neuron is designated the task of iden- tifying a given class, 100 neurons are required in the output layer of the MLP-ANN.
The computational effort needed for determining the correct combination of weights substantially increases as more parame- ters or more complicated network topologies are considered [93], hence the need to select an appropriate algorithm that will handle such learning problem. One of the most popular ANN algorithms that are used for learning is the Back Propagation (BP) algorithm [94]. The BP training algorithm adjusts weights and biases of the network in order to minimize mean square error between the actual and desired outputs using the gradient descent method. The computation of weights that minimizes the error function is considered to be a solution of the learning problem. Many variants of BP algorithm have been reported among which are the Conju- gate Gradient (CG), Scaled Conjugate Gradient (SCG) and quasi- Newton BP algorithms [95]. We have adopted SCG-BP to train the designed MLP-ANN in this study so as to take advantage of its well acclaimed speed of convergence [41,96].
The SVM, which is our second choice of pattern classifier, was introduced in 1992 by Cortes and Vapnik as a machine learning model that is based on the structural risk minimization induction principle [97,98]. It is a supervised learning model that gained pop- ularity as a result of its superior performance in a wide range of applications and its ability to handle data with high dimensionality [48,99,100]. Although, SVM was originally developed for binary classification [90], it can also be extended to cater for multiclass problem [44]. The traditional way of achieving this is to decompose the multiclass problem into groups of class problem and subse- quent construction of several binary classifiers. Currently, the two techniques that are commonly used are the One-Against-One (1A1) and One-Against-All (1AA) techniques [101,102]. However, 1AA is selected for this work based on its simplicity and past liter- ature track of efficiency [103].
The choice of appropriate kernel functions for SVM classifiers is also very crucial. Examples of popular kernel functions used in SVM are polynomial, Radial Basis Function (RBF), linear and quad- ratic [104]. Multi-Kernel Learning (MLK), which involves the combination of two or more kernel functions (to take advantage of their respective strengths) are also used to enhance the


Table 1
One-per-class coding.




performance of SVM classifiers. Examples of such MKL are com- bined RBF and linear kernels (LaRBF) in [26], RBF and polynomial kernels (RBFP) [105–107] and Gaussian, RBF and polynomial kernels- GRPF [108]. Different kernel functions were tested in this work to obtain an appropriate single SVM. We also varied the cross validation from 10-fold to 20-fold across the different kernel func- tions [25,109].

Ensemble of pattern classifiers

Many researchers have investigated the technique of combining the predictions of multiple classifiers to achieve better accuracy, a concept that is generally referred to as ensemble learning [40]. Two popular methods for creating accurate ensemble are bagging [40] and Boosting [110,111]. In [40], the author stated categorically that bagging is one of the most efficient methods that can effectively be applied in problem learning. On this background, we applied Bag- ging ensemble in this study.
Bagging ensemble method is a voting-based classification algo- rithm that allows the combination of multiple ‘‘weak” classifiers to produce more accurate and ‘‘strong” classification model. The name was derived from the words Bootstrap aggregating [40]. The algorithm works by taking different samples of the original dataset, then the data set is reassembled by using the statistical bootstrapping sampling [111] method to create and train multiple classification models. The outputs of the models are then combined using the majority voting algorithm. The general architecture of Bagging is shown in Fig. 3. Bagging ensemble was applied to gen- erate the base classifiers for the MLP-ANN and SVM ensemble clas- sifiers in this study.
Experimental setup

In this study, four different experiments were performed to establish the appropriate algorithms and classifiers for the pro- posed architecture in Fig. 1. All the experiments were performed in MATLAB R2014 environment on an Intel Core i5-2540 M CPU @2.60 GHz speed, 4.00 GB RAM, 500 Hard disk and it runs 64-bit Windows 7 operating system. The experimental data sets and pre-processing operations that were performed on them were exhaustively described in Sections 3.1 and 3.2 respectively.
Choosing the optimum data partitioning proportions for data training, validation and testing is generally essential to the perfor- mance of an ANN model [112]. In the first experiment, the cHOG- ECF was utilized to train eleven different single MLP-ANNs. Similar to what was done in [31], we experimentally determine and com- pare accuracies delivered by 60%:20%:20%, 70%: 15%: 15% and 80%:10%:10% data partitioning schemes, when the number of neu- rons in the first and second hidden layers varies from 10 to 110. The MLP-ANN structure with the best accuracy was thereafter used with a bagging ensemble procedure to obtain base classifiers for the ensemble MLP-ANN.
In the second experiment, the cULBP-ECF was used in place of the cHOG-ECF in the first experiment. All the other procedures in the first experiment were thereafter repeated for the second exper- iment. In the third experiment, the cHOG-ECF was used to train five different SVM models by varying the kernel functions, which include linear, quadratic, polynomial, RBF as well as the multi- kernel LaRBF, The model with the highest accuracy was adopted as the base classifier for the bagging ensemble operation to obtain the SVM ensemble. In the fourth experiment, the cHOG-ECF































Fig. 3. Bagging ensemble architecture.



features in experiment 3 were replaced with cULBP-ECF and all the procedures in the third experiment were thereafter repeated. The results of the different experiments are reported in the succeeding section.


Discussion of results

The outputs of the pre-processing operation using the median filter in the second block of the architecture are shown in Figs. 4 and 5. Specifically, Figs. 4a and 5a contain the raw images of one item each in the Can and Baby-Shoe classes as well as the his- tograms of their red, green and blue channels respectively. The images, as well as the histogram of each of the colour channels
after the median filter was applied are also shown in Figs. 4b and 5b respectively. A qualitative comparison of the chan- nel histograms of the raw images (Figs. 4a and 5a) and those of the filtered images (Figs. 4a and 5a) has shown that the pixel distribu- tions of the filtered image channels are different from those of the original channels. For instance, the pixel distribution density of the red channel between 150 and 200 intensities in Fig. 4a is more than the pixel distribution density between 150 and 200 intensities in the corresponding red channel of the filtered image in Fig. 4b. This clearly illustrates the smoothening effect of median filtering, thereby enhancing the extraction of more discriminating colour features from the images. This result agrees with the position of other researchers [52,113] on the effect of noise filtering on image features extraction.





Fig. 4. (a) Original and (b) filtered outputs of an image from the Can class.




Fig. 5. Original (a) and filtered (b) outputs of an image from the Baby Shoe class.


The extracted HOG features are unique for each product item in the different classes as shown in the Figs. 6 and 7 line plots. Fig. 6 shows the line plots of the cHOG-ECF vectors for items randomly selected from each 10 product classes in Fig. 2. As shown, each class is displayed as a line graph with a distinct colour and clear dissimilarities among the cHOG-ECF extracted features. The cHOG-ECF vector of the item from the Baby shoe class consistently has low values from the first to the last element with different peak levels as shown in the line plot graph. Conversely, the cHOG-ECF vector of the item from the Briefcase class consistently has the highest values from the first to the last elements with the peak at 0.28 and the lowest at 0.0063. Fig. 7 shows the line plots of the cULBP-ECF vectors of images from 10 product classes in Fig. 2. Unlike the result in Fig. 6, there are overlaps as regard their peak values and less discrimination in the values obtained from
products in the different classes. This result qualitatively shows the discriminatory strength of the cHOG-ECF above the cULBP-ECF.
Figs. 8 and 9 show that images in the briefcase class are similar to a large extent in terms of their shape and colour content. A thor- ough visual inspection on Fig. 8 confirmed that from 0.05 and above, most of the cHOG-ECF vectors overlapped, showing the extent of their similarity, while little variation occurs at the bases. Fig. 8 conveys similar notion, with similar feature peaks and sizes. However, the number of overlaps recorded in cULBP is less when compared to cHOG-ECF. The singular surge of peaks that obtruded at the tail end of cULBP-ECF vectors is another common and notice- able trait that exists in both 9 and 11.
The same trend occurs with the set of feature generated from Helmets classes with many peaks occurring in the same neigh- bourhood of 0.02 and above. As shown in Fig. 10 overlapped




0.35


0.3


0.25


0.2


0.15


0.1


0.05


0 0	10	20	30	40	50	60	70	80
cHOG-ECF Vector Index

Fig. 6. Line plots of cHOG-ECF of images from 10 different product classes.


1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

00	10	20	30	40	50	60
cULBP-ECF Vector Index

Fig. 7. Line plots of cULBP-ECF of images from 10 different product classes.


features are less pronounced when compared to line plots dis- played in Fig. 8. The peaks generated between the 34th and 56th of cHOG-ECF vectors formed a valley shaped, where lower peaks range from 0.15 and 0.2 were eminently recorded. Unlike the fea- ture generated from Helmet class uLBP-ECF vector in Fig. 9 for Briefcase, that of HelmetuLBP-ECF are less discriminatory. This is evidence from the line plots in Fig. 11, where less overlapping fea- tures are recorded.
Despite the shapes of the extracted features for different product classes are similar, their peaks as well as shape sizes are unique as shown in Figs. 6 and 7. These peculiarities are what provide a strong basis for using machine learning to distinctively identify each of the classes. Consequently, to further establish quantitatively the discriminatory differences of these two image feature  descriptors,  four  experiments  were  conducted  using
pattern classifiers. The result realised from the experimental com- parison of these three data partitioning (cross validation) schemes when the number of neurons varied from 10 to 110 is shown in Table 2. It can be observed from the table that the best classifica- tion accuracy of 83.20%, 81.6% and 78.09% was realised when uHOG-ECF image feature was used to train single MLP-ANN with 60%:20%:20%, 70%: 15%: 15%, and 80%:10%:10% data partitioning scheme respectively. The three schemes have their best accuracy when 100, 100 and 90 neurons are in the hidden layers respectively. This singular information guided our choice of 70%: 15%: 15%.
Moreover, the detail of the results when uHOG-ECF was used to train a single MLP-ANN (with 70%: 15%: 15% data partitioning scheme with 100 neurons in the two hidden layers) is shown in Fig. 12. The accuracy obtained for 10 neurons in each of the hidden


0.35


0.3



0.25



0.2


0.15



0.1



0.05



0 0	10	20	30	40	50	60	70	80
BriefCasecHOG-ECF Vector Index

Fig. 8. Line plots of cHOG-ECF of randomly selected images from Briefcase Product class.


1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
0	10	20	30	40	50	60
BriefCasecUlbp Vector Index

Fig. 9. Line plots of cULBP-ECF of randomly selected images from BriefCase Product class.


layers is 7% with MSE of 0.0095. As we increased the number of neurons, the performance accuracy of the single MLP-ANN also increased progressively (Fig. 12), and the highest accuracy of 83.2% with the lowest MSE of 0.0022 was obtained for 100 neurons in each of the hidden layers. Notably, there is a drastic reduction in the performance when the number of hidden layer neurons was increased to 110. Hence, the single MLP-ANN with 100 neurons in the hidden layer was nominated as the base classifier for the MLP-ANN ensemble.
Moreover, bagging ensemble was used to resample the cHOG- ECF features to train the nominated single MLP-ANN in order to generate twenty different base MLP-ANN classifiers. The best ten base classifiers were selected from the generated twenty classifiers similar to what is done in [114]. The result is shown in Table 3, to give an average accuracy of 87.02% for MLP-ANN ensemble with cHOG-ECF features in this first experiment. Although this result is good, we cannot decide on its acceptability at the moment until other experiments are performed. Hence, the succeeding section


0.25



0.2



0.15



0.1



0.05



0
0	10	20	30	40	50	60	70	80
HelmetcHOG-ECF Vector Index

Fig. 10. Line plots of cHOG-ECF of randomly selected images from Helmet Product class.


1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0
0	10	20	30	40	50	60
HelmetcUlbp-ECF Vector Index

Fig. 11. Line plots of cULBP-ECF of randomly selected images from Helmet Product class.



contains the description of the second experiment and the results we obtained.
In the second experiment, single MLP-ANN with varying num- ber of hidden neurons from 10 to 110 was trained with the cULBP-ECF. The result is shown in Fig. 13. The MLP-ANN with 10 neurons in the hidden layers produced an accuracy of 18.8% with MSE of 0.009. The accuracies and MSEs of the other configurations are also shown on the figure. However, the single MLP-ANN with
100 neurons in the hidden layers gave the highest accuracy of 67.10% with the lowest MSE of 0.0042.
Based on the above result, twenty base MLP-ANNs were gener- ated to form the ensemble classifier in the current experiment using bagging algorithm. Table 4 shows the accuracies and MSEs of the base classifies to give an average accuracy of 76.14% with an average MSE of 0.00281. Since the configuration of the classifier in this second experiment is similar to that of the first experiment,


Table 2
Evaluation of three common data partitioning (cross validation) schemes.



 Accuracy%	 Mean Square Error (MSE*1000)
90
80
70
60
50
40
30
20
10
0
10	20	30	40	50	60	70	80	90	100	110
Number of hidden layer neurons

Fig. 12. Experimental results of the single MLP-ANN with cHOG-ECF.



Table 3
Experimental results of the ensemble MLP-ANN with cHOG-ECF.
Table 4
Experimental results of the base MLP-ANN with cULBP-ECF.





Fig. 13. Experimental results of the single MLP-ANN with cULBP-ECF.



it can be inferred that the cHOG-ECF gives a better descriptor of product images than the cULBP-ECF. However, for further explo- ration of alternative classifier with regard to the cHOG-ECF and cULBP-ECF descriptors, we carried out more experiments as reported in the succeeding sections.
Figs. 14 and 15 show the performance plots obtained for the third experiment in which five variants of SVMs were trained with the cHOG-ECF using 10 and 20-fold cross validations respectively. As shown in Fig. 14, the SVM with LaRBF kernel function gave the highest accuracy of 83.5% when 10-fold cross validation was used, while in Fig. 14, the same kernel function produced an accuracy of 80% by 20-fold cross validation. Given these results, the LaRBF ker- nel SVM with 10-fold cross validation was selected to generate 20 base SVM classifiers using Bagging ensemble learning in the cur- rent experiment.
The average classification accuracy of 84% was realised as shown in Table 5. This result is obviously good, but it is lower in comparison with the result of the first experiment which gave an average accuracy of 87.20% using MLP-ANN ensemble with cHOG-ECF. In codicil, the accuracy of 84% obtained with SVM ensemble is only slightly better than the accuracy of 83.5% obtained with a single SVM in the current experiment.
The results of the fourth experiment are presented in Figs. 16 and 17. As clearly illustrated in the figures, SVM with LaRBF kernel on 10-fold cross validation gave the highest accuracy of 51% and highest accuracy of 47.25% in 20-fold cross validation.
Table 5
The result of the third experiment (SVM ensemble trained with cHOG-ECF).





The result of SVM ensemble using cULBP-ECF gave an average classification accuracy of 52.11% as shown in Table 6. The results of the current experiment are the poorest of all the experimental results in this study. Therefore, it is apparent that either single or ensemble SVM with uLBP-ECF are unacceptable for product image classification.
The primary objective of this study, which is to develop an enhanced product image classification architecture has been achieved. Through experimentation, we were able to establish the appropriate algorithms and classification models for realizing the proposed architecture. A summary of the results obtained from





Fig. 14. Results of the third experiment (single SVM with 10-fold cross validation and cHOG-ECF).




Fig. 15. Result of the third experiment (single SVM with 20-fold cross validation and cHOG-ECF).




Fig. 16. Results of the fourth experiment (single SVM with 10-fold cross validation and cULBP-ECF).



Fig. 17. Results of the fourth experiment (single SVM with 20-fold cross validation and cULBP-ECF).



Table 6
Results of the third experiment with ensemble SVM- cULBP-ECF.
Table 7
Summary of experimental results.



Total average	52.11%	3.94409



all the experiments conducted in this study is shown in Table 7. As shown in the Table, there is no remarkable improvement of the SVM ensemble over its single counterpart. This is because unlike most other learning algorithms, SVM has a built-in mechanism for managing bias-variance trade-off [115,116], who carried out a face detection experiment, reported that bagged SVMs gave a lower result compared to single SVM. Similarly, Valentini et al.
[117] also reported that there was no improvement with the use of SVM bagging on Leukemia data set. However, MLP-ANN ensem- ble trained with cHOG-ECF gave the highest average accuracy of 87.20% in the study at hand. This result is a substantial improve- ment over existing image based product classification works
reported in the literature [25,49,50]. For instance, Jia et al. [49], combined some base SVM classifiers and realised an overall accu- racy of 86.9% using the same PI100 dataset that we extracted for the study at hand. Although the authors designated this result as state-of-the-art classification accuracy, it is not as high as the 87.2% accuracy we obtained in this study.


Conclusion and future work

In this paper, we proposed an enhanced colour image based product classification architecture, which comprises of a median filter, the newly developed Eigen Colour feature (cHOG-ECF and cULBP-ECF) and artificial neural network ensemble for product classification in e-commerce domain. We have been able to show



that it is possible to push low classification accuracy that charac- terizes existing product image classifiers to a useable level with ensemble strategy and dimensionally reduced colour features. The accuracy realised from any classification work depends on the dataset and application [118,119], because each dataset has its own peculiarity and difficulty. In view of this background, cou- pled with the number of classes we have considered in relation to the range of accuracies that has been reported in the literature by others [24–26,29,49,50] on the same data set, the realisation of a novel classification accuracy of 87.20% on 100 categories of pro- duct using Eigen Colour feature extracted from the colour images from this architecture is a distinctive contribution of this study.
The proposed architecture based on cHOG-ECF and ensemble of artificial neural network as reported in this study can be readily integrated and implemented in a recommendation system for an accurate implicit profiling and personalised recommendation to resolve new user problem. Moreover, our proposed architecture can be employed by merchants for automatic product tagging in e-commerce domain. Another prospect of our approach is that it can easily be used as a pre-classification module in any product recommendation system architecture. Since no single feature is sufficient for handling diverse intra variation among broad cate- gories in the e-commerce research domain, future research will focus on the development of more discriminating features. In addi- tion, we will perform more intensive comparative studies on other state-of-the art machine learning methods to further enhance the performance of the product image classification architecture reported in this paper.


References

Baier D, Daniel I, Frost S, Naundorf R. Image data analysis and classification in marketing. Adv Data Anal Classif 2012;6:253–76.
Zhou D, Hu B, Wang Q, Hu B, Jia L, Wu Y., et al. Design of shopping guide system with image retrieval based on mobile platform. In: 2nd international symposium on computer, communication, control and automation (3CA). Atlantis Press; 2013.
Hu Y, Yin H, Han D, Yu F. The application of similar image retrieval in electronic commerce. Sci World J 7:2014. Hindawi Publishing Corporation.
Bhattacharya S, Das R. Facilitating consumer satisfaction by content based product classification, ICBPEM, proceedings of international conference at national institute of technology, Rourkela, Springer; 2014.
PwC South Africa. South African retail and consumer products outlook: 2012– 2016, last assessed on 29 of June 2017 from <http://www.pwc.co.za/en/ publications/retail-and-consumer-outlook.html>.
McKinsey Global Institute. Lions on the move, the progress and potential of African economies; 2010.
Olmo FHd, Gaudioso E. Evaluation of recommender systems: a new approach. Expert Syst Appl 2008;35(3):790–804.
Olugbara OO, Ojo SO, Mphahlele MI. Exploiting image content in location based shopping recommender systems for mobile users. Int J Inform Technol Decis Making 2010;9:759–78.
Ma Z, Pant G, Sheng ORL. Interest-based personalised search. ACM Trans Inform Syst (TOIS) 2007;25(1):1–38.
Han Y, Choi SM. A content recommendation system based on category correlations. Fifth international multi-conference on computing in the global information technology; 2010. p. 66–70.
Vailaya A, Figueiredo MAT, Jain AK, Zhang H-J. Image classification for content-based indexing. IEEE Trans Image Process 2001;10(1):117–30.
Iqbal Q, Aggarwal JK. Retrieval by classification of images containing large manmade Objects Using Perceptual Grouping. Pattern Recogn J 2002;35 (7):1463–79.
Vikas V. Image retrieval and classification using local feature vectors. Master degree dissertation. Department of Computer Science & Engineering, Indian Institute of Technology Madras; 2011.
Pohs W. Building taxonomy for auto-classification. Bull Am Soc Inform Sci Technol 2013;39(2):34–8.
Jain YK, Wadekar S. Classification-based retrieval methods to enhance information discovery on the web. Int J Manag Inform Technol (IJMIT) 2011;3(1):33–44.
Kannan A, Talukdar PP, Rasiwasia N, Ke Q. Improving product classification using images. In: ICDM; 2011. p. 310:319.
Agrawal R, Srikant R. On integrating catalogs. In: Proceedings of the 10th international conference on world wide web(WW-10). New York: ACM Press; 2001. p. 603–612.
Sarawagi S, Chakrabarti S, Godbole S. Cross-training: learning probabilistic mappings between topics. In: Proceedings of the Ninth ACM SIGKDD international conference on knowledge discovery and data mining Washington; 2003. p. 24–7.
Kweon DH, Hong JH, Cho S. Web image retrieval using prior tags based on word net semantic information. J Korea Multimedia Soc 2009;12(7):1032–42.
Jang H, Cho S. Flickr image classification using SIFT algorithm. Life Sci J 2014;11(7):607–11.
Lee SJ, Cho S. Tagged web image retrieval re-ranking with wikipedia-based semantic relatedness. J Korea Multimedia Soc. 2011;1(11):1491–9.
Lee K, Kim D, Kim HJ. A survey on tagging in the web 2.0 environment. Commun Korea Inform Sci Soc 2007;25(10):36–42.
Chang R, Lin S, Ho J, Fann C, Wang Y. A novel content based image retrieval system using k-means/KNN with feature extraction. ComSIS 2012;9(4).
Jia S, Kong X, Fu H, Jin G. Automatic fast classification of product images with class specific descriptor. J Electron 2010;6:7–10.
Zhang H, Sha Z. Product classification based on SVM and PHOG descriptor, IJCSNS. Int J Comput Sci Netw Secur 2013;13(9):1–4.
Oyewole SA, Olugbara OO, Adetiba E, Nepal T. Classification of product images in different color models with customised kernel for support vector machine. In: Third international conference on artificial intelligence, modelling and simulation; 2015. p. 153–7.
Nath SS, Mishra G, Kar J, Chakraborty S, Dey N. A survey of image classification methods and techniques. In: International conference on control, instrumentation, communication and computational technologies (ICCICCT), vol. 978, no. 1; 2014. p. 554–7.
Xie X, Lu L, Jia M, Seide F, Ma MY. Mobile search with multimodal queries. Proc IEEE 2008;96(4):589–601.
Tomasik B, Thiha P, Turnbull D. Tagging products using image classification. In: Proceedings of the 32nd international ACM SIGIR conference on research and development in information retrieval. Boston, MA, USA; 2009. p. 792–3.
Jia S, Kong X, Fu H, Jin G. Auto classification of product images based on complementary features and class descriptor. J Electron Inform 2010;32 (10):2294–300.
Shahin MA, Maier HR, Jaksa MB. Data division for developing neural networks applied to geotechnical engineering. J Comput Civil Eng ASCE 2004;18 (2):105–14.
Bashiri M, Geranmayeh AF. Tuning the parameters of an artificial neural network using central composite design and genetic algorithm. Scientia Iranica 2011;18(6):1600–8.
Pelánek R. Evaluation of recommender systems; 2016. Last assessed on 29 of June 2017 from <https://www.fi.muni.cz/~xpelanek/PV254/slides/evaluation. pdf>.
Bonnett C. Classifying e-commerce products based on images and text; 2016. Last assessed on 21 of June 2017 from <http://cbonnett.github.io/Insight. html>.
Ignatov D, Poelmans J, Dedene G, Viaene S. A new cross-validation technique to evaluate quality of recommender systems. Percept Mach Intell 2012:195–202.
Berka T, Behrendt W, Gams E, Reich S. A trail based internet-domain recommender system using artificial neural networks. In: Proceedings of the int conf on adaptive hypermedia and adaptive web based systems; 2002.
Hsu SH, Wen MH, Lin HC, Lee CC, Lee CH. AIMED-A personalized TV recommendation system. Interactive TV: Shared Exp 2007:166–74.
Christakou C, Stafylopatis A. A hybrid movie recommender system based on neural networks. In: Proceedings of the 5th international conference on intelligence system design and applications; 2005. p. 500–5.
Vassiliou C, Stamoulis D, Martakos D. A recommender system framework combining neural networks & collaborative filtering. In: Proceedings of the 5th WSEAS int conf on instrumentation, measurement, circuits and systems, Hangzhou, China; 2006. p. 285–90.
Breiman L. Bagging predictors. Mach Learn 1996;24(2):123–40.
Dogra HK, Hasan Z, Dogra AK. Face expression recognition using scaled- conjugate gradient back-propagation algorithm. Int J Modern Eng Res 2013;3 (4):1919–22.
Ahmad F, Roy K, O’Connor B, Shelton J, Dozier G, Dworkin I. Fly wing biometrics using modified local binary pattern, SVMs and random forest. Int J Mach Learn Comput 2014;4(3):279–85.
Adetiba E, Olugbara OO. Lung cancer prediction using neural network ensemble with histogram of oriented gradient genomic features. Sci World J 2015;2015.
Abe BT, Olugbara OO, Marwala T. Experimental comparison of support vector machines with random forests for hyperspectral image land cover classification. J Earth Syst Sci 2014;123(4):779–90.
Romero R, Iglesias EL, Borrajo L. A linear-RBF multi-kernel SVM to classify big text corpora. Biomed Res Int 2015;2015.
Tiemann M, Pauws S. Towards ensemble learning for hybrid music recommendation. In: Proceedings of the 2007 ACM conference on recommender systems; 2007. p. 177–8.



Freund Y, Iyer R, Schapire RE, Singer Y. n efficient boosting algorithm for combining preferences. Mach J Learn Res 2003;4:933–69.
Jia S, Gu Y, Zou J. Product image classification with multiple features combination. In: International conference on E-business intelligence, Atlantis Press; 2010. p. 469–75.
Jia S, Kong X, Man H. Automatic product image classification with multiple support vector machine classifiers. J Shanghai Jiatong Univ (Sci) 2011;16 (4):391–4.
Jia S, Kong X, Hong M. Automatic product images classification with two layer of	SVM	classifier.	In:	Green	communications	and networks. Dordrecht: Springer; 2012. p. 209–17.
Jia S, Gu Y, Zou J. Product image classification based on local features and SVM classifier. J Convergence Inform Technol (JCIT) 2012;7(5):1–9.
Jassim FA, Altaani FH. Hybridization of Otsu method and median filter for color image segmentation. Int J Soft Comput Eng (IJSCE) 2013;3(2):69–74.
Brodley CE, Friedl MA. Identifying mislabelled training data. J Artif Intell Res 1999;11:131–67.
Zhu X, Wu X. Class noise vs. attribute noise: a quantitative study. Artif Intell Rev 2004;22(3):177–210.
J.A. Sáez, J. Luengo, F. Herrera, A first study on the noise impact in classes for fuzzy rule based classification systems. In: Proceedings of the 2010 IEEE international conference on intelligent systems and knowledge engineering (ISKE’10), IEEE Press; 2010. p. 153–8.
Pitas I, Venetsanopoulos AN. Nonlinear digital filters: principles and applications. Springer Science & Business Media; 2013.
Geoffrine JMC, Kumarasabapathy N. Study and analysis of impulse noise reduction filters. Signal Image Process: Int J (SIPIJ) 2011;2(1):82–92.
Lajevardi SM, Hussain ZM. Feature extraction for facial expression recognition based on hybrid face regions. Adv Electr Comput Eng 2009;9:63–7.
Lowe GD. Distinctive image features from scale-invariant key points. Int J Comput Vision 2004;60(2):91–110.
Bay H, Ess A, Tuytelaars T, Gool LV. Surf: speeded up robust features. Comput Vis Image Underst 2008;10:346–59.
Dalal N, Triggs B. Histograms of oriented gradients for human detection. In: Proceedings of the IEEE computer society conference on computer vision and pattern recognition (CVPR ’05); 2005. p. 886–93.
Ojala T, Pietikäinen M, Harwood D. A comparative study of texture measures with classification based on featured distributions. Pattern Recogn 1996;29 (1):51–9.
Ojala T, Pietikäinen M, Maenpaa T. Multiresolution grayscale and rotation invariant texture classification with local binary patterns. IEEE Trans Pattern Anal Mach Intell 2002;24(7):971–87.
Kannala J, Rahtu E. BSIF: binarized statistical image features. In: Proceedings of international conference on image process; 2012. p. 1363–6.
Manjunathi BS, Ma WY. Texture features for browsing and retrieval of image data. IEEE Trans Pattern Anal Mach Intell 1996;18(8):837–42.
Turk M, Pentland A. Eigen faces for recognition. J Cogn Neurosci 1991;3 (1):71–86.
Lorenzo-Navarro CJ, Castrillon M, Ramon E, Freire D. Evaluation of LBP and HOG descriptors for clothing attribute description. First international workshop, VAAM 2014 Springer; 2014. p. 53–6.
Ming Y, Wang G, Fan C. Uniform local binary pattern based texture-edge feature for 3D human behaviour recognition. PLoS ONE 2015;10(5):1–15.
Ahonen T, Hadid A, Pietikäinen M. Face description with local binary patterns: application to face recognition. IEEE Trans Pattern Anal Mach Intell 2006;28(12):2037–41.
Gan G, Cheng J. Pedestrian detection based on HOG-LBP feature. Int conf on computational intelligence and security; 2011. p. 1184–87.
Dipankar D. Activity recognition using histogram of oriented gradient pattern history. Int J Comput Sci Eng Inform Technol 2014;4(4).
Shapiro LG, Stockman GC. Computer vision. New Jersey: Prentice Hall; 2001.
p. 1–14.
García-Olalla O, Alegre E, Fernández-Robles L, García-Ordás MT, García- Ordás. D. Adaptive local binary pattern with oriented standard deviation (ALBPS) for texture classification. EURASIP J Image Video Process 2013;31(1).
Akhloufi MA, Larbi WB, Maldague X. Framework for color-texture classification in machine vision inspection of industrial products. In: IEEE international conference on system, man, and cybernetic; 2007. p. 1067–71.
Adetiba E, Olugbara OO. Improved classification of lung cancer using radial basis function neural network with affine transforms of Voss representation. PLoS One 10(12): e0143542. https://doi.org/10.1371/journal.pone.0143542.
Shan C, Gritti T. Learning discriminative LBP-histogram bins for facial expression recognition. Proceedings of british machine vision conference (BMVC ’08); 2008. p. 1–10.
Pechenizkiy M, Puuronen S, Tsymbal A. Feature extraction for classification in knowledge discovery systems. In: Proc 7th int conf on knowledge-based intelligent information & engineering systems; 2003. p. 526–32.
Xu Y. Quaternion-based discriminant analysis method for color face recognition. PLoS ONE 2012;7(8).
Ponti M, Nazaré TS, Thumé GS. Image quantization as a dimensionality reduction procedure in color and texture feature extraction. Neurocomputing 2016;173:385–96.
Kalita J, Das K. Recognition of facial expression using eigenvector based distributed features and euclidean distance based decision making technique. Int J Adv Comput Sci Appl 2013;4(2):198.
Gaidhane VH, Hote YV, Singh V. An efficient approach for face recognition based on common eigenvalues. Pattern Recogn 2014;47:1869–79.
Tsymbal A, Puuronen S, Pechenizkiy M, Baumgarten M, Patterson D. Eigenvector-based feature extraction for classification. In: Proceedings of the 15th international florida artificial intelligence research society conference; 2002. p. 354–8.
Huang Y. Advances in artificial neural networks—methodological development and application. Algorithms 2009;2(3):973–1007.
Rahbari D. A novel approach in classification by evolutionary neural networks. Int J Comput Sci Network Secur (IJCSNS) 2014;14(9):8–936.
Cheng CT, Niu WJ, Feng ZK, Shen JJ, Chau KW. Daily reservoir runoff forecasting method using artificial neural network based on quantum-based particle swarm optimization. Water 2015;7:4232–46.
Vosniakos GC, Berardos PG. Optimizing feedforward artificial neural network architecture. Appl Artif Intell 2007;20(3):365–82.
Zama F, Hirose H. Double SVMs bagging: a subsampling approach to SVM ensemble.	Intelligent	automation	and	computer engineering. Netherland: Springer; 2009. p. 387–99.
Svozil D, Kvasnicka V, Pospichal J. Introduction to multi-layer feed-forward neural networks. Chemometr Intell Lab Syst 1997;39:43–62.
Pedro F, Pedro R, Ana A, Fernando MD. A high bit resolution FPGA implementation of a FNN with a new algorithm for the activation function. Neurocomputing 2007;71(1):71–7.
Delashmit WH, Mary MT. Recent developments in multilayer perceptron neural networks. In: Proceedings of the 7th annual memphis area engineering and science conference (MAESC ’05); 2005. p. 1–15.
Dietterich TG, Bakiri G. Multiclass learning problems via error-correcting output codes. J Artif Intell Res 1995;2:263–86.
Aly M. Survey on multiclass classification methods. Neural Netw 2005;19.
Karan O, Bayraktar C, Gumus_kaya H, Karlık B. Diagnosing diabetes using neural networks on small mobile devices. Expert Syst Appl 2012;39:54–60.
Rojas R. The backpropagation algorithm. In: Neural networks. Berlin Heidelberg: Springer; 1996. p. 149–82.
Møller MS. A scaled conjugate gradient algorithm for fast supervised learning. Neural Netw 1993;6(4):525–34.
Gopalakrishnan K. Effect of training algorithms on neural networks aided pavement diagnosis. Int J Eng Sci Technol 2010;2(2):83–92.
Cortes C, Vapnik V. Support vector networks. Mach Learn 1995;20:273–97.
Hearst MA, Dumais ST, Osman E, Platt J, Scholkopf B. Support vector machines. IEEE Intell Syst 1998;13(4):18–28.
Liu Y, Zheng YF. One-against-all multi-class SVM classification using reliability measures. In: Proceedings of IEEE international joint conference on neural networks, Montreal, Canada, vol. 2; 2005. p. 849–54.
Schӧlkopf B, Tsuda K, Vert JP. Kernel methods in computational biology. MIT Press Series on Computational Molecular Biology; 2004.
El-Yaniv R, Pechyony D, Yom-Tov E. Better multiclass classification via a margin optimized single binary problem. Pattern Recogn Lett 2008;29 (14):1954–9.
Galar M, Fernández A, Barrenechea E, Bustince H, Herrera F. An overview of ensemble methods for binary classifiers in multi-class problems: experimental study on one-vs-one and one-vs-all schemes. Pattern Recogn 2011;44(8):1761–76.
Eichelberger RK, Sheng VS. Does one-against-all or one-against-one improve the performance of multiclass classifications? In: Proceedings of the 27th AAAI conference on artificial intelligence, Bellevue, Wash, USA; 2013.
Gonen M, Alpaydin E. Multiple kernel learning algorithms. JMLR 2011;12:2211–68.
A E, Zanaty, Afifi A, Khateeb RE. Improving the accuracy of support vector machines via a new kernel functions. Int J Intell Comput Sci 2009;1:55–67.
A E, Aljahdali Zanaty S, Cripps RJ. Accurate support vector machines for data classification. Int J Rapid Manuf 2009;1(2):114–27.
Zanaty EA. Support vector machines (SVMs) versus multilayer perception (MLP) in data classification. Egypt Inform J 2012;13:177–83.
Kohavi R. A study of cross-variation and bootstrap for accuracy estimation and model selection. IJCAI 1995;14(2):1137–45.
Phienthrakul T, Kijsirikul B. Combining scalar-product-based and distance- based kernels for support vector machine. In: Proceedings of the 2005 electrical engineering/electronics, computer, telecommunications and information technology (ECTI) international conference (ECTI-CON 2005), Pattaya, Thailand, vol. 2; 2005. p. 669–72.
Freund Y, Schapire R. Experiments with a new boosting algorithm. In: Proceedings of the thirteenth international conference on machine learning, Bari, Italy; 1996. p. 148–56.
Efron B, Tibshirani R. An introduction to the bootstrap. CRC Press; 1994.
Tokar AS, Johnson PA. ‘Rainfall-runoff modeling using artificial neural networks’. J Hydrol Eng 1999;4(3):232–9.
Sáez JA, Luengo J, Herrera F. A first study on the noise impact in classes for fuzzy rule based classification systems. In: Proceedings of the 2010 IEEE international conference on intelligent systems and knowledge engineering (ISKE’10), IEEE Press; 2010. p. 153–8.
Thakur S, Adetiba E, Olugbara OO, Millham R. Experimentation using short- term spectral features for secure mobile internet voting authentication. Math Probl Eng 2015;2015.
Valentini G, Dietterich TG. Low bias bagged support vector machines. In: Proceedings of the twentieth international conference on machine learning (ICML-2003); 2003. p. 752–9.



Buciu I, Kotropoulos C, Pitas I. Combining support vector machines for accurate face detection. Proceedings of ICIP’01; 2001. p. 1054–7.
Valentini G, Muselli M, Ruffino F. Bagged ensembles of support vector machines for gene expression data analysis. In: Proceedings of the IEEE international joint conference on neural networks, vol. 3; 2003.
p. 1844–9.
Tamrakar D, Khanna P. Analysis of palmprint verification using wavelet filter and competitive code. IEEE international conference on computational intelligence and communication networks (CICN); 2010. p. 20–5.
Novianti PW, Jong VL, Roes KCB, Eijkemans MJC. Factors affecting the accuracy of a class prediction model in gene expression data. BMC Bioinformatics 2015;16(199):1–12.
