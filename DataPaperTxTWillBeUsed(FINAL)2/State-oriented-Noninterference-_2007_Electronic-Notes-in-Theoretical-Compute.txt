Electronic Notes in Theoretical Computer Science 194 (2007) 39–60	
www.elsevier.com/locate/entcs

State-oriented Noninterference for CCS
Ilaria Castellani1 ,2
INRIA Sophia Antipolis 2004 route des Lucioles, BP 93,
06902 Sophia Antipolis Cedex, France

Abstract
We address the question of typing noninterference (NI) in the calculus CCS, in such a way that Milner’s translation into CCS of a standard parallel imperative language preserves both an existing NI property and the associated type system. Recently, Focardi, Rossi and Sabelfeld have shown that a variant of Milner’s translation, restricted to the sequential fragment of the language, maps a time-sensitive NI property to that of Persistent Bisimulation-based Non Deducibility on Compositions (PBNDC) on CCS. However, since CCS was not equipped with a type system, the question of whether the translation preserves types could not be addressed. We extend Focardi, Rossi and Sabelfeld’s result by showing that a slightly simpler variant of Milner’s translation preserves a time-insensitive NI property on the full parallel language, by mapping it again to PBNDC. As a by-product, we formalise a folklore result, namely that Milner’s translation preserves a behavioural equivalence on programs. We present a simple type system ensuring PBNDC on CCS, inspired by existing type systems for the π-calculus. Unfortunately, this type system as it stands is too restrictive to grant the expected type preservation result. We sketch a solution to overcome this problem.
Keywords: Noninterference, type systems, parallel imperative languages, process calculi, bisimulation.


Introduction
The issue of secure information flow has attracted a great deal of interest in re- cent years, spurred by the spreading of mobile devices and nomadic computation. The question has been studied in some depth both for programming languages (see [26] for a review) and for process calculi [24,8,13,21,11,14,12,5,17,10]. We shall speak of “language-based security” when referring to programming languages, and of “process-based security” when referring to process calculi.
The language-based approach is concerned with secret data not being leaked by programs, that is, with the security property of confidentiality. This property is usually formalized via the notion of noninterference (NI), stating that secret inputs of programs should not influence their public outputs, since this could allow - at least in principle - a public user to reconstruct secret information.

1 Work partially supported by the ANR SETI-06-010 grant.
2 Email: Ilaria.Castellani@sophia.inria.fr

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.09.012

The process-based approach, on the other hand, is concerned with secret actions of processes not being publicly observable. Although bearing a clear analogy with the language-based approach - security levels are assigned in both cases to informa- tion carriers, respectively variables and channels - the process-based approach does not rely on quite the same simple intuition. Indeed, there are several choices as to what an observer can gather by communicating with a process. This is reflected in the variety of NI properties proposed for process calculi, mostly based on trace equivalence, testing or bisimulation (cf [8] for a review). In general, these properties do not clearly distinguish between the flow of data and the flow of control, which are closely intertwined in process calculi. Let us consider some examples.
In the calculus CCS with value passing [18], an input process a(x).P receives a value v on channel a and then becomes P {v/x}. Symmetrically, an output process a⟨e⟩.P emits the value of expression e on channel a and then becomes P . Then a typical insecure data flow is the following, where subscripts indicate the security level of channels (h meaning “high” or “secret”, and l meaning “low” or “public”):
geth(x). putl⟨x⟩
Here a value received on a high channel is retransmitted on a low channel. Since the value for x may be obtained from some high external source, this process is considered insecure. However, there are other cases where low output actions carry no data, or carry data that do not originate from a high source, as in:
geth(x). al	ch. putl⟨v⟩	geth(x). putl⟨v⟩
where al, ch are channels without parameters and v is a constant value. Although these processes do not directly transfer data from high to low level, they can be used to implement indirect insecure flows, as in the following process (where x is a boolean and actions on channels ch and dh are restricted and thus not observable):

P = ((geth(x). if x then ch else dh) | (ch. putl⟨0⟩ + dh. putl⟨1⟩)) \ {ch, dh}
The above examples suggest a simple criterion for enforcing noninterference on CCS, namely that high actions should not be followed by low actions. Admittedly, this requirement is very strong. However, it may serve, and indeed has been used, as a basis for defining security type systems for process calculi.
In the language-based approach, theoretical results have often lead to the design of tools for verifying security properties and to the development of secure imple- mentations. Most of the languages examined so far have been equipped with a type system or some other tool to enforce the desired security property [19,20,23,22].
By contrast, the process-based approach has remained at a more theoretical level. Type systems for variants of the π-calculus, which combine the control of security with other correctness concerns, have been proposed by Hennessy et al. in [11,12] and by Honda et al. in [13,14]. A purely security type system for the π-calculus was presented by Pottier in [21]. More recently, different security type systems for the π-calculus were studied by Crafa and Rossi [10] and by Kobayashi [17] (this last work also provides a type inference algorithm). Other static verification methods have been proposed for a variant of CCS in [5].
We address the question of unifying the language-based and process-based ap-

proaches, by relating both their security notions and the associated type systems. A first step in this direction was taken by Honda, Vasconcelos and Yoshida in [13], where a parallel imperative language was embedded into a typed π-calculus. This work was pursued by Honda and Yoshida in [14], where more powerful languages, both imperative and functional, were considered. In [9], Focardi, Rossi and Sabelfeld showed that a variant of Milner’s translation of a sequential imperative language into CCS preserves a time-sensitive NI property, by mapping it to the property of Persistent Bisimulation-based Non Deducibility on Compositions (PBNDC), intro- duced by Focardi and Rossi in [7]. However, since CCS was not equipped with a security type system, the question of type preservation could not be addressed.
Taking [9] as our starting point, we extend its result by showing that a simpler variant of Milner’s translation preserves a time-insensitive NI property on a parallel imperative language, by mapping it again to PBNDC. As a by-product, we show that the translation preserves a behavioural equivalence on programs. We also propose a type system for ensuring PBNDC, inspired by the type systems of [21,11,12] for the π-calculus. Unfortunately, this type system is too restrictive as it stands to reflect any of the known type systems for the source language. However, it can be used as a basis to derive a suitable type system, which is briefly sketched here.
The rest of the paper is organised as follows. In Section 2 we recall the definitions of BNDC and PBNDC for CCS and we present a type system ensuring the latter. In Section 3 we introduce the parallel imperative language and the time-insensitive NI property for it; we then propose an adaptation of Milner’s translation of this language into CCS, and show that it preserves our NI property. We conclude with a discussion about type preservation. Proofs are omitted and may be found in [6].

A simple security type system for CCS
In this section we present a security type system for CCS, inspired by those proposed for the π-calculus by Pottier [21] and by Hennessy and Riely [11,12]. We prove that this type system ensures the property of Persistent Bisimulation-based Non Deducibility on Compositions (PBNDC), introduced by Focardi and Rossi in [7].

The process calculus CCS
Our chosen process calculus is CCS with value passing and guarded sums. We start by recalling the main definitions. We assume a countable set of channels or names N , ranged over by a, b, c, with the usual notational conventions for input and output. Similarly, let V ar be a countable set of variables, disjoint from N and ranged over by x, y, z, and V al be the set of data values, ranged over by v, v'. We
define Exp, ranged over by e, e', to be the set of boolean and arithmetic expressions built from values and variables using the standard total operations. Finally, we let
val : Exp → V al be the evaluation function for expressions, satisfying val(v) = v for any value v. We will use the notation →x (resp. →v or →e) to denote a sequence
⟨x1,... , xn⟩ (resp. a sequence ⟨v1,... , vn⟩ or ⟨e1,... , en⟩).

The syntax of process preﬁxes, ranged over by π, π', is given by:
π ::= a(x) | a⟨e⟩ | a | a
Simple prefixes of the form a and a will be used in examples but omitted from our technical treatment, since they are a simpler case of a(x) and a⟨e⟩.
To define recursive processes, we assume a countable set I = {A, B,.. .} of parametric process identifiers, each of which is supposed to have a fixed arity. We then define the set of parametric terms, ranged over by T, T ', as follows:
T ::= A | (rec A(→x) .P ) where P is a CCS process, as defined next.
A term (rec A(→x) .P ) is supposed to satisfy some standard requirements: (1) all
variables in →x are distinct; (2) the length of →x is equal to the arity of A; (3) all free variables of P belong to →x; (4) no free process identifier other than A occurs in P ;
(5) recursion is guarded: all occurrences of A in P appear under a prefix.
The set Pr of processes, ranged over by P, Q, R, is given by the syntax:
P, Q ::= Σi∈I πi.Pi | (P | Q) | (νa) P | T (→e)
where I is an indexing set. We use 0 as an abbreviation for the empty sum
π .P . Also, we abbreviate a unary sum	π .P to π .P and a binary sum i∈{1,2} πi.Pi to (π1.P1 + π2.P2). In a process A(→e) or (rec A(→x) .P )(→e), the length of →e is assumed to be equal to the arity of A. Finally, if →a = ⟨a1,... , an⟩,
with ai /= aj for i /= j, the term (νa1) ··· (νan) P is abbreviated to (ν→a) P . If K = {a1,... , an}, we sometimes render (ν→a) P simply as (νK) P , or use the origi- nal CCS notation P \K, especially in examples.
The set of free variables (resp. free process identifiers) of process P will be denoted by fv (P ) (resp. ﬁd (P )). We use P {v/x} for the substitution of the variable x by the value v in P . Also, if →x = ⟨x1,... , xn⟩ and →v = ⟨v1,... , vn⟩, we denote by P {→v/→x} the substitution of each variable xi by the value vi in P . Finally, P {T /A} stands for the substitution of the parametric term T for the identifier A in P .
The semantics of processes is given by labelled transitions of the form P −α→ P '.
Transitions are labelled by actions α, β, γ, which are elements of the set:

Act d=ef
{av : a ∈ N , v ∈ V al}∪ {a¯v : a ∈ N , v ∈ V al}∪ {τ }

The subject of a prefix is defined by subj (a(x)) = subj (a⟨e⟩)= a, and the subject of an action by subj (av) = subj (a¯v) = a and subj (τ ) = τ . The complementation operation is extended to input and output actions by letting av = a¯v and a¯v = av. The operational rules for CCS processes are recalled in Figure 1. A nondeter- ministic sum	i∈I πi.Pi executes one summand πi.Pi, simultaneously discarding the
others. A summand a(x). Pi receives a value v on channel a and then replaces it
for x in Pi. A summand a⟨e⟩. Pi emits the value of expression e on channel a and then becomes Pi. The parallel composition P | Q interleaves the executions of P and Q, possibly synchronising them on complementary actions to yield a τ -action. The restriction (νb)P behaves like P where actions on channel b are forbidden.

(SUM-OP )	Σ	π .P −a→v
Pi{v/x},  if πi = a(x) and v ∈ V al



(SUM-OP2)	Σ

i∈I


πi.Pi av
Pi , if πi = a⟨e⟩ and val(e)= v




(PAR-OP1)
P −α→ P '
P | Q −α→ P ' | Q

(PAR-OP2)
Q −α→ Q'

P | Q −α→ P | Q'


(PAR-OP3)
−→ P '


−→ Q'

(RES-OP)
−→ P '
b /= subj (α)

P | Q −τ→ P ' | Q'	(νb)P −α→ (νb)P '


(REC-OP)
P {→v/→x}{ (rec A(→x) .P ) /A } −α→ P '	→v = val(→e)


(rec A(→x) .P )(→e) α P '
Fig. 1. Operational Semantics of CCS Processes


Security properties for CCS
We review two security properties for CCS: Bisimulation-based Non Deducibility on Compositions (BNDC), introduced by Focardi and Gorrieri [8] and reformulated by Focardi and Rossi in [7], and Persistent Bisimulation-based Non Deducibility on Compositions (PBNDC), proposed in [7] as a strenghtening of BNDC, better suited to deal with dynamic contexts.
We start by recalling the definition of weak bisimulation. We adopt the usual notational conventions:

For any α ∈ Act, let P =α
P '	def
τ  ∗  α	τ
−→ −→ −→
,⎨	α	'
∗P '

⇒	=
, P −τ→
∗P ' if α = τ

Definition 2.1 [Weak Bisimulation] A symmetric relation S ⊆ (Pr × Pr) is a weak bisimulation if P S Q implies, for any α ∈ Act:

If P −α→ P '
then there exists Q'
αˆ
such that Q =	Q
and P '
S Q'.

P and Q are weakly bisimilar, P ≈ Q, if P S Q for some weak bisimulation S. To set up the scenario for BNDC, we need a few more definitions.
Definition 2.2 [High and low channels] The set N of channels is partitioned into a subset of high (secret) channels H and a subset of low (public) channels L.
Input and output actions are then defined to be high or low according to the level of their supporting channel. No security level is given to τ -actions.

Definition 2.3 [Syntactically high processes w.r.t. H]
The set of syntactically high processes with respect to H, denoted PrH , is the set
of processes that contain only channels in H.
The property of Bisimulation-based Non Deducibility on Compositions (BNDC) of [8], in its reformulation given by Focardi and Rossi [7], is now defined as follows:

Definition 2.4 [BNDCH] Let P ∈ Pr and H ⊆ N be the set of high channels. Then P is secure with respect to H, P ∈ BNDCH, if for every process Π ∈ PrH ,
(νH)(P | Π) ≈ (νH)P .
When there is no ambiguity, we write simply BNDC instead of BNDCH. Let us point out two typical sources of insecurity:
Insecurity may appear when a high name is followed by a low name in P , because in this case the execution of (νH)P may block on the high name, making the low name unreachable, while it is always possible to find a high process Π that makes the low name reachable in (νH)(P | Π). Let for instance P = ah. bl. Choosing Π = ah, one obtains (νH)(P | Π) /≈ (νH)P .
Insecurity may also appear when a high name is in conflict with a low name, as in P = ah + bl. Here again, taking Π = ah one gets (νH)(P | Π) /≈ (νH)P ,
since the first process can do a silent move	r	leading to a state equivalent
to 0, which the second process cannot match. Note on the other hand that Q = ah. bl + bl is secure, because in this case, the synchronisation on channel ah in (νH)(Q | Π) may be simulated by inaction in (νH)Q.
In [7], Focardi and Rossi proposed a more robust property than BNDC, which they called Persistent Bisimulation-based Non Deducibility on Compositions (PBNDC).
To define PBNDC, a more permissive notion of bisimulation is required, based
~
α
on a new transition relation =⇒H , defined for any α ∈ Act by:


~
α
P =⇒H P

def
=
P =⇒ P '
αˆ
or P  r
∗P '
if subj (α) ∈H 

, P =⇒ P '	otherwise
Definition 2.5 [Weak bisimulation up-to-high]
A symmetric relation S ⊆ (Pr × Pr) is a weak bisimulation up to high if P S Q
implies, for any α ∈ Act:

If P −α→ P '
then there exists Q'
~
α
such that Q =⇒H
Q' and P ' S Q'.

Two processes P, Q are weakly bisimilar up to high, written P ≈H Q, if P S Q for some weak bisimulation up to high S.
Definition 2.6 [PBNDCH] Let P ∈ Pr. Then P is said to be persistently secure
with respect to H, P ∈ PBNDCH, if P ≈H (νH)P .
~
α
The transition relation =⇒H is used in the definition of PBNDC to allow high

moves of P to be matched by (possibly empty) sequences of τ -moves of (νH)P .
It was shown in [7] that PBNDC is stronger than BNDC, and that requiring PBNDC for P amounts to requiring BNDC for all reachable states of P . All the examples considered above are treated in the same way by BNDC and PBNDC. Examples of secure but not persistently secure processes may be found in [7,6].

A security type system for PBNDC
In this section we present our security type system for CCS and we show that it ensures the PBNDC property. This type system is inspired by those previously proposed for the π-calculus by Pottier [21] and by Hennessy et al. [11,12].
Security levels, ranged over by δ, θ, σ, are defined as usual to form a lattice (T , ≤), where the order relation ≤ stands for “less secret than”. Here we assume the lattice to be simply {l, h}, with l ≤ h, to match the partition of the set of channels into L and H.
A type environment Γ is a mapping from channels to security levels, together with a partial mapping from process identifiers to security levels. This mapping is extended to prefixes and visible actions by letting Γ(π) = Γ(subj (π)) and for any α /= τ , Γ(α)= Γ(subj (α)). Type judgements for processes have the form Γ ▶σ P . Intuitively, Γ ▶σ P means that in the type environment Γ, σ is a lower bound on the security level of channels occurring in P . The typing rules are as follows:


(Sum)
∀i ∈ I :	Γ(πi)= σ	Γ ▶σ Pi
Γ ▶σ Σi∈I πi.Pi
(Par)
Γ ▶σ P	Γ ▶σ Q


Γ ▶σ P | Q



(Res)
Γ, b : θ ▶σ P


Γ ▶σ (νb)P
(Sub)
Γ ▶σ P	σ' ≤ σ

Γ ▶σ' P


(Rec1)	(Rec2)

Γ(A)= σ

Γ ▶σ A(→e)
Γ, A : σ ▶σ P


Γ ▶σ (rec A(→x) .P )(→e)

Let us briefly discuss rule (Sum), which is the less standard one. This rule imposes a
strong constraint on processes  i∈I πi.Pi, namely that all prefixes πi have the same security level σ and that the Pi have themselves type σ. In fact, since each judgement Γ ▶σ Pi may have been derived using subtyping, this means that originally Γ ▶σi Pi
for some σi such that σ ≤ σi. Note that, as expected, ah. bl and ah + bl are not
	
typable. However, it should be pointed out that the secure process ah. bl + bl is not typable either. Hence, rule (Sum) is stricter than we would wish. In order to make process ah. bl + bl typable, we could envisage replacing rule (Sum) by the following

rule (Sum-Lax), which allows a prefix πi to be of level higher than l, provided its continuation process Pi is indistinguishable from the original sum process:
∀i ∈ I :	Γ ▶σ Pi ∧ ( Γ(πi)= σ ∨ ( Γ(πi) > σ ∧ Pi ≈H Σi∈I πi.Pi))

(Sum-Lax)
Γ ▶σ Σi∈I πi.Pi

Note however that rule (Sum-Lax) makes use of the semantic equivalence ≈H, and thus is not completely static. To avoid introducing such a semantic check in our type system, we shall stick, for the time being, to the more classical rule (Sum).
We proceed now to establish the soundness of this type system for PBNDC. We state here the most relevant results, referring the reader to [6] for more details.
Theorem 2.7 (Subject reduction)
For any P ∈ Pr, if Γ ▶σ P and P −α→ P ' then Γ ▶σ P '.
Lemma 2.8 (Confinement)
Let P ∈ Pr and Γ ▶σ P. If P −α→ P ' and α /= τ then Γ(α) ≥ σ.
The key for the soundness proof is the following property of typable programs:
Lemma 2.9 ( ≈H – invariance under high actions)
Let P ∈ Pr, Γ ▶σ P and H = { a ∈N : Γ(a)= h }. If P −α→ P ' and Γ(α)= h then
P ≈H P '.
Corollary 2.10 (Compositionality of ≈H for typable programs)
Let P, Q, R ∈ Pr and Γ be a type environment such that Γ ▶σ P, Γ ▶σ Q and
Γ ▶σ R .Then, if P ≈H Q, also P | R ≈H Q | R.
Note that ≈H is not preserved by parallel composition on arbitrary programs, as shown by this example, where Pi ≈H Qi for i = 1, 2 but P1 | P2 /≈H Q1 | Q2:
P1 = ah	Q1 = 0	P2 = Q2 = bl + ah
It is easy to see that P1 | P2 /≈H Q1 | Q2, since P1 | P2 can perform a τ -action which Q1 | Q2 cannot match. Note that P2 is not typable. In fact P2 is insecure. Indeed, the property of PBNDC itself is compositional, as shown in [7].
Using the above results, we may show that typability implies PBNDC:
Theorem 2.11 (Soundness)
If P ∈ Pr and Γ ▶σ P then P ≈H (νH)P, where H = { a ∈N : Γ(a)= h }.
This concludes, for the time being, our discussion about security and types for CCS.

Translating parallel imperative programs into CCS
We focus here on the parallel imperative language studied by Smith and Volpano in [30], which we call PARIMP. Several NI properties and related type systems have been already proposed for this language [27,1,29,4], inspired by the pioneering

work of Volpano, Smith et al. [32,30,31]. There exists a well known translation of PARIMP into CCS, presented by Milner in [18]. In [9], Focardi, Rossi and Sabelfeld showed that a variant of this translation preserves – by mapping it to PBNDC – a time-sensitive notion of NI for the sequential fragment of PARIMP. We shall be concerned here with the full language PARIMP, and with a time-insensitive NI property for this language. We will prove that this NI property is preserved by a suitable variant of Milner’s translation. As a by-product, we will show that our translation also preserves a behavioural equivalence on programs.

The imperative language PARIMP
In this section we recall the syntax and semantics of the language PARIMP, and we define a time-insensitive NI property for it, inspired by that of [4].
We assume a countable set of variables ranged over by X, Y, Z, a set of values ranged over by V, V ', and a set of expressions ranged over by E, E'. Formally, expressions are built using total functions F, G,... , which we assume to be in a 1 to 1 correspondence with the functions f, g,... used to build CCS expressions:
E ::= F (X1,... , Xn)
The set C of programs or commands, ranged over by C, D, is defined by:
C, D ::= nil | X := E | C ; D | (if E then C else D) |
(while E do C) | (C  D)
The operational semantics of the language is given in terms of transitions between configurations ⟨C, s⟩ → ⟨C', s'⟩ where C, C' are programs and s, s' are states or memories, that is, mappings from a finite subset of variables to values. These map- pings are extended in the obvious way to expressions, whose evaluation is assumed
to be terminating and atomic. We use the notation s[V /X] for memory update, '→ for the reflexive closure of →, and →∗ for its reflexive and transitive closure. The operational rules for configurations are given in Figure 2. The rules (ParL-Op2) and (ParR-Op2) are introduced, as in [3], to allow every terminated configuration
to take the form ⟨nil, s⟩.
A configuration ⟨C, s⟩ is well-formed if fv (C) ⊆ dom(s). It is easy to see, by inspection of the rules, that ⟨C, s⟩→ ⟨C', s'⟩ implies fv (C') ⊆ fv (C) and dom(s')= dom(s). Hence well-formedness is preserved by execution.
As for CCS, we assume variables to be partitioned into a set of low variables L and a set of high variables H. In examples, we will use the subscripts L and H for variables belonging to the sets L and H, respectively. We may now introduce the notions of low-equality and low-bisimulation.
Definition 3.1 [L-Equality] Two memories s and t are L-equal, written s =L t, if
dom(s)= dom(t) and (X ∈ dom(s) ∩ L ⇒ s(X)= t(X)).
Definition 3.2 [L-Bisimulation]
A symmetric relation S ⊆ (C× C) isa L-bisimulation if C S D implies, for any pair

of states s and t such that s =L t and ⟨C, s⟩ and ⟨D, t⟩ are well-formed:
If ⟨C, s⟩→ ⟨C', s'⟩, then there exist D', t' such that
⟨D, t⟩ '→ ⟨D', t'⟩ and s' =L t' and C' S D'.
Two programs C, D are L-bisimilar, C  L D, if C S D for some L-bisimulation S.
Note that the simulating program is required to mimic each move of the first pro- gram by either one or zero moves. This notion of low-bisimulation is inspired from [4]. We could have chosen a weaker notion, where '→ is replaced by →∗, as proposed in [27]. However our choice allows for a more precise notion of security,
which respects “state-traces”, as illustrated by Example 3.4 below.
Definition 3.3 [L-Security] A program C is L-secure if C  L C.
When L is clear, we shall speak simply of low-equality, low-bisimulation and security.


Example 3.4 The following program, where loop D d=ef
(while tt do D):

C = (if XH =0 then loop (YL := 0 ; YL := 1) else loop (YL := 1 ; YL := 0))
is not L-secure since the branches of the conditional cannot simulate each other’s moves in one or zero steps. However it would be secure according to the weaker notion of L-bisimulation obtained by replacing '→ with →∗ in Definition 3.2.
Milner’s translation of PARIMP into CCS
We now review Milner’s translation of the language PARIMP into CCS [18]. This translation makes use of two new constructs of CCS, renaming and conditional, whose semantics we assume to be known (see [18], or the full paper [6]).
First, registers are introduced to model the store. For each program variable X, the associated register RegX , parameterised by the value it contains, is defined by:
def

RegX (v) =  putX(x).RegX (x)+ getX ⟨v⟩.RegX (v)
The translation [s ] of a state s is then a pool of registers, given by :
[[s]] = RegX1 (s(X1)) | ··· | RegXn (s(Xn))	if dom(s)= {X1,... , Xn}
The translation [E ] of an expression E = F (X1,... , Xn) is a process which fetches the values of registers RegX1 ... , RegXn into the variables x1,... , xn and then trans- mits over a special channel res the result of evaluating f (x1,... , xn), where f is the CCS function corresponding to the PARIMP function F :
[[F (X1,... , Xn)]] = getX1 (x1). ··· . getXn (xn). res⟨f (x1,... , xn)⟩. 0
The channel res is used by the auxiliary operator Into, defined by:

P Into (x) Q d=ef
(P | res(x). Q)\res

To model sequential composition, a special channel done is introduced, on which processes signal their termination. Channel done is used by the auxiliary operators



(Assign-Op)


⟨X := E, s⟩→ ⟨nil, s[s(E)/X]⟩



(Seq-Op1)
⟨C, s⟩→ ⟨C', s'⟩

⟨C; D, s⟩→ ⟨C'; D, s'⟩
(Seq-Op2)


⟨nil; D, s⟩→ ⟨D, s⟩



(Cond-Op1)
s(E)= tt

⟨if E then C else D, s⟩→ ⟨C, s⟩



(Cond-Op2)
s(E) /= tt

⟨if E then C else D, s⟩→ ⟨D, s⟩



(While-Op1)
s(E)= tt

⟨while E do C, s⟩→ ⟨C; while E do C, s⟩



(While-Op2)
s(E) /= tt

⟨while E do C, s⟩→ ⟨nil, s⟩



(ParL-Op1)


(ParR-Op1)
⟨C, s⟩→ ⟨C', s'⟩

⟨C  D, s⟩→ ⟨C'  D, s'⟩
⟨D, s⟩→ ⟨D', s'⟩

⟨C	D, s⟩→ ⟨C	D', s'⟩
(ParL-Op2)


(ParR-Op2)


⟨nil  D, s⟩→ ⟨D, s⟩


⟨C	nil, s⟩→ ⟨C, s⟩


Fig. 2. Operational Semantics of PARIMP








Done, Before and Par, defined as follows, assuming d, d1, d2 to be new names:


Done d=ef


done. 0

C Before D d=ef
C1 Par C2 d=ef
(C[d/done] | d. D)\d
(C1[d1/done] | C2[d2/done] | (d1. d2.Done + d2. d1.Done))\{d1, d2}

The translation of commands is then given by: [[nil]] = Done
[[X := E]] = [[E]] Into (x) (putX⟨x⟩. Done)
[[C ; D]] = [[C]] Before [[D]]
[[(if E then C1 else C2)]] = [E]] Into (x) (if x then [[C1]] else [[C2]])

[[(while E do C)]] = W, where W d=ef

[[(C1  C2)]] = [C1]] Par [[C2]]
[E]] Into (x)
(if x then [[C]] Before W else Done)

Finally, the translation of a well-formed configuration ⟨C, s⟩ is defined by:
[[⟨C, s⟩]] = ( [[C]] | [[s]] ) \ Accs ∪ {done}
where Accs = { getX , putX | X ∈ dom(s) } is the access sort of state s.
As noted by Milner in [18], the above translation does not preserve the atomicity of assignment statements. Consider the program C = (X := X +1  X := X + 1). The translation of C is:

[[C]] = ( (getX (x). res⟨x + 1⟩ | res(y). putX ⟨y⟩. d1) \res

| (getX (x). res⟨x + 1⟩ | res(y). putX ⟨y⟩. d2) \res
| (d1. d2.Done + d2. d1.Done)) \ {d1, d2}

Here the second getX action may be executed before the first putX action. This means that the same value v0 may be read for X in both assignments, and thus the same value v1 = v0 + 1 may be assigned twice to X. Hence, while C only produces the final value v2 = v0 +2 for X, [[C ] may also produce the final value v1 = v0 + 1. It is then easy to see that the translation does not preserve security.	Let CL = (XL := XL +1  XL := XL + 1) and DL = (XL := XL +1 ; XL := XL + 1).
Let now C = (if zH =0 then CL else DL). Then C is secure, but [C]] is not.
It may be shown with similar examples (see [6]) that, in order for the translation to preserve security, it should also forbid the overlapping of assignments to different variables, as well as the overlapping of assignments with expression evaluation. To prevent such overlappings, we introduce a global semaphore for the whole store:

Sem d=ef
lock. unlock. Sem


	
Correspondingly, lock and unlock actions must be introduced in the translation of the assignment, conditional and loop commands.
The translation of the assignment command becomes:
[[X := E]] = lock. [[E]] Into (x) (putX⟨x⟩. unlock. Done)
To introduce locks in the translation of conditionals and loops, we examine two different solutions.

Solution 1. The first revised translation of conditionals and loops is given by: [[(if E then C1 else C2)]] = lock. [[E]] Into (x)( if x then unlock. [[C1]]
else unlock. [[C2]] )

[[(while E do C)]] = W, where W d=ef
lock. [[E]] Into (x)

(if x then unlock. [[C]] Before W else unlock. Done)
Our first translation of PARIMP into CCS, based on Solution 1, is summarised in Figure 3. This is essentially a simpler version of the translation proposed by Focardi, Rossi and Sabelfeld in [9], where in addition a special tick action was inserted in the encoding of each statement (just before the unlock action, in the above encodings), so as to recover a direct correspondence between execution steps in ⟨C, s⟩ and their simulation in [⟨C, s⟩ ]. This was needed to obtain a full abstraction result.
Solution 2. The second revised translation of conditionals and loops is based on the idea of localising the use of locks, by using the lock and unlock actions as delimiters around the translation of expression evaluation.
Let getseqX˜ (x˜) be an abbreviation for getX1 (x1). ··· . getXn (xn), and f (x˜) stand for
f (x1,... , xn), as usual.
The atomic translation of expression E, denoted [E]]at, is defined as follows: [[F (X1,... , Xn)]]at = lock. getseqX˜ (x˜). res⟨f (x˜)⟩. unlock. 0
The translation of conditionals and loops is then adapted by replacing [E]] by [[E]]at: [[(if E then C1 else C2)]] = [E]]at Into (x) (if x then [[C1]] else [[C2]])

[[(while E do C)]]	= W, where W d=ef
[E]]at Into (x)

(if x then [[C]] Before W else Done)
The second translation of PARIMP into CCS, based on Solution 2, is given in Figure 4, where for clarity we denote the translation by the symbol ⟨[ ]⟩ instead of [ ]. In the rest of the paper, we shall concentrate on the first translation, but all our results also hold for the second translation.
The translation preserves security
In this section we show that the translation just described preserves security. This result will be based, as usual, on an operational correspondence between programs (or more exactly, configurations) in the source language and their images in the target language. In order to relate the behaviour of a configuration ⟨C, s⟩ with that of its image [⟨C, s⟩]] = ( [[C]] | [[s]] | Sem ) \ Accs ∪ {done, lock, unlock}, we must provide a means to observe the changes performed by [C]] on [[s ] in CCS 3 . To

3 Note that, as it stands, the translation maps any configuration ⟨C, s⟩ to an unobservable CCS process.

Semaphore:

Translation of states:


def
Sem = lock. unlock. Sem

[[s]] = RegX1 (s(X1)) | · · · | RegXn (s(Xn))	if dom(s)= {X1,.. ., Xn}
Translation of expressions:
[[F (X1, ... , Xn)]] = getX1 (x1). ·· · . getXn (xn). res⟨ f (x1,. .., xn)⟩. 0

Translation of commands:
[[nil]] = Done
[[X := E]] = lock. [[E]] Into (x) (putX ⟨x⟩. unlock. Done)
[[C ; D]] = [[C]] Before [[D]]

[[(if E then C1 else C2)]] = lock. [[E]] Into (x) ( if x then unlock. [[C1]]
else unlock. [[C2]] )

[[(while E do C)]] = W, where W
def

= lock. [[E]] Into (x)

(if x then unlock. [[C]] Before W else unlock. Done) Translation of well-formed configurations ⟨C, s⟩:


Access sort of a state s:
[[⟨C, s⟩]] = ( [[C]] | [[s]] | Sem ) \ Accs ∪ {done, lock, unlock}

def
Accs = { getX , putX | X ∈ dom(s) }
Fig. 3. Translation of PARIMP into CCS




this end we introduce, as in [25] and [9], special channels dedicated to the exchange of data between processes and the environment, which we call in and out: the environment uses channel inX to feed a new value into register RegX , and channel outX to retrieve the current value of RegX .
The definition of registers is then adapted to account for the new actions. Each
RegX in our translation is replaced by the observable register ORegX defined by:
def


ORegX (v)
=  putX(x). ORegX (x) + getX ⟨v⟩. ORegX (v) + 
lock. ( inX (x). unlock. ORegX (x) + unlock. ORegX (v)) +
lock. ( outX ⟨v⟩. unlock. ORegX (v) + unlock. ORegX (v)) 



Here the locks around the inX (x) and outX ⟨v⟩ prefixes are used to prevent the environment from accessing the register while this is being used by some process. Note that after committing to communicate with the environment by means of a lock action, an observable register can always withdraw its commitment by doing an unlock action, and get back to its initial state. This ensures that the pool of observable registers, when run in parallel with the semaphore, is always weakly bisimilar to the image of some state s.
Notation: Let Env be the set {inX , outX | X ∈ Var}. We define then the set of

environmental actions to be Act	def
{α ∈ Act | subj (α) ∈ Env}.




Semaphore:

Sem d=ef

lock. unlock. Sem

Translation of states:
⟨[s]⟩ = RegX1 (s(X1)) | ··· | RegXn (s(Xn))	if dom(s)= {X1,... , Xn}
Translation of expressions:
⟨[F (X1,... , Xn)]⟩ = getX1 (x1). ··· . getXn (xn) . res⟨ f (x1,... , xn) ⟩. 0
`	getse˛q¸X→ (x→ )	x	`	f˛(→x¸)	x
Atomic translation of expressions:
⟨[F (X1,... , Xn)]⟩at = lock. getseqX→ (→x). res⟨f (→x)⟩. unlock. 0 Translation of commands:
⟨[nil]⟩ = Done
⟨[X := E]⟩ = lock. ⟨[E]⟩ Into (x) (putX⟨x⟩. unlock. Done)
⟨[C ; D]⟩ = ⟨[C]⟩ Before ⟨[D]⟩
⟨[(if E then C1 else C2)]⟩ = ⟨[E]⟩at Into (x) (if x then ⟨[C1]⟩ else ⟨[C2]⟩)

⟨[(while E do C)]⟩
= W, where W
def
=
⟨[E]⟩at Into (x)

(if x then ⟨[C]⟩ Before W else Done)
⟨[(C1  C2)]⟩ = ⟨[C1]⟩ Par ⟨[C2]⟩

Translation of well-formed configurations ⟨C, s⟩:
⟨[⟨C, s⟩]⟩ = ( ⟨[C]⟩| ⟨[s]⟩| Sem ) \ Accs ∪ {done, lock, unlock}


Access sort of a state s:

Accs

= { getX , putX | X ∈ dom(s) }


Fig. 4. Alternative translation of PARIMP into CCS


inX v
As in [9], we define now labelled transitions −−−→
X ∈ dom(s)


outX v
and −−−→
for configurations 4 :
s(X)= v

(In-Op)
⟨C, s
inX v
C, s[v/X]⟩
(Out-Op)
⟨C, s
outX v
C, s⟩

⟩ −−−→⟨ 
We also extend τ -transitions to configurations by letting:
⟨C, s⟩ −r→ ⟨C', s'⟩	⇔	⟨C, s⟩→ ⟨C', s'⟩
⟩ −−−→ ⟨

We may now define weak labelled transitions ⟨C, s⟩ α	C', s'⟩ on configurations,
=⇒⟨ 
where α ∈ ActEnv ∪ {τ }, exactly in the same way as for CCS processes.
The operational correspondence between well-formed configurations ⟨C, s⟩ and their images in CCS is then given by the following two Lemmas:
Lemma 3.5 (Program transitions are preserved by the translation)
Let ⟨C, s⟩ be a well-formed conﬁguration and α ∈ ActEnv. Then:

If ⟨C, s
α	C', s'⟩, then there exists P such that [[⟨C, s⟩
α P = [[⟨C', s'⟩]]

If ⟨C, s	r
C', s'⟩, then there exists P such that [[⟨C, s⟩
r P ≈ [[⟨C', s'⟩]]

Lemma 3.6 (Process transitions are reflected by the translation)
Let ⟨C, s⟩ be a well-formed conﬁguration and α ∈ ActEnv. Then:

If [[⟨C, s⟩	α P, then there exist C', s' such that ⟨C, s⟩ α
C', s'⟩  and

]] =⇒
P ≈ [[⟨C', s'⟩]].
=⇒⟨ 

If [[⟨C, s⟩
r⇒ P, then either [[⟨C, s⟩]] ≈ P or there exist C', s' such that

⟨C, s⟩ r
]] =
C', s'⟩ and P ≈ [[⟨C', s'⟩]].

=⇒⟨ 
The proof of Lemma 3.5 is rather straightforward, while that of Lemma 3.6 is much
more elaborate. Intuitively, we need to decompose a computation [⟨C, s⟩	α  P or
]] =⇒
[[⟨C, s⟩	r⇒ P into a sequence of micro-computations, each of which is the simulation
]] =
of a single (or empty) step of the source configuration ⟨C, s⟩, possibly interspersed with relay moves (parallel moves which do not affect the state and thus can be interleaved with transactions, which are sequences of moves accessing the state). The proof, as well as the auxiliary definitions and results required for it, may be found in the full version of the paper [6].
To compare the notion of L-security on PARIMP with that of PBNDC on CCS, it is convenient to characterise L-bisimilarity on programs by means of a bisimilarity up to high on configurations, following [9]. To this end, we introduce restricted conﬁgurations of the form ⟨C, s⟩\R, where ⟨C, s⟩ is well-formed and R ⊆ Env, whose semantics is specified by the rule:
⟨C, s⟩ −α→ ⟨C', s'⟩	subj (α) ∈/ R

(Res-Op)
⟨C, s⟩\R α
C', s'⟩\R

−→ ⟨
Let ResConf denote the set of restricted configurations, ranged over by cfg, cfg', cfgi.

For any cfg = ⟨C, s⟩\R ∈ ResConf, we let dom(cfg) d=ef
dom(s).



4 From now on we use v, v' also for PARIMP values, assuming them to coincide with CCS values.

We extend our translation to restricted configurations by letting:

[[⟨C, s⟩\
def
⟨C, s⟩]] \R

Let now EnvH d=ef {inX , outX | X ∈ H} and EnvL d=ef
{inX , outX | X ∈ L}. We

introduce a transition relation	α
H on ResConf, for any α ∈ ActEnv ∪ {τ }:


cfg '−α→H cfg'	d=ef
,⎪⎨ cfg α cfg' or cfg = cfg' if subj (α) ∈ EnvH ∪ {τ }



The transition relation
⎪ cfg −α→ cfg'	if subj (α) ∈ EnvL
~
α
'−→H is used to define the following notion of bisimulation

on restricted configurations:
Definition 3.7 [Bisimulation up-to-high on configurations]
A symmetric relation S ⊆ (ResConf × ResConf ) is a bisimulation up to high if
cfg1 S cfg2 implies dom(cfg1)= dom(cfg2) and, for any α ∈ ActEnv ∪ {τ }:

If cfg1
−α→ cfg'
then there exists cfg'
such that cfg2
'−α→H cfg'
and cfg'
S cfg' .

Two configurations cfg1, cfg2 are bisimilar up to high, written cfg1 ∼H cfg2, if
cfg1 S cfg2 for some bisimulation up to high S.
This leads us to the following characterisations of L-bisimilarity and L-security:
Proposition 3.8 (Characterisation of  L in terms of ∼H)
Let C, D be PARIMP programs. Then C  L D if and only if for any state s
such that ⟨C, s⟩ and ⟨D, s⟩ are well-formed, we have ⟨C, s⟩ ∼H ⟨D, s⟩\ EnvH and
⟨C, s⟩\ EnvH ∼H ⟨D, s⟩.
Corollary 3.9 (Alternative characterisation of L-security)
Let C be a PARIMP program.	Then C is L-secure if and only if ⟨C, s⟩ ∼H
⟨C, s⟩\ EnvH for any s such that ⟨C, s⟩ is well-formed.
Suppose that channels getX and putX have the same security level as variable X, that channels lock, unlock, res and done have level h, and that renaming preserves security levels. We may then show that the translation preserves security.
Theorem 3.10 (Security is preserved by the translation)
If C is a L-secure program, then for any state s such that ⟨C, s⟩ is well-formed,

[[⟨C, s⟩]] satisﬁes PBNDCH, where H def
{getX , putX , inX , outX  | X ∈ H} ∪

{ lock, unlock, res, done }.
As a by-product, we show that the translation preserves the behavioural equivalence which is obtained from low bisimilarity by assuming all program variables to be low, and therefore observable.
If H = ∅, it is easy to see that L-bisimilarity reduces to the following:
Definition 3.11 [Behavioural equivalence on programs]

A symmetric relation S ⊆ (C × C) is a program bisimulation if C S D implies, for any state s such that ⟨C, s⟩ and ⟨D, s⟩ are well-formed:
If ⟨C, s⟩→ ⟨C', s'⟩, then there exists D' such that ⟨D, s⟩ '→ ⟨D', s'⟩ and C' S D'. Two programs C and D are behaviourally equivalent, written C D, if C S D for some program bisimulation S.
Similarly, the transitions '−→α H and the bisimilarity ∼H on configurations reduce
to the transitions	α	and the bisimilarity ∼ defined as follows:


cfg α


'	def
,⎪⎨ cfg α
cfg' or cfg = cfg' if α = τ

'−→ cfg	=
⎪, cfg −α→ cfg'	otherwise

Definition 3.12 [Bisimulation on configurations]
A symmetric relation S on configurations is a bisimulation if ⟨C, s⟩ S ⟨D, t⟩ implies
s = t and, for any α ∈ ActEnv ∪ {τ }:


If ⟨C, s
α	C', s'⟩, then there exists D' such that ⟨D, t
α	D', t'⟩ and

⟩ −→ ⟨
⟩ '−→ ⟨
⟨C', s'⟩ S ⟨D', t'⟩.

Then ⟨C, s⟩ and ⟨D, t⟩ are bisimilar, written ⟨C, s⟩ ∼ ⟨D, t⟩, if ⟨C, s⟩ S ⟨D, t⟩ for some bisimulation S.
Proposition 3.13 (Characterisation of   in terms of ∼)
Let C, D be programs. Then C  D if and only if for any state s such that ⟨C, s⟩
and ⟨D, s⟩ are well-formed, we have ⟨C, s⟩∼ ⟨D, s⟩.
Theorem 3.14 (Behavioural equivalence is preserved by the translation)

If C  D, then for any state s such that ⟨C, s⟩ is well-formed, [[⟨C, s⟩]] ≈ [[⟨D, s⟩]].
Note that the equivalence  is rather intensional. For instance it does not in general equate the two programs nil; P and P . On the other hand we have P ; nil  P , as well as (nil  P )  P . Indeed, as soon as two programs stop modifyng the memory, they are identified by . This is not surprising since is derived from L, which was designed to capture precisely this property as regards the low memory. However, we may wish to slightly relax  so as to obtain a more natural behavioural equivalence
∼= on PARIMP, such that nil; P ∼= P . This can be obtained as follows.
Let ⟨C, s⟩ ~ ⟨C', s'⟩ denote the administrative transition relation obtained by using only the subset of rules (Seq-Op2), (ParL-Op1), (ParL-Op2), (ParR- Op1) and (ParR-Op2) of Figure 2. We may then define an equivalence ∼= which always identifies programs whose behaviours differ only for administrative moves.
Definition 3.15 [nil-insensitive behavioural equivalence on programs]
A symmetric relation S ⊆ (C×C) is a nil-insensitive program bisimulation if C S D
implies, for any state s such that ⟨C, s⟩ and ⟨D, s⟩ are well-formed:

If ⟨C, s⟩→ ⟨C', s'⟩, then there exists D' such that ⟨D, s⟩ ~∗'→ ~∗ ⟨D', s'⟩
and C' S D'.
The nil-insensitive behavioural equivalence ∼= is then defined by: C ∼= D if C S D
for some nil-insensitive program bisimulation S.
The definition of L-bisimulation and L-security could be weakened in a similar way. We conjecture that all the results proved in this section would easily extend to the nil-insensitive notions of L-security and behavioural equivalence.
Finally, we may wonder whether the arrow '→ could be replaced by the arrow →∗ in the definition of L-bisimulation (and behavioural equivalence), while preserving our results. An advantage of this choice would be to open the possibility for a full abstraction result (restricted to the processes obtained as images of programs),
since the resulting security property, which is that proposed by Sabelfeld and Sands in [27], is fully time-insensitive and thus very close in spirit to weak bisimulation.
Indeed, it is easy to see that our translation is not fully abstract (with respect to any of our security properties, whether nil-sensitive or nil-insensitive). For instance the process of Example 3.4 is not secure nor nil-insensitive secure, while its encoding into CCS is secure. For the nil-sensitive security property, another reason of failure for full abstraction is illustrated by the program:
C = (if XH =0 then YL := 0 else nil ; YL := 0)
Here [C ] is secure while C is not secure (however it is nil-insensitive secure).
At this point of discussion, it may seem surprising that a full abstraction result could be obtained in [9] for a time-sensitive security notion, which is stronger than our security properties and thus further away from weak bisimulation. In fact, as mentioned earlier, this full abstraction result was obtained by using special tick actions in the translation, whose function was precisely to enforce a correspondence between steps in the source program and their encodings in the target process. Indeed, it is easy to see that full abstraction would fail for time-sensitive security in the absence of such tick actions. For consider the program:
C' = (if XH =0 then loop else nil)
Both C' and the program C above are insecure with respect to the time-sensitive security property of [9]. On the other hand, the encodings of these programs without tick actions (i.e. according to the translation of Figure 3), are secure.
The question of whether our results could be extended to the security property of Sabelfeld and Sands [27], and whether a “natural” full abstraction result could be obtained in that case, is left for further investigation.

The translation does not preserve security types
In this section, we show that the type system presented in Section 2 is not reflected by the translation of Figure 3 (nor by that of Figure 4). We then sketch a solution to overcome this problem.

Consider the program C = (XH := XH +1 ; YL := YL + 1), which is typable in the type systems of e.g. [30,27,29,4]. This program is translated to the process [C]]:

(νd)( lock. (ν res1) (getXH (x). res1⟨x + 1⟩| res1(z1). putXH ⟨z1⟩. unlock. d)  |
d. lock. (ν res2) (getYL (y). res2⟨y + 1⟩| res2(z2). putYL ⟨z2⟩. unlock. done)) 
Now, it is easy to see that [C ] is not typable in the security type system of Section 2. Indeed, there is no assignment of security levels for the channels lock, unlock and d which allows [C ] to be typed. First of all, note that channels lock and unlock must have the same security level since each of them follows the other in the semaphore (and in the registers). Consider now the two top parallel components of [C]]: for the first component to be typable, unlock and d should be high (and thus lock should be high too); for the second component to be typable, d and lock should be low (and thus unlock should be low too). In other words, the two components impose conflicting constraints on the levels of channels lock, unlock and d.
A possible solution to this problem is to relax the type system by treating more liberally channels like lock, unlock and d (and hence done, since d is obtained from done by renaming), which carry no values and are restricted. The idea, bor- rowed from previous work [16,14,15,33,17], is that actions on these channels are data flow irrelevant insofar as they are guaranteed to occur, since in this case their occurrence does not bring any information. The typing rule (Sum) may then be made less restrictive for these actions, while keeping their security level to h. It can be observed that replacing rule (Sum) by the rule (Sum-Lax) discussed at page 8 would not solve the problem.
Note that action lock is eventually enabled from any state of [⟨C, s⟩]], since the semaphore and the pool of registers cyclically come back to their initial state. The situation is not as simple as concerns the channel done, or more precisely one of its renamings d, as the occurrence of the (unique) complementary action d could be prevented by divergence or deadlock. Notice however that deadlock cannot arise in a process [⟨C, s⟩ ], because the source configuration ⟨C, s⟩ can only contain livelocks, due to busy waiting and thus to while loops. Now, by imposing restrictions on the use of loops and conditionals in programs (as proposed in [30,27,29,4]), one may either enforce the occurrence of d in their images, or make sure that if this occurrence is uncertain because of some high test, then no low memory change can depend on it. In conclusion, provided the set of source programs is appropriately restricted by typing, the lock channels and the relay channels obtained by renaming channel done can be safely be given level h.
The formalisation of a type system along these lines, as well as the study of a more general security type system for state-oriented noninterference on CCS, is the subject of current work.

Conclusion and related work
We addressed the question of relating language-based and process-based security, by focussing on a simple parallel imperative language `a la Volpano and Smith [30] and on Milner’s calculus CCS [18]. We presented an encoding from the former to the latter, essentially a variant of Milner’s well-known translation, and showed that it preserves a time-insensitive security property. In doing so, we extended previous work by Focardi, Rossi and Sabelfeld [9] in several respects: (1) we considered a parallel rather than a sequential language, (2) we studied a time-insensitive rather than a time-sensitive security property, (3) we examined two variants of Milner’s translation, which are both simpler than that used in [9], and (4) we proposed a security type system for PBNDC on CCS which, although failing to reflect a security type system for the source language, appears to be a good step towards that purpose. As concerns related work, besides the paper [25] by Mantel and Sabelfeld, who were the first to establish security-preserving translations between programming languages and specification formalisms, we should mention the thorough comparison of language-based and process-based security carried out in [14] by Honda and Yoshida, who proposed type-preserving embeddings of powerful languages, both imperative and functional, into a variant of the asynchronous π-calculus. Closely related to [14] is Kobayashi’s security type system [17], which is equipped with a type inference algorithm. In both cases, the process calculus is more expressive than CCS and the type system is rather complex, as it is meant to grant both a security property and other correctness properties. As regards the expressiveness of the considered languages, our work is clearly less ambitious than [14]. However, an advantage of focussing on a first-order process calculus which does not require any classical typing, is that the typing requirements for security may be clearly isolated.
Moreover, some issues related to atomicity and to the impact of the sum operator
on security, arise in CCS but not in the asynchronous π-calculus.
Acknowledgments
I would like to thank Maria-Grazia Vigliotti for her contribution at an early stage of this work, Fr´ed´eric Boussinot for helpful remarks, and the anonymous referees for useful feedback on the submitted version.

References
Johan Agat. Transforming out timing leaks. Proceedings of POPL ’00, ACM Press, pages 40–53, 2000.
A. Almeida Matos, G. Boudol and I. Castellani. Typing noninterference for reactive programs. Journal of Logic and Algebraic Programming 72: 124-156, 2007.
G. Barthe and L. Prensa Nieto. Formally verifying information flow type systems for concurrent and thread systems. In Proceedings of FMSE’04, 2004.
G. Boudol and I. Castellani. Noninterference for Concurrent Programs and Thread Systems. Theoretical Computer Science 281(1): 109-130, 2002.
A. Bossi, R. Focardi, C. Piazza and S. Rossi. Verifying persistent security properties. Computer Languages, Systems and Structures 30(3-4): 231-258, 2004.

I. Castellani. State-oriented noninterference for CCS (full version). INRIA Research Report, October 2007. URL: http://www-sop.inria.fr/mimosa/personnel/Ilaria.Castellani/main-publications.html.
R. Focardi and S. Rossi. Information flow security in dynamic contexts. In Proceedings of the 15th IEEE Computer Security Foundations Workshop, 2002.
R. Focardi and R. Gorrieri. Classification of Security Properties (Part I: Information Flow). In Foundations of Security Analysis and Design - Tutorial Lectures (R. Focardi and R. Gorrieri, Eds.), volume 2171 of LNCS, Springer, 2001.
R. Focardi, S. Rossi and A. Sabelfeld. Bridging Language-Based and Process Calculi Security. In
Proceedings of FoSSaCs’05, volume 3441 of LNCS, Springer-Verlag, 2005.
S. Crafa and S. Rossi. A theory of noninterference for the π-calculus. In Proceedings of Symp. on Trustworthy Global Computing TGC’05, volume 3705 of LNCS, Springer-Verlag, 2005.
M. Hennessy and J. Riely. Information flow vs resource access in the asynchronous π-calculus. ACM TOPLAS 24(5): 566-591, 2002.
M. Hennessy. The security π-calculus and noninterference. Journal of Logic and Algebraic Programming 63(1): 3-34, 2004.
K. Honda, V. Vasconcelos and N. Yoshida. Secure information flow as typed process behavior. In
Proceedings of ESOP’00, volume 1782 of LNCS, pages 180-199, Springer-Verlag, 2000.
K. Honda and N. Yoshida. A uniform type structure for secure information flow. In Proceedings of POPL’02, ACM Press, pages 81-92. January, 2002.
N. Yoshida, K. Honda and M. Berger. Linearity and bisimulation. In Proceedings of FoSSaCs’02, volume 2303 of LNCS, pages 417-433, Springer-Verlag, 2002.
N. Kobayashi, B. Pierce and D. Turner. Linearity and the π-calculus. In Proceedings of POPL’96, ACM Press, pages 358-371, 1996.
N. Kobayashi. Type-based Information Flow Analysis for the π-Calculus. Acta Informatica 42(4-5): 291-347, 2005.
R. Milner. Communication and Concurrency. Prentice-Hall International, 1989.
A. Myers. JFlow: practical mostly-static information flow control. In Proceedings of POPL’99, ACM Press, pages 228-241, 1999.
A. Myers, L. Zheng, S. Zdancewic, S. Chong and N. Nystrom. Jif: Java information flow. Software release, http://www.cs.cornell.edu/jif, 2001.
F. Pottier. A Simple View of Type-Secure Information Flow in the π-Calculus. In Proceedings of the 15th IEEE Computer Security Foundations Workshop, pages 320–330, 2002.
F. Pottier and V. Simonet. Information flow inference for ML. ACM TOPLAS 25(1): 117-158, 2003.
V. Simonet. The FlowCaml system: documentation and user manual. INRIA RR n. 0282, 2003.
P. Ryan and S. Schneider. Process algebra and noninterference. In Proceedings of the 12th IEEE Computer Security Foundations Workshop, pages 214–227, 1999.
H. Mantel and A. Sabelfeld. A unifying approach to the security of distributed and multi-threaded programs. Journal of Computer Security 11(4): 615–676, 2003.
A. Sabelfeld and A. C. Myers, Language-based information-flow security. IEEE Journal on Selected Areas in Communications 211:5-19, 2003.
A. Sabelfeld and D. Sands. Probabilistic Noninterference for Multi-threaded Programs. In Proceedings of the 13th IEEE Computer Security Foundations Workshop, pages 200-214, 2000.
D. Sangiorgi and D. Walker. The π-calculus: a Theory of Mobile Processes. Cambridge University Press, 2001.
G. Smith. A new type system for secure information flow. In Proceedings of the 14th IEEE Computer Security Foundations Workshop, pages 115–125, 2001.
G. Smith and D. Volpano. Secure information flow in a multi-threaded imperative language. Proceedings of POPL ’98, ACM Press, pages 355–364, 1998.
D. Volpano and G. Smith. Probabilistic Noninterference in a Concurrent Language. Journal of Computer Security 7(2-3): 231–253, 1999.
D. Volpano, G. Smith and C. Irvine. A Sound Type System for Secure Flow Analysis. Journal of Computer Security 4(3):167–187, 1996.
S. Zdancewic and A. Myers. Secure information flow via linear continuations. Higher Order and Symbolic Computation 15(2-3):209-234, 2002.
