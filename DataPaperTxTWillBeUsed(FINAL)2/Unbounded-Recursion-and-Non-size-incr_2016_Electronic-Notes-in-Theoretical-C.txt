Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 322 (2016) 197–210
www.elsevier.com/locate/entcs

Unbounded Recursion and Non-size-increasing Functions
S. Mazzanti1
Dipartimento di Culture del Progetto Universit`a Iuav di Venezia Fondamenta delle Terese 2206, 30123 Venezia, Italy

Abstract
We investigate the computing power of function algebras defined by means of unbounded recursion on notation. We introduce two function algebras which contain respectively the regressive logspace computable functions and the non-size-increasing logspace computable functions. However, such algebras are unlikely to be contained in the set of logspace computable functions because this is equivalent to L = P. Finally, we introduce a function algebra based on simultaneous recursion on notation for the non-size-increasing functions computable in polynomial time and linear space.
Keywords: recursion on notation, logspace computable function, polynomial time computable function.


Introduction
Since the introduction of the Grzegorczyk’s hierarchy, algebras of subrecursive func- tions have been defined by means of bounded recursion schemes, and from the early 1990s also by means of predicative recursion schemes.
However, both bounded and predicative recursion do not correspond to pro- gramming constructs of real-world programming languages, inhibiting the benefits of a major integration of complexity theory and programming language theory [4,5]. Function algebras mostly characterize function complexity classes containing polynomial growth functions, and either bounded recursion or predicative recursion is needed to avoid functions with exponential growth. On the other hand, com- putational complexity is mainly concerned with decision problems represented as
languages or more generally as relations over a suitable data type.
In [7], the relations on natural numbers decidable in linear space and the lan- guages decidable in logarithmic space have been characterized by means of two

1 Email: mazzanti@iuav.it

http://dx.doi.org/10.1016/j.entcs.2016.03.014
1571-0661/© 2016 The Author. Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

function algebras containing very simple base functions and closed with respect to substitution and unbounded simultaneous recursion.
One algebra contains a set of regressive functions computable in linear space; the other contains a set of non-size-increasing functions computable in logarithmic space. 2
However, they contain all the characteristic functions of the decision problems solvable in linear and logarithmic space, respectively.
These results are instances of a general fact: if the base functions of a function algebra do not increase too rapidly, unbounded recursion can be used to describe interesting complexity classes. For example, both regressive and non-size-increasing functions are closed with respect to substitution and recursion on notation.
In [2], Predecessor Machines (Register Machines without increment instructions) have been introduced as a computation model for regressive functions. In particular, it has been shown that the total functions computable by Predecessor Machines are the regressive functions of Grzegorczyk’s class E2.
Type systems for the non-size-increasing polynomial time functions have been extensively studied, see e.g. [3]. Such systems constitute an alternative to predica- tive recursion which rules out not only recursive definitions leading to exponential growth, but also natural algorithms computing non-size-increasing functions.
Therefore, it seems that regressive and non-size-increasing functions could play a remarkable role in computational complexity.
Let R(F) be the set of number-theoretic functions defined as the closure with respect to substitution and recursion on notation of a list F of basic functions, the constant functions and the projection functions.
Algebra R(P ) where P is the predecessor function, has been studied in [8,9] fol- lowing [7]. Algebra R(P ) is a set of regressive logspace computable functions which contains all the sharply bounded logspace computable functions. 3 Moreover, R(P ) is the set of functions computable by Regressive Machines, which are a polynomial time version of structured Predecessor Machines [2].
In this paper we study new function algebras which extend algebra R(P ) in order to shed some light on some open questions suggested in [9]. For instance, we do not know whether R(P ) equals the set of regressive logspace computable functions.
In Section 3, we consider the algebra R(bs0, bs1) where si(x) = 2x + i and bsi(x, y) = si(x) if si(x) ≤ y and bsi(x, y) = x otherwise. Algebra R(bs0, bs1) contains the regressive logspace computable functions, but we give strong evidence that R(bs0, bs1) is unlikely to be contained in the set FL of logspace computable functions because R(bs0, bs1) ⊆ FL is equivalent to L = P. In the same way, we show that if R(P ) contained all the regressive logspace computable functions then L = P would be true.

2 The values of a regressive function are bounded by the maximum of its arguments and a constant whereas the size of the values of a non-size-increasing function is bounded by the maximum of the sizes of its arguments and a constant.
3 A function is sharply bounded iff its values can be stored in logarithmic space.

In Section 4, we consider the algebra R(sbs0, sbs1) where sbsi(x, y) = si(x) if |si(x)| ≤ |y| and sbsi(x, y) = x otherwise. Algebra R(sbs0, sbs1) contains the non-size-increasing logspace computable functions and coincides with algebra R(P ) extended with a concatenation recursion on notation operator.
Finally, in Section 5 we consider algebra S(sbs0, sbs1) obtained from R(sbs0, sbs1) by replacing recursion on notation with simultaneous recursion on notation and show that it coincides with the set of non-size-increasing functions computable in polynomial time and linear space. Using the techniques of [9], one can show that R(P ) = S(P ), but at present we do not know whether R(sbs0, sbs1)= S(sbs0, sbs1).
A possible continuation of this work could address such question as well as the search of function algebras for the regressive and non-size-increasing functions of well-known complexity classes.

Preliminaries
In this paper, we will only consider functions with finite arity on the set
N = {0, 1,.. .} of natural numbers.
From now on, we agree that x, y, z, u, v, w, i, j, k, l, n, m range over N, that a, b, c range over positive integers, that x, y, z range over sequences (of fixed length) of natural numbers, that p, q, r range over integer polynomials with non negative co- efficients (unless otherwise stated) and that f, g, h range over functions.
A function f is a polynomial growth function iff there is a polynomial p majoriz- ing (the length of) f , i. e. such that |f (x)| ≤ p(|x|) or, equivalently, f (x) < 2p(|x|) for any x, where |x1,..., xn| is the sequence |x1|,..., |xn| and |x| = [log2(x + 1)| is the number of bits of the binary representation of x. Moreover, f is sharply bounded iff there is a polynomial p such that f (x) ≤ p(|x|) for any x, f is regressive iff there is some constant k such that f (x) ≤ max(x, k) for any x, see [2] and f is non-size- increasing iff there is some constant k such that |f (x)|≤ max(|x|, k) for any x. We denote REG the set of regressive functions and NSI the set of non-size-increasing functions.
We will use the following unary functions:  the binary successor functions s0 : x '→ 2x and s1 : x '→ 2x +1 ; for i ∈ {0, 1} the bounded binary successor functions bsi : x, y '→ si(x) if si(x) ≤ y and bsi : x, y '→ x otherwise; for i ∈ {0, 1} the size bounded binary successor functions sbsi : x, y '→ si(x) if |si(x)| ≤ |y| and sbsi : x, y '→ x otherwise; the constant functions Cy : x '→ y for any y ∈ N; the signum function sg : x '→ min(x, 1); the cosignum function cosg : x '→ 1 − sg(x); the length function len : x '→ |x|.
We will also use the following functions: the modiﬁed subtraction function sub : x, y '→ x−˙ y = max(x − y, 0); the predecessor function P : x '→ x−˙ 1; the quadratum function quad : x '−→ x2 ; the division function quot : x, y '−→ [x/y♩; the remainder function rem : x, y '−→ x − y [x/y♩; the conditional function cond : x, y, z '→ y if x = 0 and cond : x, y, z '→ z otherwise; the bit function bit : x, y '→ rem([x/2y♩ , 2); the most signiﬁcant part function MSP : x, y '→ [x/2y♩; the least signiﬁcant part

function LSP : x, y '−→ x mod 2y.
Finally, we will use the following operators on functions:
the recursion on notation operator RN (g, h0, h1) transforming functions g : Na → N, h0 : Na+2 → N and h1 : Na+2 → N into the function f : Na+1 → N such that
f (0, y)= g(y) ,
f (si(x), y)= hi(x, y,f (x, y))
where i ∈ {0, 1} and x > 0 when i = 0. Moreover, the bounded recursion on nota- tion BRN (g, h0, h1, l) of g, h0, h1,l is the function f such that f = RN (g, h0, h1) and f (x, y) ≤ l(x, y) ; 
the    simultaneous    recursion    on    notation    operator
SRN (g1,..., gb, h0, h1,..., h0, h1) transforming functions g1,..., gb : Na → N
1	1	b	b
and h0, h1,..., h0, h1 : Na+b+1 → N into the functions f1,..., fb : Na+1 → N such
1	1	b	b
that
fj(0, y)= gj(y) ,
fj(si(x), y)= hj(x, y, f1(x, y),..., fb(x, y))
where 1 ≤ j ≤ b, i ∈ {0, 1} and x > 0 when i = 0;
the substitution operator SUBST (g1,..., gb, h) transforming functions g1,..., gb : Na → N and function h : Nb → N into the function f : Na → N such that f (x)= h(g1(x),..., gb(x)) .
For any function f : Na → N, set bitf (x, i)= bit(f (x), i) and


f (x)[i, j]= MSP (LSP (f (x, y),i + 1), j)= 
j≤k≤i
bitf (x, k)2k−j.

Note that f (x)[i, j] is the number with binary representation the bits from position
j to position i of f (x).
As usual, the characteristic function of a predicate Q on natural numbers is the function f (x) returning 1 if Q(x) is true, 0 otherwise.
For any functions f1,..., fa, any sets F1,..., Fb of functions and any set
{op1,..., opc} of operators, let clos(f1,..., fa, F1,..., Fb; op1,..., opc) be the in- ductive closure of {f1,..., fa} ∪ F1 ∪ ... ∪ Fb ∪ I with respect to {op1,..., opc} where I is the set of the projection functions Ia[i]: x1,..., xa '−→ xi with any arity a and 1 ≤ i ≤ a.
Finally, let

and
R(F) = clos(F, {Cn}n; SUBST, RN )
S(F) = clos(F, {Cn}n; SUBST, SRN ).

By definition, we have that R(F) ⊆ S(F). We set R(f1,..., fa)= R({f1,..., fa}).

Lemma 2.1 If F is a set of regressive (non-size-increasing) functions, then also
R(F) and S(F) are sets of regressive (non-size-increasing) functions.
Lemma 2.2 If F is a set of polynomial time regressive (non-size-increasing) functions, then also R(F) and S(F) are sets of polynomial time regressive (non-size-increasing) functions.
The following results concerning class R(P ) have been obtained in [8,9]:
R(P ) ⊆ FL;
the sharply bounded logspace computable functions coincide with the sharply bounded functions in R(P );
the characteristic functions of logspace predicates coincide with the 0 − 1 valued functions in R(P ).
We do not know whether R(P ) equals the set of regressive logspace computable functions.
Recursion on notation and regressive functions
In this section we study algebra R(bs0, bs1). First, we show that R(bs0, bs1) contains all the logspace computable regressive functions.
Then, we give strong evidence that R(bs0, bs1) ⊆ FL is not true. Indeed, R(bs0, bs1) contains a function which can decide the iterated mod problem [6], a P-complete problem under logspace reductions. Thus we may conclude that R(bs0, bs1) ⊆ FL is equivalent to L = P.
In the same way, we show that if R(P ) contained all the regressive logspace computable functions then L = P would be true.
We start by noting that, from the results of [8,9] listed at the end of the Prelim- inaries, class R(bs0, bs1) contains all the regressive logspace computable functions.

Theorem 3.1 FL ∩ REG ⊆ R(bs0, bs1).
Proof. First, P ∈ R(bs0, bs1) because
P (0) = 0,P (s0(x)) = s1(P (x)),P (s1(x)) = s0(x)
and P (x)= p(x, x) where
p(0, y)= 0,
p(s0(x), y)= bs1(p(x, y), y),
p(s1(x), y)= bs0(x, y).

Assume that f  ∈ FL ∩ REG.  Then f (x) ≤ max(x, k) for some k and bitf (x, | max(x, k)|−˙ |si(u)|) ∈ R(P ) ⊆ R(bs0, bs1) because it is a 0 − 1 valued logspace computable function. Thus we compute f (x) by concatenating its bits. To

this aim we define the function
g(0, x)	= 0 ,
g(si(u), x) = bsbitf (x,| max(x,k)|−˙ |si(u)|)(g(u, x), max(x, k))
such that g(max(x, k), x)= f (x) and so f ∈ R(bs0, bs1).	2
One could ask whether R(bs0, bs1) ⊆ FL since it is obtained by adding the bounded successors to R(P ). Below, we show that this is very unlikely to be true. Indeed, we will show that the iterated mod problem [6], which is a P- complete problem under logspace reductions, is decidable in R(bs0, bs1) and so R(bs0, bs1) ⊆ FL is equivalent to L = P .
The iterated mod problem asks if the sequence of remainders rem(... rem(rem(a, b1), b2),..., bn) is zero or not, where a, b1,..., bn is a se- quence of positive integers. We consider the coding C of number sequences of any length such that C(b1,..., bn) is the number whose binary representation is 10bn ... 10b1 where m is the bit string obtained by doubling the bits of m:
0 = λ, si(m) = mii.  The following theorem shows that there is a function
itm ∈ R(bs0, bs1) such that
itm(a, C(b1,..., bn)) = cosg(rem(... rem(rem(a, b1), b2),.	, bn)),
i.e. itm decides the iterated mod problem.
Theorem 3.2 There is a function itm ∈ R(bs0, bs1) which decides the iterated mod problem.
Proof. By Theorem 3.1, cosg, rem ∈ R(bs0, bs1). Now we show that there are functions tail, head, l in R(bs0, bs1) such that tail(C(b1,..., bn+1)) = C(b1,.  , bn),
head(C(b1,..., bn)) = bn, and l(C(b1,.  , bn)) = n.
First, let
t(0, b)	= b, 
t(s (x), b) =  div(t(x, b), 4)	if bit(t(x, b), 0) = bit(t(x, b), 1)
t(x, b)	otherwise

and note that t ∈ R(P ) ⊆ FL and the string 10b1 ... 10bn10 is the binary represen- tation of t(C(b1,..., bn+1), C(b1,..., bn+1)).
Then tail(b) = div(t(b, b), 4) and head(b) = extr2(LSP (b, |b|−˙ |t(b, b)|)) belong to R(bs0, bs1) where extr2 :  i≤n xi2i '→  i≤[n/2♩ x2i2i is in R(bs0, bs1) by Theo- rem 3.1 because extr2 is a regressive logspace computable function. Moreover, l and x '→ 2l(x) − 1 are in R(bs0, bs1) by Theorem 3.1. Indeed, l is a logspace computable function which counts the occurrences of string ”10” in the binary representation

of its argument and can be defined by sharply bounded recursion as follows
l(0)	= 0 ,
l(s (x)) =  l(x)+1	if (odd(|x|) ∧ (i = 0) ∧ bit(x, 0) = 1),
l(x)	otherwise
where l(x) < |x| and odd is the characteristic function of odd numbers. Furthermore 2l(x) − 1 is a regressive function because 2l(x) − 1 ≤ 2|x|−1 − 1 ≤ x and it belongs to R(bs0, bs1) by Theorem 3.1.
Recall that the function itg(x, z)= g|x|(z) belongs to R(bs0, bs1) for any regres- sive function g ∈ R(bs0, bs1).
Then the function C−(x, y) = head(ittail(div(x, 2), y)) belongs to R(bs0, bs1) and we have that
C−(x, C(b1,..., bn)) = head(tail|x|−˙ 1(C(b1,..., bn))) = b
for 1 ≤ |x|≤ n. Therefore, for
f (0, a, b)	= a, 
f (si(x), a, b) = rem(f (x, a, b), C−(x, b)),
we obtain
f (2l(C(b1,...,bn)) − 1, a,C(b1,..., bn)) = rem(... rem(rem(a, b1), b2),..., bn)
and itm(a, b)= cosg(f (2l(b) − 1, a, b)).	2
From the theorem above, we obtain immediately the following statement.
Theorem 3.3 L = P ⇔ R(bs0, bs1) ⊆ FL.
Proof. By [6], the iterated mod problem is P-complete under logspace reductions. Hence, if R(bs0, bs1) ⊆ FL then itm ∈ L by Theorem 3.2 and so L = P. On the other hand, if L = P then FL = FP but by Lemma 2 R(bs0, bs1) ⊆ FP and therefore R(bs0, bs1) ⊆ FP = FL.	2
Since R(P ) is a set of regressive functions, it is natural to ask if it contains all the regressive logspace computable functions. The same strategy used to show Theorem 3.2 proves that this is unlikely to be true.
Theorem 3.4 If R(P )= FL ∩ REG then L = P.
Proof. We give only a sketch of the proof. If R(P )= FL ∩ REG then the proof of Theorem 3.2 can be adapted to show that itm ∈ R(P ). But itm ∈ R(P ) implies itm ∈ L and so L = P because the iterated mod problem is P-complete.	2
Corollary 3.5 If R(P )= FL ∩ REG then R(P )= FP ∩ REG.

Proof. If R(P ) = FL ∩ REG then L = P .  Thus FL = FP and therefore
R(P )= FP ∩ REG.	2

Recursion on notation and non-size-increasing func- tions
In this section we show that algebra R(sbs0, sbs1) contains the non-size-increasing logspace computable functions and is the class of non-size-increasing functions ob- tained by extending algebra R(P ) with a concatenation recursion on notation op- erator.
Finally, we show that R(sbs0, sbs1) ⊆ FL is equivalent to L = P.
Consider the simple concatenation recursion on notation operator SCRN (h0, h1) transforming 0 − 1 valued functions h0, h1 : Na+1 → N into the function f : Na+1 → N such that
f (0, y)	= 0 ,
f (si(x), y) = shi(x,y)(f (x, y)) (i ∈ {0, 1} and x > 0 when i = 0) and set
CR(F) = clos(F, {Cn}n; SUBST, SCRN, RN ).
We start by noting that class CR(P ) contains all the non-size-increasing logspace computable functions.
Theorem 4.1 FL ∩ NSI ⊆ CR(P ).
Proof. Assume that f ∈ FL ∩ NSI. Then, |f (x)| ≤ max(|x|, k) for some k and bitf (x, max(|x|, k)−˙ |si(u)|) ∈ R(P ) ⊆ CR(P ) because it is a 0 − 1 valued logspace computable function. Therefore, by using SCRN , we define
g(0, x)	= 0 ,
g(si(u), x) = sbitf (x,max(|x|,k)−˙ |si(u)|)(g(u, x)) such that g(u, x)= f (x)[m, m−˙ |u|] where m = max(|x|, k).
Then f (x)= g(max(x, 2k − 1), x) and so f ∈ CR(P ).	2
Since the size bounded binary successor functions are non-size-increasing logspace computable functions, we obtain immediately the following corollary.
Corollary 4.2 sbs0, sbs1 ∈ CR(P ).
Now we show that the closure with respect to SCRN is equivalent to adding
sbs0 and sbs1 to the base functions.
Theorem 4.3 R(sbs0, sbs1)= CR(P ).

Proof. By Corollary 4.2, R(sbs0, sbs1) ⊆ CR(P ). On the other hand, to show that CR(P ) ⊆ R(sbs0, sbs1) it suffices to show that P ∈ R(sbs0, sbs1) and that R(sbs0, sbs1) is closed with respect to SCRN . The proof of P ∈ R(sbs0, sbs1) is similar to that of P ∈ R(bs0, bs1) in the proof of Theorem 3.1. As concerns the closure of R(sbs0, sbs1) under SCRN , consider the function

g(0, y, z)	= 0 ,
g(si(x), y, z) = sbshi(x,y)(g(x, y, z), z)
where h0, h1 : Na+1 → N are 0 − 1 valued functions in R(sbs0, sbs1), with i ∈ {0, 1} and x > 0 when i = 0. Also, note that


sbs

hi(x,y)
(u, z)=	sbs0(u, z)	if hi(x, y)=0 
sbs1(u, z)	otherwise

belongs to R(sbs0, sbs1). Then, for
f (0, y)	= 0 ,
f (si(x), y) = shi(x,y)(f (x, y))
we have f ∈ R(sbs0, sbs1) because f (x, y) = g(x, y, max(x, y)), max ∈ R(P ) and g ∈ R(sbs0, sbs1).  Note that it can be shown by induction on x that f (x, y)= g(x, y, z) for any z such that max(|x|, |y|) ≤ |z|.	2
Since R(bs0, bs1) ⊆ R(sbs0, sbs1), it is easy to see that Theorem 3.3 holds also for R(sbs0, sbs1).
Theorem 4.4 L = P ⇔ R(sbs0, sbs1) ⊆ FL.

Simultaneous recursion and non-size-increasing func- tions
In this section we show that the class S(sbs0, sbs1) coincide with the class of non-size-increasing functions computable in polynomial time and linear space.
We start by claiming that a statement analogous to Theorem 4.3 holds for alge- bra S(sbs0, sbs1). A proof can be derived from that of Theorem 4.3.
Theorem 5.1 S(sbs0, sbs1) = clos(P, {Cn}n; SUBST, SCRN, SRN ).
The following theorem recalls a function algebra for the functions computable in polynomial time and linear space, see [1, Theorem 3.45].
Theorem 5.2
FPTIMELINSPACE = clos(C0, s0, s1, max, quad; SUBST, BRN ).

Now we show that S(sbs0, sbs1) is a subset of the function algebra of Theo- rem 5.2.
For c, m > 0, let ⟨xc,..., x1; m⟩ =	i<c xi+12mi.  If xc,..., x1 < 2m then
xc,..., x1 are the base 2m digits of ⟨xc,..., x1; m⟩.
Theorem 5.3 S(sbs0, sbs1) ⊆ clos(C0, s0, s1, max, quad; SUBST, BRN ).
Proof. Set C = clos(C0, s0, s1, max, quad; SUBST, BRN ). We show the theorem by induction on S(sbs0, sbs1).
The induction basis and the induction step concerning substitution are trivial. In the following we sketch the proof of the induction step concerning simultaneous recursion on notation.
Let f1,..., fc be the functions defined by simultaneous recursion on notation from g1,..., gc, h0, h1,..., h0, h1 ∈ S(sbs0, sbs1).
1	1	c	c
Let m = max(|x, y|, b) and assume that |fi(x, y)| ≤ m. We define a function
f ∈ C such that f (x, y) encodes f1(x, y),..., fc(x, y) with a single number of cm
bits, i.e. f (x, y)= ⟨f1(x, y),..., fc(x, y); m⟩:
f (0, y)= ⟨gc(x, y),..., g1(x, y); m⟩ ,
f (si(x), y)=  hi (z1,..., zc),..., hi (z1,..., zc); m 
where zj = f (x, y)[jm − 1, (j − 1)m] for 1 ≤ j ≤ c and |f (x, y)|≤ c · max(|x, y|, b). Then fj ∈ C because fj(x, y)= f (x, y)[jm − 1, (j − 1)m].	2
The next lemma states that the class clos(C0, s0, s1, max, quad; SUBST, BRN ) contains linear growth functions only.
Lemma 5.4 For any f ∈ clos(C0, s0, s1, max, quad; SUBST, BRN ) there are b0
and c0 such that for any b ≥ b0 and c ≥ c0 we have |f (x)|≤ c · max(|x|, b).
If |f (x)|≤ c· max(|x|, b) then we say that b and c bound f . The following lemma is the bulk of the proof that
clos(C0, s0, s1, max, quad; SUBST, BRN ) ∩ NSI ⊆ S(sbs0, sbs1).
It states that any function f ∈ clos(C0, s0, s1, max, quad; SUBST, BRN ) can be ex- pressed as the concatenation of c functions in S(sbs0, sbs1) where c is a constant depending on f . The basic idea of the proof is the same as [7, Lemma 3.4]: repre- senting a block of cn bits as c blocks of n bits.
Lemma 5.5 For any f ∈ clos(C0, s0, s1, max, quad; SUBST, BRN ) with arity a there are b0 and c0 such that |f (x)| ≤ c0 · max(|x|, b0) and for any c ≥ c0 there are functions f1,..., fc : Nca+1 → N belonging to S(sbs0, sbs1) such that if c0 · max(|x|, b0) ≤ c|n|, then for any i ∈ {1,.  , c},
fi(x1c,..., x11,..., xac,.	, xa1, n)= f (x)[i|n|− 1, (i − 1)|n|]
where xj = ⟨xjc,..., xj1; |n|⟩ and xjk < 2|n| for 1 ≤ j ≤ a and 1 ≤ k ≤ c.

Proof. We show the lemma by induction on
C = clos(C0, s0, s1, max, quad; SUBST, BRN ).
Note that Lemma 5.4 states that for any f ∈ C there are infinite pairs (b0, c0) which bound f . For 1 ≤ i ≤ a, let xi = xic,..., xi1 be the sequence of digits in base 2|n| of xi.
Induction basis. Let f be any initial function of C and consider any constants
b0 and c0 which bound f . Since f ∈ FL, also
fj(x1,..., xa, n)= f (⟨x1c,..., x11; |n|⟩ ,... ⟨xac,..., xa1; |n|⟩)= f (x) belongs to FL and bitf′ ∈ S(sbs0, sbs1) by Theorems 4.1 and 4.3.
Assume c0 · max(|x|, b0) ≤ c|n| so that |f (x)| ≤ c0 · max(|x|, b0) ≤ c|n|. Then for fi(x1,..., xa, n)= fj(x1,..., xa, n)[i|n|− 1, (i − 1)|n|] where1 ≤ i ≤ c, we have
fi(x1,..., xa, n)= f (x)[i|n|− 1, (i − 1)|n|].
By Theorem 5.1 fi ∈ S(sbs0, sbs1) because fi ∈ FL ∩ NSI.
Induction step. Let f (x)= h(g(x)) and assume that there are b1 and c1 bound- ing g and b2 and c2 bounding h (to keep notation simple we consider the case of a single function g). Then for b0 = max(b1, b2) and c ≥ c0 = c1 ·c2 it is easy to see that fi(x1,..., xa, n)= hi(gc(x1,..., xa, n),..., g1(x1,..., xa, n), n) satisfies the lemma.
Now, consider function f defined by bounded recursion on notation
f (0, y)= g(y) ,
f (si(x), y)= hi(x, y, f (x, y))
where	f (x, y)	≤	p(x, y)	for	some	polynomial	p,	or	in	other	words,
|f (x, y)| ≤ c0 · max(|x|, |y|, b0) (we consider the case of a single parameter y to keep notation simple). We also assume that b0 and c0 bound g, h0 and h1.
Then, for c ≥ c0 there are functions g1,..., gc and functions h0, h1,..., h0, h1

such that

gi(y, m)= g(y)[i|m|− 1, (i − 1)|m|]
1	1	c	c

where c0 · max(|y|, b0) ≤ c|m| and y = yc,..., y1 is the sequence of digits in base 2|m| of y, and
hj(x, y, z, r)= hj(x, y, z)[i|r|− 1, (i − 1)|r|]
where c0 · max(|x|, |y|, |z|, b0) ≤ c|r| and x = xc,..., x1, y = yc,..., y1 and
z = zc,..., z1 are the sequences of digits in base 2|r| of x, y, z, respectively.

Furthermore, for 1 ≤ i, k ≤ c and j ∈ {0, 1}, we define functions hj
such that



hj (u, x, y, z, r)= hj(0,..., 0, MSP (xc, |r|−˙ |u|), xj ,..., xj
, y, z, r)

i,k	i	1	k—1


where
xj = LSP (xc—(l—1), |r|−˙ |u|) ∗ MSP (xc—l, |r|−˙ |u|)

for 1 ≤ l < k and v ∗ w = v · 2|w| + v.

Note that LSP (xc—(l—1), |r|−˙ |u|) ∗ MSP (xc—l, |r|−˙ |u|) ∈ S(sbs0, sbs1) because it is computable in logarithmic space and its length is bounded by |r|. Now, for 1 ≤ i, k ≤ c consider functions fi,k such that
fi,1(0, x, y, n)= gi(y, n) ,

fi,1(sj(u), x, y, n)= hj
(u, x, y, fc,1(u, x, y, n),..., f1,1(u, x, y, n), n),

and for 1 < k ≤ c,
fi,k(0, x, y, n)= fi,k—1(n, x, y, n) ,

fi,k(sj(u), x, y, n)= hj
(u, x, y, fc,k(u, x, y, n),..., f1,k(u, x, y, n), n).

Thus, for 1 ≤ k ≤ c and c0 · max(|x|, |y|, b0) ≤ c|n| we have |fi,k(n, x, y, n)| ≤ |n|
and
fi,k(n, x, y, n)= f (⟨xc,..., xc—k+1; |n|⟩ , y)[i|n|− 1, (i − 1)|n|].
Finally, fi(x, y, n)= fi,c(n, x, y, n)= f (x, y)[i|n|− 1, (i − 1)|n|].	2
Theorem 5.6
clos(C0, s0, s1, max, quad; SUBST, BRN ) ∩ NSI ⊆ S(sbs0, sbs1).
Proof. By the lemma above, for any f ∈ clos(C0, s0, s1, max, quad; SUBST, BRN ) of arity a there are b0 and c0 such that |f (x)|≤ c0 · max(|x|, b0) and for any c ≥ c0 there are functions f1,..., fc : Nca+1 → N belonging to S(sbs0, sbs1) such that if c0 · max(|x|, b0) ≤ c|n| then for any i ∈ {1,.  , c},
fi(x1c,..., x11,..., xac,.	, xa1, n)= f (x)[i|n|− 1, (i − 1)|n|]
where xj = ⟨xjc,..., xj1; |n|⟩ and xjk < 2|n| for 1 ≤ j ≤ a and 1 ≤ k ≤ c. But, if f is non-size-increasing there is some b ≥ b0 such that |f (x)| ≤ max(|x|, b) and we obtain f1(0,..., 0, x1,..., 0,..., 0, xa, max(x, 2b − 1)) = f (x)[m − 1, 0] = f (x) for m = max(|x|, b).	2
From Theorem 5.3, Theorem 5.6 and Theorem 5.2 we obtain immediately the following characterization of non-size-increasing polynomial time and linear space computable functions.
Theorem 5.7
S(sbs0, sbs1) = clos(C0, s0, s1, max, quad; SUBST, BRN ) ∩ NSI
= FPTIMELINSPACE ∩ NSI.

Finally, we have a new characterization of the predicates computable in polyno- mial time and linear space.
Corollary 5.8 The characteristic functions of polynomial time and linear space computable predicates coincide with the 0 − 1 valued functions in S(sbs0, sbs1).

Conclusions
In this paper we have continued the study started in [7,8,9] on the computing power of pure recursion schemes which avoid both syntactical constraints and bounds on (the growth rate of) functions.
We have introduced three new function algebras extending the algebra R(P ) of [8,9] in order to shed some light on some open questions suggested in [9].
First, we have considered the algebra R(bs0, bs1). We have shown that R(bs0, bs1) contains the regressive logspace computable functions, but we have given strong evidence that R(bs0, bs1) is not contained in the set of logspace computable functions because R(bs0, bs1) ⊆ FL is equivalent to L = P. We have also shown that if R(P ) contained all the regressive logspace computable functions then L = P would be true.
Then, we have considered the algebra R(sbs0, sbs1). We have shown that R(sbs0, sbs1) contains the non-size-increasing logspace computable functions and coincides with algebra R(P ) extended with a concatenation recursion on notation operator. However, even in this case it is unlikely that R(sbs0, sbs1) ⊆ FL because R(sbs0, sbs1) ⊆ FL is equivalent to L = P.
Finally, we have considered algebra S(sbs0, sbs1) and we have shown that it coincides with the set of non-size-increasing functions computable in polynomial time and linear space. Summarizing the results of this paper, we have
R(bs0, bs1) Ç R(sbs0, sbs1) ⊆ S(sbs0, sbs1)= FPTIMELINSPACE ∩ NSI
where the leftmost inclusion is strict because sbs0 and sbs1 are not regressive. Using the encoding technique of regressive machines introduced in [9, Section 6], one can show that R(P )= S(P ), but it does not seem possible that such technique can be applied to show that R(sbs0, sbs1)= S(sbs0, sbs1). A possible continuation of this work could address such question as well as the search of function algebras for the regressive and non-size-increasing functions of well-known complexity classes.

References
P. Clote, Computation models and function algebras, in Handbook of Computability Theory, ed. E.R. Griffor, Elsevier (1999) 589-681.
P. C. Fischer, J. C. Warkentin, Predecessor Machines, J. Comput. System Sci. 8 (1974) 190-219.
M. Hofmann, Linear types and non-size-increasing polynomial time computation, Inform. and Comp.
183 (2003) 57-85.
N. D. Jones, Computability and Complexity from a Programming Perspective, MIT Press, Cambridge, MA, 1997.
N. D. Jones, LOGSPACE and PTIME characterized as programming languages, Theoret. Comput. Sci. 228 (1999) 151-174.
H. J. Karloff, W. L. Ruzzo, The Iterated Mod Problem, Inform. and Comp. 80 (1989) 193-204.
L. Kristiansen, Neat algebraic characterizations of LOGSPACE and LINSPACE, Comput. Complexity
14 (2005) 72-88.

S. Mazzanti, Logspace computability and regressive machines, ICTCS 2014, Ceur Workshop Proceedings
1231 (2014) 285-289, URL: http://ceur-ws.org/Vol-1231/short8.pdf.
S. Mazzanti, Regressive computations characterize logarithmic space, URL: http://rice.iuav.it/414/, submitted for publication.
