

Electronic Notes in Theoretical Computer Science 265 (2010) 97–122
www.elsevier.com/locate/entcs

Bayesian Authentication: Quantifying Security of the Hancke-Kuhn Protocol
Dusko Pavlovic1 ,2
Kestrel Institute and Oxford University
Catherine Meadows1 ,3
Naval Research Laboratory

Abstract
As mobile devices pervade physical space, the familiar authentication patterns are becoming insufficient: besides entity authentication, many applications require, e.g., location authentication. Many interesting protocols have been proposed and implemented to provide such strengthened forms of authentication, but there are very few proofs that such protocols satisfy the required security properties. In some cases, the proofs can be provided in the symbolic model. More often, various physical factors invalidate the perfect cryptography assumption, and the symbolic model does not apply. In such cases, the protocol cannot be secure in an absolute logical sense, but only with a high probability. But while probabilistic reasoning is thus necessary, the analysis in the full computational model may not be warranted, since the protocol security does not depend on any computational assumptions, or on attacker’s computational power, but only on some guessing chances.
We refine the Dolev-Yao algebraic method for protocol analysis by a probabilistic model of guessing, needed to analyze protocols that mix weak cryptography with physical properties of nonstandard communication channels. Applying this model, we provide a precise security proof for a proximity authentication protocol, due to Hancke and Kuhn, that uses probabilistic reasoning to achieve its goals.
Keywords: security protocol, pervasive authentication, symbolic model, Bayesian reasoning, distance bounding


Introduction
Two paradigms of security. Traditionally, two paradigms have been used for proving protocol security. The first one, captured by the symbolic model, commonly known as “Dolev-Yao”, describes both protocol and attacker in terms of an algebraic

1 Supported by ONR.
2 Email:dusko@kestrel.edu
3 Email:catherine.meadows@nrl.navy.mil

1571-0661Published by Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2010.08.007

theory [14]. While this has been criticized as crude, it is often highly effective and easily automated. The other paradigm, captured by the computational model, usually relies on some notion of indistinguishability from the point of view of a computationally limited attacker [18]. Recently, a lot of research [3,32], starting with [1], has been devoted to drawing the two paradigms closer together. This strategy has generally been to rely upon crypto-algorithms that themselves satisfy strong enough definitions of security, so that, if used in the proper way, they can be treated as Dolev-Yao “black boxes”.
Problem of pervasive security. However, there is an emerging class of security protocols for which it seems difficult to bring these two paradigms together. Such protocols arise in heterogenous networks of diverse computational and communica- tion devices, with mixed type channels between them [34]. Nowadays ubiquitous, such networks can be viewed as a realization of Doug Engelbart’s visionary idea of smart space and pervasive computation [16]. The spatial aspects of computation give rise to a new family of security problems, where the standard authentication requirements need to be strengthened by proofs of spatial proximity. In some cases, it has been possible to refine symbolic methods to get stronger proofs [23,30]. But there are other cases that resist symbolic analysis.One such case is the Hancke- Kuhn distance bounding protocol [21], which we analyze in the present paper. The protocol consists of a timed challenge-response exchange in which a prover Peggy needs to convince a verifier Victor that she is in the vicinity. Peggy’s rapid re- sponse to Victor’s challenge is implemented using a rapidly computable function. The requirement that the function must be rapidly computable turns out to weaken it cryptographically. One of the main requirements of cryptographic strength is diffusion: for a boolean function, each bit of the output should depend on each bit of the input. But such a function is not rapidly computable. The other way around, an on-line function, that produces its output while still receiving its in- put, is easier to compute, but cannot be cryptographically strong. So there is a tradeoff between cryptographic strength and rapid computability. We explore this tradeoff in Sec. 5, and quantify the information leakage of on-line functions. The Hancke-Kuhn protocol is based on such a function.
Already in the original presentation [21] of their protocol, Hancke and Kuhn wrote down an estimate of the attacker’s chance to guess a response bit. However, besides attempting to guess some bits of the response, the attacker may also attempt to guess the secret on which the response is based. Moreover, he may attempt his guesses directly, or make use of the responses stored from other sessions. Last but not least, he may collude with Peggy. Towards a precise security proof, the diverse strategies available to the attacker must be evaluated together, and exhaustively. This requires a formal model of protocol execution.
Bayesian security.  But what model to use? The symbolic model cannot be used because the perfect cryptography assumption is not validated by the on-line function, which is the central feature of the protocol. On the other hand, the cryptographic strength and weakness of this function, and the resulting security and insecurity of their protocol, does not have anything to do with any computational

assumptions, or with the computational power of the adversary: it only depends on guessing chances, which cannot be essentially increased by computational power. Thus using the computational model does not contribute to the analysis of the central feature of the protocol, although it does apply to any implementation.
The most natural model for analyzing the Hancke-Kuhn protocol that we came up with extends the symbolic model by a rudimentary probabilistic theory of guess- ing. It retains the perfect cryptography assumption for the standard cryptographic primitives used in the protocol, in particular for the keyed hash function. In a probabilistic context, though, the perfect cryptography assumption means that the output distributions of the relevant cryptographic primitives are statistically indis- tinguishable from the uniform distribution. Assuming this for the hash function used in the protocol brings us close to the random oracle assumption, often used in computational analyses [4]. There is a sense in which the random oracle as- sumption can be construed as the probabilistic version of the perfect cryptography assumption.
In summary, we contend that the simplest model capturing the central features of the Hancke-Kuhn authentication protocol must be probabilistic, but need not be computational. The probabilistic model that we propose is an extension of the symbolic theories used in our previous work [22,8,24]. On the other hand, a ver- sion of the standard computational model can be obtained as an extension of this probabilistic model (by distinguishing a submonoid of feasible functions within our monoid of randomized boolean functions). It should be noted that these logical maps between the models go in the opposite direction from those in the explo- rations of the computational soundness of the various fragments of the symbolic model [1,3,32]. In such explorations, the symbolic languages are mapped (inter- preted) in the computational language; here, a more concrete model is mapped onto a more abstract model, which is its quotient, just like blocks of low-level code are mapped onto the expressions of a high-level programming language, or like more concrete state machines are mapped on more abstract state machines [25,26]. It follows that anything proven about the abstract model remains valid about its more concrete implementations: e.g., the Bayesian reasoning about secrecy remains valid in the computational model — provided that the assumed randomness of the hash function can be validated. This proviso is, of course, not satisfied in practice, since cryptographic hash functions are not truly random. The task, thus, remains to strengthen or refine the reasoning as to be able to discharge such unrealistic as- sumptions. This logical strategy was discusssed in [22,8]. While not widely accepted in security, this is a standard approach to refinement based software development: e.g., Euclid’s algorithm is usually described assuming the ring of integers; but the assumption that there are infinitely many integers must be discharged before the algorithm is implemented in a real computer.
The space does not allow us to delve into the details of this approach, as applied to security. They will be presented elsewhere. In the present paper, we attempt to present a very special instance of this approach, where a modest probabilistic ex- tension of the symbolic model suffices for the problem at hand — yet it leads to an

essentially different reasoning framework, with bayesian derivations instead of logi- cal. The resulting technical divergence, mitigated by the conceptual guidance from the underlying simpler model, should be viewed as one of the main features of the incremental approach, pursued in the Protocol Derivation Logic (PDL) [22,8,24]. In [23], PDL was already used to analyze distance bounding protocols, similar to Hancke-Kuhn’s, and for reasoning about pervasive security in general. An inter- esting feature of the current probabilistic extension of PDL is that the concept of guards, originally developed for reasoning about secrecy [24], now provides a crucial stepping stone into our analysis of guessing chances, and of the concrete authenti- cation guarantees in the Hancke-Kuhn protocol in Sec. 6, as well as in the abstract view of symbolic authentication in Thm. 3.4.
Related work. As already mentioned, the closest relative of the PDL formalism, underlying this work, and briefly summarized in Sec. 3, is PCL [15,11,10]. Both for- malisms owe a lot to strand spaces [17], in spirit, and in execution models, although the logical methods diverge. Our probabilistic extension of PDL is predated by the probabilistic extension of PCL in [12], and by the probabilistic extension of strand spaces in [20]. But each of the three probabilistic approaches has a different intent, and a completely different implementation, conceptually and technically. It would be interesting to explore these differences more closely, as some tasks may yield to combined modeling methods.
Paper outline. The paper continues with a review of distance bounding authenti- cation, and a description of the Hancke-Kuhn protocol. In Sec. 3 we provide a brief overview of the derivational method of protocol analysis, and of PDL. We also re- call the algebraic notions of derivability and guards, originally used for derivational analyses of secrecy, and here adapted for authenticity. The probabilistic versions of these notions are introduced in Sec. 4, and then used to model guessing. The gathered tools are then put to use. In Sec. 5, we analyze the information leakage of on-line functions in general, and characterize the Hancke-Kuhn function among them. In Sec. 6, we quantify the authentication achieved in the Hancke-Kuhn pro- tocol. Sec. 7 closes the paper with a summary of the results and a discussion of the extensions. All proofs are in the Appendix.

The Hancke-Kuhn protocol
Background
In a man-in-the-middle attack on a challenge-response protocol, the attacker relays messages, sometimes modified, between the legitimate participants. If resending a message takes time, the legitimate participants may observe slower traffic. This has been proposed as a method to prevent man-in-the-middle attacks. In particular, the challenger can measure the presumed round trip of his challenge and of responder’s response, and compute a maximal distance of the responder, assuming an upper bound on the message velocity. This can assure the authenticity of the response, if it is known that the attacker cannot be too close. This is the idea of distance

bounding [13,5]. The early security analyses of distance bounding protocols go back to the early 1990s [6]. The interest in this type of authentication re-emerged recently, with the task of device pairing and a genuine need for proximity authentication in pervasive networks. From the outset, the basic idea of distance bounding was to combine some cryptographic authentication tools, such as hashes or signatures, with a physical constraint, such as the limited speed of message exchange. Most distance bounding protocols [6,7,23] implement this combination by using two channel types: the standard network channels for the cryptographic authentication, and the timed channels for the rapid response. The Hancke-Kuhn protocol [21] stands out by it simplicity, and by the fact that both cryptographic data and the rapid response are sent on the timed channel. This, however, comes for the price of information leakage, which makes the security analysis interesting.

The protocol
As mentioned before, the goal of the Hancke-Kuhn protocol is that the prover Peggy proves to the verifier Victor that she is nearby. It is assumed that Peggy and Victor share a long term secret s, and a public hash function H. The relevant security requirement from H will turn out to be a version of the range preimage resistance [29]. The simplest way to present a protocol session is to view it in two stages.
In the ﬁrst stage, Peggy and Victor exchange values a and b, which can be predictable for the attacker, but must never be reused by Peggy and Victor in more than one protocol session. The values a and b can thus be viewed as counters.

Fig. 1. Hancke-Kuhn protocol: Second Stage

In the second stage, Peggy and Victor both form the hash h = H(s :: a :: b) and proceed with the exchange on Fig. 1. If Victor’s challenge x = (xi) ∈ Zl is a bitstring of length l, then the hash h should be 2l bits long which we view

as a concatenation h = h(0) :: h(1) ∈ Z2l
of two strings of l bits. The function

☒ : Zl × Z2l −→ Zl is defined bitwise for i = 1, 2,... ,l by
2	2	2

(x ☒ h)i = h(xi)
To summarize Fig. 1,
(1)

Victor generates a random bitstring x of length l, and sends each bit xi of x at times τi.

To each bit xi, Peggy responds with h(0) if xi = 0, and with h(1) if xi = 1.
i	i
Victor receives Peggy’s i-th bit response at time τi. He knows h as well, and can check that these responses are correct. If only he and Peggy know h, then the responder must be Peggy. He then uses the times between the sending the challenges and receiving the responses, together with the velocity of the message signal, to compute his distance from Peggy.
Discussion
Leaking information to the attacker. The crucial component of the protocol is the Hancke-Kuhn function ☒. Its main feature is that it is rapidly computable, as efficiently as the exclusive or ⊕. It is thus as suitable for timed authentication as ⊕, but it also leaks information, although less than ⊕: while x and x ⊕ g allow extracting g because g = x ⊕ x ⊕ g, x and x ☒ h allow extracting only half of the bits of h. However, it is easy to see from (1) that from x, and x ☒ h, and moreover (¬x) ☒ h, the attacker can extract all of h. That is why Peggy and Victor must not reuse their counters. If h = H(s :: a :: b) can be used in two responses, then an attacker can challenge Peggy twice, first with x and then with ¬x, and thus get x☒h and (¬x) ☒ h as the two responses. From this, he can extract h and impersonate Peggy to Victor. Even if the counters are never reused, the fact that half of the response bits can be acquired by an attacker needs to be carefully examined, and his chances to guess the rest evaluated.
Overlooked assumption. Hancke and Kuhn’s estimate that the probability that an attacker may succeed in impersonating Peggy is ( 3 )|x| relies on the implicit assumption that |x| ≤ |s|. Otherwise, if |x| > |s|, the attacker has better odds to guess s than x. In practice, of course, the assumption |x| ≤ |s| is usually satisfied, because the secret s is usually at least 256 bits long, while the challenge x may be shorter. Strictly speaking, though, the impression that protocol’s security only depends on the length of the challenge x is not correct, since a short secret s would make it vulnerable.
Dishonest prover and the kernel. Another interesting weakness is that the value of Peggy’s i-th response bit (x ☒ h)i does not depend on xi if h(0) = h(1). A
i	i
dishonest Peggy can thus analyze the hash h and respond without waiting for xi
whenever h(0) = h(1). If the response time is averaged, she is likely to appear closer
i	i
to Victor than she really is.
Since Victor’s counter b is predictable, Peggy can attempt to choose her own counter a to maximize the size of the kernel κh of h = H(s :: a :: b), defined
κh = {i ≤ l | h(0) = h(1)}	(2)
i	i
The larger the kernel, the closer Peggy can appear to Victor. However, the problem of finding a value a such that, for a fixed s and b, the image H(s :: a :: b) has a desired property is a version of the range preimage problem [29]. The assumption that H is a hash function, and in particular that it is a one-way function, implies that dishonest Peggy’s advantage in finding a preimage a such that H(s :: a :: b),

given s and b, falls within a desired range of strings with a large kernel, is negligible. This means that dishonest prover’s manipulation of the kernel is unfeasible.
Further ad hoc observations get more complicated, without providing any defi- nite assurances. This demonstrates the need for a rigorous analysis within a formal model.
Modeling the essence of the Hancke-Kuhn protocol.  The assumption that H is a one-way function will turn out to be the only point where the security of the Hancke-Kuhn protocol depends on computation. All other attack strategies only involve guessing chances. To show this, in the following sections we introduce a probabilistic (Bayesian) protocol model, which strictly extends the standard al- gebraic (symbolic) model, and is a strict fragment of the standard computational model. The hash H is modeled as a randomized function, as defined in Sec. 4. The perfect cryptography assumption of the symbolic model lifts in our Bayesian model to the assumption that the hashes are truly random, which is, of course, analogous to the random oracle assumption in the computational model. It allows us to abstract away the generic and negligible vulnerabilities, and to focus on the interesting aspects of the security of the Hancke-Kuhn protocol, achieved in spite of the cryptographic weakness of the ☒ function as it central feature.
Algebraic protocol models
We analyze the Hancke-Kuhn protocol by the derivational method. The varied ver- sions of this method have been applied to many protocols [15,22,8,11,10]. While the algebraic protocol model suffices in most cases, the Hancke-Kuhn protocol requires an evaluation of guessing chances. We attempt to find a simple model that will allow this.
Message algebras
In the Dolev-Yao protocol model, messages are represented as terms of a free algebra of encryption and decryption operations [14]. More general algebraic models allow additional operations, and additional equations [9]. Recall that an algebraic theory is a pair (O, E), where O is a set of finitary operations (given as symbols with arities), and E a set of well-formed equations (i.e. where each operation has a correct number of arguments) [19].
Definition 3.1 An algebraic theory T = (O, E) is called a message theory if O includes a binary pairing (−, −) operation, and the unary operations π1 and π2 such that E contains the equations π1(u, v)= u, π2(u, v)= v, and ((x, y) , z)= (x, (y, z)). A message algebra is a polynomial extension T [X ] of a T-algebra T .
Remarks. The third equation implies that there is a unique n-tupling operation for every n. The first two imply that the components of any tuple can be recovered. A polynomial extension T [X ] is the free T-algebra generated by adjoining a set of indeterminates X to a T-algebra T [19, §8]. The elements x, y,z ... of X are used to represent nonces and other randomly generated values. This is justified by the fact

that indeterminates can be consistently renamed: nothing changes if we permute them. That is just the property required from the random values generated in a run of a protocol 4 .
Protocol models
There are several protocol modeling formalisms that can be used for protocol deriva- tions. The process calculus in [15,11] was designed specifically for this purpose. Strand spaces [17] were designed for a different purpose, but they can be adapted for protocol derivations too. In [22,8,24] we used partially ordered multisets (pomsets) of actions [27], which allow simple tool support [2]. We stick with this approach, but the subtle (or in some cases not so subtle) differences between these approaches are of no consequence here. For completeness, we provide a brief overview. For more detail, the reader may want to consult some of the mentioned references.
In all cases, the set of actions A is generated over the message algebra T [X ] by a grammar allowing each term t ∈T [X ] to be sent in the action ⟨t⟩∈ A, and received in the action (t) ∈ A. Moreover, an indeterminate x ∈ X can be introduced into a protocol by the binding action (νx) ∈ A, which is read as ”generate fresh x”.
Challenge-response

Fig. 2. CR template

Fig. 2 shows the abstract challenge-response protocol template, where the verifier V ictor authenticates the prover P eggy. It is assumed that only Peggy is able to transform the fresh challenge cVP x into the response rVP x. This assumption is construed as a constraint on the operations cVP and rVP . The actions ⟨⟨t⟩⟩, and ((t)) are syntactic sugar for “send (resp. receive) a message from which anyone can extract t”.
Views, derivability and guards
As usual, the communication channels are assumed to be controlled by the attacker: she observes all sent messages, and controls their delivery. However, she may not

4 Of course, this is not the only requirement imposed on nonces and random values. The other requirement is that they are known only locally, i.e. by those principals who generate them, or who receive them unencrypted. This requirement is not formalized within the algebra of messages, but by the binding rules of process calculus or actions by which the messages are sent [11,24].

be able to invert all operations, and she has no insight into the fresh or secret data of other principals. Hence the different views of the various protocol participants.
A state σ reached in a protocol execution is a lower closed pomset of actions executed up to that point, with an assignment of values to principals’ local variables,

which they use to store messages and their local computations. The view Γσ
of a

principal P at a state σ consists of all terms that P may have observed up to σ, and all terms that she could derive from that. Formally, this last clause means that
σ is upper closed under the derivability relation

Ξ	▶ Θ	⇐⇒	∀t ∈ Θ ∃ϕ ∈ O(n) ∃s1,... , sn ∈	E	1	n

where Ξ, Θ ⊆ T [X ] are finite sets of terms, O(n) is the set of well-formed n-ary operations in the signature O, and the equation is derivable from E.

Authentication by challenge-response
The challenge-response protocol in Fig. 2 validates authentication if Victor is justi- fied in drawing a global conclusion from his local observation: i.e., having observed his own actions in on the left, Victor should have good reasons to conclude that Peggy must have performed her actions on the right, and that all these actions should be ordered as on the figure. Intuitively, this conclusion of Victor’s can be justified by the assumptions that
anyone who originated the response rVP x had to previously receive the chal- lenge cVP x, which could only happen after Victor sent this challenge;
no one could produce rVP x without knowing the secret sVP , so it must be Peggy.
This last conclusion is based on the assumption that only Peggy knows sVP , or only Peggy and Victor. In both cases, Victor’s reasoning is the same, because he knows that he did not send rVP x.
Using the derivability relation, these informal justifications can be refined into slightly more formal proof obligations in terms of (3), as follows. For any set of principals Π, it is required that
whenever there is a derivation Ξ ▶ rVP x, then there must also be a derivation Ξ ▶ cVP x, for any set of terms Ξ observed by Π in a run of CR before rVP x is sent;
whenever there is a derivation Ξ, cVP x ▶ rVP x, then there must also be a derivation Ξ, cVP x ▶ sVP , for any set of terms Ξ known to Π in a run of CR before rVP x is sent.
This type of authentication reasoning can be formalized using the notion of
guards from [24].
Definition 3.2 We say that a set of sets of terms G  algebraically guards a term
t with respect to a set of terms Υ, and write G guards t within Υ if for all Ξ ⊆ Υholds

Ξ ▶ t ⇒ ∃Γ ∈ G. Ξ ▶ Γ	(4)
Explanation. We say that, in a context C, G guards t if every computation path to t leads through some element of G. In other words, if Ξ allows computing t, then it is ”because” it allows computing some of t’s guards from G.
Example. Let Υ = (DH) be the set of terms that may become known to the participants and eavesdroppers of a run of the Diffie-Hellman protocol. Then
{x, gy }, {y, gx}	guards gxy	within (DH)

Note that gxy can be derived not only from {x, gy} and {y, gx} but also from {g, x, y} and {g, xy}; however, neither of these sets can occur in a run of the Diffie-Hellman protocol between two honest principals, so they are not contained in the set Υ = (DH).
Definition 3.3 Let Q be a protocol run, and A a set of actions in Q. The term context is the set

Q(A)= [ Γι
∪ ΓdA

P ∈Π
where Π is the set of principals engaged in the run, Γι
is the set of terms known

to a principal P initially, and ΓdA is the set of terms known to P before any of the actions a ∈ A are executed in Q.
Using the guard relation, we can prove that the challenge-response protocol validates authentication.
Theorem 3.4 Let Q be a run of the challenge-response protocol on Fig. 2. Suppose that the functions cVP and rVP satisfy
n{cVP x, sVP }o  guards rVP x  within Q(rVP x)

where sVP is a secret known only to Peggy (and possibly to Victor). Then Victor is justiﬁed in drawing the following global conclusion from his local observations:
V : (νx)V d ⟨cVP x⟩V	d (rVP x)V
=⇒ (νx)V d ⟨cVP x⟩V d ((cVP x))P d ⟨⟨rVP x⟩⟩−→ d (rVP x)V	(cr)
where the relation adb says that action a occurs before action b, and ⟨⟨m⟩⟩−→ denotes
the ﬁrst time P sends message m after creating it.
The proof of this theorem is obtained by expanding the definition of the guard relation and analyzing the term context of the challenge-response protocol. Several examples of reasoning with this relation can be found in [24].
Comment about perfect cryptography. The algebraic guard relation is based on the assumption that a term can only be derived algebraically, using the given operations and equations. A term t thus either lies in a subalgebra generated by a set of terms Ξ, or not, and we have Ξ ▶ t ∨ Ξ /▶ t. This means that the attacks on the implementation of the term t are abstracted away. In particular, we assume

that it is impossible to cryptanalyze the bitstrings representing t, and to derive t by accumulating partial information about it. In other words, we assume perfect cryptography.
Moreover, we assume that the algebraic derivations Ξ ▶ t only use the equations specified in the given algebraic theory T = (O, E). This means that the message algebra T is assumed to be a free T-algebra, or that it is computationally unfeasible for the attacker to find any additional equations that T satisfies, not specified in the theory T, and to use them in his derivations. This is roughly the pseudo-free algebra assumption [28].
Can we apply Thm. 3.4 to the Hancke-Kuhn protocol? The Hancke-Kuhn protocol on Fig. 1 is obviously a timed version of the challenge response template from Fig. 2, for which Thm. 3.4 provides a general security claim. If the guard condition holds, then the Theorem yields the security of the Hancke-Kuhn protocol. In the algebraic model, the attacker at a given state either knows a term, or not. As explained in Sec. 2, the attacker on the Hancke-Kuhn protocol may always obtain half of the bits of the secret shared by Victor and Peggy by challenging her. Does this mean that the attacker gets to know the secret? If not, then the guard condition is satisfied. To apply Thm. 3.4, we should thus set up the algebraic model
so that a term is known only when all of its bits are known.
Howeber, the same security proof would also hold for a modified version of the Hancke-Kuhn protocol, e.g. where x ☒ h = h(0) if x = a and x ☒ h = h(1) otherwise, for some fixed a ∈ Zl . The attacker still cannot algebraically derive the term x ☒ h without x, because this term still depends on x. The guard condition holds, and thus the protocol is algebraically secure. In reality, though, the attacker who always responds with h(1) will succeed with a probability greater than 1 − 2−l, assuming that the challenge x is drawn uniformly. The algebraic security of the Hancke-Kuhn type of protocols is not very realistic.

Protocol models with guessing
In this section we propose a probabilistic refinement of the guard relation, which captures and quantifies just the partial information leaks, like the one in the Hancke- Kuhn protocol, without adding any unnecessary conceptual machinery.

Implementing and guessing messages
In order to reason about the feasibility of the algebraic operations on messages, and about guessing, we consider the implementations of the messages t ∈ T in an algebra Ω of strings, which carries the structure of a message T-algebra, and moreover set of randomized functions.

For concreteness, we assume that Ω = Z∗
is the set of bitstrings. However,

any graded free monoid would do, since the only operations that we use are the
concatenation and the length.

Implementing messages
Let H be a partially ordered set. We call an infinitely increasing chain h0 < h1 < h2 < ··· in H a H-tower. We denote by Hω the set of towers in H.
Any free monoid Ω is partially ordered by the preﬁx relation
a и b ⇐⇒ ∃c ∈ Ω. a :: c = b
where a :: c can be viewed as the concatenation of the strings a and c. We call Ω- towers streams. They are just infinite sequences of strings, strictly extending each other: a stream is a sequence a = {al}l∈N ⊆ ΩN such that al и al+1 for all l. A stream a is called an l-stream if the length of l-th element is exactly |al| = l. The set of streams through Ω is denoted by Ωω.
N can be viewed as the special case, since a natural number can be viewed as a string of 1s. The set Nω consists of strictly increasing sequences of natural numbers.
Definition 4.1 Let X be a set of indeterminates. Its strength is a map |−| : X −→ Nω, assigning to each indeterminate x for each value of the security parameter l ∈ N the required length |x|l ∈ N.
An environment is a partial map η : X ~ Ωω such that |η(x)l| = |x|l whenever
η(x)l is deﬁned.
An implementation of a T-algebra T is an injective T-algebra homomorphism
J−) : T > Ωω.
An environment and an implementation induce a T-algebra homomorphism J−)y : T [Xy] −→ Ωω, where Xy ⊆ X is the domain of deﬁnition of η. We call this homomorphism an implementation too whenever it is injective.
The implementation of the algebra T assigns a unique string to each term. By definition of the polynomial algebra T [Xy], every algebra homomorphism T −→ U to another algebra U, and a function Xy −→ U induce a unique algebra homomorphism T [Xy] −→ U.
Since any algebraic operation on Ω lifts to a pointwise operation over any power Ωn, it also lifts to streams. So Ωω is also a T-algebra, and a monoid for (elementwise) concatenation. 5
Notation. When confusion seems unlikely, we ignore the difference between the indeterminates x,y ... ∈X and their environment values η(x), η(y) ... ∈ Ω.
Randomized functions
Consider the set of partial functions
R = {f : Ω × Ω ~ Ω |∀x∀ρ1∀ρ2.f (ρ1, a) ↓  ∧ f (ρ2, a) ↓ ⇒ |ρ1| = |ρ2|}
where f (ρ, a) ↓ means that f is defined on ρ, a, and |ρ| is the length of the bitstring
ρ. The set R is a monoid with the following composition operation
f ◦ g(ρ2 :: ρ1, a)= f (ρ2, g(ρ1, a))

5 Grading is not an algebraic operation, and it does not lift: the length of each stream is infinite.

and with the function ι (o, a) = a as the unit, where o denotes the empty string. We interpret the elements of R as randomized functions over Ω: the first argument ρ represents the random seed, and the second argument a is the actual input. The output ƒa can then be viewed as a random variable with the probability distribution
#{ρ | ƒ (ρ, a)= b}

Prob(ƒa = b)= 
2r	(5)

where r is the length of all ρ for which ƒ (ρ, a) is defined. Leaving the seed implicit,
we denote randomized functions, as presented in R, in the form ƒ :Ω −R→ Ω.
Definition 4.2 A stream of functions is a sequence ƒ = {ƒl}l∈N ∈ RN which is monotone, in the sense that for all streams a, ρ ∈ Ωω, at every l ∈ N holds
ƒl(ρl, al)  ↓	∧	ƒl+1(ρl+1, al+1) ↓ =⇒	ƒl(ρl, al)  и  ƒl+1(ρl+1, al+1)
We denote the monoid of streams of functions by Rω.
Indistinguishability
Surviving the flood of negligible factors. Every subterm of every term in every security protocol can in principle be guessed. Such probabilities are usually tolerably small: they are negligible functions of some security parameter l. In probabilistic analyses, it is often convenient to ignore such events of negligible probability. In a protocol analysis, tracking all terms and subterms that can be guessed with a negligible probability can lead to a lengthy list, without revealing anything non- negligible. In this section, we provide an underpinning for formal probabilistic reasoning up to negligible factors.
The frequencies of events are established by repeated sampling. The number of samples needed for a reasonable estimate depends on a priori chance that the event will occur. If this chance is 1 in n, then the number of the needed sample is an increasing function of n.
When sampling a stream a = {al}l∈N, we assume that a reasonable amount of samples should not be greater than q(l), where q is a function from a rig 6 Q ⊆ NN. In cryptography it is customary to take Q = N[x], the polynomials with non-negative integer coefficients. Streams are thus sampled a polynomial number of times. If the probability that the difference between al and bl will be detected in q(l) samples remains small for all l, then a = {al}l∈N and b = {bl}l∈N are considered indistinguishable. In other words, a and b are indistinguishable if the probability

that al and bl are different is less than  1 
for all q ∈ Q. Now we formalize this

intuition.
Definition 4.3 A function ν : N −→ [0, 1] is said to be Q-negligible if it converges to 0 faster than  1  for all q ∈ Q, i.e.
∀q ∈ Q ∃n ∈ N ∀l ≥ n. ν(l) <  1
q(l)

6 A rig Q is a ”ring without the negatives”: it consists of two commutative monoid structures, (Q, +, 0) and (Q, ·, 1), such that x · (y + z)= x · y + x · z and x · 0= 0.

The set of Q-negligible functions is denoted by  1 . The ordering on streams a, b ∈
Q
[0, 1]N is deﬁned up to negligible functions, i.e.
a ≤ b ⇐⇒ ∃ν∀l. al + ν(l) ≤ bl

We say that a, b ∈ [0, 1]N are Q-indistinguishable, and write a Q
b, if a ≤ b and

b ≤ a, or equivalently
a ∼ b ⇐⇒ ∃ν∀l. |al − bl| ≤ ν(l)
Assumption, examples. For simplicity, we take Q to be the rig N[x] of polyno- mials with non-negative integer coefficients, as it is usually taken in cryptography. Then, e.g., for a = {2l}l∈N and b = {l−2}l∈N holds a ∼ 0, but b /∼ 0, where 0 is viewed as the constrant sequence.
Definition 4.4 Streams of functions ƒ and g are indistinguishable if the sequences Prob(ƒa = b) and Prob(ga = b) are indistinguishable for all streams a, b ∈ Ωω. We abbreviate
ƒ ∼ g ⇐⇒ ∀ab ∈ Ωω. Prob(ƒa = b) ∼ Prob(ga = b)
Definition 4.5 A flow is an equivalence class of streams of randomized functions. The flow monoid R˜ is thus
R˜ = Rω/ ∼

Probabilistic derivability
In contrast with the algebraic derivability relation from Sec. 3.3, the probabilistic derivability relation does capture partial information leaks, using the implementa- tions of the terms. While Ξ /▶ Θ may happen because some t ∈ Θ is not algebraically derivable from Ξ, it may be easy to guess many bits of information about Θ from Ξ. We formalize this by saying that for some stream of randomized functions ƒ ∈ R, Prob(ƒ JΞ) = JΘ)) is high. By assumption, the messages Θ are easily decoded from their implementations JΘ). So if some ƒ is likely to output JΘ) on the input JΞ), then the chance to derive Θ from Ξ is high. This is what we want to capture by the following randomized derivability relation, which quantifies guessing chance.
Let X (Ξ) ⊆ X be the set of indeterminates that occur in Ξ. Any minimal environment η in which the JΞ)y is defined must be defined over X (Ξ). Since for each l the required number of bits for each x ∈ X (Ξ) is fixed to |x|l, each ηl must select the same number of bits

|X (Ξ)|l =
x∈X (Ξ)
|x|l

So there are 2|X (Ξ)|Æ environments to interpret Ξ for the security parameter l. Our chance to guess Θ from Ξ is the probability that a flow ƒ ∈ R will output JΘ)y when given the input JΞ)y, for the random choices of η. Hence the following definition.
Definition 4.6 The guessing chance Ξ ▶ Θ is the stream of probabilities

 Ξ ▶ Θ l
=
ƒÆ∈R
#{ηl | ƒlJΞ)l = JΘ)l} 2|X (Ξ,Θ)|Æ
(6)

viewed up to indistinguishability. We abbreviate ∅ ▶ Θ to Θ .
Since the functions in the sequence {ƒl}l∈N compute on streams JΞ)l, together they form a stream of functions ƒ ∈ Rω, i.e. a flow ƒ JΞ) = Θ.
Examples. For any closed term t ∈ T , i.e. such that X (t) = ∅, it holds that t = 1. To see this, note that Jt) is given in the empty environment η∅, and thus X (t) = ∅ implies |X (t)|l = 0 for all l. The supremum of (6) is reached at the
constant function stream ƒ () = Jt), and gives t = #{y∅ | ƒ ()=Jt)} = 1.
On the other hand, for every x ∈ X holds  x l = 0. There are exactly 2
|x|Æ
environments ηx, defined on x alone. To guess x without any inputs, we need a constant flow ƒ , such that ƒ () = Jx) = ηx(x), i.e. a constant stream of functions ƒl() = ηx(x)l. Whichever ƒ we may choose, exactly one environment ηx will give

ƒ () = ηx(x). So for every constant flow ƒ holds #{yx | ƒ ()Æ =Jx)Æ }
=  1 .  The
2

supremum in (6) is thus reached for all constant ƒ ∈ R˜, and x l
=  1 . But the
2

sequence  2−|x|Æ }	is indistinguishable from 0, as pointed out after Def. 4.3.
Subbayesian reasoning and Advantage
Proposition 4.7 For all sets of terms Ξ, Γ, Θ holds
Ξ ▶ Γ · Ξ, Γ ▶ Θ ≤ Ξ ▶ Γ, Θ	(7)
When Γ > 0, it follows that

Γ ▶ Θ ≤ Γ, Θ 
(8)

The inequalities become equalities if Ξ and Θ have no indeterminates in common.
Definition 4.8 The advantage provided by a set of terms Ξ in computing the terms
Θ is the value
Adv Ξ ▶ Θ = Ξ ▶ Θ − Θ
When this advantage is zero, we say that Θ is flow independent of Ξ, and write
 Ξ ⊥ Θ ⇐⇒ Adv Ξ ▶ Θ =0 ⇐⇒ Ξ ▶ Θ = Θ 
Probabilistic guards
The idea of the guard relation is that a term t is guarded by one of the guards from G if whenever t is derived, then at least one of the guards Γ ∈ G is also derived. In the algebraic model, this was simple enough to state by Definition 3.2. When t can be guessed, then this crude statement needs to be refined: the event that t is guessed must be preceded by the event that some Γ ∈G is guessed.
Definition 4.9 We say that a set of sets of terms G guards (against guessing) a term t with respect to a set of terms Υ, and write G guards t within Υ if for all Ξ ⊆ Υ

such that Adv Ξ ▶ t > 0 holds
 Ξ ▶ t ≤   Ξ ▶ Γ · Ξ, Γ ▶ t	(9)

Explanation. In the algebraic case, (4) was an attempt to capture the intuition that G guards t if all computational paths to t lead through some Γ ∈ G, assuming the context C. The above definition extends this attempt to computational paths with guessing. If we get any help from Ξ to guess t, then that help is not greater than the help we get from it to guess some guard Γ ∈G of t first, and then to guess t from this guard. Applied to message theories with trivial implementations (e.g. with Ω = 1), Def. 4.9 boils down to Def. 3.2, in the sense that the guessing chance is always constantly 0 or constantly 1, and (9) reduces to (4).
To simplify notation, we elide the environment subscripts from J−)y whenever
η is inessential for the argument.

Partitioned functions and ☒
In this section we analyze a class of quickly computable functions, like the one used in the Hancke-Kuhn protocol. One way to ensure that a function is quickly computable is to require that the bit dependency of its outputs from its inputs must be partitioned: the i-th block of output bits should only depend on the i-th block of input bits. Since in this section we are dealing with purely random input, our results are presented in terms of streams, not flows.
Definition 5.1 We say that a boolean function ƒ : Zm −→ Zn is partitioned when
2	2
m = m1 + m2 + ··· + ml
n = n1 + n2 + ··· + nl
ƒ = ƒ1 :: ƒ2 :: ··· :: ƒl
where ƒi : Zmi −→ Zni, for i = 1, 2,... l are independent on the inputs and the
2	2
 
Clearly, a boolean function receiving its input string sequentially can already return the i-th block of its outputs while still receiving i + 1st block of the inputs. Unfortunately, this convenient property also decreases cryptographic strength of the function, which requires that each bit of the output depends on each bit of the input [33]. In particular, knowing a value ƒ (z) of a partitioned function increases the chance of guessing ƒ (x). We make this precise in the next section.
Guessing partitioned functions
Proposition 5.2 (a) Let ƒ be a randomized partitioned function, and let x, z ∈ Zm
n	 2



(b) Let ƒ : Zl
−→ Zl
be randomized bitwise partitioned, i.e. |mi| = |ni| = 1 for

all i ≤ l. Then x, z, ƒ (z) ▶ ƒ (x) ≥ 2−Δ(x,z), where Δ(x, z) = #{i|x /= z} is the Hamming distance.
A consequence of Prop. 5.2 is that a proximity authentication protocol, im- plemented using a partitioned function R to compute the response rVP x = R(sVP , cVP x), cannot be secure in an absolute sense, because the response may be guessed with a non-negligible probability from the other responses rVP z. More- over, it seems that the attacker can always obtain some other responses rVP z by impersonating Victor and issuing challenges cVP z.

Lemma 5.3 A randomized boolean function ƒ : Zl −→ Zl
is bitwise partitioned if

and only if for every x ∈ Zl
2	2
it holds that

ƒ (x)= x ☒ ƒ (0l) :: ƒ (1l)	(10)
where ☒ is the Hancke-Kuhn function (1), and 0l, 1l ∈ Zl are the strings of 0s and
1s, respectively.
Bitwise partitioned functions with a minimal guessing probability can now be completely characterized: they turn out to be precisely the Hancke-Kuhn functions
(1) for which the values at 0 and at 1 are independent.
Proposition 5.4 Suppose that ƒ : Zl −→ Zl is a randomized bitwise partitioned
l	l  2	2	l
x, z, ƒ (z) ▶ ƒ (x) = 2−Δ(z,x)	(11)
if and only if for every i ≤ l it holds that
 ƒi(0) ⊥ ƒi(1) and ƒi(1) ⊥ ƒi(0)	(12)
Remark. In a sense, x ☒ (−): Z2l −→ Zl is thus a ”one-and-half-way function”,
2	2
since x ☒ h discloses only one half of the bits of h.

On the other hand, (−) ☒ h : Zl
−→ Zl
is not only an example of a bitwise

partitioned function, satisfying the needs of the Hancke-Kuhn protocol, but it is a
canonical way to represent such functions.
Guessing x ☒ h
We now consider the probability of guessing x ☒ h given various sorts of information that may be learned in the Hancke-Kuhn protocol.
Definition 5.5 a) For x ∈ Zl and I ⊆ l = {0, 1, 2,... l − 1} we deﬁne x③I ∈ Zl to
2	2
be the bit string obtained by replacing for all i ∈ I the bits xi with a “wild card” ②
x③I =  ②	if j ∈ I

b) For h = h(0) :: h(1), where h(0), h(1) ∈ Zl we deﬁne the kernel nh to be the set of places where its ﬁrst and its second half coincide, e.g.
nh = {i ∈ l | h(0) = h(1)}.
i	i

We make use of these definitions in the following.
Proposition 5.6 Suppose that h the concatenation of two constant l-bit streams, and x is a uniformly distributed l-bit stream. Then

h ▶ x ☒ h l
= 2|nh|−l

x, h ▶ x ☒ h l = x	,h ▶ x ☒ h 
③nh
The following lemma concerns the problem of deriving x ☒ h from z ☒ h for some
z.
Proposition 5.7 Let h be the concatenation of two uniformly distributed l-bit streams, let x be a uniformly distributed l-bit stream, and let z be any l-bit stream. Then the following holds.

z ☒ h ▶ x ☒ h l =
z, z ☒ h ▶ x ☒ h l  =
 3 l


Security of Hancke-Kuhn
We quantify the security of the Hancke-Kuhn protocol by evaluating Prob(crp), i.e. the probability that the sequence of events in a complete protocol run validates the following reasoning of Victor’s
V :	(νx)V d τ ⟨x⟩V d τ (x ☒ h)V
=⇒  (νx)V d τ ⟨x⟩V d (x)P d ⟨x ☒ h⟩−→ d τ (x ☒ h)V  (crp)
corresponding to the run on Fig. 1. In order to evaluate this probability, we an- alyze the probability that (crp) fails. How can it happen that Victor observes a satisfactory sequence of his own actions
V = (νx)V d τ ⟨x⟩V d τ (x ☒ h)V	(13)
but that the desired run
O = τ ⟨x⟩V d (x)P d ⟨x ☒ h⟩−→ d τ (x ☒ h)V	(14) did not take place? There are just two possibilities:
A: the responder does not know the secret s, i.e. he is the Attacker,
E: the responder knows the secret s, i.e. he is Peggy, but the response is sent Early, without receiving the challenge.
The remaining case, that the responder is Peggy, and she responds to the challenge, is just the event O. Thus ¬O = A∪ E. It follows that
Prob(crp) = Prob(O|V) = 1 − Prob(A∪ E|V)
≥ 1 − Prob(A|V) − Prob(E|V)	(15)
The (in)security of the Hancke-Kuhn protocol thus boils down to evaluating Prob(A|V) and Prob(E|V). The following lemmas and propositions show that these probabilities are negligible. The proofs are in the Appendix.

Response token. Recall that Peggy’s response token h = H(s :: a :: b) is derived from the shared secret s, Peggy’s counter a, and Victor’s counter b, using a secure public hash function H. In this section, h abbreviates H(s :: a :: b).
Assumption 6.1 The above decomposition of ¬O as A∪E is valid only if h =
H(s :: a :: b) is such that
|s| |x|, i.e. attacker’s chance to guess the secret s is negligible compared with his chance to guess the challenge x;
the counters a and b are never reused (although they may be predictable). Otherwise, the attacker may guess h, and ¬O may not be covered by A∪ E.
Guards in undesired runs
In order to evaluate Prob(crp), we need to determine the probability that the correct response x ☒ h is guessed in the undesired runs A and E. Towards this goal, we explore what can be guessed in the term contexts (cf. Def. 3.3) A(x ☒ h) and E(x). The following lemmas simplify this question.
Lemma 6.2 (a) Let A be an attack run with a long term secret s, Peggy’s counter a, Victor’s counter b, and Attacker’s challenge z, for which he obtains the response z ☒ h, where h = H(s :: a :: b). Then for any Ξ ⊆ A(x ☒ h) it holds that
Ξ ▶ x ☒ h = Ξ ∩ {s, a, b, x, z, z ☒ h} ▶ x ☒ h
(b) Let E be a run with a long term secret s, Peggy’s counter a, Victor’s counter
b, and where Peggy responds early. Then for any Ξ ⊆ E(x) it holds that
Ξ ▶ x ☒ h = Ξ ∩ {s, a, b} ▶ x ☒ h
Lemma 6.3 For h = H(s :: a :: b) and Υ ⊆ {z, z ☒ h} it holds that
 x ☒ h l = x, z ▶ x ☒ h l = 2	(16)
−l
a, b, s, x③nh ▶ x ☒ h = 1	(17)
 a, b, s, x, Υ ▶ x ☒ h = 1	(18)
Proposition 6.4 {{s}, {z ☒ h}} guards x ☒ h within A(x ☒ h)
Proposition 6.5	{x③nh}	guards x ☒ h within E(x)
The guards displayed in the preceding Propositions will now be used to evaluate Prob(V|A) and Prob(V|E), i.e. the probabilities that the authentication may fail because the Attacker breaks it, or because Peggy’s succeeds in responding Early.

Bounds on undesired runs
Proposition 6.4 and the definition of probabilistic guards say that, for a given chal- lenge x, the probability that an Attacker can violate authentication is bounded

above by
Φ ▶ s · Φ,s ▶ x ☒ h or by
 Φ ▶ z ☒ h · Φ,z ☒ h ▶ x ☒ h 
where Φ = {a, b, z, z ☒ h}. The first quantity is clearly negligible. We must show the same for the second.
Likewise, Proposition 6.5 implies that the probability that Peggy can respond
Early is bounded above by
 s, a, b ▶ x③nh · s, a, b, x③nh ▶ x ☒ h 
Note that in the attack run A, the Attacker cannot learn x until after she has created z. The distribution of z is thus independent from that of x.
Proposition 6.6 Suppose that the Attacker, before receiving Victor’s challenge x, can pick her own challenge z and obtain a single response z ☒ h. Then the stream of expected probabilities Prob(V|A) that the Attacker can deceive Victor by guessing x ☒ h is indistinguishable from the stream of probabilities p deﬁned by
Σ	 3 l

This means that Prob(V|A) is negligible.
Proposition 6.7 The stream of expected probabilities Prob(V|E) that Peggy can deceive Victor by guessing and sending her response before she receives the challenge is indistinguishable from the stream q deﬁned by

ql = Σ
Σ 2−l
h ▶ x ☒ h l
 3 l

h∈ZÆ x∈ZÆ
2	2
This means that Prob(V|E) is negligible.
Note in particular that this means that in both cases the stream of probabilities is indistinguishable from zero, since the stream 3 l is itself indistinguishable from
zero.
The final result is obtained by putting Propositions 6.4 and 6.6 together.
Theorem 6.8 Suppose that the Hancke-Kuhn protocol is realized in such a way that it satisfyes 6.1, and does not always fail for trivial reasons: i.e., there are some sessions with an honest prover Peggy and an honest veriﬁer Victor. Formally, this means that there are C, D ∈ (0, 1) such that
Prob(A), Prob(E) < C, i.e. not every response is from an Attacker, or too E arly,
Prob(V) > D, i.e. Victor sometimes observes a satisfactory run and accepts.
Then Prob(crp) is indistinguishable from 1. In other words, the Hancke-Kuhn pro- tocol achieves authentication almost certainly.

Conclusion
We have presented a framework for extending algebraic cryptographic models to probabilistic models and used it to construct a probabilistic extension of the Pro- tocol Derivation Logic. We have illustrated it by applying it to an analysis of the Hancke-Kuhn distance bounding protocol. We expect that it will be useful in the analysis of many other protocols that rely on weak cryptography to take advantage of non-standard communication channels.
We should also point out that the potential applications of our framework go far beyond purely probabilistic extensions. The main thing that needs to be done to make our framework applicable to computational models is to define a notion of feasibly computable functions, so that guessing probability can be defined in terms of feasible function streams instead of all possible function streams. We have defined such a notion and are currently investigating its applications to protocols. In future work, we expect to present a more general framework that can incorporate a wide range of methods of cryptographic reasoning.

Acknowledgement
We are grateful to Joshua Guttman, John Mitchell, Mike Mislove, and to several anonymous referees for careful reading of earlier versions of this paper, and for valuable suggestions towards improvements in presentation.

References
M. Abadi and P. Rogaway. Reconciling two views of cryptography (the computational soundness of formal encryption). J. of Cryptology, 15(2):103–127, 2002.
Matthias Anlauff, Dusko Pavlovic, Richard Waldinger, and Stephen Westfold. Proving authentication properties in the Protocol Derivation Assistant. In Pierpaolo Degano, Ralph Ku¨sters, and Luca Vigano, editors, Proceedings of FCS-ARSPA 2006. ACM, 2006. to appear.
Michael Backes, Dennis Hofheinz, and Dominique Unruh. Cosp: a general framework for computational soundness proofs. In Ehab Al-Shaer, Somesh Jha, and Angelos D. Keromytis, editors, ACM Conference on Computer and Communications Security, pages 66–78. ACM, 2009.
M. Bellare and P. Rogaway. Random oracles are practical: a paradigm for designing efficient protocols. In CCS ’93: Proceedings of the 1st ACM conference on Computer and communications security, pages 62–73, New York, NY, USA, 1993. ACM.
Thomas Beth and Yvo Desmedt. Identification tokens - or: Solving the chess grandmaster problem. In CRYPTO ’90: Proceedings of the 10th Annual International Cryptology Conference on Advances in Cryptology, pages 169–177, London, UK, 1991. Springer-Verlag.
Stefan Brands and David Chaum. Distance-bounding protocols. In EUROCRYPT ’93: Workshop on the theory and application of cryptographic techniques on Advances in cryptology, pages 344–359, Secaucus, NJ, USA, 1994. Springer-Verlag New York, Inc.
S. Capkun and J. P. Hubaux. Secure positioning in wireless networks. IEEE Journal on Selected Areas in Communication, 24(2), February 2006.
Iliano Cervesato, Catherine Meadows, and Dusko Pavlovic. An encapsulated authentication logic for reasoning about key distribution protocols. In Joshua Guttman, editor, Proceedings of CSFW 2005, pages 48–61. IEEE, 2005.
V. Cortier, S. Delaune, and P. Lafourcade. A survey of algebraic properties used in cryptographic protocols. J. Comput. Secur., 14(1):1–43, 2006.


A. Datta, A. Derek, J. Mitchell, and A. Roy. Protocol composition logic (PCL). Electron. Notes Theor. Comput. Sci., 172:311–358, 2007.
Anupam Datta, Ante Derek, John Mitchell, and Dusko Pavlovic. A derivation system and compositional logic for security protocols. J. of Comp. Security, 13:423–482, 2005.
Anupam Datta, Ante Derek, John C. Mitchell, Vitaly Shmatikov, and Mathieu Turuani. Probabilistic polynomial-time semantics for a protocol security logic. In Lu´ıs Caires, Giuseppe F. Italiano, Lu´ıs Monteiro, Catuscia Palamidessi, and Moti Yung, editors, ICALP, volume 3580 of Lecture Notes in Computer Science, pages 16–29. Springer, 2005.
Y. Desmedt. Major security problems with the “unforgeable”(Feige-)Fiat-Shamir proofs of identity and how to overcome them. In Securicom 88, 6th worldwide congress on computer and communications security and protection, pages 147–159, Paris France, March 1988.
Danny Dolev and Andrew C. Yao. On the security of public key protocols. Information Theory, IEEE Transactions on, 29(2):198–208, 1983.
Nancy Durgin, John Mitchell, and Dusko Pavlovic. A compositional logic for proving security properties of protocols. J. of Comp. Security, 11(4):677–721, 2004.
Douglas  Engelbart.	Augmenting human intellect: A conceptual framework. http://sloan.stanford.edu/MouseSite/EngelbartPapers, October 1962.
Javier Thayer Fabrega, Jonathan Herzog, and Joshua Guttman. Strand spaces: What makes a security protocol correct? Journal of Computer Security, 7:191–230, 1999.
Oded Goldreich. Foundations of Cryptography. Volume I: Basic Tools. Cambridge University Press, 2000.
George A. Gratzer. Universal Algebra. Van Nostrand Princeton, N.J.,, 1968.
Joshua D. Guttman, F. Javier Thayer, and Lenore D. Zuck. The faithfulness of abstract protocol analysis: Message authentication. Journal of Computer Security, 12(6):865–891, 2004.
Gerhard P. Hancke and Markus G. Kuhn. An RFID distance bounding protocol. In SECURECOMM ’05: Proceedings of the First International Conference on Security and Privacy for Emerging Areas in Communications Networks, pages 67–73, Washington, DC, USA, 2005. IEEE Computer Society.
Catherine Meadows and Dusko Pavlovic. Deriving, attacking and defending the GDOI protocol. In Peter Ryan, Pierangela Samarati, Dieter Gollmann, and Refik Molva, editors, Proceedings of ESORICS 2004, volume 3193 of Lecture Notes in Computer Science, pages 53–72. Springer Verlag, 2004.
Catherine Meadows, Radha Poovendran, Dusko Pavlovic, LiWu Chang, and Paul Syverson. Distance bounding protocols: authentication logic analysis and collusion attacks. In R. Poovendran, C. Wang, and S. Roy, editors, Secure Localization and Time Synchronization in Wireless Ad Hoc and Sensor Networks. Springer Verlag, 2006.
Dusko Pavlovic and Catherine Meadows. Deriving secrecy properties in key establishment protocols. In Dieter Gollmann and Andrei Sabelfeld, editors, Proceedings of ESORICS 2006, volume 4189 of Lecture Notes in Computer Science. Springer Verlag, 2006.
Dusko Pavlovic and Douglas R. Smith. Composition and refinement of behavioral specifications. In Automated Software Engineering 2001. The Sixteenth International Conference on Automated Software Engineering. IEEE, 2001.
Dusko Pavlovic and Douglas R. Smith. Guarded transitions in evolving specifications. In H. Kirchner and C. Ringeissen, editors, Proceedings of AMAST 2002, volume 2422 of Lecture Notes in Computer Science, pages 411–425. Springer Verlag, 2002.
Vaughan Pratt. Modelling concurrency with partial orders. Internat. J. Parallel Programming, 15:33– 71, 1987.
Ronald L. Rivest. On the notion of pseudo-free groups. In Moni Naor, editor, TCC, volume 2951 of
Lecture Notes in Computer Science, pages 505–521. Springer, 2004.
Phillip Rogaway and Thomas Shrimpton. Cryptographic hash-function basics: Definitions, implications, and separations for preimage resistance, second-preimage resistance, and collision resistance. In Bimal K. Roy and Willi Meier, editors, Proceedings of FSE, volume 3017 of Lecture Notes in Computer Science, pages 371–388. Springer, 2004.
Patrick Schaller, Benedikt Schmidt, David Basin, and Srdjan Capkun. Modeling and verifying physical properties of security protocols for wireless networks. In In Proceedings of the IEEE Computer Security Foundations Symposium. IEEE Computer Society Press, 2009.
Steve Selvin. On the Monty Hall problem. American Statistician, 29(3):134, August 1975. (letter to the editor).


Steve Kremer V´eronique Cortier and Bogdan Warinschi. A survey of symbolic methods in computational analysis of cryptographic systems. J. of Automated Reasoning, 2010. to appear.

A. F. Webster and Stafford E. Tavares. On the design of S-boxes. In Hugh C. Williams, editor, Proceedings of CRYPTO 1985, volume 218 of Lecture Notes in Computer Science, pages 523–534. Springer, 1985.
Ford Long Wong and Frank Stajano. Multichannel security protocols. IEEE Pervasive Computing, 6(4):31–39, 2007.

A	Appendix: The Proofs
Proof of Prop. 4.7. Let ƒl and gl be randomized functions. Consider the sets F =
{χl | ƒlJΞ)χl = JΓ)χl} and G = {ηl | glJΞ, Γ)yl = JΘ)yl}.
Claim 1. If for x, y ∈ X (Ξ, Γ) and ηl such that glJΞ, Γ)yl = JΘ)yl holds ηl(x) = 
/	η (y), holds
ηl(y), then for ηl, which is equal to ηl everywhere except on ηl(x) =  l
that glJΞ, Γ)yl = JΘ)yl, for g modified accordingly. (Intuitively, separating two pieces of input can only provide more information, not less.)
Claim 2. If ƒlJΞ)χl = JΓ)χl} and dom(χl) ⊆ dom(ηl), with χl(x) /= χl(y) ⇒ ηl(x) /= ηl(y), then ƒl can be precomposed with a permutation to yield ƒl with dom(ƒl) ⊆ dom(ηl) and ƒlJΞ)yl = JΓ)yl}.
The consequence of these claims is that we can modify ƒl and gl to ƒl and gl so
Now let hl(x) = ƒl(x) :: gl(x :: y).	Since thus hlJΞ)yl = (ƒ JΞ)yl) :: (g (JΞ)yl :: ƒ JΞ)yl)) = JΓ, Θ)yl holds, we have


#{ηl | ƒlJΞ)l = JΓ)l} 2|Ξ,Γ,Θ|Æ
· #{ηl | glJΞ, Γ)l = JΘ)l} 2|Ξ,Γ,Θ|Æ
≤
#{ηl | hlJΞ)l = JΓ, Θ)l}
2|Ξ,Γ,Θ|Æ

The inequality Ξ ▶ Γ · Ξ, Γ ▶ Θ ≤ Ξ ▶ Γ, Θ follows by observing that #{ηl | ƒlJΞ)l = JΓ)l} = #{χl | ƒlJΞ)l = JΓ)l}
2|Ξ,Γ,Θ|Æ	2|Ξ,Γ,|Æ

Proof of Prop. 5.2. For (a), xi = zi yields ƒi(xi)= ƒi(zi), so we only need to guess at most n − ni bits. For (b), xi and zi are bits, and n − Δ(x, z) of them are equal, so we only need to guess at most Δ(x, z) bits.	 
Proof of Lemma 5.3. (ƒ (x))i  = ƒi(xi) =  x ☒ ƒ (0l) :: ƒ (1l)  holds by the
definition of bitwise partitioned functions at the first step, and by (1) at the second
step.	 
Proof of Prop. 5.4. Assumptions (12) say that the inequality xi /= zi implies xi, zi, ƒi(zi) ▶ ƒi(xi) = xi ▶ ƒi(xi) . On the other hand, by definition, the components of a partitioned function are mutually independent.Hence

 x, z, ƒ (z) ▶ ƒ (x)  =
l
x, z, ƒ (z) ▶ ƒi(xi)	=
i=1
l


i=1 xi/=zi

 xi ▶ ƒi(xi) 

1
=
2
Δ(z,x)
= 2—Δ(z,x)

The other way around, using (11) at the second step, we get
l
x, z, ƒ (z) ▶ ƒi(xi) = x, z, ƒ (z) ▶ ƒ (x)	= 2—Δ(z,x)
i=1

l
=
i=1 xi/=zi
 xi ▶ ƒi(xi) 

which, with the componentwise independence, yields (12).	 
Proof of Prop. 5.6. Note that for each i ∈ nh, the bit (x ☒ h)i = h(0) = h(1) does
i	i
not depend on xi. This means that x ☒ h only depends on x③nh.	 
Proof of Prop. 5.7. Guessing x ☒ h from z and z ☒ h can be modeled as a version of the Monty Hall problem [31], where Monty randomly selects x and h and the contestant chooses z. Monty then announces z ☒ h and the contestant guesses x ☒ h. Since the bits of x☒ are independent, it is enough to consider the case l = 1.
Monty then flips three fair coins to pick the secret bits x, h(0), and h(1), while the contestant picks a bit z. Monty then announces z ☒ h = h(z). Should the contestant now guess that x ☒ h = z ☒ h, or should he switch to x ☒ h = ч(z ☒ h)?
Denote by q the probability that the contestant picks x☒h = z☒h. If h(0) = h(1), the contestant wins with this choice, because the value x ☒ h is the same for every
x. Since h(0) and h(1) were randomly chosen, Prob(h(0) = h(1)) = 1 . Otherwise, if h(0) /= h(1), then x ☒ h = z ☒ h holds if and only if x = z. Since x is random,
Prob(x = z)= 1 , and hence Prob(h(0) /= h(1) Λ x = z)= 1 , because h(0), h(1) and
2	4
x are independent.
The probability that the contestant will make a correct guess is thus
q ·  Prob h(0) = h(1) + Prob h(0) /= h(1) Λ x = z	=	3q
4
To maximize this probability, the contestant needs q = 1, and should thus stickwith Monty’s bit z ☒ h.
The proof for z ☒ h ▶ x ☒ h differs just in the detail that z is not chosen by the contestant, but obeys some unknown distribution. However, x is still independent of z. Thus for some p, Prob(x = z) = Prob(x = 0) · Prob(z = 0) + Prob(x =
1) · Prob(z = 1)= 1 p + 1 (1 — p)= 1 .	 
2	2	2
Proof of Lemma 6.2(a). By assumption, the outputs of the hash function H are indistinguishable from random strings, and thus satisfy H(u) ⊥ H(v) for all u /= v. Recall that A(x ☒ h) is the union of the contexts observed by the possible par- ticipants in the run A, before x☒h is known. Besides s, known by Victor and Peggy,

and a, b and x, announced publicly but never reused, the context A(x ☒ h) thus also contains a single additional challenge z, issued by the Attacker, and the corre- sponding response z ☒ h (provided by Peggy before she receives Victor’s challenge x).

Moreover, the Attacker may issue a family Y ⊆ Zl
of additional challenges to

Peggy, and construct a list {by}y∈У of the future values of Victor’s counter. To
each new challenge, Peggy will respond with y ☒ hy, where each response token hy = H(s :: ay :: by) is derived using a new value of the counter ay. By assumption, hy ⊥ h holds for all y. Independently of the distance of Y and the challenge x, the responses y ☒ hy will provide no information about x ☒ h. In summary, the term context A(x ☒ h) is thus
{s, a, b, x, z, z ☒ h}∪ {y, ay, by,y ☒ hy | hy = H(s.ay.by) Λ y ∈ Y }
for some Y ⊆ Zl , where a : Y → Zl is injective, and b : Y → Zn arbitrary. The
2	2	2

{s, a, b, z, z ☒ h}∩ Ξ= ∅ =⇒ Ξ ⊥ x ☒ h
and we are done.
The proof of 6.2(b) is analogous, but slightly simpler, elaborating the fact that obtaining one challenge tells nothing about another one.	 
Proof of Lemma 6.3. Since h is indistinguishable from random, the bits of any hl are indistinguishable from independent. The probability of guessing any chosen substring of length l in h is indistinguishable from 2—l. In particular, the probability of guessing xl ☒ hl for a chosen xl is indistinguishable from 2—l. Knowing which substring is being guessed presents no advantage, and thus xl ▶ xl ☒ hl = 2—l.
Equations (17) and (18) follow from Prop. 5.6.	 
Proof of Prop. 6.4. The claim follows from the fact that each set Ξ ⊆ A(x ☒ h) such that Adv Ξ ▶ x ☒ h > 0 satisfies at least one of the following inequalities:
Ξ ▶ x ☒ h ≤ Ξ ▶ s · Ξ,s ▶ x ☒ h	(A.1) Ξ ▶ x ☒ h ≤ Ξ ▶ z ☒ h · Ξ,z ☒ h ▶ x ☒ h	(A.2)
According to Lemma 6.2(a) for each subset Ξ of A(x☒ h) such that a ∈ Ξ, it suffices to consider the set Ξ ∩ {s, a, b, x, z, z ☒ h}. Once the problem is reduced this far, the rest follows by case analysis, using Lemma 6.3.	 
Proof of Prop. 6.5. The claim is that each Ξ ⊆ E(x) such that Adv Ξ ▶ x ☒ h > 0 satisfies
Ξ ▶ x ☒ h ≤ Ξ ▶ x③nh · Ξ, x③nh ▶ x ☒ h	(A.3)
Lemma 6.2(b) says that it suffices to consider Ξ ∩ {s, a, b} if a ∈ Ξ. Thus, we only need to consider the subsets of {s, a, b}, and since b is deterministic, this reduces to the subsets of {s, a}. The assumption that the stream h is indistinguishable from

random implies Ξ ▶ x☒h l = 2	whenever Ξ is a proper subset of {s, a}. So (A.3)
—l
holds trivially in that case. For Ξ = {s, a}, using Prop. 5.6 and Lemma 6.3, we have
 Ξ ▶ x☒ h l = Ξ ▶ x	 = 2	and on the other hand Ξ, x	▶ x☒ h  = 1.
③nh	|nh|—l	③nh
Hence (A.3).	 
Proof of Prop. 6.6. Since Prob(x ∈ Zl )= 2—l by assumption, and x, z, z ☒h ▶ x☒

h = 2—Δ(z,x) by (11), it follows that

Σ	Σ l 

			
3l	 3 l


	



Proof of Prop. 6.7. By hypothesis the token h = H(s :: a :: b) is indistinguishable from a random value. Since s, a, b ⊥ x also holds by assumption, s, a, b ▶ x☒h =
 h ▶ x ☒ h follows, because s, a, b can only be useful to derive h = H(s :: a :: b).
expected value that Peggy will guess x ☒ h are averaged over the possible values of
h, and hence

Σ Σ 2—l

h ▶ x ☒ h l
=	2—l · Σ
 l 

2i—l = 2—2l · 3l =
 3 l

h∈ZÆ x∈ZÆ	i
2	2

Proof of Thm. 6.8. By (15), to prove the Theorem, it suffices to show that both Prob(A|V) and Prob(E|V) are negligible. The Bayes’ Theorem and the hypotheses imply

Prob(A|V)= 
Prob(V | A) · Prob(A) ≤
Prob(V)
Prob(V | A) · C D

Since Prob(V|A) is negligible by Prop. 6.6, Prob(A|V) is negligible too. The fact that Prob(E|V) is negligible follows in the same way from Prop. 6.7.	 
