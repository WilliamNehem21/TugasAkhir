Available online at www.sciencedirect.com



Electronic Notes in Theoretical Computer Science 278 (2011) 275–288
www.elsevier.com/locate/entcs

A Logical Model of the Dynamics of Peer Pressure
Liang Zhen 1
Institute of Logic and Intelligence Southwest University Chongqing, China
Jeremy Seligman2
Department of Philosophy University of Auckland New Zealand

Abstract
Following the general programme of [6], we investigate the effect of social relationships on the dynamics of preference change within a community. Specifically, we are interested in the phenomenon of ‘peer pressure’, according to which a person’s preferences are changed in response to the preferences of a ‘peer group’. This involves both aggregation of preferences, to determine the group’s preferences and preference change. We propose a simple model of peer pressure which is still sufficiently non-trivial to display some interesting dynamics, and show how the stable configurations can be expressed logically.
Keywords: preference logic, logic in the community, aggregation, social dynamics, hybrid logic


An Example
A community of teenage girls is divided between two current fashions. Some strictly prefer A, others strictly prefer B, others are I indifferent and yet others are con- flicted O. They are influenced by their friends’ choices in the following way. If all of their friends strictly prefer one of the styles then they will too. We’ll call this strong suggestion. Even if some of their friends are indifferent, if the rest strictly prefer one style, they will still be influenced, but not as strongly. We’ll call this weak suggestion. In this case, they will change their preference so that they regard

1 Email: soul21@163.com
2 Email: j.m.seligman@gmail.com



1571-0661 © 2011 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2011.10.021

the style preferred by their non-indifferent friends so that it is at least as good as the other one. This means that if they are conflicted they will resolve the conflict in favour of their friend’s choice, and if they prefer the other style, they will become indifferent. In all other cases the girls don’t change their opinion.
The resulting dynamics has some interesting features. Representing the friendship relation as a graph we see the following looping patterns:
 B	~ B  A  ~ A  B	~ B  A  ~ ··· 


A	B
~ A	~ B
A	B
A	B
~ A	~ ··· 
A	B

If one of the friends is indifferent, however, the pattern stabilizes:


B	A	A
B ~ B
I
B
I  ~ A
B
I	I
B ~ B
B
B	B	B
B ~ B	B
B	B

A	B	B	I	B	B	B	B	B	B


A configuration I
A
with an indifferent mutual friend is stable and even when
B

the indifferent friend is out on a wing of the group, the pattern stabilizes quickly to that of the mutual friend:

B	B
~ I	~ B
I	B	B


A
When all three are friends, however, indifference spreads: I	~ I
B
I
Indif-
I



ference is not so easily shaken, as I
slightly more easy to influence:
I
is stable. But those who are conflicted are
A


I	I	A
O	~ A	~ A
A	A	A

Two friends of the same type will stand in solidarity, no matter what their environ- ment:

Preference Logic in the Community
The general framework we adopt to discuss this phenomenon is from [6]. Specifically, we will use a version of ‘facebook logic’, in which a community is modelled by a symmetric relation of ‘friendship’ which may vary across a space of possibilities. Although real communities involve much more complex social relations, ‘friendship’ alone is sufficient to demonstrate interesting dynamic behaviour.
Our models, then, will have a set A of agents, a set W of possible states and the following relations:
For each w ∈ W , a symmetric and irreflexive relation ∼w on A, which we interpret as friendship: a ∼w b means that in state w, a is friends with b. The community of a is the set of agents to whom a is connected by a chain of friends, and this is respresented by ∼∗, the transitive closure of ∼.
For each a ∈ A, a relation ≤a on W , which we interpret as preference: u ≤a v
means that for a, state v is at least as good as state u.
A community preference frame, then, is a structure F = ⟨W, A, ∼, ≤⟩. We allow for the case that our agent’s preferences are not fully rational, in the sense that ≤a may not be transitive. In the case that it is, we will say that F is transitive.
We reason about such frames using a modal language
ϕ ::= i	|	n	|	p	|	¬ϕ	|	(ϕ ∧ ϕ)	|	Fϕ	|	F∗ϕ	|	Pϕ	|	Uϕ 
where i ∈ Snom, a set of state nominals, n ∈ Anom, a set of agent nominals, p ∈ Prop, a set of propositional variables. The nominals are included in the language so that we can reason about particular agent’s preferences concerning particular states. A formula ϕ in this language is an indexical proposition, which is true or false in a state w about an agent a. In particular, the modal operators are interpreted as follows:
Fϕ means ‘all my friends, ϕ’
F∗ϕ means ‘everyone in my community, ϕ’
Pϕ means ‘all states in which ϕ holds are least as good as the current one (ac- cording to me)’
Uϕ means ‘in all states, ϕ’
More precisely, given a model M = ⟨F, V ⟩ where V : Prop ∪ Snom ∪ Anom → PW ×A is a valuation function such that V (i) is {i}× A for each i ∈ Snom and V (n) is W × {n} for each n ∈ Anom, we define


Notice in particular that P is not a normal modal operator. It is a ‘window’ operator in the sense of [1] (pp. 426–427). We need this to define preference between arbitrary propositions:

In other words, I regard ψ as at least as good as ϕ iff every ψ-but-not-ϕ-state is at least as good as every ϕ-but-not-ψ-state. My preferences concerning states that are both ϕ and ψ or neither ϕ nor ψ are irrelevant. And I prefer ψ to ϕ iff ψ is at least as good as ϕ but ϕ is not at least as good as ψ. The latter hold just in case there is at least one ψ-but-not-ϕ-state that is strictly better than all of the ϕ-but-not-ψ-states, but in conjunction with the first clause, this is equivalent to every ψ-but-not-ϕ-state being strictly better than every ϕ-but-not-ψ-states.
Two special cases are worth mentioning form the outset. Firstly, the definition is consistent with preferences between particular states: (i ≤ j) holds for agent a iff i ≤a j. Secondly, we can represent a weak preference for ϕ as (¬ϕ ≤ ϕ). Since ϕ and ¬ϕ are nowhere satisfied together, this is equivalent to U (¬ϕ → P ϕ). This holds when all the ϕ-states are at least as good as all the ¬ϕ states. A preference for ϕ, represented by (¬ϕ < ϕ) holds when at least one ϕ-states is strictly preferred to all the ¬ϕ-states.
Many definition of preference have been offered in the literature, but we believe that this one captures the simplest concept of rational preference, namely preference ceteris paribus. That is, if we assume that all of the states are equivalent ‘other things being equal’ then one should prefer ψ to ϕ under the specified condition. 3
Some further abbreviation are useful:

3 Note that ≤ is reflexive, in the sense that (ϕ ≤ ϕ) is valid.


Preference and preference change
To model these changes we consider two operators [X ≤ Y ] and [X < Y ] which upgrade the agent’s preferences in response to the perception that other agents have the corresponding preferences regarding X and Y , which are subsets of W . We will be most interested in the case where X and Y are denotations of formulas, i.e., sets of the form [ϕ] = {w ∈ W | M, w, a |= ϕ}. But the definition of these operators is easier to grasp in a more abstract setting.
For any relation ≤ on W , the operators are defined as follows. First let (X ≤ Y ) be the set of ⟨u, v⟩ such that u ∈ X and v ∈ Y . And note that M, w, a |= (ϕ ≤ ψ) iff ([ϕ] ≤ [ψ]) ⊆≤a. Now we will first assume that X and Y are disjoint. Then
[X ≤ Y ](≤) is ≤ ∪(X ≤ Y )
[X < Y ](≤) is (≤ ∪(X ≤ Y )) \ (Y ≤ X)
In other words, [X ≤ Y ] updates the agent’s preference relation by adding links from all X-states to all Y -states, and [X < Y ] does the same but also deletes links from all Y -states to all X-states. In the case that X and Y are not disjoint we use X \ Y and Y \ X in place of X and Y :
[X ≤ Y ]= [(X \ Y ) ≤ (Y \ X)]
[X < Y ]= [(X \ Y ) < (Y \ X)]
This limits the upgrade to those states on which X and Y disagree. A state that is in both X and Y or in neither of them should not be affected by the upgrade.
In both cases, these operations may not preserve the transitivity of ≤. For example,

p, q
1
q 0
2 p



[p ≤ q]
q 0
=⇒
p, q
1


2 p

When we only add links, in the case of [X ≤ Y ] there is a way to repair any loss

of transitivity, by adding more links. There is a unique smallest transitive relation containing [X ≤ Y ](≤), namely its transitive closure. This can be defined in a local way, as the following lemma shows:
Lemma 3.1 Let (X ≤ Y )∗ be the set of ⟨u, v⟩ such that there is an x ∈ X and a y ∈ Y for which u ≤ x and y ≤ v. Then ≤ ∪(X ≤ Y )∗ is the transitive closure of [X ≤ Y ](≤).
Proof. Suppose ⟨u, v⟩ and ⟨v, w⟩ are in ≤ ∪(X ≤ Y )∗.
u ≤ v. If v ≤ w then u ≤ w. Otherwise, there is x ∈ X and y ∈ Y such that
v ≤ x and y ≤ w. But u ≤ v so u ≤ x and y ≤ w and so ⟨u, w⟩∈ (X ≤ Y )∗.
v ≤ w. Similarly.
There are x1, x2 ∈ X and y1, y2 ∈ Y such that
u ≤ x1 and y1 ≤ v v ≤ x2 and y2 ≤ w
and so because of x1 and y2, ⟨u, w⟩∈ (X ≤ Y )∗.


When we delete links, in the case of [X < Y ], the situation is more complicated. We would have to repair by deleting more links, and there need be no unique maximal way of doing this. This means that the operation of upgrading preferences so as to make them strict, while retaining transitivity is non-deterministic. For the remainder of the paper, we will consider only the case this non-transitivity- preserving but deterministic operator, so as to simplify the dynamics. 4
In a model M , we write the result of upgrading agent a’s preferences with these operators as [X ≤ Y ]aM and [X < Y ]aM respectively. 5 We can then add a dynamic component to our logic, by adding unary operators
[ϕ ≤ ψ] and [ϕ < ψ] with the following semantic conditions
M, w, a |= [ϕ ≤ ψ]θ	iff	[[ϕ] ≤ [ψ]]aM, w, a |= θ
M, w, a |= [ϕ < ψ]θ	iff	[[ϕ] < [ψ]]aM, w, a |= θ
As with many dynamic operators, the success of a preference upgrade is not guar- anteed. For example, in the following model [Pq < Pp]¬(Pq < Pp):

4 Liu in [5], p.23-4, proposes a weaker upgrade operator that deletes links only in the case of indifference, and shows that it preserves transitivity. But this is not strong enough to ensure success, in our sense.
5 More precisely, M = ⟨W, A, ∼, ≤⟩ then [X ≤ Y ]aM = ⟨W, A, ∼, ≤′⟩ where ≤′ =≤b for all b /= a and
≤′ = [X ≤ Y ](≤a). Similiarly for [X < Y ]aM .



p 0  1 q
[Pq < Pp]
=⇒
p 0  1 q

But in the case that ϕ and ψ do not contain the operator P, there is no change to the valuation, the domain or the friendship structure, and so both [ϕ ≤ ψ](ϕ ≤ ψ) and [ϕ < ψ](ϕ < ψ) are valid.

Suggestion Dynamics
Consider the issue of whether α is better than β, on which members of a community may have different opinions. To make the following discussion a little easier to follow, we will fix these formulas now, although everything we say about them will be quite general, except that they must satisfy the four preference upgrade success conditions: [α < β](α < β), [α ≤ β](α ≤ β), [β < α](β < α) and [β ≤ α](β ≤ α). We will say that an agent is subject to peer pressure regarding the issue of α vs. β if she satisfies the following condition:
If (Strong Suggestion) all of her friends strictly prefer α to β (and she has at least one friend) then she will upgrade her preferences with [β < α], otherwise
if (Weak Suggestion) all of her friends regard β as at least as good as α and some of then strictly prefer α to β then she will upgrade her preferences with [β ≤ α].
The conditions for the various types of suggestion can be expressed in our language as follows:


The operation of suggestion transforms a model M = ⟨W, A, ∼, ≤,V ⟩ to model #α,βM = ⟨W, A, ∼, #α,β(≤),V ⟩ where, for each a ∈ A,
⎧⎪ [α < β](≤a) if M, a, u |= S(α, β)



#α,β(≤a)	=
⎪⎨ [α ≤ β](≤a) if M, a, u |= W (α, β)
⎪ [β ≤ α](≤ ) if M, a, u |= W (β, α)

a
⎪
⎩ ≤a	if M, a, u |= N (α, β)
We also add the suggestion operator to our language, with the obvious definition:
M, a, u |= #α,βϕ	iff	#α,βM, a, u |= ϕ
So #α,βϕ means that the agent is subject to peer pressure and after upgrading her preferences satisfies the description ϕ. It can be shown that #α,βϕ is equivalent to the conjunction of the following formulas:
S(α, β) → [α < β]ϕ
S(β, α) → [β < α]ϕ
W (α, β) → [α ≤ β]ϕ
W (β, α) → [β ≤ α]ϕ N (α, β) → ϕ
This is the basis for the dynamic behaviour observed earlier, and it is to apply our analysis of suggestion to such examples that we now turn. We will need some abbreviations for both the preference states of an agent concerning α and β and for the conditions under which they upgrade their preference in response to sugges- tion.


WN	F (I ∨ N) ∧ ⟨F⟩N ∧ ⟨F⟩I	 my friends only weakly suggest N Z	¬(SY ∨ SN ∨ WY ∨ WN)	my friends have no suggestion
We can think of these as states of a finite state machine, depicted below.
Z WN WY








Z	Z
WN	WY
SN	SY








Z
A transition from state A to state B labelled with condition C represents the validity of the formula
(A ∧ C) → #α,β B
which is ensured by the definition of suggestion and the fact that α and β satisfy the preference upgrade success conditions. For example, if an agent is in state Y and her friends only weakly suggest N, so that WN is true, then after suggestion, she will be in state I, which is to say that she becomes indifferent.

Gaining Stability
The main result of this paper is to characterise the class of pointed models that stabilize under suggestion, in the manner illustrated in Section 1. An agent a in state u of model M has stable preferences iff for some preference state σ ∈ {Y, N, I, O} for each n ≥ 0,

n α,β
M, u, a |= σ

The model M is stable at u iff every agent has stable preferences at u. In other words, they are all completely fixed in their comparison of α and β and immune to suggestion from their friends. We have already seen a number of examples of stable models, and some that never become stable. In the middle are those models that change for a number of iterations before becoming stable. This is the class we will

characterise. So, say that a model M stabilizes at u iff for some n ≥ 0, #n
M is

stable at u. 6 Likewise, we will say that an agent’s preferences stabilize at u in M
iff for some n ≥ 0, a has stable preferences at u in #n M .
Some formulas are very well behaved with respect to suggestion. They never change their truth value. We say that ϕ is an invariant of #α,β iff for any model M , state u and agent a,
M, u, a |= (ϕ → #(α, β)ϕ)
The central examples of invariant needed for our main theorem are as follows:
Lemma 5.1 The following formulas are invariants of #α,β:
Y ∧ ⟨F⟩Y	(5) N ∧ ⟨F⟩N
I ∧ ⟨F⟩I
Y ∧ F (I ∨ Y)	(6) N ∧ F (I ∨ N)
(Y ∨ I) ∧ ⟨F⟩(Y ∨ I)	(7) (N ∨ I) ∧ ⟨F⟩(I ∨ N)
F∗((F Y ∧ FF N) ∨ (F N ∧ FF Y))
⟨F⟩T

Proof. (To make the presentation of this and subsequent proofs easier to read, we

will abbreviate #n
M, u, a |= ϕ to n, a |= ϕ. So to show invariance of ϕ, we have

to show that 0,a |= ϕ implies 1,a |= ϕ.)
Suppose 0,a |= Y ∧ ⟨F⟩Y. Then 0,a |= SN and 0,a |= WN. So from the state machine we see that a can only remain in state Y, i.e., 1,a |= Y. But 0,a |= ⟨F⟩Y implies that a has a friend b in state Yand so 0,b |= Y ∧⟨F⟩Y. This means that b must also remain in Y. Thus 1,b |= Y,and so 1,a |= Y ∧ ⟨F⟩Y.
The argument is similar to that for (1). From the state machine, we see that
a and her friend must stay in state I.
Suppose 0,a |= Y ∧ F (I ∨ Y). Since 0,a |= F (I ∨ Y) we see that again 0,a |= SN and 0,a |= WN and so from the state machine, a must stay in Y. Now any friend b of a is either in state Y or in state I. In the first case, 0,b |= Y ∧ ⟨F⟩Y so by invariant (1), 1,b |= Y. In the second case, since a is a friend of b, 0,b |= ⟨F⟩Y and so 0,b |= SN. From the state machine, we see that b can only stay in I or move to Y. In either case, 1,b |= (Y ∨ I) and so 1,a |= Y ∧ F (I ∨ Y).

6 The constant reference to state u is required because in the community preference frame, friendship relations vary across states of the model.

Suppose 0,a |= (I ∨ Y) ∧⟨F⟩(I ∨ Y). Then there is a friend b of a such that both a and b are in states Y or N. If they are are in the same, then they will keep these states by the invariant (1) or (2). And if they are different, without loss of generality, suppose 0,a |= Y and 0,b |= I. Then 0,a |= ⟨F⟩I and so 0,a |= SN and must therefore either stay in state Y or move to state I, as shown in the state machine. Similarly, 0,b |= ⟨F⟩Y and so 0,b |= SN and must therefore either stay in state I or move to state Y. Either way, 1,a |= (I ∨ Y) ∧ ⟨F⟩(I ∨ Y).
Suppose 0,a |= F∗((F Y ∧ FF N) ∨ (F N ∧ FF Y)). Let b be a member of a’s community, i.e. b ∼∗ a. Then also 0,b |= F∗((F Y ∧ FF N) ∨ (F N ∧ FF Y)) and, in particular, 0,b |= ((F Y ∧ FF N) ∨ (F N ∧ FF Y)) Then without loss of generality, suppose 0,b |= (F Y ∧ FF N).
Let c be a friend of b. Then 0,c |= (Y ∧ F N). And because b is a friend of c, 0,b |= N. But also 0,b |= F ((F Y ∧ FF N) ∨ (F N ∧ FF Y)), so 0,c |= ((F Y ∧FF N) ∨ (F N ∧FF Y)). But 0,c |= (F Y ∧FF N) because 0,b |= N and so 0,c |= (F N ∧ FF Y). Now 0,c |= SN because all his friends are N and so after suggestion, 1,c |= N and since c was chosen arbitrarily as a friend of b, we can conclude that 1,b |= F N.
Now let d be a friend of c. Again 0,d |= ((F Y ∧FF N)∨(F N∧FF Y)) because 0,b |= FF ((F Y ∧ FF N) ∨ (F N ∧ FF Y)). But c is d’s friend and is in state Y so the second disjunct cannot hold and 0,d |= (F Y ∧ FF N). So 0,d |= SY and 1,d |= Y. Again d is an arbitrary friend of a friend of b, so 1,b |= FF Y.
Thus 1,b |= (F N ∧ FF Y) and hence 1,b |= ((F Y ∧ FF N) ∨ (F N ∧ FF Y)). But b is an arbitrary member of a’s community, so 1,a |= F∗((F Y ∧ FF N) ∨ (F N ∧ FF Y)).
is obvious and the remaining cases are Y-N symmetric versions of the others, and so require no further proof.	 
From these, we can show an important sufficient condition for stabilization:
Lemma 5.2 If M, u, a |= I then a’s preferences in M stabilizes at u for #α,β.
Proof. Suppose 0,a |= I. Then from the state machine, we see that she can only stay in I or move either to N or to Y So, either n, a |= I for all n, and so her preferences stabilize, or after n iterations of the suggestion operator, she moves. Since the two possibilities are Y-N symmetric, we can assume she move to Y, so that n + 1,a |= Y. But then, from the state machine, we see that n, a |= SY and so n, a |= (F Y ∧ ⟨F⟩Y). Now consider any friend b of a. Then n, b |= Y.. But a is friends with b, so n, b |= ⟨F⟩I, and so n, b |= SN. Then from the state machine, b can only stay in Y or move to I. So n + 1,b |= (I ∨ Y). But then n + 1,a |= F (I ∨ Y) and so n + 1,a |= (Y ∧ F (I ∨ Y)), which is an invariant by Lemma 5.1.	 
And now we are ready for the main theorem:

Theorem 5.3 M stabilizes at u for #α,β iff
M, u |= ¬(⟨F⟩T ∧ F∗((F Y ∧ FF N) ∨ (F N ∧ FF Y)))
Proof. Let LOOP be the formula F∗((F Y ∧ FF N) ∨ (F N ∧ FF Y)).  If M, u |=
¬(⟨F⟩T ∧ LOOP) then we must show that M does not stabilize at u. So suppose that there is an agent a such that M, u, a |= (⟨F⟩T ∧ LOOP) and, for contradiction,

that a’s preference are stable in #n
M at u. But by Lemma 5.1, LOOP is an

invariant and so n, a |= LOOP, which implies that
n, a |= ((F Y ∧ FF N) ∨ (F N ∧ FF Y))
Without loss of generality, suppose n, a |= (F Y ∧ FF N). Also ⟨F⟩T is an invariant, and so a has at least one friend, b, and n, b |= (Y ∧ F N). So a is in state N. Also a satisfies SY and so n + 1,a |= Y, contradicting the stability of a’s preferences at u in M .
For the converse, suppose that M, u |= ¬(⟨F⟩T ∧ LOOP). Let a be an agent. Then either a has no friends, in which case her preferences are already stable, or a does not satisfy LOOP at u in M . We must show that a’s preferences at u in M stabilize.
Now consider the state machine depicted earlier and suppose for contradiction that

that there is no n ≥ 0 such that a has stable preferences in #n
M at u. Since

there are only a finite number of states, a’s preferences must loop. If so, for some

n, a will be in either state Y or state N in #n
M at u. This is because if a is

initially in state Z then she cannot stay there, and Y or N are the only places to go. Also, by Lemma 5.2, it can never enter state I. So the only way to loop is by swtiching from Y to N and back. By symmetry again, we can assume that n, a |= Y and n + 1,a |= N. This can only happen by strong suggestion, so n, a |= SN, which implies n, a |= F N.
Consider a’ friends at stage n + 1. We’ll show that they can’t all be in state Y. If they were, then for any friend b, n, b |= SY because he has moved from N to Y and this can only happen if n, b |= SY. So n, b |= F Y. And this holds for all a’s friends, and so n, a |= FF Y. But we have showed that n, a |= F N and so satisfies LOOP, contradicting our earlier claim.
So at least one friend b of a is in state I or N there being no other possibilities in the machine. Then n+1,a |= ((I ∨ N) ∧⟨F⟩(I ∨ N)), which is an invariant, by Lemma 5.1. So for all m > n, m, a |= (I ∨ N). But we showes above that a’s preference can never be I and so it is always N, contradicting our assumption that a’s preferences do not become stable.	 

Concluding Remarks
We have examined a particular model of the way in which preferences within a community can be affected by social relations. The model is highly idealised but still

displays an interesting dynamic structure, especially with regard to the moderating effect of indifference and the possibility of looping vacillations within the group. By using the language of ‘logic in the community’ we have showed that it is possible to characterize this behaviour with a simple formula. This is an initial test case of our methodology. Many variables can be changed to model different kinds of dynamic social situations. Among the possibility are the treatment of knowledge or belief instead of preference and the consideration of asymmetry social relationship such as subordination and aggregation.
The most pressing issue, however, is that of looking at transitivity-preserving pref- erence upgrade operators. As we have shown, strong upgrade is an essentially non- deterministic operation, and so leads to non-deterministic dynamics, which should be interesting to investigate.
The application of modal logic to study study social dynamics of this kind is new (insofar as we know). 7 The usual approach is to use statistical modelling, typi- cally accompanied by computer simulations. This research dates back to [3], which lays out a number of postulates concerning the degree of influence of one agent on another agent’s opinions, and proves various theorems about the resulting stabilisa- tion patterns, specifically those concerned with whether or not a common opinion is formed. A recent example of research in this tradition is [4], which provides a good introduction to the mathematics involved and contains an extensive bibliog- raphy. The authors’ focus is the dynamics of ‘opinion fragmentation’ of which the formation of a consensus and the polarization of opinion are special cases.
Measured against this body of research, the contribution of the present paper can be seen as working along an orthogonal direction. Whereas most research in this area aims at giving more and more complex and accurate models of ‘influence’, we take a very simple model and show how to account for complex statements about it. As with all logic-based research, our emphasis is on what can be expressed in a particular formal language. A smaller, but significant, point is that our model is based on a very general model of preference, which includes the distinction be- tween ‘indifference’ and ‘conflict’. Most work in this area takes a metrical approach, measuring opinion on a linear scale - or, more generally, as a vector in a larger di- mensional space. Again these choices reflect a difference of focus. We are interested in the relationship between preferences between states and preferences between de- scriptions of states, and for this purpose the distinction between indifference and conflict is important.
Despite these differences, it is clear that existing research on social dynamics in psychology and AI contains many ideas that would contribute to a better under- standing of the relationship between logic and society of the kind pursued here. In particular, the interest in opinion fragmentation could provide a focus for future

7 [2] is titled ‘A Logic-based Architecture for Opinion Dynamics’ but there is no formal language or se- mantics as such. The ‘logic’ used is fuzzy logic, and it is used only in the sense that opinions are modelled as fuzzy sets. This approach suggests connections to the psychological literature that may be interesting to explore further but there is little direct comparison to be made with the present paper.

research.

References
Patrick Blackburn, Maarten de Rijke, and Yde Venema. Modal Logic. Cambridge University Press,Cambridge, 2001.
Piter Dykstra, Corinna Elsenbroich, Wander Jager, Gerard Renardel de Lavalette, and Rineke Verbrugge. A logic-based architecture for opinion dynamics. In Proceedings of the World Congress of Social Simulation, 2010.
John French. A formal theory of social power. Psychological Review, 63(3):181–194, 1956.
Rainer Hegselmann and Ulrich Krause. Opinion dynamics and bounded confidence models, analysis, and simulation. Journal of Artifical Societies and Social Simulation, 5(3), 2002.
F. Liu. Changing for the Better: Preference Dynamics and Agent Diversity. PhD thesis, ILLC, University of Amsterdam, 2008.
Jeremy Seligman, Fenrong Liu, and Patrick Girard. Logic in the community. In Mohua Banerjee and Anil Seth, editors, ICLA, volume 6521 of Lecture Notes in Computer Science, pages 178–188. Springer, 2011.
