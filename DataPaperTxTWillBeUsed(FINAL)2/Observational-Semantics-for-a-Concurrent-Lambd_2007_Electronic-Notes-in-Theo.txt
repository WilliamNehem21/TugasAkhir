

Electronic Notes in Theoretical Computer Science 173 (2007) 313–337
www.elsevier.com/locate/entcs

Observational Semantics for a Concurrent Lambda Calculus with Reference Cells and Futures
Joachim Niehrena David Sabelb Manfred Schmidt-Schaußb Jan Schwinghammerc
a INRIA Futurs, Lille, France, Mostrare Project
b J. W. Goethe-Universita¨t, Frankfurt, Germany
c Saarland University, Programming Systems Lab, Saarbru¨cken, Germany

Abstract
We present an observational semantics for λ(fut), a concurrent λ-calculus with reference cells and futures. The calculus λ(fut) models the operational semantics of the concurrent higher-order programming language Alice ML. Our result is a powerful notion of equivalence that is the coarsest nontrivial congruence distin- guishing observably different processes. It justifies a maximal set of correct program transformations, and it includes all of λ(fut)’s deterministic reduction rules, in particular, call-by-value β-reduction.
Keywords: Concurrent programming languages, lambda calculus, semantics

Introduction
The λ calculus λ(fut) [12] models the operational semantics of the core of Alice ML [16], a recent concurrent higher-order programming language of the ML family [10,3] inspired by Mozart-Oz [20]. Alice ML provides typed functional programming with mixed concurrent eager and lazy threads which may be distributed transparently over the network. In Alice ML, futures form a (light-weight) concurrency primitive, and implement lazy loading of program components [15].
Formally, λ(fut) is a call-by-value λ-calculus with reference cells and concurrent threads that synchronize on futures. Futures are like logic variables with restricted read and write access. Successful threads evaluate expressions to values and bind them to futures. Threads may be started eagerly or lazily and then operate call-by- value. Some reductions may proceed with futures as arguments while others require proper values (so they have to wait until the required futures get bound to proper values). This way, futures lead to a convenient form of (automatic) data-driven


1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.02.041

synchronization [1]. In contrast to previous purely functional λ-calculi with futures [6], λ(fut)’s reference cells permit to express synchronization constructs, such as channels of the asynchronous π-calculus [9], JoCaml-like joins [4], and streams.
In this paper we present an observational semantics for λ(fut) that is needed for reasoning about concurrent programs and program transformations. The result is a powerful notion of program equivalence that is the coarsest congruence distin- guishing observably different processes. Thus, the congruence justifies a maximal set of correct program transformations, and we prove that in particular it includes call-by-value β-reduction (but not general β-reduction). To the best of our knowl- edge, no previous semantics with these properties exists for concurrent higher-order languages with futures. Alternative approaches using encodings of λ(fut) into other concurrent formalisms – such as (typed) π-calculi – that induce a semantics also for the source language, may work in principle. But then correctness of the encoding itself requires an additional justification, and unfortunately, we do not know how to prove that observational semantics is retained, so we prefer to work directly on the language λ(fut).
Our observational semantics treats processes that cannot avoid a final error situation or a loop as equivalent, and distinguishes them from all others. Based on the operational semantics of λ(fut) we construct the observational semantics as follows. First of all, we replace call-by-value β-reduction by sharing call-by-value β-reduction where substitutions are performed explicitly and lazily, via λ(fut)’s ma- chinery for future dereferencing. This sharing variant is indispensable for proofs, but call-by-value β-reduction is correct, as we show. Second, we define a notion of successful termination for λ(fut) processes. It requires that all started threads are terminated, that there are no needed lazy threads, and that all futures of eager threads have been bound to proper values, possibly through several indirections. Since the calculus is non-deterministic, we introduce notions of may- and must- convergence in a third step, a modelling technique used previously for lambda- calculi with amb [2,11,17]. We call a process may-convergent if it may terminate successfully, and must-convergent, if all its reduction descendants must always re- main may-convergent. This notion of must-convergence is appropriate with respect to fair reduction operational semantics (see also [2,17]), that we assume for a real implementation of an evaluator. Fourth, we call two processes observably equivalent, if they exhibit the same may- and must-convergence in all contexts.
The following results are obtained. The observational equivalence is a con- gruence that includes call-by-value β-reduction and all other deterministic rules of λ(fut). A slightly unexpected result was that the reductions involving so-called han- dles (see Section 2) turn out to be correct transformations, hence they are also “de- terministic”. The only non-deterministic rule is value exchange for reference cells. We distinguish particular instances of cell exchange that preserve observational equivalence. We also show that “garbage collection” and “path compression” are correct transformations, and present a non-trivial example for optimization (Sub- section 4.5). The main tools in proving equivalences, besides the context lemma, are complete sets of forking and commuting diagrams [8,17].

x, y, z ∈ Var
c ∈ Const ::= unit | cell | thread | handle | lazy
e ∈ Exp ::= x | c | λx.e | e1 e2 | exch(e1, e2) v ∈ Val ::= x | c | λx.e
susp
p ∈ Process ::= p1 | p2 | (νx)p | x c v | x⇐e | y h x | y h • | x ⇐= e
Fig. 1. Expressions and processes of λ(fut)

Related work. Notions of program equivalence for deterministic languages with reference cells based on contextual equivalence, as e.g. considered in [13], have to be extended and adapted to take non-determinism and concurrency into ac- count. Contextual equivalence as a combination of may- and must-convergence is also known from the use of convex powerdomains in domain-theoretic models [14]. However, observational semantics provides a powerful and also practically useful se- mantics with a maximum of equations in the presence of lambda abstractions, con- currency and synchronization, dynamically created threads, state through reference cells, and sharing, a combination which is not handled by semantical models built upon powerdomains. Most previous work on semantics for concurrent languages focuses on process calculi [9,19] or investigates the theory obtained by encoding lambda calculi into process calculus (for instance, [18]). In [5,7], program behavior in fragments of Concurrent ML is characterized by bisimilarity with respect to a labelled transition system.
Plan. We recall λ(fut) in Section 2 and adapt it by sharing call-by-value β- reduction. Section 3 introduces the notion of successful termination and defines the may-must observational equivalence. We prove a context lemma which shows that observations in evaluation contexts suffice to characterize program equivalence. In Section 4, we consider correctness of program transformations with respect to observational equivalence.

Lambda(Fut)
We recall an untyped version of λ(fut) from [12] and adapt it by sharing call-by- value β-reduction. This change does not affect the observational semantics, which includes call-by-value β-reduction nevertheless, as we will prove in Section 4.
The syntax of λ(fut) is defined in Fig. 1. It has two layers, standard λ-expressions e ∈ Exp for sequential computation within threads, and processes p ∈ Process composing threads in parallel. New operations in expressions are introduced by (higher-order) constants: unit is a dummy value, and constants thread, lazy and handle serve for introducing eager threads, lazy threads, and handles, each of them together with a future. The constant cell introduces reference cells, and exch(e1, e2) expresses atomic exchange of cell values. Values v are defined as usual in a call-by- value λ-calculus. Note that values subsume variables and thus futures, even though the latter are not proper values. The only variable binder in expressions is λ. The

p1 | p2 ≡ p2 | p1	(p1 | p2) | p3 ≡ p1 | (p2 | p3)
(νx)(νy)p ≡ (νy)(νx)p	(νx)(p1) | p2 ≡ (νx)(p1 | p2)	if x /∈ fv(p2)
Fig. 2. Structural congruence of processes

set of free variables of e is denoted by fv(e). We identify expressions up to consistent renaming of bound variables and write e[e'/x] for the (capture-free) substitution of e' for x in e.
As in the π-calculus, processes p of λ(fut) are composed from components by
parallel composition p1 | p2 and new name creation (νx)p, the latter is a variable binder. The set of free variables of p is denoted by fv(p). The usual structural congruence ≡ on processes is defined by the axioms in Fig. 2. We distinguish five types of components (all different from the π-calculus): (eager concurrent) threads x⇐e will eventually bind future x to the value of expression e unless it diverges
susp
or suspends; x is called a concurrent future. Lazy threads x ⇐= e are suspended
computations that will start once the proper value of x is needed elsewhere; we call x a lazy future. Cells x c v associate (memory location) x to a value v. Handle components y h x associate handles y to futures x, so that y can be used to assign a value to x. We call x a future handled by y, or more shortly a handled future. Finally, a used handle component y h • indicates that y is a handle that has already been used to bind its future.
A process p introduces a variable x if p contains some component of the following form (for some y, e, v):
susp
x⇐e  x is concurrent future (for e)    x ⇐= e  x is lazy future (for e)
x c v  x is cell (with content v)	x h y   x is handle (for future y) y h x  x is handled future (handled by y) x h •   x is used handle
Introduced variables are also called process variables. A process is well-formed iff it does not introduce any variable twice.
The binding operator ν can be seen as defining the observational scope of vari- ables. Using the distinct variable convention and moving ν-binders to the top-level, a process p that introduces variables {x, y} can be written in the form (νx)p, where p does not contain further ν-binders. The variables in {y} are directly observable by an external observer. The others in {x} may still be observable indirectly.
The operational semantics defines an evaluation strategy ev via contexts in that reduction rules apply. A context is a process or an expression with exactly one occurrence of the hole marker, i.e. the special constant [ ]. The hole marker cannot occur at the positions that are reserved for variable introduction, and in a cell x c v, the position of the hole can only be in e for v = λx.e. Let γ be a context, and η be a term or a process that can be plugged into its hole, then we write γ[η] for the result of replacing [ ] in γ by η (possibly capturing free variables of η).
With C we denote any context that is a process. We call C flat if its hole does not occur below a λ-binder, and deep otherwise. A context D denotes a process- context, where the hole marker occurs in process position. In Fig. 3 we define

particular flat contexts of type expression that we call evaluation contexts (ECs) E and future ECs F . ECs encode the standard call-by-value, left-to-right reduction strategy, while future ECs control dereferencing operations on futures and starting suspended threads: dereferencing a future or starting the corresponding suspended thread is only allowed when the future’s value is needed for a thread to proceed.
We define the operational semantics of λ(fut) using a (small-step) reduction de-
noted by →, or −e→v in case we want to distinguish it from the general transformations
introduced in Section 4. It is the least binary relation on processes p → p' satis- fying the rules in Fig. 4. Sharing call-by-value β-reduction (β-cbvL(ev)) replaces binders λy by (νy) and binds y to the function’s argument. Writing let x = e in e' instead of (λx.e')e, sharing β-reduction takes the form well-known from calculi with explicit closures: E[let x = v in e] → (νx)(x⇐v | E[e]). Rule (fut.deref(ev)) replaces needed occurrences of x by v. Basically, this recovers standard call-by-value β-reduction, as proved in Theorem 4.23. For instance:


E[(λx λx
.x ) z z'] β-cbvL(ev)
β-cbvL(ev)	'

1	2	1
−−−−−−−→−−−−−−−→ (νx1)(νx2)(E[x1] | x1⇐z | x2⇐z )

fut.deref(ev)	'
−−−−−−−−−→	E[z] | (νx1)(νx2)(x1⇐z | x2⇐z ) ∼ E[z]
The final garbage collection step will be licensed by our observational equivalence (Theorem 4.8).
Rule (thread.new(ev)) spawns a new eager thread x⇐e, where x may occur in e, so it may be viewed as a recursive let x = e. Similarly, (lazy.new(ev))
susp
creates a new suspended computation x ⇐= e.	Dereferencing of future values
(fut.deref(ev)) and triggering of suspended computations (lazy.trigger(ev)) is controlled by future evaluation contexts F . Rule (handle.new(ev)) introduces han- dle components y h x with static scope in e; the application xv in (handle.bind(ev)) “consumes” the handle x and binds y to v, resulting in a used handle x h • and thread x⇐v. Rule (cell.new(ev)) creates new cells z c v with contents v. The exchange operation exch(z, v1) writes v1 to the cell and returns the previous contents. Since this is an atomic operation, no other thread can interfere. Note also that reduction preserves well-formedness and non-well-formedness.
Depending on the context, we will write ⊥ for both an arbitrary non-converging expression (such as thread λx.x) or process (such as x⇐x x) in the following.
Example 2.1 We deﬁne a binary choice operator that non-deterministically selects one of its two arguments. First we deﬁne demonic-choice as an eager function, so that both alternatives will be evaluated before actually choosing. As usual let K1 = λxλy.x and K2 = λxλy.y.

demonic-choice =def λu1.λu2. let z = cell K1 in
let y = thread (λ .exch(z, K2)) in (exch(z, K2)) u1 u2
For arbitrary values v1, v2 one can verify for i = 1, 2 that D[E[demonic-choice v1 v2]]
may reduce to D[E[vi]] modulo garbage collection, so the respective other branch



ECs	E	::=	x⇐ ˜
˜
E ::= [ ]
˜	v E |
exch(E, e) |
˜
exch(v, E)

Future ECs	F	::=	x⇐ ˜
˜	˜	| ˜

Process ECs	D	::=	[ ] | p | D | D | p | (νx)D
Fig. 3. Evaluation contexts

Reduction rules.
(β-cbvL(ev))	E[(λy.e) v] −→ (νy)(E[e] | y⇐v)
(thread.new(ev))	E[thread v] −→ (νz)(E[z] | z⇐v z) (fut.deref(ev))	F [x] | x⇐v −→ F [v] | x⇐v (handle.new(ev))	E[handle v] −→ (νz)(νz')(E[vz z'] | z' h z) (handle.bind(ev))	E[x v] | x h y −→ E[unit] | y⇐v | x h • (cell.new(ev))	E[cell v] −→ (νz)(E[z] | z c v) (cell.exch(ev))	E[exch(z, v1)] | z c v2 −→ E[v2] | z c v1 (lazy.new(ev))	E[lazy v] → (νz)(E[z] | z susp

(lazy.trigger(ev))	F [x] | x susp
→ F [x] | x⇐e

Non-well-formed processes. We assume that the rules cannot be applied to non- well-formed processes.
Distinct variable convention. We assume that all processes to which rules ap- ply satisfy the distinct variable convention, and that all new binders use fresh
variables (z and z'). Reduction results will then satisfy the distinct variable convention as well, except for the rule fut.deref(ev) where values with bound variables can get copied. In this case, α-renaming has to be performed before
applying the next rule.
Closure. Rule application is closed under structural congruence and process ECs
D. If p1 ≡ D[p' ], p' → p' , and D[p' ] ≡ p2 then p1 → p2.
1	1	2	2
Fig. 4. One-step reduction relation of λ(fut) denoted by → or −e→v

cannot become active. For all e1, e2, we deﬁne a lazy choice expression choice[e1, e2]
that ﬁrst chooses between e1 and e2 and then evaluates only the chosen expression:

choice[e1, e2] =def demonic-choice (lazy λ .e1) (lazy λ .e2)

One can then verify for all i = 1, 2 that D[E[choice [e1, e2]] may reduce to (νui)(ui⇐ei | D[E[ui]]) modulo garbage collection so the respective other branch can- not become active. As a consequence, the expression choice [unit, ⊥] may terminate by choosing the ﬁrst branch, or diverge by choosing the second one.

Observational Semantics
As usual, we want to consider two processes equivalent whenever it is impossible for an observer to distinguish them. We model the observer by contexts which test whether or not a process in that context terminates successfully. This raises two questions: firstly, which kinds of failure situations can arise in a concurrent calculus with futures, and secondly, how to treat computations that may diverge.

May-Must Program Equivalence
With regard to execution failure, we note that besides the possibilities of type mismatches (and the resulting stuck expressions) and deadlocks (arising from com- putations in concurrent threads blocking each other), one can also introduce a direct cyclic dependency between concurrent futures. In call-by-need lambda calculi this phenomenon is known as a black hole. We require that in a non-failing computation, every future eventually refers to a “proper” value.
Formally, we call a process p successful (meaning it has terminated success- fully), if and only if it is well-formed and for every component x⇐e of p, the future x is bound (possibly via a chain x⇐x1 | x1⇐x2 | ... | xn−1⇐xn) to a non-variable value, a cell, a lazy future, a handle, or a handled future. For example, x⇐λy.y and
x⇐y | y c z are successful, while x⇐x (a black hole) and x⇐yx | y⇐xy (a dead- locked process) are not successful.
Next, we address the question concerning the notion of observable termination that we adopt. Given a binary relation t, we write t+, t∗, tє for the transitive, reflexive-transitive and reflexive closure of t, respectively.
Definition 3.1 Let p be a process. We say that p is may-convergent (p↓) if there exists a sequence of reductions p →∗ p' such that p' is successful. It is must- convergent (p⇓) if all reduction descendants p' of p are may-convergent. We say that p is must-divergent (p⇑) if it has no reduction descendant that succeeds. It is may-divergent (p↑) if some reduction descendant of p is must-divergent.
Note that all processes p satisfy p⇑ ⇔ ¬p↓ and p↑⇔ ¬p⇓, and that non-well-formed processes are must-divergent.
Lemma 3.2 If p contains a future cycle x1⇐x2 | x2⇐x3 | ... | xn⇐x1 then p ⇑. In particular, if p↓ then p does not contain such a cycle.
We write ↓ for the set of may-convergent processes, and ⇓ for the set of must- convergent processes. Let P = ↓ or P = ⇓. We define binary relations ≤P both for processes and expressions, such that for all p, p' ∈ Process and e, e' ∈ Exp:
p ≤P p'	 iff	 ∀D. D[p] ∈ P ⇒ D[p'] ∈ P e ≤P e'	iff	∀C. C[e] ∈ P ⇒ C[e'] ∈ P
In particular, e ≤P e' iff C[e] ≤P C[e'] for all C. The contextual preorder ≤ is the intersection of may- and must-contextual approximation ≤↓ and ≤⇓. Contextual equivalence ∼ is the equivalence relation ≤ ∩ ≥ induced by the contextual preorder

≤. It is easy to see that contextual equivalence ∼ on processes and expressions is a congruence, i.e., ∼ is an equivalence relation such that e ∼ e' implies C[e] ∼ C[e'] for all contexts C; the same for processes. It is easy to verify that ⊥ /∼ p ∼ p' implies that the introduced but not ν-bound variables are the same for p and p', the same for expressions. In this case C[p] is well-formed iff C[p'] is well-formed.
Fairness
The reduction strategy of Alice ML is fair in that every possible redex will be re- duced eventually. Assuming sufficiently non-deterministic thread scheduling, this guarantees non-determinism of the choice-encoding. Fairness for λ(fut) can be im- posed as a refinement of its reduction strategy, and translates into a property of reduction sequences.
Rules of λ(fut) select one or two of the parallel components, of which at most one is rewritten while the other remains, perhaps modified, if the rules handle.bind(ev) or cell.exch(ev) have been applied, since then the handle or the cell component are modified. A redex is a subexpression that can be rewritten by applying some reduction step, or a suspended thread that can be activated (by lazy.trigger).
Either a process is must-divergent, or every reduction step of λ(fut) removes one redex while preserving all others. It is not difficult to formalize this statement, but this would not yield new insights.
Definition 3.3 A reduction sequence R starting from p is fair iff every redex is eventually reduced after a ﬁnite number of reduction steps in R. For a process p we deﬁne p↓fair iff there is a fair reduction from p to a successful process, and p⇓fair iff for every reduction p −→∗ p', we have p'↓fair .
Example 3.4 Let K1! = λx.λy.(x unit) and K2 = λxλy.y.  Let p the pro- cess x1⇐yy | z c K1! | x2⇐exch(z, K2) | y⇐λx.exch(z, K1!) (λ .(x x)) unit which is must-convergent. There is a reduction to a successful process that ﬁrst applies cell.exch( ev) (so that the z-cell contains K2), and subsequently reduces the x1- thread to unit. In contrast, the unfair reduction never puts K2 into the z-cell but always exchanges K1! with K1!.
Proposition 3.5 Let p be a process. Then p↓⇔ p↓fair and p⇓⇔ p⇓fair .
Proof. The definition of fairness excludes certain infinite reductions and the notion of may- and must-convergence is founded on finite reductions. Thus, they are not affected by imposing fairness.	 
Theorem 3.6 We have ≤↓fair = ≤↓ and ≤⇓fair = ≤⇓, hence also ∼ is unchanged if the deﬁnition is restricted to fair reductions.

Discussion
Neither may- nor must-convergence alone yields a satisfactory notion of observa- tional equivalence, as the former cannot distinguish v from choice[v, ⊥] while the latter equates choice[v, ⊥] and ⊥, where v is any value. Moreover, we believe that

our must-convergence is conceptually more adequate than considering a total must- convergence, which enforces all reductions to successfully terminate.
We adapt the example of [2]: Let J be thread (λf.λx.choice[(f x),I]) I and let I denote λx.x. Since thread can be used for fixpointing, the process u⇐J reduces to u⇐zI | z⇐((λf.λx.choice[(f x),I]) z).  Our semantics yields
u⇐I ∼ u⇐J /∼ u⇐choice[⊥,I]
where the process u⇐J is must-convergent, has an infinite reduction that is fair, and all successful results are equivalent to u⇐I. This means it is correct to intro- duce (or remove, respectively) weak divergences, but it is not correct to introduce (or remove, respectively) strong divergences (reduction possibilities to errors or must-divergent processes). However, if our must-convergence is replaced by total must-convergence, then this is reversed, and u⇐I would be non-equivalent to u⇐J , which in turn would be equivalent to u⇐choice[⊥,I].
There are also examples (see Example 3.4) of must-convergent processes with infinite reductions, where the infinite reduction are excluded if fairness is assumed. We give a further argument for our definition of must-convergence. Suppose a process p can reduce to infinitely many different values vi,i ∈ N, but cannot reduce to an error, i.e. to a must-divergent process. Then, because of the finitely branching non-determinism of λ(fut), p necessarily also permits an infinite reduction. Using
our semantics, p is must-convergent. For any p' with p' ∼ p the process p' has the possibilities to reduce to the same values as p, but not to an error. In contrast, replacing our must-convergence by total must-convergence in the definition of ∼, there may be p' ∼ p such that p' may reduce to an error, which is clearly undesirable.
Evaluation Contexts are Enough
The fundamental context lemma for expressions states that ECs provide already enough observations to distinguish observationally nonequivalent expressions and processes. Establishing equivalences is made considerably more tractable by the context lemma. It also supports proving equivalence of expressions as e.g. in Theorems 4.23 and 4.24 and in Subsection 4.5. We define contextual approxi- mations in evaluation contexts for the set of processes P =  ↓ and P =  ⇓ as e ≤ev e' iff ∀E∀D : D[E[e]] ∈ P ⇒ D[E[e']] ∈ P.
Proposition 3.7 (Context Lemma) For all e1, e2 ∈ Exp:
e1 ≤ev e2 and e1 ≤ev e2	⇒	e1 ≤ e2
↓	⇓
The proof can be found in Appendix A.
Program Transformations
We present a set of transformation rules that allow for partial evaluation, and show which of these reduction rules are correct. In particular we show that call-by-value beta reduction can be performed in arbitrary contexts.
Candidates of transformation rules are collected in Fig. 5. They are parametrized

Lifting reduction to transformation rules.
(β-cbvL(strat))	C[(λy.e) v] −→ (νy)(C[e] | y⇐v) (thread.new(strat))	C[thread v] −→ (νz)(C[z] | z⇐v z) (fut.deref(strat))	C[x] | x⇐v −→ C[v] | x⇐v (handle.new(strat))	C[handle v] −→ (νz)(νz')(C[vz z'] | z' h z) (handle.bind(strat))	C[x v] | y h x −→ C[unit] | y⇐v | x h • (cell.new(strat))	C[cell v] −→ (νz)(C[z] | z c v) (cell.exch(strat))	C[exch(y, v1)] | y c v2 −→ C[v2] | y c v1
(lazy.new(strat))	C[lazy v] → (νz)(C[z] | z susp

(lazy.trigger(strat))	C[x] | x susp
→ C[x] | x⇐e

Call-by-value beta reduction and other deterministic transformations.
(β-cbv(strat))	C[(λx.e) v] −→ C[e[v/x]] (cell.deref)	p | y c x | x⇐v −→ p | y c v | x⇐v
(gc)	p | (νy1) ... (νyn)p'  −→  p	if p' is successful and
y1,... , yn contain all process variables of p'
(det.exch)	(νx)(y⇐E˜[exch(x, v1)] | x c v2) −→ (νx)(y⇐E˜[v2] | x c v1)
No capturing. The same conditions as in Fig. 4 are assumed. In addition we assume that no variables are moved out of their scope or into the scope of some other binder, i.e., fv(v) ∩ bv(C) = ∅, and that α-renaming is also done after cell.deref.
Closure and Strategy. Transformations are always closed under structural con- gruence and D contexts. For all above rules r(strat) the class of contexts C is
r(strat)
restricted by the strategy strat. We write p1 −−−−→ p2 if p1 → p2 by this rule.
Fig. 5. Transformation rules for some strategy strat permitting contexts C


by strategies strat which fix the contexts in which the rule can be applied. We assume all transformations to be closed under structural congruence and process ECs. The strategy ev is the reduction strategy of λ(fut). It permits ECs E for all rules but fut.deref and lazy.trigger where it requires future ECs F . The strategy f permits all flat contexts, while d insists on deep contexts. Other strategies can be defined by Boolean combinations, for instance ¬ev∧f. In particular, the strategy with arbitrary contexts is a = f ∨ d.
The first set of transformation rules in Fig. 5 is obtained by lifting reduction rules of λ(fut) from ECs to contexts permitted by the strategy. The second set contains call-by-value β-reduction in contexts permitted by the strategy, garbage collection, and deterministic cell exchange. The dereferencing of values into cells (cell.deref) is included mainly for technical reasons.
Definition 4.1 A transformation t is correct iff (p, p') ∈ t implies that p ∼ p'.

First we state which transformations are not correct. In Appendix B we provide counter-examples for the transformations mentioned in the proposition below.

Proposition 4.2  The	transformations
cell.exch(ev),	lazy.trigger(f),

handle.new(¬ev),
handle.bind(¬ev),
cell.new(¬ev),
thread.new(¬ev),

lazy.new(¬ev), and the rule β-cbn with C[(λx.e) e'] −→ C[e[e'/x]] are not correct.
A helpful tool for proving correctness of transformations is the following lemma, which shows that it is not necessary to consider enclosing D-contexts if the trans- formation is alreay closed under all contexts D.
Lemma 4.3 A transformation t that is closed under all contexts D is correct iff it satisﬁes p↓⇔ p'↓ and p↑⇔ p'↑ for all pairs (p, p') ∈ t.
In the remaining subsections we will prove the correctness of various program transformations. In Subsection 4.1 we prove a lemma which implies the correctness of all deterministic reductions. In Subsection 4.2 we provide a sufficient criterion for correctness of a program transformation (Lemma 4.7). We will show that gc and det.exch obviously satisfy this criterion and hence are correct. In Subsection 4.3 we extend our proof technique with the notions of complete sets of forking and commuting diagrams which will enable us to proof the correctness of β-cbvL(f), fut.deref(f) and cell.deref. Unfortunately, the transformations β-cbvL(d) and fut.deref(d) do not meet the conditions of Lemma 4.7. Hence, in Subsection 4.4 we give a fully worked out proof of correctness using a refined induction proof method. After presenting some consequences of the correctness of β-cbvL(a) we finish this section with an exemplary application (unnecessary cell allocation) of our results. In all of our proofs we use two sets of reduction sequences:
Definition 4.4 Let p be a process. With Suc(p) (Div(p), respectively) we denote all sequences of reductions for p that end in a successful process (must-divergent process, respectively).

Correctness of Deterministic Reductions
We show that all deterministic reduction steps of λ(fut) are correct transformations. This excludes the rule cell.exch(ev), the only source of non-determinism in λ(fut). The proof relies on the diagrams used in [12] to show the uniform confluence of the fragment of λ(fut) without cell exchange and handle-errors.

Let ev be the reduction −e→v  of λ(fut) and p −e−v¬−→er  p' iff p −e→v p'
and p is may-convergent.
Lemma 4.5 A transformation t on processes that is closed under D-contexts and subsumed by reduction t ⊆ ev is correct if it satisﬁes the forking condition ev−1 ◦ t ⊆ tє ◦ (ev∗)−1.




ev¬er

·   t	 · 
 ∃ev∗
J 	 J 
∃tc

Proof. Since t is closed under D-contexts it suffices to show for all (p, p') ∈ t that p and p' have identical may- and must-convergence behaviour. That p'↓⇒ p↓ and p'↑⇒ p↑ is obvious since t ⊆ ev. We prove the remaining cases:
p↓⇒ p'↓: Since p↓, there exists R ∈ Suc(p). The proof is by induction on the

length of R, which cannot be 0 since t ⊆ ev. For the inductive step, we use the forking condition on the first reduction of R. If the diagram is closed by an ev∗
step then p'↓, otherwise the induction hypothesis applies.
p↑⇒ p'↑: By induction on the length of a minimal reduction sequence R ∈ Div(p). If the length is 0, then p is must-divergent and so p'⇑, since we have already established p' ↓⇒ p ↓. Otherwise, p is may-convergent, so that we can apply the forking diagram. The rest follows from the induction hypothesis.	 
Note that t preserves must-divergence since reduction ev does. If t raises a handle error, i.e. generates components of the form E[z v1] | z h •, then the result is a must-divergent process.
Proposition 4.6 All reduction steps of λ(fut) are correct program transformations except for cell.exch( ev).
Proof. The diagrams required by Lemma 4.5 can be shown as in [12], with a slight modification: Instead of call-by-value beta reduction one needs to consider β-cbvL(ev) and additionally the overlappings with rule cell.new(ev). Both modi- fications are easy to handle. The only rule for which some care is needed is the rule handle.bind(ev). This rule can introduce non-determinism, but only when raising handle errors which results in a must-divergent process: a typical counter example is E1[z v1] | E2[z v2] | z h y which has two reducts E1[unit] | y⇐v1 | E2[z v2] | z h • and E1[z v1] | y⇐v2 | E2[unit] | z h • that cannot be joined, but both constitute so-called handle-errors, which cannnot be reduced to successful processes. The rule commutes with itself in case no handle error is raised.	 

A Sufficient Criterion for Correctness
The following lemma provides three conditions of a transformation which ensure correctness of the transformation. We will use the lemma in this and the subsequent subsection to show that gc, det.exch, β-cbvL(f), fut.deref(f) and cell.deref are correct program transformations.

Lemma 4.7 A transformation t on processes is correct if it satisﬁes the following three conditions:

·   t	 · 
ev	 ∃evc
·  t	 · 
∃ev∗	ev

·J 	 J 
 J   ·J 

∃t∗ ·
· _ _ _ 
∃t

(fork) ev−1 ◦ t ⊆ t∗ ◦ (evє)−1	(commute) t ◦ ev ⊆ ev∗ ◦ tє
(success) for all (p, p') ∈ t: p is successful iff p' is successful and (p, p') /∈ ev.
Proof. Since t is closed under D-contexts, it is sufficient to show for all p, p' with (p, p') ∈ t that p and p' have identical may- and must-convergence behaviour.
p↓⇒ p'↓: By induction on the length of R ∈ Suc(p), we show that there exists
R' ∈ Suc(p') of smaller or equal length. In the base case of length 0, p is successful

and thus p' by condition (success). Otherwise consider the first reduction step.
There exists p1 such that p −e→v p1 and p1 has a smaller successful reduction sequence.
c	∗
Thus, we can apply condition (fork) for some p' with p' ev	' and p  −t→ p' . We
1

conclude the proof by induction on the length of p1
−t→ p' .  If this length is 0

then p1 ≡ p' so p' has a successful reduction sequence of length smaller or equal
to that of p. If the length is n, we apply the first induction hypothesis to the
first transformation step, and use the other induction hypothesis for the remaining sequence of n − 1 transformation steps.

p'↓⇒ p↓: By induction on the length of R ∈ Suc(p'). The case p −e→v
p' is obvious,

so we can assume (p, p') ∈/ ev. In the base case, this length is 0 so p' is successful. Assumption (success) implies that p is successful too. For larger lengths, we can apply the (commute) condition, and then the induction hypothesis.
p↑⇒ p'↑: By induction on the length of R ∈ Div(p) we show that there exists R' ∈ Div(p') of smaller or equal length. In the base case, p⇑, hence p'⇑ as shown in case p'↓⇒ p↓. The induction step uses the (fork) diagram.
p'↑⇒ p↑: By induction on the length of R ∈ Div(p'). In the base case, p' must- diverges and so does p as we showed in case p↓⇒ p'↓. The induction step relies on the (commute) diagram.	 
Now it is easy to show that garbage collection (gc) and deterministic cell ex- change (det.exch) are correct, since the overlappings of these transformations with reductions are trivial.

Theorem 4.8
gc and det.exch are correct program transformations.



Proof. This follows by Lemma 4.7, since gc
has no influence on reduction se-

quences, i.e. ev−1 ◦ gc ⊆ gc ◦ ev−1 and gc ◦ ev ⊆ ev ◦ gc and since the conditions ensure that there is no interference with the success of processes. In the same way the correctness of det.exch follows.	 

Correctness of β-cbvL( f), fut.deref( f) and cell.deref
For further proofs we require the notion of sets of forking and commuting diagrams, which is a formalism to represent the overlappings between a transformation rule and reductions. Informally, the completeness condition ensures that every non- trivial overlapping is covered by the set of diagrams.
Definition 4.9 Forking and commuting diagrams for a transformation t are meta- rewriting rules for some r ⊆ ev, t' ⊆ t and f being relations on processes.
·  t'  ·	·  t'  ·


r J cf
c ,	, ,
f  ,

· c 
forking diagram
z·Jz 
commuting diagram

A set of forking diagrams {←r−1
· −t→1
f
−→,... , ←−
· −t→n
f
−→}
is complete iff for

every reduction sequence p
←e−v p −→t  p there exists a forking diagram ri
ti ~ fi

1	2	3
←− · −→	−→

with (p1, p2) ∈ r−1, (p2, p3) ∈ ti and (p1, p3) ∈ fi.

A set of commuting diagrams {−t→1
· −r→1
f
−→,... , −→
· −r→n
f
−→}
is complete

iff for every reduction sequence p −→t
p2 −e→v
p3 there exists a commuting diagram

ti	ri	fi
−→ · −→ ~ −→ with (p1, p2) ∈ ti, (p2, p3) ∈ ri and (p1, p3) ∈ fi.
In the remaining part of this subsection we compute complete sets of com- muting and forking diagrams for the transformations β-cbvL(f), cell.deref and fut.deref(f) and show that the diagrams meet the conditions (fork) and (com- mute) of Lemma 4.7. The third condition (success) is proved by an additional lemma for each transformation.
First we treat the transformation β-cbvL(f), i.e. call-by-value β-reduction not inside the body of an abstraction. Correctness of arbitrary call-by-value β-reduction (particularly inside deep contexts) will be proved in subsection 4.4. The following lemma shows that condition (success) of Lemma 4.7 holds for β-cbvL(f).
β-cbvL(¬ev∧a)
Lemma 4.10 Let p1, p2 be two conﬁgurations with p1 −−−−−−−−−→ p2. Then p1 is
successful iff p2 is successful.
A case analysis of the overlappings between reductions and the transformation
β-cbvL(f) shows the following lemma:
Lemma 4.11 A complete set of forking diagrams for β-cbvL(f) and a complete set of commuting diagrams for β-cbvL(¬ev∧f) are:

· β-cbvL(f) ·
β-cbvL(¬ev∧f )·
β-cbvL(¬ev∧f) ·

 
r J	 r
·	· 
r	r	r 

_ _ _ _
_ J 
J_ _ _ _
_ J	J 

· β-cbvL(f) ·
for every reduction r
β·  -cbvL(¬ev∧f)·
for every reduction r
· ¸ ¸ ¸	r
β-cbvL(e¸v) ¸ ¸zJ˛  

for r ∈
{β-cbvL(ev), lazy.trigger(ev)}
Proposition 4.12 β-cbvL(f) is a correct transformation.
Proof. From Lemma 4.7 which is applicable by Lemmas 4.10 and 4.11 and from the fact that β-cbvL(ev) ◦ ev ⊆ ev∗.	 
The proof of correctness of the transformation fut.deref(f), i.e. copying of val- ues into flat contexts requires the transformation cell.deref, since it may happen that an overlapping of a fut.deref(f)-transformation with a reduction can only be closed using copying of values into a cell. Hence, we will prove the union of both transformations being correct.
Just as before we first prove the condition (success) required by Lemma 4.7.

fut.deref(¬ev∧a)
cell.deref

Lemma 4.13 Let p1, p2 be processes with p1 −−−−−−−−−−−→ p2 or p1 −−−−−−−→
p2, then p1 is successful iff p2 is successful.
The next two lemmas shows the forking and commuting diagrams for both trans- formations. Completeness follows by a case analysis of the overlappings between a

transformation and a reduction. In Appendix C exemplary cases are shown.
Lemma 4.14 The forking and commuting diagrams for cell.deref can be read off the following diagrams:

· cell.deref ·
r	r


cell.exch(ev)
·cell.deref ·
 
cell.exch(ev)

J	 J 
cell.deref
for every reduction r
Lemma 4.15 A complete set of forking diagrams for
·J	 ·J 
fut.deref(f)
fut.deref(f) and a com-

plete set of commuting diagrams for fut.deref(¬ev∧f) is given by the following diagrams:
·	fut.deref(f)	 ·	fut.deref( f·) 


fut.deref(ev)
J 
 
 fut.deref(ev)
·	 
r	 r

· _ _ _ _ _ _ · _ _ _ _ _ _ ·J 
·J_ _
_ _ ·J 

fut.deref(f)
fut.deref(f)
fut.deref(f)

fut.deref(f) copies a variable
fut.deref( f) 
for every reduction r
fut.deref(f∧ ¬ev )

·
cell.exch(ev)
J 
· 
 cell.exch(ev)
· 
cell.exch(ev) 
·
cell.exch(ev)

· _ _ _ _ ·J 
·J_ _ _ _ ·J 

cell.deref
fut.deref(¬e v∧ f)

fut.deref(¬e v∧ f)
cell.deref
fut.deref(¬e v∧ f)

·	·
fut.deref(ev) J 
·	·
r J 
·	·
r J	r 

·	fut.deref(ev)
· ¸	r
· _ _ _ _ ·J 

fut.deref(ev)
 J 	J 
¸
fut.deref(ev) zJ 
fut.deref(¬ev∧f)
for every reduction r

· _ _ _ _ ·	·

fut.deref(¬ev∧f)
where fut.deref(¬ev∧f) copies a
variable
r ∈ {thread.new(ev),handle.new(ev),
lazy.trigger(ev)}

From Lemma 4.7 which is applicable by combining the diagrams of Lemmas 4.14,
4.13 and 4.15 and the fact that fut.deref(ev) ◦ ev ⊆ ev∗ the following proposition holds:

Proposition 4.16
fut.deref(f) and cell.deref are correct transformations.


Correctness of fut.deref(a) and β-cbv(a)

We strengthen this result for
fut.deref(f) in order to prove the correctness of

fut.deref(d) wrt. suitable measures on terms and sequences of reductions.
Definition 4.17 Let p be a process with p ≡ x1⇐x2 | x2⇐x3 | ... xn⇐e | p' where e is not a variable and the chain of variables is maximal. Then the measure cl : Var → N0 is deﬁned as cl(x1) := n. If the chain contains a chain of cyclic thread components xi⇐xi+1 | ... | xj⇐xi then cl(x1) is undeﬁned. The measure #varf : Process → N0 is deﬁned as follows: Let p be a process, then #varf(p) is the sum of
cl(x) of all occurrences of variables x in p, where the occurrence of x is inside a flat context.

Let R = p0
−e→v
p1 ... −e→v
pn be a sequence of reductions. Then rl(R) is the

number of reductions of R, i.e. rl(R)= n, and rl¬fut.deref(ev)(R) is the number of reductions r of R with r /⊆ fut.deref(ev).

Lemma 4.18 Let p, p' be two processes with p fut.deref(f)
p'.

If there exists R ∈ Suc(p) (R ∈ Div(p), resp.) then there exists R' ∈ Suc(p')
(R' ∈ Div(p), resp.) with rl(R') ≤ rl(R).
If there exists R' ∈ Suc(p') (R' ∈ Div(p'), resp.) then there exists R ∈ Suc(p)
(R ∈ Div(p), resp.) with rl¬fut.deref(ev)(R) ≤ rl¬fut.deref(ev)(R').
Proof.  Follows	by	inspecting	the	forking	and	commuting	diagrams	for
fut.deref(f) that are used for the construction of the reduction sequences. 
Lemma 4.19 If p is a process without cyclic chains of threads, then every
fut.deref(d) transformation preserves the measure #varf .
A case analysis of the overlappings between the transformation fut.deref(d) and reductions shows the following lemma. Examples for the cases covered by the diagrams can be found in Appendix C.
Lemma 4.20 Complete sets of forking and commuting diagrams for fut.deref(d)
can be read off the following diagrams for all reductions r:
fut.deref(d)	fut.deref(d) 

·	·	·
r	r	β-cbvL(ev)
·
β-cbvL(ev)

J	 J 
fut.deref(d)
for every reduction r



· 	fut.deref(d)	 ·
J	 J 
fut.deref(f)

fut.deref(ev)
fut.deref(ev)
·J	 · 	 ·J 

fut.deref(d) fut.deref(d)
Note that the last diagram read as commuting diagram breaks the condi- tion (commute) of Lemma 4.7. Hence, the lemma is not applicable. We prove the correctness by induction on a combination of the measures #varf, rl(·) and rl¬fut.deref(ev)(·) from Definition 4.17.
Proposition 4.21 The transformation fut.deref(d) is correct.
fut.deref(d)
Proof. Let p1 −−−−−−−−→ p2. We split the proof into four parts:
p1↓⇒ p2↓: Let R ∈ Suc(p1). We show by induction on l = rl(R) that there also exists R' ∈ Suc(p2) with length ≤ l.
Lemma 4.13 implies that the base case holds. Now let l > 0. Then we can
apply one of the forking diagrams of Lemma 4.20 to a suffix of the sequence ←R−
fut.deref(d)
p1 −−−−−−−−→ p2 and then use the induction hypothesis. For the second diagram of
Lemma 4.20 we apply Lemma 4.18, and for the last diagram we apply the induction hypothesis twice.
p2 ↓⇒ p1 ↓: We use the (lexicographically ordered) measure (μ1, μ2) on re-

duction sequences of the form p1
fut.deref(a)
−−−−−−−−→  p2
−→R
with R ∈ Suc(p2), μ1 =

rl¬fut.deref(ev)(R), and μ2 = #varf(p2). Note that μ2 is defined, since by Lemma 3.2 the corresponding process does not contain a cyclic chain of threads.
Let R ∈ Suc(p2). We show by induction on (μ1, μ2) that there exists R' ∈
Suc(p1) with rl¬fut.deref(ev)(R') ≤ rl¬fut.deref(ev)(R).
For the base case let (μ1, μ2) = (0, 0). Then Lemma 4.19 implies that R must be empty.	Hence, p2 is a successful process and Lemma 4.13 shows the claim.
For the induction step let (μ1, μ2) > (0, 0). We apply a commuting diagram from

Lemma 4.20 to the sequence p
fut.deref(d)
1 −−−−−−−−→ p2
−→R .

If the first diagram is applicable, and the first reduction of R is a fut.deref(ev) then μ1 is unchanged, but μ2 is strictly decreased. Otherwise μ1 is strictly de- creased. Hence we can apply the induction hypothesis.
In case of the second diagram, μ1 is strictly decreased and Lemma 4.18 shows the existence of R' with rl¬fut.deref(ev)(R') ≤ rl¬fut.deref(ev)(R).
In case of the last diagram we can apply the induction hypothesis twice, since fut.deref(ev) decreases the measure μ2 and leaves μ1 unchanged and a fut.deref(d) transformation does not change μ2 (see Lemma 4.19).
In any case, the constructed reduction sequence satisfies rl¬fut.deref(ev)(R') ≤
rl¬fut.deref(ev)(R).
p1↑⇒ p2↑: This follows by induction on the length of a sequence R ∈ Div(p1)
and by using the forking diagrams. The base case follows from the previous case,
p2↓⇒ p1↓. The induction step is analogous to the first case of the proof.
p2 ↑⇒ p1 ↑: This follows by induction on the measure (μ1, μ2) where μ1 = rl¬fut.deref(ev)(R) with R ∈ Div(p2) being a shortest sequence of reductions and μ2 = #varf(p2). Note that μ2 may be undefined, but only for the last contractum of R, since R is a shortest sequence. Moreover, it is necessary to observe that
fut.deref(d) does not introduce cyclic chains of threads. The base case, i.e. p2⇑ follows from the first case of the proof, p1↓⇒ p2↓. The induction step is analogous to the second case, using the commuting diagrams.	 


Since fut.deref(d) and fut.deref(f) are correct program transformations, a summarizing theorem is:

Theorem 4.22
fut.deref(a) is a correct program transformation.

Now we lift the result of correctness of call-by-value β-reduction inside flat contexts to arbitrary contexts, using the context lemma and the correctness of fut.deref(a).
Theorem 4.23 β-cbv(a) is a correct program transformation.

Proof. By the context lemma it suffices to show that β-cbv(f) is correct. In all
β-cbv(f)
flat contexts C, the transformation C[(λx.e) v] −−−−−→ C[e[v/x]] can be replaced

by the sequence of transformations


C[(λx.e) v]
β-cbvL(f)
−−−−−−→	(νx) C[e] | x⇐v
fut.deref(a) ∗	gc

−−−−−−−−→  (νx) C[e[v/x]] | x⇐v −→ C[e[v/x]]
Since we have shown that β-cbvL(f), fut.deref(a) and gc are correct in Theo- rem 4.8 and Proposition 4.12, respectively, the result follows.	 
Another consequence of the correctness of fut.deref(a) and gc is:

Theorem 4.24 Path compression, (νy)(x⇐y | y⇐v) −→ x⇐v where y ∈/
correct.
fv(v), is

The theorems also imply that the following equivalence holds, which is not covered by the congruence property, since x c [] is not a context: v1 ∼ v2 =⇒ p | x c v1 ∼ p | x c v2, which follows from the equivalence p | ((νy)(x c y | y⇐v)) ∼ p | x c v.

An Example: Avoiding Unnecessary Cell Allocation
As an example application of our results we show that the function λx.λy.(let z = (cell x) in y (exch(z, unit)) can be optimized to λx.λy.(y x), by removing unnecessary cell allocations that are justified as correct transformation.
For all values v and expressions e we show let z = (cell v) in e (exch(z, unit)) ∼c (e v): Note that the let-expression on the left hand side is defined as being equiv- alent to (λz.e (exch(z, unit))) (cell v). Now let D be an arbitrary process evalua- tion context and E be an arbitrary evaluation context. We transform the process D[E[(λz.e (exch(z, unit))) (cell v)]] as follows:
cell.new(ev)
−−−−−−−−→ D[νx(E[(λz.e (exch(z, unit))) x] | x c v)]
β-cbv(a)
−−−−−→	D[νx(E[(e (exch(x, unit)))] | x c v)]
det.exch	gc
−−−−−−→	D[νx(E[(e v))] | x c unit)] −→ D[E[(e v)]]
Since  we  only  used  correct  program  transformation  we  have D[E[let z  = (cell v) in e (exch(z, unit))] ∼c  D[E[(e v)]].  An imme- diate consequence is let z  = (cell v) in e (exch(z, unit))  η  (e v) for
η  ∈  {≤ev, ≤ev, (≤ev)−1, (≤ev)−1}.  Finally we apply the context lemma and
↓	⇓	↓	⇓
have let z = (cell v) in e (exch(z, unit)) ∼c (e v). This finally proves that the
optimization is correct, since ∼c can be lifted to arbitrary contexts.
Conclusions and Outlook
We have presented an observational equivalence for λ(fut) programs, which allows us to reason about the correctness of transformations of stateful and concurrent computations, as found in the Alice ML core language [16,12]. Specifically, we have

proved correctness of partial evaluation with respect to this semantics. In future work, we plan to investigate static analyses for λ(fut), e.g. an adaptation of the calculus where touch optimization can be investigated [6]. Applying the correctness criterion of must- and may-convergence to optimizations of the reduction strategy also deserves attention.

References
Baker, H. and C. Hewitt, The incremental garbage collection of processes, ACM Sigplan Notices 12
(1977), pp. 55–59.
Carayol, A., D. Hirschkoff and D. Sangiorgi, On the representation of McCarthy’s amb in the pi- calculus., Theoret. Comput. Sci. 330 (2005), pp. 439–473.
Chailloux, E., P. Manoury and B. Pagano, “Developing Applications With Objective Caml,” O’Reilly, 2000, available online at http://caml.inria.fr/oreilly-book .
Conchon, S. and F. L. Fessant, Jocaml: Mobile agents for Objective-Caml, in: First International Symposium on Agent Systems and Applications (ASA’99)/Third International Symposium on Mobile Agents (MA’99), 1999.
Ferreira, W., M. Hennessy and A. Jeffrey, A theory of weak bisimulation for Core CML, J. Funct. Programming 8 (1998), pp. 447–491.
Flanagan, C. and M. Felleisen, The semantics of future and an application, J. Funct. Programming 9
(1999), pp. 1–31.
Jeffrey, A. and J. Rathke, A theory of bisimulation for a fragment of concurrent ML with local names, Theoret. Comput. Sci. 323 (2004), pp. 1–48.
Kutzner, A. and M. Schmidt-Schauß, A nondeterministic call-by-need lambda calculus, in: International Conference on Functional Programming 1998 (1998), pp. 324–335.
Milner, R., “Communicating and Mobile Systems: the π-Calculus,” Cambridge University Press, 1999.
Milner, R., M. Tofte, R. Harper and D. B. MacQueen, “The Standard ML Programming Language (Revised),” MIT Press, 1997.
Moran, A. K., “Call-by-name, Call-by-need, and McCarthy’s Amb,” Ph.D. thesis, Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden (1998).
Niehren, J., J. Schwinghammer and G. Smolka, A concurrent lambda calculus with futures, Theoret. Comput. Sci.364 (2006), pp. 338–356.
Pitts, A. M., Operational semantics and program equivalence, in: J. T. O’Donnell, editor, Applied Semantics, LNCS 2395 (2002), pp. 378–412.
Plotkin, G. D., A powerdomain construction, SIAM J. Comput. 5 (1976), pp. 452–487.
Rossberg, A., The missing link: dynamic components for ML, in: Proceedings of the 11th ACM SIGPLAN International Conference on Functional Programming (2006), pp. 99–110.
Rossberg, A., D. L. Botlan, G. Tack, T. Brunklaus and G. Smolka, “Alice Through the Looking Glass,” Trends in Functional Programming 5, Intellect Books, Bristol, UK, Munich, Germany, 2006 pp. 79–96.
Sabel, D. and M. Schmidt-Schauß, A call-by-need lambda-calculus with locally bottom-avoiding choice: Context lemma and correctness of transformations, Math. Structures Comput. Sci. (2007), accepted.
Sangiorgi, D., The lazy lambda calculus in a concurrency scenario, Inform. and Comput. 111 (1994),
pp. 120–153.
Sangiorgi, D. and D. Walker, “The π-calculus: a Theory of Mobile Processes,” Cambridge University Press, 2001.
Smolka, G., The Oz programming model, in: J. van Leeuwen, editor, Computer Science Today, LNCS
1000, Springer, 1995 pp. 324–343.

Context Lemma for Expressions
The context lemma for expressions says that ECs provide enough observations to distinguish nonequivalent expressions. It talks about the relations
e ≤ev e' iff ∀E∀D : D[E[e]]↓ ⇒ D[E[e']]↓
e ≤ev e' iff ∀E∀D : D[E[e]]⇓ ⇒ D[E[e']]⇓

Proposition A.1 (Context Lemma for ≤↓) For all expressions e1, e2:
e1 ≤ev e2 ⇒ e1 ≤↓ e2

This will follow from Lemma A.3. In a first step, we have to generalize the context lemma for expressions to multicontexts, which may have more than one hole, or none at all. A multicontext M with n holes is a process that permits additional constants []1,. .. , []n for marking holes in expression positions, each of which occurs exactly once. Similar as for contexts C, the component x c [] is not possible. We write M [e1,. .., en] for the process obtained by replacing []i by ei for all 1 ≤ i ≤ n. Note that e.g. the terms D[C1[[]1] | .. . | Cn[[]n]]] are multicontexts with n holes. For instance, if M is z c λx.([]1 []2) | y⇐[]3 then M [x, y, z] becomes z c λx.x y | y⇐z We assume [] = []1 so that standard contexts C become multicontexts. The i-th hole of a multicontext M is in EC position if M [e1,.. ., ei−1, [], ei+1,. .., en] is a (process) EC of the form D[E] for some expressions e1, ... , en.
Lemma A.2 If the i-th hole of M is in EC position then there exists an index j such that
M [e1,. .., ej−1, [ ], ej+1,.. ., en] is an EC for all expressions e1,. .., en.
Proof. We prove the corresponding property for expression multicontexts, by an induction on such contexts
. In the case where n ≤ 1 the proposition clearly holds. So suppose M has at least two holes. Then either
Mf is of the form λx.Mf or Mf Mf or exch(Mf , Mf ). We may assume without loss of generality that for
1	1	2	1	2

some 1 ≤ k ≤ n, Mf is a multicontext over holes [] ,. .. , [] , and Mf
is a multicontext over []
,. .., []n;

1
otherwise we rename the holes accordingly.
1	k	2
k+1

The case λx.Mf is not possible, since every instantiation of n − 1 holes of M1 yields a deep context. In

particular, this cannot be an EC.
In the case Mf Mf , we distinguish two subcases: First, if there exist e ,.. .,e 
and 1 ≤ i ≤ k such

1	2	1	k
that Mf [e ,. .., e	, [ ],e	, ... ,e ] is an EC, then by induction hypothesis there exists 1 ≤ j ≤ k such
1 1	i−1	i+1	k
that Mf [e' , ... , e'	, [ ], e'	,.. ., e' ] is an EC for all e' ,. .., e' . Therefore, by definition of ECs and

1 1	j−1
j+1	k	1	k

assumption Mf = Mf Mf , Mf[e' , ... , e'
, [ ], e'
,. .., e' ] is an EC for all e' ,.. ., e' .

1	2	1
j−1
j+1	n	1	n

Second, if for all e1,. .. , e
and 1 ≤ i ≤ k, Mf [e ,. .. ,e 
, [ ],e 
, ... ,e ] is not an EC then for all

k	1 1
i−1
i+1	k

e' , ... , e' , Mf [e' , ... , e' ] ∈ Val, for otherwise there is no instantiation of Mf = Mf Mf
that yields an EC,

1	k	1 1	k	1	2

contradicting the assumption. Moreover, by assumption we have that Mf [e
k+1
,. .., e
i−1
, [], ei+1
, ... , en]

is an EC, for some e	,. .., en and k +1 ≤ i ≤ n. By induction hypothesis and Mf = Mf Mf , there

k+1
exists k +1 ≤ j ≤ n such that Mf[e' ,. .. , e'
, [ ], e'
1	2
,. .., e' ] is an EC for all e' ,. .., e' .

1
The case exch(Mf , Mf ) is similar.
j−1
j+1	n	1	n

1	2
The statement of the lemma follows from this result by an induction on the structure of (process) multi- contexts M .	 
A redex R in a multicontext M is an EC D[E] or future EC D[F ] in M to which some reduction rule applies. If e = e1,. .., en is a sequence and I ∈ {1,. .. , n}∗ a sequence of indices of length m then we write eI for the sequence ei1 ,.. ., eim where I = i1, ... , im. We write []I for the sequence of hole markers []i1 , ... , []im .
Lemma A.3 (Generalized context lemma for may-convergence) For n ≥ 0 and e1,. .., en and
e' ,.. ., e' possibly empty sequences of expressions:
1	n

(∀1 ≤ i ≤ n : ei ≤ev e' )	⇒	∀M : M [e1,. .., en]↓ =⇒ M [e' , ... , e' ]↓
↓  i	1	n

Proof. Let M [e1,.. ., en]↓, so we have to show M [e' , ... , e' ]↓. We use induction on the following lexico-
1	n
graphic ordering of pairs (l, n), where
l is the length of a shortest succeeding sequence of reductions starting with M [e1,.. ., en], and

n is the number of holes in M .
The claim holds for all pairs (l, 0), since if M has no holes there is nothing to show. Now, let (l, n) > (0, 0). For the induction step, we assume the claim holds for all pairs (l', n') that are strictly smaller than (l, n).

We assume ∀1 ≤ i ≤ n : e
≤ev '	l

i	↓ ei and let M be a multicontext with n holes such that M [e1,. .., en] −→ p
for some successful p. There are two cases:
At least one hole of M is in EC position. Then let 1 ≤ i ≤ n be the position of the hole in EC position as determined by Lemma A.2. Let M1 be the multicontext with n − 1 holes defined by M1 ≡ M [[ ]1,. .., [ ]i−1, ei, [ ]i+1,.. ., [ ]n]. Hence M1[e1, ... , ei−1, ei+1,. .., en]↓ so that the induction hypothesis
yields M1[e' ,.. ., e'	, e'	,.. ., e' ]↓. By Lemma A.2 and the choice of i there exists an EC D'[E'] such
1	i−1  i+1	n

that D'[E'] ≡ M [e' , ... , e'	, [ ]i, e'
, . .. , e' ]. Thus, D'[E'[ei]]↓ so that D'[E'[e' ]]↓ by assumption. The

1
latter is M [e' ,.. ., e' ]↓.
i−1
i+1	n	i

1	n
No hole of M is in EC position. Note that M may contain deep holes and also holes that are not in abstractions but also not in EC position. There are also no holes of the form x c [].
If l = 0, then M [e1, ... , en] is successful, so M [e' ,. .. , e' ] is successful, too. Hence M [e' ,. .., e' ]↓.
1	n	1	n
l	'	'
If l > 0, then the first reduction step of −→ does also apply to M [e1,. .. , en], where the same reduction at the same position is used, and in the case of fut.deref(ev) and lazy.trigger(ev), the same future can
'	'	l

be used in M [e1,. .. , en] −→ .. ..
If the first reduction step of −→l

is not a fut.deref(ev), or it is a fut.deref(ev) and the referenced

value is an abstraction or variable, and there are no holes in the referenced abstraction, then there is a

'	'  I
l−1

multicontext M with n holes, M [e] −→ M [e ] −−→ .. ., where I is a permutation of {1, ... , n}, and also
M [e'] −→ M '[e'I ]. We can apply the induction hypothesis to M '[eI ], since there is a reduction of length
l − 1 to a successful process.

If the reduction −→l
begins with a fut.deref(ev), the referenced value is an abstraction, and there are

holes in the referenced abstraction, then more arguments are required. As a special notation for this part of the proof we indicate the occurrences of some of the expressions in the sequence e in the pro- cess in the context notation, which may lead to double square-bracket notation, but the meaning should
be clear. The process expression M [e] is of the form E[f1][x] | x⇐v[f2] | p[f3], where fj are sequences of ei’s, such that f1, f2, f3 = e. Reduction of this process using fut.deref(ev) results, before renam- ing, in E[f1][v[f2]] | x⇐v[f2] | p[f3], and after a renaming within v in E[f1][vρ[ρf2]] | x⇐v[f2] | p[f3].

The same reduction applied to M [e'], where f ' , f ' , f '	'	'

'	'	fut.deref(ev)

1  2  3 = e
is E[f1][x] | x⇐v[f2 ] | p[f3] −−−−−−−−−→

E[f ' ][v[f ' ]] | x⇐v[f ' ] | p[f ' ]. Note that we can in fact choose the renaming ρ such that it renames
1	2	2	3
with variables that are fresh for both of the resulting processes. Therefore, after applying ρ to the
second process, we obtain E[f ' ][vρ[ρf ' ]] | x⇐v[f ' ] | p[f ' ]. We can apply the induction hypothesis to
1	2	2	3
E[f1][vρ[ρf2]] | x⇐v[f2] | p[f3] and E[f ' ][vρ[ρf ' ]] | x⇐v[f ' ] | p[f ' ] using the sequences f1, ρf2, f2, f3 and
1	2	2	3
f ' , ρf ' , f ' , f ' , since there is a reduction of length l − 1 to a successful process, and an easy computation
1	2  2  3
shows that the hypotheses eiρ ≤ev e' ρ also hold for all parameters in ρf2 and ρf ' .	 
↓  i	2
Proposition A.4 (Context Lemma) For all e1, e2 ∈ Exp:
e1 ≤ev e2 and e1 ≤ev e2	⇒	e1 ≤ e2
↓	⇓
Proof. The part for may-convergence follows from Proposition A.1. For the remaining part, we prove the
claim that for all n ≥ 0 and sequences e1,. .., en, e' , ... , e' ,
1	n
∀1 ≤ i ≤ n : ei ≤ev e' ∧ ei ≤ev e' ⇒ (∀M : M [e' ,. .., e' ]↑ ⇒ M [e1, ... , en]↑)
↓  i	⇓  i	1	n
The lemma then follows using the remarks on the relations on may- and must- convergence and divergence in Section 3. We prove the claim by induction on lexicographically ordered pairs (l, n) where
l is the length of a shortest sequence of reductions starting with M [e' , ... , e' ] that ends in a process
1	n
p with p⇑, and
n is the number of holes in M .
If M has no holes there is nothing to show.
Now let (l, n) > (0, 0). We analyze the two cases:
At least one hole of M is in EC position. Then the same arguments as in the first part of the proof of Lemma A.3 show the claim.


No hole of M is in EC position. If l > 0 then again the argumentation of part 2 of the proof of Lemma A.3 is used.
The remaining case is l = 0, i.e., M [e' ,. . ., e' ]⇑. We have to show that M [e' , ... , e' ]⇑ ⇒ M [e1, ... , en]↑.
1	n	1	n
Using the relations between may- and must-convergence and must- and may-divergence, respectively,
stated in Section 3, an equivalent claim is M [e1, ... , en] ⇓ ⇒ M [e' ,. .., e' ] ↓. Using the precondition
1	n
and Lemma A.3 we have M [e1,.. ., en] ↓ ⇒ M [e' ,.. ., e' ] ↓. Since obviously M [e1,.. ., en] ⇓ implies
1	n
M [e1,.. ., en]↓, the claim follows.	 

Incorrectness of Transformations
Let I = λx.x. We prove Lemma 4.2 by giving counter-examples for every rule. For notational simplicity, we omit the ν-binders.

thread.new(a): Let p1 be the process y⇐λx.(thread I). Thus, p1⇓ as it is already successful. Transform- ing it using thread.new(a) gives a process p2, y⇐λx.z | z⇐(I z), which reduces to y⇐λx.z | z⇐u | u⇐z, which is clearly must-divergent because of the cyclic subprocess, hence p2↑ follows.
handle.new(a):   Let  y⇐λx.handle(λu1λu2.u2 unit) | x1⇐y unit | x2⇐y unit  be  the  pro- cess p1.   Reduction of p1 creates two handles and then terminates with a success- ful process, thus p1 ⇓.  In the case it is transformed, we obtain the process p2 ≡ y⇐λx.((λu1λu2.u2 unit) y1 y2) | y2 h y1 | x1⇐y unit | x2⇐y unit which will lead to a handle-error, i.e., p2 is must-divergent.
handle.bind(a): Consider the process p1 ≡ m⇐λx.y unit | n⇐y unit | y h z which is may- and must- convergent, whereas transformation results in the process p2 ≡ m⇐λx.unit | n⇐y unit | y h • | z⇐unit. Note that p2 is not successful but also not reducible. Hence p2 is must-divergent.
cell.new(a): Applied within an abstraction, it is possible to share values, which are otherwise unshared, for instance let p1, p2 be the following processes:


p1 ≡	z⇐λz.(cell I)
| x1⇐(exch((z unit), unit)) unit
| x2⇐(exch((z unit), unit)) unit
p2 ≡	z⇐λz.w
| w c I
| x1⇐(exch((z unit), unit)) unit
| x2⇐(exch(((z unit), unit)) unit


Process p2 evolves from p1 by applying cell.new(a). We observe that p1⇓, since both exch-operations use their own cells and both will read the identity I. On the other hand, p2⇑ since the exch-operations use the same cell, so that the thread performing the second exchange remains stuck with an application of the form unit unit.
cell.exch(ev): The transformation is clearly not correct, since it can non-deterministically choose
which exchange-operation to do first. The program x⇐exch(y, unit) | z⇐exch(y, unit) | y c x is may- convergent: after two reductions, the result is x⇐unit | z⇐x | y c unit. Using the other possibility as transformation, a must-divergent program results: x⇐x | z⇐exch(y, unit) | y c unit.
lazy.new(a): This rule is not correct inside abstractions, since there may be a sharing/desharing conflict. Let the processes p1 and p2 be defined as:


p1 ≡	y c I
| w⇐λx.lazy(λz.exch(y, unit))
p2 ≡	y c I	'
| w'⇐suλsxp.w	'

| w2⇐(w unit) (w unit) unit	| w ⇐= (λz.exch(y, unit)) w
| w2⇐(w unit) (w unit) unit

Applying lazy.new(a) to p1 results in process p2. Note that p2 ⇓, since only one exch-operation is performed (reading the identity I), whereas p1 does not converge, since two exchange-operations are performed, and thus one of these results in unit.
lazy.trigger(f): This transformation is not correct in arbitrary contexts, since it would force evaluation.
susp
An easy counterexample is y⇐x | x ⇐= x which is convergent (it is successful), but becomes must- divergent after forcing the evaluation (because of the cyclic x⇐x).
β-cbn: Let p1 ≡ y⇐λx.unit ⊥ and p2 ≡ y⇐unit, where ⊥ is a must-divergent expression. Obviously
p2 is must-convergent while p1 is must-divergent.

Examples for the Forking and Commuting Diagrams
Lemmas 4.11, 4.15, and 4.20 follow by analyzing all overlappings of the corresponding transformation with reductions. In this section we give typical example cases for the non-trivial diagrams.

Diagrams for β-cbvL(¬ev∧f)

β-cbvL(¬ev∧f) · r J 
¸ ¸	r
¸ ¸
 
The non-trivial cases occur when an β-cbvL(¬ev∧f) becomes a reduction β-cbvL(ev), as expressed by the diagram. This case may occur if r is a lazy.trigger(ev) reduction, and if the redex of the transformation β-cbvL(¬ev∧f) is inside a lazy future that gets triggered. Another case is that r is an β-cbvL(ev) reduction, e.g.

β-cbvL(ev)
¸zJ˛ 

y⇐((λx.x) y) ((λz.z) unit)  β-cbvL(¬ev∧f)  y⇐ ((λx.x) y) z | z⇐unit

r J
y⇐x ((λz.z) unit) | x⇐y _ _ _ _
r
_ _ _	J 

β-cbvL(ev)
y⇐x z | x⇐y | z⇐unit

Diagrams for cell.deref

·  cell.deref ·
r	r



cell.exch(ev)
·  cell.deref ·
 
cell.exch(ev)

J	 J	J	 J 

cell.deref  ·
fut.deref(f) ·

for every reduction r
Cases for the first diagram are obvious. An example for the second diagram is:
z⇐exch(x, y) | x c v | v⇐w   cell.deref  z⇐ exch(x, y) | x c w | v⇐w

cell.exch(ev)
J 

 	  
cell.exch(ev)
J 

z⇐v | x c y | v⇐w	fut.deref(f)
z⇐w | x c y | v⇐w


Diagrams for fut.deref(f) and fut.deref(¬ev∧f)
We show examples for the diagrams of Lemma 4.15.



fut.deref(ev)
· 	fut.deref(f)	 · 
 fut.deref(ev)
fut.deref(¬ev∧f)
·	·
fut.deref(ev) 

J_ _ _ _ _ ·	 J 
J	fut.deref(ev)

· fut.deref(f)
fut.deref(f) ·
· 
fut.deref(ev) 
·
_ _ _ J 

A typical example for both diagrams is:
fut.deref(f)
fut.deref(¬ev∧f)

x⇐ya | y⇐v | v⇐w 	 x⇐ ya | y⇐w | v⇐w

fut.deref(ev)
J 

 	  

 	  
fut.deref(ev)
J 

x⇐va | y⇐v | v⇐w
x⇐wa | y⇐v | v⇐w
fut.deref(ev)
fut.deref(f)
x⇐wa | y⇐w | v⇐w



We now examine the following four diagrams:
·fut.deref(f) · 


fut.deref(¬ev∧ f) 



r J	 r
·	·
r	r

· _ _
_ _ J 
J_ _
_ _ J 

fut.deref(f)·	·	·
fut.deref(¬ev∧f)
for every reduction r	for every reduction r

·fut.deref(f) · 
fut.deref(f∧¬ ev) 


cell.exch(ev)


 cell.exch(ev)
· 
cell.exch(ev) 
·
cell.exch(ev)

J_ _
_ _ J 
J_ _
_ _ J 


Beside simple commuting cases, where the transformation and the standard reduction do not influence each other, there are cases where the target of the dereferencing operation moves from a thread to a lazy thread or to a cell and vice versa. We show two examples:

x⇐exch(y, z) | y c v  | z⇐v	fut.deref(f) x⇐ exch(y, v ) | y c v | z⇐v

cell.exch(ev)
J 

 	  
cell.exch(ev)
J 

x⇐v2 | y c z | z⇐v1	cell.deref	x⇐v2 | y c v1 | z⇐v1


susp

fut.deref(f) 

susp

y⇐(x w) | x ⇐= z | z⇐v
lazy.trigger(ev)
y⇐(x w) | x ⇐= v | z⇐v
lazy.trigger(ev)

J			J 
y⇐(x w) | x⇐z | z⇐v	fut.deref(f)	y⇐(x w) | x⇐v | z⇐v
We now look at the diagram
fut.deref(¬ev∧f)
·	·
r J 

· ¸ ¸
fut.deref(ev¸)
r

¸zJ 

for r ∈ {thread.new(ev), handle.new(ev), lazy.trigger(ev)}
We illustrate all three cases by examples:
z⇐thread x fut.deref(f) z ⇐thread v	z⇐handle x fut.deref(f) z ⇐handle v

| x⇐v
| x⇐v
| x⇐v
| x⇐v


thread.new(ev)
J

thread.new(ev)
J

handle.new(ev)
J

handle.new(ev)
J

z⇐y
| y⇐(xy)
| x⇐v

susp
z⇐y
fut.deref(ev) | y ⇐(vy)
| x⇐v
z⇐xy z1
| z h y1
| x⇐v
fut.deref(f)	 s usp
z⇐vy z1
fut.deref(ev) | z h y1
| x⇐v

y ⇐= (x v1) | x⇐w | z⇐(y v2)
lazy.trigger(ev)
y ⇐= (w v1) | x⇐w | z⇐(y v2)
lazy.trigger(ev)

J			J 

y⇐(x v1) | x⇐w | z⇐(y v2)	fut.deref(ev)
y⇐(w v1) | x⇐w | z⇐(y v2)




Diagrams for fut.deref(d)


·  fut.deref(d)  ·
r	r



β-cbvL(ev)
· fut.deref(d) ·
 
β-cbvL(ev)

J	 J	J	 J 
· fut.deref(d) ·	· fut.deref(f) ·
for every reduction r
The first diagram has the same special cases as the diagram for fut.deref(f). The second diagram shows the only case where the target of a dereferencing operation is inside the body of an abstraction, but this is no longer the case after applying a standard reduction. An example for this case is:
y⇐(λx.(w z)) u | z⇐v 	fut.deref(d)	 y⇐ (λx.(w v)) u | z⇐v

β-cbvL(ev)
J 

 	  
β-cbvL(ev)
J 

y⇐(w z) | x⇐u | z⇐v	fut.deref(f)
The last diagram is:
y⇐(w v)) | x⇐u | z⇐v



fut.deref(ev)
· 	fut.deref(d)	 ·
 
fut.deref(ev)

J		 J 


An example for this case is:
·	fut.deref(d)	·	fut.deref(d)	·

x⇐(w z) | w⇐λz .y | y⇐v 	fut.deref(d)	 x⇐ (w z) | w⇐λz .v | y⇐v


fut.deref(ev) J 
x⇐((λz1.y) z)
| w⇐λz1.y
| y⇐v

x⇐((λz1.y) z)
fut.deref(d)	 | w ⇐λz1 .v
| y⇐v

Jfut .deref(ev)
x⇐((λz1.v) z)
fut.deref(d)	 | w ⇐λz1 .v
| y⇐v
