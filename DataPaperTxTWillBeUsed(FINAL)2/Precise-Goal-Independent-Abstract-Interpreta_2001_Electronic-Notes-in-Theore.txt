Electronic Notes in Theoretical Computer Science 42 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume42.html 17 pages


Precise Goal-Independent Abstract Interpretation of Constraint Logic Programs

Peter Schachte 1
The University of Melbourne Victoria 3010, Australia


Abstract
We present a goal-independent abstract interpretation framework for pure con- straint logic programs, and prove the sufficiency of a set of conditions for abstract domains to ensure that the analysis will never lose precision. Along the way, we formally define pure constraint logic programming systems, give a formal seman- tics that is independent of the actual constraint domain, and formally define the maximally precise abstraction of a pure constraint logic program.


Introduction
Abstract interpretation [1] is the process of mimicking the formal semantics of a program — interpreting the program — using an abstraction of the data used by the real program. By basing our analysis on the formal semantics of the program, we gain guarantees of the correctness of our results, and by using an abstraction of the real data, we often gain a guarantee of termination.
The central idea of abstract interpretation is to approximate the actual data of a program. An approximation of a program state, which we call an abstract value, will usually approximate more than a single program state. For example, we might approximate an integer by whether it is even or odd, or whether it is smaller, greater or equal to zero. Often, however, we will not be able to choose a single one of these abstractions. For example, we may know an integer variable will be either 0 or 3; in this case it could be either 0 or greater than zero. Therefore, it is not sufficient to have a set of approximate values {<0, =0, >0}. Auseful set of approximations might include {<0, ≤0, = 0, /=0, ≥0, >0}. It must also include an abstraction to indicate no information, or perfect uncertainty. This will usually be denoted T. It is also convenient to include another abstraction to indicate that no value is possible, to handle

1 Email: schachte@cs.mu.oz.au
◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.



≤0	≥0
<0	>0

⊥
Fig. 1. Hasse diagram for the signs abstract domain for a single variable

cases of unreachable, failing, (infinitely) looping, or error-causing code. This value is usually denoted ⊥.
Another way to think about this is that we are partitioning Z into three distinct sets, each corresponding to an element of {<0, =0, >0}. Then for any set of integers we can find a subset of {<0, =0, >0} that covers all the integers in the given set. Thus the set of abstract values we are interested in is the powerset of the set of signs, P({<0, =0, >0})= {∅, {<0}, {=0}, {>0}, {<0, =
0}, {<0, >0}, {=0, >0}, {<0, =0, >0}}. These abstract values will be easier to work with if they are given more convenient names. In the same order, we will use the names {⊥, <0, =0, >0, ≤0, /=0, ≥0, T}.
Clearly we can approximate any set of values by T, but some approxima- tions are better than others, and we would always like to choose the most precise approximation. To continue with our example, if a program variable could take on any of the values 1, 3, 5, 7,..., we would prefer to approximate it as >0, even though ≥0 or T would also be correct, because ≥0 and T de- scribe a larger number of concrete values than >0. This gives us a means of comparing approximations, and makes our set of abstract values a poset. Fur- thermore, every subset of our set of approximations has a least upper bound and a greatest lower bound, which means that we have a complete lattice, as depicted in the Hasse diagram in Figure 1 . If we think of our set of abstract values as a power set, then we can use subset ordering to guarantee us a com- plete lattice. Such a set of possible approximations, together with its ordering relation, is called an abstract domain.
Once we have found an abstract domain, we will want to be precise about the meanings of its elements. For this, we want a concretization function
γ : Abst → P(Conc).

We use the name Conc to refer to the concrete domain, in this example, the set of integers; Abst refers to the abstract domain, in this case {⊥, <0, =0,> 0, ≤0, /=0, ≥0, T}.
Note that γ maps abstractions to sets of concrete values, because there will always be more than a single concrete value corresponding to some abstract values (otherwise the abstract domain is not very abstract). We will also need a function to abstract the concrete values appearing in the program to be


α {c} −−F−α→ F  α {c} = αF c
α 	 α

Fig. 2. Correctness condition for function approximation
analyzed. We define an abstraction function as
α : P(Conc) → Abst.
That is, given a set of concrete values, α yields the appropriate (most precise) abstraction for that set. This should be the least upper bound of the abstrac- tions we expect for each element of the set. Note that α must be monotonic because adding to a set of concrete values to be abstracted should never result in a more precise abstraction. If this were to happen, then the more precise abstraction would certainly apply to the smaller set. Conversely, we require that γ must be monotonic because a less precise abstraction should never describe a smaller set of concrete values. Further, we will require that
∀C ⊆ Conc : C ⊆ γ (α C), and
∀a ∈ Abst : α (γ a) ± a
The first of these inequalities guarantees that abstracting and then concretiz- ing a set of values doesn’t “lose” any values, while the second assures us that concretizing and then abstracting an abstract value won’t lose any precision. This means that α and γ form a Galois connection. Ideally, we would like to have
∀a ∈ Abst : α (γ a)= a
(meaning that α and γ form a Galois insertion), but we shall not require it.
Next we need to determine how to abstract concrete operations on the data we are interested in. That is, for each concrete operation F : Conc → Conc, we must find an abstract operation Fα : Abst → Abst that faithfully approximates it. Fortunately, our α and γ functions make clear how to do this: we must require that
∀c ∈ Conc : F c ∈ γ(Fα (α{c})).
This condition is often expressed by the diagram in Figure 2 . This is only a correctness constraint, however; for optimality we would also like there to be

no F '
satisfying this constraint and also satisfying



∃a ∈ Abst : F '
a ± Fα a.

The balance of this paper is arranged as follows. Section 2 presents a denotational semantics for constraint logic programs which is independent of any particular constraint domain. It also specifies what properties we expect

a constraint logic programming system to exhibit. In Section 3 we define an abstract interpretation framework, specify the properties we expect of an abstract domain, and prove that our abstract interpretation framework will always produce a maximally precise analysis of any program providing that the abstract domain used exhibits the properties we require. Section 4 describes related work, and Section 5 presents our conclusions.

The Semantics of Constraint Logic Programs
To be confident of the correctness of our analyses of the behavior of constraint logic programs, we need to specify exactly how programs behave.
In this paper, we will concern ourselves with only the goal independent analysis of pure constraint logic programs. This decision permits us to develop a semantics, and an analysis, that is independent of implementation technol- ogy. For a discussion of the issues of this paper related to goal-dependent analysis, see Schachte [2]. Our semantics is also independent of the choice of a constraint domain.
We assume we are given the following denumerable disjoint sets:
Var the set of all variables;
Fn the set of all constructor functions;
PCon the set of all primitive constraint constructors;
Pred the set of all atom constructors.
Since equality is an essential part of all logic programming, it must be part of all constraint domains [3]. Therefore, PCon must include =, the special equality constraint.
From these sets we define Term to be the union of Var and the set of all terms that can be constructed with functors from Fn and arguments from Term. Given t, t' ∈ Term and v ∈ Var, we denote by t [t'/v] the unique result of replacing all occurrences of v in t by t'. We define vars : Term → Var to yield the set of all variables appearing syntactically in a term.
Note that t [t'/v] has some important properties which we will need. Firstly, this operation replaces all occurrences of v, so that if v /∈ vars(t'), then v /∈ vars(t [t'/v]). Also note that for any variable v', if v' /∈ vars(t) then t = (t [v'/v] [v/v']). Finally, if two substitutions are independent, they may be applied in either order; that is, if v' /∈ t, v /∈ t', and v /= v', then t'' [t/v] [t'/v']= t'' [t'/v'] [t/v].
Prim is the set of all primitive constraints formed with constructors from PCon and arguments from Term, and similarly Atom is the set of all atoms formed with constructors from Pred and arguments from Term. Lit is the set of literals Atom ∪ Prim. Each element of Body = Pf(Lit), that is, the set of finite sets of elements from Lit, representing finite conjunctions of literals. 2

2 Since we consider only goal-independent analysis of pure contstraint logic programs, and


Clause is the set of clauses H ← B where H ∈ Atom and B ∈ Body. Finally, Program = Pf(Clause) is the set of all finite programs composed of clauses from Clause. As a convenience, we extend = to Atom × Atom as an abbreviation for the equivalence of the predicate constructors and the pairwise equivalence of the arguments.
Next we define Con to be the set of all possibly existentially quantified finite conjunctions of primitive constraints. We view an element of P(Con) as describing a number of alternative constraints, that is, a disjunction of constraints.
We extend our definition of vars to cover Prim, Atom, Lit, Con, and Clause
in the obvious syntactic way.
There are several properties which we require of any constraint logic pro- gramming system we are to analyze.
Axiom 2.1 For c, c', c'' ∈ Con, t, t' ∈ Term, and v, v' ∈ Var:
Conjunction must be commutative, associative, and absorptive
( i.e., c ∧ c’' ≡ c' ∧ c’, c ∧ c’ ≡ c, and c ∧ (c' ∧ c'')’ ≡ (c ∧ c') ∧ c'’' ) 3
true must be an identity, and false an annihilator for conjunction ( true ∧ c’ ≡ c ∧ true’ ≡ c, false ∧ c’ ≡ c ∧ false’ ≡ false)
∃v : true’ ≡ true and ∃v : (c ∧ c')’ ≡ c ∧ ∃v : c’' when v /∈ vars(c);
∃v : ∃v' : c’ ≡ ∃v' : ∃v : c’;
∃v : c’ ≡ ∃v' : c’' when v' /∈ vars(c) ∧ c' ≡ c [v'/v];
The required equality constraint = must be an equivalence relation

( t = t’ ≡ true, t = t’'
≡ t' = t’, and t = t' ∧ t' = t'’'
≡ t = t'’' )

∃v : v = t ∧ c’ ≡ c [t/v] when v /∈ vars(t);
∃v : (v = t ∧ c ∧ c')’ ≡ (∃v : v = t ∧ c) ∧ (∃v : v = t ∧ c')’ when v /∈ vars(t)
✷
We extend the conjunction operation ∧ on Con to ∧ : P(Con) → P(Con) →
P(Con) asa cross-conjunction, that is, for S1, S2 ⊆ Con,
S1 ∧ S2 = {s1 ∧ s2 | s1 ∈ S1 ∧ s2 ∈ S2}\ {false}.

(Because false is not a meaningful constraint in that it can never be satisfied, it is convenient for cross-conjunction to remove it.) We naturally extend this to a unary function : Pf(P(Con)) → P(Con) as repeated cross-conjunction. We also extend existential quantification to P(Con) in a similar way: for S ⊆


we shall require that conjunction be commutative, associative, and absorptive, sets of literals are an adequate representation for clause bodies.
3 We distinguish elements of a program being analyzed from the elements of the analysis
framework being presented using Quine corners [4], written ·’. Quine corners are not quotes; the enclosed material may include variables, which are to be interpreted as such.

Con,v ∈ Var, we define
∃v : S = {(∃v : s) | s ∈ S};
we further extend ∃ to handle quantification of possibly infinite sets of vari- ables in the natural way.
It will be convenient to have a notation for performing many substitutions at once, which we gain through the extension of our notation for substitution to apply to sequences of variables and terms. We denote by t [t/v] the pairwise substitution of terms from t for variables from v in t, where t is a sequence of terms, v is a sequence of variables of the same length, no variable appears more than once in v, and v and vars(t) are disjoint. We will abuse notation by applying set operations to sequences, and understand these operations to apply to the set of elements of the sequence. Our need for sequences is small enough that it is not important that we be formal about them; we only note that for any set s it is possible to arbitrarily choose a sequence s such that s contains all and only the elements of s, without repetition. Note that our observations about t [t'/v] apply to sequences as well, as long as the sequences contain no repeated elements. In particular, t [v'/v] [v/v'] = t whenever v and v' are disjoint, and v' and vars(t) are disjoint.
Giacobazzi et al. [5] identify a number of properties that a constraint sys- tem must exhibit in order to be “sensible,” that is, in order to behave in a manner we would expect of a constraint logic programming system. The fol- lowing theorem proves that P(Con), together with the operations ∧, ∪, and
∃, the elements {true} and ∅, and at least the primitive constraint =, meet these requirements.
Theorem 2.2 For every V, V ' ⊆ Var,v ∈ Var, C, C' ⊆ Con, and t, t', t'' ∈
Term, we have the following:
∧ distributes over finite and infinite unions;
∧ is associative and has an identity {true};
∪ is associative and has an identity ∅;
∪ is commutative and absorptive;
∅ is an annihilator for ∧;
for any possibly infinite set S ⊆ P(Con),	S exists and is unique;
(∃V : ∅) ≡ ∅;
∃V : (C ∧ ∃V : C') ≡ ∃V : ((∃V : C) ∧ C') ≡ (∃V : C) ∧ (∃V : C');
∃V : ∃V ' : C ≡ ∃(V ∪ V '): C;
∃V distributes over finite and infinite unions;
{ t = t’}≡ {true};
{ t = t’' }≡ { t' = t’};
∃v : ( v = t’ ∧ t' = t'’' ) ≡ ( t' = t'’' ) [t/v] when v /∈ t;

∃v : (v = t ∧ (C ∧ C'))’ ≡ ∃v : (v = t ∧ C) ∧ (∃v : (v = t ∧ C'))’ when v /∈
vars(t).
✷
Giacobazzi et al. also require that
(C ∪ ∃V : C) ≡ ∃V : C,
but we do not wish to require this. To do so would prevent us from collecting extralogical information about predicates that may become important in the analysis of programs. For example, given the Prolog program
p(1).
p(X).
we would like our semantics to conclude that there are two solutions for p/1, one indicating that 1 is a solution and the other that any term is a solution. Including (xv) would only allow the more general solution, thwarting analyses which would need to know that 1 is also a solution. To extend this example, an analysis for definite freeness would need to know that even if p/1 is invoked with its argument unbound, it can succeed with its argument bound. A determinacy analysis would need to know that p/1 may have two solutions, and so would not be determinate when its argument is unbound. We do not discuss such analyses in this paper but we do want our framework to allow them.
We require one further function:

rename : Clause → P(Var) → Clause

produces a variant of the input clause that has no variables in common with the given set of variables. This enforces the rule that the scope of a variable is limited to the clause it occurs in.
We specify our semantic domain Den as
Den = Atom → P(Con).
It is ordered pointwise. The least denotation (⊥) maps all atoms to the empty set.
Definition 2.3 (Program semantics) The denotation of a program is given by the function Psem, which we define in terms of the auxiliary functions Csem and Lsem:
Psem : Program → Den
Csem : Clause → Den → Den
Lsem : Lit → Den → P(Con)
These functions are defined as follows:


Psem P = lfp	H Csem C
C∈P


Csem C d A = ∃V	(Lsem H = A’ d) ∧	Lsem L d
L∈B
where H ← B’ = rename C vars(A)
and V = vars(H) ∪ vars(B)



Lsem L d =
{L}	when L ∈ Prim ∧ L /≡ false
d L	when L ∈ Atom



Intuitively, we define the semantics of a program as the least fixed point of the combination of the semantics of the clauses of the program. Thus the semantics is defined by specifying how, given the set of constraints that can result from n derivation steps, we can compute the constraints resulting from n + 1 derivation steps. The semantics of an individual clause H ← B is the function which maps an atom A to the conjunction of the equality constraint H = A and the literals in the body of the clause, and projects away all the variables in the clause (leaving only the variables in the invocation). The semantics of a literal L depends upon whether it is an atom or a primitive constraint. The semantics of an atom is determined by the given denotation function (i.e., the result of the previous derivation step), while the semantics of a primitive constraint is just that constraint as a singleton set (we filter out false constraints because they cannot be satisfied).

Abstract Interpretation of Constraint Logic Programs
In abstract interpretation, we wish to find an abstract version of the semantics of a program. In fact, we really wish to abstract the semantics twice: we abstract the meaning of the program to be given in terms of some abstract domain rather than the concrete domain, giving us an abstract interpreter. Then we abstract the choice of abstract domain from this, yielding an abstract interpretation framework . The focus of this paper is the presentation of an abstract interpretation framework and the establishment of a set of sufficient conditions for this framework to always produce maximally precise analyses, according to the following definition of “maximally precise.”
Definition 3.1 (Precise approximation) Given an abstract domain ACon and an abstraction function α : P(Con) → ACon, we say that a ∈ ACon precisely approximates C ⊆ Con, and write a apprα C, as follows:
a apprα C ↔ αC = a.

For any set S, we extend this relation to functions F : S → ACon and G :
S → P(Con) in the natural way:
F apprα G ↔ ∀s ∈ S : (F s) apprα (G s).
We further extend this relation to functions F : ACon → ACon and G :
P(Con) → P(Con) as follows:
F apprα G ↔ ∀a ∈ ACon,C ⊆ Con : (a apprα C → (F a) apprα (G C)).
✷
Now we specify what we require of an abstraction.
Definition 3.2 (Abstraction) An abstraction comprises the following:
an abstract domain ACon, which is a complete lattice ordered by ±, and which has H, H, ⊥, and T, as meet, join, bottom, and top, respectively. This lattice is ordered by information content; we follow the usual convention in the abstract interpretation literature and put more information (greater certainty) lower in the lattice. 4
an abstract conjunction function ∧α : ACon → ACon → ACon.
a projection function project : P(Var) → ACon → ACon. This function is an abstraction of existential quantification
for each primitive constraint c ∈ Prim, an abstract constraint, which we denote cα. Recall that we always require = to be a primitive constraint, so there must always be an =α.	✷
We find it convenient to follow Nielson [6] in characterizing our abstract domain in terms of a representation function. We will define the needed ab- straction and concretization functions in terms of the representation function below.
Definition 3.3 We define a representation function β : Con → ACon which gives a maximally precise 5 abstraction for each concrete conjunction of con- straints as follows:



β c =
cα	when c ∈ Prim project v (β c')	when c = ∃v : c'
(β c') ∧α  (β c'')	when c = c' ∧ c''




4 The reason for this convention is that the concrete domain uses a standard subset ordering, which puts larger sets above smaller ones, and larger sets of solutions are usually abstracted to less certainty about the properties exhibited by all solutions.
5 Ideally, the abstract domain would have a unique most precise abstraction for each con-
crete conjunction of constraints, but we do not require this.


Now we may specify sufficient conditions for an abstract domain to guar- antee that our analysis will always produce a precise analysis.
Definition 3.4 (Precise abstraction) A precise abstraction is an abstrac- tion which satisfies the following constraints:
The abstract conjunction function must precisely approximate conjunction. That is,
∀c, c' ∈ Con : β (c ∧ c')= (β c) ∧α (β c')
must hold. We further require that ∧α distributes over finite and infinite joins, that is, for all (possibly infinite) A, A' ⊆ ACon,
HA ∧α  HA' = H{a ∧α a' | a ∈ A ∧ a' ∈ A'}.
These requirements of ∧α also in fact create requirements on the abstract primitive constraints.
The abstract projection function must precisely approximate existential quan- tification (project apprα ∃). That is,
∀V ⊆ Var,c ∈ Con : project V (β c)= β ( ∃V : C’).
In particular, this means that all of the following must hold:
∀Cα ∈ ACon,V ⊆ Var : vars(Cα) ∩ V = ∅ → project V Cα = Cα;
∀V ⊆ Var : project V ⊥ = ⊥;
∀Cα ∈ ACon,V ⊆ Var : vars(project V Cα) ∩ V = ∅
✷
Now we may define our abstraction and concretization functions in terms of our representation function.
Definition 3.5 From the representation function β, we define the needed concretization function γ : ACon → P(Con) and abstraction function α : P(Con) → ACon as follows:
γ a = {c ∈ Con | β c ± a} α C = H β c 
c∈C
✷
This characterization of α and γ give us the following result:
Theorem 3.6 α and γ form a Galois connection, with α the lower adjoint and γ the upper.	✷
Now we define an abstract semantics to be a function
ADen = Atom → ACon.


Finally we may define the abstract semantics of a program. Naturally, the definition is written subject to the choice of a precise abstraction, as specified in Definition 3.4 . All of the constructs of the abstraction are notionally parameters to the abstract semantic functions below, but we do not specify them as such to keep the definition manageable.
Definition 3.7 (Abstract semantic function) We specify the abstract se- mantics of a program as the result of the (goal independent) abstract semantic

function Psem, which we define in terms of the auxiliary functions Csem
and

α	α
Lsem:
Psem : Program → ADen
Csem : Clause → ADen → ADen
Lsem : Lit → ADen → ACon
These functions are defined as follows:
Psem P = lfp  H Csem C 

Csem C a A = project V   H=αA  ∧α	  Lsem L a 
where H ← B’ = rename C vars(A)
and V = vars(H) ∪ vars(B)

Lsem L a =  Lα	when L ∈ Prim
α	a L	when L ∈ Atom
✷
Given this, we wish to show that Psem apprα Psem, but first we must prove
a theorem and a lemma.
Theorem 3.8 For any sets C, C' ⊆ Con,
α (C ∧ C')= (α C) ∧α (α C')
✷
Lemma 3.9 The apprα relation on P(Con) × ACon, ordered componentwise, is admissible for fixed point induction.	✷
Now we are equipped to prove the main result of this section: that the abstract semantics given in Definition 3.7 , when applied to any abstraction satisfying Definition 3.4 , will always yield the most precise abstraction of any given program.
Theorem 3.10 Lsem apprα Lsem, Csem apprα Csem, and Psem apprα Psem.
α	α	α
Proof. First we prove Lsem apprα Lsem. Choose an arbitrary L ∈ Lit and d ∈
Den, and let a = α ◦ d. If L ∈ Prim, then we must show that α {L} apprα {L},

which obviously holds. If L ∈ Atom, then we must show that aL apprα d L, but since a = α ◦ d, this is obvious, too.
Now we show that since Lsem apprα Lsem, we also have Csem apprα Csem.
α	α
Choose an arbitrary C ∈ Clause, d ∈ Den, and A ∈ Atom, and let H ← B’ =
rename C vars(A) and V = vars(H) ∪ vars(B). We must show that
project V   H=αA  Λα	  Lsem L a  apprα EV  H = A Λ   Lsem L d 

Since we require that project apprα E and =α apprα = and Λα  apprα Λ, and

since we have shown that Lsem
apprα Lsem, together with the fact that bodies

are finite, Theorem 3.8 tells us that this must hold.
Finally we show that Psem apprα Psem. Choose an arbitrary program P and atom A; we must show that
Psem P A apprα Psem P A.
This will hold when
lfp  H Csem C  A apprα lfp  H Csem C  A.
C∈P	C∈P
Since by Lemma 3.9 apprα is admissible for fixed point induction, and since
Csem apprα Csem, this must hold.	✷

Related Work
The earliest formal semantics for logic programs was the ł semantics of van Emden and Kowalski [7]. This semantics expresses the denotation as the set of ground atoms entailed by the program. The £ semantics of Falaschi et al. [8] is a non-ground variation on the ł semantics and so, unlike ł se- mantics, is suitable where groundness of solutions is of interest. Marriott and Søndergaard [9] propose using a set of existentially-quantified conjunctions of equations, which is nicely generalized by Garc´ıa de la Banda et al. [10] to a set of existentially-quantified conjunctions of primitive constraints, without further restricting what may serve as a primitive constraint, and without spec- ifying how primitive constraints are to be interpreted. This is the approach we have adopted.
Probably the earliest work on analysis of logic programs was done by War- ren [11] in the context of the first Prolog compiler; however, the analyses intro- duced there were strictly local to a single clause. The first global static analysis system, introduced by Mellish [12], was designed to infer mode declarations for Prolog predicates, as well as finding sharing among program variables. At about the same time, Søndergaard [13] applied abstract interpretation to find unifications in a program which could safely be performed without an occur-

check. This analysis captured groundness, sharing, and linearity information about program variables.
The first to suggest an abstract interpretation framework for logic pro- gramming — the first to abstract the analysis domain from the analysis mech- anism — were Jones and Søndergaard [14], extended and refined by Marriott, Søndergaard, and Jones [9].
Bruynooghe [15] proposes a rather different approach, based on an opera- tional semantics. Bruynooghe conceives of a concrete computation as building

an and-or
tree. To avoid constructing infinite
and-or
trees, finite cyclic

graphs, closely related to rational trees, are used to approximate infinite and- or trees. Nilsson [16] replaces the use of and-or trees with context vectors, which associate a set of possible substitutions with each point in the program. This neatly avoids any difficulties with infinite and-or trees.
Le Charlier and Van Hentenryck [17] present another abstract interpreta- tion framework for logic programs, which they call GAIA. This is a top-down goal-dependent analyzer which uses tabling to avoid recomputation. Garc´ıa de la Banda and Hermenegildo [18] present a similar framework, called PLAI, which is more general in that it is designed to handle constraints other than just equality on Herbrand terms.
Gallagher et al. [19] present a goal-independent analysis framework based on a declarative semantics. This technique is based upon a pre-interpretation of the program, that is a mapping from the function symbols of the program to a (possibly different) domain. The domain to which they map the function symbols of the program fills the role of the abstract domain, and the pre- interpretation mapping serves as a representation function.
Conclusions
We have formally defined the concept of a pure constraint logic programming system and given a denotation semantics which is independent of the choice of constraint domain. Based closely on this semantics, we have presented an abstract interpretation framework. Most significantly, we have shown that when the abstract domain’s abstract conjunction and projection functions precisely approximate conjunction and existential quantification in the con- crete domain, the result provided by this abstract interpretation framework will be maximally precise. That is, no more precise abstraction will faithfully approximate the actual behavior of the program.
For more detail on this work, and for a discussion of goal-dependent anal- ysis using a similar framework, see Schachte [2].
References
P. Cousot, R. Cousot, Abstract interpretation: a unified lattice model for static analysis of programs by construction of approximation of fixpoints, in:


Conference Record of the 4th ACM Symposium on Principles of Programming Languages, Los Angeles, CA, 1977, pp. 238–252.
P. Schachte, Precise and efficient static analysis of logic programs, Ph.D. thesis, Dept. of Computer Science, The University of Melbourne, Australia (1999).
J. Jaffar, J.-L. Lassez, Constraint logic programming, in: Conference Record of the Fourteenth Annual ACM Symposium on Principles of Programming Languages, ACM Press, 1987, pp. 111–119.
W. v. O. Quine, Mathematical Logic, 2nd Edition, Harvard University Press, Cambridge, 1974.
R. Giacobazzi, S. Debray, G. Levi, Generalized semantics and abstract interpretation for constraint logic programs, Journal of Logic Programming 25 (3) (1995) 191–247.
F. Nielson, Two-level semantics and abstract interpretation, Theoretical Computer Science 69 (2) (1989) 117–242.
M. van Emden, R. Kowalski, The semantics of predicate logic as a programming language, Journal of the ACM 23 (4) (1976) 733–742.
M. Falaschi, G. Levi, M. Martelli, C. Palamidessi, A new declarative semantics for logic langauges, in: R. A. Kowalski, K. A. Bowen (Eds.), Proceedings of the Fifth International Conference and Symposium on Logic Programming, ALP, IEEE, The MIT Press, Seattle, 1988, pp. 993–1005.
K. Marriott, H. Søndergaard, N. Jones, Denotational abstract interpretation of logic programs, ACM Transactions on Programming Languages and Systems 16 (3) (1994) 607–648.
M. Garc´ıa de la Banda, K. Marriott, P. Stuckey, H. Søndergaard, Differential methods in logic program analysis, Journal of Logic Programming 35 (1) (1998) 1–37.
D. H. D. Warren, Implementing Prolog — compiling predicate logic programs,
D.A.I. Research Report 39, 40, University of Edinburgh (1977).
C. Mellish, Some global optimizations for a Prolog compiler, Journal of Logic Programming 2 (1) (1985) 43–66.
H. Søndergaard, An application of abstract interpretation of logic programs: Occur check reduction, in: B. Robinet, R. Wilhelm (Eds.), Proceedings of ESOP 86, Vol. 213 of Lecture Notes in Computer Science, Springer-Verlag, Berlin, 1986, pp. 327–338.
N. Jones, H. Søndergaard, A semantics-based framework for the abstract interpretation of PROLOG, in: S. Abramsky, C. Hankin (Eds.), Abstract Interpretation of Declarative Languages, Computers and Their Applications, Ellis Horwood, 1987, Ch. 6, pp. 123–142.


M. Bruynooghe, A practical framework for the abstract interpretation of logic programs, Journal of Logic Programming 10 (1–4) (1991) 91–124.

U. Nilsson, Towards a framework for the abstract interpretation of logic programs, in: P. D. et al. (Ed.), Programming Language Implementation and Logic Programming, no. 348 in Lecture Notes in Computer Science, Springer- Verlag, Berlin, 1988, pp. 68–82.

B. Le Charlier, P. Van Hentenryck, Experimental evaluation of a generic abstract interpretation algorithm for PROLOG, ACM Transactions on Programming Languages and Systems 16 (1) (1994) 35–101. URL http://www. acm.org/pubs/toc/Abstracts/0164-0925/174627.html

M. Garc´ıa de la Banda, M. Hermenegildo, A practical approach to the global analysis of CLP programs, in: D. Miller (Ed.), Logic Programming: Proceedings of the 1993 International Symposium, MIT Press, Vancouver, Canada, 1993, pp. 437–455.

J. Gallagher, D. Boulanger, H. Sagˇlam, Practical model-based static analysis for definite logic programs, in: Logic Programming: Proceedings of the 1995 International Symposium, The MIT Press, Portland, Oregon, USA, 1995, pp. 351–368.


A	Proofs of Theorems
Proof of Theorem 2.2 :
Proof.
This follows immediately from our definition of Λ : P(Con) → P(Con) →
P(Con).
Required by Axiom 2.1 (i) and (ii).
This is a basic property of set union.
This is a basic property of set union.
This follows from our definition of Λ.
This is basic property of set union.
This follows immediately from our definition of E : P(Var) → P(Con) →
P(Con).
Choose a sequence of variables V containing all and only the variables of V , without repetition, and choose a sequence of variables V ' such that V ' is disjoint with V and the variable of C and C', and V ' contains no repeats. By Axiom 2.1 (v), we know that EV ' : C' [V '/V ] ≡ EV : C',

and further, we know that V ∩ vars(C' [V /V ]) = ∅. Therefore,
EV : (C Λ EV : C') ≡ EV : (C Λ EV ' : C' [V '/V ])
≡ (EV : C) Λ (EV ' : C' [V '/V ])
≡ (EV : C) Λ (EV : C' [V '/V ] [V /V '])
≡ (EV : C) Λ (EV : C')
≡ (EV ' : C [V '/V ]) Λ (EV : C')
≡ EV : ((EV ' : C [V '/V ]) Λ C')
≡ EV : ((EV : C [V '/V ] [V /V ']) Λ C')
≡ EV : ((EV : C) Λ C')
This follows from our definition of E.
This follows from our definition of E.
This follows from Axiom 2.1 (vi).
This follows from Axiom 2.1 (vi).
This follows from Axiom 2.1 (vii).
This follows from Axiom 2.1 (viii).	✷
Notice that we have not used Axiom 2.1 (i) in this proof. It is in fact not necessary that Λ be commutative or absorptive; we require them because they are properties we naturally expect of a logic programming system.
Proof of Theorem 3.6 :
Proof. We must show that
∀C ⊆ Con : C ⊆ γ (α C); and
∀A ∈ ACon : α (γ A) ± A. We prove these points in turn.
Expanding the definitions of α and γ, we must show:
∀C ⊆ Con : C ⊆ {c ∈ Con | β c ±	β c'}.
c'∈C
Choose an arbitrary C ⊆ Con. We must show that
∀c ∈ C : β c ±	β c'.
c'∈C
But this is an inherent property of least upper bounds.
Expanding the definitions of α and γ, we must show:
∀A ∈ ACon :  H{β c | c ∈ Con Λ β c ± A}  ± A.
Choose an arbitrary A ∈ ACon and consider the set on the left side of

the inequality. This is a set all of whose elements are ± A. Clearly the least upper bound of this set must also be ± A.	✷
Proof of Theorem 3.8 :
Proof.
α (C Λ C')= α {c Λ c' | c ∈ C Λ c' ∈ C'}	(defn. of cross conjunction)
= H{β (c Λ c') | c ∈ C Λ c' ∈ C'}	(definition of α)
= H{(β c) Λα (β c') | c ∈ C Λ c' ∈ C'} (Λα is precise)
=  H β c  Λα  Hc' ∈ C'β c'	(Λα distributes over joins)
= (α C) Λα (α C')	(definition of α)
✷
Proof of Lemma 3.9 :
Proof. Take C to be an arbitrary chain in P(Con) × ACon such that ∀ ⟨a, s⟩∈ C : aapprαs, and take ⟨a0, s0⟩ = HC. We must show that a0apprαs0. Naturally, a0 = H{a | ⟨s, a⟩ ∈ C} and s0 = H{s | ⟨s, a⟩ ∈ C}, so we need only show that α s0 = a0. This follows from the fact that α is a lower adjoint, shown in
Theorem 3.6 , and is therefore continuous.	✷
