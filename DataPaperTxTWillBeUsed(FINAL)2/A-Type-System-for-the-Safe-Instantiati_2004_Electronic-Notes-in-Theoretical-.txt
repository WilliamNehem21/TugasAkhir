 Electronic Notes in Theoretical Computer Science 97 (2004) 197–217 
www.elsevier.com/locate/entcs




A Type System for the Safe Instantiation of Components 1
Marc Bezem 2 and Hoang Truong 3
Institute for Informatics University of Bergen
PB.7800, 5020 Bergen, Norway

Abstract
Component composition can lead to multiple instances of the same component. Some components can have only one instance loaded at a time, for example, when a unique external resource is used. We give an abstract component language and a type system ensuring the safe instantiation of components. Language features are instantiation, composition and a simple scope mechanism for discharging instances.
Keywords: Type theory, component software, program correctness.


Introduction
Imagine a computer program composed from several components. These com- ponents, possibly purchased from different vendors, may use other compo- nents, which on their turn use other components, and so on. In order to analyze this process, the phrase ‘to use a component’ is somewhat too loose and we prefer to speak of ‘to create an instance of a component’, usually denoted by the primitive new c , where c denotes the component in question.
The semantics of new c is, roughly, the allocation of the resources to run an
instance of c. This does not only mean allocating memory space for c’s data

1 This research is supported by the Research Council of Norway (NFR).
2 Email: bezem@ii.uib.no
3 Email: hoang@ii.uib.no


1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.04.037

structures and the like, but this also means creating instances of the compo- nents used by c. (The exact moment on which instances of subcomponents are created depends on the binding regime, see [15].)
In the situation sketched above it can easily happen that, unforseen by the composer, different instances of the same component are created. For many components this is no problem at all. However, there exist components which do not allow multiple instances running side-by-side [4,10], for example, in case the component uses a unique external resource like a printer or serial output device or in case the component is a centralized function such as issuing serialized ID numbers [7]. In [10], Meijer points out that the only option for all but the first request to multiple versions of a component that cannot exist side-by-side, is to fail. The single instance property of component can be controlled by the component implementation itself using the singleton pattern [7]. However, in component software, the context in which a component will be used should not be anticipated completely, therefore there are cases we need to control the number of instances of a particular component on a higher level[5]. The aim of this paper is to develop a type system which allows one to
detect statically, at development/composition time, whether or not multiple
instances of certain components are running side-by-side.
For this purpose we have designed a rudimentary component language where we have abstracted away many aspects of components. The main fea- tures we have retained are instantiation, (sequential) composition and scope. On this abstraction level there is little difference between components and classes on one hand, and instances and objects on the other. Please keep in mind that we report on ongoing research here: more sophisticated language features will be included in the near future.
The simple binding mechanism for components used here bears similarity to let binding in functional languages such as ML [11], and hence to lambda abstraction and application. However, the types used here are completely different. To some extent it turned out to be possible to develop our type theory along the lines of so-called Pure Type Systems (PTSs), see [3]. This increased our confidence in the abstractions chosen and can be viewed as a tribute to the generality of PTSs.
There are several works on type systems for components, see e.g. [14,16]. However, they do not address the issue of single instantiation of components.
The intuition behind our types bears some similarity to so-called linear types [2,6]. Linear types usually express that a value will be used exactly once within its scope, as opposed to at most once in our case. This difference is reflected in our Weakening and Start rules (see below). Nevertheless, the
possible connection with linear types must still be explored.

This paper is organized as follows. In the next section we develop the component language with its terms and operational semantics. We define types and typing relation in Section 3. Then we prove some properties of the type system in Section 4. We outline a polynomial time type inference algorithm in Section 5 before ending with some conclusions and indications of future research. Technical proofs are delegated to the appendix.

A component language
Terms
Since we are mainly interested in instantiation, composition and scope, we have abstracted in our component language from all other aspects of com- ponents. At this level of abstraction we do not detail how components are connected as in many architecture description languages like Wright [1], Dar- win [9], SADL [12], and ACME [8].
A component may or may not allow multiple instances running side-by- side. We distinguish between these two kinds of components by using two disjoint sets S and E for such ‘side-by-side’ and ‘exclusive’ components, re- spectively. So, a component in S can have arbitrarily many instances, while a component in E can have at most one instance at a time.
We use extended Backus-Naur Form with the following meta-symbols: ϵ for the empty expression, infix | for choice, postfix ∗ for Kleene closure (zero or more iterations) and round brackets for grouping. The curly brackets { and
} are part of the component language and are used as scope-delimiters.
Definition 2.1 [Component programs] The component programs are given by the following abstract syntax, with x ranging over S ∪ E.
Prog ::= Decl; Exp Decl ::= (x−≺ Exp)∗
Exp  ::= ϵ | new x Exp | {Exp}Exp

The above grammar for expressions Exp generates the same expressions as Exp ::= ϵ | new x | Exp Exp | {Exp} but has the technical advantage of non-ambiguity.
Thus a program consists of a list of so-called component declarations fol- lowed by an expression Exp which sparks off the execution. For a precise definition of the operational semantics the reader is referred to the next sec- tion. In particular the example there will help to elucidate the typing rules

that are to follow.
A component declaration x−≺ Exp states that the component x is composed from the component expression Exp. In particular, x−≺ ϵ states that x is a primitive component. A list of declarations with distinct variables is called a basis, as in PTSs [3]. We use Γ, ∆,... to range over bases.
According to the above syntax, component expressions can have several forms. The simplest, the empty expression ϵ is used for declaring primitive components. Otherwise, expressions can be a sequence of new x ’s with or without matching, possibly nested, scope-delimiters. The purpose of putting components in a scope is that, during their lifetime, these components need to collaborate with each other and can be deallocated afterwards. We use A,... , E, Exp to range over expressions.
A program is deterministic if there is at most one declaration of every component. In this paper we only work with deterministic programs.
As an example, let S = {c, d} and E = {a, b}. A well-formed program
Prog in our syntax could be as follows:

d−≺ ϵ
a−≺ new d b−≺ new a
c−≺ new d {new b new d }new a ;
new c

We will return to this example in the following sections.


Operational semantics
In this section we give the operational semantics for our language. We use so-called post-expressions, which are obtained by deleting zero or more con- secutive opening {’s in the prefix of an expression.

Definition 2.2 [Post-expressions] The post-expressions are given by the ab- stract syntax P ::= (Exp})∗Exp, with Exp as in Definition 2.1:

We also give a formal definition of concatenation of two expressions.

Definition 2.3 [Expression concatenation] The concatenated expression of

two expressions A and B, written A@B, is defined recursively as follows:

ϵ@B	= B
(new x A1)@B = new x (A1@B) ({A1}A2)@B = {A1}(A2@B)
Concatenation of an expression with a post-expression is defined in the same way as concatenation of two expressions, and results in again a post- expression.
The operational semantics is modelled as a transition system where a state is a stack S of multisets followed by a post-expression P . Stacks and post-
expressions are separated by ’ ∝ ’. Elements of the stack are separated by ‘:’. Stacks are pushed and popped at the right end. The empty stack is denoted by ∅. When the depth of stack is at least one, we use the multiset M to denote the top of the stack and S to denote the rest of the stack. When the depth of a stack is one, we write just the multiset M, as in the second transition rule below.  Multisets are denoted by [.. .], where sets are denoted, as usual, by
{.. .}. M(x) is the multiplicity of element x in multiset M. The operation 
is additive union of multisets.
Definition 2.4 [Transition rules] The transition rules are given as follows:

∅ ∝ P	terminate→	f ailure
M  ∝ ϵ	terminate→	success
S : M : M ' ∝ ϵ	terminate→	f ailure
S : M  ∝ new xP	x−≺E ∈ Prg→	S : (M  [x])  ∝ E@P
S : M  ∝ { P	push→	S : M : [ ]  ∝ P
S : M  ∝ } P	pop→	S  ∝ P

The transition rules can be explained as follows. When the stack is empty the transition process terminates to failure. When the input is ϵ, the transition process also terminates. In this case, if the depth of the stack is one, the program succeeds, else it fails. When the input is new x , x is added to the multiset at the top of the stack and new x is replaced by the declaration of x. The last two rules are for scope. When entering a new scope, that is, when
the first element of the input is ‘{’, we push a new empty multiset [ ] to the stack. When leaving a scope, that is, when the first element of the input is ‘}’,

the multiset at the top of the stack is popped. This means that all instances created in this scope have been discarded.
The example in Section 2.1 is again used to illustrate our operational se- mantics. The transition steps are showed as follows:

[]  ∝ new c	c−≺new d {new b new d }new a→
[c]  ∝ new d {new b new d }new a	d−≺→є
[c, d]  ∝ {new b new d }new a	pus→h
[c, d] : [ ] ∝ new b new d }new a	b−≺new a→ [c, d] : [b] ∝ new a new d }new a a−≺new d→ [c, d] : [a, b] ∝ new d new d }new a	d−≺→є [c, d] : [a, b, d] ∝ new d }new a d−≺→є
[c, d] : [a, b, d, d] ∝ }new a  po→p
[c, d] ∝ new a  a−≺new d→
[a, c, d] ∝ new d  d−≺→є

[a, c, d, d] ∝ ϵ  terminat→e
success


In this example, exclusive component a is instantiated two times. However, for reason of scope, there is at most one instance of a at each moment.
If d had been exclusive, the execution of program would fail at [c, d] : [a, b], new d new d }new a . Continuing loading would duplicate exclusive com- ponent d.

Type system
Types
A component expression E may use several components. Among the latter there are instances that exist for the whole lifetime of E, whereas other in- stances live only for a while and are then discharged. Therefore we use two sets to represent the type of a component expression. The first set Xi col- lects all components instantiated during the lifetime of the expression and the second set Xo consists of those components that have instances surviving the execution of the expression.
Definition 3.1 [Types] The set of types for component expressions consists



of pairs of sets

Xi|Xo

where Xo,Xi ⊆ S ∪ E. Types are denoted by super- and subscripted capitals
U,..., Z.

Typing relation
Before defining the typing relation we give a formal definition of domain, the set of variables in a basis.
Definition 3.2 [Basis variables] The set of declared variables in basis Γ, writ- ten Dom(Γ), is defined inductively as follows:

Dom()	= ∅
Dom(x−≺ A, Γ) = {x}∪ Dom(Γ) For example suppose
Γ = d−≺ ϵ, a−≺ new d, b−≺ new a, c−≺ new d {new b new d }new a
then we have
Dom(Γ) = {a, b, c, d}
A typing triple Γ ▶ A : Xi|Xo, also called typing for short, expresses that, given basis Γ, the component expression A has type Xi|Xo. The typing relation is an inductively defined set of typing triples. It is defined in the usual way by giving typing rules to construct derivation trees for valid typings.
Definition 3.3 [Typing rules]

Axiom
▶ ϵ : ∅|∅
Γ ▶ A : Xi|Xo
Start Γ, x−≺ A ▶ new x : Xi ∪ {x}|Xo ∪ {x} x ∈/ Dom(Γ)
Γ ▶ A : Xi|Xo	Γ ▶ A1 : Y i|Y o

Weakening
Γ, x−≺ A1 ▶ A : Xi|Xo	x ∈/ Dom(Γ)

Sequencing
Γ ▶ new x : Xi|Xo	Γ ▶ A : Y i|Y o


Γ ▶ new xA : Xi ∪ Y i|Xo ∪ Y o
Xo ∩ E ∩ Y i = ∅,A /= ϵ

Scope
Γ ▶ A1 : Xi|Xo	Γ ▶ A2 : Y i|Y o


Γ ▶ {A1}A2 : Xi ∪ Y i|Y o

Let us briefly explain the above five typing rules. Rule Axiom requires no premise and is used to take-off. Rule Start allows us to type a new instance of a component. The combination of Axiom and Start allows us to type in- stances of primitive components x−≺ ϵ. Weakening is used to expand bases so that we can combine typings in rule Sequencing and Scope, which allow us to type component compositions with a prefix new x and a scoped expression, respectively. The side condition x ∈/ Dom(Γ) prevents ambiguity and circu- larity. The side condition Xo ∩ E ∩ Y i = ∅ prevents exclusive components from being instantiated more than once in the same scope.
Continuing the example in Section 2.1, we show the type derivation tree for {new b new d }new a . First, a typing for new b can be derived as follows: (The names of the typing rules are shortened to their first three letters.)



Sta
Axi


▶ ϵ : ∅|∅


Sta
Sta

d−≺ ϵ ▶ new d : {d}|{d}
d−≺ ϵ, a−≺ new d ▶ new a : {a, d}|{a, d}

d−≺ ϵ, a−≺ new d, b−≺ new a ▶ new b : {a, b, d}|{a, b, d}
The typing for new d can be weakened as follows:


Sta
Axi


▶ ϵ : ∅|∅

Sta
Axi


▶ ϵ : ∅|∅

W ea

d−≺ ϵ ▶ new d : {d}|{d}

d−≺ ϵ ▶ new d : {d}|{d}

d−≺ ϵ, a−≺ new d ▶ new d : {d}|{d}
Using this result we can derive yet another typing for new d by weakening:
...	...
Wea  d−≺ ϵ, a−≺new d ▶ new d : {d}|{d} d−≺ ϵ, a−≺new d ▶ new a : {a, d}|{a, d} 
d−≺ ϵ, a−≺ new d, b−≺ new a ▶ new d : {d}|{d}
Similarly, we can weaken the typing for new a :
d−≺ ϵ, a−≺ new d, b−≺ new a ▶ new a : {a, d}|{a, d}
Now, let Γ = d−≺ ϵ, a−≺ new d, b−≺ new a . Based on the previous typings we can derive a type for {new b new d }new a as follows:



Seq
...	...

 
Γ ▶ new b : {a, b, d}|{a, b, d} Γ ▶ new d : {d}|{d}

...

Sco
Γ ▶ new b new d : {a, b, d}|{a, b, d}
Γ ▶ new a : {a, d}|{a, d}

Γ ▶ {new b new d }new a : {a, b, d}|{a, d}
Note that the side condition Xo ∩ E ∩ Y i of rule Sequencing is satisfied since
d ∈/ E.

Having defined types, terms and typing rules, we can now define the notion of a well-typed program.
Definition 3.4 [Well-typed program] A well-formed program P = Decl; Exp is well-typed if Exp can be typed in a basis built from Decl. Here it is understood that the declarations may have to be reordered to form a legal basis.

Properties of the type system
In this section we will state some properties of our type system. The invariant theorem and its correctness corollary at the end of the section relate the type system to the operational semantics. In order to prove the invariant property some definitions and lemmas are needed. Some technical proofs of lemmas are delegated to Appendix A, to improve the readability of this section.
Definition 4.1 [Bases] Let Γ = x1−≺ A1,... , xn−≺ An be a basis and let A be an expression.
Γ is called legal if Γ ▶ A : Xi|Xo for some A, Xi, and Xo.
A declaration x−≺ A is in Γ, notation x−≺ A ∈ Γ, if x ≡ xi and A ≡ Ai for some i.
∆ is part of Γ, notation ∆ ⊆ Γ, if ∆ = xi1 −≺ Ai1 ,..., xik −≺ Aik with 1 ≤ i1 < ... < ik ≤ n. Note that the order is preserved.
∆ is an initial segment of Γ, notation ∆ ± Γ, if ∆ = x1−≺ A1,... , xj−≺ Aj
for some 1 ≤ j ≤ n.
Definition 4.2 [Expression variables] The set of variables occurring in an expression A, written V ar(A), is defined inductively as follows:

V ar(ϵ)	= ∅
V ar(new x A) = {x}∪ V ar(A)
V ar({A1}A2) = V ar(A1) ∪ V ar(A2)

For example, the set of expression variables of new d {new b new d }new a is:
V ar(new d {new b new d }new a ) = {a, b, d}

For convenience we shall abbreviate from now on X ∪ {x} by X+x and X \ {x} by X−x. The latter abbreviation will only be used in cases where actually x ∈ X.

The following lemma collects a number of easy properties of a typing. These will be frequently be used in the sequel. It states that if an expression A has type Xi|Xo in a basis Γ then the set of the variables of expression A is subset of the domain of Γ. Moreover, any legal basis always has its declarations distinct.
Lemma 4.3 (Legal basis properties) If Γ ▶ A : Xi|Xo, then V ar(A) ∪ Xo ⊆ Xi ⊆ Dom(Γ), Γ ▶ ϵ : ∅|∅, and every variable in Dom(Γ) is declared only once in Γ.
Proof (Sketch) By induction on derivation (full proof in Appendix A).	 
The next lemma allows us to find the last typing rule applied to derive the type of an expression and hence it allows us to recursively calculate the
types of well-typed expressions. We will return to this issue in Section 5, Type Inference. This lemma is sometimes called the inversion lemma of the typing relation [13].
Lemma 4.4 (Generation)
If Γ ▶ new x : Xi|Xo, then x ∈ Xo and there exists ∆, ∆', A such that
Γ = ∆, x−≺ A, ∆', and ∆ ▶ A : Xi−x|Xo−x.
If Γ ▶ new xA : Zi|Zo with A /= ϵ, then there exists Xi, Xo, Y i, Y o such that Γ ▶ new x : Xi|Xo, Γ ▶ A : Y i|Y o, Zi = Xi ∪ Y i, Zo = Xo ∪ Y o, and Xo ∩ E ∩ Y i = ∅.
If Γ ▶ {B}C : Zi|Zo, then there exists Xi, Xo, Y i, Y o such that Γ ▶ B :
Xi|Xo, Γ ▶ C : Y i|Y o, Zi = Xi ∪ Y i, Zo = Y o.
Proof (Sketch) All three items are proved by induction on derivation (full proof in Appendix A).	 
In our type system the order of declarations in a legal basis is significant. The initial segment ∆ of a legal basis Γ is a legal basis for the expression of the consecutive declaration after ∆. Besides, because of the weakening rule, there can be many legal bases under which a well-typed expression can be derived. These properties are stated in the following lemma.
Lemma 4.5 (Legal monotonicity)
If Γ = ∆, x−≺ A, ∆' is legal, then ∆ ▶ A : Xi|Xo for some Xi and Xo.
If Γ ▶ A : Xi|Xo, Γ ⊆ Γ' and Γ' is legal, then Γ' ▶ A : Xi|Xo.
Proof (Sketch)
The only way to extend ∆ to ∆, x−≺ A in a derivation is by applying the rule Start or Weakening. Each of the rules has ∆ ▶ A : Xi|Xo as a

premise.
By induction on the derivation of Γ ▶ A : Xi|Xo (see Appendix A).

The following lemma can be viewed as the inverse of the previous legal monotonicity lemma. Under certain conditions we can contract the legal basis so that the expression is still well-typed in the new basis.
Lemma 4.6 (Strengthening) If Γ, x−≺ A ▶ B : Y i|Y o and x ∈/ V ar(B), then Γ ▶ B : Y i|Y o and x ∈/ Y i.
Proof (Sketch) By induction on derivation (full proof in Appendix A).	 
In our simple type system, every term has a unique type if it has a type at all. This property is stated and proved in the following proposition.
Proposition 4.7 (Uniqueness of types) If Γ ▶ A : Xi|Xo and Γ ▶ A :
Y i|Y o, then Xi = Y i and Xo = Y o.
Proof. By induction on the derivation of Γ ▶ A : Xi|Xo.
Base step: In the case of Axiom we have A = ϵ and Γ is empty, so that only Axiom is applicable. Hence, Xi = Y i = ∅ and Xo = Y o = ∅.
Induction step:
Case Start: Let Γ = Γ', x−≺ B such that:
Γ' ▶ B : Xi−x|Xo−x

Start


Γ', x−≺ B ▶ new x : Xi|Xo
x ∈/ Dom(Γ')

with x ∈ Xi and x ∈ Xo. Assume Proposition 4.7 holds for the premise and let Γ ▶ new x : Y i|Y o. By Generation Lemma we have x ∈ Y o and Γ = ∆1, x−≺ C, ∆2 and ∆1 ▶ C : Y i−x|Y o−x for some ∆1, ∆2, C.
By Lemma 4.3, there is only one declaration of x in Γ.  This means
∆1 = Γ', C = B and ∆2 is empty, so Γ' ▶ B : Y i−x|Y o−x. By IH we have Xi−x = Y i−x, Xo−x = Y o−x. So Xi = Y i, Xo = Y o as by Lemma 4.3 also x ∈ Y o.
Case Weakening: Let Γ = Γ', x−≺ B such that:
Γ' ▶ A : Xi|Xo	Γ' ▶ B : Zi|Zo

Weakening
Γ', x−≺ B ▶ A : Xi|Xo
x ∈/ Dom(Γ'),B /= ϵ

Assume Proposition 4.7 holds for the two premises and let Γ = Γ', x−≺ B ▶

A : Y i|Y o.  Since Γ' ▶ A : Xi|Xo we have x ∈/
V ar(A).  By Lemma 4.6

applied to Γ', x−≺ B ▶ A : Y i|Y o we get Γ' ▶ A : Y i|Y o. By IH we have the conclusion Xi = Y i and Xo = Y o.

Case Sequencing: Let Γ ▶ new xB : Xi|Xo with B /= ϵ be inferred by:
Γ ▶ new x : V i|V o	Γ ▶ B : Wi|Wo

Sequencing
Γ ▶ new xB : V i ∪ Wi|V o ∪ Wo
V o ∩ E ∩ Wi = ∅,B /= ϵ

By Generation Lemma 4.4 applied to Γ ▶ new xB : Y i|Y o we have Γ ▶
new x : V i|V o, Γ ▶ B : Wi|Wo, Y i = V i ∪ Wi, and Y o = V o ∪ Wo for some
1	1	1	1	1	1	1	1
V i, V o, Wi, Wo. By the IH, we have V i = V i, V o = V o, Wi = Wi, and
1	1	1	1	1	1	1
Wo = Wo. Hence, Xi = Y i = V i ∪ Wi and Xo = Y o = V o ∪ Wo follow.
Case Scope: analogous to case Sequencing.


The following lemma plays a role in the invariant of the operational se- mantics. If we replace a component new x in a well-typed expression by the declaration of x in the typing basis, then the new expression is again well-typed in the same basis.
Lemma 4.8 (Substitution) Suppose Γ ▶ new xB : Zi|Zo, then
x−≺ A ∈ Γ and Γ ▶ A : Xi|Xo for some A, Xi, and Xo.
Γ ▶ B : Y i|Y o for some Y i and Y o.
Γ ▶ A@B : Xi ∪ Y i|Xo ∪ Y o.
Proof. In Appendix A.	 
Now, we give some definitions before stating the invariant theorem and correctness corollary for our type system. In the rest of this section, we assume that we are working with some well-typed program Prog and two disjoint sets S and E of side-by-side and exclusive components, respectively.
Definition 4.9 [Single multiset, projection]
A multiset M is single if the multiplicity of every element of M is 1. Thus, a single multiset is a set and set operations apply.
The projection of a multiset M by a set E, notation M|E, is the multiset obtained by removing from M all elements that are not in E:


(M|E
)(x) =  M(x)  if x ∈ E
 0	otherwise

Definition 4.10 [Stack union projection] Suppose we have a stack of multi- sets S = S1 : ... : Sn. The multiset of exclusive elements in stack S, written

S|E, is defined as follows:
S|E = (S1	 Sn)|E
Theorem 4.11 (Invariant) Let Γ be a basis. Assume stack S = S1 : ... : Sn
with S|E single, and expressions Aj with Γ ▶ Aj : Xi|Xo for all 1 ≤ j ≤ n,
j	j
such that
(S1 : .. : Sk)|E ∩ Xi = ∅	for all	1 ≤ k ≤ n	(1)
Then, either we have termination or there exists a unique stack S' = S' : ... :

S' with S'|E single, and unique expressions Bj with Γ ▶ Bj : Y i|Y o
for all

m	j	j
1 ≤ j ≤ m , such that
S ∝ An}An−1 .. .}A1 → S' ∝ Bm}Bm−1 .. .}B1


and
(S' : ... : S' )|E ∩ Y i = ∅	for all	1 ≤ k ≤ m	(2)

1	k	k
Proof. By examining all possible transitions.
If An = ϵ and n = 1, then the transition terminates.
If An = ϵ and n > 1, then the transition step is:


S1 : ... : Sn  ∝ }An−1 .. .}A1  po→p
S1 : ... : Sn−1  ∝ An−1} .. .}A1

All the conclusions follow immediately since m = n − 1.
If An = new x , by Generation Lemma, we have x−≺ A' ∈ Γ. Then, the transition step is:
S : ... : S	∝ new x }A	.. .}A	x−≺A'∈→Γ
S1 : ... : (Sn  [x]) ∝ A'}An−1 .. .}A1
We have m = n, Bm = A', and Bj = Aj for 1 ≤ j ≤ n − 1.  Thus, Γ ▶ Bj : Xi|Xo follows immediately for 1 ≤ j ≤ m − 1. Γ ▶ Bm : Y i |Y o
j	j	m  m
also follows from Lemma 4.4 applied to Γ ▶ new x : Xi |Xo by taking
m	m
Y i = Xi −x and Y o = Xo −x.
m	m	m	m
Equation (2) holds for k ≤ m−1 by assumption and we only have to prove
Equation (2) for k = m. If x ∈/ E, the proof is trivial since (S' : ... : S' )|E =
1	n

(S' : ... : S' )|E and Y i ⊆ Xi . Otherwise, since Y i
= Xi −x, so x ∈/ Y i .

1	m	m	m
m	m	m

By Equation (1) with k = n and x ∈ Xi we have x ∈/ (S1 : ... : Sn). Hence,

(S' : ... : S' )|E∩Y i
= ∅ holds as the new exclusive variable x only occurs in

1	m	m
the left of intersection operation. The conclusion S'|E single also follows as

there is only one new x ∈ S' and x ∈/ (S1 : .. : Sn−1)|E = (S' : .. : S'
)|E.

m	1	m−1

If An = new xC with C /= ϵ, then the transition step is:
S : ... : S	∝ new x C}A	.. .}A	x−≺A'∈Γ→
S1 : ... : (Sn  [x])  ∝ A'@C}An−1 .. .}A1
We have m = n, Bn = A'@C, and Bj = Aj for 1 ≤ j ≤ n − 1. Thus, Γ ▶
Bj : Y i|Y o follows immediately for 1 ≤ j ≤ n − 1. Γ ▶ A'@C : Y i|Y o also
j	j	n	n
follows from Lemma 4.8 applied to Γ ▶ new xC : Xi |Xo . The remaining
m	m
proof is analogous to the previous case.
If An = {C}D, then the transition step is:

S1 : ... : Sn  ∝ {C}D}An−1 .. .}A1  pus→h
S1 : ... : Sn : [ ]  ∝ C}D}An−1} .. .}A1
We have m = n + 1, Bm = C, Bn = D and Bj = Aj with 1 ≤ j ≤

n − 1.  Thus, Γ ▶ Bj : Y i|Y o
follows immediately for 1 ≤ j ≤ n − 1.

j	j
Γ ▶ Bm : Y i |Y o and Γ ▶ Bn : Y i|Y o also follow from Lemma 4.4 applied to
m  m	n  n
Γ ▶ {C}D : Xi |Xo . The remaining conclusions follow trivially.
m	m

Corollary 4.12 (Correctness) Starting with the stack [ ], containing only the empty multiset, and a well-typed expression, S|E is single in every consec- utive state, that is, of every exclusive component there is at most one instance at a time.
Proof. Follows from iterating the previous theorem starting with n = 1. 

Type inference
In this section we sketch a polynomial time type inference algorithm. The type inference problem, or more precisely, an instance of this problem, is to determine, given basis Γ and expression A, a type Xi|Xo such that Γ ▶ A : Xi|Xo. By Proposition 4.7 we know that such a type is unique if it exists. Inferring such types automatically relieves the programmer from the task to give the types explicitly and have them checked. The types inferred can be expected to guide the design of the component program. Moreover, by the correctness result Corollary 4.12, a well-typed expression can be safely executed. The latter could also be tested by running the operational semantics according to the rules in Definition 2.4. However, running these rules could be exponential (by iterated duplication, for example), so that a polynomial time type inference algorithm is to be preferred.

Let Prog be a component program. A necessary (but not sufficient) con- dition for type inference is that the declarations in Prog can be reordered into a basis Γ such that, for any declaration x−≺ A in Γ, the variables occurring in A are already declared previously in Γ. In other words:

if Γ = ∆, x−≺ A, ∆' then V ar(A) ⊆ Dom(∆)	(3)

The existence of such a reordering can be detected in polynomial time by an analysis of the dependency graph associated with the declarations in Prog. From now on we assume that Γ is a basis consisting of all declarations in Prog and satisfying (3). The considerations below are independent of which particular ordering is used as long as it satisfies (3).
The basic idea behind the type inference algorithm is to exploit the fact that the typing rules are syntax-directed, or, in other words, to use the Gen- eration Lemma 4.4 reversely. By applying clause 2 and 3 of this lemma to expression of the forms new xA with A /= ϵ and {B}C, respectively, we can break down any instance of the type inference problem to instances where the expression is simply of the form new x . We can then look up the declaration of x in the basis Γ. If no declaration of x can be found then no type can be inferred. Otherwise Γ = ∆, x−≺ A, ∆' for some ∆, ∆' and A and clause 1 of the Generation Lemma allows us to reduce the problem to inferring the type of A in ∆, together with the additional task of checking if ∆' legally ex- tends ∆, x−≺ A. Here some care has to be taken in order to stay polynomial. A naive recursive algorithm could behave exponentially by generating recursively duplicate instances of the same type inference problem. Duplication can, how- ever, be avoided by storing solved instances. Observe that all instances are of the form: infer the type of A in ∆, where ∆ is an initial segment of the basis of the original type inference problem and A is a sub-expression of one of its constituents. There are polynomially many of such instances and hence type inference can be done in polynomial time. This finishes the sketch. We hope finally to be able to infer types in cubic or even quadratic time.

Conclusions and future research
We have designed a component language and a type system which allows one to detect statically whether or not multiple instances of certain components are running side-by-side. The language features instantiation, (sequential) composition and scope. For the future we plan to include more sophisticated language features such as explicit dispose operators, connectivity, concurrency features and versioning.

References
R. Allen and G. Garlan. Formalizing Architectural Connection. In Proceedings of the Sixteenth International Conference on Software Engineering, Sorrento, Italy, May 1994.
H. Baker. ’Use-Once’ Variables and Linear Objects – Storage Management, Reflection and Multi-Threading. ACM SIGPLAN Notices 30, January 1995.
H. Barendregt. Lambda Calculi with Types. In: Abramsky, Gabbay, Maibaum (Eds.), Handbook of Logic in Computer Science, Vol. II. Oxford University Press. 1992.
D. Box and C. Sells. Essential .NET, Volume I: The Common Language Runtime, Addison- Wesley, ISBN 0201734117, November 2002.
J. Cheesman and J. Daniels, UML Components: A Simple Process for Specifying Component- Based Software, Addison-Wesley, ISBN 0201708515, 2000.
M. F¨ahndrich and R. DeLine. Adoption and Focus: Practical Linear Types for Imperative Programming, Proceedings of the SIGPLAN’02 Conference on Programming Language Design and Implementation, Jun 2002.
E. Gamma, R. Helm, R. Johnson, and J. Vlissides. Design Patterns - Elements of Reusable ObjectOriented Software, Addison-Wesley, Reading, Mass., ISBN 0201633612, 1994.
D. Garlan, R. Monroe, and D. Wile. ACME: An Architecture Description Interchange Language. In Proceedings of CASCON’97, November 1997.
J. Magee, N. Dulay, S. Eisenbach, and J. Kramer. Specifying Distributed Software Architectures. In Proceedings of the Fifth European Software Engineering Conference (ESEC95), Barcelona, September 1995.
E.  Meijer  and  C.  Szyperski.  Overcoming  Independent  Extensibility  Challenges,
Communications of the ACM, Vol. 45, No. 10, pp. 41–44, October 2002.
R. Milner et alii. The Definition of Standard ML (Revised), MIT Press, ISBN 0262631814, 1997.
M. Moriconi, X. Qian, and R. A. Riemenschneider. Correct Architecture Refinement. IEEE Transactions on Software Engineering, April 1995.
B. Pierce. Types and Programming Languages. MIT Press, ISBN 0262162091, February 2002.
J. C. Seco and L. Caires, A Basic Model of Typed Components, Lecture Notes in Computer Science, Vol. 1850, 2000.
C. Szyperski. Component Software: Beyond Object-Oriented Programming, 2nd edition, Addison-Wesley, ISBN 0201745720, 2002.
M. Zenger, Type-Safe Prototype-Based Component Evolution, Proceedings of the European Conference on Object-Oriented Programming, Malaga, Spain, June 2002.

A	Appendix
Lemma 4.3 (Legal basis properties)
If Γ ▶ A : Xi|Xo, then V av(A) ∪ Xo ⊆ Xi ⊆ Dom(Γ), Γ ▶ ϵ : ∅|∅, and every variable in Dom(Γ) is declared only once in Γ.
Proof. By induction on derivation.
Base case Axiom: ▶ ϵ : ∅|∅ is trivial as V av(ϵ) = Xo = Xi = Dom() = ∅.
Induction step: We have to consider four cases corresponding to the four typing rules.



Case Start:


Γ ▶ A : Xi|Xo
Stavt Γ, x−≺ A ▶ new x : Xi+x|Xo+x x ∈/ Dom(Γ)

Assume the lemma is correct for the premise of this rule, so V av(A)∪Xo ⊆ Xi ⊆ Dom(Γ), Γ ▶ ϵ : ∅|∅ and every variable is declared at most once in Γ. Then, V av(new x ) = {x} ⊆ Xo+x ⊆ Xi+x ⊆ Dom(Γ)+x = Dom(Γ, x−≺ A). Moreover, Γ, x−≺ A ▶ ϵ : ∅|∅ follows by applying Weakening:
Γ ▶ ϵ : ∅|∅	Γ ▶ A : Xi|Xo

Weakening
Γ, x−≺ A ▶ ϵ : ∅|∅
x ∈/ Dom(Γ)

The last conclusion: every variable in Γ, x−≺ A is declared at most once, follows by the side condition x ∈/ Dom(Γ).
Case Weakening:



Weakening
Γ ▶ A : Xi|Xo	Γ ▶ B : Y i|Y o
Γ, x−≺ B ▶ A : Xi|Xo	x ∈/ Dom(Γ)

Assume the lemma is correct for the two premises of this rule, so V av(A)∪ Xo ⊆ Xi ⊆ Dom(Γ), V av(B) ∪ Y o ⊆ Y i ⊆ Dom(Γ), Γ ▶ ϵ : ∅|∅ and every variable is declared at most once in Γ. We have V av(A) ∪ Xo ⊆ Xi ⊆ Dom(Γ) ⊆ Dom(Γ, x−≺ B). The last two conclusions are proved in the same way as in the case Start.
Case Sequencing:
Γ ▶ new x : Xi|Xo	Γ ▶ A : Y i|Y o

Sequencing
Γ ▶ new xA : Xi ∪ Y i|Xo ∪ Y o
Xo ∩ E ∩ Y i = ∅,A /= ϵ

Assume the lemma holds for the two premises of this rule, so V av(new x )∪ Xo ⊆ Xi ⊆ Dom(Γ), V av(A) ∪ Y o ⊆ Y i ⊆ Dom(Γ), Γ ▶ ϵ : ∅|∅ and every variable is declared at most once in Γ. Note that V av(new x A) = 
{x}∪ V av(A). We have V av(new x A) ∪ Xo ∪ Y o ⊆ Xi ∪ Y i ⊆ Dom(Γ). The
remaining conclusions are the IHs themselves.
Case Scope:

Scope
Γ ▶ A1 : Xi|Xo	Γ ▶ A2 : Y i|Y o


Γ ▶ {A1}A2 : Xi ∪ Y i|Y o

Assume the lemma holds for the two premises of this rule, so V av(A1) ∪ Xo ⊆ Xi ⊆ Dom(Γ), V av(A2) ∪ Y o ⊆ Y i ⊆ Dom(Γ), Γ ▶ ϵ : ∅|∅ and every variable is declared at most once in Γ. Note that V av({A1}A2) = 

V av(A1) ∪ V av(A2). We have V av({A1}A2) ∪ Y o ⊆ Xi ∪ Y i ⊆ Dom(Γ). The remaining conclusions are the IHs themselves.


Lemma 4.4 (Generation)
If Γ ▶ new x : Xi|Xo, then x ∈ Xo and there exists ∆, ∆', A such that Γ = ∆, x−≺ A, ∆', and ∆ ▶ A : Xi−x|Xo−x.
If Γ ▶ new xA : Zi|Zo with A /= ϵ, then there exists Xi, Xo, Y i, Y o such that Γ ▶ new x : Xi|Xo, Γ ▶ A : Y i|Y o, Zi = Xi ∪ Y i, Zo = Xo ∪ Y o, and Xo ∩ E ∩ Y i = ∅.
If Γ ▶ {B}C : Zi|Zo, then there exists Xi, Xo, Y i, Y o such that Γ ▶ B :
Xi|Xo, Γ ▶ C : Y i|Y o, Zi = Xi ∪ Y i, Zo = Y o.
Proof. All three items are proved by induction on derivation.
Γ ▶ new x : Xi|Xo can only be derived by rule Start or rule Weakening. If it is derived by rule Start, then there is only one possibility:
∆ ▶ A : Xi−x|Xo−x

Stavt
Γ ▶ new x : Xi|Xo	x ∈/ Dom(∆)

with x ∈ Xo and Γ = ∆, x−≺ A, so that ∆' is empty. If Γ ▶ new x : Xi|Xo is derived by rule Weakening:
Γ' ▶ new x : Xi|Xo	Γ' ▶ B : Y i|Y o
Weakening	Γ', y−≺ B ▶ new x : Xi|Xo




y ∈/ Dom(Γ')

then Γ' ▶ new x : Xi|Xo and by the IH applied to Γ' ▶ new x : Xi|Xo we have x ∈ Xo, Γ' = ∆1, x−≺ A', ∆2 and ∆1 ▶ new x : Xi−x|Xo−x for some ∆1, ∆2, and A'. Now take ∆ = ∆1, ∆' = ∆2, y−≺ B, A = A' and we have all the conclusions.
Similarly, Γ ▶ new xA : Zi|Zo with A /= ϵ can only be derived by rule Se- quencing or rule Weakening. The proof for case Sequencing is immediate. If Γ ▶ new xA : Zi|Zo is derived by rule Weakening:
Γ' ▶ new xA : Zi|Zo	Γ' ▶ B : V i|V o

Weakening
Γ', y−≺ B ▶ new xA : Zi|Zo
y ∈/ Dom(Γ')

then Γ = Γ', y−≺ B and by the IH applied to Γ' ▶ new xA : Zi|Zo we have Γ' ▶ new x : Xi|Xo, Γ' ▶ A : Y i|Y o, Zi = Xi ∪ Y i, Zo = Xo ∪ Y o, and Xo ∩ E ∩ Y i = ∅. Now weakening Γ' ▶ new x : Xi|Xo and Γ' ▶ A : Y i|Y o to Γ = Γ', y−≺ B we have all the conclusions.

Similarly, Γ ▶ {B}C : Zi|Zo can only be derived by rule Scope or rule Weakening. The proof is analogous to that of the previous case.


Lemma 4.5 (Legal monotonicity)
If Γ = ∆, x−≺ A, ∆' is legal, then ∆ ▶ A : Xi|Xo for some Xi and Xo.
If Γ ▶ A : Xi|Xo, Γ ⊆ Γ' and Γ' is legal, then Γ' ▶ A : Xi|Xo.
Proof.
The only way to extend ∆ to ∆, x−≺ A in a derivation is by applying the rule Start or Weakening.
∆ ▶ ϵ : ∅|∅	∆ ▶ A : Xi|Xo

Weakening
∆, x−≺ A ▶ ϵ : ∅|∅
∆ ▶ A : Xi|Xo
x ∈/ Dom(∆)

Stavt ∆, x−≺ A ▶ new x : Xi+x|Xo+x x ∈/ Dom(∆)
Each of the rules has ∆ ▶ A : Xi|Xo as a premise.
By induction on derivation of Γ ▶ A : Xi|Xo. We prove that for all Γ' legal such that Γ ⊆ Γ' we have Γ' ▶ A : Xi|Xo.
Base case Axiom A = ϵ: then Γ' ▶ ϵ : ∅|∅ since Γ' is legal. Case Start A = new x :
∆ ▶ B : Y i|Y o
Stavt Γ = ∆, x−≺ B ▶ new x : Y i+x|Y o+x x ∈/ Dom(∆)
Let Γ ⊆ Γ' with Γ' legal.	Then there exists ∆1, ∆2, ∆3 such that
∆1, ∆, ∆2, x−≺ B, ∆3 = Γ', with all initial segments of Γ' are legal. By IH we have ∆1, ∆, ∆2 ▶ B : Y i|Y o.	As x occurs only once in

Γ' we have x ∈/
Dom(∆1, ∆, ∆2) and we can apply rule Start to get

∆1, ∆, ∆2, x−≺ B ▶ new x : Y i+x|Y o+x. Since Γ' is legal we can iterate weakening to get Γ' ▶ new x : Y i+x|Y o+x.
Case Weakening:



Weakening
∆ ▶ A : Xi|Xo	∆ ▶ B : Y i|Y o
Γ = ∆, y−≺ B ▶ A : Xi|Xo	x ∈/ Dom(∆)

Let Γ ⊆ Γ' with Γ' legal, so also ∆ ⊆ Γ'. By IH we get immediately Γ' ▶ A : Xi|Xo.
Case Sequencing A = new xB with B /= ϵ: by Generation Lemma we have Γ ▶ new x : V i|V o and Γ ▶ B : Y i|Y o with Xi = V i ∪ Y i,

Xo = V o ∪ Y o, and V o ∩ E ∩ Y i = ∅. By IHs we have Γ' ▶ new x : V i|V o
and Γ' ▶ B : Y i|Y o. Apply rule Sequencing and we get the conclusion.
Case A = {A1}A2: analogous to the case Sequencing.


Lemma 4.6 (Strengthening)
If Γ, x−≺ A ▶ B : Y i|Y o and x ∈/ V av(B), then Γ ▶ B : Y i|Y o and x ∈/ Y i.
Proof. By induction on derivation.
Case Axiom: does not apply since the basis is not empty.
Case Start: does not apply since V av(B) = V av(new x ) = {x}.
Case Weakening:



Weakening
Γ ▶ B : Y i|Y o	Γ ▶ A : Xi|Xo
Γ, x−≺ A ▶ B : Y i|Y o	x ∈/ Dom(Γ)

Then we get Γ ▶ B : Y i|Y o in the premise. Moreover, x ∈/ Y i since Y i ⊆
Dom(Γ) and x is declared only once in Γ, x−≺ A, both by Lemma 4.3.
Case Sequencing:


Sequencing
Γ, x−≺ A ▶ new y : V i|V o Γ, x−≺ A ▶ C : Zi|Zo	o
Γ, x−≺ A ▶ new yC : Y i|Y o	V

∩ E ∩ Zi

= ∅,C /= ϵ

for V i, V o, Zi, Zo such that Y i = V i ∪ Zi and Y o = V o ∪ Zo. Since x ∈/ V av(new y C) = {y}∪ V av(C) we have x /= y and x ∈/ V av(C). By IHs we get Γ ▶ new y : V i|V o and x ∈/ V i, Γ ▶ C : Zi|Zo and x ∈/ Zi. So by applying rule Sequencing we get the conclusion: Γ ▶ new yC : Y i|Y o.
Case A = {A1}A2: analogous to the case Sequencing.


Lemma 4.8 (Substitution)
Suppose Γ ▶ new xB : Zi|Zo, then
x−≺ A ∈ Γ and Γ ▶ A : Xi|Xo for some A, Xi, and Xo.
Γ ▶ B : Y i|Y o for some Y i and Y o.
Γ ▶ A@B : Xi ∪ Y i|Xo ∪ Y o.
Proof. If B = ϵ then the lemma trivially holds. So we assume B /= ϵ.
If Γ ▶ new xB : Zi|Zo with B /= ϵ, then by Generation Lemma 4.4, there exists V i, V o, Y i, Y o such that Γ ▶ new x : V i|V o, Γ ▶ B : Y i|Y o,

Zi = V i ∪ Y i, Zo = V o ∪ Y o, and V o ∩ E ∩ Y i = ∅. Apply the same lemma to Γ ▶ new x : V i|V o and we have x ∈ V o, Γ = ∆, x−≺ A, ∆' and
∆ ▶ A : V i−x|V o−x. So x−≺ A ∈ Γ is proved.
Applying Lemma 4.5 to ∆ ⊆ Γ and ∆ ▶ A : V i−x|V o−x, we have Γ ▶ A : Xi|Xo with Xi = V i−x and Xo = V o−x.
Immediate from Generation Lemma.
By induction on structure of A.
Base step: Case A = ϵ: Then Xi = Xo = ∅ by rule Axiom ▶ ϵ : ∅|∅, Lemma 4.5, and Proposition 4.7.
Case A = new y : Since new y @B = new y B, applying rule Sequencing
to Γ ▶ new y : Xi|Xo and Γ ▶ B : Y i|Y o received in the proofs of the previous clauses we have:

Γ ▶ new y : X |Xo  Γ ▶ B : Y |Y o	o	i

Sequencing
Γ ▶ new yB : Xi ∪ Y i|Xo ∪ Y o	X
∩ E ∩ Y
= ∅,B /= G

The side condition holds since Xo = V o−x and V o ∩ E ∩ Y i = ∅ also in the proof of the first clause.
Case A = new yC with C /= ϵ: By clause 1 we have Γ ▶ new yC : Xi|Xo.
By Generation Lemma, we have Γ ▶ new y : Xi|Xo, Γ ▶ C : Xi|Xo
1	1	2	2
for some Xi, Xo, Xi, Xo such that Xi = Xi ∪ Xi, Xo = Xo ∪ Xo
1	1	2	2	1	2	1	2

and Xo ∩ E ∩ Xi
= ∅.	By IH for clause 3 we have Γ ▶ C@B :

1	2
Xi ∪ Y i|Xo ∪ Y o.	By rule Sequencing we infer Γ ▶ new y (C@B) :
2	2
Xi ∪ Xi ∪ Y i|Xo ∪ Xo ∪ Y o.	The side condition for this rule Xo ∩
1	2	1	2	1

E ∩ (Xi ∪ Y i) = ∅ holds since Xo ∩ E ∩ Xi
= ∅ holds above and

2	1	2
Xo ∩ E ∩ Y i = ∅ holds from Xo ∩ E ∩ Y i = ∅ and Xo ⊆ Xi. Finally,
1	1
observe that Xi ∪ Xi ∪ Y i = Xi ∪ Y i, Xo ∪ Xo ∪ Y o = Xo ∪ Y o, and
1	2	1	2
A@B = new y (C@B).
Case A = {C}D: By clause 1 we have Γ ▶ {C}D : Xi|Xo. By Gen-

eration Lemma, we have Γ ▶ C : Xi|Xo, Γ ▶ D : Xi|Xo
for some

1	1	2	2
Xi, Xo, Xi, Xo such that Xi = Xi ∪ Xi and Xo = Xo.  By IH
1	1	2	2	1	2	2
for clause 3 we have Γ ▶ D@B : Xi ∪ Y i|Xo ∪ Y o.  By rule Scope
2	2
we infer Γ ▶ {C}(D@B) : Xi ∪ Xi ∪ Y i|Xo ∪ Y o. Finally, observe that
1	2	2
Xi ∪ Xi ∪ Y i = Xi ∪ Y i, Xo ∪ Y o = Xo ∪ Y o, and A@B = ({C}D)@B =
1	2	2
{C}(D@B).
