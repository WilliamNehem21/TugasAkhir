	Electronic Notes in Theoretical Computer Science 203 (2008) 263–284	
www.elsevier.com/locate/entcs
Comonadic Notions of Computation
Tarmo Uustalu1
Institute of Cybernetics at Tallinn University of Technology, Akadeemia tee 21, EE-12618 Tallinn, Estonia
Varmo Vene2
Dept. of Computer Science, University of Tartu,
J. Liivi 2, EE-50409 Tartu, Estonia

Abstract
We argue that symmetric (semi)monoidal comonads provide a means to structure context-dependent notions of computation such as notions of dataflow computation (computation on streams) and of tree relabelling as in attribute evaluation. We propose a generic semantics for extensions of simply typed lambda calculus with context-dependent operations analogous to the Moggi-style semantics for effectful languages based on
strong monads. This continues the work in the early 90s by Brookes, Geva and Van Stone on the use of computational comonads in intensional semantics.
Keywords: context-dependent computation, dataflow computation, tree transformations, symmetric monoidal comonads, coKleisli semantics

Introduction
Since the seminal work by Moggi in the late 80s [25], monads, more precisely, strong monads, have become a generally accepted tool for structuring effectful notions of computation, such as computation with exceptions, output, computation using an environment, state-transforming, nondeterministic and probabilistic computation etc. The idea is to use a Kleisli category as the category of impure, effectful func- tions, with the Kleisli inclusion giving an embedding of the pure functions from the base category. Although finer and coarser accounts of effects based on Lawvere theories [27] (this reference is only the first in a series of papers; for more recent pre- sentations, see [28,18]) and arrows/Freyd categories [17,30] also exist, the monadic approach remains central and best known. In particular, monads are part of the standard libraries of Haskell.

1 tarmo@cs.ioc.ee
2 varmo@cs.ut.ee

1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.05.029

But monads do not capture all meaningful kinds of impure computation. In particular, they exclude some natural notions where, instead of producing effects, computations consume something beyond just values (“contexts” of values). Hence it is natural to ask whether comonads, likely with some additional structure (as strength for monads), can deliver a solution for such cases. (Combinations of mon- ads and comonads via distributive laws can then hopefully account for notions of computation that are both effectful and context-dependent.) That this may well be so was hinted very early on by Brookes et al. [8,9] who demonstrated that what they called computational comonads can be used to make denotational semantics inten- sional. While that work was not directly involved with general context-dependent computation, intensional semantics is a form of impure instrumentation of denota- tional semantics that fits well into this idiom.
In functional programming, Kieburtz [20] was first to advocate comonads as tools for structuring context-dependent computations and gave some interesting exam- ples. The specific application of comonads to environment-passing computation or implicit parameters has been discussed by Lewis et al. [22].
In this paper, we proceed directly from the motivation to treat some impor- tant notions of context-dependent computation, namely notions of dataflow com- putation (stream-based computation) and notions of computation on trees such as tree relabellings in attribute evaluation. We demonstrate that a rather elegant framework for working with these notions of computation is given by symmetric (semi)monoidal comonads. Reassuringly, strong monads appear associated with symmetric monoidal comonads also in works on the categorical semantics of intu- itionistic linear and modal logic [4,7]. We describe some aspects of the structure of coKleisli categories corresponding to symmetric (semi)monoidal comonads and de- scribe then a general interpretation of languages for context-dependent computation into such categories.
We have previously described our proposal at work on language processors for dataflow computation [34] and attribute evaluation [35] implemented in Haskell. In this paper, written with a different slant, we look into the underlying theory, con- centrating on the issue of the most appropriate additional structure for comonads. The organization of the paper is the following. First, we present a compressed recap of strong monads, their Kleisli categories and the semantics of effectful lan- guages `a la Moggi. Then we develop our analogous account of context-dependent computation based on coKleisli categories of symmetric (semi)monoidal comonads. We emphasize the important differences resulting from the fact that, despite dual- izing from monads to comonads, we are still interested in transferring as much of a given Cartesian closed structure (possibly with coproducts and a uniform parame- terized fixpoint operation) as possible. Finally, we briefly comment on the relation to computational comonads and some important advanced issues that we intend to
treat in due detail elsewhere.
We assume that the reader knows symmetric monoidal closed and Cartesian closed categories and the categorical semantics of simply typed lambda calculus. We reproduce some basics about monads, comonads, strong functors/monads and

symmetric monoidal functors/comonads.

Monads and effectful computation
We begin by a schematic review of the monad-based approach to effectful compu- tation. The purpose is to recall the central ideas, the technical machinery and the big “scheme of things” of this case, so we can establish a standard of what we want to achieve in the case of comonads and context-dependent computation.

Monads
The starting-point in the monadic approach to (call-by-value) effectful computation is the idea that impure, effectful functions from A to B must be nothing else than pure functions from A to TB. Here pure functions live in a base category C and T is an endofunctor on C that describes the notion of effect of interest; it is useful to think of TA as the type of effectful computations of values of a given type A.
For this to work, impure functions must have identities and compose. Therefore
T cannot merely be a functor, but must be a monad.
A monad on a category C is given by a functor T : C → C (the underlying
functor ), two natural transformations η : IdC →.  T (the unit ) and μ : TT →.  T (the
multiplication) satisfying the conditions

 μT A  
TA ¸ ηTA T T  A	TTTA	T T A 
Tη	¸¸¸¸¸¸	μA	Tμ	μA
A J	¸¸ J	A J	J 

TTA μA
 T A 
TTA	μA
 T A 


This definition says that (T, η, μ) is a monoid in the endofunctor category [C, C] wrt. its (IdC, ∗) monoidal structure.
A monad T on a category C induces a category Kl(T ) called the Kleisli category
of T defined by
an object is an object of C,
a map of from A to B is a map of C from A to TB,

idT =
ηA	,

A	df A −→ TA 
if k : A →T B, l : B →T C, then l ◦T k =	k	l	where


l٨ =	Tl 

μC	.
df A
−→ TB −→ TC 

df TB −→ TTC −→ TC 
Note that it is the unit η and multiplication μ that make the Kleisli identity idT and composition ◦T possible; the laws of the identity and composition follow from those of η and μ.
From C there is an identity-on-objects inclusion functor J to Kl(T ), defined on

maps by: if f : A → B, then Jf =
f	ηB
=	ηA
Tf	.

df A −→ B
−→ TB 
A −→ TA −→ TB 

(It is truly an inclusion, if η is mono, but we ignore this.) It has a right adjoint

U : Kl(T ) →C given by: UA =
TA and, if k : A →T B, then Uk =	k	.

df	df TA −→ TB 

In our application, we use the Kleisli category Kl(T ) as the category of effectful functions and J as an embedding from the category of pure functions C. Accordingly, for us, the function ηA = J idA : A → TA is the pure identity function on A turned into a trivially effectful function. Jf : A → TB is a general pure function
f : A → B viewed as trivially effectful. μA = id٨	: TTA → TA “flattens” an
effectful computation of an effectful computation. k٨ : TA → TB is an effectful function k : A → TB extended into one that can input an effectful computation.
Well-known examples of monads on Cartesian categories 3 (optionally with co- products, optionally closed), e.g., Set, include the following.
The exceptions monad is given by
TA =df A + E where E is some object (of exceptions),

ηA =df
inl
A −→ A
+ E,
[id,inr]

μA =df (A + E)+ E −→ A + E
and is used for computation with exceptions. Properly impure functions are possible

thanks to the error-raise operation raiseA =df The output monad is given by
inr
E −→ A
+ E.

TA =df A × E where (E, e, m) is some monoid (of output traces), e.g., the type of lists of a fixed element type with nil and append,

ηA =df
ur
A −→ A ×
id
−→ A × E

μA =df (A × E)
a
× E −→ A ×
(E × E) id×m

and is used to handle observable output or time. The important operation for

generating impure functions is print :
⟨!,id⟩
E −→	× E

The environment monad is given by:
TA =df E ⇒ A where E is some object (of environments),

ηA =df Λ(
fst
A × E −→ A
): A → E ⇒ A,

μA
=df
Λ((E ⇒ (E ⇒ A)) × E
⟨ev,snd⟩
−→	E ⇒ A
ev
× E −→ A

: E ⇒ (E ⇒ A) → E ⇒ A.
It is used to deal with a readable environment. The native operation is ask =df
Λ(1 × E −→ E):1 → E ⇒ E.
Further important well-known examples include the state monad, the continua- tions monad, free monads and free completely iterative monads [2].
Strong monads
To be able to use a Kleisli category as a category of computation, we also need it to have datatypes. At the very least, it must support something product-like and in particular something approximating local composition to interpret let.

3 By a Cartesian category we mean one with finite products (the word is also used to refer to categories with finite limits).

In order for these to exist, the monad must be strong.
A strong functor on a monoidal category (C,I, ⊗) is given by an endofunctor F on C together with a natural transformation slA,B : A ⊗ FB → F (A ⊗ B) (the (tensorial) strength) satisfying
I ⊗ FA slI,A F (I ⊗ A) (A ⊗ B) ⊗ FC	slA⊗B,C	 F ((A ⊗ B) ⊗ C)

ulFA J 
F ul
J 
aA,B,FC J 
JF a A,B,C

FA	FA 
A ⊗ (B ⊗ FC)	 A ⊗ F (B ⊗ C)
 F (A ⊗ (B ⊗ C))

idA⊗slB,C
slA,B⊗C

(Note that a monad can generally have more than one strength.)
A strong natural transformation between two strong functors (F, slF ), (G, slG)
is a natural transformation τ : F →. G satisfying


A ⊗ FB 
idA⊗τB J 
A ⊗ GB
slF
A,B F (A ⊗ B)
τA⊗B
J 
 G (A ⊗ B)
A,B


A strong monad on a monoidal category (C,I, ⊗) is a monad (T, η, μ) where T is a strong functor and η, μ are strong natural transformations. The latter part means that η, μ satisfy


A ⊗ B
 A ⊗ B
A ⊗ TTB  slA,T B T ( A ⊗ TB) T slA,B T T  (A ⊗ B)

idA⊗ηB
J 	 T ( 
ηA⊗B
idA⊗μB J 

 	  
μA⊗B
J 

A ⊗ TB slA,B
A ⊗ B)
A ⊗ TB	sl

A,B
T (A ⊗ B)

(Note that Id is canonically strong and strong F , G make GF canonically strong.) A strong functor (F, sl) on a symmetric monoidal category (C,I, ⊗) is automat- ically bistrong: it is also endowed with a costrength srA,B : FA ⊗ B → F (A ⊗ B)
whose properties are symmetric to those of a strength. It is defined by


cFA,B
slB,A
F cB,A

srA,B =df FA ⊗ B
−→ B ⊗ FA −→ F (B ⊗ A)
−→ F (A ⊗ B)

A bistrong monad (T, sl, sr) is called commutative, if it satisfies
TA ⊗ TB  slTA,B T ( TA ⊗ B)T srA,B T T (A ⊗ B)
srA,TB J 

T (A ⊗ TB)
T slA,B J 
TT (A ⊗ B)	μ





A⊗B
μA⊗B

J 
 T ( A ⊗ B)

Strength is not a very restrictive condition. In particular, on Set, every monad is strong, with a unique strength. The reason is that any endofunctor F on Set

has a unique functorial strength fsX,Y : X ⇒ Y → FX ⇒ FY (internalizing its functoriality) and any natural transformation between endofunctors on Set is functorially strong. Functorial strength implies tensorial strength. Commutativity is rarer. An example of a commutative monad is the exponent monad.
Given a Cartesian category C anda (1, ×) strong monad T on it, we can manu- facture “preproducts” in Kl(T ) using the products of C and the strength sl like this:
1T =df 1	A0 ×T A1 =df A0 × A1
fstT =df η ◦ fst sndT =df η ◦ snd
!T =df η ◦ !	⟨k0, k1⟩T =df sl٨ ◦ sr ◦ ⟨k0, k1⟩
With this definition, the typing rules for products hold, but not all laws. In particular, the beta-laws fstT ◦T ⟨k0, k1⟩T = k0 and sndT ◦T ⟨k0, k1⟩T = k1 do not hold. And the binary operation ×T on objects does not extend to a bifunctor (although it is a functor in each argument separately). But some other important laws, such as, e.g., the eta-law ⟨fstT , sndT ⟩T = idT , survive. In particular, (Kl(T ),J ) is a Freyd category on C, i.e., a symmetric premonoidal category with an identity-on-objects functor from C strictly preserving the (1, ×) symmetric premonoidal structure of C and also centrality. (Since all maps of C are central, the latter part really means sending all maps of C to central maps of Kl(T )).
If C is Cartesian closed, then “pre-exponents” in Kl(T ) can be defined from the exponents of C by
A ⇒T B =df A ⇒ TB 
evT =df ev
ΛT (k) =df η ◦ Λ(k)
It is not true that A ⇒T − : Kl(T ) → Kl(T ) is right adjoint to − ×T A :
Kl(T ) → Kl(T ). So ⇒T is not a true exponent functor wrt. the preproduct functor
×T . However A ⇒T − : Kl(T ) →C is right adjoint to J (−× A): C → Kl(T ):
J (C × A) →T B
 C × A → TB 
C → A ⇒ TB  C → A ⇒T B

Semantics of effectful languages
Given a strong monad T on a Cartesian closed category C, the pure part of an effectful language can be interpreted into Kl(T ) in the standard way, relying on the generic pre-(Cartesian closed) structure of Kleisli categories of strong monads.




 K)T =df an object of Kl(T )	= that object of C
 A × B)T =df  A)T ×T B)T	= A)T × B)T
 A ⇒ B)T =df  A)T ⇒T B)T	= A)T ⇒ T B)T
 C)T =df  C0)T ×T ... ×T Cn−1)T	= C0)T × ... × Cn−1)T

 (x) xi)T =df πT
= η ◦ πi

 (x) let x ← t in u)T =df  (x, x) u)T ◦T ⟨idT , (x) t)T ⟩T = ( (x, x) u)T )s ◦ sl ◦ ⟨id, (x) t)T ⟩
 (x) fst t)T =df fstT ◦T (x)t)T	= T fst ◦ (x)t)T
 (x) snd t)T =df sndT ◦T (x)t)T	= T snd ◦ (x)t)T
 (x) (t0, t1))T =df ⟨ (x)t0)T , (x)t1)T ⟩T	= sls ◦ sr ◦ ⟨ (x)t0)T , (x)t1)T ⟩
 (x) λxt)T =df ΛT ( (x, x)t)T )	= η ◦ Λ( (x, x)t)T )
 (x) t u)T =df evT ◦T ⟨ (x)t)T , (x)u)T ⟩T	= evs ◦ sls ◦ sr ◦ ⟨ (x)t)T , (x)u)T ⟩


(The notation (x) t denotes a term t with free variables x; we have left out types; for well-typed terms, the interpretation is well-defined.) In the second column, there is the “standard” semantics in terms of the pre-(Cartesian closed) structure of Kl(T ). In the third column the same appears spelled out in more primitive
terms, after simplifications. Note, e.g., that in the semantics of let, sr is not needed,
although the definition of ⟨−, −⟩T involves it; it gets cancelled out in the simplifi-
cation.
Constructs specific to particular notions of effect must be interpreted specifically.
E.g., for exceptions we can use the coproduct monad T and set
 (x) raise t)T =df raise٨ ◦ (x)t)T

As Kl(T ) is only pre-(Cartesian closed), we have soundness of typing: x : C ▶ t : A implies (x) t)T : C)T →T A)T . But of course not all equations of lambda- calculus are validated.
In particular, we have that ▶ t : A implies  t)T :1 →T  A)T . So a closed term t
of a type A denotes an element of T A)T .

Comonads and context-dependent computation
We proceed to an analysis of context-dependent computation.

Comonads
Basics and first examples
We go straight to the definition and first properties of comonads. Comonads are the dual of monads. A comonad is a functor D : C → C (the underlying functor )
together with natural transformations ε : D →. IdC (the counit ), δ : D →. DD (the

comultiplication) satisfying

DA¸


δA  D DA


DA 	δA   D DA

¸¸¸¸¸¸¸¸
δA	¸¸¸¸¸¸¸¸

DεA	δA

DδA

J	¸ J	J	J 

DDA εDA
 D A
DDA

δDA
 D DDA

In other words, a comonad is a comonoid in ([C, C], IdC, ∗).
Dually to Kleisli categories, a comonad D on a category C induces a category
CoKl(D) called the coKleisli category of D. This is defined by:
an object is an object of C,
a map of from A to B is a map of C from DA to B,

idD =df DA −→ A,
D	D	D


k†	l

if k : A →
B, l : B →
C, then l ◦
k =df DA
−→ DB −→ C where

k† =	δA
Dk	.

DA −→ DDA −→ DB
From C there is an identity-on-objects inclusion functor J to CoKl(D), defined

on maps by: if f : A → B, then Jf =
εA	f	=	Df
εB	.

df DA −→ A −→ B	DA −→ DB −→ B
The functor J has a left adjoint U : CoKl(D) → C given by: UA =df DA and,
if k : A →D B, then Uk =	k	.
df DA −→ DB
The intuitive basis for the use of coKleisli categories as categories of impure computation should be the following. As before, we think of C as the category of pure functions, but D describes a notion of context. DA is the type of values of a given type A placed into a context. The category CoKl(D), whose maps are maps DA → B of the base category, is the category of context-dependent functions.
The function εA : DA → A is then the identity on A made trivially context- dependent, i.e., turned into a function discarding any given context. The function Jf : DA → B is a general pure function f : A → B regarded as trivially context- dependent in a similar fashion. The function δA : DA → DDA duplicates the context of a value while k† : DA → DB is a context-dependent function k : DA → B extended into one that outputs a value of in a context (so it can be postcomposed with a context-dependent function).
Some computationally meaningful examples with C a Cartesian (closed) cate- gory, e.g., Set, are the following.
The product comonad is defined by:
DA =df A × E, where E is a fixed object of C,

εA =df
fst
A × E −→ A
⟨id,snd⟩

δA =df A × E −→ (A × E) × E.
This is the dual of the exceptions monad. But its use is the same as that of the environment monad: for TA =df E ⇒ A we have CoKl(D) ∼= Kl(T ). Hence the product comonad can be used for dependence on an environment. The important

native operation of this comonad leading to impure computations is ask =df 1 ×
snd
E −→ E
The exponent comonad is given by:
DA =df S ⇒ A where (S, e, m) is a monoid in C,

ur−1
id×e	ev

εA =df (S ⇒ A) −→ (S ⇒ A) × 1 −→ (S ⇒ A) × S −→ A,
δA =df Λ(Λ(δ' )) : S ⇒ A → S ⇒ (S ⇒ A) where

' =df ((S ⇒ A) × S)
a
× S −→
(S ⇒ A) × (S × S) id×m (S ⇒ A)
ev
× S −→ A

We come to computational uses soon, but some interesting cases are, e.g., (S, e, m) =df (Nat, 0, +) and (S, e, m) =df (Nat, 0, max).
The costate comonad is given by:
DA =df (S ⇒ A) × S where S is an object of C,

εA =df (S ⇒ A)
ev
× S −→ A

δA =df (S ⇒ A) × S  −→  (S ⇒ ((S ⇒ A) × S)) × S.
This comonad arises from the composition in the appropriate order of the adjoint functors S ×− E S ⇒ −. Composition the other way around gives rise to the state monad T defined by TA = S ⇒ (A × S). Again we defer the discussion of the computational utility.
The cofree comonad on an endofunctor H on C is given by DA =df νX.A× HX (i.e., the carrier of the final A × H(−)-coalgebra, which is the cofree H-coalgebra on A). The functor DA =df μX.A × HX (i.e., the carrier of the initial A × H(−)- algebra) is also a comonad, the cofree recursive comonad [33] (dual to the free completely iterative monad [2]). The set DA is the set of nonwellfounded resp. wellfounded A-labelled H-branching trees. Think, e.g., of the case HX =df 1+ X × X, leading to binary branching with a termination option. The counit εA : DA → A extracts the root label of a given tree (so the root label is the focus value in a tree and the rest of the tree is its “context”). The comultiplication δA : DA → DDA replaces the label of every node with the subtree rooted by that node (thus equipping every node label with a local copy of its context).

Comonads for dataflow computation
Next we look at dataflow computation (stream-based computation). We are interested in notions of computation where impure functions from A to B are gen- eral, causal or anticausal functions from StrA to StrB where StrA =df νX.A × X is the set of streams with elements from A. The physical intuition here is that of discrete-time signal transformers; streams represent histories of signals. Causality (corresponding to what is physically feasible with signals) means that the present value of the output signal can only depend on the present and past values of the input signal. Anticausality means dependence on the present and future alone.
Streams are in natural bijection with functions from natural numbers: StrA ∼= Nat ⇒ A. Hence, general stream functions StrA → StrB (as used in dataflow languages like Lucid [3]) are in natural bijection with maps (Nat ⇒ A) × Nat → B,

i.e., with coKleisli maps of the costate comonad DA =df (S ⇒ A) × S where S =df Nat. Moreover, the identities and composition of general stream functions and the coKleisli identities and composition agree. So this particular instantiation of the costate comonad describes the notion of context used in general dataflow computation. We call it the streams with a position comonad, since it pairs an input stream of a stream function with a chosen position of interest in the output stream. The important operations supported this comonad are fby and next. The fby (’followed by’) operation corresponds to initialized unit delay of the input signal, while next operation corresponds to unit anticipation. In both cases, the stream is shifted but the designated position stays the same.
For clarity, here is the concrete description for the case C = Set:

DA =df (Nat ⇒ A) × Nat


Further, a position in a stream splits it into two parts, a list of elements before the position (the past of the signal) and a stream of all remaining elements (the present and future): (Nat ⇒ A) × Nat ∼= ListA × StrA. From here it is not a long way to see that the causal stream functions (where the present value of the output signal can depend on the present and past values of the input signal, but not on the future; programs in the Lustre [13] and Lucid Synchrone [29] dataflow languages denote causal stream functions) correspond precisely to the coKleisli maps of the comonad DA =df ListA×A ∼= NEListA ∼= μX.A×(1+X) (this is the cofree recursive monad on H defined by HX =df 1+ X, we call it the nonempty list comonad ). And the anticausal ones (where the present of the output signal may only depend on the present and future values of the input signal) correspond to the coKleisli maps of the comonad DA =df StrA = νX.A × X (the cofree comonad on IdC , also equivalent to the exponent comonad DA =df S ⇒ A with (S, e, m) =df (Nat, 0, +), we call it the stream comonad ). Again, in each case the identities and composition of stream functions agree with those of the coKleisli category. Of the operations discussed above, the first comonad supports only unit delay fby, while the second one only supports unit anticipation next.

The concrete description of the nonempty list comonad is this:
DA =df NEList A

εA :	NEList A	→	A
(a0,..., an−1, an)	'→	an
δA :	NEList A	→	NEList (NEList A)
(a0,..., an−1, an)	'→ ((a0),..., (a0,..., an−1), (a0,..., an−1, an))
fbyA :	A × NEList A	→	A
(a00, (a0))	'→	a00
(a00, (a0,..., an, an+1)) '→	an
The comonad for anticausal dataflow computation is concretely defined by:
DA =df StrA

εA :	StrA	→	A
(an, an+1,.. .) '→	an
δA :	StrA	→	Str(StrA)
(an, an+1,.. .) '→ ((an, an+1,.. .), (an+1,.. .),.. .)
nextA :	StrA	→	A
(an, an+1,.. .) '→	an+1

Comonads for tree transformations
A similar example is given by relabelling tree transformations, often specified with attribute grammars [21]. Let H : C → C. We are interested in relabelling tree functions TreeA → TreeB where TreeA =df μX.A×HX is the type of wellfounded A- labelled H-branching trees. (Relabellings are equally plausible for nonwellfounded trees, but we concentrate on the wellfounded case.) At any node of interest in the output tree the label is determined by the label at the same node in the input tree plus maybe some more nodes. In the case of general relabellings, dependence on the labels in all of the remaining tree is allowed. In bottom-up relabellings, only labels at and below the position of interest may influence the result. The idea is again to mark the node of interest.
The comonad for general relabellings (corresponding to general attribute gram- mars with both synthesized and inherited attributes) is the trees with a position comonad, the comonad structure on the zipper datatype of Huet [16]. This is defined by DA =df Tree'A × A ∼= PathA × TreeA where PathA =df List(A × H'(TreeA)) ∼= μX.1+ A × H'(TreeA) × X. Here F' denotes the derivative of a functor (container) F ; intuitively it is the type of one-hole versions of the container F [23,1]. An ele- ment of the type Tree'A×A consists of an A-labelled tree with the label of one node omitted, just to mark this node, along with the omitted label attached separately.

An element of the type PathA× TreeA is an A-labelled tree, split into the path from a node of interest up to the root, together with all side subtrees, and the subtree rooted by this node of interest.
As an example of how the path type is computed for a branching factor H, for HX =df 1+ X × X we have H'X =2 × X, so PathA ∼= List(A × 2 × TreeA)). An element in this type is a list of triples (the label of my parent, I am the left or right child, the side subtree rooted by my sibling) for every node from the focus node up until the root node (excluded) in a tree to relabel.
The comonad for bottom-up tree relabellings (corresponding to purely synthe- sized attribute grammars) is the tree comonad, defined by DA =df TreeA (the cofree recursive comonad on H). An element here represents a subtree of a global tree to be relabelled rooted by a node of interest.
(Notice that bottom-up tree relabellings generalize anticausal stream functions.) The important operations of the comonad are for navigation in the tree: up to the parent of a given node (this is possible in the case of general tree relabellings)
and down to the children (possible in both cases).

From streams and trees to containers
It is worth noticing that the tree with a position comonad is in fact a coproduct of costate comonads and the tree comonad is a coproduct of exponent comonads, just as the stream with a position comonad is a costate comonad and the stream comonad an exponent comonad.
The observation is that trees (just as streams) are a special case of containers [1], i.e., set functors FA =df s∈S(Ps ⇒ A) where S is a set (of shapes) and P an assignment of sets (of positions) to shapes.
Shape-preserving functions FA → FB are thus families of maps (Ps ⇒ A → Ps ⇒ B)s∈S, in other words, maps  s∈S((Ps ⇒ A) × Ps) → B. The functor DA =df s∈S((Ps ⇒ A) × Ps) ∼= F'A × A carries the comonad for the general relabellings.
To speak of abstract bottom-upness, we must confine ourselves to containers with some structure, namely: (1) for any shape s ∈ S and position p ∈ Ps, a shape s ↓ p ∈ S (for the shape of the subcontainer below position p in containers of shape s), (2) for any shape s ∈ S, a position 0s ∈ Ps (the root position), (3) for any shape s ∈ S and positions p ∈ Ps and p' ∈ Ps↓p, a position p · p' ∈ Ps (the position p' in the subcontainer as one in the global container), such that s ↓ 0s = s, s ↓ (p · p')= (s ↓ p) ↓ p', p · 0s↓p = p, 0s · p = p, and (p · p') · p'' = p · (p' · p'') — a form of dependent monoid on the family P .
The comonad for bottom-up relabellings is then DA =df  s∈S(Ps ⇒ A) ∼= F A.
Symmetric (semi)monoidal comonads
If C is Cartesian, then the coKleisli category CoKl(D) of a comonad D on C is straightforwardly Cartesian, as J : C → CoKl(D) is a right adjoint and preserves limits.

Explicitly, this structure is given by:
1D =df 1	A0 ×D A1 =df A0 × A1
fstD =df fst ◦ ε = ε ◦ Dfst sndD =df snd ◦ ε = ε ◦ Dsnd
!D =df !	⟨k0, k1⟩D =df ⟨k0, k1⟩

But finding a structure to mimic the exponents of C, if C is Cartesian closed, is not so easy. Given that exponents should be internal homsets, it is natural to choose
A ⇒D B =df DA ⇒ B
It is also unproblematic to match this up with the definition


D A,B
=df D((DA ⇒ B) × A) s
(DA ⇒ B)
ε×id
× DA −→ DA ⇒ B
ev
× DA −→ B

where sA,B =df ⟨Dfst, Dsnd⟩ : D(A × B) → DA × DB.
But given k : C ×D A →D B, i.e., D(C × A) → B, how should we define ΛD(k) : DC → DA ⇒ B, i.e., C →D A ⇒D B? It only makes sense to set ΛD(k) =df Λ(k') where k' = DC × DA −?→ D(C × A) −k→ B.
Using a strength of D (if available), we could use one of the maps

ε×id	sl
DC × DA −→ C × DA −→ D(C × A)
id×ε	sr
DC × DA −→ DC × A −→ D(C × A)
but this gives a solution where the order of two arguments of a binary function is important and the context of the value of one of the arguments is discarded.
The answer lies in symmetric monoidal and semimonoidal comonads. We review the definitions.
A strong [lax] symmetric monoidal functor between symmetric monoidal cat- egories (C,I, ⊗) and (C',I', ⊗') is a functor on F : C → C' together with an iso- morphism [map] e : I' → FI and a natural isomorphism [transformation] with components mA,B : FA ⊗' FB → F (A ⊗ B) satisfying
FA ⊗' I' id⊗'e' F A ⊗' FI mA,I F (A ⊗ I)	FA ⊗' FB mA,B F (A ⊗ B)

'	F urA
J	J 
'
FA,FB
J 
F cA,B
J 

FA	FA 
FB ⊗' FA m

B,A
 F (B ⊗ A)

(FA ⊗' FB) ⊗'
'
FA,FB,FC
mA,B⊗id  F (A ⊗ B) ⊗' FC  mA⊗B,C  F ((A ⊗ B) ⊗ C)
F aA,B,C

J 
FA ⊗' (FB ⊗' FC)

id⊗mB,C
 F A ⊗' F (B ⊗ C) m


A,B⊗C
J 
 F (A ⊗ (B ⊗ C))

A symmetric monoidal natural transformation between two (strong or lax) sym- metric monoidal functors (F, eF , mF ), (G, eG, mG) is a natural transformation τ :
F →.  G satisfying


I'   eF  F I 
τI
J 
FA ⊗' FB 
τA⊗'τB
J 
mF
A,B F (A ⊗ B)
τA⊗B
J 

I	G G I
GA ⊗' GB 	 G (A ⊗ B)
A,B


A strong [lax] symmetric monoidal comonad on a symmetric monoidal category (C,I, ⊗) is a comonad (D, ε, δ) where the underlying functor D is a strong [lax] symmetric monoidal functor (with preservation of I, ⊗ witnessed by e, m) and the counit and comultiplication ε, δ are symmetric monoidal natural transformations. The latter means that we have
I 	e  D I	DA ⊗ DB mA,B D (A ⊗ B)

εI	εA⊗εB
J	J 
εA⊗B
J 

I  I	A ⊗ B	A ⊗ B

I 	e	 D I
DA ⊗ DB 	mA,B	 D (A ⊗ B)


I 	 D I
δI	δA⊗δB
J	J 

 	  

 	  

δA⊗B
J 

e	De D DI
DDA ⊗ DDB

mDA,DB
D(DA ⊗ DB)

DmA,B
DD(A ⊗ B)

(Note that Id is canonically symmetric monoidal and that F , G being symmetric monoidal make GF canonically symmetric monoidal, so the definition is meaningful. Note also that the conditions on e are identical to those of an Eilenberg-Moore coalgebra structure on 1.)
Fairly often, as we will see shortly, the full structure of a symmetric monoidal comonad is not achievable, but not necessary either. We speak of a symmetric semimonoidal category, if the unit I is not present (or exists but is not important for us), and of a symmetric semimonoidal functor/comonad, if the unit preservation witness e is not present. We will later (in Sec. 3.4) show that that this imperfection can be avoided by switching to “typed” comonads on presheaf categories.
Let us revisit our examples. The product comonad, given by DA =df A × E with E an object, is lax symmetric monoidal (semimonoidal) as soon as E carries some commutative monoid (semigroup) structure e : 1 → E, m : E × E → E.

Indeed, we can then choose e =df
−→ 1 × E, m
A,B
=df
(A × E) × (B × E) −→

(A × B) × (E × E) ⟨id,m⟩ (A × B) × E.
The exponent comonad, given by D =df S ⇒ A with S carrying a monoid structure, is strong symmetric monoidal as witnessed by the isomorphism e =df
Λ(1 ×S −→!	1) : 1 ∼= S ⇒ 1 and natural isomorphism mA,B =df Λ(((S ⇒ A) × (S ⇒
B)) × S ⟨ev◦(fst×id),ev◦(snd×id)⟩ A × B): (S ⇒ A) × (S ⇒ B) ∼= S ⇒ (A × B).

The cofree comonad and cofree recursive comonad on any polynomial functor HX ∼= 1+ H'X are lax symmetric semimonoidal: we can choose m to “zip” two trees together, truncating wherever the branchings at a pair of corresponding nodes disagree. In the case of nonempty lists (H'X =df X), this is exactly the customary truncating zipping operation of nonempty lists. Alternatively, a single-node tree can be returned for trees of different shapes, pairing just the values at the roots.
Given a symmetric (semi)monoidal comonad D on a Cartesian closed category C,

we can define: if k : C×D A →D B, then ΛD(k) =df
Λ(k') where k' =
mC,A
DC×DA −→

D(C × A) −k→ B.
How good are the pre-exponents obtained as imitations of exponents?
If D is strong symmetric (semi)monoidal, then A ⇒D − is right adjoint to
— ×D A:
C ×D A →D B D(C × A) → B
 DC × DA → B DC → DA ⇒ B C →D A ⇒D B
Hence ⇒D is a true exponent functor and CoKl(D) is Cartesian closed just as C. If D is only lax symmetric (semi)monoidal however, then the binary operation
⇒D extends to a functor, but it has few properties of the exponent functor.
An intermediate case arises when (e and) m satisfy


DA
!DA
J 
DA
D!A
J 
DA
ΔDA
J 
DA
DΔA
J 

1	e	 D 1	DA × DA m

A,A
 D (A × A)


where ΔA =df ⟨id, id⟩ : A → A × A. These conditions are automatic, if D is strong symmetric (semi)monoidal, but not in the lax case. When met, they yield e ◦ !D1 = idD1 and mA,B ◦ sA,B = idD(A×B). As a consequence, ⇒D becomes a weak exponent operation on objects, i.e., we get evD ◦D (Λ(k) ×D idD)= k.
We note that (!A, ΔA) (corresponding to the structural rules of weakening and contraction) give a uniform comonoid structure on all objects A of C. Also, the map and natural transformation (!D1, s) witness that D is an oplax symmetric monoidal comonad that also respects the uniform comonoid structure (!, Δ).

Semantics of context-dependent languages
We are ready to define a general coKleisli semantics of context-dependent languages. We interpret lambda-calculus into the coKleisli category CoKl(D) of a symmetric (semi)monoidal comonad D on a given Cartesian closed category C of pure compu- tations. We do this, as if CoKl(D) was Cartesian closed, even if it may be merely

Cartesian “preclosed” in one of the senses discussed above. We get:

 K)D =df an object of CoKl(D)	= that object of C
 1)D =df 1D	= 1 
 A × B)D =df  A)D ×D B)D	= A)D × B)D
 A ⇒ B)D =df  A)D ⇒D  B)D	= D A)D ⇒ B)D
 C)D =df  C0)D ×D ... ×D Cn−1)D	= C0)D × ... × Cn−1)D
 (x) xi)D =df πD	= πi ◦ ε
 (x) let x ← t in u)D =df  (x, x) u)D ◦D ⟨idD, (x) t)D⟩D =  (x, x) u)D ◦ ⟨ε, (x) t)D⟩†
 (x) ())D =df !D	= ! 
 (x) fst t)D =df fstD ◦D  (x) t)D	= fst ◦ (x) t)D
 (x) snd t)D =df sndD ◦D  (x) t)D	= snd ◦ (x) t)D
 (x) (t0, t1))D =df ⟨ (x) t0)D, (x) t1)D⟩D	= ⟨ (x) t0)D, (x) t1)D⟩
 (x) λxt)D =df ΛD( (x, x) t)D)	= Λ( (x, x) t)D ◦ m)
 (x) t u)D =df evD ◦D ⟨ (x) t)D, (x) u)D⟩D	= ev ◦ ⟨ (x) t)D, ( (x) u)D)†⟩

Any construct specific to a particular notion of context receives a specific inter- pretation. E.g., for the ask construct of a language for computing with an environ- ment we can use the product comonad and define:
 (x) ask)D =df ask ◦ D!
And for the constructs of a general/causal/anticausal dataflow language we can use the appropriate comonad and define:
 (x) t0 fby t1)D =df fby ◦ ⟨ (x) t0)D, ( (x) t1))D)†⟩
 (x) next t)D =df next ◦ ( (x) t)D)†

Again, we have soundness of typing, in the form x : C ▶ t : A implies  (x)t)D :
 C)D →D A)D, but not all equations of the lambda-calculus are validated.
For a closed term ▶ t : A, soundness of typing says that t)D :1 →D A)D, i.e., D1 → A)D, so closed terms are evaluated relative to a contextuated value of the unit type.
In case of general or causal stream functions, an element of D1 is a list over 1, i.e., a natural number, for the time elapsed from the beginning of the history at a moment of interest. Of course it identifies a stream position.

If D is strong or lax symmetric monoidal (not just semimonoidal), we have a canonical choice e :1 → D1. This happens, for example, in the case of the stream comonad for anticausal dataflow computation. This is adequate as all closed terms in an anticausal language must denote constant streams, with the same value at every position. Indeed, there is no way to identify a position with an anticausal computation on no input.
In what sense is this semantics correct? We could compare the generic coKleisli semantics to some other generic semantics, e.g., an operational semantics, if we had one available. Unfortunately this is not the case: generic operational semantics for context-dependent languages is future work for us.
But we can compare the coKleisli semantics of specific languages to their stan- dard denotational semantics. Here we can observe the following. Standard dataflow languages (Lucid, Lustre/Lucid Synchrone) are first-order and here the coKleisli and standard (stream-function) semantics agree fully. How to combine dataflow constructs and higher-orderness has been unclear; various designs have been pro- posed, e.g., Colac¸o et al.’s design with two flavors of function spaces [10]. The coKleisli semantics offers a neat design motivated by mathematical considerations, namely imitation of closed structure.


Precise comonads for dataflow computation and tree transformations
Several of notions of context that we looked at do not correspond to strong symmet- ric monoidal comonads. Rather, they correspond to lax symmetric semimonoidal comonads, for the reason that m should morally be partial and the total version fails to be an isomorphism and rules out the existence of a cohering e. Here indexing in the form of use of comonads on presheaf categories can help.
Consider the case of causal dataflow. Instead of the lax symmetric monoidal comonad on Set we could work with a more refined strong symmetric monoidal comonad on [N, Set], where N is the set of natural numbers (seen as a discrete category).
We define:

(DA)n =df  Aj
j=0

(εA)n :	(DA)n	→	An
(a0,..., an) '→	an
(δA)n :	(DA)n	→	 n  (DA)j
(a0,..., an) '→ ((a0),..., (a0,..., an))
The fby operation can be defined for those A which extend to a functor ω → Set
where ω is the poset of natural numbers: we need to be able to delay stream

elements. Constant sets are typical examples.
(fbyA)n :	A0 × (DA)n	→	An
(a00, (a0))	'→	a00
(a00, (a0,..., an, an+1)) '→ An→n+1 an

(By m → n we denote the map that is there, if m ≤ n.) All of the above are same definitions as for the causal dataflow comonad defined before, except that we are “typed” by the positions in the single shape that streams can have.
This comonad is unproblematically strong symmetric monoidal in the right way, with e and m defined by
en :	1	→	(D1)n
()	'→	((),..., ())
`n+1˛t¸imesx
(mA,B)n :	(DA)n × (DA)n	→	(DA)n
((a0,..., an), (a' ,..., a' )) '→ ((a0, a' ),..., (an, a' ))
0	n	0	n
A closed term in a causal dataflow language now denotes a natural transforma- tion D1 → A where 1 ∼= D1. The nth component is thus an element of An, i.e., the term denotes an element of An for any position n. Of course typical base types would be constant: Kn =df K.
A similar treatment is possible for general dataflow computation and for bottom- up and general tree relabelling. In the case of trees, the indexing is by a pair of a shape and position.
Discussion
Brookes, Geva and Van Stone’s computational comonads
Brookes and Geva’s [8] original example of comonadic computation was inten- sional semantics. In its simplest form it is this: As the base category we use the category ωCpo of ω-cpos and ω-continuous functions. The ω-cpo DA is given by ω-chains of elements of an ω-cpo A, partially ordered pointwise. The counit com- putes the limit of an ω-chain. The multiplication sends an ω-chain to the ω-chain of its prefixes (seen as ω-chains by repeating the last element).
Notably, this is very similar in spirit to the comonad D on Set given by nonempty lists, for causal dataflow, except that nonempty lists are finite sequences and they do not have to be chains wrt. some partial order.
The data and laws of computational comonads were slightly different from those of symmetric (semi)monoidal comonads. Most notably, instead of e : 1 → D1, they had a natural transformation η with components ηA : A → DA, required to form a uniform Eilenberg-Moore coalgebra structure on all objects A. The natural transformations m and s (“merge” and “split”) were governed by laws similar, but

not fully identical or equivalent to those of a lax and oplax symmetric semimonoidal comonad.

Coproducts and recursion
As left adjoints preserve colimits, the Kleisli category of any monad on a co- Cartesian category C inherits the coproducts of C. The coKleisli category of a comonad on a coCartesian category is generally not coCartesian (dually to the case of Kleisli categories and Cartesian structure).
Approximating general recursion (a uniform parameterized fixpoint operation, equivalently a uniform trace operation [14]) of a Cartesian base category in a Kleisli category is a subtle issue that has received considerable attention [12,26,6]. This is an interesting (and non-dual!) problem also in the case of coKleisli categories. Some initial work has been done by N. Frisby in the FP community.
The coKleisli category of the cofree recursive comonad on a functor H, defined by DA =df μX.A×HX, always has a partial uniform parameterized fixpoint operation, alternatively a partial uniform trace operation, implementing guarded recursion. This can also be reformulated in terms of recursive coalgebras, dualizing Milius’s completely iterative algebras [24]. We recall that cofree recursive comonads describe the context-dependence manifested in bottom-up tree relabellings.

Combining effects and context-dependence
It is feasible that a notion of computation combines both effectfulness and context-dependence. Such combinations can correspond to distributive laws of a comonad over a monad in which case the category of impure functions is the bi- Kleisli category of the distributive law. This design appeared already in the work of Brookes and Van Stone [9]. We have applied it to clocked causal dataflow computa- tion, combining causal dataflow and exceptions [34]. Power and Watanabe [32] have given a definitive account of the mathematics of distributive laws between monads and comonads.

Lawvere theories and arrows/Freyd categories
Lawvere theories [27] and arrows/Freyd categories [17,30] 4 are finer and coarser approaches to effectful computation. Lawvere theories make the effectful opera- tions of a notion of effect explicit. Arrows/Freyd categories, generalizing strong monads/their Kleisli categories, were proposed as an axiomatization of notions of impure computation reaching beyond Moggi-style effects.
Similar treatments of context-dependent computation should also be possible; this is an avenue for investigation.
In the direction of Lawvere theories, we would like to proceed from Power and Shkaravska’s [31] analysis of the array comonad (here called the costate comonad) as one generated by a Lawvere cotheory.

4 Jacobs et al. [15,19] have developed a thorough account of the interrelationship of arrows and Freyd categories.

Concerning the other direction, we note that arrows/Freyd categories as such are not a very interesting analysis of context-dependent computation, since any comonad/coKleisli category gives trivially an arrow/Freyd category. While Freyd categories are there to axiomatize the aspects of the Cartesian structure of the base category that must survive in the category of impure computations, for a coKleisli category we know that it is properly Cartesian. The interesting issue is to give a useful axiomatization of the additionally desirable symmetric “preclosed” structure. Freyd categories were not devised for this. Rather, we are after a suitable weakening of the notions of a symmetric closed category `a la Eilenberg and Kelly (closed structure without monoidal structure) and of the adjunction in symmetric monoidal closed structure [11]. We have begun studying this matter with J. Ada`mek and J. Velebil.
Conclusions
We have demonstrated that a number of notions of context-dependent computation admit an analysis using symmetric (semi)monoidal comonads, leading to a system- atic semantics of corresponding languages, analogous in spirit to Moggi’s account of effects in terms of strong monads. Our analysis is not distant from that of Brookes et al., but we have added important new types of examples (notions of dataflow com- putation, tree labelling) and streamlined the specific data and laws for obtaining an approximation of Cartesian closed structure guided by category-theoretic crite- ria of canonicity. The resulting picture is quite elegant, especially with the view that the important examples where the basic comonad is only lax symmetric semi- monoidal can be reworked into examples of strong symmetric monoidal comonads using appropriate indexing.
Recursion (both general recursion and guarded recursion) and finer and coarser alternatives to comonads analogous to Lawvere theories and arrows are important special topics that we plan to address elsewhere. Likewise we defer to future research the study of computational uses of comonad resolutions other than the coKleisli resolution and generic operational semantics of context-dependent languages.
Acknowledgement
We are grateful to Thorsten Altenkirch, Bart Jacobs, Paul Levy, Conor McBride, Marino Miculan for useful discussions.
This work was partially supported by the Estonian Science Foundation grant no. 6940 and by the EU FP6 IST coordination action TYPES.

References
Abbott, M., T. Altenkirch, and N. Ghani, Containers: constructing strictly positive types, Theor. Comput. Sci. 342(1) (2005), pp. 3–27.
Aczel, P., J. Ad`amek, S. Milius, and J. Velebil, Infinite trees and completely iterative theories: a coalgebraic view, Theor. Comput. Sci. 300(1–3) (2003), pp. 1–45.


Ashcroft, E. A. and W. W. Wadge, “LUCID, the Dataflow Programming Language,” Academic Press, 1985.
Benton, N., G. Bierman, V. de Paiva, and M. Hyland, Linear lambda-calculus and categorical models revisited, in: E. B¨orger et al., eds, “Proc. of 6th Wksh. on Computer Science Logic, CSL ’92,” Lect. Notes in Comput. Sci. 702, Springer, 1993, pp. 61–84.
Benton, N., J. Hughes, and E. Moggi, Monads and effects, in: G. Barthe, P. Dybjer, L. Pinto, J. Saraiva, eds., “Advanced Lectures from Int. Summer School on Applied Semantics, APPSEM 2000,” Lect. Notes in Comput. Sci. 2395, Springer, 2002, pp. 42–122.
Benton, N. and M. Hyland, Traced premonoidal categories, Theor. Inform. and Appl. 37(4) (2003),
pp. 273–299.
Bierman, G. and V. de Paiva, On an intuitionistic modal logic, Studia Logica 65(3) (2000), pp. 383–416.
Brookes, S. and S. Geva, Computational comonads and intensional semantics, in: M. P. Fourman, P. T. Johnstone, and A. M. Pitts, eds., “Applications of Categories in Computer Science,” London Math. Society Lecture Note Series 177, Cambridge Univ. Press, 1992, pp. 1–44.
Brookes, S. and K. Van Stone, “Monads and comonads in intensional semantics,” Techn. Report CMU- CS-93-140, School of Comput. Sci., Carnegie Mellon Univ., 1993, 41 pp.
Cola¸co, J.-L., A. Girault, G. Hamon, and M. Pouzet, Towards a higher-order synchronous data-flow language, in: “Proc. of 4th ACM Int. Conf. on Embedded Software, EMSOFT’04,” ACM Press, 2004,
pp. 230–239.
Eilenberg, S. and G. M. Kelly, Closed categories, in: “Proc. of Conf. on Categorical Algebra (La Jolla, 1965),” Springer, 1966, pp. 421–562.
Erk¨ok, L. and J. Launchbury, Recursive monadic bindings, in: “Proc. of 5th ACM SIGPLAN Int. Conf. on Functional Programming, ICFP ’00,” ACM Press, 2000, pp. 174–185.
Halbwachs, N., P. Caspi, P. Raymond, and D. Pilaud, The synchronous data flow programming language LUSTRE, Proc. of IEEE 79(9) (1991), pp. 1305–1320.
Hasegawa, M, The uniformity principle on traced monoidal categories, in: R. Blute, P. Selinger, eds., “Proc. of 9th Conf. on Category Theory and Computer Science, CTCS ’02,” Electron. Notes in Comput. Sci. 69, Elsevier, 2003, pp. 137–155.
Heunen, C. and B. Jacobs, Arrows, like monads, are monoids, in: S. Brookes, M. Mislove, eds., “Proc. of 22nd Ann. Conf. on Mathematical Foundations of Programming Semantics, MFPS XXII,” Electron. Notes in Theor. Comput. Sci. 158, Elsevier, 2006, pp. 219–236.
Huet, G., The zipper, J. of Funct. Program. 7(5) (1997), pp. 549–554.
Hughes, J., Generalising monads to arrows, Sci. of Comput. Program. 37(1–3) (2000), pp. 67–111.
Hyland, M., G. Plotkin, and J. Power, Combining effects: sum and tensor, Theor. Comput. Sci. 357(1– 3) (2006), pp. 70–99.
Jacobs, B. and I. Hasuo, Freyd is Kleisli, for arrows, in: C. McBride, T. Uustalu, eds., “Proc. of Wksh. on Mathematically Structured Functional Programming, MSFP 2006,” Electron. Wkshs. in Computing, BCS, 2006, 13 pp.
Kieburtz, R. B., Codata and comonads in Haskell, unpublished manuscript, 1999.
Knuth, D., Semantics of context-free languages, Math. Syst. Theory 2(2) (1968), pp. 127–145. Corrigendum, ibid., 51(1) (1971), pp. 95–96.
Lewis, J. R., M. B. Shields, E. Meijer, and J. Launchbury, Implicit parameters: dynamic scoping with static types, in: “Proc. of 27th ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, POPL ’00,” ACM Press, 2000, pp. 108–118.
McBride, C., The derivative of a regular type is the type of its one-hole contexts, manuscript, 2000.
Milius, S., Completely iterative algebras and completely iterative monads, Inform. and Comput. 196(1) (2005), pp. 1–41.
Moggi, E., Notions of computation and monads, Inform. and Comput. 93(1) (1991), pp. 55–92.
Moggi, E. and A. Sabry, An abstract monadic semantics for value recursion, Theor. Inform. and Appl.
38(4) (2004), pp. 375–400.


Plotkin, G. and J. Power, Semantics for algebraic operations, in: S. Brookes, M. Mislove, eds., “Proc. of 17th Conf. on Mathematical Foundations of Programming Semantics, MFPS-XVII,” Electron. Notes in Theor. Comput. Sci. 45, Elsevier, 2001, pp. 332–345.
Plotkin, G. and J. Power, Computational effects and operations: an overview, in: M. H. Escard´o,
A. Jung, eds., “Proc. of Wksh. on Domains VI,” Electron. Notes in Theor. Comput. Sci. 73, Elsevier, 2004, pp. 149–163.
Pouzet, M., Lucid Synchrone, version 3: tutorial and reference manual, unpublished manuscript, 2006.
Power, J. and E. Robinson, Premonoidal categories and notions of computation, Math. Structures in Comput. Sci. 7(5) (1997), pp. 453–468.
Power, J. and O. Shkaravska, From comodels to coalgebras: state and arrays, in: J. Ad´amek, S. Milius, eds., “Proc. of Wksh. on Coalgebraic Methods in Comput. Sci., CMCS 2004,” Electron. Notes in Theor. Comput. Sci. 106, Elsevier, 2004, pp. 297–314.
Power, J. and H. Watanabe, Combining a monad and a comonad, Theor. Comput. Sci. 280(1–2) (2002),
pp. 137–162.
Uustalu, T. and V. Vene, The dual of substitution is redecoration, in: K. Hammond, S. Curtis, eds., “Trends in Functional Programming 3,” Intellect, 2002, pp. 99–110.
Uustalu, T. and V. Vene, The essence of dataflow programming (full version), in: Z. Horv´ath, ed., “Revised Selected Lectures from 1st Central-European Functional Programming School, CEFP 2005,” Lect. Notes in Comput. Sci. 4164, Springer, 2006, pp. 135–167.
Uustalu, T. and V. Vene. Comonadic functional attribute evaluation, in: M. van Eekelen, ed., “Trends in Functional Programming 6,” Intellect, 2007, pp. 145–162.
