

Electronic Notes in Theoretical Computer Science 225 (2009) 341–360
www.elsevier.com/locate/entcs

A Random Bag Preserving Product Operation
Michel Schellekens 1,2
Department of Computer Science/CEOL National University of Ireland, Cork 3

Abstract
The author’s current research programme is the development of a modular calculus for the average-cost of data structuring. This modular calculus provides a novel foundation for the analysis of algorithms. Its applicability to the analysis of algorithms has been demonstrated at the Center for Efficiency-Oriented Languages (CEOL) through the design of the novel programming language MOQA and the associated average-case analysis tool DISTRI-TRACK [8,4,5,2,3]. Modular computations of the average cost of data
structuring are possible through the fundamental notion of random bag preservation. Random bag preserv- ing operations enable the constructive tracking of the data and the distribution of the data states during a MOQA computation. This in turn enables the (semi-)automated derivation of the average cost of the operations. Two fundamental MOQA operations enable the creation and destruction of data structures: the MOQA product operation, which is the subject of this paper, and the MOQA delete operation, which forms the subject of [3]. The introduction of the entire MOQA language is well beyond the scope of this
paper and will be reported in a book [2]. The language has been implemented at CEOL and automated derivations of average-cost of data structuring are under way. Here we report on a (simplified) version of the fundamental notion of random bag preservation and demonstrate that the central MOQA product operation possesses this crucial property.
Keywords: Algorithms, Random Bags, Compositionality, Modularity, Languages.


Introduction
MOQA is a domain specific high-level language. The language has extensive pro- gramming capacity in the sense that it includes for-loops, (terminating) recursion and conditionals. This approach enables the programming of a wide variety of data restructuring algorithms, including most sorting and searching algorithms.
The crucial property of MOQA is that it preserves “regularity” in a certain way during its operations. This regularity is captures by the notions of random structures and random bags.  All MOQA operations are guaranteed to preserve

1 Science Foundation Ireland Principal Investigator, 07/IN.1/I977
2 Email: m.schellekens@cs.ucc.ie
3 Centre for Efficiency-Oriented Languages

1571-0661/© 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.12.085

random bags. This enables the tracking of data structures during the computations, which in turn facilitates the modular derivation of the average-case time of MOQA programs.
We focus on the product operation in this paper since the operation serves two purposes: first it enables one to insert an element (“data structure of cardinality one”) into a data structure and second, in general, it enables the merging of two data structures into a larger one. Such an operation arises for instance in Insertion Sort or Merge sort. The operation is formulated in such a way here that it applies to data structures determined by arbitrary finite partial orders, incorporating a very wide variety of data structures.

States and Random Structures
We proceed with formal definitions. The first one defines the concept of a state. Note that L forms a set of labels, which we consider to be a subset of the natural numbers equipped with their standard order, (N, ≤).
Definition 2.1 A labeling of a finite partial order (X, ±) from the countable set of labels N is an increasing injection from X to N , paired with the partial order (X, ±). A state of a finite partial order (X, ±) from a set of labels L, where |X| = |L|, is an increasing injection F : X → L, paired with the partial order (X, ±).
Note that we consider two labelings, say (F1, (X, ±1)) and (F2, (X2, ±2)), to be different when their underlying partial orders differ. This includes the case where X1 = X2 and where ±1 and ±2 differ, but where the functions F1 and F2 coincide. In practice, and with abuse of notation, when the underlying partial order is unambiguous, we will refer to a labeling F as opposed to a state (F, (X, ±)).
Of course, it follows from the above definition that states are bijections from X
to L.
Omitting the order in the following notations consists of a slight abuse of nota- tion, which will not cause ambiguities in the work. Let (X, ±) be a finite partial order. We let m(Y ) denote the set of minimal elements of (Y, ±) and M (Y ) denote the set of maximal elements of (Y, ±). Let F be a state of this partial order. We let m(F ) denote the labels for F of minimal elements of (X, ±), i.e. F (m(X)), and we let M (F ) denote the labels for F of maximal elements of (X, ±), i.e. F (M (X)). For any subset A of the set of labels L, we let m(A) denote the labels in A of minimal elements of (F−1(A), ±), i.e. F (m(F−1(A))), and we let M (A) denote the labels for F of maximal elements of (F−1(A), ±), i.e. F (M (F−1(A))). Finally we use the following notation: ∨A denotes the maximum label of the set A while ∧A denotes the minimum label of A.
Remark 2.2 It is quite evident that the greatest (least) label of a state must occur at a maximal (minimal) element.
Definition 2.3 The Random Structure on a finite partial order (X, ±), with respect to a set of labels L where |X| = |L|, is the set of all states from L of the partial

order. We denote this random structure by: RL(X, ±).


Notation: We frequently denote a random structure RL(X, ±) by R and in that case refer to the underlying set X and set of labels L as XR and LR.
We remark that the definition of a random structure does not require the un- derlying partial order to be connected.

Remark 2.4 Random structures, RL1 (X, ±) and RL2 (X, ±), of a given partial or- der (X, ±) and obtained for two different sets of labels, L1 and L2, can easily be seen to be label-isomorphic, i.e. there exists an order preserving bijection Ψ(L1,L2) from the linear order (L1, ≤) to the linear order (L2, ≤), where ≤ is the usual order on the natural numbers, such that RL2 (X, ±) = {Ψ(L1,L2) ◦ F| F ∈ RL1 (X, ±)}. So if L1 = {a1,..., an} and L2 = {b1,..., bn} where ∀i ∈ {1,...,n − 1}. ai < ai+1 and bi < bi+1 then ∀i ∈ {1,..., n}. Ψ(L1,L2)(ai) = bi. We refer to the unique equiva- lence class for the equivalence relation “label-isomorphic” as the random structure R(X, ±) of a partial order (X, ±), where the label set L is no longer indicated.


It is easy to see that random structures allow one to incorporate traditional labeled data structures, such as heaps, unordered lists and sorted lists, as long as the labelings respect the underlying order. We illustrate this in the next example, where for each data structure, i.e. partial order, all possible data states are represented.

Example 2.5 In each part of the example, we display the Hasse Diagram of the given partial order on the left and the states on the right. In each case the underlying set consists of elements {x1,..., xn}, while the labels are the set of indices {1,..., n}. Part a) illustrates that random structures incorporate the case of lists in a natural way.
Consider the partial order (X, ±) over the set {x1, x2,..., xn} equipped with the discrete order. The random structure RL(X, ±) consists of all n! permutations of labels on the elements of X and can be interpreted as the set of lists of size n. We will denote in the following such a random structure by An where A stands for “Atomic”.


	
x1	x2
... 
x3

	
xn−1 xn

The probability for labelings to be in one of these states is  1 .
Consider the partial order (X, ±) over the set {x1, x2,..., xn} equipped with a linear order. The random structure RL(X, ±) consists of a single state, denoted by Sn, which can be interpreted as the sorted list.

xn xn−1


x3 x2
x1
n n-1

3

2
1

The probability for a labeling over this partial order to be in this state is 1.
Finally, we remark that heaps can be represented as random structures over a partial order which has a tree as Hasse Diagram. Heaps of size n are denoted by Hn. For instance, the random structure H3 determined by the following Hasse Diagram and label set {1, 2, 3, 4} consists exactly of the states H4[1], H4[2] and H4[3] displayed below.
x4





x2	x3




x1
4	4	4



2	3	3


1	1
2	3	1


2

The probability for a labeling to be in one of these states is 1 .
Similarly, Heap Ordered Trees in general can be represented in this way.
It is obvious that the cardinality of Random Structures over partial orders with
n elements lies between 1 and n! included.


Floor and Ceiling Functions
We introduce “floor” and “ceiling” functions for elements of partial orders, which will be useful to specify the pseudo-code for our product operation. For a partial

order (X, ±) and an element x ∈ X, we define [x| to be the set of all elements immediately and strictly above x, i.e. [x| = {y| y N1 x}. Similarly, we define: [x♩ = {y| y и1 x}. For a discrete subset Y of X, we define: [Y | = ∪y∈Y [y| and [Y ♩ = ∪y∈Y [y♩. Given a state F with range L, the floor and ceiling of a label a ∈L and of a set of labels, is defined as follows: [a| = F ([F−1(a)|), [a♩ = F ([F−1(a)♩). For a subset A of L we define: [A| = F ([F−1(A)|), [A♩ = F ([F−1(A)♩). Of course: a ∈ [b|⇒ a > b and a ∈ [b♩⇒ a < b.

Random Structure and Random Bag preserving func- tions
The notion of Random Structure Preservation involves the notion of a random bag which is defined below.
Definition 4.1 A random bag is a finite bag of pairs, {(R1, K1),..., (Rn, Kn)}, each of which consists of a random structure R paired with a multiplicity K.
Remark 4.2 In case n = 1 and K = 1 we identify the random bag with the random structure R1. i.e. we interpret a random structure in the context of random bags as a random bag of size one and multiplicity one.
We will define operations that transform a random structure RL(X, ±) into a bag of random structures {(RL1 (X1, ±1), K1),..., (RLn (Xn, ±n), Kn)}, where
∀i ∈ {1,..., n}. Li ⊆ L.

Such operations will be called random bag preserving operations, or RB-preserving operations. The label sets Li are subsets of the original label set L since the deletion operation which we will consider may remove some labels.
We introduce the notion of a reﬁnement in the following. Random Bag Preserv-
ing operations “refine” the original partial order in that the newly created partial orders of the resulting collection have underlying sets Xi that are subsets of the original set X and have orders ±i that are finer than, i.e. include, the restriction of the original partial order ± to the new set Xi under consideration. We formalize this below.
Definition 4.3 Let R = RL(X, ±) and ∀i ∈ {1,..., n}. Ri = RLi (Xi, ±i), where
∀i ∈ {1,..., n}. Li ⊆L and ∀i ∈ {1,..., n}. Xi ⊆ X and ∀x, y ∈ Xi.x ± y ⇒ x ±i
y. We call any collection of random structures {R1,..., Rn} satisfying this condition a reﬁnement of the random structure R. We also refer to Li as a refinement of the label set L and to each (Xi, ±i) as a refinement of the partial order (X, ±).
Remark 4.4 (For the Semantics oriented reader) One can verify that the class of Random Bags with the refining order form a CPO.
Summary 1 We use the following notation: U , referred to as the universe, is a countable list of variables, say U = {un| n ∈ N}. We denote the set of all finite

partial orders over U by

POfin(U ) = {(X, ±)| X ⊆U and (X, ±) is a finite partial order.}.
The set of all labelings over partial orders from POfin(U ) is denoted by F, i.e.:
F = {F| F : (X, ±) → N, (X, ±) ∈ POfin(U ) and F is a labeling}.
Definition 4.5 A function φ: F → F is reﬁning on R if there exists a refinement
{R1,..., Rn} of R such that φ: R → R1 ∪ ... ∪ Rn is surjective.
The operations we will consider typically transform random structures R into a refinement {R1,..., Rn} of R; more precisely they determine refining functions.
Definition 4.6 In case we have determined a refinement {R1,..., Rn} of R, based on which we can establish that the function φ is refining on R, then we refer to φ in combination with this particular selection of a refinement as a representation for φ. Such a representation is denoted as follows: φ: R → {R1,..., Rn}.
The following definition formalizes the notion of Random Structure Preservation.

Definition 4.7 A function μ: F → F is Random Structure preserving on a random structure R (RS-preserving on a random structure R) iff there exists a partition F1,..., Fn of R, a refinement {R1,..., Rn} of R and non-zero natural numbers K1,..., Kn such that
∀F ∈ Ri.|μ−1(F ) ∩ Fi| = Ki.
The function μ is RS-preserving iff it is RS-preserving on every random structure.
The function μ is called strongly RS-preserving if and only if n = 1.
Note that we will demonstrate that the product operation is strongly RS- preserving.
Remark 4.8 1) Since reﬁning functions are surjective, we have in the above deﬁ- nition automatically that for each i ∈ {1,..., n}. μ(Fi) = Ri.
The deﬁnition of RS-preservation is more general than the informal use of ran- domness preservation in the literature. The informal use of randomness preser- vation only regards the preservation of the uniform distribution, where a random structure is mapped to a single random structure, as is the case for the Backwards Analysis of [7] and for the cases discussed in [6], and no non-trivial multiplicity is involved (i.e. K = 1). This is captured in our context by the notion of a strongly RS- preserving function with multiplicity one. Representations of RS-preserving func- tions in our context, map a random structure to a bag of random structures.
When we have a particular representation in mind for an RS-preserving function, we will, with abuse of terminology, refer to the image of the RS-preserving function as a random bag. In practice of course an RS-preserving function could have more than one representation.

Remark 4.9 It is clear that the deﬁnition of RS-preservation could be simpliﬁed in case the random structures R1,..., Rn have pairwise disjoint underlying partial orders. In that case the deﬁnition is equivalent to the following:
∀F ∈ Ri. |μ−1(F )| = Ki.


Of course, one can always guarantee that the random bag {R1,..., Rn} is such that the underlying partial orders are pairwise disjoint by identifying random struc- tures with the same, i.e. order-isomorphic, underlying partial orders and by ad- justing the multiplicities accordingly. We prefer to keep the more general version of RS-preservation at this time, since identiﬁcation of order-isomorphic partial or- ders in practice in general is costly and the time analysis may not require such an identiﬁcation.
Definition 4.10 In case we have determined a refinement {R1,..., Rn} of R with multiplicities K1,..., Kn with respect to some partition F1,..., Fn, based on which we can establish that the function μ is RS-preserving on R, then we refer to μ in combination with this particular selection of a refinement, partition and multiplic- ities as an RS-representation for μ. Such an RS-representation for μ is denoted as follows:

μ(F1,...,Fn): R → {(R1, K1),..., (Rn, Kn)}.
Summary 2 Typically, and with some abuse of notation, we will not mention the partition involved for RS-representations:

μ: R → {(R1, K1),..., (Rn, Kn)}.
The motivation behind this shorter notation is that once our choice for the re- fining collection, the partition and the corresponding multiplicities have been deter- mined, we only need the resulting random bag in order to determine the average-case time.

The Random Product
The random product is a fundamental MOQA data structuring operation which enables the joining of two data structures into a larger data structure. Here our aim is to illustrate that a random bag preserving product operation can be obtained and we present a proof of this result. Research is ongoing at CEOL on alternative versions of the product and efficiency comparisons. The techniques for verifying ran- dom bag preservation as outlined below are however standard approaches and serve to illustrate that the most common version of the product satisfies this property.
In order to define the random product, we first define the product of two finite partial orders. The definition is similar to the one given in [1]. Then we define the product of two labelings and we extend this definition to sets of labelings. Finally,

we define the random product on a random structure as a unary operation, which performs an operation on two substructures of the given random structure and reproduces a new random structure.


The product of two ﬁnite partial orders

Definition 5.1 Given two finite disjoint partial orders (X1, ±1) and (X2, ±2).

The set X1  X2 is defined to be the union of the disjoint sets X1 and X2. The relation ±1   ±2 is defined to be the least partial order on X1  X2 containing
±1 and ±2 and X1 × X2.

It is easy to verify that the partial order ±1  ±2 is the transitive closure of the binary relations ±1, ±2 and the set of pairs {(M, m)| M is a maximal element of (X1, ±1), m is a minimal element of (X2, ±2).

Example 5.2 If we consider the sets X1 = {x1, x2, x3} and X2 = {x4, x5, x6, x7} then X1  X2 = {x1, x2, x3, x4, x5, x6, x7}. We indicate the new pairs added via the operation  via dashed lines.


















We define the product of two labelings as a first step towards the definition of the random product of two random structures.

The product of two labelings
Let F1,F2 be labelings on finite partial orders (X1, ±1) and (X2, ±2) respectively. We call F1 and F2 disjoint when their domains X1 and X2 are disjoint and their ranges F1(X1) and F2(X2) are disjoint.

Pseudo-code for the product   on labelings
Let F1, F2 be disjoint labelings which are provided as inputs.
We define the product of the two labelings. To avoid technicalities, we assume in the following pseudo-code that the labelings F1 and F2 of which the product is taken are (implicitly) processed first to retrieve a new function F , consisting of the join of the labelings F1 and F2. The creation of F will be indicated in the final pseudo-code for the random product by the initial code line: F = F1 ∪ F2, where we consider the graph union of these functions.
We will also assume the implicit generation of the restrictions of this function F , i.e. F T X1 and F T X2, to the sets X1 and X2 respectively and hence won’t specify the detailed implementation of these restrictions in the pseudo code. The function F and its restrictions F T X1 and F T X2 will freely be referred to in the pseudo-code for P .

The pseudo-code to generate a labeling from F = F1 ∪ F2 is based on a generalization of the procedures Push-Down and Push-Up used in the pseudo-code of the Heapsort Algorithm in Section 2. We will provide pseudo-code for Williams versions of the Push operations and remark that it is straightforward to specify Floyd versions of these procedures 4 . We omit the details but will refer to these generalizations as F-Push-Down and F-Push-Up in the following. We provide pseudo-code for generalized versions of Williams’ Push operations:

W-Push-Down(b, F )
while [b♩ /= ∅ and b < ∨[b♩
swap(b, ∨[b♩,F )

W-Push-Up(a, F )
while [a| /= ∅ and a > ∧[a|
swap(a, ∧[a|,F )

As before, we will use Push-Down and Push-Up freely in the pseudo-code, with- out specifying which version we use since this is a matter of choice of implementa- tion.
We provide the pseudo-code for the Labeling-Product Algorithm where the inputs for the algorithm are the disjoint labelings F1 and F2. We denote the function F returned by the Labeling-Product algorithm as F1  F2.

4 Cf. [9] for a discussion of both versions.

Pseudo-code for the Labeling-Product Algorithm

F := F1 ∪ F2;
while ∨M (F T X1) > ∧m(F T X2) do
a := ∨M (F T X1); b := ∧m(F T X2);
swap (a, b, F );
Push-Down(b, F );
Push-Up(a, F )
Return F






Lemma 5.3 If F1 and F2 are disjoint labelings then F1  F2 is a labeling.



Proof. This follows via straightforward yet technically lengthy verifications from the pseudo-code of the random product algorithm. We omit the details.	 




Example 5.4 In the example given below, we consider two labelings F1 and F2 for the partial orders displayed below and illustrate the steps involved in executing the Labeling-Product algorithm.












	











We indicated the selection of labels of extremal elements by full circles and these elements occur swapped in the following picture. For each while loop execution, initiated by an original swap of labels of two extremal elements, the other pairs of elements to be swapped are linked in the picture via a double arrow (in dashed line display). These elements occur swapped in the picture. The final picture illustrates the end result of the computation, i.e. F1  F2.
Definition 5.5 Let L1 and L2 be disjoint sets of labels. The label-product function
   : RL1 (X1, ±1) × RL2 (X2, ±2) → RL1∪L2 (X1 ⊗ X2, ±1 ⊗ ±2)
is defined by:  (F1, F2) = F1  F2.
The following result is important to obtain that the Random Product is an RS-preserving operation.
Theorem 5.6 The label-product function is a bijection.
Proof. Consider two disjoint partial orders (X1, ±1) and (X2, ±2).
We present a proof for Williams’s versions of the Push operations. The proof for Floyd’s version is similar.
We view the execution of the labeling product algorithm as a series of swaps along chains of X1  X2. For a given pair of disjoint labelings, F1 and F2, each such chain is determined by a single run of the two push operations in the code of
the random product. We recall that at the start of the while loops, labels a and b are involved in the swaps, where in terms of the pseudo-code, a = ∨M (F T X1) and b = ∧m(F T X2). We refer to these labels as the extremal labels. The label b is swapped downwards along a unique chain in the partial order (X1, ±1) labeled by F1 and a is swapped upwards along a unique chain in the partial order (X2, ±2)

labeled by F2. The result of appending these two paths forms a chain in the product partial order (X1  X2, ±1  ±2).We will show that each such swap sequence along such a unique chain is injective. It follows that the labeling-product function  is injective.

In order to show the result, we assume that we have two labelings F1, F1 of the
partial order (X1, ±1) and two labelings F2,F' of the partial order (X2, ±2) such
that F1 and F2 are disjoint, F' and F' are disjoint and F1   F2 = F'   F'. We
1	2	1	2
show that F1 = F' and F2 = F'.
1	2
We will display the labels on the chain determined by the swap sequence arising from the call to F1  F2, by:
[a1, a2,..., am], [b1, b2,..., bk],
where (a, b) is the first pair which is swapped by the algorithm, am = a, b1 = b, the sequence [a1, a2,..., am] consists of the labels in the labeled partial order (X1, ±1
, F1) which are respectively swapped with b and the sequence [b1, b2,..., bk] consists
of the labels in the labeled partial order (X2, ±2, F2) which are respectively swapped with a.
In the above, we allow the case where m = 0 and k = 0, i.e. no swap occurs.
Similarly,we display the labels on the chain determined by the swap sequence arising from the call to F'  F', by:

1	2
[a' , a' ,..., a' ], [ '	'
'],

1	2	n
b1, b2,..., bl

where (a', b') is the first pair which is swapped by the algorithm, a' = a', b' =
b', the sequence [a' , a' ,..., a' ] consists of the labels in the labeled partial order
1	2	m
(X , ± ,F') which are respectively swapped with b' and the sequence [ '	'	' ]

1	1	1
b1, b2,..., bk

consists of the labels in the labeled partial order (X2, ±2,F') which are respectively
swapped with a'.
In the above, we again allow the case were n = 0 and l = 0, i.e. no swap occurs. We remark that Ra(F1) = Ra(F') = L1 and that Ra(F2) = Ra(F') = L2. This
1	2
implies that a = a' and b = b'.
We show that a = a'. The case b = b' is similar. The algorithm selects the maximal label a at depth 0 in the labeled partial order (X1, ±1, F1) and the maximal label a' in the labeled partial order (X1, ±1,F'). Since Ra(F1) = Ra(F') = L1 and
1	1
labelings are increasing, we know that the maximum label of L1 must occur as a label of a maximal element and thus a = a' = maximum(L1).
We remark that this fact does not alter, even after the first two push operations in the algorithm have been run through a number of times. Inductively one can show that Ra(F1) = Ra(F') remains true. Indeed, in case a < b no swaps will occur and the result holds trivially. Otherwise, after the first series of swaps has happened for the first two while loops, we obtain that in Ra(F1), the label a simply
has been replaced by the label b and in F' the same has taken place. Hence we
preserve the fact that the ranges of the respective labelings coincide, which suffices

to yield the desired property.
It follows by the fact that a = a' and b = b' at the start of each swap sequence, the number of non-trivial swap sequences induced by F1 F2 is identical to the number of non-trivial swap sequences induced by F'  F'.
Hence we can focus on the last swap sequences induced by F1  F2 and F'  F'
respectively and assume that both swap sequences, by the above, must start with a swap on the same pair of elements, a and b. Since the labelings of course have changed during the previous swap sequences, we denote the labelings at the start
of the final swap sequences by G1, G2 and G' , G' respectively.
1	2
Consider these final chains along which the labels are swapped, i.e. the chain
[G−1(a1), G−1(a2),..., G−1(am)], [G−1(b1), G−1(b2),..., G−1(bk)]

1	1
and the chain
1	2	2	2

[(G' )−1(a' ), (G' )−1(a' ),..., (G' )−1(a' )], [(G' )−1(b' ), (G' )−1(b' ),..., (G' )−1(b')].
1	1	1	2	1	n	2	1	2	2	2	l
To show injectivity for the final swap sequences, it suffices that these chains must be identical.
Indeed, assume that these paths are the same, say a path denoted by P . Since
F1  F2 = F'   F' and the swap sequence on P does of course not affect labels
of X1 — P , the labelings G1 and G' must coincide on the set X1 — P . Moreover,
since the net result of the Push-Down operation is to move the label of the maximal element of P to the element originally labeled with b in F2 and to move every other label of an element of P to the element immediately above it on P , we obtain that G1 must be identical to G' .
We claim that it is always the case that the swap sequences corresponding to b
must be the same for G1 and G' and hence, by the above, the final swap operations
form an injective operation.
We recall that since F1  F2 = F'  F', we must have that at the end of both
Push-Down operations the label b is a label of the same element in the partial order. We assume by way of contradiction that the paths are not identical and hence diverge at one point. Because b must end up at the end of the final swap sequences in the same position, we know there is a first time, after the sequences diverge, that the label b ends up as a label of the same element z of X. Say that prior to these
swaps we had: H−1(x) = b and H'−1(y) = b where x /= y and where H1 and H' are
1	1	1
the labelings obtained from G1 and G' by carrying out the swaps on G1 and G' up

to the point prior to the first convergence of the paths.
We clarify the situation for both labelings H1 and H'

in the following figure.

In H1 the label b will be swapped with a label α while in H' the label b will be
swapped with a label β.
Since after these swaps the labels of x and y will not be changed again, the labels as displayed in the figure below, are the only ones possible in order to guarantee that the final results of the Push-Down calls are identical.

x	y	a−	β	α	a−
z	α	β
We now obtain a contradiction since from labeling H1 it is clear that α < β 
while from labeling H' we obtain that β < α.
Hence we cannot have divergence of the path and the result follows.
Since the same argument holds for a, we obtain that both swap paths must be identical.
The proof can now be concluded by an inductive argument remarking that the same must hold for every pair of swap sequences, when run through in reverse order of their occurrence. Since on elements outside the swap paths, no labels are
ever swapped, we obtain that F1 = F' and F2 = F'.
1	2
Finally we need to verify that the label-product function is surjective. It suffices
to verify that |RL1 (X1, ±1)|× |RL2 (X2, ±2)| = |RL1∪L2 (X1  X2, ±1   ±2)|.
We remark that |RL1∪L2 (X1  X2, ±1   ±2)| = |R ' (X1, ±1)|× |R ' (X2, ±2)|,
L1	L2
where L' consists of the first |X | elements in the sorted version of L while L
1	2
consists of the last |X2| elements in the sorted version of L. This follows by the fact
that the sets X1 and X2 are completely connected in the partial order (X1  X2, ±1
  ±2). Since we can identify labelings up to order-isomorphism, it is clear that
|RL1 (X1, ±1)| = |R ' (X1, ±1)| and that |RL2 (X2, ±2)| = |R ' (X2, ±2)|. Hence the
L1	L2
result follows.


We obtain the following immediate corollary.
Corollary 5.7 Let L1 and L2 form a partition of the set of labels L. Then:
|RL(X1 ⊗ X2, ±1 ⊗ ±2)| = |RL1 (X1, ±1)|× |RL2 (X2, ±2).|
Example 5.8 In the example on pages 14 and 15, we illustrate that the creation of the random product of labelings is an injective process. We do not display all cases, but restrict our attention to the case of a ﬁxed set of labelings which can be used on the ﬁrst partial order ({1, 2, 3, 4}) and a ﬁxed set of labelings which can be used on the second partial order ({5, 6, 7}). It is easy to verify that the number of possible combinations of labelings for the given partial orders from the set of labels
{1, 2, 3, 4, 5, 6, 7} is 7 × 5 × 2 = 350, which prevents a complete illustration of all
cases. The ﬁrst ﬁve combinations of pairs of labelings are displayed in bold design at the top of the following page, followed by the computation steps, while the next ﬁve combinations are displayed again on the next page in bold design, followed by the computation steps.
We define the binary random product below, which may be the first type of

product that comes to mind, followed by the unary random product which is the one that will be used in the applications.



The binary random product

Definition 5.9 Let RL1 (X1, ±1) and RL2 (X2, ±2) be two disjoint random struc- tures. We define the binary random product , RL1 (X1, ±1)  RL2 (X2, ±2), by RL1∪L2 (X1  X2, ±1   ±2).

Lemma 5.10 The binary random product is RS-preserving.

Proof. This follows directly from Theorem 5.6.



Remark 5.11 The binary random product leads to complications regarding the de- termination of average-time. Indeed, the binary random product has an average time which is a function of the label sets L1 and L2. Consider the case where the set L1 happens to consist of labels which are smaller than the least label of L2. In this case the binary random product will require no push-downs nor push-ups.

At the other extreme, consider label sets L'
and L'
for which the labels of L'
are

greater than the largest label of L' . In that case clearly the binary random product
RL' (X1, ±1)   RL' (X2, ±2) will require many push-down and push-up operations.
Hence its average time will be strictly greater in general than the average time of RL1 (X1, ±1)  RL2 (X2, ±2). The dependency of the binary product operation on the label sets involved leads to complications regarding the determination of its aver- age time. Hence the MOQA language does not contain the binary random product at this stage. Instead we include the unary random product as described below, which avoids the above problem and for which formulas have been derived expressing the average-case time. There is always the option to include the binary random product operation and let the analysis tool return a black-box type message for this particular operation, where the user needs to supply their own time analysis for this particular operation. Such an approach 5




5 Continued on page 16


				









				







may be feasible for simple data structures or for the case where the tool is extended with a method to directly compute the average-case time for bounded data structure size through dynamic analysis of the binary random product.


The unary random product
We describe the unary random product which has been implemented in MOQA- Java at CEOL. This type of product is useful in implementations which involve the joining of data structures, such as for instance for the merge operation in the Mergesort algorithm and the insertion operation in the Insertion sort algorithm.

Definition 5.12 Consider a random structure R(X, ±) and distinct components I1 and I2 of X. We define the unary random product of the partial order (X, ±) with respect to components I1, I2 of X to be the partial order (X, ±I1 N I2 ) where
±I1 N I2 is the least partial order containing ± ∪ ((±T I1)  (±T I2)).
We define the unary random product to be the function:

μI1 N I2 (X): R(X, ±) → R(X, ±I1 N I2 )

where ∀F ∈ R(X, ±). μI1 N I2 (X, I)(F ) T(I1  I2) = (F T I1)  (F T I2) and
μ(F ) T (X — (I1 ∪ I2)) = F T(X — (I1 ∪ I2)).

Theorem 5.13 Consider a random structure R(X, ±) and distinct components I1 and I2 of X. The unary random product μI1 N I2 (X) is RS-preserving with multi- plicity |I1|+|I2| .
Proof. We sketch the proof. Let L be a set of labels for I1 ∪ I2. From Corol- lary 5.7 we obtain that for any partition (L1, L2) of L: |RL(I1  I2, ±1   ±2
)| = |RL (I1, ±1)|× |RL (I2, ±2)|. The result follows since there are  |I1|+|I2|  such
1	2	|I1|
partitions.	 

We remark that we can extend the unary random product to operate on random sub-structures of a given random structure as outlined in [2]. The details are tech- nical and are omitted here. Suffices it to say that in case the unary random product is applied to a so-called isolated subset of a partial order, the operation is still guar- anteed to be RS-preserving. This is illustrated in the example below. Again, we do not provide the formal definition of an isolated subset due to space restrictions. The increased generality of the application of the operations greatly increases its use in the MOQA language. The reader is referred to [2] for a comprehensive discussion.
We provide an example of the unary random product.
Example 5.14 Consider the Hasse Diagram of the following tree:

x5





x4





I

We display the eight labelings of the tree, where we selected the two leaves at the deepest level, i.e. x1 and x2, to form the atomic isolated subset I and labels for this set have been indicated as below.




We apply the unary random product to the isolated subset I = {x1, x2} and we use the components I1 = {x1} and I2 = {x2}. The result is displayed below. The
multiplicity involved is |I1+I2| = 2 = 2. Indeed, we obtain two copies of a random
|I1|	1
structure, a ﬁrst copy consisting of the labelings marked by (I), i.e. the labelings with odd indices, and a second copy consisting of the labels marked by (II), i.e. the labelings with even indices.


	



References
B. A. Davey, H. A. Priestley, Introduction to Lattices and Order, Cambridge University Press, 1990.
M. Schellekens, A Modular Calculus for the Average Cost of Data Structuring, Springer book to appear, 250 pages, May 2008 (to appear).
M. Schellekens, Compositional Average-Case Analysis, preprint, under review, 2006.
M. Boubekeur, D. Hickey, J. Mc Enery and M. Schellekens, A new Approach for Modular Average-Case Timing of Real-Time Java Programs, Accepted for publication in WSEAS Transactions on Computers, 2007.
M. Boubekeur, D. Hickey, J. Mc Enery and M. Schellekens, Towards Modular Average-Case Timing in Real-Time Languages: An Application to Real-Time Java, Accepted for publication on the 6th WSEAS International Conference on APPLIED COMPUTER SCIENCE (ACS’06), Tenerife, December, 2006.
S. Edelkamp. Weak-Heapsort, ein schnelles sortierverfahren. Diplomarbeit Universit¨at Dortmund, 1996.
D. Knuth, The art of computer programming vol.3, Addison-Wesley, 1973.
M.Schellekens, D. Hickey and G. Bollella, ACETT, a Linearly-Compositional Programming Language for (semi-)automated Average-Case analysis, IEEE Real-Time Systems Symposium - Work In Progress Session, 2004.
M. Li and P. Vitanyi. An introduction to Kolmogorov Complexity and its applications, Texts and Monographs in Computer Science. Springer Verlag, 1993.
