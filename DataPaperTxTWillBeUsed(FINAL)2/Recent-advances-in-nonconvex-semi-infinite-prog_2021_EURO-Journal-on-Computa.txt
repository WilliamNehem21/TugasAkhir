EURO Journal on Computational Optimization 9 (2021) 100006

		




Recent advances in nonconvex semi-infinite programming: Applications and algorithms
Hatim Djelassi a, Alexander Mitsosa, Oliver Steinb,∗
a Process Systems Engineering (AVT.SVT), RWTH Aachen University, Aachen, Germany
b Institute of Operations Research, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany


a b s t r a c t

The goal of this literature review is to give an update on the recent developments for semi-infinite programs (SIPs), approximately over the last 20 years. An overview of the different solution approaches and the existing algorithms is given. We focus on deterministic algorithms for SIPs which do not make any convexity assumptions. In particular, we consider the case that the constraint function is non-concave with respect to parameters. Advantages and disadvantages of the different algorithms are discussed. We also highlight recent SIP applications. The article closes with a discussion on remaining challenges and future research directions.



Introduction

This article reviews recent developments in theory, applications and algorithms for nonconvex semi-infinite programs. In such problems, finitely many variables are subject to infinitely many inequality con- straints. They can be stated as
𝑆𝐼𝑃 ∶   min 𝑓 (𝒙)  s.t.  𝒙 ∈ 𝑀
𝒙
with the set of feasible points
𝑀 = {𝒙 ∈ ℝ𝑛| 𝑔(𝒙, 𝒚) ≤ 0 for all 𝒚 ∈ 𝑌 }	(1)
and a nonempty compact index set 𝑌 ⊊ ℝ𝑚 of the inequality constraints. The defining functions 𝑓 and 𝑔 are assumed to be real-valued and at least
level nor lower-level convexity assumptions on 𝑆𝐼𝑃 for the most part continuous on their respective domains, but we neither impose upper-
of this paper.

Upper-level and lower-level convexity

In the case of convex 𝑔(⋅, 𝒚) for all 𝒚 ∈ 𝑌 , the feasible set 𝑀 is convex, so that together with a convex objective function 𝑓 , the optimization problem 𝑆𝐼𝑃 is then convex and, in particular, each locally minimal
level variable 𝒙, one speaks of upper-level convexity. An important spe- point is also globally minimal. As these assumptions involve the upper- cial case is linear semi-infinite optimization, where the functions 𝑓 and
𝑔(⋅, 𝒚), 𝒚 ∈ 𝑌 , are (aﬃne) linear.
at the computational approximation of globally minimal points for 𝑆𝐼𝑃 In the absence of upper-level convexity, one may either keep aiming
by resorting to global optimization techniques, or one is content with the computation of locally optimal points.
The lower-level problem of 𝑆𝐼𝑃 is concerned with checking feasi- bility of a point 𝒙. This constitutes the main algorithmic challenge in semi-infinite optimization because feasibility of 𝒙 is defined in terms of the infinitely many constraints 𝑔(𝒙, 𝒚) ≤ 0, 𝒚 ∈ 𝑌 . In an optimization re- formulation, they may be written as 𝑔(𝒙) ∶= max𝒚∈𝑌 𝑔(𝒙, 𝒚) ≤ 0, so that feasibility of 𝒙 may be checked by testing the optimal value 𝑔(𝒙) of the
lower-level problem
𝐿𝐿𝑃 (𝒙) ∶   max 𝑔(𝒙, 𝒚)  s.t.  𝒚 ∈ 𝑌
𝒚
for nonpositivity. This also motivates to call 𝒚 the lower-level variable.
For given 𝒙, the problem 𝐿𝐿𝑃 (𝒙) is convex if 𝑌 is a convex set and if 𝑔(𝒙, ⋅) is concave on 𝑌 . We refer to these assumptions as lower-level
convexity. Under lower-level convexity, each locally maximal value of
𝐿𝐿𝑃 (𝒙) coincides with the globally maximal value 𝑔(𝒙) and may, thus, be used to check feasibility of 𝒙. We emphasize that in the absence of
values of 𝐿𝐿𝑃 (𝒙) for nonpositivity because infeasible points 𝒙 may then lower-level convexity, it is not an option to check only locally maximal
erroneously be identified as feasible. Consequently, as opposed to the situation without upper-level convexity, a lack of lower-level convexity entails a need for some sort of global optimization technique to solve
𝐿𝐿𝑃 (𝒙).
The present survey mainly covers standard semi-infinite programs
(SIPs), while also theory, methods, and applications of generalized semi- infinite optimization (GSIP) received considerable attention over the last
two decades. In these problems, the index set 𝑌 is allowed to depend on
the upper-level variable 𝒙, that is, the feasible set has the form
𝑀𝐺𝑆𝐼𝑃 = {𝒙 ∈ ℝ𝑛| 𝑔(𝒙, 𝒚) ≤ 0 for all 𝒚 ∈ 𝑌 (𝒙)}	(2)
with a set-valued mapping 𝑌 ∶ ℝ𝑛 ⇉ ℝ𝑚.


∗ Corresponding author.
E-mail addresses: hatim.djelassi@avt.rwth-aachen.de (H. Djelassi), amitsos@alum.mit.edu (A. Mitsos), stein@kit.edu (O. Stein).

https://doi.org/10.1016/j.ejco.2021.100006
Received 17 February 2021; Received in revised form 14 May 2021; Accepted 27 June 2021
2192-4406/© 2021 The Author(s). Published by Elsevier Ltd on behalf of Association of European Operational Research Societies (EURO). This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)



Standard references

As basic references, we mention (Hettich and Kortanek, 1993) for
counterpart. Indeed, letting 𝑇 ⊊ ℝ𝑟 denote a nonempty and compact
uncertainty set and with the upper envelopes
𝑓 (𝒙) = max 𝑓 (𝒕, 𝒙)	and	𝑔 (𝒙) = max 𝑔 (𝒕, 𝒙), 𝑖 ∈ 𝐼 , 

an introduction to semi-infinite optimization, (Hettich and Zencke,
𝒕∈𝑇
𝑖	𝒕∈𝑇  𝑖

1982; Polak, 1997; Reemtsen and Görner, 1998) for algorithmic ap-
proaches to SIPs as well as Goberna and López (1998) and Goberna and López (2018) for linear semi-infinite optimization. The foundations of GSIPs are treated in the monograph (Stein, 2003).
More recent reviews on theory, applications and algorithms for
one may consider the robust counterpart
𝑅𝑂 ∶	min 𝑓 (𝒙)  s.t.  𝑔 (𝒙) ≤ 0, 𝑖 ∈ 𝐼, 
𝑥∈ℝ𝑛
of the family 𝑃 (𝒕), 𝒕 ∈ 𝑇 . Its epigraphical reformulation leads to

SIP are López and Still (2007), Guerra Vázquez et al. (2008), Shapiro (2009) and Stein (2012). Internet resources include the SIP bib- liography (López and Still, 2012) with several hundreds of references
𝑆𝐼𝑃𝑅𝑂 ∶
min
(𝒙,𝑧)∈ℝ𝑛 ×ℝ
𝑧  s.t.  𝑓 (𝒕, 𝒙) ≤ 𝑧 for all 𝒕 ∈ 𝑇 ,
𝑔𝑖 (𝒕, 𝒙) ≤ 0 for all 𝒕 ∈ 𝑇 , 𝑖 ∈ 𝐼, 

and the NEOS SIP directory (Goberna, 2013). Note that these recent re- views mainly cover optimality conditions and stability results for SIPs, while the present survey focuses on applications and algorithmic as- pects.

Motivating example

In anticipation of the presentation of current SIP application areas in Section 3, let us briefly sketch Chebyshev approximation as a classical example.
Example 1. (Chebyshev approximation) Historically, the systematic study of semi-infinite optimization is motivated by Chebyshev approxi- mation problems (cf. López and Still, 2007). In fact, consider the approx-
imation of a continuous function 𝐹 on a nonempty compact set 𝑌 ⊊ ℝ𝑚
by an element from the family of continuous functions 𝑎(𝒑, ⋅), 𝒑 ∈ 𝑃 , with parameter set 𝑃 ⊆ ℝ𝑛. Measuring the deviation of 𝐹 from 𝑎(𝑝, ⋅) on
𝑌 by the Chebyshev norm 𝐹 (⋅) − 𝑎(𝒑, ⋅) ∞,𝑌 ∶= max𝒚∈𝑌 𝐹 (𝒚) − 𝑎(𝒑, 𝒚)
leads to the Chebyshev approximation problem
𝐶𝐴 ∶  min ‖𝐹 (⋅) − 𝑎(𝒑, ⋅)‖∞,𝑌  s.t.  𝒑 ∈ 𝑃 .
Its epigraphical reformulation yields the semi-infinite program
𝑆𝐼𝑃  ∶  min 𝑞  s.t.  𝐹 (𝒚) − 𝑎(𝒑, 𝒚) ≤ 𝑞, 𝒚 ∈ 𝑌 ,
𝒑,𝑞
−𝐹 (𝒚) + 𝑎(𝒑, 𝒚) ≤ 𝑞, 𝒚 ∈ 𝑌 ,
𝒑 ∈ 𝑃 ,
with two semi-infinite constraints.
In case that the family 𝑎(𝒑, ⋅), 𝒑 ∈ 𝑃 , depends linearly on 𝒑 and 𝑃 is polyhedral, 𝑆𝐼𝑃𝐶𝐴 enjoys upper-level convexity and is even a linear SIP. This is the case, e.g., for polynomial functions 𝑎(𝒑, ⋅) of fixed max- imal degree and with unconstrained coeﬃcient vector 𝒑. The usually missing lower-level convexity in 𝑆𝐼𝑃𝐶𝐴 can be treated algorithmically for example by the Remez algorithm, if the index variable 𝒚 is scalar
(Hettich and Kortanek, 1993; Hettich and Zencke, 1982).

Relations to other problem classes
with finitely many semi-infinite constraints.
While considerable attention has been paid to robust optimization in its own right, this survey considers it to be an application of semi-infinite programming. As such, the solution of robust optimization problems and
variants of the formulation 𝑅𝑂 are discussed along with other applica-
tions of semi-infinite programming in Section 3.
Example 3. (Mathematical programs with complementarity constraints) Mathematical programs with complementarity constraints (MPCCs) consider the minimization of some objective function over a feasible set whose description contains complementarity constraints. Under the assumption of lower-level convexity and some mild regularity assump- tion, SIPs may be recast as MPCCs as follows.
Let 𝑌 = {𝒚 ∈ ℝ𝑚 𝒗(𝒚) ≤ 𝟎} be described by a function 𝒗 ∶ ℝ𝑚 → ℝ𝑠
with convex and continuously differentiable component functions, let
𝑌 satisfy the Slater condition 𝒗(𝒚̄) < 𝟎 for some 𝒚̄ (where the inequali- ties ≤ and < are meant componentwise), and let 𝑔(𝒙, ⋅) be concave and continuously differentiable for each 𝒙. Then, the bilevel reformulation
(Stein and Still, 2002)
𝐵𝐿𝑆𝐼𝑃 ∶    min 𝑓 (𝒙)  s.t.  𝑔(𝒙, 𝒚) ≤ 0, 𝒚 is an optimal point of 𝐿𝐿𝑃 (𝒙) of 𝑆𝐼𝑃 can be reformulated by means of the lower-level Karush-Kuhn- Tucker conditions as
𝑀𝑃 𝐶𝐶   ∶   min 𝑓 (𝒙)  s.t.  𝑔(𝒙, 𝒚) ≤ 0,
𝒙,𝒚,𝜸
∇𝒚 𝑔(𝒙, 𝒚) − ∇𝒗(𝒚)𝜸 = 𝟎,
𝟎 ≤ 𝜸 ⟂ −𝒗(𝒚) ≥ 𝟎,
where the last is a complementarity constraint. This approach can eas- ily be transferred to GSIPs and makes solutions methods for MPCCs (Luo et al., 1996) available for SIPs and GSIPs (Stein, 2003).
Example 4. (Disjunctive optimization) In disjunctive optimization, prob- lem constraints may be coupled not only by conjunctions, but by gen- eral logical expressions containing conjunctions and disjunctions. For example, a logical expression consisting only of disjunctions between
the constraints 𝐺𝑗 (𝒙) ≤ 0, 𝑗 = 1, … , 𝑠, leads to the disjunctive feasible
set


While this survey does not focus on them, we point out some fruit- ful relations of SIP to several other problem classes in optimization, in particular to robust optimization, to mathematical programs with com- plementarity constraints, to disjunctive programs, and to game theory.
Example 2. (Robust optimization) Optimization under uncertainty is a long-standing goal, cf. (Halemane and Grossmann, 1983; Sahinidis, 2004). The two main approaches to deal with uncertainty are (two- stage) stochastic programming, e.g., (Birge and Louveaux, 1997) and
𝑠
𝑀𝐷𝑃 =	{𝒙 ∈ ℝ𝑛 𝐺𝑗 (𝒙) ≤ 0}.
𝑗=1
On the other hand, for a one-dimensional lower-level variable 𝑦 let
𝑔(𝒙, 𝑦) ∶= 𝑦 and 𝑣𝑗 (𝒙, 𝑦) ∶= 𝑦 − 𝐺𝑗 (𝒙), 𝑗 = 1, … , 𝑠. This yields the index
set
𝑌 (𝒙) = {𝑦 ∈ ℝ| 𝑦 ≤ 𝐺𝑗 (𝒙), 𝑗 = 1, … , 𝑠} = (−∞, 𝑗 min,𝑠 𝐺𝑗 (𝒙)],
the function

worst-case or robust optimization (Ben-Tal and Nemirovski, 1999).
In the optimization problem
𝑃 (𝒕) ∶	min 𝑓 (𝒕, 𝒙)  s.t.  𝑔 (𝒕, 𝒙) ≤ 0, 𝑖 ∈ 𝐼, 
𝑔(𝒙) = max 𝑦 = min
𝑦∈𝑌 (𝒙)	𝑗=1,…,𝑠
and the feasible set
𝐺𝑗 (𝒙)

𝒙∈ℝ𝑛	𝑖
𝑛	𝑛

with finite index set 𝐼 , let the continuous functions 𝑓 , 𝑔𝑖 , 𝑖 ∈ 𝐼 , depend
𝑀𝐺𝑆𝐼𝑃 = {𝒙 ∈ ℝ | 𝑔(𝒙) ≤ 0} = {𝒙 ∈ ℝ | 𝑗 min,𝑠 𝐺𝑗 (𝒙) ≤ 0} = 𝑀𝐷𝑃 .

on some uncertain parameter 𝒕. Then, the robust optimization approach
prescribes that the worst case for 𝒕 is considered to construct a robust
As the lower-level problem is a one-dimensional linear program, it par- ticularly enjoys lower-level convexity.



In Kirst and Stein (2016), it is shown how also disjunctive programs with general logical expressions may be reformulated as GSIPs with con- vex lower-level problems, and how this connection helps to solve dis- junctive programs with GSIP methods. We remark that it is also pos- sible to incorporate disjunctive optimization ideas into GSIP solution techniques (Kirst and Stein, 2019).
Example 5. (Equilibrium selection) Consider an 𝑁 -player Nash equilib- rium problem where each player 𝜈 ∈ {1, … , 𝑁 } seeks a globally minimal
point of the problem
𝑄𝜈(𝒙−𝜈) ∶   min 𝜃 (𝒙𝜈, 𝒙−𝜈)  s.t.  𝒙𝜈 ∈ 𝑋𝜈,
𝒙𝜈
which depends on the vector 𝒙−𝜈 of all other players’ decision vectors via its objective function 𝜃𝜈 . As opposed to this dependence, in a stan- dard Nash equilibrium problem, the strategy sets 𝑋𝜈, 𝜈 = 1, … , 𝑁 , are assumed to be independent of 𝒙−𝜈. No cooperation between the players is assumed. Rather, a vector 𝒙⋆ ∈ ℝ𝑛 can be considered an equilibrium if for each 𝜈 its subvector 𝒙⋆,𝜈 is a globally minimal point of 𝑄(𝒙⋆,−𝜈).
viate from their respective optimal point 𝒙⋆,𝜈. We denote the (possibly In this situation none of the players possesses a rational incentive to de- empty) set of all such so-called Nash equilibria by 𝐸.
When 𝐸 contains more than one element, equilibrium selection prob-
can be modelled by a selection function 𝑓 ∶ ℝ𝑛 → ℝ and the equilibrium lems aim to explain why players prefer some equilibria over others. This
selection problem
𝐸𝑆𝑃 ∶	min 𝑓 (𝒙)  s.t.  𝒙 ∈ 𝐸.
𝒙
Note that a Nash equilibrium problem differs from 𝐸𝑆𝑃 in that it merely aims at finding a feasible point of 𝐸𝑆𝑃 . The Nash equilibrium problem is called player-convex if each strategy set 𝑋𝜈 is convex and each function
𝜃𝜈 (⋅, 𝒙−𝜈) is convex for given 𝒙−𝜈. If the latter function is also continu- ously differentiable, then by the variational reformulation 𝒙⋆,𝜈 ∈ 𝑋𝜈 is an optimal point of 𝑄(𝒙⋆,−𝜈) if and only if the variational inequality
token, it has been proposed to solve SIPs by solving a joint set of up- per and lower-level KKT conditions via homotopy methods (Fan et al., 2018; Liu, 2007). In the general case of a nonconvex lower-level prob- lem however, these approaches are not applicable. In the following, we survey solution approaches for SIPs with nonconvex lower-level prob- lems. These approaches have in common that they establish feasibility of a point in a SIP by globally solving the lower-level problem, either explicitly or implicitly.

Discretization methods

proximations of 𝑆𝐼𝑃 by replacing the index set 𝑌 by a finite subset The basic principle of discretization methods is the derivation of ap-
𝑌𝑘 ⊊ 𝑌. Using this discretization instead of the original index set, gives rise to a relaxation of the feasible set 𝑀 :
𝑀𝐿𝐵𝑃 (𝑌𝑘 ) = {𝒙 ∈ ℝ𝑛 𝑔(𝒙, 𝒚) ≤ 0 for all 𝒚 ∈ 𝑌𝑘 } ⊇ 𝑀 .
The set 𝑀𝐿𝐵𝑃 (𝑌𝑘 ) is given in terms of finitely many constraints and gives rise to a finite relaxation of 𝑆𝐼𝑃 , which we term a lower bounding
problem,
𝐿𝐵𝑃 (𝑌𝑘 ) ∶	min 𝑓 (𝒙)  s.t.  𝒙 ∈ 𝑀𝐿𝐵𝑃 (𝑌𝑘 ).
discretization method by considering a predetermined sequence {𝑌𝑘 } of Based on this lower bounding problem, one can construct a conceptual
successively finer discretizations
𝑌𝑘 ⊊ 𝑌𝑘+1 ⊊ 𝑌 for all 𝑘.
Then, the conceptual discretization method consists of solving 𝐿𝐵𝑃 (𝑌𝑘 )
quence of approximate solutions of 𝑆𝐼𝑃 . López and Still (2007) show for the predefined sequence of discretizations in order to obtain a se-
that under the assumptions of continuous functions and compactness of
𝑌 , this sequence of approximate solutions approaches a solution of 𝑆𝐼𝑃 ,

⟨∇𝒙𝜈 𝜃𝜈 (𝒙𝜈, 𝒙
−𝜈
), 𝒛𝜈
– 𝒙𝜈⟩ ≥ 0 for all 𝒛𝜈
∈ 𝑋𝜈
if the Hausdorff distance between 𝑌𝑘 and 𝑌 vanishes for 𝑘 → ∞.
While the conceptual discretization method is theoretically sound, it

holds. It is not hard to see that thus 𝒙⋆ ∈ 𝑋 ∶= 𝑋1 ×…× 𝑋𝑁 is a Nash
equilibrium if and only if the aggregated variational inequality
𝐹 (𝒙), 𝒛 − 𝒙 ≥ 0 for all 𝒛 ∈ 𝑋
with 𝐹 ∶= (∇𝒙1 𝜃1, … , ∇𝒙𝑁 𝜃𝑁 ) is satisfied. The set of Nash equilibria may
hence be written as
𝐸 = {𝑥 ∈ ℝ𝑛  𝐹 (𝒙), 𝒛 − 𝒙 ≥ 0 for all 𝒛 ∈ 𝑋},
and the equilibrium selection problem becomes the semi-infinite pro- gram
has the drawback that it generally requires many iterations and large
𝑌𝑘 in order to yield a level of accuracy that is suﬃcient in prac- tice. This in turn may render the solution of 𝐿𝐵𝑃 (𝑌𝑘 ) intractable for large 𝑘. Accordingly, recent advances in discretization methods build
on an adaptive discretization method that usually requires smaller dis- cretizations. Initially proposed by Blankenship and Falk (1976), based on Remez (1962) the adaptive discretization method prescribes the fol- lowing steps.
Choose an initial discretization 𝑌0 ⊊ 𝑌 and let 𝑘 = 0.
Solve 𝐿𝐵𝑃 (𝑌 ) and obtain a solution 𝒙 .

𝑘	𝑘

𝑆𝐼𝑃𝐸𝑆𝑃 ∶   min 𝑓 (𝒙)  s.t.  ⟨𝐹 (𝒙), 𝒛 − 𝒙⟩ ≥ 0 for all 𝒛 ∈ 𝑋
ized Nash equilibrium problem, where also the strategy sets 𝑋𝜈(𝒙−𝜈) are enjoying lower-level convexity. Note that in the situation of a general-
allowed to depend on the other players’ decisions, the above reformu- lation of equlibrium selection yields a GSIP. For more details on such formulations we refer to Lampariello et al. (2020).

Article structure

This article is structured as follows. In Section 2 we survey re- cent algorithmic approaches to nonconvex semi-infinite optimization. Section 3 illustrates the suitability of these methods for a list of mod- ern applications of semi-infinite optimization. We close the article with some final remarks in Section 4.

Methods

As mentioned previously, SIPs can be reformulated to MPCCs only under the assumption of lower-level convexity, in which case the KKT conditions are suﬃcient to enforce lower-level optimality. By the same
Solve 𝐿𝐿𝑃 (𝒙𝑘 ) and obtain a solution 𝒚𝑘 .
If 𝑔(𝒙𝑘 , 𝒚𝑘 ) ≤ 0, return 𝒙𝑘 (feasible optimal solution).
Let 𝑌𝑘+1 = 𝑌𝑘 ∪ {𝒚𝑘 } and go to step 2 with 𝑘 ← 𝑘 + 1.
points 𝒚𝑘 that cause the largest violation of the semi-infinite constraint From one iteration to the next, the discretization is refined with the for a given iterate 𝒙𝑘 . By this approach, the lower bounding problem is tightened successively to more accurately approximate 𝑆𝐼𝑃 . Notably,
points  𝒚𝑘  are  global  solutions of  the  lower-level  problem. for adaptive discretization to be successful, it must be ensured that the
compact host sets, the sequence {𝒙𝑘 } of iterates approaches a solution Blankenship and Falk (1976) show that for continuous functions and of 𝑆𝐼𝑃 in the limit. Furthermore, in the case of an infeasible 𝑆𝐼𝑃 , the
proving the infeasibility of 𝑆𝐼𝑃 , see e.g., (Mitsos and Tsoukalas, 2015). lower bounding problem becomes infeasible in finitely many iterations,
that the generation of points feasible in 𝑆𝐼𝑃 can only be guaranteed in The major drawback of the adaptive discretization method is the fact
the limit. Accordingly, a practical implementation of the method must allow for a positive feasibility tolerance with respect to the semi-infinite constraints. Recent advances building on this method have focused on remedying this point in particular while also weakening the underlying



assumptions and extending the method to more general problems such as GSIPs (Still, 1999; 2001).
may be modified by additionally allowing to drop points from 𝑌𝑘 when We mention that Step 5 of the above adaptive discretization scheme the new set 𝑌𝑘+1 is formed. Such exchange methods were suggested in,
e.g., Hettich and Kortanek (1993) and Goberna and López (1998) for
linear SIPs, and they also received some attention for the solution of convex SIPs (Zhang et al., 2010). However, since we are not aware of successful dropping rules in the nonconvex case, the present review does not further comment on this topic.

Feasible point adaptations
Mitsos (2011) proposes to address the problem of finding feasible points by introducing an upper bounding problem
𝑈𝐵𝑃 (𝑌𝑘 , 𝜀𝑔 ) ∶   min 𝑓 (𝒙)  s.t.  𝒙 ∈ 𝑀𝑈𝐵𝑃 (𝑌𝑘 , 𝜀𝑔 ),

wherein 𝑀𝑈𝐵𝑃 (𝑌𝑘 , 𝜀𝑔 ) is obtained by restricting the right-hand side of a set of discretized constraints by 𝜀𝑔 > 0.
𝑀  (𝑌 , 𝜀𝑔 ) = {𝒙 ∈ ℝ𝑛| 𝑔(𝒙, 𝒚) ≤ −𝜀𝑔 for all 𝒚 ∈ 𝑌 }
requirements for the solution of subproblems, particularly the LLP. Indeed, while Blankenship and Falk (1976) assume the exact global solution of the LLP, (Mitsos, 2011) only assumes that the solution accuracy is suﬃcient to conclusively determine feasibility of a given iterate. Similarly Djelassi and Mitsos (2017) assume that subprob- lems can be solved to an arbitrary absolute optimality tolerance, which is set as needed according to a refinement scheme. However, Harwood et al. (2019) point out that in both cases, the proofs of conver- gence fail to consider a case where these assumptions are insuﬃcient. In order to remedy this issue, they propose a relative optimality tolerance for the solution of the lower-level problem. Djelassi (2020) points out that a similar result can be achieved by using absolute tolerance and using a more aggressive version of the tolerance refinement scheme from Djelassi and Mitsos (2017).
Beyond guarantees for the generation of feasible solutions, the meth- ods discussed previously may also provide superior performance to the original adaptive discretization method in practice. Indeed, due to the provision of convergent upper bounds, the feasible point adaptations
may terminate earlier based on 𝜀-optimality than the original method

Notably, for arbitrary 𝑌𝑘 ⊊ 𝑌 and 𝜀𝑔 > 0, 𝑀𝑈𝐵𝑃 (𝑌𝑘 , 𝜀𝑔 ) is generally nei- ther a superset nor a subset of 𝑌 . Accordingly, 𝑈𝐵𝑃 (𝑌𝑘 , 𝜀𝑔 ) is generally neither a relaxation nor a restriction of 𝑆𝐼𝑃 . However, through popu- lation of 𝑌𝑘 and reduction of 𝜀𝑔 , 𝑈𝐵𝑃 (𝑌𝑘 , 𝜀𝑔 ) can be restricted and re-
laxed, respectively. Under the assumption that there exists a point that satisfies a Slater condition with respect to the semi-infinite constraint,
𝑈𝐵𝑃 (𝑌𝑘 , 𝜀𝑔 ) can be used to construct an upper bounding procedure that
Slater point is also 𝜀-optimal in 𝑆𝐼𝑃 , the upper bounding procedure yields a feasible point in finitely many steps. Furthermore, if such a produces an 𝜀-optimal solution in finitely many steps. Together with
the convergent lower bounds produced by the basic adaptive discretiza- tion method, Mitsos (2011) proposes an algorithm that is guaranteed to
terminate finitely with an 𝜀-optimal solution.
Tsoukalas and Rustem (2011) build on the adaptive discretization
method by proposing an algorithm centered around the oracle problem
𝑂𝑅𝐴(𝑌𝑘, 𝑓𝑂𝑅𝐴 ) ∶   min max{𝑓 (𝒙) − 𝑓𝑂𝑅𝐴 , max{𝑔(𝒙, 𝒚) | 𝒚 ∈ 𝑌𝑘 }},
ment of the underlying discretization-based approximation of 𝑆𝐼𝑃 . In
the following section, we discuss an approach of such an improvement
based on the ideas from reduction methods.

Reduction-based adaptation
Pure reduction methods rest on assumptions under which for a given
𝒙 ∈ 𝑋, the set of global solutions to 𝐿𝐿𝑃 (𝒙) is finite. Given this property and additional smoothness assumptions, the feasible set of 𝑆𝐼𝑃 can be approximated in a neighborhood of 𝒙 by only considering these finitely many solutions to 𝐿𝐿𝑃 (𝒙) and their sensitivity with respect to 𝒙. Then,
one can devise a conceptual reduction method that successively per-
proximation by solutions of 𝐿𝐿𝑃 (𝒙) (López and Still, 2007). Note how- forms local optimization steps of the approximation and updates the ap- ever, that this method calls for finding all global optimizers in 𝐿𝐿𝑃 (𝒙)
repeatedly, which renders it intractable for the general case of SIPs with nonconvex lower-level problems.

where 𝑓
𝑂𝑅𝐴
is a target objective value. Given a discretization 𝑌𝑘
⊊ 𝑌 
Nevertheless, from the perspective of discretization methods, the
reduction-based approximation has the advantage that it considers the

and some 𝑓𝑂𝑅𝐴 ∈ ℝ, the optimal objective value of 𝑂𝑅𝐴(𝑌𝑘, 𝑓𝑂𝑅𝐴 ) in-
dicates whether 𝑓𝑂𝑅𝐴 is attainable by 𝑆𝐼𝑃 . Indeed, if the optimal ob- jective value is positive, 𝑓𝑂𝑅𝐴 is unattainable for 𝑆𝐼𝑃 and therefore a
positive, the obtained solution point 𝒙𝑘 can be checked for feasibility by lower bound. If on the other hand, the optimal objective value is non- solving 𝐿𝐿𝑃 (𝒙𝑘 ). As in the original adaptive discretization method, this
either yields a proof of feasibility (and an upper bound) or a point that is
gorithm that chooses 𝑓𝑂𝑅𝐴 according to bisection on the objective space added to the discretization. Tsoukalas and Rustem (2011) propose an al-
to solve 𝑆𝐼𝑃 . Given initial guesses for the lower and upper bounds and and successively solves the oracle problem and the lower-level problem
nate finitely with an 𝜀-optimal solution. As pointed out by Mitsos and under appropriate assumptions, the algorithm is guaranteed to termi-
Tsoukalas (2015), the assumptions made are slightly stronger than the ones made in Mitsos (2011).
Djelassi and Mitsos (2017) compare the two aforementioned al-
gorithms and identify a strong relation between 𝑈𝐵𝑃 (𝑌 , 𝜀𝑔 ) and
sensitivity of the global optimizers of 𝐿𝐿𝑃 (𝒙). Indeed, the discretiza-
tion points added according to the adaptive discretization method can
be understood as zeroth-order approximations of lower-level optimiz- ers. Seidel and Küfer (2020) highlight this relation and propose to include sensitivity information about the discretization points in the discretization-based approximation. They show that their newly pro-
to a stationary point of 𝑆𝐼𝑃 where the original adaptive discretiza- posed discretization scheme provides a quadratic rate of convergence
this inclusion of sensitivities in the lower bounding problem 𝐿𝐵𝑃 (𝑌𝑘 ) tion scheme only converges linearly. Djelassi (2020) points out that
generally entails a loss of its bounding properties. As a consequence, the inclusion of sensitivities cannot be applied directly to the bound- ing algorithms discussed in the previous section. In order to remedy this problem, Djelassi (2020) proposes an alternative formulation of the discretization-based subproblems that preserves their bounding proper- ties. However, due to the involvement of nonsmooth functions in this

𝑔	𝑘	formulation, it is doubtful whether the same quadratic rate of conver-

𝑂𝑅𝐴(𝑌𝑘, 𝑓𝑂𝑅𝐴 ). Indeed, while 𝑈𝐵𝑃 (𝑌𝑘 , 𝜀 ) is subject to a set of re-
stricted constraints, the objective of 𝑂𝑅𝐴(𝑌𝑘, 𝑓𝑂𝑅𝐴 ) is to maximize such a restriction balanced with the minimization of 𝑓 (𝑥). Djelassi and Mit-
a slight adaptation of 𝑂𝑅𝐴(𝑌𝑘, 𝑓𝑂𝑅𝐴 ) in order to generate updates for sos (2017) thus propose an algorithm that exploits this relation by using the restriction parameter 𝜀𝑔 . The algorithm inherits the guarantees for
convergence and finite termination from Mitsos (2011) while improving upon both of its predecessors in terms of performance on a standard SIP test set (Watson, 1983).
In  addition  to  guaranteeing  feasible  points  finitely, Mitsos (2011) and Djelassi and Mitsos (2017) slightly weaken the
gence as in Seidel and Küfer (2020) can be obtained here.

Generalizations & specializations
Beyond the solution of SIPs, the adaptive discretization method has been applied to other problem classes that are closely related to SIPs. Indeed, only shortly after the original publication of the method by Blankenship and Falk (1976), Falk and Hoffman (1977) proposed a spe- cialization to min-max programs of the following form.
MMP ∶	min max 𝑓 (𝒙, 𝒚)
𝒙∈𝑋 𝒚∈𝑌



As shown previously for the Chebyshev approximation problem in Example 1, this min-max program can be recast in its epigraphical for- mulation as the SIP
branching of the lower-level variable space. In the following, we sepa- rate overestimation methods into two groups according to the kind of overestimation they employ (interval or relaxation-based).

𝑆𝐼𝑃𝑀𝑀𝑃 ∶
min
𝒙∈𝑋,𝜂∈ℝ
𝜂  s.t.  𝜂 ≥ 𝑓 (𝒙, 𝒚) for all 𝒚 ∈ 𝑌 .
Interval methods
Bhattacharjee et al. (2005a,b) proposed the first deterministic algo-

Falk and Hoffman (1977) proposed to solve this SIP using the adaptive discretization method. Notably and unlike the general SIP case, the prob-
feasibility gap due to the semi-infinite constraint in 𝑆𝐼𝑃𝑀𝑀𝑃 translates lem of generating feasible points finitely does not arise here. Indeed, any to an optimality gap in 𝑀𝑀𝑃 . By the same token, given any 𝒙 ∈ 𝑋, the solution of the lower-level problem of 𝑀𝑀𝑃 provides a value for 𝜂 such that (𝒙, 𝜂) is feasible in 𝑆𝐼𝑃𝑀𝑀𝑃 .
More recent advances in this area focus on the solution of gener- alizations of SIPs rather than specializations. As such, the oracle ap- proach proposed by Tsoukalas and Rustem (2011) for the solution of SIPs was initially proposed by Tsoukalas et al. (2009) for the solution of GSIPs, bilevel programs and min-max programs with coupling con- straints. In contrast to the SIP variant, the original publication prescribes the solution of subproblems by stochastic methods and does not pro- vide a proof of convergence. The method proposed by Mitsos (2011) is extended to GSIPs in Mitsos and Tsoukalas (2015). Furthermore, the methods in Mitsos (2011) and Djelassi and Mitsos (2017) are extended to existence-constrained SIPs, which possess three rather than two levels in Djelassi and Mitsos (2021).
Both Tsoukalas et al. (2009) and Mitsos and Tsoukalas (2015) pay particular attention to a concern that generally arises when discretiza- tion methods are applied to GSIPs. In the SIP case, it is trivial to obtain a subproblem that only considers a subset of the index set since the index set is independent of the upper-level variables. In the GSIP case however, the index set depends on the upper-level variables and the con- struction of discretization-based subproblems must take account of this fact. Then, the derivation of valid subproblems usually involves logical constraints that are only imposed when the underlying discretization point is lower-level feasible. Tsoukalas et al. (2009) and Mitsos and Tsoukalas (2015) employ such constraints and recast them as nons- mooth constraints. Furthermore, in order to ensure convergence of the discretization-based approximations, both approaches ensure that each new discretization point satisfies a Slater condition with respect to the coupling lower-level constraints. Since such a Slater condition can only be satisfied by inequality constraints, these approaches do not permit the presence of coupling lower-level equality constraints. However, un- der a uniqueness assumption for the solution of such coupling equal- ity constraints, convergence of discretization methods can be recovered (Djelassi et al., 2019; Stuber and Barton, 2015).

Overestimation methods

In this section we discuss methods that overestimate the optimal ob- jective value of the LLP. Underlying all these methods is the observation that this overestimation entails a restriction of the SIP. Indeed, letting
𝑔̂ ∶ ℝ𝑛 → ℝ overestimate 𝑔̄ on ℝ𝑛, it holds that
𝑔(𝒙, 𝒚) ≤ 𝑔̄(𝒙) ≤ 𝑔̂(𝒙) for all 𝒚 ∈ 𝑌 , 𝒙 ∈ ℝ𝑛.
Accordingly, the overestimation problem
rithm for the global optimization of SIPs. As is typical in deterministic global optimization, they perform a branch-and-bound in the upper- level variables. In each node, they construct both lower and upper bounds. For the lower bound, they use a discretization method. The key novelty is that they propose to overestimate the lower-level objective function using natural interval extensions, which yields a restriction of the SIP. The restriction is a finite smooth nonconvex NLP. Any feasible point of this NLP is also a feasible point of the SIP and thus provides an upper bound to the optimal objective value. Following standard practice in deterministic global optimization, Bhattacharjee et al. (2005b) solve this nonconvex restriction using local NLP solvers. They prove finite convergence of their algorithm to an approximate optimal solution of the SIP. The key assumption is the existence of SIP Slater points. Note that also (Bianco and Piazzi, 2001) use interval extensions for the LLP in a genetic algorithm for the solution of SIPs.
Marendet et al. (2020) propose a branch-and-bound algorithm for the solution of SIPs with box-constrained LLPs. They build on an exist- ing interval-based global optimization solver and extend its capabilities for the treatment of semi-infinite constraints. In particular, they perform branching on the upper-level variables while maintaining for each node of the branch-and-bound tree a tessellation that provides a superset of the lower-level optimal solutions for the given node. Then, upper and lower bounds on the optimal lower-level objective are obtained via nat- ural interval extensions applied over the tessellation. Convergence of these bounds and in turn convergence of the branch-and-bound scheme are achieved by successively refining the tessellations. Beyond this ex- tension of the branch-and-bound scheme, Marendet et al. (2020) also propose the use of constraint programming techniques in order to tighten the bounds on the lower-level optimal objective.

Relaxation methods
Unlike the interval methods from Bhattacharjee et al. (2005a,b), the adaptive convexification method from Floudas and Stein (2007) and Stein and Steuermann (2012) is a local method for the upper-level prob- lem which guarantees semi-infinite feasibility by global optimization ideas for the lower-level problem. As an upper-level local method it generally needs lower numerical effort than methods which aim both at
tive convexification is to tessellate the index set 𝑌 into finitely many lower-level and upper-level global optimality. The main idea of adap-
smaller sets and to convexify the resulting subproblems. Ideas of spatial branching are used to refine the tessellation.
In the special case of a scalar index set 𝑌 the tessellation is formed
by closed subintervals. For any such subinterval 𝑌 ′ a seperate lower- level problem 𝐿𝐿𝑃 ′(𝒙) is considered, in which 𝑔(𝒙, ⋅) is maximized over
𝑌 ′. Since 𝑌 ′ is convex, a possible nonconvexity of 𝐿𝐿𝑃 ′(𝒙) can only be due to the nonconcavity of 𝑔(𝒙, ⋅) on 𝑌 ′. Floudas and Stein (2007) then suggest to overestimate 𝑔(𝒙, ⋅) on 𝑌 ′ by a concave function 𝑔̂(𝒙, ⋅) which is constructed by techniques of the 𝛼BB method from Adjiman et al. (1998a,b). If no additional information is available, the 𝛼BB method
generates a concave overestimator by adding an appropriately scaled

𝑂𝐸 ∶	min 𝑓 (𝒙)  s.t.
𝒙
𝑔̂(𝒙) ≤ 0
quadratic relaxation function to the original function 𝑔(𝒙, ⋅), where the
size of the scaling factor is determined by interval arithmetic.

is a restriction of 𝑆𝐼𝑃 and any solution of 𝑂𝐸 is also feasible in 𝑆𝐼𝑃 . Furthermore, there are several overestimation approaches for which 𝑂𝐸
is either finite or can be reformulated as a finite problem.
problems in order to generate feasible points in 𝑆𝐼𝑃 . Furthermore, the Overestimation methods for the solution of SIPs employ such finite
methods usually prescribe a refinement of the overestimation such that
of 𝑆𝐼𝑃 . The refinement usually involves some kind of tessellation or it can be shown that a sequence of iterates converges to a solution
The concavity of the overestimators entails that all lower-level prob- lems of the approximating SIP are convex, so that it may be solved via the MPCC reformulation from Example 3. In fact, the implementation
from Floudas and Stein (2007) computes a stationary point 𝑥̄ of the
MPCC and terminates if it is also stationary for the original SIP within
given tolerances. Otherwise the algorithm refines the tessellation in the
the      active      indices      of      𝑥̄. spirit of a discretization method by splitting the current subintervals at



While Floudas and Stein (2007) focus on the discussed case of a scalar index set, Stein and Steuermann (2012) generalize this approach to higher dimensional index sets which, in addition, are not necessarily box-shaped. The resulting algorithm is shown to be well-defined, con- vergent and finitely terminating.
Another approach to improve on the interval-based methods from Bhattacharjee et al. (2005a,b) is the approach of Mitsos et al. (2008b). The aim therein is the global solution of SIPs in the absence of any convexity assumptions. Recall that a restriction of the LLP leads to a relaxation of the SIP, and a relaxation of the LLP to a restriction of the SIP. Mitsos et al. (2008b) used these properties to respectively con- struct lower and upper bounds to the optimal objective value of the SIP. The relaxation of the LLP is performed via convex relaxations of the lower-level objective function. This results in general to nonconvex optimization problems. As the relaxations of the LLP are tighter than the interval-based method in Bhattacharjee et al. (2005a,b), the upper bound to the SIP is potentially also tighter. Mitsos et al. (2008b) discuss alternative methods to construct the relaxations, along with advantages and disadvantages. For the lower bounding problem, a combination of discretization and lower-level necessary optimality conditions are pro- posed.

Other methods

Some recently proposed methods cannot be neatly categorized as dicretization or overestimation methods.
Indeed, Okuno and Fukushima (2020) propose a sequential quadratic programming approach for SIPs that uses an exchange method to solve its semi-infinite quadratic suproblems. Therein, an exchange method is essentially a discretization method that selectively drops dis- cretization points. In general, it is diﬃcult to obtain sensible drop- ping rules for SIPs with nonconvex lower-level problems. Okuno and Fukushima (2020) circumvent this issue by applying the exchange method to subproblems with linearized semi-infinite constraints.
Lv et al. (2019) consider 𝑆𝐼𝑃 in terms of the lower-level optimal
value function, which generally yields a nonconvex nonsmooth prob-
lem. They propose an infeasible bundle method in order to solve this nonsmooth problem (and the underlying SIP) to local optimality. Simi- lar to discretization methods, the bundle method maintains and succes- sively refines an approximation of the lower-level optimal value func- tion. However since the bundle method directly approximates the lower- level optimal value function, it requires evaluations of its subgradient in addition to the global solution of the lower-level problem.

Related methods in bilevel programming

Due to the close relation of SIPs and bilevel programs, we also men- tion that the basic concepts of the methods discussed here are also applicable in bilevel programming absent convexity assumptions. As such, the adaptive discretization method is used to solve bilevel pro- grams in Mitsos et al. (2008a), Mitsos (2010), Tsoukalas et al. (2009), Wiesemann et al. (2013) and Djelassi et al. (2019). Similarly, a relaxation-based branch-and-bound method for the solution of bilevel programs is proposed in Kleniati and Adjiman (2014a, 2014b, 2015).

Applications

Over the last decades, several interesting applications of SIP have been proposed and solved. Some applications however still remain in- tractable.

Chebyshev approximation

While the Chebyshev approximation problem from Example 1 can be solved for scalar index sets by the Remez algorithm (Remez, 1962),
Floudas and Stein (2007) illustrate the benefits of the adaptive convex- ification method from Section 2.2.2 for this problem class. Although their method can generally be only expected to solve the upper-level problem locally, the special structure of polynomial Chebyshev approx- imation allows to provide not only upper bounds for the minimal value
of 𝑆𝐼𝑃𝐶𝐴 via the generated feasible points, but the splitting points of the
generated index set tessellations can also be used to form upper-level LP
relaxations. In the numerical example from Floudas and Stein (2007) the resulting lower bounds on the minimal value provide a certificate that the terminal feasible point of the adaptive convexification method is
10−3 -optimal. We also remark that the applicability of the Remez algo-
rithm is restricted to scalar index sets, while the modern SIP solution
methods from Section 2 allow the treatment of higher dimensional in- dex sets.

Design centering

Design centering problems consist in maximizing some measure
𝑓 (𝒙), for example the volume, of a parametrized body 𝑌 (𝒙) while it is inscribed into a container set 𝐺(𝒙),
max 𝑓 (𝒙)  s.t.  𝑌 (𝒙) ⊆ 𝐺(𝒙).
𝒙
They have been studied extensively, see for example (Gritzmann and Klee, 1994; Horst and Tuy, 1996; Nguyen and Strodiot, 1992; Polak, 1982; Stein, 2006), and they are also related to the so-called set con- tainment problem from Mangasarian (2002).
In applications, the set 𝐺(𝒙) often is independent of 𝒙 and has
a complicated structure, while 𝑌 (𝒙) possesses a simpler geometry.
For example, in the robot maneuverability problem, Graettinger and
container  set  𝐺  by  inscribing  an  ellipsoid  𝑌 (𝒙)  into  𝐺. Krogh (1988) determine lower bounds for the volume of a complicated
The design centering problem of cutting a gem of maximal volume with prescribed shape features from a raw gem is treated in Nguyen and Strodiot (1992) and, with the bilevel algorithm for semi-infinite opti- mization from Stein and Still (2003) in Winterfeld (2008).
when the container set is described by a functional constraint as 𝐺(𝒙) = The connection with semi-infinite optimization becomes apparent
{𝒚 ∈ ℝ𝑚 𝑔(𝒙, 𝒚) ≤ 0}. Then, the inclusion constraint 𝑌 (𝒙) ⊆ 𝐺(𝒙) is
equivalent to the GSIP constraint
𝑔(𝒙, 𝒚) ≤ 0 for all 𝒚 ∈ 𝑌 (𝒙),
appears if the body 𝑌 is independent of 𝒙, while the container 𝐺(𝒙) is so that the design centering problem becomes a GSIP. A standard SIP allowed to vary with 𝒙. Many design centering problems can actually be reformulated as standard SIPs, if the 𝒙-dependent transformations of
𝑌 (𝒙) consist of, for example, translation, rotation, and scaling, whose
inverse transformations can as well be imposed on the container set.
Examples for the solution of nonconvex design centering problems by the adaptive convexification method from Section 2.2.2 are provided by Floudas and Stein (2007) and Stein and Steuermann (2012).

Kinetic model reduction

Model reduction is in general very important for engineering when the full model results in intractable problems, in particular for online applications. A plethora of methods exist for model reduction. Among them we want to concentrate on optimization-based error-control meth- ods.
In particular, consider reactive flows, involving thousands of species and reactions. A prime application for such models is the fundamental understanding and optimization of internal-combustion engines for the simultaneous increase of eﬃciency and mitigation of exhaust pollutants. Such applications require spatially-distributed dynamic models. This re- sults in systems of partial differential equations in four independent variables, namely time and the three spatial coordinates. In addition to mass balance (continuity equation), and energy/momentum balance,



for each species a species mass balance needs to be resolved. The number of partial differential equations is approximately equal to the number of species. Species balances contain production terms due to the chemical reactions. As a result, the number of reactions determines the coupling of the differential equations and the stiffness. Computational fluid dynam- ics with fully resolved chemistry is typically intractable. One approach is to introduce so-called adaptive chemistry, Schwer et al. (2003) and Green et al. (2001), wherein for different parts of the spatial domain different kinetic mechanisms are used.
One way to generate the reduced kinetic mechanisms, is to formulate an optimization problem (Bhattacharjee et al., 2003) with the objective function of minimizing the number of reactions or alternatively mini- mizing the weighted reactions and species (Mitsos et al., 2008c). A key idea is that the methods impose the validity of the kinetic mechanism for a finite number of points in the space of thermodynamic states (tem- perature, pressure and concentration of each species). The validity is given by comparing the production rates of the full model to that of the reduced model and allowing for a maximum difference. Under suit- able formulation, this results in mixed-integer linear programs which are tractable with state-of-the-art solvers. However, the finite number of points in thermodynamic space does not guarantee validity of the developed models for a range of thermodynamic states. Imposing the validity for the range results in a design centering problem which can
be formulated as 𝐺𝑆𝐼𝑃 or 𝑆𝐼𝑃 along the lines sketched in Section 3.2.
For details, the reader is referred to Bhattacharjee (2003) and Oluwole
et al. (2007, 2006).
Recall that semi-infinite programming is historically motivated by Chebyshev approximation, cf. López and Still (2007). As such, the oc- currence of a semi-infinite program in this model reduction should not be surprising. In an abstract sense, the full model can be seen as the func- tion to be approximated and the reduced model as the approximating function.

Robust optimization and flexibility analysis

Starting with Ben-Tal and Nemirovski (1999), a large part of the lit- erature on robust optimization (Example 2) studies assumptions on the
problems at hand, under which the robust counterpart 𝑅𝑂 is algorithmi-
cally “tractable”. These assumptions usually involve upper-level as well
as lower-level convexity, or are even stronger. For more recent develop- ments in robust optimization we refer to the monograph (Ben-Tal et al., 2009).
Recently, one can observe a trend towards convex nonlinear robust problems (Mutapcic and Boyd, 2009) and even nonconvex robust opti- mization (Bertsimas et al., 2009). In the general case and as shown in
Example 2, robust optimization formulations correspond to 𝑆𝐼𝑃 . Ac-
cordingly, existing results from semi-infinite optimization literature can
be used and in fact should be considered.
As an extension of the robust optimization framework, Ben- Tal et al. (2004) propose adjustable robust optimization. Therein and similar to two-stage stochastic programming, the decision variables are separated into “here and now” decisions and “wait and see” decisions. While the former have to be taken in anticipation of the worst case regarding uncertainty, the latter may be taken in response to the real- ization of uncertainty. When considering the semi-infinite formulation of such problems, the addition of the “wait and see” decisions results in an existence-constrained SIP.
Recent applications of adjustable robust optimization include invest- ment problems (Takeda et al., 2007) and network expansion problems (Ordóñez and Zhao, 2007). Solution approaches to these problems often rely on convexity assumptions that enable the reformulation of the prob- lem as a single-level problem. However, as pointed out previously, the general nonconvex case of existence-constrained SIPs is approachable, at least in theory, via discretization methods.
While robust optimization is a recognized field in the operations re- search community, similar concepts have been developed independently
in the process systems engineering community under the name of flexi- bility analysis (Zhang et al., 2016). Indeed, the flexible design problem proposed in Grossmann and Sargent (1978) and Halemane and Gross- mann (1983) amounts to an adjustable robust optimization problem for the design of chemical plants. Further contributions extend the frame- work of flexibility analysis by proposing auxiliary problems to mea- sure the degree of flexibility of a given design (Grossmann et al., 1983; Swaney and Grossmann, 1985a; 1985b). As in robust optimization, flexi- bility analysis problems can be cast as SIPs or existence-constrained SIPs. Furthermore, flexibility analysis problems are commonly solved under monotonicity or convexity assumptions, which permit the reformulation of the problems as single-level problems.
The present review and most literature contributions consider mod- els without dynamics. Dealing with uncertainty has also been a long- lasting goal in the (process) control community. Therein, dynamics are essential, and thus models are differential equation systems, or even differential-algebraic equation systems. For such applications, the reader is referred to Puschke et al. (2017), Puschke et al. (2018) and Puschke and Mitsos (2018) and the references therein. Note also that SIP methods have been applied to rigorously handle path constraints in dynamic systems (Chen and Vassiliadis, 2005; Fu et al., 2015); however this does not pertain to uncertainty. Solving the subproblems in these dynamic systems is extremely challenging and currently globally only tractable for small systems.

Thermodynamics

Another application of SIP and bilevel optimization is the param- eter estimation in mixture thermodynamics, which are prevalent in chemical engineering. We will here focus on so-called excess Gibbs free energy models, which describe the deviation of a mixture from ideal behavior. For details the reader is referred to Bollas et al. (2009),
Gibbs free energy 𝐺𝑒 is given as a function of temperature 𝑇 , pressure Mitsos et al. (2009) and Glass et al. (2018a). Mathematically, the excess
𝑃 , composition 𝒛 and some adjustable parameters 𝒒. Typically, the com-
position vector 𝒛 consists of molefractions; by the closure condition one
species is not included. The latter are typically determined from equi-
indexed by 𝑘, each with composition 𝒛𝑘. As such, the corresponding librium measurements, i.e., cases where there are more than one phases
model in the parameter estimation must predict stable equilibria.
Stable equilibrium at constant temperature 𝑇 and pressure 𝑃 corre-
sible compositions 𝒛𝑘. A necessary but not suﬃcient criterion for sta- sponds to the global minimization of Gibbs free energy over the pos-
bility are the so-called isopotential equations: the chemical potential of each species is the same across each phase. Mathematically, these corre- spond to first-order optimality conditions of the minimization of Gibbs free energy. Specialized necessary and suﬃcient criteria for stability ex- ist based on tangent-plane (Baker et al., 1982) and duality (Mitsos and Barton, 2007). Simply said, these reformulate the optimality definition to a semi-infinite constraint with the advantage of reducing the dimen- sionality. For instance in the case of a binary mixture with three phases, six variables and three constraints would be used in the minimization, while a single variable is used for the specialized criteria.
Most parameter estimation tools use the necessary-only criteria re- sulting in nonlinear programs of the form
min LS 𝒛𝑘  s.t.  𝒗 𝒛𝑘, 𝒒 = 𝟎,
𝒒,𝒛𝑘
where 𝐿𝑆 is the objective function, typically least-square errors. These
nonconvex problems are typically solved with local methods resulting in
criteria, the compositions 𝒛𝑘 are not guaranteed to be stable equilibria. suboptimal fits. More gravely, by imposing the necessary-only stability
This essentially means that the excess Gibbs free energy models are ap- plied in a wrong way inside the parameter estimation. If they are then applied correctly in process simulation, very different predictions will be found.



Another approach is to solve the parameter estimation problem in a nested approach
min LS 𝒛̂𝑘 (𝒒)
𝒒
where 𝒛̂𝑘 is calculated by a thermodynamic package for a given value of 𝒒. Ideally, the same thermodynamic package is used that will then be
used also in process simulation. If the thermodynamic package is rig- orous, stability of the predictions is guaranteed. This corresponds to a nonsmooth solution method of the bilevel formulation (Dempe, 2017). This approach is in essence used in the standard tool DPP (Westhaus and Sass, 2004). As the problem is nonsmooth, either a derivative-free method or a nonsmooth method needs to be used. In practice, one can also heuristically apply a derivative-based method.
The third approach, proposed by Bollas et al. (2009), Mitsos et al. (2009) and Glass et al. (2018a) and implemented in Glass et al. (2018b) is to consider the specialized stability criterion and solve the resulting SIP. For the case of binary mixture and two phases
described by the corresponding compositions 𝑧1, 𝑧2 the optimization
problem is roughly given by
min 𝐿𝑆(𝑧1, 𝑧2)  s.t.  𝒗(𝑧1, 𝑧2, 𝒒) = 𝟎 ∧ 𝑔(𝒒, 𝑦) ≤ 0, for all 𝑦 ∈ [0, 1]
𝒒,𝑧1 ,𝑧2
It should be noted that the problems have no 𝑆𝐼𝑃 Slater points. They can
be solved approximately with the aforementioned discretization-based
algorithms. With a suitable a-priori discretization in the order of 5–10 points, a quite small number of iterations is needed, typically less than
5. Thus, the main challenge is to solve the subproblems. For a moderate number of measurement points they are tractable with standard solvers. For large numbers of parameters, they are quite expensive and still an open challenge.

Conclusions and future challenges

The present paper gives a review of current methods and applications for SIPs with nonconvex lower-level problems. While we identify multi- ple directions of research in this area, we note that all discussed methods solve the lower-level problem to global optimality, either explicitly or implicitly. Accordingly, we emphasize that the discussed methods are expected to run in acceptable time only if the lower-level dimension is moderate, say up to between four and ten, depending on the prob- lem structure. The design of methods which are able to handle larger lower-level dimensions is a basic algorithmic challenge in semi-infinite optimization. Similarly a large number of upper-level variables can be challenging.
For the development of such methods, a few benchmark problems exist as well as some comparison of algorithms. It may be helpful to organize this in a more systematic framework. Similarly, some open- source and commercial SIP solvers are available, but a larger variety is desirable.
While this paper focuses on smooth and continuous nonconvex lower-level problems, in practice semi-infinite constraints also appear in more general settings, like with nonsmooth defining functions and/or with mixed-integer variables. Some of the aforementioned methods do not make assumptions on differentiability of the functions involved and are also applicable to the mixed-integer case. However, these methods rely on the global solution of subproblems which is challenging in the nonsmooth/mixed-integer case. So overall it is fair to say that the de- velopment of theory and methods for SIPs with nonsmoothness/integer variables is still in its infancy.
As a final remark, semi-infinite constraints can as well appear in the formulation of instances of other problem classes such as multi-objective programming, bilevel programming and Nash equilibrium problems. The combination of the methods from the present survey with ap- proaches for these problem classes is a challenging subject of future research. Similarly, an opportunity exists for the robust optimization
community to use classic and recent theory, algorithms and solvers from SIP.

Declaration of Competing Interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

References

Adjiman, C.S., Androulakis, I.P., Floudas, C.A., 1998. A global optimization method, al- phaBB, for general twice-differentiable constrained NLPs – II. Implementation and computational results. Comput. Chem. Eng. 22, 1159–1179.
Adjiman, C.S., Dallwig, S., Floudas, C.A., Neumaier, A., 1998. A global optimization method, alphaBB, for general twice-differentiable constrained NLPs – I. Theoretical advances. Comput. Chem. Eng. 22, 1137–1158.
Baker, L.E., Pierce, A.C., Luks, K.D., 1982. Gibbs energy analysis of phase equilibria. Soc.
Petrol Eng. J. 22 (5), 731–742.
Ben-Tal, A., El Ghaoui, L., Nemirovski, A.S., 2009. Robust optimization. Princeton Series in Applied Mathematics. Princeton University Press.
Ben-Tal, A., Goryashko, A., Guslitzer, E., Nemirovski, A., 2004. Adjustable ro- bust solutions of uncertain linear programs. Math. Program. 99 (2), 351–376. doi:10.1007/s10107-003-0454-y.
Ben-Tal, A., Nemirovski, A., 1999. Robust solutions of uncertain linear programs. Oper.
Res. Lett. 25 (1), 1–13. doi:10.1016/S0167-6377(99)00016-4.
Bertsimas, D., Nohadani, O., Teo, K.M., 2009. Nonconvex robust optimization for problems with constraints. INFORMS J. Comput. 22, 1–177.
Bhattacharjee, B., 2003. Kinetic Model Reduction Using Integer and Semi-infinite Pro- gramming. Massachusetts Institute of Technology PhD thesis.
Bhattacharjee, B., Green Jr., W.H., Barton, P.I., 2005. Interval methods for semi-infinite programs. Comput. Optim. Appl. 30 (1), 63–93. doi:10.1007/s10589-005-4556-8.
Bhattacharjee, B., Lemonidis, P., Green Jr., W.H., Barton, P.I., 2005. Global solution of semi-infinite programs. Math. Program. 103 (2), 283–307. doi:10.1007/s10107-005-0583-6.
Bhattacharjee, B., Schwer, D.A., Barton, P.I., Green Jr., W.H., 2003. Optimally-reduced ki- netic models: reaction elimination in large-scale kinetic mechanisms. Combust. Flame 135 (3), 191–208. doi:10.1016/s0010-2180(03)00159-7.
Lo Bianco, C.G., Piazzi, A., 2001. A hybrid algorithm for infinitely constrained optimiza- tion. Int. J. Syst. Sci. 32 (1), 91–102. doi:10.1080/00207720121051.
Birge, J.R., Louveaux, F., 1997. Introduction to Stochastic Programming. Springer-Verlag. Blankenship, J.W., Falk, J.E., 1976. Infinitely constrained optimization problems. J. Op-
tim. Theory Appl. 19 (2), 261–281. doi:10.1007/bf00934096.
Bollas, G.M., Barton, P.I., Mitsos, A., 2009. Bilevel optimization formulation for parameter estimation in vapor-liquid(-liquid) phase equilibrium problems. Chem. Eng. Sci. 64 (8), 1768–1783. doi:10.1016/j.ces.2009.01.003.
Chen, T.W.C., Vassiliadis, V.S., 2005. Inequality path constraints in optimal control: a fi- nite iteration epsilon-convergent scheme based on pointwise discretization. J. Process Control 15 (3), 353–362.
Dempe, S., 2017. Bilevel optimization: reformulation and first optimality conditions. In: Aussel, D., Lalitha, C. (Eds.), Generalized Nash Equilibrium Problems, Bilevel Pro- gramming and MPEC, Forum for Interdisciplinary Mathematics. Springer, Singapore. Djelassi, H., 2020. Discretization-based Algorithms for the Global Solution of Hierarchical
Programs. RWTH Aachen University, Aachen, Germany PhD thesis.
Djelassi, H., Glass, M., Mitsos, A., 2019. Discretization-based algorithms for generalized semi-infinite and bilevel programs with coupling equality constraints. J. Glob. Optim. 75 (2), 341–392. doi:10.1007/s10898-019-00764-3.
Djelassi, H., Mitsos, A., 2017. A hybrid discretization algorithm with guaranteed feasibility for the global solution of semi-infinite programs. J. Glob. Optim. 68 (2), 227–253. doi:10.1007/s10898-016-0476-7.
Djelassi, H., Mitsos, A., 2021. Global solution of semi-infinite programs with existence constraints. J. Optim. Theory Appl. doi:10.1007/s10957-021-01813-2.
Falk, J.E., Hoffman, K., 1977. A nonconvex max-min problem. Nav. Res. Logist. Q. 24 (3), 441–450. doi:10.1002/nav.3800240307.
Fan, X., Li, M., Gao, F., 2018. A noninterior point homotopy method for semi- infinite programming problems. J. Appl. Math. Comput. 56 (1–2), 179–194. doi:10.1007/s12190-016-1067-y.
Floudas, C.A., Stein, O., 2007. The adaptive convexification algorithm: a feasible point method for semi-infinite programming. SIAM J. Optim. 18 (4), 1187–1208. doi:10.1137/060657741.
Fu, J., Faust, J.M.M., Chachuat, B., Mitsos, A., 2015. Local optimization of dynamic pro- grams with guaranteed satisfaction of path constraints. Automatica 62, 184–192.
Glass, M., Djelassi, H., Mitsos, A., 2018. Parameter estimation for cubic equations of state models subject to suﬃcient criteria for thermodynamic stability. Chem Eng Sci 192, 981–992. doi:10.1016/j.ces.2018.08.033.
Glass, M., Hoffmann, T., Mitsos, A., 2018b. Bilevel optimization algorithm for rigorous & robust parameter estimation in thermodynamics. Accessed 05 February 2021, https://www.avt.rwth-aachen.de/cms/AVT/Forschung/Software/~kvkz/BOARPET/.  Goberna, M. A., 2013. NEOS semiinfinite programming directiory. Accessed November
10, 2020, https://neos-guide.org/content/semi-infinite-programming.
Goberna, M.A., López, M.A., 1998. Linear Semi-infinite Optimization. Wiley, Chichester. Goberna, M.A., López, M.A., 2018. Recent contributions to linear semi-infinite optimiza- tion: an update. Ann. Oper. Res. 271 (1), 237–278. doi:10.1007/s10479-018-2987-8.



Graettinger, T.J., Krogh, B.H., 1988. The acceleration radius: a global performance mea- sure for robotic manipulators. IEEE J. Robot. Autom. 4, 60–69.
Green Jr., W.H., Barton, P.I., Bhattacharjee, B., Matheu, D.M., Schwer, D.A., Song, J., Sumathi, R., Carstensen, H.H., Dean, A.M., Grenda, J.M., 2001. Computer construc- tion of detailed chemical kinetic models for gas-phase reactors. Ind. Eng. Chem. Res. 40 (23), 5362–5370.
Gritzmann, P., Klee, V., 1994. On the complexity of some basic problems in computational convexity. I. Containment problems. Discret. Math. 136 (1–3), 129–174.
Grossmann, I.E., Halemane, K.P., Swaney, R.E., 1983. Optimization strate- gies for flexible chemical processes. Comput. Chem. Eng. 7 (4), 439–462. doi:10.1016/0098-1354(83)80022-2.
Grossmann, I.E., Sargent, R.W.H., 1978. Optimum design of chemical plants with uncer- tain parameters. AlChE J. 24 (6), 1021–1028. doi:10.1002/aic.690240612.
Guerra Vázquez, F., Rückmann, J.J., Stein, O., Still, G., 2008. Generalized semi- infinite programming: a tutorial. J. Comput. Appl. Math. 217 (2), 394–419. doi:10.1016/j.cam.2007.02.012.
Halemane, K.P., Grossmann, I.E., 1983. Optimal process design under uncertainty. AlChE
J. 29 (3), 425–433. doi:10.1002/aic.690290312.
Harwood, S. M., Papageorgiou, D. J., Trespalacios, F., 2019. A note on semi-infinite pro- gram bounding methods. arXiv:191201763v1.
Hettich, R., Kortanek, K.O., 1993. Semi-infinite programming: theory, methods, and ap- plications. SIAM Rev. 35 (3), 380–429. doi:10.1137/1035089.
Hettich, R., Zencke, P., 1982. Numerische Methoden der Approximation und semi-in- finiten Optimierung. Teubner, Stuttgart.
Horst, R., Tuy, H., 1996. Global Optimization. Springer, Berlin Heidelberg doi:10.1007/978-3-662-03199-5.
Kirst, P., Stein, O., 2016. Solving disjunctive optimization problems by generalized semi-infinite optimization techniques. J. Optim. Theory Appl. 169, 1079–1109.
Kirst, P., Stein, O., 2019. Global optimization of generalized semi-infinite programs using disjunctive programming. J. Glob. Optim. 73 (1), 1–25. doi:10.1007/s10898-018-0690-6.
Kleniati, P.M., Adjiman, C.S., 2014. Branch-and-sandwich: a deterministic global opti- mization algorithm for optimistic bilevel programming problems. Part I: theoretical development. J. Glob. Optim. 60 (3), 425–458. doi:10.1007/s10898-013-0121-7.
Kleniati, P.M., Adjiman, C.S., 2014. Branch-and-sandwich: a deterministic global op- timization algorithm for optimistic bilevel programming problems. Part II: con- vergence analysis and numerical results. J. Glob. Optim. 60 (3), 459–481. doi:10.1007/s10898-013-0120-8.
Kleniati, P.M., Adjiman, C.S., 2015. A generalization of the branch-and-sandwich algo- rithm: from continuous to mixed-integer nonlinear bilevel problems. Comput. Chem. Eng. 72, 373–386. doi:10.1016/j.compchemeng.2014.06.004.
Lampariello, L., Sagratella, S., Shikhman, V., Stein, O., 2020. Interactions between bilevel optimization and Nash games. In: Dempe, S., Zemkoho, A. (Eds.), Bilevel Optimiza- tion: Advances and Next Challenges. Springer, pp. 3–26.
Liu, G., 2007. A homotopy interior point method for semi-infinite programming problems.
J. Glob. Optim. 37 (4), 631–646. doi:10.1007/s10898-006-9077-1.
López, M.A., Still, G., 2007. Semi-infinite programming. Eur. J. Oper. Res. 180 (2), 491–
518. doi:10.1016/j.ejor.2006.08.045.
López, M. A., Still, G., 2012. References in semi-infinite optimization. Accessed November 10, 2020, http://wwwhome.math.utwente.nl/~stillgj/sip/lit-sip.pdf.
Luo, Z., Pang, J., Ralph, D., 1996. Mathematical Programs with Equilibrium Constraints.
Cambridge University Press, Cambridge.
Lv, J., Pang, L.P., Xu, N., Xiao, Z.H., 2019. An infeasible bundle method for nonconvex constrained optimization with application to semi-infinite programming problems. Numer. Algorithms 80 (2), 397–427. doi:10.1007/s11075-018-0490-6.
Mangasarian, O.L., 2002. Set containment characterization. J. Glob. Optim. 24 (4), 473–480.
Marendet, A., Goldsztejn, A., Chabert, G., Jermann, C., 2020. A standard branch-and- bound approach for nonlinear semi-infinite problems. Eur. J. Oper. Res. 282 (2), 438–
452. doi:10.1016/j.ejor.2019.10.025.
Mitsos, A., 2010. Global solution of nonlinear mixed-integer bilevel programs. J. Glob.
Optim. 47 (4), 557–582. doi:10.1007/s10898-009-9479-y.
Mitsos, A., 2011. Global optimization of semi-infinite programs via re- striction of the right-hand side. Optimization 60 (10–11), 1291–1308. doi:10.1080/02331934.2010.527970.
Mitsos, A., Barton, P.I., 2007. A dual extremum principle in thermodynamics. AlChE J. 53 (8), 2131–2147.
Mitsos, A., Bollas, G.M., Barton, P.I., 2009. Bilevel optimization formulation for parameter estimation in liquid-liquid phase equilibrium problems. Chem. Eng. Sci. 64 (3), 548–
559. doi:10.1016/j.ces.2008.09.034.
Mitsos, A., Lemonidis, P., Barton, P.I., 2008. Global solution of bilevel pro- grams with a nonconvex inner program. J. Glob. Optim. 42 (4), 475–513. doi:10.1007/s10898-007-9260-z.
Mitsos, A., Lemonidis, P., Lee, C.K., Barton, P.I., 2008. Relaxation-based bounds for semi- infinite programs. SIAM J. Optim. 19 (1), 77–113. doi:10.1137/060674685.
Mitsos, A., Oxberry, G.M., Barton, P.I., Green Jr., W.H., 2008. Optimal automatic reaction and species elimination in kinetic mechanisms. Combust. Flame 155 (1–2), 118–132. Mitsos, A., Tsoukalas, A., 2015. Global optimization of generalized semi-infinite pro- grams via restriction of the right hand side. J. Glob. Optim. 61 (1), 1–17.
doi:10.1007/s10898-014-0146-6.
Mutapcic, A., Boyd, S., 2009. Cutting-set methods for robust convex optimization with pessimizing oracles. Optim. Methods Softw. 24 (3), 381–406.
Nguyen, V.H., Strodiot, J.J., 1992. Computing a global optimal solution to a design cen- tering problem. Math Program. 53 (1, Ser. A), 111–123.
Okuno, T., Fukushima, M., 2020. An interior point sequential quadratic programming- type method for log-determinant semi-infinite programs. J. Comput. Appl. Math. 376, 112784. doi:10.1016/j.cam.2020.112784.
Oluwole, O.O., Barton, P.I., Green Jr., W.H., 2007. Obtaining accurate solutions us- ing reduced chemical kinetic models: a new model reduction method for mod- els rigorously validated over ranges. Combust. Theor. Model. 11 (1), 127–146. doi:10.1080/13647830600924601.
Oluwole, O.O., Bhattacharjee, B., Tolsma, J.E., Barton, P.I., Green Jr., W.H., 2006. Rig- orous valid ranges for optimally reduced kinetic models. Combust. Flame 146 (1–2), 348–365.
Ordóñez, F., Zhao, J., 2007. Robust capacity expansion of network flows. Networks 50 (2), 136–145. doi:10.1002/net.20183.
Polak, E., 1982. An implementable algorithm for the optimal design centering, tolerancing, and tuning problem. J. Optim. Theory Appl. 37 (1), 45–67.
Polak, E., 1997. Optimization. Algorithms and Consistent Approximations. Springer, Berlin.
Puschke, J., Djelassi, H., Kleinekorte, J., Hannemann-Tamás, R., Mitsos, A., 2018. Ro- bust dynamic optimization of batch processes under parametric uncertainty: utiliz- ing approaches from semi-infinite programs. Comput. Chem. Eng. 116, 253–267. doi:10.1016/j.compchemeng.2018.05.025.
Puschke, J., Mitsos, A., 2018. Robust feasible control based on multi-stage eNMPC con- sidering worst-case scenarios. J. Process Control 69, 8–15.
Puschke, J., Zubov, A., Kosek, J., Mitsos, A., 2017. Multi-model approach based on para- metric sensitivities - a heuristic approximation for dynamic optimization of semi-batch processes with parametric uncertainties. Comput. Chem. Eng. 98, 161–179.
Reemtsen, R., Görner, S., 1998. Numerical methods for semi-infinite programming: a sur- vey. In: Reemtsen, R., Rückmann, J.J. (Eds.), Semi-Infinite Programming. Springer, US, pp. 195–275.
Remez, E.I.A., 1962. General computational methods of Chebyshev approximation: The problems with linear real parameters. U. S. Atomic Energy Commission, Division of Technical Information.
Sahinidis, N.V., 2004. Optimization under uncertainty: state-of-the-art and opportunities.
Comput. Chem. Eng. 28 (6–7), 971–983.
Schwer, D.A., Lu, P.S., Green Jr., W.H., 2003. An adaptive chemistry approach to modeling complex kinetics in reacting flows. Combust. Flame 133 (4), 451–465.
Seidel, T., Küfer, K.H., 2020. An adaptive discretization method solving semi- infinite optimization problems with quadratic rate of convergence. Optimization doi:10.1080/02331934.2020.1804566.
Shapiro, A., 2009. Semi-infinite programming, duality, discretization and optimality con- ditions. Optimization 58 (2), 133–161. doi:10.1080/02331930902730070.
Stein, O., 2003. Bi-level strategies in semi-infinite programming. Nonconvex Optimization and Its Applications, vol 71. Springer, US, New York, NY doi:10.1007/978-1-4419-9164-5.
Stein, O., 2006. A semi-infinite approach to design centering. In: Dempe, S., Kalash- nikov, V. (Eds.), optimization With Multivalued Mappings: Theory. Applications, and Algorithms Springer, US, Boston, MA, pp. 209–228. doi:10.1007/0-387-34221-4_10.
Stein, O., 2012. How to solve a semi-infinite optimization problem. Eur. J. Oper. Res. 223 (2), 312–320. doi:10.1016/j.ejor.2012.06.009.
Stein, O., Steuermann, P., 2012. The adaptive convexification algorithm for semi- infinite programming with arbitrary index sets. Math. Program. 136 (1), 183–207. doi:10.1007/s10107-012-0556-5.
Stein, O., Still, G., 2002. On generalized semi-infinite optimization and bilevel optimiza- tion. Eur. J. Oper. Res. 142 (3), 444–462. doi:10.1016/s0377-2217(01)00307-1.
Stein, O., Still, G., 2003. Solving semi-infinite optimization problems with interior point techniques. SIAM J. Control Optim. 42 (3), 769–788. doi:10.1137/s0363012901398393.
Still, G., 1999. Generalized semi-infinite programming: theory and methods. Eur. J. Oper.
Res. 119 (2), 301–313. doi:10.1016/s0377-2217(99)00132-0.
Still, G., 2001. Generalized semi-infinite programming: numerical aspects. Optimization 49 (3), 223–242.
Stuber, M.D., Barton, P.I., 2015. Semi-infinite optimization with implicit functions. Ind.
Eng. Chem. Res. 54 (1), 307–317. doi:10.1021/ie5029123.
Swaney, R.E., Grossmann, I.E., 1985. An index for operational flexibility in chem- ical process design. Part I: formulation and theory. AlChE J. 31 (4), 621–630. doi:10.1002/aic.690310412.
Swaney, R.E., Grossmann, I.E., 1985. An index for operational flexibility in chemi- cal process design. Part II: computational algorithms. AlChE J. 31 (4), 631–641. doi:10.1002/aic.690310413.
Takeda, A., Taguchi, S., Tütüncü, R.H., 2007. Adjustable robust optimization mod- els for a nonlinear two-period system. J. Optim. Theory Appl. 136 (2), 275–295. doi:10.1007/s10957-007-9288-8.
Tsoukalas, A., Rustem, B., 2011. A feasible point adaptation of the Blankenship and Falk algorithm for semi-infinite programming. Optim. Lett. 5 (4), 705–716. doi:10.1007/s11590-010-0236-4.
Tsoukalas, A., Rustem, B., Pistikopoulos, E.N., 2009. A global optimization algorithm for generalized semi-infinite, continuous minimax with coupled constraints and bi-level problems. J. Glob. Optim. 44 (2), 235–250. doi:10.1007/s10898-008-9321-y.
Watson, G.A., 1983. Numerical experiments with globally convergent methods for semi-infinite programming problems. In: Fiacco, A.V., Kortanek, K.O. (Eds.), Semi- Infinite Programming and Applications. Springer, Berlin, Heidelberg, pp. 193–205. doi:10.1007/978-3-642-46477-5_13.
Westhaus, I.U., Sass, R., 2004. From raw physical data to reliable thermodynamic model parameters through dechema data preparation package. Fluid Phase Equilib. 222– 223, 49–54. doi:10.1016/j.fluid.2004.06.036. Proceedings of the Fifteenth Sympo- sium on Thermophysical Properties, code under https://dechema.de/en/dpp.html



Wiesemann, W., Tsoukalas, A., Kleniati, P.M., Rustem, B., 2013. Pessimistic bilevel opti- mization. SIAM J. Optim. 23 (1), 353–380. doi:10.1137/120864015.
Winterfeld, A., 2008. Application of general semi-infinite programming to lapidary cutting problems. Eur. J. Oper. Res. 191 (3), 838–854. doi:10.1016/j.ejor.2007.01.057.
Zhang, L., Wu, S.Y., López, M.A., 2010. A new exchange method for convex semi-infinite programming. SIAM J. Optim. 20 (6), 2959–2977.
Zhang, Q., Grossmann, I.E., Lima, R.M., 2016. On the relation between flexibility analysis and robust optimization for linear systems. AlChE J. 62 (9), 3109–3123. doi:10.1002/aic.15221.
