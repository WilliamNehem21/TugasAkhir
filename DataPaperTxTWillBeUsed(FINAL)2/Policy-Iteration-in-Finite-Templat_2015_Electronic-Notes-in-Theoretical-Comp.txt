Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 317 (2015) 3–18
www.elsevier.com/locate/entcs
Policy Iteration in Finite Templates Domain
Assal´e Adj´e 1,2
DTIM
Onera Toulouse
31055 Toulouse Cedex 4 - France.

Abstract
We prove in this paper that policy iteration can be generally defined in finite domain of templates using La- grange duality without any assumption on the templates. Such policy iteration algorithm always converges to a fixed point under a very simple technical condition. This fixed point furnishes a safe over-approximation of the set of reachable values taken by the variables of a program. The paper also discusses the choice of good templates and links these good templates to invariant algebraic relations. When templates are well chosen, the policy iteration algorithm developed in this paper can be easily initialised for one single loop programs.
Keywords: Abstract interpretation, policy iteration, convex optimisation.

Introduction
In [1,2], we introduced a complete lattice consisting of sub-level sets of (possibly non-convex) functions, which we use as an abstract domain in the sense of abstract interpretation [5] for computing numerical program invariants. This abstract do- main is parameterised by a basis of functions, akin to the approach put forward by Manna, Sankaranarayanan, and Sipma (the linear template abstract domain [17]), except that the basis functions or templates which we used need not be lin- ear. In [1,2], we also developed a policy iteration scheme using Shor relaxation and semi-definite programming in the case of affine arithmetics and quadratic con- straints. We only proved that this latter policy iteration converged to a postfixpoint of the relaxed semantics. Moreover, in [1,2], the quadratic templates were provided by the user or more precisely an automatician. Indeed, the set of quadratic tem- plates used in examples of [1,2] contains a Lyapunov function of the affine systems induced by the (affine) arithmetics programs. The usage of Lyapunov functions as quadratic templates was fully automatised by Roux et al in [13].

1 Email: assale.adje@onera.fr
2 The author is supported by the RTRA / STAE Project BRIEFCASE.

http://dx.doi.org/10.1016/j.entcs.2015.10.002
1571-0661/© 2015 The Author. Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

Contribution of the paper. In this paper, we present a policy iteration algo- rithm in finite templates domain using Lagrange duality without any restriction on the arithmetics of the program or the algebraic structure of templates. We also prove that such policy iteration algorithm converges to a fixed point of the relaxed semantics functional.
The paper also deals with the generation of good templates in the simple case of one-loop programs and we link the notion of good templates with Lyapunov functions. Indeed, templates can be thought as invariant algebraic relations which help to prove correctness of the programs. We show that a good choice of templates leads a natural initial policy.
Organisation of the paper. The paper is organised as follows. Section 2 recalls the abstract domain based on non-linear templates and abstract semantics functional. Section 3 details the general construction of the relaxed semantics function using Lagrange duality. Section 4 recalls both Kleene iteration and policy iteration in templates domain and gives convergence proofs. Section 5 proposes a discussion on what the good templates are and how we can initialise policy iteration easily in case on one-loop programs. Section 6 consists in applications. Finally Section 7 concludes.

Recalling the generalised templates
In [1,2], we introduced the concept of generalised templates which are just functions from Rd to R. We can think of hidden algebraic relations to prove certain properties on the analysed program. For the moment, we suppose that these functions are given by some oracles. Suppose that the subset of relations between variables is fixed, we denote by P this set and P ⊆ F Rd, R . First, we recall the basic definitions (abstraction and concretisation maps) and prove that this pair of maps forms a Galois connection. Then we describe the lattice structures of abstract and concrete domains.

Basic notions
We are interested in replacing the classical concrete semantics by meaning of sub- level sets i.e. we have a functional representation of numerical invariants through the functions of P. An invariant will be determined as the intersection of sub-level sets. The problem is thus reduced to find the optimal levels on each templates p. We introduce a set of functions from P to R = R ∪ {−∞} ∪ {+∞} denoted by F P, R . For an element v ∈ F P, R , we associate the intersection of sub-level sets defined by v(p) where p belongs to P.
Definition 2.1 (P-sub-level sets) To a function v ∈ F P, R , we associate the
P-sub-level set denoted by v٨ and deﬁned as:
v٨ = {x ∈ Rd | p(x) ≤ v(p), ∀p ∈ P} =	{x ∈ Rd | p(x) ≤ v(p)}
p∈P

When P is a set of convex functions, the P-sub-level sets corresponds to the inter- section of classical sub-level sets from convex analysis. In our case, P can contain non-convex functions so P-sub-level sets are not necessarily convex in the usual sense.
We also want a functional representation of a set. In convex analysis, it is well- known that a closed convex set can be represented by its support function i.e. the supremum of linear forms on the set (e.g. [14, § 13]). Here, we use the same notion but we replace the linear forms by the functions p ∈ P which are not necessarily linear. This generalisation is not new and was introduced by Moreau [11]. The reader can be also consult [15,16] for more details about those concepts.
Definition 2.2 (P-support functions) To X ⊆ Rd, we associate the abstract support function denoted by X† and deﬁned as:
X†(p)= sup p(x)
x∈X

We equip the F P, R  with the classical partial order for the functions i.e v ≤ w ⇐⇒ v(p) ≤ w(p) for all p ∈ P . We order the set of the subsets of Rd by the inclusion. By taking these orders, we get the following proposition.
Proposition 2.1 The pair of maps v '→ v٨ and X '→ X† deﬁnes a Galois connec- tion between F P, R and the set of subsets of Rd.
In the terminology of abstract interpretation, (.)† is the abstraction function, and (.)٨ is the concretisation function. The Galois connection result will provide the correctness of the semantics.
The lattices of P-convex sets and P-convex functions
Now, we are interested in closed elements (in term of Galois connection) that we call here P-convex elements.

Definition 2.3 (P-convexity) Let v ∈ F P, R , we say that v is a P-convex func- tion if v = (v٨)†. A set X ⊂ Rd is a P-convex set if X = (X†)٨.

Definition 2.4 We respectively denote by VexP(P '→ R) and VexP(Rd) the set of
P-convex function of F P, R  and the set of P-convex sets of Rd.

The family of functions VexP(P '→ R) is ordered by the partial order of real-valued functions i.e v ≤ w ⇐⇒ v(p) ≤ w(p) ∀p ∈ P. The family of set VexP(Rd) is ordered by the inclusion order denoted by ⊆. Galois connection permits to construct lattice operations on P-convex elements. Note that as classical convex notion, infima of P-convex functions and joins of P-convex sets are not P-convex and should be convexified. Moreover, as classical convexity, P-convexity is preserved by functional suprema and intersections (meets of P-convex sets).

Definition 2.5 (The meet and join) Let v and w be in F P, R . We denote by inf(v, w) and sup(v, w) the functions deﬁned respectively by, p '→ inf(v(p), w(p)) and p '→ sup(v(p), w(p)). We equip VexP(P '→ R) with the join operator v ∨ w =

sup(v, w) and the meet operator v ∧w = (inf(v, w)٨)†. Similarly, we equip VexP(Rd)
with the join operator X H Y = ((X ∪ Y )†)٨ and the meet operator X H Y = X ∩ Y .
It is well-known that with the previous lattice operations, the lattice sets of P-convex elements are isomorphic complete lattices. The next theorem follows readily from the fact that the pair of functions v '→ v٨ and C '→ C† defines a Galois connection, see e.g. [7, § 7.27].

Theorem 2.2 (VexP(P '→ R), ∧, ∨) and (VexP(Rd), H, H) are isomorphic complete lattices.


Abstract semantics
Suppose now we are given a program with d variables (x1,..., xd) and n control points numbered from 1 to n. We suppose this program is written in a simple toy ver- sion of a C-like imperative language, comprising global variables, no procedures, as- signments of variables using only parallel assignments (x1,..., xd)= T (x1,..., xd), tests of the form r(x1,..., xd) ≤ 0, where r : Rd '→ Rm (m denotes the number of conjunctions of real tests), and while loops with similar entry tests. We do not recapitulate the standard collecting semantics that associates to this program a monotone map F : ℘(Rd) n → ℘(Rd) n whose least fixed points lfp(F ) has as ith component (i = 1,..., n) the subset of Rd of values that the d variables x1,..., xd can take at control point i. The aim of this section is to compute, inductively on the syntax, the abstraction (or a good over-approximation of it) F of F from F P, R n to itself defined as usual as using Proposition 2.1:

F : VexP(P '→ R) n → VexP(P '→ R) n
v	'→ (F (v٨))†	:= p '→	sup	p(y)
y∈F (vs))

The notation v٨ is in fact the vector of sets (v٨, ··· , v٨), (F (v٨)†) is also interpreted
1	n
component-wise. We recall that standard collecting semantics F can only take three
forms at some control point l. For variable assignments with a map T : Rd → Rd which acts on set of control point lj: Fl(X) = T (Xl′ ). We will denote by A the set of control points representing assignments. For assignments under tests (for both branches of conditional branchments) with a map T : Rd → Rd (acting on set of control point lj) and a test map rl : Rd → Rm: Fl(X)= T (Xl′ ∩ r—1(Rm)).
l	—
We will denote by I the set of control points representing assignments under tests.
For unions (for while loops and join of both branches of condition branchments): Fl(X) = Xl1 ∪ Xl2 . We will denote by U the set of control points representing unions.  Finally, the abstract functional F  takes the following form in case of

assignments under tests and assignments (taking rl ≡ −1 for instance):


sup
y∈T (vs ∩r−1(Rm))

p(y)= sup
x∈vs

p(T (x)) if l ∈ A ∪ I



sup
y∈vs ∪vs
p(y)= v٨
∪ v٨ † (p)	if l ∈ U

In case of assignments, the abstract functional is the value functional of a con- strained optimisation problem and the new least fixed point equation to solve be- comes:

inf{v ∈ VexP(P '→ R) n | F (v) ≤ v} .	(2)
Relaxed semantics using Lagrange duality
In this section, we construct the relaxed semantics from Lagrange duality in general setting without any consideration (except finiteness) on the set of the templates. This construction is an asbtract version of the work of Gaubert et al [8] where the authors only deal with linear templates and affine program arithmetics. Here, the templates and program arithmetics can be non-linear. Nevertheless, non-linearity implies that abstract semantics and relaxed semantics are not equal in general.
First, we quickly recall the concept of Lagrange duality. Then, we construct the relaxed semantics on the assignments, tests and joins. Finally, we present the properties of the relaxed semantics that will be used to prove convergence of policy iteration algorithm to a fixed point of relaxed semantics.

Lagrange duality
Let f , {fi}i=1,...,k be functions on Rd. Let us consider the following constrained maximisation problem:
sup{f (x) | fi(x) ≤ 0, ∀i = 1,..., k}	(3)
In constrained optimisation, it is classical to construct another constrained optimi- sation problem from the initial one in order to solve an easier problem. Lagrange duality (for details see e.g. [4, § 5.3]) consists adding linearly the constraints with a weight on each (Lagrange multipliers) to the objective function. and optimise both weights and problem variable. In our context, the optimal value of Problem (3) is given by the sup-inf (primal) value (4):


sup
inf
f (x) − Σ λifi(x) .	(4)


The weak duality theorem (see e.g. [4, Prop. 5.6.1]) ensures that if we commute the inf and the sup in Formula (4), the result (dual value) is greater than the optimal

value of Problem (4).


inf
sup f (x) − Σ λifi(x) .	(5)


Note that the function λ '→ supx∈Rd f (x)−Σk	λifi(x) is always convex (the image
of a segment is smaller than the segment of images) and lower semi-continuous (the
sublevel sets are topologically closed), so it has good properties to minimise it.
Finally, the optimal values of Problem (4) and Problem (5) coincide (strong duality theorem see e.g. [4, Prop. 5.3.2]) when the functions −f , fi are convex lower semi-continuous and if the Slater’s condition (i.e. there exists x ∈ Rd such that fi(x) < 0 for all i = 1,..., k) holds. The Slater’s condition will be discussed in Subsection 3.4.

Abstraction of assignments and test using Lagrange duality
Equation (1) becomes an optimisation problem of the form of Equation (3) and we can use Lagrange duality as in the first step of Subsection 3.1. In our case, Lagrange multipliers are some non-negative functions λ from P to R. We thus consider the function which we will call the relaxed function:
 FR(v) (p)=	inf	sup p(T (x)) + Σ λ(q) (vl′ (q) − q(x)) − μ rl(x) .	(6)

l
λ∈F(P,R+) x∈Rd
μ∈Rm

q∈P


Abstraction of loops

Note that the following double inequalities hold for all v ∈ F P, R n,
sup(vexP(vl1 ), vexP(vl2 )) ≤ v	∪ v  ≤ sup(v , vl )	(7)
٨	٨  †
2
This means that as for zones, the union of two such P-convex functions vl1 and vl2
is directly given by taking their maximum on each element of the basis of functions
P. Nevertheless, during the fixed point iteration (as in Section 4) the functions vl1 and vl2 are not necessarily P-convex. Moreover, if we take the abstract semantics F (v), we do not have an infimum of linear forms (or at least a maximum of linear forms) on the abstract values vl1 and vl2 , a formulation that we need. Finally, we relaxed the abstract semantics F (v) by the supremum itself and:
FR(v)= sup(vl , vl ) .	(8)
l	1	2
Properties of the relaxed semantics
The introduction of relaxed semantics aims to get better computational properties of the semantics. We describe in this subsection the properties of the relaxed semantics which justify the using of the new semantics.

First, we recall that relaxed semantics is a safe over-approximation of the ab- stract semantics (Theorem 3.5 in [2]).

Theorem 3.1 Let i be in A ∪ I ∪ U. For all v ∈ F P, R n, F (v) ≤ FR(v).
Furthermore, we recall that relaxed semantics is monotone (Prop 3.7 in [2]). This property is crucial to show that policy iteration provides more and more precise over-approximation of an invariant until a fixed point is reached.

Proposition 3.2 For i ∈ A ∪ I ∪ U, v '→ FR(v) is monotone on the set F P, R n.
Finally, we recall that the relaxed semantics functional acts as an affine maps on the abstract element (see Lemma 3.10 in [2]). This property is used to prove that Let v be in F P, R n and let i ∈ A ∪ I, we now define, for p ∈ P, for (λ, μ) ∈
F (P, R+) × Rm, F λ,μ(v) by:
+	i
 F λ,μ(v) (p) := Σ λ(q)vl′ (q)+ V λ,μ(p)	(9)

where V λ,μ(p) := sup p ◦ T (x) − Σ λ(q)q(x) − μ rl(x) .	(10)

x∈Rd
q∈P

The relaxed functional can now be readily rewritten as follows.

Lemma 3.3 For i ∈ A ∪ I:  FR(v) (p)= infλ∈F(P,R
μ∈Rm
) F λ,μ(v) (p) .

Now, we discuss Slater’s condition. First, we give the formal definition of it.
Definition 3.1 (Slater’s condition) Let f : Rd → R and g : Rd '→ Rk. A constrained maximisation sup{f (x) | g(x) ≤ 0, x ∈ Rd} satisﬁes Slater’s condition iff there exists x0 ∈ Rd such that g(x0) < 0 i.e. for all coordinates i = 1,..., k, gi(x0) < 0.
Slater’s condition is linked to the non-emptiness of the interior of the set of con- straints. Indeed if the interior of set of constraints is nonempty and constraints function gi are convex and lower-semicontinuous, then int({x ∈ Rd | g(x) ≤ 0}) = 
{x ∈ Rd | g(x) < 0}, where int denotes the interior set and g = (g1, g2,..., gk).
Depending on templates we choose, it is easy to check Slater’s condition. For example, taking a set of templates P such that for some x0 ∈ Rd, p(x0) = 0 for all p ∈ P, for i ∈ A ∪ I, if vl(i)(p) > 0 and rl(x0) < 0, then Slater’s condition holds for maximisation problem (1).
In term of static analysis, fixed point iteration appears when the analysed pro- gram contains loops. Slater’s condition can fail when the set of possible values taken during the loop iteration is a singleton or templates p are equalities (splitted in p and −p) invariant by loop body.
Slater’s condition is a sufficient condition to the existence of optimal solutions to the minimisation problem which appears in relaxed functional. Indeed Slater’s condition implies the level boundiness of the dual functional. Optimal solutions will be used to compute a ”pivoting” policy when a fixed point is not reached.

Proposition 3.4 (Selection property) Let i ∈ A ∪ I. Assume that the maximi- sation problem (1) satisﬁes the Slater’s condition and for all p ∈ P, there exists (λp, μp) ∈ F (P, R+) × Rm such that:
sup p(T (x)) − Σ λp(q)q(x) − μ rl(x)

x∈Rd
q∈P


is ﬁnite. Then the minimisation problem (6) admits a solution i.e. for all p ∈ P, there exists (λp∗, μp∗) ∈ F (P, R+) × R+ such that:
 FR(v) (p)= p ◦ T (x)+ Σ λp∗(q) vl′ (q) − q(x) − μ∗ rl(x)

The last result of this section discuss about continuity of the relaxed functional. Kleene iteration and policy iteration are iterative processes to compute fixed point. It is important to prove that the limits of the sequences produced by both iterations scheme are fixed points. To show it, we need continuity.
Proposition 3.5 (Continuity result on FR) The following assertions holds:

Let i ∈ A ∪ I ∪ U. Let p ∈ P. For all decreasing sequences (vn)n≥0 ∈ F P, R :

 FR( inf vn)  (p)=  inf FR(vn)  (p) .

Let p ∈ P. Let i ∈ A ∪ I. Assume, there exists a nonempty compact set

K	such that  FR(·) (p) = inf
sequences (vn)n≥0 ∈ F  P, R n:

i,p
F λ,μ(·)(p); Then for all increasing

 sup FR(vn) (p)= FR(sup vn) (p) .
	

Solving fixed point equations
Fixed point equations in templates domain
As usual in abstract interpretation, we are interested in solving the least fixed point Equation (2). Nevertheless, the function F is not easily computable (since the templates p are general). Hence, we solve instead the following fixed point equation in F P, R n:

inf{v ∈ F P, R n | FR(v) ≤ v} .	(11)
We next describe and compare two ways of computing (or approximating) the small- est fixed point of the relaxed semantics equation: Kleene iteration in Section 4.2, and policy iteration in Section 4.3.

Kleene iteration
We denote by ⊥ the smallest element of F P, R n i.e. for all i = 1, ··· ,n and for all

p ∈ P, ⊥i (p)= −∞. The Kleene iteration sequence in F P, R  is thus as follows:
n


v0 =⊥, for k ≥ 0, vk+1 = FR(vk) .
Now using continuity result of Proposition 3.5, we get the following theorem:
Theorem 4.1 If for all i ∈ A∪I, for all p ∈ P, there exists a nonempty compact set

Ki,p such that FR(·) (p)= inf(λ,μ)∈K
to the smallest ﬁxed point of FR.

i,p
F λ,μ(·)(p); then Kleene iteration converges

Kleene iteration has the inconvenience that the values vk which are obtained at a given iteration k (before convergence) do not provide a safe invariant. We shall see that policy iteration does not have this inconvenient: even if it is stopped at an intermediate step, it does provide a safe invariant. Moreover, the convergence of the Kleene iteration can be very slow, so it needs to be coupled with an acceleration technique which provides over-approximations. In [1,2], after a given number of iterations, and during a few iterations, we round bounds outwards with a decreasing precision (akin to the widening used in [9]).
Policy Iteration
We present now policy iteration algorithm. As usual, we present first the policies notion and then describe completely policy iteration at Algorithm 1.
Policy deﬁnition
A policy iteration algorithm can be used to solve a fixed point equation for a mono- tone function written as an infimum of a family of simpler monotone functions, obtained by selecting policies, see [6,8] for more background. The idea is to solve a sequence of fixed point problems involving simpler functions. In the present setting, we look for a representation of the relaxed function
FR = inf F π	(12)
π∈Π
where the infimum is taken over a set Π whose elements π are called policies, and where each function F π is required to be monotone. The correctness of the algorithm relies on a selection property, meaning in the present setting that for each argument (i, v, p) of the function FR, there must exist a policy π such that FR(v) (p) = 
i
π
Fi (v) (p). The idea of the algorithm is to start from a policy π, compute the
smallest fixed point v of F π, evaluate FR at point v, and, if v /= FR(v), determine the new policy using the selection property (see Proposition 3.4) at point v.
Let us now identify the policies. Lemma 3.3 shows that for each template p, each coordinate FR corresponding to an assignment i ∈ A ∪ I can be written as the infimum of a family of affine functions v '→ F λ,μ(v), the infimum being taken over

the set of a couple of Lagrange multipliers (λ, μ). Choosing a policy π consists in selecting, for each i ∈ A ∪ I and p ∈ P, a Lagrange multiplier a pair of Lagrange multipliers λ, μ (for i ∈ A a Lagrange multiplier has to be chosen, the added test is trivial ans thus μ has to be chosen equal to 0). We denote by πi(p) the value of (λ, μ) chosen by the policy π. Then, the map F π in (12) is obtained by replacing FR by the affine functions appearing in Lemma 3.3, for i ∈ A ∪ I. For coordinates

corresponding to loops, i.e., i ∈ U, we take F π
= FR
(the choice of policy is

trivial) since the infimum operation does not appear in the expression of FR (see
Equation (8)).
Proposition 3.4 shows that the selection property is valid under a Slater con- straint qualification condition. We thus introduce FS(P, R)n, the set of elements of F P, R which satisfy the Slater condition when the component Fi of F corresponds to an assignment or a test. More concretely: v ∈ FS(P, R)n, if, for all i ∈ A ∪ I the set: {x ∈ Rd | q(x) < vl′ (q), ∀ q ∈ P}∩ {x ∈ Rd | rl(x) < 0} is non-empty.
Note we can do restrictions on policies when degenerate cases appear. At some control point i and for corresponding label j, if there exists p ∈ P such that vj(p)= 
−∞ then we can choose any vector of non-negative λ such that λ(p) /= 0. Note that
in this case, FR(v) ≡ −∞ and the smallest fixed point of FR for the coordinate i must check vi ≡ −∞. At some control point i and for corresponding label j, if there exists p ∈ P such that vj(p)= +∞ then we can choose any vector of non-negative λ such that λ(p) = 0 for all p ∈ P such that vj(p)= +∞. These two restrictions let us work with finite values when we have to compute optimal policies.
Algorithm

Algorithm 1 Policy iteration in finite templates domain
Choose π0 ∈ Π, k = 0.
Compute V πk = {V πk (q)}	and define the associated function F πk by choosing
λ and μ according to policy πk using Equation (10).
Compute the smallest fixed point vk in F P, R n of F πk .

If wk ∈ FS(P, R)n continue otherwise return wk.
Evaluate FR(wk), if FR(wk)= wk return wk otherwise take πk+1 s.t. FR(wk)= 
F πk+1 (wk). Increment k and go to 2.

In [1,2], we have proved that policy iteration on quadratic templates converges to a postfixpoint of our relaxed functional (Theorem 4.2 here). Actually, the re- sult holds independently of the restriction on quadratic templates. Combined with Theorem 3.1, this postfixpoint is also a postfixpoint of abstract semantics.
Theorem 4.2 The following assertions hold: (1) FR(vl) /= vl =⇒ FR(vl) < vl;
(2) the sequence vl computed by Algorithm 1 is strictly decreasing; (3) the limit v∞
of the sequence vl is a postﬁxpoint: FR(v∞) ≤ v∞.
Theorem 4.2 ensures that Algorithm1 produces a sequence of safe over-approximations

of the numerical invariant we want. Now we complete Theorem 4.2 by showing that actually, Algorithm 1 converges to a fixed point.
Theorem 4.3 (Convergence of Algorithm 1) If Slater condition is always sat- isﬁed then policy iteration converges to a ﬁxed point.
Proof. Third point of Theorem 4.2 is FR(v∞) ≤ v∞. Now we have to prove that v∞ ≤ FR(v∞). At third step of Algorithm 1, we compute the smallest fixed point of F πk . Since we have for all k ≥ 0, vk+1 ≤ vk and by the fact that F πk+1 is order-preserving we have: vk+1 = F πk+1 (vk+1) ≤ F πk+1 (vk) = FR(vk). Now by taking the infimum on k, we get v∞ = infk vk+1 = infk vk ≤ infk FR(vk) and finally using the commutation of decreasing inf thanks to Proposition 3.5 then infk FR(vk)= FR(infk vk)= FR(v∞) and we conclude that v∞ ≤ FR(v∞).     2
For the third step of Algorithm 1, since P is finite and using Lemma 3.3, F πl is monotone and affine F (P, R ∪ {+∞})n, we compute the smallest fixed point of F πl by solving the following linear program see [8, Section 4]:
min Σ Σ vi(q) s.t. F πl (v) (q) ≤ v (q), ∀k = 1, ··· , n, ∀q ∈ P	(13)
k	k
i=1 q∈P
Templates design and initial policies
The choice of the initial policies is a crucial point for the quality of the fixed point found by policy iteration. For example, if we know that the values of the variables are bounded an unbounded first invariant can be a fixed point and policy iteration stops. The choice depends on the template design algorithm.
The set of reachable values taken by the variables of the analysed program is bounded (in the sense of a Rd-norm) if there exists a function P such that P is level bounded (∀ α ∈ R, {x ∈ Rd | P (x) ≤ α} is bounded) and a sub-level of P is an invariant (i.e. contains all possible values taken by the variables of the analysed program). Nevertheless, finding both invariant function (relation) and invariant level seems to be difficult and in a first time, in template design step, we only focus on invariant relations. It means that we are looking for a function such that all sub-levels are invariant by program updates (assignments and guarded assignments). We can formulate the problem as follows.
Problem 5.1 Find a function P : Rd → R such that:
For all α ∈ R there exists β ∈ R+ such that P (x) ≤ α =⇒ x  2 ≤ β;    (14a)
For all i ∈ A ∪ I, for all vi ∈ R, ri(x) ≤ 0 ∧ P (x) ≤ vi =⇒ P (Ti(x)) ≤ vi. (14b)
We can formulate Problem 5.1 as a constrained maximisation problem and then using Lagrange duality in order to get a more restrictive but easier to solve problem. A solution can be given when affine or polynomial arithmetic are considered. We in- troduce Problem 5.2 which only deals with inequalities. The formulation in terms of

positivity implies that we could consider relaxations such as sum-of-squares [12,10] to compute polynomial invariants relations. The main issue to this generalisation is the selection of the right degree of the polynomial solution.
Problem 5.2 Find P : Rd → R, {γi,i ∈ I}, γi ∈ Rm) such that:
∀ x ∈ Rd, P (x) − x  2 ≥ 0;	(15a)
∀ i ∈ A ∪ I, ∀ x ∈ Rd, P (x) − P (Ti(x)) + γ ri(x) ≥ 0;	(15b)
The next proposition states that a solution of Problem 5.2 gives a solution to Problem 5.1.
Proposition 5.3 (Problem 5.2 solves Problem 5.1) We have:
If P satisﬁes (15a) then P satisﬁes (14a);
if (P, {γi}i∈A∪I) satisﬁes (15b) then (P, {γi}i∈A∪I) satisﬁes (14b).
if (P, {γi}i∈A∪I) is a solution to Problem 5.2 then (P, {γi}i∈A∪I) is a solution to Problem 5.1.
Note that Proposition 5.3 and Inequations (15b) can be used to compute un- bounded algebraic invariant relations between variables. Then these relations can be used as templates and finite bounds on them (to compute the ”diameter” of the numerical invariant) can be found by using policy iteration. If we are interested in proving that set of reachable values are bounded and we must consider the whole set of inequalities included Inequality (15a).
Now, we present the second main result of the paper. Let (P, {γi}i∈A∪I) be a solution of Problem 5.2. Using a set of templates P = {P, xi '→ x2}. Then policy iteration can be easily initialised (independently of Kleene iteration and widening) for one simple loop program i.e. one loop with one update inside.
Theorem 5.4 (Policy iteration initialisation) Let us consider the class of pro- grams and the associated relaxed semantics of Figure 1.















Fig. 1. A class of one-loop programs at the top and its associated relaxed semantics functional at the bottom
The C is the nonempty set where the variables are assumed to be in and C†

denotes the abstraction of C. The map T : Rd → Rd represents the update of the variables. Let (P, γ) a solution to Problem 5.2 and let P = {x '→ x2,i = 1,..., d}∪ {P}. For all pj ∈ P, Policy iteration can be initialised with the policy:

π0(pj)= ⎛p '→ ⎧⎨ 0 if p /= P , γ⎞


(16)

⎝	⎩ 1 if p = P	⎠

Moreover, the following polyhedron: {v ∈ F (P, R)3 | F π0 (v) ≤ v} is nonempty and bounded from below and lfp(F π0 ) has ﬁnite coordinates.
Proof. Consider the initial policy π0 such that π3 is given by Equation (16), we have: F π0 (v) = C†, F π0 (v) = sup{v ,v },	F π0 (v) (p) = v (P )+ V π0 (p) with

V π0 (p) = sup
x∈Rd
p(T (x)) − P (x) − γ r3(x). From Inequality (15a), we have for

all pj ∈ P, pj /= P that pj(x) ≤  x 2 ≤ P (x) for all x ∈ Rd and then pj(T (x)) ≤
T (x) 2 ≤ P (T (x)) for all x ∈ Rd also holds. From Inequality (15b), we have
P (T (x)) ≤ P (x)+ γ r (x) for all x ∈ Rd. Finally, V π0 (pj) = sup	pj(T (x)) −
3	3	x∈Rd
P (x) − γ r3(x) ≤ 0 for all pj ∈ P.  We conclude that the polyhedron: K0 =
{v ∈ F (P, R)3 | F π0 (v) ≤ v} or more precisely K0 = {v ∈ F (P, R)3 | C† ≤
v , v ≤ v , v ≤ v , v (P )+ V π0 (pj) ≤ v (pj), ∀ pj ∈ P} is nonempty and bounded
1	1	2	3	2	2	3	3

from below then the linear program: Min{Σ3
Σp∈P
vi(p) | v ∈ K0} has a finite

solution.	2

Examples
With a Lyapunov function
Recall that, for a linear discrete-time dynamical system x := Ax, a quadratic func- tion x '→ x Lx, where L is a d × d symmetric matrix, is called Lyapunov function iff: L is positive definite i.e. x Lx > 0 for all nonzero x ∈ Rd and L − A LA is positive definite. Note that L is positive definite is equivalent up to a multiplicative constant to L − Id is positive semi-definite (x (L − Id)x ≥ 0 for all x ∈ Rd).
Suppose there exists only one (convergent) linear update in the analysed program without guards (test is of the form −1 ≤ 0), then (x '→ x Lx, 0) is a solution of Problem 5.2 for every Lyapunov function x '→ x Lx. An algorithm to compute automatically floating points certified Lyapunov functions for while infinite loops and one (guarded) affine update has been developed in [13].
As to illustrate the interest of the approach, let us consider a harmonic oscillator: x¨ + cx˙ + x = 0. The program of this example which is given at Figure 2 implements an Euler explicit scheme with a small step h = 0.01 and c = 1, that is, which
simulates the linear system (x, v) = T (x, v) with T = ⎛ 1	h	⎞ .
⎝−h 1 − h⎠
By semi-definite programming, we can compute a Lyapunov function for the lin-



Fig. 2. Euler integration scheme of a harmonic oscillator

ear system (x, v) :'→ (x, v)L(x, v) defined as: L = ⎛2 1⎞
⎝1 3⎠

. Recall that Lyapunov

functions for linear updates are solution of Problem 5.2. We also use the quadratic functions x : (x, v) '→ x2 and v : (x, v) '→ v2 which corresponds to interval con- straints. We introduce the set of templates P = {x, v, L}. The set of templates P is thus good set of templates in the sense of Section 5 and we can use Theorem 5.4 to initialise Algorithm 1 and so we choose:
π0(x)= (0, 0, 1), π0(v)= (0, 0, 1), π0(L)= (0, 0, 1) .
3	3	3
In the case of quadratic templates P, it is easy to evaluate functions V π. By basic
π0	π0	π0
quadratic programming, we find: V3 3 (x)= V3 3 (v)= V3 3 (L) = 0. To compute the
least fixed point of F π0 , we solve the linear program (see 13) and we obtain the following set at control point 2: {x2 ≤ 7, v2 ≤ 7, 2x2 + 3v2 + 2xv ≤ 7} which does not provide a fixed point of FR. After 5 iterations, policy iteration stops with a fixed point which provides the following numerical invariant at loop:
{x2 ≤ 3.5000, v2 ≤ 2.3333, 2x2 + 3v2 + 2xv ≤ 7} .
Unbounded case
We consider a program which contains a loop while and non trivial test. This program is described at Figure 3.


Fig. 3. A simple program with a loop and a test
i(i + 1)

We want to prove that j ≤
. We use policy iteration to prove it. The
2

numerical invariant is unbounded and thus for using Proposition 5.3, we can only

check whether Inequality (15b) holds to initialise our policy iteration. We are looking for non-negative μ such that:
− (i + 1)(i + 2) + j + i + i(i + 1) − j + μ(42 − i) ≤ 0 ∀ (i, j) ∈ R2
2	2
A simple calculus permits to show that the inequality holds for μ = 0. So we use the singleton set of templates P = {(i, j) '→ −i(i + 1) + j}.  Then we can
2
take as initial policy π0 = (1, 0) and we get V π0 = 0 and we have to solve the
linear program: Min{v1 + v2 + v3 | v1 ≥ 0, v2 ≥ v1, v2 ≥ v3, v3 ≥ v2}. We get v1 = v2 = v3 = 0 which is a fixed point of FR and provides the wanted numerical invariants.
Conclusion and Future Works
We define policy iteration algorithm in a general setting using a finite domain of templates and prove that the algorithm converges to a fixed point of the relaxed semantics. This latter result allows us to use characterisation tools [3] to check whether the solution found is the smallest one. We also define the problem of com- puting good templates and prove that initialisation of policy iteration is provided from this choice of invariant relations. Future works should include an automatic method to compute the invariant algebraic relations and automatic way to initialise policy iteration from the relations generated.

References
A. Adj´e, S. Gaubert, and E. Goubault. Coupling policy iteration with semi-definite relaxation to compute accurate numerical invariants in static analysis. In A. D. Gordon, editor, ESOP, volume 6012 of Lecture Notes in Computer Science, pages 23–42. Springer, 2010.
A. Adj´e, S. Gaubert, and E. Goubault. Coupling policy iteration with semi-definite relaxation to compute accurate numerical invariants in static analysis. Logical Methods in Computer Science, 8(1), 2011.
A. Adj´e, S. Gaubert, and E. Goubault. Computing the smallest fixed point of order-preserving nonexpansive mappings arising in positive stochastic games and static analysis of programs. Journal of Mathematical Analysis and Applications, 410(1):227 – 240, 2014.
A. Auslender and M. Teboulle. Asymptotic Cones and Functions in Optimization and Variational Inequalities. Springer, 2003.
P. Cousot and R. Cousot. Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints. In Conference Record of the Fourth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 238–252, Los Angeles, California, 1977. ACM Press, New York, NY.
A. Costan, S. Gaubert, E. Goubault, M. Martel, and S. Putot. A policy iteration algorithm for computing fixed points in static analysis of programs. In Proceedings of the 17th International Conference on Computer Aided Verification (CAV’05), volume 3576 of LNCS, pages 462–475. Springer, 2005.
B. A. Davey and H. A. Priestley. Introduction to lattices and order. Cambridge University Press, New York, second edition, 2002.
S. Gaubert, E. Goubault, A. Taly, and S. Zennou. Static analysis by policy iteration on relational domains. In Proceedings of the Sixteenth European Symposium Of Programming (ESOP’07), volume 4421 of LNCS, pages 237–252. Springer, 2007.


E. Goubault, S. Putot, P. Baufreton, and J. Gassino. Static analysis of the accuracy in control systems: Principles and experiments. In S. Leue and P. Merino, editors, Formal Methods for Industrial Critical Systems, volume 4916 of Lecture Notes in Computer Science, pages 3–20. Springer Berlin Heidelberg, 2008.
J.B. Lasserre. Moments, positive polynomials and their applications. Imperial College Press optimization series. Imperial College Press, 2010.
J. J. Moreau. Inf-convultion, sous-additiv´e, convexit´e des fonctions num´eriques. Journal de Math´ematiques Pures et Appliqu´ees, 49:109–154, 1970.
P. Parillo. Semidefinite programming relaxations for semialgebraic problems. Math. Prog., 96(2, series B):293–320, 2003.
P. Roux, R. Jobredeaux, P-L. Garoche, and E. Feron. A generic ellipsoid abstract domain for linear time invariant systems. In T. Dang and I. M. Mitchell, editors, HSCC, pages 105–114. ACM, 2012.
R.T. Rockafellar. Convex Analysis. Princeston University Press, 1996.
A. M. Rubinov. Abstract Convexity and Global optimization. Kluwer Academic Publishers, 2000.
I. Singer. Abstract Convex Analysis. Wiley-Interscience Publication, 1997.
S. Sankaranarayanan, H. B. Sipma, and Z. Manna. Scalable analysis of linear systems using mathematical programming. In The Sixth International Conference on Verification, Model Checking and Abstract Interpretation (VMCAI’05), volume 3385 of LNCS, pages 25–41, January 2005. http:
//www.metapress.com/link.asp?id=X2G04CAME7MDKD72.
