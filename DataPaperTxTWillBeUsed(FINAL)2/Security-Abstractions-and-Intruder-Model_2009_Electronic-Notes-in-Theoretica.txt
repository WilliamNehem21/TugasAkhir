

Electronic Notes in Theoretical Computer Science 242 (2009) 99–112
www.elsevier.com/locate/entcs

Security Abstractions and Intruder Models (Extended Abstract)
Michele Bugliesi 1 and Riccardo Focardi 2
Dipartimento di Informatica Universita` Ca’ Foscari di Venezia

Abstract
Process algebraic specifications of distributed systems are increasingly being targeted at identifying security primitives well-suited as high-level programming abstractions, and at the same time adequate for security analysis and verification. Drawing on our earlier work along these lines [5], we investigate the expressive power of a core set of security and network abstractions that provide high-level primitives for the specifi- cations of the honest principals in a network as well as the lower-level adversarial primitives that must be assumed available to an attacker.
We analyze various bisimulation equivalences for security, arising from endowing the intruder with (i) differ-
ent adversarial capabilities and (ii) increasingly powerful control on the interaction among the distributed principals of a network. By comparing the relative strength of the bimimulation equivalences we obtain a direct measure of the discriminating power of the intruders, hence of the expressiveness of the corresponding models.
Keywords: Process algebras, bisimulation for security, intruder model


Introduction
The challenges in achieving security in distributed systems often create a tension between two conflicting requirements. On the one side, security concerns call for detailed formal specifications of the safeguards built against the threats to which the systems are exposed. On the other side, programming the systems needs techniques and reasoning methods that abstract away from such details to focus on the expected functional properties.
In the literature on process calculi, this tension has generated a range of ap- proaches, with two extremes. At one end, we find specifications that draw on low- level cryptographic primitives as in the spi calculus [3] or in the applied-pi calculus [1]. At the other end lie specifications based on the pi calculus [11], which assume

1 Email: michele@dsi.unive.it
2 Email: focardi@dsi.unive.it

1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.06.015

very abstract, and hard-to-implement, mechanisms to secure communications by hiding them on private channels. A more recent line of research [2,9,4,6,7] follows a different approach, aimed at identifying security primitives well-suited as high-level programming abstractions, and at the same time adequate for security analysis and verification in adversarial setting.
Drawing on our initial ideas in [5], in the present paper we further assess the adequacy of our approach by investigating the expressive power of our security and network abstractions. In particular, we analyze various bisimulation equivalences for security, associated with a variety of intruder models. The models arise from en- dowing the intruders with (i) different adversarial capabilities and (ii) increasingly powerful control on the interaction among the distributed principals of a network. The bisimulation equivalences, in turn, provide a direct measure of the discrim- inating power of the intruders, hence of the expressiveness of the corresponding models.
The starting point is the asynchronous pi-calculus with security abstractions we defined in [5]. In this model, the intruder has the capability to interfere in all network interactions: it can forge its own traffic, intercept all messages and forward them back to the network, possibly replicating them. However, similarly to what happens in the Dolev-Yao model for cryptographic protocols, it cannot learn any secret message and cannot forge any authenticated transmission. For this intruder, we give a sound characterization of strong barbed equivalence in terms of strong asynchronous bisimulation. Also, we show that asynchronous and synchronous bisimilarity coincide.
We then extend our network abstractions with a new primitive that enables the intruder to silently eavesdrop on network traffic (without necessarily intercepting it). We show that the new capability adds no discriminating power to the intruder, in that it does not affect the security equivalences (either synchronous or asyn- chronous). On the other hand, eavesdropping turns out to be strictly less powerful than intercepting.
As a further, and final step, we look at the notion of intruder adopted in [4], that corresponds to what is sometimes referred to as the man-in-the-middle intruder. In this new model two principals may never engage in a synchronization directly as it is customary for the semantics of traditional process calculi (and as we assume in the initial model). Instead, all exchanges take place with the intruder’s intervention. We show, somewhat surprisingly, that this additional control on the interactions on the network does not change the notion of equivalence, hence does not add discriminating power to the intruder.
Plan. Sections 2 and 3 review the calculus from [5]. Sections 4 and 5 discuss the results for the Dolev-Yao intruder of [5]. Section 6 contrasts this model with the man-in-the-middle intruder of [4]. Section 7 concludes the presentation.

Security and Network Abstractions
We start with a brief review of the calculus of security and network abstractions from [5]. We presuppose two countable sets N and V of names and variables, respectively, and let a − q range over names, , w, x, y,z over variables and t, u, v over N ∪ V. Names enable communication, but serve also as identities: for instance, b⟨a : n˜⟩ indicates an output to b originating from a, while b(a : x˜) denotes an input performed by b of a message from a. Tuples are indicated by a tilde, as in n˜, x˜, v˜.

High-Level Principals
The syntax of the high-level calculus is below.

H, K ::= u⟨a : v˜⟩◦	(Output)
|  a(v : y˜)◦.H	(Input)
|  0	(Null)
|  H|K	(Parallel)
|  if u = v then H else K  (Conditional)
|  A⟨u˜⟩	(Definition)
|  (νa)H	(Restriction)
We use v as short for the name or variable v, or the distinguished name − associated with an anonymous identity. The null, parallel composition and conditional forms are just as in the pi-calculus. A⟨u˜⟩ is the process defined by a (possibly recursive)

definition
def
A(x˜) = H
(A may only occur guarded in H). The restriction (νa)H has

the familiar pi-calculus syntax but weaker scoping rules (see below). As to commu- nication, we have four output forms, depending whether a is a or − and whether
is • or the empty character, as explained next: u⟨− : v˜⟩ denotes a plain output, a communication primitive that conveys no security guarantee; u⟨a : v˜⟩ denotes a public, but authentic output, which certifies the originator of the message, and en- sures that the message cannot be replayed; u⟨− : v˜⟩• denotes a secret transmission, providing guarantees that only the intended receiver will have access to the message payload; finally, u⟨a : v˜⟩• denotes a secure transmission, combining the guarantees of the authentic and secret modes. In sum, the secret outputs protect from message disclosure, while authentic outputs protect against replication and forging. On the other hand, an opponent may intercept all outputs, and then selectively forward them back to the network.

The input forms have dual semantics: a(v :
y˜)◦.H denotes an input, which

consumes a message sent on a from v or −, binding y˜ to the tuple of names that form the payload. The input prefix is thus a binder for the variable y˜, whose scope is H: instead, v must be instantiated at the time the input prefix is ready to fire. As for output, ◦ signals the secrecy mode and v the authenticity one. Inputs and

outputs must agree on the transmission mode to synchronize.
Like in the local pi-calculus [10], we make a clear distinction between the input and output capabilities for communication, and we disallow the transmission of the former. Note, to this regard, that input prefixes are built around names (not vari- ables) in the channel position. Similarly, we require a name in the sender position of authentic messages. Taken together, these constraints guarantees that a process H never gets to dynamically impersonate a new identity, in the following sense:
Definition 2.1 [Impersonation] A process H impersonates an identity a iff H uses a as the subject of a(u : y˜)◦.H, or as the source of an authentic (public or secret) output, as in u⟨a : v˜⟩◦.

Networks and Intruders
Networks provide the low-level counterpart of the high-level calculus we just dis- cussed. In addition, they make it possible to express the capabilities of an attacker. The syntax is given below: within networks, names are partitioned into two sets Nt and Nu of trusted and untrusted identities, respectively. By convention, we assume that α-renaming respects this partition.


M, N, O ::= u⟨a : v˜ 
|  a(u : y˜ 
t˜⟩◦	(Low Output)
z˜)◦.M	(Low Input)

|  0 | M |N | A⟨u˜⟩ | (νa)N | if u = v then M else N

|  †z(x : y˜ 
w˜)◦.M	(Intercept)

|  !i	(Forward/Replay)
The first two productions introduce the network-level primitives for input and out- put and are subject to the same restrictions about the use of names as in the high-level syntax. The novelty is in the additional components t˜ of the output mes- sages: these represent the network view of the payload, i.e. the view of the payload given to an external observer of the message, and are bound to the variables z˜ in the input prefix upon synchronization. The last two productions define the adversarial

primitives. The intercept prefix †z(x : y˜ 
w˜)◦.M enables an adversary to intercept

all network messages. The prefix is a binder for the name i and all its component

variables, with scope M : intercepting the output b⟨a : m˜ 
n˜⟩◦ creates a copy of the

message indexed by the fresh name i and binds z to the target b, x to a and w˜ to n˜. As to y˜, the binding depends on the secrecy mode of the message and on the trust status of the identity b. In particular, if the message is secret and b ∈ Nt then y˜ gets bound to n˜, otherwise y˜ is bound to m˜ . Notice (i) that intercepting a secret message directed to a trusted principal does not break the secrecy of the payload, and (ii) that a message can be intercepted even if it is directed to a restricted iden-
tity, as in (νb)b⟨a : m˜	n˜⟩◦. The cached copies of the intercepted messages may be
manipulated by way of the replay/forward form !i that uses the index i to forward

a copy back to the network, or to produce a replica (in case the original messages was not authenticated).

Definition 2.2 [Well-formed Networks] We say that plain output u⟨− : v˜ 
t˜⟩

is well-formed iff v˜ = t˜; a secret/secure u⟨a : v˜ 
t˜⟩• or authentic u⟨a : v˜ 
t˜⟩ output

is well-formed iff |v˜| = |t˜|. A network N is well-formed iff it is closed (has no free
variable) and all of its outputs are well-formed.
The network view of a message depends on the transmission mode: it coincides with the payload in plain outputs, while it is a fresh tuple of names in each authentic and/or secret output. The correspondence between message formats is established by the following translation of high-level principals H into their network level coun- terparts [H]. We only give the clauses for the communication forms (the remaining clauses are defined homomorphically). As discussed in [5], in a cryptographic im- plementation, the chosen format may be realized by means of a time-dependent signature, in an authentic message, and by a randomized encryption in a secret output.


[u⟨− : v˜⟩]	  u⟨− : v˜ 
v˜⟩

[u⟨a : v˜⟩]	 (νc˜)u⟨a : v˜  [u⟨a : v˜⟩•]	 (νc˜)u⟨a : v˜ 
c˜⟩	(|v˜| = |c˜|)
c˜⟩•	(|v˜| = |c˜|)

[b(u : x˜)◦.H]  b(u : x˜	y˜)◦.[H]	(|x˜| = |y˜|∧ y˜ ∩ fv (H)= ∅)

The partition on the set of identities makes it possible to identify, within a network, the trusted components from the intruder.
Definition 2.3 [Trusted processes vs Intruders] A network process N is trusted iff N ≡ [H], with H high-level principal, it only impersonates identities in the set Nt and only creates fresh names in the same set. A network process N is an opponent/intruder iff it only impersonates identities in the set Nu and only creates fresh names in the same set.
Throughout, we reserve the letters P and Q to range over the class of trusted processes, and their run-time derivatives.

Barbed Equivalence
The dynamics of the calculus is given in Table 1 in terms of reduction and structural congruence. To formalize the dynamics of networks, we need a special form to represent the copies of the messages stored upon interception. We introduce the new form below as part of what we call run-time network configurations:


M, N, O ::= ... as in Section 2.. . | b⟨a : m˜ 
c˜⟩◦


Structural congruence
(Struct Par Comm) M |N ≡ N |M
(Struct Par Assoc) (N |N ')|N '' ≡ N |(N '|N '') (Struct Par Zero)	N |0 ≡ N
(Struct Res Zero)	(νa)0 ≡ 0
(Struct Res Comm) (νa)(νb)N ≡ (νb)(νa)N
(Struct Res Par)	M |(νa)N ≡ (νa)(M |N )	when a /∈ fn (M )

(Struct Rec)	A⟨w˜⟩ ≡ N {w˜/x˜}
(Struct If True)	if a = a then M else N ≡ M
def
if A(x˜) = N and
|w˜| = |x˜|

(Struct If False)	if a = b then M else N ≡ N	when a /= b
(Struct Equiv)	M ≡ M, M ≡ N implies N ≡ M,
N ≡ N ' and N ' ≡ N '' imply N ≡ N ''
(Struct Cong)	N ≡ N ' implies (νn)N ≡ (νn)N ' and N | N '' ≡ N ' | N ''

Reduction
In the (Intercept) rule i ∈/ {b, a, m˜ , c˜}, σ is the substitution {b/z, a/x, p˜/y˜, c˜/w˜}, and the p˜ are as follows: if ◦ = • and b ∈ Nt then p˜ = c˜ else p˜ = m˜ .


(Struct)
M ≡ M ' M ' −→ N ' N ' ≡ N M −→ N
(Res)
N −→ N '

(νa)N −→ (νa)N '
(Par)
M −→ M '

M |N −→ M '|N

(Intercept) b⟨a : m˜ 

(Comm)	b⟨a : m˜ 
c˜⟩◦ | †z(x : y˜ 
c˜⟩◦ | b(a : y˜ 
w˜)i.N −→ (νi)(b⟨a : m˜ 
z˜)◦.N −→ N {m˜ /y˜, c˜/z˜}
c˜⟩◦
| Nσ)


(Forward)	b⟨a : m˜ 

(Replay)	b⟨− : m˜ 
c˜⟩◦ c˜⟩◦


| !i −→ b⟨a : m˜ 

| !i −→ b⟨− : m˜ 
c˜⟩◦ c˜⟩◦


| b⟨− : m˜ 

c˜⟩◦


Table 1 Reduction Semantics
The index i attached to the cached copy is associated univocally with the intercept that created the copy, as shown in the (Intercept) rule. Notice, in the same rule, that the bindings created depend on the structure and, more specifically, on the secrecy of the intercepted message, as explained earlier on. As for the remaining reductions, (Comm) is the usual synchronization rule, while (Forward) and (Reply) formalize the semantics of the adversarial form !i. Notice in particular that a non- authentic message is replicated, while an authentic one is not (the cached copy is erased).
The semantics of the calculus is completed by a notion of contextual equality based on reduction barbed congruence [8]. We first define the observation predicate, as usual in terms of barbs.

Definition 3.1 [Barb] We write N ↓b whenever N ≡ (νn˜)(b⟨... ⟩◦|N ') and b /∈ n˜
Definition 3.2 [Intruder Equivalence] A symmetric relation R on (run-time) networks is (i) barb preserving if M RN and M ↓ b imply N ↓ b; (ii) reduction closed if M RN and M −→ M ' imply N −→ N ' with M 'RN '; (iii) contextual if M RN

implies M | ORN | O for all (closed) intruder O and (νn˜)M R(νn˜)N for all names n˜
∈ Nu. Intruder equivalence I is the largest equivalence relation that is reduction closed, barb-preserving and contextual.
Notice that we define observation in terms of strong bisimulation: this is a conse- quence of the fact that all interactions occur on the network. Also note that we restrict to adversarial contexts, as our intention is to find a reasoning method specif- ically targeted at the analysis of security-centric properties. Accordingly, we define two processes equivalent if they cannot be distinguished by any opponent/intruder that observes them and/or actively interacts with them, reading, intercepting, for- warding and replaying the messages exchanged, or forging new ones.

Labelled transitions and bisimilarity
We give an alternative formulation of the semantics of networks, based on la- belled transitions. The labelled transitions are organized in two sets. A first set, in Table 2, collects the transitions that correspond to the reduction semantics of Section 3. In most cases the transitions are either standard, or constitute the direct counterpart of the corresponding reductions in Table 1. The two (Output Inter- cepted) transitions deserve more attention. First notice that, when the receiver is trusted, the label exhibits different information depending on the secrecy mode of the output. Secondly, observe that the transitions leave in their residual a cached copy of the message emitted: this reflects the effect of an interaction with a sur- rounding context that tests the presence of an output by intercepting it. A further remark is in order on the difference between the two rules that govern scope extru- sion. The difference is best understood if we take the view that a channel name comprises the two identities of the end-points it connects: the source and the des- tination. Under this interpretation the (Open) rule states that the channel name is not extruded, as in the pi-calculus, while the (Open Intercepted) opens the scope in accordance with the reduction semantics by which intercepting a message dis- closes the identity of the receiver (as well of the sender) even though restricted. The following, standard result connects the reductions with the silent actions in the labelled transition semantics.
Lemma 4.1 (Harmony)

α
If M −→ M '
α
and M ≡ N then N −→ N '
and M '
≡ N '

N −→ N ' if and only if N	τ
N '.

A second set of labelled transitions, in Definition 4.2, provide the observable counterpart of the labelled transitions of Table 2. They are obtained by the transi- tions in in Table 2 by filtering away all the transitions that involve the adversarial forms (intercept and forward/reply) as well all the transitions that may not be ob- served by an opponent by virtue of the restriction the opponent suffers on the use of the trusted identities of a network.


Common Transitions
(Input)	(Output)



b(a : y˜ 
b(a:m˜ c˜)◦
w˜)◦.N −−−−−−−−→ N {m˜ /y˜, c˜/w˜}



(Secret Output Intercepted)
b ∈ Nt	i ∈/ {b, a, m˜ , c˜}
(Output Intercepted)
b /∈ Nt or ◦ /= •	i ∈/ {b, a, m˜ , c˜}




(Open)
◦

(Open Intercepted)
◦


(p˜)b(a:m˜ c˜⟩
−−−−−−−−−−→ N	n ∈ {m˜ , c˜}− {b, a, p˜}
(p˜,i)†b(a:m˜ c˜⟩i

N −−−−−−−−−−−−→ N '  n ∈ {b, a, m˜ , c˜}− {p˜, i}





(Replay/Forward)
(Intercept)


	

(i⟩
!i −−→ 0
†z(x : y˜ 
w˜)◦.N
†b(a:p˜ c˜)◦
−−−−−−−−→
N {b/z, a/x, p˜/y˜, c˜/w˜}



(Restr)
α
N −→ N '
α
(νn)N −→


n /∈ n(α) (νn)N '
(Cond)
(a = b ∧ M α  N ) ∨ (a /= b ∧ M ' α  N )

if a = b then M else M ' α  N

(Par)
α
M	'
(Rec)
α	'


def

α
M | N, N | M −→

M ' | N, N | M '

A⟨w˜
α
⟩ −→ N '



Intruder


(Synch)
(p˜)α
M −−−→ M '





α
N −→ N '




p˜ ∩ fn(N )= ∅

τ
M | N −→
(νp˜)(M ' | N ')

(Co-replay)	(Co-forward)

	



b⟨− : m˜ 
(i)
c˜⟩◦ −−→ b⟨− : m˜ 
c˜⟩◦


| b⟨− : m˜ 
c˜⟩◦


b⟨a : m˜ 
(i)
c˜⟩◦ −−→ b⟨a : m˜ 
c˜⟩◦


Table 2
Labelled Transition Semantics







Definition 4.2 [Observable LTS] We say that a network has an observable tran-

sition, noted N
α
▶−→
N ', if and only if it may be derived by the following rules:


α
−→ N
⎧⎪⎪⎨ b(a : m˜	c˜)	a ∈ Nt ⎫⎪⎪
◦





N	N '
α /∈
(p˜)b⟨a : m˜ 
⎪
c˜⟩◦	b ∈ Nt
⎪



The notions of synchronous and asynchronous bisimulation arise as expected from the observable labelled transitions.
Definition 4.3 [Intruder Bisimularity] Let R be a symmetric relation over net-

works. R is a bisimulation if whenever M RN and M
α
▶−→
M ' with bn(α)∩ fn(N )= 

∅ there exists N ' such that N
α
▶−→
N ' and M 'RN '.

R is an asynchronous bisimulation if whenever M RN and M
α
▶−→
M ' with

bn(α) ∩ fn(N ) = ∅ one has: (i) if α is not an input, then N
α
▶−→
N ' and M 'RN ';

(ii) if α is an input, then N
α
▶−→
N ' and M 'RN ' or N ▶τ
N ' and M 'RN ' |α.

Bisimilarity ∼ is the largest bisimulation, and asynchronous bisimilarity ∼a is the largest asynchronous bisimulation.
By adapting the proof in [5] we can show that ∼a implies I . Hence ∼a is a sound, purely coinductive, proof technique for I . In the next two theorems, we implicitly assume processes to be derivatives of trusted processes.
Theorem 4.4 (Soundness) ∼a ⊆ I
A further, more interesting relationship exists between the asynchronous and syn- chronous versions of bisimilarity. Indeed, the ability to intercept all traffic makes asynchronous bisimilarity just as powerful as as synchronous bisimilarity.

Theorem 4.5 (Asynchronous vs synchronous Bisimilarity)
∼a = ∼

Proof sketch. Clearly ∼ ⊆ ∼a because, by definition, a synchronous bisimulation is also an asynchronous bisimulation. To prove the reverse inclusion, we show that R = {(P, Q) | P ∼a Q} is a bisimulation. The crux of the proof is to show that whenever P ∼a Q, the input actions by P (resp. Q) may always be matched by corresponding input actions by Q (resp. P ). We give the outline, leaving the somewhat elaborate details to the full version of the paper.

Assume P
β
▶−→
P ' and let β be an input action. Then Q may match this move by

a τ transition: however, this transition is not entirely silent, because, to make the
τ step, Q must emit an output, which can be intercepted, hence observed, by the environment. Let then Q' be the process reached by Q via the output (intercepted) transition. Since P ∼a Q, P must have a corresponding transition to a P ' ∼a Q'.

At this stage, we still have P ' ▶β
P '' for some P '', and we can repeat the same

reasoning we just made, now on Q' rather than Q. The reasoning may be repeated only a finite number of times, unless P and Q have infinitely many outputs ready

to fire, which cannot happen, as replication, and recursion, may only occur guarded in our processes. Thus, after a finite number of steps, it must be the case that Q responds to the β transition by P with a corresponding β transition. The proof follows by showing that, indeed, Q may respond to the input action at the very first step, as the input action β commutes with all the intervening outputs involved in the bisimulation game we just illustrated.	 
The proof breaks if we lift the restriction that recursion be guarded: indeed, not only the proof breaks, but the result itself is false. Here is a counter-example. Let
∗R denote the replicated version of R, defined by the unguarded recursive definition
∗R d=ef ∗R | R. Consider
=	∗ a⟨− : m⟩| ∗ a(− : x).a⟨− : x⟩ | b(− : x).b⟨− : x⟩

Q	d=ef
∗ a⟨− : m⟩| ∗ a(− : x).a⟨− : x⟩

Clearly P	/∼ Q, because there is no way for Q to match the input transition available for P on b. On the other hand, the two processes cannot be distinguished
b(−:n)	
in the asynchronous version of -bisimilarity as P ’s move on b, P −−−−→ Q | b⟨− : n⟩,
may be matched by Q via a τ -transition that takes Q back to itself (thanks to the presence of the replicated output).
The result breaks similarly in the presence of a choice operator P1 + P2, with

the usual semantics P + P
α
P ' if P
α
P ' or P
α
P '. The counterexample

1	2 −→
1 −→
2 −→

is given by the following processes, where a(− : x)∗ denotes the guarded recursive process Q d=ef a(− : x).Q.


P '	d=ef
Q'	def
a(− : x)∗ | (a⟨− : x⟩ + b(− : x).b⟨− : x⟩)

=	a(− : x)∗ | a⟨− : x⟩
Clearly P ' /∼ Q', because there is no way for Q' to match the input transition available for P ' on b. On the other hand, the two processes cannot be distinguished
b(−:n)
in the asynchronous version of bisimilarity as P ' −−−−→ a(− : x)∗ | b⟨− : x⟩, may

be matched by Q'  τ
a(− : x)∗.

Eavesdroppers
We continue our analysis on the strength of our security abstractions by extending the set of adversarial forms to include an eavesdrop primitive.


M, N ::= ... (as in Section 2) ... | ?z(x : y˜ 
w˜)◦.M



Like the intercept prefix, ?z(x : y˜ 
w˜)◦.M is a binder for the name i and for all of its

component variables, with scope M . The semantics is given in Table 3: the reduc- tions and labelled transitions follow the exact same rationale as the corresponding


Reduction: as in the intercept rules, σ is the substitution {b/z, a/x, p˜/y˜, c˜/w˜}, and the p˜ are as follows: if ◦ = • and b ∈ Nt then p˜ = c˜ else p˜ = m˜ . Moreover, in the (Eavesdrop) rule, i ∈/ {b, m˜ , c˜}.




(Eavesdrop Auth) b⟨a : m˜  (Eavesdrop)	b⟨− : m˜ 
c˜⟩○ | ?z(x : y˜ 
c˜⟩○ | ?z(x : y˜ 


w˜)○.N −→ b⟨a : m˜ 

w˜)○.N −→ b⟨− : m˜ 
c˜⟩○ | (νi)Nσ 

c˜⟩○ | (νi)(b⟨− : m˜ 

c˜⟩○


| Nσ)

Labelled Transitions:


(Output Eavesdropped)
b /∈ Nt or ◦ /= •	i ∈/ {b, m˜ , c˜}



(Secret Output Eavesdropped)
b ∈ Nt	i ∈/ {b, m˜ , c˜}
(Output Eavesdropped Auth)
b /∈ Nt or ◦ /= •	i ∈/ {b, a, m˜ , c˜}


(Secret Output Eavesdropped Auth)
b ∈ Nt	i ∈/ {b, a, m˜ , c˜}


	


(Open Eavesdropped)

◦
(p˜,i)?b(a:m˜ c˜⟩i

N −−−−−−−−−−−−→ N '  n ∈ {b, a, m˜ , c˜}− {p˜, i}
(Eavesdrop)




?b(a:p˜ c˜)◦

(νn)N −−−−−−−−−−−−−−→ N '
?z(x : y˜ 
w˜)i.N −−−−−−−−→ N {b/z, a/x, p˜/y˜, c˜/w˜}



Table 3 Semantics of Eavesdropping

rules for the intercept primitive, with the differences (i) that eavesdropping does not consume the output, and hence (ii) that it does not create a copy in case the output is authentic.
In the rest of this section we analyze the import of eavesdropping on the dis- criminating power of the intruder. In that direction we let (∼κ)κ⊆{†,?,!} denote the family of bisimilarity relationships associated with the corresponding set of adver- sarial primitives. Similarly, we define the set (∼κ)κ⊆{†,?,!} for the asynchronous setting, and look at the relative strength of (some of) the equivalences in these sets. Our first result shows that eavesdropping does not give any additional discrim-
inatory power.
Theorem 5.1 ∼†! = ∼†?!, and similarly ∼†! = ∼†?!.
a	a
Proof sketch. Clearly, ∼†?! ⊆ ∼†!. For the reverse inclusion, we show that eaves-
a	a
dropping can be encoded in terms of intercept and forward/reply. The same tech- nique applies in the proof for the synchronous relationships.	 
Next, we show that eavesdropping is strictly less powerful than intercepting.
Theorem 5.2 ∼†!	Ç ∼?! and similarly ∼†!	Ç ∼?!.
Proof sketch. Clearly ∼†?! ⊆ ∼?!, which implies	†!	?! by Theorem 5.1 above.
a	a	∼a ⊆ ∼a
The exact same reasoning applies in the synchronous case. That the inclusions
are strict follows by the following counter-example, which applies uniformly to the


Reductions:



(Forward) b⟨a : m˜ 
c˜⟩○

| !i | b(a : y˜ 
z˜).N −→ N {m˜ /y˜, c˜/z˜}



(Replay) b⟨− : m˜ 
c˜⟩○
| !i | b(− : y˜ 


z˜).N −→ b⟨− : m˜ 
c˜⟩○
| N {m˜ /y˜, c˜/z˜}

Labelled Transitions


(Co-replay)


b(—:m˜ c˜)◦
N −−−−−−−−→ N '
(i)∗
(Co-forward)
b(a:m˜ c˜)◦
N −−−−−−−−→ N '

(i)∗

b⟨− : m˜ 
c˜⟩○ | N −−−→ b⟨− : m˜ 
c˜⟩○
| N '
b⟨a : m˜ 
c˜⟩○ | N −−−→ N '



Table 4
Man-in-the-middle reductions and labelled transitions
synchronous and asynchronous cases. Let a ∈ Nt, and take the following two processes:

d=ef
def
a⟨− : m⟩ | a⟨− : m⟩ | ∗ a(− : x).a⟨− : x⟩

=	a⟨− : m⟩ | ∗ a(− : x).a⟨− : x⟩
P and Q are easily distinguished by using the intercept prefix to count the outputs in the two processes. On the other hand, P ∼?! Q as this counting in not possible for an eavesdropper, because (i) eavesdropping does not consume the messages, and
(ii) a is a trusted name, hence the intruder cannot impersonate a to input on a. 

Men in the middle
We continue our analysis by looking at the intruder model adopted in [4], which we adapt to our calculus. In this new model, two principals may never engage in a synchronization directly as in our initial semantics in Section 3. Instead, all exchanges require the mediation of the intruder which intercepts all outputs and then delivers them to the processes in the exact moment they are ready to consume them. As a result, the reduction relation arises from the relation defined in Table 1 by dropping the (Comm) rule and by replacing the (Forward) and (Replay) rules with two rules in Table 4.
A corresponding modification is required on the labelled transition semantics to mimic the form of three-way synchronization induced by the new rules of reduction. In particular, the new labelled transitions arise from those defined in Table 2 by (i) replacing the rules (Co-reply) and (Co-forward) with the two rules in Table 4, and
(ii) by dropping the (Synch) rule in when α and α are input and output actions, respectively (thus effectively disabling direct synchonization between trusted pro- cesses). The observable LTS for the new semantics is derived exactly as we did in
Definition 4.2. We let ∼∗ be the bisimilarity relationship associated with the new
LTS: notice that, having disabled all τ -actions on trusted processes, the relations of asynchronous and synchronous bisimilarity on trusted processes collapse to the same relation ∼∗ .

At a first look, the new equivalence ∼∗
would appear finer than ∼ due to the

tighter control the new intruder can exercise over the interaction between the prin- cipals of a network. As it turns out, however, this additional control does not add any discriminating power.

Theorem 6.1 On trusted processes, ∼∗
= ∼.

Proof sketch. We prove the two inclusions separately, by coinduction. The in-
clusion ∼∗ ⊆ ∼ is subtle, as we need to identify the ‘right’ pairs of run-time pro-
cesses to be included in the candidate relation. In that direction, we define pro-
cesses P and Q cache-consistent iff P ≡ (νp˜)(Pˆ | b⟨a : m˜	c˜⟩◦) if and only if
Q ≡ (νq˜)(Qˆ | b⟨a : m˜ '  c˜⟩◦), with m˜ = m˜ ' whenever ◦ /= • or b /∈ Nt. Now we define
the relation
R = {(P, Q) | P ∼∗ Q and P, Q are cache-consistent}
and show that R is a ∼-bisimulation. This is enough to prove the claim because any two trusted processes are trivially cache-consistent (they have no cached copies). The proof shows that re-emitting a cached message when no process is ready to input it does not given any discriminating power. It derives from the following closure

property for ∼∗
system:
under the co-reply/co-forward transitions
(i)
▶−−→
from the original

Let P and Q be cache-consistent processes.	If P ∼∗
Q and P
(i)
▶−−→
P ' then

(i)
Q	'
' ∗	'

▶−−→ Q
and P
~ Q .

The reverse implication follows by coinduction, using the relation
R = {(P, Q) | P ∼ Q}
The subtlety here is to show that whenever P ∼ Q and P consumes a forward or a replica of a cached message, then the same must happen on Q. Again, this is a consequence of the discriminating power provided by intercept: were Q not to respond as expected, an observer would be able to tell Q from P based on the presence of an output that cannot be observed in P .	 
The hypothesis that P and Q be trusted processes (hence cache-consistent) is crucial for the proof. Indeed, the theorem is false for arbitrary run-time config-
urations. For instance b⟨− :m  m⟩i ∼ 0, as neither process has any transition;
on the other hand, clearly, b⟨− : m  m⟩i /∼ 0 as the process on the left has an
(i)-transition, while 0 clearly has not.

Conclusions
We have investigated a core set of abstractions for distributed communication, and assessed their adequacy for security verification by analyzing their interplay with a

class of different intruder models. Our results show that the abstractions are robust, in that the observational equivalences they yield are preserved under the different observations available with the different adversarial primitives and interaction mod- els which we have considered.
In its present form, the framework is targeted at secrecy and authentication. Future work includes expending it to account for more advanced properties required in modern network applications such as e-commerce protocols and electronic voting.

Acknowledgement
Work partially supported by MIUR Project SOFT: Security-Oriented Formal Tech- niques.

References
Abadi, M. and C. Fournet, Mobile values, new names, and secure communication, in: POPL 2001: The 28th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, London, 2001,
pp. 104–115.
Abadi, M. and C. Fournet, Private authentication, Theor. Comput. Sci. 322 (2004), pp. 427–476.
Abadi, M. and A. D. Gordon, A calculus for cryptographic protocols: The spi calculus., Inf. Comput.
148 (1999), pp. 1–70.
Ad˜ao, P. and C. Fournet, Cryptographically sound implementations for communicating processes, in:
M. Bugliesi, B. Preneel, V. Sassone and I. Wegener, editors, ICALP (2), Lecture Notes in Computer Science 4052 (2006), pp. 83–94.
Bugliesi, M. and R. Focardi, Language based secure communication, in: Proceedings of the 21st IEEE Computer Security Foundations Symposium, CSF 2008, Pittsburgh, Pennsylvania, 23-25 June 2008 (2008), pp. 3–16.
Corin, R., P.-M. Deni´elou, C. Fournet, K. Bhargavan and J. J. Leifer, Secure implementations for typed session abstractions, in: 20th IEEE Computer Security Foundations Symposium, CSF 2007, 6-8 July 2007, Venice, Italy (2007), pp. 170–186.
Fournet, C. and T. Rezk, Cryptographically sound implementations for typed information-flow security, in: Proceedings of the 35th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL 2008, San Francisco, California, USA, January 7-12, 2008 (2008), pp. 323–335.
Honda, K. and N. Yoshida, On reduction-based process semantics, Theor. Comput. Sci. 151 (1995),
pp. 437–486.
Laud, P., Secrecy types for a simulatable cryptographic library, in: V. Atluri, C. Meadows and A. Juels, editors, ACM Conference on Computer and Communications Security (2005), pp. 26–35.
Merro, M. and D. Sangiorgi, On asynchrony in name-passing calculi, Mathematical Structures in Computer Science 14 (2004), pp. 715–767.
Milner, R., J. Parrow and D. Walker, A calculus of mobile processes, Parts I and II, Information and Computation 100 (1992), pp. 1–77.
