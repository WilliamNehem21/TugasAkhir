Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 352 (2020) 129–148
www.elsevier.com/locate/entcs
Monads, Partial Evaluations, and Rewriting
Tobias Fritz1
Perimeter Institute for Theoretical Physics Waterloo, ON, Canada
Paolo Perrone2
Department of Mathematics Massachusetts Institute of Technology Cambridge, MA, U.S.A.

Abstract
Monads can be interpreted as encoding formal expressions, or formal operations in the sense of universal algebra. We give a construction which formalizes the idea of “evaluating an expression partially”: for example, “2+3” can be obtained as a partial evaluation of “2+2+1”. This construction can be given for any monad, and it is linked to the famous bar construction [15, VII.6], of which it gives an operational interpretation: the bar construction is a simplicial set, and its 1-cells are partial evaluations.
We study the properties of partial evaluations for general monads. We prove that whenever the monad is weakly cartesian, partial evaluations can be composed via the usual Kan filler property of simplicial sets, of which we give an interpretation in terms of substitution of terms.
For the case of probability monads, partial evaluations correspond to what probabilists call conditional expectation of random variables, and partial evaluation relation is known as second-order stochastic domi- nance.
In terms of rewritings, partial evaluations give an abstract reduction system which is reflexive, confluent, and transitive whenever the monad is weakly cartesian. This manuscript is part of a work in progress on a general rewriting interpretation of the bar construction.
Keywords: Monads, bar construction, rewriting, higher dimensional rewriting, simplicial sets, stochastic dominance.

Background: monads and formal expressions
An interpretation of the theory of monads, in terms of universal algebra [9], is that a monad is like a consistent choice of spaces of formal expressions in a signature. This interpretation is most accurate for monads on the category of sets, but the categorical constructions work in general.
In more detail, a monad consists of the following data. First of all, we have a functor T : C → C, which consists of the following assignments:

1 Email: tfritz@pitp.ca
2 Email: pperrone@mit.edu

https://doi.org/10.1016/j.entcs.2020.09.007
1571-0661/© 2020 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

To each space X, we assign a new space TX, which we think of as containing formal expressions of elements of X in a certain signature, modulo the equa- tions specified by the theory. For example, the elements of TX may exactly be the formal sums of elements of X.
Given two spaces X and Y and a function f : X → Y , we get a function Tf : TX → TY , which we think of as elementwise substitution. This assignment should preserve identity and composition. In the case of formal sums, given a function f : X → Y , we automatically get a function from formal sums of elements of X to formal sums of elements of Y by just “extending linearly”. For example:
a + b + 2c	'−→	f (a)+ f (b)+ 2f (c).	(1)
In the case of formal sums, any element x can be considered a (trivial) formal sum. For general monads, this is encoded in the unit natural transformation η :
idC ⇒ T . Moreover, formal sums of formal sums can be reduced to just formal sums, such as


can be reduced to
(a + b + c)+ (a + b + d)

2a + 2b + c + d.

This in general is encoded in the monad multiplication transformation μ : TT ⇒ T . The unit and multiplication transformations are then required to satisfy the monad equations


TTTX 
Tμ 
TTX	TX	TX 

μ
μ
TTX 
μ	η
μ
TX	TTX 
Tη 
μ
TX	TTX 

TX 
(2)

for all X in C.
In general, the category C need not be concrete. Therefore, instead of elements, we look at generalized elements: in general, what we can interpret as a “formal expression” should be a morphism S → TX for some object S of C. Let’s have the following convenient definition:
Definition 1.1 Let (T, η, μ) be a monad on a category C, and X be an object. A generalized formal expression on X is a morphism p : S → TX, where S is an object of C.
If T lives on Set, then for S we can take a singleton set 1, recovering the usual formal expressions. The same can be done for many concrete categories. Neverthe- less, we will drop the word “generalized” and just speak of morphisms S → TX for general C as formal expressions.
Often, formal expressions can be evaluated to a result. For example, the ex- pression 3 + 2 can be evaluated to 5. An algebra of a monad is an object in which (generalized) formal expressions can be evaluated to actual (generalized) elements.

So for the formal sum monad on Set, the category of algebras is precisely the cat- egory of commutative monoids, since in commutative monoids formal sums can be evaluated to actual elements in a way which respects usual rewriting rules for working with sums, namely associativity and commutativity.
Formally, an algebra of the monad T consists of an object A together together with an evaluation map e : TA → A, suitably compatible with η and μ in the sense of making the diagrams


TTA	Te 
μ
η
TA	A	TA 
e	e

TA	e	A	A

commute. By (2), every object TX is an algebra with respect to μ : TTX → TX, the free algebra on X.
Definition 1.2 Let (A, e) bea T -algebra. Given a (generalized) formal expression
p : S → T A, we call its result the (generalized) element of A given by e ◦ p : S → A.
Partial evaluations and partial decompositions


Consider the sums and

3+4+5	(3)

7+ 5.	(4)

Not only do they have the same result, but in addition, we can say that the sum (4) can be obtained from (3) by partially evaluating the expression. Just as well, we would like to say that the sum (3) can be obtained from (4) by partially decomposing the terms in the expression.
Let’s try to make this precise. The idea is that there is a formal sum of formal sums, i.e. a formal sum with one level of brackets, such that removing the brackets yields the term on the left, and such that performing the operations in the brackets (and then removing the brackets) yields the term on the right. That is:
(3 + 4) + (5)
remove brackets	evaluate brackets
3+4+5	7 +5 
As we have seen in Section 1, the “formal sums of formal sums” live in TTA. The map which can be seen as “removing the brackets” is the multiplication map μ : TTA → T A, and the map that evaluates the expressions within the brackets is the image of the evaluation map e under the functor T , i.e. Te : TTA → T A. We can then give a general definition of partial evaluations for all monads.

Definition 2.1 Let (T, η, μ) bea monad ona category C, let (A, e) bea T -algebra, and consider the formal expressions p, q : S → T A. A partial evaluation of p into q, or a partial decomposition of q into p is a map k : S → TTA, or “nested formal expression”, which makes the following diagram commute:




TA	μ
S
k
TTA  TA 
Te 

Basic properties
From the definition and the triangle identities we have immediately the following result, which is a sort of consistency check: any expression has two trivial partial evaluations, namely to itself and to its result (viewed as a formal expression).
Proposition 2.2 Let (A, e) be a T -algebra as above, and p : S → T A. Then:
p admits a partial evaluation to itself;
p admits a partial evaluation to η ◦ e ◦ p, which we call its total evaluation.
Proof
Consider (Tη) ◦ p : S → TTA. Then μ ◦ (Tη) ◦ p = p by the right unitality (2) of the monad, and (Te) ◦ (Tη) ◦ p = T (e ◦ η) ◦ p = p by functoriality of T together with the unit condition of the algebra. Therefore, (Tη) ◦ p gives a partial evaluation of p into itself.
Consider η ◦ p : S → TTA. We have a diagram
η
TA  TTA 
e	Te 
η
A  TA
which commutes by naturality of η. Now μ ◦ η ◦ p = p by the left unitality of the monad, and (Te) ◦ η ◦ p = η ◦ e ◦ p by the commutativity of the diagram above. Therefore η ◦ p gives a partial evaluation of p into η ◦ e ◦ p.
□
Example 2.3 Consider the free commutative monoid monad (or multiset or bag monad) on Set, take the algebra (A, e) to be the set of natural numbers N under addition, and let S = 1, the terminal set. Then the formal expressions are sums of natural numbers, considered as lists up to permutation. The expression 3 + 4 + 5 admits a partial evaluation into itself, given by
(3) + (4) + (5)
remove brackets	evaluate brackets
μ	Te 
3+4+5	3 +4+5 

and a partial evaluation into its result 12, or total evaluation, given by
(3 +4+ 5)
remove brackets	evaluate brackets
μ	Te 
3+4+5	12
Here is another consistency check: if p admits a partial evaluation into q, then
p and q necessarily must have the same result.
Proposition 2.4 (Law of total evaluation) Consider the formal expressions p, q : S → T A, and suppose that there exists a partial evaluation from p into q. Then p and q have necessarily the same result, i.e. e ◦ q = e ◦ p.
Proof The multiplication square of the T -algebra (A, e) is a commutative diagram

TTA	Te	TA 
μ	e
TA	e	A

Now suppose that k : S → TTA gives a partial evaluation of p into q, i.e. μ ◦ k = p, and (Te) ◦ k = q. Then, since the square above commutes,
e ◦ q = e ◦ (Te) ◦ k = e ◦ μ ◦ k = e ◦ p,

as was to be shown.	□
Example 2.5 Following Example 2.3, there is a partial expression of 3 + 4 + 5 into 7 + 5, witnessed by (3 + 4) + (5):

(3 + 4) + (5)
remove brackets	evaluate brackets
μ	Te 
3+4+5	7 +5 
The two formal expressions have then necessarily the same result, in this case, 12.

Composing partial evaluations
There is another appealing property to expect from partial evaluations, namely that if we can partially evaluate p to q and q to r, then we expect that we should be able to partially evaluate p to r.
Example 2.6 Consider again sums of natural numbers. Then the formal sum 1 + 1 + 1 + 1 can be partially evaluated to 2 + 2, and 2 + 2 can be partially (and

totally) evaluated to 4. This is witnessed by the following elements:
(1 + 1) + (1 + 1)	(2 + 2)
1+1+1+1	2 +2	4
In order to construct a partial evaluation from the left to the right, we need an expression such that removing its brackets yields 1 + 1 + 1 + 1, and evaluating the brackets yields 4. The idea is that 4 is obtained by 2 + 2, but each of the 2 in the expression is itself obtained by 1 + 1. Therefore we can substitute each term 2 by the term of which it is a partial evaluation, in other words, we form the expression ((1 + 1) + (1 + 1)) which sits in the diagram:
((1 + 1) + (1 + 1))
(1 + 1) + (1 + 1)	(2 + 2)
μ	Te 
1+1+1+1	2 +2	4
In order to get the witness of the composite partial evaluation, we have to then remove the inner nesting, or inner brackets, via the map Tμ. The element thus obtained is (1 + 1 + 1 + 1), as expected:
((1 + 1) + (1 + 1))
Tμ 
(1 + 1) + (1 + 1)	(1 + 1 + 1 + 1)	(2 + 2)

μ
μ
1+1+1+1	Te 

Te 
2 +2	4

Let’s now try to generalize the example above, and the role of “substitution”. First, let’s introduce some terminology. We recall the definition of a cartesian monad.
Definition 2.7 [e.g. [13, Section 4.1]] Let (T, η, μ) be a monad on a category C. The monad (T, η, μ) is called cartesian if:
The functor T preserves pullbacks;
All naturality squares of η and μ are pullbacks.
Example 2.8 Every monad on Set which arises from a (non-symmetric) operad is cartesian [13, Section C.1].
As we will see, partial evaluations for cartesian monads are particularly well- behaved. But cartesianness is also a very restrictive condition, and we thus consider

a variant of it, based on the standard concept of weak pullback.
Definition 2.9 Let C be a category. A commuting square in C
f
A  B
g	m
C	n	D
is a weak pullback if for every object S of C and pair of arrows b : S → B and c : S → C such that m ◦ b = n ◦ c, there exists an arrow a : S → A such that the following diagram commutes:
S

B

m

C	n	D
Note that we do not require the map a to be unique. We use this to generalize the notion of weakly cartesian monad [19,3] from Set to all categories.
Definition 2.10 Let (T, η, μ) be a monad on a category C. We say that (T, η, μ) is weakly cartesian if:
The functor T preserves weak pullbacks;
The naturality squares of η and μ are weak pullbacks.
Example 2.11 The free monoid monad on Set is cartesian [3, Observation 2.1(d)]. The free commutative monoid monad on Set is weakly cartesian, but not cartesian [3, Example 8.2].
We have the following result:
Proposition 2.12 Let T be a monad on a category C. Let (A, e) be a T -algebra, and suppose that the following diagram is a weak pullback:


TTTA 
μ

TTA 
TTe 



Te 
TTA 
μ

TA 

(5)

Then the partial evaluation relation on every set of formal expressions C(S, TA)
is transitive.
Proof We have to prove the following: given p, q, r : S → TA and k, h : S → TTA such that (Te) ◦ k = p, μ ◦ k = (Te) ◦ h = q, and μ ◦ h = r. Then there exists ρ : S → TTA such that Te ◦ ρ = p and μ ◦ ρ = r.

Consider now the commutative diagram:





(6)










(which commutes by the composition, associativity, and naturality squares). Then we have that p sits in the bottom left corner, q in the top corner, and r in the bottom right corner, while k sits in the top left corner, and h in the top right. Since the top diamond is exactly diagram (5), which by hypothesis is a weak pullback diagram, there exists an a : S → TTTA such that (6) still commutes. Therefore ρ := (Tμ) ◦ a is such that (Te) ◦ ρ = p and μ ◦ ρ = r.	□
Since the square (5) is necessarily a weak pullback for any weakly cartesian monad, we have
Corollary 2.13 Let T be a weakly cartesian monad. Then for every T -algebra
(A, e) and every object S, the partial evaluation relation on C(S, TA) is transitive.
Since the free commutative monoid monad is weakly cartesian, this construction reproduces Example 2.6.
In the same way, if T is cartesian, or only if μ is, then the diagram (5) is a pullback. This makes the composition of partial evaluations into an algebraic operation, if we keep track of the element of TTA which witnesses each partial evaluation relation.
As a simplicial object
The diagram (6) essentially encodes the first three levels of the bar construction [15, Section VII.6]. In particular, the weak pullback condition of Proposition 2.12 is exactly a Kan filler condition, as for nerves of categories and more generally qua- sicategories, applied to the bar construction. More generally, the bar construction

has the flavor of a higher-categorical extension of the partial evaluation relation. The study of its higher compositional properties is work in progress; in this section, we describe what we know so far.
Definition 3.1 Let T be a monad on C and (A, e)a T -algebra. The bar construc- tion of (A, e) is the simplicial object A• in the category of T -algebras given by the following assignments for all i ≥ 0:
Ai := T i+1A;
dj : Ai+1 → Ai given by
Tjμ : T i+2A → T i+1A for 0 ≤ j < i + 1, and
T i+1e : T i+2A → T i+1A for j = i + 1;
sj : Ai → Ai+1 given by T j+1η : T i+1A → T i+2A for 0 ≤ j ≤ i.
The simplicial identities are guaranteed to hold by the monad and algebra struc- ture, and by naturality of the structure maps. This implies, in particular, that given an object S of C, we get a simplicial set C(S, A•), with the following interpretation:
The vertices of the simplicial set are given by the (generalized) elements of T A,
i.e. (generalized) formal expressions;
The 1-simplices are given by witnesses of partial evaluations: since the source and target maps
d0, d1 : C(S, A1) −→ C(S, A0)
are exactly given by applying μ and Te as in the definition of the partial evaluation relation, Definition 2.1. We can hence view the 1-simplices of the bar construction as arrows pointing in the direction of partial evaluation;
For every vertex, or equivalently formal expression, the map
s0 : C(S, A0) −→ C(S, A1)
given by Tη gives an “identity” 1-simplex, which has the correct source and target, corresponding to the proof of Proposition 2.2.
The composition of 1-simplices, when defined as in the proof of Proposition 2.12, is given by a 2-simplex which is exactly a Kan filler of an inner horn. When T is weakly cartesian, this filler always exists. When T is cartesian, this filler is more- over unique, and the resulting simplicial set is even the nerve of a category [18].
Since partial evaluations (or equivalently, partial decompositions) are in most cases intrinsically directed, these simplicial objects (and the simplicial sets that we obtain by proving them with objects S) give “spaces” which are intrinsically directed. As spaces, it thus seems most natural to study them with the methods and tools of directed homotopy theory (see for example [8]).
In terms of rewriting systems
An abstract reduction system (ARS) is a set equipped with a binary relation, called the reduction relation [1, Chapter 1].

Given a monad T on C,a T -algebra (A, e), and an object S, partial evaluations of S-indexed expressions give a binary relation on C(S, TA). The results of Section 2 then give the following.
Proposition 4.1 The set C(S, TA) equipped with the partial evaluation relation →
gives an ARS with the following properties:
Reflexivity: for each s ∈ C(S, TA), s → s;
Confluence: if for s, t, u ∈ C(S, TA) we have
s
t	u
then there exists z ∈ C(S, TA) such that
s
t	u

z
In particular, z can always be given by the “total evaluation” η ◦ e ◦ t = η ◦ e ◦ u
of Proposition 2.4;
If T is weakly cartesian, then → is transitive.
The composition of partial evaluations can be thought of as a “rewriting of rewritings”, which points to the theory of higher rewritings (see for example [2,14]). At least in this framework, however, higher rewrite rules are defined in terms of simplicial rather than globular shapes.

Examples
Here are some examples of monads and of the partial evaluations that they induce. Here we restrict to monads on Set, and traditional elements (as in, arrows from the terminal set 1 → X as opposed to more general arrows S → X).

Monoid and group action monads.
Let G be a monoid (or group) in Set. The same example works more generally for internal monoids (or groups) in a cartesian monoidal category in terms of generalized elements, but we explain it only in the case of Set for simplicity.
The assignment X '→ G×X is part of a functor equipped with a monad structure, with unit and multiplication induced by those of G, and the algebras e : G×A → A are the objects equipped with G-actions. Let now (g, x) and (h, y) be elements of G × A. We have that (h, y) is a partial evaluation of (g, x) if and only if there is an

element (h, l, x) ∈ G × G × A such that hl = g and lx = y. In pictures:

g

x	gx

In other words, (h, y) is a partial evaluation of (g, x) if and only if we can write g as a composite hl, such that “applying only the part l to x gives y”. So (h, y) is “further along in the orbit” than (g, x). If G is a group, then whenever x and y are on the same orbit we can find the decomposition above, by setting l = h−1g, and the partial evaluation relation is symmetric: it is the equivalence relation given by belonging to the same orbit. If G is only a monoid, instead, then the partial evaluation relation is generally stronger than being in the same orbit and need not be symmetric.
As this monad (on Set) is associated to a non-symmetric operad, it is a cartesian monad. Thus witnesses of partial evaluations can be uniquely composed (and their composition is given by the composition of the monoid or group). In this case, the category whose nerve is the simplicial set Set(1, A•) arising from the bar construction has pairs (g, x) as above as objects, and triples (h, l, x) as above as morphisms, with domain (hl, x) and codomain (h, lx).
Idempotent monads.
For idempotent monads, it is easy to check that all partial evaluations are trivial, in the sense that the partial evaluation relation is the equality relation.
Free monoid monad.
This monad is also associated to an operad. Therefore, also here, partial evalu- ations can be uniquely composed, and form a category. We are currently not aware of a more explicit description of this category.
Free commutative monoid monad.
This monad is weakly cartesian [3]. Therefore, partial evaluation witnesses in
TTA can still be composed, but the composition is typically not unique.
Partial evaluations in probability
Partial evaluations for probability monads permit to compare probability distribu- tions in terms of how spread or how random they are.
Common ways of measuring the “randomness” of a probability measures are functionals like variance and entropy. However, there is important information that a single real number cannot encode. Intuitively, a single number can measure only “how much” the randomness is, but not “where”, or “in which way”.
Example 6.1 Consider for example the probability distributions on R whose den- sities are represented in the following picture.



−1	0	1
One can say that p is “more random” or “more spread” than q around the same center of mass. Instead, while r looks more “peaked” than q, it is so “somewhere else”: it has indeed less randomness quantitatively, but over different regions. In a partial order, we would say that q and r are incomparable. In higher dimensions, the same would be true if the two distributions were spread around the same cen- ter of mass, but along different directions. This is what we mean by “where the randomness is”.
It turns out that partial evaluations can be employed to detect this finer notion of randomness, and that they are related to the so-called second-order stochastic dominance relation [4]. In the rest of this section we will sketch how this works. The details have been worked out in the second author’s PhD thesis [16, Chapter 4]. Again we will focus on set-theoretic elements rather then generalized elements.
The idea of probability monads
The idea of using monads in the context of probability theory, as we describe it here, goes back to Lawvere [12] and Giry [7].
We have seen that monads can be interpreted in terms of formal expressions encoding possible “operations”. In the case of probability monads, the operations in question are formal convex combinations, or mixtures.
Consider a coin flip, where “heads” and “tails” both have probability 1/2. Then
in some sense, this is a convex combination of “heads” and “tails”. Formally, the set
{“heads”, “tails”} is not set in which convex combinations are defined, so one can’t really take actual mixtures of its elements. However, one can embed {heads, tails} into the space
λ “heads” + (1 − λ) “tails” | λ ∈ [0, 1] ,
using the map which sends
“heads” '→ 1 “heads” + 0 “tails”, “tails” '→ 0 “heads” + 1 “tails”.
In this new space, one can actually take convex combinations: for example, 1/2 “heads”+1/2 “tails” is now a convex combination of the extremal points “heads” and “tails”. In general one does not only take finite convex combinations, but rather integrals with respect to normalized measures, so we are talking about generalized mixtures, in the sense of Choquet theory [20]. The interpretation is nevertheless the same.

Given an object X, which we can think of a set of possible (deterministic) states, we can form an object PX, which contains “formal mixtures” of elements of X;
Every function f : X → Y gives a function Pf : PX → PY by convex-linear extension;
X is embedded into PX via a map δ : X → PX which maps an element x ∈ X
to the trivial formal convex combination x;
Formal mixtures of formal mixtures can be evaluated using the map E : PPX →
PX, as the following example illustrates.
Example 6.2 Suppose that you have two coins in your pocket. Suppose that one coin is fair, with “heads” on one face and “tails” on the other; suppose the second coin has “heads” on both sides. Suppose now that you draw a coin randomly, and flip it.
We can sketch the probabilities in the following way:
?

coin 1	coin 2
			
heads	tails	heads	tails
Let X be the set {“heads”, “tails”}. A coin gives a law according to which we will obtain “heads” or “tails”, so it determines an element of PX. Since the choice of coin is also random (we also have a law on the coins), the law on the coins determines an element of PPX.
By averaging, the resulting overall probabilities are
?
	
heads	tails
In other words, the “average” or “composition” can be thought of as an assignment E : PPX → PX, from laws of “random random variables” to laws of ordinary random variables.
There are spaces, for example R, where one can take actual mixtures. These correspond exactly to the algebras of P . In other word, a P -algebra is a space with (finite and possibly suitably infinite) convex combinations satisfying suitable equations, such as a convex subset of some vector space. Taking expectation values is one of the most important operations in probability theory: the spaces where this can be done are precisely the algebras of a probability monad.
The details of how this is carried out in practice vary, depending on the choice of category, of monad, and so on. So in particular, one may get different sorts of “convex spaces”. The probability monad that we use in this section, the Kantorovich

monad, has as algebras precisely the closed convex subsets of Banach spaces (see [6]). Another example in the literature is the Radon monad on the category of compact Hausdorff spaces: its algebras are precisely the compact convex subsets of locally convex topological vector spaces [21,11].
Two examples
We recall here the definition of two probability monads: the distribution monad on Set, of use in theoretical computer science, and the Kantorovich monad, which one can consider as an analogue with possibly continuous distributions, in the category of complete metric spaces.
First we sketch the basic construction of the distribution monad, also known as the convex combination monad or ﬁnitary Giry monad.
Let X be a set. Define DX as the set whose elements are functions p : X → [0, 1] such that p(x) /= 0 for only finitely many x, and x∈X p(x) = 1. Note that the sum above is finite if one excludes all the vanishing terms. The elements of DX are called ﬁnite distributions or ﬁnitely supported probability measures over X.
Given a function f : X → Y , one defines the pushforward Df : DX → DY as follows. Given p ∈ DX, then (Df )(p) ∈ DY is the function


y '→
x∈f−1(y)
p(x).

This makes D into an endofunctor on Set. The unit map δ : X → DX maps the element x ∈ X to the function δx : X → [0, 1] given by
δ (y) =	1	y = x;
0	y /= x.
The multiplication map E : DDX → DX maps ξ ∈ DDX to the function Eξ ∈ DX
given by

Eξ(x) =
p∈DX
p(x) ξ(p).

The maps E and δ satisfy the usual monad laws. The D-algebras are known as convex spaces, and their morphisms as affine or convex-linear maps. For more details, see for example [5] and [10].
The Kantorovich monad is a monad on the category CMet of complete metric spaces and short (nonexpanding) maps, i.e. functions f : X → Y such that for every x, xj ∈ X,
d f (x),f (xj) ≤ d(x, xj).
Definition 6.3 Let X be a complete metric space. The Kantorovich-Wasserstein space PX is the space whose elements are Radon probability measures on X with finite first moment, and whose metric is given by:

d(p, q) := sup
f :X→R
∫ f dp − ∫ f dq,

where the supremum is taken over all the short maps X → R.
The assignment X '→ PX is part of a functor: we can assign to each morphism f : X → Y a morphism Pf : PX → PY given by the push-forward of probability measures. In other words, if p ∈ PX and A is a measurable subset of Y , then:
(Pf )(p)(A) := (f∗p)(A)= p(f−1(A)).
The unit of the monad is given by the Dirac delta map δ : X → PX, which assigns to each x ∈ X the Dirac mass δx concentrated at X. The composition E : PPX → PX is given by integration, as in Example 6.2: if μ ∈ PPX and A is a measurable subset of X, then
(Eμ)(A) :=	p(A) dμ(p).
PX 
The algebras of the Kantorovich monad must be first of all objects of our cate- gory, i.e. complete metric spaces. Moreover, as we have seen, they should be closed with respect to convex combinations in some sense, as for example convex regions of a vector space. Closed convex subsets of Banach spaces are then an ideal candi- date: they are complete metric spaces, and they are convex. It can be proven [6, Section 5.3] that the P -algebras in CMet are exactly the closed convex subsets of Banach spaces (up to isomorphism), with the structure map given by the (Bochner) integral.
For more details, we refer the reader to [6] and [16].
Partial expectations, dilations, conditional expectations
Let’s now study partial evaluations for algebras of the two probability monads mentioned above. The material in this subsection about the Kantorovich monad be found more in detail in [16, Section 4.2.1], in particular, all the proofs can be found there (modulo some differences in terminology). The result is closely related to previous work of Winkler and Weizs¨acker (see [20] and the discussion therein).
First of all, for both monads the partial evaluation relation is transitive.
Proposition 6.4 Consider a function f : X → Y . The following commutative diagram is a weak pullback.


DDX
μ

DX
DDf



Df
DDY
μ

DY

Proof Let p ∈ DX, let α ∈ DDY be given as the formal convex combination


α :=
q∈DY
αq δ,	qy δy⎞.
y∈Y

Let p = Σx px (x), and suppose that μ(α)= f∗p, which means that for every y ∈ Y ,

q∈ΣDY
αq qy =
x∈f−1(y)
px.

Take now the measure β ∈ DDX given by


β :=
q∈DY
αq δ,	qy · p|y⎞.
y∈Y



We have
f∗∗β = Σ

αq δ,⎝Σ qy f∗(p|y)⎞⎠ = Σ



αq δ,⎝Σ qy δy⎞⎠ = α.



Just as well,
μ(β)= Σ

αq Σ qy · p|y = Σ

Σ αq qy · p|y

q∈DY
= Σ
y∈Y
Σ
y∈Y q∈DY
px · p|y = Σ(f∗p)y δy · p|y = f∗p · p|y = p.

y∈Y x∈f−1(y)
y∈Y

□

The analogous statement for the Kantorovich monad is the following result [16, Theorem 2.6.9]:
Theorem 6.5 For every naturality square
TTX	E	TX 
TTf	Tf 
TTY	E	TY 
of the multiplication transformation E : PP ⇒ P, the weak universality property required of a weak pullback holds for maps out of the singleton space 1.
This is enough to see that the partial evaluation relation for algebras of the Kan- torovich monad is transitive at the level of ordinary elements. But more generally, we do not know:
Problem 6.6 Is the multiplication of the Kantorovich monad weakly cartesian?
Given a set or complete metric space X, let p, q be distributions in DX or PX, respectively. The intuition behind a partial evaluation from p to q is that q is “more concentrated” than p, or “closer to a delta at its center of mass”. From the statistical point of view, q is better approximated by just looking at its expectation than p, since p is “more spread out”.

Just as well, also the inverse process, partial decomposition, is useful in proba- bility. It is known and it goes under the name of a dilation: a random map which intuitively “only spreads, but does not translate” (think of diffusion without drift, or the kernel of a martingale). In statistics, this roughly corresponds to “adding unbiased noise”, or “casual, not systematic errors”.
Definition 6.7 In the category of sets, let (A, e) be a D-algebra (for example, A = R), and let p ∈ DA. A p-dilation is a map k : A → DA such that for all a in the support of p, e(k(a)) = a.
Definition 6.8 In the category of complete metric spaces, let (A, e) bea P -algebra. For p ∈ P A, a p-dilation is a map k : A → P A, e(k(a)) = a for p-almost all a ∈ A.
Trivially, every dilation is a p-dilation. The most trivial dilations are the unit components of D and P .
Proposition 6.9 In the category of sets, let (A, e) be a D-algebra, and let p, q ∈
DA. The following conditions are equivalent:
There exists a partial decomposition of p into q;
There exists a p-dilation k such that E ◦ Dk(p)= q.
Proof
(a) ⇒ (b): Let r ∈ DDA be a partial decomposition of p into q, i.e. De(r) = p and E(r)= q. Construct a map k : A → DA as follows. For each s ∈ DA which lies in the support of r, note that e(s) ∈ A lies in the support of p = De(r). Now for each a in the support of p, define k(a) ∈ DA by “conditioning”, i.e.

 1 
k(a)(b) :=
p(a)
s∈eΣ−1(a)
r(s) s(b)

for all b ∈ A. The value of k outside the support of p can be arbitrary, and we get a p-dilation. Moreover,
Dk(p)(s)=	p(a) k(a)= r(s),
a
so that Dk(p)= r, and so E ◦ Dk(p)= q.
(b) ⇒ (a): Define r := Dk(p). We have that E(r)= q by hypothesis. Moreover, for each a in the support of p, e(k(a)) = a, so that
De(Dk(p))(a)=	p(a) e(k(a)) = p(a),
a
hence De(r)= p. Therefore, r is a partial decomposition of q into p.
□
We have then again the following result for the continuous case [16, Lemma 4.2.17].

Theorem 6.10 In the category of complete metric spaces, let (A, e) be a P-algebra, and let p, q ∈ P A. The following conditions are equivalent:
There exists a partial decomposition of p into q;
There exists a p-dilation k such that E ◦ k∗p = q.
We have gained an extra interpretation: in the context of probability, a partial decomposition of p into q is a process of “adding noise”, or “letting diffusion take place”. Conversely, we can then also interpret partial evaluations as “removing noise”.
In probability theory there exists already a concept that intuitively is a “partial expectation”, namely, conditional expectation of random variables. It turns out that the two concepts are in some sense equivalent, at least in the case of the Kantorovich monad.
Definition 6.11 Consider a probability space (X, F, μ), a sub-σ-algebra G of F, and measurable mappings f, g : X → A such that f∗μ and g∗μ have finite first moment. We say that g is a conditional expectation of f given G if:
The function g is also G-measurable;
For every G in the σ-algebra G, we have

g dμ =	f dμ.
G	G
For brevity, we extend the terminology to the image measures themselves:
Definition 6.12 Let p, q ∈ P A. We call a conditional expectation of p into q in distribution a probability space (X, F, μ) together with a sub-σ-algebra G of F, and mappings f, g : X → A, with f F-measurable and g G-measurable, such that p = f∗μ, q = g∗μ, and g is a conditional expectation of f given G.
Here is now the main result [16, Theorem 4.2.14]:
Theorem 6.13 Let (A, e) be a P-algebra, and let p, q ∈ P A. The following condi- tions are equivalent:
There exists a partial evaluation of p into q;
There exists a conditional expectation of p into q in distribution.
So, in particular, the law of total evaluation of Proposition 2.4 corresponds to the well-known law of total expectation of random variables.
This does not mean, however, that whenever there is a partial evaluation of p into q, their associated random variables are in relationship of conditional expecta- tion: we are only looking at the distributions, and we are not even taking them to be jointly distributed: while it can be shown that both a partial evaluation of p into q and a conditional expectation in distribution do determine a joint distribution, the mere existence of either kind of structure does not. In other words, the theorem

does not give an equivalence of structures (partial evaluations and conditional ex- pectations), but merely an equivalence of properties of admitting those structures. The question of whether the equivalence can be strengthened to an equivalence of structures, up to suitable isomorphism, is currently still open.
Yet again an additional interpretation can be given, connecting to the notion of second-order stochastic dominance. We can interpret a concave function as a “risk- averse observer”, as it is customary in mathematical finance [17,4]. The reason is that the integral of a convex function is higher if the integration measure is more “concentrated”.
Definition 6.14 Let (A, e) be a P -algebra, and let p, q ∈ P A. We say that p ≤ q in the second-order stochastic dominance relation if and only if for every concave function f : A → R,
∫ f dp ≤ ∫ f dq.
We have that this order is again equivalent to the partial evaluation order [16, Theorem 4.4.9]:
Theorem 6.15 Let (A, e) be a P-algebra, and let p, q ∈ P A. We have that p ≤ q in second-order stochastic dominance if and only if there is a partial evaluation from p to q.
Therefore, the partial evaluation order for probability distributions on Banach spaces encodes in a categorical way exactly also the notion of randomness that is used in mathematical finance, native to that field.
Acknowledgements
This paper was originally written for the Applied Category Theory 2019 school. We thank the participants of our and other groups for their interest, useful feedback and fruitful collaboration. We also thank Dirk Hofmann, Joachim Kock, Steve Lack, Rostislav Matveev, Paige Randall North, Sharwin Rezagholi, David Spivak, and Tarmo Uustalu for the very fruitful discussions and the helpful advice. Most of this paper was written while both authors were with the Max Planck Institute for Mathematics in the Sciences, which we thank for providing an outstanding research environment.

References
Ronald V. Book and Friedrich Otto. String Rewriting Systems. Springer, 1993.
Albert Burroni. Higher-dimensional word problems with applications to equational logic. Theoret. Comput. Sci., 115(1):43–62, 1993. 4th Summer Conference on Category Theory and Computer Science (Paris, 1991).
Maria Manuel Clementino, Dirk Hofmann, and George Janelidze. The monads of classical algebra are seldom weakly cartesian. J. Homotopy Relat. Struct., 9:175–197, 2014.
Peter C. Fishburn. Stochastic dominance and moments of distributions. Mathematics of Operations Research, 5(1):94–100, 1980.

Tobias Fritz. Convex Spaces I: Definitions and Examples. arXiv:0903.5522.
Tobias Fritz and Paolo Perrone. A probability monad as the colimit of spaces of finite samples. Theory and Applications of Categories, 34(7):170-220, 2019. arXiv:1712.05363.
Mich`ele Giry. A categorical approach to probability theory. In Categorical aspects of topology and analysis, volume 915 of Lecture Notes in Mathematics. 1982.
M. Grandis. Directed Algebraic Topology. Cambridge University Press, 2009.
Martin Hyland and John Power. The category-theoretic understanding of universal algebra: Lawvere theories and monads. ENTCS, 172:437-458, 2007.
Bart Jacobs. From probability monads to commutative effectuses Journal of Logical and Algebraic Methods in Programming, 94:200–237, 2018.
Klaus Keimel. The monad of probability measures over compact ordered spaces and its Eilenberg-Moore algebras. Topology Appl., 156(2):227–239, 2008.
William Lawvere. The category of probabilistic mappings. Available at https://ncatlab.org/nlab/ files/lawvereprobability1962.pdf, 1962.
Tom Leinster. Higher Operads, Higher Categories, volume 298 of London Mathematical Society Lecture Note Series. Cambridge University Press, 2004. arXiv:math/0305049.
Samuel Mimram. Towards 3-dimensional rewriting theory. Logical Methods in Computer Science, 10:1–47, 2014.
Saunders Mac Lane. Categories for the Working Mathematician. Springer, 2000.
Paolo Perrone. Categorical Probability and Stochastic Dominance in Metric Spaces. PhD thesis, University of Leipzig, 2018. Available at http://www.paolperrone.org/phdthesis.pdf.
M. Rothschild and J. E. Stiglitz. Increasing risk: I. A definition. Journal of Economic Theory, 2:225- 243, 1970.
Graeme Segal. Classifying spaces and spectral sequences. Hautes E´tudes Sci. Publ. Math., 34:105–121, 1968.
Mark Weber. Generic morphisms, parametric representations and weakly cartesian monads. Theory and Applications of Categories, 13(14):191–234, 2004.
Gerhard Winkler. Choquet order and simplices with applications in probabilistic models. Lecture Notes in Mathematics. Springer, 1985.
Tadeusz S´wirszcz. Monadic functors and convexity. Bull. Acad. Polon. Sci. S´er. Sci. Math. Astronom. Phys., 22, 1974.
