Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 325 (2016) 127–146
www.elsevier.com/locate/entcs


Iteration and Labelled Iteration
Bram Geron1 and Paul Blain Levy 2
School of Computer Science, University of Birmingham, Edgbaston, Birmingham, B15 2TT, UK


Abstract
We analyse the conventional sum-based representation of iteration from the perspective of programmers, and show that the syntax they suggest is fundamentally not a good representation of Java-style iteration with for, while, break, and continue. We present an alternative syntax, which we call “labelled iteration”, where loops are identified using labels.
The languages are analysed: we give denotational and operational semantics, adequacy proofs for both languages, and a translation function from sum-based iteration to labelled iteration.
Keywords: iteration, loops, lexical binding, operational semantics, denotational semantics, higher-order language, lambda calculus, de Bruijn indices


Introduction
Overview
Iteration is an important programming language feature.
In imperative languages, it is best known in for and while loops. The meaning of such a loop is to iterate code until some condition is met, or if the condition is never met, the loop diverges. Such loops are often supplemented by break and continue.
It has also been studied in the lambda calculus setting [13,19,21].
In the categorical setting, iteration corresponds to complete Elgot monads [9]. They descend from iterative, iteration, and Elgot theories, and their algebras and monads [7,1,2,3,23], which study variants of the sum-based iteration †. This field is related to Kleene monads [10,17,18].

1 Email: bxg314@cs.bham.ac.uk
2 Email: P.B.Levy@cs.bham.ac.uk

http://dx.doi.org/10.1016/j.entcs.2016.09.035 1571-0661/© 2016 Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

Iteration can be implemented using recursion, but it is simpler: semantics of recur- sion require a least fixpoint, where iteration has a simple set-based semantics. Also from the programmer’s perspective, iteration and recursion are different: a program using a for or while loop can sometimes be clearer than the same program using recursion.

The sum-based representation of iteration
We study two representations of iteration. First, the classical sum-based construct
† that turns a computation Γ,A M A B into a computation Γ,A M † B. Categorically, this representation of iteration corresponds to complete Elgot monads [9]. To understand the correspondence better, we introduce a term constructor iter for −†. (Details are in Section 2.)
Γ ⊢v V ∶ A	Γ, x∶A ⊢c M ∶ A + B
Γ ⊢c iter V, x. M ∶ B
Imperative programs with for and while can now be encoded using iter. As an example, the program on the left corresponds to the term on the right:



x ∶= V ;
while (p(x)) {

iter V, x.
if p(x)

} x ∶= f (x);
then return inl f (x)

return g(x);
else return inr g(x)

This works as follows. The iter construct introduces a new identifier x, which starts at V . The body is evaluated. If the body evaluates to inr W , then the loop is finished and its result is W . If the body evaluates to inl V ′, then we set x to V ′, and keep on evaluating the body until it evaluates to some inr W .

The “De Bruijn index” awkwardness with the sum-based representation
Programmers using imperative languages regularly use nested loops, as well their associated break and continue statements, which may be labelled. Such state- ments are not essential for programming, and code using break or continue can be rewritten so it does not use either statement, but this usually comes at a price in readability. There is usually a labelled and an unlabelled form of break and continue.
On the left side of Figure 1, we show an program in a Java-like language with nested labelled loops, and labelled continue statements.  The colours can be ig-

nored for now. The program computes the formula	0≤i≤8
a[i][0]≠
0≤j≤8
∧ a[i][j] even
a[i][j],





int sum = 0;
outer∶ for (int i = 0; i ≤ 8; i++){


if (a[i][0] == 5)
continue outer; int prod = 1;
inner∶ for (int j = 0; j ≤ 8; j++){

if (¬isEven(a[i][j]))
continue inner;
if (a[i][j] == 0)
// product will be 0.
continue outer;
prod = prod ∗ a[i][j];
}

iter ⟨0, 0⟩, l1.  let ⟨sum, i⟩= l1 in if i ≥ 9 then
return inr sum
else if a[i][0] == 5 then return inl ⟨sum,i + 1⟩
else iter ⟨1, 0⟩, l2.  let ⟨prod,j⟩= l2 in if j ≥ 9 then
return inr inl ⟨sum + prod,i + 1⟩
else if ¬isEven a[i][j] then return inl ⟨prod,j + 1⟩
else if a[i][j] == 0 then


else

}	sum = sum + prod ;
int result = sum;


Figure 1.	Two programs programs that compute the same formula. The left hand program is written in Java; the right hand program uses fine-grain call-by-value with sum-based iteration. Related fragments
have the same colour. Both programs compute ∑ 0≤i≤8 ∏	0≤j≤8	a[i][j] .
∧ a[i][0]≠5  ∧ a[i][j] even
although the specific formula is not important for the example. Recall from Java that “continue inner” aborts the current iteration of the inner loop, and continues with a fresh iteration of the inner while loop. Statement “ continue outer” does the analogous thing but for the outer loop. It will abort the inner loop implicitly.
On the right side, we have a similar program to compute the same formula, but using sum-based iteration.
We use colour to indicate fragments that are intuitively related, because control flows to the same place after those fragments:
After continue inner and the two occurrences of return inl  ,j  1 , control flows to the beginning of the inner loop. We have drawn a solid purple box around those fragments. The assignment to prod on the left also precedes the beginning of the inner loop, and we have coloured it purple.

After both occurrences of continue outer, control flows to the beginning of the outer  loop. Similarly, after	and after the two occurrences of return inr inl  , control flows to the beginning of the outer iter. We have drawn a thick dashed red box around those fragments. The assignment to sum on the left also precedes the beginning of the outer loop, and we have coloured it red.
Note that in the left (Java) program, both statements in red boxes are written the same: “continue outer”.
Both programs work, but the syntax of the right hand program has two awkward- nesses for programmers:
Continuing to the outer loop (red) is written	in one case, and return inr inl in the other cases. The same “control fragment” is written differently depending on where it occurs. This makes moving code into and out of the inner loop error-prone.
return inl  is used to resume both the inner and the outer iteration. To find out where control resumes, a reader of the program must carefully look up the innermost enclosing iteration. In contrast, in the Java program there can be no mistake about where control resumes after continue outer.
This awkwardness is exacerbated when there are three or more nested loops with the same structure: on the right hand side,
return inl (⋯) would continue the innermost enclosing iteration
return inr inl (⋯) would continue the second-innermost enclosing iteration
return inr inr inl	would continue the third-innermost enclosing iteration, which would always be the outer iteration.
We call this the “De Bruijn index awkwardness”, because De Bruijn’s indices [6] for identifiers in λ calculus also work by counting intermediate binders, and they have similar disadvantages for programmers. Indeed, De Bruijn [6] claims his notation to be good for a number of things, but does not claim that it is “easy to write and easy to read for the human reader”. For a brief introduction to De Bruijn indices, we refer to [14]; the same issue has also been studied from a different angle in [4,22].

The solution: Labelled iteration
We solve the De Bruijn index awkwardness with a second iteration construct, which we call labelled iteration and which we will also spell iter. It binds a name x A with a dual purpose:
It holds a value of type A.
It serves as a label for restarting the loop, upon which a new value of type A must be supplied.





int sum = 0;
outer∶ for (int i = 0; i ≤ 8; i++){


if (a[i][0] == 5)
continue outer; int prod = 1;
inner∶ for (int j = 0; j ≤ 8; j++){

if (¬isEven(a[i][j]))
continue inner;
if (a[i][j] == 0)
// product will be 0.
continue outer;
prod = prod ∗ a[i][j];
}

iter ⟨0, 0⟩, l1.	let ⟨sum, i⟩ = l1 in if i ≥ 9 then
return sum
else if a[i][0] == 5 then raisel1 ⟨sum,i + 1⟩
else iter ⟨1, 0⟩, l2.	let ⟨prod,j⟩ = l2 in if j ≥ 9 then
raisel1 ⟨sum + prod,i + 1⟩
else if ¬isEven a[i][j] then raisel2 ⟨prod,j + 1⟩
else if a[i][j] == 0 then


else

}	sum = sum + prod ;
int result = sum;


Figure 2. Two programs programs that compute the same formula. The left hand program is written in Java; the right hand program uses fine-grain call-by-value with labelled iteration. Related fragments have
the same colour. Both programs compute ∑ 0≤i≤8 ∏	0≤j≤8	a[i][j] .
∧ a[i][0]≠5  ∧ a[i][j] even
In Figure 2, we have put the same Java program side-by-side side with an imple- mentation using labelled iteration.
Like sum-based iteration, labelled iteration has a set-based semantics, but the type system is more involved. We explain labelled iteration in more detail in Section 3. We chose the spelling raise because there is a similarity with raising an exception; see also the discussion in Section 4.

Contributions

We define both languages: we give a type system, denotational semantics, big-step operational semantics, and an adequacy theorem for both languages. We explain the De Bruijn index awkwardness with the first language, and give a realistic example.

We show that the first construct can be macro-expressed in terms of the second construct.
For both types of iteration, we study only loops with continue: we omit break
because we believe it is a straightforward extension.
We define the language with sum-based iteration in Section 2, and the language with labelled iteration in Section 3.

Sum-based iteration

We define both our constructs in terms of fine-grain call-by-value or FGCBV [20], which is a variant of call-by-value lambda calculus that has a syntactic separation between values and computations, and in which the evaluation order is made explicit.
We explain FGCBV and sum-based iteration here. The syntax and type system of FGCBV is given in Figure 3. We give a simple set-based semantics with divergence:

J1) = {⋆}
Jnat) = N

JΓ) = ∏(x∶A)∈Γ JA)

JA + B) = JA) + JB) JA × B) = JA) × JB)
JA → B) = JA) → (JB) + {ı})
JΓ ⊢v V ∶ A) ∈ JΓ) → JA)
JΓ ⊢c M ∶ A) ∈ JΓ) → (JA) + {ı})


The semantics of plain FGCBV and FGCBV with sum-based iteration are the same, except of course that the latter has an extra construct. We give big-step operational semantics for both languages in Figure 5. The adequacy statements are simple:
Proposition 2.1 (adequacy)
For each closed term M of plain FGCBV without iteration, there is a unique
V such that M ⇓ return V , and JM )∅ = inl JV )∅.
For each closed term M of FGCBV with sum-based iteration, either
there is a unique V such that M ⇓ return V , and JM )∅ = inl JV )∅, or
M does not reduce to a terminal, and JM )∅ = inr ı.

Labelled iteration with pure function types
Introduction
To fix the De Bruijn index awkwardness indicated in Section 1.3, we now give a language that has an effectful “labelled iteration” construct instead. The judgements

values	V, W ∶∶= x ∣ ⟨⟩∣ 0 ∣ succ V ∣ inl V ∣ inr V ∣ ⟨V, W ⟩∣ λx. M
computations	M, N ∶∶= ∣return V ∣ let V be x. M ∣ M to x. N
case V of {inl x. M ; inr y. N }∣ case V of ⟨x, y⟩. M 
types	A, B, C ∶∶= 1 ∣ nat ∣ A + B ∣ A × B ∣ A → B


 (x ∶ A)∈ Γ
Γ ⊢v x ∶ A	Γ ⊢v ⟨⟩ ∶ 1	Γ ⊢v 0 ∶ nat
Γ ⊢v V ∶ nat


Γ ⊢v succ V ∶ nat

Γ ⊢v V ∶ A
Γ ⊢v inl V ∶ A + B

Γ ⊢v V ∶ A


Γ ⊢c return V ∶ A

Γ ⊢v V ∶ B


Γ ⊢v inr V ∶ A + B

Γ ⊢v V ∶ A	Γ,x ∶ A ⊢c M ∶ B
Γ ⊢c let V be x. M ∶ B

Γ ⊢v V ∶ A	Γ ⊢v W ∶ B


Γ ⊢v ⟨V, W ⟩∶ A × B

Γ ⊢c M ∶ A	Γ,x ∶ A ⊢c N ∶ B


Γ ⊢c M to x. N ∶ B

Γ,x ∶ A ⊢c M ∶ B
Γ ⊢v λx. M ∶ A → B
Γ ⊢v V ∶ A → B	Γ ⊢v W ∶ A


Γ ⊢c V W ∶ B

Γ ⊢v V ∶ nat	Γ ⊢c M ∶ C	Γ,x ∶ nat ⊢c N ∶ C
Γ ⊢c case V of {0. M ; succ x. N }∶ C

Γ ⊢v V ∶ A + B	Γ,x ∶ A ⊢c M ∶ C	Γ,y ∶ B ⊢c N ∶ C
Γ ⊢c case V of {inl x. M ; inr y. N }∶ C

Γ ⊢v V ∶ A × B	Γ,x ∶ A, y ∶ B ⊢c M ∶ C
Γ ⊢c case V of ⟨x, y⟩. M ∶ C

Addition for sum-based iteration
Γ ⊢v V ∶ A	Γ,x ∶ A ⊢c M ∶ A + B
Γ ⊢c iter V, x. M ∶ B

Figure 3. Above: syntax of plain fine-grain call-by-value. Sum-based iteration adds only one term construct and no values or types; the type derivation of this term is given below.

in this language are

Δ; Γ ⊢c M ∶ A	for computations
Γ ⊢v V ∶ A	for values

We give the typing rules in Figure 6. Γ is a context of identifiers bound to values, as usual. Δ exists only for computations; it is a context of typed labels. Denotations

Fine-grain call-by-value

Jx)ρ = ρ(x) J⟨⟩)ρ = ⟨⟩ J0)ρ = 0

J⟨V, W ⟩)ρ = ⟨JV )ρ, JW )ρ⟩
Jλx. M )ρ = λ(a∈JA)).JM )(ρ,x↦a)
Jreturn V )ρ = inl JV )ρ
Jlet V be x. M )ρ = J⎧M )(ρ,x↦JV )ρ)

Jsucc V )ρ = 1 + JV )ρ
Jinl V )ρ = inl JV )ρ
JM to x. N )ρ
⎪JN )	if JM )ρ = inl v
⎪⎩inr ı	if JM )ρ = inr ı

Jinr V )ρ = inr JV )ρ


Jcase V of {0. M ; succ x. N })
JV W )ρ = JV )ρ JW )ρ

= ⎧⎪⎨JM )ρ	if JV )ρ = 0

ρ	⎪JN )	if JV ) = 1 + n

⎩⎧⎪
(ρ,x↦n)	ρ

Jcase V of {inl x. M ; inr y. N })
= ⎪⎨JM )(ρ,x↦a)	if JV )ρ = inl a

ρ	⎪⎩JN )

(ρ,y↦b)
if JV )ρ
= inr b

Jcase V of {⟨x, y⟩. M })ρ = JM )(ρ,x↦a,y↦b)	if JV )ρ = ⟨a, b⟩



Jiter V, x. M )ρ

= ⎨⎪
⎪
∧∀i ∶ JM )(ρ,x↦vi) = inl inl vi+1
∧JM )(ρ,x↦vk ) = inl inr w

⎪⎩inr ı	if no such v0..k exists

Figure 4.	Denotational semantics of values and terms in fine-grain call-by-value, and semantics of the sum-based iteration construct.


of judgements are


JΔ; Γ ⊢c A) = ( ∏ JB))→ ( ∑ JC) + JA) + {ı})

(x∶B)∈Γ	(y∶C)∈Δ
JΓ ⊢v A) = ( ∏ JB))→ JA) .
(x∶B)∈Γ


Γ is used to form values.


 (x∶A)∈ Γ Γ ⊢v x ∶ A

Δ is used to form computations, much like raising an exception. However, conven- tionally, exception names come from a global set. Our “exception names”, which we call labels, will be bound in the same way that identifiers are bound by λ.

Furthermore, when a label is raised, it must be parametrised by a value of the


Fine-grain call-by-value
T ∶∶= return V


return V ⇓ return V
	M [V /x]⇓ T	
let V be x. M ⇓ T
 M ⇓ return V	N [V /x]⇓ T M to x. N ⇓ T


M [W /x]⇓ T λx. M ) W ⇓ T

	M0 ⇓ T	
case 0 of {0. M0; succ x. Msucc}⇓ T

M [V /x, W /y]⇓ T
case ⟨V, W ⟩ of {⟨x, y⟩. M }⇓ T

	Msucc[V /x]⇓ T	
case (succ V ) of {0. M0; succ x. Msucc}⇓ T


	Minl[V /x]⇓ T	
case (inl V ) of {inl x. Minl; inr x. Minr}⇓ T

Addition for sum-based iteration
T ∶∶= return V

	Minr[V /x]⇓ T	
case (inr V ) of {inl x. Minl; inr x. Minr}⇓ T

∃k ≥ 0 ∃(V1, ⋯, Vk) ∀i ∈ {1..k}∶ M [Vi−1/x]⇓ return inl Vi	M [Vk/x]⇓ return inr Z
iter V0, x. M ⇓ return Z


Figure 5. Big-step operational semantics of plain fine-grain call-by-value and of sum-based iteration. In our operational semantics, closed terms reduce to “terminal” terms of the same type, or they do not reduce at all. We use metavariable T for terminals. For FGCBV and its extension with sum-based iteration, terminal terms are always of the form return V . Introducing a separate notion of terminals might seem odd for now, but in Figure 8 we extend the rules for FGCBV and add another form of terminal. So T above may come to stand for something other than return V further in the paper.

corresponding type. The typing rule is as follows:
Γ ⊢v V ∶ A	(x∶A)∈ Δ Δ; Γ ⊢c raisex V ∶ B
We thus have these judgements.
(x ∶ nat × bool) ; (y∶nat, z∶bool) ⊢c raisex ⟨3, true⟩∶ string (x ∶ nat × bool) ; (y∶nat, z∶bool) ⊢c raisex ⟨y, z⟩∶ 0
(x ∶ nat × bool) ; (y∶nat, z∶bool) ⊢c return y ∶ nat
But we cannot raise identifiers:
(x ∶ nat × bool) ; (y∶nat, z∶bool) ⊢/c raisey 3
And we can also not use labels for their value:
(x ∶ nat × bool) ; (y∶nat, z∶bool) ⊢/c return x ∶ nat × bool
Indeed, the typing rule of return (see Figure 6 on the next page) shows that x is not

Values and types are the same as in fine-grain call-by-value in Figure 3 on page 133.
computations	M, N ∶∶= ⋯ ∣ iter V, x. M ∣ raisex V

 (x∶A)∈ Γ Γ ⊢v x ∶ A

Γ ⊢v V ∶ A
Δ; Γ ⊢c return V ∶ A

⋅ ; Γ, x∶A ⊢c M ∶ B
Γ ⊢v λx. M ∶ A → B
Γ ⊢v V ∶ A	Δ; Γ, x∶A ⊢c M ∶ B


Δ; Γ ⊢c let V be x. M ∶ B

Δ; Γ ⊢c M ∶ A	Δ; Γ, x∶A ⊢c N ∶ B
Δ; Γ ⊢c M to x. N ∶ B

Γ ⊢v V ∶ A → B	Γ ⊢v W ∶ A
Δ; Γ ⊢c V W ∶ B



Γ ⊢v ⟨⟩ ∶ 1
Γ ⊢v V ∶ A
Γ ⊢v inl V ∶ A + B

Γ ⊢v V ∶ B
Γ ⊢v inr V ∶ A + B


Γ ⊢v V ∶ nat	Δ; Γ ⊢c M ∶ C	Δ; Γ, x∶A ⊢c N ∶ C
Δ; Γ ⊢c case V of {0. M ; succ x. N }∶ C

Γ ⊢v V ∶ A + B	Δ; Γ, x∶A ⊢c M ∶ C	Δ; Γ, y∶B ⊢c N ∶ C
Δ; Γ ⊢c case V of {inl x. M ; inr y. N }∶ C

Γ ⊢v V ∶ A × B	Δ; Γ, x∶A, y∶B ⊢c M ∶ C
Δ; Γ ⊢c case V of ⟨x, y⟩. M ∶ C


Γ ⊢v V ∶ A	Δ, x∶A; Γ, x∶A ⊢c M ∶ B
Δ; Γ ⊢c iter V, x. M ∶ B

Γ ⊢v V ∶ A	(x∶A)∈ Δ Δ; Γ ⊢c raisex V ∶ B


Figure 6. Syntax of labelled iteration.





available in the context of the argument to return:


y∶nat, z∶bool ⊢v V ∶ nat × bool
(x ∶ nat × bool) ; (y∶nat, z∶bool) ⊢c return V ∶ nat × bool


Our use of a syntactically separate kind of names bears resemblance to the use of function names by Kennedy [16] for control.

Labelled iteration
We now wish to use labels to generalise the iter V, x. M from last section. Remember that previously when M reduces to
return inl V ′,	then the loop should be re-tried with value V ′,
return inr W,	then the result of the loop is W.
Our new notation will also be iter V, x. M . However, here x is both an identifier and a label:
Γ ⊢v V ∶ A	Δ, x∶A; Γ, x∶A ⊢c M ∶ B
Δ; Γ ⊢c iter V, x. M ∶ B
Now similarly when writing iter V, x. M , when M reduces to
raisex V ′,	then the loop should be re-tried with value V ′,
raisey W, (y ≠ x)	then the loop should be aborted
and loop y should be re-tried with value W,
return W,	then the result of the loop is W.
We wish to repeat that the same name x can appear in both Δ and Γ. We pose no general syntactic restriction on x A Δ and x B  Γ to have the same type. However, to be able to form iter V, x. M , we must have x in both Δ and Γ of the same type.
We also wish to note at this point that we define the semantics of our language on the binding diagrams [8], that is, on the abstract syntax modulo α-equivalence.

Labelled iteration and λ
Now that contexts for computations are different from contexts for values, the con- ventional fine-grain call-by-value judgements have to be tweaked to work in this setting. The typing rule for return in Figure 6 is simple: when we move upwards from a computation to a value judgement we just forget about Δ.
Γ ⊢v V ∶ A
Δ; Γ ⊢c return V ∶ A
But reversely, for λ, we have a choice: what should Δ be? We take what seems to be the only reasonable choice: to reset Δ to the empty context, ⋅ .
⋅ ; Γ, x∶A ⊢c M ∶ B
Γ ⊢v λx. M ∶ A → B
Java agrees with this choice: it is a syntax error to write a labelled continue or break with a label outside of the current method [11]. From a programmer’s perspective, this means that all functions are pure.

Denotational semantics
Recall that the semantics of term and value judgements is as follows.
JΔ; Γ ⊢c A) = ( ∏ JB))→ ( ∑ JC) + JA) + {ı})
(x∶B)∈Γ	(y∶C)∈Δ
JΓ ⊢v A) = ( ∏ JB))→ JA)
(x∶B)∈Γ

The denotation of types is as follows.
J1) = {⋆}
Jnat) = N
JA + B) = JA) + JB) JA × B) = JA) × JB)
JA → B) = JA) → (JB) + {ı})
We give the semantics of terms and values in Figure 7. We use the following notation for elements of the ternary sum (∑(x∶B)∈ΔJB) + JA) + {ı}):
return a	(for a ∈ JA))	(compare to the term notation: return V ),
raisex b	(for b ∈ JB))	(compare to the term notation: raisex V ),
ı.
Definition 3.1 [weakening] We say that  ′  ′ is stronger than   when  ′
and Γ′ ⊆ Γ. Alternatively, we say that Δ; Γ is weaker than Δ′; Γ′.

A term in a context is also a term in a weaker context, with the same derivation. A value in a context is also a value in a weaker context, with the same derivation.
Definition 3.2 [closedness]
When ⋅ ⊢v V ∶ A, then we say that V is closed.
When Δ; ⋅ ⊢c M ∶ A, then we say that M is closed.
Definition 3.3 A substitution (between two-zone contexts) σ Δ′; Γ′  Δ; Γ con- sists of two parts,
for every label (x ∶ A)∈ Δ′, a label σlab(x) of type A in Δ, and
for every identifier (x ∶ A)∈ Γ′, a value σid(x)	(Γ ⊢v σid(x)∶ A).
Remark 3.4 From a two-zone substitution   ′ ′	we can trivially obtain a one-zone substitution Γ′ Γ. By abuse of notation, we also write σ for this obtained substitution on one-zone contexts. Similarly, from a one-zone substitution σ Γ′ Γ, we obtain trivially a two-zone substitution ; Γ′  ; Γ, for which we also write σ.



Jx)ρ = ρ(x) J⟨⟩)ρ = ⟨⟩ J0)ρ = 0
Jreturn V )ρ = return JV )ρ Jraisex V )ρ = raisex JV )ρ
Jlet V be x. M )ρ = JM )(ρ,x↦JV ) )

Jsucc V )ρ = 1 + JV )ρ
⎧⎪	ρ

Jinl V )ρ = inl JV )ρ
JN )	if JM ) = return v
JM to x. N )ρ = ⎨⎪raisey w	if JM )ρ = raisey w

Jinr V )ρ = inr JV )ρ
J⟨V, W ⟩)ρ = ⟨JV )ρ, JW )ρ⟩
Jλx. M )ρ = λ(a∈JA)).JM )(ρ,x↦a)

Jcase V of {0. M ; succ x. N })

⎪ı	if JM )ρ = ı 
JV W )ρ = JV )ρ JW )ρ

= ⎧⎪⎨JM )ρ	if JV )ρ = 0

ρ	⎪JN )	if JV ) = 1 + n

⎩⎧⎪
(ρ,x↦n)	ρ

Jcase V of {inl x. M ; inr y. N })
= ⎪⎨JM )(ρ,x↦a)	if JV )ρ = inl a

ρ	⎪⎩JN )

(ρ,y↦b)
if JV )ρ
= inr b

Jcase V of {⟨x, y⟩. M })ρ = JM )(ρ,x↦a,y↦b)	if JV )ρ = ⟨a, b⟩

∧∀i ∶ JM )(ρ,x↦vi) = raisex vi+1
⎪	∧JM )(ρ,x↦vk ) = return w
∧∀i ∶ JM )(ρ,x↦vi) = raisex vi+1
⎪	∧JM )(ρ,x↦vk ) = raisey w
⎪⎩ı	if no other case matches


Figure 7. Denotational semantics of terms and values of the language with labelled iteration. See also Section 3.2.

We can use a substitution	′  ′	as follows on terms. Given a term
Δ′; Γ′ ⊢c M ∶ A, we obtain the term Δ; Γ ⊢c Mσ ∶ A by
for any	, replacing all occurrences of	(where	is free) by raiseσlab(x) (V σ), where Vσ is given similarly by induction. And
for any x ∈ Γ, replacing all value occurrences of identifiers by σid(x).
For one-zone contexts  we have the usual notion of substitution   ′	that assigns a value (over ) to each identifier of ′. And given ′ v  , we obtain similarly Γ ⊢v Vσ ∶ A.
Two-zone contexts and their substitutions form a category, and one-zone contexts and their substitutions form another category. That is, substitutions can be com- posed associatively and composition has an identity.
Lemma 3.5 (substitution lemma)

T ∶∶= return V ∣ raisex V	M ⇓ raise V

M to x. N ⇓ raisex V
∃k ≥ 0 ∃(V1, ⋯, Vk) ∀i ∈ {1..k}∶ M [Vi−1/x]⇓ raisex Vi	M [Vk/x]⇓ return Z
iter V0, x. M ⇓ return Z


∃k ≥ 0 ∃(V1, ⋯, Vk) ∀i ∈ {1..k}∶ M [Vi−1/x]⇓ raisex Vi	M [Vk/x]⇓ raisey Z
iter V0, x. M ⇓ raisey Z

(x ≠ y)



Figure 8. Big-step operational semantics for labelled iteration. This figure extends Figure 5. Namely, we add rules, and we add a new form of terminal: raisex V .

Let one-zone substitution σ ∶ Γ′ → Γ be given. If Γ′ ⊢v V ∶ A, then
ρ	(x↦Jσ(x))ρ)x∈Γ′
Let two-zone substitution σ ∶ Δ′; Γ′ → Δ; Γ be given.

If Δ′; Γ′ ⊢c M ∶ A, then JMσ)ρ = f (JM )(x↦Jσ
where f maps raisex v to raiseσlab(x) v.
(x))ρ)x∈Γ′ ) ,



Operational semantics

We define a big-step “reduction” relation	between closed terms	c
and (closed) terminals Δ; ⋅ ⊢c T ∶ A of the same type, such that for every such M

M ⇓ T = return V , or
M ⇓ T = raisex V , x ∈ dom Δ, or

M does not reduce.

Derivation rules are given in Figure 8, and the reduction relation is defined as their least fixed point.

Theorem 3.6 (adequacy)
If M ⇓ return V , then JM )∅ = return JV )∅.
If M ⇓ raisex V , then JM )∅ = raisex JV )∅.
If M does not reduce, then JM )∅ = ı.

Translation from sum-based iteration
Let  c   or  v   be a term or value in the language with sum-based iteration. We define a translation	,	from sum-based iter- ation, such that  ; Γ c translate M  A or Γ v translate V  A, respectively, in the language with labelled iteration. The translation macro-expands sum-based iter as follows. The other constructs are left unchanged.

translate(iter V, x. M )= iter V, x. (translate(M ) to result .


′	′})

case result of {inl y. raisex y; inr x . return x
where translate(M ) is implicitly weakened by adding x to Δ.
Theorem 3.7 (translation preserves semantics)
Let	c	a term of the language with sum-based iteration, and	. Then JM )ρ = Jtranslate(M ))ρ.
Let	v	a value of the language with sum-based iteration, and	. Then JV )ρ = Jtranslate(V ))ρ.
Corollary 3.8 If   in the language with sum-based iteration, then there is ′ such that	′ in the language with labelled iteration, and	′ . And if M does not reduce to a terminal, then translate(M ) does not reduce to a


Discussion and related work

In our presentation of labelled iteration, we have chosen to only consider pure func- tions. It is an important future task to extend the present system so as to allow for functions that raise an iteration.
We have noticed the De Bruijn index awkwardness in settings other than itera- tion. For instance, it is customary in functional languages such as Haskell to use monad transformers [12] to embed imperative programs with multiple side-effects, but they suffer from a similar De Bruijn index awkwardness: the ith monad trans- former is addressed by writing “ lifti effect ”. This issue and proposed solutions have been studied in the literature [15,24,5], but addressing effects using labels seems yet unexplored. Imperative languages address mutable cells using identifiers, and it is possible that addressing effects with labels might benefit the readability of similar functional programs as well.
Many programming languages have not just unlabelled and labelled continue, after which we have modelled our combination of iter and raise, but also unlabelled and labelled break. It should be straightforward to introduce a construct that binds a label like iter, but when the label is raised with parameter a, the result of that construct is a, so that raise of that label resembles break. Such a construct, together

with the raise we used in this paper, resembles an intra-procedural form of exception handling. If we wrap an iter inside this new construct and use one label for breaking and one for continuing, we can “ break” and “continue” from this combination of constructs, to deepen the resemblence with Java-style loops.

Conclusion

In the present article we summarize the essence of the sum-based representation of iteration, and evaluate it from a programming perspective. Although it might work well for a semantics standpoint, it is inadequate for programmers to program in. We propose an alternative representation of iteration that is suitable for programmers, but still has relatively clean semantics.


References

Peter Aczel, Jiří Adámek, Stefan Milius, and Jiří Velebil. Infinite trees and completely iterative theories: a coalgebraic view. Theoretical Computer Science, 300(1–3):1–45, May 2003.
Jiří Adámek, Stefan Milius, and Jiří Velebil. Elgot Algebras. Logical Methods in Computer Science, 2(5), November 2006.
Jiří Adámek, Stefan Milius, and Jiří Velebil. Elgot theories: a new perspective on the equational properties of iteration. Mathematical Structures in Computer Science, 21(Special Issue 02):417–480, April 2011.
Stefan Berghofer and Christian Urban. A Head-to-Head Comparison of de Bruijn Indices and Names.
Electronic Notes in Theoretical Computer Science, 174(5):53–67, June 2007.
Edwin Brady. Programming and Reasoning with Algebraic Effects and Dependent Types. In Proceedings of the 18th ACM SIGPLAN International Conference on Functional Programming, ICFP ’13, pages 133–144, New York, NY, USA, 2013. ACM.
N. G. de Bruijn. Lambda calculus notation with nameless dummies, a tool for automatic formula manipulation, with application to the Church-Rosser theorem. Indagationes Mathematicae (Proceedings), 75(5):381–392, January 1972.

Calvin C. Elgot. Monadic Computation and Iterative Algebraic Theories. In H. E. Rose and J. C. Shepherdson, editors, Studies in Logic and the Foundations of Mathematics, volume 80 of Logic Colloquium ’73 Proceedings of the Logic Colloquium, pages 175–230. Elsevier, 1975.
M. Fiore, G. Plotkin, and D. Turi. Abstract syntax and variable binding. In 14th Symposium on Logic in Computer Science, 1999. Proceedings, pages 193–202, 1999.
Sergey Goncharov, Christoph Rauch, and Lutz Schröder. Unguarded Recursion on Coinductive Resumptions. In Proceedings of the 31st Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXI), volume 319 of Electronic Notes in Theoretical Computer Science, pages 183–198. Elsevier, December 2015.
Sergey Goncharov, Lutz Schröder, and Till Mossakowski. Kleene Monads: Handling Iteration in a Framework of Generic Effects. In Alexander Kurz, Marina Lenisa, and Andrzej Tarlecki, editors, Algebra and Coalgebra in Computer Science, number 5728 in Lecture Notes in Computer Science, pages 18–33. Springer Berlin Heidelberg, September 2009. DOI: 10.1007/978-3-642-03741-2_3.

James Gosling, Bill Joy, Guy L. Steele, Gilad Bracha, and Alex Buckley. The Java® language speciﬁcation. Addison-Wesley, Upper Saddle River, NJ, java se 8 edition, 2014.
Mark P. Jones. Functional Programming with Overloading and Higher-Order Polymorphism. In Johan Jeuring and Erik Meijer, editors, Advanced Functional Programming, volume 925, pages 97–
136. Springer, 1995.


Yoshihiko Kakutani. Duality between Call-by-Name Recursion and Call-by-Value Iteration. In Julian Bradfield, editor, Computer Science Logic, number 2471 in Lecture Notes in Computer Science, pages 506–521. Springer Berlin Heidelberg, September 2002. DOI: 10.1007/3-540-45793-3_34.
Fairouz Kamareddine and Alejandro Ríos. A λ-calculus à la de Bruijn with explicit substitutions. In Manuel Hermenegildo and S. Doaitse Swierstra, editors, Programming Languages: Implementations, Logics and Programs, number 982 in Lecture Notes in Computer Science, pages 45–62. Springer Berlin Heidelberg, September 1995. DOI: 10.1007/BFb0026813.
Ohad Kammar, Sam Lindley, and Nicolas Oury. Handlers in Action. In Proceedings of the 18th ACM SIGPLAN International Conference on Functional Programming, ICFP ’13, pages 145–158, New York, NY, USA, 2013. ACM.
Andrew Kennedy. Compiling with Continuations, Continued. In Proceedings of the 12th ACM SIGPLAN International Conference on Functional Programming, ICFP ’07, pages 177–190, New York, NY, USA, 2007. ACM.
Dexter Kozen and Konstantinos Mamouras. Kleene Algebra with Products and Iteration Theories. In Simona Ronchi Della Rocca, editor, Computer Science Logic 2013 (CSL 2013), volume 23 of Leibniz International Proceedings in Informatics (LIPIcs), pages 415–431, Dagstuhl, Germany, 2013. Schloss Dagstuhl–Leibniz-Zentrum für Informatik.
Dexter Kozen and Konstantinos Mamouras. Kleene Algebra with Equations. In Javier Esparza, Pierre Fraigniaud, Thore Husfeldt, and Elias Koutsoupias, editors, Automata, Languages, and Programming, number 8573 in Lecture Notes in Computer Science, pages 280–292. Springer Berlin Heidelberg, July 2014. DOI: 10.1007/978-3-662-43951-7_24.
J. Laird. The Elimination of Nesting in SPCF. In Paweł Urzyczyn, editor, Typed Lambda Calculi and Applications, number 3461 in Lecture Notes in Computer Science, pages 234–245. Springer Berlin Heidelberg, April 2005. DOI: 10.1007/11417170_18.
Paul Blain Levy. Call-by-push-value: Decomposing call-by-value and call-by-name. Higher-Order and Symbolic Computation, 19(4):377–414, December 2006.
John Longley. The recursion hierarchy for PCF is strict. Informatics Research Report EDI-INF-RR- 1421, School of Informatics, University of Edinburgh, July 2015.
Conor McBride and James McKinna. Functional Pearl: I Am Not a Number–I Am a Free Variable. In Proceedings of the 2004 ACM SIGPLAN Workshop on Haskell, Haskell ’04, pages 1–9, New York, NY, USA, 2004. ACM.
Stefan Milius and Tadeusz Litak. Guard Your Daggers and Traces: On The Equational Properties of Guarded (Co-)recursion. Electronic Proceedings in Theoretical Computer Science, 126:72–86, August 2013.
Dominic Orchard and Tomas Petricek. Embedding Effect Systems in Haskell. In Proceedings of the 2014 ACM SIGPLAN Symposium on Haskell, Haskell ’14, pages 13–24, New York, NY, USA, 2014. ACM.
W. W. Tait. Intensional interpretations of functionals of finite type I. Journal of Symbolic Logic, 32(02):198–212, August 1967.


A  Appendix: proofs

We first prove adequacy of fine-grain call-by-value without iteration. The adequacy of FGCBV + sum-based iteration and the adequacy of the language with labelled iteration are then minor modifications. All our adequacy proofs are in the style of Tait [25].
We use the following substitution lemma for both plain FGCBV and FGCBV with sum-based iteration.
Lemma A.1 Assume a substitution σ ∶ Γ′ → Γ and an environment ρ ∈ JΓ).

Let Γ′ ⊢v V ∶ A be a value. Then JV )(x↦Jσ ) )
Let Γ′ ⊢c M ∶ A be a term. Then JM )(x↦Jσ ) )
= JV σ)ρ.
= JMσ)ρ.

The proofs of both substitution lemmas, Lemma A.1 and Lemma 3.5, are routine and we omit them.

Adequacy of FGCBV without iteration
We prove adequacy with the help of the following type-indexed predicate on closed values and terms.
Definition A.2 By mutual induction on the type of V and M , respectively.
when ⊢v V ∶ 1 ∶	P (V )≡ true when ⊢v V ∶ nat ∶	P (V )≡ true when ⊢v V ∶ A + B ∶	P (inl V )≡ P (V )
P (inr V )≡ P (V )
when ⊢v V ∶ A × B ∶	P (⟨V, W ⟩) = P (V )∧ P (W )
when ⊢v V ∶ A → B ∶	P (λx. M )≡ ∀(⊢v W ∶ A)∶ P (W )⇒ P (M [W/x])
when ⊢c M ∶ A ∶	P (M )≡ ∃(⊢v V ∶ A)∶ (P (V ) ∧ M ⇓ return V ∧ JM )∅=inl JV )∅)

Observe that P (M ) implies adequacy of M .
Proposition A.3
If Γ ⊢v V ∶ A, and if for all (x∶B)∈ Γ we have a closed ⊢v σx ∶ B satisfying P (σx),

If Γ ⊢c M ∶ A, and if for all (x∶B) ∈ Γ we have a closed ⊢v σx ∶ B satisfying
x

Proof
By induction on the value or term. Here are some interesting and less interesting cases.
V = x) Then Vσ = σx, which was assumed to satisfy P .
M = return V ) Trivially by induction.
V	λy. M ) We have to show that if v W  A satisfies P , then M σ, W y  satisfies
P . By induction.
) We are allowed to assume	, so the induction hypothe- sis gives us	. We know that   and	reduce to the same terminal. We know		, which we know is equal to JN [σ, (V σ)/x])∅ by the substitution lemma. Now P (N [σ, (V σ)/x]) implies

M = V W ) Similarly.

′	) From the induction, we get	such that	and	′
and	′	. From the derivation rule and the induction, we get	′
such that P (V ′) and N [σ, V /x]⇓ return V ′, and JN [σ, V /x])∅ = inl JV ′)∅.
By the substitution lemma,	, and because we know
JM ′σ)∅ = inl JV )∅, we know that by definition
J(M ′σ) to x. (Nσ))∅ = JNσ)x↦JV )  .
This completes the proof for this case.
M		case V of	) Depending on the type of V , but for every type trivially by case analysis on V σ.
◻
Corollary A.4 All closed values and terms satisfy P.
Adequacy directly follows from this.
Observe that the only cases in which we essentially looked at the normal form of Mσ are return V and M to x. N . Specifically, we did not use the normal form of Mσ in the let case. This means that we can reuse most of the proof for FGCBV with sum-based iteration.

Adequacy of FGCBV + sum-based iteration
Similar structure. We redefine P (M ):
P (⊢c M ∶ A)= ∃(⊢v V ∶ A)∶ ((P (V ) ∧ M ⇓ return V ∧ JM )∅ = inl JV )∅))
∨ (M ⇓̸ ∧ JM )∅ = inr ı))

We have the same proposition as Proposition A.3 in this case:
The case M = return V is still trivial.
For	′	, we have to consider the alternative case that	′	and
JM ′σ)∅ = inr ı. This case is trivial.
For iter, observe that every sequence V1, , Vk in the operational semantics corre- sponds uniquely to a sequence
v0 = JV σ)∅, v1 = JV1)∅, v2 = JV2)∅, ⋯, vk = JVk)∅
for the denotational semantics, and the proof in that case is analogous to the proof for let.
To prove that non-existence of a valid sequence	for the operational se- mantics implies the non-existence of a valid sequence v0, ⋯, vk, we instead prove

the contrapositive. Indeed, we have our initial Vσ already, and by induction on a valid sequence	together with the induction hypothesis, we obtain step by step our sequence V1, ⋯, Vk. So now we also know that iter V, x.M ⇓̸ implies
∅

Adequacy of the language with labelled iteration
Similar structure.
We redefine P (M ) again. Recall that M closed means that Δ; ⋅ ⊢c M ∶ A.

P (M ) ≡( (∃(⊢v V ∶ A)∶ (P (V ) ∧ M ⇓ return V ∧ JM )∅ = return JV )∅))
∨ (∃((x∶B)∈ Δ)∶ ∃(⊢v V ∶ B)∶ (P (V ) ∧ M ⇓ raisex V ∧ JM )∅ = raisex JV )∅))
∨ (M ⇓̸ ∧ JM )∅ = ı) )

We have a proposition analogous to Proposition A.3.
Proposition A.5
If Γ ⊢v V ∶ A, and if for all (x∶B)∈ Γ we have a closed ⊢v σx ∶ B satisfying P (σx),

If	c	, and if we have a substitution	′	′	such that
P (σid(x)) on all identifiers, then P (Mσ).
The additional case for sequencing is trivial.
The case P (raisex V ) is trivial.
The additional case for iteration is analogous.
