Electronic Notes in Theoretical Computer Science 110 (2004) 115–132 
www.elsevier.com/locate/entcs


Parameterized LR Parsing
Peter Thiemann and Matthias Neubauer1 ,2
Institut fu¨r Informatik Universit¨at Freiburg Georges-K¨ohler-Allee 079
D-79110 Freiburg, Germany

Abstract
Common LR parser generators lack abstraction facilities for defining recurring patterns of produc- tions. Although there are generators capable of supporting regular expressions on the right hand side of productions, no generator supports user defined patterns in grammars.
Parameterized LR parsing extends standard LR parsing technology by admitting grammars with parameterized non-terminal symbols. A generator can implement such a grammar in two ways, either by expansion or directly. We develop the theory required for the direct implementation and show that it leads to significantly smaller parse tables and that it has fewer parsing conflicts than the expanded grammar. Attribute evaluation for a parameterized non-terminal is possible in the same way as before, if the semantic functions related to the non-terminal are polymorphic with respect to the parameter.
We have implemented parameterized LR parsing in the context of Essence, a partial-evaluation based LR parser generator for Scheme.
Keywords: LR parser generator, productions, attribute evaluation, polymorphism, partial evaluation.


Introduction
LR parsing [11] is a powerful tool in the toolbox of the language designer. It provides a parsing algorithm that works in linear time for a wide range of context-free grammars. The theory of LR parsing has been explored in numerous works and it has become a standard part of lectures and textbooks on compiler construction [1]. It also forms the foundation of a whole range

1 Email: thiemann@informatik.uni-freiburg.de
2 Email: neubauer@informatik.uni-freiburg.de



1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.06.007


of parser generation tools starting with yacc/bison [10,5], the ideas of which have been adapted to virtually any programming language around.
While there has been some evolution of the tools with respect to modular- ization of parsing actions and integration of the specifications of parsing and scanning, the actual raw matter, the grammar, remains in its original form in the parser specification. Since large grammars may well run into several hun- dred productions, grammar maintenance can become a tedious task. Hence, it is surprising that none of the parser generators has a facility for introducing abstractions over grammar rules.
The main attempt to introduce some abbreviation mechanism into LR grammars is the consideration of regular right-hand sides for rules [3]. How- ever, only a few LR parser generators (e.g., [7]) support regular right hand sides or extended BNF directly. Consequently, typical grammars for LR parser
generators are full of rule groups that implement common grammatical pat- terns. Here are some examples with the number of uses of that pattern from a randomly picked grammar.
lists with separator (seven times)
DelimTypeSchemes	: /* empty */
| NEDelimTypeSchemes ; NEDelimTypeSchemes	: TypeScheme
| NEDelimTypeSchemes ’,’ TypeScheme ;
plain lists (five times plus two non-empty lists)
TypeVars	: /* empty */
| NETypeVars ;
NETypeVars	: TypeVar
| NETypeVars TypeVar ;
optional items (two times)
Imports	: /* empty */
| Imports import typename ;
Often, even the semantic actions coincide or can be made to coincide easily.
Our proposal derives almost directly from these observations. Instead of relying on a fixed set of (regular) operators for use in the right-hand side of grammar rules, we make available an arbitrary, user-definable set of operators
in the form of parameterizable nonterminal symbols. These nonterminals are
used like functions. They can be invoked with actual parameters in the right- hand side of a production. Some care must be taken to restrict the actual parameters suitably, for example, to only one nonterminal or one formal pa- rameter. Without restriction to the actual parameters, we would obtain the notion of a macro grammar which is strictly more powerful than a context-free grammar [4].
With our proposed extension, a grammar writer can write parameterized productions corresponding to the patterns exhibited above once and for all.


Sets of parameterized nonterminals might be collected in modules and reused between grammars.
The following example shows parameterized rules for the grammatical pat- terns identified above.
SepList (Sep, Item)	: /* empty */
| NESepList (Sep, Item) ; NESepList (Sep, Item)	: Item
| NESepList (Sep, Item) Sep Item ;
List (Item)	: /* empty */
| NEList (Item) ;
NEList (Item)	: Item
| NEList (Item) Item ;
Option (Item)	: /* empty */
| Item ;
For the examples above it also makes sense to define generic semantic actions. The only requirement is that these actions are polymorphic with respect to the semantic values of the parameters. Hence, the SepList (Sep, Item) and the List (Item) might both return a value of type List Item and the Option (Item) might return a value of type Maybe Item. Type- specific semantic actions should take place when returning from parameterized nonterminal instantiated with actual nonterminals.
One way of implementing parameterized LR parsing is by separately spe- cializing parameterized nonterminals with respect to all the nonterminals ac- tually instantiated as parameters separately. This specialization terminates trivially because of our restriction on actual parameters. However, it turns out that developing the theory directly for parameterized grammars yields smaller parse tables (since the parameterized parts can be shared) and some- times avoids parsing conflicts.
We have extended the LR(k) parser generator Essence [17] to generate parameterized LR(k) parsers. Initial experiments with the implementation are encouraging.

Overview
Before developing the theory of parameterized LR parsing, we make an excur- sion into formal language theory to introduce the reader to macro grammars and macro languages in Section 2. After defining a suitably restricted notion of macro grammar, Section 3 introduces the basic definitions for parameterized LR parsing. Section 4 defines the parsing algorithm, starting with a non- deterministic specification and then defining the notion of conflict to obtain deterministic parsers. Section 5 is devoted to attribute evaluation. It defines a type system that assigns polymorphic types to parameterized nonterminals. Section 6 describes our implementation of parameterized LR parsing in the


context of Essence, a parser generator for Scheme. Finally, Section 7 considers related work and Section 8 concludes and sketches some future work.

Macro Grammars
To define macro grammars properly, we need some standard definitions from universal algebra. A signature is a pair Γ = (N, a) of a finite set N and an arity function a : N → N, the set of non-negative integers. The set TΓ(X) of Γ-terms with variables X (a set disjoint from N ) is defined inductively by
X ⊆ TΓ(X)
(∀n ∈ N, t1 ... tn ∈ TΓ(X),A ∈ N ) a(A) = n ⇒ A(t1,... , tn) ∈ TΓ(X).
Definition 2.1 A macro grammar is a quadruple (Γ, Σ, P, S) where Γ = (N, a) is a signature with N the nonterminal symbols, Σ is a finite set of terminal symbols, P ⊆ N × TΓ' (Σ ∪ N) is a finite set of macro productions, and S ∈ N with a(S) = 0 is the start symbol. The signature Γ' extends Γ by a binary operator · (concatenation) and a constant ε (empty string).
The productions are subject to the following restriction. If A → w ∈ P
with a(A) = n, then w ∈ TΓ' (Σ ∪ {0,... ,n − 1}).
A macro grammar generates words over the set of terminal symbols using the following derivation relation ⇒ on TΓ' (Σ).
If A → w ∈ P , a(A) = n, t1 ... tn ∈ TΓ' (Σ),
then A(t1,... , tn) ⇒ w[0 '→ t1,... ,n − 1 '→ tn], and
if f ∈ Γ', a(f ) = n, t1 ... tn ∈ TΓ' (Σ), ti ⇒ t' , then f (t1,... , ti,... , tn) ⇒ f (t1,... , t' ,... , tn).
That is, the relation comprises all pairs of terms and it is closed under compat-
ibility. As usual, ⇒∗ denotes the reflexive transitive closure of the derivation relation.

A term w is in the language generated by the grammar if S ⇒∗
w and

w ∈ T·,ε(Σ), which can be considered as an element of Σ∗ in the obvious way.
Usually, the derivation relation is restricted to either substitute nontermi- nals inside-out (IO) or outside-in (OI).
IO reduction A(t1,... , tn) ⇒IO w[0 '→ t1,... , n−1 '→ tn] only if t1,... , tn ∈
T·,ε(Σ) (they do not contain nonterminals) and the relation is closed under
compatibility as before.
OI reduction the reduction rule for ⇒OI is the same as for ⇒, but compat- ibility is restricted to f ∈ {·, ε} (reduction does not proceed into argument positions).


The respective languages are called IO- and OI-macro languages. They have been investigated in detail [6] and we recall some of their properties below. 3
In general, the language generated from a grammar under IO reduction is different from the language generated under OI reduction. (One corre- sponds to call-by-value, the other to call-by-name.)
The classes of IO- and OI-macro languages are incomparable.
The IO- and OI-macro languages are a strict hierarchy of languages be- tween context-free languages and context-sensitive languages [4].
The macro grammars that we have introduced here only correspond to the first level of the hierarchy mentioned above. However, taken in their full
generality, they can describe languages that are not context-free. For example, the following macro grammar generates the set {anbncn | n ∈ N}:
S	→ F (ε, ε, ε)
F (A, B, C) → ABC
F (A, B, C) → F (aA, bB, cC)
Here, we have taken the liberty of naming the parameters of F instead of using the numbering scheme from the definition.
Since we are interested in making abstractions to help define context-free languages only, we need to restrict the general definition.

Definition 2.2 A restricted macro grammar is a macro grammar (Γ, Σ, P, S) where each production has the form A → t1 ··· tm (for m ∈ N) such that, for each 1 ≤ i ≤ m, either ti ∈ Σ or ti = B(s0,... , sl−1) where l = a(B) and, for each 0 ≤ j < l, either sj ∈ N with a(sj) = 0, a nullary nonterminal symbol, or sj ∈ {0,... , a(A) − 1}, a parameter symbol.

Each restricted macro grammar determines a context-free grammar by spe- cialization of the nonterminals with respect to their parameters. The resulting



3 The definition we are giving above is not the one that has been used to obtain the cited results. The original definition considers strings as trees build from monadic operators (the characters) so that standard nonterminals in a context-free grammar are also monadic operators serving as placeholders for trees. In a macro grammar, nonterminals receive additional parameters that range over monadic operators. Adding further parameter sets leads to higher levels in the mentioned hierarchy.


grammar is determined by (N ', Σ,P ', (S, ε)) where
N ' = {(A, A0 ... An−1) | A, A0,... , An−1 ∈ N, a(A) = n, a(Ai) = 0}
⊆ N × N ∗
P ' = {(A, A0 ... An−1) → |t1|A ...A	··· |tm|A ...A	| A → t1 ··· tm ∈ P }
where (for a ∈ Σ, j ∈ N)
|a|A0...An−1	= a
|B(s0,... , sl−1)|A0 ...An−1  = (B, ||s0||A0...An−1 ... ||sl−1||A0...An−1 )
|j|A0...An−1	= (Aj, ε)
||C||A0...An−1	= C
||j||A0...An−1	= Aj
The following lemma makes the connection precise. The language of the specialized grammar corresponds to the language of the restricted macro gram- mar under OI-reduction.
Lemma 2.3 Let M = (Γ, Σ, P, S) be a restricted macro grammar and G = (N ', Σ,P ', S) the corresponding context-free grammar as constructed above.
S ⇒∗	w iff (S, ε) ⇒∗	w.
Proof. We show that each derivation step in M corresponds to a derivation step in G.
Since OI reduction restricts compatibility to the concatenation operator, all terms derivable from S in M can be written in the form s1 ··· sm where,

for each i, either si ∈ Σ or si = Ai(Ai ,... , Ai	i
), for some nullary non-

0	a(A )−1
terminals Ai . (This can be proven by induction on the number of derivation

steps for S ⇒∗
M,OI
s1 ··· sm.)

Hence, the translation function |··· |B... from the construction above is
applicable to all derivable terms where the subscript is empty since no pa-

rameters occur in derivable terms. It remains to see that if S ⇒∗
M,OI
α and

α⇒M,OIα', then |α| ⇒G |α'|. But this is immediate from the construction of the production set P '.	 
Hence, restricted macro grammars with OI reduction define exactly context- free languages. The restriction that actual parameters are either single nonter- minals or formal parameters is less severe than it may appear. Alternatively, the actual parameters may be restricted to either a single formal parameter or an arbitrary word over terminals and (nullary) nonterminals. Such a gram-


mar can be transformed to restricted form as defined above by introducing new nullary nonterminals for each word that appears as an actual parameter. However, definition 2.2 is easier to work with formally.
Example 2.4 A restricted macro grammar for a fragment of the grammar of JavaScript [9] expressions serves as running example. The fragment encom- passes constants, c, array literals enclosed in [ and ], as well as object literals enclosed in { and }. Array and object literals both contain comma-separated lists modeled with the parameterized nonterminals L and N . Object literals consist of key-value assignments as described by nonterminal A. Terminal
symbols are indicated by typewriter font.

Remark 2.5 The construction from Lemma 2.3 does not rely on the fact that parameters are nullary nonterminals. It works for (a suitable notion of) restricted higher-order OI-macro grammars, as well.

Parameterized LR Parsing
Starting from a restricted macro grammar M, we develop the core theory of LR parsing, starting with LR items. For the sake of a name, they are called
parameterized LR items, or short PLR items. All definitions are given relative to the arbitrary, but fixed, grammar M = (Γ, Σ, P, S) with Γ = (N, a). Let further k ∈ N be the lookahead, i.e., the number of characters used to decide
on a parsing action. We assume familiarity with the standard notions of LR
parsing theory.
Definition 3.1 A PLR(k) item is a triple of a production A → t1 ··· tm, an integer i with 0 ≤ i ≤ m, and a string v ∈ Σ∗ with length |v| ≤ k. It is written [A → t1 ··· ti • ··· tm, v], if i > 0, or [A → •t1 ··· tm, v], if i = 0.
The standard theory defines a nondeterministic finite automaton with ε transitions with the set of LR items as states. In the presence of parameters, the automaton construction needs to be generalized to a transition graph with an additional kind of arcs in comparison to a finite automaton. The construction of this graph requires—as in the standard case—the computation of k-prefixes of right-hand sides of rules. However, since right-hand sides can now contain parameters, this computation must take place relative to a parameter instance.



Definition 3.2 A parameter instance is a tuple of nullary nonterminals C = (C0,... , Cm−1).
A parameter instantiation (for C) is a tuple s = (s0,... , sl−1) of nullary nonterminals or parameter references (i.e., integers in the range 0 ... m − 1). The application s(C) of parameter instantiation s to parameter instance
C yields a new parameter instance s(C) = D = (D0,... , Dl−1) where Di = si, if si is a nullary nonterminal, and Di = Cj if si = j, a parameter reference.
The well-known construction of a first-k set for the right-hand side of a production needs to be parameterized with respect to an instance.
Definition 3.3 The set of k-prefixes of an right-hand side term with respect to instance C is defined (with respect to M) by

ﬁrstC(ε)	= {ε}
ﬁrstC(α · β) = {preﬁx (vw) | v ∈ ﬁrstC (α),w ∈ ﬁrstC(β)}
k	k	k	k
ﬁrstC(a)	= {a}
ﬁrstC(i)	=  {ﬁrst()(δ) | Ci → δ ∈ P }


ﬁrstC(B(s)) =  {ﬁrsts(C)(δ) | B → δ ∈ P }
where preﬁxk(a1 ... am) = a1 ... al with l = min(k, m).
Example 3.4 In Example 2.4, the nonterminals N and L occur in two in- stances (C, A) and (C, E). Respectively,
ﬁrst(C,A)(N ) = {c}	ﬁrst(C,A)(L) = {ε, c}
1	1
ﬁrst(C,E)(N ) = {c, {, [}	ﬁrst(C,E)(L) = {ε, c, {, [}
1	1
Definition 3.5 The PLR(k) transition graph has as nodes PLR(k) items and arcs labeled with either a terminal symbol, a nonterminal symbol, a parameter, or a parameter instantiation. First, we need two auxiliary notions.
A path X0 ... Xn with an arc labeled lj between Xj−1 and Xj has parameter instance C with respect to B if either

n = 0 and C = B
n > 0 and either
ln = (s), X0 ... Xn−1 has parameter instance D with respect to B, and
C = s(D), or
ln is not an instantiation and X0 ... Xn−1 has parameter instance C with respect to B.

A node X has parameter instance C if there is a nullary nonterminal B, a 














0

N −> N(0,1) 0 . 1
1
N −> N(0,1) 0 1 .
E

A −> "c" ":" E .

Fig. 1. Transition Graph of Example Grammar
production B → δ ∈ P , a terminal string v, and a path from node [B → •δ, v] to X that has parameter instance C with respect to ().
The transition graph is then defined as the smallest graph G such that the following conditions hold.
[S → •α, ε] is a node of G, if S → α ∈ P (S is the start symbol).
If X = [A → β • aγ, v] is a node of G, then Y = [A → βa • γ, v] is a node of
G and X −a→ Y is a labeled arc in G.
If X = [A → β • B(s1,... , sk)γ, v] is a node of G (for k ≥ 0), B → δ ∈ P , X has parameter instance C, and v' ∈ ﬁrstC (γv), then Y = [B → •δ, v'] is a node of G and X (s1 ,...,sk) Y is a labeled arc in G.
If X = [A → β • B(s1,... , sk)γ, v] is a node of G (for k ≥ 0), then Y = [A → βB(s ,... ,s ) • γ, v] is a node of G and X −B→ Y is a labeled arc in
1	k
G.
If X = [A → β • iγ, v] is a node of G, then Y = [A → βi • γ, v] is a node of

G and X −→i
Y is a labeled arc in G.

If X = [A → β • iγ, v] is a node of G, X has parameter instance C = (C0,... , Cl−1), Ci → δ ∈ P , and v' ∈ ﬁrstC(γv), then Y = [Ci → •δ, v'] is a 
node of G.


Example 3.6 Figure 1 is the transition graph for the example grammar for lookahead k = 0. In the figure, terminal symbols are indicated with double quotes. The lookahead part of the items is omitted (since it is always empty).
The inclusion of C → •, is caused by N → N (0, 1) • 0 1 in instances (C, A) or (C, E). The inclusion of A → •c :E is caused by N → •1 in instance (C, A).
The figure shows that the subgraph for the parameterized nonterminals is shared among their instances.

In traditional LR parsing, the state of a parser is the closure of a set of kernel items. In parameterized LR parsing the state of a parser is a mapping from tuples of nullary nonterminals to a set of PLR(k) items. The notion of closure corresponds to a notion of consistency of a state.

Definition 3.7 A PLR(k) pre-state is a mapping that sends a tuple of nullary nonterminals to a set of PLR(k) items.
A PLR(k) pre-state q is consistent with respect to transition graph G if,
(s)
for all C ∈ dom(q), [A → β • γ, v] ∈ q(C) and [A → β • γ, v] −→ Y in G
implies that Y ∈ q(s(C)).
A PLR(k) state is a consistent PLR(k) pre-state.

The function close maps a PLR(k) pre-state q to the smallest PLR(k) state containing q. The close function performs all instantiation of parameters by enforcing the consistency condition. This happens to be the only place in a
PLR parser, where instantiation plays a role!
The goto function implements a state transition in the parser. It maps a PLR(k) pre-state and a grammar symbol to a PLR(k) state.

goto(q, a) = close  C '→ {[A → βa • γ, v] | [A → β • aγ, v] ∈ q(C)}
C ∈ dom(q),
goto(q, B) = close	C'→ {[A → βB(s) • γ, v] | [A → β • B(s)γ, v] ∈ q(C)}

∪ {[A → βi • γ, v] | [A → β • iγ, v] ∈ q(C), Ci = B}
  C ∈ dom(q),

Example 3.8 Continuing the running example further, the initial state of the parser is the closure of the PLR(0) pre-state {() '→ {[S → •E]}}, that is
() '→ {[S → •E], [E → •c], [E → •{L(C, A)}], [E → •[L(C, E)]]}

Applying the goto function with terminal { as argument yields ()	'→ {[E → { • L(C, A)}], [A → •c: E]}
(C, A) '→ {[L → •], [L → •N (0, 1)], [N → •1], [N → •N (0, 1) 0 1]}
For comparison, the transition with terminal [ yields ()	'→ {[E → [ • L(C, E)]]}
(C, E) '→ {[L → •], [L → •N (0, 1)], [N → •1], [N → •N (0, 1) 0 1]}
Hence, the parsing state becomes modular with the parameterized part being reusable (but requiring a two-stage mapping to compute goto).

PLR(k) Parsing Algorithm
We adhere to the functional description of LR parsing given by Leermakers
[13] and exploited in earlier work by one of the authors [18]. The idea of the functional description is that a parser is considered as a nondeterministic function mapping an input string to a pair of a PLR(k) item and a new string. The specification of a parser is thus
([A → β • γ, v], w'') ∈ parse(w)	iff	w = w'w'' ∧ γ ⇒∗ w' ∧ preﬁx (w'') = v
k

Nondeterministic Parsing
In our specific case, the parser function depends on a PLR(k) state and— instead of dealing with nondeterministic functions—it will return a set of pairs of PLR(k) item and unconsumed input. Interestingly, the main parser function does not change with respect to the previous formulation [17].
[q] (w, c1 ... cnactive(q)) = 
letrec
c0(X, w) = let q' = goto(q, X) in [q'](w, c0c1 ... cnactive(q'))
in   (	{c|α|(A, w) | [A → α•, v] ∈ q, preﬁxk (w) = v}
∪ {c0(a, w') | w = a · w',a ∈ nextterm(q)})
The parsing function [q] has two parameters, the input string and a list of continuations. Each continuation corresponds to a function that shifts on a nonterminal whenever a reduction occurs. Calling the continuation performs the reduce operation: “pop the right-hand side of the production from the parse stack and then push the state corresponding to the left-hand side.” For


readers used to the stack-based implementation, it is probably best to regard the list c1 ... as a representation of the topmost items of the parse stack.
The function c0 performs a shift action by pushing the continuation corre- sponding to the current state (itself) on the list of continuations and changing the state according to the symbol X.
The auxiliary functions need to be extended to PLR(k) states. The func- tion nactive : PLR-state → N determines the maximum number of continua- tions required to perform a reduce action in any state reachable from state q.
It is the maximum number of symbols to the left of the dot in any item in q.

nactive(q) = max{|β| | C ∈ dom(q), [A → β • γ, v] ∈ q(C)}
The other auxiliary function nextterm : PLR-state → P(Σ) yields the set of terminal symbols immediately to the right of the dot in any item in a state.

nextterm(q) = {a | C ∈ dom(q), [A → β • aγ, v] ∈ q(C)}
Deterministic Parsing
The above, nondeterministic parsing function performs generalized LR pars- ing [12,21,15] because it explores all parsing alternatives “concurrently.” To obtain a deterministic parsing function, states with “parsing conflicts” need to be identified and ruled out. As with standard LR parsing, there are two kinds of conflicts, a shift-reduce conflict or a reduce-reduce conflict.
Definition 4.1 A PLR(k) state q has a shift-reduce conflict if there are B, C ∈ dom(q) (not necessarily different) such that [A → β • aγ, u] ∈ q(B) and [B → δ•, v] ∈ q(C) with ﬁrstB(aγu) = v.
A PLR(k) state q has a reduce-reduce conflict if there are B, C ∈ dom(q) (not necessarily different) such that [A → β•, v] ∈ q(B) and [B → δ•, v] ∈ q(C) with A → β different from B → δ.
A restricted macro grammar is a PLR(k) grammar if the states extracted
from the grammar’s transition graph are all free of conflicts.
While the generalized shift-reduce conflict is identical to the standard no- tion, the reduce-reduce conflict turns out to be less restrictive. Here is an example that exhibits the difference with respect to the expanded grammar
from Lemma 2.3. Let G be given by the productions
S → L(A),S → L(B),L → ε, L → 0 L(0),A → a, B → b
where the parameterized nonterminal L generates lists. (The example ab- stracts from a situation where two alternative ways of writing the items of a parameter list.) The expanded grammar has productions
S → LA,S → LB, LA → ε, LA → A LA, LB → ε, LB → B LB,A → a, B → b


and the (standard LR) closure of {[S → •LA], [S → •LB]} has a reduce-reduce conflict between [LA → •] and [LB → •] already (ignoring the shift-reduce conflict of either item with [A → •a] and [B → •b]):
S → •LA,S → •LB,
LA → •, LA → •A LA, LB → •, LB → •B LB,A → •a, B → •b
However, the PLR(0) closure of {() '→ {[S → •L(A)], [S → •L(B)]}} is
()	'→ {[S → •L(A)], [S → •L(B)], [A → •a], [B → •b]}
'→ {[L → •], [L → •0 L(0)]}
'→ {[L → •], [L → •0 L(0)]}
and—according to our definition—there is no reduce-reduce conflict because the underlying production of the reduce items is L → ε in both cases.
Apart from the different definition of conflict, the remaining notions of
conflict resolution go through as in the standard case.

Attribute Evaluation
As with standard LR(k) parsers, a PLR(k) parser can evaluate all attributes occurrences in a parse tree of an S-attributed grammar during parsing. The novelty is that attributes of parameterized nonterminals should have poly- morphic types. To see that, let’s reconsider the grammar fragment for comma separated lists from the introduction, equipped with generic semantic actions:
SepList (Sep, Item)
: /* empty */	{ s1 ()	}
| NESepList (Sep, Item)	{ s2 ($1) } ; NESepList (Sep, Item)
: Item	{ n1 ($1) }
| NESepList (Sep, Item) Sep Item	{ n2 ($1, $2, $3) } ;
In fact, Sep and Item may be regarded as type variables so that the generic type for NESepList (Sep, Item) has the form ∀αβ.τ . This observation may be phrased as a type system for semantic actions of parameterized grammars. It relies on an unspecified, external typing judgment ∆ ▶' e : τ which relates a typing environment ∆ and an expression e to its type τ . The only assumptions about this type system are that types may contain type variables and ∀- quantification is permitted at the top-level.
To derive the type of the right-hand side w{e} of a rule with semantic action e, as captured by judgment Θ ▶ w{e} : τ requires two premises. First, A typing environment ∆ is created by the judgment Θ ▶i w ⇒ ∆ from the typing environment for nonterminals, Θ, a position in the right-hand side of a
production, i, and a right-hand side of a production, w. Second, the right-hand


side is the type of the semantic action in typing environment ∆ as derived by the external judgment ∆ ▶' e : τ .
Θ ▶1 w ⇒ ∆	∆ ▶' e : τ

Θ ▶ w{e} : τ
The next set of rules specifies the construction of the variable environment for typing the semantic action. It assumes that the action refers to attributes of right-hand side symbols by a positional notation, $i.


Θ ▶i ε ⇒ ∅ 
Θ ▶i+1 w ⇒ ∆

Θ ▶i aw ⇒ ∆, $i : Σ 
Θ ▶i+1 w ⇒ ∆	Θ(j) = τ Θ ▶i jw ⇒ ∆, $i : τ

Θ ▶i+1 w ⇒ ∆	Θ(B) = ∀α1 ... αm.τ	(∀1 ≤ j ≤ m) Θ ▶ sj : τj

Θ ▶i B(s1 ... sm)w ⇒ ∆, $i : τ [αj '→ τj]
The next rule specifies an auxiliary judgment used to infer the instantiation for a parameterized nonterminal.

Θ(j) = τ Θ ▶ j : τ
Θ(B) = τ

Θ ▶ B : τ

The final group of rules collects the types from the productions. The first rule collects the types of all right-hand sides, makes sure that their types are all equal, and that the resulting type is polymorphic with respect to the parameters of the left-hand side nonterminal.
a(A) = m	Θ, 1 : α1,... ,m : αm ▶ wi{ei} : τ
Θ(A) = ∀α1 ... αm.τ	(∀1 ≤ j ≤ m) αj ∈/ free(Θ, α1,... , αj−1) Θ ▶ A → w1{e1} | ... | wn{en}
Finally, the productions in a grammar must be mutually consistent.
dom(Θ) = N	(∀p ∈ P ) Θ ▶ p

Θ ▶ P

Implementation
We have implemented parameterized LR parsing in the context of Essence, a partial-evaluation based LR parser generator for Scheme [17].
Essence differs from most other parser generators, as for example bison [5] or yacc [10], both in the way it is built and it is used. Instead of testing


and debugging a parser running several edit–generate–compile–test cycles, the user solely works with a generic parser taking both a grammar and an input stream as input to develop the final grammar. Hence, no generation and recompilation is necessary to try out changes to a grammar. In the end, an automatic program transformation called partial evaluation produces a generated parsers from the general parser [16,18]. This guarantees consistency and ensures correctness. Nonetheless users of Essence need not to have any special knowledge about partial evaluation techniques.
Integrating parameterized LR parsing into Essence amounts to adapting its general parser to parameterized LR parsing. A parser generator for PLR pars- ing results again by applying a partial evaluation framework to the adapted general parser with respect to PLR(k) grammars the same way it is done for the original Essence parser.
The general parser of Essence is a straightforward reformulation of a func- tional description of general LR parsers in the Scheme programming language [13,18]. The integration of PLR(k) parsing resulted in implementing an addi- tional representation for PLR grammars, for parse items, and in implementing
adapted versions of ﬁrst, goto, nactive and nextterm. The rest of the pars-
ing infrastructure of Essence, as for example the main parser function, stays unchanged.

Related Work
Parser combinators [20,8] are a highly flexible way of specifying parsers in functional programming languages. In particular, the use of polymorphic functions and parameterized parsers is a natural way of structuring code with parser combinators. In contrast to the present work, they perform predictive or top-down parsing. Recent advances [19] have widened their scope consider- ably with respect to earlier, inefficient proof-of-concept implementations. The present work makes some of the polymorphism and flexibility that make parser combinators attractive available to the construction of LR parsers.
The syntax definition formalism SDF [22] supports arbitrary context-free grammars and creates GLR parsers [12,21,15] for them. For convenience, right-hand sides may contain an extended set of regular operators. An SDF specification also defines a lexical syntax. SDF includes an abbreviation mech- anism which works by expansion.
Extensions of LR parsing with regular operators on the right-hand sides of productions have been explored by Chapman [2]. He extends the stan-
dard item set construction with new cases for these operators. However, the attached semantic actions are fixed to e.g. list construction.


The compiler construction toolkit Eli [7] also constructs bottom-up parsers from grammars with regular right-hand sides. The regular operators are ex- panded in a preceding grammar transformation. Extended BNF productions are more often supported by LL parser generators [14].
One reviewer mentioned van Wijngaarden (or W-) grammars [23], a Turing- complete parameterized grammar formalism used in the definition of AL- GOL 68. Conceptually, W-grammars consist of two-levels. The first level defines context-free languages of interpretations of grammar symbols. These interpretations are used to generate the actual grammar productions by substi- tution into rule templates. However, W-grammars are a conceptual modeling tool and are not geared at generating efficient recognizers. Rather, they have been designed for describing context-sensitive aspects of programming lan- guages. They lack the conciseness and ease of use of direct parameterization, which is a familiar concept from programming practice.

Conclusion and Future Work
Restricted macro grammars are an extension of context-free grammars that enables modular grammar construction from user-definable, parameterized nonterminal symbols. Restricted macro grammars recognize exactly context- free languages and are amenable to linear-time parsing and evaluation of L- attributions using an extension of LR parsing. They are particularly suited for languages that support parametrically polymorphic function because parame- terized nonterminals require such functions for specifying the semantic actions. Due to polymorphism, they avoid some reduce-reduce conflicts. Polymorphic attributions may also have applications in conflict avoidance for ordinary LR parsers.
In the present formalization, the lookahead sets for different parameter instances are simply merged. A refined formulation might consider conditional items where the lookahead is bound to specific parameter instantiations. This refinement would enable the closure operation to omit unreachable lookahead
strings and avoid conflicts between otherwise unrelated instances.
A more direct implementation, factorizing the table construction and the goto function, should be investigated. We hope that this would yield a more effective size reduction of the parse tables, but this is subject to further study.
A formal notion of type soundness for the type system in Section 5 should be defined and type inference for the system should be investigated.
Another avenue for future work would be to work out a notion corre- sponding to LALR parsing. It might also be worth considering the present framework for parsing OI-macro languages in their full generality. In that


case, it would not be possible to precompute the transition graph, rather the graph would evolve according to the input parsed.

References
A. V. Aho, R. Sethi, and J. D. Ullman. Compilers Principles, Techniques, and Tools. Addison- Wesley, 1986.
N. P. Chapman. LR parsing: theory and practice. Cambridge University Press, Cambridge, UK, 1987.
K. Culik and R. Cohen. LR-regular grammars—an extension of LR(k) grammars. J. Comput. Syst. Sci., 7:66–96, 1973.
W. Damm. The IO- and OI-hierarchies. Theoretical Computer Science, 20(2):95–207, May 1982.
C. Donnelly and R. Stallman. Bison—The YACC-compatible Parser Generator. Free Software Foundation, Boston, MA, Nov. 1995. Part of the Bison distribution.
M. J. Fischer. Grammars with macro-like productions. In IEEE Conference Record of 9th Annual Symposium on Switching and Automata Theory, pages 131–142, 1968.
R. W. Gray, V. P. Heuring, S. P. Levi, A. M. Sloane, and W. M. Waite. Eli: A complete, flexible compiler construction system. Communications of the ACM, 35(2):121–130, Feb. 1992.
G. Hutton and E. Meijer. Monadic parsing in Haskell. Journal of Functional Programming, 8(4), 1998.
E.   International.	Ecmascript language specification. http://www.ecma-international.org/publications/files/ECMA-ST/Ecma-262.pdf , Dec. 1999. ECMA-262, 3rd edition.
S. C. Johnson. Yacc—yet another compiler compiler. Technical Report 32, AT&T Bell Laboratories, Murray Hill, NJ, 1975.
D. E. Knuth. On the translation of languages from left to right. Information and Control, 8:607–639, 1965.
B. Lang. Deterministic techniques for efficient non-deterministic parsers. In ICALP1974, pages 255–269, 1974.
R. Leermakers. The Functional Treatment of Parsing. Kluwer Academic Publishers, Boston, 1993.
T. J. Parr and R. W. Quong. ANTLR: A predicated-LL(k) parser generator. Software— Practice & Experience, 25(7):789–810, July 1995.
J. Rekers. Parser Generation for Interactive Environments. PhD thesis, University of Amsterdam, 1992.
M. Sperber and P. Thiemann. The essence of LR parsing. In W. Scherlis, editor, Proc. ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation PEPM ’95, pages 146–155, La Jolla, CA, USA, June 1995. ACM Press.
M.	Sperber
and P. Thiemann. Essence—User Manual. Universit¨at Freiburg, Freiburg, Germany, Feb. 1999. Available from ftp://ftp.informatik.uni-freiburg.de/iif/thiemann/essence/ .
M. Sperber and P. Thiemann. Generation of LR parsers by partial evaluation. ACM Transactions on Programming Languages and Systems, 22(2):224–264, Mar. 2000.


S.	D.	Swierstra.	Fast,	error	repairing	parsing	combinators.
http://www.cs.uu.nl/groups/ST/Software/UU_Parsing/ , Aug. 2003.
S. D. Swierstra and L. Duponcheel. Deterministic, error-correcting combinator parsers. In
J. Launchbury, E. Meijer, and T. Sheard, editors, Advanced Functional Programming, volume 1129 of Lecture Notes in Computer Science, pages 184–207. Springer-Verlag, 1996.
M. Tomita. Efficient Parsing for Natural Languages. Kluwer Academic Publishers, 1985.
M. van den Brand and P. Klint.	ASF+SDF meta-environment user  manual.
http://www.cwi.nl/projects/MetaEnv/meta/doc/manual/user-manual.html , July 2002.
A. e. van Wijngaarden.  Report on the algorithmic language ALGOL 68.  Numerische Mathematik, (14):79–218, 1969.
