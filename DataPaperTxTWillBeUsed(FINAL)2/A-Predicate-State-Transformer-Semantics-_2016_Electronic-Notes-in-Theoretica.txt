Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 325 (2016) 185–200
www.elsevier.com/locate/entcs

A Predicate/State Transformer Semantics for Bayesian Learning
Bart Jacobs1	Fabio Zanasi2
Institute for Computing and Information Sciences (iCIS) Radboud University Nijmegen
The Netherlands

Abstract
This paper establishes a link between Bayesian inference (learning) and predicate and state transformer operations from programming semantics and logic. Specifically, a very general definition of backward inference is given via first applying a predicate transformer and then conditioning. Analogously, forward inference involves first conditioning and then applying a state transformer. These definitions are illustrated in many examples in discrete and continuous probability theory and also in quantum theory.
Keywords: Inference, learning, Bayes, Kleisli category, effectus, predicate transformer, state transformer


Introduction
Increasingly probabilistic programs are used to describe problems in Bayesian infer- ence ([2]), see e.g. [10,19,4,1,21]. The term ‘inference’ is used for what is informally best called: learning 3 . Learning involves updating one’s knowledge, in the light of certain evidence, typically given via the validity of a certain predicate (which may be a fuzzy one). In this situation one represents knowledge in terms of likelihoods, via a probability distribution (in the discrete case) or a probability measure (in the continuous case). Updating one’s knowledge then involves computing a conditional distribution/measure.
Now that the overlap between the (probabilistic) programming community and the Bayesian community is growing, a merging of concepts and techniques can be expected. This paper is an example. It shows how the notions of predicate and state transformer from programming languages semantics ([7]) can be used in precisely

1 Email: bart@cs.ru.nl
2 Email: fzanasi@cs.ru.nl
3 The Bayesian community associates learning to various tasks. A prominent learning task is finding out what the topology of a network is, based on (in)dependence relations, starting from a big joint distribution.

http://dx.doi.org/10.1016/j.entcs.2016.09.038
1571-0661/© 2016 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

defining two fundamental notions of learning: backward and forward inference. A conditioning operation, which makes a certain distribution/measure depend on a predicate, also plays a role. In a nutshell, the correspondence can be summarised as follows.



Predicate Transformer and then Conditioning

 

Backward
~  Inference J


Conditioning and then State
 Transformer

 

Forward
~  Inference J


This connection hopefully works as an Aha Erlebnis, giving a sudden insight. In- deed, predicate transformers work backwards, from predicates on post-states to predicates on pre-states. This is precisely what is at stake in backward inference — as we will demonstrate. Similarly, state transformers work in a forward direction, which is what happens in forward learning.
Strictly speaking, the main contribution of this paper is only one definition, namely of (backward and forward) inference, see Definition 2.1. Contrarily to tra- ditional approaches, our formulation is not tied to the probabilistic setting, but works in the context of any effectus, that is a categorical notion embracing a wide spectrum of computational models, both classical, probabilistic and also quantum, see [11,5]. Within the theory of effectuses, predicate and state transformers are well-defined, and predicates (or effects) and states can be nicely organised in state- and-effect triangles, which connect predicates and states via a (dual) adjunction (1), see also [12]. Intriguingly, these triangles correspond to what physicists call the du- ality between states and effects, referring to the opposite directions in the work of Schr¨odinger and Heisenberg on quantum foundations. Within this effectus context one can also describe normalisation and conditioning of states in an abstract manner (see [13,5]). Therefore, we believe effectuses form the right setting for developing a general approach to inference.
Still, precisely recognising what is what in this setting is a subtle matter. For instance, what is a predicate, at the abstract level? Traditionally in probability theory ‘events’ are used as predicates. Formally they are subsets of the sample space, corresponding to ‘sharp’ predicates on this space. More generally, ‘fuzzy’ predicates are considered; they are functions taking values in the unit interval [0, 1]. The sharp predicates can then be characterised as the ones taking values in the Boolean subset {0, 1} ⊆ [0, 1]. In discrete probability every distribution is at the same time a fuzzy predicate. This blurs the picture — the confusion between states and predicates is particularly evident in Bayesian network representations, where nodes may play both roles. In continuous probability there is, in principle, a clear distinction between states (probability measures) and predicates (measurable functions to [0, 1]). But again, things easily get mixed up, when a state/measure is given by a probability distribution function (pdf), which looks very much like a predicate. The framework of effectus theory helps in this respect, since it gives a clear distinction between states, as maps of the form 1 → X, and predicates, as

maps X → 1 + 1. Only when this perspective is recognised, the role of predicate and state transformers becomes clear. It is for this reason that we think it is justified to dedicate an entire paper to elaborating and explaining a single definition.
The paper is organised as follows. We first introduce the notions of backward and forward inference in terms of predicate and state transformers and show some basic properties. Then, we concentrate on illustrating the impact and power of our definition in many situations. We show what our abstract setting translates to in discrete and continuous probability theory and also (briefly) in quantum theory. We elaborate many examples of computations of how inference works, and what it produces. Of special interest is the application of our definition of inference in Bayesian networks. It is shown that the forward/backward distinction can be used flexibly, and can describe what inference means at different points in the network.
Backward and forward inference, abstractly
In this section we describe our abstract set up for inference, both in a backward and forward manner. This works in the setting of an effectus: briefly, this is a category with finite coproducts (+, 0) and a final object 1, such that certain diagrams are pullbacks and certain maps are jointly monic. By virtue of these basic requirements, an effectus is able to capture some basic aspects of quantum computation, with probabilistic computation as special case, see [11,5].
States in an effectus C are maps of the form 1 → X and predicates are maps X → 2 = 1 + 1. The set of states Stat(X) of an object X form a convex set, and the set of predicates Pred(X) on X form an effect module. States and predicates give rise to a ‘state-and-effect triangle’ of the form:

op
,¸¸¸
Pred=Hom(−,2)
C
zC+onv
Stat=Hom(1,−)

(1)

We refer to [11] for details about effect modules and convex sets. In the current setting we need the predicate transformer f∗ = Pred(f ) and state transformer f∗ = Stat(f ) operations associated with a map f : X → Y in the base category C. They are given by pre- and post-composition:


f∗=(−)◦f
Pred(X)	Pred(Y )
Stat(X)
f∗ =f◦(−)
 St¸at(Y )

In concrete examples of effectuses states are distributions — in the Kleisli category of the distribution monad — or probability measures — in the Kleisli category of the Giry monad — or just states — in C∗- or W∗-algebras. We will understand states as descriptions of our state of knowledge. Given a predicate p and a state ω on the same object X two definitions are of interest:
ω |= p := p ◦ ω	and	ω|p,  the conditional state on X.	(2)

The expression ω |= p describes the validity, or expected value, of the predicate in the state ω. Typically its value is in the unit interval [0, 1]. If this validity ω |= p is non-zero, then the conditional state ω|p exists. It is the updated state of knowledge after observing ‘evidence’ p. In each of the above concrete examples of states we can define such conditional states (see below). In fact, conditioning can be defined abstractly in the theory of effectuses, using ‘assert’ maps, see [5, Example 58], but we don’t need such a level of abstraction here.
We now distinguish two forms of inference (learning).
Definition 2.1 Backward inference ω|f∗ (q) involves first applying a predicate trans- former and then computing a conditional. This applies in situations of the form:


1 	ω	 X¸
f	 Y ¸
q	 1 +¸1	(3)

More explicitly, one first applies the predicate transformer f∗ to the predicate q on
Y , and then computes the backwardly inferred conditional state ω|f∗ (q) on X.
Forward inference f∗(ω|p) is first computing a conditional and then applying a state transformer. This works in a situation:


1 	ω	 X¸
p
  
1+1 
f	 Y ¸

(4)

In this case the conditional state on X is ω|p, and applying the state transformer
f∗ gives the forwardly inferred state f∗(ω|p) on Y .
In the trivial case where the map f is the identity there is no difference between backward and forward inference. Inference then just involves updating a state (of knowledge). Notice that in backward inference we use a predicate on the codomain of the map f , namely q, and update our knowledge about the state on f ’s domain
X. In forward inference we use a predicate on the domain of f , namely p, and use it to infer more about the state on f ’s codomain Y . This may also be called ‘evidence propagation’.
In the situation (4) we have the following Galois style equalities for validity:
"ω |= f∗(q) = q ◦ f ◦ ω = "f∗(ω) |= q .

In general, there are very few ‘nice’ algebraic properties for conditional states. For instance, we do have f∗ ω|f∗ (q) = f ◦ ω |q, but only for the special case where the map f is ‘pure’. The latter means for instance in a Kleisli category that the map comes from the underlying category.
In the remainder of this paper we shall illustrate these forms of inference via several examples, involving various kinds of computation, and including Bayesian networks where the above map f in (3) and (4) arises from a graph (network of conditional probability tables). The composition notation ‘◦’ used above looks de- ceptively simple, but will each time be interpreted differently in different categories.

This leads to various concrete forms of inference which are all instances of the same pattern.


Inference with discrete probability
We shall write D for the discrete probability monad on the category Set of sets and functions. The set D(X) contains the finite discrete probability distributions ω over X which we write as formal convex combinations:


ω = r1
|x1⟩ + ··· + rn
|xn
⟩	where	x1,..., xn ∈ X
r1,..., rn ∈ [0, 1] with
Σi ri = 1.


The ‘ket’ notation |x⟩ is meaningless syntactic sugar, used to distinguish elements x ∈ X from their occurrence in such formal convex sums. Notice that such ω ∈ D(X) can be identified with functions ω : X → [0, 1] with finite support supp(ω)= 
{x ∈ X | ω(x) /= 0} and with  x∈X ω(x) = 1. This function-description is often more convenient.
We shall write Kl(D) for the Kleisli category of the distribution monad D. Its objects are sets X, and its morphisms X → Y are stochastic matrices, in the form of functions X → D(Y ).
We will see later (in Section 3.1) how Bayesian networks can be seen as certain arrows of Kl(D). For this interpretation, it is of importance that Kl(D) forms a symmetric monoidal category, with the following ingredients. The monoidal product
⊗ is defined on objects as the cartesian product × in Set, with unit 1. On arrows
f : A → X and g : B → Y , it is defined as

f ⊗ g :=  A × B  f×g  D¸(X) × D(Y )  dst  D¸(X × Y ) 


where the map dst sends a pair (ρ, σ) ∈ D(X)×D(Y ) to the distribution in D(X×Y ) given by (x, y) '→ ρ(x) · σ(y). The symmetry twX,Y on X ×Y is the lifting to Kl(D)

of the isomorphism X ×Y −=→ Y are clear from the context.
Y ×X in Set; we will omit the subscript when X and

We now turn to the description of states and predicates in Kl(D). Notice that states ω : 1 → X in Kl(D) can be identified with distributions ω ∈ D(X). Since D(2) ∼= [0, 1] we can identify predicates X → 2 = 1 + 1 in Kl(D) with functions X → [0, 1], that is, with fuzzy predicates. We will often make both identifications when emphasising the role of states and predicates in a computation.
Given a Kleisli map f : X → D(Y ), a state ω ∈ D(X) and a predicate q ∈ [0, 1]Y we have the following descriptions for state and predicate transformation. They

arise from unravelling (Kleisli) composition in Kl(D).
f∗(ω) := Σ" Σx∈X f (x)(y) · ω(x) y 
f∗(q)(x) :=	f (x)(y) · q(y).	(5)
y∈Y

For a distribution ω ∈ D(X) and a predicate p ∈ [0, 1]X on the same set X we define the validity ω |= p in [0, 1] as:

ω |= p := Σx∈X ω(x) · p(x).	(6)

If this validity ω |= p is non-zero, then the conditional state ω|p ∈ D(X) is given as formal convex sum:

ω|p
:=	ω(x) · p(x) x .
x∈X	ω |= p

(7)

We shall describe a familiar medical test example in the current setting. We use the following notational convention. We write a letter D for a certain disease, which is represented as a two-element set 2D = {d, d⊥}, where the element d represents occurrence of the disease, and d⊥ represents non-occurrence. A distribution over 2D is, e.g., of the form 1 |d⟩ + 3 |d⊥⟩, when describing that the disease occurs with
probability 1 . Similar we write 2T for a (positive) test, where 2T = {t, t⊥}. For each such set 2A = {a, a⊥} we write A?: 2A → [0, 1] for the sharp predicate given by A?(a)=1 and A?(a⊥)= 0.
Consider the following situation in the Kleisli category Kl(D).


,,⎨

		

1

100
|d⟩ + 100 |d ⟩

,, s(d⊥) = 1 |t⟩ + 19 |t⊥⟩ .

The state ω describes the a priori probability of 1% that someone has the disease. The map s describes the sensitivity of the test: when someone has the disease, the test will be positive in 90% of the cases, and when someone does not have the disease there is still a 5% chance that the test is positive.
A basic question is: what is the chance that I have the disease if I test positive? We formalise this by adding the predicate T ?: 2T → [0, 1], which expresses that there is a positive test. We then compute consecutively the predicate s∗(T ?): 2D → [0, 1], the validity ω |= s (T ?) and the inferred conditional state ω|s∗ (T ?). We use

formulas (5), (6), and (7) for backward inference from Definition 2.1:


s∗(T ?)(d) =  9
 9 10
s∗(T ?)(d⊥) =  1
 1 20
· 1+ 10 · 0

· 1+ 20 · 0

ω |= s∗(T ?) =  1  ·  9
+  99	 1
(8)

=  9  +  99 

1000
 117
2000
2000

ω|s∗ (T ?) = 2000 · "  1  ·  9 |d⟩ +  99
·  1 |d⊥⟩ 

=  18 |d⟩ +  99 |d⊥⟩ .

Hence after a positive test the chance that I have the disease is  18 ∼ 15%. This is
an instance of backward inference, where an observation on the codomain (the test outcome) changes the state of knowledge about the domain (the disease occurrence). Of course, standard Bayesian methods will arrive at the same outcome. The point is that we can describe these methods here in a uniform, abstract manner via calculations in (Kleisli) categories.
We briefly describe a forward example. Suppose that I know that the chance of having this disease is half as likely for me, for instance because I belong to a particular age group. We model this via the predicate p : 2D	[0, 1] given by p(d)= 1 and p(d⊥) = 1. We would like to learn what the probability is of getting a positive test under these circumstances.
We take a step back, and ask ourselves: what is the probability of getting a positive test in general — without the adapted likelihood. This probability is computed via the state transformer s∗ from (5) — that is, via Kleisli composition in Kl(D) as:


s∗(ω) = ( 1
 9 +  99
·	) |t⟩ +( 
 1 +  99
·	) |t ⟩

=  117 |t⟩ + 1883 |t⊥⟩ .

For forward inference we first compute the conditional state ω|p and then push it forward to a state s∗(ω|p) on 2T .
ω |= p =  1  · 1 +  99 · 1

100  2
199
200
100

ω|p = 200 · "  1  · 1 |d⟩ +  99
· 1 |d⊥⟩ 

=  1  |d⟩ + 198 |d⊥⟩

199
s∗(ω|p) = ( 1
199
 9 + 198 ·  1 ) |t⟩ +( 1
 1 + 198 · 19 ) |t⊥⟩

=  216 |t⟩ + 3764 |t⊥⟩ .

Hence, upon knowing that I have a reduced (halved) risk, my chance of getting a
positive test goes down from  117 ∼ 5.8% to	∼ 5.4%. The impact is limited,
3980
because I only have a very small chance of having the disease in the first place —
and the false positive probability of the test is 5%.
By imposing the predicate p on the disease state ω we adapt the influence of the state ω on the outcome. This may be useful for counterfactual reasoning, see [17]. In this way one can test to what extend a conclusion depends on certain initial states. For instance, if a particular conclusion is reached starting in a state where 70% of the participants is female, then by imposing an additional predicate on this state that changes the gender percentage, one can check if the same conclusion is reached.









Inference in a Bayesian network


Bayesian networks are graph-like structures, widely-adopted for the representation of probabilistic relationships between random events. They are usually depicted as directed acyclic graphs with nodes standing for random variables and edges indicat- ing causal dependencies between them. Inference tasks are one of the fundamental uses of these networks. They are typically performed by updating a single node- event and then propagating the information to the rest of the network. Computing the inference typically goes through a repeated use of the Bayes’ rule for conditional probability, see e.g. [16,18,17,2].
In this subsection we show how our abstract account of inference instantiates to the case of Bayesian networks. Our approach predicts the same outcomes as traditional Bayesian inference, but also improves it in two ways. First, it is more flexible and compositional, as it allows to focus on single nodes in the same way as on bigger portions of the network, with the same methodology. Second, it is more structured, in the sense that the computations that would require the use of Bayes’ rule are carried out by the categorical machinery — essentially, by composition of arrows in a category.
In order to illustrate this picture, we will use as a running example the situation of a scientist that wants to publish a paper at a conference. The specification for the corresponding Bayesian network consists of a graph together with conditional

probability tables.
,
Time
z


ell Written


itive Reviews
  


,
r ,z˛	 ,
˛A  cceptance




(9)

,	, ,	vz
,  , z	,	J

Skill	 ¸	Results
J	J
  ¸PC Member
Championing
	J










The initial conditions of the example estimate whether there is enough time available to prepare the paper (the variable T ) and whether the scientist is sufficiently skilled to do the necessary research (S). The results that the scientist is able to obtain (R) depend both on the time and the skill, while how well the paper reads only depends on the time. Both results and readability have an influence on whether the reviews will be positive (P ), but results will be more relevant. Similarly, these two factors may lead a PC member to enthusiastically endorse the paper (M ), independently of what the reviewers say, although this possibility is quite rare. Finally, acceptance
(A) is influenced by the reviews and by the possible endorsement of a PC member.
In order to study inference in this example, we first need to formulate it in more categorical terms. We shall express our Bayesian network (9) as an arrow in the Kleisli category Kl(D) of the distribution monad D. First, each node N of the graph, say with k incoming edges from nodes N1, N2,..., Nk, is associated with an arrow N : 2k → 2 in Kl(D), which we conveniently write using the same labeling convention for the elements of 2 as in the disease example:
2	⊗ 2	⊗ ... ⊗ 2		N	 2 ¸.
The probability distributions defining N are given according to the probability table of the node. For instance, the Kleisli map A : 2P ⊗2M → 2A for acceptance is defined by:
(p, m) '→ 1 |a⟩	(p, m⊥) '→  7 |a⟩ +  3 |a⊥⟩
(p⊥, m) '→  8 |a⟩ +  2 |a⊥⟩	(p⊥, m⊥) '→  1 |a⟩ +  9 |a⊥⟩ .
Another example is  the initial map T : 1 → 2T for the time node, which amounts to the distribution 4 |t⟩ +  6 |t⊥⟩ in D(2T ) ∼= [0, 1]. In order to recover the whole
network (9), one pastes node-arrows together using the symmetric monoidal struc-
ture of Kl(D), which we recalled in the beginning of this section. Nodes in (9) that

have multiple outgoing edges are modeled by composing the corresponding arrow 2k → 2 with the pairing map δ : 2 → 22 defined by x '→ 1 |(x, x)⟩. The Bayesian network (9) in its entirety is then expressed as the following arrow in Kl(D), where for simplicity we omit the subscripts naming the elements of each copy of 2.





1 	T ⊗S	 2 ⊗¸2
δ⊗id
(2 ⊗ 2) ⊗ (2 ⊗ 2)  P ⊗M  2 ⊗¸2 	A	 2 ¸
id⊗tw⊗id
(2 ⊗ 2) ⊗,(,2 ⊗ 2)
δ⊗δ

2 ⊗ 	W ⊗R	 ¸

We have written the “structural” arrows vertically. A more insightful representation of the same arrow can be given using the graphical language of string diagrams [20], with 2k depicted as a bundle of k wires and δ as . The result almost resembles the original network.


(10)

It may be calculated 4 that the entire arrow 1 → 2 in (10) amounts to the distri- bution 0.48 |a⟩ + 0.52 |a ⟩ in D(2) = [0, 1]. In words: given 40% of chances that the scientist has enough time at disposal and 70% of chances of being adequately skilled, the odds of having a paper accepted at the conference is ∼48%.
We now have everything in place to instantiate our framework for inference. As this example is more elaborated than the previous ones, it gives us the possibility to explore the situation in which knowledge update only involves a segment of the computation, namely f or g in the following partitioned version of (10).



1
T
 2 ⊗¸2

 2 ⊗¸2


 2 ¸

In order to formulate a backward inference question, we follow the recipe (3) and introduce a predicate A?: 2A → [0, 1] that tests for acceptance of the paper. It is a sharp predicate, defined by A?(a)=1 and A?(a⊥)= 0.
First we compute ω|(g◦f)∗ (A?), that is, the odds that the accepted paper actually was submitted by a scientist with an adequate amount of time and skill to concoct

4 For simplicity, here and in the next calculations we approximate distribution values to two decimal digits.

it.

ω = 0.28 |t, s⟩ + 0.12 |t, s⊥⟩ + 0.42 |t⊥, s⟩ + 0.18 |t⊥, s⊥⟩
(t, s) '→ 0.67	(t, s⊥) '→ 0.58

(g ◦ f )∗(A?) =
(t⊥, s) '→ 0.40	(t⊥, s⊥) '→ 0.29

ω |= (g ◦ f )∗(A?) = 0.48
ω|(g◦f )∗ (A?) =
x∈2T ⊗2S

ω(x) · (g ◦ f )∗(A?)(x) 0.48

= 0.39 |t, s⟩ + 0.15 |t, s⊥⟩ + 0.35 |t⊥, s⟩ + 0.11 |t⊥, s⊥⟩
We observe that, after finding out that the paper has been accepted, the chances that the scientist had both sufficient time and skill rise from 28% to 39%.
As a second example, we shift the attention from the author to the paper itself. The following state on 2W ⊗ 2R expresses the chances that an accepted paper was actually well written and contained strong scientific results. Note that it mixes state and predicate transformers to bind different segments of the network.
f∗(ω)|g∗ (A?) = 0.48 |w, r⟩ + 0.18 |w, r⊥⟩ + 0.24 |w⊥, r⟩ + 0.10 |w⊥, r⊥⟩
We see that, in our model, roughly one half of the accepted papers had both quali- ties, but only 10% of them had none.
Lastly, we consider an example of forward inference. Following the recipe (4), we introduce a predicate E?: 2T ⊗ 2S → [0, 1] on the state ω : 1 → 2T ⊗ 2S : it expresses the event that, while writing the paper, the scientist finds out that the main result contains a minor mistake and thus needs some revision.


(t, s) '→  2
(t, s⊥) '→  4
(t⊥, s) '→  3
(t⊥, s⊥) '→  6 .

Differently from A?, this E? is a fuzzy predicate: a mistake gets more likely the less time and skill are available to the scientist. If this situation occurs, the scientist may still be able to produce on time a paper that gets accepted, but chances are lower: they decrease from 48% to 43%. This is expressed by the following inference.
(g ◦ f )∗(ω|E?) = 0.43 |a⟩ + 0.57 |a⊥⟩ .
Remark 3.1 We have modeled a Bayesian network as a graph in the Kleisli cate- gory Kl(D). This is inspired by the approach of Fong [8], except that he uses the Kleisli category Kl(G) of the Giry monad (even though all his examples are discrete). Such graphs in Kl(D) or Kl(G) can be seen as symmetric monoidal functors from a PROP P, generated by a signature with the nodes and edges of the network, to the Kleisli category. We recall that a PROP (product and permutation category [15]) is a symmetric strict monoidal category with the natural numbers as objects and with monoidal product ⊕ given by addition of numbers. Intuitively, PROPs generalise Lawvere theories from the cartesian to the linear setting; functors from P as above are called the models of P.

In our case, the model P → Kl(D) sends ⊕ to the monoidal product ⊗ of Kl(D), and sends the number 1 to the object 2 = 1 + 1 in Kl(D). P has pairing (copying)
, but a crucial point is that these copiers are not natural — as can be checked easily in Kl(D). This implies that P is not a Lawvere theory (cf. [3]), and there is no associated monad on Set.
This monad perspective comes up in the following way. A Bayesian network with set of nodes X can be seen as a coalgebra of the form:


X   c  B(¸X)	where	B(X) = 
U⊆finX
[0, 1]2#U

This coalgebra c sends a node N ∈ X to a pair c(N ) = ⟨c1(N ), c2(N )⟩ where c1(N ) ⊆fin X is a finite set of predecessor nodes of N , and c2(N ): 2n → [0, 1] is the associated conditional probability table — where n = #c1(N ) ∈ N is the number predecessors. Since [0, 1] ∼= D(2), this map c2(N ) is a Kleisli map 2n → 2 in Kl(D), as used in the above description of the paper-acceptance example.
It is not hard to see that the mapping X '→ B(X) is a functor on Set, and comes with a unit map X → B(X). But B is not a monad, at least not in the expected obvious sense, precisely because the copiers   are not natural.
Inference with continuous probability
Our abstract description of inference allows us to transfer the definitions from the discrete to the continuous approach simply by switching from the Kleisli category Kl(D) of the distribution monad to the Kleisli category Kl(G) of the Giry monad [9] on measurable spaces. We shall sketch an example where the function f in the inference situation (3) is the identity, but where we have multiple predicates pi for successive learning. Hence there is no predicate/state transformation involved. We describe the essentials and refer to [5] for more information.
A state ω : 1 → X in the Kleisli category Kl(G) is a probability measure ω ∈ G(X), given by a function ω : ΣX → [0, 1] that maps measurable subsets to probabilities. A predicate p : X → 2 in Kl(G) is a measurable function p : X → [0, 1] since G(2) = [0, 1]. The validity ω |= p in [0, 1] and conditional state ω|p in G(X) are given by the following integration formulas.
ω |= p := ∫ p dω	and	ω| (M ) := ∫M p dω .	(11)

Often the state/probability measure ω that we start from is given by a probability density function. This means that ω is of the form φ |= q, for some predicate q. In that case the conditional state ω|p = (φ|q)|p is the same as the condition of the product predicate: φ|q·p with pdf q · p. This greatly simplifies the picture below.
The inference example that we use is a continuous version of the archeological example described in [13]. The aim is to infer the date of a tomb at an archeological site of which we already know that it is from the interval 0 − 100 AD. We are specifically looking to find three kinds of objects, labelled 0, 1, 2 of which we know

the time of use more precisely. They are used to infer the age of the tomb. This knowledge is represented by three predicates p0, p1, p2 : [0, 100] → [0, 1] given by the formulas:

p (x) = 0.6 · e−(x−20)2/2000 p (x) = 0.9 · e−(x−50)2/1500 p (x) = 0.8 · e−(x−90)2/1000



Our inference works as follows. We start from the uniform measure ω = φ|q with
pdf q(x) =  1  on [0, 100], for the Lebesgue measure φ. Its probability on the
sub-interval [a, b] ⊆ [0, 100] is given by the integral:
ω([a, b]) = φ|q([a, b]) = ∫ b q dφ = ∫ b  1  dφ = b−a .

We now successively observe objects i1,..., in, for ik = 0, 1, 2, and compute the conditional probability measure (··· (ω|pi1 ) ··· )|pin . We can describe this measure via the product pdf q · pi1 ··· pin , after normalisation. Below we sketch the shape of some of the resulting pdf’s (ignoring normalisation), after finding certain objects
successively.

after finding 2	after finding 2,1	after finding 2,1,0 after finding 2,1,0,0
These curves describe the inferred probability for the age of the tomb in the interval 0 – 100 AD.

Quantum inference
Our inference situations (3) and (4) can also be interpreted in the effectus of von Neumann algebras for quantum computation. Actually, one uses the opposite vNAop of the category vNA of von Neumann algebras, with normal completely positive unital maps between them (see [5] for details). We have to take the oppo- site category because maps between von Neumann algebras should be understood as predicate transformers. Typical examples are the von Neumann algebras B(H ) of bounded operators on a Hilbert space H . Below we use the matrix algebra M2 = B(C2) as special case.
For instance, the situation (3) translates into a diagram of maps in the category

vNA pointing in the other direction:

C ¸,ω	 B ¸,f	A ¸,q	C2

The conditional state ω|f∗ (q) : B → C in backward inference is given by the general formula:

b '−→
ω	f (q) b	f (q)
ω"f (q)	.	(12)

In this situation predicate transformation f∗(q) = f ◦ q works in the opposite direction. The square-roots arise from the particular form of ‘assert’ map that is used for von Neumann algebras, see [5] for details. The predicate q : C2 → A is a positive unital map, and can thus be identified with an effect in A , that is, with an element q ∈ A satisfying 0 ≤ q ≤ 1.
Bayesian inference in a quantum setting is a relatively new topic, see e.g. [14,6]. At this stage we only apply our general pattern from Definition 2.1 in a quantum setting. The illustration below repeats the disease-test example from Section 3 for the von Neumann algebra M2 of 2 × 2 complex matrices. Our only ambition at this stage is to show how the quantum description extends the probabilistic one. Consider therefore the diagram:
C ¸ω,  M2 ¸s,  M2 e T ?= ( 1 0 )
These test (sensitivity) and state maps are given by:

" a b 



  9 a+ 1 d	0

		

" a b	1	99



Predicate transformation yields:
9
s(T ?) = s( 1 0 ) =	10  1 
20


and	ω


"s(T ?)



117

2000

The backward inferred state ω|s∗ (T ?) is according to (12):

" a b  '−→ 2000 · ω   √9/10 √0
  a b   √9/10 √0



117	√9/200 c	1/20 d

117	117
We see that the outcome is the same, up to some re-shuffling, as in the discrete probabilistic presentation in (8). But this situation allows much richer structure, for instance using as state ρ : M2 → C the map ρ a b  = 1 (a − b − c + d).

Conclusions
This paper has clarified the role of states and predicates, and of state transformers and predicate transformers, in Bayesian inference. An abstract definition of for- ward and backward inference has been given in the context of effectus theory, and interpreted and elaborated in several contexts and examples.
The generality of our approach allows for applications outside of the traditional probabilistic setting; the case of Von Neumann algebras is one such example which has been described here only in limited, probabilistic form. The power of the prop- erly quantum approach (see also [14,6]) will be elaborated elsewhere.
The application to Bayesian networks also leaves room for interesting develop- ments. As sketched in Remark 3.1, the interpretation of networks as arrows of Kl(D) can be seen as part of a broader picture, that can be formulated in the language of PROPs and their models. We find particularly worthwhile trying to understand Bayesian inference, as introduced in the present paper, as a categorical transforma- tion on models of a PROP: it should map one network into another one with the same topology, but different probability distributions.
Acknowledgement
The authors acknowledge support from the European Research Council under the European Union’s Seventh Framework Programme (FP7/2007-2013) / ERC grant agreement no 320571.

References
Adams, R. and B. Jacobs, A type theory for probabilistic and Bayesian reasoning (2015), see arxiv. org/abs/1511.09230.
Barber, D., “Bayesian Reasoning and Machine Learning,” Cambridge Univ. Press, 2012.
Bonchi, F., P. Sobocinski and F. Zanasi, Lawvere categories as composed PROPs, in: Coalgebraic Methods in Computer Science (CMCS 2016), colocated with ETAPS 2016, 2016, pp. 11–32.
Borgstr¨om, J., A. Gordon, M. Greenberg, J. Margetson and J. V. Gael, Measure transformer semantics for Bayesian machine learning, Logical Methods in Comp. Sci. 9(3) (2013), pp. 1–39.
Cho, K., B. Jacobs, A. Westerbaan and B. Westerbaan, An introduction to effectus theory (2015), see
arxiv.org/abs/1512.05813.
Coecke, B. and R. Spekkens, Picturing classical and quantum Bayesian inference., Synthese 186 (2012),
pp. 651–696.
Dijkstra, E. W., “A Discipline of Programming,” Prentice Hall PTR, Upper Saddle River, NJ, USA, 1997, 1st edition.
Fong, B., “Causal Theories: A Categorical Perspective on Bayesian Networks,” Master’s thesis, Univ. of Oxford (2012), see arxiv.org/abs/1301.6201.
Giry, M., A categorical approach to probability theory, in: B. Banaschewski, editor, Categorical Aspects of Topology and Analysis, number 915 in Lect. Notes Math. (1982), pp. 68–85.
Goodman, N. D., The principles and practice of probabilistic programming, in: Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL ’13 (2013), pp. 399–402.

Jacobs, B., New directions in categorical logic, for classical, probabilistic and quantum logic, Logical Methods in Comp. Sci. 11(3) (2015), pp. 1–76.
Jacobs, B., A recipe for state and effect triangles, in: L. Moss and P. Sobocinski, editors, Conference on Algebra and Coalgebra in Computer Science (CALCO 2015), LIPIcs 35 (2015), pp. 116–129.
Jacobs, B., B. Westerbaan and A. Westerbaan, States of convex sets, in: A. Pitts, editor, Foundations of Software Science and Computation Structures, number 9034 in Lect. Notes Comp. Sci. (2015), pp. 87–101.
Leifer, M. and R. Spekkens, Towards a formulation of quantum theory as a causally neutral theory of Bayesian inference, Phys. Rev. A 88(5) (2013), p. 052130.
Mac Lane, S., Categorical algebra, B Am Math Soc 71 (1965), pp. 40–106.
Pearl, J., “Probabilistic Reasoning in Intelligent Systems,” Graduate Texts in Mathematics 118, Morgan Kaufmann, 1988.
Pearl, J., “Causality. Models, Reasoning, and Inference,” Cambridge Univ. Press, 2009, 2nd ed. edition.
Russell, S. and P. Norvig, “Artificial Intelligence. A Modern Approach,” Prentice Hall, 2003.
S´cibior, A., Z. Ghahramani and A. Gordon, Practical probabilistic programming with monads, in: Proc. 2015 ACM SIGPLAN Symp. on Haskell (2015), pp. 165–176.
Selinger, P., A survey of graphical languages for monoidal categories, Springer Lecture Notes in Physics
13 (2011), pp. 289–355, available at http://arxiv.org/abs/0908.3347.
Staton, S., H. Yang, C. Heunen, O. Kammar and F. Wood, Semantics for probabilistic programming: higher-order functions, continuous distributions, and soft constraints, in: Logic in Computer Science (LICS 2016), 2016, to appear, available at http://arxiv.org/abs/1601.04943.
