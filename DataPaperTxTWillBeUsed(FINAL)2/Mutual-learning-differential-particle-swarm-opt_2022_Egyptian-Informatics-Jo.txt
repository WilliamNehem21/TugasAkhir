Egyptian Informatics Journal 23 (2022) 469–481











Mutual learning differential particle swarm optimization
Anping Lin a, Shanglin Li b,c,⇑, Rongsheng Liu a
a School of Physics and Electronic Electrical Engineering, Xiangnan University, Chenzhou 423000, PR China
b School of Computer Science and Artificial Intelligence, Xiangnan University, Chenzhou 423000, PR China
c Hunan Engineering Research Center of Advanced Embedded Computing and Intelligent Medical Systems, Chenzhou 423000, PR China



a r t i c l e  i n f o 

Article history:
Received 9 February 2022
Revised 17 March 2022
Accepted 11 April 2022
Available online 26 April 2022

Keywords:
Mutual learning
Particle swarm optimization Differential evolution
Elite DE mutation
a b s t r a c t 

This study proposes a mutual learning strategy to develop a high performance hybrid algorithm based on particle swarm optimization and differential evolution. In the mutual learning strategy, the position information in PSO subswarm is employed for DE mutation, and the DE individuals are used to construct learning exemplar for PSO subswarm together with particles’ historical best position. A novel elite DE mutation is proposed to speed up the convergence rate of DE subswarm. Based on mutual learning tech- nique, the mutual learning differential evolution particle swarm optimization (MLDE-PSO) is proposed. To evaluate the performance of MLDE-PSO, three groups of test functions are employed, namely thirteen basic functions, thirteen rotated basic functions and thirty CEC2017 functions. The test results are com- pared with three state-of-the-art PSO algorithms, three recently PSO algorithms and DE/rand/1. The test results indicate that the proposed MLDE-PSO performs better than the other seven comparison algo- rithms, especially on rotated functions and CEC2017 functions. The rotation test shows that MLDE-PSO is not very sensitive to rotation transformation.
© 2022 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Computers and Artificial Intel-
ligence, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creative-
commons.org/licenses/by-nc-nd/4.0/).





Introduction

Particle swarm optimization (PSO) only uses primary mathe- matical operations and can obtain a high convergence speed. For PSO converges fast and can obtain high performance, it is widely applied to function optimization and real applications. Since the inception of PSO in 1995, a lot of PSO variants have been reported, the performance of PSO has been improved significantly. However, most of the current PSO variants can only perform well on a group of certain optimization problems, fewer PSO can achieve high per- formance on various types of optimization problems.
To improve the performance of PSO on different characteristics problem, the evolutionary community racks out their brains. In general, the improved PSO algorithms can be roughly divided into four categories, namely parameters regulating [1], neighborhood

* Corresponding author.
E-mail address: lsl@xnu.edu.cn (S. Li).
Peer review under responsibility of Faculty of Computers and Information, Cairo University.
topology[1], learning strategy [2,3] and hybridizing with other optimization technique[4]. Houssein et al. [5] summarized the recently development of PSO algorithms.
The learning strategy is an effective approach to improve the performance of PSO. A series of PSO algorithms construct effective learning exemplars to guide the evolution of particles. For exam- ple, CLPSO [6] adopts a comprehensive learning strategy in which different dimensions of a particle learns from different particles; Social learning particle swarm optimization (SLPSO) [7]adopts a social learning strategy in which the particles only learn from other particles with better fitness value; Xu et al. [8] introduces a dimen- sional learning strategy to employ the promising information dis- covered by the particle swarm; Molaei[9] introduces an enhanced learning strategy in which all the particles are employed to regulate any particle’s motion; Lim [10] proposes an elitist learning strategy based on orthogonal experimental designed stochastic perturbation techniques. Yan [11] proposed random learning mechanism to enhance swarm diversity, in random learn- ing mechanism each particle learns from a random neighbor parti- cle with a given probability. Ye [12] proposes dynamic learning strategy by dividing the whole swarm into exploitation oriented ordinary particles and exploration oriented communication parti- cle dynamically. The aforementioned PSO algorithms show that employing the information of elite neighbor particles for updating



https://doi.org/10.1016/j.eij.2022.04.003
1110-8665/© 2022 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Computers and Artificial Intelligence, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



particles’ velocity can enhance swarm diversity and mitigate pre- mature convergence.
To improve the applicability of PSO, kinds of intelligent opti- mization algorithms are transplanted into PSO. For example, Juang
[13] employs PSO and genetic algorithm (GA) to evolve elite parti- cles and proposes hybrid GA and PSO. Javidrad [14] employs sim- ulated annealing (SA) and PSO to evolve the population and proposed hybrid particle swarm and simulated annealing stochas- tic optimization (PSO-SA). Chen[15] transfers the migration of biogeography-based optimization to PSO and proposes biogeography-based  learning  particle  swarm  optimization
random numbers. The global version PSO can achieve high conver- gence rate, however, while it suffers from premature convergence.

2.2. DE

Differential evolution (DE) is one of the most powerful and ver- satile evolutionary optimizers for the continuous parameter space in recent times [25]. DE moves a population of individual towards the global optima through mutation, crossover and selection oper- ators. The candidate solution vectors are referred to as individuals and denoted by target vector XG={xG ; xG ; ··· ; xG }. i = 1, 2, .. ., NP

PSO and proposes hybrid of Levy flight and particle swarm opti- mization (LPSO). Jaferi [17] proposes a hybrid algorithm based on
PSO and cultural algorithm for truss structures design. Khan[18]
is the indice of the individual, G is the iteration number and D is the number of dimension. In the initialization, the individuals are ini- tialized randomly. In each generation, a mutant vector VG =-

G	G	G

employs (GSA) to overcome premature stagnation of PSO and pro- poses Hybrid Gravitational Search Particle Swarm Optimization Algorithm (HGSPSO).
Among the hybrid PSO algorithms, hybridizing DE and PSO attracts great attention in EC community. For DE and PSO can com-

into PSO algorithm in 2003, a series of hybrid algorithms based on DE and PSO are proposed. The concept of hybrid algorithm is
using DE operators to enhance swarm diversity of PSO, or employ-
{vi;1; vi;2; ··· ; vi;D}is generated by mutation operator for each
individual. Five most frequently used mutation strategies [26] implemented in the DE codes are given as below:
DE/rand/1.

VG = XG + F · (XG — XG )	(3)
DE/current-to-best/1.

VG = XG + Fi · XG — XG + Fi · (XG — XG )	(4)

ing PSO to speed up the convergence of DE. The major hybridizing
methods including (1) Series structure, employs DE further to evolves the particle swarm [20]; (2) Parallel structure, adopting
i	i

DE/ best/1.
best	i
r2	r3

both DE and PSO to evolve their own subswarm [21]; (3) Crossover, employing DE and PSO simultaneously to generating offspring through crossover [22]. (4) Cascading, employing DE to construct
learning exemplar for PSO [23]. More detailed introduction of
VG = XG  + Fi · (X — X )	(5)
DE/ best/2.

VG = XG + Fi · XG — XG + Fi · (XG — XG )	(6)

DE-PSO will be introduced in section 2.3. Due to the opposite char- acteristics, the performance of some hybrid DE-PSO algorithms on
complex multimodal problems may worse than classical DE algo-
i	best	r1	r2

DE/ rand/2.
r3	r4

rithms. DE needs relatively bigger population than PSO to avoid

VG = XG + Fi · XG — XG + Fi · (XG — XG )	(7)

for hybrid DE and PSO algorithms. Developing high performance hybrid DE and PSO algorithm still attracts the attention of EC com- munity. To fully use the advantages of DE and PSO algorithms, this study proposed a mutual learning strategy for hybridizing DE and PSO. Furthermore, an elite mutation is introduced to accelerate the convergence speed of DE subswarm. The rest of this paper is orga- nized as follows: Section 2 reviews the related works, Section 3 proposes the methodology, section 4 conducts experiments and


The indices r1, r2, r3, r4, r5 ∈ [1, NP]are mutually exclusive inte- gers randomly. Fi is a scaling factor to scale the difference vectors. After mutation, the crossover operation is conducted between the individual and its mutant vector to generate a trial vector UG={uG ; uG ; ··· ; uG }. The crossover operation is executed accord-
ing to eq.(8).
( vG if randj ≤ CR or(j = jrand)





Related works

Canonical PSO

In PSO, each potential solution is regarded as a particle. The par- ticle flies in the search space to find the global optima under the attractive force from its personal best position (Pbest) and the glo- bal best position (Gbest). The widely used global version PSO updates its velocity and position according to eq .(1), (2) [24].
where CR ∈ (0; 1]is a crossover rate defined by user. j = 1, 2, .. ., D is the indice of dimension. randj ∈ [0,1] is a uniform distributed ran- dom number. jrand ∈ [1,D] is a random integer to guarantee the trial
vector UG will differ from its target vector Xi,G in at least one dimension.
After mutation, the fitness value of the trial vector is evaluated and the selection operation is performed. The selection is carried out according to eq.(9) between the trial vector UG and its target
vector XG based on their fitness value.

vi d = xvi d + c1 · r1 d · p  — pos  + c2 · r2 d · (g — pos )	(1)
G	( UGiffit(UG)≤ f (XG)

 

posi;d = posi;d + vi;d	(2)
where the velocity vector, Pbest vector and position vector of the ith
where fit(·) is the objective function. If the trial vector’s fitness value
fit(UG) is no worse than its target vector’s fitness value fit(VG), the

particle are denoted by Vi = [vi, 1, vi,2, .. ., vi,D], Pi = [pi,1, pi,2, .. ., pi,D],	trial vector UG will replace its target vector XG. Otherwise, the target
i	i

and Posi = [posi,1, posi,2, .. ., posi,D], respectively. G = [g1, g2, .. ., gD] stands for the Gbest vector. x stands for an inertia weight, c1 and c2 are two acceleration coefficients. r1,d,r2,d ∈ [0,1]are two uniform
vector will be kept for the next generation. The mutation, crossover and selection operations are carried out repeatedly until the termi- nation criteria is satisfied.



2.3. Hybrid DE and PSO

G
Er1
is randomly selected from top Nelite individual.

A serials hybrid DE and PSO are proposed in the past. For exam- ple, Pei [27] taking the PSO as auxiliary mutation operator and the DE for crossover operation to avoid the deficiency of using single algorithm. Chen [23] proposed a hybridizing PSO and DE for fea- ture selection by employing differential evolution to breed promis- ing and efficient exemplars for PSO. Sato [28] proposed multi- swarm differential evolutionary particle swarm optimization (MS-DEEPSO) for energy network optimization. Wang [29] intro- duces a self-adaptive mutation strategy for hybrid differential and PSO algorithm, the selection probability of DE and PSO opera- tors are self-adapted based on their previous performance. Epitro- pakis proposes a serial structure framework for hybridizing DE and PSO. Sayah et al. [30] proposed a DE-PSO algorithm by incorporat- ing PSO into the conventional DE algorithm as a supplementary mutation operator to improve global search capability. Liu et al. [21]employs PSO to evolve the better half of the DE individuals in each iteration. Seyedmahmoudian [31] proposed a DE-PSO algo- rithm by adopting DE and PSO to evolve the population alterna- tively. Chen et al. [32] employs two different differential evolution operators to construct learning exemplar for PSO and proposed particle swarm optimizer with two differential muta- tions. Chen et al. [33] merge the differential evolution operator into each sub-swarm, and proposed a dynamic multi-swam differential evolution learning particle swam optimizer (DMSDL-PSO). DMSDL-
Nelite = round(NP — (NP — Nend)* iter/iterm)	(11)
Nelite denotes the top Nelite individuals in DE subswarm sorted by fitness value. Nelite is decreasing linearly during the optimization process, aiming to concentrate the searching in the neighborhood of a few promising individuals. In the early stage of optimiza-
tion, XG is randomly selected from the whole population to achieve high exploration. As the increasing of iteration, XG is selected form a few of high quality individuals to improve conver-
gence speed in the later stage.

Crossover learning exemplar

The learning exemplar is of vital importance to improve the performance of PSO. For example, CLPSO [6], OLPSO [35], GL-PSO
[36] improve the performance of PSO by construct high quality learning exemplars. In this study, individuals of DE subswarm is adopted to generate learning exemplars for PSO subswarm accord- ing to Algorithm 1. The crossover is carried out to generate try learning exemplar according to eq. (12,13).

Algorithm 1 Generating learning exemplar of MLDE-PSO
For d = 1:D/* Generating try learning exemplar


Update exempd according to eq.(12,13)

PSO adopts differential mutation to enhance exploration and employs Quasi-Newton method as a local searcher to enhance the exploitation. Xin et al. [34] summarized the existing hybrid algorithms based on DE and PSO.

Methodology

Motivation

As two excellent intelligent optimization algorithms, PSO and DE have their own distinct characteristic. For instance, PSO employs relatively small population and converges fast, while it may be apt to fall into local optima when optimizing complex mul- timodal problems. Furthermore, PSO is rotation variant, hence its
End
If fit(Exempi) < fit(Exemplari) /* Selection of learning exemplar
Exemplari = Exempi
Exemplar_vali = fit(Exempi)
End




Note: fit(·)stand for the fitness function. Exempi, Exemplari, Exem- plar_vali stand for try learning exemplar, learning exemplar, and fit- ness of learning exemplar of particle i, respectively. d and D denote for the indice of dimension and dimension.

performance on rotated problems is not satisfactory. On the con- trary, DE requires a relatively large population size and performs better on complex multimodal problems, while it converges rela-
exempd =
d  (rand <= Pcr)
r	(rand > Pcr)
(12)

tively slowly on unimodal problems. For PSO and DE generating offspring in different ways, it is difficult to make good use of their advantages without crapping each other. A few hybrid DE-PSO
algorithm seven can’t outperform classic DE algorithms on com-

Pcr =
0.9
0.1
(Pbestval(i) <= Val(r)) (Pbestval(i) > Val(r))
(13)

plex multimodal problems. Based on the aforementioned weakness
vd = xvd + c1 · rd · Exempard — Posd + c2 · rd · (Gbestd — Posd)

i	i	i
of hybrid DE-PSO algorithms, this study introduces a mutual learn- ing strategy for hybridizing DE and PSO, to fully use the promising
i	i	i
i
(14)

information in both DE and PSO subswarm. In the mutual learning strategy, the DE and the PSO subswarm work in parallel, and the elite information is exchanged between two subswarm to improve the population quality. The position vector of PSO subswarm is employed for DE mutation to speed up the response of DE sub- swarm, furthermore, the elite DE mutation is employed for acceler- ating the convergence speed of DE subswarm.

Elite DE

DE/rand/1 has strong exploration, while it converges too slowly. To improve the convergence rate of DE/rand/1, an elite DE (de- noted by Elite-DE) is proposed in this study. Elite-DE generates trial vectors according to eq. (10,11).
VG = XG + F · (X — X )	(10)
For arbitrarily particle i, a random selected DE individual r is employed for generating a try learning exemplar through cross- over. The crossover probability is determined by eq.(13). According to the guidance of Storm [42], cr = 0.9 (the crossover probability of DE) can speed convergence. Hence, if Pbestval(i) (the fitness value of particle i)is no worse than Val(r) (the fitness value of individual r), the crossover probability Pcr = 0.9, otherwise Pcr = 0.1. Based on the crossover, most dimensions of learning exemplar are copied from the better solution between PSO particles and DE individuals, hence the diversity of PSO subswarm is enhanced. In the selection operation, the learning exemplar is replaced by the try learning exemplar if the latter’s fitness value is better. With selection oper- ation, the quality of learning exemplar is guaranteed. For the DE subswarm is rotation invariant, employing DE individual for gener- ating PSO learning exemplar can give the PSO subswarm partial




Elite DE with best position

To further enhance information between DE and PSO sub- swarm, Elite DE with the best position (denoted by E-DEx) is employed for generating trial vector of DE subswarm.
VG = XG 1 + Fi · (XG — XG 3 )	(15)
XG is a random individual chosen from the union DE swarm and Posibest (Posibest denotes for the current position of the best par- ticle in the PSO subswarm). Posibest is updated in every iteration, hence employing Posibest for DE mutation can speed up the response of DE subswarm to the landscape of optimization problem.

The proposed method

The flowchart of the proposed MLDE-PSO is given in Fig. 1. The whole swarm is divides into a DE subswarm and a PSO subswarm. Two subswarms work alternatively and cooperatively according to the mutual learning strategy, and then some promising informa- tion can be exchanged sufficiently. As a result, the quality of the whole swarm can be improved. In the initialization, the population of both DE subswarm and PSO subswarm are initialized, and the parameters of DE subswarm and PSO subswarm are assigned will initial value. The number of elite individual, inertial weight and acceleration coefficients are adjusted in every iteration. Then, two subswarms are evolving according to their own ways. The valuable information is exchanged between two subswarms. The position of the best particle is employed for DE mutation, and the DE individuals are utilized for generating learning exemplar in PSO subswarm through crossover. If the number function eval- uations FE is less than the maximum function evolution, the opti-
mization goes to next iteration, otherwise the optimization is ended and outputs results. Since two subswarms can learn from each other, both the DE subswarms and the PSO subswarms can employ the other subswarm’s promising information to improve swarm quality, thereby both the DE subswarm and the PSO sub- swarm can employ the other swarm’s advantages to overcome its own defects. The mutual learning strategy proposed in this study can be applied to other hybrid intelligent optimization algorithm.


Experimental work

Experimental setup

In this study, three group test functions are employed to test the performance of MLDE-PSO. (1) 13 selected basic functions adopted by a few representative PSO variants [36] are employed to compare the performance of MLDE-PSO on basic optimization problems. (2) The aforementioned 13 basic functions are rotated to evaluate the performance of MLDE-PSO on rotated problems. (3) 30 CEC2017
[37] functions adopted by most of recently literature in evolution- ary community are employed to test the performance of MLDE-PSO on competitive optimization. Details of 13 basic functions denoted by (BF1 ~ BF13) are given in Table1, BF1-BF7 are seven unimodal functions, BF8-BF13 are six multimodal functions. To test the rota- tion invariance feature of MLDE-PSO, thirteen basic functions are rotated with rotation matrix. The rotation functions can be expressed in eq.(16).

RFi(x)= BFi(x * M)	(16)
i [1,13] is the index of function. M is a rotation matrix [38], its condition number is 2.




Fig. 1. The flow chart of MLDE-PSO.


Table 1
Basic test function.

No.	Test function	Domain	Name

BF1	f 1(x) = Pn 1 x2
[-100,100]	sphere

i=
BF
i=1
i
n i=1
|xi|	[-10,10]	Schwefel’s P2.22

BF3	f 3 (x) = Pn 1 (Pi 1xj )	[-100,100]	quadric
BF4	f 4 (x) = max |xi |, 1 6 i 6 30	[-100,100]	Schwefel’s P2.2.1
BF5	f (x) = Pn—1 h100 xi 1 — x2 2 + (xi — 1)2 i	[-10,10]	Rosenbrock’s

BF6	f 5(x) = Pn
(xi + 0.5)2	[-100,100]	Step

BF7	f 7 (x) = P30 x4 random[0, 1)	[-500,500]	Schwefel’s
BF8	f 7 (x) = Pn  x2 — 10 cos (2pxi ) + 10	[-5.12,5.12]	rastrigin

BF9	f 8(x) = —20 exp  —0.2q1ﬃﬃﬃ/ﬃﬃﬃnﬃﬃPﬃﬃﬃﬃﬃnﬃﬃﬃﬃﬃﬃxﬃﬃﬃ2ﬃﬃ  — exp(1/nPn
cos(2pxi )) + 20 + e	[–32,32]	ackley

i=1 i
,ﬃﬃ
i=1

BF10	f 9(x) = 1/4000Pn
x2 — Qn
cos(xi/
i )+ 1	[-600,600]	griewank

BF11	f 11(x) = p {1 — sin2(py1)+ Pn—1 (yi — 1)2 [1 + 10sin2(pyi 1)] + (yn — 1)2 }
[-50,50]	General penalized

+Pn 1 u(xi, 10, 100, 4), yi = 1 + 1 (xi + 1)

BF12	f 12(x) = 1 10sin2(3px1)+ Pn—1 (xi — 1)2 [1 + 10sin2(pxi+1)] + Pn
u(xi , 5, 100, 4)	[-50,50]	General penalized


10
BF13	f 13(x) =  n
 y2 — 10 cos (2pyi) + 10 + Pn
i=1
u(xi, 10, 100, 4)	[-5.12,5.12]	Non-continuous Rastrigin

i=1  i


  x x	0 5
i=1
8< k xj — a m ,  xj > a

Note: In BF
and BF
, y =
  i| i| 6 .
andu x , a, k, m =
0, —a 6 xj 6 a	.

12	13  i
round(2xi ) |x|0.5	j
: k —xj — a m ,  xj < —a



To further test the performance of MLDE-PSO on complex mul- timodal function, thirty CEC2017 functions (F1-F30) are tested. The maximum function evolution is set as 10000*D, D is the number of
tance between the population and their centriod. The diversity is calculated according to eq. (17).

dimension. All the functions are run for 30 independent runs and

Diversity
1 XNP rXﬃﬃﬃﬃﬃﬃﬃDﬃﬃﬃﬃﬃﬃﬃﬃxﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃx—ﬃﬃﬃﬃﬃ2ﬃﬃ	17

MS Windows 10 64-bit OS and Matlab R2018b Compiler.
NP = NDE
+ NPSO
, x— denote for jth dimension mean position of

Seven selective peer algorithms are compared with MLDE-PSO covering three state-of-the-art PSO algorithms, three recent PSO algorithm and one classic DE algorithms. CLPSO [6] adopts compre- hensive learning strategy to enhance the exploration of PSO. In comprehensive learning, each particle learns from the whole swarm and different dimensions learn from different particles. CLPSO performs well on multimodal problems. FDR-PSO [39] employs the nearby high fitness particles to guide the motion of learning particle. FDR-PSO avoids premature convergence at the cost of slowing down convergence speed in the early stage. UPSO
[40] employs local version PSO and global version PSO simultane- ously to achieve good balance between exploration and exploita- tion. TSL-PSO [8] utilizes two learning strategy to evolve two subswarms respectively. One subswarm adopts dimensional learn- ing strategy to enhance local search while the other subswarm uses comprehensive learning strategy to enhance exploration. GGL-PSOD [41] employs ring topology neighbor particles to con- struct learning exemplar and linearly adjusting control parameters to balance exploration and exploitation. GGL-PSOD exhibits high adaptability on different kinds of optimization problems. DMSDL- PSO divides the swarm into a few dynamic subswarm and employ DE mutation to construct learning exemplar of PSO, the Quasi- Newton method is employed for local search. DE/rand/1 [42] bears strong exploration while converges slowly, it performs well on complex multimodal problems. For Elite-DE is modified from DE/ rand/1, hence DE/rand/1 is adopted for comparison test. The parameters of comparison algorithms presented in Table 2 are in
both DE and PSO subswarm. For PSO subswarm, xi,j = pi,j . Fig. 2.a shows that the diversity of DE/rand/1 decreases slowly, means the population of DE/rand/1 converges slowly, hence it can’t achieve high accuracy on Sphere function. In the starting the diver- sity curve of Elite-DE is almost overlap with DE/rand/1, while in the later stage, the diversity curve of Elite-DE decreasing faster than DE/rand/1. MLDE-PSO can preserve sufficient diversity in the early stage and converge to the current best solution quickly in the later stage. Thereby MLDE-PSO can obtain high accuracy on Sphere function. Fig. 2.b shows that on Rastrigin functions, the population of DE/rand/1 can’t converge to a small area. Elite- DE can’t converge in the early stage, while in the later stage, Elite-DE converges to the found best solution quickly. MLDE-PSO converges at suitable speed in the early, while in the later stage, the diversity of MLDE-PSO decreasing slowly. The diversity curves indicate that with PSO subswarm, MLDE-PSO bears stronger exploitation than DE/rand/1, MLDE-PSO can keep sufficient diver- sity in the early stage and converge to the neighborhood found best solution to achieve high accuracy.
Table 2
Parameters configuration of algorithms.

No.  Algorithm	year	Parameter settings

[40]

accordance with the original publications.

Search behavior test

To analyze the search behavior of MLDE-PSO, the diversity curves on Sphere function and Rastrigin function are given in Fig. 2. The diversity curves of DE/rand/1 and Elite-DE are provided for comparison. The diversity is evaluated by mean Euclidean dis-
4	TSL-PSOD
2019  N1 = 15, N2 = 25,w = 0.9–0.4, c1 = 1.5,c2 = 1.5,












Fig. 2. Diversity curves of MLDE-PSO and DE.



Comparison test on basic test functions

The comparison test results on basic test functions of MLDE- PSO and seven peer algorithms are presented in Table 3 and Table 4. The statistic wilcoxon signed-rank test is employed for comparing
the performance of MLDE-PSO and the other peer algorithm. In Table 3 and Table 4, FV stands for mean fitness value in thirty inde- pendent runs. SP is employed to evaluate the convergence speed of algorithms to achieve the predefined accuracy, it can be expressed in eq.(17).


Table 3
Test results on unimodal basic test functions.

Note: FV and SR denote for mean fitness value, and success rate, respectively. SP expressed in eq.(17) stands for the quotient of the average number of function evaluations needed by an algorithm to reach the predefined thresholds.


Table 4
Test results on multimodal basic test functions.



mean(SP)= FEMAX * (1 — SR)/SR + mean(FE of success runs)

(17)
mean errors among eight algorithms. The best results are high- lighted in bold.
The results in Table 3 indicated that MLDE-PSO ranks the first

In this study, the predefined accuracy is e = 1  10—6. SR denotes for success rate, it equals to the quotient of number of success runs divided by total runs. In the pairwise wilcoxon signed-rank test, the symbol ‘‘>”,‘‘=” and ‘‘<” in row of ‘‘FV” denote for the performance of MLDE-PSO is ‘‘significant better than”‘‘tie with”, ‘‘significant worse than” the compared algo- rithm, respectively. The row of ‘‘rank” stands for the rank of
on six unimodal functions out of seven unimodal functions. Only on BF5, MLDE-PSO performs worse than other peer algorithms. MLDE-PSO achieves zero errors on BF1, BF2, BF3, and BF6. On BF4, MLDE-PSO achieves very high accuracy too. MLDE-PSO yields the lowest SP on BF1-BF4, BF6 and BF7, which means the convergence speed of MLDE-PSO on these functions are faster than other com- pared algorithms. DMSDL-PSO and UPSO achieve the lowest SP



on BF5 and BF6, respectively. If one algorithm can’t achieve the given accuracy in thirty runs, its SP is marked with ‘‘INF”. In the aspect of success rate ‘‘SR”, MLDE-PSO generated 100% success rate on all unimodal functions except BF5. On Rosenbrock function BF5, MLDE-PSO fails to yield the given accuracy in thirty runs. All the algorithms yield 100% success rate on BF1-BF3. On BF6, only FDR- PSO and UPSO fail to yield 100% success rate. The Wilcoxon signed rank test results show that MLDE-PSO performs significant better than the other algorithms on BF1-BF4 and BF7. On BF6, MLDE- PSO’s performance is better than FDR-PSO and UPSO, tie with the rest peer algorithms. In the criteria of rank of mean errors, MLDE-PSO ranks the first on BF1-BF4, BF6 and BF7. On BF5, MLDE- PSO ranks the eighth.
On six multimodal functions, MLDE-PSO achieves the best per- formance on BF8-BF10 and BF13, on two penalty function BF11 and BF12, MLDE-PSO only performs better than other FDR-PSO and UPSO on BF11. MLDE-PSO consumes the lowest SP on BF8-BF10 and BF13. On BF11 and BF12, TSL-PSO and UPSO yields the lowest SP, respectively. On the aspect of success rate, MLDE-PSO generates 100% success rate except BF11 and BF12. On two penalty functions BF11 and BF12, MLDE-PSO fails to achieve the given accuracy in thirty runs, MLDE-PSO can’t yield high performance, for than pen- alty function changed the landscape of the optimization problem. CLPSO, TSL-PSO, GGL-PSOD, DMSDL-PSO and DE/rand/1 achieve 100% SR on BF11, while on BF12, only FDR-PSO and MLDE-PSO fail to achieve 100% SR. The Wilcoxon signed rank test results indicate that MLDE-PSO performs better than other algorithms on BF9, per- forms no worsen than other algorithms on BF8, BF10, and BF13. MLDE-PSO ranks the first on BF8-BF10 and BF11, ranks the sixth, eighth on BF11 and BF12, respectively.
The test results on basic test functions are summarized in Table 5. According to the summary of test results in Table 5, MLDE-PSO yields the best performance for 6, 4 and 10 times on unimodal functions, multimodal functions and all thirteen basic functions, respectively. The average ranks show that MLDE-PSO yields the best rank on unimodal functions, DMSDL-PSO yields the best rank on multimodal functions and all thirteen basic func- tions. The Wilcoxon signed rank test results show that on uni- modal functions MLDE-PSO performs better than other peer algorithms on six or five functions. On multimodal functions, MLDE-PSO is outperformed by DMSDL-PSO, CLPSO and TSL-PSO on three, two, and two functions, respectively. The overall perfor- mance of MLDE-PSO is worse than DMSDL-PSO and CLPSO, almost the same with TSL-PSO, better than FDR-PSO, UPSO, GGL-PSOD and DE/rand/1. On all thirteen functions, MLDE-PSO outperforms CLPSO, FDR-PSO, UPSO, TSL-PSO, GGL-PSOD, DMSDL-PSO and DE/
rand/1 on six, ten, nine, seven, nine, six and eight functions, respec- tively. For DMSDL-PSO employs local search strategy to enhance convergence, DMSDL-PSO performs better than MLDE-PSO on mul- timodal functions. The overall performance of MLDE-PSO is better than DMSDL-PSO, DE/rand/1 and other peer algorithms. For MLDE- PSO employs PSO subswarm and Elite-DE to enhance exploitation,
it performs better than DE/rand/1. Only on BF5 and penalty func- tion BF11 and BF12, MLDE-PSO performs worse than DE/rand/1.

Comparison test on rotated basic test functions

In this test, thirteen rotated basic functions are rotated form BF1 BF13 with condition number is 2 matrix to increase the diffi- culty on finding the global optima. Table 6 indicate that on seven rotated unimodal functions (RBF1-RBF7), MLDE-PSO yields the best performance except on RBF5. With local search strategy, DMSDL- PSO generates the best performance on RBF5. MLDE-PSO consumes the lowest SP except RBF1 and RBF5, DMSDL-PSO achieves the low- est SP on RBF1 and RBF5. MLDE-PSO yields 100% success rate except RBF5. On RBF1 all algorithms yields100% success rate, on RBF3 only CLPSO fail to yield 100% success rate. The Wilcoxon signed rank test show that MLDE-PSO performs better than other algorithms except on RBF5 and RBF6. On RBF5, MLDE-PSO performs worse than DMSDL-PSO, better than the rest of peer algorithms. On RBF6, MLDE-PSO performs better than FDR-PSO and TSL-PSO, performs almost the same with the rest algorithms. MLDE-PSO ranks the first except on RBF5. On RBF5, DMSDL-PSO ranks the first and MLDE-PSO ranks the second.
On six rotated multimodal functions, Table 7 shows that MLDE- PSO achieves the best performance except on two penalty func- tions RBF11 and RBF12. DE/rand/1 yield the best performance on RBF11 and RBF12. MLDE-PSO consumes the lowest SP except on RBF11 and RBF12. TSL-PSO consumes the lowest SP on RBF11 and RBF12. MLDE-PSO achieves the highest success rate on RBF8-10 and RBF13. On RBF11 TSL-PSO yields the highest success rate, on RBF12, DMSDL-PSO yields the highest success rate. MLDE-PSO ranks the first on RBF8,RBF9, RBF10 and RBF13, ranks the fourth on RBF11 and ranks the eighth on RBF12. DE/rand/1 ranks the first on RBF11 and RBF12.
The summary of test results in Table 8 indicate that MLDE-PSO yields the best performance for six, four and ten times on unimodal functions, multimodal functions and all rotated basic functions. MLDE-PSO achieves the best average rank on rotated unimodal functions, rotated multimodal functions and all rotated basic func- tions. The Wilcoxon signed-rank test results show MLDE-PSO per- forms better than other algorithms on unimodal functions, multimodal functions and all rotated function. For MLDE-PSO has DE subswarm, its performance is not impacted significantly by rotate transformation. For DE/rand/1 is rotation invariant, it per- forms well on rotated basic functions too. For other peer PSO algo- rithms, their performance are impaired by rotate transformation. Hence MLDE-PSO win more advantages on rotated functions than on basic functions.

Comparison test on CEC2017 functions

Table 9 indicates that among thirty CEC2017 functions, MLDE- PSO yields the best performance on all three unimodal functions,




Table 5
Summary of test results on basic test functions.


Test results on unimodal rotated basic test functions.




Table 7
Test results on multimodal rotated basic test functions.





Table 8
Summary of test results on rotated basic test functions.



Table 9
Test results on CEC2017 functions.

Note: The symbol ‘‘>”,‘‘=” and ‘‘<” denote for the performance of MLDE-PSO is ‘‘significant better than”, ‘‘tie with” and ‘‘significant worse than” the compared algorithm in the wilcoxon signed rank test with significance level of 0.05.


four simple multimodal functions, seven hybrid functions and five composition functions. On functions F9, MLDE-PSO and DE/rand/1 tie for first, and on function F22,GGL-PSOD, DE/rand/1 tie for first. MLDE-PSO win the best performance on nineteen functions out of thirty CEC2017 functions. DMSDL-PSO, DE/rand/1, GGL-PSOD and CLPSO win the best performance on six, five, two and one func- tions, respectively. MLDE-PSO outperforms CLPSO, FDR-PSO, UPSO, TSL-PSO, GGL-PSO, DMSDL-PSO and DE/rand/1 on twenty five, twenty seven, thirty, twenty seven, twenty three, twenty two and twenty one functions, respectively. MLDE-PSO exhibits high performance on different types of CEC2017 functions. The advan- tage of MLDE-PSO on unimodal functions, simple multimodal func- tions and hybrid functions are more significant than on composition functions. The overall performance of MLDE-PSO is better than DE/rand/1, DMSDL-PSO and other peer algorithms. Though DMSDL-PSO employs DE to construct learning exemplar and local search strategy to enhance exploitation, it is still outper- formed by MLDE-PSO.

Convergence speed analysis

To compare the convergence speed of MLDE-PSO with other peer algorithms, the convergence curves four basic functions and four rotated functions are given in Fig. 3. The rotated func- tion RBF2, RBF5, RBF10 and RBF12 are modified form basic func- tion BF2, BF5, BF10 and BF12, thereby the impact of rotation transformation can be evaluated by comparing the convergence curves of basic function and relevant rotate function. On BF2,
MLDE-PSO converges fast and achieve high accuracy, TSL-PSO, UPSO and FDR-PSO follows MLDE-PSO. With PSO subswarm and elite DE mutation, MLDE-PSO performs much better than DE/rand/1. On RBF2, MLDE-PSO yield high accuracy and win more advantages, other peer algorithms’ performance are impaired by rotation transformation significantly. On BF5, MLDE-PSO is trapped into local optima, DMSDL-PSO, DE/rand/1 and FDR-PSO occupy top three. On RBF5, DE/rand/1, DMSDL- PSO yield high accuracy. GGL-PSOD, CLPSO and MLDE-PSO fall behind.
On multimodal functions BF10, MLDE-PSO find the global optima very fast, DMSDL-PSO, DE/rand/1, CLPSO and TSL-PSO achieve high accuracy too, UPSO, GGL-PSOD and FDR-PSO are trapped into local optima. On RBF10, MLDE-PSO, DMSDL-PSO and DE/rand/1 obtain high performance, TSL-PSO and CLPSO are impacted by rotation transformation and can’t find the global optima. On BF12, MLDE-PSO fail to achieve high accuracy, for the penalty function misguiding MLDE-PSO to local optima. FDR-PSO falls into local optima too, the rest algorithms find the global optima successfully. On RBF12, DE/rand/1 and DMSDL-PSO obtain high accuracy, UPSO and MLDE-PSO fall behind, MLDE-PSO per- forms slightly better than UPSO.
The convergence curves indicate that DE/rand/1 and MLDE-PSO are not sensitive to rotation transformation. MLDE-PSO performs well on BF2, BF10, RBF2 and RBF10, while on BF5, BF12, RBF5 and RBF12, MLDE-PSO can’t achieve high accuracy. The penalty function changes the landscape of optimization problem and mislead MLDE-PSO to local optima.


	








Fig. 3. convergence curves of MLDE-PSO and peer algorithms.


Impact of PSO subswarm size

In this section, the PSO subswarm size is set as NPSO = 1, 3, 5, 7, 9 to analyze the impact of PSO subswarm size, other parameters are set according to Table 2. The mean fitness value ‘‘FV” and rank of mean errors are presented in Table 10. The results in Table 10 show that BF1, BF2, BF3, BF6, BF8, BF9, BF10 and BF13 are not sensitive to PSO subswarm population size. On the rest functions, the overall performance of NPSO = 3 performs better than other setting, NPSO =1 and NPSO = 9 performs well too. Increasing the PSO subswarm size can improve the proposed algorithm’s performance on BF5 and BF11.

Conclusions

This paper proposed a mutual learning strategy for hybridizing DE and PSO. Based on the mutual learning strategy, mutual learn- ing differential evolution particle swarm optimization (MLDE-PSO) is proposed. MLDE-PSO employs DE and PSO subswarm to evolve their own subswarm and valuable information is exchanged
between two subswarms. The position information in PSO sub- swarm is employed for DE mutation and the DE individuals are employed for constructing learning exemplars for PSO subswarm. To further improve exploitation of DE subswarm, an elite DE muta- tion is adopted. The experiments on basic functions, rotated basic functions and CEC2017 functions indicated that the overall perfor- mance of MLDE-PSO is better than other compared classic PSO algorithms, recently PSO algorithms and classic DE. On complex functions and rotated functions, MLDE-PSO exhibits more advan- tages. MLDE-PSO is less sensitive to rotation transformation than compared algorithms. On penalty functions, the performance of MLDE-PSO is relatively weak. In the future research, MLDE-PSO will be extended to constraint test functions and real-life optimiza- tion problems.

Declaration of Competing Interest

The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper.


	







Fig. 3 (continued)



Table 10
Parameters selection of MLDE-PSO.




Acknowledgements

The author thanks the reviewers and other scholars for provid- ing precious suggestion on this manuscript. This work is supported by the Scientific Research Fund of Hunan Provincial Education Department under Grant 20A460 and 20B536, the Scientific Research Start-up Fund for High-level Talents in Xiangnan Univer- sity, the Applied Characteristic Disciplines of Electronic Science and Technology of Xiangnan University. (Code is available https://www.researchgate.net/publication/360191796_Mutual_ learning_differential_particle_swarm_optimization).

References:

Lynn N, Ali MZ, Suganthan PN. Population topologies for particle swarm optimization and differential evolution. Swarm Evol Comput 2018;39:24–35.
Qin Q, Cheng S, Zhang Q, Li Li, Shi Y. Particle swarm optimization with interswarm interactive learning strategy. IEEE Trans Cybern 2016;46 (10):2238–51.
Xiang Z, Ji D, Zhang H, Wu H, Li Y. A simple PID-based strategy for particle swarm optimization algorithm. Inf Sci 2019;502:558–74.
Chen X, Tianfield H, Du W. Bee-foraging learning particle swarm optimization. Appl Soft Comput 2021;102:107134.
E. H. Houssein, A. G. Gad, K. Hussain, and P. N. Suganthan, Major Advances in Particle Swarm Optimization: Theory, Analysis, and Application, Swarm and Evolutionary Computation, vol. 63, 2021/06/01/ 2021, p. 100868.
Liang JJ, Qin AK, Member S, Suganthan PN, Member S, Baskar S. Comprehensive learning particle swarm optimizer for global optimization of multimodal functions. IEEE Trans Evol Comput 2006;10:281–95.
Cheng R, Jin Y. A social learning particle swarm optimization algorithm for scalable optimization. Inf Sci 2015;291:43–60.
Xu G, Cui Q, Shi X, Ge H, Zhan Z-H, Lee HP, et al. Particle swarm optimization based on dimensional learning strategy. Swarm Evol Comput 2019;45:33–51.
S. Molaei, H. Moazen, S. Najjar-Ghabel, and L. Farzinvash, Particle swarm optimization with an enhanced learning strategy and crossover operator, Knowledge-Based Systems, vol. 215, 2021/03/05/ 2021, p. 106768.
Lim WH, Mat Isa NA. An adaptive two-layer particle swarm optimization with elitist learning strategy. Inf Sci 2014;273:49–72.
Yan B, Zhao Z, Zhou Y, Yuan W, Li J, Wu J, et al. A particle swarm optimization algorithm with random learning mechanism and Levy flight for optimization of atomic clusters. Comput Phys Commun 2017;219:79–86.
Ye W, Feng W, Fan S. A novel multi-swarm particle swarm optimization with dynamic learning strategy. Appl Soft Comput 2017;61:832–43.
Juang C-F. A hybrid of genetic algorithm and particle swarm optimization for recurrent network design. IEEE Trans Syst Man Cybernet Part B Cybernet A Publ IEEE Syst Man Cybernet Soc 2004;34(2):997–1006.
Javidrad F, Nazari M. A new hybrid particle swarm and simulated annealing stochastic optimization method. Appl Soft Comput 2017;60:634–54.
X. Chen, H. Tianfield, C. Mei, W. Du, and G. Liu, Biogeography-based learning particle swarm optimization, Soft Computing, vol. 21, 2017/12/01 2017, pp. 7519-7541.
Charin C, Ishak D, Mohd Zainuri MAA, Ismail B, Mohd Jamil MK. A hybrid of bio-inspired algorithm based on Levy flight and particle swarm optimizations for photovoltaic system under partial shading conditions. Sol Energy 2021;217:1–14.
Jafari M, Salajegheh E, Salajegheh J. Optimal design of truss structures using a hybrid method based on particle swarm optimizer and cultural algorithm. Structures 2021;32:391–405.
T. A. Khan and S. H. Ling, A novel hybrid gravitational search particle swarm optimization algorithm, Engineering Applications of Artificial Intelligence, vol. 102, 2021/06/01/ 2021, p. 104263.
Z. Wen-Jun and X. Xiao-Feng, DEPSO: hybrid particle swarm with differential evolution operator, in SMC’03 Conference Proceedings. 2003 IEEE International
Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483), 2003, pp. 3816-3821 vol.4.
Epitropakis MG, Plagianakos VP, Vrahatis MN. Evolving cognitive and social experience in Particle Swarm Optimization through Differential Evolution: A hybrid approach. Inf Sci 2012;216:50–92.
H. Liu, Z. Cai, and Y. Wang, Hybridizing particle swarm optimization with differential evolution for constrained numerical and engineering optimization: Elsevier Science Publishers B. V., 2010.
Hao Z, Guo G, Huang H. A particle swarm optimization algorithm with differential evolution. In: 2007 International conference on machine learning and cybernetics. p. 1031–5.
Chen K, Xue B, Zhang M, Zhou F. Hybridising particle swarm optimisation with differential evolution for feature selection in classification. In: 2020 IEEE Congress on Evolutionary Computation (CEC). p. 1–8.
Shi YH, Eberhart R. A modified particle swarm optimizer. New York: IEEE; 1998.
Das S, Mullick SS, Suganthan PN. Recent advances in differential evolution – An updated survey. Swarm Evol Comput 2016;27:1–30.
Qin AK, Huang VL, Suganthan PN. Differential evolution algorithm with strategy adaptation for global numerical optimization. IEEE Trans Evol Comput 2009;13(2):398–417.
Xiao-gen P. A new hybrid differential particle swarm optimization algorithm and application. In: 2020 international conference on computer engineering and intelligent control (ICCEIC). p. 157–62.
Sato M, Fukuyama Y, Iizaka T, Matsui T. Total optimization of energy networks in a smart city by multi-swarm differential evolutionary particle swarm optimization. IEEE Trans Sustainable Energy 2019;10(4):2186–200.
Wang S, Li Y, Yang H. Self-adaptive mutation differential evolution algorithm based on particle swarm optimization. Appl Soft Comput 2019;81:105496.
Sayah S, Hamouda A. A hybrid differential evolution algorithm based on particle swarm optimization for nonconvex economic dispatch problems. Appl Soft Comput J 2013;13(4):1608–19.
Seyedmahmoudian M, Rahmani R, Mekhilef S, Maung Than Oo A, Stojcevski A, Soon TK, et al. Simulation and hardware implementation of new maximum power point tracking technique for partially shaded PV system using Hybrid DEPSO method. IEEE Trans Sustainable Energy 2015;6(3):850–62.
Chen Y, Li L, Peng H, Xiao J, Yang Y, Shi Y. Particle swarm optimizer with two differential mutation. Appl Soft Comput 2017;61:314–30.
Chen Y, Li L, Peng H, Xiao J, Wu Q. Dynamic multi-swarm differential learning particle swarm optimizer. Swarm Evol Comput 2018;39:209–21.
Xin B, Chen J, Zhang J, Fang H, Peng Z-H. Hybridizing differential evolution and particle swarm optimization to design powerful optimizers: a review and taxonomy. IEEE Trans Syst Man Cybern Part C Appl Rev 2012;42(5):744–67.
Zhan Z-H, Zhang J, Li Y, Shi Y-H. Orthogonal Learning Particle Swarm Optimization. IEEE Trans Evol Comput 2011;15(6):832–47.
Gong Y-J, Li J-J, Zhou Y, Li Y, Chung H-H, Shi Y-H, et al. Genetic learning particle swarm optimization. IEEE Trans Cybern 2016;46(10):2277–90.
M. Z. A. N.H. Awad, J.J. Liang, B.Y. Qu, P.N. Suganthan. (2016). Problem definitions and evaluation criteria for the CEC 2017 special session and competition on single objective bound constrained real-parameter numerical optimization. Available: http://www.ntu.edu.sg/home/epnsugan/
Suganthan PN, Hansen N, Liang JJ, Deb K, Chen YP, Auger A, et al. Problem definitions and evaluation criteria for the CEC2005 special session on real- parameter optimization. In: IEEE Congress on Evolutionary Computation. p. 1–50.
Peram T, Veeramachaneni K, Mohan CK. Fitness-distance-ratio based particle swarm optimization. Swarm Intelligence Symp 2003:174–81.
Parsopoulos KE, Vrahatis MN. A unified particle swarm optimization scheme. Int Conf Comput Methods Sci Eng, Ser lecture series on computer & computational sciences Attica. Greece: Vsp International Science; 2004.
Lin A, Sun W, Yu H, Wu G, Tang H. Global genetic learning particle swarm optimization with diversity enhancement by ring topology. Swarm Evol Comput 2018.
Storn R, Price K. Differential evolution – A simple and efficient heuristic for global optimization over continuous spaces. J Global Optim 1997;11:341–59.
