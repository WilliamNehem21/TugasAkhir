Engineering Science and Technology, an International Journal 45 (2023) 101490








Full Length Article
Alexnet architecture variations with transfer learning for classification of wound images
Hüseyin Eldem a,*, Erkan Ülker b, Osman Yas¸ar Is¸ıklı c
a Vocational School of Technical Sciences, Computer Technologies Department, Karamano˘glu Mehmetbey University, Karaman 70100, Turkey
b Faculty of Engineering and Natural Sciences, Department of Computer Engineering, Konya Technical University, Computer Engineering Department, Konya 42500,
Turkey
c Karaman Education and Research Hospital, Vascular Surgery Department, Karaman 70100, Turkey



A R T I C L E I N F O 


Keywords:
Wound image classification Convolutional Neural Networks (CNN) Deep learning
Transfer learning Modified AlexNet
A B S T R A C T 

In medical world, wound care and follow-up is one of the issues that are gaining importance to work on day by day. Accurate and early recognition of wounds can reduce treatment costs. In the field of computer vision, deep learning architectures have received great attention recently. The achievements of existing pre-trained archi- tectures for describing (classifying) data belonging to many image sets in the real world are primarily addressed. However, to increase the success of these architectures in a certain area, some improvements and enhancements can be made on the architecture. In this paper, the classification of pressure and diabetic wound images was performed with high accuracy. The six different new AlexNet architecture variations (3Conv_Softmax, 3Conv_SVM, 4Conv_Softmax, 4Conv_SVM, 6Conv_Softmax, 6Conv_SVM) were created with a different number of implementations of Convolution, Pooling, and Rectified Linear Activation (ReLU) layers. Classification perfor- mances of the proposed models are investigated by using Softmax classifier and SVM classifier separately. A new original Wound Image Database are created for performance measures. According to the experimental results obtained for the Database, the model with 6 Convolution layers (6Conv_SVM) was the most successful method among the proposed methods with 98.85% accuracy, 98.86% sensitivity, and 99.42% specificity. The 6Conv_SVM model was also tested on diabetic and pressure wound images in the public medetec dataset, and 95.33% accuracy, 95.33% sensitivity, and 97.66% specificity values were obtained. The proposed method provides high performance compared to the pre-trained AlexNet architecture and other state-of-the-art models in the literature. The results showed that the proposed 6Conv_SVM architecture can be used by the relevant de- partments in the medical world with good performance in medical tasks such as examining and classifying wound images and following up the wound process.





Introduction

Pressure and diabetic foot ulcers can cause psychological and trau- matic problems when they require a long-term treatment process, as well as the pain effect on patients. The long healing processes of these chronic wounds cause increased costs for patients and governments. As in many subjects in the field of medicine, the evaluation of wound im- ages by computer science is of great importance to contribute to the treatment processes. Recently, many studies have been conducted on the detection, segmentation and classification of wound images in patients [1]. In the medical field, due to the difficulties of obtaining data existing architectures are use Transfer Learning (TL) in medical image
classification problems. In this way, a deep learning (DL) architecture trained on a large dataset can takes advantage of the architecture’s previous knowledge and experience for medical image classification by
using TL principles. Thus, faster or better solutions are provided for different medical problems.
Alexnet architecture [2], is one of the Deep Learning (DL) architec- tures and has gained a great importance among CNN architectures by winning the ImageNet competition in 2012. In AlexNet, the first five layers consist of convolutional layers and the last three layers are fully connected layers. There are also pooling and activation layers among the layers. AlexNet architecture is frequently used in classification problems [3]. In addition, it is seen in the literature that AlexNet architecture is




* Corresponding author.
E-mail address: heldem@kmu.edu.tr (H. Eldem).

https://doi.org/10.1016/j.jestch.2023.101490
Received 17 March 2023; Received in revised form 23 June 2023; Accepted 14 July 2023
Available online 28 July 2023
2215-0986/© 2023 The <Authors>. Karabuk University. Publishing services by Elsevier B.V This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).


Table 1


used successfully in solving different classification problems by making changes (improvements or modifications) on its architecture and even by making use of TL [4–7].
In this paper, AlexNet architecture has been proposed for the clas-
sification of diabetic and pressure ulcer images by modifying it with a different number of layers to increase the classification success. A new wound data set was produced by collecting 2090 wound images from the patients at Karaman Training and Research Hospital in Türkiye. Wound images in the dataset were used as input data in DL architectures. The proposed models focus on the definition of wound images using a combination of different numbers of Rectified Linear Activation (ReLU), Pooling and Convolution layers (3Conv_Softmax, 3Conv_SVM, 4Con- v_Softmax, 4Conv_SVM, 6Conv_Softmax, 6Conv_SVM). Finally, fully connected layer and activation function are used in the original AlexNet architecture. The proposed models classify wound images as granule, necrotic, and slough. In this paper, the Softmax classifier layer used in AlexNet was removed and the SVM classifier was also used instead. Therefore, the evaluation performances of the proposed models with Softmax classifier and SVM classifier were also examined.

Related works

Studies on wound images in the literature are about detection, seg- mentation, and classification of wound images [1,8–10]. [11] performed Binary classification on 1335 wound images collected from patients at
Palo Alto VA Hospital and the Washington University Medical Center, in St. Louis. A positive or negative output of a wound image is produced for each of the 9 classes they have determined and the method called DeepWound. [12], studied 400 images belonging to 4 classes (100 im- ages from each of the venous, diabetic, pressure, and surgical wound types) collected from the AZH Wound and Vascular Center in Milwau- kee, Wisconsin. They made a binary classification of wound images as Surgical and Venous; and a triple classification as Surgical, venous and Diabetic with an Ensemble Deep CNN-based classifier. The success rate of the tests with images belonging to 4 classes is very low with 68.69%. They applied AlexNet architecture on the datasets with the transfer learning technique. In another paper, [13] proposed a CNN architecture called DFU_QUTNet which is tested on 754 foot images collected from patients in Iraq Nasiriyah Hospital Diabetic Center. In the study, the
success of the images on the normal or abnormal classes was measured by making binary classification of the wounds. [14] studied a total of 397 images from Lancashire Teaching Hospitals, of which 292 were from diabetic foot wounds (abnormal) and 105 from healthy patients (normal). They obtained 92.5% accuracy by binary classification of wound images for normal and abnormal classes. [15] determined whether diabetic foot ulcers were infection and ischemia on 1459 new datasets they collected from Lancashire Teaching Hospitals. They used InceptionV3, ResNet50 and InceptionResNetV2 architectures. They achieved a success of 90.3% in binary classification about whether the images are ischaemia or not, and 72.7% in binary classification about whether there is infection. [16] worked on a total of 397 images from Lancashire Teaching Hospitals, of which 292 were from diabetic foot wounds (abnormal) and 105 from healthy patients. They compared the results obtained with the proposed CNN architecture named DFU SPNet with the studies by [13] and [14]. The datasets in the literature are summarized in Table 1.
On the other hand, modified AlexNet architectures are discussed in different studies. Modified AlexNet architectures are suggested in studies such as diabetic retinopathy images [17], x-ray images [18], tumor detection in mammogram images [19,20], plant leaf classifica- tion [21], potatoes classification [22], crop disease detection [23], chest X-Ray images [24], cephalometric radiographs [25], pathological brain research [26], magnetic resonance images [26], chest X-Ray and lung CT scan images [27], M-FISH chromosome images [28], digital breast tomosynthesis 3D Imaging [29], and tomato leaf classification [30]. In some studies, layers such as Convolution and Max Pooling used in AlexNet were added, and in some studies convolution, layers were reduced for extracting more detailed features. In some studies, only transfer learning was performed by changing the number of classes in the relevant study (such as 2, 3, and/or 4) instead of 1000 different classes in AlexNet available in fully connected layer. In addition, for the normalization process, it is aimed to increase the success of the studies by applying different normalization processes such as cross channel normalization and batch normalization instead of local response normalization [17–27,29–38].
When the studies in the literature are examined, the standard Alex-
Net architecture has been used only for the classification of venous, diabetic, pressure, and surgical wound types by [12] specifically for the


	
Pressure Wound	Diabetic Foot Ulcer

Fig. 1. Pressure and Diabetic Wound Image Examples.




Fig. 2. Segmented Input image examples [41].


Fig. 3. Transfer Learning Strategy and Work Flow of proposed Modified AlexNet Structure.


Fig. 4. AlexNet Architecture [2].








Fig. 5. Structure of the proposed (a) 6Conv_Softmax and 6Conv_SVM, (b) 4Conv_Softmax and 4Conv_SVM (c) 3Conv_Softmax and 3Conv_SVM.


classification of wound images.
In this paper, the proposed models are compared with the perfor- mances of traditional DL methods on the same dataset. Pre-trained and state-of-the-art models were used with the principle of TL and results were obtained by applying them to our original wound dataset. AlexNet, googlenet, densenet201, mobilenetv2, resnet18, resnet50, resnet101, shufflenet, nasnetmobile, efficientnetb0, vgg16, vgg19, squeezenet, darknet19, darknet53, inceptionv3, xception, inceptionresnetv2, and nasnetlarge pretrained DL architectures were used in this paper based on the results of previous paper of the authors [39]. All methods were re-
coded by the authors with the training parameters obtained from the experimental results [40] to make a fair comparison. The best per- forming AlexNet architecture among these methods is discussed in this study. The success of the methods is presented using classification per- formance (or called evaluation) metrics which are accuracy (ACC), sensitivity (SEN), specificity (SPE), precision (PRE), and f1-score (F1SCO).


Table 2
Layers of Proposed Modified AlexNet Model Variations and Hyper parameter values (s = stride, p = padding).


Material and method

Dataset, preprocessing and data augmentation

In this paper, at Karaman Training and Research Hospital in Türkiye, 2090 original images collected from different patients in the categories of granule, necrotic and slough were used. Images were obtained with Iphone 7 Plus and 48mp Android operating system mobile phone, and Ipad Pro tablet from a maximum distance of 30 cm to cover the entire wound area. The images are usually 1200×1600 resolution and consist of 1050 pressure sores and 1050 diabetic foot ulcers. In Fig. 1, an example is given from the pictures in the data set.
It is important to segment only the wound area from an image taken from patients to extract the features of wound images to classify with high performance by deep learning methods. The encoder-decoder- based MobileNet-UNet architecture was taken as reference in this paper to separate non-wound parts such as skin, patient clothing, etc. from the original image [41]. Examples of wound images segmented with the MobileNet-UNet architecture are given in Fig. 2. In this way,
only the parts that contain wound information were given formally as input to the architectures used in this study.
In the training phase, all images in the dataset were data augmented with rotation, mirroring, flipping and cropping methods to avoid over- fitting. As a result, a new data set containing a total of 10,500 images, 3500 granules, 3500 necrotic and 3500 sloughs, was produced and used in this paper.

Classification

Determination of granule, necrotic and slough wound types is of great importance in terms of following the treatment stages of the wounds of the patients. In this study, a three-class classification problem as granule, necrotic and slough is solved. In addition, it is aimed to classify the wound images according to tissue type with high accuracy and to investigate the effect of DL models in medical image processing. To provide a solution to this problem, three new architectures with 3, 4, and 6 CNN layers were proposed by modifying the CNN-based AlexNet architecture.  In  addition,  using  the  SVM  classifier  for  these




Fig. 6. The most successful model of the Proposed Modified Methods (6Conv_SVM).



Table 3
Used Parameters Values.
Maximum epoch (ME)	150
Learning rate (LR)	10e-4
Drop factor (DF)	0.5
Drop period (DP)	5
Minibatch size (MBS)	32
Optimizer	Stochastic Gradient Descent with Momentum (SGDM) Dataset Split Ratio	70% Train 10 %Validation, and 20% Test
architectures, it was examined how it performs compared to the existing Softmax classifier in AlexNet.
AlexNet architecture, has the best results on our new dataset and is the focus of this study [39]. The results obtained the proposed model were compared with the results of the literature for similar wound image classification. The TL strategy and the work flow of the proposed system are shown in Fig. 3.




Table 4
Evaluation metrics.
Accuracy	(TP + TN)/(TP + TN + FP + FN)	The rate of the accurate estimations to the total number of estimations
Sensitivity (recall)	TP/(TP + FN)	True Positive Rate: The ratio of TP results to the total number of true positive samples
Specificity	TN/(FP + TN)	True Negative Rate: Ratio of TN results to total actual number of negative samples
Precision	TP/(TP + FP)	Positive Predictive Value: Proportion of positive samples correctly estimated from all samples estimated to be
positive

Dice Similarity (F1 Score)
(2*TP)/(2*TP + FP + FN)	Harmonic mean of precision and sensitivity




Proposed models of AlexNet with variations

This section details the proposed modified AlexNet architectures for classification of wound images. It is a CNN architecture developed by the original AlexNet architecture [2], with an input image size of 227×227. AlexNet with 8 layers depth is the winner of ILSVRC 2012 competition. The first 5 layers are convolutional and the last 3 layers are fully con- nected. There are also activation and pooling layers among the layers. It has an important place among CNN models [42]. Classic AlexNet ar- chitecture is presented in Fig. 4.
In this study, three new models were proposed, by increasing and decreasing the number of convolution layers. In addition, all three models were discussed both with the Softmax classifier as in the original AlexNet architecture and with the SVM classifier. In this way, it was examined how the convolution layer in the CNN architecture would affect and improve the classification result. Finally, the effect of Softmax and SVM Classifiers on these three proposed architectures were also investigated. The structure of all three proposed methods is shown in Fig. 5. Hyper parameters were provided by experimental results. The information and hyper parameters of the layers are presented in Table 2. The architecture with six Convolution layers in Fig. 5(a) has 6 Convolution layers with 11×11, 5×5, 3×3, 3×3, 3×3, and 3×3 filters,
respectively. Each Convolution layer has 96, 256, 384, 384, 384, 256
filters, 0, 2, 1, 1, 1 and 1 padding, and ReLU activation function, respectively. The architecture with four Convolution layers in Fig. 5(b) has 4 Convolution layers with 11×11, 5×5, 3×3 and 3×3 filters,
respectively. Each Convolution layer has 96, 256, 384, 256 filters 0, 2, 1
and 1 padding, and ReLU activation function, respectively. The archi- tecture with three Convolution layers in Fig. 5(c) has 3 Convolution layers with 11×11, 5×5 and 3×3 filters, respectively. Each convolution layer has 96, 256, 384 filters, 0, 2 and 1 padding and ReLU activation function, respectively.
Rectified Linear Unit activation layer (ReLu) improves learning speed and classification accuracy by vanishing the gradient problem [43]. In all three models, Maximum Pooling layers with 3×3 filter size were used after Convolution and ReLU layers. In this way, the compu- tational cost of the feature map is reduced, valuable features (valuable feature elements) are retained and classification accuracy is increased [44].
In this paper, the proposed models were compared and the most successful model was found to be the 6Conv_SVM model with 6 convolution layers. The layers and parameter values of the 6Conv_SVM model are given in Fig. 6. A comparison of the results obtained by proposed models is presented in Section 4.
Experimental results

In this study, the performances of the six proposed models were evaluated in our original diabetic and pressure wound images dataset collected from patients through a specialist medical doctor. All methods were implemented on Matlab platform. In the Experimental Results, a computer with technical specifications Xeon Silver 4114 2.2 GHz pro- cessor, 32 GB RAM, NVIDIA Quadro P5000 (×2) GPU was used for training and testing processes.
In all experiments, 16 mini batch size, stochastic gradient descent with momentum (SGDM) optimizer algorithm, 0.5 decay (drop factor) and 5 drop period parameters were used with learning rate 10e-4. Each model was run with 150 epochs, by separating 70% of the images in our dataset as train, 10% as validation and 20% as test data. Training data was not used as validation and testing data. The parameter values used are also given in Table 3.

Performance metrics

To evaluate the performances of the six models proposed in this study, a confusion matrix of each model was produced. Performances are compared using the evaluation metrics Accuracy (ACC), Sensitivity (SEN), Specificity (SPE), Precision (PRE), and f1 Score (F1SCO). Eval- uation metrics are given in Table 4. TP, TN, FP, and FN stand for true positive (correctly confirmed specimen), true negative (correctly rejec- ted specimen), false positive (falsely confirmed specimen), and false negative (falsely rejected specimen), respectively.


Fig. 7. Graphical Comparison of Evaluation Rates obtained by SVM Classifier.


Table 5
Comparison results of proposed models (All values in %).


	

	


Fig. 8. Graphical Comparison foreach Evaluation Metric obtained by SVM Classifier.


Table 6
Confusion matrix for proposed 3Conv_SVM model.
Table 8
Confusion matrix for AlexNet model.




Table 7
Confusion matrix for proposed 4Conv_SVM model.
Table 9
Confusion matrix for proposed 6Conv_SVM model.





Table 10
Medetec Dataset Results (All values in %).


The results on the our new dataset

First of all, the proposed methods were tested on our dataset under specified experimental conditions. The results are listed in Table 5. According to Table 5, the 3 Convolution layer method performed poorly when used with both classifiers (3Conv_Softmax and 3Conv_SVM). The best results were obtained in ACC, SEN, SPE, PRE, F1SCO metrics with a success rate of over 98% when our proposed model with 6 Convolution layers was used together with the SVM classifier (6Conv_SVM).
The proposed model with 6 Convolution layers also showed a per- formance of over 94% when used with the Softmax classifier. In the experiments with both classifiers, it is seen that the 6Conv_Softmax and 6Conv_SVM models obtained by increasing the convolution layer in- crease the success. In addition, similar experimental studies have been carried out for architectures with seven or more layers (max = 10) by increasing the Convolution layer. These methods and their details were not included in this paper, since there was no improvement in the results of the evaluation metrics.
6Conv_SVM recognizes the properties of wound images. It was found to be a very effective model on our wound dataset due to its high clas- sification rates. The visual comparison of the SVM classifier metric values in Table 5 is given in Fig. 7. In addition, the results of the SVM classifier, which produces better results than the Softmax classifier, are given in Fig. 8 for each metric. The balanced and high results of the 6Conv_SVM model, which is the best of the proposed model variations, can be seen in Figs. 7 and 8.
Confusion matrices are also given in Tables 6–9 to evaluate the
performances of the classifier models. Confusion matrices provide in- formation about whether the images used in testing the classification performance of the methods belong to the real class. The actual class values are shown in each column, and the predicted results by the model are seen in each row.


The results on the Medetec dataset

The 6Conv_SVM model was tested with the same experimental con- ditions on the Medetec dataset, which is presented as open source in the literature. All 177 images of pressure wounds and 49 diabetic foot ulcers with different resolutions (usually 560×410) in the Medetec dataset were used [45]. The results are listed in Table 10.
In Table 10, the results of 6Conv_SVM are presented with the eval- uation metric results of ACC, SEN, SPE, PRE and F1SCO. As seen in Table 10, evaluation metric results obtained by using 6Conv_SVM on this Medetec dataset are lower than the results in our dataset. It was
observed that the success decreased due to the low number of images. However, the 6Conv_SVM model, which is the most successful among the proposed methods, still achieved over 90% success.

Comparison of proposed architecture with literature results

A standard database containing wound images has not been used in the literature. Therefore, it is not possible to make a fair comparison. The studies were carried out on researchers’ own image data set collected
from specific institutions/hospitals etc. In particular, there is no study
showing which of the granule, necrotic and slough classes diabetic foot ulcer and pressure ulcer images belong to. Studies have generally inferred on a binary classification that shows whether the wound images considered in the relevant study belong to that type, rather than tissue classification of the wound image. [12] studied which of the venous, diabetic, pressure, and surgical classes wounds belongs to. In the liter- ature comparison, 3-class Classification achievements of this study were discussed.
Papers that classify similar or different types of wound images are discussed in comparisons since they are similar in terms of image properties.
The results of 6Conv_SVM, which obtained the best results from the Modified Alexnet architectures proposed in this paper, and the results of other studies that classify similar wound images in the literature, are given in Table 11 with the evaluation metric results of ACC, SPE, PRE and F1SCO.
[11,13–16] made a binary classification on their datasets from the studies used in the comparison presented in Table 11. In the study, in
which 3 classes were used in the data set [12], a classification was made according to wound types.
All metric results in Table 11 are usually above 70%. In addition, the metric values given in the studies were specified and the others were left blank. In the first study [11] 93% SEN value was high, while other ACC, SPE, PRE and F1SCO values were low. In another study [12], metric results were found to be approximately 87% in the evaluation of 400 images collected. In the study, which included binary classification ex- periments on 754 images consisting of only diabetic foot wound images, a PRE value of 95.4 was obtained for 754 images [13]. Goyal et al. [14,15], who classified diabetic foot wounds in 2018 and 2022, obtained 92.5% ACC with binary classification on 397 images in the first study. In their other studies, they obtained 90.3 % ACC in ischemia/non-ischemia classifications, and 72.7% ACC in infection/non-infection classifications on 1459 pictures. In the last study [16] used in the comparison in Table 11, they obtained between 92% and 96% values in all evaluation metrics in their experiments on 397 diabetic foot ulcer images. When the results obtained from the literature and the results obtained with the 6Conv_SVM model proposed in this study are compared, the success over 98% in each evaluation metric is better than the literature models in Table 11.

Discussion

In this paper, it is discussed how the deep learning architecture


Table 11
Literature comparison (All values in %).



AlexNet method is used for chronic wound research. It reveals the classification of wounds according to tissue characterization. MobileNet-Unet architecture based on encoder-decoder structure is used for image segmentation. Alexnet architecture, which is one of the deep learning architectures, and its different modifications are discussed and its performance in wound image classification is examined.
In the medical world, wound care and follow-up is one of the issues that are studied more and more every day. Accurate and early recog- nition of chronic wounds can reduce treatment costs. Wound classifi- cation is also used in national reports on quality to analyze clinical, economic and educational outcomes. Nurses and doctors, who are in- tegral members of the healthcare team, must ensure that their data is accurate, consistent and reliable. As in many subjects in the medical field, the evaluation of wound analysis by computer science is of great importance in terms of contributing to the treatment processes. The
number of wound care specialists is insufficient in the world. That’s why certain surgical units provide support in some hospitals. Wound care
nurses are the biggest supporters of physicians. Therefore, nurses have to have a knowledge of the wound healing process and make a complete patient diagnosis before focusing on the patient’s wound.
Nurses also have important duties in the preparation of the wound
bed. Recognition and management of wound bed problems, such as necrotic tissue, excessive exudate, results in a well-prepared wound bed and optimal healing. During the Covid process, the number of ampu- tated feet has increased considerably, as he could not come to the hos- pital due to a diabetic foot wound and could not receive the correct diagnosis and treatment.
Advances in wound products have brought along a broad knowledge of the biology of chronic wounds. Analyzing the hundreds of types of wound products well, being aware of these products, correct and appropriate use requires a strong algorithm. In particular, proper wound bed preparation requires proper classification. This preparation includes stimulation of wound edges to eliminate dead tissue, control bacteria, promote inflammation, moisture balance, and epidermal migration. In general, if a wound bed is suitable for grafting, gene therapy, and other advanced methods, it should be very well vascularized, non-infected, free of fibrinous material, eschar, and excessive exudate in the wound. In short, wound bed preparation can be defined as bringing the wound bed to a level that will allow it to accept new treatment products. In this whole process, it is the qualified wound classification that determines the clinical course.

Conclusion

Achieving high accuracy in classification of wound images is of great importance for the improvement of clinical decision-making processes. Every study on wound images collected from patients makes a great contribution to the literature in terms of meeting the ultimate needs such as diagnosis and care in the real world. AlexNet architecture, which is one of the deep learning methods, is an architecture that is frequently studied in the literature on image classification. To increase the success of this architecture in the related classification problem, different im- provements are made on the architecture. In this paper, the replacement of the classifier in the last classification layer in the normal AlexNet architecture and the classification success of the proposed CNN archi- tectures on wound images using different convolution layers are dis- cussed. Instead of the Softmax classification layer of the proposed CNN architectures, the SVM classification algorithm is also used. Transfer learning success performances in CNN architectures are also compara- tively examined. The proposed architectures have been retrained. Considering all three methods (3Conv_Softmax, 4Conv_Softmax and 6Conv_Softmax) recommended for classification of wound images and the performances of these methods when using the SVM classifier (3Conv_SVM, 4Conv_SVM and 6Conv_SVM), it was seen that the 6Con- v_Softmax method achieved the most successful evaluation results. It was observed that the convolution layer added to the AlexNet
architecture increases the classification accuracy. The model with 6 Convolution layers (6Conv_Softmax) was the most successful method among the methods recommended with 98.85% accuracy, 98.85% sensitivity, 99.42% specificity. In future studies, it can be aimed to in- crease performance by making modifications or improvements on other methods whose performance is close to the AlexNet architecture.

Declaration of Competing Interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

Acknowledgments

This study was supported by the Scientific Research Project at Konya Technical University, Konya, Turkey (No. 231113005).

References

R. Zhang, D. Tian, D. Xu, W. Qian, Y. Yao, A survey of wound image analysis using
deep learning: classification, detection, and segmentation, IEEE Access 10 (2022) 79502–79515.
A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep
convolutional neural networks, Adv. Neural Inf. Proces. Syst. 25 (2012).
Alom, M.Z., et al., The history began from alexnet: A comprehensive survey on deep learning approaches. arXiv preprint arXiv:1803.01164, 2018.
L. Alzubaidi, M.A. Fadhel, O. Al-Shamma, J. Zhang, J. Santamaría, Y.e. Duan, S.
R. Oleiwi, Towards a better understanding of transfer learning for medical imaging: a case study, Appl. Sci. 10 (13) (2020) 4523.
SanaUllah Khan, N. Islam, Z. Jan, I. Ud Din, J.J.P.C. Rodrigues, A novel deep learning based framework for the detection and classification of breast cancer using
transfer learning, Pattern Recogn. Lett. 125 (2019) 1–6.
X. Yu, J. Wang, Q.-Q. Hong, R. Teku, S.-H. Wang, Y.-D. Zhang, Transfer learning for medical images analyses: A survey, Neurocomputing 489 (2022) 230–254.
P. Kora, et al., Transfer learning techniques for medical image analysis: A review,
Biocybernet. Biomed. Eng. (2021).
C. Chakraborty, Computational approach for chronic wound tissue characterization, Inf. Med. Unlocked 17 (2019), 100162.
F. Ferreira, I.M. Pires, V. Ponciano, M. Costa, M.V. Villasana, N.M. Garcia,
E. Zdravevski, P. Lameski, I. Chorbev, M. Mihajlov, V. Trajkovik, Experimental Study on Wound Area Measurement with Mobile Devices, Sensors 21 (17) (2021) 5762.
C. Liu, X. Fan, Z. Guo, Z. Mo, E.-C. Chang, Y. Xu, Wound area measurement with 3D transformation and smartphone images, BMC Bioinf. 20 (1) (2019).
Shenoy, V.N., et al. Deepwound: Automated postoperative wound assessment and surgical site surveillance through convolutional neural networks. in 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2018. IEEE.
B. Rostami, D.M. Anisuzzaman, C. Wang, S. Gopalakrishnan, J. Niezgoda, Z. Yu, Multiclass Wound Image Classification using an Ensemble Deep CNN-based Classifier, Comput. Biol. Med. 134 (2021) 104536.
L. Alzubaidi, M.A. Fadhel, S.R. Oleiwi, O. Al-Shamma, J. Zhang, DFU_QUTNet:
diabetic foot ulcer classification using novel deep convolutional neural network, Multimed. Tools Appl. 79 (21-22) (2020) 15655–15677.
M. Goyal, N.D. Reeves, A.K. Davison, S. Rajbhandari, J. Spragg, M.H. Yap, Dfunet:
Convolutional neural networks for diabetic foot ulcer classification, IEEE Trans. Emerg. Topics Comput. Intell. 4 (5) (2020) 728–739.
M. Goyal, et al., Recognition of ischaemia and infection in diabetic foot ulcers:
Dataset and techniques, Comput. Biol. Med. 117 (2020), 103616.
S.K. Das, P. Roy, A.K. Mishra, DFU_SPNet: A stacked parallel convolution layers based CNN to improve Diabetic Foot Ulcer classification, ICT Express 8 (2) (2022)
271–275.
T. Shanthi, R. Sabeenian, Modified Alexnet architecture for classification of diabetic retinopathy images, Comput. Electr. Eng. 76 (2019) 56–64.
S.Q. Salih, H.K. Abdulla, Z.S. Ahmed, N.M.S. Surameery, R.D. Rashid, Modified
alexnet convolution neural network for covid-19 detection using chest x-ray images, Kurdistan J. Appl. Res. (2020) 119–130.
Boudouh, S.S. and M. Bouakkaz. Breast cancer: Using deep transfer learning
techniques alexnet convolutional neural network for breast tumor detection in mammography images. in 2022 7th International Conference on Image and Signal Processing and their Applications (ISPA). 2022. IEEE.
Omonigho, E.L., et al. Breast cancer: tumor detection in mammogram images using modified alexnet deep convolution neural network. in 2020 International Conference in Mathematics, Computer Engineering and Computer Science (ICMCECS). 20IEEE.
S.A. Wagle, H. R, Comparison of Plant Leaf Classification Using Modified AlexNet and Support Vector Machine, Traitement du Signal 38 (1) (2021) 79–87.
M.A. Muthiah, E. Logashanmugam, N.M. Nandhitha, C.K. kumar, D. Hariteja,
Performance evaluation of conventional CNN architectures and modified ALEXNET



for the classification of potatoes by thermal imaging, Russ. J. Nondestr. Test. 56 (9) (2020) 718–726.
Yeh, J.-F., S.-Y. Wang, and Y.-P. Chen. Crop Disease Detection by Image Processing
Using Modified Alexnet. in 2021 IEEE 3rd Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability (ECBIOS). 2021. IEEE.
M. Kaur, V. Kumar, V. Yadav, D. Singh, N. Kumar, N.N. Das, A. Dogra,
Metaheuristic-based deep COVID-19 screening model from chest X-ray images,
J. Healthcare Eng. 2021 (2021) 1–9.
K.-S. Lee, J.-J. Ryu, H.S. Jang, D.-Y. Lee, S.-K. Jung, Deep convolutional neural networks based analysis of cephalometric radiographs for differential diagnosis of orthognathic surgery indications, Appl. Sci. 10 (6) (2020) 2124.
S. Lu, Z. Lu, Y.-D. Zhang, Pathological brain detection based on AlexNet and transfer learning, J. Comput. Sci. 30 (2019) 41–47.
A. Bhandary, G.A. Prabhu, V. Rajinikanth, K.P. Thanaraj, S.C. Satapathy, D.
E. Robbins, C. Shasky, Y.-D. Zhang, J.M.R.S. Tavares, N.S.M. Raja, Deep-learning framework to detect lung abnormality–A study with chest X-Ray and lung CT scan images, Pattern Recogn. Lett. 129 (2020) 271–278.
V. Kanimozhi, M. Balasubramani, R. Anuradha, Hierarchal Bayes model with
AlexNet for characterization of M-FISH chromosome images, Med. Biol. Eng. Compu. 59 (7) (2021) 1529–1544.
A.M.A. El-Shazli, S.M. Youssef, A.H. Soliman, Intelligent Computer-Aided Model
for Efficient Diagnosis of Digital Breast Tomosynthesis 3D Imaging Using Deep Learning, Appl. Sci. 12 (11) (2022) 5736.
H.-C. Chen, A.M. Widodo, A. Wisnujati, M. Rahaman, J.-W. Lin, L. Chen, C.-
E. Weng, AlexNet convolutional neural network for disease detection and classification of tomato leaf, Electronics 11 (6) (2022) 951.
A. Boudiaf, S. Benlahmidi, K. Harrar, R. Zaghdoudi, Classification of surface defects
on steel strip images using convolution neural network and support vector machine, J. Fail. Anal. Prev. 22 (2) (2022) 531–541.
R. Ghulanavar, K.K. Dama, A. Jagadeesh, Diagnosis of faulty gears by modified
AlexNet and improved grasshopper optimization algorithm (IGOA), J. Mech. Sci. Technol. 34 (10) (2020) 4173–4182.
S.K. Gundewar, P.V. Kane, Bearing Fault Diagnosis in Induction Motor Using Modified AlexNet Algorithm, Springer, 2020. 2021..
J. Jing, A. Dong, P. Li, K. Zhang, Yarn-dyed fabric defect classification based on convolutional neural network, Opt. Eng. 56 (09) (2017) 1.
V. Kanimozhi, M. Balasubramani, R. Anuradha, Hierarchal Bayes model with AlexNet for characterization of M-FISH chromosome images, Med. Biol. Eng.
Compu. 59 (7–8) (2021) 1529–1544.
S. Sameer, et al., Pest and Disease Detection From Plant Leaves Using Enhanced AlexNet Model, IEEE, 2021.
D. Xie, et al., Deepfake Detection on Publicly Available Datasets Using Modified AlexNet, IEEE, 2020.
Z. Zhu, et al., Extreme Weather Recognition Using Convolutional Neural Networks, IEEE, 2016.
H. Eldem, E. Ülker, O.Y. Is¸ ıklı, Classification of Pressure and Diabetic Chronic Wound Tissue Images with Deep Learning Methods, (In Review) (2022).
H. Eldem, E. Ülker, O.Y. Is¸ ıklı, Effects of Training Parameters of AlexNet Architecture on Wound Image Classification, Traitement du Signal 40 (2) (2023)
811–817.
H. Eldem, E. Ülker, O. Yas¸ar Is¸ıklı, Encoder–decoder semantic segmentation models for pressure wound images, Imag. Sci. J. (2023) 1–12.
Sunitha Nandhini, A., et al. Pancreases Segmentation and Classification Based on RCNN and AlexNet. in International Conference on Computing, Communication, Electrical and Biomedical Systems. 2022. Springer.
Q. Li, et al., Medical Image Classification With Convolutional Neural Network, IEEE, 2014.
S. Pang, Z. Yu, M.A. Orgun, A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images, Comput. Methods
Programs Biomed. 140 (2017) 283–293.
Steve, T. Medetec Pressure Wound Dataset. 2021; Available from: http://www. medetec.co.uk/slide scans/pressure-ulcer-images-a/index.html, http://www. medetec.co.uk/slide scans/pressure-ulcer-images-b/index.html.
