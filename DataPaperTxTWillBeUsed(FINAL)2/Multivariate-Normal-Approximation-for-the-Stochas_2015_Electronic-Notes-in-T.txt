Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 316 (2015) 67–82
www.elsevier.com/locate/entcs

Multivariate Normal Approximation for the Stochastic Simulation Algorithm: Limit Theorem and Applications
Vincent Picard1
Universit´e de Rennes 1 IRISA UMR 6074
INRIA Dyliss Rennes, France
Anne Siegel2
CNRS IRISA UMR 6074
INRIA Dyliss Rennes, France
J´er´emie Bourdon3
Universit´e de Nantes
LINA UMR 6241 – Computational Biology (ComBi) group INRIA Dyliss
Nantes, France

Abstract
Stochastic approaches in systems biology are being used increasingly to model the heterogeneity and the intrinsic stochasticity of living systems, especially at the single-cell level. The stochastic simulation algo- rithm – also known as the Gillespie algorithm – is currently the most widely used method to simulate the time course of a system of bio-chemical reactions in a stochastic way.
In this article, we present a central limit theorem for the Gillespie stochastic trajectories when the living system has reached a steady-state, that is when the internal bio-molecules concentrations are assumed to be at equilibrium. It appears that the stochastic behavior in steady-state is entirely characterized by the stoichiometry matrix of the system and a single vector of reaction probabilities.
We propose several applications of this result such as deriving multivariate confidence regions for the time course of the system and a constraints-based approach which extends the flux balance analysis framework to the stochastic case.
Keywords: Stochastic Simulation, Multivariate statistics, Random walks


1 Email: vincent.picard@irisa.fr
2 Email: anne.siegel@irisa.fr
3 Email: jeremie.bourdon@univ-nantes.fr

http://dx.doi.org/10.1016/j.entcs.2015.06.011
1571-0661/© 2015 The Authors. Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

The quantitative analysis of systems of coupled chemical reactions also known as reaction networks is a major center of interest in systems biology. Two main math- ematical frameworks have been proposed to investigate their kinetic behaviour [12]. On the one hand the ordinary differential equations (ODEs) provide deterministic trajectories for the average quantities of molecules at the population level. On the other hand the chemical master equation gives a probabilistic description of the trajectories at the single-cell level. In both cases and especially in the latter one the solutions rapidly become intractable as the size and the complexity of the net- works increase. As a consequence, computational methods have been thoroughly developed during the last decades to provide insight into the dynamics of reaction networks.
In the world of ODEs, one can use numerical analysis algorithms to compute approximate trajectories of the average quantities of molecules. The main issue of this approach is that a perfect knowledge of the system is required to derive an appropriate system of ODEs in the first place. In other words, all the molecular species, reactions, kinetic laws (law of mass actions, Michaelis-Menten, . . . ) and their parameters must be known. This level of knowledge is far beyond the scope of the current experimental possibilities and so the quantitative analysis of large metabolic networks cannot be obtained from this approach. A successful method, with respect to the aforementioned difficulties, is to consider the particular class of the ODEs solutions where the speeds of the internal molecular concentrations are equal to zero. In that case, the network is in a simpler state referred to as the steady- state where the reactions are balanced and the internal metabolite concentrations are constant. This method, named flux balance analysis (FBA) [16], is a constraint- based approach that takes advantage from the computational advances in linear programming to explore the fluxomic capabilities of reaction networks. Its strength is mainly due to the little required knowledge about the network: basically, the only needed information is the stoichiometry matrix. Consequently, FBA has lead to numerous applications and extensions such as flux coupling analysis.
While ODEs have become widespread in the systems biology community they fail to provide a model at the individual scale that can exhibit stochastic behaviours. Yet, multiple biological examples have been presented to demonstrate that life is inherently stochastic [1,5]. Moreover, the current development of single-cell biology techniques [11] (fluoresence, microscopic imaging, mass spectrometry) provide more and more experimental data at the individual scale. As a consequence, there is currently an important need for probabilistic methods in systems biology [19]. For instance, consider the reaction network on Figure 1 together with a (fictitious) experimental time serie that represents the concentrations of molecules for a single cell. A frequent question in systems biology, named model validation, is to decide whether the proposed set of reactions are consistent with the observed data or not. At the single-cell level stochastic fluctuations exist, especially when the quantities of molecules are small, so ODEs models cannot help much since they are inherently deterministic and cannot allow one to discriminate between incorrect trajectories




Fig. 1. An example of reaction network (slightly modified from [15]) with experimental data.



and normal stochastic fluctuations.
The probabilistic counterpart of ODEs is the chemical master equation which was believed to be computationally intractable until D. T. Gillespie popularized a simple yet efficient kinetic Monte Carlo algorithm [7] to simulate exact probabilis- tic trajectories. The algorithm, referred to as the stochastic simulation algorithm (SSA) has become the cornerstone of the probabilistic kinetic methods in systems biology [20], multiple biological applications have been presented [14,1] and im- proved [6] versions have been proposed in the literature. Hence, the SSA and its variations can be seen as the probabilistic counterpart of the numerical analysis algorithms for ODEs. However, using the SSA leads to the same problems as the ODEs approach: a perfect knowledge of the system is required including proba- bilistic kinetic parameters. These parameters are even more difficult to infer since numerous individual trajectories are necessary. Another known problem is that the algorithm becomes computationally too expensive when the simulation time is too long or when the number of reaction events explodes. To deal with this issue, ap- proximated versions [2,9] of the SSA have been proposed as well as approximations of the chemical master equation [8,18].
The aim of this work is to demonstrate that the steady-state analysis that has been used to derive FBA from ODEs is also completely within the reach of the probabilistic methods. We derive the consequences of applying the same simpli- fying assumption (that is, the system as the system has reached a steady-state in which the quantities of internal chemical species are constant) to the SSA. The consequence is the existence of a multivariate central limit theorem (CLT) for the trajectories where the limiting distribution is specified by the stoichiometry matrix and reaction probabilities which are the analogous of FBA fluxes. Thus our ap- proach needs as much information as FBA, that is to say mainly the stoichiometry, but is inherently stochastic. In the article, we derive the CLT for the stochastic trajectories of a reaction network in steady-state. Then, we present multiple theo- retical and practical applications of this result. For instance, we derive conﬁdence regions for the aforementioned model validation problem (Figure 1) and we propose a constraints-based approach, similar to FBA, to integrate experimental data.

The SSA in Steady-State
We study systems of coupled chemical reactions known as reaction networks. A reaction network consists of n molecular species X1,..., Xn that are involved in m chemical reactions
Ri :	ai,1X1 + ··· + ai,nXn → bi,1X1 + ··· + bi,nXn	(1 ≤ i ≤ m).	(1)
The parameters ai,j, bi,j ∈ N are the stoichiometry coefficients of the reaction net- work. The number ai,j represents the quantity of Xj molecules consumed by the reaction Ri and the number bi,j represents the quantity of Xj molecules produced by the reaction Rj. The global effect of the reactions on the molecular quanti- ties is often summarized by the stoichiometry matrix S = (si,j)1≤i≤m, 1≤j≤n where si,j = bi,j − ai,j. In our notations, each row of the stoichiometry matrix repre- sents the effect of one reaction on the molecular quantities. Reversible reactions are modeled using two irreversible reactions.
In this work we study the dynamics of reaction networks, that is, the time evolution of the molecular quantities of a reaction network. We denote by xi the number of Xi molecules at time t ≥ 0 and xt ∈ Rn the column vector of all quantities at time t. The trajectory of the system is the family (xt)t∈R. Let ei = (0, ··· , 0, 1(i), 0, ··· , 0)T be the Rm-canonical basis vectors and assume that we know the initial state x0 of the system. We consider that the stochastic process xt is a jump process, that is, there exists an increasing sequence of random events (tk)k∈N such that xt is constant on each interval [tk, tk+1[ and t0 = 0. At each time tk (k > 0), one reaction randomly occurs and the value of x changes according to the occurring reaction, thus one can write
∀k ∈ N,	xtk+1 = xtk + S eμk+1 ,	(2)
where (μk)k∈N∗ is a random variable representing the index of the reaction that occurs at time tk and ST is the transpose of the stoichiometry matrix. The inter- reaction times τk are also random variables defined as τk = tk − tk—1 for k ∈ N∗. Notice that the stochastic process is entirely determined by x0 and the distribution of (μk, τk)k∈N∗ . In the article, we mainly focus on the stochastic process (yk)k∈N = (xtk )k∈N referred to as the embedded process which represents the succession of changes in the chemical species quantities.
The Stochastic Simulation Algorithm
The SSA [7] is a kinetic Monte Carlo methods that implements a choice for (μk+1, τk+1) based only on the current molecular quantities xtk . This assumption is justified when considering homogeneous well stirred systems in thermal equilib- rium. The fundamental idea behind the SSA is that the reaction waiting time for each possible combination of the Ri reactants is independent and randomly expo- nential with a parameter ci named the stochastic kinetic rate. This fundamental assumption leads to a simulation of correct probabilistic trajectories with regard

to the chemical master equation [7]. In the SSA, it is important to notice that the exponential assumption concerns each possible instance of a chemical rule, so the waiting time for any instance of a particular chemical reaction is exponential with parameter hi = ci × {reactant combinations}. This value referred to as the propensity of the reaction increases with the available quantities of reactants.
The Steady-State
Inspired from the success of steady-state analysis for ODEs, that is to say FBA approaches, we aim to investigate steady-state analysis in the context of probabilis- tic dynamics. First, let us now introduce a formal definition of the steady-state conditions for reaction networks that form the initial assumptions of our analysis.
Definition 1 A reaction network follows the steady-state conditions if all τk and μk are mutually independent, (τk)k are identically distributed, and (μk)k are iden- tically distributed.
If the steady-state conditions hold then the stochastic process (xt) is entirely determined by the initial state x0, the stoichiometry matrix S and both the distributions of (τk)k∈N and (μk)k∈N. The reaction probabilities column vector p = (Pr (μk = i))1≤i≤m describes the distribution of (μk)k∈N at steady-state. With- out loss of generality, we assume that pi is positive for every i (otherwise, Ri never occurs and can be removed from the system).
Importantly, the steady-state conditions hold for an execution of the SSA as soon as the propensities are constant.
Proposition 2.1 In the SSA, if all propensities hi are constant at each execution of the iteration, then the steady-state condition holds.
Indeed, according to the SSA when the propensities hi are constant, (μk, τk)k∈N∗
are sampled independently using a Bernoulli distribution with reaction probabili-

ties pi =
hi
m hl
and the inter-reactions times are exponentially distributed with

parameter Σl=m1	h . To define our framework, we will consider the strong hypothe-
i
sis that the system has constant propensities. Notice that this excludes numerous oscillating systems such as the Lotka-Volterra dynamics.
Central Limit Theorem for the Embedded Process
We focus on the embedded process (yk) = (xtk ) which describes the succession of changes in the molecular quantities. It is straightforward to establish from (2) that


∀k ∈ N,	yk = y0 + S
k

l=1

eμl

.	(3)

The stochastic process qk = Σk	eμ counts all the occurrences of each reaction
l
until time tk, so we refer to (qk) as the reaction counting process (RCP). In this sec-
tion we demonstrate that, under the steady-state conditions, the embedded process is a random walk that admits a central limit theorem. We proceed in two steps,

first we prove this result on the RCP (which corresponds to the case S = Idn) and then we use an affine transformation to obtain the general result.
We remark that if the steady-state conditions hold then the RCP is a random walk [4,10] in Nm, since it has independent and identically distributed increments eμl . In other words, qk+1 is obtained from qk by randomly selecting a dimen- sion according to the probabilities p and then moving forward this direction. It is well known that this type of Markovian processes [4,3] admits a central limit the- orem (CLT). Formally, the result can be obtained using the classical multivariate CLT [17].
Proposition 2.2 Under the steady-state conditions, the RCP qk = Σk	eμ  con-
l
verges to a multivariate Gaussian distribution with covariance matrix V (p) =
diag(p) − ppT:
1	Q
√k (qk − kp) k→−→+∞ N (0,V (p)) .	(4)
Now that we have demonstrated that the RCP converges to a normal distribu- tion, we can notice that by virtue of equation (3), the embedded process yk is simply an affine transformation of the RCP. Thus, the embedded process is also a random walk where the possible steps are the affine transformation of the canonical basis vectors (see Figure 2 for an example). Due to the stability of normal distributions


R2(p2)
R3(p3)
0	R1(p1)

k l=1

eμl k
random walk RCP

Fig. 2. Illustration of the random walk behaviour on the example system {X → 2Y ; ∅ → Y ; ∅ → X + Y }.
with regard to affine transformations, the embedded process also tends to a normal distribution and we obtain a multivariate CLT for the embedded process.
Proposition 2.3 (Central limit theorem for the embedded process) Under the steady-state conditions, the the embedded process yk = xtk converges in distribution to a multivariate Gaussian distribution with covariance matrix W (S, p)= ST diag(p) − ppT S:

 1  

T	Q
 	

In other words, the yk distribution asymptotically tends to a multivariate Gaussian distribution N y0 + kSTp, kW (S, p) . Our contribution includes the analytical ex- pressions for the mean and the variance-covariance matrix which depend only on S and p. In the appendix, we also provide the reader with a complete characteriza- tion of the degenerated cases for the limiting distribution depending on the form of the stoichiometry matrix. The rest of the article presents theoretical and practical

applications of this asymptotic result.

Confidence ellipsoids and accumulation speeds
In this section we introduce other convergence results that are consequences of the CLT. The first result is the introduction of α-confidence ellipsoids that are likely sets of possible values for yk with asymptotic probability 1 − α. We present an illustrative application to the model validation problem. The second result is a convergence proposition which demonstrates the relation between the steady-state reaction probabilities and the practically relevant notion of ratios of accumulation speeds.

Conﬁdence ellipsoids
The value of a real random variable with known probability distribution is often estimated using confidence intervals. A confidence ellipsoid is a generalization of a confidence interval when the random variable is a Gaussian vector. Let us start by giving a formal definition of conﬁdence ellipsoids.
Proposition 3.1 (confidence ellipsoid) Let S be a m× n stoichiometry matrix,
p a positive probability vector, α ∈]0, 1] a tolerance error and y0 ini tial qua ntities.

1 − α where Bn(0, tα) is the Rn centered ball of radius tα and  ·  is the Eu- clidean norm. Assume that ker W (S, p)= {0} and consider V ∈ GLn(R) such that W (S, p)= VV . Then the subset

n	1	—1 
T  ¨

E (S, p, y0, α, k)=	z ∈ R	|	¨ √k V	z − y0 − kS p ¨ ≤ tα	(6)
does not depend on the particular choice of V and is a non degenerated Rn-ellipsoid
called the α-confidence ellipsoid.
Remark that a well-suited V can be calculated using the Choleski decomposi- tion [13] or the spectral decomposition. The idea behind the definition is to deter- mine the appropriate affine map that transforms yk into a centered reduced normal random variable. The soundness of the approach is demonstrated by the following proposition.
Proposition 3.2 The embedded process yk belongs to the conﬁdence ellipsoid
E (S, p, y0, α, k) with a probability that tends to 1 − α when k increases
Pr (yk ∈ E (S, p, y0, α, k)) k→−→+∞ 1 − α.	(7)
Contrary to ODE or FBA approaches, our method does take fluctuations and inter-species correlations into account: the confidence ellipsoid is centered on the expected value of yk but its dimensions are calculated using the variance-covariance

matrix. Moreover, the advantages of the multivariate approach is now clearly il- lustrated. Imagine one uses a non multivariate method to calculate the asymptotic α-confidence intervals for each specie (ya)1≤a≤n, then he would obtain a multidimen- sional rectangle for the possible values of p which contains the confidence ellipsoid. In other words, the multivariate rectangle has an asymptotic probability larger than 1 − α. Conversely, it is straightforward to derive a confidence interval for ya from the confidence ellipsoid by using Sj = (si,a)1≤i≤m (a-th column of S) instead of S, that is to calculate the projection of the ellipsoid on the (0, ea) axis.
Illustration on a model validation example. Let us illustrate our results on the example of a metabolic pathway initially proposed in [15]. The system is slightly modified to distinguish the by-products of reactions 2 and 3, leading to the reaction network depicted in Figure 1. We assume for instance that y0 = 0 and p = (0.3, 0.2, 0.1, 0.2, 0.1, 0.1)T. This value allows us to equilibrate the production and the consumption of metabolites B, C, and D. Focusing on the outputs of the system, we consider the reduced stoichiometry matrix Sj where only the output columns (E, byp, byp2) are kept. Now let us consider that we can measure the quantities of E, byp and byp2 in 3 different individual cells after k = 100 reactions: o1 = (40, 15, 5)T, o2 = (23, 19, 11)T and o3 = (35, 25, 15)T.
The problem of model validation is to decide which of these cells are consistent with the given reaction network and p. To address this issue, we calculate the equation of a confidence ellipsoid


¨	 2.1822	0	0
    z1 
 0.3  ¨

E (α, 100) :	err(z)= ¨ √100
0.7559 2.6458	0
0.7071 0.7071 3.5355
z2	100
z3
0.2
0.1
¨ ≤ 3 (8)

corresponding to a tolerance error α  2.9%. The reader can refer to the appendix for more details about the derivation. Applied to the data sets at hand, we assume that k is large enough so that the asymptotic regime is reached. Computing the quadratic errors for the data at hand err(o1)  2.66, err(o2)  1.73 and err(o3) 
yields that both o1 and o2 belong to the confidence ellipsoid E (α, 100) whereas o3 does not. We conclude that, with probability 1−α  97%, data about cells 1 and 2 are consistent with the model prediction. On the contrary, data about cell 3 are not consistent with the model and deserve a careful study. Importantly, one may remark that the expected value E(y100) = (30, 20, 10)T was easy to compute but provides no relevant information to check the consistency of o1, o2 and o3 alone. Our method is relevant because it makes also use of the variances and covariances.

3.2  Ratios of accumulation speeds
Our second convergence result concerns the ratios of accumulation speeds between two output species Xa and Xb, defined as
(ya − ya)/tk	ya − ya

ρa,b(k)=	k	0	= k	0
(k > 0).	(9)

(yb − yb)/tk	yb − yb

This quantity is highly interesting for multiple reasons. First, it gives information about the production rates of the system. Second, it is easy to measure experimen- tally. Indeed, by virtue of Proposition 2.3, the quantities of outputs in steady state are linear in average and ρa,b is simply the ratio of the slopes corresponding to the average production of Xa and Xb. Moreover, the knowledge of the exact reaction times tk is not necessary. Third, it is by nature a relative quantity while many bio- logical experiments (western blots, Southern blots and other electrophoresis-based techniques) initially provide relative quantitative data between species (however ab- solute quantitative data can be obtained using a reference chemical specie whose absolute quantity is known). We now introduce a proposition demonstrating that ρa,b is also theoretically very interesting.
Proposition 3.3 For all a, b ∈ {1,..., n}, if (STp)b /= 0 then the ratio of ac-
cumulation speeds ρa,b(k) between Xa and Xb converges in probability to ρ¯a,b = (STp)a/(STp)b: 6ε > 0, limk→+∞ Pr  ρa,b(k) — (STp)a/(STp)b > ε  = 0.
The proposition can be viewed as a prediction of ρa,b(k) since the probability that ρa,b(k) belongs to any positive-length interval that contains ρ¯a,b tends to 1. In other words, the proposition states that ρa,b is a consistent estimator of a ratio involving the reaction probabilities p. Thus, the proposition establishes a relation between the measurable quantity ρa,b and the parameters of the steady-state.
From observations to constraints-based analysis
The previous applications consisted in deriving properties about yk based on per- fect knowledge of p. However, in most of the biological applications, the reaction probabilities are unknown and one has to rely on experimental results to infer the model parameters. This is the main motivation of the following applications that consists in deriving constraints on the reaction probabilities p from experimental data. As the vector p is only a description of the system dynamics at steady-state, one can only use the experimental data obtained when the system is in steady- state regime. Thus the time t0 = 0 refers to the start of the steady state regime that is when the reactant quantities are assumed to be constant. One advantage of our analysis is that qualitative asymptotic results about yk have already been established in the previous sections. For instance Proposition 2.3 states that the expectancies, variances and covariances grows linearly with k. What we do not know are the slopes of these linear growths. In this section, we assume that these steady-state slopes can be experimentally measured and we derive constraints on p based on these observations (Table 1).
Direct application of Proposition 2.3 lead us to the matrix constraints (1) (2) and (3) of Table 1 while constraints (4) are direct consequences of Proposition 3.3. The algebraic constraints are a rewriting of the matrix constraints as simple alge- braic expressions. Remark that the constraint (1a) simply states that the reaction probabilities must be balanced to maintain an average constant quantity of Xa molecules. Notice that γ in observations (1bc) and (2abcd) may be difficult to mea- sure on realistic experimental time series since one needs to know the exact reaction


Table 1
Translation table from biological observations to constraints on the reaction probabilities.

times (tk). However, this is not the case of observations (1a) and (4abc). The linear
constraints Σm  pi = 1 and 0 ≤ pi ≤ 1 (i = 1 ... m) should also be added to the
set of constraints.
A toy example. We propose a toy example (Figure 3) to illustrate our constraints- based approach. The system contains one input reaction that produces a metabolite
A. The metabolite is then transformed into other metabolites (B, C, D, E) that are used to produce four different outputs (O1, O2, O3, O4). In the model, the input reaction has no reactant meaning that the input metabolites quantities are assumed to be constant. We assume the following assumptions on the system : (H0) a steady-state has been reached where the quantities of internal species (A, B, C, D, E) remain constant and the outputs O1, O2, O3 and O4 are accumulating, (H1) the variability in the accumulation of O1 is bounded : V ar(yO1 ) ≤ k · 0.2, (H2) the covariance between accumulations of O1 and O2 satisfies Cov(yO1 , yO2 ) ≤ —0.01k,
(H3) the speed of accumulation of O3 is more than half the speed of accumulation of O2. The proposed numerical values (0.2, —0.01 and 1/2) are purely arbitrary and are chosen for illustration purposes.

Fig. 3. A toy example to illustrate the constraints-based approach.

The hypothesis H0 led us to the following set of constraints for the steady-state reaction probabilities (left column). These constraints are linearly independent so the system has 2 degrees of freedom and we focus on the possible values of (p1, p2) keeping in mind that the other components of p can be calculated using the following system (right column).

6i, 0 ≤ pi ≤ 1,


pi =1 
i=1
p8 = p5 + p6 + p7 (A in steady-state)
p5 = p1 (B in steady-state)
p6 = p2 (C in steady-state) p7 = p3 + p4 (D in steady-state) p3 = p4 (E in steady-state)

p3 = 1/6 — p1/2 — p2/2 p4 = 1/6 — p1/2 — p2/2 p5   = p1
p6    = p2
p7 = 1/3 — p1 — p2 p8	= 1/3

Hence in most of the cases, if one has m reactions and nj balanced metabolites, the number of degrees of freedom will be m—nj —1. Notice that the (H0) hypothesis also includes that the reaction probabilities belong to [0, 1], so we must only consider the values of (p1, p2) such that the above expressions for pi(i = 3,..., 8) are in the correct range, that is (H0) : p1 + p2 ≤ 1/3. Now we translate the hypothesis into constraints using the translation table: (H1): p1 — p2 ≤ 0.2, (H2): —p1p2 ≤ —0.01 and (H3): p3 ≥ p2/2 ⇔ p2 ≤ 1/6 — p1/2. The possible values of (p1, p2) subjected to these constraints are depicted on Figure 4. The association of the four constraints gives rise to a small set S of possible values for (p1, p2), thus we obtain a good idea bout the steady-state parameters.
This constraints-based approach allows a derivation of new insights on the model. Indeed, we have derived a set S of possible values for (p1, p2). Then, by virtue of Proposition 3.3 we know that the ratios of accumulation speeds between O1 and O2 will converge to p1/p2. In Figure 4 we represent the extremal values of p1/p2 for two sets of constraints: the first does not include (H3) while the second one does. Under hypothesis (H0), (H1) and (H2) alone the possible values for p1/p2 belong to the interval [0.11, 7.6]. If the hypothesis H3 – concerning the accumulating speeds between O2 and O3 – is added, then the area of the solution set is clearly reduced and the possible values for p1/p2 is restricted to [0.6, 6.5]. Thus, we have derived from the hypothesis a range of possible values for the ratio of accumulating speeds between O1 and O2.

Conclusion
In this work, we have studied the asymptotic distribution of the molecular quanti- ties of a reaction network under a strong steady-state hypothesis, using the SSA. We provided analytical expressions for the mean and the variance-covariance matrix which depend on S and p. We presented several theoretical and practical conse- quences of this theorem: the possibility to derive confidence ellipsoids, the model validation problem, the convergence of the ratios of accumulation speeds. Toy ex- amples illustrates our results.
A very interesting aspect of our work is that the constraints-based approach can be considered as a probabilistic counterpart of FBA. In FBA, the fluxes f quantify the occurrence rates of each reaction in steady-state with the main hypothesis that the fluxes are balanced such that the internal metabolites concentrations remain constant. Thus, FBA-based methods are constraints-based approaches where f is assumed to belong to the so-called steady-state cone. In our approach, internal

p2	p2	p2





p1

Variance constraint (H1)
p2
1/3
p1

Covariance constraint (H2)
p2
1/3
p1

Speeds constraint (H3)







p1
1/3

0.6
S


6.5




p1
1/3

(H0) ∩ (H1) ∩ (H2)	(H0) ∩ (H1) ∩ (H2) ∩ (H3)

Fig. 4. The gray regions correspond to the sets of all valid (p1, p2) with respect to the steady-state hypothesis (H0) and the given observations (H1), (H2) and (H3). The black dots correspond to the extreme possible values of p1/p2.
chemical species are also considered to be balanced. While FBA only concentrates on fluxes at the population level, our original approach at the cell level not only integrates the metabolite balance constraints but can also make use of the second moments (variances and co-variances) of the outputs. Hence, we can integrate the intrinsic variability of productions at the cell level. However, the additional con- straints are no longer linear but quadratic (and not necessarily positive quadratic) and cannot be solved (for instance) by the classical Dantzig simplex algorithm. Thus, the constraints-based approach opens perspectives to apply efficient con- straint resolution or optimization techniques.

References
Adam Arkin, John Ross, and Harley H McAdams. Stochastic kinetic analysis of developmental pathway bifurcation in phage λ-infected escherichia coli cells. Genetics, 149(4):1633–1648, 1998.
Yang Cao, Daniel T Gillespie, and Linda R Petzold. Efficient step size selection for the tau-leaping simulation method. The Journal of chemical physics, 124:044109, 2006.
Stewart N Ethier and Thomas G Kurtz. Markov processes: characterization and convergence, volume
282. John Wiley & Sons, 2009.
William Feller. Introduction to Probability Theory and Its Applications, Vol. II POD. John Wiley & sons, 1974.
Naama Geva-Zatorsky, Nitzan Rosenfeld, Shalev Itzkovitz, Ron Milo, Alex Sigal, Erez Dekel, Talia Yarnitzky, Yuvalal Liron, Paz Polak, Galit Lahav, et al. Oscillations and variability in the p53 system. Molecular systems biology, 2(1), 2006.
Michael A Gibson and Jehoshua Bruck. Efficient exact stochastic simulation of chemical systems with many species and many channels. The journal of physical chemistry A, 104(9):1876–1889, 2000.

Daniel T Gillespie. A general method for numerically simulating the stochastic time evolution of coupled chemical reactions. Journal of computational physics, 22(4):403–434, 1976.

Daniel T Gillespie. The chemical langevin equation. The Journal of Chemical Physics, 113:297, 2000.

Daniel T Gillespie. Approximate accelerated stochastic simulation of chemically reacting systems. The Journal of Chemical Physics, 115:1716, 2001.
Allan Gut. Stopped random walks: Limit theorems and applications. Springer, 2009.

Matthias Heinemann and Renato Zenobi. Single cell metabolomics. Current Opinion in Biotechnology, 22(1):26–31, 2011.

Volkhard Helms. Principles of computational cell biology. Wiley, 2008.

Roger A Horn and Charles R Johnson. Matrix analysis. Cambridge university press, 2012.

HarleyH. McAdams and Adam Arkin. Stochastic mechanisms in gene expression. Proceedings of the National Academy of Sciences, 94(3):814–819, 1997.

Jason A Papin, Nathan D Price, Sharon J Wiback, David A Fell, and Bernhard O Palsson. Metabolic pathways in the post-genome era. Trends in biochemical sciences, 28(5):250–258, 2003.

Karthik Raman and Nagasuma Chandra. Flux balance analysis of biological systems: applications and challenges. Briefings in bioinformatics, 10(4):435–449, 2009.

A. W Van der Vaart. Asymptotic statistics, volume 3. Cambridge university press, 2000.

EWJ Wallace, DT Gillespie, KR Sanft, and LR Petzold. Linear noise approximation is valid over limited times for any chemical system that is sufficiently large. Systems Biology, IET, 6(4):102–115, 2012.

Darren J Wilkinson. Stochastic modelling for quantitative description of heterogeneous biological systems. Nature Reviews Genetics, 10(2):122–133, 2009.

Darren J Wilkinson. Stochastic modelling for systems biology, volume 44. CRC press, 2012.

Degenerate Cases of the Limiting Distribution
In the main matter section, we have seen that the embedded process (yk)k under the steady-state conditions is a random walk entirely determined by S and the reaction probabilities p. When normalized, it asymptotically follows a Gaussian distribution with variance-covariance matrix W (S, p). However this does not mean that the process actually spreads in all directions. Another formulation of this fact is to notice that W (S, p) is symmetric and positive but not necessarily deﬁnite. The study of the degenerate cases is interesting for at least two reasons: it provides a better understanding of the dynamics of a given system and it allows considering a reduced equivalent and simpler system Sj where W (Sj, p) is definite. We prove that there are only two causes of degeneracy. The first one is the well known possible existence of P-invariants [20] that restricts the dynamics to an affine subspace. The second one corresponds to the degeneracy of the underlying reaction counting process: in some cases the set of reachable points after a given number of random steps is included in an affine hyperplane.

P-invariants
A solution z to the linear equation Sz = 0 is called a P-invariant. P-invariants are meaningful since they correspond to conservation laws of the network [20]. Indeed, if z is a P-invariant then its coordinates are also the coordinates in the dual basis of a conserved linear form ϕ, that is to say 6t, ϕ(xt)= ϕ(x0). The main consequence of the relationship ϕ /= 0 is that the system trajectory is included in the affine hyperplane defined by the equation ϕ(z) = ϕ(x0). This necessarily leads to a degenerate case for the Gaussian limiting distribution. More generally if dim ker S = k then the trajectory is included in an affine subspace of dimension n — k.
To perform a P-invariant elimination, it is always possible to consider an equiva- lent reaction network Sj without non-null P-invariants by removing certain columns of S. Indeed, let us consider a non-null P-invariant z and assume without loss of generality that z1 /= 0, then the molecular quantity x1 is a function of x2, ··· , xn:
t	t	t

1	1	1	Σ	i	i

6t, xt = z
z1x0 —

i=2
zi(x0 — xt)
.	(.1)

Hence, one can always remove the first column of S to decrease by 1 the dimension of the P-invariants space. By repeating successively this procedure, we eventually obtain a reaction network without non-null P-invariant.
RCP invariants
The second source of degeneracy is a particular property of certain random walks where the set of reachable points after a given number of steps is included in an affine hyperplane. For instance, this is the case of the aforementioned RCP qk =

k l=1
eμl k
(which is equal to yk when S = Idn and x0 = 0).  Indeed, it is

straightforward to prove that for all probability distributions on (μk)k, yk belongs
to the affine hyperplane defined by the equation Σn	zi = k. This is because the
system trajectory steps forward in one direction at each reaction (see Fig .1 for a 2D example). Thus the degeneracy of the embedded process can be inherited from the degeneracy of the RCP. Similarly to P-invariant elimination, knowing the equation of these affine hyperplanes allows constructing a reduced equivalent and non-degenerated Sj by eliminating one of the molecular species.
Characterization
Let us now introduce a general theorem that characterizes the degenerate cases of the limiting Gaussian distribution. The theorem takes into account both sources of degeneracy. Our proof relies on the orthogonal reduction of symmetric matrices.
Proposition .1 Let S be the stoichiometry matrix of a system. Let p be a positive reaction probability vector. Consider u = (1, ··· , 1)T ∈ Rn. Then one and only one of the following cases occurs.
If S has non null P-invariants, then dim ker W (S, p) > 0.












Fig. .1. Illustration of a degenerate random walk on the example system {∅ → X; ∅ → Y }. After k
reactions, the system lies necessarily in the affine hyperplane defined by equation X + Y = k.



If S is injective and Sz = u, then has a unique solution η then ker W (S, p)= 
span(η).
If S is injective and Sz = u has no solution, then ker W (S, p)= {0}.
The first case occurs when S is not injective, which is equivalent to ST being not surjective. Equation efeq:affinemap implies that (yk) is in the image of ST, so when ST is not surjective we necessarily obtain a degenerate case. The second case is a non trivial condition that corresponds to the second source of degeneracy. When a solution η exists, yk is included in the affine hyperplane parallel to the
hyperplane Σn	ηizi = 0 and passing through x0 + kSTp . The last case is the
regular one. The following table depicts some examples of simple reaction systems that illustrates the three cases.




Derivation of the ellipsoid equation (8)
We fix tα = 3 corresponding to a tolerance error of


  1	
1	3


(2π) 2


x∈B3(0,3)


exp  — x

dx  0.0292909  2.9%	(.2)

and we calculate the corresponding confidence ellipsoid. According to the previous the results, the limiting variance-covariance matrix is



W (Sj, p)=	—0.06 0.16 —0.02
—0.03 —0.02 0.09
(.3)



and its Choleski decomposition is
⎛ 0.4583	0	0
V =	—0.1309	0.378	0

⎞⎟⎟⎠ .	(.4)

—0.0655 —0.0756 0.2828
As the distribution is not degenerated, we can determine the equation of the α- confidence ellipsoid for the embedded process :


¨	⎛2.1822	0	0
⎞ ⎛⎛z1⎞
⎛0.3⎞⎞¨

E (α, 100) :	¨ √
 0.7559 2.6458	0
⎟ ⎜⎜z ⎟ — 100 ⎜0.2⎟⎟¨ ≤ t
. (.5)

¨ 100 ⎝
⎟⎠ ⎜⎝⎜⎝ 2⎟⎠
⎜⎝	⎟⎠⎟⎠¨	α

0.7071 0.7071 3.5355	z3
¨	`
0.1
¨

`¨	V˛−¸1
˛¸ x	¨x


