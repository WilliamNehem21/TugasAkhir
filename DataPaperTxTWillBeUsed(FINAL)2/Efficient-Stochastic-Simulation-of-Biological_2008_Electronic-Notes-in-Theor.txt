	Electronic Notes in Theoretical Computer Science 194 (2008) 165–180	
www.elsevier.com/locate/entcs

Efficient Stochastic Simulation of Biological Systems with Multiple Variable Volumes
Cristian Versari 1	Nadia Busi2
Dipartimento di Scienze dell’Informazione Universita` di Bologna
Bologna, Italy

Abstract
The application of concurrent calculi to the formalisation of biological systems constitutes a promising approach to the analysis in silico of biological phenomena. The Gillespie algorithm is one of the main models exploited for their stochastic simulation. While the original algorithm considers only one fixed-volume compartment, the simulation of biological systems often requires multi-compartment semantics. In this paper we present an enhanced formulation of an extended version of the algorithm which handles multiple compartments with varying volumes. The presented algorithm is used as basis for the implementation of an extension of the stochastic π-Calculus, called Sπ@, which allows an intuitive and concise formalisation of such systems. The algorithm is also efficient in presence of a high number of compartments and reactions, therefore Sπ@ represents the starting point for the development of an effective tool for the simulation of biological systems with dynamical structure even in presence of computationally expensive phenomena like diffusion.
Keywords: stochastic simulation, π-Calculus, process calculi


Introduction
The application of concurrency theory to Systems Biology represents a recent and promising approach to the modelling, simulation and analysis in silico of biological systems. After the first application of the π-Calculus [15,14,16,18] to the formal- isation and simulation of biochemical systems [22,20] the interest of the research community has focused on the development of calculi (e.g. [21,3,19,5,11]) which aim at modelling more faithfully the biological reality of interest.
The typical structure of biological systems suggests that their effective mod- elling requires the introduction of multiple compartments with dynamical structure, as denoted by many of the cited approaches. The Gillespie stochastic simulation algorithm [9,10] (SSA for short) constitutes one of the more exploited chemical

1 Email: versari@cs.unibo.it
2 Email: busi@cs.unibo.it

1571-0661 © 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.12.012

abstractions for the effective simulation of bio-systems expressed in terms of con- current calculi, but its original formulation is limited to systems composed of a single, fixed-size volume. In order to overcome these limits we introduced in [24] an extended version of the SSA which handles multiple, variable volumes (multi- compartmental SSA, MSSA for short) together with an extended version of the stochastic π-Calculus, called Sπ@. The Sπ@ language allows to formalise straight- forwardly biological systems with dynamical compartment structure which can be then simulated by means of the MSSA.
Unfortunately, the MSSA inherits the computational complexity of the original SSA with the additional parameter of the number of compartments. This causes any simulation to be unfeasible when the number of compartments grows significantly, as noted in [7]. Several improvements of the SSA have already been proposed [8,1,7] but none of them can be applied to the MSSA with appreciable gain because of its unique features of considering multiple, stochastically varying volumes.
In this paper we present an enhanced version of the MSSA (EMSSA) whose com- plexity scales logarithmically (instead of linearly) both with the number of reactions and with the number of compartments of the system. The EMSSA constitutes then a valid implementation for the exact stochastic simulation of biological systems in presence of dynamical structure and varying volumes which effectively handles phenomena like osmosis [24], diffusion [7] and cellular growth and division [13].

Structure of the Paper
The paper is organised as follows. In Sect. 2 the preliminary notions concerning the original SSA, the MSSA and the Sπ@ calculus are introduced. In Sect. 3 the enhanced MSSA is formulated together with some suggestions for further improve- ments. In Sect. 4 some conclusive remarks are reported.

Preliminaries
Gillespie Stochastic Simulation Algorithm
The original SSA considers a fixed volume V containing a mixture of N chemical species S1,... SN interacting through M reaction channels R1,... , RM . X1,... , XN represent respectively the number of molecules for each of the Si chemical species. The state of the system at any time t is characterised by the state vector X(t) = X1(t),... , XN (t) = x where Xi(t) is the number of molecules of species Si at the given time. νμ = (ν1μ,... , νNμ) is the state change vector , which contains all the informations on the number and species of reactant molecules and reaction products for each reaction Rμ. For a reaction of the kind
Rμ :	Si + Sj → Sk	i /= j
we have that νiμ = νjμ = —1, while νkμ = +1 and νlμ = 0 for every other index
l. The probability that an Rμ reaction will occur inside V in the next infinitesimal

time interval (t, t + dt) is calculated as
aμ(x) dt = Xi(t)Xj(t)cμ dt

where cμ dt is the probability that a particular molecular pair of the involved chem- ical species will react according to Rμ inside V in the next infinitesimal interval (t, t + dt) and aμ(x) is the propensity function of Rμ. In general, aμ(x) is calculated as
aμ(x)= hμ(x)cμ	(1)
where hμ(x) represents the number of distinct Rμ molecular reactant combinations available at some time t inside V .
The dynamics of the system obeys the chemical master equation (CME) [9,10,1]


δP (x, t|x0, t0)/δt =
(2)

M
μ=1
[aμ(x — νμ)P (x — νμ, t|x0, t0) — aμ(x)P (x, t|x0, t0)]

where P (x, t|x0, t0) is the probability that X(t) will be x, given that X(t0) = x0. The CME is hard to solve except for very simple systems. The SSA provides a stochastic simulation method rigorously equivalent to the CME. Starting from an initial state, the SSA allows the system to evolve stochastically by providing the next state reached after a single firing of one of the M molecular reactions, chosen according to the CME. The aim of the algorithm is to find when the next reaction ﬁres (i.e. the value of the time variable τ ) and which of the M reactions is (the index μ of the next reaction Rμ).
The function P (τ, μ|x) dτ represents the probability that, given the state x at some time t, the next reaction in V will occur in the infinitesimal time interval (t + τ, t + τ + dτ ) and will be an Rμ reaction. It can be calculated as the product of the probability P (τ |x) that, given the state x at some time t, no reaction will occur in the time interval (t, t + τ ), times the probability aμ(x) dτ that an Rμ reaction will occur in the time interval (t + τ, t + τ + dτ ):
P (τ ', μ'|x') dτ ' = P (τ '|x')aμ(x') dτ '
Since [1 —  j aj(x') dτ '] is the probability that no reaction will occur in time dτ '
from the state x',
P (τ ' + dτ '|x')= P (τ '|x') · [1 — Σ aj(x') dτ ']
j


from which

P (τ |x)= exp(— Σ aj(x)τ )
j=1

Hence, the function P (τ, μ|x) is given by


P (τ, μ|x)= ,⎨

μ = 1,... ,M 

(3)

,,, 0	otherwise
where a0(x)= ΣM  aj(x).
In order to generate a random pair (τ, μ) according to Expr. (3) by a pair (z1, z2) obtained by a unit-interval uniform random number generator, the following resampling is evaluated in the SSA for τ


1
τ =
a0(x)
1
log
z1
(4)

while μ is calculated as the smallest integer satisfying
Σ aj(x) > z2a0(x)	(5)
j=1
The SSA can be summarised as follows:
Algorithm 1 (Gillespie Stochastic Simulation Algorithm)
calculate ai,i = 1,... ,M and a0 from Expr. (1);
generate uniformly two random numbers z1, z2 in the interval (0, 1);
calculate τ from Expr. (4) and μ from Expr. (5);
update the states of the species to reflect the execution of reaction μ and set
t = t + τ;
go to step (i).
For details we refer to [10].
Stochastic Simulation with Multiple Compartments
In [24] we introduced a simple extension of the original SSA which allows to handle multiple volumes with variable sizes and still reflects the original CME. This can be achieved by expressing the propensity function aj of each reaction in function of the volume V of the compartment. In the case of reactions fired by two reactant molecules, we have:
aμ(x)= hμ(x)cμ = V −1(x)hμ(x)rμ	(6)
The rμ dt value represent the probability that an Rμ reaction fires in the infinitesi- mal time dt inside a unit-size volume containing a single molecule pair undergoing reaction Rμ.

The volume V (x) of the compartment at some time t in the state x = X(t) = X1(t),... , XN (t) is calculated as the sum of the volumes occupied by each of the molecules located inside V . Given the function v : {S1,... , SM }→ R which returns the volume occupied by one molecule of each chemical species, V is calculated as
V (x)= Σ v(Sj)Xj(t)	(7)
j=1
In the case of aeriform systems or systems composed of one (or few) chemical species, the function v(Sj) can be easily estimated by knowing the molecular weight of the species and their density. In the case of real systems composed of thousands of different species, v(Sj) may only be estimated by formulating a specific kinetic model.
In presence of more than one compartment, each of the Rj reactions must be considered w.r.t. the compartment the reaction occurs in. This means that each Rμ reaction is characterised by C different propensity functions, one for each of the C compartments. In the case of reactions fired by two reactant molecules
ak (x)= hk (x)ck = V −1(x)hk (x)rμ	k = 1,... ,C	(8)
μ	μ	μ	k	μ


where
x = X(t)= X˜1(t),... , X˜C (t) ,

X˜k (t)= Xk(t),... ,Xk (t) 

Each Xk(t) represents the number of molecules of the Sj chemical species inside compartment k at time t. The value ak (x) dt represents the probability that the reaction Rμ will happen inside compartment k in the next infinitesimal interval dt. Each volume Vk is calculated as

M
k j
j=1
The value a0 of Expr. (3) becomes

C	M	C
a0(x)= Σ Σ ak(x)= Σ ak(x)	(10)
k=1 j=1	k=1

where ΣM

ak(x)= ak(x). Expr. (5) is then unchanged:



1
τ =
a0(x)
1
log
z1
(11)

where a0 is calculated according to Expr. (10).
In order to identify both the compartment ψ and the reaction μ by a single generation of a unit-interval random number z2, Expr.  (5) is modified so that

(ψ, μ) is the smallest pair of indexes satisfying

ψ	μ
Σ Σ ak(x) > z2a0(x)	(12)
k=1 j=1
where (ψ, μ) < (ψ', μ') ⇐⇒ f (ψ, μ) < f (ψ', μ'), with f (ψ, μ)= (ψ ∗ (M + 1) + μ).
The multi-compartmental simulation algorithm (MSSA) can be finally expressed as a slight variation of the SSA:
Algorithm 2 (Multi-compartmental Stochastic Simulation Algorithm)
calculate ak with k = 1,... , C,	i = 1,... ,M from Expr. (8), (9) and a0 from Expr. (10);
generate uniformly two random numbers z1, z2 in the interval (0, 1);
calculate τ from Expr. (11) and (ψ, μ) from Expr. (12);
update the states of the species to reflect the execution of reaction (ψ, μ) and set t = t + τ;
go to step (i).
As discussed in [24], the original Gillespie’s propensity functions are recovered when the system is composed of a single compartment of unitary volume: this may be achieved by setting v(Sj) = 0 ∀j and adding a fictitious element of volume 1 not participating in any reaction. Although immediate, this expedient seems quite artificial. A more faithful modelling would be obtained by specifying the total (not null) volume of the products of each reaction equal to the total volume of the respective reactants. Further elements not taking part in the reactions but influencing their rates (such as water, which may dilute reactants and slow down reactions even without direct chemical interaction) shall also be specified, because they actually determine the total volume of the compartment.

The Stochastic π@ calculus
The MSSA was introduced in [24] for the simulation of processes expressed in the Stochastic π@ calculus (Sπ@ for short), which allows to describe formally biological systems with dynamical compartment structure and variable volumes. The expres- siveness of Sπ@ is comparable [23] to compartmentalised languages like Bioambients
[21] and Brane Calculi [3].
The π@ language [23] is a conservative extension of the π-Calculus [15,16,14] with polyadic synchronisation for encoding compartments and different levels of priority for gaining atomicity [2,4,11]. The Sπ@ language can be considered in first approximation as the stochastic version of a core π@ limited to two levels of priority and two names for each channel. The capability of giving infinite rates to reactions replaces the two priority levels of this core π@, while the two names denoting each action assume different meaning, since the first represents the type of (chemical) reaction, while the second the compartment where the reaction takes place.

The syntax and semantics of Sπ@ follows.
Definition 2.1 Let N , C be distinct sets of names on finite alphabet, with m, n ranging over N, a, b over C and x, y over X = N ∪ C. Let also v range over R within the interval [0, +∞[. The syntax of the Sπ@ language is defined as
P	::=	0		Σ πi.Pi			P  Q		!π.P		(ν x)P π	::=	n@a : v(x˜)		n@a : v⟨x˜⟩
where x˜ represents zero or more names x1,... , xi ranging over X .
0 is the null process, capable of doing nothing.  i∈I πi.Pi, written also π1.P1 + π2.P2 in the case |I| = 2, represents the guarded choice between different actions. P  Q means that P and Q are two processes executing in parallel. !π.P is the guarded replication. (ν x)P allows the scope restriction of the name x: the re- striction of compartment names allows the creation of new compartments, while the restriction of reaction names is used in several ways, like for representing bind- ings between different elements. The expressions n@a : v(x˜) and n@a : v⟨x˜⟩ represent respectively the polyadic input and output capabilities of a process, where
n is the kind of reaction the process is ready to perform: in Expr. (8) it corre- sponds to the index μ denoting the reaction Rμ;
a is the compartment where the reaction may take place, corresponding to k in Expr. (8);
v corresponds to v(Sμ) in Expr. (9) and represents the volume occupied inside compartment a by the process ready to perform the input or output action.
Sπ@ syntax allows to easily specify processes which are located (and hence may occupy volume) in more than one compartment. For example, the process P
P ≡ n@a : v1.Q1 + m@b : v2.Q2 + p@a : v3.Q3
occupies some space both in compartment a and in compartment b. Anyway, since Sπ@ syntax does not allow to associate a unique volume value with each action name, P may be written as well as
P ≡ n@a : v13.Q1 + m@b : v2.Q2 + p@a : 0.Q3
with v13 = v1 + v3. In fact the volumes occupied in compartments a, b are the same in both cases. This kind of overloading may be avoided by changing the syntax of the choice operator, for example by specifying the volume occupied in each compartment in a list (associative array):
P ≡ [a : v13,b : v2]n@a.Q1 + m@b.Q2 + p@a.Q3
Even if in this way the syntax is more rigorous, it loses readability, so Def. 2.1 is still preferable.

Definition 2.2 The congruence relation ≡ is defined as the least congruence satis- fying alpha conversion, the commutative monoidal laws with respect to both ( ,0) and (+,0) and the following axioms:
(ν x)P	Q ≡ (ν x)(P	Q)	if x ∈/ fn(Q) (ν x)P ≡ P		if x ∈/ fn(P )
!π.P ≡ π.( !π.P  P ) where the function fn is defined as

fn(n@a : v(x˜))
fn(0)
def
= {n, a}	fn(n@a : v⟨x˜⟩)
def
= ∅	fn((ν x)P )
def
= {n, a, x˜}
def
= fn(P ) \ {x}

def
Σ	def

fn(π.P )
= fn(π) ∪ fn(P )	fn(

i∈I
πi.Pi) =
fn(πi.Pi)
i

fn(P 
def
Q) = fn(P )
∪ fn(Q)
fn( !π.P )
def
= fn(π.P )

Definition 2.3 Sπ@ semantics is given in terms of the following reduction system:


(C)
rate(n)
(n@a : v (x˜).P + M )	(n@a : v ⟨y˜⟩.Q + N )
P {y˜/x˜} Q

—→r	P '	P —→r	P '

(R)
(ν x)P
—→r
(P )
(ν x)P '	P  Q
—→r
P '  Q

(E)
P ≡ Q	P —→r	P '	P ' ≡ Q'


—→r	Q'

The rule (C) allows the communication of the names x˜ from process P to Q, where they are properly substituted to names y˜. The function rate : N → (R ∪
+∞) is an external function which permits to associate the correct rate with each reaction, where the rate corresponds to the value rμ of Expr. (8). Rules (R), (P ), (E) allow the transition of processes in presence of restriction, parallel operator or by exploiting structural equivalence.
Definition 2.4 A Sπ@ system S is said to be in standard form if
S = (ν x˜) P1  ···  Pj  !Pj+1  ···  !Pk and each Pi is a non-empty sum.
Proposition 2.5 For every Sπ@ system S, there exists a system S' such that S ≡
S' and S' is in standard form.
In order to calculate the value hμc of Expr. (8), we introduce, according to [17], the function Act which permits to know the number of possible combinations of inputs and outputs on a reaction channel inside a given compartment.

Definition 2.6 The activity Act of channel n inside compartment a in the system
S is defined as
Actn@a(S)= (Inn@a(S) · Outn@a(S)) — Mixn@a(S)
where S is in standard form, Inn@a(S) and Outn@a(S) are the number of unguarded
inputs and outputs on channel n inside compartment a, and Mix	(S) is the sum of Inn@a(Σi) · Outn@a(Σi) for each summation Σi in S.
The function chan allows to know all the active channels inside each compart- ment in a given system S.
Definition 2.7 Given a Sπ@ system S in standard form
S = (ν x˜) P1  ···  Pj  !Pj+1  ···  !Pk the function chan is defined recursively as follows:
chan(S)=  chan(Pi)	chan(Σ πi.Pi)=   chan(πi)

i=1
chan(n@a : v(x˜)) = chan(n@a : v⟨x˜⟩)= {n@a}
i∈I
i∈I

Definition 2.8 Given a Sπ@ system S in standard form
S = (ν x˜) P1  ···  Pj  !Pj+1  ···  !Pk 
the volume Vola of the compartment a in the system S is calculated as follows:
Vola(S)= Σ Vola(Pi)
i=1
Vola(	πi.Pi)=	Vola(πi)
i∈I	i∈I
Vola(n@a : v⟨x˜⟩)= Vola(n@a : v(x˜))


Vola
(n@b : v(x˜)) = ,⎨ v	a = b
, 0	otherwise

If Vola(S)= 0, then a is given the default volume value 1.
The following algorithm corresponds to each repetition of the loop of Alg. 2.
Algorithm 3 Given a Sπ@ system S in standard form, the selection of the next reaction Next(S) and of the delay Delay(S) relative to the MSSA are described by the following algorithm:
For each channel ci in chan(S), with chan(S)= {c1,... , cj }, calculate
ai = Actn@b(S) ∗ rate(n)/ Volb(S)

where ci = n@b for some n ∈ N ,b ∈ C.
Calculate a0 = Σj	ai
Generate two random numbers z1, z2 ∈ [0, 1] and calculate τ, λ such that

λ−1	λ

τ = (1/a0) ln(1/z1)
Σ ai < z2a0 ≤ Σ ai

i=1	i=1
Next(S)= cλ and Delay(S)= τ.
The value cλ = n@b for some n, b denotes the reaction channel n (corresponding to μ in Alg. 2) and the compartment c (corresponding to ψ in Alg. 2) of the next reaction happening after τ time. The two processes performing the synchronisation step on cλ are then randomly chosen as for SPiM.
For further description and applicability of the Sπ@ calculus we refer to [24].

Efficient Formulation of the Simulation Algorithm
In the original formulation of the SSA [10] each transition of the system from one state x to a subsequent state x' requires at most M operations needed to know which of the M reactions will happen next, in function of the random number gen- erated in the second step of the algorithm. In fact, in order to find the index μ in Expr. (5), M summations are required in the worst case. Several improvements or alternatives to the SSA have been proposed (e.g. [8,1,7]) which reduce the com- putational complexity of each transition to O(log M ) or optimise it in function of reaction rates.
The MSSA inherits the complexity order of the original SSA, linear in the num- ber of distinct reactions. However in this case the number of independent reaction is M · C, where C is the number of compartments. As noted in [7], the simulation becomes computationally unfeasible if C grows significantly. Unfortunately, none of the proposed improvements can be directly applied to the MSSA with appreciable gain. The main reason is that the propensity functions ak depend of the volumes Vk. Each reaction firing may change the volume of one or more compartments, so that all the propensity functions of reactions located into the involved compartments shall be recalculated. This would cause the complexity of the algorithm to be still linear in the number of the M reactions even after the optimisations proposed in [8,7]. Also the optimised direct method (ODM) formulated in [1] would provide no substantial gain in the (not unusual) case that the chemical composition of the compartments is almost the same: in this situation the complexity would be almost linear in the number of compartments in the best case.
Nevertheless, the computational complexity order of the MSSA can be reduced to O(log M + log C) by exploiting the same data structures proposed in [8] for enhancing directly the SSA. These structures are justified by two observations. The first is that only few propensity functions change at each transition and these can be easily identified by building a dependency graph. The second is that the linear

search in step (iii) can be improved by exploiting (twice) a binary search tree. The definitions of the needed data structures follow.
Definition 3.1 Let νkμ be the state change vector of reaction μ firing inside com- partment ψ, νψμ = (ν˜ψμ,... , ν˜ψμ), with ν˜ψμ = (νψμ,... , νψμ).
1	C	j	j1	jN
Let Re(Rμ) ⊆ {S1,... , SN } be the chemical species needed to fire reaction Rμ.
Let G(VG, EG) be a directed graph with vertex set {0,... , (C · M ) — 1}. For each vertex pair (n, n'),n = f (ψ, μ), n' = f (ψ', μ'), where f (ψ, μ) = (ψ ∗ M + μ),

the edge e = (n, n') is in E
iff ∃j ∈ {1,... ,N } : S ∈ Re(R ' ) ∧ νψμ /= 0.

G	j	μ
ψ'j

G represents the dependency graph of the system. Each vertex n of G represents a reaction Rμ inside a compartment ψ. Every edge from n to n' indicates that reaction Rμ inside ψ influences reaction Rμ' inside ψ' by changing the concentration in ψ' of at least one of the reactants of Rμ' . The dependency graph allows to know the only propensity functions which need to be updated after each transition.
We now define the structure of non-cumulative complete binary search tree.
Definition 3.2 A binary tree T is recursively defined as nil (the empty tree) or (n, Tl, Tr) where n = (v, D) is the node, v ∈ R+ is its value and D the associated data, Tl and Tr are binary trees.
Let hgt(T ) be the height of the tree, with hgt(nil) = 0 and hgt((n, Tl, Tr)) = 1+ max(hgt(Tl), hgt(Tr)).
Let levi(T ),i ≥ 0 be the list of elements of the i-th level of the tree, with levi(nil) = [∅],  lev0((n, Tl, Tr)) = [n] and levi((n, Tl, Tr)) = levi−1(Tl)& levi−1(Tr) for i > 0, with & representing the appending of lists.
Let el(T ) be the list of element values of T , with el(nil) = [], el(((v, D), Tl, Tr)) = [v]& el(Tl)& el(Tr).
A binary tree T is complete if is empty, or if ∅ ∈/ levhgt(T )−2(T ) and there exist no lists l1, l2 and node n, such that levhgt(T )−1(T )= l1&[∅, n]&l2.
A complete binary tree is a non-cumulative binary search tree (NCBST) if it is empty, or if T = ((v, D), nil, nil), or if T = ((v, D), T , T ) and v =  el(T )+ 
Σ el(Tr), and both Tl and Tr are non-empty non-cumulative search trees.
A binary tree is complete if all the levels are full, except for the last which presents all the remaining leaves on the left. The tree is also a non-cumulative search tree if each node value is equal to the sum of the values of its offspring. The definitions are illustrated in Fig. 1. A non-cumulative binary search tree can be transformed into a binary search tree by summing up the value of each node to all the nodes of its right sub-tree.
We define now the function which implements the search in a NCBST.
Algorithm 4 Let T = ((v, D), Tl, Tr) be a non-empty NCBST and p ∈ R,p ∈ [0, v[, with T, p formal parameters of the function:
if Tl = Tr = nil (i.e. T is a leaf) then return (p/v, D), else
let Tl = ((vl, D),T l,T l); if p < vl then set T ← Tl and go to (i), else
l	r
set p ← (p — vl),T ← Tr and go to (i).

(a)	(b)






(c)








Fig. 1. Non-cumulative complete binary search trees.


Given a NCBST T = ((v, D), Tl, Tr) and a random number p = r · v, with r ∈ [0, 1[, the function returns the data associated with the leaf i, where
Σ(leaf j value) < p < Σ(leaf j value)
j<i	j≤i

and leaves are numbered from left to right, as in Fig. 1 (b). The function returns also the remainder of p scaled to the interval [0, 1[, which allows to avoid the generation of a further random number in the next algorithm. A short example of execution follows.
Example 3.3 Consider the tree in Fig. 1 (a). Let p = 20. The root node is not a leaf, so it must be checked if p < vl = 26, where vl is the value associated with the left sub-tree. The condition is true, so the loop cycle must be repeated starting from Tl. The value of the left sub-sub-tree is vll = 11 < p, hence p ← 20 — 11 and the search continues in Tlr. Now p = 9 < vlrl = 12 and Tlrl is a leaf, so the algorithm ends and returns (0.75, D).

The computational complexity of the algorithm is O(log K), where K is the number of nodes of the tree. Given a list of l non-negative real numbers, it is also possible to build a corresponding NCBST in O(l) with all the elements of the list appearing as leaves of the tree. This is the technique exploited for executing step
(iii) of the MSSA in logarithmic time.
We can now define the improved MSSA. We first note that the values ak in Expr.

(10) can be written as
ak(x) = ΣM ak(x)= ΣM


V −1(x)hk(x)rμ

j=1 j
j=1 k	j
(13)

= V −1(x) ΣM
hk(x)rμ = V −1(x)αk(x)

where
M	M
αk(x)= Σ hk(x)rμ = Σ αk(x)	(14)

j
j=1
j
j=1



with

αk(x)= hk(x)rμ	(15)

j	j
Furthermore, the summation of Expr. (12) can be expressed as


Σψ	Σμ
ak(x)= Σψ−1 ak(x)+ Σμ
aψ(x)= 

k=1
j=1 j
k=1
j=1 j
(16)

Σψ−1 ak(x)+ V −1 Σμ
αψ(x)

The enhanced MSSA (EMSSA) is defined as follows.
Algorithm 5 (Enhanced Multi-compartmental Stochastic Simulation Algorithm)
calculate Vk from (9), αk from Expr. (15), αk from Expr. (14), ak from Expr.
(13), with k = 1,... , C,	j = 1,... ,M, and a0 from Expr. (10);
build the dependency graph of the system according to Def. 3.1;
build the NCBST T0 such that its leaves are ((ak, k), nil, nil), with k = 1,... ,C;
build C NCBSTs such that ((αk, j), nil, nil) are the leaves of the k-th NCBST
T k, with j = 1,... ,M and k = 1,... ,C;
generate uniformly two random numbers z1, z2 in the interval (0, 1);
calculate τ from Expr. (11) and set t = t + τ;
let (v, D) the value returned by Alg. 4 called with parameters (T0, a0 · z2); set
ψ ← D, according to Expr. (16);
let (v', D) the value returned by Alg. 4 called with parameters (T ψ, αψ · v); set
μ ← D, according to Expr. (16);
update the states of the species and T0,T 1,... ,TC to reflect the execution of reaction (ψ, μ) by updating only the propensity functions and volumes and sub- trees indicated by the dependency graph built at step (ii);
go to step (v).
The initialisation of the algorithm includes the building of the dependency graph and of two kinds of NCBSTs. The first, constituted by T0, is the only which contains informations on the Vk volumes of the compartments. The second kind,

represented by {T 1,... ,TC }, contains the informations on the propensity functions of the reactions inside each compartment. This double-tree organisation allows to express the propensity functions independently of their respective volumes, so that they do not need to be recalculated as the volumes change.
The height of T0 is [log(2 · C)|, while the height of each T k is [log(2 · M )|. The search of steps (vii) and (viii) are consequently executed in O(log C) and O(log M ) respectively. The most expensive operation is step (ix): if MaxV is the maximum number of compartments influenced by some reaction Rμ and MaxR is the maximum number of propensity functions modified by some reaction R' , the number of opera- tions is bounded by (MaxV log C + MaxR log M ), because each update of the leaf of a NCBST T requires hgt(T ) updates of the ancestor nodes. Since MaxV , MaxR are constants, the computational complexity of the algorithm is O(L(log C + log M )), where L is the number of transitions of the systems, each corresponding to one reaction firing and one execution of the loop in Alg. 5.

Further enhancements
The number of operations needed to perform step (ix) can be considerably reduced by grouping together the indexes of the compartments and reactions whose volumes and propensity functions change simultaneously. This can be achieved by a proper analysis of the dependency graph of the system and may lead in the best case to (2 MaxV +2 MaxR + log C + log M ) operations. Steps (vii) and (viii) can be improved by adapting the enhancements to the SSA discussed in [1] to NCBSTs. The NCBST structure may be changed as shown in Fig. 1 (c). Here the leaves of NCBSTs of increasing height linked in a list contain the propensity function values in increasing order of firing frequency of the corresponding reactions. The frequencies can be calculated by previous benchmarking, as in [1].

Related work
Some extensions of the Gillespie algorithm which handle variable volumes were al- ready defined in [13,12]. The volume here is expressed as known function of time and introduced in the evaluation of the propensity functions. Although this approach may likely provide less computationally expensive algorithms, it can be applied only in the case that the variation of the volume in function of time can be considered deterministic and it is known. Conversely, the MSSA allows to associate the volume with the propensity functions so that its variation is introduced transparently in the stochastic evolution of the system and is handled coherently with the CME without requiring previous knowledge of its behaviour.
The next subvolume method (NSM) [7] faces the problem of efficient simulation of chemical systems in presence of molecular diffusion. The NSM is thought for a high number of subvolumes with statical structure, of fixed and equal size. Any implementation of the EMSSA would likely be slower in the special case considered for the NSM, but constitutes an efficient generalisation in the case of dynamical structure and different, varying volumes. In fact, the computational complexity

order of the EMSSA is the same of the NSM, since they are both logarithmic in function of the number of compartments and reactions.

Conclusion
We have presented an enhanced stochastic simulation algorithm based on Gillespie SSA [10] which allows to model systems with multiple compartments and variable volumes. Its computational complexity scales logarithmically – instead of linearly – with both the number of reactions and the number of compartments, so that it turns out to be very efficient also in the case of high number of compartments. The algorithm can be used for an improved implementation of the Sπ@ calculus
[24] which constitutes an elegant candidate for the representation of systems with dynamical compartment structure and varying volumes. The improved Sπ@ calcu- lus allows the efficient and exact stochastic simulation of biological systems also in presence of phenomena like osmosis, cellular growth and division [13], diffusion [7]. Although the algorithm does not require to know the volume associated with each molecule species (as discussed in [24]), the formulation of a specific kinetic model for the estimation of reactant densities would allow to refine the simulation
and is left for future work.
The same optimisations considered here may also be used for an efficient imple- mentation of the SSA in the case of multiple compartments with fixed volumes but variable temperature.

References
Cao, Y., H. Li and L. Petzold, Efficient formulation of the stochastic simulation algorithm for chemically reacting systems.,J Chem Phys 121 (2004), pp. 4059–4067.
Carbone, M. and S. Maffeis, On the expressive power of polyadic synchronisation in pi-calculus., Nord.
J. Comput. 10 (2003), pp. 70–98.
Cardelli, L., Brane calculi., in: Danos and Sch¨achter [6], pp. 257–278.
Cleaveland, R., G. Lu¨ttgen and V. Natarajan, Priority in process algebra, in: J. Bergstra, A. Ponse and
S. Smolka, editors, Handbook of Process Algebra, Elsevier Science Publishers, 2001 pp. 711–765.
Danos, V. and C. Laneve, Formal molecular biology., Theor. Comput. Sci. 325 (2004), pp. 69–110.
Danos, V. and V. Sch¨achter, editors, “Computational Methods in Systems Biology, International Conference CMSB 2004, Paris, France, May 26-28, 2004, Revised Selected Papers,” Lecture Notes in Computer Science 3082, Springer, 2005.
Elf, J. and M. Ehrenberg, Spontaneous separation of bi-stable biochemical systems into spatial domains of opposite phases, Systems Biology 1 (2004), pp. 230–236.
URL http://link.aip.org/link/?BDJ/1/230/1

Gibson, M. and J. Bruck, Efficient exact stochastic simulation of chemical systems with many species and many channels, Journal of Physical Chemistry A 104 (2000), pp. 1876–1889.
URL http://pubs3.acs.org/acs/journals/doilookup?in_doi=10.1021/jp993732q

Gillespie, D. T., A general method for numerically simulating the stochastic time evolution of coupled chemical reactions, Journal of Computational Physics 22 (1976), pp. 403–434.
URL  http://dx.doi.org/10.1016/0021-9991(76)90041-3
Gillespie, D. T., Exact stochastic simulation of coupled chemical reactions, J. Phys. Chem. 81 (1977),
pp. 2340–2361.


Kuttler, C., C. Lhoussaine and J. Niehren, A stochastic pi calculus for concurrent objects, in: Proceedings of the Second International Conference on Algebraic Biology, Lecture Notes in Computer Science (2007).
Lecca, P., A time-dependent extension of gillespie algorithm for biochemical stochastic π-calculus, in:
SAC ’06: Proceedings of the 2006 ACM symposium on Applied computing (2006), pp. 137–144.
Lu, T., D. Volfson, L. Tsimring and J. Hasty, Cellular growth and division in the gillespie algorithm, in: Systems Biology, IEE Proceedings, 2004, pp. 121–128.
Milner, R., “Communicating and mobile systems: the π-calculus,” Cambridge University Press, New York, NY, USA, 1999.
Milner, R., J. Parrow and D. Walker, A calculus of mobile processes, i, Inf. Comput. 100 (1992),
pp. 1–40.
Milner, R., J. Parrow and D. Walker, A calculus of mobile processes, ii, Inf. Comput. 100 (1992),
pp. 41–77.
Phillips, A. and L. Cardelli, A correct abstract machine for the stochastic pi-calculus, in: Bioconcur’04
(2004).
Priami, C., Stochastic pi-calculus., Comput. J. 38 (1995), pp. 578–589.
Priami, C. and P. Quaglia, Beta binders for biological interactions., in: Danos and Sch¨achter [6], pp. 20–33.
Priami, C., A. Regev, E. Y. Shapiro and W. Silverman, Application of a stochastic name-passing calculus to representation and simulation of molecular processes., Inf. Process. Lett. 80 (2001), pp. 25– 31.
Regev, A., E. M. Panina, W. Silverman, L. Cardelli and E. Y. Shapiro, Bioambients: an abstraction for biological compartments., Theor. Comput. Sci. 325 (2004), pp. 141–167.
Regev, A., W. Silverman and E. Y. Shapiro, Representation and simulation of biochemical processes using the pi-calculus process algebra., in: Pacific Symposium on Biocomputing, 2001, pp. 459–470.
Versari, C., A core calculus for a comparative analysis of bio-inspired calculi, European Symposium on Programming (2007), available at http://www.cs.unibo.it/∼versari/files/cversari-esop07.pdf.
Versari, C. and N. Busi, Stochastic simulation of biological systems with dynamical compartment structure, in: CMSB, 2007, available at http://www.cs.unibo.it/∼versari/files/cversari-cmsb07.pdf. URL http://www.cs.unibo.it/~versari/files/cversari-cmsb07.pdf
