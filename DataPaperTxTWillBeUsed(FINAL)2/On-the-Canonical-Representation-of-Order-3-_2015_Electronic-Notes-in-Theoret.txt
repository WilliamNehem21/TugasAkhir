Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 318 (2015) 143–158
www.elsevier.com/locate/entcs

On the Canonical Representation of Order 3 Discrete Phase Type Distributions 4
Illés Horváth1
MTA-BME Information systems research group Budapest, Hungary
János Papp2
Technical University of Budapest Budapest, Hungary
Miklós Telek3
Technical University of Budapest Budapest, Hungary

Abstract
In spite of the fact that discrete phase type (DPH) distributions are used almost as often as continuous phase type (CPH) distributions canonical representation is not available for general (cyclic) order 3 DPH distributions yet.
In this paper we investigate the canonical representation of DPH distributions of order 3. During the course of this investigation we find that the problem of canonical representation of order 3 DPH distributions is far more complex than the one of order 3 CPH distribution. As a result we needed to distinguish 8 different subclasses of order 3 DPH distributions, while it was enough to distinguish 3 subclasses of order 3 CPH distributions for their canonical representation. Additionally, we were not able to prove all subclasses of DPH distributions with the relatively simple methodology which was suﬃcient for the canonical representation of order 3 DPH distributions.
Keywords: Discrete phase type distributions, Canonical representation, Similarity transformation.


Introduction
Stochastic performance models were restricted to “memoryless” distributions (expo- nential in case of continuous time models and geometrical in case of discrete time

1 Email:horvath.illes.antal@gmail.com
2 Email:papp.janos.90@gmail.com
3 Email:telek@hit.bme.hu
4 The authors thanks the support of the OTKA K101150 project.

http://dx.doi.org/10.1016/j.entcs.2015.10.024
1571-0661/© 2015 The Authors. Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

models) for a long time in order to utilize the nice computational properties of dis- crete state Markov models. Phase-Type distributions [8,9] have been introduced for relaxing this modeling limitation on the considered distributions, while maintaining the nice Markovian behavior.
For a period of time continuous time stochastic models with CPH distributions were more often applied in performance modeling of computer and communication systems, but also in this period the analysis of the continuous time models were of- ten based on the method of embedded Markov chains, which transforms the analysis problem into discrete time. Later on, with the rise of slotted time telecommunica- tion protocols (e.g., ATM) discrete time models become primary modeling tools (for recent surveys see [1,6]). As a consequence, approximation of experimental data set with CPH gained more attention for a period of time. Especially, the acyclic subset of CPH distributions gained popularity due to the simple canonical forms available for their representation [4]. The use of acyclic PH distributions has a further im- portant consequence. A lot of properties of the acyclic CPH and the acyclic DPH distributions are identical. For example the same canonical representations apply for acyclic DPH distributions as for acyclic CPH ones [3]. Due to this similarity the problem of fitting DPH distributions was considered to be similar to the one of fit- ting CPH distributions, but this similarity is limited to the acyclic PH distributions only, as it is indicated through a counterexample in [11]. The canonical represen- tation of order 3 CPH distributions is provided in [5]. In this paper we investigate similar canonical forms for order 2 and 3 DPH distributions, which is a much more involved problem. The complexities of the canonical representation of order 3 CPH and DPH distributions are well represented by the number of forms needed to cover the whole order 3 CPH and DPH classes. [5] reports 3 forms which cover the class of order 3 CPH distributions, while here we present 8 forms to cover the class of order 3 DPH distributions.
In a preceding version of this paper [10] we have found canonical forms for DPH distributions of order 3 with all possible eigenvalue structures except one (referred to as PNP case) and presented a conjecture for that case. In the mean time it turned out that the conjecture for the PNP case in [10] was not valid. In this paper we repeat the proved findings of [10] for order 3 DPH distributions and devote special attention to the PNP case. The findings of [10] for order 2 DPH distributions are not presented here.
The rest of the paper is organized as follows. The next section provides a short introduction of DPH distributions. Section 3 summarizes the results of [10] on the canonical representation of DPH distributions of order 3 with all possible eigenvalue structures expect the PNP case. The new results of the paper are presented in Section 4, which discusses the canonical representation of order 3 DPH distributions with PNP eigenvalue structure. The difficulty of the PNP case comes from the fact that the methodology which allowed to prove the canonical forms for order 3 CPH and order 3 DPH with non PNP eigenvalue structure is not applicable for the PNP case.

Introduction
Discrete phase type and matrix geometric distributions
We define DPH [8] and matrix geometric (MG) distributions and their continuous counterparts CPH [9] and matrix exponential (ME) distributions [2] first.
Definition 2.1 Let X be a discrete positive random variable with probability mass function (pmf)
pi = Pr(X = i)= αAi−1a,	i = 1, 2,...,	(1)
where α is an initial row vector of size n, A is a square matrix of size n × n, a = (1 − A1), 1 is the column vector of ones of size n and α1 = 1 (there is no probability mass at t = 0).  In this case, we say that X is matrix geometrically
distributed with representation α, A, or shortly, MG(α, A) distributed.
We anticipate here and discuss, in details, later that the vector-matrix represen- tation (α, A) of a DPH distribution is not unique. More than one vector-matrix pairs might represent the same distribution.
Definition 2.2 If X is an MG(α, A) distributed random variable, where α and A
have the following properties:
αi ≥ 0,
Aij ≥ 0, A1 ≤ 1,
I − A is non-singular, where I is the unity matrix,
then we say that X is discrete phase type distributed with representation α, A, or shortly, DPH(α, A) distributed.
The vector-matrix representations satisfying the conditions of Definition 2.2 are called Markovian.
Definition 2.3 If X is an DPH(α, A) distributed random variable and A is an upper triangular matrix then we say that X is acyclic discrete phase type distributed with representation α, A, or shortly, ADPH(α, A) distributed.
The sets of ADPH, DPH, and MG distributions that can be described with size n representations are referred to as order n ADPH, DPH, and MG distributions, respectively. From Definition 2.1 – 2.3 it follows that
order n ADPH ⊂ order n DPH ⊂ order n MG.
[10] discusses the relation of these sets of distributions for order 2 and shows that order 2 ADPH ⊂ order 2 DPH ≡ order 2 MG.
Continuous phase type and matrix exponential distributions
The continuous counterparts of these distributions are the CPH and the matrix exponential distributions.

Definition 2.4 Let X be a continuous positive random variable with cumulative distribution function (cdf)
FX (x)= Pr(X < x)=1 − αeAx1,
where α is an initial row vector of size n, A is a square matrix of size n× n, 1 is the column vector of ones of size n and α1 =1 (there is no probability mass at t = 0). In this case, we say that X is matrix exponentially distributed with representation
α, A, or shortly, ME(α, A) distributed.
Definition 2.5 If X is an ME(α, A) distributed random variable, where α and A have the following properties: αi ≥ 0, Aii < 0, Aij ≥ 0 for i /= j, A1 ≤ 0, A is non-singular, then we say that X is continuous phase type distributed with
representation α, A, or shortly, CPH(α, A) distributed.
Definition 2.6 If X is a CPH(α, A) distributed random variable, where A is an upper triangular matrix then we say that X is acyclic continuous phase type dis- tributed with representation α, A, or shortly, ACPH(α, A) distributed.
Definition 2.7 Any order n ACPH(α, A) can be represented with the following vector matrix pair
⎡ −λ1 λ1	⎤

[γ1, γ2,..., γn] , ⎢
⎢
. . .	. . .
−λn−1 λn−1 ⎥

⎣	−λn ⎦
where 0 ≤ γi ≤ 1 and λi are the eigenvalues of −A such that λi ≥ λi−1. This representation is referred to as Cumani’s canonical form [4].
The vector-matrix representations satisfying the conditions of Definition 2.5 are called Markovian. By these definitions we have the following relations: order n ACPH ⊂ order n CPH ⊂ order n ME. Further more for order 2 we have [7,11]: order 2 ACPH ≡ order 2 CPH ≡ order 2 ME, which is a significantly difference compared to the order 2 sets of continuous distributions. In the sequel we focus on discrete distributions, the continuous ones are introduced for indicating the relations of DPH and CPH distributions.

Similarity transformation
A given DPH(α, A) distribution can be represented with more than one vector matrix pair.
Theorem 2.8 Let B a square matrix of size n such that B is invertible and B1 = 1. Then the vector matrix pair γ = αB, G = B−1AB is another representation of DPH(α, A).

Proof

p¯i = Pr(X¯ = i)= γGi−1(1 − G1)
= αB(B−1AB)i−1(1 − B−1AB1)
= αAi−1(1 − A1)= pi.



(2)


2

There are important consequences of Theorem 2.8. The B−1AB transformation of matrix A, referred to as similarity transformation, maintains the eigenvalues of matrix A and only modifies the associated eigenvectors. This way the eigenvalues of the matrix of any representation are strongly related with the distribution and can be used to characterize different distribution subclasses.
Further more, an infinite set of vector-matrix pairs represent a given ADPH, DPH, or MG distribution and ADPH and DPH distributions can be described with non-Markovian vector matrix pairs.
Definition 2.9 A canonical representation is a convenient vector-matrix pair cho- sen from the infinite set of vector-matrix pairs defining the same distribution.
For the convenient canonical representation of DPH distributions we follow the same principles as in [5]. That is the canonical representation is Markovian, takes Cumani’s acyclic canonical form [4] if possible and contains the maximal number of zero elements. Among the candidates with these properties we choose the ones which cover the largest set of distributions in order to reduce the set of considered structures.

Canonical form of order 3 DPH distributions
We classify order 3 DPH distributions according to their eigenvalue structure as follows. We order the eigenvalues in decreasing absolute value and denote the ones with negative real part by N and the ones with non-negative real part by P. For example, PNP means that 1 ≥ |s1|≥ |s2|≥ |s3| and Re(s1) ≥ Re(s3) ≥ 0 > Re(s2), where si, i = 1, 2, 3 denote the eigenvalues. Due to the fact that the eigenvalue with the largest absolute value (dominant) has to be real and positive (to ensure positive probabilities in (2) for large i) we have the following cases: PPP, PPN, PNP, PNN. Complex (conjugate) eigenvalues can occur only in cases of PPP and PNN.

Case PPP
We define the canonical form in the PPP case based on the canonical representation of order 3 CPH distribution.
Theorem 3.1 If the eigenvalues of the order 3 DPH(γ, G) are all non-negative we define the canonical form as follows. The vector matrix pair (γ, G − I) define an order 3 CPH. Let (α, A) be the canonical representation of CPH(γ, G − I) as defined in [5]. The canonical representation of DPH(γ, G) is (α, A + I).

Proof The complete proof of the theorem requires the introduction of the procedure defined in [5]. Here we only demonstrate the result for the case when the canonical representation of CPH(γ, G − I) is acyclic. When the eigenvalues of G are 1 > s1 ≥ s2 ≥ s3 > 0 the eigenvalues of G − I are 0 > s1 − 1 ≥ s2 − 1 ≥ s3 − 1 >
−1.  In this case the matrix of the acyclic canonical form of CPH(γ, G − I) is
⎡s3 − 1	0	s∗ = 0⎤

⎢1 − s2 s2 − 1	0
and the associated vector α is non-negative. Finally,

⎣	0	1 − s1 s1 − 1⎦
⎡  s3	0	s∗ = 0⎤

⎢1 − s2	s2	0
is non-negative and the associated exit probability

⎣	0	1 − s1	s1	⎦
vector, 1 − A1 = [1 − s3, 0, 0]T , is non-negative as well.
In the general case s∗ might be positive and si − 1, i = 1, 2, 3 are not the eigenvalues of A, but also in that case it holds that the elements of A + I and 1 − A1 are non-negative.	2
The rest of the cases require the introduction of new canonical structures.

Case PPN
Theorem 3.2 If the eigenvalues of the order 3 DPH(γ, G) are 1 > |s1| ≥ |s2| ≥ 
|s3| and Re(s1) ≥ Re(s2) > 0 > Re(s3) then its canonical representation is DPH(γB, A), where
⎡ x1 1 − x1	0	⎤
⎣ 0	x3	0	⎦
x1 = s1, x2 = s2 + s3, x3 =  −s2s3  and matrix B is composed by column vectors
b1 = 1 − b2 − b3, b2 = 	1	 G(1 − G1), b3 =  1  (1 − G1).
(1−x2)(1−x3)	1−x3
Proof The eigenvalues of the canonical matrix are s1, s2, s3. We need to prove that 0 ≤ xi < 1 and γbi ≥ 0 for i = 1, 2, 3. Based on the eigenvalue conditions of the PPN case the validity of x1 and x2 readable. For x3 it is readable that x3 > 0 and for the other boundary we have
 −s2s3	 < 1 1 − s2 − s3
−s2s3 < 1 − s2 − s3
0 < 1 − s2 − s3 + s2s3
0 < (1 − s2) (1 − s3)
`  >˛¸0  x `  >˛¸0  x

b2 and b3 are non-negative vectors, because (1 − G1) and G(1 − G1) are the one and two steps exit probability vector of DPH(γ, G) and 0 ≤ x2, x3 < 1.
Finally, from the first column of the matrix equation GB = BA we have another expression for b1, x1b1 = Gb1. That is, x1 = s1 is the largest eigenvalue of G and b1 is the associated eigenvector which is positive according to the Perron-Frobenius theorem.	2

Case PNN
Theorem 3.3 If the eigenvalues of the order 3 DPH(γ, G) are 1 > |s1| ≥ |s2| ≥ 
|s3|, Re(s1) > 0 > Re(s3) ≥ Re(s2) and |s2|2 ≤ 2s1(−Re(s2)) then its canonical representation is DPH(γB, A), where
⎡ x1 1 − x1	0	⎤

⎣ x3	0	0	⎦
x1 = −c2, x2 =  −c1  , x3 =   −c0   , the matrix elements are defined based on the
1+c2	1+c1+c2
coefficients of the characteristic polynomial of G, c0 = −s1s2s3, c1 = s1s2 + s1s3 +
s2s3, c2 = −s1−s2−s3. and matrix B is composed by column vectors b1 = 1−b2−b3,
b2 = 	1	 G(1 − G1), b3 =  1  (1 − G1).
(1−x2)(1−x3)	1−x3
Proof The eigenvalues of the canonical matrix are s1, s2, s3. We need to prove that
0 ≤ xi < 1 and γbi ≥ 0 for i = 1, 2, 3.
Let λi = −si for i = 1, 2, 3. The trace of matrix G (the sum of its diagonal elements) equals to the sum of its eigenvalues and so the sum of the eigenvalues as well as −c2 are non-negative. Consequently, 0 ≤ x1 < 1. Now we consider x2. (1 + c2) is positive, so we need to show that c1 is non-positive.
If the eigenvalues are all real, then we can write

c1 = s1s2 + s3 (s1 + s2),
`<˛¸0x	`<˛¸0x `	≥˛¸0	x

that is the sum of a negative and a non-positive numbers, so the result will also be negative.
If s2 and s3 are complex conjugates, we can write them as s2 = −u + iv and
s3 = −u − iv where u, v are positive reals. With these notations:

c1 = s1(−u + iv)+ s1(−u − iv)+ (u2 + v2)= u2 + v2 − 2s1u ≤ 0
where the last inequality comes from |s2|2 ≤ 2s1(−Re(s2)).

Now we show that x2 is less than 1:
x2 < 1
−c1 < 1+ c2
0 < 1+ c1 + c2
We can see that the last inequality holds if we write 1+ c1 + c2 in the following way:
1+ c1 + c2 = (1 + λ1)(1 + λ2)(1 + λ3) − λ1λ2λ3 > 0,
`	>˛¸0	x	` <˛¸0 x
additionally, λ1λ2λ3 = c0 so we also get, that x3 is positive:


<0
x  =	− ¸xc0`˛
`	>˛¸0	x

> 0.

The upper bound of x3 also follows:
x3 < 1
−c0 < 1+ c1 + c2
0 < 1+ c0 + c1 + c2
0 < (1 + λ1)(1 + λ2)(1 + λ3)
b2 and b3 are non-negative vectors, because (1 − G1) and G(1 − G1) are the one and two steps exit probability vector of DPH(γ, G) and 0 ≤ x2, x3 < 1.
Finally, from the matrix equation GB = BA we have an explicit expression for b1, b1 = 	1    G2(1 − G1). That is, b1 is a probability vector (G2(1 − G1)) multiplied by a positive constant.	2
Theorem 3.3 does not cover the case when |s2|2 > 2s1(−Re(s2)). This case can occur only when s2 and s3 are complex conjugate eigenvalues. The following theorem applies in this case.
Theorem 3.4 If the eigenvalues of the order 3 DPH(γ, G) are 1 ≥ |s1|≥ |s2|≥ |s3|, Re(s1) > 0 > Re(s3) ≥ Re(s2) and |s2|2 > 2s1(−Re(s2)) then we use the same canonical form as in case of PPP in Theorem 3.1.
Proof Similar to the proof of Theorem 3.1, this proof also builds on the procedure of [5] which do not introduce here.	2
The cases considered in this section and in [5] have been proved based on the properties of the eigenvalues and the fact that the probability mass (density) function of DPH (CPH) distributions are non-negative. It seems that for the PNP case which is deferred to the next section these properties are not sufficient for proving the completeness of the canonical forms, but the boundaries of the order 3 DPH class

(which is different from the ones of the order 3 MG class) needs to be utilized in an explicit way. In other words utilizing the fact that the probability mass function of DPH distributions is not negative is insufficient in the PNP case.


Case PNP
For the PNP case the canonical form is based on the following main observation.
Observation 1 If the eigenvalues of the order 3 DPH(γ, G), s1, s2, s3, are such that 1 > |s1| ≥ |s2| ≥ |s3|, Re(s1) ≥ Re(s3) ≥ 0 > Re(s2) then it can be represented in one of the following three forms.
PNP1: DPH(α, A), where
⎡ x1 1 − x1	0	⎤

⎣ 0	x3	0	⎦
c0 = −s1s2s3, c1 = s1s2 + s1s3 + s2s3, c2 = −s1 − s2 − s3, are the coefficients of the characteristic polynomial of G, the matrix elements are defined based on
these coefficients as x1 = −c2, x2 =  c0−c1c2  , x3 = 	c0(1+c2)	 and matrix B

c2(1+c2)
c0−c2−c1c2−c2

is composed by column vectors b1 = 1 − b2 − b3, b2 = 	1	 G(1 − G1),

b3 =  1  (1 − G1).
PNP2: DPH(α, A) with


⎡ x1 0	0	⎤

a3	a1s1+a2s2
1−s3  (s1−1)(s2−1)
(a1+a2)(1−s1−s2) (s1−1)(s2−1)
2 1 − x2 ⎥

⎣ 0 x3	0	⎦
where x1 = s3, x2 = s1 + s2, x3 =  −s1s2  , and a1, a2 are the coefficients of the geometric series of the probability mass function pi = a1si−1 + a2si−1 + a3si−1.

PNP3: DPH(α, A) with
1	2	3


⎡ x1 1 − x1	0	⎤



⎣ 0	x3	x33 ⎦
where the parameters are defined as a function of x33 and the coefficients of the

characteristic polynomial


x1 = −c2
— x33
,	x2
= c0 − (c2 + x33)(c1 + x33(c2 + x33)) ,
(c2 + x33 + 1)(c2 + 2x33)

	(c2 + x33 + 1)(c0 + x33(c1 + x33(c2 + x33)))	
x = −	,
3	3 + 2(c2 + 1)x2 + (c1 + (c2 + 1)(c2 + 2))x33 − c0 + c2(c1 + c2 + 1)
matrix B is composed by column vectors b1 = 1−b2−b3, b2 = 	1  (G− x33I)(1 − G1), b3 =   1   (1 − G1) and x33 is the smallest non-negative real solution of α1 = γb1 = 0.
It is important to note that, similar to the canonical representation of the pre- vious section, the PNP1, PNP2, PNP3 representations as defined above are ap- plicable with both, Markovian and non-Markovian, (γ, G) vector-matrix pairs.
Based on Observation 1, for the PNP case a unique canonical form can be defined as follows. If PNP1 is Markovian then PNP1 is the canonical form. If PNP1 is non-Markovian and PNP2 is Markovian then PNP2 is the canonical form. If PNP1 and PNP2 are non-Markovian then PNP3 is the canonical form with the smallest positive x33 which satisfies αb1 = 0. The main observation is supported by the following results.
Theorem 4.1 Representations PNP1, PNP2 and PNP3 are identical with the order 3 DPH(γ, G).
Proof In all representations PNP1, PNP2 and PNP3, the eigenvalues of matrix A are s1, s2, s3. The identity of representations PNP1 and PNP3 with DPH(γ, G) comes from the fact that these representations are defined by a similarity transfor- mation with matrix B, and B is the solution of BA = GB. Representation PNP2 is defined by the coefficients of the geometric series of the probability mass function.
It is easy to see, that pi = a1si−1 + a2si−1 + a3si−1 = αAi−1(1 − A1) for i ≥ 1. 2
1	2	3
Theorem 4.2 If the order 3 DPH(γ, G) is PNP type then its PNP1 representation is such that matrix A is substochastic (non-negative with x3 < 1) and the second and third coordinate of α is non-negative.
Proof We need to prove that 0 ≤ xi < 1 and γbi ≥ 0 for i = 2, 3.
Let λi = −si for i = 1, 2, 3. In this case λ2 is strictly positive and so λ1 is also strictly negative. λ3 is non-positive. So c0 = λ1λ2λ3 ≥ 0. The positivity of x1 = −c2 follows from the fact that the sum of the eigenvalues of G is positive.
1+ c2 =1 + λ1 + λ2 + λ3 > 0

`>˛¸0x
`≥˛¸0

1 > −c2
1 > x1

The first inequality follows from −1 < λ1 and |λ3| ≤ |λ2|. The next inequality also

follows from −1 < λ1, λ3 and 0 < λ2.
1+ c0 + c1 + c2 = (1 + λ1)(1 + λ2)(1 + λ3) > 0
In the following we use that −c2 < 1. From that we get c0 ≥ −c2c0.
c0 − c2 − c1c2 − c2 ≥− c2 (1 + c1 + c2 + c0) > 0
`<˛¸0x `	>˛¸0	x
The above expression is the denominator of x3. In its nominator c0 is non-negative and 1+ c2 is positive, so x3 is non-negative too. We need to show that x3 < 1:
x3 < 1
c0 + c0c2 < c0 − c2 − c1c2 − c2
0 < −c2(1 + c0 + c1 + c2).
We saw that above. At the end of this case we consider x2:
x2 < 1
c0 − c1c2 > c2(1 + c2) c0 − c2 − c1c2 − c2 > 0.
We use here that the eigenvalues of λi are decreasing and only λ2 is positive:

≤0	≤0	≥0
x = −(λ¸ 1 x+` λ˛2)(λ¸ 1 x+` λ˛3)(λ¸ 2 x+` λ˛3) ≥ 0
`>˛¸0x `>˛¸0x
b2 and b3 are non-negative vectors, because (1 − G1) and G(1 − G1) are the one and the two steps exit probability vectors of DPH(γ, G) and 0 ≤ x2, x3 < 1.	2
According to Theorem 4.2 the PNP1 representation of an order 3 DPH with PNP eigenvalue structure is Markovian if and only if the first coordinate of its initial vector is Markovian. The following Theorem presents the boundary of this set.
Theorem 4.3 If the order 3 DPH(γ, G) is PNP type then its PNP1 representation is Markovian iﬀ

a  > (s2 − 1)(s1 + s3)  a (s
— s ) s2 + (s + s
— 1)s
+ (s
— 1)(s
+ s ) 

where
— (s1 − 1)(s3 − 1)s3(s2 + s3) 
ϑ = (1 − s1) s2 − s2  s2 + (s3 − 1)s2 + (s3 − 1)s3 + s1(s2 + s3 − 1) 

Proof  A (non-Markovian) matrix representation of pi = a1si−1 + a2si−1 + a3si−1 is
1	2	3
⎛ s1 0 0 ⎞


1−s1
1−s2
1−s1
1−s2
⎝ 0 0 s3 ⎠

ing (κ, K) to PNP1 representation and solving α1 = γb1 > 0 gives the statement of the theorem.	2
Theorem 4.4 If the order 3 DPH(γ, G) is PNP type then its PNP2 representation is Markovian if a1 + a2 > 0, a1s1 + a2s2 > 0 and 1 − a1/(1 − s1) − a2/(1 − s2) > 0.
Proof Matrix A is Markovian, because the eigenvalue conditions readily ensure that 0 < x1, x2, x3 < 1. Additionally, conditions a1 + a2 > 0, a1s1 + a2s2 > 0 and 1 − a1/(1 − s1) − a2/(1 − s2) > 0 ensures that the 3rd, 2nd and 1st coordinate of α, respectively, are non-negative.	2
For PNP3 representation the relation of the elements of vector α and a1, a2 can be obtained in the same way as for PNP1 representation in the proof of Theorem
4.3. The following theorems bound the set of order 3 DPH distributions which have Markovian PNP3 representation.
Observation 2 If the order 3 DPH(γ, G) is PNP type and its PNP1 repre- sentation is non-Markovian then its PNP3 representation is not Markovian if a2 < (a1s1(−s1 + s3))/(s2(s2 − s3)).
When x33 = s3 (the smallest positive eigenvalue) in the PNP3 representation (that is α1 = 0) the x3 element of the representation becomes 0 and a2 = (a1s1(−s1+ s3))/(s2(s2 −s3)). Below this boundary the PNP3 representation is not Markovian.
Observation 3 If the order 3 DPH(γ, G) is PNP type and its PNP1 representation is non-Markovian then the upper boundary of the a2 parameter of the order 3 DPH distributions with Markovian PNP3 representation is obtained when α2(x33)= 0.
The expression for the upper boundary can be obtained by symbolic analysis tools, but it is extremely complex and meaningless to present here, but numeric analysis for a PNP triple of eigenvalues are easy to perform.

Numerical demonstration
For a given triple of PNP eigenvalues Theorem 4.3 defines a half plane on the a1, a2 plane where the PNP1 representations are Markovian, while Theorem 4.4 defines a triangle on the same plane where the PNP2 representations are Markovian. Figure 1 depicts these Markovian regions for PNP1 and PNP2 representations.
Observations 2 and 3 presents the shape of the region where the PNP1 repre- sentation is non-Markovian and the PNP3 representation is Markovian. The lower bound is a straight line while the upper bound has a strange curve. Figure 2 demon- strates Markovian regions for the three representations with the same eigenvalues. We note that the applied graphical tool has got some weaknesses. The triangular

representing Markovian PNP2 representations in Figure 2 should be identical with the one in Figure 1. The tool tends to cut the peeks of the regions. For example both the Markovian PNP2 and the Markovian PNP3 regions start from (a1, a2)= (0, 0) as it is the case in Figure 1.
It can be seen in Figure 2 that there is no need for PNP3 representation when the eigenvalues are 0.8, −0.7, 0.3. A different case occurs when the eigenvalues are 0.25, −0.15, 0.05, see Figure 3. In this case PNP2 representation useless and the PNP1 and PNP3 representations cover the Markovian PNP2 aria. But there are cases (e.g., when the eigenvalues are 0.28, −0.22, 0.05 in Figure 4) when all the three representations are needed with the same set of eigenvalues. Figure 5) enlarges the area where the three sets meet.



0.2	0.2




0.1	0.1




0.0	0.0




–0.1	–0.1




–0.2	–0.2


0.00	0.05	0.10	0.15	0.20	0.25
Figure 1. Sets of the Markovian PNP1 and PNP2 representations on the a1, a2 plane with eigenvalues 0.8, −0.7, 0.3
0.00	0.05	0.10	0.15	0.20	0.25
Figure 2.  Sets of the Markovian PNP1, PNP2 and PNP3 representations with eigenval- ues 0.8, −0.7, 0.3

0.3	0.3
0.2	0.2
0.1	0.1
0.0	0.0
–0.1	–0.1
–0.2	–0.2

–0.3
0.00	0.05	0.10	0.15	0.20	0.25	0.30
–0.3
0.00	0.05	0.10	0.15	0.20	0.25	0.30

Figure 3. Limits of the Markovian PNP representa- tions with eigenvalues 0.25, −0.15, 0.05
Figure 4. Limits of the Markovian PNP representa- tions with eigenvalues 0.28, −0.22, 0.05

0.35
0.30
0.25
0.20
0.15
0.10	0.12	0.14	0.16	0.18	0.20
Figure 5. Enlarged plot of the Markovian PNP representations with eigenvalues 0.28, −0.22, 0.05

Exhaustive search
For the majority of the eigenvalue structures, which are discusses in Section 3 we found simple analytic ways to prove that all Markovian order 3 DPH with the given properties can be transformed into the associated Markovian canonical form. Unfortunately, we could not find such simple proof for the PNP case.
Looking for an approach to prove Observation 1 we considered the following ex- haustive method. Based on the fact that any Markovian order 3 DPH representation with less than 6 zero elements in the representation (initial vector, matrix and exit vector) can be similarity transformed to a Markovian representation with 6 zero el- ements, it is enough to prove that all Markovian order 3 DPH representations with 6 zero elements can be represented according to Observation 1.
For a given distribution of the 6 zero elements such a proof is feasible and its complexity is comparable with the complexity of the proofs of Section 3. The weak- ness of this approach is the high number different distribution of the 6 zero elements. We collected the possible non-symmetric and non-circular symmetric distributions of the 6 zero elements in the representation and eliminated the obviously meaning- less ones (e.g. where the matrix has lower rank) and we remained with more than 300 different structures (actually we worked with 319 structures, but some of them might still be redundant). This high number of the different distributions of zero elements inhibited as to prove Observation 1 along this approach.
In spite of the fact that the exhaustive approach does not lead us to a formal proof we made a good use of it in extensive numerical analysis and counter example search. Previously, we used a large number of random DPH generation for finding counter examples [10], but the probability of sampling a DPH with a PNP eigenvalue structure whose PNP1 and PNP2 representation are non-Markovian and PNP3 representation is Markovian was negligible small. Based on the results of Section 4 the boundaries of the sets for which the PNP1, PNP2 and PNP3 representations are Markovian are easy to compute, and due to the exhaustive approach we could

focus the numerical investigations to the neighborhood of these boundaries.
By implementing a general transformation method which transforms to the 300 different structures with 6 zero elements we computed numerically how many of them are Markovian for a s1, s2, s3, a1, a2 tuple. Our numerical experiences verified Observation 1 together with Theorem 4.3, Theorem 4.4 and Observations 2 and 3. Outside the Markovian area of the PNP1, PNP2 and PNP3 representations non of the other representations were Markovian, while inside the areas typically more than one of the 300 different structures were Markovian, and at least one of the PNP1, PNP2 and PNP3 representations was always among the Markovian ones.

Implementation notes
The theorems presenting the canonical forms for various eigenvalue structures define indeed explicit procedures based on the eigenvalues (s1, s2, s3, with decreasing ab- solute values) and occasionally on the (a1, a2) coefficients. As an example Figure 6 demonstrate the steps of the procedure for generating the PPN canonical form based on Theorem 3.2. We note that this procedure can be called with both, Markovian and non-Markovian γ, G representation.
1: procedure CanonicalDPH-PP(γ, G)
2:	[s1, s2, s3]= eig(G);
3:	e = [1; 1; 1];
4:	x1 = s1; x2 = s2 + s3; x3 = −s2s3/(1 − s2 − s3);
5:	b3 = 1/(1 − x3)(e − G ∗ e);
6:	b2 = 1/(1 − x2)G ∗ b3;
7:	b1 = e − b2 − b3;
⎡ x1 1 − x1	0	⎤




9: end procedure
⎣ 0	x3	0	⎦

Figure 6. Canonical representation of order 3 DPH with PPN eigenvalue structure based on Theorem 3.2
If the (a1, a2) coefficients are needed from a γ, G representation for a canonical form with different eigenvalues, they can be obtained from the spectral decomposi-
tion of matrix G as follows. Let G = Σ3	skukvk be the spectral decomposition
of G with right eigenvectors uk and left eigenvectors vk, then
pi = Pr(X = i)= γGi−1(1 − G1)= Σ si−1 γukvk(1 − G1),	i = 1, 2,..., 



defines the (a1, a2) coefficients.
k=1
`	˛ak¸	x

The only exception, where the presented canonical form does not define an ex- plicit procedure is the PNP3 representation. In that case the x33 value is defined as

the smallest non-negative real solution of γb1 = 0, which is a polynomial equation of order 3. Due to the explicit solution of order 3 polynomial equations we could have defined the solution explicitly, but it was too complex to be presented here. Sym- bolic analysis packages can easily compute the explicit expression for the solutions of γb1 = 0. For a fully symbolic analysis (based on the eigenvalues) those symbolic solutions can be used, otherwise one can resort to a numerical solution.
The boundaries of the eigenvalue based decompositions are not discussed yet. There are some boundaries, e.g., the limit between PPP and PPN eigenvalue struc- tures where one of the eigenvalue is 0 and the obtained distribution can be rep- resented by an order 2 DPH. In other cases the canonical representation of both sides of the limit are applicable, e.g. on the limit between the PNP and PPN eigen- value structures (for example s1 = 0.8, s2, s3 = ±0.4), both the PNP and the PPN canonical forms are applicable.

References
Alfa, A., Discrete time queues and matrix-analytic methods, Top 10 (2002), pp. 147–185.
URL http://dx.doi.org/10.1007/BF02579008

Bladt, M. and M. F. Neuts, Matrix-exponential distributions: Calculus and interpretations via flows, Stochastic Models 19 (2003), pp. 113–124.
Bobbio, A., A. Horváth, M. Scarpa and M. Telek, Acyclic discrete phase type distributions: Properties and a parameter estimation algorithm, Performance Evaluation 54 (2003), pp. 1–32.
Cumani, A., On the canonical representation of homogeneous Markov processes modelling failure-time distributions, Microelectronics and Reliability 22 (1982), pp. 583–602.
Horváth, G. and M. Telek, On the canonical representation of phase type distributions, Performance Evaluation 66 (2009), pp. 396 – 409.
Lakatos, L., L. Szeidl and M. Telek, “Introduction to Queueing Systems with Telecommunication Applications,” Springer, 2013.
URL  http://www.springer.com/mathematics/probability/book/978-1-4614-5316-1

Mitchell, K. and A. van de Liefvoort, Approximation models of feed-forward G/G/1/N queueing networks with correlated arrivals, in: Proc. 4th Int. Workshop on Queueing Networks with Finite Capacity (2000), pp. 32/1–12.
Neuts, M., Probability distributions of phase type, in: Liber Amicorum Prof. Emeritus H. Florin (1975),
pp. 173–206.
Neuts, M., “Matrix Geometric Solutions in Stochastic Models,” Johns Hopkins University Press, Baltimore, 1981.
Papp, J. and M. Telek, Canonical representation of discrete phase type distributions of order 2 and 3, in: In Proc. of UK Performance Evaluation Workshop, UKPEW 2013, 2013.
Telek, M. and A. Heindl, Matching moments for acyclic discrete and continuous phase-type distributions of second order, International Journal of Simulation Systems, Science & Technology 3 (2002), pp. 47–57, special Issue on: Analytical & Stochastic Modelling Techniques.
