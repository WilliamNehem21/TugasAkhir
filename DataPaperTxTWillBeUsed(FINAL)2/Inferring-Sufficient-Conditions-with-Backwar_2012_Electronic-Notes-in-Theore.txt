Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 287 (2012) 89–100
www.elsevier.com/locate/entcs

Inferring Sufficient Conditions with Backward Polyhedral Under-Approximations
Antoine Min´e1,2
CNRS & E´cole Normale Sup´erieure 45, rue d’Ulm, 75005 Paris
France

Abstract
In this article, we discuss the automatic inference of sufficient pre-conditions by abstract interpretation and sketch the construction of an under-approximating backward analysis. We focus on numeric domains and propose transfer functions, including a lower widening, for polyhedra, without resorting to disjunctive com- pletion nor complementation, while soundly handling non-determinism. Applications include the derivation of sufficient conditions for a program to never step outside an envelope of safe states, or dually to force it to eventually fail. Our construction is preliminary and essentially untried, but we hope to convince that this avenue of research is worth considering.
Keywords: abstract interpretation, static analysis, polyhedra, backward analysis.


Introduction
A major problem studied in program verification is the automatic inference of in- variants and necessary conditions for programs to be correct. In this article, we consider a related problem: the inference of sufficient conditions.
Consider the simple loop in Fig. 1, where j is incremented by a random value in [0; 1] at each iteration. A forward invariant analysis would find that, at the end of the loop, j ∈ [0; 110] and the assertion can be violated. A backward analysis of necessary conditions would not infer any new condition on the initial value of j because any value in [0; 10] has an execution satisfying the assertion. However, a backward sufficient condition analysis would infer that, for the assertion to always hold, it is sufficient to start with j ∈ [0; 5]. Applications of sufficient conditions include: counter-example generation [3], contract inference [6], verification driven by temporal properties [12], optimizing compilation by hoisting safety checks, etc.

1 This work is supported by the INRIA project “Abstraction” common to CNRS and ENS in France.
2 Email: mine@di.ens.fr


1571-0661 © 2012 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2012.09.009

j = [0;10]; i = 0;
while (i < 100) { i++; j = j + [0;1]; }
assert (j <= 105);

Fig. 1. Simple loop example.

Abstract interpretation [4] has been applied with some success [1] to the auto- matic generation of (over-approximated) invariants, thanks notably to the design of effective abstract domains, in particular numeric domains [7], allowing efficient sym- bolic computations in domains of infinite size and height. Yet, it has barely been applied to the automatic inference of sufficient conditions (although [4] discusses under-approximations) and then generally using finite domains or bounded control- flow paths [3], while logic-based weakest precondition methods [8] have thrived. We attribute this lack to the perceived difficulty in designing theoretically opti- mal [17] as well as practical under-approximations, and the fact that sufficient and necessary conditions differ in the presence of non-determinism. Existing solutions are restricted to deterministic programs, exact abstract domains (e.g., disjunctive completions, which do not scale well), or set-complements of over-approximating domains (e.g., disjunctions of linear inequalities, that cannot express invariants as simple as j ∈ [0; 5]). We present here a preliminary work that hints towards the opposite: it seems possible to define reasonably practical (although non-optimal) polyhedral abstract under-approximations for non-deterministic programs.
Section 2 introduces sufficient conditions at the level of transition systems. Sec- tion 3 presents some algebraic properties of backward functions, which are exploited in Sec. 4 to design under-approximated operators for polyhedra. Section 5 discusses related work and Sec. 6 concludes.

Transition Systems
Invariants and sufficient conditions
To stay general, we consider, following [4], a small-step operational semantics and model programs as transition systems (Σ,τ ); Σ is a set of states and τ ⊆ Σ × Σ is a transition relation. An execution trace is a finite or infinite countable sequence of states (σ1,..., σi,.. .) ∈ Σ∞ such that ∀i : (σi, σi+1) ∈ τ .
Invariants. The invariant inference problem consists in, given a set I ⊆ Σ of initial states, inferring the set inv(I) of states encountered in all executions starting in I.
This set can be expressed as a fixpoint following Cousot [4]: 3
inv(I)= lfpI λX.X ∪ post(X)	(1)
def
where lfpx f is the least fixpoint of f greater than or equal to x and post(X) = { σ ∈
Σ | ∃σj ∈ X : (σj, σ) ∈ τ }.

3 In [4], Cousot notes it sp(τ∗) and defines it rather as lfp λX.I ∪ post(X). Both formulations are equivalent: both equal ∪n≥0 postn(I) because post is a complete ∪—morphism in the complete lattice (r(Σ), ⊆, ∪, ∩).

Sufficient conditions. In this article, we consider the reverse problem: sufficient condition inference, which consists in, given an invariant set T to obey, inferring the set of initial states cond(T ) that guarantee that all executions stay in T . It is also given in fixpoint form following Bourdoncle [2]: 4
cond(T ) = gfpT λX.X ∩ p˜re(X)	(2) where gfpx f is the greatest fixpoint of f smaller than or equal to x and
p˜re(X) = { σ ∈ Σ | ∀σj ∈ Σ : (σ, σj) ∈ τ =⇒ σj ∈ X }. cond(T ) is indeed a
sufficient condition and, in fact, the most general sufficient condition:
Theorem 2.1 ∀T, X : inv(cond(T )) ⊆ T and inv(X) ⊆ T =⇒ X ⊆ cond(T ).
Non-determinism. The function p˜re we use differs from the function pre used in most
backward analyses [2,4,16] and defined as pre(X) = { σ ∈ Σ | ∃σj ∈ X : (σ, σj) ∈
τ }. Indeed, p˜re(X) /= pre(X) when the transition system is non-deterministic, i.e., some states have several successors or none. Non-determinism is useful to model unspecified parts of programs, such as the interaction with unanalyzed libraries or with the environment (as in Fig. 1), and permits further abstractions (Sec. 4.6). Using p˜re ensures that the target invariant T holds for all the (possibly infinite) sequences of choices made at each execution step, while pre would infer conditions for the invariant to hold for at least one sequence of choices, but not necessarily all (a laxer condition).
Blocking states. Any state σ without a successor satisfies ∀X : σ ∈ pre(X), and so, σ ∈ T =⇒ σ ∈ cond(T ). Such states correspond to a normal or abnormal program termination — e.g., the statement y = 1/x generates a transition only from states where x /= 0. In the following, we assume the absence of blocking states by adding transitions to self-looping states: error states transition to a self-loop ω ∈/ T , and normal termination states transition to a self-loop α ∈ T , so that no erroneous execution can stem from cond(T ).
Approximation. Transition systems can become large or infinite, so that inv(I) and cond(T ) cannot be computed efficiently or at all. We settle for sound approxima- tions. Invariant sets are over-approximated in order to be certain to include all program behaviors. Sufficient condition sets are dually under-approximated as any subset Ij ⊆ cond(T ) still satisfies inv(Ij) ⊆ T .
Applications of sufficient conditions
This section presents a few applications of computing an under-approximation of cond(T ). The rest of the paper focuses on how to compute it effectively.
Given a set of initial states I, the subset of initial states that never lead to a run-
def
time error nor assertion violation can be expressed as Iω = I ∩ cond(Σ \ {ω}). An
analyzer computing an under-approximation of Iω infers sufficient initial conditions

4 In [2], Bourdoncle calls this set always(T ) and defines it equivalently as gfp λX.T ∩ p˜re(X), but only considers the case where 6σ : | post({σ})| = 1, i.e., p˜re = pre.

so that all executions are correct (i.e., never reach ω). Applied to a single function, it infers sufficient conditions on its parameters and global entry state ensuring its correct behavior. An application to software engineering is the automatic inference of method contracts. An application to optimizing compilation is run-time check hoisting: a fast version of the function without any check is called instead of the regular one if, at the function entry, sufficient conditions making these checks useless hold.
As last application, we consider the automatic inference of counter-examples. Given a set T of target states (e.g., erroneous states), we seek initial conditions such that all the executions eventually reach a state in T . In that case, Thm. 2.1 cannot be directly applied as it focuses on invariance properties while we are now interested in an inevitability property. We now show that this problem can nev- ertheless be reduced to an invariance one, of the form cond(Tj) for some T j. We use an idea proposed by Cousot et al. [5] for the analysis of termination (another inevitability property): we enrich the transition system with a counter variable l counting execution steps from some positive value down to 0 when reaching T . Given (Σ,τ ) and T ⊆ Σ, we construct (Σj,τj) and T j as:
Σj d=ef Σ × N,	T j d=ef { (σ, l) ∈ Σj | l > 0 ∨ σ ∈ T }

((σ, l), (σj, lj)) ∈ τ j
⇐d⇒ef
((σ ∈/ T ∧ (σ, σj) ∈ τ ) ∨ σ = σj ∈ T ) ∧ l = lj +1 

This transformation is always sound and sometimes complete:
Theorem 2.2 If (σ, l) ∈ cond(Tj), then all the traces starting in σ eventually enter a state in T . If the non-determinism in τ is ﬁnite, 5 the converse holds.
The restriction to finite non-determinism may hinder the analysis of fair systems, as an infinite number of countable choices must be performed, e.g.:
while ([0; 1]) { n = [0; +∞]; while (n > 0) { n = n − 1 }} . 6
Backward Functions
Program semantics are not generally defined as monolithic transition systems, but rather as compositions of small reusable blocks. To each atomic language instruction i corresponds a forward transfer function posti, and we will construct backward transfer functions directly from these posti. Formally, given a function f : P(X) →
→−
P(Y ), we define its backward version f as:

→−
f : P(Y ) → P(X) s.t.
→−−
→−
f (B)
= { a ∈ X | f ({a}) ⊆ B } .	(3)
→−

We note immediately that post = p˜re. Moreover, · enjoys useful properties. We
list a few ones to give a gist of the underlying algebraic structure:
Theorem 3.1

5 I.e., 6σ : post({σ}) is finite, which is weaker than requiring a bounded non-determinism.
6 Note that, if the number of infinite choices is bounded, they can be embedded as fresh non-initialized variables to obtain a program with finite non-determinism.

(i)
→−
f is a monotonic, complete ∩−morphism.

→−	→−	→−

(ii)
f is a sup-∪−morphism: ∪i∈I f (Bi) ⊆ f (∪i∈IBi)

(in general it is not a ∪−morphism, nor is it strict, even when f is).
→−

(iii) If f is a strict complete ∪−morphism, then A ⊆
→—
f (B) ⇐⇒ f (A) ⊆ B, that

is, we have a Galois connection: P(X) →−f−− P(Y ).
f

→−−−
→−	→−

(iv)
f ∪ g =
f ∩ g (note that ∪, ∩, ⊆ are extended point-wise to functions).

→−−−
→−	→−

(v)
f ∩ g ⊇
f ∪ g (in general, the equality does not hold).

→−−
→−	→−

If f is monotonic, then f ◦ g ⊆
If f is a strict complete ∪−
g ◦ f .
→−−
→− ◦ →−

f ⊆ g =⇒ →−g ⊆ →−
morphism, then f ◦ g = g	f .

If f and g are strict complete ∪−morphisms, then f ⊆ g ⇐⇒ →−g ⊆ →−
→−−−−−−−−−−−−−−−

If f  is a strict complete ∪−morphism,	then
→−
λy.gfpy (λz.z ∩ f (z)).
λx.lfpx (λz.z ∪ f (z))	=

Property iv is useful to handle semantics expressed as systems of flow equations
→−
∀i : Xi = ∪j Fi,j(Xj); we get: ∀j : Xj = ∩j Fi,j(Xi). Compositional semantics
make use of ◦, ∪, and nested least fixpoints (vii, iv, x). Properties iii and x gen- eralize Thm. 2.1 and Eq. 2. Finally, viii–ix, turn forward over-approximations into backward under-approximations. All these properties will also be useful to design abstract operators for atomic statements, in Sec. 4.
Under-Approximated Polyhedral Operators
We use the results of the previous section to design practical backward operators sufficient to implement an analysis. We focus on numeric properties that we abstract using convex closed polyhedra (although the ideas we present can be used in other linear inequality domains, such as intervals or octagons). Familiarity with the over- approximating polyhedron domain [7] is assumed.
We assume a set V of variables with value in Q. Environments ρ ∈E = V → Q
map each variable to its value in Q. A polyhedron P can be encoded as a set C =
{ c ,...,c } of affine constraints c = (a · x ≥ b ), which represents γ (C) d=ef { ρ ∈
1	n	i	i	i	c
E | ∀(a · x ≥ b) ∈ C : a · ρ(x) ≥ b }, but also as a set of vertices and rays (V, R), so
called generators, which represents γ (V, R) = { Σ	α v + Σ	β r | α ,β ≥

Σ	v∈V
r∈R  r	v	r

0,	v∈V αv = 1 }. Here, a denotes a vector, · is the dot product, and ρ(x) is the
vector of variable values in environment ρ. Given a statement s, we denote by
τ {| s |} its forward concrete transfer function, and by →−τ {| s |} its backward version
→−τ {| s |} def →−−−
Note that ∅ can always be used to under-approximate any →−τ {| s |}, the same way over-approximating analyzers soundly bail-out with E in case of a time-out or unimplemented operation. Because backward operators are generally not strict



Fig. 2. Modeling the test y ≤ 0 backwards in the concrete (a) and with polyhedra (b)–(d).


(i.e.,
→−
f (∅) /= ∅, as the tests in Sec. 4.1), returning ∅ at some point does not prevent

finding a non-empty sufficient condition at the entry point; it only means that the analysis forces some program branch to be dead.

Tests
We first consider simple affine tests a · x ≥ b. We have:
τ {| a · x ≥ b? |} R	= { ρ ∈ R | a · ρ(x) ≥ b }
and so	→−τ {| a · x ≥ b? |} R = R ∪{ ρ ∈E | a · ρ(x) < b }
On polyhedra, forward affine tests are handled exactly by simply adding the con- straint. However, the result of a backward affine test on a closed convex set is gener- ally not closed nor convex (see Fig. 2.a), so, we need an actual under-approximation. One solution is to remove a · x ≥ b from the set C, as:
Theorem 4.1 γc(C \ {a · x ≥ b}) ⊆ →−τ {| a · x ≥ b? |} γc(C).
Sometimes, this results in the identity (Fig. 2.b) which is indeed a (trivial) under- approximation. More precise (i.e., larger) under-approximations can be computed by removing the constraints that are redundant in C ∪ {a · x ≥ b}. Intuitively, these are constraints that restrict γc(C) in the half-space a · x < b, while the test result is not restricted in this half-space (Fig. 2.c). In practice, we first add a · x ≥ b, then remove redundant constraints, then remove a · x ≥ b.
Consider now the degenerate case where γc(C) |= a · x = b (Fig. 2.d). Con- straint representations are not unique, and different choices may result in dif- ferent outcomes.  To guide us, we exploit the fact that tests come in pairs, one for each program branch: while a forward semantics computes, at a branch
split, (Y, Z) = (τ {| a · x ≥ b? |} X, τ {| a · x < b? |} X), the backward computation merges both branches as X = →−τ {| a · x ≥ b? |} Y ∩ →−τ {| a · x < b? |} Z. Assum- ing that Y = γg(VY , RY ) is degenerate, we construct a non-degenerate polyhe- dron before computing →−τ {| a · x ≥ b? |} by adding the rays r from Z such that τ {| a · x ≥ b? |} γg(VY , RY ∪ {r}) = τ {| a · x ≥ b? |} γg(VY , RY ). The effect is to create common rays in →−τ {| a · x ≥ b? |} Y and →−τ {| a · x < b? |} Z to make the subse- quent intersection as large as possible. This simple heuristic is sufficient to analyze Fig. 1 (where the degeneracy comes from the invariant i = 100 at loop exit) but it is nevertheless fragile and begs to be improved.

To handle strict tests, we note that τ {| a · x ≥ b? |} over-approximates τ {| a · x > b? |}, and so, by Thm. 3.1.viii, →−τ {| a · x > b? |} can be under-approximated by →−τ {| a · x ≥ b? |}. Similarly for non-deterministic tests, τ {| a · x ≥ [b; c]? |} = τ {| a · x ≥ b? |}, and so, →−τ {| a · x ≥ [b; c]? |} is modeled as →−τ {| a · x ≥ b? |}. We will see in Sec. 4.6 that non-linear tests can be abstracted into such non-deterministic affine ones. Finally, boolean combinations of tests are handled as follows, using Thm. 3.1.iv,vii: 7
τ {| t1 ∨ t2 |} = τ {| t1 |} ∪ τ {| t2 |} and so →−τ {| t1 ∨ t2 |} = →−τ {| t1 |} ∩ →−τ {| t2 |} τ {| t1 ∧ t2 |} = τ {| t2 |} ◦ τ {| t1 |} and so →−τ {| t1 ∧ t2 |} = →−τ {| t1 |} ◦ →−τ {| t2 |}
For instance, →−τ {| a · x = [b; c]? |} = →−τ {| a · x ≥ b? |} ◦→−τ {| (−a) · x ≥ −c? |}.
Projection
Given a variable V , projecting it forgets its value:
τ {| V := ? |} R = { ρ[V '→ v] | ρ ∈ R, v ∈ Q }
and so	→−τ {| V := ? |} R = { ρ ∈E | ∀v ∈ Q : ρ[V '→ v] ∈ R }
We have the following property:
Theorem 4.2 If R is convex closed, then →−τ {| V := ? |} R is either R or ∅.
The projection can be efficiently and exactly implemented for polyhedra as: if τ {| V := ? |} P = P then →−τ {| V := ? |} P = P , otherwise →−τ {| V := ? |} P = ∅. Adding and removing an uninitialized variable can then be derived as follows:
→−τ {| del V |} = τ {| add V |}
→−τ {| add V |} = τ {| del V |} ◦ →−τ {| V := ? |}

Assignments
By Thm. 3.1.viii, and given that the forward projection over-approximates any assignment, the backward projection can be used to under-approximate any as- signment, but this is rather coarse. More interestingly, general assignments can be reduced to tests by introducing a temporary variable V j. We note [V j/V ] the renaming of V as V j. We have:
τ {| V := e |} = [V/V j] ◦ τ {| del V |} ◦ τ {| V j = e? |} ◦ τ {| add V j |}
and so →−τ {| V := e |} = →−τ {| add V j |} ◦ →−τ {| V j = e? |} ◦ →−τ {| del V |} ◦ [V j/V ]
In case of degeneracy on a test argument, Sec. 4.1 relied on rays provided by another polyhedron to guide the operation. We do not have another polyhedron here, but we know that the test is followed by a projection (as part of →−τ {| add V j |}), hence, the heuristic is modified to use the rays V j and −V j. Intuitively, we try to maximize the

7 We avoid the use of ∩ for Λ as it does not behave well with respect to →—· , see Thm. 3.1.v.

set of environments ρ such that the result of the test contains { ρ[V j '→ v] | v ∈ Q }, and so, will be kept by →−τ {| V j := ? |}.
Moreover, some restricted yet useful classes of assignments enjoy more direct abstractions, based solely on forward operators, such as:
Theorem 4.3
→−τ {| V := [a; b] |} = τ {| V := ? |} ◦ (τ {| V := V − a |} ∩ τ {| V := V − b |}) ◦
τ {| V ≥ a? ∧ V ≤ b? |}).
→−τ {| V := V + [a; b] |} = τ {| V := V − a |} ∩ τ {| V := V − b |}.
→−τ {| V := W |} = τ {| V := ? |} ◦ τ {| V = W ? |}	(when V /= W).
If V	:= e is invertible, i.e., there exists an expression e—1 such that
τ {| V := e—1 |} ◦ τ {| V := e |} = τ {| V := e |} ◦ τ {| V := e—1 |} = λR.R, then
→−τ {| V := e |} = τ {| V := e—1 |} — e.g., V := Σ	αW W with αV /= 0.

Lower widening
Invariance semantics by abstract interpretation feature least fixpoints, e.g., to han- dle loops and solve equation systems. Traditionally, they are solved by iteration with an upper convergence acceleration operator, the widening o [4]. To compute sufficient conditions, we under-approximate greatest fixpoints instead (Eq. 2 and Thm. 3.1.x). We thus define a lower widening o obeying:
γ(A o B) ⊆ γ(A) ∩ γ(B).
For any sequence (Xn)n∈N, the sequence Y0 = X0, Yn+1 = Yn o Xn+1 stabilizes:
∃i : Yi+1 = Yi.
As a consequence, for any under-approximation F of a concrete operator F , and any X0, the sequence Xi+1 = Xi o F (Xi) stabilizes in finite time to some Xδ; moreover, this Xδ satisfies γ(Xδ) ⊆ gfpγ(X0) F [4].
On polyhedra, by analogy with the widening o [7] that keeps only stable con-
straints, we define a lower widening o that keeps only stable generators. Let VP and RP denote the vertices and rays of a polyhedron P = γg(VP , RP ). We define o formally as:


VAoB
= { v ∈ VA | v ∈ B }
(4)

RAoB
= { r ∈ RA
| B ⊕ R+r = B }

where ⊕ denotes the Minkowski sum (A ⊕ B d=ef { a + b | a ∈ A, b ∈ B }) and R+r
denotes the set { λr | λ ≥ 0 }). We have:
Theorem 4.4 o is a lower widening.
Generator representations are not unique, and the output of o depends on the choice of representation. The same issue occurs for the standard widening. We can use a similar fix: we add to A o B any generator from B that is redundant with a generator in A. Our lower widening can also be refined in a classic way by

permitting thresholds: given a finite set of vertices (resp. rays), each vertex v (resp. ray r) included in both polyhedra A and B (v ∈ A ∧ v ∈ B, resp. A ⊕ R+r = A ∧ B ⊕ R+r = B) is added to A o B. As for any extrapolation operator, the effectiveness of o will need, in future work, to be assessed in practice. There is ample room for improvement and adaptation.
Lower widenings are introduced in [4] but, up to our knowledge, and unlike (up- per) widenings, no practical instance on infinite domains has ever been designed. Lower widenings are designed to “jump below” fixpoints (hence performing an in- duction) and should not be confused with narrowing operators that “stay above” fixpoints (performing a refinement).
Joins
In invariance analyses, unions of environment sets are computed at every control flow join. Naturally, a large effort in abstract analysis design is spent designing pre- cise and efficient over-approximations of unions. By the duality of Thm. 3.1.iv, such joins do not occur in sufficient condition analyses; they are replaced with intersec- tions ∩ at control-flow splits, and these are easier to abstract in most domain (e.g., polyhedra). Hence, we avoid the issue of designing under-approximations of arbi- trary unions. We do under-approximate unions as part of test operators (Sec. 4.1), but these have a very specific form which helped us design the approximation.
Expression approximation
We focused previously on affine tests and assignments because they match the expressive power of polyhedra, but programs feature more complex expressions. In [13], we proposed to solve this problem for over-approximating transfer functions using an expression abstraction mechanism. We noted e ±D f the fact that f approximates e on D, i.e., ∀ρ ∈ D : J e )ρ ⊆ J f )ρ, where J · ) : E → P(Q) evaluates an expression in an environment. Then:
if R ⊆ D then τ {| V := e |} R ⊆ τ {| V := f |} R and τ {| e? |} R ⊆ τ {| f ? |} R
so, in the abstract, e can be replaced with f if the argument A satisfies e ±γ(A ) f . We now show that this method also works for under-approximations:
Theorem 4.5 If e ±D f, we have:
→−τ {| V := e |} R ⊇ (→−τ {| V := f |} R) ∩ D.
→−τ {| e? |} R ⊇ (→−τ {| f ? |} R) ∩ D.
We study the case of abstract assignments (tests are similar): →−τ {| V := e |} A can be replaced with →−τ {| V := f |} A ∩ D if e ±γ(D ) f . One way to construct f is to use
the “linearization” from [13]: it converts an arbitrary expression into an expression
of the form Σ  αV V + [a; b] by performing interval arithmetics on non-linear parts,
using variable bounds from D . The theorem does not make any hypothesis on the choice of D (unlike the case of forward analysis). A smaller D improves the precision of f by making [a; b] tighter, but, as we want to maximize the result of the

backward assignment, we should avoid discarding states in →−τ {| V := f |}R but not in
→−τ {| V := f |} R ∩ D. In practice, we use for D the result γ(D ) of a prior invariance analysis as we know that, in the concrete, →−τ {| V := e |} R ⊆ γ(D ). For instance, the assignment →−τ {| X → Y × Z |} R will be replaced with →−τ {| X → Y × [0; 1] |} R ∩ D if the invariant γ(D ) before the assignment implies that Z ∈ [0; 1].
It may seem counter-intuitive that over-approximating expressions results in under-approximating backward transfer functions. Observe that over- approximations enlarge the non-determinism of expressions, and so, make it less likely to find sufficient conditions holding for all cases.
Implementation
We have implemented a proof-of-concept analyzer [14] that infers sufficient pre- conditions for programs written in a toy language to never violate any user-specified assertion. It first performs a classic forward over-approximating analysis, followed with a backward under-approximating one. All the abstract operators are imple- mented with polyhedra, on top of the Apron library [10]. It is able to find the sufficient condition j ∈ [0; 5] in the example of Fig. 1. We also analyzed the Bub- bleSort example that introduced polyhedral analysis [7].
Related Work
Since their introduction by Dijkstra [8], weakest (liberal) preconditions have been much studied, using a variety of inference and checking methods, including inter- active theorem proving [9] and automatic finite-state computations. These meth- ods are exact (possibly with respect to an abstract model over-approximating the concrete system, so that sufficient conditions on the model do not always give suffi- cient conditions for the original system). Fully automatic methods based on under- approximations are less common.
Bourdoncle introduces [2] sufficient conditions, denoted always(T ), but only fo-
cuses on deterministic systems (i.e., p˜re = pre). He also mentions that classic
domains, such as intervals, are inadequate to express under-approximations as they are not closed under complementation, but he does not propose an alternative. Moy [15] solves this issue by allowing disjunctions of abstract states (they corre- spond to path enumerations and can grow arbitrarily large). Lev-Ami et al. [11] derive under-approximations from over-approximations by assuming, similarly, that abstract domains are closed by complementation (or negation, when seen as formu- las). Brauer et al. [3] employ boolean formulas on a bit-vector (finite) domain. These domains are more costly than classic convex ones, and our method is not limited to them.
Schmidt [17] defines Galois Connections (and so best operators) for all four backward/forward over-/under-approximation cases using a higher-order powerset construction. Mass´e [12] proposes an analysis parametrized by arbitrary temporal properties, including p˜re operators, based on abstract domains for lower closure operators. We shy away from higher-order constructions. We may lose optimality

and generality, but achieve a more straightforward and, we believe, practical frame- work. In particular, we do not change the semantics of abstract elements, but only add new transfer functions, and achieve the same algorithmic complexity as forward analyses.
Cousot et al. [6] propose a backward precondition analysis for contracts. It differs from the weakest precondition approach we follow in its treatment of non- determinism: it keeps states that, for some sequence of choices (but not necessarily all), give rise to a non-erroneous execution. Our handling of inevitability is directly inspired from Cousot et al. [5].
Conclusion
In this article, we have discussed the inference of sufficient conditions by ab- stract interpretation. We have presented general properties of backward under- approximated semantics, and proposed example transfer functions in the poly- hedra domain. Much work remains to be done, including designing new under- approximated operators (tests and lower widenings, in particular), considering new domains, experimenting on realistic programs. Our construction and results are very preliminary and remain mostly untried; our hope is only to convince the reader that this constitutes a fruitful avenue of research.

References
J. Bertrane, P. Cousot, R. Cousot, J. Feret, L. Mauborgne, A. Min´e, and X. Rival. Static analysis and verification of aerospace software by abstract interpretation. In AIAA Infotech@Aerospace, number 2010-3385, pages 1–38. AIAA, Apr. 2010.
F. Bourdoncle. Abstract debugging of higher-order imperative languages. In Proc. of the ACM Conf. on Prog. Lang. Design and Implementation (PLDI’93), pages 46–55. ACM, Jun. 1993.
J. Brauer and A. Simon. Inferring definite counterexamples through under-approximation. In NASA Formal Methods, volume 7226 of LNCS, Apr. 2012.
P. Cousot. M´ethodes it´eratives de construction et d’approximation de points fixes d’op´erateurs monotones sur un treillis, analyse s´emantique de programmes (in French). Th`ese d’E´tat `es sciences math´ematiques, Universit´e scientifique et m´edicale de Grenoble, Grenoble, France, 21 Mar. 1978.
P. Cousot and R. Cousot. An abstract interpretation framework for termination. In Conference Record
of the 39th Annual ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, pages 245–258, Philadelphia, PA, January 25-27 2012. ACM Press, New York.
P. Cousot, R. Cousot, and F. Logozzo. Precondition inference from intermittent assertions and application to contracts on collections. In Proc. of the 12th Int. Conf. on Verification, Model Checking and Abstract Interpretation (VMCAI;11), volume 6538 of LNCS, pages 150–168. Springer, Jan. 2011.
P. Cousot and N. Halbwachs. Automatic discovery of linear restraints among variables of a program. In Proc. of the 5th ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages (POPL’78), pages 84–97. ACM Press, 1978.
E. W. Dijkstra. Guarded commands, non-determinacy and formal derivation of programs. Comm. ACM, 18(8):453–457, 1975.
C. Flanagan, R. Leino, M. Lillibridge, G. Nelson, J. Saxe, and R. Stata. Extended static checking for Java. In Proc. of the SIGPLAN Conf. on Programming Language Design and Implementation (PLDI’02), pages 234–245. ACM, June 2002.
B. Jeannet and A. Min´e. Apron: A library of numerical abstract domains for static analysis. In Proc. of the 21th Int. Conf. on Computer Aided Verification (CAV’09), volume 5643 of LNCS, pages 661–667. Springer, June 2009.


T. Lev-Ami, M. Sagiv, T. Reps, and S. Gulwani. Backward analysis for inferring quantified pre- conditions. Technical Report TR-2007-12-01, Tel Aviv University, Dec. 2007.
D. Mass´e. Temporal Property-driven Verification by Abstract Interpretation. PhD thesis, E´cole Polytechnique, Palaiseau, France, Dec. 2002.
A. Min´e. Symbolic methods to enhance the precision of numerical abstract domains. In Proc. of the 7th Int. Conf. on Verification, Model Checking, and Abstract Interpretation (VMCAI’06), volume 3855 of LNCS, pages 348–363. Springer, Jan. 2006.
A. Min´e. The Banal static analyzer prototype, 2012. http://www.di.ens.fr/~mine/banal.
Y. Moy. Sufficient preconditions for modular assertion checking. In Proc. of the 9th Int. Conf. on Verification, Model Checking, and Abstract Interpretation (VMCAI’08), volume 4905 of LNCS, pages 188–202. Springer, Jan 2008.
X. Rival. Understanding the origin of alarms in Astr´ee. In Proc. of the 12th Int. Symp. on Static Analysis (SAS’05), volume 3672 of LNCS, pages 303–319. Springer, Sep. 2005.
D. A. Schmidt. Closed and logical relations for over- and under-approximation of powersets. In Proc. of the 11th Int. Symp. on Static Analysis (SAS’04), volume 3148, pages 22–37. Springer, Aug. 2004.
