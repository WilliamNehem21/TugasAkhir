

Electronic Notes in Theoretical Computer Science 238 (2009) 41–56
www.elsevier.com/locate/entcs
Convincing Proofs for Program Certification
Manuel Garnacho,1 Micha¨el P´erin2
Universit´e de Grenoble, inpg, cnrs

Abstract
At the highest level of formal certification, the current research trend consists in providing evaluators with a formal checkable proof produced by automatic verification tools. The aim is to reduce the certification process to verifying the provided proof using a proof-checker. However, to date, no certified proof-checker has emerged. In addition, checkable proofs do not eliminate the need to validate the formalization of the verification problem. In this paper we consider the point of view of evaluators. We elaborate criteria that must be fulfilled by a formal proof in order to convince skeptical evaluators. Then, we present a methodology based on this notion of convincing proofs that requires simple formalizations to reach the level of confidence of formal certification. The key idea is to build a certified proof-checker – in collaboration with the evaluators – which is finally used to validate the proof provided by developers. We illustrate our approach on the correctness proof of a buffering protocol written in c that manages the data exchanges between concurrent tasks in avionics control systems.
Keywords: certification, formal proofs, certified proof-checker, reduction of the trusted computing base.


At the highest level of certification many norms in avionics (DO-178B, IEC61508) or security (Common Criteria) highly recommend the use of formal methods [10,16]. Additionally, in some fields, computer aided verification is mature enough to re- wards the developers with a rich feedback and an increase in confidence. Formal methods would then become worthwhile if the verdict of the verification tools could be reused in the certification process. However, this is not the case since evalua- tors cannot assume that the implementation of a verification tool is correct. Even approaches in which verification tools are instrumented to produce formal proofs of their verdict [2,11,13,14,15,17] can be rejected. Indeed, even though it is commonly thought that a formal proof is the highest reachable level of confidence one can ex- pect, evaluators put strong conditions before accepting a formal proof as certificate. For instance, an overlooked issue that arises in formal veriﬁcation of processors is the model validation, which is crucial to ensure that formal analysis applies to the actual machine (M.Wildings [21]).

1 Email: manuel.garnacho@imag.fr
2 Email: michael.perin@imag.fr

1571-0661© 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.09.005

We illustrate our understanding of the evaluators’ requirements3 for the use of formal proofs in certification on a realistic case study: the proof of correctness of a buffering protocol written in c that manages the data exchanges between concurrent tasks in avionics control systems [19]. In order to convince evaluators that a program P carries out a property Φ, by the means of a proof: (i ) the proof must be checkable by a machine using a proof-checker that the evaluators have already certified; (ii ) the program P addressed in the proof must be the actual program to certified, not a simplified or abstract representation of P ; (iii ) the property Φ addressed in the proof must be in a setting on which the evaluators agreed; (iv ) the semantics of the language in which P is written and the semantics of the logic that is used to state the property Φ must be explicit to sustain the validation process; (v ) all of these definitions must be obvious and, if possible, be kept close to the standard background of computer scientists in mathematics; (vi ) finally, it should be obvious that the proof exactly addresses the verification problem and not another similar problem. We introduce the terminology “convincing proofs” to denote checkable proofs that fulfill these six requirements. As a starting point we review related work on checkable proofs with respect to these criteria.
Related work  In theory, the verification methods that return a witness could be enhanced to produce convincing proofs [17]. Let us stress the points that require some extra work to meet the criteria of convincing proofs. All algorithmic methods that determine if a program fulfills a property apply many transformations to the initial verification problem. Among them, the most common are abstraction (e.g., from c to boolean programs [11]), reduction to so-called small models [2], and reformulation in another framework (e.g., from μ-calculus to games theory [13], from imperative to functional programs [7]). Several tools use external theorem provers and decision procedures that must then be certified or instrumented [4,14]. Criteria
(ii) and (iii) require that all of these transformations and external computations appear with justification in the final proof. Most verification tools do not fulfill criterion (iv) since the semantics of their framework (the programming language and its associated logic) are hard-coded into the tools and not easily available for validation.
Closer to our work is the use of deductive methods based on the calculus of weakest preconditions. The tools caduceus/why [8] and caveat [16] are used in verification of critical applications written in c. They offer a good tradeoff between automation and confindence. However they do not produce a proof of correctness of the original program that could be checked by an independent cer- tified prover: caveat uses internal decision procedures and simplification rules and caduceus/why transforms the original program before generating verifica- tion conditions which entails the correctness. The generation of checkable proofs is addressed in the Proof-Carrying Code architecture (pcc [14]) and its foundational extension (fpcc [22]): the formal proof of an untrusted program is checked before

3 The following list of evaluator requirements was elaborated in the industrial project eden that aims at certifying security applications at the highest level of the Common Criteria (see http://www.eden-rntl.org) and through participation to several working groups with the French certification authority for security (dcssi), and with the formal methods teams of eads and ratp (the French metro company).

its execution, thus preventing users from the possible damage due to downloaded applications. These frameworks do not fulfill all of the evaluators’ requirements: pcc still depends on a generator of verification conditions (vcg) to connect the proof, the program and the property. Moreover the definition of the program and property semantics is part of 23 000 lines of c that implement the vcg. That se- mantics is explicit in fpcc but it must be given in the minimal logic used in the proof (based on lambda calculus). Experience has shown that this results in numer- ous definitions and very complex semantics models [9]. Finally, it is worth noticing that, to date, no proof-checker has been certified. Hence, criterion (i) remains un- satisfied, despite an attempt to minimize and prove the coq proof-checker in the coq proof assistant [3].
Approach  In this paper, we focus on the evaluator requirements. We present a framework for certification that is illustrated on a buffering protocol written in c that manages the data exchanges between concurrent tasks in avionics control systems. The resulting proof of correctness fulfills the criteria of convincing proofs. More precisely, our framework conforms to the following guideline: (i ) the certifi- cation process leads to a trusted proof-checker which is built in collaboration with the evaluators; (ii ) the proof is done on the abstract syntax tree of the program. The original program can be filtered out from the proof-term using a simple and easy to validate pretty printer (not presented in this paper); (iii ) evaluators and developers must agree on a logical framework in which the correctness property can be stated; (iv ) they must validate all the logical and semantic rules of the proof-system; (v ) these derivation rules must then be carefully chosen: they must be obvious and as few in number as possible to ease the validation process. In this paper, we use extended transition systems, symbolic history of variables and symbolic equalities. The program is given an operational semantics as derivation rules which define the effect of an instruction in terms of basic predicates of the logic. Contrarily to general purpose verification tools, only the instructions used in the program to be certified must be addressed. (vi ) the program and the prop- erty appear explicitly in the correctness statement. The proof-term consists in the derivation tree of that statement which then appears at the root.
Our work has been inspired by studies on fpcc [1,9] but it differs on two impor- tant points that were dictated by criteria (i) and (vi) of convincing proofs: 1) we avoid the definition of an operational semantics for all constructions and operators of c; 2) optimized proof-checkers for compact proofs are very complex and will be difficult to certify. For this reason, this paper focuses on transparency of the proof- checker. The compactness of proofs is left for future work. As far as we know it is the first attempt to produce a checkable proof in foundational logic of a non trivial program (a protocol for event driven system) reasoning directly on non-transformed c code and reducing the tcb close to minimum: a compiler and a machine.
Outline of the paper The rest of the paper is devoted to the design of a framework for convincing proofs. It is based on foundational proofs and depends on the construction of a certified proof-checker in collaboration with evaluators.

Since the certification process requires that evaluators validate the semantics rules, we show in Section 1 how to take advantage of this validation phase to produce a certified proof-checker by a straightforward translation of the semantics rules. In Section 2, we briefly present the protocol and the correctness statements that will serve as a basis to illustrate our framework. The formalization of the verification problem is explained in Section 3. The derivation rules that capture the semantics of c programs, of concurrent tasks, of priority and preemption are given in Section 4. Their translation into prolog is straightforward and defines the recursive proof- checker function. Improvements and future work are discussed in Section 5.
Construction of a certified proof-checker
Our reduction of the trusted computing base (tcb) is a consequence of the fact that our methodology produces a certiﬁed proof-checker that is finally used to val- idate the proof. The idea is the following: we explain each derivation rule of the proof system to the evaluators who must accept and validate each rule – to succeed, the rules must be simple and obvious. The proof-checker is then a straightforward translation of these rules into a programming language – to be trusted, the trans- lation must be simple and obvious. The proof-checker can then be removed from the tcb which is then reduced to a compiler and a machine. Finally, the proof of correctness is validated using the certified proof-checker which checks that it is a combination of valid derivation steps.
Foundational ﬁrst-order logic on uninterpreted predicates
We consider the first-order logic over uninterpreted predicates represented by syn- tactical terms. The formulæ are built using the standard connectors (∧, ∨, ⇒, ¬) and the quantifiers (∀, ∃). In our framework, all predicates and connectives are un- interpreted in the sense that they are not associated to models (the mathematical structures on which the predicates can be interpreted to determine their validity). The intended meaning of each term of the logic is captured in the set of derivation rules that define the proof system. We recall that a proof system does not give a semantic meaning to a formula ; it only defines the provability of statements as derivability in the following sense: a statement is provable if and only if it can be obtained by the application of the derivation rules [20]. The distinction between va- lidity with respect to a model and provability is not significant to evaluators: they must either validate the model of a logic or its proof system. Our claim is that it is easier to validate derivation rules.
The logical proofs are drawn up in the proof-system of the natural deduction for first-order logic. It is known to be sound and complete [20]. Thanks to its strong connection with logical deduction steps used in mathematical proofs, it is easy to obtain its validation by evaluators. The derivation rules are given in Figure 1 in addition to the principle of induction on natural numbers and Leibniz’s elimina- tion of equality. We adopt a presentation of statements as sequents of the form H ▶ Φ which means that Φ can be derived under the hypothesis H. Compared




  H ▶ Φ2	
H ▶ Φ1 ∨ Φ2

∨intro1
  H ▶ Φ1	
H ▶ Φ1 ∨ Φ2

∨intro2
H, Φ1 ▶ Ψ  H, Φ2 ▶ Ψ
	 ∨elim
H, Φ1 ∨ Φ2 ▶ Ψ



H ▶ Φ1  H ▶ Φ2
	 ∧intro
H ▶ Φ1 ∧ Φ2
H ▶ Φ1 ∧ Φ2
	 ∧elim1
H ▶ Φ2
H ▶ Φ1 ∧ Φ2
	 ∧elim2
H ▶ Φ1




(Φ∈H)	hyp
H ▶ Φ
H, Φ ▶ Ψ


H ▶ Φ ⇒ Ψ
⇒intro	H ▶ Φ H ▶ Φ ⇒ Ψ ⇒elim
H ▶ Ψ



H, Φ ▶ ⊥ 
¬
H ▶ ¬¬Φ ¬elim	H ▶ Φ[x ← x˜]
H ▶ ∀x, Φ
∀

(t )

H ▶ ¬Φ
intro
H ▶ Φ
∀intro
H ▶ ∀x, Φ

H ▶ Φ[x ← t]
elim



H ▶ Φ ∧ ¬Φ
⊥
H ▶ ⊥ 
H ▶ Φ[x ← t]
∃intro	(x˜∈/Var (Ψ))
H ▶ ∃x, Φ
H ▶ ∃x, Φ H, Φ[x ← x˜] ▶ Ψ
∃elim
H ▶ Ψ



H ▶ Φ H ▶ e = e'

H ▶ Φ[e ← e']

=elim
x = y =		 =refl
y = x	sym	x = x


e = simpl(e)
simpl



H ▶ Φ(0) H ▶ ∀k:nat, Φ(k) ⇒ Φ(k + 1)


H ▶ ∀n:nat, Φ(n)

ind	Q∈{∀,∃}
H ▶ Q x:typ, Φ


H ▶ Q x, typ(x) ⇒ Φ

type(↑↓)

Φ, Ψ denotes formulæ, x˜ is a fresh symbol, t denotes a term that can be chosen, Var(Φ) is the set of free variables of Φ and Φ[x ← y] denotes the formula Φ where all free instances of x are replaced by y. Rule (=elim) is also known as Leibniz’s replacement of an expression e by an equivalent one e'. The transitivity of equality is a consequence of (=elim). The rule (simpl) uses the simplification function of Section 3.2.
Rule (ind) is the induction principle on natural numbers. Rule (type) translates type constraints as a predicate. The other rules are the standard ones of the natural deduction.

Fig. 1. Rules of the natural deduction and induction for first-order logic in a sequent presentation

to other proof systems, sequents simplify the management of hypotheses and this reveals useful to obtain a simple proof-checker by a straightforward translation of the derivation rules in Section 1.3.

The representation of proof-terms
A proof of a statement H ▶ Φ is a ﬁnite derivation tree whose conclusion – the root of the tree 4 – is the statement to prove, and which is only formed of valid applications of the derivation rules of the proof system, meaning that each particular application of a rule is obtained by instantiating its variables while respecting the side condition (if there is one). In our framework, derivation trees are represented as terms (denoted by ∇, ∇1,...) which conform to the following BNF syntax where Φ is a formula and H is a list of formulæ.
∇ ::= apply(rule name, [∇1,..., ∇n], H ▶ Φ)
Since a proof is a finite tree, its leaves can only be applications of derivation rules with no premises, e.g., apply(hyp, [ ], H ▶ Φ), the invocation of the (hyp) rule of Figure 1 that can exploit a hypothesis Φ if the side-condition Φ ∈H holds.

4 In the literature on proof systems a proof-term is usually represented as a tree with hypotheses on leaves and the statement to prove at its root.

Construction of the proof-checker
Consider the derivation rule (∧intro) of Figure 1. A derivation tree ∇ = apply(∧intro, [∇1, ∇2], H ▶ Φ1 ∧ Φ2) is a proof of the statement H ▶ Φ1 ∧ Φ2 if the three following conditions are satisfied: the last step of ∇ is a valid instanti- ation of (∧intro), ∇1 is a proof of H ▶ Φ1 and ∇2 is a proof of H ▶ Φ2. These conditions can easily be written as a prolog clause where the statement H ▶ Φ and the formula Φ1 ∧Φ2 are denoted by the terms sequent(H,Φ) and and(Φ1,Φ2). We remind the reader that, in prolog, terms are not interpreted, meaning that they are not functions but syntactic representations which can be inspected using pattern-matching.


The (∧intro) derivation rule:
H ▶ Φ1  H ▶ Φ2
check(∇,Seqt):- Seqt = sequent(H, and(Φ1, Φ2)),
∇ = apply(and intro, [∇1, ∇2], Seqt),

H ▶ Φ1
∧ Φ2
∧intro
check(∇1, sequent(H, Φ1)),

and the corresponding prolog clause:	check(∇2,  sequent(H, Φ2)).

The predicate check(∇,Seqt) holds if ∇ is a valid proof of the statement Seqt where Seqt = H ▶ Φ1 ∧ Φ2. The proof-checking consists in verifying that: ∇ is an application of the rule (∧intro) to two sub-proofs ∇1 and ∇2 with Seqt as conclusion, and the sub-proofs (∇1, resp. ∇2) are valid proofs of the premises (H ▶ Φ1, resp. H ▶ Φ2) of the rule (∧intro). This explains the recursive calls to check(∇1, sequent(H, Φ1)) and check(∇2, sequent(H, Φ2)).
The proof-checker is obtained in a similar way by applying the straightforward translation of Figure 2 to each derivation rule. The result is a set of prolog clauses that define a recursive predicate check(∇,H ▶ Φ) which holds if and only if ∇ is a valid derivation of the statement H ▶ Φ with respect to the rules of the proof system. This predicate uses only a subset of prolog for derivation rules (recursion, a limited form of unification and no backtracking). This choice is defended in [22]. Actually, any programming language with recursion and pattern-matching can be used but the formulation in prolog had our preference since it is close to mathematical definitions.



∇ = apply 0B rule
B@

[∇1	...	∇n]


H ▶ Φ
check(∇,Seqt):- Seqt= sequent(H, Φ),
∇ = apply(rule, [∇1,..., ∇n], Seqt),
condition,
check(∇1, sequent(H1, Φ1)),
.. ., check(∇n, sequent(Hn, Φn)).



Fig. 2. Translation of derivation rules into prolog clauses that define the proof-checker recursive function

The rest of the paper describes our use of this framework to produce a convincing proof of correctness for a complex communication protocol written in c. First, the logical proof-system is enriched with derivation rules that define the semantics of the protocol. Second, the validation of these rules by the evaluators and their translation in prolog furnish a certified proof-checker. Finally, evaluators deliver

the certificate if and only if the proof-term provided by the developpers is accepted by the proof-checker.
Case study: correctness of a communication protocol
In this section we briefly present the protocol that will serve to illustrate our notion of convincing proofs. The protocol is used to implement multi-tasking real-time data-flow applications on an event-based operating system featuring priority and pre-emption [19]. It has been designed for an avionics control system that consists in a pool of tasks running on a single processor. Each task has an id i and is triggered by the environment on arrival of an event i. It then reads available inputs from other tasks, does some computation and outputs its results to all others tasks.
The development of the control system is conducted under the assumption that computations take no time, that is, the output of a task is available instantaneously after its triggering. This so-called synchronous or 0-delay assumption drastically simplifies the development since engineers need only focus on the data-flow be- tween tasks [5]. Therefore, the actual implementation must ensure that a task r (a reader) which uses the output of a task w (a writer) gets the correct output with respect to the data-flow ordering independently of the computation time of each task (see Section 2.2 and [19] for details).

The protocol
The protocol of Figure 3 garantees this property despite any number of temporary suspension (preemption) of any task by other tasks of higher priority and whatever the priorities of the tasks. It consists in two c procedures that manage a series of two-place buffers. A pair of buffers (Bh2l[w][r],Bl2h[w][r]) is required for each pair of read and write tasks (say Task w, Task r). Actually, only one of these buffers is significant depending on the priority order of the reader and the writer. For instance, data exchanges between a high-priority writer w and a low-priority reader r are done by the means of the buffer Bh2l[w][r].
An execution of a Task i consists in a sequence of two calls: a call to os(i) that updates the reading (inst. I1) and writing (inst. I2) locations of a Task i, followed by a call to task(i) that collects the inputs from the buffers (inst. I3), calls the computation function of Task i (inst. I4) and writes the results back in the buffers (inst. I5). Since the rest of the paper does not require a deeper understanding of the behavior of the protocol, we refer the interested reader to [19] for a more detailed description. We now turn to the formalization of the correctness problem.

The correctness property
In order to state the correctness property, following [19], we define three events that govern the run of a Task: i denotes a triggering of Task i that begins with the execution of os(i). Triggering events come from the environment through sensors. The others events i and i are produced by the operating system. i indicates



int prio[T ]; // prio is a static array that associates a priority level to a task id

bool lwl[T ][T ]; // lwl[w][r] = location where a low writer w must write for a high reader r bool lwh[T ][T ]; // lwh[w][r] = location where a high writer w must write for a low reader r bool lrl[T ][T ]; // lrl[r][w] = location where a low reader r must read from a high writer w bool lrh[T ][T ]; // lrh[r][w] = location where a high reader r must read from a low writer w
data Bl2h[T ][T ][2]; // Bl2h[w][r] = two-place buffer for low (w) to high (r) data flow data Bh2l[T ][T ][2]; // Bh2l[w][r] = two-place buffer for high (r) to low (w) data flow
data inp[T ][T ]; // inp[r][w] = input of task r from task w data out[T ]; // out[i] = output of task i

void os(taskid i){ taskid w,r ;
void task(taskid i){ taskid w,r ;

I1: updates
reading locations of Task i
I2: updates 2
for(w = 0; w < T ; w++){ lrh[i][w] = !lwl[w][i];
lrl[i][w] =  lwh[w][i];
}
for(r = 0; r < T ; r++){
I3: reads 2
inputs of Task i
4
for(w = 0; w < T ; w++){ if(prio[i] > prio[w])
inp[i][w] = Bl2h[w][i][ lrh[i][w] ]; else
inp[i][w] = Bh2l[w][i][ lrl[i][w] ];

writing
lwl[i][r] = !lwl[i][r];

locations of Task i
if (lrl[r][i] == lwh[i][r])
lwh[i][r] = !lwh[i][r];
I4:	out[i] = computation(i,inp[i]);
I : writes 2 for(r = 0; r < T ; r++){

}
}	outputs
of Task i
Bl2h[i][r][ lwl[i][r] ] = out[i];
Bh2l[i][r][ lwh[i][r] ] = out[i];
}  }



Fig. 3. The global variables and c procedures of the protocol for a given number T of tasks

priority level







os(i)

task(i)
time


Fig. 4. Representation of the run of a Task with id i: it executes os(i) then task(i)

the starting point of task(i) which ends by sending the i event (see Figure 4). Each event is annotated by its occurence number such that the sequence of events
k .. k .. k refers to the kth run of Task i. The correctness of the protocol for high-
i	i	i
to-low data-flows can now be stated precisely:
Consider a task w (the writer) and a task r (the reader) such that prio[w] ≥ prio[r]. For each possible sequence of events σ such that the kth triggering of Task w (event k ) is the latest run of w before the pth triggering of Task r (event p) the pth input of task r from w must be the kth output of task w.
The formal statement of the high-to-low correctness property is given in Figure 6. The correctness property for low-to-high data-flows is a bit more subtle but very
similar. The meaningful part of Figure 6 is k .. p .. k+1 ⊆ σ ⇒ (inp[r][w])p =
w	r	w
(out[w])k where (x)k is the kth value of x, and e..e' denotes a loose sequence where the dots represent an unspecified sequence of events, and σ' ⊆ σ means that the

priority level






e




0	1

Fig. 5. Illustration of the protocol behavior for high-to-low data-flows

∀T :nat, ∀k:nat, ∀p:nat, ∀r:nat, ∀w:nat, ∀σ:seq,	the variables are typed
w ≤ T ∧ r ≤ T ........................................................... T is the size of the pool of tasks
∧ decl(os(int i){...T...}) ∧ decl(task(int i){...T...})	declarations of the protocol procedures
∧ pcse(os(i), i) ∧ pcse(task(i), i ; i)	associates procedure calls and seq. of events
∧ wf(σ)	σ is a well-formed sequence of events
∧ prio[w] ≥ prio[r]	we consider the case of a high-to-low data-flow
∧ p ⊆ σ	the pth execution of task r completed its execution
∧ k .. p .. k+1 ⊆ σ ............ k is the latest triggering of Task w before the pth triggering of Task r
w	r	w	w
⇒ (inp[r][w])p = (out[w])k	the data-flow respects the triggering order of the Tasks r and w

Fig. 6. The formal correctness property for high-to-low data-flow
sub-sequence σ' can be extracted from σ, that is, all events of σ' appear in σ and their ordering in σ' is preserved in σ. The loose sequence k .. p .. k+1 captures the
w	r	w
scenario addressed in the correctness property, then the required data-flow can easily
be specified as an equality using history of variables. The predicate pcse associates a procedure call to a sequence of events: pcse(os(i), i) captures the fact that os(i) is atomic (its starting and ending events are collapsed into a single event i). On the contrary, pcse(task(i), i ; i) points out that task(i) is preemptable.
Finally, notice that the implementation of Figure 3 is parameterized by the number T of tasks to manage. This parameter is universally quantified in the correctness property meaning that the proof covers all possible instantiations of T . Figure 5 shows the data-flows obtained between a high-priority Task w and a low-priority Task r for a scenario illustrating two cases of pre-emptions. Notice that the high-to-low buffer Bh2l[w][r] achieves the data-flows required to satisfy the
correctness property for both inputs of Task r.
Formalization using extended transition systems
In order to prove the correctness of the protocol, we must provide formal definitions of: the semantics of c programs, the priority and preemption mechanisms, the predicates that are used to express the property. Moreover, the protocol makes several assumptions concerning the sequences of events emitted by the system under control ; they must appear in our formalization.

Event-based extended transitions systems
All the states along a run of the system are named by a symbol such as V, V1,.... Intuitively, they refer to memory states. To represent the behavior of the control system as a transition system, we introduce three predicates that relate source and target states to: transitions on the execution of a sequential program ; transitions on execution of an interleaving of programs ; and transitions on a event. The predicate ⟨V, P, V'⟩ holds if all terminating runs of the program P , starting in the initial state V, results in a state V'. Similarly, ⟨V, P1|P2, V'⟩ holds if all interleaved executions of programs P1, P2 make the system evolve from state V to V'. Finally,
the predicate V −→e V' holds if e is the only event that occurs between the states V
and V'.	Therefore, the behavior of the control system wrt. a sequence of events
σ = e1 ; e2 ; ... ; en can be represented as a conjunction of predicates that link events

and states	0 e1	1	1 e2	2
en
n−1	n


Semantics of assignments as a conjunction of symbolic equalities
The proof requires us to reason on sequences of assignments independently of the actual values of the variables. Therefore, we extend the domain of values with symbols made of a variable annotated with the number of times it has been updated. Thus, x0 denotes the value of variable x at the beginning of the execution and xn its value after n assignments of x. In this setting, the semantics of a sequence of assignments is exactly captured by a conjunction of symbolic equalities. For instance, the sequence of instructions t = x ; x = y ; y = t have the semantic property t1 = x0 ∧ x1 = y0 ∧ y1 = t1 from which it is easy to prove that x1 = y0
∧ y1 = x0, meaning that the instructions correctly swap the values of x and y.
Formally, the value of a program variable x in a state V is represented by the term eval(V,x). In our framework formulæ and expressions are represented as uninterpreted terms, meaning that they are not functions but syntactical structures which can be explored. Expressions can be simplified by the mean of Rule (simpl, Fig. 1) using a recursive function (simpl) over the structure of terms that evaluates the arithmetic part and preserves the symbolic part of an expression. For an atomic expression e, simpl(e) is equal to e if e is a constant or a symbolic value xn or a logical variable i; it is undefined if e is a program variable. We now define the effect of simpl on term constructors of expressions.
simpl(eval(V, x)) = xk a symbolic value with k = ac(V, x) if x is a program variable simpl(eval(V, i)) = i  if i is a logical variable (i.e. not sensitive to state) simpl(eval(V, c)) = c  if c is a constant
simpl(eval(V, t[e1,..., en]))  = eval(V, t[ simpl(Eval(V,e1)) ,..., simpl(Eval(V,en)) ]) if t is an array
simpl(eval(V, op(e1,..., en))) = simpl(op(eval(V,e1),..., eval(V,en)))
simpl(op(e ,...,e )) = ( ocp (simpl(e1),..., simpl(en))  if simpl(ei) is a constant, for all i
The symbol op denotes the mathematical operator on values while op is a term constructor. The term ac(V, x) plays a central role ; it denotes the assignment counter of x at state V. It is updated at each assignment of x, see Rule (asg3, Fig. 9).

The semantic rules of the proof-system
The proof system that must be validated by the evaluators consists in the logical rules of Figure 1, the semantic rules of Figures 7, 8, 9, 10, additional rules to deal

with operators (+,−,<,≤) on natural numbers, the rule bool(b)
¬¬b = b
on booleans and one

typing rules per operator. The mathematical and typing rules are not provided. They are very simple since the protocol set boolean and above all the management of buffer doesn’t depend on the domain of the data stored in it.
For the sake of clarity, the derivation rules are written using simplifying no- tations: all modifications of the set of hypotheses are due to the logical rules (∨elim,⇒intro, ¬intro,∃elim) of Figure 1. Therefore, we omit the hypotheses and write Φ instead of H ▶ Φ in the semantic rules since none of these rules introduce or remove hypotheses. The symbol (↑↓) means that the rule can be used in both directions and summarizes two derivation rules. The side-condition of a rule is a constraint that governs its application. It is evaluated by the proof-checker instead of being part of the proof.	A typing side condition typ(x) on a variable x corresponds to checking that typ(x) belongs to the current hypotheses. The typing constraints (evt(e), seq(σ),...) are omitted when the type of variable is clear from the context. The intended meaning of the semantic rules is given in the figures and only the most significant will be commented here. Figure 7 defines well-formed traces of events. Due to the side condition wf(σ), these rules can only be used with a sequence σ which has been declared as a well-formed sequence in the hypotheses. Successive runs of a task i form a sequence of events which can be defined by the regular expression (i ; i ; i)∗. Then, a well-formed sequence is an interleaving of such sequences (for all tasks from 0 to T ) that complies with the priorities of tasks. This definition is captured by the rules of Figure 7 which follow the original
formulation of assumptions on the control systems given in [19].
Figure 8 formally defines properties of the operators (..), (;) and (⊆) on traces of events. Rule (=seq , Fig. 8) which derives equality on sub-sequences of a well-formed trace σ is valid since each event of σ is unique (events of a well-formed trace are annotated with an occurrence number). Figure 9 gives an operational semantics to the c constructions used in the protocol. The effect of an instruction is defined in terms of properties of its source and target states. The semantics of simple for loops (for 1, for 2, Fig. 9) is defined in terms of a sequence of simpler instructions. This form of equivalence-based semantics is easily validated by programmers. Our semantics of assignments – in terms of assignment counters ac(V, v), see (asg 3, Fig. 9) – is precise enough to express that a program P has no effect on a variable v: this holds if and only if the assignment counter of v hasn’t been changed during the execution of
P . Rule (independency) elaborates on this remark: if P1 has no effect on a variable v then the effect of the execution of P1|P2 on v is that of P2. No other property of the interleaving of programs is needed in the correctness proof. Finally, the rules of Figure 10 relate sequences of events, sequences of programs and transitions between
states on the basis of associations pcse(P, σ) between a procedure call P and its sequence of events σ.



k .. p ⊆ σ  prio[i] > prio[j]	k .. p ⊆ σ  prio[i] > prio[j]

i	j
wf(σ)



k ⊆ σ
i	j
priority1	wf(σ)


k ⊆ σ






k ⊆ σ  k > 1
priority2

	i	
wf(σ)	sched
wf(σ) 	i	 sched	wf(σ)  i	 schedt

k ..
s
k ⊆ σ
k .. 
k ⊆ σ




ek .. ep ⊆ σ
k−1 ..
k ⊆ σ

σ	'

evt(e) 	 evt	evt(e),wf(σ)
∃i,k e = k ∨ e = k ∨ e = k
i	i
k < p
inc	wf(σ)
V −→V 


∀v ac(V, v)=0 
init

i	i	i
The definition of well-formed traces of events captures the assumptions about the control system. A well- formed trace respects the priorities. If the priority of Task i is greater than that of Task j and Task i starts before Task j then it finishes its execution (event k): before Task j starts (priority1) and before
the end of Task j (priority2). Each starting event k is preceded by a triggering event k (scheds). Each
i	i
finishing event k is preceded by the corresponding starting event k (schedf ). A triggering event k is taken
i	i	i
into account by the system (and appears in the trace) if and only if the current task ended its previous
execution (schedt). Rule (evt) says that events are elements of {k, k, k | i, k ∈ }. The occurrence
i  i  i
number of each event increases along a well-formed trace (inc). Finally, a well-formed trace of events starts with an initial state where the variables have not been assigned: their counters of assignment equal 0 and their values are unknown.

Fig. 7. The definition of well-formed traces of events



σ' ⊆ σ
σ1 .. σ2 ⊆ σ
e ; σ1 ; e' ⊆ σ  e ; σ2 ; e' ⊆ σ



∃σ1 ,σ2 σ1 ; σ' ; σ2 = σ
def⊆ (↑↓)
∃σ'
σ1 ; σ' ; σ2 ⊆ σ
def..(↑↓)	wf(σ)
σ1 = σ2
=seq



σ1 ; σ2 ⊆ σ
σ1 .. σ2 ⊆ σ
σ1 .. σ2 ⊆ σ
σ1 .. σ2 .. σ3 ⊆ σ



σ1 .. σ2 ⊆ σ
weakening
σ ⊆ σ	subl
subr
σ2 ⊆ σ
σ1 .. σ3
subm
⊆ σ



σ .. e1 ⊆ σ'  σ .. e2 ⊆ σ'
σ1 .. e ⊆ σ  e .. σ2 ⊆ σ

	 merge		 join

σ .. e1 .. e2 ⊆ σ ∨ σ .. e2 .. e1 ⊆ σ'
σ1 .. e .. σ2 ⊆ σ


Rule (def⊆) defines the sub-sequence predicate (⊆). Rule (def..) captures the intended meaning of the loose sequence notation σ1 .. σ2. Two sub-traces of a well-formed sequence σ which have corresponding starting and ending events are equivalent (= seq) since all events are unique in a well-formed sequence. Any sequence σ1; σ2 can be seen as a special case of a loose sequence σ1 .. σ2 = σ1 ; σ ; σ2 for an empty
σ (weakening). Rules (subl, subr, subm) are used to focus on sub-parts of a given loose sequence. On
the contrary loose sequences can be combined using Rules (merge, join). All of these rules are necessary
and sufficient to conduct the case study on possible completion with the events k , k , p, p of the loose
w  w  r  r
sequence k .. p .. k+1 used in the correctness property.
w	r	w

Fig. 8. Operations and relations between sequences (;) sub-sequences (⊆) and loose sequences (..)

The sketch of the proof and its construction
The proof of the correctness property of Figure 6 is driven by an induction on k of a property Φ that implies the correctness property. It is common in proofs of programs that the expected property is not inductive and therefore requires the proof of a stronger property Φ that is inductive and entails the desired one [4]. The Φ property extends the conclusion of the correctness property in a conjunction of the initial goal with additional propositions which state that 1) tasks other than r and w do not affect the arrays A[r]...[...] and A[w]...[...] for any array A used
in the protocol and 2) in the target state of a triggering event p (resp. k ) the
r	w
assignment counter of inp[r][w] (resp. out[w]) is equal to p (resp. k).	The interesting part in the proof of Φ consists in a case study of all the possible ways
to complete the sub-sequence k .. p .. k+1 with the events k , k , p, p. Then,
w	r	w	w	w	r	r





⟨V, v=e, V'⟩
	 asg1
eval(V',v)= eval(V,e)
⟨V, v=e, V'⟩
	 asg2
∀x, ¬alias(V, v, x) ⇒ eval(V',x)= eval(V,x) ∧ ac(V', x)= ac(V, x)


⟨V, v=e, V'⟩
ac(V', v)= ac(V, v)+1 asg3	int(x),int(y)

syntax
x  /=  y


no−alias1

∀V ¬alias(V, x, y)

syntax
t /= t' ∨ eval(V,e1) /= eval(V,e' ) ∨ ... ∨ eval(V,en) /= eval(V,e' )

data(t[...]),data(t' [...])
1
∀V ¬alias(V, t[e ][...][e ], t'[e' ]...[e' ])
n
no−alias2

1	n	1	n

⟨V1, P1;P2, V2⟩


seq (↑↓)
⟨V, P, V'⟩  eval(V,exp)
'


if1
⟨V, P, V'⟩  ¬(eval(V,exp))
'


if2

∃V ⟨V1, P1, V⟩∧ ⟨V, P2, V2⟩
⟨V, if(exp){P} else { }, V ⟩
⟨V, if(exp){ } else {P}, V ⟩


⟨V, for(i=0;i<0;i=i+1){ }, V'⟩	⟨V, for(i=0;i<n;i=i+1){P (i)}, V'⟩∧ 0 < n 
⟨V, i=0 , V'⟩	for1 (↑↓)	safe(P,{i,n})⟨V, for(i=0;i<n−1;i=i+1){P (i)} ; P (n), V'⟩ for2 (↑↓)


decl(proc(p1,..., pn){Body(p1 ,...,pn )})
⟨V,  Body(eval(V,v1),..., eval(V,vn)) , V'⟩
⟨V, proc(v ,...,v ) , V'⟩	proc−call

1	n
Rule (asg 1) states that after the c instruction v=e the value of v in the target state is that of e in the source state. In the meantime, all variables which are not aliased to v are not affected by the assignment of v: neither their value nor their assignment counter (asg 2). The guarantee of non-aliasing is obtained by rules (no−alias1) and (no−alias2) which exploit the type of variables, the syntactic comparison of variable name, and in some cases a simple reasoning on the indices of arrays. Each assignment of a variable v increases its counter of assignment (asg3). The simple for loops of the protocol are tackled by standard proofs of loop invariants that use the induction principle (ind, Fig. 1) and the Rules (for 1, for 2) which define the meaning of a for loop in terms of simpler instructions. The condition safe(P, V ) of Rule (for 2) syntactically checks that the program P doesn’t write variables of V . Rules (if1, if2) are borrowed from standard operational semantics of conditional instructions. Rule (proc−call) relates procedure calls to the execution of their body. No other rule is needed to reason on the procedures os and task of the protocol.

Fig. 9. Semantic rules for the C instructions used in the protocol




σ	seq−state1
σ1 ; σ2
V1 −−−−→ V2
σ1	σ2

seq−state2 (↑↓)

∃V,V' V −→V'	∃V V1 −−→V ∧ V −−→ V2


∃σ	σ	'

σ1 |σ2	'

V −→V 
'
seq−prg1 (↑↓)	pcse(P1 ,σ1 ),pcse(P2 ,σ2 )
V −−−−→V 
'
seq−prg2 (↑↓)

∃P ⟨V, P, V ⟩	⟨V, P1|P2, V ⟩

σ	'	'  '

V −→V 
size(σ, 0)
size(σ, n) size(σ ,n )

V = V'	size0	evt(e) size(e, 1) size1	size(σ|σ',n + n')	size2
∀V1, ⟨V, P1, V1⟩ ⇒ ac(V, v)= ac(V1, v)  ⟨V, P2, V2⟩
⟨V, P |P , V'⟩ ⇒ eval(V',v)= eval(V ,v)	independency
1  2	2
Rules (seq−state1) and (seq−state2) link memory states and sequences of events by means of the predicate
σ	'
V −→V . Then, Rules (seq−prg1) and (seq−prg2) associate sequences of events to executions of programs
and vice versa: Rule (seq−prg1) assumes the existence of a correspondence between executions of programs and sequences of events. Rule (seq−prg2) exploits the sequences of events associated to programs by the static predicate pcse in order to bind the interleaved execution of two programs to the interleaving of their sequences of events. Two states that are joined by a sequence of size 0 are equal (size0). An event is a sequence of size 1 (size1). No event is lost in the interleaving of two sequences (size2). The last rule (independency) states a crucial property of the interleaved execution of two programs P1 and P2. If P1 has no effect on a variable v – i.e. its assignment counter ac(..., v) has not been modified from V to V1 – then, the effect of P1|P2 on v is that of P2. This rule is a reformulation of the Owicki-Gries’ rule for concurrent programs.

Fig. 10. Relating memory states, sequences of events and sequences of instructions

for each sub-sequence, the execution of the procedures associated to events are examined to prove (inp[r][w])p = (out[w])k in every case. All of these proofs rely on the same two lemmata which show that: 1) tasks other than r and w that can be interleaved with r and w do not affect the pair of buffers used by r and w ;
2) the effect of os(r), os(w), task(r), task(w) realize the expected data-flow.
Large parts of the proof were conducted automatically with the help of a sym- bolic interpreter of c programs developed for this occasion. The interpreter inter- acts with the user for conditional instructions and records the derivation steps in a proof-term that is built during the guided execution. The resulting proof-term contains proof-obligations which must be completed afterward. The inductions and the proof of independency were done by hand with the help of lemmata.5
By using a prover such as pvs or b we would have benefited from simplifications and decision procedures for arithmetic but it is not possible to produce an indepen- dent proof-term using these provers. Therefore, we would have had to include the prover in the tcb. Actually we started with the coq proof-assistant which produces proof-terms but the overhead, the complexity of formalization and the numerous proof-obligations revealed that coq was not inappropriate for our purpose, even if it provides tactics to reduce the proof activity. Moreover, the coq proof-checker is not yet certified.
Conclusion
The evaluators need to be completely convinced before delivering a certificate of correctness for an application. At the highest level of certification, evaluators must be suspicious (the proof must address the actual correctness property and the actual program instead of an abstract model of the problem), conservative (they dislike new theories and new tools that require a deep understanding to validate their verdict) and rigorous (they will investigate the provided evidence until they reach a deep understanding of the proof and will reject any opaque deduction). Finally, they are skeptical (they only accept combinations of low level evidence), and, justly, paranoiac (they trust almost no tools and ask for a minimal tcb). Generally speak- ing, the less theoretical background is needed to understand a proof, the easier they are to convince.
pcc, fpcc and verification tools that produce an independent checkable witness of their verdict give a great level of confidence in a software. However, these tech- niques fail to fulfill all of the evaluators’ requirements. To date, the greatest level of confidence has been reached by developments in lf or coq. These frameworks pro- duce formal proofs using the smallest known set of general purpose derivation rules and, consequently, they offer small proof-checkers [1]. Even then, the evaluators can reject such proofs if they are not familiar with the underlying theory of lf and coq which are based on dependant types and the Curry-Howard isomorphism [18]. More likely, such proofs can be rejected due to the overly detailed formalization of the semantic model that is required in these provers [9].

5 Lemmata cannot introduce potential flaws as they are just systematic combinations of derivation rules.

In this paper we present the notion of convincing proof designed to meet evalu- ators’ requirements. It can be summarized as follows: the logic of the property and the semantics of the system are explicit; they are given as derivation rules which must be validated by the evaluators; the proof uses only these validated rules; the proof-checker is also validated as it consists in a straightforward translation of the derivation rules in a recursive function. Therefore the tcb is close to minimum: {a compiler,6 a machine}. Our methodology reduces the evaluators’ task to the vali- dation of the derivation rules and only relies on the theoretical background of any competent bachelor in computer science.
We illustrate our framework on the correctness proof of a data exchange protocol used to implement multi-tasking real-time data-flow applications on an event-based operating system featuring priority and preemption [19]. The proof of the protocol takes into account all of the system characteristics and provides evidence at a rea- sonable level of detail, avoiding the full description of an operational semantics of concurrency (to render the management of tasks by the os).
Our goal is now to produce convincing proofs by instrumentation of existing automatic verification tools. This is achievable once the set of derivation rules that correspond to the verification steps has been identified. We also seek for a way to benefit from the power of the coq proof-assistant [6] and its numerous libraries of mathematical theories while maintaining the global proof at a convincing level of reasoning – unnecessary details must be kept out of the proof. Our plan is to isolate purely mathematical theorems and to reserve coq for their demonstration.

References
Appel, A., N. Michael, A. Stump and R. Virga, A trustworthy proof checker, Journal of Automated Reasoning 31 (2003), pp. 231–260.
Arons, T., A. Pnueli, S. Ruah, J. Xu and L. Zuck, Parameterized verification with automatically computed inductive assertions, in: Computer Aided Verification, LNCS 2102 (2001), pp. 221–234, (CAV’01).
Barras, B., Verification of the interface of a small proof system in coq, in: Types for Proofs and Programs, LNCS 1512 (1996), pp. 28–45, (TYPES’96).
Bensalem, S., Y. Lakhnech and S. Owre, InVeSt: A tool for the verification of invariants, in: Computer Aided Verification, LNCS 1427 (1998), pp. 505–510, (CAV’98).
Benveniste, A., P. Caspi, S. Edwards, n. Halbwachs, P. Le Guernic and R. de Simone, The synchronous languages 12 years later, IEEE Computer Society 91 (2003), pp. 64–83.
Bertot, Y. and P. Cast´eran, “Interactive Theorem Proving and Program Development (Coq’Art: The Calculus of Inductive Constructions),” Texts in Theoretical Computer Science, Springer, 2004.
Filliˆatre, J.-C., Verification of non-functional programs using interpretations in type theory, Journal of Functional Programming 13 (2003), pp. 709–745.
Filliˆatre, J.-C. and C. March´e, The Why/Krakatoa/Caduceus platform for deductive program verification, in: Computer Aided Verification, LNCS 4590 (2007), pp. 173–177, (CAV’07).
Hamid, N. and Z. Shao, Interfacing Hoare logic and type systems for foundational proof-carrying code, in: Theorem Proving in Higher Order Logics, LNCS 3223 (2004), pp. 118–135, (TPHOL’04).

6 Attempts to remove compilers from the tcb are not convincing, unless we can certify one compiler. The research on this topic has recently obtained encouraging results [12].

Hennell, M., J. Woodcock and M. Woodward, The safety integrity levels of IEC 61508 and a revised proposal, in: Embedded Systems Show (2006), (ESS’06).
Henzinger, T., R. Jhala, R. Majumdar, G. Necula, G. Sutre and W. Weimer, Temporal-safety proofs for systems code, in: Computer Aided Verification, LNCS 2404 (2002), pp. 526–538, (CAV’02).
Leroy, X., Formal certification of a compiler back-end, or: programming a compiler with a proof assistant, in: ACM Conference on Principles of Programming Languages (2006), pp. 42–54, (POPL’06).
Namjoshi, K. S., Certifying model checkers, in: Computer Aided Verification, LNCS 2102 (2001), pp. 2–13, (CAV’01).
Necula, G. C., Proof-carrying code, in: ACM Conference on Principles of Programming Languages
(1997), pp. 106–119, (POPL’97).
Peled, D. and L. Zuck, From model checking to a temporal proof, in: SPIN Workshop on Model Checking Software, LNCS 2057 (2001), pp. 1–14, (SPIN’01).
Randimbivololona, F., J. Souyris, P. Baudin, A. Pacalet, J. Raguideau and D. Schoen, Applying formal proof techniques to avionics software: A pragmatic approach, in: Formal Methods in the Development of Computing Systems, LNCS 1709 (1999), pp. 1798–1815, (FM’99).
Tan, T. and R. Cleaveland, Evidence-based model checking, in: Computer Aided Verification, LNCS
2404 (2002), pp. 455–470, (CAV’02).
Thompson, S., “Type theory and functional programming,” Addison-Wesley, 1991.
Tripakis, S., C. Sofronis, N. Scaife and P. Caspi, Semantics-preserving and memory-efficient implementation of inter-task communication under static-priority or EDF schedulers, in: ACM Conference on Embedded Software (2005), pp. 353–360, (EMSOFT’05).
van Dalen, D., “Logic and Structure,” Springer-Verlag, 1997.
Wilding, M., D. A. Greve and D. Hardin, Efficient simulation of formal processor models, Formal Methods in System Design 18 (2001), pp. 233–248.
Wu, D., A. W. Appel and A. Stump, Foundational proof checkers with small witnesses, in: ACM Conference on Principles and Practice of Declarative Programming (2003), pp. 264–274, (PPDP’03).
