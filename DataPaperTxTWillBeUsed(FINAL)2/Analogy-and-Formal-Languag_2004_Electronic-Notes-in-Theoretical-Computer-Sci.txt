Electronic Notes in Theoretical Computer Science 53 (2002)
URL:  http://www.elsevier.nl/locate/entcs/volume53.html  12 pages

Analogy and Formal Languages

Yves Lepage 1 ;2
ATR Spoken Language Translation Research Laboratories 619-0288 Kyo¯to,Japan



Abstract
In this paper, we advocate a study of analogies between strings of symbols for their own sake. We show how some sets of strings, i.e., some formal languages, may be characterized by use of analogies. We argue that some preliminary “good properties” obtained may plead in favour of the use of analogy in the study of formal languages in relationship with natural language.



Introduction
In linguistics, for Humboldt, Hermann Paul, Baudoin de Courtenay and Saussure, analogy applied to words is the cognitive process by which, given two forms of a word, and only one form of a second word, one creates the
missing form: o¯ra¯to¯rem : o¯ra¯tor = hono¯rem : x	)	x = honor (analogi-
cal equation). Such analogies between strings of symbols, generally noted A : B = C : D, put four strings of symbols into “proportions.” They seem to be independent of any particular language, and the faculty of solving such equations, at least on the symbol level, has been argued to be an au- tonomous process and a universal ability [5].
We shall be concerned only with analogies on the symbol level, and not directly with analogies like arm : hand = leg : foot. Moreover, we will not be concerned with sentences like an atom is like the solar system, which are improperly called analogies precisely because they rest on analogies (here: an electron is to the nucleus as a planet is to the sun, see [3]).

1 Thanks to Prof. Boitet for reading drafts of this paper. Also, thanks to the anonymous referees who pointed out many imperfections and mistakes. All remaining errors are, of course, mine.
Email: yves.lepage@atr.co.jp
 c 2002 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


Analogies

Examples

So we consider analogies only pertaining to the level of symbols. Let us clarify with some cases that do not exemplify the type of analogies that we intend to deal with:
 : g6=  : w
abc : ac 6= acb : ac a : b 6= c : d
walk : walked 6= go : went bird : wings 6= fish : fins abc : ac 6= ca : anything
The first line shows that symbols cannot be decomposed: in our view, wis not gplus black. The second line shows that, for us, analogy deals firstly with symbols, and only in a second step with order, so that in this case, the valid analogy for us is: abc : ac = acb : ab. The following three lines show that no further information outside the given will be consid- ered: a resolution algorithm should not have knowledge about, say, the alphabetical order, nor should it know English conjugation, nor should it have knowledge about animal morphology. The last line, and many other similar ones, show that, if a single symbol of the first string (here b) does not belong to either the second string or to the third, then, there is no analogy which can hold, so that the following analogical equation does not have any solution: abc : ac = ca : x.
Now, the following examples are, in our view, valid analogies. Although the third one yields a barbarism (goed), it is the exact solution to the ana- logical equation walk : walked = go : x (see [15, p. 231]). The last one shows that analogical equations may have several solutions. Hence, in general, a given analogical equation may have no solution, a unique solu- tion, or several solutions.
 g: 4 g=  w: x  ) x = 4 w
look : looked = walk : x	) x = walked walk : walked = go : x	) x = goed
fable : fabulous = miracle : x  ) x = miraculous ab : aabb = aaaabbbb : x ) x = aaaaabbbbb
aba : aa = cbcbcbc : x  ) x = ccbcbc _ x = cbccbc _ x = cbcbcc


Formalization
Starting with general properties, Aristotle (Nicomachian Ethics), as well as Hermann Paul [13, chap. V, x 76, p. 107] use common sense when they perform what is called exchange of the means: A : B = C : D , A : C = B : D. Another property, relying on the symmetry of equality, is also used by Aristotle: A : B = C : D , C : D = A : B. These two properties con- sidered as axioms, lead to five other equivalent forms of the same analogy, so that one can give the following theorem, useful in obtaining further theorems. The proof is trivial.
Theorem 2.1 The eight following analogies are equivalent:
A : B = C : D
A : C = B : D	(exchange of the means)
B : A = D : C	(inversion of ratios)
B : D = A : C
C : A = D : B
C : D = A : B	(symmetry of equality)
D : B = C : A	(exchange of the extremes)
D : C = B : A	(symmetry of reading)

Similarity and Distances
Having examined a range of analogies between strings of symbols, 3 we conjectured that no solution to the analogical equation A : B = C : x ex- ists if one of the symbols in A appears in neither B nor C (see 2.1). By contrapositive, for a solution to exist, any symbol in A should appear in B or C or in both, so that the following axiom can be laid.
Axiom 1 Let V be an alphabet.

8(A; B; C; D) 2 (V ) ;	A : B = C : D	) A    B [ C
This should hold also when taking the order of symbols into account, so that, in general, analogy does not reorder any of the components of the strings. As a consequence, the length of A is less than or equal to the sum of its similarities with B and C, where the similarity (A; B) between two strings of symbols A and B is defined as the length of their longest common subsequence. 4

3  We call V the set of symbols, and V  the set of strings built with elements of V . In the sequel, thus, (A; B; C; D) 2 (V )4 . A denotes the set of different symbols in the string A.
4	Recall that a subsequence is not necessarily connected.	For instance,
 (ababababa; aaaaa) = 5, or  (triangle; angularity) = 4.


Axiom 2 Let V be an alphabet.
8(A; B; C; D) 2 (V ) ;	A : B = C : D	) j A j   (A; B)+  (A; C)
If the length of A is less than this sum, it means that some symbols in A appear in the same order also in B and C, and hence also in D, as they must be copied in the same order in the solutions of the analogical equa- tion. Let us call (A; B; C; D) the number of occurrences of such symbols. One gets:
A : B = C : D	) j A j =  (A; B)+  (A; C)   (A; B; C; D)
By application of Theorem 2.1, one gets seven such equalities:
j A j =  (A; C)+  (A; B)   (A; C; B; D)
j B j =  (B; A)+  (B; D)   (B; A; D; C)
j B j =  (B; D)+  (B; A)   (B; D; A; C)
j C j =  (C; A)+  (C; D)   (C; A; B; D)
j C j =  (C; D)+  (C; A)   (C; D; A; B)
j D j =  (D; B)+  (D; C)   (D; B; C; A)
j D j =  (D; C)+  (D; B)   (D; C; B; A)
All ’s being equal and by the symmetry of similarity, the list of equalities reduces to only four ones with j A j, j B j, j C j and j D j as their first mem- bers.
8 j A j =  (A; B)+  (A; C)   (A; B; C; D)
<> j B j =  (B; A)+  (B; D)   (A; B; C; D)
j C j =  (C; A)+  (C; D)   (A; B; C; D)
:> j D j =  (D; B)+  (D; C)   (A; B; C; D)
This leads easily to the following lemma:
Lemma 2.2 Let V be an alphabet. 8(A; B; C; D) 2 (V  )4;
8 j A j  (A; B) = j C j  (C; D)	(1)


A : B = C : D	)
<> j B j  (B; D) = j A j  (A; C)	(2)

j C j  (C; A) = j D j  (D; B)	(3)
:>

By addition of lines (1) and (4), and by the symmetry of similarity, one gets the following remarkable result, which says that the sums of the lengths of the extremes and of the means are equal.


Lemma 2.3 Let V be an alphabet.
8(A; B; C; D) 2 (V ) ;	A : B = C : D	) j A j + j D j = j B j + j C j
As a consequence of the previous result, there is no place for general reduplication in this framework. General reduplication would have led us to write down: Let V be an alphabet.
8(A; B) 2 (V ) ;	A : B = AA : BB
But this contradicts the previous lemma. For example, an : bm = a2n : b2m , would imply n + 2m = 2n + m, which is possible if and only if n = m. 5
The previous results can be gathered in the following (partial) charac- terization of analogies between strings of symbols, where D appears only on the left side of the equalities, and where the right sides contain only A, B and C.
Theorem 2.4 Let V be an alphabet. 8(A; B; C; D) 2 (V  )4;

>8
A : B = C : D	) <>
 (B; D) =  j A j + j B j +  (A; C)
 (C; D) =  j A j + j C j + (A; B) j D j =  j A j + j B j + j C j

> (A; B; C; D) =  j A j +  (A; B)+  (A; C)
With one more constraint, this characterization leads directly to the im- plementation of an algorithm for the resolution and the verification of analogical equations. However, this partial characterization is sufficient for the sequel of this paper, in order for us to prove some other formal results.
It is known that the similarity is in relationship with a particular string distance [10], which we call edit distance, to follow the terminology of [18,
p. 40–41], the one equipped only with insertions and deletions. 6
Proposition 2.5 Let V be an alphabet of symbols,let  be the similarity be- tween strings and let Æ be the edit distance.
8(A; B) 2 (V  )2;  Æ(A; B) = j A j + j B j  2   (A; B)
By substituting the similarities with the distances in Theorem 2.4, one gets a more intuitive form of the previous characterization of analogies

5 In fact, it appears that “pure analogy” and “reduplication analogy” are to be considered as two different axiomatic systems, the first one with exchange of the means, symmetry of equality and our two previous axioms, and the second one with exchange of the means, symmetry of equality and a reduplication axiom.
6  Substitutions are obtained by applying a deletion and then an insertion, or an inser- tion followed by a deletion. For instance, Æ(edit; edition) = 3 (insertion of three symbols: i, o and n), Æ(triangle; angularity) = 10 (deletion of t, r, i, insertion of u, deletion of e, and insertion of a, r, i, t, y). The edit distance is a metric, as it verifies the three axioms of identity, symmetry and triangular inequality.


between strings of symbols.
Theorem 2.6 Let V be an alphabet. 8(A; B; C; D) 2 (V  )4;

8>
> A : B = C : D	) <
Æ(A; B) = Æ(C; D)
Æ(A; C) = Æ(B; D)
j A j + j D j = j B j + j C j
1

>
>
>>:
 (A; B; C; D) =	4
  (j A j + j B j + j C j + j D j
  Æ(A; B)  Æ(A; C)
  Æ(B; D)  Æ(C; D))

The first three equalities of the system can be visualized in the follow- ing figure:
A

Contiguity and Concatenation
An intuition about analogies is that two analogies could always be con- catenated if they do not have any symbol in common. In fact, there are three possible ways of concatenating which meet intuition. However, for- mally, concatenating is not the only possibility. One could mix up sym- bols, for instance: " : a = bb : bab. We shall reject this possibility.
Axiom 3 Let V be an alphabet, and V 1 V, V2  V, such that V1 \ V 2 = ;, 8(A1; B1 ; C1; D1) 2 (V 1 ) ; 8(A2 ; B2; C2; D2 ) 2 (V2 ) such that,
A1 : B1 = C1 : D1	and	A2 : B2 = C2 : D2
we postulate that there are only three possible ways of concatenating the analogies
8 A1 A2 : B1 B2 = C1 C2 : D1 D2
>< A1 A2 : B1 B2 = C2 C1 : D2 D1
>>: A1 A2 : B2 B1 = C2 C1 : D1 D2
Thus, " : a = bb : bab is no more a valid analogy for us. The previous axiom implies that there are only two possible solutions to the analogical equation: " : a = bb : x	) x = abb _ x = bba, and consequently, the analogical equation ab : aabb = aabb : x  has aaabbb as a unique


solution, and aababb is not a solution. The previous axiom is necessary in the proof of Theorems 4.1 and 4.2.

Formal Languages
Having studied analogies between strings of symbols, and having posited and deduced some formal results, we may now turn to the construction of sets of strings of symbols using analogies.

Immediate Analogical Derivation
We first introduce immediate analogical derivation.
Definition 3.1 Let V be an alphabet. The immediate analogical deriva- tion, noted `  , modulo a set M   V   V , whose elements (v; v0) are noted v ! v0 , is defined in the following way:

8(w; w0) 2 V  V ;	w `   w0	, 9v ! v0 2 M = w : w0 = v : v0
Although we use the notation ! for the elements of M, it is not to be interpreted in the way it would be in classical rewriting systems. This no- tation is just to make a parallel with the classical presentations of gram- mars, where the elements of M are called rules. However, the meaning here is different. With standard rules, w is exactly matched against v to produce, in a second step, w0. Here, the result w0 depends on the way v (not w) “matches” w and v0 at the same time.

Analogical Languages
We now show how some languages, i.e., some sets of symbol strings, can be constructed with a device based on analogy.
Definition 3.2 Let V be an alphabet. Let A  V and M  V  V , both finite. The language of analogical strings (A; M) is defined in the follow- ing way:
+
 (A; M) = A[ f w0 2 V  j 9w 2 A = w `   w g


with
`  .
+
`M  , the transitive closure of the immediate analogical derivation

The previous definition conforms to the usual presentation of formal languages. It aims at the generation of a language. Thus, as usual, stan- dard structural induction is used to generate all of the members of a lan- guage of analogical strings. Starting with the elements of A, all possible analogies with the elements of M as models are applied.


The reciprocal problem of generation is that of recognition. With an analogical system, the grammaticality of a given string, i.e., its member- ship in a language, is tested against the set of attested strings of that lan- guage, after the reduction of that given string, by analogy, using the set of models. For recognition, the strings in the pairs of M are used in the reverse direction they appear in M, and the analogies are solved in the direction reverse to that for generation. This is possible thanks to the in- version of ratios in Theorem 2.1.
The “linguistic” interpretation of a language of analogical strings (A; M) is thus as follows: A is the set of attested strings, i.e., the set of strings against which any candidate element of the language will be compared in fine; M is the set of paradigmatic models (declensions, conjugations, morphological derivations, syntactic transformations, etc.), according to which any candidate element of the language is reduced 7 by analogy.


Where Are Analogical Languages?
We shall now briefly consider the relevance of analogical languages to the study of natural language from the point of view of the class of such lan- guages.

Examples of Languages
It is possible to prove, by induction and with the use of Axiom 3, that the following three famous regular, context-free and, context-sensitive lan- guages are all languages of analogical strings:
fan =n  1g = (fag; fa ! aag)
fan bn =n  1g = (fabg; fab ! aabbg)
fan bn cn =n  1g = (fabcg; fabc ! aabbccg)
and that, more generally:
Theorem 4.1

fan an ::: an
= n  1g =  (fa a ::: a
g; f(a a ::: a
! a2 a2 ::: a2 )g)

1  2	m
1 2	m
1 2	m
1 2	m

Proof. For fan =n  1g.
Completeness: (fag; fa ! aag)  fan =n  1g. Recall that w is the set of different symbols in string w. Suppose that w 2 (fag; fa ! aag). This
 
is equivalent to: a `  w. Hence, there exists a sequence of strings w1, w2,

7  The word reduce is taken to mean a reduction to a normal form, not in the sense that the strings would become shorter.


..., wn such that the first column in the following array holds.
a : w1 = a : aa	,		w1 : a = aa : a	)	w1  a [ aa = fag w1 : w2 = a : aa	,	w2 : w1 = aa : a	)	w2  w1 [ aa
.	.	.
wn : w = a : aa  ,  w : wn = aa : a  )  w  wn [ aa
The second column in the array is obtained by inversion of ratios; the third column is the application of Axiom 1. This last column implies: w fag, which means that w is of the type an .
Consistency: fan =n 1g  (fag; fa ! aag). By induction on n, any string of the form an is obtained by analogy with an element of (fag; fa ! aag). Base: fag  (fag; fa ! aag) by the definition of a language of analogical strings. Induction: suppose that an is a member of (fag; fa ! aag). The unique solution x of the analogical equation a : aa = an : x is an+1 2 fan =n  1g.
For fan bn =n  1g.
Completeness:	 (fabg; fab ! aabbg) fan bn =n 1g. A rationale similar to the one above gives w 2 fan bn =n  1g ) w  fa; bg. By induction, by Axiom 3, all a’s are before the b’s, hence w = an bm with n necessarily equal to m.
Consistency: fan bn =n  1g  (fabg; fab ! aabbg). By induction on n. Base: ab 2 (fabg; fab ! aabbg) is true, by definition of a lan- guage of analogical strings. Induction: suppose that an bn is a member of
 (fabg; fab ! aabbg). Because a : aa = an : an+1 and b : bb = bn : bn+1 are true analogies, and by Axiom 3, the unique solution x of the analogical equation ab : aabb = an bn : x is an+1bn+1 2 fan bn =n  1g.
For fan bn cn =n  1g.
The proof is the same as for fan bn =n  1g, by decomposing
abc : aabbcc = an bn cn : an+1bn+1cn+1
into ab : aabb = an bn : an+1bn+1 and c : cc = cn : cn+1 which both hold.
Identical rationales prove that fan an ::: an	= n  1g is a language of

analogical strings.
1  2	m

2

As a result, expressed as languages of analogical strings, the famous three examples for regular, context-free and, context-sensitive languages are very simple (one attested string and one derivation rule only), and, fortunately, absolutely similar.
Using a similar proof as for the theorem above, it is easy to prove that:
Theorem 4.2
fam bn cm dn = n  1 ^ m  1g =  (fabcdg; fabcd ! abbcdd; abcd ! aabccdg)


This context-sensitive language, which is thus also a language of analogi- cal strings, is the basis of two famous counter-examples against the context- freeness of natural language: in the morphology of Bambara [1], and in the syntax of the Zurich dialect of Swiss German [17]. It is worth noting that, expressed as a language of analogical strings, this language is quite simple.
Thus, some context-sensitive languages are languages of analogical strings.
The question is: does that go too far?

Constant Growth
Mild context-sensitivity was proposed in [7] to characterize the family of languages that suits natural language (larger than context-free, but strictly smaller than context-sensitive), and a characterization in four properties was proposed in [8]. One of these properties, that of constant growth, is weaker than semilinearity ([12] refuted recently that natural languages would be semilinear) :
Definition 4.3 A language L has the constant growth property if (and only if ) when arranging the strings of the language in increasing order of length, two consecutive lengths do not differ by arbitrarily large amounts.
Now, it can be proven using Lemma 2.3 that:
Theorem 4.4 Any language of analogical strings verifies the constantgrowth property.
Proof. Let (A; M) be a language of analogical strings. Let us call kA the maximum over all j w j with w in A. kA exists, because A is finite. Let us call kM the maximum over all j v0 j j v j with v ! v0 in M. kM exists also, because M is also finite.
 (A; M) is generated by induction, starting with the elements of A, by application of immediate analogical derivations with the elements of M.
At the beginning of the generation, the set A has the constant growth property, with kA, a possible (too large) bound for the amounts between two consecutive lengths.
Suppose that, at one step of the generation by induction, the generated set of all strings created until that step has the constant growth property.
In the next step, a new string is generated with the help of an element
w obtained during the last step. In fact, zero, one, or several 8 elements w0
may be generated with the help of any element v ! v0 of M, depending whether the analogy v : v0 = w : x has zero, one, or several solutions. When there exists at least one such solution w0, Lemma 2.3 tells us that
j v j + j w0 j = j v0 j + j w j, thus j w0 j j w j = j v0 j j v j. If j w0 j j w j 0, the length decreases, and j w0 j can be arranged in between lengths of

8  Axiom 1 and Lemma 2.3 imply that an analogical equation has a finite number of solutions.


already generated elements of the language, and even possibly before kA. If j w0 j j w j > 0, the length increases, but by less than k . As this is true for all new strings w0 generated during the new step, consequently, the new set of generated strings union the set of strings generated until that step has the constant growth property, with k = max(kA; kM) as a bound for the amounts between two consecutive string lengths arranged in increasing order.
This concludes the proof by induction.	2
Consequently, a language like fa2n =n 2 INg is not a language of analog- ical strings, as it does not have the bounded growth property. Luckily thus, some “unnatural” languages are out of the reach of languages of analogi- cal strings.

Conclusion
Only a small number of proposals have been made for the modelization of analogy, maybe because the dominant stream in linguistics for years, the generative one, against works by the founders of modern linguistics (e.g., [13, chap. V & XII] or [15, Part III, Chap. 4 & 5]), explicitly rebutted analogy as a possible object of research (see [6, 132 and 136], for quotations from Chomsky). However, according to other arguments [5], analogy may be argued to be a component in language (of course, surely not the only one). We have shown how to generate a family of formal languages, called languages of analogical strings. It is important to note that their construc- tion, as is the case with simple contextual grammars [4], does not make any use of non-terminals. Grammaticality is simply tested against some attested strings, after reduction according to some models. The approach by reduction to attested forms has already been advocated in natural lan-
guage processing [14].
The key language fan bm cn dm =n 1g against the context-freeness hy- pothesis of natural language is easily shown to be a language of analogi- cal strings. Also, all languages of analogical strings possess the constant growth property, which intervenes partially in mild context-sensitivity, a notion introduced to cope with the apparent power of human languages.


References
Culy, C., The complexity of the vocabulary of Bambara, Linguistics and Philosophy 8 (1985), pp. 345–351.
Dowty, D., L. Karttunen and A. Zwicky, editors, “Natural language processing,” Cambridge University Press, Cambridge, 1985.


Gentner, D., Structure mapping: A theoretical model for analogy, Cognitive Science 7 (1983), pp. 155–170.
Ilie, L., “On Ambiguity in Internal Contextual Languages,” in [11], 1998, pp. 29–45.
Itkonen, E., Iconicity,analogy,and universal grammar, Journal of Pragmatics
22 (1994), pp. 37–53.
Itkonen, E. and J. Haukioja, “A rehabilitation of analogy in syntax (and elsewhere),” in [9], 1997, pp. 131–177.
Joshi, A., “Tree adjoining grammars: How much context-sensitivity is required to provide reasonable structural description?” in [2], 1985, pp. 206– 250.
Joshi, A., K. Vijay-Shanker and D. Weir, “The Convergence of Mildly Context-Sensitive Grammar Formalisms,” in [16], 1991, pp. 31–81.
Kert esz, A., “Metalinguistik im Wandel: die kognitive Wende in Wissenschaftstheorie und Linguistik,” Peter Lang, Frankfurt a/M, 1997.
Levenshtein, V., Binary codes capable of correcting deletions, insertions and reversals, Soviet Physics-Doklady 10 (1966), pp. 707–710.
Mart n-Vide,  C.,  editor,  “Mathematical  and  computational analysis of natural language,” John Benjamins Publishing Co., Amsterdam
/ Philadelphia, 1998.
Michaelis, J. and M. Kracht, “Logical Aspects of Computational Linguistics,”
Number 1328 in LNCS/LNAI, Springer Verlag, Berlin, 1997, 329–345 pp.
Paul, H., “Prinzipien der Sprachgeschichte,” Niemayer, Tu¨bingen, 1920 [5th ed., 1st ed. 1880].
http://www.gutenberg.aol.de/paulh/prinzip/paulvorr.htm
Sager, N., “Natural Language Information Processing: A Computer Grammar of English and Its Applications,” Addison-Wesley, Reading, Mass., 1981.
Saussure, F., “Cours de linguistique ge´ne´rale,” Payot, Lausanne et Paris, 1995 [1st ed. 1916].
Sells, P., S. Shieber and T. Wasow, editors, “Foundational Issues in natural language processing,” MIT Press, Cambridge, 1991.
Shieber, S. M., Evidence against the context-freeness of natural language, Linguistics and Philosophy 8 (1985), pp. 333–343.
Stephen, G. A., “String searching algorithms,” World Scientific, Singapore– New Jersey–London–Hong Kong, 1998.
