

Electronic Notes in Theoretical Computer Science 244 (2009) 67–79
www.elsevier.com/locate/entcs

Reasoning with Uncertain and Conflicting Opinions in Open Reputation Systems
Andreas Gutscher1
Institute of Communication Networks and Computer Engineering Universit¨at Stuttgart
Stuttgart, Germany

Abstract
Reputation systems support users to distinguish between trustworthy and malicious or unreliable services. They collect and evaluate available user opinions about services and about other users in order to determine an estimation for the trustworthiness of a specified service. The usefulness of a reputation system highly depends on its underlying trust model, i. e., the representation of trust values and the methods to calculate with these trust vales. Several proposed trust models that allow representing degrees of trust, ignorance and distrust show undesired properties when conflicting opinions are combined. The proposed consensus operators usually eliminate the incurred degree of conflict and perform a re-normalization. We argue that this elimination causes counterintuitive effects and should thus be avoided. Therefore, we propose a new representation of trust values that reflects also the degree of conflict, and we develop a calculus and operators to compute reputation values. Our approach requires no re-normalizations and thus avoids the thereby caused undesired effects.
Keywords: Trust model, reputation system, paraconsistent logic.

Introduction
The use of online services and applications (e. g., online shops, social networks and peer-to-peer applications) has become widespread in recent years. An important security problem related to online services is that users have to interact with a number of different services and other users they do not know very well and with whom they have little or no past experience. However, the users need to know whether services and other users are trustworthy, i. e., whether they will behave as expected (e. g., whether information sources are competent and reliable and whether services will handle disclosed personal information responsibly).
Therefore, the use of reputation systems has been proposed for various appli- cations, e. g., to find reliable partners in online market places (e. g., eBay) and to detect malicious behavior in peer-to-peer and mobile ad-hoc networks. Reputation

1 Email: andreas.gutscher@ikr.uni-stuttgart.de

1571-0661 © 2009 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2009.07.039

systems systematically collect available user recommendations about the trustwor- thiness of services and of other users, combine these statements and compute the resulting reputation value of all services according to a trust model. The trust model of a reputation system defines how to represent, reason and calculate with trust values. Designing a sound trust model is difficult because trust statements are uncertain. Thus, it is necessary to reason with uncertain indications and degrees of support, and it can happen that opinions conflict with each other.
Handling conflicting opinions has not yet been satisfactorily solved. Present trust models usually eliminate the probability mass associated with conflicting sce- narios (e. g., Dempster-Shafer [11] and Jøsang [8]) or handle conflict in the same way as ignorance (Yager [12]). We argue that the degree of conflict is valuable information for the requesting application. We propose therefore a trust model that represents also the degree of conflict in the resulting reputation values. We define corresponding calculi that allow us to reason with conflicting opinions and to compute with discrete and continuous trust values.
In Sect. 2, we present related existing trust models and discuss their drawbacks. In Sect. 3, we propose our improved trust model. We demonstrate the confidence computation on an example in Sect. 4 and conclude in Sect. 5.
Related Work
A large number of approaches for modeling, representing, reasoning and computing with trust, reputation and uncertain information [4,11,1,8,9,10,7,12,5,6] has been proposed. In the following, we present some possibilities to represent trust relations and trust values as well as approaches to reason and compute with trust values.
Representation of Trust Relations and Trust Values
Trust is often described as the belief of a trustor in the competence and benevolence of a trustee to act honestly, reliably and dependably. Gambetta [4] describes trust as “a particular level of the subjective probability with which an agent assesses that another agent or group of agents will perform a particular action [. . . ] in a context in which it affects his own action”, which is more suitable in our context.
Various possibilities to represent the strength of trust relations quantitatively have been proposed. Trust values can be expressed by a fix number of discrete values (e. g., PGP/GnuPG 2 ) or by continuous values, e. g., by a value t ∈ [0, 1] (Maurer [10]). It is often beneficial to express the degree of certainty the trustor has in his rating in order to allow for more reliable reputation results. We therefore focus on trust models that represent degrees of trust, distrust and uncertainty. The Dempster-Shafer theory [11] is a complex mathematical theory for reasoning with uncertain evidence. In simple cases with one single proposition confidence values can be represented by a lower bound b (belief ) and an upper bound p (plausibility), where 0 ≤ b ≤ p ≤ 1. Baldwin [1] similarly represents opinions in Fuzzy Logic with

2 Pretty Good Privacy http://www.pgp.com, GNU Privacy Guard http://www.gnupg.org

a belief and a plausibility value. In Subjective Logic [8] a trust value t = (b, i, d) is represented by the degrees of belief (b), ignorance (i) and disbelief (d) (with b, d, i ∈ [0..1], b + d + i = 1), which is mathematically equivalent to the previous representations via belief and plausibility (p = b + i, d =1 − p).

Reasoning and Computing with Trust
Reputation systems collect and evaluate opinions of different entities. The collected opinions consist of trust statements with corresponding trust values and must be based on the own experience of the issuing entities (first-hand opinions). Reputation systems evaluate all available opinions from the point of view of the requesting entity according to a set of inference rules and return a computed reputation value (second- hand opinion). Inference rules define which new trust statements one can derive and how the resulting reputation values are computed from the first-hand trust values. Approaches to compute with deterministic trust values are often related to non-classical multi-valued logics (see for example [3]). We first discuss approaches with probabilistic operators and then approaches with probabilistic initial views.
Computation Approaches with Probabilistic Operators
Reputation systems with probabilistic operators successively merge trust statements according to the inference rules and compute the reputation value of the resulting trust statement with probabilistic operators. Unfortunately, with the proposed, non-distributive operators this approach works only in directed series-parallel trust graphs [9]. We nevertheless discuss proposed operators for trust values represented by belief, ignorance and disbelief values (t = (b, i, d) with b, i, d ∈ [0, 1] and b+i+d =
1). We use the symbols from Tab. 1 to present the corresponding truth tables.

Table 1
Trust values used in related work



Conjunction, Disjunction and Negation Operators
Baldwin [1] and Jøsang [8] proposed the following operators:

⎛	bxby	⎞
⎛	bx + by − bxby	⎞
⎛ dx ⎞

tx ∧ ty = ⎝ ixiy + ixby + bxiy ⎠ , tx ∨ ty = ⎝ ixiy + ixdy + dxiy ⎠ , ¬tx = ⎝ ix ⎠

dx + dy − dxdy
dxdy	bx

The belief value b of a conjunction can be interpreted as the probability that both input values are belief, d as the probability that at least one input value is disbelief. The remaining probability mass is assigned to ignorance. The disjunction operator is constructed accordingly. The negation operator swaps the belief and

disbelief values. From these operators we can derive the corresponding truth tables for the discrete trust values belief, ignorance and disbelief (see Fig. 1).

Fig. 1. Deterministic conjunction, disjunction and negation operators (Baldwin, Jøsang)


Recommendation Operator
A recommendation operator (⊗) concatenates two trust relations i. e., it com- bines a trust relation from an entity EA to an entity EB with trust value tx with a trust relation from EB to an entity EC with trust value ty to one single trust relation from EA to EC with trust value tx ⊗ ty (see Fig. 2).
Jøsang’s recommendation operator [8] follows the advice of trusted recom- menders and ignores unknown and distrusted recommenders (ignorance favoring strategy). The operator and the corresponding truth table are shown in Fig. 2.
⎛	bxby	⎞




EA	EB
tx⊗ty =	bxiy + ix + dx
EC	bxdy


Fig. 2. Recommendation operator (Jøsang)


Consensus Operator
A consensus operator (⊕) combines the trust values of two trust relations that refer to the same proposition. Jøsang [8], Dempster-Shafer [11] and Yager [12] have proposed the consensus operators shown in Fig. 3 (undefined values are indicated by ⬦). Intuitively, the combination with ignorance does not change discrete trust values, and in the cases of Dempster-Shafer and Yager the combination of two identical discrete trust values t' results in t'. The operators differ in their conflict handling strategy. Dempster-Shafer’s operator is defined only for 1−bxdy −dxby > 0,
i. e., it is undefined for the combinations of belief with disbelief. The probability mass of undefined combinations is eliminated and b, i and d are re-normalized so that b + i + d = 1. Jøsang’s operator is defined only for ix + iy − ixiy > 0, i. e., it is, in addition, undefined for the combinations of two belief values and of two disbelief values, which is counterintuitive as the trust values are identical. Jøsang, too, performs a re-normalization. These re-normalizations have the effect of completely ignoring conflict and can thus lead to counterintuitive effects [13]. Yager’s consensus operator [12] assigns the probability mass of conflicting combinations to ignorance. This avoids the counterintuitive effects of re-normalizations, but conflict is then indistinguishable from ignorance. In security-critical applications, it can be very


bxiy
1
+ ixby ⎞

tx ⊕ ty = ix+iy−ixiy ⎝
ixiy dxiy + ixdy




bxby
1
+ bxiy
+ ixby ⎞

tx ⊕ ty = 1−bxdy−dxby ⎝
ixiy
dxdy + dxiy + ixdy

⎛ bxby

+ bxiy
+ ixby ⎞

tx ⊕ ty =	ixiy + bxdy + dxby
dxdy + dxiy + ixdy

Fig. 3. Jøsang’s (top), Dempster-Shafer’s (middle) and Yager’s (bottom) consensus operators
important to distinguish these cases and treat them differently. A high degree of conflict indicates that the trustee misbehaved in the past or that some recommenders are lying, whereas ignorance indicates merely a lack of information.
Computation Approaches with Probabilistic Initial Views
Other approaches (e. g., Maurer [10] and Gutscher [6]) represent trust values by a value t ∈ [0, 1]. The trust values tj of the n first-hand trust relations (j = 1,..., n) are interpreted as probability values in the following random experiment: Each of the n trust relations is considered valid with the corresponding probability tj. Then the inference rules are repeatedly applied to the valid trust relations and to already derived trust relations. The resulting reputation value is defined as the probability that it is possible to infer the requested reputation relation from the valid first-hand trust relations. With this approach, it is possible to evaluate trust graphs with arbitrary topology including loops and intersecting trust paths, but it is not possible to express the degree of ignorance in the trust values. We describe an adapted version of this approach in Sect. 3.4.2 in more detail.
New Approach for Reasoning with Conflict
We have shown that neither the handling of conflicting opinions nor the evaluation of trust graphs has been solved satisfactorily in current trust models. Therefore, we propose new representations for trust relations and trust values that reflect the degrees of belief, ignorance, disbelief and conflict (Sect. 3.1 and Sect. 3.2), and we present an approach for reasoning and computing with these trust values. This extends the trust representation in our previous approach [6], which is contained as a special case in the new approach.
We start with a deterministic calculus for discrete trust values (Sect. 3.3) and extend it for calculating with continuous values (Sect. 3.4). Our evaluation approach handles conflicting opinions reasonably, it is free from counterintuitive effects caused by re-normalizations and it can be applied to trust graphs with arbitrary topology.

Representation of Trust Relations
A trust relation is a unidirectional relation from an entity, EA (the trustor ) to an other entity EB (the trustee). The trust relation expresses the belief of the trustor that the trustee will behave as expected with respect to some property or context r (e. g., for “taking care of my children” or “being a good dentist”).
We distinguish between two types of trust: functional trust and recommendation trust with a certain number of recommendation hops. Functional trust expresses the belief that the trustee has the property r (e. g., “he is a good dentist”), whereas recommendation trust expresses the belief that the trustee can recommend other entities with property r over h ≥ 1 recommendation hops (e. g., h = 1 expresses the belief, that the trustee “will recommend good dentists”, h = 2 that he “will recommend good dentist recommenders”, etc.).
The belief that a certain trust relation exists is represented by a trust state- ment H = Trust(EA, EB, r, h) (where h = 0 indicates functional trust and h ≥ 1 recommendation trust) with an associated trust value t (see Sect. 3.2). We as- sume that trust relations are in general neither symmetric (i. e., Trust(EA, EB, r, h) does not imply Trust(EB, EA, r, h)), nor transitive (i. e., Trust(EA, EB, r, h) and Trust(EB, EC, r, h) does not imply Trust(EA, EC, r, h)). Whether and under which conditions trust relations can be combined to trust chains should be specified ex- plicitly with the help of inference rules (an example is given in Sect. 4).

Representing Uncertainty and Conflict in Trust Values
We reason with uncertain information, therefore, we cannot decide whether a state- ment H is “true” or “false”. We can only collect and evaluate indications that support or refute H. Therefore, we introduce the following propositions: H+ de- notes that there are indications that support H (e. g., own experience or opinions of trustworthy entities). Similarly, H− denotes that there are indications that refute
H. However, the inability to find indications supporting H is not an indication refuting H (i. e., it does not imply H−), and vice versa. Likewise, the existence of indications supporting H does not exclude the possibility to find indications refut- ing H, either (i. e., H+ does not exclude H−), and vice versa. First-hand opinions normally do not contain both supporting and refuting indications for H (i. e., H+ and H−) at the same time, but if we combine opinions of different entities it is entirely possible to find both H+ and H−. The latter indicates that the entities do not agree with each other and that at least some of these indications suggest the wrong conclusion, but this is not a logical contradiction.
We introduce the discrete trust values belief, ignorance, disbelief and conflict to represent the four possible combinations of these propositions (see Tab. 2).
In order to describe degrees of belief, ignorance, disbelief and conflict we pro- pose to represent continuous trust values by t = (b, i, d, c) with b, i, d, c ∈ [0, 1]. b is the trustor’s subjective estimation of the probability that there are indications supporting (but no refuting) H. Similarly, d is the subjective estimation of the probability that there are indications refuting (but no supporting) H. c is the sub-


Table 2
Trust values in our approach

jective estimation of the probability that there are both supporting and refuting indications for H at the same time, and i represents the subjective estimation of the probability that there are neither supporting nor refuting indications for H. These four cases are complementary, therefore b + i + d + c = 1. In first-hand trust relations c is usually 0. The correspondence between discrete and continuous trust values is shown in Tab. 2.
The trust representation in our previous approach [6] is contained as a special case in the new approach. Our previous trust value t∗ ∈ [0, 1] corresponds to the degree of belief, 1 − t∗ to the degree of ignorance, hence t = (t∗, 1 − t∗, 0, 0).

Deterministic Operators
Inference rules define the logic of reputation systems, i. e., whether opinions can be combined and how the resulting reputation value depends on the trust values of the first-hand trust relations. In the following, we propose deterministic operators for conjunction, disjunction, negation, recommendation and consensus for the formula- tion of inference rules. As we favor a computation approach with probabilistic initial view it is sufficient to define these operators for discrete trust values. In Sect. 3.4, we show how these deterministic operators can be used with continuous trust values. Some examples for typical trust inference rules are shown in Sect. 4, more inference rules for reputation systems, especially also for validating the authenticity of public keys, can be found in [6].
To find the truth tables for the discrete trust values we proceed as follows: We

represent the discrete trust values t'
and t'
of the input trust relations (Hx and Hy)

as sets of propositions according to Tab. 2 (e. g., H+, H−). For each operator we
x	y
define from which combinations of the input propositions we can infer propositions for the output reputation value (H+, H−). Finally, we interpret the set of output propositions as the discrete reputation value t' of the derived trust statement H.
Interestingly, this approach leads to the same truth tables for the conjunction, disjunction and negation operators as Belnap’s paraconsistent four-valued logic [2] although Belnap derived these operators in a different approach from a bilattice. Belnap’s logic does not provide recommendation and consensus operators though.
Conjunction Operator
The conjunction operator for deterministic trust values corresponds to the logical
AND -operation and is denoted by t' = t' ∧ t' . The conjunction of trust statements
x	y

in inference rules is denoted accordingly by Hx ∧ Hy ⇒ H. We can conclude that there are indications supporting H if we have supporting indications for both Hx and Hy. Similarly, we can conclude that there are indications refuting H if we have indications refuting Hx or Hy:
H+,H+ ⇒ H+	H− ⇒ H−	H− ⇒ H−
x	y	x	y
According to the procedure described in Sect. 3.3, we can now derive the truth table of the conjunction operator (see Fig. 4) from these two statements.

Fig. 4. Our deterministic conjunction, disjunction and negation operators
Note that the conjunction of conflict with disbelief results in disbelief because either H− or H− is sufficient to justify H−. It is interesting that the conjunction
x	y
of conflict with ignorance results in disbelief, too. Conflict for t' combined with
ignorance for t' for example means that we can justify H+ and H−. H− allows
y	x	x	x
us to conclude H−, but H+ does not allow any conclusion without H+, so that we
x	y
obtain disbelief. The situation is different in the case of conjunction of conflict with
belief which allows the justification of both H+ and H− and thus results in conflict.
Disjunction Operator
Similarly, the disjunction operator corresponds to the logical OR-operation and is
denoted by t' = t' ∨ t' . The disjunction of trust statements is denoted accordingly
by Hx ∨ Hy ⇒ H. We can conclude that there are indications supporting H if we have indications supporting Hx or Hy. Similarly, we can conclude that there are refuting indications for H if we have refuting indications for both Hx and Hy:
H+ ⇒ H+	H+ ⇒ H+	H−,H− ⇒ H−
x	y	x	y
The truth table of the disjunction operator is shown in Fig. 4. The disjunction
of conflict with ignorance or belief results in belief because either H+ or H+ is
sufficient to justify H+. It is not possible to justify H− because this would require
both H− and H−. The disjunction of conflict with disbelief allows the justification
x	y
of both H+ and H− and results thus in conflict.
Negation Operator
The negation operator computes the reputation value of the opposite of a trust
statement. It is denoted by t' = ¬t' and ¬Hx ⇒ H. We can conclude that there
are indications supporting H if we have indications refuting Hx, and vice versa:
H+ ⇒ H−	H− ⇒ H+
x	x
The truth table of the negation operator is shown in Fig. 4.

Recommendation Operator
The resulting reputation values of concatenated trust relations can be calculated
with the recommendation operator, which is denoted by t' = t' ⊗ t' . The concate-
nation of trust statements is denoted accordingly by Hx ⊗ Hy ⇒ H. We follow the ignorance favoring strategy of Subjective Logic [8], i. e., we ignore opinions of unknown and untrustworthy recommenders. We can thus conclude that there are indications supporting H if we have supporting indications for both Hx and Hy, and we can conclude that there are indications refuting H if we have indications supporting Hx and indications refuting Hy:
H+,H+ ⇒ H+	H+,H− ⇒ H−
x	y	x	y
The truth table of the recommendation operator is shown in Fig. 5. If there are

Fig. 5. Our deterministic recommendation and consensus operators

no indications supporting Hx (i. e., in the cases of ignorance or disbelief ) then we cannot derive any indications about H, else (i. e., in the cases of belief and conflict ) we can conclude that there are indications supporting H (or refuting H) exactly if there are indications supporting Hy (or refuting Hy respectively). Therefore, the

results are identical for t'
= belief and t'
= conflict.

Consensus Operator
The consensus operator is used to combine the trust values of two distinct opinions
(t' and t' ) that refer to the identical trust statement H. It calculates the cumulative
reputation value, which is denoted by t' = t' ⊕ t' .  This combination of trust
statements is denoted by Hx⊕Hy ⇒ H, but this is usually not necessary because the consensus operator is applied implicitly whenever an inference rules allows deriving an already existing trust statement. We can conclude that there are indications supporting H (or refuting H) if at least one opinion has indications supporting H (or refuting H respectively), i. e., it is sufficient to unify the two sets representing the discrete trust values. The truth table of the consensus operator is shown in Fig. 5. Combining a trust value with ignorance or with an identical trust value does not change the trust value. Mixing belief and disbelief results in conflict. Conflicting trust values remain conflicting when combined with other trust values.
Properties of the Discrete Operators
The conjunction, disjunction and negation operators are identical to Belnap’s operators [2]. Therefore the standard classical properties hold, i. e., involution (¬(¬H)= H), commutativity (H1∧H2 = H2∧H1, H1∨H2 = H2∨H1), associativity

((H1 ∧ H2) ∧ H3 = H1 ∧ (H2 ∧ H3), (H1 ∨ H2) ∨ H3 = H1 ∨ (H2 ∨ H3)), distributivity (H1 ∧ (H2 ∨ H3)= (H1 ∧ H2) ∨ (H1 ∧ H3), H1 ∨ (H2 ∧ H3)= (H1 ∨ H2) ∧ (H1 ∨ H3))
and the De Morgan laws (¬(H1 ∧ H2)= ¬H1 ∨ ¬H2, ¬(H1 ∨ H2)= ¬H1 ∧ ¬H2).
Moreover we find that consensus is commutative (H1⊕H2 = H2⊕H1), consensus and recommendation are associative ((H1 ⊕ H2) ⊕ H3 = H1 ⊕ (H2 ⊕ H3), (H1 ⊗ H2) ⊗ H3 = H1 ⊗ (H2 ⊗ H3)) and that all operators are distributive over consensus (¬(H1 ⊕ H2) = ¬H1 ⊕ ¬H2, H1 ∧ (H2 ⊕ H3) = (H1 ∧ H2) ⊕ (H1 ∧ H3), H1 ∨ (H2 ⊕ H3) = (H1 ∨ H2) ⊕ (H1 ∨ H3), H1 ⊗ (H2 ⊕ H3) = (H1 ⊗ H2) ⊕ (H1 ⊗ H3),
(H1 ⊕ H2) ⊗ H3 = (H1 ⊗ H3) ⊕ (H2 ⊗ H3)). The latter ensures that the resulting reputation value does not depend on the order in which the inference rules are applied. This is very important to ensure consistency in trust graphs with loops and intersecting trust paths.
Reputation Computation with Discrete and Continuous Trust Values
We first describe the reputation computation with discrete trust values, and propose then two approaches to compute with continuous trust values. Due to the discussed drawbacks of the computation approach with probabilistic operators, we choose an approach with a probabilistic initial view. We also define corresponding probabilistic operators and show that both approaches can be mixed.
Reputation Computation with Discrete Trust Values
To compute the resulting discrete reputation value t' for a requested trust statement H we first represent the discrete trust values of the available first-hand opinions as sets of propositions according to Tab. 2 (e. g., {H+}, {H+,H−}).  Next, we
x	y	y
repeatedly apply all inference rules to all initial and already derived propositions until no more new propositions can be derived. We test whether it was possible to derive H+ and H− and interpret this result set as the discrete trust value t'.
Reputation Computation with Probabilistic Initial View
We propose the following approach to compute with continuous trust values. It is based on the following random experiment: For each of the n first-hand trust statement Hj (j = 1,..., n) with trust value tj = (bj, ij, dj, cj) we choose a discrete trust value t' : With probability bj we choose belief, with probability ij ignorance, with probability dj disbelief and with probability cj conflict. Next, we compute the resulting discrete reputation value t' from the chosen discrete trust values with the deterministic approach described in Sect. 3.4.1. The resulting reputation value t = (b, i, d, c) is defined as follows: b is the probability that t' is belief, i the probability that t' is ignorance, d that t' is disbelief and c that t' is conflict.
This reputation value computation can be implemented with different methods. An intuitive approach to compute the exact solution is to set up a table with all possible constellations (“possible worlds ”) of the discrete trust values t' . For each possible world the resulting discrete reputation value t' is computed according to Sect. 3.4.1. For each possible world we compute in addition the probability pk that this world will occur. pk is the product of the corresponding probabilities bj, ij, dj

or cj of the n trust values. To obtain the resulting belief value b we add up the probabilities pk of all worlds in which t' is belief, i is the sum of the probabilities pk of all worlds in which t' is ignorance, etc. This approach is illustrated in Table 3 in Sect. 4. We expect that for most applications the average length of trust chains will be quite small and that only a small fraction of the available trust statements are relevant to compute the requested reputation value, so that the computational complexity is acceptable. In many cases approximate solutions are sufficient, so that heuristics and stochastic Monte Carlo simulations can be used, too.
Reputation Computation with Probabilistic Operators
Let Hx and Hy be two independent trust statements with corresponding trust values tx = (bx, ix, dx, cx) and ty = (by, iy, dy, cy). If we assume Hx ∧ Hy ⇒ H, Hx ∨ Hy ⇒ H, ¬Hx ⇒ H, Hx ⊗ Hy ⇒ H or Hx ⊕ Hy ⇒ H as the single derivation rule of the scenario and compute the resulting reputation value for H according to Sect. 3.4.2, we obtain the reputation values shown in Fig. 6. Computing with these formulas

⎛	bxby
⎞	⎛ bx + by − bxby + cxiy + ixcy ⎞

tx∧ty = ⎜
ixiy + ixby + bxiy
⎟, tx∨ty = ⎜
ixiy + ixdy + dxiy

dx + dy − dxdy + cxiy + ixcy
cxcy + bxcy + cxby
¬tx = (dx, ix, bx, cx)
dxdy
cxcy + dxcy + cxdy

⎛	(bx + cx)by	⎞
tx ⊗ ty	(bx + cx)iy + ix + dx	tx ⊕ ty
bx	cx dy
(bx + cx)cy
⎛	bxby + bxiy + ixby	⎞
ixiy
dxdy + dxiy + ixdy
bxdy + dxby + cx + cy − cxcy

Fig. 6. Our probabilistic conjunction, disjunction, negation, recommendation and consensus operators
(probabilistic operators) is less complex than the possible worlds approach and can thus speed up the evaluation. Although only series-parallel trust graphs can be evaluated completely with the probabilistic operators alone, they are nevertheless useful because the operator-based and the possible worlds computation methods can be mixed : It is, for example, possible to merge independent trust statements with the probabilistic operators first, and then solve the remaining, more “complex” parts of the trust graph with the possible worlds approach.
Example
In this example (Fig. 7a) we show how to compute the reputation value t for H = Trust(EA, ED, r, 0). The following inference rule 3 defines how to concatenate a recommendation trust relation (h > 0) with a functional trust relation:
Trust(EA, EB, r, h) ⊗ Trust(EB, EC, r, 0) ⇒ Trust(EA, EC, r, 0)	(1)
To demonstrate the use of the probabilistic operators (Fig. 6) we first replace the trust statements H1 and H2 by a new trust statement H5 = Trust(EA, ED, r, 0)

3 taken from [6], simplified and extended for reasoning with distrust

H1 = Trust(EA, EB, r, 1)	EB t1 = (0.5, 0.3, 0.2, 0)
H2 = Trust(EB, ED, r, 0)
H5 = Trust(EA, ED, r, 0)
t5



EA
t3 = (0.7, 0.3, 0, 0)
ED	EA
ED
t3	t4

H3 = Trust(EA, EC , r, 1)
EC
(a)
H4 = Trust(EC , ED, r, 0)
H3	EC	H4
(b)

Fig. 7. Example scenario (a) and simplified example scenario (b)
(see Fig. 7b) and compute the corresponding reputation value t5: t5 = t1 ⊗ t2 = (0, b1i2 + i1 + d1, b1d2, 0)= (0, 0.8, 0.2, 0)
Next we demonstrate the possible worlds computation approach on the resulting scenario (Fig. 7b) consisting of H3, H4 and H5. In Table 3 we list all possible com-
binations of the discrete trust values t' , t' and t' , the resulting discrete reputation
3  4	5
value t' and the probability associated with this world.

t'	t'	t'
t'	Probability

  3	4	5	
Table 3
Evaluation with possible worlds approach

The second-to-last row for example represents the world with the predicates

H+, H+ and H−. H−
is identical to H−. With the inference rule (1) we can

3	4	5	5
conclude H+,H+ ⇒ H+. The combination of the predicates H+ and H− results
3	4
in conflict (implicit consensus operation). This world will occur with a probability of b3b4d5 = 0.126. To obtain the final continuous reputation value t = (b, i, d, c) we add all probabilities for each of the four discrete trust values: b = b3b4i5 = 0.504, d = i3i4d5 + i3b4d5 + b3i4d5 = 0.074, c = b3b4d5 = 0.126 and i = 1− b − d − c = 0.296. Thus, we obtain t = (0.504, 0.296, 0.074, 0.126).
Summary and Conclusions
The elimination of the probability mass associated with conflict causes counter- intuitive effects and should thus be avoided. The degree of conflict is important information and its interpretation can be application specific. It should therefore be returned to the requesting application. We propose new representations for dis- crete and continuous trust values that reflect the degree of conflict. Therefore, we do not need any re-normalization, which avoids the known counterintuitive effects. We also propose operators to formulate inference rules as well as a deterministic and a probabilistic calculus to compute with discrete and continuous trust values.

We propose a computation strategy with probabilistic initial view that can be used to evaluate trust graphs with arbitrary topology. To reduce the computational com- plexity we propose in addition corresponding probabilistic operators and show that both approaches can be mixed in order to speed up the reputation computation.

References
Baldwin, J. F., Evidential Support Logic Programming, Fuzzy Sets Systems 24 (1987), pp. 1–26.
Belnap, N. D., A Useful Four-valued Logic, in: Modern Uses of Multi-valued Logic, 1975, pp. 8–37.
Bergstra, J. A., I. Bethke and P. Rodenburg, A Propositional Logic With 4 Values: True, False, Divergent and Meaningless (1995), pp. 199–217.
Gambetta, D., “Can We Trust Trust?” Basil Blackwell, 1988 pp. 213–237.
Grandison, T. and M. Sloman, A Survey of Trust in Internet Application, IEEE Communications Surveys & Tutorials 3 (2000), pp. 2–16.
Gutscher, A., A Trust Model for an Open, Decentralized Reputation System, in: Proceedings of the Joint iTrust and PST Conferences on Privacy Trust Management and Security (IFIPTM 2007), 2007,
pp. 285–300.
Jonczy, J. and R. Haenni, Credential Networks: a General Model for Distributed Trust and Authenticity Management, in: PST, 2005, pp. 101–112.
Jøsang, A., Artificial Reasoning with Subjective Logic, in: Proceedings of the Second Australian Workshop on Commonsense Reasoning, 1997.
Jøsang, A., E. Gray and M. Kinateder, Simplification and Analysis of Transitive Trust Networks (2006),
pp. 139–161.
Maurer, U., Modelling a Public-Key Infrastructure, in: Proc. 1996 European Symposium on Research in Computer Security (ESORICS’ 96), Lecture Notes in Computer Science 1146 (1996), pp. 325–350.
Shafer, G., “A Mathematical Theory of Evidence,” Princeton Univ. Press, 1976.
Yager, R. R., On the Dempster-Shafer Framework and New Combination Rules, Information Sciences
41 (1987), pp. 93–137.
Zadeh, L. A., Review of Books: A Mathematical Theory of Evidence, The AI Magazine 5 (1984),
pp. 81–83.
