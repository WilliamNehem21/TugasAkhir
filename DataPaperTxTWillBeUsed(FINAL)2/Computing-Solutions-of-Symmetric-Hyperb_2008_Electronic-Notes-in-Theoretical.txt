

Electronic Notes in Theoretical Computer Science 221 (2008) 243–255
www.elsevier.com/locate/entcs

Computing Solutions of Symmetric Hyperbolic Systems of PDE’s
Svetlana Selivanova 1,2
S.L. Sobolev Institute of Mathematics Siberian Division of the Russian Academy of Sciences
Novosibirsk, Russia
Victor Selivanov 1,3
A.P. Ershov Institute of Informatics Systems Siberian Division of the Russian Academy of Sciences
Novosibirsk, Russia



Abstract

∂u	Pm


 ∂u

We study the computability properties of symmetric hyperbolic systems of PDE’s A ∂t +
i=1
Bi ∂xi = 0,

A = A∗ > 0, Bi = B∗, with the initial condition u|t=0 = ϕ(x1,..., xm). Such systems first considered by K.O. Friedrichs can be used to describe a wide variety of physical processes. Using the difference equations approach, we prove computability of the operator that sends (for any fixed computable matrices
A, B1,..., Bm satisfying some natural conditions) any initial function ϕ ∈ Ck+1(Q, Rn), k ≥ 1, to the
unique solution u ∈ Ck(H, Rn), where Q = [0, 1]m and H is the nonempty domain of correctness of the system.
Keywords: Hyperbolic system, PDE, computability, metric space, norm, matrix pencil, difference scheme, stability, finite-dimensional approximation.


Introduction
We study the computability properties of symmetric hyperbolic systems
,⎨  ∂u	Σm	∂u

u|t=0 = ϕ(x1,..., xm),

1 The second author supported by DFG-RFBR Grant 06-01-04002 and by RFBR Grant 07-01-00543a.
2 Email: s seliv@yahoo.com
3 Email: vseliv@ngs.ru

1571-0661© 2008 Published by Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.12.021

where A = A∗ > 0 and Bi = B∗ are constant symmetric n × n-matrices, t ≥ 0, x = (x1,..., xm) ∈ Q = [0, 1]m, ϕ : Q → Rn and u : Q × [0, +∞) - Rn is a partial function. In particular, we prove computability of the operator that sends (for any fixed computable A, B1,..., Bm satisfying some natural conditions) any initial function ϕ ∈ Ck+1(Q, Rn), k ≥ 1 to the unique solution u ∈ Ck(H, Rn) of (1), where H /= ∅ is the largest set where the unique solution of the initial value problem (1) exists. Note that u and ϕ may be considered as n-tuples of functions; sometimes it will be easier not to use the boldface font to denote such vector-functions.
Such systems first considered by K.O. Friedrichs [2] can be used to describe a wide variety of physical processes like those considered in the theories of elasticity, acoustics, electromagnetism etc. Some of these processes can also be described via the wave equation, but in many cases it is more convenient to solve the equivalent first-order systems (1) which actually form a more general class of PDE’s. Some motivation for doing so was given in [2] were the well-posedness of (1) (i.e., the existence, uniqueness and continuous dependence of the solution on initial data) was established. The notion of a hyperbolic system (applicable also to broader classes of systems) is due to I.G. Petrovskii [11].
The Friedrichs method (described in more modern terminology in [4]) to prove the existence theorem is based on finite difference approximations, in contrast with the Cauchy-Kovalevskaya method based on approximations by analytic functions and a careful study of infinite series (see e.g. [13]). This feature of the Friedrichs method is interesting from the computational point of view because it yields (as we show here) algorithms for solving PDE’s in the exact sense of computable analysis
[15] which are based on methods really used in numerical analysis. Thus, in this way one is filling the gap between the exact approach of computable analysis and heuristic algorithms (the correctness of which is not always clear) widely used in numerical analysis. For other methods of proving computability of PDE’s solutions see e.g. [12,16,17].
Our proof relies on the well-known classical theorem of the theory of differ- ence schemes (see e.g. [7]) stating that the approximation and stability properties of a difference scheme imply its convergence to the solution of the correspondent differential equation in the grid norm uniformly on steps (see Section 4 for some additional details). We use this theorem to prove a convergence result (Theorem 4.1) in suitable functional norms.
The well-posedness of the initial value problem (1) in the maximal domain H was established for a general case by I.G. Petrovskii. A proof for systems close to ours based on the difference equation method is presented in [4] where sufficient details are given for the one-dimensional case m = 1. We work here with a slightly modified difference scheme described in detail in [5] and widely used in numerical methods (cf. e.g. [8,14] and references therein). Among reasons to use the modified scheme here are the possibilities of generalizing our proofs to some other processes (including shock waves) and of constructing analogous higher-order schemes in a hope to make an insight into complexity of the resulting algorithms.
The set H above (which is, under some restrictions on A, B1,..., Bm, a convex

polyhedron being an intersection of 2m + 1 semispaces of Rm+1, details are given below) is the nonempty domain of existence and uniqueness of the solution u of (1). It is computable from A, B1,..., Bm using the eigenvalues of the so called regular matrix pencils λA − Bi [3] for i = 1,..., m. The computability of spectrum of a symmetric matrix follows from [19]. Using this result we show that a canonical form for the one-dimensional case m = 1 of (1) known as “form in Riemannian invariants” is computable from A, B1 and cardinalities of the spectra of the matrix A and of the pencil λA− B1. This leads to a stable scheme and to an algorithm for computing the solution of (1).
Although we need here only eigenvalues of the mentioned matrix pencils, the procedure of finding them involves the search of eigenvectors of the matrix A and another symmetric matrix as well, and these eigenvectors will be also essentially used in our further proofs. We prove the computability of eigenvectors of regular matrix pencils in Section 3, generalizing the result in [19] that the eigenvectors of a symmetric matrix are computable if and only if the cardinality of spectrum of the matrix is known in advance. Moreover, we observe the existence of efficient algorithms for computing the eigenvalues of a regular matrix pencil λA−B provided that we know the cardinality of spectrum of A. Interestingly, in some practically important cases the cardinality may be found from natural physical reasons, e.g. invariance of considered systems under rotations, as in [8,14].
The rest of the paper is organized as follows. In Section 2 we recall some nota- tion, notions and facts. In Section 3 we prove the computability of the canonical form and of the set H. In Section 4 we describe the difference scheme for (1) and some of its properties. In Section 5 we prove the computability of the solution op- erator for (1). We conclude in Section 6 with a short discussion of possible future work.
Notation, Notions and Known Facts
Matrix Pencils and Description of H
We need some facts about eigenvalues of the matrix pencils λA − Bi, i = 1,..., m. For the theory of matrix pencils see e.g. [3]. Recall that a regular matrix pencil is a matrix λA − B where λ is a real parameter, A and B are symmetric real n × n- matrices, and A > 0. The determinant det(λA − B) is called the characteristic polynomial of λA − B. The roots of the characteristic polynomial are called eigen- values of the pencil. For any eigenvalue λ of λA − B there is a non-zero vector z = (z1,..., zn)T (called eigenvector of λA−B related to this eigenvalue) such that (λA − B)z = 0. The following fact is well-known (see e.g. [3], p. 281):
Theorem 2.1 For any regular matrix pencil λA−B there are eigenvalues λ1,..., λn and related to them A-orthogonal eigenvectors z1,..., zn (this means that ⟨Azj, zk⟩ = δj,k for all j, k = 1,...,n where δj,k is the Kronecker symbol, i.e., δj,k = 0 for j /= k and δj,k = 1 for j = k).
Now let us recall the structure of the domain of correctness H ⊆ Rm+1, i.e.,

the maximal set where, for any k ≥ 1 and ϕ ∈ Ck+1(Q, Rn) there exists a unique solution u ∈ Ck(H, Rn) of the initial value problem (1).
The set H is known to be (see e.g. [4]) a nonempty intersection of the semispaces


t ≥ 0, xi − λ(i)
t ≥ 0, xi − 1 − λ(i)
t ≤ 0, (i = 1,..., m)



of Rm+1 where, for each i = 1,..., m, λ(i)
is the maximal and λ(i)
is the minimal

eigenvalue of the matrix pencil λA − Bi. We are especially interested in the case when H is a compact subset of Q × [0, +∞) (obviously, a sufficient condition for

this to be true is λ(i)
> 0 and λ(i)
< 0 for all i = 1,..., m; this is often the case

for natural physical systems).

Spaces under Consideration
Let Rm be the Euclidean space with the usual norm. As it is known, this space is separable, i.e., it has a countable dense subset (e.g., the set of vectors with rational coordinates). We will consider some subspaces of Rm (as a metric space) with the induced metric, in particular the m-dimensional unitary cube Q = [0, 1]m. Such subspaces are also separable. In particular, a countable dense subset of Q is formed
by the binary-rational vectors (x1,..., xm) where xi =  yi  for some k ≥ 0 and
yi ∈ {0, 1,..., 2k}.
We will work with several functional spaces most of which are subsets of the set C(Rm, Rn)  C(Rm, R)n of integrable continuous functions ϕ : Rm → Rn equipped with the L2-norm. In particular, we deal with the space C(Q, Rn)  C(Q, R)n (resp. Ck(Q, Rn)) of continuous (resp. continuously k-time differentiable) functions ϕ : Q → Rn equipped with the L2-norm


||ϕ||L2
 ∫Q

|ϕ(x)|2dx)

1

2
, |ϕ(x)|2 = ⟨ϕ, ϕ⟩ =

Σi=1

ϕ2(x).

We will also use the sup-norm ||ϕ||s = supx∈Q|ϕ(x)| on C(Q, Rn) and the sL2-norm
||u||sL2 = sup0≤t0≤T  ∫  |u(x, t0)|2dx

on C(Q × [0,T ], Rn) where T > 0. Whenever we want to emphasize the norm we use notation like CL (Q, Rn), Cs(Q, Rn) or CsL (Q × [0,T ], Rn). In case when
2	2
the domain of correctness H is compact and H ⊆ Q × [0,T ], we consider also the space CsL (H, Rn) defined in the same way as the last of the mentioned spaces. The space Cs(Q, Rn) is known to be complete while the spaces CL (Q, Rn) and
CsL (Q × [0,T ], Rn) are not complete.
Note that the space C(Q, Rn) is separable w.r.t. any of the norms. A countable dense set in C(Q, Rn) frequently used in dealing with difference equations is formed as follows.  Take a rectangular grid on Q with rational coordinates (in fact, the
uniform grids Gk with step  1 on each coordinate suffice). Relate to any function fk :

Gk → Q on the finite set Gk of grid nodes the continuous extension f˜k : Q → R of f obtained by piecewise-linear interpolation on each coordinate. Such interpolations known also as multilinear interpolations are the simplest class of splines (see e.g. [18]). Note that the restriction of f˜k to any grid cell is a polynomial of degree m. The extensions f˜k induce a countable dense set in C(Q, Rn) with any of the three norms.
For all τ > 0 and integer k ≥ 0,L ≥ 1, let Gτ be the grid in Q × [0,T ], T = Lτ ,
with step h =  1 on the space coordinates xi and step τ on the time coordinate t.
Just as above, such grids induce a countable dense set in C(Q× [0,T ], Rn) with any of the three norms.
In the study of difference equations the interaction between the infinite-dimensio- nal space C(Q, Rn) (with a given norm) and the corresponding finite-dimensional spaces RG of grid functions f : G → R (with the discrete analog of the given norm) plays a crucial role. The discrete analogs of the norms in Cs(Q, Rn), CL (Q, Rn) and CsL (Q × [0,T ], Rn) are defined in the natural way. E.g., in the last case the norm of a grid function f : Gτ → R is defined by



||f||sL2
= max0≤lτ≤T ,hm	f 2(x, lτ )⎞ .
x∈Gk


We also need the Cantor space Σω of infinite words over a finite alphabet Σ containing at least two symbols. This space plays a crucial technical role in the exact definition of computability over metric (and even more general) spaces. It is well-known that Σω is a complete separable metric space.

Computability Notions
We use the TTE-approach to computability over metric spaces developed in the K. Weihrauch’s school (see e.g. [15,16,1] for more details).
Recall that a computable metric space is a triple (M, d, ν) where (M, d) is a metric
space and ν : ω → M is a numbering of a dense subset rng(ν) of M such that the set {(i, j, q, r) | i, j ∈ ω, q, r ∈ Q, q < d(νi, νj) < r} is computably enumerable.
The Cauchy representation of a computable metric space (M, d, ν) is the partial surjection δM : Σω - M defined exactly on the elements p ∈ Σω which code (in a natural way) sequences {pi} of natural numbers such that d(νpi, νpk) ≤ 2−k for i ≥ k and {ν(pi)}i∈ω is convergent and sending any such code p to δM (p) = limiν(pi). Following [15], by Cauchy sequences we mean in this paper sequences {ν(pi)}i∈ω satisfying the condition above. An element x ∈ M of a computable metric space is called computable if x = δM (p) for a computable Cauchy sequence coded by p ∈ Σω
Metric spaces Rm, Σω , Cs(Q, Rn), CL (Q, Rn) and CsL (Q×[0,T ], Rn) discussed
2	2
in the previous subsection (w.r.t. the metrics induced by the norms and natu- ral numberings of the dense subsets specified above) are computable. The same
applies to spaces Cs(H, Rn), CL (H, Rn) and CsL (H, Rn) provided that matrices
2	2

A, B ,...,B	are computable (as elements of Rn×n) and λ(i)
> 0, λ(i)
< 0 for

1	m	max
min

all i = 1,..., m.
A partial function f : M - M1 on the elements of computable metric spaces (M, d, ν) and (M1, d1, ν1) is computable if there is a computable partial function fˆ : Σω - Σω which represents f w.r.t. the Cauchy representations of M and M1, i.e., δM (fˆ(p)) = f (δM (p)) for each p ∈ dom(δM ). Informally, f is computable if there is an algorithm (realized as a Turing machine sending infinite input words over Σ to infinite output words over Σ) which sends any convergent Cauchy sequence
{ai} of elements of rng(ν) with limiai ∈ domf to a convergent Cauchy sequence
{bi} of elements of rng(ν1) such that limibi = f (limiai).
Let G be the grid in Q with step h =  1 on each coordinate.  From well-
known facts of computable analysis [15] it follows that ϕ '→ ϕ|G is a computable operator from Cs(Q, Rn) to RG. From well-known properties of the piecewise-linear interpolations (see e.g. [4,18]) it follows that f '→ f˜ is a computable operator from
(RG)s to CL (Q, Rn) (see also the estimate (11) below).

Computing the Canonical Form and Domain
First we show that for any one-dimensional (i.e., for m = 1) system (1) of the form
A∂u + B∂u = 0, u = (u ,u ,...,u )T	(2)


	
∂t	∂x
1	2	n

we can compute an equivalent system in the canonical form
∂v + M ∂v = 0,  M = diag{μ ,μ ,...,μ }.	(3)


	
∂t	∂x
1	2	n

Theorem 3.1 Given as inputs symmetric real matrices A, B with A > 0 and the cardinalities of spectra of A and λA− B, we can compute a system in the canonical form (3) equivalent to (2).
Proof. We have to compute the matrix M and the non-degenerate linear trans- formation T of variables u = T v. Since matrices A and B are symmetric and A > 0, there is a non-degenerate matrix T such that T∗AT = In (In is the iden- tity n-dimensional matrix) and T∗BT = diag{μ1, μ2,... μn}. The matrix T may be constructed in the following way:
Applying the orthogonal matrix L, L∗L = In, formed by the coordinates of the normed eigenvectors of A, transform A to the diagonal form
L∗AL = Λ = diag{λ1, λ2,..., λn}

where λj > 0 are the eigenvalues of A. The unknown functions are then transformed to u = Lv1 while the matrix B is transformed to B1 = L∗BL.
Applying the transform v1 = Dv2, where D = Λ  2 , make the coefficient of
∂ the identity matrix D∗ΛD = I , D∗B D = B .
∂t	n	1	2

Applying the transform v2 = Kv, where K is the orthogonal matrix formed
by the coordinates of normed eigenvectors of B , make the coefficient of  ∂	a

2
diagonal matrix; note that the identity coefficient of ∂
∂t


∂x
remains unchanged.

Finally, we set T = LDK and u = T v. In this way, the linear substitution v = T−1u transforms the system (2) to the canonical form (3). From the main result of [19] it follows that, given A and the cardinality of spectrum of A, one can compute the eigenvectors of A. Thus, matrices L, Λ, K, B1, B2 are computable from A, B and the cardinalities of spectra of A and λA − B.	 
From well-known facts of computable analysis we immediately obtain
Corollary 3.2 If A, B are computable symmetric real matrices with A > 0 then there exist a computable diagonal matrix M and a computable linear transformation T, u = T v, such that (3) is equivalent to (2).
Next we observe that the domain H for the problem (1) is computable from

A, B ,...,B 
(i.e., the vector (λ(1)
,..., λ(m) , λ(1)
,..., λ(m) ) from Subsection 2.1

1	m	max
max
min
min

is computable from A, B1,..., Bm).
Since, for each i = 1,..., m, λ(i)
is the maximal and λ(i)

is the minimal

eigenvalue of the matrix pencil λA − Bi, and maximum and minimum of a vector of reals are computable [15], it suffices to show that the vector (λ1,..., λn) of eigenvalues of λA − B is computable from A, B.  But (λ1,..., λn) is the vector
of roots of the characteristic polynomial, hence it is computable [15].
Again we immediately obtain
Corollary 3.3 If A, B1,..., Bm are computable symmetric real matrices with A > 

0 then λ(1)
,..., λ(m) , λ(1)
,..., λ(m)
are computable reals.

max
max
min
min

In case when, along with matrices A, B1,..., Bm, the cardinality of spectrum of A is given we may use the algorithm from the proof of Theorem 3.1 to compute

λ(1)
,..., λ(m) , λ(1)
,..., λ(m)
in a more efficient way than just finding the roots

max
max
min
min

of the characteristic polynomials and computing maximum and minimum. Indeed, again it suffices to show that the vector (λ1,..., λn) of eigenvalues of λA − B is computable from A, B and the cardinality of spectrum of A.
Let L be the orthogonal matrix formed by coordinates of the normed eigenvectors of A. By [19], L is computable. Then L∗L = In, and the matrix L∗AL = Λ = diag{λ1,..., λn} is diagonal, where λj > 0 are the eigenvalues of A. By the proof of Theorem 2.1 in [3], the eigenvalues of λA − B coincide with those of the symmetric
∗	∗	− 1
matrix B2 = D B1D where B1 = L BL and D = Λ 2 .  Therefore, they are
computable by well-known efficient algorithms of linear algebra (see e.g. [6]).

Finite-Dimensional Approximation
In this section we shortly describe the difference scheme for the initial value problem
(1) and formulate some of its properties most of which are known [5,7]. Additional

details will be given in the journal version of the paper.

Description of the Difference Scheme
The difference scheme may be chosen in various ways. Our scheme taken from [5] is a little more complicated than the scheme used in [4] but it has some useful feature mentioned in the introduction. We describe it in few stages.
First we describe some discretization details. Simplifying notation, we stick to the 2-dimensional case x1 = x, x2 = y, B1 = B, B2 = C, i.e. m = 2 and n ≥ 2. For m ≥ 3 the difference scheme is obtained in the same way as for m = 2 but the transfer from m = 1 to m = 2 is nontrivial.
Consider the uniform rectangular grid G on Q = [0, 1]2 defined by the family of lines {x = xj}, {y = yk} where 1 ≤ j, k ≤ 2N for some natural number N (because of many indices we slightly modified here the grid notation from Subsection 2.2). Let h = xj −xj−1 = yk −yk−1 = 1/2N be the step of the grid. Relate to any function g ∈ {u1,..., un} and any fixed time point t = lτ, l ∈ N, the vector of dimension 22N with the components


=	 j − 1
k − 1




equal to the values of g in the centers of grid cells.
Note that, strictly speaking, we work with modifications of the grids Gk in Subsection 2.2 when the centers of grid cells are taken as nodes of the modified grids.
Consider the following two auxiliary one-dimensional systems with parameters obtained by fixing any of the variables x, y:

A∂u + B∂u
∂t	∂x
∂u	∂u
, A	= 0 
∂t	∂y

where u = (u1, u2,..., un)T . Transform the systems into the canonical forms


∂vx + M
∂vx = 0,  ∂vy + M
∂vy = 0.	(4)

∂t
as described in Section 3.
x ∂x
∂t	y ∂y

Any of the systems (4) in the canonical form consists of n independent equations of the form
∂w + μ∂w = 0	(5)
∂t	∂x
where w = w(x, t) is a scalar function and μ ∈ R. Consider for the equation (5) the following difference scheme. The function w(t0, x) already computed on the time level t = t0 (initially t = 0) is substituted by the piecewise-constant function

with the values wj− 1
within the corresponding grid cell xj−1 < x ≤ xj. The “large

values” defined at the boundaries of the grid cells are computed as follows:


w	1 , μ > 0,
Wj	2
wj+ 1 , μ < 0.
(6)

Values on the next time level t = t0 + τ (τ is a time step depending on h as specified below) are then computed as


j− 1
1
2
(Wj − Wj−1).
h

The grid solutions computed in this way approximate solutions of the differential equation (5) with the first order of accuracy on h (in the usual sense of numerical analysis, see e.g. [7]).
Recall that a difference scheme is stable if the corresponding difference operators

Lτ	2N
j− 1 2N

h (that send the grid function {wj− 1 }j=1 to the grid function {w	2 }j=1) are
bounded uniformly on h. The investigation of stability of difference schemes usually relies on Fourier analysis (here we only mention without proofs some known related
facts [7] applied to our scheme).  The necessary and sufficient condition for our

scheme to be stable is |μ|τ
h
≤ 1.

Taking the scheme above for each equation of the systems (4), we obtain for them schemes of the following form:


vx	2 − vxj− 1
+
(Vx)j − (Vx)j−1

	2 	M	= 0 
τ	h
where lower indices mean step lτ , upper indices mean step (l + 1)τ and Vj is the vector consisting of the “large values” given by one-dimensional formulas (6).
As shown in [5], making the inverse transformation we can write the following scheme that approximates the system (1) with the first order of accuracy:

j− 1 ,k− 1
u	2	2 − uj− 1 ,k− 1	Uj+1,k− 1 − Uj,k− 1	Uj− 1 ,k+1 − Uj− 1 ,k
A 	2	2  + B 	2	2  + C 	2	2  = 0	(7)


where
τ	h	h

Uj− 1 ,k = TxVj− 1 ,k, Uj,k− 1 = TyVj,k− 1 .

2	2	2	2
The stability condition looks now as

τ	 1
τx
+  1	≤ 1,	(8)
τy

where τx = maxi{μi(μA − B)}h and τy = maxi{μi(μA − C)}h are the maximal time steps guaranteeing the stability of the corresponding one-dimensional schemes.
,	j− 1 ,k− 1 ,

Some Estimates
Here we assume that the domain H is compact, hence H ⊆ Q × [0,T ] for some
T > 0. Given (8), with the aid of Fourier transform, it can be derived that

j− 1 ,k− 1
||{u	2	2 }||A ≤ ||{uj− 1 ,k− 1 }||A,	(9)
2	2

where

||{uj− 1 ,k− 1 }||A = h2 Σ Auj− 1 ,k− 1 , uk− 1 ,j− 1 .
Using an equivalent norm, fixing the initial values at the right hand side of (9) and

taking the maximal value of the left hand side w.r.t.
such that  j− 1

k− 1	 ∈


for some j, k ∈ {1, 2,..., 2N } we obtain
2	2
2N	2N

max0≤lτ≤T ,⎝h2 Σ u2 1

1 ⎞⎠ ≤ c · ,⎝h2 Σ ϕ2 1

1 ⎞⎠	(10)


for some constant c depending only on A, B, C (where u2 = ⟨u, u⟩).
Finally, we derive an estimate for the piecewise-linear interpolation ϕ|G of the initial function on the grid G and the piecewise-linear interpolation u˜ of of the grid function u on the grid on Q × [0,T ] obtained from G and the time step τ . It is known [5] and easy to see by a direct computation that


max0≤lτ≤T	∫
|u˜(x, y, t)|2dxdy ≤ max0≤lτ≤T ,⎝h2 Σ u2 1
1 ⎞⎠ .	(11)



Obviously,

H∩{t=lτ}
j,k
j− 2 ,k− 2

h2 Σ ϕ2

≤ h2 1 max	ϕ2
	

≤ sup
	

ϕ˜|


(x, y).

The last three estimates imply that for a constant c we have

||u˜|H||sL2  = max0≤lτ≤T ,
H∩{t=lτ}

|u˜(x, y, t)|2dxdy ≤

≤ c · sup(x,y)∈Qϕ|G(x, y) = c · ||ϕ|G||s.	(12)
Convergence of the Difference Scheme
Let ϕ ∈ Ck+1(Q, Rn) for some k ≥ 1 and let A, B1,..., Bm be symmetric real

matrices such that A > 0 and λ(i)
> 0, λ(i)
< 0 for all i = 1,..., m.  By

Subsection 2.1, H is compact and there is a unique solution u ∈ Ck(H, Rn) of (1). Let T > 0 be the smallest number with H ⊆ Q × [0,T ]. For any k ≥ 0, let ϕ|Gk

be the restriction of ϕ to the grid Gk in Q with step  1
(recall that ϕ is actually

an n-tuple of functions, hence the restrictions are componentwise). Note that Gk
here denote the modified grid in Subsection 4.1 rather than the grid in Subsection
2.2. For any k ≥ 0, let τk be the time step such that the scheme (7) is stable (τk is
any number satisfying (8) for h =  1 and dividing T ). For any k ≥ 0, let uk be the
solution of the difference equation (7) on the grid Gτ in Q× [0,T ] obtained from Gk

and the time step
˜denotes the piecewise-linear

τk. Recall from Subsection 2.2 that f
interpolation of a grid function f .
Theorem 4.1 In notation and assumptions of the previous paragraph there is a constant c depending only on A, B1,..., Bm such that for all k ≥ 0 we have ||uk −
u|Gτ ||sL ≤ c ·  1 and ||u˜k − u||sL ≤ c ·  1 , where u is the solution of (1).
k	2	2k	2	2k
Proof. The first estimate is a particular case of a well-known classical theorem of the theory of difference schemes (see e.g. [7]) stating that the approximation and stability properties of a difference scheme imply its convergence to the solution of the correspondent differential equation in the grid norm uniformly on steps.
For the second estimate, we have ||u˜k −u||sL2 ≤ ||u˜k − u˜|Gτ ||sL2 + ||u˜|Gτ −u||sL2 .



c ·  1
for some constant c, hence also ||u˜|Gτ − u||sL
≤ c ·  1
for some constant



k	k
||u˜k − u˜|Gτ ||sL ≤ c ·  1 for some constant c. This implies second estimate.	 
Computing the Solution Operator
We are ready to prove the main result of this paper:
Theorem 5.1 Let k ≥ 1, let A, B1,..., Bm be computable symmetric real matrices

with A > 0, and let λ(i)
> 0, λ(i)
< 0 for all i = 1,..., m. Then the operator

ϕ '→ u sending any ϕ ∈ Ck+1(Q, Rn) to the unique solution u ∈ Ck(H, Rn) of (1) is a computable partial function from Cs(Q, Rn) to CsL (H, Rn).
Proof. (Sketch) We use notation of Theorem 4.1. First note that, by Corollary 3.3 and Subsection 4.1, T is a computable real. Simplifying technical details, assume T to be a rational number (in the general case, take a computable Cauchy sequence of rationals converging to T ). Choose a computable sequence {τk} of rational numbers for which the estimates of Theorem 4.1 hold.
According to Subsections 2.3 and 2.2, we have to find an algorithm that, given
n	˜
a sequence {fk} of grid functions fk : Gik  → Q	such that {fk} is a Cauchy
sequence converging in Cs(Q, Rn) to ϕ, computes a sequence {vk} of grid functions
vk : Gτ → Qn such that {v˜k|H} is a Cauchy sequence converging in CsL (H, Rn) to
u. W.l.o.g. we may assume that the sequence {ik} is increasing (otherwise, choose a suitable subsequence of {fk}).
Let vk be constructed from fk by the algorithm of the difference equation in

Subsection 4.1. It suffices to show that for some constant c (depending only on

A, B1,..., Bm) we have ||v˜k|H − u||sL2
≤ c ·  1
for all k. We have

||v˜k|H − u||sL2 ≤ ||v˜k|H − u˜k|H||sL2 + ||u˜k|H − u||sL2 .	(13)


By Theorem 4.1, ||u˜k|H − u||sL2
≤ c ·  1 
2
for a constant c, hence it remains to get

the same estimate for the first summand in (13). Since ||f˜k − ϕ||s ≤ c ·  1 
for a

constant c, ||fk −ϕ|G ||s ≤ c ·  1  for the same c. Since the scheme operator is linear
k	2ik
by the remark at the end of Subsection 4.1, from (10) we obtain ||uk|H −vk|H||sL2 ≤ c·||fk−ϕ|Gk ||s for a constant c. Since the operator of piecewise-linear interpolation is linear, from (12) we get the estimate for the first summand and hence the statement of the theorem.	 
As usual, we immediately obtain
Corollary 5.2 Let k ≥ 1, let A, B1,..., Bm be computable symmetric real matrices

with A > 0, let λ(i)
> 0 and λ(i)
< 0 for all i = 1,..., m, and let ϕ ∈ Ck+1(Q, Rn)

be a computable element of Cs(Q, Rn). Then the unique solution u ∈ Ck(H, Rn) of
(1) is a computable element of CsL (H, Rn).
Concluding Remarks
There are many open questions and directions of possible future research related to this paper. We guess that some generalizations and strengthenings of our results hold (e.g., for more complicated sets in place of Q, for the case when matrices A, B1,..., Bm are also varied, for Sobolev spaces (which are very popular in the study of equations similar to ours [10]) in place of the spaces discussed above, for other types of differential and difference equations, and so on. It would be also interesting to investigate schemes with higher order of accuracy and algoritms based on the popular finite element method.

Acknowledgement
We are grateful to Vasco Brattka for sending us some preprints on computability in linear algebra and to Vadim Isaev for some useful hints concerning approximations.

References
Brattka V. “Computablity over topological structures.” In: Computability and Models (eds. S.B. Cooper and S.S. Goncharov), Kluwer, New York, 2003, 93–136.
Friedrichs K.O. “Symmetric hyperbolic linear differential equations.” Communication on Pure and Applied Math., 7 (1954), 345–392.
Gantmacher F.R. “Matrix Theory.” (Russian, translated into English). Nauka, Moscow, 1966.
Godunov S.K. “Equations of Mathematical Physics.” (Russian). Nauka, Moscow, 1971.


Godunov S.K., ed. “Numerical solution of higher-dimensional problems of gas dynamics.” (Russian), Nauka, Moscow, 1976.
Godunov S.K. “Modern Aspects of Linear Algebra.” (Russian), Nauchnaya Kniga, Novosibirsk, 1997.
Godunov S.K. and Ryaben’kii V.S. “Introduction to the Theory of Difference Schemes.” (Russian). Fizmatgiz, Moscow, 1962.
Godunov S.K. and Selivanova S.V. “Experiments on using the resonance effect for spectral analysis of finite-dimensional skew-symmetric operators.” Siberian Journal of Numerical Mathematics, 9, No 2 (2006), 123–136 (Russian).
Ker-I Ko. “Complexity Theory of Real Functions.” Birkh¨auser, Boston, 1991.
Misohata S. “Theory of Partial Differential Equations.”(Russian, translated from Japanese). Mir, Moscow, 1977.
Petrovskii I. “U¨ ber das Cauchysche Problem fu¨r Systeme von partiellen Differenzialgleichungen.” Rec. Math. (Matematicheskii Sbornik), 2(44), 1937, 814–868.
Pour-El M.B. and Richards. “Computability in Analysis and Physics.” Perspectives in Mathematical Logic, Springer, Berlin, 1989.
Schauder J. “Das Anfangswertproblem einer quasilinearen hyperbolischen Differenzialglichung zweiter Ordnung in Beliebiger Anzahl von unabh¨angigen Verhinderlichen.” Fundamenta Mathematicae, 24 (1955), 213–246.
Selivanova S.V. “Experiments on computing the oscillation spectra in elasticity theory.” Bachelor thesis (Russian), Novosibirsk University, 2005.
Weihrauch, K. “Computable Analysis.” Berlin, Springer, 2000.
Weihrauch K. and Zhong N. “Is wave propagation computable or can wave computers beat the Turing machine?” Proceedings of the London Mathematical Society, 85(2), 2002, 312–332.
Weihrauch K. and Zhong N. “Computing the solution of the Korteweg-de Vries equation with arbitrary precision on Turing machines.” Theoretical Computer Science, 332(1-3), 2005, 337–366.
Zavyalov Yu.S., KvasovB.I. and Miroshnichenko V.L. “Methods of the Spline Functions.” (Russian), Fizmatgiz, Moscow, 1980.
Ziegler M. and Brattka V. “A Computable spectral theorem.” Proc. CCA-2001, Lecture Notes in Computer Science, v. 2064 (2001), 378–388.
