Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 351 (2020) 25–50
www.elsevier.com/locate/entcs

A Constraint-based Language for Multiparty Interactions 1
Linda Brodo2
Universit`a degli Studi di Sassari, Italy.
Carlos Olarte3
ECT, Universidade Federal do Rio Grande do Norte

Abstract
Multiparty interactions are common place in today’s distributed systems. An agent usually communicates, in a single session, with other agents to accomplish a given task. Take for instance an online transaction including the vendor, the client, the credit card system and the bank. When specifying this kind of system, we probably observe a single transaction including several (binary) communications leading to changes in the state of all the involved agents. Multiway synchronization process calculi, that move from a binary to a multiparty synchronization discipline, have been proposed to formally study the behavior of those systems. However, adopting models such as Bodei, Brodo, and Bruni’s Core Network Algebra (CNA), where the number of participants in an interaction is not fixed a priori, leads to an exponential blow-up in the number of states/behaviors that can be observed from the system. In this paper we explore mechanisms to tackle this problem. We extend CNA with constraints that declaratively allow the modeler to restrict the interaction that should actually happen. Our extended process algebra, called CCNA, finds application in balancing the interactions in a concurrent system, leading to a simple, deadlock-free and fair solution for the Dinning Philosopher problem. Our definition of constraints is general enough and it offers the possibility of accumulating costs in a multiparty negotiation. Hence, only computations respecting the thresholds imposed by the modeler are observed. We use this machinery to neatly model a Service Level Agreement protocol. We develop the theory of CCNA including its operational semantics and a behavioral equivalence that we prove to be a congruence. We also propose a prototypical implementation that allows us to verify, automatically, some of the systems explored in the paper.
Keywords: Concurrency theory, constraints, multiparty interactions


Introduction
Nowadays concurrent and mobile systems are ubiquitous in several domains and applications. They pervade different areas in science (biological and chemical sys-

1 The joint work of the authors was possible thanks to the Visiting Scientist grant of University of Sassari. Carlos Olarte was also funded by CNPq. Linda Brodo was also funded by “fondo di Ateneo per la ricerca 2019 ” of University of Sassari.
2 Email: brodo@uniss.it
3 Email: carlos.olarte@gmail.com

https://doi.org/10.1016/j.entcs.2020.08.003
1571-0661/© 2020 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

tems), engineering (security protocols and mobile and service oriented computing) and even the arts (tools for multimedia interaction). In general, concurrent systems exhibit complex forms of interaction, not only among their internal components, but also with the surrounding environment. Hence, a legitimate challenge is to pro- vide computational models allowing us to understand the nature and the behavior of such complex systems. As an answer to this challenge, process algebra such as CCS [17], the π-calculus [18] and CSP [13] among several others have arisen as mathematical formalisms to model and reason about concurrent systems.
It is worth noticing that there is no unified model for concurrency, as in the case of the λ-calculus for sequential computations. Concurrency is, in fact, a relatively young area in computer science, and there are many models that accurately capture some behaviors but ignore/abstract some others. For instance, CCS focuses on the synchronization of processes: by exhibiting complementary actions two processes handshake and synchronize. However, no message is indeed sent among the agents. Data-passing extensions of CCS allow to overcome this problem, but the underlying communication network remains invariant during computation since processes can- not create and communicate new/private communication channels. The π-calculus gives a step forward and allows the communication of names (representing data and also communication links) that can later be used in other interactions. Many other process algebras have emerged as extensions of existing ones to cope with specific behaviors or they have taken inspiration from particular systems as in the case of calculi for system biology. For instance, the Spi Calculus [1] incorporates cryptographic primitives into the π-calculus for the specification and verification of security protocols and the Brane Calculi [10] took inspiration from the interaction of cell’s membranes to model biological interactions. The beauty of all these for- malisms relies on their simplicity (few operators), formal semantics and reasoning techniques, including behavioral equivalences (e.g., bisimulation), modal logics and model checking for specifying and verifying system’s properties.
Most of the process algebras in the literature focus on binary interactions. Con- sider for instance CCS where a process a.P (P prefixed by the input action a) can synchronize with a.Q (Q prefixed by the output action a) when they are in a parallel composition (e.g., as in a.P | a.Q). Such synchronization is made explicit via a spe- cial action τ (called the silent action) and what we observe is the synchronization of
these processes in the transition a.P | a.Q −τ→ P | Q where, after the handshake,
P and Q continue their executions.
In this paper we shall focus on a multiparty extension of CCS, the so called Core Network Algebra (CNA) [4,6,5], a multiparty process algebra where the number of participants in each synchronization is not fixed a priori. In CNA, the binary inter- action of CCS is extended and the usual input and output prefixes are generalized to links, e.g., a\b, that can be thought of as the forwarding of a message received on channel a (the input channel) to another channel b (the output channel). The standard input and output prefixes of CCS are recovered when links expose only an output ( τ \b ), or an input ( a\τ ); these particular actions are the ends of a link chain where τ is the silent action (as in CCS). A link chain is the mechanism

in CNA by which n ≥ 2 entities can synchronize. Each entity must offer a link that has to match with an adjacent link offered by another entity. For instance, if three processes offer, respectively, the links a\b, b\c and c\d, they can synchronize and produce the link chain a\b\c\d, where information flows from a to d through b and
b c
c.
In [7,8] the authors showed that the multiparty and open (arbitrary number of participants) nature of CNA poses interesting problems for the point of view of verification. In particular, while the number of possible successor states from a CCS process is quadratic on the number of its outermost prefixes, it is exponential in the case of a CNA process. Moreover, it is possible to specify a graph of agents as a CNA process P (some examples in Section 4.2) and we can check that there is a Hamiltonian path in the graph iff there is exactly one immediate successor of P . We explored in [7,8] symbolic techniques aiming to tame the inherent complexity of the CNA transition system.
The goal of the present paper is to define a suitable extension of CNA that allows the specifier to control, in a declarative way, the behavior of processes. More precisely, we provide mechanisms that allow us to include in a CNA specification certain restrictions that appear naturally in the modeled system at hand. For instance, we may be interested in transitions/paths in a graph to have certain length or to specify upper bounds on the number of participants in an open interaction. This is the purpose of introducing constrains and values in prefixes: the process a\b⟨!vp⟩(?cp).P offers the link a\b at a given cost/value vp and checks whether the interaction with some other processes satisfies the constraint cp. When this process interacts with, e.g., b\c⟨!vq⟩(?cq).Q, the synchronization a\b\c has a final cost v = vp + vq and it can actually happen if v satisfies both cp and cq. As we shall see, the control mechanism due to constraints have interesting properties and, in the quest of defining such extensions, we found solutions to distributed problems that do not have a simple solution in other process calculi. Quoting Jos´e Meseguer [16], “increased expressiveness is not a theoretical luxury, but an eminently practical goal, since formal speciﬁcation languages should describe as simply and naturally as possible the widest possible class of systems.”. This is precisely our goal here.

Contributions and organization. We start in Section 2 recalling the CNA frame- work. In Section 3 we introduce the notion of constraints based on complete lattices and monoids. Such structure allows us to compare values (e.g, c < 42 ) and also to accumulate values (e.g., adding the length/cost of two paths in a graph). We then extend the language of CNA to allow processes to communicate such values and also to query constraints on them. Hence, a transition can happen only if all the involved agents satisfy their own constraints. We call this new calculus constrained CNA (CCNA). We shall show that CCNA is a conservative extension of CNA (No- tation 3.7): CNA processes can be seen as CCNA processes that exchange the less restrictive value and query the always-true constraint. In Section 3.2 we endow CCNA with a suitable operational semantics. This semantics has some novelties wrt the standard one for CNA: we follow a late approach in contrast to the early one

used in [5]. Our semantics is then a good middle point between the inherent non- deterministic early semantics and the (more involved) symbolic semantics in [8]. Section 3.3 introduces the notion of (network) bisimulation for CCNA process and we prove that this equivalence is a congruence (thus allowing us to replace equals by equals in larger systems). In Section 4.1 we show that the use of constraints leads to a simple solution for the Dinning Philosopher problem where concurrent processes compete for the use of some resources. Our solution is deadlock-free and fair: all the agents can progress infinitely often. Fairness is usually imposed as an external condition but here, the constrained transition system satisfies such prop- erty. In Section 4.2 we model a graph representing a transportation system and we show how constraints allow us to discard some (undesired) behaviors. Moreover, in Section 4.3, we present an application in the context of a Service Level Agreement (SLA) protocol where constraints naturally represent restrictions such as the upper bound for the price of the service to be paid and the minimal quality (bandwidth) the client is expecting. Section 5 concludes the paper and present related work. We have also implemented a tool using the Maude system [16]. We shall not describe in depth such system here but we shall exemplify its use in Section 5. We thus con- tribute with a formal framework to specify constrained multiparty interactions and a prototypical tool showing its appropriateness as (automatic) reasoning technique.

Background on link chained interactions
Let C be the set of channel names, ranged over by a, b, c, ..., and τ, 2 two distin- guished symbols not in C. A = C∪ { τ }∪{ 2 } is the set of actions, ranged over by α, β, ..., where the symbol τ denotes a silent action, while the symbol 2 denotes a virtual (non-specified) action.
Definition 2.1 (Links: solid, virtual and valid) A link is a pair l = α\β, with α, β ∈ A. We call α the source site of l and β the target site of l. A link α\β is solid if α, β /= 2; the link 2\2 is called virtual. A link is valid if it is solid or virtual. We shall use L to denote the set of valid links.
Intuitively, a\b records an action a (or equivalently an input on channel a) anda co-action b (or an output on b), such that the input on a (receiving from the source of a communication) can be forwarded (to the target of the communication) along channel b. The τ -action is used when no interaction is required on the left (as in τ \a), on the right (as in a\τ ) or on both sides (as in τ \τ ). The link τ \τ is called τ-link. A virtual link 2\2 represents a non-specified interaction that will be later completed. Examples of valid links are 2\2, a\a, τ \a, b\a, τ \τ . The links 2\a, a\2 are not valid.
Links can be combined in link chains. Intuitively, a link chain s = l1...ln represents a multiparty interaction where each li records the source and the target sites of each hop.
Definition 2.2 (Link Chain) A link chain is a ﬁnite sequence s = l1...ln of valid links li = αi \βi . We say that s is valid if:

for all i ∈ [1, n), ⎧⎨ βi, αi+1 ∈C implies βi = αi+1
βi = τ	iff αi+1 = τ
∃i ∈ [1, n]. li /= 2\2.

; and

We shall use VC to denote the set of valid link chains. The length of a link chain s (i.e., the number of links in s) will be denoted as |s|.
Condition (i) says that two adjacent solid links must match on their adjacent sites. In order to highlight such a matching, we shall write link chains as, e.g., a\b\c\d instead of sequences of links as in a\b b\c c\d. Condition (i) also says that
b c
the silent action τ cannot be matched by a virtual action 2. As we shall see, this is
required since a τ -action can be only matched with τ when processes synchronize on restricted channels. Condition (ii) says that a valid link chain must have at least one solid link (i.e., the chain 2\2\2 is not valid). Some examples of valid link chains are: 2\a \b\τ , a\2\c \d, and τ \a\τ . The first chain represents an interaction where
2 b	b  2	a
there is a pending synchronization on the left of a\b; similarly, the second chain
represents an interaction where a third-party process must offer a link joining b and c (i.e., b\c). Finally, the last chain is the result of a binary interaction between a process performing the output τ \a and a process performing the input a\τ . The following are examples of link chains that are not valid: a\c\d, 2\τ \a, and a\c \d.
b	2	τ
Hereafter, we only consider valid links and valid link chains. We shall use ⊥ to
denote non-valid links and chains.
Now we introduce the merge operator s • sj that acts on two link chains of the same length, i.e. |s| = |sj|. Intuitively, s • sj makes the two link chains collapse into one link chain where some of the virtual links in s (resp. sj) have been substituted with the corresponding solid links in sj (resp. s).
Definition 2.3 (Merge) Let α, β ∈A be actions. The merge operator on actions is deﬁned as follow:

α • β = α if β = 2	α • β = β if α = 2	α • β = ⊥ otherwise


For links, let l1 = α1 \β
and l2 = α2 \β
be valid links and α1 • α2 = xα, β1 • β2 = xβ.

If xα, xβ /= ⊥, then l1 • l2 = xα \x
. Otherwise, l1 • l2 = ⊥. For the merge

on chains, let s = l1...ln and sj = lj ...lj
be valid chains with li = αi \β
and

j	α′	j
n	i
j	j

li = i \β′ . If li • li /= ⊥ for all i ∈ [1, n] and (l1 • l1)...(ln • ln) is a valid chain,
then s • sj = (l1 • lj )...(ln • lj ). Otherwise, s • sj = ⊥.
1	n
As an example, the chains 2\2\a \b and c\2\2 cannot merge, as they have
2 2	a
different length; a\2\2 and 2\c \d cannot merge since a\c\d is not a valid chain; a
b	2	b
chain s cannot merge with itself; finally, c\2\b \d and 2\a \2\2 merge into c\a\b\d.
a  2	2 b	a b
As usual in process calculi, names are restricted in order to force interactions.
Let s = l1...ln = ... αi \αi+1 \βi+1 ... be a link chain. We say that a is matched in s
if both
a /= α1 and a /= βn (i.e., a cannot occur in the endpoints), and

for any i ∈ [1, n), either βi = αi+1 = a or βi, αi+1 /= a.
Otherwise, we say that a is unmatched (or pending ) in s. For example, a and b
are matched in τ \a\b\d. Instead, neither a nor b are matched in d\2\c \b.
a b	a  2
Definition 2.4 (Restriction) Let α, β ∈ A be actions and a ∈ C be a channel name. We deﬁne the following operations on actions and links:


(ν a)α = ⎧⎨ τ if α = a
⎩ α otherwise

and	(ν a) α\β


= ((ν a)α)\



((ν a)β)

We lift those operations to link chains as follow:

(ν a)s = ⎧⎨ ((ν a)l1) ... ((ν a)ln) if a is matched in s
⎩ ⊥	otherwise
For instance, in s = τ \a\2\2, the name a is matched and (νa)s = τ \τ \2\2; whereas
a b	τ  b
(νb)s is undefined since b is pending in s.
CNA with constraints
In this section we present the CNA calculus equipped with data passing and con- strains on those data. Unlike the link-calculus [5] (and also the π-calculus in that respect), we will consider values which are not channel names, thus they will have a separate definition set. Our goal is to perform some checks on the data that partic- ipants in a interaction can share. Values will be taken from an algebraic structure that allows us to compare (≤) and also to accumulate (⊗) those values. The fol- lowing definitions are from [11] that simplifies at some extent the presentation of c-semiring [3] (another algebraic structure used for accumulating and comparing constraints).
Recall that a partial order is a pair ⟨Ð, ≤⟩ such that Ð is a set and ≤ is a reflexive, transitive and antisymmetric relation on Ð. We use < to denote the strict version of
≤ (i.e., v < vj if v ≤ vj and v /= vj). We also use ≥ and > with the expected meaning. A complete lattice is a partial order where any subset X ⊆Ð has a least upper bound denoted as HX. By duality, the greatest lower bound, denoted as HX, also exists. As usual, we use T and ⊥ to denote, respectively, HÐ and H∅. An abelian (or commutative) monoid is a triple ⟨Ð, ⊗, T⟩ where ⊗ : Ð× Ð → Ð is a commutative and associative operator and T is its identity (i.e., 6v ∈ Ð.v ⊗T = T⊗ v = v).
Definition 3.1 (CLM [11]) A complete lattice monoid (for short CLM) is a tuple K = ⟨Ð, ≤, ⊗⟩ s.t. ⟨Ð, ≤⟩ is a complete lattice, ⊥ and T are, respectively, the least and the greatest elements of Ð and ⟨Ð, ⊗, T⟩ is a commutative monoid. We assume that ⊗ distributes over glb’s, i.e.,
6v ∈ Ð.6X ⊆ Ð.v ⊗ HX = H{v ⊗ x | x ∈ X}

Let us explain the above definition with a concrete instance that we shall use in the following sections. Consider the structure KN = ⟨N∞, ≥, +⟩ where N∞ is the set
+	+
of natural numbers completed with ∞ and ≥ is the usual “greater than” relation
on N∞ (e.g., 5 ≥ 2). We can think of the elements in N∞ as costs. Note that we
+	+
consider 0 as the “best” (T) cost (x ≤ 0, i.e., x ≥ 0 for any x ∈ N∞). Also, ∞ is
the worst (⊥) cost we can assume. We accumulate costs with + (addition on N). When costs are added, we get “worse costs” (e.g., 3 + 2 ≥ 3). More generally, we can show that ⊗ is an intensive operator : 6v, vj ∈ Ð,v⊗vj ≤ v. It is also possible to prove that ⊥ is absorbing for ⊗ (i.e., 6v ∈ Ð.v ⊗⊥ = ⊥). In our concrete example, v + ∞ = ∞.
Definition 3.2 (Residuation) Let K = ⟨Ð, ≤, ⊗⟩ be a CLM and v, vj ∈ Ð. The residuation of v with respect to vj is deﬁned as v ÷ vj = H{x ∈Ð | v ≤ vj ⊗ x}.
As expected, v ≤ vj ⊗ (v ÷ vj) (due to distributivity). Moreover, if vj ≤ v then
v ÷ vj = T. In KN, ÷ is subtraction on N∞ ( v ÷ vj = v − vj) if v ≥ vj (i.e.,
v ≤ vj) and 0 otherwise. (See [2] for a discussion on residuation in constrain-based formalisms).
It is possible to combine different CLMs in order to measure/compare different entities in a single operation.
Lemma 3.3 (Combining CLMs) Let K1 = ⟨Ð1, ≤1, ⊗1⟩ and K2 = ⟨Ð2, ≤2, ⊗2⟩ be CLMs. Deﬁne K = K1 × K2 = ⟨Ð1 × Ð2, <, ⊗⟩ where (v, w) ≤ (vj, wj) iff v ≤1 vj and w ≤2 wj; and (v, w) ⊗ (vj, wj)= (v ⊗1 vj,w ⊗2 wj). Then, K is a CLM.
Proof. The existence of arbitrary lubs is an easy consequence of the existence of lubs in K1 and K2. Distributivity also follows easily. Note that we can also define (point-wise) residuation on K.	2
Constrained multiparty interactions
Now we are ready to introduce the syntax of constrained CNA, from now on denoted as CCNA, which is parametric with respect to a CLM. In the following, we fix the CLM K = ⟨Ð, ≤, ⊗⟩ with residuation operator ÷. We shall use u, v to range over elements of Ð. We shall call data-variables to variables (usually denoted as x, y,  )
that take values from Ð.
Definition 3.4 (Syntax of CCNA) Given a set of channel names C (ranged over by a, b) and a CLM K, processes in CCNA are built from the syntax

exp ::= a | v | x | exp ⊗ exp | exp ÷ exp	expressions
atm ::= exp  expj	where  ∈ {≤, <, =, /=, ≥, >}	atomic constraints
c, cj ::= atm | c ∧ cj	constraints
p, q  ::= 0 | l⟨!e⟩(?c).P  | p + q	sequential processes
P, Q ::= p | P | Q | (ν a)P  | A⟨a1,..., an; e1,..., em⟩	processes

where a is a distinguished data-variable representing the accumulated value of an interaction; v ∈ Ð; x is a data-variable; e is an expression where a does not occur; l = α\β is a solid link built from C∪{τ} (i.e. α, β /= 2); A is a process identiﬁer for which we assume a (possibly recursive) deﬁnition of the form A(b; x) , P where b is a list of pair-wise distinct names and x is a list of pair-wise distinct data-variables; and ei is an expression where a does not occur.	2
In the following paragraphs, we explain in detail each of the components of this definitions. The symbol a denotes a special data-variable that accumulates (using
⊗) the values added by each of the participants in an interaction (Definition 3.10 below). In KN, examples of valid expressions are 3, 5 − y, 5 + x + a, etc.
Constraints will be used to check if the agents agree on the values of a given interaction. In KN, examples of atomic constraints are 5 ≥ 3, x ≥ 4, x ≥ y + 3, a ≥ 10, etc. A constraint is just a conjunction of such atoms. We use tt to denote the (always true) atomic constraint ⊥≤ T.
Before explaining the meaning of processes, we need an extra definition. The only binder for (data-) variables is the process definition A(b; x) , P where the variables in x occur bound in P . We shall use fv (P ) to denote the set of free (data-
) variables in the process P . We shall also use fv (c) to denote the set of free (data-) variables in c (including a).
Definition 3.5 (Entailment) We say that a constraint c is ground if it does not contain data-variables nor the symbol a (i.e., fv (c) = ∅). Given a ground atomic constraint c = e ej, we say that c holds, notation K |= c, if e and ej reduce (performing the operations ⊗ and ÷ in K), respectively, to v and vj and the relation v vj holds in K. Otherwise, we write K |= c. We extend this notion to ground constraints as follows: K |= c1 ∧· · ·∧cn whenever K |= ci for all i ∈ 1..n. Let c, cj be constraints s.t. fv (c), fv (cj) ⊆ {a}. We say that c, cj are equivalent, notation c ≈ cj if 6v ∈ Ð.K |= c[v/a] iff K |= cj[v/a].
As an example, we have the following entailments: KN |= 3 + 2 ≤ 1 + 2 ; and KN |= 3 ÷ 2 ≥ 1 + 2. Moreover, if c1 = tt ∧ 3 ≤ a and c2 = a +0 ≥ 5 ÷ 2 then c1 ≈ c2.
The process 0 does nothing. The process l⟨!e⟩(?c).P offers the solid link l along with the value denoted by the expression e and checks whether the constraint c holds. After this interaction, the process behaves as P . The non-deterministic process p + q can either behave as p or q. Interleaved parallel composition is denoted as P | Q. The process (ν a)P behaves as P but it cannot exhibit any action a. Hence, we can say that a is local (or private) in P . As usual, (ν a)P binds the free occurrences of a in P .
The   call   A⟨a1, ..., an; e1, ..., em⟩   behaves   as   the   process P [a1/b1, ..., an/bn][e1/x1,..., em/xm]  if  the  constant  A  is  defined  as A(b1, ..., bn; x1, ..., xm) , P .  As expected, the actual parameters substitute the formal parameters of the definition. Besides binding the variables xi, the above definition binds the names bi. We shall use fn(P ) and bn(P ) to denote, respectively, the free and bound names in P .

We shall impose some restrictions on process that are commonplace in the lit- erature (see e.g., [12]).
Definition 3.6 (Valid Processes) Processes are taken up to alpha-conversion (renaming of bound names). We assume that in a process deﬁnition A(b; x) , P, fn(P ) ⊆ b and fv (P ) ⊆ x. Moreover, in order to guarantee the transition system to be ﬁnitely branching, we assume that recursive calls in P must be guarded inside a preﬁx l⟨!e⟩(?c).Q. Finally, we assume that in all processes, the occurrence of a data-variable x (different from a) is always bound by a process deﬁnition.
For instance, the processes l⟨!2⟩(?x > 5).Q and l⟨!2 + x⟩(?a > 5).Q are not valid since x occurs free (and not bound by a process definition). Moreover, the process
def
definition A() = A⟨⟩|P is not valid since the call A⟨⟩ is not guarded (thus making
the transition system infinitely branching).
Notation 3.7 For the sake of readability, we shall use the following shortcuts. We shall omit a trailing 0, e.g. by writing a\b instead of a\b.0. We shall also write l⟨!e⟩ instead of l⟨!e⟩(?tt). Recall that v⊗T = v for all v ∈ Ð. Hence, we shall write l(?c) instead of l⟨!T⟩(?c). Finally, we shall simply write l instead of l⟨!T⟩(?tt). Note that any CNA process is also a CCNA process whose shared value (T) is irrelevant for the ﬁnal interaction and whose constraint always holds (tt).
The following example shows how constraints can be used to limit the number of participants in a multiparty interaction. For the moment, the discussion about the behavior of process remains informal until we define the semantics in the next section.
Example 3.8 The process P = a\b is able to interact with any other process, say Q = c\d and synchronize producing the link chain a\2\c \d. Other outputs
b  2
can be also expected from that interaction, as e.g.	c\2\a \b.  In fact, a 3-party
d 2
synchronization is also possible with yet another process R = b\c, thus building the
chain a\b\c\d. More generally, P can interact with an unbounded number of other
b c
processes by building suitable (valid) link chains. This means that interactions in
CNA are open since the number of participants is not ﬁxed a priori. This is a quite expressive feature of the calculus but it makes also difficult to reason about processes. (See [7] and [8] for symbolic techniques to deal with this problem). Consider the structure KN and the processes below

Pj = a\b⟨!1⟩(?a ≤ 2)	Qj = c\d⟨!1⟩(?a ≤ 2)	Rj = b\c⟨!1⟩(?a ≤ 2)
Hence, Pj can interact with at most one of the other two processes (Qj or Rj) since, in each interaction, the value 1 is accumulated and such value must be less than 2. This is a very intuitive (and declarative) mechanism for counting and restricting the participants in an interaction.	2
Derived construct (tuples). Let us introduce an idiomatic construct that will be useful. Due to Lemma 3.3, we can assume that agents offer links with tuples of

l⟨!e⟩(?c)
l⟨!e⟩(?c).P −−−−−→ P
Act
p −→ Pj
p + q −→ Pj

q −→ Qj
Lsum	μ
p + q −→ Qj

Rsum



μ	μ	j
P  μ	j	φ	j

P −→ Pj
	Q −→ Q	
Lpar	Rpar
  −→ P	Q −→ Q
Com

μ
P | Q −→
Pj | Q
μ
P | Q −→
P | Qj
P | Q μ•φ Pj | Qj



P [a/b][v/x] −→ Pj
A(b; x) , P
Ide
P −→ Pj

Res

A⟨a; v
⟩ −→ Pj
(νa)μ
−−−→ (νa)P


Fig. 1. Semantics. All the rules have the proviso that the labels in the transitions are valid (Def. 3.10).
elements as, e.g., (e1,..., en). Such tuples are elements of the CLM K1 ×· · ·× Kn.
Hence, we shall use the more convenient notation
l⟨!e1,..., en⟩(?c1 ∧· · · ∧ cn)
where each constraint ci may use the special symbol ai (denoting the accumulated values in the i-th position of the tuple). Note that these tuples and constraints can be easily rewritten in the syntax of Definition 3.4 by using the construction in Lemma 3.3. Since each CLM Ki represents a different value/measure to be accumu- lated, it is not legal to combine values of different CLMs in the same expressions. For instance, expressions as, e.g., a1 ÷ a2 are not legal. Similarly for constraints. Next notational convention allows us to give alias for the “accumulating” variables ai to make specifications cleaner.
Notation 3.9 (Tuples and variables) For  a  given  speciﬁcation,  we can  determine  that  tuples  used  in  interactions  are  of  the  form
⟨x1, ..., xn⟩ where the aliases xi cannot be bound by a process deﬁni- tions.  Hence, we write l⟨!x1 = e1,..., xn = en⟩(?c1 ∧ · · · ∧ cn) to mean l⟨!e1,..., en⟩(? (c1 ∧· · · ∧ cn) [a1/x1, ..., an/xn]). Moreover, if vi = T, we fur- ther omit “xi = T”. For instance, if we determine that tuples are of the form ⟨cost, speed⟩, the expression l⟨!speed = 1⟩(?cost ≤ 3 ∧ speed ≥ 10) means l⟨!T, 1⟩(?a1 ≤ 3 ∧ a2 ≥ 10).

Semantics
In this section we introduce the operational semantics for CCNA. A novelty in this semantics is the use of a late approach where the number of participants is inferred only in the communication rule in contrast to the early approach adopted in [4] (where the rule Act needs to “guess” the size of the interaction) . This distinction will be clarified in brief.
Before defining the semantics, we shall lift the definition of merge on link chains (Definition 2.3) to consider also valued-constrained-chains (VCC) of the form s⟨!e⟩(?c) where s is a link chain, e is a ground expression (no free variables) and c is a constraint where fv (c) ⊆ {a}. For that, we allow link-chains to be enlarged (injecting virtual links) or contracted via the relation ►( defined below.

Definition 3.10 (Valued-constrained-chains and operations) We let ►( be the least equivalence relation over link chains closed under the axioms (whenever both sides are valid link chains):

s 2\2 ►( s	s1 2\2\2 s2 ►( s1 2\2 s2	2\2 s ►( s	s1 α\a\β s2 ►( s1α\2\a \β s2
2	a	a 2

We merge VCCs as follow: s⟨!e⟩(?c) • sj⟨!ej⟩(?cj) = (w • wj)⟨!e ⊗ ej⟩(?c ∧ cj) with s ►( w and sj ►( wj. We deﬁne (νa)(s⟨!e⟩(?c)) as ((νa)s)⟨!e⟩(?c). We say that a VCC s⟨!e⟩(?c) is valid iff s is a valid link chain and K |= c[e/a].
We shall use μ, φ to range over VCCs. Note that the values are merged using the ⊗ operator of the CLM. Note also that, in order to check the validity of a VCC, the symbol a is replaced with the current accumulated value e. Since we are assuming that there are no free data-variables in a process (see Definition 3.6), once the data- variables of a definition have been replaced with concrete values, c[e/a] is indeed a ground constraint. Finally, since there are no occurrences of names in values and constraints, the restriction operation on VCCs acts only on the link chains (Definition 2.4) and hence, e and c remain the same.
The structural operational semantics is given by the labeled transition system (P, VCC, −→) where the set P of states is the set of CCNA processes, labels are valid valued-constrained-chains (VCC) and the transition relation −→ is the minimal transition relation generated by the rules in Figure 1.
The prefix process l⟨!e⟩(?c).P simply offers the link l with value/expression e
and checks whether c is valid, i.e., l⟨!e⟩(?c) must be a valid VCC (Rule Act). If p

is able to exhibit a transition to Pj with label μ, then p + q	μ
Pj (Rule Lsum).

Similarly for q (Rule Rsum). If P can exhibit a transition, it can also exhibit the same transition when running in parallel with Q (Rules Lpar and Rpar). In Res, if P offers the action μ then (νa)P offers (νa)μ (if it is valid). Rule Ide simply replaces the formal parameter with the actual parameters.
The synchronization mechanism (Rule Com) works by merging two VCCs. When doing that, note that the link chains can be enlarged (Definition 3.10) and hence, the links of one chain can be placed in an admissible position of the other chain. Note that the decision about the length of the resulting chain is postponed until the use of the rule Com. This is a different approach from the one considered in
[4] (for CNA processes) where the size of the interaction must be inferred in the Act rule (by enlarging in this rule l with ►(). We also note that contrary to CCS, the Rule Com in CCNA (and CNA) can appear several times in the proof tree of a transition since the merging operator can always inject more virtual links to allow other agents to participate as shown in the following example.
Example 3.11 Consider the CLM KN and the processes:

P = τ \a⟨!2⟩(?a ≤ 10).P j    Q = a\b⟨!3⟩(?a ≤ 12).Qj    R = b\τ ⟨!5⟩(?a ≥ 4).Rj


a\b(!3⟩(?a≤12)
Act
′

b\τ (!5⟩(?a≥4)
Act
′

τ	Act
Q −−−−−−−−−−−→ Q
a b
R −−−−−−−−−−→ R
Com

\a(!2⟩(?a≤10)	′	\b\τ (!8⟩(?a≤12∧a≥4)	′  ′

P −−−−−−−−−−−→ P
Q|R −−−−−−−−−−−−−−−−→ Q |R
τ \a\b\τ (!10⟩(?c)
Com

P|Q|R  −−−a−−b−−−−−−−→  P′|Q′|R′
τ \τ \τ \τ (!10⟩(?a≤10∧a≤12∧a≥4)


′  ′  ′
× Res

(νa, b)(P|Q|R) −−−−−−−−−−−−−−−−−−−−−−−→ (νa, b)(P |Q |R )


Fig. 2. Derivation in Example 3.11.




representing three agents interested in building a house. Each of them has a cost for her services (e.g., P charges $2). Moreover, P is not willing to participate in a project that costs more than $10 and R does not participate in “small” projects with a cost below $4. P requires someone providing a service matching its output link a. Q offers a and expects in exchange b and R provides b. The three agents can indeed engage in the project as the derivation in Figure 3.2 shows. Note that (νa, b)τ \a\b\τ = τ \τ \τ \τ . Also, in all the steps of this derivation the labels of the
a b	τ  τ
transitions are valid VCCs. Rule Com is used twice in the derivation, thus resulting
in a 3-party interaction.

If we deﬁne P2 as τ \a⟨!2⟩(?a < 10).P j
the process (νa, b)(P2|Q|R) does not

have any transition since s⟨!10⟩(?a < 10 ∧ a ≤ 12 ∧ a ≥ 4) is not a valid VCC. Moreover the names a, b are restricted and none of the processes in P2|Q|R can evolve independently using the rules Lpar and Rpar (e.g., a is not matched in τ \a and then, (νa)τ \a is not valid). In words, P2 refuses a 3-party interaction with Q and R since the project will cost more than she expects.	2
Example 3.12 (Conditionals) Given an atomic constraint c = e1  e2, let c
denote the atomic constraint e1 e2 where   substitutes = with /=, ≤ with >,
< with ≥, etc. It is straightforward to see that: (1) c = c ; and (2) given a ground atomic constraint c, K |= c iff K |= c. We can deﬁne a condi- tional construct to select the continuation of a process depending on the entail- ment of a constraint. More precisely, if c = c1 ∧ · · · ∧ cn where each ci is an atomic constraint, we can write l⟨!e⟩(if ?c then P else Q) to denote the process l⟨!e⟩(?c).P + l⟨!e⟩(?c1).Q + ··· + l⟨!e⟩(?cn).Q. Note that P is executed whenever all ci hold (and hence c holds) and Q is executed if there is a ci that does not hold in the underlying CLM.	2
Definition 3.13 (Computations) Let W∗ be the set of ﬁnite and inﬁnite se- quences of valid VCCs. Let P be a process and σ = s1.s2... ∈ W∗ be an inﬁnite
sequence. We say that σ is a computation of P if P = P0 −s→1  P1 −s→2  P2 −s→3  · · · .
If P cannot afford any transition, we shall write P −→ and we call P a dead-lock. If σ = s1.s2...sn ∈ W∗ is a ﬁnite sequence, we say that σ is a (ﬁnite) computation
of P if P = P0 −s→1  P1 ··· Pn−1 −s→n  Pn −→. In both cases we shall write P  −σ→.
We shall use O(P ) ⊆ W∗ to denote the set {σ | P −σ→}.

Network bisimulation
Now we define a behavioral equivalence on CCNA processes that we show to be a congruence. In the tradition of CNA, we do not distinguish between processes that exhibit different internal transitions. This is reflected in the following extension of the equivalence relation DD originally proposed in [4].
Definition 3.14 (Equivalence DD) We let DD be the least equivalence relation over link chains closed under the following inference rules:


s ►( sj
s DD sj	s1
α\τ \β s2 DD s1
α\β s2

We lift such relation to VCC as follows: s⟨!e⟩(?c) DD sj⟨!e⟩(?cj) iff s DD sj and
c ≈ cj.
Definition 3.15 (Network Bisimulation) A network bisimulation R is a binary relation over CCNA processes such that, if P R Q then:

μ
if P −→
μ
if Q −→
Pj, then ∃ φ, Qj such that μDDφ, Q	φ
Qj, then ∃ φ, Pj such that μDDφ, P	φ
Qj, and Pj R Qj; Pj, and Pj R Qj.

P and Q are network bisimilar, notation P ∼ Q, if there exists a network
bisimulation R s.t. P R Q.
Following standard techniques (see e.g., [12,23]), we can show that ∼ is an equivalence relation and it is the largest network bisimulation relation.
Let us give some illustrative examples with the structure KN. For any P , 0 ∼ l⟨!3⟩(?a ≤ 2).P since KN /|= 3 ≤ 2. Moreover, merging constraints cannot make a ≤ 2 valid (due to intensiveness of ⊗ w.r.t. ≤, i.e., a will be always greater than 3).
The processes P = l⟨!3⟩(?a ≤ 5) and Q = l⟨!3⟩(?a ≤ 7) cannot be considered equivalent: Q can, for instance, synchronize with R = lj⟨!4⟩ while P cannot. Now consider P = l⟨!2⟩(?a ≤ 2) and Q = l⟨!4⟩(?a ≤ 4). Note that both processes can synchronize with a process of the form R = lj⟨!0⟩(?c). However, if c = a ≤ 2, P and R can synchronize but Q and R cannot.
Next we show that ∼ is a congruence relation and then, we can replace “equals by equals” in any context. For that, let C[·] denote a process expression with a single occurrence of a hole [·]. Moreover, if P is a process, C[P ] denotes a process expression resulting from the substitution of the hole [·] with P .
Theorem 3.16 (Congruence) If P ∼ Q then, for any context C[·], C[P ] ∼ C[Q].
The above theorem is proved by exhibiting appropriate network bisimulations for any case/context. The complete proof is in the appendix.
Applications: fairness and constrained interactions
In this section we give three compelling examples showing how to declaratively control multiparty interactions by means of constraints. The first example is the

canonical problem of the dinning philosophers. In this case, by adding constraints, we are able to specify a deadlock free and fair solution for the problem. The second example models a network transportation system where constraints may represent costs or temporal restrictions. In our last example, constraints are used to model service level agreements in a negotiation protocol.
The dinning philosophers
The classical example of the dining philosophers (DP) has been introduced to study interactions between concurrent entities that want to share some resources. The problem relates n philosophers sitting around a table, where each one has its own dish, and they can only eat or think. When they, independently, decide to eat, they need two forks. On the table, there is only one fork between two dishes, i.e., exactly n forks.
It is well known there is no symmetric and deadlock-free specification of this system using only binary interactions [12] as in, e.g., CCS. Let us illustrate the problem considering only two philosophers. The philosophers are specified as the

CCS process Pi = fi.f(i+1)mod 2.eati.P j
where P0 first grabs the fork 0, then he

grabs the fork 1 to later start eating (similarly for P1). If we run in parallel P0 and
P1 along with the processes specifying the two forks (Fi = fi.F j), the system can reach a deadlock when P0 takes the fork 0 and P1 takes the fork 1.
By using a multiparty synchronization calculus, the DP problem has a simple and very natural deadlock free specification (see [7,8] for a solution using CNA and [12] for a solution using Multi-CCS). In that case, in an atomic (or multiparty) interaction, a philosopher takes at the same time both forks, thus avoiding the deadlock situation described above. However, the solutions in Multi-CCS and CNA may exhibit unfair computations where, e.g., a given philosopher eats or thinks all the time (and the others cannot progress).
Definition 4.1 (Fairness [24]) Let π be an inﬁnite computation, π = P0 −s→1
P1 −s→2  P2 −s→3  · · · . A VCC μ is relentlessly enabled in π if 6 πjj, πj s.t. π = πjjπj,
πj contains a process Pi that can afford a transition labeled with μ. Moreover, π is strongly fair if each relentlessly enabled VCC μ on πj occurs in πj.
In words, a computation π is strongly fair if an action (VCC) that is relentlessly enabled in π, occurs infinitely often in π.
Here we focus on a fair solution for the DP problem: due to deadlock-freeness, every computation is infinite and, by fairness, in every computation each philosopher eats infinitely many times. For that, we use constraints to neatly implement a sort of ticket service, thus guaranteeing that philosophers must alternate the use of the forks. From now on, we fix the CLM to be the structure KN.
Below we describe our first attempt to solve the problem. Unfortunately, the specification is deadlock-free but it is not fair. We shall use DP (n) to denote the instance of the DP problem with n philosophers and i+ to denote (i + 1)mod n.
Example 4.2 (Dinning Philosophers) Let n ≥ 2 be the number of philosophers (and forks) in the problem and deﬁne Forki with i ∈ [0, n) as follows:



Forki(l, r) , τ \τ (?l =0 ∧ r = 0).Forki⟨N, N⟩
+ τ \upL (?l > 0).τ \dw .Forki⟨l-1, r⟩  +	upRi \τ (?r > 0).dwi \τ .Forki⟨l, r-1⟩

In this speciﬁcation, N is a global parameter/constant of the model indicating how many times we allow a philosopher to consecutively use the forks. The param- eter l of the deﬁnition is the maximum number of times the philosopher on the left can use the i-th fork. Similarly, for the parameter r. Every time the i-th fork is used by the philosopher on its left (resp. right), the parameter l (resp. r) is decremented (using ÷) by 1. The process Forki(l, r) can reset its parameters to the initial val- ues only when both l and r are equal to zero. The values of the parameters are checked by the constraints associated to the preﬁx τ \upL (resp. upRi \τ ) that allow the philosopher on the left (resp. right) to grab the fork.
The speciﬁcation of the philosophers is as follows:


Phili() , τ \tk .Phili⟨⟩ + upLi \upR
.τ \eat .dwi \dw
.Phili⟨⟩

i	+	i	+
n	n
Hence, the process Phili⟨⟩ can either think or establish a 3-party synchronization with the forks on his right and on his left. In that case, he can eat to later release both forks in another 3-party synchronization. In fact, the release of the forks can be done independently and there is no need for a multiparty synchronization.
The whole system restricts all the channel names but eati which is a visible action:
DP = (ν u˜pLi, u˜pRi, d˜wi)(Phil0| ... |Philn−1|Fork0(N, N )| ... |Forkn−1(N, N ))
Here u˜pLi, u˜pRi, d˜wi stand for the sets of channel names used in Phili and
Forki with i ∈ [0, n-1).	2
The transition system generated by the process DP (that can be computed with our tool, see Section 5) is indeed deadlock free. Moreover, once Pi has used the forks N times, he has to wait until his neighbors eat also N times to be able to eat again. This means that Pi cannot take control of the forks forever and, at some point, he has to wait for the others. In other words, there are no computations where, e.g., Pi eats infinitely many times and Pj can never grab the forks.
In this model, however, we cannot prove that Pi can

tk0
tk0
eat infinitely many times. The problem is the thinking action: there is an infinite computation where, e.g., P0 is always thinking and nobody is eating. Such computation corresponds to the loop on state S1 in the abstract version of the transition system in the figure on the left. In this loop, the action gbi, representing Pi grabbing the forks,

is always enabled. This situation can be interpreted as “Pi has the potential of grabbing the forks but the scheduler never gives him the chance to do it”.
The fair system can be obtained by controlling also the thinking action. Similar to the solution in [12], we can enforce that philosophers must eat after thinking, thus alternating between thinking and eating states. This is the purpose of moving to the state Philj after exhibiting the think action in the model below.
Example 4.3 (Fair alternating system) Consider the processes deﬁnitions Fork and DP in Example 4.2 where the deﬁnition of Phili is modiﬁed as follows:

Phili() , τ \tk .Phil’i⟨⟩ + upLi \upR
.τ \eat .dwi \dw
.Phili⟨⟩

i	+	i	+
n	n

Philj() , upLi \upR
.τ \eat .dwi \dw
.Phili⟨⟩

i	+	i	+
n	n
For illustration, consider a possible transition where the philosopher n-1 takes
both forks to later eat and release the forks:

(ν n˜)τ \upLn-1 \upR0 \τ (?1>0 ∧ ?1>0)	τ \
(ν n˜) τ \dwn-1 \dw0 \τ

DP	upLn-1 upR0
eatn-1
dwn-1 dw0

−−−−−−−−−−−−−−−−−−−−−−→ DP1 −−−−−→ DP2 −−−−−−−−−−−−→ DP3
where n˜	=	u˜pLi, u˜pRi, d˜wi; DP1 is as DP but Phil0 is replaced with
i	+	+
n	n
and, ﬁnally,
DP3 = (ν u˜pLi, u˜pRi, d˜wi)(Phil0| ... |Philn−1|Fork0(N-1,N )| ... |Forki(N, N )| ... |Forkn-1(N, N-1)) .
Note the new state of the forks 0 and n-1, namely, Fork0(N-1,N ) and Forkn-1(N, N-1).	2
We can show that the process DP in the above example produces an alternating execution between the philosophers. For concreteness, consider only two philoso- phers and let DPW be as DP (2) where we ignore the think actions, i.e., we consider only the process Philj() calling to itself, instead of calling the process Phili⟨⟩. We can define the following specification:

def
Spec() =
\eat0 .
\eat1 .Spec⟨⟩  +
\eat1 .
\eat0 .Spec⟨⟩

stating that philosophers must alternate when N = 1. We can then prove the equivalence DW ∼ Spec⟨⟩.
Let us now show that fairness holds even considering the thinking action. Without loss of generality, let N = 1. For readability, let us give a more ab- stract representation of the state of the forks as a ring of tuples of the form Sn = ⟨a0, a1⟩⟨a1, a2⟩⟨a2, a3⟩ ... ⟨an−1, a0⟩ where ai ∈ {0, 1, ?}. Such ring is subject to the following transition rules:
Grab: ... ⟨x, 1⟩⟨1, y⟩··· ⇒ ... ⟨x, ?⟩⟨?, y⟩ ... 
Grab-0: ⟨1, x⟩ ... ⟨y, 1⟩⇒ ⟨?, x⟩ ... ⟨y, ?⟩
Grab-0-end: ⟨?, x⟩ ... ⟨y, ?⟩⇒ ⟨0, x⟩ ... ⟨y, 0⟩
Grab-end: ... ⟨x, ?⟩⟨?, y⟩··· ⇒ ... ⟨x, 0⟩⟨0, y⟩ ... 
Reset: ... ⟨0, 0⟩··· ⇒ ... ⟨1, 1⟩ ... .
The state of the fork i is represented by the i-th tuple ⟨l, r⟩ where l=1 (resp. l=0)

means that the left philosopher may (resp. cannot) take this fork and l =? is the intermediate state where the philosopher is eating to later release the forks (thus abstracting the steps DP1 and DP2 in Example 4.3). The transition Grab (and Grab-0 for Phil0) abstracts the operational step from DP to DP1 and Grab-end (and Grab-0-end for Phil0) the transition from DP1 to DP3. Moreover, due to the definition of Fork in Example 4.2, from the state ⟨0, 0⟩ the only possible transition for the fork is to reset its parameters leading to the state ⟨1, 1⟩.
Next lemma proves that, for all philosopher Pi, always is the case that Pi will eventually eat. More precisely,
Lemma 4.1 (fairness) Let n ≥ 2, N ≥ 1 and DP(n) be the n-dining philosopher system formalized in Example 4.3. Then, O(DP) /= ∅ and, for all σ ∈ O(DP):
Deadlock-freeness: σ is an inﬁnite sequence ;
Fairness: for all i ∈ [0, n), the label τ \eati appears inﬁnitely often in σ.
Proof. Let us give a sketch of the proof (more details in the appendix and an automatic proof for a specific instance of n in the next section). For deadlock- freeness, consider the state Sn = ⟨a0, a1⟩⟨a1, a2⟩⟨a2, a3⟩ ... ⟨an−1, a0⟩ where ai ∈
{0, 1, ?}. If there is an ai s.t. ai ∈ {1, ?}, then, it is always possible to apply the rules Grab or Grab-end to make a transition. Otherwise (i.e., if ai = 0 for all i ∈ 0..n−1) then, it is always possible to apply the Reset rule. The proof of fairness follows by contradiction. Let σ be a computation of DP(n) such that 0 < m ≤ n philosophers will never perform the eating action. This means that in σ, the state includes tuples of the form ··· ⟨i, 1⟩⟨1, j⟩··· where the 1’s remain the same (i.e., these values never become 0 due to an application of Grab). We can show that σ must be finite and, indeed, there will be a maximum number of transitions before getting a deadlock (thus a contradiction since σ must be infinite).	2
A direct consequence of Lemma 4.1 is given by the following corollary.
Corollary 4.1 (Starvation freedom) Let n ≥ 2, N ≥ 1 and DP(n) be a n-dining philosopher system formalized as in Example 4.3. In every (inﬁnite) computation, the Grab-end transition (the action after eating) occurs inﬁnitely often for each adjacent tuple.
Note that in Example 4.3 we can specify different constants Ni for the parameters of the process Forki⟨li, ri⟩, with the restriction that ri = li+ , i.e. the number of times that two consecutive forks are used by their common adjacent philosopher must be the same. This is useful when we are modeling systems in which there are different priorities for the use of the resources. Also in situations where the
network of agents is not completely balanced (since some of them may work faster than others).
In the next example, we show that values and constraints can be useful to specify, declaratively, the internal state of processes. For that, we consider the case where philosophers may decide to remain thinking for a while and then, they decide to eat. In this scenario, it is important for the system that philosophers moving to the thinking state do not block the activities of the others. We thus assume

that philosophers take the decision (of thinking or eating again) and such decision must be communicated to the two adjacent forks. In turn, the forks may perform synchronizations with philosophers that have already consumed all their N usages whenever the adjacent philosopher is in the thinking state.
Example 4.4 (Constraints as states) Consider the following speciﬁcation for the philosophers:

Phili()	def idlLi
\idlR
+ .Phil-Idlei⟨⟩ +
in
upLi
\upR
+ .Phil-Eati⟨⟩
in

Phil-Eat() def τ \eat .dwi \dw
.Phili⟨⟩

=	i
def tau
+
n
wLi

upLi

Phil-Idlei() =
\tki .Phil-Idlei⟨⟩ +
\wRi .
\upR + .Phil-Eati⟨⟩
in

In Phili we see two new sets of names and links: idlLi and idlRi (resp. wLi
and wRi) are used to synchronize with both forks and communicate the fact that the philosopher goes to the thinking state (resp. starts eating again). The model for the forks is as follows:

Forki(l, r, idll, idlr)
def idlRi
\τ .Forki⟨l, r, idll, 1⟩ +
\idlLi .Forki⟨l, r, 1, idlr⟩+

wRi \τ .Forki⟨l, r, idll, 0⟩ + τ \wLi .Forki⟨l, r, 0, idlr⟩+
τ \upLi (?l =0 ∧ idlr = 1).τ \dwi .Forki⟨l, r, idll, idlr⟩+ upRi \τ (?r =0 ∧ idll = 1).dwi \τ .Forki⟨l, r, idll, idlr⟩+ the 3 choices in Example 4.2
The process DP(n) is deﬁned as usual, adding the new names in the set of
restricted names.
In Forki, besides l and r, we also have parameters to determine the current state of the left and right philosophers. The first line in the definition allows for communicating the decision of going to the thinking/idle state (for the right and left philosopher). Similarly, the second line is used to communicate the intention of start eating again. Most importantly, the third line allows for a synchronization with the left philosopher even if l = 0. In that case, the right philosopher must be in the idle state. Similarly for the forth line. In this system we cannot prove fairness as in Lemma 4.1 (since there are unfair always-thinking computations). We can assume (externally) a fairness condition ruling out such computations or specify a more controlled version of Phil-Idlei that, for instance, “counts” and controls the number of thinking actions.
Before closing this section, let us note that all the solutions presented here satisfy the usual requirements for this problem: fully distribution (there is no central agent coordinating the activities of the philosophers) and symmetry (all philosophers and forks are identical). The control of the agents defined here rely completely on their internal state and all of them are symmetrically defined as Phili and Forki. If we dispense with symmetry, there is a simple solution for the problem in CCS where P0 grabs first the fork on his left (F0) and P1 grabs first the fork on his right (again, F0). Hence, there is no a deadlock in this asymmetric specification as the one described

in the beginning of this section. As pointed out in [12], the solution for the problem in Multi-CCS (as well as ours in CCNA) is fully distributed in an abstract level: there is no a central shared memory. However, it is not possible to have a truly distributed deterministic implementation of this kind of multiparty synchronization mechanisms [15].


The network transportation system
The following example is a simplified version of the network transportation system presented in [7] where each transportation system has a specific cost. Passengers may specify a threshold for the value they are willing to pay for a trip starting and ending at the required stations. For simplicity, we are not considering the model of the stations. Here we model a complete trip of the passenger as a single transition that also records all the data concerning the trip (i.e. the sum of the costs of the used means of transport).
Example 4.5 (Network Transportation System) Consider the following def- initions:


P = τ \s | s3 \τ (?a ≤ 5)	MoT (s1, s2, c) , s1\s2⟨!c⟩.MoT M 1= MoT (s1, s2, 3)	M 2= MoT (s2, s3, 2)
T 1= MoT (s1, s3, 7)
System = (νs)(P | M 1 | M 2 | T )

Here, P is willing to go from s1 to s3. She offers its links for free but she constraints synchronizations to have cost at most 5. On the other side, M 1 does not impose any constraint but it forces the ﬁnal agreement to have cost at least 3. In this system, there is only one possible transition, namely,

(νs) τ \s1 \s2\s3\τ ⟨!5⟩(?5≤5)

System
s1 s2 s3
(νs)(M 1 | M 2 | T )


where P has to synchronize with both M 1 and M 2 (and pay 5). Note that P cannot take the train T since the chain τ \s1\s3\τ ⟨!7⟩(?7 ≤ 5) is not valid (Def. 3.10).
s1 s3
We can model the situation in which the passengers have two kinds of constraints: cost and time. In this case, values are tuples (Notation 3.9) of the form ⟨cost, time⟩. Each means of transport offers services at a given cost and speed and passengers may pose constraints on those values. Furthermore, adding a third element to the tuple, we can also restrict the number of connections a passenger is willing to accept (see Example 3.8).

Service Level Agreements (SLA)
We propose an extended model for the Service Level Agreements (SLA) protocol specified in [9]. In this kind of protocols, before the effective provisioning of a service, the involved parties should agree on a set of parameters, such as the cost the client should pay or the service quality the provider is willing to offer.
Example 4.6 (SLA Protocol) Here we consider a client C asking a web hosting provider P the use of a service. P, in turn, can offer the service once it receives the availability of the bandwidth from a third party T . Hence we shall consider tuples of the form ⟨cost, bw⟩ (see Notation 3.9). The client is modeled as
C , τ \s(?cost < MaxC ∧ bw > MinB).C
where MaxC (maximal cost) and MinB (minimal bandwidth) are constants for the model. We may have several T js offering different options for the provider, for instance:

T1 , th\τ ⟨!25, 100⟩.T1	T2 , th\τ ⟨!17, 70⟩.T2 + th\τ ⟨!32, 130⟩.T2 .

Here, T1 has only one option of service (at cost 25) while T2 offers two possibil- ities of bandwidth (70 and 130) at different costs. The provider P charges an extra fee depending on the bandwidth availability that he has received from T :
P , s\th⟨!2, 0⟩(?cost < 60).P	+ s\th⟨!3, 0⟩(?60 ≤ cost < 100).P	+ s\th⟨!5, 0⟩(?cost ≥ 100).P
The system is SLA , (ν s, th)(P | C | T1 | T2) and a possible transition is

(ν s,th) τ \s\th\τ ⟨!20⟩(?c)
SLA −−−−−−−−−−−−−−−→ SLA
where c = 20 < MaxC ∧ 70 > MinB ∧ 60 ≤ 70 < 100. What we are observing is a synchronization between P, C and the ﬁrst option of T2 (and thus, the ﬁnal cost is 20).	2
5	Concluding Remarks
On top of the tool described in [8], we have implemented a rewriting logic [16] specification of the semantics proposed here in the Maude System. The tool is available at https://gitlab.com/carlos_olarte/SiLVer. We built a suitable signature for the syntax of CCNA processes and specified the operational rules as rewriting rules. We profit from the symbolic techniques proposed in [8] to efficiently check when two or more links can be combined into a valid link chain. Using this tool, we can check for instance that for a particular instance of n, all the systems DP (n) discussed in Section 4.1 are deadlock free. For that, it is just a matter to ask whether there is a reachable state without transition (i.e., a normal form, “⇒ !”): search [1] DP(2) ⇒ ! S:State .. The answer is No solution. telling us that such state does not exist, thus proving deadlock freeness for DP (2). More interestingly, we can

verify the fairness condition in Lemma 4.1. For that, we use the model checker in Maude and ask if the property 2 {τ \eat0 } is valid. Here 2 and  are the linear time temporal logic (LTL) modalities “always” and “eventually”. The answer is true for the system in Example 4.3 and false (with a suitable counterexample) for the other models. We can also verify safety for all the systems. For that, we can ask if there is a state reachable from DP (2) where both τ \eat0 and τ \eat1 are enabled. The answer is No solution.. The tool also offers facilities to traverse the transition system, generate traces and produce a DOT file (graph description language) with the resulting transition system.
We are currently working on an extension of the Symbolic Link Modal Logic pro- posed in [8] to offer mechanisms to specify properties involving constraints. This should allow us to state properties such as “the process P cannot exhibit a n-party synchronization with n > N ” or “the server will never admit more connections that its bandwidth-limit allows”. Coupling this logic with the already implemented in- frastructure for model checking in Maude will provide more (automatic) verification techniques to reason about CCNA specifications. It would be also interesting to ex- plore a wider range of behavioral equivalences including weak-network-bisimulation and also stronger versions of network-bisimulations (where, e.g, DD-related link chains are not identified). Efficient decision procedures for those equivalences have not been explored yet.
In the examples presented here, for the sake of uniformity, we have used only one CLM (KN). There are many choices for it (see e.g., [11,3]). For instance, consider the structures KP = ⟨[0, 1], ≤, ×⟩ and KF = ⟨[0, 1], ≤, min⟩. In the first one, the subscript “P ” is for probability and agents accumulate values in the real interval [0, 1] by multiplying them. Hence, the accumulated value gets closer to 0 when more agents are involved in an interaction. In the second structure the “F ” stands for fuzzy, where values are accumulated by choosing the minimal value. In this case, agents can define a threshold for interaction based on their preferences expressed as values in the interval [0, 1]. As pointed out in Lemma 3.3, it is possible to combine such structures to obtain richer ones. Some examples using those structures are in the tool’s web page.
Multiparty calculi with different synchronization mechanisms have been pro- posed, e.g., in CSP [13] and full Lotos [22]. These calculi offer parallel operators that exhibit a set of action names (or channel names), and all the parallel processes offering that action (or an action along that channel) can synchronize by executing it. In [20], a binary form of input allows for a three-way communication. The reader may also refer to [14] where it is shown that CCSn (or n-join CCS), an extension of CCS that allows prefixes to synchronize with at most n outputs, is strictly more expressive than CCSn−1. The multiparty calculus most related to CNA is in [19], where links are named and are distinct from the usual input/output actions: there is one sender and one receiver (the output includes the final receiver name). Finally, we mention the cc-π calculus [9] that combines the name-passing discipline of the π-calculus with constraints in the style of concurrent constraint programming (see a survey in [21]). This calculus does not offer multiparty synchronization and its

semantics is necessarily more involved due to the name-passing discipline of the π-calculus. As showed here, constraints in CCNA allows for a declarative control of processes in a very natural way.

References
Abadi, M. and A. D. Gordon, A calculus for cryptographic protocols: The spi calculus, Inf. Comput.
148 (1999), pp. 1–70.
URL https://doi.org/10.1006/inco.1998.2740

Bistarelli, S. and F. Gadducci, Enhancing constraints manipulation in semiring-based formalisms, in: G. Brewka, S. Coradeschi, A. Perini and P. Traverso, editors, ECAI 2006, Frontiers in Artificial Intelligence and Applications 141 (2006), pp. 63–67.
URL http://www.booksonline.iospress.nl/Content/View.aspx?piid=1647

Bistarelli, S., U. Montanari and F. Rossi, Semiring-based contstraint logic programming: syntax and semantics, ACM Trans. Program. Lang. Syst. 23 (2001), pp. 1–29.
URL https://doi.org/10.1145/383721.383725

Bodei, C., L. Brodo and R. Bruni, Open multiparty interaction, in: N. Mart´ı-Oliet and M. Palomino, editors, WADT 2012, Revised Selected Papers, Lecture Notes in Computer Science 7841 (2012), pp. 1–23.
URL  http://dx.doi.org/10.1007/978-3-642-37635-1_1

Bodei, C., L. Brodo and R. Bruni, A formal approach to open multiparty interactions, Theor. Comput. Sci. 763 (2019), pp. 38–65.
URL https://doi.org/10.1016/j.tcs.2019.01.033

Bodei, C., L. Brodo, R. Bruni and D. Chiarugi, A flat process calculus for nested membrane interactions, Sci. Ann. Comp. Sci. 24 (2014), pp. 91–136.
URL http://dx.doi.org/10.7561/SACS.2014.1.91
Brodo, L. and C. Olarte, Symbolic semantics for multiparty interactions in the link-calculus, in:
B. Steffen, C. Baier, M. van den Brand, J. Eder, M. Hinchey and T. Margaria, editors, SOFSEM 2017, LNCS 10139 (2017), pp. 62–75.
URL  https://doi.org/10.1007/978-3-319-51963-0_6
Brodo, L. and C. Olarte, Verification techniques for a network algebra, Fundam. Inform. 172 (2020),
pp. 1–38.
URL  https://doi.org/10.3233/FI-2020-1890

Buscemi, M. G. and U. Montanari, Cc-pi: A constraint-based language for specifying service level agreements, in: R. De Nicola, editor, ESOP 2007, LNCS 4421 (2007), pp. 18–32.
URL  https://doi.org/10.1007/978-3-540-71316-6_3
Cardelli, L., Brane calculi, in: V. Danos and V. Scha¨chter, editors, CMSB 2004, LNCS 3082 (2004),
pp. 257–278.
URL  https://doi.org/10.1007/978-3-540-25974-9_24

Gadducci, F., F. Santini, L. F. Pino and F. D. Valencia, Observational and behavioural equivalences for soft concurrent constraint programming, J. Log. Algebr. Meth. Program. 92 (2017), pp. 45–63.
URL https://doi.org/10.1016/j.jlamp.2017.06.001

Gorrieri, R. and C. Versari, “Introduction to Concurrency Theory - Transition Systems and CCS,” Texts in Theoretical Computer Science. An EATCS Series, Springer, 2015.
URL  https://doi.org/10.1007/978-3-319-21491-7

Hoare, C. A. R., “Communications Sequential Processes,” Prentice-Hall, Englewood Cliffs (NJ), USA, 1985.
Laneve, C. and A. Vitale, The expressive power of synchronizations, in: LICS 2010 (2010), pp. 382–391.
URL https://doi.org/10.1109/LICS.2010.15

Lehmann, D. J. and M. O. Rabin, On the advantages of free choice: A symmetric and fully distributed solution to the dining philosophers problem, in: J. White, R. J. Lipton and P. C. Goldberg, editors, POPL (1981), pp. 133–138.
URL http://doi.acm.org/10.1145/567532.567547

Meseguer, J., Twenty years of rewriting logic, J. Log. Algebr. Program. 81 (2012), pp. 721–781. URL https://doi.org/10.1016/j.jlap.2012.06.003


Milner, R., “Communication and Concurrency,” International Series in Computer Science, Prentice Hall, 1989, sU Fisher Research 511/24.
Milner, R., J. Parrow and D. Walker, A calculus of mobile processes, I and II, Inf. Comput. 100 (1992),
pp. 1–40.
URL  https://doi.org/10.1016/0890-5401(92)90008-4

Montanari, U. and M. Sammartino, Network conscious pi-calculus: a concurrent semantics, in: MFPS 2012, Electronic Notes in Theoretical Computer Science 286 (2012), pp. 291–306.
Nestmann, U., On the expressive power of joint input, Electronic Notes in Theoretical Computer Science
16(2) (1998).
Olarte, C., C. Rueda and F. D. Valencia, Models and emerging trends of concurrent constraint programming, Constraints An Int. J. 18 (2013), pp. 535–578.
URL  https://doi.org/10.1007/s10601-013-9145-3

Peter H. J. van Eijk, M. D., Chris A. Vissers, “The Formal Description Technique LOTOS,” North- Holland, 1989.
Sangiorgi, D., “Introduction to Bisimulation and Coinduction,” Cambridge University Press, 2011.
van Glabbeek, R. and P. H¨ofner, Progress, justness, and fairness, ACM Comput. Surv. 52 (2019),
pp. 69:1–69:38.
URL https://doi.org/10.1145/3329125


Appendix
Congruence (Theorem 3.16)
In this section we prove that P ∼ Q implies that, for any context C[·], C[P ] ∼ C[Q]. Recall that the (co-inductive) technique for showing that two processes are (network) bisimilar consists in exhibiting a network bisimulation R containing the two processes (see, e.g., [23]). Since P ∼ Q, we know that there exists a network bisimulation R containing the pair (P, Q). For each context C[·], we show a suitable Rj s.t. (C[P ], C[Q]) ∈ Rj.
Case μ.[·]. The needed relation is Rj = {(μ.P, μ.Q) | μ ∈ V CC}∪ R. Clearly, μ.P can only perform μ and proceed as P . Similarly for μ.Q. Since (P, Q) ∈ R, Rj is indeed a network bisimulation.
Case [·]+ R. Note that P and Q must be sequential processes. Let Rj = R∪ 
{(P + R, Q + R) | R ∈ P} ∪ I where I is the identity relation on P (P is the set of CCNA processes). There are two possible transitions for P + R. (1) If

P + R	j
μ	j	j

and μjDDμ s.t. Q	μ′	Qj. We conclude by noticing that Q + R	μ′	Qj and
(P j, Qj) ∈ Rj. (2) If R moves, we observe P + R	μ	Rj. Then, Q + R	μ	Rj
and clearly (Rj, Rj) ∈ Rj. The case R + [·] follows similarly.
Case [·]|R. The needed network bisimulation is Rj = {(P|R, Q|R) | (P, Q) ∈ R and R ∈ P}. The process P|R exhibits 3 kind of transitions. P|R moves to

Pj|R with label μ using the rule Lpar. Hence, P	μ
Pj and there exists Qj

and μjDDμ s.t. Q	μ′
Qj and (P j, Qj) ∈ R. By using Lpar, Q|R	μ′
Qj|R and

clearly (P j|R, Qj|R) ∈ Rj as needed. The case when R moves (using Rpar) is

μ
trivial. If P and R synchronizes (using Com), it must be the case that P  −→
Pj,

R −→ Rj
and the label of the transition is μ • ψ. We also know that there exists

Qj and ξDDμ s.t. Q	ξ
Qj and (P j, Qj) ∈ R. We can suitable enlarge (via ►(

ξ•ψ
and	) the link chains in ψ and ξ to make ψ • ξ valid and Q|R −→
Qj|Rj as

needed. The case R|[·] is similar.
Case (νa)[·]. The needed relation is Rj = {((νa)P, (νa)Q) | (P, Q) ∈ R and a ∈

(νa)μ
V CC}. If (νa)P	−→
(νa)Pj it must be the case that P	μ
Pj. Hence there

exists Qj and μjDDμ s.t. Q	μ′
Qj and (P j, Qj) ∈ R. We conclude by noticing

that (νa)Q
(νa)μ′
−→ (νa)Q
(for that, we can easily show that if (νa)μ is valid, then

(νa)μj is also valid for μjDDμ. ) and hence, ((νa)Pj, (νa)Qj) ∈ Rj as needed.  2

Proof of fairness (Lemma 4.1)
For the sake of readability, we shall change marginally the notation of the reachable states (processes) from DP (n). Note that the set of labels (ignoring the constraint

tt) of the transition system generate from DP is L = {τ \eat , τ \tk
| i ∈ [0, n)}∪ 

{ τ \τ \τ \τ }∪ { τ \τ }. The first component corresponds to the (visible) eating and
τ τ
thinking actions; the second component to the 3-party interaction for grabbing and
releasing the forks (see transitions in Example 4.3); and τ \τ to the reset action (first line in the definition of Fork in Example 4.2). Let us use eati, tki, grabi, releasei and reseti to denote such actions. For conciseness, we fix N = 1.
The process Forki(l, r) and its sucessor states will be represented as the tuple
⟨l, r⟩. For that, note that a fork can be in one of the following states (see Example 4.2):
Forki(1, r) (resp. Forki(l, 1)) where it can synchronize with the philosopher on the right (resp. on the left). We shall write these states, respectively, as ⟨1, r⟩ and ⟨l, 1⟩.
τ \dw .Forki⟨0, r⟩ and dwi \τ .Forki⟨l, 0⟩. The first (resp. second) is the result after a synchronization with the philosopher on the left (resp. right). Let us denote those states as the tuples ⟨?, r⟩ and ⟨l, ?⟩.
Forki(0, 0) (notation ⟨0, 0⟩) where the only possible transition is a reset action leading to ⟨1, 1⟩.
We can also simplify the notation to represent the philosophers. For that, note that they can be in one of the following states (see processes and transitions in Example 4.3):
Phili, where he can grab the forks or think. We shall use GTi to denote that state.
After thinking, the resulting process is Philj whose only possible action is to grab the forks. We shall denote that state as Gi.

After grabbing the forks, the new state is τ \eat .dwi \dw
.Phili⟨⟩ where the only

i	+
n
possible action is to eat. We shall use Ei to denote that state.

After exhibiting the eati action, the new state is dwi \dw
n
.Phil, from now on

denoted as Ri.
After releasing the forks, we are back in the state GTi.
Hence, any resulting process from DP (n) can be succinctly represented as
P0 ··· Pi ··· Pn−1 ⟨l0, r1⟩⟨l1, r2⟩⟨l2, r3⟩··· ⟨ln−1, r0⟩ where each Pi is either GTi, Gi, Ei, or Ri.
Some valid transitions of this system are:

P
··· GT
··· P
⟨l ,r ⟩··· ⟨l
,r ⟩⟨l ,r 
⟩··· ⟨l
,r ⟩
−tk→i

0	i	n−1	0  1
i−1 i
i i+1
n−1  0

P0 ··· Gi ··· Pn−1 ··· (Phil i thinks)

··· Gi
·	⟨l

i−1
, 1⟩⟨1, ri+1⟩··· 
grabi
−→ · · · Ei
·	⟨l

i−1
, ?⟩⟨?, ri+1
⟩··· (grab-

bing the forks)

··· Ei
ing)
·	⟨l

i−1
, ?⟩⟨?, ri+1
⟩··· 
−ea→ti
· · · Ri
··· · ·· ⟨l

i−1
, ?⟩⟨?, ri+1
⟩··· (eat-

··· Ri
·	⟨li−1
, ?⟩⟨?, ri+1
⟩··· releasei
· · · GTi
·	⟨li−1
, 0⟩⟨0, ri+1
⟩··· (re-

lease the forks).
··· ··· ⟨0, 0⟩··· r−es→eti

··· · ·· ⟨1, 1⟩··· (reset the fork i)

After the transition (iv), the only available action for the i-th philosopher is to think (only once). In this state, he can only grab the forks again once his neigh- bors eat and the forks perform the reset action. More precisely, the configuration
... ⟨1, 0⟩⟨0, 1⟩ ... means that the philosopher in the middle has eaten and, after thinking, he remains blocked until his neighbors eat and release the forks.

Proof. Lemma 4.1. We prove the two points (deadlock-freeness and fairness) separately.
Consider the state Sn = P0 ··· Pn−1 ⟨a0, a1⟩⟨a1, a2⟩⟨a2, a3⟩ ... ⟨an-1, a0⟩ where ai ∈ {0, 1, ?}. If there is an ai s.t. ai ∈ {1, ?}, then, it is always possible to exhibit a grab (ai = 1), eat or release (ai =?) transition. Otherwise (i.e., if ai =0 for all i ∈ 0..n-1) then, it is always possible to exhibit a reset transition.
The proof is by contradiction. Let DP (n) be a n-dining philosopher system such that there exists i ∈ [0, n) and Phili that performs eati finitely often. Without loss of generality (due to the circularity of the configuration) assume that i = 0. Consider the suffix of the computation σ where Phil0 has already performed all the eating actions, i.e., in the rest of the (infinite) computation, we do not observe eat0. Hence, this philosopher is either in the state GT0 and, after thinking, in state G0. We shall show that this computation cannot be infinite (thus a contradiction).
Once the neighbor Phil1 eats and releases the forks, we are in the following situation DPj = G0 GT1 ··· ⟨a0, 0⟩⟨0, a2⟩ ... .
In this state, Phil1 cannot eat again (he can only think).	If Phil2
eats,  a2 becomes 0 and a reset on Fork1 is possible:	DPj	−→∗

G0 GT1 ··· ⟨a0, 0⟩⟨0, 0⟩ ... −→∗ re−s→et1
G0 GT1 ··· ⟨a0, 0⟩⟨1, 1⟩ ... 

If a0 = 1, Fork0 cannot reset until Phil0 eats (which is not possible by hypothesis). This reasoning goes on for all the n − 1 philosophers that are willing to eat. Once all of them have eaten, and all the forks that could have reset have already performed that action, the configuration is:
DPjj = G0 ··· Gn—1⟨1, 0⟩⟨1, 0⟩ ... ⟨1, 0⟩⟨0, 1⟩⟨0, 1⟩ ... ⟨0, 1⟩⟨0, 1⟩
Hence, if Phil0 does not eat, at some point, all the philosophers will be blocked. In fact, counting only the eating and reset actions, the system can

perform at most
n-1
i =
i=1
n×(n—1) transitions:


⟨1, 1⟩⟨1, 1⟩⟨1, 1⟩ ... ⟨1, 1⟩⟨1, 1⟩⟨1, 1⟩	at most n-1 eat actions if
Phil0 does not eat
⟨1, 0⟩⟨0, 0⟩⟨0, 0⟩ ... ⟨0, 0⟩⟨0, 0⟩⟨0, 1⟩	at most n-2 reset actions
⟨1, 0⟩⟨1, 1⟩⟨1, 1⟩ ... ⟨1, 1⟩⟨1, 1⟩⟨0, 1⟩	at most n-3 eat actions
⟨1, 0⟩⟨1, 0⟩⟨0, 0⟩ ... ⟨0, 0⟩⟨0, 1⟩⟨0, 1⟩	at most n-4 reset actions
... 
⟨1, 0⟩⟨1, 0⟩ ... ⟨1, 0⟩⟨0, 1⟩⟨0, 1⟩ ... ⟨0, 1⟩⟨0, 1⟩ no transition if Phil0 does not eat
If Phil0 does not eat, Fork0 and Forkn-1 cannot reset. Hence, from row 2 on, the state of these forks will be, respectively, ⟨1, 0⟩ and ⟨0, 1⟩. At this point, Fork1 and Forkn-2 are able to reset, and this justifies the configuration in row 3. At row 4, Phil1 and Philn-2 cannot eat since the needed forks are not available and they cannot reset. Hence, assuming that Phil0 does not eat breaks the possibility of restarting all the forks and a deadlock is reached.
2
