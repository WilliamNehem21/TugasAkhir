

Electronic Notes in Theoretical Computer Science 229 (5) (2011) 75–95
www.elsevier.com/locate/entcs

Modularity and Implementation of Mathematical Operational Semantics
Mauro Jaskelioff1
Facultad de Ciencias Exactas, Ingenier´ıa y Agrimensura, Universidad Nacional de Rosario, Av. Pellegrini 250, S2000BTP Rosario, Argentina
Neil Ghani2
Dept. of Computer and Information Sciences, University of Strathclyde, 26 Richmond St., Glasgow G1 1XH, United Kingdom
Graham Hutton3
School of Computer Science, University of Nottingham,
Jubilee Campus, Wollaton Road, Nottingham NG8 1BB, United Kingdom

Abstract
Structural operational semantics is a popular technique for specifying the meaning of programs by means of inductive clauses. One seeks syntactic restrictions on those clauses so that the resulting operational semantics is well-behaved. This approach is simple and concrete but it has some drawbacks. Turi pioneered a more abstract categorical treatment based upon the idea that operational semantics is essentially a distribution of syntax over behaviour. In this article we take Turi’s approach in two new directions. Firstly, we show how to write operational semantics as modular components and how to combine such components to specify complete languages. Secondly, we show how the categorical nature of Turi’s operational semantics makes it ideal for implementation in a functional programming language such as Haskell.
Keywords: Modularity, Category Theory, Operational Semantics, Haskell


Introduction
Operational semantics is one of the primary techniques for formally specifying the meaning of programs. Traditionally, one defines the operational semantics of a programming language as a relation over the syntax of programs. In structural operational semantics [19], this relation is defined by a set of inductive rules, and

1 Email: mauro@fceia.unr.edu.ar
2 Email: ng@cis.strath.ac.uk
3 Email: gmh@cs.nott.ac.uk

1571-0661 © 2011 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2011.02.017

one seeks syntactic restrictions on these rules so that the resulting operational se- mantics has certain desirable properties. However, despite the relative simplicity of this syntactic approach to operational semantics, it has a number of significant drawbacks:
Being syntactic, the restrictions on rules are often rather intricate, and it is not clear how they arise. This intricacy makes proving meta-theoretic results difficult, and makes it virtually impossible to see how these results are affected by changes to the language under consideration, or to the notion of observable behaviour of the semantics being defined. One gets the feeling that there is some deeper mathematical structure at play that is being obscured by the syntactic clutter.
Being syntactic, operational semantics presented in this form is language-specific. As a result, it is difficult to implement a generic notion of operational semantics in a high-level programming language such as Haskell. Compare, for example, with the use of logical frameworks to implement logics and type theories; such language-independent frameworks are clearly missing for operational semantics. One would like to be able to write data types whose inhabitants are operational semantics, and programs which manipulate such data types.
Being syntactic, it is not clear how to relate operational semantics to the more abstract and high-level denotational semantics. This is more than just a math- ematical irritation: by utilising concepts from category theory, denotational se- mantics has given us many language-independent mathematical tools to structure programs. These include, for example, monads, initial algebra semantics and Kan extensions. The fact that these tools are language independent suggests that they somehow get at the essence of computation. The same cannot currently be said of operational semantics, with its inherently language-dependent flavour.
Overall, we are left with the feeling that we need to get at the mathematical essence of operational semantics, to allow mathematical tools to be used to structure and reason about operational semantics in a high-level manner, and to make it easier to relate it to denotational semantics. Indeed, at this point, we can begin to wonder if we really need operational and denotational semantics. A categorical semantics encompassing both approaches may actually be what we are striving for.
But the development of such an approach has already begun! Ten years ago, Daniele Turi did something rather remarkable. He abstracted from the concrete, syntactic, language-dependent approach to operational semantics and proclaimed that operational semantics was a categorical construct, namely a distributive law between syntax and behaviour. In one fell swoop [24], Turi opened the way to tackling all of the above problems. By parameterising his treatment by a functor representing syntax and a functor representing semantics, he abstracted away from the specific details of particular languages and their meaning. Moreover, it became possible to relate the operational and denotational approaches; indeed, they become two sides of the same coin, as they define the same semantic function, one by the universal property of the final coalgebra, the other by the universal property of the initial algebra. That is, the semantic function J−): μΣ → νB from the syntax into

the behaviour, is induced by both an algebra over the final coalgebra νB and a coalgebra over the initial algebra μΣ. These are provably equal.
We further develop of Turi’s categorical approach to operational semantics by addressing the questions of modularity and implementation. More precisely, the article makes the following contributions:
We develop a modular operational semantics, by structuring Turi’s primitive con- cept of behaviour. We show how to write modular semantic components and how to construct languages built from these components. We stress that a general ap- proach to modularity in Turi’s mathematical operational semantics has not been considered before (but see the related work section at the end of the article.)
We implement our ideas in Haskell, which helps to bring Turi’s categorical work to the functional programming community in a more accessible way, makes the ideas directly executable, facilitates experimentation, and allows us to benefit from Haskell’s well-developed support for monadic programming. We stress that the question of how to implement Turi’s mathematical operational semantics has also not been considered. This is no trivial task as there a variety of implementation issues which must be addressed so that the resulting code retains the elegance and simplicity of the category theory which inspires it.
As with any work that involves implementing mathematics, it is important to be clear about the relationship between the mathematical theory and its concrete implementation. We use categorical tools as our main technical devices, and use Haskell to illustrate and make these categorical techniques more accessible to the programming languages community. For the purposes of this article, it suffices to work in the category Set of sets and total functions, but the reader should bear in mind that the mathematical theory generalises to other categories. For example, Haskell is not based on Set but on the category CPO, which has considerable extra structure which admits partial functions. Because we do not rely on the extra structure, and because we can use Haskell to reason about its total fragment [2], Haskell provides a convenient syntax for programming in Set. Some languages require the framework to be interpreted in CPO-like categories [12], in particular for dealing with general recursion, but for all the examples we consider, the structure of Set is enough.
The article is aimed at functional programmers with a basic knowledge of cat- egory theory and semantics, but we do not assume prior knowledge of Turi’s cate- gorical approach to semantics. The Haskell code from the article is available from the authors’ websites.

Structural Operational Semantics
Operational semantics gives meaning to terms in a language by defining a transition relation that captures execution steps in an abstract machine. Reasoning about this relation can be difficult. Therefore Plotkin proposed structural operational semantics (SOS), in which the transition relation is defined by structural recursion



Fig. 1: Structural operational semantics for P
Fig. 2: Structural operational semantics for Z
on syntax-directed rules [19]. One then uses the principle of structural induction to reason about the induced transition relation.
Example 2.1 Consider a simple process language P whose terms p ∈ P are speci- fied by the following grammar, which corresponds to Basic Process Algebra [1]:
p ::=  !a | p ; p | p H p
The informal meaning of the operators in the language is that !a prints the char- acter a on the screen, p ; q sequences the execution of p and q, and p H q non- deterministically chooses to execute either p or q.
We give an operational semantics for P by the set of structural rules in Figure 1. The rules recursively define relations →⊆ P × A × P and −→ C ⊆ P × A, on terms
P and set of characters A. We write p −→a  pj for (p, a, pj) ∈ → and p −→a  C for
(p, a) ∈ −→ C. Intuitively, the transition p −→a  pj represents a term p which can
evolve into term pj by printing the character a on the screen, whereas p −→a C holds for terms which can terminate successfully by printing character a.
Example 2.2 We define a simple language of arithmetic expressions, with integers, additions and a conditional expression, whose terms z ∈ Z are specified by the following grammar:
z  ::= Z | z + z | ifz z z z
The informal meaning of ifz c t e is that if c is 0 then t is evaluated, otherwise e is evaluated. We give an operational semantics for this language in Figure 2. The rules recursively define a relation ⇓ ⊆ Z × Z, where we write t ⇓ n for (t, n) ∈ ⇓. Intuitively, t ⇓ n means that term t can evaluate to integer n.
Note that the semantics were given in a small-step style for P and big-step style for Z. However, the mathematical approach to operational semantics that we use in this article treats these two different styles uniformly.
Example 2.3 Let us consider now a language E of exceptions:
e ::= throw | catch e e
The informal meaning is that throw throws an exception and catch t u evaluates
t and, if t throws an exception, recovers from it by evaluating u. Its operational



Fig. 3: Structural operational semantics for E
Fig. 4: Additional rules for combining P and E

Fig. 5: Additional rules for combining Z and E
semantics is given by the rules in Figure 3 and define a predicate ↑ ⊆ E, where we write e ↑ for e ∈ ↑. Intuitively, e ↑ means that e can throw an exception.
This language is not very useful by itself as the only possible outcome is to throw an exception. Its real utility is exhibited when one considers the language E together with some other language. For example, we will consider combining E with P and Z. However, to put the languages together we need to add extra rules explaining how catch deals with the transitions defined by the other languages and how the operators in other languages deal with exceptions. In Figures 4 and 5, we show all the rules that need to be added to combine E with P and Z.
More generally, combining operational semantics is not just a matter of the tedious and error-prone task of adding extra syntactic rules, but may also involve modifying the original rules, which makes it difficult to formally relate the original and combined languages. The underlying problem is that SOS lacks a language- independent theory that would clarify what combining languages means in general, rather than for specific rules.
Modular Syntax
The first step towards obtaining modular operational semantics is to obtain modular syntax, in the sense that terms of a language are constructed by combining smaller languages. It is straightforward to implement the grammar for P as a recursive datatype:
data P = Put A | Seq P P | Alt P P
type A = Char
However, datatype P is monolithic. In order to obtain modular syntax we need to

reveal the underlying structure, separating the operators of the language from the description of its terms. We use the standard categorical technique (for example, see [5]) of modelling terms by the free monad over a signature, and the combination of languages by the coproduct of free monads.
Terms as Free Monads
We will specify the syntax of a language by its signature, that is, the set of its oper- ators and their corresponding arities. Each signature has a corresponding instance of the Functor class (see Appendix B), which we call a signature functor.
Example 3.1 The signature functor for P is as follows:
data P a = Put A | Seq a a | Alt aa 
instance Functor P where
fmap  (Put c)	= Put c
fmap f (Seq p q)= Seq (f p) (f q )
fmap f (Alt p q) = Alt (f p) (f q )
Terms constructed with operators from the signature functor f and with vari- ables of type x are given by the free monad on f at x , represented by the datatype Term f x . The flexibility of having variables of an arbitrary type will be used later on to represent the meta-variables in operational rules.
data Term f x = Var x | Con (f (Term f x ))
That is, a term is either a variable or an operator from f applied to a term. It is now straightforward to make such terms into both Functors and Monads:
instance Functor f ⇒ Functor (Term f ) where
fmap f (Var x )	= Var (f x )
fmap f (Con t )	= Con (fmap (fmap f ) t )
instance Functor f ⇒ Monad (Term f ) where
return	= Var
(Var x ) >>= f   = f x
(Con t ) >>= f	= Con (fmap (>>=f ) t )
We will not use the fact that Term f is a monad in this article, but we mention it because it shows that terms structured in this way come equipped with a substitu- tion operator, as given by (>>=) :: Term f a → (a → Term f b) → Term f b [6,15]. With this representation of terms, the natural manner in which to process terms is using a generic fold operator [16,8]:
foldTerm :: Functor f ⇒ (a → b) → (f b → b) → Term f a → b
foldTerm var  (Var a)	= var a
foldTerm var con (Con fta)= con (fmap (foldTerm var con) fta)
Intuitively, the argument of type a → b is used to process variables, and the argu- ment of type f b → b (an f -algebra) is used to process operators.

Finally, the programs of a language are its closed terms. That is, programs are terms with variables taken from the empty datatype Zero, which comes equipped with a canonical map empty :: Zero → a into any other type a.
type Program f = Term f Zero
Thus, we have a generic notion of syntax equipped with well-behaved substitu- tion and a well-behaved recursion operator. Moreover, as shown in the next section, we obtain a simple and principled method for combining the syntax of languages.
Coproducts of Free Monads
We have shown that signatures define the operators of a language. In order to obtain modular syntax we will combine the signatures of small languages to obtain a signature for the complete language.
The natural way to combine two languages is to take the coproduct of the free monads modelling them. Since free constructions preserve coproducts, this is equivalent to the free monad on the coproduct of their signature functors.
data (f ⊕ g ) a   = Inl (f a) | Inr (g a)
instance (Functor f , Functor g ) ⇒ Functor (f ⊕ g ) where
fmap h (Inl fx ) = Inl (fmap h fx )
fmap h (Inr gx ) = Inr (fmap h gx )
copair	:: (f a → b) → (g a → b) → (f ⊕ g ) a → b
copair f  (Inl fa) = f fa
copair  g (Inr ga)= g ga
The function copair processes the coproduct of functors f and g , given that we provide two functions: one to process f and the other to process g . We can use copair to define an f ⊕ g -algebra from an f -algebra and a g -algebra. Therefore, foldTerm can be used to process f ⊕ g terms.
Example 3.2 We rewrite P as the coproduct of the signatures of its operators:
type P   = Put ⊕ Seq ⊕ Alt
data Put a = Put Char data Seq a = Seq aa data Alt a = Alt aa 
The P-term ( !a ; !b) H !c is written in Haskell as the program prog in Figure 6.
Example 3.3 In a similar manner, we rewrite the operators of Z and E as separate languages. Again, the syntax of the complete languages can be recovered by the coproduct of their operators.

data N a	= N Int data Add a = Add aa data Ifz a	 = Ifz aaa 
type Z = N ⊕ Add ⊕ Ifz
data Thr a = Thr
data Cat a = Cat aa 
type E = Thr ⊕ Cat



Fig. 6: The term ( !a ; !b) H !c, as a Program of signature P
Note that now we may define the syntax of new languages simply by choosing which constructs we would like to have. For example, we may define the syntax EP of P extended with exceptions, EZ of Z extended with exceptions, or a non- deterministic arithmetic language NDZ:
type EP	= Thr ⊕ Cat ⊕ Put ⊕ Seq ⊕ Alt type EZ	= Thr ⊕ Cat ⊕ N ⊕ Add ⊕ Ifz type NDZ = N ⊕ Add ⊕ Alt
Coproducts provide a structured, mathematical foundation for assembling syn- tax. There are, however, some practical concerns. As shown in Figure 6, we had to define auxiliary functions put , seq , and ·H· to make the definition of programs less cumbersome. These shorthands will only work for terms of signature P, and would need to be changed should the language be extended. For instance, if we were working with the language EP, then we would have to define a new auxiliary function putj as:
putj	:: Char → Term EP a
putj c = Con (Inr (Inr (Inl (Put c))))
Redefining these auxiliary functions every time we change our language is inher- ently non-modular. In the following subsection we show how to solve this problem.

Automatic Injections and Projections
Consider a function which produces terms of signature G. If G = Fi, this function can be easily extended to produce terms of signature Σ = F1 ⊕ ... ⊕ Fn by post- composing it with foldTerm Var (ini · Con), where ini is the corresponding injection into the coproduct. We would like this extension to work on terms of any signature containing G, but this is not the case here: G will not be at a fixed position i for every signature containing G. In general, we would like to be able to define functions on coproducts of datatypes for which only a limited part is known.
The solution to this problem [14,21] is to parameterise each function by injec- tion/projection pairs corresponding to each of the summands a function is interested in. We can avoid writing this parameterisation with the following type class:
class (Functor sub, Functor sup) ⇒ sub ‹→ sup where

inj :: sub a → sup a
prj :: sup a → Maybe (sub a)
We can think of sub ‹→ sup as meaning “sub is a subtype of sup”. The class method inj is used to inject a subtype sub into the supertype sup, and prj let us do a case analysis on a sup to determine if it is in fact a sub.
The following instances state the reflexivity of · ‹→ ·, and that if f = gi for some i, then f is a subtype of a coproduct g1 + (g2 + (... )) . Note that the sum should be associated to the right for the type-checker to be able to infer an instance, so we need to be careful when constructing coproducts.
instance (Functor f ) ⇒ f ‹→ f where
inj = id prj = Just
instance (Functor f , Functor g ) ⇒ f ‹→ f ⊕ g where
inj	= Inl
prj (Inl f ) = Just f
prj 	= Nothing
instance (Functor h, f ‹→ g ) ⇒ f ‹→ h ⊕ g where
inj	= Inr · inj prj (Inr a)= prj a
prj 	= Nothing
For convenience, we define an auxiliary function f ❽ g for processing supertypes, which applies a function g if we are in the case of a chosen subtype and a function f otherwise.
(❽)   :: (sub ‹→ sup) ⇒ (sup x → a) → (sub x → a) → sup x → a
(f ❽ g ) x = case prj x of
Nothing → f x
Just y	→ g y 
Finally, we will rewrite the auxiliary functions in Figure 6 so that they work with any signature which satisfies certain requirements expressed as type constraints. In Figure 7 we show the modular constructors for the operators in P , Z, and E.
With the use of coproducts and the functorial representation of signatures, we achieved our goal of obtaining and implementing a modular syntax.

Transition Relations as Coalgebras
As shown in Section 2, operational semantics are given by a transition relation which represents execution steps in an abstract machine. Transition relations can be modeled in a generic, categorical way by coalgebras [10]. Given an endofunctor B, a B-coalgebra is an object X and a structure map X → BX. The carrier of the coalgebra X can be seen as the states of an abstract machine while the endofunctor B represents the observable behaviour of the machine.



Fig. 7: Modular constructors for the operators of P , Z, and E
Every relation R ⊆ X × Y can be written as a function X → PY mapping every element in X to its set of related elements in Y . The simplest technique for interpreting the powerset functor in Haskell is to use the list functor. Thus, we interpret relations R ⊆ X × Y as Haskell functions X → [Y].
Example 4.1 The SOS rules for the language P defined two transition relations
→ ⊆ P × A × P and −→ C ⊆ P × A. Given our decision to interpret relations as Haskell functions, it is natural to write these as coalgebras with carrier Program P, and structure functions Program P → [(A, Program P)] and Program P → [A] respectively. In order to make the coalgebraic structure explicit, let us define func- torial composition, the functor Pr a, which pairs a character from A with a, and the constant A functor:
data (h ◦ g ) x = Comp{deComp :: (h (g x ))}
instance (Functor h, Functor g ) ⇒ Functor (h ◦ g ) where
fmap f (Comp c)= Comp (fmap (fmap f ) c)
data Pr a = Pr A a
data KA a = KA A
Using these definitions, we can express the transition relation −→ by a ([ ] ◦ Pr)-coalgebra on Term P and the transition relation −→ C by a ([ ] ◦ KA)- coalgebra on Term P. Furthermore, we can pack both transition relations into a ([ ] ◦ (Pr ⊕ KA))-coalgebra on Term P which captures all the observable behaviour of language P.

Example 4.2 Consider the language Z of Section 2. A simple inductive argument shows that the ⇓ relation is a function. Hence, we can describe the induced transition relation by a KI-coalgebra, where KI is the constant Int functor.
data KI a = KI Int
Example 4.3 The transition relation ↑ can be represented by a KE-coalgebra, where KE is the constant unit functor.
data KE a = KE
As shown in these last two examples, when the transition relation is a function, we can remove the powerset (or list). In this manner, the determinism of the underlying transition system is made explicit, avoiding the need for a separate proof. Being able to describe precisely what is observable by choosing the appropriate behaviour functor is an important advantage of the coalgebraic approach.

Execution of transition systems
In order to execute a transition system specified by a coalgebra, we unfold the coalgebra [10,9] to construct a tree of observations. The appropriate notion of tree is given by the greatest fixpoint 4 of the behaviour functor of the coalgebra.
codata Nu f = Nu (f (Nu f ))
unfold	:: Functor b ⇒ (x → b x ) → x → Nu b
unfold g = Nu · fmap (unfold g ) · g
In conclusion, coalgebras provide an abstract model of transition systems, where the type of the transition system and its corresponding notion of equality are deter- mined by a functor. However, as discussed in the next section, this is not sufficient to model structural operational semantics.

Mathematical Operational Semantics
Coalgebras provide an abstract model of transition systems. Unfortunately, they do not support a proper theory of SOS. In particular, the carrier of a coalgebra is unstructured, and hence a purely coalgebraic approach will not be able to take advantage of the fact that the carrier of the coalgebra is the set of terms, and hence, has an algebra structure. Therefore, in order to develop a mathematical operational semantics, what we need is a structure which contains both coalgebraic and algebraic features. Turi constructed such a structure in his categorical framework for SOS by focusing on the operational rules rather than on the transition relation.
In this section we present our implementation of Turi’s framework. To begin

4 In Haskell there is no distinction between least and greatest fixpoints of recursive datatypes. To distinguish between them, we write least fixpoints as data and greatest fixpoints as codata.

with, let us consider a typical operational rule and analyse its structure:


p −→a p ; q −→a
pj
pj ; q
premisses source → target

In general, a rule consists of some premisses and a conclusion. The source of the conclusion consists of an operator of the language (the ; operator, in the example above) applied to some metavariables (p and q) which stand for arbitrary terms. Premisses are transitions from these metavariables. Finally, the target of the con- clusion is a term with metavariables taken from the source of the conclusion and from the premisses (q and pj, respectively).
In the previous two sections we showed how to abstract syntax by a signature functor and observable behaviour by a behaviour functor. Using these concepts we can abstract the structure of operational rules.

The Type of Operational Rules
Given a language with syntax determined by a signature functor s and behaviour functor b, its structural operational semantics is given by rules of the form:

The type above says that operational rules are defined by a function which given two environments and the source of the conclusion of a rule, returns the transition in the conclusion of the rule. The x in the type declaration above corresponds to variables in the source of a transition (source variables) and y to variables in the target of a transition (target variables). The environments are:
Term environment: specifies which target variable corresponds to each source variable. It enables us to use source variables to construct the term in the target of the conclusion.
Behaviour environment: specifies the transition corresponding to each source variable. It plays the role of the premisses in an operational rule.
Note that source and target variables are polymorphic to ensure that the defined semantics do not depend on their actual nature. The distinction between source variables and target variables guarantees that the induced semantics depends only on the behaviour of its subterms, and not on the actual subterms.
Example 5.1 In Figure 8 we give operational semantics 5 to the constructs of P given in Example 3.1 with a behaviour functor ([ ] ◦ (KA ⊕ Pr).

5 For clarity, in Figure 8 we have omitted the constructors for functorial composition.

Function orP implements the operational rules of P given in Figure 1 by pattern- matching on the operator in the source of the conclusion. In the case of Put c, the only possible transition is to print c and terminate. In the case of Seq p q , we analyse the type of each possible transition of p to see which transition to perform (for the definition of the monad instance for lists, see appendix B.3). If p may print a character c and terminate, then Seq p q prints c and continues execution with term q . If p may print c and continue execution with term pj then Seq p q prints c and continues execution with term Seq pj q . In the case of Alt p q, the possible transitions are the union of the possible transitions from p and from q .
It is important to note that values of type OR s b are isomorphic to Turi’s abstract operational rules (see Appendix A). Consequently, not only are they a structured, language-independent formulation of SOS, but also they are guaranteed to induce a transition relation with bisimulation as a congruence and to generate an adequate denotational model. We prefer OR rules rather than Turi’s abstract oper- ational rules since they lead to a natural implementation in a functional language.
Obtaining a Transition Relation
Every operational rule OR s b induces a lifting opMonad of the syntax monad Term s to the category of b-coalgebras. The function opMonad (the operational monad [22]) takes a b-coalgebra on x and returns a b-coalgebra on Term s x . Intu- itively, opMonad shows that given an operational rule and the semantics of variables x in the terms, we can give semantics to terms with variables from x .
opMonad	:: (Functor s, Functor b) ⇒
OR s b → (x → b x ) → Term s x → b (Term s x ) opMonad op k = snd · foldTerm ⟨Var, fmap Var · k⟩
⟨Con · fmap fst, fmap join · op fst snd⟩
where ⟨f , g⟩ a = (f a, g a)
In order to execute a Program we unfold the coalgebra obtained from opMonad : run  :: (Functor s, Functor b) ⇒ OR s b → Program s → Nu b
run op = unfold (opMonad op empty)
It is a simple exercise for the reader to use opMonad to obtain a denotational model s (Nu b) → (Nu b) corresponding to a given OR.
This concludes our functional implementation of Turi’s mathematical opera- tional semantics. In the next section we tackle the question of how to modularly combine operational rules.
Modular Operational Semantics
Operational rules OR s b are defined for a signature functor s and behaviour functor
b. In Section 3 we showed how to obtain modular syntax by abstracting from a specific signature functor, and instead considering a signature functor equipped with type constraints as in Figure 7. Our goal now is to obtain a similar abstraction



Fig. 8: Operational semantics for P



technique for behaviours.
Many behaviours that appear in practice, including all the behaviours in our examples, are of the form m ◦ b, where m is a monad and b is a coproduct of functors. If we only consider operational semantics with behaviours of this form we can abstract from a concrete m ◦ b and obtain modular behaviours:
Rather than considering a concrete monad, we consider a monad m which sup- ports certain required operations. This is exactly the technique proposed by Liang et al. [14] and implemented in the Haskell library.
The same technique used to abstract from concrete syntax using the ‹→ relation can be used to abstract coproducts of behaviours b.
Putting together modular behaviours with modular syntax yields the following definition of modular operational rules:

Modular operational rules MOR differ from concrete operational rules OR in two ways:
they distinguish between the signature s of the semantic component being defined, and the signature of the complete language t ,
they consider behaviours to be the functorial composition of a monad m and a functor b.
Given a MOR, we can ossify it and obtain a concrete OR by fixing the signature of the complete language to be the signature of the language being defined, and providing a behaviour which satisfies the behaviour requirements of the given MOR.
ossify	:: MOR s s m b → OR s (m ◦ b)
ossify mor te be = Comp · mor te (deComp · be)

Combining Modular Operational Rules
Combining modular operational rules is a simple matter of taking their copair. The requirements on the behaviour of the combined rules is the combination of the requirements on behaviour of each component.
( )	:: MOR s t m b → MOR sj t m b → MOR (s ⊕ sj) t m b
(op1  op2 ) te be = copair (op1 te be) (op2 te be)
This is the fundamental tool for combining modular operational rules. The constraint that the monad m and behaviour b should be the same for the input rules of appears to be a severe restriction that undermines our original goal. However, as it will be shown next, we can sidestep this restriction by defining modular operational rules over an abstract monad and behaviour.


Deﬁning Modular Operational Rules
The following example shows how to write the modular components for the operators of P :

The fundamental idea is that each component should have the least possible requirements on syntax and behaviour, as given by the type constraints in the type signatures above. For morPut , the only requirements are that Put is in the syntax of the complete language, and that KA is in the behaviour. The semantic component for morSeq is a bit more subtle. After obtaining the behaviour of the first argument with be it needs to check whether execution of the first argument has finished, as indicated by a behaviour KA. This check is implemented by a case analysis with the ❽ operator. In the case of a behaviour KA, it will move on to the second argument with a Pr transition, as it is done in the non-modular semantics of P. The most interesting part is the handling of the case where the behaviour is not KA,



Fig. 9: Modular operational rules for the operators of Z

Fig. 10: Modular operational rules for the operators of E
but some possibly unknown behaviour 6 . Here, a step is made by propagating the unknown behaviour and continuing execution with the term obtained by adding the (Seq [−] q ) context to the resulting term of the transition. The semantic component for Alt is almost the same as the corresponding case in the non-modular semantics of P, except that now we do not explicitly require a behaviour [ ], but ask for the monad in the behaviour to support the mplus operation (described in appendix B.4).
Example 6.1 Modular operational semantics for the modular components of Z and E are given in Figures 9 and 10, respectively. In morAdd , the monad in the behaviour forces the choice of an order of evaluation of the arguments of Add. In the next subsection, we will show how to modularly obtain an addition operator with non-deterministic order of evaluation.

6 We say possibly unknown behaviour because in this case the behaviour might be the known behaviour
Pr, or an unknown behaviour.

Putting it all together
After writing modular operational rules for all the fragments, it is time to reap the fruits of our hard work. The following examples show how straightforward it is to obtain semantics for new languages by combining modular components.
Example 6.2 We construct modP a modular version of the language P which combines the modular operational rules of its operators. The requirements on syntax and behaviour of modP are the combination of the requirements of its components. To obtain a concrete operational semantics for P we fix the syntax to be exactly P and we instantiate the monad m to be the list monad [ ], which satisfies the requirement of being a MonadPlus:
morP :: (Put ‹→ s, Seq ‹→ s, Alt ‹→ s, KA ‹→ b, Pr ‹→ b, MonadPlus m) ⇒
MOR P s m b
morP = morPut  morSeq  morAlt
orPj  :: OR P ([ ] ◦ (Pr ⊕ KA))
orPj  = ossify morP
Example 6.3 A modular version of language Z is defined as the combination of the semantics of N, Add, and Ifz. To obtain a concrete version we fix the syntax and semantics with ossify . In this case the monad in the behaviour has no requirements, so we can instantiate it to the identity monad (described in Appendix B.2):
morZ :: (N ‹→ s, Ifz ‹→ s, Add ‹→ s, Monad m, KI ‹→ b) ⇒ MOR Z s m b morZ = morN morAdd morIfz
z :: OR Z (Id ◦ KI)
z = ossify morZ
Example 6.4 Adding exceptions to P is just a matter of adding the semantics of throw and catch:
ep :: OR EP ([ ] ◦ (KE ⊕ Pr ⊕ KA))
ep = ossify (morThr  morCat  morP )
Example 6.5 Adding exceptions to Z is once again, just a matter of adding the semantics of throw and catch:
ez :: OR EZ (Id ◦ (KE ⊕ KI))
ez = ossify (morThr  morCat  morZ )
Example 6.6 A version of Z which can also print characters is the following:
zp :: OR (Put ⊕ Seq ⊕ Z) (Id ◦ (KA ⊕ Pr ⊕ KI))
zp = ossify (morPut  morSeq  morZ )
Our modular semantics of addition has a fixed evaluation order from left to right. In order to define a version of addition with a non-deterministic order of evaluation we extend the semantics with H and define non-deterministic addition addND as syntactic sugar for the term (a + b) H (b + a).

zP :: OR (Put ⊕ Seq ⊕ Alt ⊕ Z) ([ ] ◦ (KA ⊕ Pr ⊕ KI)) zP = ossify (morPut morSeq morAlt morZ ) addND a b = (a ‘add ‘ b) H (b ‘add ‘ a)
In order to obtain a combined semantics we need to provide a monad which supports the operations required by the modular components. One way to obtain such a monad is to use monad transformers together with liftings of operations as in [14]. Another way would be to use the coproduct of monads [5,7] or to use Lawvere theories [20]. Note that the requirements do not specify any order on the layering of effects, so there could be many different monads that satisfy these requirements, each yielding different combined semantics.
Related Work
A practical approach to modular operational semantics for certain specific effects has recently been put forward by Mosses [17], but it is based on the syntactic rather than semantic approach to SOS. Turi showed with a few examples how operational rules which are parametric in their behaviour could be instantiated to different settings [23] but did not attempt to systematize this technique. Lenisa et al. [13] defined an operation that combines two operational rules on the same behaviour OR s b and OR sj b into an operational rule OR (s ⊕ sj) b, but did not consider the problem of semantics with different behaviour. The advantage of defining the combination operation for MOR rather than OR is that elements of MOR are flex- ible enough to allow the separate definition of operators which depend on other operators. This flexibility is especially advantageous if each operator has different requirements on the behaviour functor, as each operator will be defined with less requirements, yielding a more general semantics. Kick [11] presented the dual of the syntax combination operation for ORs, that is, an operation which takes two operational rules OR s b and OR s bj, and returns a OR s (b ⊗ bj) (where ⊗ is functorial product). This operation does not seem to be powerful enough to sup- port the combinations we are trying to obtain. However, it would be interesting to see how this operation, in the particular case of the behaviour being of the form PB, could be used to obtain results similar to ours by exploiting the isomorphism P(A + B) ∼= P(A) × P(B).
Conclusion
We have developed a modular approach to operational semantics which allows us to define the semantics of a language as a combination of the semantics of its in- dividual components. Our approach is based on writing the operational semantics on partially known syntax and behaviour, and on the representation of an opera- tional semantics as a polymorphic function that distributes syntax over behaviour. This high-level modular approach leads to a simple and natural implementation in Haskell, which serves to make our work more accessible and also to allow readers to experiment further with our constructions.

As with Turi’s original work, this paper is fundamentally first-order. Therefore, in terms of future work, our primary aim is to consider modular operational se- mantics for languages with more advanced features, such as binding and recursion. Incorporating binding operations into Turi’s framework is a difficult task, see [4,3] for example, but we have some preliminary ideas in this direction. In addition, we would like to investigate the extent to which our ideas are applicable to other models of program execution, such as abstract and virtual machines.
Our eventual aim is to be able to write modular operational semantics in Haskell in as clean and simple way as modular interpreters [14].
Acknowledgement
We would like to thank Sam Staton, Peter Mosses and Wouter Swierstra for their valuable feedback, and the FP lab in Nottingham and anonymous referees for their useful comments.

References
Bergstra, J. A. and J. W. Klop, Algebra of communicating processes with abstraction, Theor. Comput. Sci. 37 (1985), pp. 77–121.
Danielsson, N. A., J. Hughes, P. Jansson and J. Gibbons, Fast and loose reasoning is morally correct, in: “Proc. of 33rd ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, POPL ’06 (Charleston, SC, Jan. 2006),” ACM Press, 2006, pp. 206–217.
Fiore, M. and S. Staton, Comparing operational models of name-passing process calculi, Electron. Notes in Theor. Comput. Sci. 106 (2004), pp. 91–104.
Fiore, M. and D. Turi, Semantics of name and value passing, in: “Proc. of 16th Ann. IEEE Symp. on Logic in Computer Science, LICS ’01 (Boston, MA, June 2001),” IEEE CS Press, 2001, pp. 93–104.
Ghani, N. and C. Lu¨th. Composing monads using coproducts, in: “Proc. of 7th ACM SIGPLAN Int. Conf. on Functional Programming, ICFP ’02 (Pittsburgh, PA, Oct. 2002 ),” ACM Press, 2002, pp. 133– 144.
Ghani, N. and C. Lu¨th. Monads and modular term rewriting, in: E. Moggi and G. Rosolini, eds., “Proc. of 7th Int. Conf. on Category Theory and Computer Science, CTCS ’97 (Santa Margherita Ligure, Sept. 1997),” Lecture Notes in Computer Science 1290, Springer, 1997, pp. 69–86.
Ghani, N. and T. Uustalu, Coproducts of ideal monads, Theor. Inform. and Appl. 38(4) (2004), pp. 321– 342.
Hagino, T., “A Categorical Programming Language,” PhD thesis, University of Edinburgh, 1987.
Hutton, G., Fold and unfold for program semantics, in: “Proc. of 3rd ACM SIGPLAN Int. Conf. on Functional Programming, ICFP ’98 (Baltimore, MD, Sept. 1998),” ACM Press, 1998, pp. 280–288.
Jacobs, B. and J. Rutten, A tutorial on (co)algebras and (co)induction, Bull. of EATCS 62 (1997),
pp. 222–259.
Kick, M. and J. Power, Modularity of behaviours for mathematical operational semantics, Electron. Notes in Theor. Comput. Sci. 106 (2004), pp. 185–200.
Klin, B., Adding recursive constructs to bialgebraic semantics, J. of Log. and Algebr. Program. 60–61
(2004), pp. 259–286.
Lenisa, M., J. Power, and H. Watanabe, Distributivity for endofunctors, pointed and co-pointed endofunctors, monads and comonads, Electron. Notes in Theor. Comput. Sci. 33 (2000), pp. 230–260.

Liang, S., P. Hudak and M. Jones, Monad transformers and modular interpreters, in: “Conf. Record of 22nd ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, POPL ’95 (San Francisco, CA, Jan. 1995),” ACM Press, 1995, pp. 333–343.
Mac Lane, S., “Categories for the Working Mathematician,” 2nd ed., Graduate Texts in Mathematics
5, Springer, 1998.
Meijer, E., M. Fokkinga, and R. Paterson, Functional programming with bananas, lenses, envelopes and barbed wire, in: J. Hughes, ed., “Proc. of 5th ACM Conf. on Functional Programming Languages and Computer Architecture, FPCA ’91 (Cambridge, MA, Aug. 1991),” Lecture Notes in Computer Science 523, Springer, 1991, pp. 124–144.
Mosses, P. D., Modular structural operational semantics, J. of Log. and Algebr. Program. 60–61 (2004),
pp. 195–228.
Peyton Jones, S., ed., “Haskell 98 Language and Libraries: the Revised Report,” Cambridge University Press, 2003.
Plotkin, G. D., A structural approach to operational semantics, Technical Report DAIMI FN-19, University of Aarhus, 1981. Reprinted in: J. of Log. and Algebr. Program. 60–61 (2004), pp. 17–139.
Plotkin, G. D. and J. Power, Computational effects and operations: an overview, Electron. Notes in Theor. Comput. Sci. 73 (2004), pp. 149–163.
Swierstra, W., Data types `a la carte, J. of Funct. Program. 18(3) (2008), pp. 1–14.
Turi, D., “Functorial Operational Semantics and Its Denotational Dual,” PhD thesis, Free University, Amsterdam, 1996.
Turi, D., Categorical modelling of structural operational rules: case studies, in: E. Moggi and
G. Rosolini, eds., “Proc. of 7th Int. Conf. on Category Theory and Computer Science, CTCS ’97 (Santa Margherita Ligure, Sept. 1997),” Lecture Notes in Computer Science 1290, Springer, 1997,
pp. 127–146.
Turi, D. and G. D. Plotkin, Towards a mathematical operational semantics, in: “Proc. of 12th Ann. IEEE Symp. on Logic in Computer Science, LICS ’97 (Warsaw, June/July 1997),” IEEE CS Press, 1997, pp. 280–291.

ORs are Turi’s Operational Rules
Operational rules ORs are isomorphic to Turi’s abstract operational rules AOR. Categorically, this can be seen by the universal property of right Kan extensions and their end formula [15], which is valid in any parametric model. More concretely, the isomorphism is given by the following functions:
type AOR s b = ∀ a · s (a, b a) → b (Term s a) fromOR   :: OR s b → AOR s b 
fromOR os	= os fst snd
toOR	:: (Functor s) ⇒ AOR s b → OR s b toOR aor te be = aor · fmap ⟨te, be⟩
where ⟨f , g⟩ a = (f a, g a)
Additional definitions
Functors and Monads
A datatype is shown to have a functorial or a monadic structure by an instance of the following classes, plus the proof that certain coherence conditions hold [18].
class Functor f where
fmap :: (a → b) → f a → f b

class Monad m where
return :: a → m a 
(>>=) :: m a → (a → m b) → m b 
The multiplication of a monad for all Monad instances is:
join :: Monad m ⇒ m (m a) → m a 
join = (>>=id)
The Identity Monad
The identity monad is given by the following instances:
data Id a = Id a
instance Functor Id where fmap f (Id a)= Id (f a) instance Monad Id where
return	= Id
(Id a) >>= f = f a
The List Monad
The list monad is given by the following instances:
instance Functor [] where
fmap f []	= [] 
fmap f (x : xs)= f x : fmap f xs
instance Monad [] where
return x	= [x ]
[] >>= f	= [ ]
(x : xs) >>= f = f x ++ (xs >>= f )
The class of MonadPlus monads
Monads that support choice and failure, such as the list monad via ++ and [ ], are instances of the class MonadPlus:
class (Monad m) ⇒ MonadPlus m where
mzero :: m a 
mplus :: m a → m a → m a 
