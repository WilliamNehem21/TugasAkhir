Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 352 (2020) 105–128
www.elsevier.com/locate/entcs

Domain Theoretic Second-Order Euler’s Method for Solving Initial Value Problems

Abbas Edalata,1 Amin Farjudianb,2 Mina Mohammadianc,3 Dirk Pattinsond,4

a Department of Computing Imperial College
London, UK
b School of Computer Science University of Nottingham Ningbo China Ningbo, China
c Faculty of Mathematical Sciences University of Tabriz
Tabriz, Iran
d School of Computer Science The Australian National University
Canberra, Australia



Abstract
A domain-theoretic method for solving initial value problems (IVPs) is presented, together with proofs of soundness, completeness, and some results on the algebraic complexity of the method. While the common fixed-precision interval arithmetic methods are restricted by the precision of the underlying machine ar- chitecture, domain-theoretic methods may be complete, i. e., the result may be obtained to any degree of accuracy. Furthermore, unlike methods based on interval arithmetic which require access to the syntactic representation of the vector field, domain-theoretic methods only deal with the semantics of the field, in the sense that the field is assumed to be given via finitely-representable approximations, to within any required accuracy.
In contrast to the domain-theoretic first-order Euler method, the second-order method uses the local Lips- chitz properties of the field. This is achieved by using a domain for Lipschitz functions, whose elements are consistent pairs that provide approximations of the field and its local Lipschitz properties. In the special case where the field is differentiable, the local Lipschitz properties are exactly the local differential proper- ties of the field. In solving IVPs, Lipschitz continuity of the field is a common assumption, as a sufficient condition for uniqueness of the solution. While the validated methods for solving IVPs commonly impose further restrictions on the vector field, the second-order Euler method requires no further condition. In this sense, the method may be seen as the most general of its kind.
To avoid complicated notations and lengthy arguments, the results of the paper are stated for the second- order Euler method. Nonetheless, the framework, and the results, may be extended to any higher-order Euler method, in a straightforward way.
Keywords: domain theory, domain of Lipschitz functions, initial value problem, algebraic complexity, interval arithmetic.


https://doi.org/10.1016/j.entcs.2020.09.006
1571-0661/© 2020 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

Introduction
We consider the ordinary differential equation (ODE) initial value problem (IVP):

⎧⎪⎨
⎩
yj = f (y),
y(0) = (0,..., 0),	(1)
`˛n¸x

in which f : [−K, K]n → [−M, M ]n is a continuous vector field, for some natural number n ≥ 1, and positive rational numbers K, M ∈ Q+. From now on, we refer to f as the ‘field’.
By Peano’s theorem, the mere continuity of the field f guarantees existence of a differentiable solution y : [− K , K ] → [−K, K]n (see, e. g., [29] for a proof). It
M  M
is also well-known that, by further assuming that f is Lipschitz continuous, the
uniqueness of the solution can be guaranteed.
There are plenty of established methods and algorithms for solving problems of type (1) [19]. These are usually implemented using floating-point approximation of real numbers. These implementations have inherent inaccuracies, mainly due to round-off and truncation errors, which may be tolerated when small errors do not incur significant costs. A tighter control over errors may be obtained through error analysis [17] in limited cases.
A more general alternative is offered by validated numerics, where results are obtained with absolute guarantees of correctness. Interval arithmetic provides a foundation for many available validated numerics [25]. There are many efficient in- terval based validated numerics for problem (1) available in the literature, including efficient high-order Taylor based methods, e. g., [2,27,30]. In fact, it is well known that, by assuming the field f to be analytic, the solution to IVP (1) may be ob- tained in polynomial time [26] by using a Taylor model, which is in contrast to the PSPACE-completeness of IVP solving without analyticity assumption [20].
While the aforementioned methods are efficient, they are not explicitly grounded in the denotational semantics for interval arithmetic provided by domains and con- tinuous lattices [1,16]. By combining powerful tools from order theory and topology, domain theory provides a rich semantic model for validated numerics. An added ad- vantage of developing differential equation solvers in a domain-theoretic framework is that they can be subsequently incorporated into domain-theoretic models for other important applications, such as reachability analysis of hybrid systems [11,22,23].
As opposed to working with Taylor coefficients, in a domain-theoretic approach, the field is interpreted as the limit (under Scott topology) of a sequence of finitely- representable approximations. Indeed, domain based approaches for solving prob- lem (1) have been introduced for both (first-order) Euler’s method [10], and Picard’s method [12]. In classical numerical analysis, the (first-order forward) Euler method

1 Email: A.Edalat@ic.ac.uk
2 Email: Amin.Farjudian@nottingham.edu.cn
3 Email: Mina.Mohammadian@anu.edu.au
4 Email: Dirk.Pattinson@anu.edu.au

is arguably the most basic scheme for numerical solution of IVPs. The Euler method is based on a very simple geometric intuition, whereby the solution is constructed by taking small steps of size (say) h > 0, and approximating y(t + h) ≈ y(t)+ hf (y(t)). The Picard method, on the other hand, is based on the well-known Picard-Lindel¨of theorem [29, Theorem 2.2], whereby successive approximations {yn | n ∈ N} of the solution of the IVP are obtained via the iteration yn+1(x)=  x f (yn(t)) dt.
Remark 1.1 A numerical scheme for solving IVPs is said to be of order n if, whenever the solution of an IVP is a polynomial of degree at most n, then the solution may be obtained exactly by the scheme [19, Page 8]. 5
The time complexity and convergence of domain theoretic Picard method was further studied in [15] for an implementation using arbitrary precision floating-point numbers. Picard’s method lends itself naturally to implementation using function interval arithmetic [4], with the further advantage that it can handle some uncertain initial values as well [21].
Nonetheless, Picard’s method has quite a large memory footprint, and the first-order Euler’s method—which has a smaller memory footprint—does not use the local Lipschitz properties of the field. This is while, in the first-order Eu- ler method [10], Lipschitz continuity of the field is required, in order to guarantee uniqueness of solutions. In the current paper, we present a domain-theoretic second- order Euler method, which makes use of the local Lipschitz properties of the field. By using domain theory, we are able to retain full generality, in the sense that, while the field f is assumed to be Lipschitz continuous, no further restriction is required.
Remark 1.2 [autonomous versus non-autonomous IVPs] In the current pa- per, we consider only IVPs of the form (1), i. e., autonomous IVPs. Converting a non-autonomous IVP to an autonomous one, by adding an extra variable, is a well- known technique. For instance, given a non-autonomous equation yj(t)= f (y(t), t) with y(t) = (y1(t),..., yn(t)), the function defined by z(t) = (y(t), t) satisfies the autonomous equation zj(t)= g(z(t)) with g(θ1,..., θn+1) ·= (f (θ1,..., θn+1), 1). It is well-known that the uniqueness of solutions for the non-autonomous IVP is guar- anteed if the field f is Lipschitz continuous in its first n (out of n + 1) arguments. To ensure uniqueness of solutions for the autonomous IVP (1), we assume that the field is Lipschitz continuous in all of its arguments. As such, we lose a slight bit of generality.
The results of the current paper can be generalized, in a straightforward man- ner, to similar analysis of any n-th order Euler method. The main result needed for this generalization is a variation of Taylor’s theorem, as will be presented in Corol- lary 2.14. We present only the second-order method here because the notations (mainly, indices) may be written without much clutter. Presenting the results for the general n-th order Euler’s method, however, will require handling complicated notations for multi-dimensional matrices, which will only obscure the main ideas.

5 Alternatively, a numerical scheme is said to be of order n if, for every step size h, the local error incurred is of order O(hn+1).

It should also be pointed out that, while we have taken the initial values in (1) to be all zeros, generalization to initial conditions of the form y(t0)= (q1,..., qn), in which t0, q1,..., qn ∈ Q, is straightforward. The cases where some initial values are irrational points, or non-degenerate intervals, need further considerations which are not the focus of the current work.
We study the algebraic complexity and convergence properties of the second- order method. This, in turn, paves the way for a more detailed bit complexity, similar to [15].
Preliminaries and Notation
We assume that the reader is familiar with the basic concepts and common notations in domain theory [1,16], including interval domains [5,14]. We let I[−K, K]n denote the ω-continuous bounded complete domain of non-empty compact n-dimensional
hyper-rectangles  n  [ai, bi] in [−K, K]n, ordered by reverse inclusion, i. e., A ±
B ⇐⇒ B ⊆ A. We define IRn, which has no bottom element, in a similar way.
By adding Rn as the bottom element, we obtain the domain IRn = IRn ∪ {Rn}.
For any x ∈ Rn, the singleton {x} is a maximal element of IRn . Where there is no confusion, for simplicity, we may write x instead of {x}. For any subset X of a
poset D, we write	X and . X to denote the least upper bound, and the greatest
lower bound, of X, respectively, assuming that they exist.
In what follows, we assume that a ∈ Q. Although the assumption is not neces- sary for many of the results, it makes the presentation of the material simpler:
Definition 2.1 [Partitions] A partition of [0, a] is a finite sequence (q0,..., qk) of real numbers such that 0 = q0 < ··· < qk = a. Furthermore:
We let P denote the set of all partitions of an interval of interest, e. g., [0, a].
The norm |Q| of a partition Q = (q0,..., qk) is given by |Q| ·= max{qi − qi−1 |
1 ≤ i ≤ k}.
We define P1	·=	{Q ∈P	|	|Q|≤ 1} and P1,Q	·=	{Q ∈P	|
q0,..., qk ∈ Q, and |Q|≤ 1}. . 
The minimal width of a partition Q = (q0,..., qk) is given by m(Q) ·= min{qi − qi−1 | 1 ≤ i ≤ k}.

We let rQ ·=  |Q| 
denote the ratio of the maximum to minimum distances

between successive partition points.
A partition Q = (q0,..., qk) is said to be equidistant iff rQ = 1, i. e., ∀i ∈
{0,...,k − 1} : qi+1 − qi = a .
Definition 2.2 [Width]
For any interval α = [α, α], the width of α is defined by w(α) ·= α − α.
For an n-dimensional box α = (α1,..., αn), the width is defined by w(α) ·= max1≤i≤n w(αi).
If width is already defined over a given set B, then it can be lifted to functions

from any arbitrary set A to B by:
∀f : A → B :	w(f ) ·= sup{w(f (x)) | x ∈ A}.
Note that it is possible to have w(f )= ∞.
A notion of interval distance (Definition 2.3 (i) below), which coincides with the Hausdorff distance of two intervals, was used by Moore [24,25]. For analyzing the speed of convergence, we will need the following extension of this concept:
Definition 2.3 [Interval Distance]
For any pair of intervals x  = [x, x] and y  = [y, y], let d(x, y) ·= max | x − y |, | x − y | .
For α = (α1,..., αn) and β = (β1,..., βn) in IRn, we let d(α, β) ·= max{d(αi, βi) | 1 ≤ i ≤ n}.
Let X be an arbitrary set, and let f, g : X → IRn. Then, we define d(f, g) ·= sup{d(f (x), g(x)) | x ∈ X}.
Definition 2.4 [Symmetric Expansion] For any α = ([a1, a1],..., [an, an]) ∈ IRn and r ≥ 0, we define the symmetric expansion of the interval vector α with the real constant r as follows:
α ⊕ r ·= ([a1 − r, a1 + r],..., [an − r, an + r]).
Note that, for each 1 ≤ j ≤ n, the j-th component of α ⊕ r is the Minkowski sum of [aj, aj] and [−r, r].
Notation 2.5 (S, V ) Throughout this article:
We let S denote the function space [0, a] ⇒ I[−K, K]n for constructing solu- tions of (1), with the Euclidean topology on [0, a], and the Scott topology on I[−K, K]n.
We let V denote the function space I[−K, K]n ⇒ I[−M, M ]n of interval vector ﬁelds.
Definition 2.6 [Extension, Canonical Extension: If ]
An interval valued map u ∈ V is said to extend the classical vector field
f : [−K, K]n → [−M, M ]n iff:
∀x ∈ [−K, K]n :	u({x})= {f (x)} .
Similarly, u ∈ V is said to extend the interval valued g : [−K, K]n →
I[−M, M ]n iff:
∀x ∈ [−K, K]n :	u({x})= g(x).
Every continuous vector field f = (f1,..., fn): [−K, K]n → [−M, M ]n has a
canonical extension If ∈V given by:



∀α ∈ I[−K, K]n :	If (α) ·= ({f1(x) | x ∈ α},..., {fn(x) | x ∈ α}) .
Similarly, every Euclidean-Scott continuous g = (g1,..., gn) : [−K, K]n →
I[−M, M ]n has a canonical extension Ig ∈V given by:
∀α ∈ I[−K, K]n :	Ig(α) ·= . g1(x),..., . gn(x)  .
x∈α	x∈α
in which . denotes the greatest lower bound operator. If and Ig are the maximal extensions of f and g, respectively, among all the extensions in V.
Definition 2.7 [Interval Lipschitz] We say that a function u : I[−K, K]n →
I[−M, M ]n is interval Lipschitz with constant L ≥ 0 iff:
∀α ∈ I[−K, K]n :	w(u(α)) ≤ L w(α).
In particular, if u is interval Lipschitz, then it maps every maximal element of I[−K, K]n to a maximal element of I[−M, M ]n because ∀x ∈ [−K, K]n : w(u({x})) ≤ L w({x})= 0.
Definition 2.8 [Single-Step Function: bχO] Assume that (X, Ω) is a topological space, and (D, ±) is a pointed directed-complete partial order (cppo), with bottom element ⊥. Then for any open set O ∈ Ω, and any element b ∈ D, we define the single-step function bχO : X → D as follows:


bχO
·= ⎧ b, if x ∈ O,
⎩ ⊥, otherwise.


We recall the concept of a domain-theoretic derivative for a function f : U → R defined on an open subset U ⊆ Rn. We denote the continuous domain of the non- empty, compact and convex subsets of Rn, taken together with Rn as the bottom element and ordered by reverse inclusion, by CRn .
Definition 2.9 [L-derivative] Assume that O ⊆ U ⊆ Rn, both O and U are open, and b ∈ CRn:
The single-step tie δ(O, b) is the set of all functions f : U → R for which b(x − y) ± f (x) − f (y) for all x, y ∈ O. The set b(x − y) is obtained by taking the inner product of every element of b with the vector x − y, and ± is the reverse inclusion order on CRn .
The L-derivative of f : U → R is defined as L(f ) ·=  {bχO f ∈ δ(O, b)}.
It is easy to see that single-step functions are Euclidean-Scott continuous. It has been shown that the L-derivative is a Scott continuous function, and, in case f is

classically differentiable at x ∈ U , then the L-derivative and the classical derivative coincide [6].
A large number of properties of the classical derivative can be generalized to its domain theoretic counterpart, e. g., additivity and the chain rule [9]. Of particular importance to the current paper is the generalization of the mean value theorem to the domain theoretic setting [8, Theorem 5.4], which follows from the corre- sponding result for the Clarke-gradient [3, Theorem 2.3.7], and the fact that the Clarke-gradient coincides with the domain theoretic derivative in finite dimensional Euclidean spaces [6]
In this paper, instead of CRn , we work with IRn :
⊥	⊥
Definition 2.10 [Lˆ-derivative] Let U ⊆ Rn be an open set:
In the definition of L-derivative (Definition 2.9), if CRn is replaced with IRn ,
then we obtain the concept of Lˆ-derivative for functions of type U → R.
For a vector valued function f = (f1,..., fm): U → Rm, we let:
Lˆ(f ) ·= Lˆ(f ),..., Lˆ(f ) | ,

in which, (·)| denotes the transpose of a matrix. In other words, for each 1 ≤ i ≤ m and x ∈ U , let Lˆ(fi)(x) ≡ (αi,1,..., αi,n) ∈ IRn . Then, for each x ∈ U , Lˆ(f )(x) is the m × n interval matrix [αi,j]1≤i≤m,1≤j≤n.
Recall that the solution of the IVP (1) is a function of a single variable, of type f = (f1,..., fn) : [α, β] → Rn. For each component fj with 1 ≤ j ≤ n, if K is a local Lipschitz constant for fj around x, then [−K, K] ± L(fj)(x)= Lˆ(fj)(x). We also have:
Lˆ(f )= (L(f1),..., L(fn))| : [α, β] → IRn .
Remark 2.11 In general, Lˆ(f ) contains the Clarke gradient of f , and they are not always equal [18].
Notation 2.12 If f = (f1,..., fn) : [a, b] → Rn is k-times differentiable and 0 ≤
i ≤ k, we write f (i) : [a, b] → Rn for the i-th classical derivative of f.
For the proof of soundness, we need a slight generalization of the classical Tay- lor’s theorem. In the classical version, one considers a k times continuously differ- entiable function on an interval [α, β], and the k + 1-st derivative is required to exist in the interior (α, β). The domain theoretic generalization only requires that the k-th derivative is Lipschitz in the interior (α, β) of the domain of definition. As the k + 1-st derivative (in the domain theoretic sense) may be interval valued we can only stipulate set theoretic containment, rather than equality. More formally:
Lemma 2.13 Assume that k ∈ N and let f : [α, β] → R be a function that is
k-times continuously differentiable and suppose that the k-th derivative f (k) of f is

Lipschitz in (α, β). Then:

k	j	k+1
f (β) ∈ Σ f (j)(α) · (β − α)  + L(f (k))(θ) · (β − α)	 ,

for some θ ∈ (α, β).
Proof. We adapt the proof of the classical Taylor’s theorem from [28, Theorem 5.15] and, in the last step, use the mean value theorem for the domain theoretic derivative.
Consider the Taylor polynomial

k	j
P (t) ·=	f (j)(α) · (t − α)  ,
j!
j=0


and let:

In particular: Then, we define:
f (β) − P (β)
M ·= (β − α)k+1 .

f (β)= P (β)+ M (β − α)k+1.	(2)

∀t ∈ [α, β]:	g(t) ·= f (t) − P (t) − M (t − α)k+1.

We note that P (j)(α) = f (j)(α), for 0 ≤ j ≤ k. Thus, g(α) = gj(α) = ··· =
g(k)(α)= 0.
As g(β) = 0, we find, by the classical mean value theorem, a point x1 ∈ (α, β) such that gj(x1) = 0. Applying the classical mean value theorem iteratively (and using the fact that g is k times continuously differentiable) we find points x2,..., xk where g(j)(xj) = 0. Specifically, this gives xk ∈ (α, β) with g(k)(xk) = 0. Solving for f and evaluating at xk, we obtain:
f (k)(xk) − f (k)(α)= (k + 1)! M (xk − α).

By the domain theoretic mean value theorem [8, Theorem 5.4] there exists θ ∈
(α, xk) ⊆ (α, β) for which f (k)(xk) − f (k)(α) ∈ L(f (k))(θ) · (xk − α). As a result,
(k + 1)! M (xk −α) ∈ L(f (k))(θ) · (xk −α) which entails that (k + 1)! M ∈ L(f (k))(θ), because xk − α /= 0. Putting this into (2) we obtain:
k	j	k+1

j!
j=0
k	j
(k + 1)!
k+1

j!
j=0
(k + 1)!
2

Corollary 2.14 Assume that k ∈ N and let f : [α, β] → Rn be a function that is k-times continuously differentiable and suppose that the k-th derivative f (k) of f is Lipschitz in (α, β). Then:

k	j	k+1
f (β) ∈ Σ f (j)(α) · (β − α)  + ILˆ(f (k))([α, β]) · (β − α)	 ,

in which, ILˆ(f (k)): I[α, β] → IRn is the canonical extension of Lˆ(f (k)).
Proof. For each component 1 ≤ j ≤ n, a point θj ∈ (α, β) may be obtained using Lemma 2.13. Then:
ILˆ(f (k))([α, β]) ± L(f (k)(θ1)),..., L(f (k)(θn)) .
The claim now follows directly.	2

A Domain-Theoretic Second-Order Euler Method
Based on an interval analysis technique for solving IVPs using the Euler method [24, Chapter 8], a ﬁrst-order domain-theoretic Euler operator was introduced in [10], together with an analysis of its convergence and algebraic complexity:
Definition 3.1 [First-Order Euler Operator: E] Suppose Q = (q0,..., qk) ∈ P, and let a ·= K . Then:
The Euler operator with linear expansion El : P × V → [0, a] → I[−K, K]n
is defined by:


El (Q)(x) ·=   (0,..., 0),	∫

			
if x = 0,

	 	

Similarly, the Euler operator with constant expansion Ec : P× V → [0, a] →
I[−K, K]n is defined by:


Ec (Q)(x) ·=   (0,..., 0),	∫

			
if x = 0,

		 	

in which Δqi ·= qi+1 − qi.
In the sequel, where appropriate, E will stand for either of El or Ec.
Intuitively, we think of u ∈ (I[−K, K]n ⇒ I[−M, M ]n) as a domain extension of the (classical) field f : [−K, K]n → [−M, M ]n. Furthermore, to guarantee unique- ness of solutions, we assume that u is interval Lipschitz. The domain extension u of the field f may not be finitely-representable. As such, one of the main strengths of

the domain-theoretic framework is that, the (ideal) solution of (1) can be approxi- mated to any given degree of accuracy, using only finitely-representable objects:
Theorem 3.2 ([10, Corollary 12]) Suppose (un)n∈N is a sequence in V with u = n∈N un and (Qn)n∈N is a sequence of partitions with limn→∞ |Qn| = 0. Then n∈N Eun (Qn) is real valued and satisﬁes (1).
The first-order operators of Definition 3.1 move forward in time based on a conservative global bound M on the Lipschitz constant of the solution. This is inevitable for a validated method which should account for all possible errors and inaccuracies. Furthermore, although the field f is assumed to be Lipschitz contin- uous, the Lipschitz properties of f are not used by the first-order operators. Thus, by requiring the Lipschitz properties of the field to be provided as another input parameter, we devise a second-order Euler method.
As the domain V does not contain any information about the Lipschitz properties of its elements, we briefly provide the description of a suitable domain for Lipschitz vector fields, which in particular, includes differentiable vector fields as an important subset. For a more comprehensive account, the reader may refer to [7,8].
Assumption 1 For the remainder of this article, we assume that the Lˆ-derivative of the ﬁeld f : [−K, K]n → [−M, M ]n of problem (1) is bounded, i. e.:
∃Mj > 0: ∀x ∈ [−K, K]n :	[−Mj,Mj]n2 ± Lˆ(f )(x).	(3)
Definition 3.3 [V 1] We define the domain V1 to be the subdomain of:
V∗ ·= (I[−K, K]n ⇒ I[−M, M ]n) ×  I[−K, K]n ⇒ I[−Mj,Mj]n2  ,

consisting of consistent pairs (u, uj) ∈ V∗. A pair (u, uj) is said to be consistent iff there exists an h : [−K, K]n → [−M, M ]n satisfying u ± Ih and uj ± ILˆ(h).
Remark 3.4 Given a pair (u, uj) ∈ V∗, by merely assuming that u and uj are extensions of a classical vector field g and its Lˆ-derivative gj, we obtain consistency for free. Nonetheless, when dealing with imprecisely given input data over which we have no control, this consistency may be violated. As a result, we need an effective
method for verifying the consistency of a given pair (u, uj) ∈ V∗. Fortunately, the domain V1 can indeed be equipped with an effective structure [8].
We will also need an estimate on the local Lipschitz constant of domain-theoretic extensions of a given field. For any interval matrix A =  [aij, aij] m×n, the norm
 A ∞ is defined as:


A 	·= max
1≤i≤m

Σj=1

max
| ai,j |, | aij |, .




Assumption 2 In the sequel, we assume that u and uj are interval extensions of the ﬁeld f and its Lˆ-derivative Lˆ(f ), respectively, and satisfy the following additional

condition:

∀x ∈ I[−K, K]n :	w(u(x)) ≤  uj(x)  ∞ w(x).	(4)

Lemma 3.5 Given a Lipschitz vector ﬁeld f : [−K, K]n → [−M, M ]n, let L ·=

supx∈[—K,K]n
 Lˆ(f )(x)  ∞. Then, f is L-Lipschitz continuous in [−K, K]n, i. e.:
∀x, y ∈ [−K, K]n :	 f (x) − f (y)  ∞ ≤ L  x − y ∞.


Proof. The lemma follows from the mean value theorem for the L-derivative [8, Theorem 5.4], and the fact that the Lˆ-derivative approximates the L-derivative. 2
Corollary 3.6 Suppose that u : I[−K, K]n → I[−M, M ]n and uj : I[−K, K]n →

I[−Mj,Mj]n2  are the canonical extensions of the classical vector
ﬁeld f	:

[−K, K]n → [−M, M ]n and its satisfy condition (4).
Lˆ-derivative
Lˆ(f ), respectively. Then, u and uj

In summary, condition (4) ensures that the (matrix) norm of the paired deriva- tive uj of u acts as a local interval Lipschitz constant. As Corollary 3.6 demon- strates, this condition is satisfied for the canonical extensions of the vector field and its Lˆ-derivative.
Next, we introduce the main operator of the current paper:
Definition 3.7 [Second-Order Euler Operator: E2]
Let a ∈ (0,	K	′ ]. The second-order Euler operator E2 : P1 ×V1 → [0, a] →
M (1+nM )
I[−K, K]n is defined as follows: for a given partition Q ≡ (q0,..., qk) of [0, a] satisfying |Q|≤ 1, and a given pair (u, uj) ∈ V1:

y(x) ·=   (0,..., 0),	if x = 0,
·	y(q )+ ∫ x u (y(q )) + (t − q )(uj · u) (y(q ) ⊕ Δq M ) dt, if q < x ≤ q	,


in which:
y ≡ E2
i	qi	i	i



′ (Q);
i	i	i
i+1
(5)

(u,u )
Δqi ·= qi+1 − qi;
(uj · u)(·) denotes the product of the interval matrix uj(·) with the interval vector
u(·).
Remark 3.8 While the first-order operators of Definition 3.1 provide piece-wise affine enclosures of the solution, the operator of Definition 3.7 provides piece-wise quadratic enclosures of the solution. Indeed, in special cases, if the solution is a polynomial of degree (at most) 2, then by applying the operator of Definition 3.7, one may obtain the exact solution. For instance, let y = (y1, y2), and consider the rather simple IVP:

⎡ yj (t) ⎤
⎡ 2αy2(t)+ β ⎤
⎡ y1(0) ⎤
⎡ 0 ⎤

⎣ yj (t)
⎦ = ⎣
,
1	y2(0)
⎦ = ⎣

⎦ ,	(6)

in which α, β ∈ R. The unique solution of (6) is given by y1(t) = αt2 + βt and
y2(t)= t. It is not difficult to verify that, by taking the extensions:
u(ρ, θ)= ⎡⎣ 2αθ + β ⎤⎦	and	uj(ρ, θ)= ⎡ 0 2α ⎤ ,


the operator of (5) yields the exact quadratic solution of (6). This, together with Remark 1.1, justifies using the term ‘second-order’.
In contrast with the first-order operators of Definition 3.1, which use only an extension u of the field, the second-order operator uses an extension uj of the L- derivative of the field as well. We need to show that E2 is well-defined:
Lemma 3.9 Assume that Q = (q0,..., qk) ∈ P1, and let yj = [yj, yj] ·= E2	′ (Q)j
(u,u )
be the j-th component of E2	′ (Q), for every j ∈ {1,..., n}. Then, both yj and yj
(u,u )
are Lipschitz continuous with Lipschitz constant:
ΛQ ·= M (1 + |Q|nMj).


In particular:

∀x ∈ [0, a]:	E2

′ (Q)(x) ∈ I[−K, K]n.	(7)

(u,u )
Proof. We prove the lemma for yj. The proof for yj is almost identical. Hence, our aim is to show that:
∀x, xj ∈ [0, a]:	| yj(xj) − yj(x) |≤ ΛQ| xj − x |.	(8)
Indeed, it suffices to prove (8) for the special case of qi ≤ x ≤ xj ≤ qi+1, for some 0 ≤ i ≤ k − 1. Referring to (5), note that:
The interval entries in the vector u and matrix uj are bounded by M and Mj,
respectively. As uj is an n × n matrix, and u is an n × 1 vector, each interval component of the vector uj · u is bounded by nMMj.
∀t ∈ [qi, qi+1]: t − qi ≤ |Q|. As such, we obtain:
∫ x′ 

which proves (8). Extending the proof to all pairs x, xj ∈ [0, a] is straightforward.
Finally, claim (7) also follows from the assumptions that a ≤	K	′ and |Q|≤ 1.
M (1+nM )
Thus, the proof is complete.	2

Corollary 3.10 E2	′ (Q) ∈ [0, a] ⇒ I[−K, K]n, i. e., E2
′ (Q) is Euclidean-

(u,u )
Scott continuous.
(u,u )

Proof. By Lemma 3.9, for each j ∈ {1,..., n}, yj is lower semicontinuous, and yj
is upper semicontinuous, since they are both continuous. As a result, E2	′ (Q) is
(u,u )
Euclidean-Scott continuous.	2
Proposition 3.11 (Soundness) Assume that z : [0, a] → [−K, K]n is a classical solution of (1). Then:
∀x ∈ [0, a]:	E2	′ (Q)(x) ± z(x).

(u,u )
Proof. Assume that Q = (q0,..., qk) ∈ P1, and let y ≡ E2
′ (Q). By induction

on i, we show that:
(u,u )

∀i ∈ {0,..., k} :	y T [0, qi] ± z T [0, qi].
The base case of i = 0 is immediate. For the inductive step, let x ∈ (qi, qi+1]. As z
is a solution of (1), it satisfies zj = f (z). By Corollary 2.14, we have:


z(q )+ (x −	j
1	− q )2ILˆ(zj)([q , x]) ± z(x).	(9)

i	qi)z (qi)+ 2 (x	i	i
Furthermore, from the Chain rule of [9, Lemma 3.3], we have (ILˆ(f ) ·
If )(Iz([qi, x])) ± ILˆ(zj)([qi, x]). Thus, from (9) we deduce:


z(q )+ (x −
1	− q )2(ILˆ(f ) · If )(Iz([q , x])) ± z(x).	(10)

i	qi)f (z(qi)) + 2 (x	i	i
Furthermore, as | zj | is bounded by M , by the mean value theorem, we have: z(θ) ∈
Iz(qi) ⊕ (x − qi)M ⊆ y(qi) ⊕ ΔqiM , for any θ ∈ [qi, x]. Thus:
y(qi) ⊕ ΔqiM ± Iz([qi, x]).	(11)


Thus, we may write:
x
y(x)= y(qi)+ 
qi


u (y(qi)) + (t − qi)(uj


· u) (y(qi) ⊕ ΔqiM ) dt

(induction hypothesis and (11))

± z(qi)+ 
x
u (z(qi)) + (t − qi)(uj
qi
· u) (Iz([qi, x])) dt

 u and uj domain extensions of f and Lˆ(f ) 

± z(qi)+ 
x
f (z(qi)) + (t − qi)(ILˆ(f ) · If )(Iz([qi, x]))dt
qi

= z(q )+ (x −
1	− q )2(ILˆ(f ) · If )(Iz([q , x]))

i
(by (10))
± z(x).
qi)f (z(qi)) + 2 (x	i	i


2

Convergence Analysis
In this section, the completeness of the second-order method will be established. In other words, we will show that, it is possible to approximate the solution of the IVP (1) to any required accuracy. Naturally, to obtain higher accuracy in the results, the second-order operator shall require finer approximations of the field f
and its derivative Lˆ(f ), together with finer partitions of the interval [0, a].
First, in Subsection 4.1, we present convergence results for the case where an in- terval extension (u, uj) of the pair (f, Lˆ(f )) is provided. From a Turing computabil- ity angle (e. g., within the framework of Type-II Theory of Effectivity (TTE) [31]) this assumption is unrealistic, because interval extensions of (f, Lˆ(f )), as defined in Definition 2.6, need not be finitely-representable. Thus, in Subsection 4.2, we will present convergence results for the case where we have approximations, rather than extensions, of the field and its derivative.
Remark 4.1 Note that we have assumed Mj > 0, as introduced in (3). This will help us avoid division by zero in some of our analyses in the current section. The case Mj = 0 arises only when the vector field f is constant, in which case the IVP (1) may be solved trivially using symbolic computations.

Interval extension of the vector ﬁeld
Recall that (u, uj) ∈ V1 is assumed to be a domain extension of (f, Lˆ(f )), satisfying assumption (4):
Proposition 4.2 Assume that Q = (q0,..., qk) is a partition of [0, a] and let L ·=
nMj. Then:
2	2	|Q|2LM

Proof. Let y ≡ E2	′ (Q). We have:

(u,u )

w(y(x)) ≤ w(y(qi)) +

x
w (u (y(qi))) + w
qi

 (t − qi)(uj

· u) (y(qi) ⊕ ΔqiM ) dt

(by assumption (4))

≤ w(y(qi)) +
x
 uj(y(qi))  ∞ w(y(qi))dt +
qi
|Q|2LM
x
(t − qi)LMdt
qi

≤ w (y(qi)) (1 + |Q|L)+	2	.
2
Corollary 4.3 (Speed of convergence) For any partition Q ∈ P1, we have:


2
(u,u )

(Q) 
1
≤ |Q|M e	− 1 .	(12) 2

In particular, when Q is equidistant:


2
(u,u )
(Q) 
1
≤ |Q|M e	− 1 .	(13) 2

Proof. Assume that Q = (q ,...,q ), and let c ·= |Q|2LM , d = 1 + |Q|L. We prove
0	k	2
by induction on i that:
Σ
	 


The case of i = 0 is immediate from Proposition 4.2 and the fact that w(y(q0)) = 0. For i > 0, again, by Proposition 4.2, we have:
w E2	′ (Q)(x) ≤ w E2	′ (Q)(x) · d + c

(u,u )
(u,u )
(by induction hypothesis)




Thus, we obtain:
 

	
≤ ⎛⎝c


Σ

i—1 j=0
dj⎞⎠ d + c = c


dk − 1



Σj=0

dj.

= 1 |Q|M  (1 + |Q|L)k − 1 

= 1 |Q|M  (1 + m(Q)r
2	Q
L)k − 1 

1	"	a

	

 k	#



≤ 1 |Q|M 2
 earQL
— 1 ,

which proves (12). Inequality (13) now follows, because for an equidistant Q, we have rQ = 1.	2
Remark 4.4 In [10], it was explicitly required that u satisfy an interval Lipschitz condition. In the current paper, by assuming uj to be bounded, we get a global interval Lipschitz constant of L = nMj.
Let us briefly compare the speed of convergence of the second-order E2 and the first-order E, as expressed in [10, Proposition 7]. As can be seen, the worst case

estimates for E2 and E are all but the same, save for a factor of 1
which does

not appear in [10, Proposition 7]. This is because we had to consider the global interval Lipschitz constant L = nMj to obtain the various estimates. Nonetheless, we believe that in practice, E2 exhibits better convergence properties, as the second- order method uses the local Lˆ-derivative of the vector field rather than the global
Lipschitz constant.

From Proposition 3.11 (soundness), Corollary 4.3 (convergence), and the fact that S is bounded complete, we obtain:
Theorem 4.5 (Completeness) Suppose (Qn)n∈N is a sequence of partitions sat-
isfying limn→∞ |Qn| = 0. Then E2	′ (Qn)	is a bounded set, hence it has a
supremum y = [y, y] = .n∈N E2	′ (Qn), which satisﬁes w(y) = 0, and y = y is a
Approximations of the ﬁeld
As already mentioned, in an effective framework, such as TTE, one may only work with ﬁnitely-representable approximations of the field f and its Lˆ-derivative Lˆ(f ). Being finitely-representable depends on the chosen language, and how the strings of the language are mapped into objects of the semantic model.
Recall that, for any given domain D and element d ∈ D, the set:
⇑ d ·= {x ∈ D d ≥ x}
is a Scott-open subset of D. As such, for any pair of domains D and E, and elements d ∈ D and e ∈ E, from Definition 2.8 we obtain the single-step function eχ⇑d : D → E which satisfies:


∀x ∈ D :	eχ⇑d
·= ⎧ e, if d ≥ x,
⎩ ⊥, otherwise.

In IRn , the way-below relation ≥ satisfies: ∀a, b ∈ IRn : a ≥ b  ⇐⇒  b ⊆ a○,
⊥	⊥
in which, a○ denotes the interior of a. Thus, for any a, b ∈ IRn , the single-step

function bχ⇑a may be expressed as:

∀x ∈ IRn :	bχ⇑a(x) ·=

⎧ b,  if x ⊆ a○,
⎩ ⊥, otherwise.


In the framework of the current paper, a map v : I[−S, S]n → I[−T, T ]m may be considered finitely-representable if it is the supremum of a finite set of single- step functions (eiχ⇑di )i∈I , where each di is an n-dimensional hyper-rectangle in [−S, S]n with rational coordinates, and each ei is an m-dimensional hyper-rectangle in [−T, T ]m with rational coordinates.
Hence, instead of assuming that an extension of (f, Lˆ(f )) is given to us, we assume that we can obtain approximations of an extension (u, uj) of (f, Lˆ(f )) to
within any degree of accuracy. For instance, we may assume that we are given a sequence (un, uj )n∈N in V1 satisfying:
∀n ∈ N : (un, uj ) ± (u, uj).
limn→∞ d(un, u) = 0 and limn→∞ d(uj , uj) = 0, in which d is the interval
distance function of Definition 2.3.

Proposition 4.6 (Monotonicity of E2 in (u, uS)) Assume	that
(u1, uj ), (u2, uj ) ∈ V1, and (u1, uj ) ± (u2, uj ).	Then, for any given partition
1	2	1	2
Q ∈ P1, we have E2	′ (Q) ± E2	′ (Q).
(u1,u1)	(u2,u2)
Proof. The proof follows immediately from monotonicity of interval integration in (u, uj).	2
This shows that tighter enclosures of (f, Lˆ(f )) provide more accurate enclosures of the solution of (1). For computational purposes, however, we need not just monotonicity, but continuity:
Proposition 4.7 (Continuity of E2 in (u, uS)) Assume that (uj, uj )j∈J is a di-
rected set in V1, and let (u, uj) ·= .	(uj, uj ). Then E2	′ = .	E2	′ .
Proof. For a partition Q = (q0,..., qk) ∈ P1, to avoid clutter, we write y ≡

E2	′ (Q), and yj ≡ E2
′ (Q). We will prove, by induction on i ∈ {0,..., k},

(u,u )
that:
(uj ,uj )



y T [0, qi]=	yj T [0, qi].	(14)
j∈J



For i = 0, we obtain (14) from Definition 3.7. Thus, assume that 0 ≤ i < k, and that (14) has been proven up to i. By induction hypothesis, we have y(q ) = 
.j∈J yj(qi), which also implies that:


y(qi) ⊕ ΔqiM =	(yj(qi) ⊕ ΔqiM ) .	(15)
j∈J


Hence, using the interchange-of-suprema law [1, Proposition 2.1.12], for any x ∈
[qi, qi+1], we obtain:

.	. "	∫ x	j	#

(continuity of addition)
.	. "∫ x	j	#

(continuity of integration)
∫ x .	j

(interchange of suprema)


= y(qi)+ 
∫ x .
uj ⎛⎝ .
yj(qi)⎞⎠

qi j∈J
j∈J

+(t − qi)( . uj · . uj) ⎛⎝ . (yj(qi) ⊕ ΔqiM )⎞⎠ dt

j∈J
j∈J
j∈J

(by assumptions and (15))
∫ x	j

(by Definition 3.7)
= y(x).
2
We can now show that, it is possible to obtain the solution of (1) by providing tighter approximations of (f, Lˆ(f )), and finer partitions:
Corollary 4.8 Assume that (un, uj )n∈N is a sequence in V1 which satisﬁes (u, uj)= 

.n∈N
(un, uj ), and let (Qn)n∈N be a sequence of partitions in P1 such that

limn→∞ |Qn| =0 . Then .n∈N E2	′ (Qn) is real-valued and satisﬁes (1).
(un,un)
Proof. Follows from Proposition 4.7 and Theorem 4.5, and another application of the interchange-of-suprema.	2
Next, we present some estimates on the speed of convergence, in the presence of approximations of the vector field:
Lemma 4.9 Assume that Q = (q0,..., qk) ∈ P1 is a partition and (u1, uj ) ±
(u, uj). Furthermore, deﬁne d ·= d (u1, u) and dj ·= d(uj , uj), where d is the interval
distance function of Deﬁnition 2.3. Then:

∀x ∈ [qi, qi+1]:	w E2	′ (Q)(x)  ≤ w E2
′ (Q)(qi) δ + ξ,



in which:
δ =1 + |Q|L	and	ξ = |Q|d +

(M + d)(L + ndj)|Q|2
.
2

Proof. To avoid clutter, we let y1 ≡ E2
′  (Q) and A1 ≡ y1(qi)⊕ΔqiM . Following

Definition 3.7, we have:

"∫	x
(u1,u1)
j	#

w(y1(x)) ≤ w(y1(qi)) + w
∫ x



u1 (y1(qi)) + (t − qi)(u1 · u1) (y1(qi) ⊕ ΔqiM ) dt
qi




∫ x	j



j	j 

≤ w(y1(qi)) +
x
(L w(y1(qi)) + d) dt +
qi
x
(t − qi) n(Mj
qi
+ dj)(M + d)dt

≤ w(y1(qi)) + L|Q| w(y1(qi)) + |Q|d +
n(Mj + dj)(M + d)|Q|2
2

= w(y1(qi)) (1 + L|Q|)+ |Q|d +
(L + ndj)(M + d)|Q|2
.
2

This completes the proof.	2
Corollary 4.10 With the same assumptions as in Lemma 4.9, we have:

2 (u1,u1)
(Q) ≤		ξ L|Q|
 earQL − 1 .

In particular, when Q is equidistant:

2 (u1,u1)
≤		ξ L|Q|
 eaL − 1 .

Proof. Similar to the proof of Corollary 4.3.	2
At this point, we should point out that there are indeed two independent factors that affect the speed of convergence. Yet, Corollary 4.10 implies that, it suffices to assume that the approximations to u converge at the same rate as the norm of the partitions tend to zero. We also need d(uj , uj) to be bounded, but that is alway the
case as d(uj , uj) ≤ 2Mj:
Theorem 4.11 Let (Qn)n∈N  be a sequence of partitions in P1  satisfying

limn→∞ |Qn| = 0. Furthermore, assume that (u, uj)= .
n∈N
(un, uj ), and for some

constant C1 > 0, we have d(un, u) ≤ C1|Qn|. By letting yn ≡ E2
′ , we obtain:

∃C2 ≥ 0, ∀n ∈ N :	w(yn) ≤ C2|Qn|.
n∈N yn is real-valued and is a solution of (1).
Proof. Note that:
(un,un)

ξ L|Q|
 2d(un, u)+ (M + d(un, u))(L + nd(uj , uj))|Qn|
=	.
2L

Now, the result follows from Corollaries 4.10 and 4.8.
2

As an example, consider the case where successive partitions Qn+1 are ob- tained by bisecting Qn, and the approximations to (u, uj) satisfy d(un, u) ≤ 2—n. In such a scenario—which is common in arbitrary precision floating-point interval arithmetic—Theorem 4.11 is applicable.
Complexity Analysis
In this article, a domain-theoretic framework has been adopted within which sound- ness and completeness results have been obtained, together with explicit upper bounds on the rate of convergence. A further useful feature of the domain-theoretic framework is that the algorithms may be directly implemented, with the conver- gence results retained, and with accuracies limited only by the time and space (i. e., memory) resources available. This should be contrasted with:
floating-point based methods that are inherently inaccurate;
methods based on traditional interval libraries, which use fixed-precision floating- point numbers as end-points. These methods can guarantee soundness, but not completeness, even theoretically. The reason is that the precision of the end- points are limited by the bit size used in the underlying architecture (e. g., 32 bits, 64 bits, etc.).
For computation purposes, a domain must be augmented with an effective struc- ture:
Definition 5.1 [Effectively given domain [13]]
Let (D, ±) be an ω-continuous domain with a bottom element ⊥, and assume that B is a countable base for D, enumerated as B = {b0, b1, b2,.. .}, in which b0 = ⊥. The domain D is said to be effectively given with respect to the enumeration b iff the set {(m, n) ∈ N2 | bm ≥ bn} is recursively enumerable (r. e.).
An element x ∈ D of an effectively given domain is computable if and only if the set Bx ·= {m ∈ N | bm ≥ x} is r. e.. For the interval domain I[a, b] with a, b ∈ Q, one may choose B to be the set of intervals in [a, b] with rational end- points. Under any reasonable enumeration of B, the set {(m, n) ∈ N2 | bm ≥ bn} should be recursive. Indeed, for two intervals x = [x, x], and y = [y, y], we have x ≥ y  ⇐⇒ x < y ≤ y < x. This extends to interval domains of the form I[a, b]n, again, with a, b ∈ Q. Here, the set of n-dimensional rectangles with rational vertices provides a countable base B, and the relation ≥ also turns out to be decidable on B × B under any reasonable enumeration. For x, y ∈ I[a, b]n we have: x ≥ y ⇐⇒ y ⊆ x○.
Notation 5.2 (I[a, b]nD) Assume that D is a dense subset of R. By I[a, b]nD we denote the set of all n-dimensional rectangles in I[a, b]n whose vertices lie in D.
Thus, by taking D ≡ Q, we obtain the base I[a, b]nQ for the interval domain I[a, b]n. We need to present bases for the spaces S and V1. In [10], where the first-order Euler operators of Definition 3.1 were studied, the set of functions whose upper and lower bounds form piecewise affine functions provided the suitable base for S. For

the second-order Euler operator, from (5) it can be seen that, in general, we need piecewise quadratic functions:
Definition 5.3 [S2] The set S2 of piecewise Q-quadratic functions of type [0, a] →
Q	Q
I[−K, K]n is defined as the set of functions f : [0, a] → I[−K, K]n satisfying the
following conditions:

For every j ∈ {1,..., n}, if we write the j-th component of f as fj = [fj, fj], then both fj and fj are continuous over [0, a].
There exist rational numbers 0 = q0 < q1 < . . . < qk = a, such that, for all i ∈ {1,..., k}, the restrictions to [qi—1, qi] of fj and fj—denoted fji and fji, respectively—are quadratic with rational coefficients. In other words, there exist αji, αji, βji, βji, γji, γji ∈ Q such that:

  fji(x)= αjix2 + βjix + γji,


Trivially, piecewise quadratic functions include piecewise affine functions. Hence, the following follows directly from [10, Section 5]:

Proposition 5.4 The set S2
forms a base for S.

Indeed, it is not difficult to verify that an effective structure may be provided over S with respect to the base S2 . We do not need this fact in the current paper, so we move on to the discussion of a base for V1.
In [10], for the first-order Euler operators, the field was taken to be an element of the domain V, as in Notation 2.5. The set comprising supremums of finite sets of single-step functions of the form 1≤j≤k γj χ⇑βj provides a base for V. For the second-order operator, we need the information about both the field and its
Lˆ-derivative. By referring to Definition 3.3, it may be seen that, in general, we
need to consider pairs .	γj χ⇑β , .	′ γj χ⇑β′  comprising supremums of


I[−	j
j n2

are defined over the same set of boxes:
Definition 5.5 [V 1] The set V1 is defined as the set of elements of V1 of the form:
Q	Q
⎛⎝ . γj χ⇑β , . γj χ⇑β ⎞⎠

in which k  ∈  N, β1,..., βk  ∈  I[−K, K]nQ, γ1,..., γk  ∈  I[−M, M ]nQ, and,
γj ,..., γj ∈ I[−Mj,Mj]n2  .
1	k	Q
Proposition 5.6 The set V1 forms a base for V1.
Proof. See [8].	2

Remark 5.7 The domain V1 may also be equipped with an effective structure with respect to the base V1 . The details may be found in [8, Section 3].

The bases S2
and V1
were chosen with the following in mind, which should be

straightforward to verify:
All the elements of S2

and V1

are finitely-representable.

Given Q ∈ P1,Q and (u, uj) ∈ V1 , the result of applying the second-order Euler
operator, i. e., E2	′ (Q), is an element of S2 .
(u,u )	Q
These properties make it easier to implement and analyze the second-order oper- ator. For instance, in what follows, we will analyze the algebraic complexity of the second-order Euler operator. In other words, we will obtain an estimate of the significant number of operations related to the given partitions and elements of the relevant bases. This provides a prequel to future analyses of the bit-complexity of the method. First, we need the following notation:
Definition 5.8 [N (Q), N (uˆ)]
For any given partition Q ≡ (q0,..., qk), we let N (Q) ·= k.
For a given element uˆ ≡ (.	γj χ⇑β , .	γj χ⇑β ) ∈ V1 , we let
Proposition 5.9 (Algebraic complexity) For any given Q = (q0,..., qk1 ) ∈ P1,Q and
uˆ ≡ (u, uj)=( .	γj χ⇑β ,	.	γj χ⇑β ) ∈ V1 ,

E2	′ (Q) can be computed in O N (Q)N (uˆ) algebraic steps.
(u,u )
Proof. As before, let us write y ≡ E2	′ (Q), and assume that we have calculated
(u,u )
y T [0, qi—1] for some 0 < i ≤ k1. To extend the calculation over the interval [qi—1, qi], we follow (5). We fix an index 1 ≤ j ≤ n, and compute the j-th component yj over [qi—1, qi]. As Ai ·= y(qi—1)⊕Δqi—1M is constant, i. e., independent of the integration variable t, in order to obtain u(Ai), we need to compare Ai with each βj, for all 1 ≤ j ≤ k2. This takes O(k2) algebraic steps. A similar argument shows that uj(Ai) and u(y(qi—1)) may be obtained in O(k2) algebraic steps.
Focusing on the j-th component, we get the intervals:
ρji ·= y(qi—1) ;
νji ·= u(y(qi—1)) ;
σji ·= (uj · u) (y(qi—1) ⊕ Δqi—1M )  .
If we denote the j-th component of y T [qi—1, qi] by yji = [yji, yji], then we obtain:


			

∀x ∈ [qi—1, qi]: 
2
yji(x)= 1 σji(x − qi—1)2 + γji(x − qi—1)+ ρji.

We need to obtain the relevant quadratic enclosures for all the subintervals in Q.
Hence, E2	′ (Q) may be computed in O(k1k2) algebraic steps.
(u,u )
2
Concluding Remarks
We presented a domain-theoretic framework for solving IVPs using the second-order Euler method. The soundness and completeness results were obtained, together with some upper bounds on the algebraic complexity of the method. Although we focused on the second-order Euler method, in the light of Corollary 2.14, extension to any n-th order is possible.
In the current paper, we focused on the theoretical underpinnings of the Euler method for solving IVPs. In particular, the results demonstrate the power of domain theory, and present another application for the domain of Lipschitz functions.
Our next step will be to shift the focus to the experimental side, and compare the performance of the second-order Euler method with the first-order Euler method, and also with the Picard method. Furthermore, it will be interesting to see how n-th order Euler methods compare with one another. Intuitively, higher-order Euler methods should have better convergence properties. Yet, raising the order comes with an overhead of computations. For instance, in the current paper, we have seen that, compared with the first-order Euler method, the second-order method requires more computations in order to handle the information about the Lipschitz properties of the field, something which was not needed in the first-order method. Thus, it is conceivable that after a certain order, the gain in convergence properties will be offset by the computation overhead.

References
Abramsky, S. and A. Jung, Domain theory, in: S. Abramsky, D. M. Gabbay and T. S. E. Maibaum, editors, Semantic Structures, Handbook of Logic in Computer Science 3, Clarendon Press, Oxford, 1994 pp. 1–168.
Berz, M. and K. Makino, Verified integration of ODEs and flows using differential algebraic methods on high-order Taylor models, Reliable Computing 4 (1998), pp. 361–369.
Clarke, F. H., “Optimization and Nonsmooth Analysis,” Classics in Applied Mathematics, Society for Industrial and Applied Mathematics, 1990.
Duracz, J., A. Farjudian, M. Koneˇcny´ and W. Taha, Function interval arithmetic, in: H. Hong and
C. Yap, editors, Mathematical Software – ICMS 2014, Lecture Notes in Computer Science 8592 (2014),
pp. 677–684.
Edalat, A., Domains for computation in mathematics, physics and exact real arithmetic, Bull. Symbolic Logic 3 (1997), pp. 401–452.
Edalat, A., A continuous derivative for real-valued functions, in: S. B. Cooper, B. Lo¨we and A. Sorbi, editors, New Computational Paradigms: Changing Conceptions of What is Computable (2008), pp. 493–519.
Edalat, A. and A. Lieutier, Domain theory and differential calculus (functions of one variable), in: Proceedings of 17th Annual IEEE Symposium on Logic in Computer Science (LICS’02), Copenhagen, Denmark, 2002, pp. 277–286.
Edalat, A., A. Lieutier and D. Pattinson, A computational model for multi-variable differential calculus, Information and Computation 224 (2013), pp. 23–45.

Edalat, A. and D. Pattinson, Inverse and implicit functions in domain theory, in: Proceedings. 20th Annual IEEE Symposium on Logic in Computer Science (2005), pp. 417–426.
Edalat, A. and D. Pattinson, A domain theoretic account of Euler’s method for solving initial value problems, in: J. Dongarra, K. Madsen and J. Wa´sniewski, editors, PARA, Lecture Notes in Computer Science 3732, 2006, pp. 112–121.
Edalat, A. and D. Pattinson, Denotational semantics of hybrid automata, The Journal of Logic and Algebraic Programming 73 (2007), pp. 3–21.
Edalat, A. and D. Pattinson, A domain-theoretic account of Picard’s theorem, LMS Journal of Computation and Mathematics 10 (2007), pp. 83–118.
Edalat, A. and P. Su¨nderhauf, A domain theoretic approach to computability on the real line, Theoretical Computer Science 210 (1999), pp. 73–98.
Escardo, M. H., PCF extended with real numbers, Theoretical Computer Science 162 (1996), pp. 79– 115.
Farjudian, A. and M. Koneˇcny´, Time complexity and convergence analysis of domain theoretic Picard method, in: W. Hodges and R. de Queiroz, editors, Proceedings of WoLLIC ’08, Lecture Notes in Artificial Intelligence 5110 (2008), pp. 149–163.
Gierz, G., K. H. Hofmann, K. Keimel, J. D. Lawson, M. W. Mislove and D. S. Scott, “Continuous Lattices and Domains,” Encyclopedia of Mathematics and its Applications 93, Cambridge University Press, 2003.
Higham, N. J., “Accuracy and Stability of Numerical Algorithms,” Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 2002, second edition.
Imbert, C., Support functions of the Clarke generalized Jacobian and of its plenary hull, Nonlinear Analysis: Theory, Methods & Applications 49 (2002), pp. 1111––1125.
Iserles, A., “A First Course in the Numerical Analysis of Differential Equations,” Cambridge Texts in Applied Mathematics, Cambridge University Press, 2009.
Kawamura, A., Lipschitz continuous ordinary differential equations are polynomial-space complete, in:
CCC ’09: 24th Annual IEEE Conference on Computational Complexity, 2009, pp. 149–160.
Koneˇcny´, M., J. Duracz, A. Farjudian and W. Taha, Picard method for enclosing ODEs with uncertain initial values, in: Proceedings of the Eleventh International Conference on Computability and Complexity in Analysis (CCA 2014), Technische Universit¨at Darmstadt, Germany, 2014, pp. 41– 42.
Moggi, E., A. Farjudian, A. Duracz and W. Taha, Safe & robust reachability analysis of hybrid systems, Theoretical Computer Science 747 (2018), pp. 75–99.
Moggi, E., A. Farjudian and W. Taha, System analysis and robustness, in: T. Margaria, S. Graf and K. G. Larsen, editors, Models, Mindsets, Meta: The What, the How, and the Why Not? Essays Dedicated to Bernhard Steffen on the Occasion of His 60th Birthday (2019), pp. 36–44.
Moore, R. E., “Interval Analysis,” Prentice-Hall, Englewood Cliffs, New Jersey, USA, 1966.
Moore, R. E., R. B. Kearfott and M. J. Cloud, “Introduction to Interval Analysis,” Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 2009.
Mu¨ller, N. and B. Moiske, Solving initial value problems in polynomial time, in: Proc. 22 JAIIO - PANEL ’93, Part 2, 1993, pp. 283–293.
Nedialkov, N., K. Jackson and J. Pryce, An effective high-order interval method for validating existence and uniqueness of the solution of an IVP for an ODE, Reliable Computing 7 (2001), pp. 449–465.
Rudin, W., “Principles of Mathematical Analysis,” McGraw-Hill, 1976, 3 edition.
Teschl, G., “Ordinary Differential Equations and Dynamical Systems,” Graduate studies in mathematics, American Mathematical Society, 2012.
Tucker, W., “Validated Numerics: A Short Introduction to Rigorous Computations,” Princeton University Press, 2011.
Weihrauch, K., “Computable Analysis, An Introduction,” Springer, 2000.
