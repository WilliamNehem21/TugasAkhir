

Electronic Notes in Theoretical Computer Science 225 (2009) 421–439
www.elsevier.com/locate/entcs
Functionally-Generalised MOQA Operations
Thierry Vallee1,2
Dept. of Mathematical Sciences Georgia Southern University Georgia, United States

Abstract
The programming language MOQA was designed by Michel Schellekens in [5,7] specifically to facilitate the average execution time analysis of its programs. MOQA is based on a special data structure and an associated suite of operations. This special data structure, said here as labeled partial orders (lpo), is a pair (P, l) such that P = (X, ±) is a poset and l : X '→ L a strictly increasing bijection between
X and a totally ordered set L. MOQA basic operations are defined on lpo’s under some restrictions. These restrictions guarantee the main property of MOQA’s operations, said here as Automatic Random Preservation. Random Preservation (RP) is a fundamental property used to calculate the average time of programs, opening the way to a (semi-)automation of this calculation in MOQA.
In the paper, we introduce functionally-generalised versions of some MOQA basic operations. Those ver- sions are defined with more natural restrictions and in a more general way than the correspondent MOQA operations. As a consequence of their greater generality, they are not RP on all their domains in con- trast to MOQA operations. Nevertheless, they have two good properties. The first one is that they have the intended semantics. For instance, the generalised split actually splits any lpo into two parts using a label as a pivot. The second one is that the subdomains on which they are RP are strictly bigger than the domains where MOQA basic operations are defined and RP. A tractable characterisation of those RP subdomains is an open problem and its solution would be an important step toward an implementation of the functionally-generalised operations as Automatic RP operations.
Keywords: Posets, Average Execution Time, Program Semantics, Data Structure Operations


Introduction
MOQA is a new programming language, based on a kernel of basic operators, intro- duced by M. Schellekens in order to facilitate the Average Execution Time Analysis (A-ETA) of its programs (cf. [5,7,4,6,8]). The design of MOQA is developed in [5,7] where the semantics of the basic operators is given via operations, refered here as basic MOQA operations. In this article, we present functional-generalisations of three of these operations: the projection, the unary product and the split.
A first motivation for developing MOQA was that, according to the literature (see for instance [2,3,5]), A-ETA of programs is much harder than the worst case

1 Research supported by Science Foundation Ireland under Grant 02/IN.1/181
2 Email: vallee th@yahoo.fr

1571-0661/© 2008 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.12.090

execution time analysis (WC-ETA). A-ETA leads to complex techniques without satisfactory generality. The second remark is that, curiously and in contrast to worst case, average time has a good property which helps the timing: compositionality.
In order define compositionality, we recall first that a multiset or bag is a collec- tion which allows copies of the same element. For example, {a, a, b} is a multiset. Multisets are used to store the outputs of programs. For instance, the output mul- tiset of the addition on the set I = {3, 1}2 is the set O+(I) = {4, 4, 2, 6}. Then compositionality of average time is expressed by the following equation easily in- fered from the definition of average time, where P ; Q is the program obtained by the concatenation of P and Q, and T¯P (I) is the average execution time of the program
P on I: T¯P ;Q(I) = T¯P (I)+ T¯Q(OP (I)).
Compositionality allows the determination of the average time of a complex program by analysing its sub-programs. It facilitates timing modularity since the analysis of T¯Q(OP (I)) can be reused. So a question arises: why is A-ETA so com-
plex? A closer look to OP (I) gives an answer. Indeed, even when I is uniformly distributed, OP (I) is generally not. For instance {3, 1}2 contains one copy of each pair of integers while {4, 4, 2, 6} contains two copies of 4 and only one copy of 2 and
6. Moreover, there is no general control on the distribution of the outputs. These two facts makes it difficult and hard to predict the calculation of T¯Q(OP (I)). So the approach of [5,7] was to design the basic operations of MOQA in order to obtain a general control on the multiplicities (number of copies) of the outputs of those
operations. The control relies also on the particular data structure used by MOQA, said here as labeled partial orders (lpo’s). A lpo is a pair (P, l) such that P = (X, ±) is a poset and l : X '→L is a strictly increasing bijection between X and a totally ordered set of labels L. The bijection l is said here as a labeling. Intuitively, a lpo
is twofold: it contains a list of labels, which may be the relevant information for the programmer, and a partial order, used in particular by the system running MOQA to keep a control on the output multiplicities. A Random Structure (RS) is the set
of all lpo’s for a given P and a given L. The essential property of MOQA basic
operations is that they allow a control on the multiplicities of the outputs as soon as the inputs form a Random Structure (RS). That property is said here as Random Preservation (RP).
Nevertheless, the MOQA projection, unary product and split operations are defined under some unusual restrictions on the lpo’s. Although, these restrictions guarantee the RP of MOQA’s operations on their domains, they have some un- wanted side effects. First, they make programming harder for the programmer who must be careful with both the semantics and the RP of his programs. Moreover, the restrictions prevent a free modularity of programs. Indeed, suppose that the programmer had written a program Q and that he wants to re-use it, for instance, in the program P ; Q. Even if P and Q are semantically correct, that is, they compute independently the intended functions, the good conditions allowing the application of MOQA’s operations of Q may have been destroyed by the previous operations of P , making the execution inside Q impossible in P ; Q.
Thus, it seems to be of interest to separate the semantics correctness of MOQA’s

programs from their RP correctness. For that we introduce generalised versions of the projection, unary product, and split, which are defined for labelings under nat- ural programming conditions. As a consequence of this generality, these operations are not RP on all their domains of definition. Nevertheless, they have two good properties. First, they behave as expected, that is, they have the same behavior as the corresponding MOQA operations. For instance, the generalised split actually splits the set of labels into two parts using the first label as a pivot. Second, they also generalise Random Preservation since they are RP on parts of their domains where the MOQA basic operations are not defined and so a fortiori not RP.
In Section 2, we present several notions, in particular the notion of Random Preservation. Note that we will introduce a distinction between Random Preserva- tion and Automatic Random Preservation, a distinction which is not done in [5,7]. In Section 3, we define the notions of isolated subsets of a poset and local trans- formation. Isolated subsets are used in particular to express the restrictions on the applicability of MOQA operations. Then in Section 4, we introduce MOQA operations and their generalisations. Finally, Section 5 we discuss the RP property of the generalisations. We remark that this article is essentially self-contained. In particular we introduce the notions from [5,7] we need.

Prelimanaries
In this section we introduce some notations and operations on posets and lpo’s, we then introduce posets as special case of directed graph. Finally, we recall the key notions of labeling, random structures and random preservation.

General notations
We will use N to denote the set of positive integers. We will use P to denote a poset, XP to denote the ground set of P , or simply X when there is no ambiguity, and ±P or ± to denote the partial order (p.o.) on XP .
Definition 2.1 Let X, Y be sets, R be a binary relation on X and P = (X, R):
X \ Y = {x ∈ X : x ∈/ Y }
X ⊆f Y to express that X ⊆ Y and X is finite.
Card(X) will denote the cardinal of the set X.
ΔX = {(x, x) : x ∈ X}
R T Y = R ∩ Y 2;	P T Y = (Y, R T Y )
Dom(R) = {x : ∃y, xRy};	Codom(R) = {y : ∃x, xRy}
Let X, Z two sets and f a function, we note Codom(f ) by f (X) and:
f ² Y = {(y, f (y)) : y ∈ Y }
f : X '→ Z to express that X = Dom(f ) and f (X) ⊆ Z.
f : X ‹→ Z to express that X ⊆ Dom(f ) and f (X) ⊆ Z.

Definition 2.2 Let P = (X, ±) be a poset, y ∈ X and Y ⊆ X. The following sets are respectively the ceiling, floor of y in P :
[y|P = {x ∈ X \ {y} : y ± x ∧ ∀z ∈ X (y ± z ± x ⇒ z = x ∨ z = y)}
[y♩P = {x ∈ X \ {y} : x ± y ∧ ∀z ∈ X (x ± z ± y ⇒ z = x ∨ z = y)}
For Y ⊆ P , define [Y |P = ∪y∈Y [y|P and [Y ♩P = ∪y∈Y [y♩P .
We drop the index P in the notations above as soon as there is no ambiguity on the poset P . A similar convention is used whenever a subscript can be removed without loss of clarity. We define now the Hasse Diagram of a poset.
Definition 2.3 For every poset P = (X, ±), the Hasse Diagram of P is the pair (X, ≺) where the binary relation ≺ is defined on X2 by: x ≺ y iff x ∈ [y♩.
Remark 2.4 Clearly ≺ ⊆± and moreover: x ± y iff there exists x1,... xn ∈ X
such that x = x1 ≺ x2 ≺ ... ≺ xn = y.
Definition 2.5 An atomic poset is a poset of the form AY = (Y, ΔY ).

Posets as (simple) directed graphs
It is convenient to interpret posets as particular cases of (simple) directed graphs defined here as pairs (X, R) where R is a binary relation on X. The (undirected) graph underlying a digraph (X, R) is the graph with vertices X and edges the pairs e = {x, y} such that (x, y) ∈ R. A path linking two nodes x, y in a graph is an alternative sequence x = x1e1x2 ... xnenxn+1 = y such that, for every i ∈ {1,..., n}, ei = {xi, xi+1}. We write x × y when two nodes are linked by a path. We recall that a subset Y of a graph is connected if x × y for all distinct x, y ∈ Y , and a component if it is maximal connected.
Definition 2.6 Y ⊆ X is zigzag closed in the digraph (X, R) if it is an union of components of the underlying graph, that is, if x ∈ X, y ∈ Y and x × y then x ∈ Y .

Simply-labeled digraph and labeled partial order
Definition 2.7 A simply-labeled digraph (sldg) is a pair (P, l) where P = (X, R) is a digraph and l : X '→ L is a bijection where L is a totally ordered set. A labeled partial order (lpo) is a sldg where P = (X, ±) is a poset and the bijection l is increasing, that is, for every x, y ∈ X, x ± y ⇒ l(x) ≤ l(y).
An useful and intuitive way to represent lpo’s (and sldg’s) is given in the example below. The poset is represented by its Hasse Diagram (reflexive and transitive edges are not drawn). Since the names of nodes are not relevant, they are simply represented by anonymous circles where the corresponding labels are written.
Example 2.8 Two lpo’s F1 = (P, l1) and F2 = (P, l2) with labels {1, 3, 4}, P = ({x, y, z}, {(x, z), (y, z)}), and l1(z) = l2(z) = 4, l1(x) = 1, l1(y) = 3, l2(x) = 3 

and l2(y) = 1:
The lpo F1	The lpo F2

4◯
/’ `
/	 
/	 
4◯
/’ `
/	 
/	 

1◯	3◯	3◯	1◯
We remark that F1 and F2 are the only possible lpo’s for P and {1, 3, 4}.
Definition 2.9 (P, l) T Y denotes the pair (P T Y, l ² Y ), for every sldg (P, l).
Remark 2.10 If l is a labeling on the poset (X, ±) and (X, ±') is a poset such that ±'⊆± then l is a labeling on (X, ±').

Random Structure and Random Preservation
A Random Structure (RS) is the set of all possible lpo’s for given poset P and set of labels L. It is denoted by RL(P ), or simply R. For instance Example 2.8 represents the RS on P = ({x, y, z}, {(x, z), (y, z)}) with L = {1, 3, 4}.
An operation or a program applied on different inputs may leed to the same output. In order to keep track of the number of inputs corresponding to a given output, the notion of output multiset is defined below. But first, we introduce multisets and two of their constructors.
Definition 2.11 A multiset is a function M : X '→ N \ {0}. For every set x, the multiplicity mulM (x) of x in the multiset M is defined as M (x) in case x ∈ X, and as 0 otherwise.
Definition 2.12 Let M , N be multisets, Z a set, and k ∈ N:
Z × k = {(x, k) : x ∈ Z}
M ⊕ N = {(x, k) : x ∈ Dom(M ) ∪ Dom(N ) ∧ k = mulM (x)+ mulN (x)}
Definition 2.13 Let Op be an operation and Z ⊆f Dom(Op), we define respec- tively the output set and output multiset of Op applied to Z as:
Op(Z) = {Op(x) : x ∈ Z}
OOp(Z) = {(y, k) : y ∈ Op(Z) ∧ k = Card(Op−1(y))}
Definition 2.14 Two RS’s are isomorphic if their underlying posets are.
Definition 2.15 An operation Op is Random Preserving (RP) on respectively a random structure R, a set of lpo’s F if:
There exist stricly positive integers n, K1,..., Kn and random structures
R1,... Rn such that:
OOp(R) = R1 × K1 ⊕ ... ⊕ Rn × Kn.
It is RP on every random structure R⊆ F.
If moreover the Ri’s are all isomorphic then the operation Op is said Strongly random preserving (SRP) on R (resp. on F if it is RSP on every R⊆ F).

Note that the MOQA unary product and split are RP on their domains while the projection is SRP (cf. [7]). But, as already mentioned these operations are more than simply RP in the above sense. Indeed, for each of these operations Op, there also exists a function able to compute from every RS R ⊆ Dom(Op) the integer n, the Ki’s and Ri’s of Definition 2.15. Thus, we speak of Automatic Random Preservation concerning MOQA basic operations. We will discuss again this notion in the Conclusion.

Isolated subsets and Local Transformation
From now on, it is convenient to work with a fixed infinite set O. We define D as the set of all finite digraphs with ground set X ⊆ O. We define similarly the set O of all finite posets with ground set X ⊆ O. We denote by S the sets of all sldg’s (P, l) with P ∈D and l such that Codom(l) ⊆ N. Finally, we denote by F the sets of all lpo’s (P, l) with P ∈O and l such that Codom(l) ⊆ N.

Isolated subset of a Poset
First we recall the definition of an isolated subset in [7]. Then we give the equivalent formulation we use. We recall that an element of a poset is minimal if it has no other element below it, it is maximal if it has no other element above it.
Definition 3.1 For all posets P and Z ⊆ Y ⊆ XP , we denote by mY (Z) the set of minimal elements of Z in the poset P T Y , and by MY (Z) the set of maximal elements of Z in the poset P T Y .
Definition 3.2 Let P = (X, ±) be a poset. A subset Y ⊆ X is:
Atomic in P if ±T Y = ΔY
Isolated in P if it satisfies the two following isolation conditions:
[Y \ mY (Y )♩⊆ Y and ∀x, y ∈ mY (Y ), [x♩ = [y♩
[Y \ MY (Y )|⊆ Y and ∀x, y ∈ MY (Y ), [x| = [y|
Atomic Isolated if atomic and isolated.
We give now a new notation and an equivalent characterisation of isolation.
Definition 3.3 For a poset P = (X, ±), x ∈ X and Y ⊆ X, we write x ± Y (resp.
Y ± x) to express that x ± y (resp. y ± x) for every y ∈ Y .
Lemma 3.4 A set Y ⊆ X is isolated in P = (X, ±) iff it veriﬁes:
For all x ∈ X\Y and y ∈ Y : x ± y implies x ± Y
For all x ∈ X\Y and y ∈ Y : y ± x implies Y ± x.
Proof. We prove that the isolation condition i of Definition 3.2 is equivalent the point i above. The fact that condition ii and point ii are equivalent can shown using a dual reasoning. The result follows trivially from these two equivalences.

We show first that condition i of isolation implies point i. Let x ± y, with x ∈ X \ Y and y ∈ Y . Let x1,..., xn ∈ X be a sequence given by Remark 2.4 such that x = x1 ≺ x2 ≺ ... ≺ xn = y. Let now i be the biggest index such that xi−1 ∈/ Y . We have n ≥ i ≥ 2 since x ∈/ Y , and xi ∈ mY (Y ) (otherwise we would have xi−1 ∈ [Y \ mY (Y )♩ ⊆ Y contradicting xi−1 ∈/ Y ). Let now y' ∈ Y . Clearly there is z ∈ mY (Y ) such that z ± y'. We get then xi−1 ∈ [z♩ since ≺⊆± and [z♩ = [xi♩ by isolation of Y . We conclude x ± y' by transitivity of ±.
Suppose now that Y verifies point i, we show that isolation condition i holds. We show first that i implies [Y \ mY (Y )♩ ⊆ Y .  Indeed let x ∈ [y♩ for some
y ∈ Y \ mY (Y ), and suppose x ∈/ Y .  Since y is not minimal in P T Y , there
exists y' ∈ Y distinct from y such that y' ± y. We have then x ± y' by point i with x /= y' since y' ∈ Y . That contradicts x ∈ [y♩, and so by contradiction x ∈ Y . Take now x, y ∈ mY (Y ), we have to prove [x♩ = [y♩. We show [x♩ ⊆ [y♩, the converse inclusion can be proved by a similar reasoning. So let z ∈ [x♩, we have z ∈/ Y by minimality of x and so z ± y by point i. Now if z ∈/ [y♩, there exist z' /= z, y such that z ± z' ± y. Again by minimality of y, we have z' ∈/ Y , and so z' ± x by point
i. That contradicts z ∈ [x♩, and so by contradiction z ∈ [y♩.	 
Definition 3.5 Let I, J, Y ⊆f O:
DY = {P ∈D : Y ⊆ XP };  OY = {P ∈O : Y ⊆ XP }
AY = {P ∈O : Y is atomic in P};	IY = {P ∈O : Y is isolated in P}
ZIJ = {P ∈ OI∪J : I, J are zigzag closed in P T I ∪ J}
AIY = AY ∩ IY ;	JIJ = II∪J ∩ ZIJ
Local Transformations
Definition 3.6 A function Θ is a local transformation of Y on D ⊆D if for every digraph P = (X, R) ∈ D:
Θ(P ) is a digraph with ground set X.
R' \ Y 2 = R \ Y 2, where R' denotes the binary relation on X in Θ(P ).
If moreover, Θ(P ) is a poset for every poset P ∈ D, then it is said a local poset
transformation on D.
In other words, a local transformation of Y modifies the digraph P at most locally on Y . In particular, condition ii in the definition implies that R' T(X \ Y ) = R T(X \ Y ). We link now the two notions of isolation and local transformation.
Lemma 3.7 For every local transformation Θ of Y and every poset P ∈ IY :
Θ(P ) is a poset iff Θ(P ) T Y is.
Proof. Let P = (X, ±) be a poset where Y is isolated and let Θ(P ) = (X, ±'). If Θ(P ) is a poset then Θ(P ) T Y clearly is. Now suppose that Θ(P ) T Y is a poset on Y . Note first that the reflexivity and antisymmetry of Θ(±) on X comes easily from its reflexivity and antisymmetry on Y and condition ii of Definition 3.6. It remains to prove the transitivity. So suppose x ±' y ±' z.

If (x, y) ∈/
Y 2 and (y, z) ∈/
Y 2, then by condition ii we get x ± y ± z, and

so x ± z since ± is transitive by hypothesis on P . Now if x ∈/ Y or z ∈/ Y then condition ii gives x ±' z. We prove that the other case is impossible. Indeed, if x, z ∈ Y then y ∈/ Y (since (x, y) ∈/ Y 2). But x ± y implies Y ± y and so z ± y by Lemma 3.4, which is impossible since y ± z.
Suppose now (x, y) ∈ Y 2 or (y, z) ∈ Y 2. Notice first that if x, y, z ∈ Y then the result is immediate by transitivity of ±' on Y . So suppose as a first case that x, y ∈ Y , and z ∈/ Y . We get y ± z by condition ii, and since Y is isolated, we get Y ± z, and so x ± z, and by condition ii, x ±' z. The second possible case x ∈/ Y and y, z ∈ Y , is similar.	 

We extend now the notion of local transformation to sldg’s and lpo’s, and then extend Lemma 3.7 to lpo’s.

Definition 3.8 A local sldg transformation of Y on S ⊆ S is a function which associates to every (P, l) ∈ S a sldg (P ', l') such that:
The function P '→ P ' is a local transformation of Y .
l(XP ) = l'(XP )
l(x) /= l'(x) ⇒ x ∈ Y , for every x ∈ XP .
If moreover the function P '→ P' is a poset transformation and l' is a labeling of P '
for every l, then Θ is said a local lpo transformation.

Lemma 3.9 For every local transformation Θ of Y and every lpo (P, l) such that
P ∈ IY : Θ(P, l) is a lpo iff Θ(P, l) T Y is.

Proof. Let P = (X, ±) and Θ(P, l) = (P ', l'). Let also L = l(X), LY = l(Y ) and L¯ = l(X \ Y ). Remark first that condition ii of Definition 3.8 implies that l'(X) = L, condition iii that l'(X \ Y ) = L¯, and so l'(Y ) = LY . Remark also that by condition i in Definition 3.8 and Lemma 3.7, P ' is a poset iff its restriction to Y is. Hence, in particular and since l' increasing on X implies l' increasing on Y ⊆ X, we have immediatly that if Θ(P, l) is a lpo then Θ(P, l) T Y is.
Suppose now that (P ', l') T Y is a lpo, and so l' is increasing from Y to LY . Since P ' is a poset, it remains to prove that l' is increasing on X. So let x, y ∈ X such that x ±' y. We have to prove l'(x) ≤ l'(y). We can suppose x ∈/ Y or y ∈/ Y , otherwise the result is given by the hypothesis. Moreover, if x, y ∈ X \ Y , it is immediate
by condition iii of Definition 3.8. There remains two cases x ∈ Y	∧ y ∈/ Y or
x ∈/ Y ∧ y ∈ Y . We show the first one, the second is similar. By y ∈/ Y , we have l'(y) = l(y), and since {x, y} ∈ ±' \ Y 2 = ± \ Y 2 (condition i of Definition 3.8 and condition ii of Definition 3.6), x ± y. Moreover, since Y is by hypothesis isolated in P , we get that Y ± y. Since l is a labeling of P , we have l(Y ) = LY ≤ l(y) = l'(y), and so in particular l'(x) ≤ l'(y).	 

Functionally-generalised operations
We define in this section the generalised operations as well as the corresponding MOQA operations. For that we introduced first some auxiliary functions.

Auxiliary operations on posets and lpo’s
Definition 4.1 For (X, ±) a poset and Y ⊆ X, define:
Y ↑ = {x ∈ X \ Y : Y ± x};	Y ↓ = {x ∈ X \ Y : x ± Y }
We remark that Y ↑ is closed under upper bound and Y ↓ under lower bound.
Definition 4.2 For every set Y ⊆f O, we define the operation ıY : OY '→ DY
by setting ıY (X, ±) = (X, ±ıY ) where the binary relation ±ıY on X is defined by:
z ±ıY z iff one of the following clauses is satisfied:
'
z, z' ∈ X \ Y ∧ z ± z'
z, z' ∈ Y ∧ z ± z'
z ∈ Y ↓ ∧ z' ∈ Y
z ∈ Y ∧ z' ∈ Y ↑
The intuitive idea underlying the definition of ±ıY is to remove any link between and element of Y and an element x of X \ Y except if x is below all the elements of Y or if x is above all the elements of Y .
Lemma 4.3 For every Y ⊆f O, we have ıY : OY '→ IY .
Proof. Remark first that if ıY (P ) is a poset and x ±ıY y, where x ∈ X \ Y and y ∈ Y , then the only clause of Definition 4.2 which can apply is clause iii taking x = z and y = z'. From that, clearly condition i of Lemma 3.4 holds. The same remark applies in case y ±ıY x for condition ii of the lemma. That shows that Y is isolated in ıY (P ). It remains to prove that if P = (X, ±) ∈ OY then ±ıY is a p.o. on X.
Note first that the reflexivity of ±ıY on X is ensured by the two first clauses (taking x = y). Note also that if x ∈ Y ∧ y ∈ Y ↑, we have x ± y by definition of
Y ↑. The same remark hold if x ∈ Y ↓ ∧ y ∈ Y . Hence, we have ±ı ⊆ ±. From
that we get trivially the antisymetry of ±ıY . Then, the transitivity follows by a straightforward reasoning by case from the hypothesis x ±ıY y ∧ y ±ıY z and using the different clauses of Definition 4.2.	 
Lemma 4.4 For every poset P ∈ IY we have ıY (P ) = P.
Proof. Let P = (X, ±) such that Y is isolated in P . We have immediatly ±ıY ⊆±. Now suppose x ± y. If x, y ∈ X \ Y or x, y ∈ Y , we have immediatly x ±ıY y. Two cases remain, x ∈ Y ∧ y ∈ X \ Y or x ∈ X \ Y ∧ y ∈ Y . In the first case, the
isolation of Y and x ± y give Y ± y (Lemma 3.4), that is, y ∈ Y ↑ and so x ±ı  y.
In the second case, we get similarly x ∈ Y ↓ and so again x ±ı  y.	 

Definition 4.5 For all posets P = (X, ±) and I, J ⊆ X:
I P J = {(x, y) ∈±: x ∈ I ∧ ∃z ∈ J, x ± y ± z}
We remark that I × J ∩ ± is a subset of I P J (taking y = z).
Definition 4.6 For all disjoint I, J ⊆f O, define the function ℘IJ : OI∪J '→ DI∪J
by setting ℘IJ (X, ±) = (X, ±℘IJ ) where:	±℘IJ = ± \ (I  J ∪ J  I)
Definition 4.7 For every Y ⊆f O, we define the operation @Y : OY '→ DY by setting @Y (X, ±) = (X, ±@Y ) where:	±@Y = ± \ (Y  Y \ ΔY )
Intuitively, ±℘IJ is obtained from ± by deleting any path between an element of I and an element of J inside the underlying graph, creating some kind of “parallel” sub-posets in ℘IJ (X, ±). The p.o. ±@Y is obtained by deleting any path between distinct elements of Y .
Lemma 4.8 For all disjoint I, J ⊆f O, we have ℘IJ : OI∪J '→ ZIJ
Proof. Let P = (X ±) ∈ OI∪J . We remark that, by definition of ℘IJ , we get easily ±℘IJ ∩ I × J = ∅ = J × I∩ ±℘IJ . The fact that if ℘IJ (P ) is a poset then
℘IJ (P ) ∈ ZIJ comes easily from that.
We prove that ±℘IJ is a p.o. on X. Remark first that ±℘IJ ⊆±, and so the antisymetry of ± implies immediatly the antisymetry of ±℘IJ . Now, the reflexivity comes straighforwardly from the hypothesis I and J disjoint. Then, to prove the transitivity of ±℘IJ suppose x ±℘IJ y ±℘IJ z. We have x ± y ± z and so x ± z. Suppose now that x /±℘IJ z. By definition of ±℘IJ , we get (x, z) ∈ I J or (x, z) ∈ J I. We prove that the first case is contradictory, the second case can be proved contradictory in a similar way. Indeed, if (x, z) ∈ I J, we have x ∈ I and there exist z' ∈ J such that x ± z ± z'. Now since x ± y ± z', we have also (x, y) ∈ I J, and so (x, y) ∈/±℘IJ . That contradicts the hypothesis x ±℘IJ y.	 
Lemma 4.9 For every Y ⊆f O, we have @Y : OY '→ AY .
Proof. Let P = (X, ±) ∈ OY . We remark that, by definition of ±@Y , we get easily ±@Y  ∩ Y × Y = ΔY . The fact that if @Y (P ) is a poset then Y is atomic in @Y (P ) comes then straightforwardly. In order to prove that ±@Y is a p.o. on X, remark first that ±@Y ⊆±, and so we have immediatly the antisymetry of ±@Y from the antisymetry of ±. The reflexivity is obvious from the definition. Finally the transitivity is proved in the same way than for ±℘IJ in Lemma 4.8.	 
Lemma 4.10 For all I, J, Y ⊆f O such that I, J are disjoint:
℘IJ is a local poset transformation of I ∪ J on II∪J .
@Y is a local poset transformation of Y on IY .
Proof. We have to prove condition ii of Definition 3.6 for a poset P = (X, ±) where
I ∪ J and Y are isolated. We show the result for ℘IJ , the proof is similar for @Y .
Let Z = I ∪ J. We have ±℘IJ ⊆± and so immediatly ±℘IJ \ Z ⊆± \ Z . We
2	2
reason now by contradiction. So let (x, y) ∈± \ Z2 such that (x, y) ∈/±℘	\ Z2. By

the first hypothesis we have x ± y, and also x ∈/ I ∪J or y ∈/ I ∪J. Moreover, by the second hypothesis, we have (x, y) ∈ I J or (x, y) ∈ J I since ±℘IJ = ± \ (I J∪J I). Note that the case x ∈/ I∪J is then impossible since the definition of would implies x ∈ I or x ∈ J. So suppose now y ∈/ I ∪ J. We show that the case (x, y) ∈ I J is impossible, a similar reasoning holds for the case (x, y) ∈ J I. Indeed, suppose the first case, we have x ∈ I and there exists z ∈ J such that y ± z. Since x ± y ⇒ I ∪ J ± y by weak-isolation, we get also z ± y. Hence we have y = z ∈ J which is contradictory with y ∈/ I ∪ J.	 
Lemma 4.11 Let I, J, Y ⊆f O such that I and J are disjoint, and P ∈ O:
If P ∈ JIJ then ℘IJ (P ) = P.
If P ∈ AIY  then @Y (P ) = P.
Proof. Suppose I, J, Y and P = (X, ±) satisfying the hypothesis of the lemma:
We have to prove ±℘IJ =±. We remark that ±℘IJ ⊆±, and so it remains to show
±⊆±℘IJ , which is done by contradiction. Suppose x ± y and x /±℘IJ y. We get (x, y) ∈ I J or (x, y) ∈ J I. We show that the first case is contradictory, the second case is similar. Indeed, if (x, y) ∈ I J we get x ∈ I and there exist z ∈ J such that x ± y ± z. So we get x ± z and I is not zigzag closed in P T I ∪ J (since z ∈ J and I ∩ J = ∅ by hypothesis).
We have to prove ±@Y =±. We remark that ±@Y ⊆±, and so it remains to prove the converse inclusion which is done by contradiction. So suppose x ± y and x /±@Y y. We get (x, y) ∈ Y Y with x /= y. We have x ∈ Y and there exists z ∈ Y such that x ± y ± z. We have y ∈/ Y , otherwise Y would be not atomic, and so by isolation we get Y ± y. So in particular z ± y, and then z = y, which is impossible.

Definition 4.12 For all I, J, Y ⊆f O where I, J are disjoint:
(i) jIJ = ℘IJ ◦ ıI∪J	(ii) @ıY = @Y ◦ ıI∪J
Lemma 4.13 For all I, J, Y ⊆f O where I, J are disjoint:
If P ∈ JIJ then jIJ (P ) = P and jIJ : OI∪J '→ JIJ .
If P ∈ AIY then @ıY (P ) = P and @ıY : OY '→ AIY .
Proof. The first point is a direct application of Lemmas 4.4, 4.11 and Lemmas 4.3,
4.8; the second of Lemmas 4.4, 4.11 and Lemmas 4.3, 4.9.	 
We extend now Definition 3.5 to F as well as jIJ and @ıY to lpo’s.
Definition 4.14 FY (resp. FAIY and FJ IJ ) is the set of lpos of F with posets in OY (resp. in AIY and JIJ ), for all I, J, Y ⊆f O.
Definition 4.15 For all I, J, Y ⊆f O with I, J disjoint and (P, l) respectively in
FJ IJ and FAIY , define: jIJ (P, l) = (jY (P ), l) and @ıY (P, l) = (@ıY (P ), l).

Since ±ıY , ±℘IJ and ±@Y are subsets of ±, the following fact comes immediatly from Remark 2.10 and Lemma 4.13.
Fact 4.16 For all I, J, Y ⊆f O such that I, J are disjoint:
If (P, l) ∈ FJ IJ then jIJ (P, l) = (P, l) and jIJ : FI∪J '→ FJ IJ .
If (P, l) ∈ FAIY then @ıY (P, l) = (P, l) and @ıY : FY '→ FAIY .

The generalised projection
The language MOQA has a projection operator Proj which takes two arguments: a lpo l and a set Y . Its semantics are given in [7] by a class of projections ProjY (the first argument is used as a parameter). These projections operations are defined on lpo’s only when Y is isolated in the underlying poset. A trivial way to extend them
would be to set ProjY (P, l) to return a special value “Error” when P ∈/ IY . We
introduce below more interesting extensions where ProjY (P, l) is defined without an error message as soon as Y ⊆ XP . As already mentioned, this condition is more
natural and easy to control than the isolation one. The operations are defined in two steps: on the poset first and then on the lpo. We remark that it is done in the same way in [7] and so Proposition 4.19 is immediate.
Definition 4.17 Let P = (X, ±) ∈O a poset and Y ⊆f O, define:
projG(P ) = ⎧⎨ (Y, ±T Y ) if  Y ⊆ X
⎩ “Error'' else
Definition 4.18 Let (P, l) ∈F and Y ⊆f O, define:
ProjG(P, l) = ⎧⎨ (projY (P ), l ² Y ) if	Y ⊆ XP
⎩ “Error''	else
Proposition 4.19 For all Y ⊆f O and (P, l) ∈ FY , ProjG(P, l) isa lpo on P T Y . Moreover, if P ∈ IY then projG(P ) = projY (P ) and ProjG(P, l) = ProjY (P, l).
Y	Y
The generalised (unary) product
The language MOQA has an operator   which takes three arguments: two sets I and J, and a lpo. Its semantics are given in [7]. We present this semantics and our generalisation below. It is done in two steps, starting with the operation ⊗ on posets.

The unary product on posets
The semantics of described here is slightly different from the original one of [7]. Nevertheless, the equivalence of the two formulations is straightforward. Remark also that we generalise Definition 4.20 to the case where I and J are zigzag closed in I ∪ J (but not necessary components as in the original definition).

Definition 4.20 For all I, J ⊆f O disjoint and posets P = (X, ±) ∈ JIJ , we define the unary product of P relatively to I, J by: ⊗IJ (P ) = (X, ± ∪ I × J).
We remark that ⊗IJ (P ) is a poset on X. Indeed, the reflexivity of ± ∪ I × J is immediate, the transitivity follows easily from isolation and the antisymetry from zigzag closure. It is easy to check that Definition 4.20 is equivalent to the one in [7] when I, J are components. Another way to prove the result is to use Lemma 3.7 and the easy fact that ⊗IJ is a local transformation of I ∪ J on JIJ . The operation was called “unary” product because it is a partial unary operation on the class of finite posets, and “product” because it performs a kind of (binary!) product of I and J inside X. A trivial extension of ⊗IJ is define by setting ⊗IJ (P ) = “Error'' whenever P ∈/ JIJ . A more interesting one is introduced below.
Definition 4.21 For all posets P = (X, ±) and I, J ⊆f O disjoint, define:
⊗G (P ) = ⎧⎨ ⊗IJ ◦ jIJ (P ) if  I, J ⊆ X
⎩ “Error''	else
A direct application of point i of Lemma 4.13 gives the following result.
Lemma 4.22 For every poset P ∈ OI∪J :
⊗G (P ) is a poset with ground set XP .
⊗G (P ) = ⊗IJ (P ), if moreover P ∈ JIJ .
Generalised unary product extended to lpo’s
We extend now ⊗G to a function  G  on lpo’s. That extension generalises the
operations	IJ of [7]. The latter is defined from two other operations defined
respectively on pairs of posets and pairs of lpo’s, and said binary products.  We
introduce first these binary operations and then we define  IJ and   .
G


The binary products
Notice that the presentation of the binary products is here slightly different that the one in [7]. In particular, the binary product F  F' of two disjoint lpo’s F = (P, l) and F' = (P ', l') is defined as a labeling of the binary product P ⊗P' instead of the corresponding lpo’s (with poset P ⊗ P ' and the labeling defined here as F F'). This technical modification allows a simplification of the presentation. The binary product ⊗ on disjoint posets is given now. We remark that the fact that I, J are disjoint in the definition implies in particular that ±∪ ±' is a p.o. on I ∪ J. Hence P ⊗ P ' is a poset for the same reasons that ⊗IJ (P ) in Definition 4.20.
Definition 4.23 For all posets P = (I, ±) and P' = (J, ±') such that I, J are disjoint we define P ⊗P' as the poset with ground set I ∪J and p.o. ±∪ ±' ∪ I ×J.
The extension  of ⊗ to pairs of disjoint lpo’s in defined in [7] using a pseudo code involving two operations PushUp and PushDown. These operations gener- alise to near-lpo’s the William’s PushDown and PushUp which transform a near-

heap into a heap (cf. [1,9]). We give first an intuitive description on the behavior of PushDown (the PushUp operation being simply its dual).
A near-lpo is a lpo where the biggest label has been replaced by a fresh label (a label not appearing in the lpo). The behavior of PushDown is illustrated using Example 4.24 below. The first step is obtained by replacing the biggest label, here 4, by a fresh one, here 2. Then, PushDown first checks if the replacing label is bigger than all labels below it. If it is true then PushDown stops. If not, which is the case in our example, it swaps the replacing label with the biggest label below it, that is, in our example, it swaps 2 and 3. Then it iterates the same operations, continuing to push down the replacing label, until either the replacing label is bigger that all the labels below it or it is placed on a minimal element of the poset. In our example, after the first swap 2 has reached a minimal node and so PushDown stops. It is straightforward to verify that, when PushDown stops, the results of its swaps on the near-lpo is a lpo (in particular from the fact that the swaps always involve the biggest label below the label to be swapped).
Example 4.24 Application of the PushDown operation on a near-lpo obtained from lpo F by replacing 4 by 2 :
The lpo F	The near-lpo F4←2   F4←2 after swaping 3 and 2
4◯	2◯	3◯

/’ `
/	 
/	 
/’ `
/	 
/	 
/’ `
/	 
/	 

1◯	3◯
1◯	3◯
1◯	2◯


We describe the behavior of the  algorithm on two disjoint lpo’s. Let F = (P, l) and F' = (P ', l') be lpo’s where P and P ' have disjoint ground sets I and J, and where l(I) = L and l'(J) = L' are disjoint. Note that since l is increasing the maximum label of L is necessary on a maximal node of I, otherwise it would have some node above it in ± with a label bigger than a, which is impossible. Dual reasoning ensures that b, the minimum label of l', is necessary on a minimal node of J. Then we have two cases: either a is below b or it is not. In the first case, all the labels of L are necessary below all the labels of L', and it is straightforward, by defining F  F' = l ∪ l', to check that F  F' is a labeling on P ⊗ P '. In the
second case, a and b are swapped, and then a is pushed up in (P ', l'	) and b is
pushed down in (P, la←b) using PushDown and PushUp. As already noticed, the results of these two operations will be lpo’s on respectively P and P '. Hence, we are back into the initial situation with labelings on P, P', and set of labels L' and Lb←a clearly disjoint. Then the algorithm iterates the same process, checks if the maximum label on P is below the minimum label on P ', swaps these labels or not, and so on. Since the biggest label on P is always swapped with the smallest label on P ', clearly, after some iterations of the process, the maximum label on P will be below the minimum one on P ' (in the worst case when all the labels of L or L' will have been swapped) and the algorithm will stop. We then defined F	F'
as the union of the two labelings on P and P ' obtained from the iterations. We
recall the following result from [7] and then define  IJ and   .
G


Lemma 4.25 If F = (P, l) and F' = (P ', l') are disjoint lpo’s then F	F' is a labeling on P ⊗ P '.
Definition 4.26 Let I, J ⊆f O be disjoint sets, and F = (P, l) ∈ FJ IJ :

  IJ (P, l) = (⊗IJ (P ), ⊗IJ (l))
where ⊗IJ (l) = l ² (XP \ I ∪ J) ∪ F T I

F T J.

It is easy to check that	IJ is local lpo transformation on FJ IJ , and so by Lemmas 3.9 and 4.25 we get immediatly.
Lemma 4.27 For all I, J ⊆f O disjoint:  IJ : FJ IJ '→ F.
Definition 4.28 Let I, J ⊆f O disjoint and (P, l) ∈ F:


  G (P, l
⎧⎪⎨  IJ ◦jIJ (P, l) if	I ∪ J ⊆ XP

IJ	) = 
⎪⎩ “Error''	else
As a direct application of point i of Fact 4.16 and Lemma 4.27, we get.

Proposition 4.29 For all I, J ⊆f O disjoint,  G
: FI∪J ‹→ F. If moreover

P ∈ JIJ then  IJ (P, l) =   (P, l).
G


The generalised split
The language MOQA has an operator Split which takes two arguments: a set Y and a lpo. Its semantics are summarized here and then we introduce our generalisation in two steps.

The generalised split on posets
We present the semantics of the Split operator in a slightly different way than it was done in [7]. In particular, we suppose from now on that O is totally ordered.
Definition 4.30 For all Y ⊆f O and positive integer m ∈ {1,..., Card(Y )}, define Y <mth (resp. Y ≤mth ) as the subset containing the m − 1 (resp. the m) smallest elements of Y (relatively to the order on O). The subset Y >mth (resp. Y ≥mth ) contains the elements of Y with ranks strictly above (resp. above or equal) m.
Definition 4.31 Let P = (X, ±) ∈ AIY , m ∈ {1,..., Card(Y )} and y be the mth
smallest element of Y . We define the poset splitm(P ) = (X, ±m) by:
± = ± ∪ (Y <mth × Y ≥mth ) ∪ ({y}× Y >mth )

Clearly splitm
is a local transformation on AIY , and so splitm
is a poset if its

restriction to Y is (Lemma 3.7). Note that the reflexivity of ±m is immediate by re- flexivity of ±, while the antisymmetry and the transitivity on Y are straightforward

using in particular the fact that, for every distinct x, x' ∈ Y , x ±m
We give now an example.
x' ⇒ x' ∈ Y ≥mth .

Example 4.32 split3 applied to AY (cf. Definition 2.5), Y contains five nodes:

Y

o  o  o  o  o

  split3 )
o
 ` 
//’
o
o
/’
o
 ` 
o


Definition 4.33 Let Y ⊆f O, P ∈O and m a positive integer:
⎧⎪⎨ splitm ◦ @ıY (P ) if	Y ⊆ XP ∧ m ∈ {1,... Card(Y )}
⎪⎩ “Error''	else
A direct application of the point ii of Lemma 4.13, we get the following.
Lemma 4.34 For all P ∈ OY and m ∈ {1,..., Card(Y )}, splitG(m, P ) is a poset.
If moreover P ∈ AIY , then splitG(m, P ) = splitmP.
Y	Y

The generalised split extended to lpo’s
We define the extension SplitG of splitG to lpo’s and the corresponding operation
Y	Y
SplitY . The latter operation is defined first on lpo’s with atomic posets (cf. Def-
inition 2.5) using an algorithm written in pseudo-code. It is then generalised to every lpo where Y is atomic isolated. We present first that algorithm. For that, we introduce here a special notation AtSplit for the operation implemented by the algorithm. Moreover, as for  , we prefer to define AtSplit(AY , l) as a labeling instead of a lpo as it is done in [7].
Let Y ⊆f O and F = (AY , l) be an atomic lpo, and let L = l(Y ). The algorithm processes as follow. First, it picks up the label a on the first element of Y and determines its rank m in L by comparing that label to other labels. Now, the algorithm defines a bijection l' : Y '→L as follow, where y is the mth smallest element of Y : it puts the m − 1 smallest labels on the elements of Y <mth , the pivot label a on y and finally the rest of the labels on Y >mth . The example below gives a simple application of SplitY . Note that Fact 4.36 is quite obvious.
Example 4.35 AtSplit applied to (AY , l), where Y contains five points written from left to right according to their ranks in O:


2o 3o
5o 4o 1o
AtSpli)t	1o	2o
3o 5o 4o



Fact 4.36 For every atomic lpo (AY , l), AtSplit(AY , l) is a labeling on splitm(P ),
where m is the rank of l(y) in l(Y ) and y is the smallest element of Y .
We can now introduce SplitY and SplitG.
Definition 4.37 For every Y ⊆f O and (P, l) ∈ FAIY , define:
SplitY (P, l) = (splitY (P ), SplitY (l))

where SplitY (l) = l ² (X \ Y ) ∪ AtSplit((P, l) T Y )
It is easy to check that SplitY is local lpo transformation on FAIY , and so by Lemmas 3.9 and Fact 4.36, we get immediatly.
Lemma 4.38 For every Y ⊆f O: SplitY : FAIY '→ F.
Definition 4.39 For every Y ⊆f O we define the operation SplitG on F by:
SplitG(P, l) = ⎧⎨ SplitY ◦ @ıY (P, l) if	Y ⊆ XP
⎩ “Error''	else
A direct application of point ii of Fact 4.16 and Lemma 4.38 gives.
Proposition 4.40 For every Y ⊆f O, we have SplitG : FY ‹→ F. If moreover
P ∈ AIY then SplitG(P, l) = SplitY (P, l).

RP-Domains of the Generalised Operations
We first introduce formally the notions of Domain of Deﬁnition (Def-Domain) and Domain of Random Preservation (RP-Domain) of a function acting on lpo’s. We recall that the definition of Random Preservation is given in Section 2.4.
Definition 5.1 For an operation Op with domain a subset of F, we call respectively Domain of Definition and RP-Domain the following sets:
Domdef (Op) = {F ∈ Dom(Op) : Op(F ) ∈ F}
Domrp(Op) = ∪{R : R is a Random Structure and Op is RP on R}
As already mentioned, RP-domains and Def-domains of MOQA operations are identical. It is not the case for the generalised ones and it would be easy to exhibit random structures where they are defined but not RP. Nevertheless, Propositions 4.19, 4.29 and 4.40 express in particular that the generalised operations, when restricted to the domains of the corresponding MOQA operations, coincide with these operations. That fact implies in particular that the RP-domains of generalised operations contain the RP-domains of the corresponding MOQA operations. In fact we have a stronger result.
Theorem 5.2 For all I, J, Y ⊆f O such that I, J disjoint:
Domrp(SplitG) ⊃ Domrp(SplitY )
Domrp(  G ) ⊃ Domrp(   )
Domrp(ProjG) ⊃ Domrp(ProjY )
We prove now Theorem 5.2 by giving examples where the MOQA operators are not defined (and so a fortiori not RP) while the generalised operations are both defined and RP. Notes that random structures are represented by their underlying posets; the choice of the set of labels L being not relevant here. We write ×K to

express that the output multiset OOp(R) of the operation Op applied to R is equal to Op(R) × K.
In the first example below, the shape of the underlying poset is not changed by the operation. Indeed, one can verifies that all the links between nodes of the underlying posets which had been deleted by application of the operations @ıY and jIJ are finally put back in place by application of operations splitY and ⊗IJ . Then the operations SplitG and  G work as the identity on lpos of the RS of the example.
Note finally that the result of random preservation expressed by that example can be generalised to random structures where input and output posets are isomorphic.
Example 5.3 Let y be the smallest element of Y w.r.t the order on O. We remark that Y is not atomic and I, J are not zigzag closed:
,		 

Y	o  o  o
  SplitG
o  o  o	×1

\	 ` ˆ/’
yo
 ` ˆ/’
yo

  		J

,		 

//’
o
o	 J
 ` 
o	 G
//’
o
o
 ` 
o

I ˆz z  ˆ J
IJ )
ˆz z   ˆ	×1

, zz	  zz

o	o
 `  /’
o
o	o
 `  /’
o

J
In the next example the operation ⊗G reverse a poset denoted by K3,1 to give a
poset K1,3. The application of  G to the RS on K3,1 give then one copy of the RS
on K1,3. Remark, that the RP result expressed by the example can be generalised
to every integers n, m.
Example 5.4 We remark that I, J are not zigzag free in I ∪ J.
,	 , I	,	 ,J

o	G
J	IJ)
o  o  o	×1

/’ `ˆ 
 `  ˆ /’

, /o
o o ,
, /o , I

 	 J	 	 J
We recall that ProjY is strongly random preserving (cf. Section 2.4). The operation ProjG has the same property on the random structure in the example below, where 3 isomorphic copies of the output set are generated.
Example 5.5 We remark that Y is not isolated.
o	o	o	o

o	o		)
 /o	×3

,ˆ	ˆ 
 ` //’
ProjG
 ` /’

   o	Y

Conclusion and Future Work
In this article, we introduced three generalised MOQA operations. These opera- tions have several advantages compared to their correspondent MOQA operations. First, they extend the domains of definition of the latter in a non trivial and still meaningful way, using more natural restrictions. Secondly, as shown in the previous section they extend also the domains of random preservation of the corresponding MOQA operations. The fact that the examples given in Section 5 can be generalised indicates that this extension is non-trivial and quite rich.
Nevertheless, and in contrast to MOQA operations, there is no known charac- terization of the RP-domains of generalised operations. That implies in particular that there is no known computable function able to calculate in full generality the output multiplicities as it can be done in MOQA (cf. Section 2.4). The semi- automatisation of average time analysis deriving from the existence of that function is then not possible either.
Thus, the next step toward a full generalisation of MOQA operations including the semi-automation of average time analysis would be a tractable characterization of RP-domains of the functionally-generalised operations, or at least non trivial subsets of these domains. Note also the generalisations we gave here may be not the only possible ones.

References
Aho A., J. Hopcroft and J. Ullma: “Data structures and algorihms”, Addison-Wesley Series in Computer Science and Information Processing, Addison-Wesley (1987).
Flajolet P., J. S. Vitter: “Average-Case Analysis of Algorithms and Data Structures”, Handbook of Theoretical Computer Science, Volume A: Algorithms and Complexity, Elsevier (1990), 431-524.
Knuth D.: “The art of computer programming vol.3”, Addison-Wesley (1973).
Manning J.: Reconstruction of Partial Orders, MFCSIT’06 Proceedings, Cork, Ireland (Aug 2006), 296-299.
Schellekens M.: Compositional Average-Case Analysis, Preprint, submitted to the Journal of ACM (2006), 78p.
Schellekens M.: Modular Timing, An overview of CEOL research. MFCSIT’06 Proceedings, Cork, Ireland (Aug 2006), 300-303.
M. P. Schellekens, A Modular Calculus for the Average Cost of Data Structuring, Springer book to appear (2008), 250 pp.
Schellekens M., Hickey D., Bollella G.: ACETT, a Linearly-Compositional Programming Language for (semi-)automated Average-Case analysis. IEEE Real-Time Systems Symposium - WIP session Proceedings (2004).
Williams J.W.J: Algorithm 232, Communication of ACM 7(6), 347-348, 1964.
