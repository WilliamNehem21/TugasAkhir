Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 338 (2018) 79–95
www.elsevier.com/locate/entcs

Machine-checked Proof of the Church-Rosser Theorem for the Lambda Calculus Using the Barendregt Variable Convention in Constructive Type Theory


Ernesto Copello1,2 Nora Szasz3
A´lvaro Tasistro3

Universidad ORT Uruguay Montevideo, Uruguay

Abstract
In this article we continue the work started in [3], deriving in Constructive Type Theory new induction principles for the λ-calculus, using (the historical) first order syntax with only one sort of names for both bound and free variables, and with α-conversion based upon name swapping. The principles provide a flexible framework for mimicking pen-and-paper proofs within the rigorous formal setting of a proof assistant.
We here report on one successful application, namely a complete proof of the Church-Rosser Theorem. The whole development has been machine-checked using the system Agda [5].
Keywords: Lambda Calculus, Formal Metatheory, Type Theory


Introduction
Let us consider the following definition of the Lambda Calculus terms:
M, N ::= x | MN | λx.M
Fig. 1. Lambda Calculus syntax

where x ranges over a denumerable set of variables V .
This syntax has been considered too concrete a level on which to formally develop the metatheory of the calculus. The reason is that there is no significant difference between terms that differ only in the choice of the names of the bound variables,

1 Currently at The University of Iowa, Iowa City, USA, Email: ernesto-copello@uiowa.edu
2 Partially supported by a scholarship granted by Agencia Nacional de Investigaci´on e Innovaci´on, Uruguay.
3 Email: szasz,tasistro@ort.edu.uy

https://doi.org/10.1016/j.entcs.2018.10.006
1571-0661/© 2018 The Author(s). Published by Elsevier B.V.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

i.e., that are α-equivalent; and therefore it becomes natural to identify such terms already at the syntactic level. In the classical setting this amounts to working on α-equivalence classes of terms. One way to do this is to reason generally on terms by choosing adequate representatives of the classes in question. A prominent illustration of this practice is given in Barendregt’s book [1], and the criterion followed to choose the representatives has thenceforth received as standard name the Barendregt Variable Convention (BVC).
In previous work [3], we have justified a form of the BVC in Constructive Type Theory by the following method: We introduced a recursion principle allowing the definition of strongly α-compatible functions on concrete terms, i.e. functions on the syntax introduced above that equate α-equivalent terms. This principle allows one to specify the value of the function in the case of abstractions by considering only the case in which the bound variable does not belong to a given list of names. The principle is actually implemented by computing, for each given term, a canonical α- equivalent representative that satisfies such restriction. Then, the specified function actually operates on the computed representative. The α-conversion is implemented using the elementary operation of name swapping as in nominal techniques (see for instance [7] and [8]). Using this principle we have been able to define e.g. the substitution operation by considering, for abstractions, only the convenient case in which variable capture is avoided.
In addition, we also introduced a corresponding induction principle, which is presented in Figure 2. This principle requires the property being proved to be α- compatible, that is, preserved by α-conversion. In other words, it must be a property of the abstract terms arising from the identification of α-equivalent concrete ones. As before, the induction principle allows us to prove the case of abstraction con- sidering only the case in which the bound name does not belong to a given list of names:
P α-compatible (∀x) P (x)
(∀M, N ) (P (M ) ∧ P (N ) ⇒ P (M N ))
(∃xs, ∀M, ∀x/∈xs)(P (M ) ⇒ P (λx.M )) (∀M ) P (M )
Fig. 2. Alpha induction principle

In this formulation and hereafter we use the following convention for fixing the range of quantifiers: x, y, z, . . . range over (names of) variables, M , N , . . . range over λ-terms, and xs ranges over lists of variables.
The principles referred to above were actually derived from the ordinary struc- tural induction on concrete terms. As first applications, we developed, using the Agda proof assistant [5], some metatheoretical results concerning substitution that will be mentioned in the next section.
In this work we present strengthened α-induction principles on λ-terms that can be used to satisfactorily deal with relations whose definitions involve name swapping, and that allow us to avoid finite lists of names in binding positions, not

just in abstractions but in any term. In this way we can scale the metatheory of the λ-calculus up to the Church-Rosser Theorem, formally reproducing a form of the BVC in the formalisation. The set of obtained principles provides a flexible framework quite able to pleasantly mimic pen-and-paper proofs within the rigorous formal setting of a proof assistant.
The work that stands closest to the present one is [10], where Urban and Norrish show how to emulate the BVC when performing induction on relations over λ- terms. They illustrate the use of the induction principles by proving the Substitution Lemma for parallel reduction, and the Weakening Lemma of the typing relation. They present two induction principles on relations, one for the parallel reduction relation, and another one for the typing relation. When carrying out a proof by induction on these relations they are able to avoid a finite set of variable names as binders. To prove these strengthened induction principles they require that the relation definition rules satisfy the following preconditions: all functions and side conditions should be equivariant (i.e., preserved by name permutation), the side conditions must imply that all bound variables do not occur free in the conclusions, and all bound variables must be distinct. As a consequence, they have to modify the definition of the original relations to satisfy these preconditions in order to be able to prove the soundness of their induction principles.
All the definitions and proofs presented in the present article have been fully formalised in Constructive Type Theory [4] and machine-checked employing the system Agda [5]. The corresponding code is public, and it is available at:
https://github.com/ernius/formalmetatheory-nominal-Church-Rosser
In the subsequent text we give the proofs in English with a considerable level of detail so that they serve for making it clear how their formalisation was carried out. The structure of the following sections is as follows: in Section 2 we recall the basic concepts of the λ-calculus, and some definitions and results from our previous work that are necessary for a better understanding of the material presented in this one. In Section 3 we introduce two new strengthened α-induction principles on λ- terms that will be useful to prove the main results of this work. Then, in Section 4 we present the notion of β-reduction and prove the Church-Rosser Theorem by using the standard method due to Tait and Martin-L¨of which involves the formulation and study of the parallel β-reduction. The overall conclusions are exposed in Section 5.

Preliminaries
Variables belong to a denumerable set of names, and terms are inductively defined as in Figure 1.
The freshness relation states that a variable does not occur free in a term:
Definition 2.1 [Freshness]


x /= y x#y
x#M	x#N x#MN 
x#M x#λy.M
x#λx.M

x /∈b M denotes that the variable x does not occur in a binding position in term M :

Definition 2.2 [/∈b]


x /∈b
y	 x /∈b M	x /∈b N  x /∈b MN 
 x /= y	x /∈b M  x /∈b λy.M

Next comes the operation of swapping of names. A finite sequence (composi- tion) of name swaps constitutes a finite name permutation, which is the renaming mechanism to be used on terms. The action of swapping is first defined on names themselves:


Definition 2.3 [Swapping]

(x y) z =

y if z = x x if z = y
⎩ z if x /= z Λ y /= z,

and then it is directly extended to terms by swapping all names occurring in a term, including abstraction positions.
The permutation operation is just defined as the sequential application of a list of swaps. We usually use π to denote permutations, and the application of a permutation π to a term M is written π M . (x y) π denotes the permutation consisting of the swap (x y) followed by the permutation π.
In the next definition we give a syntax-directed definition of α-conversion (~α) based on the swapping operation.
Definition 2.4 [Alpha equivalence relation]

(~ v)
M~αMj	N~αNj

α	x ~α x
(~αa)	MN ~
MjNj



(~α
 (6z /∈ xs) (x z)M ~α (y z)N  λ)	λx.M ~α λy.N

In [3] we proved that this is an equivalence relation, preserved by the permutation operation (i.e. equivariant).
The substitution operation is defined using the α-compatible recursion principle mentioned in the previous section, and as a direct consequence of this, the following lemma is automatically derived:
Lemma 2.5 (α-compatibility of substitution)
M ~α Mj ⇒ M [x:=N ]= Mj[x:=N ].

The following results are successfully proved using the induction principles of [3].

Lemma 2.6 (Substitution preserves α-conversion) N ~α Nj ⇒ M [x:=N ] ~α M [x:=Nj].
Lemma 2.7 (Substitution under permutation)
π (M [x:=N ]) ~α (π M )[(π x):=(π N )].

The next lemma shows that substitution commutes with abstraction up to
α-conversion. This is so because the hypotheses ensure a fresh enough binder.

Lemma 2.8 (Substitution commutes with abstraction)
x /= y Λ x#N  ⇒ (λx.M )[y:=N ] ~α λx.(M [y:=N ]).
As a consequence of the previous lemma, we obtain:
Lemma 2.9 (Substitution composition)
x /= y Λ x#P  ⇒ M [x:=N ][y:=P ] ~α M [y:=P ][x:=N [y:=P ]].

The following result was not proved in our previous work, so we exhibit it in detail.
Lemma 2.10 (Swapping substitution variable)
x#M ⇒ ((x y)M )[x:=N ] ~α M [y:=N ].

Proof. We use our α-induction principle in Figure 2. First, for arbitrary names
x, y and term N we consider the following predicate on terms:
Π(M ) ≡ x#M ⇒ ((x y)M )[x:=N ] ~α M [y:=N ].
We have to prove that Π is α-compatible, that is, if M~αP and Π(M ), then Π(P ). Assume Π(M ) and x#P . Then, as freshness is preserved through ~α, we have that x#M . Then we proceed as follows:
((x y)P )[x:=N ] = {~α equivariance and Lemma 2.5} ((x y)M )[x:=N ] ~α {Π(M ) and x#M}
M [y:=N ]   = {Lemma 2.5}
P [y:=N ].
Now we can proceed to the induction proper. We show the interesting case, namely the one of abstractions: We have x#λz.Mj, where we choose z /∈ {x, y}∪ fv(N ). We need to prove ((x y)(λz.Mj))[x:=N ] ~α (λz.Mj)[y:=N ]. As x#λz.Mj and z /= x we get x#Mj. Then we can reason as follows:
((x y)(λz.Mj))[x:=N ]	= {def. of swap} (λ((x y)z).((x y)Mj))[x:=N ] = {z /∈ {x, y}}
(λz.((x y)Mj))[x:=N ]	~α {Lemma 2.8}
λz.(((x y)Mj)[x:=N ])	~α {i.h.} λz.(Mj[y:=N ])	~α {Lemma 2.8} (λz.Mj)[y:=N ]
2

The preceding proof illustrates the usual pen-and-paper informal practice, which uses the BVC to assume binders fresh enough in some defined context, allowing us to apply substitution in a naive way without need of renaming.
The next result is a quite direct consequence of the previous lemma:
Lemma 2.11
x#λy.M  ⇒  ((x y)M )[x:=N ] ~α M [y:=N ].
Alpha Induction Principles
In this section we introduce two new α-induction principles. The first one is pre- sented in Figure 3.
P α-compatible (6x) P (x)
(6M, N ) (P (M ) Λ P (N ) ⇒ P (M N ))
(∃xs, 6M, 6x/∈xs) ((6π) P (π M ) ⇒ P (λx.M )) (6M ) P (M )
Fig. 3. Alpha induction principle with permutations
It is a strengthened version of the one shown in Figure 2, where the induction hypothesis of the abstraction case allows us to assume the property for all permu- tations of names in the body. This principle is useful to deal with relations which make use of the permutation operation in their definitions. We will show an example of this situation in the proof of Lemma 4.7 in the next section.
The α-induction principle with permutations shown in Figure 3 is proved using the one in Figure 4, which was derived in [3] from simple structural induction on λ-terms, in very much the same way as complete induction on natural numbers is derived from ordinary mathematical induction.
(6x) P (x)
(6M, N ) (P (M ) Λ P (N ) ⇒ P (M N ))
(6M, x) ((6π) P (π M ) ⇒ P (λx.M )) (6M ) P (M )
Fig. 4. Strong permutation induction principle

Proof. (Alpha induction principle with permutations).
The variable and application cases are direct. For the abstraction case, given any term M and variable x, we must prove P (λx.M ) knowing:
(6π) P (π M )	(1a)
(∃xs, 6Mj, 6y/∈xs) ((6πj) P (πj Mj) ⇒ P (λy.Mj))	(1b)
Let xs be a list of names as in (1b). Let us further pick y not in xs and also fresh in λx.M . Then for all Mj, πj, P (πj Mj) ⇒ P (λy.Mj) holds. So taking Mj =

(x y)M we have that (6πj)P (πj ((x y)M )) ⇒ P (λy.(x y)M ). Now, as πj((x y)M )= ((x y)πj)M , we can use (1a) to get P (λy.(x y)M ) from (1b), and finally P (λx.M ) because P is α-compatible and λx.M ~α λy.(x y)M . This last α-equivalence holds because we have chosen y fresh in λx.M .	2
The next induction principle (Figure 5) enables us to assume bound variables not in a given finite list of names xs through the entire induction, and not only for the abstraction case.
P α-compatible (6x) P (x)
(6M, N ) ((6y ∈ xs,y /∈b MN ) Λ P (M ) Λ P (N ) ⇒ P (M N ))
(6M, x) ((6y ∈ xs,y /∈b λx.M ) Λ P (M ) ⇒ P (λx.M )) (6M ) P (M )
Fig. 5. Strengthened α-induction principle

Proof. (Strengthened α-induction principle).
To derive this principle we introduce a rewrite function such that, given a list of names xs and a term M , rewrite (xs,M ) returns a term α-convertible with M that does not contain any element of xs as binder.
To prove P (M ) for any term M , we proceed as follows. Given a list of names xs, an α-compatible predicate P , and the following hypotheses:


(6x) P (x)
(6M, N ) ((6y ∈ xs,y /∈b MN ) Λ P (M ) Λ P (N ) ⇒ P (M N ))
(6M, x) ((6y ∈ xs,y /∈b λx.M ) Λ P (M ) ⇒ P (λx.M ))
(2)

we prove the following predicate Π by structural induction on terms:
Π(M ) ≡ ((6x∈xs) ⇒ x /∈b M ) ⇒ P (M )	(3)
Then, we use this predicate Π on the term rewrite (xs,M ), which has no bound variables in xs to obtain P (rewrite (xs,M )). Finally, as P is α-compatible and rewrite (xs,M ) ~α M we get that P (M ) holds for any M .
In turn, the proof of Π(M ) by structural induction on M is straightforward because of the syntax directed definition of /∈b:
Variable case: Direct.
Application case: We need to prove Π(MN ) for any M, N , such that Π(M ) and Π(N ) hold. That is, we have to prove P (MN ), given that any variable x in xs satisfies that x /∈b (MN ). Then, by the syntax directed definition of /∈b, we directly have that x /∈b M and x /∈b N , and so we are able to use the induction hypothesis on M and N to get P (M ) and P (N ). So, we have that all the premises in the second assertion in (2) hold, and hence its conclusion P (MN ).
Abstraction case: We must prove Π(λy.M ), that is, we need to prove P (λy.M ) knowing that every variable x in xs satisfies that x /∈b λy.M . By the definition of

/∈b, we have that x /= y and x /∈b M . We can apply the last result to the induction hypothesis Π(M ) to get P (M ). Finally, we get the desired result using the third assertion in (2).
2
Parallel Beta Reduction
The β-reduction relation (→β) is defined as the compatible (with the syntactic constructors) closure of the β-contraction (λx.M )N dβ M [x:=N ]. The classical proof of confluence of β-reduction by Tait and Martin-L¨of rests upon the property of confluence of the so-called parallel reduction, which can apply several β-contractions “in parallel” in one single step. We present our definition in Figure 6.

(⇒v)

x ⇒ x
M ⇒ Mj	N ⇒ Nj
(⇒a)	MN ⇒ MjNj

(Exs, 6z /∈ xs) (x z)M ⇒ (y z)N
(⇒λ)	λx.M ⇒ λy.N


(⇒β)
λx.M ⇒ λy.Pj	N ⇒ P jj	Pj[y:=P jj] ~α P
(λx.M )N ⇒ P
Fig. 6. Parallel reduction relation

The first three rules have the same form as the ones defining the α-conversion relation presented in Definition 2.4, which provides evidence that we want this parallel reduction to be compatible with α-conversion, that is, if M ⇒ N , M ~α Mj and N ~α Nj then Mj ⇒ Nj. We will prove this property in Lemmas 4.5 and 4.6. Finally, note that the (⇒β) rule has an extra premise involving α-conversion. The reason for this is that our substitution operation modifies the bound names in terms as a consequence of being defined with our α-recursion principle. Without that additional premise we would not be able to prove that ⇒ is α-compatible on its right hand side.
We start by proving some basic properties:
Lemma 4.1 (Reflexivity of ⇒)
M ⇒ M.
Proof. Direct application of the permutation induction principle in Figure 4.  2
Lemma 4.2 (Equivariance of ⇒)
M ⇒ N ⇒ πM ⇒ πN.
Proof. By induction on the definition of ⇒.
The variable and application cases are direct. In the abstraction case, we have to prove λ(π x).(π M ) ⇒ λ(π y).(π N ) from the premise of the rule (⇒λ) and the corresponding induction hypothesis. We can in addition exclude the variable

z mentioned in the premise from the domain of the permutation π and reason as follows:
(x z)M ⇒ (y z)N	⇒  {i.h.}
π((x z)M ) ⇒ π((y z)N )	⇒ {def. of perm.}
((π x) (π z))(π M )⇒((π y) (π z))(πN )	⇒ {as z /∈ dom(π) then (π z)= z}
((π x) z)(π M ) ⇒ ((π y) z)(π N )	⇒ {(⇒ λ) rule}
λ(π x).(π M ) ⇒ λ(π y).(π N ).
In the (⇒ β) case we must prove (λ(π x).(π M ))(π N ) ⇒ π P from premises λx.M ⇒ λy.Pj, N ⇒ P jj and P ~α Pj[y:=P jj]. By direct application of the induction hypotheses corresponding to the first two premises we get:
λ(π x).(π M ) ⇒ λ(π y).(π Pj)
and π N ⇒ π P jj	(4)
Then, using the third premise we can reason as follows:
P ~α Pj[y:=P jj]	⇒ {~α equivariance}
π P ~α π (P j[y:=P jj])	⇒ {Lemma 2.7}
π P ~α (π Pj)[(π y):=(π P jj)] ⇒ {~α symmetry}
(π Pj)[(π y):=(π P jj)] ~α π P 
We obtain the desired result using the (⇒β) rule with (4) and this last result as premises.	2
As a direct consequence of the previous lemma we derive the following result:
Corollary 4.3 (Preservation of ⇒ under abstraction)
M ⇒ N  ⇒ λx.M ⇒ λx.N.
The following lemmas state that our parallel reduction relation is preserved by α-equivalence. Both results are proved by easy inductions on the parallel reduction relation.
Lemma 4.4 (Right α-compatibility of ⇒)
M ⇒ N Λ N ~α P  ⇒ M ⇒ P.
Lemma 4.5 (Left α-compatibility of ⇒)
M ~α N Λ N ⇒ P  ⇒ M ⇒ P.
We can now prove in a direct manner that α-conversion is included in the parallel reduction.
Lemma 4.6
~α ⊆ ⇒ .
Proof. Given M ~α N , as ⇒ is reflexive by Lemma 4.1, we also know M ⇒ M . Then using Lemma 4.4 we obtain the desired result.
2
As ⇒ basically applies β-contractions, no free variable should be introduced at any step, therefore freshness is preserved.

Lemma 4.7 (⇒ preserves freshness)
x#M Λ M ⇒ N ⇒ x#N.
Proof. We use the α-induction principle with permutations (Figure 3) on the term
M . In order to apply this principle we must prove, for any variable x, that the predicate
Π(M ) ≡ (6N ) (x#M Λ M ⇒ N ⇒ x#N ).
is α-compatible, which follows from the α-compatibility of both freshness and parallel reduction. Now, for the main result, we only show the interesting ab- straction case of the induction (i.e. for a term λy.Mj). We therefore have that x#λy.Mj and λy.Mj ⇒ λz.Nj, and we must prove x#λz.Nj. Now, λy.Mj ⇒ λz.Nj must be the result of an application of the (⇒λ) rule, so we get its premise (6w/∈xs) (y w)Mj ⇒ (z w)Nj. The α-induction principle allows us to exclude some variables for the abstraction case, so we can also assume y /= x. Using this inequality and the hypothesis x#λy.Mj we get by definition that x#Mj. Now let u be a variable such that u#Nj,u /∈ xs and u /= x; then x#(y u)Mj because x /= y, x /= u and x#Mj. We can apply the premise of the (⇒λ) rule with u, as u /∈ xs, and we get (y u)Mj ⇒ (z u)Nj. We use the induction hypothesis on Mj and per- mutation (y u) with the previous two results to get x #(z u)Nj. We also have that λu.(z u)N j ~α λz.Nj because u #Nj. Then, as ~α preserves freshness, we get the desired result.	2
We can now prove the following inversion lemmas, which state that the original definition of parallel reduction by Takahashi [9] (which we note ⇒T in the next definition) can be derived from ours. These lemmas will be useful in the proof of the diamond property of our relation ⇒.

x ⇒T x
M ⇒T Mj	N ⇒T Nj
MN ⇒T MjNj
M ⇒T Mj
λx.M ⇒T λx.Mj

M ⇒T Mj	N ⇒T Nj
(λx.M )N ⇒T Mj[x:=Nj]
Fig. 7. Takahashi’s parallel reduction relation.

Lemma 4.8 (⇒ λ-inversion)
λx.M ⇒ Mj ⇒ (EMjj) (M ⇒ Mjj Λ λx.M ⇒ λx.Mjj Λ Mj ~α λx.Mjj).
Proof. By definition of ⇒ it must be the case that λx.M ⇒ Mj is a result of an application of (⇒ λ) rule; then we have that Mj is in an abstraction λy.N , and that there exists a list of variables xs such that (6z/∈xs) (x z)M ⇒ (y z)N . We take Mjj = (x y)N , and prove that Mjj satisfies the three properties of the thesis.
Let z be a variable such that z /∈ xs and z#λy.Mj. By definition of #, x#λx.M , and then, as parallel reduction preserves freshness, x#λy.N also holds. So:

(x z)M ⇒ (y z)N	⇒ {⇒ equivariance} (x z)(x z)M ⇒ (x z)(y z)N ⇒ {swap self inverse} M ⇒ (x z)(y z)N	⇒ {(*)}
M ⇒ (x y)N
(*) Here we apply Lemma 4.4 with the premise (x z)(y z)N ~α (x y)N . This swapping cancellation property requires z and x to be fresh enough, as it is the case.
We apply Lemma 4.4 with λx.M ⇒ λy.N and the α-equivalence obtained above to prove λx.M ⇒ λx.(x y)N .
To prove λy.N ~α λx.(x y)N , as x is fresh in λy.N , we swap y with x in this term to get the α-equivalent term λx.(x y)N (Lemma 4.2).
2
Lemma 4.9 (⇒ β-inversion)
If (λx.M )N ⇒ P is obtained by application of the (⇒ β) rule in the following way:
λx.M ⇒ λy.Mj	N ⇒ Nj	Mj[y:=Nj] ~α P

(⇒β)
(λx.M )N ⇒ P

then, (EMjj) (λx.M ⇒ λx.Mjj Λ Mjj[x:=Nj] ~α P ).
Proof. We prove that Mjj = (y x)Mj satisfies the thesis.
x#λx.M and λx.M ⇒ λy.Mj so by Lemma 4.7 x#λy.Mj. We can then swap y with x in the last term and obtain the α-equivalent term λx.(y x)Mj, using Lemma 4.2. Then, by Lemma 4.4 we get λx.M ⇒ λx.(y x)Mj.
For the second condition we reason as follows:
((y x)Mj)[x:=Nj]		=	{swap commutativity} ((x y)Mj))[x:=Nj] ~α {Corollary 2.11} Mj[y:=Nj]	~α {hypothesis}
P
2
Theorem 4.10 (⇒ Substitution Lemma)
M ⇒ Mj Λ N ⇒ Nj ⇒ M [x:=N ] ⇒ Mj[x:=Nj].
The Substitution Lemma for parallel reduction is the crux of the Church-Rosser Theorem, and the place in which our α-induction principles in [3] fail to capture the BVC. If we perform induction on the term M , the problem appears in the beta application case, specifically when the term is a redex. We then have M = (λy.P )Q, and we need to prove ((λy.P )Q)[x:=N ] ⇒ R[x:=Nj]. But, as we are in the application case of the induction, the original α-induction principle gives no freshness information about the binder y. The use of the BVC would allow us to choose y different from x and fresh in N , and with those freshness conditions we could push the substitution inside the abstraction without any variable capture by the use of Lemma 2.8. We next use our strengthened α-induction principle presented in Figure 5 to prove this result.

Proof. Given terms N, Nj such that N ⇒ Nj, and a variable x, we consider the following predicate on terms:
Π(M ) ≡ (6Mj) (M ⇒ Mj ⇒ M [x:=N ] ⇒ Mj[x:=Nj]).
Π is α-compatible, which is a direct consequence of both substitution and ⇒ being α-compatible (Lemmas 2.5,4.4,4.5). Then we can use our strengthened α-induction principle to prove Π by induction on the term M , excluding the variable x, and the free variables in terms N and Nj from the binders in M . We show the proof of the interesting application and abstraction cases.
Application case: we prove (6P, Q) ((6z ∈ {x}∪fv(N )∪fv(Nj), z /∈b P Q) Π(P ) Λ Π(Q) ⇒ Π(P Q)). We have two subcases according to which rule is used to reduce the application P Q.
(⇒a) rule subcase: we have that P ⇒ Pj and Q ⇒ Qj and we need to prove that (P Q)[x:=N ] ⇒ (P j Qj)[x:=Nj]. The proof is a direct application of the (⇒a) rule to the induction hypotheses.
(⇒β) rule subcase: given (λy.P )Q ⇒ R we must prove ((λy.P )Q)[x:=N ] ⇒
R[x:=Nj]. We use the inversion Lemma 4.9 to obtain that there exists P jj such that λy.P ⇒ λy.P jj Λ P jj[y:=Qj] ~α R. Next, as we have assumed the binder y different from x and also fresh in N and Nj, we can reason as follows:
λy.P ⇒ λy.P jj	⇒  {i.h.}
(λy.P )[x:=N ] ⇒ (λy.P jj)[x:=Nj] ⇒ {Lemma 2.8}
λy.(P [x:=N ]) ⇒ λy.(P jj[x:=Nj])
By the induction hypothesis we know Q[x:=N ] ⇒ Qj[x:=Nj]. So if we prove:
P jj[x:=Nj][y:=Qj[x:=Nj]] ~α R[x:=Nj]	(5) we will be able to apply the (⇒ β) rule and get that (λy.(P [x:=N ]))(Q[x:=N ])
⇒ R[x:=Nj]. Then, using the freshness premises, we can pull out the sub-
stitution operation on the left side of this parallel reduction, and using the Lemma 4.5, of α-compatibility of ⇒, we finally get the desired result.
It just remains to prove (5) to end the proof of this subcase. Again, here the
classical informal proofs use the BVC. We can also mimic this practice in this case since our induction principle gives us a binder y distinct form x and fresh in Nj. Then, we have the freshness premises to successfully apply the sub- stitution composition Lemma 2.9 and conclude this proof in the following steps:
P jj[x:=Nj][y:=Qj[x:=Nj]] ~α {Lemma 2.9}
P jj[y:=Qj][x:=Nj]	=	{Lemma 2.5 and P jj[y:=Qj] ~α R }
R[x:=Nj]
Abstraction case: we have to prove (6P, y) (6z ∈ {x} ∪ fv(N ) ∪ fv(Nj),z /∈b λy.P ) Λ Π(P ) ⇒ Π(λy.P ). We apply the inversion Lemma 4.9 to the hypothesis λy.P ⇒ Q to get that there exists Qj such that: P ⇒ Qj, λy.P ⇒ λy.Qj and Q ~α λy.Qj. Then, we can conclude the proof in the following way:

P ⇒ Qj	⇒ {ind. hyp.}
P [x:=N ] ⇒ Qj[x:=Nj]	⇒ {⇒ equivariance} (y z)(P [x:=N ]) ⇒ (y z)(Qj[x:=Nj]) ⇒ {(⇒λ) rule}
λy.P [x:=N ] ⇒ λy.Qj[x:=Nj]	⇒ {Lemma 2.8}
(λy.P )[x:=N ] ⇒ (λy.Qj)[x:=Nj]	⇒ {Lemma 2.5 and Q ~α λy.Qj}
(λy.P )[x:=N ] ⇒ Q[x:=Nj]
2
In [10], the authors proceed by induction on the relation, so x, N, Nj are universally quantified over the β-contraction rule definition, and they are forced to add the same freshness premises that we were able to assume in this proof –by the use of our strengthened α-induction principle– directly into the premises of their modified beta rule of the parallel relation. In contrast, we are performing induction on the term M to prove the predicate Π, and hence we are able to maintain those variables as a fixed context outside the definition of Π. Then by the use of our strengthened α-induction principle we are able to mimic the BVC also in the ap- plication case of the proof, specifically in the previously exposed (⇒β) rule subcase.
Finally, we prove the diamond property of the parallel reduction. Instead of directly proving it by induction on terms (which can easily be done), we will follow the shorter method by Takahashi [9]. For this we first define the “star” operation (Figure 8), such that for any λ-term M , M∗ is the result of contracting all the β-redexes existing in M simultaneously. Then we prove that for any terms M, N , if M ⇒ N , then N ⇒ M∗ (Lemma 4.11). Finally, the diamond property of ⇒ follows directly as a corollary of this result.


x∗	=	x
(λx.M )∗	=	λx.M∗
(	x	M )∗	=	x M∗ ((M1M2) M3)∗ =	(M1M2)∗M∗ ((λx.M1) M2)∗ =	M∗[x := M∗]
1	2
Fig. 8. Takahashi’s star function

Lemma 4.11 (Star property)
M ⇒ N  ⇒ N ⇒ M∗.
Proof. By structural induction on M . We show the interesting application and abstraction cases.
Abstraction case: we have to prove that N ⇒ (λx.M )∗ = λx.M∗, knowing that
λx.M ⇒ N holds.
We can use the inversion Lemma 4.8 on the latter to obtain the existence of the term Nj such that: N ~α λx.Nj and M ⇒ Nj. We can now apply the induction hypothesis, and then Corollary 4.3 to M ⇒ Nj, and obtain λx.Nj ⇒ λx.(M∗).

This last result directly gives us the desired result by Lemma 4.5 since we know that N ~α λx.Nj.
Application case: we have three subcases.
The first two correspond to the third and fourth lines of the star operation defi- nition, and are directly derived from the induction hypotheses.
Finally, the redex case can be subdivided accordingly to which rule, (⇒a) or (⇒β), is used in the last step of its parallel reduction:
· (⇒a) rule subcase: we have that λx.M ⇒ N and Mj ⇒ Nj, and we need to prove that NNj ⇒ ((λx.M )Mj)∗ = M∗[x := Mj∗].
We begin applying the inversion Lemma 4.8 to the hypothesis λx.M ⇒ N to get that there exists Njj such that N ~α λx.Njj and M ⇒ Njj. We can now apply the induction hypothesis to the latter, and then Corollary 4.3 to conclude λx.Njj ⇒ λx.M∗. Besides, we can also apply the induction hypothesis to the premise Mj ⇒ Nj to get Nj ⇒ Mj∗. We can combine the last two inferred parallel reductions, using the (⇒β) rule, and derive that (λx.Njj)Nj ⇒ M∗[x :=
Mj∗] holds. From this result we directly get the desired result just noticing that
N Nj ~α (λx.Njj)Nj, because N ~α λx.Njj and Nj ~α Nj.  Hence, by left
α-compatibility of the parallel relation (Lemma 4.5) we finish this subcase.
· (⇒β) rule subcase: we have the following hypotheses: λx.M ⇒ λyN , Mj ⇒ Nj and N [y := Nj] ~α P , and we need to prove that P ⇒ M∗[x := Mj∗] holds. We proceed analogously to the previous subcase getting that there exists Njj such that λy.N ~α λx.Njj, Njj ⇒ M∗ and Nj ⇒ Mj∗. Then we apply Substi- tution Lemma for ⇒ (Lemma 4.10) to obtain Njj[x := Nj] ⇒ M∗[x := Mj∗], and we can use left α-compatibility Lemma 4.5 to finish the proof if we prove that P ~α Njj[x := Nj].
Finally, we prove that this last alpha equivalence holds:
P	~α  {hypothesis}
N [y := Nj]	~α {by Lemma 2.11 as x#λy.N}
((x y)N )[x := Nj] =	{by Lemma 2.5 as (x y)N ~α Njj}
Njj[x := Nj]
In the previous derivation we used the freshness condition x#λy.N , which fol- lows from λy.N ~α λx.Njj, x#λx.Njj, and the fact that freshness is preserved under α-conversion.
2

As a direct consequence of the previous lemma, we have the following result:
Lemma 4.12 (Diamond property of ⇒)
M ⇒ N Λ M ⇒ P ⇒ EQ, N ⇒ Q Λ P ⇒ Q.

Definition 4.13 [Confluence]
A relation is confluent if its reflexive and transitive closure has the diamond prop- erty.

We omit the proof details of the next results because they do no deal with
λ-terms. They are proved in a direct way as in the classical literature.
Lemma 4.14 If a relation R has the diamond property then it is confluent.
Lemma 4.15 If a reduction relation R is confluent, then so is its reflexive and transitive closure R∗.
As a direct application of the preceding two lemmas, we obtain:
Lemma 4.16 (Confluence of ⇒)
⇒∗ is confluent.
If we now consider the β-reduction →β, we have:
Lemma 4.17
(→β ∪ ~α)∗ = ⇒∗
Proof. We prove the double inclusion.
To prove (→β ∪ ~α)∗ ⊆ ⇒∗, it is enough to prove (→β ∪ ~α) ⊆ ⇒. By Lemma 4.6 we know ~α⊆ ⇒, and →β⊆ ⇒ can be proved by a direct induction on the →β reduction relation.
Finally, to prove ⇒∗⊆ (→β ∪ ~α)∗ we first prove ⇒ ⊆ (→β ∪ ~α)∗ by a direct induction on ⇒. Then, by monotonicity of ∗ over ⊆, we get ⇒∗⊆ ((→β ∪ ~α)∗)∗, and the desired result follows from idempotence of ∗.	2
Using the last two lemmas we finally arrive at the Church-Rosser Theorem.
Theorem 4.18 (Church-Rosser)
The relation (→β ∪ ~α) is confluent.
Conclusions
We have introduced principles of induction on terms of the Lambda Calculus that allow us to reason on the abstract terms that arise by identifying α-equivalent concrete ones. The principles work for α-compatible predicates, i.e. properties preserved by α-conversion, and allow us to carry out the corresponding proofs by choosing convenient representatives of the abstract terms in question, namely by avoiding names in binding positions belonging to explicitly provided finite lists. We have derived these principles ultimately from the ordinary structural induction on (concrete) terms. Therefore we have provided a full justification of this form of the Barendregt Variable Convention (BVC). The whole work has been carried out in Constructive Type Theory —and machine-checked using the system Agda— with- out modifying the ordinary definitional equality of terms or formulating any kind of quotient construction. For the whole implementation to work it has proven essential to define α-conversion in terms of a fundamental operation of name swapping, as in Pitts and Gabbay’s Nominal Techniques.
That the method of formalisation can be useful is maybe illustrated by our full formal proof in Agda of the Church-Rosser Theorem. In this paper we have given a summarized description in English language of such proof, although showing

the details we believe essential for the reconstruction of the completely formal ver- sion, which is publicly available at https://github.com/ernius/formalmetatheory- nominal-Church-Rosser.
In our development, the definition of the parallel reduction relation has to be formulated in such a way as to ensure that the relation is α-compatible. Because of this, it looks more concrete than the classical one, as presented by Barendregt [1] or Takahasi [9]. However, we are able to prove inversion lemmas that allow us to recover the original parallel reduction definition, and from them we are able to reproduce Takahashi’s proof of the diamond property.
In a similar work, Urban and Norrish [10] also have to modify the parallel reduction relation in order to derive an ad-hoc induction principle on the parallel reduction to successfully prove the Substitution Lemma for this relation. However, they do not have to ensure the α-compatibility of the parallel reduction because in their formalisation α-convertible terms are syntactically equal, since they work at the level of terms quotiented by α-equivalence, as explained in [6]. We believe our approach is more direct and general, since we derive an induction principle on simple terms, and not on the more complex relations over them. As shown in the beta subcase of the proof of the Substitution Theorem, we are able to derive the freshness conditions for the binders directly from our α-induction principle, as in the BVC, and not explicitly imposing them in the definition of the parallel reduction.
As another application of our method, we have been able to formalise a proof of the Subject Reduction Theorem for the system of assignment of simple types in a quite direct way, which is also publicly available at the aforementioned site. Finally, we have generalised the techniques here exposed to a framework of regular trees with binders, thereby obtaining pleasant treatments of e.g. metatheory of the System F alongside that of the pure Lambda Calculus by way of instantiation. Report on this work can be found in the first author’s PhD thesis [2].

References
Hendrik Barendregt. The λ-calculus Its Syntax and Semantics, volume 103 of Studies in Logic and the Foundations of Mathematics. North Holland, revised edition, 1984.
Ernesto Copello. On the Formalisation of the Metatheory of the Lambda Calculus and Languages with Binders. PhD thesis, PEDECIBA Inform´atica, Uruguay, August 2017.
Ernesto Copello, A´lvaro Tasistro, Nora Szasz, Ana Bove, and Maribel Ferna´ndez. Alpha-structural induction and recursion for the λ-calculus in constructive type theory. Electronic Notes in Theoretical Computer Science, 323:109 – 124, 2016.
Per Martin-Lof. Intuitionistic type theory, volume 1 of Studies in Proof Theory. Lecture Notes. Bibliopolis, Naples, 1984. Notes by Giovanni Sambin.
Ulf Norell. Towards a Practical Programming Language Based on Dependent Type Theory. PhD thesis, Department of Computer Science and Engineering, Chalmers University of Technology, September 2007.
Michael Norrish. Mechanising λ-calculus using a classical first order theory of terms with permutations.
Higher-Order and Symbolic Computation, 19(2):169–195, 2006.
Andrew M. Pitts. Nominal Logic, a First 0rder Theory of Names and Binding. Information and Computation, 186(2):165–193, 2003.
Andrew M. Pitts. Alpha-Structural Recursion and Induction. Journal of the ACM, 53(3):459–506, May 2006.


M. Takahashi. Parallel Reductions in λ-Calculus. Information and Computation, 118(1):120 – 127, 1995.
Christian Urban and Michael Norrish. A formal treatment of the Barendregt variable convention in rule inductions. In Proceedings of the 3rd ACM SIGPLAN Workshop on Mechanized Reasoning About Languages with Variable Binding, MERLIN ’05, pages 25–32, New York, NY, USA, 2005. ACM.
