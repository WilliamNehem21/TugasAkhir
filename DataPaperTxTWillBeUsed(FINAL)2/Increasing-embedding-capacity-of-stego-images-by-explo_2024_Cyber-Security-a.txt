Cyber Security and Applications 2 (2024) 100028

		




Increasing embedding capacity of stego images by exploiting edge pixels in prediction error space
Habiba Sultanaa,âˆ—, A.H.M. Kamala, Tasnim Sakib Aponb, Md. Golam Rabiul Alam b
a Jatiya Kabi Kazi Nazrul Islam University, Mymensingh, 2220, Bangladesh
b BRAC University, Dhaka, 1212, Bangladesh


a r t i c l e	i n f o	a b s t r a c t

	

Keywords:
Edge detection Predictor Embedding capacity PSNR
Steganography Steganalysis
In the field of data concealing, edge detection techniques are frequently employed, particularly for improving image quality and data security. These methods, however, have a lower embedding capacity. In order to take advantage of more edge pixels, many strategies are used nowadays. These schemes either combine the output from multiple edge detectors or enlarge the edges of an edge image by dilating. Even so, if the amount of data is vast, the techniques might not be able to conceal all of it. Therefore, a novel strategy for edge exploitation is still needed to regulate the effectiveness of edge detection-based data-hiding strategies. By using edge detectors in the prediction error space, we utilized more edge pixels in this study (PES). Applying a predictor on the cover image and then calculating the prediction errors, we prepared the PES. The edges in PES were then marked using the edge detector. The edge-error corresponding pixels received more information than the relevant pixels that
more edges, which does help to achieve a higher embedding capacity. We implanted ğ‘¥ number of secret bits in did not create an edge-error. Additionally, we combined the results from different edge detectors to produce edge pixels and ğ‘¦ number of bits in non-edge pixels where ğ‘¥ > ğ‘¦. The simulation results show that the proposed
scheme outperforms its rivals on all performance-measuring criteria, including payload, stego image quality, and resistance to attack.





Introduction

Security is an essential part of data communications. There are many techniques in the literature that are currently being used for securing the data. The premier one is cryptography. A cryptography method encrypts the secret messages into an unintelligible format, known as ciphertext, to prevent intruders from realizing the meaning of it [1]. Such meaningless random content in a message, in fact, makes the in- truder curious and deeply attentive to look for some hidden meaning in it. Watermarking is another way of securing the message [2]. How- ever, that technique is mainly used for serving data integrity. Addition- ally, some watermarking methods remain their masks visible on the cover media. Due to those limitations, steganography has taken a firm stand in the field of secured communication. Steganography is a pro- cess of hiding data in a cover media, e.g., image, audio, video, text, bio-signals, DNA sequence, etc. [3]. Among these media, images are gaining popularity as a cover media for their higher degree of informa- tion redundancy and flexible size for communication over the Internet [4]. In steganography, an embedding technique implants secrets in a cover media. The modified media is called stego media. That stego me- dia is then sent to a destination. The destination end applies an exact de-

âˆ— Corresponding author.
E-mail address: srity.cse@jkkniu.edu.bd (H. Sultana).
embedding algorithm to extract the secrets from it. Some de-embedding algorithms, additionally, generate the cover media from the stego one [5â€“17]. Therefore, all of these methods can be divided into reversible or irreversible depending on their ability to build cover media from stego one.
Intruders can even check if there is something secret in it. In that case, they deal with the possibility of changing cover contents. Such analyses are known as steganalysis techniques [18]. With these consid- erations in mind, the performance of steganography is evaluated with the ability to increase the data hiding rate, decrease the distortion rate of the carrier and resist attacks.
There are diverse techniques for hiding information in image con- tent. A major part of such algorithms applies edge detection methods [1,2,19â€“32], as a part of their embedding technique. These schemes find edge and non-edge pixels first and then embed more bits in edge pixels than non-edge ones; because the human visual system is less sensitive to changes in sharp areas of images compared to smooth areas. Such methodology is very useful in yielding both better stego quality and higher data security. However, the embedding capacity depends more on the number of identified edge pixels. The embedding capacity goes high when the number of edge pixels is large.


https://doi.org/10.1016/j.csa.2023.100028
Received 15 May 2023; Received in revised form 9 July 2023; Accepted 3 August 2023
Available online 9 August 2023
2772-9184/Â© 2023 The Authors. Publishing Services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)



In 2016, Lee et al. [19] proposed a reversible data hiding method based on reduplicated exploiting modification, image interpolation, and canny edge detection. To enhance the image quality, Kumar et al.
[20] proposed a steganography system with fuzzy edge identification and least significant bit (LSB) substitution methods in 2018. S. Sun in 2015 showed another post-processing technique to improve the visual quality of stego images [21]. He applied Huffman encoding to Canny- detected edge pixels to measure the number of bits that could be im- planted in each pixel. The method next used a correction method for increasing the visual quality of their stego image. Vanmathi and Prabu in 2017 employed fuzzy logic edge detection method for detecting edge pixels. The authors applied a chaotic method for encrypting messages and the LSB substitution technique for implanting those in edge pix- els [22]. G. Swain in 2015 adopted a pixel value difference policy to enhance data security [23]. Uses of Canny, Sobel, and fuzzy as edge de- tection were compared in [24] in 2017 by Bai et al.. Setiadi in 2022
[25] increased the number of edge pixels by applying morphological operator dilation on edge image owing to improve the edge pixels and thus, the embedding capacity. The author also applied hybrid edge de- tectors for the same purpose. In addition to the edge detection tech- nique, Kusuuma et al. [26] in 2018 applied an encryption method for the secret message to strengthen the security of hidden data. Khan et al.
[27] in 2015 replaced four LSBs of detected edge pixels in their data hiding algorithm. That scheme, indeed, destroyed the image quality roughly. Again, Chen et al. [28] in 2010 combined the results of Canny and Fuzzy edge detectors to exploit more edge pixels. Tseng and Leng in 2014 [29] improved the distortion rate of [28] by working on im- age blocks rather than the whole image at a time. Link in [25], Gaurav and Ghanekar in 2018 [30] applied a dilation operator to increase the number of edge pixels. They implanted secret bits by applying bit-wise exclusive-OR (XOR) operation between the binaries of each edge pixel and a message chunk. Vishnu et al. in 2020 [31] also used the Canny edge detection method to identify the edge pixels. Next, they computed pixel value differences between each of the two consecutive edge pix- els reading in a sequential manner. That pixel value differences were used to implant secret bits in edge pixels. Sultana and Kamal in 2021
[32] employed multiple edge detectors and then measured the desired edge pixels for data hiding by doing a logical AND operation among the pixels of each of the same positions in edge images. That policy is ef- fective for getting better stego quality while the size of the demanded implantable message is small. Setiadi et al. in 2018 [32], combined the results of canny and sobel edge detectors to increase the number of edge pixels.
Studies in the state of the art reveal that edge detection-based em- bedding schemes suffer from less embedding capacity. Therefore, as the demand for data hiding increases, so does the challenge with the capa- bility of such schemes, because the number of edge pixels obtained in such a conventional way may be unable to conceive the demanded in- formation. Such good methods will then be ineffective. Our target is to
The key contributions of this research are as follows:
An image steganography approach has been proposed for eï¬ƒcient data hiding on the edges of an image. We have applied edge detectors in prediction error space to increase the embedding capacity of the stego image which signifies the novelty of this research.
We have adapted the technique of combining the results of multiple edge detectors owing to increase the number of edge pixels, further. We have also made our scheme enable to concealment of a different number of bits in edge and non-edge pixels. Therefore, the proposed scheme increases both the embedding capacity and the visual quality of stego images. At the same time, it shows strong resistance against statistical attacks.
Throughout this manuscript, Section 2 discussed previous existing studies related to this manuscript. Section 3 presents the proposed method neatly. The simulated results of our scheme are demonstrated in Section 4. Section 4.6 is devoted to testing the robustness of the pro- posed scheme against attacks. Section 5 narrates the implications and limitations of our work. Finally, Section 6 draws a conclusion of the article.
Related works

Human visioning systems are sensitive to local changes. In the image, local changes are marked as edges. Edges in the image appear along ei- ther horizontal, vertical, or diagonal gradient directions. A filter, known as a kernel, is used to detect the edges in an image. Very commonly used edge detectors are Canny, Sobel, Log, Prewitt, Laplacian, and Fuzzy edge detectors. Now briefly describe those operators in the following:
Roberts edge detection
Lawrence Roberts develops the Roberts edge detection (1965). It measures the 2-D spatial gradient of an image in a straightforward and quick manner.


ğ‘…ğºğ‘¥

ğ‘…ğºğ‘¦
This technique highlights areas of high spatial frequency, which fre- quently coincide with edges. The most common application of this approach is when both the input and the output are grayscale im- ages. The estimated full amplitude of the spatial gradient of the input image at each place in the output is represented by the pixel values at each location.
Robertâ€™s cross-operator consists of 2 Ã—2 convolution kernels. ğºğ‘¥ is a
simple kernel and ğºğ‘¦ is rotated by 900. The gradient magnitude is:

graphic method. For this, we have enriched the edge detection space so	|ğº| =	ğ‘…ğº2 + ğ‘…ğº2 enhance the embedding capacity of the edge detection-based stegano-			
(1)

that the applied edge detector can detect more edge pixels. To get that, we applied a predictor on the image pixels. We have measured the pre- diction errors as well. In the prediction error space, we have applied the edge detector. That strategy noticeably increases the number of edge- forming errors in the error space. Corresponding positions of edge and non-edge errors in error space are noted. We have used that positional map to link to the image domain. That mapping is done to classify the image contents as edge and non-edge pixels. We then implant secrets in these pixels by embedding rules. That strategy boosts up the embedding capacity notably. Nevertheless, still, the scheme faces problems in hid- ing large volumes of data. We further try to increase the number of edge pixels by combining the edge images of multiple edge detectors. Exper- imental results deduce that the proposed method performs better than the other competing schemes, and shows a noticeable improvement in its capability of hiding more data.
An approximate magnitude is computed:
ğº = ğ‘…ğºğ‘¥ + ğ‘…ğºğ‘¦	(2)
Sobel edge Detection




ğ‘†ğºğ‘¥


ğ‘†ğºğ‘¦



In 1970, Sobel developed the Sobel edge detection method. In order to highlight areas of high spatial frequency that correlate to edges,

The gradient magnitude is:
|ğº| = âˆšğ¿ğº2 + ğ¿ğº2
(7)

gradient magnitude at each location in ğ‘› input grayscale images. an image. Typically, it is used to determine the predicted absolute
least is made up of two 3 Ã—3 complication kernels. The other kernel According to the bottom tableâ€™s disclosure, the operator at the very is just the first one rotated 900. The Roberts Cross operator and this are extremely similar. Sobel Edge detection operator consists of 3 Ã—3 convolution kernels. ğºğ‘¥ is a simple kernel and ğºğ‘¦ is rotated by 900.
An approximate magnitude is computed:
ğº = ğ¿ğºğ‘¥ + ğ¿ğºğ‘¦	(8)
Typically, the Laplacian is employed to determine whether a pixel is on the light or dark side of an edge.
Canny Edge Detection The Canny edge detection method is one of
the common edge detection methods in the industry. It was first de-

The gradient magnitude is:
|ğº| = âˆšğ‘†ğº2 + ğ‘†ğº2
(3)
signed in 1983 by John Canny for his masterâ€™s thesis at MIT, and it still outperforms several more recent algorithms. Prior to using the

An approximate magnitude is computed:
ğº = ğ‘†ğºğ‘¥ + ğ‘†ğºğ‘¦	(4)
Prewitt edge detection
Prewitt first suggested the Prewitt edge detection in 1970. Prewitt is a reliable method for determining an edgeâ€™s size and direction.
This gradient-based edge detector is estimated in the 3 Ã—3 neighbor-
hood for eight directions. Calculations have been made for all eight
convolution masks. The next step is to choose one complexity mask, specifically with the largest module in mind.
The gradient magnitude is:
from the image. The Canny approach is superior since it applies the tendency to identify edges and a serious threshold value after pre- serving the characteristics of the edges in the image. These are the algorithmic steps:
A Gaussian filter is used to remove noise from the input image.
Calculating the gradient of image pixels in order to determine magnitude along the x and y dimensions.
Suppress the non-max edge contributor pixel points while taking into account a cluster of neighbors for any curve pointing in the direction of the specified edge.
As a last step, apply the hysteresis thresholding technique to pre-

|ğº| = âˆšğ‘ƒ ğº2 + ğ‘ƒ ğº2
(5)
serve pixels with gradient magnitudes greater than or equal to 1



An approximate magnitude is computed:
ğº = ğ‘ƒ ğºğ‘¥ + ğ‘ƒ ğºğ‘¦	(6)
Prewitt detection tends to provide somewhat noisier findings but is computationally slightly easier to execute than Sobel detection.




ğ‘ƒğºğ‘¥


ğ‘ƒğºğ‘¦
LoG edge detection
A 2-D isotropic measurement of an image is the Laplacian of Gaus- sian. Laplacian, which is also utilized for edge detection, is the region of an image that is emphasized and experiences fast intensity vari- ations. To lessen the sensitivity of noise, the Laplacian is applied to an image that has been smoothed using a Gaussian smoothing filter. This operator creates a single grayscale image from a single grayscale image that is input. The input image is represented in Laplacian as a collection of discrete pixels. In order to approach the second deriva- tives in the definition, a discrete convolution kernel is discovered. The following are the top two kernels:




ğ¿ğºğ‘¥


ğ¿ğºğ‘¦
to 0.
Generally, edge detectors are used in pattern recognition, image mor- phology, and feature extractions. In the field of image steganography, edge detectors are used to improve the security of hide data as well as to collect the data hiding features. These schemes first detect the edge and non-edge pixels in a cover image. Then these schemes either im- plant in edge pixels only or embed a different number of bits in edge and non-edge pixels. Bearing that in mind, we studied a good number of articles on that state of the art. Among those, we found the works of Junlan Baiet al. [24] and Setiadi D. R. I. M. [25] which were very close to our research objectives. As a result, we studied these two articles with deep attention and built the foundation of our proposed work on them. In 2017, Junlan Bai et al. [24] proposed a steganography approach based on the combination of edge detection and LSB substitution meth- ods. In their scheme, the authors first prove that if a few of the LSBs of image pixels are cleared and then an edge detector is applied on that
cleared image, let ğ¼ğ‘ ğ‘™ğ‘Ÿ, the detection information is almost the same as
age, say ğ¼ğ‘œ. Therefore, they proposed to clear ğ‘› bits of information in an computing edge information by applying the detector in the original im-
in the pixels of the cover image by ğ‘˜ âˆ’ ğ¿ğ‘†ğµ substitutions, where ğ‘˜ â‰¤ ğ‘›. image before applying an edge detector. They are allowed to implant In practice, they used ğ‘› = 5. Thereafter, they formed stego image ğ¼ğ‘  by implanting ğ‘¥-bits of information in detected edge pixels and ğ‘¦-bits of in- formation in non-edge pixels, where ğ‘¥ > ğ‘¦. At the extraction phase, their scheme again cleared ğ‘› bits of LSBs from stego pixels of ğ¼ğ‘ . That cleared image is, indeed, ğ¼ğ‘ ğ‘™ğ‘Ÿ. Hence, the extraction phase feels no ambiguity to
then, extracts ğ‘¥ bits of LSBs from edge pixels and ğ‘¦ bits of LSBs from detect the same set of edge pixels as the data-hiding phase. The scheme,
non-edge pixels.
ilar to Junlan Bai et al.â€™s scheme. He also implanted ğ‘¥ bits of informa- In 2019, Setiadi proposed an image steganography that is very sim- tion in edge pixels and ğ‘¦ bits of secrets in non-edge pixels. However, he
added some pre-processing tasks to increase the number of edge pixels
detectors, say ğ‘š number of detectors, on 5-LSBs cleared images. These owing to improving the embedding capacity. He applied multiple edge
ğ‘š detectors separately generate ğ‘š edge images. Let these edge images are ğ¼ğ‘’1, ğ¼ğ‘’2, ..., ğ¼ğ‘’ğ‘š. The scheme increases the number of edge pixels by
combining these edge results by doing logical OR operations among the


Table 1
Summary of related works.



edge images, i.e., by ğ¼ğ‘’1 âˆ¨ ğ¼ğ‘’2 âˆ¨â€¦âˆ¨ ğ¼ğ‘’ğ‘š. Let the resultant image is ğ‘Ÿğ¼ğ‘’. He dilated the edge image ğ‘Ÿğ¼ğ‘’ to increase edge pixels more. He then
separated the edge and non-edge pixels from the dilated image.
In 2021, Sultana et al. proposed image steganography based on hy- brid edge detectors. In their scheme, the authors applied multiple edge
detectors, say ğ‘ number of detectors, on ğ‘šâˆ’ LSBs cleared image, and
those detectors separately generated edge images. These edge images
are combined using logical AND operations. The authors then implant
where function Î¨ returns the remainder value when one divides ğ¼ (ğ‘–, ğ‘—)
by 2ğ‘›.

Generating prediction error space
Let the height and width of image ğ¼ be â„ and ğ‘¤, respectively. Then,
the predicted values of four corner pixels are computed by Eq. (10).
â§âª ğ‘(1, 1) = ğ¼ (1,2)+ğ¼ (2,1)

ğ‘¥ bits into edge pixels and ğ‘¦ bits into non-edge pixels, where ğ‘¥ > ğ‘¦.
In 2018, Setiadi proposed image steganography based on canny-
Sobel edge detector and LSB substitution methods. In this scheme, the
âªğ‘(1, ğ‘¤) =
â¨
ğ¼ (1, ğ‘¤ âˆ’ 1) + ğ¼ (2, ğ‘¤) 2
ğ¼ (â„ âˆ’ 1, 1) + ğ¼ (â„, 2)
(10)

authors applied multiple edge detectors, say ğ‘š number of detectors, on the cover image. These ğ‘š detectors separately generate ğ‘š edge images. Let these edge images be ğ¼1, ğ¼2, ..., ğ¼ğ‘š. The scheme hybridized those edge images using logical OR operations, i.e., by ğ¼1 âˆ¨ ğ¼2 âˆ¨â€¦âˆ¨ ğ¼ğ‘š. Let the resultant image is ğ‘Ÿğ¼ğ‘’. As a result, this scheme increases the number
of edge pixels. At the same time, the author is added one special char-
into binary form. The authors then implant ğ‘¥ bits into edge pixels and acter at the end of the secret message then this message is transformed
ğ‘(â„, 1) =
2
ğ‘(â„, ğ‘¤) = ğ¼ (â„ âˆ’ 1, ğ‘¤) + ğ¼ (â„, ğ‘¤ âˆ’ 1)
2
Similar way, the other pixels in the first row, last row, first column, and last column are calculated by Eq. (11).
â§âª ğ‘(1, ğ‘—) = ğ¼ (1, ğ‘— âˆ’ 1) + ğ¼ (2, ğ‘—) + ğ¼ (1, ğ‘— + 1)

ğ‘¦ bits into non-edge pixels (where ğ‘¥ > ğ‘¦) based on message length.
ğ¼ (â„, ğ‘— âˆ’ 1) + ğ¼ (â„ âˆ’ 1, ğ‘—) + ğ¼ (â„, ğ‘— + 1)
ğ‘ â„, ğ‘—

Table 1 provides a summary of comparisons among the existing stud- ies. It is also demonstrated how our proposed model differs from previ- ous works.
âªâ¨ ğ‘(ğ‘–, 1) =
âª
3
ğ¼ (ğ‘– âˆ’ 1, 1) + ğ¼ (ğ‘–, 2) + ğ¼ (ğ‘– + 1, 1)
3
(11)

Proposed method


The proposed work consists of three phases: pre-processing, data em- bedding, and data extracting. Our Initial phase of pre-processing is ex- plained in Section 3.1. Data embedding is present in Section 3.2 and
In the same way, we compute all other middle pixels by Eq. (12).
ğ‘(ğ‘–, ğ‘—) = ğ¼ (ğ‘– âˆ’ 1, ğ‘—) + ğ¼ (ğ‘–, ğ‘— âˆ’ 1) + ğ¼ (ğ‘– + 1, ğ‘—) + ğ¼ (ğ‘–, ğ‘— + 1)
4

(12)

finally Section 3.3 goes over our extraction phase. Figs. 1 and 2 depict the overall proposed method.
Pre-processing phase

As our target is to implant more bits in edge pixels than the non- edges, both the data hider and the data extractor should detect and iden- tify the same set of edge pixels. To do that equally, a homogeneous field is required where both the data hider and data extractor can detect the same set of edge pixels. Previous works commonly applied their edge detectors in that homogeneous field. But, in that stage, our target is to apply a predictor on that homogeneous field and, thereafter, to compute the prediction errors. We would then want to compute edge pixels with the help of that prediction error space. These pre-processing tasks are shown in blocks of the first four levels of Fig. 1 Encoder.
Generating homogeneous field
Before starting that discussion, let the taken cover image is ğ¶ and an instance of it is ğ¼ . We first clear ğ‘›-bits of LSBs from every pixel of
ğ¼ . To explain the LSB clearing method, consider a pixel value at (ğ‘–, ğ‘—)
location of ğ¼ , i.e., ğ¼ (ğ‘–, ğ‘—), is 175. The binary conversion of that pixel
value is 01001011. Then, clearing 3 bits of LSBs from 01001011 will
of  ğ‘›-bits  of  LSBs  from  each  pixel  by  Eq.  (9). yield 01001000. In decimal, it will be 72. We generalize that clearing
ğ¼ (ğ‘–, ğ‘—) = ğ¼ (ğ‘–, ğ‘—) âˆ’ Î¨(ğ¼ (ğ‘–, ğ‘—), 2ğ‘›);	(9)
Thus, we compute all predicted values. Finally, the prediction errors and the absolute values of the prediction errors are calculated by Eqs. (13) and (14), respectively.
ğ‘ğ¸(ğ‘–, ğ‘—) = ğ¼ (ğ‘–, ğ‘—) âˆ’ ğ‘(ğ‘–, ğ‘—)	(13)
ğ‘ğ¸ğ‘(ğ‘–, ğ‘—) = ğ‘ğ¸(ğ‘–, ğ‘—)	(14)
where 1 â‰¤ ğ‘– â‰¤ â„, 1 â‰¤ ğ‘— â‰¤ ğ‘¤ and ğ‘ stands for absolute value of ğ‘.

Edge image generation
We have applied ğ‘š-number of â€˜edge detection operatorsâ€™, e.g., canny, sobel, fuzzy, Robert, Prewitt, log, etc., on ğ‘ğ¸ğ‘ to measure edge pixels,
separately. We have generated the edge image by Eq. (15).
ğ‘’ğ¼ (ğ‘–) = ğ‘“ (ğ‘ğ¸ğ‘, Î©)	(15)
where Î© is one of the ğ‘š edge detection operators, i.e., Î© âˆˆ {ğ¶ğ‘ğ‘›ğ‘›ğ‘¦,
ğ‘†ğ‘œğ‘ğ‘’ğ‘™, ğ¿ğ‘œğ‘”,  ğ¹ ğ‘¢ğ‘§ğ‘§ğ‘¦, ğ‘…ğ‘œğ‘ğ‘’ğ‘Ÿğ‘¡,  ğ‘ƒ ğ‘Ÿğ‘’ğ‘¤ğ‘–ğ‘¡ğ‘¡, ğ‘’ğ‘¡ğ‘.},  1 â‰¤ ğ‘– â‰¤ ğ‘š  and  ğ‘“  returns  the edge image ğ‘’ğ¼ from ğ‘ğ¸ğ‘ for a specific edge detector Î©. Each edge image
is a binary image. For each pixel, the edge image holds a 0 or 1. A 1 in
image ğ‘ğ¸ğ‘ is in the detected edge. We consider that the edges in ğ‘ğ¸ğ‘ are edge image means the corresponding pixel (indeed, absolute error) of the edges of ğ¼ . The experiment reveals that the number of edge pixels in ğ‘ğ¸ğ‘ is more than that in ğ¼ for the same edge detector. Hence, the application of an edge detector in ğ‘ğ¸ğ‘ will provide us with more edge





Fig. 1. The Encoder-Decoder architectures of the Proposed Method.




Fig. 2. The top-level overview of the Proposed Method.



pixels in ğ¼ . Our objective is to enhance the embedding capacity of an
edge detection-based scheme. Therefore, such an attempt will lead us
to our goal. To improve further, we have combined the detected edge results. To do that, we have applied logical OR operations among the
edge images. The OR image, i.e., resultant image ğ‘Ÿğ¼ (ğ‘–, ğ‘—), is computed
by Eq. (16).
ğ‘Ÿğ¼ (ğ‘–, ğ‘—) = ğ‘’ğ¼ (1, ğ‘–, ğ‘—) âˆ¨ ğ‘’ğ¼ (2, ğ‘–, ğ‘—) âˆ¨â€¦âˆ¨ ğ‘’ğ¼ (ğ‘š, ğ‘–, ğ‘—)	(16)
where 1 â‰¤ ğ‘– â‰¤ â„, 1 â‰¤ ğ‘— â‰¤ ğ‘¤ and âˆ¨ stands for logical OR operator. This
way, we have generated the resultant edge image from prediction error
space by hybridizing edge detectors.
values, respectively. The absolute values of prediction errors are ğ‘ğ¸ğ‘. Eqs. (13) and (14) compute the prediction errors and their absolute Using Eq. (15) we have computed edge image ğ‘’ğ¼ (ğ‘–) from ğ‘ğ¸ğ‘ for dif- ferent edge detectors Î©. Combining all edge images by Eq. (16), we form the resultant edge image ğ‘Ÿğ¼ . We have separated the edge pixels
ğ‘’ğ‘ƒ and their corresponding positions ğ‘’ğ‘ƒ ğ‘ƒ in ğ¼ by Eq. (17). The same Eq. (17) helps us in finding non-edge pixels ğ‘›ğ‘’ğ‘ƒ and their positions ğ‘›ğ‘’ğ‘ƒ ğ‘ƒ in ğ¼ . Next from each of the edge-located pixels, i.e., from (ğ‘ , ğ‘¡), we have measured ğ‘‘ğ‘¥, where ğ‘‘ğ‘¥ = ğ‘†(ğ‘ , ğ‘¡) âˆ’ ğ¼ (ğ‘ , ğ‘¡). Similar way, from each of the non-edge located pixels, we have computed ğ‘‘ğ‘¦ by ğ‘‘ğ‘¦ = ğ‘†(ğ‘¢, ğ‘£) âˆ’ ğ¼ (ğ‘¢, ğ‘£). Here, ğ‘ , ğ‘¡, ğ‘¢, ğ‘£, ğ‘–, and ğ‘— are defined in the immediate previous subsection.
Next, we have extracted the binaries of the secret by Eq. (19).

Data implantation phase
{ğ‘ğ‘¥
= Î¦(ğ‘‘ğ‘¥)
(19)

Now, it is the turn to embed secrets in image ğ¼ . The whole data
hiding process is depicted in Fig. 1 Encoder. The data-hiding steps are
as follows:

location in ğ¼ . That classification is done using the help of the resul- â€¢ A module is developed to classify edge and non-edge pixels and their tant edge image ğ‘Ÿğ¼ . The Eq. (17) is used to do that.
[ğ‘’ğ‘ƒ , ğ‘’ğ‘ƒ ğ‘ƒ , ğ‘›ğ‘’ğ‘ƒ , ğ‘›ğ‘’ğ‘ƒ ğ‘ƒ ] = ğ¹ (ğ¼ , ğ‘Ÿğ¼ )	(17)
where ğ¹ returns edge pixels ğ‘’ğ‘ƒ , their positions ğ‘’ğ‘ƒ ğ‘ƒ , non-edge pix- els ğ‘›ğ‘’ğ‘ƒ and their positions ğ‘›ğ‘’ğ‘ƒ ğ‘ƒ in ğ¼ . The function ğ¹ performs the
calculation of these four return values by the following module of
ğ¹ .
Function ğ¹ (ğ¼ , ğ‘Ÿğ¼ )
Compute the size of image ğ¼ . Let it is (â„, ğ‘¤) [ğ‘’ğ‘ƒ , ğ‘’ğ‘ƒ ğ‘ƒ ] = ğºğ‘’ (ğ¼ , ğ‘Ÿğ¼ , â„, ğ‘¤)
ğ‘ğ‘Ÿğ¼ = (ğ‘Ÿğ¼ âˆ’ 1) Ã— (âˆ’1)
[ğ‘›ğ‘’ğ‘ƒ , ğ‘›ğ‘’ğ‘ƒ ğ‘ƒ ] = ğºğ‘’ (ğ¼ , ğ‘ğ‘Ÿğ¼ , â„, ğ‘¤)
return [ğ‘’ğ‘ƒ , ğ‘’ğ‘ƒ ğ‘ƒ , ğ‘›ğ‘’ğ‘ƒ , ğ‘›ğ‘’ğ‘ƒ ğ‘ƒ ]
where ğºğ‘’ is defined below.

Function ğºğ‘’ (ğ´, ğµ, â„, ğ‘¤)
ğ‘˜ = 0
for ğ‘– = 1 to â„ for ğ‘— = 1 to ğ‘¤ if ğµ(ğ‘–, ğ‘—) == 1
ğ‘…1(ğ‘˜) = ğ´(ğ‘–, ğ‘—)
ğ‘…2(ğ‘˜, 1) = ğ‘–, ğ‘…2(ğ‘˜, 2) = ğ‘—
return ğ‘…1, ğ‘…2

Next, we implant x bits and y bits of secrets in each edge and non-
method. Let ğ‘¥-bits of information is ğ‘ğ‘¥ and ğ‘¦-bits of information is edge pixel, respectively, of the cover image by the LSB substitution
ğ‘ğ‘¦. In that, the substitution task is performed by Eq. (18)
ğ‘ğ‘¦ = Î¦(ğ‘‘ğ‘¦)
where Î¦(ğ‘‘ğ‘¥) means binary conversion of decimal value ğ‘‘ğ‘¥ and Î¦(ğ‘‘ğ‘¦)
means binary conversion of decimal value ğ‘‘ğ‘¦.
Fig. 1 Decoder represents the overall extraction phase.

Result analysis

This Section is divided into several sub-sections. In Section 4.1 we go over the experimental setup with which our study is carried out. Section 4.4 discusses the mathematical representation of feature values. Later in Section 4.5 we analyze the complexity. Section 4.2 reveals our experimental results. Finally, Section 4.3 provides a clear discussion re- garding our findings.
We have investigated and compared the performance of the proposed scheme with the works of Bai et al. [24], Setiadi [25], Sultana et al.
[32] and Rasol et al. [34]. We first selected images for the experiment, set up our experiment, and then analyzed the results.

Experimental setup

We worked on MATLABâ€™s edition R(2017a) on Windows 7. The con- figuration of the laptop was comprised of an Intel (R) Core (TM) i5- 8500T CPU@ 2.10 GHz 2.11 GHz processor and RAM of 8.00 GB. We first collected 10 commonly used images, as shown in Fig. 3, as a stan- dard image dataset. We conducted all primary experiments on that stan- dard image dataset. To test our scheme in a large image dataset, we used the BOSS dataset [33]. The BOSS dataset consisted of 499 images. We
resized the images to 512 Ã— 512 and converted the color to grayscale to
fit our program.
We developed two different programs for each of the proposed meth- ods, Bai et al., Setiadi D. R. I. M., Sultana et al. and Rasol et al. where one is for data implantation and the other is for retrieving the implanted
secrets from stegos. According to the algorithm, we cleared ğ‘› bits of LSBs

ğ‘†(ğ‘ , ğ‘¡) = ğ¼ (ğ‘ , ğ‘¡) + Î¦(ğ‘ğ‘¥)
ğ‘†(ğ‘¢, ğ‘£) = ğ¼ (ğ‘¢, ğ‘£) + Î¦(ğ‘ğ‘¦)
(18)
from the cover images. We then verified the schemes by implanting dif- ferent numbers of bits in edge and non-edge pixels, however, these are

where Î¦(ğ‘ğ‘¥) stands for decimal conversion of binary ğ‘ğ‘¥, ğ‘  =
ğ‘’ğ‘ƒ ğ‘ƒ (ğ‘–, 1), ğ‘¡ = ğ‘’ğ‘ƒ ğ‘ƒ (ğ‘–, 2),  ğ‘¢ = ğ‘›ğ‘’ğ‘ƒ ğ‘ƒ (ğ‘—, 1), ğ‘£ = ğ‘›ğ‘’ğ‘ƒ ğ‘ƒ (ğ‘—, 2)  and  1 â‰¤ ğ‘– â‰¤
ğ‘ğ‘œ_ğ‘‚ğ‘“ _ğ¸ğ‘‘ğ‘”ğ‘’_ğ‘ƒ ğ‘–ğ‘¥ğ‘’ğ‘™ğ‘ , 1  â‰¤ ğ‘—  â‰¤ ğ‘ğ‘œ_ğ‘‚ğ‘“ _ğ‘›ğ‘œğ‘›ğ¸ğ‘‘ğ‘”ğ‘’_ğ‘ƒ ğ‘–ğ‘¥ğ‘’ğ‘™ğ‘ .  Here,  ğ‘ğ‘¥   will be different for each of the ğ‘  and ğ‘¡. The same is true for ğ‘ğ‘¦. This means that, each time a different ğ‘ğ‘¥ and ğ‘ğ‘¦ of secret will be implanted.
That stego image ğ‘† is then sent to a receiver end. The receiver end next extracts the implanted secrets from ğ‘†.

3.3. Extraction phase

The extraction phase undergoes necessary pre-processing tasks. The
receiver copies the stego image ğ‘† to ğ¼ . It then clears ğ‘› bits of LSBs extraction phase is depicted in Fig. 1 Decoder. Like the sender, the from ğ¼ by Eq. (9). Consider, that ğ‘›-LSB cleared image is also ğ¼ . The scheme then applies the same predictor to ğ¼ to predict its pixel val-
ues. That prediction of pixel values is done by Eqs. (10) to (12). Again,
no more than ğ‘› bits in any way. The performance of the schemes is ver-
ified by several feature values, such as edge pixel generation capability,
embedding payload, peak signal-to-noise ratio (PSNR), structural simi- larity index matrix (SSIM), standard deviation, correlation coeï¬ƒcient, entropy, cosine similarity, pixel difference histogram, and chi-square text, etc.

Experimental results

In order to distinguish between edge and non-edge pixels in the ex- periment, we initially employed Canny, Sobel, and Log edge detectors in one, three, and five LSBs cleared images. When given an input image, the Canny, Sobel, and Log-based edge detector functions of MATLAB return an edge image. Binary images are used for edges. Utilizing 10 input images as a starting point, Table 2 depicts the edge images that
plant ğ‘¥ bits of information in edge pixels and ğ‘¦ bits of information in were generated. It is already mentioned that the embedding rules im-



Table 2
original   images   (ğ‘›   =   0)   and   5-LSBs   cleared   images   (ğ‘›   =   5). Edge images generated from ten cover images. The images were formed for Canny, Sobel, and Log edge detectors both from





Fig. 3. Cover images for the experiment (a) Baboon, (b) Barbara, (c) Basket, (d) Boat, (e) F16, (f) Lena, (g) Livingroom, (h) Peppers, (i) Walkbridge, (j) Wheel.


Fig. 4. Stego images for the corresponding cover images: (a) Baboon, (b) Barbara, (c) Basket, (d) Boat, (e) F16, (f) Lena, (g) Livingroom, (h) Peppers, (i) Walkbridge,
(j) Wheel.


tuple (ğ‘¥, ğ‘¦). As ğ‘¥ > ğ‘¦, an attempt of increasing the number of edge pix- non-edge pixels. In all following discussions, we will represent that as a
els will certainly boost the yielded embedding capacity. We did it by detecting edges in prediction error space. The justification is shown in Figs. 3 and 4. Table 3 also summarises the number of edge pixels that were found in ten sample images by different methods. Table 3 provided statistics collected from 5-LSBs cleared images.
We analyzed all the proposed and competing schemes to check their quantitative ability in hiding data. For that, all the schemes were exper-
imented with for different values of (ğ‘¥, ğ‘¦). Here Tables 5 and 6 repre-
sent the payload results for (ğ‘¥, ğ‘¦) âˆˆ {(2, 1), (3, 1), (3, 2), (4, 1), (4, 2), (4, 3)}.
the different values of (ğ‘¥, ğ‘¦) is published. We analyzed the performance There, a list of how much data can be hidden by a scheme for each of
shown in Fig. 7 for (ğ‘¥, ğ‘¦) = (4, 1). The same result is depicted in Fig. 8 for in the embedding capacity as well. Embedding capacity is graphically
499 images of the BOSS dataset.
We also analyzed the visual quality and structural originality of stego images. Visual quality is measured by PSNR values. Payload per losses of
for  every  (ğ‘¥, ğ‘¦)  are  listed  in  Tables  7  and  8. PSNR is sketched in Fig. 9. The structural similarity index value, SSIM,

Discussions on results

The primary objective of this research is to strengthen the data- hiding ability of our scheme in terms of implanted data amount. As we worked on edge detection-based data embedment arena and the pro- posed scheme implanted more bits in edge pixels than the non-edge ones, we gave emphasis to increasing the number of edge pixels. For this, we applied the edge detector algorithms in prediction error space. Experiments have shown that this method is quite effective. The results of Fig. 5 is a snap-shoot of our experiment that is done on Lenaâ€™s im- age. The figure is annotated with obtained edge pixels. Compared to







Table 3
Statistics of Edge pixels for ğ‘› = 5.



state-of-art, that number is about double in our scheme. For ten images of the standard dataset, the results are shown in detail in Fig. 5 and
Table 3. Table 3 states the results for ğ‘› = 5, where Fig. 5 depicts the
same for ğ‘› = 1, ğ‘› = 3 and ğ‘› = 5. Corresponding embedding capacities are
depicted in 6. The results of Figs. 5 and 6 and Table 3 confirm that all
edge detectors recognize more contents as edge contents in prediction error space.
Fig. 5. A scene of how the edge detectors perform in prediction error space in detecting edge. The figure shows that each edge detector detects a large number of edge pixels in the prediction error space than in the image domain. Since our target is to increase the number of Edge pixels, this figure proves that the application of an edge detector in prediction error space has been successful.


















































edge pixels at a rate of (ğ‘¥, ğ‘¦). The embedding capacity is depicted in After justifying that truth, we implanted secrets in edge and non-
Fig. 7 for ten sample images. The figure states that the proposed scheme enhances the embedding capacity by about Bai 80% of et al. [24], 50% of Setiadi [25], 90% of Sultana et al. [32] and 70% of Rasol et al. [34]. To justify the performance of the proposed scheme, we experi- mented on 499 images of the BOSS dataset as well. The experiments said the same fact. Those results are summarised in Fig. 9 In all the im- ages, the proposed scheme provides dominating results over the other competing schemes. However, those depicted results were obtained for
(ğ‘¥, ğ‘¦) = (4, 1) only. Table 4 represents the results for all combinations
of (ğ‘¥, ğ‘¦), e.g., (ğ‘¥, ğ‘¦) âˆˆ {(2, 1), (3, 1), (3, 2), (4, 1), (4, 2), (4, 3)}. Additionally,
this table also explains that the proposed scheme offers much more pay-
loads than the alternatives. That the proposed scheme considerably en- hances the embedding capacity is therefore validated.
When a scheme implants its secrets in an image, obviously, it de-
that were implanted in an image per one dB of ğ‘ƒ ğ‘†ğ‘ğ‘… loss. The mea- stroys the visual quality of that image. We measured the number of bits
surement is illustrated graphically in Fig. 9. It is easy to see from the diagram that the proposed scheme implants a satisfactory amount of data as opposed to one dB PSNR loss, and it is higher than the compet- ing schemes. Again, the results of SSIM are figured out in Table 5 for



Fig. 6. Number of edge pixels in image and prediction error space (PES). After clearing 1-bit LSB, we com- puted edge pixels that were detected by Canny. A sim- ilar approach was done for 3-bit and 5-bit LSB-cleared images. These are represented in the figure by solid lines and diamond, square, and circle markers, respec- tively. The same was done by applying our predictor and then employing Canny in PES. These results are presented by dash lines and diamond, square, and cir- cle markers, respectively. The figure states that Canny well performs in all PES-based experiments.
























ure is generated by embedding at (x,y)=(4,1). The Fig. 7. Comparison of embedding rate. This fig-
figure states that the proposed scheme yields em- bedding capacity at a dominating rate which is about 50% higher than Setiadi, 70% higher than Rasol et al., 80% higher than Bai at al. and 90% higher than Sultana et al.




Fig. 8. Performance comparison of the proposed scheme with Bai, Setiadi, Sultana, and Rasol in terms of capacity in the BOSS image dataset. That experiments were done to justify the proposed scheme in a large image dataset. The figure states that our proposal is unbeaten in producing a larger embedding capacity.




























Fig. 9. Number of embedded bits per 1dB loss of PSNR. Regarding that per 1dB loss of PSNR, the pro- posed scheme noticeably dominates the other com- peting schemes.




Fig. 10. Difference of standard Deviations of cover and stego images. The figure states that the differences are very small, close to each other. The proposed method is closer to zero.
































Fig. 11. Correlation coeï¬ƒcients. All the schemes present higher correlations.


Fig. 12. Difference of entropy between cover and stego. The differences are very small and insignifi- cant to mention.
































Fig. 13. Cosine similarity values. Measured cosine similarity values are very high in all the images.


Fig. 14. Pixel Difference Histogram of Baboon.






























Fig. 15. Pixel Difference Histogram of Basket.


Fig. 16. Comparison of chi-square values among the schemes in the logarithmic scale.






















Table 4
Execution time per image (in seconds).
parameters. PSNR is measured by Eq. (22).

ğ‘ƒ ğ‘†ğ‘ğ‘… = 10 log
Where,
2552
10 ğ‘€ğ‘†ğ¸
(22)

ğ‘¤  â„




all the stated combinations of (ğ‘¥, ğ‘¦). Depending on the distortion rate SSIM value ranges from 0 to 1. A higher value of SSIM signifies better originality of the image. The table confirms that the SSIM values of all
ğ‘€ğ‘†ğ¸ =   1   âˆ‘ âˆ‘(ğ‘†  âˆ’ ğ¶ğ‘–, ğ‘—)2;
here, ğ‘† is the stego image and ğ¶ is the original cover image.
We expect to have our ğ‘ƒ ğ‘†ğ‘ğ‘… value at 100dB. That ğ‘ƒ ğ‘†ğ‘ğ‘… is, in-
age is a tempered image. Hence, the value of ğ‘ƒ ğ‘†ğ‘ğ‘… will deteriorate. deed, achievable for two identical images only. However, the stego im- The amount of loss in ğ‘ƒ ğ‘†ğ‘ğ‘… value, let ğ‘™ğ‘œğ‘ ğ‘ ğ‘ƒ ğ‘†ğ‘ğ‘…, is measured by (23).
ğ‘™ğ‘œğ‘ ğ‘ ğ‘ƒ ğ‘†ğ‘ğ‘… = (100 âˆ’ ğ‘ƒ ğ‘†ğ‘ğ‘…)ğ‘‘ğµ	(23)
Again, SSIM is calculated by Eq. (24).
  (2ğœ‡ ğœ‡ + ğ¶ )(2ğœ  + ğ¶ ) 

the schemes are both high and very close to each other. Though these
ğ‘†ğ‘†ğ¼ğ‘€ =
ğ‘ ğ‘ 
1	ğ‘ğ‘ 	2
(24)

(ğœ‡2 + ğœ‡2 + ğ¶1)(ğœ2 + ğœ2 + ğ¶2)

schemes randomly dictate one another, there is nothing significant to
ğ‘	ğ‘ 
ğ‘	ğ‘ 

mention about the level of dictation. Thus, we can conclude that the proposed schemes do not destroy the quality of the image at any signif- icant level, and are even higher than the others.
Mathematical representation of feature values

the number of edge and non-edge pixels in a cover image be ğ‘’ğ‘ğ‘‡ and Payload is the total number of implanted bits in the cover image. Let
ğ‘›ğ‘ğ‘‡ , respectively. Then the maximum achievable payload ğ‘ƒ ğ¿ is defined
by Eq. (20).
ğ‘ƒ ğ¿ = ğ‘’ğ‘ğ‘‡ Ã— ğ‘¥ + ğ‘›ğ‘ğ‘‡ Ã— ğ‘¦	(20)
Sometimes, capacity is also measured to have a closer look at the per- formance of a scheme. Capacity means the number of implanted bits per
pixel. Embedding capacity, ğ¸ğ¶, is measured by Eq. (21)
In Eq. (24), ğœ‡ğ‘ and ğœğ‘ are the mean and variance of pixel values in the cover image. Likewise cover, ğœ‡ğ‘  and ğœğ‘  are the same for the stego image. Again, ğœğ‘ğ‘  is the co-variance between the cover and stego image. ğ¶1 and
ğ¶2 are two constants. In experiment, we set ğ¶1 = 0.0001 and ğ¶2 = 0.0009
There are many methods of analyzing the security of a scheme. Very
simple but common ones are entropy measurement, analyzing correla- tion among the pixels, and checking the cosine similarity between the cover and stego image. The entropy is measured by Eq. (25).
ğ» = âˆ’  ğ‘ğ‘˜ log2(ğ‘ğ‘˜)	(25)
ğ‘˜
where, ğ‘ğ‘˜ is the probability associated with gray value ğ‘˜ and 1 â‰¤ ğ‘˜ â‰¤ 255.
In our experiment, we used the population correlation coeï¬ƒcient.
Populations were measured from the pixel histogram. Population corre- lation is defined by Eq. (26).

ğ¸ğ¶ =	ğ‘
â„ Ã— ğ‘¤
Where â„ and ğ‘¤ are the image height and width.
(21)
ğœŒ  =  ğœğ‘ğ‘ 
ğ‘ğ‘ 	ğœğ‘ ğœğ‘ 
(26)

While hiding data, maintaining image quality is a challenging issue. PSNR and SSIM are two commonly used image distortion measurement
where ğœğ‘ and ğœğ‘  are population standard deviations in cover ğ¶ and stego
ğ‘†. Again, ğœğ‘ğ‘  is the co-variance between the cover and stego image.


Table 5
Comparison of the payload of the proposed scheme with its competing methods.















Table 6
Comparison of the payload of the proposed scheme with its competing methods.


Table 7
Comparison of SSIM results of the proposed scheme with other competing schemes.


Table 8
Comparison of SSIM results of the proposed scheme with other competing schemes.



Equation (27) gives us the cosine similarity values.
ğ‘“	(ğ¶, ğ‘†) = ğ‘ğ‘œğ‘ (ğœƒ)
statistics, we measured correlation coeï¬ƒcients ğœŒğ‘† ğ¶ between the cover than the others and it is closer to zero. To verify further with similar

ğ¶ğ‘œğ‘ ğ‘†ğ‘–ğ‘š
âˆ‘â„  âˆ‘ğ‘¤
and stego image. ğœŒğ‘† ğ¶ > 0 means a positive correlation between cover

=	â„
ğ‘–=1
ğ‘¤
ğ‘—=1
ğ¶(ğ‘–,ğ‘—)âˆšâˆ‘â„
ğ‘¤
ğ‘—=1
ğ‘†(ğ‘–,ğ‘—)
and stego image and ğœŒğ‘† ğ¶ signifies a perfect relationship when it reaches
to 1. Similarly, a negative value of ğœŒğ‘† ğ¶ indicates a negative relationship.

where ğ¶ and ğ‘† are cover and stego images.
When they are the same, the function ğ‘“ğ¶ğ‘œğ‘ ğ‘†ğ‘–ğ‘š provides the highest value, which is 1. ğ‘“ğ¶ğ‘œğ‘ ğ‘†ğ‘–ğ‘šâ€™s computed value depends on the tempering effect in image ğ‘†. The more tempered in ğ‘†, the smaller the value of
ğ‘“ğ¶ğ‘œğ‘ ğ‘†ğ‘–ğ‘š.

Analyzing the complexity

We compare the time complexity of different schemes by analyzing their execution time and compared with existing studies and result is shown in Table 4. In terms of completion time author Baiâ€™s study outper- formed every other study. On average authorâ€™s proposed scheme require about 13.42 s [24]. Similar to Baiâ€™s study, Sultana and Rasolâ€™s proposed framework requires 13.43 and 13.52 s [32,34]. Setiadiâ€™s study on the other hand requires 14.06 s [25]. On average, our suggested method consumes 14.67 s per image. Even though it ends up taking a little bit longer, it exceeds all previous research and yields significantly superior outcomes as a consequence. Thus this difference of 0.5â€“1 s can be over- looked.

Security analysis

We statistically analyzed our scheme to check its robustness against various attacks. We first measured the standard deviation of pixel values from their mean, separately, in cover and stego images. Let the standard
deviation in cover and stego image is ğœğ‘ and ğœğ‘ . Next, we calculated
ğœŒğ‘† ğ¶ = 0 stands for no relationship between two images. Results of ğœŒğ‘† ğ¶
are depicted in Fig. 11. Though the proposed method shows a lower
correlation value, its difference from others is insignificance. Rather, as
with others, it represents a higher correlation between cover and stego.
We measured the entropy values ğ» as well. We computed ğ» both
in cover and stego images. Next, we calculated their differences. That
difference value is zero for two identical images. Results are plotted in Fig. 12. The figure shows that none of the results are greater than 0.08, i.e., these are very small and close to zero. We also computed cosine similarities between cover and stego images. That value is 1 for two identical images and 0 for two fully mismatched images. The results are demonstrated in Fig. 13. The figure illustrates that all the values are greater than 0.999, which is very high. Besides, the values in all the schemes are very close to each other, where, the maximum variation is o.0008, i.e., 0.9998-0.999.
Thus, it can be deduced from the results of these experiments that our method is strong enough to protect against attacks on implanted data.
We used statistical tools of pixel difference histogram (PDH) to iden- tify the stego images. The PDH of the original images and corresponding stego images are shown in Figs. 14 and 15.
We also used another statistical tool of Chi-Square test for determin- ing the difference between stego and cover images. This test is used to find out whether a difference between two images is due to chance or a relationship between them. The experimental result of the Chi-square test is shown in Fig. 16.

their difference by ğœğ‘‘ = ğœğ‘ âˆ’ ğœğ‘ . Ideally, ğœğ‘‘ should be zero for a non-
tempered image. That ğœğ‘‘ is drawn in Fig. 10 against different images.
The results show that the proposed scheme produces smaller differences
ğœ’ğ·ğ¹ 2 =
(ğ‘†ğ‘– âˆ’ ğ¶ğ‘–)2
ğ¶ğ‘–
(28)

where ğ·ğ¹ is the degrees of freedom, ğ¶ and ğ‘† are cover and stego im- ages. ğ·ğ¹ is calculated by (Fig. 16)
ğ·ğ¹ = (â„ âˆ’ 1) âˆ— (ğ‘¤ âˆ’ 1)	(29)
Here â„ and ğ‘¤ are the height and width of the cover and stego images
(Tables 6â€“8).

Discussion

Using this research, it can secure both messages and communicating parties. No intruder can able to receive some beneficial information from the sending file during transmission. Besides Corporations government and law enforcement agencies can connect privately and communicate secretly.
Although this model has many advantages it also has some limi- tations. This model cannot work without edge detectors. This model consumes time when applying predictor and it is not a big matter. If a steganography approach generates someone to suspect the carrier medium, thus the model has been unsuccessful.

Conclusion

This research first time proposes the idea of grouping image pixels as edge and non-edge by applying an edge detector in its prediction er- ror space. The research first generates a prediction error space from a cover image and then applies a desired predictor in that created error space. The locations of detected edge errors are mapped in the cover image to classify edge and non-edge pixels. That strategy, significantly, increases the number of edge pixels. As the edge detection-based embed- ding schemes implant more bits in edge pixels than non-edge pixels, the same rules then well perform in the proposed method. The experimental results deduce that the scheme does not compromise the visual or struc- tural quality of the cover image more than the other competing schemes. Moreover, statistical analyses exhibit that the proposed scheme demon- strates stronger security against attacks. In the future, we hope to work on making the scheme reversible. At the same time, we would like to repeatedly embed an image with a back-and-forward strategy. In the back-and-forward strategy, we will increase the present values of pixels in the first cycle of data embedment and decrease the updated values in the second cycle of data embedment. Thus, we want to implant any length of the message in an image by managing its visual quality. In that case, managing the schemeâ€™s reversibility is a pre-requisition. We also would like to work with other media such as audio, video, and text. We will apply this model for forensic or other security purposes.

Availability of data and materials

We used data from â€œThe Bank of Standardized Stimuli (BOSS), a New Set of 480 Normative Photos of Objects to Be Used as Visual Stimuli in Cognitive Research, Mathieu B. Brodeur, Emmanuelle Dionne-Dostie, Tina Montreuil, Martin Lepageâ€ and various reliable sources (Internet).

CRediT authorship contribution statement

Habiba Sultana: Conceptualization, Methodology, Soft- ware. A.H.M. Kamal: Conceptualization, Methodology, Software. Tasnim Sakib Apon: Data curation, Writing â€“ original draft.

Acknowledgments

The first author is a fellow of the ICT division of the Ministry of Post, Telecommunication, and Information Technology of the Government of Bangladesh. Therefore, we want to devote a thank to the concerned min- istry, and at the same time, we would like to acknowledge that support.
References

H. Al-Dmour, A. Al-Ani, A steganography embedding method based on edge identi- fication and XOR coding, Expert Syst. Appl. 46 (2016) 293â€“306.
H. Sultana, A study on steganography and steganalysis, Int. J. Sci. Eng. Res. 9 (12) (2018).
H. Sultana, A.H.M. Kamal, An edge detection based reversible data hiding scheme, in: 2022 IEEE Delhi Section Conference (DELCON), IEEE, 2022.
P.W. Adi, F.Z. Rahmanti, N.A. Abu, High quality image steganography on integer harr wavelet transform using modulus function, in: International Conference on Sci- ence in Information Technology (ICSITech), IEEE, 2015.
H. Sultana, A.H.M. Kamal, M.M. Islam, Enhancing the robustness of visual degrada- tion based HAM reversible data hiding, J. Comput. Sci. 12 (2) (2016) 88â€“97.
A.H.M. Kamal, M.M. Islam, Enhancing embedding capacity and stego image quality by employing multi predictors, J. Inf. Secur. Appl. 32 (2017) 59â€“74.
A.H.M. Kamal, M.M. Islam, Boosting up the data hiding rate through multi cycle embedment process, J. Vis. Commun. Image Represent. 40 (2016) 574â€“588.
A.H.M. Kamal, M.M. Islam, Capacity improvement of reversible data hiding scheme through better prediction and double cycle embedding process, in: 2015 IEEE In- ternational Conference on Advanced Networks and Telecommuncations Systems (ANTS), IEEE, 2015.
A.H.M. Kamal, M.M. Islam, An image distortion-based enhanced embedding scheme, Iran J. Comput. Sci. 1 (3) (2018) 175â€“186.
A.H.M. Kamal, M.M. Islam, A prediction error based histogram association and map- ping technique for data embedment, J. Inf. Secur. Appl. 48 (2019) 102368.
A.H.M. Kamal, M.M. Islam, Z. Islam, An embedding technique for smartcard-sup- ported e-healthcare services, Iran J. Comput. Sci. 3 (4) (2020) 195â€“205.
A.H.M. Kamal, M.M. Islam, Enhancing the embedding payload by handling the affair of association and mapping of block pixels through prediction errors histogram, in: 2016 International Conference on Networking Systems and Security (NSysS), IEEE, 2016.
W. Hong, Adaptive reversible data hiding method based on error energy control and histogram shifting, Opt. Commun. 285 (2012) 101â€“108.
H. Yao, C. Qin, Z. Tang, Y. Tian, Improved dual-image reversible data hiding method using the selection strategy of shiftable pixelsâ€™ coordinates with minimum distortion, Signal Process. 135 (2016) 26â€“35.
S. Yi, Y. Zhou, Binary-block embedding for reversible data hiding in encrypted im- ages, Signal Process. 133 (2017) 40â€“51.
A.H.M. Kamal, M.M. Islam, Enhancing the performance of the data embedment pro- cess through encoding errors, Electronics (Basel) 5 (4) (2016) 79.
A.H.M. Kamal, M.M. Islam, Facilitating and securing oï¬„ine e-medicine service through image steganography, Healthc. Technol. Lett. 1 (2) (2014) 74â€“79.
M.D. Hasan, M.A.M. Amin, S.T. Mahdi, Steganalysis techniques and comparison of available softwares, Cyberspace (2020).
C.F. Lee, W. C-Y, C. K-C, An eï¬ƒcient reversible data hiding with reduplicated exploit- ing modification direction using image interpolation and edge detection, Multimed. Tools Appl. (2016).
S. Kumar, A. Singh, M. Kumar, Information hiding with adaptive steganography based on novel fuzzy edge identification, Defence Technol. 15 (2) (2019) 162â€“169.
S. Sun, A novel edge based image steganography with 2ğ‘˜ correction and Huffman
encoding, Inf. Process. Lett. (2015).
C. Vanmathi, S. Prabu, Image steganography using fuzzy logic and chaotic for large payload and high imperceptibility, Int. J. Fuzzy Syst. (2017).
G. Swain, Adaptive pixel value differencing steganography using both vertical and horizontal edges, Multimed. Tools Appl. 75 (21) (2016) 13541â€“13556.
J. Bai, C.-C. Chang, T.-S. Nguyen, C. Zhu, Y. Liu, A high payload steganographic algorithm based on edge detection, Displays 46 (2017) 42â€“51.
D.R. Setiadi, Improved payload capacity in LSB image steganography uses dilated hybrid edge detection.
E.J. Kusuma, O.R. Indriani, C.A. Sari, E.H. Rachmawanto, D.R.I.M. Setiadi, An im- perceptible LSB image hiding on edge region using DES encryption, in: 2017 Inter- national Conference on Innovative and Creative Information Technology (ICTTech), IEEE, 2018.
S. Khan, N. Ahmad, M. Ismail, N. Minallah, T. Khan, A secure true edge based 4 least significant bits steganography, IEEE, 2015.
W.J. Chen, C.C. Chang, T.H.N. Le, High payload steganography mechanism using hybrid edge detector, Expert Syst. Appl. 37 (2010).
H.W. Tseng, H.S. Leng, High-paylaod block-based data hiding scheme using hybrid edge detector with minimal distortion, IET Image Process. 8 (2014).
K. Gaurav, U. Ghanekar, Image steganography based on canny edge detection, dila- tion operator and hybrid coding, J. Inf. Secur. Appl. 41 (2018) 41â€“51.
B. Vishnu, S.R. Sajeesh, L.V. Namboothiri, Enhanced image steganography with PVD and edge detection, in: 2020 Fourth International Conference on Computing Method- ologies and Communication (ICCMC), IEEE, 2020.
H. Sultana, A.H.M. Kamal, Image steganography system based on hybrid edge de- tector, in: 2021 24th International Conference on Computer and Information Tech- nology (ICCIT), IEEE, 2021.
D.R.I.M. Setiadi, J. Jumanto, An enhanced LSB-image steganography using the hy- brid canny-sobel edge detection, Cybern. Inf. Technol. 18 (2) (2018).
M.B. Brodeur, E. Dionne-Dostie, T. Montreuil, M. Lepage, The bank of standardized stimuli (BOSS), a new set of 480 normative photos of objects to be used as visual stimuli in cognitive research, PLoS ONE 5 (2010) e10773.
