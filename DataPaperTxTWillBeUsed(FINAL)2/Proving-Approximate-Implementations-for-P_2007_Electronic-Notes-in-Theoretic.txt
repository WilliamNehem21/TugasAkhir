Electronic Notes in Theoretical Computer Science 174 (2007) 71–93	
www.elsevier.com/locate/entcs

Proving Approximate Implementations for Probabilistic I/O Automata
Sayan Mitra1	Nancy Lynch2
Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology
Cambridge, USA

Abstract
In this paper we introduce the notion of approximate implementations for Probabilistic I/O Automata (PIOA) and develop methods for proving such relationships. We employ a task structure on the locally controlled actions and a task scheduler to resolve nondeterminism. The interaction between a scheduler and an automaton gives rise to a trace distribution —a probability distribution over the set of traces. We define a PIOA to be a (discounted) approximate implementation of another PIOA if the set of trace dis- tributions produced by the first is close to that of the latter, where closeness is measured by the (resp. discounted) uniform metric over trace distributions. We propose simulation functions for proving approxi- mate implementations corresponding to each of the above types of approximate implementation relations. Since our notion of similarity of traces is based on a metric on trace distributions, we do not require the state spaces nor the space of external actions of the automata to be metric spaces. We discuss applications of approximate implementations to verification of probabilistic safety and termination.
Keywords: Approximate implementation, equivalence, Approximate simulation, Abstraction, Probabilistic I/O Automata.


1	Introduction
Implementation relations play a fundamental role in the study of complex interact- ing systems because they allow us to prove that a given concrete system implements an abstract specification. Formally, an automaton is said to implement another au- tomaton if the set of traces or the observable behavior of the first is subsumed by that of the latter. Many different kinds of implementation or abstraction re- lations and their corresponding proof methods have been developed for timed [1], hybrid [17,30,29] and probabilistic automata [19,20,5,2,28,4].
These traditional notions of implementation rely on equality of traces. That is, every trace of the concrete system must be exactly equal to some trace of the

1 Email: mitras@theory.csail.mit.edu
2 Email: lynch@theory.csail.mit.edu

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2006.11.040

abstract specification. It is well known from [16,10,15] that such strict equality based implementation relations are not robust. Small perturbations to the parameters of the system produces traces with slightly different numbers (representing say, timing or probability information), and thus breaks the equality between traces. One way to overcome this problem is to relax the notion of implementation by taking into consideration the “similarity” of traces that are not exactly equal. In [16] Jou and Smolka formalized “similarity” of traces using a metric and developed the corresponding notion of approximate equivalence for probabilistic automata. Based on similar ideas, there is now a growing body of work on developing robust notions of approximate implementations; in Section 1.1, we briefly describe previous contributions in this area that are related to our work. Apart from providing robust implementation relations, notions of approximate implementation also enable us to create abstract models without introducing extra nondeterminism.
In this paper we introduce the notion of approximate implementations for the Probabilistic Input/Output Automaton (PIOA) [27,6] and develop simulation based methods for proving such relationships. A PIOA is a nondeterministic automaton with a countable state space. Transitions are labelled by actions. Many transitions may be possible from a given state. Each transition gives a discrete probability dis- tribution over the state space. We use a task structure [5]—an equivalence relation on the set of locally controlled actions—as a means for restricting the nondetermin- ism in a PIOA. The resulting automaton model is called task-PIOA. A task-PIOA interacts with a task scheduler to give rise to a probability distribution over its executions. For every such distribution there exists a corresponding distribution over its set of traces, which is called a trace distribution. Visible behavior of a task-PIOA is the set of trace distributions that it can produce. A task-PIOA is said to (exactly) implement another task-PIOA if the set of trace distributions of the first is a subset of the trace distributions of the latter. Implementations, simulation relations for proving implementations, and compositionality results for task-PIOAs are presented in [5]. A special kind of approximate implementation relation that tolerates small differences in the probability of occurrence of a particular action is used in [6] to verify a security protocol. In contrast, the notions of approximation introduced here are more general because they are based on metrics on trace dis- tributions. We define two kinds of approximate implementations of task-PIOAs:
(1) uniform approximate implementation is based on the uniform metric of trace
distributions [23], and (2) discounted approximate implementation is based on the discounted uniform metric.
A PTIOA A is a δ-approximate implementation of another PTIOA B, for a positive δ, if the for any trace distribution of A, there exists a trace distribution of B such that their discrepancy over any measurable set of traces is at most δ. We present Expanded Approximate Simulations (EAS) for proving uniform approx- imate implementations. EAS is a natural generalization of the simulation relation presented in [6]. Let μ1 and μ2 be probability distributions over executions of task- PIOAs A and B. An EAS from A to B is a function φ mapping each μ1, μ2 pair to a nonnegative real. The number φ(μ1, μ2), is a measure of how similar μ1 and μ2 are

in terms of producing similar trace distributions. Informally, if φ(μ1, μ2) ≤ ϵ, for some ϵ ≥ 0, then it is possible to closely (with respect to the uniform metric on trace distributions) simulate from μ2 anything that can happen from μ1, and further, the
resulting distributions, say μ' and μ' , are also close in the following sense. There
exists a joint distribution ψ supported on the set {(η1, η2) | φ(η1, η2) ≤ ϵ} such that
the marginals of ψ have means μ' and μ' , respectively. Informally, this means that
' and μ' can be decomposed into a set of measures that are close in the sense of φ.
Uniform approximate implementations are useful for deducing probabilistic safety properties. However, since they gives absolute bounds on the discrepancy over any set of traces, they do not give us useful information when the probability of the set itself is smaller than the approximation factor δ. To get useful bounds on the discrepancies over a sequence of sets of traces that have monotonically decreas- ing probabilities, we have to employ different approximation factors for each set. We address this problem by introducing a sequence {δk}k∈N of discount factors, and defining PTIOA A to be a δk-discounted approximate implementation of B, if the for any trace distribution of A, there exists a trace distribution of B such that their discrepancy over any trace of length k is at most δk. We define Discounted Approx- imate Simulations (DAS) in a similar way as we defined EAS and prove that they are sound for proving discounted approximate implementations. We demonstrate the utility of discounted approximate implementations and DASs by proving that the probability of termination of an ideal randomized consensus protocol (after a certain number of rounds) is close to the same probability for a protocol that uses biased coins.

Related Work
As we mentioned, Jou and Smolka [16] first introduced the idea of formalizing sim- ilarity of traces by using metrics. Approximation metrics for probabilistic systems in the context of Labelled Markov Processes (LMP) have been extensively inves- tigated and many fundamental results have been obtained by Desharnais, Gupta, Jagadeesan and Panangaden [10,8,9] and by van Breugel, Mislove, Ouaknine, and Worrell [35,32,33,21,22]. The first set of authors introduced a Kantorovich-like met- ric for LMPs and presented the logical characterization of this metric. Van Breugel et al. have presented intrinsic characterizations of the topological space induced by the above metric. This characterization is based on a final coalgebra for a functor on the category of metric spaces and nonexpansive maps. Another interesting facet of this body of work is the polynomial time algorithm for computing the metric pre- sented by van Breugel and Worrell in [34]. For Generalized Semi-Markov Processes (GSMP) [15], Gupta, Jagadeesan and Panangaden have developed pseudo-metric analogues of bisimulation and have shown that certain observable quantitative prop- erties are continuous with respect to the introduced metric. Kwiatkowska and Nor- man have developed the denotational semantics for a divergence-free probabilistic process algebra based on a metric on probability distribution over executions [18]. In the non-probabilistic setting, Girard and Pappas [13,12] have developed the theory of approximate implementations for Metric Transition Systems (MTS). The

state space and the space of external actions of an MTS are metric spaces. Based on these metrics, the authors develop a hierarchy of approximation pseudo-metrics between MTSs measuring distance between reachable sets, sets of traces and bisim- ulations. The authors have also developed algorithms for exactly and approximately computing these metrics.
Our work differs from all of the above in at least one of the following ways: (a) the task-PIOA model allows both nondeterministic and probabilistic choices, and
(b) the implementation relation in our framework is based on trace distributions and not bisimilarity of states. Approximate implementation is derived from a metric over trace distributions, and thus, we do not require the state spaces of the underlying automata nor the common space of external actions to be metric spaces. Metrics on trace distributions of PIOAs are used by Cheung in [7]to show that sets of trace distributions form closed sets in a certain metric space. This result is then used to show that finite tests are sufficient to distinguish between a members of a certain class of PIOAs. The metric used in the above work is related to our uniform metric but it is defined on the set [0, 1]Traces whereas our uniform metric is exclusively defined on the set of trace distributions.
Organization
In the next Section, we give the basic definitions and results from the task-PIOA framework. We refer the reader to [14] for a detailed treatment and for all the proofs. In Section 3 we introduce uniform approximate implementations for closed task-PIOAs and we propose expanded approximate simulations as a sound method for proving uniform implementations. In Section 4, we discuss the need for discount- ing when measuring discrepancies in trace distributions. This leads to the notion of discounted approximate implementations and we propose a second type of sim- ulations for proving such implementation relationships. Finally, in Section 5 we outline how our results extend to general (not necessarily closed) task-PIOAs and conclude with a discussion on future research directions. Proofs of auxiliary lemmas and formal statements of some relevant results from [5] appear in the Appendices.
Task-PIOA Framework
Given a set X, we denote a σ-algebra over X by FX , the set of discrete (sub-) probability measures on X by Disc(X) (resp. SubDisc(X)). If μ is a discrete proba- bility or sub-probability measure on X, the support of μ, written as supp(μ), is the set of elements of X that have non-zero measure. The task-PIOA model used in this paper is slightly more general than the one in [5] because we allow the starting configuration of an automaton to be any distribution over states and not just a Dirac mass.
Definition 2.1 A task-structured Probabilistic I/O Automaton A is a 7-tuple (Q, ν¯, I, O, H, D, R) where:
Q is a countable set of states;

ν¯ ∈ Disc(Q) is the starting distribution on states;
I, O and H are countable and pairwise disjoint sets of actions, referred to as input, output and internal actions, respectively. The set A := I ∪ O ∪ H is called the set of actions of A. If I = Ø, then A is closed. The set of external actions of A is E := I∪O and the set of locally controlled actions is L := O∪H.
D ⊆ (Q × A × Disc(Q)) is a transition relation. An action a is enabled in a state q if (q, a, μ) ∈ D for some μ.
R is an equivalence relation on the locally controlled actions. The equivalence classes of R are called tasks. A task T is enabled in a state q if some action a ∈ T is enabled in q.
In addition, A satisfies:
Input enabling: For every q ∈ Q and a ∈ I, a is enabled in q.
Transition determinism: For every q ∈ Q and a ∈ A, there is at most one
μ ∈ Disc(Q) such that (q, a, μ) ∈ D.
Action determinism: For every q ∈ Q and T ∈ R, at most one a ∈ T is enabled in q.
An execution fragment of A is a finite or infinite sequence α = q0 a1 q1 a2 ... of alternating states and actions, such that (i) if α is finite, then it ends with a state; and (ii) for every non-final i, there is a transition (qi, ai+1, μ) ∈ D with qi+1 ∈ supp(μ). We write α.fstate for q0, and, if α is finite, we write α.lstate for its last state. We use FragsA (resp., Frags∗ ) to denote the set of all (resp., all finite) execution fragments of A. An execution of A is an execution fragment beginning from some state in supp(ν¯). ExecsA (resp., Execs∗ ) denotes the set of all (resp., finite) executions of A. The trace of an execution fragment α, written trace(α), is the restriction of α to the set of external actions of A. We say that β is a trace of A if there is an execution α of A with trace(α)= β. TracesA (resp., Traces∗ ) denotes
the set of all (resp., finite) traces of A.
Nondeterministic choices in A are resolved using a scheduler, which is a function
σ : Frags∗ −→ SubDisc(D) such that (q, a, μ) ∈ supp(σ(α)) implies q = α.lstate.
Thus, σ decides (probabilistically) which transition (if any) to take after each finite execution fragment α. Since this decision is a discrete sub-probability measure, it may be the case that σ chooses to halt after α with non-zero probability: 1 − σ(α)(D) > 0. A scheduler σ and a finite execution fragment α generate a measure μσ,α on the σ-field FExecsA generated by cones of execution fragments, where each cone Cα' is the set of execution fragments that have α' as a prefix. The theory of probabilistic executions of task-PIOAs with a general class of history dependent schedulers has been developed in [5].
In this paper we restrict our attention to static (or oblivious), schedulers that do not depend on dynamic information generated during execution. Although re- strictive this class of schedulers arise naturally in many applications, including in analysis of security protocols [6]. A task schedule for A is any finite or infinite sequence σ = T1T2 ... of tasks in R. A task schedule can be used to generate a

unique probabilistic execution of the task-PIOA A. One can do this by repeatedly scheduling tasks, each of which determines at most one transition of A. Formally, we define an operation that “applies” a task schedule to a task-PIOA:

Definition 2.2 Let A be an action-deterministic task-PIOA. Given μ ∈ Disc(Frags∗ ) and a task schedule σ, apply(μ, σ) is the probability measure on FragsA defined recursively by:
apply(μ, λ) := μ. (λ denotes the empty sequence.)
For T  ∈ R, apply(μ, T ) is defined as follows.  For every α ∈ Frags∗ ,
apply(μ, T )(α) := p1 + p2, where:
p1 = μ(α')η(q) if α is of the form α' aq, where a ∈ T and (α'.lstate, a, η) ∈ D; p1 = 0 otherwise.
p2 = μ(α) if T is not enabled in α.lstate; p2 =0 otherwise.
For σ of the form σ' T , T ∈ R, apply(μ, σ) := apply(apply(μ, σ'),T ).
For σ infinite, apply(μ, σ) := limi→∞(apply(μ, σi)), where σi denotes the length-
i prefix of σ.

In Case (ii) above, p1 represents the probability that α is executed when applying task T at the end of α'. Because of transition-determinism and action-determinism, the transition (α'.lstate, a, η) is unique, and so p1 is well-defined. The term p2 repre- sents the original probability μ(α), which is relevant if T is not enabled after α. It is routine to check that the limit in Case (iv) is well-defined. The other two cases are straightforward. Given any task schedule σ, apply(ν¯, σ) is a probability distribution over ExecA. Several useful properties of the apply(, ) function relating sequences of probability distributions on executions and traces are given in Appendix A.
We note that the trace function is a measurable function from FExecsA to the σ-field generated by cones of traces. Thus, given a probability measure μ on FExecsA we define the trace distribution of μ, denoted tdist(μ), to be the image measure of μ under the trace function. We extend the tdist() notation to arbi- trary measures on execution fragments of A. We write tdist(μ, σ) as shorthand for tdist(apply(μ, σ)), the trace distribution obtained by applying task schedule σ starting from the measure μ on execution fragments. We write tdist(σ) for tdist(apply(ν¯, σ)). A trace distribution of A is any tdist(σ). We use tdists(A) to denote the set {tdist(σ): σ is a task schedule for A} of all trace distributions of A.
Composition of a pair of PIOAs is defined as follows:

Definition 2.3 Two PIOAs Ai = (Qi, ν¯i, Ii, Oi, Hi, Di), i ∈ {1, 2}, are said to be compatible if Ai ∩ Hj = Oi ∩ Oj = Ø whenever i /= j. In that case, we define their composition A1||A2 to be the PIOA (Q1 × Q2, (ν¯1, ν¯2), (I1 ∪ I2) \ (O1 ∪ O2), O1 ∪ O2, H1 ∪ H2, D), where D is the set of triples ((q1, q2), a, μ1 × μ2) such that
a is enabled in some qi, and
for every i, if a ∈ Ai then (qi, a, μi) ∈ Di, otherwise μi = δqi .

Exact implementations and Simulations
Two task-PIOAs A1 and A2 are comparable if they have the same set of external actions. Given comparable closed task-PIOAs A1 and A2, A1 is said to implement A2 if tdists(A1) ⊆ tdists(A2). If A1 and A2 implement each other then they are said to be equivalent . In [5] a simulation relation for closed, task-PIOAs is defined and it is shown to be sound for proving the above implementation relation. This definition is based on three operations involving probability measures: flattening, lifting, and expansion.
Let X and Y be a sets. If η ∈ Disc(Disc(X)), then the flattening of η, denoted by flatten(η) ∈ Disc(X), is defined by flatten(η) = μ∈Disc(X) η(μ)μ. The lifting operation takes a relation R⊆ X × Y and “lifts” it to a relation L(R)⊆ Disc(X) × Disc(Y ) defined by: μ1 L(R) μ2 iff there exists a weighting function w : X × Y → R≥0 such that: (i) for each x ∈ X and y ∈ Y , w(x, y) > 0 implies x R y, (ii) for each x ∈ X,  y w(x, y) = μ1(x), and (ii) for each y ∈ Y ,  x w(x, y) = μ2(y). Finally, the expansion operation takes a R⊆ Disc(X) × Disc(Y ), and returns a relation E (R)⊆ Disc(X) × Disc(Y ) such that μ1 E (R) μ2 whenever they can be decomposed into two L(R)-related measures. Formally, E (R), is defined by: μ1 E (R) μ2 iff there
exist two discrete measures η1 and η2 on Disc(X) and Disc(Y ), respectively, such that μ1 = flatten(η1), μ2 = flatten(η2), and η1 L(R) η2.
The next definition expresses consistency between a probability measure over finite executions and a task schedule. This condition is used to avoid useless proof obligations in the definition of both exact and approximate simulations.
Definition 2.4 Suppose A is a closed, task-PIOA and σ is a finite task schedule for T . μ ∈ Disc(Frags∗ ) is consistent with σ if supp(μ) ⊆ supp(apply(ν¯, σ)).
Suppose we have a mapping c that, given a finite task schedule σ and a task T of a task-PIOA A1, yields a task schedule of another task-PIOA A2. The idea is that c(σ, T ) describes how A2 matches task T , given that it has already matched the task schedule σ. Using c, we define a new function full(c) that, given a task schedule σ, iterates c on all the elements of σ, thus producing a “full” task schedule of A2 that matches all of σ.
Definition 2.5 Let A1, A2 be task-PIOAs, and let c : (R1∗ × R1) → R2∗ be a function that assigns a finite task schedule of A2 to each finite task schedule of A1 and task of A1. The function full(c) : R1∗ → R2∗ is recursively defined as: full(c)(λ) := λ, and full(c)(σT ) := full(c)(σ)- c(σ, T ) (the concatenation of full(c)(σ) and c(σ, T )).
Now we give the definition of exact simulation relation for task-PIOAs. Note that the simulation relations do not just relate states to states, but rather, probability measures on executions to probability measures on executions. The use of measures on executions here rather than just executions is motivated by certain cases that arise in proofs where related random choices are made at different points in the low-level and high-level models (see, e.g., proof of OT protocol in [6]).

Definition 2.6 Let A1 and A2 be two comparable closed task-PIOAs. A relation R from Disc(Execs∗(A1)) to Disc(Execs∗(A2)) is a simulation from A1 to A2 if there exists c : (R1∗ × R1) → R2∗ such that following properties hold:
Start condition: ν¯1 R ν¯2.
Step condition: If μ1 R μ2, σ ∈ R1∗, μ1 is consistent with σ, μ2 is consistent

with full(c)(σ), and T ∈ R1, then μ'
E (R) μ'
where μ'
= apply(μ1,T ) and

' = apply(μ2, c(σ, T )).
Trace condition: If μ1 R μ2, then tdist(μ1)= tdist(μ2).
We close this section with the statement of the soundness theorem for the above simulation relation which has been proved in [5].
Theorem 2.7 Let A1 and A2 be comparable closed action-deterministic task- PIOAs. If there exists a simulation relation from A1 to A2, then tdists(A1) ⊆ tdists(A2).
Uniform Approximate Implementation
In this section we define approximate implementations for task-PIOAs based on the uniform metric on trace distributions and propose Expanded Approximate Simula- tions (EAS) as a sound method for proving uniform implementations. Informally, a task-PIOA A1 uniformly approximately implements a task-PIOA A2, if every trace distribution of A1 is “close” to some trace distribution of A2, where “closeness” is defined by the uniform metric on trace distributions.
Definition 3.1 Let A be a closed task-PIOA. The uniform metric (pseudo-metric) over trace distributions of A is the function du : Disc(TracesA) × Disc(TracesA) → R≥0 defined by:

du(μ1, μ2) :=	sup
C∈FTracesA
|μ1(C) − μ2(C)| .

In general, the above definition makes du a pseudo-metric over trace distributions; some abuse of terminology we will refer to du as a metric. We define A1 to be an δ-implementation of A2 if the one-sided Hausdorff distance from tdists(A1) to tdists(A2) is at most δ.
Proposition 3.2 Suppose A1 and A2 are closed task-PIOAs. For i ∈ {1, 2}, let
{μij}j∈J be a chain of discrete probability distributions on the traces of Ai and let
limj→∞ μij = μi. Then limj→∞ du(μ1j, μ2j)= du(μ1, μ2).
Proof. We have to show that for every ϵ > 0, there exists N ∈ N, such that for all k > N , du(μ1k, μ2k) − du(μ1, μ2) < ϵ. From triangle inequality, we get that for any k, du(μ1k, μ2k) ≤ du(μ1k, μ1)+ du(μ1, μ2)+ du(μ2, μ2k). Therefore, it suffices to show that exists N ∈ N, such that for all k > N , du(μ1k, μ1)+ du(μ2, μ2k) ≤ ϵ. Now since limj→∞ μ1j = μ1, limj→∞ μ2j = μ2, we know that there exists N' ∈ N,
such that for all k > N', for every C ∈ FTraces , |μij(C) − μi(C)|≤ є . If we choose
N = N', we have for all k > N , du(μ1k, μ1)+ du(μ2, μ2k) ≤ ϵ, are required.	 

Definition 3.3 Suppose A1 and A2 are comparable, closed task-PIOAs. For δ > 0, A1 is said to δ-implement A2, written as A1 ≤δ A2, if for every μ1 ∈ tdists(A1) there exists μ2 ∈ tdists(A2) such that du(μ1, μ2) ≤ δ. Closed task-PIOAs A1 and A2 are said to be δ-equivalent , written as A1 ∼=δ A2, if A1 ≤δ A2 and A2 ≤δ A1.
Metrics over probability distributions have been a subject of intense research in probability theory (see, for example, the books [26] and [11]). Because of their applicability to probabilistic safety and termination proofs, in this paper we use the uniform metric and the discounted version of the uniform metric (see Section 4), to define approximate implementations for task-PIOAs. As we shall see in the next section, the soundness of expanded approximate simulations rely only weakly on the choice of the metric. In fact, with the appropriate changes in the definition of EAS, it is sound for proving approximate implementations with respect to any metric satisfying Proposition 3.2.

Expanded Approximate Simulations
Our definition of EAS relies on an expansion operation on real valued functions. This operation generalizes the notion of expansion of a relation used in Defini- tion 2.6.
Definition 3.4 Let x be an element of the set X and {λi}i∈I be a countable se- quence of numbers such that  λ = 1. If there exists a sequence {x } in X such that x =   λ x , then x is a convex combination of the {x }'s. A function φ : X → R≥0 ∪ {∞} is convex if for every x = i∈I λixi, φ(x) ≤ i∈I λiφ(xi). If equality holds then the function is said to be distributive.

Definition 3.5 Given a function φ : X × Y → R≥0 ∪ {∞}, the expansion of φ, written as φˆ, is a function φˆ : X × Y → R≥0 ∪ {∞} defined as:

φˆ(x1, y1) :=	min
ψ∈DPisc(X ×Y)
x1=Px ψ(x,y)x

max
(x,y)∈supp(ψ)
φ(x, y)	(1)

y1= x ψ(x,y)y


The value of
φˆ is defined in terms of a minimization problem over all joint

distributions over Disc(X × Y) that have first and second marginals with means equal to x1 and y1, respectively. The function that is minimized is the maximum value of φ over all points in the support of ψ. When stated in this form the definition of the expansion of φ is indeed reminiscent of the pth Wasserstein metric for p = ∞. Given a function φ : X × Y → R≥0 ∪ {∞}, an alternative but equivalent way of
defining the expansion φˆ, is as follows:


Definition 3.6 For any ϵ ≥ 0,
φˆ(x1, y1) ≤ ϵ if and only if there exists a joint

distribution ψ ∈ Disc(X × Y) such that:


x1














Fig. 1. Marginal distributions of the optimal joint distribution ψ for φˆ(x1, y1)= є. Support of ψ is contained within the elliptical region. In particular, ψ is concentrated in the regions Z1 and Z2 each carrying half of the total mass.


max
x,y∈supp(ψ)
x1 =	Σ
φ(x, y) ≤ ϵ	(2)
ψ(x, y)x	(3)

x,y∈supp(ψ)
y1 =
x,y∈supp(ψ)

ψ(x, y)y	(4)

The consistency requirements imposed by Equations (3) and (4) constrain the choice of ψ to those joint distributions over X × Y, for which the expected values of x and y coincide with x1 and y1. Given φ, we say that joint distribution ψ is a feasible for x1 and y1 if it satisfies the consistency requirements. If ϵ is the smallest nonnegative real for which there exists a feasible ψ that also satisfies Equation (2), that is, maxx,y∈supp(ψ) φ(x, y) ≤ ϵ, then we say that ψ is an optimal distribution for φˆ(x1, y1)= ϵ. The next proposition is a straightforward consequence of Defini- tion 3.6.
Proposition 3.7 For any φ : X × Y → R≥0 ∪ {∞} and ϵ > 0, if φ(x1, y1) ≤ ϵ for some x1 ∈ X, y1 ∈ Y, then φˆ(x1, y1) ≤ ϵ.
Proof. Suppose φ(x1, y1)= ϵ1 for some 0 < ϵ1 ≤ ϵ. The joint distribution δx1,y1 is a feasible distribution for x1 and y1. Since φ(x1, y1)= ϵ1 ≤ ϵ, φˆ(x1, y1) ≤ ϵ. 
Figure 1 shows a point (x1, y1) outside the set {(x, y) | φ(x, y) ≤ ϵ}, where φˆ(x1, y1) = ϵ. The marginal distributions for the optimal joint distribution ψ are shown on the x and the y axes.
Our new notion of approximate simulation for task-PIOAs is a function φ :

Disc(Frags∗
)×Disc(Frags∗
) → R≥0 ∪{∞} and the expansion of this function plays

a key role in the definition of simulation. Informally, the simulation function φ gives a measure of similarity between two distributions over the execution fragments of two automata. If φ(μ1, μ2) ≤ ϵ, then, first of all, it is possible to closely simulate from μ2 anything that can happen from μ1. Here closeness of simulation is measured

with the du metric on the trace distributions.  Secondly, if μ'
distributions obtained by taking a step from μ1 and μ2, then μ'
and μ'
and μ'
are the are also

close in the sense that φˆ(μ' , μ' ) ≤ ϵ.
1	2
Definition 3.8 Suppose A1 and A2 are two comparable closed task-PIOAs, ϵ is a

nonnegative constant, and φ is a function Disc(Frags∗
) × Disc(Frags∗
) → R≥0 ∪

{∞}. The function φ is an (ϵ, δ)-expanded approximate simulation from A1 to A2
if exists a function c : R∗ × R1 → R∗ such that the following properties hold:
1	2
Start condition: φ(ν¯1, ν¯2) ≤ ϵ.
Step condition: If φ(μ1, μ2) ≤ ϵ, T ∈ R1,σ ∈ R∗ and μ1 is consistent with σ,
and μ2 is consistent with full(c)(σ), then φˆ(μ' , μ' ) ≤ ϵ, where μ' = apply(μ1,T )

and μ'
= apply(μ2, c(σ, T )).
1	2	1

Trace condition: There exists δ > 0 such that if φ(μ1, μ2) ≤ ϵ then
du(tdist(μ1), tdist(μ2)) ≤ δ.
Soundness of Expanded Approximate Simulations
This section culminates in Theorem 3.11 which states that (ϵ, δ)-expanded approx- imate simulations are sound with respect to δ-approximate implementations. First we prove two key lemmas used in the proof of the theorem.
Lemma 3.9 Suppose φ is a (ϵ, δ)-expanded approximate simulation from A1 to
A2. For any μ1 ∈ Disc(Frags∗ ) and μ2 ∈ Disc(Frags∗ ), if φˆ(μ1, μ2) ≤ ϵ then
du(tdist(μ1), tdist(μ2)) ≤ δ.
Proof. Since φˆ(μ1, μ2) ≤ ϵ we know that there exists a joint distribution ψ which is feasible for μ1, μ2, and for every η1, η2 ∈ supp(ψ), φ(η1, η2) ≤ ϵ. So, for i ∈ {1, 2},
μi = Ση1,η2∈supp(ψ) ψ(η1, η2)ηi and from the trace condition it follows that
tdist(μi)=	ψ(η1, η2) tdist(ηi).
η1,η2∈supp(ψ)
We can then express du(tdist(μ1), tdist(μ2)) as follows:

sup
C∈FTraces∗
=	sup
| tdist(μ1)(C) − tdist(μ2)(C)|
| Σ ψ(η1, η2) tdist(η1)(C) − Σ ψ(η1, η2) tdist(η2)(C)|

C∈FTraces∗
η1,η2
η1,η2

≤	sup	Σ ψ(η1, η2)|(tdist(η1)(C) − tdist(η2)(C))|.
C∈FTraces∗ η1,η2
For any η1, η2 ∈ supp(ψ), φ(η1, η2) ≤ ϵ and since φ is an (ϵ, δ)-expanded approx- imate simulation, du(tdist(η1), tdist(η2)) ≤ δ. From Definition 3.1, it follows that
| tdist(η1)(C) − tdist(η2)(C)| ≤ δ.  Therefore, we have du(tdist(μ1), tdist(μ2)) ≤
Ση1,η2 ψ(η1, η2)δ ≤ δ.	 
Lemma 3.10 Suppose φ : Disc(X1) × Disc(X2) → R≥0 ∪ {∞} is a function,
μi ∈ Disc(Xi) for i ∈ {1, 2}, φˆ(μ1, μ2) ≤ ϵ with optimal distribution ψ.	Let

fi : Disc(Xi) → Disc(Xi) be distributive functions, for i ∈ {1, 2}. If for each
ρ1, ρ2 ∈ supp(ψ), φˆ(f1(ρ1), f2(ρ2)) ≤ ϵ, then φˆ(f1(μ1), f2(μ2)) ≤ ϵ.
Proof. For each ρ1, ρ2 ∈ supp(ψ), let ψρ1ρ2 be the optimal distribution for
φˆ(f1(ρ1), f2(ρ2)) = ϵ. We define a joint distribution ψ' on Disc(X1) × Disc(X2) as
follows:

ψ' :=
(ρ1,ρ2)∈supp(ψ)
ψ(ρ1, ρ2)ψρ1,ρ2
(5)

and show that ψ' is a feasible distribution for f1(μ1) and f2(μ2) and for any η1, η2 ∈
supp(ψ'), φ(η1, η2) ≤ ϵ.
For feasibility of ψ' we have to show that for i ∈ {1, 2}, fi(μi) equals:
ψ'(η1, η2)ηi
η1∈Disc(X1),η2∈Disc(X2)

=	Σ	⎡	Σ
ψ(ρ1, ρ2)ψρ ,ρ (η1, η2)⎤ ηi

η1∈Disc(X1),η2∈Disc(X2) ⎣(ρ1,ρ2)∈supp(ψ)	⎦
=	Σ	ψ(ρ1, ρ2) ⎡	Σ	ψρ ,ρ (η1, η2)ηi⎤


(ρ1,ρ2)∈supp(ψ)
=
(ρ1,ρ2)∈supp(ψ)
⎣η1∈Disc(X1),η2∈Disc(X2)	⎦
ψ(ρ1, ρ2)fi(ρi)	[from feasibility of ψρ1,ρ2 ]

= fi ,	Σ	ψ(ρ1, ρ2)ρi⎞	[from distributivity of fi]
⎝(ρ1,ρ2)∈supp(ψ)	⎠
= fi(μi)	[from feasibility of ψ].

For optimality of ψ' it suffices to show that for all η1, η2 ∈ supp(ψ'), φ(η1, η2) ≤ ϵ. If ψ'(η1, η2) > 0 then from Equation (5) it follows that there exists ρ1, ρ2 ∈ supp(ψ) such that ψρ1,ρ2 (η1, η2) > 0. Since ψρ1,ρ2 is a optimal distribution
for φˆ(f1(ρ1), f2(ρ2)) = ϵ, from its optimality we know that for any ν1, ν2 ∈
supp(ψρ1,ρ2 ), φ(ν1, ν2) ≤ ϵ. In particular, η1, η2 ∈ supp(ψρ1,ρ2 ) and so we have
φ(η1, η2) ≤ ϵ.
 
Theorem 3.11 Let A1 and A2 be two closed comparable task-PIOAs. If there exists a (ϵ, δ)-expanded approximate simulation function from A1 to A2 then A1 ≤δ A2.
Proof. Let φ be the assumed (ϵ, δ)-expanded approximate simulation function from
A1 to A2. Let μ1 be the probabilistic execution of A1 generated by the starting
distribution ν¯1 and a (finite or infinite) task schedule T1, T2,.. .. For each i >
0, we define σi to be c(T1 ... Ti−1, Ti). Let μ2 be the probabilistic execution of
A2 generated by ν¯2 and the concatenation σ1, σ2,.. .. It suffices to show that:
du(tdist(μ1), tdist(μ2)) ≤ δ.

For each j ≥ 0, let us define μ1,j := apply(ν¯1, T1,..., Tj) and μ2,j := apply(ν¯2, σ1,..., σj). For i ∈ {1, 2} and for each j ≥ 0, μi,j ≤ μi,j+1 and limj→∞ μi,j = μi. (the above uses Lemma A.7 of Appendix A). Observe that for every j ≥ 0, μ1,j+1 = apply(μ1,j, Tj+1) and also that μ2,j+1 = apply(μ2,j, σj+1).
Step 1a. We prove by induction that for all j ≥ 0, φˆ(μ1,j, μ2,j) ≤ ϵ. For j =
0, μ1,0 = ν¯1 and μ2,0 = ν¯2. By the start condition of the simulation function,
φ(μ1,0, μ2,0) ≤ ϵ and therefore by Proposition 3.7 φˆ(μ1,0, μ2,0) ≤ ϵ.
Step 1b. For the inductive step, we assume that φˆ(μ1,j, μ1,j) ≤ ϵ and show that
φˆ(μ1,j+1, μ1,j+1) ≤ ϵ. First of all, note that μ1,j+1 = apply(μ1,j, Tj+1) and μ2,j+1 =
apply(μ2,j, c(σjTj+1)). For i ∈ {1, 2}, let us define fi : Disc(Frags∗ ) → Disc(Frags∗ )
as f1(η) := apply(η, Tj+1) and f2(η) := apply(η, c(σjTj+1)). If we can apply Lemma 3.10, to the functions f1 and f2 then it follows that φˆ(f1(μ1,j), f2(μ2,j)) ≤ ϵ as required.
Step 1c. It remains to check that these two functions satisfy all the conditions in the hypothesis of Lemma 3.10. Distributivity of f1 and f2 follow from Propo- sition B.2 (see Appendix B). Suppose φˆ(μ1,j, μ1,j) ≤ ϵ with optimal distribution
ψ, and suppose η1, η2 ∈ supp(ψ), we have to show that φˆ(f1(η1), f2(η2)) ≤ ϵ.
Since η1, η2 ∈ supp(ψ), from optimality of ψ, we know that φ(η1, η2) ≤ ϵ. Ob- serve that for i ∈ {1, 2}, supp(ηi) ⊆ supp(μi,j), and thus η1 is consistent with Tj+1 and η2 is consistent with c(σjTj+1). Therefore, by the step condition on φ, φˆ(apply(η1, Tj+1), apply(η2, c(σjTj+1))) ≤ ϵ. Since f1(η1) = apply(η1, Tj+1) and f2(η2) = apply(η2, c(σjTj+1)), we have φˆ(f1(μ1,j), f2(μ2,j)) ≤ ϵ, as required in the hypothesis of Lemma 3.10.
Step 2. From Lemma 3.9, for each j ≥ 0, du(tdist μ1,j, tdist μ2,j) ≤ δ. From Lemma A.5 of Appendix A we know that for i ∈ {1, 2}, limj→∞ tdist(μi,j) = tdist(μi). From Proposition 3.2 we conclude that du(tdist(μ1), tdist(μ2)) =
limj→∞ du(tdist(μ1,j), tdist(μ2,j)) ≤ δ.	 

Need for Expansion
In the step condition in the definition of EAS (Definition 3.8) it is required that
if φ(μ1, μ2) ≤ ϵ then φˆ(μ' , μ' ) ≤ ϵ. Indeed, if we replace this condition with the
1	2
weaker condition—if φ(μ1, μ2) ≤ ϵ then φ(μ' , μ' ) ≤ ϵ—the resulting approximate
1	2
simulation functions that we would obtain would be sound for proving approximate implementations. However, such non-expanded approximate simulation functions are be considerably less powerful than EASs. The key motivation for generalizing simulation relations to their current expanded form, first came from the verification of the Oblivious transfer protocol in [6]. In this section, we present a version of this example adapted to our setting of approximate implementations.
Example 1(Trapdoor and Rand) Consider an abstract automaton Rand that ran- domly chooses a number z between 0 and n and outputs it. We assume that n is odd. Trapdoor , on the other hand, first chooses a random number y with slightly different probabilities. The first n−1 numbers are chosen with probability  1  − ϵ
2	n+1
and the remaining are chosen with probability  1  + ϵ) Trapdoor then applies a



Fig. 2. Left: Rand and Trapdoor automata. Right: Witnessing joing distribution.

known permutation (e.g., z = (y+1) mod n) to the chosen number, and outputs the result. The Rand and the Trapdoor for n = 3 automata are shown in Figure 2. Suppose the out actions producing the final value of z are external actions. Then, we would like these actions (tasks) to correspond which means that the choose step of Trapdoor should map to no step of Rand . We present an approximate simula- tion function that “ought to work” for this example. Instead of using a simulation function on distributions of finite execution fragments, we use a simpler φ that is a function on distribution of states.
⎧ max	[μ (s)+ μ (u)] ∀ s ∈ supp(μ ),u ∈ supp(μ ), s.z /= u.z
φ(μ1, μ2) :=  0	∀ s ∈ supp(μ1),u ∈ supp(μ2), s.z = s.y = ⊥
 1 
n+1
Informally, states corresponding to different values to z produce completely dif- ferent outputs, and thus they should be relatively unrelated. The first condition in the definition of φ assigns a large value (maxs,uμ1(s)+ μ2(u)) to distributions that contain such mismatched states. The second condition is satisfied only for the Dirac masses δr0 and δt0 , and therefore φ is 0. Finally, the third condition is satisfied for distributions supported on states that have the same value of z, and where the variable y has been assigned a value in the Trapdoor automaton.
Let μ11 = apply(δt0 , choose) and μ21 = apply(δr0 , λ) = δr0 . Then, for all s ∈ supp(μ11), s.z = r0.z = ⊥, and hence by the third condition in the definition of φ, φ(μ11, μ21) = ϵ. Next, let μ12 = apply(μ11, comp) and μ21 = apply(μ22, comp). Then, there exists s ∈ supp(μ21) and u ∈ supp(μ22), such that s.z /= u.z, and by the first condition, φ(μ12, μ22) ≥  2  , which is much larger than ϵ. Therefore, we cannot use φ as an approximate simulation function to prove that Trapdoor is a good approximate implementation for Rand .
We show that φ can be used as an approximate simulation function if we use φ
as an EAS. It suffices to prove that φˆ(μ12, μ22) ≤ 2ϵ, and we will use the witnessing
joint distribution shown in the table of Figure 2. Indeed, the marginal distributions of ψ match with μ21 and μ22. Further, for any η, ν in the support of ψ, η and ν have the following properties: (1) either they are Dirac masses at states that have the same value of z, in which case φ(η, ν)= ϵ from the third condition in the definition

of φ, otherwise (2) for any s ∈ X1 and u ∈ X2, η(s) ≤ ϵ and ν(u) ≤ ϵ, and therefore by the first condition φ(η, ν) ≤ 2ϵ. From the above it follows that φˆ(μ12, μ21) ≤ 2ϵ, which is what we set out to prove.
Probabilistic Safety
Suppose A1 and A2 are comparable closed task-PIOAs such that A2 ≤δ A1. Suppose further that A1 violates some safety property S with probability at most p then we can conclude that A2 violates S with probability at most p + δ. We first prove the following more general result. Let (Traces, FTraces) be the measurable space of traces containing the traces of both A1 and A2. Let (X, FX ) be another measurable space. A random variable is a measurable function X : (Traces, FTraces) → (X, FX ). We use the standard notation μ[X = x] := μ({β ∈ Traces | X(β)= x}, for x ∈ X.
Proposition 3.12 Let X be random variable on (Traces, FTraces). Suppose A2 ≤δ A1 and there exists 0 ≤ p ≤ 1 such that for all μ1 ∈ tdists(A1), μ1([X = x]) ≤ p. Then, for all μ2 ∈ tdist(A2), μ2[X = x] ≤ δ + p.
Proof. Fix μ2 ∈ tdists A2. Since A2 ≤δ A1 from Definition 3.3 there exists μ1 ∈ tdists(A1), such that du(μ1, μ2) ≤ δ. We know that supC |μ2(C) − μ1(C)| ≤ δ. In particular, |μ2([X = x]) − μ1([X = x])| ≤ δ. As μ1([X = x]) ≤ p, we have μ2([X = x]) ≤ p + δ as required.	 
We denote the common set of external actions of A1 and A2 by E. Let us assume that violation of some safety property S is indicated by the occurrence of one of the external actions from the set U ⊆ E. We define the function XU : Traces → {0, 1} as XU (β) := 1 if some action from U occurs in the trace β, otherwise XU (β) := 0. It can be easily checked that XU is a measurable function and therefore is a boolean valued random variable. Then, the event [XU = 1] corresponds to the set of traces in which S is violated. Now, if we know that in any trace distribution of A1 the probability of any U occurring is at most p and that A2 ≤δ A1, then from Proposition 3.12 we can conclude that in any trace distribution of A2 the probability of occurrence of U is at most δ + p.
Discounted Uniform Metric
In the preceding section we defined uniform approximate implementation for PIOAs and proved that EASs are sound for proving this implementation relationship. We also demonstrated that uniform approximate implementations are suitable for rea- soning about certain classes of properties, like safety properties, where it is sufficient to quantify the absolute discrepancy in the trace distributions over all sets of traces. For certain other classes of properties the uniform metric is not suitable, because the worst case discrepancy over all sets of traces does not convey useful information. We illustrate this with the following example.
Example 2. (Randomized Consensus) The Ben-Or consensus protocol [3] is a randomized algorithm for n fault-prone processors to agree on a valid value by com-

municating over an asynchronous network. The algorithm proceeds in a sequence of stages in each of which nonfaulty processes send and receive messages based on coin-flips and comparison of values. If the processes have access to perfectly random coins, then with probability  1 , a stage ends successfully and all nonfaulty processes agree on a value, and after one communication round of a successful stage the con- sensus value is disseminated. An unsuccessful stage is followed by the beginning of the next stage.
The automaton in Figure 3 captures the termination behavior of the algorithm. The protocol starts is state s10, the starting state for each of the successive stages are the states s20, s30,.. .. The successful completion of the ith stage is represented by state si1. The action a models the computation and communication within a stage. From stage si0, with probability p it leads to s(i+1)0, the next stage, and with probability 1 − p it leads to si1. The action d marks the termination of the protocol and it takes si1 to si2 with probability 1.
a	a	a

a


d



Fig. 3. Automata representing Ben-Or consensus protocol.
Suppose PIOA A1 is an instance of the automaton in Figure 3 with perfect
random coins, that is, p = 1 −  1 and 1 − p =  1 .  And let A2 be a PTIOA
instance of the same automaton with slightly biased coins. We model the transition probabilities for A2 by p + ϵ and 1 − p − ϵ, for a small positive ϵ. We would like to compare the probabilities of termination of A1 and A2 after a certain number of rounds, say k. With the uniform approximate implementation, we can show that the difference in the probabilities is less than δ, for a fixed δ > 0, however if individual probabilities of termination are themselves less than δ then this δ-approximation is too coarse and does not give us any useful information. In the remainder of this section, we show how a discounted version of the uniform metric can be used to make more fine grained comparison of probabilities of traces.
Discounted Approximate Simulations
Definition 4.1 A probability distribution μ on execution fragments of A is said to

be ﬁnite if Frags∗
is a support for μ.
is a support for μ. A trace distribution μ of A is finite if Traces∗

Since any set of finite execution fragments is measurable, any finite probability distribution on execution fragments of A can also be viewed as a discrete probability measure on Frags∗ . Likewise, a finite trace distribution can be viewed as a discrete distribution over Traces∗ . In this section, we consider task-PIOAs with finite (trace)

distributions and will treat these distributions as discrete distributions on execution fragments or traces.
Definition 4.2 For any k  ∈ N, the kth uniform metric is a function dk  :
Disc(TracesA) × Disc(TracesA) → R≥0 defined as:

dk(μ1, μ2) :=	max
β∈E∗,|β|=n
|μ1(β) − μ2(β)|.

Definition 4.3 Suppose A1 and A2 are comparable, closed task-PIOAs and
{δk}k∈N is a collection of positive real numbers, called discount factors. If for every trace distribution μ1 in tdist(A1) there exists a trace distribution μ2 ∈ tdist(A2) such that for every k ∈ N, dk(μ1, μ2) ≤ δk, then we say that A1 δk-implements A2 and write this as A1 ≤δk A2. A1 and A2 are said to be δk-equivalent , written as A1 ∼=δk A2, if A1 ≤δk A2 and A2 ≤δk A1.
Proposition 4.4 For all k ∈ N, dk is a pseudometric.
Proof. The symmetry property is easy to check. We prove that dk satisfies the triangle inequality. Let μ1, μ2, μ3 be distributions on E∗. dk(μ1, μ3) = maxβ∈E∗,|β|=k |μ1(β) − μ3(β)|. Suppose β3 is a trace that realizes the supremum.
|μ1(β3) − μ3(β3)|≤ |μ1(β3) − μ2(β3)| + |μ2(β3) − μ3(β3)|

dk(μ1, μ3) ≤ max
β,|β|=k
|μ1(β) − μ2(β)| + max
β,|β|=k
|μ2(β) − μ3(β)|,

≤ dk(μ1, μ2)+ dk(μ2, μ3).


We define a new kind of approximate simulation called Discounted Approximate Simulation (DAS) for proving discounted approximate implementations for task- PIOAs. Given a distribution μ over executions (or traces) we denote the longest execution (respectively trace) in the support of μ by L(μ). We extend this notation to a pair of distributions by defining L(μ1, μ2)= max(L(μ1), L(μ2)).
Definition 4.5 Suppose A1 and A2 are two comparable closed task-PIOAs, and
{φk}k∈N is a collection of functions, where each φk : Disc(Frags∗ )×Disc(Frags∗ ) →
R≥0 ∪ {∞}. Given a collection of real number pairs {ϵk, δk}k∈N, the collection {φk}
is an (ϵk, δk)-discounted approximate simulation from A1 to A2 if there exists a function c : R∗ × R1 → R∗ such that the following properties hold:
1	2
Start condition: φ0(ν¯1, ν¯2) ≤ ϵ0.
Step condition: If for all k ≤ L(μ1, μ2), φk(μ1, μ2) ≤ ϵk, T ∈ R1,σ ∈ R∗, μ1 is consistent with σ, and μ2 is consistent with full(c)(σ), then for all k ≤ L(μ' , μ' ),

φk(μ' , μ' ) ≤ ϵk, where μ' = apply(μ1,T ) and μ'
1	2
= apply(μ2, c(σ, T )).

1	2	1	2
Trace condition: If for all k ≤ L(μ1, μ2), φk(μ1, μ2) ≤ ϵk then for all k ≤
L(tdist(μ1), tdist(μ2)) dk(tdist(μ1), tdist(μ2)) ≤ δk.
We prove Theorem 4.6 which states that (ϵk, δk)- approximate simulations are sound with respect to δk-approximate implementations.

Theorem 4.6 Let A1 and A2 be two closed isomorphic comparable task-PIOAs. If there exists a (ϵk, δk)-discounted approximate simulation function from A1 to A2 then A1 ≤δk A2.
Proof. Let φ be the assumed (ϵk, δk)-discounted approximate simulation function from A1 to A2. Let μ1 be the probabilistic execution of A1 generated by the starting distribution ν¯1 and a finite task schedule T1, T2,..., Tn. For each i > 0, we define σi to be c(T1 ... Ti−1, Ti). Let μ2 be the probabilistic execution of A2 generated by ν¯2 and the concatenation σ1, σ2,..., σn. It suffices to show that dw(tdist(μ1), tdist(μ2)) ≤ δ. For each j ≥ 0, let us define μ1,j := apply(ν¯1, T1,..., Tj) and μ2,j := apply(ν¯2, σ1,..., σj).	For i ∈ {1, 2} and for each j ≥ 0, μi,j ≤ μi,j+1 and μi,n = μi. Observe that for every j ≥ 0, μ1,j+1 = apply(μ1,j, Tj+1) and μ2,j+1 =
apply(μ2,j, σj+1).
We prove by induction that for all j ≥ 0, for all k ≤ L(μ1,j, μ2,j), φk(μ1,j, μ2,j) ≤ ϵk. For j = 0, μ1,0 = ν¯1 and μ2,0 = ν¯2. By the start condition of the simulation function, φ0(μ1,0, μ2,0) ≤ ϵ. For the inductive step, we assume that for all k ≤ L(μ1,j, μ2,j), φk(μ1,j, μ2,j) ≤ ϵk. Then, from Part (ii) of Definition 3.8 it follows that for all k ≤ L(μ1,j+1, μ2,j+1), φk(μ1,j+1, μ2,j+1) ≤ ϵk. In particular, for all k ≤ L(μ1, μ2), φk(μ1, μ2) ≤ ϵk, from which, using condition (iii) it follows that for all k ≤ L(tdist(μ1), tdist(μ2)), dk(tdist(μ1), tdist(μ2)) ≤ δk.	 
Example 2.(Continued) Let ϵk = δk = (p + ϵ)k − pk, for each k ∈ N. We will show that A1 and A2 are δk-equivalent using the following discounted approximate simulation:
for each k,  φk(μ1, μ2)= maxα,anum(α)=k|μ1(α) − μ2(α)|,	(6)

where μ1 ∈ Disc(Execs∗
), μ2 ∈ Disc(Execs∗
), and anum(α) is the number of

occurrence of the action a in the execution α.
Proposition 4.7 The collection of functions {φk} deﬁned above is an (ϵk, δk)- discounted approximate simulation from A1 to A2.
Proof. [Sketch] We check that the collection {φk} satisfies the three conditions in Definition 4.5.
Start condition: ν1 = ν2 = δs10 , and therefore φ0(ν1, ν2)= 0.
Step condition: We define the task correspondence function in the obvious way, c(σ, T ) := T , where σ is a task schedule and T is a task for A1. Thus

for any μ1 ∈ Disc(Execs∗
) and μ2Disc(Execs∗
) that are obtained from ν1

and ν2 by applying a sequence of tasks, L(μ1, μ2) = L(μ1) = L(μ2). Consider

any μ1 ∈ Disc(Execs∗
),μ2 ∈ Disc(Execs∗
), and suppose μ1 = apply(ν1, σ)

and μ2 = apply(ν2, full(c)(σ)). Let us denote μ' = apply(μ1,T ), and μ' =
apply(μ2, c(σ, T )) = apply(μ2,T ). Then, it suffices to show that for all k ≤
L(μ1, μ2), φk(μ' , μ' ) ≤ (p + ϵ)k −ϵk. This part of the proof is by a case analysis
1	2
on the types of tasks, T = {a}, {d} and the types of executions.
The interesting cases are for T = {a} and executions of the form α = α'ask0
or α = α'as(k−1)1, for some k ≤ L(μ1). For the first case, μ' (α) = μ1(α')p

and μ' (α) = μ2(α')(p + ϵ), and therefore φk+1(μ' , μ' ) = p|μ2(α') − μ1(α')| +
2	1	2
ϵμ2(α'). From the inductive hypothesis, |μ2(α') − μ1(α')|≤ ϵk. It follows that,
φk+1(μ' , μ' ) ≤ p|(p + ϵ)k − pk| + ϵ(p + ϵ)k ≤ ϵk+1. Likewise in the second case,
1	2
μ' (α)= μ1(α')(1 − p) and μ' (α)= μ2(α')(1 − p − ϵ), and performing a similar
1	2
calculation as above, we can show that φk+1(μ' , μ' ) ≤ ϵk.
1	2
Trace condition:  First of all, for any μ1 ∈ Disc(Execs∗ ) that are ob-
tained from ν1 by applying a sequence of tasks, L(μ1) = L(tdist(μ1)). If β is a trace of the form akd, for some k ≥ 0. Then, for i ∈ {1, 2}, tdist(μi)(β)= μi(α), where α = s10as20 ... sk0ask1dsk2. From which it follows that | tdist(μ1)(β) − tdist(μ2)(β)| = |μ1(α) − μ2(α)|≤ φk+1(μ1, μ2) ≤ ϵk+1. On the other hand, if β is a trace of the form ak+1, for some k ≥ 0. Then, for i ∈
{1, 2}, tdist(μi)(β)= μi(α1)+μi(α2), where α1 = s10as20 ... s(k+1)0as(k+1)1 and where α2 = s10as20 ... s(k+2)0. Thus, | tdist(μ1)(β) − tdist(μ2)(β)| = |μ1(α1)+ μ1(α2) − μ1(α1) − μ2(α1)| = |μ1(α) − μ1(α)|, where α = s10as20 ... s(k+1)0. Therefore, | tdist(μ1)(β) − tdist(μ2)(β)|≤ φk+1(μ1, μ2) ≤ ϵk+1 as required.

Approximations for Task-PIOAs
In this section, we discuss how the notion of uniform approximate implementations and the soundness of EASs extendeds to general (not necessarily closed) task-PIOAs. In an analogous manner, discounted approximate implementation and DAS can also be extended.
The basic idea is to define a new notion of implementation following the approach of [5]. We formulate the external behavior of a A as a mapping from possible “en- vironments” for A to sets of trace distributions that can arise when A is composed with the given environment.
Definition 5.1 An environment for task-PIOA A is a task-PIOA E such that the
composition of A and E is closed.
Definition 5.2 The external behavior of a task-PIOA A, written as extbehA, is a function that maps each environment task-PIOA E for A to the set of trace distributions of the composition of A and E .
Approximate implementation for general task-PIOAs can then be defined to be inclusion of external behavior for all environments.
Definition 5.3 If A1 and A2 are comparable then A1 is said to δ-implement A2, for some δ ≥ 0, if for every environment task-PIOA E for both A1 and A2, for every μ1 ∈ extbehA1 (E ) there exists μ2 ∈ extbehA2 (E ) such that du(μ1, μ) ≤ δ.
Based on this modified definition of approximate implementation the soundness of expanded approximate simulations for general task-PIOAs follow as a Corollary to Theorem 3.11.

Corollary 5.4 Let A1 and A2 be two comparable task-PIOAs. Suppose that for every environment E for both A1 and A2, there exists a (ϵE , δ)-approximate simu- lation function from the composition of A1 and E to the composition of A2 and E. Then A1 ≤δ A2.
Conclusions
In this paper we have introduced approximate implementations for probabilistic I/O automata. We have employed the task mechanism of [6] to obtain the trace distributions of a PIOA, and then we have defined two different kinds of approx- imate implementations, based on the uniform metric and the discounted uniform metric on trace distributions. We proposed expanded approximate simulations and discounted approximate simulations for proving, the two proposed implementation relations, respectively. EAS and DAS can be used to approximately reason about probabilistic safety and termination properties. PIOAs can be nondeterministic and our construction does not require the underlying state spaces of the automata or the space of external actions to be metric spaces.
In our formulation of expanded approximate simulations, a simulation proof re- duces to finding an optimal joint distribution satisfying certain constrains on the marginals. This is closely related to the well known Kantorovich optimal trans- portation problem. For well-behaved classes of simulation functions, therefore, we would like to explore the possibility of proving approximate simulations by solving optimization problems.
In the future, we want develop a new kind of Discounted Expanded Approximate Simulations that combines the features of EAS and DAS. We would also like to develop simulation based proof techniques where the simulation functions are func- tions of distributions over states and not functions of distributions over execution fragments. Finally, we would like to extend the notion approximate implementa- tions to the Probabilistic Timed I/O Automaton framework [24].
Acknowledgement
We thank Professor Sanjoy Mitter for many useful comments on this work.

References
R. Alur and D. L. Dill. A theory of timed automata. Theoretical Computer Science, 126:183–235, 1994.
C. Baier. Polynomial-time algorithms for testing probabilistic bisimulation and simulation. In R. Alur and T. A. Henzinger, editors, Proceedings of the Eighth International Conference on Computer Aided Verification CAV, volume 1102 of LNCS, pages 50–61, New Brunswick, NJ, USA, 1996.
M. Ben-Or. Another advantage of free choice: Completely asynchronous agreement protocols. In
PODC, pages 27–30, Montreal, Canada, August 1983.
M. L. Bujorianu, J. Lygeros, and M. C. Bujorianu. Bisimulation for general stochastic hybrid systems. In Morari and Thiele [25], pages 198–214.
R. Canetti, L. Cheung, D. Kaynar, M. Liskov, N. Lynch, O. Pereira, and R. Segala. Task-structured probabilistic I/O automata. Technical Report MIT-CSAIL-TR-2006-060, Massachusetts Institute of Technology, Cambridge, MA, September 2006.


R. Canetti, L. Cheung, D. Kaynar, M. Liskov, N. Lynch, O. Pereira, and R. Segala. Using task- structured probabilistic I/O automata to analyze an oblivious transfer protocol. Technical Report MIT- CSAIL-TR-2006-019, Massachusetts Institute of Technology, Cambridge, MA, March 2006. Available from http://theory.csail.mit.edu/tds/papers/Kirli/TR-2006-019.pdf.
L. Cheung. Reconciling nondeterministic and probabilistic choices. PhD thesis, ICIS, Radboud University Nijmegen, The Netherlands, 2006.
J. Desharnais, V. Gupta, R. Jagadeesan, and P. Panangaden. Approximating labelled markov processes.
Inf. Comput., 184(1):160–200, 2003.
J. Desharnais, V. Gupta, R. Jagadeesan, and P. Panangaden. Metrics for labelled markov processes.
Theor. Comput. Sci., 318(3):323–354, 2004.
J. Desharnais, R. Jagadeesan, V. Gupta, and P. Panangaden. The metric analogue of weak bisimulation for probabilistic processes. In Proceedings of the 17th Annual IEEE Symposium on Logic in Computer Science (LICS), Copenhagen, Denmark, 22-25 July 2002, pages 413–422. IEEE Computer Society, 2002.
R. M. Dudley. Probabilities and Metrics:Convergence of laws on metric spaces, with a view to statistical testing. Number 45 in Lecture Notes Series. Aarhus Universitet, June 1976.
A. Girard, A. A. Julius, and G. J. Pappas. Approximate simulation relations for hybrid systems. In
IFAC Analysis and Design of Hybrid Systems, Alghero, Italy, June 2006.
A. Girard and G. J. Pappas. Approximation metrics for discrete and continuous systems. In IEEE Transactions on Automatic Control, 2005.
D. K. Goldenberg, J. Lin, and A. S. Morse. Towards mobility as a network control primitive. In MobiHoc ’04: Proceedings of the 5th ACM international symposium on Mobile ad hoc networking and computing, pages 163–174. ACM Press, 2004.
V. Gupta, R. Jagadeesan, and P. Panangaden. Approximate reasoning for real-time probabilistic processes. The Quantitative Evaluation of Systems, First International Conference on (QEST’04), 00:304–313, 2004.
C.-C. Jou and S. A. Smolka. Equivalences, congruences and complete approximations for probabilistic processes. In CONCUR 90, number 458 in LNCS. Springer-Verlag, 1990.
D. K. Kaynar, N. Lynch, R. Segala, and F. Vaandrager. The Theory of Timed I/O Automata. Synthesis Lectures on Computer Science. Morgan Claypool, November 2005. Also available as Technical Report MIT-LCS-TR-917.
M. Z. Kwiatkowska and G. Norman. Probabilistic metric semantics for a simple language with recursion. In MFCS ’96: Proceedings of the 21st International Symposium on Mathematical Foundations of Computer Science, pages 419–430, London, UK, 1996. Springer-Verlag.
K. G. Larsen and A. Skou. Bisimulation through probabilistic testing. Inf. Comput., 94(1):1–28, 1991.
P. Lincoln, J. Mitchell, M. Mitchell, and A. Scedrov. A probabilistic poly-time framework for protocol analysis. In CCS ’98: Proceedings of the 5th ACM conference on Computer and communications security, pages 112–121, New York, NY, USA, 1998. ACM Press.
M. W. Mislove, J. Ouaknine, D. Pavlovic, and J. Worrell. Duality for labelled markov processes. In
Proceedings of FOSSACS 04, volume 2987 of LNCS. Springer, 2004.
M. W. Mislove, J. Ouaknine, and J. Worrell. Axioms for probability and nondeterminism. ENTCS, 2004.
S. Mitra and N. Lynch. Approximate simulations for task-structured probabilistic I/O automata. In
LICS workshop on Probabilistic Automata and Logics (PAul06), Seattle, WA, August 2006.
S. Mitra and N. Lynch. Probabilistic timed I/O automata, October 2006. Submitted for review.
M. Morari and L. Thiele, editors. Hybrid Systems: Computation and Control, 8th International Workshop, HSCC 2005, Zurich, Switzerland, March 9-11, 2005, Proceedings, volume 3414 of Lecture Notes in Computer Science. Springer, 2005.
S. T. Rachev. Probability metrics and the stability of stochastic models. John Wiley & Sons, 1991.
R. Segala. Modeling and Verification of Randomized Distributed Real-Time Systems. PhD thesis, Laboratory for Computer Science, Massachusetts Institute of Technology, June 1995.
S. Strubbe and A. J. van der Schaft. Bisimulation for communicating piecewise deterministic markov processes (cpdps). In Morari and Thiele [25], pages 623–639.

P. Tabuada, G. J. Pappas, and P. U. Lima. Composing abstractions of hybrid systems. In Tomlin and Greenstreet [31], pages 436–450.
A. Tiwari and G. Khanna. Series of abstractions for hybrid automata. In Tomlin and Greenstreet [31], pages 465–478.
C. Tomlin and M. R. Greenstreet, editors. Hybrid Systems: Computation and Control, 5th International Workshop, HSCC 2002, Stanford, CA, USA, March 25-27, 2002, Proceedings, volume 2289 of Lecture Notes in Computer Science. Springer, 2002.
F. van Breugel, M. Mislove, J. Ouaknine, and J. B. Worrell. An intrinsic characterization of approximate probabilistic bisimilarity. In Proceedings of FOSSACS 03, LNCS. Springer, 2003.
F. van Breugel, M. W. Mislove, J. Ouaknine, and J. Worrell. Domain theory, testing and simulation for labelled markov processes. Theoretical Computer Science, 2005.
F. van Breugel and J. Worrell. An algorithm for quantitative verification of probabilistic transition systems. In CONCUR ’01: Proceedings of the 12th International Conference on Concurrency Theory, pages 336–350, London, UK, 2001. Springer-Verlag.
F. van Breugel and J. Worrell. Towards quantitative verification of probabilistic transition systems. In ICALP ’01: Proceedings of the 28th International Colloquium on Automata, Languages and Programming,, pages 421–432, London, UK, 2001. Springer-Verlag.

Appendix: Limits of Chains of Distributions
All the definitions and lemmas in this Appendix are from [5]. In this Appendix A will be a task-PIOA. Given a finite execution fragment α of A, the cone of executions generated by this fragment Cα is the set of all execution fragments that extend α. Given a finite trace β of A, Cα is the set of all traces that extend β.
Definition A.1 If μ1, μ2 ∈ Disc(FragsA), such that for every α ∈ Frags∗ , μ1(Cα) ≤
μ2(Cα), then we write μ1 ≤ μ2.
Definition A.2 A chain of probability measures on execution fragments of A is an infinite sequence μ1, μ2,... of probability measures on execution fragments of A such that μ1 ≤ μ2 .. .. Given a chain, the limit of the chain is defined as a function μ on the σ-algebra generated by the cones of execution fragments of A, as follows: for each α ∈ Frags∗ , μ(Cα) := limi→∞ μi(Cα).
Standard measure theoretic arguments guarantee that μ can be extended uniquely to a probability measure on the σ-field generated by the cones of finite execution fragments.
Definition A.3 If μ1, μ2 are probability measures on traces of A, such that for every finite trace β of A μ1(Cβ) ≤ μ2(Cβ), then we write μ1 ≤ μ2.
Definition A.4 A chain of probability measures on traces of A is an infinite se- quence μ1, μ2,... of probability measures on traces of A such that μ1 ≤ μ2 .. .. Given a chain of probability measure on traces, the limit of the chain is defined as a function μ on the σ-algebra generated by the cones of traces of A, as follows: for each finite trace β of A, μ(Cβ) := limi→∞ μi(Cβ).
Again, μ can be extended uniquely to a probability measure on the σ-field gen- erated by the cones of finite traces.
Lemma A.5 (4 of [5]) Let μ1, μ2,... be a chain of measures on FragsA and let
μ = limi→∞ μi, then limi→∞ tdist(μi)= tdist(μ).

Lemma A.6 (11 of [5]) Let μ ∈ Disc(Frags∗ ) and σ be a ﬁnite task schedule for
A. Then apply(μ, σ) ∈ Disc(Frags∗ ).
Lemma A.7 (20 of [5]) Let μ ∈ Disc(Frags∗ ) and σ1, σ2,... be a ﬁnite or inﬁnite sequence of task schedulers for A. For each i > 0 let ηi = apply(μ, σ1σ2 ... σi). Let σ = σ1σ2 ... be the concatenation of the all the task schedulers, and let η = apply(μ, σ). Then the ηi’s form a chain and η = limi→∞ ηi.
Appendix: Lemmas for Approximate Simulations
This Appendix provides proofs of several propositions stated in the paper and also some auxiliary lemmas used for proving the soundness theorem.
The following is a proof of Proposition 3.2.
Lemma B.1 Let {μi}i∈I be a countable family of discrete probability measures

μi ∈ Disc(Frags∗ ) and let μ = Σ

i∈I
λiμi be a convex combination of {μi}, where

Σi∈I λi = 1. Let T be task of A. Then apply(μ, T )= Σi∈I λi apply(μi,T ).
Proof. Suppose p1 and p2 are the functions used in the definition of apply(μ, T ),
and suppose for each i ∈ I, pi and pi be the functions used in the definition of
apply(μi,T ). Fix a finite execution fragment α. We show that p1(α)= Σi λipi (α)
and p2(α)= Σi λipi (α), from which it follows that apply(μ, T )(α)= p1(α)+p2(α)= 
Σ λi(pi (α)+ pi (α)) = Σ λi apply(μi,T ).
To prove that p1(α)= Σi λipi (α), we consider two cases. If α = α'aq where α' ∈
supp(μ), a ∈ T , and (α'.lstate, a, η) ∈ D, then, by Definition 2.2 p1(α)= μ(α')η(q)
and for each i ∈ I, pi (α) = μi(α')η(q). Thus, p1(α) = Σi λipi (α). Otherwise,
again by Definition 2.2 p1(α) = 0 and for each i ∈ I, pi (α) = 0, and the result holds

trivially.
To prove that p2(α)= Σi

λipi (α), we consider two cases. If T is not enabled in

α.lstate then, by Definition 2.2, p2(α) = μ(α), and for each i ∈ I, pi (α) = μi(α).
Thus, p2(α) = Σi λipi (α). Otherwise, again by Definition 2.2 p2(α) = 0 and for
each i ∈ I, pi (α) = 0, and the result holds trivially.	 
Proposition B.2 Let {μi}i∈I be a countable family of discrete probability mea-

sures μi ∈ Disc(Frags∗ ) and let μ = Σ

i∈I
λiμi be a convex combination of {μi},

where	λ  = 1.	Let σ be a ﬁnite sequence of tasks.	Then apply(μ, σ) =
Σi∈I λi apply(μi, σ).
Proof. The proof is by induction on the length of σ. If σ is the empty sequence,

then for any η ∈ Disc(Frags∗ ), apply(η, σ)= η and it follows that μ = Σ

i∈I
λiμi =

i∈I λi apply(μi, σ).	For the induction step, let σ = σ'T .	By Definition 2.2, apply(μ, σ'T ) = apply(apply(μ, σ'),T ). By the induction hypothesis, apply(μ, σ') = i λi apply(μi, σ') and thus, apply(μ, σ'T )= apply(	i λi apply(μi, σ'),T ). For each
i ∈ I, apply(μi, σ') is a discrete probability measure in Disc(Frags∗ ). By Lemma B.1,
apply(	λ apply(μ , σ'),T ) =	λ apply(apply(μ , σ'),T ). Using Definition 2.2 it follows that apply(μ, σ'T )= Σi λi apply(μi, σ'T ) as required.	 
