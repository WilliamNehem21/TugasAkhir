Available online at www.sciencedirect.com
ScienceDirect


CAAI Transactions on Intelligence Technology 1 (2016) 241e248
http://www.journals.elsevier.com/caai-transactions-on-intelligence-technology/
Original Article
Fourier Locally Linear Soft Constrained MACE for facial landmark localization*
Wenming Yang*, Xiang Sun, Weihong Deng, Chi Zhang, Qingmin Liao
Graduate School at Shenzhen, Tsinghua University, Tsinghua Campus, The University Town, Shenzhen 518055, China
Available online 20 October 2016

Abstract
This paper proposes a novel nonlinear correlation filter for facial landmark localization. Firstly, we prove that SVM as a classifier can also be used for localization. Then, soft constrained Minimum Average Correlation Energy filter (soft constrained MACE) is proposed, which is more resistent to overfittings to training set than other variants of correlation filter. In order to improve the performance for the multi-mode of the targets, locally linear framework is introduced to our model, which results in Fourier Locally Linear Soft Constraint MACE (FL2 SC-MACE). Furthermore, we formulate the fast implementation and show that the time consumption in test process is independent of the number of training samples. The merits of our method include accurate localization performance, desiring generalization capability to the variance of objects, fast testing speed and insensitivity to parameter settings. We conduct the cross-set eye localization experiments on challenging FRGC, FERET and BioID datasets. Our method surpasses the state-of-arts especially in pixelwise accuracy.
Copyright © 2016, Chongqing University of Technology. Production and hosting by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

Keywords: Facial landmark localization; Overfitting; Multimode; FL2 SC-MACE




Introduction
Facial landmark detection has been drawing increasing at- tentions due to its important role in face recognition, face animation, human computer interaction, expression recogni- tion and 3D face modeling [16,17]. Generally, it can be categorized as face alignment and feature localization. In the task of face alignment, a number of facial landmarks like pupils, nostril and the corner of the mouth are localized interactively. In this vein, perhaps the most popular kind of approaches is Constrained Local Model (CLM [16]), which ultilizes localizer (also referred to as local expert) to detect each landmark separately. The global statistical constraint characterized by the Point Distribution Model (PDM) [3] is

* This work was supported by the Special Foundation for the Development of Strategic Emerging Industries of Shenzhen under Grant JCY20130402145002441.
* Corresponding author.
E-mail address: yangelwm@163.com (W. Yang).
Peer review under responsibility of Chongqing University of Technology.
then imposed on the localization result for modification. While recent literatures concentrate on how to optimize the global parameters according to the structure of human faces, they simplified the discussion on the local expert by utilizing linear SVM or Adaboost in consideration of its efficiency and effectiveness. In some other circumstances, only the co- ordinates of crucial feature points are need. Localizing all facial points may decrease the efficiency in practical use. For example, face recognition needs to detect eyes to remove the similarity variances. For these reasons, a precise and efficient localizer purely using local texture is extremely required.
The approaches for feature localization can be divided into two categories: 1) shape based methods and 2) statistics based methods. Shape based methods, which utilize special geo- metric characteristics of landmarks like pupils, have demon- strated good performance in the situation where the subject show front face and the feature points are visible [4,5]. However they may fail when the subjects show multiple head poses or the features are distorted by some expressions (e.g. closed eyes). Besides, its also hard to transit the method to


http://dx.doi.org/10.1016/j.trit.2016.10.006
2468-2322/Copyright © 2016, Chongqing University of Technology. Production and hosting by Elsevier B.V. This is an open access article under the CC BY-NC- ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



other landmarks. On the contrary, statistics based methods learn the classifiers or templates to determine where the target landmark is. As a representative of statistics based method, correlation filter based localizer has gained success recently. Its merits include shift invariance, robustness to noise and speediness of testing. While correlation filter is optimized to generate an explicit peak at the position of the target in the output plane, it suffers the risks of overfitting to the training samples and the incapability to deal with multimode situa- tions. There have been some attempts to overcome the draw- back of overfitting. In Ref. [6], the whole correlation output is specified for each training image. In Ref. [7], Maximum Margin Correlation Filter (MMCF) combines Mean Square Error SDF with SVM to make a tradeoff between the locali- zation advantage of synthetic discriminant function (SDF) and the generalization capability of SVM. However, since they are all linear methods, the performances deteriorate when the feature points show multiple patterns. Xie et al. introduced RBF kernel to MACE [8]. Mahalanobis et al. construct a quadratic filter using Rayleigh quotient [9]. Though nonlinear
Y(u, v)= H(u, v)X*(u, v)	(1)
plate and the test image respectively. ($)* denotes conjugate where H(u,v) and X(u,v) is the DFT of the synthesized tem- operator. The framework is much like sliding window, in
which each subregion of test image is matched with a tem- plate. However there are several differences between correla- tion operator and sliding window: 1) each subregion could be normalized in the framework of sliding window, which could not be achieved by correlation; 2) because of the lack of normalization, in the testing process peak-to-sidelobe ratio (PSR) [24] rather than simply the output is measured.

Minimum Average Correlation Energy

MACE is the most widely used and researched kind of correlation filter. The earliest version of MACE is proposed in [15], which requires the inner product of template and the true class samples to strictly reach a fixed value:

frameworks are applied, they are still prone to overfitting due
to hard constraints on the cost function.
min h~H Sh~
(2)

~H ~

In this paper, we propose a novel correlation filter which can be used for individual face landmark detection and as local
s.t.
h xi = ui,  i = 1, 2, …l

expert for face alignment algorithms. We first prove why
SVM, as a classifier, is also a well performed localizer. Based on the analysis, we propose soft constrained MACE, which minimizes average correlation energy with soft constraint. In order to avoid the fundamental drawback that single correla-
where h~ is the template to be calculated and ui is the desired
negative ones). ($)H is conjugate transposition and ~xi is the inner product value (e.g. 1 for positive samples and 0 for S = X*Xi is the average energy diagonal matrix, where Xi DFT of the training sample re-ordered into a column vector.

constrained MACE with local linear kernel in Fourier domain, and formulate a nonlinear filter named FL2 SC-MACE. Based


is a N2 × N2 diagonal matrix with the elements of x~ ordered
~H ~	P	~ 



conducted on spatial domain rather than Fourier domain. Be- sides, the testing speed is independent of the quantity of training samples. Our method has the merits of superior localization performance, the generalization to the variance of objects, fast testing speed and insensitivity to parameters. Validation experiments for eye localization are conducted on FRGC, BioID and FERET. To verify the generalization per- formance, we demonstrate cross-set results and show that FL2 SC-MACE outperforms the state-of-arts by a considerable margin.

Backgrounds and soft constrained MACE
Correlation filter
ergy of the correlation output between the template and all the
training samples is suppressed overall. It can be proved that if only one training sample is involved, the optimized correlation
result will be a delta function X*h~ = c(1, 0, …0)T . When there are more than one training samples, it is overdetermined for all
the correlation results to be delta functions. Observations show that the hard constraint as the form of (2) often leads to the sensitivity to distortions and the overfitting to the training samples, which affects the generalization capability of the filter.
Aiming at solving the drawbacks brought by hard constraint, unconstrained MACE is proposed [2]:

~H ~ ~ H ~

In the past decades, different correlation filters that emphasize different goals have been proposed. A filter is
max
h~
h~H
Sh~
(3)

synthesized based on the training samples, which is then cross- correlated with the test image. There is supposed to be a distinct peak at the ground truth location of the target (a blunt peak would affect the accuracy of the localization), and flat responses elsewhere on the correlation plane. In real applica- tion, the calculation is always conducted on spatial frequency
domain:
where m~ = 1/N  ~xi is the mean of the DFTs of training
samples. Unconstrained MACE shows better tolerance to
noises than constrained filters. By removing the hard constraint, it permits the correlation planes to adjust to what- ever value that best optimizes the criterion. However it still doesn't exclude the risk of overfitting. Assuming the response
~H ~

of one training sample h xi is extremely high, it would cause



~H ~ ~ H ~
~H ~

large value of h mm h, which results in the overlook of the
large enough to guarantee a high value of h xi. Note that

influence of other training samples.

Why is SVM a good localizer?

SVM is an optimal classifier in the sense of maximum margin. According to Parseval theorem, the objective function
of SVM converted to the Fourier domain can be written as:
though both using soft constraint, soft constrained MACE is
different from (MMCF [12]). While MMCF is a tradeoff be- tween MSE-SDF and SVM, soft constrained MACE seeks the melioration of SVM and MACE simultaneously.
For further analysis, the dual problem writes as:
max   Xa — 1 X Xa a y y ~x S—1~x

~H ~	X 

 ~H
0≤ai ≤C	i
i	i
i j i j i	j
j
(7)

min h
h~
h + C
i
1 — yi h
~xi + b
+	(4)
s.t.	aiyi = 0
i

where C is the penalty parameter. [$]+ = max($, 0) is referred
~H ~
The frequency components of the training samples are
equilibrized by S—½. This could be regarded as a pre-

to as hinge loss function. While h
~H ~
h is optimized to maximize
~H ~ —1
whitening process in the Fourier domain. Fig. 1 shows the

the margin (minimize h
h is equivalent to maximize (h h)  ,
typical correlation output plane of soft constrained MACE

which is proportional to the margin), the penalty item seeks to
punish the outliers. Here we re-interpret the objective function of SVM in the sense of localization rather than classification, and reveal how SVM achieves good localization performance. The localization task involves two key capabilities: 1) when the object is not the target, the response should stay low to keep from false detecting, and 2) when a target appears, the localizer should not only detect it, but localize it accurately, which requires the output plane to be a sharp peak rather than a blunt one. As S is a diagonal positive definite matrix defined
in (2), h~H Sh~ satisfies the axiom of norm and thus is referred to
as S-norm. The equivalence of S-norm and l2-norm can be written as:
(top) and SVM (bottom). The sharpness of the formal one means it is more suitable for localization task. In addition, because soft constrained MACE calculates the maximum margin hyperplane for the weighted DFTs, only the samples that approximate to the decision hyperplane contribute to the synthesis of the correlation template, which eliminates the risks of overfitting to the training set. While all variants of MACE aim to minimize average correlation energy and maximize the peak value, soft constrained MACE is less likely to overfit samples.
In summary, there exits close relationships between the classification by SVM and the localization by correlation filter. In addition to the sense of maximum margin classification, the objective function of SVM can also be interpreted as

~H ~	~H ~	~H ~

s1h h ≤ h Sh ≤ s2h h	(5)
improving the correlation peak value and suppressing the

where s1 and s2 are constant and correspond to the minimum
and maximum eigenvalues of S. SVM suppresses the energy of the correlation output by minimizing the l2 regularizer.
~H ~
Meanwhile, as h x is the origin of the correlation output,
~H ~
[1 — yi(h xi + b)]+ is actually the soft constraint on the cor-
relation peak value.

The formulation of soft constrained MACE

Savvides et al. indicate that the correlation template works to whiten the amplitude spectrum and cancel the phase of the image, which yields a flat spectrum plane [24]. As the energy decays with the increase of the frequency, the correlation template is expected to amplify the energy of the high fre-
quency region. Though (5) gives an upper limit of the average correlation energy, SVM doesn't emphasize the characteristics of objects' spectrums. Soft constrained MACE which mini- mizes the average correlation energy is written as:

~H ~	X 



 ~H ~
(6)

In order to minimize the objective function, if a diagonal entry of S is large, the corresponding entry of the template h~ is supposed to be small. On the other hand, the entries of the template with respect to the small energy are expected to be
Fig. 1. The typical correlation output plane of soft constrained MACE (top)
and SVM (bottom). Both results are multiplied by a Gaussian function. Though SVM suppresses the energy of the correlation output plane as well, soft constrained MACE show more obvious effect, which results in a sharper peak.



energy of the whole correlation output. In comparison, the objective function of MACE can be interpreted as calculating the optimal decision hyperplane for the weighted DFT of samples. Based on the analysis, we propose soft constrained
where xi is the IDFT of S—1/2~xi and ci is the SVD codes with respect to x . An interpretation of FLSC kernel is that as the
samples distribute in several different manifolds, the inner product value can judge whether two samples belong to the

MACE, which is formulated to overcome the overfitting.
same one. In compensation, cH cj
provides local informations

Fourier local soft constrained MACE
The previous discussion illustrates training the correlation filter is equivalent to participating the weighted DFTs in fre- quency domain. Therefore, though soft constrained MACE is less likely to overfit data, it doesn't settle the problem that the
optimization of linear correlation filter is overdetermined and
ill-posed when the data are characterized of multiple patterns. Recently some researchers proposed local based classifiers whose essential idea is that a query sample is judged by a hy- perplane which is estimated only by the samples that adjoin to it [27,32]. The performances are comparable to traditional kernel
about whether they are also resemblant within the subspace.
Therefore only when two samples are from the same manifold and share the similar coding information can FLSC-kernel get large value.
In testing process, the decision function gives the form as:
HFLSC(x)=   yiaiKLS(x , xi)+ b	(13)
i

where yi and ai are the label and weight of xi. Like the case of kernel SVM, as the number of training samples increases, the computation complexity grows linearly with it. To alleviate the computation complexity, noting in (12) that:

methods. However, they suffer from huge quantity of time cost during test. In this section, we aim to resolve the overfitting efficiently by means of Fourier local linear approach.
Local linear-SVM (LL-SVM) [25] deems the decision

bci bcj
= xT
u1,
b1
bbs

2, ..,
2

n

n0
bsn0
  u1,

b1
bbs

2, ..,
2
T
n0	x
bsn0
(14)

template as a function of the sample being judged. The sample
1  H X0
u˘nuT

is first projected on a local basis. Then a decision function is obtained by using stochastic gradient descent. Instead of using local coding scheme, Zhang et al. [30] coded samples by the singular vectors of the matrix composed by the vectorized
training data: M = (x1, x2, …xn)= USV , and proved the
= S—2 ~xi
n0
= xT
n=0
n=0
unuT
n xj

bn
n xj
bn
(15)
(16)

model is equivalent to a finite kernel which can be written as:
where ui
are the singular vectors trained by the DFTs of the

K x , x  = < c xT , c xT >	(8)
where < $, $ > is the Frobenius inner product and ci = UT xi is the coefficient of xi projecting on the principle left singular
samples, u˘ is the DFT of u and u is the IDFT of S—1/2u , the
quadratic form of x:
T X X bunuT	T

vectors. If the DFTs of samples are chosen to be the feature

 

FLSC
s2 bi€i

theory of SVD that U~ = FU, where F is the Fourier transform
matrix. Therefore we have:
~c = U~ T ~x = c	(9)
Note that (8) can be simplified as:
= xT UU X X€ x + b	(18)
= xT Ax + b	(19)
where €xi is the DFT of aiS—1x~i. The bold capital letters denote

K x , x = cT c X x x
= cT c xT x
(10)
the vectors ordered into the correspond matrixes (e.g. Ub is

sponding singular value bui/si), and A = Ub U XbX€ is the

where xmi is the m-th element of the i-th sample. Use Parseval theorem:
K ~xi , ~xj = ~cH~cj~xH~xj = cT cjxT xj = K xi , xj	(11)
quadratic matrix. To further accelerate the decision process,
considering the localization tasks to which bias b is ignorable and

That is, the kernel value preserves when the manipulations are conducted in Fourier domain. Now consider implementing the local linear scheme to soft constrained MACE. All the
DFTs of the samples are weighted by S—½. The FLSC kernel
e

where the symmetric matrix Ae = A + AT /2 is the even part of A, the decision function can be reformulated as:

then has a form of:
HFLSC(x)= xT Aex = xT ZLZT x =
Xm0
li zT x 
(21)

K	 x , x = bcHbc bxH bx
= bc bc ~x S ~x
(12)
i=1



where Z is an orthogonal matrix and L is a diagonal matrix whose elements are all real. zi are the eigenvectors and li are the corresponding eigenvalues sorted in descend order with respect to its absolute value. Since the rank of A is no more than that of U, m0 is equal to two times of the number of singular vectors used for coding. Experimentally, we found the selection of the number of singular vector doesn't affect
much to the performance, which guarantees the fast imple-
mentation of FL2 SC-MACE. By further eliminating the ei- genvectors zi with small eigenvalue energy, the computation can be achieved more efficiently without deteriorating the performance.

Experiment
We conduct a cross-set eye localization experiment based on BioID, FERET and FRGC databases. This experiment is suitable for verifying the performance of our method because there are many cases when the subjects wear glasses and close eyes, which are different patterns from the standard eye model. We choose cross-set experiment because 1) many state-of-the- art methods have demonstrated satisfying results of intra-class experiment but not exactly in the case of cross-set experiment, and 2) cross-set experiment is more analogous to the real practice, in which the collect environment of training set may not be the same as that of the testing set. Though current re- searches also attempt to localize other landmarks of faces, we
eyes respectively, and d is the ground truth distance between the two eyes.

Procedures

resize them to 100 × 100. The images which are not detected are We use OpenCV to crop faces from all three datasets, and discarded. Since the cropped face image fits the anthropometric
ratio, we will localize eyes in a rough region that is large enough to cover all kinds of extreme cases. Rationally, the negative samples are randomly selected in the same region. Also, they should keep away from the authentic positions at least about 0.1 times of d. Each image provides one positive feature and 20 negative features for two eyes respectively. All the feature
vectors have the dimension of 21 × 21. Each of them is normalized by taking a log(1 + v), deducting its mean and normalizing the energy. The training samples are firstly con-
voluted by S—½. SVD is then implemented on the filtered sample features. SVM packets like Libsvm [14] can be used to train the
weighting coefficients ai, with the kernel as a form of (12). While A is obtained following (19), the correlation templates zi and eigenvalues li can be calculated. The position with the highest peak-to-sidelobe ratio is regarded as eye location.

Result

In the first experiment, we test the performance changes

focus on eye localizing experiment because almost all the
with respect to the number of singular vectors ui
to code. We

landmark detection methods use the special structure of the face, which is not the main point of this paper. Nevertheless, our method is nicely compatible for many landmark detection approaches, which also use a localizer like SVM to give a evaluation of candidate pixels.
image resolution fixed at 384 × 286. The samples are BioID is a challenging dataset for eye localization task with collected under a large variety of illumination, expression and
pose. The FERET database was constructed ranging from 1993 to 1997 over 15 sessions for automatic face recognition experiments. It consists 994 subjects photoed at different an-
gles with the size of 512 × 768 pixels. We choose regular
frontal images and alternative frontal images (referred to as fa
and fb) for our experiment. FRGC aims to provide sufficient data for researchers who are engaged in face recognition. It comprises six experiments. Among 50000 available images, some are collected in still controlled lighting condition and some are not. In all datasets, there are a number of images when the subjects either close their eyes or wear glasses.
Normalized error is used to assess our outcome. This measurement was firstly proposed by Jesorsky [19] and is a reasonable criterion with respect to the real application of eye localizer. In this metric, the worse localized eye is measured:
partition FRGC into two groups. The training group consists
2000 images and the remaining are assigned to testing group. Fig. 3 shows the localization performance as a function of the



max(el, er)
en =	d
(22)

where el and er are the Euclidian distances between the ground
truth and the estimated location with respect to left and right
Fig. 2. The green crosses denote the ground truth positions while the red ones denote the predict positions.


simple unimodal normal distribution whose mean and variance are those of training set.
Table 1 shows the results of our approach and others. We provide results with or without prior knowledge. If the authors didn't provide a complete result, we will make an approxi-
mation based on the performance curve or simulate their
methods. Note that although some papers demonstrate a good localization rate, i.e. [31], which reaches 89.6%, when
e = 0.05 and 99.1% when e = 0.25, we exclude those results
from Table 1 because the training and validation process are
executed on BioID as well. As can be seen from the results presented, FL2 SC-MACE demonstrates a desired result in both accurate and coarse localization.
Tables 2 and 3 show the localization results of several facial landmarks, i.e., eye corner, mouth corner and nose on LFPW [21] and HELEN database [22]. Since these two da-


Fig. 3. The performance as a function of the number of basis singular vectors.	Table 1
The comparison of cross-set eye localization performance. If the author doesn't give result, we will estimate it according to the given curve or simulate the

number of singular vectors u . As can be seen, the perfor- mance is insensitive to the parameter.
algorithm ourselves (underlined figures).
Method	e ≤ 0.05	e ≤ 0.1	e ≤ 0.25


database are used for training. As can be seen, QLS-MACE shows overall advantages beyond others, especially in accu- rate localization performance (e < 0.05). Fig. 2 demonstrates

Since a number of eye locating methods are tested on BioID with the same normalization error measurement, it's facilitative to compare our methods with the preceding results.
In this experiment we still guarantee that all training samples are from other datasets than BioID. Prior knowledge of eye position is also used to improve performance. Following MAP criterion, the posterior probability writes as:
P((x, y)|I)fP(I|(x, y))P((x, y))	(23)
The bold is the best performance in the corresponding correction level.


Table 2
The percentage that the localization error of the landmark is less than 10% of the eye-to-eye distance on LFPW database.


Method	Left eye corner	Left mouth corner	Nose



likelihood [36], we model prior probability P((x,y)) by a
Ours	85.07%	78.28%	68.78%





Fig. 4. Cross-set performances in FRGC FERET and BioID databases. QSL-MACE demonstrates overall advantages in both accurate and coarse localization.



Table 3
The percentage that the localization error of the landmark is less than 10% of the eye-to-eye distance on HELEN database.


Table 4
The comparison of running time for detecting one eye. The number of training samples (including both positive and negative ones) accounts to 40000. All algorithm are imple- mented by C on Intel I7 CPU.



tabases consist of unconstrained faces from Internet, it is not necessary to perform cross-set experiment for validating the generalization capability. Therefore, we combine the training sets of the databases as the generic training set. Note that we
didn't compare our method with face alignment algorithms because 1) FL2 SC-MACE detects feature points only relying
on local appearance, while face alignment algorithms utilize the global face shape to rectify the results, and 2) our approach is compatible with many face alignments [16,17] by locally detecting candidate feature points. As can be seen, our algo- rithm outperforms the commonly used localizers. It means FL2 SC-MACE is still effective in complex situations such as multiple face poses, expressions, disturbance and so on.
In Table 4 we compare the running speed of FL2 SC-MACE with that of other typical methods. We conduct algorithms by C on Intel I7 CPU among which SVMs are implemented by LibSVM [14]. All localizers are trained by 2000 images, which lead to roughly 4000 SVs for kernel SVM. As can be seen, the fast testing speed of FL2 SC-MACE enables real-time applications.

Conclusion
This letter proposes a correlation filter referred to as FL2 SC-MACE. Soft constraint is imposed on the cost function of MACE to overcome the overfitting. Fourier local linear model is further introduced so that it could deal with multimode situations. We conducted cross-set eye localization experi- ments to demonstrate the superior performance and efficiency of our method. In future work we will seek an accurate and fast face alignment algorithm based on FL2 SC-MACE.

Acknowledgment
This work was supported in part by the Natural Science Foundation of China under Grant No.61471216 and in part by
the Special Foundation for the Development of Strategic Emerging Industries of Shenzhen under Grant No.J- CYJ20150831192224146 and No.JCYJ20150601165744635.

References
A. Mahalanobis, B.V.K.V. Kumar, S. Song, et al., Appl. Opt. 33 (17) (1994) 3751e3759.
T.F. Cootes, C.J. Taylor, D.H. Cooper, et al., Comput. Vis. Image Underst. 61 (1) (1995) 38e59.
R. Valenti, T. Gevers, Accurate eye center location and tracking using isophote curvature, in: IEEE Conference on Computer Vision and Pattern Recognition, CVPR, 2008, pp. 1e8.
Y. Ren, S. Wang, B. Hou, et al., IEEE Trans. Image Process. 23 (1) (2014) 226e239.
D.S. Bolme, B. Draper, J.R. Beveridge, Average of synthetic exact filters, in: IEEE Conference on Computer Vision and Pattern Recognition, CVPR, 2009, pp. 2105e2112.
A. Rodriguez, V.N. Boddeti, B.V.K.V. Kumar, et al., IEEE Trans. Image Process. 22 (2) (2013) 631e643.
C. Xie, M. Savvides, B.V.K. VijayaKumar, Kernel correlation filter based redundant class-dependence feature analysis (KCFA) on FRGC2. 0 data, in: Analysis and Modelling of Faces and Gestures, Springer Berlin Heidelberg, 2005, pp. 32e43.
A. Mahalanobis, R.R. Muise, S.R. Stanfill, Appl. Opt. 43 (27) (2004) 5198e5205.
[12] A. Rodriguez, V.N. Boddeti, B.V.K.V. Kumar, et al., Maximum margin correlation filter: a new approach for localization and classification, in: IEEE Transactions on Image Processing, 2013, pp. 631e643.
C.C. Chang, C.J. Lin, ACM Trans. Intell. Syst. Technol. (2011).
Abhijit Mahalanobis, B.V.K. Kumar, David Casasent, Appl. Opt. 26 (1987) 3633e3640.
Jason M. Saragih, Simon Lucey, Jeffrey F. Cohn, Face alignment through subspace constrained mean-shifts, in: International Conference on Computer Vision e ICCV, 2009, pp. 1034e1041.
Xiaowei Zhao, Shiguang Shan, Xiujuan Chai, Xilin Chen, Cascaded Shape Space Pruning for Robust Facial Landmark Detection, ICCV, 2013.
M. Tu¨rkan, M. Pardas, A.E. Cetin, Human eye localization using edge projections, in: VISAPP, 2007, pp. 410e415.
Oliver Jesorsky, Klaus J. Kirchberg, Robert W. Frischholz, Robust Face Detection Using the Hausdorffdistance, Audio-and Video-based Bio- metric Person Authentication, 2001.
D. Cristinacce, T. Cootes, Scott, A multistage approach to facial feature detection, in: Proceedings of the 15th BMVC, 2004, pp. 277e286.
P.N. Belhumeur, D.W. Jacobs, D.J. Kriegman, N. Kumar, Localizing parts of faces using a consensus of exemplars, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), IEEE, Colorado Springs, USA, 2011, pp. 545e552.
V. Le, J. Brandt, Z. Lin, Interactive facial feature localization, in: Proc. IEEE Eur. Conf. Comput. Vis. (ECCV), Firenze, Italy, 2012, pp. 679e692.
Zhiheng Niu, et al., 2d Cascaded Adaboost for Eye Localization, ICPR, 2006.
M. Savvides, B.V.K.V. Kumar, P.K. Khosla, “Corefaces”-robust Shift Invariant PCA Based Correlation Filter for Illumination Tolerant Face Recognition, CVPR, 2004.
Lubor Ladicky, Philip Torr, Locally Linear Support Vector Machines, ICML, 2011.
Stylianos Asteriadis, et al., An eye detection algorithm using pixel to edge information, in: Int. Symp. on Control, Commun. and Sign. Proc, 2006.
Hao Zhang, et al., Discriminative Nearest Neighbor Classification for Visual Category Recognition, CVPR, 2006.
Bart Kroon, Alan Hanjalic, Sander MP. Maas, Eye localization for face matching: is it always useful and under what conditions?, in: Proceedings of the 2008 International Conference on Content-based Image and Video Retrieval, ACM, 2008.



R. Valenti, T. Gevers, Accurate Eye Center Location and Tracking Using Isophote Curvature, CVPR, 2008.
Zhang Ziming, et al., Learning Anchor Planes for Classification, NIPS, 2011.
Fei Yang, et al., Eye Localization through Multiscale Sparse Dictio- naries, Automatic Face & Gesture Recognition and Workshop, 2011.
M. G€onen, E. Alpaydin, Localized Multiple Kernel Learning, ICML, 2008.
David S. Bolme, Bruce A. Draper, J. Ross Beveridge, Average of Syn- thetic Exact Filters, CVPR, 2009.
Xiaoyang Tan, et al., Enhanced Pictorial Structures for Precise Eye Localization under Incontrolled Conditions, CVPR, 2009.
Fabian Timm, Erhardt Barth, Accurate Eye Centre Localisation by Means of Gradients, VISAPP, 2011.
J. Platt, Adv. Large Margin Classif. 10 (3) (1999) 61e74.


Wenming Yang received the B.S. and M.S. in material science from Harbin University of Science and Tech- nology, Harbin, China in 2000 and 2003, respectively. In 2006, he received the Ph.D in electronic engineer-
ing from Zhejiang University, Hangzhou, China. From 2007 to 2009, He was a Post doctoral Fellow in Department of Electronic Engineering, Tsinghua University. Since 2013, He has been associate pro- fessor in Department of Electronic Engineering at Graduate School at Shenzhen, Tsinghua University.
His research interests include image processing and pattern recognition, computer vision, biometrics, video surveillance, image super-resolution and non-destructive testing based on artificial vision.
Xiang Sun received the B.S. of Communication En- gineering in 2013, Beijing University of Posts and Telecommunications, Beijing, China. In 2016, he received M.S. of electronic engineering from Tsinghua
University, Beijing, China. He is now working at Big Data Inventation Centre of Creditease, Beijing, China. His research interests include face recognition and automatic credit to business.





Qingmin Liao born in 1963. He received the B.S. degree in radio technology from the University of Electronic  Science  and  Technology  of  China,
Chengdu, China, in 1984, and the M.S. and Ph.D. degrees in signal processing and telecommunications from the University of Rennes 1, Rennes, France, in 1990 and 1994, respectively. Since 1995, he has been joining with Tsinghua university, Bei-jing, China. He became Professor in the Department of Electronic Engineering of Tsinghua University, in 2002. From 2001 to 2003, he served as the Invited Professor with a
tri-year contract at the University of Caen, France. Since 2010, he has been Director of the Division of Information Science and Technology in the Graduate School at Shenzhen, Tsinghua University, Shenzhen, China. His research interests include image/video processing, transmission and analysis; biometrics; and their applications to teledetection, medicine, industry, and sports. He has published over 90 papers internationally.
