Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 338 (2018) 97–114
www.elsevier.com/locate/entcs


An Interpretation of CCS into Ludics

Stefano Del Vecchio1,2 and Virgile Mogbil1
1LIPN, CNRS – Université Paris 13, Villetaneuse, France
2Dipartimento di Matematica e Fisica, Università Roma Tre, Roma, Italia.

Abstract
Starting from works aimed at extending the Curry-Howard correspondence to process calculi through linear logic, we give another Curry-Howard counterpart for Milner’s Calculus of Communicating Systems (CCS) by taking Ludics as the target system. Indeed interaction, Ludics’ dynamic, allows to fully represent both the non-determinism and non-confluence of the calculus.
We give an interpretation of CCS processes into carefully defined behaviours of Ludics using a new con- struction, called directed behaviour, that allows controlled interaction paths by using pruned designs. We characterize the execution of processes as interaction on behaviours, by implicitly representing the causal order and conflict relation of event structures. As a direct consequence, we are also able to interpret deadlocked processes, and identify deadlock-free ones.
Keywords: Calculus of Communicating Systems (CCS), Linear logic, Ludics interaction, non-determinism.

Introduction
Process algebras are an approach to concurrent theory, to model interactive systems, based on communication, often as message-passing, and reasoning on primitive op- erators like parallel composition; among the most known and used systems there are Milner’s Calculus of Communicating Systems (CCS) [14], and the π-calculus ([15], [16]). In our work we focus on the former to give an interpretation in the proof theory setting of Ludics [12], which bring back together syntax and semantics following the paradigm of interactive computation, similarly to what is done in game semantics. Finding a proper Curry-Howard counterpart for such calculi could provide a logical foundation to concurrent computation, and some insight into its dynamic.
Usual models for concurrency can be used to give semantics to process algebra,
e.g. event structures [23] for CCS [22]. Like Petri Nets [18], event structures are a true concurrent model but based on explicit causal order and conflict relations to reveal concurrency. Using closure on these notions, semantical properties easily char-
acterize behaviours such as (no) conflicts, choice independence and confluence. Such closures are also present in our interpretation but internalized in Ludics’ behaviours directly by bi-orthogonality. From another view point, our Ludics interpretation of

https://doi.org/10.1016/j.entcs.2018.10.007 1571-0661/© 2018 Published by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

CCS expresses all possible schedulings under non-deterministic choices. Somehow this brings it closer to interleaving models for concurrency like traces and labeled transition systems [24] whose main ability is to characterize observational equiva- lence.
Motivations and related works. The motivations of this work come from stud- ies aiming at extending the Curry-Howard correspondence outside the functional setting, to model concurrency. Many approaches achieved such a correspondence (as [7]), though by imposing determinism to processes, i.e. limited to concurrent systems where only a deterministic behaviour can occur. However, reduction on processes is, in general, non-deterministic and non-confluent: this intrinsically lim- its a possible correspondence with cut elimination or normalization of proofs, whose nature is confluent and deterministic, effectively restraining a process to functional behaviour.
We start from works based on Linear logic [11] (which inspired many systems, being a logic particularly tied to interaction) that stress the difficulties with the mentioned approaches; in particular [4], [3], [5] and [8]. In [8] the authors show that differential nets are a suitable target system for a correspondence, though the translation proposed is not modular, in the sense that we cannot compose two differ- ential nets to represent the (parallel) composition of two processes. But even proof nets, that have similar dynamics to process calculi, with a local and asynchronous cut elimination procedure, were unable to express the behaviour of concurrent sys- tems without a shift of correspondence, based on the scheduling of executions [6]: from proof-nets as processes to proof-nets as executions, stressing the fact that the meaning of a proofs lies in its normal form, reached by cut elimination, while the meaning of a process is not one of its multiple irreducible forms, but how each form is reached: which channels communicate, and what is the form of the process at each step. The aim of our work is to try to carry out the same correspondence, but in the setting of Ludics [12] to overcome the limitations of cut elimination by using a logical system with interaction at its core.
Ludics has already been related to process calculi in works by C. Faggian and co.: from this connection the authors aim at gaining a way to represent replication (as in [2]) and non determinism inside Ludics – whose standard version is lacking both; however the correspondence between execution and interaction is not developed at all. As we understand now, our work is rather taking the opposite direction of [9], by effectively representing the causal order and conflict relation of event structures in Ludics using behaviours. This is achieved using a new construction, found in [10], called directed behaviour, that allows controlled interaction paths from carefully pruned designs. Finally we form a strong correspondence between execution in CCS and interaction in Ludics, without losing neither its non-determinism nor its non- confluence (i.e. multiple normal forms).
Outline. After background notions and notations for both Ludics (designs, be- haviours and interaction) and MCCS (a simple fragment of CCS), we define in the third section our interpretation ⟦P ⟧ of a process P in term of a Ludics’ behaviour equipped with an assignment function. Section 4 summarizes the main results for

MCCS and finishes with their extension to replication-free CCS. At first we focus on the correspondence between process execution and Ludics interaction: ⟦P ⟧ char- acterizes all executions on P . We then present the parallel composition as merging of interpretations, and an operational version of the interpretation corresponding to the process execution. We also give a characterization of deadlock-free processes, in the form of a sufficient condition to check on the interpretation for deadlock-freedom. In the last section we explain how to apply our technique to full CCS, that is an extension to replication using Terui’s computational Ludics [20].


Background
Ludics is an abstraction of multiplicative-additive linear logic proofs in sequent cal- culus, under focused discipline (used for optimizing proof-search space by Andreoli [1]), thus cut-free and with a strict alternation between positive and negative rules. Designs the objects of Ludics, replace formulas with addresses ξ,ζ,... (se- quences of natural numbers); subformulas becomes sub-addresses ξ.1, ξ.2.1,.   To
give an intuition, proofs are rewritten in the following way:
Example 2.1 A focused proof of the formula ((A1 ⊗ A2) & B) ` C is:
⊢ A1, C, Δ1	⊢ A2, Δ2
⊢ A1 ⊗ A2, C, Δ	⊢ B, C, Δ

⊢ ((A1 ⊗ A2) & B) ` C, Δ
where the connectives & and ` are introduced at the same time. Going further, and considering only positive formulas, it becomes
Aı ⊢ C, Δ1	Aı ⊢ Δ2
1	2
⊢ A1 ⊗ A2, C, Δ	⊢ B, C, Δ

((A1 ⊗ A2)ı ⊕ Bı)⊗ Cı ⊢ Δ
Finally in Ludics, formulas are forgotten, and we have
ξ.1.1 ⊢ ξ.3, Δ1	ξ.1.2 ⊢ Δ2
⊢ ξ.1, ξ.3, Δ	⊢ ξ.2, ξ.3, Δ

ξ ⊢ Δ
where the Δis are sets of addresses.
Formally, designs can be defined thus:
Definition 2.2 A design D isa tree of abstract sequents built and labeled by rules called actions, such that each branch ends with a positive action. The rules are the following:

Daimon (Dai+
∶)	⊢ Δ s

where Δ is a finite set of addresses. The Daimon is a positive action.


Positive action:
.. .	ξ.i ⊢ Δi	...  (+, ξ,I)
⊢ Δ,ξ 

where i ∈ I, with I ⊂ N. I is the ramification of the rule and ξ is its focus. Δis are disjoint and included in Δ.
.. .	⊢ ξ.I, ΔI	...  (−, ξ, N) 
Negative action:	ξ ⊢ Δ
where N is the ramification of the rule, and ξ its focus. N ⊂ Pfin(N), ξ.I =
ξ.1,..., ξ.n, with 1,...,n ∈ I and I ∈ N ; the ΔIs are included in Δ.
The ramification denotes the number of branches generated by the rule; i.e. the premises containing the sub-addresses ξ.i, with i ∈ I, or ζ.i1,...,ζ.in with i1,..., in ∈ I and I ∈ N . Any rule with a sub-address ξ.i as focus is justified by the rule introducing ξ.
Positive and negative actions are strictly alternated and Dai+ can only be the
last action of a design.
Interaction is the equivalent in Ludics of cut elimination, and define its dy- namic; the way a design interact is explicited by its syntax, closing the gap with semantics. We use the presentation and definitions found in [17], essentially the same as the seminal article [12]. The following example gives an idea of two orthogonal

designs and interaction between them:		
s10

⊢ ξ.2.1.1, ξ.1.1.1 (−, ξ.2.1, {{1}})9
ξ.2.1 ⊢ ξ.1.1.1 (+, ξ.2, {1})6
ξ.1.1.1 ⊢ (+, ξ.1.1, {1})4 ξ.2.1.1 ⊢ (+, ξ.2.1, {1})8 ⊢ ξ.1.1.1, ξ.2 (−, ξ.1.1, {{1}})5

⊢ ξ.1.1 (−, ξ.1, {{1}})3
ξ.1 ⊢
⊢ ξ
⊢ ξ.2.1 (−, ξ.2, {{1}})7
ξ.2 ⊢ (+, ξ, {1, 2})0
ξ.1.1 ⊢ ξ.2 (+, ξ.1, {1})2
⊢ ξ.1, ξ.2 (−, ξ, {{1, 2}})1
ξ ⊢

Here the numbers denote the n-th interaction step. Interaction starts from the cut on the bases (i.e.  conclusions ⊢ ξ and ξ ⊢), and checks the premises of the
+ rule: if the ramification {1, 2} finds a match in the corresponding negative rule, interaction continues, and ends successfully if it reaches a daimon s: it fulfills the
role of axioms, stopping proof-search. In case of successful interaction between two designs D and C, we say that they are orthogonals, denoted DıC or C ∈ Dı (and
vice-versa). We will interpret processes as behaviours; formally we have
Definition 2.3 A behaviour is a set of designs B = {D1,..., Dn} of same base
closed by bi-orthogonality, i.e. such that Bıı = B.
MCCS, a fragment of Milner’s CCS. At first we restrict our setting to the multiplicative fragment of CCS, as presented in [4], in short called MCCS, to keep it as simple as possible. In section 4.5 the same tools will be used to represent non- deterministic choice and name hiding (aka restriction). Replication is addressed in section 5 and treated in a reformulated version of Ludics by K. Terui, called c-ludics [20]. MCCS terms are described by the following syntax:
P, Q ∶= 1 ∣ al.P ∣ am.P ∣ (P ∣ Q)

a, b, c,... denotes channel names occurrences, taken from a countable set A of names, and are labeled with locations l, m, o,.. ., taken from a countable set Loc of locations (LocP denotes the locations of a process P ). They are denoted al, bm, co, etc. al.P is the positive action prefix, am.P the negative one, and P ∣ Q the parallel composition of two processes. We use 1 to denote the empty process, instead of the traditional 0, since it is not only the neutral element of the non-deterministic choice (+), but also of the parallel composition (P ∣ 1 ≡ P ), which shows a multiplicative behaviour in our interpretation (as we will see, there is also a connection with the linear logic unit 1). A partial order on locations <P is induced by the prefix order of the occurrences of channel names they label: if P = al.bm ∣ Q, then l <P m. A synchronization, denoted i, j, u, v,.. ., is a pair (al, am) of dual channel-name occurrences, which we can synchronize to perform execution, by the local rule

al.P ∣ am.Q →(l,m) P ∣ Q.
The set of synchronizations of P is denoted SP . If two synchronizations u, v have a location in common, then (u, v) ∈ XP , the set of xor conditions of P , a conflict- like relation. With xor(u) = {v1,..., vn ∣ (u, vi) ∈ XP , 1 ≤ i ≤ n} we denote the set of synchronizations in conflict with u, i.e. the ones that cannot be in the same execution sequence with u. The partial order on locations <P is naturally extended to synchronizations and denoted ≼SP : u ≼SP v if there is a location l ∈ u and a location m ∈ v such that l <P m. Equality comes from the fact that a location of u could be smaller or greater than a location of v and vice-versa, forming a cycle u ≼ v ≼ u in the order.


The interpretation
We present here the interpretation of the MCCS fragment. Firstly, the elements of the process relevant for execution must be represented: via an assignment of locations, cuts, and xor conditions to addresses, we can code them into designs. We interpret each element of LocP , SP and XP into negative designs, then put them together as premises (sub-designs) of a single positive design, the base design, denoted DP , that is a preliminary and naive interpretation of a process P .
Secondly, also the order and conflict relations between these elements need to be coded, and respected during interaction: a new operation on designs is used to restrict interaction paths accordingly to the said relations, and closure properties are obtained by bi-orthogonality, generating a behaviour. The partial orders <P and ≼SP and the conflict relation XP are represented using particular directed (or non commutative) modifications of DP , called restriction designs, denoted R(P ). These modifications exploit a technique found in [10], the pruning of a branch of a design, which affects interaction in the context of a behaviour. The role of R(P ) is restricting the possible interactions on DP by forcing them to respect the prefix order and conflict relation, once we put the designs together as the set of generators of a behaviour. Using the designs of the previous example, we try to give an intuition

of the idea behind the pruning.

ξ.1.1.1 ⊢ (+, ξ.1.1, {1})
Example 3.1 D ∶  ⊢ ξ.1.1 (−, ξ.1, {{1}})
ξ.1 ⊢
⊢ ξ
s


ξ.2.1.1 ⊢ (+, ξ.2.1, {1})
⊢ ξ.2.1 (−, ξ.2, {{1}})
ξ.2 ⊢ (+, ξ, {1, 2})

s

⊢ ξ.2.1.1, ξ.1.1.1 (−, ξ.2.1, {{1}})
ξ.2.1 ⊢ ξ.1.1.1 (+, ξ.2, {1})
C ∶	⊢ ξ.1.1.1, ξ.2 (−, ξ.1.1, {{1}}) ξ.1.1 ⊢ ξ.2 (+, ξ.1, {1})
⊢ ξ.1, ξ.2 (−, ξ, {{1, 2}})
ξ ⊢
⊢ ξ.1.1.1, ξ.2.1.1 (−, ξ.1.1, {{1}})
ξ.1.1 ⊢ ξ.2.1.1 (+, ξ.1, {1})
E ∶	⊢ ξ.2.1.1, ξ.2 (−, ξ.2.1, {{1}}) ξ.2.1 ⊢ ξ.2 (+, ξ.2, {1})
⊢ ξ.2, ξ.1 (−, ξ, {{1, 2}})
ξ ⊢

Both C and E are orthogonal to D. However
s



D. ∶ ξ.1 ⊢
⊢ ξ.2.1
p
ξ.2 ⊢
⊢ ξ
(−, ξ.2, {{1}})
(+, ξ, {1, 2})

where p denotes a pruning on the branch starting with ξ.1 ⊢, is orthogonal only to E : interaction cannot continue on ξ.1, since it is not introduced by a rule anymore, but can only pass through ξ.2 ⊢, stopping at the s above ξ.2.1. In conclusion, E ∈ 
{D, D.}ı, since it visits the ξ.2 branch first, while C ∉ {D, D.}ı; in this way we have forced interaction to respect the order ξ.2 < ξ.1.
Formally, let [ ]P be an assignment function from LocP ∪ SP ∪ XP to addresses: for x ∈ LocP ∪SP , we build the negative design G[x] described by the device of Fig.1 where [x]P is the address assigned to the synchronization or location in question; for instance [u]P = ξ.1 and [l]P = ξ.2, with u ∈ SP and l ∈ LocP . Each (u, v) ∈ XP , to fork the interaction path, is interpreted by w[u, v], in Fig.1, where we note the action as & since it is a binary negative rule, and xoru & xorv is an address assigned to the clause (u, v). Then, the base design is:


DP =(	Ⓒ
x‹(£P uLocP ),(u,v)‹FP
{G[x], w[u, v]})

where Ⓒ stands for a sole positive rule (+, ξ,I) with each element of the set as an


[x]P .1.1 ⊢
xoru.1 ⊢
xorv.1 ⊢
s
⊢ [l].1



⊢ [x]P .1
⊢ xoru
⊢ xorv


..	[l]⊢	..
p
[i] ⊢	..


G[x]=  [x]P ⊢	w[u, v]= 


xoru & xorv ⊢	R(i)=	⊢ ξ


Fig. 1. Device designs, and restriction design for i ‹ £P .

element of the ramification I (we assume that the assigned addresses have all the same prefix ξ). Each negative design is thus a different premise, each containing a sub-address of the focus. A restriction R(i) for a synchronization i = (am, ao) such that, for instance, l <P o, is an alteration of a copy of DP obtained by forcing a s on G[l] and a pruning on G[i]. Such restriction R(i) is of the form described in Fig.1, where the dots ⋯ stands for all the other sub-designs of DP , which remain unaffected. Any interaction with a design orthogonal to both R(i) and DP will be forced to visit [l] ⊢ before [i] ⊢. For (u, v) ∈ XP , instead, we need two restriction designs described in Fig.2; thus tying each member of the xor pair (u or v) to a different branch of the negative rule, which effectively fork the interaction path. To finish we need to put the base design and all restriction designs together: they form the generators of a behaviour, obtained by bi-orthogonality. Therefore, let
BP = Bıı = ({DP }∪ R(x)∪ R((u, v)))ıı
for all x ∈ (SP ∪ LocP ), (u, v) ∈ XP (note that R(x/(u, v)) is actually a set of restrictions, usually more than one design).  Then, the interpretation of P is
⟦P ⟧= (BP , [ ]P ), the pair formed by the behaviour BP and an assignment function
[ ]P from SP , XP and LocP to addresses.



Main results
In this section we present results for MCCS, and will extend the setting to replication-free CCS only later, for which all the results remain valid. Solutions for the extension to replication are presented in the next section, giving a correspon- dence for full CCS.
The results consist of the expected correspondence between process execution and interaction in Ludics (Theorem 4.3), and between parallel composition and the merging of interpretations – that is, the operation Ⓒ on behaviours, the ludical correspective of the linear logic tensor – when composing independent processes (Theorem 4.5); then, an operation mimicking execution on behaviours, giving us an intended weak subject reduction property (Theorem 4.6), and a characterization
of deadlock-free processes, based on the notion of visitable paths of a behaviour
(Theorem 4.8).


s xorv.1 ⊢	xoru.1 ⊢		 s

⊢ xoru
⊢ xorv
p	⊢ xoru
⊢ xorv	p

..	xoru & xorv ⊢	..
⊢ ξ
⊢	..
..	xoru & xorv ⊢	..
⊢ ξ
⊢	..


Fig. 2. Two restriction designs for (u, v)‹ FP .

Correspondence between execution and interaction
In order to form a correspondence between the dynamic of a process P and its inter- pretation ⟦P ⟧ we need to be able to extract from interaction the relevant information describing execution. The core notion is the one of visited actions inside an interac- tion path. The actions considered at each step by interaction are said visited, and an interaction path on a design is the sequence of visited actions. Our aim is to give a definition of associated execution which will make any orthogonal design describe an execution sequence, even if the empty one; at the same time the directed restrictions will ensure that if a design is orthogonal to BP then its associated execution on the process P is admissible, i.e. it respects the partial order on synchronizations <£P , and the xor conditions XP , thus being a possible execution sequence on P . The following notion is therefore well defined. Let KÐ be the sequence of actions of D

visited during interaction with C, we have
Definition 4.1 Let C ∈ Bı . The execution on P associated to C is →i
execution sequence such that for all synchronization i ∈ (i1,..., in),
(−, [i], {{1}})(+, [i].1, {1}) = G[i]∈ KÐP ,

⋯ →in

, the

ordered as they are visited by the interaction path.

An Example of associated execution
Example 4.2 Let DP =

	

ξ.1.1.1 ⊢ (+, ξ.1.1, {1})4
⊢ ξ.1.1 (−, ξ.1, {{1}})3
ξ.1
ξ.2.1.1 ⊢ (+, ξ.2.1, {1})8
⊢ ξ.2.1 (−, ξ.2, {{1}})7
ξ.2


⋯ (+, ξ,I)0







and C=
⊢ ξ
⊢ ξ.2.1.1, ξ.1.1.1, Δ s10
(−, ξ.2.1, {{1}})9
ξ.2.1   ξ.1.1.1, Δ (+, ξ.2, {1})6
⊢ ξ.1.1.1, ξ.2, Δ (−, ξ.1.1, {{1}})5 ξ.1.1 ⊢ ξ.2, Δ (+, ξ.1, {1})2
⊢ ξ.1, ξ.2, Δ (−, ξ, {I})1
ξ

Assume ξ.1 = [i] and ξ.2 = [j]. Then KÐP =
(+, ξ,I)(−, [i], {{1}})(+, [i].1, {1})(−, [j], {{1}})(+, [j].1, {1}).
Therefore the execution associated to KÐP is →i,j. Furthermore i, j are minimal
synchronizations with respect to ≼£P , since they are visited first in DP (and therefore also have no xor conditions).
By construction of the interpretation and definition of associated execution, we find the expected correspondence between execution on processes and interaction on behaviours:
Theorem 4.3 Let P be a MCCS process, ⟦P ⟧ characterizes all executions on P.

With characterizes we mean that to each interaction between BP and Bı is as-
sociated an execution, and each execution is associated to at least one interaction. It correspond to an admissible execution since the restriction designs force interaction
to respect the partial order <P and conflict relation XP .

Parallel composition as merging of interpretations
To make the translation modular we need to represent the parallel composition on processes P ∣ Q by a composition of their respective behaviours BP and BQ, via a logical operation on them. This operation, called merging, is based on Ⓒ, the Ludics equivalent of the linear logic tensor ⊗, which is the extension to behaviours of the
more primitive composition ⊙ on positive designs, also called merging (of designs).
Informally, let D and C be designs of the same base ⊢ ξ and of respective first action
(+, ξ,I) and (+, ξ,J ), such that I ∩ J = ∅. Then,
D⊙ C = {(+, ξ,I ∪ J )c ∣ (+, ξ,I)c ∈D or (+, ξ,J )c ∈ C}
where c denotes a branch (usually called a chronicle) of the design in question. If
I ∩ J ≠∅ or either D or C are s, then D⊙ C = s.
The full operation is defined thus:
Definition 4.4 [17] Let B and E be positive behaviours, with disjoint ramifications of the first rule, and of same base. Then
B Ⓒ E = {D ⊙ C ∣ D ∈ B, C ∈ E }ıı
This operation, along with a composition of the assignments [ ]P ∪ [ ]Q and a few intermediate steps, let us compose the interpretations of two processes P and Q to achieve the interpretation of P ∣ Q. In the trivial case where P and Q cannot communicate, it is a straight correspondence:
Lemma 4.1 Given BP and BQ as behaviours with the same base, and disjoint ramifications of the first rule, if there is no communication between P and Q, then the corresponding interpretation is
⟦P ∣ Q⟧= (BP Ⓒ BQ, [  ]P ∪[  ]Q).
The assumption poses no issues, since the addresses assigned by the function [ ]P are completely arbitrary, and it only matters which element is assigned to which address. We may also assume a renaming of either [ ]P or [ ]Q to have them disjoint : this would let DP and DQ have the same base, but a disjoint ramification of the first action; i.e. no common sub-address, and thus no conflict in the assignments [ ]P and [ ]Q. If there are possible communications between P and Q a few modifications are needed on the construction of the interpretation, to account for the new synchronizations generated in the parallel composition P ∣ Q, and their xor conditions; but the logical core operation ⊙ is kept intact on the base designs. The

new objects that need to appear in the merging can be captured by the sets
newSP |Q = SP |Q ∖ (SP ∪ SQ)	and	newXP |Q = XP |Q ∖ (XP ∪ XQ).
We can deduce the new synchronizations, xor conditions and their restriction designs by checking [ ]P and [ ]Q, which carry the information about channel names, with no need to know the structure of the processes. What we need to add is a design NP |Q which accounts for the new element generated in the parallel composition.  Given two processes P and Q, let (+, ξ,I) and (+, ξ,J ) be the first action of, respectively, DP and DQ; then NP |Q is the following design, for N ∩ I = N ∩ J =∅ 

G[k1] ⋯ G[kn] w[x1, y1] ⋯ w[xn, yn] (+, ξ,N )
⊢ ξ
where we have {k1,..., kn}= newSP |Q, and {(x1, y1),..., (xn, yn)} = newXP |Q.
With [ ]N we denote the assignment of newSP |Q and newXP |Q to addresses introduced by the ramification N . We then consider DP ⊙ DQ ⊙ NP |Q, and build the restriction designs on this extended base design in the same way, to make interaction respect <P |Q, which is the union of the two partial orders <P ∪ <Q (no new location is generated), and XP |Q. The only new restrictions will be the ones about elements of newSP |Q and newXP |Q. The result of the operation takes the base design DP ⊙ DQ ⊙ NP |Q together with the restrictions re-built on it, to generate a behaviour by
bi-orthogonal closure; the result of this operation is denoted (BP BQ)ıı. Then, by taking the union of the assignments we get the merging of interpretations :
⟦P ⟧  ⟦Q⟧= ((BP  BQ)ıı, [ ]P ⊙Q ∪[ ]N ).
The following result is a generalization of the previous lemma:
Theorem 4.5 Let P, Q be MCCS processes. We have ⟦P ⟧  ⟦Q⟧= ⟦P ∣ Q⟧.

Subject reduction property
An explanation of the interpretation can be found by understanding process ex- ecution inside ⟦P ⟧. This can be seen through a subject reduction property. We define the reduction on ⟦P ⟧ for a given u ∈ SP as an operation that matches exe- cution →u on P , denoted ⟦P ⟧ ↝u (⟦P ⟧)u. Technically, we use an operation called trimming, that is a carefully defined projection on behaviours (originally defined in [12] and [17]), essentially a removal of a sub-ramification from the first action (+, ξ,I) of DP (operation that affects the whole behaviour, since it is built on DP ). Informally, reduction is defined by erasing a sub-ramification, thus the entire sub- designs G[x] or w[x, y], corresponding to a designed synchronization u = (al, am), called the branches associated to u: G[u], G[l] and G[m], G[x] and w[u, x] for x ∈ xor(u), and w[x, y] for y ∈ xor(x). Let K = {i,..., m} be the corresponding sub-ramification, then the first action of DP becomes (+, ξ,I ∖ K).

As a consequence, all the R(P ) will miss the same sub-designs, as well as the whole behaviour BP . There is a sort of inclusion of (⟦P ⟧)u in ⟦P ⟧ from the point of view of the possible interactions and associated executions; that is, for each in- teraction path Kł′ on (⟦P ⟧)u, there is an interaction path Kł on ⟦P ⟧ such that
the execution associated to Kł′ is either the same, or a sub-execution, of the one
associated to Kł. This second case holds if Kł′ visits G[v] for a synchronization v such that u ≼£P v – since G[u] has been erased in (⟦P ⟧)u, then execution on G[v] is directly possible, while on ⟦P ⟧, G[u] must be visited first. The first case holds, in general, since (DP )u is strictly smaller than DP , thus any interaction on (BP )u is also possible on BP . Note that the restrictions corresponding to the elements associated to u automatically disappear in the behaviour (BP )u: since the branches of these elements are erased, there are no more s and prunings in the restrictions in question, making them exactly equal to (DP )u.
The reduction on the interpretation is the operational side of our interpretation:
Theorem 4.6 Let P be a MCCS process interpreted by ⟦P ⟧. Given a synchroniza- tion u ∈ SP such that P →u P t, we have ⟦P t⟧= (⟦P ⟧)u, i.e.
P	→u	P t
□–□	□–□
⟦P ⟧ ↝u (⟦P ⟧)u

The interpretation is thus not preserved during execution, but this must be the case if we want to fully represent the dynamic of a process. Indeed we preserve the non- confluence of execution: ⟦P ⟧ keeps all the possible executions to normal forms of P . As a consequence, for some maximal execution sequences, we have:
Corollary 4.7 Let One = ⊢ ξ (+, ξ, ∅) (the design generating the behaviour that
corresponds to the linear logic multiplicative unit 1), and let P be a MCCS process:
if P →. 1 then ⟦P ⟧ ↝. {One}ıı for the same synchronization sequence.

Deadlocks
By restricting a behaviour interpreting a process P to the set of its visitable paths,
i.e. the branches of BP which are actually visited by some interaction with Bı , we obtain what is called the incarnation of a behaviour, which can give us some
important information about the process. The result can be seen as a projection on BP that erases the sub-ramification – and thus the sub-designs – never visited during interaction. We can restrict the definition to the incarnation of DP , denoted ∣DP ∣,
i.e. the branches of DP visited by some interaction, with the following consequences:
Theorem 4.8  (i) If ∣DP ∣= DP , then P is deadlock free.
(ii) If ∣DP ∣≠ DP , then the non visitable part of DP is never accessed by interaction, and its process counterpart represent the common part of all normal forms,

where no synchronizations can occur (for any execution path); moreover, P is not reducible to 1.
A process P is deadlocked if P is in normal form, P ≠ 1, and there is also a cycle in the partial order ≼£P on synchronizations; other definitions focus on the lack of communication on certain chosen occurrences of channel names (as for instance in [13]). In case (i), P is deadlock free since any part of P is potentially synchronizable (is visitable in ⟦P ⟧). We don’t know if P →. 1, but for each channel there is at least one execution path where it is synchronized with a dual, i.e. any part of P can be accessed by some execution. Thus, there are no cycles in the order ≼£P , and we can potentially communicate with any channel of P (i.e for all channels there is a synchronizing execution sequence).
In case (ii), for the correspondence between interaction and execution, if a part of DP is never visited, then there are some channels of the process that cannot be synchronized (either there is no dual, a deadlock, or the execution is blocked for some other reason) and, since each occurrence of a channel name is represented in
⟦P ⟧, we also know which these channels are. Notice that ∣DP ∣ is the only relevant design to check, since the restriction designs are modifications of DP only needed to restrain the possible interactions, and interaction-order. Thus, if an interaction visits any branch of a restriction R(⋯), then it visits the same branch on DP .
For the same correspondence, we can interpret deadlocked processes in be- haviours with no issues: the deadlocked part will just be non visitable in ⟦P ⟧. For example:

P = 1 2
3 4	5 6

a .b .Q ∣ b .c .R ∣ c .a .S

is deadlocked, with a cycle u
= (a1, a6)≼ 
u =( 2
3) ≼ 
u = (c4, c5)≼	u .



1	£P	2
b ,b 
£P	3


£P	1

On the side of ⟦P ⟧, we have restrictions which will prevent us to interact with any ui, since each G[ui] (1 ≤ i ≤ 3) have as requisite a G[l] for a location l of another synchronization in the cycle, which is not accessible as well for the same reason; therefore, there will be no orthogonal design interacting with any G[ui].

Extension to replication-free CCS: Non-deterministic Choice and Hiding
We present here the replication-free fragment of CCS, and the extension of the pre- vious results. The non-deterministic choice + (also called sum) is a mutual exclusion between its two members; it waits for an external choice, i.e. a context in parallel composition, which selects one process to use by synchronizing with the channels of one of the two members, dropping the other for that execution path. Execution is therefore generalized in the following way:



P = al.P t + bm.Qt ∣ an.P tt + o	tt →	P t ∣ P tt
From the point of view of interaction the interpretation is extended with a xor
o
condition in XP on the synchronizations on a and b, i.e u = (al, an) and v = (bm, b ).
Indeed, once we have performed execution on one, the other is excluded from the same execution path. On the other hand, both are possible until a choice is made,

and choosing one of the two synchronizations u and v, by transitivity of the partial order <P on locations, necessarily exclude from any further execution all the internal synchronizations of P t (if v is chosen) or P tt (if u is chosen) – as in event structures, where the conflict relation is hereditary w.r.t. causal implication. This is effectively described by the xor relation already present in the MCCS interpretation, that can mimic the non-deterministic choice, by extending it to members of a sum +.
The hiding operator extends the term syntax with νa(P ), also known as re- striction P /a in early texts. It declares that a channel name is bound and private inside its scope, then hidden, i.e. that cannot communicate with channels outside its scope. If P = νa(al.R) ∣ am.Q then the pair (al, am) cannot synchronize, and hence the channels would not be able to communicate. The execution rule is then considered under the scope of ν operators, up to common structural equivalence, which let push the hiding inside a process, until it reaches its maximal/minimal scope:
νa(P ∣ Q)≡ νa(P ) ∣ Q, if a ∉ fv(Q),
νa(P ) ∣ νb(Q)≡ νa(νb(P ∣ Q)) ≡ νb(νa(P ∣ Q)), if a ∉ fv(Q) and b ∉ fv(P ).
where fv notes the un-bound channels of a process. For a simple interpretation of hiding, we already have all the needed material: we restrict our definition of synchronizations so that only some pairs of dual channels are considered. We can
denote with al such a bound name; then we exclude from SP any pair (al, am) such
that only one channel is tagged, i.e. either is al or am. If both are tagged then it is
still a synchronization. This implies that inside DP and R(P ) there is no trace at all of the hiding that can occur in the process P , we can only check its presence from the static assignment [ ]P , which only tells us singularly which channels occurrences
are hidden. The result is that we forbid some interaction paths by not interpreting,
instead of resorting to more restrictions.

Replication: a reformulation in computational Ludics
To handle replication one can follow the ideas of [21] to type event structures, by considering a restricted version of the π-calculus 1 , a linear typed version of San- giorgi’s πI-calculus [19]. Such calculus has the same expressive power as the version with free name passing, and linearity only breaks for replicated outputs, but deter- minism is preserved by the uniqueness of inputs. This allow us to keep both ≼£P and locations for synchronizations, even with replication. By this way the presented tools can be applied.
Another possibility to represent replication comes from an already existing ver- sion of Ludics dedicated for this. K. Terui formulated a complementary syntax for Ludics called computational Ludics [20] (aka c-ludics), closer to higher order π-calculus, to achieve practical advantages with the general goal of developing an

1 Notice that [21] introduces such calculus to bypass the main diﬃculty to extend CCS semantics to the π-calculus: to switch from dynamic α-conversion that allows to represent the dynamic creation of a name, to a static one at typing time.

interactive theory of computability and complexity based on Ludics. The feature that seems most interesting to us is the possibility to represent infinite designs by a finite generator, allowing recursive definitions. Design generators let us easily extend the interpretation to the full calculus with replication.
Terui’s syntax is based on a signature A = (A, ar), where A is a set of names, and ar ∶ A → N is a function giving an arity to each name. A denumerable set of variables V is needed, denoted x, y, z,.. .. A positive action is either s, Ω (noting the divergence), or a, with a ∈ A; a negative action is x ∈ V , or a(x1,..., xn), with
a ∈ A and ar(a) = n. x1,..., xn are distinct variables, and —→x a denotes a vector of
variables of the arity of a. Informally, a design D is co-inductively defined by
P ∶∶= s ∣ Ω ∣ (N0 ∣ a⟨N1,..., Nn⟩),
N ∶∶= x ∣ ∑ a(—→x a).Pa.
P denotes the positive actions, N the negative actions. A name denotes both the polarity and cardinality of the ramification of a rule, and, in the negative rule, the variables stand for each sub-address of the ramification. If N0 is not a variable x in a positive design, then it becomes a cut.
A reformulation of the designs used in the translation is possible, since it holds the following:
Remark 5.1 Standard c-designs 2 (i.e. ≠ Ω, linear, cut-free and identity-free) correspond to the original designs.
Consequently, it is easy to show that using the pruning to build restriction designs can naturally be applied to c-designs. Assuming an assignment from LocP , SP , XP to names, we have the following correspondence:

G[u]= [u](xu).(xu ∣ [u.1]⟨0⟩).
	
w[u, v]= [xoru](xu).xu ∣ [xoru.1]⟨0⟩+ [xorv](xv).xv ∣ [xorv.1]⟨0⟩.
DP = x0 ∣ a⟨G[x],..., w[x, y],.. .⟩, with x varying on SP ∪ LocP , and (x, y) on XP ;
where [ ] denotes the assignment function. Interaction is called reduction, and is defined in λ-calculus style on positive c-designs with a cut, by:
(∑ a(x—→.P )∣ a —→	P —→ x—→]
where —→ is of lenght ar(a). The reduction relation select the a(x—→) that matches
N	a
with a —→ , thus assuring us that they have the same arity. Then, in the corre- sponding Pa, each variable is substituted by a negative design inside the scope of a;
reduction can then continue on P —→ x—→], until a normal form is reached (a variable
a[N / a
x or s), or it diverges (Ω). Using the reduction relation, we can rewrite example
3.1 using prunings and s easily:
D = x0 ∣ a0⟨a1(x1).x1 ∣ a11⟨0⟩, a2(x2).x2 ∣ a21⟨0⟩⟩
C = a0(x1, x2).x1 ∣ a1⟨a11(x11).x2 ∣ a2⟨a21(x21).s⟩⟩.

2 See [20], remark 2.2.

E = a0(x1, x2).x2 ∣ a2⟨a21(x21).x1 ∣ a1⟨a11(x11).s⟩⟩
D. = x0 ∣ a0⟨0p, a2(x2).s⟩.
where p denotes a pruning, and 0 the empty negative action: it denotes that the + action has a premise, but there is no further action in the branch. Both reductions C ∣ D and E ∣ D reach s after five reduction steps. Instead, only E is orthogonal to D.. To perform reduction, we must substitute x0 in D. with E, obtaining
E ∣ D. = (a0(x1, x2).x2 ∣ a2⟨a21(x21).x1 ∣ a1⟨a11(x11).s⟩⟩) ∣ a0⟨0p, a2(x2).s⟩
Reduction reach s in only 2 steps:
(a2(x2).s)∣ (a2⟨a21(x21).0p)∣ a1⟨a11(x11).s⟩⟩.
s.
Instead, the reduction
C ∣ D. = (a0(x1, x2).x1 ∣ a1⟨a11(x11).x2 ∣ a2⟨a21(x21).s⟩⟩)∣a0⟨0p, a2(x2).s⟩
at the second step diverges:
(0p)∣ (a1⟨a11(x11).s)∣ a2(x2).s ∣ a2⟨a21(x21).⟩⟩.
Ω; since 0p has no P0 and variables to perform the substitution on.
Therefore, the reformulation in c-ludics does not affect restriction designs, or the behaviour BP , and the correspondence between execution and interaction still holds. About the merging of interpretations, the operation ⊙ is simply an extension of the arity of a positive rule – or a substitution with a name of the needed arity – by putting together in the scope of this action all the negative designs that we have. Thus from D = x0 ∣ a1⟨N1,..., Nk⟩ and C = x0 ∣ a2⟨Nk+1,..., Nk+n⟩ we obtain D⊙ C = x0 ∣ a3⟨N1,..., Nk, Nk+1,..., Nk+n⟩.
Trimming, instead, require us to erase the sub-ramification associated to a certain synchronization from DP , thus reducing the arity of the first action a, and removing the corresponding negative designs (the dual operation of ⊙). A substitution to a name of the right arity might be required, but the operation itself poses no issues. When reducing DP to One, the form we obtain is One = x0 ∣ a⟨⟩ = x0 ∣ a, a positive action with a 0-ary name.
The main issue with c-ludics is that some difficulties arises when defining the assignment function, since names require modifications every time we act on DP , and variables are not absolute values. Both cases complicate the read back from ⟦P ⟧ to elements and relations of the process. This forces the assignment to be deduced from the structure of a c-design, and not be independent from it anymore, while also losing the 1 − 1 correspondence with elements of the process.

Conclusion
The interpretation of CCS into Ludics tries to overcome the problems, and satisfy the goals, that motivated our work. Its main properties are:
A logical characterization of the full dynamic of processes without imposing func- tional behaviour, resorting to multiple translations by partially determinizing ex- ecution via scheduling, or sacrificing the non-determinism or non-confluence itself (by imposing linearity and other constraints on the syntax).
A partial modularity in the interpretation, which let us combine the interpreting structures, behaviours in our case, as we do with processes via parallel com- position. We are able to represent the composition via a ludical operation on behaviours that, in the trivial case where there is no communication between two processes, exactly interpret the linear logic tensor ⊗. Otherwise, some more arti- ficial and non-ludical steps are required, by working on the assignment functions, but the core operation ⊙ is kept intact on the base designs.
Insights on the dynamics of processes, as expliciting what parallel composition entails when two process communicate, what causes forks in an execution paths, and how the different reduced forms of a process are related through their inter- pretations.
As a consequence of these properties, we have that:
subject reduction describe a particular inclusion between the interpretations of a process and of one of its reduced forms, with respect to their structures and possible interactions;
along with execution, deadlocks are also characterized. Instead of being a property of the interpretation – as it is with typing systems, where if a process is typable, then it is deadlock free – the interpretation in Ludics is oblivious of their presence, as is interaction on behaviours. Still, we have a way to know if a process is deadlock-free, or if it can’t be reduced to 1, via the visitable paths of a behaviour.
Finally, the reformulation in c-ludics [20] let us have access to non-linearity and recursive definition in the form of finite designs generators, and thus extend the interpretation to the full calculus by using the same techniques presented here.
Another point requiring further investigation is the evident strong connection with event structures, which seem naturally represented by directed behaviours, generated via restriction designs of a base one. Indeed, event structures are indirectly already represented, passing through processes, since they are a model of CCS-like calculi [22].

References
Andreoli, J., Logic programming with focusing proofs in linear logic, J. Log. Comput. 2 (1992), pp. 297– 347.
URL http://dx.doi.org/10.1093/logcom/2.3.297
Basaldella, M. and C. Faggian, Ludics with repetitions (exponentials, interactive types and

completeness), Logical Methods in Computer Science 7 (2011).
URL  https://doi.org/10.2168/LMCS-7(2:13)2011

Beffara, E., A concurrent model for linear logic, Electr. Notes Theor. Comput. Sci. 155 (2006), pp. 147– 168.
URL http://dx.doi.org/10.1016/j.entcs.2005.11.055

Beffara, E., A logical view on scheduling in concurrency, in: Proceedings Fifth International Workshop on Classical Logic and Computation, CL&C 2014, Vienna, Austria, July 13, 2014., 2014, pp. 78–92.
URL https://doi.org/10.4204/EPTCS.164.6

Beffara, E. and F. Maurel, Concurrent nets: A study of preﬁxing in process calculi, Theor. Comput. Sci. 356 (2006), pp. 356–373.
URL http://dx.doi.org/10.1016/j.tcs.2006.02.009

Beffara, E. and V. Mogbil, Proofs as executions, in: Theoretical Computer Science - 7th IFIP TC 1/WG 2.2 International Conference, TCS 2012, Amsterdam, The Netherlands, September 26-28, 2012.
Proceedings, 2012, pp. 280–294.
URL  http://dx.doi.org/10.1007/978-3-642-33475-7_20

Caires, L. and J. A. Pérez, Linearity, control eflects, and behavioral types, in: Programming Languages and Systems - 26th European Symposium on Programming, ESOP 2017, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2017, Uppsala, Sweden, April 22-29, 2017, Proceedings, 2017, pp. 229–259.
URL  https://doi.org/10.1007/978-3-662-54434-1_9

Ehrhard, T. and O. Laurent, Interpreting a ﬁnitary π-calculus in diflerential interaction nets, Inf. Comput. 208 (2010), pp. 606–633.
URL http://dx.doi.org/10.1016/j.ic.2009.06.005

Faggian, C. and M. Piccolo, Partial orders, event structures and linear strategies, in: Typed Lambda Calculi and Applications, 9th International Conference, TLCA 2009, Brasilia, Brazil, July 1-3, 2009. Proceedings, 2009, pp. 95–111.
URL  http://dx.doi.org/10.1007/978-3-642-02273-9_9
Fouqueré, C. and M. Quatrini, Study of behaviours via visitable paths, Submitted to journal (2016).
URL https://arxiv.org/abs/1403.3772v3
Girard, J., Linear logic, Theor. Comput. Sci. 50 (1987), pp. 1–102.
URL  http://dx.doi.org/10.1016/0304-3975(87)90045-4

Girard, J., Locus solum: From the rules of logic to the logic of rules, Mathematical Structures in Computer Science 11 (2001), pp. 301–506.
URL http://dx.doi.org/10.1017/S096012950100336X

Kobayashi, N., S. Saito and E. Sumii, An implicitly-typed deadlock-free process calculus, in: CONCUR 2000 - Concurrency Theory, 11th International Conference, University Park, PA, USA, August 22-25, 2000, Proceedings, 2000, pp. 489–503.
URL  https://doi.org/10.1007/3-540-44618-4_35

Milner, R., “A Calculus of Communicating Systems,” Lecture Notes in Computer Science 92, Springer, 1980.
URL  https://doi.org/10.1007/3-540-10235-3

Milner, R., J. Parrow and D. Walker, A calculus of mobile processes, I, Inf. Comput. 100 (1992), pp. 1– 40.
URL  https://doi.org/10.1016/0890-5401(92)90008-4
Milner, R., J. Parrow and D. Walker, A calculus of mobile processes, II, Inf. Comput. 100 (1992),
pp. 41–77.
URL  https://doi.org/10.1016/0890-5401(92)90009-5

Quatrini, M., “ La Ludique : une théorie de l’interaction, de la logique mathématique au langage naturel,” Habilitation à diriger des recherches, Université Aix-Marseille (2014).
URL  https://hal.archives-ouvertes.fr/tel-01234909

Rozenberg, G. and P. S. Thiagarajan, Petri nets: Basic notions, structure, behaviour, in: Current Trends in Concurrency, Overviews and Tutorials, 1986 pp. 585–668.
URL https://doi.org/10.1007/BFb0027048
Sangiorgi, D., π-calculus, internal mobility, and agent-passing calculi, Theor. Comput. Sci. 167 (1996),
pp. 235–274.
URL  http://dx.doi.org/10.1016/0304-3975(96)00075-8

Terui, K., Computational ludics, Theor. Comput. Sci. 412 (2011), pp. 2048–2071. URL http://dx.doi.org/10.1016/j.tcs.2010.12.026


Varacca, D. and N. Yoshida, Typed event structures and the linear π-calculus, Theor. Comput. Sci. 411
(2010), pp. 1949–1973.
URL http://dx.doi.org/10.1016/j.tcs.2010.01.024

Winskel, G., Event structure semantics for CCS and related languages, in: Automata, Languages and Programming, 9th Colloquium, Aarhus, Denmark, July 12-16, 1982, Proceedings, 1982, pp. 561–576.
URL https://doi.org/10.1007/BFb0012800

Winskel, G., Event structures, in: Petri Nets: Central Models and Their Properties, Advances in Petri Nets 1986, Part II, Proceedings of an Advanced Course, Bad Honnef, 8.-19. September 1986, 1986,
pp. 325–392.
URL  https://doi.org/10.1007/3-540-17906-2_31
Winskel, G. and M. Nielsen, 4, Oxford Clarendon Press, 1995.
