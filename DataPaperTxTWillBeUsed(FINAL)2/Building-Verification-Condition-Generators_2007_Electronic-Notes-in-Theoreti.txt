Electronic Notes in Theoretical Computer Science 191 (2007) 73–83	
www.elsevier.com/locate/entcs

Building Verification Condition Generators by Compositional Extension
A. J. van Leeuwen1
Department of Information and Computing Sciences Utrecht University
Utrecht, The Netherlands

Abstract
Current mechanizations of programming logics are often in the form of verification condition generators. These front ends to a prover translate a program and assertions into conditions that state that the program fulfills its assertions. Traditional verification condition generators are monolithic encapsulations of a pro- gramming language’s semantics. This makes it hard to build such verification generators when designing a new language, or when extending a language.
We propose a more compositional method of building verification condition generators, using ideas from monadic denotational semantics and from generic programming. Our technique allows us to extend an existing verification condition generator to handle new language constructs, but also to add extensions at another level, such as the ability to generate validation traces. We explain the technique through an example, extending a simple while language with a construct for exception handling. This construct not only needs an extension to the logic, but also a change of its structure.
Keywords: Hoare logic, monadic logic, programming language semantics


Introduction
Development and maintenance of implementations of realistic programming logics is known to be hard. There are few methods of dealing with the changes that are incurred by changing the language or the addition of features. Implementing these changes is a dangerous and error prone process that can easily introduce inconsistencies in the logic.
Logics underlying imperative languages are usually syntax driven and imple- mented as a recursive function over the target program [5]. Although this is a straightforward method of implementing these logics, it leads to programs that cannot be altered or extended easily.
We demonstrate a technique that enables us to change and extend the imple- mentation of a logic in a modular way, that is without directly tampering with the

1 Email: arthurvl@cs.uu.nl

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2006.08.052

Stmt → Variable := Expr
| Stmt ; Stmt
| if Expr then {Stmt } else {Stmt }
| inv Expr while Expr do {Stmt }
Figure 1. Simple imperative language L

code of the existing implementation of a logic. Our approach has several advantages. First and foremost is the advantage that it is safer. Second, it allows enabling and disabling alterations at will. Thus we can always fall back on the existing imple- mentation. Third, it enables us to easily create a set of related partial logics, each of which can be used separately for light weight verification.
Our technique uses ideas from generic programming and monadic denotational semantics to represent a syntax driven logic. Generic programming abstracts from algebraic datatypes, and these techniques can thus be used to abstract from the actual implementation of the abstract syntax used to represent programs. The main use we make is that of a generic fold, encapsulating the recursion over the datatype, which we assume to be easily specified. This allows us to decouple the recursion scheme from the calculation of the semantics.
Monadic denotational semantics has been introduced as a method of separating concerns in denotational semantics [11,1]. The key idea is to choose an abstraction for the domain of the semantics such that different computations in that domain can be combined in a standard fashion. By relying on that combination method, independence of the domain is achieved. Thus, given a monadic domain, we can hide those aspects that do not affect a specific part of the logic. This allows us to keep the code of the base logic unchanged despite adding to the underlying structure, which normally affects the implementation of each rule in the logic.

Implementing a logic
Consider the simple imperative language L shown in Figure 1. For simplicity, we assume that all statements terminate. The syntax inv i while g do S is for a simple while loop where i is a candidate invariant specified by the programmer.
We will specify a verification condition generator for the logic of this language in terms of a predicate transformer logic [3]. A predicate transformer is a function that takes a predicate and a statement in a language, and returns a predicate transformed
function takes postconditions into preconditions, such that p = pre P q ⇒ {p}P {q} according to the semantics of that statement. In the best known instantiation, this where {p}P {q} is a Hoare-triple stating that pre- and postcondition p and q are
valid for statement P . Figure 2 shows rules that specify how the value of pre can be
computed. Note that the value is only valid if the additional conditions that occur in the calculation for the while rule also hold.
This specification is syntax driven: for each production rule in the syntax, there is one rule specifying how to calculate pre. Therefore, calculating the value of pre (S) q given a statement S and a post-condition q is a matter of recurring over

pre (x := e) q = q[e/x]

pre (S1; S2) q  = pre (S1) (pre (S2) q)
pre (if g then {S1} else {S2}) q = if g then pre (S1) q else pre (S2) q p = pre (S) i
▶ i ∧ ¬g ⇒ q
▶ i ∧ g ⇒ p
pre (inv i while g do {S}) q = i
Figure 2. Derivation rules for pre for language L

the structure of S. Some rules emit extra verification conditions that should also be collected, thereby resulting in the term veriﬁcation condition generator for the implementation of pre. The straightforward implementation of such a verification condition generator computes both the precondition and collects the verification conditions. Let us name the function pvcg . Given a program s and a post-condition q , pvcg s q would return a tuple (p, vcs ) where vcs is a list of verification conditions
and p is pre (s) q. Its type therefore is pvcg :: Stmt → Expr → (Expr, [ Expr ]). An
example in the functional programming language Haskell is in Figure 3. We will
later silently reuse and extend the datatype Stmt , but not specify Expr . The logical connectives are to be read as constructors of the type Expr .
Although straightforward, such code is not easily changed. Turning it into an explicit algebra over the provided algebraic data type makes changes easier. The way to implement the algebra as a fold over the abstract syntax can be easily seen: it involves making a separate function for each alternative in the datatype representing the abstract syntax, and passing those functions as arguments to the fold. The set of passed functions clearly specifies an algebra over the language, with the nonterminals in the language being the sorts, and the alternatives inducing the operations. Applying the generic fold gives us the unique homomorphism between the initial algebra and the algebra specified.
This decouples the recursion over the syntax from the calculation of the pre- condition and the other verification conditions. Unfortunately the code then still strongly depends on the exact structure of the domain. We can improve on that.
Looking at the type of the implementation, Stmt → Expr → (Expr, [ Expr ]), we see that it takes a statement and an expression and returns a new expression,
if we ignore the fact that we also collect other verification conditions alongside the calculation. However, using monads, we can abstract from such collection.
Moggi introduced the use of monads in programming in recognizing that monads

can represent a computation over a value [11], such as the process of collecting conditions alongside transforming a predicate. Within a monadic setting, values can be injected into computations, and monadic computations can be bound together to form new computations. We denote these operations on monads with return to inject values into computations, and >>= to sequentially combine a computation over a value with a function taking that value and returning a new computation. The
type of return is return :: a → ma and that of >>= is >>= :: ma → (a → m b) → m b,
operations, return is a left- and right-identity of >>=, that is (return x ) >>= f ≡ where m a represents the type of a monad m over values of type a. In these f x and m >>= λy → return y ≡ m. Furthermore, >>= is associative, that is (m >>= f ) >>= g ≡ m >>= (λx → f x >>= g ). Most monads provide more operations than just return and >>=, but the associativity and identity laws allow us to still
combine them. The extra operations provide the functionality to collect verification conditions, for example.
We can state the implementation’s type as Stmt → Expr → m Expr , where the monad m abstractly represents the act of collecting the side conditions. Using a
fold and monads, the code for the verification condition generator looks like that in Figure 4.
We assume a function record that records verification conditions in values of type m (), that is, of a monad over the unit type. By using the abstract sequential combination of computations as opposed to explicit threading of values, we need not specify the exact monad m. We merely need the associativity of subsequent record computations.
The structure of the functions defined in the example is simple. For each con- structor in the datatype Stmt we have a function that, given the predicate trans- formers for recursive occurrences of Stmt and the other arguments to the construc-
data Stmt = String := Expr	-- Variable := Expr
| Stmt :> Stmt	-- Stmt ; Stmt
| IfElse Expr Stmt Stmt	-- if Expr then {Stmt } else {Stmt }
| While Expr Expr Stmt	-- inv Expr while Expr do {Stmt }
pvcg ' :: Stmt → Expr → (Expr, [ Expr ])
pvcg ' (x := e)	q	= (subst (x , e) q, [ ])
pvcg ' (s1 :> s2 )	q	= (p, vcs2 ++ vcs1 )
where	(p', vcs2 ) = pvcg ' s2 q
(p, vcs1 )	= pvcg ' s1 p'
pvcg ' (IfElsee s1 s2 ) q	= (e → s1q ∧¬ e → s2q , vcs1 ++ vcs2 )
where	(s1p, vcs1 )= pvcg ' s1 q
(s2p, vcs2 )= pvcg ' s2 q
pvcg ' (While i g body ) q	= (i , c1 : c2 : vcs')
where	c1	= i ∧¬ g → q
c2	= i ∧ g → p
(p, vcs')	= pvcg ' body i
Figure 3. Simple implementation of rules in Figure 2

pvcg Assign x e	= λq → return (subst (x , e) q )
pvcg Seq p s1 p s2	= λq → p s2 q >>= λp' →
p s1 p' >>= λp →
return p
pvcg IfElse g p s1 p s2 = λq → p s1 q >>= λp →
p s2 q >>= λp' →
return (g → p ∧¬ g → p') pvcg While i g p body	= λq → p body i >>= λp →
record (i ∧¬ g → q ) >>= λ →
record (i ∧ g	→ p) >>= λ →
return i
pvcg = f oldStmt (pvcg Assign,
pvcg Seq , pvcg IfElse, pvcg While)
Figure 4. Folded monadic implementation of a vcg for L


tor, returns a function of type Expr → m Expr . Each function is composed of computations in a monad, bound together with >>=. As the right-hand argument
of >>= is a function taking a value and returning a computation, we explicitly state λ-abstractions. In some cases the value is not interesting, such as in the monads resulting from record . The notation λ is for binding to a value but immediately
example is either Expr → m Expr or () → m Expr , with the latter only for the discarding it. The type of the λ-abstractions on the right-hand sides of >>= in the λ-abstractions that discard their binding.
Note that although the code is not shorter, the structure of the rules in Figure 2 is more closely followed, and there is less visible administrative overhead. Also
note that we could have written pvcg Seq p s1 p s2 = λq → p s2 q >>= p s1 , which means the same, but hides that the result of the computation of p s2 is fed into
p s1 , whose result is then returned.

Modifying a logic
Modifying a straightforward implementation as a recursive function involves chang- ing the entire function. Modifying the implementation in Figure 4 involves changing only those functions affected. Furthermore, as we abstract from the structure of the domain in Figure 4, it is possible to change that independently.
constructs raise and try {Stmt } catch {Stmt }. This involves adding appropriate Suppose we add exception handling to our language by adding the syntactical alternatives to the Stmt datatype, and the need to write new rules to handle these
new constructs. As the generic fold is independent of the exact alternatives present in the datatype, we need not rewrite it. We assume that expressions do not in themselves raise exceptions.
Now, if we naively impose that no valid program may execute raise, we can

pvcg Raise'	= λq → return false pvcg TryCatch' p s1 p s2 = λq → p s1 q
pvcg = f oldStmt (pvcg Assign,
pvcg Seq , pvcg IfElse, pvcg While, pvcg Raise',
pvcg TryCatch')
Figure 5. Initial extension of pvcg from L to L1

simply take the precondition of a try {s1 } catch {s2 } block to be that of s1 . The resulting logic is implemented in Figure 5.
This naive code is not entirely satisfactory, but it already shows reuse of the existing code. A more satisfactory logic actually allows exceptions, not only their syntax, and handles them. This requires making a distinction between the postcon- dition for normal execution, and the postcondition for exceptional execution, and a method of specifying both. Figure 6 shows a set of derivation rules to be used for the extended language. It changes the predicate transformer so that it does not just take predicates, but tuples of predicates, one for the postcondition for normal exe- cution and one for the postcondition for exceptional execution. In this specification of the derivation rules adding exception handling changes all previously existing rules. This is precisely what we wish to avoid.
Our technique can do that, with ease! Assume our computational monad m not only records verification conditions, but also stores the current postcondition for the exceptional case, with functions getPostE and setPostE to access that post- condition. Then we can write our verification condition generator as in Figure 7. As can be seen, we have needed no additional changes to the existing code at all, even though we have changed the domain. Note that adding the possibility for expressions to raise an exception involves adding invocations to getPostE in the appropriate places, but that such changes cannot be avoided.

Constructing the domain
We have left the method of specifying the monad encapsulating the domain implicit. One way of specifying this monad is by directly choosing one. In our example, we need a monad that allows us to record predicates, and that keeps a distinct state. A direct specification of such a monad can be found in Figure 8. It specifies exactly the operations we need, and can be substituted for the monad m in both Figure 4 and 7. The new type RecExc a is specified as a tuple consisting of a list of expressions, an expression and a value of type a. The additional constructor is a technical requirement allowing one to distinguish the type RecExc a from the type ([ Expr ], Expr, a). For this type RecExc a the functions return and >>= are then defined. As >>= is an infix operator, it is enclosed in parentheses for the prefix definition.

Although this works, it involves replacing the entire monad upon changes. Much nicer would be the ability to just add aspects to the existing monad. Traditional approaches of combining monads are the use of distributive laws over monads [7] or the use of monad transformers [4,10]. We have chosen to use another approach, that of monadic coproducts, as described by Luth and Ghani [9].
A monad can be thought of as a computational layer over a certain value. If we want to combine computational actions from different monads, we can put multiple computational layers over a value. However, when choosing one particular layering of monads for the combined monad, in general one cannot directly find the >>= function. In a monadic coproduct we do not choose one particular layering but rather all possible layerings of two monads. Unfortunately, this denotes a largely redundant computational structure, as one is interested in computational actions rather than in layers of possible computational actions. The trick is to identify the actual computational actions, and quotient the coproduct’s structure so that each actual computational action is only represented once in the coproduct.
Formally, the coproduct m ⊕ n of two monads m and n is just the coproduct in the category of monads. The coproduct has these useful properties: there are
pre (x := e) (q, q') = (q[e/x], q')

pre (S1; S2) (q, q') = (pre (S1) (pre (S2) q), q')
pre (if g then {S1} else {S2}) (q, q') = (if g then pre (S1) q else pre (S2) q , q') p = pre (S) i
▶ i ∧ ¬g ⇒ q
▶ i ∧ g ⇒ p
pre (inv i while g do {S}) (q, q') = (i, q')
pre (raise) (q, q') = (q', q')

p = pre (S1) (q, p')
p' = pre (S2) (q, q')
pre (try {S1} catch {S2}) (q, q') = (p, q')
Figure 6. Derivation rules for pre for extended language

pvcg Raise	= λq → getPostE
pvcg TryCatch p s1 p s2 = λq → getPostE >>= λq ' →
p s2 q >>= λp' → setPostE p' >>= λ → p s1 q >>= λp → setPostE q ' >>= λ → return p
pvcg = f oldStmt (pvcg Assign,
pvcg Seq , pvcg IfElse, pvcg While, pvcg Raise ,
pvcg TryCatch )
Figure 7. Full pvcg for L1 using code from L


inl and inr taking m respectively n into m ⊕ n, and for any other monad r and monad morphisms, natural transformations commuting with return and bind , called two given monad morphisms α : m → r and β : n → r there is a unique monad morphism coproduct (α, β): m ⊕ n → r such that
coproduct (α, β) ◦ inl = α and coproduct (α, β) ◦ inr = β.
To actually construct a monadic coproduct, one needs finitary layered monads,
that is monads for which the behaviour on infinite objects is determined by its behaviour on finite objects, and for which it is possible to determine if the monadic value is in the range of the return function. The latter requirement allows us to distinguish between layers in which an action has been performed and layers which can be safely ignored, and therefore allows us to actually calculate the required quotient. Fortunately, many practical monads have these properties.
Given two finitary layered monads, we specify the coproduct as a datatype encapsulating the monads separate from the values under the monads. That is, two monads m and n can be added together to form a coproduct Plus m n that is defined as
data Plus m n a = PlusM (m (Plus m n a))
| PlusN (n (Plus m n a))
| PlusVar a
newtype RecExc a = RecExc ([ Expr ], Expr, a)
return x	= RecExc ([ ], tt , x )
(>>=) (RecExc (xs, p, v )) f  = RecExc (xs ++ ys, p, v ')
where (RecExc (ys, p', v ')) = f v
record p	= RecExc ([ p ], tt , ()) getPostE (RecExc (xs, p, v )) = RecExc (xs, p, p) setPostE p	= RecExc ([ ], p, v )
Figure 8. A monad allowing recording and exceptional state operations

newtype Record a = Record ([ Expr ], a)
return x	= Record ([ ], x )
(>>=) (Record (xs , x )) f	= Record (xs ++ ys, y )
where (Record (ys, y )) = f x
record p	= Record ([ p ], ())
Figure 9. A simple recording monad
newtype PostE a = PostE (a, Expr ) return x	= PostE (a, tt ) (>>=) (PostE (x , e)) f	= PostE (y, e)
where (PostE (y, e')) = f y
getPostE (PostE (x , e)) = PostE (e, e)
setPostE e	= PostE ((), e)
Figure 10. A monad encapsulating a second postcondition

and in this monad a single layer of a monad m over a value a would be represented using PlusM (m (PlusVar a)). For more details as to how to calculate the quotient or implement the coproduct function, see the paper by Luth and Ghani [9].
Suppose that we have the monad in Figure 9. This monad is finitary. It also is layered, as a monadic value is in the range of return if and only if the list of recorded expressions is empty. It provides a method of capturing side conditions, but not an exceptional postcondition. If we now take Plus Record Identity to be our monad,
we can see that λp → inl ◦ record p forms the required operation corresponding to
the occurrence record in Figure 4.
As we mentioned before, for a satisfactory semantics of the exception handling construct we added, we need to add a method of recording the exceptional postcon- dition. To do so, we take another monad, as in Figure 10. This monad is also finitary and layered. Filling in that monad in the place of Identity in the previous coproduct
gives us Plus Record PostE . With this monad the operations inr ◦ getPostE and
λe → inr ◦ setPostE e correspond to the required getPostE and setPostE in Figure
7. Furthermore, the existing operation for record is still valid.
The problem that remains is that of choosing a monad r that we map the operations on Record and PostE to. This monad r is the essential domain of the semantics. In this case we can use a general state carrying monad, with as state a tuple of expressions and an expression, that is State ([ Expr ], Expr ). This monad has functions get and put , where get extracts the state from the monad, and put takes the state and puts it back under a monad over the unit type. Their
types are get :: State ([ Expr ], Expr ) ([ Expr ], Expr ) and put :: ([Expr ], Expr ) →
functions alpha and beta we get coproduct alpha beta :: Plus Record PostE a → State ([ Expr ], Expr ) (). The mapping is given in Figure 11. From the given State ([ Expr ], Expr ) a, which allows us to interpret the values created in the co-
product monad within the chosen essential domain of the semantics. Note that alpha and beta can be defined independently of each other.

type Domain e = Plus Record PostE e
alpha (Record (xs, p)) = get >>= put ◦ (λ(ys , q ) → (ys ++ xs, q ))
beta (PostE (p, e))	= get >>= put ◦ (λ(ys , q ) → (ys, e))
Figure 11. Combining Record and PostE
Research direction
Given this implementation method for verification condition generators, several re- search paths remain. Not only do we want a more compositional way of implement- ing a verification condition generator, we also want to formally verify said generator, as for example Homeier and Martin described [5]. One hypothesis we have inves- tigated is that our approach makes it possible to not only reuse existing code, but also to reuse proofs so that proving e.g. soundness for a changed verification con- dition generator need not be done from scratch. This does indeed seem possible for a simple language, given more care in constructing the underlying monad than exposed in section 4. The question remains if this scales to languages with function abstraction and application.
Another research path is that of combining this method of specifying a logic with the existing methods of building monadic interpreters and compilers, so that when designing a language one can declaratively specify syntax and semantics, and get a complete implementation of the language, including a sound proof system, for free.

Related Work
The usefulness of monads for programming language semantics was already realized by Moggi and Cenciarelli [11,1], and then expanded upon by Espinosa, Liang and Hudak [4,8]. Monads were applied to proving properties over programs by Jacobs and Poll [6] and more recently by Schro¨der and Mossakowski [13].
Jacobs and Poll specify only the essential monad in which to interpret the se- mantics of Java, solving the problem that we discuss in the beginning of section 4 in the direct fashion. They do not specify how to deal with changes to the language however.
Our approach differs from the one by Schr¨oder and Mossakowski in that instead of specifying a logic that is independent of the underlying monad, we use the monad to implement a logic. That is, our logic is built using monadic actions, and therefore the reasoning in the logic depends heavily on the exact monad used, whereas the logic of Schro¨der and Mossakowski is parameterized on the monad, and reasoning is valid in all possible monads.
The use of algebras and folds in our approach is reminiscent of attribute gram- mars [12]. For our purposes we would need a method of introspection on the gram- mar rules, so that we can perform the modifications that we described. The first class attribute grammars by De Moor, Backhouse and Swierstra [2] may well fit the bill. The methods of composing these grammars also suggests another approach to

specifying the semantics.

Conclusion
We have shown a novel technique to deal with extensions to the implementation of a verification condition generator. This technique provides for a method of mod- ular development of the verification condition generator in the face of changing requirements. Experiments have shown that the technique works.

References
Cenciarelli, P. and E. Moggi, A syntactic approach to modularity in denotational semantics, in: CTCS 5 (1993).
de Moor, O., K. Backhouse and S. D. Swierstra, First class attribute grammars, Informatica: An
International Journal of Computing and Informatics 24 (2000), pp. 329–341, special Issue: Attribute grammars and Their Applications.
Dijkstra, E. W. and C. S. Scholten, “Predicate Calculus and Program Semantics,” Texts and Monographs in Computer Science, Springer Verlag, Berlin, 1990.
Espinosa, D., “Semantic Lego,” Ph.D. thesis, Columbia University (1995).
Homeier, P. V. and D. F. Martin, Trustworthy tools for trustworthy programs: A verified verification condition generator, in: TPHOLS 1994, number 859 in LNCS (1994), pp. 269–284.
Jacobs, B. and E. Poll, A monad for basic java semantics, in: T. Rus, editor, AMAST 2000, number 1816 in LNCS (2000), pp. 150–165.
King, D. J. and P. Wadler, Combining monads, in: J. Launchbury and P. M. Sansom, editors, Proceedings of the Glasgow Workshop on Functional Programming, Workshops in Computing Series (1992).
Liang, S., P. Hudak and M. Jones, Monad transformers and modular interpreters, in: POPL’05 (1995),
pp. 333–343.
Lu¨th, C. and N. Ghani, Composing monads using coproducts, in: ICFP’02 (2002), pp. 133–144.
Moggi, E., An abstract view of programming languages, Technical Report ECS-LFCS-90-113, University of Edinburgh (1989).
Moggi, E., Computational lambda-calculus and monads, in: LICS’89, IEEE Computer Society Press, Washington, DC, 1989 pp. 14–23.
Paakki, J., Attribute grammar paradigms — a high-level methodology in language implementation, ACM Computing Surveys 27 (1995), pp. 196–255.
Schr¨oder, L. and T. Mossakowski, Monad-independent dynamic logic in hascasl, Journal of Logic and Computation 14 (2004), pp. 571–619.
