	Electronic Notes in Theoretical Computer Science 177 (2007) 153–168	
www.elsevier.com/locate/entcs

Implementing Dynamic-Cut in T OY 1
R. Caballero2	Y. Garc´ıa-Ruiz3
Departamento de Sistemas Informa´ticos y Programaci´on Universidad Complutense de Madrid
Madrid, Spain

Abstract
This paper presents the integration of the optimization known as dynamic cut within the functional-logic system T OY . The implementation automatically detects deterministic functions at compile time, and includes in the generated code the test for detecting at run-time the computations that can actually be pruned. The outcome is a much better performance when executing deterministic functions including either or-branches in their definitional trees or extra variables in their conditions, with no serious overhead in the rest of the computations. The paper also proves the correctness of the criterion used for detecting deterministic functions w.r.t. the semantic calculus CRWL.
Keywords: determinism, functional-logic Programming, program analysis, programming language implementation.


Introduction
Nondeterminism is one of the characteristic features of Logic Programming shared by Functional-Logic Programming. It allows elegant algorithm definitions, increas- ing the expressiveness of programs. However, this benefit has an associated draw- back, namely the lack of efficiency of the computations. There are two main reasons for this:
The complexity of the search engine required by nondeterministic programs, which slows down the execution mechanism.
The possible occurrence of redundant subcomputations during a computation.
In the Logic Programming language Prolog, the second point is partially solved by introducing a non-declarative mechanism, the so-called cut. Programs using cuts are much more efficient, but at the price of becoming less declarative.

1 This work has been funded by the projects TIN2005-09207-C03-03 and S-0505/TIC/0407.
2 Email: rafa@sip.ucm.es
3 Email: ygruiz@gmail.com

1571-0661 © 2007 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2007.01.009

In the case of Functional-Logic Programming the situation is somehow alleviated by the demand driven strategy [2,8], which is based on the use of deﬁnitional trees [1,8]. Given any particular program function, the strategy uses the structure of the left-hand sides of the program rules in order to reduce the number of redundant subcomputations. The implementation of modern Functional-Logic languages such as T OY [9] or Curry [6] is based on this strategy. Our proposal also relies on the demand driven strategy, but introduces a safe and declarative optimization to further improve the efficiency of deterministic computations. This optimization is the dynamic cut, first proposed by Rita Loogen and Stephan Winkler in [10]. In [4,3] the same ideas were adapted to a setting including non-deterministic functions and a demand driven strategy, showing by means of examples the efficiency of the optimization.
However, in spite of being well-known and accepted as an interesting opti- mization, the dynamic cut had not been implemented in any real system up to now. In this paper we present this implementation in the functional-logic system T OY (available at http://toy.sourceforge.net).
The dynamic cut considers two special fragments of code:
Rules with existential variables in the conditions.
Sets of overlapping rules occurring in deterministic functions.
As we will explain in section 3, computations involving these fragments of code can be safely pruned if certain dynamic conditions are fullfilled.
A key point of the optimization is detecting deterministic functions. The infor- mation about deterministic functions is required not only at compile time but also at run-time, when it is used for checking dynamically if the cut must take place in a particular computation. As previous works [10,4,3] have shown, this dynamic test is necessary for ensuring the correctness of the cut, i.e. that the optimization does not affect the set of solutions of any goal.
The determinism analysis performed by the system follows the well-known cri- terion of non-ambiguity already introduced in [10]. From the theoretical point of view, the novelty of this paper w.r.t. previous work is that we have proved formally the correctness of such a criterion w.r.t. the semantic calculus CRWL, proposed as suitable logic foundation for Functional-Logic Programming in [5]. Of course, com- pleteness cannot be established because determinism is an undecidable property [13]. For that reason we also allow the user to annotate explicitly some functions as deterministic.
The paper is organized as follows. The next section introduces the non-ambiguity criterion for detecting deterministic functions and the correctness theorem. Section 3 shows by means of examples the cases where the optimization will be applied. Section 4 presents the steps followed during the implementation of the dynamic cut in T OY, and Section 5 finalizes presenting some conclusions.

Detecting	Deterministic	Functions	in	Functional- Logic Programs
This section proves the correctness of the non-ambiguity condition used for detecting deterministic functions w.r.t. the semantic calculus CRWL [5].

The CRWL calculus
CRWL is an inference system consisting of six inference rules:

BT Bottom:


e → ⊥ 
RF Reflexivity:


X → X

e1 → t1 .. . em → tm
DC Decomposition
c e1 ... em → c t1 .. . tm
c ∈ CDn ∪ FSn+1, m ≤ n, ti ∈ CTerm⊥

FA Function Application: e1 → t1 ... , en → tn C  r → a	a a1 .. . ak → t
f e1 .. . en a1 ... ak → t

(k ≥ 0)




JN Join:
if	t /= ⊥,  (f t1 .. . tn → r ⇐ C) ∈ [R]⊥
e1 → t  e2 → t
t ∈ CTerm
e1 == e2

The notation [R]⊥ In rule FA represents the set of all the possible instances of pro- gram rules, where each particular instance is obtained from some function defining rule in R, by some substitution of (possibly partial) terms in place of variables. See
[5] for a detailed description of this and related calculi.

Deterministic Functional-Logic Functions
Before defining and characterizing deterministic functions we need to establish briefly some basic notions and terminology. We refer to [5] for more detailed defi- nitions. We assume a signature Σ= ⟨DC, FS⟩, where DC and FS are ranked sets of constructor symbols resp. function symbols. Given a countably infinite set V of variables, we build CTerms (using only variables and constructors) and Terms (using variables, constructors and function symbols). We extend Σ with a special nullary constructor ⊥ (0-arity constructor) obtaining a new signature Σ⊥ and we will write T erm⊥ and CTerm⊥ (partial terms) for the corresponding sets of terms in this extended signature.
A T OY program P is composed of data type declarations, type alias, infix op- erators, function type declarations and a set of defining rules for functions symbols. Each defining rule for a function f ∈ FS has a left-hand side,a right-hand side and

a optional condition:	f t1 .. . tn
lef|t-ha{nzd si}de
→	r
right-h|{azn}d side
⇐	C
con|d{zit}ion

where t1 ... tn must be linear Cterms and C must consist of finitely many (possibly zero) joinability statements e1 == e2 with e1, e2 ∈ T erm. A natural approximation ordering ± for partial terms can be defined as the least partial ordering over T erm⊥ satisfying the following properties:
⊥± t, for all t ∈ T erm⊥

X ± X, for all variable X
if t1 ± s1, ..., tn ± sn, then c t1 ... tn ± c s1 ... sn, for all c ∈ DCn and ti, si ∈
CTerm⊥.
A partially ordered set (poset in short) with bottom is a set S equipped with a partial order ± and a least element ⊥ (w.r.t. ±). D ⊆ S is a directed set iff for all x, y ∈ D there exists z ∈ D such that x ± z, y ± z. A subset A ⊆ S is a cone, iff ⊥ ∈ A and for all x ∈ A, y ∈ S y ± x ⇒ y ∈ A. An ideal I ⊆ S is a directed cone. The program semantics is defined by the semantic calculus CRWL presented in [5].	CRWL (Constructor Based ReWriting Logic) is a theoretical framework for the lazy functional logic programming paradigm. Given any program P , CRWL proves statements of the form e → t with e ∈ T erm⊥ and t ∈ CTerm⊥. We denote by P ▶CRWL e → t that the statement e → t can be proved in CRWL w.r.t. P . The intuitive idea is that t is a valid approximation of e in P. The denotation of any e ∈ T erm⊥, written [e]], is defined as: [[e]] = {t ∈ CTerm⊥ | P ▶CRWL e → t}.
Now we are ready for presenting the formal definition of deterministic function in our setting.
Definition 2.1 (Deterministic Functions)
Let f be a function defined in a program P. We say that f is a deterministic function iff [f tn ] is an ideal for every tn s.t. ti is a CTerm⊥ for all i = 1 ... n.
We call a function non-deterministic, if it does not fulfill the previous definition. The intuitive idea behind a deterministic function is that it returns at most one re- sult for any arbitrary ground parameters [7]. In addition, in a lazy setting whenever a function returns some value t, it is expected to return all the less defined terms s ± t as well. The previous definition of deterministic function takes this idea into account. Consider for instance the following small program:
data pair = pair int int	f 1 = pair 1 2	g 1 = 1	g 1 = 2
Using CRWL it can be proved that [f 1]] = {⊥, pair ⊥ ⊥, pair 1 ⊥, pair ⊥ 2, pair 1 2}, [[f t]] = {⊥} if t /= 1, [g 1]] = {⊥, 1, 2}, [[g t]] = {⊥} if t /= 1. Then g is a non-deterministic function because for the parameter 1 the set {⊥, 1, 2} is not an ideal, in particular because it is not directed: taking x = 1,y = 2 it is not possible to find z ∈ {⊥, 1, 2} s.t. x ± z, z ± 2. On the other hand, it is easy to check that f is a deterministic function.
Non-ambiguous functions
The definition 2.1 is only a formal definition and cannot be used in practice. In
[4] an adaptation of the non-ambiguity condition of [11] is presented, which we will use as an easy mechanism for the effective recognition of deterministic functions. Although not all the deterministic functions are non-ambiguous, the non-ambiguity criterion will be enough for detecting several interesting deterministic functions.
Definition 2.2 (Non-ambiguous functions)
Let P be a program defining a set of functions G. We say that F ⊆ G is a set of

non-ambiguous functions if every f ∈ F verifies:
If f t¯n = e ⇐ C is a defining rule for f , then var(e) ⊆ var(t¯) and all function symbols in e belong to F .
For any pair of variants of defining rules for f , f t¯n = e ⇐ C, f t¯'n = e' ⇐ C', one of the following two possibilities holds:
Left-hand sides do not overlap, that is, the terms (f t¯n) and (f t¯'n) are not
unifiable.
If θ is the m.g.u. of f t¯n and f t¯'n, then eθ ≡ e'θ.
In [3,4] the inclusion of the set on non-ambiguous functions in the set of deterministic functions was claimed. Here, and thank to the previous formal definition, we will be able to prove the result.
Before that we need some auxiliar lemmata. The proofs of these results are tedious but straightforward using induction on the structure of the CRWL-proofs and are not included for the sake of the space. The first two lemmata establish substitution properties that will play an important role in the proof. The lemmata use the symbol CSubst for the set of all the c-substitutions, which are mappings θ : V → CTerm, and the notation CSubst⊥ for the set of all the partial c-substitutions θ : V → CTerm⊥ defined analogously. We note as tθ the result of applying the substitution θ to the term t.
Lemma 2.3  Let t ∈ CTerm, s ∈ CTerm⊥ be such that t ± s. There there exists a substitution θ ∈ CSubst⊥ verifying tθ = s.
Lemma 2.4  Let t, t' ∈ CTerm be such that: 1) t, t' are linear, 2) var(t)∩var(t')= 
∅ and 3) There exists γ = m.g.u.(t,t’). Let s ∈ Cterm⊥ be a term and θ, θ' ∈ CSubst⊥ such that tθ ± s, t'θ' ± s. Then there exists a substitution θ'' s.t. tγθ'' = t'γθ'' = s.
Lemma 2.5  Let P be aprogram and e ∈ T erm⊥. Then:
Let t, t' ∈ CTerm⊥ be such that P ▶CRWL e → t and t' ± t. Then P ▶CRWL
e → t'.
Let P be a program and e ∈ T erm⊥ and θ ∈ CSubst⊥ be s.t. P ▶CRWL eθ → t. Then P ▶CRWL eθ' → t for all θ' s.t. θ ± θ'.
Let e¯n s.t. ei ∈ T erm⊥ for all i = 1 ... n, and s.t. P ▶CRWL e e¯n → t, and
a ∈ T erm⊥ such that e ± a. Then P ▶CRWL a e¯n → t.
[[e]] is a cone.
Now we are ready to prove that non-ambiguous functions are deterministic.
Theorem 2.6 . Let P be a program and f be a non-ambiguous function deﬁned in
P. Then f is deterministic.
Proof. In order to check that f is a deterministic function, we must prove that [[f t¯n ] is an ideal, i.e.:
- [[f t¯n ] is a cone by lemma 2.5 item iv).

- [[f t¯n ] is a directed set. We prove a more general result: Consider e ∈ T erm⊥ and suppose that all the function symbols occurring in e are correspond to non-ambiguous functions. Then, [[e]] is a directed set.
Let be. t, t' ∈ Cterm⊥ verifying (R1) : P ▶CRWL e → t and (R2) : P ▶CRWL e → t'. We prove that exists s ∈ Cterm⊥ s.t.: a) t ± s, b) t' ± s and c) P ▶CRWL e → s by induction on the depth l of a CRWL -proof for e → t:
l = 0. Three possible CWRL-inference rules:
BT. Then t = ⊥ and defining s = t' we have: a) ⊥ ± s, b) t' ± s and c)
P ▶CRWL e → s (by (R2)).
RF. Then the proof for (R1) must be of the form X → X, and hence e = X and t = X. Then t' only can be X or ⊥ (otherwise no CRWL inference could be applied and (R2) would not hold). We define s as X and then: a) t ± X b) t' ± X c) P ▶CRWL e → s by (R1).
DC. Then e = c, t = c, with c ∈ DC0. Then t' must be either c or ⊥. In any case defining s as c the result holds.
l > 0 There are three possible inference rules applied at the first step of the proof:
DC. Then e = c e1 ... em, t = c t1 ... tm with c ∈ DCn ∪ FSn+1, m ≤ n. Analogously t' = c t1 ... tm and the first inference rules of any proof for (R1) y (R2) must be of the form:

(R1) :
e1 → t1 .. . em → tm c e1 ... em → c t1 .. . tm
e1 → t' .. . em → t'
(R2) :
c e1 .. . em → c t .. . t

1	m
The proofs for P ▶CRWL ei → ti and P ▶CRWL ei → t' have a maximum depth of l − 1. Therefore by induction hypotheses exists si ∈ Cterm⊥ satisfying ti, t' ± si, and P ▶CRWL ei → si for all 1 ≤ i ≤ m. Then defining s = c s1 ... sm, t ± s, t' ± s hold and P ▶CRWL e → s with a proof starting with a DC inference.
JN. Very similar to the previous case.
AF. Then e is of the form f e¯n with ei ∈ CTerm⊥ for i = 1 ... n. Moreover n is greater of equal to the program arity of f . Hence an AF inference must have been applied at the first step of any proof of (R2). In each case a suitable instance (I1) y (I2) must have been used. We call θ and θ' to the substitutions associated to the first and to the second instance respectively, θ, θ' ∈ CSubst⊥.
The first inference step of each proof will be of the following form:


(1) :
e1 → t1θ, . . . , ek → tkθ, Cθ, rθ → a, a ek+1 .. . en → t f e1 .. . ek ek+1 .. . en → t
e1 → t' θ', . .., ek → t' θ', C'θ', r'θ' → a', a' ek+1 .. . en → t'

(2) :	1
k
f e1 ... ek ek+1 .. . en → t'

with (k > 0), t, t' /= ⊥ and the rule instances:
I1: (f t1 ... tk → r ⇐ C)θ ∈ [R]⊥	I2: (f t'

... t'

→ r' ⇐ C')θ' ∈ [R]⊥

Now we consider separately two cases: a) I1 e I2 correspond to the same program rule, and b) each instance correspond to a different program rule. The first case is easy to check and does not rely on the non-ambiguity criterion. For the sake

of the space we only include the proof of the case b).
Assume that I1, I2 are instances of two different program rules. By the non-ambiguity criterion there exists γ=m.g.u. (f t¯k ,f t¯'k), i.e. tiγ = t'γ for
i = 1 ... k and rγ = r'γ. Calling ui to tiγ = t'γ, the rule instances can be seen as: (f u1 ... uk → r'' ⇐ Cγ) and (f u1 ... uk → r'' ⇐ C'γ). Now we must look for some s ∈ CTerm⊥ such that: a) t ± s, b) t' ± s and c) P ▶CRWL f e¯n → s for some substitution θ''. The proof of c) can be of one of these two forms
e1 → u1θ'', . . . , ek → ukθ'', Cγθ'', r''θ'' → a'', a'' ek+1 ... en → s

(4) :

(5) :


f e1 ... ek ek+1 ... en → s
e1 → u1θ'', . . . , ek → ukθ'', C'γθ'', r''θ'' → a'', a'' ek+1 .. . en → s f e1 .. . ek ek+1 ... en → s

We observe that γ unifies the heads and fusions the right-hand sides, but it doesn’t relation C y C'. We consider the form (4) (the (5) is analogous). From the premises of (1) y (2) we know that P ▶CRWL ei → tiθ and P ▶CRWL ei → t'θ' for i = 1 ... k. By induction hypotheses exists si ∈ CTerm⊥ s.t.: a)tiθ ± si, b)
t'θ' ± si, and c) P ▶CRWL ei → si. Since ti, t' are unified by γ, we can apply
i	i
the Lemma 2.4. Then there exist substitutions θi which we can restrict to the variables in ui s.t. uiθi = si. (u1,... , uk) is a linear tuple because (t1,... , tk)
and (t' ,... , t' ) are both linear. Then we can define a substitution θ'' as:



θ''
1
(X) = 
k
θi(X) if X ∈ var(ti, t' ) for some i, 1 ≤ i ≤ k θ(X) otherwise

ensuring that there exist CRWL -proofs of ei → uiθ'' for all i = {1,... , k} in (4) (this is because uiθi = uiθ'').
Checking that rest of the premises of (4) also have CRWL -proof requires similar arguments.



The non-ambiguity condition characterizes a set of functions F as deterministic. This is because the value of a function may depend on other functions, and in general this dependence can be mutual. In practice the implementation starts with an empty set F of non-ambiguous functions, adding at each step to F those functions that satisfy the definition and that only depend on functions already in F . This is done until a fix-point for F is reached.
Although most of the deterministic functions that occur in a program are non- ambiguous as well, there are some functions which are not detected. This happens for instance in the function f of following example: f 1 = 1  f 1 = g 1  g 1 = 1. It would be useful to use additional determinism criteria, such as those based on abstract interpretation proposed in [12], but the detection of deterministic function will be still incomplete. For that reason the system allows the programmer to distinguish deterministic functions annotating them by using --> instead of =, as in the following example:  f 1 --> 1  f 1 --> g 1   g 1 = 1,
which indicates that f is deterministic. The non-annotated functions like g will be analyzed following the non-ambiguity criterion.


	
Fig. 1. Two methods for multiplying


	


multi (toNat X) (toNat Y)
odd (power zero (toNat N))
without dynamic cut
odd (power zero (toNat N))
with dynamic cut

Fig. 2. Comparative tables

Pruning Deterministic Computations
In this section we present briefly the two different situations where the dynamic cut can be introduced.

Deterministic Functions Deﬁned through Overlapping Program Rules
Sometimes deterministic functions can be defined in a natural way by using over- lapping rules. Consider for instance the two programs of Figure 1. Both programs contain functions for computing arithmetic using Peano’s representation. The func- tion toNat is used for easily converting positive numbers of type int to their Peano representation. The only difference between P1 and P2 is the method for multiply- ing numbers. The function multi at P2, which we have called ’classical’ reduces the first argument before each recursive call until it becomes zero. The method multi of P1, which we have called ’parallel’, reduces both arguments before the recursive call. Observe that the first two rules of multi in P1 are overlapping. However it is easy to check that it is a non-ambiguous and hence a deterministic function.

The first table at Figure 2 shows the time 4 required for computing the first answer for goals of the form multi (toNat X) (toNat Y) == R in both programs.
The symbol means that the system has run out of memory for the goal. From this data it is clear that the parallel multi of P1 behaves better than its classical counterpart of P2. The reason is that in P1 the computation of multi reduces the two arguments simultaneously saving both time and space. However this kind of ’parallel’ definition is not used very often in Functional-Logic Programming because programmers know that overlapping rules can produce unexpected behaviors due to the backtracking mechanism. Indeed using P1 a goal like multi zero zero == R has two solutions, both giving R the value zero, instead of only one as expected (and as the program P2 does). Such redundant computations can affect the efficiency of other computations. The central table of Figure 2 contains the time required by both programs for checking if the N-th power of zero is odd without the dynamic cut optimization. The goal returns no in both cases as expected, but we observe that now P1 behaves rather worse than P2, even running out of memory for large enough numbers. This is because the subgoal power zero (toInt N) needs to compute N multiplications, and in P1 this means N redundant computations. Thus using P1 without dynamic cut the goal odd (power zero (toInt N)) will check N times if zero is odd, while in P2 this is done only once. The dynamic cut solves this situation, detecting that multi in P1 is a deterministic function and cutting the possibility of using the second rule of multi if the first one has succeeded producing a result (and satisfying some conditions explained below). The third table, at the right of Figure 2 has been obtained after activating the dynamic cut. The problem of the redundant computations has been solved. It is worth pointing out that the data of the first table do not change after activating the optimization, because all the goals considered produce only one answer, and the dynamic cut optimization only has effect on the second and posteriors answers.

Existential variables in conditions
Consider now the program of Figure 3. It includes a simple representation of DNA molecules, which are build by two chains of nucleotides. The nucleotides of the two strands are connected in compatible pairs, defined in the program through function compatible. The function dna detects if its two input parameters represent two strands that can be combined in a DNA molecule. Function dnaPart checks if the two input sequences S1 and S2 contain some subsequences P1 and P2 of length L that can occur associated in a DNA molecule. This function relies in function part which checks if the parameter X is a sublist of length L of the list Y. The functions
++ and length, represent respectively the concatenation of lists and the number of elements in a list. Consider the following session in the system T OY :
Toy> dnaPart (repeat 1000 adenine) (repeat 1000 thymine) 5 yes.	Elapsed time: 844 ms.
more solutions? y
yes.	Elapsed time: 40390 ms.

4 All the results displayed in seconds, obtained on a computer at 2.13 GHz with 1 Gb of RAM



Fig. 3. Detecting DNA strands

The goal dnaPart (repeat 1000 adenine) (repeat 1000 thymine) 5 asks if in two strands of 1000 nucleotides of adenine and thymine respectively it is possible to find two subsequences of 5 nucleotides, one from each strand, which can occur associated in a DNA molecule. The answer given by the system after 0.8 seconds is yes (actually all the subsequences of n elements of the first strand are compatible with all the subsequences of n elements of the second strand). If the user asks for a second answer, the same redundant answer yes is obtained after more than 40 seconds. The second answer is useless because it doesn’t provide new information, and greatly affects the efficiency. It can be argued that there is no point in asking for a second answer after the first, but this situation can occur as subcomputations of a bigger computation and cannot be avoided in general.
Examining the code we find out easily the source of the redundant computation: the condition of function part includes two existential variables U and V. When the user asks for more solutions the backtracking mechanism looks for new values of the variables satisfying the conditions. But this is unnecessary because the rule already has returned true and cannot return any new value. The dynamic cut will avoid this redundant computation. Here is the same goal running after activating the dynamic cut optimization in T OY :
Toy>dnaPart (repeat 1000 adenine) (repeat 1000 thymine) 5 yes.	Elapsed time: 844 ms.
more solutions ? y
no.	Elapsed time: 0 ms.
Now the system detects automatically that there are no more possible solutions after the first one, reducing the 40 seconds to 0. The interested reader can find in [4] more experimental results. The experiments in that paper were tested introducing manually the code for the dynamic cut before the optimization was part of the system. However the results have been confirmed by the current implementation.
Dynamic conditions for the cut
From the previous examples one could consider that the cut can be introduced safely in the code of functions multi and part without taking into account any run-time test. But the cut also depends on dynamic conditions. There are two situations

that must be taken into account before applying the cut:
Variable bindings.
Consider the goal: multi X zero == R, with X a logical variable. Using the program
P1 of Figure 1 this goal produces two answers: { X'→zero, R'→zero } and { R'→zero
}. The first answer is obtained using the first rule for multi and the second answer through the second rule. Introducing a cut after the first answer would be unsafe; the second answer is not redundant, but gives new information w.r.t. the first one. As it includes no binding for X it can be interpreted as ’for every X, the equality multi X zero == zero holds’, and therefore subsumes the first answer.
Non deterministic functions computed.
Suppose we include a new function zeroOrOne in the program P1 of Figure 1 defined as:  zeroOrOne = zero	zeroOrOne = s zero
Then a goal like multi zeroOrOne (s zero) == R will return two answers: { R '→ zero } and { R '→ s zero }. Introducing the cut after the first answer would be again unsafe. But in this case it is not because it prevents the use of the second rule, but because it would avoid the backtracking of the non-deterministic function zeroOrOne that leads to the application of the third rule of multi, yielding the second answer.
Therefore the cut must not take place if after obtaining the first result of the de- terministic function any of the variables in the input arguments has been bound or a non-deterministic function has been computed. As we will see in the following para- graph the implementation generates a dynamic test for checking these conditions before introducing the cut.

Implementing the Dynamic Cut
Compiling programs into Prolog
The T OY compiler transforms T OY programs into Prolog programs following ideas described in [8]. A main component of the operational mechanism is the compu- tation of head normal forms (hnf) for expressions. The translation scheme can be divided into three phases:
Higher order T OY programs are translated into programs in first order syntax.
Function calls f (e1,... , en) occurring in the first order T OY program rules are replaced by Prolog terms of the form susp(f (e1,... , en), R, S) called suspensions. The logical variable S is a flag which is bound to a concrete value, say hnf, once the suspension is evaluated. R contains the result of evaluating the function call. Its value is meaningful only if S==hnf holds.
Finally the Prolog clauses are generated, adding code for strict equality and hnf (to compute head normal forms). Each n-ary function f is translated into a Prolog predicate f (X1,... , Xn,H). When computing a hnf for an unevaluated suspension susp(f(X1,... ,Xn),R,S),a call f(X1,... ,Xn,H) will occur in order to obtain in H the desired head normal form.

We are particularly interested in the third phase (code generation), since it will be affected by the introduction of dynamic cuts. Before looking more closely at this phase we need to introduce briefly our notation for definitional trees.

Deﬁnitional Trees in T OY
Before generating the code for any function the compiler builds its associated def- initional tree. In our setting the definitional tree dt of a function f , can be of one of the following three forms:

dt(f ) = f (t¯n) → case X of ⟨c1(Xm1 ) : dt1; ... ; ck(Xmk ) : dtk⟩, where X is the variable at position u in f (t¯n) and c1 ... ck are constructor symbols, with dti a definitional tree for i = 1 ... k.
dt(f )= f (t¯n) → or ⟨dt1 | ... | dtk⟩, with dti a definitional tree for i = 1 ... k.
dt(f )= f (t¯n) → try (r ⇐ C), with f t¯n = r ⇐ C corresponding to an instance of a program rule for f .
In each case we say that the tree has a case/or/try node at the root, respectively. A more precise definition together with the algorithm that produces a definitional tree from a function definition can be found in [8]. The only difference is that we do not allow ’multiple tries’, i.e. try nodes including several program rules, replacing them by or nodes with multiple try child nodes, one for each rule included in the initial multiple try. The tree obtained by this modification is obviously equivalent and will be more suitable for our purposes. As an example of a definitional tree, consider again the definition of function multi in the program P1 of Figure 1.
Its definitional tree, denoted as dt(multi), is defined in T OY as:
dt(multi) =	multi(A,B)→ or ⟨
multi(A,B)→ case A of
⟨ zero	: multi (zero, B) → try (zero) % 1st rule
; s(X)	: multi (s(X),B) → case B of
⟨ s(Y) : multi (s(X), s(Y)) → try (s (add X (add Y (multi(X,Y))))) ⟩ % 3rd rule
| multi(A,B)→ case B of ⟨ zero: multi (A,zero) → try (zero) ⟩ % 2nd rule



Deﬁnitional trees with cut
From the definitional tree dt of each function the T OY system generates a defi- nitional tree with cut, dtc. Definitional trees with cut have the same structure as usual definitional trees. The only difference is that they rename some or and try nodes as orCut and tryCut, respectively. We define a function Γ transforming a def- initional tree dt into its corresponding definitional tree with cut straightforwardly by distinguishing cases depending on the root node of dt:
Γ( f (t¯n) → case X of ⟨c1(Xm1 ): dt1; ... ; ck(Xmk ): dtk⟩ )= 
f (t¯n) → case X of ⟨c1(Xm1 ): Γ(dt1); ... ; ck(Xmk ): Γ(dtk)⟩
Γ( f (t¯n) → or⟨dt1 | ... | dtk⟩ ) = 

f (t¯n) → orCut ⟨Γ(dt1) | ... | Γ(dtk)⟩, if f is deterministic.
Γ( f (t¯n) → or⟨dt1 | ... | dtk⟩ ) = 
f (t¯n) → or ⟨Γ(dt1) | ... | Γ(dtk)⟩, if f is non-deterministic.
Γ (f (t¯n) → try (r ⇐ C)= f (t¯n) → tryCut (r ⇐ C) if some existential variable occurs in C (i.e. some variable occurs in C but not in the rest of program rule).
Γ (f (t¯n) → try (r ⇐ C)= f (t¯n) → try (r ⇐ C) if no existential variable occurs in C.
For instance the dt of function multi displayed above is transformed into the following definitional tree with cut dct (denoted dtc(multi)):
dtc(multi) =	multi(A,B)→ orCut ⟨
multi(A,B)→ case A of
⟨ zero	: multi (zero, B) → try (zero) % 1st rule
; s(X)	: multi (s(X),B) → case B of
⟨ s(Y) : multi (s(X), s(Y)) → try (s (add C (add D (multi(C,D))))) ⟩ % 3rd rule
| multi(A,B)→ case B of ⟨ zero: multi (A,zero) → try (zero) ⟩ % 2nd rule

Notice that the only difference corresponds to the root, which has been transformed into a orCut node because multi is a deterministic function.



Generating the code

Now we can describe the function prolog(f, dtc) which generates the code for a function f from its definitional tree with cut dtc. The function definition depends on the node found at the root of dtc. There are five possibilities:
Case 1. dtc = f (s¯) → case X of ⟨c1(Xm1 ): dtc1; ... ; cm(Xmk ): dtcm⟩. Then:
prolog(g, dtc)= {g(s¯, H): − hnf (X, HX), g'(s¯σ, H).} ∪ 
prolog(g', dtc1) ∪ ... ∪ prolog(g', dtcm)
where σ = X/HX and g' is a new function symbol. The first call to hnf ensures that the position indicated by X is already in head normal form, and therefore can be used in order to distinguish the different alternatives.
Case 2. dtc = f (s¯) → or⟨dtc1 | ... | dtcm⟩. Then:
prolog(g, dtc)= {g(s¯, H): − g1(s¯, H).} ∪ ... ∪ {g(s¯, H): − gm(s¯, H).} ∪ 
prolog(g1, dtc1) ∪ ... ∪ prolog(gm, dtcm)
where g1,... , gm are new function symbols. In this case each new function symbol represents one of the non-deterministic choices.
Case 3. dtc = f (s¯) → orCut⟨dtc1 | ... | dtcm⟩. Then

prolog(g, dtc)= {g(s¯, H) : −varlist(s¯, Vs), g'(s¯, H),
(checkvarlist(Vs), !;  true). } ∪ 
{g'(s¯, H): −{g1(s¯, H).} ∪ ... ∪ {g'(s¯, H): − gm(s¯, H).} ∪ 
prolog(g1, dtc1) ∪ ... ∪ prolog(gm, dtcm)
where g', g1,... , gm are new function symbols. Observe the differences with the case 2:
A new function g' is used as an intermediate auxiliary function between g and the non-deterministic choices.
g starts calling a predicate varlist. This predicate, whose definition is tedious but straightforward, returns in its second parameter Vs a list containing all the logical variables in the input parameters, including those used as flags for detecting the evaluation of suspensions of non-deterministic functions.
After g' succeeds, i.e. after an or-branch has produced a result, the test for the dynamic cut is performed. This test, represented by predicate checkvarlist, checks if any of the variables in the list produced by varlist has been bound. This will mean that either an input logical variable has been bound or a non- deterministic function has been evaluated. In any of these cases the cut is avoided. Otherwise the dynamic cut, which is implemented as an ordinary Prolog cut, is safely performed. The definition of checkvarlist is simple:
checkVarList([ ]).
checkVarList([X|Xs]):- var(X), \+varInList(X,Xs), checkVarList(Xs).
The literal \+varInList(X,Xs), checks if the variable X occurs twice in the list, detecting bindings among variables of the list.
Case 4. dtc = try (e ⇐ l1 == r1,... , ln == rn). Then
prolog(g, dtc)= { g(s¯, H): − equal(l1, r1),... , equal(ln, rn), hnf (e, H). }
If all equalities in the conditions are satisfied the program rule returns the head normal form of its right-hand side e.
Case 5. dtc = tryCut (e ⇐ l1 == r1,... , ln == rn). Then
prolog(g, dtc)= {g(s¯, H) : −varlist((s¯, e), Vs),
equal(l1, r1),... , equal(ln, rn), (checkvarlist(Vs), !; true), hnf (e, H).}
This case is similar to the case of the orCut. The main difference is that in this case we also collect the possible new variables of the right-hand side, because if the condition binds any of them the cut must be discarded.

Examples
Now we show the Prolog code generated by T OY for some of the function examples presented through the paper:
Prolog code for function part of Figure 3:
part(A, B, C, true):- varList( [A, B, C ], Vs ),
equal(susp( ++, [ susp(++, [D,A]),J]),B), equal(susp(length, [A]), C),
(checkVarList(Vs), !; true).
This corresponds to the implementation of a tryCut node. In this example varList only looks for variables and non-deterministic functions in the parameters A, B and C, because the right-hand side of this rule is the ground term true.
Prolog code for function multi of Figure 1
multi(A, B, H):- varList([A,B], Vs),
multi’(A, B, H),
(checkVarList(Vs), ! ; true ).
multi’(A, B, H):- hnf(A, F),
multi’_1(F, B, H). multi’(A, B, zero):- hnf(B, zero).
multi’_1(zero, B, zero). multi’_1(s(X), B,
s(susp(add,[X,susp(add,[Y,susp(multi,[X,Y])])]))):- hnf(B, s(Y)).
The code of this example corresponds to the implementation of an orCut node. The two branches are represented here by the two clauses for multi' (correspond- ing to function g' in the case 3 of the previous subsection). The cut is introduced if the first alternative, which corresponds to a case node with two possibilities, succeeds.

Conclusions
In this paper we have presented the implementation of the dynamic cut optimization in the Functional-Logic system T OY . The optimization improves dramatically the efficiency of the computations in the situations explained in the paper. Moreover, we claim that in practice it allows the use of some elegant and expressive function definitions that were disregarded due to their inefficiency up to now.
The cut is introduced automatically by the system following the next steps:
The deterministic functions of the program are detected using the non- ambiguity criterion. The correctness of the criterion is ensured by theorem
2.6. Also the user can indicate explicitly that any function is deterministic.
The definitional tree associated to each program function is examined. The or nodes occurring in deterministic functions are labeled during this process as or-cut nodes. Also the try nodes corresponding to program rules including existential variables in the conditions are labeled as try-cut nodes.
During the code generation the system will generate the dynamic cut code for or-cut and try-cut nodes. However the cut only will be performed if the dynamic conditions explained in subsection 3.3 are fulfilled.

We think that a similar scheme might also be used for incorporating the dynamic cut to the Prolog-based implementations of the Curry language [6].
Currently the dynamic cut must be turned on in T OY by typing the command /cut at the prompt. However, we have checked that the optimization produces almost no overhead in the cases where it cannot be applied, and we plan to provide it activated by default in the future versions of the system.

References
Antoy, S., Definitional trees, in: Int. Conf. on Algebraic Logic Programming (ALP’92), number 632 in LNCS (1992), pp. 143–157.
Antoy, S., R.Echahed and M. Hanus, A needed narrowing strategy, Journal of the ACM 47 (2000),
pp. 776–822.
Caballero, R. and F. L´opez-Fraguas, Dynamic-cut with definitional trees, in: Proceedings of the 6th International Symposium on Functional and Logic Programming, FLOPS 2002, number 2441 in LNCS (2002), pp. 245–258.
Caballero, R. and F. L´opez-Fraguas, Improving deterministic computations in lazy functional logic languages, Journal of Functional and Logic Programming 2003 (2003).


Gonz´alez-Moreno, J., M. Hortal´a -Gonz´alez,
F. L´opez-Fraguas
and M. Rodr´ıguez-Artalejo , An

approach to declarative programming based on a rewriting logic, The Journal of Logic Programming 40
(1999), pp. 47–87.
Hanus, M., Curry: An Integrated Functional Logic Language (version 0.8.2. march 28, 2006), Available at: http://www.informatik.uni-kiel.de/ curry/papers/report.pdf (2006).
Henderson, F., Z. Somogyi and T. Conway, Determinism analysis in the mercury compiler (1996).
URL citeseer.ist.psu.edu/henderson96determinism.html

Loogen, R., F. L´opez-Fraguas and M. Rodr´ıguez-Artalejo, A demand driven computation strategy for lazy narrowing, in: Int. Symp. on Programming Language Implementation and Logic Programming (PLILP’93), number 714 in LNCS (1993), pp. 184–200.
Loogen, R., F. L´opez-Fraguas and M. Rodr´ıguez-Artalejo, Toy: a multiparadigm declarative system, in:
Int. Symp. RTA’99, number 1631 in LNCS (1999), pp. 244–247.
Loogen, R. and S. Winkler, Dynamic detection of determinism in functional-logic languages, in: Int. Symp. on Programming Language Implementation and Logic Programming (PLILP’91), number 528 in LNCS (1991), pp. 335–346.
Loogen, R. and S. Winkler, Dynamic detection of determinism in functional logic languages, in: J. Maluszynski and M. Wirsing, editors, Programming Language Implementation and Logic Programming: Proc. of the 3rd International Symposium PLILP’91, Passau, Springer, Berlin, Heidelberg, 1991 pp. 335–346.
Pen˜a, R. and C. Segura, Non-determinism analyses in a parallel-functional language, Journal of Logic Programming 2004 (2005), pp. 67–100.
Sawamura, H. and T. Takeshima, Recursive Unsolvability of Determinacy, Solvable Cases of Determinacy and Their Applications to Prolog Optimization, in: Proceedings of the Symposium on Logic Programming, 1985, pp. 200–207.
