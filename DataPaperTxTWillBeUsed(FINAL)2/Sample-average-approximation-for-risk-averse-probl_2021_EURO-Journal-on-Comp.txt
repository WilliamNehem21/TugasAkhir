EURO Journal on Computational Optimization 9 (2021) 100005

		




Sample average approximation for risk-averse problems: A virtual power plant scheduling application
Ricardo M. Limaa,‚àó, Antonio J. Conejob, Lo√Øc Giraldi a,e, Olivier Le Ma√Ætre c, Ibrahim Hoteitd,
Omar M. Knioa
a Computer, Electrical and Mathematical Sciences & Engineering Division, King Abdullah University of Science and Technology (KAUST), Thuwal 23955-6900, Saudi Arabia
b Integrated Systems Engineering-Electrical and Computer Engineering, The Ohio State University, OH, USA
c Centre de Math√©matiques Appliqu√©es, CNRS, Inria, Ecole Polytechnique, Palaiseau, France
d Physical Science and Engineering Division, King Abdullah University of Science and Technology (KAUST), Saudi Arabia
e CEA, DES, IRESNE, DEC, Cadarache F-13108 Saint-Paul-Lez-Durance, France


a r t i c l e	i n f o	a b s t r a c t

	

Keywords:
Sample average approximation
Risk-averse stochastic programming Virtual power plant
In this paper, we address the decision-making problem of a virtual power plant (VPP) involving a self-scheduling and market involvement problem under uncertainty in the wind speed and electricity prices. The problem is modeled using a risk-neutral and two risk-averse two-stage stochastic programming formulations, where the conditional value at risk is used to represent risk. A sample average approximation methodology is integrated with an adapted L-Shaped solution method, which can solve risk-neutral and specific risk-averse problems. This methodology provides a framework to understand and quantify the impact of the sample size on the variability of the results. The numerical results include an analysis of the computational performance of the methodology for two case studies, estimators for the bounds of the true optimal solutions of the problems, and an assessment of the quality of the solutions obtained. In particular, numerical experiences indicate that when an adequate sample size is used, the solution obtained is close to the optimal one.





Introduction

The optimal operation and electricity market involvement of virtual power plants (VPPs) is currently an active field of research. VPP refers to an aggregation of distributed energy resources (DER) that interacts with the electricity market as a single entity (Awerbuch and Preston, 1997; Pudjianto et al., 2007). These DERs involve generators with small ca- pacities or that face significant trading risks if operating by themselves. For example, a wind farm trading in an electricity market is subject to uncertain wind speeds, electricity prices, and imbalance costs, which may involve high risk. Aggregating multiple and diverse generators into a VPP creates an entity with a single power generation profile and a larger power capacity than the constituting units. A VPP has flexibility due to the complementarity of its diverse resources, and capacity to de- velop market intelligence to optimize its participation in the electricity market (through offers in the pool and by signing forwards contracts). However, to define a single power output profile, a self-scheduling prob- lem considering all constituting generators, their interactions, and their
generation constraints needs to be solved, which is more diÔ¨Écult than solving individual generator problems. The VPP concept is particularly relevant for the integration of distributed renewable energy resources in power systems to mitigate flexibility limitation and power output un- certainty. Additional details on the technical and commercial functions of VPPs can be found in Pudjianto et al. (2007), Morales et al. (2014), and Jansen et al. (2008). In Section 1.1, a review on VPP optimization is presented. Within the different aspects of a VPP operation, we are concerned with the optimal scheduling of the generation units and the interaction with the electricity market.
In the present work, we propose a sample average approximation (SAA) methodology (Kleywegt et al., 2001; Shapiro and Homem-De- Mello, 2000) to solve the risk-averse stochastic programming problem that describes the operation of a VPP. Three important aspects in the im- plementation of the SAA are studied: 1) the development of an eÔ¨Écient solution methodology; 2) the impact of the sample size on the perfor- mance of the methodology; and 3) the determination of point estimates and confidence intervals for the solutions.


‚àó Corresponding author.
E-mail  addresses:  ricardo.lima@kaust.edu.sa  (R.M.  Lima),  conejonavarro.1@osu.edu  (A.J.  Conejo),  loic.giraldi@cea.fr  (L.  Giraldi),  olivier.le- maitre@polytechnique.edu (O. Le Ma√Ætre), ibrahim.hoteit@kaust.edu.sa (I. Hoteit), omar.knio@kaust.edu.sa (O.M. Knio).
https://doi.org/10.1016/j.ejco.2021.100005
Received 22 October 2020; Received in revised form 7 February 2021; Accepted 11 March 2021
2192-4406/¬© 2021 The Authors. Published by Elsevier Ltd on behalf of Association of European Operational Research Societies (EURO). This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)



Literature review: optimization of VPPs

In the literature, VPP models with distinct portfolios of generation units, different interactions with the electricity market, and, conse- quently, various sources of uncertainty can be found. In terms of inter- actions with the electricity market, the main features captured by VPP models include:
forward contracts (Lima et al., 2015; Pand≈æiƒá et al., 2013a; Shaban- zadeh et al., 2016);
offers to the day-ahead market (Baringo and Baringo, 2017; Dab- bagh and Sheikh-El-Eslami, 2016; Kardakos et al., 2016; Moghad- dam et al., 2013; Pand≈æiƒá et al., 2013b; Rahmani-Dabbagh and Sheikh-El-Eslami, 2016; Shayegan-Rad et al., 2017; Tajeddini et al., 2014; Zamani et al., 2016);
offers/bids to the balancing market (Dabbagh and Sheikh-El-Eslami, 2016; Kardakos et al., 2016; Tajeddini et al., 2014);
offers to spinning reserves (Dabbagh and Sheikh-El-Eslami, 2016); and
strategic offering considering the market clearing and other market players‚Äô strategies (Kardakos et al., 2016).
The operational decision-making problem of VPPs involves decisions under uncertainty due to the nature of the renewable energy sources and electricity prices. Therefore, stochastic optimization approaches constitute a natural framework to address this type of problems. The most used approaches are based on stochastic programming and ro- bust optimization. Some examples include the application of risk-neutral stochastic programming models (Lima et al., 2018; Pand≈æiƒá et al., 2013a;
in Lima et al. (2018) does not use an SAA approach, but rather focuses on risk-averse problems and their solutions using the L-Shaped method (Van Slyke and Wets, 1969). In that work, 14 variants of the L-Shaped method using combinations of single and multiple optimality cuts and eÔ¨Écient parallel implementations are discussed, without considering SAA.
In this work, we propose a more elaborate approach that eÔ¨Éciently relies on multiple samples to assess solutions and determine confidence intervals on the relevant performance indices of the VPP operation. No such work is available for VPP applications.

Literature review: sample average approximation

The term sample average approximation is used in the literature to refer to a problem that approximates a stochastic optimization one (Shapiro and Homem-De-Mello, 2000), but it is also used to indicate a methodology where the solution of that approximate problem is per- formed multiple times and increasingly accurate solutions are obtained (Kleywegt et al., 2001). The repetition enables the calculation of con- fidence intervals of the optimal objective function value, and also the assessment of the solution.
The detailed characterization and statistical properties of the SAA methodology, namely consistency and rates of convergence to optimal objective function values and solution, have been stud- ied by Mak et al. (1999), Shapiro and Homem-De-Mello (2000), Kleywegt et al. (2001), and reviewed in detail in Shapiro (2009) and Homem-de Mello and Bayraksan (2014). In these works, expressions for the convergence to the optimal value and solution are developed and ex-

2013b), risk-averse stochastic programming (Dabbagh and Sheikh-El-
pressions relating the probability of an optimal solution ùë•‚àó
to be equal

Eslami, 2016; Kardakos et al., 2016; Lima et al., 2018; Moazeni et al.,
to the true solution ùë•‚àó
ùëÅ
with the sample size are established. However,

2015; Moghaddam et al., 2013; Tajeddini et al., 2014), robust optimiza- tion (Lima et al., 2015; Rahimiyan and Baringo, 2016; Shabanzadeh et al., 2015), and recently, a hybrid approach based on stochastic pro- gramming and robust optimization (Baringo and Baringo, 2017).
When risk-neutral or risk-averse stochastic programming models are used, the problem is solved for a random uncertainty sample. The main assumption is that the sample used is representative of the full distribu- tion of the uncertainties in the problem. In the works above, the sample size ranges from less than 100 elements to a maximum of 400, except in the work Lima et al. (2018) where samples of up to 25,000 elements were used. In some works, a reduced sample size was obtained using a scenario-reduction method (Dupaƒçov√° et al., 2003). Typically, the size of the sample is limited by the capability to solve the problems using the corresponding extensive form and a branch and cut solver for mixed- integer linear programming (MILP) problems. Compared with the works cited above, our VPP model considers a time horizon of one week di- vided into periods of one hour, whereas most works above consider the 24 h of the next day. The time horizon of one week avoids the myopic view of a single-day horizon, which neglects the temporal coupling of some VPP constraints that condition next day operations. Therefore, this extended horizon enables considering constraints of thermal units, e.g., minimum up-time and minimum down-time, and water mass balances in the reservoir of hydro units across consecutive days, at the cost of a larger model.
We emphasize that risk-averse stochastic programming models are
more complex to solve than risk-neutral stochastic programming; there- fore, the impact of the sample size and the length of the time hori- zon on the computing time of risk-averse problems are comparatively more critical. Some works propose an out-of-sample analysis that pro- vides an additional characterization of the solution resulting from the stochastic programming model (Baringo and Baringo, 2017). Compared to an out-of-sample analysis that performs a study for a single solu- tion, the SAA methodology includes a first stage with multiple opti- mization replications using different samples to generate alternative solutions and to provide a point estimate of the upper bound on the true objective function value (for a maximization problem). The work
as stated in Kleywegt et al. (2001) and Linderoth et al. (2006), it is im- practical to determine some of the constants in those expressions. Fur- thermore, the expressions do not provide an estimate of the computing time required to obtain the approximated solutions and point estimates of the bounds. Therefore, computational experiments are essential to determine the trade-off between the computational resources and the accuracy obtained from the sample size. This type of analysis was per- formed, for example, in Linderoth et al. (2006) and Verweij et al. (2003). Wang (2007) and Wang and Ahmed (2008) were the first to propose SAA methods for risk-averse stochastic programming problems. They focused on min-max problems with expected value objectives and prob- lems with constraints involving expected values. For these problems, they proved that the results of their SAA problems converge exponen- tially fast to the true results of the stochastic problems as the sample
size increases.
A related method to this work, which has been extended to inte- grate an SAA methodology with risk measures, is stochastic dual dy- namic programming (SDDP) (Pereira and Pinto, 1991). In Philpott and de Matos (2012) and Shapiro et al. (2013) are developed risk- averse SDDP methods to address multistage linear stochastic program- ming models describing power systems planning problems. In risk- averse SDDP, the upper bound estimators are known to be weak (Shapiro, 2011), and in this regard, importance sampling was proposed in Kozm√≠k and Morton (2015) to improve the quality of those estimators (for a minimization problem).
Regardless of the approach used, it is generally essential to develop an eÔ¨Écient SAA methodology that can handle a large number of replica- tions as well as large sample sizes to calculate tight confidence intervals. Furthermore, an eÔ¨Écient methodology is paramount to study the impact of the sample size on the computational performance of the methodol- ogy. This is a central theme of the present work.

SAA applied to a risk-averse VPP optimization model

The application of SAA methodologies to the scheduling problems of VPPs has not been reported in the literature. To fill the gap, we propose



an SAA methodology to solve these problems that is based on methods from Linderoth et al. (2006). Specifically, a distinct class of risk-averse problems from those considered in Linderoth et al. (2006) is addressed, and thus, insights that are not found in Linderoth et al. (2006) and Verweij et al. (2003) are analyzed and discussed.
In this work, new avenues to solve the VPP problem are explored, focusing on the application of an SAA methodology that leads to com- prehensive results for the VPP, including point estimates, confidence in- tervals, and the assessment of the solution obtained. The main contribu- tions of this work are twofold: 1) providing new and eÔ¨Écient strategies to improve the performance of the SAA methodology; and 2) carrying out a comprehensive computational study applied to a VPP risk-averse two-stage stochastic programming problem. Specifically, an eÔ¨Écient ini- tialization strategy to handle multiple optimization replications that re- duces the computing time is proposed. In addition, a new method to reduce the number of times the bound estimation stage is ran is dis- cussed. As a result, a detailed analysis of the effect of the sample size shows that, unexpectedly, increasing the sample size for the optimiza- tion leads to a reduction of the overall computing time in one of the procedures implemented. This reduction occurs because savings in the bound estimation stage compensate the additional time spent on the optimization with larger samples.
The paper is organized as follows. In Section 2, the problem state- ment and a description of the VPP studied are presented. The stochastic models with a focus on the objective functions are described in Section 3. The SAA approach and the implementation of two solution procedures are presented in Section 4, while the sampling techniques are shown in Section 5. The computational results are discussed in Section 6 and conclusions are summarized in Section 7. In a supplementary document, appendices with the deterministic model of the VPP, flow diagrams of the solution procedures used, and additional extensive computational results are made available.

Problem statement

In  this  work,  we  revisit  the  problem  considered  in Lima et al. (2018) but using an SAA methodology. The problem addresses the optimal operation and electricity market involvement of a VPP that consists of a thermal unit, a wind power farm, and a pumped-storage hydroelectric plant. This configuration provides the flexibility of two dispatchable units, two renewable sources, and storage to manage the energy available and to respond to the market. The VPP participates in the electricity market as a single entity by selling and buying electricity in the market pool and through weekly contracts. The time horizon is one week, divided into 168 hourly periods.
The VPP generates electricity through the three units and may con- sume electricity to pump back water to the upper reservoir of the hydro plant. Uncertainty in the wind speed and the electricity prices is consid- ered, with a constant value for each hourly period.
The decision sequence of the VPP involves a two-stage framework. In the first-stage, the decisions are made before the beginning of the time horizon, where the VPP has to decide on the self-scheduling of the thermal unit and the electricity to buy or sell through forward contracts. The self-scheduling of the thermal unit involves only the commitment, defined as the periods where it is up or down. The VPP can choose to buy or sell electricity from two different weekly contracts, each one in- volving fixed prices and quantities. In the second-stage, the decisions for the full week are aggregated into one stage. These decisions are related to the dispatching of the thermal and hydro plants and to the additional electricity to buy or sell in the electricity pool (short-term electricity market). The dispatch involves the hourly determination of the power to generate by the thermal unit when it is up and the power generation or consumption by the pumped-storage hydro plant.
The objective of the VPP is to maximize the operational profit by de- termining an optimal solution concerning: a) the commitment, dispatch, and coordination between units in each period; b) the electricity bought
and sold in each period; and c) the electricity bought or sold through contracts. From the decision-maker perspective, the optimal first-stage variables are the most relevant. These decisions are implemented and fixed during the time horizon, whereas the optimal second-stage vari- ables for the 168 periods represent recourse actions based on the realiza- tions of the uncertain parameters. In practice, during the week, the VPP needs to solve additional decision problems to define the bidding strat- egy for the specific electricity market pool (day-ahead market, intra-day market, balancing market). These problems have a shorter horizon and use updated information for wind speed and electricity prices.
The thermal unit has lower and upper bounds on the power gen- eration, minimum up-time and down-time, start-up and shutdown and power-up and power-down ramp rate limits. Regarding costs, this unit has fixed and variable generation costs, hot and cold start costs. The state of the thermal unit before the beginning of the time horizon is known. The hydro plant has lower and upper limits on the volume of water of the upper reservoir, and an upper bound on the pumped flow of water.

Risk-averse stochastic models

In this section, the main characteristics of the risk-averse stochas- tic programming formulations for the VPP problem are described. The deterministic version of the VPP optimization problem is described in Appendix A, where the objective function, constraints, variables, and input data are presented. Below, we focus on building a general risk- averse stochastic programming formulation that will be used in the SAA methodology outlined in Section 4.

VPP general stochastic programming formulation

The stochastic programming formulation of the VPP problem is an extension of the deterministic VPP problem, which results from con- sidering the electricity prices and the wind power output as random variables. In the deterministic VPP problem, the aim is to maximize the profit defined as the difference between the revenues from selling elec- tricity and the costs of operation and buying electricity. In the stochastic version, the profit is a random function, and thus the aim is to maximize

a functional of the profit. We start by denoting the profit function ùëì as
ùëì (ùë•+, ùë•‚àí, ùë¢, ùë¶+(ùúâ), ùë¶‚àí(ùúâ), ùë†(ùúâ), ùúâ) ‚à∂= (ùëê+)‚ä§ùë•+ + (ùëê‚àí)‚ä§ùë•‚àí + ùëê0‚ä§ùë¢
+ ùëêÃÉ0‚ä§(ùúâ)ùë¶+(ùúâ) ‚àí ùëêÃÉ0‚ä§(ùúâ)ùë¶‚àí(ùúâ) + ùëê‚ä§ùë†(ùúâ)	(1)

where ùúâ ‚à∂ Œ© ‚Üí ‚Ñùùëü is a random vector defined on the probability space (Œ©, , ùëÉ ), with Œ© being the set of all possible outcomes,  a ùúé-algebra and ùëÉ a probability measure. The vectors ùëê+, ùëê‚àí, ùëê0, and ùëê ‚àà ‚Ñùùëõ1 denote deterministic vectors with known parameters, whereas, ùëêÃÉ0(ùúâ) is a ran- dom vector. The vectors ùë•+, ùë•‚àí, ùë¢, ùë¶+(ùúâ), ùë¶‚àí(ùúâ), ùë†(ùúâ) ‚àà ‚Ñùùëõ1 represent the
variables of the VPP model.
The vectors ùë•+, ùë•‚àí, and ùë¢ correspond to the first-stage decisions. ùë•+,
ùë•‚àí capture the power to sell and buy through the contracts, respectively. The revenues related to the contracts are represented by (ùëê+)‚ä§ùë•+, while the costs by (ùëê‚àí)‚ä§ùë•‚àí. The vector ùë¢ encapsulates the binary variables that define the operation mode of the thermal unit. Therefore, the term ùëê0‚ä§ùë¢
represents the startup costs, shutdown costs, and fixed costs of operation of the thermal unit.
The second-stage decisions are represented by the vectors ùë¶+(ùúâ),
ùë¶‚àí(ùúâ), ùë†(ùúâ), and ùëü(ùúâ). Note that ùëü(ùúâ) is not part of the objective function. The vectors ùë¶+(ùúâ), ùë¶‚àí(ùúâ) denote the energy to sell or buy to the market, and the vector ùëêÃÉ0(ùúâ) denotes the uncertain hourly electricity prices. The vector ùë†(ùúâ) is the electricity generated by the thermal unit. Finally, the vector ùëü(ùúâ) captures the energy generated or consumed by the pumped-
storage hydro unit and the volumes of water associated with this unit.
The stochastic model of the VPP aims at maximizing a functional of the profit subject to the constraints that define the region of operation of the thermal unit, pumped-storage hydro plant, and the two contracts


that are offered to the VPP:
and ùêπùëì
is the cumulative distribution of ùëì, ùêπ (ùë§) = ùëÉ {ùëì ‚â§ ùë§}.

ùë•+ ,ùë•‚àí ,ùë£,ùë¢,ùë¶+max‚àí (ùúâ),ùë†(ùúâ),ùëü(ùúâ)
ùúì [ùëì (ùë•+, ùë•‚àí, ùë¢, ùë¶+(ùúâ), ùë¶‚àí(ùúâ), ùë†(ùúâ), ùúâ)]
From an optimization perspective, there are two additional defini- tions that are relevant. The first is due to Pflug (2000), which defines

s.t.	ùê¥+ùë•+ + ùê¥‚àíùë•‚àí + ùêµùë£ ‚â§ ùëè
the CVaR through the optimization problem

ùê∏ùë¢ ‚â§ ùëî
		

CVaR
[ ] = max { ‚àí  1
[( ‚àí
)+]}

ùë†(ùúâ) ‚àí ùë¶+(ùúâ) + ùë¶‚àí(ùúâ) + ùëü(ùúâ) ‚àí ùë•+ + ùë•‚àí
+‚Ñé(ùúâ) = 0,  a.s.
ùêΩùëü(ùúâ) ‚â§ ùëó,  a.s.
ùë•+, ùë•‚àí ‚àà ‚Ñùùëõ1 , ùë£, ùë¢ ‚àà ùîπùëõ1 , ùë¶+(ùúâ), ùë¶‚àí(ùúâ),
(2)
where (‚ãÖ)+ = max{‚ãÖ, 0}. In Pflug (2000), it is shown that the optimal value of ùúÇ in (6) is the VaR1‚àíùõº [ùëì ]. The second definition shows that the func-
tion that defines the CVaR of losses is a convex function (Rockafellar and Uryasev, 2000), which in our specific case leads to the equality

+	max {CVaR	[ùëì (ùë•, ùëß, ùë¶(ùúâ), ùúâ)]}

ùëûùë¢ùëéùëëùë†(ùúâ) ‚àà ‚Ñùùëõ1 , ùëü(ùúâ) ‚àà ‚Ñùùëõ1 ,
where ùîπ ‚à∂= {0, 1}, ùë£ are the binary variables associated with the choice
ùë•,ùëß,ùë¶(ùúâ)
=  max
1‚àíùõº
{ùúÇ ‚àí  1  {[ùúÇ ‚àí ùëì (ùë•, ùëß, ùë¶(ùúâ), ùúâ)]+}}.	(7)

of blocks in the contracts, ‚Ñé(ùúâ) ‚àà ‚Ñùùëõ1 defines the uncertain wind power,
ùê¥+, ùê¥‚àí ‚àà ‚Ñùùëö1 √óùëõ1 , ùêµ ‚àà ‚Ñùùëö1 √óùëõ1 , ùê∂ ‚àà ‚Ñùùëö2 √óùëõ1 , ùê∑ ‚àà ‚Ñùùëö2 √óùëõ1 , ùê∏ ‚àà ‚Ñùùëö3 √óùëõ1 , ùêΩ ‚àà
ùë•,ùëß,ùë¶(ùúâ),ùúÇ
1 ‚àí ùõº

‚Ñùùëö4 √óùëõ1 are matrices with known parameters, and ùëè ‚àà ‚Ñùùëö1 , ùëë ‚àà ‚Ñùùëö2 , ùëî ‚àà
‚Ñùùëö3 , ùëó ‚àà ‚Ñùùëö4 are vectors with known parameters.
In Problem (2), the first constraint covers the contracts. The second
constraint represents the relationships among the binary variables as- sociated with the commitment of the thermal unit. The third constraint captures the region of operation of the thermal unit, including minimum


Based on the properties of the CVaR, we define an objective function representing the maximization of a combination of the expected profit and CVaR:
max ùúì [ùëì (ùë•, ùëß, ùë¶(ùúâ), ùúâ)] ‚à∂=  max	ùîº (1 ‚àí ùõΩ)ùëì (ùë•, ùëß, ùë¶(ùúâ), ùúâ)
ùë•,ùëß,ùë¶(ùúâ)	ùë•,ùëß,ùë¶(ùúâ),ùúÇ
(	 1 	)]}




captures the region of operation of the pumped-storage hydro plant. See Appendix A for details.
For the sake of clarity on the exposition of the SAA methodology, a compact formulation of the model with a simplified notation is in-
troduced. We set ùë• ‚à∂= (ùë•+, ùë•‚àí), ùë¶ ‚à∂= (ùë¶+(ùúâ), ùë¶‚àí(ùúâ), ùë†(ùúâ), ùëü(ùúâ)), ùëß ‚à∂= (ùë¢, ùë£),
ùëê ‚à∂= (ùëê+, ùëê‚àí), ùëê ‚à∂= ùëê0, ùëêÃÉ ‚à∂= ùëêÃÉ0 with proper dimensions:
max	ùúì [ùëì (ùë•, ùëß, ùë¶(ùúâ), ùúâ) ‚à∂= ùëê‚ä§ùë• + ùëê‚ä§ùëß + ùëêÃÉ‚ä§(ùúâ)ùë¶(ùúâ)]
where ùõΩ ‚àà [0, 1] is a parameter that defines the weights of the expec- tation and CVaR of ùëì . We are particularly interested in the solution of Problem (3) with (8) defined with ùõΩ = (0, 1) and ùõΩ = 1 (maximization of
the CVaR of the profit) using an SAA approach.
Detailed analyses on the properties of the CVaR and VaR metrics and their integration into stochastic programming can be found in Pflug (2000), Rockafellar and Uryasev (2000), Rockafellar (2007), and

ùë•,ùëß,ùë¶(ùúâ)
s.t.	ùê¥ùë• + ùêµùëß
ùê∂ùëß + ùê∑ùë¶(ùúâ)  ùëë,  a.s.
ùë¶(ùúâ) + ùë• = ‚Ñé(ùúâ),  a.s.
ùë• ‚àà ‚Ñùùëõ1 , ùëß ‚àà ùîπùëõ1 , ùë¶(ùúâ) ‚àà ‚Ñùùëõ1 ,
(3)
Sarykalin et al. (2008). Risk metrics for multi-stage stochastic program-
ming, such as the expected CVaR can be found in Pflug and Ruszczyn- ski (2005), Shapiro et al. (2009), and Mello and Pagnoncelli (2016). Also, the work in Alonso-Ayuso et al. (2018) provides extensive com- parisons on multi-period risk metrics.

+	+

where ùë•, ùëß denote first-stage variables and ùë¶(ùúâ) second-stage variables, ‚Ñé(ùúâ) ‚àà ‚Ñùùëõ1 and ùëêÃÉ(ùúâ) ‚àà ‚Ñùùëõ1 are random vectors, ùëê, ùëê, and ùëêÃÉ are determinis- tic vectors with known parameters, ùê¥ ‚àà ‚Ñùùëö1 √óùëõ1 , ùêµ ‚àà ‚Ñùùëö1 √óùëõ1 , ùê∂ ‚àà ‚Ñùùëö2 √óùëõ1 , and ùê∑ ‚àà ‚Ñùùëö2 √óùëõ1 are matrices with known parameters, and ùëè ‚àà ‚Ñùùëö1 and

Sample average approximation

For the generic problem formulation

ùëë ‚àà ‚Ñùùëö2 are vectors with known parameters.
ùë§‚àó =	max
ùë•,ùë¶(ùúâ),ùëß‚àà
{ùîºùúâ [ùúô(ùë•, ùë¶(ùúâ), ùëß, ùúâ)]},	(9)

3.2. Risk-averse VPP stochastic models
where  ÓâÉ ‚à∂= {ùë•, ùë¶(ùúâ), ùëß ùê¥ùë• + ùêµùëß ‚â§ ùëè; ùê∂ùëß + ùê∑ùë¶(ùúâ) ‚â§ ùëë, ùëé.ùë†.; ùêπ ùë¶(ùúâ) + ùê∫ùë• =
‚Ñé(ùúâ), ùëé.ùë†.; ùë• ‚àà ‚Ñùùëõ1 , ùëß ‚àà ùîπùëõ1 , ùë¶(ùúâ) ‚àà ‚Ñùùëõ1 }, we define the sample average ap-

the CVaR of the profit in the objective function. The CVaR is a coher-
proximation problem as (Kleywegt et al., 2001; Shapiro and Homem-De- Mello, 2000):

ent risk measure with relevant properties in terms of convexity (Artzner
et al., 1999; Pflug, 2000; Rockafellar and Uryasev, 2000). Therefore, it has clear advantages over non-convex risk measures. Note that CVaR
‚àó =  max
ùëÅ
1 ùëÅ
ùëÅ
ùúô(ùë•, ùë¶, ùëß, ùúâùëõ)}
,	(10)

is not the only possibility to measure the risk; other measures have been suggested including the variance, value at risk, drawdown, or
ùëõ=1
for a sample with independent and identically distributed elements
ùúâùëõ from the distribution of ùúâ, and where	‚à∂= {ùë•, ùë¶(ùúâùëõ), ùëß ùê¥ùë• + ùêµùëß

buffered probability of exceedance; see Pflug and R√∂misch (2007) and


ùëõ	ùëõ	ùëõ
ùëÅ
ùëõ	ùëõ
|  ùëõ1

the CVaR to a loss function, whereas in this work the CVaR is applied	+
ùõΩ
‚àó	‚àó  ‚àó  ‚àó

to a profit one, which leads to different definitions below as compared
The optimal value and solution of Problem (9) are ùë§ and ùë• , ùë¶ , ùëß ,

respectively, which are approximated by ùë§‚àó and ùë•‚àó , ùë¶‚àó , ùëß‚àó
obtained

with the works cited. The terms ‚Äúaverage value at risk‚Äù and ‚Äúexpected
from (10). Note that ùë§‚àó
ùëÅ	ùëÅ  ùëÅ  ùëÅ

shortfall‚Äù are also used to refer to the CVaR (Rockafellar, 2007).
The CVaR for the (1 ‚àí ùõº) quantile of random variable ùëì is defined as the conditional expectation of ùëì for ùëì	VaR1‚àíŒ±[f] (Rockafellar and
Uryasev, 2000):
CVaR1‚àíùõº [ùëì ] = ùîº ùëì ùëì ‚â§ VaR1‚àíùõº [ùëì ] ,	(4)
where VaR1‚àíùõº [ùëì ] is the value at risk defined as
VaR1‚àíùõº [ùëì ] = max{ùë§ ùêπ (ùë§) ‚â§ 1 ‚àí ùõº},	(5)
ùëÅ is a random variable that depends on the sample
of ùúâùëõ.
The objective function (8) involve the CVaR measure, which may
not resemble the generic formulation in (9). However, note that (8) is reformulated as a function of the expectation operator.
Using the SAA methodology, two types of inference statistics for the solutions are calculated: 1) point estimates and confidence intervals for
the upper and lower bounds on the optimal objective function value ùë§‚àó;
2) a point estimates of the upper bound on the gap between ùë§‚àó and ùë§‚àó .


Table 1
Case 1. Optimization results for the formulation with ùõΩ = 0. The results are ordered by the optimal objective function value (ùë§ÃÇ ùëÅ,ùëö ). ùëÄ = 30, ùëÅ = 10. Bold ‚Äì set of distinct first-stage solutions.

First-stage variables (aggregated)

ùëö ‚Äì Optimization replication index, ùë§ÃÇ ùëÅ,ùëö - optimal objective function value for optimization repli- cation ùëö, ITER ‚Äì number of iterations of the L-Shaped method, GAP ‚Äì gap between the upper and
lower bound within the L-Shaped method, T ‚Äì elapsed wall-clock time, UT ‚Äì percentage of up-time of the thermal unit, SUP/SD ‚Äì number of startups/shutdowns of the thermal unit, SELLC/BUYC ‚Äì power sold/bought through contracts.


Besides, for the specific application, the solutions are complemented with the corresponding point estimates and confidence intervals for the expected profit and the CVaR of the profit.
jective function value ùë§‚àó, the following notation is used: a) for the upper To evaluate the inference statistics on the bounds of the optimal ob- bound, ùëÅ denotes the sample size, ùëõ is the index of an element of the sample, ùëÄ is the number of replications, and ùëö is the replication index;
b) for the lower bound, ùëÅ ‚Ä≤ denotes the sample size, ùëõ‚Ä≤ is the index of an element of the sample, ùëá and ùëá ‚Ä≤ are the number of replications, and ùë° and ùë°‚Ä≤ are replication indices. For the upper bound on the gap between
ùë§‚àó and ùë§‚àó , ùëÅ, ùëõ, ùëÄ, and ùëö are used with the same purpose as in a).
rences. These results do not support a clear-cut decision on the best solution to choose. Obviously, the variance of these results is due to the size of the sample used for the optimization. However, with a small sample and the methodologies presented in this work, it is possible to provide a set of inference statistics and to assess the solutions. This in- formation can help the selection of first-stage solutions.
The impact of the sample size ùëÅ and the number of replications ùëÄ
on the probability of obtaining an optimal solution to the true problem
work, it is claimed that the relation between ùëÅ and this probability from the SAA problem is discussed in Kleywegt et al. (2001). In that
is problem specific, and that beyond a given ùëÄ, it would be better to

ùëÅ	‚Ä≤

Note that the symbols ùë°, ùë° , and ùëá are not related to the symbols ùë° and ùëá
used in Appendix A to refer to time periods and time horizon.
Motivating example
In this section, we illustrate the variance of the optimal objective function values and first-stage solutions obtained using different sam- ples having the same size. The samples and results used in this exam-
increase ùëÅ .
Upper bound on the optimal objective function value ùë§‚àó
The approximation of ùë§‚àó is done by calculating point estimates of lower and upper bounds on ùë§‚àó. An upper bound on ùë§‚àó is defined by the
well-known relation ùîº[ùë§‚àó ]  ùë§‚àó (Mak et al., 1999). The value of the

ple are part of the computational experiments described in Section 6.
ùîº[ùë§‚àó ]
ùëÅ
is estimated by the statistical estimator
ùëàùêµùëÅ,ùëÄ
that is determined

Table 1 outlines the results of 30 optimization replications, each with a
sample of size ùëÅ = 10, for the maximization of the expected profit.
by solving ùëÄ optimization problems (10)

The variability of these results can be highlighted with the results
of two samples. The first sample (ùëö = 1) has optimal objective function
ùë§ÃÇ ùëÅ,ùëö =	maÓâÉx
{  1 ‚àëùëÅ
ùúô(ùë•, ùë¶, ùëß, ùúâùëõ,ùëö)}
,  ‚àÄùëö ‚àà ùëÄ,	(11)

value of 3,738,467 and first-stage solution {100, 0, 0, 0, 265}, whereas
ùë•,ùë¶,ùëß‚àà
ùëÅ,ùëö
ùëÅ ùëõ=1

for ùëö = 2, the optimal objective function value is 2,828,660 with first- stage solution {100, 0, 0, 50, 55}. This table also shows that the first-
stage solution {100, 0, 0, 0, 265} corresponds to the higher profits, and
and by using ùë§ÃÇ ùëÅ,ùëö to estimate the ùëàùêµùëÅ,ùëÄ through
 1 ‚àëùëÄ


The sample variance estimator is
1	2		1	 ‚àëùëÄ (	)2
		
‚â• ùëîùëéùëù(ùë•ÃÇ , ùëßÃÇ ).	(22)
Óà≥ is calculated using ùîº[ùë§‚àó ] as a valid statistical upper bound on
		  

Thus, ùëàùêµ	is a statistical estimator of ùîº[ùë§ÃÇ
] with the 100(1 ‚àí ùõº‚Ä≤)%
Mak et al. (1999), it is proposed to use the upper limit of the confidence

ùëÅ,ùëÄ	ùëÅ
confidence interval
interval of the estimator of Óà≥ as an upper bound on the ùëîùëéùëù(ùë•ÃÇ  , ùëß ).
ùëÅ

ùêøùëà ùêµùëÅ,ùëÄ , ùëà ùëà ùêµùëÅ,ùëÄ  ‚à∂= ùëà ùêµùëÅ,ùëÄ ‚àí ùë°ùëÄ ‚àí1,ùõº‚Ä≤ ùë†ùëÅ,ùëÄ , ùëà ùêµùëÅ,ùëÄ + ùë°ùëÄ ‚àí1,ùõº ùë†ùëÅ,ùëÄ ,
(14)
where ùë°ùëÄ ‚àí1,ùõº‚Ä≤ is the critical value from the t-distribution.
Lower bound on the optimal objective function value ùë§‚àó
We define ùêøùêµùëÅ ‚Ä≤ ,ùëö,ùëá as an estimator of a lower bound on ùë§‚àó, which is associated with a first-stage solution from the optimization replication
ùëö denoted by (ùë•ÃÇùëÅ,ùëö , ùëßÃÇùëÅ,ùëö ). The calculation of ùêøùêµùëÅ ‚Ä≤,ùëö,ùëá is done using ùëá
independent samples of size ùëÅ ‚Ä≤, as follows
This upper limit calculation is presented in Procedure 2. Note that this procedure uses the same sample to calculate the two terms on the left hand side of the inequality in (22), and the upper bound on the gap is always positive. Additional details regarding variants of evaluation pro- cedures and convergence analysis of the gap estimator can be found in Bayraksan and Morton (2006) and Mak et al. (1999).

4.5. Implementation
The practical computation of the statistical point estimates and confidence intervals described in Sections 4.2‚Äì4.4 is presented in Procedures 1 and 2, and the corresponding diagrams in Appendix B. These two procedures involve two stages denoted as optimization stage

ùë§ÃÇ
ùëÅ ‚Ä≤ ,ùëö,ùë°
=  max
ùëÅ ,ùëö,ùë°

ùëá
 1
ùëÅ ‚Ä≤
ùëÅ ‚Ä≤
ùëõ‚Ä≤=1
ùúô(ùë•ÃÇ
ùëÅ,ùëö
, ùë¶, ùëßÃÇ
ùëÅ,ùëö
, ùúâùëõ‚Ä≤ ,ùë° )}
,  ‚àÄùëö ‚àà ùëÄ, ‚àÄùë° ‚àà ùëá ,
(15)
and bound estimation stage. In line 3 of Procedures 1 and 2, a risk- neutral or a risk-averse stochastic programming problem is solved. Each of these problems can be solved directly using an MILP solver or by decomposition. We adopt the latter and use the L-Shaped method pro- posed in the seminal work of Van Slyke and Wets (1969). This choice

ùêøùêµ
ùëÅ ‚Ä≤ ,ùëö,ùëá
= 1	ùë§ÃÇ
ùëá ùë°=1
ùëÅ ‚Ä≤ ,ùëö,ùë°
,  ‚àÄùëö ‚àà ùëÄ.	(16)
is supported by a previous successful application of this method in solv- ing large scale problems (Lima et al., 2018). The L-Shaped method is

Note that the estimator ùêøùêµ
ùëÅ ‚Ä≤ ,ùëö,ùëá
is associated with the solution of the
an extension of Benders decomposition (Benders, 1962) for two-stage
stochastic programming problems, which is straightforward to describe

optimization replication with index ùëö. To generate a single estimator of
the lower bound (from the ùëÄ bounds ùêøùêµùëÅ ‚Ä≤ ,ùëö,ùëá ), the first-stage solution
using problem (23):

that corresponds to the maximum value of ùêøùêµùëÅ ‚Ä≤ ,ùëö,ùëá is selected and for
max
‚ä§ + ‚ä§
+ (1 ‚àí
) ‚àëùëÅ [	(
ùëõ)]

{ 1 ‚àëùëÅ ‚Ä≤	}
+ùõΩ
ùúÇ ‚àí 1 ‚àí
ùëù (ùúÇ ‚àí ùëÑ(ùë•, ùëß, ùúâùëõ))+
ùõº ùëõ=1
(23)

ùë§ÃÇ ùëÅ ‚Ä≤ ,ùë°‚Ä≤ = max
ùëÅ ,ùë°
ùëÅ ‚Ä≤
ùëõ‚Ä≤ =1
ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâùëõ ,ùë°)
,  ‚àÄùë°‚Ä≤ ‚àà ùëá ‚Ä≤,	(17)
ùë†.ùë°.	ùê¥ùë• + ùêµùëß ‚â§ ùëè
ùë• ‚àà ‚Ñùùëõ1 , ùëß ‚àà ùîπùëõ2 , ùúÇ ‚àà ‚Ñù,

where (ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ ) is the first-stage solution selected. For this first-stage
solution, the estimator of the lower bound is given by
 1 ‚àë
+
where ùëÑ(ùë•, ùëß, ùúâùëõ) is defined as
ùëÑ(ùë•, ùëß, ùúâùëõ) ‚à∂=	max	ùëêÃÉ‚ä§ùë¶ùëõ	‚é´

ùêøùêµ ‚Ä≤  ‚Ä≤ =
ùë§ÃÇ
‚Ä≤ ‚Ä≤ ,	(18)
ùë¶ùëõ	ùëõ	‚é™

and the sample variance of ùêøùêµ ‚Ä≤
‚Ä≤ through
ùë¶ùëõ = ‚Ñéùëõ ‚àí ùë•  ‚é¨‚é™

2	2	1
‚àëùëÄ (



ùëÅ ,ùëá
)2
ùë¶ùëõ
‚àà ‚Ñùùëõ3

with the confidence interval defined as
[ùêøùêøùêµùëÅ ‚Ä≤ ,ùëá ‚Ä≤ , ùëàùêøùêµùëÅ ‚Ä≤ ,ùëá ‚Ä≤ ] ‚à∂= [ùêøùêµùëÅ ‚Ä≤ ,ùëá ‚Ä≤ ‚àí ùë°ùëá ‚àí1,ùõº‚Ä≤ ùë†ùëÅ ‚Ä≤,ùëá ‚Ä≤ , ùêøùêµùëÅ ‚Ä≤,ùëá ‚Ä≤ + ùë°ùëá ‚àí1,ùõº‚Ä≤ ùë†ùëÅ ‚Ä≤ ,ùëá ‚Ä≤ ].
(20)
This approach to calculate the point estimate of the lower bound is based on Linderoth et al. (2006).
Upper bound on the gap between ùë§‚àó and ùîºùúâ [ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâ)]

of a solution (ùë•ÃÇùëÅ , ùëßÃÇùëÅ ), which defines an estimator of an upper bound on In Mak et al. (1999), it is derived a method for assessing the quality
the following gap:
ùëîùëéùëù(ùë•ÃÇùëÅ , ùëßÃÇùëÅ ) ‚à∂= ùë§‚àó ‚àí ùîºùúâ ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâ) .	(21) This gap represents the difference between the true optimal solution ùë§‚àó and the true optimal solution ùîºùúâ ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâ) for (ùë•ÃÇùëÅ , ùëßÃÇùëÅ ). The upper
bound, , on the ùëîùëéùëù(ùë•ÃÇ , ùëßÃÇ ) is defined as (Mak et al., 1999):
tion, meaning one subproblem for each element ùëõ = 1, ‚Ä¶ , ùëÅ of the sam- ple. This formulation moves the variable ùë¶ùëõ to the subproblems. The
L-Shaped method is an iterative method, where in each iteration the following steps are performed:
A relaxation of problem (23), called master problem, is solved. This
volving ùëÑ(ùë•, ùëß, ùúâùëõ), and thus, its objective function value provides an master problem is constructed by outer-approximating the terms in-
solution of this master problem is the first-stage variables: (ùë•, ùëß). upper bound on the objective function value of problem (23). The
The subproblems (24) are solved independently for fixed values of the first-stage variables obtained from the master problem.
The VaR and CVaR of the second stage profit are evaluated based on the distribution of the second stage profits (the objective function values of the subproblems), and they are used in the next step.
The upper and lower bounds are calculated and the method termi- nates if the gap between these bounds reaches a specified threshold.
The dual variables solution of the subproblems are used to build the
outer-approximations to be added to the master problem in the next

Óà≥ ‚à∂= ùîº[
max
ùë•,ùë¶,ùëß‚àà ùëÅ
1 ùëÅ
ùëÅ ùëõ=1
ùúô(ùë•, ùë¶, ùëß, ùúâùëõ)} ‚àí
1 ùëÅ
ùëÅ ùëõ=1
ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâùëõ)]
iteration. In the next iteration, these outer-approximations ‚Äúcut‚Äù the solution of the master problem obtained in step 1.


	

Procedure 1 Proposed implementation of an SAA method. Input: ùëÄ
samples of size ùëÅ : ùúâùëõ,ùëö, ùëõ = 1, ‚Ä¶ , ùëÅ, ùëö = 1, ‚Ä¶ , ùëÄ ; ùëá samples of size
gap between ùë§‚àó and ùîºùúâ ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâ) (Bayraksan and Morton, 2006; Procedure 2 Proposed implementation of the upper bound on the

1, ‚Ä¶ , ùëÅ ‚Ä≤, ùë°‚Ä≤ = 1, ‚Ä¶ , ùëá ‚Ä≤; and confidence level. Output: first-stage solu-
tion, point estimates of bounds on the optimal objective function value
ùë§‚àó, and confidence intervals.
1: for ùëö = 1 to ùëÄ do
2:	Initialize the L-Shaped method with (ùë•ÃÇùëèùëíùë†ùë° , ùëßÃÇùëèùëíùë†ùë° ), if this solution
  
ùëÅ : ùúâùëõ,ùëö, ùëõ = 1, ‚Ä¶ , ùëÅ, ùëö = 1, ‚Ä¶ , ùëÄ ; and confidence level. Output: upper bound on the ùëîùëéùëù(ùë•ÃÇùëÅ , ùëßÃÇùëÅ ) = ùë§‚àó ‚àí ùîºùúâ [ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâ]
1: for ùëö = 1 to ùëÄ do
2:	Initialize the L-Shaped method with (ùë•ÃÇùëÅ , ùëßÃÇùëÅ ) or if available, with
(ùë•ÃÇùëèùëíùë†ùë° , ùëßÃÇùëèùëíùë†ùë° )

is available
ùëÅ,ùëö
ùëÅ,ùëö
ùëÅ,ùëö
ùëÅ,ùëö

3:	Solve using the L-Shaped method each MILP problem with the
3:	Solve using the L-Shaped method each MILP problem with the
sample with size ùëÅ of i.i.d. ùúâùëõ,ùëö:

sample with size ùëÅ of i.i.d. ùúâùëõ,ùëö:
ùëÅ
ùë§ÃÇ
=	max
{  1 ‚àëùëÅ
ùúô(ùë•, ùë¶, ùëß, ùúâùëõ,ùëö)}
(28)

ùë§ÃÇ
ùëÅ,ùëö
=	max
ùë•,ùë¶,ùëß‚àà
1	ùúô(ùë•, ùë¶, ùëß, ùúâùëõ,ùëö)
ùëÅ
(25)
ùëÅ,ùëö
ùë•,ùë¶,ùëß‚ààÓâÉ
ùëÅ ùëõ=1

4:	Let (ùë•ÃÇ
, ùë¶ÃÇùëõ
ùëÅ,ùëö
, ùëßÃÇ
ùëõ=1
) be the optimal solution from (25)
4:	Let (ùë•ÃÇ
ùëÅ,ùëö
ùëõ
ùëÅ,ùëö
, ùëßÃÇ
ùëÅ,ùëö
) be the optimal solution of (28)

ùëÅ,ùëö
ùëÅ,ùëö
ùëÅ,ùëö
5:	if ùë§ÃÇ ùëÅ,ùëö > ùë§ÃÇ ùëÅ,ùëö‚àí1 then

5:	if ùë§ÃÇ ùëÅ,ùëö > ùë§ÃÇ ùëÅ,ùëö‚àí1 then
6:	(ùë•ÃÇùëèùëíùë†ùë° , ùëßÃÇùëèùëíùë†ùë° ) ‚Üê (ùë•ÃÇùëÅ,ùëö , ùëßÃÇùëÅ,ùëö )

6:	(ùë•ÃÇùëèùëíùë†ùë° , ùëßÃÇùëèùëíùë†ùë° ) ‚Üê (ùë•ÃÇ
, ùëßÃÇ	)
ùëÅ,ùëö  ùëÅ,ùëö

ùëÅ,ùëö
7:	end if
ùëÅ,ùëö
ùëÅ,ùëö
ùëÅ,ùëö
7:	end if
8:	Solve each LP subproblem with the sample with size ùëÅ of i.i.d.

8:	if (ùë•ÃÇùëÅ,ùëö , ùëßÃÇùëÅ,ùëö ) is a new solution then
9:	for ùë° = 1 to ùëá do {Lower bound estimation}
10:	Solve each LP subproblem with the sample with size ùëÅ ‚Ä≤ of
i.i.d. ùúâùëõ‚Ä≤ ,ùë° :
ùúâùëõ,ùëö :
max
ùëÅ,ùëö
1 ùëÅ
ùëÅ ùëõ=1
ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâùëõ,ùëö)}
(29)

ùë§ÃÇ
ùëÅ ‚Ä≤ ,ùëö,ùë°
=  max
ùëÅ ,ùëö,ùë°
 1
ùëÅ ‚Ä≤
ùëÅ ‚Ä≤
ùëõ‚Ä≤ =1
ùúô(ùë•ÃÇ
ùëÅ,ùëö
, ùë¶, ùëßÃÇ
ùëÅ,ùëö
, ùúâùëõ‚Ä≤ ,ùë° )}
(26)
9:	Evaluate
1 ùëÅ
ùëÅ,ùëö = ùëÅ
ùúô(ùë•ÃÇùëÅ,ùëö , ùë¶ÃÇùëõ
, ùëßÃÇùëÅ,ùëö , ùúâùëõ,ùëö) ‚àí ùúô(ùë•ÃÇùëÅ , ùë¶ÃÇùëõ , ùëßÃÇùëÅ , ùúâùëõ,ùëö)]
(30)

11:	end for
10: end for
ùëõ=1

12:	Evaluate ùêøùêµùëÅ ‚Ä≤ ,ùëö,ùëá using (16)
13:	if ùëö = 1 then
14:	(ùë•ÃÇùëÅ , ùëßÃÇùëÅ ) ‚Üê (ùë•ÃÇùëÅ,ùëö , ùëßÃÇùëÅ,ùëö )
11: Evaluate the statistical point estimate for the expected gap and sam- ple variance
ùëÄ

15:	else if ùëö > 1 and ùêøùêµ
ùëÅ ‚Ä≤ ,ùëö,ùëá
> ùêøùêµ
ùëÅ ‚Ä≤ ,ùëö‚àí1,ùëá
then
ùëÅ,ùëÄ
=  1	Óà≥
ùëÄ
ùëÅ,ùëö
(31)

16:	(ùë•ÃÇùëÅ , ùëßÃÇùëÅ ) ‚Üê (ùë•ÃÇùëÅ,ùëö , ùëßÃÇùëÅ,ùëö )
17:	end if
18:	end if
(ùë†ùëÄ )2 =
ùëö=1
	1	 ùëÄ
ùëÄ (ùëÄ ‚àí 1) ùëö=1
ùëÅ,ùëö
	2
ùëÅ,ùëÄ
(32)

19: end for
12: return upper bound ùëàùê∫ùëÅ,ùëÄ
ùëÅ,ùëÄ
+ ùë°
ùëÄ ‚àí1,ùõº ùë†ùëÄ

20: Evaluate ùëàùêµùëÅ,ùëÄ using (12) and the confidence interval using (14)		
21: for ùë°‚Ä≤ = 1 to ùëá ‚Ä≤ do {Lower bound estimation}
22:	Solve each LP subproblem with the sample with size ùëÅ ‚Ä≤ of i.i.d.

ùúâùëõ‚Ä≤ ,ùë°‚Ä≤ :
ùë§ÃÇ ùëÅ ‚Ä≤,ùë°‚Ä≤ =  max
ùëÅ ,ùë°
 1
ùëÅ ‚Ä≤
ùëÅ ‚Ä≤
ùëõ‚Ä≤ =1
ùúô(ùë•ÃÇ , ùë¶, ùëßÃÇ , ùúâùëõ‚Ä≤ ,ùë°‚Ä≤ )}
(27)
pabilities available. In this work, the parallelization is exploited in the solution of the independent LP subproblems in two places: 1) within the L-Shaped method; and 2) at the lower bound estimation, where for each
first-stage solution, ùëÅ ‚Ä≤ LP subproblems are solved.

23: end for
24: Evaluate ùêøùêµùëÅ ‚Ä≤ ,ùëá ‚Ä≤ using (18) and the confidence interval using (20)
In Procedures 1 and 2, we implement an initialization step that uses

25: return (ùë•ÃÇùëÅ
, ùëßÃÇùëÅ
), ùëàùêµùëÅ,ùëÄ
, ùêøùêµ
ùëÅ ‚Ä≤ ,ùëá
‚Ä≤ , and confidence intervals
the best first-stage solution obtained in a replication ùëö‚Ä≤ < ùëö to initialize the L-Shaped method in replication ùëö. This initialization is indicated in
line 2 of Procedure 1, where (ùë•ÃÇùëèùëíùë†ùë° , ùëßÃÇùëèùëíùë†ùë° ) is the best first-stage solution.

ùëÅ,ùëö  ùëÅ,ùëö

The outer-approximations are known as optimality cuts. These cuts require that all subproblems in step 2 are feasible, otherwise, a feasi- bility subproblem needs to be solved for each infeasible subproblem. The optimal values of the dual variables of these feasibility subprob- lems are then used to build cuts, known as feasibility cuts, to be added to the master problem in the next iteration. In the problems studied in this work, the subproblems are always feasible for all values of the first- stage variables. This is due to the possibility to buy electricity from the pool, which is implemented in the subproblems to satisfy contracts de- cided in the master problem. An algorithmic description, specific prob- lem formulations, expressions for bounds, and details on handling the
variable ùúÇ and the CVaR calculation can be found in Lima et al. (2018),
and the outer-approximations derivations and convergence analysis in
Van Slyke and Wets (1969), Birge and Louveaux (2011), and Kall and Mayer (2011).
Clearly, the solution of multiple replications of risk-averse prob- lems in Procedures 1 and 2 is a computationally demanding pro- cess, especially for MILP problems. Therefore, implementations of Procedures 1 and 2 should include strategies to reduce their overall com- puting time. An attractive approach is to parallelize the implementation of these procedures taking advantage of the modeling and hardware ca-
tion replication (ùëö = 1). In contrast, in Procedure 2, by construction, the We note that this first-stage solution is not available in the first optimiza- solution (ùë•ÃÇùëÅ , ùëßÃÇùëÅ ) is available at the beginning of the procedure, thus,
the initialization mentioned in line 2 is active from the first replication. The initialization step entails that in the first iteration of the L-Shaped method, the best first-stage solution is assigned to the first-stage solu- tion, instead of finding a solution using the master problem. With this initialization step, the initial lower bound of the L-Shaped method, cal- culated after solving the LP subproblems, is generally better than the one calculated using the solution of the master problem in the first iter- ation. Note that the corresponding computational gain is multiplied by the number of optimization replications.
In the bound estimation stage, the bounds described in Sections 4.2‚Äì
4.4 are evaluated using the first-stage solutions and the objective func- tion values obtained from the optimization stage. In Procedure 1, the lower bound estimation is computationally more demanding than the upper bound estimation. Therefore, we implement another important time saving strategy: the lower bound estimation is only carried out for
perform the lower bound estimation only for ùúñ-different first-stage so- new distinct first-stage solutions. Note that an alternative would be to
lutions. This alternative would avoid the computing time for the lower bound estimation for slightly different first-stage solutions. In the dis-



cussion of the results, the impact of avoiding the lower bound estimation for repeated solutions on the computing time is analyzed and situations where it is relevant are identified.
The risk-averse formulations involving the CVaR measure add an ex- tra burden to the L-Shaped method and lower bound estimation. The
tional average of the ùëÑ(ùë•, ùëß, ùúâùëõ) (defined in (24)). To reduce this evalu- evaluation of the CVaR measure requires the calculation of the condi-
plemented, where the evaluation of the CVaR for ùõº > ùõº‚Ä≤ re-uses the in- ation time, an eÔ¨Écient approach in the lower bound estimation is im-


T P
a ùúé-algebra and P a probability measure. Let ùêº = [ùëé, ùëè] be an interval of ‚Ñù. ùëã is a square-integrable stochastic process that is assumed to be defined on ùêº . The Karhunen‚ÄìLo√®ve decomposition of the process can be
expressed as
‚àû
ùëã(ùë°) = ùúá(ùë°) +	ùúÜùëñ ùëâùëñ (ùë°)ùúâùëñ ,	(36)
ùëñ=1

formation of the distribution of the previous CVaR evaluation for ùõº‚Ä≤.
With this overall approach, we provide a full characterization of the
where (ùëâùëñ )‚àû
is a Hilbert basis of ùêø2(ùêº ), the random variables (ùúâùëñ )‚àû are
ùëñ=1 ‚àû

solution of our problem, which encompasses the following information:
approximation of the optimal solution, in terms of the first-stage variables;
mutually independent, with zero mean and unit variance, and (ùúÜùëñ )ùëñ=1
are positive constants in a decreasing order (ùúÜ1	ùúÜ2	‚ãØ 0). Under suÔ¨Écient regularity of the covariance ùê∂, the pairs (ùúÜùëñ , ùëâùëñ )‚àû are solutions
of the following Fredholm integral equation of the second kind

point estimate and confidence interval for the upper bound on the true optimal objective function value;
ùë° ‚ààùêº
ùê∂(ùë°, ùë°‚Ä≤)ùëâùëñ (ùë°‚Ä≤)dùë°‚Ä≤ = ùúÜùëñ ùëâùëñ (ùë°).	(37)

point estimate and confidence interval for the lower bound on the
true optimal objective function value;
The random variable ùúâùëñ is defined by

point estimate on the upper bound on the gap between the true op-
ùúâ =  1  ‚à´
ùëâ (ùë°)(ùëã(ùë°) ‚àí ùúá(ùë°))dùë°.	(38)

timal objective function value and the expected optimal objective
ùëñ
ùúÜùëñ
ùëñ
ùë°‚ààùêº

function value associated with a first-stage solution;
Note that if ùëã is a Gaussian process, then the random variables (ùúâùëñ )‚àû

Therefore, this information provides inference statistics on the solu- tions that are more informative than the single optimal objective func- tion value and corresponding first-stage variables of a deterministic problem.
In the next section, we describe the sampling procedure to generate
follow the standard Gaussian distribution.

2.3. Discretization
Let (ùë†ùëñ )ùëõ  be a regular discretization of the interval ùêº such that
ùëé = ùë†0 ‚â§ ùë†1 ‚â§ ‚ãØ ‚â§ ùë†ùëõ = ùëè,  and  ùë†ùëñ+1 ‚àí ùë†ùëñ = Œîùë°,	(39)

the samples of the wind and electricity prices.
and let (ùë°ùëñ )ùëõ
be the midpoints (ùë†ùëñ ‚àí ùë†
ùëñ‚àí1
)‚àï2. Evaluating the integral in

Sampling

Sampling the electricity prices

We generate the samples for the electricity prices from an ARIMA model that is fitted to an electricity price time series. Specifically, the samples are drawn by sampling the error term of the ARIMA model; see Conejo et al. (2010) for a discussion on this type of approach. Specific details for the data used are given in Section 6.1.1.

Sampling the wind speed with a truncated Karhunen‚ÄìLo√®ve expansion

In this section, we briefly introduce the KLE, and in Section 6,
Eq. (37) with a midpoint-quadrature formula at every ùë°ùëó yields
ùëõ
ùê∂(ùë°ùëñ , ùë°ùëó )ùëâùëñ (ùë°ùëó )Œîùë° = ùúÜùëñ ùëâùëñ (ùë°ùëñ ).	(40)
ùëó=1
Let the matrix ùêæ ‚àà ‚Ñùùëõ√óùëõ and the vector ùëäùëñ ‚àà ‚Ñùùëõ be defined by
ùêæùëñùëó = Œîùë°ùê∂(ùë°ùëñ , ùë°ùëó ),  and  ùëäùëñùëó = ùëâùëñ (ùë°ùëó ).	(41)
The discretized Fredholm integral equation leads to the following alge- braic eigenvalue problem
ùêæùëäùëñ = ùúÜùëñùëäùëñ .	(42)
The time discretization followed by a truncation of the sum yield there- fore the approximations

we provide additional information regarding the wind data used. See Ma√Ætre and Knio (2010, Section 2.1) for a presentation on KLE.
ùëã(ùë°ùëñ ) ‚âà ùúá(ùë°ùëñ ) +
ùëõ	
ùúÜùëó ùëäùëóùëñùúâùëó ‚âà ùúá(ùë°ùëñ ) +
ùëó=1
ùëü
ùëó=1
‚àöùúÜùëó ùëäùëóùëñùúâùëó .	(43)

Wind speed model
Assuming that the wind speed ‚Ñé(ùë°) is always strictly positive, we
adopt here a log-normal model where ùëã(ùë°) = log(‚Ñé(ùë°)) is a Gaussian pro-
Given a tolerance ùúñ, the constant ùëü is chosen such that
1
ùëñ=ùëü+1	2 ‚â§

cess with mean function ùúá(ùë°) and covariance function ùê∂(ùë°, ùë°‚Ä≤), which are
ùëõ
ùëñ=1
ùúÜùëñ
ùúñ,	(44)

approximated in our application using a sample (ùë•ùëñ(ùë°))ùëÅ  and the empir-	2

ical estimation
ùëñ=1
ensuring that the relative ùêø
error between the ùëõ-terms and the ùëü-terms

ùúá(ùë°) ‚âà
1 ùëÅ
ùëÅ ùëñ=1
ùë•ùëñ(ùë°)	(33)
ùëÅ
approximations is less than ùúñ.
Numerical experiments

The results presented in this section demonstrate the new features

and  ùê∂(ùë°, ùë°‚Ä≤) ‚âà   1   ‚àë(ùë•ùëñ(ùë°) ‚àí ùúá(ùë°))(ùë•ùëñ(ùë°‚Ä≤) ‚àí ùúá(ùë°‚Ä≤)).	(34)
Given a time interval uniformly discretized (ùë°ùëñ )ùëõ  with a resolution
Œîùë° = 1 h, the rest of Section 5.2 is dedicated to the KLE-based approxi-
mation of the wind speed model under the form
implemented in the proposed procedures and provide a complete set of statistical results to better support the decision-maker. The objectives of the experiments are fourfold:
to demonstrate the positive impact of the proposed strategies on the computing time;

‚Ñé(ùë°ùëñ ) ‚âà exp
(ùúá(ùë°ùëñ ) +
ùëü
ùëñ=ùëó
‚àöùúÜùëó ùëäùëóùëñùúâùëó
),	(35)
to analyze the performance of the optimization stage for risk-averse approaches;
to compute high-quality solutions for the VPP problem;

where (ùúâùëñ )ùëü
are independent random variables drawn according to the
to assess those solutions using statistic estimators and confidence

standard normal distribution.	intervals.



Table 2
Summary of the specifications of the thermal unit in Cases 1 and 2.



The first and second objectives above are related to the first contribu- tion of this work and the third and fourth objectives to the second con- tribution. In terms of the organization of the results, we discuss the com- putational performance of Procedure 1 in Section in 6.2, the objective function values in Section 6.3, the first-stage solutions in Section 6.4, and the maximum gaps obtained in Section 6.5.
sample size ùëÅ on the computing time of the L-Shaped method and the More specifically, in Procedure 1, we analyze the impact of a) the variance of the solutions; b) the sample size ùëÅ ‚Ä≤ on the computing time and variance of the solutions; c) the number of replications ùëá and ùëá ‚Ä≤ on
the  sample  size  ùëÅ  on  the  upper  bound  estimation. the lower bound estimation. In Procedure 2, we study the influence of
In a supplementary document, detailed experimental results that support the ones presented in this section are provided.

Description of the case studies

We consider two cases pertaining to the VPP described in Section 2, which we refer to as Cases 1 and 2. In both cases a similar wind farm and a similar pumped-storage hydro unit are considered. However, the specifications of the thermal unit in each case are different in terms of initial state, operational constraints, and costs. Table 2 specifies the differences in terms of capacity and costs between the thermal unit in Cases 1 and 2.
For the same samples of the wind speed and electricity prices, these differences induce a distinct reaction of the VPP. Furthermore, the higher generation cost of the thermal unit in Case 2 leads to a situa- tion where the gap between the electricity price and generation costs is smaller than the gap in Case 1. The results presented in this section show that the two cases are suÔ¨Éciently distinct to give a broad view on the performance of the methods used in this work.
The solutions of interest for the VPP problem are the optimal first- stage solutions and the performance indices expected profit and the CVaR of the profit for different quantiles. Given the number of elements in each sample, and the fact that in practice, the second-stage variables have to be adjusted to the future realization of the random variables, these variables are less meaningful and thus their values are not re- ported.

Wind speed and electricity prices data
We consider a time horizon of 168 h, which corresponds to the week of August 25‚Äì31, 2014. The ARIMA model uses the same structure and fit of the model proposed in Lima et al. (2018). The electricity price time series has 12 weeks before the week studied, from the Iberian Peninsula electricity market (Iberian Electricity Market, 2015).
The raw data for the wind speed for a specific wind farm location consists of a wind speed ensemble with 51 members obtained from the European Centre for Medium Range Weather Forecasts (ECMWF). We use the wind speed ensemble and the KLE to generate additional samples of the wind speed for the SAA methodology. The electricity prices are considered independent of the wind speed available at the location of the considered VPP, due to the small capacity of the VPP in each case study, which has no market power to influence the electricity prices.
Table 3
Size of the extensive form and problems within the L-Shaped method.










‚Ä† ‚Äì Sizes refer to the second iteration of the L-Shaped method. ‚ãÜ ‚Äì Size refers to the dual of (24). NCNST ‚Äì number of constraints plus objec-
tive function; NVAR ‚Äì number of total variables; 0‚Äì1 NVAR ‚Äì number of binary variables.


Setup of the parameters of the procedures
The risk-neutral and risk-averse stochastic programming problems are solved with an L-Shaped based method with single optimality cuts.
10,800 s, a maximum gap between the bounds of 1√ó10‚àí4%, and a max- For this method, the stop criteria are a maximum wall-clock time of
imum number of iterations of 5000. Note that this gap is related to the bounds on the objective function value within the L-Shaped method for a given sample. These bounds are not related to the bounds described in Sections 4.2 and 4.3.
following parameters ùëÄ = 30 (number of optimization replications), We perform a sensitivity analysis with Procedure 1 combining the
ùëÅ ‚àà {10, 50, 100, 500, 5000} (size of the samples used in each optimiza- tion replication), ùëá ‚àà {10, 30}, ùëá ‚Ä≤ ‚àà {10, 30} (number of replications in the lower bound estimation), ùëÅ ‚Ä≤ ‚àà {5000, 25, 000} (size of the samples
used in the lower bound estimation).
We	consider	four	combinations	of	(ùõΩ, ùõº) ‚àà
{(0, ‚àí), (0.5, 0.9), (1, 0.9), (1, (ùëÅ ‚àí 1)‚àïùëÅ )} for the optimization replica- tion. The case with ùõº = (ùëÅ ‚àí 1)‚àïùëÅ corresponds to the maximization
of the worst profit consistently with the definition of the CVaR. In the lower bound estimation, for each first-stage solution we evaluate point estimates and confidence intervals of the CVaR of the profit for
ùõº ‚àà {0.9, 0.95, (ùëÅ ‚Ä≤ ‚àí 1)‚àïùëÅ ‚Ä≤}.
For Procedure 2, we set ùëÄ = 30 (number of replications of the op- timization) and ùëÅ ‚àà {500, 5000} (size of the samples). All confidence
intervals presented correspond to 95%.
A workstation with 40 Intel Xeon CPU E5-2680 v2 @ 2.80 GHz pro- cessors, and 125.8 Gb of RAM was used and the solution of the LP sub- problems was distributed among the 40 CPUs. The MILP and LP prob- lems were solved with CPLEX 12.7.1.0 using the GAMS/GRID/GUSS ca- pabilities to distribute the solution of the LP subproblems.

Computational performance

In this subsection, we first present the dimensions of the problems considered and discuss the choice of the L-Shaped method over the di- rect solution of the extensive form. Next, the benefits of the proposed initialization of the L-Shaped method are shown and then analysis on the overall performance of Procedure 1 is provided.
lions of constraints and variables for samples with ùëÅ = 5000, and that In Table 3, we show that the size of the extensive form reaches mil-
master   problem   and   ùëÅ    smaller   subproblems. the L-Shaped method decomposes the extensive form into one smaller
We adopt the L-Shaped variant that provided the best performance in Lima et al. (2018), i.e., Algorithm 1, which corresponds to using a single optimality cut for each of the expectation and CVaR operators and calculating VaR based on the solution of the subproblems, rather than
using VaR as a first-stage variable. In that work it is shown that for ùõΩ = 0,
the L-Shaped method with an eÔ¨Écient parallelization solution of the
the extensive form. Whereas for ùõΩ ‚àà {0.1, 0.5, 0.9, 1.0}, ùõº = 0.9, sample subproblems is one order of magnitude faster than the direct solution of


Fig. 1. Average wall-clock time for 30 opti- mization replications for the combinations of sample sizes and risk parameters studied.











Table 4
Ratio between the total wall-clock time for 30 optimization repli-
solution (T0) in the L-Shaped method. ùëÄ  = 30. cations using an initial solution (Tinit) and without using an initial



sizes of 5100 elements, and maximum wall clock time of 7200 s, the MILP solver applied to the extensive form did not find a feasible solution for four case studies similar to the two considered in this work. We refer the reader to that work for detailed computational results showing the superior performance of the L-Shaped method over solving directly the extensive form.

Initialization of the optimization stage
Table 4 shows the ratios between the total wall-clock time with and without initialization for 30 optimization replications.
These results cover four combinations of risk parameters using two sample sizes ‚Äì 500 and 5000 elements ‚Äì over 30 replications. A ratio smaller than one means that the initialization is effective in reducing the total computing time. Overall, the results suggest that the initializa- tion reduces the required computing time. The exception is the formula-
tion with ùõΩ = 1 and ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, (last row of Table 4). This peculiar
behavior occurs because convergence is not reached for the first-stage
solution over the replications, and thus, one solution from one repli- cation is not necessarily a good initial solution for another replication. For the remaining risk metrics, there is convergence for the first-stage variables, and therefore, the initialization has a positive impact on com- puting time. This is further discussed in Section 6.2.4.

Performance of the optimization stage
Fig. 1 a and b shows for Cases 1 and 2, respectively, the average wall-clock time for 30 optimization replications as a function of the risk parameters and size of the sample. These results show that with a sam- ple with 10 elements, the average wall-clock time for Case 1 is approxi- mately 1 s, independently of the risk parameters. However, this comput-
ing time increases with the sample size, with the formulation with ùõΩ = 1,
ùõº = (ùëÅ ‚àí 1)‚àïùëÅ exhibiting a steeper increase for an average of 3146 s.
For Case 2 the average wall-clock time for the formulations with the
cuses on the results of the formulations with ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ . CVaR is independent of the size of the sample. The next sub-section fo-
Performance of the optimization stage for ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ
The formulation with ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ exhibits some relevant
results that are worth discussing. First of all, for the formulations with
which requires resources, however, for ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ this evalu- the CVaR, the L-Shaped method evaluates the CVaR in each iteration,
ation is straightforward. In general, comparing the formulations with
ùõΩ = 0 and ùõΩ > 0, ùõº < (ùëÅ ‚àí 1)‚àïùëÅ in terms of computing time, we can
demanding. For example, in Fig. 1a for ùëÅ = 500, the computing times see that the CVaR specific calculation is not computationally the most for ùõΩ = 0 and ùõΩ > 0, ùõº < (ùëÅ ‚àí 1)‚àïùëÅ are similar. On the other hand, for
ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ the average number of iterations is 5.7, whereas for ùõΩ = 1, ùõº = 0.9 it is 2.0. Therefore, the higher computing times ob- tained with ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ do not arise from the CVaR evalua-
tion, but rather from the number of iterations executed by the L-Shaped method, as discussed below.
For Case 1, for ùëÅ = 10, the L-Shaped method requires on average 2.1
iterations to meet the stopping criteria, while for ùëÅ = 5000 it requires on
average 8.6 iterations. Fig. 2 presents the profiles of the bounds in the
L-Shaped method for the optimization replications with the lower and higher number of iterations within each optimization replication with
ùëÅ = 10 and ùëÅ = 5000. The figures for Case 1 show that for ùëÅ = 10 the
number of iterations ranges from 2 to 4, while for ùëÅ = 5000 it ranges
demands extra iterations, since for ùõΩ = 0 and ùëÅ = 5000, the L-Shaped from 2 to 21 iterations. However, it is not the size of the sample that
method requires on average 2.0 iterations to meet the stopping criteria. It is rather the elements within large samples that have an impact on
of  the  CVaR  of  the  profit  with  ùõº  =  (ùëÅ  ‚àí  1)‚àïùëÅ . the performance of the L-Shaped method if applied to the maximization
For Case 2, Fig. 1b shows that the average wall-clock times for the formulations with the CVaR are independent of the size of the sample.
In the specific case of ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, for ùëÅ = 10, the L-Shaped
ria, whereas for ùëÅ = 5000 it requires on average 11.4 iterations. These method requires on average 101.2 iterations to meet the stopping crite-
results combined with the results in Fig. 1b indicate that 1) Case 2 forces the L-Shaped method to perform more iterations than Case 1, for the same samples, which is explained by the higher generation costs of the thermal unit in Case 2; and 2) consequently, for the formulations that maximize the worst profit observation, the L-Shaped method requires additional iterations than the other formulations. Fig. 2c and d shows
number of iterations obtained with ùëÅ = 10 and ùëÅ = 5000. From these the profiles of the optimization replications with the lower and higher
quires few iterations. For example, 10 and 6 for ùëÅ = 10 and ùëÅ = 5000, figures, it is also clear that in some replications the L-Shaped method re-
25  for  ùëÅ  =  10  and  ùëÅ  =  5000,  respectively. respectively, while in others it may require a large number ‚Äì 417 and
Overall, these results show that:
the maximization of the CVaR of the profit with ùõº = (ùëÅ ‚àí 1)‚àïùëÅ
son with ùõΩ = 0. The reason is that in the former problem, the search forces the L-Shaped method to perform more iterations, by compari-
is driven by the worst profit, which forces the L-Shaped method to search for the optimal commitment of the thermal unit or contract se-
case profit. By contrast, the problem with ùõΩ = 0 is driven by the max- lection to respond to the low electricity prices that induce the worst


Fig. 2. Upper and lower bounds (continuous lines) from the L-Shaped method. The dashed line is the objective function for the first-stage solution. In each sub-figure, there are the two
higher number of iterations. For ùëÄ = 30, ùõΩ = 1, optimization replications with the lower and and ùõº = (ùëÅ ‚àí 1)‚àïùëÅ .



















imization of the expected profit that is less sensitive to low electricity price observations;
the size of the samples have an impact on the performance of the L-Shaped method because increasing the sample size increases the likelihood of observations with lower electricity prices;
Table 5
Case 1. Number of successful optimization replications and distinct solutions.
ùëÄ = 30.
ùõΩ = 0	ùõΩ = 0.5, ùõº = 0.9	ùõΩ = 1, ùõº = 0.9	ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ
ùëÅ	SR	DS	SR	DS	SR	DS	SR	DS

the thermal plant with higher generation costs induces more itera-		 tions of the L-Shaped method by comparison with the thermal plant
with lower generation costs; and
the variability in the number of iterations required by the L-Shaped method in each optimization replication is induced by the differ-

ent characteristics of the observations with lower electricity prices among the samples. By different characteristics, we mean that across the samples, the lower electricity prices occur on different hours of the week and distinct minimum values.


Combined performance of the optimization and bound estimation stages
Fig. 3 presents the total wall-clock time required by Procedure 1 and by its two main stages: optimization and bound estimation. This fig-
ure compares the computational performance obtained with ùõΩ = 0 and
ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ . It also shows the impact on the computing time of
bound estimation, from {ùëá , ùëá ‚Ä≤} = 10 and ùëÅ ‚Ä≤ = 5000 to {ùëá , ùëá ‚Ä≤} = 30 and increasing the number of replications and the sample size in the lower
ùëÅ ‚Ä≤ = 25, 000. Using ùëÅ ‚Ä≤ = 25, 000 and {ùëá , ùëá ‚Ä≤} = 30 the overall time in- creases, by comparison with ùëÅ ‚Ä≤ = 5000 and {ùëá , ùëá ‚Ä≤} = 10, but there is no
influence on the optimization time.
These results provide relevant insights regarding the trade-off be- tween the sample size and the overall time required. We can observe that increasing the sample size in the optimization, the overall time
does not monotonically increase. In fact, for ùõΩ = 0, there is a minimum
overall time for ùëÅ = 500, instead of ùëÅ = 10; see Fig. 3a and c. This be-
havior is explained by noting that: 1) the lower bound estimation is
replication; and 2) for ùëÅ = 10, multiple distinct solutions are obtained, only performed when a new solution is obtained from an optimization whereas for ùëÅ = 500, only one distinct solution is obtained. In Fig. 3, as
ùëÅ increases the time required by the optimization stage increases, but not the lower bound estimation time. For ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, there is also a minimum time that corresponds to ùëÅ = 10 for ùëÅ ‚Ä≤ = 5000 and
SR ‚Äì number of successful optimization replications that meet the stop criteria (out of 30); DS ‚Äì number of distinct solutions.

{ùëá , ùëá ‚Ä≤} = 10, and ùëÅ = 50 for ùëÅ ‚Ä≤ = 25, 000 and {ùëá , ùëá ‚Ä≤} = 30; see Fig. 3b and d.
of distinct solutions obtained as a function of ùëÅ and the risk parameters We complement these results by presenting in Table 5 the number
for Case 1.
This table shows that increasing the sample size, the problem con-
except for ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ . For ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, increasing verges to one distinct solution for all combinations of risk parameters;
cific situation, ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, the objective is to maximize the the sample size increases the number of distinct solutions. In this spe-
first-stage solutions for ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ is the hourly commitment single worst observation of the profit. The primary difference among the
of the thermal plant; see also additional results available in the supple- mentary document. This difference suggests that the thermal plant is prone to shutdown and startup to follow the lowest electricity price ob- servation. The samples with more elements have a higher likelihood of lower electricity prices, which from one sample to the other may occur at different hours of the week. Therefore, distinct first-stage solutions emerge among the optimization replications.
The number of distinct solutions obtained with ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ
for ùëÅ = 500 also justifies the worst performance of the initialization im-
plemented in the L-Shaped method. Thus, one solution from one opti-
mization replication may not be a good starting point for an optimiza- tion replication with a different sample.


Fig. 3. Case 1. Wall-clock time as a function of the size of the sample for the optimization.
ùëÄ = 30.





























Fig. 4. Case 2. Wall-clock time as a function of the size of the sample for the optimization.
ùëÄ = 30.






















For Case 2 with ùõΩ = 0, the results show that increasing the sample
size for the optimization, the number of distinct solutions decreases,
Fig. 4a and c. However, for ùõΩ = 1 with ùõº ‚àà {0.9, (ùëÅ ‚àí 1)‚àïùëÅ }, the number which means a decrease in the time for the lower bound estimation; see
of distinct solutions is equal to the number of optimization replications, which means that there is no convergence to a distinct solution; see Table 6. Therefore, the computing time for the lower bound estimation is independent of the sample size for the optimization; see Fig. 4b and d.
Objective function values and its bounds

value ùë§‚àó for the different formulations as a function of the samples size This section presents the bounds on the optimal objective function
and the number of replications. Figs. 5 and 6 show the limits of the
mal objective function value ùë§‚àó obtained for Case 1 and Case 2, respec- confidence intervals for the upper and lower bounds on the true opti-
tively. These figures illustrate the impact of the sample size and number
tervals for ùõΩ = 0 and ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ . In the supplementary results of replications used in the lower bound estimation on the confidence in-
document, the bounds for additional risk parameters are presented.
expected profit (ùõΩ = 0), the point estimate of the upper bound on the true A relevant result shows that for the formulation that maximizes the optimal objective function value ùë§‚àó falls within the confidence interval of the upper bound for all ùëÅ tested. Increasing the sample size reduces
confidence intervals. For the formulation with ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, the the confidence interval, converging approximately to the center of the


Fig. 5. Case 1. Limits of the confidence inter- vals on the point estimate of the lower and up-
per bounds (ùêøùêµùëÅ‚Ä≤ ,ùëá ‚Ä≤ and ùëàùêµùëÅ,ùëÄ ) on the true
optimal objective function value (ùë§‚àó) as a func- tion of risk parameters, ùëÅ ‚Ä≤, ùëá , and ùëá ‚Ä≤. ùëÄ = 30.




























Fig. 6. Case 2. Limits of the confidence inter- vals on the point estimate of the lower and up-
per bounds (ùêøùêµùëÅ‚Ä≤ ,ùëá ‚Ä≤ and ùëàùêµùëÅ,ùëÄ ) on the true
optimal objective function value (ùë§‚àó) as a func- tion of risk parameters, ùëÅ ‚Ä≤, ùëá , and ùëá ‚Ä≤. ùëÄ = 30.





















Table 6
Case 2. Number of successful optimization replications and distinct solutions.
ùëÄ = 30.
ùõΩ = 0	ùõΩ = 0.5, ùõº = 0.9	ùõΩ = 1, ùõº = 0.9	ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ
SR ‚Äì number of successful optimization replications that meet the stop criteria (out of 30); DS ‚Äì number of distinct solutions.
point estimate of the upper bound overestimates the true optimal objec-
confidence intervals (for different ùëÅ ). Thereby, increasing the sample tive function value, and the point estimate is not included in all the
size for the optimization decreases the value of the point estimate and range of the confidence intervals.
Figs. 5 and 6 indicate that the confidence interval for the lower
with the samples with ùëÅ ‚Ä≤ = 5000, {ùëá , ùëá ‚Ä≤} = 10. For example, this can be bound on the true optimal objective function value is underestimated
seen comparing in Fig. 5a and b the confidence interval for the lower bound represented by the dashed lines. These results indicate that for
ùëá ‚Ä≤ = 10 there is a bias in the estimation of the lower bound on the true
optimal objective function value. However, as ùëÅ ‚Ä≤ is increased to 25,000


Table 7
Case 1. First-stage solutions and point estimates of the lower bound on the true optimal objective function value (ùêøùêµùëÅ‚Ä≤ ,ùëá ‚Ä≤ ) with confidence intervals. ùëÅ ‚Ä≤ = 25, 000, {ùëÄ, ùëá , ùëá ‚Ä≤} = 30.

First-stage solutions (aggregated)	CI, [LLB,ULB]

CI ‚Äì Confidence interval, LLB and ULB as in (20), UT ‚Äì percentage of up-time of the thermal unit, SUP/SD ‚Äì number of startups/shutdowns of the thermal unit, SELLC/BUYC ‚Äì power sold/bought through contracts.


and {ùëá , ùëá ‚Ä≤} to 30, the confidence interval of the lower bound converges with the confidence interval of the upper bound.
Note that for the optimization replications where the L-Shaped method did not meet the stopping criteria, the upper bound from the L-Shaped method is used to evaluate the point estimate on the upper bound on the true optimal solution. This replacement justifies the larger range of the confidence interval for the upper bound for Case 1 with
ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, ùëÅ = 5000 in Fig. 5c and d, and for Case 2 with
ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, ùëÅ ‚àà {10, 5000} in Fig. 6c and d.
Overall, the convergence of the bounds for ùëÅ ‚Ä≤ = 25, 000, {ùëá , ùëá ‚Ä≤} = 30 indicate that high-quality solutions are obtained, which are further
assessed in the next sub-section.





First-stage solutions

Tables 7 and 8 provide the best first-stage solution and inference statistics resulting from each set of risk parameters and sample size.
The first stage solutions are given in aggregated form to simplify their presentation. Therefore, to distinguish between equal aggregated solutions that correspond to distinct disaggregated solutions, the point estimates of their lower bounds are provided.
For  Case  1,  for  each  set  of  risk  parameters  (ùõΩ, ùõº) ‚àà
{(0, ‚àí), (0.5, 0.9), (1, 0.9)} there is only one distinct solution, inde- pendently of the sample size for the optimization. However, ùõΩ = 1,
ùõº = (ùëÅ ‚àí 1)‚àïùëÅ has three distinct solutions, which are identified by the three distinct values of ùêøùêµùëÅ ‚Ä≤,ùëá ‚Ä≤ , see Table 7.
For Case 2 with ùõΩ = 0, the same first-stage solution is obtained in-
dependently of the sample size for optimization, while for the other set
of risk parameters, within each set there are slight variations on the power bought through contracts. The slight variations in this variable lead to small variations in the lower bound and confidence interval for the point estimate of the lower bound on the true optimal objective function value.
These results explain why the confidence interval on the point esti- mate for the lower bounds in Figs. 5 and 6 are represented by (almost) horizontal dashed lines.
Gap between ùë§‚àó and ùîºùúâ [ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâ)]

the upper bound on the gap between ùë§‚àó and ùîºùúâ ùúô(ùë•ÃÇùëÅ , ùë¶, ùëßÃÇùëÅ , ùúâ) , as de- We further evaluate each distinct solution using a point estimate on
scribed in Section 4.4. Tables 9 and 10 show this point estimate for
ùëÅ = 500 and ùëÅ = 5000, for Cases 1 and 2, respectively.
For Case 1, a gap of zero is obtained for the solutions with ùõΩ = 0 and
ùõΩ = 0.5, independently of ùëÅ, and for ùëÅ = 5000 for ùõΩ = 1, ùõº = 0.9. For the
other risk parameters, the maximum relative gap is 1.5%.
For Case 2, the solution obtained for ùõΩ = 0 has a gap of zero for both values of ùëÅ . The remaining gaps are relatively small, as the maximum
relative gap is 1.1%.
We also present the wall-clock time required, which consists of the time for the optimization and lower bound estimation. It is clear that the
formulations with ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ are more demanding, in partic-
ular for ùëÅ = 5000. The limiting step in this procedure is the optimization stage, which in Case 1 with ùõΩ = 1, ùõº = (ùëÅ ‚àí 1)‚àïùëÅ and in Case 2 is much
Figs. 3a, b and 4 a, b. For example, in Case 2 with ùëÅ = 500, the optimiza- more demanding than the lower bound estimation, as it can be noticed in tion stage requires on average 1216 s and 20,998 s for ùõº < (ùëÅ ‚àí 1)‚àïùëÅ and ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, respectively, while the lower bound estimation on
average only requires 73 s.
For the assessment of multiple solutions of the same problem, Procedure 2 can be improved by noting that the optimization stage is independent of the solution to assess. Therefore, to assess multiple so- lutions, it is necessary one optimization stage (valid for all solutions) plus one lower bound estimation stage per solution. In this way, and given the computing times for the optimization stage mentioned in the previous paragraph, the computing time required by Procedure 2 could be significantly reduced.
Conceptually, Procedure 1 is oriented to the generation of solutions and specific inference statistics, whereas the objective of Procedure 2 is to assess the solution quality of a given solution. The optimization stage is similar in both procedures, however, the lower bound estimation in Procedure 1 is made for each new solution, whereas in Procedure 2 it is only for the single input solution of the procedure. The common parts between the procedures suggest that they can be merged to take ad- vantage of these similarities to reduce the overall computing time. A merging would require Procedure 1 to be adapted so that during the



Table 8
Case 2. First-stage solutions and point estimates of the lower bound on the true optimal objective function value (ùêøùêµùëÅ‚Ä≤ ,ùëá ‚Ä≤ ) with confidence intervals. ùëÅ ‚Ä≤ = 25, 000, {ùëÄ, ùëá , ùëá ‚Ä≤} = 30.

First-stage solutions (aggregated)	CI, [LLB,ULB]

CI ‚Äì Confidence interval, LLB and ULB as in (20), UT ‚Äì percentage of up-time of the thermal unit, SUP/SD ‚Äì number of startups/shutdowns of the thermal unit, SELLC/BUYC ‚Äì power sold/bought through contracts.



Table 9
Case 1. Distinct first-stage solutions and the upper bound on the absolute gap (ùëàùê∫ùëÅ,ùëÄ ) obtained from Procedure 2.
ùëÄ = 30.
First-stage variables (aggregated)	ùëÅ = 500	ùëÅ = 5000
UT ‚Äì percentage of up-time of the thermal unit, SUP/SD ‚Äì number of startups/shutdowns of the thermal unit, SELLC/BUYC ‚Äì power sold/bought through contracts.



Table 10
Case 2. Distinct first-stage solutions and the upper bound on the absolute gap (ùëàùê∫ùëÅ,ùëÄ ) obtained from Procedure 2.
ùëÄ = 30.
First-stage variables (aggregated)	ùëÅ = 500	ùëÅ = 5000
UT ‚Äì percentage of up-time of the thermal unit, SUP/SD ‚Äì number of startups/shutdowns of the thermal unit, SELLC/BUYC ‚Äì power sold/bought through contracts.



lower bound estimation, the required information can be extracted to evaluate the upper bound on the gap defined in (22).

Conclusions

We presented and applied a methodology based on SAA to generate first-stage solutions and inference statistics for the optimal operation of a VPP. To cope with the computational complexity of the problems ad- dressed, new strategies were developed to reduce the computing time of the optimization replications and innovations on managing the repe- tition of sampling, optimization, and evaluation of first-stage solutions. We performed a detailed characterization of the overall solution by providing point estimates and confidence intervals for the main quanti- ties of interest, including a) upper and lower bounds for the true optimal objective function value; and b) an upper bound on the gap between the true optimal objective function value and the optimal objective func- tion value for a given first-stage solution. This methodology is applied to formulations involving a parameterized combination of the expected profit and the CVaR of the profit. The results and discussions focus on the extremes of the parameterization ‚Äì the risk-neutral and risk-averse
solutions.
For specific conditions, we identified a relevant trade-off between the size of the sample used in the optimization and the time spent on the lower bound estimation; specifically, increasing the size of the sample for the optimization reduces the time spent in the lower bound estima- tion and the overall required time. Two reasons justify this behavior:
1) the lower bound estimation is only performed for new first-stage so- lutions; and 2) increasing the sample size for the optimization reduces the number of distinct first-stage solutions. There is one exception to this behavior, which occurs for specific instances of the maximization
of the CVaR with ùõº = (ùëÅ ‚àí 1)‚àïùëÅ, where each optimization replication
provides one distinct first-stage solution.
For the present setup, computational experiments indicated that with the number of replications performed, the five sample sizes tested con- verge to the same solution or a neighboring solution. These results in- dicate that the replications with samples of ten elements can generate first-stage solutions that are the same or close to the best solutions gen- erated from samples of 500 elements. However, the variance of the solu- tions obtained with samples of 10 elements makes it diÔ¨Écult to identify whether the best solution has been obtained.
The inference statistics indicate that some of the optimal first-stage solutions of the SAA problem are relatively close to the true optimal solution.
Although the definition of the sample size and the number of replica- tions that guarantee specific bounds or convergence is problem depen- dent, some practical insights are in order. As general guidelines, given limited time and computational resources, the first issue to address is the sample size for the optimization. On the one hand, if the optimiza- tion replications are relatively eÔ¨Écient, then larger samples should be used to reduce the variance of the solutions, eventually avoiding the lower bound estimation for repeated solutions. On the other hand, more diÔ¨Écult optimization problems may require smaller samples for the op- timization, which increase the variance. However, our results indicate that among the solutions found, there is a high probability of identifying an excellent first-stage solution that can be further evaluated with the lower bound estimation.
Future work can evolve in two directions: 1) a comparison between risk-averse stochastic programming and robust optimization; and 2) the study of alternative risk metrics. Regarding the comparison, the first- stage solutions and point estimates of the expected profit and the CVaR of the profit obtained in this work can be contrasted with the solutions from a robust optimization approach. Additionally, it would be rele- vant to explore alternative risk metrics, such as stochastic dominance (Escudero and Monge, 2018), and to assess the quality of the solu- tions and the overall SAA methodology performance with alternative risk metrics.
Declaration of Competing Interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

Acknowledgments

Research reported in this publication was supported by research funding from King Abdullah University of Science and Technology (KAUST). Antonio J. Conejo‚Äôs contribution is partly supported by NSF project 1808169. We would like to thank two referees for their com- ments and contributions that helped to improve the presentation of this work.

Supplementary material

Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.ejco.2021.100005.
References

Alonso-Ayuso, A., Escudero, L.F., Guignard, M., Weintraub, A., 2018. Risk management for forestry planning under uncertainty in demand and prices. Eur. J. Oper. Res. 267, 1051‚Äì1074.
Artzner, P., Delbaen, F., Eber, J., Heath, D., 1999. Coherent measures of risk. Math. Fi- nance 9, 203‚Äì228.
, 1997. In: Awerbuch, S., Preston, A. (Eds.), The Virtual Utility: Accounting, Technology & Competitive Aspects of the Emerging Industry. Springer US.
Baringo, A., Baringo, L., 2017. A stochastic adaptive robust optimization approach for the offering strategy of a virtual power plant. IEEE Trans. Power Syst. 32, 3492‚Äì3504.
Bayraksan, G., Morton, D.P., 2006. Assessing solution quality in stochastic programs.
Math. Program. 108, 495‚Äì514. Ser. B
Benders, J.F., 1962. Partitioning procedures for solving mixed-variables programming problems. Numer. Math. 4, 238‚Äì252. doi:10.1007/BF01386316.
Birge, J.R., Louveaux, F., 2011. Introduction to Stochastic Programming. Springer. Conejo, A.J., Carri√≥n, M., Morales, J.M., 2010. Decision Making Under Uncertainty in
Electricity Markets. Springer US.
Dabbagh, S.R., Sheikh-El-Eslami, M.K., 2016. Risk assessment of virtual power plants of- fering in energy and reserve markets. IEEE Trans. Power Syst. 31, 3572‚Äì3582.
Dupaƒçov√°, J., Gr√∂we-Kuska, N., R√∂misch, W., 2003. Scenario reduction in stochastic pro- gramming ‚Äì an approach using probability metrics. Math. Program. 95, 493‚Äì511.
Escudero, L.F., Monge, J.F., 2018. On capacity expansion planning under strategic and operational uncertainties based on stochastic dominance risk averse management. Comput. Manag. Sci. 15, 479‚Äì500.
Iberian Electricity Market, 2015. www.omie.es.
Jansen, J.C., van der Welle, A., Nieuwenhout, F., 2008. Deliverable D3.2.4: The Virtual Power Plant Concept From an Economic perspective: Updated Final Report. Technical Report. Energy Research Centre of the Netherlands (ECN). http://www.fenix-project.org
Kall, P., Mayer, J., 2011. Stochastic Linear Programming. Springer US.
Kardakos, E.G., Simoglou, C.K., Bakirtzis, A.G., 2016. Optimal offering strategy of a virtual power plant: a stochastic bi-level approach. IEEE Trans. Smart Grid 7, 794‚Äì806.
Kleywegt, A., Shapiro, A., Homem-De-Mello, T., 2001. The sample average approximation method for stochastic discrete optimization. SIAM J. Optim. 12, 479‚Äì502.
Kozm√≠k, V., Morton, D.P., 2015. Evaluating policies in risk-averse multi-stage stochastic programming. Math. Program. 152, 275‚Äì300.
Lima, R.M., Conejo, A.J., Langodan, S., Hoteit, I., Knio, O.M., 2018. Risk-averse formula- tions and methods for a virtual power plant. Comput. Oper. Res. 96, 350‚Äì373.
Lima, R.M., Novais, A.Q., Conejo, A.J., 2015. Weekly self-scheduling, forward contracting, and pool involvement for an electricity producer. An adaptive robust optimization approach. Eur. J. Oper. Res. 240, 457‚Äì475.
Linderoth, J., Shapiro, A., Wright, S., 2006. The empirical behavior of sampling methods for stochastic programming. Ann. Oper. Res. 142, 215‚Äì241.
Ma√Ætre, O.L., Knio, O.M., 2010. Spectral Methods for Uncertainty Quantification: With Applications to Computational Fluid Dynamics. Springer Science & Business Media.
Mak, W., Morton, D., Wood, R., 1999. Monte carlo bounding techniques for determining solution quality in stochastic programs. Oper. Res. Lett. 24, 47‚Äì56.
Homem-de Mello, T., Bayraksan, G., 2014. Monte Carlo sampling-based methods for stochastic optimization. Surv. Oper. Res. Manag. Sci. 19, 56‚Äì85.
Mello, T.H.-d., Pagnoncelli, B.K., 2016. Risk aversion in multistage stochastic program- ming: a modeling and algorithmic perspective. Eur. J. Oper. Res. 249, 188‚Äì199.
Moazeni, S., Powell, W.B., Hajimiragha, A.H., 2015. Mean-conditional value-at-risk opti- mal energy storage operation in the presence of transaction costs. IEEE Trans. Power Syst. 30, 1222‚Äì1232.
Moghaddam, I.G., Nick, M., Fallahi, F., Sanei, M., Mortazavi, S., 2013. Risk-averse prof- it-based optimal operation strategy of a combined wind farm-cascade hydro system in an electricity market. Renew. Energy 55, 252‚Äì259.
Morales, J.M., Conejo, A.J., Madsen, H., Pinson, P., Zugno, M., 2014. Integrating Renew- ables in Electricity Markets. Springer US.



Pand≈æiƒá, H., Kuzle, I., Capuder, T., 2013. Virtual power plant mid-term dispatch optimiza- tion. Appl. Energy 101, 134‚Äì141.
Pand≈æiƒá, H., Morales, J.M., Conejo, A.J., Kuzle, I., 2013. Offering model for a virtual power plant based on stochastic programming. Appl. Energy 105, 282‚Äì292.
Pereira, M., Pinto, L., 1991. Multistage stochastic optimization applied to energy planning.
Math. Program. 52, 359‚Äì375.
Pflug, C., 2000. Probabilistic Constrained Optimization: Methodology and Applications.
Springer US, pp. 272‚Äì281.
Pflug, G., Ruszczynski, A., 2005. Measuring risk for income streams. Comput. Optim. Appl.
32, 161‚Äì178.
Pflug, G.C., R√∂misch, W., 2007. Modeling, Measuring and Managing Risk. World Scientific Publishing Co. Pte. Ltd..
Philpott, A.B., de Matos, V.L., 2012. Dynamic sampling algorithms for multi-stage stochas- tic programs with risk aversion. Eur. J. Oper. Res. 218, 470‚Äì483.
Pudjianto, D., Ramsay, C., Strbac, G., 2007. Virtual power plant and system integration of distributed energy resources. IET Renew. Power Gen. 1, 10‚Äì16.
Rahimiyan, M., Baringo, L., 2016. Strategic bidding for a virtual power plant in the day-a- head and real-time markets: a price-taker robust optimization approach. IEEE Trans. Power Syst. 31, 2676‚Äì2687.
Rahmani-Dabbagh, S., Sheikh-El-Eslami, M.K., 2016. A profit sharing scheme for dis- tributed energy resources integrated into a virtual power plant. Appl. Energy 184, 313‚Äì328.
Rockafellar, R.T., 2007. Coherent approaches to risk in optimization under uncertainty.
INFORMS 38‚Äì61.
Rockafellar, R.T., Uryasev, S., 2000. Optimization of conditional value-at-risk. J. Risk 2, 21‚Äì41.
Sarykalin, S., Serraino, G., Uryasev, S., 2008. Value-at-risk vs. conditional value-at-risk in risk management and optimization. INFORMS 270‚Äì294.
Shabanzadeh, M., Sheikh-El-Eslami, M.-K., Haghifam, M.R., 2015. The design of a risk-hedging tool for virtual power plants via robust optimization approach. Appl. Energy 155, 766‚Äì777.
Shabanzadeh, M., Sheikh-El-Eslami, M.-K., Haghifam, M.R., 2016. A medium-term coali- tion-forming model of heterogeneous DERs for a commercial virtual power plant. Appl. Energy 169, 663‚Äì681.
Shang, D., Kuzmenko, V., Uryasev, S., 2018. Cash flow matching with risks controlled by buffered probability of exceedance and conditional value-at-risk. Ann. Oper. Res. 260, 501‚Äì514.
Shapiro, A., 2009. On a time consistency concept in risk averse multistage stochastic pro- gramming. Oper. Res. Lett. 37, 143‚Äì147.
Shapiro, A., 2011. Analysis of stochastic dual dynamic programming method. Eur. J. Oper.
Res. 209, 63‚Äì72.
Shapiro, A., Dentcheva, D., Ruszczy≈Ñski, A., 2009. Lectures on Stochastic Programming: Modeling and Theory. In: MPS-SIAM Series on Optimization. Society for Industrial and Applied Mathematics, pp. 253‚Äì332.
Shapiro, A., Homem-De-Mello, T., 2000. On the rate of convergence of optimal solutions of monte carlo approximations of stochastic programs. SIAM J. Optim. 11, 70‚Äì86.
Shapiro, A., Tekaya, W., Costa, J.P.d., Soares, M.P., 2013. Risk neutral and risk averse stochastic dual dynamic programming method. Eur. J. Oper. Res. 224, 375‚Äì391.
Shayegan-Rad, A., Badri, A., Zangeneh, A., 2017. Day-ahead scheduling of virtual power plant in joint energy and regulation reserve markets under uncertainties. Energy 121, 114‚Äì125.
Tajeddini, M.A., Rahimi-Kian, A., Soroudi, A., 2014. Risk averse optimal operation of a virtual power plant using two stage stochastic programming. Energy 73, 958‚Äì967.
Van Slyke, R., Wets, R., 1969. L-shaped linear programs with applications to optimal con- trol and stochastic programming. SIAM J. Appl. Math. 17, 638‚Äì663.
Verweij, B., Ahmed, S., Kleywegt, A.J., Nemhauser, G., Shapiro, A., 2003. The sample av- erage approximation method applied to stochastic routing problems: a computational study. Comput. Optim. Appl. 24, 289‚Äì333.
Wang, W., 2007. Sample Average Approximation of Risk-Averse Stochastic Programs. H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology Ph.D. thesis.
Wang, W., Ahmed, S., 2008. Sample average approximation of expected value constrained stochastic programs. Oper. Res. Lett. 36, 515‚Äì519.
Zamani, A.G., Zakariazadeh, A., Jadid, S., 2016. Day-ahead resource scheduling of a re- newable energy based virtual power plant. Appl. Energy 169, 324‚Äì340.
