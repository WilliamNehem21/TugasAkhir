Egyptian Journal of Basic and Applied Sciences 4 (2017) 112–122







Full Length Article
An efficient similarity measure for content based image retrieval using memetic algorithm
Mutasem K. Alsmadi
Department of MIS, Collage of Applied Studies and Community Service, University of Dammam, Saudi Arabia



a r t i c l e  i n f o

Article history:
Received 24 September 2016
Received in revised form 11 February 2017 Accepted 28 February 2017
Available online 17 March 2017

Keywords:
Color signature Color texture
Content based image retrieval (CBIR) Neutrosophic
Memetic algorithm Shape feature Similarity measure
a b s t r a c t 

Content based image retrieval (CBIR) systems work by retrieving images which are related to the query image (QI) from huge databases. The available CBIR systems extract limited feature sets which confine the retrieval efficacy. In this work, extensive robust and important features were extracted from the images database and then stored in the feature repository. This feature set is composed of color signature with the shape and color texture features. Where, features are extracted from the given QI in the similar fashion. Consequently, a novel similarity evaluation using a meta-heuristic algorithm called a memetic algorithm (genetic algorithm with great deluge) is achieved between the features of the QI and the fea- tures of the database images. Our proposed CBIR system is assessed by inquiring number of images (from the test dataset) and the efficiency of the system is evaluated by calculating precision-recall value for the results. The results were superior to other state-of-the-art CBIR systems in regard to precision.
© 2017 Mansoura University. Production and hosting by Elsevier B.V. This is an open access article under
the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).






Introduction

Recently enormous number of images database are available worldwide [1–3]. In order to utilize these databases an effective and robust retrieval and search approach is required. The tradi- tional process for image retrieval is performed by describing every image with a text annotation and retrieving images by searching the keywords. This process has become very laborious and ambigu- ous because of the rapid increase in the number of images and the diversity of the image contents. Herby the content based image retrieval (CBIR) received a lot of attention [4]. A handful number of researches in the past decade were working on retrieving images from the huge repositories by analyzing image contents [5], since the beginning of 1990s CBIR was an active field for multimedia community research [6].
The aim of a CBIR algorithm is to determine the images that are related to the QI from the database [7]. CBIR can retrieve images that are similar to the query input image using the ‘‘query by example” technique which requires the user to input any descrip- tion about the query image. The system of CBIR works mainly by extracting features from the query image, then searching for these extracted features. These extracted features are used to calculate feature vector for the query image, CBIR represents every image

E-mail addresses: mksalsmadi@gmail.com, mkalsmadi@uod.edu.sa
in the database with a vector, after inputting the QI, the CBIR sys- tem computes its feature vector then compares it with the vectors stored for every image in the database. CBIR system returns the images that are similar in features to the QI.
Das et al. [8] described a method for extraction of features through binarization of images to enhance images retrieval and identification using content based image recognition. The authors tested their system using two public datasets with a sum of 3688 images. This method reduced the size of features to 12 regardless of the dimensions of image. The statistical measures (based on pre- cision and recall results) were adopted for the evaluation purpose. One disadvantage of this method is the misclassification of query images which would affect the performance of the retrieval com- pared to other existing approaches.
Ashraf et al. [9] proposed a technique for representation of image and feature extraction using bandelet transform, this approach consistently returns the main (core) objects’ information that are contained in an image. The artificial neural networks were used for image retrieval, the system performance and achievement was assessed using 3 public data sets namely: Coil, Corel, and Cal- tech 101, the precision and recall values were used for the retrieval efficiency evaluation
Seetharaman and Selvaraj [10] proposed a method for image retrieval using statistical tests, such as Welch’s t-tests and F- ratio. Both of the structured or textured input query images were examined. In the experiment, the entire image is considered in


http://dx.doi.org/10.1016/j.ejbas.2017.02.004
2314-808X/© 2017 Mansoura University. Production and hosting by Elsevier B.V.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).



the textured image, while in the structured image, the shape is separated into various regions based on its nature. The first step of the foresaid test is applying F-ratio test and the passed images proceeded to the energy spectrum testing. Then if images suc- ceeded the two tests it was decided that these images are similar. Else, they are different. For validation and verification of the per- formance Mean Average Precision score was used.
Feng et al. [11] proposed an image descriptor (Global Correla- tion Descriptor) for texture and color feature extraction respec- tively so that they had the same influence on CBIR. Global Correlation Vector and Directional Global Correlation Vector were also proposed, they integrated the benefits of structure element correlation and statistics of histogram to describe texture and color features. Corel-10 K and Corel-5 K datasets were used for valida- tion, and the recall and precision were used for the efficiency evaluation.
In Zeng [12] a local structure descriptor is proposed for image retrieval. Local structure descriptor is created based on the local structures underlying colors; it has combined the color, shape and texture as a one unit for retrieval of images. In addi- tion, they proposed an algorithm for feature extraction which is able to extract local structure histogram using local structure descriptor.
Madhavi et al. [13] proposed an approach known as image retrieval using interactive genetic algorithm for calculating a high number of selective features then comparing of related images for these features. The approach was tested on a group of 10,000 general images to prove the efficiency of the proposed approach.
Ali et al. [14] Presented a CBIR approach using integration of Speeded-Up Robust Features (SURF) and Scale Invariant Feature Transform (SIFT). The representations of these local features are used for retrieval because SIFT is robust to rotation and scale change, and SURF is more robust to illumination changes. The inte- gration of SURF and SIFT enhances the effectiveness of CBIR. The comparisons and evaluation were conducted on Corel-1500, Corel-2000, and Corel-1000.
One of the most commonly used meta-heuristics in optimiza- tion problems is the genetic algorithm. Genetic algorithm (GA) is a search algorithm which stimulates the heredity in the living things [15]. GA is very effective in finding the optimum solution from the search space [16].
In order to enhance the performance of a meta-heuristic such as GA, a local search algorithm is needed to help the GA for exploiting the solution space rather than just concentrating on exploring the search space. One excellent local search is the great deluge algo- rithm. The great deluge algorithm (GDA) was presented by Dueck
[17] as a local search algorithm. The main idea of this algorithm came from the analogy that someone is climbing a hill and trying to move in any direction to find a way up for keeping his feet dry and the water level is raising through a great deluge. The great deluge algorithm when inserted in the genetic algorithm was an effective way to yield a good solution instead of using the genetic algorithm alone [18].
Based on the abovementioned revision and discussion, this work utilizes a memetic algorithm (MA) to find the images that has the highest similarity with the QI from a database. During the CBIR process every image in the database is indicated by chro- mosome, from the QI the color signature, shape and color texture are extracted and also from the chromosomes that were generated. The next step is calculating fitness function for every chromosome using similarity difference equation. After that MA processes like crossover, mutation, great deluge local search and selection of the highest fitness chromosome are applied on the chromosomes; the CBIR retrieves the most relevant images to the QI from the images database.
Materials and methods

Feature extraction

The CBIR system proposed in this work determines the features in the image utilizing its optical contents such as color signature, shape and color texture. Fig. 1 represents the block diagram of the proposed method and the details of each process will be illus- trated in the following sections.

Color features extraction

Color feature is an essential component for image retrieval. For huge image databases, image retrieval using the color feature is very successful and effective. Although color feature is not a persis- tent parameter, because it is subjected to many non-surface char- acteristics for example, the taking conditions such as illumination, characteristics of the device, the device view point [1,19,20]. The steps of the color feature extraction are shown below:

Color planes values RGB are separated into individual matrices namely; Red, Green and Blue matrices.
For each color matrix color histogram is calculated.
Variance and median of color histogram are calculated.
The summation of all row variances and medians is calculated.
The calculated features of all matrixes (R, G and B) are com- bined as feature vector.
The feature vectors are stored in the features database.

Shape features extraction

The shape feature extraction mainly aims to capture the proper- ties of the shape of the image items. This eases the process of shape storing, transmitting, comparing against, and recognizing. The shape features should be free of rotation, translation, and scaling [1,21,22].
To store, transmit, or recognize shape, an efficient way to find the shape features is investigated. The selected features are inde- pendent from any mathematical transformation. A colored image has three values per each pixel, to extract the features we convert the color image into one two-dimensional array, and that made according to Craig, formula as follows [1,23]:
2 0.2989 3
Ig = [ Ir  Ig  Ib ] *  0.587	(1)
0.114
Where Ig is the combined 2D matrix, Ir · Ig · Ib are the color com- ponents which construct the colored image. Ig is represented as the
grey level combined image. As a preprocessing step: noise reduced by using median filter. Median filter is beneficial to reduce salt and pepper noise and speckle noise [24]. Also, median filter has edge- preserving property it is used where blurring of edges is undesir- able [24]. Median filter with width w and length l algorithm is as follows:

Around each pixel collect all pixels with length l/2 and width w/2 around it.
Sort all collected pixels.
Update the pixel value by the pixel value in the middle order in the previous list.

After applying the median filter, the image becomes almost without noise data. Then the neutrosophic clustering algorithm is applied to separate pixels with very near values and to ignore




Fig. 1. The proposed method block diagram.


indeterminate pixels from the gray image [25,26]. The algorithm is as follows:

Select k centroids pixel values.
For each pixel assign random membership value to each centroid.
Assign T, N values with the image I and F value with the inverse of T.
Calculate the new centroid value as the weighted mean of the pixel values, where the weight is the member ship value to that centroid but the weight magnitude if it the pixel is not indeter- minate and tininess if it is indeterminate.
Update the membership values as one over the ratio of the overall differences between the centroid and the pixels’ values, and the differences between the pixel values and all other centroid values.
Update the image I by applying the mean filter over pixels with significant values.
If the updated membership values are almost equal to it before update then stop otherwise go to step 3 again.

Finally apply the canny algorithm to find the edges around the similar pixels (grouped pixels) [1]. In this work Canny edge detec- tion method was used for shape features extraction, edge based shape representation was used, which gives a numerical informa- tion about image, these information is constant, even the size, direction, and position of the objects in the image are changed. After applying canny edge detection method different shapes can be obtained which exists in the Ig image and then the shaped con- tent indices are extracted and stored in the database in form of fea- ture vector.



Color texture features

Color texture features classification is an essential step for image segmentation using CBIR. Thus, this work proposes an approach that is based on texture analysis to classify color texture instead of segmentation alone.

Grey-level co-occurrence matrix (GLCM)

The GLCM is a robust image statistical analysis technique [27– 30]. GLCM can be defined as a matrix of two dimensions of joint probabilities between pixels pairs, with a distance d between them in a given direction h [30]. Haralick [31] extracted and defined 14 feature from the GLCM for the texture features classification. But these 14 features are highly correlated, so in our research we avoided this problem by using five features for the comparison. The Steps of the color texture features extraction is shown below:
Filtering the input image using the 5 × 5 Gaussian Filter.
Filtered image is divided into 4 × 4 blocks.
For each block Standard Deviation, Homogeneity, mean value,
Contrast and Energy are calculated using GLCM, these features were calculated based on four directions as diagonally (45° and 135°), vertically (0°) and horizontally (90°).
The extracted features are stored in the feature database.

Proposed memetic algorithm

Initially, the proposed memetic algorithm (genetic algorithm and great deluge algorithm) generates chromosomes, the genes in the chromosomes indicates the images of the database. The chromosome can’t contain repeated genes and the genes values depend on the number of database images that will be queried. The features extracted from every image are gathered as a feature set and the set of features from the query image also are extracted. Then each chromosome is subjected to the crossover, mutation (genetic operators) and great deluge algorithm local search in order to generate new chromosome. Moreover; the parameter set- tings of the proposed MA were determined experimentally.

Solution representation

In this study, the proposed memetic algorithm (GA and GDA) uses a direct representation for each candidate solution (chromo- somes) in the population, which consists of information on the number of images in the database and the number of matches in a binary form.

The initial population

Initially, a number of chromosomes are generated randomly; the number of chromosomes is the population size (pop_size). The number of required images which are related to the input query image will determine the number of genes in each chromo- some. Fig. 2 shows how the chromosome is generated.
Generally, the GA starts by computing the fitness of each candi- date solution in the initial population. While stopping criterion is not met, the following processes are employed: (i) Select a solution for reproduction using some selection mechanisms (e.g. roulette wheel). (ii) Generate offsprings using crossover and mutation oper-
ators. (iii) Compute new generations until either an optimal solu- tion is found or the maximum number of generations is reached.

Crossover operation

Crossover is the main operator in the genetic algorithm. Cross- over generates a new generation (chromosomes) from two parents using single cut point [16]. Where, this operation works by deter- mining single crossover point on both selected parent chromo- somes, a random number between 1 and 1c-1 is selected, 1c is the chromosome length. At the selected crossover point the parent chromosomes are cut, and the components after that point is exchanged between the parent chromosomes. Fig. 3 shows the generated offspring using the operation of crossover.

Mutation operation

The mutation operator produces random changes in solutions, which provides a chance for lost solutions from the population. Mutation operation is performed using bit-by-bit method. The mutation operator will be executed if the ratio of mutation (Pm) is verified. In this work, Pm equals 0.02 and the point that will be mutated is randomly selected. Fig. 4 shows the offspring that was generated by the mutation operator.

Great deluge algorithm

Before moving to the next generation, a local search algorithm is applied to improve a solution (chromosome) obtained from the genetic algorithm after the genetic operators are performed. This process makes the convergence of genetic algorithm faster. We then re-insert the resulted solution from the local search back to the genetic algorithm for the next generation. Then the process will proceed to the next generation and updates the population of chromosomes.
This work uses the Great Deluge Algorithm (GDA) for increasing the quality of solution (weight) through increasing the fitness number, which helps in enhancing the process of exploitation dur- ing the searching process. GDA is incorporated as a local search algorithm into the employed genetic search process to improve the exploitation process rather than the exploration process. A local search attempts to improve the quality of a solution while working as a perturbation operator.
The GDA is introduced by Dueck in 1993 [28]. It mimics a flood, where the ‘‘water level” (WL) is continuously rising and the candi- date solution must lie above the ‘‘surface” in order to survive [28]. GDA is different from other local search algorithm (e.g. hill climb- ing or simulated annealing) in the acceptance method of a candi- date solution from a neighborhood. For example, it accepts all solutions with fitness function (solution quality) values less than or equal to the current boundary value.
During the run process, the GDA may accept a worse solution than the current best solution in hand. First step, choose an initial configuration. Second step, modify the old configuration into a new one. Third step, compare the quality values of the two configura- tions. Fourth step, decide whether the new configuration is ‘‘ac- ceptable” or not. If the new configuration is acceptable, then it serves as the old configuration for the next step. If the new config- uration is not acceptable, the algorithm will proceed with a new modification of the old configuration. The crucial parameter is



Fig. 2. Chromosome form.




Fig. 3. Crossover operation.


Fig. 4. Mutation operation.


the ‘‘rain speed”, which controls convergence towards better solu- tions. A worse solution will be accepted if its fitness value is larger than of WL, this is considered as the control parameter. Fig. 5 shows a generic pseudo code for the GDA.
The WL is initialized with the value WLinitial. The WLinitial will increase in every iteration by the ‘‘rain speed” (Up). As suggested by Bykov [32], we use parameter Up. Where, the GDA is robust to this parameter. It is calculated by Eq. (2), below:
previous results. The WLinitial is set to the lower boundary of the obtained results. Generally, in order to control the search space, the GDA uses a lower water level for a maximization approach. The GDA increases the water level with a fixed positive value. Where, GDA initializes WLinitial and set it to the quality of the initial solution S, then it calculates the increasing rate ’b’ using Eq. (3).
b = (Estimated Quality — S)/Number of iterations	(3)

Up =
f (x')— WLinitial
N	(2)
In our proposed algorithm, solutions with higher fitness values are always accepted, while solutions with fitness values equal to the best solution’s fitness value are accepted if they have a smaller

Where, f(x’) is the goal value, and N is the number of iterations. This goal value can be estimated either by hill climbing algorithm or by
number of matching features. The GDA terminates when a solution reaches the estimated quality of the final solution (an improved



Choose initial configuration Old_Config;
//Old_Config is best solution found so far from genetic algorithm Choose WLinitial and Up;
For n = 0 to number of iterations
Generate New_Config of the Solution from genetic algorithm;
//by a small stochastic perturbation If Fitness(New_Config) > WL;
Old_Config:=New_Config;
End If;
WL = WL + UP;
End for;
Return an improved solution back to genetic algorithm


Fig. 5. A generic pseudo code of the GDA [38].



solution in term of quality). The search continues until reaching the lower limit (estimated quality). Table 1 shows the parameters setting of the proposed MA. Fig. 6 shows the pseudo code of the proposed MA.


Fitness function

Using a selected fitness function, the algorithm evaluates all candidate solutions from the entire population. The fitness func- tion indicates how good a candidate solution is. Mainly, the algo- rithm’s performance and the solution of the optimization problem depend on the fitness function. Therefore, the way to select a fitness function is very important in the algorithm design phase.
The next step is to determine fitness value (quality) for the gen- erated new chromosomes. Fitness depends on the match between the image to be queried and the feature sets of the newly gener- ated chromosomes. The best chromosome is the chromosome which has the minimum similarity difference compared with the input query image. Genes of the optimal obtained chromosome indicates the most related images to the input query image. The following is the equation of the similarity difference, see Eq. (4).
Image dataset

Corel dataset was used in our experiments; the Corel dataset consists of 10,908 different images with the size of 256 * 384 or 384 * 256 for each image. Therefore; the results were reported using ten semantic sets, each set has 100 images. These groups of datasets are Buses, Mountains, Beach, Elephants, Food, Flowers Africa, Horses, Dinosaurs and Buildings. The results were reported using these groups because most of the remarkable researches [9,13,33–37] used these groups to show the effectiveness of their CBIR methods. Thus; a clear results comparison can be conducted in using the reported results. The steps for the proposed CBIR tech- nique using the MA is shown in Fig. 7.

Results and discussion

The proposed CBIR system was tested with number of QIs and the similar images were retrieved from the corel image database. In order to achieve this, the features including color histogram, shape and color texture were extracted from each image in the database. Fig. 8 shows the original butterfly image, gray scale but- terfly image, the filtered grayscale butterfly image using median filter, edge detected butterfly image using the canny algorithm. Figs. 9–11 shows some retrieved images and their query images.
Color signature was used to compute the features of color his-

n	n

Similarity Difference = Xf j(I1)— Xf j(I2) 6 0.005	(4)
togram in terms of Variance and median, canny edge detection

j=1
j=1
method was used to calculate and compute the shape features, color texture was used to compute the features of GLCM in terms

In the proposed algorithm, the similarity of the two images is
measured as: The difference between of the total query image fea-
of standard deviation, homogeneity, mean value, contrast and energy. All the features extracted from color signature, shape and

n	n

tures (denote as P f j (I1)) and database image features (P f j (I2)).
color texture grouped and combined with each other in the created

j=1
j=1
feature set and after the feature set is extracted from the database

difference ≤ 0.005) to consider that the two images are similar. The difference must be less than or equal to 0.005 (e.g. similarity The similarity difference of the proposed fitness function was
determined experimentally.



3.7. Selection of chromosomes

Selection is the process that guides the algorithm towards an optimal solution by preferring chromosomes with high fitness. In this study, a roulette wheel is used as the selection mechanism of best retrieved images from the database based on the amount of features matches. The process is repeated until the maximum number of iterations is reached, then the best chromosomes that have the highest fitness number are selected from the set of chro- mosomes that are previously obtained. These optimum chromo- somes were utilized for retrieving the related images from the image database. This means, the similar images that will be retrieved effectively are the images with the indices which are rep- resented with the genes of the best chromosomes. Fig. 7 illustrates the steps of similarity measure based on MA for the proposed CBIR technique.


Table 1
Shows the parameters setting of the MA.
images, the feature set is compared with the input query image’s feature set using the GA in order to retrieve the similar images from the stored images in the database. After completing the pro- cess of feature extraction, MA was used for measuring the similarity.
The GA generates random chromosomes (pop_size) with a length of n, the number of required images that are related to the QI will determine the number of genes in each chromosome. The feature extraction is done for the chromosomes that were gen- erated and for the query image. The chromosomes are then sub- jected to the mutation and crossover operations, and great deluge local search and selection mechanism in order to find the optimum chromosome. After crossover, mutation and great deluge local search operations were completed the chromosomes that have the optimal values are selected. These selected chromosomes are the indices of the images that are relevant to the query image. This procedure is repeated till reaching the maximum number of iterations Itermax = 1000.

Evaluation of the retrieval (precision/recall)

Precision (specificity) is a measure of the system ability in retrieving only the similar images to the query image. The Recall rate which is known as true positive rate or sensitivity, measures the ability of CBIR systems in terms of number of

		similar image retrieved with their similar images in the data-

Parameter	Value
GA generation number	1000
Crossover rate	0.90
Mutation rate	0.02
Fitness value for chromosome	0.005
base. To elaborate the results, precision and recall were com- puted based on number of query images (from the test dataset) and the similar images that were retrieved from the corel image database.

GDA generation number	600
Initial water level	0
Final water level	100
recall
number of similar image retrieved
= total number of similar images in the database	(5)



Memetic Algorithm
Set the GA parameters
Set the GD algorithm parameters
begin
Population:= generate genetic algorithm initial solutions;
repeat the following until stopping criterion Select two parents for offspring production Employ crossover GA operator
Employ mutation GA operator
Enhance offspring via Great Deluge algorithm local search Replace population with new version
end end;


Fig. 6. The pseudo code of the MA [39].

Begin
Set the parameters pop_size, pc , pm , WLinitial and WLfinal.
Generate the initial population according to paragraph 3.1
Calculate the fitness based on similarity difference
Apply crossover according to Pc parameter (Pc >=0.90) as described in section 3.2.
Apply Mutation as shown in section 3.3.
Apply great deluge algorithm local search.
Calculate the fitness based on similarity difference
Select the best chromosome from the database equivalent to the query image.
Retrieve image indexed by best chromosome.
End


Fig. 7. Similarity measure based on Memetic algorithm for the proposed CBIR technique.



Fig. 8. Shape features extraction steps



(a)

(b)
Fig. 9. a. QI b. Some retrieved images.

(a)



(b)
Fig. 10. a. QI b. Some retrieved images.


(a)

(b)
Fig. 11. a. QI b. Some retrieved images.



Table 2
Recall-Precision measurements.


Groups	Precision	Recall


Evaluation on Corel image set

The proposed CBIR system was compared with some of the recent CBIR systems [9,13,33–37], in order to measure the usability of the proposed method. The motivation for this selection to com- pare with these methods is that the results of these methods were reported using a common denomination of ten semantic sets, each set has 100 images of Corel dataset. Thus; a clear results compar- ison can be conducted using the reported results. Hence, the per- formance comparison can be conducted. Table 3 shows the comparison of the average precision for each group of the proposed system with other comparative systems. The results indicate that the proposed system obtained better performance in term of preci-
sion than other systems. Table 4 shows the comparison of the aver-

precision = number of similar image retrieved total number of images retrieved
(6)
age recall rates for each group of the proposed system with the same comparative systems, the recall results of the proposed sys-

Eqs. (5) and (6) compute the precision and recall for the query image [1]. Table 2 shows recall-precision that was computed for some QI and their retrieved images. Fig. 12 shows the graph of the same precision-recall for our CBIR system. The graph shows that our CBIR system is highly effective and robust for the retrieval of images. Experimentally, when the number of similar images retrieved is increased, the precision and recall will be improved. The reported results using the combination of extracted features and MA techniques show very promising improvements in terms of efficiency and accuracy of the CBIR overall process.
tem obtained the best recall rates. Fig. 13 illustrates the precision performance of proposed system with other recent systems. Fig. 14 illustrates the comparison of the recall rates performance with the same comparative systems. As illustrated in table 4, the proposed system obtained the best recall rates.
In conclusion, the above comparison results indicates that the proposed system improved the precision and recall rates and out- performed the other state-of-the-art methods [9,13,33–37] in terms of precision and recall rates, where the average precision and recall rates were 0.882 and 0.7002 respectively. This is because





Fig. 12. Recall and Precision graph.


Table 3
Comparison results of the proposed method against other retrieval standard methods based on average precision.



Table 4
Comparison results of the proposed method against other retrieval standard methods based on average recall.





Fig. 13. Comparison results of the proposed method against other retrieval standard methods based on precision.




Fig. 14. Comparison results of the proposed method against other retrieval standard methods based on recall.



the authors in [9,13,33–37] developed CBIR systems that extract a limited number of feature sets, which limit the efficiency of retrie- val. While this work extracted robust and extensive set of features utilizing color signature using color histogram technique, shape using neutrosophic clustering algorithm and canny algorithm, and color texture using GLCM. Moreover; this work used the meta-heuristic techniques to optimize the precision of the retrieved images. Where, incorporating GD algorithm with the GA increased the quality of solution (weight) through increasing the fitness number, which helped in enhancing the process of exploitation during the searching process. The experimental results obviously show that the meta-heuristic techniques help to retrieve the highest number of the relevant images compared with the query image.

Conclusion

This work proposed an effective CBIR system using MA to retrieve images from databases. Once the user inputted a query image, the proposed CBIR extracted image features like color signa- ture, shape and texture color from the image. Then, using the MA based similarity measure; images that are relevant to the QI were retrieved efficiently. The conducted experiments based on the Corel image database indicate that the proposed MA algorithm has strong capability to discriminate color, shape and color texture features. Incorporating GD algorithm with the GA increased the quality of solution (weight) through increasing the fitness number, which helped in enhancing the process of exploitation during the searching process. Our proposed CBIR system was evaluated by dif- ferent images query. The execution results presented the success of the proposed method in retrieving the similar images from the images database and outperformed the other CBIR systems in terms of average precision and recall rates. This can be represented from the precision and recall values calculated from the results of retrieval where the average precision and recall rates were 0.882 and 0.7002 respectively. In the future, filtering techniques will be employed to get more accurate results in the content based image retrieval system.

References

Syam B, Rao Y. An effective similarity measure via genetic algorithm for content based image retrieval with extensive features. Int Arab J Info Technol (IAJIT) 2013;10(2).
Sumana I J, Islam M M, Zhang D and Lu G. Content based image retrieval using curvelet transform. In Multimedia Signal Processing, 2008 IEEE 10th Workshop on, pp. 11–16.
Kanimozhi T, Latha K. A Meta-Heuristic Optimization Approach for Content Based Image Retrieval using Relevance Feedback Method. In Proceedings of the World Congress on Engineering 2013 London, U.K.
Jaime-Castillo S, Medina J M, Sánchez D. A system to perform cbir on x-ray images using soft computing techniques. In Fuzzy Systems, 2009. FUZZ-IEEE 2009. IEEE International Conference on, pp. 1314–1319.
Shashank J, Kowshik P, Srinathan K, Jawahar C. Private content based image retrieval. In Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on, pp. 1–8.
Radwan AA, Latef BAA, Ali AMA, Sadek OA. Using genetic algorithm to improve information retrieval systems. World Acad Sci Eng Technol 2006;17(2):6–13.
Carneiro G, Chan A B, Moreno P J and Vasconcelos N. Supervised learning of semantic classes for image annotation and retrieval. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 2007; 29(3): 394-410
Das R, Thepade S, Bhattacharya S, Ghosh S. Retrieval architecture with classified query for content based image recognition. Appl Comput Intell Soft Comput 2016;2016:2.
Ashraf R, Bashir K, Irtaza A, Mahmood MT. Content based image retrieval using embedded neural networks with bandletized regions. Entropy 2015;17 (6):3552–80.
Seetharaman K, Selvaraj S. Statistical tests of hypothesis based color image retrieval. J Data Anal Info Process 2016;4(02):90.
Feng L, Wu J, Liu S, Zhang H. Global correlation descriptor: a novel image representation for image retrieval. J Vis Commun Image Represent 2015;33:104–14.
Zeng Z. A novel local structure descriptor for color image retrieval. Information 2016;7(1):9.
Madhavi KV, Tamilkodi R, Sudha KJ. An innovative method for retrieving relevant images by getting the top-ranked images first using interactive genetic algorithm. Proc Comput Sci 2016;79:254–61.
Ali N, Bajwa KB, Sablatnig R, Chatzichristofis SA, Iqbal Z, Rashid M, et al. A novel image retrieval based on visual words integration of SIFT and SURF. PLoS ONE 2016;11(6):e0157428.
Goldberg DE. Genetic algorithms in search, optimization and machine learning, 1989. 372.
Badawi UA, Alsmadi MKS. A hybrid memetic algorithm (genetic algorithm and great deluge local search) with back-propagation classifier for fish recognition. Int J Comput Sci Issues 2013;10(2):348–56.
Dueck G. New Optimization Heuristics. J Comput Phys 1993;104(1):86–92.
Foutsitzi G A, Gogos C G, Hadjigeorgiou E P, Stavroulakis G E. Actuator location and voltages optimization for shape control of smart beams using genetic algorithms. In Actuators, pp. 111–128.
Alsmadi M, Omar K. Fish classification: fish classification using memetic algorithms with back propagation classifier, 2012.
Alsmadi MK, Omar KB, Noah SA. Fish classification based on robust features extraction from color signature using back-propagation classifier. J Comput Sci 2011;7(1):52.
Alsmadi M, Omar KB, Noah SA, Almarashdeh I. Fish recognition based on robust features extraction from size and shape measurements using neural network. J Comput Sci 2010;6(10):1088–94.
Badawi UA, Alsmadi MK. A general fish classification methodology using meta- heuristic algorithm with back propagation classifier. J Theoret Appl Info Technol 2014;66(3).
Jyothi G, Sushma C, Veeresh DSS. Luminance based conversion of gray scale image to RGB image. Int J Comput Sci Info Technol Res 2015;3(3):279–83.
Shanmugavadivu P, Shanthasheela A. Feature Variance Based Filter For Speckle Noise Removal. IOSR J, 1(16): 15–19.
Alsmadi M K. A hybrid Fuzzy C-Means and Neutrosophic for jaw lesions segmentation. Ain Shams Eng J.
Guo Y, Sengur A. NCM: neutrosophic c-means clustering algorithm. Pattern Recogn 2015;48(8):2710–24.
Benco M, Hudec R, Kamencay P, Zachariasova M, Matuska S. An advanced approach to extraction of colour texture features based on GLCM. Int J Adv Rob Syst 2014;11.
Alsmadi MK, Omar KB, Noah SA, Almarashdeh I. Fish recognition based on robust features extraction from color texture measurements using back- propagation classifier. J Theoret Appl Info Technol 2010;18(1).
Haralick RM. Statistical and structural approaches to texture. Proc IEEE 1979;67(5):786–804.
Nikoo H, Talebi H, Mirzaei A. A supervised method for determining displacement of gray level co-occurrence matrix. In Machine Vision and Image Processing (MVIP), 2011 7th Iranian, pp. 1–5.
Haralick RM, Shanmugam K. Textural features for image classification. IEEE Trans Syst Man Cybernet 1973;6:610–21.
Bykov Y. Time-predefined and trajectory-based search: single and multiobjective approaches to exam timetabling. Nottingham: University of Nottingham; 2003.
Rao MB, Rao BP, Govardhan A. CTDCIRS: content based image retrieval system based on dominant color and texture features. Int J Comput Appl 2011;18 (6):40–6.
Youssef SM. ICTEDCT-CBIR: Integrating curvelet transform with enhanced dominant colors extraction and texture analysis for efficient content-based image retrieval. Comput Electr Eng 2012;38(5):1358–76.
Lin C-H, Chen R-T, Chan Y-K. A smart content-based image retrieval system based on color and texture feature. Image Vis Comput 2009;27(6):658–65.
Jhanwar N, Chaudhuri S, Seetharaman G, Zavidovique B. Content based image retrieval using motif cooccurrence matrix. Image Vis Comput 2004;22 (14):1211–20.
ElAlami ME. A novel image retrieval model based on the most relevant features. Knowl-Based Syst 2011;24(1):23–32.
Sacco W F, de oliveira C R E, Pereira C M N A. Two stochastic optimization algorithms applied to nuclear reactor core design. Prog Nucl Energy 2006;48 (6):525–39.
Moscato P. Memetic algorithms: a short introduction. In: David C, Marco D, Fred G, Dipankar D, Pablo M, Riccardo P, Kenneth V P, editors. New ideas in optimization. UK: McGraw-Hill Ltd.; 1999. p. 219–34.
