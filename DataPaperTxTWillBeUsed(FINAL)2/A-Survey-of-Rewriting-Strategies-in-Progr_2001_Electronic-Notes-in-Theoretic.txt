Electronic Notes in Theoretical Computer Science 57 (2001)
URL:  http://www.elsevier.nl/locate/entcs/volume57.html  35 pages



A Survey of Rewriting Strategies in Program Transformation Systems



Eelco Visser
Institute of Information and Computing Sciences, Universiteit Utrecht, P.O. Box 80089, 3508 TB Utrecht, The Netherlands. http://www.cs.uu.nl/ visser, visser@acm.org


Abstract
Program transformation is used in a wide range of applications including compiler construction, optimization, program synthesis, refactoring, software renovation, and reverse engineering. Complex program transformations are achieved through a num- ber of consecutive modi cations of a program. Transformation rules de ne basic modi cations. A transformation strategy is an algorithm for choosing a path in the rewrite relation induced by a set of rules. This paper surveys the support for the de nition of strategies in program transformation systems. After a discussion of kinds of program transformation and choices in program representation, the ba- sic elements of a strategy system are discussed and the choices in the design of a strategy language are considered. Several styles of strategy systems as provided in existing languages are then analyzed.


1	Introduction

Program transformation has applications in many areas of software engineer- ing such as compilation, optimization, refactoring, program synthesis, software renovation, and reverse engineering. The aim of program transformation is to increase programmer productivity by automating programming tasks, thus enabling programming at a higher-level of abstraction, and increasing main- tainability and re-usability.
Many systems for program transformation exist that are often specialized for a speci c object language and/or kind of transformation. All these systems share many ideas about program transformation and use similar techniques, but are often ad-hoc in many respects. The ultimate goal is to achieve a speci cation language or family of speci cation languages for the high-level, declarative speci cation of program transformation systems in which generic, language independent schemas of transformation can be captured, and which admits eÆcient implementation of those transformations that can scale up to large programs.
 c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


This survey aims at understanding the similarities and di erences between systems for program transformation by analyzing existing systems on the ba- sis of publications. Many aspects of program transformation such as parsing, pretty-printing and formulating basic transformations are fairly well under- stood. Therefore, this survey concentrates on transformation strategies, i.e., the control part of transformation systems that determine the order of appli- cation of basic transformation steps.
The paper is structured as follows. Section 2 presents a taxonomy of program transformation. Section 3 discusses the choices in program repre- sentations that can be used in program transformation systems.  Section	4
discusses the ingredients of a system for the speci cation of program trans-
formation rules and strategies. Section 5 discusses the implementation of program transformation in a number of dedicated transformation languages. Section 6 summarizes and discusses some areas for research in the implemen- tation of transformation systems.

2	Program Transformation

A program is a structured object with semantics. The structure allows us to transform a program. Semantics includes the extensional and intensional behavior of a program and gives us the means to compare programs and to reason about the validity of transformations. A programming language is a collection of programs that comply with the same set of structural and semantic rules. This is a rather broad de nition that is intended to cover proper programming languages (with an operational interpretation), but also data formats, domain-speci c languages, and aspects of programs such as their control- or data- ow.
Programming languages can be clustered into classes with structural and/or semantic similarities. One of the aims of a general framework for program transformation is to de ne transformations that are reusable across as wide a range of languages as possible. For example, the notions of variable and variable binding are shared by all programming languages. Transformations dealing with variables such as bound variable renaming, substitution, and uni-
 cation can be de ned in a highly generic manner for all languages at once.
Program transformation is the act of changing one program into another. The term program transformation is also used for a formal description of an algorithm that implements program transformation. The language in which the program being transformed and the resulting program are written are called the source and target languages, respectively.
Program transformation is used in many areas of software engineering, including compiler construction, software visualization, documentation gen- eration, and automatic software renovation. In all these applications we can distinguish two main scenarios, i.e., the one in which the source and target languages are di erent (translations) and the one in which they are the same



Translation
   Migration
   Synthesis
  Re nement
  Compilation
   Reverse engineering
  Decompilation
  Architecture extraction
  Documentation generation
  Software visualization
   Analysis
  Control- ow analysis
  Data- ow analysis
Rephrasing
   Normalization
  Simpli cation
  Desugaring
  Weaving
   Optimization
  Specialization
  Inlining
  Fusion
   Refactoring
  Design improvement
  Obfuscation
   Renovation


Fig. 1. A taxonomy of program transformation

(rephrasings). These main scenarios can be re ned into a number of typical subscenarios based on their e ect on the level of abstraction of a program and to what extent they preserve the semantics of a program. This re nement results in the taxonomy in Figure 1.

2.1  Translation
In a translation scenario a program is transformed from a source language into a program in a di erent target language. Translation scenarios can be distinguished by their e ect on the level of abstraction of a program. Although translations aim at preserving the extensional semantics of a program, it is usually not possible to retain all information across a translation. Translation scenarios can be divided into synthesis, migration, reverse engineering, and analysis. Their relations are illustrated by the diagram in Figure 2.

2.1.1  Synthesis
Program synthesis is a class of transformations that lower the level of ab- straction of a program. In the course of synthesis design information is traded for increased eÆciency. In re nement [50] an implementation is derived from a high-level speci cation such that the implementation satis es the speci - cation. Compilation [1,2,36] is a form of synthesis in which a program in a high-level language is transformed to machine code. This translation is usually achieved in several phases. Typically, a high-level language is rst translated into a target machine independent intermediate representation. Instruction selection then translates the intermediate representation into machine instruc- tions. Other examples of synthesis are parser and pretty-printer generation from context-free grammars [1,11].



Fig. 2. Relation between kinds of program transformation
2.1.2  Migration
In migration a program is transformed to another language at the same level of abstraction. This can be a translation between dialects, for example, trans- forming a Fortran77 program to an equivalent Fortran90 program or a trans- lation from one language to another, e.g., porting a Pascal program to C.

2.1.3  Reverse Engineering
The purpose of reverse engineering [12] is to extract from a low-level program a high-level program or speci cation, or at least some higher-level aspects. Reverse engineering raises the level of abstraction and is the dual of synthesis. Examples of reverse engineering are decompilation in which an object pro- gram is translated into a high-level program, architecture extraction in which the design of a program is derived, documentation generation, and software visualization in which some aspect of a program is depicted in an abstract way.

2.1.4	Analysis
Program analysis reduces a program to one aspect such as its control- or data-
 ow. Analysis can thus be considered a transformation to a sublanguage or an aspect language.

2.2	Rephrasing
Rephrasings are transformations that transform a program into a di erent program in the same language, i.e., source and target language are the same. In general, rephrasings try to say the same thing in di erent words thereby aiming at improving some aspect of the program, which entails that they change the semantics of the program. The main subscenarios of rephrasing are normalization, optimization, refactoring, and renovation.


2.2.1  Normalization
A normalization reduces a program to a program in a sublanguage, with the purpose of decreasing its syntactic complexity. Desugaring is a kind of normalization in which some of the constructs (syntactic sugar) of a language are eliminated by translating them into more fundamental constructs. For example, the Haskell language de nition [44] describes for many constructs how they can be desugared to a kernel language. Other examples are module
 attening and the de nition of EBNF constructs in pure BNF as is done for
example in the SDF2 normalizer [51]. Simpli cation is a more general kind of normalization in which a program is reduced to a normal (standard) form, without necessarily removing simpli ed constructs. For example, consider transformation to canonical form of intermediate representations and algebraic simpli cation of expressions. Note that normal form does not necessarily correspond to being a normal form with respect to a set of rewrite rules.

2.2.2  Optimization
An optimization [2,36] is a transformation that improves the run-time and/or space performance of a program. Example optimizations are fusion, inlining, constant propagation, constant folding, common-subexpression elimination, and dead code elimination.

2.2.3  Refactoring
A refactoring [24] is a transformation that improves the design of a program by restructuring it such that it becomes easier to understand while preserving its functionality. Obfuscation [16] is a transformation that makes a program harder to understand by renaming variables, inserting dead code, etc. Obfus- cation is done to hide the business rules embedded in software by making it harder to reverse engineer the program.

2.2.4  Renovation
In software renovation the extensional behavior of a program is changed in order to repair an error or to bring it up to date with respect to changed requirements. Examples are repairing a Y2K bug, or converting a program to deal with the Euro.


2.3	Program Transformation Systems
A program transformation system is determined by the choices it makes in program representation and the programming paradigm used for implement- ing transformations. The next section discusses considerations in choosing a representation for programs. The remaining sections consider implementation of transformations.


3	Program Representation

Although some systems work directly on text, in general a textual represen- tation is not adequate for performing complex transformations. Therefore, a structured representation is used by most systems. Since programs are written as texts by programmers, parsers are needed to convert from text to structure and unparsers are needed to convert structure to text. However, this might change in the future; in the Intentional Programming framework [17] programs are stored, edited and processed as source graphs. Editing of programs is done via structure editors.
A number of issues should be considered when choosing a program rep- resentation: to use parse trees or abstract syntax trees, trees or graphs, how to represent variables and variable bindings, and how to exchange programs between transformation components.

3.1	Parse Trees or Abstract Syntax Trees
Parse trees contain syntactic information such as layout (whitespace and com- ments), and parentheses and extra nodes introduced by disambiguating gram- mar transformations. Since this information is often irrelevant for transforma- tion, parse trees are usually transformed into abstract syntax trees that do not contain such information. However, for some applications (such as software renovation and refactoring) it is necessary to restore as much as possible the original layout of the program after transformation. This requires that layout is stored in the tree and preserved throughout transformation. Especially the latter aspect is problematic; it is not clear in a generic manner where to insert comments in a transformed fragment of a program. Origin tracking [20] might be useful here.
For other applications (e.g., certain optimizations and compilation) it is necessary to carry type information in the tree. This requires the extension of the tree format to store type information and to preserve consistency of types throughout transformation.

3.2	Trees or Graphs
Program structure can be represented by means of trees, directed-acyclic graphs (DAGs), or full edged graphs with cycles.
Using pure trees is costly because copying of a tree (e.g., by using a variable twice in constructing a new tree) requires creating a complete copy. Therefore, most systems use DAGs. When copying a tree, only a pointer to the tree gets copied, thus sub-trees are shared by multiple contexts. The advantage of sharing is reduced memory usage. In the ATerm library [8] this approach is taken to the extreme by only constructing one instance for each sub-tree that is constructed, thus achieving maximal sharing and minimal memory usage.
Sharing saves memory, makes copying cheap, and, in the case of maximal


sharing, testing for equality is cheap as well. However, the downside of sharing is that performing a transformation of a tree requires re-building the context in which the transformed tree is used. It would be more attractive to overwrite the root node of the sub-tree that is changed with the new tree, thus updating all contexts in which the old tree was used. However, this is not valid in general. Two occurrences of a shared tree that are syntactically the same can have a completely di erent meaning depending on their context. Even if they have the same meaning, it is not always desirable to change both occurrences.
The same problem of occurrence arises when associating information with nodes. When sharing is based on syntactic equivalence alone, annotations become associated with all occurrences of the tree. Consider the examples of position information in parse trees and type annotations in abstract syntax trees to conclude that this is usually not desirable.
Finally, full edged graphs can be useful to represent back-links in the tree to represent, for example, loops in a control- ow graph [2,33,36], or links to declarations [17]. Updateable graphs make it easy to attach new information to nodes, for example results of analysis. The problem of destructive update versus copying while doing transformation is even more problematic in graphs. Since a sub-graph can have links to the entire graph, it may be required to reconstruct the entire graph after a transformation, if it is necessary to keep the original graph as well. For very speci c purposes such as lazy evaluation of functional programs, it is possible to make such graph updates transparent.


3.3	Variable Bindings
A particular problem of program transformation is the handling of variables and variable bindings. In the common approach variables and variable bind- ings in an abstract syntax tree are treated just like any other construct and the transformation system has no special knowledge of them. This requires the implementation of operations to rename bound variables, substitution, etc. Transformations need to be aware of variables by means of extra conditions to avoid problems such as free variable capture during substitution and lifting variable occurrences out of bindings.
Transparent handling of variable bindings is desirable. Higher-order ab- stract syntax (hoas) [34,30,45] gives a solution to such problems by encoding variable bindings as lambda abstractions. In addition to dealing with the prob- lem of variable capture, hoas provides higher-order matching which synthesizes new functions for higher-order variables. One of the problems of higher-order matching is that there can be many matches for a pattern, requiring a mecha- nism for choosing between them. FreshML [46] provides a weaker mechanism for dealing with variable bindings that transparently refreshes variable names, thus solving the capture problem. Substitution for variables has to be dealt with explicitly. Both hoas and FreshML require some amount of encoding for the syntactic structure to  t the lambda abstraction binding scheme.  This


can become rather far removed from the structure described by the grammar for more complex binding schemes.
All approaches that rename variables are in con ict with requirements that original names are preserved, which is required in applications such as refactoring and renovation.
A problem that is not addressed by the approaches discussed above is as- sociating declaration information, e.g., type declarations, with usage. This usually requires maintaining a symbol table during transformation, or dis- tributing the information over the tree, annotating usage occurrences of a symbol with the information in the declarations. Either way, the information needs to be kept consistent during transformations.

3.4	Exchange Format
Finally, a program representation should be supported by an exchange format that makes it possible to exchange programs between transformation compo- nents. Example formats are XML, which supports exchange of tree shaped data, and the Annotated Term Format [8], which supports exchange of DAGs, maintaining maximal sharing. See [28] for a bibliography of exchange formats.

4	Implementation of Program Transformation

A complex program transformation is achieved through a number of consec- utive modi cations of a program. At least at the level of design it is useful to distinguish transformation rules from transformation strategies. A rule de-
 nes a basic step in the transformation of a program. A strategy is a plan for
achieving a complex transformation using a set of rules.
For example, consider the transformation rules in Figure 3. The Inline rules de ne inlining of function and variable de nitions. The Dead rule elimi-

Fig. 3. Some example transformation rules


nates an unused variable de nition. The Extract rule abstracts an expression into a function. The Hoist rule de nes lifting a function de nition out of a variable de nition if the variable is not used in the function. Using this set of rules di erent transformations can be achieved. For example, a constant propagation strategy in an optimizer could use the InlineV and Dead rules to eliminate constant variable de nitions:
let x = 3 in x + y  ->  let x = 3 in 3 + y  ->  3 + y
On the other hand, the ExtractFunction strategy in a refactoring browser could use the Extract and Hoist rules to abstract addition with y into a new function and lift it to top-level.
let x = 3 in x + y
-> let x = 3 in let addy(z) = z + y in addy(x)
-> let addy(z) = z + y in let x = 3 in addy(x)
Rules can be applied interactively by a programmer via a graphical user interface. The problem with such manipulations is that the transformation is not reproducible, since the decisions have not been recorded. By automating the transformation process, a series of basic transformations can be repeatedly applied to a program. By generalizing the sequence of transformations the combined transformation can be applied to many programs. This requires a mechanism for combining rules into more complex transformations. This section discusses the basic ingredients for speci cation of rules and strategies.

4.1	Transformation Rules
Rules are based on the semantics of the language. A rule generally preserves the semantics of the program. That is, before and after the application of a rule the program has the same meaning. Usually the observable behavior of the program is preserved, but some other aspect is changed. Optimizations, for example, try to decrease the time or space resource usage of a program. Applying constant propagation can decrease the need for registers, for in- stance. Extracting a function during refactoring can improve the readability of the program.
A rule consists of recognizing a program fragment to transform and con- structing a new program fragment to replace the old one. Recognition involves matching the syntactic structure of the program and possibly verifying some semantic conditions. The replacement in a rule can consist of a simple term pattern, a function that constructs a new tree or graph, or a semantic action with arbitrary side-e ects.
When using a tree or term representation term pattern matching can be used. First-order term patterns can be used to decompose terms by simultane- ously recognizing a structure and binding variables to subterms, which would otherwise be expressed by nested conditional expressions that test tags and select subterms. However, rst-order patterns are not treated as rst-class cit-



Fig. 4. Phenomena in composition of transformation rules: in nite branches, in- verses, con uence, non-con uence

izens and their use poses limitations on modularity and reuse: no abstraction over patterns is provided because they may occur only in the left-hand side of a rewrite rule, the arms of a case, or the heads of clauses; pattern matching is at odds with abstract data types because it exposes the data representation; a
 rst-order pattern can only span a xed distance from the root of the pattern
to its leaves, which makes it necessary to de ne recursive traversals of a data structure separately from the pattern to get all needed information.
For these reasons, enhancements of the basic pattern matching features have been implemented or considered for several languages. For example, list matching in ASF+SDF [19] is used to divide a list into multiple sublists pos- sibly separated by element patterns. Associative-commutative (AC) matching in OBJ, Maude [13] and ELAN [4] supports the treatment of lists as multi- sets. Higher-order uni cation in Prolog [37,45] allows higher-order matching of subterms in an arbitrary context [22,29], which in turn allows matching of subterms at arbitrarily deep levels using higher-order variables without ex- plicit traversal of the structure involved. Views for Haskell, as proposed in [57], provide a way to view a data structure using di erent patterns than are used to represent them. Overlays in Stratego [52] are pseudo-constructors that abstract from an underlying representation using actual constructors.

4.2	Transformation Strategies
A set of transformation rules for a programming language induces a rewrite relation on programs [18]. If the relation is con uent and terminating, there is a unique normal form for every program. In that case it is a matter of applying the rules in the most eÆcient way to reach the normal form. However, in program transformation this is usually not the case. As illustrated in Figure 4, a set of transformation rules can give rise to in nite branches (e.g., by inlining a recursive function), inverses in which a transformation is undone (e.g., by distribution or commutativity rules), and non-con uence in which a program can be transformed into two di erent programs.


Depending on the goal of a transformation task, a path should be chosen in the rewrite relation. For a speci c program it is always possible to nd the shortest path to the optimal solution for a speci c transformation task. However, for most transformation tasks the process of nding a path needs to be automated, and optimal solutions might only be approximated. A strategy is an algorithm for choosing a path in the rewrite relation. Given one set of rules, there can be many strategies, each achieving a di erent goal. On the other hand, a general strategy can be applicable to many di erent sets of rules.
A strategy can be provided by the transformation engine or can be user- de nable. There is a range of possibilities between these two options:
  Fixed application order. The engine applies rules exhaustively according to a built-in strategy. Examples are innermost and outermost reduction.
  Automatic dependency analysis. The engine determines a strategy based on an analysis of the rules. Examples are strictness and laziness analysis
  Goal driven. The engine nds out how to apply rules to achieve a user- de ned goal.
 Strategy menu. A strategy can be selected from a small set. For example, choose between innermost and outermost reduction or annotate constructors with laziness information.
  Completely programmable. The strategy to apply rules can be programmed in a strategy language.
Whether de ned by the user or by the engine, the strategy needs to be ex- pressed and implemented formally. The rest of this section considers the ingredients of a language for de ning strategies.

4.2.1  Sequential Composition
To choose a path in the rewrite relation the basic rules should be combined into transformations. Transformations can be combined by consecutively applying two transformations, by conditionally choosing between two transformations, and by repeating transformations, iteratively or recursively.

4.2.2  Non-Deterministic Programming
Choosing between two paths based on properties of the current program can be too limited. It might be necessary to decide on the appropriateness of a choice after applying several transformations. One approach is to speculatively explore paths until an acceptable solution is found, the other is to explore all paths in parallel and choose the best solution.
In the case of speculative exploration some kind of non-deterministic choice between two alternative paths is needed. On failure in one of the paths, the other path is taken. If backtracking is local, the choice is made after one of the chosen branches succeeds. If back-tracking is global, failure at any point


inside or after the choice causes back-tracking to the alternative path. This allows exploring the full search space, until an acceptable solution is found.
Parallel exploration of all paths requires a mechanism for comparing solu- tions based on some kind of cost function. For some such problems dynamic programming techniques can be used to eÆciently apply all transformations.
In between speculative and parallel exploration is goal based exploration in which a set of constraints leads to discarding paths inconsistent with the constraints.

4.2.3  Structure Traversal
A rewrite relation includes application of rules in any context. This entails traversing the program representation structure to nd the location where the rule is applied, applying the rule, and rebuilding the context. In addition to the sequential order of application and the choice between paths, the location where a rule is applied is also determined by the strategy. It is unattractive to express these locations by means of paths in a tree, since it is ineÆcient to traverse and rebuild the context for each rule application. Often rules are applied close to each other in the tree.
Therefore, some mechanism is needed to traverse syntax trees and to ap- ply transformation rules at subtrees. A language-speci c traversal mechanism requires de nition of traversals for all constructs in a language. This can lead to large speci cations for large languages (having a complex abstract syntax). A language generic traversal mechanism supports the de nition of generic traversals over abstract syntax trees. This requires exposing the underlying representation model. Traversal mechanisms can provide a set of xed traver- sals such as top-down and bottom-up, or provide traversal primitives from which all kinds of traversals can be de ned.

4.2.4  Information Carrying Strategies
Strategies may carry information that can be used in making decisions about paths to take and in passing context-sensitive information to rules.

4.2.5  Separation of Rules and Strategies
Although we have distinguished rules at the conceptual level, at the imple- mentation level rules and strategies can be intertwined, i.e., the rules can be hardwired in the de nition of the strategy. Alternatively, rules and strategies can be de ned separately, which entails that strategies are parameterized with a set of rules.
Separate de nition of rules and strategies leads to clearer speci cations that allow reasoning about smaller entities (rules, strategies) separately. Fur- thermore, separate de nition enables the reuse of rules and strategies and the generic implementation of aspects of transformation systems that are common to all or a class of languages. However, intertwining may sometimes be re- quired for eÆciency reasons. In these cases it desirable that the intertwining


be done by a compiler rather than by the speci er.

4.2.6  Abstraction
To achieve reuse of strategies in general, and separation of rules from strate- gies, in particular, an abstraction mechanism is needed that allows abstraction over rules and strategies. That is, it should be possible to name and parame- terize rules and strategies.

5  Program Transformation Languages

This section discusses a number of languages designed speci cally for the im- plementation of program transformation. The following topics will be dis- cussed: interactive program transformation, intentional programming, tree parsing, term rewriting and a number of extensions of basic term rewriting addressing the problems of standard rewriting strategies: strategy annota- tions, sequences of canonical forms, exploring the reduction space with non- deterministic strategies, guiding rewriting by re ection, rewriting with traver- sal functions, and generic rewriting strategies.

5.1  Interactive Program Transformation
Draco [39,40] was the rst system to support the transformation of high- level domain-speci c programs to executable code. The system supported the de nition of transformation rules for optimizations and re nements to transform high-level constructs into lower-level ones.
Transformation rules and re nements are identi ed by means of names. Transformation rules also have application codes that specify their relative precedences. The application of transformations and re nements to a domain program is controlled by the user through an interactive process. In this process the user has to select domain, instance (region in the abstract syntax tree representing the program), and locale (node in the abstract syntax tree). Transformations can be applied directly to the currently selected locale using apply. The system can examine the tree and suggest transformations to apply. Using the transform command all transformation rules in a certain range can be applied automatically. The transform command uses a bottom-up traversal over the tree, applying rules in the provided code range. Rules with higher codes are applied rst. In [38] there are also descriptions of a top-down traversal and of traversals that apply the best rules rst. Re nements can be applied individually using try and use. A certain amount of automation of the process is possible by means of tactics.

5.2  Intentional Programming
Intentional programming is a meta-programming system under development at Microsoft Research. A good description of intentional programming is given


in [17].
In intentional programming a program is represented by a source tree in- stead of by a source text. Each node of a source tree has a reference to its declaration (thus making the tree into a source graph). For example, an oc- currence of a variable has a link to its declaration. Likewise each language construct, or intention, corresponds to a tree node that de nes it. Intentions can be used by making links to the de nitions of the intentions. For example, a while statement is a node with two children corresponding to the condi- tion and the iteration statement together with a link to the while intention. Domain-speci c programming abstractions can be captured by de ning new intentions.
Source trees are implemented by reducing them to source trees using only R-code intentions. R-code intentions are basic constructs that can translated to some form of machine code by a code generator. Part of the de nition of each intention is a method reducing it to its R-code. The dependencies between these reduction methods are computed and interpreted by the inten- tional programming engine to reduce an entire program to its R-code.


5.3	Simple Tree Parsing
Tree parsing is analogous to string parsing; instead of nding structure in a string, the goal is to nd structure in a tree by covering the tree with patterns. Sorcerer [42,43] is the tree parser generator for the antlr language processing system. Sorcerer generates tree walkers from tree grammars. A tree grammar is a bnf-like notation for the de nition of tree structures. For example, the grammar
exp : #(PLUS exp exp)
| INT
describes expression trees composed from integers and addition.
Tree translations and transformations are achieved by associating actions with the grammar productions. Translations to textual output are achieved by printing actions. For example, the following grammar prints expressions using in x notation.
exp : #(PLUS exp <<printf("+");>> exp)
| i:INT <<printf("%d", i);>>
Tree transformations are achieved by reconstructing trees and returning them as results. For example, the following grammar transforms expressions by swapping the arguments of the PLUS operator.
exp :! #(PLUS l:exp r:exp) <<#exp = #(PLUS r l);>>
| INT
Grammar non-terminals can have arguments that can be used in the ac- tions in productions. Non-terminals can also return results. A tree grammar


gives rise to a set of mutually recursive functions, one for each non-terminal, that together de ne a one-pass traversal over a tree. Patterns can be nested and can use regular tree expressions with optionals, alternatives and lists.
Transformation rules in tree grammars are embedded in grammar produc- tions. Separation of rules and strategies and generic tree traversals are not supported in sorcerer.

5.4	Tree Parsing with Dynamic Programming
If a tree grammar is ambiguous, multiple parses of a tree are possible. The parser needs to decide which parse to take. By associating costs to each production, the disambiguation can be based on the accumulated cost of a tree. Dynamic programming techniques can be used to compute all possible parses in one traversal.
Burg [25,26,48] is a system for code generation from intermediate represen- tation (ir) expression trees. A mapping from ir trees to machine instructions is de ned by means of a tree grammar. A production of the form n -> t (c) de nes a mapping of tree pattern t to non-terminal n at cost c. Associated with each production is an action to take when the production is selected. For example, Proebsting [48] gives the example grammar in Figure 5. Ac- cording to this grammar, the term Fetch(Fetch(Plus(Reg,Int))) has two coverings corresponding to the derivations 4(4(6(5(2,3)))) and 4(4(8(2))) with costs 7 and 4, respectively.
As illustrated by this example, more than one covering of a tree is pos- sible, corresponding to di erent ways to generate code. Each node can have several di erent parses because of overlapping patterns and chain rules. The costs associated with the productions express the cost of executing the asso- ciated machine instruction. The goal of a code generator is to nd the lowest cost covering (i.e., lowest execution time) of an intermediate representation expression tree.
According to bottom-up rewriting theory (burs) an ir tree can be trans- lated to a sequence of instructions using the following strategy. In a bottom-up traversal all lowest-cost patterns that match each node are computed and as- sociated with the node. This involves matching the right-hand sides of the productions to the tree, taking into account earlier matches for sub-trees. In- structions are then selected in a top-down traversal that is driven by the goal non-terminal for the root of the tree.
This restricted form of rewriting can also be applied [48] for simple type

Fig. 5. Example BURG speci cation


inference problems, for checking tree formats, and for tree simpli cations.

5.5	Term Rewriting
Term rewriting [18] is supported by systems such as OBJ [27], ASF+SDF [19], ELAN [5], and many more. Term rewriting is an attractive paradigm for pro- gram transformation. First-order terms can be used to describe the abstract syntax of programs. For example, consider the declaration of propositional formulae in Figure 6. A rewrite rule of the form t1 -> t2 declares the trans- formation of a term matching pattern t1 to the instantiation of t2. Rewrite rules can be used to express basic transformation rules and can be considered as operationalizations of the algebraic laws of the language. For example, the rewrite rules in Figure 6 express basic laws of propositional logic, i.e., the distribution rules, the rule of double negation, and the De Morgan rules. Us- ing stronger forms of pattern matching such as various instances of equational matching (e.g., AC matching, list matching), patterns can capture complicated term con gurations. Furthermore, in conditional rewrite rules additional tests on the patterns can be stated.
A redex is a subterm that matches with a rewrite rule. A term is in normal form if it has no redices. Rewrite engines for term rewrite systems compute the normal form of terms with respect to sets of rules in speci cations. This involves exhaustively applying rules to subterms until no more rules apply. A rewrite engine can employ di erent strategies to order the application of rules. In innermost rewriting all subterms of a term are normalized before rules are applied to the term itself. In outermost rewriting redices closest to the root of the term are rewritten rst. This implies that rules are automatically applied

Fig. 6. Signature and rewrite rules for propositional formulae.


throughout a term and that no traversals over the syntax tree need to be de ned.
However, the complete normalization approach of rewriting turns out not to be adequate for program transformation, because rewrite systems for pro- gramming languages will often be non-terminating and/or non-con uent. In general, it is not desirable to apply all rules at the same time or to apply all rules under all circumstances.
As an example, consider again the set of rewrite rules in Figure 6. This rewrite system is non-terminating because rules DAOL and DAOR enable rules DOAL and DOAR, and vice versa. If we want to de ne a transformation to normalize formulae to disjunctive normal form we could discard rules DOAL and DOAR. However, if in another part of the transformation a conjunctive normal form is required we need a di erent rewrite system. It is not possible to combine these rules in one rewrite system.
The common solution to this kind of problem is to introduce additional constructors (functions) that achieve normalization under a restricted set of rules. Figure 7 shows how the rewrite system in Figure 6 can be turned into a terminating rewrite system that de nes the normalization to disjunctive normal form (DNF). To normalize a formula to DNF the function dnf should be applied to it. Normalization to conjunctive normal form requires a similar de nition.

Fig. 7. Functionalized rewrite system for disjunctive normal form.


The dnf function mimics the innermost normalization strategy by recur- sively traversing terms. The auxiliary functions not and and are used to apply the distribution rules and the negation rules. In functional programming such auxiliary functions are known as smart constructors [21]. In the de nition of the rules for and and not it is assumed that the arguments of these functions are already in disjunctive normal form. For example, if none of the arguments of and is an Or term, the term itself is considered to be in DNF.
In the solution in Figure 7, the original rules have been completely inter- twined with the dnf transformation. The rules for negation cannot be reused in the de nition of normalization to conjunctive normal form. For each new transformation a new traversal function and new smart constructors have to be de ned. Many additional rules had to be added to traverse the term to
 nd the places to apply the rules. Instead of 5 rules, a total of 13 rules were
needed. Rules AND3 and NOT4 are default rules that only apply if the other rules do not apply. Without this mechanism even more rules would have had to be used to handle the cases were the real transformation rules do not apply. Default rules were introduced in ASF+SDF [19].
The kind of problem illustrated in the example above occurs frequently in all kinds of transformations. Examples are the normalization of SDF2 syntax de nitions to Kernel-Sdf [51]; desugaring of programming constructs; and refactoring in which parts of a program may have to simpli ed, while others may have to de-simpli ed.
In general, trying to overcome the problems of non-termination and non- con uence leads to encoding of control in terms of additional rewrite rules (which is at variance with our goal to separate rules from strategies as much as possible) . This usually leads to a functional programming style of rewriting, overhead in the form of traversal rules for each constructor in the signature, intertwining of rules and function de nitions, all of which makes reuse of rules impossible, and leads to speci cations that are much harder to understand.


5.6	Rewriting with Traversal Functions
In ASF+SDF controlling the application of transformation rules has been recognized as a problem for a long time. Especially for the speci cation of transformations for large languages such as cobol the overhead of de ning traversals was seen as the problematic factor. First this was solved by the generation of default traversal rules [11,10] that could be overridden by normal rules. In this approach typically only a few rewrite rules have to be speci ed, corresponding to the non-default behaviour of the traversal. However, the number of generated rules still proves to be a source of overhead, be it for the compiler, not the programmer. Furthermore, providing a new traversal scheme requires the addition of a new generator.
In a recent approach [9], traversal functions are supported directly by the rewriting engine, avoiding the compile-time overhead of generated rules. Fig-



Fig. 8. Disjunctive Normal Form with traversal function (Version 1)


ure 8 illustrates the approach applied to the problem of normalization to disjunctive normal form.	Note that the example does not use ASF+SDF syntax.	The speci cation is the same as that in Figure 7, but the dnf function has been declared a traversal function in the signature.	The at- tribute traversal(trafo,bottom-up) declares that dnf performs a bottom- up traversal over its argument. This means that the function is rst applied to the direct subterms (and, thus, recursively to all subterms) before it is ap- plied at the term itself. Rules need to be declared only for those constructs that are transformed. The default behaviour is to reconstruct the term with the original constructor. In the example this reduces the speci cation of the traversal from 6 to 2 rules. In general, for a signature with n constructors only m of which need to be handled in a special way, this saves n  m rules.
There is still some overhead in the speci cation in Figure 8 in the form of the dispatching from the traversal function to the smart constructors and the default rules for the smart constructors. A more concise speci cation is the one in Figure 9 in which no smart constructors are used. In this style only one rule is needed for each original rule. However, the problem with this style is that the recursive calls in the right-hand sides of the rules will completely retraverse the tree (the arguments of which are already normalized) before applying one of the rules.
ASF+SDF provides a limited set of traversals. For traversal strategy there is a choice between top-down and bottom-up. The latter has been explained above. A top-down traverses down the tree and stops as soon as a rule ap- plies. In addition a traversal can be a transformation (trafo) and/or a traver- sal which accumulates information along the way (accu). Finally, traversal



Fig. 9. Disjunctive Normal Form with traversal function (Version 2)



functions can be parameterized with additional arguments that contain static information to be used during traversal.
The advantage of traversal functions is that default traversal behaviour does not need to be implemented manually. This is similar to default visi- tors in object-oriented programming or folds with updatable fold algebras in functional programming. However, the approach has a number of limitations.
First of all, there is no separation of rules from strategies. A rule is bound to one speci c traversal via the traversal function. It is not possible to reuse rules in di erent traversals, for example, to normalize under di erent rule sets. Furthermore, rules are intertwined with strategies, making it hard to distinguish the basic transformation rules from the traversal code, and to argue about correctness of the whole.
Secondly, the traversal function schema provides a limited range of traver- sals. The bottom-up variant does a full traversal of the tree. The top-down variant stops as soon as it has found a rule application, this requires explicit de ninition of recursion in rules. Although it is possible to implement a wide range of traversals, this requires gluing together the basic traversals in an ad- hoc manner. It is not possible to de ne new traversal schemas in a reusable way, i.e., as a new traversal attribute. That would require extending the rewrite engine.
Finally, the traversals provided by the language capture an abstraction, i.e., certain traversal schemata. There is no possibility in the language to give further abstractions for alternative traversal schemata, or for more elaborate functionality involving traversals. This is desirable for building libraries with language independent strategies. For example, de ning substitution without variable capture is similar for many languages, given the shape of variables and variable bindings. Extrapolating the traversal function approach, more and more such abstractions will be captured as additional primitives in the rewrite engine. At some point it will make sense to extend the language with a mechanism for specifying such abstractions generically.


5.7  Term Rewriting with Strategy Annotations
Another problem in term rewriting is that of terms with in nite reduction paths that cannot be resolved by removing unnecessary rules. For example, the speci cation in Figure 10 de nes the computation of the factorial function using the conditional If. Using a pure innermost rewriting strategy a term Fac(3) does not terminate, since the arguments of If are evaluated before rules IfF or IfT are applied. Using an outermost strategy would solve the problem, but outermost is harder to implement eÆciently. Therefore, several systems provide strategy annotations to delay the evaluation of arguments.
Note that these strategy annotations help to make some rewrite systems terminating, but that they do not help in other respects for program trans- formation. For example, traversals over abstract syntax trees still need to be de ned explicitly.

5.7.1  Just-in-time
The strategy annotations in [47] are designed to delay the evaluation of argu- ments, but guarantee that the term reached after evaluation is a normal form with respect to the rewrite system, i.e., contains no redices.
A strategy annotation for a constructor is a list of argument positions and rule names. The argument positions indicate the next argument to eval- uate and the rule names indicate a rule to apply. The innermost strategy corresponds to an annotation strat(C) = [1,2,3,..,R1,R2,R3,...] for a constructor C and indicates that rst all its arguments should be evaluated and then the rules Ri should be applied. By requiring that all argument po- sitions and all rules for a constructor are mentioned in the annotation, it can be guaranteed that a normal form is reached. The just-in-time strategy is a permutation of argument positions and rules in which rules are applied as early as possible.
Using these annotations the non-termination for the rewrite system in Figure 10 is solved by means of the annotation

Fig. 10. Rewrite system with non-terminating reduction path.

















Fig. 11. Speci cation with strategy annotations [41]. strat(If) = [1,IfT,IfF,2,3,IfE]
that declares that only the rst argument should be evaluated before applying rules IfT and IfF.

5.7.2	E-Strategy
The just-in-time strategy cannot deal with rewrite systems that do not have normal forms for some terms. For example, consider the rules in Figure	11.
Terms of the form Inf(n), for some natural number n, do not have a normal form.
The E-strategy [41] of the CafeOBJ system uses an extended form of strat- egy annotations in which not all arguments need to be evaluated. In this style a strategy annotation is a list of argument positions and the root position (0). The annotation declares the order of evaluation of the arguments. The root position 0 indicates the evaluation of the term at the root. Not all argument positions need to be declared. An undeclared argument is not evaluated.
For example, the non-termination in Figure 11 is solved by the strategy annotation (1 0), which indicates that rst the rst argument of Cons should be evaluated and then the constructor itself (0). The second argument is never evaluated. The E-normal form of Nth(S(Z),Inf(Z)) is S(Z). Also the term Inf(Z) has a normal form, i.e., Cons(Z,Inf(S(Z))).

5.7.3  Laziness annotations
The strategy annotations discussed above are interpreted by the rewrite en- gine. In [23] it is shown how rewrite systems with laziness annotations can be compiled into rewrite systems that can be evaluated using an innermost strategy.
A laziness annotation indicates for an argument of a constructor that it is lazy, i.e., that no reductions should be performed for subterms of that argument, unless needed for matching. For example, for the rewrite system



Fig. 12. Result of translating speci cation with laziness annotations to eager spec- i cation [23].
in Figure 11 the laziness annotation Lazy(Cons,2) achieves the delay of the evaluation of the second argument of Cons.
A rewrite system with laziness annotations can be translated to an ea- ger rewrite system using thunks. A thunk is an auxiliary data structure that stores the structure of the term. For example, the term rewrite system (TRS) in Figure 11 is transformed to the eager TRS in Figure 12. Note that Thunk is a generic constructor for representing thunks, L is a constructor for indicat- ing the thunked pattern, and Vec1 is a constructor for denoting a vector of length 1.
Note that annotations depend on the application in which they are used. For example, without the Inf constructor there is no reason for annotating the second argument of Cons as lazy.

5.8	Sequences of Canonical Forms
Tampr stands for Transformation Assisted Multiple Program Realization Sys- tem. The tampr system [6,7], which has been in use since the seventies, is designed for the derivation of eÆcient implementations from speci cations through transformations, in particular in the domain of numerical program- ming.
A tampr speci cation consists of a series of rewrite rules. The tampr rewrite engine applies rewrite rules exhaustively to reach a canonical form. The prob- lem of non-termination caused by rules that are each others' inverses that we encountered in Section 5.5 is solved in tampr by organizing a large transfor- mation into a sequence of consecutive reductions to canonical forms under di erent sets of rewrite rules. Typically such a sequence starts with several preparatory steps that bring the program in the right form, followed by the pivotal step which achieves the actual transformation, followed by some post- processing.
In [7] this is illustrated with the transformation from a polynomial in y:


(x2 + 2x + 1)y2 + (x2
9)y
(20x2 + 18x
18)


to the equivalent polynomial in x

(y2 + y  20)x2 + (2y2  18)x + (y2  9y + 18)


This is achieved by means of the following sequence of canonical forms: sum-of-monomonials;
x-commuted-to-right;
like-powers-collected; x-factored-out
The sum-of-monomonials canonical form transforms the polynomial into x y + 2xy + y + x y  9y  20x   18x + 18
By commuting the multiplications, the x-commuted-to-right canonical form
is achieved:


y x + 2y
2x + y2
+ yx2
 9y  20x
 18x + 18


The like-powers-collected canonical form commutes the additions to bring monomonials with the same power of x together:


y x + yx2
 20x
+ 2y
x  18x + y
  9y + 18


Finally, by factoring out the powers of x, the desired form is reached.

5.9	Non-deterministic Sequential Strategies
Elan [3] is a language for rewriting with user-de nable strategies in a special strategy language. An elan speci cation consists of a set of unlabeled rewrite rules, which are applied using a xed innermost strategy, and labeled rules, which are applied by user-de ned strategies. Rewrite rules support matching modulo associativity and commutativity.
A strategy expression combines several rule labels by means of strategy operators. The application of a strategy to a term leads to a set of results. An empty set of results denotes failure. Evaluation of a term involves normalizing the term according to the unlabeled rules, and then applying a strategy to it. Strategies exist at two levels: the elementary strategies built into the lan- guage that can be used to apply labeled rules and de ned strategies, which
are interpreted using innermost rewriting.
An example of the use of labeled rules and elementary strategies in the def- inition of Knuth-Bendix completion (from [35]) is shown in Figure 13. Other applications of elan include constraint solving and communication protocol testing.
The identity strategy id succeeds and returns the singleton set containing the subject term. The failure strategy fail returns the empty set. The sequential composition e1; e2 of two strategies rst applies e1, then e2. There are several choice operators each with di erent back-tracking prop- erties. The operator dk(e1,...,en) (don't know) returns all results from all strategies ei. The operator dc(e1,...,en) (don't care) returns the results



Fig. 13. Example elan rules and strategy for Knuth-Bendix completion [35].


from one of its argument strategies as long as it does not fail. The opera- tor first(e1,...,en) returns the results of the rst ei that does not fail. The operators dc one(e1,...,en) and first one(e1,...,en) return only one result. The operator iterate*(e) (iterate+(e)) returns all possible re- sults from iterating the strategy e zero (one) or more times. The operator repeat*(e) (repeat+(e)) returns the last set of results from repeatedly ap- plying e until it fails. Finally, the operator normalize(e) normalizes a term with respect to a strategy, i.e., applying the strategy to all subterms until it fails for all sub-terms. Note that all other operators apply labeled rules at the root. There is no other support for term traversal using elementary strategies.
Using de ned strategies language speci c traversal can be de ned using congruence operators.
A limited form of genericity is provided by the preprocessor mechanism of the language, which supports the de nition of speci cation schemas. Elan does not support language generic term traversal.



5.10	Generating Strategies with Re ection

Maude [13] is one of the successors of the algebraic speci cation formalism OBJ. Maude supports two kinds of rewrite rules: equations and rules. Equa- tions are applied using an innermost strategy and rules are applied using an outermost strategy. Pattern matching in equations and rules can use matching modulo many combinations of associativity, commutativity and identity.
Maude does not support operators for the de nition of strategies. Instead the language provides a meta-level in which speci cations can be manipulated by re ection [14,15].


5.11  Generic Traversal Strategies
Stratego [54,55] is a language for program transformation completely based on rewriting strategies. Stratego supports sequential programming with local backtracking, generic and speci c term traversal, strategy abstraction, and
 rst class pattern matching.
Figure 14 gives several examples of uses of strategies. The examples use basic operators and de ned strategies discussed below. The strategies disj-nf and conj-nf de ne normalizations to disjunctive and conjunctive normal- form, respectively, using the rules from Figure 6. The eval strategy performs constant folding on propositional formulae using the standard truth rules (not shown here). The strategies desugar and impl-nf de ne two desugarings of propositional formulae, i.e., elimination of implication and equivalence, and desugaring to implicative normal-form using standard elimination rules (not shown here).

5.11.1  Sequential Programming
Strategies are programs that attempt to transform terms into terms, at which they may succeed or fail. In case of success the result of such an attempt is a transformed term. In case of failure there is no result of the transformation. Strategies can be combined into new strategies by means of the following oper- ators. The identity strategy id leaves the subject term unchanged and always succeeds. The failure strategy fail always fails. The sequential composition s1 ; s2 of strategies s1 and s2 rst attempts to apply s1 to the subject term and, if that succeeds, applies s2 to the result. The non-deterministic choice s1 + s2 of strategies s1 and s2 attempts to apply either s1 or s2. It succeeds if either succeeds and it fails if both fail; the order in which s1 and s2 are tried is unspeci ed. The deterministic choice s1 <+ s2 of strategies s1 and s2 attempts to apply either s1 or s2, in that order. Note that ; has higher

Fig. 14. Various transformations on propositional formulae.



Fig. 15. Generic iteration strategies.

precedence than + and <+. The recursive closure rec x(s) of the strategy s attempts to apply s to the entire subject term and the strategy rec x(s) to each occurrence of the variable x in s. The test strategy test(s) tries to apply the strategy s. It succeeds if s succeeds, and reverts the subject term to the original term. It also fails if s fails. The negation not(s) succeeds (with the identity transformation) if s fails and fails if s succeeds. Examples of strategies that can be de ned with these operators are the try and iteration strategies in Figure 15.

5.11.2  Term Traversal
The combinators discussed above combine strategies that apply transforma- tions to the root of a term. In order to apply transformations throughout a term it is necessary to traverse it. For this purpose, Stratego provides a congruence operator C(s1,...,sn) for each n-ary constructor C. It applies to terms of the form C(t1,...,tn) and applies si to ti. An example of the use of congruences is the operator map(s) de ned in Figure 16 that applies a strategy s to each element of a list.
Congruences can be used to de ne traversals over speci c data struc- tures. Speci cation of generic traversals (e.g., pre- or post-order over ar- bitrary structures) requires more generic operators. The operator all(s) applies s to all children of a constructor application C(t1,...,tn). In par- ticular, all(s) is the identity on constants (constructor applications without children). The strategy one(s) applies s to one child of a constructor appli- cation C(t1,...,tn); it is precisely the failure strategy on constants. The strategy some(s) applies s to some of the children of a constructor applica- tion C(t1,...,tn), i.e., to at least one and as many as possible. Like one(s), some(s) fails on constants.
Figure 16 de nes various traversals based on these operators. For instance, oncetd(s) tries to nd one application of s somewhere in the term starting at the root working its way down; s <+ one(x) rst attempts to apply s, if that fails an application of s is (recursively) attempted at one of the children of the subject term. If no application is found the traversal fails. Compare this to the traversal alltd(s), which nds all outermost applications of s and never fails.



Fig. 16. Speci c and generic traversal strategies.

5.11.3  Match, Build and Variable Binding
The operators we have introduced thus far are useful for repeatedly applying transformation rules throughout a term. Actual transformation rules are con- structed by means of pattern matching and building of pattern instantiations.
A match ?t succeeds if the subject term matches with the term t. As a side-e ect, any variables in t are bound to the corresponding subterms of the subject term. If a variable was already bound before the match, then the binding only succeeds if the terms are the same. This enables non-linear pattern matching, so that a match such as ?F(x, x) succeeds only if the two arguments of F in the subject term are equal. This non-linear behavior can also arise across other operations. For example, the two consecutive matches
?F(x, y); ?F(y, x) succeed exactly when the two arguments of F are equal.
Once a variable is bound it cannot be unbound.
A build !t replaces the subject term with the instantiation of the pattern t using the current bindings of terms to variables in t. A scope {x1,...,xn: s} makes the variables xi local to the strategy s. This means that bindings to these variables outside the scope are undone when entering the scope and are restored after leaving it. The operation where(s) applies the strategy s to the subject term. If successful, it restores the original subject term, keeping only the newly obtained bindings to variables.

5.11.4  Abstraction
A strategy de nition f(x1,...,xn) = s introduces a new strategy opera- tor f parameterized with strategies x1 through xn and with body s. La- beled transformation rules are abbreviations of a particular form of strat- egy de nitions. A conditional rule L : l -> r where s with label L, left- hand side l, right-hand side r, and condition s denotes a strategy de ni-


tion L = {x1,...,xn: ?l; where(s); !r}. Here, the body of the rule rst matches the left-hand side l against the subject term, and then attempts to satisfy the condition s. If that succeeds, it builds the right-hand side r. The rule is enclosed in a scope that makes all term variables xi occurring freely in l, s and r local to the rule.
Stratego also supports pattern abstraction by means of overlays [52].

5.11.5  Generic Strategies
Using the machinery of Stratego, highly generic strategies can be de ned. The Stratego library de nes a wide range of generic strategies including traversal strategies as in Figure 16. In addition the library de nes a number of higher- level language-independent operations such as free-variable collection, bound variable renaming, capture free substitution, syntactic uni cation, and com- puting the spanning tree of a graph. These operations are parameterized with the relevant language constructs and work generically otherwise [53].
A problem of some generic strategies is that they lack knowledge of the computations in their argument strategies, which may cause overhead. For example, the innermost strategy in Figure 16 renormalizes arguments of left- hand sides of rules when they are used in the right-hand side. In [31] it is shown how this can be repaired by fusing the generic innermost strategy with its arguments.

6  Concluding Remarks

6.1  Summary
In this paper I have given an overview of considerations that play a role in building program transformation systems and focussed on the role of strategies for control of transformation rules. Several languages for program transfor- mation are discussed, each representing a particular style of strategy support, covering the following styles:
   simple tree parsing
   tree parsing with dynamic programming
   exhaustive evaluation
  traversal functions
   strategy annotations
   sequence of canonical forms
  non-deterministic sequential strategies
   re ective strategies
   generic traversal strategies
This discussion follows the development from languages with built-in strategies to languages with fully programmable strategies.


6.2	Future Work
The languages discussed in this paper are closely related to the term rewriting paradigm. Since any implementation of program transformation is ultimately a form of rewriting, languages dedicated to transformation will likely be based on rewriting. However, program transformation systems are also programmed in other paradigms. An extended survey should also investigate how strate- gies are modeled in these paradigms. The strategies discussed in this paper control transformation by explicitly ordering the application of rules. Another approach is to let constraints or goals guide the application of rules.
Finally, the various approaches to strategies are illustrated with very small examples. A better comparison between the various approaches can be achieved by encoding one or several more complex program transformations.

6.3	Research Issues
There are numerous unresolved issues in the speci cation and implementation of strategies for program transformation, including the following:
  Strategies are used to control the application of rewrite rules in order to pre- vent undesired interference between transformations. The design of strate- gies is based on an analysis of this interference. Often this analysis is in- formal. For pure, unconditional rewrite rules, analysis techniques exist for discovering such interference. For more complex transformation rules such analysis is needed as well.
  How can dynamic programming in the style of BURG be expressed in a more general framework of strategies while obtaining the same eÆciency? Can the approach be generalized to more complex, cascading transformations? In other words, how can we nd the optimal sequence of transformations. For the complexities this may involve in an high-performance computing context see [49].
   Is there a type system that reconciles static typing with generic strategies?
 How can we transparently deal with variable bindings and other context- sensitive issues? What is the interaction between strategies and higher-order abstract syntax?
  In [33] rewrite rules on control- ow graphs are de ned using temporal logic assertions. What is the role of strategies in graph transformation?
  Generic strategies parameterized with rules or other strategies often have to renormalize/retraverse terms. In [31] an optimization for the case of the generic de nition of innermost is given. There is a general need for fusion of generic traversals.
  In general, the fusion of generic strategies with rules can be seen as a form of aspect weaving [32]. Can strategies be formulated in terms of aspect- oriented programming?


  Origin tracking [20] for term rewriting relates a normalized term to the orig- inal term. Applications include error messages and layout reconstruction. How can we compute origins in a system with strategies? In systems with a clean separation between rules and strategies it should be possible to make the inheritance of origin information transparent to strategies.

6.4	Online Survey
This survey is part of a larger e ort to create an overview of the theory and practice of program transformation in the online survey of program transfor- mation [56].


Acknowledgments
I would like to thank Bernhard Gramlich and Salvador Lucas for inviting me to write this paper for the Workshop on Rewriting Strategies. Jan Heer- ing, Patricia Johann, Paul Klint, and Jurgen Vinju commented on a previous version of this paper.


References

[1] A. Aho, R. Sethi, and J. Ullman. Compilers: Principles, techniques, and tools.
Addison Wesley, Reading, Massachusetts, 1986.  2.1.1

[2] A. W. Appel. Modern Compiler Implementation in ML. Cambridge University Press, 1998. 2.1.1, 2.2.2, 3.2
[3] P. Borovansky , H. Cirstea, H. Dubois, C. Kirchner, H. Kirchner, P.-E. Moreau,
C. Ringeissen, and M. Vittek. ELAN: User Manual. Loria, Nancy, France, v3.4 edition, January 27 2000. 5.9
[4] P. Borovansky , C. Kirchner, and H. Kirchner. Controlling rewriting by rewriting. In J. Meseguer, editor, Proceedings of the First International Workshop on Rewriting Logic and its Applications, volume 4 of Electronic Notes in Theoretical Computer Science, Asilomar, Paci c Grove, CA, September 1996.
Elsevier.  4.1

[5] P. Borovansky , C. Kirchner, H. Kirchner, P.-E. Moreau, and M. Vittek. Elan: A logical framework based on computational systems. In J. Meseguer, editor, Electronic Notes in Theoretical Computer Science, volume 4. Elsevier Science Publishers, 1996. Proceedings of the First Workshop on Rewriting Logic and Applications 1996 (WRLA'96). 5.5

[6] J. M. Boyle. Abstract programming and program transformation|An approach to reusing programs. In T. J. Biggersta and A. J. Perlis, editors, Software Reusability, volume 1, pages 361{413. ACM Press, 1989. 5.8


[7] J. M. Boyle, T. J. Harmer, and V. L. Winter. The TAMPR program transformation system: Simplifying the development of numerical software. In
E. Arge, A. M. Bruaset, and H. P. Langtangen, editors, Modern Software Tools for Scienti c Computing, pages 353{372. Birkhauser, 1997. 5.8
[8] M. G. J. van den Brand, H. de Jong, P. Klint, and P. Olivier. EÆcient annotated terms. Software, Practice & Experience, 30(3):259{291, 2000. 3.2, 3.4
[9] M. G. J. van den Brand, P. Klint, and J. Vinju. Term rewriting with traversal functions. Technical Report SEN-R0121, Centrum voor Wiskunde en Informatica, 2001. 5.6
[10] M. G. J. van den Brand, M. P. A. Sellink, and C. Verhoef.  Generation of components for software renovation factories from context-free grammars.
Science of Computer Programming, 36:209{266, 2000. 5.6

[11] M. G. J. van den Brand and E. Visser. Generation of formatters for context- free languages. ACM Transactions on Software Engineering and Methodology, 5(1):1{41, January 1996. 2.1.1, 5.6
[12] E. Chikofski and J. Cross. Reverse engineering and design recovery: A taxonomy. IEEE Software, 1990. 2.1.3
[13] M. Clavel, S. Eker, P. Lincoln, and J. Meseguer.  Principles of Maude. In J. Meseguer, editor, Proceedings of the First International Workshop on Rewriting Logic and its Applications, volume 4 of Electronic Notes in Theoretical Computer Science, pages 65{89, Asilomar, Paci c Grove, CA, September 1996.
Elsevier.  4.1, 5.10

[14] M. Clavel and J. Meseguer.  Re ection and strategies in rewriting logic. In J. Meseguer, editor, Electronic Notes in Theoretical Computer Science, volume 4. Elsevier Science Publishers, 1996. Proceedings of the First International Workshop on Rewriting Logic and its Applications. 5.10
[15] M. G. Clavel. Re ection in General Logics and in Rewriting Logic with Applications to the Maude Language.  PhD thesis, Universidad de Navarra,
Facultad de Filoso a y Letras, Pamplona, Espan~a, 1998. 5.10

[16] C. Collberg, C. Thomborson, and D. Low. Manufacturing cheap, resilient and stealthy opaque constructs. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL 98), pages 184{196, San Diego CA, USA, January 1998. 2.2.3
[17] K. Czarnecki and U. W. Eisenecker. Intentional programming. In Generative Programming. Methods, Tools, and Applications, chapter 11. Addison-Wesley, 2000. 3, 3.2, 5.2
[18] N. Dershowitz and J.-P. Jouannaud. Rewrite systems. In J. van Leeuwen, editor, Handbook of Theoretical Computer Science, volume B, chapter 6, pages 243{320. Elsevier, 1990. 4.2, 5.5


[19] A. van Deursen, J. Heering, and P. Klint, editors. Language Prototyping. An Algebraic Speci cation Approach, volume 5 of AMAST Series in Computing.
World Scienti c, Singapore, September 1996. 4.1, 5.5, 5.5
[20] A. van Deursen, P. Klint, and F. Tip. Origin tracking. Journal of Symbolic Computation, 15(5{6):523{546, 1993. 3.1, 6.3
[21] C. Elliott, S. Finne, and O. de Moor.  Compiling embedded languages. In Semantics, Applications and Implementation of Program Generation (SAIG'00), Springer Lecture Notes in Computer Science, 2000. 5.5
[22] A. Felty. A logic programming approach to implementing higher-order term rewriting. In L.-H. Eriksson, L. Hallnas, and P. Schroeder-Heister, editors, Extensions of Logic Programming (ELP '91), volume 596 of Lecture Notes in Arti al Intelligence, pages 135{158. Springer-Verlag, 1992. 4.1
[23] W. J. Fokkink, J. F. T. Kamperman, and H. R. Walters. Lazy rewriting on eager machinery. ACM Transactions on Programming Languages and Systems, 22(1):45{86, January 2000. 5.7.3, 12
[24] M. Fowler. Refactoring: Improving the Design of Existing Programs. Addison-
Wesley, 1999. 2.2.3
[25] C. W. Fraser, D. R. Hanson, and T. A. Proebsting. Engineering a simple, eÆcient code-generator generator. ACM Letters on Programming Languages and Systems, 1(3):213{226, September 1992. 5.4
[26] C. W. Fraser, R. R. Henry, and T. A. Proebsting. BURG|fast optimal instruction selection and tree parsing. ACM SIGPLAN Notices, 27(4):68{76,
April 1992.  5.4
[27] J. A. Goguen and T. W. et. al. Introducing OBJ. Technical Report SRI-CSL- 92-03, SRI International Computer Science Laboratory, March 1992. 5.5
[28] T. E. H. Kienle, J. Czeranski. Exchange format bibliography. In Workshop on Standard Exchange Format (WoSEF), pages 2{9, Limerick, Ireland, June 2000. 3.4
[29] J. Heering. Implementing higher-order algebraic speci cations. In D. Miller, editor, Proceedings of the Workshop on the Prolog Programming Language, pages 141{157. University of Pennsylvania, Philadelphia, 1992. Published as Technical Report MS-CIS-92-86; http://www.cwi.nl/~jan/HO.WLP.ps.  4.1
[30] G. Huet and B. Lang. Proving and applying program transformations expressed with second-order patterns. Acta Informatica, 11:31{55, 1978. 3.3
[31] P. Johann and E. Visser. Fusing logic and control with local transformations: An example optimization. In B. Gramlich and S. Lucas, editors, Workshop on Reduction Strategies in Rewriting and Programming (WRS'01), volume 57 of Electronic Notes in Theoretical Computer Science, Utrecht, The Netherlands, May 2001. Elsevier Science Publishers. 5.11.5, 6.3


[32] G. Kiczales, J. Lamping, A. Mendhekar, C. Maeda, C. Lopes, J.-M. Loingtier, and J. Irwin. Aspect-oriented programming. Technical report, Xerox Palo Alto Research Center, 1997. 6.3
[33] D. Lacey and O. de Moor. Imperative program transformation by rewriting. In Compiler Construction (CC'01), Lecture Notes in Computer Science. Springer-
Verlag, April 2001. 3.2, 6.3

[34] O. de Moor and G. Sittampalam. Higher-order matching for program transformation. Theoretical Computer Science, 269(1{2):135{162, 2001.  3.3
[35] P.-E. Moreau.  Compilation de r egles de r e ecriture et de strat egies non- d eterministes. PhD thesis, L'Universit e Henri Poincar e-Nancy 1, June 22 1999. 5.9, 13
[36] S. S. Muchnick. Advanced Compiler Design and Implementation. Morgan Kaufmann Publishers, 1997. 2.1.1, 2.2.2, 3.2
[37] G. Nadathur and D. Miller. An overview of Prolog. In R. A. Kowalski, editor, Logic Programming. Proceedings of the Fifth International Conference and Symposium, volume 1, pages 810{827, Cambridge, Mass., USA, 1988. MIT Press. 4.1
[38] J. M. Neighbors. Software Construction Using Components. PhD thesis, Department of Information and Computer Science, University of California,
Irvine, 1980. 5.1

[39] J. M. Neighbors. Draco 1.2 Users Manual. Department of Information and Computer Science, University of California, Irvine, Irvine, CA, USA, June 1983. 5.1
[40] J. M. Neighbors. The Draco approach to constructing software from reusable components. IEEE Transactions on Software Engineering, SE-10(5):564{573,
September 1984.  5.1

[41] K. Ogata and K. Futatsugi. Implementation of term rewritings with the evaluation strategy. In Proceedings 9th Symposium on Programming Languages: Implementations, Logics, and Programs (PLILP'97), volume 1292 of Lecture Notes in Computer Science, pages 225{239, Southampton, 1997. Springer-
Verlag.  11, 5.7.2

[42] T. J. Parr. SORCERER reference. In Language Translation Using PCCTS and C++. A Reference Guide, chapter 4, pages 161{199. Automata Publishing Company, 1993. Available at http://www.antlr.org/buybook.html.  5.3
[43] T. J. Parr. An overview of SORCERER: A simple tree-parser generator. http://www.antlr.org/papers/sorcerer.ps, April 1994. 5.3
[44] S. Peyton Jones, J. Hughes, et al. Report of the programming language Haskell98. a non-strict, purely functional language, February 1999. 2.2.1


[45] F. Pfenning and C. Elliot. Higher-order abstract syntax. In Proc. SIGPLAN Conference on Programming Language Design and Implementation (PLDI'88), pages 199{208. ACM, 1988. 3.3, 4.1
[46] A. M. Pitts and M. J. Gabbay.  A metalanguage for programming with bound names modulo renaming. In R. Backhouse and J. N. Oliveira, editors, Proceedings of the 5th International Conference on Mathematics of Programme Construction (MPC2000), volume 1837 of Lecture Notes in Computer Science, pages 230{255, Ponte de Lima, Portugal, July 2000. Springer-Verlag. 3.3
[47] J. van der Pol. Just-in-time: On strategy annotations. In Proceedings of the International Workshop on Reduction Strategies in Rewriting and Programming (WRS 2001), 2001. 5.7.1
[48] T. A. Proebsting. BURS automata generation. ACM Transactions on Programming Languages and Systems, 17(3):461{486, May 1995. 5.4, 5.4
[49] Sarkar. Automatic selection of high-order transformations in the IBM XL FORTRAN compilers. IBM Journal for Research and Development, 41(3):233{ 264, May 1997. 6.3
[50] D. R. Smith. KIDS: A semiautomatic program development system. IEEE Transactions on Software Engineering, 16(9):1024{1043, 1990. 2.1.1
[51] E. Visser. Syntax De nition for Language Prototyping. PhD thesis, University of Amsterdam, September 1997. 2.2.1, 5.5
[52] E. Visser. Strategic pattern matching. In P. Narendran and M. Rusinowitch, editors, Rewriting Techniques and Applications (RTA'99), volume 1631 of Lecture Notes in Computer Science, pages 30{44, Trento, Italy, July	1999.
Springer-Verlag.	4.1, 5.11.4
[53] E. Visser. Language independent traversals for program transformation. In
J. Jeuring, editor, Workshop on Generic Programming (WGP'00), Ponte de Lima, Portugal, July 2000. Technical Report UU-CS-2000-19, Department of Information and Computing Sciences, Universiteit Utrecht. 5.11.5
[54] E. Visser. Stratego: A language for program transformation based on rewriting strategies. System description of Stratego 0.5. In A. Middeldorp, editor, Rewriting Techniques and Applications (RTA'01), volume 2051 of Lecture Notes in Computer Science, pages 357{361. Springer-Verlag, May 2001. 5.11
[55] E. Visser, Z.-e.-A. Benaissa, and A. Tolmach. Building program optimizers with rewriting strategies. ACM SIGPLAN Notices, 34(1):13{26, January 1999. Proceedings of the International Conference on Functional Programming (ICFP'98). 5.11
[56] E. Visser et al. The online survey of program transformation. www. program-transformation.org, 2000{2001. 6.4
[57] P. Wadler. Views: A way for pattern matching to cohabit with data abstraction. In ACM Symposium on Principles of Programming Languages, pages 307{313, Munich, January 1987. ACM. 4.1
