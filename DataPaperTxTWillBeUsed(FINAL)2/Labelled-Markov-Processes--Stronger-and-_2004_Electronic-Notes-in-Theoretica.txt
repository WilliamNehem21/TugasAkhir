Electronic Notes in Theoretical Computer Science 87 (2004) 157–203 
www.elsevier.com/locate/entcs


Labelled Markov Processes: Stronger and Faster Approximations
Vincent Danos
Universit´e Paris 7, Paris
Jos´ee Desharnais
Universit´e Laval, Qu´ebec
Prakash Panangaden
University of Oxford, Oxford and McGill University, Montr´eal

Abstract
This paper reports on and discusses three notions of approximation for Labelled Markov Processes that have been developed last year. The three schemes are improvements over former construc- tions [11,9] in the sense that they define approximants that capture more properties than before and that converge faster to the approximated process. One scheme is constructive and the two others are driven by properties on which one wants to focus. All three constructions involve quoti- enting the state-space in some way and the last two are quotients with respect to sets of temporal properties expressed in a simple logic with a greatest fixed point operator. This gives the possibility of customizing approximants with respect to properties of interest and is thus an important step towards using automated techniques intended for finite state systems, e.g., model checking, for continuous state systems. Another difference between the schemes is how they relate approximants with the approximated process. The requirement that approximants should be simulated by the approximated process has been abandoned in the last scheme.
Keywords: Probability theory, Labelled Markov Processes, Approximation.










1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.09.018

Contents


Introduction
Acknowledgement
Preliminaries
Notations
Measurable spaces and Probabilities
Labelled Markov Processes
Aside: analytic state spaces
Temporal properties and simulation
Improved Constructive Approximation
Abstract Approximations
Pre-LMPs
Temporal properties
Co-simulation morphisms
The infimum construction
Aside: another infimum construction
Quotients and Simulations
Quotients and Logical Properties
Abstract approximants are optimal
The sup-quotient
Stronger Approximants
Semantics of L∗ via fixed points
Semantics of L∗ via simulations
Quotients with L∗
Approximation through average
Conditional expectation
The finite case
The example that says it all
When Ep( |Λ) is unique
Projecting LMPs
A “uniform” probability on (S, σ(L0))
Compressing Σ
Approximations
Convergence
Conclusion References
159
161
162
162
162
163
164
164
166
172
173
174
175
176
177
178
180
181
182
182
184
187
188
190
191
192
193
194
195
196
197
198
198
199
202

Introduction
Labelled Markov Processes (LMPs) are probabilistic transition systems where the state space might be any general measurable space, in particular this includes situations where the state space may be continuous. They are es- sentially traditional discrete-time Markov processes enriched with a notion of interaction by synchronization on labels, familiar from process-algebras. They have been studied intensively in the last few years especially in relation with the question of bisimulation [7,10,11,21,20,12]. This is because they embody simple probabilistic interactive behaviours, and yet are rich enough to encom- pass many examples and to suggest interesting mathematics.
The initial motivation was the inclusion of continuous state spaces with a view towards eventual applications involving stochastic hybrid systems. An unexpected benefit of this additional generality has been the discovery that a simple temporal probabilistic logic, L0, captures a natural notion of equiv- alence between such processes, namely strong bisimulation. Remarkably this logic needs neither infinite conjunction, even though the systems may have even uncountable branching, nor negation nor any kind of negative construct (like the “must” modality). With this logical view, it became natural to think of the interplay between discrete structures (the logic) and the continuous mathematics of LMPs (measure and probability theory). This led to the im- portant question of understanding what it means to be an approximation of a given LMP and especially of a “finite” approximant.
The approximation theory has developed along two lines. Desharnais et. al. [10] have developed a metric between LMPs which can be viewed as a “re- laxation” of the notion of strong bisimulation. This metric can be used to say that one LMP “comes close to” behaving like another. The other direction was to develop a notion of “finite” approximant [11,9] and cast this in a do- main theoretic setting. The papers just cited established that even a system with an uncountable state space could be approximated by a family of finite state processes. The family of approximants converge to the system being ap- proximated in both metric and domain-theoretic senses. The approximations interact smoothly with the logic in the following sense. Any formulas of L0 that are satisfied by any approximant of P are satisfied by the process P itself and any formula satisfied by P is satisfied by some approximant.
At that point, there remained two soft spots in the approximation theory. First, while an approximant clearly ought to be some sort of finite quotient by temporal properties of the process being approximated, nobody so far was able to lay his hands on a precise way of phrasing just this intuition. Previous results state that every approximant satisfies some subset of the L0 properties that the process being approximated satisfies, but one does not have a way


of saying in advance what these properties are. Second, another motivation for developing the theory further is that when fed with a finite process the approximation machinery was unable to retrieve the process itself in the limit. Instead, a bisimilar process was obtained. For instance, the pure loop process, with one state and one a-transition to itself, was approximated by all its finite unfoldings, i.e., by chains of a-transitions; this seems spectacularly not what one would like to have intuitively, even if it is acceptable on the technical side (the infinite chain of a-transitions is bisimilar to the loop, after all).
The first approximation scheme that we present in this paper is an im- provement of an unfolding scheme [9] that circumvent the second limitation. The two other approximation notions that we present are variants that over- come both limitations. They have been introduced in recent papers by Danos and Desharnais [5] and by Danos, Desharnais and Panangaden [6]. Concern- ing the former, we take a here a slightly different route and correct a mistake in the original paper. We also strengthen the latter notion by considering L0 extended with fixed points operators.
Specifically the first approach is based on the idea that the approximations can be “guided” by a family of formulas of interest. In other words, if there is a set of formulas of particular importance, one can construct a specific finite approximant geared towards these formulas. One can then be sure that the process in question satisfies a formula of interest if and only if the approxi- mant does. Second, a much more compact representation is used so that loops are not unwound and convergence is attained more rapidly. A disadvantage is that the approximations obtained are not LMPs because the transition “prob- abilities” are not measures. Instead they are close to the measure-theoretic notion of capacity [2]. Capacities are not additive but they have instead a continuity property and are sub (or super) additive. Our LMP approximants will use superadditive and co-continuous set maps.
Actually, one can have the best of both worlds, keeping the flexibility of a customizable approach to approximation and staying at the same time within the realm of LMPs. This what the second approach does. It is based on a radical departure from the ideas of the previous approaches [5,9]. In these approaches one always approximated a system by ensuring that the transition probabilities in the approximant were below the corresponding transition in the full system. Here we approximate a system by taking a coarse-grained discretization (pixellization) of the state space and then using average values. This new notion is not based on the natural simulation ordering between LMPs as were the previous approaches.
Instead of simulation we use conditional expectation. This is a traditional construction in probability theory which, given a probability triple (S, Σ, p)


(sample space), a Σ-measurable random variable X (observation), and a sub-σ algebra Λ (pixellization of the sample space), returns the conditional expec- tation of X with respect to p and Λ. This conditional expectation is written Ep(X|Λ) and in some suitable sense is the best possible Λ-measurable approxi- mation of X. The best will prove to be enough in our case, in that conditional expectations will construct for us low-resolution averages of any given LMP. Furthermore, an LMP will be known completely, up to bisimilarity, from its finite-resolution (meaning finite state) averages.
Moreover the new construction gives closer approximants in a sense that we will have to make precise later. They are also likely to be more robust to numerical variations in the system that one wants to approximate, since they are based on averages. Of course this is a speculative remark and needs to be thrashed out in subsequent work. To summarize, the new approximants are customizable, probabilistic and more accurate and possibly more robust as well. Beyond this construction, we would like to convey the idea that prob- ability theory and its toolkit - especially the uses of averages and expectation values - are remarkably well adapted to a computationally-minded approach to probabilistic processes. It has a way of meshing finite and continuous no- tions of computations which is not unlike domain-theory. We expect far more interaction in the future between these theories than what is reported here. Work on probabilistic powerdomains [16] and integration on domains [13,14] provides a beginning. Curiously enough the bulk of work in probabilistic pro- cess algebra rarely ever mentions averages or expectation values. We hope that the present paper stimulates the use of these methods by others.


Acknowledgement
The first author wishes to thank Prakash Panangaden for the lecture series on Labelled Markov Processes given during his stay in Paris in May 2002 at the PPS lab, and for numerous instructive discussions about the subject as a whole. He also wishes to thank Franc¸ois Laviolette for suggesting many improvements to the ideas developed in this paper. Jos´ee Desharnais and Prakash Panangaden have benefitted immensely from discussions with Vineet Gupta and Radha Jagadeesan. All of us have benefitted from the stimulating atmosphere at the Bellairs Institute of McGill University on Barbados and would like to thank all the participants of the workshop on Domain Theoretic Methods for Probabilistic Processes. Jos´ee Desharnais would like to acknowl- edge the support of NSERC and FCAR. Prakash Panangaden would like to thank NSERC for support.

Preliminaries
This section is a brief reminder of the main objects of the trade with definitions slightly optimized for the development we have in mind. The paper is self- contained, though the reader might find useful to consult a book on basic probability theory, such as David Williams’ book [22].

Notations
When S is a set and A ⊆ S, we write 1A for A’s indicator function (this is sometimes called the characteristic function of A). When A, B are disjoint sets, we sometimes write A + B for the (disjoint) union, and conversely each time we write A + B it is understood that A and B are indeed disjoint. We write ↓An when An is a decreasing sequence of sets, that is An ⊇ An+1 and
∩An for the limit. Similarly we write ↑An for an increasing sequence of sets
An, i.e., An ⊆ An+1 and ∪An for the limit.
When R is an equivalence relation over S, and s ∈ S, the equivalence class of s is written either [s]R or simply [s], when R is clear from the context. If A is a set of equivalence classes, one uses the usual set-theoretic notation for union ∪A := {s ∈ S | [s] ∈ A}. When R is a binary relation over S, not necessarily an equivalence relation, one writes R(s) for {t | (s, t) ∈ R}. One also says that a set A is R-closed, if whenever s ∈ A and (s, t) ∈ R, t ∈ A, or in other words, if for all s ∈ A, R(s) ⊆ A.

Measurable spaces and Probabilities
A measurable space is a pair (S, Σ) where S is a set and Σ ⊂ 2S is a σ-algebra over S, that is, a set of subsets of S, containing S and closed under countable intersection and complement. Well-known examples are [0, 1] and R equipped with their respective Borel σ-algebras generated by the intervals which we will both denote by B.
A map f between two measurable spaces (S, Σ) and (S', Σ') is said to be measurable if for all A' ∈ Σ', f −1(A') ∈ Σ. Writing σ(f ) for the σ-algebra generated by f , namely the set of subsets of the form f −1(A') with A' ∈ Σ', one can rephrase this by saying σ(f ) ⊆ Σ.
The set of measurable maps from (S, Σ) to (R, B) will be denoted mΣ. It is easily seen that a map f from (S, Σ) to (R, B) is in mΣ, if and only if for all r ∈ R, f −1((r, +∞)) ∈ Σ (or f −1([r, +∞)) ∈ Σ). This latter set is sometimes written {f > r} ({f ≥ r}). One says a map f from (S, Σ) to (R, B) is simple, if it can be writteΣn as  i≤k ai1Ai , with ai ∈ R, and Ai ∈ Σ. Any

disjoint, in which case {f > r} = ∪{i|a >r}A' which is in Σ, and one sees that
i	i
all simple maps are in mΣ. We also take note, for further use, that countable
infima preserves measurability. Indeed if fn is a sequence in mΣ, then for all
r, {infn fn ≥ r} = ∩n{fn ≥ r}
A subprobability on (S, Σ) is a map p : Σ → [0, 1], such that for any countable collection (An) of pairwise disjoint sets in Σ, p( n An)=  n p(An). A subprobability is an actual probability when in addition p(S) = 1. The condition on p is called σ-additivity and can be conveniently broken up into two parts:
additivity : p(A ∪ A')= p(A)+ p(B), for A, B disjoint,
continuity : ∀ ↑An ∈ Σ: p(∪An)= supn p(An).
Let (S, Σ, p) be a probability triple, that is to say a measurable space (S, Σ) together with a probability p. A subset N ⊂ S is said to be negligible if there exists a A ∈ Σ such that N ⊆ A and p(A)= 0.
We write Np for p-negligible subsets. Two functions X, Y on (S, Σ, p) are said to be almost surely equal, written X = Y a.s., if {s ∈ S | X(s) /= Y (s)}∈ Np. Sometimes we say p-a.s. equal if we wish to emphasize which measure we are talking about.
The subset of mΣ consisting of the functions that are integrable with respect to p will be denoted by L1(S, Σ, p). A last piece of notation that we will use is to write Xn ↑ X when Xns and X are in mΣ, meaning that Xn ≤ Xn+1 with respect to the pointwise ordering and Xn converges pointwise to X.
Labelled Markov Processes
We begin by defining the objects of interest:
Definition 2.1 [LMP] S = (S, Σ,h : L × S × Σ → [0, 1]) is a Labelled Markov Process (LMP) if (S, Σ) is a measurable space, and:
for all a ∈ L, A ∈ Σ, h(a, s, A) is Σ-measurable as a function of s;
for all s ∈ S, h(a, s, A) is a subprobability as a function of A.
A pointed LMP is an LMP with a distinguished state i, called the initial state, and is written S = (S, i, Σ, h).
Given a state property, one says a pointed LMP has this property if its initial state has it. For instance, one says two pointed LMPs are bisimilar when their two initial states are. After the traditional terminology in Markov chains, the map h is called the kernel or the transition probability function of S. Most of the time, we will write h(a, s, A) simply as ha(s, A). It is a measure of the likelihood that being at s and receiving a the LMP will jump to a state in A.
Some particular cases: 1) when S is finite and Σ = 2S we have the familiar


probabilistic transition system, 2) when h(a, s, A) does not depend on s or on a, we have the familiar (sub)probability triple. An example of the latter situation is ([0, 1], У, h) with h(a, s, B)= λ(B) with λ the Lebesgue measure on the collection У of Borel sets.
Equivalently LMPs can be defined as follows:
Definition 2.2 [LMP2] A Labelled Markov Process consists of a measurable space (S, Σ) and a family of Σ-measurable functions (h(a, A))a∈L,A∈Σ with values in [0, 1], such that:
additivity: for all disjoint A, B in Σ: h(a, A ∪ B)= h(a, A)+ h(a, B);
continuity: for all increasing sequence †An in Σ: h(a, ∪An)= sup h(a, An).
From the definition it follows that for all a, s, one has h(a, S)(s) ≤ 1.
In this second definition we view an LMP as a Σ-indexed family of Σ- measurable functions, namely the random variables “probability of jumping to A in one step labelled with a”, instead of an S-indexed family of probabilities on Σ. Both definitions are related by h(a, s, A) = h(a, A)(s) and we will use whichever is more convenient in the following sections. Another license we will take is not to mention actions when, as is often the case, they are not relevant in a particular example or proof, and simply write h(s, A) or h(A)(s).

Aside: analytic state spaces
In previous treatments, the LMP state space was required to be an analytic topological space [7]. Bisimulation and simulation can be defined either di- rectly through behavioural conditions on kernels, or, indirectly, by using logi- cal characterizations. These logical and behavioural definitions only coincide when the state space is analytic. In the present paper, one mostly uses the latter form of definition, and therefore one has no need for the analytic struc- ture.

Temporal properties and simulation
LMPs differ from standard Markov chains in that the kernels are only asked to be subprobabilities and also depend on an auxiliary set L of actions. This seemingly small difference leads to a very different interpretation for them. They are construed as interactive processes which synchronize on labels and therefore one is interested in various notions of bisimulations and simulations as in non-deterministic process algebras [18].
The following “bisimulation logic” L0 is a central tool for asserting prop- erties of LMPs:
θ := T| θ Λ θ | ⟨a⟩rθ.


The depth |θ| of a formula θ is defined as: |T| = 0, |θ0 Λ θ1| = max(|θ0|, |θ1|) and |⟨a⟩rθ| = |θ| + 1.
Definition 2.3 Given an LMP S, one may inductively define the map [.]]S :
L0 → Σ as:
[[T]]S = S,
[[θ0 Λ θ1]]S = [[θ0]]S ∩ [[θ1]]S ,
[[⟨a⟩rθ]]S = {s ∈ S | ha(s, [[θ]]S ) ≥ r}
Sometimes, one needs a strict form of ⟨a⟩rθ, written ⟨a⟩>rθ, the semantics of which is defined as [[⟨a⟩>rθ]]S = {s ∈ S | ha(s, [[θ]]S ) > r}. This variant is used in the approximation construction of the next section but not otherwise. The logic L0 can also be added a disjunction, interpreted as the union, i.e. [[θ0 ∨ θ1]]S = [[θ0]]S ∪ [[θ1]]S , and the resulting logic is called L∨.
We write s |= θ to mean s ∈ [[θ]]S and θ' ≤ θ to mean that θ' is a subformula of θ. Monoidal equations: θ0 Λ (θ1 Λ θ2) = (θ0 Λ θ1) Λ θ2, θ0 Λ θ1 = θ1 Λ θ0, θ ΛT = θ all clearly preserve [.]]S .
Given a set F of formulas of L0, one can compare two states with respect to this set. We write sometimes s ≈F t to mean that s and t satisfy the exact same formulas of F.
The logic also induces a form of simulation between states in the sense that a state can be said to simulate another one if it satisfies at least the same formulas as the other does. The concept can be cast in behavioural terms as in the following definition.
Definition 2.4 [11] Let S = (S, Σ, h) be a LMP. A relation R on S is a simulation if whenever sRs', we have that for all a ∈ L and every R-closed set A ∈ Σ, ha(s, A) ≤ ha(s', A). We say s is simulated by s' if sRs' for some simulation relation R. If S and T are pointed LMPs, we say that S simulates T if the initial state of S simulates the initial state of T .
This definition can be extended easily to simulation between states of dif- ferent LMPs.
The notion of simulation meshes properly with the logic in the sense of the following proposition.
Proposition 2.5 [11] If s simulates s', then for all formulas θ ∈ L0, s' |= θ
implies s |= θ.
If one adds disjunction to L0, the converse of this result is also true; that is, the simulation induced by the logic L∨ is equivalent to Definition 2.4 (but this result uses analyticity of the state space [11]).
One can construct a family of metrics, dc for c ∈ (0, 1), all of them be-


ing closely related to L0, and which one can think of each as measuring the complexity of the simplest distinguishing formula between two states, if any.
We don’t give here the precise definition of these metrics here, but we do want to use them to have neat convergence statement for approximants. For that matter, it is enough to use the following result, which is a direct consequence of results relating the logic and the metrics [10].
Proposition 2.6 Let (Fi)i∈N be an increasing sequence of sets of formulas converging to the set of all formulas of L0. Let S be an LMP and (Si)i∈N a sequence of LMPs. If Si ≈Fi S for every i, then for all c ∈ (0, 1)
dc(Si, S)−→i→∞0.

With these preliminary definitions in place, we move on to the first ap- proximation scheme.

Improved Constructive Approximation
In this section and the following, we propose two ways of approximating LMPs from below. The goal is to determine a family of finite processes that are sim- ulated by the original LMP, and converge to it. We will work with pointed LMPs, because this is convenient when it comes to comparing an LMP with its approximations. The first approach, explained in the present section, de- pends on two parameters, the depth of observation and the accuracy of the probabilities. It improves on a former LMP approximation scheme based on an “unfolding” construction [9]. In this original scheme, as the approximation was refined, there were more and more transitions possible. We follow almost the same idea in the new construction. Some limitations of this first approach will be overcome by the second approach, given in the next section, and based on quotients with respect to sets of formulas.
The state-space is constructed as in the original scheme, but there will be “more” transitions possible, specifically some transitions will introduce cy- cles. As said, there are two parameters to the approximation: one is a natural number n, and the other is a positive rational ϵ. The number ϵ measures the accuracy with which the transition probabilities of the approximant approx- imate the transition probabilities of the original process. The parameter n represents the depth of our observation; in the original scheme, n was also the depth of the (acyclic) transition graph of the approximant itself, but it is no longer the case in the improved scheme, since it obtains cyclic graphs.
Given a labelled Markov process S = (S, Σ, h), a natural number n and a rational number ϵ > 0, we define S∗(n, ϵ) as an n-step unfolding approximation


of S. Its state-space is divided into n+1 levels which are numbered 0, 1,..., n. Bisimulation is the greatest fixed point of a suitable operator on relations and that one has - for each n -a level n approximation to bisimulation [9]. At each level, say n, the states of the approximant is a partition of S corresponding to what one might call n-bisimulation up to precision ϵ. The initial state of S∗(n, ϵ) is at level n and transitions from a state of level l go to a state of level l or l − 1. Thus, in particular, the unique state of level 0 either has no outgoing transitions or has a transition to itself. The main difference between the improved scheme and the original one is that transitions to states at the same level are now allowed.
In the following we omit the curly brackets around singletons.
Definition 3.1 Let (S, i, Σ, h) be a labelled Markov process, n ∈ N and ϵ a positive rational. We define the finite-state approximation S∗(n, ϵ) as the tuple (P, p0, 2P , ρ) where:
P is a finite subset of Σ × {0,... , n}; the numbers from 0 to n correspond to the level of the states. States are defined by induction on their level.
At level 0 there is one state (S, 0).
Now, given the states (C1, l), (C2, l),... , (Cm, l) at level l, we define states of level l + 1 as follows. Let (Bj)j∈I be the partition
{{0}, (0, ϵ/m], (ϵ/m, 2ϵ/m],... }
of the interval [0, 1] into intervals of size ϵ/m, where m is the number of states at level l. States of level l + 1 are obtained by forming the coarsest

common refinement of the partition {Ci}m
and the partition generated by

the sets ha(·, Ci)−1(Bj), for every set Ci and every a ∈ L, j ∈ I. If a set X
is in this partition of S, (X, l + 1) is a state of level l + 1.
The initial state p0 of S∗(n, ϵ) is the unique state (X, n) such that X contains
i, the initial state of S.
Transitions can happen between states of the same level, or from a state to a state of the preceding level, and the transition probability function is given as follows. Let (X, l + 1), (Y, l + 1), (Z, l) be states of level l +1 and l, where l ≥ 0. Then we set:
ρa((X, l + 1), (Y, l + 1)) := infx∈X ha(x, Y )
ρa((X, l + 1), (Z, l))	:= infx∈X ha(x, Z)

k i=1
ρa((X, l + 1), (Zi,l + 1))



where {Zi}k
is the unique partition of Z such that (Zi,l + 1) is a state for

every i. Unspecified transitions are given the value 0.

The partition of S at level l + 1 is defined in such a way that every state x ∈ X (where X is a member of the partition) has probability within ϵ/m to jump to every set in the partition of level l (not necessarily true for transitions to states of level l + 1). Intuitively, transitions are filled as follows: from a given state (X, l + 1), transitions to states at the same level are given the maximum possible probability (compatible with the condition of staying below all simulating states x ∈ X). This would not be sufficient to guarantee that the transition stays close to the corresponding transition of S because the partition of level l + 1 is constructed with respect to states of level l. Since this condition is essential to preserve the accuracy of the approximation — and the statement of the lemma below reflects this — we complete the probability by adding transitions to states (Z, l).
Let us introduce here a few further notations. If s ∈ S, we denote by (Xs, l) the unique state at level l such that s ∈ Xs. We will write (Y, l) for the set {(Y1, l), (Y2, l),... }, where Y = ∪Yj; in this case, we often say that Y is a union of sets at level l and that the Yi’s correspond to states of level l. By extension, we will write ρa((X, l + 1), (Y, l)) to mean  j ρa((X, l + 1), (Yj, l)). The same notation will be used when we work with states of consecutive levels corresponding to the same subset of S: for example, we will write (Y, l ∪ l + 1)
to mean {(Y1, l), (Y2, l), ··· , (Y ',l + 1), (Y ',l + 1), ··· }, with ∪Yi = ∪Y ' = Y .
1	2	i
Note that every set of level l − 1 is a union of sets of level l because the
partition of S at level l is a refinement of the partition at level l − 1.
The following lemma uses crucially the fact that the partition of [0, 1] depends on the number of states m at the preceding level. This is because the kernels ρa are defined as infima, and therefore introduce a default of additivity, which one has to keep under control by refining the precision. The next section will offer a direct treatment of approximation via superadditive kernels.
Lemma 3.2 Let S be a labelled Markov process, and s ∈ S. In S∗(n, ϵ), if Y
is a union of sets appearing at level l, then:
0 < ha(s, Y ) − ρa((Xs,l + 1), (Y, l ∪ l + 1)) ≤ ϵ.

Proof. The first inequality is trivial. Before proving the second one, note that the lemma is not necessarily true if Y is a union of sets appearing at the same level as (Xs,l + 1).
Let s ∈ S and (Xs,l + 1), (Yi,l + 1), (Y ', l), i = 1,... , k, j = 1,... , k' be

states of S∗(n, ϵ) such that Y = ∪k  Yi
k' j=1
Y '. Let m be the number of

states at level l. Then for all j = 1,..., k' and t ∈ Xs we have
|ha(s, Y ') − ha(t, Y ')| < ϵ/m,
j	j
because of the way S is partitioned on level l + 1. Moreover, we have
ρa((Xs,l + 1), (Y, l ∪ l + 1))
= ρa((Xs,l + 1), (Y, l)) + ρa((X, l + 1), (Y, l + 1))
k'	k
= Σ ρa((Xs,l + 1), (Y ', l)) + Σ ρa((Xs,l + 1), (Yi,l + 1))

j=1 k'
=	inf
s∈Xs

ha(s, Y '))
i=1

and hence
j=1

|ha(s, Y ) − ρa((Xs,l + 1), (Y, l ∪ l + 1))|
k'	k'

= | Σ ha(s, Y ') − Σ inf
ha(s, Y ')|

j=1 k'
j
j=1
s∈Xs	j

≤ Σ |ha(s, Y ') − inf
ha(s, Y ')|

j
j=1 k'
≤	ϵ/m
j=1
s∈Xs	j

≤ ϵ.	 
Since every transition probability of S∗(n, ϵ) is smaller than in the corre- sponding transition in S, then every state (X, l) in S∗(n, ϵ) is simulated by every state s ∈ X in S.
Proposition 3.3 Every labelled Markov process S simulates all its approx- imations of the form S∗(n, ϵ). More precisely, every state (X, l) of S∗(n, ϵ) (l ≤ n) is simulated in S by every s ∈ X.
Proof. The proof is conceptually easy but the notation necessary for the bookkeeping makes it hard to read. Let S∗(n, ϵ) = (P, p0, ρ) and let U = (U, u0, Ω, ν) be the direct sum of S∗(n, ϵ) and S. Now let R be the relation on U that relates a state (X, l) from S∗(n, ϵ) to every state s ∈ X from S. We prove that R is a simulation. Consider two related states, (X, l) and s ∈ X and let Z ∈ Ω be R-closed, that is, Z ∩ S ∈ Σ and R(Z ∩ P ) ⊆ Z. We want to prove that νa((X, l),Z ∩ P ) ≤ νa(s, Z ∩ S). We will prove the inequality for Z∗ a set containing Z ∩ P and defined as follows: Z∗ is the smallest set


containing Z ∩ P and satisfying the property that if it contains a state of level l − 1, it contains every corresponding state of level l. This is possible because the partition of level l is finer than the one of level l − 1. Of course, Z∗ may contain some other state of level l that do not intersect states of level l − 1.
The only transitions with positive probability from (X, l) are to states of level l and l − 1 so we can assume that Z∗ is a union of states of these levels, and hence it must be of the form
Z∗ = (Y ',l ∪ l − 1) ∪ (Y, l),
where, as before, the notation (Y, l) may refer to a union of sets of level l. By the way Z∗ is constructed, Y ∪ Y ' ⊆ Z ∩ S. Then we have, by (the first inequality of) the preceding lemma
νa((X, l),Z ∩ P ) ≤ ρa((X, l), Z∗)
= ρa((X, l), (Y ',l ∪ l − 1)) + ρa((X, l), (Y, l))
k
≤ ha(s, Y ')+ Σ ρa((X, l), (Yi, l))	where ∪k	Yi = Y
i=1 k
= ha(s, Y ')+	inf ha(s, Yi)
s∈X
i=1
≤ ha(s, Y ')+ ha(s, Y )
= ha(s, Y ' ∪ Y )
≤ νa(s, Z ∩ S)
and hence the result.	 
The next theorem is the main result of this section. The proof is exactly the same as for the previous version of the construction except for the very last sequence of inequalities, which is adapted to the fact that transitions can happen between states of the same level. Notice that here we use a semantics for L∨ with strict inequality in the modal formula.
Theorem 3.4 If a state s ∈ S satisﬁes a formula φ ∈ L∨, then there is some approximation S∗(n, ϵ) such that (Xs, n) |= φ.
Proof. The proof is by induction on the structure of formulas. We prove the following stronger induction hypothesis. We prove that for all formulas φ there is an increasing sequence (Xn)n≥|φ| of sets in Σ which satisfy:
∪n≥|φ|Xn = [[φ]]S ;
Xn = ∪s∈Xn Cs, where (Cs, l) ∈ S∗(n, 1/2n) and l ≥ |φ|;
the states (Cs, l) satisfy φ in S∗(n, 1/2n).

It is obvious for T with Xn = S for all n.
Consider φ = φ1 Λ φ2. Assume the claim is true for φj, j = 1, 2. Let (Xj)n≥|φ | be the sequence for φj. Now define for n ≥ |φ|, the sequence
n	j
Xn = X1 ∩ X2.
n	n
Note that this is an increasing sequence of sets in Σ. We first prove (i): for all s |= φ, there is some n such that s ∈ Xn. Choose n = max(n1, n2) where nj is such that s ∈ Xj . Now for (ii) and (iii), let s ∈ Xn, for a fixed n ≥ |φ|. Then because all states (Cs, l) satisfy φj and Cs ⊆ Xj , we have (Cs, l) |= φ1 Λ φ2 and Xn = ∪s∈Xn Cs. The proof for the case φ1 ∨ φ2 is similar.
Consider φ' = ⟨a⟩>qφ, and assume the claim is true for φ. Let d = |⟨a⟩>qφ|,
ϵn = 1/2n and let (Xn)n≥d−1 be the sequence for φ.
Now define for n ≥ d, the sequence
Yn = ∪{C : (C, d) ∈ S∗(n, ϵn), and ∀s ∈ C, ha(s, Xn) > q + ϵn}.
This is an increasing sequence of sets in Σ because if (C, d) ∈ S∗(n, ϵn) and C ⊆ Yn, then for all s ∈ C we have ha(s, Xn+1) ≥ ha(s, Xn) ≥ q + ϵn. Moreover, if (C', d) is a state of S∗(n, ϵn+1) and s, t ∈ C', then ha(t, Xn+1) > ha(s, Xn+1) − ϵn+1 ≥ q + ϵn − ϵn+1 = q + ϵn+1.
We now prove (i), that is, for all s |= φ', there is some n such that s ∈ Yn. So assume ha(s, [[φ]]) > q. Then there is some n such that ha(s, Xn) − q > 2ϵn because ha(s, ·) is a measure and Xn is an increasing sequence which converges to [φ]] and ϵn (= 1/2n) is decreasing to 0. Now since Xn is a union of states of level l − 1 ≥ d − 1, then for every t ∈ Cs, with (Cs, l) a state of S∗(n, ϵn) we have
|ha(s, Xn) − ha(t, Xn)| < ϵn
and hence ha(t, Xn) − q > ϵn. Thus Cs ⊆ Yn and (i) and (ii) are proved. Note that the inequality sign in the meaning of the modal formula was crucial to this part of the proof.
We now prove (iii). Let s ∈ Yn, for a fixed n ≥ d. Then because all states (X, l − 1), where X ⊆ Xn and l − 1 ≥ d − 1, satisfy φ and by Lemma 3.2, we have
ρa((Cs, l), ([[φ]]S∗(n,єn),l ∪ l − 1)) ≥ ρa((Cs, l), (Xn,l ∪ l − 1))
≥ ha(s, Xn) − ϵn
>q + ϵn − ϵn = q,
and hence, (Cs, l) |= φ' for all l ≥ d as wanted in (iii).	 
The following results shows that a finite process is eventually approxi- mated by itself. This is the main reason why we have introduced this new

construction.
Corollary 3.5 For every ﬁnite process there exists a bisimilar approximation.
Proof. Since the process S is finite, the partition at the highest level of S∗(n, 1/2n) must stabilize when n increases. In fact, it must converge to the bisimulation equivalence classes. Indeed, if two states are not bisimilar they must be distinguished by a formula φ. Then by the (proof of the) previous theorem there is some n such that the two states are not in the same set of S∗(n, 1/2n). Thus the partition at the highest level corresponds exactly to the bisimulation equivalence classes. By construction of approximants, transitions from states of this level will only happen to states of this same level and hence the result.	 
Corollary 3.6 Let S be an LMP. Then for c < 1 we have
dc(S, S∗(n, 1/2n)) → 0
and it is also true for c = 1 if the set of inﬁnite sequences of non-bisimilar states starting in the initial state of S is of measure 0.

Abstract Approximations
Looking again at the construction above, one might wonder why Theorem 3.4 is so hard to prove. Indeed, we partition the state-space with respect to some depth and some accuracy of transition probability in such a way that one could think that the construction is faithful to formulas of the right depth and with probabilities that are a multiple of the accuracy. However, by taking the infimum, we lose some probabilities to unions of sets. This is because the infimum over a disjoint union is greater than or equal to the sum of infima over its parts. By not taking this into account, i.e., by underestimating the transition probabilities to sets of states, we get slightly away from the logic. This is one reason why the logic must have a strict inequality sign in the modal formula. In the approximation scheme presented in this section, we will take all transitions into account and we will show how to quotient an LMP by a set of L0 formulas. A natural candidate for the quotient kernel is to take the infimum of the original kernel over equivalent states. This is what we have done in the preceding section, by defining the state-to-state transition using the infimum and then defining the transition probability to a set of states to be the sum of the transition probabilities to the individual states in the set; this way we manifestly have additivity. This leads to underestimating the transition probabilites to sets of states quite drastically. We can try to use the


infimum to sets of states and get a perhaps better estimate of the approximate transition probabilities. Unfortunately this destroys additivity; if we take a set of probability distributions {µi|i ∈ I} and attempt to define a “measure” by µ(A) = infi∈I µi(A) we lose additivity. The following example illustrates why and also shows that taking infima over sets of states can give very bad estimates.
Example 4.1 Consider the following LMP, where unweighted transitions are of probability 1.
s0  b[.5]  s   a  s1  a	 · 
¸¸¸	,,
¸¸	,b

b[.5]
¸¸v za	 
,,,vz
·

We want to quotient it with respect to the equivalence defined by all formulas of the form ⟨a⟩rT and ⟨b⟩rT for all r ∈ [0, 1]. The result is as follows:
[s ]  b[1]  [s , t]  a  [s ]

0




Both dotted transitions are given value 0, for
1
]
·


inft∈[s] ha(t, ∪[s1]) = inft∈[s] ha(t, {s1})=0 
and similarly for dead states. However inft∈[s] ha(t, {s1, ·}) = 1. Hence the re- sulting transition probability function is not a measure and hence the quotient is not an LMP.
This example illustrates that if we want to take infima, we will have to weaken something in the objects of study. In the preceding section, the weak- ening was on the logical requirements, in this section we will weaken the notion of LMPs. This can be done because even if infima do not preserve additivity of measures, they do preserve super-additivity.
Pre-LMPs
The difference between a pre-LMP and an LMP lies in the following definition.

Definition 4.2 Given a measurable space (S, Σ), a function f :Σ → [0, 1] is called a pre-measure if:
∀A, B ∈ Σ disjoint: f (A + B) ≥ f (A)+ f (B);
∀ ↓An ∈ Σ: f (∩An)= infn f (An).


Easy consequences of the first condition are f (∅) = 0 and monotonicity: A ⊆ B ⇒ f (A) ≤ f (B). The second property is a (co)continuity property. If one replaces the inequation in the first clause by an equation, the definition is equivalent to f being a sub-probability. Choquet introduced a similar notion under the name “capacity” [2] and realized the importance of keeping con- tinuity while giving up additivity. This definition is weaker than Choquet’s since he required both (upwards) continuity and (downwards) co-continuity.
Definition 4.3 A pre-LMP is a triple S = (S, Σ,h : L × S × Σ → [0, 1]) where (S, Σ) is a measurable space, and for all a ∈ L, s ∈ S, A ∈ Σ: ha(s, .) is a pre-measure, and ha(., A) is measurable.
The intent of this definition is to use pre-LMPs as estimators for LMPs. It is not necessary that the estimation engine be of the same nature as what it tries to estimate. What we are interested in is how easy it is to handle and how well it estimates. Pre-LMPs turn out to be better estimators than LMPs as will be illustrated in Proposition 4.19.

Temporal properties
Semantics of L0 still makes sense with pre-LMPs.
Lemma 4.4 For all pre-LMP S and θ ∈ L0: [[θ]]S ∈ Σ.
Proof.	Easy induction on L0.	 
To the modal operator of L0, namely ⟨a⟩r, a family of maps is naturally associated, still written ⟨a⟩r :Σ → Σ and called the shifts:

⟨a⟩r(A) := {s ∈ S | ha(s, A) ≥ r}.

Clearly ⟨a⟩r(A)= ha(., A)−1([r, 1]), and ha(., A) being measurable for all A ∈
Σ, one has that ⟨a⟩r(A) ∈ Σ (actually, ha(., A) is measurable iff for all r,
⟨a⟩r(A) ∈ Σ). As said in the preceding section, one can also define the strict shifts as ⟨a⟩>r(A) := {s | ha(s, A) > r}, which are endomaps of Σ as well.
With this new notation: [⟨a⟩rθ]]S = ⟨a⟩r([[θ]]S ).
Actually a much stronger statement than the lemma above can be made:
Theorem 4.5 [3] Let (S, Σ, h) be an LMP, the σ-algebra generated by ([[θ]]S )θ∈L0
is the smallest sub-σ-algebra of Σ which is closed under the shifts ⟨a⟩r.
The theorem deserves mention because it gives purely measure-theoretic status to L0 and besides, we will use it again in the next section.

Co-simulation morphisms
The following notion of morphism between pre-LMPs will witness the relation between a process and its approximant. Recall that our goal is to define approximants as quotients of pre-LMPs under equivalence relations. Such quotients are usually related to the original process S through a measurable map from S to its quotient; this map will be proven to be a co-simulation morphism.
Definition 4.6 Given S, S' two pre-LMPs, a map q : S → S' is said to be a
co-simulation iff it is surjective, measurable and for all a ∈ L, s ∈ S, A' ∈ Σ':
ha(s, q−1A') ≥ h' (q(s), A').

If S and S' are pointed LMPs with initial states i and i', then one asks additionally that q(i)= i'.
Caveat: we are changing the original definition of simulation morphisms [8], reversing the inequation and requiring surjectivity. Nevertheless, we can use the proof of the dual result with simulation morphisms [8, Proposition 3.6.7] because it does not use the additivity property.
Proposition 4.7 If q : S → S' is a co-simulation morphism, then every
s ∈ S simulates q(s).
This proposition will allow us to make sure that the approximant is simu- lated by (or is below ) S.
Proposition 2.5 can also be extended to pre-LMPs.
Corollary 4.8 Let q : S → S' be a co-simulation, then for all θ ∈ L0, s ∈ S: q(s) ∈ [[θ]]S' ⇒ s ∈ [[θ]]S .
Proof. The statement can be restated as q−1[[θ]]S' ⊆ [[θ]]S . The proof is by induction on L0:
for T, one has [θ]]S' = S' and q−1S' = S = [[θ]]S ;
q−1[[θΛψ]]S' = q−1([[θ]]S' ∩[[ψ]]S' )= q−1([[θ]]S' ∩[[ψ]]S' )= q−1[[θ]]S' ∩q−1[[ψ]]S' ⊆
[[θ]]S ∩ [[ψ]]S ;
if q(s) ∈ [[⟨a⟩rθ]]S' , then s ∈ [[⟨a⟩rθ]]S because:

r ≤ h' (q(s), [[θ]]S' ) ≤ ha(s, q−1[[θ]]S' ) ≤ ha(s, [[θ]]S ).

 


The inﬁmum construction
Proposition 4.11 below, which says when “one can take infima” over equiva- lence classes, is important in the sense that without it we could not construct any quotient.
Definition 4.9 [Compatible equivalences] Let (S, Σ) be a measurable space, R be an equivalence relation on S, and A be in Σ. One defines the closure of A as:
[A]+ := {s | [s] ∩ A /= ∅},
and one says the relation R is compatible with (S, Σ) if:
6A ⊆ S : A ∈ Σ → [A]+ ∈ Σ.

Take note that this compatibility condition is weaker than asking all R- closed subsets of S to be in Σ. For instance, if R is the identity, then the latter condition is satisfied only if the measurable space is discrete (i.e., Σ = 2S), whereas the former is always trivially true, since [A]+ = A.
The closure of A provides the best upper approximation of A, within the R- closed subsets of S. One may also define a best lower approximation [A]− :=
{s | [s] ⊆ A /= ∅}. Since [A]− = ([Ac]+)c, it is also measurable and both approaches are equivalent.
Example 4.10 There is no reason in general why R should be compatible, but sometimes it is. An important example is when R has countably many classes, all in Σ. Then, since [A]− is the union of all classes contained in A, it is measurable.
As another example consider ([0, 1], У), and take Y-closed sets to be the subsets of [0, 1] closed under some φ : [0, 1] → [0, 1] such that φ(Σ) ⊆ Σ. Then [A]+ = ∪An, with A0 = A, and An+1 = An ∪ φ(An), the sequence of successive one-step closures. For instance, if one takes φ to be the symmetry λx.(1 — x), [A]+ is just the closure under symmetry and is obtained in one step.
One now wants to extend this notion of lower approximation of sets in Σ to functions in mΣ.
Proposition 4.11 Let (S, Σ) be a measurable space, R be an equivalence compatible with (S, Σ), and g be a bounded function in mΣ, the function [g]−(s) := inft∈[s] g(t) is itself in mΣ.
Proof. The argument decomposes in two parts. We suppose first g is a simple function. As such, it can always be written as  i≤k ai1Ai , with ai


strictly increasing, and Ais pairwise disjoint and all in Σ. Define the decreas- ing sequence Bi := {s | [s] ⊆ ∪i≤j≤kAj}. Since Bi = [∪i≤j≤kAj]−, and R is compatible, Bi is in Σ. Set now Ci = Bi \ Bi+1, one has:
[g]− = Σ	ai1C
which indeed is a simple measurable function, since again Cis are all in Σ.
For the general case of a bounded function, we may suppose without loss
of generality, that 0 < g ≤ 1. We then define the following sequence of simple functions:

gn :=
Σ2n−1(i + 1)2−n
1{i2−n<g≤(i+1)2−n  }

This sequence is decreasing and converging pointwise to g, that is to say, for all s, g(s)= infn gn(s). One has:

[g]−(s) := inft∈[s] infn gn(t)
= infn inft∈[s] gn(t)
= infn[gn]−(t)
and now [g]− is expressed as an infimum of a countable family of functions, the [gn]−, which we know from the first part of the argument are all measurables, and is therefore itself measurable.	 
Note that the second part of the argument uses boundedness to approach g from above. We don’t know if that additional assumption about g can be lifted. Anyway, it is not a constraint in the application to LMP kernels, since these have values in [0, 1]. Apart from that, the argument uses no assumption on g. A similar argument can be made for the supremum based dual construction, obtaining a measurable [g]+.
To understand the necessity of the compatibility condition, let us consider another example. Take g = 1A, and R an equivalence relation on S. Then it is readily seen that [g] = 1[A]−. So [1A] will be measurable if and only if [A]− ∈ Σ.

Aside: another inﬁmum construction
A comparable construction was given in the paper where the notion of pre- LMP was first defined [5]. That one did not rely on a compatibility assumption on the equivalence relation, but on the assumption that the equivalence is countably generated.


Specifically, one says an equivalence R on (S, Σ) is countably generated, if there exists a countable family F ⊆ Σ, such that sRt if and only if for all A ∈ F, s ∈ A if and only if t ∈ A. This is the case for all equivalence relations generated by a choice of formulas in L0, and thus seems a good working assumption regarding the particular application we have in mind.
Suppose now given a countably generated equivalence relation R on (S, Σ). One can always exhibit an increasing sequence of finite families Fi ⊆ Σ, such that ∪iFi = F and F generates R. Each Fi finitely generates an equivalence Ri, which is compatible as said earlier, and therefore the [.]− construction works fine. One may then define, for any g ∈ mΣ:
gi := [g]−
g٨ := supi gi
It is readily seen that: 1) g٨ does not depend on the particular choice of the increasing sequence Fi, that 2) it is Σ-measurable and 3) it is constant on R classes. Clearly when both g٨ and [g]− exist, gi ≤ [g]−, so g٨ ≤ [g]−.
It was claimed wrongly in the original paper [5, Prop.13] that g٨ = [g]−. Here is an example showing that sometimes this might be a strict inequality. Take ([0, 1], У) as measurable space, Fi = {[0, 1/j]; i ≥ j > 0} as the generat- ing set, and g(0) = 1 and g(s /= 0) = 0. One has gi = 0, so g٨ = 0, while 0 is alone in its class and therefore [g]− = g.
This new lower approximation of g could be an alternative to [g]− when R is not compatible but countably generated. The bad news about it is that if we use it in Definition 4.12 below, we do not get Lemma 4.13, as co-continuity is false.
Here we choose to work with compatible relations, and will restrict to quo- tients induced by finite sets of formulas. Accordingly, in the rest of the paper, we will simply say that R is an equivalence on a given pre-LMP (S, Σ, h), to actually mean that R is compatible with (S, Σ).
Quotients and Simulations
Definition 4.12 Given an equivalence R on a pre-LMP S = (S, Σ, h), we define the quotient pre-LMP, written SR, as the following triple (SR, ΣR, hR):
—SR is the set of R equivalence classes,
—ΣR is the quotient σ-algebra of R-closed sets of Σ,
—hR(a, [s], A) := inft∈[s] ha(t, ∪A) for a ∈ L, s ∈ S and A ∈ ΣR. If S has an initial state, then its equivalence class is the quotient initial state.
When the kernel and the equivalence matches exactly (in the sense that


equivalent states have equal transition probabilities to unions of equivalence classes), then hR([s], A) = h(t, ∪A) for all t ∈ [s] and the construction boils down to an ordinary bisimulation quotient.
We have seen in Example 4.1 that this quotient does not always define an LMP. However it does define a pre-LMP.
Lemma 4.13 SR as deﬁned above is a pre-LMP.
Proof. We have three things to verify according to Definition 4.3 above. The first is obvious. For the second condition, the verification that hR(a, [s], .) is a pre-measure breaks down in two subconditions. (We drop the labels since they play no role in the argument.)
Super-additivity. If A, B are disjoint sets in ΣR:
h(s, ∪(A + B)) = h(s, ∪A + ∪B)
≥ h(s, ∪A)+ h(s, ∪B)
≥ hR([s], A)+ hR([s], B).

Co-continuity. Let ↓An be a decreasing sequence of sets in ΣR, then ↓∪An is also a decreasing sequence of R-closed sets of Σ and:
hR([s], ∩An) := inft∈[s] h(t, ∩(∪An))
= inft∈[s] infn h(t, ∪An)
= infn inft∈[s] h(t, ∪An)
=: infn hR([s], An)
so indeed hR([s], .) is a pre-measure.
Finally for the third, we verify that for all A ∈ ΣR and r ∈ R, the set
{hR(., A) ≥ r} is in ΣR. Writing q for the canonical projection from S to SR, we can write our set as:
{[s] | hR([s], A) ≥ r} = q({s | inf h(t, q−1A) ≥ r})
t∈[s]
i.e., as the projection of a set which is clearly R-closed and, by Proposi- tion 4.11 applied to h(., q−1A) (which indeed is a measurable function, since q is measurable and therefore q−1A ∈ Σ), belongs to Σ.	 
Clearly:

Proposition 4.14 SR is simulated by S. Speciﬁcally, the canonical surjection
q : S → SR is a co-simulation.
Quotients and Logical Properties
Now that we know the quotient SR exists, we need to bring up the properties it might share with S. Combining Proposition 4.14 with Corollary 4.8, we get that each property that SR satisfies is also satisfied by S.
Corollary 4.15 Let R be an equivalence on S, then for all θ ∈ L0, and s ∈ S:
[s] ∈ [[θ]]SR ⇒ s ∈ [[θ]]S .
We now need a converse to this, that will quantify how good the approxi- mation given by the quotient is, and say how much of the L0 properties of s in S are still properties of [s] in SR.
Definition 4.16 We will say R reﬁnes a property θ if and only if all inter- pretations of subformulas of θ are R-closed.
In other words: for all θ' ≤ θ and all (s, t) ∈ R, if s |= θ' then t |= θ'.
Proposition 4.17 Let R be an equivalence on S, then 6θ ∈ L0 that R reﬁnes,
s ∈ S: s ∈ [[θ]]S ⇒ [s] ∈ [[θ]]SR .
Proof. The lemma can be rephrased as q−1[[θ]]S ⊇ [[θ]]S . We prove it by induction on θ. The only interesting case is when θ = ⟨a⟩rψ, and then one has for all a, s:
hR(a, [s], [[ψ]]S ) = inft∈[s] h(a, t, q−1[[ψ]]S )
= inft∈[s] h(a, t, [[ψ]]S )
where the second equation is by induction (since R refines also ψ, q−1[[ψ]]S ⊇ [[ψ]]S and by the corollary above, these two subsets of S are actually equal). It follows that if s |= θ and [s] |= θ, there must be a t ∈ [s] close enough to the infimum, such that t |= θ either, which means R actually does not refine θ.	 
Subformulas have to be included in the refinement condition and this can be seen on a small example. Say r ≥ u, here are S and a quotient SR:

s0		a[r]	 s		a[u]	 t z		z 
[s ] 	a[r]	 [s , t]

Now set θ = ⟨a⟩r⟨a⟩uT; one has:
[[⟨a⟩uT]]S = {s, s0}, [[θ]]S = {s0},
[[⟨a⟩uT]]SR = {[s0]}, [[θ]]SR = ∅,
so though [θ]]S is R-closed and s0 ∈ [[θ]]S , yet qR(s0)= [s0] /∈ [[θ]]SR . Combining the last two statements in the particular case of logically gen-
erated approximations, we get:
Theorem 4.18 (abstract approximants) Let J be a ﬁnite downward closed subset of L0, and R be the associated equivalence on £:
6θ ∈ J, 6s ∈ S : s ∈ [[θ]]S e [s]R ∈ [[θ]]SR .
Proof. R is an equivalence on £ because it is has finitely many classes, which are all measurable, and hence Corollary 4.15 applies. Now R refines J and is even the coarsest such equivalence, and one may apply Proposition 4.17. 
A particular case is J = {T}, and then £R = ({∗}, {∅, {∗}}, ha) with ha(∗, ∅) = 0 and ha(∗, {∗}) = infs∈S ha(s, S) =: αa. So £R is the loop with coefficients (αa)a∈L. Of course very few properties are retained here, namely the combinations of ⟨a⟩r with r ≤ αa. This trivial approximation can be thought of as a quite blunt abstract interpretation of £. The theorem above explains, in essence, how to construct arbitrarily sharper ones. Note also that the set of formulas that are satisfied by a state of the quotient is not necessarily included in J: it may satisfy more formulas.
To go beyond quotients by finite sets of formulas, one has to take care of compatibility of the generated equivalence. This has to be verified on a case-by-case study. Here is an example of a non-finite quotient. Go back to the example where the underlying measurable space is ([0, 1], У), and take h(s, A)= s.λ(A).
Abstract approximants are optimal
A noteworthy observation is that if one wants the quotient map q to generate a simulation, the choice made above for hR is optimal, ΣR is the largest σ- algebra that will make q measurable and all other kernels would be pointwise smaller:
Proposition 4.19 Given £, £' two pre-LMPs and q : £ → £' a co-simulation morphism, and deﬁning the equivalence relation generated by q on S as (s, t) ∈ R if q(s)= q(t), one has:

Σ' is a sub-σ-algebra of ΣR;
for all s' ∈ S', A' ∈ Σ': h'(s', A') ≤ hR(s', A').
Yet another way of saying this is: the identity ι : £R → £' is a co-simulation which decomposes q as ι ◦ qR. The proof of 1) is left to the reader. Point 2) is obvious. Note that R, the equivalence associated to q, is not in general an equivalence on £, since it might not be compatible with (S, Σ). All we are saying here, is that when hR is measurable, it is the best pre-LMP for the ordering generated by co-simulations. To make this a more satisfying state- ment, one would have to add some topological or domain-theoretic structure on state spaces, to make sure the construction is always possible.
To wrap up, we now know for one thing, that pre-LMP support what seems the natural construction, as summarized in Theorem 4.18, whereas with plain LMPs one has to restrict to finite quotients. And with this last proposition, we see that pre-LMPs also give more accurate finite predictors.

The sup-quotient
We have shown how to construct quotients of pre-LMPs using infima of mea- surable functions. One could be interested in the dual construction using suprema. All the results above can be dualized to their supremum coun- terpart with little modification. Basically, one has to reverse inequality signs and replace co-continuity with continuity. The resulting model could be called conveniently sub-pre-LMP, since suprema generate subadditive kernels (and our pre-LMPs should then be called super-pre-LMPs since they have super- additive kernels as we know). The quotient of a sub-pre-LMP is above the original process instead of below. Consequently, we have a simulation mor- phism instead of a co-simulation in the equivalent of Proposition 4.14. The semantics has to be adapted as well, replacing ⟨a⟩r(A) with the strict version
⟨a⟩>r(A).

Stronger Approximants
We now extend the results of this section to a logic with fixed points. A more detailed account of this fixed point logic was given elsewhere [4]. This extension will allow us to approximate with respect to a much richer class of properties. More to the point, we have seen in section 3 how the introduction of loops in the approximants allows for quicker convergence when there are loops in the transition graph of the original process. In the present section we have just shown how the approximations may be guided by formulas. However, the formulas used only capture one step transitions and one needs richer formulas


to capture looping behaviour. In fact one needs exactly the fixed point logic of this section.
Extended logic
We introduce an extended logic L∗ to capture cyclic temporal properties. To deal with mutual fixed point equations, it is convenient to present the extended formulas as automata.
Definition 4.20 [cyclic temporal properties] An L∗ formula is a pair (I, λ), with I a finite indexing set and λ a partial map from L × I × I to [0, 1].
We write dom(λ) for the domain of λ; working with total maps, by ex- tending λ to be zero outside dom(λ), turns out to be inconvenient. We will use freely the automaton terminology and talk about I as the state space and λ as the transition map. Notice that there is no condition on the transition function: it need not be a subprobability distribution. One should understand the transitions as if they were non-deterministic.
First of all we show how to present our usual L0 formulas as automata.
Definition 4.21 [mapping L0 to L∗] One defines a map (.)∗ from L0 to L∗
0	0
as follows:
I is the set of θ’s (occurrences of) maximal conjunctive sub-formulas,
λ(a, θ0, θ1)= r iff θ0 = ⟨a⟩rθ1 Λ θ' for some θ', up to the monoidal equations associated to Λ.
The simplest example is T∗ = ({T}, ∅). The next simplest is (⟨a⟩.5T)∗ = ({⟨a⟩.5T, T}, {(a, ⟨a⟩.5T, T, .5)}), or in graphical automata notation:
⟨a⟩ T a[.5]	 T .

A more complicated formula is ⟨a⟩1θΛ⟨b⟩.5T, which translates (again in graph- ical automata notation) to:


θ∗ ¸,a[1]
⟨a⟩1θ Λ ⟨b⟩.5T
b[.5]	 T .

This correspondence is one-one, up to monoidal equations, and θ∗ is always a tree.
Now, given £ an LMP, we would like to extend the map [.]]S to L∗-formulas, or in other words, to make sense of s |= θ for our new formulas. This will be done using two independent approaches that will turn out to be equivalent. One will be the definition of a suitable fixed point in the category CS defined below, and the other one will be in terms of simulation relations.

Semantics of L∗ via ﬁxed points
Let CS be the sub-Cartesian category of Set generated by:
cartesian powers of Σ: 1 = Σ0, Σ, ..., Σn, ... 
shifts ⟨a⟩r :Σ → Σ,
intersections ∩ : Σ × Σ → Σ. If one restricts to shifts with rational coefficients, there are only countably many arrows in CS.
Note that products in CS are ordinary set-theoretic products, not products of measurable spaces. The objects of the category CS , i.e., the Σns, are equipped with a partial order in the following way:

(A1,... , An) ≤ (B1,... , Bn) if 6i, 1 ≤ i ≤ n : Ai ⊆ Bi.

The key to the extension of [.]]S is the following:
Lemma 4.22 Morphisms of CS are all monotone and co-continuous; endo- morphisms of CS all have greatest ﬁxed points.
Proof. First of all, we observe that shifts are indeed returning results in Σ by definition of a pre-LMP. Secondly, all generators are clearly monotone. Thirdly, if ↓An is a decreasing sequence in Σ then:

⟨a⟩r(∩An) = {s | ha(s, ∩An) ≥ r}
= {s | infn ha(s, An) ≥ r}
= ∩⟨a⟩r(An)
where the second equation uses co-continuity of ha(s, .) on Σ, given by defi- nition of pre-LMP kernels. So shifts are co-continuous, and so are evidently projections, intersections and all cartesian combinations of them.
Lastly, suppose ψ is an endomorphism, since it is monotone, it has a great- est fixed point in (2S )n, and since ψ is also co-continuous, this fixed point can be written as ∩nψn(S,... , S) and hence is in Σn.	 

In fact CS has a structure of traced Cartesian category (or Cartesian cat- egory with fixed points [15]). We will write Yψ for the fixed point of ψ. This is, of course, what we use for interpreting fixed points in the logic.
More generators could be added to the collection while keeping the key lemma above. For example, we could have added unions, countable unions and countable intersections to the generators (and therefore the countable power ΣN as an object of CS ). This might indeed prove useful at some later

stage, but for now we do not do this. We could not have added maps such as:
ψ(A)= ⟨a⟩r(A) \ ⟨a⟩r' (A)= {s | ha(s, A) ∈ [r, r )}
which is not monotone; having only positive operators in the basic logic is crucial here. More subtly, strict shifts though they are monotone, cannot be added because they are not co-continuous and we need greatest fixed points (as made clear below).
So, strict shifts are not co-continuous and neither are shifts continuous. Here is an example: ([0, 1], У, h) with ha(s, B)= λ(B), where λ is the Lebesgue measure on У, and while ∪n[0, 1—1/n]= [0, 1], but for no n can we be Lebesgue sure to hit [0, 1 — 1/n] there is always a 1/n chance that we do not, and so
⟨a⟩1([0, 1 — 1/n]) = ∅. A similar case can be made that strict shifts are not co-continuous using intervals ↓(0, 1/n].
Definition 4.23 Given a formula θ = (I, λ) ∈ L∗, we define in turn {|θ|}S ∈

CS[ΣI , ΣI] and [θ]]S ∈ ΣI by:
{|θ|}S(τ )(i) :=
(a,i,j)∈dom(λ)

with τ ∈ ΣI a I-indexed tuple in Σ, and:

⟨a⟩λ(a,i,j)(τ (j))

[[θ]]S := Y{|θ|}S = ∩p ↓{|θ|}p (S,... , S) where the p stands for the number of iterations.
This somewhat pedantic notation comes handy when one wants to access
states by their names, not their indices. We will use concrete tuple notation in examples, but not in proofs. Symbol τ sounds like “tuple” and is supposed to be suggestive of what τ is, a tuple. When dom(λ) is empty (which happens exactly when the corresponding state is dead in θ), we take the convention that the intersection is equal to the full set S.
Each component map λτ.{|θ|}S(τ )(i) is in CS [ΣI, Σ] indeed, since it is clearly expressed as a finite intersection of shifts; therefore the lemma above applies, and [θ]]S = Y{|θ|}S is well-defined and lies in ΣI.
Lemma 4.24 For all θ = (I, λ) ∈ L∗, [[θ]]S ∈ ΣI.
Least fixed points are not interesting here, that is in the absence of specific atomic properties on the state space, since one has to use strict shifts to have them in Σ, but ⟨a⟩>r(∅) = 0 for all pre-LMPs, so these would always be empty.

Example 4.25 Here is an LMP example with state space S = {s0, s1, s2}
followed by a cyclic formula θ in L∗:
	.3	
z 

£ = s0
.3	  s1	θ =
˛q1  




  s2 ¸, .6
.25	.5
q2 ¸c

The operator converges to a fixed point in two steps:
{|θ|}S(A1, A2)= (⟨⟩.5A2, ⟨⟩.25A1),
Y{|θ|}S = {|θ|}2 (S, S)= ({s0, s1}, {s0, s2}),
[[θ]]S (q1)= {s0, s1}.
Intuitively Y{|θ|}S is finding the biggest state-sets in £ satisfying the specifi- cation described by θ.
The following example might be helpful for people used to the µ-calculus notation.
Example 4.26 Suppose that we have the νX.⟨a⟩1X formula and we want to express this in L∗. We think of this automata theoretically. There is a state where X is satisfied and the system can do an a transition with probability 1 and return to this state. Thus in L∗ we write: {q}, λ(a, q, q)= 1.

a[1]
 r
νX.⟨a⟩1X =  q
Suppose we want to write the usual temporal logic formula with “until”: say, a1U b.5 meaning that the system can keep doing a with probability 1 until it does a b with probability .5. In this case the automaton has two states and the L∗ version would be ({q1, q2}, {λ(a, q1, q1)= 1, λ(b, q1, q2)= .5}).



a U b
a[1]
= q  rb[.5]	 q 

1	.5	1	2
Now with Definition 4.23 and a formula θ ∈ L0, we can build both [θ]]S and [θ∗]]S , so obviously we have to say something ! (Reminder: formulas are used as their own indexing sets when coerced in L∗.)

Lemma 4.27 Deﬁnitions 4.23 and 2.3 of [[θ]]S agree, in the sense that for all
θ ∈ L0: [[θ∗]]S (θ)= [θ]]S .
Proof. The proof is an induction on L0, where we prove in addition that the fixed point Y{|θ|}S is obtained in |θ| steps (and therefore “convergence time” for L0 formulas is independent of £).
θ = T: then I = {T}, λ = ∅ and {|T∗|}S(τ )(T)= S, [[T∗]]S (T)= S which is the correct answer obtained in 0 = |T| steps;
θ = θ0 Λ θ1: I = I0 · I1 is the smashed sum of I0 and I1, obtained by fusing the initial states θ0 and θ1 into θ (since θ0 and θ1 are no longer maximal conjunctive) and taking the disjoint union otherwise; the only state where λ changes value is precisely θ itself, and λ(a, θ, i) = λ0(a, θ0, i)+ λ1(a, θ1, i); so that, by definition:
{|θ∗|}S(τ0 · τ1)(θ)= {|θ∗|}S(τ0)(θ0) ∩ {|θ∗|}S (τ1)(θ1)
0	1
[[θ∗]]S (θ)= [θ∗]]S (θ0) ∩ [[θ∗]]S (θ1)
0	1
and the answer is obtained in max(|θ0|, |θ1|).
θ = ⟨a⟩rθ0: I = I0 +{θ}; λ takes now one more value, namely λ(a, θ, θ0)= r and:
{|θ∗|}S(τ )(θ)= ⟨a⟩r(τ (θ0)),
again the correct answer, and obtained in |θ0| + 1 steps, as expected.	 

Semantics of L∗ via simulations
The fixed point definition of L∗’s semantics, while being convenient for measure- theoretic considerations, is a bit clumsy when it comes to understanding what is going on. To rectify this we introduce a more perspicuous seman- tics s ∈ [[θ]]S (i) which will turn out to be equivalent to the one just given.
Observe that when we say that a state satisfies a logical property, we ex- pect this state to satisfy at least this property, and that it may satisfy other properties as well. Now that our properties are stated in a labelled transition setting, it is tempting to use the corresponding algebraic notion, that is, sim- ulation. Indeed, if we look back to Example 4.25, we can observe that (the reflexive and transitive closure of) the relation (q1, s0), (q1, s1), (q2, s0), (q2, s2) is a simulation relation.
The definition 2.4 of simulation must be extended to include systems that are not pre-LMPs. Recall that even if we view formulas of L∗ as automata, they are not pre-LMPs because of the fact that a-transitions probabilities may sum up to some number > 1. This problem is easily disposed of by considering


formulas as non-deterministic systems, and thus every transition as defining a distinct sub-probability distribution.
Definition 4.28 Given θ = (I, λ) ∈ L∗, £ = (S, Σ, h) a pre-LMP, a relation S ⊆ I × S is a non-deterministic simulation if for all a ∈ L, (i, s) ∈ S and j ∈ I: λ(a, i, j) ≤ ha(s, S(j)).
It is understood above that 6i, S(i) ∈ Σ. However, this requirement is not in Definition 2.4 of simulation between LMPs, for if it was, bisimulation would not be a simulation. This issue is technically complex and not addressed here. The reader must keep in mind that this definition of simulation is safe only if we deal with countable state-space processes or if we manipulate simulated processes related by a co-simulation morphism, as will be argued in Lemma 4.30 below. 1
Proposition 4.29 Given θ = (I, λ) ∈ L∗, £ = (S, Σ, h) a pre-LMP, S ⊆
I × S is a simulation if and only if for all i:
— S(i) ∈ Σ,
— S(i) ⊆ {|θ|}S(λj.S(j))(i).
Proof. The proof is by trivial manipulation of the various definitions.	 
Now we say that s simulates i, when there exists a non-deterministic sim- ulation S, with (i, s) ∈ S. Here is the rephrasing: s ∈ [[θ]]S (i), or s |= θ(i) in shorthand notation, if and only if s simulates i. We also observe that [θ]]S , regarded as a relation on I × S, is the coarsest simulation.

Quotients with L∗
We can now prove the analog of Corollary 4.8: co-simulation morphisms pre- serve formulas of L∗.
Lemma 4.30 Let £, £' be pre-LMPs and q : £ → £' be a co-simulation morphism, then for all θ = (I, λ) ∈ L∗, i ∈ I, s ∈ S: q(s) ∈ [[θ]]S' (i) ⇒ s ∈
[[θ]]S (i).
Proof. Composing a non-deterministic simulation on I × S' with the co- simulation q gives a simulation for £.	 
Finally, it remains now to prove the analog of Proposition 4.17, that is, that quotient states satisfy the same formulas of J as the states they J-

1 We conjecture that requiring that S(i) ∈ Σ be an analytic set in S would solve the problem.


approximate. But before we have to explain what it means now for an equiv- alence R over £ to refine a formula θ ∈ L∗.
Definition 4.31 Let £ be a pre-LMP, R be an equivalence over £, and θ = (I, λ) ∈ L∗, then R refines θ if for all i ∈ I, [[θ]]S (i) is R-closed.
By Lemma 4.27, this second definition coincides with the definition given before for L0 (to be exact, only maximal conjunctive subformulas have to be R-closed, so next proposition is marginally better).
With our definition in place we can home in on our proposition:
Proposition 4.32 Let £ be a pre-LMP and R be an equivalence on £ which reﬁnes θ, then for all i ∈ I, s ∈ S: s ∈ [[θ]]S (i) ⇒ [s]R ∈ [[θ]]SR (i).
Proof. Let R be an equivalence relation refining θ, and assume that s |= θ(i). Then there is an associated simulation relation S between θ and £ such that for all iSs, if λ(a, i, j) = r then ha(s, S(j)) ≥ r. Now let us prove that the corresponding relation between θ and £R is a simulation relation. This relation R∗ is defined as iR∗[s] if iR't for all t ∈ [s]. Since R refines θ, and by definition of R∗ in terms of S, we have that S(j)= q−1R∗(j) where q is the quotient function. But now if λ(a, i, j)= r then ha(t, S(j)) ≥ r for all t ∈ [s] and hence hR(a, [s], R∗(j)) = inft∈[s] ha(t, q−1R∗(j)) = inft∈[s] ha(t, S(j)) ≥ r.
 
We can pithily summarize the results of this section in a statement paral- leling Theorem 4.18:
Theorem 4.33 (strong approximants) Let £ be a pre-LMP, J be a ﬁnite subset of L∗, and R the associated equivalence on £, then for all θ = (I, λ) ∈ J , s ∈ S and i ∈ I:
s ∈ [[θ]]S (i) e [s]R ∈ [[θ]]SR (i).
Proof. As in the parallel statement, R has finitely many equivalence classes which are all in Σ, because R has finitely many generators, namely the [θ]]S (i), for θ ∈ J, i ∈ Iθ. So again R is an equivalence on £, the quotient £R is well-defined by Lemma 4.13, and the projection is a co-simulation morphism by Proposition 4.14, so Lemma 4.30 applies, and this gives the left to right implication. Besides and by definition, R is the coarsest equivalence on £ refining all θs in J, so one may apply Proposition 4.32 and obtain the other implication.	 
Note that, even if £ is itself infinite state, the quotient will be finite, as soon as J is, just as in the L0 case.


The following result, which now follows easily, is one of the main moti- vations for using a logic with loops. We first need to prove that simulation relation between finite LMPs preserve formulas of L∗.
Lemma 4.34 If two states s and t of a ﬁnite LMP are related by a simulation relation, then every formula of L∗ that s satisﬁes is also satisﬁed by t.
Proof. The proof lies on simple manipulations of relations and inequalities and on the fact that every set in a finite LMP is measurable.	 
Theorem 4.35 For every ﬁnite-state LMP, there is a ﬁnite set of formulas
J of L∗ such that the quotient with respect to J is bisimilar to the process
itself.
Proof. The logic L∗ clearly characterizes bisimulation of LMPs. 2 Indeed, it is an extension of L0 and since simulation preserves satisfaction of formulas of L∗ (by the preceding lemma), so does bisimulation. This implies that if two states are not bisimilar, then there is a formula of L∗ that will distinguish them. There are finitely many pairs, and taking all formulas that distinguish pairs of non-bisimilar states and closing this set under subformulas yields a finite set of formulas. This set defines a quotient which is bisimilar to the original finite- state process. Indeed, since non-bisimilar states belong to different equivalence classes, we have that every state of the quotient is made of bisimilar states of the original process. These states have the same transition probability to every bisimulation-closed set, and hence to every equivalence class.	 

Approximation through average
In this section, we present a customizable approach to approximation and stay within the realm of LMPs. The approach is based on a radical departure from the ideas of the previous approaches. In the previous approaches one always approximated a system by ensuring that the transition probabilities in the approximant were below the corresponding transition in the full system. Here we approximate a system by taking a coarse-grained discretization (pixelliza- tion) of the state space and then using average values. This new notion is not based on the natural simulation ordering between LMPs as were the previous approaches.
Instead we use conditional expectation, which will construct for us low- resolution averages of any given LMP. Furthermore, an LMP will be known

2 Note that for uncountable processes, this result needs an assumption that the state-space is analytic.


completely, up to bisimilarity, from its finite-resolution (meaning finite state) averages.
We first recall the definition of conditional expectation, then we identify circumstances in which the conditional expectation is actually defined point- wise and not only “almost everywhere”. We construct an adaptation of the Lebesgue measure on any given LMP that will serve as the ambient proba- bility which we need to drive the construction home. With all this in place we may turn to the definition of approximants. This conditional expectation will be made with respect to a σ-algebra generated by a set of formulas of L∗. We will prove that the approximant satisfies exactly the same formulas of the given set as does the process being approximated. This will prove that they are correct, but we will also show the precise relation in which they stand with the order-theoretic approximants given in Section 4.


Conditional expectation
The expectation Ep(X) of a random variable X is the average computed by
Xdp and therefore it is just a number. The conditional expectation is not a mere number but a random variable. It is meant to measure the expected value in the presence of additional information. The conditional expectation is typically thought of in the form: “if I know in advance that the outcome is in the set A then my revised estimate of the expectation is Ep(X|A).” However additional information may take a more subtle form than merely stating that the result is in or not in a set.
The additional information takes the form of a sub-σ algebra, say Λ, of Σ. In what way does this represent “additional information”? The idea is that an experimenter is trying to compute probabilities of various outcomes of a random process. The process is described by (S, Σ, p). However she may have partial information in advance by knowing that the outcome is in a measurable set A. Now she may try to recompute her expectation values based on this information. To know that the outcome is in A also means that it is not in the complement Ac. Note that {∅, A, Ac, S} is in fact a (tiny) sub-σ-algebra of Σ. Thus one can generalize this idea and say that for some given sub-σ-algebra Λ of Σ she knows for every A ∈ Λ whether the outcome is in A or not. Now she can recompute the expectation values given this information.
How can she actually express this revised expectation when the σ-algebra Λ is large? It is presented as a density function so that for every Λ-measurable set B one can compute the conditional expectation by integration over B. Thus instead of a number we get a Λ-measurable function called the conditional

expectation given Λ and written Ep( |Λ). 3
It is not at all obvious that such a function should exist and is indeed a fundamental result of Kolmogorov [22, p.84].
Theorem 5.1 (Kolmogorov) Let (S, Σ, p) be a probability triple, X be in L1(S, Σ, p) and Λ be a sub-σ-algebra of Σ, then there exists a Y ∈ L1(S, Λ, p) such that

6B ∈ Λ.
B
Xdp =
B
Y dp.	(1)

Not only does the conditional expectation exist, but it has a lot of prop- erties. As a functional of type
Ep( |Λ) : L1(S, Σ, p) → L1(S, Λ, p)
it is linear, positive, monotone with respect to the pointwise ordering and continuous in the sense that for any sequence (Xn) with 0 ≤ Xn † X and Xn, X ∈ L1(S, Σ, p), then Ep(Xn|Λ) † Ep(X|Λ) . . . but it is not uniquely defined ! All candidate conditional expectations are called versions of the condi- tional expectation. It is easy to prove that any two Λ-measurable functions satisfying the characteristic property (1) given above may differ only on a
negligible set (a set of p-probability zero).
The ﬁnite case
As we have said before, the basic intuition of Ep(X|Λ) is that it averages out all variations in X that are below the resolution of Λ, i.e., which do not depend on Λ. In particular, if X is independent of Λ, then Ep(X|Λ) = Ep(X), 4 and X is completely averaged out. 5 On the other hand, if X is fully dependent on Λ, in other words if X is Λ-measurable, then Ep(X|Λ) = X.
This intuition is exact in the case that the sample space S is ﬁnite. We may
suppose then that Σ = 2S, and Λ will be generated by a set of equivalence classes. But then Y = Ep(X|Λ) has to be constant on equivalence classes

3 Take note that, in the same way as Ep(X) is constant on S, the conditional expectation will be constant on every “pixel” or smallest observable set in Λ. In the above “tiny” sub- σ-algebra, this means constant on both A and Ac. This will turn out to be exactly what we need later when pixels are defined by sets of formulas.
4 Recall that in this equation the left-hand side is a function while the right-hand side is a
number; we mean to say that the function on the left is a constant function whose value is given by the right-hand side.
5 Given a probability triple (S, Σ, p), a random variable X ∈ mΣ is said to be independent of
a sub-σ-algebra Λ if for any event A ∈ σ(X) and B ∈ Λ, p(A∩B) = p(A)p(B). In particular, as one can easily verify, X is always independent of the trivial σ-algebra Λ0 = {∅,S} and by the remark above, Ep(X|Λ0) = Ep(X) the ordinary unconditional expectation of X.


(else it is not Λ-measurable) and by the characteristic property, with B an equivalence class [s], we get:

Y (s).p([s]) = ∫



[s]

Y dp =
[s]

Xdp =	X(t)p({t})) = E(1[s]X),
t∈[s]

where 1[s] is the indicator function of the measurable set [s].
When p([s]) > 0 we see that Y is exactly the p-average of X over equiva- lence classes associated to Λ:
1
Y (s)= p([s]) · E(1[s]X).

The example that says it all
Now that it is understood that in the finite state-space case conditional ex- pectations are averages over equivalence classes, we can consider a revealing example. Put S = {x, y, 0, 1}, Σ = 2S, L = {a} (there is only one label, so we will not even bother to write a in the kernels); h({0})(x)= h({1})(y)=1 and every other state-to-state transition is of probability zero. Suppose Λ identifies x and y, and call the resulting class z.
One can conceive of three ways to define a kernel k on the quotient space
{z, 0, 1}. The first two are already familiar from the two previous sections. One can define k as the inﬁmum over {x, y} or dually one can take it to be the supremum:

ki({0})(z)= 0,  ki({1})(z)= 0,  ki({0, 1})(z)= 1,
ks({0})(z)= 1,  ks({1})(z)= 1,  ks({0, 1})(z)= 1.

or one can also define k as an average (using here the uniform probability on the underlying state space):

ka({0})(z)= 1/2,  ka({1})(z)= 1/2,  ka({0, 1})(z)= 1.

As we said earlier, the use of the infimum results in super-additive kernels while the use of a supremum results in sub-additive kernels:

ki({0, 1})(z)= 1 > ki({0})(z)+ ki({1})(z)= 0
ks({0, 1})(z)=1 < ks({0})(z)+ ks({1})(z)= 2.


Of the three options, only the third preserves additivity:
ka({0, 1})(z)=1 = ka({0})(z)+ ka({1})(z).
Besides we observe that, perhaps not surprisingly, in all cases the kernel ob- tained by using averages is sandwiched between the others, e.g.:
0= ki({0})(z) ≤ ka({0})(z)= 1/2 ≤ ks({0})(z)= 1.
The rest of this section is essentially about structuring this nice concrete notion of approximant by averages as a general construction and explaining in what sense these approximants are actually approximating what they are supposed to be approximants of.
When Ep( |Λ) is unique
There is one thing we have to confront. As we noted before, conditional expectations are unique only “almost surely.” Now we want to use them to average our family of h(a, A) and, from the definition of an LMP, we need these averages to be defined pointwise, not only up to p. Yet, in the case of finite systems, one option is to choose for p the uniform probability on S, in which case “almost surely” actually means “surely,” since only the empty set is in Np. This, intuitively, is because points are big enough chunks to be seen by the probability distribution. This leads to the following two definitions.
Definition 5.2 [pixels] Let (S, Σ) be a measurable space, one says s and t ∈ S
are Σ-indistinguishable if 6A ∈ Σ, s ∈ A ↔ t ∈ A.
This is an equivalence on S and we write [s]Σ, or sometimes simply [s] to denote the equivalence class of s. One has [s]Σ = ∩{A | s ∈ A ∈ Σ}. So equivalence classes might not be measurable themselves, unless Σ is countably generated, which is the case we are interested in.
Definition 5.3 [granularity] Let (S, Σ, p) be a probability triple and Λ ⊆ Σ be a sub-σ-algebra of Σ; p is said to be granular over Λ if for all s ∈ S, [s]Λ /∈ Np.
In other words, p is granular over Λ if no Λ equivalence class is negligible. What this means intuitively is that the “pixellization” of Λ is always seen by
p. It may be instructive to point out that there are at most countably many equivalence classes in this case.
As an example, we can take the probability triple ([0, 1)2, У2, λ2), where λ2
is the Lebesgue measure on the square, and Λ = У× [0, 1). Then [s]Λ = {s}× 


[0, 1) ∈ Λ and λ2([s]) = 0 so our p is not granular over this Λ. The measurable sets of Λ are very thin strips. They are too fine to be granular. But if we take a cruder Λ, namely that generated by the squares [k/n, k + 1/n) ×[h/n, h + 1/n) for k, h < n (with n fixed), then [s]Λ is such a square of λ2-measure 1/n2, so here p is granular.
The big payoff of granularity is the following:
Lemma 5.4 (Uniqueness lemma) Let (S, Σ, p) be a probability triple, Λ ⊆
Σ, p granular over Λ, X and Y both Λ-measurable, then:
X = Y a.s. ⇒ X = Y.
So in this case “almost surely” does mean “surely !”
Proof. Set A := {s ∈ S | X(s)= α Λ Y (s)= β} and t ∈ A. One has A ∈ Λ, by Λ-measurability of X and Y , but then [t]Λ ⊆ A (otherwise A splits [t]Λ). So by granularity p(A) > 0 (else [t]Λ is negligible), and therefore α = β or else X and Y differ on a non negligible set A.	 
So in this favourable circumstances we can do away with versions. If
X ∈ L1(S, Σ, p), and p is granular over Λ:
Ep(X|Λ) : L1(S, Σ, p) → L1(S, Λ, p)
is uniquely defined and we can proceed to the main definition.
Projecting LMPs
Definition 5.5 [projection of an LMP] Given (S, Σ) a measurable space, Λ a sub-σ-algebra of Σ, p a probability on (S, Σ) granular over Λ, and £ = (h(a, A))a∈L,A∈Σ an LMP on (S, Σ), one defines the p-projection of £ on Λ, written (£|Λ)p as:
h'(a, A)= Ep(h(a, A)|Λ), for a ∈ L, A ∈ Λ.
Take note that this is the version of the conditional expectation. Existence follows from the fact that the h(a, A) evidently are integrable with respect to p (they are measurable, positive and bounded by 1), in other words they are in L1(S, Σ, p).
Proposition 5.6 (Staying within LMPs) (£|Λ)p is an LMP.
Proof.  All maps h'(a, A) are Λ-measurable by definition of the condi- tional expectation; h'(a, A) has values [0, 1], because conditional expectation


is monotone, and from 0 ≤ h(a, A) ≤ 1, one gets 0 = Ep(0|Λ) ≤ h'(a, A) ≤ Ep(1|Λ) = 1; additivity is because Ep( |Λ) is linear; continuity follows from the fact that Ep( |Λ) is itself continuous (a property known as the conditional form of the monotone convergence theorem).	 
We may now round off the construction by changing the state space.
Let us write [ ]Λ : S → [S]Λ for the canonical surjection to the set of equivalence classes and denote accordingly the quotient σ-algebra by [Λ]Λ. Then one can define the quotient LMP ([S]Λ, [Λ]Λ, k) with:
k(a, B)([s]Λ) := h'(a, ∪B)(t) := Ep(h(a, ∪B)|Λ)(t),
with t ∈ [s]. Take note that the right hand side is independent of the choice of t ∈ [s]Λ since h'(a, A) is Λ-measurable, and therefore h'(a, A) has to be constant on [s]Λ (else the equivalence is split by an event in Λ). Moreover, [ ]Λ is a bisimulation morphism (which was formerly called a “zig-zag” [7]) from (£|Λ)p to ([S]Λ, [Λ]Λ, k) and as such it preserves all L0 properties.
So far we have a quotient theory for LMPs when pixels are big enough, but everything hinges on the choice of an ambient p. This is the second problem we have to deal with.

A “uniform” probability on (S, σ(L0))
The key is to construct an appropriate measure, and we will use L0 to do this. So, given an LMP £ = (S, Σ, h), and a ﬁxed enumeration (θn) of L0, we first define a sequence (S, Λn) of measurable spaces: 6
Λ0 := {∅, S}, Λn := σ([[θi]]S ; i < n).
Then for each n, we set τn := 1[[θ ]] and define αn : {0, 1}n → Λn as:
αn(x)= ∩i<n{s | τi(s)= xi}, with the convention that {0, 1}0 = {∗} and α0(∗)= S.
Each Λn is a finite boolean algebra and so has atoms (non empty sets in
Λn with no proper subsets); each atom of Λn is the image by αn of a unique sequence x ∈ {0, 1}n, but not all sequences are mapped to atoms, some are mapped to the empty set.
Now the idea is to construct p stagewise and at each stage to divide evenly the mass of an atom αn(x) ∈ Λn between its proper subsets in Λn+1 if there

6 For each n, Λn ⊆ Λn+1, this is usually called a filtration.


are some. Specifically, we define inductively pn on Λn-atoms as:
p0(∅)= 0, p0(S)= 1
αn+1(x0) /=∅, αn+1(x1) /=∅ ⇒ pn+1(αn+1(x0)) = pn+1(αn+1(x1)) = 1 · pn(αn(x)) αn+1(x0) = ∅, αn+1(x1) /=∅ ⇒ pn+1(αn+1(x0)) = 0, pn+1(αn+1(x1)) = pn(αn(x)) αn+1(x0) /=∅, αn+1(x1) = ∅ ⇒ pn+1(αn+1(x0)) = pn(αn(x)), pn+1(αn+1(x1)) = 0

Clearly each pn extends to a unique probability on (S, Λn) since it is defined on Λn-atoms and the pn are compatible in the sense that pn+1 T Λn = pn; the sequence pn converges to an additive set map on the union ∪nΛn.
In most cases, including the case of finite state spaces, this p will be extend- able to a sort of “skewed” Lebesgue measure, also written p, and defined on σ(L0), the σ-algebra generated by our temporal formulas. 7 But, and contrary to what was said in a former version of this construction [6], in the absence of further structure on the state space, one cannot guarantee this. On the other hand, if such an extension exists, it is unique. From now on, we will take the conservative assumption that this extension exists.
We take note, for future use, that for any finite set of formulas J ⊂ L0, writing ΛF the associated σ-algebra, one has:
p([s]Λ ) ≥ 2−N	(2)
where N = max {i | θi ∈ J} and s ∈ S.
Second, we observe that the p obtained here will depend on the original enumeration, and we leave for future investigation the question of whether there is a principled way of choosing p. In our case, all choices will work equally well.
As an example we can consider the transition system with only state s, only one letter a and h(a, {s})(s)= 1/2. Then s |= θ if and only if all coefficients used in θ are below 1/2. In this case, and as with all one-state systems, at any stage there will be at most one atom namely {s} and therefore p({s})= 1.
Compressing Σ
But the reader might protest that to apply the projection, one needs a prob- ability on an arbitrary Σ not just on σ(L0). Well, in fact, it is enough to consider the latter case because of Theorem 4.5 (saying that σ(L0) is the smallest σ-algebra closed under shifts).
Therefore, σ(L0) is always included in Σ, since Σ has to be closed by shifts (this is equivalent to asking that h(a, A) are all Σ-measurable) and one can

7 To be exact, by σ(L0) we mean σ([[θ]]S ; θ ∈ L0).


always “compress” an LMP to σ(L0). The obtained LMP is obviously bisim- ilar to the first since by construction states are the same and their temporal properties remain the same as well. Without loss of generality, we may and will suppose thereafter that Σ = σ(L0).

Approximations
Now we can complete the approximation construction.
Let £ be a compressed LMP £ = (S, Σ, h) with Σ = σ(L0), and J ⊆ L∗ be a ﬁnite set of formulas, set Λ to be the σ-algebra, σ(J ), generated by J on S.
We observe that by inequation (2), p is granular over Λ, so the machinery gets us a ﬁnite-state LMP approximant:


£ = (S, Σ, h) [.]Λ
= ([S]Λ
, [Λ]Λ
, k)

which is the quotient constructed above after the appropriate projection.
There are at most 2|F| states in £F , in particular it is a finite-state proba- bilistic transition system.

Convergence
We need to say how the obtained £F approximates £. In the previous approaches, approximants were always below the approximated process and hence simulated by it. It is not the case here since approximants are neither above nor below £. However, £F does converge to £. This is what the fol- lowing proposition says; it improves on the analog proposition in the original paper which only concerned the smaller logic L0.
Proposition 5.7 For every ﬁnite subformula-closed set of formulas J ⊂ L∗:
£F ≈F £.
Proof.
Let R be the coarsest simulation between θ = (I, λ) ∈ L∗ and £. Define R∗ to be the composition of R with the quotient morphism from £ to £F . This is well defined since R is the coarsest simulation and because equivalent states satisfy the same formulas of J. We prove that R∗ is a simulation. Let (i, [s]) ∈ R∗ and j ∈ I. Then λ(a, i, j) ≤ h(a, R(j))(t) for all t ∈ [s] because it is true for at least one t ∈ [s] by definition of R∗ and because all states in [s] satisfy the same formulas of J. This implies that λ(a, i, j) ≤ Ep(h(a, R(j))|Λ)(t) for all t ∈ [s], which shows that R∗ is a simulation since ∪R∗(j)= R(j).

Now let R be a simulation between θ = (I, λ) ∈ L∗ and £F . Define R∗
to be the composition of R with the inverse of the quotient morphism from
£ to £F . We prove that R∗ is a simulation. Let (i, s) ∈ R∗ and j ∈ I, that is, (i, [s]) ∈ R. Thus λ(a, i, j) ≤ Ep(h(a, ∪R(j))|Λ)(t) for all t ∈ [s]. Then
at least one t ∈ [s] satisfies λ(a, i, j) ≤ h(a, ∪R(j))(t) = h(a, R∗(j))(t). This
equation is true for all t ∈ [s] because they all satisfy the same formulas of J, and hence it is true for s, as wanted.	 
From Proposition 2.6, it follows now easily that:
Theorem 5.8 If (Ji) is an increasing sequence of subformula-closed sets of formulas converging to the set of all formulas L∗, then for all c ∈ (0, 1):
dc(£F , £)—→i→∞0.

We could have taken another route to prove Proposition 5.7. As the ex- ample 5.3 suggested, quotients constructed with conditional expectations do lie between the inf- and the sup- approximants [5]:

k(a, [A])([s]Λ) := h'(a, A)(s)

=   1   ∫
h'(a, A) dp	h'(a, A) constant on [s]Λ

=   1   ∫
h(a, A) dp	[s]Λ ∈ Λ

≥ inft∈[s]Λ h(a, A)
The second equation holds both because h'(a, A) is constant on equivalence classes and because p is granular and therefore p([s]Λ) > 0. The third equation is the characteristic property of conditional expectations. A similar type of argument allows one to reason analogously for the supremum case.
Thus another, indirect, way to prove the previous proposition, is to use this sandwiching effect and the fact that the infimum and supremum were proven to give approximations in the same sense as proposition 5.7 [5]. This also makes clear in which sense the average-based approximants are better than the order-theoretic ones.

Conclusion
We have presented a constructive approximation which is an improvement of the original one [9], and also two new abstract notions of approximation. The first is based on customizing the approximation with respect to certain


formulas of interest, the second is based on averaging techniques, or - more precisely - on the use of conditional expectations.
For the first abstract construction, we have added two simple ideas to the theory of LMPs: first, LMP approximants should be quotients with respect to the LMP bisimulation logic L0, yielding stronger approximants; second, the same quotient construction, supposing there is one, should be possible with a logic enriched with greatest fixed points and produce families of approxi- mants sharing cyclic behaviours with the approximation target, resulting in a faster approximation construction, since finite processes are approximated by themselves at some finite stage.
Not only do these two ideas carry through, but despite their apparent independence they work together fruitfully. Some of the known constructions and definitions have to be relaxed in so doing but the resulting theory is in many ways more pleasing than the original.
We believe that the present work is an important step towards model- checking LMPs. For example, if one knows what are the properties that a given continuous process should satisfy, one would prefer to check for these properties on a finite faithful approximant of the process instead of checking each property on the process itself. Our construction achieves this goal since it theoretically ensures exact satisfaction of formulas.
Observe that in Example 4.1, if one was interested specifically in the initial state s0 one could live with the approximant: [s0]  b  [s , t] because [s0] is equivalent to s0, if we consider only formulas of depth 1 —of course there is a loss for other states like s and t which are not equivalent to [s, t]. This suggests that there may still be a way of quotienting with formulas and obtain an LMP. We want to investigate this possibility, which we think will be a fairly easy task. More interestingly, observe that the quotient we have defined does not depend only on the satisfied formulas, we crucially use probability information from the system itself. This implies that two processes that are J-equivalent may not have the same quotient. We plan to investigate the possibility of using the quotient construction without using the actual values of the transition probabilities in the original process, but only values provided by formulas that are satisfied. Instead, we would use only formulas in J and take infima over the formulas satisfied by equivalent states. Every state in the resulting pre-LMP would be the representant for every J -equivalent state. An important application of this would be a way to construct a process by using only the formulas that it has to satisfy, that is, the automated design of probabilistic models from specifications. We believe that in this case, there will be no LMP that will satisfy the same property (even for finite quotients), showing that pre-LMPs are essential for the design of probabilistic systems.


On the practical side, the effective construction of these pre-LMPs could be costly in time or inconvenient. One has to choose a set of formulas that will be used to quotient the state space. A pre-LMP is then produced by computation of an infimum from every equivalence class to possibly every logically definable union of states. This last step increases complexity significantly.
However, we also presented an even faster version of approximants which parallels a former construction [9] and introduces additional loops. The incon- venient of this concrete approximation scheme is that one does not have the choice of formulas, except for their depth and a desired precision. The same properties are satisfied: every formula satisfied by a state is eventually satisfied by the state approximant, and finite processes are eventually approximated by themselves.
Ongoing research is also trying to apply this theory of approximants to other probabilistic models such as continuous time Markov chains and to ex- tend it to a richer logic. One potential application are Markov Decision Pro- cesses that one finds in the field of machine learning. Approximants have been studied in this field, but always with a focus on partitioning the state-space without taking account of the behaviour of processes, that is, of the actual transitions that states can take. As a result, bisimilar or behaviourally close states can be split in the process, whereas our constructions always partition the state-space with respect to satisfaction of formulas.
The last approach to approximation is more probabilistically-minded. It is based on conditional expectations. Given a probability p on (S, Σ), and a sub-σ-algebra Σ' of Σ, it is possible to define the conditional expectation given Σ' of any integrable function according to p. Applied to finite-state systems, the idea downs to taking the quotient kernel to be an average rather than an infimum.
This technique for LMPs shares a number of good properties with our first abstract approach. It can be customized in the same sense; however, one can use it and also stay within the framework of traditional LMPs and avoid having to work with pre-measures.
We feel that, beyond the properties of the construction, there are some new directions implicit in this probabilistic approximation work. First, the idea of granularity is, we feel, significant. One of the big obstacles to the applicability of modern probability theory on general spaces to the computational setting has been the curse of non uniqueness embodied in the phrases “almost ev- erywhere” and “almost surely” seen almost everywhere in probability theory. One can even argue that the bulk of the computer science community has worked with discrete systems to try and avoid this non uniqueness. Our use of granularity shows a new sense in which the discrete can be used to dispel

the non uniqueness that arises in measure theory.
The second important direction that we feel should be emphasized is the use of averages rather than infima. This should lead to better numerical properties. More striking than that however is the fact that the simulation order is not respected by the approximants. Perhaps it suggests that some sort of non monotone approximation occurs. Similar phenomena have been observed by Martin [17] - which was the first departure from Scott’s ideas of monotonicity as being one of the key requirements of computability - and also in the context of non determinate dataflow [19].
Let us conclude with a further comment on why we do not mention any properties of analytic space, in contrast to what is done in previous papers on LMPs. In fact, analyticity is needed if one wants to use the fact that the relational definition of bisimulation is characterized by the logic. If one is happy with only the logic or the metric in order to compare or work with LMPs, there is no need for analyticity of the state space in the definition. However, if one indeed needs the analytic property of processes, the results of the present paper carry through since the quotient of an analytic space under countably many conditions is analytic. This follows essentially from well known facts about analytic spaces, see for example chapter 3 of “Invitation to C∗-algebras” by Arveson [1].

References
W. Arveson. An Invitation to C∗-Algebra. Springer-Verlag, 1976.
G. Choquet. Theory of capacities. Ann. Inst. Fourier (Grenoble), 5:131–295, 1953.
Vincent Danos and Jos´ee Desharnais. Note sur les chaˆınes de Markov ´etiquet´ees. Unpublished (in French), 2002.
Vincent Danos and Jos´ee Desharnais. A fixpoint logic for Labelled Markov Processes. In Proceedings of the International Workshop on Fixed Points in Computer Science (FICS’03), pages 413–422, Warsaw, 2003.
Vincent Danos and Jos´ee Desharnais. Labeled Markov Processes: Stronger and faster approximations. In Proceedings of the 18th Symposium on Logic in Computer Science, pages 341–350, Ottawa, 2003. IEEE.
Vincent Danos, Jos´ee Desharnais, and Prakash Panangaden. Conditional expectation and the approximation of labelled Markov processes. In CONCUR 2003 - Concurrency Theory, volume 2761 of Lecture Notes in Computer Science, pages 477 – 491. Springer-Verlag Heidelberg, December 2003.
J. Desharnais, A. Edalat, and P. Panangaden. Bisimulation for labelled Markov processes.
Information and Computation, 179(2):163–193, Dec 2002.
Jos´ee Desharnais. Labelled Markov Processes. PhD thesis, McGill University, November 1999.
Jos´ee Desharnais, V. Gupta, R. Jagadeesan, and P. Panangaden. Approximating labeled Markov processes. Information and Computation, 184(1):160–200, July 2003.


Jos´ee Desharnais, Vineet Gupta, R. Jagadeesan, and Prakash Panangaden. Metrics for labeled Markov processes. In Proceedings of CONCUR99, Lecture Notes in Computer Science, pages 258–273. Springer-Verlag, 1999.
Jos´ee Desharnais, Vineet Gupta, R. Jagadeesan, and Prakash Panangaden. Approximating continuous Markov processes. In Proceedings of the 15th Annual IEEE Symposium On Logic In Computer Science, Santa Barbara, Californie, USA, pages 95–106, 2000.
E.-E. Doberkat. Semi-pullbacks and bisimulations in categories of stochastic relations. In Proceedings of the 30th International Colloquium on Automata, Languages, and Programming (ICALP), number 2719 in Lecture Notes In Computer Science, pages 996–1007. Springer- Verlag, 2003.
Abbas Edalat. Domain of computation of a random field in statistical physics. In C. Hankin,
I. Mackie, and R. Nagarajan, editors, Theory and Formal Methods 1994: Proceedings of the second Imperial College Department of Computing Workshop on Theory and Formal Methods, pages 11–14. IC Press, 1994.
Abbas Edalat. Domain theory and integration. Theoretical Computer Science, 151:163–193, 1995.
Masahito Hasegawa. Recursion from cyclic sharing: traced monoidal categories and models of cyclic lambda calculi. In 3rd International Conference on Typed Lambda Calculi and Applications (TLCA’97), volume 1210 of LNCS, pages 196–213. Springer, 1997.
C. Jones and G. D. Plotkin. A probabilistic powerdomain of evaluations. In Proceedings of the Fourth Annual IEEE Symposium On Logic In Computer Science, pages 186–195, 1989.
Keye Martin. The measurement process in domain theory. In International Colloquium on Automata, Languages and Programming, pages 116–126, 2000.
R. Milner, J. Parrow, and D. Walker. A calculus of mobile processes i and ii. Information and Computation, 100:1–77, 1992.
Prakash Panangaden and V. Shanbhogue. The expressive power of indeterminate dataflow primitives. Information and Computation, 98(1):99–131, 1992.
Franck van Breugel, Michael Mislove, Jo¨el Ouaknine, and James Worrell. An intrinsic characterization of approximate probabilistic bisimilarity. In Proceedings of the 6th International Conference on Foundations of Software Science and Computation Structures (FOSSACS), number 2620 in Lecture Notes In Computer Science, pages 200–215, 2003.
Franck van Breugel, Steven Shalit, and James Worrell. Testing labelled markov processes. In Proceedings of the 29th International Colloquium on Automata, Languages, and Programming (ICALP), number 2380 in Lecture Notes In Computer Science, pages 537–548. Springer-Verlag, 2002.
David Williams. Probability with Martingales. CUP, Cambridge, 1991.
