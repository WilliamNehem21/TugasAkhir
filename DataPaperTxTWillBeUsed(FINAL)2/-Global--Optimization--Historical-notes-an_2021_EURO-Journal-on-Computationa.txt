EURO Journal on Computational Optimization 9 (2021) 100012

		




(Global) Optimization: Historical notes and recent developments
Marco Locatelli a, Fabio Schoenb,‚àó
a DIA - Universit√† di Parma, Parco Area delle Scienze, 181/A, Parma - 43124, Italy
b DINFO - Universit√† degli Studi di Firenze, via di S. Marta, 3, Firenze - 50139, Italy


a r t i c l e	i n f o	a b s t r a c t

	

Keywords:
Global optimization Heuristics
Exact methods
Recent developments in (Global) Optimization are surveyed in this paper. We collected and commented quite a large number of recent references which, in our opinion, well represent the vivacity, deepness, and width of scope of current computational approaches and theoretical results about nonconvex optimization problems. Before the presentation of the recent developments, which are subdivided into two parts related to heuristic and exact approaches, respectively, we briefly sketch the origin of the discipline and observe what, from the initial attempts, survived, what was not considered at all as well as a few approaches which have been recently rediscovered, mostly in connection with machine learning.





introduction

It seems worthwhile, in a special issue like this one, to devote a few words to the foundation of (global) optimization as an independent re- search topic. Looking back to the early days might prove useful, as some old ideas which, in the beginning, did not lead to much development, might prove to be interesting for current research, when considered from a modern perspective. Moreover, it is interesting to notice how some of the sub-fields which have seen a very large set of contributions in recent years, were almost totally neglected in the beginning. We refer in partic- ular to exact (global) optimization methods based on implicit enumer- ation and to the jungle of ‚Äúnature inspired‚Äù population heuristics. For what concerns this kind of heuristics, we need of course to cite at least the book Holland (1975) where the basic ideas of genetic algorithms are nicely introduced. In what follows, we will first give a quick overview of the main approaches contained in the two classical books devoted to the subject in the 70‚Äôs (Dixon and Szeg√∂, 1975; 1978). Then, we will give more details on recent developments. We also refer to our book Locatelli and Schoen (2013) for a detailed discussion about (global) op- timization topics, updated as of the date of publication of the book. After the historical introduction, the paper will consider two topics: recent, or re‚Äìdiscovered, heuristic approaches and recent developments in exact approaches. A final observation before the beginning of the paper: here and in the title we parenthesized the word (global). We will omit doing so in the paper, but we would like to observe that, although in the past the subject was considered somewhat exotic and off the main research streams, nowadays the richness of both theory as well as computational approaches gives to the subject a full recognition in the scientific com- munity. We might then propose, with a slightly provocative style, to
rename the whole subject simply as ‚Äúoptimization‚Äù ‚Äì what else should we look for when optimizing, if not a global optimum?
The paper is structured as follows. After the brief introduction given in this section, in Section 2 we recall the contents of the two books
edited in the70‚Ä≤s by Lawrence Dixon and Giorgio Szeg√∂, which gave
a strong initial impulse to the whole discipline. In Section 3 we re-
view some of the many heuristic computational approaches published in the literature in recent years (say, roughly after the publication of our book Locatelli and Schoen (2013), of which this paper might be consid- ered as a continuation). Section 4 surveys recent literature dealing with structured optimization problems for which an exact procedure can be designed. In Section 5 we briefly discuss some computational aspects and suggest sites where exhaustive lists of GO test problems and solvers can be found. Some concluding remarks are finally presented.

On the origins of global optimization

Many early papers dealt with non convex optimization problems and outlined basic algorithms. We recall here, as particularly inter- esting examples, Dantzig (1960), McCormick (1972), Beale and For- rest (1976), Falk and Soland (1969), Soland (1971), McCormick (1976), Horst (1976). All of these papers had impact on the whole field, as well as many others we are not citing here. Despite the relevance of these as well as many other early papers, it can quite safely be assumed that the first ‚Äúlarge scale‚Äù diffusion of the ideas of Global Optimization (denoted by GO in what follows) can be credited to the two ‚Äúorange‚Äù books Dixon and Szeg√∂ (1975, 1978). These two books, although clearly not the first publications in GO, gave a fundamental impulse to the whole research field and since their publication, the term ‚ÄúGlobal Optimization‚Äù started to be a recognized and respected label, characterizing optimization the-

‚àó Corresponding author.
E-mail addresses: marco.locatelli@unipr.it (M. Locatelli), fabio.schoen@unifi.it (F. Schoen).

https://doi.org/10.1016/j.ejco.2021.100012
Received 30 October 2020; Received in revised form 20 September 2021; Accepted 25 September 2021
2192-4406/¬© 2021 The Author(s). Published by Elsevier Ltd on behalf of Association of European Operational Research Societies (EURO). This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)



ory and methods for nonconvex optimization problems. To insist on the fact that the field was just in its infancy at that time, it might be observed that only 9 of the 25 papers in the first volume and only 12 out of 24 in the second one were grouped in the ‚ÄúGlobal Optimization‚Äù chapters, all the others being local optimization papers, despite the title of the two books. It might be of interest to observe the topics which, at that time, were considered as the most promising ones. In this section we will briefly review some of the main ideas proposed at that time and comment on their success in the GO literature and practice.
We can group the first few papers on global optimization as follows:

Space covering. This area was related to methods aiming at implicitly exploring the whole feasible region. In particular, methods were described, mainly for 1‚Äìdimensional optimization, which, based on the knowledge of (an upper bound to) the Lipschitz constant of the objective function,
ror in the approximation of ùëì ‚ãÜ = minùë•‚ààùëÜ ùëì (ùë•). could be built with a guaranteed maximum er-
In the survey by Dixon (1975) the methods of Evtushenko (1971) and of Shubert (1972) (later known as Piyavskii-Shubert (Piyavskii, 1972)) were described. In the following years those approaches generated a stream of research in Lipschitz‚Äìoptimization, with some interesting ap- proaches but also severe limitations. In general, as nicely described in another milestone in the field, Horst and Tuy (1993), these can be seen as precursors and special cases of modern Branch & Bound algorithms. The idea of Branch & Bound for nonlinear optimization was not considered at all in the two original books.
Trajectory methods. At those times the idea of following the trajectory
of a suitable set of differential equations seemed to be very promising. Some of the proposed ap- proaches required locating saddle points in the boundary of the region of attraction of known local optima in order to be able to escape and explore new basins. A group of papers in the book, mostly from Joanna Gomulka and Gior- gio Treccani, explored this idea. In the follow- ing years this approach received less attention, although some similarities can be traced with some approaches based on stochastic differential equations and with some recent approaches in the neural network literature. A recent survey on developments in this algorithmic family can be found in Alexandropoulos et al. (2020).
Bayesian Optimization. At those times, GO problems with as few as ten
variables, with just box constraints, were con- sidered as the frontier in computational GO ap- proaches. Much of the effort then was devoted to very small scale problems; even at small scale, black-box problems were considered as very rel- evant. In fact, practical problems arise in which the objective function is not available in analyt- ical form, but can only be evaluated at specific points, possibly through an expensive procedure. Among the most interesting and profound ideas for small dimensional, possibly 1‚Äìdimensional, GO problems, Bayesian Optimization (BO) was particularly relevant. The main ideas of BO can be traced back to papers published in the 60‚Äôs by Harold Kushner (see, e.g., Kushner (1964)) and then generalized in Mockus (1975) and in many papers by the same author. The idea of
BO is fascinating: assume the objective function is a realization of a stochastic process, typically a Gaussian one. Then, given a prior distribu- tion on the possible sample paths of the pro- cess, after a few observations of the objective function, possibly affected by errors, have been performed, a posterior distribution can be com- puted, leading to a conditional stochastic model which is further updated as soon as the true ob- jective function is observed at new sample points. This stochastic model can be analyzed in order to answer, through suitable numerical algorithms, queries like: find the point at which the expected value of the function is minimum, or find the point at which the expected improvement over the current best observation is maximum. These queries are themselves GO problems, but, dif- ferently from the original one, possess a known analytical expression, from which gradients can be analytically computed; the global optimiza- tion required can be carried out with standard GO methods, without any necessity of excessive precision. It is worth observing that, although born in a stochastic framework, these methods are indeed deterministic. A nice and relevant gen- eralization and implementation of the BO ideas can be found in Jones et al. (1998), currently among the top cited papers in the whole GO lit- erature. Among the reasons for the great success of this paper we can mention the fact that, after a period in which BO almost disappeared from the literature, as a consequence of the high in- crease in complexity per iteration in the multi‚Äì dimensional case, the implementation of EGO de- scribed in Jones et al. (1998) recently became a standard for hyperparameter optimization in machine learning (see, e.g., Frazier (2018) for a recent survey). The field has considerably ex- panded in the last years and it is the subject of very active research.
Random Search. Methods based on some form of random sam-
pling were considered in the two books, as they are in general simple to implement and do not require first order information on the objective function. In Gaviano (1975) some general con- vergence results were proven; quite a few papers proposed random search algorithms, which, how- ever, did not find great attention in the following years. The field was quite productive for some time, and new approaches have been published in recent years. Some of those we consider as the most interesting ones are reviewed in our book Locatelli and Schoen (2013).
Clustering. This, at the time, seemed to be one of the bright- est and most innovative ideas. The eÔ¨Éciency of the most elementary GO method, Multistart (sample some random points and start a local search from each of them), is improved by care- fully selecting from which sample points it seems worth starting an expensive local optimization. Ideally, a single local search should be started from each basin of attraction (and, possibly, not from all of them, but just from the most ‚Äúpromising‚Äù ones). This idea was first proposed in Becker and Lago (1970) and then has been expanded and made available to a larger audi-



ence in T√∂rn (1978). The idea of the proposed approach is both simple and powerful. First draw a uniform sample of feasible points. Then ‚Äúcon- centrate‚Äù the sample towards local optima either by temporarily discarding a fraction of highest value observations, or by performing a few de- scent steps. Finally, identify higher density re- gions (clusters), from each of which a single local search is started. The approach had immediately a great success and seemed to represent ‚Äúthe‚Äù GO method of choice, until a few years later, when it gradually got abandoned. There might be many reasons for the decline of clustering methods. We conjecture that this might be due to:
the practical impossibility of dealing with large dimensional problems, say with more than 10 variables;
the fact that the method could be used just to speed up Multistart, while more advanced algorithms appeared in the literature;
the method became popular as it allows to save on local searches which, at the time, were very time consuming. With the advent of modern local optimization methods, al- though saving unnecessary local searches re- mains a good point, the eÔ¨Éciency of local search made those savings quite negligible in the overall method.
In recent years, some new methods have been proposed (see Bagattini et al., 2018; Bagattini et al., 2019; Schoen and Tigli, 2021) which re- visit these ideas trying to soften as much as pos- sible the above defects.

Recent heuristic GO methods

In this section we would like to present a few recent papers dealing with modern GO algorithms. The papers cited in this section come either from the vast field of evolutionary approaches or have been stimulated and, in some cases, re-discovered thanks to the exponential growth in the interest around machine learning. We point out that the review of recent literature will be partial and biased towards our knowledge and preferences. It is really an impossible task to track all the papers dealing with GO heuristics, and even more diÔ¨Écult to highlight those which are indeed relevant and truly innovative. But we tried to do our best in describing interesting new approaches in this wide field.

Population-based, evolutionary methods

An enormous quantity of papers dealing with variants of the basic evolutionary population schemes appeared in recent years. In the au- thors‚Äô opinion it is quite disturbing that most of the papers in this sub- field justify themselves by some sort of an inspiration from nature, and, frequently, do not report any theoretical justification of the algorithmic choices, nor a fair and wide numerical comparison with state-of-the-art algorithms on well recognized benchmarks of test functions. A charac- teristic within this family of approaches is that they are mostly based on some variation of very basic schemes which include:
a random generation of the initial set of solutions (initial popula- tion);
a combination mechanism which takes parts of the components of the solutions represented in the current population and generates a new set of solutions;
possibly a mutation, through which some solutions are randomly perturbed;
possibly, in memetic algorithms, a local search applied to a selection of the elements in the current population;
a substitution criterion, based on observed function values, by which from the original and the current population, a new set of solutions is built.

Some standard algorithms arose from this basic scheme. The most no- table, in GO, are Differential Evolution (DE) and Particle Swarm (PS), for whose description we address the reader to the rich literature on the sub- ject or to our chapter in Locatelli and Schoen (2013). Some recent sur- veys have been published on this subject (see, e.g., Das et al. (2016) or Del Ser et al. (2019)). In the recent literature some new proposals ap- peared like, e.g., Cui et al. (2016) or Wu et al. (2016), where multiple populations, with different evolution strategies, are evolved simultane- ously and compete among themselves to improve the best population. It seems that memetic variants of DE stand out as a good compromise between simplicity and quality. For DE we can even cite some theoreti- cal convergence results (Ghosh et al., 2012; Locatelli and Vasile, 2015) which can suggest guidelines for algorithm definition.
Among many variants of DE, those based on the exploitation of lo- cal optimization (memetic variants) are very interesting, as many GO problems allow for fast and reliable local search tools. In Cabassi and Lo- catelli (2016) an analysis of some variants of the basic memetic DE is in- troduced and numerically shown to be very effective on a wide range of GO test problems of varying dimension. In Schoen and Tigli (2021) those methods have been extended and mixed with a clustering approach in order to save unnecessary local searches; numerical results show that it is possible to significantly improve the eÔ¨Éciency of those population‚Äì based methods while keeping their good quality. On a different line of research, in Mansueto and Schoen (2021) a DE‚Äìbased memetic ap- proach is used to build an eÔ¨Écient GO method for optimal clustering in Euclidean spaces. In that paper a specialized local search is used, based
on the well known ùêæ‚Äìmeans clustering algorithm, coupled with the ex-
ploration capabilities of DE.
A source for many evolutionary algorithms, as well as test problems, can be found in the various CEC (the IEEE Congress on Evolutionary Computation) competition websites. It appears that, in those competi- tions, a dominant role is played by population‚Äìbased methods which in some way exploit the separability or partial separability of prob- lems. The idea of, at least partially, decompose a GO into sub-problems is adopted by quite a large number of successful approaches in those competitions. Of course, for separable problems it is easy to forecast their good performance, but numerical results seem to be quite inter- esting also for non separable ones. The paper Ma et al. (2019) con- tains a survey on decomposition‚Äìbased methods and presents the ba- sic ideas of these approaches. There are many variants of the basic scheme, which typically differ in the decomposition strategy and the recombination one; many are based on a Gauss-Seidel‚Äìlike strategy in which optimized subsets of variables are fixed and used while optimiz- ing different subsets. We can cite here, as an example of an eÔ¨Écient GO approach, Hadi et al. (2019), where, starting from an adaptive DE scheme in which some hyperparameter is adjusted during the evolu- tion, a hybrid, decomposition‚Äìbased, memetic approach is proposed. In particular, at some stage of the computation, variables are randomly grouped and different local optimization algorithms are associated to each sub-group of variables. The winner of the 2019 CEC competition Sun et al. (2019) uses an innovative strategy to decompose non separa- ble problems which leads to a highly eÔ¨Écient method. Their decompo- sition scheme is based on the identification of subsets of variables which partially overlap one another.
Finally, we would like to mention the family of CMA-ES (Covari-
ance Matrix Adaptation Evolutionary Strategies) algorithms (see, among many papers on the subject, Hansen and Ostermeier (2001) for an early introduction to the approach, or Hansen (2006) for a survey on variants of the basic method). The idea behind CMA-ES is that of having a popula- tion of solutions to a GO problem which evolves through sampling from



a multinomial distribution whose mean and covariance matrix evolve during the iterations and in some sense adapts to the level sets of the objective function. The objective function is evaluated at each sample point and a new mean and covariance matrix are generated through an updating mechanism. Oversimplifying a description of this family of approaches, which is indeed quite vast, we might say that they try to adapt search directions and step sizes in order to favour changes in the current population members which are likely to contribute much to the improvement of the objective function. This is usually obtained by following directions associated to the principal components of the co- variance matrix, which is built in such a way as to adapt to observed function values. In Diouane et al. (2015a,b) an interesting extension of the basic scheme is presented in which, imposing a criterion of suÔ¨É- cient decrease in the objective function, some convergence properties are obtained.

Basin-Hopping methods

Multistart is one of the simplest GO methods, where a local search is started from each point randomly generated within the feasible region of a GO problem. It is usually considered a low eÔ¨Éciency algorithm for GO due to the computational waste it produces in rediscovering the same local optima more than once and due to its absence of any learn- ing mechanism (see Section 3.4 for further comments on these topics). However a relatively simple modification of Multistart, which goes un- der the name of Basin Hopping (BH), or Iterated Local Search, is quite an interesting approach for many hard GO problems. As in Multistart, also in BH local optimization is performed starting from a random ini- tial point. However in BH, after a local optimum is found, new local searches are performed starting from a (suitably defined) neighborhood of the current one until possibly a better local optimum is found; in this case new local searches are performed starting from a neighborhood of the new local minimum, and the whole procedure is repeated until some stopping rule is satisfied. The version we sketch here is the monotonic version of the method: non monotonic ones have also been successfully implemented. BH has been used in Vink√≥ and Gelle (2017) as a tool to build a graph of neighboring local optima, much in the sense of what was described in Chapter 3 of our book Locatelli and Schoen (2013). Given a BH algorithm with specific parameters, a run on a specific test function generates a set of local optima which can be pairwise connected in a graph in which an oriented arc exists between two local minima if the second one has been reached through a BH step from the first one. The resulting graph associated to some classical test functions can be an- alyzed. It might be possible to exploit this information in order to build advanced BH methods, but this is still a subject of current research. A hybrid approach, mixing Differential Evolution with BH is presented in Di Carlo et al. (2020), where a simple criterion is presented to save un- necessary local searches.
Most recent literature on BH and its variations, including
population‚Äìbased variants as discussed, e.g., in Grosso et al. (2007), deals with application of these methods. Many of those applications are in computational chemistry, a field where BH was born and has found a prominent space in current research. As an example, in Zhao et al. (2017) a modified BH is applied to the optimization of atomic clusters. Among the many variations, in this paper it is sug- gested that some variables are kept fixed at certain iterations (those corresponding to the location of specific subsets of atoms), while some others are subject to perturbation in BH steps. Moreover, some accep- tance criteria different from the improvement of the objective function are suggested, like the exploration of new geometrical configurations. In Ferreiro-Ferreiro et al. (2019) a simple modification of the BH scheme is introduced and tested on specific atomic clusters. The idea is to let BH explore deeper basins by reducing its ‚Äúgreediness‚Äù. To this aim, at each iteration, several neighboring local optima are generated and, instead of moving towards the first improving one, the best is chosen as the starting
point of the next iteration. In Wales (2018) variants of BH are described in the context of energy landscapes for atomic clusters. Different accep- tance rules are proposed that differ from the classical monotonic and Metropolis-like acceptance rules, generalizations to multiple objectives in the exploration phase are introduced, and further refinements based on molecular dynamics are proposed.

Methods for expensive black-box objective functions

This field has recently attracted enormous attention, driven by ma- chine learning research, as algorithms within this framework are con- sidered as especially suitable for hyperparameter calibration in training machine learning tools like, e.g., deep learning architectures. A survey on the subject of optimization‚Äìbased hyperparameter choice in machine learning recently appeared in Yang and Shami (2020), where a list of available software is also provided. Also, in Tran et al. (2020) a dis- cussion on the use of optimization tools in hyperparameter tuning is presented. In applications for hyperparameter setting, two levels are usually present. At the lower level, given a training set, learning pro- ceeds by suitably choosing (in neural networks, as an example) con- nection weights in such a way that a loss function is minimized; at the upper level the loss function itself, the overall architecture and, some- times, the optimization algorithm used for training, depend on a rela- tively small number of hyperparameters (e.g., the parameter associated to regularization, the number of layers, the ‚Äúlearning rate‚Äù,...). These hyperparameters are usually optimized considering the performance of the lower level trained system on a validation set, different from the one used for training. In general, thus, the objective function to be op- timized at this level is neither known, nor cheap, and is modeled as a black box. GO methods for expensive cost functions are among the primary choices for this tuning. We will not even try to summarize the overwhelming quantity of reports recently published on this sub- ject on arXiv. Although excellent research is sometimes found in that dynamically exploding repository, here we chose to refer exclusively to papers published in high quality refereed journals. A nice survey of state-of-the-art approaches in Bayesian Optimization can be found in Frazier (2018), while in Zhan and Xing (2020) several different objec- tive functions based on variation of the originally proposed Expected Improvement are presented and discussed. In Mathesen et al. (2020) an interesting generalization of Bayesian Optimization models is proposed, in which the ‚Äúacquisition function‚Äù takes into account the desire to im- prove the exploration capabilities, as the exploitation is delegated to a trust-region based local search which takes into account the available budget of function evaluations. It is interesting how, even in an expen- sive function setting, the idea of performing local optimization can be effectively exploited. In Ahmed et al. (2020) it is suggested to use an estimate of the Lipschitz constant in order to improve the search for the next observation point, an approach which, at least for moderately sized problems, might have some relevance. Instead, in Bemporad (2020) the proposed approach is not based on a stochastic model of the objective function, but, taking inspiration from those models, the author proposes a surrogate function composed of three elements: an interpolation of ob- served sample values, a distance from the points in the sample, distance of the objective function values. This acquisition function is optimized in order to decide where the next observation should be placed.
A recent stream of research has started exploring the possibility of
applying the idea of Bayesian Optimization to large scale GO prob- lems. The main tool used to greatly increase the dimension of problems which can be solved through this approach is the idea of random em- beddings. The philosophy of these approaches (see Binois et al., 2020; Moriconi et al., 2020; Wang et al., 2016) relies on the assumption that for large dimensional problems there exists a true ‚Äúlow effective dimen- sionality‚Äù, which can be considered as a low‚Äìdimensional linear em- bedding such that the objective function does not change when mov- ing along directions which are orthogonal to this embedding. A differ-



ent approach to large-scale adaptation of these methods is reported in Snoek et al. (2015), where a neural network is used to learn a set of basis functions to be used to build a Bayesian linear regressor which substitutes the computationally expensive classical one.
Among the most interesting approaches in the Bayesian Optimization literature, it seems worth citing extensions to the constrained case and, in particular, to the case in which also the constraints are expensive, black-box, functions. Hern√°ndez-Lobato et al. (2016) present a detailed survey of constrained Bayesian Optimization methods. A novel frame- work is also introduced for the case where at each iteration a new sample point needs to be generated at which both the objective function as well as the constraints have to be evaluated. However, in the proposed ap- proach, it is assumed that functions (objective and constraints) might be at least partially separable into parts (so called ‚Äútasks‚Äù) ‚Äì as a simple example, the objective function might be evaluated on a CPU while the constraints are defined in a way that enables to exploit the parallelism of a GPU. In these cases, the merit (or ‚Äúacquisition‚Äù) function which guides the search for the next evaluation point, should be defined in such a way as to support a similar decomposition. In that paper, a novel acquisi- tion function, called PESC (Predictive Entropy Search with Constraints) is proposed as particularly well suited in this framework. Constrained Bayesian Optimization is also considered in Feliot et al. (2017), mostly in the context of an extension of the basic approach to multi-objective optimization, an interesting topic which is, however, out from the scope of this paper.
On a different line of research, in Garrido-Merch√°n and Hern√°ndez-
Lobato (2020) the problem is considered of adapting the approach to in- teger and categorical variables, both ordered as well as unordered. The interest on such a kind of extension has been greatly stimulated by the application of GO to hyperparameter calibration in machine learning, where, e.g., in a neural network, one might wish to calibrate the num- ber of neurons, of layers, of filters on a convolution, which are integer‚Äì valued parameters. Otherwise hyperparametrs can be associated, e.g., to the activation function at a neuron, or to the loss function, or to the kernel function used in a Support Vector Machine; each of these can be seen as an example of categorical unordered parameter. The field has seen much expansion and interest in the scientific community and pa- pers started to appear describing novel software implementations, like, e.g., Kandasamy et al. (2020); Martinez-Cantin (2014).
We conclude this subsection by citing Kim (2020), a recent theo- retical paper which provides a rational explanation on how Bayesian Optimization algorithms proceed by alternating exploitation, or learn- ing, phases with exploration, or optimization. Exploitation is connected with a greedy cost optimization strategy, while exploration is associated to variance regularization. The whole process, analyzed in the context of Dynamic Programming, is analyzed and it is shown how the temporal discount factor of a Markov Decision Process plays the role of trade‚Äìoff parameter between exploration and exploitation.

Methods on the intersection between machine learning and GO

The title of this subsection refers to methods in which the search towards a global optimum, or, at least, a good local one, is guided by some form of ‚Äúlearning‚Äù, much in the spirit of modern machine learn- ing approaches. In this part we would like to include the re-discovery of clustering methods. These methods, as recalled in Section 2, were based on the idea of learning, from the sample, the shape of differ- ent basins of attractions of local optima, before starting expensive lo- cal searches. Clustering is one of the pillars of unsupervised learning and it might be of interest to look to those methods as early imple- mentations of machine learning tools for GO. In Bagattini et al. (2018, 2019) and, Schoen and Tigli (2021) we proposed different strategies in order to overcome the limitations of original clustering methods. In par- ticular, we showed that the idea of those algorithms can be successfully applied to much more refined algorithms than the standard Multistart,
by showing how a memetic Differential Evolution variant, inspired by Cabassi and Locatelli (2016), can profitably save a very large number of useless local searches while maintaining the quality of the original. Moreover, we showed how to use the same ideas with methods based on local search methods which are, in a sense, more refined and ‚Äúglobal‚Äù than standard, gradient-based, local optimization tools. Finally, some experiments on random projections enabled us to extend the approach to high dimensional problems.
It is worth noticing also that in the field of chemical physics many approaches are proposed in which GO methods (in particular, variations of basin hopping) are guided by knowledge on the prob- lem domain obtained through machine learning. As an example, in Meldgaard et al. (2018), low dimensional features are extracted from the original variables of atomic clustering problems and regression is used to assign an energy contribution to each atom in order to let GO algorithms focus on the parts of the current solution which contribute most to the objective function.
We conclude this section citing a paper which does not belong to the literature on algorithms but is quite relevant to the subject. The paper Kawaguchi (2016) deals with a conjecture on the absence of local optima which are not global when using a quadratic loss in training a deep neural network. The results proven there are interesting, as the problem is neither convex nor concave, yet it seems that training with a local optimization algorithm can always lead to a global optimum solution, thus partially explaining the success of local methods in training neural networks.

Exact GO methods

While in the previous section we discussed heuristic approaches, in this section we deal with exact GO methods. We will first discuss ‚Äùeasy‚Äù GO problems, i.e., GO problems which can be reformulated as (tractable) convex problems or, at least, can be solved in polynomial time with re- spect to the size of the problem data and the inverse of the required pre- cision (we refer, e.g., to Ben-Tal and Nemirovski (2001) for a detailed discussion about computational complexity in the context of continu- ous optimization problems and, in particular, in the context of convex optimization problems). Later on, we will discuss exact GO methods (ba- sically, branch-and-cut approaches) which are usually applied to ‚Äôhighly structured‚Äô GO problems. We will often refer to Quadratic Programming (QP) problems, which arise in many different contexts. Applications of QPs include the reformulation of some combinatorial optimization prob- lems, like, e.g., max-clique and max-cut, portfolio optimization, packing problems, blending and pooling problems. More applications of QPs can be found in Furini et al. (2019), where a QP library is introduced.

‚ÄúEasy‚Äù GO problems

Global optimization is, in general, a hard task. Even highly struc- tured GO problems, like, e.g., Standard Quadratic Programming (StQP), where a quadratic form is minimized over the unit simplex, have been proved to be NP-hard. All the same, there are some classes of GO prob- lems, in particular some QP problems, solvable in polynomial time. These include problems having the so called hidden-convexity property: though not convex, these problems can be reformulated as (tractable) convex problems. The best known of such problems is the trust region problem, where a quadratic function is minimized over the unit ball. It has been shown in Rendl and Wolkowicz (1997) that this problem admits a semidefinite reformulation. In fact, in Ben-Tal and den Her- tog (2014) it has been shown that the trust region problem and, ac- tually, a generalization where the unit ball constraint is replaced by a more generic quadratic constraint, can be reformulated as a sim- pler convex conic quadratic problem under the assumption that the Hessian matrices of the objective and constraint functions are simul- taneously diagonalizable. After transforming both the objective and the



tained by first introducing new variables ùë¶ùëñ and the related constraints constraint into separable functions, the conic quadratic problem is ob-
ùë¶ùëñ = ùë•2, and then relaxing these equalities into inequalities ùë•2 ‚â§ ùë¶ùëñ .
class of QCQPs which includes the diagonal ones, and it is shown that the condition implies the result proved in Burer and Ye (2020) when applied to diagonal QCQPs. In Jeyakumar and Li (2018) a class of min-

ùëñ	ùëñ

The work Jiang et al. (2018) proposes a Second Order Cone Program- ming (SOCP) reformulation for this problem without requiring the as- sumption of simultaneous diagonalization. The paper Wang and Kilin√ß- Karzan (2020) proposes a convex reformulation in the original space of variables. Further problems with the property of hidden-convexity have been introduced in the last two decades. In Pong and Wolkow- icz (2014) it is shown that, under suitable assumptions, a semidefinite relaxation for the problem of minimizing a quadratic function over a region defined by a two-sided quadratic constraint (i.e., a lower and upper bound are imposed over a quadratic function), is exact. For the same problem Jiang et al. (2018) presents a SOCP reformulation. The work Beck and Teboulle (2009) introduces a semidefinite reformulation for the problem of minimizing the ratio of two quadratic functions over a possibly degenerate ellipsoid. In Burer and Anstreicher (2013) and Sturm and Zhang (2003) it has been proven that problems with a quadratic objective function, a unit ball constraint and a single lin- ear cut can be reformulated as semidefinite problems with an addi- tional SOC-RLT (Second Order Cone - Reformulation Linearization Tech- nique) constraint. The result has been extended in Burer and Anstre- icher (2013) to the case of two parallel linear cuts and later on, in Burer and Yang (2015), generalized to the case of an arbitrary num- ber of linear constraints, provided that such constraints do not intersect in the interior of the unit ball. For problems with a quadratic objective function and two quadratic constraints, in Ye and Zhang (2003) it is proved that if all the quadratic functions are homogeneous (i.e., there are no linear terms), then an exact SDP relaxation exists.
Many papers in the literature provide conditions under which some
convex relaxation of a class of nonconvex problems turns out to be exact. For QCQP problems (problems where objective and constraint functions are all quadratic), the work Kim and Kojima (2003) provides some sign conditions about the data under which SDP and SOCP relax- ations are exact. The paper Sojoudi and Lavaei (2014) considers QCQP
problems without linear terms, i.e., with objective function ùë•‚ä§ùê¥0ùë• and
constraints ùë•‚ä§ùê¥ùëòùë• ‚â§ 0, ùëò = 1, ‚Ä¶ , ùëö (but it also discusses a way to in-
clude also linear terms). For these problems a graph Óà≥ is built with
ùëõ nodes (one for each variable) and an edge (ùëñ, ùëó) exists if and only if
ùê¥ùëò ‚â† 0 for some ùëò ‚àà {0, 1, ‚Ä¶ , ùëö}. Next, exactness of SDP and SOCP re-
graph. For instance, exactness holds if for each edge (ùëñ, ùëó) all entries ùê¥ùëò , laxations are related to some sign conditions and to the structure of this
ùëò ‚àà {0, 1, ‚Ä¶ , ùëö}, have the same sign, and graph Óà≥ is acyclic. The paper
Jeyakumar and Li (2014) considers the problem of minimizing quadratic
functions over a feasible region defined by a ball constraint and lin- ear constraints. A so called dimension condition is introduced under which the SDP relaxation turns out to be exact. Following Ben-Tal and den Hertog (2014), in Locatelli (2015b, 2016a) a simpler convex conic quadratic relaxation is considered and in Locatelli (2016a) it is shown that such relaxation is equivalent to the SDP one. Then, a condition for exactness of the relaxation more general than the dimension condition is derived from the KKT conditions of the convex conic quadratic relax- ation. The paper Ho-Nguyen and Kilin√ß-Karzan (2017) considers a SOCP relaxation in the original space of variables for problems with quadratic
objective function, a unit ball constraint and constraints ùê¥ùë• ‚àí ùëè ‚àà G,
where ùê¥ ‚àà ‚Ñùùëö√óùëõ, ùëè ‚àà ‚Ñùùëö, and G ‚äÇ ‚Ñùùëö is a closed convex cone. The pa-
given the epigraph of the problem, with the additional variable ùë° and the per introduces conditions under which the relaxation is tight. Moreover, additional constraint ‚Ñé(ùë•) ‚â§ ùë°, where ‚Ñé is the objective function, condi-
tions are provided for the derivation of its convex hull. In Burer and Ye (2020) diagonal QCQPs are considered, where all the Hessian ma- trices of the quadratic functions are diagonal. In this case the work provides some conditions related to the feasibility of suitably defined polyhedral sets, which guarantee the existence of rank-one solutions of the SDP relaxations and, thus, exactness of the relaxation. The work Wang and Kilin√ß-Karzan (2021) presents an exactness condition for a
imax QCQPs is addressed (the objective is the maximum of a finite set of quadratic functions). A SOCP reformulation of the Lagrangian dual is presented. Exactness of this SOCP problem is proved when the epi- graphical set (the epigraph of all the quadratic functions involved in the objective and in the constraints) is closed and convex. The Celis‚Äì Dennis‚ÄìTapia (CDT) problem, where a quadratic function is minimized over the intersection of two ellipsoids, has been investigated in some works. For instance, Ai and Zhang (2009) gives a necessary and suf- ficient condition for the exactness of the Lagrangian relaxation for this problem. Different papers investigate the possibility of narrowing (or closing) the duality gap by adding SOC-RLT constraints Burer and Anstreicher (2013), by solving two subproblems with SOC constraints Yuan et al. (2017), by adding lifted RLT cuts Yang and Burer (2016), by adding KSOC cuts Anstreicher (2017) (we refer to Section 4.2.4 for a discussion of all these cuts). It is also worthwhile to mention the re- sult in Yang et al. (2018) stating that the addition to QCQPs of further reverse convex constraints, imposing that feasible points cannot lie in the interior of non-intersecting ellipsoids, does not lead to more diÔ¨Écult problems. More precisely, the existence of a tight SDP relaxation for the problem without such constraints implies the existence of a tight SDP relaxation also for the problem with these constraints.
For some problems exact convex reformulations are not known but
still the problem can be solved in polynomial time. The polynomial methods usually enumerate all the (polynomially bounded) KKT points for these problems. An example of such enumerative methods is pro- posed in Bienstock and Michalka (2014b) for problems with a quadratic objective function, some ball constraints, some reverse ball constraints (i.e., constraints which impose that points cannot lie in the interior of a ball), and some linear constraints. The method runs in polynomial time provided that the number of ball and reverse ball constraints is fixed, and that the number of faces of the polyhedron defined by the set of lin- ear inequalities having a nonempty intersection with the set defined by the ball constraints is polynomially bounded. The papers Consolini and Locatelli (2017) and Sakaue et al. (2016) provide a polynomial-time method to solve a generalization of the CDT problem, where one of the two quadratic constraints is allowed to be nonconvex. The proposed
variate polynomial system with polynomials of degree at most 2ùëõ and method identifies all the KKT points of the problem by solving a bi-
with the two unknowns corresponding to the Lagrange multipliers of the two quadratic constraints. The algorithm has a polynomial com-
plexity but with a large exponent (six) with respect to the number ùëõ of
variables. Interestingly, a rather different polynomial-time approach for
this problem has been presented in Bienstock (2016). In this approach a sequence of feasibility problems for systems of quadratic inequalities is solved by a polynomial-time algorithm based on Barvinok‚Äôs construction Barvinok (1993). The algorithm is hard to implement but the approach can also be extended to any fixed number of quadratic constraints, pro- vided that one of them is strictly convex.
We conclude this section by mentioning problems for which a polynomial-time solution algorithm is not available but for which polynomial-time approximation schemes are available. In Bomze and de Klerk (2002) a Polynomial Time Approximation Scheme (PTAS) is introduced for the StQP problem. The PTAS is based on the evaluation of the objective function over a uniform grid. In de Klerk et al. (2006),
degree ùëë over the unit simplex. In Depetrini and Locatelli (2011) a Fully the result has been extended to the minimization of polynomials of fixed
Polynomial Time Approximation Scheme (FPTAS) has been proposed for Linear Fractional-Multiplicative Programming problems, where sums or products of a fixed number of ratios of aÔ¨Éne functions are minimized over polytopes. The FPTAS is based on the solution of LP problems over a nonuniform grid. The approach has also been extended to a more general class of problems in Locatelli (2013) and Mittel and Schulz (2013).



Exact methods for ‚Äúdifficult‚Äù GO problems

Branch-and-Cut (B&C) methods are most widely employed for the exact solution of GO problems. In what follows we briefly sketch how they work. A collection C of subsets of the feasible region is maintained throughout the algorithm. The collection is initialized with a single set corresponding to the whole feasible region. Then, during the execution of the algorithm the problem is subdivided into subproblems by branch- ing operations. Each branching operation replaces a subset in C by other subsets which cover it. For each subproblem a relaxation, often a con- vex relaxation, is defined whose solution gives a lower bound for the subproblem. The relaxation can be strengthened through the introduc- tion of cutting planes, which are guaranteed not to remove feasible or, at least, optimal solutions. A global upper bound is possibly updated each time a feasible point is detected, e.g., as a result of the solution of the convex relaxation. Fathoming rules are applied, and, in particular, all subproblems in the collection C whose lower bound is not lower than
the current upper bound (possibly decreased by a tolerance value ùúÄ) are
removed from the collection C. The algorithm stops as soon as the col-
lection C is empty. In some cases, a further collection g is maintained. Such collection contains all subsets over which the lower bound is not higher than the current upper bound. Then, when the algorithm stops (i.e., when the collection C is empty), the subsets in the collection g
the optimal value by at most the tolerance value ùúÄ. The theoretical is- contain all feasible solutions whose objective function value differ from
sue of the finiteness of B&C methods has been widely investigated in the past and for this we refer to GO textbooks like Horst and Parda- los (1995), Horst et al. (2001) and Horst and Tuy (1993). In what follows we discuss the most recent developments related to the main operations of B&C approaches emphasized above. Note that we are not going to discuss operations like upper bounding and fathoming since these are rather standard operations for which significant developments cannot be expected. For what concerns fathoming we only observe that, be- sides the standard rule based on the comparison between lower and upper bounds, in some cases it is possible to introduce fathoming rules based on optimality conditions. In particular, one can remove subsets from C for which it is possible to guarantee that they do not contain points fulfilling necessary optimality conditions.

Branching
Branching operations can be subdivided into two broad classes, spa- tial branching and KKT branching. Spatial branching can be applied to generic GO problems. The feasible region of the GO problem is initially enclosed into a region with a simple geometrical form. Then, branch- ing is performed by subdividing this region into smaller regions, often, but not necessarily, with the same geometrical form. The intersections of these smaller regions with the original feasible set give rise to the subsets entering the collection C. The most common geometrical form is a box, since lower and upper bounds for the variables are often already part of the GO problem description or, alternatively, can be easily computed by solving auxiliary problems. But other geometrical forms have been adopted in the literature. For instance, simplices and polyhedral cones have been often employed, see again the textbooks (Horst and Pardalos, 1995; Horst et al., 2001; Horst and Tuy, 1993). Note that in all these cases (boxes, simplices, polyhedral cones) the branching operation sub- divides a subset into smaller subsets, whose interiors do not overlap, but which can share some common face. Some papers (Cartis et al., 2015; de Angelis et al., 2004; Fowkes et al., 2013; Hager and Phan, 2009; Le Thi, 2000) employ ellipsoids, exploiting the fact that quadratic func- tions and also some cubic functions can be eÔ¨Éciently minimized over these sets. In this case the subsets generated by a branching operation may have overlapping interiors. We also mention T√≥th et al. (2016), where a subdivision into regular simplices is proposed, which also leads to subsets with overlapping interiors.
For some specific problems further geometrical forms have been con- sidered. For QCQP problems, Linderoth (2005) employs cartesian prod-
ucts of rectangles and right-angled triangles. For linear sum-of-ratios problems in Kuno (2005) cartesian products of trapezoids are used, while for the same problem Locatelli (2015a) employs cartesian prod- ucts of rectangles and right-angled triangles as in Linderoth (2005). The use of these geometrical forms is strictly related to the development of tight under- and over-estimators for bilinear and bivariate fractional functions over the two-dimensional regions appearing in the cartesian products, i.e., rectangles, right-angled triangles and trapezoids.
The subdivision can be performed either in a problem-independent or in a problem-dependent way. In the former a subregion is subdivided into subregions of equal size. The most common problem-independent subdivision is bisection, where the subregion, say a box, is split into two subregions through a subdivision of the longest edge performed at its midpoint (for ellipsoids the longest edge is replaced by the longest axis). Instead, problem-dependent subdivisions take the solution of the convex relaxation into account. If the objective function is underestimated by a convex function, the subdivision is performed in such a way that the error at the optimal solution of the convex relaxation, i.e., the difference between the objective function and the convex underestimating function evaluated at such optimal solution, is reduced as much as possible in the newly generated subregions. Note that it is important to reduce the error at the optimal solution of the convex relaxation, since the value of the convex underestimating function at this point is equal to the lower bound computed over the subregion. Then, reducing the error usually means improving (increasing) the lower bound of the newly generated subregions with respect to the lower bound over the original subregion. KKT branching has a more limited applicability with respect to spa- tial branching. It is employed for QP problems with linear constraints. In particular, for Box QP problems (problems with a quadratic objec- tive function and box constraints) in Vandenbussche and Nemhauser (2005a,b) it is observed that these problems can be reformulated by re- placing the original feasible region with the one defined by the KKT conditions. This requires the addition of the variables corresponding to the Lagrange multipliers of the box constraints, while the original quadratic objective function can be replaced by a linear one, involv- ing also the additional variables. The only nonconvex constraints of the reformulation are those corresponding to the complementarity condi- tions. These are initially omitted, while KKT branching first selects a constraint according to some rule (usually the one with the largest vi- olation of the complementarity condition at the solution of the convex relaxation), and then splits the current subregion into two new subre- gions by imposing that in one subregion the constraint is active, while in the other the corresponding Lagrange multiplier is set equal to 0. The work Burer and Vandenbussche (2008) extends the approach to feasi- ble regions which are general polytopes. While the idea is the same, the simple approach of omitting the complementarity conditions in order to get a convex (linear) relaxation does not work in the general case since it leads to a trivial bound. Therefore, in Burer and Vandenbuss- che (2008) an SDP relaxation is introduced. A different SDP relaxation has been proposed in Burer and Vandenbussche (2009) for Box QP prob- lems with further developments in Chen and Burer (2012), which reports very good computational results for problems with a dense Hessian ma- trix. KKT branching is also employed in Audet et al. (1999) for a special QP case, the case of disjoint bilinear programming. It is also worthwhile to point out here that the reformulation of QP problems based on KKT conditions has also been used to convert the solution of these problems into the solution of Mixed Integer Linear Programming (MILP) prob- lems, where additional binary variables are used to establish whether a constraint is active or, alternatively, its Lagrange multiplier is equal to zero (see, e.g., Xia et al. (2020) where good results, especially for StQP
problems, are reported).

Convex underestimating functions
Convex underestimating functions or, analogously, concave overesti- mating functions, are essential for the definition of convex relaxations. The ability of detecting them and evaluating their tightness, i.e., how



close they are to the original function, strictly depends on the proper- ties of the original function and on the region over which the underesti- mation takes place. For some functions and regions of relatively simple
by inequalities where the left-hand side is imposed to be not lower than the convex envelope (over a suitable rectangle or interval) of the right- hand side, and not larger than its concave envelope. A simple example

form it is possible to compute the tightest convex underestimator, also
of factorable function is the sum of bilinear terms ‚àëùëõ
ùê¥ùëñùëó
ùë•ùëñ ùë•ùëó . A

known as convex envelope. More formally, given a function ùëì and a re-
gion ùëã, the convex envelope of ùëì over ùëã is defined as follows for each
ùë• ‚àà ùëã:
ùëêùëúùëõùë£ùëì,ùëã (ùë•) = sup{ùëê(ùë•) ‚à∂ ùëì (ùë¶) ‚â• ùëê(ùë¶), ‚àÄùë¶ ‚àà ùëã,  ùëê is convex},
i.e., ùëêùëúùëõùë£ùëì,ùëã is the largest convex underestimator of ùëì over ùëã (note that in the above definition ‚Äôùëê is convex‚Äô can be replaced with ‚Äôùëê is
aÔ¨Éne‚Äô). Analogously, we can define concave envelopes, i.e., tightest
vex envelopes, since the concave envelope of ùëì over ùëã can easily be concave overestimators. In what follows we will always refer to con- seen to be the opposite of the convex envelope of ‚àíùëì over ùëã. Besides
some results for specific functions, the best known of which is probably McCormick convex envelope for bilinear terms over rectangles, some
mostly related to so called polyhedral convex envelopes. A function ùëì general results appeared in the literature. The first general results were admits a polyhedral convex envelope over a region ùëã if its convex en-
ular, if ùëã is a polytope, a function ùëì is said to admit a vertex polyhedral velope is the maximum of a finite number of aÔ¨Éne functions. In partic-
lope of the same function over the vertex set of ùëã. In fact, according to convex envelope if its convex envelope is equal to the convex enve-
convex envelopes for continuously differentiable functions ùëì . The condi- Rikun (1997) polyhedral convex envelopes are always vertex polyhedral
of ùëã) guarantees the existence of a vertex polyhedral convex envelope tion of edge-concavity (concavity along each segment parallel to an edge
(Meyer and Floudas, 2005a; Tardella, 2003; 2008). For instance, multi- linear functions always admit vertex polyhedral convex envelopes over
are strictly related to triangulations of the polytope ùëã with a number boxes. In Meyer and Floudas (2005a) it is shown that these envelopes of simplices which can be very large (e.g., of size ùëõ! for ùëõ-dimensional
except for some special cases. In particular, when ùëã is the unit box and boxes). Identification of the triangulation may be a rather diÔ¨Écult task,
ùëì is submodular over the vertex set of ùëã, the convex envelope is the Lov√°sz extension of ùëì (see Tawarmalani et al., 2013). Recently, differ-
Most of them require that ùëã is a box, while ùëì is required to satisfy differ- ent results about non-polyhedral convex envelopes have been presented. ent assumptions. In Tawarmalani and Sahinidis (2001) ùëì is assumed to
ing ùëõ ‚àí 1 variables are fixed. In Jach et al. (2008) the Hessian of ùëì is be convex if we fix the value of one variable and concave if the remain- assumed to have at least one negative eigenvalue over the box and ùëì is
(2012, 2013) ùëì is a product function ‚Ñé(ùê≥)ùëî(ùê≤), where ‚Ñé and ùëî must fulfill convex if the value of one variable is fixed. In Khajavirad and Sahinidis some conditions (e.g., ‚Ñé must be nonnegative and convex and with some specific form, ùëî must be nonnegative and component-wise concave). In Ballerstein and Michaels (2014) and Locatelli (2016b) ùëì is required to be (strictly) convex if we fix the values of ùëõ ‚àí 1 variables, while if we
is attained at a vertex of the corresponding (ùëõ ‚àí 1)-dimensional box. In fix the value of the remaining variable, the minimum of the function all the above works, the required properties for ùëì imply that the con- vex envelope of ùëì over the box is equivalent to the convex envelope
of the same function over the border of the box. In Locatelli (2020) a case where this does not hold has been discussed, namely the convex envelope of bivariate cubic functions over rectangles.
The convex (and concave) envelopes of some functions of relatively simple form (usually, univariate or bivariate functions) can also be em- ployed to underestimate and/or overestimate functions with a more complicated form. This is the case for factorable functions, i.e., functions which can be progressively decomposed into the sum and product of simple univariate and bivariate functions, for which convex and concave envelopes are available (see, e.g., Khajavirad et al., 2014; Scott et al., 2011; Tawarmalani and Sahinidis, 2004). For instance, given the fac-
torable function ùëíùë•1 ùë•2 ùë•3 , we first introduce the new variables ùë•4 = ùë•1 ùë•2 ,
ùë•5 = ùëíùë•4 , and ùë•6 = ùë•5 ùë•3 , and then these equality constraints are replaced
possible convex underestimator (concave overestimator) for this func- tion over the unit hypercube can be obtained by summing McCormick‚Äôs convex envelope (McCormick‚Äôs concave envelope) of each single bi- linear term over the unit square. Unfortunately, the convex underes- timator is not the convex envelope of the overall sum (in general, the convex envelope of a sum is not the sum of the convex envelopes of the single terms of the sum). Similarly, for the concave overestimator. However, there are some results which bound the difference between the concave overestimator and the convex underestimator. In particu- lar, in Luedtke et al. (2012) it is shown that such difference cannot be larger than the difference between the concave and the convex enve-
lope over the unit hypercube times a ùëÇ(ùëõ) constant, while in Boland
et ‚àöal. (2017) the order of magnitude of the constant has been refined to
ùëÇ(  ùëõ).
For a poorly structured function ùëì the best known approach for un- derestimating ùëì is the one proposed within the framework of the ùõº-BB approach (see Adjiman et al. (1998a, 1996, 1998b)). In this case, ùëì is
function ùëû is introduced such that the Hessian of ùëì ‚àí ùëû is semidefinite only assumed to be twice-continuously differentiable and a nonnegative positive over a box ùëã or, stated in another way, ùëì ‚àí ùëû is a convex un- derestimator of ùëì over ùëã. In the original ùõº-BB approach ùëû was defined
as
‚àëùëõ
ùëû(ùë•) =	ùõºùëñ (ùë•ùëñ ‚àí ùìÅùëñ )(ùë¢ùëñ ‚àí ùë•ùëñ ),
ùëñ=1
where ùìÅùëñ , ùë¢ùëñ are, respectively, the lower and upper bound for variable
ùë•ùëñ within the box ùëã, while the values ùõºùëñ are suitably chosen in or- der to guarantee convexity of ùëì ‚àí ùëû over ùëã. Later on, different func- tions ùëû have been proposed in the literature, like, e.g., spline functions Meyer and Floudas (2005b), obtained by first subdividing the box ùëã into smaller sub-boxes and then computing different (and sharper) ùõº val-
ues over these sub-boxes, or exponential functions (Akrotirianakis and Floudas, 2004). In the recent work Kazazakis and Adjiman (2018) a fur- ther variant has been proposed, where the original function is replaced
by a so called ùúá-subenergy function, with the property that its eigen-
values have a smaller magnitude with respect to those of the original
to  choose  tighter  ùõº  values  in  those  regions. function in the regions far away from global minimizers, thus allowing
For poorly structured GO problems we should also mention meth- ods based on interval arithmetic. These are rigorous methods, i.e., they guarantee the detection of a solution within a prescribed tolerance even in the presence of rounding errors. The overall number of contributions in this field in the last two decades is relatively limited, but there are some interesting works. We first mention the two surveys (Araya and Reyes, 2016; Neumaier, 2004), to which we refer for a more detailed discussion about the topic. In some works first and second order infor- mation are employed both to define linear and quadratic underestimat- ing functions and to fathom (or shrink) boxes which are guaranteed not to include points satisfying first and second order necessary optimality conditions (see, e.g., Hansen et al., 2007; Markot and Schichl, 2014;
Martinez et al., 2004). Note that the original ùõº-BB approach exploits
second order information to derive a convex quadratic underestimating
function. In Borradaile and Van Hentenryck (2005), Kearfott (2011) and Neumaier and Shcherbina (2004) safe linear underestimators are dis- cussed. These are linear relaxations which take into account numeri- cal errors in the computation of the coeÔ¨Écients of the linear functions. The paper Berenguel et al. (2013) presents ways to take into account separability of the objective function. In Carrizosa et al. (2004) it is shown that simple translations of the variables allow to derive bet- ter inclusion functions through interval arithmetic. A discussion about different branching rules for the subdivision of a box into sub-boxes can be found in Csallner et al. (2000) and Mark√≥t et al. (2006). In



Jansson et al. (2007) interval arithmetic is applied to compute rigor- ous error bounds for the optimal value of semidefinite programs. In Domes and Neumaier (2016) it is shown that the information extracted from local optimization, namely the approximated local optimizer as well as the corresponding Lagrange multipliers, can be exploited to form an aggregated redundant constraint which turns out to be power- ful in order to tight the bounds on the variables (see also the following Section 4.2.5). The authors also remark that such aggregate constraints are able to reduce the so called cluster eÔ¨Äect, i.e., the presence of a large cluster of unfathomed small boxes in the regions around the global min- imizer, which is a serious obstacle to the eÔ¨Éciency of B&C approaches. We also mention the successful application of an interval method to the circle packing problem (see Mark√≥t and Csendes, 2005).
We conclude this section by observing that up to now we have talked
about convex underestimators. However, as discussed in Section 4.1, there are some nonconvex problems which can be solved eÔ¨Éciently. So, in some cases nonconvex underestimators can be employed. For in- stance, in Cartis et al. (2015) and Fowkes et al. (2013) the objective function is underestimated by quadratic and cubic functions, whose min- imizers can be eÔ¨Éciently computed over spheres, which are the regions generated by the branching operation adopted in those works. If the branching operation generates polyhedral sets with a limited number of vertices, then concave underestimators can be employed. Indeed, the minimum value of a concave function over a polytope is attained at a vertex of the polytope. This is done, e.g., in the context of Lipschitz op- timization (see, for instance, Hendrix and T√≥th, 2010; PaulavicÀòius and ZiÀòlinskas, 2014), where a concave lower bounding function based on the Lipschitz condition is minimized over a simple polyhedral region (in particular, a simplex).

Problem reformulations and convex relaxations
For some nonconvex problems a convex relaxation can be derived by first reformulating the problem, usually with the addition of new vari- ables, and then removing or relaxing the nonconvex constraints of the
QCQPs, where the additional matrix variable ùëã and the equality con- reformulation. A typical example is the well known Shor relaxation for
straint ùëã = ùë•ùë•‚ä§ are introduced. This way, each quadratic form ùë•‚ä§ùëÑùë•
successors. The predecessors are copositive reformulations for some sub- classes of QP problems. In particular, the first of such results is a copos- itive reformulation of StQP problems presented in Bomze et al. (2000). In the successors of Burer (2009), completely positive and copositive reformulations have been extended to other classes of optimization problems. In fact, in Burer (2009) itself the result is extended also to cases where some quadratic equality constraints appear. In Burer and Dong (2012) it is shown that QCQPs can be reformulated as general- ized copositive programs, i.e., problems defined over the generalized
completely positive cone, where the requirement ùë•ùëò ‚àà ‚Ñùùëõ , ‚àÄùëò ‚àà ùêæ, is
replaced by ùë•ùëò ‚àà G, ‚àÄùëò ‚àà ùêæ, where G is a convex cone. The paper
Amaral et al. (2014) reformulates the problems of minimizing the ratio
of two quadratic functions over a polyhedral region as problems over the cones of completely positive matrices and of copositive matrices. In
problems whose variables are constrained to belong to G ‚à© n, where Bai et al. (2016) it is shown that, under suitable assumptions, QCQP
G is a convex cone and n is a region defined by linear equality con- straints, can be reformulated as problems over the cone of completely positive matrices. In Bomze et al. (2017) it is shown that, besides the one presented in Burer (2009), other equivalent completely positive re- formulations for mixed-binary QPs are possible. The interest of these equivalent reformulations lies in the fact that, once the completely pos- itive cone is relaxed into a tractable one, the new reformulations may lead to tighter bounds. In Bomze et al. (2018) it is shown that for QP problems with quadratic objective function, two quadratic constraints and some further linear constraints, under suitable assumptions a copos- itive reformulation exists. For some problems, a completely positive re- formulation is not available but still they admit completely positive re- laxations. In Bomze (2015) it is proved that for QCQPs bounds returned by completely positive relaxations dominate Lagrangian dual bounds. This result has been extended to polynomial programming problems in Kuang and Zuluaga (2018) after the introduction of completely positive tensors.
Unfortunately, though convex, the cones of copositive and com-
pletely positive matrices are not tractable, i.e., problems over these cones cannot be solved in polynomial time by interior point methods because the computation of their self-concordant barrier functions can-

can be replaced by the linear term ùëÑ ‚àô ùëã = ‚àëùëõ
ùëÑùëñùëó
ùëãùëñùëó
. Nonconvex-
not be performed in polynomial time. All the same, reformulations over the completely positive or copositive cone allow to define polynomi-

ity only lies in the rank-one constraint ùëã = ùë•ùë•‚ä§. A convex relaxation is
straint ùëã ‚™∞ ùë•ùë•ùëá , i.e., it is required that the matrix ùëã ‚àí ùë•ùë•‚ä§ is positive obtained by replacing the equality constraint with the semidefinite con-
semidefinite. The resulting SDP bound has a good quality but is costly. Conversely, SOCP relaxations, obtained by replacing quadratic functions with convex quadratic underestimating functions, have a poorer qual- ity but are faster to compute. For this reason in Burer et al. (2014) it is proposed to construct mixed SOCP-SDP relaxations which allow for a balance between the quality of the bound and the time needed to com- pute it.
The work Burer (2009) introduces an exact reformulation for QP problems with quadratic objective function and linear constraints, pos-
vex  cone  of  ùëõ  √ó  ùëõ  completely  positive  matrices sibly with some binary variables. The reformulation is based on the con-
C‚àó = {ùëã ‚àà ‚Ñùùëõ√óùëõ ‚à∂ ùëã = ‚àë ùë• ùë•‚ä§, |ùêæ| has finite cardinality, ùë• ‚àà ‚Ñùùëõ ,
ally solvable convex relaxations by replacing these cones with tractable
matrices are tractable and they outer approximate C‚àó and, being self- cones. The cone of nonnegative matrices and the cone of semidefinite dual, they inner approximate Cùëõ . The intersection of these two cones
is the cone of doubly nonnegative matrices, which inner approximates
Cùëõ (in fact, equality holds for ùëõ < 5), while its dual cone, i.e., the cone
ative and a semidefinite matrix, outer approximates C‚àó. Different hi- made up by matrices which can be obtained by summing a nonneg- erarchies of cones {Gùëü } have been proposed in the literature such that
‚àÄùëü ‚à∂ Gùëü ‚äÉ Gùëü+1 ‚äÉ C‚àó, i.e., the cones are finer and finer outer approxima-
tions of the completely positive cone and, conversely, their dual cones are finer and finer inner approximations of Cùëõ (see de Klerk and Pasech- nik, 2002; Parrillo, 2000; Pe√±a et al., 2007). Although the bounds based
on these hierarchies tend to become sharper as ùëü increases, the main
drawback is that the size of these problems tends to increase rapidly

ùëõ
‚àÄùëò ‚àà ùêæ},
ùëò‚ààùêæ
ùëò ùëò
ùëò	+
with ùëü, since they involve ùëõùëü+1 √ó ùëõùëü+1 matrices or a comparable number of ùëõ √ó ùëõ matrices. Thus, from the computational point of view only the use of small values for ùëü is feasible. In Bundfuss and Duer (2009), after

and its dual cone, the dual cone of copositive matrices:
observing that a matrix ùê¥ is copositive if and only if ùë•‚ä§ùê¥ùë• ‚â• 0 for all

Cùëõ
= {ùëã ‚àà ‚Ñùùëõ√óùëõ ‚à∂ ùë•‚ä§ùëãùë• ‚â• 0 ‚àÄùë• ‚àà ‚Ñùùëõ }.
ùë• ‚àà Œîùëõ, where Œîùëõ is the ùëõ-dimensional unit simplex (see also T√≥th et al.,
2021), polyhedral inner and outer approximations of the copositive

In Burer (2009) it is proved that, under mild assumptions, any QP prob- lem with linear constraints and, possibly, some binary variables, can be reformulated as a problem over the convex cone of completely positive matrices (we refer, e.g., to the survey paper Bomze et al. (2012) for a discussion about problems over this cone and over the dual cone of copositive matrices). This result has some predecessors and different
cone are proposed, based on simplicial subdivisions of the unit sim- plex. It is shown that, under suitable assumptions, bounds computed by replacing the copositive cone with these approximations tend to con- verge to the optimal value of the copositive problem, provided that the length of the largest edge of the simplices in the partition converges to 0.



In order to strengthen the bound obtained by replacing C‚àó with a tractable cone, we may also proceed as follows. Let ùëã‚ãÜ be the opti-
mal solution obtained by solving the relaxation over the tractable cone
G ‚äÉ C‚àó. Then, either ùëã‚ãÜ ‚àà C‚àó or ùëã‚ãÜ ‚àà G ‚ßµ C‚àó. In the former case ùëã‚ãÜ is
ùë•ùëñ of the problem. Again for Box QP, in Burer and Letchford (2009) first the objective function is linearized with the addition of the variables ùëãùëñùëó and the related constraints ùëãùëñùëó = ùë•ùëñ ùë•ùëó , and then the convex hull of the
set

ùëõ	ùëõ	ùëõ

also an optimal solution of the completely positive problem. Otherwise,	{
ùëõ+ùëõ(ùëõ+1)‚àï2	}

by definition of dual cone, there exists some ùê∂ ‚àà Cùëõ such that ùê∂ ‚àô ùëã‚ãÜ < 0.
(ùë•, ùëã) ‚àà [0, 1]
‚à∂ ùëãùëñùëó = ùë•ùëñ ùë•ùëó , 1 ‚â§ ùëñ ‚â§ ùëó ‚â§ ùëõ ,

Thus, adding the inequality ùê∂ ‚àô ùëã ‚â• 0 to the previous relaxation, we are
able to strengthen the previously computed bound. In other words, a
separation problem is solved. Such an approach has been explored in
is analyzed. Many facet-inducing inequalities for this set are de- rived from valid inequalities for the Boolean quadric polytope (see Padberg (1989)):

Burer and Dong (2013) and also in Bomze et al. (2010) for what con- cerns the completely positive reformulation of the max-clique problem.
{
(ùë•, ùëã) ‚àà {0, 1}
ùëõ+ùëõ(ùëõ‚àí1)‚àï2
}
ùëñùëó	ùëñ ùëó	‚â§ ùëñ < ùëó ‚â§ ùëõ .

Note that this topic would also fit into the following Section 4.2.4 about cutting planes.
Reformulations and relaxations have also been proposed for poly-
nomial programming problems. The unconstrained minimization of a
For QP problems or, more generally, for polynomial programming prob- lems, a convex relaxation can be strengthened by the Reformulation- Linearization Technique (RLT), introduced in Sherali and Tunc-
bilek (1992). If the linear constraints ùëé‚ä§ùë• ‚â• ùëè1 and ùëé‚ä§ùë• ‚â• ùëè2 are present,

1	2

polynomial ùëì with degree ùëë can easily be reformulated as:
then first the additional quadratic constraint (ùëé‚ä§ùë• ‚àí ùëè1 )(ùëé‚ä§ùë• ‚àí ùëè2 ) ‚â• 0,

1	2

sup	ùõº
ùëì (ùë•) ‚àí ùõº ‚àà gùëõ,ùëë ,
is linearized by replacing the terms ùë•ùëñ ùë•ùëó with the additional variables implied by the two linear constraints, is added, and then this constraint
ùëãùëñùëó . A typical example are the RLT constraints obtained by multiplying

where g
ùëõ,ùëë
is the set of nonnegative polynomials of degree at most
the box constraints 0 ‚â§ ùë•ùëñ , ùë•ùëó ‚â§ 1:

ùëë. However, the set of nonnegative polynomials is not easily repre-
sentable. Therefore, a tractable relaxation can be obtained by replac-
most ùëë, i.e., polynomials which can be written as a sum of a finite num- ing it with the set of Sum-Of-Squares (SOS) polynomials of degree at ber of square of polynomials of degree at most ùëë . The nice feature of
SOS polynomials is that they are representable by a positive semidefi-
ùëãùëñùëó ‚â• 0, ùëãùëñùëó ‚â• ùë•ùëñ + ùë•ùëó ‚àí 1, ùëãùëñùëó ‚â§ ùë•ùëñ , ùëãùëñùëó ‚â§ ùë•ùëó ,
which also correspond to the classical McCormick envelopes. In
including both the semidefinite condition on the variable matrix ùëã Anstreicher (2009) it is shown that for Box QPs and some QCQPs,
and RLT constraints, leads to significatively better bounds than us-

nite condition imposed over matrices with dimension
ùëÇ(ùëõùëë‚àï2) In fact,
ing the semidefinite condition or the RLT constraints alone. The paper
Anstreicher and Burer (2010) derives convex hulls for quadratic forms

Papp and Yildiz (2019) discusses an alternative and cheaper way to rep- resent SOS polynomials. The bound based on the SOS relaxation (and its dual counterpart, the moment relaxation, see Lasserre, 2001) has been strengthened with the definition of hierarchies of bounds both for the unconstrained and the (polynomially) constrained case, which have been discussed in different papers such as, e.g., de Klerk et al. (2017a,b), Lasserre (2001, 2005, 2006), Laurent (2007), Nie (2013), Nie (2014),
Nie et al. (2006) and Vui and So‚Äôn (2008).

Outer approximation and cutting planes
When the feasible region ùëÜ is not convex, we need to outer approx-
The tightest convex outer approximation of ùëÜ is called convex hull of imate it with a convex region in order to derive a convex relaxation.
ùëÜ and is denoted by ùëê‚Ñéùë¢ùëôùëô(ùëÜ). One possibility to derive a convex outer approximation is to replace each constraint ùëî(ùë•) ‚â§ 0 defining ùëÜ, ùëî non- convex, with a constraint ùëê(ùë•) ‚â§ 0, where ùëê is a convex underestimator of ùëî over ùëÜ, so that all the material discussed in Section 4.2.2 could
be applied here. The tighter the convex underestimator, the tighter is the convex outer approximation. However, replacing each nonconvex
function ùëî with its convex envelope over a suitable region containing
ùëÜ leads to a convex outer approximation, but this is not necessarily
the convex hull. A simple example is the following. Given the region
ùëÜ = {(ùë•, ùë¶) ‚àà [1, 2] ‚à∂ ùë•ùë¶ ‚â• 3}, according to the previous discussion the
over small-dimensional regions (triangles and boxes) based on semidefi- nite and nonnegative conditions over matrices and, possibly, additional
defined  for  the  characterization  of  ùëê‚Ñéùë¢ùëôùëô(ùëÜ)  when RLT constraints. In Bienstock and Michalka (2014a) cutting planes are
ùëÜ = {(ùë•, ùëû) ‚àà ‚Ñùùëë √ó ùëÖ ‚à∂ ùëû ‚â• ùëÑ(ùë•), ùë• ‚àà ‚Ñùùëõ ‚ßµ ùëñùëõùë°(ùëÉ )},
where ùëÑ is convex and differentiable and ùëñùëõùë°(ùëÉ ) denotes the interior of set ùëÉ . A polynomial separation algorithm is proposed for the case when ùëÑ is quadratic and strictly convex, while ùëÉ is a polyhedron or
an ellipsoid. The work Burer and Kilin√ß-Karzan (2017) derives convex relaxations and, under suitable assumptions, even convex hulls for the intersection of the following sets:
a SOC representable cone G, i.e., given a matrix ùêµ ‚àà ‚Ñùùëõ√ó(ùëõ‚àí1) and
ùëè ‚àà ‚Ñùùëõ, G = {ùë• ‚à∂ ‚Äñùêµ‚ä§ùë•‚Äñ ‚â§ ùëè‚ä§ùë•};
a cone g defined by a homogeneous quadratic function, i.e., g =
{ùë• ‚à∂ ùë•‚ä§ùê¥ùë• ‚â§ 0}, for some matrix ùê¥ ‚àà ‚Ñùùëõ√óùëõ;
an aÔ¨Éne hyperplane.

Based on the observation that ùê¥ ‚™∞ ùëÇ and ùêµ ‚™∞ ùëÇ implies ùê¥ ‚äó ùêµ ‚™∞ ùëÇ, where ‚äó denotes the Kronecker product, in Anstreicher (2017) so called Kronecker product constraints are introduced. Let ùêª (ùë•) ‚™∞ ùëÇ and ùê∫(ùë•) ‚™∞
ùëÇ be semidefinite constraints where single components of both matrices
are aÔ¨Éne functions of ùë•. Then, a Kronecker product constraint is ob-

nonconvex function ùë•ùë¶ should be replaced by its concave envelope over
[1, 2]2 , i.e., by min{ùë• + 2ùë¶ ‚àí 2, 2ùë• + ùë¶ ‚àí 2}. But the resulting convex re-
tained by replacing in ùêª (ùë•) ‚äó ùê∫(ùë•) ‚™∞ ùëÇ each term ùë•ùëñ ùë•ùëó
with ùëã
ùëñùëó
. These

gion {(ùë•, ùë¶) ‚àà [1, 2] ‚à∂ ùë• + 2ùë¶ ‚àí 2 ‚â• 3, 2ùë• + ùë¶ ‚àí 2 ‚â• 3} is not the convex hull of ùëÜ, since ùëÜ is already a convex set (just note that ùë•ùë¶ ‚â• 3 can be rewritten as ùë• ‚â• 3‚àïùë¶). More generally, in Anstreicher (2012) for QCQPs, with additional linear constraints defining a polytope ùëÉ , it is shown that replacing the quadratic terms with their convex envelopes over ùëÉ leads
the convex hull of the set {(1 ùë•)(1 ùë•)‚ä§, ùë• ‚àà ùëÉ } (note, however, that both to a convex relaxation which is dominated by the one obtained through
the convex envelope and the convex hull may be hard to compute).
Many results about convex hulls have been presented in the recent literature. The work Vandenbussche and Nemhauser (2005b), within the framework of a branch-and-bound approach for Box QP problems
constraints are generalization both of the classical RLT constraints ob- tained from two linear inequality constraints, and of the SOC-RLT con- straints obtained from one linear inequality constraint and a SOC con- straint. In Wang and Kilin√ß-Karzan (2021) for some QCQPs, conditions are given under which the convex hull of the epigraph of the QCQP is the projection of the epigraph of its Shor relaxation. In Del Pia and Kha- javirad (2017, 2018) in the context of binary polynomial problems, i.e., problems with a polynomial objective function, some binary variables and some other variables constrained to belong to the interval [0,1], valid inequalities are derived to characterize the convex hull of multi- linear sets:

based on KKT branching (see Section 4.2.1), considers convex hulls of the regions defined by the KKT conditions related to each single variable
ùëÜ =
{
(ùë•, ùë¶) ‚à∂ ùë¶ùêº
}
‚àè
=	ùë•ùëñ , ùêº ‚àà S, ùë• ‚àà {0, 1}ùëõ  ,
ùëñ‚ààùêº



where S is a collection of subsets of {1, ‚Ä¶ , ùëõ} with cardinality not lower
than two.
convex hulls for the intersection of cubes with regions {(ùë•, ùë¶, ùëß) ‚à∂ The paper (Nguyen et al., 2018) presents the (non polyhedral)
ùë•ùëè1 ùë¶ùëè2 ‚â• ùëß} and with regions {(ùë•, ùë¶, ùëß) ‚à∂ ùë•ùë¶ùëè2 ‚â§ ùëß} for ùëè1 , ùëè2 ‚â• 1. In
Davarnia et al. (2017) a description is given for the convex hull of sets
ùëÜ = {(ùë•, ùë¶, ùëß) ‚à∂ ùë• ‚àà [0, 1]ùëõ, ùê∏ùë• ‚â• ùëì, ùë¶ ‚àà ‚Ñùùëö, ùë¶ ‚â• 0, ùëí‚ä§ùë¶ ‚â§ 1,
ùëßùëò = ùë¶‚ä§ùê¥ùëò ùë•, ùëò = 1, ‚Ä¶ , ùêæ},
where ùê∏ ‚àà ‚Ñùùë°√óùëõ, ùëì ‚àà ‚Ñùùë°, ùëíùëö is the ùëö-dimensional vector with all compo- nents equal to one, ùê¥ùëò ‚àà ‚Ñùùëö√óùëõ. Then, ùë• belongs to a polyhedral subset of the unit box, ùë¶ belongs to the ùëö-dimensional unit simplex, while ùëß is obtained by bilinear terms involving ùë• and ùë¶. An application to net-
work interdiction problems is presented. In Bonami et al. (2019) some cutting planes to strengthen linear relaxations of QPs with linear con- straints are proposed. The cutting planes are based on a well known result by Motzkin and Straus (see Motzkin and Strauss (1965)) about max clique problems. For this reason, they are called Motzkin-Straus clique inequalities. The work Santana and Dey (2020) establishes that the convex hull of the intersection of the region defined by a quadratic equality constraint and a polytope is SOCP representable. In
Bienstock et al. (2020) valid inequalities are introduced for sets ùëÜ ‚à© ùëÉ ,
where ùëÜ is a closed set and ùëÉ is a polyhedron. A cutting plane algorithm
is proposed. Given an oracle returning the distance of some point from
ùëÜ, the algorithm generates cutting planes which are able to approximate
ùëê‚Ñéùë¢ùëôùëô(ùëÜ ‚à© ùëÉ ) in an arbitrarily precise way. An application to polynomial
vex hulls are given for subsets of ‚Ñù5, arising in pooling problems and programming is presented. In Luedtke et al. (2020) non polyhedral con-
defined by some linear constraints and a nonconvex bilinear constraint.

Bound tightening
Rather special cutting planes are those involving lower and upper bounds on single variables. Strengthening these bounds is also known
as bound tightening. Given a lower and upper bound ùìÅ and ùë¢ for vari-
ables ùë•, a bound tightening procedure can be viewed as a function re- ceiving the box [ùìÅ, ùë¢] in input and returning a box [ùìÅ‚Ä≤, ùë¢‚Ä≤] ‚äÜ [ùìÅ, ùë¢], such that [ùìÅ, ùë¢] ‚ßµ [ùìÅ‚Ä≤, ùë¢‚Ä≤] does not contain any feasible point (feasibility-based
bound tightening) or, more powerfully, does not contain any optimal so- lution (optimality-based bound tightening). The importance of bound- tightening is due to the fact that it does not only reduce the feasible re- gion of a convex relaxation, but it also improves the quality of (convex) underestimating functions for the objective and constraint functions. In- deed, in many cases the underestimating functions depend on the lower and upper limits for the variables and they tend to become tighter as these limits become tighter. The importance of bound-tightening for an eÔ¨Écient solution of nonconvex problems is proved by the fact that many
GO solvers (such as BARON Sahinidis (2017), BMIBNB Lofberg (2004),
COUENNE Belotti et al. (2006), SCIP Gamrath et al. (2020)) include
procedures to perform it.
A simple way to perform bound tightening is by minimizing and maximizing each variable over a convex relaxation of the feasible re- gion (feasibility-based bound tightening), or over the same relaxation with an additional constraint imposing that a convex underestimating function for the objective function is not larger than the current known upper bound (optimality-based bound tightening, since the additional constraint may remove feasible points but no optimal solution). Since, as previously commented, convex underestimating functions usually de- pend on variable bounds, once all bounds have been tightened, the new bounds improve the quality of the underestimating functions so that a further round of bound-tightening may allow to further reduce the bounds. This can be iteratively repeated until convergence. Such itera- tive procedure has been theoretically and computationally investigated in Caprara and Locatelli (2010) and Caprara et al. (2016). Note, how- ever, that such iterative procedure, while providing tight bounds, is quite expensive, requiring the solution of many convex subproblems.
In Gleixner et al. (2017) three techniques are introduced to keep the computational cost of these bound tightening techniques under control. The work Tawarmalani and Sahinidis (2004) presents a general theo- retical framework for bound-tightening techniques and discusses ways to exploit dual solutions of convex subproblems in order to perform the tightening. Constraint propagation techniques are also widely employed to tighten bounds. For factorable functions, first a directed acyclic graph (DAG) is built, where the nodes correspond to the variables (both the original variables and the additional variables introduced to model fac- torable functions), while the arcs represent the dependencies between the variables. Then, bound tightening is performed by forward and back- ward propagation along this graph. This technique is discussed in dif- ferent papers such as Belotti et al. (2009), Messine (2004), Schichl and Neumaier (2005), Vu et al. (2009) and Wechsung et al. (2015). In Puranik and Sahinidis (2017) it is observed that, in order to perform optimality-based bound tightening, besides the previously mentioned additional constraint involving a convex underestimating function of the objective, one could also add constraints imposing necessary opti- mality conditions or, more precisely, a convex relaxation of such con- ditions. This is also done in Zhang et al. (2020) where some topics are addressed such as how to bound the dual variables appearing in the optimality conditions, for which explicit bounds are not given.

Computational aspects, test problems and solvers

Most of the papers cited in this work report computational experi- ments on different sets of test problems and with different solvers. Dis- cussing in detail computational experiences, test functions and solvers is beyond the scope of the current work. However, we make a few ob- servations and, for the interested reader, we provide pointers to papers and web sites where these aspects are presented in more detail.

Computational aspects

Here we briefly discuss a couple of observations which are well known but should always be taken into account when evaluating and comparing different solution approaches.
The first observation is that we should never search for the ‚Äôbest‚Äô approach to solve GO problems. This is obviously true for the whole class of GO problems, since such wide class encompasses problems with fairly different properties and characteristics, which lead to fairly differ- ent approaches for their solution. But it is also true for much narrower subclasses of GO problems. In particular, we mention here a subclass of problems which attracted a lot of attention in the recent literature, namely the class of nonconvex QP problems with linear constraints. Well
known commercial software products like CPLEX and GUROBI have re-
cently introduced solvers for the solution of problems within this class. These QP problems can be tackled in many different ways. As already mentioned at the end of Section 4.2.1, in Xia et al. (2020) the problem is reformulated as a Mixed Integer Linear Program (MILP) after refor- mulating it with the inclusion of the KKT conditions. Binary variables are included to model the nonconvex complementarity conditions. In Chen and Burer (2012) the problem is still reformulated with the inclu- sion of KKT conditions and KKT branching is applied, but semidefinite relaxations are considered. In Bonami et al. (2018) a spatial branch-and- cut approach is proposed with the addition of valid cuts for the Boolean Quadric Polytope. In Liuzzi et al. (2021) another spatial branch-and- bound approach with intensive bound-tightening has been applied to a class of QP problems arising from an application in game theory.
The outcome of the computational experiments reported in all these works is that none of the proposed methods strictly dominates the oth- ers. The method proposed in Xia et al. (2020), as well as problem spe- cific ones proposed in Gondzio and Yildrim (2021), Liuzzi et al. (2019), are the best performing over the subclass of StQP problems. The ap- proach proposed in Bonami et al. (2018) performs quite well over the subclass of Box QP problems and techniques proposed in that paper have



been successfully incorporated in CPLEX. However, for Box QP prob- lems with dense Hessian matrices the best approach appears to be the one proposed in Chen and Burer (2012). Finally, the approach proposed in Liuzzi et al. (2021) is the best performing over the subclass of QP
problems presented in that work (but ongoing experiments prove its ef- fectiveness over more general QP problems with linear constraints).
The second observation we should always keep in mind is that when- ever we deal with a class of special structured GO problems, incorporat- ing as much as possible the special structure into a solution approach allows for significant improvements. That holds true both for exact and for heuristic methods. We just mention a couple of examples taken from our own personal experiences, but many other examples could be given. Circle packing problems are special structured QCQPs with many nonconvex quadratic constraints, namely the nonoverlapping con- straints. The best exact methods for this problem (see, e.g., Mark√≥t and Csendes (2005) for circle packing into a unit square) are those which incorporate tools based on special properties of the circle packing prob- lem, such as symmetry-breaking tools. Special purpose methods strongly outperform general purpose methods for QCQPs when applied to circle
packing problems.
Molecular conformation problems lead to challenging GO problems, with a number of local minimizers which grows exponentially with the number of atoms. Exact methods can be applied only at very small dimensions (i.e., with a small number of atoms). But many excellent heuristic approaches exist. Also in this case the best performing ap- proaches strongly rely on special properties (in particular, geometrical properties) of the molecular conformation problems (see, e.g., Ferreiro- Ferreiro et al., 2019; Wales, 2018; Zhao et al., 2017).

Test problems

Test problems for GO have been proposed in different papers, like, e.g., Furini et al. (2019) for QP problems. We also recall the book Floudas et al. (1999). Currently, there are different web sites which pro- vide large sets of GO test problems. In Neumaier (2021) many academic as well as real-life GO test problems are reported. Large collections of test functions have been reported in Gavana (2021); this quite recent web site reports results of some GO algorithms over the presented test functions and, based on these results, a classification of the diÔ¨Éculty of the test functions is proposed. Through different editions of the GECCO Workshop on Real-Parameter Black-Box Optimization Benchmarking (BBOB), a collection of test problems has been collected. Details can be found in Auger et al. (2019). Another conference, the IEEE Congress on Evolutionary Computation (CEC), organised different competitions on Large Scale Global Optimization, providing many test functions (see, e.g., ≈†kvorc et al. (2019) and the web site IEEE TfLsgo (2021)).

Solvers and their comparison

In previous sections we mentioned some GO solvers such as BARON, BMIBNB, COUENNE, SCIP and for nonconvex QPs with linear con- straints also CPLEX and GUROBI. But others are available (see, e.g.,
Neumaier (2021) for quite an extensive list). The work Biscani and Izzo (2020) describes pagmo and pygmo, C++/Python libraries for massively parallel global, possibly multi-objective, optimization. The web site Johnson (2021) makes available NLopt, another quite large
set of software tools for nonlinear and global optimization. Even SciPy
Jones et al. (2001‚Äì) includes a set of implemented general purpose GO algorithms. Most of the sites containing test problems also present detailed numerical comparisons among different solvers. Many papers compare a newly proposed approach with a limited set of existing GO approaches. But only few papers make a systematic comparison between a large set of different solvers. Here we mention Neumaier et al. (2005), where different GO exact methods are compared, and Rios and Sahini- dis (2013), which presents many different derivative-free algorithms for bound constrained problems. We also mention Beiranvand et al. (2017),
which discusses some guidelines to perform a fair comparison be- tween different solvers. Finally, CEC competitions offer the opportunity of comparing with many different algorithms, while within the con- text of GECCO-BBOB workshops, the Comparing Continuous Optimizers (COCO) platform allows for automated benchmarking. Users can bench- mark their own solvers over a wide set of test functions and compare their results with those of other solvers.

Conclusions

In this paper we presented our view on what we consider as relevant in the recent GO literature. It can be immediately seen, by simply brows- ing the rich list of references below, how the field is attracting more and more active research and novel computational paradigms. Large scale GO problems are no more out of the scope of solution algorithms, to the
point that even professional solvers like GUROBI and CPLEX now in-
clude some GO solver, at least for nonconvex quadratic optimization. Al- though we tried our best to cover many recent advances, we do not claim to have given account of all relevant papers in the field. This survey re- flects our personal points of view on the subject and we are perfectly aware that omissions are inevitable. Besides alternative approaches to the GO problems presented in this paper, we deliberately did not even mention other relevant fields, like multi-objective GO, stochastic GO, bi-level optimization, parallel, distributed, GPU based or quantum com- puting. These topics might become the subject of a different survey.

Acknowledgements

We would like to thank the co-editors of this issue, Miguel Anjos, Tibor Ill√©s, and Tam√°s Terlaky, for their kind invitation to contribute to this important collection of papers. We also thank the anonymous reviewers for their careful reading and constructive suggestions.

References
Adjiman, C.S., Androulakis, I.P., Floudas, C.A., 1998. A global optimization method, ùõºBB, for general twice-differentiable constrained NLPs - II. Implementation and computa- tional results. Comput. Chem. Eng. 22, 1159‚Äì1179.
method, ùõºBB, for process design. Comput. Chem. Eng. Suppl. 20, S419‚ÄìS424. Adjiman, C.S., Androulakis, I.P., Maranas, C.D., Floudas, C.A., 1996. A global optimization
method, ùõºBB, for general twice differentiable NLPs- I. Theoretical advances. Comput. Adjiman, C.S., Dallwig, S., Floudas, C.A., Neumaier, A., 1998. A global optimization
Chem. Eng. 22, 1137‚Äì1158.
Ahmed, M.O., Vaswani, S., Schmidt, M., 2020. Combining Bayesian optimization and Lip- schitz optimization. Mach. Learn. 109 (1), 79‚Äì102.
Ai, W., Zhang, S., 2009. Strong duality for the CDT subproblem: a necessary and suÔ¨Écient condition. SIAM J. Optim. 19, 1735‚Äì1756.
Akrotirianakis, I.G., Floudas, C.A., 2004. A new class of improved convex underestimators for twice continuously differentiable constrained NLPs. J. Global Optim. 30, 367‚Äì390.
Alexandropoulos, S.-A.N., Pardalos, P.M., Vrahatis, M.N., 2020. Dynamic search trajectory methods for global optimization. Ann. Math. Artif. Intell. 88 (1), 3‚Äì37.
Amaral, P., Bomze, I., J√∫dice, J., 2014. Copositivity and constrained fractional quadratic problems. Math. Program. 146, 325‚Äì350.
Anstreicher, K., 2012. On convex relaxations for quadratically constrained quadratic pro- gramming. Math. Program. 136, 233‚Äì251.
Anstreicher, K., 2017. Kronecker product constraints with an application to the two-trust-region subproblem. SIAM J. Optim. 27, 368‚Äì378.
Anstreicher, K.M., 2009. Semidefinite programming versus the reformulation-lineariza- tion technique for nonconvex quadratically constrained quadratic programming. J. Global Optim. 43, 471‚Äì484.
Anstreicher, K.M., Burer, S., 2010. Computable representations for convex hulls of low-di- mensional quadratic forms. Math. Program. 124, 33‚Äì43.
Araya, I., Reyes, V., 2016. Interval Branch-and-Bound algorithms for optimization and constraint satisfaction: a survey and prospects. J. Global Optim. 65, 837‚Äì866.
Audet, C., Hansen, P., Jaumard, B., Savard, G., 1999. A symmetrical linear maxmin ap- proach to disjoint bilinear programming. Math. Program. 85, 573‚Äì592.
Auger, A., Brockhoff, D., Hansen, N., TusaÀò r, T., GECCO workshop on real-parameter black-box optimization benchmarking (BBOB2019). http://numbbo.github.io/workshops/BBOB-2019/Accessed: 2021-04-02.
Bagattini, F., Schoen, F., Tigli, L., 2018. Clustering methods for the optimization of atomic cluster structure. J. Chem. Phys. 148 (14).
Bagattini, F., Schoen, F., Tigli, L., 2019. Clustering methods for large scale geometrical global optimization. Optim. Methods Softw. 34 (5), 1099‚Äì1122.
Bai, L., Mitchell, J.E., Pang, J.-S., 2016. On conic QPCCs, conic QCQPs and completely positive programs. Math. Program. 159, 109‚Äì136.



Ballerstein, M., Michaels, D., 2014. Extended formulations for convex envelopes. J. Global Optim. 60, 217‚Äì238.
Barvinok, A., 1993. Feasibility testing for systems of real quadratic equations. Discr. Com- put. Geom. 10, 1‚Äì13.
Beale, E.M.L., Forrest, J.J.H., 1976. Global optimization using special ordered sets. Math.
Program. 10 (1), 52‚Äì69.
Beck, A., Teboulle, M., 2009. A convex optimization approach for minimizing the ratio of indefinite quadratic functions over an ellipsoid. Math. Program. 118, 13‚Äì35.
Becker, R.W., Lago, G.V., 1970. A global optimization algorithm. In: Proceedings of the 8th Allerton Conference on Circuits and Systems Theory, pp. 3‚Äì12.
Beiranvand, V., Hare, W., Lucet, Y., 2017. Best practices for comparing optimization al- gorithms. Optim. Eng. 18, 815‚Äì848.
Belotti, P., Bonami, P., Vigerske, S., W√§chter, A., 2006. Couenne, an exact solver for non- convex MINLPs.
Belotti, P., Lee, J., Liberti, L., Margot, F., W√§chther, A., 2009. Branching and bounds tightening techniques for non-convex MINLP. Optim. Methods Softw. 24, 597‚Äì634.
Bemporad, A., 2020. Global optimization via inverse distance weighting and radial basis functions. Comput. Optim. Appl..
Ben-Tal, A., den Hertog, D., 2014. Hidden conic quadratic representation of some non- convex quadratic optimization problems. Math. Program. 143, 1‚Äì29.
Ben-Tal, A., Nemirovski, A., 2001. Lectures on Modern Convex Optimization. Society for Industrial and Applied Mathematics.
Berenguel, J., Casado, L., Garcia, I., Hendrix, E., Messine, F., 2013. On interval branch-and-bound for additively separable functions with common variables. J. Global Optim. 56, 1101‚Äì1121.
Bienstock, D., 2016. A note on polynomial solvability of the CDT problem. SIAM J. Optim.
26, 488‚Äì498.
Bienstock, D., Chen, C., Mu√±oz, G., 2020. Outer-product-free sets for polynomial optimiza- tion and oracle-based cuts. Math. Program. 183, 105‚Äì148.
Bienstock, D., Michalka, A., 2014. Cutting-planes for optimization of convex functions over nonconvex sets. SIAM J. Optim. 24, 643‚Äì677.
Bienstock, D., Michalka, A., 2014. Polynomial solvability of variants of the trust-region subproblem. In: SODA 14 Proceedings of the Twenty-Fifth Annual ACM-SIAM Sym- posium on Discrete Algorithms, pp. 380‚Äì390.
Binois, M., Ginsbourger, D., Roustant, O., 2020. On the choice of the low-dimensional domain for global optimization via random embeddings. J. Global Optim. 76 (1), 69‚Äì90.
Biscani, F., Izzo, D., 2020. A parallel global multiobjective framework for optimization: PAGMO. J. Open Source Softw. 5 (53), 2338.
Boland, N., Dey, S., Kalinowski, T., Molinaro, M., Rigterink, F., 2017. Bounding the gap between the McCormick relaxation and the convex hull for bilinear functions. Math. Program. 162, 523‚Äì535.
Bomze, I., 2015. Copositive relaxation beats lagrangian dual bounds in quadratically and linearly constrained quadratic optimization problems. SIAM J. Optim. 25, 1249‚Äì1275. Bomze, I., Cheng, J., Dickinson, P., Lisser, A., 2017. A fresh CP look at mixed-binary QPs:
new formulations and relaxations. Math. Program. 166, 159‚Äì184.
Bomze, I., Frommlet, F., Locatelli, M., 2010. Copositive bounds for improving SDP bounds on the clique number. Math. Program. 124, 13‚Äì32.
Bomze, I., Jeyakumar, V., Li, G., 2018. Extended trust-region problems with one or two balls: exact copositive and Lagrangian relaxations. J. Global Optim. 71, 551‚Äì569.
Bomze, I., Schachinger, W., Uchida, G., 2012. Think co(mpletely)positive! matrix prop- erties, examples and a clustered bibliography on copositive optimization. J. Global Optim. 52, 423‚Äì445.
Bomze, I.M., de Klerk, E., 2002. Solving standard quadratic optimization problems via linear, semidefinite and copositive programming. J. Global Optim. 24, 163‚Äì185.
Bomze, I.M., Duer, M., de Klerk, E., Roos, C., Quist, A., Terlaky, T., 2000. On copositive programming and standard quadratic optimization problems. J. Global Optim. 18, 301‚Äì320.
Bonami, P., G√ºnl√ºk, O., Linderoth, J., 2018. Globally solving nonconvex quadratic pro- gramming problems with box constraints via integer programming methods. Math. Program. Comput. 10, 333‚Äì382.
Bonami, P., Lodi, A., Schweiger, J., Tramontani, A., 2019. Solving quadratic programming by cutting planes. SIAM J. Optim. 29, 1076‚Äì1105.
Borradaile, G., Van Hentenryck, P., 2005. Safe and tight linear estimators for global opti- mization. Math. Program. 102, 495‚Äì517.
Bundfuss, S., Duer, M., 2009. An adaptive linear approximation algorithm for copositive programs. SIAM J. Optim. 20, 30‚Äì53.
Burer, S., 2009. On the copositive representation of binary and continuous nonconvex quadratic programs. Math. Program. 120, 479‚Äì495.
Burer, S., Anstreicher, K.M., 2013. Second-order-cone constraints for extended trust-region subproblems. SIAM J. Optim. 23 (1), 432‚Äì451.
Burer, S., Dong, H., 2012. Representing quadratically constrained quadratic programs as generalized copositive programs. Oper. Res. Lett. 40, 203‚Äì206.
Burer, S., Dong, H., 2013. Separation and relaxation for cones of quadratic forms. Math.
Program. 137, 343‚Äì370.
Burer, S., Kilin√ß-Karzan, F., 2017. How to convexify the intersection of a second order cone and a nonconvex quadratic. Math. Program. 162, 393‚Äì429.
Burer, S., Kim, S., Kojima, M., 2014. Faster, but weaker, relaxations for quadratically constrained quadratic programs. Comput. Optim. Appl. 59, 27‚Äì45.
Burer, S., Letchford, A.N., 2009. On nonconvex quadratic programming with box con- straints. SIAM J. Optim. 20, 1073‚Äì1089.
Burer, S., Vandenbussche, D., 2008. A finite branch-and-bound algorithm for nonconvex quadratic programming via semidefinite relaxations. Math. Program. 113, 259‚Äì282.
Burer, S., Vandenbussche, D., 2009. Globally solving box-constrained nonconvex quadratic programs with semidefinite-based finite branch-and-bound. Comput. Op- tim. Appl. 43, 181‚Äì195.
Burer, S., Yang, B., 2015. The trust region subproblem with non-intersecting linear con- straints. Math. Program. 149, 253‚Äì264.
Burer, S., Ye, Y., 2020. Exact semidefinite formulations for a class of (random and non-ran- dom) nonconvex quadratic programs. Math. Program. 181, 1‚Äì17.
Cabassi, F., Locatelli, M., 2016. Computational investigation of simple memetic ap- proaches for continuous global optimization. Comput. Oper. Res. 72, 50‚Äì70.
Caprara, A., Locatelli, M., 2010. Global optimization problems and domain reduction strategies. Math. Program. 125, 125‚Äì137.
Caprara, A., Locatelli, M., Monaci, M., 2016. Theoretical and computational results about optimality-based domain reductions. Comput. Optim. Appl. 64, 513‚Äì533.
Carrizosa, E., Hansen, P., Messine, F., 2004. Improving interval analysis bounds by trans- lations. J. Global Optim. 29, 157‚Äì172.
Cartis, C., Fowkes, J., Gould, N., 2015. Branching and bounding improvements for global optimization algorithms with Lipschitz continuity properties. J. Global Optim. 61, 429‚Äì457.
Chen, J., Burer, S., 2012. Globally solving nonconvex quadratic programming problems via completely positive programming. Math. Program. Comput. 4, 33‚Äì52.
Consolini, L., Locatelli, M., 2017. On the complexity of quadratic programming with two quadratic constraints. Math. Program. 164, 91‚Äì128.
Csallner, A.E., Csendes, T., Mark√≥t, M.C., 2000. Multisection in interval branch-and-bound methods for global optimization I. Theoretical results. J. Global Optim. 16, 371‚Äì392. Cui, L., Li, G., Lin, Q., Chen, J., Lu, N., 2016. Adaptive differential evolution algorithm with novel mutation strategies in multiple sub-populations. Comput. Oper. Res. 67,
155‚Äì173.
Dantzig, G.B., 1960. On the significance of solving linear programming problems with some integer variables. Econometrica 28 (1), 30‚Äì44.
Das, S., Mullick, S., Suganthan, P., 2016. Recent advances in differential evolution-an updated survey. Swarm Evol. Comput. 27, 1‚Äì30.
Davarnia, D., Richard, J.-P., Tawarmalani, M., 2017. Simultaneous convexification of bi- linear functions over polytopes with application to network interdiction. SIAM J. Op- tim. 27, 1801‚Äì1833.
de Angelis, P.L., Bomze, I.M., Toraldo, G., 2004. Ellipsoidal approach to box-constrained quadratic problems. J. Global Optim. 28, 1‚Äì15.
de Klerk, E., Hess, R., Laurent, M., 2017. Improved convergence rates for Lasserre-type hierarchies of upper bounds for box-constrained polynomial optimization. SIAM J. Optim. 27, 347‚Äì367.
de Klerk, E., Lasserre, J., Laurent, M., Sun, Z., 2017. Bound-constrained polynomial opti- mization using only elementary calculations. Math. Oper. Res. 42, 834‚Äì853.
de Klerk, E., Laurent, M., Parrillo, P.A., 2006. A PTAS for the minimization of polynomials of fixed degree over the simplex. Theor. Comput. Sci. 361, 210‚Äì225.
de Klerk, E., Pasechnik, D.V., 2002. Approximation of the stability number of a graph via copositive programming. SIAM J. Optim. 12, 875‚Äì892.
Del Pia, A., Khajavirad, A., 2017. A polyhedral study of binary polynomial programs.
Math. Oper. Res. 42, 389‚Äì410.
Del Pia, A., Khajavirad, A., 2018. On decomposability of multilinear sets. Math. Program.
170, 387‚Äì415.
Del Ser, J., Osaba, E., Molina, D., Yang, X.-S., Salcedo-Sanz, S., Camacho, D., Das, S., Suganthan, P., Coello Coello, C., Herrera, F., 2019. Bio-inspired computation: where we stand and what‚Äôs next. Swarm Evol. Comput 48, 220‚Äì250.
Depetrini, D., Locatelli, M., 2011. Approximation of linear fractional/multiplicative prob- lems. Math. Program. 128, 437‚Äì443.
Di Carlo, M., Vasile, M., Minisci, E., 2020. Adaptive multi-population inflationary differ- ential evolution. Soft comput 24 (5), 3861‚Äì3891.
Diouane, Y., Gratton, S., Vicente, L.N., 2015. Globally convergent evolution strategies.
Math. Program. 152 (1‚Äì2), 467‚Äì490.
Diouane, Y., Gratton, S., Vicente, L.N., 2015. Globally convergent evolution strategies for constrained optimization. Comput. Optim. Appl. 62 (2), 323‚Äì346.
Dixon, L., 1975. Towards global optimisation. In: Dixon, L., Szeg√∂, G. (Eds.), Towards Global Optimization. North-Holland, pp. 29‚Äì54.
Dixon, L., Szeg√∂, G. (Eds.), Towards global optimisation. proceedings of a workshop at the University of Cagliari, Italy, October 1974, 1975. North-Holland.
Dixon, L., Szeg√∂, G. (Eds.), 1978. Towards Global Optimisation 2. North-Holland. Domes, F., Neumaier, A., 2016. Constraint aggregation for rigorous global optimization.
Math. Program. 155, 375‚Äì401.
Evtushenko, Y.P., 1971. Numerical method for finding the global extremum of a function.
Vyl. Mat. I Mat. Fiz. 11, 1390‚Äì1403. (in Russian)
Falk, J.E., Soland, R.M., 1969. An algorithm for separable nonconvex programming prob- lems. Manage. Sci. 15 (9), 550‚Äì569.
Feliot, P., Bect, J., Vazquez, E., 2017. A Bayesian approach to constrained single- and multi-objective optimization. J. Global Optim. 67 (1), 97‚Äì133.
Ferreiro-Ferreiro, A.M., Garc√≠a-Rodr√≠guez, J.A., Souto, L., V√°zquez, C., 2019. Basin Hop- ping with synched multi L-BFGS local searches. Parallel implementation in multi-CPU and GPUs. Appl. Math. Comput. 356, 282‚Äì298.
Floudas, C.A., Pardalos, P.M., Adjiman, C.S., Esposito, W.R., Gumus, Z.H., Harding, S.T., Klepeis, J.L., Meyer, C.A., Schweiger, C., 1999. Handbook of Test Problems in Local and Global Optimization. Nonconvex Optimization and its Applications, 33. Kluwer Academic Publishers, Dordrecht.
Fowkes, J., Gould, N., Farmer, C., 2013. A branch and bound algorithm for the global opti- mization of Hessian Lipschitz continuous functions. J. Global Optim. 56, 1791‚Äì1815. Frazier, P.I., 2018. Bayesian optimization. In: Gel, E., Ntaimo, L., Shier, D., Greenberg, H.J. (Eds.), Recent Advances in Optimization and Modeling of Contemporary Problems.
INFORMS, pp. 255‚Äì278.
Furini, F., Traversi, E., Belotti, P., Frangioni, A., Gleixner, A., Gould, N., Liberti, L., Lodi, A., Misener, R., Mittelmann, H., Sahinidis, N., Vigerske, S., Wiegele, A., 2019. QPLIB: A library of quadratic programming instances. Math. Program. Comput. 11, 237‚Äì 265.



Gamrath, G., Anderson, D., Bestuzheva, K., Chen, W.-K., Eifler, L., Gasse, M., Gemander, P., Gleixner, A., Gottwald, L., Halbig, K., Hendel, G., Hojny, C., Koch, T., Le Bodic, P., Ma- her, S., Matter, F., Miltenberger, M., M√ºhmer, E., M√ºller, B., Pfetsch, M., Schl√∂sser, F., Serrano, F., Shinano, Y., Tawfik, C., Vigerske, S., Wegscheider, F., Weninger, D., Witzig, J., 2020. The SCIP Optimization Suite 7.0. Technical Report. Optimization Online.
Garrido-Merch√°n, E.C., Hern√°ndez-Lobato, D., 2020. Dealing with categorical and integer‚Äì valued variables in Bayesian optimization with Gaussian processes. Neurocomputing 380, 20‚Äì35.
Gavana, A., Global Optimization Benchmarks. http://infinity77.net/go_2021/. Accessed: 2021-04-02.
Gaviano, M., 1975. Some general results on the convergence of random search algorithms in minimisation problems. In: Dixon, L., Szeg√∂, G. (Eds.), Towards Global Optimiza- tion. North-Holland, pp. 149‚Äì157.
Ghosh, S., Das, S., Vasilakos, A.V., Suresh, K., 2012. On convergence of differential evo- lution over a class of continuous functions with unique global optimum. IEEE Trans. Syst. Man Cybern.Part B (Cybernetics) 42 (1), 107‚Äì124.
Gleixner, A., Berthold, T., M√ºller, B., Weltge, S., 2017. Three enhancements for optimiza- tion-based bound tightening. J. Global Optim. 67, 731‚Äì757.
Grosso, A., Locatelli, M., Schoen, F., 2007. A population-based approach for hard global optimization problems based on dissimilarity measures. Math. Program. 110 (2), 373‚Äì404.
Hadi, A.A., Mohamed, A.W., Jambi, K.M., 2019. LSHADE-SPA Memetic framework for solving large-scale optimization problems. Complex Intell. Syst. 5 (1), 25‚Äì40.
Hager, W., Phan, D., 2009. An ellipsoidal branch and bound algorithm for global opti- mization. SIAM J. Optim. 20, 740‚Äì758.
Hansen, N., 2006. The CMA evolution strategy: a comparing review. In: Lozano, J.A., Lar- ra√±aga, P., Inza, I., Bengoetxea, E. (Eds.), Towards a New Evolutionary Computation: Advances in the Estimation of Distribution Algorithms. Springer, Berlin, Heidelberg,
pp. 75‚Äì102.
Hansen, N., Ostermeier, A., 2001. Completely derandomized self-adaptation in evolution strategies. Evol. Comput. 9 (2), 159‚Äì195.
Hansen, P., Lagouanelle, J.-L., Messine, F., 2007. Comparison between Baumann and ad- missible simplex forms in interval analysis. J. Global Optim. 37, 215‚Äì228.
Hendrix, E.M.T., T√≥th, B., 2010. Introduction to Nonlinear and Global Optimization.
Springer, New York, NY.
Hern√°ndez-Lobato, J.M., Gelbart, M.A., Adams, R.P., Hoffman, M.W., Ghahramani, Z., 2016. A general framework for constrained bayesian optimization using informa- tion-based search. J. Mach. Learn. Res. 17 (160), 1‚Äì53.
Ho-Nguyen, N., Kilin√ß-Karzan, F., 2017. A Second-Order Cone based approach for solving the trust-region subproblem and its variants. SIAM J. Optim. 27, 1485‚Äì1512.
Holland, J.H., 1975. Adaptation in Natural and Artificial Systems: An Introductory Anal- ysis with Applications to Biology, Control, and Artificial Intelligence. University of Michigan Press.
Horst, R., 1976. An algorithm for nonconvex programming problems. Math. Program. 10 (1), 312‚Äì321.
Horst, R., Pardalos, P.M. (Eds.), 1995. Handbook of Global Optimization. Kluwer Aca- demic Publishers, Dordrecht.
Horst, R., Pardalos, P.M., Thoai, N.V., 2001. Introduction to Global Optimization. Non- convex Optimization and Its Applications, 48. Springer Verlag.
Horst, R., Tuy, H., 1993. Global Optimization: Deterministic Approaches, 2nd edition Springer Verlag.
Gondzio, J., Yildrim, E., 2021. Global solutions of nonconvex Standard Quadratic Pro- grams via Mixed Integer Linear Programming reformulations. J. Glob. Optim 81, 293‚Äì321.
IEEE TfLsgo. IEEE Task Force on Large-Scale Global Optimization. https://www.tflsgo.orgAccessed: 2021-04-02.
Jach, M., Michaels, D., Weismantel, R., 2008. The convex envelope of (ùëõ‚Äì1)-convex func-
tions. SIAM J. Optim. 19, 1451‚Äì1466.
Jansson, C., Chaykin, D., Keil, C., 2007. Rigorous error bounds for the optimal value in semidefinite programming. SIAM J. Numer. Anal. 46, 180‚Äì200.
Jeyakumar, V., Li, G., 2014. Trust-region problems with linear inequality constraints: ex- act SDP relaxation, global optimality and robust optimization. Math. Program. 147, 171‚Äì206.
Jeyakumar, V., Li, G., 2018. Exact second-order cone programming relaxations for some nonconvex minimax quadratic optimization problems. SIAM J. Optim. 28, 760‚Äì 787.
Jiang, R., Li, D., Wu, B., 2018. SOCP reformulation for the generalized trust region subproblem via a canonical form of two symmetric matrices. Math. Program. 169, 531‚Äì563.
Johnson, S. G., The NLopt nonlinear-optimization package. http://github.com/stevengj/ nlopt. Accessed: 2021-04-02.
Jones, D.R., Schonlau, M., Welch, W.J., 1998. EÔ¨Écient global optimization of expensive black-box functions. J. Global Optim. 13 (4), 455‚Äì492.
Jones, E., Oliphant, T., Peterson, P., et al., 2001‚Äì. SciPy: Open source scientific tools for Python. Accessed: 2021-04-02.
Kandasamy, K., Vysyaraju, K.R., Neiswanger, W., Paria, B., Collins, C.R., Schneider, J., Poczos, B., Xing, E.P., 2020. Tuning hyperparameters without grad students: scalable and Robust Bayesian optimisation with dragonfly. J. Mach. Learn. Res. 21, 1‚Äì27.
Kawaguchi, K., 2016. Deep Learning without Poor Local Minima. Technical Report arXiv:1605.07110v3. Massachusetts Institute of Technology.
Kazazakis, N., Adjiman, C., 2018. Arbitrarily tight ùõº-BB underestimators of general non‚Äì
linear functions over sub-optimal domains. J. Global Optim. 71, 815‚Äì844.
Kearfott, R.B., 2011. Interval computations, rigor and non-rigor in deterministic continu- ous global optimization. Optim. Methods Softw. 26, 259‚Äì279.
Khajavirad, A., Michalek, J., Sahinidis, N., 2014. Relaxations of factorable functions with convex-transformable intermediates. Math. Program. 144, 107‚Äì140.
Khajavirad, A., Sahinidis, N., 2012. Convex envelopes of products of convex and compo- nent-wise concave functions. J. Global Optim. 52, 391‚Äì409.
Khajavirad, A., Sahinidis, N.V., 2013. Convex envelopes generated from finitely many compact convex sets. Math. Program. 137, 371‚Äì408.
Kim, M.J., 2020. Variance regularization in sequential Bayesian optimization. Math. Oper.
Res. 45 (3), 966‚Äì992.
Kim, S., Kojima, M., 2003. Exact solutions of some nonconvex quadratic optimization problems via SDP and SOCP relaxations. Comput. Optim. Appl. 26, 143‚Äì154.
Kuang, X., Zuluaga, L., 2018. Completely positive and completely positive semidefinite tensor relaxations for polynomial optimization. J. Global Optim. 70, 551‚Äì577.
Kuno, T., 2005. A revision of the trapezoidal branch-and-bound algorithm for linear sum-of-ratios problems. J. Global Optim. 33, 215‚Äì234.
Kushner, H.J., 1964. A new method of locating the maximum point of an arbitrary multi- peak curve in the presence of noise. J. Basic Engi.g 97‚Äì106.
Lasserre, J.B., 2001. Global optimization with polynomials and the problem of moments.
SIAM J. Optim. 11, 796‚Äì817.
Lasserre, J.B., 2005. Polynomial programming: LP-relaxations also converge. SIAM J. Op- tim. 15, 383‚Äì393.
Lasserre, J.B., 2006. A sum of squares approximation of nonnegative polynomials. SIAM
J. Optim. 16, 751‚Äì765.
Laurent, M., 2007. Semidefinite representations for finite varieties. Math. Program. 109, 1‚Äì26.
Le Thi, H.A., 2000. An eÔ¨Écient algorithm for globally minimizing a quadratic function under convex quadratic constraints. Math. Program. 87, 401‚Äì426.
Linderoth, J., 2005. A simplicial branch-and-bound algorithm for solving quadratically constrained quadratic programs. Math. Program. 103, 251‚Äì282.
Liuzzi, G., Locatelli, M., Piccialli, V., 2019. A new branch-and-bound algorithm for stan- dard quadratic programming problems. Optim. Methods Softw. 34, 79‚Äì97.
Liuzzi, G., Locatelli, M., Piccialli, V., Rass, S., 2021. Computing mixed strategies equilibria in presence of switching costs by the solution of nonconvex QP problems. Comput. Optim.. To appear
Locatelli, M., 2013. Approximation algorithm for a class of global optimization problems.
J. Global Optim. 55, 13‚Äì25.
Locatelli, M., 2015. Alternative branching rules for some nonconvex problems. Optim.
Methods Softw. 30, 365‚Äì378.
Locatelli, M., 2015. Some results for quadratic problems with one or two quadratic con- straints. Oper. Res. Lett. 43, 126‚Äì131.
Locatelli, M., 2016. Exactness conditions for an SDP relaxation of the extended trust region problem. Optim. Lett. 10, 1141‚Äì1151.
Locatelli, M., 2016. Non polyhedral convex envelopes for 1-convex functions. J. Global Optim. 65, 637‚Äì655.
Locatelli, M., 2020. Convex envelope of bivariate cubic functions over rectangular regions.
J. Global Optim. 76, 1‚Äì24.
Locatelli, M., Schoen, F., 2013. Global Optimization: Theory, Algorithms, and Applica- tions. SIAM-MOS. SIAM.
Locatelli, M., Vasile, M., 2015. (Non) convergence results for the differential evolution method. Optim. Lett. 9 (3), 413‚Äì425.
Lofberg, J., 2004. YALMIP : a toolbox for modeling and optimization in MATLAB. In: 2004 IEEE International Conference on Robotics and Automation (IEEE Cat. No.04CH37508), pp. 284‚Äì289.
Luedtke, J., D‚ÄôAmbrosio, C., Linderoth, J., Schweiger, J., 2020. Strong convex nonlinear relaxations of the pooling problem. SIAM J. Optim. 30, 1582‚Äì1609.
Luedtke, J., Namazifar, M., Linderoth, J., 2012. Some results on the strength of relaxations of multilinear functions. Math. Program. 136, 325‚Äì351.
Ma, X., Li, X., Zhang, Q., Tang, K., Liang, Z., Xie, W., Zhu, Z., 2019. A survey on cooperative co-evolutionary algorithms. IEEE Trans. Evol. Comput. 23 (3), 421‚Äì441.
Mansueto, P., Schoen, F., 2021. Memetic differential evolution methods for clustering problems. Pattern Recognit 114, 107849.
Markot, M., Schichl, H., 2014. Bound constrained interval global optimization in the CO- CONUT environment. J. Global Optim. 60, 751‚Äì776.
Mark√≥t, M.C., Csendes, T., 2005. A new verified optimization technique for the ‚Äúpacking circles in a unit square‚Äù problem. SIAM J. Optim. 16, 193‚Äì219.
Mark√≥t, M.C., Fernandez, J., Casado, L.G., Csendes, T., 2006. New interval methods for constrained global optimization. Math. Program. 106, 287‚Äì318.
Martinez, J., Casado, L., Garcia, I., Sergeyev, Y., Toth, B., 2004. On an eÔ¨Écient use of gradient information for accelerating interval global optimization algorithms. Numer. Alg. 37, 61‚Äì69.
Martinez-Cantin, R., 2014. Bayesopt: a bayesian optimization library for nonlinear opti- mization, experimental design and bandits. J. Mach. Learn. Res. 15 (115), 3915‚Äì3919. Mathesen, L., Pedrielli, G., Ng, S.H., Zabinsky, Z.B., 2020. Stochastic optimization with adaptive restart: a framework for integrated local and global learning. J. Global Op-
tim..
McCormick, G., 1972. Attempts to calculate global solutions of problems that may have local minima. In: Lootsma, F. (Ed.), Numerical Methods for Non-Linear Optimization. Academic Press, pp. 209‚Äì221.
McCormick, G.P., 1976. Computability of global solutions to factorable nonconvex pro- grams: Part I Convex underestimating problems. Math. Program. 10 (1), 147‚Äì175.
Meldgaard, S.A., Kolsbjerg, E.L., Hammer, B., 2018. Machine learning enhanced global optimization by clustering local environments to enable bundled atomic energies. J. Chem. Phys. 149 (13), 134104.
Messine, F., 2004. Deterministic global optimization using interval constraint propagation techniques. RAIRO-Oper. Res. 38 (4), 277‚Äì293.
Meyer, C.A., Floudas, C.A., 2005. Convex envelopes for edge-concave functions. Math.
Programm. B 103, 207‚Äì224.




tiable functions by piecewise quadratic perturbation: spline ùõºBB underestimators. J. Meyer, C.A., Floudas, C.A., 2005. Convex underestimation of twice continuously differen-
Global Optim. 32, 221‚Äì258.
Mittel, S., Schulz, A., 2013. An FPTAS for optimizing a class of low-rank functions over a polytope. Math. Program. 141, 103‚Äì120.
Mockus, J., 1975. On Bayesian methods of optimisation. In: Dixon, L., Szeg√∂, G. (Eds.), Towards Global Optimization. North-Holland, pp. 166‚Äì181.
Moriconi, R., Kumar, K.S.S., Deisenroth, M.P., 2020. High-dimensional Bayesian optimiza- tion with projections using quantile Gaussian processes. Optim. Lett. 14 (1), 51‚Äì64.
Motzkin, T.S., Strauss, E.G., 1965. Maxima for graphs and a new proof of a theorem of Tur√°n. Can. J. Math. 17, 533‚Äì540.
Neumaier, A., Global optimiztion. https://www.mat.univie.ac.at/~neum/glopt.html Ac- cessed: 2021-04-02.
Neumaier, A., 2004. Complete search in continuous global optimization and constraint satisfaction. In: Acta Numerica 2004. Cambridge University Press, pp. 271‚Äì369.
Neumaier, A., Shcherbina, O., 2004. Safe bounds in linear and mixed-integer program- ming. Math. Program. 99, 283‚Äì296.
Neumaier, A., Shcherbina, O., Huyer, W., Vink√≥, T., 2005. A comparison of complete global optimization solvers. Math. Program. 103 (2), 335‚Äì356.
Nguyen, T., Richard, J.-P., Tawarmalani, M., 2018. Deriving convex hulls through lifting and projection. Math. Program. 169, 377‚Äì415.
Nie, J., 2013. Certifying convergence of Lasserres hierarchy via flat truncation. Math.
Program. 142, 485‚Äì510.
Nie, J., 2014. Optimality conditions and finite convergence of Lasserres hierarchy. Math.
Program. 146, 97‚Äì121.
Nie, J., Demmel, J., Sturmfels, B., 2006. Minimizing polynomials via sum of squares over the gradient ideal. Math. Program. 106, 587‚Äì606.
Padberg, M., 1989. The boolean quadric polytope: some characteristics, facets and rela- tives. Math. Program. 45, 139‚Äì172.
Papp, D., Yildiz, S., 2019. Sum-of-squares optimization without semidefinite program- ming. SIAM J. Optim. 29, 822‚Äì851.
Parrillo, P.A., 2000. Structured Semidefinite Programs and Semi-algebraic Geome- try Methods in Robustness and Optimization. California Institute of Technology, Pasadena.
PaulavicÀò ius, R., ZiÀòlinskas, J., 2014. Simplicial Global Optimization. Springer, New York,
NY.
Pe√±a, J., Vera, J., Zuluaga, L.F., 2007. Computing the stability number of a graph via linear and semidefinite programming. SIAM J. Optim. 18, 87‚Äì105.
Piyavskii, S.A., 1972. An algorithm for finding the absolute extremum of a function. USSR Comput. Math. Math.Phys. 12 (4), 57‚Äì67.
Pong, T., Wolkowicz, H., 2014. The generalized trust region subproblem. Comput. Optim.
Appl. 58, 273‚Äì322.
Puranik, Y., Sahinidis, N., 2017. Bounds tightening based on optimality conditions for nonconvex box-constrained optimization. J. Global Optim. 67, 59‚Äì77.
Rendl, F., Wolkowicz, H., 1997. A semidefinite framework for trust region subproblems with applications to large scale minimization. Math. Program. 77, 273‚Äì299.
Rikun, A.D., 1997. A convex envelope formula for multilinear functions. J. Global Optim.
10, 425‚Äì437.
Rios, L., Sahinidis, N., 2013. Derivative-free optimization: a review of algorithms and comparison of software implementations. J. Global Optim. 56, 1247‚Äì1293.
Sahinidis, N., 2017. BARON 17.8.9: Global Optimization of Mixed-Integer Nonlinear Pro- grams, User‚Äôs Manual.
Sakaue, S., Nakatsukasa, Y., Takeda, A., Iwata, S., 2016. Solving generalized CDT problems via two-parameter eigenvalues. SIAM J. Optim. 26, 1669‚Äì1694.
Santana, A., Dey, S., 2020. The convex hull of a quadratic constraint over a polytope.
SIAM J. Optim. 30, 2983‚Äì2997.
Schichl, H., Neumaier, A., 2005. Interval analysis on directed acyclic graphs for global optimization. J. Global Optim. 33, 541‚Äì562.
Schoen, F., Tigli, L., 2021. EÔ¨Écient large scale global optimization through cluster- ing-based population methods. Comput. Oper. Res. 127 (105165).
Scott, J.K., Stuber, M.D., Barton, P.I., 2011. Generalized McCormick relaxations. J. Global Optim. 51, 569‚Äì606.
Sherali, H.D., Tuncbilek, C.H., 1992. A global optimization algorithm for polynomial pro- gramming problems using a reformulation-linearization technique. J. Global Optim. 2, 101‚Äì112.
Shubert, B.O., 1972. A sequential method seeking the global maximum of a function. SIAM
J. Numer. Anal. 9.
≈†kvorc, U., Eftimov, T., Koro≈°ec, P., 2019. CEC real-parameter optimization competitions: Progress from 2013 to 2018. In: 2019 IEEE Congress on Evolutionary Computation (CEC), pp. 3126‚Äì3133.
Snoek, J., Ripped, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N., Patwary, M., Prab- hat, Adams, R., 2015. Scalable Bayesian optimization using deep neural networks, 3,
pp. 2161‚Äì2170.
Sojoudi, S., Lavaei, J., 2014. Exactness of semidefinite relaxations for nonlinear optimiza- tion problems with underlying graph structure. SIAM J. Optim. 24, 1746‚Äì1778.
Soland, R.M., 1971. An algorithm for separable nonconvex programming problems II: nonconvex constraints. Manage. Sci. 17 (11), 759‚Äì773.
Sturm, J.F., Zhang, S., 2003. On cones of nonnegative quadratic functions. Math. Oper.
Res. 28 (2), 246‚Äì267.
Sun, Y., Li, X., Ernst, A., Omidvar, M.N., 2019. Decomposition for large-scale optimiza- tion problems with overlapping components. In: 2019 IEEE Congress on Evolutionary Computation (CEC), pp. 326‚Äì333.
Tardella, F., 2003. On the existence of polyhedral convex envelopes. In: Frontiers in Global Optimization. Kluwer Academic Publishers, pp. 563‚Äì574.
Tardella, F., 2008. Existence and sum decomposition of vertex polyhedral convex en- velopes. Optim. Lett. 2, 363‚Äì375.
Tawarmalani, M., Richard, J.-P.P., Xiong, C., 2013. Explicit convex and concave envelopes through polyhedral subdivisions. Math. Program. 138, 531‚Äì577.
Tawarmalani, M., Sahinidis, N.V., 2001. Semidefinite relaxations of fractional programs via novel convexification techniques. J. Global Optim. 20, 137‚Äì158.
Tawarmalani, M., Sahinidis, N.V., 2004. Global optimization of mixed-integer nonlinear programs: a theoretical and computational study. Math. Program. 99 (3), 563‚Äì591.
T√∂rn, A.A., 1978. A search‚Äìclustering approach to global optimization. In: Towards Global Optimization 2. North‚ÄìHolland, pp. 49‚Äì62.
T√≥th, B., Hendrix, E., Casado, L., Garcia, I., 2016. On refinement of the unit simplex using regular simplices. J. Global Optim. 64, 305‚Äì323.
T√≥th, B., Hendrix, E.M.T., Casado, L.G., 2021. On monotonicity and search strategies in face-based copositivity detection algorithms. Central Eur. J. Oper. Res. available on- line.
Tran, N., Schneider, J.-G., Weber, I., Qin, A.K., 2020. Hyper-parameter optimization in classification: to-do or not-to-do. Pattern Recognit. 103, 107245.
Vandenbussche, D., Nemhauser, G.L., 2005. A branch-and-cut algorithm for nonconvex quadratic programs with box constraints. Math. Program. 102, 559‚Äì575.
Vandenbussche, D., Nemhauser, G.L., 2005. A polyhedral study of nonconvex quadratic programs with box constraints. Math. Program. 102, 531‚Äì557.
Vink√≥, T., Gelle, K., 2017. Basin Hopping Networks of continuous global optimization problems. Central Eur. J. Oper. Res. 25 (4), 985‚Äì1006.
Vu, X.-H., Schichl, H., Sam-Haroud, D., 2009. Interval propagation and search on directed acyclic graphs for numerical constraint solving. J. Global Optim. 45, 499‚Äì531.
Vui, H.H., So‚Äôn, P.T., 2008. Global optimization of polynomials using the truncated tan- gency variety and sums of squares. SIAM J. Optim. 19, 941‚Äì951.
Wales, D.J., 2018. Exploring energy landscapes. Annu. Rev. Phys. Chem. 69 (1), 401‚Äì425. Wang, A., Kilin√ß-Karzan, F., 2020. The generalized trust region subproblem: solution com-
plexity and convex hull results. Math. Program. available online.
Wang, A., Kilin√ß-Karzan, F., 2021. On the tightness of SDP relaxations of QCQPs. Math.
Program. to appear.
Wang, Z., Hutter, F., Zoghi, M., Matheson, D., Feitas, N.d., 2016. Bayesian optimization in a billion dimensions via random embeddings. J. Artif. Intell. Res. 55, 361‚Äì387.
Wechsung, A., Scott, J., Watson, H., Barton, P., 2015. Reverse propagation of McCormick relaxations. J. Global Optim. 63, 1‚Äì36.
Wu, G., Mallipeddi, R., Suganthan, P.N., Wang, R., Chen, H., 2016. Differential evolution with multi-population based ensemble of mutation strategies. Inf. Sci. 329, 329‚Äì345.
Xia, W., Vera, J., Zuluaga, L., 2020. Globally solving nonconvex quadratic programs via linear integer programming techniques. INFORMS J. Comput. 32, 40‚Äì56.
Yang, B., Anstreicher, K., Burer, S., 2018. Quadratic programs with hollows. Math. Pro- gram. 170, 541‚Äì553.
Yang, B., Burer, S., 2016. A two-variable approach to the two-trust region subproblem.
SIAM J. Optim. 26, 661‚Äì680.
Yang, L., Shami, A., 2020. On hyperparameter optimization of machine learning algo- rithms: theory and practice. Neurocomputing 415, 295‚Äì316.
Ye, Y., Zhang, S., 2003. New results on quadratic minimization. SIAM J. Optim. 14, 245‚Äì267.
Yuan, J., Wang, M., Ai, W., Shuai, T., 2017. New results on narrowing the duality gap of the extended Celis-Dennis-Tapia problem. SIAM J. Optim. 27, 890‚Äì909.
Zhan, D., Xing, H., 2020. Expected improvement for expensive optimization: a review. J. Global Optim. 78 (3), 507‚Äì544.
Zhang, Y., Sahinidis, N., Nohra, C., Rong, G., 2020. Optimality-based domain reduction for inequality-constrained NLP and MINLP problems. J. Global Optim. 77, 425‚Äì454.
Zhao, Y., Chen, X., Li, J., 2017. TGMin: a global-minimum structure search program based on a constrained basin-hopping algorithm. Nano Res. 10 (10), 3407‚Äì3420.
