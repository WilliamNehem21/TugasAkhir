	Electronic Notes in Theoretical Computer Science 96 (2004) 7–28	
www.elsevier.com/locate/entcs




Axioms for Probability and Nondeterminism
Michael Mislovea,1 and Jo¨el Ouaknineb,2 and James Worrella,1
aTulane University, Department of Mathematics, 6823 St Charles Avenue, New Orleans LA 70118, USA
bComputer Science Department, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh PA 15213, USA

Abstract
This paper studies a simple calculus for finite-state processes featuring both nondeterministic and probabilistic choice. We present a domain model and an operational semantics for our calculus. The denotational model uses the probabilistic powerdomain of Jones and Plotkin, combined with a geometrically convex variant of the Plotkin powerdomain. The operational model defines transition rules under which a process makes transitions to probability distributions over states. We prove a full abstraction result that shows two processes have the same denotation if and only if they are probabilistically bisimilar. We also show that the expected laws for probability and nondeterminism are sound and complete with respect to the denotational model.
Keywords: Probabilistic bisimulation, nondeterministic choice, Segala-Lynch probabilistic automaton, CCS


Introduction
By now there is a well-established subset of the concurrency literature dealing with process algebras that feature probabilistic choice—either instead of, or in addition to, nondeterministic choice. In giving an operational semantics to such languages one must specify not only which transitions are possible, but also the probabilities with which they are taken (see, e.g., [19]). In the presence

1 Support by the US National Science Foundation and the US Office of Naval Research is gratefully acknowledged.
2 Support by the ONR contract N00014-95-1-0520, Defense Advanced Projects Research
Agency and the Army Research Office under contract DAAD19-01-1-0485 is gratefully ac- knowledged.

1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.04.019

of unguarded recursion the resultant bookkeeping becomes quite complicated, and arguably undermines the usual advantages of an operational approach. On the other hand, in a domain model many technicalities can be hidden by importing standard constructions and results from general domain theory.
This paper gives a domain-theoretic semantics for a probabilistic process algebra. We use the probabilistic powerdomain [12] to model probabilistic choice, and we use a geometrically convex variant of the Plotkin powerdomain, independently due to Mislove [16] and Tix [20], to model nondeterministic choice. We also give an operational semantics for the process algebra, and we show that our domain model is fully abstract with respect to probabilistic bisimilarity. The relies on the main result of the paper, which presents a set of laws for probabilistic and nondeterministic choice that is sound and complete with respect to our domain model. The completeness result applies to finite- state processes; thus we restrict ourselves to a process algebra with prefixing, probabilistic choice, nondeterministic choice and recursion. However, for the completeness proof it turns out to be more convenient to work with the domain model than the operational model.
The nondeterministic sum of terms E and F is written E + F , while, for 0 < p < 1, the probabilistic sum of p times E and 1 − p times F is written E ⊕p F . The model we describe is non-alternating, that is, there is only one type of process, and the operators + and ⊕p can be applied without restriction. To accommodate both types of choice, following the probabilistic automaton model of Segala and Lynch [18], we model the initial capabilities of a process as a set of probability distributions. Nondeterministic choice is modelled by union, and probabilistic choice by pointwise lifting the natural probabilistic sum operator on probability distributions to sets of such distributions. This last artifice entails that our semantics satisfies the following distributive law of probabilistic choice over nondeterministic choice
(E + F ) ⊕p G = (E ⊕p F )+ (F ⊕p G) .	(1)
Another consequence of our interpretation of probabilistic choice is that, in order to ensure that the law E⊕pE = E holds, we model the initial capabilities of a process asa geometrically convex 1 set of probability distributions. In turn this entails the following convexity law for nondeterministic choice
E + (E ⊕p F )+ F = E + F .	(2)

1 A set S of probability distributions is geometrically convex if pσ + (1 − p)ν ∈ S whenever σ, ν ∈ S and 0 ≤ p ≤ 1. Later on we will also introduce the notion of order convexity for such sets.

Thus the nondeterministic choice of E and F also includes any convex combi- nation of E and F . Operationally this corresponds to the idea of Segala and Lynch [18] that a nondeterministic choice could be resolved into a probabilistic choice by means of a randomized scheduler.
The distributive law (1) facilitates a semantics in which nondeterministic choice and probabilistic choice satisfy the expected laws. On the other hand, the dual requirement that nondeterministic choice distribute over probabilistic choice would force us to revise some of these laws. For example, an instance of this other distributive law is
(E ⊕ 1 F )+ (E ⊕ 1 F )= E ⊕ 1 ((E + F ) ⊕ 2 F ) .
			
2	2	4	3
It would seem undesirable to retain the idempotence of + in the presence of such an identity. In particular, it would imply that the simple fifty-fifty choice E ⊕ 1 F is equal to various weighted combinations of E, F and E + F .
2
The dual distributive law tends to arise in those models where the guiding
philosophy is that probabilistic choices should be resolved before nondetermin- istic choices. Examples of such models can be found in [13,17]. Analogously, the distributive law (1) implies that nondeterministic choices are resolved be- fore probabilistic choices in our model.

Related Work
Stark and Smolka [19] and Baeten et al. [4] give complete axiomatizations of probabilistic bisimilarity for calculi featuring probabilistic choice, but without nondeterministic choice. The development in [19] closely follows the treat- ment of equations for bisimilarity in finite-state CCS by Milner [15]. Our completeness proof follows the same pattern, except that arguments based on operational semantics get replaced by domain theory.
Following Milner [15] and Stark and Smolka [19], we include a unique fixed point rule (cf. F4 in Table 1) for guarded recursion as part of our ax- iomatization. This is really a schema of conditional equations. By contrast, a purely equational axiomatization of probabilistic bisimilarity has recently
been obtained by Aceto, E´sik and Ingo´lfsd´ottir [2]. Their approach involved
adding axioms for probabilistic choice to an underlying equational formulation of iteration theories.
Bandini and Segala [6] give a complete axiomatization of strong and weak probabilistic bisimilarity for an algebra including nondeterministic and prob- abilistic choice, but not recursion. One significant difference between their formulation and ours is that they introduce syntactic restrictions on the ap- plication of probabilistic choice and nondeterministic choice. For instance, the

distributive law (1) would be ill-typed in their setting.
Baier and Kwiatkowska [5] consider the combination of probability and nondeterminism from a domain-theoretic perspective. Like us they produce a model for a process algebra by solving a domain equation involving the proba- bilistic powerdomain. However they use the Hoare powerdomain, rather than the geometrically convex Plotkin powerdomain. Furthermore they introduce probability via an operator of action-guarded probabilistic choice rather than the unrestricted probabilistic choice operator that we model. Finally they do not axiomatize their semantics.
A radically different way to model probability and nondeterminism in do- main theory has been investigated by Varacca [21]. He models probabilistic choice using a monad of indexed valuations. This structure is more rigid than the usual probabilistic powerdomain (which is a quotient), and it supports a categorical distributive law over the Hoare powerdomain. Using this distribu- tive law he defines a combined monad of probabilistic and nondeterministic choice. The corresponding equational theory however does not include the law E ⊕p E = E.
Andova [3] considers the addition of probabilistic choice to the algebra ACP , studied extensively by de Bakker and his students. The pivotal issue in Andova’s work is how to extend the parallel composition operator of ACP to the algebra extended to include probabilistic choice, an issue that requires considerable delicate reasoning to resolve.
Finally, the paper den Hartog [11] presents an extensive consideration to the interactions between differing forms of nondeterministic and probabilistic choice, called local and global, and which correspond to internal and external choice operators.

A Probabilistic Calculus
We begin by introducing our calculus PE of probabilistic expressions. This is the language of [19] augmented with a nondeterministic sum operator. The grammar for PE terms is as follows.
E ::= X | 0 | aE | E + E | E ⊕p E | µXE
where a ∈ Act and 0 <p< 1.
Here X is a process variable, 0 is the inactive process, E + F is the nonde- terministic choice of E and F , and E ⊕p F is the probabilistic choice of E and
F . While the index p is restricted to the open interval (0, 1), it is convenient to allow E ⊕1 F as a synonym for E and E ⊕0 F as a synonym for F . We write fv(E) for the set of free variables in a term E, and we write E{F/X}

to denote the term obtained by substituting F for all free occurrences of X in
E. A closed term – i.e., one without free variables – is called a probabilistic agent.
It is convenient to have a notation for arbitrary finite nondeterministic and probabilistic sums. We write the sum E1 + (E2 + (··· + En ) ··· ) as
Σn	Ei. The empty summation Σ0	Ei stands for 0. We also write the sum

i=1
iΣ=1n

i<n and rn = j<n(1 − pj). Thus ri is the probability that the i-th summand is selected.
We use Ω as an abbreviation for µXX, and we think of this as the divergent process. Intentionally this is different from [19,2] where µXX is interpreted as the inactive process, denoted 0. (Despite this difference in intentions we claim that the axioms presented in Section 7 yield a conservative extension of the theory presented in [19,2].)
Example 2.1 We give an example to illustrate some basic intuitions about the interaction between probability and nondeterminism in the presence of unguarded recursion. Consider the following two processes:
P ≡ µX(aX ⊕ 1 (X + bX)) ,	(3)

2
Q ≡ µX(aX + (aX ⊕ 1 bX)) .	(4)
2
We first give an informal argument that P = Q. Each transition of P arises as the convex combination of the transitions of each summand of the probabilistic

choice operator ⊕ 1
2
after unwinding the recursion. The left-hand summand

can only do an a-action and become P again. One possibility for the right-
hand summand is to do a b-action and become P . We thus infer that one possible (probabilistic) transition of P is to do an a-action with probability 1/2 and a b-action with probability 1/2, and become P again in either case. This takes care of the right branch of the process Q.
We also can unwind the recursion, say n times, and then select a branch that results in a visible action – a or b. Because we also have the accumulated possibility of executing an a on each unwinding, the possible actions of P on such a sequence of unwindings together with their probabilities are to do
a with probability 2n−1 and to do b with probability  1 , and in either case
become P again. Since we have a continuous semantics, we infer that P can do a with probability 1 and then become P again, which takes care of the left branch of Q. This shows informally that P can do anything Q can.
The converse requires noting an important property of our semantics: a nondeterministic choice can be resolved by any probabilistic choice of the components. Since Q can either do a with probability 1, or do a and b with

equal probability, and then become Q again, this property implies Q can do any convex combination of these behaviors. This implies Q can do a with
probability 2n−1 or b with probability  1  for each n, and then become Q again,
2n	2n
which are the possible behaviors we deduced for P . Thus, on an informal basis,
we conclude that P = Q.
Actually, we can provide a formal argument by anticipating the axioms in Table 1 from Section 7; here is a two line equational proof that P = Q:
µX(aX ⊕ 1 (X + bX)) = µX((aX ⊕ 1 X)+ (aX ⊕ 1 bX)) by D1
		
2	2	2
= µX(aX + (aX ⊕ 1 bX)) by F2 .
2



Powerdomains

In this section we bring together the results from domain theory that we re- quire to build and analyze our model. In particular, we define the combined powerdomain Pow(D) and the attendant probabilistic and nondeterministic choice operators. The constructs themselves are what is important for under- standing the paper. We carefully state some of the hypotheses required to make the constructions work (e.g., continuity and coherence), but we think that these technicalities may safely be omitted on a first reading.
For us a domain is a particular type of ordered set, specifically a continuous dcpo with a bottom element. A Scott-continuous map between domains is a monotone function that preserves directed suprema. If (D, ±) is a domain and L ⊆ D, we write ↑ L for the set {x ∈ D : (∃y ∈ L) y ± x}, and we write
↓ L for the set {x ∈ D : (∃y ∈ L) x ± y}.
As usual, we will consider a domain D as a topological space in its Scott topology. Recall that U ⊆ D is open in the Scott topology if it is an upper set (U = ↑ U ) and is inaccessible by directed suprema: for each directed set A, A ∈ U implies A ∩ U /= ∅. Another relevant topology for us is the Lawson topology. This is a Hausdorff refinement of the Scott topology, obtained by adding as sub-basic opens those sets of the form D \ ↑ d, where d ∈ D. We will be particularly concerned with domains that are compact in the Lawson topology: the so-called coherent domains. This class is important for us in that it is closed under the probabilistic powerdomain (cf. [9] or [7]) and the Plotkin powerdomain, and because the latter admits a topological on coherent
domains.

The Probabilistic Powerdomain
Next we introduce the probabilistic powerdomain VD of a domain D. The elements of VD are valuations on D. These are like probability measures, but can be defined using purely topological data. Technically, a valuation on D is a mapping ν : ΣD → [0, 1] from the lattice (ΣD, ⊆) of Scott open subsets of D to the unit interval satisfying the following laws.
strictness
ν∅ =0 and νD =1 
modularity
ν(U ∪ V )+ ν(U ∩ V )= νU + νV for all U, V .
Scott continuity
ν( i∈I Ui)= supi∈I νUi for every directed family {Ui}i∈I.
The set of all valuations VD becomes a domain when equipped with the pointwise order: σ ± ν iff σU ≤ νU for all U ∈ ΣD. Furthermore, VD is coherent whenever D is coherent [9,7].
The Scott topology on VD can be described directly in terms of the Scott topology on D using a probabilistic modality. The sub-basic opens are the sets
pU = {ν ∈ VD : νU > p}
where 0 ≤ p ≤ 1 and U ⊆ D is Scott open.
Each element x ∈ D gives rise to a valuation δx defined by δx(U ) = 1 if
x ∈ U , and δx(U )=0 otherwise. A simple valuation has the forΣm	a∈A raδa
A central result about simple valuations is the Splitting Lemma; this will be used in the proof of completeness of our equational axiomatization.
Lemma 3.1 (Jones [12]) Let σ = a∈A raδa and ν = b∈B sbδb be simple valuations on D. Then σ ± ν if and only if there exists a family of transport (or flow) numbers {ta,b | a ∈ A, b ∈ B}⊆ [0, 1] satisfying
For each a ∈ A, Σb∈B ta,b = ra,
For each b ∈ B, Σa∈A ta,b = sb,
ta,b /=0 implies a ± b.
The Geometrically Convex Plotkin Powerdomain
Let D be a coherent domain. We say that L ⊆ D is a lens if L is nonempty, compact in the Lawson topology and order convex, i.e., L = ↑ L ∩ ↓ L. We let PD denote the set of all such lenses together with the emptyset, and we denote a typical element of Pow(D) by X or Y . The set PD becomes a

coherent domain when equipped with the Egli-Milner order. This is defined by
L ± L' iff ↓ L ⊆ ↓ L' and ↑ L' ⊆ ↑ L
for lenses L and L', and {⊥} ± ∅.
The Scott topology on PD can be described directly in terms of the Scott topology on D using ‘may’ and ‘must’ modalities. The sub-basic opens are the sets
o U = {X ∈ PD | X ⊆ U }
U = {X ∈ PD | X ∩ U /= ∅}
where U ⊆ D is Scott open.
Our model for probabilistic and nondeterministic choice is a retraction of PVD. In order to define this we first need to recall the concepts of order- convex closure and geometrically-convex closure. Given a Lawson compact set S ⊆ VD, the order-convex closure of S is defined to be ↑ S ∩ ↓ S. The geometrically-convex closure of S is defined to be {pσ + (1 − p)ν : σ, ν ∈ S, 0 ≤ p ≤ 1}. An important fact is that both closure operators preserve Lawson compactness.
We now define the composite closure operator
⟨−⟩ : PVD → PVD
by taking ⟨X⟩ to be the order-convex closure of the geometrically-convex clo- sure of X. (Note that the order-convex closure of a geometrically convex set is still geometrically convex.) Then ⟨−⟩ is a Scott continuous idempotent map whose image, which we denote Pow(D), is precisely the collection of geometrically-convex elements of PVD. It follows that Pow(D) is a retraction of PVD and is thus a coherent domain in the inherited order.
We can equip Pow(D) with operations for probabilistic and nondetermin- istic sum as follows. Given S and S' in Pow(D) the nondeterministic sum X + Y is defined by
X + Y = ⟨X ∪ Y ⟩.
The probabilistic sum X ⊕p Y is defined by
X ⊕p Y = ⟨ {pσ + (1 − p)ν : σ ∈ S, ν ∈ S'}⟩ .

Given a finite set F = {ν1,..., νn}⊆ VD we define {|ν1,... , νn|} to be the element of Pow(D) generated by L, that is,
{|ν1,... , νn|} = ⟨↑ F ∩↓ F ⟩ .

By standard arguments, both + and ⊕p are Scott continuous as maps from Pow(D) × Pow(D) to Pow(D). We also note that for lenses L and L', L ⊕p L' converges to L as p tends to 1 and it converges to L' as p tends to 0. Lastly we remark that the distributive law (1) holds in Pow(D), essentially because the operation of probabilistic choice on Pow(D) is defined pointwise. We refer the reader to Mislove [16] and Tix [20] for further explanation of these points.

Separated Sum
The remaining construction on domains that we use is separated sum. Let Act be a finite set of actions, which we fix once and for all. Given a domain D write  a∈Act D for the Act-fold coprodu ct of D with itself, with a new bottom

with a ∈ Act and d ∈ D, and ⟨a, d⟩± ⟨a', d'⟩ iff a = a' and d ± d'.

The Domain Model
To find a domain model of PE we solve a probabilistic version of Abramsky’s domain equation for bisimulation [1]. More precisely, we construct a domain D for which there is an isomorphism

ι : D ∼= Pow( 
a∈Act
D ) .	(5)

General domain theory [10] tells us that not only can we find such a domain, but there is a canonical such choice—the so-called minimal invariant. We think of this domain as a universal Segala-Lynch probabilistic automaton [18]. Following this intuition, if ν ∈ ι(d), then we write d → ν—read d has capability ν.
Below we show how to interpret terms of the process algebra PE in the domain D. The semantics of a term E relative to an environment ρ (mapping variables to elements of D) is denoted [E]]ρ. Recursion is handled in the stan- dard way using least fixed points. In the following definitions of the semantic map we have elided the isomorphism ι : D → Pow( a∈Act D) for notational transparency.
[[0]]ρ = ∅
[[aE]]ρ = {| δ⟨a,[[E]]ρ⟩ |}
[[E + F ]]ρ = [[E]]ρ + [[F ]]ρ
[[E ⊕p F ]]ρ = [[E]]ρ ⊕p [[F ]]ρ
[[µXE]]ρ = µθ[[E]](ρ[X '→ θ]) .

These equations define a compositional map from PE to our domain model
D, thus giving a denotational model for our process calculus.
A Domain Logic
Next we introduce a domain logic L for D. We use this logic as a tool to show that one element of D is below another. In particular, it is used in the proof of the soundness of some of the equational rules below (cf. Table 1). The logic is based on the topological description of the various functors underlying the construction of D. In order to fully capture a domain via a logic one should also give a proof system for telling when two formulas represent the same open set, cf. Abramsky [1]. For our purposes however this is unnecessary.
In the grammar for L there are two phrase types: state formulas and probabilistic formulas. This corresponds to the alternation of nondeterministic and probabilistic choice in the domain equation. State formulas are denoted by Roman letters and probabilistic formulas by Greek letters:
(state formulas) f ::= f ∧ f | f ∨ f | ♦ϕ | oϕ
(probabilistic formulas) ϕ ::= T| ⊥| ϕ ∧ ϕ | ϕ ∨ ϕ | ⟨a⟩pf
where a ∈ Act, and p ∈ [0, 1].
The modal depth of formulas is defined by
md(oϕ)= md(♦ϕ)= md(ϕ)+1 md(⟨a⟩pf )= md(f ) .
As usual, the modal depth of a conjunction (disjunction) is the maximum of the modal depth of the conjuncts (disjuncts).
We define a satisfaction relation between elements of D and state formulas, and between elements of V( a∈Act D) and probabilistic formulas.
d ▶ ♦ϕ iff (∃ν)(d → ν ∧ ν ▶ ϕ) d ▶ oϕ iff (∀ν)(d → ν ⇒ ν ▶ ϕ)
ν ▶ ⟨a⟩pf iff ν{⟨a, d⟩ : d ▶ f } >p .
Given d, d' ∈ D, we say that d “n d' if d ▶ f implies d' ▶ f for each formula f with md(f ) ≤ n. Similarly, given ν, σ ∈ V( a∈Act D), we say that ν “n σ if ν ▶ ϕ implies σ ▶ ϕ for each formula ϕ with md(ϕ) ≤ n.
Using the modal descriptions of the topologies on the powerdomains, and the inductive construction of the domain D, one can prove the following result.

Theorem 4.1 Given d, d' ∈ D, d ± d' iff d “n d' for all n ∈ N.
In other words, the domain logic characterizes the order on the domain D.

Operational Semantics
In this section we define an operational semantics for PE. Later, in Section 6 we show that the domain-theoretic semantics from Section 4 is fully abstract with respect to a form of probabilistic bisimilarity we define below.
Let PE denote the set of all PE terms and PA the set of probabilistic agents, i.e., the closed terms. We let a∈Act PE stand for the flat poset of ele- ments ⟨a, E⟩, where a ∈ Act and E ∈ PE, ordered discretely, and with a bot- tom element ⊥ adjoined. The operational semantics of PE can be seen as pre- senting a transition relation E → µ, where E is a term and µ ∈ V( a∈Act PE) is a (necessarily simple) valuation. In actual fact we define a function inits(E) which gives the initial behaviours of a term E, i.e., inits(E)= {µ | E → µ}.
The set inits(E) is geometrically convex by definition. Since each transition E → µ can be seen as arising from a scheduler resolving the nondeterminism in E, this last requirement corresponds to the possibility of having proba- bilistic schedulers. As we have explained earlier, this feature is crucial for our semantics to satisfy the distributive law (1) of probabilistic choice over nondeterministic choice. It also will be the case that inits(E) is order-convex; given the notion of bisimulation presented in Definition 6.2 it is harmless to identify a set with its order-convex closure in this context.
As we mentioned earlier, a complicating factor in defining an operational semantics for PE is the presence of unguarded recursion. For a simple example of this phenomenon, consider the term P ≡ µX((aX ⊕ 1 X)+ bX). It is clear
2
that one possible transition is P → δ⟨b,P ⟩. Slightly less obviously, another
possible transition is P → δ⟨a,P ⟩. This transition corresponds to a scheduler which always selects the left-hand summand in the body of the recursion; under such a scheduler it is guaranteed that the action a will occur eventually. In the purely probabilistic setting, Stark and Smolka [19] handle unguarded recursion by separately calculating the possible transitions of a term and the probabilities with which they occur. These probabilities are calculated as least fixed points. Our approach is similar in spirit, but necessarily more complex
in the presence of nondeterminism.
To handle unguarded recursion we introduce environments in our opera- tional semantics. Given a set of variables X = {X1,... , Xn}, an environment is a function
σ : {X1,..., Xn}→ Pow(  a∈Act PE)
giving the initial transitions of each variable Xi. We write inits(E, σ) for the initials of a term E in free variables X˜ with respect to the environment σ; this
induction: first by induction on the number of occurrences in E of a subterm

of the form µXF which is not within the scope of a prefixing operator, and then by structural induction on E. The clauses in the definition are as follows:
inits(0, σ)= ∅
inits(X, σ)= σ(X)
inits(aE, σ)= {δ⟨a,E⟩}
inits(E + F, σ) = inits(E, σ) + inits(F, σ)
inits(E ⊕p F, σ) = inits(E, σ) ⊕p inits(F, σ)
inits(µXE, σ) = µθ inits(E', σ[X '→ θ]), where E' arises by substituting
µXE for all guarded occurrences of X in E.
The last clause says that inits(µXE, σ) is the least solution of the equation
θ = inits(E', σ[X '→ θ])
in the domain Pow( a∈Act PE). Observe that if X is guarded in E, then E' is just E{µXE/X}, so X does not occur free in E' and the given fixed point is reached in one step. In fact the fixed point in this clause is solely directed toward unguarded occurrences of the variable X.
Example 5.1 Consider the agent P ≡ µX((aX ⊕ 1 X)+ bX). Then inits(P )

2
is the least solution of the equation
θ = inits((aP ⊕ 1 X)+ bP, [X '→ θ]) .

2
This can be constructed as the join in Pow(  a∈Act PA) of the following chain
{| δ⊥ }| , {| δ⟨b,P ⟩, 1 δ⟨a,P ⟩ + 1 δ⊥ }| , {| δ⟨b,P ⟩, 3 δ⟨a,P ⟩ + 1 δ⊥, 1 δ⟨a,P ⟩ + 1 δ⟨b,P ⟩ }| , ··· 
2	2	4	4	2	2
which is equal to {|δ⟨a,P ⟩, δ⟨b,P ⟩}| .

Full Abstraction
Theorem 6.1 expresses the compatibility of the operational semantics defined above with the denotational model D ∼= Pow( a∈Act D) from Section 4. Tech- nically it says that the denotational map [−]] : PA → D is a coalgebra homo- morphism, cf. [1].
Theorem 6.1 The following diagram commutes
PA 	inits	zP,ow(	PA)

[[−]]
, 
P ow(‘a∈Act[[−]])
z	 , 

Proof. (Sketch) The proof follows the inductive structure of the definition of inits(P ). The induction cases for prefixing, nondeterministic choice and prob- abilistic choice are immediate and exploit the similarity of the corresponding clauses in the definitions of inits and [− ]. The induction case for recursion relies on a compatibility between the respective fixpoint constructions in the operational and denotational semantics of recursion.	 

Bisimulation and Modal Logic
Our domain-theoretic semantics for probabilistic agents corresponds to a ver- sion of probabilistic bisimulation. Definitions of bisimulation for agents fea- turing both probabilistic choice and nondeterministic choice have appeared in [18,13]. The definition below is slightly different since we take account of divergence in our operational semantics.
Let R be a relation on PA. We extend R to a relation on a∈Act PA by defining
⟨a, E⟩ R ⟨b, F ⟩ iff a = b and ER F
⊥ R ⟨b, F ⟩ for all b, F
⊥ R ⊥
Next we defi ne the relation “R on V( a∈Act PA) by µ “R ν if µ(O) ≤ ν(R(O))
	
Definition 6.2 We say that a relation R on PA is a partial probabilistic bisimulation [1] if P R Q implies
P → µ implies (∃ν)(Q → ν and µ “R ν)
Q → ν implies (∃µ)(P → µ and µ “R ν).
If agents P and Q are related by a partial probabilistic bisimulation then we write P ± Q.
We can use the operational semantics for PE to define a satisfaction re- lation between probabilistic agents and formulas of the logic L introduced in Section 4. In fact this definition is syntactically almost identical to the corresponding definition in Section 4. The three clauses are
P ▶ ♦ϕ iff (∃ν)(P → ν ∧ ν ▶ ϕ) P ▶ oϕ iff (∀ν)(P → ν ⇒ ν ▶ ϕ) ν ▶ ⟨a⟩pf iff ν{⟨a, P ⟩ : P ▶ f } >p .
As a corollary of the compatibility of the operational and denotational semantics for PE, as expressed in Theorem 6.1, we obtain the following result relating the two semantics for the logic L.

Corollary 6.3 For each probabilistic agent P and formula f on L, P ▶ f iff
[[P ]] ▶ f.
Proof. By induction on the modal depth of f , using Theorem 6.1 for the induction step.	 
The following result says that the logic L characterizes probabilistic agents up to bisimilarity. It is a slight variant of [13, Theorem 8].
Theorem 6.4 Given probabilistic agents P and Q, P ± Q iff P ▶ f implies
Q ▶ f for all formulas f ∈ L.
The following theorem is the main result of this section. It says that the domain semantics for probabilistic agents is fully abstract with respect to partial probabilistic bisimilarity.
Theorem 6.5 Given probabilistic agents P and Q, P ± Q iff [[P ]] ± [[Q]].
Proof.
P ± Q iff (∀f ∈ L)(P ▶ f ⇒ Q ▶ f ) (by Theorem 6.4)
iff (∀f ∈ L)([[P ]] ▶ f ⇒ [[Q]] ▶ f )  (by Corollary 6.3)
iff [P ]] ± [[Q]] (by Theorem 4.1) .


Equations
The following table gives a list of (in)equations between PE terms. These will be shown to be sound and complete with respect to the domain model D.
The semilattice equations N1–N4 are exactly the axioms for strong bisim- ilarity from [15]. The equations P1–P3 are the axioms for probabilistic bisim- ilarity from [19]. Nondeterministic choice and probabilistic choice interact via the distributive laws D1 and D2. The remaining equations concern recursion. Rule F4 implies that guarded recursions have unique fixed points. (A variable
X is guarded in a term E if each free occurrence of X in E appears in a subterm of the form aE'.) Rules F1 and F2 show how to eliminate unguarded variables from recursive definitions.
One can think of the distributive laws D1 and D2 as saying that in an expression E ⊕p F the nondeterministic choices of E and F are resolved first, and then combined probabilistically. In particular, if F represents the empty choice, as in D2, then E ⊕p F is inert. On the other hand, if we are guided by the dual distributive law, as in [13], then E ⊕p 0 denotes an agent which behaves like E with probability p and 0 with probability 1 − p. We also note


Fig. 1. (In)equations for PE terms
that in the process algebras studied in [5,6] the nil process 0 cannot appear as a summand in a probabilistic choice owing to certain syntatic restrictions.
We write ▶ E ± F to indicate that there is a deduction of E ± F . The provability relation ▶ is extended pointwise to term vectors.
One straightforward but important consequence of axioms D1 and P1 is
▶ E + F = E + (E ⊕p F )+ F.	(6)
A special case of this convexity equation occurs as an axiom in the presentation of Bandini and Segala [6].
Following the pattern of [15,19] the completeness of this system hinges on a couple of important transformations that can be effected by combinations of the equations. The first of these is the standard de Bakker-Bekic-Scott construction of solutions of mutually recursive definitions. This is embodied in the following proposition, which is [15, Theorem 5.7].

Proposition 7.1 (Solution Lemma)	Let X˜ = (X1,... , Xm) and Y˜ =
(Y1,..., Yn) be vectors of distinct variables, and G˜ = (G1,... , Gm) a vector of terms with free variables in (X˜, Y˜) in which each Xi is guarded. Then there exist expressions E˜ = (E1,... , Em) with free variables in Y˜ such that
▶ E˜ = G˜{E˜/X˜}.
Moreover, if F = (F1,... , Fm) is a vector of terms with free variables in Y such that ▶ G{F /X}± F , then ▶ E ± F .
Definition 7.2 A simple term is either Ω, a variable, or a prefix aE.  A
standard form is a term of the form
m  n(i)
Σ Σ⊙ rij Eij
i=1 j=1
where each Eij is a simple term.
Thus a standard form is a nondeterministic sum, with each summand being a probabilistic sum of simple terms. If a term aE occurs as one of the Eij then we say that E is a derivative of the standard form.
The next proposition says that each PE term E is provably equal to the first coordinate of term vector E which is the solution of a recursive definition.
Proposition 7.3 (Standard Forms) For any term E with free variables in Y , there are terms E1,... , Ek also with free variables in Y such that ▶ E = E1 and each Ei is provably equal to a standard form where each derivative is taken from the set {E1,... , Ek}. Thus, for instance,

Σ ,Σn(i)
n'(i)	

▶ E1 =
 ⊙ rijaij Ef (i,j) ⊕p(i) Σ⊙ sij Yg(i,j) ⊕q(i) Ω .


Similar equations hold for each of the Ei.
Proof. (Sketch) The proof is by structural induction on E. The distributive laws D1 and D2 are used to handle the inductive case E ≡ F ⊕p G. The fixed point equations F1–F3 are used to handle the inductive case E ≡ µXF . 

Soundness and Completeness
The following theorem, the main result of this paper, asserts that the equations above are sound and complete for the model D.

Theorem 8.1 ▶ E ± F iff [[E]] ± [[F ]].
The soundness of the axioms N1–N4, P1–P3, D1 and D2 follows imme- diately from the relevant algebraic properties of the operations + and ⊕p on Pow(D). We can now bootstrap the soundness of the fixed-point laws F1–F4. We explain two cases in some detail in order to show how the domain-theoretic underpinnings can be put to work.

Soundness of F2
For simplicity, to avoid mentioning environments, we assume that the only free variable occurring in E and F is X. We also omit semantic brackets, treating terms E and F directly as functions on our semantic domain D.
Suppose d ∈ D is a fixed point of E + F , that is, d = E(d)+ F (d). Then (E(d) ⊕p d)+ F (d)= (E(d) ⊕p (E(d)+ F (d))) + F (d)
= E(d)+ (E(d) ⊕p F (d)) + F (d) (distributivity)
= E(d)+ F (d) (convexity)
= d. 
Thus d is also a fixed point of (E ⊕p X)+ F . Since recursion is modelled by
least fixed points, it follows that [µX((E ⊕p X)+ F )]] ± [[µX(E + F )]].
On the other hand, suppose d = (E(d)⊕pd)+F (d). We show that d is also a prefixed point of E +F and conclude that [µX(E +F )]] ± [[µX((E ⊕p X)+F )]]. To this end, consider the following derivation.
d = (E(d) ⊕p d)+ F (d)
= (E(d) ⊕p ((E(d) ⊕p d)+ F (d))) + F (d)
= (E(d) ⊕p (E(d) ⊕p d)) + (E(d) ⊕p F (d)) + F (d)
= (E(d) ⊕2p−p2 d)+ (E(d) ⊕p F (d)) + F (d) .
One can further transform the last expression above by rewriting the subterm
d to (E(d) ⊕p d)+ F (d) and then simplifying using distributivity and convexity
(2). By repeatedly performing these transformations one obtains a sequence of expressions of the form
(E(d) ⊕rn d)+ (E(d) ⊕sn F (d)) + F (d)
that are all equal to d and such that rn and sn tend to 1. From the continuity properties of the operators + and ⊕p this sequence converges in the Scott topology to E(d)+ F (d). It follows that E(d)+ F (d) ± d. Thus d is indeed a prefixed point of E + F .

Soundness of F4
Suppose that F is a term in which the variable X is guarded. Furthermore suppose that E and E' are terms with [E]] = [[F {E/X}]] and [[F {E'/X}]] ± [[E']], that is, E is a fixed point of F and E' is a prefixed point of F . To demonstrate the soundness of F4 we have to show that [E]] ± [[E']]. This follows from the lemma below (by taking G ≡ X).
Lemma 8.2 Let G be a term with fv(G) ⊆ fv(F ); then [[G{E/X}]] ± [[G{E'/X}]].
Proof. We prove by induction that [G{E/X}]] “n [[G{E'/X}]] for each n ∈
N. By Theorem 4.1 this entails the desired result. For simplicity, to avoid mentioning environments, we suppose that X is the only variable occurring free in F .
The variable X is guarded in G{F/X}. Thus G{F/X} has standard form
Σ ,Σn(i)	
⊙ rijaij Gij  ⊕p(i) Ω	.
i=1	j=1
From the soundness of all the laws excepting F4 it follows that each term has the same denotation as its standard form. Thus
[[G{E/X}]] = [[G{F {E/X}/X}]]
= [[G{F/X}{E/X}]]
Σ ,Σn(i)	

= [[
Similarly one has
⊙  rijaijGij{E/X} ⊕p(i) Ω  ]] .	(7)
i=1	j=1

Σ ,Σn(i)	

[[G{E'/X}]] ± [[
⊙  rijaijGij{E'/X} ⊕p(i) Ω  ]] .	(8)
i=1	j=1

The induction hypothesis entails that [Gij{E/X}]] “n [[Gij{E'/X}]] for each pair i, j. The induction step relies on the structural similarities be- tween the standard forms (7) and (8). In particular, for each capability ν of [[G{E/X} ] there is a capability σ of [G{E'/X}]] with ν “n σ. Conversely for each capability σ of [G{E'/X} ] there is a capability ν of [G{E/X}]] with ν “n σ. It immediately follows that [G{E/X}]] “n+1 [[G{E'/X}]].	 

Completeness
Below we give a skeleton proof of the completeness of our axioms.

Suppose E and F are terms, which for simplicity are assumed to be closed, such that [E]] ± [[F ]. By Proposition 7.3 there is a vector of closed terms E˜ = (E1,... , Ek), and a vector G˜ = (G1,... , Gk) of terms in free variables X˜ = (X1,... , Xk), such that each Gi is a standard form, ▶ E = E1, and
▶ E˜ = G˜{E˜/X˜} .

Similarly, there is a vector of closed terms F = (F1,... , Fl), and a vector of terms H = (H1,... , Hl) in variables Y = (Y1,... , Yl), such that each Fj is a standard form, ▶ F = F1, and
▶ F˜ = H˜{F˜/Y˜} .
˜ Thus E˜ and F˜ can be seen as fixed points of two different term vectors
‘product vector’ P , all of whose free variables are guarded, and which (roughly speaking) has E as a fixed point and F as a prefixed point. One then appeals to Proposition 7.1 to conclude that ▶ E ± F . A key technical ingredient in the construction of P is the Splitting Lemma. This is used to realize probability distributions occurring in G and H as marginals of joint distributions in P .
Next we give a more detailed recipe for constructing the term vector P . Let R = {(i, j) : [Ei]] ± [[Fj]]}. Thus, in particular, (1, 1) ∈ R. Let Z be a vector of variables indexed over R. We define P to be a vector of terms indexed over R such that each component of P is a term in free variables Z in standard form. As an example we illustrate how to construct the term P(1,1).
Suppose that E1 has the following standard-form expansion
Σ ,Σn(i)	

▶ E1 =
⊙ rijaij Ef (i,j) ⊕p(i) Ω	.	(9)
i=1	j=1

Also we have the standard-form expansion of F1,
m' ,n'(i)	
▶ F1 = Σ Σ⊙ r' a' Ff'(i,j) ⊕p'(i) Ω .	(10)

Since [E1]] ± [[F1]], by the definition of the order on the geometrically convex powerdomain, we have that each summand in (9) (of the outer sum) is less than some convex combination of summands in (10). By the convexity equation
(6) there is no loss of generality in assuming that each summand in (9) is less

than some summand in (10). For instance, suppose that the first summand in
(9) is less than the first summand in (10), i.e.,


n(1)
n'(1)

[[Σ⊙  r1ia1iEf(1,i) ⊕p(1) Ω]] ± [[Σ⊙  r'
' Ff '(1,j) ⊕p'(1) Ω]] .

i=1	j=1
Applying the Splitting Lemma to this inequality, there is a family sij of non- negative real numbers such that whenever sij > 0, then
a1i = a'
f (1, i)Rf '(1, j)

n'(1)
j=1
ij = r1i

Σn(1) sij ≤ r' .
We thus generate the term
i=n(1),j=n'(1)
⊙ sija1iZ(f (1,i),f ' (1,j)) ⊕p(1) Ω .
i,j=1
Each inequality between summands in the standard forms for E1 and F1 gener- ates a term like the one above. Then P(1,1) is taken to be the nondeterministic sum of the terms so generated.
Finally, the conditions on sij generated by the Splitting Lemma guarantee that E is provably a fixed point of the term vector P , and F is provably a prefixed point of the same term vector.

Summary
The main construction of this paper uses a powerdomain combining proba- bilistic choice and nondeterminism as the basis for a domain equation whose solution gives a denotational model that is sound and complete for the axioms we listed in Section 7. The other main contribution of the paper is Theo- rem 6.5 which asserts that the domain model is fully abstract with respect to partial probabilistic bisimilarity. These results have their inspiration in two preceding works: the development of a domain equation for bisimulation from [1], and the presentation of a powerdomain combining nondeterminism and probabilistic choice in [16,20].
Analogous results have been devised for other models for probabilistic choice, a number of which have been mentioned in Subsection 1.1. While some of these related works consider probabilistic choice and nondeterminism

together, we know of no presentation of a sound and complete logic for a model combining both forms of nondeterminism with recursion. Furthermore, we use a denotational model to reason about the algebra we study. We believe that attempting to analyze our algebra directly in terms of a purely operational semantics would significantly increase the complexity of many of the proofs. A major feature of our approach is our ability to use “off-the-shelf” results from domain theory, such as the topological representation of our powerdo- main model, and the Splitting Lemma, which is a central result about the probabilistic powerdomain.
There is a close link between our model and that of [19], which we have already alluded to in Subsection 1.1 and elsewhere. In [19], Stark and Smolka consider a variant of CCS in which probabilistic choice replaces nondetermin- istic choice. If we restrict attention to the subalgebra of purely probabilistic processes (i.e., those which do not employ nondeterminism), then two such processes are equivalent in our semantics if and only if they are equivalent in the Stark–Smolka semantics.
Furthermore, in the Stark–Smolka approach, the process µX X has no transitions. This is reflected in their semantics by the fact that processes make transitions to subprobability distributions – ones with total mass ≤ 1. On the other hand, our semantics gives the process µX X a single transition, to the probability measure δ⊥, and in our semantics, processes make transitions to probability distributions. The link between the two is that a process P in the Stark–Smolka semantics with total mass v < 1 corresponds to the process in our semantics that has component (1−v)δ⊥, and whose remaining distribution is the same as in the Scott–Smolka approach.

References
S. Abramsky. A Domain Equation for Bisimulation. Information and Computation 92 (1991),
pp. 161–218.
L. Aceto, Z. Esik and A. Ing´olfsdo´ttir. Equational Axioms for Probabilistic Bisimilarity. In
Proceedings of 9th AMAST, Lecture Notes in Computer Science 2422 (2002), pp. 239–253.
S. Andova, Process algebra with probabilistic choice, Proc. ARTS’99, Bamberg, Germany, J.-P. Katoen, ed., Lecture Notes in Computer Science 1601 (1999), Springer-Verlag, pp. 111-129.
J. Baeten, J. Bergstra and S. Smolka. Axiomatizing probabilistic processes: ACP with generative probabilities. Information and Computation 121(2) (1995), pp. 234–255.
C. Baier and M. Kwiatkowska. Domain Equations for Probabilistic Processes. Mathematical Structures in Computer Science 10 (2000), pp. 665–717.
E. Bandini and R. Segala. Axiomatizations for probabilistic bisimulation. Proceedings of ICALP 2001, Lecture Notes in Computer Science2076 (2001), pp. 370–381.
F. van Breugel, M. Mislove, J. Ouaknine and J. Worrell. An intrinsic characterization of approximate probabilistic bisimilarity. Proceedings of FOSSACS 2003, Lecture Notes in Computer Science 2620 (2003), Springer Verlag, pp. 200-215.


R. van Glabbeek, S. Smolka and B. Steffen. Reactive, generative and stratified models of probabilistic processes. Information and Computation 121:1 (1995), pp. 59–80.
A. Jung and R. Tix. The Troublesome Probabilistic Powerdomain. In Third Workshop on Computation and Approximation, Proceedings. Electronic Notes in Theoretical Computer Science 13 (1998), http://www.elsevier.nl/locate/entcs/volume13.html .
G. Gierz, H. Hofmann, K. Keimel, J. Lawson, M. Mislove, D. Scott. Continuous Lattices and Domains, Cambridge, 2003.
J.I. den Hartog, Probabilistic Extensions of Semantical Models, PhD thesis, Vrije Universiteit Amsterdam, 2002.
C. Jones. Probabilistic nondeterminism, PhD Thesis, Univ. of Edinburgh, 1990.
B. Jonsson, K. Larsen and W. Yi. Probabilistic Extensions of Process Algebras. In J.A. Bergstra, A. Ponse and S. Smolka, editors, Handbook of Process Algebra, pages 685–710, Elsevier, 2001.
K.G. Larsen and A. Skou. Bisimulation through Probabilistic Testing. Information and Computation 94(1) (1991), pp. 1–28.
R. Milner. A complete inference system for a class of regular behaviours. Journal of Computer and System Sciences 28 (1984), pp. 439–466.
M. Mislove. Nondeterminism and probabilistic choice: obeying the laws. In Proceedings 11th CONCUR, Lecture Notes in Computer Science 1877 (1999), pp. 350–364.
C. Morgan, A. McIver, K. Seidel, J. Sanders. Refinement-oriented probability for CSP, Oxford University Computing Laboratory Technical Report TR-1294, 1994.
R. Segala and N. Lynch. Probabilistic simulations for probabilistic processes. Proceedings of CONCUR 94, Lecture Notes in Computer Science 839 (1994), pp. 481–496.
E.W. Stark and S.A. Smolka. A complete axiom system for finite-state probabilistic processes. In Proof, Language, and Interaction: Essays in Honour of Robin Milner. MIT Press, 2000.
R. Tix. Continuous D-cones: Convexity and Powerdomain Constructions. PhD thesis, Technische Universit¨at Darmstadt, 1999.
D. Varacca. The Powerdomain of Indexed Valuations. In Proceedings of 17th LICS, IEEE Computer Society Press, 2002.
