 Electronic Notes in Theoretical Computer Science 97 (2004) 125–153 
www.elsevier.com/locate/entcs




On the Expressiveness of Relative-Timed Coordination Models
I. Linden and J.-M. Jacquet1
Institute of Informatics University of Namur Namur, Belgium
K. De Bosschere2
ELIS
Ghent University Ghent, Belgium
A. Brogi3
Department of Computer Science University of Pisa
Pisa, Italy

Abstract
Although very simple and elegant, Linda-style coordination models lack the notion of time, and are therefore not able to precisely model real-life coordination applications. Nevertheless, industrial proposals such as TSpaces and JavaSpaces, inspired from Linda, have incorporated time constructs. This paper aims at a systematic study of the introduction of relative time in coordination models. It builds upon previous work to study the expressiveness of Linda, Linda extended with a delay mechanism and Linda primitives extended to support the duration of tuples and of the suspension of communication operations.
Keywords: Temporal coordination languages, semantics, expressiveness


1 Email: ili,jmj@info.fundp.ac.be
2 Email: kdb@elis.rug.ac.be
3 Email: brogi@di.unipi.it


1571-0661 © 2004 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2004.04.034

Introduction

As motivated by the constant expansion of computer networks and illustrated by the development of distributed applications, the design of modern software systems centers on re-using and integrating software components. This induces a paradigm shift from stand-alone applications to interacting distributed sys- tems, which, in turn, naturally calls for well-defined methodologies and tools aiming at integrating heterogeneous software components.
In this context, a clear separation between the interactional and the com- putational aspects of software components has been advocated by Gelernter and Carriero in [15]. Their claim has been supported by the design of a model, Linda ([9]), originally presented as a set of inter-agent communication prim- itives which may be added to almost any programming language. Besides process creation, this set includes primitives for adding, deleting, and testing the presence/absence of data in a shared dataspace.
A number of other models, now referred to as coordination models, have been proposed afterwards. Some of them extend Linda in different ways, for instance by introducing multiple dataspaces and meta-level control rules (e.g., Bauhaus Linda [22], Bonita [26], µLog [18], PoliS [11], Shared Prolog [5]), by addressing open distributed systems (e.g., Laura [33]), middleware web-based environments (e.g., Jada [12]), or mobility (e.g., KLAIM [23]). A number of other coordination models rely on a notion of shared dataspace, e.g., Concurrent Constraint Programming [29], Gamma [2] and Linear Objects [1], to cite only a few. A comprehensive survey of these and other coordination models and languages has been recently reported in [25].
However, the coding of applications reveals that data rarely has an eternal life and that services have to be provided in a bounded amount of time. For in- stance, a request for information on the web has to be satisfied in a reasonable amount of time. More crucial is even the request for an ambulance which, not only has to be answered eventually but within a critical period of time. The list could also be continued with software in the areas of air-traffic control, manufacturing plants and telecommunication switches, which are inherently reactive and, for which, interaction must occur in “real-time”.
Although there is an obvious application need, the introduction of time has not been deeply studied in the context of coordination languages and models, the notable exceptions being [4,24,27,28], yet proposed in the context of concurrent constraint programming, and [7,8].
This paper aims at contributing to the study of time in coordination lan- guages and models. More precisely, it builds upon [19] to perform a system- atic and exhaustive study of two extensions proposed there. These extensions

adopt the classical two-phase functioning approach to real-time systems illus- trated by languages such as Lustre ([10]), Esterel ([3]) and Statecharts ([16]). This approach may be described as follows. In a first phase, elementary ac- tions of statements are executed. They are assumed to be atomic in the sense that they take no time. Similarly, composition operators are assumed to be executed at no cost. In a second phase, when no actions can be reduced or when all the components encounter a special timed action, time progresses by one unit.
Although simple, this approach has been proved to be effective for mod- elling reactive systems. For instance, in many reactive systems, timed actions determine instants at which inputs are sampled or output is produced. In the coordination context, it still leaves room for several variants:
time may be introduced in the form of delays, stating that a communi- cation primitives should only be processed after some units of time;
time may also be introduced by stating that tuples on the tuple space are only valid for some units of time; similarly, requests for tuples cannot be postponed indefinitely;
time may finally be introduced by specifying intervals of time in which actions should be processed.
In this paper, we consider only the first two extensions. These extensions were introduced in [19] with some expressiveness results. However, as will be appreciated by the reader, this paper aims at a much deeper study of these expressiveness results. In particular, all the results of sections 3 and 4.2 are original with respect to [19] while the comparisons of sections 4.1 and 4.3 have lead to 8 new results with respect to [19].
We postpone the comparison with other work to section 5 when technical notions and results necessary for the discussion will have been introduced.
The rest of this paper is structured as follows. Section 2 introduces the families of languages under study in the paper. All of them rest on common sequential, parallel and choice operators. The Linda-like languages are first modelled as the L family. Relative delays are then introduced and relative timing primitives are defined thereafter. The expressiveness hierarchy of each family of languages, considered in isolation, is studied in section 3. The inter- family comparison is discussed in section 4. In order to keep the size of this paper within reasonable limits, only the most difficult proofs have been done. We refer the interested reader to [20] where all the results are demonstrated. Finally, in section 5 we draw our conclusion and discuss related work.



Fig. 1. Comparative syntax of the languages.
The families of languages
Common syntax and rules
All languages considered in this paper contain sequential, parallel and choice operators. They differ only in the set of communication primitives they em- body. As a result, assuming such a set, the syntax of a statement, subsequently called agent, is defined by the “general rule” of figure 1 and its semantics is provided by rules (S), (P), and (C) of figure 2. There, configurations are of the form ⟨A | σ⟩ where A represents the agent under consideration and σ represents a memory, to be specified for each family of languages.
Note that, for simplicity of presentation, only finite processes are treated here, under the observation that infinite processes can be handled by extending the results of this paper in the classical way, as exemplified for instance in [17].

The family of Linda-like concurrent languages
To start with, consider the family of languages L(X ), parameterized on the set of Linda-like communication primitives X . This set X consists of the basic Linda primitives out, in, and rd, for putting an object in a shared dataspace, getting it and checking for its presence, respectively, together with a primitive testing the absence of an object from the dataspace. Formally, the language is defined as follows.
Definition 2.1 Let Stoken be an enumerable set, the elements of which are subsequently called tokens and are typically represented by the letters t and
u. Define the set of communication actions Scom as the set generated by the



Fig. 2. Comparative semantics of the languages.

L rule of figure 1. Moreover, for any subset X of Scom, define the language
L(X ) as the set of agents A generated by the general rule of figure 1.
For any X , computations in L(X ) may be modelled by a transition system written in Plotkin’s style. Following the intuition, most of the configurations consist of an agent together with a multi-set of tokens denoting the tokens currently available for the computation. To easily express termination, we shall introduce particular configurations composed of a special terminating symbol E together with a multi-set of tokens. For uniformity, we shall abuse

language and qualify E as an agent. However, to meet the intuitive expectaion, we shall always rewrite agents of the form (E ; A), (E || A), and (A || E) as A. This is technically achieved by defining the extended set of agents as follows, and through simplifications derived by imposing a bimonoid structure.
Definition 2.2 Define the extended set of agents Seagent by the following grammar
Ae ::= E | C | A ; A | A || A | A + A
Moreover, we shall subsequently assert that the structure (Seagent, E, ; , || ) is a bimonoid and simplify elements of Seagent accordingly.
Definition 2.3 Define the set of stores Sstore as the set of finite multisets with elements from Stoken.
Definition 2.4 Define the set of configurations Sconf as Seagent × Sstore. Configurations are denoted as ⟨A | σ⟩, where A is an (extended) agent and σ is a multi-set of tokens.
Definition 2.5 The transition rules for the L agents are the general ones of figure 2 together with rules (T), (A), (N), (G) of that figure, where σ denotes a multi-set of tokens.
Rule (T) states that an atomic agent tell(t) can be executed in any store
σ, and that its execution results in adding the token t to the store σ. Rules
(A) and (N) state respectively that the atomic agents ask(t) and nask(t) can be executed in any store containing the token t and not containing t, and that their execution does not modify the current store. Rule (G) also states that an atomic agent get(t) can be executed in any store containing an occurrence of t, and it deletes the occurence of t from the resulting store. Note that the symbol ∪ actually denotes multiset union.
We are now in a position to define the operational semantics.
Definition 2.6
Let δ+ and δ− be two fresh symbols denoting respectively success and failure. Define the set of final states Sfstate as the set Sstore ×{δ+, δ−}.
Define the operational semantics O : Sagent → P(Sfstate) as the fol- lowing function: For any agent A,
O(A)= {(σ, δ+): ⟨A | ∅⟩ →∗ ⟨E | σ⟩}
∪ {(σ, δ−): ⟨A | ∅⟩ →∗ ⟨B | σ⟩ /→,B /= E}

Normal form
A classical result of concurrency theory is that modelling parallel composition by interleaving, as we did, allows agents to be considered in a normal form. We first define what this actually means, and then state the proposition that agents and their normal forms are equivalent in the sense that they yield the same computations.
Definition 2.7 Given a subset X of Scom, the set Snagent of agents in normal form is defined by the following rule, where N is an agent in normal form and c denotes a communication action of X .
N ::= c | c ; N | N + N
Proposition 2.8 For any agent A, there is an agent in normal form N such that O(A)= O(N ).

The family of Linda-like concurrent languages with delay
One way of introducing time in coordination languages is to postpone the exe- cution of the primitives for some period of time. This amounts to introducing a special delay primitive.
Definition 2.9 Let Stime be the set of positive integers. Define the set Sdcom as the set generated by the D rule of figure 1, where t ∈ Stoken and d ∈ Stime. Moreover, for any subset X of Sdcom \ {delay}, define the language D(X ) as the set of agents generated by the general rule of figure 1 for C ∈X ∪ {delay}.
The configurations to be considered here are similar to those used for the L family. However, time needs to be taken into account explicitly in the transitions. This done in two ways. First, by the introduction of a new rule (D1), which defines a new transition relation ~ to express the progress of time by one unit. In fact, the → reduction is used to model the first phase of the two-phase functioning approach to real-time while the ~ relation is used to model the second phase of this approach.
Second, as a result of the progress of time, delays under reduction, must be decreased by one unit. This is achieved by the A− construct. Note that, to avoid that the computation infinitely tries to decrease blocked non-delay primitives, rule (D1) requires A− to express some progress, namely to be different than A.
Finally, rule (D2) is introduced to reduce a delay of 0 unit of time to E. Summing up, the transitions to be considered are defined as follows.

Definition 2.10 Define the set of configurations Sdconf as Seagent'×Sstore, where Seagent' is the set of extended agents defined as in definition 2.2 but by taking C ∈ Sdcom instead of C ∈ Scom.
Definition 2.11 Given an agent A ∈ D(X ), we denote by A− the agent defined inductively as follows where d > 0


tell(t)− = tell(t) ask(t)− = ask(t) nask(t)− = nask(t)
get(t)− = get(t) delay(0)− = delay(0) delay(d)− = delay(d − 1)
(B ; C)− = B− ; C
(B || C)− = B− || C−
(B + C)− = B− + C−

Definition 2.12 Define the transition rules for the D agents as the general ones of figure 2 and rules (T), (A), (N), (G), (D1) and (D2) of that figure.
The operational semantics is defined by integrating the two phase-relations in one relation.
Definition 2.13
Let '−→ be the relation defined by ⟨A | σ⟩ '−→ ⟨B | τ ⟩ iff ⟨A | σ⟩→ ⟨B |
τ ⟩ or ⟨A | σ⟩ ~ ⟨B | τ ⟩.
Define the operational semantics Od : D(Sdcom) → P(Sfstate) as the following function: For any timed agent A,
Od(A)= {(σ, δ+): ⟨A | ∅⟩ '−→∗ ⟨E | σ⟩}
∪ {(σ, δ−): ⟨A | ∅⟩ '−→∗ ⟨B | σ⟩ /'−→,B /= E}

The family of Linda-like concurrent languages with relative durations
A second way of introducing time in the family L(X ) consists of enriching the primitives ask, nask, get, and tell themselves by durations. Formally, the new family of languages R(X ) is defined as follows.
Definition 2.14 Define the set Stcom of timed communication primitives as the one generated by the R rule of figure 1, where t ∈ Stoken and d ∈ Stime ∪ {∞}. For any subset X of Stcom, define the language R(X ) as the set of agents generated by the general rule of figure 1.
The configurations to be considered for the family R(X ) are similar to those used for the family L(X ). The introduction of time induces here the following adaptations:
The intuition behind the construct telld(t) is that t is added to the store but for d units of time only. To capture this fact, the tokens of the store

have associated durations.
As another consequence, this duration has to be updated after each tick of the clock. This motivates the introduction of the − operator acting on the store.
Similarly, the intuition behind the askd(t), naskd(t), and getd(t) primi- tives is that, if needed, suspension may occur only up to d units of time. As a result, a similar operator, also denoted −, has to be introduced to decrease the period of suspension after each tick of the clock.
This intuition leads to the following definitions.
Definition 2.15
Given an agent A ∈ R(X ), we denote by A− the agent defined inductively as follows: 4


telld(t)− = telld(t) askd(t)− = askmax{0,d−1}(t)
naskd(t)− = naskmax{0,d−1}(t) getd(t)− = getmax{0,d−1}(t)

(B ; C)− = B− ; C
(B || C)− = B− || C−
(B + C)− = B− + C−

Define the set of timed stores Ststore as the set of multisets of elements of the form td where t is a token and d is a duration. Given a timed store σ, we denote by σ− the new store obtained by decreasing the duration associated with the tokens by one unit and by removing those associated in σ with 1 unit of time: precisely, if all the notations are understood to relate to multi-sets: σ− = {td−1 : td ∈ σ, d > 1}
Define the set of configurations Sconf as Seagent × Ststore. Configura- tions are denoted as ⟨A | σ⟩, where A is an (extended) timed agent and σ is a timed store.
Due to the introduction of time, the operational semantics is defined by means of the transition relations → and ~ describing the two phase approach. They basically adapt the relations defined for the L family. Accordingly, rules (Tr), (Ar), (Nr), and (Gr) adapt respectively rules (T), (A), (N), (G) in the obvious way by requiring that communication primitives be executed only for a strictly positive duration. Moreover, rule (T0) states that telling a token for a zero duration succeeds by not updating the store. Rule (Wr) is the analogue of rule (D1).

4 We extend classical arithmetic on natural numbers by ∞− 1= ∞.

Definition 2.16 Define the transition rules for the R agents as rules (S), (P), (C), (T0), (Tr), (Ar), (Nr), (Gr), (Wr) of figure 2.

The operational semantics is defined by using an auxiliary relation '−→, defined in a similar way as in the previous subsection. We shall subsequently write this semantics as Or.

Definition 2.17 Define the operational semantics Or : R(Srcom) → P(Sfstate) as the following function: For any timed agent A,
Or(A)= {(σ∗, δ+): ⟨A | ∅⟩ '−→∗ ⟨E | σ⟩}
∪ {(σ∗, δ−): ⟨A | ∅⟩ '−→∗ ⟨B | σ⟩ /'−→,B /= E}
where σ∗ denotes the multiset of the tokens present in σ without their duration.


Intra-family comparison
Modular embedding
A natural question to ask is whether the time extensions we just introduced strictly increase the expressivness of the Linda language and, if so, whether some of the timed primitives may be expressed in terms of others.
A basic approach to answer that question has been given by Shapiro in
[30] as follows. Consider two languages L and L'. Assume given the semantic mappings (observation criteria) S : L →O and S' : L' → O', where O and O' are some suitable domains. Then, according to [30], L can embed L' if there exists a mapping C (coder) from the statements of L' to the statements of L, and a mapping De (decoder) from O to O', such that De(S(C(A))) = S'(A), for every statement A ∈ L'.
This approach is however too weak since, for instance, the above equa- tion is satisfied by any pair of Turing-complete languages. To circumvent this problem, De Boer and Palamidessi have proposed in [13] to add three con- straints on the coder C and on the decoder De. First, De should be defined in an element-wise way w.r.t. O:

∀X ∈O : De(X)= {Deel(x) | x ∈ X}	(P1) for some appropriate mapping Deel. Second, the coder C should be defined in

a compositional way w.r.t. the sequential, parallel and choice operators: 5


C(A ; B)= C(A); C(B)
C(A || B)= C(A) || C(B)
C(A + B)= C(A) + C(B)

(P2)

Finally, the embedding should preserve the behavior of the original processes
w.r.t. deadlock, failure and success (termination invariance):
∀X ∈ O, ∀x ∈ X : tm'(Deel(x)) = tm(x)	(P3)
where tm and tm' extract the information on termination from the observables of L and L', respectively. An embedding satisfying these properties (P1, P2, P3) is said to be modular.
The existence of a modular embedding from L' into L is subsequently denoted by L' ≤ L. It is easy to see that ≤ is a pre-order relation. Moreover if L' ⊆ L then L' ≤ L, that is, any language embeds all its sublanguages. This property descends immediately from the definition of embedding, by setting C and De equal to the identity function.
When two languages L and L' embed each other, they are said to be equivalent. This is denoted as L ≡ L'. Finally, we write L' < L when L' ≤ L but L /≤ L'
The study of the embedding in the L(X) family has been done in [6]. We can thus limit our exploration to the D and R families of languages.
The hierarchy of the languages with delay
We now turn to the D family of languages. A first result is that any language embeds all its sublanguages.
Proposition 3.1 For all subsets X and Y of {ask, nask, get, tell} such that
X ⊆ Y , one has D(X) ≤ D(Y )
The primitive nask alone has no more power than delay.
Proposition 3.2 D(∅) ≡ D(nask).
The primitives tell and ask introduce new forms of computations, the first one by modifying the store and the second by introducing failures. While D(tell) and D(ask) are both strictly more powerful than D(∅), they are not comparable to one another.

5 Actually, this is only required for the parallel and choice operators in [13].

Proposition 3.3 Ð(tell) /≤ Ð(∅), Ð(ask) /≤ Ð(∅), Ð(ask) /≤ Ð(tell), and
Ð(tell) /≤ Ð(ask).
Without the tell primitive, the store stays empty and the get and nask do not provide more power than the ask an delay primitives.
Proposition 3.4 Ð(ask) ≡ Ð(get) ≡ Ð(ask, get) ≡ Ð(ask, nask)
≡ Ð(nask, get) ≡ Ð(ask, nask, get).
We now consider the languages Ð(ask, tell) and Ð(nask, tell) obtained by extending Ð(tell) with the ability of checking the presence and the ab- sence of data, respectively, in the dataspace. It is easy to establish that both Ð(ask, tell) and Ð(nask, tell) are strictly more expressive than Ð(tell).
Proposition 3.5 Ð(ask, tell) /≤ Ð(tell) and Ð(nask, tell) /≤ Ð(tell).
While Ð(ask, tell) extends stricly Ð(ask), Ð(nask, tell) is not comparable with Ð(ask).
Proposition 3.6 For any X ⊆ {nask, get, tell}, one has
Ð(ask, tell) /≤ Ð(ask)
Ð(nask, tell) /≤ Ð(ask)
Ð(ask, X) /≤ Ð(nask, tell)
Proof. Cases (i) and (ii) are easily proved by contradiction. For case (iii), let us proceed also by contradiction and assume that Ð(ask, X) ≤ Ð(nask, tell) and that the coder C and decoder Ðe satisfy properties P 1 to P 3. The proof is based on the examination of the normal form of the coding of the primitives delay and ask.
First, consider C(delay(i)) for i > 0. Since C(delay(i)) is in Ð(nask, tell), its normal form can be written as
C(delay(i)) = (delay(j1); A1) + ... + (delay(jn); An)
+ (nask(t1); B1) + ... + (nask(tm); Bm)
+ (tell(s1); C1) + ... + (tell(sl); Cl)
for some times ji’s and tokens ti’s and si’s, with n, m, l ≥ 0. Our first obser- vation is that the coding can not contain any choice starting with a nask, a tell or a delay(0) primitive, i.e. m = 0, l =0 and jk > 0(1 ≤ j ≤ n). Indeed, if there is one choice starting with a nask primitive, then the coding of the agent delay(i) + (delay(0) ; ask(t)) accepts the following derivation
⟨C(delay(i) + (delay(0) ; ask(t)) | ∅⟩ → ⟨B1 | ∅⟩

As delay(i) succeeds on the empty store, the agent B1 has to suceeds. This derivation provides then a valid prefix for a successful derivation of the agent. This contradicts, by property P 3, the fact that delay(i) + (delay(0) ; ask(t)) has only failling computations on the empty store. The absence of choice starting with a tell and delay(0) primitive can be shown similarly.
Consequently, the agent C(delay(i)) for i > 0 has then a normal form of the following type: C(delay(i)) = (delay(j1); A1) + ... + (delay(jn); An), where jk > 0 (1 ≤ j ≤ n).
A second observation about C(delay(i)) is that the jk’s (1 ≤ k ≤ n) are greater than i. This property can be proved by induction on i. For i = 1, it results from the first observation. Now consider any delay(i), delay(i + 1) and their coding
C(delay(i)) = (delay(j1); A1) + ... + (delay(jn); An)
C(delay(i + 1)) = (delay(k1); B1) + ... + (delay(km); Bm)
We denote by kK the smallest kl’s (1 ≤ l ≤ m). If kK is less than any jl, the coding of the agent delay(i + 1) + (delay(i) ; ask(t)) accepts the following derivation

⟨C(delay(i + 1) + (delay(i); ask(t)) | ∅⟩
~kK ⟨... + (delay(0) ; BK) + ... | ∅⟩ → ⟨BK | ∅⟩

As delay(i + 1) succeeds on the empty store, this derivation provides a valid prefix for a successful derivation of the agent. This contradicts, by property P 3, the fact that delay(i + 1) + (delay(i) ; ask(t)) has only failing com- putations on the empty store. Any kl must then be strictly greater than at least one of the jl. By the induction principle, any jl is greater than i, and therefore any kl is greater than i + 1.
Secondly, observe the coding of an agent ask(t). By observing the deriva- tions of C(ask(t) + delay(0)), we conclude in a similar way to delay(i) that the agent C(ask(t)) has a normal form of the following type:
C(ask(t)) = (delay(t1); A1) + ... + (delay(tm); Am)
We are now in a position to establish a contradiction. Assume we have such a coding of ask(t) and denote by ti the minimum of the tk(1 ≤ k ≤ m). Now, the coding of delay(ti) is
C(delay(ti)) = (delay(j1); B1) + ... + (delay(jn); Bn)
where jk ≥ ti(1 ≤ j ≤ n). The agent delay(ti) + ask(t) accepts the following derivation

⟨C(delay(ti) + ask(t)) | ∅⟩ ~ti ⟨... + (delay(0) ; Ai) + ... | ∅⟩
→ ⟨Ai | ∅⟩
As ask(t) fails on the empty store, this derivation provides a valid prefix for a failing derivation of the agent. This contradicts, by property P 3, the fact that delay(ti) + ask(t) has only successful computations on the empty store.	 
Proposition 3.7 Ð(nask, tell, X) /≤ Ð(ask, tell), for any X ⊆ {ask, get}.
Proof. The proof, similar to that of the previous proposition, is based on the examination of the normal form of the coding of the primitives delay and nask.	 
In the presence of tell and get primitives, ask primitive is redundant.
Proposition 3.8
Ð(get, tell) ≡ Ð(ask, get, tell)
Ð(nask, get, tell) ≡ Ð(ask, nask, get, tell)
Proof. (i). The inequality Ð(get, tell) ≤ Ð(ask, get, tell) is obvious. The converse inequality is obtained by coding each get, tell and delay primitive by itself and each ask(t) primitive by get(t); tell(t).
The inequality Ð(nask, get, tell) ≤ Ð(ask, nask, get, tell) is immediate. To establish the converse inequality, we first code any token t by a pair of tokens which we denote (t1,t2). Note that this can be done because Stoken is enumerable: for instance, it is sufficient to associate the token associated with the integer n to the tokens associated with the integers 2n and 2(n + 1). Given such a coding of tokens, we define the coder C as follows.


C(ask(t)) = get(t2); tell(t2)
C(nask(t)) = nask(t1)
C(get(t)) = get(t2); get(t1)

C(tell(t)) = tell(t1); tell(t2)
C(delay(n)) = delay(n)

Moreover, the decoder Ðe is defined as follows: Ðe ((σ, δ)) = (σ, δ) where σ is composed of the tokens t for which t1 and t2 are in σ, the multiplicity of occur- rences of t being that of pairs (t1, t2) in σ. To conclude, it remains to establish that Od(A) = Ðe(Od(C(A))), for any agent A of Ð(ask, nask, get, tell). The key point for this proof consists of first establishing that if, A' denotes C(A), for any agent A, and, if σ' denotes the store obtained by coding the tokens of σ, for any store σ, then ⟨A | σ⟩ −→ ⟨B | τ ⟩ if and only if ⟨A' | σ'⟩ −→∗ ⟨B' | τ '⟩,

for any agents A, B and any stores σ, τ . This in turn is proved by inductively reasoning on the structure of the agent A and for parallelly composed agents by reasoning on their normal forms.	 
The language Ð(get, tell) happens to be strictly more expressive than
Ð(ask, tell).
Proposition 3.9 Ð(ask, tell) ≤ Ð(get, tell) and Ð(get, tell) /≤ Ð(ask, tell) To be complete, we show now that, if a language contains the tell primitive,
nask and get are incomparable. The following lemma will help us in this task.
Lemma 3.10 For any agent A in Ð(ask, nask, tell), if ⟨A | σ⟩ '→∗ ⟨B | σ ∪ τ ⟩ then ⟨A || A | σ⟩ '→∗ ⟨B || B | σ ∪ τ ∪ τ ⟩ where ∪ denotes union on multisets.
Proof. The proof is conducted by induction on the number of steps of the computation ⟨A | σ⟩ '→∗ ⟨B | σ ∪ τ ⟩.	 
Proposition 3.11 For any X ⊆ {ask, get} and Y ⊆ {ask, nask}, one has
Ð(nask, tell, X) /≤ Ð(get, tell)
Ð(get, tell, Y ) /≤ Ð(ask, nask, tell)
Proof. For case (i), the proof is similar to that of proposition 3.7. For case (ii), let us proceed by contradiction and assume that Ð(get, tell) ≤ Ð(ask, nask, tell).  In that case, as Od(tell(t) ; get(t)) = {(∅, δ+)} any computation of A = C(tell(t)) ; C(get(t)) starting in the empty store is successful by P3.  By lemma 3.10, there is a computation of B = C(tell(t)) ; (C(get(t)) || C(get(t))) starting in the empty store that is successful, which contradicts, by P2 and P3, the fact that Od(tell(t); (get(t) || get(t))) = {(∅, δ−)}.	 

The hierarchy of the languages with relative duration
As expected, the first result for the R family of languages is that any language embeds all its sublanguages.
Proposition 3.12 For all subsets X and Y of {ask, nask, get, tell} such that
X ⊆ Y , one has R(X) ≤ R(Y )
The primitives tell and ask respectively introduce the possibility of modi- fying the store and the getting of failures. While R(tell) and R(ask) are both strictly more expressive than R(∅), they are not comparable to one another.

Proposition 3.13 For any X ⊆ {nask, get, tell}, one has Y(tell) /≤ Y(∅), Y(ask) /≤ Y(∅), Y(tell) /≤ Y(ask), and Y(ask, X) /≤ Y(tell).
On the empty store, the ask and get primitives have the same behaviour.
Proposition 3.14 Y(ask) ≡ Y(get) ≡ Y(ask, get).
In the Y family, the nask primitive alone is strictly more expressive than the ask primitive alone.
Proposition 3.15 Y(ask) ≤ Y(nask) and Y(nask) /≤ Y(ask).
The ask and get primitives do not add any expressive power to Y(nask).
Proposition 3.16 Y(nask) ≡ Y(ask, nask) ≡ Y(nask, get) ≡ Y(ask, nask, get).
While Y(nask) is strictly more expressive than Y(ask), it is still incom- parable to Y(tell).
Proposition 3.17 For any X ⊆ {ask, get, tell} and Y ⊆ {ask, nask, get}, one has Y(nask, X) /≤ Y(tell) and Y(tell, Y ) /≤ Y(nask).
Y(ask, tell) turns out to be strictly more expressive than Y(nask).
Proposition 3.18 Y(nask) ≤ Y(ask, tell) and Y(ask, tell) /≤ Y(nask).
While Y(ask, tell) and Y(nask, tell) are both strictly more powerful than
Y(tell) and Y(nask), they are incomparable.
Proposition 3.19 For any X ⊆ {nask, get} and Y ⊆ {ask, get}, one has
Y(ask, tell, X) /≤ Y(nask, tell) and Y(nask, tell, Y ) /≤ Y(ask, tell).
The primitives {get, tell} are strictly more expressive than the pair of primitives {ask, tell}. Moreover adding ask to Y(get, tell) does not yield in an additional expressiveness.
Proposition 3.20
Y(ask, tell) ≤ Y(get, tell)
Y(get, tell) /≤ Y(ask, tell)
Y(get, tell) ≡ Y(ask, get, tell)
Proof. (i). Because of the infinite enumerability of the tokens, we associate with each token t a pair of tokens that, for simplicity, we denote tf and ti. Intuitively, they correspond to a token t on the store with, a finite or infinite duration, respectively. As there is no nask primitives, decreasing the duration of finite tokens in the transitions will occur only in case of failing computation.

In this context, there will be temporal transitions until the current store σ
satisfies σ− = σ, i.e. until all tokens with finite duration disappear.
We can then define the coder C as follows, with d1, d2 > 0 and with d1
finite.
C(tell0(t)) = tell0(t)	C(telld1 (t)) = tell∞(tf )
C(tell∞(t)) = tell∞(ti)	C(ask0(t)) = ask0(t)
C(askd2 (t)) = (get1(tf ); tell∞(tf )) + (get1(ti); tell∞(ti)) The associated decoder Ðe is defined by :
 (σ∞, δ−) if δ = δ−

Ðe((σ, δ)) =
 (σf , δ−)	if δ = δ+

where σ∞ = {t : ti ∈ σ} and σf = {t : ti ∈ σ ∨ tf ∈ σ}.
Assume that Y(get, tell) ≤ Y(ask, tell) and consider tell1(a) ; get1(a). Since C is compositional and since Or(tell1(a) ; get1(a)) = {(∅, δ+)}, the termination mark of any element of Or(C(tell1(a)) ; C(get1(a))) is success- ful.		As C(get1(a)) is composed of ask and tell primitives only and since ask, tell primitives do not destroy elements, it follows that any element of Or(C(tell1(a)) ; C(get1(a)) ; C(get1(a))) has a successful termination mark. However, Or(tell1(a); get1(a); get1(a)) = {(∅, δ−)} which contradicts prop- erty P3.
The inequality Y(get, tell) ≤ Y(ask, get, tell) follows directly from the inclusion of languages. To prove the converse inequality, we consider the coder of point (i), extended by C(get0(t)) = get0(t) and C(getd2 (t)) = get1(tf ) + get1(ti)	 
Moreover the languages Y(ask, nask, tell) and Y(get, tell) are incompara- ble. To establish this property, we introduce an auxiliary lemma.
Lemma 3.21 For any agent A in Y(ask, nask, tell), if ⟨A | σ⟩ '→∗ ⟨B | τ ⟩ then for some τ ' ⊆ τ: ⟨A || A | σ⟩ '→∗ ⟨B || B | τ ∪ τ '⟩ where ∪ denotes union on multisets.
Proposition 3.22 For any X ⊆ {ask, get} and Y ⊆ {ask, nask},
Y(get, tell, Y ) /≤ Y(ask, nask, tell)
Y(nask, tell, X) /≤ Y(get, tell)

Proof. (i). Let us proceed by contradiction and assume that Y(get, tell) ≤ Y(ask, nask, tell).  In that case, as Or(tell1(t) ;  get1(t)) = {(∅, δ+)},
any computation of A = C(tell1(t)) ; C(get1(t)) starting in the empty store is successful by P3.  By lemma 3.21, there is a computation of B = C(tell1(t)) ; (C(get1(t)) || C(get1(t))) starting in the empty store that is successful, which contradicts, by P2 and P3, the fact that Or(tell1(t); (get1(t) || get1(t))) = {(∅, δ−)}.
(ii). The proof similar to that of proposition 3.19 (ii).	 

Inter-family comparisons
Comparing the L and Ð families
The comparison between the L and Ð families is substantiated by the re- sults presented in this section together with those established in [19] and in section 3.2.
The main observation here is that – except in the case of nask primitive alone – the Ð(X) language is strictly more expressive than the corresponding L(X) and no L is more expressive than a Ð language. In other words, the delay primitive can not be expressed by (any combination of) the other primitives. The first result is that, as intuitively expected, for the same set of primitives
X, the language Ð(X) is more powerful than L(X).
Proposition 4.1 For any X ⊆ {ask, nask, get, tell}, L(X) ≤ Ð(X). The only member of the Ð family equivalent to a L(X) is Ð(nask).
Proposition 4.2 One has L(nask) ≡ Ð(nask).
If the language contains at least one primitive other than nask, the delay
primitive cannot be expressed in any L(X).
Proposition 4.3 For any X, Y ⊆ {ask, nask, get, tell}, if X contains at least one primitive other than nask, then Ð(X) /≤ L(Y ).
Proof. There are three cases to consider, where the primitive in X other than
nask is ask, get or tell.
Case 1: ask ∈ X. Consider the agents A = delay(0) and B = delay(1) ; ask(t). The agent A + B is in Ð(X) and Od(A + B)= {(∅, δ+)}.
We proceed by contradiction. Assume that Ð(X) ≤ L(Y ) and that there is a coder C from agents of Ð(X) to agents of L(Y ). We shall establish that

O(C(A + B)) contains a failing computation which is imposssible in view of property P 3.
By property P 2, one has C(delay(1) ; ask(t)) = C(delay(1)) ; C(ask(t)). As Od(delay(1)) = {(∅, δ+)} and Od(delay(1) ; ask(t)) = {(∅, δ−)}, one should have ⟨C(B) | ∅⟩ −→ ⟨T | τ ⟩ for some agent T ∈ L(Y ) and some store τ , with ⟨T | τ ⟩ leading to a failing computation. By property P 2, one has C(A + B) = C(A) + C(B). The thesis then results from the fact that
⟨C(A) + C(B) | ∅⟩ −→ ⟨T | τ ⟩ is a valid computation prefix of C(A + B) which leads to a failing computation.
Case 2: get ∈ X. This case is treated as the first one by considering the agents A = delay(0) and B = delay(1) ; get(t).
Case 3: tell ∈ X. Consider the agents A = tell(a) and B = delay(1) ; tell(b).
The agent A + B is in Ð(X) and Od(A + B)= {({a}, δ+)}.
We proceed by contradiction. Assume that Ð(X) ≤ L(Y ) and that there is a coder C from agents of Ð(X) to agents of L(Y ) and a decoder Ðe which satisfies the constraints P 1 to P 3.
The definition of coder and decoder gives:
Ðe(O(C(A))) = Od(A) = {({a}, δ+)}
Ðe(O(C(B))) = Od(B) = {({b}, δ+)}
As all the computations of C(A) and C(B) are succesfull, O(C(A) + C(B)) =
O(C(A)) ∪ O(C(B)). Properties P 1 and P 3 then give
Ðe(O(C(A + B))) = Ðe(O(C(A) + C(B)))
= Ðe(O(C(A)) ∪ O(C(B)))
= Ðe(O(C(A))) ∪ Ðe(O(C(B)))
= {({a}, δ+), ({b}, δ+)}

In addition to the L(X) ≤ Ð(X) inclusions of property 4.1, one has the quite unexpected following inequality.
Proposition 4.4 L(ask, nask) ≤ Ð(nask, tell).
In the rest of the section we show that there is no other inclusions between those two hierarchies. This corresponds to the fact that, except for the empty store, the delay primitive is not able to express any other primitive.
Proposition 4.5 For any X ⊆ {ask, nask, get, tell}, if X /⊆ {nask} then
L(X) /≤ Ð(nask)

Proposition 4.6  L(ask, X)	/≤	Ð(tell),	L(get, Y )	/≤	Ð(tell),	and
L(nask, tell) /≤ Ð(tell), for any X ⊆ {nask, get, tell}, Y ⊆ {ask, nask, tell}.
Proposition 4.7 L(tell, X) /≤ Ð(ask), for any X ⊆ {ask, nask, get}.
Proposition 4.8 L(ask, tell, X)	/≤	Ð(nask, tell) and L(get, tell, Y )	/≤ Ð(nask, tell), for any X ⊆ {nask, get}, Y ⊆ {ask, nask}.
Proposition 4.9 L(nask, tell, X)	/≤	Ð(ask, tell) and L(get, tell, Y )	/≤ Ð(ask, tell), for any X ⊆ {ask, get}, Y ⊆ {ask, nask}.
Proposition 4.10 For any X ⊆ {ask, nask}, Y ⊆ {ask, get},
L(get, tell, X) /≤ Ð(ask, nask, tell)
L(tell, nask, Y ) /≤ Ð(get, tell)
Proof. (i). We proceed by contradiction and assume that L(get, tell) ≤ Ð(ask, nask, tell). In that case, as 0(tell(t) ; get(t)) = {(∅, δ+)}, any computation of A = C(tell(t)) ; C(get(t)) starting with the empty store is successful by P3. Lemma 3.10 gives that, as a consequence, there is a computation of B = C(tell(t)) ; (C(get(t)) || C(get(t))) starting with the empty store that is successful, which contradicts, by P2 and P3, the fact that 0(tell(t); (get(t) || get(t))) = {(∅, δ−)}.
(ii). Again we proceed by contradiction. Otherwise, C(tell(a)) ; C(nask(a)) has only successful computations, which, by P3, contradicts the fact that 0(tell(a) ; nask(a)) = {({a}, δ−)}. Indeed, since 0(tell(a)) = {({a}, δ+)}, by P3 any computation of C(tell(a)) (starting with the empty store) is success- ful. Similarly, it follows from 0(nask(a)) = {(∅, δ+)} that any computation starting with the empty store is successful, and consequently, so is any com- putation starting from any store, since C(nask(a)) is composed of get, tell and delay primitives. Summing up, any (successful) computation of C(tell(a)) starting with the empty store can be continued by a (successful) computation of C(nask(a)).	 
Comparing the L and Y families
The first result in the comparison between the L(X) and Y(X) families is that, as intuitively expected, for the same set of primitives X, the language Y(X) is more expressive than the language L(X).
Proposition 4.11 L(X) ≤ Y(X), for any X ⊆ {ask, nask, get, tell}.
The two empty languages are equivalent.
Proposition 4.12 L(∅) ≡ Y(∅).

The languages L(X) and Y(X) do not differ if X contains only one of the primitives ask, get or tell.
Proposition 4.13
L(ask) ≡ L(get) ≡ L(ask, get) ≡ Y(ask) ≡ Y(get) ≡ Y(ask, get)
L(tell) ≡ Y(tell)
Unlike the other primitives nask is sufficient to distinguish L(nask) and
Y(nask).
Proposition 4.14 Y(nask) /≤ L(nask).
The pairs of primitives (ask, nask), (nask, get), (ask, tell) and (get, tell) do not dinstinguish the languages L and Y.
Proposition 4.15
L(ask, nask) ≡ Y(ask, nask) L(get, nask) ≡ Y(get, nask) L(ask, tell) ≡ Y(ask, tell) L(get, tell) ≡ Y(get, tell)
The pair of primitives nask, tell distinguish the two families L and Y.
Proposition 4.16 Y(nask, tell, X) /≤ L(Y ), for any X ⊆ {ask, get} and
Y ⊆ {ask, nask, get, tell},
Comparing the Ð and Y families
We finally compare the Ð and Y families. The first main observation is that the delay primitive cannot be expressed in any Y(X) language. The second one is that, when Y(X) is more expressive than L(X) – i.e. if {nask, tell}⊆ X – the corresponding Ð(X) and Y(X) languages are not comparable. The only member of the Ð(X) languages that is less powerful than some Y(Y ) is Ð(nask).
Proposition 4.17 Ð(nask) ≤ Y(nask), Y(nask) /≤ Ð(nask), Ð(nask) ≤ Y(tell), and Y(tell) /≤ Ð(nask)
If a language contains at least one of the primitives ask, get and tell, the
delay primitive cannot be expressed in any Y(X) language.
Proposition 4.18 For any X, Y	⊆ {ask, nask, get, tell} such that X ∩
{ask, get, tell} /= ∅, one has Ð(X) /≤ Y(Y )
Proof. The proof is conducted according to the inequality X∩{ask, get, tell} /=
∅, which naturally leads to three cases: ask ∈ X, get ∈ X, tell ∈ X.

Case 1. ask ∈ X. For contradiction, suppose that Ð(X) ≤ Y(Y ) and consider the coder C and the decoder Ðe which satisfy the properties P 1 to P 3.
By property P 3, the coding of delay(1) has only successful computations on the empty set. The first step of any such computation corresponds to the execution of a telld(t) or naskd(t) primitive on the empty set and thus is not a temporal step. Any computation can be represented as follow.
⟨C(delay(1)) | ∅⟩ → ⟨C' | σ⟩ '→∗ ⟨E | τ ⟩
where Ðe((τ, δ+)) = (∅, δ+).
We now consider the agent delay(1) ; ask(t). By property P 3, its coding has only failing computations. Property P 2 then gives that the following computation is a valid prefix for a failing computation.
⟨C(delay(1)) ; C(ask(t)) | ∅⟩ → ⟨C' ; C(ask(t)) | σ⟩ '→∗ ⟨C(ask(t)) | τ ⟩
As the first step is not a temporal transition, this gives, by definition of + , a valid prefix for a failing computation of the coding of the agent delay(0) + (delay(1) ; ask(t)). That contradicts the fact that, by P 3, this agent has only successful computations.
Case 2. get ∈ X. It is sufficient to replace ask by get in the previous proof.
Case 3. tell ∈ X. We proceed by contradiction as for the first case and consider the agent delay(1) ; tell(t). By property P 3, its coding has only successful computations. By property P 2, such a computation begin with a successful computation of C(delay(1)) and goes on with a successful compu- tation of C(tell(t)). One thus has
⟨C(delay(1)) ; C(tell(t)) | ∅⟩ → ⟨C' ; C(tell(t)) | σ⟩ '→∗ ⟨C(tell(t)) | τ ⟩ '→∗ ⟨E | µ⟩
where Ðe((µ, δ+)) = ({t}, δ+).
As the first step is not a temporal transition, this gives by the definition of + a valid successful computation of the coding of the agent delay(0) + (delay(1) ; tell(t)). This contradicts the fact that any computation of this agent finishes on the empty set.	 
We have argued in section 4.2 that if X is a set of primitives that is not the {nask} singleton and does not contain the pair {nask, tell}, the languages L(X) and Y(X) are equivalent. The following results are the transcription of the comparison of Ð(X) and L(X) languages of section 4.1 in the comparison between the Ð(X) and Y(X) languages due to these equivalences.



Proposition 4.19
Y(∅) ≤ Ð(∅)
Ð(∅) /≤ Y(∅) Y(tell) ≤ Ð(tell) Y(nask) ≤ Ð(ask)
Y(nask) ≤ Ð(nask, tell)

Y(ask, tell) ≤ Ð(ask, tell) Y(ask, tell) /≤ Ð(ask) Y(ask, tell) /≤ Ð(nask, tell) Y(get, tell) ≤ Ð(get, tell)
Y(get, tell) /≤ Ð(ask, nask, tell)

The nask and tell primitives taken together cannot be expressed in any language in the Ð family.
Proposition 4.20 Y(nask, tell, X) /≤ Ð(Y ), for any X ⊆ {ask, get} and
Y ⊆ {ask, nask, get, tell}.
Proof. Since Ð(ask, nask, get, tell) ≡ Ð(nask, get, tell), it is sufficient to prove that Y(nask, tell, X) /≤ Ð(nask, get, tell).
For contradiction, suppose that Y(nask, tell, X) ≤ Ð(nask, get, tell) and consider the coder C and decoder Ðe satisfying properties P 1 to P 3. The proof is based on the examination of the normal form of the coding of the primitives nask.
For any i ∈ Stime, the agent C(naski(t)) is in Ð(ask, nask, get, tell), and its normal form can then be written as
C(naski(t)) = (delay(j1); A1) + ... + (delay(jn); An)
+ (nask(t1); B1) + ... + (nask(tm); Bm)
+ (get(u1); C1) + ... + (get(ul); Cl)
+ (tell(v1); D1) + ... + (tell(vk); Dk)

where n, m, l, k ≥ 0.
Our first observation is that the coding can not contain any choice starting with a tell or a delay(0) primitive, i.e. k =0 and jx > 0 (1 ≤ x ≤ n). Indeed, if there is one choice starting with a tell primitive, then the coding of the agent telli+1(t); (naski(t) + nask1(s)) accepts the following derivation
⟨C(telli+1(t); (naski(t) + nask1(s)) | ∅⟩
'→∗ ⟨C(naski(t) + nask1(s)) | σti+1⟩→ ⟨D1 | σti+1 ∪ {v1}⟩
As the computation of telli+1(t); naski fails, this derivation provides a valid prefix for a failing derivation of the agent. That contradicts, by property P 3, the fact that telli+1(t); (naski(t) + nask1(s)) has only successful computa-

tions on the empty store. The absence of an alternative in the choice starting with a delay(0) primitive can be shown similarly.
Now, denote by σtj (j ∈ Stime) any store such that
⟨C(tellj(t)) | ∅⟩ '→∗ ⟨E | σtj⟩.
The second observation is that any of the nask(tk) (k = 1,... , m) and get(uk) (k = 1,... , l) primitives appearing in the coding of nask(i) fails on any σtj(j ∈ Stime). Indeed if there is a nask(tK) that succeeds with σtJ , the coding of the agent tellJ (t) ; (naski(t) + nask1(s)) has the following derivation
⟨C(tellJ (t); (naski(t) + nask1(s)) | ∅⟩ '→∗ ⟨C(naski(t) + nask1(s)) | σtJ ⟩
→ ⟨BK | σtJ ⟩

On the one hand, if J ≤ i, tellJ (t) ; naski(t) fails and this provides a valid prefix for a failing derivation of the agent. On the other hand, if J > i, this derivation provides a successful derivation with a final configuration decoded as (δ+, ∅). Both cases contradict, by property P 3, the fact that the semantics of telli+1(t); (naski(t) + nask1(s)) is {(δ+, {v})}. The absence of successful get(uk) on σtj can be shown similarly.
The third observation is about the delay primitives appearing in the cod- ing. None of the j1,... , jl > 0 can have 1 as value. Indeed, if jJ = 1, in view of our second observation, the coding of the agent telli(t); (naski(t) + naski+1(t)) accepts the following derivation
⟨C(telli(t); (naski(t) + naski+1(t)) | ∅⟩ '→∗ ⟨C(naski(t) + naski+1(v)) | σti⟩
~ ⟨... + (delay(0) ; AJ ) + ... | σti−⟩
→ ⟨AJ | σti−⟩
As telli(t) ; naski(t) fails, this derivation provides a valid prefix for a failing derivation of the agent. That contradicts, by property P 3, the fact that telli+1(t) ; (naski(t) + naski+1(t)) has only successful computations on the empty store.
An inductive reasoning leads similarly to the property that no value of
Stime is possible for tj.
All these observations together lead to the fact that the coding of a naski(t) primitive has a normal form of the following type:
C(naski(t)) = (nask(t1); B1) + ... + (nask(tm); Bm)
+ (get(u1); C1) + ... + (get(ul); Cl)

where every nask(tk)(k = 1,... , m) and get(uk)(k = 1,... , l) primitive ap- pearing in the coding of nask(i) fails on any σtj(j ∈ Stime). Consequently,
⟨C(tell1(t); nask2(t)) | ∅⟩ '→∗ ⟨C(nask2(t)) | σt1⟩ is a valid prefix for a failling computation of C(tell1(t); nask2(t)). However, this contraditcs, by property P 3, the fact that tell1(t); nask2(t) has only successful computations. 

Conclusion
In this paper we studied two extensions of Linda in order to introduce relative time in coordination languages. Both are based on the two-phase functioning approach to real-time systems already employed by languages such as Lustre ([10]) and Esterel ([3]).
The resulting families of languages have been described by means of transi- tion systems written in Plotkin’s style. Their expressiveness has been studied by means of the concept of modular embedding introduced in [13]. The com- plete expressiveness hierarchy of each family has been examined. We have also compared the expressiveness of languages of different families. All these results are summed up in figure 3. On the point of notations, an arrow from a language L1 to a language L2 means that L2 strictly embeds L1, that is L1 < L2.
This paper is a continuation of our previous work [19]. There the families Ð and Y were introduced and some expressiveness results were presented. However, this paper presents a much deeper study of the expressiveness of Ð and Y. In particular, none of the results of sections 3 and 4.2 have appeared in [19]. Moreover, the comparisons of sections 4.1 and 4.3 have lead here to 13 propositions whereas only 5 were presented in [19].
Other related proposals for the introduction of time in coordination-like languages are [27] and [28]. Both pieces of work concern concurrent constraint languages ([29]), which may be viewed as a variant of Linda restricted to two communication primitives putting information in a tuple space and checking the presence of information in it. Technically, concurrent constraint languages can thus be viewed as the language L({ask, tell}). The paper [27] introduces time in this context by identifying quiescent points in the computation where no new information is introduced and by providing an operator for delaying computations by one unit. At each quiescent point in time, the tuple space is reinitialized to an empty content. The paper [28] extends this framework, on the one hand, by introducing a primitive for checking the absence of in- formation and reacting on this absence during the same unit of time and, on the other hand, by generalizing the delay(1) mechanism in a hence A con- struct which states that A holds at every instant after the considered time.


L(∅)
R(∅)
L(nask)	L(ask)
D(∅)	L(get)
D(nask)	L(ask, get)
R(ask)
R(get) R(ask, get)
L(tell)	L(ask, nask)
R(tell)	L(nask, get)
L(ask, nask, get) R(nask)  R(ask, nask) R(nask, get) R(ask, nask, get)
L(nask, tell)	D(tell)	L(ask, tell)	D(ask)
R(ask, tell)		D(get) D(ask, get) D(ask, nask) D(nask, get)
D(ask, nask, get)



D(nask, tell)	R(nask, tell)	L(ask, nask, tell)	D(ask, tell)	L(get, tell)
L(ask, get, tell) R(get, tell) R(ask, get, tell)
R(ask, nask, tell)	D(ask, nask, tell)	L(nask, get, tell)	D(get, tell)
L(ask, nask, get, tell) D(ask, get, tell)

R(nask, get, tell)	D(nask,get, tell)
D(ask, nask, get, tell)



R(ask, nask, get, tell)
Fig. 3. Comparison of the L, D and R families of languages

The resulting languages are called tcc and tdcc. In fact, rephrased in our framework, these languages correspond respectively to restricted variants of our Ð({ask, tell, nask}).
Although weaker than, for instance, the whole Y language, the paper [32]

has shown that the language tcc can embed one classical representative of the state oriented synchronous languages, namely Argos ([21]), and one rep- resentative of the declarative class of dataflow synchronous languages, namely Lustre ([10]). It follows from section 4 that the same result holds for most of the languages we have proposed.
De Boer, Gabbrielli, and Meo have presented in [4] a timed interpretation of concurrent languages by fixing the time needed for the execution of parallel tell and ask operations as one unit and by interpreting action prefixing as the next operator. A delay mechanism is presented in Oz ([31]), a language which combines object oriented features with symbolic computation and constraints, and, (relative) time-outs have been introduced in TSpaces ([34]) and JavaS- paces ([14]). A formal semantics of these time-outs and other mechanisms, different from our expressiveness study, is presented in [7].
Another piece of work on the expressiveness of timed constraint systems is [24]. There, various extensions of the tcc languages have been studied: extension with replication and recursive procedures with static scoping. De- cidability results are proved as well as several encodings, which are however not of the form of modular embeddings studied in this paper.
Finally, [8] investigates the impact of various mechanisms for expired data collection on the expressiveness of coordination systems. However, the study is based on Random Access Machines, on ordered and unordered tells of timed data and on decidability results. In contrast, we study a richer class of mech- anisms and foccus on modular embeddings.

References
J.-M. Andreoli and R. Pareschi. Linear Objects: Logical Processes with Built-in Inheritance.
New Generation Computing, 9(3-4):445–473, 1991.
J. Banatre and D. LeMetayer. Programming by Multiset Transformation. Communications of the ACM, 36(1):98–111, 1991.
G. Berry and G. Gonthier.	The Esterel Synchronous Programming Language: Design, Semantics, Implementation. Science of Computer Programming, 19, 1992.
F.S. De Boer, M. Gabbrielli, and M.C. Meo. A Timed Concurrent Constraint Language.
Information and Computation, 161(1):45–83, 2000.
A. Brogi and P. Ciancarini. The Concurrent Language Shared Prolog. ACM Transactions on Programming Languages and Systems, 13(1):99–123, January 1991.
A. Brogi and J.-M. Jacquet. On the Expressiveness of Linda-like Concurrent Languages.
Electronic Notes in Theoretical Computer Science, 16(2):61–82, 1998.
N. Busi, R. Gorrieri, and G. Zavattaro. Process Calculi for Coordination: from Linda to JavaSpaces. In Proc. AMAST, Lecture Notes in Computer Science. Springer Verlag, 2000.
N. Busi and G. Zavattaro. Expired Data Collection in Shared Dataspaces. Theoretical Computer Science, 298:529–556, 2003.


N. Carriero and D. Gelernter. Linda in Context. Communications of the ACM, 32(4):444–458, 1989.
P. Caspi, N. Halbwachs, P. Pilaud, and J. Plaice. Lustre: a Declarative Language for Programming Synchronous Systems. In Proc. POPL’87. ACM Press, 1987.
P. Ciancarini. Distributed Programming with Logic Tuple Spaces. New Generation Computing, 12(3):251–284, 1994.
P. Ciancarini and D. Rossi. Jada: Coordination and Communication for Java Agents. In Proc. 2nd International Workshop on Mobile Object Systems, volume 1222 of Lecture Notes in Computer Science, pages 213–228. Springer-Verlag, 1996.
F.S. de Boer and C. Palamidessi. Embedding as a Tool for Language Comparison. Information and Computation, 108(1):128–157, 1994.
E. Freeman, S. Hupfer, and K. Arnold. JavaSpaces: Principles, Patterns, and Practice. Addison-Wesley, 1999.
D. Gelernter and N. Carriero.	Coordination Languages and Their Significance.
Communications of the ACM, 35(2):97–107, 1992.
D. Harel. Statecharts: a Visual Formalism for Complex Systems. Science of Computer Programming, 8, 1987.
E. Horita, J.W. de Bakker, and J.J.M.M. Rutten. Fully abstract denotational models for nonuiform concurrent languages. Information and computation, 115(1):125–178, 1994.
J.-M. Jacquet and K. De Bosschere. On the Semantics of µLog. Future Generation Computer Systems, 10:93–135, 1994.
J.-M. Jacquet, K. De Bosschere, and A. Brogi. On Timed Coordination Languages. In A. Porto and G.-C. Roman, editors, Proc. 4th International Conference on Coordination Languages and Models, volume 1906 of Lecture Notes in Computer Science. Springer, 2000.
I. Linden, J.-M. Jacquet, K. de Bosschere, and A. Brogi. On the expressiveness of relative- timed coordination models. Technical report, Institute of Informatics, University of Namur, Belgium, 2003.
F. Maraninchi. Operational and Compositional Semantics of Synchronous Automaton Composition. In Proc. Concurr’92, volume 630 of Lecture Notes in Computer Science. Springer, 1992.
D. Gelernter N. Carriero and L. Zuck. Bauhaus Linda. In In P. Ciancarini, O. Nierstrasz, and
A. Yonezawa, editors, Object based models and languages for concurrent systems, volume 924 of Lecture Notes in Computer Science, pages 66–76. Springer-Verlag, 1994.
R. De Nicola, G. Ferrari, and R. Pugliese. KLAIM: a Kernel Language for Agents Interaction and Mobility. IEEE Transactions on Software Engineering, 1998.
M. Nielsen, C. Palamidessi, and F.D. Valencia. On the Expressive Power of Temporal Concurrent Constraint Programming Languages. In Proceedings of the 4th international ACM SIGPLAN conference on Principles and practice of declarative programming, pages 156–167. ACM, 2002.
G.A. Papadopolous and F. Arbab. Coordination Models and Languages. Advances in Computers, 48, 1998.
A. Rowstron and A. Wood. A Set of Tuple Space Primitives for Distributed Coordination. In Proc. 30th Hawaii International Conference on System Sciences, volume 1, pages 379–388. IEEE Press, 1997.
V. Saraswat, R. Jagadeesan, and V. Gupta. Programming in Timed Concurrent Constraint Languages. In B. Mayoh, E. Tougu, and J. Penjam, editors, Computer and System Sciences, volume ASI-131 of NATO. Springer Verlag, 1994.


V. Saraswat, R. Jagadeesan, and V. Gupta.	Timed Default Concurrent Constraint Programming. Journal of Symbolic Computation, 11, 1996.
V.A. Saraswat. Concurrent Constraint Programming Languages. The MIT Press, 1993.
E.Y. Shapiro. Embeddings among Concurrent Programming Languages. In W.R. Cleaveland, editor, Proceedings of CONCUR’92, pages 486–503. Springer-Verlag, 1992.
G. Smolka. The Oz Programming Model. In J. Van Leuwen, editor, Computer Science Today, volume 1000 of Lecture Notes in Computer Science, pages 324–343. Springer Verlag, 1995.
S. Tini. On the Expressiveness of Timed Concurrent Constraint Programming. Electronics Notes in Theoretical Computer Science, 1999.
R. Tolksdorf.  Coordinating Services in Open Distributed Systems with LAURA.  In
P. Ciancarini and C. Hankin, editors, Coordination’96: First International Conference on Coordination Models and Languages, volume 1061 of Lecture Notes in Computer Science. Springer-Verlag, 1996.
P. Wyckoff, S.W. McLaughry, T.J. Lehman, and D.A. Ford. TSpaces. IBM Systems Journal, 37(3), 1998.
