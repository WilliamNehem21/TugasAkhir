Static source code analysis for software bug detection has come a long way since its early beginnings as a compiler technology. However, with the introduction of more sophisticated algorithmic techniques, such as model checking and constraint solving, questions about performance are a major concern. In this work we present an empirical study of our industrial strength source code analysis tool Goanna that uses a model checking core for static analysis of C/C++ code. We present the core technology and abstraction mechanism with a focus on performance, as guided by experience from having analyzed millions of lines of code. In particular, we present results from our recent study within the NIST/DHS SAMATE program. The results show that, maybe surprisingly, formal verification techniques can be used successfully in practical industry applications scaling roughly linearly, even for millions of lines of code.

Software development cycles are a major competitive aspect in many market seg- ments including mobile phone handsets, games, and consumer electronics. The obvious goal is to deliver software as fast as possible, as cheaply as possible, and at the highest quality possible. For these reasons, automation and tool support play an important role. One of the areas for a high potential of automation and cost saving is testing and debugging, where around 50% of all development costs are spent.

In recent years new algorithmic techniques have been developed by the formal methods community and approaches like model checking, SAT solving, and abstrac- tion refinement are increasingly used for software analysis [14,5,8]. While these technologies can provide powerful capabilities, they come with the stigma of not being practicable for real-life systems, as being slow, and not being scalable to large code bases. That is, these new technologies are suspected to lack in performance or have to sacrifice accuracy.

Accuracy: code analysis is done on an abstraction of programs, which may result in false positives, i.e. bugs that are artifact of the abstraction rather than real bugs in the program. The ratio of false positives versus issued warnings should be kept low to give useful feedback to the programmer.

We specifically address the challenges cited above and we present some detailed results from our recent participation in the Software Assurance Metrics And Tool Evaluation (SAMATE) 1 program run by the National Institute of Standards and Technology (NIST) and the Department of Homeland Security (DHS). We present a number of qualitative results and real-life software bugs found in large open-source code bases. Additionally we give detailed quantitative analysis on the scalability of our model checking approach, both in terms of lines of code (LoC) as well as number of checks performed.

The rest of this paper is organized as follows. In Section 2 we motivate the use of static analysis in the software development life-cycle. Section 3 examines the techniques used by Goanna to achieve scalable and accurate results. Section 4 presents results achieved in SAMATE tests. Section 5 discusses our experience with integrating Goanna into existing development environments. Finally, Section 6 draws conclusions and discusses future work.

In this section we describe the underlying core technology of Goanna. In particular, we explain the model checking approach to static analysis, core abstract interpreta- tion applications, and additional techniques for path-sensitive and inter-procedural analysis. The combination of these technologies is used to detect potential crash causing code, security vulnerabilities, memory leaks and the like. A detailed list of detected vulnerabilities and checks that Goanna can perform can be found in [12].

Some of the checks performed by Goanna are beyond the scope of syntactical anal- ysis or variable range analysis as they are path-sensitive. This is why one core technology implemented in Goanna is model checking. A model is a transition system annotated with atomic propositions. A check or property is defined in a temporal logic [3] that can capture path-dependent specifications.

Implementation. When analyzing source code, the models are usually small but the properties to check are numerous (see Section 4.2). Most of the CTL formulas do not have nested modalities and thus are rather easy to check. This is why Goanna

Implementation. Basic regular expression pattern matching is sufficient for some queries, such as whether a library function such as strcpy is used or not. However, queries can become more complicated, and a series of interdependent queries may be used for more advanced checks, for example to identify inconsistent use of semantic attributes. For this purpose Goanna uses tree-pattern matching [4] on the AST. This enables expressive queries taking branching substructures into account and is flexible enough to define a wide range of non path-dependent checks.

A general technique to automatically approximate and track data values is ab- stract interpretation [6]. Goanna implements abstract interpretation to estimate the potential ranges for each interger and pointer variable at each program loca- tion. This enables us to, for instance, estimate the potential index values whenever an array is accessed or NULL pointer dereference.

Implementation. To overcome this challenge we have developed a compositional approach computing function summaries automatically. These function summaries contain information that is needed for particular checks e.g. ranges of variables re- turned by the function, existence of path to NULL pointer dereference. Instead of propagating information of the whole function, which can be prohibitively large, only the summary information is used. The information for each function is stored in a database that can be enriched when some new knowledge is available e.g. con- straints on the input data of the function.

On top of the previous techniques we also use data flow analysis [2] to examine the flow of information between variables and other elements of interest. An example is checking for the flow of tainted data in a security context. While data flow analysis is useful to track information flow, it is less amendable to precision improving tech- niques such as refinement and also does not typically return any counter-example traces if a program property is violated.

Various test suites were provided for SATE 2010 among them the code of open source projects Dovecot, Wireshark, and Chromium. A detailed report with the weaknesses discovered by each tool was submitted by each group to NIST experts. The experts analyzed the results and assigned one of the following categories to each discovered weakness.

size of the CTL properties. Each Goanna check translates to one CTL property. Moreover, for each program variable there might be one check of the same class. For example, each variable has to be checked for being uninitialized. The scalability of our analysis will therefore depend on the size of CFG and number of properties that have to be checked.

In summary, the code size and in turn the number of states that are generated is a good indicator for the runtime. It is worth mentioning though, that model checking itself only accounts for around 20% of the overall runtime. The rest of the runtime is spent in parsing, generating the models, pattern matching, or analyzing data flow. The number of generated states is also a good measure for the complexity of the source code, and thus for the complexity of other types of analysis techniques.

In this work we presented our practical results from using automated formal meth- ods, in particular model checking, for static bug detection of industrial software. An important contribution is the empirical demonstration that our model checking approach to static analysis scales roughly linearly to millions of lines of C/C++ code. Moreover, we have shown that our Goanna tool is able to detect previously unknown and relevant safety and security flaws automatically in large C/C++ code bases.

Future work is to push the envelope further. This means, we endeavor to succes- sively add more formal verification techniques such as SMT solving and automated theorem proving to create an even more fine-grained analysis without overly com- promising performance. Some early results in that direction can be found in [10]. Moreover, we see another important challenge in addressing real concurrency issues resulting from multi-threaded code.

