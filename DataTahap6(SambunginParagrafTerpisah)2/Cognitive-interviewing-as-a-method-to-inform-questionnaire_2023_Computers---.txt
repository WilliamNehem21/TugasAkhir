Research of immersive technology in education is rapidly expanding with potential to educate future students in healthcare disciplines. Despite increasing literature there is a lack of validated instruments to investigate the effects of these technologies. Cognitive interviewing is a valuable evaluation method to check comprehension of a measure and was applied to a new measure of user experience of immersive technology for healthcare education (ITEM). A 5 domain self-reported measure of: immersion, intrinsic motivation, cognitive load, system usability, and debrief. Prior to the interview 9 participants were allocated to augmented reality and virtual reality educational activities. Verbal probing and think aloud techniques through semi-structured cognitive interviews were conducted. The ITEM was found to have high content validity index scores and relationships between domains were further explored through qualitative analysis. The results indicate high clarity of un- derstanding for those completing the ITEM and supports future research as part of an ongoing validation process.

Learner-centred pedagogy can observe improvements in procedural skills with deliberate practice to acquire new microskills to a mastery learning approach in VR (Andersen, Konge, Thomasen, & Sorensen, 2016) and AR (Lia et al., 2018, p. 10576). Kolb's experiential learning whereby experience is converted to knowledge and skill has been considered as a theoretical pedagogy for airway management learning in VR (Samosorn et al., 2020). Cognitive frameworks involve an internal mechanism whereby information is re-organised with working and long-term memory (Khalil & Elkhider, 2016). Mayer's cognitive theory considers the sensory processing from dual process of audio and visual to multimedia (Mayer, 2014), which can be interpreted as a system with limited cognitive demand (cognitive load). Immersive media has been described as multi-sensory and the Cognitive Affective Model of Immersive Learning (CAMIL) proposes important factors to learning that included: immersion, fidelity, agency, interest, motivation, and cognitive load (Makransky & Petersen, 2021). Immersive technology affords cognitive, procedural, and affective domains first described in Bloom's taxonomy (Adams, 2015).

An online-modified Delphi was undertaken to solicit stakeholder views, to guide and support ITEM domain construct (Jacobs, Foote, & Williams, 2022). Educationalists involved in simulation from a range of backgrounds took part: doctors, technicians, researchers, and adminis- trators, and were invited to consider the way that the experience of those engaged in immersive TEL can be measured. The consensus with 100% agreement were 7 factors should be measured: what was learnt, the de- gree of immersion experienced, fidelity provided, debrief, psychological safety, patient safety, and cost effectiveness. There was 100% agreement that participant experience should be used as the most efficient method of collecting data. Additionally, there was support for a generalisable measure that can be used with different technologies and settings.

All aspects of validity are important. It is essential for example that the content assessment of items maps to the overall construct that they are intended to measure. The internal structure relates to the individual items, such as, reliability and item difficulty (David A. Cook & Hatala, 2016). Preliminary work on the design of ITEM incorporated the domains of immersion and motivation of participants experiencing immersive

Part of establishing evidence for validity is its pre-test evaluation. The preliminary version of the tool was reviewed in a focus group of medical educators, and questionnaire item revision through direct feedback was undertaken prior to cognitive interviewing (CI). A mixed methods approach was chosen to include a quantitative analysis, using the CVI (Rodrigues, Adachi, Beattie, & MacDermid, 2017), with clarity of assessment of items assessed using qualitative CI (Egger-Rainer, 2019).

Semi-structured interviewing of respondents can be conducted using verbal probe (VP), think-aloud (TA), or combined techniques. VP involves spontaneous or scripted questions most commonly asked concurrently with respondents answering an item (Buers et al., 2014; G. Willis, 2005). Cognitive operations can be mapped on to scripted questions that cover item terminology, item understanding, item response and combining items for desired construct (Peterson, Peterson, & Powell, 2017). Scripting of probes and using a coding system has the advantage of interview consis- tency between different interviewers. By contrast, TA is with minimal prompting and interviewers listen to respondents articulating their conscious thought stream. Interviewer and respondent training on this method is recommended to avoid hesitation. There is no uniform method of conducting CI and some support a combined VP and TA approach to gain most insights, with TA preferencing to concept understanding and VP to exploring specific items (Priede & Farrall, 2011).

CIs were undertaken by 2 trained authors to reduce confirmation bias (Peterson et al., 2017; Woolley, Bowen, & Bowen, 2006). A Qualtrics survey that included VP of open and closed questions to each of the 40 questions forming the ITEM was used. Interviewers introduced the pro- cess to participants whereby verbalising conscious thought was encour- aged and responses to VP questions were transcribed for all 40 items. A 4 question VP was designed that included: understanding of the measure item, repeating the question in the participants own words, key words in ITEM question were explored for further comprehension, alternative wording to any parts of question probed, and finally field notes for further qualitative analysis.

Analytical technique of transcribing during interview for follow up coding and rapid analysis for confirmation of domain construct (Taylor, Henshall, Kenyon, Litchfield, & Greenfield, 2018). The team undertook a within-case analysis for each respondent's transcript and identified key phrases. Discrepancies of respondent's understanding from the intending meaning was probed with follow up questioning, for item development and rewording. Each item was matched to the pre-existing domain and charted in a matrix that had all respondents' answers. Authors met for an iterative process of coding and evaluation of domains for their degree of agreement with the intended construct. Furthermore, inductive/de- ductive hybrid thematic analysis was selected to synthesise the mixed methods data for theory generative retroduction (Proudfoot, 2022).

The ITEM is the first multidomain instrument that can assess the user's immersion, perceived learning, and usability of immersive tech- nology in the context of healthcare education. This study demonstrated high correlation in the content analysis to the 5 domains of the ITEM. In the qualitative analysis, a process of TA and VP, the participants reviewed different modalities of immersive media in healthcare education, and provided insights into their comprehension of questions as they respon- ded accordingly to their perceived experience of the media (Council, 1984). There were 2 questions that introduced confusion by the language used to describe the phenomena of interest. Understanding of the lan- guage used for the target population of a questionnaire is important when establishing the validity (Schildmann et al., 2015). The analysis sug- gested relationships exist between some variables, such as motivation and confidence, which is not surprising given the subjectivity underlying responses, and less understood process of how we learn and the com- plexities of linking this to individual and external factors (Franz, Oberst, Peters, Berger, & Behrend, 2022).

It is a multi-sensory experience, and this will impact on the cognitive load. The arrows represent a two-way exchange, for example, the tech- nology interface is the usability of the technology for an individual or the immersion experienced is related to the content and the individual. The cognitive factors of processing tasks are also depicted as a varying level (between high and low), as does the intrinsic reward mechanisms of motivation. Multi-sensory experience is controlled by the immersion and interface enables multi-sensory processing, which occurs in multiple cerebral areas, however, is limited by cognitive load and our motiva- tional states. Finally, the experience is conceptualised with reference to prior learning and allows for interaction again with the media anchored through immersion and the interface. This promotes a repetition of

Bias exists with the selection of measures that forms the complete ITEM. Although, selected through a process of literature review and adapting for healthcare use in pilot studies. The process of CI is to support the content and how we might trust the accuracy of feedback participants will return. Numerous other measures exist that investigate the domains in ITEM and these remain available to study.

Several limitations existed in the methodology applied in CI, which are possible errors in comprehension of interviewer, interviewee, or both (Lenzner, Hadler, & Neuert, 2022). There can be a reactivity bias whereby responses are created just because they have been asked. Furthermore, the cognitive demand of interviews create can influence survey response and understanding (G. B. Willis & Artino, 2013). Thirdly, the CI can fail to detect the problems with the survey, perhaps if there were too few interviews to uncover all problems. Applying a framework and inquiring through a standardised method of design, as in this study, can help minimise these errors (Conrad & Blair, 2004).

This study did not extrapolate the performance scores of participants to infer or imply meaning, or even calculate the participants scores for ITEM (Kane, 2013). For example, it's not established in this study whether a high ITEM score reflects a better experience or technology assessment. A comprehensive approach to validation needs to consider this in different settings and educational outcomes given the simulation-based assessments are surrogates to real-world performance (David A. Cook & Hatala, 2016). Future study of exploratory factor analysis on the ITEM with a larger group of participants in these settings is recommended.

comprehensible and adds to the accumulating evidence to support the interpretation of the intended indirectly measurable concepts. Two questions were amended to improve questionnaire design. The ITEM development explored the evidence that supported a theoretical frame- work. Findings indicate the need for further work in assessing if the in- strument has value for assessing a growing field of technology use in educating current and future healthcare professionals. In particular, more extensive application of the instrument to multiple different MR medium and media to establish the degree to which inferences are made on the operationalisations of the construct and attempt to evidence the corre- spondence of theory with reality.

The participants identity was protected and personal information was not revealed in this study. Participants freely consented and informed of study withdrawal at any point. Written consent was provided for data to be used for publication, however, personal data is not available to be shared publicly. The study was approved by the undergraduate research office at Great Western Hospital, United Kingdom.

Chan, M., Uribe-Quevedo, A., Kapralos, B., Jaimes, N., Jenkin, M., & Kanev, K. (2020). A preliminary usability comparison of augmented and virtual reality user interactions for direct ophthalmoscopy. Aug 12-14. In Paper presented at the IEEE 8th international conference on serious games and applications for health (SeGAH) (Vancouver, CANADA).

Gupta, A., Cecil, J., & Pirela-Cruz, M. (2018). A virtual reality enhanced cyber physical framework to support simulation based training of orthopedic surgical procedures. Aug 20-24. In Paper presented at the 14th IEEE international conference on automation science and engineering. Munich, GERMANY: IEEE CASE). Tech Univ Munich.

