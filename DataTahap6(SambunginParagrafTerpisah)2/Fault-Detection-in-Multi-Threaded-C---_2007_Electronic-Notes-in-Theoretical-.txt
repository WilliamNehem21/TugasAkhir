Due to increasing demands in processing power on the one hand, but the physical limit on CPU clock speed on the other hand, multi-threaded programming is becoming more important in current applications. Unfortunately, multi-threaded programs are prone to programming mistakes that result in hard to find defects, mainly race-conditions and deadlocks. The need for tools that help finding these faults is immanent, but currently available tools are either difficult to use because of the need for annotations, unable to cope with more than a few 10 kLOC, or issue too many false warnings. This paper describes experiments with the freely available tool Helgrind and results obtained by using it for debugging a server application comprising 500 kLOC. We present improvements to the runtime analysis of C++ programs that result in a dramatic reduction of false warnings.

Runtime-methods scale well, but only faults on the path of execution are taken into account. Hence, detecting all possible data races is impossible. But it is possible to detect and report all apparent data races on the execution path. An efficient lock-set based runtime-algorithm called Eraser [14] was implemented in the open- source tool Valgrind and is thereby available for all Linux-x86 based environments. Unfortunately, at least for C++ applications, the number of falsely reported possible data races is too large, making the tool difficult to use since every reported location has to be checked by hand.

The solution is to combine both static and runtime analysis, by annotating the program automatically and transparently to the programmer. The annotation provides the runtime method with additional knowledge gathered from the structure of the source code. While these hints reduce reporting of false positives, they are not necessary. Therefore, it is still possible to analyze programs, where only parts of the source code are available.

This work presents results from experiments where the Eraser implementation in the tool Helgrind was applied to an existing network server application. Two improvements were made: One to better simulate actual hardware behavior (i.e. bus locking). Another to cope with effects introduced by C++ specific implementation issues. This drastically reduces the amount of false positives reported, making the tool usable for the debugging of large C++ applications. In particular, the amount of false positives removed by our improvements during our experiments was in the

This paper is organized as follows: Section 2 contains an overview of runtime methods for fault detection in multi-threaded programs and presents the runtime detection implemented in Helgrind in greater detail. In Section 3, we present our method of source-code annotation in order to make runtime analysis more accurate and describe the general environment for the experiments. Section 4 contains re- sults from our experiments. Finally, Section 5 concludes the paper with a general discussion of our results.

In this section, we first present some definitions of faults unique to concurrent programs. Then an overview of runtime methods for detecting these faults is given. This is followed by a more detailed description of the algorithms implemented in the freely available tool Helgrind, which was used as a basis for our experiments.

Suppose, we have a data structure containing two elements: let us say the date- of-birth and age of an arbitrary person. The two variables depend on each other because, the current age of the person could be calculated by counting the time elapsed from date-of-birth until now. In addition, there is a synchronization object protecting access to the data. Two setter-methods exist, one to set the date-of-birth and the other to set the age. Now, when updating the structure we first write the new date of birth followed by a call to set the new value for age. Both methods use synchronization to protect their field accesses. Therefore the rule, that every single access to the shared location is protected by synchronization, is satisfied. Nevertheless, it is possible to reach an inconsistent state between two write accesses that depend on each other, because the lock is released in-between.

While usually not resulting in actual faults, the locking strategy itself has an impact on the performance of the application. At worst, all data are protected by a single (global) lock, resulting in unnecessary blocking of independent threads. Generally, heavy usage of a global resource by all threads degrades performance and drastically reduces the speed-up in multi-processor systems.

A method that was developed to detect data races in the DSM System Millipage is the algorithm DJIT [6]. It utilizes vector time frames and access logging to check the happens-before relation between concurrent accesses to a shared location. It relies on the assumption of an underlying coherent system and detects only the first apparent data race.

The main advantage of the lock-set algorithm is the ability to detect all possible data races that exist on the execution path. On the other hand, it sometimes gives too many false detections. DJIT tries to locate only apparent data races. Hence, it detects data races on a subset of shared locations that are reported by the lock- set approach and misses some real data races. Therefore, Multi-Race [13] tries to improve the data race detection capabilities by combining enhanced versions of Lock-set and DJIT into a common framework.

In [12] the authors combine a lock-set based data race detector with a vector clock based happens-before relation check on Java synchronization primitives. Ac- tions on these primitives are viewed as events that impose an order on memory accesses between them. Unfortunately, neither their assumption that unsynchro- nized memory writes become visible in causal order is true on all SMP systems, nor is the relation between signal and wait operations on conditions strong enough to impose the assumed order.

The basic synchronization object in POSIX-Threads is a mutex (mutual exclusion), with methods to acquire (lock ) and release (unlock ) it. Only one thread can hold a lock at any given time. All other threads that try to lock it are blocked until the mutex is released again.

There are cases where the algorithm is now incomplete because of its dependence on the actual interleaving. A data race occurs when the first read access by another thread occurs before the initialization of the shared memory is complete. It is not detected by the algorithm, because in the observed interleaving, all writes took place before the first (shared) read access.

Instead of a thread being owner of a shared variable that is in EXCLUSIVE state, it is now a thread segment that owns it. Then, whenever another thread accesses the memory, it is checked whether the thread-segments overlap. If not, the new thread-segment becomes the new owner instead of the variable switching into SHARED state.

Since the number of false positives due to polymorphic object destruction code is rather large and identifying them by hand is too much work, it is necessary to suppress them automatically. It is done by annotating every delete operation in the source code of the program in order to mark deleted memory for the race detection as exclusively owned by the running thread. That way, accesses by other threads during destruction are still detected.

When checking a program using the original Helgrind algorithm, it is not necessary to compile the source code in a special way. Symbol information is needed for convenience. Without the debug symbols, Helgrind is not able to print source line information or the function names on the call stack for locations where a fault is suspected. To check a program for errors, it can be run unmodified with Helgrind.

The application is built from several hundred kLOC of C++ code, hence exper- imental tools, only written as proof-of-concept, are not applicable. Furthermore, there are no restrictions on the usage of C++ language constructs ruling out many of these experimental tools that rely on the usage of only a subset of the C++ language (e.g., to keep the parser simple).

For data races, an on-the-fly checker (Helgrind) is used. Deadlocks on Mutex locks are detected by the application using a timeout while trying to acquire a lock inside the lock-function. Since the race-checker also does dead-lock detection, application level detection is not needed.

During our experiments, we found a number of real bugs in the analyzed program. Since the application has about 500 kLOC, it is not always easy to decide whether a reported warning is a true defect, a false warning or just a benign race. Nevertheless, we found a lot of real defects in the program - a selection of bugs that seem to be common is presented here.

In a multi-threading environment, the use of some of the system functions is not safe. Especially, all functions that use static data or, even worse, return a pointer to static data are not thread-safe. The usage of some of these functions in the application resulted in possible data races reported by the tool.

state. Nevertheless, a thread should be the single owner of an object, when the thread deletes the object. Hence, the data race checker could set the state of its memory to exclusive. This holds under the assumption that data is not accessed after calling delete and thereby invoking its destructor. Actual violations of this assumption are detected by ordinary memory checking tools that are able to detect acesses to released memory blocks. Therefore, it is not a special case for multi- threaded programs and could be neglected during data race detection.

The detection algorithm does not take into account that the operations are atomic. The read and write operations of the reference counter are atomic, because it is an integer value and all writes are protected by a bus locking prefix. It is impossible to derive that from simple observations, as the reference counter is part of the structure that contains the data.

Generally, most runtime techniques can execute on-the-fly or offline. Both have their advantages. On-the-fly analysis usually has a significant negative impact on the execution speed of the analyzed program. Offline analysis needs information logging which may result in heavy memory usage. On the one hand, on-the-fly

In our case, where each access to a memory location had to be logged, offline analysis would be almost impossible for long execution traces. Thus, the time consumed by analysis directly reduces the execution speed of the observed program. Furthermore, since Valgrind executes binaries on a virtual machine, even without instrumentation program execution is slow.

Nowadays, many implementations of on-the-fly race detection algorithms exist. Un- fortunately, most academic proof-of-concept implementations are not applicable to real-world applications. At least, the need to cope with more than a subset of C++ is a knockout criterion, because to our knowledge no parser is freely available that is able to generate an abstract syntax tree for the full ISO C++ language.

