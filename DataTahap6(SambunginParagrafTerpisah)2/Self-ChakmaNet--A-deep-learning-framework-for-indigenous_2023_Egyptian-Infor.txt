Mobile Assisted Language Learning (MALL) enables quick access for every learner regardless of location or time restrictions [14]. There are many existing AI based learning app, such as, Duolingo [27], Hello En- glish [11], Babbel [13], Memrise [28], and Busuu [29]. These apps provide learning facilities on some popular languages such as English, French, Spanish, Estonian, German, and Russian. But there is no such app for indigenous languages such as Chakma, Marma, Saotal etc. in Bangladesh. A digital learning platform is needed to preserve this lan- guage. AI can be implemented for enhancing the reading, writing, speaking and listening skills.

work because of its promising results in contemporary computer vision research. It generates heatmaps to the parts of the input image that model considers when making predictions. This could make it easier for users to understand how the network makes predictions.

Data cleaning was performed exclusively on the ISI numerals and EKush datasets. Following the cleaning process, the ISI numerals dataset was reduced to 19,392 images for the training and validation set, and 4,000 images for the testing set, resulting in a total of 23,392 images. It is important to mention that the original dataset prior to cleaning contained 27,500 images. Conversely, the Ekush dataset underwent a cleaning process resulting in a total of 17,745 images allocated to the training set, 5,053 images assigned to the test set, and 2,530 images designated for the validation set.

the two final loss values. In early epochs, the Self-ChakmaNet optimiza- tion learning curves exhibited notches for validation and test, but as the epoch continued on, the loss reduced toward zero with a saturation trend. Overall, the Self-ChakmaNet is well-fitted model as state-of-the- art MobileNet_V2 for Chakama Handwritten Character recognition.

predictions based on the stroke pattern of the character. All the pre- dictions of Self-ChakmaNet follows the stroke pattern of the character with hotter or red mapping in the heatmap. All these visualization out- comes support the interpretability of the models. These models are not making predictions on arbitrary features, rather than focusing impor- tant features as stroke pattern of the handwritten character. Overall, the Self-ChakmaNet is classifying the instances as MobileNet_V2 with a high degree of accuracy as well as from the relevant features.

[45], and [43]. The total number of parameter of BDNet [45] was more than 1.71 millions and the model proposed in literature [43] had even more than this number of trainable parameters. Compared to these gi- ant models, Self-ChakmaNet was trained on only 453k parameters and

