Technically, a normative code is seen as a set G of conditional norms, i.e. a set of such ordered pairs (a, x). For each such pair, the body a is thought of as an input, representing some condition or situation, and the head x is thought of as an output, representing what the norm tells us to be desirable, obligatory or whatever in that situation. The task of logic is seen as a modest one. It is not to create or determine a distinguished set of norms, but rather to prepare information before it goes in as input to such a set G, to unpack

Positive permission is more elusive. As a first approximation, one may say that something is positively permitted by a code if and only if the code explicitly presents it as such. Makinson and van der Torre distinguish what they call forward and backward permission as two distinct kinds of positive permission. Forward permission answers to the needs of the citizen, who needs to know whether an action that he is entertaining is permitted in the current situation. It also corresponds to the needs of authorities assessing the action once it is performed. If there is some explicit permission that covers the action in question, then it is itself implicitly permitted. On the other hand, backward permission fits the needs of the legislator, who needs to anticipate the effect of adding a prohibition to an existing corpus of norms. If prohibiting x in condition a would commit us to forbid something that is implicit in what has been expressly permitted, then adding the prohibition is inadmissible under pain of incoherence, and the pair (a, x) is to that extent protected from prohibition.

The proof theory of the various kinds of permissions contains various un- expected properties and proof-theoretic novelties. For example, whenever out satisfies a Horn rule, then the corresponding negperm operation satisfies an inverse one. Forperm and backperm are very different operations. Whereas forperm satisfies SI, backperm satisfies weakening of the input WI. Like nega- tive permission, backperm satisfies the inverse rule of any Horn rule satisfied by out; but forperm satisfies instead a subverse rule. See [24] for the details.

In this section we consider the proof rules of input/output logics as prop- erties that can be enforced on the components by exogenous coordination. In particular, it has been suggested by Makinson and van der Torre that the identity rule corresponds to a forward loop, and that the cumulative transitiv- ity rule corresponds to a feedback loop. We use lions to make this idea more precise. The problem can be phrased as follows. How far can the various ways of strengthening the input/output operation out1 to outn (n = 2,3,4) with out without +, be simulated by integrating other familiar devices into the system as a whole? Before we introduce the definitions, we consider two examples.

Whereas the identity rule and the cumulative transitivity rule are naturally modeled as feed forward and feedback loops, this is not the case for the dis- junction rule. In the semantics of input/output logics, this rule corresponds to reasoning by cases. We can consider reasoning by cases as a kind of exogenous coordination, in the sense that we can ensure that a component behaves like it is reasoning by cases, when it is not really doing so. The idea is that in the wrapper around the component, we need to generate the cases, and then we collect the outputs again.

Moreover, the properties of the lion depend on the properties of the com- ponents. For example, when both B and D satisfy identity, then the lion satisfies the identity rule. Likewise, when both B and D satisfy cumulative transitivity, then the lion satisfies this rule. However, when B satisfies the disjunction rule, then the lion does not have to satisfy the disjunction rule.

Thus far, we have assumed integer time, in the sense that the input and output streams may be seen as a function from the natural numbers to propositions. In other words, we have implicitly assumed that there is a clock such that every tick of the clock, a new output is generated from the input. This can be generalized to real time by making time explicit. For example, an abstract behavior type defines an abstract behavior as a relation among a set of timed- data-streams. We do not further consider this extension here.

Moreover, once we use streams, we can use more complicated channels. A typical example is a register channel, which delays the throughput of data. For example, a register(1) outputs its input with a delay of one clock tick. Such a channel contains a buffer, with an initial value which is outputted as the first element of the output stream.

In this section we discuss the relevance of interactive computing in general, and lions in particular, for research on agent theory and normative multi- agent systems. A pioneering approach which has inspired us is the work of Jan Treur and colleagues, on the design of interacting reasoning components [33]. Our discussion in this section is based on some of our own research. In the BOID agent architecture, interaction among the various mental attitudes like belief and desire, results in certain types of behavior. In a multi-agent system, a kind of qualitative game theory is used to describe and analyze the interaction among agents. In normative multi-agent systems, norms are used to coordinate the interaction among agents. Finally, in agent communication protocols, interaction is coordinated through social commitments.

Obligations can be defined in the BDI framework. The desires or goals of the normative system are the obligations of the agent. This contributes to the open problem whether norms and obligations should be represented explicitly, for example in a deontic logic, or they can also be represented implicitly.

The clauses deal with various circumstances. For example, the first clause expresses the objective of the norm. The second clause ensures that normative systems will only detect actual violations. Similarly, the third clause prevents arbitrary sanctions. The last clause shows that the sanction is undesirable, and hence will deter agents from violating the norm.

goal, while abstracting from the individuals that will eventually execute them. A role is usually described in terms of normative descriptions, expectations, standardized patterns of behavior, social commitments, goals and planning rules. The normative description specifies the obligations that any agent who plays the role (called the actor) should obey. Goals are his intrinsic motiva- tions. Roles, thus, seem to be strictly related to the notion of agent: they are described using notions like actions, goals and obligations.

In agent theory there are at least two kinds of semantics. One is based on the paradigm of mental attitudes. it makes specific assumptions about the internal architecture of the agents. The other is based on social commitments, and makes no assumptions about the agents. This approach is more in line with the paradigm of interactive computing. In this section we discuss the two approaches, and also propose a synthesis [8].

The method we adopt is to model dialogue as a game in which agents play roles. Speech acts are moves in the game and their preconditions and effects refer to the mental states attributed to the roles, not to the mental states of the agents themselves. This approach presupposes that mental attitudes can be attributed to roles as well as to agents. Following [10,12], we describe roles as agents with mental attitudes, albeit of a different kind, since they are not autonomous.

Since such dialogue games consist of both constitutive and regulative rules, they can be considered as a normative multi-agent system. Just as for roles, our view of normative systems is based on the agent metaphor: a normative system can technically be considered as an agent to which mental attitudes are attributed. Moreover, normative systems, like organizations, can be artic- ulated in roles.

In this paper we consider logical input/output nets, or lions for short, as models of interactive computing. Lions are based on input/output logic, a deontic logic not used as a non-classical inference engine deriving output from input, but as a secretarial assistant for transformations from input to output. We present a few definitions, but no formal results.

input. Yet another alternative applies an input/output operation at every propositional input, but assumes that the set of norms can change over time. Secondly, we consider lions with AND and register gates, formalizing the behavior of channels and connectors. The extension illustrates how gates from Boolean circuits can be used to extend lions, and how operators for streams can be introduced to model behavior over time. We also observe that more

Our discussion has highlighted a number of future research directions for lions. A proof theory for lions can be developed, constraints can be added to lions, and permissions can be introduced to distinguish two kinds of outputs. The introduction of time in streams introduces new possibility of studying new proof rules of input/output logics, and the introduction of new kinds of channels and gates introduces a variety of new conceptual and formal issues. Given the huge number of possible extensions, we feel that we need guid- ance to develops lions, just like the development of input/output logic has been guided by issues in deontic logic. We are motivated to build normative multi-agent systems on top of lions, based on the idea that interaction plays a crucial role in normative multi-agent systems. In the agent architecture the behavior of an agent is determined by the interaction among the mental atti- tudes, in a multi-agent system game theory is used to describe and analyze the interaction among agents, in normative multi-agent systems norms are used to coordinate interactions among agents, and in communication interaction is

One particular extension we believe can be guiding the further develop- ment of lions for normative multi-agent systems is the development of value webs, which are networks that describe the exchange of value. For example, a value web may model the exchange of goods for money, possibly including third parties such as shippers and banks. We suspect that when not only information but also values are transported over channels, new issues arise.

