We present new algorithms for determining optimal strategies for two-player games with proba- bilistic moves and reachability winning conditions. Such games, known as simple stochastic games, were extensively studied by A.Condon [2,3]. Many interesting problems, including parity games and hence also mu-calculus model checking, can be reduced to simple stochastic games. It is an open problem, whether simple stochastic games can be solved in polynomial time.

tation of the search space as a subset of the hyper-cube [0, 1]N . The main idea is to divide this set into convex subregions in which linear optimization methods can be used. We show how one can proceed from one subregion to the other so that, eventually, a region containing the optinal payoffs will be found. The total number of subregions is exponential in the size of the game but, in practice, the algorithms need to visit only few of them to find a solution.

Many problems studied in computer science have an elegant presentation in a form of two-player graph games with various winning conditions. This in- cludes verification of open components, controller synthesis and also theory of alternating automata. Hence a question of finding efficient algorithms for solv- ing graph games, i.e., for deciding which player possess a winning strategy and

In this paper we focus on simple stochastic games [2]. These are two-player, turn-based games with random moves. The objective in the game is to reach a final position (a sink) with the best possible associated payoff. Thus, rather than looking for a winning strategy, we want to find an optimal strategy, that is a strategy which guarantees the best expected payoff for a player.

We are interested in this kind of games because, on the one hand, other important graph games, like parity and mean-payoff games, can be easily reduced to simple stochastic games. On the other hand, simple stochastic games are instances of general stochastic games which have a rich and well developed theory. We believe that this link between an old area of operational research and the current studies can provide new insights into the problem of the complexity of graph games. Simple stochastic games are also interesting as a model for open, probabilistic components. Efficient algorithms for solving simple stochastic games can be used for verification of such components or even for synthesis of components meeting given specification.

The rest of this paper is organized as follows. Section 2 contains basic definitions and properties of simple stochastic games. The existence of the optimal value and memoryless determinacy of the game is stated here. We present first of our algorithms in Section 3. We prove its convergence to the op- timal solution and also prove that the number of iterations of the algorithm is bounded by the number of different strategies in the game. Section 4 describes our second algorithm. It is a modification of the first algorithm which replaces costly solving of linear optimization problems by much simpler computations. We prove convergence of this simplified version of the algorithm and argue that the number of iterations is at most exponential in the size of the game. In Section 5 we describe the strategy improvement algorithms which we use as yardsticks to measure performance of our algorithms. Section 6 summarizes results of our experiments.

For each (nonterminal) position x game G(x) starts at x and is played until a sink is reached. Hence a play of G(x) is a maximal path x, x1, x2,... in the graph G. If it ends in a sink s then the outcome of the play is p(s) and player max is interested in maximizing this outcome while min wants to minimize it.

In each step of Algorithm 1 a linear optimization problem must be solved. This can be done in polynomial time but the solution can be costly to compute. In the next algorithm, we propose how to replace the linear optimization problem by much simpler computations at the expense of performing only sub-optimal improvements in each iteration.

None of the known methods for solving simple stochastic games has satisfac- tory complexity analysis. It seems though, that one of the simplest methods, the strategy improvement, works particularly well in practice. We decided to use strategy improvement algorithms as yardsticks to measure efficiency of our new algorithms.

number of iterations each algorithm needs to solve a game. This means that we treated solving a linear constraint problem as an atomic operation. For Algorithm 3 we counted the total number of strategy updates, taking into account also the costs of the inner loop of step 2.

Our main contribution is a new technique for finding the optimal values of a simple stochastic game which is comparable with the strategy improvement method. The technique is based on a geometric interpretation of node valua- tions as points in the hyper-cube [0, 1]N and identification of player strategies with the subregions of this cube. In this setting we show a different method for improving the current pair of strategies by advancing from one subregion to the other in a monotonic way.

