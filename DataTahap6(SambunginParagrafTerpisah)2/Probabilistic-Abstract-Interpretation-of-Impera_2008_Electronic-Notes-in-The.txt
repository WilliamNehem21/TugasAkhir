In 1981, Kozen [3] described a semantics for probabilistic programming languages in terms of linear operators on Banach spaces. A program is then a linear map from an input probability measure (the joint distribution of the initial values of its vari- ables) to an output sub-probability measure (since there may be some probability of non-termination). Monniaux [4] and Di Pierro and Wiklicky [6] use two different ideas to extend abstract interpretation to these domains, resulting in a probabilistic abstract interpretation.

This paper is structured as follows. In Section 2 we describe a simple imper- ative language with message passing, and give a concrete probabilistic semantics in Section 3. Following this, we review the framework of abstract interpretation in Section 4 before presenting our abstraction and abstract semantics in Section 5. We conclude with Section 6.

Note that these expressions are always linear. This does not reduce expressivity, since non-linear operations can be encoded using loops. By defining our language in this way we will need only to abstract loops in order to abstract non-linear behaviour, hence two separate abstractions are not necessary.

Note that without loss of generality, we only allow a variable to be compared with a constant. Since we can construct more complex comparisons by first defining a new variable, this serves to simplify our abstraction as we shall see later. Furthermore, conjunctions and disjunctions of conditions can be expressed (albeit inefficiently) by nesting if-statements, hence are not necessary as primitives.

Before we describe our semantics in terms of probabilistic automata, we first need to describe the data environment of a program; in other words, the domain of its variables. Rather than considering individual values that a variable can take, we consider it to take a range of values according to some probability distribution. In essence, variables are viewed as random variables and the operation of the program is to transform them. However, since we are only concerned with the distribution of these random variables (specifically, their joint distribution), we can treat the program as operating on this distribution directly.

Calling a function f , defined f (Xj1 ,... , Xjn ) { C }, can be thought of as modifying the denotation of the body of the function so that the argument variables are re- placed by the actual arguments, and the return call is replaced by the appropriate variable assignment. More formally: is the composition of the originals. If there is more than one start or exit transition, we must take all possible combinations. Hence in the worst case, the size of the automaton may grow exponentially in the number of branching instructions.

Classical abstract interpretation [1] is a mathematical framework that relates a concrete domain to an abstract one. Properties in the abstract domain are safe approximations (supersets) of their concrete counterparts. By constructing a suit- able abstract domain and abstract semantics, we can reason about properties of a program that would otherwise be undecidable in general, at the cost of some precision.

In the probabilistic setting, our domains are Banach spaces rather than pre- ordered sets, but the above approach still applies. By applying classical abstract interpretation to the probabilistic setting, we take an approach similar to Mon- niaux [4]. Rather than comparing measures by their total measure, however, we choose a much stronger comparison, which we call the strict ordering on measures.

An alternative approach taken by Di Pierro, Wiklicky et al [6,5] is to look for a probabilistic analogue of the Galois connection. This, the Moore-Penrose pseudo inverse, gives the closest approximation to the inverse of a function, leading to a probabilistic notion of safety. While this approach has had much success, it is difficult to use in practice for infinite Banach spaces (i.e. continuous measures), such as the ones we consider.

We would like our concrete domain to consist of all possible measures, and our abstract domain to be the truncated multivariate normal measures, as described. Unfortunately, constructing an abstraction function from such a domain is not a simple task. Not only does it contain measures that we cannot write down, but it is difficult to satisfy the relational homomorphism property (Definition 4.1). Instead we restrict our concrete domain to those measures that can be computed by a series of linear operations and truncations applied to a multivariate normal measure. Whilst this is restrictive, it still allows us to represent a useful class of measures, and loosening this is the subject of future work. More formally:

The interesting case is the last one, which identifies loops whose variables are only incremented or decremented by a constant value. This occurs when the covari- ance matrix is unmodified, meaning that the variables have only been shifted by a constant amount. We can extend this to detect other types of loop activity (for example, a multiplicative update), but that is beyond the scope of this paper.

We conclude this paper with a brief discussion of the abstract collecting semantics. As we have seen, our memoised abstract interpretation associates a set of measures to each state in the abstract semantics. We are not interested in the set itself, however, but in the sum of the measures it contains. Thus our collecting semantics can be seen as a way to safely approximate this sum to a measure that is easier to compute. This need not be a truncated multivariate normal measure as the result of this final stage of analysis is not needed for further computation.

At present, the only general solution we have is a numerical one. To compute an upper bound of the measure on a particular interval [a, b], we iteratively sum all the measures in the set, applied to this interval. Although the set of measures will in general be infinite, we note that the iterated sum will quickly converge as the residual probability mass exponentially decreases. It is easy to calculate such measures from a truncated multivariate normal measure, by performing eigenvalue decomposition to separate it into independent truncated normal measures. This loses some precision, since we over-approximate the truncation interval, but it is a safe approximation.

In this paper, we presented an abstract interpretation of a probabilistic automaton semantics for a simple imperative language. We believe that this work is comple- mentary to other approaches to probabilistic abstract interpretation, allowing an efficient approximation to the behaviour of programs whose input is governed by a probability distribution. There is clearly some way to go in terms of improving this approach, for example finding a better abstract collecting semantics and a greater range of widening operators. We also need to carry out some larger case studies, to investigate the precision of the bounds in comparison to other methodologies.

The ultimate aim of this work is to provide a formal framework for the ideas presented in [8], where we attempt to derive stochastic models of communication protocols directly from source code. The advantage of abstract interpretation is that it can be easily automated, and therefore fits in well with the aim of providing tools that can be used by real developers. We feel that the abstract interpretation presented in this paper is an important milestone towards this goal.

