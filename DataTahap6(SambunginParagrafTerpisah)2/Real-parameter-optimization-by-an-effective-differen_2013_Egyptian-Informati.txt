Abstract This paper introduces an Effective Differential Evolution (EDE) algorithm for solving real parameter optimization problems over continuous domain. The proposed algorithm proposes a new mutation rule based on the best and the worst individuals among the entire population of a particular generation. The mutation rule is combined with the basic mutation strategy through a linear decreasing probability rule. The proposed mutation rule is shown to promote local search capability of the basic DE and to make it faster. Furthermore, a random mutation scheme and a modified Breeder Genetic Algorithm (BGA) mutation scheme are merged to avoid stagnation and/or premature convergence. Additionally, the scaling factor and crossover of DE are introduced as uniform random numbers to enrich the search behavior and to enhance the diversity of the pop- ulation. The effectiveness and benefits of the proposed modifications used in EDE has been exper- imentally investigated. Numerical experiments on a set of bound-constrained problems have shown that the new approach is efficient, effective and robust. The comparison results between the EDE and several classical differential evolution methods and state-of-the-art parameter adaptive differ- ential evolution variants indicate that the proposed EDE algorithm is competitive with , and in some cases superior to, other algorithms in terms of final solution quality, efficiency, convergence rate, and robustness.

plex optimization problems. The rest of the paper is organized as follows. In Section 2, the standard DE algorithm is intro- duced. Next, in Section 3, the new EDE algorithm is described in detail. Section 4 reports on the computational results of test- ing benchmark functions and on the comparison with other techniques is discussed. Section 5 discusses the effectiveness of the proposed modifications. Finally, conclusions and future works are drawn in Section 6.

where j = 1, 2, ... ,D, rand(j) e [0, 1] is the jth evaluation of a uniform random generator number. CR e [0, 1] is the crossover probability constant, which has to be determined by the user. randn(i) e {1, 2, ... , D} is a randomly chosen index which en-

All evolutionary algorithms, including DE, are stochastic popu- lation-based search methods. Accordingly, there is no guarantee to reach the global optimal solution all the times. Nonetheless, adjusting control parameters such as the scaling factor, the crossover rate and the population size, alongside developing an appropriate mutation scheme, can considerably improve the search capability of DE algorithms and increase the possibil- ity of achieving promising and successful results in complex and large scale optimization problems. Therefore, in this paper, four modifications are introduced in order to significantly enhance the overall performance of the standard DE algorithm.

and combine the global search capability with local search ten- dency. The strength and efficiency of the above scheme is based on the fact that, at the beginning of the search, two mutation rules are applied but the probability of the basic mutation rule to be used is greater than the probability of the new strategy. So, it favors exploration. Then, in the middle of the search, through generations, the two rules are approxi- mately used with the same probability. Accordingly, it bal- ances the search direction. Later, two mutation rules are still applied but the probability of the proposed mutation to be per- formed is greater than the probability of using the basic one. Finally, it enhances exploitation. Therefore, at any particular

Hence, F must be a positive value in order to bias the search direction for the trial vectors in the same direction. In fact, if the value of F is kept constant value the diversity of the popula- tion is extremely decreased during the search process as the all the vectors are perturbed by the same difference vector compo- nent. Therefore, Instead of keeping F constant during the search process F is set as a random variable for each trial vector so as to perturb the best vector xG by different directed weights. There- fore, F is introduced as a uniform random variable in [0.2, 0.8], where the range is determined empirically. Accordingly, this range ensures both exploitation tendency (with small F values) and exploration ability (with large F values). In order to reduce the number of parameters of the proposed algorithm F is also used with basic mutation.

After many experiments, in order to make a comparison with other algorithms with all dimensions, we observed that d = E 06 and K = 25 generations are the best settings for these two parameters over all benchmark problems and these values seem to maintain the convergence rate as well as avoid stagnation and/or premature convergence in case they occur. Indeed, these parameters were set to their mean values. In this paper, these settings were fixed for all dimensions without tun- ing them to their optimal values that may attain good solutions better than the current results and improve the performance of the algorithm over all the benchmark problems.

its diversity as well as advance its local tendency through a search process. Thus, after the above analysis and discussion, the proposed algorithm EDE show competitive performance in terms of quality of solution, efficiency, convergence rate and robustness. It is superior to conventional DE methods, and it is also competitive with and, in some cases superior to the-state-of-the-art well-known self-adaptive DE algorithms and its three versions EDE 1, EDE 2 and EDE 3. Accordingly, the main benefits of the proposed modifications are the remark- able balance between the exploration capability and exploita- tion tendency through the optimization process that leads to superior performance with fast convergence speed and the ex- treme robustness over the entire range of benchmark functions which are the weak points of all evolutionary algorithms.

