e.g. [22], however we believe that they are fundamentally different concepts: assertions are lacking one important ingredient for representing built-in test- ing, which is the notion of a test or a test case. Assertions can be used in a test and provide valuable information for error detection during test execution, but one cannot say that an assertion or its execution represents a test. A test is an experiment under controlled conditions that applies a set of test cases in a test procedure or test framework; so that we can only talk about built-in testing if we have test cases as integral part of components. Built-in testing strategies comprise the built-in self-test metaphor whose idea is derived from the self-test capabilities commonly built into hardware components. Built-in self test components are software modules that comprise their own test cases. In sloppy terms we could say that these are software components coming with their own tests for checking their own implementation.

So far, the principles of built-in tests have been developed [8,11]. However, there model-based design, specification and execution has not yet been con- sidered to a large extend. In particular in the realm of MDA (model-driven architectures), the modeling of built-in tests as an integral part of component and system development needs to be addressed. With the development of UML 2.0 [20] together with the UML 2.0 Testing Profile [21,27] he technolog- ical base for model-based component and test development has been created. This paper will specifically discuss the use of UML for the model-based ap- proach towards built-in tests.

The paper describes at first the principal concepts of built-in tests and proceeds with the generation of built-in tests from system models. Subse- quently, the specification of built-in tests and their execution are discussed. An example demonstrates the application of model-based built-in tests. The paper concludes with an outlook.

A test involves the invocation of the methods of an associated component with predefined input values and the checking of the returned results against the expected results. The input data and expected results are referred to as a test case. Under the object paradigm, a test case also often not only involves the checking of the results of the method invocations but also the checking of the correctness of the state transitions according to the external states. A test suite for a server tester component therefore contains a num- ber of test cases that are developed according to distinct testing criteria, for example the coverage of the state transition model or the coverage of the functional specification. These are typically augmented with tests according

The basic principles of encapsulation and information hiding dictate that external clients of a component should not see the internal implementation and internal state information. The external test software of a component therefore cannot get or set any internal state information. The user of a correct component simply assumes that a distinct operation invocation will result in a distinct externally visible state of the component. However, the component does not usually make this state information visible in any way. This means that expected state transitions as defined in the specification state model cannot normally be tested properly. The contract testing paradigm is therefore based on the principle that components should expose their logical or externally visible (as opposed to internal) states by extending the normal functional server.

Testing that is based on the UML has many concepts in common with tra- ditional code-based testing techniques. Source code can be seen as a con- crete representation of a system, or parts thereof, and UML models are more abstract representations of the same system. More concrete representations contain more and more detailed information about the workings of a system. It can be compared with zooming in on the considered artifacts, generating a finer grained representation but gradually loosing the overview on the entire system. Less concrete representations contain less information about details but show more of the entire system. This can be compared with zooming out to a coarser grained level of representation making it easier to overview the entire system but loosing the details out of sight. The advantage of using model-based development techniques and the UML for development and test- ing is that a system may be represented entirely through one single notation over all levels of detail, that goes from very high level and abstract repre- sentations of the system showing only its main parts and most fundamental functions, down to the most concrete possible levels of abstraction similar and very close to source code representations. It means that in a development project we are only concerned with removing the generality in our descriptive documents without having to move between and ensure consistency among different notations. The same is true when testing is considered.

Code-based testing is concerned with identifying test scenarios that satisfy given code coverage criteria, and exactly the same concepts can be applied to more abstract representations of that code, i.e. the UML models. In that respect we can certainly also have model coverage criteria for testing. In other words, more abstract representations of a system lead to more abstract test artifacts, and more concrete representations lead to more concrete test artifacts of that system. Therefore, in the same way in that we are removing the generality of our representations in order to receive finer grained levels of detail and eventually our final source code representation of the system, in parallel we have to remove the generality of the testing artifacts for that system and move progressively towards finer grained levels of testing detail. Also, the system models in UML have to be accompanied by test models in UML, for which purpose the UML Testing Profile [21,27] has been developed.

Coverage is an old and fundamental concept in software testing. Coverage criteria in testing are used, based on the assumption that only the execution of a faulty piece of code may exhibit the fault in terms of a malfunction or a deviation from what is expected. If the faulty section is never executed in a test it is unlikely to be identified through testing, so program path test- ing techniques, for example, are amongst the oldest software testing and test case generation concepts [30] in software development projects. This idea of coverage has led to quite a number of structural testing techniques over the years that are primarily based upon program flow-graphs [2] such as branch coverage, predicate coverage, or DU-path-coverage to name only a few. These traditional coverage criteria all have in common that they are based on doc- uments (i.e. flow graphs, source code) very close to the implementation level. Traditionally, these coverage criteria are only applied at the unit level which sees the tested module as a white box for which its implementation is known and available to the tester. On a higher level, in an integration test, the individual modules are only treated as black boxes for which no internal knowl- edge is assumed. An integration test is traditionally typically performed on the outermost sub-system that incorporates all the individually tested units, so that we assume white-box knowledge of that outermost sub-component, but not of the integrated individual units. Traditional developments only separate between these two levels: white box test in unit testing, and black box test in integration testing. Additionally, there may be an acceptance test of the

More modern recursive and component-based development approaches do not advocate this strict separation since individual units may be regarded as sub-systems in their own right, i.e. components for which no internal knowl- edge is available, or integrating sub-systems, i.e. also components, for which internal knowledge may be readily available. Particularly in component-based developments where we cannot really strictly separate units from sub-systems both approaches may be readily applied in parallel according to whether only black-box information, e.g. external visible functionality and behavior, or ad- ditionally white-box information, e.g. internal functionality and behavior, are available.

The UML testing profile is an extension of UML 2.0 being based upon the UML metamodel. It defines a modeling language for visualizing, specifying, analyzing, constructing and documenting the artifacts of a test system. The testing profile particularly supports the specification and modeling of soft- ware testing infrastructures. It follows the same fundamental principles of UML in that it provides concepts for the structural aspects of testing such as the definition of test components, test contexts and test system interfaces, and behavioral aspects of testing such as the definition of test procedures, test setup, execution and evaluation. The core UML may be used to model and describe testing functionality since test software development can be seen as any other development for functional software properties. However, as soft- ware testing is based on a number of special test-related concepts these are provided by the testing profile as extensions to UML. The concepts are mainly grouped into concepts for test architecture, test behavior and test data.

A means for evaluating test results derived by different objects within the test system in order to determine an overall verdict for a test case or test suite. This evaluation process is called arbitration. Users can either use the default arbitration scheme of the profile (i.e. the classical functional arbitration, where negative results have priority over positive results), or define their own arbitration scheme using an arbitration test component.

Test behaviors specify the actions and evaluations necessary to check the test objective, which describes what should be tested. For example, UML interaction diagrams, state machines and activity diagrams can be used to define test stimuli, observations from the SUT, test control/invocations, co- ordination and actions. However, when such behaviors are specified as tests the prime focus is given to the definition of normative or expected behaviors. The handling of unexpected messages is achieved through the specifica- tion of defaults providing the means to define more complete, yet abstract test models. This simplifies validation and improves the readability of test models. The separate behavior of defaults is triggered if an event is observed that is not explicitly handled by the main test case behavior. The partition- ing between the main test behavior and the default behavior is up to the designer. Within the testing profile default behaviors are applied to static behavioral structures. For example, defaults can be applied to combined frag-

Another important aspect of test specification is the use of wildcards in test data. For example, pattern matching and regular expressions are very useful when specifying behavior for handling unexpected events, or events containing many different values. Therefore, the UML testing profile introduces wildcards allowing the specification of: (1) any value, denoting any value out of a set of possible values, and (2) any or omitted values, denoting any value or the lack of a value (in the case where multiplicities range from 0 upwards).

JUnit is an open source unit testing framework, which is widely used by developers who implement unit tests in Java. The mapping primarily focuses on the JUnit framework. For instance, when no trivial mapping exists to the JUnit framework, existing JUnit extensions such as for re- peated test case runs or for active test cases can be used.

TTCN-3 (Testing and Test Control Notation [14,28,25]) is widely ac- cepted as a standard for test system development in the telecommunica- tion and data communication area. TTCN-3 is a test specification and implementation language to define test procedures for black-box testing of distributed systems. Although TTCN-3 was one basis for the devel- opment of the testing profile, they differ in some aspects, but the UML testing profile specifications can be represented by TTCN-3 modules and executed on TTCN-3 test platforms.

This section elaborates with an example the individual parts and steps to- wards model-based built-in tests. The RIN system [23], which supports work- ing floor maintenance staff in their everyday working tasks, is taken as an example. This communication system hosts multiple communication devices that are interconnected through a radio network and controlled and supported by a number of desktop working places. The desktop working places help the maintenance staff to achieve their tasks and provide additional information. They can guide a worker through complex tasks by looking at the video signals from the workers video facility, give advice to the worker through the audio device, and provide additional information, for example the download of user manuals or video-based repair guides. Each of the communication devices has defined capabilities that are made public to all the other devices through the Resource Information Network.

about a valid client from the environment. The test case Registering can be executed by the Client built-in test component (runs on) and tests the RINServer component (system). It initially activates a default to handle all unexpected or no responses from the server. The test initially checks the precondition for the tests and the proceeds with the main body by trying to register the valid client. Afterwards, the result is checked: is the client really registered and is the RINServer in state registered. All valid executions of the tests result in a pass verdict. Invalid executions lead to fail. If the precondition for the test is not fulfilled an inconclusive will be returned.

