The omnipresence of resource-constrained embedded systems makes them critical components. Program- mers have to provide strong guarantees about their runtime behavior to make them reliable. Among these, giving an upper bound of live memory at runtime is mandatory to prevent heap overflows from happening. The paper proposes a semi-automatic technique to infer the space complexity of ML-like programs with explicit region management. It aims at combining existing formalisms to obtain the space complexity of imperative and purely functional programs in a consistent framework.

In this paper, we propose a language `a la ML mixing purely functional and imperative features with an explicit region mechanism. To retrieve information about a program memory interactions, we rely on a static type & effect system and manual memory management through region related primitives. The type system aims at ensuring the absence of memory-related errors at compile time. To

The main goal of this paper is to introduce a framework to combine various memory consumption analyses depending on the programming style used at func- tion level to provide an upper bound of live memory at compile time considering reclaimed memory. In the remainder, related works are presented in section 2. We describe the language in section 3 with its type & effect system on which we base our analysis. Then, we show how to deal with purely functional and imperative features in sections 4, 5 as described above and section 6 composes them in a con- sistent framework. Then, we show how it works on an example in section 7. Finally, we conclude with a discussion about current limitations and further improvements.

Resource consumption analysis started in the late 70s with METRIC [14] targetting the best, worst and average execution times of programs written in a pure subset of Lisp. Based on recurrence relations, it can be adapted to memory consumption analysis. Contrary to time, memory can be reclaimed. Hence, new methods have emerged from both purely functional and imperative communities to obtain upper bounds on live memory.

several projects. Among them, RAML [7], a pure ML language and RAJA [8], a subset of the Java language. It is able to infer polynomial bounds on live memory considering some side-effects [5] in the last version without any user annotation.

Invariants over iteration spaces have been used in the JConsume [2] project targetting the Java language. It considers side-effects through an escape mechanism. It also relies on invariants provided by external tools or the programmer to extract program space complexity. Thanks to the escape mechanism, it can provide an upper bound on live memory.

In modern high-level languages, memory management is often performed by a garbage collector. Mainly ruled by dynamic criteria, predicting its behavior is a difficult problem. For instance, we need to know when it will be triggered and how much memory will be reclaimed.

that the access to a value in region r is sound. For region allocated values, we have different rules. We need to distinguish region handlers from other values because of the linearity constraints. The role of the primitive instantiate is to replace type parameters with fresh type variables. Hence,

To introduce capabilities in the system, the primitive newrgn has to be used. It gives the permission to allocate, read, write values in the region. We can see that the capability is qualified with a linear property. At creation, we know that it has not been shared. This is an important criterion for reclaiming a region.

Sometimes using a region handler several times is necessary. For instance, when you need to pass several region handlers as arguments to a function. This is the case when you use a function that copies a list in two distinct regions. To perform this, aliasrgn can help. Leaving the scope of this primitive restores the linearity property we had before.

We have a set of rules giving information about the memory behavior of our programs and providing guarantees that a well typed should not crash because of memory management. Moreover, regions give us an abstract view of the heap at compile-time. In section 6, we will see how this view can be useful to do a resource consumption analysis.

To perform a resource consumption analysis, we need to model the runtime en- vironment with respect to memory usage. Programs written in our language can allocate memory with the creation of five different kinds of values: closures, pairs, lists, references and region handlers. Thus, we introduce five constants representing the amount of allocated memory for a pair, a list node, an empty list, a reference and a region handler. For closures, we introduce a specific operator because the amount of memory used is proportional to the number of free variables. We assume that compilation schemes do not introduce additional heap memory allocations.

The goal of this analysis is to provide an upper bound of live memory at compile- time to prevent heap overflows. The analysis consists in a mix of several existing resource consumption analyses. It returns the amount of allocated memory in each region involved by a function call. With region sizes and the region mechanism, we are able to consider reclaimed memory.

To analyze a program, we distinguish functions written with a purely functional style from those written with an imperative style. To do this, we rely on the language effect system. In this language, side effects happen through reference updates. Hence, if a function type is labelled with a write effect on a region r then this function is considered impure and is analyzed with the analysis based on invariants on iteration spaces. Whereas if the function only performs alloc or read effects then it is seen as pure and can be analyzed thanks to automatic amortized analysis.

The analysis being compositional, we cannot easily count the number of times a function is applied. This constrains us to add the following restriction: potential contains in a function closure has to be null. Thus, memory consumption can only be parameterized by the function parameters.

The pattern matching rule is crucial. Depending on the branch taken, different assumptions about data structure sizes can be made. For instance, if the nil branch is taken then we know that the list is empty. But if the cons branch is taken then we know that the list has at list one element with its potential. This rule combined with allocation sites drive the analysis.

With this rule, the amount of potential available cannot be duplicated but is shared among different variables. For instance, List a k0 means that each list element has k0 credits. If this list is shared between variables x : List a k1 and y : List a k2 then we generate a constraint similar to k0 = k1 + k2.

This function can allocate memory in different regions (depending on how it is called). We are interested in the more general case. What size regions r, r1 and r2 will be? To do this we apply the analysis to each region. Hence, we are going to get three different sets of relations to minimize.

Programs written with an imperative style perform side-effects through the use of references. To consider them, we need to use a different method: invariants on iteration spaces. We rely on recent work done in the JConsume project [2] targeting Java programs at the bytecode level.

We adapt this analysis to programs written in our language. We still rely on the user to provide invariants. They can be expressed using all classic arithmetical and logical operators. These can be directly provided by her or obtained through the use of external tools. They are written with the with syntax as in

Contrary to the original work, here we do not care about the notion of escape memory as it is already handled through the use of regions. As in the automatic amortized analysis, we are looking for the sizes of the different regions involved in the computations. To perform this, invariants characterize the number of iterations. Here, invariants are linear relations but the user could provide other classes as well. The advantage of linear invariants comes when we try to infer them.

assignments are cumulative, meaning that data is added to previous data reachable through the reference. Hence, to determine the amount of memory reachable from them, we rely on the same invariants. In the end, we dereference ys and zs, so we propagate the amounts of memory reachable through these references.

To track side-effects, it is necessary to manage references with some accuracy. For instance, if a reference is updated then we need to propagate new size informa- tion about the value being dereferenced to pursue the analysis. Unfortunately, space complexities are not directly related to the sizes of the data structures involved. The

If the programmer employs the region mechanism with a fine granularity, it is possible to derive data structure sizes from space complexity. The function append is a good illustration of this principle. Its type shows that the two lists can reside in two different regions and that the resulting list lives in the same region than the second argument. The combination of the base case and the effect alloc r2 entails that data is added to the second list. Thanks to this, we can deduce that the size of the resulting list is the sum of lists passed as arguments.

When size relations cannot be extracted automatically, the programmer has to provide them manually with the with syntax just like for the imperative analysis to run the analysis. Annotations can be provided through the use of classic arithmeti- cal operators and the size operator. This size operator is a way to count the number of node of a data structure. Variables bound to integers can be used directly to refer to the integer itself.

Conditional expressions introduce the use of the operator max. To keep the analysis sound, we need to consider the worst case. Here, it means the maximum of memory allocated in a region and the maximum amount of memory reachable from a reference.

The following example shows how the analysis is performed. The main function is revappend which concatenates two lists by reversing the first one to be tail recursive. This function can be written in at least two different styles: purely functional and imperative.

The imperative version of revappend is analyzed thanks to invariants on it- eration spaces. Here, the side-effect is local to the function. Hence, the amount of allocated memory is the only information propagated. Here, the invariant is length !rs = size xs + size ys where size ys is a constant. It is linear and could be obtained in an automatic way. In other cases, we would rely on programmer annotations. From this, we can deduce the amount of allocated memory. In this case, it is also proportional to the length of the first list.

In this example, both analyses return similar results. Then, we can instantiate symbolic expressions to get the amount of memory necessary to execute the program in a safe way. Here, we can see that the region rr is freed at the end. If the program would be larger, this region would have been considered as non-existent to analyze the rest of the memory allocated.

We present a language `a la ML mixing pure and imperative features with an explicit region mechanism. Memory management is performed by the programmer through a set of primitives and checked at compile time. This mechanism provides information about the heap topology and lifespans of allocated values.

The analysis relies mainly on an effect system and a region mechanism. The effect system allows us to combine several analyses depending on the programming style employed by the programmer. Regions offer lifespans of allocated values. This prevents overpessimistic bounds because we can consider reclaimed regions at compile time. Automatic amortized analysis is used on pure functions and invariants on iteration spaces are employed on imperative functions.

