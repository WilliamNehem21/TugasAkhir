Conducting qualitative analysis necessitates substantial allocation of resources and time, which has been well-established in the research community (Smith, 2018; Patton, 2015; Heath et al., 2010). Video analysis, in particular, presents a formidable challenge due to its intri- cate nature, often demanding specialized technology and labor-intensive manual processes (Atkinson, 2007; Knoblauch et al., 2008). These processes can involve procedures such as: (1) crafting descriptive narratives of actors and activities (Laurier, 2019), (2) frame-by-frame analyses (Pipkin et al., 2016), (3) inductive extraction of themes (Krogh et al., 2015) and audio transcription (Schmidt et al., 2023; Schidt & Glaser, 2021a, 2021b). This becomes even more complicated when analyzing 360-degree spherical videos, due to their unique format and challenges in interpretation (Yaqoob et al., 2020). However, recent advancements in computer vision techniques like ob- ject detection and scene recognition, as well as artificial intelligence (AI) analysis methods such as deep learning and neural networks (Hwang et al., 2020) have the potential to revolutionize the way researchers analyze video data (Buch et al., 2011). These technologies can automate many manual processes like data labeling, feature extraction, and pattern recognition and provide more accurate and efficient results owing to their ability to process vast amounts of data swiftly and to learn from iterative processes (Tschang & Almirall, 2021).

Recent advances in technology have brought attention to the po- tential use of virtual reality (VR) technology in general, and SVVR in particular, as an intervention tool for autism (cf. Glaser & Schmidt, 2022; Schmidt et al., 2019). According to Slater (2018), VR is a computer-generated model of reality that allows users to interact with and obtain information from the model using ordinary human senses, and that is typically associated with three-dimensional environments benefits such as predictability, structure, customizable task complexity, control, realism, immersion, automation of feedback, assessment, and reinforcement (Bozgeyikli et al., 2018). Given the affordances of the technology, VR can be used to simulate real-life experiences in a controlled and safe environment (Dixon et al., 2020). This can help in- dividuals with autism develop the skills and confidence needed to suc- cessfully navigate real-world situations (Parsons & Cobb, 2016).

potential of AI technologies to facilitate the teaching and learning pro- cess with the goal of furthering inferences, judgments, and/or pre- dictions in educational settings (Holmes et al., 2016). In recent years, advances in computational systems and processing power has led to a renewed interest in using AI, and there is a growing number of studies being published that broadly explore the potential of this technology (Hwang et al., 2020). More specifically, AI has been widely applied to education technologies and learning environments including intelligent tutoring systems, teaching robots, learning analytics dashboards, adaptive learning systems, etc. (Hwang et al., 2020).

involve using data mining algorithms to analyze large datasets of stu- dent performance data, such as test scores, grades, and attendance re- cords, in order to identify factors that are associated with academic success (Ramaphosa et al., 2018). This information can then be used by educators to tailor their instruction and support to the needs of indi- vidual students, and to identify areas where additional resources or in- terventions may be needed. Data mining in education can also be used to identify trends and patterns in student behavior and engagement, such as the effectiveness of different teaching methods or the impact of various factors on student motivation and retention (Aldowah et al., 2019). By analyzing this data, educators can better understand the factors that influence student learning and achievement, and can use this information to make more informed decisions about how to improve teaching and learning in their classrooms (Bienkowski et al., 2012).

oso was a SVVR experience designed to model the behaviors of using public transportation for autistic adults. The target goals of the SVVR intervention were situated around providing a formalized shuttle training routine as transportation is often cited as being one of the greatest barriers to community integration for individuals with dis- abilities (Allen & Mor, 1997; Carmien et al., 2005). Virtuoso uses a stage-wise technique that progresses from simple to complex across a spectrum of low-tech to high-tech tools (Schidt & Glaser, 2021a, 2021b). The stage-wise approach includes (1) skill introduction, (2) 360-degree video modeling of the skill, (3) rehearsal of the skill within a fully immersive VR scenario, and (4) real-world practice of the skill. The work presented in this manuscript focuses entirely on the second stage of our approach. In this stage, users were presented within a series of 360-de- gree videos that broke the task of catching a shuttle bus into four discrete subskills, including: (1) check the daily schedule, (2) walk to the shuttle,

were also recruited from the day program, as they were student staff members. Purposeful sampling was used to identify autistic participants who would represent a broad range of comorbidities across the autism spectrum. Six autistic participants were recruited, all of whom were male, had a medical diagnosis of autism, and were between 22 and 35 (M = 26.6) years old. Autism diagnosis included the Peabody Picture Vocabulary Test (M = 134; min = 57; max = 196; SD = 58), Social Responsiveness Scale (M = 71; min = 65; max = 82; SD = 6), and the Behavior Rating Inventory of Executive Function (M = 79; min = 50; max = 94; SD = 17). In addition, six neurotypical participants were recruited. Convenience sampling was used to recruit neurotypical par- ticipants, all of whom were staff members in the adult day program, were evenly divided between male and female, and were between 21 and 26 (M = 22.6) years old. All participants viewed the SVVR videos in

This study took part within a structured usage test of the Virtuoso intervention, with all data being collected during June of 2019. Two separate groups of participants took part in the study: a group of autistic adults (n = 6) and a group of neurotypical peers (n = 6). Participants from each group took part in one data collection session that lasted around 1 h. During this time, participants viewed SVVR videos pre- sented using an Oculus Rift. Four videos were presented. The videos

In contrast to this, for ASD P1 in Step 1, the probability of transitioning from an object to a person varies. While for ASD P1, P3, and P4 there was a high probability of transitioning to a person state from an object state (96.8%, 95.8%, 70.3% respectively), the probability was lower for P6 (45.6%). For ASD P2 and P5, there was a much lower probability of transitioning to a person state from an object state (35% and 39.2%, respectively).

The majority of research investigating autistic gaze patterns has been performed using eye tracking technologies (Boraston & Blakemore, 2007; Guillon et al., 2014; Papagiannopoulou et al., 2014). The current study provides a novel method for gaining insights into how autistic users interact with and view SVVR videos and provides a comparison with neurotypical participants. The insights gained from the three AI questions pertaining to its validity and reliability remain unanswered. While our research design and methodologies were thoughtfully chosen to ensure rigor and objectivity, the nature of exploratory research inherently invites further investigation and replication to establish the generalizability and robustness of the findings. Future research with larger and more diverse datasets, as well as a broader range of SVVR contexts, could contribute to a more comprehensive understanding of SVVR behavior dynamics across different populations and scenarios.

g., Narejo et al., 2021). Using generic object detection models (for example, we used the general YOLO algorithm for object detection) is likely to be insufficient for specialized studies. Ultimately, real world applications need greater certainty in predicting the next state of objects (Zhao & Li, 2020). For better results, researchers need to train CV al- gorithms using the specific objects included in their data set (Ouyang & Wang, 2019).

During the preparation of this work the authors used ChatGPT 3.5 in order to improve language and readability, with caution. After using this tool/service, the author(s) reviewed and edited the content as needed and takes full responsibility for the content of the publication.

M. Exeter, A. Grincewicz, M. Schmidt, & A. Tawfik (Eds.), Intersections across disciplines: Interdisciplinarity and learningThe centrality of interdisciplinarity for overcoming design and development constraints of a multi-user virtual reality intervention for adults with autism: A design case. New York, NY: Springer.

A. A. Tawfik, A. Grincewicz, & M. Schmidt (Eds.), Educational technology beyond content: A new focus for learningPromoting acquisition and generalization of embodied skills in a 3D collaborative virtual learning environment for individuals severely impacted by autism. New York, NY: Springer.

