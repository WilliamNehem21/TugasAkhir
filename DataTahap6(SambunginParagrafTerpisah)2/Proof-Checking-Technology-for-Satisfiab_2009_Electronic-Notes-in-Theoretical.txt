A common proof format for solvers for Satisfiability Modulo Theories (SMT) is proposed, based on the Edinburgh Logical Framework (LF). Two problems arise: checking very large proofs, and keeping proofs compact in the presence of complex side conditions on rules. Incremental checking combines parsing and proof checking in a single step, to avoid building in-memory representations of proof subterms. LF with Side

Proof production is currently not widely supported among SMT solvers. One of the main reasons for this is the lack of a common proof format. Such a format, supported by a proof checker and defined as part of the SMT-LIB standard, will facilitate implementation of proof production in SMT solvers by providing a common target for proof production. A common proof format is also a critical first step to interfacing SMT solvers with theorem provers. Such a format will serve as an intermediate language, which can then be translated into the formats of particular theorem provers.

The same qualities that make LF attractive for proof-carrying code applications make it so as a proof format for SMT solvers. These qualities are centrally flexibility and support for higher-order abstract syntax (HOAS) [6]. The advantages of HOAS are well-known for encoding syntax with binding, such as is found in SMT formulas, which can make use of first-order quantifiers. Flexibility is very important for SMT, since the variety of logical theories supported by SMT solvers, the variety of deductive systems used to describe the solving algorithms, and the relatively early stage of development of the field mean that it would be very difficult if not practically impossible to design a single set of inference rules that would be a good target for all solvers. A first step to a common logic is to have a common meta-logic in which solver implementors can describe their axioms and rules.

A very standard approach to LF checking, and to many other language processing problems, is to parse textual input into an abstract syntax tree (AST), and then process the AST. This approach is a non-starter for checking very large proofs, for several reasons. First, we should not count on being able to fit the AST into main memory. Using the experimental setup described below, we can easily generate 100M proofs using a prototype proof-producing SAT solver in a relatively short time, on the order of tens of minutes. Longer runs, or runs using an SMT solver, which perform theory-specific inferences in addition to the propositional ones recorded by the SAT solver, may easily add a factor of 10 or 100 to the proof size. Storing proofs of this size in main memory may then prove quite difficult. A second problem with checking very large proofs arises when the proofs are deeply nested. In this case, a naive recursive implementation of the proof checking algorithm, or even the parser, can lead to stack overflow.

The problems of dealing with very large proofs are exacerbated if inferences must contain proofs of usually tacit side conditions. Consider the resolution proof rule. This rule, which historically has a central place in automated reasoning, is used critically in state-of-the-art SAT and SMT solvers, in particular during clause learning [13]. We consider here a relatively simple form of (propositional) resolution, namely binary resolution with factoring. Supporting more complex rules such as

To encode binary propositional resolution with factoring in pure LF, we must insist that each resolution inference comes with a proof of a side condition showing that C1 and C2 resolve as just described to give the resolvent, which the inference proves. That proof may be a trace of the computation of the resolvent, or perhaps evidence based on a more declarative view of the relationship between the resolvent and C1 and C2. But there is no obvious way to reduce its size from O(|C1| + |C2|) to a constant. And hence, the size of resolution proofs will be completely dominated by the size of the proofs of their side conditions.

To deal with this problem, we adapt the solution used by previous authors to decrease proof size [11,5]. There, checking a proof was replaced with running a verified logic program. Here, we seek a solution enabling a spectrum of methods from completely declarative (pure LF) to completely computational (as in the works just cited) proof checking. The proposed approach is called LF with Side Conditions (LFSC). Encoded inference rules may stipulate side conditions using code written in a very simple functional programming language. Whenever the encoded inference rule is applied (to all its arguments, as we will insist), the side condition is checked by running the given side condition code. If running the code succeeds, then the side condition check does, too. If the code fails (as it may explicitly do, or do by failure of pattern matching), then the side condition check fails and the LFSC type checker rejects the application of the rule.

judgment. If the variable x does not occur free in T2, then we stipulate that the result of substituting a non-existent term t2 for x in T2 is just T2. The reader might wonder when our boolean flag could ever be false. An implementation of incremental checking (or any LF checking algorithm, for that matter) should provide top-level commands for declaring and defining constants, as well as for checking the types of terms. In a command to check the type of a term, it is not necessary to create the term itself, and hence in that case, we can use the incremental checking judgment with the boolean flag initialized to false.

