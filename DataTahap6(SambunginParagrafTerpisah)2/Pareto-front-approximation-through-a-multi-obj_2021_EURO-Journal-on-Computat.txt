In order to overcome these limitations, descent methods extend- ing classical scalar optimization techniques have been proposed to address constrained and unconstrained multi-objective problems (see, e.g., Drummond and Iusem, 2004; Fliege et al., 2009; Fliege and Svaiter, 2000). In this work we will bring particular attention to one of such algorithms, the extension of scalar augmented Lagrangian method (Birgin and Martinez, 2014) to the multi-objective case proposed by Cocchi and Lapucci (2020).

In this section, we provide a rigorous formal analysis of Algorithm 3 from a theoretical perspective. We first show that the pro- cedure is actually well defined and then we state its asymptotic con- vergence properties. Before proceeding, we need to make a reasonable assumption.

the computational experiments, we decided to run it with 10 different seeds for the pseudo-random number generator. Every execution had the same time limit used for the other algorithms (2 min). After the ex- ecution of the 10 runs, we compared the fronts based on the purity met- ric and we chose the best one among them. In this case, the reference front for the comparison was obtained by combining the fronts of the

to the seed used for its random operations. Note however that, since we consider a best case scenario for NSGA-II, the overall comparison should be considered at least partially biased in favor of this algorithm. The other methods (FRONT-ALAMO, DMS, MOSQP) are deterministic. Therefore, they were executed once.

We included in our benchmark the slightly modified versions of the BNH problems and the LAP problems from Cocchi and Lapucci (2020). We also included a modification of the OSY problem (Osyczka and Kundu, 1995). The modified form of this problem can be found in Appendix A.

In this paper, we considered smooth multi-objective optimization problems subject to convex constraints. We focused on the task of gener- ating good Pareto front approximations for this class of problems. After a brief review of the existing literature, we proposed an Augmented La- grangian Method specifically designed for this task.

Cocchi and Lapucci (2020), which is designed to produce a single Pareto- stationary solution. The proposed algorithm handles, at each iteration, a list of points that are mutually non-dominated and Pareto-stationary with respect to the current multi-objective augmented Lagrangian. Line searches along steepest common and partial descent directions are em- ployed to carry out an exploration of the objectives space. The penalty parameter and the Lagrange multipliers are updated taking into account constraints violations committed by all the points in the current list.

Moreover, thorough computational experiments show that our method outperforms the SQP algorithm in terms of popular metrics for multi-objective optimization. We also compared the proposed procedure with the state-of-the-art derivative-free (DMS) and genetic (NSGA-II) approaches. Our procedure proved to obtain better results even w.r.t.

