This paper studies the complementarity of test and deductive proof processes for Java programs specified in JML (Java Modeling Language). The proof of a program may be long and difficult, especially when automatic provers give up. When a theorem is not automatically proved, there are two possibilities: either the theorem is correct and there are not enough pieces of information to deal with the proof, or the theorem is incorrect. In order to discriminate between those two alternatives, testing techniques can be used. Here, we present experiments around the use of the JACK tool to prove Java programs annotated with JML assertions. When JACK fails to decide proof obligations, we use a combinatorial testing tool, TOBIAS, to produce large test suites that exercise the unproved program parts. The key issue is to establish the relevance of the test suite with respect to the unproved proof obligations. Therefore, we use code coverage techniques: our approach takes advantage of the statement orientation of the JACK tool to compare the statements involved in the unproved proof obligations and the statements covered by the test suite. Finally, we ensure our confidence within the test suites, by evaluating them on mutant program killing exercises. These techniques have been put into practice and are illustrated by a simple case study.

Three methods are provided to modify the system. Init resets all buffers to zero. Add(x) increases the total number of elements of the system by x (x > 0) by adding x elements to the buffers; these elements are distributed in b1, b2, and b3. Remove(x) decreases the total number of elements in the system by x (x > 0) by removing x elements from the buffers.

The Java Applet Correctness Kit (or JACK) [2] provides an environment for the verification of Java and JavaCard programs annotated with JML. JACK aims at proving properties of a given Java class, considered in isolation; these properties are expressed as JML assertions. It implements a fully automated weakest precondition calculus that generates proof obligations (POs) from annotated Java sources. Each proof obligation is related to a path in the source code of the program.

All checks succeed: the behavior of the operation conforms with the specification for these input values and initial state. The test delivers a PASS verdict. An inter- mediate or final check fails: this reveals an inconsistency between the behavior of the operation and its specification. The implementation does not conform to the specification and the test delivers a FAIL verdict. An initial check fails: in this case, performing the whole test will not bring useful information because it is performed outside of the specified behavior. This test delivers an INCONCLUSIVE

Each operation call may lead to a PASS, FAIL or INCONCLUSIVE verdict. As soon as a FAIL or INCONCLUSIVE verdict happens, we choose to stop the test case execution and mark it with this verdict. A test case that is carried out completely receives a PASS verdict.

Combinatorial testing performs combinations of selected input parameters values for given operations and given states. For example, a tool like JML-JUnit [3] generates test cases which consist of a single call to a class constructor, followed by a single call to one of the methods. Each test case corresponds to a combination of parameters of the constructor and parameters of the method.

For the 819 test cases generated from S2 JCoverage [8] reports that 100% of the Java statements have been executed. So, at least all the operations have been covered, and all JML assertions have been evaluated while exiting these operations. But, at this point, nothing guarantees that the path of each proof obligation has been covered by a test.

Mutation analysis is based on seeding the implementation with a fault by ap- plying a mutation operator, and checking whether test set identifies this fault or not [5,11]. A mutated program is called a mutant. A mutant is said to be killed if the test suite reveals its error.

In order to limit the number of mutants, we applied mutations only to statements that are involved in the path related to unproved POs. For instance, we generated 20 mutants corresponding to the unproved PO #7 and our test suite killed 100% of them. An interesting point is that different tests of a same packet may kill different mutants. This means that these packets feature some kind of diversity.

At this point of the case study, we have reached sufficient confidence in the correctness of the remaining proof obligations to get back to an interactive proof activity. Actually, only POs #1 to #5 deserve to be proved at this stage, because corrections of Remove will not affect their correctness. Of course, nothing guarantees that our test suite was able to detect all kinds of subtle errors. This is why a final proof activity is definitely needed to assess program correctness. Still, the benefit of our testing activity is that the validation engineer will not waste time trying to prove false proof obligations, or even correct ones such as #6 or #7 which may be affected by the correction of Remove.

the real world, written with 500 LOC, distributed into 8 classes. The specification is given in JML. Most preconditions are set to true. Since the application deals with money, and since some users may have malicious behaviors, the application is expected to have defensive mechanisms. Thus, it is supposed to accept any entry, but it should return error messages or raise exceptions if the inputs are not those expected for a nominal behavior.

For each class, we produced only one TOBIAS schema. They were rather straightforward, as S2 in the previous case study. Their design and unfolding with the TOBIAS tool only took us a few minutes. Each schema produced between 48 and 1024 test cases. We then executed them, and, as expected, failed tests were only related to Currency_src.

The mutation analysis was not possible for Account and Rule due to unsolved technical problems. For the other classes, we could notice that all mutants were killed for Balances_src and Transfers_src. However, no mutant have been killed for SavingRule and SpendingRule. Clearly, testing schemas for those two classes were not relevant enough. More insightful test schemas must be defined to gen- erate appropriate test suites for these classes and increase the confidence in their correctness.

schemas can generate several thousand of test cases). Their execution may reveal errors in the code under validation and hence point out false proof obligations. The huge number of succeeded tests, and an evaluation of the quality of the test suite, should increase the confidence in the remaining proof obligations.

Statement vs Path coverage. Since JACK is based on the notion of path, it makes sense to use path coverage instead of statement coverage. Besides the fact that we do not have such a tool available in our environment, we suspect that this more detailed analysis will slow down the testing process, and may in some cases result into over-detailed test reports. Therefore, we believe that it should be provided as an option.

Automatic process. Our approach only makes sense if the whole testing process is cheaper than interactive proof activities. Here each step is automated. JACK associates automatically PO to paths. Tests can be generated automatically thanks to combinatorial tools, such as TOBIAS. JCoverage analyses automatically lines covered during test execution. Grouping test cases is done by sorting JCoverage results. Killing mutants is done automatically.

Feeding assertions into the proof process. The tests generated with TOBIAS are designed independently of the structure of the code or the specification. We ex- pect that they could provide interesting input to the Daikon invariant generator [7]. This would allow to feedback of the proof process with assertions generated from the tests, resulting in a secondary benefit of the testing activity.

