LAA creates unique document layout representation from which software for information extraction is learned to identify target fields on documents. The extractor is machine learning based solution that is trained on available layouts from a training dataset. Learning procedure is heavily dependent on document lay- out containing positions of target fields on the document.

The motif for this research is to implement document under- standing system that must be capable to extract target fields from document images processed with different OCR engines. Different OCR engines generate different layouts for the same document image. Layouts are stored in searchable PDF format. In addition, we do not have any information which OCR engine is used to gen- erate searchable PDF which is input to the extraction module.

Without LAA module, we must train and maintain specific extractor for each OCR engine. Although this solution is not effi- cient, it is not possible to implement it in situation where we can not know which engine is used to generate specific searchable PDF. So, we must have LAA module than converts any layout rep- resentation to unique form from which extractor can identify tar- get fields.

The basic use case in a document understanding system is as follows [2]. Documents are arriving from the stream. The system takes the current document and runs specific OCR engine that con- verts document image into searchable PDF file. Generated file is, after that, sent to the information extraction module responsible for extraction of target information. But the input stream can con- tain searchable PDFs instead of images. It is not possible to know source of the searchable PDF file. For instance, the system does not know which OCR engine is used to generate PDF or if the PDF is digitally created. In the case when searchable PDF file arrives from the stream, it is directly sent to the information extraction module.

According to the previous, input to the information extraction module is always document in searchable PDF format. PDF docu- ments are stored as set of very complex instructions that deter- mine how elements will be situated on the document. This representation does not contain complex structural elements such as sentences or paragraphs.

Additionally, the LAA is responsible for achieving information extraction module robustness: the same layout should be gener- ated regardless of document source. We want to eliminate any dependence on OCR engine, eventually searchable PDF can be dig- itally created. Further, the LAA should be capable to deal with pos- sible anomalies regarding document geometry. For example, when document is generated and/or scanned some fields can be rotated or translated in unexpected way. The LAA must flatten and smooth such undesirable transformations and create layout that is as close as possible to ideal case.

The paper is organized as follows. The next section presents related work. Motivation, novelty and contribution of the proposed method is discussed in the third section. The forth section intro- duces LAA algorithm for layout alignment. Along with the main idea several modifications are considered. The fifth section is

Page segmentation is the most important step in document lay- out analysis. The page segmentation algorithms divide a document image into homogeneous segments. Each segment is part of phys- ical layout structure and can represent text, typewritten text, graphics, diagram, logo, etc. Line segmentation algorithms detect the beginning, the end, the top and the bottom of each text line. As it is mentioned in the introductory section, in this study we con- centrate on line detection. So, physical document layout can be represented as set of recognized text lines.

Also, authors propose very articulate classification of page seg- mentation algorithms that allows to identify main techniques implemented in the algorithms. According to them, there are three groups of segmentation algorithms for physical layout labelling. Additionally, every method is classified as top-down or bottom- up. Top-down approaches start generating layout from the docu- ment level. Bottom-up methods create layout from the pixel level. Algorithms from the first group must know in advance the lay- out type they extract. For instance, some algorithms can recognize only Manhattan layout. Another layout types can be described with set of rules or grammar. These algorithms can be used without a

Algorithms from the third group appeared last. The main approach behind them is to combine several other algorithms in one complex procedure. On the other hand, some algorithms from this group are based on methods from artificial intelligence area (neural networks, for instance) to learn significant parameters and build appropriate model for layout extraction.

On other hand, information extraction algorithms heavily depend on document geometry and positional information. Many of them extract target information based on its position on the document and spatial relations with other elements [9,1,22,11]. In addition, their training consists of learning spatial relations between fields [12].

The main motif for this research arises from challenges in design and implementation of a document understanding system that must be capable to extract target fields from document images processed with different OCR engines. In other words, the aim is to make differ- ent page segmentation algorithms and OCR engines compatible in a sense that for the same document image they will produce the same physical layout. With this approach, document understanding sys- tems become independent of pre-processing steps depending on page segmentation algorithm and OCR engine used.

An obvious solution is to maintain different extractors for every OCR engine. This will work only when it is known which OCR engine is used for processing document image and generating cor- responding searchable PDF. The pseudo code for such solution is presented below.

The previous implementation implies that significant cost must be spent in maintaining extractor models for every OCR engine. For example, size of extractor models can be hundreds of MB. Also, it is usually mandatory to implement active learning paradigm meaning that each extractor model must be periodically retrained with doc- uments processed so far. This will increase models size as well as spend significant processor time.

To the best of our knowledge this is the first study discussing such problem. The LAA is based on KMeans clustering algorithm with specific procedures for normalization and initial centroid gen- eration. In this research we concentrate on administrative docu- ments. Our method does not make any assumption about document layout and it is parameter free.

The LAA can remind of voting methods mentioned in the Related work section. These methods are trying to find correct lay- out by voting between layouts obtained with several complemen- tary approaches. It is possible because all of them process original document image and can involve and combine results of several external systems. In contrary, the method proposed in this study is not able to access the original document image or layout repre- sentations of every possible OCR engine to vote between them. It is provided with just one layout generated from the original image by unknown OCR engine and encoded into searchable PDF format.

searchable PDF and ensures that they will be placed uniquely regardless of which OCR engine is used. Otherwise, all information regarding to elements position and size must be eliminated from extractor knowledge and model. Inevitably, this will degrade its capability and usability (because of lack of the most important attributes for model training).

Firstly, we must define unique measurement scale for trans- forming bounding box attribute. This measurement scale determi- nes size of virtual document page and it is used for positioning text boxes on the virtual page. Such page consists of lines. The line is uniquely identified with its y position on the page. Each text box must be assigned to only one line.

The first step consists of text boxes extraction from a current page of searchable PDF file with PDFMiner library. The result is represented in the form of XML tree. Traversal of the tree is per- formed to generate list of text boxes corresponding to words. Every word, apart from textual content, is extended with its bounding box attribute bbox. As we explained earlier, the bounding box is position (X, Y ) of the bottom left vertex as well as its width and height.  Bottom  left  corner  of  the  page  is  (0, 0). virtual rectangle that borders word region. It is represented with

Information extraction systems heavily depends on document geometry and positional information. Many of them extract target information based on its position on the document and spatial relations with other elements [9,1,22,11]. To achieve desired infor- mation extraction independence of document source it is essential to introduce unique measurement scale and units. Otherwise, all information regarding to text box position and size must be elim- inated from extractor knowledge and model. Inevitably, this will degrade its capability and usability (because of lack of the most important attributes for model building).

ized. This implies transforming values to become part of a smaller or more appropriate range. In other words, normalization step is to transform coordinates X and Y, width and height for every word to the target interval [newmin, newmax]. We tested LAA with several methods for normalization.

butes default target interval is set to [0, 100]. In this case the nates X and Y, width and height for every word. For all four attri- butes, Amin = 0 holds. For coordinate X, we set Xmax = pagewidth. virtual page width is 100 as well as the page height. For all attri- The value for source page width is known from the first step

objects. Every word is represented as one object in the list. Apart from attributes that are read from the XML tree (created through PDFMiner interface), every word is extended with values repre- senting normalized bounding box region. Attribute nbbox is of the following form nbbox = x_norm, y_norm, width_norm, height_norm.

Every word is represented with Y component from the normal- ized bounding box attribute. Intuitively, it is because text line is dominantly determined with its position on Y axes. The Y compo- nent represents normalized position of left bottom vertex. The best experimental results are achieved with this approach. Alternatives that are also implemented and tested represent word with any other vertex or centroid of the corresponding bounding region.

The last step from the LAA algorithm loop generates list of detected lines. One line is represented with one cluster. At this moment we know for every word which cluster it belongs to. The information is included in generated clustering model. Briefly, every word is labelled with identifier of cluster it is assigned to. For

In this section we explain experimental protocol for testing LAA module. We performed a series of experiments on the set of 56 document images of very low quality and on the set of 30 docu- ment images of higher quality but still less than 100 ppi. In the rest of this section these datasets are referred to as Dataset A and Data- set B, respectively. With FineReader we extracted 1298 text lines from the Dataset A and 1150 text lines from the Dataset B. Entirely, 2448 text lines. Tesseract recognized 1165 text lines from the Dataset A and 1106 text lines from the Dataset B. Altogether, 2271 text lines. Samples are real client documents from several dif- ferent classes: forms, invoices, air tickets, contracts etc. For com- parison, datasets used in several very popular competitions of page segmentation algorithms were of size between 720 and 4034 text lines [7].

The performance of the LAA algorithm is measured based on the Line Accuracy Measure usually denoted by FM and introduced in [7]. The FM measure (can be considered as F1 score) is widely used to estimate line segmentation algorithms. It combines Detection Rate (can be considered as recall) and Recognition Accuracy (can be considered as precision).

Consider two searchable PDFs generated with two different OCR engines from the single document image. They contain two lay- outs, potentially different. For this experimental protocol we can assume that each layout is represented with a set of text lines. Each line in the layout is represented with surrounding bounding box,

The LAA approach is based on clustering method. The main idea is to introduce unique measurement scale and to group words into clusters, i.e. text lines. Input to the algorithm is searchable PDF file generated by unknown OCR engine. LAA aligns given physical lay- out in a way that if any other OCR engine is used to process the same document image the resulting layout is always the same.

