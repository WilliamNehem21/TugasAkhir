Plover is an automated property-verifier for Haskell programs that has been under development for the past three years as a component of the Programatica project. In Programatica, predicate definitions and property assertions written in P-logic, a programming logic for Haskell, can be embedded in the text of a Haskell program module. Properties refine the type system of Haskell but cannot be verified by type-checking alone; a more powerful logical verifier is needed.

This paper is about the use of generalized, programmed strategies to construct Plover. Section 2 introduces P-logic, a programming logic for Haskell. This is followed by an overview of the architecture of Plover in Section 3 and its implemen- tation in Section 4, which includes a brief introduction to the strategy programming language Stratego. Normalization strategies are discussed in Section 5 and some type-specific strategies are given in Section 6. Section 7 contains a discussion of generic strategies, some of which are specific to Plover and some of which are not. The paper concludes with a summary of what has been accomplished to date in Section 8 and a survey of related work in Section 9.

Other examples of language-specific verification logics are ACL2 [18], a verifica- tion logic for Common Lisp, and Sparkle [10], a verifier for Clean 2.0. The advantage offered by direct formulation of assertions in a language-specific verification logic is that it is unnecessary to translate expressions and their asserted properties into some other logical formalism, which may have a different type system, and with the attendant risk that errors may be introduced in the translation.

A unary (or monadic) predicate can be specified as a fixed-point of a predicate abstraction expression. Both least and greatest fixed-point definitions are possible, and in general, these definitions will differ semantically. A fixed-point predicate definition is prefaced by either of two binders of a predicate variable, Lfp or Gfp.

In Haskell, the notion of a program module is a collection of function, type and class definitions together with a header that defines the external visibility of names defined in the module and the internal visibility of names that may be imported from other modules. A name used within a module may be qualified with the name of the module in which it is defined or may be unqualified, if no ambiguity results. Programatica observes the name visibility conventions of Haskell modules, while extending the space of defined names to include the names of properties and asser- tions, whose definitions are enclosed within comment brackets {-P: ... } so that

Often, program verification is confused with computer-aided theorem-proving, to which it is related. There are important differences as well. In mathematics, the proof of a theorem is often of as much interest as the theorem itself. In computer- aided theorem proving, the objective is to construct a proof object that can be displayed in a form intelligible to an knowledgable human. In contrast, when veri- fying a property of a program, the reasoning steps that are successfully discharged are of little or no interest so long as one is confident that they are logically sound. The interest is in the result, or in case of a failed proof attempt, in gaining an intuitive understanding of why the attempt failed.

Pushing the point further, in the Curry-Howard types-as-propositions analogy, a proof that a type is inhabited (proposition is satisfiable) is manifested as a program of the type. Discovery of a proof synthesizes such a program. Program verification, however, is analogous to proof checking, rather than proof synthesis. In verification, one is given a program conjectured to satisfy an asserted predicate. The verification task is to check that the truth of that conjecture follows from rules of logic and the formal theory of the programming language.

This distinction between theorem-proving and program verification has conse- quences for the design of a verification tool. Most importantly, since constructing an intelligible proof object is not an objective of verification, a verifier can take shortcuts that would be inadmissible in a theorem-prover, so long as they are co- herent with the rules of the programming logic. Shortcuts include model-relative decision procedures for decidable subtheories of the programming logic. Such meta- strategies can dramatically improve the performance of an automated verification tool, relative to that of a theorem-prover.

or Pred implement rules of propositional and predicate calculus that underlie P- logic. Rewrites that depend also on terms of sorts HTerm and HPattern implement rules that interpret Haskell semantics. A few rules analyze terms of sort HType to distinguish instances of Haskell type classes.

The identifiers conc, map(1) 5 and filter(1) are the names of Stratego library strategies that implement functions. These functions calculate list concatenation, map an argument strategy over a list of terms and filter a list with respect to an argument strategy, respectively. The library strategy not(1) invokes its argument strategy on the current term, and in case it succeeds, the not(1) strategy fails. If the argument strategy fails, then not(1) succeeds and leaves the current term and binding environment unchanged.

representation as terms in a free algebra. When the union of two disjoint theories is decidable, they must have a common model 6 . Decision procedures that have a common model are said to cooperate. However, it is not always easy to find a common model for two theories, even when one exists.

The first alternative of the whnf strategy is satisfied by an Abs construction with any well-sorted subterms as arguments. The recursively defined alternative is satisfied by any Var term and also by an App term whose rator is either a Var term or an App term in weak head normal form. Thus the recognition strategy excludes any App terms that has an Abs term as rator. There is no restriction on the rand subterm of an App construction.

The second definition is similar to the first, but adds the restriction that the rand of an App term must be in head normal form. Since the allowed forms of the rator and rand subterms differ, an additional level of recursive definition is needed to accommodate both forms. Finally, the third definition adds the restriction that the body of an Abs term must have the specified normal form, as well.

by the operator symbol (<+) rather than the symbol (+). The symbol (<+) desig- nates left-biased choice rather than nondeterministic choice of alternative strategies. Since the pattern of the final alternative would match an arbitrary pair of terms, it overlaps the patterns of each of the rules that precede it, and is programmed to fire only as a default alternative.

Each normalization strategy first tries the recognition strategy for its respective normal form, returning immediately in case the current term is normalized. Other- wise, if the current term matches an App construction, then BetaSubst is tried after normalizing appropriate subterms of the construction. In case BetaSubst succeeds, it is still not assured that the result term is normalized, thus the normalization strategy is applied recursively to the result.

Some types uniquely determine the top-level structure of normal-form terms of the type. Product types (finite tuples) and data types with only a single constructor have this property. Structure-determining types see greater use in Haskell programs than in many other languages.

One could implement a complete decision procedure for boolean satisfiability to attempt to resolve values for Bool-typed expressions. Plover does not do this. Instead, it implements a series of weaker strategies that attempt to eliminate the most common use made of Bool-typed expressions: as discriminators in if-then-else expressions and guards.

Several strategies employed in Plover cannot be called type-specific, yet they deal with program constructions that are particular to Haskell. These include strategies for local definitions introduced in let or where clauses, guarded expressions, fixed- point induction and strategies that instantiate quantified assumptions. We shall consider in detail the strategies Plover uses for let expressions and for instantiating lemmas.

A let expression constitutes a list of local definitions that scope over a single object expression. The order in which definitions are listed is semantically unimportant in Haskell, as they scope over one another, as well. Thus a set of definitions may be mutually recursive.

The operator (>>=) defines function application in the monad. An application m >>= f produces a function that evaluates the monadic structure of m by applying it to a state variable to produce a (value, state) pair. The components of this pair are passed as arguments to f , which returns a new (value, state) pair.

Steps 1 and 2 can be embedded in a traversal strategy to reorganize and simplify let expressions throughout a possibly larger term. During a term traversal, each remaining definition that is both non-recursive and independent of any definition that precedes it in the list ordering is analyzed to determine whether it depends on any variable bound in an immediately enclosing a case branch or abstraction term. If it does not, the enclosing expression is rewritten to a let expression into which the independent definition has been syntactically lifted.

In verification, as in theorem-proving, a task can often be simplified by breaking it into stages, utilizing assertions previously verified (or assumed) as lemmas from which to prove an assertion. The form taken by a lemma is typically that of a proposition, universally quantified over some number of its variables. To incorporate a such lemma, it is written as an implicand of the assertion to be verified.

The potential complexity of theorem-proving has always been viewed as a potential limitation on the use of automation. In mathematics, the intuition of a knowlegeable and patient human can guide construction of a proof of a complex result. Such intuition is unavailable to an automated proof tool.

On the other hand, when a single strategy step can generate multiple verification conditions, the complexity of a verification can grow exponentially in the depth of its derivation tree. This is where real complexity problems lie. Realizing this, one programs strategies for a verifier with an eye to minimizing VC-multiplying situations. This is another area in which strategies offer a programming advantage over conventional, conditional rewriting techniques.

Systems with powerful capability for deduction have evolved from the term-rewriting paradigm. Conditional term-rewriting systems have been extended with capabilities for reflection, allowing strategies for manipulating both terms and rules to be written in the same language framework that is used to write programs and specifications. Two such systems are ELAN [1] and Maude [5]. These systems do not incorporate model-based decision procedures, but instead axiomatize decidable theories with rewrite rules.

Verification tools have been designed for several existing programming languages and some formal specification languages as well. Most verifiers integrate decision procedures with logical reasoning to discharge verification conditions derived from formal property assertions embedded in or appended to a program or specification. They do not construct proof terms to justify their conclusions. Simplify (see below) has been included in this summary because it is used as a deductive engine by several verifiers, although it is not, by itself, specialized to any programming language.

Sparkle [10] is a verification assistant specially constructed for the functional programming language Clean [3,24]. It comprehends the syntax and semantics of Clean 2.0. Sparkle is an interactive tool, offering a user a library of proof tactics that may be invoked while attempting to prove an asserted property of a Clean program fragment.

ESC-Java [12] generates first-order formulas as verification conditions for prop- erties asserted by embedding annotations in Java programs. It is based upon a partial theory of the semantics of Java expressions. It operates automatically, with- out interactive input from a human user. Verification conditions generated from an annotated Java program by ESC-Java are submitted to Simplify, a first-order theorem-prover.

PVS [22] is a custom-designed verifier for assertions formulated in the PVS specification language, which is derived from classical, typed higher-order logic. The designers of PVS have pioneered the inclusion of cooperating decision procedures in a verifier [9,25]. The verifier has an interactive interface that allows a user to specify strategies but is capable of carrying out proof steps automatically, using pre-programmed strategies. PVS has been used to specify and verify fault-tolerant flight control systems, secure computing platforms and other safety or security- critical systems.

Theorem provers are based upon a small core of logical rules that guarantee their soundness. All reasoning steps follow by application of one or more of these rules to the formal axioms of a specified theory or by application of previously proved lemmas concluded from that theory. A theorem prover does not rely on decision procedures and does not contain programmed interpretations of axioms of a user- specified theory in its trusted base.

