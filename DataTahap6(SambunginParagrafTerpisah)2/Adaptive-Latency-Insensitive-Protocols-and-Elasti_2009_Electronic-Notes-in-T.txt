In this section we describe the two approaches [6] and [9], which will be called ALIP and ECEE in the following. We refer the reader to the original papers for a detailed discussion of their properties. ALIP and ECEE are sufficiently different between each other as their static counterparts LIP and EC (see [2]), to justify a detailed analysis of their pros and cons.

Although we did not make any power evaluation, it might be the case that less power is consumed in ECEE - at the same performance of ALIP - due to the possibly higher number of clock-gating events caused by antitokens. But it can also be the case that the extra (possibly long) wires and extra control logic add more power than local counters in ALIP. More work is needed on this point.

From this discussion it is clear that general rules of better applicability of one protocol with respect to the other are hard to define. In particular cases, like those reported in the next two sections, the supremacy of ALIP in terms of performance emerges clearly. Section 5 will show that the combination of multiple conditions, emulated by means of a set of benchmarks, makes the analysis rather difficult.

In this section we illustrate the cases in which we observed some penalties that affect ECEE compared to ALIP with simple and readily understandable examples. The first one is the classic reconvergent fanout case in which the output of a block is sent to two (or more) branches with different latencies. The second one is representative of the class of problems that arise when state holding blocks are involved.

It is worth mentioning that such phenomenon, for static protocols, can be solved with extra buffers or buffer sizing [13]. However, adaptive protocols might depend on more subtle data-related interaction between the various parts of the system that cannot be as efficiently modeled and optimized out. Furthermore, such optimiza- tions could be substantially expensive either in hardware or optimization time.

We implemented an ALIP and an ECEE version of this simplified DLX in behav- ioral VHDL which allows to vary parameters, such as the mix of instructions, the percentage of data-dependency, the possibility to send instruction bursts (e.g. many consecutive pipelined MUL operations followed by many ADD ones). With this set- ting we were able to gather many interesting data and compare the behavior of ALIP and ECEE in a rather complex yet still manageable example.

Both in case of data dependency and of independence we varied the percentage of instructions that use the pipelined unit from 0% to 100% in steps of 10%. In this experiment, the latency of the pipelined unit was set to 3, while the multi-cycle unit was never used (execution latency of all instructions 0 or 3 cycles). We discuss first the results in the extreme cases (0% and 100%) and then the intermediate ones.

The previous relevant DLX case exemplifies some of the remarks of previous sections concerning the better potential for performance in the ALIP case. How- ever this does not prevent from possible better performance of ECEE in particular cases. Complex interactions between blocks in a topology with a larger number of components might favor the ECEE case, as next section shows.

