The need for backward execution in debuggers has been raised a number of times. Backward execution helps a user naturally think backwards and, in turn, easily locate the cause of a bug. Backward execution has been implemented mostly by state-saving or checkpointing, which are inherently not scalable. In this paper, we present a method to generate reverse code, so that backtracking can be performed by executing reverse code. The novelty of our work is that we generate reverse code on-the-fly, while running a debugger, which makes it possible to apply the method even to debugging multi-threaded programs.

It has been pointed out in a number of papers that enabling backward execution in debuggers would be of great help in a debugging process [1,3,6,7]. A typical debugger-aided bug-finding, where a debugger does not support backward execu- tion, is performed in iterative steps of: (1) guess a problematic point which may cause an unexpected behaviour of a program, and set a breakpoint there (2) restart a debugging session and watch a program state on the breakpoint. This procedure is time-consuming, not only because a user must repeat starting and stopping debug- ging sessions until finally identifying the cause of the error, but also because guesses made by a user are often not precise. What is worse, as a mainstream language like Java begins to support multi-threading, the traditional debugging procedure often even does not work because one cannot keep the scheduling order between threads the same as before, by only restarting a program. On the other hand, if a debugger assignment whose right hand side contains more than one variable. For instance, x := p + q cannot be defined in the form of Definition 5. For the moment, let us restrict to the case where the right hand side of an assignment depends on at most one variable. We will expand our consideration to multiple-variable case in Section 4.2.1.

In this section, we illustrate the restore function used in Definition 9 and 13. Func- tion application restore(x) actually also carries on previous-value-inference proce- dure for x based on an assignment trace. In the following, we show an algorithm for the restore function, along with one more definition used in the algorithm.

Proof. In (a), we only need to look into assignments between ar and a2 (including ar) because no RRA for variable y does not allow redefinition of y (see Definition 6). Therefore a2 approaches a1 and, in turn, the above procedure always terminates.

Throughout the argument, we relied on inverse functions to achieve value restora- tion. Inverse functions may be either given by a user or more preferably derived automatically. As mentioned in a later section, derivation of inverse functions is another active research topic. However since we express an arithmetic expression as a function format, we suggest a way to derive an inverse function from it.

There have been a number of attempts to provide reverse execution for debuggers. The easiest way to achieve reverse execution is to save program locations and old values that may be necessary in running a program backwards [2,11,26]. A clear drawback of this state-saving approach is that the amount of data to be saved grows very high easily as a program runs.

More often, reverse execution is simulated by reexecuting a program until the earlier point. It appears to work well with small size program, but it cannot avoid suffering from increasing time overhead as a program size gets bigger. Hence the reexecution idea often comes in tandem with checkpointing. Old values are saved per periodic checkpoints, not per every statement or instruction, and when we want to backtrack, first we go back to the closest earlier checkpoint from the position we want to jump back to, and then reexecute the remaining part down to the destination point [1,8]. For example, [1] sets checkpoints on borders of control structures of a program, such as the beginning and end of if or while statements. However, essentially checkpointing and reexecution also cannot avoid memory accumulation because memory is consumed every checkpoint.

Meanwhile there is a limitation on the extent of statements that can benefit from the presented method. Most heap update statements are not invertible. For example, although o:=o.f is self-defined assignment 9 , it does not give a clue about the previous value of o. Note that the same limitation is shared by [4] that also generates reverse code, based on control/data dependency analysis result in static time, as explained in Section 7.

Backtracking plays an important role in many areas in computer science besides debugging. Simulation, model checking, theorem proving and logic programming are a few of them. And more often than not, efficient memory usage is one of the critical issues in those areas. We hope the backtracking method presented here can help alleviate memory blow-ups in other areas too.

We have presented a reverse code generation method that can be used for reverse execution while debugging. The novelty of our work is that we generate reverse code on-the-fly based on a logged history of transitions, which are basically pointers to program locations. This dynamic generation makes it possible to be get reverse code even for multi-threaded programs.

One possible future work is to see how one can benefit from dynamic slicing as in [2,5]. We suppose it will help improve reverse code generation time by removing unnecessary assignments from an assignment trace. There are also a number of engineering issues. For example, it may be possible to calculate reverse code in the background while tracing a program forward step by step in a debugger, and have reverse code ready when one needs to backtrack. Or checkpointing could be employed and reverse code should only be generated between checkpoints. We can also cache reverse code and reuse it later if variable update is only locally affected. Lastly, as we mentioned in the previous section, we are also interested in extending this work to functional programming languages.

