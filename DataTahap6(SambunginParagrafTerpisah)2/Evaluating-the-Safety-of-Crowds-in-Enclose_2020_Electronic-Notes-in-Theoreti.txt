This article deepens a previous work presented in [4], where Markovian Agents (MA, [5]) were used to model and analyze the behavior of people in a closed environment where a panic situation occurred. We present a more complex scenario, in which the crowd motion is studied under a stressful situation and managed by means of visual signals positioned in different places in the office. Individuals have roles also and evacuation follows given guidelines, previously communicated to each member.

Abu Bakar and others review some modeling techniques in [1], (for instance, Agent-Based Simulation (ABS), Social Force Simulation (SFS) and an hybrid of the two) of fire evacuation in a closed space, though the actual simulation is post- poned to future work. An in-depth discussions about the modelization of a pool of human, dynamic crowd simulation, stress and fears models is presented in [3]. Different approaches, such as models based on the leader-follower paradigm, have been presented in [9], where the authors study a scenario, consisting of a collec- tive adaptive system (CAS), by the perspective of a leader, performing a random walk, and an agent acting as follower. The model is further analyzed by the process algebra PALOMA [10].

Cellular automata [19] [15] [22] are based on a finite grid-based representation of the environment, where cells describe the local state of the system, which evolves in steps according to its previous state and the state of near cells with proper rules and influence radius, depending on the kind of problem modeled. Applications span over video games related map evolution, human behavior analysis, support to archi- tectural planning, traffic management in cities and artificial intelligence behavioral models. This approach is naturally fit to represent obstacles and exhibits significant computational advantages, because it is generally not computational intensive and easily parallelizable, thus it can scale up with minimal burden. On the other hand, it is not specially fit, due to the cell-oriented representation, to applications that are bound to measure speed and tracing of individuals.

abstracting the behavior of individuals with a consistent and rich framework and complex interactions. An agent is driven by an intelligent reactive strategy that is articulated in Belief, Desire and Intention [18] to confer it autonomous decisional abilities. Agents interact and react, and can collaborate or compete: their evolution is described and computed individually in an environment of which the emerging global state can be observed as a result.

Noticeable are techniques based on swarm intelligence, in which emergent so- lutions are generated as a kind of collective intelligence of a population of single agents [16] interacting and collaborating individually on a stochastic or chaotic ba- sis. Markovian Agents (MA) [5] are agents that are characterized by a stochastic behavior that is described by a discrete-state continuous-time finite Continuous Time Markov Chain (CTMC), in which interactions between agents are a compo- nent influencing the CTMC infinitesimal generator. MA interact with the environ- ment in which they operate as well, allowing a flexible description of it in terms of obstacles, distance-like or path-like propagation and similar features. Interactions between MA are shaped as a message-based communication and occur by means of an individual perception function, allowing broadcast communication as well.

Markovian Agents [5] is a formalism to describe spatially distributed systems where agents have a finite number of states, and their dynamics is described by a transition kernel, which consists of an induced transition matrix and a local transition matrix. The agents are distributed across several locations: as a result, a model that is based on a set of interacting Markovian Agents is said to be a Markovian Agent Model (MAM). The formalism is interesting because it can model distributed systems in which local behavior can be distinct for each agents.

and the Parametric Transitions. The latter explicitly represents events whose rate depends on the location where the agent is located: in other words, the rate parameter of the corresponding distribution is a spatial property, which depends on the location where the agent is positioned, and which is then used to model actions induced by the environment where the agent is operating. They act however exactly as the other transitions, following the same habilitation and firing rules. Remote Places represents instead places of different agents, positioned either in the same location, or in different locations of the same model. One of the key restrictions however, is that remote places can be connect to transitions only with test or inhibitor arcs. In this way, one agent cannot change the state of other agents, but it can be influenced by their state.

The solution process first computes the state space and the transition matrix for each class instance cj@i. Specifically, it follows the conventional techniques of state space generation defined for Petri Nets with the following extensions. Firstly, remote places are not considered in state space generation: since they are connected only to transitions with test and inhibitor arcs, they have no impact on the set of reachable states of an agent. Before generating the state space of the model, parameters are replaced with their actual value assigned by the topology definition. Remote places are then used to create guard functions that multiply the rate of the transitions to which they are connected, implementing the enabling rules defined by the test and inhibitor arcs. In this way, for each agent instance cj@i in each location vi, an is obtained by the dependencies of each infinitesimal generator Qcj@i (N) on the complete state of the model N. More details can be found in [5]. Another interest- ing formulation is presented in [12]. Interested readers may also check additional readings such as [21], [6], [7] and [11] that present relevant research on different views of the proposed methodology.

