In this paper we present a modular representation of software architecture for HIRTS that focusses on component failure properties, (rather than the expected, correct behaviour). It is much easier for an engineer to analyse an individual component manually for its local failure behaviour, than to attempt to analyse an entire system. The failure behaviour of components is then re- corded in a fully compositional manner, allowing the automatic determination of the failure behaviour of the whole system. To this end, a semantics of failure propagation and transformation is outlined, which we name FPTC (Failure Propagation and Transformation Calculus). Thus, the potential of automatic analysis to reduce the cost of change is enormous: if the fault behaviour of the system as a whole is calculated purely from the composition of its parts, then the impact of a component change or architectural change can be predicted very cheaply.

In this paper, we restrict our attention mainly to software. However we hope that the techniques presented might be capable of adaptation to complete engineering systems, including the physical hardware, electrical and hydraulic plant, and so on. Also, whilst our focus on failure properties does not address the full range of safety concerns, it does however provide one important piece of evidence towards the construction of a safety argument.

We also note in passing that there are other types of failure dependency between components, such as the allocation of schedulable software units to CPUs. This kind of dependency can and should be added into the graph as well. For instance, each CPU can be modelled as a component with an FPTC expression describing its failure modes, and connected by error-flow arcs directly to the software processes running on it.

regarded as a token-passing network. Tokens corresponding to failure modes are introduced by sources, transformed and propagated by the network nodes, and removed by sinks. We are interested in the flows of failures, and thus can annotate the arrows of the diagram with tokensets, that is, the set of all possible failures that can be propagated along a dependency path.

We choose the latter interpretation (assume the worst). Failure propaga- tion is likely to be the common behaviour of any software component in the absence of further design work. But if a component can detect and correct a failure, that is unusual, and should be noted explicitly.

to more-general. We prefer the latter rule based on generality/specificity, since the former rule would allow the semantics of the specification to change depending on the textual ordering of clauses, which is somewhat fragile and open to cut-and-paste mistakes. It is of course useful for the analysis toolset to report (optionally) on which clauses are overlapping, to avoid unintentional slips; likewise if any potential patterns are missing, such as when an explicit default is omitted.

Nevertheless, despite the extra semantic complexity involved, it has been demonstrated in practice by well-established programming languages (e.g. ML, Haskell), which make heavy use of pattern-matching, that the inclusion of overlapping patterns is a good way to reduce syntactic clutter and improve readability.

detailed implementation, because it can pick up potential problems before the code is written, when they are cheaper to fix. Another point worth noting is that the provided design is incomplete, specifying only the launch portion of the software, not the actual flight control (pools for communicating data to the flight phase are left unconnected). This too is realistic of real projects, where the full design is only performed after a demonstration of the viability of some critical portions.

We injected individual failure modes to potential sources of errors, e.g. the hardware sensor components, then performed the automated part of the ana- lysis to determine how errors flowed through the network. Our tool annotates every arrow in the diagram with its final computed failure tokenset. For the purposes of this case study, we are especially interested in what failures might be expressed on the inputs to the flight control actuators.

As already mentioned, one of the biggest costs of high-integrity software is associated with safety recertification after necessary change to the system, and our aim with this work is to enable a re-analysis to become simpler and cheaper.	So to investigate the comparative ease of change in the present analysis, we make an small alteration to the architecture: by swapping the IMU sensor component for one with different failure properties. This is typical of the type of change one might make in the maintenance phase of a product, as hardware components become obsolete or unobtainable, and must be replaced. With a different IMU failure mode, whereby the unit could instead provide

We identify two key deficiencies in FPTN. First, whereas an FPTC analysis reuses the existing system design as the basis of its flow graph, the original FPTN is much more ad hoc, recording only known error flows. That is, an arc is included on a diagram only if it represents the transmission of a known particular fault type between components, but an actual data or control con- nection between components is omitted from the FPTN diagram if it is not currently known to cause error transmission. A later change to one component might alter not only the types of failure generated, but also where those failures are propagated to, thus necessitating some non-local re-working of the FPTN diagram to change the connection topology. The only way to determine the new connection graph is by manual reanalysis of all the components and their contexts. By contrast, FPTC diagrams are based on the full architecture used for developing the software code itself, to identify and record all potentially important dependencies, whether or not they are currently known to engage in any error flow. Thus FPTC keeps the model and reality synchronised as much as possible, and localises the effect of any changes.

The technique has been used in practice on a case study of an avionics application, where the design was incomplete, and the implementation un- available. This demonstrates the utility of the analysis at the early stages of a project, in order to avoid a potentially hazardous design. We also demon- strated the ease of re-analysis in the face of design changes of different types. This leads us to believe that the technique could have particular value in the fields of incremental safety certification, and product-line families.

Goals for the future include the extension of our FPTC framework to look at Quality of Service issues. If we re-designate the symbolic tokens of FPTC from failure modes to representations of the quality of system data, that is, our confidence in its accuracy, (e.g. Low, Medium, High), or the severity of any associated failure, then it may be possible to notate the transformational efficacy of common components such as multi-lane voters, redundant wiring schemes, and so on. Do value faults get amplified through feedback loops, or reduced? Is low quality data relied on in high-integrity partitions? This could enable us to be more confident about the impact of change in a large and complex design, detecting whether the addition or removal of elements introduces a possible single point of failure.

