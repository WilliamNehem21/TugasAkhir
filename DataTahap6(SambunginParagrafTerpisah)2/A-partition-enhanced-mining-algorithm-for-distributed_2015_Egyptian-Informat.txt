There are two phases in the execution of the PEMA. In the first phase of the initial mining task, the mining agent logically divides i.e. horizontally segments the database into a number of non-overlapping partitions, when the database is relatively small as defined in previous sections. This depends solely on the number of available data sites in the system. This is simply number, that is, 33506 transactions from the above example. It is obvious in the example that the first twelve partitions will have exactly the same number of partitions while the last par- tition will have the rest of the transactions which is a little more than the first twelve. This will take care of the effect of the first approximation. This paper assumed that the database is located on secondary storage while the total available mem- ories are also known in advance.

Finally, it should be noted the system proposed in this work works in a dynamic fashion; in that it performs horizontal seg- mentation or partitioning of the database through the data agent whenever the average length of transactions in the data- bases is very small. For very large data with long transaction lengths, vertical partitioning of the data was deployed by the data agent to improve the performance of the mining algo- rithm. This hybrid component of PEMA is a typical represen- tation of the novel method being preached in this work. It combined horizontal segmentation, vertical partitioning and incremental mining of datasets in one method. This was very necessary because real-life databases are usually fragmented in various locations. One major thing unique to this work is that, PEMA could be deployed to mine both real and synthetic datasets already vertically distributed in various data sites and/ or can as well dynamically and vertically partition very large datasets with very long transaction lengths e.g. Covertype data form UCI machine learning repository, while distributing them to the various sites depending on the available number of mining sites. This is one of the major tasks performed by the data agent in our architecture. PEMA is very flexible as it does not only perform the global mining task, also has provisions for partial global mining; a situation in which a data miner is not interested in mining all the parts of the data or all the data sites available. This was easily achieved by PEMA as shown in the results presented in section four.

The experiments were designed to analyze the effect of the fol- lowing: the number of data sources, the size of the datasets in terms of number of records, and the size of the datasets in terms of number of items. All datasets described were used for one experiment or the other. All experiments were per- formed on four virtual machines running on Intel (R) Core (TM) i5-2450M CPU @ 2.50 GHz, 2501 MHz, 2 Core(s), 3

Logical Processor(s) Pentium(R) with 6 GB of main memory running on Windows 7 Home Premium Edition. Datasets used for the experiment were distributed on the four virtual machi- nes created. The following were measured for one or more of the experiments: (i) response time (seconds/milliseconds), (ii) the communication overhead (number and size of messages exchanged). The experiments were performed by varying the minimum support threshold between the ranges of 0% and 100% of total transactions depending on the particular dataset used. The ARM results of the PEMA algorithm described in section three of this work were compared with the performance of other existing state-of-the-art algorithms such as Apriori, AprioriTFP and FP-Growth.

DARM experiments were also conducted on the remaining datasets, which are connect4 and covertype. The minimum support of 20% and a minimum confidence of 80% were used as default values for PEMA. The results of these experiments are also shown in the following subsections. It should be noted here that these values could be changed anytime by the user as the need arises.

results of this experiment showed that with connect4 dataset and 75% min_sup threshold, all the methods exchanged high number of exchanges except PEMA. Also, for all the four methods, the size of messages exchanged improved consider- ably as the percentage minimum support threshold is gradually increased. PEMA had the best performance even at the 75% min_sup threshold and dropped a little as it increases.

