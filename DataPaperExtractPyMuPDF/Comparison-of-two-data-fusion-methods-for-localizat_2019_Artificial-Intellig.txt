Comparison of two data fusion methods for localization of wheeled
mobile robot in farm conditions
S. Erfani ⁎, A. Jafari, A. Hajiahmad
Department of Agricultural Machinery Engineering, College of Agriculture and Natural Resources, University of Tehran, Karaj, Iran
a b s t r a c t
a r t i c l e
i n f o
Article history:
Received 29 January 2019
Received in revised form 10 May 2019
Accepted 11 May 2019
Available online 15 May 2019
Localization of a mobile robot with any structure, work space and task is one of the most fundamental issues in
the ﬁeld of robotics and the prerequisite for moving any mobile robot that has always been a challenge for re-
searchers. In this paper, the Dempster-Shafer (D.S.) and Kalman ﬁlter (K.F.) methods are used as the two main
tools for the integration and processing of sensor data in robot localization to achieve the best estimate of posi-
tioning according to the unsteady environmental conditions in agricultural applications. Also, by providing a new
method, the initial weighing on each of these GPS sensors and wheel encoders is done based on the reliability of
each one. Also, using the two MAD and MSE criteria, the localization error was compared in both K.F. and D.S.
methods. In normal Gaussian noise, the K.F. with a mean error of 2.59% performed better than the D.S. method
with a 3.12% error. However, in terms of non-Gaussian noise exposure, the K.F. information was associated
with a moderate error of 1.4, while the D.S. behavior in the face of these conditions was not signiﬁcantly changed.
The experimental tests conﬁrmed the statement.
© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open
access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
Keywords:
Sensory data fusion
Mobile robot
Localization
Dempster - Shafer method
Kalman ﬁlter
1. Introduction
Today, agricultural automation is inevitable in order to save on costs
and produce more per unit area. Robotics can also meet the goals of au-
tomation in agriculture, by minimizing the tough, risky, deadly and long
working conditions, along with precise monitoring and control. With
the development of research in this ﬁeld and the development of tools
used to guide robots, including optical, ultrasound and radio sensors,
the problem of increasing the accuracy and speed of the robots was con-
sidered (Murakami et al., 2006). Data fusion is a method for combining
the data from several sources of information used to obtain a brighter
picture of the problem being investigated and measured. Data fusion
systems are currently being used in a variety of ﬁelds, including sensor
networks, robotics, photo and video processing, and smart system de-
sign. A lot of research, especially in recent years, has been done in the
ﬁeld of data fusion, but there is still a long gap between intelligent sys-
tems in this area with the ability of organisms, especially the ability of
the human brain (Hall and Llinas, 1997). Klein (1993) provided a deﬁni-
tion of the integration of sensor data, which combines sensor data, from
one type or from different sources of data. Both deﬁnitions provide a
general form in the use of sensors and can be used in a variety of appli-
cations, including remote sensing. The authors have reviewed many of
the methods of data fusion and discussed each one. Based on the
strengths and weaknesses of previous work, a basic deﬁnition of infor-
mation integration is presented as follows: Information integration is
an effective way to automatically or semi-automatic conversion of infor-
mation from different sources or at different time points into an effec-
tive output that in the decision-making process, acts automatically or
supports human decision-making. In studies for localization, the combi-
nation of the global positioning system and other sensors such as iner-
tial
measurement
sensors,
position
detection
sensors
(digital
compass), camera, radar and laser sensors, have shown more accurate
results than the use of only the GPS (Keicher and Seufert, 2000;
Subramanian et al., 2006; Li et al., 2010). The combination of GPS
speed with the INS sensor was used to measure the slip angle of the ve-
hicle and the tire when it was turned (Bevly et al., 2001). In other re-
search, Zhang et al. (2002) equipped an agricultural tractor with an
intelligent navigation system with machine vision sensors and optical
ﬁber gyroscope. In a research conducted by Mizushima et al. (2011) po-
sitioning sensors were combined with three vibrational gyroscopes and
two inclinometers. Park (2016) for safe and comfortable mobile robot
navigation in dynamic and uncertain environments, extended the
state of the art in analytic control of mobile robots, sampling based op-
timal path planning, and stochastic model predictive control.
Shafer et al. (2003) introduced the theory of evidence, later known
as the Dempster-Shefer theory. The basis of this approach is to integrate
data into evidence or beliefs that can manage information deﬁciencies.
This was a reinterpretation of Arthur Dempster's research in the
1960s, which, according to Dempster, has been largely modiﬁed by
Shafer (Shafer et al., 2003). Denoeux et al. (2017) provided two new
Artiﬁcial Intelligence in Agriculture 1 (2019) 48–55
⁎ Corresponding author.
E-mail addresses: saeederfani@ut.ac.ir (S. Erfani), Jafarya@ut.ac.ir (A. Jafari),
Hajiahmad@ut.ac.ir (A. Hajiahmad).
https://doi.org/10.1016/j.aiia.2019.05.002
2589-7217/© 2019 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://
creativecommons.org/licenses/by-nc-nd/4.0/).
Contents lists available at ScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage: http://www.keaipublishing.com/en/journals/artificial-
intelligence-in-agriculture/
division methods, along with simulation of some applications in the D.S
method. Liu et al. (2017), in their research, proposed a new weighting
method in Dempster-Shafer theory by a fuzzy algorithm that can use
the evidence obtained from different methods to classify the target.
Despite extensive research in the ﬁeld of robotics and control, the
implementation of plans and methods of localization in the agricultural
industry has been less studied due to the fundamental difference in the
laboratory environment with real conditions. Because highly accurate
sensors such as DGPS, in addition to the high cost, have access restric-
tions, In this paper, various methods of integrating global positioning
unit and inertia measurement unit are utilized by Dempster-Shafer the-
ory as well as Kalman ﬁltering, and the results were compared to select
an accurate method for localization at an appropriate cost. Also, by in-
troducing a new method, initial weighting has been made on the infor-
mation of each of the GPS sensors and wheel encoders, based on the
reliability of each one. In addition to obtaining the geometric equations
governing the robot, a PD controller was implemented for kinematic
control and evaluation of the robot localization algorithms.
The rest of the paper is organized as follows: The kinematic model-
ing of the agricultural robot, the simulation of the robot in the
MATLAB SimMechanic, localization by Dempster- Shafer and Kalman
ﬁlter are given in Materials and Method section. Comparing of these
two methods and the results is presented in Result and Discussions.
The experimental tests were designed to investigate the validity of sim-
ulation results. And ﬁnally, last section, where some conclusions are
highlighted.
2. Materials and method
2.1. Modeling
In this section, a model will be created for a robot that is a car-like
robot. The typical model for the four-wheel robots is the bicycle
model shown in Fig. 1. The two-wheel drive model has a rear wheel
mounted on its body, and the front wheel plate rotates around a vertical
axis for steering. The position of the robot is represented by a moving
coordinate system whose x-axis is in the direction of moving forward
of the robot and its center corresponds to the center of the rear axle of
the robot. The conﬁguration of the robot is also deﬁned by general coor-
dinates q = (x,y,θ) ∈ C in which, C, is an Euclidean two-dimensional
space. In this coordinate system, the speed of the robot is along the x-
axis, because the robot cannot slip sideways. And because of the low
speed, longitudinal slip and centrifugal force can be ignored.
vx ¼ v; vy ¼ 0
ð1Þ
The wheels cannot move in the direction of the dashes, and these
two dashes cut off at one point, which is called the instantaneous center
of rotation. This point is the center of the circle the robot tracks and the
angular velocity of the robot is obtained from the following equation.
_θ ¼ v
R1
ð2Þ
In which R1 ¼ L�
tanγ and L is equal to the length of the robot.
As can be imagined, the radius of the robot's circular path increases
with increasing length of the robot. On the other hand, the steering
angle has a mechanical limit and its maximum value speciﬁes the min-
imum R1 value. So if the steering angle is constant, the robot runs a cir-
cular arc.
According to Fig. 1, R2 N R1, which means that the front wheel must
travel longer and therefore have a higher speed than the rear wheel.
Also, in a four-wheel robot, the outer wheels are rotational with differ-
ent radials from the inner wheels. Therefore, there is very little differ-
ence between the steering angle of the steering wheels, and this
difference can be made using the Ackerman steering mechanism on
the steering wheels. Similarly, in moving wheels, the speed of rotation
varies. The speed of the robot is equal to (v cos θ,v sin θ) in the reference
coordinate system. By combining it with Eq. (2), the equations of mo-
tion are obtained as follows.
_x ¼ v cosθ
ð3Þ
_y ¼ v sinθ
ð4Þ
_θ ¼ v
L tanγ
ð5Þ
This model is a kinematic model of the robot, because it is described
by the speed of the robot, not the force and torque that speeds up. In the
global or reference coordinate system:
_y cosθ−_x sinθ ¼ 0
ð6Þ
This is a non-holonomic motion control. Another important feature
of this model is that when the robot speed is zero, then _θ ¼ 0. This
means that the robot direction cannot be changed without moving. It
comes from Eq. (5). Because, _θ is the instantaneous velocity of rotation.
Also the robot command is always less than π=2.
2.2. Simulation
In this section, according to the kinematic model of the robot, a sim-
ulation of the robot in the MATLAB software has been addressed. Fig. 2
shows the implementation of Eqs. (3) to (5) in the Simulink environ-
ment. Linear speed and steering angle as input, and position and angle
of the robot are considered as output of this model.
In order to have a dynamic environment and visual representation of
the robot's motion, the robot model is interconnected individually in the
SimMechanics of Matlab software to allow the robot's behavior in deal-
ing with various control algorithms be observed by combining it with
Simulink environment. By placing a sensor on a robot, in order to report
its position and angles (such as the gyroscope sensor), these robot fea-
tures are available throughout the path. The robot moves with constant
velocity and the steering angle is the only control variable.
The control commands to the simulated model have been imple-
mented from controllers written in the Simulink. In addition, by
reporting the amount of rotation of each joint, in fact, will be an encoder
Fig. 1. Bicycle model of four wheeled robot.
49
S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48–55
on the each wheel which produces output in radians per second. In
Fig. 3, simulation of the robot and the transfer of various parts of
SolidWorks to the SimMechanics, along with an explanation of each
part, are presented.
2.3. Localization
Now, the robot positioning in the simulation environment is per-
formed using two methods, Kalman ﬁlter and Dempster-Shafer. Also,
the initial weighing to the sensors' results will be explained and applied.
2.3.1. Dempster - Shafer's theory
Dempster-Shafer's Theory of Evidence according to many credible
references, is the most powerful method in data fusion. In fact, this
method merges data at the decision level. This method has the ability
to integrate any numerical, signal, and multi-dimensional data. One of
the areas that this tool and its features are underused is the localization.
In this paper, ﬁrstly will be shown how D.S. Theory of Evidence can be
used in precise positioning of moving objects, and then the performance
of this method in localization will be compared with K.F. method. D.S
theory is a generalization of the Bayesian method that can handle sensor
information defects. In the event that all necessary information is avail-
able, all data fusion methods provide a comprehensive and acceptable
approach but in the face of lack of sensitivity and sensitivity data, they
are not reliable. In such cases, data fusion methods should make as-
sumptions about sensor data which may not match on real data.
Consequently, conﬂicting results may be obtained. But D.S. theory is
not limited by model defects or previous information defects. So, the ev-
idence is determined solely on the basis of the obtained data, and not by
the assumed data. So it can be concluded that this method is a quick and
an accurate tool for combining incomplete data. For sensory data fusion
using the D.S. method, a given weight must be assigned to each data
source at any given time. For this purpose, ﬁrstly, by the standard devi-
ation of data, for the N last produced data, the amount of data validation
for each sensor is determined. If the standard deviation of the N last data
is smaller than the speciﬁed value α, there are fewer jumps and more
conﬁdence in that sensor, and if the standard deviation is greater than
that value, reliability will be less. α and N values are empirically deter-
mined based on the behavior of sensor data or expert opinion. Initially,
the variance of each sensor's data is calculated:
σ2 ¼ 1
N
X
N
i¼1
ðxi−μ
Þ2
ð16Þ
Hihgly reliable level c1 ¼ 1
ð
Þ σ2 ≤α
ð17Þ
Poorly reliable level c2 ¼ 2
ð
Þ σ 2 Nα
With each new data, the variance of the N last data is updated and
the upper and lower levels of conﬁdence are speciﬁed. These levels
Fig. 2. Simulation of the kinematics model of robot.
Fig. 3. Simulate a robot and transfer parts to the simulator SimMechanics.
50
S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48–55
(a) 
(b) 
(c) 
Fig. 4. Noise simulation diagrams and the results of applying the fusion tool to the robot position parameters.
51
S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48–55
are used in Shannon entropy relations as follows: (Lu et al., 2016)
Pc
1t ¼
R c1t
R
c1t þ
R
c2t
; Pc
2t ¼
R c2t
R
c1t þ
R
c2t
ð18Þ
And the entropy criterion for each of the Sensors is obtained as fol-
lows:
Hit ¼
X
2
c¼1
Pc
it log2Pc
it
ð19Þ
Finally, by the entropy obtained for each Sensor, and using the for-
mula below, its weight will be determined (Lu et al., 2016):
Wit ¼
1
ðHit
Þ2 PI
i¼1 Hit
ð
Þ−2
ð20Þ
The greater the entropy of a sensor's data, the lower the conﬁdence
level, and consequently the lower the weight assigned.
2.3.2. Sensor noise simulation and performance analysis of fusion tools
Firstly, the positioning data of two sensor data sources- Sensor 1: the
GPS data and Sensor 2: the total of IMU data and the rear wheel
encoders- is received from sensor blocks in the Simulink toolbox, and
re-simulated after adding noise and bias up to 10% of the turmoil to
Fig. 5. Entropy graph of sensor data and weight assigned to sensor sources.
Table 1
Comparison of the performance of two data fusion tools in simulation.
Test number
Benchmarking
D.S (% error)
K.F (% error)
1
MAD
MSE
1.99
4.76
1.45
2.59
2
MAD
MSE
2.23
6.02
1.59
3.22
3
MAD
MSE
1.94
4.76
1.42
2.62
4
MAD
MSE
1.77
4.01
1.49
2.85
5
MAD
MSE
1.78
3.45
2.03
5.23
6
MAD
MSE
1.43
2.77
1.59
3.22
52
S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48–55
those. Then, in the ﬁrst step, for a speciﬁc semicircular path, the sensor
values are combined by Kalman ﬁlter and Dempster-Shafer separately.
In the following, there are three series of diagrams, each showing one
of the robot position parameters. In each series of charts, the output of
the simulated blocks of two sensor sources that are coupled with
noise, and the results of applying two data fusion tools are shown. In
Fig. 4a, the parameter x, in the Fig. 4b, the parameter y and in the
Fig. 4c, the parameter θ are analyzed and in MATLAB simulation toolbox,
the performance of these two data fusion tools is shown in a given time
period and path. As indicated in these diagrams, the red-dashed paths
are the real robot motions in the simulation environment, which is ex-
pected to show by the ideal sensors. Purple and pale green colors are
shown simulated sensor data after the noise respectively for the ﬁrst
and second sensor sources. Also the blue color shows the fusion of
two noisy sensor data by D.S. method and the dark green color shows
the fusion by the K.F. method. It is clear that the Kalman method
shows better performance in Gaussian noise.
Fig. 5a is the entropy graph of the two sensor sources, and Fig. 5b is
the obtained weight graph based on sensor data. As shown in these
charts, the entropy of the Sensor 1 is greater than the Sensor 2, which
Fig. 6. a) Mobile robot implemented for tests. b) GPS module. c) IMU/AHRS module.
Fig. 7. a) Dempster-Shafer method. b) Kalman Filter method.
Fig. 8. a) Dempster-Shafer method. b) Kalman Filter method.
53
S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48–55
indicates more disorder in GPS data than the encoder plus IMU data and
so, the reliability of the data is less and the weight allocated to that Sen-
sor will be less.
3. Results and discussions
Looking at the diagrams of Fig. 4, K.F. seems to have a better perfor-
mance than D.S., but according to Fig. 5, the need to provide a bench-
mark for comparing the performance of these two data fusion tools
seems to be necessary. For this reason, the Mean Absolute Deviation
(MAD) and Mean square Error (MSE) criteria have been used. MAD,
also referred to as the “mean deviation” or sometimes “average absolute
deviation”, is the mean of the data's absolute deviations around the
data's mean: the average (absolute) distance from the mean. “Average
absolute deviation” can refer to either this usage, or to the general
form with respect to a speciﬁed central point. The mean absolute devi-
ation of a set {x1,x2,x3, … ,xn} is
MAD ¼ 1
n
X
n
i¼1
xi−m x
ð Þ
j
j
ð21Þ
Which n is the number of values and m(x) is the mean. MAD has
been proposed to be used in place of standard deviation since it corre-
sponds better to real life. Because the MAD is a simpler measure of var-
iability than the standard deviation. This method's forecast accuracy is
very closely related to the MSE method which is just the average
squared error of the forecasts. Although these methods are very closely
related, MAD is more commonly used because it is both easier to com-
pute (avoiding the need for squaring) and easier to understand.
MSE ¼ 1
n
X
n
i¼1
xi−bxi
�
�2
ð22Þ
which bxi is predicted value.
The numbers in the table below belong to the x variable in each sim-
ulation test and for each evaluation criterion.
The simulation reported in the previous section has been carried out
six times for two different paths (a linear path and a circular path). In
the ﬁfth and sixth tests, the noise level applied to the Sensors is non-
Gaussian noise. Typical IMU/GPS integration approaches usually adopt
the Gaussian error assumption. However, in practice, especially during
off-road navigation and when several sources of GPS interference are
present, this assumption does not hold. To this end, the best non-
Gaussian noise model is the Huber estimator using a robust estimator
algorithm, which is able to handle multipath GPS signals as well as in-
tentional and unintentional interferences. Gaussian mixture models
are based on the representation of any non-Gaussian distribution as
the sum of multiple Gaussian densities with different weights
(Karlgaard and Schaubt, 2007). For the IMU/GPS algorithm discussed
here, the noise is assumed to be composed of two Gaussian
components.
The results presented in Table 1 show that the performance of the
Dempster-Shafer method in sensor data fusion associated with non-
Gaussian noise is better than the Kalman ﬁlter. Since in real life the
noise behavior is more non-Gaussian, it seems that the Dempster
method will perform better in dealing with real issues.
4. Experimental results
In this section, an unmanned ground vehicle is implemented practi-
cally to perform real-time navigation. This vehicle has been constructed
in Biosystem Mechanical Engineering Department of Tehran University.
The vehicle used as mobile robot has a servo mechanism as its steering
mechanism. Then the aforementioned controller have been imple-
mented and the platform is examined in two case study to verify the re-
sults of simulation. The GPS module applied in the experiment is NEO-
M8N and the IMU/AHRS module is GY-801. The vehicle and modules
can be seen in Fig. 6.
In the platform test a linear and a circular smooth path are generated
as desired paths. These paths are fed into the system as inputs sepa-
rately. So, the actual paths are obtained. The relation between the de-
sired and actual path is shown in Figs. 7 and 8. The root mean square
error (RMSE) criterion is used for comparing the performance of these
two methods. According to Table 2, the Dempster-Shafer method had
better performance in path tracking. Also the error between actual
and desire orientation angles during the circle path is shown in Fig. 9
and Table 2.
Axis units x and y are in Figs. 7 and 8 in meter, and in Fig. 9, the x-axis
is in terms of time (second) and the y axis in radians.
As seen from the Figures and Table above, the Dempster-Shafer
method provides better performance with less error than Kalman Filter
in vehicle localization. Mean deviation from desire path in path tracking
by Dempster-Shafer method is about 15.5 cm in linear path and about
17 cm in circular path. This method shows an error about 17.7 degree
in orientation during circular path tracking. Localization using Kalman
Filter makes up a higher error about 4.7% in linear path and about 5%
Table 2
Comparison of the performance of two data fusion tools in experimental test.
Path
RMSE
D.S
Linear path
0.156
Circular path
0.172
Orientation error
0.31
K.F.
Linear path
0.203
Circular path
0.224
Orientation error
0.40
Fig. 9. The error between actual and desire orientation angles. a) Dempster-Shafer method. b) Kalman Filter method.
54
S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48–55
in circular path. Orientation error in circular path is about 23 degree by
Kalman ﬁlter method.
5. Conclusion
In this paper, tried to simulate controlling of an agricultural tractor
robot and it's localization in real condition using Dempster-Shafer and
Kalman ﬁlter algorithms, as data fusion tools. The results showed a bet-
ter performance of the Dempster-Shafer method when applying non-
Gaussian noise which is the reliability validation of the Dempster-
Shafer method in conditions close to real conditions. To verify the valid-
ity of this statement and also to compare these two methods of data fu-
sion for localization in real-world conditions, two paths were designed
on the crop soil. The mobile robot prepared for autonomous navigation
tracked the aforementioned paths by the controller described in the
paper. Results show the better performance of Dempster-Shafer
method in comparison with Kalman Filter.
References
Bevly, D.M., Sheridan, R., Gerdes, J.C., 2001. Integrating INS sensors with GPS velocity
measurements for continuous estimation of vehicle sideslip and tire cornering stiff-
ness. Proceedings of the 2001 American Control Conference. IEEE, Arlington, VA,
USA https://doi.org/10.1109/ACC.2001.945508.
Denoeux, T., Li, S., Sriboonchitta, S., 2017. Evaluating and comparing soft partitions: an ap-
proach based on Dempster-Shafer Theory. Journal of IEEE Transactions on Fuzzy Sys-
tems. 26 (3), 1231–1244. https://doi.org/10.1109/TFUZZ.2017.2718484.
Hall, D.L., Llinas, J., 1997. An introduction to multisensor data fusion. Journal of Proceed-
ings of the IEEE. 85 (1), 6–23. https://doi.org/10.1109/5.554205.
Karlgaard, C.D., Schaubt, H., 2007. Huber-based divided difference ﬁltering. AIAA Journal
of Guidance, Control and Dynamics 30 (3), 885–891. https://doi.org/10.2514/
1.27968.
Keicher, R., Seufert, H., 2000. Automatic guidance for agricultural vehicles in Europe. Jour-
nal of Computers and electronics in agriculture. 25 (1), 169–194. https://doi.org/
10.1016/S0168-1699(99)00062-9.
Klein, L.A. 1993. Sensor and data fusion concepts and applications. Society of Photo-
Optical Instrumentation Engineers (SPIE) Bellingham, WA, USA. ISBN: 0819432318.
Li, W., Huang, Y., Cui, Y., Dong, S., Wang, J., 2010. Trafﬁcability analysis of lunar mare ter-
rain by means of the discrete element method for wheeled rover locomotion.
J. Terrramech. 47 (3), 161–172. https://doi.org/10.1016/j.jterra.2009.09.002.
Liu, Y.T., Pal, N.R., Marathe, A.R., Lin, C.T., 2017. Weighted fuzzy Dempster-Shafer frame-
work for multi-modal information integration. Journal of IEEE Transactions on
Fuzzy Systems. 26 (1), 338–352. https://doi.org/10.1109/TFUZZ.2017.2659764.
Lu, C.-C., Ying, K.-C., Chen, H.-J., 2016. Real-time relief distribution in the aftermath of
disasters–a rolling horizon approach. Journal of Transportation research part E: logis-
tics and transportation review. 93, 1–20. https://doi.org/10.1016/j.tre.2016.05.002.
Mizushima, A., Ishii, K., Noguchi, N., Matsuo, Y., Lu, R., 2011. Development of a low-cost
attitude sensor for agricultural vehicles. Journal of Computers and electronics in agri-
culture. 76 (2), 198–204. https://doi.org/10.1016/j.compag.2011.01.017.
Murakami, N., Dale Will, J., Ito, A., Steffen, M., Inoue, K., Kita, K., Miyaura, S., 2006. Environ-
ment identiﬁcation technique using hyper omni-vision and image map. Proceedings
of the 3rd IFAC Intl. Workshop Bio-Robotics, pp. 317–320 (DOI:10.1.1.472.918).
Park, J.J., 2016. Graceful Navigation for Mobile Robots in Dynamic and Uncertain Environ-
ments. (Ph.D. diss.). Mechanical Engineering Dept., University of Michigan.
Shafer, G., Gillett, P.R., Scherl, R.B., 2003. A new understanding of subjective probability
and its generalization to lower and upper prevision. Int. J. Approx. Reason. 33 (1),
1–49. https://doi.org/10.1016/S0888-613X(02)00134-2.
Subramanian, V., Burks, T.F., Arroyo, A., 2006. Development of machine vision and laser
radar based autonomous vehicle guidance systems for citrus grove navigation. Jour-
nal of Computers and electronics in agriculture. 53 (2), 130–143. https://doi.org/
10.1016/j.compag.2006.06.001.
Zhang, Q., Wu, D., Reid, J.F., Benson, E.R., 2002. Model recognition and validation for an
off-road vehicle electrohydraulic steering controller. J. Mech. 12 (6), 845–858.
https://doi.org/10.1016/S0957-4158(01)00030-7.
55
S. Erfani et al. / Artiﬁcial Intelligence in Agriculture 1 (2019) 48–55
