Original Article
Local binary patterns based on directional wavelet transform for
expression and pose-invariant face recognition
Mohd. Abdul Muqeet a,⇑, Raghunath S. Holambe b
a Electrical Engineering Department, Muffakham Jah College of Engineering and Technology, Hyderabad, TS 500034, India
b Department of Instrumentation Engineering, S.G.G.S Institute of Engineering and Technology, Nanded, Maharashtra 431606, India
a r t i c l e
i n f o
Article history:
Received 1 July 2017
Revised 21 October 2017
Accepted 15 November 2017
Available online 13 December 2017
Keywords:
Face recognition
Directional wavelet transform (DIWT)
Local binary patterns (LBP)
a b s t r a c t
Face image variations such as expression and pose radically increase the intra-class variations which
affect the performance of feature extraction methods. It is desirable to extract more robust local discrim-
inative features to effectively represent such face variations. This paper proposes a novel facial feature
extraction method which utilizes interpolation-based directional wavelet transform (DIWT) and local
binary patterns (LBP). An efﬁcient direction assessment method based on quadtree partitioning is imple-
mented to facilitate adaptive direction selection in the local regions from the face images to obtain DIWT
sub-bands. LBP histogram features are extracted from selected top-level DIWT sub-bands to obtain local
descriptive feature set. Experimental results are simulated on ORL database, GT database, and FEI data-
base. A comparison with various contemporary methods which include holistic, local descriptors and
LBP-based non-adaptive multiresolution analysis methods illustrate the efﬁcacy of the proposed method.
� 2017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an
open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
1. Introduction
In the security-heightened world, face recognition has emerged
as a popular biometric recognition method with non-intrusive and
low precision equipment for image acquisition. Prominent holistic
face recognition methods are PCA [1], LDA [2], and locality preserv-
ing projections (LPP) [3]. Local descriptors [4–7] are attaining
much interest due to their ease of implementation and robustness
to noise. Local binary patterns (LBP) [4] are effectively applied for
facial feature extraction owing to its texture discrimination capa-
bility and computational efﬁciency [5]. Jabid et al. [6] proposed a
robust local facial feature descriptor based on local directional pat-
terns (LDP) and conﬁrmed good results compared to LBP. But LDP
exhibit sensitivity to noise and rotation. Weber local descriptors
(WLD) [7] are more descriptive and computationally efﬁcient than
LBP. Recently, Zhang et al. [8] used the WLD to extract local facial
features at predeﬁned facial landmarks and effectively captured
pose-invariant features. Ullah et al. [9] applied WLD for gender
classiﬁcation from face images. Although such local descriptors
achieve higher recognition results than holistic methods, their per-
formance restricts due to variations in expression, pose, illumina-
tion and occlusion.
DWT-based methods are increasingly admired for face recogni-
tion and assure good recognition results with certain modiﬁcation
in the way the DWT sub-bands are utilized [10–12]. But due to iso-
tropic property and less directionality, these methods do not
assure superior recognition results for moderate to extreme varia-
tions in expression and pose. Numerous multiresolution analysis
(MRA) methods with anisotropic scaling and better directionality
are combined with LBP to extract MRA-based local descriptive fea-
tures. Local Gabor binary patterns (LGBP) [13] combine the Gabor
ﬁlters with LBP and provide high accuracy at the cost of high
dimensionality histogram features. Arousi et al. [14] presented a
face recognition technique under illumination-variant conditions
using the SPT decomposition and LBP. Recently, Zou et al. [15]
evolved a new feature descriptor based on the curvelet transform
and LBP. Here, authors used the LBP coded image of low-
frequency approximation sub-band and mid-frequency subbands
to form the feature set. These MRA [10–12] and LBP-based MRA
methods [13–15] despite capturing the directional information
lack the adaptation in selecting directions based on image charac-
teristics. Moreover, suffer from various issues such as sub-band
selection to form an efﬁcient feature set, a high computational rate,
https://doi.org/10.1016/j.aci.2017.11.002
2210-8327/� 2017 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
⇑ Corresponding author at: Electrical Engineering Department, Muffakham Jah
College of Engineering and Technology, Banjara Hills, Hyderabad 500034, TS, India.
E-mail address: ab.muqeet2013@gmail.com (M.A. Muqeet).
Peer review under responsibility of King Saud University.
Production and hosting by Elsevier
Applied Computing and Informatics 15 (2019) 163–171
Contents lists available at ScienceDirect
Applied Computing and Informatics
journal homepage: www.sciencedirect.com
and complex ﬁlter design. Face variations mainly affect the edge
manifolds of an image and if directional information and orienta-
tion of such edge manifolds can be approximated adaptively it will
signiﬁcantly improve the performance.
Adaptive directional lifting wavelet transforms [16–18] due to
the beneﬁt of directional lifting and adaptation in the direction
selection as per characteristics of the image have been effectively
used for image compression. Chang et al. [16] proposed a direction
adaptive discrete wavelet transform (DA-DWT) for image compres-
sion. Only one pair of lifting step and non-interpolated distant inte-
ger samples are used to realize directional lifting. Here Neville
ﬁlters [21] are used as the prediction and update ﬁlters. Ding
et al. [17] suggested adaptive directional lifting (ADL) for image
coding and used interpolated fractional samples. ADL method
could be implemented with one or two pairs of lifting steps with
5/3 or 9/7 tap ﬁlters [20]. Maleki et al. [18] proposed directional
wavelets (DIW) with megaquad partitioning algorithm in the adap-
tive directional lifting based framework to efﬁciently capture edge
features.
Furthermore, due to lifting based factorization, perfect recon-
struction is also assured and the resultant multiresolution image
is completely compatible with that of the conventional 2-D DWT
multiresolution image. Recently, Muqeet and Holambe proposed
a face recognition method [19] using DA-DWT [16] for face veriﬁ-
cation and established its effectiveness compared to various
famous subspace and non-adaptive MRA methods.
To effectively deal with the expression and pose variation in
face images this paper consider the underlying theory of DIW
and proposes interpolation-based directional wavelet transform
(DIWT). In the implementation of DIWT, we used quadtree parti-
tioning instead of megaquad partitioning which is used in DIW
[18]. LBP is applied to the selected top-level DIWT sub-bands
which eventually extract the descriptive histogram features.
Finally, LDA is applied to obtain discriminant features in reduced
space. Nearest Neighbor (NN) [2] classiﬁer is used in an identiﬁca-
tion process. The outline of the paper is depicted as follows. A
review of the related methodology is explained in Section 2 includ-
ing the DIWT and LBP. Further, in Section 3, proposed facial feature
extraction method is explained. In Section 4 experimental results
are performed on three eminent face databases and results of the
proposed method are compared with various contemporary meth-
ods. Conclusions based on the method are presented in Section 5.
2. Material and methods
The primary motivation of the proposed method is to obtain
efﬁcient MRA-based local descriptive features from the face
images.
The
subsections
will
illustrate
the
DIWT
with
the
improved quadtree partitioning method, and review LBP and its
importance in proposed facial feature extraction method.
2.1. Directional wavelet transform (DIWT)
The essence of directional wavelet transform (DIWT) is to per-
form the lifting wavelet transform steps at a viable variety of direc-
tions while preserving the characteristics of multiresolution,
localization, and isotropy intact. The DIWT still performs the con-
ventional lifting wavelet transform but consist of modiﬁcation in
the prediction and update step. The 2-D DIWT can be realized with
only one pair of lifting step, which means only one prediction step
followed by one update step.
Let X ¼ fði; jÞji; j 2 Z2g signify an image deﬁned on a 2-D orthog-
onal sampling grid. Let xe ¼ xð2i; jÞ and xo ¼ xð2i þ 1; jÞ represent
even and odd samples respectively. Here we consider row sub-
sampling. Column sub-sampling follows the same relations with
exchange of row and column variables.
In the prediction step, odd samples xoði; jÞ 2 Xo are predicted
from even samples xeði; jÞ 2 Xe. The prediction of each odd sample
is a linear combination of neighboring even samples with a strong
correlation. We express that the pixels have a strong correlation in
the direction d. Here samples from six even rows are selected to
take part in prediction step given in (1) and the generated high-
pass sub-band Hði; jÞ is depicted in (2),
Pðxoði; jÞÞ ¼
X
Np�1
n¼�Np
Kp
n � xeði þ n; j þ ntan�1dÞ
ð1Þ
Hði; jÞ ¼ gH � ½xoði; jÞ � Pðxoði; jÞÞ�
ð2Þ
where 2Np, Kp, and gH are the length of the prediction ﬁlter, the
coefﬁcient of the prediction ﬁlter, and scaling factor respectively.
Now in update step, even samples xeði; jÞ are updated from odd
row samples of high pass signal along the same optimal direction
d. Similarly samples from six nearest even rows take part in update
step. The update step and the low-pass sub-band Lði; jÞ are given in
(3) and (4) respectively,
Uðxeði; jÞÞ ¼
X
Nu�1
n¼�Nu
Ku
n �
xoði þ n; j þ ntan�1dÞ�
Pðxoði þ n; j þ ntan�1dÞÞ
"
#
ð3Þ
Lði; jÞ ¼ gL � ½xeði; jÞ þ g�1
H � ½UðHði; jÞÞ��
ð4Þ
where 2Nu, Ku, and gL are the length of the update ﬁlter, the coefﬁ-
cient of the update ﬁlter, and scaling factor respectively. Neville ﬁl-
ters [21] with six vanishing moments are used for prediction and
update ﬁlter [16], i.e. Np ¼ Nu ¼ 3. These ﬁlters possess linear phase
characteristics with high vanishing moments which increase their
texture discrimination capability. From [21], the coefﬁcients of the
prediction
ﬁlter
can
be
obtained
as
Kp
n ¼ ½3; �25; 150; 150;
�25; 3�=28 and the coefﬁcients of update ﬁlter can be obtained as
Ku
n ¼ ½3; �25; 150; 150; �25; 3�=29.
For
our
feature
extraction
method, we consider ﬁve directions aligned at f45�; 72:5�; 90�;
112:5�; 135�g [18]. This direction set is used to demonstrate the efﬁ-
cacy of DIWT to capture directional multiresolution features. The
term j þ ntan�1 in (1) and (3) may not always be an integer sample
and does not exist on the original sampling grid. Consequently, an
interpolation scheme is carried out to estimate the intensity at this
non-integer sample [18],
xði þ n; j þ ntan�1dÞ ¼
X
Nc�1
l¼�Nc
al � xði þ n; ½j þ ntan�1d � l�Þ
ð5Þ
where ½�� denotes the integer part, Nc ¼ 1 and a�1 ¼ a0 ¼ 0:5 which
selects the two closest even samples for interpolation [18]. The inte-
ger samples used to interpolate the non-integer samples at the opti-
mal direction d have to be even sampled. If the optimal direction
crosses over the integer sample the value is estimated by the near-
est even sample otherwise, the fractional sample is calculated from
interpolation of two nearest even samples as given in (5). The sub-
pixel interpolation improves the directional orientation property of
the image and maximises the compaction of image energy into low
frequency sub-band.
Due to face variations, each face image contains a varying
amount of information located at different local pixel regions. To
consider these local regions the quadtree partitioning scheme is
applied which facilitate effective direction assignment. Here each
face image is quadtree partitioned into non-overlapping blocks
and a direction from the direction set is selected for each block
based upon the minimum value of the prediction error energy.
All the pixels in a quadtree block will have the same direction.
164
M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171
The proposed partitioning scheme used in our proposed method is
explained here. Let each face image is quadtree partitioned into
non-overlapping blocks with initial block size as Sini and minimum
block size as Smin where quadtree partitioning need to stop. Each
block is denoted by Sb 2 X and sample from each block is denoted
as xSb 2 Sb. The energy summation of the prediction error for each
block is calculated as,
PEðSd
b;iÞ ¼
X
i
kxSb;i � PSb;iðxSb;iÞk2
2 þ kD
ð6Þ
The complexity of this partitioning is controlled by a value of
Lagrangian multiplier k, speciﬁcally if we set it to zero; we may
obtain a full tree and if we set it to 1 does not allow any partition-
ing [18]. D is the number of bits spent on signaling the selection of
direction. The direction which gives the minimum prediction error
is obtained as,
db ¼ argminifPEðSd
b;iÞg
ð7Þ
To check each of quadtree partition is an optimal partition or
not, an improvement in the quadtree partitioning is presented.
Now further quadtree partitioned each block Sb into four sub-
blocks Sb;r; r ¼ 1; . . . ; 4 and for each Sb;r calculate the prediction
error
PEðSd
b;rÞ
and
consecutively
the
direction
db;r.
If
PEðSd
b;rÞ P PEðSd
bÞ and size of sub-block Sb;r reaches to Smin then stop
partitioning and store the optimal direction and optimal block
otherwise, repeat the previous step of quadtree partitioning. Quad-
tree partitioned blocks improves the adaptive direction selection of
pre-assigned ﬁve directions and thus the edge manifolds present at
the diagonal directions including horizontal and vertical direction
can be effectively approximated in DIWT implementation.
The above-mentioned 1-D process can be easily extended to the
2-D case where second dimension lifting is again performed on
Hði; jÞ high pass and Lði; jÞ low pass sub-bands generating four
sub-bands LHði; jÞ, LLði; jÞ, HHði; jÞ, and HLði; jÞ. The schematic of 2-
D DIWT is presented in Fig. 1. Partitioning structure with direction
estimation is presented in Fig. 2 for a face image from GT database
[23].
2.2. Local binary patterns
The local binary patterns (LBP) [4] has emerged as an efﬁcient
local feature descriptor for face recognition [5,13–15]. To assign a
label for each pixel, the LBP operator uses its intensity value as a
threshold and compares it against pixel values in a 3 � 3 neighbor-
hood and considers the result as a binary number. Generally, the
LBP is computed with P sampling points ðxp 2 ð0; . . . ; P � 1ÞÞ in
the neighborhood of center pixel xmðic; jcÞ at a radial distance given
by R [4],
LBPP;R ¼
X
P�1
p¼0
ts � ðxp � xmÞ � 2p
ð8Þ
tsðdiffÞ ¼
1;
ðdiffÞ P 1
0;
ðdiffÞ < 0
�
ð9Þ
where tsðdiffÞ is a threshold function. Fig. 3 illustrates the LBP oper-
ator and the consequent label for center pixel xm. If the sampling
points p’s are not mapped in the neighborhood of the center pixel,
they are bi-linearly interpolated [4]. Ojala et al. [4] introduced uni-
form patterns, where a binary pattern is uniform if it contains at
most two bitwise transitions from 0 to 1, or vice versa when the
binary pattern is considered circularly,
UðLBPP;RÞ ¼ jsðxp�1 � xmÞ � sðx0 � xmÞj þ
X
P�1
p¼1
jsðxp � xmÞ
� sðxp�1 � xmÞj
ð10Þ
It was veriﬁed that ‘‘uniform” patterns are fundamental pat-
terns of local image textures [4]. In the mapping of LBPP;R to
LBPu2
P;R, subscript u2 means that the uniform patterns U(LBP) have
a value of at most 2. There are P � ðP � 1Þ þ 2 uniform patterns
and remaining non-uniform patterns are accumulated into one sin-
gle bin resulting in P � ðP � 1Þ þ 3 feature dimension. After LBP
labeling of the image, codes of all pixels of an input image xLði; jÞ
are collected and formed into a histogram [4] given as,
Hl ¼
X
i;j
FfxLði; jÞ ¼ lg;
l ¼ 0; 1; 2; . . . ; n � 1
ð11Þ
FfAg ¼
1;
if A is true
0;
if A is false
�
ð12Þ
where n is the number of different labels produced by the LBP oper-
ator. With LBPu2
8;1, the feature dimension is 59. The LBP histogram is
a composition of micro-patterns and provides information about
the local distribution of spots, edges over the entire image. LBP
Fig. 1. Schematic of 2-D DIWT.
Fig. 2. (a) Face image (GT face database). (b) Quadtree partitioning structure with
direction estimation.
Fig. 3. Example of LBP computation.
M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171
165
has tolerance to illumination and offer simplicity in implementation
and can be effectively used for local feature descriptor in our pro-
posed method.
3. Proposed face recognition method
In the proposed method, LBP histograms are extracted from
DIWT sub-bands to form a novel MRA-based local feature descrip-
tor. To achieve this, we perform DIWT decomposition and consider
the top-level low-frequency approximation sub-band LL and high-
frequency sub-bands HL, and LH. Due to the adaptive direction
selection within the quadtree partitioned blocks and directional
lifting, dependencies found over image discontinuities can be
effectively de-correlated which concentrate most of the energy of
high-frequency sub-bands into low-frequency LL sub-band [17].
But the sub-bands HL and LH also contain edge and contour details
of face images signiﬁcant in extracting pose and expression rele-
vant features with the aid of LBP. We ignored the high-frequency
HH sub-band as it mostly contains the noise with negligible feature
details. Histogram encoded for the whole sub-band describes only
the occurrences of the micro-patterns without describing their
location information. To preserve the spatial characteristics and
to a form a robust local feature descriptor, multi-region LBPu2
8;1 uni-
form pattern-based histograms features [4] are obtained from non-
overlapping regions of DIWT sub-bands {LL, HL, LH}. LBPu2
8;1 patterns
are statistically signiﬁcant and offer reduced dimensionality with
increased robustness to noise.
Each of the sub-band {LL, HL, LH} is equally divided into m non-
overlapping rectangle regions R0; R1; . . . ; Rm, each of size x � y pix-
els. From each of these m regions we extract local histogram fea-
tures LBP Rk each with 59 labels separately. Local histograms
features from successive regions are concatenated to form a
multi-region single enhanced histogram feature with dimension
59 � m. Let LL Hl;k, HL Hl;k, and LH Hl;k denote the concatenated his-
togram features for LL, HL, and LH sub-bands respectively,
LL Hl;k ¼
X
i;j
FfLLLði; jÞ ¼ lgLLfði; jÞ 2 Rkg
ð13Þ
HL Hl;k ¼
X
i;j
FfHLLði; jÞ ¼ lgHLfði; jÞ 2 Rkg
ð14Þ
LH Hl;k ¼
X
i;j
FfLHLði; jÞ ¼ lgLHfði; jÞ 2 Rkg
ð15Þ
where l ¼ 0; 1; 2; . . . ; n � 1; k ¼ 0; . . . ; m � 1.
Furthermore LL Hl;k, HL Hl;k, and LH Hl;k histogram features are
concatenated to form LBP FV feature set representing DIWT-
based local histogram feature,
LBP FV ¼ ½LL Hl;k; HL Hl;k; LH Hl;k�
ð16Þ
We have maintained 128 � 128 pixels uniform size for face
images of all the face databases. Each of the DIWT sub-bands {LL,
HL, LH} is of size 32 � 32 pixels. In our proposed method each of
these sub-bands is divided into m ¼ 16 regions with x � y ¼ 8 � 8
pixels
regions
with
collective
dimension
of
LBP_FV
is
59 � m � 3 ¼ 2832. The consideration of size of each region
x � y ¼ 8 � 8 and obtaining 16 regions from the DIWT sub-band
coefﬁcients provides a trade-off between recognition performance
and feature vector length. The multi-region histogram feature
LBP FV provides a novel DIWT-based local descriptive feature from
the sub-band coefﬁcients. LDA is applied to LBP FV to obtain
reduced dimension discriminant feature space. Similarly, DIWT
and consecutively LBP are applied on test face images to obtain test
histogram features. Next, LDA is applied to obtain the reduced
dimension test features. Finally, we apply the NN classiﬁer to clas-
sify test features in the reduced space for face identiﬁcation. The
overall ﬂow of the proposed method is presented in Fig. 4.
4. Experimental results
All experiments are conducted using Matlab 2014a on a stan-
dard i3-330 2.13 GHz machine with 2.0 GB RAM. To evaluate the
efﬁcacy of the proposed expression and pose-invariant feature
extraction method, we consider three face databases such as ORL
database [22], Georgia Tech (GT) database [23] and FEI face data-
base [24,25]. Face feature extraction methods such as LDA [2],
LPP [3], LBP [5], LDP [6], WLD [7], LGBP [13], and LSPBPS [14]
and CTLBP [15] have been compared against our proposed method.
4.1. Parameter settings
In this sub-section, we discuss parameter settings for imple-
mentation of our proposed and different comparative methods.
With face image size 128 � 128, the DIWT decomposition level J
for all the databases is selected two as optimal [19].
A set of experiment is also conducted on databases to select the
optimal value of Sini and k. The parameter Sini is the initial block size
required to start the quadtree partitioning. The parameter k con-
trols the quadtree partitioning. With reference to [19], for quadtree
partitioning we select three different values of Lagrangian multi-
plier, speciﬁcally k ¼ 5, k ¼ 7 and k ¼ 9 to obtain the optimal value.
Again considering [19], we performed the proposed method for
two different block sizes Sini ¼ 8 � 8 and Sini ¼ 16 � 16 individually.
We also consider Smin ¼ 4 � 4 pixels. We randomly selected ﬁve
images as training and rest images as test images for all the three
databases. Moreover, we repeat the individual experiment on
individual database ten times and noted the average rank-one
Fig. 4. Diagram of the proposed method.
166
M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171
recognition rate as depicted in Table 1. Based upon the results, we
consider Sini ¼ 8 � 8 pixels and k ¼ 9 as optimal, which demon-
strate their effectiveness to capture directional features as regards
to local face variations.
For LDA, and LPP based methods the NN classiﬁer is used with
Euclidean distance measure. For LBP and LGBP, images are parti-
tioned into the 8 � 8 pixel region. For LGBP, we used ﬁlters at ﬁve
different scales and eight orientations [13]. LBPu2
8;1 with NN classi-
ﬁer and Chi-square distance measure is used for both the methods
[5]. For LDP, 56 bin histogram features are extracted from 8 � 8
non-overlapped regions of face images. Chi-square dissimilarity
measure is used to compare two spatially encoded LDP histograms
features. For WLD, a patch size of 3 � 3 pixel is considered for cod-
ing and generated histograms of differential excitation and orien-
taion component are concatenated into a 2-D histogram. Later
this 2-D histogram is encoded into a 1-D histogram to be used as
the feature vector and Chi-square dissimilarity measure is used
to compare two histograms. For LSPBPS, multi-region LBPu2
8;1 is
obtained from all the generated sub-bands to form the feature
set and Chi-square dissimilarity measure is used to compare two
LSPBPS histogram features. For CTLBP, the LBP coded image of
low-frequency sub-band with mid-frequency sub-bands are used
to form the feature set and LPP is used for dimensionality reduction
[15]. To evaluate the performance we use cumulative match char-
acteristic (CMC) curves [26,27]. CMC curve is used as a measure of
1: m identiﬁcation system performance. It judges the ranking capa-
bilities
of
our
proposed
method.
Due
to
random
selection
approach, we run the experiment ten times on each database
and only report the average rank-one recognition rates in all fol-
lowing experiments.
4.2. Experiment on the ORL face database
The ORL database entails 400 images composed from 40 dissim-
ilar subjects with 10 diverse images of each subject. The face
images exhibit changes in the capture time, lighting, head position,
facial expressions such as eyes open or closed, smiling or not smil-
ing. All the face images are resized to 128 � 128. Some samples
images of one subject are shown in Fig. 5.
We randomly choose N (N = 2, 3, 4, 5) images of each subject for
training and the rest images for testing. Table 2 shows the average
rank-one recognition rates of different comparative methods.
Selecting N = 5 randomly, the average CMC for different methods
are also depicted in Fig. 6. It is visible both from Table 2 and
Fig. 6 that the proposed method yields superior results. A substan-
tial improvement of 11.77%, 10.72% can be observed over LDA and
LPP methods for N = 2. We can also observe an improvement of
12.59%, 11.55%, 9.25% over LBP, LDP, and WLD respectively for N
= 2. Compared with LBP-based non-adaptive MRA methods such
as LGBP, LSPBPS, and CTLBP our method exhibit higher rank-one
recognition rates even for fewer numbers of training images. The
proposed method makes an adaptive selection of best lifting direc-
tion from the direction set and uses interpolated samples at the
spatial resolution of ﬁve directions and preserves the local details
of expression and pose-variant features. Such details, when
extracted in terms of LBP histogram features, improves the overall
performance.
4.3. Experiments on the GT face database
The Georgia Tech (GT) face database comprises of 750 JPEG
color images of 50 distinct persons. All images are captured against
a cluttered background with dissimilar facial expression, lighting
conditions, and scale. All images are converted to grayscale images
and resized to 128 � 128 pixels. Some sample images of a subject
are shown in Fig. 7. We randomly consider N (N = 3, 4, 5, 6, 7)
images of each subject for training, respectively, and in every case,
the remaining images for testing. Comparative results are depicted
in Table 3. The average cumulative match curves for different
methods are described in Fig. 8 for N = 7. It is observed that the
proposed method not only outperforms LDA and LPP but also
excels with LBP, LDP, and WLD. As compared to LGBP, LSPBPS,
and CTLBP for N = 3, our method offers improvement of 16.80%,
8.84%, and 7.30% respectively. Speciﬁcally, the improvement is sig-
niﬁcant for less number of training images. LGBP, CTLBP, and
LSPBPS do not provide adaptation in selecting a direction within
a block of samples. Whereas, DIWT performs directional lifting
with the adaptive directional selection and considers the edge
manifolds relating to expression and pose variations effectively.
Table 1
Comparison of different sub-block size and value of Lagrangian multiplier (%).
Block Size/Database
k ¼ 5
k ¼ 7
k ¼ 9
8 � 8
16 � 16
8 � 8
16 � 16
8 � 8
16 � 16
ORL
95.19
94.34
95.81
95.00
97.00
96.22
GT
67.12
66.44
67.89
67.11
68.40
67.23
FEI
81.78
80.25
82.60
81.00
84.67
83.50
Fig. 5. Samples face images of a subject from the ORL face database.
Table 2
Benchmarking of the rank-one recognition rates on the ORL face database (%).
Number of training samples per subject
2
3
4
5
LDA
73.63
76.29
83.33
87.00
LPP
74.50
78.00
87.75
90.50
LBP
72.94
80.61
86.39
90.49
LDP
73.81
83.22
85.58
91.00
WLD
75.73
84.60
89.37
92.50
LGBP
79.20
83.90
90.43
92.52
LSPBPS
81.27
84.50
92.10
94.50
CTLBP
82.50
84.86
93.33
95.00
Proposed method (DIWTLBP)
83.45
88.26
94.17
97.00
M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171
167
Moreover, LBP histogram features from DIWT sub-bands contain
most signiﬁcant details which improve the recognition rate.
4.4. Experiments on the FEI face database
The FEI database contains 14 color images of 200 subjects taken
against a white homogenous background. The images are in
upright front position but a proﬁle rotation of about 180� is consid-
ered while capturing the images which increase the complexity of
this database [25]. Sample images of a subject are shown in Fig. 9.
All the images are manually cropped and resized to 128 � 128
pixels and converted to grayscale images. We randomly choose N
(N = 3, 4, 5, 6, 7) images of each subject for training and the rest
images for testing. Table 4 illustrates the average rank-one recog-
nition rates for different methods. The average CMC curves for dif-
ferent methods are depicted in Fig. 10 for N = 7. LDA and LPP being
holistic methods fail to consider the extreme expression and pose
variations. We observe an improvement of 21.10%, 14.24%, and
10.89% over LBP, LDP, and WLD respectively for N = 3. As compared
to LSPBPS and CTLBP which considers more sub-bands to achieve
good results we used only three top-level sub-bands of DIWT to
effectively generate descriptive features using the LBP histogram.
When N = 6, there is an improvement of 6.81%, 5.96%, and 4.82%
over LGBP, LSPBPS, and CTLBP respectively. Thus the proposed
Fig. 6. CMC curves of comparative methods for ORL database.
Fig. 7. Samples face images of a subject from the GT face database.
Table 3
Benchmarking of the rank-one recognition rates on the GT face database (%).
Number of training samples per subject
3
4
5
6
7
LDA
31.50
45.45
48.40
52.22
58.50
LPP
45.17
54.55
57.60
64.89
70.75
LBP
43.20
51.64
56.20
62.78
68.74
LDP
47.33
56.71
61.45
66.40
72.75
WLD
52.00
60.82
64.40
71.22
75.49
LGBP
48.67
58.91
63.80
70.00
74.76
LSPBPS
53.33
61.36
66.20
73.56
77.50
CTLBP
54.23
62.35
67.60
74.89
78.73
Proposed method (DIWTLBP)
58.50
65.66
68.40
77.33
82.25
168
M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171
method also works well for the database with a large number of
face images under pose and expression variations.
4.5. Comparison with different adaptive directional lifting methods
In order to demonstrate the efﬁcacy of DIWT with ﬁve direc-
tions, we compare it with two adaptive directional lifting methods
such as ADWT with nine directions [19] and ADL [17] with nine
directions with 9/7 tap ﬁlters. To implement ADWT and ADL, sim-
ilar settings from Section 4.1 are considered such as J = 2,
Sini ¼ 8 � 8, Smin ¼ 4 � 4 and k = 9. Furthermore, for a fair compar-
ison similar LBP setting are also applied for histogram feature
extraction. For ORL database N = 5, and for GT and FEI face database
N = 7 images are randomly considered as training images and rest
as testing images. Table 5 illustrates the comparative results.
ADWT incorporates block-based partitioning and do not considers
the interpolation of fractional samples. In our proposed method
quadtree partitioning scheme and incorporation of interpolation
mechanism for fractional samples considers the face image charac-
teristics more efﬁciently. In ADL, adaptation of nine directions
increases computational complexity.
4.6. Computational complexity
The proposed method also has a comparable computational
time for feature extraction compared with different methods.
Fig. 11 shows the computation time of some of the comparative
method to process an ORL database face image of size 128 � 128
Fig. 8. CMC curves of comparative methods for GT face database.
Fig. 9. Samples face images of a subject from the FEI face database.
Table 4
Benchmarking of the rank-one recognition rates on the FEI face database (%).
Number of training samples per person
3
4
5
6
7
LDA
46.73
48.20
56.89
68.50
74.29
LPP
48.55
51.20
59.78
72.00
78.00
LBP
51.36
56.40
65.33
74.25
84.57
LDP
55.82
65.32
67.61
77.25
86.29
WLD
58.00
67.60
70.19
78.57
86.86
LGBP
54.73
63.00
75.11
82.00
87.71
LSPBPS
59.45
66.20
76.67
82.75
88.29
CTLBP
60.91
64.40
78.89
83.75
90.29
Proposed method (DIWTLBP)
65.09
73.80
84.67
88.00
91.14
M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171
169
pixel resolution and to produce the features and no further step of
dimensionality reduction and classiﬁcation is applied. We mainly
considered those methods which require the feature extraction at
the pre-processing stage. The LGBP method has the highest compu-
tation time.
5. Conclusion
This paper offered a novel expression and pose-invariant facial
feature extraction method primarily based on DIWT-based LBP his-
togram features. To implement the DIWT an effective quadtree
partitioning scheme is implemented. DIWT provides adaptation
in directional selection based on image characteristics and efﬁ-
ciently represents image edge manifolds. Multi-region LBP his-
togram features from the top level sub-bands {LL, HL, LH} form
an efﬁcient feature set. According to Tables 2–4, it is proven that
the proposed method demonstrates superior discrimination ability
and yields the best rank-one recognition results for the selected
face databases. From the results, we can signify that the proposed
method not only excels with the holistic method such as LDA and
LPP but also demonstrate superiority against various local descrip-
tors such as LBP, LDP, and WLD methods for face images with les-
ser to extreme expressions and pose variations. Our experimental
results verify that the proposed method also outperforms some
non-adaptive LBP-based MRA methods such as LGBP, LSPBPS, and
CTLBP. We also demonstrated the effectiveness of our method over
other adaptive directional lifting methods.
References
[1] M. Turk, A. Pentland, Eigenfaces for recognition, J. Cognit. Neurosci. 3 (1)
(1991) 71–86.
[2] P.N. Belhumeur, J.P. Hespanha, D.J. Kriegman, Eigenfaces vs. Fisherfaces:
recognition using class speciﬁc linear projection, IEEE Trans. Pattern Anal.
Mach. Intell. 19 (7) (1997) 711–720.
[3] X. He, S. Yan, Y. Hu, P. Niyogi, H. Zhang, Face recognition using laplacianfaces,
IEEE Trans. Pattern Anal. Mach. Intell. 27 (3) (2005) 328–340.
[4] T. Ojala, M. Pietikäinen, T. Maenpää, Multiresolution gray-scale and rotation
invariant texture classiﬁcation with local binary patterns, IEEE Trans. Pattern
Anal. Mach. Intell. 24 (7) (2002) 971–987.
[5] T. Ahonen, A. Hadid, M. Pietikäinen, Face description with local binary
patterns: application to face recognition, IEEE Trans. Pattern Anal. Mach.
Intell. 28 (12) (2006) 2037–2041.
[6] T. Jabid, M.H. Kabir, O. Chae, Local directional pattern (LDP)-a robust image
descriptor for Object Recognition, in: Proceedings of 7th IEEE International
Conference on Advanced Video and Signal Based Surveillance, 2010, pp. 482–
487.
[7] J. Chen, S. Shan, C. He, et al., WLD: a robust local image descriptor, IEEE Trans.
Pattern Anal. Mach. Intell. 32 (9) (2010) 1705–1720.
[8] Z. Zhang, L. Wang, Q. Zhu, S.K. Chen, Y. Chen, Pose-invariant face recognition
using facial landmarks and weber local descriptor, Knowl.-Based Syst. 84
(2015) 78–88.
[9] I. Ullah, M. Hussain, G. Muhammad, H. Aboalsamh, G. Bebis, A.M. Mirza,
Gender recognition from face images with local WLD descriptor, in: 19th
International Conference Systems, Signals and Image Processing (IWSSIP), pp.
417, 420, 11–13 April 2012.
[10] J.T. Chien, C.C. Wu, Discriminant waveletfaces and nearest feature classiﬁers
for face recognition, IEEE Trans. Pattern Anal. Mach. Intell. 24 (12) (Dec. 2002)
1644–1649.
[11] Z.H. Huang, W.J. Li, J. Wang, T. Zhang, Face recognition based on pixel-level and
feature-level fusion of the top-level’s wavelet sub-bands, Info. Fusion 22
(2015) 95–104.
[12] Z.H. Huang, W.J. Li, J. Shang, J. Wang, T. Zhang, Non-uniform patch based face
recognition via 2D-DWT, Image Vision Comput. 37 (2015) 12–19.
[13] W. Zhang, S. Shan, W. Gao, H. Zhang, Local Gabor binary pattern histogram
sequence (LGBP): a novel non-statistical model for face representation and
recognition, in: Proceedings of IEEE International Conference and Computer
Vision, 2005, pp. 786–791.
[14] M. El Aroussi, M. El Hassouni, S. Ghouzali, M. Rziza, D. Aboutajdine, Local
steerable pyramid binary pattern sequence LSPBPS for face recognition
method, Int. J. Signal Process. 5 (4) (2009) 281–284.
Fig. 10. CMC curves of comparative methods for FEI face database.
Table 5
Rank-one recognition rates for different LBP-based adaptive directional transform
methods (%).
Database
ADWTLBP
ADLLBP
DIWTLBP
ORL
95.00
95.50
97.00
GT
81.72
81.00
82.25
FEI
89.67
90.80
91.14
0
0.5
1
1.5
2
2.5
Seconds
Fig. 11. Computation time for ORL face image.
170
M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171
[15] L. Zhou, W. Liu, Z.M. Lu, T. Nie, Face recognition based on curvelets and local
binary pattern features via using local property preservation, J. Syst. Software
95, 209–216. https://doi.org/10.1016/j.jss.2014.04.037.
[16] C.L. Chang, B. Girod, Direction-adaptive discrete wavelet transform for image
compression, IEEE Trans. Image Process. 16 (5) (May 2007) 1289–1302.
[17] W. Ding, F. Wu, X. Wu, S. Li, H. Li, Adaptive directional lifting-based wavelet
transform for image coding, IEEE Trans. Image Process. 16 (2) (Feb. 2007) 416–
427.
[18] A. Maleki, B. Rajaei, H.R. Pourreza, Rate-distortion analysis of directional
wavelets, image processing, IEEE Trans. Image Process. 21 (2) (2012) 588–600.
[19] M.A. Muqeet, R.S. Holambe, Local appearance-based face recognition using
adaptive directional wavelet transform, J. King Saud Univ. – Comput. Inform.
Sci. (2017), https://doi.org/10.1016/j.jksuci.2016.12.008.
[20] W. Sweldens, The lifting scheme: construction of second generation wavelets,
SIAM J. Math. Anal. 29 (2) (1998) 511–546.
[21] J. Kovacevic, W. Sweldens, Wavelet families of increasing order in arbitrary
dimensions, IEEE Trans. Image Process. 9 (3) (2000) 480–496.
[22] [Online] ORL database, http://www.uk.research.att.com/pub/data/att_faces.
zip.
[23] [Online] GT Database, http://www.aneﬁan.com/research/facereco.htm.
[24] [Online] FEI Database, http://fei.edu.br/cet/facedatabase.html.
[25] G. Thomaz, C. Eduardo, G. Antonio, A new ranking method for principal
components analysis and its application to face image analysis, Image Vis.
Comput. 28 (2010) 902–913.
[26] P.
Phillips,
P.
Grother,
R.
Michaels,
D.
Blackburn,
T.
Elham,
J.
Bone,
FRVT
2002:
Facial
Recognition
Vendor
Test,
Technical
report,
DoD,
April
2003.
[27] V. Štruc, N. Pavešic, The Complete Gabor-Fisher Classiﬁer for Robust Face
Recognition,
EURASIP
Advances
in
Signal
Processing,
vol.
2010,
2010,
https://doi.org/10.1155/2010/847680.
M.A. Muqeet, R.S. Holambe / Applied Computing and Informatics 15 (2019) 163–171
171
