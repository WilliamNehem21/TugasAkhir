Sparse representation of 3D images for piecewise dimensionality reduction
with high quality reconstruction
Laura Rebollo-Neira *, Daniel Whitehouse
Mathematics Department, Aston University, B47ET, Birmingham, UK
A R T I C L E I N F O
Keywords:
Image representation with dictionaries
Greedy pursuit algorithms
A B S T R A C T
Sparse representation of 3D images is considered within the context of data reduction. The goal is to produce high
quality approximations of 3D images using fewer elementary components than the number of intensity points in
the 3D array. This is achieved by means of a highly redundant dictionary and a dedicated pursuit strategy
especially designed for low memory requirements. The beneﬁt of the proposed framework is illustrated in the ﬁrst
instance by demonstrating the gain in dimensionality reduction obtained when approximating true color images
as very thin 3D arrays, instead of performing an independent channel by channel approximation. The full power
of the approach is further exempliﬁed by producing high quality approximations of hyper-spectral images with a
reduction of up to 371 times the number of data points in the representation.
1. Introduction
Sparse representation of 2D images has been a subject of extensive
research in the last ﬁfteen years [1–3]. Applications which beneﬁt from
sparsity range from image restoration [4,5] and classiﬁcation [6–8] to
feature extraction [9,10] and super resolution reconstructions [11,12].
While sparse representation of 3D arrays has received less attention, the
advantage of modeling these arrays as a superposition of 3D elementary
components is recognized in previous publications [13–16].
At present, the most widely used multichannel images in every day
life are true color images. The simplest way of sparsely representing these
images is channel by channel, or adding constraints of correlation across
colors [4,17]. However, as demonstrated in this work, sparsity in the
representation of true color images can increase substantially if the
approximation is realized by means of 3D elements taken from a highly
redundant dictionary. The effect is of course more pronounced for arrays
involving more channels, such as hyper-spectral images.
From a practical view point, the current drawbacks of 3D sparse
modeling using a large dictionary are (i) storage requirements and (ii) the
complexity of the concomitant calculations. In this paper we propose a
method which, by addressing (i) leaves room for possible high perfor-
mance implementations using Graphics Processing Unit (GPU) pro-
gramming. While the approach is illustrated using Central Processing
Unit (CPU) programming, the storage requirements are shown to ﬁt
within 48 Kb's of fast access shared memory of a GPU when the
approximation of a 3D image is realized with a partition block size of
8 �8 � 8 and with a separable dictionary of redundancy 125.
The main contributions of the paper are listed below.
� The low memory implementation of the Orthogonal Matching Pursuit
(OMP) strategy, called Self Projected Matching Pursuit (SPMP) [18] is
dedicated to operating in 3D (SPMP3D) with separable dictionaries.
This technique delivers an iterative solution to the 3D least squares
problem which requires much less storage than direct linear algebra
methods. It could therefore be also applied with any other of the
pursuit strategies that include a least squares step [14,19–22].
� The Cþþ MEX ﬁle for the SPMP3D method has been made available
on a dedicated website [23]. All the scripts for reproducing the results
of the paper in the MATLAB environment have also been placed on
that website.
� Remarkable reduction in the dimensionality of the representation of
true color images and hyper-spectral images, with high quality
reconstruction, is demonstrated using highly redundant and highly
coherent separable dictionaries.
The results suggest that the method may be of assistance to image
processing applications which rely on a transformation for data reduction
as a ﬁrst step of further processing. For examples of relevant applications
we refer to Refs. [24–28].
* Corresponding author.
E-mail address: rebollol@aston.ac.uk (L. Rebollo-Neira).
Contents lists available at ScienceDirect
Array
journal homepage: www.elsevier.com/journals/array/2590-0056/open-access-journal
https://doi.org/10.1016/j.array.2019.100001
Received 10 February 2019; Received in revised form 17 April 2019; Accepted 29 May 2019
Available online 20 June 2019
2590-0056/© 2019 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
Array 1-2 (2019) 100001
2. Notational convention
R represents the set of real numbers. Boldface letters are used to
indicate Euclidean vectors, 2D and 3D arrays. Standard mathematical
fonts indicate components, e.g., d 2 RNis a vector of components dðiÞ 2 R;
i ¼ 1;…;N. The elements of a 3D array I 2 RNx�Ny�Nzare indicated as Iði;j;
mÞ; i ¼ 1;…;Nx; j ¼ 1;…;Ny; m ¼ 1;…;Nz. Moreover, for each m-value
Im 2 RNx�Nystands for the 2D array of elements Imði;jÞ ¼ Iði;j;mÞ; i ¼ 1;…;
Nx; j ¼ 1;…;Ny, which, when not leaving room for ambiguity will also be
represented as Ið:;:; mÞ. The transpose of a matrix, Gsay, is indicated as
G>.
The inner product between 3D arrays, say I 2 RNx�Ny�Nzand G 2
RNx�Ny�Nz, is given as:
D
G; Ii3D ¼
X
Nx
i¼1
X
Ny
j¼1
X
Nz
m¼1
Gði; j; mÞIði; j; mÞ:
For G 2 RNx�Ny�Nzwith tensor product structure, i.e. for G ¼ gx � gy �
gz, with gx 2 RNx;gy 2 RNyand gz 2 RNz, we further have
�
G; Ii3D ¼
X
Nz
m¼1
hgx; Imgy�
gzðmÞ ¼ hp; gz�
;
(1)
where for each value of m the vector Imgy 2 RNxarises by the standard
matrix-vector multiplication rule and p 2 RNzis given by its components
pðmÞ ¼ hgx;Imgyi; m ¼ 1;…;Nz. Note that hp;gziindicates the Euclidean
inner product in 1D, i.e.
�
p; gzi ¼
X
Nz
m¼1
pðmÞgzðmÞ:
The deﬁnition ð1Þinduces the norm I3D ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
hI; Ii3D
p
.
3. Sparse representation of multi-channel images
Suppose that a 3D image, given as an array I 2 RNx�Ny�Nzof intensity
pixels, is to be approximated by the linear decomposition
Ik ¼
X
k
n¼1
cðnÞDℓn;
(2)
where each cðnÞis a scalar and each Dℓnis an element of RNx�Ny�Nzto be
selected from a set, D ¼ fDngM
n¼1, called a ‘dictionary’.
A sparse approximation of I 2 RNx�Ny�Nzis an approximation of the
form (2) such that the number k of elements in the decomposition is
signiﬁcantly smaller than N ¼ NxNyNz. The terms in the decomposition
(2) are taken from a large redundant dictionary, from where the elements
Dℓnin (2), called ‘atoms’, are chosen according to an optimality criterion.
Within the redundant dictionary framework for approximation, the
problem of ﬁnding the sparsest decomposition of a given multi-channel
image can be formulated as follows: Given an image and a dictionary,
approximate the image by the ‘atomic decomposition’ (2) such that the
number k of atoms is minimum. Unfortunately, the numerical minimization
of the number of terms to produce an approximation up to a desired
error, involves a combinatorial problem for exhaustive search. Hence, the
solution is intractable. Consequently, instead of looking for the sparsest
solution, one looks for a ‘satisfactory solution’, i.e., a solution such that
the number of k-terms in (2) is considerably smaller than the image
dimension. For 2D images this can be effectively achieved by greedy
pursuit strategies in the line of the Matching Pursuit (MP) [29] and OMP
[30] methods, if dedicated to 2D separable dictionaries [14,18,32,33].
Within a tensor product framework the consideration of OMP in 3D is
natural.
Let's assume that a 3D dictionary is obtained as the tensor product
D ¼ D x � D y � D zof three 1D dictionaries D x ¼ fdx
m 2 RNxg
Mx
m¼1,
D y ¼ fdy
m 2 RNyg
My
m¼1, and D z ¼ fdz
m 2 RNzg
Mz
m¼1, with MxMyMz ¼ M.
For computational purposes the 1D dictionaries are stored as three
matrices Dx 2 RNx�Mx, Dy 2 RNy�Myand Dz 2 RNz�Mz. Suppose now that a
3D array I 2 RNx�Ny�Nzis to be approximated by an atomic decomposition
of the form
Ik ¼
X
k
n¼1
cðnÞdx
ℓx
n � dy
ℓy
n � dz
ℓz
n;
(3)
where for n ¼ 1;…;kthe atoms dx
ℓx
n, dy
ℓy
nand dz
ℓz
nare selected from the given
1D dictionaries. The common step of the techniques we consider for
constructing approximations of the form (3) is the stepwise selection of
the atoms in the atomic decomposition. On setting k ¼ 1and I0 ¼ 0at
iteration k the algorithm selects the indices ℓx
k, ℓy
kand ℓz
kas follows
ℓx
k; ℓy
k; ℓz
k ¼ arg max
n¼1;…;Mx
i¼1;…;My
s¼1;…;Mz
��������������
�
dx
n � dy
i � dz
s; Rk�1i3D
��������������
;
(4)
with Rk�1 ¼ I � Ik�1. It is the determination of the coefﬁcients cðnÞ; n ¼
1;…;kin (3) that gives rise to pursuit strategies which go with different
names.
3.1. Matching Pursuit in 3D (MP3D)
The MP approach in 3D would simply calculate the coefﬁcients in (3)
as
cðnÞ ¼
D
dx
ℓx
n � dy
ℓy
n � dz
ℓz
n; Rn�1i3D;
n ¼ 1; …; k:
(5)
The main drawback of the MP method is that it may select linearly
dependent atoms. Moreover, that approximation is not stepwise optimal
because at iteration k the coefﬁcients (5) do not minimize the norm of the
residual error. The pursuit strategy that overcomes these limitations is
the so called OMP [30].
3.2. Orthogonal Matching Pursuit in 3D
The implementation of OMP in 3D (OMP3D) we describe here is the
3D extension of the implementation of OMP in 2D given in Ref. [32]. An
alternative algorithm called Kronecker-OMP, which is based on the
Tucker representation of a tensor, is discussed in Ref. [14]. Our algorithm
is based on adaptive biorthogonalization and Gram-Schmidt orthogo-
nalization procedures, as proposed in Ref. [31] for the one dimensional
case.
In order to ensure the coefﬁcients cðnÞ; n ¼ 1;…;kinvolved in (3) are
such that
��Rk��2
3D ¼ hRk;Rki3Dis minimum, the decomposition (3) should
fulﬁll that
Ik ¼
X
k
n¼1
cðnÞdx
ℓx
n � dy
ℓy
n � dz
ℓz
n ¼ bPVkI;
(6)
where
bPVkis
the
orthogonal
projection
operator
onto
Vk ¼
spanfdx
ℓx
n � dy
ℓy
n � dz
ℓz
ng
k
n¼1. This is ensured by requiring that Rk ¼ I �
bPVkI. The required representation of bPVkis of the form bPVkI ¼ Pk
n¼1Anh
Bk
n; Ii3D, where each An 2 RNx�Ny�Nzis an array with the selected atoms
An ¼ dx
ℓx
n � dy
ℓy
n � dx
ℓz
n. The concomitant biorthogonal reciprocal set Bk
n;
n ¼ 1; …; kcomprises the unique elements of RNx�Ny�Nzsatisfying the
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
2
conditions:
i) hAn; Bk
mi3D ¼ δn;m ¼
8
<
:
1
if n ¼ m
0
if n 6¼ m:
ii) Vk ¼ spanfBk
ng
k
n¼1:
Thus, the coefﬁcients cðnÞ; n ¼ 1;…;Nin (6) which guarantee mini-
mum norm of the residual error are calculated as
cðnÞ ¼
�
Bk
n; Ii3D;
n ¼ 1; …; k:
The required arrays Bk
n; n ¼ 1;…;kshould be upgraded and updated to
account for each newly selected atom. Starting from k ¼ 1;R0 ¼ I, B1
1 ¼
W1 ¼ A1 ¼ dx
ℓx
1 � dy
ℓy
1 � dz
ℓz
1, where
ℓx
1; ℓy
1; ℓz
1 ¼
arg max
n¼1;…;Mx
i ¼ 1; …; My
s ¼ 1; …; Mz
���������������
�
dx
n � dy
i � dz
s; Rk�1i3D
���������������
;
at iteration k þ 1the indices ℓx
kþ1; ℓy
kþ1; ℓz
kþ1corresponding to the new
atom Akþ1 ¼ dx
ℓx
kþ1 � dy
ℓy
kþ1 � dz
ℓz
kþ1are selected as in (4). The required
reciprocal set Bkþ1
n
; n ¼ 1;…;k þ 1is adapted and upgraded by extending
the recursion formula given in Ref. [31] as follows.
Bkþ1
n
¼ Bk
n � Bkþ1
kþ1
�
Akþ1; Bk
ni3D;
n ¼ 1; …; k;
where
Bkþ1
kþ1 ¼ Wkþ1
�
kWkþ1k2
3D;
with
Wkþ1 ¼ Akþ1 �
X
k
n¼1
Wn
kWnk2
3D
hWn; Akþ1i3D;
including, for numerical accuracy, the re-orthogonalization step:
Wkþ1 ← Wkþ1 �
X
k
n¼1
Wn
jjWnjj2
3D
hWn; Wkþ1i3D:
Although the image approximation is carried out by partitioning the
images into relatively small 3D blocks, memory requirements of the
OMP3D method are high. Indeed, the above are 2ðk þ 1Þnonseparable
arrays each of dimension N ¼ NxNyNzwhich need to be stored in double
precision. Hence, we consider next a low memory implementation of the
orthogonal projection step, which avoids having to store the arrays Wn;
n ¼ 1;…; kand Bk
n; n ¼ 1;…; kand fully exploits the separability of the
dictionary.
3.3. Self Projected Matching Pursuit in 3D (SPMP3D)
The Self Projected Matching Pursuit (SPMP) methodology was
introduced in Ref. [18] and conceived to be used with separable dictio-
naries in 2D (SPMP2D). Because the technique is based on calculations of
inner products, it can be easily extended to operate in 3D (SPMP3D).
Suppose that at iteration k the selection process has chosen the atoms
labelled by the triple of indices fℓx
n; ℓy
n; ℓz
ngk
n¼1and let ~I
kbe the atomic
decomposition
~I
k ¼
X
k
n¼1
aðnÞdx
ℓx
n � dy
ℓy
nB � dz
ℓz
n;
(7)
where the coefﬁcients aðnÞ; n ¼ 1;…;kare arbitrary numbers. Every array
I 2 RNx�Ny�Nzcan be expressed as
I ¼~I
k þ ~R:
(8)
For
~I
kto
be
the
optimal
representation
of
Iin
Vk ¼
spanfdx
ℓx
n � dy
ℓy
n � dz
ℓz
ng
k
n¼1, in the sense of minimizing the norm of the
residual ~R, it should be true that bPVk ~R ¼ 0. The SPMP3D method fulﬁlls
this property by approximating ~Rin Vk, via the MP method, and sub-
tracting that component from ~R. The following algorithm describes the
whole procedure.
Starting from k ¼ 0and R0 ¼ I, at each iteration, implement the steps
below.
i) Increase k ← k þ 1and apply the criterion (4) for selecting the triple of
indices ðℓx
k;ℓy
k;ℓz
kÞ. Save this triple in the array Lðk;1 : 3Þ ¼ ðℓx
k;ℓy
k;ℓz
kÞ;
and set
cðkÞ ¼
D
dx
ℓx
k � dy
ℓy
k � dz
ℓz
k; Rk�1i3D
and implement the update of the residue Rk ¼ Rk�1 � cðkÞdx
ℓx
k � dy
ℓy
k �
dz
ℓz
kas follows:For s ¼ 1;…Nzcalculate
ΔRkð :; :; sÞ ¼ Rk�1ð :; :; sÞ � cðkÞdx
ℓx
k
�
dy
ℓy
k
�>
dz
ℓz
kðsÞ;
to update Rk as
Rk ¼ Rk�1 � ΔRk:
ii) Given the indices Lðn;1 : 3Þ ¼ ðℓx
n;ℓy
n;ℓz
nÞ; n ¼ 1;…;kof the previously
selected atoms, and a tolerance ε for the projection error, realize the
orthogonal projection up to that error as follows. Set j ¼ 1, ~R
0 ¼
Rkand at iteration j apply the steps a) - c) below.
a) For n ¼ 1;…;kevaluate
αðnÞ ¼
D
dx
ℓx
n � dy
ℓy
n � dz
ℓz
n; ~R
j�1i3D;
(9)
and single out the value k�such that
k� ¼ arg max
n¼1;…;k
��αðnÞ
��:
(10)
The value k�signalizes the indices ℓx
k�; ℓy
k�; ℓz
k�corresponding to the
already selected atoms with maximum correlation with the residual ~R
j�1.
cðk�Þ ← cðk�Þ þ αðk�Þ
and for s ¼ 1;…;Nzevaluate
Δ~R
jð :; :; sÞ ¼ αðk�Þ dx
ℓx
k�
�
dy
ℓy
k�
�>
dz
ℓz
k� ðsÞ
to update the residual ~R
jas
~R
j ¼ ~R
j�1 � Δ~R
j:
b) If jαðk�Þj < εstop. Otherwise update the coefﬁcient
This step subtracts from the residual a component in Vkand add that
component to the approximation. ~I
k
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
3
c) Increase j ← j þ 1and repeat the steps a) - c) to keep subtracting
components of ~R
jin Vkuntil iteration, J say, for which the stopping
criterion b) is met. This criterion indicates that, up to tolerance ε, the
residual has no component in Vkso that one can set Rk ¼ ~R
J�1.
Continue with steps i) and ii) to keep enlarging Vkuntil, for a required
tolerance error ρ, the condition Rk
3D < ρis reached.
Remark 1.
For each ﬁxed value k the rate of convergence
lim
j→∞I � ~R
j ¼ bPVkI
through the steps a) - c) above is given in Ref. [34] for the one dimen-
sional case. The proof for 3D is identical to that proof, because a 3D array
can be represented as a long 1D vector. What varies is the implementa-
tion. A vectorized version of the algorithm would not be applicable in this
context.
3.3.1. Implementation details
The bulk of the computational burden in the SPMP3D method lies in
the realization of the selection of atoms (4). Algorithm 1 outlines a
procedure implementing the process. It should be stressed once again
that the algorithm is designed to use as little memory as possible, rather
than to reduce complexity.
Algorithm 1 Implementation of the selection of atoms (c.f. (4))
Procedure ½α;ℓx;ℓy;ℓz� ¼ Sel3DAtomðR;Dx;Dy;DzÞ
Input: 3D array R, matrices Dx, Dy Dz the columns of which are the atoms in the
corresponding dictionaries.
Output: selected indices ℓx;ℓy;ℓz, and α ¼ hdx
ℓx � dy
ℓy � dz
ℓz ;Ri3D
{Initiate the algorithm}
ðNz; MzÞ ¼ sizeðDzÞ ; Mx ¼ sizeðDx; 2Þ; My ¼ sizeðDy; 2Þ q ¼ zerosðMx; MyÞα ¼ 0
for m ¼ 1 : Mz do
qð:; :Þ ¼ 0
for s ¼ 1 : Nz
qð:;:Þ ¼ qð:;:Þ þ D>
x Rð:;:;sÞDydz
mðsÞ
end for
{Realize (4) by ﬁnding the partial maximum, and its argument, for each m-plane}
½l1;l2;~q� ¼ maxðjqð:;:ÞjÞ
if~q > αthen
α ¼ ~q; ℓx ¼ l1; ℓy ¼ l2; ℓz ¼ m
end if
end for
At iteration k the outputs of Algorithm 1 are saved as cðkÞ ¼ α and Lðk;
1 : 3Þ ¼ ðℓx;ℓy;ℓzÞ. The implementation details for selecting the triple of
indices at the projection step are given in Algorithm 2. This is used in
Algorithm 3 for the realization of the actual projection to recalculate the
coefﬁcients in the atomic decomposition.
Algorithm 2Selection of the triple of indices from the reduced dictionary (c.f. (10))
Procedure ½α�;k�� ¼ SelTripðR;Dx;Dy;Dz;LÞ
Input: As in Algorithm 1 plus the array L, with the triple of indices
Lðn; 1 : 3Þ ¼ ðℓx
n; ℓy
n; ℓz
nÞ; n ¼ 1…k
Output: k� and the corresponding values of α (c.f. (10)) to update the coefﬁcients and
residual {Initiate the algorithm}
α� ¼ 0
for n ¼ 1 : k do
p ¼ 0
for s ¼ 1 : Nz do
p ¼ p þ ðdx
ℓx
n Þ>Rð:;:;sÞdy
ℓy
n dz
ℓz
n ðsÞ
end for
if jpj > jα�j then
k� ¼ n and α� ¼ p
end if
end for
Algorithm 3Implementation of the self projection steps a) - c).
Procedure ½~R;c� ¼ Proj3D(R;Dx;Dy;Dz;L;c;ε;MaxJ).
Input: As in Algorithm 2, plus the coefﬁcients of the atomic decomposition c, a
tolerance parameter ε for the numerical error of the projection, and a maximum
number of permitted iterations, MaxJ.
Output: Orthogonal residual ~R. Coefﬁcients ~c of the optimized atomic decomposition.
for j ¼ 1 : MaxJ
{Selection of atoms using Algorithm 2}
½α�;k�� ¼ SelTrip(R;Dx;Dy;Dz;L)
{Check stopping criterion}
if jα�j < ε then
stop
end if
{Update the coefﬁcients}
cðk�Þ ← cðk�Þ þ α�
{Update the residual}
for s ¼ 1 : Nz then
Rð:; :; sÞ ← Rð:; :; sÞ � α�ðdx
ℓx
k� Þ>Rð:;:;sÞdy
ℓy
k� dz
ℓz
k� ðsÞ
end for
end for
{For clarity in the description only, we re-name here the residual and coefﬁcients}
R ¼ R; c ¼ c
Due to computational complexity and memory requirements, pursuit
strategies using general dictionaries can only be implemented on an
image partitioned into small blocks.
We consider nonoverappling blocks. The approximation of each block
is carried out independently of the others. When the approximation of all
the blocks is concluded, these are assembled together to produce the
approximation of the whole image. While the sparsity results yielded by
the OMP3D and the SPMP3D methods are theoretically equivalent, we
have seen that the latter implementation is much more economic in terms
of storage demands. As discussed in Remark 2 below, this feature makes
the SPMP3D algorithm suitable for possible GPU implementations using
only the fast access shared memory. Assuming for simplicity in the no-
tation that a 3D image is partitioned into cubes of size N3
b and the dic-
tionaries D x, D y and D z are all of the same size Nb � rNb, where r > 1 is
the redundancy of the 1D dictionary, the SPMP3D algorithm storage
needs are as follows.
1. Two N3
b arrays for the intensity block in the image partition and the
residual of the corresponding approximation.
2. Three matrices of size Nb � rNb for each dictionary, in case they are
different.
3. A r2 � N2
b array for the selection of indices in Algorithm 1.
4. A vector of k real numbers to store the coefﬁcients of the atomic
decomposition and k vectors of size 3 to store the indices of the atoms
in the atomic decomposition. The value of k is the total number of
atoms in the approximation of the block.
Since the stepwise complexity is dominated by the selection of indices
(c.f. (4)), within this setup it is O(r3N5
b) and for true color images
O(r3N3
b).
Remark 2.
By considering blocks of size 8 �8 � 8 and dictionaries of
redundancy r ¼ 5 in each dimension, the above listed storage needs of
the SPMP3D algorithm comfortably ﬁt the fast access shared memory of a
GPU in CUDA, which currently is 48 Kb. Indeed, in the worst-case sce-
nario (corresponding to an approximation of zero error using k ¼ 83
atoms for the approximation of an 8 �8 � 8 block) SPMP3D would
require 38 Kb to store most of the arrays in double precision, except for
those with the selected indices which contain integer numbers. This still
leaves 10 Kb for temporary variables to be used within calculations.
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
4
3.4. Mixed dictionaries
A key factor for the success in the construction of sparse representa-
tions is to have a good dictionary. While a number of techniques for
learning dictionaries from training data have been proposed in the
literature [35–42], they are not designed for learning large and highly
coherent separable dictionaries. Nevertheless, previous works [18,32,33,
43] have demonstrated that highly redundant and highly coherent
separable dictionaries, which are easy to construct, achieve remarkable
levels of sparsity in the representation of 2D images. Such dictionaries are
not speciﬁc to a particular class of images. A discrimination is only made
to take into account whether the approximation is carried out in the pixel
intensity or in the wavelet domain.
As will be illustrated by the numerical examples in the next section,
the approximation of the images we are considering are sparser when
realized in the wavelet domain (wd). This entails the following steps:
� Apply a wavelet transform to each channel Im; m ¼ 1; …; Nz to obtain
the arrays Um;m ¼ 1;…;Nz. For the numerical examples we have used
the 9/7 Cohen-Daubechies-Feauveau biorthogonal wavelet transform
[44].
� Approximate the array U 2 RNx�Ny�Nz exactly as it is done in the pixel
domain (pd).
� Apply the inverse wavelet transform to the approximated planes to
recover the approximated intensity channels.
The mixed dictionary we consider for the 2D approximation consists
of two sub-dictionaries: A trigonometric dictionary, D x
T, which is the
common sub-dictionary for the approximation in both domains, and a
dictionary of localized atoms, which contains atoms of different shapes
when used in each domain.
The trigonometric dictionary is the union of the dictionaries D x
C and
D x
S deﬁned below:
D x
C ¼
�
wcðnÞcos πð2i � 1Þðn � 1Þ
2Mx
; i ¼ 1; …; Nx
�Mx
n¼1
D x
S ¼
�
wsðnÞsin πð2i � 1ÞðnÞ
2Mx
; i ¼ 1; …; Nx
�Mx
n¼1
;
where wcðnÞ and wsðnÞ; n ¼ 1; …; Mx are normalization factors, and
usually Mx ¼ 2Nx. Thus, the trigonometric dictionary is constructed as
D x
T ¼ D x
C[D x
S.
For approximations in the pd we add the dictionary, D x
Lp, which is
built by translation of the prototype atoms in the left graph of Fig. 1. This
type of dictionary is inspired by a general result holding for continuous
spline spaces. Namely, that spline spaces on a compact interval can be
spanned by dictionaries of B-splines of broader support than the corre-
sponding B-spline basis functions [45,46]. Thus, the ﬁrst 4 prototype
atoms hi; i ¼ 1; …; 4 in the left graph of Fig. 1 are generated by dis-
cretization of linear B-spline functions of different support. For m ¼
1; 2; 3; 4 those functions are deﬁned as follows:
hmðxÞ ¼
8
>
>
>
>
>
>
>
<
>
>
>
>
>
>
>
:
x
m
if
0 � x < m
2 � x
m
if
m � x < 2m
0
otherwise:
(11)
The remaining prototypes, h5; h6 and h7, in the left graph of Fig. 1 are
generated taken the derivatives of the previous functions: h5ðxÞ ¼
ðh2ðxÞÞ
0, h6ðxÞ ¼ ðh3ðxÞÞ
0 and h7 ¼ ðh4ðxÞÞ
0. The corresponding dictio-
naries D Hm; m ¼ 1; …; 7 are built by discretization of the variable x in
(11) and sequential translation of one sampling point, i.e.,
D Hm ¼ fwhmðnÞhmði � nÞjNx; i ¼ 1; …; NxgM
n¼1;
m ¼ 1; …; 7;
where the notation hmði � nÞjNx indicates the restriction to be an array of
size Nx. The numbers whmðnÞ; n ¼ 1; …; M; m ¼ 1; …; 7 are normaliza-
tion factors. The dictionary D x
Lp arises by the union of the dictionaries
D Hm; m ¼ 1; …; 7 i.e., D x
Lp ¼ [7
m¼1D Hm. The whole mixed dictionary
D x
pd is ﬁnally formed as D x
pd ¼ D x
C[D x
S[D x
Lp. For the other dimension
we take D y
pd ¼ D x
pd.
For approximations in the wd we use the dictionary of localized atoms
D x
Lw as proposed in Ref. [33], which is built by translation of the pro-
totype atoms pi; i ¼ 1; …; 7 in the right graph of Fig. 1. Notice that p1 ¼
h1 and p3 ¼ h5. The remaining prototypes are given by the vectors:
p2 ¼ ð1; 1; 0; 0; …; 0Þ? 2 RNx; p4 ¼ ð1; 1; 1; 0; …; 0Þ? 2 RNx; p5 ¼
ð�1; 1; 1; 0; …; 0Þ? 2 RNx;
p6 ¼
ð1; �1; 1; 0; …; 0Þ? 2 RNx;
p7 ¼
ð�1; �1; 1; 0; …; 0Þ? 2 RNx;The corresponding dictionaries D Pm; m ¼ 1;
…; 7 are built as in the previous case by sequential translation of one
sampling point,
D Pm ¼
�
wpmðnÞpmði � nÞ
��Nx; i ¼ 1; …; Nx
�M
n¼1;
m ¼ 1; …; 7;
where the numbers wpmðnÞ; n ¼ 1; …; M; m ¼ 1; …; 7 are normalization
factors. The dictionaries D Pm; m ¼ 1; …; 7 give rise to D x
Lw ¼ [7
i¼1D Pm.
The latter generates the mixed dictionary D x
wd ¼ D x
C[D x
S[D x
Lw and
D y
wd ¼ D x
wd.
The
corresponding
2D
dictionaries
D pd ¼ D x
pd � D y
pd
and
D wd ¼ D x
wd � D y
wd are very large, but never used as such. All the cal-
culations are carried out using the 1D dictionaries. In order to demon-
strate the gain in sparsity attained by the approximation of 3D images by
partitioning into 3D blocks, we use dictionaries D wd and D pd only for
the approximation of the single channel 2D images. For the 3D case we
Fig. 1. The left graph illustrates the prototype atoms which generate by translation the dictionaries D Hm; m ¼ 1; …; 7: The prototypes in the right graph generate by
translation the dictionaries.D Pm; m ¼ 1; …; 7:
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
5
maintain the redundancy of the 3D dictionary equivalent to that of the 2D
dictionary, by considering the 1D dictionary
~D
x
pd ¼ D x
C[D x
S[D P1:
Notice that D P1 is the standard Euclidean basis for RNx, also called the
Dirac's basis, i.e., the basis arising by translation of the ﬁrst atom in Fig. 1.
Notice that ~D
x
pd⊂D x
pd and ~D
x
pd⊂D x
wd. We also consider ~D
y
pd ¼ ~D
x
pd and
~D
z
pd ¼ ~D
x
pd, but taking Nx ¼ Nz. The redundancy of the resulting dic-
tionary ~D pd ¼ ~D
x
pd � ~D
y
pd � ~D
z
pd is equivalent to the redundancy of the
2D dictionary D pd. In 3D we use the same dictionary in both domains
~D wd ¼ ~D pd.
4. Numerical results
The merit of the simultaneous approximation of multiple channel
images is illustrated in this section by recourse to two numerical exam-
ples. Firstly we make the comparison between the sparsity produced by
the joint approximation of the Red-Green-Blue (RGB) channel images
partitioned into blocks of size Nb �Nb � 3 and the sparsity obtained by
the independent approximation of each channel partitioned into blocks
of size Nb � Nb. Secondly, the full power of the approach is illustrated
through the gain in sparsity attained by approximating hyper-spectral
images partitioned into 3D blocks, vs the plane by plane approximation.
In both cases, once the approximation of each 3D block Iq in the
image partition is completed, for q ¼ 1; …; Q the kq-term atomic
decomposition of the corresponding block is expressed in the form
Ikq
q ¼
X
kq
n¼1
cqðnÞdx
ℓx;q
n � dy
ℓy;q
n � dz
ℓz;q
n :
(12)
The sparsity of the representation of an image of dimension N ¼ Nx �
Ny � Nz is measured by the Sparsity Ratio (SR), which is deﬁned as:
SR ¼ N
K;
(13)
where for the 3D representation K ¼ PQ
q¼1kq; with kq the number of
atoms in the atomic decomposition (12). For the channel by channel
decomposition of a Nz-channel image, each channel is partitioned into
P ¼ ðNx � NyÞ=N2
b blocks Ip;z; p ¼ 1;…;P, which are approximated by the
2D atomic decompositions
Ikp;l
p ¼
X
kp;l
n¼1
cp;l
p ðnÞdx
ℓx;p;l
n
� dy
ℓy;p;l
n ;
l ¼ 1; …; Nz;
(14)
where the indices ℓx;p;l
n
; ℓy;p;l
n
are selected for each channel l by the
OMP2D algorithm. Accordingly, the number K in (13) is given as K ¼
PNz
l¼1
PP
p¼1kp;l, with kp;l the number of atoms in the atomic decomposi-
tion (14).
Notice that the SR is a measure of the reduction of dimensionality for
representing an image. The larger the value of the SR the smaller the
dimensionality of the atomic decomposition representing the whole
image. The required quality of the approximation is ensured with respect
to the Mean Structural SIMilarity (MSSIM) index [47,48] and the clas-
sical Peak Signal-to-Noise Ratio (PSNR), which for a 3D image is deﬁned
as
PSNR ¼ 10 log10
 
ðImaxÞ2
MSE
!
;
MSE ¼ kI � IKk3D
Nx � Ny � Nz
;
where Imax is the maximum intensity range and IK the image approxi-
mation.
4.1. Example I
In this example we use the Kodak data set consisting of 24 true color
images shown in Fig. 2.
The approximations are realized in both domains by maintaining the
Fig. 2. Illustration of the Kodak data set consisting of 24 true color images, credit Rich Franzen [49]. The size of these images is 768 � 512 � 3, for most of them,
except for numbers 4, 9, 10, 17, 18 and 19, which are of size 512 � 768 � 3. (For interpretation of the references to color in this ﬁgure legend, the reader is referred to
the Web version of this article.)
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
6
same redundancy in the 2D and 3D dictionaries. For the independent
approximation of the 2D channels the partitions are realized with blocks
of size 8 � 8 and 16 � 16 (a partition of block size 24� 24 does not
improve results for this data set). Accordingly, the simultaneous
approximation of the 3 color channels involves partitions of block size
8 �8 � 3 and 16 �16 � 3 respectively.
As already discussed, for the independent approximation of the 2D
channels we consider the dictionaries D pd (in the pd) and D wd (in the
wd) as given in Sec. 3.4. For the simultaneous approximation of the 3
channels we consider the dictionaries ~D pd given in the same section.
Both dictionaries have redundancy of 125.
The average values of SR (SR), with respect to the 24 images in the
set, are given in Table 1 for the approaches and partitions indicated by
the ﬁrst column.
All the results in the left half of the table correspond to PSNR ¼ 45 dB
and all the results in the right half correspond to PSNR ¼ 41 dB. The third
and ﬁfth columns give the standard deviations (std). For completeness we
have also produced the SR rendered by nonlinear thresholding of the
wavelets coefﬁcients (last row in the table). Notice that the resulting
sparsity is poor in comparison with the other 2D results.
All the results were obtained in the MATLAB environment on a
notebook 2.9 GHz dual core i7 3520 M CPU and 4 GB of memory. For the
channel by channel approximation a Cþþ MEX ﬁle implementing
OMP2D was used. For the 3D approximation SPMP3D was implemented
by a Cþþ MEX ﬁle.
As observed in Table 1 the largest SR is achieved in the wd and
partition 16 �16 � 3 (c.f. last but one row of Table 1). However, the
results obtained by partition 8 �8 � 3 are very close (c.f. last row of the
upper half of Table 1) and constitute a better tradeoff between SR and
approximation time.
Fig. 3 shows the actual values of SRs for this partition in the wd for
each of the 24 images in the data set (c.f. Fig. 2). The average time for the
3D approximation was 53 s per image.
Fig. 4 demonstrates the gain in visual quality obtained when the
approximation of Images 3, 7 and 12 are realized simultaneously in 3D,
instead of independently for each 2D channel. In both cases the SR is
ﬁxed at a high value SR ¼ 63.5. While the 3D approximation is still of
good quality (c.f. images on the left in Fig. 4) the distortion of the channel
by channel approximation is very noticeable even at the scale of the
ﬁgure (c.f. images on the right in Fig. 4).
As a ﬁnal remark it is worth noting that the number kq of atoms in the
approximation of each block q of an image partition produces a mean-
ingful summary of local sparsity.
The upper graphs of Fig. 5 are a representation of the piecewise
sparsity corresponding to Image 22 in the Kodak data set. Both graphs are
arrays of 64 � 96 points. Each point corresponds to the number kq of
atoms in the approximation of a block q. The left graph corresponds to
block size 8 � 8 in the 2D approximation, by taking the average kq over
the three channels in the block, which is roughly the kq-value corre-
sponding to the equivalent block in the gray scale image. The right graph
corresponds to kq for each block of size 8 �8 � 3 in the 3D approxima-
tion. Both approximations are realized in the pd. The lower graph is the
image given as 3 channels of 512 � 768 pixels each. It follows from the
ﬁgure that the points corresponding to the 3D approximation give mode
details about the image.
4.2. Example II
We consider now the approximation of the hyper-spectral images
illustrated in Fig. 6. Details on the images acquisition and processing are
described in Refs. [50–52].
All four images are of size 1016 � 1336 � 32, and have been
approximated in partitions of block size Nb � Nb, with Nb ¼ 8; 16, and 24
for the 2D approximation, and 8 �8 � 8 for the 3D approximation. For
the 2D channel by channel approximation we use the dictionaries D pd
and D wd as deﬁned in Sec. 3.4. For the 3D approximation we maintain
the redundancy as in 2D using the dictionary ~D pd introduced Sec. 3.4
and ~D
a
wd ¼ ~D
a
pd.
Because the range of intensity varies across the images, in order to
compare SRs with different approaches we ﬁx the Signal to Noise Ratio
(SNR)
Table 1
Mean value of the SR, with respect to the 24 images in the set, obtained with the 2D and 3D approximations in both the pd and wd for two different sizes of the image
partition. The last row in the table gives the results corresponding to standard nonlinear thresholding of wavelet coefﬁcients, to achieve the same quality of the
approximation as with the dictionaries: PSNR ¼ 45dB (left half) and PSNR ¼ 41dB (right half).
PSNR
45 dB
41 dB
SR
std
SR
std
pd 2D 8 � 8
6.2
2.0
9.1
3.5
pd 3D 8 � 8 � 3
10.3
2.9
16.1
5.5
wd 2D 8 � 8
7.1
2.6
11.8
5.8
wd 3D 8 � 8 � 3
11.6
3.8
20.9
9.2
pd 2D 16 � 16
7.1
2.5
11.1
5.0
pd 3D 16 � 16 � 3
11.6
3.6
18.8
7.5
wd 2D 16 � 16
7.5
2.7
12.0
6.2
wd 3D 16 � 16 � 3
12.4
3.9
20.4
8.9
Thresholding in the wd
3.2
1.1
4.9
2.6
Fig. 3. SR for the 45 dB approximation, in the wd, of each of the 24 images in
the Kodak data set (c.f. Fig. 2 enumerated from top left to bottom right). The
results for the independent approximation of each 2D color channel are repre-
sented by the ﬁlled circles and those corresponding to the simultaneous
approximation of the 3 channels are represented by the ﬁlled squares. The
corresponding partitions are of size 8 � 8 and 8 � 8 � 3. (For interpretation of
the references to color in this ﬁgure legend, the reader is referred to the Web
version of this article.)
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
7
Fig. 4. Approximations of Images 3, 7 and 12 in the Kodak data set, for SR ¼ 63.5. The images on the left are the 3D approximations. The images on the right are the
2D channel by channel approximations.
Fig. 5. The upper graphs are a representation of the piecewise sparsity corresponding to Image 22 in the Kodak data set. Both graphs are arrays of 64� 96 points. Each
point corresponds to the number kq of atoms in the approximation of a block q. The left graph corresponds to the 2D approximation and the right graph to the 3D
approximation. The lower graph is the image given as 3 channels of 512 � 768 pixels each.
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
8
SNR ¼ 10 log10
 
kIk2
3D
kI � IKk
2
3D
!
:
(15)
Every block in the partition is approximated up to the same error.
With all the approaches, two global values of SNR (31 dB and 33 dB)
were considered. These values of SNR correspond to the values of PSNR
shown in Tables 2 and 3. In all of the cases the approximations are of
excellent visual quality.
The SRs produced by the 3D approximation are indicated by SR3D and
those produced by the 2D plane by plane approximation by SR2D. The
times for completing the approximations are given in the row right after
the corresponding sparsity result.
Remark 3.
In both Tables 2 and 3 the values of SR3D are signiﬁcantly
larger than the values of SR2D, except for the Col. image and 24 � 24
blocks. For this image we were able to increase the 3D block size up to
16 �16 � 16 and the results for SNR ¼ 31dB are SR3D ¼ 357 in the pd
and SR3D ¼ 892 in the wd (35 min and 10 min respectively). For SNR ¼
33 dB SR3D ¼ 247 in the pd and SR3D ¼ 590 in the wd (55 min and 20
min respectively).
Fig. 6. Illustration of the hyper-spectral images available on [53,54]. From top left to bottom right in Table 2 are labelled as Ribei., Graff., Rose, and Col. The of size of
all four images is 1016 �1336 � 32 pixels.
Table 3
Same description as in Table 2, but the approximations are realized by applying
ﬁrst a wavelet transform to each of the 32 channels.
Image
Ribei.
Graff.
Rose
Col.
SNR ¼ 31 dB
PSNR
46.8
48.2
47.8
46.7
SR2D Nb ¼ 8
28.6
26.8
38.6
56.5
Time (min)
1.4
1.5
1.2
0.8
SR2D Nb ¼ 16
36.5
34.1
63.4
144.8
Time (min)
2.7
3.5
2.3
0.9
SR2D Nb ¼ 24
37.2
35.7
71.1
193
Time (min)
9.2
12
4.8
1.8
SR3D Nb ¼ 8
86.5
108.0
182.2
371.7
Time (min)
13
10
6
3
SNR ¼ 33 dB
PSNR
48.8
50.2
49.9
48.7
SR2D Nb ¼ 8
22.6
21.8
33.0
56.1
Time (min)
1.7
1.8
1.5
1.0
SR2D Nb ¼ 16
26.6
25.8
48.2
118.3
Time (min)
3.5
5.0
2.3
1.1
SR2D Nb ¼ 24
21.9
26.8
52.0
144.0
Time (min)
12
15
8.5
1.9
SR3D Nb ¼ 8
55.1
70.5
129.5
313.3
Time (min)
23
18
10
1.8
Table 2
Values of SR for the approximation in the pixel-intensity domain of the images
listed in the ﬁrst row. SR2D indicates the SR for the plane by plane approximation
in partition of block side Nb ¼ 8; 16, and 24. SR3D corresponds to a partition in
3D blocks of size 8 � 8 � 8. The times for completing the approximations are
given immediately below the sparsity results in minutes.
Image
Ribei.
Graff.
Rose
Col.
SNR ¼ 31 dB
PSNR
46.8
48.2
47.8
46.7
SR2D Nb ¼ 8
19.2
19.2
24.1
47.7
Time (min)
1.6
1.6
1.3
0.9
SR2D Nb ¼
16
27.3
25.5
38.7
110.6
Time (min)
3.4
3.8
2.1
1.1
SR2D Nb ¼
24
29.6
26.8
44.2
147.5
Time (min)
7.6
9.2
4.5
1.5
SR3D Nb ¼ 8
49.1
59.7
74.6
137.2
Time (min)
18
15
10
6
SNR ¼ 33 dB
PSNR
48.8
50.2
49.8
48.7
SR2D Nb ¼ 8
15.2
15.4
19.3
41.5
Time (min)
2.3
2.1
1.7
1.1
SR2D Nb ¼
16
20.4
19.5
29.1
86.4
Time (min)
5.4
5.6
2.9
1.2
SR2D Nb ¼
24
21.9
20.5
32.7
106.3
Time (min)
12
14
6.8
1.9
SR3D Nb ¼ 8
33.5
41.6
53.2
106.5
Time (min)
25
21
16
8
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
9
On comparing the two tables a drastic improvement in the values of
SR3D is observed when the approximation is realized in the wavelet
domain. This feature is a consequence of the fact that the planes of the
natural images are very sparse in the wavelet domain. In order to high-
light differences we produce next the SR3D corresponding to the two
remote sensing images in Fig. 7. The graph on the left represents the
Urban remote sensing hyper-spectral image taken from Ref. [55]. The
graph on the right is a portion of the University of Pavia image also taken
from Ref. [55].
Fig. 8 plots the SR vs four values of SNR, corresponding to the 3D
approximations of the Urban and University of Pavia images in both the
pd and wd.
Notice that the results in the pd are much closer to the results in the
wd than they are in the case of the natural images in Fig. 6. This is
because, as illustrated in Fig. 9, the planes of the remote sensing images
are not as sparse in the wd as the planes of the natural images are.
5. Conclusions
High quality approximation of 3D images has been considered within
the context of data reduction. A remarkable improvement in sparsity
achieved by the simultaneous approximation of multiple channels has
been illustrated through numerical experiments of different natures.
Firstly it was demonstrated that a standard data set of RGB images can be
approximated at high quality using far fewer elementary components if
each image is treated as a very thin 3D array instead of as 3 independent
2D arrays. Secondly the full power of the approach was demonstrated
through the approximation of hyper-spectral images. For the hyper-
spectral natural images the sparsity is remarkably higher if the approx-
imation is realized in the wavelet domain. For the remote sensing images
the domain of approximation has less inﬂuence because, as opposed to
natural images, these images are not as sparse in the wavelet domain as
natural images are.
Taking into account the major reduction of dimensionality demon-
strated by the numerical examples in this work, we feel conﬁdent that the
proposed approach will be of assistance to the broad range of image
processing applications which rely on a transformation for data reduction
as a ﬁrst step of further processing.
Fig. 7. Illustration of two remote sensing hyper-spectral images taken from Ref. [55]. The graph on the left is the Urban image (size 320 �320 � 128 pixels). The
graph on the right is a portion of the University of Pavia image (256 �256 � 96 pixels).
Fig. 8. SR vs SNR values for the 3D approximation in both the pd and wd for the
Urban and University of Pavia remote sensing images.
Fig. 9. Absolute value of the wavelet transform of a plane in the Col. image (left graph) and in the University of Pavia image (right graph).
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
10
Declaration of Competing Interest
The authors declare no conﬂict of interest.
Acknowledgments
We are also indebted to P. Getreuer, for making available the wave-
letcdf97 MATLAB function that we have used for the transformation of
each single channel image to the wavelet domain.
References
[1] Wright J, Ma Yi, Mairal J, Sapiro G, Huang TS, Yan S. Sparse representation for
computer vision and pattern recognition. Proc of the IEEE 2010;98:1031–44.
[2] Elad M. Sparse and redundant representations: from theory to applications in signal
and image processing. Springer; 2010.
[3] Zhang Z, Xu Y, Yang J, Li X, Zhang D. A survey of sparse representation: algorithms
and applications. IEEE access; 2015.
[4] Mairal J, Eldar M, Sapiro G. Sparse representation for color image restoration. IEEE
Trans Image Process 2008;17:53–69.
[5] Dong W, Zhang L, Shi G, Li X. Nonlocally centralized sparse representation for
image restoration. IEEE Trans Image Process 2013;22:1620–30.
[6] Gou J, Hou B, Ou W, Mao Q, Yang H, Liu Y. Several robust extensions of
collaborative representation for image classiﬁcation. Neurocomputing 2018.
https://doi.org/10.1016/j.neucom.2018.06.089.
[7] Gou J, Yi Z, Zhang D, Zhan Y, Shen X, Du L. Sparsity and geometry preserving graph
embedding for dimensionality reduction. IEEE Access 2018;6:75748–66. 10.1109/
ACCESS.2018.2884027.
[8] Gou J, Wang L, Yi Z, Lv J, Mao Q, Yuan Y-H. A new discriminative collaborative
neighbor representation method for robust face recognition. IEEE Access 2018;6:
74713–27. https://doi.org/10.1109/ACCESS.2018.2883527. 2018.
[9] Wright J, Yang AY, Ganesh A. Robust face recognition via sparse representation.
IEEE Trans Pattern Anal Mach Intell 2009;31:210–27.
[10] Yuan XT, Liu X, Yan S. Visual classiﬁcation with multitask joint sparse
representation. IEEE Trans Image Process 2012;21:4349–60.
[11] Yang J, Wright J, Huang T. Image super-resolution via sparse representation. IEEE
Trans Image Process 2010;19:2861–73.
[12] Zhang Y, Liu J, Yang W, Guo Z. Image super-resolution based on structure-
modulated sparse representation. IEEE Trans Image Process 2015;9:2797–810.
[13] Dabov K, Foi A, Katkovnik V. Image denoising by sparse 3-D transform-domain
collaborative ﬁltering. IEEE Trans Image Process 2007;16:2080–95.
[14] Caiafa CF, Cichocki A. Computing sparse representations of multidimensional
signals Using Kronecker Bases. Neural Comput 2013;25:186–220.
[15] Cichocki A, Mandic D, De Lathauweri L, Zhou G, Zhao Q, Caiafai C, Phan HA.
Tensor decompositions for signal processing applications: from two-way to
multiway component analysis. IEEE Signal Process Mag 2015;32:145–63.
[16] Dai Q, Yoo S, Kappeler A. Sparse representation-based multiple frame video super-
resolution”. IEEE Trans Image Process 2017;26:2080–95.
[17] Mousavi HS, Monga V. Sparsity-based color image super resolution via exploiting
cross channel constraints. IEEE Trans Image Process 2017;26:5094–106.
[18] Rebollo-Neira L, Bowley J. Sparse representation of astronomical images. J Opt Soc
Am 2013;30:758–68.
[19] Donoho DL, Tsaig Y, Drori I, Starck J. Stagewise orthogonal matching pursuit. IEEE
Trans Inf Theory 2006;58:1094–121.
[20] Needell D, Tropp JA. CoSaMP: Iterative signal recovery from incomplete and
inaccurate samples”. Appl Comput Harmon Anal 2009;26:301–21.
[21] Eldar Y, Kuppinger P, Bi€olcskei H. Block-sparse signals: uncertainty relations and
efﬁcient recovery. IEEE Trans Signal Process 2010;58:3042–54.
[22] Rebollo-Neira L, Matiol R, Bibi S. Hierarchized block wise image approximation by
greedy pursuit strategies. IEEE Signal Process Lett 2013;20:1175–8.
[23] L. Rebollo-Neira, http://www.nonlinear-approx.info/examples/node09.html (Last
access April 2019)..
[24] Tao JianWen, Wen Shiting, Hu Wenjun. Robust domain adaptation image
classiﬁcation via sparse and low rank representation. J Vis Commun Image
Represent 2015;33:134–48.
[25] Nie Wei-Zhi, Liu An-An, Su Yu-Ting. 3D object retrieval based on sparse coding in
weak supervision. J Vis Commun Image Represent 2016;37:40–5.
[26] Gao Z, Li SH, Zhu YJ, Wang C, Zhang H. Collaborative sparse representation leaning
model for RGBD action recognition. J Vis Commun Image Represent 2017;48:
442–52.
[27] Zhang Youqiang, Guo Cao, Li Xuesong, Wang Bisheng. Cascaded random forest for
hyperspectral image classiﬁcation. IEEE JSelect Top Appl Earth Observ Remote Sens
2018;11:1082–94.
[28] Li Guiji, Peng Manman, Ke Nai, Li Zhiyong, Li Keqin. Visual tracking via context-
aware local sparse appearance model. J Vis Commun Image Represent 2018;56:
92–105.
[29] Mallat S, Zhang Z. Matching pursuit with time-frequency dictionaries. IEEE Trans
Signal Process 1993;41(12):3397–415.
[30] Pati YC, Rezaiifar R, Krishnaprasad PS. Orthogonal matching pursuit: recursive
function approximation with applications to wavelet decomposition,” Proc. of the
27th ACSSC, vol. 1; 1993. p. 40–4.
[31] Rebollo-Neira L, Lowe D. Optimized orthogonal matching pursuit approach. IEEE
Signal Process Lett 2002;9:137–40.
[32] Rebollo-Neira L, Bowley J, Constantinides A, Plastino A. Self contained encrypted
image folding. Physica A 2012;391:5858–70.
[33] Rebollo-Neira L. Effective sparse representation of X-Ray medical images. Int J Num
Method Biomed Eng 2017. https://doi.org/10.1002/cnm.2886.
[34] Rebollo-Neira L, Rozlo�zník M, Sasmal P. Analysis of a low memory implementation
of the Orthogonal Matching Pursuit greedy strategy. http://arxiv.org/abs/1
609.00053; 2017.
[35] Kreutz-Delgado K, Murray JF, Rao BD, Engan K, Lee Te-Won, Sejnowski TJ.
Dictionary learning algorithms for sparse representation. Neurocomputing 2003;15:
349–96.
[36] Aharon M, Elad M, Bruckstein A. K-SVD: an algorithm for designing overcomplete
dictionaries for sparse representation. IEEE Trans Signal Process 2006;54:4311–22.
[37] Rubinstein R, Zibulevsky M, Elad M. Double sparsity: learning sparse dictionaries
for sparse signal approximation. IEEE Trans Signal Process 2010;58:1553–64.
[38] Tosi�c I, Frossard P. Dictionary Learning: what is the right representation for my
signal? IEEE Signal Process Mag 2011;28:27–38.
[39] Zepeda J, Guillemot C, Kijak E. Image compression using sparse representations and
the iteration-tuned and aligned dictionary. IEEE J Select Top Signal Process 2011;5:
1061–73.
[40] Hawe S, Seibert M, Kleinsteuber M. Separable dictionary learning. In: Proceedings
of the 2013 IEEE conference on computer vision and pattern recognition; 2013.
p. 438–45.
[41] Srinivas M, Naidu RR, Sastry CS, Krishna Mohana C. Content based medical image
retrieval using dictionary learning. Neurocomputing 2015;168:880–95.
[42] Wen B, Ravishankar S, Bresler Y. Structured overcomplete sparsifying transform
learning with convergence guarantees and applications. Int J Comput Vis 2015;114:
137–67.
[43] Rebollo-Neira L. A competitive scheme for storing sparse representation of X-Ray
medical images. PLoS One 2018. https://doi.org/10.1371/journal.pone.0201455.
[44] Cohen A, Daubechies I, Feauveau JC. Biorthogonal bases of compactly supported
wavelets. Commun Pure Appl Math 1992;45:485–560.
[45] Andrle M, Rebollo-Neira L. Cardinal B-spline dictionaries on a compact interval.
Appl Comput Harmon Anal 2005;18:336–46.
[46] Rebollo-Neira L, Xu Z. Adaptive non-uniform B-spline dictionaries on a compact
interval. Signal Process 2010;90:2308–13.
[47] Wang Z, Bovik AC, Sheikh HR, Simoncelli EP. Image quality assessment: from error
visibility to structural similarity. IEEE Trans Image Process 2004;13:600–12.
[48] I. Kowalik-Urbaniak, D. Brunet, J. Wang, D. Koff, N. Smolarski-Koff, E. Vrscay, B.
Wallace, and Z. Wang, “The quest for ‘diagnostically lossless’ medical image
compression: a comparative study of objective quality metrics for compressed
medical images”, Proc. SPIE 9037, Medical Imaging 2014: Image Perception,
Observer Performance, and Technology Assessment, 903717 (March 11, 2014); doi:
10.1117/12.2043196.
[49] R. Franzen, http://r0k.us/graphics/kodak/(Last access April 2019)..
[50] Foster DH, Nascimento SMC, Amano K. Information limits on neural identiﬁcation
of colored surfaces in natural scenes. Vis Neurosci 2004;21:331–6.
[51] Foster DH, Amano K, Nascimento SMC, Foster MJ. Frequency of metamerism in
natural scenes. J Opt Soc Am 2006;23:2359–72.
[52] Nascimento SMC, Amano K, Forster D. Spatial distributions of local illumination
color in natural scenes. Vis Res 2016;120:39–44.
[53] D. H. Foster, https://personalpages.manchester.ac.uk/staff/d.h.foster/Hyperspectra
l_images_of_natural_scenes_04.html (Last access April 2019)..
[54] D. H. Foster, http://personalpages.manchester.ac.uk/staff/d.h.foster/Local_Ill
umination_HSIs/Local_Illumination_HSIs_2015.html (Last access April 2019)..
[55] http://lesun.weebly.com/hyperspectral-data-set.html (Last access April 2019)..
L. Rebollo-Neira, D. Whitehouse
Array 1-2 (2019) 100001
11
