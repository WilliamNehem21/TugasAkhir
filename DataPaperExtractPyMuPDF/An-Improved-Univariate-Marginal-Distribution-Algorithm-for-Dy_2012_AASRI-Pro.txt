 AASRI Procedia  1 ( 2012 )  166 – 170 
2212-6716 © 2012 Published by Elsevier Ltd. 
doi: 10.1016/j.aasri.2012.06.026 
 
 
2012 AASRI Conference on Computational Intelligence and Bioinformatics 
An Improved univariate Marginal Distribution Algorithm for 
Dynamic Optimization Problem 
Wu Yana*, Liu Xiaoxiongb 
a Department of Mathematics, Xidian University, Xi’an 710071, China 
bSchool of Automation Northwestern Polytechnical University, Xi’an 710072, China 
 
Abstract 
In dynamic environments, it is difficult to track a changing optimal solution over time. An improved univariate marginal 
distribution algorithm (IUMDA) is proposed to deal with dynamic optimization problems. This approach is composed of 
the diffusion model, which uses the information of current population, and the inertia model, which uses the part history 
information of the optimal solution. After an environment changed, the strategy is changed by a detecting operator to 
guide increasing the population diversity. Finally an experimental study on dynamic sphere function was carried out to 
compare the performance of IUMDA and mutation UMDA. The experimental results show that the IUMDA is effective 
for the function with moving optimum and can adapt the dynamic environments rapidly. 
 
© 2012 Published by Elsevier B.V. 
Selection and/or peer review under responsibility of American Applied Science Research Institute 
 
Keywords: Evolutionary algorithm, Univariate marginal distribution algorithm (UMDA), Dynamic optimization problems, diversity of 
population 
1.Introduce 
Although most of the optimization problems discussed in the scientific literature is static, many real-word 
problems are dynamic, such as uncertainty dynamic control systems, material processed. In these dynamic 
optimization problems, the evaluation function (or fitness function) and the constraints may change over time. 
 
* Corresponding author. Tel.: +86-029-88431398; fax: +0-000-000-0000 . 
E-mail address: yanerch@163.com. 
AASRI
Procedia
www.elsevier.com/locate/procedia
Available online at www.sciencedirect.com
Open access under CC BY-NC-ND license.
Open access under CC BY-NC-ND license.
167
 Wu Yan and Liu Xiaoxiong /  AASRI Procedia  1 ( 2012 )  166 – 170 
 
In such cases the optimization algorithm has to track a moving optimum as closely as possible, rather than just 
finds a single good solution.  
It has been argued that evolutionary algorithms (EAs) may be a particularly suitable candidate for this type 
of problems. However EAs need to be adapted for optimal results on dynamic optimization problems. When 
the changes occur, the solution given by the optimization procedure may be no longer effective and may 
actually be misguiding the search. In order to overcome the problems mentioned above, many methods have 
been proposed [1-8]. Considered above mentions, a new univariate marginal distribution algorithm (IUMDA) 
is proposed to solve dynamic optimization problems in this paper. 
2.Improved Optimization Algorithm 
Considered the dynamic multi-objective optimization is as followings: 
1
2
min
( , )
(
( , ),
( , ),
,
( , ))
[ , ]
M
f x t
f x t
f
x t
f
x t
subject to x
L V
�
�
�
                                                                                  (1) 
Where t  is time variable, x  is decision variable, [ , ]
L V  is search space, 
( , )
f x t  is objective which has 
the continuous objective function of M and changes with time.  
About this problem, the designed aim is that the algorithm must track a changing optimal solution over 
time when environments are changed. So we must use intelligence optimization algorithm to solve this 
problems. As the tradition evolutionary algorithms, the continue version of univariate marginal distribution 
algorithm (UMDA) is one sort of Estimation of Distribution Algorithms and has been applied to many 
optimization problems [6-7]. 
In the static environments, the optimal solution 
*( )
x t of the current population is usually acted as an 
attractor, which attracts the other individuals move towards the attractor to find the promising region of the 
optimum. However in the dynamic environments, when the problem changes at the end of generationt , the 
next optimal solution may move away from
*( )
x t . In order to find the new optimal solution, the algorithm 
needs increase the diversity and search new space which is different from the region presented by current 
population. That is to say the promising region of optimum is away from
*( )
x t . If the environment changes at 
the end of generation t  corresponding to the k -th change, the optimal solution of the current population is 
denoted by 
*( )
x t �
*( )
x t is the optimal solution of generation t �, it is applied with the following formula 
to generate new individual
xnew
.  
*
1(
( ))
xnew
x
x
x t
�
�
�
�
                                                                                                                        (2) 
Where 
1�  is random number from [0, 1]. According to the diffusion model, if the environment changes at 
the end of generationt , then 
*( )
x t  can be considered as a repeller rather than an attractor. The reppeller 
guides the algorithm to search space away from the repeller and to increase the diversity of the population 
using the current information.  
After the environment changed, it will be effective for dynamic optimization to predict the new optimal 
position by previous optimal solution. Assume that the environment changes at the end of generation t  
corresponding to the k -th change, the optimal solution of the current population is
*( )
x t , and then 
*
*
( )
(
1)
x t
� x t
�
 which called velocity of optimal solution at change period
k �1
 is used as the inertia 
velocity at change period k to predict the next optimal solution. The model is denoted in the following. 
168  
 Wu Yan and Liu Xiaoxiong /  AASRI Procedia  1 ( 2012 )  166 – 170 
 
*
*
2(
( )
(
1))
xnew
x
x t
x t
�
�
�
�
�
                                                                                                (3)  
Where x
�U
(U is the set of selected individuals),
2
�  is a random number from [0, 1], which denotes the 
step size to move in direction of (
v k �1)
. From this model, if the prediction is correct, the prediction set aids 
the population to discover the new optimal solution quickly. In order to detect the environment changed 
automatically, a detecting operator is proposed as follows: 
1
1,
,
(
, )
(
,
1)
( )
max
(
, )
(
,
1)
sn
i
i
i
i
i
i
sn
f x
f x
sn
f x
f x
�
�
� �
�
�
�
�
�
�
�
�
�
�
�
                                                                                    (4) 
Where 
ix  is individual 
1,2,
i
sn
�
�
� which is choose 10% of the colony dimension. When the 
( )
� �
��
 (�  is a threshold), the environment is changed. Then by using the inertia prediction the algorithm 
convergence is increased. 
Based on the consideration above, the improved approach makes useful of the current information and part 
history information, and guide the population to search the promising region. Then an improved UMDA 
(IUMDA) is presented by incorporating UMDA with this approach. The following is the improved algorithm: 
Step1. 
t � 0
�for everyone variable, obtain randomly the parameters of a normal probability distribution 
for each variable. 
Step2. Draw
t
X to obtain a population 
( )
Pop t  of N  individuals; 
Step3. Test for change. Calculate ( )
� � , if the environment no changes, then turn to step 4, otherwise turn 
to step 6; 
Step4. Generate M  neighbor individuals of 
*( )
x t to form the neighbor set U , where the neighbor 
distance is controlled in [0.05. 0.15]; 
Step5. Apply the formula (2), an individual will be adjusted the new population; 
Step6. Apply the formula (2) and formula (3) on U  and get one set of D ; 
Step7. Estimate the parameters of the new density functions according to ( )
S t . 
Step8. Mutate 
it 1
� � according to mutation probability; 
Step9. If the termination is not satisfied,
1
t
t
� �
 go to step 2, otherwise, stop. 
3.Experimental Study 
In order to test the performance of the proposed algorithm, we used the dynamic sphere function with three 
dimensions [8]. The function is formulated as: 
2
2
2
1
2
3
( , , , )
(
( ))
(
( ))
(
( ))
k
k
k
f x y z t
x
t
y
t
z
t
�
�
�
�
�
�
�
�
�
                                                             (5) 
Where ( , , )
x y z
is a time-invariant “basis” landscape. 
1
2
3
(
( ),
( ),
( ))
k
k
k
t
t
t
�
�
�
are the global optimal 
solution, which is a time-varying parameter, and moves randomly or period in different trajectories to 
construct dynamic function. In the above dynamic function, suppose that the environment is periodically 
changed every �  generation, and then 
/
k
� �t �
�
�
� is the change period index, where t  is the generation 
counter. According to the different type along which optimal point moves, we can get three different dynamic 
test functions. 
169
 Wu Yan and Liu Xiaoxiong /  AASRI Procedia  1 ( 2012 )  166 – 170 
 
In the dynamic random type, the optimal location is calculated as follows: 
        
1
(0,1)
k
k
m
m
sN
�
�
�
�
�
�
m �1,2,3
�
0
0
�m
�
                                                                     (6) 
Where 
N(0,1)
 is a Gaussian random variable with mean 0 and variance 1. Here the severity parameter 
determines the variance of the noise added to the previous optimal solution.  In this paper, the search space is 
set to 
( 50.0,50.0)3
�
and T is set to 25. In linear type, when the global optimal location moves past the 
search space, then the location moves in contrary direction by primary change severity. 
Experiments were carried out to compare the performance of the IUMDA and MUMDA on the test 
environments constructed above. MUMDA is hyper mutation based UMDA, in which hyper mutation is 
selected to increase the diversity when the problem is changed. In order to compare performance of different 
algorithms, the total population size N is fixed at 40 individuals. The other parameters are set to
� � 0.5
, 
r � 0.2
.  
The experimental results on test functions with different dynamic type are plotted in Fig 1 and summarized 
in Table 1. 
 
(a)  The IUMDA results                                            (b) The MUMDA results 
Fig.1. Experimental results on random linear type of dynamic functions. 
Table 1 Offline error � standard error for different change severities on random type 
 
Algorithms 
Shift severity s  and change period �  
s =0.1, � =1       s =1.0, � =5       s =5.0, � =10 
IUMDA 
0.0161 � 0.0799 
0.1190 � 0.0500 
1.3317 � 1.2206 
MUMDA 
0.2437 � 0.8173 
0.5768 � 0.2119 
12.6367 � 7.5438 
 
Figure 1 show the results of average optimum which plotted against generation. In each figure, three 
dynamic environments are tested by three algorithms. The environmental dynamics parameters are set to 
s =0.1, � =1; s =1.0, � =5 and s =5.0, � =10 respectively. 
170  
 Wu Yan and Liu Xiaoxiong /  AASRI Procedia  1 ( 2012 )  166 – 170 
 
From these figures, it can be seen that, generally, IUMDA outperforms MUMDA in the same environment. 
One straight forward approach to make EAs more suitable for dynamic environments is to increase the 
diversity after a change. However the random immigrant and hyper mutation approaches increase the 
diversity by generating the new individuals in the whole search space. Although these two approaches 
increase the diversity, the diversity is too dispersive to concentrate the promising region of optimum. Thus the 
computation time needed to track the optimum will be delayed. So in same environment the average optimum 
of MUMDA is worse than IUMDA. In such cases the improved algorithms has positive effect on the proposed 
algorithm to adapt the changed environment. 
4.Summary 
In dynamic environments, it is important that the optimization algorithm is able to continuously track the 
moving optimum over time. In this paper, we proposed a new approach algorithm to tackle dynamic 
environments. The objective of the approach is to increase the diversity in a guide fashion after a change. In a 
dynamic environment, it will be effective to predict the new optimal position by previous optimal solution.  
In this paper, because of considering a new strategy for dynamic optimal problems, the proposed method 
only fits for Dynamic test function, and is good than other MUMDA faintly. To get better optimum results in 
dynamic environments, the algorithm is to improve in future yet. 
Acknowledgements 
This work is supported by the National Natural Science foundation of China (No.61105065). This work is 
supported by the Aeronautical Science Foundation of China (No. 20100753009). 
References 
[1] Blackwell, T. M., Branke, J., Multiswarms, Exclusion, and anti-convergence in dynamic environments, 
IEEE Transactions on Evolutionary Computation, 2006, 10 (4):459-472 
[2] Yaochu, J., Branke, J., Evolutionary optimization in uncertain environments-a survey, IEEE  transactions 
on evolutionary computations, 2005, 9(3):1-15 
[3] Yang, S., Memory-Enhanced Univariate Marginal Distribution Algorithms for Dynamic Optimization 
Problems, The IEEE Congress on Evolutionary Computation, 2005, Vol.1:2560-2567 
[4] Yang, S., Yao, X., Experimental study on population-based incremental learning algorithms for dynamic 
optimization problems. Soft Comput, 2005, Vol.9:815-834 
[5] Hatzakis, I., Wallace, D., Dynamic multi-objective optimization with evolutionary algorithms: a forward-
looking approach, Genetic And Evolutionary Computation Conference, Proceedings of the 8th annual 
conference. Seattle, Washington, USA, 2006, Vol.2:1201-1208  
[6] Mühlenbein, H., Zinchenko, L., Kureichik, V. and Mahnig, T., Effective Mutation Rate for Probabilistic 
Models in Evolutionary Analog Circuit Design, Proceedings of the IEEE International Conference on 
Artificial Intelligence Systems, 2002, Vol.3:401-406 
[7] Tang, M., Raymond Y. K. Lau,  A Hybrid Estimation of Distribution Algorithm for the Minimal 
Switching Graph Problem, Proceedings of the International Conference on computational Intelligence for 
Modelling, Control and Automation, and International Conference on Intelligent Agents, Web Technologies 
and Internet Commerce, 2005, Vol.1:708-713   
[8] Angeline, P. J., Tracking, Extrema in Dynamic Environments, Proceedings of the 6th Int Conference on 
Evolutionary Programming, 1997, Vol.3:335-345  
