 AASRI Procedia  1 ( 2012 )  486 – 491 
2212-6716 © 2012 Published by Elsevier Ltd. 
doi: 10.1016/j.aasri.2012.06.076 
2012 AASRI Conference on Computational Intelligence and Bioinformatics  
Unstructured Road Edge Detection and Initial Positioning 
Approach based on Monocular Vision 
Yunpeng Zhaoa*, Hong Wanga,Runchen Yana
aState Key Laboratory of Intelligent Technology and Systems 
     Tsinghua National Laboratory for Information Science and Technology 
Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China 
Abstract 
This paper proposes two complementary road edge detection methods for unstructured roads. The methods can be used for 
visual navigation and intelligent control of mobile robots. One method is color-based, which is applicable to the 
circumstance that the road and off-road areas have obvious color difference; the other is based on threshold segmentation 
and can be applied even the road boundary is not clear. On the other hand, shadow has enormous impact on threshold 
segmentation method, but color-based method is not sensitive to it. These make the two methods complementary. 
Furthermore, on the basis of edge detection, inverse perspective projection transformation is carried out to calculate 
running state of the robots. Through experiments on mobile robot platform, verifications that the two proposed methods 
complement each other in different road environments well are made. The experiments also show that the methods 
achieve high accuracy in initial positioning and meet requirement of real-time. 
2012 Published by Elsevier B.V. Selection and/or peer review under responsibility of American Applied 
Science Research Institute 
Keywords: road recognition, road edge detection, unstructured road
* Corresponding author. Tel.: +86-13488661432. 
E-mail address: zyp1245@163.com. 
AASRI
Procedia
www.elsevier.com/locate/procedia
Available online at www.sciencedirect.com
Open access under CC BY-NC-ND license.
Open access under CC BY-NC-ND license.
487
 Yunpeng Zhao et al. /  AASRI Procedia  1 ( 2012 )  486 – 491 
1. Introduction 
Road recognition for intelligent vehicles and mobile robots is a hot research topic in computer vision. 
Existing road recognition researches focus on structured road with road lane. The researches for unstructured 
road are far from enough. 
There are three main categories in unstructured road recognition, feature-based methods, model-based 
methods and machine learning based methods. Commonly used features in feature -based include color, 
texture and edge[1][2]. This category is vulnerable to water stain, shadow and lighting condition. Model-based 
methods[3][4] establish the mathematical model for road boundary, and calculate related parameters in the 
model to get the boundary. However, it is difficult for methods in this category to establish proper general 
model for all the forms of road. Machine learning based methods[5] train the detection system to automatically 
collect and accumulate road features in the video image, so that detections become more and more stable and 
reliable. However, the actual process to collect a large number of training samples requires tremendous time. 
To meet the challenge, lack of generality, in unstructured road detection, this paper proposes two 
complementary road edge detection methods for unstructured roads. One method is color-based, which is 
applicable to the circumstance that the road and off-road areas have obvious color difference and is not 
sensitive to shadow. The other is based on threshold segmentation and is suitable to be applied in the road 
where boundary is not clear, but shadow has enormous impact on it. By combining these two methods, 
generality in unstructured road detection can be achieved. The proposed methods only detect one side of the 
road edge, reducing the requirement of field view, installation angle of camera. Once the edge of the road is 
detected, positioning of the robot relative to the edges of the road is calculated, inverse perspective projection 
transformation. It provides good support for navigation and control of robots. 
The rest of the paper is organized as following. Section 2 introduces the proposed two methods for road 
edge detection. Section 3 elaborates initial positioning based on road edge detection. Section 4 gives out 
experiments. And finally Section 5 concludes the work and points our future works. 
2. Road Edge Detection Methods 
2.1. Color-based Method 
Color-based method uses both color feature and edge feature, as individual feature based detection suffers 
affect from shadow. Colors on both sides of the road edge are usually very different, and the image gradient 
of road edge is generally very large. We look for colors of road area and non-road area around points with 
greater gradient, further to determine whether the points are road edge candidates. 
The method is illustrated in the environment where the non-road area is green belt, and the right edge of 
the read is detection target, as a case. First canny edge extraction is done on the grayscale of the original 
image, and we denote it C. Then the original image is transformed into HSV space and recorded as M.  
Binary image of M can be got using following formula for each point in M. White points in the binary 
image denote green points, and black points denote non-white points. f(x) is the pixel gray value. H and S are 
the H and S components of original pixel. 50-100 and 0-40 are H and S range interval for green pixel. 
There will be some scattered interference point in binary image got from this procedure. We etching and 
inflate the binary image to remove small interference point. The etching and inflated image is denoted as N. 
Once C and N are got, the following steps are taken to get road edge candidate points. 
�
�
�
�
f
=255,
50<
110,0<
40
                            (1)
f
=0,else
X
if
H
S
X
�
�
���
��
488  
 Yunpeng Zhao et al. /  AASRI Procedia  1 ( 2012 )  486 – 491 
1)
Scan C from bottom to top, from left to right. When white point is scanned, record the positioning of 
the point x and go to step 2); 
2)
Scan around point x in N. If the left small area is full of black points, and the right small area contains 
white point, go to step 3);otherwise go to step 1); 
3)
Add point x into road edge candidate points. 
Assume that the total number of candidate edge points is t; the number of points in C is p. If t and p satisfy 
the following formulas, it means that there may be no shadow on the road and the edge of the road is not clear. 
Then the current method should be stopped by switching to threshold segmentation based method. Otherwise, 
the method continues to fit the road edge line using road edge candidate points. 
Even in road edge candidate points, there are still a lot of noise points. RANSAC[6] is used to reduce errors, 
by using it fitting a straight line is carried out twice to remove point with particularly large error. 
2.2. Threshold Segmentation Based Method 
This method is an extension of Otsu[7]’s maximum between-class variance method. It clusters the pixels 
adaptively according to grayscale image, so that dynamic threshold segmentation can be achieved. 
The method divides the image pixels into two categories C0 and C1 according to threshold t, in order to 
maximize between-class variance of C0 and C1.The method is based on the fact that pixels belong to the same 
area should have smaller between-class variance, and between-class variance of different areas should be 
maximal. 
Assume image grayscale range is {0,1,…,l-1}, there is ni pixel with grayscale i. The total number of pixel 
is                                  , so the probability a pixel with grayscale i appear is: 
Select threshold t to divide the pixels into two categories, the target and the background (that is, we want to 
split the road area and non-road area): C0={0,1,…,t}; C1={t+1,t+2,…,l-1}.The probability C0 and C1 appears 
is:
Their average grayscale is: 
Total average grayscale is: 
Between-class variance of C0 and C1 is: 
Inner-class variance is: 
Total variance is: 
                                                                                                                                               ����
l-1
1
=0
p =
 , p
0, 
p =1                                                            (2)
i
i
i
i
n
N
�
�
l-1
=0
=
i
i
N
n
�
� �
� �
-1
0
1
=0
= +1
P
=
   P
=
P                                                           (3)
t
l
i
i
i
i t
t
P
t
�
�
� �
� �
� �
� �
-1
0
0
1
1
1
=0
= +1
t =
    
=
P
                                  (4)
t
l
i
i
i t
ip
P t
t
iP
t
�
�
�
�
-1
=0
                                                                        (5)
l
T
i
i
iP
� ��
� �
� �
� �
� �
� �
2
2
2
0
0
1
1
=
-
+
-
                                             (6)
B
T
T
O
t
P t
t
P t
t
�
�
�
�
�
�
�
�
�
�
�
�
� �
� �
�
�
� �
� �
�
�
� �
-1
2
2
2
1
1
0
0
1
1
=0
= +1
0
1
=
-
+
-
      (7)
t
l
W
i
i t
P
P
O
t
P t
i
P t
i
P t
P t
�
�
�
�
�
�
�
�
�
�
�
�
�
�
�
�
�
�
2
2
2
T
B
W
O
O
O
�
�
489
 Yunpeng Zhao et al. /  AASRI Procedia  1 ( 2012 )  486 – 491 
As
 is based on second-order statistical properties, �
 is based on first-order statistical properties. 
And 
 has nothing to do with t. Simple decision guideline can be introduced: 
                                                                                                                                                                  ����
This guideline will enable dynamic 
 that best separate two categories be the threshold, and thus
 is set 
the maximum criteria: 
We convert the image into grayscale image and traversal through each pixel. According to maximum 
criteria of Between-class variance, optimal threshold t can be got. Transform the image into binary image 
using the optimal threshold, and then canny edge extraction is done. Scan from left to right (if it is right edge 
detection) to get the first white pixels, and the road edge can be got by conducting Hough transform upon 
these pixels. 
3. Initial Positioning 
When robot is traveling, lateral displacement between the robot and the edge of the road and driving angle 
deviation should be calculated continuously. 
Inverse perspective projection transforms the detection result, to form a top view. Lateral displacement is 
the vertical distance between the robot center and the edge, and driving angle deviation is the angel between 
the direction the robot is travelling and the direction of the edge. 
Assume the position of the robot is B in Fig 1, the center solid line (ABC) is the direction the robot is 
travelling, and dashed line (DE) is the extension of edge. The driving angle deviation  is the angel between 
the center solid line and the dashed line. The length of BD is lateral displacement. And it does not matter 
whether they are positive or negative. 
                
Fig. 1. Driving angle deviation and lateral displacement calculation  
can be calculated as follow. Coordinates for each pixel in the edge line can be got in former detection 
algorithm. Multiplied by the inverse perspective projection transformation matrix H, coordinates for each 
pixel in the straight line DE can be got. Using the coordinates for the two pixels, the slope of the line can be 
calculated. Then we can get
. If the x coordinate of the two pixels are the same,
is 0�.
� �
2
2
=
B
T
t
�
�
�
� �
� �
*
max0< < -1
= max
                                                (10)
t l
t
t
�
�
490  
 Yunpeng Zhao et al. /  AASRI Procedia  1 ( 2012 )  486 – 491 
Lateral displacement (BD) can be calculated as follow. Calculate the coordinates of A, and assume the y 
coordinate of A is h. Assume actual distance between robot center and the image bottom (BC) is d (mm), 
transform to pixel distance
, where 
(mm) is actual length of a pixel. Lateral displacement (BD) 
is
, where height is image height in pixels, which is also C’ y coordinate. 
4. Experiments 
Experiments are carried out in Mobilerobots’ Pioneer 3-AT robot platform. The robot possesses 2.3GHz 
dual core processors, 1 G memory and Windows XP sp2 operating system. The development environment is 
Visual Studio C++ 2005, involving OPENCV open source library for image processing.  
As shown in Fig. 2, in the circumstance where the road and off-road areas have obvious color difference 
and there is shadow, color-based method achieve better results and will be used. 
      
Fig. 2. (a) actual road; (b) canny edge image; (c) binary image of the green area; (d) candidate edge points and detection result 
As shown in Fig. 3, when the road boundary is not clear, the method based on threshold segmentation will 
be used. 
Fig. 3. (a)color-based method doesn’t work ; (b) binary image of threshold segmentation; (c) canny image; (d) detection result 
It can be seen that the two methods complement each other well. 
Fig. 4 is the image for calculating lateral displacement and travel angle. Experiences validate the initial 
positioning achieve high accuracy (± 4 °, ± 100mm actually). 
               
Fig. 4. top view of the detection result 
The methods also meet the requirements of real-time, as shown in the table 1: 
Table 1. Running time for each step 
Step 
Time(ms)
491
 Yunpeng Zhao et al. /  AASRI Procedia  1 ( 2012 )  486 – 491 
Color-based method 
78 
Threshold segmentation based mothod 
94 
Initial positioning 
31 
5. Conclusion and Future work 
This paper proposes two complementary road edge detection methods for unstructured road. One method is 
color-based, which is applicable to the circumstance that the road and off-road areas have obvious color 
difference and is not sensitive to shadow. The other is based on threshold segmentation and is suitable to be 
applied in the road where boundary is not clear, but shadow has enormous impact on it. By combining these 
two methods, generality in unstructured road detection can be achieved. When the road edge is got, 
positioning of the robot relative to the edges of the road is calculated, inverse perspective projection 
transformation. Experiments show that the two methods achieve high accuracy in initial positioning and lays 
foundation for navigation and control. 
In the future, tracking algorithm can be added to further improve stability and reliability for real-time; sign 
detection can be used together with these two methods to achieve autonomous mobile robot traveling on the 
road. 
References 
 [1] He Yinghua, Wang Hong, Zhang Bo. Color-based road detection inurban traffic scenes. IEEE 
Transactions on Intelligent Transportation Systems, 2004,5 (4) : 309-318. 
[2] Wang Jian, Ji Zhong, Su Yuting. Unstructured road detection using hybrid features .International 
Conference on Machine Learning and Cybernetics, Baoding, China, 2009: 482-486. 
[3] Chen Long, Li Qingquan, Mao Qingzhou, et al. Block-constraint line scanning method for lane detection. 
2010 IEEE Intelligent Vehicles Symposium, San Diego, USA, 2010: 89-93. 
[4] Mohamed A. Real time detection of lane markers in urban streets. IEEE Intelligent Vehicles Symposium, 
Eindhoven, IEEE, 2008: 7-12�
[5] Foedisch M, Takeuchi A. Adaptive real-time road detection using neural networks. Proceedings of the 7th 
International IEEE Conference on Intelligent Transportation Systems, 2004: 167-172. 
[6] Fischler, M.A. and Bolles, R.C. Random Sample Consensus. A Paradigm for Model Fitting with 
Applications to Image Analysis and Automated Cartography. Communications of the ACM, 1981, 24(6): 
381–395,. 
[7] Nobuyuki Otsu . A threshold selection method from gray-level histograms. IEEE Trans. Sys., Man., Cyber. 
1979, 9 (1): 62–66. 
