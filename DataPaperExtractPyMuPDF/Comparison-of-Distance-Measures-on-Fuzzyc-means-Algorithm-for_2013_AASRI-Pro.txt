 AASRI Procedia  4 ( 2013 )  50 – 56 
2212-6716 © 2013 The Authors. Published by Elsevier B.V.
Selection and/or peer review under responsibility of American Applied Science Research Institute
doi: 10.1016/j.aasri.2013.10.009 
ScienceDirect
Co
Abst
A stu
for a
utiliz
varia
accur
 
© 20
Sele
 
Keyw
1. In
Rece
effic
algo
thou
 
* 
E
ompariso
Jiho H
tract 
udy on the use o
an image classi
zes only mean i
ance and mean 
racy when com
013.Published
ection and/or p
workds: Fuzzy c-M
ntroduction 
ent increase u
ciently. Severa
orithm andSelf
ught as an imp
 
Corresponding a
E-mail address: pa
2013 AAS
on of Di
for
Hana,  Dong
aDept. of E
bKo
of  two differen
fication proble
information fro
information. E
mpared with som
d by Elsevier B
peer review un
Means, Classifica
se of compres
al conventiona
f OrganizingM
proved version
author. Tel.: +82-3
arkd@dreamwiz.
SRI Confere
istance M
r Image 
g-Chul Park
Electronics Eng., M
rea Electronics T
nt distance mea
m in this pape
om an image blo
Evaluationson a
me conventional
B.V. 
nder responsib
tion, Divergence 
ssed image da
al algorithms 
Map(SOM) [1]
n of  earlier clu
31-330-6975; fax
com 
ence on Inte
Measure
Classific
ka*, Dong-
Myongji Univ.,Gy
Tech. Inst.,SongN
 
sures, Euclidea
er.Conventional
ock for its featu
a set of Caltech
l algorithms wit
bility of Amer
Measure, SOM
ata requires for
adopted for th
][2].FCM algo
ustering. The 
x: +82-31-330-69
elligent Syst
s on Fuz
cation P
-Min Wooa
Gyeongi-do, 449-7
Nam, 463-816, Rep
an distance and 
l FCM algorith
ure while FCM
h databaseshow
th Euclidean di
rican Applied 
r an automatic
his purpose inc
orithm is the m
FCM algorith
977 
tems and Co
zzyc-Me
roblem
a, and Soo-
728, Rep. of  KOR
p. of  KOREA 
divergence dist
hm which uses 
M algorithm with
w that Divergen
istance. 
Science Rese
c tool thatcan 
cludesFuzzy c
most widely u
hm shows mor
ontrol 
eans Alg
-Young Mi
REA 
tance, for FCM
Euclidean dista
h divergence ut
nce-based FCM
earch Institute 
retrieve imag
c-Means (FCM
used one and c
re robustnessw
orithm 
inb 
M is conducted 
ance measure 
tilizes both of 
M gives higher 
e data 
M) 
can be 
when 
Available online at www.sciencedirect.com
© 2013 The Authors. Published by Elsevier B.V.
Selection and/or peer review under responsibility of American Applied Science Research Institute
Open access under CC BY-NC-ND license.
Open access under CC BY-NC-ND license.
51
 Jiho Han et al. /  AASRI Procedia  4 ( 2013 )  50 – 56 
compared with SOM and k-Means algorithm. By combining the ideas of FCM and divergence measure for the 
problem of image classification, we expect a better feature extraction procedure for more accurate 
classification scheme. The method adopts the FCM algorithm with Divergence Measure [3]-[5]for acquiring 
texture information from image data. 
Section 2 summarizes FCM algorithms with two different distance measures: Euclidean distance and 
divergence distance. Section 3 reports the evaluations and a comparison of different schemes through 
experiments. Section 4 presents  conclusions. 
2. Adopted Clustering Algorithms 
2.1. Fuzzy c-MeansAlgorithm 
The following  equation is used as the objective function for FCM[2] : 
 
                                                                                                              (1) 
 
wheredi(xk) ,
ki,m, n, and c follow the definitions in [2]. 
From Eq. (1), Bezdekfinds  the following equations [2]: 
                                                                                                                                            (2) 
 
                                                                                                                                                 (3) 
2.2. FCM with Divergence Measure 
The choice of different distance measure can affect the performance of clustering results [1]. This leads to 
the idea of divergence measure for image classification problem. 
Given two Gaussian Probability Density Functions, 
and
, i = 1, 
, d ,  the 
divergence distance can be defined as follows[6,8]: 
 
 
 
                                                                                                       (4) 
52  
 Jiho Han et al. /  AASRI Procedia  4 ( 2013 )  50 – 56 
where 
,
,
and 
follow the definition in [6,8]. Note that the divergence measure is also called as 
Kullback-Leibler Divergence. 
 
FCM calculates the parameters of center and membership values by applying all the data at once in batch 
mode. However, the D-FCM used in the proposed classifier calculates and updates their parameters at each 
application of each data vector as the Gradient-based FCM [3]. The advantage of this iterative application and 
updating the center parameters was reported in [3]. When each data vector is presented to the network, the 
following can be also found : 
                                                                                                                                            (5) 
Subsequently, the following update equation for  the mean and variance was derived[6]: 
 
                                                                                                     (6) 
 
                                                                                                          (7) 
where
,
,
,
, and 
 follow the definitions in [6]. 
 
3. Experiments and Results 
For evaluation and comparison purpose for different classification schemes, we performed some 
experiments on a set of the Caltech image database[7]. The Caltech image database has been widely used as a 
benchmark data for various image classification problems. Examples of the four-category data used in 
experiments are given in Fig. 1.200 data are used for each category. Preparation for experiments follows the 
procedure used in [4]:  150 randomly selected training data and 50 remaining data for each class are used for 
the evaluation of different classifier schemes.  Note that all the image data are converted to grey images with 
identical resolution. 
The first step for designing a data classifier is the feature extraction process. The local feature extraction 
adopted in our experiments allows us to find localized feature information from entire image space.By 
collecting thefeature information from local points, each image data can be expressed in terms of features. In 
our experiments, 8 8 blocks are used for extracting localized information of an image data. The local 
information in each image window can be extracted by using conventional feature extraction methods [9]-[11]. 
Among them, Gabor filters and wavelet filters show reasonable performance except requiring extensive 
computational burden. This computational burden keeps these methods from being used for feature extraction 
tools for several applications. On the other hand, the Discrete Cosine Transform (DCT) is more suitable to 
acquire frequency information in images and DCT is used for our experiments because DCT does not require 
so much computational effort. Even though DCT coefficients out of each block image produces 64-
dimensional one, the 32 lower frequency part of the 64 coefficients are used [4] and this yields a total 32-
dimensional vector value for each local block image. 
The model for a data category is formed by deciding the code vectors using clustering algorithms on its 
feature vectors. The modeling or training process consists of finding representativecode vector for 
53
 Jiho Han et al. /  AASRI Procedia  4 ( 2013 )  50 – 56 
eachcategory with its feature vectors.Bayesian classifier is utilized for the performance evaluation on various 
classification schemes. Itallocates a class for a given testdata according to the following probability  
calculation [4]: 
 
                                                                                                                          (8) 
 
                                                                                                                              (9) 
 
                                                                                                    (10) 
whereM,ci,d (=32), 
and 
i follow the definitions in [4].  
 
 
 
 
 
 
 
 
 
 
 
 
(a) Car                                                                                   (b) Motorbike 
 
 
 
 
 
 
 
 
 
(c) Bike (d) Airplane 
 
Fig. 1  Examples of data 
54  
 Jiho Han et al. /  AASRI Procedia  4 ( 2013 )  50 – 56 
T
algo
seve
accu
FCM
code
num
summ
From
infor
dista
resu
15 c
Som
futur
dive
 
 
 
 
 
 
Fig. 2
Table
 
 
The same train
orithms, SOM 
eral numbers o
uracies. The av
M are observed
e vector numb
mbers reach 1
marizes the c
m  Fig. 2 and
rmation plays
ance measure 
lts are reporte
ode vectors. C
me other featur
re research. F
ergence measu
 
 
 
 
 
 
 
 
 
 
 
 
 
2. Comparison of 
e 1. Classification
ning and test p
and FCM, an
of code vecto
verage accura
d as 42.22%, 4
bers. Note th
5. Note also 
classification p
d Table 1, w
s an important
allows the im
ed in [4]. Tabl
Car images ar
re extraction 
Future resear
ure environme
f classification acc
n performance of 
 
SOM 
FCM 
D-FCM 
procedures for
nd compared w
rs up to 19 ar
acies over diff
44.61%,and 7
hat their class
that SOM a
performance f
we can notice 
t role in impr
mage classifie
le 2 shows a c
e classified w
methods that 
rch also inclu
ent. 
curacies ofvariou
SOM, FCM, and
Car 
98 
97 
100 
r the same dat
with the accur
re used for ea
ferent number
73.33%, respec
sification accu
and FCM don
for each categ
that the cova
roving the cla
er to have an 
confusion mat
well enough wh
can discrimin
ude the comp
 
us classifier schem
d D-FCM for the c
Bike 
Mo
63 
66 
78 
ta sets are per
racy of the pro
ach algorithm.
rs of code vec
ctively. The c
uracies are so
n’t use the v
gory of image
ariance value
ssification acc
advantage ov
trix of D-FCM
hile motorbike
nate car data 
parison of F
mes  over number
case of 15 code v
otorbike
Airpl
7 
13
5 
17
51 
76
rformed on tw
oposed algorit
. Fig. 2 summ
ctors (3 to 19)
classification a
omewhat satu
variance while
e data when 1
utilized in D
curacy for im
ver the Euclid
M based image
e data are  con
from airplane
CM and Gra
rs of code vectors
vectors 
lane
Avg
Accurac
3 
45.2
7 
46.2
6 
76.2
wo conventiona
thm. During e
marizes their c
) for SOM, F
accuracy is inc
urated when  
e D-FCM do
15 code vecto
D-FCM along
mage data. The
dean distance 
e classifier for
nfused with ai
e data need to
adient-based F
s 
g. 
cy(%) 
25 
25 
25 
al clustering 
experiments, 
classification 
CM, and D-
creased with 
code vector 
oes. Table 1 
ors are used.  
g with mean 
e divergence 
and similar 
r the case of 
irplane data. 
o be done in 
FCM under 
55
 Jiho Han et al. /  AASRI Procedia  4 ( 2013 )  50 – 56 
Table 2. Detailed classification results of D-FCM  
 
 
Classified 
 
 
Car 
Bike 
Motorbike
Airplane 
Inputs 
Car 
0 
100 
0 
0 
Bike 
2 
78 
12 
8 
Motorbike 
0 
6 
51 
43 
Airplane 
7 
2 
15 
76 
 
4. Conclusions 
A comparative study Euclidean distance and divergence distance for FCM is conducted in this paper.When 
used for an image classification problem, conventional FCM algorithm which uses Euclidean distance 
measure utilizes only mean information from an image block for its feature. On the other hand, FCM 
algorithm with divergence utilizes both of variance and mean information from an image block  for its 
features.  Self-Organizing Map is also used in our experiments as a baseline method for the performance 
comparison purpose.  Experiments on Caltech database are performed for a four category problem. 
Classification accuracies from different classification schemes imply that  divergence-based FCM is a better 
fit for image classification problem than the conventional FCM or SOM that use only the mean information as 
their features for image data. We can conclude that the divergence information of image data plays an 
important role in image classification problem and the resultant classification scheme that uses the divergence 
information as well as the mean information from image data is a better choice for image classification 
problem. However, a further effort should be given to find a feature extraction method for overcoming the 
confusion between Motorbike data and Airplane data. 
 
Acknowledgements 
This work was supported byIT R&D program of The MKE/KEIT (10040191) and by National Research 
Foundation of Korea Grantfunded by the Korean Government (2010-0009655). 
 
 
References 
[1]Bezdek, J.C. Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum;1981. 
[2]Kohonen,T.The Self-Organizing Map. Proceedings of  IEEE, 1990;78 :1464-1480. 
[3]Park D.C.et. al. Classification of Audio Signals Using Gradient-Based Fuzzy c-Means Algorithm with 
Divergence Measure. Proc. Pacific Rim Conference on Multimedia.2005; 698-708. 
[4]Park D.C., Woo D.M. Image classification using Gradient-Based Fuzzy c-Means with Divergence Measure. 
Proc. Int. Joint Conference on Neural Networks.2008; 2520-2524. 
[5]Park D.C. Satellite Image Classification Using a Divergence-Based Fuzzy c-Means Algorithm.Proc.Int. 
Conf. on Image and Signal Processing. 2012;555-561. 
[6]Park D.C. et. al.Centroid Neural NetworkWith a Divergence Measurefor GPDF Data Clustering.IEEE 
56  
 Jiho Han et al. /  AASRI Procedia  4 ( 2013 )  50 – 56 
Transactions on Neural Networks. 2008;19(6): 948-957. 
[7]http://www.vision.caltech.edu/html-files/archive.html 
[8]FukunagaK. Introduction to Statistical Pattern Recognition, Academic Press Inc.;1990. 
[9]Daugman J.G. Complete Discrete 2D Gabor Transform by Neural Networks forImage Analysis and 
Compression. IEEE Transactions  on Acoustics, Speech, and SignalProcessing.1988;36:1169-11179. 
[10]Pun C.M., LeeM.C. Extraction of Shift Invariant Wavelet Features for Classification of Images with 
Different Sizes. IEEE Transactions on Pattern Analysis andMachine Intelligence. 2004;26(9) :1228-1233. 
[11]Huang Y.L., Chang R.F. Texture Features for DCT-Coded Image Retrieval andClassification. Proc. Int. 
Conf. on Acoustics, Speech, and SignalProcessing.1999;6:3013-3016. 
 
