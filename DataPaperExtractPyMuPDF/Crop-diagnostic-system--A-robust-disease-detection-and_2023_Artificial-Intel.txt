Crop diagnostic system: A robust disease detection and management
system for leafy green crops grown in an aquaponics facility
R. Abbasi a, P. Martinez b, R. Ahmad a,⁎
a Aquaponics 4.0 Learning Factory (AllFactory), Department of Mechanical Engineering, University of Alberta, 9211 116 St., Edmonton, AB T6G 2G8, Canada
b Mechanical and Construction Engineering Department, Northumbria University, Newcastle Upon Tyne NE7 7YT, UK
a b s t r a c t
a r t i c l e
i n f o
Article history:
Received 4 August 2022
Received in revised form 7 July 2023
Accepted 6 September 2023
Available online 09 September 2023
Crops grown on aquaponics farms are susceptible to various diseases or biotic stresses during their growth cycle,
just like traditional agriculture. The early detection of diseases is crucial to witnessing the efﬁciency and progress
of the aquaponics system. Aquaponics combines recirculating aquaculture and soilless hydroponics methods and
promises to ensure food security, reduce water scarcity, and eliminate carbon footprint. For the large-scale imple-
mentation of this farming technique, a uniﬁed system is needed that can detect crop diseases and support re-
searchers and farmers in identifying potential causes and treatments at early stages. This study proposes an
automatic crop diagnostic system for detecting biotic stresses and managing diseases in four leafy green crops,
lettuce, basil, spinach, and parsley, grown in an aquaponics facility. First, a dataset comprising 2640 images is con-
structed. Then, a disease detection system is developed that works in three phases. The ﬁrst phase is a crop clas-
siﬁcation system that identiﬁes the type of crop. The second phase is a disease identiﬁcation system that
determines the crop's health status. The ﬁnal phase is a disease detection system that localizes and detects the
diseased and healthy spots in leaves and categorizes the disease. The proposed approach has shown promising
results with accuracy in each of the three phases, reaching 95.83%, 94.13%, and 82.13%, respectively. The ﬁnal dis-
ease detection system is then integrated with an ontology model through a cloud-based application. This ontol-
ogy model contains domain knowledge related to crop pathology, particularly causes and treatments of different
diseases of the studied leafy green crops, which can be automatically extracted upon disease detection allowing
agricultural practitioners to take precautionary measures. The proposed application ﬁnds its signiﬁcance as a de-
cision support system that can automate aquaponics facility health monitoring and assist agricultural practi-
tioners in decision-making processes regarding crop and disease management.
© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open
access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
Keywords:
Computer vision
Deep learning
Disease detection
Leafy crops
Aquaponics
Digital farming
1. Introduction
An aquaponic system is the combination of two well-known tech-
nologies, namely recirculating aquaculture system (RAS) and a hydro-
ponics system (soilless growing of plants) that work together in an
integrated environment (Abbasi et al., 2021a). The rationale of this soil-
less growing system involves sharing the mutual beneﬁt of the available
resources, such as water and nutrients, between aquaculture and plant
production. Fish eats food and excretes waste consisting of ammonia
(NH3
+) and other constituents, which are then converted by certain
microbes to nitrates (NO3
−). This enriched efﬂuent is then pumped
into the hydroponic component of the system, where the nutrients are
readily available for uptake. Under this general idea, it can be implied
that aquaponic is a green and sustainable food production system
(Yanes et al., 2020).
Despite all the advantages offered by this emerging and growing
technology, a few challenges need special attention, particularly consid-
ering its large-scale implementation. Being a greenhouse and a symbi-
otic environment, the parameters and factors (light, temperature, pH,
moisture, etc.) that need to be controlled are diverse (Abbasi et al.,
2021b). For the system to be functional and efﬁcient, a delicate equilib-
rium among these parameters must be established (Gillani et al., 2022).
Optimal conditions must be met for the growth and development of all
three varieties of organisms that are present in the system (ﬁsh, bacte-
ria, and plants). Another signiﬁcant challenge is related to crop diseases
resulting from either nutrient deﬁciency or inadequate management of
the system, impacting crop quality and causing crop wastage (Dhal
et al., 2022; Stouvenakers et al., 2019). As Khirade and Patil pointed
out, identifying crop diseases and applying disease management prac-
tices are key to preventing losses in the yield and quantity of agricultural
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
⁎ Corresponding author.
E-mail address: raﬁq.ahmad@ualberta.ca (R. Ahmad).
https://doi.org/10.1016/j.aiia.2023.09.001
2589-7217/© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http://
creativecommons.org/licenses/by-nc-nd/4.0/).
Contents lists available at ScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage: http://www.keaipublishing.com/en/journals/artificial-
intelligence-in-agriculture/
products (Khirade and Patil, 2015). For this reason, early detection of
disease outbreaks is crucial for the progress of aquaponics farms. Tradi-
tionally, crop diagnostic is performed by agricultural specialists who vi-
sually examine the plant leaves. This practice, however, is subjective,
destructive, time-consuming, and labor-intensive (Dutot et al., 2013).
Moreover, it also requires the experts to be proﬁcient with extensive
knowledge of various diseases, their symptoms, and treatments (Khan
et al., 2022). Other methods include chemical analyses, leaf color chart
(LCC) matching, soil plant analysis development (SPAD), hyperspectral
imaging, and spectral remote sensing, which again are either time-
consuming or costly or destructive techniques (Weaver et al., 2020).
To address these problems, different automatic crop disease detection
systems based on artiﬁcial intelligence (AI) techniques such as machine
learning and deep learning are developed as they offer contactless,
rapid, environmental-friendly, and accurate methods for performing a
non-invasive evaluation of crops' health and quality (Bedi and Gole,
2021; Singh et al., 2020). Deep learning techniques offer two signiﬁcant
advantages over machine learning techniques. First, the feature extrac-
tion process is automatic, and second, the time to process large datasets
of high dimensions is signiﬁcantly reduced (Bedi and Gole, 2021).
In addition to disease detection, it is also paramount that farm prac-
titioners and researchers have access to relevant information about crop
management strategies that allow them to pick up methods and treat-
ments appropriately to prevent diseases, thereby gaining both eco-
nomic and environmental beneﬁts (Barosa et al., 2019). In most cases,
such information is dispersed throughout multiple heterogeneous
data sources — posing a need for a uniﬁed model that contains knowl-
edge about the causes and treatments of different crop diseases. Seman-
tic technologies such as ontologies have proven effective for data
integration in multiple domains (Rodríguez-García et al., 2021). An on-
tology is a formal and explicit speciﬁcation of a shared conceptualiza-
tion (Studer et al., 1998). The logical formalisms behind ontological
models allow autonomous agents to interpret the information that is
being processed (Horrocks et al., 2005). Ontology can be used to con-
struct a knowledge base containing relevant information about causes
and suggested treatments of crop diseases, which can be extracted
upon disease detection (Rodríguez-García et al., 2021). With this infor-
mation, farm practitioners are able to get clear guidelines to effectively
perform crop monitoring and disease management.
In this study, an automatic system based on deep learning tech-
niques is presented for the detection and classiﬁcation of diseases in
four leafy green crops, lettuce, basil, parsley, and spinach, grown in an
aquaponics facility. Taking advantage of semantic technologies, an on-
tology model, ‘AquaONT’ is developed by authors in previous work
(Abbasi et al., 2021b) that contains knowledge about causes and treat-
ments of different diseases. This ontology model is integrated with a dis-
ease detection system through an interface established on a cloud-
based application.
The remainder of the paper is structured as follows: Section 2 sum-
marizes the most recent literature related to crop disease detection sys-
tems, Section 3 presents the methodology used to design the proposed
system, Section 4 discusses the experimental results and ﬁndings, and
ﬁnally, Section 6 concludes the paper and presents the future prospects.
2. Related work
The rapid developments in AI have made a major breakthrough in
deep learning (DL) and computer vision (CV) technologies by solving
complex problems like image classiﬁcation, object detection, speech
recognition, voice recognition, natural language processing, and medi-
cal imaging, among others (Abbasi et al., 2022a; Subeesh and Mehta,
2021). In particular, convolutional neural networks (CNNs) have proved
their efﬁciency in various sectors such as automotive, healthcare, or re-
tail, and are also being integrated in agriculture for automatic crop dis-
ease detection — presenting a reasonable alternative to traditional
practices (Pathan et al., 2020). In recent years, several models and
applications have been developed for crop disease identiﬁcation and
diagnosis. This section investigates some latest works present in the
literature.
Anami et al. designed a deep convolutional neural network (DCNN)
based framework for automatic recognition and classiﬁcation of various
biotic and abiotic paddy crop stresses using the pre-trained visual ge-
ometry group model, VGG-16 (Anami et al., 2020). The ﬁeld images
are used in the proposed approach captured during the booting growth
stage. Bedi and Gole proposed a hybrid model based on a convolutional
autoencoder (CAE) network and CNN for automatic bacterial spot dis-
ease detection present in peach plants using their leaf images from a
publicly available dataset named ‘PlantVillage’ (Bedi and Gole, 2021).
Paymode and Malode developed a CNN-based method using pre-
trained VGG-16 for detecting healthy, unhealthy, and diseased leaves
in tomato and grape plants (Paymode and Malode, 2022). Fuentes
et al. combined ResNet with Faster R-CNN, R-FCN, and SSD. They pro-
posed a method to detect the diseases and insect pests of tomato plants,
achieving the effective identiﬁcation of nine different types of diseases
and insect pests (Fuentes et al., 2017). Chen et al. proposed a method
to detect rice plant diseases using the DenseNet model of deep transfer
learning (Chen et al., 2020).
To identify the cucumber disease spots in greenhouses, Ma et al. de-
veloped a CNN-based system, combining a compound color feature with
a region-growing algorithm (Ma et al., 2018). A disease recognition al-
gorithm based on VGGNet and InceptionV3 with reduced model size
and improved recognition accuracy is proposed by Rahman et al. for
rice plants (Rahman et al., 2020). Oppenheim et al. proposed a disease
classiﬁcation algorithm based on an improved VGG network for accu-
rate and quick identiﬁcation and classiﬁcation of spots on potato crops
(Oppenheim et al., 2019). A method based on an improved CNN is pro-
posed by Fan et al. to identify nine kinds of common corn diseases from
images with a complex background (Fan et al., 2021). Khan et al. pro-
posed an apple disease detection system that works in two stages
(Khan et al., 2022). Based on the Xception model, the ﬁrst stage clas-
siﬁes whether the leaf is healthy or diseased, and the second stage,
based on Faster-RCNN, performs disease detection.
Qi et al. developed a disease recognition system based on an im-
proved YOLOv5 (squeeze-and-excitation (SE) module is added) model
to identify the tomato virus diseases in the greenhouse (Qi et al.,
2022). Nandhini et al. proposed a deep learning model that combines
RNN and CNN for disease classiﬁcation and early prediction in the Plan-
tain tree (Nandhini et al., 2022). Abbas et al. proposed a deep learning-
based method for tomato disease detection that utilizes the Conditional
Generative Adversarial Network (C-GAN) to generate synthetic images
of tomato plant leaves (Abbas et al., 2021). A DenseNet121 model was
then trained on synthetic and real images using transfer learning to clas-
sify the tomato leaves images into ten categories of diseases. An efﬁcient
detection model (EFDet) consisting of an efﬁcient backbone network, a
feature fusion module, and a predictor is proposed for the detection of
cucumber leaf diseases in complex backgrounds by Liu et al. (Liu et al.,
2021). Likewise, a YOLOv5-based disease detection model to detect bac-
terial spot disease in bell pepper plant from the symptoms seen on the
leaves (Mathew and Mahesh, 2022).
A framework is proposed for an aquaponics system based on image
processing and decision tree methodology that performs disease detec-
tion of four leaf species, eggplant, chilli, citrus, and mandarin, and auto-
matically generates a report which is sent to the owner through the
mobile application if the disease is detected (Barosa et al., 2019). Like-
wise, a CNN-based approach for detecting plant disease in smart hydro-
ponics provides a tool to the farmers capable of doing the task of an
agricultural extension worker with even better accuracy (Musa et al.,
2021). An application based on image processing and SVM is developed
to classify apple diseases (Lisha Kamala and Anna Alex, 2021). Yudha
et al. proposed a model based on Faster R-CNN with Inception V2 algo-
rithm to recognize the diseases in hydroponic lettuce (Yudha Pratama
et al., 2020).
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
2
The literature survey has revealed that researchers have extensively
used deep learning techniques for plant or crop disease detection and
classiﬁcation. The analysis shows that most disease detection systems
are developed for open-air farms. Only a few systems are developed
for modern farming systems, such as aquaponics or hydroponics. Most
models are developed considering multiple diseases of only one crop.
Moreover, to the best of the authors' knowledge, no comprehensive
and uniﬁed disease detection system is proposed for identifying dis-
eases of multiple leafy green crops grown in aquaponics facilities.
Disease detection in leafy green presents various challenges. For in-
stance, there exists a strong resemblance among the foliage of different
leafy green crops that might impact the performance of the detection
system. Secondly, due to differences in light illumination during imag-
ing, the visual symptoms of different diseases may appear similar. An-
other challenge is the availability of a dataset of leafy green crops that
can be used for disease detection. Deep learning models require a
huge amount of data for training, and to the best of the author's knowl-
edge, there is no sufﬁcient sized large-scale open-source dataset avail-
able that can be utilized for this research. There are a few datasets,
such as PlantVillage, PlantDoc, and CropDeep (Noyan, 2022; Singh
et al., 2019; Zheng et al., 2019). PlantDoc and PlantVillage are open-
source datasets with no categories of leafy green crops. CropDeep
dataset contains images of some of the leafy green, but it is not open
source. Lastly, none of the aforementioned models provides information
related to the causes and treatments of detected diseases.
Apart from AI techniques, ontology-based systems are also devel-
oped over the years for plant disease diagnosis and treatment recom-
mendations. Jearanaiwongkul et al. developed an ontology-based
expert system called ‘RiceMan’ for disease identiﬁcation and control
recommendation in rice crops (Jearanaiwongkul et al., 2021). Likewise,
Rodríguez-García et al. proposed a decision support system based on an
ontology model for crop pests and diseases recognition (Rodríguez-
García et al., 2021). It also provides information on agriculture practices
and permitted pest control measures. In these systems, users are re-
quired to select crop and observed symptoms from the list for further
processing, which is a time-consuming process. Whereas, in deep learn-
ing models, this information can be obtained by using crop images. Deep
learning techniques can be combined with ontology models to develop
efﬁcient decision support systems for disease management in crops. The
idea of combining the two techniques is relatively new in the agricul-
ture sector, and hence, limited work is done in this regard that primarily
focuses on enabling smart services (monitoring and control) in IoT-
based farming systems or detection of cyber-attacks (Abbasi et al.,
2021b).
Considering the research gaps and potential opportunities, this
study aims to create a dataset consisting of high-quality RGB images
(healthy and diseased) of four leafy green crops: little gem romaine let-
tuce, spinach, parsley, and basil. This study also aims to develop a crop
diagnostic system based on deep learning models and ontology models
for detecting diseases and identifying causes and potential treatments
in stated crops, respectively.
3. Research methodology
The block diagram illustrating the three sequential modules of the
research methodology is shown in Fig. 1. First module involves the
preparation of the dataset and training of classiﬁcation and object de-
tection models. The disease detection model works in three phases.
The ﬁrst and second phase uses lightweight classiﬁcation models to
classify the type of crop and identify whether the classiﬁed crop has
a disease or not, respectively. Phase 3 is the detection stage that
uses an object detection model to detect and localize the diseased
and non-diseased spots in the crops. The third phase also tells the
class of the diseased spots. The purpose behind adding two classiﬁca-
tion phases before the detection phase is three-fold. First, to improve
the detection performance by reducing the number of wrong
detections which could arise as the model has to identify and localize
different disease spots of varying sizes. Second, to determine the
characteristics of the crop identiﬁed in the ﬁrst phase in relation to
aquaponics' system design by linking it with the knowledge model.
Lastly, to reduce the overall processing time by ﬁltering out invalid
inputs in the second phase. The second module aims to extract the in-
stances of relevant classes such as potential causes and treatments of
detected diseases from the ontology model ‘AquaONT’ developed by
authors in previous work (Abbasi et al., 2021b). In the third module,
a cloud-based application is developed using Streamlit1, where a
pre-trained disease detection model and ontology model are de-
ployed to obtain a complete crop diagnostic system. Upon identiﬁca-
tion of the crop in phase 1, its characteristics in relation to optimal
environmental (pH, temperature, illumination, etc.), growth (width,
height, area, etc.), and grow bed design (plant site spacing) parame-
ters for an aquaponics facility are extracted from ontology model
using OWLready22 (ontology-oriented programming package in Py-
thon). The authors have conducted a study that identiﬁed design pa-
rameters as vital knowledge in ensuring high crop yields and product
quality in an aquaponics facility (Abbasi et al., 2021a). Likewise, once
the disease and its type are detected in phase 3, the potential causes
and recommended treatments are extracted from the ontology
model. Each element of each module is presented in detail in the fol-
lowing subsections.
3.1. Dataset preparation
The dataset preparation involves three steps, i) data acquisition, ii)
data annotation, and iii) data augmentation, which are detailed below.
3.1.1. Data acquisition
This study considers four leafy green crops, lettuce, basil, parsley,
and spinach. The dataset consists of healthy and diseased images of
these crops, which are acquired from different sources such as NFT
based aquaponics facility built in AllFactory 4.0 Lab (University of Al-
berta, Canada), Google search engine, and Ecosia3 (a search engine
based in Berlin, Germany). The diseases considered for the four crops
while developing the dataset are listed below.
• Lettuce: Bacterial leaf spot and Downy mildew
• Basil: Downy mildew
• Parsley: Septoria leaf spot
• Spinach: Downy mildew and Stemphylium leaf spot
To enhance the ﬂexibility of the model to correctly classify and de-
tect disease, it is ensured that images have non-homogeneous back-
grounds, different illumination conditions, and disease maturity stages
(Jha et al., 2019). A total of 2000 images are gathered from all the re-
sources. Among these images, 800 images showed healthy crops (200
images per crop), and 1200 images showed the diseases mentioned
above (240 images per disease). Fig. 2 shows some of the sample images
from the dataset.
3.1.2. Data annotation
Data annotation is one of the vital steps for the successful devel-
opment of object detection models. The process is manual and in-
volves labeling the desired objects in an image with a label or tag
that refers to a particular class. The labeled data is used during the
training of the model. There are various open-source annotation
tools, but in this study, LabelImg4 is used. LabelImg is a python
based graphical annotation tool that supports a variety of deep
learning algorithms (Qi et al., 2022). In this study, the annotations
1 https://streamlit.io/.
2 https://pypi.org/project/Owlready2/.
3 https://www.ecosia.org/.
4 https://github.com/tzutalin/labelImg.
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
3
are generated in COCO JSON and YOLO Darknet TXT formats because
in the disease detection phase, two object detection models are
tested to design the ﬁnal system.
3.1.3. Data augmentation
Next, the data augmentation process is performed to supplement
and enrich the dataset. This helps increase the model's generalizability
and overcome the problem of overﬁtting. Moreover, it also allows the
model to learn as many relevant features as possible. This study uses
Albumentations, a Python library, for fast and ﬂexible image augmenta-
tions (Buslaev et al., 2020). The different augmentation techniques ap-
plied are ﬂip, rotation, noise, blur, and brightness. Fig. 3 shows
examples of different augmentation operations. After applying the
data augmentation, the ﬁnal dataset comprises of 2640 images with
their annotations. The ﬁnal distribution of the dataset is presented in
Table 1.
3.2. Disease detection model development
Object detection is a complex task, and disease detection of leafy
green crops comes with its own set of challenges. To overcome these
challenges, the detection process in this study is divided into three pri-
mary phases. Fig. 4 shows the detailed pipeline of the disease detection
model.
The ﬁrst phase of the proposed system uses a lightweight CNN ar-
chitecture to classify input images into one of the four types of crops:
lettuce, basil, parsley, and spinach. ResNet-50 is used as the base
model for the CNN architecture in this study and its last layer is re-
placed with one global average pooling layer, one dense layer (fully
connected layer) of size 1024 and activation function ReLu, and one
output layer that uses Softmax for classiﬁcation task and making
ﬁnal predictions. ResNet050 is used as it has a simple design, high ac-
curacy, and is suitable for small datasets (He et al., 2015). The crop
Fig. 2. Samples from leafy green image dataset. (For interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this article.)
Fig. 1. Proposed methodology for disease detection and control recommendation system.
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
4
type identiﬁed in this stage saves to a folder and also acts as an input
to the next phase.
Phase 2 of the system also uses ResNet-50 and classiﬁes the input
from phase 1 into one of the following eight classes.
i) Lettuce-Healthy
ii) Lettuce-Diseased
iii) Basil-Heathy
iv) Basil-Diseased
v) Spinach-Healthy
vi) Spinach-Diseased
vii) Parsley -Healthy
viii) Parsley-Diseased
The architectural design of ReNet-50 used in phase 2 is kept similar
as in phase 1 except for the output layer which now has eight classes. If
the input image classiﬁed into one of the ‘Diseased’ crop categories, it
goes to phase 3. On the other hand, if any of the ‘Healthy’ crop categories
are identiﬁed, the process ends, and the classiﬁed image does not go to
the next phase for further processing.
The third phase of the proposed system is disease detection, which
involves classifying and localizing the diseased spots in an image and
classifying them into one of the disease classes mentioned below.
i. Lettuce-Bacterial leaf spot
ii. Lettuce-Downy mildew
iii. Basil-Downy mildew
iv. Parsley-Septoria leaf spot
v. Spinach-Downy mildew
vi. Spinach-Stemphylium leaf spot
Phase 3 activates only when the input from the previous phase is one
of the ‘Diseased’ categories. To develop a disease detection model, an
object detection algorithm is used. In the past recent years, advances
in deep learning and computer vision have greatly accelerated the mo-
mentum of object detection (Khan et al., 2022). Numerous object detec-
tion algorithms (object detectors) are developed and used in the disease
detection of crops. These detectors are broadly classiﬁed into two
categories: i) two-stage detectors based on region proposal and ii)
one-stage detectors based on regression or classiﬁcation (Nguyen
et al., 2020). The popular two-stage detectors are Fast-RCNN, Faster-
RCNN, and Mask-RCNN, and one-stage detectors involve YOLO (You
Only Look Once) family (Liu et al., 2021).
Khan et al. conducted a research where they ran three different
models, Faster-RCNN, YOLOv4, and EfﬁcientDet, to solve a similar kind
of problem for apple crops (Khan et al., 2022). It has been observed
that Faster RCNN with mAP (mean average precision) of 42.1%
outperformed YOLOv4 (mAP of 41.4%) and EfﬁcientDet (mAP of 38%).
As per these results, Faster-RCNN seems the right choice for this study.
But YOLOv5 model developed by Ultralytics (Glenn, 2023) has substan-
tially improved the detection speed while maintaining the detection ac-
curacy. Therefore, both approaches are tested in this study.
3.3. Disease detection model training
NVIDIA GeForce RTX 3090 is used to train all the models in three
phases of the disease detection system. The classiﬁcation model devel-
oped in stage 1 is implemented in PyTorch (an open source machine
learning framework based on the torch library developed by Meta
AI5). Using the transfer learning (TL) approach, ResNet-50 pre-trained
on ImageNet is used (Russakovsky et al., 2015). The pre-trained model
Fig. 3. Example of different augmentation operations applied on original image.
Table 1
Distribution of crop information in the used dataset among the studied crops.
Crop
Healthy
Diseased
Total
Disease 1
Disease 2
Lettuce
240
280
280
800
Basil
240
280
–
520
Spinach
240
280
280
800
Parsley
240
280
–
520
5 https://pytorch.org/hub/pytorch_vision_resnet/.
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
5
saves a lot of time as it is already trained on some dataset and hence
contains the weights and biases of previous training that represent the
features of the dataset it was trained on, which are often transferable
to different datasets (Abbas et al., 2021). Hence, model parameters are
initialized using the TL approach and then retrained on a custom dataset
prepared in section 3.1.1 with a learning rate of 0.0001, a batch size of
64, an input size of 224×224×3, and 100 epochs. The model
was tuned using the Adam optimizer. For the classiﬁcation model in
phase 2, a batch size of 64 is used, and values of the remaining
hyperparameters are kept the same.
For training the object detection models, the dataset is split into 75%
for training, 20% for validation, and 5% for testing. The ﬁrst model is im-
plemented in Detectron2 that uses pre-trained architecture (trained on
COCO dataset) ‘Faster-RCNN with ResNet-101 + FPN’. The model uses
COCO JSON annotation format and is trained for 3000 iterations with
the initial learning rate of 0.01 for the ﬁrst 500 iterations and then
0.001 for the next 2500 iterations.
The second model, YOLOv5s, is implemented in PyTorch. Again, a
pre-trained version of the algorithm is used to enhance the training pro-
cess and reduce time. For YOLOv5s, the annotation format is YOLO
Darknet TXT but with the addition of a YAML ﬁle containing model con-
ﬁguration and class values. The model is trained for 3000 iterations. The
hyperparameters and their values for the two models are shown in
Table 2.
3.4. Ontology model
The complete development and details of all the concepts and in-
stances of ontology model ‘AquaONT’ developed by authors are avail-
able at (Abbasi et al., 2021b). AquaONT is a uniﬁed ontology model
that represents and stores the essential knowledge of an aquaponics
4.0 system. It consists of six concepts: Consumer Product, Ambient Envi-
ronment, Contextual Data, Production System, Product Quality, and Pro-
duction Facility. In this study, two classes, ‘Consumer Product’ and
‘Product Quality’ are used for knowledge extraction. The ‘Consumer
Product’ class provides an abstract view of the type, growth status,
and growth parameters of ready-to-harvest crops in an aquaponics sys-
tem. Whereas the ‘Product Quality’ class provides knowledge on crop
attributes related to pathology (crop diseases, causes, and the ways
and means by which these can be managed or controlled) and morphol-
ogy (canopy dimensions such as area, length, width, etc.). Four crops:
lettuce, basil, parsley, and spinach, are considered in this study. Their
growth conditions and morphological and pathological attributes stored
as instances of the respective classes are extracted once the crop and
disease are classiﬁed. Fig. 5 shows the hierarchical architecture of the
‘Consumer Product’ and ‘Product Quality’ classes with their instances
for the ‘Basil’ crop in Protégé6 (an open-source ontology editor and
framework developed at Stanford University) environment.
3.5. Cloud-based application
The trained model of the crop disease detection system is then saved
and deployed on a cloud-based application built on Streamlit. The ontol-
ogy model ‘AquaONT’ is also deployed on application, and relevant clas-
ses are integrated with the ﬁnal disease detection model through
Owlready2 library. The layout of the application is shown in Fig. 6. It
consists of two user inputs ‘Select Model’ and ‘Upload Image’. ‘Select
Model’ provides an option to select the model as per requirement,
which in this study are ‘Crop Classiﬁcation’ referring to phase 1, ‘Disease
or No Disease’ referring to phase 2, and ‘Disease Type, causes and Treat-
ments’ referring to phase 3 of the proposed disease detection system.
Fig. 4. Detailed pipeline for the crop diagnostic process.
Table 2
Values of hypermeters used for two objection detection methods.
Hyperparameters
Methods
Faster-RCNN
YOLOv5s
Input size
600 × 600
416 × 416
Batch size
16
16
Learning rate
0.001
lr0 = 0.01, lrf = 0.001
Momentum
0.89
0.937
Gamma value
0.1
ﬂ_gamma = 0.0
Weight decay
0.0001
0.0005
Training time
1.5 h
50 min
6 https://protege.stanford.edu/products.php#desktop-protege.
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
6
After model selection, an image is uploaded which is used by all the
models. Once the disease is detected and classiﬁed, the causes and treat-
ments of the disease are extracted from the ontology model automati-
cally and displayed on the application panel. This kind of information
is useful as it will allow agricultural practitioners to determine the
causes of diseases and take precautionary steps in the early stages to
avoid crop wastage and economic loss.
4. Experimental results and discussion
This section presents the results of experiments performed in the
current research work. First, the performance evaluation of deep learn-
ing models in three phases of the disease detection system is discussed.
Next, the trained and validated system is tested on new data. In the end,
the signiﬁcance of the complete system is presented.
The performance of the classiﬁcation model in phase 1 is evalu-
ated using a validation dataset. For this phase, there are four classes
to be classiﬁed, namely lettuce, basil, spinach, and parsley. The distri-
bution of labeled images in the validation set for this model is shown
in Table 3.
The performance of the model is presented in the form of a confu-
sion matrix (CM) shown in Fig. 7. The overall accuracy, precision, recall,
and F-measure are computed by using the respective formulae, follow-
ing common metrics for the performance of deep learning models in the
literature (Khan et al., 2022). The computed metrics are summarized in
Table 4.
The classiﬁcation model in phase 1 has achieved an overall accuracy
of 95.83%, average precision of 96.25%, average recall of 96%, and aver-
age F1-score of 96.25%. As noted in Table 4, the performance metrics
of the ‘spinach’ class are lower than the other classes. Most model con-
fusion comes in between spinach, basil, and lettuce leaves, particularly
during the initial stages of their growth cycle.
Next, the performance of the classiﬁcation model in phase 2 is eval-
uated in a similar fashion. For phase 2, there are six classes that model
classiﬁes, which are mentioned in section 3.2. Table 5 shows the distri-
bution of the validation set used for the model in phase 2.
The CM for this model is shown in Fig. 8 and performance metrics are
summarized in Table 6.
The classiﬁcation model in phase 2 has achieved an overall accuracy
of 94.13%, average precision of 94%, average recall of 94%, and average
F1-score of 93.6%. It can be observed from the CM in Fig. 8 that the
model is also prone to confusion in distinguishing between some of
the classes. For instance, six examples of LD (Lettuce-Diseased) are clas-
siﬁed among LH (1), BD (1), SH (2), and SD (2). This might be due to a
lack of clarity in identifying leaf patterns and diseased spots.
Finally, the performance of selected models for the detection phase
(phase 3) is evaluated using a validation dataset. For this phase, there
are six different diseases that models have to detect in crop leaves.
These six diseases and their distribution in the validation dataset are
given in Table 7.
In this phase, the metric that is used to evaluate and compare the
performance of two models, i-e, Faster-RCNN, and YOLOv5s, is mean av-
erage precision (mAP). The mAP is the primary evaluation indicator
used for the evaluation of object detection models (Khan et al., 2022).
In particular, mAP@0.5 (mean value of mAP at IOU threshold = 0.5) is
evaluated. The comparison of the two models against all the classes is
presented in Table 8. It can be seen that YOLOv5s with mAP@0.5 of
82.13% have outperformed Faster R-CNN. The two models have
achieved the best mAP score for Lettuce-Bacterial Leaf Spot (LBS),
Parsley-Septoria Leaf Spot (PSS), and Spinach-Stemphylium Leaf Spot
(SSS), whereas a low mAP score is observed for Lettuce-Downy Mildew
(LDM), Basil-Downy Mildew (BDM), and Spinach-Downy Mildew
(SDM). Downy Mildew initially causes light green to yellow angular
spots on the upper surfaces of leaves and hence looks similar indepen-
dently of the crop type. This causes confusion for the detector in distin-
guishing the crop-speciﬁc Downy Mildew. But with more data, this
issue can easily be resolved. Later in the growth cycle, the plant tissue
affected with Downy Mildew turns tan in spinach, purplish brown in
Fig. 5. Hierarchical structure of ‘Consumer Product’ and ‘Product Quality’ classes and respective instances in relation to Basil Crop.
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
7
basil, and light brown in lettuce, which are correctly identiﬁed by the
detector.
The performance evaluations of models in three phases have shown
that detection models are not as straightforward as classiﬁcation
models. This is because an image consists of many objects which belong
to either the same class or different classes. Hence, three things must be
veriﬁed during evaluation, including object class, bounding box (object
location), and conﬁdence.
In the end, the two detection models are compared in terms of infer-
ence time which is an important metric that determines the detection
speed. It is observed that one-stage detector i-e., YOLOv5s with a
Fig. 6. Layout of cloud-based application for disease detection.
Table 3
Dataset distribution of validation set for phase 1.
Class (Health + Diseased)
Number of images
Lettuce
160
Basil
104
Spinach
160
Parsley
104
Fig. 7. Confusion matrix of classiﬁcation results in phase 1.
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
8
detection speed of 52.8 FPS (frames per second) is faster than Faster-
RCNN with a detection speed of 43.2 FPS. Moreover, it is also observed
that YOLOv5s accurately detect objects of varying sizes with little to
no overlapping boxes. All the comparisons between the two detection
models show that YOLOv5s have a clear advantage in terms of accuracy
and run speed. Therefore, in this study, YOLOv5s is used for developing
the disease detection system.
After training and validation, the ﬁnal crop disease detection system
with YOLOv5s is tested using the test set containing new images. The
system has shown promising results by effectively classifying and de-
tecting the diseases in speciﬁed crops, which shows the system's ro-
bustness in terms of dealing with a variety of objects having different
shapes, patterns, textures, and colors. Fig. 9 shows examples where
the system has accurately classiﬁed the crop and detected the diseased
and healthy spots in crop leaves. Images in the ﬁrst row of Fig. 9 are the
results from three phases of the disease detection system for the Lettuce
crop, which is suffering from Bacterial Leaf Spot disease. Similarly, row 2
and row 3 are the results from three phases of the system showing Spin-
ach and Parsley, respectively, and the diseases they are suffering from,
such as Downy Mildew and Septoria Leaf Spot disease respectively.
The ﬁnal crop disease detection system is then deployed on a cloud-
based application developed in section 3.5. Fig. 6 shows the layout of the
application. The ontology model discussed in section 3.4 is also inte-
grated with the ﬁnal system to build a complete real-time crop diagnos-
tic system. The images are acquired wirelessly from the aquaponics
facility through an interface developed on the Google Cloud Platform
Table 4
Results of classiﬁcation model in phase 1.
Crop
Accuracy
Precision
Recall
F1-Score
Lettuce
0.97
0.95
0.96
0.96
Basil
0.98
0.96
0.96
0.96
Spinach
0.96
0.94
0.94
0.94
Parsley
0.99
1
0.98
0.99
Average
–
96.25%
96%
96.25%
Overall accuracy
95.83%
Table 5
Distribution of validation dataset for phase 2.
Class
Number of images
Lettuce-Healthy (LH)
48
Lettuce-Diseased (LD)
112
Basil-Healthy (BH)
48
Basil-Diseased (BD)
56
Spinach-Healthy (SH)
48
Spinach-Diseased (SD)
112
Parsley-Healthy (PH)
48
Parsley-Diseased (PD)
56
Fig. 8. Confusion matrix of classiﬁcation results in phase 2.
Table 6
Performance metrics of classiﬁcation model in phase 2.
Class
Accuracy
Precision
Recall
F1-score
LH
0.979
0.86
0.92
0.89
LD
0.981
0.96
0.95
0.95
BH
0.989
0.90
0.98
0.94
BD
0.983
0.91
0.93
0.92
SH
0.981
0.91
0.88
0.89
SD
0.983
0.96
0.96
0.96
PH
0.994
0.98
0.96
0.97
PD
0.992
0.98
0.96
0.97
Average
–
94%
94%
93.6%
Overall accuracy
94.13%
Table 7
Distribution of validation dataset in phase 3.
Class
Number of images
Lettuce-Bacterial Leaf Spot (LBS)
56
Lettuce-Downy Mildew (LDM)
56
Basil-Downy Mildew (BDM)
56
Parsley-Septoria Leaf Spot (PSS)
56
Spinach-Downy Mildew (SDM)
56
Spinach- Stemphylium Leaf Spot (SSS)
56
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
9
by the authors in previous work (Abbasi et al., 2022b). The images are
stored in a folder to be used by the crop diagnostic system. Once the
crop type and its disease are identiﬁed, the causes and treatments are
automatically extracted from the ontology model and displayed on the
application panel. For instance, Fig. 6 shows an example of working
crop diagnostic system for parsley crops. The disease detected by the
system after image uploading is Septoria Leaf Spot. The crop diagnostic
system extracts the knowledge about potential causes and general
treatments of this disease from AquaONT. The primary causes of
Septoria Leaf Spot in Parsley could be high humidity level, infected
seeds, leaf wetness, etc. This disease could also be caused due to irregu-
lar variations in air temperature. The potential preventive measures and
treatments suggested by the system for this disease include:
maintaining optimal humidity and temperature levels in accordance
with Parsley crop and indoor aquaponics environment throughout the
growth cycle, treating seeds before germination with hot water or
Clorox bleach, using conventional fungicides if the disease is spread
out in multiple plants. Downy Mildew disease is one of the most com-
mon diseases observed in different crops (McGrath, 2021). In the
greenhouse or indoor farming environment, the potential causes of
this disease are the same irrespective of crop type, which includes:
high humidity, cool temperatures, infected seeds, and leaf wetness
(Margaret Tuttle McGrath, 2021). Therefore, the methods to treat
Downy Mildew in lettuce, basil, and spinach are also similar. This
means that the classiﬁcation of Downy Mildew disease with respect to
crop type does not impact the results related to disease treatments. De-
spite this independence, it is still signiﬁcant to perform the classiﬁcation
of Downy Mildew for each crop individually as its symptoms for three
crops, lettuce, basil, and parsley, change later in the growth cycle. This
might cause confusion for the detector to distinguish Downy Mildew
from other diseases. For instance, the lettuce tissue affected with
Downy Mildew eventually turns brown in later stages and these symp-
toms are similar to the Bacterial Leaf Spot symptom in lettuce, and both
diseases have different treatment methods.
The signiﬁcance of the proposed system is that it can act as a vital
tool for agriculturalists who wants to develop and digitize aquaponics
farm. This system will allow them to diagnose diseases at early stages
and also assist them in decision-making regarding crop characteristics
Table 8
Class-wise comparison of two detection models.
Class
mAP
Faster-RCNN
YOLOV5s
Lettuce-Bacterial Leaf Spot (LBS)
77.32
83.86
Lettuce-Downy Mildew (LDM)
73.89
78.63
Basil-Downy Mildew (BDM)
75.47
80.11
Parsley-Septoria Leaf Spot (PSS)
78.63
84.55
Spinach-Downy Mildew (SDM)
74.19
79.87
Spinach-Stemphylium Leaf Spot (SSS)
79.52
85.74
mAP@0.5
76.34
82.13
Fig. 9. Results from proposed disease detection system.
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
10
and treatments of diseases. Moreover, this study will also promote the
introduction of new implementations, such as research on the complex
relationship between dynamic parameters (environmental and water)
and diseases in aquaponics farms and self-adapting farms in case of dis-
ease detection. These smart technologies in the aquaponics system will
reduce crop wastage and ensure both economic and environmental
beneﬁts.
5. Conclusions and future prospects
This study proposes a crop diagnostic system for leafy green crops
grown in an aquaponics environment. Four leafy green crops, lettuce,
basil, spinach, and parsley, are considered. The ﬁrst dataset is devel-
oped that contains 2640 healthy and diseased images of these four
crops collected from various sources. Next, a system is proposed
that can efﬁciently and effectively identify crops and diseases. The
detection system works in three phases. The ﬁrst phase classiﬁes
the crop type, the second phase classiﬁes whether the crop is healthy
or diseased, and then in the third phase, the disease is detected if the
crop is classiﬁed as diseased in the previous phase. All the models
used in this study are initialized using transfer learning and then
trained on a dataset prepared for leafy green crops. The performance
of the models is evaluated, and promising results are achieved. For in-
stance, in the detection phase, YOLOv5s with mAP@0.5 of 82.13% and
detection speed of 52.8 FPS has outperformed Faster-RCNN. Based
on the performance, YOLOv5s is selected as a ﬁnal model for this
study. The ontology model that contains knowledge related to causes
and treatments of diseases is then integrated with the ﬁnal crop dis-
ease detection system. Finally, a cloud-based application is designed
where the ﬁnal crop diagnostic system consisting of a disease detec-
tion system and ontology model is deployed. The proposed system
proves to be accurate and ﬂexible enough to be used in real scenarios
and hence is not limited to being disturbed by potential changing
conditions and environments. It can be a helpful tool for agricultural
practitioners who want to explore modern farming practices and
want to integrate smart techniques into their farms. This system
will not only help them in disease diagnosis and quantiﬁcation but
will also assist them in decision-making regarding potential treat-
ments against identiﬁed diseases at early stages.
For future work, the system will be extended to include other leafy
green crops. Moreover, the dataset will also be extended, and more
real-ﬁeld images will be incorporated. Moreover, a mobile application
will be constructed, reducing the latency, and providing data privacy,
which normally occurs in cloud-based systems.
CRediT authorship contribution statement
R. Abbasi: Conceptualization, Methodology, Software, Validation,
Formal analysis, Visualization, Investigation, Data curation, Writing –
original draft, Writing – review & editing. P. Martinez: Conceptualiza-
tion, Methodology, Visualization, Writing – review & editing,
Supervision. R. Ahmad: Supervision, Funding acquisition, Project
administration, Writing – review & editing.
Declaration of Competing Interest
The authors declare that they have no known competing ﬁnancial
interests or personal relationships that could have appeared to inﬂu-
ence the work reported in this paper.
Acknowledgments
The authors acknowledge the ﬁnancial support of this work from the
Natural Sciences and Engineering Research Council of Canada (NSERC)
(Grant File No. ALLRP 545537-19 and RGPIN-2017-04516).
References
Abbas, A., Jain, S., Gour, M., Vankudothu, S., 2021. Tomato plant disease detection using
transfer learning with C-GAN synthetic images. Comput. Electron. Agric. 187,
106279. https://doi.org/10.1016/J.COMPAG.2021.106279.
Abbasi, R., Martinez, P., Ahmad, R., 2021a. An ontology model to support the automated
design of aquaponic grow beds. Proced. CIRP 100, 55–60. https://doi.org/10.1016/j.
procir.2021.05.009.
Abbasi, R., Martinez, P., Ahmad, R., 2021b. An ontology model to represent aquaponics 4.0
system’s knowledge. Inf. Process. Agric. https://doi.org/10.1016/J.INPA.2021.12.001.
Abbasi, R., Martinez, P., Ahmad, R., 2022a. The digitization of agricultural industry – a sys-
tematic literature review on agriculture 4.0. Smart Agric. Technol. 2, 100042. https://
doi.org/10.1016/J.ATECH.2022.100042.
Abbasi, R., Martinez, P., A.R, 2022b. Data acquisition and monitoring dashboard for IoT en-
abled aquaponics facility. The
10th
International
Conference on Control,
Mechatronics and Automation (ICCMA 2022) (Accepted). IEEE.
Anami, B.S., Malvade, N.N., Palaiah, S., 2020. Deep learning approach for recognition and
classiﬁcation of yield affecting paddy crop stresses using ﬁeld images. Artif. Intell.
Agric. 4, 12–20. https://doi.org/10.1016/J.AIIA.2020.03.001.
Barosa, R., Hassen, S.I.S., Nagowah, L., 2019. Smart aquaponics with disease detection. 2nd
Int. Conf. Next Gener. Comput. Appl. 2019, NextComp 2019 - Proc https://doi.org/10.
1109/NEXTCOMP.2019.8883437.
Bedi, P., Gole, P., 2021. Plant disease detection using hybrid model based on convolutional
autoencoder and convolutional neural network. Artif. Intell. Agric. 5, 90–101. https://
doi.org/10.1016/J.AIIA.2021.05.002.
Buslaev, A., Iglovikov, V.I., Khvedchenya, E., Parinov, A., Druzhinin, M., Kalinin, A.A., 2020.
Albumentations: Fast and ﬂexible image augmentations. Inf. 11. https://doi.org/10.
3390/INFO11020125.
Chen, J., Zhang, D., Nanehkaran, Y.A., Li, D., 2020. Detection of rice plant diseases based on
deep transfer learning. J. Sci. Food Agric. 100, 3246–3256. https://doi.org/10.1002/
JSFA.10365.
Dhal, S.B., Bagavathiannan, M., Braga-Neto, U., Kalafatis, S., 2022. Nutrient optimization
for plant growth in Aquaponic irrigation using machine learning for small training
datasets. Artif. Intell. Agric. 6, 68–76. https://doi.org/10.1016/J.AIIA.2022.05.001.
Dutot, M., Nelson, L.M., Tyson, R.C., 2013. Predicting the spread of postharvest disease in
stored fruit, with application to apples. Postharvest Biol. Technol. 85, 45–56. https://
doi.org/10.1016/J.POSTHARVBIO.2013.04.003.
Fan, X., Zhou, J., Xu, Y., Peng, X., 2021. Corn disease recognition under complicated back-
ground based on improved convolutional neural network. Nongye Jixie Xuebao/
transactions Chinese Soc. Agric. Mach. 52, 210–217. https://doi.org/10.6041/J.ISSN.
1000-1298.2021.03.023.
Fuentes, A., Yoon, S., Kim, S.C., Park, D.S., 2017. A robust deep-learning-based detector for
real-time tomato plant diseases and pests recognition. Sensors 17, 2022. https://doi.
org/10.3390/S17092022.
Gillani, S.A., Abbasi, R., Martinez, P., Ahmad, R., 2022. Review on energy efﬁcient artiﬁcial
illumination in aquaponics. Clean. Circ. Bioecon. 2, 100015. https://doi.org/10.1016/J.
CLCB.2022.100015.
Glenn, 2023. Ultralytics/yolov5 [WWW Document]. URL. https://github.com/ultralytics/
yolov5.
He, K., Zhang, X., Ren, S., Sun, J., 2015. Deep residual learning for image recognition. Proc.
IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. 2016-December, pp. 770–778
https://doi.org/10.48550/arxiv.1512.03385.
Horrocks, I., Patel-Schneider, P.F., Bechhofer, S., Tsarkov, D., 2005. OWL rules: a proposal
and prototype implementation. Web Semant. https://doi.org/10.1016/j.websem.
2005.05.003.
Jearanaiwongkul, W., Anutariya, C., Racharak, T., Andres, F., 2021. An ontology-based ex-
pert system for Rice disease identiﬁcation and control recommendation. Appl. Sci. 11,
10450. https://doi.org/10.3390/APP112110450.
Jha, K., Doshi, A., Patel, P., Shah, M., 2019. A comprehensive review on automation in ag-
riculture using artiﬁcial intelligence. Artif. Intell. Agric. 2, 1–12. https://doi.org/10.
1016/J.AIIA.2019.05.004.
Khan, A.I., Quadri, S.M.K., Banday, S., Latief Shah, J., 2022. Deep diagnosis: a real-time
apple leaf disease detection system based on deep learning. Comput. Electron.
Agric. 198, 107093. https://doi.org/10.1016/J.COMPAG.2022.107093.
Khirade, S.D., Patil, A.B., 2015. Plant disease detection using image processing. Proc. - 1st
Int. Conf. Comput. Commun. Control Autom. ICCUBEA 2015, pp. 768–771. https://doi.
org/10.1109/ICCUBEA.2015.153.
Lisha Kamala, K., Anna Alex, S., 2021. Apple fruit disease detection for hydroponic plants
using leading edge technology machine learning and image processing. Proc. - 2nd
Int. Conf. Smart Electron. Commun. ICOSEC 2021, pp. 820–825. https://doi.org/10.
1109/ICOSEC51865.2021.9591903.
Liu, C., Zhu, H., Guo, W., Han, X., Chen, C., Wu, H., 2021. EFDet: an efﬁcient detection
method for cucumber disease under natural complex environments. Comput. Elec-
tron. Agric. 189, 106378. https://doi.org/10.1016/J.COMPAG.2021.106378.
Ma, J., Du, K., Zheng, F., Zhang, L., Sun, Z., 2018. Disease recognition system for greenhouse
cucumbers based on deep convolutional neural network. Nongye Gongcheng
Xuebao/transactions Chinese Soc. Agric. Eng. 34, 186–192. https://doi.org/10.11975/
J.ISSN.1002-6819.2018.12.022.
Mathew, M.P., Mahesh, T.Y., 2022. Leaf-based disease detection in bell pepper plant using
YOLO v5. Signal, Image Video Process. 16, pp. 841–847. https://doi.org/10.1007/
S11760-021-02024-Y/FIGURES/12.
McGrath, Margaret Tuttle, 2021. Pest management [WWW Document]. Cornell Univ URL
https://www.vegetables.cornell.edu/pest-management/ accessed 8.3.22.
Musa, A., Hamada, M., Aliyu, F.M., Hassan, M., 2021. An intelligent plant Dissease detec-
tion system for smart hydroponic using convolutional neural network. Proc. - 2021
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
11
IEEE 14th Int. Symp. Embed. Multicore/Many-Core Syst. MCSoC 2021, pp. 345–351.
https://doi.org/10.1109/MCSOC51149.2021.00058.
Nandhini, M., Kala, K.U., Thangadarshini, M., Madhusudhana Verma, S., 2022. Deep learn-
ing model of sequential image classiﬁer for crop disease detection in plantain tree
cultivation. Comput. Electron. Agric. 197, 106915. https://doi.org/10.1016/J.
COMPAG.2022.106915.
Nguyen, N.D., Do, T., Ngo, T.D., Le, D.D., 2020. An evaluation of deep learning methods for
small object detection. J. Electr. Comput. Eng. 2020. https://doi.org/10.1155/2020/
3189691.
Noyan, M.A., 2022. Uncovering Bias in the Plant Village Dataset. https://doi.org/10.48550/
arxiv.2206.04374.
Oppenheim, D., Shani, G., Erlich, O., Tsror, L., 2019. Using deep learning for image-based
potato tuber disease detection. Phytopathology 109, 1083–1087. https://doi.org/10.
1094/PHYTO-08-18-0288-R.
Pathan, M., Patel, N., Yagnik, H., Shah, M., 2020. Artiﬁcial cognition for applications in
smart agriculture: a comprehensive review. Artif. Intell. Agric. 4, 81–95. https://doi.
org/10.1016/J.AIIA.2020.06.001.
Paymode, A.S., Malode, V.B., 2022. Transfer learning for multi-crop leaf disease image
classiﬁcation using convolutional neural network VGG. Artif. Intell. Agric. 6, 23–33.
https://doi.org/10.1016/J.AIIA.2021.12.002.
Qi, J., Liu, X., Liu, K., Xu, F., Guo, H., Tian, X., Li, M., Bao, Z., Li, Y., 2022. An improved YOLOv5
model based on visual attention mechanism: application to recognition of tomato
virus disease. Comput. Electron. Agric. 194, 106780. https://doi.org/10.1016/J.
COMPAG.2022.106780.
Rahman, C.R., Arko, P.S., Ali, M.E., Iqbal Khan, M.A., Apon, S.H., Nowrin, F., Wasif, A., 2020.
Identiﬁcation and recognition of rice diseases and pests using convolutional neural
networks. Biosyst. Eng. 194, 112–120. https://doi.org/10.1016/J.BIOSYSTEMSENG.
2020.03.020.
Rodríguez-García, M.Á., García-Sánchez, F., Valencia-García, R., 2021. Knowledge-based
system for crop pests and diseases recognition. Electron 10, 905. https://doi.org/10.
3390/ELECTRONICS10080905.
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A.,
Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2015. ImageNet large scale visual
recognition challenge. Int. J. Comput. Vis. 115, 211–252. https://doi.org/10.1007/
S11263-015-0816-Y.
Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., Batra, N., 2019. PlantDoc: a dataset for
visual plant disease detection. ACM Int. Conf. Proceeding Ser. 249–253. https://doi.
org/10.1145/3371158.3371196.
Singh, V., Sharma, N., Singh, S., 2020. A review of imaging techniques for plant dis-
ease detection. Artif. Intell. Agric. 4, 229–242. https://doi.org/10.1016/J.AIIA.
2020.10.002.
Stouvenakers, Gilles, Dapprich, Peter, Massart, Sebastien, Jijakli, M.H., Stouvenakers, G.,
Massart, S., Jijakli, M.H., Dapprich, P., 2019. Plant pathogens and control strategies
in aquaponics. Aquapon. Food Prod. Syst. 353–378. https://doi.org/10.1007/978-3-
030-15943-6_14.
Studer, R., Benjamins, V.R., Fensel, D., 1998. Knowledge engineering: principles and
methods. Data Knowl. Eng. https://doi.org/10.1016/S0169-023X(97)00056-6.
Subeesh, A., Mehta, C.R., 2021. Automation and digitization of agriculture using artiﬁcial
intelligence and internet of things. Artif. Intell. Agric. 5, 278–291. https://doi.org/10.
1016/J.AIIA.2021.11.004.
Weaver, W.N., Ng, J., Laport, R.G., 2020. LeafMachine: using machine learning to automate
leaf trait extraction from digitized herbarium specimens. Appl. Plant Sci. 8. https://
doi.org/10.1002/APS3.11367.
Yanes, A.R., Martinez, P., Ahmad, R., 2020. Towards automated aquaponics: a review on
monitoring, IoT, and smart systems. J. Clean. Prod. https://doi.org/10.1016/j.jclepro.
2020.121571.
Yudha Pratama, I., Wahab, A., Alaydrus, M., 2020. Deep learning for assessing unhealthy
lettuce hydroponic using convolutional neural network based on faster R-CNN with
Inception V2. 2020 5th Int. Conf. Informatics Comput. 2020. ICIC. https://doi.org/10.
1109/ICIC50835.2020.9288554.
Zheng, Y.Y., Kong, J.L., Jin, X.B., Wang, X.Y., Su, T.L., Zuo, M., 2019. CropDeep: the crop vi-
sion dataset for deep-learning-based classiﬁcation and detection in precision agricul-
ture. Sensors 19, 1058. https://doi.org/10.3390/S19051058.
R. Abbasi, P. Martinez and R. Ahmad
Artiﬁcial Intelligence in Agriculture 10 (2023) 1–12
12
