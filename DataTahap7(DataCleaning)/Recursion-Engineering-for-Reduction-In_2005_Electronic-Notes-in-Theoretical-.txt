this paper is about exploring the space of ri automata for a given grammar. we shall give examples from ansi-c, ibm vs-cobol and pascal which show that making small compromises in the amount of stack activity suppression can drastically reduce automaton size whilst not significantly affecting run time stack activity. we shall describe some heuristics that may be used to guide the specification of these automata but our main goal is to develop a tool that automatically optimises ri automaton size for a given application. we shall report on work-in-progress in the automatic derivation of these parsers giving algorithms and some preliminary indications of computational feasibility.



a technical compromise would be to place an upper bound on the levels of nesting that may be used. we can write a regular grammar for any bracket nesting language with a finite maximum nesting level simply by enumerating all the possible nestings. the size of such grammars grows rapidly so a low upper bound might need to be imposed.



a much more attractive idea is to somehow separate out the regular parts of a grammar from the parts that are truly context free: i.e. those that include fully embedded recursion in which a recursive call has both non-empty left and right contexts. ri parsing is such a technology.



reduction incorporated parsing was introduced by aycock and horspool with further development described in. their algorithm does not admit hidden left recursion. our closely-related riglr algorithm allows completely general context free grammars to be used, and we also describe an alternative automaton construction process.



in the rest of this paper we present a variety of experiments that show features of riglr behaviour that motivate our automation project. the main message is that small changes to grammar terminalisation schemes can yield big reductions in the size of ri automata without significantly impacting parse times. these experiments give at best glimpses of the overall picture: a fuller characterisation of the space of ri automata will be possible when our automated tools are complete.



in principle we could define programming language grammars in terms of individual ascii characters, but a traditional compiler usually comprises a lexical analyser that consumes tokens defined as regular sets over characters; and a parser which performs context free matching on the resulting token stream. this arrangement is attractive for several reasons: a regular lexer will usually be faster than a context free parser; segmenting the input stream into meaningful tokens can aid error reporting; and the terminal set of the parser can be large with respect to the underlying alphabet which can reduce the number of non-determinisms in the grammar.(consider, for instance an ll(1) parser for pascal which was attempting to work with individual characters: the keywords do and downto would generate a left-factoring conflict.) in addition, it is convenient to allow white space and comments to be quietly discarded by the lexer. a full character-level context free grammar for, say, c would



we can reduce the size of the automaton by adding extra terminalisations within this chain. if we break a chain of length n in the middle, we convert an exponential in n to the sum of two exponentials in n/2. we expect, therefore, that if we try adding one extra terminalisation at all the positions in the chain then we shall see a steadily decreasing size towards the middle and then an increase.



expect our profiler to perform. cobol lends itself to manual manipulation because keyword introduced statements are placed into separate rules. this makes it easy to terminalise just those parts of the grammar that relate to specific statements. in block structured languages like c and pascal, the rules are far more intertwined, rendering manual analysis ineffective. terminalisations of particular, rather than all, instances of a nonterminal are likely to be effective for c and pascal and these could also be identified via profiling.



adrian johnstone, elizabeth scott, and giorgios economopoulos. the grammar tool box: a case study comparing glr parsing algorithms. in gorel hedin and eric van wick, editors, proc. 4th workshop on language descriptions, tools and applications ldta2004, also in electronic notes in theoretical computer science. elsevier, 2004.



