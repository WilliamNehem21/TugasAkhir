pan**(a community that investigated text based tasks) started to add arabic in their gi task dataset in 2017. the approaches investigated in pan gi tasks were not specific for arabic language in addition to the low gi accuracies achieved by their proposed solutions. there is a scarcity in the work that targets gi for egyptian dialect in specific. previous work in gi investigated several



hussein, s. et al. proposed a classical machine learning approach for the gi problem considering egyptian dialect. the authors worked on extracting gender features from the text as semantic features. their proposed model considered two feature vectors; i) a mixed feature vector combining embedding vector representation and semantic features employed with random forest classifier, and ii) n-gram feature vector used with logistic regression classifier. they achieved 87.6% accuracy for the gi problem over a labeled dataset they retrieved from twitter for egyptian dialect tweets.



kodiyan et al. investigated gender detection for different languages with multiple dialects, such as english, spanish, portuguese and arabic. they investigated the validity of cnn, and the bidirectional recurrent neural network(rnn) with gru. it turns out that rnn with gru outperforms cnn in terms of accuracy. as a result, they achieved 79.03%, 72.57%, 79.5%, and 71.58% gi accuracy for english, spanish, portuguese, and arabic, respectively.



miura et al. proposed a model for word and character embedding. they considered rnn for the word embedding case, while cnn for character embedding case. additionally, the authors added multiple attention layers. the embedding layer was initialized by a model that was trained through twitter dataset. for the gi task, the average achieved accuracy for dialectical arabic was 79.17%.



deep learning has proven its success in multiple natural language processing(nlp) problems with different models and architectures. in the authors proposed nn-based models to solve the gi problem. the models were designed based on a mixture of building units that achieved good performance in several text classification tasks. for the gi problem, several architectures such as cnn, lstm have been studied in the literature and have shown great promise in solving the problem at hand. this work first starts by the simple nn models and utilizes them to solve the gi problem. afterwards, a level of sophistication is added to the nn models by combining different layers from several nn models in order to achieve higher gi accuracy. in this section, a set of nn architectures that were investigated in this work will be presented. for each nn architecture, the parameters have been fine-tuned to optimize the gi accuracy.



gru. the gru is a modified version of the lstm layer. it was initially introduced by. it consists of two gates, a reset gate, and an update gate. intuitively, the reset gate determines how to combine the new input with the previous memory, and the update gate defines how much of the previous memory to keep around. the used recurrent activation for the gates is sigmoid and the activation function for the states(hidden and output states) is scaled exponential linear unit(selu).



model 1simple artificial neural network(ann). this is a model of a simple nn architecture that consists of fully connected layers without the recourse to complex layers such as convolutional or lstm layers. it consists of an embedding layer as described in section 3.2.1.1, followed by four fully connected layers containing 80, 40, 30, and 1 node(s), respectively. a do was added with 0.15 dropping probability. the activation function for all the 2. the kernel sizes for the three channels are 2, 4 and 8, respectively. the values for the pool size and the kernel sizes are realized after several experiments to achieve the highest gi accuracy for the model. after that, for each channel, there is a bidirectional gru layer with 40 nodes. next, the output of the three channels is con-



catenated and fed to a set of two dense layers with 30, and 20 nodes respectively. the dense layers employed the relu activation function. the output layer for this model is similar to the one illustrated in the previous models.



i.e. number of layers, number of nodes per layer and activation functions. additionally, the input tweet is a single tweet with maximum length of 50 characters. the gi accuracy with do probabilities 0.05 and 0.1 is in range 70.1%+/-0.3%. in the experiment with



by adding gru layer to the existing multichannel cnn model, i.e., model 6. vi) finally, the multichannel convolutional bidirectional gru model achieves the highest accuracy in gi using edgad, which is 91.37% for 12 concatenated tweets and 140 input length.



since the work in this field is still in its initial phases, the experiments can be extended to investigate the images posted by each account. the input vector for the nn models can be extended to include language specific features for gi i.e. usage of female suffixes and prefixes.



