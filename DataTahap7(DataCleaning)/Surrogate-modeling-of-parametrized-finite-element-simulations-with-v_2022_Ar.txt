a machine learning based strategy is proposed for creating parametric surrogate models from parametrized finite element model simulation results. in the first major step, a unified nodal data structure is created from the topologically inhomogeneous set of finite element simulations. this is achieved by utilizing re-sampling and the coherent point drift method for node registration of the different designs. in the second major step, a parametric surrogate model is trained for predicting the initial coordinates using a fully-connected feed-forward neural network. two different recurrent neural network modeling approaches are presented and compared for the prediction of various field quantities with different degrees of complexity and non-linearity.



for the first proposed modeling approach, a node-by-node prediction is applied, where the time series of each structural node is predicted independently via a compact long-short term memory(lstm) model. for each node, the initial coordinates of the node are used as additional input features. for the second modeling approach, an all-at-once prediction is applied, where the time series of all structural nodes are predicted at once by training an lstm model on a reduced output space obtained by principal component analysis(pca).



large set of simulation results in a graphical post-processor is tedious and time-consuming for the engineer. furthermore, it has to be noted that a technical solution usually has to meet several criteria, e.g. manufacturability, accessibility, order of assembly, etc. hence, is often difficult to express the underlying engineering optimization problem in terms of a cost function in advance. a parametrized solution of the investigated simulation series is sought to allow for fast decision making, which enables a quick(real-time) manual assessment of the structural response depending on the feature parameter values.



a corresponding parametrized surrogate model maps the input features to the observed responses of the simulated doe in a generalized way, such that valid predictions within the trained domain can be obtained. several methods for creating surrogate models can be found in the literature. for many of these methods, dimensionality reduction plays a role in order to increase the computational efficiency. a comprehensive summary on dimensionality reduction methods is provided in ref.. due to its simplicity, linear dimensionality reduction methods such as the proper orthogonal decomposition(pod), also referred to as principal component analysis(pca), have been employed in conjunction with interpolation methods for fluid dynamics



in, a method for learning the time evolution of physical structures is developed using structure-preserving neural networks(spnn), which comply with the first and second principles of thermodynamics without previous knowledge on the nature of the system. in ref., the time evolution of a mechanical structure is predicted using sparse auto-encoders for model reduction and a spnn.



in, an lstm model is applied for predicting the time-dependent structural deformation response of a parametrized fe structure including bifurcation phenomena. in ref., the features of an fe structure with hidden geometrical and numerical parametrization are revealed in an unsupervised manner using a convolutional neural network autoencoder(cnn-ae), where the corresponding latent space vector is then passed to an lstm model for prediction of the time-series response of the whole structure.



ond major step, various time series responses of the unified fe structure are predicted and represented on top of the previously predicted initial coordinates point cloud. two different modeling approaches for the time-series prediction are investigated and compared, referred to by the node-by-node and the all-at-once approaches. the approaches are compared to corresponding finite element simulation data to access accuracy and predictability, and are also assessed with respect to model training time and model evaluation time.



in section 2, the investigated load case is discussed. in section 3, the parametric solution approaches for the initial coordinates and the timeseries predictions are discussed. in section 4, the parametric solution approaches are compared to the finite element simulation results used for training. the node-by-node approach is also applied to unseen validation sets and used to reveal yet undetected response patterns. section 5 concludes the paper.



it is noted that in contrast to the node-by-node approach, the initial coordinates are not used as input features for the all-at-once approach. the architecture of the lstm and time-distributed dense layers is identical to the node-by-node approach, where a gaussian dropout layer is applied after the lstm cell. the real values of the input feature vector xgeomfeatures are scaled into the range[0, 1] in advance.



again it is noted that the chosen size of the output vector of the lstm cell, ht, defines the size of the cell state parameters ct and the size of the corresponding weights and biases. for the all-at-once model, all timeseries quantities to be learned from the doe data, e.g. disp, epmx or pnck, refer to the corresponding initial coordinate locations.



training preparation: for all predicted outputs, the lstm utilizes 128 units(size of the output vector ht) and a linear output activation function f d. the doe for the time series prediction comprises 10 designs. for the all-at-once network architecture, the time series of a complete design is predicted conjointly in one step.



analysis of the dimensionality reduction process, section 3.2.2, the low overall value for the pnck indicates the expected poor generalization of the trained network. the all-at-once model is re-trained using all available data over the same number of epochs. the results of the all-at-once model are discussed in section 4.



dimensionality reduction: as mentioned in section 3.2.2, the dimensionality reduction for the pnck output revealed a poor r2 value for the validation set, indicating that the pca does not create a generalized dimensionality reduction. the pnck response of the two-moving-holes example is characterized by very narrow zones of high pnck values surrounded by large domains of zero or close-tozero values. a dimensionality reduction method aims to maintain the bulk of information, and the high pnck values in the narrow zones are partially considered outliers and are eventually dropped in the truncated representation without losing a significant amount of explained variance.



is performed at feature values of posx= 5.0 mm and posy= 5.0 mm. then, the position of the large hole is increased posx={6.0, 7.0, 9.0, 10.0} mm over a series of simulations while keeping the position of the small hole constant at posy= 5.0 mm. finally, the position of the large



hole is kept constant at posx= 10 mm, and the position of the small hole is varied over a series of fe simulation: posy={5.5, 6.0, 6.5, 7.0} mm. the final pnck field of these validation fe simulations are shown in



an overall poor prediction is obtained for the all-at-once approach. in the prediction, the different crack modes are not separated properly. several crack patterns are predicted simultaneously and the level of the pnck values is significantly lower than in the ground truth fe simulations.



by-node approach. the all-at-once approach did not provide satisfying predictions of pnck. investigation of the input feature parameter space using the node-by-node approach revealed the existence of a new crack pattern, which has not been observed in the underlying available doe data. the new crack pattern could be confirmed by running an fe simulation using the identified feature parameter values, supporting the generalization of the trained node-by-node model.



limitations of the all-at-once approach: the initial coordinates, which are used as additional local input features for the node-by-node approach, provide crucial additional information for network generalization. these local features cannot be used for the presented global allat-once approach, which can only establish global relations(interpolations) between the snapshots(designs) it has seen during the training. in contrast to the all-at-once approach, the node-by-node approach allows independent(uncoupled) learning of the time-series of individual nodes, depending on their initial coordinates.



coherent point drift(cpd) is an elastic point set registration method. it is used to transform a source point cloud to a similar, but not identical, target point cloud, while maintaining the underlying topological structure. a complete description is provided in ref.]. below, the basic cpd algorithm is briefly revisited.





