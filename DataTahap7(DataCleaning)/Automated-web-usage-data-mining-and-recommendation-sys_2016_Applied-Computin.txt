abstract the major problem of many on-line web sites is the presentation of many choices to the client at a time; this usually results to strenuous and time consuming task in finding the right product or information on the site. in this work, we present a study of automatic web usage data mining and recommenda- tion system based on current user behavior through his/her click stream data on the newly developed really simple syndication (rss) reader website, in order to provide relevant information to the individual without explicitly asking for it. the k-nearest-neighbor (knn) classification method has been trained to be used on-line and in real-time to identify clients/visitors click stream data, matching it to a particular user group and recommend a tailored browsing option that meet the need of the specific user at a particular time. to achieve this, web users rss address file was extracted, cleansed, formatted and grouped into meaningful session and data mart was developed. our result shows that the k-nearest neighbor classifier is transparent, consistent, straightforward, simple



data mining system can be classified using different criteria. jiawei and micheline [13], identified these criteria as kind of database mined, kind of knowledge mined, type of technique utilized and according to type of application adapted. federico and pier [9], stated further that in web usage data mining task, different techniques can be adopted, but the issue is how to determine which technique is most appro- priate for the problem at hand. a multiple approach or an integrated technique that combines the benefits of a number of individual approaches can be adopted by a comprehensive data mining system [28]. [13,15,16], stated that there are dif- ferent techniques for data classification which includes; decision tree classifier, bayesian classifier, k-nearest neighbor classifier, and rule base classifier. in our work, the k-nearest neighbor classification method was adopted.



decision tree: the use of classification and regression tree (cart) was adopted by amartya and kundan [1] in their work. in constructing a decision tree, they applied both the gini index(g) and entropy value (ei) as the splitting indexes, the model was experimented with a given set of values, different sets of results were obtained for both the outlook, humidity, windy, temp, and time for execution. the result of the experiment shows that the best splitting attribute in each case was found to be outlook with the same order of splitting attributes for both indices.



the som model: self organizing map (som) or kohonen neural network model was explored by xuejuu et al. [30], in their work, to model customers nav- igation behavior. the model was used to create clusters of queries based on user session as extracted from web log with each cluster representing a class of users with similar characteristics, in order to find the web links or product of interest to a current user on a real-time basis. the experimental result of the som model performance was compared with that of k-means model, and the som model was found to outperform the k-means model with value of correlation co-efficient of som model scoring twice that of k-means result.



bayesian classifier model: decision rule and bayesian network, support vector machine and classification tree techniques were used by rivas et al. [27], to model accidents and incidents in two companies in order to identify the cause of accident. data were collected through interview and modeled. the experimental result was compared with statistics techniques, which shows that the bayesian network and the other methods applied are more superior than the statistics technique. rivas et al. [27], stated further that the bayesian/k2 network is of advantage as it allows what-if analysis on data, which make the data to be deeply explored.



the k-nearest neighbor (k-nn) algorithm is one of the simplest methods for solving classification problems; it often yields competitive results and has signifi- cant advantages over several other data mining methods. our work is therefore based on the need to establish a flexible, transparent, consistent straightforward, simple to understand and easy to implement approach. this is achieved through the application of k-nearest neighbor technique, which we have tested and proved to be able to overcome some of the problems associated with other avail- able algorithms. it is able to achieve these by the following:



data pre-processing: in the original database file extracted, not all the informa- tion are valid for web usage data mining, we only need entries that contain rele- vant information. the original file is usually made up of text files that contains large volume of information concerning queries made to the web server in which in most instance contains irrelevant, incomplete and misleading information for mining purpose [30,11]. resul and ibrahim [26], described data preprocessing as the cleansing, formatting and grouping of web log files into meaningful session for the sole aim of utilizing it for web usage mining.



the problem at hand is a classification problem, therefore the k-nearest neighbor method of data mining is ideal. the objective of the system is to create a mapping, a model or hypothesis between a given set of documents and class label. this mapping was later to be used to determine the class of a given test(unknown or unlabeled) documents [31]. the k-nearest neighbor model is the simplest and most straightforward for class prediction, it is the most popular similarity or distance based text and web usage classification and recommendation model [31].



let xi be an input tuple with p features (xi1, xi2, .. ., xip) let n be the total number of input tuples (i = 1, 2, .. ., n) let p be the total number of features (j = 1, 2, .. ., p)



a categorical attribute is a nonnumeric attribute such as color and object name. to calculate the distance, we simply compare the corresponding values of the attri- butes in tuple x1 with that of x2, if the values are the same, then the difference is taken to be zero(0), otherwise the difference is taken to be one(1). for instance, if two users, x1 and x2 click stream on the rss reader site is both sport news cate- gory, then the difference is zero(0), but if tuple x1 is sport and tuple x2 is politics, then the difference is taken to be one(1) [13].



this section evaluates our system by applying the result of the experiment con- ducted. the result was presented and analyzed in order to evaluate the quality of our recommendation system based on k-nearest neighbor classification model. in the previous section we established that a class with minimum distance to the test tuple will be predicted for 1-nn or in case ties exist, the weighted dis- tance predict a class with greater weighted distance as in 5-nn in example 1 and recommendation will be made based on this, for user with unknown class.



