this paper addresses an optimization problem arising in the market for computer services. a service provider employs a cluster of servers in order to offer a number of different services to a community of users. the users pay for having their jobs run, but demand in turn a certain quality of service. more precisely, a user wishes to submit a specified number of jobs of a given type, at a specified rate(jobs per



in addition, there is an energy consumption cost associated with each running server. the provider thus faces a difficult trade-off: energy costs are minimized by keeping the number of servers powered up as low as possible, while revenues are maximized by using as many servers as possible in order to be able to accept incoming streams and avoid paying penalties. it is therefore desirable to employ dynamic policies for deciding when to power servers on and off and whether to admit incoming streams or not. moreover, those policies should react appropriately to changes in demand. note that even when there is sufficient service capacity to serve a stream, it may be advisable to reject it if the likelihood of paying a large penalty is high enough.



there is an extensive literature on both server allocation and energy-saving topics. however, the particular problem considered here does not appear to have been studied before. perhaps the most closely related work is by mazzucco et al[9,10,11] and mitrani. the concepts of charge, obligation and penalty were defined in and were applied to individual jobs(rather than to streams). the notion of a user stream was introduced in. that paper examined the allocation of servers between different types of users, but did not consider the costs of providing the servers and the desirability of dynamically powering them up and down. the latter aspects were studied in and, without addressing the economics of user streams and the admission policies associated with them.



n. b. it is worth emphasizing that the right-hand side of(2) is a random variable; its value depends on every job that belongs to the stream. hence, even if all interarrival and service times are distributed exponentially, one would have to include quite a lot of past history into the state descriptor in order to make the process markov. this remark explains why some of the approximations that follow are really unavoidable.



the times taken to power servers up or down are assumed to be small compared to the lifetime of a stream and will be neglected. also, it is assumed that the intervals between consecutive policy decision instants are large compared to individual job interarrival and service times. that is, enough jobs arrive and are served during such an interval to enable the system to be treated as having reached steady state.



the value of ca2 will be taken as 1(i.e., assume that the arrival processes of both streams and jobs within a stream are reasonably close to poisson). that assumption is not essential, but if it is not made, some mechanism of estimating ca2 would have to be provided.



to compare the performance of the current state, simple and default policies, a number of simulation experiments were carried out. in all cases, the profits achieved by the three policies in a system where the total number of servers is n= 40, are plotted against the stream arrival rate. each point in the graphs corresponds to a simulation run where more than a million jobs arrive and are served. each run is divided into 10 portions and the observations corresponding to those portions form a sample for the purpose of computing confidence intervals.



type. then there would be a separate queue for each stream type. as well as deciding how many servers should be powered up, one would have to decide how many of the active servers should be allocated to each queue. in addition, there could be a cost associated with switching an operative server from one queue to another. that would also be an interesting topic of future research.



