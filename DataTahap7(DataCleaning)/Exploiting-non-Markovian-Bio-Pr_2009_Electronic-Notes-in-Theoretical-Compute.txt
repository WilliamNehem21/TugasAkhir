the stochastic simulation algorithm(ssa) is a milestone in the realm of stochastic modeling of biological systems, as it inspires all the current algorithms for stochastic simulation. essentially, the ssa shows that under certain hypothesis the time to the next occurrence of a biochemical reaction is a random variable following a negative exponential distribution. unfortunately, the hypothesis underlying ssa are difficult to meet, and modelers have to face the impact of assuming exponentially distributed reactions besides the prescribed scope of applicability. an opportunity of investigation is offered by the use of generally distributed reaction times.



the paper is organized as follows. sect. 2 gives a brief tutorial on blenx, a process calculi inspired programming language designed for modeling biological systems, and we comment on how general distributions have been managed. then, sect. 3 discusses the impact of assuming abstract reactions as exponentially distributed through a few biological examples of increasing complexity. finally, sect. 4 exploits the capability of models including generally distributed reaction times.



the betawb framework is a computational tool that supports textual and visual programming with blenx. the betawb can be seen as an in-silico laboratory, where(in-silico) experiments can be designed(i.e., a blenx program is written), simulated and analyzed. the quantitative component of the experiments is guaranteed by the stochastic capability of blenx, on the line of, where a continuous-time markov process is taken as foundational quantitative model. this section provides an introduction to the visual version of blenx and introduces the formal tools for managing non-markovian processes.



the primitive x!(sig) sends a signal sig through interaction site x: ide. replication rep assures that the process sends a signal each time it is needed, i.e., each time substrate and enzyme interact. the primitive x?(sig) waits a signal on the interaction site x: ids that enables the change of the type in idp by means of ch(x, idp).



means that type ide and ids, expressed by boxes e and s respectively, may bind with a rate of 0.5. the rate is the unique parameter of a negative exponential distribution that describes the stochastic behaviour of the action. the other two values in the tuple(1) are the rates for decomplexing and interacting and will be commented later in this section. the tuple(1) allows inferring the following evolution of the system e s:



that prescribes that each time the types ide and idp are bound they have to unbound immediately, represented by the key-word inf(i.e. infinite rate). the zeros in the third and fifth position means that types ide and idp cannot bind and cannot interact if they are bound. the tuple(2) allows inferring transition[t5]:



we conclude this brief tutorial on the blenx language introducing events. the primitives we describe above work with elementary reactions, but, as we already pointed, it is difficult to describe biological systems only in terms of elementary reactions. events specify transitions that are not elementary reactions. here we consider two classes of events, namely join and split. the join event[e1] is enabled when a box b1 and a box b2 are available. the left part in brackets of the event is called condition, while join(b) is called verb.[e1] removes boxes b1 and b2 and adds a box b. the duration of the transition is specified by the rate parameter e1 value, as usual, the unique parameter of a negative exponential distribution. the split event[e2]



event[e3] uses a tricky version of event[e2]. in fact, the second output box nil is the blenx representation of an empty system and therefore event[e3] transforms box b into box s with rate 0.0078. note that the blenx language offers a richer set of primitives w.r.t. the ones presented here; for a detailed description of the full language we refer the reader to.



since blenx is rooted into process calculi theory, we look at process calculi for including general distributions support. general distributions are not memoryless, that is the probability distribution of a transition is not independent from the transitions already happened. therefore, general distributions introduce the problem of tracking the time consumed by each transition, since this influences the probability distributions of the transitions that are going to be executed. the problem was faced by the process calculi community following three main approaches, namely, counters, st semantics, and enhanced operational semantics.



the semantics of tipp uses counters to track how many times an action has not been selected to happen, and adjusts probability distribution accordingly. the approach taken in integrates clocks into models and expresses clocks start and clocks termination events through the use of an st semantic; in this way dependency between transitions can be considered. finally, in the reach labels of the enhanced operational semantics allow to derive the firing distributions of enabled transitions. we adopt this last approach mainly because enhanced operational semantics can be also used besides the scope of general distributions to retrieve interesting biological information as causality and locality. the details about the enhanced semantics of blenx and how general distributions are derived can be found in. here we only sketch the general ideas rephrasing the example above. suppose to have a system with two instances of product box p, say p1 and chosen and executed. memoryless property of exponential distributions assures that the time of transition[t6]2 does not depend on the time t1 consumed by[t6]1. in a general setting memoryless does not hold and the time distribution of[t6]2 is influenced by the time consumed by[t6]1. enhanced operational semantics allows defining causality: a transition[ti] causes a transition[tj] if[tj] cannot be executed before[ti]. the notion of causality supports enabling memory discipline, namely the stochastic distribution of the time consumed by a transition[t] must be influenced by all the transitions fired from the states where[t] was first enabled. therefore, the runtime support of blenx is extended to support causality and enabling memory discipline. in particular, inspired by, we implemented an ad-hoc extension of the blenx stochastic simulator engine based on classical optimized discrete event simulator solutions. from a user point of view, the extended version of blenx allows to specify also general distributions and not only unique rate parameters. for instance, event[e3] can be extended as:



events[e3 1] and[e3 2] have the same qualitative behaviour of[e3], but different time distributions. in particular[e3 1] has associated a gamma distribution with shape 2 and scale 64.1, while[e3 2] is distributed as an hyperexponential, i.e., the sum of two exponentials with rates 0.003 and 0.01, and weight 0.12879 and 0.87121,



respectively. playing with general distributions lets to test different hypothesis for, e.g., the pathway that leads to box s from box p. next section builds on this example and gives some insight about the use of general distributions for modeling complex biological systems.



in this section we introduce a few examples of biological systems that include abstract reactions. we present their modeling within the extended blenx language and the results obtained via the extended stochastic simulator 3. the purpose of this few case studies is twofold: they allow quantifying the impact of assumptions such as supposing all the reactions as elementary; and they provide the basis for further discussing the advantages offered by the inclusion of generally distributed reaction times into models.



in particular, we refer to one of the models presented in from which we take all the quantitative parameters. in the blenx model we implemented, each element composing the network is represented as a box; we have a box d representing the dna string, a box dr representing the complex of the dna with a dna polymerase r,a box m representing the mrna, the box p representing the protein p expressed, a box p2 representing the protein p dimer and finally a box q representing the complex of the dimer and the dna, i.e., the dna inhibition. all the chemical reactions reported in can be translated simply in blenx using events. we have the transcription, translation, and the decay of the mrna and of the protein p which we describe using, respectively, events:



it is an easy guess to conjecture that complex non-linear systems such as the biochemical ones can be sensitive to variances of event occurrence times: we provided some evidence for it with three simple examples. unfortunately, assuming a negative exponential distribution of every reaction occurrence time limits the possibility of defining accurate models of non-elementary transformations, as there is no lever to match statistical properties of phenomena beyond their expected occurrence times. an important implication of this limitation is that, to make models to fit wet-lab data, the rates of reactions may need to be changed to unrealistic values. consider for instance the third example provided in the previous section. in the gene regulatory network model that uses general distributions, to fit an observed steady-state level of protein expression, one can tune the variance of a transcription distribution without changing its expected value. however, if modelers assume elementariness of every reaction, the only possibility left to match experimental data is to change their rate constants.



an interesting modeling facet that surely deserves to be subject of future work is the exact representation of the competition among reactions. in fact, this is quite a delicate area of modeling, whose importance becomes evident when dealing with general distributions. consider for example the transcription relation in example 3.3. obviously, the first stage of the transcription process is in competition with the polymerase decomplexation reaction. however, if we model the whole transcription process as a single elementary reaction, we cannot limit the scope of this competition to the first stage only. thus, it would be like saying that the polymerase could decomplex from dna and stop gene transcription at any time during the process, which is not realistic. indeed, this extended competition is what is actually modeled for the example 3.3 in the literature as well as in the model variants presented in this paper that used generally distributed transcription times. this shortcoming of abstract reaction modeling is encountered whatever is the distribution used to model the transcription time. however, when we explicitly consider the multi-stage nature of the transcription process, for instance in the form of an erlang distribution, we have a degree of freedom in playing with the preemption at the various stages of the process. thus, we could specify that only the first stage of the erlang can be preempted because of the competition with the polymerase unbinding reaction. it is clear that the opportunities offered by this refined modeling only become available when considering the details of the staged nature of abstract reactions, and thus only in a framework that allows going beyond the pure elementariness of biochemical reactions.



the ssa algorithm is the de-facto standard for simulating the dynamic evolution of systems of stochastic reactions. ssa assumes elementary reactions and therefore the time to the next reaction is a random variable following negative exponential distribution. however, it is difficult to describe complex biological systems only in terms of elementary reactions. quite often there is an incomplete knowledge of the full set of reactions comprising the systems under inspection. thus, researchers have to introduce abstract reactions in their models, without considering the impact of using ssa like algorithms with abstract reactions. this calls for an investigation of the dichotomy of the qualitative abstract reactions and the quantitative elementariness assumed in the simulation algorithms.



we started by extending the modeling language blenx and the associated computational framework betawb with general distributions. blenx allows including in the same model different levels of(qualitative) abstraction and so it is well suited to be tested in an environment with general distributions. here we described the general ideas underlying blenx and its extension in a tutorial fashion, pointing the interested reader to. then, we described three examples that present an increasing complexity. the examples resulted sensitive to variances of reaction occurrence times as non-linearity and complexity of the system increase. moreover, the extension presented can help in providing better matching between wet-lab experiments and in-silico results.



