biomolecular computation frameworks. we will see that the turingtypical asymptotic slowdowns can be avoided while using a biomolecular computing model. this provides an advance over both earlier work on automata-based computation models(turing machines, counter machines, etc.), and over some other



a number of contributions exist in this area; a non-exhaustive list:[1,3,7,10,8,11,12,17,20,21,25,26,30,31,5,33] the list is rather mixed: several of the articles describe concrete finite-automaton-like computations, emphasising their realisation in actual biochemical laboratory contexts. as such their emphasis is not on general computations but rather on showing feasibility of specific computations in the laboratory. articles[7,8,12,20,33] directly address turing completeness, but the algorithmic or programming aspects are not easy to see.



what do we mean by a program(roughly)? an answer: a set of instructions that specify a series(or set) of actions on data. actions are carried out when the instructions are executed(activated,...) further, a program is software, not hardware. thus a program should itself be a concrete data object that can be replaced to specify different actions.



how to show turing completeness of a computation framework. this is typically shown by reduction from another problem already known to be turing complete. notation: let l and m denote languages(biological, programming, whatever), and let[p]]l denote the result of executing l-program p, for example an input-output function computed by p. then we can say that language m is at least as powerful as l if



a popular choice is to let l be some very small turing complete language, for instance minsky register machines or two-counter machines(2cm). the next step is to let m be a biomolecular system of the sort being studied. the technical trick is to argue that, given any l-instance of(say) a 2cm program, it is possible to construct a biomolecular m-system that faithfully simulates the given 2cm.



there can be no pointers to data: addresses, links, or unlimited list pointers. in order to be acted upon, a data value must be physically adjacent to some form of actuator. a biochemical form of adjacency: a chemical bond between program and data.



on the other hand there exist available biochemical resources to tap, i.e., free energy so actions can be carried out, e.g., to construct local data, to change the program control point, or to add local bonds into an existing data structure. biological analogs: brownian movement, atp, oxygen.



the above constraints suggest how to structure a biologically feasible model of computation. the main idea is to keep both program control point and the current data inspection site always close to a focus point where all actions occur. this can be done by continually shifting the program or the data, to keep the active program blob(apb) and active data blob(adb) always in reach of the focus. the picture illustrates this idea for direct program execution.



in addition each blob has 8 cargo bits of local storage containing boolean values, and also identified by numerical positions: 0, 1, 2,..., 7. when used as program, the cargo bits contain an instruction(described below) plus an activation bit, set to



a specific instruction set(a bit arbitrary). the formal semantics of instruction execution are specified precisely by means of a set of 128 biochemical reaction rules in the style of. for brevity here, we just list the individual instruction formats and their informal semantics. notation: b is a 2-bit bond site number, c is a 3-bit cargo site number, and v is a 1-bit value.



note: the apb-adb bond* has moved: before execution, it connected apb with adb. after execution, it connects apbj with adb, where apbj is the next instruction: the successor(via bond s) of the previous apb. also note that the activation bit has changed: before, it was 1 at apb(indicating that the apb was about to be executed) and 0 at adbj. afterwards, those two bit values have been interchanged.



data may move about, e.g., rotate as needed to keep their contact points adjacent(the apb and the adb). for now, we shall not worry about the thermodynamic efficiency of moving arbitrarily large program and data in this way; for most realistic programs, we assume them to be sufficiently small(on the order of thousands of blobs) that energy considerations and blob coherence are not an issue.



there is certainly a close analogy between blob programs and a rudimentary machine language. however a bond is not an address, but closer to a two-way pointer. on the other hand, there is no address space, and no address decoding hardware to move data to and from memory cells. an instruction has an unusual format, with 8 single bits and 4 two-way bonds. there is no fixed word size for data, there are no computed addresses, and there are no registers or indirection.



the usual programming tasks(appending two lists, copying, etc.) can be solved straightforwardly, albeit not very elegantly because of the low level of blob code. appendix a shows how to generate blob code from a turing machine, thus establishing turing-completeness.



all instructions are currently in use in the self-interpreter, indeed all instructions appeared to be necessary in programming it. with the possible(but, we believe, unlikely) exception of the various swap instructions(swl, sbs, swp1, swp3), we conjecture the instruction set to be parsimonious in the sense that no proper subset of the instruction set can be used to simulate the remaining instructions. a possible formal proof is being investigated.



the usual turing machine has a fixed number of 1-dimensional tapes(though kdimensional versions exist, for fixed k). cellular automata as in[29,8,32] havea fixed 2-dimensional architecture. dimensionality questions are not relevant to minskystyle machines with a fixed number of registers, e.g., the two-counter machine.



indeed so large that dimensionality makes no difference: on any traditional model where data dimensionality makes sense, it would be an easy exercise to show that ptime= ptime3d. what if instead we study the class lintime of problems solvable in linear time(as a function of input size)? alas, this smaller, realistically motivated class is not very robust for turing machines, as small differences in turing models can give different versions of lintime(sections 18, 19, 25.6 in). it seems likely though that the lintime class for blob machines is considerably more robust.



