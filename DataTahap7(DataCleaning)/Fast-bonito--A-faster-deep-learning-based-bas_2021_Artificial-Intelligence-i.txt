the neural network backbone of bonito is inspired by quartznet [13], which was originally developed for speech recognition, so we thought it might not be the best neural network architecture for trans- lating raw electronic signals into bases. we also investigated into the bonito neural network architecture to find potential bottlenecks limit- ing its performance. the neural network backbone of bonito consists of multiple tcsconv-bn-relu modules. each tcsconv-bn-relu mod- ule consists of several time-channel separable convolutions (tcsconv), a batch normalization (bn) layer, and a relu activation function. al- though this architecture reduces the number of parameters of the model dramatically, the inference engine library for the hardware is not well written, which slows it down to some extent.



the search space defines the controller module in the nas approach. a sample-eval-update loop [16] is used to train the controller. at each step, a batch of models are sampled from the controller. each model is trained for several epochs in the trainer module, and then its infer- ence latency and accuracy will be measured. after computing the multi- objective reward by accuracy and latency, the reward set as the input of the controller and its parameters are updated by maximizing the ex- pected reward.



the bonito version used in this study was 0.2.3. fast-bonito was also developed using the same training and validation datasets. bonito is still an active project that keeps releasing new features. we will also continuously update fast-bonito with the new bonito features in the future.



