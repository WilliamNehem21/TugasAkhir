the neural network backbone of bonito is inspired by quartznet, which was originally developed for speech recognition, so we thought it might not be the best neural network architecture for translating raw electronic signals into bases. we also investigated into the bonito neural network architecture to find potential bottlenecks limiting its performance. the neural network backbone of bonito consists of multiple tcsconv-bn-relu modules. each tcsconv-bn-relu module consists of several time-channel separable convolutions(tcsconv), a batch normalization(bn) layer, and a relu activation function. although this architecture reduces the number of parameters of the model dramatically, the inference engine library for the hardware is not well written, which slows it down to some extent.



the search space defines the controller module in the nas approach. a sample-eval-update loop is used to train the controller. at each step, a batch of models are sampled from the controller. each model is trained for several epochs in the trainer module, and then its inference latency and accuracy will be measured. after computing the multiobjective reward by accuracy and latency, the reward set as the input of the controller and its parameters are updated by maximizing the expected reward.



the bonito version used in this study was 0.2.3. fast-bonito was also developed using the same training and validation datasets. bonito is still an active project that keeps releasing new features. we will also continuously update fast-bonito with the new bonito features in the future.



