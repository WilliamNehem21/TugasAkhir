botnet is an organized network of distributed and infected computers(zombies) executing malicious codes called bots, under the remote command of a human originator called botnetmaster. the evolution of the internet has played host to a network of distributed and compromised computers. hence, the use of the internet attracts certain risks which make botnet one of the key issues in internet security.



users to exploit[2,3]. increasingly, malicious users are constantly developing more advanced methods to profit from cybercrime activities[4,5]. this occurrence has led to the design and implementation of a distributed architecture of remotely controlled networks of infected hosts, called botnets, for performing malicious activities. with a single command from a command and control(c&c) server, botnetmaster can control networks of vulnerable hosts[6,7,8]. botnetmaster usually performs maintenance and update of their c&c set-up on fast-flux service network(ffsn) to make the detection of bots difficult.



ffb detection is a traditional machine learning task where the features of an instance are fed to a classifier and the classifier attempts to detect the class membership of that instance. however, unlike common classification tasks where the feature set is fixed, ffb detection demands that the researcher learns new features or adopt known reliable existing subsets based on the literature[12,13,14]. a number of botnet detection systems(bds) have been developed, but the identification, adoption, and merger of reliable features for detection still remains a problem. this is because most of the botnet detection systems are limited in accuracy due to the unreliable nature of the existing features[15,16,3,17]. secondly, the inability of a bds to deal with botnetmaster constant evasion mechanisms to masquerade the operations of legitimate internet devices[18,17]. evasion mechanisms are the different techniques adopted by botnetmaster to make the detection of their bots difficult. these techniques include advertizing the ip addresses of several zombies as phishing web servers and performing update operations on the c&c server.



honeynet is a collection of simulated servers called honeypots on a physical server. the honeypots are loopholes that are intentionally introduced to motivate attackers to attack the system. the main purpose is to gather bot signatures and mechanisms of the c&c server. the honeynet-based detection usually generates a report regarding the detected bot signatures to better understand the penetration mechanisms of the botnet. however, the damages caused by the botnet are not always detected. honeypots can be classified as low-interaction and high-interaction honeypots based on their simulation capability. the low-interaction honeypots allow partial penetration to the attackers through the simulation of a few features that define the real system. in other words, low-interaction honeypots limit the accessibility of the attackers to the real system through controlled features. for example, provos presented a low interaction honeypot framework called honeyd. the framework simulates virtual honeypots with thousands of ip addresses at the network level. the developed honeyd showed high security capability in botnet detection and prevention. on the other hand, the high-interaction honeypots allow full penetration to the attackers through the simulation of all features of the real system. in other words, high-interaction honeypots allow full accessibility of the attackers to the real system through uncontrolled features. for example, vrable et al.



employed normal traffic for training. the method consists of two detectors which profile and analyze the anomaly behavior with increased accuracy and reduced false alarms compared to traditional anomaly detectors. martinez-bea et al. proposed a hybrid real-time fast-flux detection model by building a linear svm classifier that merged the feature sets of both mcgrath et al.



proposed a dns rule-based method for botnet detection. the method applied dns query and response rules to detect any anomaly dns query and response activities. the proposed method showed an improved accuracy and low false alarm rate for botnet detection. for further studies on dns-based detection, literatures such as[53,54,55,56] are recommended.



mining-based detection uses several data mining and machine learning algorithms to detect botnet c&c traffic. for example, ibrahim et al. proposed a multilayer framework that consists of filtering and detection modules for botnet detection. the filtering module was to filter and reduce the number of network features and group the network traffic in the minimum time interval. the detection module then used the reduced network features for botnet detection based on a multilayer framework. the result showed that the proposed method can detect botnet with good accuracy. for further studies on mining-based detection, literatures such as[58,59,60,61] are recommended.



proposed a set of heuristics methods to detect dns-based black-hole list(dnsbl) lookup queries executed by a botmaster to know whether their bot have been blacklisted. the proposed heuristic method was able to provide counter intelligent measures to the methods used by botmasters to determine blacklisted bots. the goal of the proposed heuristic model is to detect in real-time dnsbl queries executed by botmasters from legitimate dnsbl queries. however, the proposed heuristic model cannot handle distributed dnsbl queries by botmaster.



k-nearest neighbor(k-nn) is one of the simplest of all machine learning techniques. it is regarded as the traditional nonparametric technique in pattern recognition for the categorization of data[68,69]. it classify and assigns objects to the modal class of its predefined nearest neighbors. k represents the number of predefined nearest neighbors for an object and denotes a vital factor that determines the performance of the classifier. different k-values will trigger different performances in the classifier and thus a considerably small positive integer is needed for k-value. a big and even number k-value can adversely affect the classification time and impact the prediction accuracy, while a small and odd number k-value can increase the prediction accuracy. k-nn is termed instance-based learning because of its peculiarity compared to the inductive learning methods. thus, k-nn as an instancebased learning, does not include a model training phase, instead it determines the instances of input attributes and classifies new instances based on the determined k-nearest neighbor of the new instance.



tion of several ip addresses of the domain. researchers such as knysz et al., and hsu et al. revealed that the ip addresses of botnet domains increased rapidly after the first dns query. this phenomenon is adopted by botnetmasters to evade real-time detection solutions that focus on 1 dns query for the accumulation of domain ip addresses.



detector: the c4.5 decision tree was built to automatically generate the detection rules for the k-nn. the detector computes genetic threshold value(gtv) for ip addresses using the gakd-k-nn algorithm. it performs detection based on the decision tree rules and the gtv using k-nn distance measure as in(4). the knn used kd tree for the search of k-values. the manhattan distance was adapted because of its suitability for high dimension-



the testing dataset was tested with three machine learning algorithms namely: genetic algorithm and k-nearest neighbors(ga-k-nn), k-nn and support vector machines(svm). the justification for this evaluation is to determine the learning algorithm that best suits the detector. the svm algorithm was implemented with the aid of libsvm. the performance of these algorithms was evaluated in terms of false positive rate(fpr), false negative rate(fnr), true positive rate(tpr), true negative rate(tnr) and accuracy.



the developed bot-ffx showed overall performance with oa of 99.178%, fpr of 0.8%, and fnr of 0.8%. this result shows the positive contribution of bot-ffx for botnet attack classification with reduced false alarm rate. the reduced false alarm rate was due to the ability of the bot-ffx to clearly differentiate between botnet and benign domains using the adopted attributes.



