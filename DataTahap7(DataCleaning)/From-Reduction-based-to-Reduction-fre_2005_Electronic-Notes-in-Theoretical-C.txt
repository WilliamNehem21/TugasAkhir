deforest the intermediate term by replacing the composition of the decomposition function and of the plug function by a refocus function that directly maps a reduction context and a contractum to the next reduction context and redex, if there are any. such a refocused normalization function(i.e., a normalization function using a refocus function instead of a decomposition function and a plug function) can be viewed as an abstract machine.



it is our experience that starting from a reduction semantics for a language of terms, we can refocus the corresponding reduction-based normalization function into an abstract machine, and refunctionalize this abstract machine into a reduction-free normalization function. we have successfully tried this construction on the lambda-calculus, both for weak-head normalization and for full normalization. the goal of this article is to illustrate it with the simple examples of arithmetic expressions and terms of the free monoid.



in section 2, we implement a reduction semantics for arithmetic expressions in complete detail and in standard ml, and we define the corresponding reduction-based normalization function. in section 3, we refocus the reduction-based normalization function of section 2 into an abstract machine, and we present the corresponding reduction-free normalization function. in sections 4 and 5, we go through the same motions for terms in the free monoid. sections 2 and 4 might appear as intimidating; however, except that they are expressed in ml, they describe straightforward reduction semantics as have been developed by felleisen and his co-workers for the last two decades[27, 28,45]. for this reason, these two sections have a parallel structure. similarly, to emphasize that the construction of a reduction-free normalization function out of a reduction-based normalization function is systematic, we have also



to define a reduction semantics for simplified arithmetic expressions(integer literals and additions), we specify their abstract syntax, their notion of reduction(computing the sum of two integers), their reduction contexts and the corresponding plug function, and how to decompose them into a reduction context and the left-most inner-most redex, if there is one. we then define a one-step reduction function that decomposes a non-value term into a reduction context and a redex, contracts the redex, and plugs the contractum into the context. we can finally define a reduction-based normalization function that repeatedly applies the one-step reduction function until a value, i.e., a normal form, is reached.



to define a reduction semantics for terms in the free monoid over a given carrier set, we specify their abstract syntax(a distinguished unit element, the other elements of the carrier set, and products of terms), their notion of reduction(oriented conversion rules), their reduction contexts and the corresponding plug function, and how to decompose them into a reduction context and the right-most inner-most redex, if there is one. we then define a onestep reduction function that decomposes a non-value term into a reduction context and a redex, contracts the redex, and plugs the contractum into the context. we can finally define a reduction-based normalization function that repeatedly applies the one-step reduction function until a value, i.e., a normal form, is reached.



in this section, we transform the reduction-based normalization function of section 4.7 into a reduction-free normalization function, i.e., one where no intermediate term is ever constructed. we first refocus the reduction-based normalization function and we obtain a pre-abstract machine. we then simplify this pre-abstract machine into an abstract machine. this abstract machine is in defunctionalized form, and we refunctionalize it. the result is in continuation-passing style and we re-express it in direct style. the resulting direct-style function is a traditional flatten function with an accumulator; in particular, it is reduction-free.



in this article, we have built on the computational content of a reductionbased normalization function as provided by a reduction semantics, and we have presented a simple, derivational way to construct a reduction-free normalization function. we have illustrated the construction on two examples, arithmetic expressions and terms in a free monoid. elsewhere, we have successfully constructed weak-head normalization functions for the lambda-calculus(a.k.a. evaluation functions) and normalization functions for the lambda-calculus(yielding long beta-eta-normal forms, when they exist), thereby establishing a link between normalization by evaluation and abstract machines for strong reduction[15, 33, 38]. we have also constructed one-pass cps transformations, which provide an early example of normalization by evaluation.



ma-lgorzata biernacka, dariusz biernacki, and olivier danvy. an operational foundation for delimited continuations in the cps hierarchy. technical report brics rs-04-29, daimi, department of computer science, university of aarhus, aarhus, denmark, december 2004. a preliminary version was presented at the the fourth acm sigplan workshop on continuations(cw 2004).



olivier danvy and lasse r. nielsen. refocusing in reduction semantics. technical report brics rs-04-26, daimi, department of computer science, university of aarhus, aarhus, denmark, november 2004. a preliminary version appears in the informal proceedings of the second international workshop on rule-based programming(rule 2001), electronic notes in theoretical computer science, vol. 59.4.



