first-order methods for solving convex optimization problems have been at the forefront of mathematical optimization in the last 20 years. the rapid development of this important class of algorithms is motivated by the success stories reported in various applications, including most importantly machine learning, signal processing, imaging and control theory. first-order methods have the potential to provide low accuracy solutions at low computational complexity which makes them an attractive set of tools in large-scale optimization problems. in this survey, we cover a number of key developments in gradient-based optimization methods. this includes non-euclidean extensions of the classical proximal gradient method, and its accelerated versions. additionally we survey recent developments within the class of projection-free methods, and proximal versions of primaldual schemes. we give complete proofs for various key results, and highlight the unifying aspects of several optimization algorithms.



the traditional standard in convex optimization was to translate a problem into a conic program and solve it using a primaldual interior point method(ipm). the monograph nesterov and nemirovski(1994) was instrumental in setting this standard. the primaldual formulation is a mathematically elegant and powerful approach as these conic problems can then be solved to high accuracy when the dimension of the problem is of moderate size. this philosophy culminated into the development of a robust technology for solving convex optimization problems which is nowadays the computational backbone of many specialized solution packages like mosek(andersen and andersen, 2000), or sedumi(sturm, 1999). however, in general, the iteration timization, mainly because of its good scalability properties and small iteration costs. conceptually, it is an interesting optimization method, as it allows us to solve convex programming problems with complicated geometry on which proximal operators are not easy to evaluate. this, in fact, applies to many important domains, like the spectrahedron, or domains defined via intersections of several half spaces. cg is also relevant when the iterates should preserve structural features of the desired solution, like sparsity. section 5 gives a comprehensive account of this versatile method.



work of the proximal gradient method(pgm). pgm is a very powerful method which received enormous interest in optimization and its applications. for a survey in the context of signal processing we refer the reader to combettes and pesquet(2011). a general survey on proximal operators can be found in beck(2017); parikh and boyd(2014).



problem(p)(usually obtained after consulting a black-box oracle). various conditions on the well-posedness of the prox-mapping have been stated in the literature. we will not repeat them here, but rather refer to the recent survey(teboulle, 2018). below we give some examples.



ror descent(md) method(nemirovski and yudin, 1983). a version of this method for convex composite non-smooth optimization was proposed in duchi et al.(2010), and an overview of subgradient/mirror descent type of methods for non-smooth problems can be found in beck(2017); dvurechensky et al.(2020b); lan(2020). the main difference between bpgm and md is that one replaces the assumption that



in this section we turn our attention to a classical method for solving linearly constrained optimization problems building on the classical idea of the celebrated method of multipliers. an extremely powerful proponent of this class of algorithms is the alternating direction method of multipliers(admm), which has received enormous interest from different directions, including pdes, mixedinteger programming, optimal control and signal processing(yang and zhang, 2011; yuan, 2012). the very influential monograph contains over 180 references, reflecting the deep impact of alternating methods on optimization theory and its applications. following the general spirit of this survey, we introduce alternating direction methods in a proximal framework, it impossible to implement the algorithm in parallel, which makes it slightly unattractive for large-scale problems in distributed optimization. moreover, due to the result of chen et al.(2016) the convergence of admm for general linear constraints does not generalize to more than two blocks. leaving parallelization issues aside, shefi and teboulle shefi and teboulle(2014) proposed an interesting extension of the admm by adding further quadratic penalty terms, which allows much flexibility by suitably choosing the norms employed in the algo-



sults in a smaller step-size than the adaptive step, which hints towards a deterioration of performance. nevertheless, this trick allows us to handle convex programming problems outside the lipschitz smooth case, which is not uncommon in various applications.



to conclude, we reiterate that the step-size choices analyzed here are the most common, but there may be many more choices of stepsize which provide similar guarantees. for example, freund and grigas(2016) suggests new step-size rules based on an alternative analysis of the cg method that utilizes an updated duality gap.(nesterov, 2018a) discusses recursive step-size rules, and in dvurechensky et al.(2020a); odor et al.(2016) new step-size rules are suggested based on additional assumptions on the problem structure.



bregman proximal gradient method in the setting of relative smoothness and relative strong convexity(see section 3.3.3 for the definition of relative smoothness). yet, the negative result of suggest that, in general, the acceleration in the relative smoothness setting is not possible.



which allow to obtain linear convergence rate we refer the reader to bolte et al.(2017); necoara et al.(2019). the linear convergence rate can be obtained under quadratic error bound condition by a widely used restart technique, which dates back to nemirovskii and nesterov(1985); nesterov(1983).



we close this survey, with a very important fact which nesterov writes in the introduction of his important textbook(nesterov, 2018b): in general, optimization problems are unsolvable. convex programming stands out from this general fact, since it describes a significantly large class of model problems, with important practical applications, for which general solution techniques have been developed within the mathematical framework of interior-point techniques. however, modern optimization problems are large-scale in nature, which renders these polynomial time methods impractical. first-order methods have become the gold standard in balancing cheap iterations with low solution accuracy, and many theoretical and practical advances having been made in the last 20 years.



