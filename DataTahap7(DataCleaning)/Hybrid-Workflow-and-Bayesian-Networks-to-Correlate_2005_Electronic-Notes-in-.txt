safeguard is a system that aims to improve the dependability and survivability of large complex critical infrastructures by using distributed autonomous agents to monitor and protect them. this paper describes the embedding of a workflow management system within one of the safeguard agents to support real-time correlation of information from anomaly detectors, intrusion detection systems and other system monitors. the workflow management system interprets workflow models, which are represented by augmented petri nets modelling generic forms of attack or failure. the workflow management system also triggers appropriate responses automatically according to the reasoning results of bayesian networks linked to transitions in the workflows. a case study example from the management of electricity distribution networks will be presented.



the safeguard agent system is implemented as a hierarchically layered agent system. it combines distributed detection and distributed response with integration of critical information from many sources. the safeguard agent system has hybrid detector agents that monitor the operators, system components and system malfunction detectors within an infrastructure in order to assess the state of the system and if it contains erroneous data or under attack. problems within the system, such as anomalous data or file integrity violations, will be identified. this information can be either passed to the operator or automatically acted upon, in order to prevent or limit inappropriate behaviour. the most important agents will now be covered in more detail.



the wrapper agents are attached to the existing intrusion detection systems that gather information about the system and possible attacks on the system. wrapper agents simply allow information from existing diagnostic and ids components can be integrated within the safeguard system. information from wrapper agents is sent to the correlation agents. an example is file integrity checker wrapper agent, which monitors integrity violations on critical system files.



the workflow correlation agents(wcas) contain an embedded workflow management system. predefined workflow models for the managed network are loaded to the workflow management system. transitions of these workflow models are associated with predefined bayesian network models. workflow correlation agents are responsible for integrating information from the different hdas or wrapper agents and reasoning about the state of the network and behaviour of operators. some of these transitions are used to model actions or to communicate with a separate action agent. in this way the correlation and action agents work together to provide a quick response that rectifies problems as they arise. an example of available responses includes changing firewall policies when a worm is reported by the wcas to stop the propagation of the worm in the network.



workflow management systems are used to define, manage and execute workflows using software whose order of execution is driven by a computer representation of the workflow logic. there are many commercial and noncommercial workflow management tools available such as cosa and openwfe. each application provides different functionalities and serves different users. in our research we chose the bossa workflow system as our workflow management system because it has the following advantages:



basic petri net modeled workflows for bossa workflow management system have the following elements: places, transitions, and weighted arcs. workflows in our system can only be started at one point. this point should be marked by placing a single token at that point. four different types of transition can be used to construct a workflow. the transition type is set using the first few letters of its name.



bayesian networks are constructed in an xml format using the graphical capabilities of the javabayes software. the ebayes software is embedded in the correlation agent and this is used when updating the beliefs of nodes in the bayesian networks that are linked to transitions in the workflow. a bayesian network provides a link between incoming messages from anomaly detectors and a transition in the workflow. each bayesian network contains one or more observable nodes which corresponding to incoming messages. observables are linked by the bayesian network to nodes associated



bayesian network b1. incoming messages from different anomaly detectors update the observable nodes in b1. bayesian network will work out the probability of proposition b transition1. if the probability exceeds a certain threshold, transition t1 will fire. then the token in place place0 will be transferred to the corresponding place according to the value of the attribute a. attribute a is an internal variable that is maintained by the workflow engine. its value can be changed by messages from other agents. this routing continues until the end of workflow is reached.



two families of worm were emulated for test purposes, namely code red and slammer. only the latter is reported here. slammer uses udp for its propagation and sends a single infection packet to a randomly chosen ip address. to control the propagation rate, the range from which this random ip address is chosen can be set using a command line argument. the impact of the worm emulation upon the electricity network and the safeguard response were measured by using network probe to monitor the total network traffic. the worm emulation was initially run without safeguard and then with safeguard so that the effectiveness of the safeguard response could be evaluated. in the safeguard tests, a string was included inside the worm and a signature written for prelude ids to test the ability of safeguard to respond to a known worm. safeguard was also tested without prelude to evaluate the ability to detect and respond to an unknown worm on the network. all the tests were run with a single vulnerable process running on one machine and a single malicious process on a second machine.



a prototype system for enhancing the survivability and dependability of large scale infrastructures is being constructed and is being evaluated on two important kinds of critical infrastructure, namely electricity distribution and the management of a telecommunications network. instances of all the main agents of the system have been constructed. current work is on implementing the test beds for the electricity and telecommunications domains and on evaluating the techniques developed.



this paper has concentrated on an aspect of our approach to correlation. by correlation is meant the synthesis of information from diverse kinds of anomaly detector and ids and making sense of this information. information is synthesized for patterns of attack that can extend over a period of time. the time events occur can matter. for example, a scan in itself may not be



one important aspect of the approach not described here is the creation of a variety of anomaly detectors that detect deviations from normality. the system is trained under normal operation and then deviations from normality are detected. this is how the system can initially detect new kinds of attack. work flows are used in an attempt to go a little further. for patterns of attack that have been analysed then a framework for confirmation and action is provided by the workflows. action and synthesis of information can be intertwined.



