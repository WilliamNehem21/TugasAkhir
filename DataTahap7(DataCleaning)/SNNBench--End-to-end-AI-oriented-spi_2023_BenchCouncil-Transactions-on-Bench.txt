spiking neural networks(snns) show great potential for solving artificial intelligence(ai) applications. at the preliminary stage of snns, benchmarks are essential for evaluating and optimizing snn algorithms, software, and hardware toward ai scenarios. however, a majority of snn benchmarks focus on evaluating snn for brain science, which has distinct neural network architectures and targets. even though there have several benchmarks evaluating snn for ai, they only focus on a single stage of training and inference or a processing fragment of a whole stage without accuracy information. thus, the existing snn benchmarks lack an end-to-end perspective that not only covers both training and inference but also provides a whole training process to a target accuracy level.



on the other hand, two benchmarks have been proposed to evaluate the snns for ai[11,12]. one benchmark from ostrau et al. focuses on the inference stage by converting a pre-trained dnn model to an snn model and providing accuracy information. however, it does not consider the training phase or other learning rules. although another benchmark from kulkarni et al. includes both the training and inference stages, it employs much simpler neural network architectures(2) different from the previous work, we find that using stdp learning rule(88%) is hard to achieve the state-of-the-art convergence accuracy(99.91%) compared to the backpropagation(98%) and conversion-based learning rules(96.72%). moreover, the convergence accuracies using stdp have much larger fluctuations than the other two rules, with a standard deviation higher than 2.4%, while the value is below 0.3% for the other



gpu is not always the best for snn. in our experiments, we found that when the number of neurons in a layer of snn is small, like 400, the cpu performs better than the gpu. this could be due to the small size of the snn networks, which leads to short gpu computation times that cannot offset the synchronization overhead between the cpu and gpu, or the software framework used for simulating snns may not be optimally designed for exploiting the full potential of gpus. for recurrent networks, the training time on gpu using lif neurons is 1.37 times that of on cpu. using lsnn neurons, the gap is 1.22 times. in future work, we plan to explore larger snn networks and further optimization of both the software framework and the mapping of snn workloads to the gpu hardware.



several benchmarks have been proposed to study computational neuroscience, which employs mathematical models and computer simulations to understand how electrical and chemical signals process and represent information in the brain. brette et al. simulated a network containing 4000 neurons, 80% of which were excitatory and 20% were inhibitory neurons, randomly connected with a probability of 2%. they proposed four benchmarks, each with the same network architecture but different combinations of spiking neurons and synaptic types, and provided simulation specifications that include



covering the typical characteristics of deep learning. on the one hand, the benchmark should consider different learning approaches, like supervised, unsupervised, semi-supervised, and reinforcement learning. on the other hand, the benchmark should contain both training and inference phases. important factors should be considered for different phases, like the diverse learning rules, spiking neurons, connection types, etc.



the basic paradigm of ai is to train a model using the training dataset first and then make inferences on the test dataset. it is wellknown that training and inference are different. the most significant difference is that training involves weight updating and even the evolution of network architectures, such as neural architecture search and evolutionary optimization. on the other hand, weights and architecture remain unchanged during inference. hence, they have different workload characteristics, as verified in section 4.2. as a direct result, hardware architectures designed for training and inference differ, like various dnn accelerators. if one only considers one of the phases, it may mislead the hardware design. therefore, it is not sufficient to only consider training or inference.



many benchmarks use indirect metrics like operations per second because they are easy to measure. however, these metrics may not reflect whether a hardware system can solve real ai tasks. different design strategies like float point precision can lead to non-objective assessments. for example, a hardware system that achieves high operations per second may not be able to train to the target accuracy if it adopts a low float point precision implementation. to address this issue, snnbench trains the model to the target accuracy and uses accuracy as an important metric.



snnbench is designed for ai applications and focuses on image classification and speech recognition as benchmarking tasks. these two tasks are widely used in deep learning and serve as representative benchmarks. the benchmark suite includes state-of-the-art, stateof-the-practice, classical spiking neural architectures that are widely accepted and highly cited in snn research. for the image classification task, snnbench uses the modified national institute of standards and technology(mnist) handwritten digits database. for the speech recognition task, snnbench uses the speech commands v2 dataset, which contains 105,829 audio files of spoken words and is widely used for simple speech recognition tasks.



in the brain, neurons with similar functions are organized into a neural population group. similarly, in deep learning, neurons are organized layer-by-layer into distinct connection types, such as fully connected, convolutional, and recurrent layers. snnbench provides workloads with different connection types to take advantage of the mature and efficient connection types developed in deep learning.



to ensure the reproducibility and usability of our benchmarks, we have taken several steps to address the intrinsic stochastic nature of ai. firstly, ai algorithms typically rely on randomness, such as choosing a random initial state for training and shuffling the input data, to enhance their robustness. however, these methods can also make it challenging to reproduce benchmark results. secondly, the operations used in deep learning algorithms, such as convolution and matrix multiplication, have various implementations, which can further increase the volatility of benchmark results. to mitigate this, we have set the same random seed for all benchmarks, including pytorch, python, and numpy random libraries, ensuring that the initial states and input order remain consistent with each run. we have also disabled the cudnn benchmarking feature that selects the most efficient convolution implementation in time. instead, we have made pytorch choose a deterministic algorithm for all operations, ensuring that the same algorithms and implementations are used for each run. additionally, to improve usability, we have used docker to set up a consistent experiment environment for each run of the benchmark.



workload#1: image-stdp training workload uses the stdp learning rule to update the synaptic weights, where stronger connections are formed if pre-synaptic neurons consistently lead to postsynaptic neurons firing, and weaker connections are formed if the opposite is true. this reflects the impulsiveness of the brain, where some neurons enhance the reaction while others prevent it. the excitatory and inhibitory neurons both have lif behavior but opposite weight-updating strategies. we check the accuracy of every iteration and train the model to the convergent state, and check if it reaches the target accuracy.



workload#2: image-stdp inference workload uses the trained model to infer on the test dataset. after training, the label of the image that elicits the most firing in a neuron is assigned to that neuron. during inference, the label of the image is assigned based on the most fired neurons. counting the spiking distributions can get the inference result. we study the stdp learning rule in different scales by implementing snns with 100, 400, 1600, and 6400 neurons in the excitatory and network architecture is similar to dnn, except it has different computing units. we adopt an implementation that is a simple convolution network containing two convolution and max pooling layers and a fully connected layer as the output layer. all the computing units are lif neurons.



method and lif-based neurons. one workload uses traditional lif neurons, while the other uses the lsnn neuron, a lif variant with adaptive thresholds that are dynamic during training but fixed during inference. additionally, we evaluate a workload that uses standard activation functions as computing units, serving as the baseline for deep neural network(dnn) performance.



in this section, we conduct a series of experiments to show the effectiveness of snnbench. first, we perform workload characterization on snnbench in section 4.2 and show the reproducibility of snnbench in section 4.3. then, we compare the impact of learning rules and computing units on the snn training and inference performance in section 4.4 and section 4.5, respectively. finally, we evaluate the scalability of snnbench in section 4.6.



the nonzero operator on these two tensors costs 603.57 us and 56.32 us, respectively. the performance gap is one order of magnitude. this also implies that the impact of different input characteristics on performance is enormous. the workload characteristics are almost the same for the two speech recognition tasks because they use similar learning rules and are only different in computing units. they differ from image classification tasks in that they need to process speech data so that they contain the spectral operator(fft transformation in this case). the backward operator also occupies a high total time that image classification tasks do not.



in this experiment, we perform a top-down analysis for each workload. our findings reveal that the majority of workloads allocate considerable time to pointwise, blas, tensor-related, and data loading operators. image-backprop and image-conversion workloads display distinct characteristics compared to others, such as reduced blas operation time and elevated spike firing rate in the converted snn model, impacting performance. the workload characteristics remain consistent between the two speech recognition tasks, as they employ similar learning rules and vary only in computing units. additionally, they incorporate the spectral operator, which is absent in image classification tasks.



accuracy of the model reaches 97.73%, which can be compared with similar architecture dnns. and the training and inference time are only 1/73 and 1/84 of the stdp learning rule. we think this is because the surrogate backpropagation can train the data batch by batch, but the stdp learning rule can only train the data in one sample once. the surrogate backpropagation can fully use the underlying parallel computing hardware.



the stdp training rule is relatively challenging to use. firstly, it is difficult to train and may not necessarily achieve accuracy comparable to the previous two methods. secondly, the training speed is too slow, and current snn frameworks cannot efficiently map the stdp algorithm to gpus. however, if unsupervised learning is desired, the stdp learning rule is the only option.



first epoch for all these three neural networks. after that, the accuracy of neural networks using lif and lsnn remains at the same level as the first epoch, but the accuracy of the neural network with the lstm unit reaches 90% after reaching the convergence state. using the same network architecture, two snn networks achieve lower accuracy than dnn networks, this may be because the parameters of the snn network have not been sufficiently tuned, such as the threshold value of firing spikes. indicated that lsnn has better performance than lif, but the accuracy of lif and lsnn are similar, which may prove that the parameters of the snn networks are not tuned well. however, this paper primarily focuses on benchmarking rather then the algorithm, we did not spend much time on parameter optimization, as it is beyond the scope of this work. even though we can fine-tune the parameters the final accuracy gap is large(67% vs. 90%). hence we can conclude that for the same architecture, snn can hardly achieve the accuracy that dnn achieved. in terms of ease of use, snns are currently not comparable to dnns because even though the user does not carefully adjust the lstm parameters, good results can be achieved.



threads exceeds three. this may be related to the input size of the three operators since the image-stdp workload does not support batch training, so the data input size is small, and performance is best with three threads. if the data input size becomes larger, it will benefit from more hardware computing units, as we discussed in section 4.4. from the result, the number of intra-operator threads that gains the best performance is also the thread number that the most cost operators get the best performance. these optimal numbers of threads are 3, 8, 6, 1, 1, and 2, respectively. therefore, it cannot be simply said that the more hardware threads, the better. different operators and different data input sizes correspond to different optimal thread numbers. in



