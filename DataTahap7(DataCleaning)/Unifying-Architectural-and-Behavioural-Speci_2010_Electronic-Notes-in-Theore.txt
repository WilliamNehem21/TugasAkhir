we present a novel specification language called jdc to be used at design phase of distributed components. the extensive seek for asynchrony in distributed components demands new techniques for its specification that have not been addressed before. we propose to focus the specification on its data-flow; this allows to reason about inter-component synchronisations produced by a data-driven synchronisation model. the language is endowed with enough formality so it allows a constructive approach; it allows the generation of behaviour models which can be model-checked, and the generation of code skeletons with the control flow of components. globally, this approach aims at generating components with strong guarantees w.r.t. their behaviour.



a major originality of our work is that we target distributed component systems communicating by asynchronous method calls with futures, concretely in the frame of the grid component model(gcm). the gcm is a novel component model defined by the european network of excellence coregrid. the gcm is based on the fractal component model, with extensions addressing grid computing. from fractal, gcm inherits a hierarchical structure with strong separation of concerns between functional and non-functional behaviours. the extensions to fractal come from the fact that in grid computing components are deployed over thousands of nodes, so scalability plays a major role.



stslib provides a formal component framework that synthesises components from symbolic protocols in terms of symbolic transition systems(sts). just as pnets, sts concisely represents infinite systems, however, sts relies on abstract data types(adt) which are more expressive than our simple types(see section 2.3), but less intuitive for software engineers. both formalisms rely on(n-ary) synchronisation vectors, but in sts they are static whereas in pnets they are dynamic;



the originality of our work is to focus on service invocations, and implicit synchronisation by the mean of futures. we will show that the data-flow and the access to the transmitted results implicitly set the synchronisations. this approach provides a high-level and powerful abstraction for the programmer that is close to the programming model.



instead of proving that legacy code is safe, in this paper we take a constructive approach similar to[14,18]. the idea is to specify the system, prove that the specification is correct, and then generate(java) code skeletons guaranteed to conform to the specification. pnets is left as the underlying formalism that interfaces with model-checkers, and the programmer uses a high-level specification on top of pnets. the language is called java distributed components(jdc for short).



the paper is organised as follows. section 2 discusses the foundations of the specification language. then, section 3 illustrates how components can be described and composed using an architecture specification. in section 4, we define the black-box behaviour of a component, that abstracts the internal details of a component. section 5 specifies abstractions of user types. finally, section 6 explains how to generate both behavioural models and code skeletons from our specification language.



proactive guarantees that, once the promised value of a future is known, it is transmitted to every component that has received a reference to it. moreover, the various strategies used for transmitting the future values are proved not to change the component behaviour. a precise operational semantics of proactive is given by the asp-calculus. these results inspire our specification language to adopt futures in order to decouple components.



in the gcm, the relation between an internal interface and an external interface of a component is arbitrary: interceptors can transform or intercept any incoming invocation. for simplicity, in this paper, we assume that there is an exact match for each pair of external-internal interfaces(interfaces that have the same type and name, but with opposite roles); and that invocations on an external(resp. internal) server interface is directly forwarded to the corresponding internal(resp.external) client interface.



the fields of the concrete class that are of interest are included as a record. the domains of these fields are such that they are precise enough to hold the property to prove. this is done recursively in order to find the abstractions of the other variables of interest.



the operators are abstract versions of the class methods, that capture the behaviour of interest for a variable. it is possible to have multiple versions of the same operator, each one taking different abstract versions of the arguments and return types. similarly, the same applies to constructors.



the example above illustrates the use of a data abstraction influencing the control-flow. a short-sale must not exceed a maximum number of products, but there is no constraint on the type of products. therefore, the abstraction of the product list must be precise enough to take into account whether the maximum has been exceeded or not, and can abstract away the product information.



the abstraction for the product list has no counter. instead, it focuses on the states the list can have: the list is either empty, ok or full. this abstraction is imprecise w.r.t. the number of products it has, so actions on the list are nondeterministic. adding a product from an empty state never reaches the limit for a short-sale, however, from an ok state it may(the state change to full is nondeterministic). note that the context guarantees that we never call add() when the list is full.



defining abstractions can be burden without a tool support. for developping this kind of tool a first step is to characterise what is a good abstraction. it surely depends on the property to prove, but there are a couple of general ideas that support some automatising of the abstractions.



for each service, a storage for each of its local variables. a storage is a parameterized labelled transition systems(pltss) that stores the variable state, and that exports actions set and get for accessing the variable. these storage are synchronised with all the pltss of the service methods and the service policy.



a plts for each service policy. the service policy is a state machine so the transformation is straightforward. the reactive behaviour is transformed into two actions, one synchronised with the queue, and another that fires the affected service method. similarly, each active behaviour is transformed into an action that fires the method directly.



for each architecture specification of a component, the compiler generates a composite component. the composite architecture is expressed with the gcm adl(architecture description language). the composite adl defines the component type and its content based on the adls of other subcomponents, bindings and the idls of the interfaces.



we aim at safe-by-construction components. our approach is to define the architecture, the behaviour, and an abstraction of data within the specification language. the specification is formal enough in order to generate behavioural models that can be model-checked, and to generate code skeletons that include the control code of components.



since in jdc the architectural part is basically that found in classical adls, vce can be seen as a front-end for the architectural part of the jdc specification language. there are other architectural features in the gcm that were not addressed in jdc, and we provide support for them in vce. for example, we will show how non-functional aspects can be defined, as well as one-to-many and many-to-one communications.



2.1 diagrams for component structures and state machines. in our new version, we abandoned the strict definition of the uml diagrams, that were not sufficient for our needs. our new graphical constructs can be considered as a specific uml profile for the gcm components, or as an independent domain specific language(dsl) for the gcm.



we provide an editor with custom diagrams for the gcm. we stress on the architectural specification of both functional and non-functional behaviours. we define a meta-model for dealing with these aspects, and provide verification features for validating the design. the tool is fully integrated into eclipse, and can interface with the gcm runtime files, namely the gcm adl and the interface signatures.



collective interfaces provide some synchronisation and distribution capacities. there are of two kinds in the gcm: multicast, that distribute one message with its parameters to a set of destinations; and gathercast, that synchronise and gather a set of messages with their parameters. a client interface may be a multicast interface, meaning that a call toward this interface can be distributed to many server interfaces depending on the distribution used. similarly, a server interface may be a gathercast interface, meaning that multiple client calls will be synchronised and a single call will be performed towards the service component.



in section a.1 we present the editor; first, the functional specification, then the nf specification, and finally the validation and adl generation features. in section a.2 we present the tool architecture, and its place in the platform. finally, the annex concludes in section a.3 with a summary and some future work.



in this section we present our component editor. vce is built as an eclipse plug-in using code generated using the topcased environment. it is uses a model-driven-architecture pattern, with an ecore metamodel at its kernel. we do not detail the meta-model in here, but basically it is built on the symmetry between structure of the content and the structure of the membrane. moreover, it is compatible with the architectural definition of jdc, and we expect to provide the user with similar tools for the behavioural part as well.



to ensure the integrity of the user model, we define a minimum set of invariants that every model must hold. these invariants are defined with ocl(object constraint language), and complement the meta-model by expressing constraints that were left undefined. by defining the rules using ocl, we let our meta-model open. this allows us, in theory, to define different set of rules depending on particular implementations of the gcm.



we are able to generate adls from these diagrams useful within gcm. in its current state, we only generate gcm adl files with the definition of the content. the membrane is still not taken into account because the adl for dealing with non-functional aspects is still being defined.



