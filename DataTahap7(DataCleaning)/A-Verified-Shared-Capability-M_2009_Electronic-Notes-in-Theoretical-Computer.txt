this paper presents a high-level access control model of the sel4 microkernel. we extend an earlier formalisation by elkaduwe et al with non-determinism, explicit sharing of capability storage, and a delete-operation for entities. we formally prove that this new model can enforce systemglobal security policies as well as authority confinement. by treating sharing explicitly in the abstract access control model we simplify considerably the refinement proof towards the sel4 implementation. to our knowledge this is the first machine-checked access control model with explicit sharing of authority.



our attempts to prove refinement between the access control model and the operational specification have shown that features of sel4, which are also present in other capability systems, make proof especially complicated. these features are, in increasing order of complexity: non-determinism, deletion of entities(not just capabilities), and sharing of capability storage. the first, non-determinism, is mostly technical and easy to treat. the second, deletion of entities, is conceptually simple, but introduces a mismatch between entities that occur in the security specification and those that exist in the implementation; an example is presented later. the third, sharing of capability storage, introduces a conceptual problem. moreover, if one naively formalises the classical approach, a great deal of unnecessary complexity into the relation between abstract and concrete states in the refinement proof.



we provide the first formal model and security analysis of shared capability storage. shared capability storage changes the basic predicates of the analysis and introduces additional possibilities for transmitting authority and information. we show how the analysis can be adjusted to account for shared authority and we prove that the adjusted system is still suitable for enforcing mandatory, system-global access control policies as well as authority confinement and isolation.



while the refinement proof is not yet complete, enough progress has been made to expose a security problem in an early version of the operational specification: even though a grant operation to transfer authority from a thread a to another thread b is checked explicitly when started, an interruption may occur, and another check is not made upon resuming the operation, even though the authority could have been revoked from a during that interruption. the completion of the operation would therefore be unauthorised and would not refine the security model where all such operations are atomic. the problem has been fixed in the meantime, and shows how refinement can be used to expose subtle defects such as this one.



isabelle supports tuples with named components. for instance, we write record point={x:: nat, y:: nat} for the type point with two components of type nat. if p is a point, a possible value for p is notated(| x= 5, y=2|). the term xp stands for the x-component of p. updating p from a current value(| x= 5, y=2|), with the update notation p(| x:= 4|), gives(| x= 4, y= 2|).



sharing is traditionally addressed by arguing around it: that b and c share capability storage amounts to grant authority between them in both directions and should be modelled as such. any action on the capabilities of b must be immediately mirrored on those of c. there is nothing conceptually wrong with this argument, but as sharing structures become more complicated, so too does the relationship between the abstract model and the details of an implementation. the security model must express both normal grant capabilities as well as additional ones to account for sharing. the formalisation of the relationship between it and an implementation model is complex, and proving that it holds is cumbersome. moreover, there is no longer a simple correspondence between operations executed in the two models: actions in the security model depend on the state of the implementation model.



we contend, in this paper, that it is much easier and more convenient to model sharing explicitly and to account for it directly during security analysis. further, any security monitor that operates according to the main theorems of the model will have to account for sharing anyway. an explicit model of sharing thus also benefits implementors of security monitors.



following the elkaduwe model, we do not distinguish between active(e.g. a thread) and passive(e.g. memory) objects, but rather call all kernel objects entities. formally, an entity is just a set of capabilities, which is the only property of interest at this level.



a grant right to another is able to grant its capabilities to this other entity. the store right models the concept of shared capabilities. if an entity has a store rights to another entity, then it has direct access to all the capabilities stored in that entity. since multiple entities can have a store capability to a single entity, this allows sharing of capabilities. we use the term all-rights to denote the set of all access rights; formally all-rights={read, write, grant, create, store}.



neither the sysread ec nor the syswrite ec operation change the state of capabilities in the system. they clearly do not connect disconnected entities. the syscreate e n c1 c2 operation creates a new entity(n) by using free memory provided by an existing entity(e1) and by assigning a new capability for controlling access to n to existing capability storage(e2). it is only legal if the initiating entity e has both a capability(c1) with create rights to e1, and a capability(c2) with store and write rights to the cnode e2 where the new



this operation clearly has the possibility of adding a capability to an entity that did not previously possess this capability. in fact, if an entity x is store connected to e3 and e2 store connected to y, then introducing a store connection between e3 and e2 will connect x and y. however a connection between e3 and e2 is only ever created if a connection existed between e and e2, and since e and e3 are already connected, any connections introduced are already transitively present beforehand.



both the sysremove e c1 c2 and sysrevoke e c operations remove capabilities: in the former case from the entity pointed to by c1 and in the latter case from a whole set of entities. as in the elkaduwe model, we do not specify explicitly which set of entities is removed by revoke, because this set is tracked in a complex data structure cdt(capability derivation tree) in the implementation that adds nothing that is relevant for our purposes to the security analysis. our formulation with nondeterminism makes this more natural than before. given this set, the revoke operation is then just a repeated call of remove.



since we define the state as a partial function from entity-ids to entities, the definition of executing delete is trivial. sysdelete simply removes an entity; therefore it cannot connect disconnected entities. we will see in the next subsection that delete has an interesting side effect that slightly changes the formal statement of theorem 4.4 and theorem 4.5 as well as theorem 5.1.



a function step combines precondition checks on the current state, from legal, with the effects of operations, from step'. in contrast to the elkaduwe model, operations now return a set of possible states. the definition of step ensures that the result always includes the initial state, thereby accounting for the possibility that an implementation of sel4 may abort an operation for reasons that are ignored in step'. for example, an implementation of the syscreate operation will fail if it is not provided with sufficient memory, but this kind of detail is irrelevant in the security model.



this subsection introduces the formal statements of the main lemmas in the security proof. we define sane as an invariant that is a precondition to most theorems in our security model. we call a state sane if all capabilities point to entities that exist.



instead of strengthening the precondition, we could get around this by introducing names for entities that are unique not only over the lifetime of the entity, but over the lifetime of the whole system. these names would have to come from an infinite set. we chose not to do so, because this problem exists in the implementation as well, and there is no way to implement such system life-time names in reality unless the system runs for a known finite time only. as for shared capability storage, we believed it better to bring the problem out into the open and reflect it explicitly in the security analysis.



the definitions are unchanged from elkaduwe et al. the subsys-caps function takes the set of entities in the subsystem, and then the union of all their capabilities. here, these are all capabilities that the entities transitively have access to. a capability c dominates a capability set c(c:> c) if c provides at most as much authority as capability c over the entity c points to.



theorem 4.5(confinement of authority). given a sane state s, a non-empty subsystem spanned by x in s, and a capability c with a target identity y in s, if the authority of the subsystem does not exceed c in s, then it will not exceed c in any future state of the system for as long as x and y both exist.



the security analysis so far was concerned with de-jure rights, i.e. rights that are directly conferred by capabilities. if we are interested in the flow of information through the system, then we need to consider de-facto rights. as mentioned previously, de-facto rights model entities that may try to collaborate to transport information through indirectly authorised channels. if a has read access to b, and c has write access to b, then de facto, a has read access to c even though de jure, no read operation from a to c will ever be



as mentioned previously, our sel4 access control model is inspired by the take-grant model. the original analysis on the take grant model[12, 2] already uses the same approximation to model the exposure of access rights: the transitive, symmetric closure on the given initial graph. the difference here is that we make capability storage and sharing explicit and that we conduct all proofs in isabelle/hol.



rushby provides a formulation of isolation called non-interference. non-interference is stronger than the concept of isolation we use in this formalisation, because it goes beyond access control. it also includes covert storage channels, whereas we are only concerned with the overt, explicitly authorised, but still possibly indirect flows of information. the difference is that non-interference would for instance cover things like leaking information by making an observable decision in the program that depends on secret data. non-interference traditionally talks about different security levels that should be kept separate, whereas we are in this model more interested in which entities can communicate with each other in a highly dynamic setting. non-interference is not necessarily preserved under refinement, so special care would need to be taken to connect such a property to the operational model and the c implementation of sel4.



