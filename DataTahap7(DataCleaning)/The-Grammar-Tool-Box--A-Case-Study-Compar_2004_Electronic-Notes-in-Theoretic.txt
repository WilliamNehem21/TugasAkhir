in the last decade the computing community has shown an increasing interest in parsing techniques that go beyond the standard approaches. there are a plethora of parser generators that extend both top-down and bottom-up approaches with backtracking and lookahead constructs. as we have noted elsewhere such parsers can display surprising pathologies: in particular parser generators such as precc, pccts, antlr and javacc are really matching strings against ordered grammars in which the rule ordering is significant, and it can be hard to specify exactly what language is matched by such a parser. in any case, backtracking yields exponential parse times in worst case.



haviour but on modern hardware this need not preclude their use. several eiffel compilers use earley parsers to support their relaxed use of expression separators. tools such as asf+sdf stress generality and can parse ambiguous languages with support for shared packed parse forests which efficiently encode all possible derivations along with sophisticated techniques for disambiguating the forest. asf+sdf uses glr parsing to accomplish this: as a final indicator that general techniques are entering the mainstream consider that even gnu bison had recently acquired a glr mode, although the implementation is perhaps not yet industrial strength.



specified as a detailed chain of operations on grammars and automata. our goal is to open up the degrees of freedom in translator implementation in a structured way so that reproducible experiments can be mounted between competing techniques. naturally, a pre-written gtb script may be used to get the effect of a conventional parser generator like yacc or rdp so gtb can replace those kinds of tools in a production environment.



gtb can handle multiple grammars simultaneously, and extract multiple grammars from a rule set by using different start symbols(a facility which is useful for some techniques that segment grammars, such as the aycock and horspool trie-based automaton). the built-in function grammar constructs a grammar object from a particular start rule and as a side effect calculates first and follow sets. grammar augmentation is automatically applied, if necessary. the following is an extract of the text generated by running gtb with the example script given above.



the generate function uses breadth first search to output either sentential forms or sentences of the grammar. we can specify leftmost, rightmost or random selection of the nonterminal in a sentential form for expansion. of course, most interesting languages are infinite, so we can specify an upper bound on the number of outputs. the parameter of zero in the above example specifies no upper bound, so all sentential forms will be generated.



pascal and c typify the top down and bottom up schools of language design. in the folklore at least, pascal is thought of as being designed for ll(1) parsing and c for lalr parsing. in practice, pascal is indeed reasonably close to ll(1) notwithstanding the if-then-else ambiguity and the need for lexical backtracking to distinguish between a real literal(2.3) and an integer range





the ibm vs-cobol grammar is salutary. our first attempt expanded all closures by creating a new left-recursive nonterminal for each closure. gtb ran out of memory when trying to create an lr(1) nfa for this grammar. simple back substitution for head and tail recursive rules generated an nfa



we use a separate tool ebnf2bnf to perform these conversions which takes as input an(e)bnf grammar annotated with expansion operators and outputs an(e)bnf grammar. the tool constructs a rules tree from the original grammar and then performs tree transformations under the control of the annotations, before writing the grammar back out. an ambitious environment that supports this kind of operation has been prototyped in asf+sdf: the authors describe ebnf to bnf conversion as yacc-ification. our tool emphasises ease-of-use and traceability of the basic operations.



