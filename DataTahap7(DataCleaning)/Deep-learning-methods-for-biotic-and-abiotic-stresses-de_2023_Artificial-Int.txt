in machine learning, optimization is done each time a model is trained: the learning algorithm optimizes the values of the model pa- rameters to minimize the prediction error on the training dataset. however, the hyperparameters are not optimized during training. the number of layers in a neural network, the number of neurons per layer, etc., are hyperparameters that are not optimized during training. the choice of values for the hyperparameters influences the quality of the final model, sometimes strongly. on the other grape, orange, peach, pepper, potato, raspberry, soybean, squash, straw- berry, and tomato. diseases are bacterial, fungal, and viral infections. the remaining 18% used data from ai challenger 2018, imagenet, crowd ai, plantdisease, coffee leaf, etc. the sensors used to collect this data are cameras, smartphones, and drones.



supervised machine learning. samajpati and degadwala (2016) propose the classification of apple fruit diseases from the extraction of features and colors. random forest classifiers were used for disease clas- sification. still, on apple, omrani et al. (2014) were interested in detect- ing three-leaf diseases (alternaria, black spot, and apple leaf miner) using support vector regression based on the radial basis function. the authors compared ann and svm as a classifier and found that svm per- formed better. note that the data used are unbalanced between the to reduce the spatial size of the image representation and the computa- tional and processing overhead of neural networks. it also extracts key positionally and rotationally invariant features. the last layer uses the flattened output of the previous pooling/convolution layer as input. flattened means that a 3d matrix or array is expanded into a vector. specific mathematical calculations are performed for each fc layer. after the vector has passed through all the fully connected layers, the softmax activation function is used in the last layer to calculate the probability that input will belong to a particular class. this process is re- peated for other classes and individual images within those classes. it trains the network and teaches you, for instance, to distinguish between



deep unsupervised learning. this technique allows running the learning process without labeled data available. the model is supposed to organize the data on its own, based on the input data's features, to discover the data's unknown structure or relationship. this approach often includes generation network technology, dimensionality reduc- tion, and clustering. some members of the dl family are working well on nonlinear dimensionality reduction and clustering tasks. these in- clude restricted boltzmann machine (rbm) and autoencoder.



the restricted boltzmann machine (rbm) or boltzmann ma- chine: is a generative unsupervised model that learns a probability distribution from the original dataset and infers data it has never seen before. the rbm has an input layer and one or more hidden layers. it uses a neural network with neurons connected to neurons in the same layer and other neurons in other layers. the nodes are connected in a circle. in contrast to all deterministic network models, the rbm model is called stochastic. it is ideal for system monitoring and handwritten digit recognition (eg: check verification and crimi- nal evidence). the advantage of rbm is its possibility to encode any distribution due to its expressiveness and computational efficiency. in addition, using hidden layer activation as input to other models is a helpful feature to improve performance. this technique is more challenging to train.



autoencoder was used to predict and classify early and late phe- nomena resulting from macronutrient deficiencies in tomato plants (tran et al., 2019) and for detection of lead concentration in lettuce (xin et al., 2020). in general, the most crucial drawback of unsuper- vised learning methods is their inability to provide accurate



the r2 and the root mean square error (rmse) are the few ob- served regression metrics. the rmse is the square root of the mean square error. it is used to measure the standard deviation of the re- siduals. the coefficient of determination or r-square is the propor- tion of the variance of the dependent variable that the linear regression model explains. the r2 is a scale-free score, which means that regardless of whether the values are small or large, the r-square value will be less than one. the r2 and rmse are calculated using the following formulas.



