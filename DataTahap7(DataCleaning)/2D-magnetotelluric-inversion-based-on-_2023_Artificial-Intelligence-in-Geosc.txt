in this study, a deep learning algorithm was applied to two-dimensional magnetotelluric (mt) data inversion. compared with the traditional linear iterative inversion methods, the mt inversion method based on convolu- tional neural networks (cnn) does not rely on the selection of the initial model parameters and does not fall into the local optima. although the cnn inversion models can provide a clear electrical interface division, their inversion results may remain prone to abrupt electrical interfaces as opposed to the actual underground electrical situation. to solve this issue, a neural network with a residual network architecture (resnet-50) was constructed in this study. with the apparent resistivity and phase pseudo-section data as the inputs and with the resistivity parameters of the geoelectric model as the training labels, the modified resnet-50 model was trained end-to-end for producing samples according to the corresponding production strategy of the study area. through experi- ments, the training of the resnet-50 with the dice loss function effectively solved the issue of over-segmentation of the electrical interface by the cross-entropy function, avoided its abrupt inversion, and overcame the computational inefficiency of the traditional iterative methods. the proposed algorithm was validated against mt data measured from a geothermal field prospect in huanggang, hubei province, which showed that the deep learning method has opened up broad prospects in the field of mt data inversion.



with the progress of computer performance and forward algorithms, more nonlinear inversion methods have been proposed. simulated annealing inversion (shi and wang, 1998; sharma, 2012), ant colony algorithm inversion (liu et al.,. 2015), genetic algorithm inversion (schwarzbach et al., 2005), particle swarm optimisation algorithm inversion (shaw and srivastava 2007) and bayesian inversion (guo et al., 2011; di et al., 2020), these nonlinear methods have been implemented in electromagnetic fields and have achieved good results. furthermore, there are some previous applications of ann to 2d mt inversion (montahaei and oskooi, 2014; el-qady and ushijima 2001), which demonstrates the feasibility of artificial intelligence in the field of mt inversion.



tion of the model responses, thus rendering its computational efficiency favorable. several studies have explored various dl-based methods of geophysical prospecting. liu et al. (2021) proposed a dl model for re- sistivity data inversion by incorporating a smoothing constraint and depth weighting into loss function to reduce false anomalies and improve the inversion accuracy. zhang et al. (2021) used a convolu-



magnetic induction (emi) data and instantaneously estimated the number of subsurface conductivity layers. li et al. (2020) used the dl technique for the rapid imaging of time-domain airborne electromag- netic data. many studies have also applied the dl algorithm to seismic full-waveform inversion (zhang and alkhalifah, 2019) and other geophysical fields, such as gravity (he et al., 2021; yang et al., 2022) and magnetism. previous studies have showed that dl-based methods offer high computational efficiency, accurate and precise predictions,



advantages. for example, sigmiod(x) is smooth and easy to differentiate but causes gradient disappearance. tan h(x) can slow down the gradient different activation functions exhibit different advantages and dis- disappearance but leads to high computational cost. relu(x) shows low computational cost and can quickly converge during training but may



series of convolution layers, the essence of which is down-sampling. as the dimension of data becomes increasingly high after multiple convo- lutions, and the graph of features does not change significantly, a large number of parameters are generated, which results in not only the dif- ficulty of training the network, but also the issue of overfitting. there- fore, data are typically compressed by pooling connections among the convolution layers in order to reduce the data dimensionality and the number of parameters. in particular, the pooling operation serves to aggregate statistics between a pixel and its surrounding data, reduce the size of the feature map, and take the average or maximum value of its adjacent areas so as to further reduce the number of parameters. this can be used to fuse the feature maps of the previous layer and prevent overfitting as the parameters of adjacent regions have a strong corre- lation. there are two common pooling operations: maximum pooling and average pooling.



the loss function is an operation used to measure the difference between the predicted and observed (label) values. in the training stage of the model, once the training data of each batch were sent to the model, the predicted value was outputted through forward propagation, and the difference between the predicted and real values was calculated through the loss function to obtain the loss value. then, the model updated each parameter in the network through backpropagation in order to reduce the loss between the observed and predicted values. thus, the model predictions were close to the observed values, while the best-fit network mapped the relationship based on the training data.



sistivity values, and trap combinations to form different geoelectric models. these characteristic values included the length, thickness, po- sition in the grid, resistivity value, and number of resistivity transition layers. due to the large number of the variables, the number of samples obtained according to the permutation combination was too large, resulting in unbearable computational cost. therefore, a certain pro- duction strategy was developing for datasets, such as controlling the step size of the variable variation to reduce the total number of samples and adding random values to variables to increase sample diversity. simul- taneously, the representativeness of the samples was improved to the extent possible. accordingly, 5% gaussian noise was added to some sample features to prevent the network from underfitting and improve the generalizability performance of the network.



at the current level of geophysical exploration, observation data inevitably contains noise and errors, which in general leads to the multiplicity of geophysical inversion solutions. there are often many models used to fit observation data, and the complexity can be arbi- trarily high. however, due to issues such as ill posed nature, they often cannot achieve complete fitting results.if we change our thinking and seek to develop the fitting model in the most simplified direction to reflect the most basic feature information of the underground real model, the computational cost may be smaller and the goal may be completed the training, and finished the experiment. ningbo bai derived part of the theory and revised the expression of the formula and draft, and checked the code. bo han supervised the method and provided the methodological support. xiangyun hu provided data and improved conceptualization.



