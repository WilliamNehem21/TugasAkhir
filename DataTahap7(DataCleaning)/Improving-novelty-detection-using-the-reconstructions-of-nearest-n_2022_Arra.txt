novelty detection is an important field of research as identifying previously unknown behaviours in systems is critical for their main- tenance and smooth operation. it is the procedure in which a model is able to identify new classes of data that it has not been exposed to before. novelty detection is a far-reaching topic having been applied extensively in fields such as manufacturing [1], cyber-security [2], biomedical analysis [3,4], astronomy [5] and many more [6].



or outlying samples. then, during inference, the ae is exposed to novel samples which result in higher errors thus enabling novelty detection. methods such as mean-square-error (mse) [22], residual error [3], structural-similarity (ssim) [26] or feature consistency [27] are used to calculate the pixel-wise difference.



a common problem with using autoencoding methods for novelty detection is that aes can generalise to unseen classes thereby perform- ing poorly as novelty detectors [28]. in [9], this issue is addressed by placing a classifier in the training path of a multi-discriminator based autoencoder, which results in a fairly complicated and costly training procedure. on the contrary, we propose the nearest-latent- neighbours (nln) algorithm which uses the reconstructions of the nearest-neighbours in the latent space of autoencoders in-order to combat the aforementioned generalisation problem.



a critical distinction among all related work is whether supervised, semi-supervised, or unsupervised methods have been used [31]. su- pervised methods typically relate more strongly to anomaly detection scenarios, where both the normal and anomalous data classes are known a-priori [13]. however, supervision is not applicable in many settings, as anomalous classes are either underrepresented or just not known [13]. in the unsupervised setup, we have no a-priori information if the available data contains normal or abnormal samples [31].



semi-supervised methods are the most common in practice, as nor- mal (non-anomalous, non-novel) data is most easily collected from most systems [6]. in this case, models are designed to represent the expected operating conditions of a system and any deviations from that are considered novel. these deviations may, in some cases, be considered anomalous, however this is dependent on the context of operation [7]. for the remainder of the paper we focus on semi-supervised methods, where we designate particular classes of a dataset as novel and all other as expected.



it has been demonstrated that reconstruction-error based meth- ods alone are not particularly robust to noise, changing backgrounds and viewing angles [7]. in generative autoencoding models such as vaes, reconstruction probability or attention-mechanisms are used to improve performance [21,25,34]. furthermore generative adver- sarial networks (gans) [35] are used for reconstruction-error based anomaly detection [3,36,37]. here the residual error is calculated as the difference between the training and generated images using their intermediate representations provided by the discriminator. more re- cently, self-supervised learning (ssl) has been applied to aes and offers improved performance in novelty detection by using in-painting [23] or position prediction [38] pretext tasks.



for multi-class novelty detection, multiple classes are considered inliers and a single class is considered novel [8,20,27,36]. this is an inherently more challenging evaluation framework as the model should be able to generalise to multiple classes and still be capa- ble of detecting novel samples. in this work we evaluate our nln- enabled models in both a multiple-inlier-single-outlier (miso) and single-inlier-multiple-outlier (simo) contexts as defined by [30].



in [9,28] the generalisation problem of autoencoders when used for one-class novelty detection is described. they show that when an ae is trained on the relatively complex 8-class from the mnist dataset [46], the ae is able to implicitly learn the representations of digit classes such as the 1, 3, 6 and 7. in effect, reconstruction-based novelty detectors are prone to misidentify these implicitly learnt classes.



in order to evaluate our work across a number of different datasets we adapt our models accordingly. we adopt autoencoding the architec- ture specified in [24] for the evaluation of the nln algorithm on the mvtec-ad dataset. for mnist, cifar-10 and f-mnist we modify a lenet [56] based autoencoding architecture. the encoder consists of 3 is not the case for the texture classes. we suspect that this is due to our nln-enabled ae not being able to distinguish between different texture-patches. this behaviour is similarly demonstrated in [24], and we believe that this is an inherent weakness of standard autoencoding architectures.



