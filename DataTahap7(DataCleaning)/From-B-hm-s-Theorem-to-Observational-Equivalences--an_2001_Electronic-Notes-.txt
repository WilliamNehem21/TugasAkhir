there are essentially two ways of looking at the computational behaviours ofterms. one consists in putting the term within a context(possibly of-calculus extensions) and observing some properties(typically termination). the other consists in reducing the term until some meaningful information is obtained: this naturally leads to a tree representation of the information implicitly contained in the original term. the paper is an informal overview of the role played by bohm's theorem in these observations of terms.



implication being obvious!). if c[] is such a context, then a context like( xy:c[])i, where i x:x and( x:xx)( x:xx), is reducible to normal form when receiving m, and diverges when receiving n. the theorem can therefore be rephrased as stating that, given two distinct-normal forms, there is a context c[] such that c[m] has a normal form(i.e., converges to a value) while c[n] is nonterminating.



the rest of paper is organized as follows. in sect. 2 we examine the behaviours of terms within pure-calculus contexts, w.r.t. three di erent choices of what is to be assumed as the set of values. on the other hand, sect. 3 discussescalculus extensions allowing to discriminate terms exactly in the same manner as well-known tree representations of terms. we draw some conclusions in sect. 4.



is computed by the leftmost-outermost strategy: the term is rst reduced to its head normal form, then the normal forms of its subterms are recursively computed. the coinductive de nition corresponds to the way the possibly in nite normal form is gradually built by the same strategy in a possibly in nite approximating computation, like an irrational number is built by its successive rational approximations. it is therefore natural to de ne the notions of approximate or partial term, and correspondingly of approximate or partial bohm tree, using the symbol? for the subterms not yet in head normal form, i.e., the subterms yet to be computed. like bohm trees proper, the approximate trees were introduced by, with the name of bohm-like trees.



which, though joinable at every nite step, converge to two di erent limits, namely and(i(i(i:::))). with def. 2.1, on the contrary, all the approximants of hh are?, so the one limit is trivially?; more generally, the uniqueness of limits is preserved, and with it the uniqueness of meaning(if we adhere to a\syntactic" view of semantics).



-normal form, existing for every term, the one emerging from the above considerations. to keep distinct the newly de ned class of syntactic-semantic objects{ possibly in nite and possibly containing the pseudonite?{ from the ordinary nite terms, the de nition is formally given in terms of trees: the standard de nition of bohm trees. also observe the subtly di erent role played by the symbol? in bohm trees, where it denotes the unsolvable, from the one played in the approximants where it denotes the unsolved, i.e., a redex still to be computed; unsolved that keep unsolved forever are unsolvable.



actually, the nondeterministic choice operator gives too much freedom for replacing variables. we need to control that every time one occurrence of a variable is replaced by a combinator di erent from the expected one, the whole term cannot converge. this control can be realized by adding a standard numerical system, i.e., besides the constant 0, three numeric unary functional constants: a constructor s, a destructor p, and a test zero?.



as recalled respectively in subsect. 2.1 and in subsect. 2.3, besides the ordinary-reduction two other kinds of reduction{ and correspondingly of normal form{ have been considered in the pure-calculus: the head reduction, with the associate notion of head normal form, and the weak head reduction, or lazy reduction, with the associate notion of weak head normal form.



the ordinary reduction, also generically called-reduction, is the one induced by the rules;;;; by excluding the rule, one obtains the head reduction, induced by the rules;;; nally, the weak head reduction is obtained by further excluding the rule, i.e., it is the one induced by;. for each reduction relation there is the corresponding notion of normal form, which is a term where none of the rules of the respective set applies. by adding the-rule to the ordinary and head reduction one respectively obtains the



the normalizing leftmost outermost strategy for ordinary reduction, simply called normal reduction in the following, can be recursively de ned, as reminded in subsect. 2.1, by means of the head reduction. it also admits a recursive de nition using the weak head reduction: to normally reduce a term, reduce it by weak head reduction; if this terminates, then either the resulting whnf is a variable, in which case the normal reduction also terminates, or it has the form x:m or xm1::: mm, in which cases recursively weak head reduce the subterms, respectively m or m1,...,mm.



the l evy-longo tree[22,21,20] of a-normal form is the tree representation of this inductive structure of nested weak head normal forms, like the bohm tree was for nested head normal forms. here too the above de nition, if read coinductively, de nes the notion of a generalized, possibly in nite,normal form, existing for every term. approximate l evy-longo trees are the analogous of the approximate bohm trees, and so are the notions{ w.r.t. their bohm-tree homologous{ of partial order and limit.



in the representation based on head normal forms, the atom of relevant information is the whole underlined part in x1::: xn:xm1::: mm(with m; n 0). in the representation based on weak head normal forms, this atom is further split into smaller separate components x1,..., xn, x, since the minimal relevant information is the underlined part in x:m or xm1::: mm.



it is easy to verify that zero terms are either unsolvable terms of order zero, like and( x:xxx)( x:xxx), or they are reducible to terms of the form xm1::: mn where n 0, i.e., to applications of a free variable to any number(also zero!) of arguments.



