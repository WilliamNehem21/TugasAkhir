failure prediction has long known to be a challenging problem. with the evolving trend of technology and growing complexity of high-performance cloud data centre infrastructure, focusing on failure becomes very vital particularly when designing systems for the next generation. the traditional runtime fault-tolerance(ft) techniques such as data replication and periodic check-pointing are not very effective to handle the current state of the art emerging computing systems. this has necessitated the urgent need for a robust system with an in-depth understanding of system and component failures as well as the ability to predict accurate potential future system failures. in this paper, we studied data in-production-faults recorded within a five years period from the national energy research scientific computing centre(nersc). using the data collected from the computer failure data repository(cfdr), we developed an effective failure prediction model focusing on high-performance cloud data centre infrastructure. using the auto-regressive moving average(arma), our model was able to predict potential future failures in the system. our results also show a failure prediction accuracy of 95%, which is good. we thus believe that our strategy is practical and can be adapted to use in existing real-time systems.



there is also an urgent need for cloud service providers(csp) to offer a scalable, efficient and reliable on-demand resource to their customers in the presence of faults thereby fulfilling their service level agreement(sla). component failures within the cloud infrastructure are common, but large cloud data centres should be designed to guarantee a certain level of availability to the business system. infrastructure-asa-service(iaas) cloud presents computational resources(e.g., cpu and memory), storage resources and networking capacity that ensures high availability in the face of such failures. cloud systems can have tremendous failure rates as they feature many servers that are geographically dispersed with a high workload. the availability of such systems can be quickly endangered if the failure is not sufficiently handled.to guarantee the availability of services to cloud users, cloud infrastructures should be designed such that they should have minimal or insignificant system downtime. replication of data and checkpointing technique are some of the common existing strategies used to ensure availability of cloud services.



infrastructure as a service(iaas) is the most basic and important cloud service model under which virtual machines, load balancers, fault tolerance, firewalls and networking services are provided. the client or cloud user is provided with the capability to provision processing, storage, network and other fundamental computing resources to deploy and run arbitrary software such as operating system and applications. common examples of these services include rackspace, gogrid, ec2, google apps, concur, cisco webex, citrix goto meetings, adobe marketing cloud, facebook, flickr) and amazon cloud.



under the paas model, a computing platform including apis, operating system and development environment are provided as well as programming language execution environment and web servers. the client maintains the applications, while the cloud provider maintains the service run-time, databases, server software, integrated server oriented architectures and storage networks. various types of paas vendors offerings can include complete application hosting, development, testing and extensive integrated services that include scalability and maintenance. some key players include microsoft windows azure and google apps engine godaddy, windows azure, apprenda, google app engine, amazon web services, wordpress. the main benefit of these services includes focus on high-value software rather than infrastructure, leverage economies of scale and provide scalable go-to-market capability.



the remaining sections of this paper are organized as follows: section 2 presents a brief summary of work related to this study. section 3 presents a vivid description of our methodology, our proposed system model formulation and a brief overview of our dataset. section 4 discusses the results, the analysis of the system failure distribution across the time under study and the failure prediction. section 5 finally concludes the paper.



failures impact on availability and dependability of cloud data centre infrastructure, high-performance computing and distributed server systems has gained enormous attention in recent times. however, very few work has attempted to fully analyse and predict high performance and cloud failure data characteristics empirically. the authors in have made a good attempt to analyse the failure data of a largescale production cloud environment consisting of over 12,500 servers, which includes a study of failure and repair times and characteristics for both cloud workloads and servers, but they never looked at the failure correlation between workload intensity and size of the system respectively.



ofthe artworks. we decided to use a public dataset to enable other researchers in the field to compare their outcome with our obtained results. furthermore, in this work we are not limiting our experiments to a single hardware, rather we attempt to predict several component failures. for a more comprehensive review of other works of literature by other scholars, the reader is referred to-.



for several decades, time series models have been utilized in all fields of study for prediction. the models like autoregressive(ar), moving average(ma) and exponential smoothing ranging from linear to non-linear regression and a host of many others. box and jenkins developed a classical time series model called autoregressive integrated moving average(arima). these techniques were successfully applied in various domians such as data centre, complex industrial system and transportation networks and healthcare to predicts the failure of their systems-.



this nersc data was collected with the purpose of providing failure specifics for i/o related systems and components in as much detail as possible so that analysis might produce some useful findings. data were collected for storage, networking, computational machines, and file systems for production use at nersc from the 2001-2006 time frame. the data was extracted from a database used for tracking system troubles, called remedy, and is currently stored in a mysql database and available for export to excel format. as part of the scidac petascale data storage institute(pdsi) project collaboration this is the failure data for the high-performance computing system-2(mpp2) operated by the environmental and molecular science laboratory emsl), molecular science computing facility(mscf),.



the authors would like to thank the anonymous reviewers. their valuable comments and suggestions made the presentation of this paper much improved. one of the authors bashir mohammed is a petroleum technology development fund(ptdf) scholar. we would like to express our sincere gratitude to ptdf for their funding support.



