concurrent and distributed systems are more and more becoming open environments where components, agents or services interact one with another by dynamically establishing connections. for instance, in service oriented architectures, computational resources may be accessed through temporary interactive sessions. such open-interaction environments, subject to the dynamical binding of their components, may result into systems being partially defined even at run-time. describing and analysing the behaviour of such systems in presence of incomplete information



web crawlers(also known as bots, spiders or scutters) are programs that systematically browse the web to gather(and even produce) data. prominent examples include useful applications such as those used to feed search engines(e.g. googlebot), and spambots that collect email addresses or post forums with malicious purposes(e.g. spamming or phishing).



some protocols exist that aim at harmonising the collaboration between crawlers and sites. for instance, robot exclusion and inclusion protocols(e.g. the de-facto standards robots.txt and sitemaps, respectively) are used by web sites to inform crawlers of links to be excluded and included in their spidering activity. crawlers are free to respect or not such protocols but web servers can sometimes distinguish crawlers from human browsers(e.g. based on navigation speed or patterns) and thus control whether protocols are being respected or violated.



completely) and before communicating the page to its(possibly remote) database. a cautious crawler moves(i.e. changes target page) in a similar way, but does not check the page existence when communicating the url of a page to its database. a rash crawler checks nothing, i.e. it assumes the existence of pages that it communicates or tries to examine. all three kinds of crawler are able to examine an existing page. for the sake of simplicity we restrict to static networks: no page is added or removed during crawling activities.



we model such scenario with a simple name-based calculus where crawler agents c operate on a web of links link(x, y). we assume denumerable sets of channel names(ranged by a, b,...) and of site addresses(ranged by x, y, z, w,...) are available. the web system s may be empty or comprise crawlers, links and their composition:



pages are seen just as collections of links with the same origin. if the collection is empty we say the page is missing, it is valid otherwise. if the target of a link is a missing page, then the link is called broken.



any crawler can learn new site addresses by looking at the links departing from its current site. the corresponding rules are identical for the three different kind of crawlers and abstract away the actual interaction that would take place in concrete crawlers(rules learn). the graphical representation makes evident that the interface of the crawler agent may be enlarged by the acquisition of a new site address.



for the forms(c) and(d)(observations link(x, y)| y and c| link(x, y)| y) we exploit theorem 4.9 to derive a proper decoration for y. we show what happens for link(x, y)| y, but the other case is entirely analogous.



