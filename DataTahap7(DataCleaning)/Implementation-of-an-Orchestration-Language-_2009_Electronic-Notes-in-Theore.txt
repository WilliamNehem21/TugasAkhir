the present paper addresses this problem with an implementation of the orchestration language orc as a domain specific language in haskell. orc was, therefore, realized as a combinator library using the lightweight threads and the communication and synchronization primitives of the concurrent haskell library. with this implementation it becomes possible to create orchestrations that re-use existing haskell code and, conversely, re-use orchestrations inside other haskell programs.



the complexity inherent to distributed computation, entails the need for the classification of efficient, reusable, concurrent programming patterns. the paper discusses how the calculus of recursive schemes used in the derivation of functional programs, scales up to a distributed setting. it is shown, in particular, how to parallelize the entire class of binary tree hylomorphisms.



software composition. actually, at present, the point is not only to master the complexity of building and deploying a large application in time and budget, but also to manage an open-ended structure of autonomous components, possibly distributed and highly heterogeneous. the ubiquity of concurrency, in the double perspective of distribution and parallelism, entails the need for new approaches and languages for composing, at runtime, interacting software.



implemented as a domain specific language in haskell, orc becomes available to a vast community of users and developers. for example, a main motivation for developing horc was the possibility of coupling an orc animator to coorinspector, a tool for extracting coordination scripts(expressed in orc) from legacy code. horc makes possible to validate such scripts and, eventually, to transform them.



4 a small detail note: the definition of orc includes also a special operator called 0. in horc, though, 0 was implemented as a primitive site. to keep the symmetry of the presentation, we will defer the introduction of 0 until the primitive sites.



sites may return values that can be used by other site calls. we say that such values are published by the site call. due to the need for generality, site calls have very loose semantics: sites may take arbitrary time to respond or even not at all. so each individual site call may publish zero or one value.



common sub-expressions may be abstracted through the use of expressions, or as we prefer to call them, functions. functions are expressions where certain parameters have been abstracted by variables. these variables are introduced in the declaration of the function in a tuple next to its name; this is followed by the expression to which calls to the function reduce.



to count the number of threads that have still to finish, we abstract the act of processing messages by a function. this function repeatedly reads one publication, forwards it, if applicable, to the calling expression and calls itself recursively to process further messages. one of the arguments of this function is an accumulator that counts the number of threads still running. whenever it receives a nothing it decrements the value of the accumulator passed to the recursive calls. when the accumulator reaches zero, the function terminates.



instead, prune is composed by two steps. in the first step, f and the channel to which it publishes are initialized. prune then waits until a value is published or f terminates. in the latter case the operator terminates immediately without starting g or publishing any value. if f does publish a value, then a kill signal is sent to its thread and recursively to its child threads.



in this section we will show only two of the examples we have implemented in horc. for the first one we picked up the eight queens problem solution of and re-written it in horc to show the differences between the two languages. in the second example we focus in expressing more general programming patterns. we extend the definition of hylomorphism by allowing certain parts to run in parallel. as we later show, with this abstraction it becomes trivial to implement a parallel quicksort algorithm. among the other programming patterns we implemented in horc are mapreduce and workflow patterns.



this generalises the type of binary trees, by replacing the recursive part by an additional type variable b. the values of type b will be fed to the recursive calls. these recursive calls will, in turn, replace those values with their results which will then be consumed by the catamorphism. the definition of our de-forested binary tree hylomorphism is by introducing threads and communication primitives among them(channels and mvars); horc is built on top of these primitives. another approach is the semiexplicit parallelism provided by gph; instead of mandating a certain division of tasks, the programmer annotates the code, identifying possible division of tasks, and the runtime decides which of those divisions to follow. horc seems to lay in between the two approaches: it is higher level than using pure threads but the division of tasks is still fixed.



