laa creates unique document layout representation from which software for information extraction is learned to identify target fields on documents. the extractor is machine learning based solution that is trained on available layouts from a training dataset. learning procedure is heavily dependent on document layout containing positions of target fields on the document.



the motif for this research is to implement document understanding system that must be capable to extract target fields from document images processed with different ocr engines. different ocr engines generate different layouts for the same document image. layouts are stored in searchable pdf format. in addition, we do not have any information which ocr engine is used to generate searchable pdf which is input to the extraction module.



without laa module, we must train and maintain specific extractor for each ocr engine. although this solution is not efficient, it is not possible to implement it in situation where we can not know which engine is used to generate specific searchable pdf. so, we must have laa module than converts any layout representation to unique form from which extractor can identify target fields.



the basic use case in a document understanding system is as follows. documents are arriving from the stream. the system takes the current document and runs specific ocr engine that converts document image into searchable pdf file. generated file is, after that, sent to the information extraction module responsible for extraction of target information. but the input stream can contain searchable pdfs instead of images. it is not possible to know source of the searchable pdf file. for instance, the system does not know which ocr engine is used to generate pdf or if the pdf is digitally created. in the case when searchable pdf file arrives from the stream, it is directly sent to the information extraction module.



according to the previous, input to the information extraction module is always document in searchable pdf format. pdf documents are stored as set of very complex instructions that determine how elements will be situated on the document. this representation does not contain complex structural elements such as sentences or paragraphs.



additionally, the laa is responsible for achieving information extraction module robustness: the same layout should be generated regardless of document source. we want to eliminate any dependence on ocr engine, eventually searchable pdf can be digitally created. further, the laa should be capable to deal with possible anomalies regarding document geometry. for example, when document is generated and/or scanned some fields can be rotated or translated in unexpected way. the laa must flatten and smooth such undesirable transformations and create layout that is as close as possible to ideal case.



the paper is organized as follows. the next section presents related work. motivation, novelty and contribution of the proposed method is discussed in the third section. the forth section introduces laa algorithm for layout alignment. along with the main idea several modifications are considered. the fifth section is



page segmentation is the most important step in document layout analysis. the page segmentation algorithms divide a document image into homogeneous segments. each segment is part of physical layout structure and can represent text, typewritten text, graphics, diagram, logo, etc. line segmentation algorithms detect the beginning, the end, the top and the bottom of each text line. as it is mentioned in the introductory section, in this study we concentrate on line detection. so, physical document layout can be represented as set of recognized text lines.



also, authors propose very articulate classification of page segmentation algorithms that allows to identify main techniques implemented in the algorithms. according to them, there are three groups of segmentation algorithms for physical layout labelling. additionally, every method is classified as top-down or bottomup. top-down approaches start generating layout from the document level. bottom-up methods create layout from the pixel level. algorithms from the first group must know in advance the layout type they extract. for instance, some algorithms can recognize only manhattan layout. another layout types can be described with set of rules or grammar. these algorithms can be used without a



algorithms from the third group appeared last. the main approach behind them is to combine several other algorithms in one complex procedure. on the other hand, some algorithms from this group are based on methods from artificial intelligence area(neural networks, for instance) to learn significant parameters and build appropriate model for layout extraction.



on other hand, information extraction algorithms heavily depend on document geometry and positional information. many of them extract target information based on its position on the document and spatial relations with other elements[9,1,22,11]. in addition, their training consists of learning spatial relations between fields.



the main motif for this research arises from challenges in design and implementation of a document understanding system that must be capable to extract target fields from document images processed with different ocr engines. in other words, the aim is to make different page segmentation algorithms and ocr engines compatible in a sense that for the same document image they will produce the same physical layout. with this approach, document understanding systems become independent of pre-processing steps depending on page segmentation algorithm and ocr engine used.



an obvious solution is to maintain different extractors for every ocr engine. this will work only when it is known which ocr engine is used for processing document image and generating corresponding searchable pdf. the pseudo code for such solution is presented below.



the previous implementation implies that significant cost must be spent in maintaining extractor models for every ocr engine. for example, size of extractor models can be hundreds of mb. also, it is usually mandatory to implement active learning paradigm meaning that each extractor model must be periodically retrained with documents processed so far. this will increase models size as well as spend significant processor time.



to the best of our knowledge this is the first study discussing such problem. the laa is based on kmeans clustering algorithm with specific procedures for normalization and initial centroid generation. in this research we concentrate on administrative documents. our method does not make any assumption about document layout and it is parameter free.



the laa can remind of voting methods mentioned in the related work section. these methods are trying to find correct layout by voting between layouts obtained with several complementary approaches. it is possible because all of them process original document image and can involve and combine results of several external systems. in contrary, the method proposed in this study is not able to access the original document image or layout representations of every possible ocr engine to vote between them. it is provided with just one layout generated from the original image by unknown ocr engine and encoded into searchable pdf format.



searchable pdf and ensures that they will be placed uniquely regardless of which ocr engine is used. otherwise, all information regarding to elements position and size must be eliminated from extractor knowledge and model. inevitably, this will degrade its capability and usability(because of lack of the most important attributes for model training).



firstly, we must define unique measurement scale for transforming bounding box attribute. this measurement scale determines size of virtual document page and it is used for positioning text boxes on the virtual page. such page consists of lines. the line is uniquely identified with its y position on the page. each text box must be assigned to only one line.



the first step consists of text boxes extraction from a current page of searchable pdf file with pdfminer library. the result is represented in the form of xml tree. traversal of the tree is performed to generate list of text boxes corresponding to words. every word, apart from textual content, is extended with its bounding box attribute bbox. as we explained earlier, the bounding box is position(x, y) of the bottom left vertex as well as its width and height. bottom left corner of the page is(0, 0). virtual rectangle that borders word region. it is represented with



information extraction systems heavily depends on document geometry and positional information. many of them extract target information based on its position on the document and spatial relations with other elements[9,1,22,11]. to achieve desired information extraction independence of document source it is essential to introduce unique measurement scale and units. otherwise, all information regarding to text box position and size must be eliminated from extractor knowledge and model. inevitably, this will degrade its capability and usability(because of lack of the most important attributes for model building).



ized. this implies transforming values to become part of a smaller or more appropriate range. in other words, normalization step is to transform coordinates x and y, width and height for every word to the target interval[newmin, newmax]. we tested laa with several methods for normalization.



butes default target interval is set to[0, 100]. in this case the nates x and y, width and height for every word. for all four attributes, amin= 0 holds. for coordinate x, we set xmax= pagewidth. virtual page width is 100 as well as the page height. for all attrithe value for source page width is known from the first step



objects. every word is represented as one object in the list. apart from attributes that are read from the xml tree(created through pdfminer interface), every word is extended with values representing normalized bounding box region. attribute nbbox is of the following form nbbox= x_norm, y_norm, width_norm, height_norm.



every word is represented with y component from the normalized bounding box attribute. intuitively, it is because text line is dominantly determined with its position on y axes. the y component represents normalized position of left bottom vertex. the best experimental results are achieved with this approach. alternatives that are also implemented and tested represent word with any other vertex or centroid of the corresponding bounding region.



the last step from the laa algorithm loop generates list of detected lines. one line is represented with one cluster. at this moment we know for every word which cluster it belongs to. the information is included in generated clustering model. briefly, every word is labelled with identifier of cluster it is assigned to. for



in this section we explain experimental protocol for testing laa module. we performed a series of experiments on the set of 56 document images of very low quality and on the set of 30 document images of higher quality but still less than 100 ppi. in the rest of this section these datasets are referred to as dataset a and dataset b, respectively. with finereader we extracted 1298 text lines from the dataset a and 1150 text lines from the dataset b. entirely, 2448 text lines. tesseract recognized 1165 text lines from the dataset a and 1106 text lines from the dataset b. altogether, 2271 text lines. samples are real client documents from several different classes: forms, invoices, air tickets, contracts etc. for comparison, datasets used in several very popular competitions of page segmentation algorithms were of size between 720 and 4034 text lines.



the performance of the laa algorithm is measured based on the line accuracy measure usually denoted by fm and introduced in. the fm measure(can be considered as f1 score) is widely used to estimate line segmentation algorithms. it combines detection rate(can be considered as recall) and recognition accuracy(can be considered as precision).



consider two searchable pdfs generated with two different ocr engines from the single document image. they contain two layouts, potentially different. for this experimental protocol we can assume that each layout is represented with a set of text lines. each line in the layout is represented with surrounding bounding box,



the laa approach is based on clustering method. the main idea is to introduce unique measurement scale and to group words into clusters, i.e. text lines. input to the algorithm is searchable pdf file generated by unknown ocr engine. laa aligns given physical layout in a way that if any other ocr engine is used to process the same document image the resulting layout is always the same.



