global network of computers interconnected through different media using a standard protocol is called internet. modern human beings rely on the internet for their education, trade, socialization and entertainment, among many other important aspects of human life. information sharing, e-commerce and entertainment have taken a new dimension. evidently, the internet is the biggest revolution in the computing and communications world. web threats pose a broad range of risks, including financial damages, identity theft, loss of confidential information or data, theft of net- work resources, damaged brand/personal reputation, and erosion of consumer confidence in e-commerce and online banking.



in reflectfon/amplfficatfon based floodfng attacks, the attacker initiates small dns queries with forged source ip addresses which provoke a large extent of network traffic. and the dns response messages are significantly larger than dns query messages. as the result, this large extent of network traffic is directed towards the targeted system to incapacitate it.



the major focus of an http flood ddos attack is toward gener- ating attack traffic that closely simulates legitimacy of a human user. thereby it becomes harder for a victim to differentiate between legitimate and attack traffic. because of this type of attacks, the server becomes unavailable to legitimate users. the main impact of application layer ddos attacks are :unusually slow network performance (opening files or accessing web sites), unavailability of a particular web site, inability to access any web site, dramatic increase in the number of spam emails received.



the recent escalation of application layer dos attacks have attracted a significant interest of a research community. since application layer attacks usually do not manifest themselves at the network level, they avoid traditional network based detection mechanisms. as such, security community focused on specialized application-layer dos attacks detection mechanisms. these research efforts can be broadly divided into several groups:



puzzle-based methods are similar to these approaches. however, instead of monitoring characteristics of particular applications, puzzle-based methods, as the name suggests, offer a puzzle to solve and detect potential dos attack by the ability of the client at the ip addresses to solve it or by their reaction to the offered puzzle. one of these techniques is the detection of attacks using captcha puzzle [14]. although this technique may offer a simple approach to attack detection and mitigation, a number of studies showed its ineffectiveness [15,16].



fadir salmen et al. [22] created digital signature of network phase for flow analysis by using two meta-heuristic approaches. to investigate the behavior of planned approaches they injected abnormal traffic and showed improved accuracy in detection ddos attacks however the primary model is incapable for detection the dos attacks.



liu et al. [28] proposed dat (defending systems against tilt ddos attacks) is built with two coordinated defenders namely in/egress filter (if) and behavior analyzer (ba). the counter- attack mechanism offers different services to each user depending on their degree of deviation. yu et al. [29] proposed dow (defense



senthilnath et al. [33,34] explored the use of firefly algorithm for clustering. local minima is obtained by using the k-means clus- tering and this drawback was overcome by the firefly algorithm. the authors used k-means and firefly algorithm for clustering pur- pose which increases the time complexity and this is not applica- ble for detecting application layer ddos attacks in real time analysis.



in [43] the authors investigated the effect of signaling attacks and storms in mobile networks, focusing on signaling anomalies that exploit the radio resource control (rrc) protocol in umts net- works. as mobile devices and apps increasingly access the cloud in order to offload computationally intensive or energy-costly activities, signaling storms can create heavy overloads that can sig- nificantly impair system performance and offer very poor quality of service to users. in [44] authors defined the detection and miti- gation technique for storms that uses a software counter for each mobile user, within mobile devices or in signaling system.



the need of metrics should explore in contrast to packet pat- terns. the detailed exploration of the constraints observed in exist- ing contemporary models, which are stated in related work (see section 2), it is obvious to state that, in distributed environment, diversified packet flow is easy to achieve through minimal time frames and session time. the arrival rate based on human users, including a proxy server seems to constitute the non-pattern (ran- dom) cases. hence, to challenge this constraint, this manuscript devised a novel set of metrics, which are derived from absolute time interval rather than the session time and packet patterns.



technique called bat algorithm used to perform search to assess the compatibility during test phase. the cosine metric is used to identify the signatures of given transactions is used in training phase. the cosine similarities identify attribute set that imposes a discernibility relation. the signatures set that imposes the dis- cernibility is critical since, the signatures having similar context in both records of normal and flood formats are obsolete to



all transactions are formed into sessions that can be either ran- dom or variable timings. their exists different number of sessions for each time interval. count of number of sessions observed in one time interval gives maximum number of sessions of that time interval which helps in observing the user sessions to detect appli- cation layer ddos attacks.



user will access multiple pages in different sessions of time interval. how many pages are accessed in one time interval helps in observing whether the environment in network is malicious or normal. page access count of absolute time interval is the number of web pages accessed in that time interval.



many bio-inspired algorithms exist; bat algorithm belongs to this class which is based on swarm intelligence. the bat algorithm uses the echo based location determining behavior of bats to solve both single objective and multi-objective optimization problems. in proposed approach bat algorithm is used for classification (clas- sify the attack traffic and normal traffic).



step 1 and 2: initialize the bat population has to be produced. one record is treated as one bat for which it has any number of features. define the random number between m, t. where m is the number of features, and t is the number of classes.



step 7: above process has to be done for remaining all bats. step 8: calculate the error and update the random number. step 9: do the next iteration by using the above process until it reaches the maximum number of iterations.



prepared dataset of both normal and attack is given as input for the bat algorithm individually. for normal dataset, each record is considered as one bat and compare with the remaining bats to know how much distance it has to move towards the remaining bats. this has to be done for all the remaining bats. updated records are carried over to next iteration or generation. maximum number of iterations has to be performed for getting the accurate classifiers. once all the iterations are completed, the normal classi- fier is extracted and marked as normal signature. the same process is carried for attack training records to get the attack signature.



testing dataset has to be preprocessed by using the dataset pre- processing process. prepare the dataset with five attributes as like in the dataset preparation. calculate the total weight (light inten- sity) of the testing records individually. calculate the cosine simi- larity of testing record with both normal and attack signatures and declare whether the testing record is attack or normal by using the rules defined in section 4.2.



the proposed technique is tested against caida [38] (center for applied internet data analysis) dataset 2007. core objectives of this dataset are collection and sharing of data for research or scien- tific analysis of internet traffic, topology, routing, performance and security related events. dataset contains the parameters like server ip address, timestamp, time zone, object id/url of the web page, response code/status, number of bytes sent.



