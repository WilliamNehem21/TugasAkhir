allocation techniques and ilp instruction scheduling. if a classical register allocation is done early, the introduced false dependences inhibit a good further ilp extraction. however, this conclusion does not prevent any compiler from performing effectively an early register allocation, but with the condition that the used allocator should be sensitive to the scheduler as done in[12,11,8].



in some cases, we must introduce spill code and hence we change the problem(the input ddg). also, a combined pass of scheduling with register allocation presents an important drawback if not enough registers are available. during scheduling, we may need to insert load-store operations if no enough free registers exist. we cannot guarantee the existence of a valid issue time for these introduced memory access in an already scheduled code; resource or data dependence constraints may prevent from finding a valid issue slot inside an already scheduled code. this fact forces to iteratively apply scheduling followed by spilling until reaching a solution.



is provided in section 4. our large range of experiments show that our initial heuristics are nearly optimal in section 5. before concluding, we make a discussion in section 6 to argument why the rs concept is a better way for handling register constraints prior to ilp scheduling.



we prove that reducers problem reduces from the problem of scheduling under register constraints. let us start by defining the latter problem. for the sake of clarity of this proof, we assume that the considered register type t is implicit(we do not include t in our notations inside this proof).



the intlp system tries to build a coloring of the interference graph with exactly rt colors(the maximal number of available registers). if no solution can be found with rt registers, then solve another intlp after decrementing rt(until to 1). if no final solution can be found when reaching one available register, then the register saturation cannot be reduced and spilling is unavoidable. the variables xi t are computed using following constraints.



we did an extensive set of experiments on some scientific codes extracted from specfp, whetstone, livermore and linpack we used cplex to solve our intlp programs. since all the problems of rs computation and reduction are nphard, reaching the optimal solutions were very time consuming(from many seconds to many days). the experimented dags are simply some loop bodies(excluding branches). detailed numerical results and plots are shown in. basically, all our heuristics presented in are nearly optimal.



clearly, our rs reduction algorithm is very efficient: it, in most of times, optimally reduces rs with optimal ilp loss. sub-optimal ilp loss is, in most of times, accompanied with optimal rs reduction, while sub-optimal rs reduction is mostly accompanied with super-optimal ilp loss. we get both sub-optimal ilp loss and sub-optimal rs reducing in less than 1% of the cases.



our dag and processor model admit explicit reading from and writing to registers. thus, our method is more generic than the existing techniques, and can be applied for superscalar, vliw and epic codes. for the two later cases, a special care must be taken when reducing rs: we must prohibit non-positive circuits in the resulted dags.



computing the register saturation of a dag is np-complete. an intlp exact formulation is presented. our formal mathematical modeling and theoretical study in enables us to give nearly optimal heuristics. in the presence of branches, global rs of an acyclic cfg is brought back to rs in dags(basic blocs) by inserting entry and exit values with the corresponding flow arcs(see).



