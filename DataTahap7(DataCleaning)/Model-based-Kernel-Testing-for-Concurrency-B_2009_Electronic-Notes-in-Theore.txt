despite the growing need for customized operating system kernels for embedded devices, kernel development continues to suffer from high development and testing costs for several reasons, including the high complexity of the kernel code, the infeasibility of unit testing, exponential numbers of concurrent behaviors, and a lack of proper tool support. to alleviate these difficulties, this study proposes the model-based kernel testing(mokert) framework, which supports detection of concurrency bugs in the kernel by combining both model checking techniques and testing methods. the mokert framework was applied to the file systems of the linux 2.6 kernel and found a data race bug in the proc file system.



there are few tools that can support kernel testing, as the side effects caused by the testing tool/environment at the kernel space can halt the kernel or cause unexpected behaviors. in addition, testing tools often depend on libraries that cannot be used in the kernel environment. for these reasons, kernel developers continue to use printk() or a kernel log as a main debugging aid.



this study proposes a model-based testing framework for concurrency bugs in the kernel by using model extraction and model checking techniques. considering the difficulties of testing the kernel as mentioned earlier, model checking presents a viable alternative approach for analyzing kernels, since this technique can analyze each component of the complex kernel independently by modeling the component and the related portion of the environment in an abstract manner. in addition, model checking can explore numerous scenarios exhaustively, and generate concrete counter examples, which can be a useful aid to debugging. however, a pure model checking approach alone is problematic in that a developer cannot know whether a counter example detected through model checking is an actual bug or a false alarm due to the gap between the abstract model and target code.



promela(a modeling language of the spin model checker) is similar to the c programming language in several aspects. first, promela provides control statements such as if, goto, and do. in addition, promela models complex data structures using typedef and arrays, although pointer variables are not directly supported. also, promela supports inline functions which can simulate c functions.



the model-based kernel testing(mokert) framework applies the analysis result(i.e., a counter example) from model checking to the original target program so as to alleviate the difficulties of debugging concurrency bugs in the kernel code. most model checking frameworks do not suitably consider this issue, although it is crucial for the success of model checking techniques in the software industry.



mokert allows a user to replay one counter example repeatedly. thus, a user can conveniently identify the genuine cause of the counter example in the kernel code, not merely in the corresponding abstract formal model. this can be a very useful aid for detecting concurrency bugs, as thread scheduling should be controlled manually otherwise.



kernel bugs are often reported through manual code inspections, discussions, or artificial scenarios without actual testing, due to the difficulties involved with kernel testing(see section 1). thus, for example, the linux changelog contains dozens of bug patches that are not necessary or that do not fix a bug correctly. mokert can help users validate a bug patch by modifying the model according to the bug patch and model checking it to check whether the bug patch actually removes the bug. if the model checker generates a counter example, mokert can replay the counter example to check whether it is due to the incorrect bug patch or a false alarm.



at the run-time phase, the target threads execute with a controller thread and a monitor thread. the controller thread controls scheduling of the target threads via the inserted probes. the monitor thread monitors the target threads and the controller thread, and checks whether the counter example is replayed correctly or not.



the first case is what we expect from replaying the counter example. the second and the third cases indicate that replaying the counter example fails. if the last step of the counter example is not reached within a given amount of time, the monitor notifies a user of the replay failure with log information such as the status of each target thread and the function call stack. replay failures can occur for the following reasons:



by analyzing vfs readdir() and do rmdir() where the execution stalled, it was found that ext2 readdir() was protected by the mutex in vfs readdir(), as indicated at lines 33 and 39 of vfs readdir(), and ext2 rmdir() was protected by the same mutex at lines 2064 and 2072 in do rmdir(). considering that ext2 readdir() and ext2 rmdir() could be invoked only from vfs readdir() and do rmdir(), the data race detected from our model for ext2 readdir() and ext2 rmdir() was a false alarm. after we refined the model to include vfs readdir() and do rmdir(), spin did not generate a counter example.



this paper proposed the mokert framework to detect concurrency bugs in the kernel. the framework applies the analysis result of model checking(i.e., a counter example) to the actual kernel code. thus, the framework increases the level of user confidence, as it confirms the exhaustive model checking result on the real kernel code. we have demonstrated the effectiveness of the framework through three case studies on the the file systems of the linux 2.6 kernel and found a hidden data race bug in the proc file system.



