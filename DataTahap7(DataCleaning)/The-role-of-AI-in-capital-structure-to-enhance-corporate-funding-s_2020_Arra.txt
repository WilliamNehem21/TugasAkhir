the purpose of this study was to assess if artificial intelligence(ai) could be used in the capital asset pricing model(capm) and whether the use of ai could bring a more accurate estimation of expected returns. cost of capital defines the minimum return expected from any investment made by a firm. hence for managers to maximise the value of the corporation, it is essential to have an accurate estimation of the cost of capital.



for the purpose of analysing securities, the adjusted closing stock prices of 10 high-tech public companies were studied from january 2013 to january 2019. this research assumed that there is a need to predict returns for the next year. hence one year of historical data was used to calculate traditional capm value and also train the recurrent neural networks(rnn) to predict stock prices of the upcoming year. a generic deep learning network architecture was developed with the use of long short term memory(lstm) and dropout layers. after calculating the returns using traditional and ai approaches, two methods for calculation of capm were proposed and compared.



since most investments made by a business have a long-term outcome, the financial analyst uses the average of yield to maturity of default-free securities over many years(between 10 to 30 years in the u.s.) as the benchmark of the risk-free rate. hence sudden drops and rises in these securities can influence the cost of capital but using the average value will eliminate the sensitivity to these critical fluctuations. this was particularly important in financial crises that happened in 2008.



artificial intelligence(ai) is broadly defined as an algorithm that is capable of learning and thinking. learning is defined as the ability to update coefficients and parameters of an algorithm to enable it to recognise the pattern between input and output data. ai algorithm is defined in a variety of mathematical models, namely deep learning, neural networks, image recognition, etc.. deep learning is a form of machine learning that passes the learnings from the input through multiple layers(typically three or more) to gain a better understanding of outputs. one of the most significant applications of ai that perhaps threatened employments is the ability to analyse information, find patterns and make better decisions than humans while being empowered to execute activities in many cases. a well-known example of job susceptibility to ai is the driverless cars that have the potential to eliminate many jobs. in the context of finance, ai has been extensively used for pattern recognition and prediction of future events.



optimisation algorithms to identify the best parameters for a neural network model. ballings, van den poel et al. explored a variety of different models including random forest, kernel factory, adaboost, logistic regression, neural networks, k-nearest neighbor and support vector machines. they concluded that the random forest model outperformed others in the prediction of stock prices.



pao showed that neural networks are able to capture non-linear effects when modelling a capital structure that stays hidden in regression algorithms. general regression neural networks(grnn) was used to evaluate the capital structure of 163 uk retail companies. in this study, they collect various financial ratios(including growth in assets, net profitability, market to book value, etc.) to predict the debt ratio of retail firms in 2006. they trained the network using the financial data collected from 2002 to 2005, and their objective was to determine which factors have the highest influence on capital structure. they concluded that net profitability and depreciation to sale ratio are the most important compounding factors for measurements of capital structure. their findings were compatible with pecking order theory and they showed that neural networks are able to tolerate noise in data.



in this section, both the traditional method of calculating capm and the newly proposed methods will be compared. to do this, first analysis for calculating capm will be performed. it will be followed by the development of a neural network to predict stock prices. then a new capm will be calculated using predicted data. this will be followed by the calculation of return directly from the predicted data. finally all these findings will be compared with the actual returns.



all the calculations in this paper in terms of both analysis of financial data and the development of a neural network is done in python(3.7), which is a popular programming language. microsoft excel(2019) is used to organise and manage data that are generated using the python code.



where rlog is the logarithmic rate of return, p1 is the adjusted closing price of the previous day and p2 is the adjusted closing price of today. financial analysts rely on logarithmic return when they calculate the return of a single security. although there is not an official rule for this calculation, it has been a common practice. it is important to note that since the stock market is open only 5 days every week, in this study for consistency the average daily return is multiplied by 250 to obtain the annual average return.



rnn has one major problem, and that is an issue which is termed as vanishing gradient. this occurs when the gradient(partial derivative with consideration of inputs) becomes so small that essentially prevents weights from having any effect. to overcome this problem, a new method has been proposed by ref. that is called long short term memory(lstm). this method is briefly described next as it is used in this study to increase the accuracy of the predictions.



for clarity, in this section the outputs of the study should be described to enable the reader to make sense of the data that are produced following the procedures described in methodology section. first, using historical data of the past one year, capm(expected return) is calculated. second, using the same data that are used to calculated capm, the lstm was trained. upon completion of this training, the network predicts the prices in the upcoming year from which a return is calculated. third, the



the network hyperparameters are kept constant in this study due the limitation in time and computational cost of the project. hence, the results of the ai algorithm on other companies or other years may be better or worse than the example provided in this section. however, the performance of the network is not the objective of this research. the aim of this section of the study was to demonstrate the selected network architecture is capable of predicting stock prices with reasonable accuracy. this would be enough to carry on with the rest of the study and satisfy research hypothesis. hence readers should be aware that the performance of the network can certainly be improved if the target is to predict the future data more accurately.



these literature arguments. first, the estimation of risk or beta parameter may not be needed any more with its current definition. this is because market volatility is not playing a significant role when stock prices can be predicted accurately which also impacts capital asset pricing models; hence, risk should be defined in a new manner that relates to the uncertainty associated with the prediction of stock prices using ai. two possible methods could be suggested. one approach is to introduce a new algorithm that can incorporate uncertainty(probability of its occurrences) as a multiplier to the predicted returns on security. another method would be to evaluate the reliability of predictions on historical data and incorporate the standard deviation as the uncertainty associated with predictions.



will adjust itself upon the availability of new information. however, as it was demonstrated in this research, ai algorithms including recurrent neural networks(rnn) can adjust themselves in real-time. hence this problem becomes an infinite loop of adjustments through both the market and algorithms to make the prices more volatile. considering the nature of the stock market and the enormous number of available ai algorithms with various capabilities, it would be unrealistic for the market to be able to maintain this adjustment in a way that it competes with all predictive algorithms; hence, if these algorithms become publicly available and are used on a daily basis by most investors, the impact on the market would be extremely complicated to forecast at this stage. however, there is a good chance that ai can adapt and maintain a reasonably good accuracy of predictions.



a twenty years review on ai algorithms and their application in finance demonstrated that very few studies had used rnn. the application of rnn on the prediction of inflation data was evaluated in a previous study that demonstrated the ability of these algorithms in dealing with non-linear data. rnn was also applied to the prediction of foreign exchange rates and considered to be successful for implementation in real-time prediction platforms. more advanced rnn algorithms such as lstm which was used in this study demonstrated a much better ability to predict stock prices in the chinese market. heaton, polson et al. concluded that deep learning can detect behaviours that are not visible to financial theories that currently exist. compatible to literature, this study found that stock prices can be accurately predicted using deep learning recurrent neural networks that incorporated lstm algorithms.



direct application of ai to cost of capital could not be found in the literature. however, nelson, pereira et al. showed that rnn could accurately predict the trend in the data. this is compatible with the concept of beta that is used as a risk factor in capm that attempts to use historical data to predict security trend in comparison to market.



the focus of this study was to evaluate if ai could improve the accuracies associated with the estimation of cost of capital and expected returns. to do this, data of 10 public tech companies were collected, and traditional capm values were calculated every year for five years. the actual returns were also calculated using historical data. then two methods of using ai was proposed that included estimation of returns directly from the predicted values, or calculation of capm using predicted values.



for the purpose of analysing securities, the adjusted closing stock prices of 10 public tech companies were exported. these prices were collected for the past six years, starting from january 1, 2019. this research assumed that there is a need to predict returns for the next year. hence one year of historical data was used to calculate traditional capm value and also train the rnn to predict stock prices of the upcoming year. as it is known from the nature of ai algorithms, the more data provided, the more accurate the network will become. however, in terms of capm calculation, the more data that provided, the less reliable the prediction may become. this is because the future may not reflect historical patterns. for consistency in this study, only one year of historical data was used in both traditional and ai methods.



sophisticated ai methods. in this study, to overcome this bias of variation in ai algorithms and networks, once the network was optimised on a limited number of data, all the parameters and architecture were kept the same. of course, in ideal circumstances, these parameters should be optimised. however, the selected method would show whether the use of a generic neural network, designed and developed by an ai engineer, would be superior to traditional methods or not. this would simulate the situation that financial analysts only uses the algorithm without having any prior knowledge of ai or programming to predict stock prices. as a result of this issue, the network may not have performed flawlessly on some of the datasets.



by studying the results, in most cases when traditional capm is compared to the actual returns, it was found that the traditional value was consistently underestimating the returns in all ten companies and all five years. in many cases, ai predicted capm followed the same pattern. on average, the ai predicted capm was able to predict a more accurate return in comparison to the traditional method. this accuracy on average was 18% closer to the actual value. so by replacing this new method into the cost of capital calculation, the results of wacc can be improved by 18%.



when comparing ai predicted returns with traditional capm, it was noticed that consistently ai predicted returns were closer to the actual returns. quantitatively on average ai was calculated to be 60% more accurate. also, the ai predicted returns had the smallest standard deviation, which means there was a reasonably good consistency in the prediction of future returns. the implementation of this method in wacc would significantly increase the accuracy of the cost of capital calculation. it should be noted that if the network parameters and architecture are optimised, these values are likely to improve and get closer to actual returns.



as the community starts to trust the prediction of stock prices using ai, there will be a need to develop a new parameter that can evaluate the uncertainties associated with predictions. this could serve as a replacement to the beta which measures the risk in any investment. this research focused on the application of ai in one industry(high-tech) that is based in the us market. future research should evaluate the outcome of this analysis in other markets and industries to increase the reliability of these findings. since capm is used in portfolio planning, future research should explore the impact of using ai in designing portfolios in comparison to traditional capm method.



