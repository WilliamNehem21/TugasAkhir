in this paper we report on the capacity planning framework for performance evaluation process algebra(pepa) implemented in the pepa eclipse plug-in. pepa is a language in which modellers can compositionally describe complex systems. generally modellers define several different kinds of processes which interact with each other by sharing activities. once the model is defined, it can be numerically evaluated via a suite of techniques to obtain performance metrics. if the model is accurate enough then these translate to, and provide insight to, the real system under investigation.



being able to predict the performance of a proposed service by modelling the service and calculating the response-time under a given client-load is clearly useful. however when designing the system we still have some flexibility around the number of components that we may deploy. in the simple case we may be able to deploy more or fewer servers. in a more complex environment there are different components that make up the service being offered. for example there may be web servers and database servers as well as an external authentication service.



rates are associated with activities performed by each component. the symbol t is used to indicate that the component will passively cooperate with another on this activity. in this case the passive component may enable or restrict the activity from being performed by the cooperating component but the rate when enabled is determined by the actively cooperating component. the component(a, r).p performs the activity a at rate r whenever it is not blocked by a cooperating component and becomes the process p. the component(a, t).q passively synchronises on a and becomes process q.



nents. for example a web-service must spend money to obtain and run the physical(or virtual) servers which host the web-service. however the designer will also wish to ensure that the service gives enough performance such that, for example, the response-time is sufficiently low.



recall that our performance measure may be associated with the throughput of an action or the average response-time. additionally in either case we may desire either a high or low value. hence the cost function must be capable of penalising both a high or a low value for a performance measure. the simple solution is to set a target value for the performance measure and calculate the difference from this value. the modeller sets the target and the direction, so for a performance measure which we wish to search for as low a value as possible we have:



unfortunately it is impossible for us to set a useful default here since we cannot know in advance how the populations are costed. in addition the unit used for the rates in the model is undefined. hence determining how costly each unit of, for example, response-time is, is a task that is necessarily left for the user. to see this, consider that a model which used seconds as the unit can have all rates in the model multiplied by 1000. the steady-state probabilities will not change, but any response-time measure we calculate will now be in the units of milliseconds rather than seconds. this new model is just as valid, but clearly there would be a much smaller real cost associated with a one time unit rise in average response-time. hence the weights used in this model would need to reflect that.



our example scenario concerns a previously studied scenario which formed part of a case study of the sensoria project[6, chapter 2]. it concerns a hypothetical european-wide virtual university in which students study remotely. the part of the case study considered in the above work and in this work concerns the course selection phase where students already matriculated to the university must enrol in specific courses. although the students only enrol in a few courses per year they all do this at the same time, so it is important that sufficient provision is provided to maintain a responsive service.



now, although the left-hand side of the cooperation enables replya,b, the activity is not offered by the right-hand side, thus making the left-hand side effectively blocked until execute terminates(i.e., after an average duration of 1/r time units). these basic modelling patterns will be used extensively in this case study, as discussed next.



the entire search took 9499 seconds, or under 160 minutes. in doing so it solved 1694 models. we can say that each model therefore took approximately 5.1 seconds to solve on average. each model may take a different time to solve because the rates affect how quickly the model is solved. in addition there is some time spent performing the search algorithm logic, but this will serve us as an approximation. all of the computations described here were performed on a standard desktop computer. in addition it is the relative, rather than absolute times that we are mostly concerned with.



finally we wish to claim that capacity planning, or more generally a heuristic search, is a useful addition to any modelling software. it is difficult to provide the correct interface, but this is ultimately worth the effort. the capacity planning extension to the pepa eclipse plug-in project is now available as of october 2014.



