resource-rich shale gas plays a pivotal role in new energy types. the key to scientifically and efficiently developing shale gas fields is to clarify the main factors that affect the production of shale gas wells. in this paper, according to the shale gas reservoir characteristic of the fuling marine longmaxi formation, a single-well geological model was established using the reservoir numerical simulation software cmg. then, 10,000 different reservoir models were randomly generated for different formation physical parameters, completion parameters, and fracturing parameters using the monte carlo method, and these 10,000 models were simulated numerically. the machine learning model uses a dataset of 10,000 different geological, completion, and fracturing parameters as input and 10,000 production curves as output. multiple machine learning regression methods were used to train and test the dataset, and the optimal method(gbdt algorithm) was selected, and the accuracy r2 of the test set of the gbdt prediction model is 0.96. a fracturing parameter optimization workflow was constructed by combining a production prediction model with a particle swarm optimizer(pso). the process can quickly optimize the fracturing parameters and predict the production for each time by targeting the cumulative gas production under different geological conditions. the optimized parameters are fracture spacing, characteristics of shale gas reservoirs(onwunalu and durlofsky, 2009; williams-stroud, 2008; xu et al., 2015). curtis et al.(curtis, 2002) introduced the concept of shale and shale gas. they analyzed and compared the maturity, gas adsorption coefficient, reservoir thickness, organic content, and total gas volume of five shale reservoirs in the



development and that successful extraction of shale gas reservoirs requires hydraulic fracturing. zhang(zhang et al., 2009) investigated the effect of reservoir parameters and hydraulic fracturing parameters on the productivity of shale gas reservoirs using eclipse software. unsteady gas flow from matrix to fracture and multi-component gas desorption were considered. the matrix-fracture coupling factor(sigma) and fracture permeability were used to characterize the fracture network caused by fracturing. the effects of matrix and fracture permeability, non-darcy flow coefficient, porosity, matrix sub-grid, channeling coefficient, rock compressibility, half-length, and spacing of prominent fractures on production were analyzed. weiyu et al.(yu and sepehrnoori, 2013) demonstrated the accuracy of multi-stage hydraulic fracture numerical simulations for valuable barnett shale production data by factoring in gas desorption effects. based on the barnett shale data, six uncertain parameters within a reasonable range are determined to finalize the optimal design based on npv maximization for different gas price conditions. this integrated technique optimizes well location and hydraulic fracture treatment design to produce the best drainage area around the well. it gives insight into hydraulic fracture interference between single



plackett-burman-type linear experimental design method. parameters such as the practical reconstruction volume, the number of primary fractures, and the length of prior fractures were optimized through sensitivity analysis. zhu dawei et al.(zhu et al., 2020) developed a coupled local grid encryption-embedded discrete fracture model for fractured well production prediction. they adopted an orthogonal design to optimize parameters, including fracture length, fracture conductivity, and the number of fracture sections.



developed by comparing the prediction accuracy and prediction mean square deviation of multiple models. the coefficient of determination(r2) of both the training and prediction sets of adaboost and rf algorithms were higher and the prediction results were better. however, the mean square error difference between the adaboost training and validation sets was large, indicating that the adaboost method had the problem of overfitting. as a result, wang proposed developing the production prediction model utilizing rf rather than the adaboost method. tan chaodong et al.(tan et al., 2020) used the fracturing construction history data of 200 existing wells and reservoir physical characteristics to develop a bayesian neural network model to optimize the fracturing parameters. principal component analysis(pca) was employed to decrease the dimensionality even further. the bayesian



(1) the application of machine learning techniques in optimizing shale gas fracturing parameters and predicting shale gas production is currently a trending area of research that demands further exploration to unlock its full potential.(2) most studies get one data point, e.g., final recovery, daily oil(gas) production, etc. they are not a complete production curve, so it is impossible to use machine learning for parameter optimization and production prediction.(3) because of the complex physical properties of shale gas reservoirs, most research models tend to be idealized, which significantly weakens prediction accuracy. geological conditions of shale gas reservoirs and historical production data should be needed to ensure the accuracy of prediction models.(4) in the above research investigation, the small data set resulted in an insufficient amount of data. when machine learning is then performed on the data, overfitting occurs, thus making the established prediction models perform poorly.



this study proposes a complete workflow for optimizing fracturing parameters in horizontal shale gas wells, combining reservoir numerical simulation with machine learning to generate a machine learning model and using particle swarm algorithm(pso) to optimize fracture parameters. section 2 describes the machine learning methods used in this study, and the workflow is illustrated. section 3 develops the reservoir geological and numerical models for the target block. section 4, a shale gas horizontal well-fracturing dataset is obtained by numerical simula-



this section describes the methodological principles and the workflow of the main algorithms used in the study. the methods used include machine learning methods(wang et al., 2023)(linear regression(kavitha s et al., 2016; lim, 2019), support vector machines(svm)(cios et al., 2007; vapnik, 1999), decision tree(dt) regression(wang and xia, 2017), gradient boosting decision tree(gbdt) regression, random forest(brieman, 2001; gamal et al., 2021)), and particle swarm optimization(pso).



the particle swarm optimization was first proposed by kennedy(kennedy and eberhart, 1995), an american psychologist, and ebert art, an electrical engineer, in 1995 as a new parallel metaheuristic algorithm. the algorithm simulates the mechanism of cooperation in the flock foraging behavior of organisms such as flocks of birds and fish in nature to find the optimal solution to the problem(fernandez-martinez et al., 2008).



the meta-heuristic algorithm is a heuristic algorithm modification created by merging a stochastic algorithm with a local search algorithm. meta-heuristics is an iterative generating process that allows for studying and exploiting the search space with heuristic algorithms via the clever mixing of many notions. learning tactics are utilized in this process to collect and master knowledge to locate near-optimal solutions effectively.



prediction models and analyzing data effectively. to ensure the comparability of these parameters, it is necessary to standardize the original data. by applying data standardization techniques, we can eliminate the impact of varying magnitudes among the parameters, facilitating more reliable and meaningful analysis.



in the field of data standardization, two commonly employed methods are z-score normalization(jain et al., 2005; zou et al., 2020) and min-max normalization(kim et al., 2021). z-score normalization, also known as standardization, is a widely recognized data standardization technique. it involves transforming raw data into a standard normal distribution with a mean of 0 and a standard deviation of 1. this method is useful as it eliminates the scale differences among different variables in the dataset, making the data comparable and facilitating meaningful analysis.



step 2: database generation. the 10,000 sets of varying reservoir models are randomly generated and simulated using the monte carlo method to obtain the corresponding 10,000 sets of production curves for the orientation of different reservoir physical parameters, completion parameters, and fracturing parameters. multi-factor sensitivity analysis is performed on these parameters.



step 3: machine learning model building and application. the data set from step 2 is used as the input for the machine learning model with 10,000 different sets of geological, completion, and fracturing parameters and 10,000 different sets of production curves as the output. the best method(gbdt algorithm) is then chosen by training the data set with various machine learning regression techniques.



shale reservoirs have extremely low permeability and microfractures with different degrees of development. the overall performance is characterized by dual pore, so a dual pore dual permeability model is usually established to simulate the shale numerically. a single-well numerical model of a shale multi-stage fractured horizontal well is built using the geological characteristics of the upper ordovician wufeng formation reservoir and the engineering parameters of horizontal wells in the sichuan basin and its outlying areas.



prediction accuracy of the neural network model developed in this study(ottah et al., 2015). the value of r2 runs from 0 to 1, and the higher the number, the better the model fit. the formula for calculating r2 is as follows.



ume increases to a certain level, a further increase in langmuir volume significantly improves gas well production. as the langmuir volume increases, the proportion of adsorbed gas in the matrix increases, although the free gas content does not change. with 30 years of cumulative production, the adsorbed gas recovery is increasing as the free gas is continuously recovered.



the particle swarm optimization protocol(pso), a well-known meta-heuristic global optimizer, to determine the optimal design of fracturing parameters. the pso algorithm is combined with a trained gradient boosting decision tree(gbdt) model, which serves as a fitness evaluator for a large set of project design parameters. by employing the gbdt model, the computational burden of the optimization process is significantly reduced, allowing for a larger number of pso iterations.



different machine learning models have other production prediction effects. by comparing five production prediction models, we concluded that gbdt and random forest yielded r2 of 0.96 and 0.93, respectively, and they predicted models with better prediction performance than linear, svm, and decision tree regressor. through more in-depth testing and training, the final study concluded that the gbdt model was used to predict single well capacity and evaluate fracturing effectiveness.



