regression random forest is an ensemble learning approach that creates many regression tree models built from bootstrap samples of the training data(breiman, 2001). it also injects some randomness into the tree-growing process by randomly selecting only a subset of predictor variables to consider for split-point selection at each node. this operation reduces the chance of the same strong predictor variables to be selected when a split is to be carried out, thus avoiding regression trees from becoming overly correlated. the multiple regression tree predictors are knitted together to reduce the prediction variance and increase prediction accuracy. the method predicts the value that is the mean prediction of all individual regression tree predictors.



chiles and delfiner(2012). the simulation is performing using the r package rgeostats package(renard et al., 2020). this simulated data example for which the ground-truth is available everywhere within the study domain refers to a situation where there is a non-linear relationship between the response variable and predictor variables with some interactions between predictor variables. also, the response variable shows some spatial auto-correlation and its distribution is not gaussian.



provided by the regression-kriging, the traditional regression random forest, and the proposed one. the spatial prediction map resulting from the regression-kriging differs from the ones provided by the traditional regression random forest and the proposed regression random forest. in particular, the spatial prediction map of regression-kriging is smoother than the two others.



