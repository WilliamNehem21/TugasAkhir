machines and hyperspectral technology to identify early sugar beet diseases, with an accuracy rate of 97% for distinguishing healthy sugar beet from diseased leaves. wang et al.(2019) extracted color, shape, and texture features of fungal diseases such as powdery mildew, rust, and leaf spots on wheat leaves and used support vector machines to classify and identify them. used fuzzy c-means clustering algorithm to extract 25 disease features of wheat leaves and classified them using an artificial neural network to determine whether wheat was infected. traditional machine learning relies on manually generated specific features, which results in low recognition efficiency. remote sensing methods have achieved certain research results in crop stress monitoring, but lack spectral specificity of diseases, which may encounter uncertainty issues in monitoring. with the continuous development of big data and deep learning research, plant phenotype research based on deep learning methods provides a new means for crop disease recognition and has achieved significant results in crop monitoring and management.



identification models. statistical analysis showed that the resnet50 and svm classification models had higher recognition accuracy than the other models. proposed an optimized dense convolutional neural network called densenet, which achieved an accuracy of 98.06% and had fewer parameters and computation time than similar cnns. studied external defects in tomatoes and compared them with transfer learning training, showing that the resnet18 model was the best. in peanut variety identification,



which further decreased to 13, 20, 16, and 14 after integrating the cbam module. notably, the cbam module significantly improved recognition of sesame spot disease. by combining the bigru module to extract advanced features, misclassification rates were further reduced to 7, 8, 5, and 9 respectively. the results demonstrate the effectiveness of using rnns to process features of rice diseases, thereby enhancing the performance of the cnns.



this paper proposed an improved cnn for extracting features of rice diseases by combining inception and resnet theories. the network addresses the high misidentification rate by incorporating information about the rice disease images and their surrounding context. the improved cnn also includes cbam module for more precise feature extraction. additionally, bigru was introduced to recognize the relationships between stress image features, deepening the model's understanding of the images and the structural characteristics of rice diseases. the effectiveness of the proposed model is demonstrated through experiments, which show higher accuracy and lower cost compared to other models. however, the current dataset still has limitations, with only four types of rice disease samples. to address this, future work will focus on collecting more comprehensive real-field samples and improving the model structure to increase its generalization ability in complex scenarios.



