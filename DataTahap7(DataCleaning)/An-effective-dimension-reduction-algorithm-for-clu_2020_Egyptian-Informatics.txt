building an accurate and efficient text-clustering algorithm needs to tackle the problem of high dimensionality by using an accurate dimension reduction technique. since the high dimensionality produces a different, noise which affects the accuracy of the clustering algorithm. any efficient clustering algorithm needs to extract the main concepts of the text by eliminating the noise and reducing the dimensionality of the data. the dimension reduction techniques decrease the dimensionality of data such that the of the original data set[3,21,22]. the method of computing the principal component from the data matrix x is done by computing the eigen decomposition of the covariance matrix of the data matrix x. but the fastest algorithm is by using the svd to factorize the matrix x into u r rvtr, which give the k sample principal components as the projection of utk on the x data matrix. this projected space gives pca after applying whiten transformation to normalize variances to one to remove any noises. in this paper the features extracted using the pca(i.e. the projected space after whiten transformation is used in the clustering algorithm).



the researcher represents the corpus documents using termdocument matrix. each columns in this matrix stands for a given document whereas a row stands for a unique term. we represent a document of the corpus by a vector of terms in this document. the jth document is symbolized by vector xj=[w1j, w2j,..., wmj]t, where wij is the term weight and the number of terms is m in the corpus.



the reuters 21,578 dataset consists of a collection from the reuters newswire. this corpus contains 21,578 documents in 135 topics. i selected 10 categories from this corpus and removed any document in more than one topic, leaving 7293 documents(18933 unique words) in 10 categories.



i applied common preprocessing methods for the arabic corpus and english corpus such as stopword filtering, stemming using the stemmers(i.e. light stemmer for arabic and porter stemmer for english) and tfidf term weighting formula is used to form a term document matrix for each corpus.



