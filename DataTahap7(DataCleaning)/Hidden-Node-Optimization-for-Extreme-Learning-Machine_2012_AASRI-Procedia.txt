the number of hidden nodes is a critical factor for the generalization of elm. generally, it is heavy for time consumption to obtain the optimal number of hidden nodes with trial-and-error. a novel algorithm is proposed to optimize the hidden node number to guarantee good generalization, which employs the pso in the optimization process with structural risk minimization principle. the simulation results indicate our algorithm for the optimal number of hidden nodes is reasonable and feasible with 6 datasets on benchmark problems by the accuracy comparisons.



srm-elm (structural risk minimization elm, srm-elm) algorithm is proposed in this work to obtain an optimal number of hidden nodes for elm by pso, with structural risk minimization (srm) principle that consist of empirical risk and vc confidence. the most superiority of srm-elm is to avoid the overfitting by introduced the vc theory. moreover, pso chosen as the optimal tool will reduce the operation time compared with ga or de (differential evolution) algorithm.



vc-dimension h can be used as a measure of the computational complexity for machine learning. a good vc-dimension can improve the generalization of neural network. but, there is not a universal formula to calculate h for neural network. vc-dimension h was deduced with some formulae for the feedforward network with sigmoid activation function[10-12],



this work proposed a novel algorithm to optimize the number of hidden nodes for elm by srm and pso. we modified the formula for the vc confidence to reconstruct a concave function for srm as the objective function. then we employed pso to optimize the srm function for the optimal number for hidden nodes for elm. the experiment results demonstrate that our algorithm can be used to obtain the effective number of hidden nodes and an excellent generalization.



