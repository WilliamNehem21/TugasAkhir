abstract the rfid technology has penetrated the healthcare sector due to its increased functionality, low cost, high reliability, and easy-to-use capabilities. it is being deployed for various applications and the data captured by rfid readers increase according to timestamp resulting in an enormous volume of data duplication, false positive, and false negative. the dirty data stream generated by the rfid readers is one of the main factors limiting the widespread adoption of rfid technology. in order to provide reliable data to rfid application, it is necessary to clean the collected data and this should be done in an effective manner before they are subjected to warehousing. the existing approaches to deal with anomalies are physical, middleware, and deferred approach. the shortcomings of existing approaches are analyzed and found that robust rfid system can be built by integrating the middleware and deferred approach. our proposed algorithms based on hybrid approach are tested in the healthcare environment which predicts false positive, false negative, and redundant data. in this paper, healthcare environment is simulated using rfid and the data observed by rfid reader consist of anomalies false positive, false negative, and duplication. experimental evaluation shows that our cleansing methods remove errors in rfid data more accurately and efficiently. thus, with the aid of the planned data cleaning technique, we can bring down the healthcare costs, optimize business processes, streamline patient identification processes, and improve patient safety.



rfid is a technology which uses radio communication between tags and readers to automatically identify the locations of items. in a networked environment of rfid readers, enormous data are generated from the proliferation of rfid readers. the raw data generated from the readers cannot be directly used by the application because it consists of enormous volume of data duplication, false positive, and false negative. thus, the rfid data repositories must cope with a number of quality issues. these data quality issues include data redundancy, false positive, and false negative. poor data quality has adverse effects at the operational, tactical, and strategic levels of an organization. this is especially true in the healthcare field where cost pressures and the desire to improve patient care drive efforts to integrate and clean organizational data.



an rfid reader periodically sends out rf signals to its range. when an rf tag that moves within the range of the reader receives the signals, it will send a response signal along with its unique identifier code, timestamp, and location id. the reader receives the response signal and registers the data stream as one entry. there would be some rf tags which are not supposed to be detected by the reader and may be read due to the spatial divergence of rf signals sent by the reader. such readings are termed as false positive readings[8,9].



duplicate readings are classified into reader duplicates and data duplicates. the former occurs when a tag is present in the vicinity of more than one reader which is simultaneously sending signals to it. consider a scenario where readers r1, r2, and r3 are redundant since the tag t1 is read by all three readers at the same time, thus responsible for reader level redundancy.



the latter occurs when a reader reads a large amount of non-difference information at a time interval. for instance, in hospital management system, a tagged entity(say a doctor) may move to his consulting room and sit the whole day and send the data to the rfid management system constantly through the reader placed in his vicinity. but, from the management point of view, the most useful information for event detection is when the tagged entity(say a doctor) enters and exits his consulting room. therefore, it is necessary to reduce rfid data redundancy before processing.



parallel. this is because of overlapping in the reading vicinity of multiple readers and it is termed reader level duplication. duplicate readings at the data level occur when an rfid reader keeps reading the same object repeatedly. the proposed cbade predicts and cleans the duplication in middleware approach. the middleware cleaned data are stored into the database



rules that specify an rfid tag and its mobility. it defines the list of all allowed tag-location combinations. timestamp here defines the assumption or set rule that specify an rfid tag and its validity in a specific region mentioned in precondition with a time bound limit. it defines the list of all allowed time window for a specific tag-location combination.



