the component-based development method and formal language research communities have come up with solutions for component feature mapping on abstraction levels above implementation. various approaches have been proposed over the years to alleviate the typical component adaptation and wiring problems. some of the methods proposed are of a more formal nature, such as cl, koala, piccola, or abstract behavior types. some others view component integration from a more global perspective and embed the concepts of composition in an overall, less formal development framework. the most commonly known of these so-called development methods, most of which are based on object technology, are omt, fusion, room, hood, ooram, catalysis,



uml components, select perspective, foda, rational unified process(rup), to name only the most commonly known. many of the concepts coming from these methods are readily applied in industry more or less successfully on an intra-organizational level, e.g., the rational unified process. however, development methods are not universally applicable across organizational boundaries. due to their complexity, they are usually embedded deeply in an overall organizational context, so that their concepts are not transferable easily between customers and suppliers. moreover, they are bound to distinct graphical notations, and particular tools, that do not necessarily permit easy exchange of information between different stakeholders, i.e., in text form.



the previously mentioned formal component composition and coordination languages elevate the reasoning about properties of component composites to a higher level of abstraction, trying to avoid a full implementation cycle. however, they seem not to have made their ways into industry, simply because industry is afraid of the high initial investment associated with the introduction of rigorous specification techniques. koala is an exception, because it is coming out of an industrial context. although, koala provides syntactical mappings for object wiring only and does not consider behavior.



lsa is based on a terms-by-documents matrix that represents the occurrences of terms in existing documents. the columns of the matrix a correspond to the documents and the rows correspond to the stemmed and normalized terms. the cells contain the number of occurrences of a term in a document. this matrix a is analyzed by singular value decomposition(svd) to derive the latent semantic structure model, leading to three other matrices t, s, and dt: a= t0s0dt 0. t0 and dt 0 have orthonormal columns, representing the left and right singular vectors, and s0 is diagonal, containing the singular values. if the singular values(s0) are ordered according to size, the first k-largest may be kept and the remaining



in the callisto case study we had many uml diagrams available, apparently containing essential concepts that were not considered in the analysis. this lead to poor linking of concepts in these documents. a textual description would probably lead to much better results. graphical notations are more and more being used in industry because people can grasp the essentials of such documents more easily. in the future we will have to look at how we can extract this information automatically and make it available in textual form.



lsa helps us to identify few relevant components out of a large repository. the experiments that we performed are quite promising with that respect. lsa does not provide support for the next step in component procurement, the assessment of the likely adaptations to be carried out. at this moment we have no answer to this next problem.



