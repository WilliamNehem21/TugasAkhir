the inspiration for the present work comes from two recent developments. the first is the beginning of a categorical understanding of bayesian inversion and learning[9,8,7] the second is a categorical reconstruction of relative entropy[3,2,15]. the present paper provides a categorical treatment of entropy in the spirit of baez and fritz in the setting of standard borel spaces, thus setting the stage to explore the role of entropy in learning.



the second gave a powerful framework for constructing several natural transformations. in the hope was expressed that one could use these ideas to understand bayesian inversion, a core concept in machine learning. in this was realized in a remarkably novel way. these papers carry out their investigations in the setting of standard borel spaces and are based on the giry monad[11,13].



our contribution is to develop the theory of baez et al. in the setting of standard borel spaces; their work is carried out with finite sets. while the work of gives a firm conceptual direction, it gives little guidance in the actual development of the mathematical theory. we had to redevelop the mathematical framework and find the right analogues for the concepts appropriate to the finite case.



in this section we review some of the background. we assume that the reader is familiar with concepts from topology and measure theory as well as basic category theory. we have found books by ash, billingsley and dudley to be useful.



definition 2.2 a standard borel space is a measurable space obtained by forgetting the topology of a polish space but retaining its borel algebra. the category of standard borel spaces has measurable functions as morphisms; we denote it by stbor.



proof. since f satisfies all the above properties on finstat, we can apply theorem 5.2 in order to establish that f= crefin= cre for all morphisms in the subcategory finstat. we show that f extends uniquely to cre on all morphisms in sbstat.



as promised, we have given a categorial characterization of relative entropy on standard borel spaces. this greatly broadens the scope of the original work by baez et al.[3,2]. however, the main motivation is to study the role of entropy arguments in machine learning. these appear in various ad-hoc ways in machine learning but with the appearance of the recent work by danos and his co-workers[9,7,8] we feel that we have the prospect of a mathematically well-defined framework on which to understand bayesian inversion and its interplay with entropy. the most recent paper in this series adopts a point-free approach introduced in[5,6]. it would be interesting to extend our definitions to a point-free situation.



