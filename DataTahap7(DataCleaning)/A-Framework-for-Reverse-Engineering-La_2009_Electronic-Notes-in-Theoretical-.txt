when assessing the quality and maintainability of large c++ code bases, tools are needed for extracting several facts from the source code, such as: architecture, structure, code smells, and quality metrics. moreover, these facts should be presented in such ways so that one can correlate them and find outliers and anomalies. we present solidfx, an integrated reverse-engineering environment(ire) for c and c++. solidfx was specifically designed to support code parsing, fact extraction, metric computation, and interactive visual analysis of the results in much the same way ides and design tools offer for the forward engineering pipeline. in the design of solidfx, we adapted and extended several existing code analysis and data visualization techniques to render them scalable for handling code bases of millions of lines. in this paper, we detail several design decisions taken to construct solidfx. we also illustrate the application of our tool and our lessons learnt in using it in several types of analyses of real-world industrial code bases, including maintainability and modularity assessments, detection of coding patterns, and complexity analyses.



in the last years, several tools have emerged to support program understanding, software maintenance, reverse engineering, and reengineering activities. a large part of such tools extract their information mainly from the source code via static analysis. this includes a set of operations ranging from code parsing and fact extraction, fact aggregation and querying, up to interactive presentation.



for the c++ language, there are few static analysis and reverse engineering toolsets which meet all above criteria. robust static analysis of industry-size c++ code bases is particularly hard, given the language complexity, its several dialects, the presence of mixed c and c++ code, and the use of a preprocessor. moreover, although several c and c++ static analyzers exist, few come integrated in a framework with query, metrics, and interactive visualization tools which make them truly scalable and easy to use by software engineers.



interactive user interface which uses several novel visualization techniques to achieve scalability. solidfx was designed to cover a wide range of analyses, ranging from local variable level up to system architecture, and also as an open environment which allows integration of third-party analyses via plug-ins. overall, solidfx offers to reverse engineers the same look-and-feel that integrated development environments(ides) such as visual c++ or eclipse offer to software developers.



components: the parser, the query and metric engine, and the data views which solidfx adds atop of fact extraction and analysis engines. section 4 presents several applications of our tool on three real-life code bases. section 5 discusses our experience with using solidfx in practice and feedback obtained from actual customers. section 6 concludes the paper with future work directions.



this is our target domain. c++ static analyzers can be roughly grouped into two classes: lightweight analyzers do only partial parsing and type-checking of the input code, and thus produce only a fraction of the entire static information. lightweight analyzers include srcml, sniff+, gccxml, mcc, and several custom analyzers constructed using the antlr parser-generator. typically, such analyzers use a limited c++ grammar and do not perform preprocessing and scoping and type resolution. this makes them quite fast and relatively simple to implement and maintain. however, such analyzers cannot deliver the detailed information that we need for our(visual) analyses, as we shall see later. moreover, lightweight analyzers cannot guarantee the correctness of all the produced facts, as they do not perform full parsing. in contrast to these, heavyweight analyzers perform(nearly) all the steps of a typical compiler, such as preprocessing, full parsing and type checking, and hence are able to deliver highly accurate and complete static information. wellknown heavyweight analyzers with c++ support include dms, columbus, asf+sdf, elsa, and cppx. however more powerful, heavyweight analyzers are also significantly(typically over one order of magnitude) slower, and considerably more complex to implement.



heavyweight analyzers can be further classified into strict ones, typically based on a compiler parser which will halt on lexical or syntax errors(e.g. cppx); and tolerant ones, typically based on fuzzy parsing or generalized left-reduce(glr) grammars,(e.g. columbus). our early work to design an ire for c++ used a strict gcc-based analyzer. we quickly noticed the limitations of using strict analyzers. typical users do not have a fully compilable code base, e.g. because of missing includes or unsupported dialects, but still want to be able to analyze it.



the output of static analyzers, mostly produced by runnign batches, can be fed to a range of visualization tools. many such tools exist, ranging from linelevel, detail visualizations such as seesoft up to architecture visualizations which combine structure and attribute presentation, e.g. rigi, codecrawler, or softvision. an extensive overview of software visualization techniques is provided by diehl in.



extractor. a project is analyzed one source file(translation unit) at a time by the fact extractor(sec. 3.3), which saves information on four kinds of data elements(lexical, syntax, type, and preprocessor) in the database. each data element is assigned a unique id. the database is structured as a set of binary files, one per translation unit, and a set of has maps which allow referring to the elements by id within each file.



as outlined in section 3.1, our solidfx environment uses a c and c++ heavyweight analyzer of own construction. we based this analyzer on elsa, an existing c++ parser designed using a glr grammar. atop the parser which produces a parse forest of all possible input alternatives, elsa adds the complex typechecking, scoping, and symbol lookup rules that disambiguate the input to yield an annotated syntax graph(asg). the asg contains two types of nodes: abstract syntax tree(ast) nodes, based on the glr grammar; and type nodes, which encode the type-information created during disambiguation, and are attached to the corresponding ast nodes.



first, the parser, preprocessor and preprocessor filter operate in parallel. the preprocessor reads the input files and outputs a token stream enriched with(row,column) location data. for this, we can use a standard c preprocessor, e.g. as provided by the boost or libcpp libraries), patched to output token locations along with the tokens.



(section 3.2). in other words, the filtering phase eliminates all ast nodes which are present in the included headers but are not referred to by ast nodes contained in the analyzed sources. this eliminates all declarations and preprocessor symbols contained in the include headers which are not referred to in the sources. filtering the parsed output is essential for performance and scalability, as it reduces the output with one up to two orders of magnitude 4. finally, the filtered output is written to file using a custom binary format.



all in all, the several design choices made during the fact extractor implementation, i.e. using the elsa parser which has a highly optimized core written in c; providing lightweight error recovery at global declaration and function/class scope levels; filtering unreferenced symbols from the parser output; and writing the output in an optimized binary format, deliver an efficient heavyweight parser. solidfx is roughly three to six times, on the average, faster than columbus, one of the fastest heavyweight c++ parsers that we could test, and also scales well to analyze projects of millions of lines of code. for such projects, the fact databases saved on disk can take hundreds of megabytes. however, as we shall see next, querying such databases is still very fast.



function calls, variable uses, or type uses. the extracted diagrams can be laid out by hand or automatically using the graphviz library or a custom graph layout library developed by us. moreover, class and method metrics can be drawn atop of the laid out diagrams using icons scaled and colored to show the metric values, following an extension of the technique described in. the combination of diagrams and metrics is a powerful instrument for performing various types of code quality and modularity assessments(see section 4).



a data exporter. this type of integration allows us to extend our ire by reusing several existing software analysis and visualization tools with a minimal amount of effort. external views are preferred when the interaction between the fact database and the view is rather loose, and when the amount of data to be passed to the view is limited, as compared to the built-in views, which heavily access the fact database at a fine-grained level.



we illustrate now the solidfx ire with several samples from its actual usage within a number of industrial projects 6. in all these cases, the analyzed c++ code was developed by third parties, and we were not familiar with the code or its purpose before the analysis 7. the results of the analyses were discussed together with the stakeholders, mainly using the data views. an typical analysis session would take a few hours from the initial code hand-over until the results were available. a complete code base assessment would typically take three to six such sessions, where increasingly refined questions and hypotheses would be tested during the later sessions by means of specific queries on narrowed-down parts of the code base.



integration of its functions, presented under a uniform interface, and the possibility to execute complex analyses with minimal(or no) programming. using the ire was not much more effective than using scripted command-line tools for the extraction phase. however, for the exploration phase, the ire and its tight tool integration were more productive than using the same tools standalone, connected by little scripts and data files. reverse-engineering and code assessment scenarios are by nature iterative and exploratory, so they map perfectly to repeated selection, query, and interactive visualization operations.



it is tempting to consider the extension of our ire solution to existing ide tools, such as eclipse or visual studio. the main problem, in both cases, regards the availability of an efficient heavyweight parser which offers also fine-grained access to its fact database. a recent step in this direction is cdt, an open c/c++ development toolkit for eclipse. cdt resembles the goal, and loosely has the same architecture as solidfx, albeit in a much earlier consolidation phase. visual studio has the right type of parser infrastructure support built-in, so would be an excellent candidate. however, at the present date, the parser api is not



we have presented the design of solidfx, an integrated reverse engineering environment for c and c++. solidfx combines a heavyweight tolerant c++ parser with a fact database offering fine-grained access, an open query and metric engine, and several scalable visualizations that combine code, metrics, and diagrams. due to the high integration of these tools, solidfx enables users to conduct reverseengineering sessions with the same ease as software development is traditionally done in ides. several typical applications of the ire are presented.



we are currently working in extending solidfx in several directions. refined static information can be extracted from the basic facts, such as control flow and data dependency graphs, leading to more complex and useful safety analyses. secondly, we are working to implement a number of predefined ready-to-use analysis packages, such as checking for the misra c standard, thereby making the use of solidfx even more productive and easy.



