we aim at improving the performance of distributed algorithms for model checking and state space reduction. to this end, we introduce a new distribution policy of states over workers. this policy reduces the number of transitions between states located at different workers. this in turn is expected to reduce the communication costs of the distributed algorithms.



the main idea is to use abstract interpretation techniques to compute a small approximation of the state space, starting from some high level description of the system. based on this approximation, the connectivity of concrete states is predicted. this information is used to distribute states with expected connectivity to the same worker. experiments show a considerable reduction of cross transitions, at the expense of a modest unbalance of nodes per worker.



the behaviour of a reactive system can be represented as a state space or labelled transition system(lts). nodes of the lts correspond to states, edges to transitions between states, and labels on edges correspond to events. in enumerative model checking, an lts is generated from a system specification, and desired properties are checked by a model checking algorithm.



most algorithms above are based on reachability procedures, in which information is transfered between states that are connected by transitions. so, in order to reduce the communication costs, we must minimize the number of cross transitions, i.e., edges between states on different workers. at the same time, the number of nodes per worker must be balanced, in order to maximally exploit the parallelism possibilities.



as a solution, we propose to compute a small approximation of the state space by an abstract interpretation[8,15] of the system specification. the connectivity of abstract states is used to predict connectivity between the corresponding concrete states. in particular, the abstraction function is used, in order to assign the states to a worker.



as a feasibility study, we implemented this distribution policy. we measured the number of nodes per worker and the number of cross transitions. we compared the results with the random distribution on a number of large state spaces(millions of states). the improvement on the cross transitions are impressive, while the penalty of unbalanced number of nodes per worker remains modest. so, even though our ideas have not yet been inserted in the



related work. many papers presenting distributed model checking algorithms and other distributed applications on large graphs, acknowledge the importance of a good graph partitioning method. graph(bi-)partitioning is an np-hard optimization problem, therefore near-optimal solutions are computed using specialized heuristics or general stochastic procedures(like simulated annealing, genetic algorithms). our approach is an heuristics especially designed for graphs representing behaviours(ltss).



our approach has similarities to the one presented in, where a partitioning function is defined taking into account the structure of the original(petri net) specification. this gives a small number of cross transitions at the risk of bad balance. however, our experiments show that the abstract interpretation distribution algorithm produces a much lower proportion of cross transitions. the partitioning problem shows up in symbolic model checking as well.



all our distributed tools perform on an iterative basis, alternating computation and communication phases. the good performance of computation phases relies on the balanced workload, that is on a balanced assignment of states to workers. the communication phases consist mostly of exchanging information about neighbour states. therefore the communication performance depends on the amount of transitions that cross worker boundaries(cross transitions). our algorithm for branching bisimulation reduction walks, in every iteration, through whole subgraphs of silent steps. this operation is especially expensive if these subgraphs are scattered on more workers, as it is usually balance, i.e., more-or-less the same number of states on each worker. to measure this, we introduce the notion of worst case balance(wcb), as being the difference(in%) between the biggest load(number of states) assigned to a worker and the average load. since the sets of states assigned to different workers are disjoint, the average load is the total number of states divided by the number of workers.



as we have presented above, computing an abstract approximation of a system gives a prediction about the shape of the state graph and the connections among the states. we use the abstract transition system to optimize the number of cross transitions. however, the abstract graph does not contain information about the number of concrete states that are related to every abstract state, therefore the minimization of the cross transitions may have the drawback of the loss of balance of the system. to attack this problem, we first distribute the abstract states over c classes. the partitioning algorithm is:



for a feasibility study of our distribution policy, we implemented the steps above with minimal effort. we added code to our existing tools, to measure the effect on balance and cross transitions, but the implementation leaves still space for improvements. the results are compared with an existing and widely used implementation.



the selection of the initial abstraction is a crucial point in order to obtain satisfactory results. in our preliminary experiments, we hide the main part of the systems. we let unhidden some variables that control the flow of the system. this technique has the advantage that it can be completely automatized since the control flow variables can be easily detected. typically, the control flow represents accurately the shape of the final graph. this technique generates rather small abstractions which mainly contain may transitions. we believe that by increasing the size of the abstractions the results can be better. moreover, we think that the abstractions have to contain not only information about the control flow but also about data.



in all the cases but one the percentage of internal transitions is much higher using the abstract distribution than using the random one. in the case of the leader specification it is 6.5 times better. the only non-positive result is given by the bad client protocol. in this case the number of internal transitions is slightly worse than in the random case. this bad result may come from the fact that the number of abstract states of the initial abstraction is too small in relation with the number of concrete states or from a wrong selection of the initial abstraction. even though the last non-positive result, in the rest of the cases the gain is considerable.



the random distribution maximizes the balance of the system, the worst case balance is typically very close to the average. for the abstraction guided distribution the balance is not that perfect. the only case that the loss of balance is important is for the splice system in which one worker receives more than half of the states. this is due to the very small number of abstract states of the selected abstraction, which, however, leads to a very good transitions ratio.



the abstractions are computed in few seconds and the complexity of the state space generation is not incremented by performing the abstraction guided distribution. it is only needed to compute the mapping function from concrete states to abstract classes for every new state. the final redistribution is quickly computed due to the very small number of classes.



the next phase of the experiments will consist in doing some tests about the performance speed-up of the distributed model checking tools. for this purpose, we have to integrate the methodology in the existing distributed tools. we consider that the measurements presented above are a good indication about the final results, therefore we expect to increase the performance, specially for the cycle reduction algorithm in which the distribution of transitions plays a very important role. our method is completely scalable and has no extra cost for bigger instances of systems.



as we have seen, the algorithms used on the experiments are very simple. we believe that using more sophisticated algorithms may produce better distributions of states and transitions. we are currently working on an interface of our implementation with the software package chaco, which provides a collection of efficient graph partitioning algorithms.



