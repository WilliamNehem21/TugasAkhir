in previous work we have developed an effective rewrite system for specialization and optimization of generic programs. in this paper we extend it to also cover recursive data types. the key idea is to specialize traversal combinators using well-known recursion patterns, such as folds or paramorphisms. these are ruled by a rich set of algebraic laws that enable aggressive optimizations. we present a type-safe encoding of this rewrite system in haskell, based on recent language extensions such as type-indexed type families.



unfortunately, the obvious advantages provided by this style of generic programming come at a price: the performance of generic functions is much worse than analogous non-generic ones. in, the syb implementation of a standard set of benchmark functions was reported to run 7 times slower in average than the non-generic implementation. part of this performance loss is due to the run-time checks needed to determine at each node whether to apply specific or generic behavior. the remaining is due to structural reasons inherent to this style of generic programming: the traversal combinators must blindly traverse the whole data structure, even if a certain branch does not mention types where the specific behavior applies.



some new syb-like generic programming libraries have been proposed to address this efficiency problem. according to a recent survey, two of the most efficient are uniplate and smash. the former outperforms syb by restricting the power of the traversal combinators. the latter offsets some of the run-time checks to compile-time, but needs extra work from the programmer in order to support new data types.



in previous work, we have taken a different approach to tackle this problem: we developed a rewrite system that specializes generic functions for specific types. this specialization proceeds in two phases:(1) the generic functions are specialized to non-optimized point-free definitions;(2) these definitions are then optimized using standard algebraic laws for point-free combinators. the major drawback of that approach was the lack of support for user defined recursive types, such as the company type above.



the major contribution of this paper is to extend that specialization mechanism to also cover recursive data types. more specifically, we will focus on inductive data types that can be defined as fixpoints of functors. the key idea is to specialize traversal combinators using well-known recursion patterns for inductive types, such as folds or paramorphisms. likewise to standard point-free combinators, these recursion patterns are also characterized by a rich set of algebraic laws that enable further optimizations after specialization. most of the definitions that result from the new rewrite system have runtimes close to the hand-written non-generic ones. another contribution is the haskell encoding of these new laws: thanks to recent language extensions such as type-indexed type families, we managed to get an implementation that closely mimics the theory.



the key to avoid infinite expansions is to specialize traversal combinators using an alternative definition based on standard recursion patterns such as folds. likewise to point-free combinators, these recursion patterns are characterized by powerful algebraic laws, that will enable us to optimize the specialized definitions. for a comprehensive presentation of most standard recursion patterns and the respective laws see.



in order to overcome this problem, we decided to represent functors using typeindexed type families[21,3], a new extension to the haskell type system already supported in ghc. developed with type-level programming in mind, type families are type constructors that represent sets of types. set members are aggregated according to the type parameters passed to the type family constructor, called type indices: family constructors can have different representation types for different type indices. a type family to represent functors can defined as follows.



the first example is the generic transformation to increase all salaries. in order to increase the readability of the specialized point-free definitions, we will consider that the type-specific behavior is for the employee type instead of salary. in syb we have the following definition.



unlike systems specially designed to implement fusion(such as), our rewrite system cannot implement the full power of the fusion laws. however it covers most of the particular instances that occur during the specialization of generic functions. for example, the above optimization was possible due to the following instance of fusion-cata.



as expected, for both examples, the syb generic definitions perform much worse than the hand-written, and the loss factor grows with the database size. the syb gadt variant is at least twice as fast, but still much slower than the hand-written. the specialized point-free definitions perform closer to the hand-written, with loss factors of 1.11(increase 100) and 2.85(salaries) for the biggest sample. this performance loss is mainly due to the use of in and out to convert between user defined types and they structural representation as a sum of products. for these particular examples, the performance of the specialized point-free code is tangentially better than uniplate. as discussed in the next section, uniplate also has some mechanisms to avoid traversing unnecessary branches, which justify the proximity in the results. although quite standard when comparing generic programming libraries, these example are not particularly flattering to our optimization mechanism: in fact, there are no large branches of data that can be avoided in the traversals. for example, if the company data type had any other information besides departments(not containing the type salary), the runtime would remain the same, further widening the gap to syb. we also achieve a significant advantage when optimizing compositions of generic functions: for example, in the higher salaries example our specialized point-free definition was already 1.35 times faster than uniplate for the biggest



unlike syb, some generic programming libraries have been designed with performance issues in mind, usually at the cost of expressiveness. one such library is uniplate, that is among the fastest libraries currently available for generic programming in haskell. that fact, together with the syb-like flavor of its combinators, motivated an obvious inclusion in the comparative performance analysis of the previous section. the key idea behind uniplate is that most generic traversals have value-specific behavior for just one type. building on this insight, this library provides two key combinators to specify bottom-up generic transformations:



the main advantage of uniplate is that generic functions execute fast out of the box, without the need of an explicit optimization phase. on the other hand, likewise to syb, our optimization technique can handle more powerful combinators, that target different types in a single traversal. using fusion techniques, our approach can also further optimize combinations of traversals, while uniplate speedups are constrained to individual traversals.



another very efficient syb-like generic programming library is smash. instead of using run-time checks to find the target types, it offsets them to compiletime by using heterogeneous collections to encode the type-specific cases of generic functions. unfortunately, the speedup obtained with this technique comes at the cost of extra work from the programmer: in order to support a new data type, all different traversal combinators must be defined from scratch, while in syb they can all be generically implemented using just two primitive methods.



a different approach has been followed in, where a technique named symbolic evaluation was developed to optimize generic haskell programs. it focus on the specialization of fully applied functions and tries to eliminate conversions between types and their structural representations. symbolic evaluation guarantees that the intermediate structures are completely removed from the optimized code. a similar technique could be used in our framework to further optimize the point-free definitions, via an additional translation step to explicitly recursive point-wise code.



as previously mentioned, our main goal was to extend the specialization mechanism presented in to also cover inductive types. in we already described how it could be used to optimize the structure-shy xpath query language. this technique was harnessed into the prototype schema-aware xpath compiler xpto. query compilation in xpto proceeds as follows: the xml schema is parsed into a sum of products representation using type a; the xpath query is parsed into a type-safe representation of type pf a; the rewrite system is used to specialize the query to the given schema; the specialized point-free definition is output into a new haskell program to be compiled and linked with an xml parser and point-free execution library; the resulting program can then be used to execute the original query against xml files conforming to the given schema. we are currently deploying the new technique presented here into the xpto compiler in order to handle



we have extended an existent mechanism to specialize syb-like generic functions to also cover user defined recursive data types. by focusing on inductive types(fixpoints of functors) we were able to use recursion patterns such as folds and paramorphisms to encode generic traversals. these recursion patterns are characterized by nice algebraic laws, that were incorporated in a type-safe rewrite system to further optimize the specialized code. the definitions produced by our specialization mechanism perform close to hand-written non-generic ones. thanks to recent extensions of the haskell type-system, such as type-indexed type families or generalized algebraic data types, our implementation of the rewrite system closely mimics the theoretical presentation.



the major limitation of the current approach is that it only supports singlerecursive inductive types. we are currently investigating how to extend it to cover more general forms of recursion, such as mutually-inductive data types or nested data types. particularly relevant to this endeavor is the work described in, showing that higher-order functors can be used to give an initial algebra semantics to nested data types(likewise to standard inductive types).



