a quantification of this visual similarity could lead to the querying of a documental database using a documental pattern as the query. the answer to this query can be either the most(visually) similar document of the database or the most similar document from a pre-defined set. this last type of answer can be used as a classification method. moreover, the importance of visual features of web pages is increasing from the viewpoint of search engines optimization.



in a methodology for visual comparison is proposed. the method segments a page image into several regions based on image processing, and the result is presented as a graph. the similarity is then calculated by a graph matching algorithm. unlike us, the structure based on the tags is not considered. finally, a method for



plan of paper. the paper is organized as follows. section 2 recalls some standard notions, and introduces web page descriptions. in section 3, we present a transformation of html code that allows us to get a clear visual structure of a web page. section 4 formalizes a compression technique for web pages. this technique packs together those subterms which represent repetitive structures and shrinks those chains of tags that does not influence visually. in section 5, we define a measure of similarity between two web pages based on the tree edit distance algorithm[7,18]. section 6 describes the main features of our prototypical implementation. section 7 concludes and discusses future work.



when we look at a web page, we are not aware of the underline html code, but are only able to distinguish its visual structure. however, two different pieces of html code can express the same visual sensation. let us illustrate this by means of a rather intuitive example.



example 3.1 illustrates that, in order to provide for appropriate comparison among pages, the visual effect of each of the html tags should be considered. in the following we present an abstraction of web pages, which translates each web page to a canonical representative according to its visual structure.



in this section, we present two compression functions for the term that represents a web page which dramatically reduce the size of each singular page. horizontal compression(hrz) packs together those subterms which represent repetitive structures. vertical compression(vrt) shrinks those chains of tags that does not influence visually the result. first of all, let us introduce the notion of marked term, which will be used in the following sections.



note that, in favour of the largest numbers of repetitions, we use the integer division with round up[|. roughly speaking, definition 4.2 computes the mark, i.e., the number of repetitions of the currently processed node by using both the new and old values of its father. let us illustrate this by means of an example.



considering the translation given in section 3.1, this structured information favours the formation of chains of tags that does not influence in the overall structure of the page. in the following, we describe how to shrink the chains of tags while preserving the overall structure.



in definition 4.5, the first condition ensures that no repetitions are disregarded. the second condition ensures that t consists of a chain of tags(only having one child). the third condition states that grouping(grp) has a particular higher status than other elements, and thus, should not be compressed. the last condition allows us to keep information of the term. also note that the repetitions[r1]...[rn] of subterms of t are not considered.



the operators given in section 4.2 and section 4.3 allow us to compute the horizontal and vertical compression of a term. this is done by shrinking chains and joining subterms. in order to formalize the overall compression of a term, we define the following operator.



definition 5.2 assigns a quantitative measure, a real number between 0 and 1, that expresses the similarity of two pages. note that, a central question in the tree edit distance algorithm(and therefore in our comparison) is how to choose the cost values of single operations. in this work, we choose the natural(and intuitive) measure that assigns identical cost to insertion and deletion as well as relabeling





html was designed to visualize structure and information in an understandable way to humans. the main problem is its mixtures of semantic content, page structure and layout. web pages comparison is currently an open problem, whose importance extends from search engines to web data mining.



v. eglin and s. bres. document page similarity based on layout visual saliency: application to query by example and document classification. in proceedings of the seventh international conference on document analysis and recognition(icdar 03), page 1208. ieee computer society, 2003.



