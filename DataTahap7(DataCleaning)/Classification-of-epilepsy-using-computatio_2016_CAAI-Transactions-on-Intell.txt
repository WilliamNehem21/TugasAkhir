this paper deals with a real-life application of epilepsy classification, where three phases of absence seizure, namely pre-seizure, seizure and seizure-free, are classified using real clinical data. artificial neural network(ann) and support vector machines(svms) combined with supervised learning algorithms, and k-means clustering(k-mc) combined with unsupervised techniques are employed to classify the three seizure phases. different techniques to combine binary svms, namely one vs one(ovo), one vs all(ova) and binary decision tree(bdt), are employed for multiclass classification. comparisons are performed with two traditional classification methods, namely, k-nearest neighbour(knn) and naive bayes classifier. it is concluded that svm-based classifiers outperform the traditional ones in terms of recognition accuracy and robustness property when the original clinical data is distorted with noise. furthermore, svm-based classifier with ovo provides the highest recognition accuracy, whereas ann-based classifier overtakes by demonstrating maximum accuracy in the presence of noise.



epilepsy is a neurological condition such that it affects brain and the nervous system. it is a very commonly known neurological disorder and approximately 1% of general population is affected. only in the uk, around 1 in 100, more than half a million people suffer from epilepsy. there can be many causes of epilepsy and sometimes it is not possible to identify them. in the domain of epilepsy, seizure is referred to as an epileptic seizure and brain is the source. during an epileptic seizure normal functioning of the brain is disturbed for that certain time period, causing disruption on signalling mechanism between brain and other parts of the body. these seizures can put epilepsy patients at higher risk for injuries including fractures, falls, burns and submersion injuries, which are very common in children. these injuries happen because seizure can happen anytime and anywhere without prior warning and the sufferer would continue his or her activity with an unconscious mind. if a system can effectively predict the pre-seizure phase(the transition time of the brain towards developing seizure), it could then generate an early warning alarm so that precautions can be taken by the sufferer. absence seizure is one from many forms of generalized epileptic seizures in which larger part of the brain is disturbed. these seizures are very short and sometime may go un-notice. the patient seems confused and may not remember the seizure afterwards. the complex spike-and-wave patterns generated by the brain during these seizures can be recorded on the electroencephalogram(eeg) and a neurologist can identify the three absence seizure phases namely seizure-free, preseizure and seizure[3,4]. to automate this process, eeg data is converted into a digital format and fed into a computerized



seizure detection(classification) system, which can automatically recognize the input pattern. the two core modules of this classification system are: feature extraction and design of a classifier using these features. a feature extraction method extracts the most discriminative information from the eeg recordings, which means an ideal feature can have the property of differentiating among three phases of absence seizure.



the svm method maps the non-linear and inseparable data from an input space into a higher dimensional feature space where the data would then be linearly separable. this task is accomplished by utilising the concept of separating hyper planes. instead of computing a mapping function, the use of kernel function saves the computational demand especially for feature mapping function of higher dimensional space. the svm algorithm aims to maximize the margin(the region separating the support vectors on either side of the hyperplane) and tries to find an optimal hyperplane. hence, also called the maximal margin classifier. although, the training parameters for svm technique are very few, it can still be a computationally time consuming and highly complex. nonetheless, svm has a good generalization ability, solution to the overfitting problem and also performs well in a high dimensional feature space.



the organisation of this paper is as follows. section 2 explains the mechanism of digital data acquisition from epilepsy patients and also discusses the process of feature extraction method for designing the epilepsy classification system. it then explains how the three computational intelligence techniques; svm, ann and k-mc work. section 3 presents classification results that include design of classifiers using svm, ann and k-mc and evaluation of these classifiers against two traditional classification methods, nbc and k-nn. the paper ends with concluding remarks in section 4.



dwt decomposes the signal into several levels and each level represents a particular coarseness of the signal. at each level, the signal is passed through the high pass filter(hpf), which acts as the mother wavelet, and the low pass filter(lpf) that acts as a mirror version of the corresponding hpf. the output of each level is the downsized signal by a factor of 2.



according to the learning procedure, these techniques can be divided into supervised and unsupervised learning. in supervised learning, the algorithm takes example inputs(training dataset) and their corresponding output(class labels). it then learns a general rule of mapping inputs to outputs. svm and ann follow this strategy. in an unsupervised learning mechanism, no output is attached with the input examples. the data is grouped and clustered based on their natural or similar characteristics. k-mc is an unsupervised learning algorithm. in this research, we have explored svm, ann and k-mc.



case. non-linear support vector classifiers(svcs) use the kernel trick, which maps the original feature space to another higher dimensional space and through this mapping process the classification task may become easier. in this study we use the following three kernel functions.



where the subscript j indexes units in the input layer and p indexes units in the hidden layer. wpj denotes the input-tohidden layer weights at the hidden unit p. the subscript k indexes in the output layer and nh denotes the number of hidden units. d represents the dimension of the ith input sample. the advantage of using ffnn compared with svm is that for c-classes(outputs), the network can learn c



known backpropagation algorithm. the goal of this algorithm is to find a set of weight values for all the connections, such that it can minimize the error between the actual and desired output. a new sample x(*) is classified using the trained ffnn.



to achieve the maximum recognition accuracy of the three seizure phases, we have tried different number of hidden layers, hidden nodes and various combination of activation functions in this study. the best recognition accuracy was achieved by using 4 hidden-layer ffnn. the first hidden layer has 22 neurons and uses radial basis activation function. the second hidden layer has an array of 8 neurons and each node uses tangent sigmoid activation function. the third and fourth hidden layers contain 10 and 4 neurons respectively, and both the sense that it minimizes the sum of the squared lengths of the error, x(i) mk. where c represents the total number of clusters(classes), x(i) is the ith sample, and dk is the kth cluster. hence, a partition is optimal if it minimizes je and also called minimum variance partition. in our case, the data was



section 2.2, and to perform the classification experiments, each dataset is divided into 22 testing samples and 88 training samples. the training dataset is used to train the classifier. after the training process, the classifier is tested using the testing dataset to evaluate its recognition accuracy for any new pattern(sample). the percentage of recognition accuracy for both training and testing datasets are calculated separately based on correctly classified samples within each individual dataset.



to perform the experiments with svm-based classifiers, a soft-margin classifier has been used in all the multiclass svm classifiers. when polynomial kernel function(7) is used, we choose q 5. when radial basis kernel function(8) is used, we choose g 0.2. these values are used in all experiments which are achieved by trial and error approach for the best performance.



for k-mc, 100 iterations were performed to determine the cluster centres. however, clustering is a random process, which starts with random cluster centres. during these iterations, if the clusters did not change their positions, new clusters centres were determined to avoid the local minima problem. this process replicated itself 5 times.



2.3.1. nn is the neural network classifier consisting of four hidden layer architecture, nbc is naive bayes classification method, which uses two different density estimation methods, normal(nbn) and kernel smoothing function(nbk). k-nn is shown with different values of k(i.e., 1, 3, 5 and 7). and finally, k-mc shows the k-means clustering results.



generally, the recognition accuracy is decreasing when the noise level is increasing. the recognition accuracy of svm with polynomial kernel function has badly degraded in all the multiclass svm methods. however, svm with linear kernel function has shown good robustness property in the presence of different noise levels. among all the classification methods, the nn classifier has shown the maximum recognition accuracy of 85.8943% at highest noise level of 1. from the discussion and the results presented, it is fair to conclude that nn has a good generalization ability which is not very much degraded under the increasing levels of noise.



this paper has presented different supervised(svm and nn) and unsupervised(k-mc) learning algorithms for classifying epilepsy seizure phases. computationally intelligent techniques nn and svm have proved to be very good in recognising and classifying the complex and complicated patterns in the input data(eeg signals). the performance of these algorithms has been compared with two traditional classification methods, nbc and k-nn. it can be concluded that nn and svm have demonstrated the best recognition accuracy compared with traditional classification methods and an unsupervised learning algorithm, k-mc. furthermore, nn and svm both showed robustness property by maintaining best results even when the input data is contaminated with different noise levels. in addition, the feature extraction method is also introduced in the paper, which is able to gain rich information of the signal at a moderate dimension of the feature vector. also, the nn method outperforms the svm methods for some of the noisy dataset cases. in future, more classification methods based on neural networks such as selforganising maps and deep learning architecture will be explored and try to find the method, which is best at both noisy case and noise free case.



ph.d. degree from the department of manufacturing engineering, city university of hong kong, in 2010. he currently serves as an associate professor in the school of brain and cognitive sciences, beijing normal university, beijing, china. his research interests include biosignal analysis, neural engineering, and dynamics system.



respectively. currently, he works in beijing jiaotong university, beijing, china as professor. his current research interests include networked control systems; communication, control, and security in smart grid; control and security of cyber-physical system; communication and control technologies in smart traffic systems; intelligent control theory with applications for communication, networks and other areas.



