the theory of recursive data types is a valuable modeling tool for software verification. in the past, decision procedures have been proposed for both the full theory and its universal fragment. however, previous work has been limited in various ways. in this paper, we present a general algorithm for the universal fragment. the algorithm is presented declaratively as a set of abstract rules which are terminating, sound, and complete. we show how other algorithms can be realized as strategies within our general framework. finally, we propose a new strategy and give experimental results showing that it performs well in practice.



recursive data types are commonly used in programming. the same notion is also a convenient abstraction for common data types such as records and data structures such as linked lists used in more conventional programming languages. the ability to reason automatically and efficiently about recursive data types thus provides an important tool for the analysis and verification of programs.



perhaps the best-known example of a simple recursive data type is the list type used in lisp. lists are either the null list or are constructed from other lists using the constructor cons. this constructor takes two arguments and returns the result of prepending its first argument to the list in its second argument. in order to retrieve the elements of a list, a pair of selectors is provided: car returns the first element of a list and cdr returns the rest of the list.



which indicates whether a given term was constructed using that constructor. as an example of the more general case, suppose we want to model lists of trees of natural numbers. consider a set of three recursive data types: nat, list, and tree. nat has two constructors: zero, which takes no arguments(we call such a constructor a nullary constructor or constant); and succ, which takes a single argument of type nat and has the corresponding selector pred. the list type is as before except that we now specify that the elements of the list are of type tree. the tree type in turn has two constructors: node, which takes an argument of type list and has the corresponding selector children, and leaf, which takes an argument of type nat and has the corresponding selector data. we can represent this set of types using the following convenient notation based on that used in functional programming languages:



there are three main contributions of this work over earlier work on the topic. first, our setting is more general: we allow mutually recursive types and multiple constructors. the second contribution is in presentation. we present the theory itself in terms of an initial model rather than axiomatically as is often done. also, the presentation of the decision procedure is given as abstract rewrite rules, making it more flexible and easier to analyze than if it were given imperatively. finally, as described in section 4, the flexibility provided by the abstract algorithm allows us to describe a new strategy with significantly improved practical efficiency.



finally, another approach based on first-order reasoning with the superposition calculus is described in. this work shows how a decision procedure for a recursive data type can be automatically inferred from the first-order axioms, even though the axiomatization is infinite. although the results are impressive from a theoretical point of view, the scope is limited to theories with a single constructor and the practical efficiency of such a scheme has yet to be shown.



it is not difficult to see that the problem of determining the satisfiability of an arbitrary set of literals is np-complete. the problem was shown to be np-hard in. to see that it is in np, we note that given a type completion, no additional splits are necessary, and the remaining rules can be carried out in polynomial time. however, as with other np-complete problems(boolean satisfiability being the most obvious example), the right strategy can make a significant difference in practical efficiency.



that the greedy splitting strategy can be improved in two significant ways. first, the simple split rule should be replaced with the smarter split 1 and split 2 rules. second, these rules should be delayed as long as possible. we call this the lazy splitting strategy. the lazy strategy reduces the size of the resulting derivation in two ways. first, notice that split 1 is only enabled when some selector is applied to u. by itself, this eliminates many needless case splits. second, by applying the splitting rules lazily(in particular by first applying selector rules), it may be possible to avoid splitting completely in many cases.



