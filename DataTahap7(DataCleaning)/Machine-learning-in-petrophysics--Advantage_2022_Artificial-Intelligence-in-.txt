machine learning provides a powerful alternative data-driven approach to accomplish many petrophysical tasks from subsurface data. it can assimilate information from large and rich data bases and infer relations, rules, and knowledge hidden in the data. when the physics behind data becomes extremely complex, inexplicit, or even unclear/unknown, machine learning approaches have the advantage of being more flexible with wider applicability over conventional physics-based interpretation models. moreover, machine learning can be utilized to assist many labor-intensive human interpretation tasks such as bad data identification, facies classification, and geo-features segmentation out of imagery data.



the biggest advantage originates from the petrophysical data itself being well structured and understood. petrophysical data acquired either from laboratory core analysis or downhole logging tools has well defined physical models. as such, many well-developed machine learning algorithms can be applied on petrophysical data. the results from machine learning models can also be verified. xu et al.(2019) categorized petrophysical data by its source, type, index, and dimension. the most common datasets handled by machine learning are depth indexed core measurements and well logs. the data types and dimension may be different depending on data acquisition objectives, as exampled below.



as its adoption in petrophysics quickly grows, ml has proven to be a powerful tool for a wide range of problems. despite an incredible amount of excitement generated by in various fields, ml is not a silver bullet that can solve all problems. in many cases, ml solutions may not be optimal solutions due to the nature of the problem or the quantity and quality of the available data. before applying ml on any petrophysical problem, we may want to ask ourselves whether ml is necessary or cost effective?



regardless, whatever model or method used, the aim of using ml is to find an answer to assist in business decision making. sometimes, the answer does not need to be perfect to work, especially when considering the uncertainties of acquired data and data representativeness(ma and amabeoku, 2015). however, when a physical model is too complex or unavailable, problems may not be solvable from physics point of view. in this case, ml, as a data-driven tool, can usually provide an answer with quantified uncertainty(khan et al., 2018; basu et al., 2020, chen et al., 2022). as it says, all models are wrong, but some are very useful. if the ml answer is proved to be good to assist in business decision making, it is useful.



high-dimensional data such as arrays, images, waveforms, and 3d volumes are challenging to the capability of human recognition. even with the assistance of modern 3d visualization, it is still hard for human to accurately label and interpret high-dimensional data. for example, it is nearly impossible to pin-point different minerals on a high-resolution thin section image or trace every pore on a 3d volume ct scan of a rock. in these cases, we must resort to machine to find a solution.



are many, including tool calibration, tool resolution, samples acquisition, and physical sample alteration before testing. for both ml and human working, if data is not representative to the targeted problem, the produced answers would be unreliable. ml techniques can be used to identify outlier data(akkurt et al., 2018, misra et al., 2019) and make corrections to the identified data with inputs from subject matter experts. however, if uncorrected non-representative data is used in ml modeling, it is not expected that machine would recognize this data quality issue, which will affect the modeled results. it is suggested that erroneous outliers be removed and all necessary corrections should be applied to the data before using them in the machine leaning model.



data consistency is another issue faced by both physical modeling and ml approach. data acquisition settings may vary significantly from well-to-well and from field-to-field. technology also evolves rapidly over time, thus tools used for data acquisition may be different from the same service provider or from different service providers. borehole environments may change with advancement of drilling and drilling fluids. geology always varies vertically and laterally. with field development, reservoirs are also undergoing fluid transitions(gas-oil-water) and changes in geo-mechanics with pore pressure changes. correction and normalization of all these factors are difficult, but necessary to ensure data quality and consistency from different wells or locations.



the ml model trained by labeled data is strongly impacted by the accuracy of the labeled data. if the labeled data is inaccurate, the ml model will be misled. for example, core data are often considered as ground truth to calibrate well log interpretation or to train well log based ml model. if the core measurements are mishandled and give inaccurate results(e.g., permeability measurements without applying correct reservoir stresses), this inaccuracy will be transferred to the well log based model as well. machine cannot tell whether the labeled data from core is accurate or not. geologists label facies based on their own experience and the labeling process can be biased. therefore, the ml model trained by the human labeled data will also show the same bias.



the importance of physics cannot be underestimated even with machine learning approach. this is particularly true when the data size is small. physics informed or guided ml potentially performs better, thus has gained much more attention recently(liu et al., 2021). understanding the physics, if possible, behind the data should always be helpful in correcting and/or normalizing data or extracting representative rock attributes(xu et al., 2012). in many cases, forward physical modeling can be used to generate large volume of synthetic data for training or verifying the machine learning models.



data size is not big enough, overfitting becomes a common issue, if too many unknowns are intended to be solved. therefore, it is also suggested that the machine learning model be as simple as possible. applying sophisticated deep learning model on a small petrophysical dataset may lead to seemingly good but erroneous results.



petrophysical interpretation heavily relies on human expertise and knowledge. an experienced petrophysics interpreter often sees a lot of features behind the noisy and complex dataset such as in borehole image interpretation. machine learning assisted petrophysical interpretation workflows can benefit from human expert inputs and guidance at multiple stages of the project, including data quality control and improvement, data labeling, model selection and verification. more importantly, advanced machine learning model should be able to assimilate human expertise and accumulate a knowledge database from multiple projects.



in many cases we reviewed from the literature, ml approves to be an alternative technology powerful enough to change business practices, but remains complementary and needs to be calibrated to physics-based model. being complementary and alternative means that ml can solve what physical model can solve, and more efficient in cases of big data. however, it may not show huge advantage over conventional physical models in term of accuracy.



for example, in the 2022 spwla ml contest(fu et al., 2021), ml is used as an alternative to solve multiple mineral composition model. the training data is from 10 wells that have results calculated with conventional multimineral solver. therefore, we cannot verify the model performance beyond the conventional multimineral solver. the best case is that ml can achieve the same accuracy level as the conventional multimineral solver. for a practical field study, one can apply the same multimineral model to newly drilled wells for formation evaluation. in this case, ml may work as an alternative approach, without expecting extra advantage.



2018). another example may be that a well-trained convolutional neural network can be used to automatically segment geological features including vugs and fractures out of huge volume of imagery data quickly(liu et al., 2022). we believe more disruptive applications will emerge by leveraging deep learning to achieve automation in interpreting high-dimensional data, such as borehole image analysis, evaluation of cement quality and pipe corrosion(viggen et al., 2020; xu et al., 2022).



akkurt, ridvan, conroy, tim t., psaila, david, paxton, andrea, 2018. jacob low, and paul spaans."accelerating and enhancing petrophysical analysis with machine learning: a case study of an automated system for well log outlier detection and reconstruction. in: spwla 59th annual logging symposium. onepetro.





