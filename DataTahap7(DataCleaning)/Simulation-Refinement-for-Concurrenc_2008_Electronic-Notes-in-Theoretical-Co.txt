in recent years, we extended the theory of abadi and lamport(1991) on the existence of refinement mappings. the present paper gives an overview of several extensions of the theory and of a number of recent applications to practical verifications. it concludes with a sketch of the results on semantic completeness, and a discussion of the relationship between semantic completeness and methodological convenience.



indeed, one of the first problems with concurrent algorithms is the specification. they are usually reactive programs: they start in a rather blank initial state, interact in meaningful ways with their environment, and when they terminate it is often by mishap. in particular they cannot be specified by preconditions and postconditions only.



overview. section 2 gives the basic formalism with specifications, executions, behaviours, invariants, strict implementations and simulations, refinement functions and forward simulations. in section 3, we discuss a range of(non)atomicity conditions, to be used in section 4 where we verify a lock-free implementation of a row of atomically modifiable variables.



a visible specification k is said to strictly implement a visible specification l if every observed behaviour of k is an observed behaviour of l. in order to prove such a thing, however, we must be able to look behind the scenes. we therefore introduce simulation relations.



it is well-known that refinement functions are not enough to prove all simulation relations. a natural way to prove that one specification simulates another is by starting at the beginning and constructing the corresponding behaviour in the other specification inductively. this idea is formalized in forward simulations[7,22,23], defined as follows.



the minimal correctness assumption for a shared variable is that the correctness of its read and write operations is guaranteed if and only if these operations are performed under mutual exclusion. in other words, chaos can result whenever two processes concurrently access the variable. let us call such variables unsafe.



in other applications, the aba phenomenon can be a problem. this problem is avoided in the load-linked, store-conditional primitive ll/sc, which for a shared variable x is described as follows. the variable x gets a field links of type set of process.



when cas variables or ll/sc variables are offered by the concurrency platform, they have simple types like integer. it is therefore important to implement atomically modifiable variables of arbitrary types by means of cas or ll/sc variables of simple types. alternatively, one may look for wait-free implementations of ll/sc variables by means of cas or ll/sc variables of simple types, e.g..



in[5,6], we considered the problem of implementing a row of atomically modifiable variables of an arbitrary type by means of safe variables of the same type. given are n processes and m shared variables. every process needs repeatedly to inspect and modify some variable according to some given argument. logically the actions on the variables must be independent(done



the system is not allowed to modify arg and out. the only observable variables are out.p for all p. in other words, the observation function removes all other variables. the types node, arg, item and command c are parameters of the problem. in particular, command c can be used to observe the values of array node via result.



before dealing with the correctness of this algorithm, we need to model the assumption that the elements of array ar are not more than safe. this means that during a modification of ar[mp], writing by some other process leads to chaos, while reading may return an arbitrary value. we model this by means of a boolean array wr[m+ n], initially false, with the intention that wr[j] indicates that some process is writing ar[j]. we introduce a location 11 where the acting process sets the flag wr(mp) to indicate that it will be writing there. if it is set already, chaos results. in the next instruction, reading of ar[mi] gives a nondeterministic result when wr[mi] holds. the flag at mp is reset after command c(arg, ar[mp], tmp). we thus obtain: 14. aq0 is preserved because of aq1 and aq3. aq1 is preserved because of aq0, aq2, aq3, and aq4. aq2 is preserved because of aq1, aq3, and aq4. aq3 is preserved because of aq1, aq2, aq4, and the new predicate



the purpose of the computation is in the values computed in 13 and transferred in 12 and 14. we expect that the invariants for the values will be forced upon us by the proof of the refinement function. in the concrete algorithm, progress only occurs when the sc in 14 succeeds. we therefore take this event as the linearization point. in view of formula(1), we propose the refinement function



we come back to the private variable tmp used in lines 13 and 14. the programmer can just as well replace tmp by result in 13 and omit the assignment to result in 14. then, however, the refinement function fca is no longer correct because result changes in the line 13, which corresponds to a skip statement in the abstract specification. the easiest solution would be to introduce a history variable, say prev, that remembers the previous value of result, and to use prev in the refinement function. the introduction of prev would need a forward simulation.



sometimes, when matching a concrete specification with the abstract specification it is supposed to implement, the verifier feels that the abstract specification does a certain nondeterministic step earlier than the concrete specification. in order to get a simulation between the two, they may then feel forced to extend the concrete specification with a ghost variable the value of which is guessed nondeterministically. this is called a prophecy. we give an example in section 5.3 below.



the conditions(epfw) and(epbw) are restricted versions of(f1) and(b1) for forward and backward simulations. conditions(eptot) and(epcon) serve to connect episodes with nonepisodic periods. one may note that the graph of a refinement mapping is an episodic simulation for every episodic set.



in concurrency, we abstract from time, but not from the order in which phenomena occur. this means that the fact that a state remains unchanged during a finite number of steps is not observable. this is formalized by the concept of stuttering. we have therefore to complicate matters by allowing nonstrict implementations and simulations.



according to, therefore, specification k is called an implementation of specification l if every observed behaviour of k has a stuttering that is an observed behaviour of l. we thus allow the observed behaviours of the implementation to be slowed down by inserting stutterings. we now also get nonstrict versions of simulations and forward simulations.



this result was strengthened considerably in where we eliminated the conditions of strictness and preservation of quiescence. we summarize the main results here. it may be unexpected, but we have to introduce a history variable that only expresses that time increases forever.



in this theorem, the clocking extension and the stuttering forward simulation g are needed merely to control the execution speed. the real power of the theorem is in the eternity extension. in the strict case, we do not even need arbitrary forward simulations. in the nonstrict case, the stuttering forward simulation g is used only to enforce stutterings. in some sense the eternity extension is too powerful. we have come to regard it as a kind of sledge hammer that is to be applied sparingly and with the utmost care.



semantic completeness must not be confused with methodological convenience. in the completeness result, we only used refinement mappings, but no refinement functions and no strict forward simulations. yet refinement functions and strict forward simulations are the main tools used in practical verifications.



in, we extended this repertoire with splitting simulations in which the progress property(f2) of forward simulations is replaced by a condition in terms of states and the step relation. this work needs further extension, because(f2) is an invitation for sloppy reasoning but splitting simulations are not often applicable. indeed, whenever possible, it would be good to replace even condition(f2) for refinement functions by a condition in terms of the state and the step relation. work in progress indicates that this can be done when the supplementary properties are given in terms of weak fairness.



in, we proved a refinement criterion for atomicity of read-write variables. the proof of this criterion is based on forward simulations, refinement functions, eternity extensions, and the new concept of gliding simulations. these gliding simulations are conceptually easier than eternity extensions, but technically nasty. the atomicity criterion provides a refinement justification for some older verifications and is also used in the recent verification of algorithm c2 of haldar and vidyasankar.



in the course of several verification projects of concurrent algorithms, we were forced to use theorem provers, first nqthm, later pvs, primarily for the administration of proof obligations. using theorem provers forced us to emphasize the specifications that were to be proved. the adoption of refinement was forced upon us when we needed prophecies of the transactions in the serializable database interface of.



