in the hydroponics subfield, alipio et al. (2017) proposed a bayesian network (bn) algorithm to automate plant growth by controlling the light intensity, the soil acidity, the water temperature and the humidity. they were able to increase the production by around 66.67% compared to manual control; however, from a probabilistic perspective bns gener- ate probability density functions rather than the maximum a posteriori estimated direct parameter values, which adds additional unnecessary output neuron was implemented with a sigmoid activation function that produces activation values comprised between 0 and 1. training was performed for 250 epochs, using the adam optimizer and a categor- ical cross-entropy cost function. data was transferred to the optimizer through batches of 2048 samples. to track the model performance, the cost function and the accuracy were computed at the end of each epoch on the training and validation sets using the following expres- sions respectively:



for both groups, the models' performance improves with the con- struction of more complex mlps. more neurons yield generally better performance and vice versa. this observation is quite logical since hav- ing a more complex architecture enables to fit more complex data pat- terns. on the other hand, trying to fit a very simple model to a complex data distribution yields poor performance, since the trainable parameter number is insufficient. we will denote the model instances within group 1 by model (i) where i is the number of neurons within the hidden layer. for group 2, each instance will be denoted by model (i, j) where i and j are respectively the number of neurons per hidden layers 1 and 2.



the evolution of its mean cost and accuracy along the training/cross- validation process. the mean loss converges to a value of 0.16 while the mean accuracy to 0.97. no generalization gap is observed between the training and cross-validation curves which evolve tightly close to each other. this confirms that the model's learning has been performed within an optimal regime without underfitting nor overfitting the data. a further evaluation of model (7,8) on the test set yielded an accuracy of



this work focused on developing a tinyml-oriented solution for a machine learning-based autonomous greenhouse microclimate control based on multi-variate sensed data (5 variables). the mlp architecture has been selected and various hyperparameters have been experimented while training 90 model instances. a robust five-fold training/cross-validation procedure on a balanced dataset was also car- ried out to find the optimal and best-performing model. from an evalu- ation metric-based perspective, multiple mlps can fulfill the task; however, from a tinyml perspective, only the model with the less pa- rameter number has to be kept for optimized computations and



although the obtained performance metric can be contended as satis- factory. we consider that it may be ameliorated further. herein we suggest: (1) a model centric avenue, which focuses on modifying the parameters and hyperparameters; or a (2) data-centric avenue which focuses on collecting additional and more refined data.



