prevention of deadlocks: when the synchronous system is transformed into a gals architecture, the input transitions that were bound in the original system are unbundled, as previously discussed. this out-of-order reception of signals should not cause the system to enter into a deadlock state. therefore, there should be additional constraints in the transformed model to avoid such occurrences.



i.e. synchronisation using clocks. depending on the semantics of transition step execution, we can formulate different levels of synchronicity, from global, i.e. fully synchronous, down to fully asynchronous. however, we also need some criteria which would impose a particular form of execution policy on the petri net model of the system. for example, from the point of view of performance we may want to change the policy of(global) maximum step firing parallelism, because such a semantics assumes that the clock signal is only activated after all the events in the previous step have been executed. this leads to the operation with a worst case



the previous section presented the idea about max-o semantics used to describe distributed architectures. the standard interleaving semantics for pn does not associate any notion of maximal firing by which a set of transitions are always fired concurrently. therefore, maximal output semantics is introduced which binds sets of output transitions in order to fire them concurrently.



the standard semantics have interleaved output steps and the max-o semantics have maximal output steps. hence, the interleaving semantics will have more permissive steps as compared to max-o semantics. therefore, intuitively we can say that the processes of standard semantics are richer than the processes of max-o semantics.



in order to model a distributed architecture from a synchronous system model, we apply the theory of petri net with localities which was originally introduced in. in the previous work, the co-located transitions executed maximally. we extend this by making a distinction between input and output transitions and allowing the input transitions to execute as and when they arrive and restricting the output transitions to execute maximally and in persistent steps only. this extension is in direct relation to the synchronous behaviour, discussed in the previous sections. analogies can be drawn between our proposed notion and the notion of burst-mode circuits, presented in[11,12], from the point of view of allowing multiple signal changes on each transition and taking into account i/o causality. on the other hand, the former can be viewed as a generalisation of burst-mode circuits. this is because it uses pn as a model of computation which allows the bursts/bundles to be introduced in a flexible way, based on subsets of events bundled in bursts and independent bursts, preserving a level of true concurrency between them.



this paper addressed the problem of synthesising a gals system by a desynchronisation methodology which employed pn as its model of abstraction. the granularity of desynchronised systems, thus constructed using pns, is smaller than the ones obtained from the previous method and thus is easier to automate and apply even for large complex circuits. the gals system can be obtained by applying the theory of localities to a synchronous system model preserving the synchronous properties of the input output signals.



the proposed methodology needs to be automated to reduce design time and designer intervention. the locality allocation can be further optimised to meet various criteria, e.g. to minimise interconnection between localities and to increase the component speed. it could also be possible to apply other ways of unbundling transitions(e.g. not necessarily consider all inputs to be desynchronised) and thus obtain different conditions for persistent steps.



