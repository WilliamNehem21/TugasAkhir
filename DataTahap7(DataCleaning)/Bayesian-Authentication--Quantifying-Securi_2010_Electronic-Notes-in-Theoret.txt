the most natural model for analyzing the hancke-kuhn protocol that we came up with extends the symbolic model by a rudimentary probabilistic theory of guessing. it retains the perfect cryptography assumption for the standard cryptographic primitives used in the protocol, in particular for the keyed hash function. in a probabilistic context, though, the perfect cryptography assumption means that the output distributions of the relevant cryptographic primitives are statistically indistinguishable from the uniform distribution. assuming this for the hash function used in the protocol brings us close to the random oracle assumption, often used in computational analyses. there is a sense in which the random oracle assumption can be construed as the probabilistic version of the perfect cryptography assumption.



related work. as already mentioned, the closest relative of the pdl formalism, underlying this work, and briefly summarized in sec. 3, is pcl[15,11,10]. both formalisms owe a lot to strand spaces, in spirit, and in execution models, although the logical methods diverge. our probabilistic extension of pdl is predated by the probabilistic extension of pcl in, and by the probabilistic extension of strand spaces in. but each of the three probabilistic approaches has a different intent, and a completely different implementation, conceptually and technically. it would be interesting to explore these differences more closely, as some tasks may yield to combined modeling methods.



bounding[13,5]. the early security analyses of distance bounding protocols go back to the early 1990s. the interest in this type of authentication re-emerged recently, with the task of device pairing and a genuine need for proximity authentication in pervasive networks. from the outset, the basic idea of distance bounding was to combine some cryptographic authentication tools, such as hashes or signatures, with a physical constraint, such as the limited speed of message exchange. most distance bounding protocols[6,7,23] implement this combination by using two channel types: the standard network channels for the cryptographic authentication, and the timed channels for the rapid response. the hancke-kuhn protocol stands out by it simplicity, and by the fact that both cryptographic data and the rapid response are sent on the timed channel. this, however, comes for the price of information leakage, which makes the security analysis interesting.



surviving the flood of negligible factors. every subterm of every term in every security protocol can in principle be guessed. such probabilities are usually tolerably small: they are negligible functions of some security parameter l. in probabilistic analyses, it is often convenient to ignore such events of negligible probability. in a protocol analysis, tracking all terms and subterms that can be guessed with a negligible probability can lead to a lengthy list, without revealing anything nonnegligible. in this section, we provide an underpinning for formal probabilistic reasoning up to negligible factors.



we have presented a framework for extending algebraic cryptographic models to probabilistic models and used it to construct a probabilistic extension of the protocol derivation logic. we have illustrated it by applying it to an analysis of the hancke-kuhn distance bounding protocol. we expect that it will be useful in the analysis of many other protocols that rely on weak cryptography to take advantage of non-standard communication channels.



catherine meadows, radha poovendran, dusko pavlovic, liwu chang, and paul syverson. distance bounding protocols: authentication logic analysis and collusion attacks. in r. poovendran, c. wang, and s. roy, editors, secure localization and time synchronization in wireless ad hoc and sensor networks. springer verlag, 2006.



