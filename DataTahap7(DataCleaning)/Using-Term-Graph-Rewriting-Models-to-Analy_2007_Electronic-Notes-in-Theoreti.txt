graph pattern, both are rooted. patterns are incomplete graphs in which terms or sub-terms may be holes such as f in(push); holes are always uppercase. in right patterns, variable-for-variable substitutions may be attached to a hole, see(let) and(reduce) for example.



(update) nodes c, b and a with the value of d. then the copy at a is specialised by(reduce). as b has been updated on its first use the second use is much faster, one(lookup) and(update) copy the value of b into a.



1. then there is one(vupdate), two(iupdate) steps and an(ireduce) which make b and c indirections to d(c is collectible by gc). finally, a(lookup), an(iupdate), an(ireduce) and a garbage collection produce the result. value indirections seem



typically space leak refers to the situation where objects persist in memory after they are known to be unwanted. failing to recycle a heap object, or losing all pointers to it, is an example caused by poor programming. however, if the language specification demands a garbage collector the compiler is at fault. in both cases the presence of a leak means that some part of the implementation has done worse than the specification demands. we cannot deduce the presence of a leak from the program specification alone or the program alone or the compiler alone or the language specification alone.



a compiler, especially those which act on non-program structures like indirections. we advocate the inclusion of a space semantics as part of a language specification. this provides an arbitrary standard model against which implementations can be compared to decide whether they leak. of course, the space semantics may need to be changed so our comparison method should not assume a fixed standard.



accurate evaluators overcome this problem. we call an evaluator accurate if its space usage multiplied by initial graph size bounds its size usage. if its space usage bounds its size usage it is uniformly accurate. accuracy means that evaluators can use more size on bigger graphs without being called leaky. in some sense this contradicts our claim to have a meaningful model of space and leaks. clearly uniformly accurate evaluators, or measuring size usage, lead to a valid notion of relative leak; clearly general evaluators and measuring space usage do not; but is accuracy enough to



we justify this position by separating the initial graph from the input. space complexity is a function of the input size, not the initial graph size, otherwise a sub-linear complexity is impossible. therefore if the value of n in our discussion is determined by the input the evaluators could not be accurate. if the value of n is part of the program then the evaluators can be accurate and preserve or hide a size discrepancy through the constant factor allowed by the initial graph size.



it should terminate(confluence may also be important). its main property, however, is that it should decrease the graph size. abstractly we can say that garbage collectors are terminating rewrite systems which do not increase graph cardinality by more than some collector-dependent constant factor! this is precisely the guarantee of a space relation. the significance is that to investigate space-safe translation is to investigate garbage collection. the thesis exploits this idea to define non-standard collectors and uses them in some leakiness proofs.



proach come from the development of accurate evaluators which are guaranteed to be meaningful abstract models of space usage. this means that if an accurate evaluator is leakier than another in our model, its implementation is guaranteed to have a space fault. the difficulty of graphs is that they are further removed from implementations than conventional abstract machines so it can be difficult to model the space behaviour of some aspects of real implementations, or to argue that the model retains the essential behaviour of the implementation. an example in is the modelling of environment-based machines which do not implement proper trimming. despite this distance, having some framework which guarantees any evaluator the properties of interest seems a useful approach. graphs are primitive in that they do not distinguishing the characteristics or purpose of different structures. graph rewriting is a good evaluator framework because its generality encourages the development of widely-applicable proof techniques.



graph garbage collectors and translators are term-graph rewrite systems too. it is appropriate to distinguish them from our rooted evaluators because we can define their space behaviour more abstractly. garbage collectors and translators have important common properties. again, the approach is to decide on the properties of interest and to use restrictions on a general rewriting framework to guarantee them.



