in section 2 we recapitulate the conventional parser combinators and investigate where the problems mentioned above arise. in section 3 we present different basic machinery which adds error correction; the combinators resulting from this are still very short and may be used for small grammars. in section 4 we show how to extend the combinators with the(demand driven) computation of look-ahead information. in this process we minimize the number of times that a symbol is inspected. finally we present some further extensions in section 5 and conclusions in section 7.



if we extend the combinators from the previous section to keep track of the farthest point in the input that was reached, the parser returns that value only after backtracking has been completed. unfortunately, we have by then lost all context information which might enable us to decide on the proper error correcting steps. so we will start by converting our combinators into a form that allows us to work on all possible alternatives concurrently, thus changing from a depth-first to a breadth-first exploration of the search space. this breadth-first approach might be seen as a way of making many parsers work in parallel, each exploring one of the possible routes to be taken.



this is a special type that is not allowed by the haskell98 standard, since it contains type variables b and result that are not arguments of the type parser. by quantifying with the forall construct we indicate that the the type of the parser does not depend on these type variables, and it is only through passing functions that we link the type to its environment. this extension is now accepted by most haskell compilers. so the parser that recognises a value of type a combines this value with the stack of previously found values which will result in a new stack of type b, which in its turn is passed to the continuation as the new stack.



corresponding tails. an end node represents the end of a sentence. the:|: nodes corresponds to nodes that are both a choice node(stored in the left operand) and an end node(stored in its right operand) 3. notice that the language ab|ac is represented by:



in our final solution we will merge these two approaches. we will compute sents fragments on which we base the decision how to proceed with parsing, and use the continuation based parsers to actually accept the symbols. since the information represented in the new data structure closely resembles the information stored in a state of an lr(0) automaton, we will use that terminology. so instead of building the complete sents structure, we will construct a similar structure which may be used to select the parser to continue with.



(:|:) this corresponds to the situation where we either may continue with using further symbols to make a decision, or we will have to use information about the followers of this nonterminal. this will be the only place where we continue with a possibly non-deterministic parsing process. it corresponds to a shift-reduce conflict in an lr(0) automaton.



the function mkparser interprets a look structure and pairs it with its corresponding realparser. the function mkparser constructs a function choose that is used in the resulting realparser to select(choose input) a realparser p) making use of the current input. once selected this parser p is then called(p r st e input). so the function choose, that is the result of the homomorphism over the look structure, has type input-> realparser a.



this definition seems to be horrendously costly, but again we are saved by lazy evaluation. keep in mind that these look structures are only being used in the function mkparser, and are only inspected for the branches until a found or reduce node is reached. if the grammar is ll(1) this will only be one step! as soon as mkparser has done its job the whole structure may be garbage collected.



in this case the check that it is present and the error correcting behavior can be skipped. so all we have to do is to take a single symbol from the input, incorporate it into the result, and continue parsing. we record the successful step by adding an ok-step.



computation of a full look-ahead may be costly, e.g. when the choice structures that are computed become very large, and are not used very often. in such cases one may want to use a non-deterministic approach. for this purpose dynamic versions are also available that have the efficiency of the backtracking approach given before.



can be extended to incorporate the accumulation of any further needed information; examples of such kinds of information are the name of the file being parsed, a line number, an environment in which to locate specific identifiers, etc. in that case the state should at least be able to store error messages, and recognized symbols. extra combinators have been introduced in the library to update the state.



the number of times a symbol is inspected may be more than once: where a bottom-up parser would have a shift-reduce conflict we basically pursue both paths until a difference is found; if the grammar is lr(1) this implies we are inspecting one symbol twice in such a situation. we feel that in all practical circumstances this is to be preferred over the construction of full lr(1) parsers, where the number of states easily explodes. it is the relatively low number of states of the lr(0) automaton, and thus of our approach, that makes the lalr(1) handled by yacc to be preferred over lr(1). besides that has our approach the advantage of smoothly handling also longer look-aheads when needed. the lazy evaluation takes nicely care of the parallel pursuit for success that would be a nightmare to encode in c or java.



