worst-case execution time (wcet) is a parameter necessary to guarantee timing constraints on real-time systems. the higher the worst-case execution time of tasks, the higher will be the resource demand for the associated system. the goal of this paper is to propose a different way to perform loop unrolling on data-dependent loops using code predication targeting wcet reduction, because existing techniques only consider loops with fixed execution counts. we also combine our technique with existing unrolling approaches. results showed that this combination can produce aggressive wcet reductions when com- pared with the original code.



loop unrolling can contribute to improve the instruction level parallelism (ilp) and execution performance of programs, by enabling more optimization that are affected by code expansion. although, this code expansion can lead to instruction-cache perfor- mance degradation, if not carefully applied. if loop unrolling is applied before the register allocation phase, register pressure can be increased, leading to the insertion of more spill and reload oper- ations in the code. however, a standard compiler cannot use loop unrolling directly if worst-case execution time (wcet) reduction is desirable, due to the instability of the execution path that gener- ates the worst possible execution time and negative cache effects. some techniques were proposed in the literature to achieve wcet reduction using loop unrolling, as in [4,6]. in these works, loops are



the contribution of this paper is twofold. firstly, we propose an alternative way to perform loop unrolling on loops with arbitrary (or variable) execution counts. traditionally, loops with unknown execution counts are unrolled with fixed unrolling factors, with the corner conditions (i.e, the unrolling factor is not a multiple of the number of iterations) treated with branch instructions. the approach adopted in this work is to treat the same corner condi- tions using code predication instead of instructions that perform control flow changes. code predication is already used in software pipelining of loops, but its application directly with loop unrolling was not reported in the literature. code predication also can be explored using a transformation called if-conversion, which is a standard compiler optimization that converts control dependen- cies into data dependencies, removing branches.



the second contribution of this paper is the combination of our technique with other standard unrolling approaches for data dependent loops and loops with fixed execution counts. in this way, we can decide on a per loop level which of the approaches should be used for loop unrolling. this combination of techniques is important because not every loop can be unrolled in the same way. for example, loops with variable number of iterations must include compare and branch instructions to treat different exit conditions, but loops with static execution counts can be unrolled without these instructions. the necessity of compare and branch instructions is not the only difference when unrolling these two types of loops, but the selection of a valid unrolling factor is also different. in loops with a static number of iterations, we can only consider unrolling factors that perfectly divide such number of iterations. until the present moment, no work addressing the com- bination of different unrolling techniques was identified in the literature.



the remainder of this paper is organized as follows: section 2 outlines the related work on loop unrolling directed to wcet reduction. section 3 shows the motivations of this work. section 4 explains the proposed approach to perform loop unrolling target- ing real-time applications. in section 5 we describe briefly our testbed. section 6 presents the obtained results using a benchmark suite. in section 7 presents our conclusions and final remarks.



the first work that concerns wcet reduction using loop unrol- ling, consists in applying this optimization directly at assembly level [4]. in this work, only innermost loops with fixed number of iterations are unrolled and the unrolling factor used for all loops is 2. although, not all candidate loops are unrolled, but only those that are present in the worst-case execution path (wcep), and they are kept unrolled only if wcet reduction is achieved. at every opti- mization application, the wcet information must be re-calculated to update the worst-case path information that drives the algo- rithm. this recalculation is necessary because any code change that affects the wcet may result in a wcep change. these wcet recal- culations are a common strategy employed by compilers focused in worst-case execution time reduction. experiments using a proces- sor with no caches showed that a wcet reduction up to 10% was achieved for all benchmarks.



both the previously presented approaches consider only loops with fixed number of iterations. in fact, both techniques can be used to unroll loops with arbitrary counts or data-dependent loops, providing necessary code to exit the loop when the termination condition is reached. this code is commonly generated as branch instructions.



if-conversion [7] is a technique used to convert control depen- dencies into data dependencies. the basic principle consists in eliminating gotos and branches and inserting logical variables to control the execution of instructions in the program. if- conversion can be performed at ir-level or machine-level as stated by [8] and is related to region enlargement techniques used to expand the instruction scheduling scope beyond a single basic block, which is specially beneficial for very long instruction word machines (vliw).



the application of if-conversion techniques in loops is not a novel idea. software pipeline [9] can benefit from if-conversion and code predication to control the execution of prologue and epilogue of pipelined loops [10]. another technique that can benefit from if- conversion is loop flattening [11]. loop flattening is a form of soft- ware pipelining that merges nested loops into a single loop body, providing necessary code to control the execution and the flow of data between blocks. in [12] if-conversion is used to eliminate back-edges of flattened loops. the next section outlines the motiva- tion and the key ideas behind the proposed unrolling technique.



there are some approaches to perform the loop unrolling opti- mization considering this loop. the simpler strategy consists in optimizing only loops with fixed counts. in this case, the compiler chooses an unrolling factor that exactly divides the number of iter- ations of the loop. if a compiler is able to optimize data-dependent



in the next section, we present our approach to perform loop unrolling which applies simultaneously code predication directly in machine code. the technique starts from a simple data- dependent loop and directly generates an unrolled and predicated version, as done step-by-step in this section. the main improve- ment of our approach is that it avoids the use of branch instruc- tions, differently from what is usually done by traditional techniques.



the algorithm works as follows: first, header and body are identified, which is done by lines 2 and 3. the second step removes the unconditional branch from the loop body to the header. this branch instruction will be re-inserted at the end of the algorithm, as a last instruction (line 14). the next step is to unroll the loop using the provided unrolling factor, using the original loop body as first copy.



(p) means that the operation execution is conditioned to the con- tent of the flag register p, which is a common notation of predi- cated code. for comparison purposes, the same code is unrolled in the standard way as shown in code listing of listing 6. compar- ing the two approaches, we can see that the predicated version presented fewer instructions than the standard counterpart (with branches).



for data-dependent loops with some kind of control flow change inside of the loop body, we can use loop unrolling with compare and branch instructions to exit the loop when the condition is reached. for simplicity, we apply this unrolling alternative to loops with call instructions in the body. this approach is also a common strategy considering compiler optimization, and we will omit its representation in pseudo-code. if we must use this approach, we



for data-dependent loops with simple loop bodies, we can use the predicated version. we cannot use this type of unrolling in loops with call instructions because condition or flag registers are not commonly exposed to the calling conventions used in processors. if we had to save the flag registers, it would be better to use the previous approach. we will call this approach as predi- catedloopunrolling, as presented by algorithm 1.



the previous algorithm is responsible for unrolling the loops of a program using a set of unrolling factors. it is also necessary to choose a unrolling factor for each loop that minimizes the wcet. as we are interested only in verifying the effectiveness of our tech- nique, we are not concerned in choosing an optimal unrolling fac- tor considering code increase and wcet reduction.



we adopted a scheme that tries to iteratively choose an unrol- ling factor for each loop in the program. if the loop has no impact on the worst-case execution time, i.e. resides outside the wcep (worst-case execution path), it will be kept rolled, otherwise it will be unrolled. the set of unrolling factors will vary according to char- acteristics of the loop, such as data dependency and parity of exe- cution counts.



if the unrolled loop increases the wcet, then it will be also kept rolled. otherwise it will be maintained unrolled using the factor that best minimizes the wcet considering the previously consid- ered ones from the set. each loop is processed exactly once, and after each loop handling the wcet (and wcep) information must be updated to guide the treatment of the next loops. to verify if a wcet increase occurs, it is necessary to perform a program recompilation and an invocation to the wcet analyzer. we do not reconsider loops in case of path changes, since typically all loops in a program are on the wcep, as stated by [6]. we only check if the current loop is on the wcep.



must allow the correlation between the loops and the worst- case execution time related data. execution counts must be exported as well. in case of data-dependent loops, execution counts can be provided as annotations in the source code, for example. these execution counts are also necessary for the cal- culation of the worst-case execution time.



as we can see, the previous relation between compiler and algo- rithm forms a cyclic and incremental approach to optimize loops. the parameter of algorithm 3 is the representation of a compiled program. the first step of the algorithm is to retrieve a list of (exported) loops of the program representation (line 2) followed by a wcet analysis (line 3). the main loop of the algorithm iter- ates over the loop list (line 4), considering only loops that are in the wcep (line 5). then, we assume that it will be kept rolled (line 6) if its is not possible to choose an unrolling factor. the next step sor characteristics, these values can be tuned experimentally. if such unrolling factor exists, we recompile the program and test for wcet changes. in case of wcet increase (line 21), we use the last chosen unrolling factor (line 22) and skip to the next loop. otherwise we use the actual factor updating the wcet (line 24 and 25).



we used a custom compiler back-end developed for the target architecture using the llvm [18] infrastructure. the compiler also produces all necessary information for wcet calculation, as an annotated cfg containing information like loop bounds and map- pings between cfg nodes (basic blocks) and a target program code. for data-dependent loops, worst-case execution counts (or bounds) must be provided through source code annotations.



the unrolling technique was implemented in our back-end at the end of machine code generation. it is difficult to perform wcet-oriented optimization using llvm due to its highly opti- mized pass-manager that isolates the treatment of each function of a compilation unit. due to this fact, we cannot optimize the pro- gram as a whole aiming at wcet reduction using the standard llvm pass-manager because the generated code is only fully mate- rialized at the end of the complete process. moreover, the pass- manager deallocates any machine related code representation structures of a function after writing its generated object code to file at the end of the pass-manager execution. so, when we can finally calculate the wcet of a program, we cannot use this data to change the code (optimization application), because the needed intermediate structures no longer exist. due to this fact, strategies like that proposed by [5], where the analyzer is invoked directly by the compiler to take optimization decisions cannot be used.



responsible to select the parts of the program that must be opti- mized, using wcet information as guidance. this tool shares a database with the compiler that is used as communication chan- nel. this database stores facts about the structure of the program and values that specify if such structure must be touched by a specific optimization. the tool invokes the compiler to generate the object code and data used as input for the wcet analyzer. after that, wcet information is obtained through the wcet analyzer. using this information, the planning tool updates the database using heuristics like the one proposed in section 4.3, which chooses the loops and unrolling factors and invokes the compiler again. this task repeats until wcet stabilization or when the entire code is already analyzed by the planning tool.



we proposed in this paper an alternative way to perform loop unrolling with arbitrary iteration counts. traditionally, this type of loop is unrolled using compare and branch operations to control different exit conditions or contexts. what we propose is the use of code predication to control the loop execution under different exit conditions, since worst-case analyzers tend to consider that each loop, even unrolled, is always fully executed up to its execution bound. the approach can be used in architectures with full predi- cation support and is better applicable when branch operations are segmented in more than one step.



we introduced an algorithm that performs this code transfor- mation directly at the machine code level (or assembly). in our framework, each data dependent loop of each benchmark is anno- tated with a safe loop bound that represents an upper bound on the execution count. after loop unrolling application, the annota- tion is transformed to reflect the new loop bound of the unrolled loop. since our technique does not depend on branches, the num- ber of instructions is reduced and the instruction scheduling scope



we also proposed a strategy that selects which unrolling tech- nique to apply in a per loop basis. for loops with fixed execution counts, we applied the standard technique that unrolls loops using unrolling factors that perfectly divide execution counts to avoid compare and branch instructions. for data dependent loops, we used our predicated or the branch-based approach, depending on the case.



we observed in the experiments that the combination of unrol- ling techniques was able to reduce the wcet of 18 from 33 bench- marks. for six benchmarks we obtained gains above 20%. in the experiments, we also showed that the predicated approach, even with its limited applicability, can exploit cases where the standard approach fails to get wcet reduction.



