cranfield urban observatory that builds on elements of the rttc and is designed to allow users to develop user interfaces to monitor, characterise and compare a variety of environmental and infrastructure systems plus behaviours(e.g., water distribution, power grids). the third is the data and analytics facility for national infrastructure, a cloud-based high-performance computing cluster, developed to receive, store and present such data to advanced analytical and visualisation tools.



a broad range of low-cost environmental and latent physical parameter sensing technologies are now widely available. the breadth, variation and relatively low cost of many of these sensors is in part due to the rapid uptake of accessible electronics/computing environments and related developments within internet of things(iot) infrastructures. observable parameters can include physical, spectroscopic, chemical, biological, biometric, acoustic and vibration, electrical, thermodynamic and thermophysical properties(with measurements taken either directly or indirectly). these can be used to provide insights into the wider environment or specific information about infrastructure or networks. key to this has been the advent of widespread low-cost wireless communications hardware and software, primarily associated with global telecommunications. early examples are the general packet radio service(gprs) and global navigation satellite system, e.g., global positioning systems. the gprs is linked to 2nd and 3rd generation mobile telephony networks(2g and 3g). this has been surpassed by post 3g and 4g standards and approaches, e.g., wideband code division multiple access and long-term evolution, and the emergent 5g infrastructure. these developments have allowed large amounts of geo-temporally referenced data to be telemetered globally on previously unachievable scales and with relative ease. coupled with advances in encryption and fidelity retention, together with allied cloud capabilities for receiving and processing the data arising, this has further opened new opportunities for broad scale information transfer.



in this paper, we discuss a framework of generalised network architectures for environmental sensing to analyse the digital enabled environmental approach in the field of analytics control. we seek to explore end-to-end aspects of network design, some of the wider landscape of network operation, and the data pipeline. the paper discusses selected case studies specifically from an application perspective, as well as drawing on wider aspects of dispersed heterogeneous environmental sensing networks. the concepts described in this paper will be discussed



data ownership. data ownership can be a complex issue especially where the network has multiple users and sponsors(e.g., a sciencedriven network installation supported through government operational permissions), and data fusion is used in the pre-processing of data streams. definition of ownership and intellectual property(ip), at the network design stage is also vital, as are planning exercises for downstream analytics and/or product combination.



with statutory responsibilities or powers also need be considered given that some measurements once processed and validated have legal and compliance implications(e.g., mixing ratios of a regulated pollutant gas species). the transfer of data in this way also has data ownership implications. similarly, for international data transfer, additional national governmental jurisdictions and considerations need to be accounted for, as some data may be considered a national asset, security issue or saleable item. hence, it needs specific permissions for onward sharing or dissemination.



data legacy. plans for data legacy need to be incorporated into network design. this includes ip control(related to the data ownership) of both the pre-processed data and the various levels of processed data. in many applications best practice would retain both the original data and the mechanism for its processing and transforming. in other applications synthesised products with contextual data are the appropriate products to be stored. this data needs to be both a faithful record from the network and the analytics approaches used as well as contains the needed(as defined by user groups) useful data. associated with data legacy is the importance of maintaining appropriate levels of metadata being generated so as to enable discovery and findability of data assets. various international isos and related standards may be adopted, e.g., iso19115, dublin core, data catalog vocabularydcat, alongside national



available for remote access, analysis and presentation. this scope has expanded beyond immediate operational and functional analytics to include wider environmental data associated with a range of water, sanitation and hygiene initiatives. this broadening of scope is to allow more integrated installation and improved operational control for each specific installation environment.



local node, or in dispersed mesh networks from remote in-network nodes. feedback from sub elements of the network can be used to change overall network behaviour or to change behaviour for selected parts of the network. for example, information from a network component remote from the system under control(e.g., a change in weather in one part of the network changing the rttc drainage control across the network or just in the path of the weather change). remote automated feedback can be also be input to the access node and therefore onwards to the network, by user control direct to the sensors, by actuators(e.g., locally connected laptop), or via telemetered input from remote users or off-line analysis systems.



variable within the rttc. data needs to be stored locally(even if briefly) in some form before being made available via the access node as a rolling backup to prevent catastrophic information loss. the data storage format needs to be robust as at this initial stage there is no backup to the data being collected(data security is discussed in 2.3.1). the data generated by the components of the analytics system is often initially in a machine-readable form which is unconverted into a human



readable form or format. this is usually a function of the sensor operation itself(e.g., machine counts representing a capacitance value within a set range which is proportional to a humidity value). this data is then transmitted to the local node where it can be managed. management operations can involve longer term storage, transformation(e. g., to human readable data or conversion using pre-set conversion tables), compilation(with input from other sensors/actuators of both similar and dissimilar types) and compression(for efficient long-term storage, preparation for access or telemetering to preserve bandwidth). this managed data can then be made available for local access or telemetry.



be based on the cloud-based nosql architecture, which is powerful, widely used and robust, holding documents at an entity level. direct user control can also be used to access the stored cloud data. at this level the data can also be further managed with a combination of transformation, compilation and compression tasks.



the cranfield university urban observatory, which is currently under development, is designed to allow users to monitor, characterise and compare a wide variety of environmental and infrastructure systems and behaviours. these currently include(but are not limited to): water distribution, power grids, biodiversity, pollution, environmental data, street networks, population density, biodiversity and pedestrian behaviour. the experience gained through the rttc project is now being used to underpin the development of the cranfield university urban observatory, which forms part of a wider network of six urban observatories in the uk funded through the ukcric. the cranfield university urban observatory is unique, being located on a self-contained site in a semi-rural location, representing a microcosm of a complex city system. the site not only includes traditional campus infrastructure(e.g., halls of residence, teaching and research facilities) described in the rtcc design approach, using environmental sensors to capture facets of a complex system in real, or near-real time. this permits extenuated management decisions to be adopted and trialled as scenarios, as well as recreation of circumstances leading up to particular events. a fundamental aspect of the observatory is that the data arising from these assets will be brought together, using a common data platform, within the envelope of the cranfield university urban observatory, and accompanied by a diverse range of analytical and dissemination tools and functionality. the observatory project team identified these fundamental aspects as being critical to enabling research and generating knowledge. in addition, the observatory has been designed to enable data sharing, for example with the wider ukcric urban observatories, and data users, via common data structures and apis.



increasingly the mechanism by which research questions are framed, facilitating interaction between stakeholders, students, academics and professional service units(e.g., campus facilities), allowing any of these groups to generate research questions[28,29]. the cranfield university urban observatory forms an integral part of the wider cranfield living laboratory initiative. this is developing the use of the cranfield university campus as a testbed for transformative technologies and approaches for the delivery of enhanced social, economic and environmental outcomes in response to major challenges such as future urban design, hybrid transport systems, provision of sanitation, wellbeing and a range of issues associated with integrated infrastructure development. here the data provided by the urban observatory is facilitating academic research, teaching, and operational decision-making in relation to such issues.



infrastructure modelling challenges, for example optimal and demand-driven siting of plant and infrastructure facilities. the iro approach will facilitate operators being able to determine which data themes are appropriate for inclusion in a modelling approach. however, another challenge is the sheer volume and diversity of the data held and therefore, connected with this, will be the need to enable efficient data discovery through associated metadata records, drawing on standards such as dcat. through the combination of these approaches, dafni aims to improve the efficiency, reliability and sustainability of infrastructure through better sharing and use of data, the exploitation of simulation and optimization techniques, and engagement with stakeholders through visualisation.



