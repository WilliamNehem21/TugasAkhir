levees are constructed to provide safety along natural water bodies, to stop the flooding of low-lying areas. the presence of sand boils along the outside of the levee signifies a possible impending structural failure of the construction. this can result in a lot of damage to both property and life. the analysis and monitoring of sand boils are currently done manually[2,3].



we aim to automate this process by picking the best models out of several developing machine learning models, that can most accurately detect sand boils near the levees so that personnel can be more targeted in their monitoring. the dataset for this study has been collected manually from various sources since there is no centralized dataset available for these relevant images. it has been made sure that it contains satellite images of rough terrain that can pose as a challenge for a machine learning algorithm to identify sand boils from. this resulted in the creation of a robust predictor capable of identifying potential sand boils with high accuracy, which was ensured by comparing it with other potential machine learning approaches.



especially in the new orleans area. however, levees and flood-walls degrade over time due to the impact of severe weather, development of sand boils, subsidence of land, seepage, development of cracks, etc. further, published data indicates that coastal louisiana lost approximately 16 square miles of land between 1985 and 2010. in 2005, there were over 50 failures of the levees and floodwalls protecting new orleans, louisiana, and its surrounding suburbs following the passage of hurricane katrina and landfall in mississippi. these failures caused flooding in 80% of the city of new orleans and all of st. bernard parish. events like hurricane katrina in 2005 have shown that levee failures can be catastrophic, and very costly. if these levees fail due to these conditions, there is a potential for significant property damage, and loss of life, as experienced in new orleans in the 2005 hurricane, katrina. it is of great importance to monitor the physical conditions of levees for flood control[3,17]. the great mississippi flood of 1927 and 1993 are some other examples of the development of sand boils. the mississippi



and the height and diameter if a cone of sand is formed around it must be measured to determine the severity of the sand boil. levees need to be appropriately maintained and actively monitored for failure. due to the tremendous length and variations of levee structures, proper operation and maintenance of levees can be challenging, especially when it is currently done manually[2,3] using physical surveys which are a drain on time and resources. this thesis aims to speed up this process and assist in the monitoring process of levees and coastal changes by detecting sand boil from images, expected to be collected by drones for monitoring the levees.



computer vision is the study of algorithms that manipulate imagebased data. these algorithms extract features from images and pass them to machine learning models, which then identify particular regions of interest(roi) in the image. object detection, however, is a combination of computer vision and machine learning. it recognizes an instance of the target object and draws bounding boxes around it.



the major difference between image detection and recognition is that the former is generally concerned with detecting where the image a particular object resides by drawing bounding boxes around them. image detection can be treated as a simple classification problem where the image can be classified based on the presence of the object within it. image detection is an essential preprocessing step for object recognition. object recognition is used to compare the similarity between two images. for example, face recognition algorithms that group pictures of people together.



the real world. application of machine learning on object detection can be challenging depending on the characteristics of the object. detection of sand boils within the muddy settings could be very hard to perform from a given image. object detection has previously been applied to some similar issues.



in this research, the dataset was collected from different sources. there is no centralized, easy to access data for levees and sand boils available. hence, most of the collection was done manually. an additional explanation of the subsets of data used for each method is described below.



the usage of a subset of images was necessary for the other methods because, to input the images, the exact areas within the samples containing the positive region must be hand annotated. it is a manual process that is intensely time-consuming. hence, we labeled only 956 images as positive samples. to do this, a tool called bboxlabel was used. bboxlabel is an opensource tool that opens a simple gui where it allows the user to load a directory of images and annotate them. these annotations are stored in two formats. both a simple text file and an xml file format which both yolo and ssd use. on the other hand, annotations for the viola-jones method are internally calculated by opencv using a simple command. these files generated by opencv cannot be used by yolo and ssd because they have one major distinction. the x, y annotation from bboxlabel tool is the center coordinate of the image, whereas the one calculated by opencv is the coordinate of the top-left pixel.



in this section, we describe the features from both positive and negative samples that have been extracted and fed into the machine learning methods. for the viola-jones algorithm, the features used are called haar features. these are calculated internally by opencv. they can be visualized to see which regions of the image contribute to the classification of it being a positive sample. further discussion and examples can be found in the results section. for the yolo algorithm and the ssd method, since the architecture can be considered a part of the convolutional neural network, the features are extracted internally by the convolutional net itself. for the non-deep learning methods, we need to extract some features manually as described below.



the cascade is trained using 25 stages, 4500 positive samples, and 3000 negative samples. this results in an xml file that can be used to make predictions on a test dataset. the test dataset contains a total of 8300 images out of which 2000 are negative samples, and the rest are positive samples of sand boils. the cascade training is stopped at stage 25, and the intermediate stages, 10, 15, 20 and 25 are tested for performance. the best performance is achieved by cascade stage 15. this is evidenced in the results section.



the single-shot multibox detector[7,43] is an improvement on the yolo object detector in the sense that it does not have to traverse through the image twice as yolo does. it can map out the object in a single shot. it is a very fast approach and extremely accurate. ssd is also a deep learning method for object detection.



a pytorch implementation with some alterations to the number of classes, etc. of ssd was used to make the detections. after training the net for 200 epochs, we use the latest generated checkpoint to make the predictions. then we produce the bounding boxes for each of the images in the test data set.



the genetic algorithm is an evolution-based algorithm that iteratively generates new populations and selects the best possible set of genes to do so. over successive generations, the population moves toward the most optimized solution. this algorithm can be applied to a variety of optimization problems. we chose to use it to select the best possible set of features among the 700 that were derived. we arrived at a total of 324 features. after running the above-described methods on both sets of features, it was determined that the complete set of 700 features performed better in comparison to the feature set selected by the genetic algorithm. the possible reasons for failure might be that the genetic algorithm-based feature selection uses xgboost to compute the fitness of the population. the features selected using xgboost might not always be the optimal settings for other state-of-the-art algorithms. another reason is that the set of hog features described above work on the basis of corresponding pixels. trying to isolate the features might prove not to be useful.



