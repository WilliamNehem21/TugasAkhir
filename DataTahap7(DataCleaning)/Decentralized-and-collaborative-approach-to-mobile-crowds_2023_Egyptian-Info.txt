where so many parties are involved such as in mobile crowd sensing systems, problems due to conflict of interest are bound to arise. things get more problematic due to the centralized nature of the system where some parties may feel the service provider is biased towards someone. therefore, such a system where one does not feel cheated and has a say in the working is much needed.



mendations. here again only the concern of privacy is discussed while achieving a particular task involving private data of users but there is no reward or incentive to be paid out to workers in such a system. the problem in this paper states is that nowadays there are lots of tasks being solved through human intelligence by the use of crowdsourcing systems but the majority of them are centralized and also suffer from a single point of failure. in this paper a decentralized approach to a crowdsourcing system has been provided as well as performance and security issues like ddos attacks discussed and ways to prevent them given. a novel approach for block generation which is essential to develop for a decentralized platform working as a means of data collection and its processing. this solves the issue of fork and centralization. a trust system is also given which can help identify malicious entities and prevent them from harming the mcs system as a whole. architectural diagrams along with mathematical and graphical representations for complete understanding and implementation are given.



kafka, developed by the apache foundation is an open source, distributed streaming platform that allows for the development of real-time event-driven applications. it allows the development of applications that continuously produce and consume streams of data records. kafka is a distributed platform which runs as a cluster that can span multiple servers or data centers. other servers run kafka connect to continuously import and export data as event streams to integrate kafka with your existing systems such as relational databases as well as other kafka clusters. to let you implement mission-critical use cases, a kafka cluster is highly scalable and fault-tolerant: if any of its servers fails, the other servers will take over their work to ensure continuous operations without any data loss.[7,10].



each and every node in the system behaves like a producer and a consumer. a producer writes the messages to the topic whereas a consumer consumes the messages from the topic. when sending a message node acts as a producer and sends the message to a topic. to receive the message a node acts as a consumer and consumes the message from topic.



there is a topic created for every node in the system. the topics can be distributed in different brokers who are coordinated by the zookeeper in kafka. also, to boost performance, different partitions of the same topic can be used by the nodes working on the same task or in the same area.



the details to add the block are sent as a value which follows avro schema. apache kafka presently supports three schema formats viz. json, avro and protobuf for key or value. the messages are stored in a topic and can be read by the nodes anytime as offset associated with the topic is stored/tracked.



the message to be sent is firstly encrypted by the public key of the receiver and then sent. the receiver then decrypts the encrypted message using its private key. in our work streams of data are broadcasted to all the nodes by the sender(producer) and each of the receiver nodes(consumer) checks if the message was meant for them or not. if yes, then that consumer tries to decrypt the message and displays it. when a message is sent it is visible to all the nodes in encrypted form in the form of byte arrays and the nodes can access that value to display it or anything else. rsa is an asymmetric cryptographic technique for encryption and decryption of messages. being an asymmetric technique there are two keys, namely public key(used for encryption and can be known to every-one) and private key(used for decryption and should be known to the message receiver only). a popular encryption program pgp(pretty good privacy) generally used for encrypting emails is also based on rsa. in our case we would be sending messages from one node to another and hence to promise confi-



a blockchain is a platform used for doing computation and other information technology tasks which is decentralized in nature and instead of depending upon one single authority to make all the decisions there are many authoritative domains available who are capable of doing the same and need not trust each other in taking part in any rational decision-making process. here the chain of blocks is used to maintain and store the record of messages exchanged between the nodes. each of the nodes here contains a chain of blocks where all the message records are stored. since each node is having their own copy, in case some malicious block is added by a 3rd party or by a node itself to cheat or gain unfair advantage the others will get to know. this will be useful to solve any conflicts that may arise using the consensus mechanism.



when a message is sent by a node(producer) it contains the details which will be used to generate a block for the same. a new block added will contain the hash of its previous block. and this addition is done only after it satisfies the proof of work done. since each of the nodes will be maintaining its own copy and the kafka servers are distributed across regions so there will not be a single point of failure and neither will a malicious entity be able to alter any blocks which would get accepted by the others.



the blockchain usually follows a distributed structure where the chain is distributed among several people who form a peer-topeer network. the process of adding a block in the chain is time consuming as it has to be validated by every-one(or majority) in the system. this makes the system difficult to tamper with and contributes to its security.



the hash value of the latest block is included in the details used to create a new block and thus the block added will contain the hash value of its previous block. the block addition is done only after it satisfies the proof of work consensus mechanism. there will not be a single point of failure as each and every node maintains its own copy and the kafka servers/brokers are distributed across regions. there will be no malicious entity who can alter the blockchain as it would not get accepted by the other nodes or participants.



taking the mean of the time taken to send a message to other nodes after getting connected to the cluster, we get the value as: r(time taken in sending a message after connecting to cluster)/15= 133.61 s/15= 8.907 s.



we have presented here a mcs system which is decentralized in nature and supports continuous feedback between the nodes for the work being done which keeps them in loop throughout the process. decentralization is capable of solving some of the problems faced in traditional approaches and the feedback mechanism implemented in the system aims to solve those problems at a more refined level. this in turn impacts incentive compensation and aims to enhance the reward system prevalent in traditional systems. the focus of this paper is on implementing the continuous feedback mechanism integrating it with an encryption layer to add an extra layer of security. we did not give any details on implementing the reward system but the concepts stated here might be helpful and may contribute to refine the traditional reward systems without any drastic changes. to further enhance this system, we might consider developing a mechanism which makes the system more secure and the information being exchanged more privacy friendly. in current implementation the nodes can see the transaction details and can easily find out who is the sender and the receiver. the identity of the nodes can be kept secret thus protecting their privacy in the system which may consist of thousands of nodes.



