a decision procedure for arbitrary first-order formulas can be viewed as combining a propositional search with a decision procedure for conjunctions of first-order literals, so boolean sat methods can be used for the propositional search in order to improve the performance of the overall decision procedure. we show how to combine some boolean sat methods with non-clausal heuristics developed for first-order decision procedures. the combination of methods leads to a smaller number of decisions than either method alone.



for large formulas with significant boolean structure, the size of the propositional search tree dominates the overall performance, so heuristics and clever search algorithms for sat are important. we can combine sat methods with non-clausal heuristics developed for first-order decision procedures to obtain a method which takes fewer decisions to decide a formula than either one by itself. section 2 reviews existing methods for propositional satisfiability and describes some non-clausal search heuristics. section 3 describes our implementation combining these methods, and section 4 gives quantitative results obtained using cvc lite, a proof-producing decision procedure for a combination of theories without quantifiers.



in the first-order version of dpll, we replace variable assignments with first-order assumptions. propositionally satisfying assignments are checked by submitting the conjunction of first-order literals induced by a propositional assignment to the first-order decision procedure. if the first-order decision procedure is online(like cvc lite is) then first-order literals can be submitted as the partial assignment is built, rather than when the algorithm finds a propositionally satisfying assignment. the algorithm may then discover much earlier that a partial assignment does not first-order satisfy the formula.



cvc lite) uses the same strategy of generating conflict clauses based on proof assumptions. the ics decision procedure does an optimized trial-and-error elimination of irrelevant literals in a clause rather than tracking dependencies on assumptions. verifun takes an intermediate approach: it cannot produce proofs, but it does track just enough dependency information to enable the production of conflict clauses.



a great difficulty of the dpll algorithm is choosing splitters. the order in which splitters are chosen can have a huge impact on the performance of the algorithm, because a particular choice may prune a large subtree of the decision tree. sat solvers such as chaff incorporate decision heuristics which work well on many pure boolean problems given in cnf. but we can do better by taking advantage of the structure of a non-clausal(i.e. non-cnf) formula to guide the search.



however, we may encounter a sub-problem that contains a splitter that is in the cache, but is not effective for the sub-problem; the sub-problem is not closely related to the sub-problem for which the splitter was originally effective. in particular, when a splitter is added to the cache because it is effective for a small sub-problem, it is unlikely that it will be effective for a much larger sub-problem. moreover, a poor splitter choice in a large subproblem is worse, in terms of the amount of extra work it causes, than in a small sub-problem.



finally, the splitters in the cache are ordered according to how recently they were added to the cache. so for a particular sub-problem, the newest splitter that is in the sub-problem and has sufficient trust for the height of the sub-problem is chosen. if no such splitter exists in the cache we fall back to the dfs heuristic.



the caching heuristic is similar in some respects to the heuristics in chaff(both vsids and the heuristic that chooses a splitter from the most recent conflict clause if possible), insofar as they both try to take advantage of the adjacency of similar sub-problems as the decision tree is searched. the differences are that the caching heuristic is somewhat more conservative(it puts splitters in the cache only when it finds an effective splitter, not on every conflict), it falls back to the dfs heuristic when there are no applicable splitters in the cache, it makes no attempt to weed out splitters that do not contribute to the two conflicts of an effective splitter(corresponding to conflict-clause minimization), and it maintains a trust metric to avoid poor splitter choices. while the caching heuristic is somewhat ad hoc, it works well in practice.



result of an and expression is known to be true, then both of its child expressions must be true. this direct propagation can be done more efficiently than bcp on the cnf translation. however, in our present implementation the cost of the first-order decision procedure is much greater than that of bcp, so this optimization does not significantly improve the overall results.



with simple search, the caching heuristic improves on dfs in both number of decisions and time. the fast search with dfs improves on the simple search in number of decisions, and the addition of cnf clauses to the fast search improves further on the number of decisions. finally, the combination of the fast search with cnf clauses and the caching heuristic does better than either method alone in number of decisions, but is somewhat slower than the caching heuristic alone.



