et al., 2019; he et al., 2019; olayiwola and sanuade, 2021). in recent years, advanced applications utilizing sonic logs have reached to eval- uating gas-hydrate systems, which are expected to provide additional geological implications in the exploration and exploitation followed. (saumya et al., 2019; you et al., 2021). while the monopole logging tool has a limitation in measuring shear wave data from slow formations, the



models that integrate a multi-hidden layer extreme learning model (melm) and optimization algorithms such as particle swarm optimizer and genetic algorithm. these data-driven approaches have made great achievements in generating practical as well as reliable synthetic shear sonic logs. however, previous studies were more focused on comparing overall performances among prospective machine learning models to identify the superiority. for this reason, it has limitations in terms of maximizing the performance of the best model. first, in most studies, a single set of hyperparameters was provided, which were determined



followed. in this study, we introduce a hybrid machine learning model generating shear sonic log for the purpose of enhancing model perfor- mances compared to the general approach. as an unsupervised geological characterization as well as an alternative way of geological characterization, data clustering was applied to test if it could help enhance the model performance. and pso algorithm is combined with three representative machine learning models such as svr, dnn (deep neural network), and lstm in order to find an optimal set of hyper- parameters. these two approaches are expected to improve the perfor- mance of general machine models further as well as reduce manual intervention and time spending.



multi-linear regression (mlr) model was employed to compare predic- tion accuracies for different numbers of the feature. the mlr model is relatively simple and easy to code as well as quick to process compared to advanced machine learning models. for this reason, the mlr model was used as a sort of tester to determine an optimal combination of features. five cases (from one to five input logs) were set, and features for each case were selected using the rank of the pearson correlation coefficient. the five-feature case showed the best accuracies both for the mean absolute error (mae) and determination of coefficient (r2)



denotes the weight matrix between the input and lstm units, and wh denotes the weight matrix between the hidden states. the symbol * denotes elementwise multiplication. w is the weight between the hidden state and output. y d is the dts (i.e., predicted target value) at d-th depth.



the pso is one of the optimization algorithms employed to find an optimal solution through iterative computation using a variety of vari- ables (bonyadi and michalewicz, 2017). in the pso algorithm, a popu- lation of particles (i.e., a swarm) of candidate solutions (i.e., swarms) is designed to seek the best solution in the search space while moving positions. the initial position and velocity of the swarms are randomly selected within the upper and lower bound. each position of the parti- from a range of values used for previous studies (bansal et al., 2011; anemangely et al., 2019; zhu and wang, 2018). callback and early stopping functions (maximum epoch: 500, patience: 10) were applied to reduce unnecessary execution time during each run of dnn and lstm.



hybrid machine learning model was introduced for the purpose of enhancing the accuracy in predicting dts log values. an unsupervised classification algorithm utilizing k-means clustering was combined with three types of machine learning models such as svr, dnn, and lstm. optimal hyperparameters were determined by the pso algorithm. the main findings are as follows:



three machine learning models showed fair to good performances in dts log predictions. lstm-pso and dnn-pso models outperformed over svr-pso models. lstm-pso models were better than dnn models in r2, mae, and residual distributions, but it contains more outliers that ultimately raise mse and rmse higher than dnn-pso models.



