aerial video stabilization system aims to remove undesired motion in aerial v deo. this motion is the result of undesired movement of mobile sensor. in this article we present a new video stabilization system for unmanned aerial vehicles (uav). our system is based on keypoints tracking. we use scale invariant feature transform (sift) keypoint detection, and matching to estimate parameters of affine transformation model. then, kalman filter with median filter is applied to remove video noise. a number of real aerials videos surveillances demonstrate that this method can achieve good performance.



techniques of video stabilization can be divided into four groups: optical approach, mechanical approach, electronic approach and digital approach. in this paper we focused on digital approach. this technique is an image pre-processing. all digital stabilization systems handle three essential aspects. the first one estimates the global motion, the second one concerns the motion smoothing and the last one is related to the motion compensation. among these components, the step of global motion estimation is the most vital but also the most difficult one [9].



in this paper we present a new system to stabilize aerial video surveillance by extracting and matching sift point for consecutive frames. in the following, sec.2 cites some related works on video stabilization; sec. 3 describes our proposed system. results achieved by our system are presented in sec.4. finally sec.5 presents summarized conclusions.



our input is a real video captured from uav. first of all, sift point are extracted and matched for two consecutive frame. next, inter frames motion is estimated using affine transform model. finally, both kalman filtering and median filtering are used in the step of frame compensation. the details are explained as follows.



in our approach, we estimate global motion vector by extracting sift points from two successive frame. next we calculate local motion vector by matching they two sets of invariant features. in other words, local motion vector between frame n-1 and frame n, can be estimated by extracting both the first and the second keypoints kpoint1 (xpoint1, ypoint1, 1) and kpoint2 (xpoint2, ypoint2, 1) from these two frames. in this step, we can show how the keypoint has probably moved from two successive frames. then we use ransac (random sample consensus) to select optimal matching. but, by this method, we obtain a whole number of local motion vectors. they sets of vector does not contain helpful indication for real movement of the camera because they include matches related to moving objects in the frame. deal with this problem we assume that, comparing to other motions, the velocity of moving objects in the scene is very large. for this reason we use a fixed threshold to eliminate moving object. as a result, we can generate the transformation matrix.



motion can be described either by a 2-d model or by a 3-d model [2]. the various transformations occurring in the 2d plane are translation, euclidean or rotation, similarity and affine. thus, in our method we adopt a four parameter 2-d affine estimation model to describe geometric transformation between two consecutive frames. given a point localized as pn(xn, yn ,1) in framen, and located as pn+1 (xn+1,yn+1,1) in framen+1, the transformation model from pn to pn+1 can be described as:



a new system for aerial video stabilization has been introduced in this article. the main idea of this system is to filtered undesired motion by detecting and matching sift point in order to predict the interframe motion. to evaluate our system we used real video captured by a camera installed on uav. the experimental results prove the efficiency and accuracy of our stabilization system. our future work will concentrate on performing motion estimation by integrating optical flow in the process of local motion detection.



