cheminformatics is the chemical field that deals with the storage, retrieval, analysis and manipulation of an increasing volume of available chemical data, and it plays a fundamental role in the fields of drug discovery, biology, chemistry, and biochemistry. open source and freely available cheminformatics tools not only contribute to the generation of public knowledge, but also to reduce the technological gap between high- and low- to middle- income countries. here, we describe a series of in-house cheminformatics applications developed by our academic drug discovery team, which are freely available on our website ( as web apps and stand-alone versions. these apps include tools for clustering small molecules, decoy generation, druggability assessment, classificatory model evaluation, and data standardization and visualization.



cheminformatics describes the use of information technology to han- dle chemical information [1]. the field itself has been integrated with the chemical sciences for many decades. however, the term was coined relatively recently, when the increasing amount of chemical data gen- erated within the drug discovery field (e.g., due to the implementa- tion of combinatorial chemistry and high-throughput screening plat- forms) made the use of chemical information technologies increasingly mandatory [2]. although cheminformatics has a wide scope, core tasks within the cheminformatics field include the management of chemical databases and datasets, storage and retrieval of chemical information, structure-property relationships, in silico screening, and the design of combinatorial and focused libraries.



small academic research center dependent on the university of la plata (unlp, argentina) with a focus on drug discovery projects, and a partic- ular interest in the field of infectious tropical diseases. as part of these, we have developed publicly accessible cheminformatics web apps de- ployed through the streamlit framework and standalone source codes. here, we provide an overview of these resources, which are freely ac- cessible on our website at these include clustering, decoy generation, druggability prediction apps, and other secondary resources related to chemical data standardization and visu- alization.



several data science and machine learning platforms have been de- veloped thus far, enabling users with limited coding ability to create pipelines for data exploration, analysis, and mining. some well-known examples include knime, pipeline pilot, and alteryx. although they of- fer free and open-source distributions, most advanced features or third- party applications are only available under commercial licenses, which sometimes makes them inaccessible to small research units in develop- ing countries.



all applications within the lideb tools suite were deployed as web apps on the streamlit platform, so scientists can use them through a user-friendly interface using computational resources allocated to the cloud. alternatively, their standalone distributions are written in plain python, under an object-oriented programming (oop) paradigm and using open-source libraries, offering a higher level of customization and code reusability. moreover, they can easily be plugged into existing chemoinformatic pipelines.



in the input step, the molecules to be clustered should be provided as a .csv file, where each line corresponds to a molecule in smiles format. after optional standardization employing molvs [9], mordred [10] is used to compute 1613 molecular descriptors for each molecule. alter- natively, users may provide their own pool of molecular descriptors as tab-delimited .txt file.



in the input step, the molecules are provided again in smiles nota- tion as a .csv file, but instead of calculating molecular descriptors, the molecular representations are encoded into estate1 molecular finger- prints, calculated by rdkit, with a fixed-length fingerprint containing 79 features [25]. the umap algorithm, a nonlinear dimensionality reduc- tion technique based on riemannian geometry and algebraic topology, is then applied to reduce the hyperdimensional space of the fingerprints, retaining the most informative features of the process. the size of the embedded space is determined based on the size of the dataset. in the clustering step, the gmm algorithm is applied to the molecules in the embedded umap space to search for the number of k clusters that max- imizes the silhouette score. an elbow plot of the silhouette score vs. k is presented for visual estimation of the optimal k. the same additional cvis previously described for irapca are also calculated and the same output files are generated.



once the optimal cutoff has been identified, chica is re-run with this distance value, generating four output files: clustering_assignations.csv which specifies which molecules have been assigned to which cluster according to the chosen cutoff value; cluster_distribution.csv, which speci- fies the number of obtained clusters and their sizes; validations.csv which contains the values of the cvis; and settings.csv, which contains the se- lected parameters in the run.



windows can be narrowed or expanded by the user. if fewer than 400 molecules are recovered in this randomly chosen chembl subset, the property limits are extended by a factor of 1.5, up to five times. for in- stance, in the case of mw the window is extended, round by round, to



preliminary list of decoys are estimated. for this, the difference between each known active compound and each decoy in terms of the six pairing properties is calculated and summarized with a physicochemical similar- ity score (pss) ranging from 0 (lowest similarity) to 1 (highest similarity) [38]. the compounds are then ordered with descending pss values, and the top 200 are selected.



the quality of the generated decoy molecules, in terms of the physic- ochemical matching of decoys and the risk of allowing latent active compounds in the decoy set (lads), was determined by the deviation from the optimal embedding score (doe score) and the assessment of the doppelganger score, respectively, as recommended by vogel et al. [38]. the doe score was obtained by analyzing the spatial distances of the molecules in the chemical space defined by the six normalized physicochemical properties used to match queries and decoys. briefly, the distances from each active compound to all remaining active com- pounds and decoys were calculated in the normalized multidimensional space and molecules were sorted in ascending order according to these distances. the real class of each molecule (labeled 1 for active com- pounds and 0 for decoys) and the obtained distances were later used to build a receiving operating characteristic (roc) curve for each active compound, and the average absolute value of the difference between the area of these roc curves and the area of a randomly sorted list of compounds (0.5) was defined as the doe score:



seventy percent of the proteins in each class was sampled for the training set of the classifiers. the remaining proteins were used as a test set to validate the generated models externally. to realize this sampling representatively, we used a clustering strategy that combined dimen- sionality reduction of zernike descriptors [45] by principal component analysis (pca) followed by the application of the k-means clustering algorithm.



in contrast, in the randomization test the class label was random- ized across the proteins comprising the training set. the training set with the randomized variable was used to train new models, from the descriptor selection step. this procedure was repeated 1000 times for each descriptor subset. randomized models are expected to have poor accuracy compared with real models.



listo is a standardization web app that helps to automatically stan- dardize collections of chemical structures that may present different, non-homogeneous molecular representations. this simple standardiza- tion is useful for ensuring a homogeneous format of molecules before calculating any conformation-independent molecular descriptor. in this process each molecule, submitted in a .txt file in smiles notation, passes through a series of standardization steps that are included in molvs. by default, listo retains only the parent fragment of the molecule (the largest organic covalent unit in the molecule), removes all stereochem- ical information from tetrahedral centers and double bonds, mantains the uncharged version of the fragment parent, replaces atoms with the most abundant isotope, disconnects metals from organic atoms, ap- plies a series of transformations to correct common drawing errors, and removes hydrogen atoms. the web app also returns the canoni- cal tautomer, which is a unique representation, selected with a scor- ing function from all possible tautomers that could be generated from a molecule; importantly, the canonical tautomer is not necessarily the most energetically favorable [47]. a log file with additional information regarding potential problems for specific standardization actions can be downloaded. in addition, the standardized molecules can be visual- ized in the web app through the interactive chemical viewer mols2grid (



we presented and discussed an array of cheminformatics tools developed in our academic drug discovery laboratory. these open- source resources are freely available as online web apps ( biol.unlp.edu.ar/) and as standalone versions ( lideb/). they were developed using publicly available open-source re- sources and internal programming.



