language-based security approaches to access control and information flow control must at some point rely on a language for expressing policies. however there will in general be several choices for the correct policy language for any given application, and several choices for the implementation of a policy language in a given domain. this article considers an approach to implementing the policy language at the application level, relying on trusted cryptographic libraries whose interface security guarantees are used to verify the correctness of the policy language implementation.



using these libraries, they are implicitly enforcing security policies for the data is being exchanged. this policy is often unstated, or only stated informally in program comments. if these security policies are stated in a suitably formal policy language, then adherence to these policies may be verified, often using automatic or semiautomatic techniques.



one particular approach, exemplified by language-based security, is to express the policies in a policy language that is incorporated into the type system. typechecking then provides an avenue for checking the correct manipulation of data according to the security policies expressed in program types. these security policies can then be related to the cryptographic libraries used to secure network communications, via typed apis for cryptographic operations that express the security guarantees these operations are intended to enforce(e.g., encryption for secrecy, digital signing for integrity).



as a major example, we consider a particular policy language implemented as a library in such a framework. the policy language in question is chosen because it has two disparate implementations, involving quite different sets of cryptographic operations. this demonstrates the wisdom of moving the implementation of the policy language out of the language itself and into libraries. not only does it appear impractical to expect a single universal policy language that will satisfy the needs of all applications, but it is also questionable if there is a single universal implementation of a policy language that matches all applications.



ordinary types are used to check the well-formedness of values. besides function and polymorphic types, we include datatypes for basic structuring. these datatypes go beyond ml datatypes in two significant ways: they allow nonregular recursive type descriptions, and they allow free(implicitly existentially quantified) type parameters in the types of data constructors. both facilities are critical for examples we have developed.



representations of these entities. in many cases these are simple constants(for example, public keys identify principals and strings identify roles), but in some cases structured representations may be necessary(for example, for parameterized roles). we treat rep as a special type constructor rather than introduce kind polymorphism, which technically is necessary because the form of the argument of rep may range over different kinds(propositions, principals, roles, etc).



it is important to understand the difference between the types f and rep f. the former denotes the type of a certificate that verifies that a statement in the policy language is valid. such a certificate is built using the constructors for the inference rules of the language. the latter denotes the type of a value-level representation for a policy language statement. it is only checked for its well-formedness, not for its veracity.



for the purposes of the example in this article, we add a kind prin for principals, as well as a proposition form p says f for statements in an arbitrary policy language. the rules of a policy language based on this will include rules for combining certificates, so that the combination can be checked and the resulting statement verified. an interesting question then arises: how to generate primitive policy language statements while ensuring their integrity. one approach is to rely on private signing keys, e.g., an operation of type



our main example illustrates the general approach of bringing aspects of the policy language outside the trusted computing base(tcb) and implementing them as libraries. as explained in sect. 1, part of the motivation for this approach is the myriad possibilities for the policy language. even if one were to fix on a policy language, there may be several possible implementation strategies associated with it. the example in this and the following sections illustrates an end-to-end approach based on the policy language itself being implemented outside the tcb.



general delegation has been criticized in some circles because of the expense of credential chain discovery and of checking credential chains. cascaded delegation is a more limited form of delegation that only allows credential chains to be extended in one direction[29,37]. cascaded delegation was explicitly developed for delegation in distributed systems. role-based cascaded delegation(rbcd) synthesizes role-based access control and cascaded delegation.



the authorize and delegate rules rely on static compile-time credential checking based on type-checking. the correctness of the credentials built using these rules is based on the types of the arguments, which are unsigned cleartext. credentials based on these rules are amenable to forgery and tampering when transmitted across address spaces. so there should be some way to build credential chains, using cryptographic signing, that prevents these forms of attacks.



these operations take credentials as arguments. providing cleartext credentials of type d says f is insufficient: the combined credentials will typically be bundled up and retransmitted across unsafe networks, and the digital signatures for the original credentials from which the cleartext credentials are derived must be included in this bundling. therefore instead of cleartext credentials of type d says f, we use combined cleartext and ciphertext credentials of type simplecert(d, f). a value of such a type is a pair of a ciphertext credential(with the signing principal elided) and the underlying cleartext credential(with the signing principal d made explicit in the type). it is straightforward to map between ciphertext credentials and these credential pairs during marshalling and unmarshalling.



a.r. there is an implicit use of existential types to elide the intermediate role a0.r0 in the type. the initiate operation creates an empty chain, the extend operation extends the chain by one more role, and the say operation recurses over



as noted, this does not affect the implementations of the rbcd operations, since they do not perform authentication. authentication is performed in the process of unmarshalling signed certificates and building simple certificates. if simple certificate formation is restricted to the makecert(make a new simple certificate) and authcert(build a new simple certificate from ciphertext) operations, then authentication failures are isolated to the latter.



into one. we define this aggregation operation for simple certificates(pairs of cleartext and ciphertext credentials), rather than just ciphertext credentials, in order to continue doing well-formedness checks on the underlying cleartext credential without having to digitally authenticate. the aggregation operation takes as its third argument an inference rule for combining the underlying cleartext credentials when ciphertext credentials are merged.



the new concept introduced by the hcbe operations is that of combined signing and authentication keys. the aggregation operation of hcbe builds a new ciphertext, from two signed ciphertexts, by signing the underlying cleartexts with the combination of the original private signing keys. the combination of the corresponding public keys is then used to authenticate. an advantage of the hcbe approach over the rsa approach is that the identities of the signing principals, beyond the first principal in the chain, does not need to be revealed, thus providing some notion of privacy in credential chain checking. we represent key combination



in sect. 2 we discussed the issue of how to generate primitive policy language statements, of the form p says f, while ensuring the integrity of the statement. simply creating a data structure of representation type rep(p says f) is obviously insufficient. the approach mentioned in sect. 2, similar to the approach of proof-carrying authentication, relies on private signing keys for principals to generate these statements. in this section we consider another approach, related to integrity-checking in language-based security.



the integrity constraint in the labelled type ensures that this is a valid primitive statement in the policy language. unlike the aforesaid approaches, it does not rely on cryptographic libraries. therefore expensive cryptographic signing operations, and some assumptions about key management, are avoided for credential creation and manipulation as long as the credentials stay within a process address space. going one step further, we may treat p says f as an abbreviation:



labels and policies still rely on some notion of principals, at least in the jif framework. however alternatives may be explored where the form of policies is generalized from acls, and where principals then become derived concepts(derived from the access policies). this is an interesting line of further work that we are currently pursuing.



we have described an approach for building distributed implementations of policy languages over untrusted networks, building on trusted cryptographic libraries and using the language type system to carry correctness guarantees through the implementation. at the same time, we have deliberately omitted aspects of the implementations, for the purpose of simplifying the exposition. we deliberately treat the cryptographic operations as black boxes and do not consider attacks based on exploiting properties of the algorithms. so this approach is very much based on dolev-yao assumptions about the algorithms. additionally we do not consider network attacks based on protocol weaknesses, for example, exploiting attacks based on repeated uses of nonces. there has been a great deal of good work on type-based approaches to security protocol verification[18,19], essentially defining domain-specific languages in which it is impossible to implement incorrect protocols. these approaches make explicit notions of nonces, with type systems that prevent their repeated use and track correspondence assertions to verify aspects of the protocols. it appears to be plausible that our approach can be combined with these other approaches, at the cost of some increase in complexity(primarily the addition of effect types). the main conceptual overhead in this approach is a ubiquitious use of parameterized types to model security policies in the type system. since there is successful experience with the use of genericity in ml, haskell, ada, increasingly java generics and to some extent c++ templates, we are confident are our approach could be adopted by reasonably competent software developers. we are in the process of implementing this approach to test this assertion.



