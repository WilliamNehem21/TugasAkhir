the implementation of computational techniques based on ai tech- niques embedded in a robotic upper limb exoskeleton system represents the main topic for the present study. in this paper, a novel emg-based online shoulder motion recognition and control system is introduced. the online signal sensation system and robot motion control system are connected by labview software using a graphical computer program- ming approach. the essential role of this system is to connect the emg (semg) pattern recognition has been studied for the feasibility of voluntary control of a robotic device [19,35,36], including emg-based pattern recognition for upper-limb motion pattern recognition [37, 38]. most of the studies processed emg signals only for one dof motion pattern recognition [39]. we have started to develop a computer system that can sense muscle activation patterns and process the multiple channels of emg signals for upper limb exoskeleton motion control to assist the activities of daily living (adl) [34,35]. the performance has been evaluated and preliminary outcomes published in papers [35,40], however, the architecture of the emg-controlled, ml-based computer system has not been introduced or published. this paper presents detail information regarding online data acquisition, signal processing, and system connection. this paper also compares the difference between offline analysis accuracy and online performance accuracy.



processing emg signals for robotic upper arm control has been developed according to the neuromuscular characterization, but robot motions are still cumbersome because of the complexity of the muscu- loskeletal system of the upper limb [41]. the emg-controlled prosthesis also faces challenges from electrode placement location and pattern changes of emg activation over time, leading to a longer training pro- cess [42]. to date, most of the literatures have reported the mechanisms of hand/wrist control with fewer dofs (degree of freedom) of motions compared with shoulder joint [41]. the bionic control of an upper-limb exoskeleton is more complex that the control of other joint exoskeletons such as the wrist, knee, or ankle joint exoskeletons. currently, there are only a few of literature that reported the studies of emg-controlled bilitation have been proposed, the main trend in the research is the development of wearable robotic exoskeletons controlled by the fusion of data collected from multiple sensors with the training of intelligent algorithms [10]. the focus of our current study is on shoulder/upper limb exoskeleton intuitive control for carrying out activities of daily living (adl). the long-term goal of our research is to develop reliable systems through industrial or clinical validation and improvement of technical features targeting at intuitive control of the robot in order to have positive impacts on human strength augment and the rehabilita- tion process. the current study reports an approach of emg-based multiple-sensors signal fusion for shoulder motion pattern recognition and integration of the sensor system and ml processing system into a customized prototype of an upper limb exoskeleton system for intuitive control. this approach will enable the systems to be used in various applications related to robotic exoskeletons, including human perfor- mance enhancement, workload reduction, medical rehabilitation, or support for daily living activities.



robot system using emg signals recorded from six muscles of the upper limb among 7 healthy subjects, the results showed that nn yielded an accuracy of up to 88.7% during the training process while svm obtained an accuracy up to 85.9% in model validation [66]. using emg signals recorded from 12 muscles of the upper limb among 15 healthy subjects, the results showed that cnn obtained a recognition accuracy between 79.64% and 97.57%, the accuracy was affected by motion speed and the devices used for emg signal recording [40].



connected with the delsys egm data acquisition system, the lab- view acquisition program was run to read all emg signals from the delsys system and perform the feature extraction process simulta- neously. both raw emg signals and emg features were saved by the program as a csv formatted file. subjects were asked to perform a non- stop single pattern of motion repetitive twenty times following the pre- recorded video paradigm. for each motion, two csv format files (one for raw emg, one for emg features) were saved. after the acquisition process, python programs were developed to combine all emg features files and label the emg features for the later training process.



a customized offline machine learning training labview system was then used to generate machine learning models for the online emg recognition process. in this study, svm models (linear kernel-based and rbf kernel-based), one single-layer neural network model, and linear regression model were generated. the offline machine learning training labview system was developed using the analytics and machine learning toolkit. this system read the training data from the csv file and generated json format trained models, which were used in the real- time system.



the first step of the model training process was to input the csv file path into the system and define the hyperparameters of the svm and the ann methods. the second step was to run the labview program. then the system saved the trained models as jason files. for each subject, three machine learning models including lr (logistic regression), svm (support vector machine), and ann (artificial neural network) were trained by their training data [35].



the real-time emg recognition subsystem consisted of two real-time emg processing functions and real-time recognition function. the emg processing function was the same as the emg acquisition and processing module used in the offline training process (section 2.2). the emg processing function directly streamed the feature data into the online emg recognition function. this emg processing function used the trained model from the offline training process and made a classification decision based on the real-time input from the emg processing and feature extraction subsystem. after the classification decision was made, a motion command was sent to the upper-limb exoskeleton system to perform the responding motion. in the system performance test, each subject was asked to perform the selected motions ten times for each motion, and the accuracy of the system performance was determined. also, the tests were repeated for each machine learning model.



trigno sdk software was used in the development of the emg real- time control system. the trigno sdk software was used to connect trigno avati emg acquisition hardware and software to the labview software (ni, tx) for two software system interactions. using labview, the program connected the trigno sdk through an ip address and then communicate with a ni data board through a command port. the time window frame interval for trigno sdk was set at 13.5 ms.



after noise filtering, the features of emg data were extracted. in this study, sliding root mean square (rms) was used to extract the features from the raw emg signals of 12 muscles with a sliding window of 540 ms and an overlapping window of 81 ms. these features were then input into the pattern recognition module. a pre-trained machine learning module was loaded into the system for shoulder motion pattern recognition.



performed to determine the difference in accuracy of each motion pattern recognition among the three individual machine learning algo- rithms for different motion patterns. the accuracy of motion recognition was also compared between offline analysis and real-time performance. spss software (version 28, ibm, armonk, ny) was used for statistical analysis. a p value smaller than 0.05 was considered to be statistically significant.



correct prediction accuracy for the different designated motions, while other cells show the accuracy of the wrongly prediction. the accuracy was calculated from true positive, true negative, false positive, and false negative cases derived from the confusion matrix. the accuracy, together with precision, recall, and f1 score for each specific motion were thus obtained.



these three ml algorithms performed upper limb motion pattern recognition and exoskeleton motion control with an accuracy ranging between 71% and 98. in real-time motion pattern recognition and mo- tion control, svm outperformed ann and lr. svm is designed for small- size dataset applications. ann fits better for medium-sized datasets. the dataset we collected in this study was smaller; thus, svm revealed better performance [90]. lr fits better for dichotomous data [91,92] since the datasets in this study consisted of multiple-dimension information including emg channel, emg amplitude, and time point variables, hence the lr could yield a relatively lower accuracy in motion pattern recognition.



in real-time exoskeleton motion control testing, the system recog- nized resting and abduction with higher accuracy than drinking and pushing forward motions. one reason might be that these two kinds of motions are very similar, especially during the initial phase of motion. this could cause the machine-learning-based system confused in motion pattern recognition during the initial phase of drinking and pushing forward actions.



[97] were proposed to permit three-dimensional exercise training for patients with impaired arms [98]. most of these upper-limb rehabilita- tion robots were developed targeting robot-assisted therapy for the upper limb after a stroke. our upper limb exoskeleton system was also developed aiming for medical rehabilitation; however, it can also be applied to industrial robots.



limitations of this study include that this real-time system can only recognize four different motion patterns, which is far from enough for the activity of daily life (adl) training. the motion control is trajectory instead of adaptive motion control. twelve emg modules were used to recognize 4 kinds of discrete actions of adl. too many sensors may increase the complexity of actual use and commercial product devel- opment. the minimal number of sensors for optimal performance was not studied. this emg-controlled shoulder/upper limb exoskeleton has not been tested among clinical patients or industrial workers, it is un- known how the system will work among patients with remnant weak emg signal.



future work will focus on the development of a better computing system for the wearable sensor-controlled upper-limb exoskeleton sys- tem to better discriminate similar motions. the investigation will be performed to determine the minimal number of emg sensors for optimal performance. the effects of ml-based emg signals on the adaptive control of an upper limb exoskeleton will be studied.



this study demonstrated the feasibility of ml computing in multiple channels of emg signal processing for a real-time shoulder motion pattern recognition and wearable exoskeleton motion control. svm yielded better accuracy than the lr and ann in performance. the off- line pattern recognition had a higher accuracy than the accuracy of real- time exoskeleton motion control.



this study was performed in the department of orthopaedic surgery and sports medicine, detroit medical center, and the robotic rehabil- itation laboratory, department of biomedical engineering, wayne state university, detroit, michigan, usa. this work is supported by the wayne state university uptf professional development grant (grant# 20201020) and rehabilitation institute of michigan foundation (grant# 22-2-003) and by the national natural science foundation of china (grant# 51975360, 52035007). the authors would like to thank edward rozek, rachel toccalino, and linda gross assistance in this research.



xu y, liu x, cao x, huang c, liu e, qian s, liu x, wu y, dong f, qiu cw, qiu j, hua k, su w, wu j, xu h, han y, fu c, yin z, liu m, roepman r, dietmann s, virta m, kengara f, zhang z, zhang l, zhao t, dai j, yang j, lan l, luo m, liu z, an t, zhang b, he x, cong s, liu x, zhang w, lewis jp, tiedje jm, wang q, an z, wang f, zhang l, huang t, lu c, cai z, wang f, zhang j. artificial intelligence: a powerful paradigm for scientific research. innovation 2021;2:100179.



