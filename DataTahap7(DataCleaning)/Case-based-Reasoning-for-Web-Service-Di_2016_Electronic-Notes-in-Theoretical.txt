service-oriented computing(soc) has seen an ever increasing adoption by providing support for building distributed, inter-organizational applications in heterogeneous environments. mostly, the software industry has adopted soc by using web service technologies. a web service is a program with a well-defined interface that can be located, published, and invoked by using standard web protocols.



our proposal models a case-based reasoner for service selection, where the main contribution is threefold. we define a case representation capturing information in web services functional descriptions(typically wsdl). moreover, we draw a parallel among the key steps in cbr and the problem of web service discovery and selection. finally, we provide three implementations for the similarity function, concerning structural and semantic aspects from functional service descriptions.



the rest of the paper is organized as follows. section 2 details the service selection process. section 3 presents the application of cbr in the context of service selection. section 4 details the alternatives for the similarity function. section 5 presents the experimental validation of the approach. section 6 discusses related work. conclusions and future work are presented afterwards.



finally, the last step decides whether or not to include the confirmed solution(tested case) in kb. the learning case decision can rely upon different criteria. in this approach, we use a threshold value(th) over the similarity function: if the similarity function returns a value higher than the threshold, then the case is added to the kb.



the operations evaluation calculates similarity between this complex attribute in the new case, and the analogous attribute in the problem part of each case in kb. since the main criterion of our service selection approach is functional similarity, this attribute presents the highest weight(w= 0.6) and the most complex similarity function in this case-based reasoner. details of the similarity function for the operations attribute are presented in section 4.



to evaluate semantic aspects the similarity functions compare terms and identifiers from operations. we implemented three alternatives for these functions. the first two make use of wordnet. wordnet is a domain-independant lexical database of the english language that is structured as a lexical tree. wordnet groups terms in synsets(synonym sets) that represent the same lexical concept. several relationships connect different synsets, such as hypo/hyperonyms, holonyms/meronyms and antonyms. all hierarchies ultimately go up the root node{entity}. the wordnet structure can be accessed through different java libraries, each one implementing different metrics and features. particularly, in this work we used jwi 6(in the first similarity function) and jwnl 7(in the second similarity function). these libraries are among the most complete and easy to use for wordnet lexical tree manipulation.



stop words are meaningless words that are filtered out prior to, or after, processing natural language data(text). we defined a stop words list containing articles, pronouns, prepositions, words from other stop words lists and each letter of the alphabet. the terms lists obtained from the previous step are analyzed to remove any occurrence of a word belonging to the stop words list.



stemming is the process for reducing words to their stem, base or root form. due to common problems of standard syntactical stemmers, we adapted the semantic stemmer provided by wordnet. the stemming step receives as input a terms list. for each term in the list is verified that it belongs to the wordnet dictionary. if it does so, the corresponding stems are added to the result list. otherwise, the original term is added to the result list, considered as an abbreviation or acronym. after generating both lists of stems, their compatibility is calculated considering semantic information. this information is expressed as a vector of integers v={t, e, s, h1, h2} including: the total terms between both lists(t), the identical(exact) terms(e), synonyms(s), hyperonyms(h1) and hyponyms(h2). for example, let be the identifiers getreservation and getcurrentbooking extracted from the cases of the car rental example in section 4.1. according to the term lists semantic comparison, these identifiers present:



first, the normalized depth matrix(nd) is generated. the depth is defined as the shortest path between two terms in the wordnet hierarchy. these values are normalized by the maximum depth of the wordnet hierarchy(16). formally, the normalized depth is calculated according to formula 4.



the considered data-set consisted in 62 services extracted from the data-set of. we have generated(through a tool developed in our group) one case for each service to settle the initial kb, according to the object-oriented case representation presented in section 3.1.



to execute the cbr for service selection, we have defined one scenario considering three implementations according to the similarity functions presented in section 4, and the 506 new cases generated by mutating operation signatures. considering traditional techniques of service retrieval and selection, we also populated the easysoc service registry with the relevant services, and then queried such registry with the operation signatures. easysoc leverages vector space model(vsm) and web service query-by-example(wsqbe) to represent web service descriptions and queries.



the work in presents an approach for wsc using cbr. this approach combines cbr with semantic specifications of services in the owl-s language to firstly reduce the search space of web services(i.e., improve service discovery), and then build an abstract composite process. authors assume that web service providers are in charge of semantically annotating functional service descriptions according to the owl-s ontology. however, this hardly occurs in practice, and most domains currently lack a descriptive ontology. our work exploits the most possible information in the(always available) service functional descriptions, to build the case representation.



web service similarity is addressed in as a key solution to find relevant substitutes for failing web services. the approach calculates lexical and semantic similarity between identifiers comprising service names, operations, input/output messages, parameters, and documentation. to compare message structures and complex xml schema types, authors make use of schema matching. however, a straightforward comparison of complex types can be performed without dealing with



the woogle search engine for web services is presented in. based on similarity search, woogle returns similar web services for a given query based on operation parameters as well as operations and services descriptions. authors introduced a clustering algorithm for grouping descriptions in a reduced set of terms. after that, similarity between terms is measured using a classical ir metric such as tf/idf. the provided solution is limited to evaluating similarity using semantic relations between clustered terms.



the work in extends uddi with uddi registry by example(urbe), a web service retrieval algorithm for substitution purpose. the approach considers the relationships between the main elements composing a service specification(porttype, operation, message, and part) and, if available, semantic annotations. the weak point of the approach is, as we stated earlier, that providers do not annotate their services often in practice, even when introducing annotations provides a more accurate description of the service.



