The mechanism of action (MoA) of a compound describes the biological interaction through which it produces a pharmacological effect. Multiple data sources can be used for the purpose of predicting MoA, including com- pound structural information, and various assays, such as those based on cell morphology, transcriptomics and metabolomics. In the present study we explored the benefits and potential additive/synergistic effects of com- bining structural information, in the form of Morgan fingerprints, and morphological information, in the form of five-channel Cell Painting image data. For a set of 10 well represented MoA classes, we compared the perfor- mance of deep learning models trained on the two datasets separately versus a model trained on both datasets simultaneously. On a held-out test set we obtained a macro-averaged F1 score of 0.58 when training on only the structural data, 0.81 when training on only the image data, and 0.92 when training on both together. Thus indicating clear additive/synergistic effects and highlighting the benefit of integrating multiple data sources for MoA prediction.

A comparative study for library enrichment reported better predic- tive power for High-throughput screening performance using Cell Paint- ing as opposed to L1000 gene expression profiling [8]. Whereas, for pre- dicting MoA, Way et al. [9] found that L1000 outperformed Cell Paint- ing, but that there was complementarity, i.e. some MoAs were better predicted by one of the assays compared to the other. A related study by Lapins and Spjuth [10] compared Cell Painting, L1000 and chemical structure based predictors, and found MoA classes that were predicted better by each of the three predictors relative to the other two, support- ing the idea of a likely benefit through combining these different data sources. Another study predicting MoA [11], based on data from the ExCAPE database, which compared models built using image based fea- tures to those built using chemical structure descriptors, provided fur- ther support for the complementarity of these two data types, whereby the models performed somewhat differently at an individual class level. Besides comparing models built using different types of data it is also possible to combine the datasets and analyze them simultaneously to search for additive or synergistic effects. For predicting cytotoxicity and proliferation Seal et al. [12] compared Random Forest models us- ing Cell Painting image based features, molecular fingerprints, and com- bining both data sources. They found that the models based on image features outperformed those based on molecular fingerprints, but the combined models performed best in ten out of twelve cases. Another study predicting the bio-activity of approximately 16,000 compounds [13], found that models based on features derived from Cell Painting images outperformed those based on chemical structure profiles from graph convolutional networks (GCNs, [14]), but that the fusion of the

pounds. The compounds were administered to U2OS cells in 384 well plates at a dose of 10 micro-molar. Images at a resolution of 2160 x 2160 pixels were taken across 9 sites in each well and each compound was replicated 6 times. The compounds were distributed across 18 plates using PLAID (Plate Layouts using Artificial Intelligence Design, [21]).

[25] to convert the SMILES strings into graphs. For the CNN we gener- ated the feature matrix for each SMILES string based on the approach of Hirohara et al. [26]. Initially, we selected 42 chemical features to prepare the feature matrix of each SMILES string based on the selected chemical features. Secondly, due to the blank parts of the feature ma- trix resulting from inconsistent lengths of the SMILES, we applied zero padding to maintain uniform dimensions of the feature matrix. For the recurrent neural network, the LSTM, we utilized SMILES pair encoding

The 5 channels in the Cell Painting image data were standardized to remove plate-level effects based on the mean and standard deviation of the pixel intensities in the control DMSO wells in each plate. The images were resized from their original dimension down to 256 x 256 pixels. A quality control run on the data to detect saturation and blur in the images found no saturation issues (such as fibers across the field of view) but did detect some blurred images. However, given that a common data augmentation strategy for deep learning models is to purposefully blur the images we decided not to remove these blurred images from the dataset.

We also explored machine learning algorithms that operate on tab- ular data (in contrast to the deep neural networks described above). The more traditional machine learning models have shown compet- itive performance with deep learning models when dataset sizes are relatively small [32]. For instance, Jiang et al. [33] showed that four descriptor-based models outperformed four graph-based models on sev- eral benchmark datasets. We examined five individual machine learning algorithms and four ensemble algorithms. The individual algorithms in- cluded random forests [34], light gradient boosting machines [35], cat boost [36], k-nearest neighbors classifiers [37], and logistic regression [38]. The ensemble algorithms included bagging [39], stacking [40], ity. The two JAK inhibitor compounds in our test set (curcumol and CEP-33779), both of which were predicted poorly, are each at opposite extremes of the distribution for cLogS. The compounds NMS-873, NKP- 1339 and CYT-997 were also the least soluble for their MoA classes.

Due to data limitations our test set had only two to four compounds per MoA. The test-level predictive performance under such conditions may suffer if by chance any of these compounds happened to be outliers for their class. Based on our compound level analysis using DataWarrior it appears that this may have been the case for our two JAK inhibitor test compounds, thus potentially explaining the low F1 score for the MLP for this MoA.

Although it was somewhat surprising that for our models based on only the chemical descriptors, the simplest deep learning architecture, the MLP, outperformed the more complex networks architectures ex- plored, a similar result has been obtained in a previous study [49] per- forming drug target prediction on a large benchmark dataset from the ChEMBL database. In our MLP architecture, we used an unconvention- ally high dropout rate to alleviate the overfitting problem as a result of the scarcity of chemical structure data. We also tested other possi- ble architectures, such as reducing the dropout rate and increasing the number of hidden layers, with fewer neurons in each layer. However, these modifications did not improve the model performance.

Predicting the MoA of a compound can benefit greatly from the inter- action of multiple sources of data [2]. Various studies [9,10,13,53] have shown that image and transcriptomics assays contain both overlapping and distinct cell state information. Thus, an even better predictive model than our final one could potentially be achieved with the additional inte- gration of transcriptomics data. Further, other types of chemical struc- ture representations such as 3D descriptors could be explored. In the present study, for the image based model and the combined model, we used a set of ten well represented MoA classes and a widely established 2D descriptor for representing chemistry. In future work we will explore the predictive ability of these models across a wider range of classes whilst accounting for potential polypharmacological effects. Again the conformal prediction method mentioned above will likely prove useful for this purpose. Contrary to previous belief, polypharmacology, where a compound concurrently engages with multiple targets or processes, is the rule rather than the exception in biology [19].

In this work we explored the fusion of chemical structure and cell morphology data for the purpose of mechanism of action prediction. To the best of our knowledge our work represents the first combination of molecular fingerprint data and five-channel fluorescence Cell Painting image data, trained using deep learning in an end-to-end fashion, to pre- dict mechanism of action. Furthermore, for improved model flexibility and performance, we used the raw input images, as opposed to featured derived from them, as input to the models. We found a clear and signifi- cant improvement in predictive performance for models trained on both input types simultaneously, as opposed to in isolation, with an increase in F1 score of 0.11, highlighting the benefit of combining data sources for mechanism of action prediction.

