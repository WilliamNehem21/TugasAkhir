The bioconcentration factor (BCF) represents the tendency of a chemical to accumulate in organic tissues or living animals - typically fish. It is defined as the ratio between the concentration in the organism and the concentration in the surrounding water phase at steady-state conditions in the laboratory [1]. Oftentimes, this ratio is normalized to a fixed lipid content (5%) of the test organism. Common test species are fathead minnow, bluegill sunfish, or rainbow trout.

Experimental BCF data for model training was taken from Grisoni et al. [4]. They compiled BCF values for 1056 compounds by merging three datasets, which had been used for the development of BCF QSAR models, and 45 compounds with special metabolism or known Kow- BCF relationships (e.g., pyrethroids, organophosphorus compounds, perfluorinated and polychlorinated compounds). In terms of chemi-

To build the external test set, we searched for BCF values in the PPDB [31] (as of 08-03-2022) that were neither part of our training dataset nor part of the Meylan model [6,7] training set. Only entries with an assigned quality level of 4 or 5 were kept, which means the endpoints have been reviewed and curated by the PPDB providers and were used for regulatory purposes in the majority of the cases. To main- tain feasibility with our modelling approach, we excluded molecules containing metal atoms and stereoisomers with more than 0.8 log units difference in BCF between the isomers. Furthermore, we cross-checked the reliability of the data based on original study reports or public list of endpoints. This led to the correction of flufenoxuron, spirodiclofen, metaflumizone, camphechlor and removal of aldicarb, vinclozolin, 1- dodecanol, and acrylonitrile from the set. However, we could not check ca. one third of the molecules because the data origin was not referenced precisely. In total, the final curated test set contains 80 molecules.

[13] to 512 dimensional descriptors without any further pre-processing by CDDD. Note that this circumvents the applicability domain restric- tions imposed by the CDDD pipeline (logP -5 to 7; molecular weight 12 to 600 g/mol; 3 to 50 heavy atoms) and affected around 3% of the molecules from our datasets. For a discussion of the impact of this de- cision, see subsection Applicability Domain. Nine molecules had to be excluded from the training set at this stage, because they contain Sn, which is not part of the CDDD vocabulary.

All our cross-validation routines were conducted on these cluster splits, for both single-task and multitask models. For training processes involving both hyperparameter optimizations and model selections, nested cross-validation [34] was employed to avoid optimistic biases when evaluating model performances. Nested cross-validation uses the data effectively to create a series of data splitting (training, validation and test). Simple leave-one-cluster-out cross-validation was used when only tuning hyperparameters for fixed model structures.

Support vector regressor (SVR), random forest (RF), and XGBoost were trained on the BCF data using the CDDD embeddings as input fea- tures. Nested cluster cross-validation was employed to perform hyper- parameter optimizations and model selection. Our cross-validated train- ing results showed that the CDDD descriptors work best in combination with SVR, as previously reported [13]. The optimal SVR has radial basis 0.005. In addition, early stopping was employed to avoid overfitting, where the patience and epoch number are finetuned during optimiza- tion. All hyperparameter values specified in the text were obtained by optimizing the loss function on an extensive hyperparameter grid. The training scripts and all optimal hyperparameters can be found in the supporting information.

To explain our BCF model, we borrowed ideas from post-hoc pertur- bation methods, feature ablation and occlusion [44,45]. The aim is to establish a gradient-free method for assessing the importance of indi- vidual SMILES characters. In general, such methods replace the original input features with a baseline value to create a perturbed input. It is expected that the more important a feature is, the greater the change in

From the models tested, only Vega Read-across was able to outper- form our xBCF model, but only when considering molecules inside the applicability domain, i.e. when very similar molecules exist in the train- ing set. This restricted the applicability to 102 out of 184 molecules. Our xBCF model on the other hand, was evaluated on the full set of molecules. Moreover, the LOCO evaluation process involves a certain degree of extrapolation, which means the model is useful even for new chemical classes.

the cross-validation results due to higher similarity to the training set. For the other models, the external test set is a more demanding task compared to the training data and many models fail to properly predict these molecules. Some of the models even struggle to outperform the linear logD model, which might indicate overfitting. The generally infe- rior performance can have several reasons. First, the data we collected, although carefully checked, might have undergone a less rigorous cura- tion than the training set, which had been checked and used in multiple works already. Therefore the experimental BCF values might be slightly

With these goals in mind, we introduce two input perturbation meth- ods to obtain signed atom-level sensitivity scores. Together with smart visualizations, these methods allow inspecting the model predictions for each input molecule of interest. Because they are gradient-free, the methods can be widely applied, independently of the downstream mod- eling algorithm used.

The resulting sensitivity scores are context-dependent, as opposed to rule-based systems which would assign the same meaning to a particular substructure in all molecules, regardless of the context. The context of course refers to the input SMILES, such that different SMILES notations lead to small variations in the sensitivity scores. We provide examples based on randomized SMILES in the Supporting Information that show the qualitative stability of the explanations.

very high values to several terminal atoms with a double bond and clos- ing brackets, which appear in non-terminal positions in the SMILES string (see e.g., triallylamine example). Removal of these characters would lead to the formal introduction of new bonds between remote parts of the molecule, and thus a more drastic change to the molecule than removal of a single atom.

Overall, we consider the character substitution method slightly more useful for users who want to focus on the visualization of the molecu- lar structures, because of its robustness with respect to symmetry. The character deletion method can provide additional insights for terminal atoms, brackets, or other characters that have pronounced importance due to their particular position in the SMILES string. In the following sections, we focus on the character substitution method.

By training, many organic chemists are used to think in terms of func- tional groups to derive conceptual models and explain molecular proper- ties. Not surprisingly, there is a large variety of QSAR approaches in the literature building on functional groups or substructure contributions, e.g., classical group contribution methods, atom-centered fragments, fingerprints, and many more [56]. An ideal explainable AI framework for molecular property prediction would assign attributions to both in- dividual atoms and larger substructures. We were curious whether our data-driven approach could be used to explore effects of functional groups, keeping in mind that our sensitivity scores are conceptually different from additive contributions. For this analysis, we summed up the sensitivity scores for a set of common functional groups (including bracket and bond characters) for the molecules in our BCF training set.

We compare these group sensitivity scores to the correction factors of the KOWWIN model [7,36] as a typical representative for group con- tribution models. KOWWIN predicts logKow as a linear combination of group contributions, i.e., fitted parameters for a set of pre-defined atoms and functional groups. Additionally, we compared the QSARpy modula- tors [57] that were derived from differences in measured logKow upon addition or removal of molecular fragments. When multiple modulators matched the KOWWIN description we selected only the most general definition.

approach, where both lipophilicity (logD) and BCF are predicted simul- taneously. Based on a rigorous evaluation, we show that our model is more accurate than previously published models, and generalizes well on unknown regions of the chemical space. It is purely data-driven and therefore independent from expert-crafted rules or the definition of functional groups. More importantly, we provide SMILES token sensitiv- ity scores which serve as local explanations for each prediction. This new explanation method relies on SMILES token substitutions or deletions, and can be applied to downstream models based on CDDD descriptors or other string-based models learning directly from SMILES strings. We hope that together with a robust prediction model, the explainability layer will increase the value and trustworthiness of the predictions. It allows users to poke inside the inner workings of the model and could help with molecular design and mechanistic understanding of processes involved in bioaccumulation. We discussed various examples to spot-

light important perks of the explanation methods, and to give guidance for their interpretation. We could show that the two methods highlight, how the prediction changes upon changing (substitution approach) or removing (deletion approach) a character from the input SMILES. We emphasize that this approach provides useful means to understand the predictions of the model based on its internal representation. How- ever, the sensitivity scores should not be confused with incremental contribution factors that sum up to the total prediction for the molecule.

We share the logBCF training and test sets along with the associated logD values (measured or predicted), cluster splits, and BCF predictions. The logD training set is a proprietary in-house dataset and cannot be shared. We provide the sensitivity scores as a JSON file that can be used with XSMILES. The python code repository to calculate sensitivity scores is available via https://github.com/Bayer-Group/xBCF.

