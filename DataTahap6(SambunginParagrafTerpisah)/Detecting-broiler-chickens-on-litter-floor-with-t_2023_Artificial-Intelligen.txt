Poultry provides a valuable source of proteins but face a number of challenges worldwide. Among the many challenges is the welfare concerns of the birds under intensive management systems (Chai et al., 2018, 2019). Due to the large number of chickens reared at any given time in a house, accurate and efficient monitoring of birds can improve their health and welfare status (Li et al., 2021; Okinda et al., 2020). Currently, most broiler houses are monitored manually, however, this approach could be both laborious and erroneous. Automatic broiler monitoring system could collect individual bird data within a flock and provide critical information to aid digital management (Subedi et al., 2023a, 2023b; Yang et al., 2022).

Deep learning technology has powerful feature representation capa- bilities, fast processing speed, and can resolve problems associated with external interferences. Thus, deep learning algorithms are appropriate models for developing an automatic, efficient and intelligent tool for an- imal farming (Qiao et al., 2021). Deep learning technologies have been applied to the study of large animals (pigs, sheep, cattle), such as object

In the current study, we incorporated a convolutional block atten- tion module (CBAM) into YOLOv5 to enhance the algorithm's ability to extract image features. To do this, we used a complex dataset of broiler images (e.g., birds at different ages, fresh and reused litter and multiple pens) to train and test the model. The proposed YOLOv5- CBAM improved the acquisition ability of small object features and the accuracy of small target detection.

Jocher et al. (2020) developed the YOLOv5 algorithm and demon- strated that it was more accurate and faster compared to the previous YOLO model. The YOLOv5s network consists of three parts: backbone, neck, and prediction. Broiler chicken images were used as input for the backbone to obtain image features, the neck part was used to inte- grate the extracted feature information and generate feature maps, and the prediction part was used to generate bounding boxes and pre- dict categories for the generated feature maps. The detailed process is provided as a supplementary material.

In the target detection task of broiler chickens at different growth stages and in different scenes, occlusion or small targets occupy fewer pixels, and their feature information is easily lost in the deep network, which leads to missed and false detection of targets. The CBAM module can effectively increase the weight of the occlusion or small targets in the entire feature map through channel and spatial attention modules, making the information easier to be learned by the network (Woo et al., 2018). The broiler image features extracted from the C3 module were denoted as F, and the channel attention map was generated by where, TP, FP and FN are the numbers of true positive samples, false pos- itive samples and false negative samples, respectively. The mAP is the mean of all classified AP (Average Precision). n represents the number of object categories (n = 1). FPS refers to the number of images identi- fied within 1 s.

YOLOv5-CBAM-broiler model. The proposed approach integrates CBAM into YOLOv5 and improved the overall detection performance, espe- cially in the case of small targets or occlusions. In addition, the results show that YOLOv5-CBAM could detect broilers of different ages effec- tively and provides the basis for real-time target detection for intelligent poultry management.

This study was supported by a cooperative grant 58-6040-6-030 (Lilong Chai) and 58-6040-8-034 (S. E. Aggrey) from the United State Department of Agriculture-Agriculture Research Service; USDA-NIFA Hatch Project (GEO00895): Future Challenges in Animal Production Systems-Seeking Solutions through Focused Facilitation; UGA CAES Dean's Office Research Fund; and Georgia Research Alliance - Venture Fund.

