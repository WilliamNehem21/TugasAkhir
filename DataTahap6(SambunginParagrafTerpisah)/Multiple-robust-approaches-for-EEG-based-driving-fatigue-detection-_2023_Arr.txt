Staying alert is quite crucial for many jobs such as driving, con- struction works and security guarding during night shifts etc. [1] The primary reason for all the accidents in the world is due to the drowsiness of the drivers. Drowsy driving can occur in any scenario but predomi- nantly occurs in long-distance transportation. Several factors cause ac- cidents due to fatigueness and drowsiness [2]. For drowsiness related crashes, a lot of factors are responsible such as length of the journey, weather condition, uniformity of the road, driving history of the driver, time of occurrence and the health condition of the driver. Before the onset of drowsiness, the driver must be alerted and it is one of the best methods to prevent the crash caused due to drowsy driving [3]. New sumption of a heavy meal during daytime, medications, lack of proper sleep, overthinking due to financial and family problems can cause drowsiness [6]. However, a lot of other accompanying factors are also present when drowsiness is referred too. An important impact on the progression of drowsiness is related to age and gender. Other important factors are smoking addiction leading to a poor appetite and sleep pattern, health issues caused due to anxiety, hypertension, high blood pressure etc. If one is feeling drowsy, there is always a state of reduced alertness and so it causes a performance degradation in the work and the person would not be able to think properly. The sudden changes in the behavioral pattern and sudden decline in cognitive functions can be easily measured and quantified using EEG signals [7].

In the proposed strategy 4, after pre-processing, the Correntropy spectral density and Lyapunov with Rosenstein algorithm is imple- mented and then the multi distance signal level difference is computed. Then the geometry of the SPD matrices is computed and the Geodesic minimum distance to the Riemannian means is calcu- lated. Finally tangent space mapping is implemented to it before feeding it to classification with machine learning classifiers.

In the proposed strategy 5, after pre-processing, the HHT is computed and then the Hilbert marginal spectrum is computed. Then using the Blackhole algorithm, the features are selected and finally it is classified with Cascade Adaboost classifier. The reasons for the algorithms chosen in the proposed methods are done after an in- depth study of the individual properties of the algorithms.

To the pre-processed EEG signals, MFA is applied initially [34]. To design the intrinsic graph to explain the intra-class compactness, the famous graph-embedding based framework utilized is MFA. In order to explain the inter-class separation with the penalty graph also, this technique is used widely. In the standard MFA method, the distance measurement technique is the traditional Euclidean distance whereas in this paper the distance measurement technique utilized is the inner product. The solution process of the algorithm can be optimized and simultaneously it is kept consistent with the distance measurement technique. The computation of the proximity degree of same class in the intrinsic graph Gc is done by means of assessing the sum of the distance values between each sample and its nearest K sample points from the similar class, so that the intra-class compactness Sc is achieved and expressed as:

Using domain adaption, the mapping matrix W is learnt given the features of both strong class and weak class. The weak class features P are extracted and projected them using W into the latent space so that the corresponding strong class features Q = PW are obtained. The inferred strong class features are used for testing and testing using a machine learning classifier and in our work four classifiers are consid- ered such as NBC, KNN, SVM and Adaboost respectively.

To evaluate and assess the ability of the features in classifying the EEG signals, ANFIS is also used [41]. The features in the dataset are learnt by the ANFIS so that the system parameters can be adjusted well based on a given error criterion. For analyzing various types of signals, ANFIS is widely used. The training of the ANFIS classifiers is done with the backpropagation gradient descent technique and the least squares method so that the generalization is improved. The training of the ANFIS classifiers is done with these techniques using the input functions. The samples are given the binary target values of (1,0) and (0,1) respec- tively. By utilizing a generalized bell-shaped membership function, the design of the fuzzy rule architecture of the ANFIS classifiers was done as dinary correlation function and it is also positive-definite and so it is utilized in many signal processing applications. CSD is dependent on the Fourier transform of the centered Correntropy function and it is a pos- itive definite matrix. A favorable performance for signals with Gaussian and non-Gaussian statistics is exhibited by CSD. Spectral estimation

The first step lies in the reconstruction aspect of the attractor dy- namics from a single time series. Method of delays is used as one goal of the work so that a fast and versatile algorithm is developed [42]. The reconstructed trajectory p is expressed as a matrix where every row is a phase-space vector.

The essential features are then chosen by the Black-hole algorithm [48]. Black-hole algorithm is used here as it is relatively easy to implement and is somewhat free from the tuning parameter issues. This algorithm utilizes a method of exploration/exploitation which is totally free of external components so that the probability of being affected to unexpected changes is reduced drastically. In every evaluation, the black hole algorithm in optimization problem converges to global optimal, whereas some of the other standard algorithms like PSO, ACO and GA might get stuck in local optimal solutions. The black hole al- gorithm is inspired by the law of attraction/absorption and it is dependent on the phenomenon of the same name which occurs in outer space. Three main fundamentals are present in this algorithm as follows.

represented by xd(t + 1). The event horizon is actually a radius R which is originated by the black hole. The black hole can be easily absorbed and destroyed in case a star crosses the horizon, so that a new star could be created randomly. It is observed as the probability of crossing the even horizon and is computed as follows:

where the performance value that has the best solution is represented by fbn and the value associated with the quality of the ith star is represented by fi and the number of stars in represented by n. The star crosses the event horizon when the distance between the black hole and the star is less than the radius. The absorption of this star happens and the random generation of the new one is done. The variability offered by even ho- rizon is highlighted so that the common problem of local optimum

criteria. It is quite difficult to assess the quality of found solutions in situations where the optimal solutions are not known apriori. In such a case, the ideal stop criteria depend on the total number of executed it- erations in the algorithm. The stop criteria in our work are initially set as 1000 off-line iterations. The optimization procedure is displayed in Al- gorithm 1. The random generation of the initial n star population for every intrinsic signal starts accordingly.

weak classifier is computed. Then for all the training samples, the weight values of this weak classifier are computed. Then for all the training samples, the weight values are re-adjusted and ultimately these weight values are chosen as an input to the next training iteration. In every training iteration, a new weak classifier is added and so there is a minimal improvement in the Adaboost classifier. Ultimately, the result of the strong classifier H(F) is expressed as follows:

The degree of variability in an algorithm is allowed by randomness. The process of absorption of the algorithm in the loop statement is carried out. The calculation of the quality of each solution is done and it is assessed by the performance of the feature. The solution is considered to have a high quality if the rating value is close to 1. The solution is considered to be of low quality if the rating value is close to 0. When the stars are absorbed by the black hole, the solutions are generated. For each intrinsic signal, this process generates a real number of pre- dictabilities. The locations are swapped if a star reaches a value which is better than the black hole. A new value is generated randomly if a star where the number of positive samples is represented by p and the number of negative samples is represented by q. The weight values of positive samples and negative samples are represented by wp and wn respectively. The sum of all these T weak classifiers give us the strong classifier H(F). The strong classifier is expressed as follows:

The features selected by the Black-hole optimization algorithm are then fed to the Cascade-Adaboost classifier [49]. A parallel classifier is Adaboost classifier which combines many linear weak classifiers. The weak classifier can be enhanced by the AdaBoost training algorithm so that self-adaptive goals can be easily achieved. In the given feature set, the focus is on the classification of one dimension by every weak clas- sifier. By adding a lot of weak classifiers, several key features can be easily focused on by the AdaBoost classifier. By adding a lot of weak classifiers, several key features can be easily focused on by the AdaBoost classifier. Once the addition of the weak classifier is done, the employ- ment of the minimum error is calculated so that the weight value of this negative sample, then it would be removed in the training set and as a result it would not progress to the next Adaboost classifier. Conse- quently, the number of training samples in training set is mitigated if the input feature vector F is assessed as a positive sample, then this partic- ular training sample progresses to the next layer for classification. The training samples on the end layer are quite similar to each other and so there is a good focus on similar training samples by the Adaboost clas- sifiers. As a result, cascade-Adaboost classifiers have the versatility to classify the selected features efficiently giving a high classification ac- curacy.

For this study, a publicly available EEG dataset was used [50]. For the acquisition of EEG signals, a brain cap with 32 electrodes was used. The utilized dataset in this work has EEG signals with 32 channels. The age group of the subjects was between 17 and 25 and the EEG data was collected from 16 healthy subjects (8 males and 8 female). With the help of a driving simulator and a brain cap, the EEG signals were collected. Prior to the experiment, no stimulants were used by subjects such as tea, coffee, alcohol, beer, energy drinks etc. The standard metrics utilized here for the analysis was Sensitivity, Specificity and Accuracy and is represented by the following formulae as follows: + Conditional Feature Mapping + Cross domain transfer learning with machine learning classifiers produced a high classification accuracy of 99.12% and the reason for obtaining this high classification accuracy could be attributed to the combination factors of MFA and conditional feature mapping accompanied with cross domain transfer learning. The proposed FAWT + TQWT with ANFIS produced a high classification accuracy of 98.18% and this reason is due to the combined performance of the properties of the versions of the wavelet transform with ANFIS

is widely preferred. To analyze and detect the fatigueness of the driver, many algorithms based on EEG signals have been proposed. In this work, five efficient strategies were proposed and the high classification accu- racy of 99.13% was obtained when the CSD and Lyapunov exponents with multi distance signal level based tangent space mapping and SVM is utilized. The second-best classification accuracy of 99.12% is obtained with the proposed MFA and conditional feature mapping and cross domain transfer learning technique is utilized. The third best classifi- cation accuracy of 98.18% is obtained when the proposed FAWT and TQWT technique is utilized with ANFIS classifier. Future works aim to

classifier. The proposed CSD and Lyapunov exponents with multi dis- tance signal level based TSM with SVM produced the highest classifi- cation accuracy of 99.13% and the reason can be contributed to the nature of the components used in this experiment, that when it was hybrid together a higher classification accuracy was obtained. Finally, when the proposed HHT with Hilbert marginal spectrum and black hole optimization with cascade Adaboost classifier was obtained, a high

This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2022R1A5A8019303) and partly funded by the Ministry of Education (RS-2023-00250246) and partly supported by the Bio&Medical Tech- nology Development Program of the NRF funded by the Korean gov- ernment (MSIT) (No. RS-2023-00223501) and partly supported by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2021-0-02068, Artificial Intelligence Innovation Hub).

