Thus, in this paper, we still adopt soft margin consistency and apply it to semi-supervised problems and then propose the semi- supervised soft margin consistency based multi-view maximum entropy discrimination (SSMVMED). But during the process of SSMVMED, there is a potential trouble when the data sets consist of few labeled instances and many unlabeled ones. As we know, compared with unlabeled instances, labeled ones can provide more useful discriminant information while in real-world applications, most data sets consist of few labeled instances and many unlabeled ones and labeling instances is a high-cost task. Thus, for traditional semi-supervised problems, the performances of learning machines are sensitive to the data sets. In order to enhance the performance of a learning machine, a widely used and feasible method is gener- ating additional unlabeled instances with the original labeled or unlabeled ones and combining all instances together. These addi- tional unlabeled instances will possess some discriminant informa- tion derived from the original labeled and unlabeled instances. Here, Universum learning [28] is such a kind of method. For

But for these Universum-based learning machines, there still exists two key problems. First one is that when generating Univer- sum set, the weights of views and features which play different discriminant roles are always neglected. Second one is that when generating the additional unlabeled instances, traditional Universum-based learning machines only adopt labeled or unla- beled instances for generation. In order to solve the first problem, we adopt weighted multi-view clustering (WMVC) [37] which is a multi-view clustering method and can find the optimal cluster assignment. With WMVC, the weights of views and features can be gotten. For the second problem, we try to design some schemes and adopt both labeled and unlabeled instances to generate the additional unlabeled instances.

SMVMED is different from MVMED and AMVMED due to the margin of SMVMED is soft. SMVMED achieves margin consistency by minimizing the KL-divergence between the posteriors of margin parameters from two views. Then a trade-off parameter balancing large margin and margin consistency is also introduced to make the model more flexible. The model of SMVMED is given below.

(1) Course data set [10] is used to describe web pages and we want to predict whether the given web page is a course page or not; (2) Citeseer and Cora data sets both consist of 4 views and we choose view content and cites here [38]; (3) WebKB data set consists of web pages collected from four universities: Cornell, Texas, Wiscon- sin and Washington which have 5 categories, i.e., student, project, course, stuff and faculty. Data in WebKB are described with two views: content and citation. We treat WebKB in four separate data sets grouped by universities [39]; (4) NewsGroup data set [40] is of six groups extracted from the 20-Newsgroup dataset, i.e., M2, M5,

[45] (paired t-test is different from t-test) and Nemenyi statistical test [46] for quantitative evaluation analysis. Paired t-test is used to analyze if the differences between two compared learning machines on one data set are significant or not. Then for Nemenyi statistical test, it is used to analyze if the differences between two compared learning machines on multiple data sets are significant or not. Nemenyi is different from another famous test, i.e., Fried- man statistical test which is used to analyze if the differences between all compared learning machines on multiple data sets are significant or not. Since the number of compared learning machines here is two, thus we adopt Nemenyi statistical test rather than Friedman statistical test. In generally, the differences always indicate the ones in test accuracy. Thus, here we conduct quantita- tive evaluation analysis in terms of test accuracy.

In order to validate the higher training time, we give the com- putational complexity of them theoretically. As we know, in SSMVMED, it consists of three steps. So here, we will discuss the computational complexities for different steps. For convenience, we let the number of labeled instances be N, the number of original unlabeled instances be L, the number of additional unlabeled instances be U.

Here, we apply SSMVMED to regression problem. The regres- sion problem discussed here aims to estimate full joint distribu- tions from incomplete information which has also been discussed in [44]. In [44], authors proposed generalized cross entropy model (GCEM) and estimated the distribution of Singapore household profile (http://www.singstat.gov.sg) with the joint probability dis- tribution of the household dwelling type (HD), household size (HS) and home ownership (HO) measures. In those experiments, authors conducted the experiments on three different cases: (1) pure entropy with constraints, (2) minimum discrimination infor- mation without constraints, and (3) minimum discrimination information with constraints. Moreover, authors adopted (a) accu- sifier parameter H directly. As we know, the decision always be indirectly in practice. So soft margin consistency based multi- view maximum entropy discrimination (SMVMED) has been pro- posed. Although related experiments have validated the effective- ness of SMVMED, it is only adaptive to supervised problems. Indeed, in real-world, most data sets are semi-supervised, namely, the data sets consist of labeled instances and unlabeled instances. So this paper extends the model of SMVMED to the semi- supervised problems and develop a semi-supervised SMVMED (SSMVMED). Furthermore, in order to get more useful discriminant information, we propose some schemes to generate more addi- tional unlabeled instances. Moreover, these generated additional unlabeled instances will also be used in the model of SSMVMED along with the original labeled and unlabeled instances so that the performance of a learning machine can be boosted. Related experiments on multi-view data sets from different aspects have validated the effectiveness of SSMVMED theoretically and empiri- cally. From the experiments, it is found that (1) compared with

