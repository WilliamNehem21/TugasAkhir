In our earlier research we developed a signal analysis method for nystagmic eye movements investigated in otoneurological tests (Juhola et al., 2009, 2011). For the automatic analysis of such signals poor or invalid nystagmic eye movements should correctly be separated from valid nystagmic eye movements, because valid eye movements can only be used for the data analysis needed for the diagnostics of otoneurological patients. Typically, invalid nystagmic eye movements are cor- rupted by noise or artefacts. Thus, we have also studied the classification of nys- tagmic eye movement candidates into invalid and valid, hereafter called the rejected and accepted, on the basis of machine learning methods (Juhola et al., 2013). We then observed how their complicated distribution made the classifica- tion task difficult and attempted to reduce the greater subset (class) of the rejected eye movement candidates in a learning set, which was performed by cleaning away a part from them. Surprisingly, a simple cleaning process impaired classification results of some of the machine learning methods applied. We realized that the rea- son for such a seemingly conflicting situation originated from the complicated var- iable distribution of the data (Juhola et al., 2013).

In our original cleaning procedure (Juhola et al., 2013) we assumed that there would be two classes in the data having their class centres in different areas. This assumption was reasonable in the sense that the poor nystagmic beat candidates were marked to be rejected (manually or automatically) typically since some of their variable values were above some upper bounds. For instance, segments

After the manual selection of nystagmic beat candidates there were 2171 ac- cepted and 3818 rejected beats. After the automatic selection these numbers were 2517 and 3472, and after using the both ways jointly 1645 and 4344, respectively. Thus, after cleaning, i.e., reducing the larger class of the rejected beats, the num- bers were 2171, 2517 and 1645 for each of the classes in these three situations.

The automatic selection was better in some cases than the manual and auto- matic ones together. Apparently, this stemmed from the fact that manual selection criteria may vary a little from time to time. Instead, the automatic selection always functions stably.

The use of greater nearest neighbour numbers (5, 7, 9 or 11) than 3 originally used improved the classification results slightly further since more elements were cleaned out from the majority class compared to the situation of 3 nearest neigh- bours. However, no such conclusion could be drawn that this phenomenon would typically be present. After all, the properties of data and their distribution are essential.

