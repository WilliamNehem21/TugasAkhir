approached. Generally speaking, frost is the formation of ice crystals on exposed surfaces, either by freezing dew or by phase change from vapor to ice (Blanc et al., 1963). Several other definitions of the phenomenon are described in the literature, such as: a) occurrence of temperature less

such as Multilayer Perceptron (Kalaiarasi and Maheswari 2020; Jamei et al., 2015; Diniz et al., 2021), Support Machine Vector (Xu et al., 2021a; Lu et al., 2019; Zendehboudi and Hosseini 2019), Random For- ests (Ismail et al., 2021; Diedrichs et al., 2018; Noh et al., 2021), Con- volutional Neural Network (Talsma et al., 2022; Wassan et al., 2021).

Due to the numerous existing algorithms, it is natural to inquire which network architecture suits better for frost forecast. Diniz et al., (2021) compared three machine learning classifiers the Random Forest (RF); Support Vector Machine (SVM) and Multi-layer Perceptron (MLP), and concluded that RF is the most efficient algorithm to indicate frost. Similar results were obtained by Noh et al. (2021) while comparing RF to SVM and logistic regression models. On the other hand, in Xu et al. (2021b) and Zendehboudi and Hosseini (2019) the SVM was the scheme that presented better performance when compared to the other algo- rithms. It results that the performance of the network depends on several factors such as: data treatment, variables used and tuning of the 2022) is an operational product that combines observed temperature, an estimated lapse rate and a digital elevation GTOPO30 together with the ECMWF reanalysis data to produce a more accurate spatial temperature product at an spatial resolution of 5 km. SAMeT depicts maximum, minimum and average temperature for the whole South American re- gion. The historical dataset runs back to January 1st, 2000 and is updated daily to the present day, the data is made available at http://ftp. cptec.inpe.br/modelos/tempo/SAMeT.

appropriate in regions of complex terrain. The domain used comprise the whole South America and part of the adjacent oceans. For the pre- sent study, the operational forecasts with spatial resolution of 15 km and 50 vertical levels were used. The initial and lateral boundary conditions come from the Global Forecast System (GFS) analyzes and forecasts, respectively. The Eta model is responsible for providing prognostic meteorological variables used to train, evaluate and test the neural network.

Stage 4 - Back propagation: In this stage, the network training takes place, that is, the interactive adjustments of the weights. Therefore, the weights are adjusted based on the total error (mean squared error). This error is propagated back through the network, starting from the output layer, passing through the hidden layers to the input. The algorithm responsible for training/adjustments is called Back propagation. This algorithm seeks to minimize the quadratic errors from the gradient descent calculation during the iterative process. The generic expression for calculating the gradient and adjusting the weights can be written in a matrix form as: totaling 504 experiments. For these experiments, the hyper- parameters used were the default of each optimizer, that is, ADAM with learning rate and decay of 0.001 and 0.9, respectively, and SGD with learning rate and momentum of 0.010 and 0.0, respectively.

The results were discussed in terms of determining the best ANN topology and hyperparameters for two optimizers (ADAM and SGD). And from this determination, the performance of the perceptron net- works, together with the predictions of the Eta model were evaluated. The inclusion of Eta in the evaluations occurs in order to verify how much the resulting ANNs are able to improve the performance of the regional model with regard to the prediction of frost events.

based on different datasets, methodological approaches, and specific contexts. A study conducted by Fuentes et. all (2018), also addressing frost prediction with an MLP neural network, reached a different conclusion. They found that increasing the number of neurons in the network led to improved performance. This implies that, in their dataset and specific context, a more complex approach with more neurons might be necessary to effectively tackle the frost prediction task. This diver- gence in results underscores the importance of ongoing research and careful consideration of specific conditions in which neural networks are applied. There may be nuances in neural network behavior that depend on data characteristics and prediction objectives. Therefore, while my study favored a simpler approach, the study by Fuentes et al. (2018)

In general, it is evident that ANNs have the ability to substantially mitigate the bias present in the Eta model, a finding also highlighted in studies conducted by Guarnieri et al. (2006). In these studies, re- searchers used predictions generated by the Eta model as input for an MLP-type ANN, aiming to predict solar radiation. In an additional study that adopted a similar approach, but with the WRF model, Lima et al.

POD analysis shows that ANNs had higher values than Eta, with ADAM slightly higher than SGD. It is also noted that the model showed a slight drop in the probability of detecting the event with the increase in the forecast lead time. ADAM and SGD showed a decrease of 4% (vari- ation between 0.80 and 0.76), while Eta 2% (variation between 0.65 and 0.63). The slightly greater drop seen in the ANNs may be associated with the fact that the ANNs were trained only with the 24 h forecast.

In terms of FAR, both ANNs and Eta presented values very close to each other. For 24 h the values were around 0.17, while for 48 and 72 h they were 0.20 and 0.25, respectively, indicating an increase in the number of false alarms with the increase in the forecast period. It is interesting to note that the ANNs, even considerably increasing the POD values, managed to keep the FAR values low, indicating a potential gain in relation to Eta.

The CSI shows that the ANNs presented performances (between 0.59 and 0.68) and were superior by about 10 percent to those of the Eta (between 0.53 and 0.58) for all lead times. Comparisons between the ANNs show that no significant differences were found for all the lead times evaluated. In general, the performance diagram shows that the ANNs were consistently better than the Eta model in all indexes analyzed and for all forecasted times. Among the ANNs, it can be said that the one with the ADAM optimizer indicated slightly superior available on the National Institute for Space Research (INPE) website (http://tempo.cptec.inpe.br/geada/pt). In order to verify whether the ANNs could be a possible substitute for the IG, a comparison between these two different methodologies was carried out. The R2 region, defined in Rozante et al. (2019), coincides with the region of this study, and therefore was used in this comparison.

