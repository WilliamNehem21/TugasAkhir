for recommendation and automation across different applications in wired and wireless networks. Therefore, knowledge can be referred to as intelligence over a network, and having intelligence over a network with different environmental characteristics can be a breakthrough in network performance. For instance, in resource management problems, parameters such as bandwidth, quality of service (QoS), and power can be obtained and processed using an ML algorithm in different network situations. The output of ML is then stored as knowledge for network automation. Moreover, in networking applications, routing decisions can benefit from knowledge for better route discovery while the network is overpopulated. Further, user information, including mo- bility patterns and velocity, can be used as an initial stage to generate knowledge to improve the accuracy of localization and handover.

an autonomous network can manage and optimize network applica- tions without human intervention. In autonomous networks, network information or telemetry is collected and used by ML techniques to automatically troubleshoot, instruct, or manage the network. Hence, monitoring and retrieval of network telemetry data in real time will provide an opportunity for ML-based optimization algorithms to enable intelligence for 6G networks.

KDN, there is no survey that comprehensively studies applications of ML in different layers of wireless networking with their relationship and usage in the KDN architecture. Moreover, there exist some limitations in recent works and the overall challenges in applying KDN, which also need attention for KDN to be fully functional. Furthermore, the benefits of having a KDN in the network are clearly stated in the pro- posed research studies. For instance, the authors of [4,15] investigated the general advantages and use cases of the KP and introduced the KDN switch operator along with its architecture. More concretely, the work in [12] examined deep reinforcement learning (DRL) for QoS- aware routing. The literature in [13] proposed a solution for mitigating data center congestion issues by deploying KDN in the network. Such works demonstrate the benefits of adapting knowledge before making decisions in wireless networks.

A thorough review of the applications of ML within the KDN paradigm is presented, covering resource management, network- ing, mobility management, and localization. This survey focuses on the MAC layer, network layer, and application layer (the PHY layer is outside the scope of this study). To cover every aspect of a wireless network, resource management is broken down into resource allocation, power management, QoS, base station (BS) switching, cache, and backhaul management. Networking appli- cations are further classified into route selection, clustering, user association, traffic classification, and data aggregation. Mobility prediction and handover management lie within the mobility section, and finally, indoor localization.

The data plane in KDN is responsible for forwarding, dropping, processing, and packet modification. This layer works precisely like the data plane in SDN, where it consists of physical and virtual device elements. This layer operates unaware of the rest of the network and relies on the instructions and control rules coming from other planes.

In this section, a brief history of SDN and its enabling standards are presented. Then, complete clarification of P4 against OF and the benefits of P4 over the network are presented. For KDN to be fully functional, data collection is the key, and two powerful tools to do this are OF and P4.Both advantages and disadvantages of these two protocols are stated in this section.

The programming protocol-independent packet processor language is abbreviated as P4. In 2013, the P4 high-level language for pro- grammable protocol-independent packet processors was developed through the collaboration of Barefoot Networks, Intel, Stanford Uni- versity, Princeton University, Google, and Microsoft [5]. P4 enables the programmability of the data plane and allows switches to process the packet. Hence, vendors and enterprises will be able to develop their own application-oriented software for a programmable switch chip, resulting in several benefits to the network, such as reducing the packet processing time, modifiable packet headers, and switch protocol independence. These programmable switch chips are based on a protocol-independent switch architecture (PISA).

Behavioral Model (BM): This is a P4 software switch compiler written in C and C++. The compiler takes a P4 program as an input and then creates a C/C++ program based on the input. The first version of BM is called p4c-behavioral, which depends on a program to generate a high-level intermediate representation of P4 (nicknamed P4-HLIR). P4-HLIR produces a target-independent P4 parser in the Python programming lan- guage, which assists the compiler in developing the correct C code for the intended targets. However, this behavioral version has some issues, such as generating extra codes and recompiling codes every time a modification is made to the P4 program.

Independent Hardware Target : The authors in [45] proposed a target-independent compiler so that it can reduce the complexity of implementation. In their technique, the independent target program is linked to a library called the hardware abstrac- tion library (HAL), where this library is implemented for each target. They separate hardware specifications and hardware- independent functionalities to improve portability. However, their method was only implemented for the Intel platform and the Intel data plane development kit (DPDK). In addition, the performance of the compiler is lower than that of hardware- dependent compilers.

Most of the available P4 programming translators are compilers. However, there exists research for developing interpreters [47], which still needs further attention. Currently, most of the focus is on pro- grammable hardware switches with PISCES that are compiled to a customized software-based POF switch (PVS), where POF stands for protocol oblivious forwarding.

and classification. In regression problems, we try to predict continu- ous value output, and in classification problems, the prediction is for discrete value output. Classification problems are used to distinguish between different things, such as prediction in image processing, to differentiate between a cat and a dog [50]. In contrast, regression problems cannot be considered as a classification problem [51]. The following are the popular survey works on SL techniques:

Logistic Regression: Classification problems are used for logistic regression to assign observations to a discrete set of input classes. For example, the common use of this algorithm is to predict spam emails, student pass or fail grades, fraudulent websites, and so on. This learning algorithm uses the gradient descent method to optimize the solution. In contrast to linear regression, in the logistic regression model, a number between 0 and 1 is assigned to each data point instead of fitting a straight line or hyperplane. The predicted values are the probabilities generated by the sigmoid function. In other words, from the function out- puts, the learning algorithm decides which category the output data belongs. This algorithm has some drawbacks that can also be applied to linear regression. For instance, if the data are perfectly separated, the algorithm can no longer be trained, or interpretation is more difficult because the interpretation uses multiplication rather than addition. However, some advantages make the algorithm interesting, including multiclass classifica- tion and the probability distribution of the data. More details about the logistic regression are found in [52].

In unsupervised learning (UL), the input data are unlabeled data, where the algorithm has to find patterns and hidden structures to learn a useful function. The enormous data collection by devices and sensors results in a lack of labeling due to the unavailability of funds to pay for manual allocation or the nature of the data itself. The UL is extensively used in clustering and data aggregation [56]. The following algorithms are the most common UL techniques: (2) Principal Component Analysis (PCA): This is a statistical proce- dure that transforms a set of correlated variables into a set of linearly uncorrelated variables using orthogonal transforma- tions [55]. The fundamental idea of PCA is to reduce the di- mensionality of the data and optimize it to major components or features. This statistical method represents the datasets in more economical and smaller observed variables for faster data processing in ML. Moreover, PCA works optimally with linear models for feature extraction, data compression, and redundancy of variables, such as image processing, signal processing, com- munications, and control systems/theory [57]. In this algorithm, singular value decomposition (SVD) plays an essential role in computing lower-dimensional data. SVD extracts the eigenvalues from the covariance matrix, which is the best approximation of the original dataset with fewer arguments. For more information on computation and simulation, refer to [55,58].

Joint Utility and Strategy Estimation Based Learning : The util- ity and strategy estimation-based learning relies on the same concept as the classical RL. However, the main difference is that the agent receives an estimation of the expected utility from the environment and the updated reward. The probabil- ity distributions are modified based on the utility estimation, where the probabilities (also known as strategies) are selected actions [70,71]. Using this algorithm, the regret of each action in the process can be obtained using the received reward and utility parameters. Then, regret can be used to update the strategy. The main advantage is that the algorithm can be fully distributed

A neural network is a type of artificial intelligence for information processing that imitates the human brain. The neural network structure consists of thousands of closely connected, simple processing nodes. Neural networks are organized into layers, and in each layer, many nodes move the data. With the development of graphics processing units (GPUs) to accelerate the processing time, NN has attracted con- siderable attention from researchers and companies [72]. The following NN techniques are explained in this study.

Extreme Learning Machine (ELM): The extreme learning machine is an NN with multiple hidden layers with randomly chosen parameters, often referred to as a feed-forward neural network (FFNN). This is the simplest and the first artificial neural net- work, which aims to approximate a function to map an input to an output such as the XOR function. Different layers connect each node to other nodes in the network, including the hidden layer, input, and output layers. The information flows only in one direction, and it does not include any feedback, or the nodes do not form a cycle, differentiating it from the RNN.

assist learning more robustly. For deep learning and RL, knowledge can be defined as weights and Q-values, respectively. For instance, when deep learning is adapted for resource management, the ML process can use the weights that have been trained for other resource management tasks as the initial weight. For example, a similar network with the same number of nodes and similar behavior with a trained ML and a fully operational resource management policy can provide knowledge for other similar networks. Moreover, in RL, the Q-values learned from an environment can be used in a similar environment to make better decisions during the initial stage of learning. The specifications for utilizing TL with RL can be further studied in [77]. While there are advantages of having prior knowledge for learning a pattern, there are some limitations and negative impacts on the performance, which needs further attention that exceeds the scope of this study.

These four criteria are the essential parts of each network, and they need optimization to keep up with standards and demands in future heterogeneous networks. In this section, we discuss recent ML studies in a wireless network. Here, ML-based information is stored as knowledge for that specific network to facilitate other similar networks.

Nowadays, resources among networks are scarce and expensive. Many studies have started to use optimization methods and introduced new ideas for resource management [78]. However, recent studies have utilized ML algorithms to improve the efficiency. These studies focused on spectrum allocation, power management, QoS, BS switching, cache, and backhaul management. Knowledge that KDN provides is beneficial to these standard problems in wireless networks. Once the complex- ity of the network increases in 6G, there needs to be a centralized intelligence that can receive general network information and process that information through an ML algorithm to produce meaningful knowledge. Therefore, it is an excellent opportunity to study research works and identify those with the potential to attain useful knowledge in the KDN framework.

In [80], the authors developed a dynamic spectrum allocation algo- rithm in a distributed manner using a deep multi-user RL. Their method allocates the shared bandwidth into orthogonal channels, and users ac- cess the spectrum at each time slot based on a random-access protocol. First, users attempt to transmit packets with a certain probability. Then,

The authors of [113] used three different methods to minimize the backhaul load by predicting the cache content from raw video data. First, a 3D CNN is used for feature extraction, in which a single frame of the video is analyzed alternatively. Second, the SVM algorithm is utilized for generating represen- tation vectors of videos, and third, a regression model predicts the video popularity content. After obtaining the popularity of videos, the optimal segment of each video is cached by the BS to minimize the backhaul traffic. The proposed algorithm predicts the popularity of a new video without any statistical information. Here, the BS is connected to the core network, where the core network is connected centrally to the content server, which represents a centralized cache strategy.

content at the BS local storage. This method suits the centralized architecture of the KDN to serve users directly with a minimum delay. A more sophisticated strategy was adopted in [119] to perform caching, computing, and networking in a systematic, centralized manner using the SDN controller, which is a close research study to initiate knowledge to accomplish different networking tasks.

An autonomous vehicle or self-driving car can communicate with other vehicles, roadside units, and infrastructure. This ca- pability is known as vehicle-to-vehicle (V2V) and vehicle-to- infrastructure (V2I) communication to exchange essential in- formation, such as speed, location, environmental conditions, etc., to nearby vehicles and the controller. Authors of [138] proposed a delay-bounded routing framework for vehicular ad hoc networks (VANETs). They focused on delivering messages with user-defined delay parameters and minimum usage of the radio spectrum. The delay-bounded routing protocol uses linear regression to predict the traveling distance and available time for forwarding a message. Their algorithm has two schemes, the greedy and centralized schemes, which are both based on linear regression. The greedy strategy predicts the available time by using current sampling data, and the centralized scheme uses global statistical information to choose the optimal path for routing. The simulation results illustrate that the radio usage is greatly reduced. Moreover, the functionality of using both greedy and centralized-based techniques establishes a connec- tion for the hybrid architecture of KDN to enable the installation of routing protocols in VANETs.

In [139], the authors combined two SL classifiers; decision tree learner and rule learner, for routing optimization in a wireless sensor network. They proposed a MetricMap based on MintRoute, which collects the routing protocol to obtain the link quality. MetricMap uses two components, the first component updates the features for the learning strategy when a packet arrives. The second component controls the link classification with input from the features, and the output values indicate the link quality. For their performance measurements, they considered data latency, data delivery rate, and fairness index. From the evaluation of the 30 sensor nodes in the network, the

In [142], a supervised DNN was proposed for routing optimiza- tion in heterogeneous networks to predict the path from the source to the destination node. Each router in the network uses a DNN to predict the next hop; the DNN takes traffic patterns as in- puts, and based on these inputs, it generates the desired output. The output of the deep learning structure significantly improved the network traffic management. There are three phases to ob- tain a fully functional ML. The first phase is the initial phase, where the traditional routing protocols, such as OSPF, provide the network route, and the network starts to operate. At the same time, the second phase is the training phase to train the deep learning system from the collected information based on the traditional operating system. Finally, the running phase is the stage in which the machine is fully trained and can provide real- time routing strategies. This method has been proven to have a higher throughput and lower overhead compared to OSPF. The proposed study suggests a greedy-based distributed architecture over a knowledge-based network to increase the throughput.

The authors of [152] added intelligence to the network to miti- gate the complexity of network topologies. They integrated both centralized and distributed network functionality to guarantee high QoS. Their hybrid approach uses AI routers for distributed intelligence and a network mind for centralized intelligence. AI routers are responsible for hop-by-hop IP routing to ease

Knowledge derived from supervised learning: One of the problems in ML is class imbalance, where the class distributions are highly separated. This means that the total number of minority or scares classes (also known as positive ones) is far less than the majority class (represented as negative) for a two-class scenario. When we apply a traditional classifier in these scenarios, they are likely to predict everything as a majority or negative class. In [161], the authors used logistic regression for imbalanced problems to improve the performance of the learning procedure. The proposed method is called logistic regression for imbalanced learning based on clustering (LRILC). First, K-mean clustering was applied to the dataset to partition the majority class into small clusters. Logistic regression is then used to overcome the class-imbalance problem. The experimental results show a higher accuracy in clustering the dataset compared to state-of- the-art classification methods. The proposed method can be used in a centralized KDN to solve imbalanced problems with large datasets.

Among the challenges associated with IoT, two challenges pose threats to the overall network connectivity, including battery life and the ability of edge devices to communicate over a long distance. One promising technology among low-power wide- area networks (LPWANs) is LoRa, which operates based on spread-spectrum modulation techniques. In [163] ML algorithms were adapted to edge devices to mitigate two challenges: life expectancy and the ability to communicate over long distances. To achieve this, LoRa is used for low-power transmission, and KNN is used for the activity classification process. They have accomplished an amazing low energy expenditure of 5.1 mJ in power consumption for activity classification, resulting in a battery life of 331 days. A similar technique can be deployed to IoT distributed edge devices to increase the device lifetime in a distributed manner.

coordinate their transmissions while reducing energy consump- tion and traffic load. This study formulated the problem as a noncooperative game between clusters, where clusters seek to minimize the cost function to reduce energy consumption. Based on the information regarding the location of SBSs and the capability of handling users and data traffic, the cluster determines their transmission power and on/off situation. The simulation results show improved overall performance when using the cluster-based coordination method in small-cell net- works. The algorithm attempts to reduce the overhead on a centralized controller by allowing the SBS to decide based on their locally acquired information. Hence, this method can be fitted to the distributed architecture of the KDN.

a bias value, and the reward of the system is determined by the BS when calculating the number of outages. The proposed algorithm increases the throughput and decreases the number of disconnected UEs. This algorithm is a greedy-based cell ex- pansion by every UE, which can be used in a distributed KDN architecture.

appropriate BS to create communication links and determine the transmission power. The transmission power of the user is the action of the agent throughout the learning procedure. The reward function is the sum energy efficiency of all the UEs. The objective of the learning algorithm is to maximize the expected accumulated reward under QoS constraints. The convergence of multi-agent DQN was analyzed in the simulation results, and it proved to be superior to traditional RL-based techniques. Moreover, the algorithm maximizes the long-term overall network performance and demonstrates efficient energy consumption. The distributed method above shows a solid con- nection to the distributed KDN architecture. Chou et al. used DRL to jointly solve user association and resource management problems in mobile edge computing (MEC) to improve the QoE for online video streaming in 5G networks [176]. The problem is formulated based on the Markov decision process (MDP) and analyzed by a deep deterministic policy gradient (DDPG) algo- rithm based on the supply demand interpretation of the Lagrange dual problems. First, they used the traditional optimization La- grangian approach, where the source of the performance loss in this algorithm was identified as the Lagrangian multiplier update

Knowledge derived from transfer learning : To avoid training data from scratch, researchers in [182] method to address multi- class traffic classification problems, and they utilized Maxent as the base classifier in their approach. A new classification task in TrAdaBoost was used to extract labeled data from several network traffic sources. Next, the Maxent model is used to classify and convey traffic knowledge from the source domain to the target domain. The proposed scheme was trained and transferred as prior knowledge for different environments to reveal its performance. They tested their method with two tra- ditional ML algorithms based on Maxnet, known as NoTL and NoTL advance, where TrAdaBoost achieves better performance compared to the other two methods. Their learning algorithm can achieve high accuracy in classifying network data traffic and provide a promising solution for centralized KDN architecture.

of users and their activities can help generate intelligence to increase network performance. Recently, there have been many advancements in mobility prediction and handover management in the field of ML. In the following sections, some ML techniques for the two essential components of mobility management are presented.

Knowledge derived from supervised learning : In [209], the authors presented a feature-scaling-based KNN (FS-KNN) to improve the localization accuracy. The algorithm depends on the measured RSS reported by the MS, which accounts for the actual relation- ship between the signal differences and geometrical distances. To obtain the parameters of the weight function, iterative train- ing was established to tune the parameters. After training the model, the algorithm finds the optimal values corresponding to the actual distance between a newly received RSS vector and each fingerprint. Then, the user location with an average error as low as 1.70 m is determined by solving a weight mean of locations based on K nearest reference points. This algorithm has two phases, which train the system in the offline phase and use it for online location estimation. The offline trained algorithm can authors of [210] proposed an online independent support vector machine (OISVM) for indoor localization that avoids training from scratch. Their model uses the RSS of WiFi signals to make online predictions and facilitate mobile devices. The proposed model includes two phases: offline and online. The algorithms learn through pre-collected RSS with reference point (RP) labels appended to the corresponding RSS during the offline phase. The offline phase also incorporates kernel parameter selection and data sampling to deal with the imbalanced dispersion of the data samples. In the online phase, new RSS samples are collected by a centralized local AP for online learning and to estimate the location. Compared to traditional SVM methods, their method can balance the accuracy of localization and model size. From the simulation results, the location estimation error decreased by 0.8 m, while the training phase time and period were re- duced considerably compared to the traditional techniques. The proposed technique can be used via a distributed architecture of KDN.

Different training data are collected or generated for supervised, unsupervised, and reinforcement learning, depending on the character- istics of the problem. For instance, in spectrum allocation problems, the authors of [82,83] used non-cooperative game methods where the data were trained based on the collected information from the primary and secondary users. In [86] the same non-cooperative spectrum allocation is modeled with the difference where the data is collected using an RNN model at each BS; here, BSs continuously interact with each other to collect training data. Other authors of [84] used joint utility and strategy estimation-based learning to collect D2D information and gen- erate training data. In power allocation, when the SL method is used, such as in [89,229,230], the authors aim to adapt a neural network to approximate power allocation in a complex environment, including the genetic and WMMSE algorithms. Using these algorithms enables these studies to generate training data under different network scenarios that can later be used in KPs as knowledge. Obtaining appropriate raw data is important for researchers on the same topics. For example, in cache problems, the authors used different datasets for cache management to

In networking scenarios, specifically in routing problems, the col- lected dataset is usually obtained from a simulator. For instance, in [137], the authors implemented a neural network using the Om- net++ simulator for traffic engineering. In this study, the SDN con- troller collects traffic flow reports from the nodes in the networks and separates different features to feed the SL algorithm. In [142], the authors investigated DNN-based routing to solve dynamic routing problems. The training dataset collects traffic patterns and paths that a packet will undertake to reach the destination in the proposed study. The routing paths were obtained using the traditional OSPF strategy from a software simulator. In other studies, such as in [141], the dataset was generated in real-time through online fashion with routers in the network for intelligent route selection.

In RL, the learning algorithm continuously updates itself through interaction with the environment. In these problems, the learning agent takes action in a particular state. Then, it receives a reward from the en- vironment, where the environment is created as a virtual environment by specific software, such as NS3, Matlab. For example, in spectrum management, researchers in [84] optimized the spectrum usage from reward feedback for each D2D pair. In power management, the authors of [105] used the reward as the difference between the maximum total power consumption and the current total power consumption to perform BS switching on/off to minimize the overall network power consumption.

Techniques for deploy regression or classification: For these two techniques, SVM, KNN, and NN are mostly used [111,112,140, 193,194]. SVM is the most robust prediction method for binary classification with low complexity [113]. At the same time, KNN is a multiclass classifier, mostly known for its simplicity of implementation. In problems where the dataset is not linearly separable, KNN is a better classifier than SVM. In the KNN approach, only the distance metric and K parameter must be selected, whereas in SVM, the regularization and kernel param- eters must be chosen carefully. Although these two algorithms are simple compared to neural networks, NN is more robust in feature extraction and improves overall network performance. For instance, a DNN can handle large datasets and achieve

Techniques for deploy clustering: ML models applied to clustering mainly include K-mean clustering. However, there are other supervised and NN studies deployed to clustering problems. K- mean clustering is one of the most popular and simplest methods for clustering data. Generally, the K-mean is used to differentiate between groups with similar data points and patterns. Neural networks are also used to organize the input data. For instance, given a set of images, the NN can organize and provide images with similar content. This process does not provide clusters, but it creates meaningful representations of the dataset, which can be used for clustering. The main difference between these two algorithms is the complexity of implementation. Moreover, in K-mean clustering, the number of cluster centroids (K value) is essential; however, in NN, the design of the hidden layers and other factors must be considered.

After summarizing the terms and conditions associated with ML algorithms, we need to investigate the motivations for applying the appropriate ML algorithm to KDN-based networks. It is essential to ex- amine the reasons and motivations for adapting KDN-based approaches to wireless networks. The subsections below provide the reasons for applying ML and knowledge to the network based on the literature surveyed throughout this study.

Traditional optimization algorithms can only work for deterministic networks, which have certain characteristics. These algorithms are not practical in current real-life network scenarios, as the network traffic changes every day. In contrast, ML is the capability of machines to learn how to respond to any specific situation. Hence, they are more reliable than traditional algorithms owing to their flexibility and adaptation to new environments. In [80], DRL was utilized for spectrum allocation and was able to provide twice the channel throughput when compared to slotted-aloha with optimal probability. In [89], an SL algorithm was developed to train a DNN for power management, and it was shown to be superior to a state-of-the-art interference management algorithm. In cache management, the authors of [115] used the RL algorithm for content caching at the BS and compared it with two traditional cache update schemes, namely LRU and LFU, where it shows a better long-term cache hit rate. Moreover, in [173], the RL-based algorithm for user association performs much better than traditional dual-decomposition-based approaches. Overall, ML techniques have the potential to provide superior performance to traditional optimization algorithms. Other surveyed works for this motivation are as follows [92, 109,115,121,169,173,219,230].

One of the important reasons and motivations for using ML al- gorithms is their ability to handle complex problems and datasets. The authors of [86] trained a multi-agent RL-based with ESN for efficient spectrum allocation and load balancing in LTE-U networks. Other researchers in [168] used CNN to achieve a low-complexity and high-accuracy clustering algorithm to classify three different types of waveforms in wireless communication systems. Moreover, the ability to handle high-complexity problems is the main reason why authors use RL. For example, for the on/off sleep mode control of small cells, the authors of [103] used distributed Q-learning to decide on the sleep mode of each BS, which led to a low-complexity sleep-mode control algorithm. Overall, the motivation for providing a low-complexity so- lution for the KDN paradigm can be seen in the literature [12,79,118, 152,167,194,211,216,219].

One of the crucial aspects in 6G wireless networks is intelligence, and many research studies are now focusing on exploring how knowl- edge and intelligence can be integrated into wireless networks. This survey paper investigated the concept of knowledge-defined network- ing, which aims to combine SDN and ML/AI to create a programmable and knowledge-aware networking architecture. We first introduced emerging technologies to facilitate KDN, specifically the SDN paradigm, network telemetry, and ML algorithms. We then investigated most of the widespread applications of wireless networks. The reviewed studies in network applications were based on the most recent ML-based approached to create automated applications in KDN-based wireless networks. The applications were categorized into the MAC layer, Net- work layer, and Application layer. Resource management problems were distributed within the MAC layer and classified as spectrum allocation, power management, QoS, BS switching, cache, and back- haul management. Networking and mobility management problems were investigated in the network layer. Networking problems were described as routing strategies, clustering, user/BS association, traffic classification, and data aggregation. Mobility prediction and handover management were considered in mobility management. Then, from

Sepehr Ashtari (Graduate Student Member, IEEE) received the B.S. degree in electrical and electronic engineering from Eastern Mediterranean University (EMU), North Cyprus, Turkey, in 2016 and the M.S. degree in telecommunica- tion engineering from the University of New South Wales (UNSW), Sydney, Australia, in 2019. He is currently pursu- ing the Ph.D. degree in telecommunication and information technology at the University of Technology (UTS), Sydney, Australia.

From 2015 to 2016, he was a Research Assistant with the Department of Electrical and Electronic Engineering, North Cyprus, Turkey. He has worked as a research fellow at the Commonwealth Scientific and Industrial Research Organisation (CSIRO) on several wireless communication projects. His research interest includes improvement of wireless cellular communication, routing protocols, software or knowledge-based networking, 5G resource allocation, and machine learning optimization in wireless networks.

Mehran Abolhasan (Senior Member, IEEE) is currently an Associate Professor and the Deputy Head of the School of Electrical and Data Engineering, University of Technology Sydney. He has over 20 years of experience in research and development and serving in research leadership roles. Some of these previous roles include serving as the Director of research programs for the Faculty of Engineering and IT, and the Laboratory Director for the Telecommunication and IT Research Institute, University of Wollongong. He has authored over 160 international publications and has won over four million dollars in research funding. He won a number of major research project grants, including the ARC Discovery Project, ARC Linkage Project, and a number of CRC and other government and industry-based grants. He currently leads the Software-Defined Networks Lab at UTS and his current research interests include software defined networking, the IoT, wireless mesh, wireless body area networks, cooperative networks, 5G networks and beyond, and sensor networks.

