In this paper we combine object segmentation with low-level features in order to propose a higher level of description in terms of semantic primitives. The visual content of a shot is summarized on-the-fly into key frames, such that each one represents a new event. The first frame of the shot is automatically selected as key frame. Then, each received frame is segmented into salient objects, and a position-based criterion is combined with a shape-based one to reject irrelevant objects. Next, many-to-many correspondence between objects of the current frame and those extracted in previous key frames allows to decide if the current frame corresponds to a new event. The main contribution of the proposed method is the summarization on-the-fly of a shot while extracting key frames illustrating relevant events. Many tests on standard videos showed that the proposed method is able to preserve the overall content of a shot with minimum data, even when the camera returns to parts of the scene already visited before. Next section describes the proposed method and experimental results are presented in section 3 to prove objectively the effectiveness of the method using standard metrics.

The proposed method for key frames extraction is mainly based on shot boundary detection and object- based event detection. In fact, after partitioning the input video into shots [2], key frames are selected on-the- fly from each shot while looking for important events corresponding to the appearance and the disappearance of significant objects. For that purpose, the first frame F1 in each input shot is automatically considered as key frame KF1 and is also segmented into salient objects using a fuzzy coarse region segmentation technique [1].

KF1, while giving priority to recent key frames (initially, ref=j=Card()). Thus, Ft is considered as key frame only if some objects are totally added to, or removed from, the scene in this frame (2). In addition to the implicit integration of the temporal behavior with the visual appearance of salient objects, the comparison of each frame with the already selected key frames avoids the consideration of the temporally appearance or disappearance of objects as new events. In particular, the given priority to recent key frames allows the detection of the repetitive events without testing a huge set of frames. Besides, the many-to-many assignment avoids the consideration of occlusion effects as new events, what minimizes the redundancy of the final key frames. Once the decision is performed for Ft, the same object-based event detection procedure is applied on- the-fly for the next received frame Ft+1 and so on until the end of the shot. We note that from the second shot, each frame Ft, including the first one of the shot, must be compared not only to the key frames already extracted from this shot but also to those selected within all precedent shots.

