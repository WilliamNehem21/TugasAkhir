Novelty detection is an important field of research as identifying previously unknown behaviours in systems is critical for their main- tenance and smooth operation. It is the procedure in which a model is able to identify new classes of data that it has not been exposed to before. Novelty detection is a far-reaching topic having been applied extensively in fields such as manufacturing [1], cyber-security [2], biomedical analysis [3,4], astronomy [5] and many more [6].

or outlying samples. Then, during inference, the AE is exposed to novel samples which result in higher errors thus enabling novelty detection. Methods such as mean-square-error (MSE) [22], residual error [3], structural-similarity (SSIM) [26] or feature consistency [27] are used to calculate the pixel-wise difference.

A common problem with using autoencoding methods for novelty detection is that AEs can generalise to unseen classes thereby perform- ing poorly as novelty detectors [28]. In [9], this issue is addressed by placing a classifier in the training path of a multi-discriminator based autoencoder, which results in a fairly complicated and costly training procedure. On the contrary, we propose the Nearest-Latent- Neighbours (NLN) algorithm which uses the reconstructions of the nearest-neighbours in the latent space of autoencoders in-order to combat the aforementioned generalisation problem.

A critical distinction among all related work is whether supervised, semi-supervised, or unsupervised methods have been used [31]. Su- pervised methods typically relate more strongly to anomaly detection scenarios, where both the normal and anomalous data classes are known a-priori [13]. However, supervision is not applicable in many settings, as anomalous classes are either underrepresented or just not known [13]. In the unsupervised setup, we have no a-priori information if the available data contains normal or abnormal samples [31].

Semi-supervised methods are the most common in practice, as nor- mal (non-anomalous, non-novel) data is most easily collected from most systems [6]. In this case, models are designed to represent the expected operating conditions of a system and any deviations from that are considered novel. These deviations may, in some cases, be considered anomalous, however this is dependent on the context of operation [7]. For the remainder of the paper we focus on semi-supervised methods, where we designate particular classes of a dataset as novel and all other as expected.

It has been demonstrated that reconstruction-error based meth- ods alone are not particularly robust to noise, changing backgrounds and viewing angles [7]. In generative autoencoding models such as VAEs, reconstruction probability or attention-mechanisms are used to improve performance [21,25,34]. Furthermore Generative Adver- sarial Networks (GANs) [35] are used for reconstruction-error based anomaly detection [3,36,37]. Here the residual error is calculated as the difference between the training and generated images using their intermediate representations provided by the discriminator. More re- cently, self-supervised learning (SSL) has been applied to AEs and offers improved performance in novelty detection by using in-painting [23] or position prediction [38] pretext tasks.

For multi-class novelty detection, multiple classes are considered inliers and a single class is considered novel [8,20,27,36]. This is an inherently more challenging evaluation framework as the model should be able to generalise to multiple classes and still be capa- ble of detecting novel samples. In this work we evaluate our NLN- enabled models in both a Multiple-Inlier-Single-Outlier (MISO) and Single-Inlier-Multiple-Outlier (SIMO) contexts as defined by [30].

In [9,28] the generalisation problem of autoencoders when used for one-class novelty detection is described. They show that when an AE is trained on the relatively complex 8-class from the MNIST dataset [46], the AE is able to implicitly learn the representations of digit classes such as the 1, 3, 6 and 7. In effect, reconstruction-based novelty detectors are prone to misidentify these implicitly learnt classes.

In order to evaluate our work across a number of different datasets we adapt our models accordingly. We adopt autoencoding the architec- ture specified in [24] for the evaluation of the NLN algorithm on the MVTec-AD dataset. For MNIST, CIFAR-10 and F-MNIST we modify a LeNet [56] based autoencoding architecture. The encoder consists of 3 is not the case for the texture classes. We suspect that this is due to our NLN-enabled AE not being able to distinguish between different texture-patches. This behaviour is similarly demonstrated in [24], and we believe that this is an inherent weakness of standard autoencoding architectures.

