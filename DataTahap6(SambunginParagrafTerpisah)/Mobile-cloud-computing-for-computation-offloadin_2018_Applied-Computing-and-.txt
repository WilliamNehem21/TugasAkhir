Recently, user preferences for computing have changed because of the latest developments and enhancements in mobile computing technologies. Several reports and studies have presented the importance of MCC and its impact on mobile clients and enterprises. For instance, and according to a recent study by ABI Research, more than 240 million busi- ness will use cloud services through mobile devices by 2015 and this will push the revenue of the MCC to $5.2 billion [11]. Moreover, the usage of smartphones has increased rapidly in various domains, including enterprise, management of infor- mation systems, gaming, e-learning, entertainment, gaming, and health care. Although the predictions that mobile devices will be dominating the future computing devices, mobile devices along with their applications are still restricted by some limitations such as the battery life, processor potential, and the memory capacity of the SMDs [31]. Nowadays, modern mobile devices have sufficient resources such as fast proces- sors, large memory, and sharp screens. However, it is still

This paper is organized as follows: Section 2 explains the essential background concepts and terminology, including CC, the MCC concept, and computation offloading. Section 3 presents the offloading approaches. A comparison between the different offloading frameworks and their critical issues is dis- cussed in Section 4. Section 5 highlights general issues and challenges in computation offloading for MCC. Finally, Sec- tion 6 gives a summary and points to future work.

(1) enormous computing resources available on demand, (2) payment for use as needed and on a short-term basis (storage by the day and release them as needed), and (3) simplified IT management and maintenance capabilities [1]. CC provides cli- ents with different applications as services via the Internet. As examples of public CC we can list Windows Azure and Ama- zon Web Services (AWS). Windows Azure is an open and flex- ible cloud platform which provides several services to develop,

deploy and run web applications and services in cloud data centers [33]. AWS, which is considered as an example of a pub- lic computing tool, provides users with two models: infrastruc- ture as a service and software as a service. These services allow the user to use virtualized resources in cloud data centers [23]. Computational clouds implement a variety of service models in order to use them in different computing visions [4].

The first step is application partitioning which is very impor- tant for computation offloading. It divides the application into offloadable and non-offloadable components meaning which components to retain on the mobile device and which to migrate to the cloud server. The decision whether a component is offloadable can be taken based on different information. The programmer can annotate application components for exam- ple through a special API as offloadable. Compute intensive parts that are candidates for offloading can be identified also by source code analysis in combination with performance pre- diction or via application profiling. If the partitioning is done at design time, both techniques have a limited accuracy since they do not take the real execution context into account, when the application is run.

The offloading decision is the final step before remote execu- tion is started for offloadable components. Whether an installed remote component is used in the SMD application or not depends typically on the execution context. If the deci- sion is taken at runtime, more precise information is available, for example, the SMD might even not have a wireless connec- tion or the energy consumption for transferring the data for the remote execution might simply be too high. Whenever the situation changes, the offloading can be adapted. Such a runtime decision induces some overhead that typically is not present if the decision is taken at design time.

According to when the decision is taken to offload computation on a remote server, we can distinguish two types of offloading frameworks. The first class is static offloading frameworks. Here all the presented steps are performed at design time, before the application is started on the mobile device. The other classes are dynamic offloading frameworks. In those frame- works, at least the final decision whether to offload a computa- tion is taken at runtime. The other two steps can be executed at design or runtime. For example, a framework that is based on user annotations of offloadable components and on pre- installation of the components on a remote server will be called a dynamic offloading framework, if it decides at runtime whether it is better to offload computation or not.

This section introduces different existing offloading frame- works. For each of the frameworks we identify the approaches used in the three steps introduced in the previous section. At the end of the section, the different frameworks will be com- pared with respect to their most important properties.

The partitioning step in this framework combines static program analysis with program profiling to produce a set of offloadable components while meeting some constraints, such as methods that use mobile sensors should be executed locally. The framework uses thread level granularity for partitioning of applications. The role of static analysis is to discover con- straints on possible migration points while profiling aims to build a cost model for offloading and execution. Partitioning and integration of the applications are performed at the appli- cation level.

reachable heap objects, and then resumed. On the cloud server, when the migrated thread reaches a re-integration point, it is suspended, packaged, and then shipped back to the mobile device. Finally, the received packaged thread is merged into the state of the original process in the mobile device.

MAUI [8] is a framework that considers energy saving on smartphones as the main objective function for the offloading process. MAUI is a highly dynamic offloading framework because of a continuous profiling process. The framework hides the complexity of a remote execution from the mobile user and gives the impression as if the entire application is being executed on the mobile device.

The authors presents different experiments in order to com- pare the energy consumption of running three applications(- face recognition, chess, and video) standalone on the smartphone versus using MAUI for remote execution to ser- vers that are located elsewhere. The face recognition applica- tion can achieve strong energy savings when using MAUI. On the one hand, the results of the conducted experiments showed that the energy consumed when offloading code using 3G is 2.5 times higher than offloading code to a close server. On the other hand, the energy savings for both video and chess game are less strong but they are still important; when offload- ing to a close server, MAUI saves 45% for chess and 27% energy for the video game.

Satyanarayanan et al. suggest in [29] a VM based cloudlet framework. A cloudlet can be defined as a hosting environ- ment for offloaded tasks that is deployed to remote resources, as different as individual servers or parallel systems. Cloudlets are virtual-machine (VM) based on support scalability, mobil- ity, and elasticity. They are located in single-hop nearness to mobile devices.

to the cloudlet) are used by the mobile client to specify the suit- able cloudlet for computation offloading. Once the cloudlet is determined for offload, the mobile client sends the application code and the application metadata to the cloudlet server. The cloudlet server deploys the application code in the guest VM. Once the deployment is done, the execution of the application is launched.

We can take a scenario where the user must execute a com- putation intensive application. At runtime, the application dis- covers a nearby cloudlet and offloads the computation intensive mobile application [15]. However, because of loss of network connectivity, the mobile application can find a dif- ferent cloudlet and run the application in a short time.

Sharing the same concern but from a different perspective, Qian et al. present in [28] a system that monitors application and device status and that automatically decides where the code should be executed. The goal of Jade was to maximize the benefits of energy-aware computation offloading for mobile applications while minimizing the burden on develop- ers to build such an application.

Profiling: In order to make correct offloading decisions, the framework should have updated information concerning the status of the application and the device. Application profiling is the process of collecting information about pro- grams, such as energy consumption, data size, execution time, and memory usage. Similarly, device profiling collects information about devices status, such as battery level, CPU usage, and wireless connection.

In order to check the amount of energy that Jade can save for mobile device, authors run face detection application on a mobile device. The application performs face detection on 50 pictures with size of each less than 200 KB. Results showed that Jade reduces the power consumption for face detection application. Average power consumption was decreased by 34%.

Zhao et al. present in [38] the mirror server framework that uses Telecommunication Service Provider (TSP) based remote services. A TSP is a type of communication service provider which provides voice communication services such as landline telephone services. Mirror server extends capabilities of smart- phones by providing three different types of services: computa- tion offloading, security, and storage. Mirror server is a powerful server which retains VM templates for different mobile device platforms.

In the preparation step, a new VM instance is created. This VM is called mobile mirror and the mirror server takes care of managing and deploying the mobile mirrors on a computing infrastructure in the telecom network. Applications are exe- cuted in the mirror VM instances and results are returned to the SMD. The framework employs an optimized mechanism for offloading.

Cuckoo is a dynamic offloading framework as it takes the offloading decision at runtime and offloads the well-defined components of the application. In case the remote resources are not reachable (i.e. network connection is not available) then the application can be executed on local resources (the mobile device).

The framework can offload the whole or part of an applica- tion to a cloud server. The prototype of Phone2Cloud is imple- mented for Android and Hadoop environment (to serve as a cloud). It consists of several components, including an offload- ing decision engine, a local execution manager, a bandwidth monitor, a resource monitor, an execution time predictor, a remote execution manager, and an offloading proxy that links the offloading decision engine to remote execution manager.

For instance, face finder application costs more energy on smartphone than on a cloud server and the difference between the two costs gets bigger as input grows. The reason behind this is because data transmission costs less energy than running the application locally. Moreover, the energy consumption in smartphones grows faster than that on the cloud server. Thus, face finder application should be offloaded to cloud.

Annotation is one of the important attributes in partition- ing step. It can be seen as a metadata added to the source code. The current partitioning algorithms used in the offloading frameworks can be categorized as (a) automatic and (b) manual.

It can be seen from the presented frameworks that they use different approaches to offload intensive tasks to remote cloud servers. However, none of them use or adopt containers tech- nology such as Linux Containers (LXC). LXC is attracting researchers these days as a lightweight alternative to full machine virtualization such as the common known hypervisors such as KVM or Xen. Recently, research suggests that applica- tions running in containers can achieve approximately same speed in memory, processing and also network throughput as if they were running on a physical machine [41]. LXC is con- sidered as an OS level virtualization where each container has its own environment called a namespace where specific pro- cesses are running and isolated from the rest of the system. The usage of containers instead of VM will be a good idea since it is lighter than VM.

One of the challenges in the current computation offloading frameworks is the diversity and heterogeneity of smartphone architectures and operating systems. This diversity is seen in the following example: MAUI [8] is an offloading framework which is applicable for the .Net framework whereas Mirror Server [38] is a framework which is compatible with the Android platform. A consistent access to cloud services is expected wherein SMDs are enabled to access cloud comput- ing services regardless of the installed operating system or the used hardware. A standardized offloading framework for different smartphone platforms is still a challenging issue in the MCC field.

In [39], the authors focus on optimizing tasks and compu- tations, and they explore secure offloading of applicable linear programming (LP) computations. In this paper, authors build their work based on the decomposition of the LP computation offloading into public LP solvers running on the cloud and pri- vate LP parameters owned by the customer. To achieve an effi- cient and validate results, the authors focus on the fundamental duality theorem of LP computation and come up with the essential conditions that must satisfied by correct results. Bugiel et al. present in [40] an architecture for secure outsourcing of data and arbitrary computations to an untrusted commodity cloud. The architecture proposed in their approach consists of two clouds (twins): a trusted cloud and a commodity cloud.

The security threat is advancing in a quick manner more than we can keep up with it. Security techniques need to enhance and progress constantly to meet new changes and new offered services. Thus, it is no longer possible to define a security system that would solve all the security threats at once.

The available computation offloading frameworks still need to be automated. This will help the offloading process to be per- formed in a seamless fashion while discovering the surrounded environment [5,9,14]. The achievement of such automation is not an easy task as it needs the implementation of a protocol dedicated to finding and discovering services depending on the current context and its constraints.

(2) mobile cloud computing, and (3) computation offloading. More specifically, it presents existing frameworks for computa- tion offloading along with the various techniques used to enhance the capabilities of smartphone devices based on the available cloud resources. The paper investigates the different issues in current offloading frameworks and highlights chal- lenges that still obstruct these frameworks in MCC. Moreover, the paper shows the different approaches that are used by the frameworks to achieve offloading. Some of these approaches use static offloading while others employ dynamic offloading. Even though there exist a variety of approaches, all of them target the same objective which is the improvement of the smartphone device capabilities by saving energy, reducing response time, or minimizing the execution cost.

We notice that current offloading frameworks are still fac- ing some challenges and difficulties. For instance, lack of stan- dard architectures. This shortage leads to more complications while developing and managing a proposed framework. Finally, it is important to come up with a lightweight paradigm or model that will help to overcome the difficulties and mini- mizing efforts while developing, deploying, and managing an offloading framework.

