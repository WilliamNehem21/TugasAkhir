the discontinuity of characteristic distribution (e.g., pixel grayscale and texture) in an image. It is a collection of pixels with step changes in the image. As one of the primary image features, image edge detection is mainly used to enhance the contour edges, details and grayscale jumps in an image.

step, the end-to-end method is used to obtain salient objects; in the second step, the contours are extracted based on gradient information of salient objects. However, this method with two steps is complicated in computation. At the same time, the error is expanded, including the salient object extraction error and the contour extraction error with gradient information. In the deep category-aware semantic edge detection network (CASENet) [15], each contour pixel is associated with more than one category. The pixels appear in contours or junctions belonging to two or more semantic categories. A saliency detection method based on salient contour-aware with twice learning strategy is proposed in [16], but it cannot always extract saliency contours accurately. Liu et al. [17] presented a simultaneous detection method of salient object, edge, and skeleton using the dynamic feature inte- gration (DFI) and the task-adaptive attention module. It produces most important edges in the image, but it cannot distinguish object contours exactly.

The remainders of this paper are organized as follows. Section 2 introduces related works of contour extraction and the basic network structure. The principle of the salient object contour extraction are described in Section 3. Section 4 demonstrates the effectiveness of the proposed method. At last, the conclusion and future works are stated in Section 5.

Multi-task hierarchical network: In the network of HED, the loss generated by multiple side-outputs is directly conveyed back to the corresponding convolutional layer, avoiding the gradient disappear- ance. At the same time, different scales of features are learned at different convolutional layers. Based on the idea of side-outputs, the RCF makes full use of multi-scale and multi-level information of the object, and completes image-to-image prediction by fusing all mean- ingful convolutional features. The FSDS classifies image pixels to five categories according to the size of the skeleton scale; different stages of network structure have different perception fields; and different perception fields can supervise different skeleton pixel categories. In the network of learning multi-task deep side outputs (LMDS) [19], some regression tasks are added to the FSDS network structure to predict pixel scales. The hierarchical feature integration network (Hi- Fi) [27] can further extract richer features and promote the recognition accuracy. Therefore, a new hierarchical network is designed for salient object contour extraction in this paper.

In order to extract object contour pixels in convolutional neural network, the image pixels confront with classification problems. The pixel scales are classified by piecewise quantization. The number of categories depends on the sizes of receptive fields in the network structure. For example, from the first stage to the fifth stage of the VGG16, as the extracted features become more and more abstract, the

In experiment procedures, firstly, the contour maps are generated based on the trained models. Then, the refined contours are obtained by the standard non-maximum suppression algorithm [29]. Finally, the refined contour maps are evaluated by PR curves and F-measures. In addition, the performance of the proposed algorithm is verified through comparative experiments on three datasets, and the generalization ability of the new algorithm is proved by cross validation.

The contour extraction accuracy results of several different network structures are compared in detail. Generally, the VGG16-based hierar- chical network maximally has four levels. In the experiments of contour extraction, the methods of different levels are named as Ours1, Ours2, and Ours3. It is verified that for the proposed method, when the level exceeds 2, the accuracy will be reduced, so the Ours3 is adopted at

In the future work, the new approach will be extendedly optimized in two possible manners. Firstly, a more effective network structure can be designed for object recognition. Secondly, multi-regressive aiding tasks like classification tasks can be merged into the network, which are not appeared in existing methods. After the fusion step, the regression data can be used to estimate more accurate inscribed circle radiuses between the contour and the skeleton. Finally, the contours are limited to five categories, which reduces the contour accuracy, so better results may be generated by increasing scale categories.

