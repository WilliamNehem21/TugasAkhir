In this study, several image processing methods are used to pre- process dragon real-time images. After segmentation, thirteen features are extracted. ANOVA and LASSO are also used to rank features based on mutual scores. Six machine learning classifiers namely, Decision Tree, Random Forest, KNN, AdaBoost, Logistic Regression, and SVM were applied to the top-ranked feature sets and evaluated using seven performance measures to assess their efficacy. A comparison of two feature selection techniques based on performance results is included to analyze the best feature selection technique adopted for dragon disease recognition. Finally, the computational cost is also estimated in order to find the significance of feature sets. The main contribution of our research is as follows:

This paper is organized into five sections. A brief introduction is mentioned in Section 1 and a literature review is discussed in Section 2. In Section 3 proposed method and material are described. The experi- mental results and evaluation of the proposed model and a comparative analysis and model validation have been analyzed in Section 4. The paper is concluded with the outcome of the study, limitation, and future work in Section 5.

Dragon fruit is currently known as a healthy fruit all over the world. Many people are encouraged to plant dragon fruit, however, due to improper diagnosis, they are faced with losses. As a result, researchers are attempting to solve the problem using artificial intelligence and have also provided their proposed analysis.

L. Hakim et al. [6] presented a method for classifying dragon fruit based on their appearance (color and texture) using machine learning. They worked with three unique classes, totaling 81 images. The classification result was tested using two classic machine learning

B. Doh et al. [10] suggested a technique for disease identification in citrus fruits based on computer vision and machine learning. The dataset used in this study was not specified; nonetheless, the proposed study focused on categorizing six different types of citrus fruit. K- means clustering was employed for image segmentation. In addition, SVM and ANN were integrated into the image classification process. In comparison, the ANN model achieved an image classification accuracy of 93.12%, while the SVM model had an accuracy of 88.96%.

Local Binary patterns and Global color histograms are two color fea- tures used to classify papaya disease [12]. They obtained a dataset from the Mendeley database, which contains 214 images of five different types of papaya. In this work, they used k-means clustering for image segmentation and a support vector machine for categorizing the papaya classes with 96.3% accuracy.

A hybrid machine-learning technique has been introduced by A.B. Mustafa et al. [14] to diagnose plant bacterial and fungal diseases. They conducted their research based on 500 samples with 3 classes namely fungal, bacterial, and healthy. The images were identified using KNN, SGD, and Random Forest. CNN-KNN and CNN-RF achieved 92.4% and 87.4% accuracy, respectively, while CNN-SGD achieved 93.6%.

W. N. Syazwani et al. [15] utilized contrast-limited adaptive en- hancement to enhance the captured images. The researchers engaged in a study of three distinct feature extraction, namely color, texture, and shape. Additionally, the researchers employed the analysis of variance (ANOVA) feature selection approach to identify the most significant feature. And finally, six different machine learning algorithms are applied to classify the fruit crown and non-fruit crown. However, their combined ANN-GDX model outperformed with an accuracy rate of 94.4%.

There are several processes for classifying dragon fruit diseases, which are divided into numerous sections. Our first step was to collect the image from the field. Secondly, we need to preprocess the data be- fore conducting this research. In addition, utilizing GLCM and statistical feature extraction, we also extracted 13 individual features from an image. ANOVA and LASO are two separate feature selection strategies used to determine the mutual score of each feature. Following the con- clusion of the feature selection process, the top 10 features were chosen

Typically, images are stored as massive matrices containing the values of individual pixels. It might be challenging for machine learning algorithms to learn from such large amounts of data. Feature extraction is the process of choosing the most informative features from a dataset in order to reduce the dimensionality of the data [21]. During the process of feature extraction, we identified a total of 13 distinct fea- tures, including GLCM and statistical features including Contrast (CNT), Correlation (CRL), Skewness (SKEN), kurtosis (KTS), Variance (VAR), Standard deviation (STD), Entropy (ENT), Energy (EG), Mean (MN), Homogeneity (HGN), Root means square (RMS), Smoothness (SM) and Inverse difference moment (IDM).

Feature selection is a data processing approach used to identify effective features from data and remove irrelevant features [22]. To de- termine the feature selection process, we used the Analysis of Variance (ANOVA) and Least Absolute Shrinkage Selection Operator (LASSO) to evaluate the score of feature ranking. However, after completing the feature ranking, we observed that three features, namely RMS, smoothness, and IDM, have nearly identical values. To mitigate the issue of redundancy, we eliminated these features and finally selected the top 10 features including CNT, CRL, SKEN, KTS, VAR, STD, ENT, EG, MN, and HGN to conduct this study.

In this section, we mention the splitting ratio of train, validation, and test. The training, validation, and testing separation values are 60%, 20%, and 20% respectively. Training data is utilized to train a machine learning model and based on test data evaluate the efficiency of each model. As with validation data, it is used to compare the performance of various trained models.

also performed well with AUC values of 0.9896, 0.9762, 0.9139, and 0.8208. The SVM had the lowest AUC value of 0.6907 among all models tested. The ROC curve shows the larger area of the model based on performance. After evaluating the ROC curve, the LASSO feature selection outperforms the ANOVA feature selection. To ensure and guarantee the reproducibility of the models presented in this work, all datasets utilized in the creation of predictive models are accessible on GitHub.

