Previous learning-based methods only employ clear images to train the dehazing network, but some useful information such as hazy images, media transmission maps and atmospheric light values in datasets were ignored. Here, we propose a local feature residual network (LFR-Net) for single image dehazing, which is aimed at improving the quality of dehazed images by fully utilizing the information in the training dataset. The backbone of LFR-Net is structured by feature residual block and adaptive feature fusion model. Furthermore, to preserve more details for the recovered clear images, we design an adaptive feature fusion model that adaptively fuses shallow and deep features at each scale of the encoder and decoder. Extended experiments show that the performance of our LFR-Net outperforms the state-of-the-art methods.

the prevailing training datasets [21] for image dehazing include hazy images, ground-truth, transmission maps and atmospheric light values. Previous learning-based image dehazing improved the performance of networks by increasing the layers of the dehazing network, which increases the resources for computation. However, the transmission maps and atmospheric light values contained in the dehazing training dataset are not used when dehazing networks are trained.

Most learning-based dehazing methods [14,22] usually have an encoder and decoder structure. The main features of the hazy image are extracted using the encoder, and a clear image is restored using a decoder. However, most network encoders have shallow layers in different scales, which can only extract the shallow features of the current scale, resulting in the loss of details in the clear image restored by the decoder. For example, the encoder of GFN [22] does not extract deep features at all scales, which results in loss of details in the dehazed results.

The following structure is used to compose this paper. The related work with image dehazing is described in Section 2. In Section 3, we systematically described the proposed approach and its various components. In Section 4, comparative experiments of LFR-Net with state-of-the-art (SOTA) methods and ablation experiments are carried out. Finally, in Section 5, we summarize this study and look forward to future research.

Double-Conv and FR block contain shallow features and deep features at the current scale, respectively. If we adopt a regular skip connection, the dehazed image would be lost the shallow features of the encoder. Therefore, we design an adaptive feature fusion module to enhance the ability of shallow feature preservation. The feature maps of Double- Conv and FR blocks are fused using adaptive weights, and then the fused features are concatenated to the downsampled deep features. The result of the adaptive feature fusion can be expressed as:

The loss function of LFR-Net consists of three components, which are L1 loss, perceptual loss and haze loss. Lim et al. [31] indicate that L1 loss and perceptual loss perform well in image restoration tasks. Therefore, we choose L1 loss and perceptual loss to optimize LFR-Net.

Most dehazing methods use the output of the neural network and ground-truth to construct a loss function that optimizes the parameters of the neural network to generate better dehazed results. However, the input hazy images, medium transmission maps, atmospheric light values are ignored in the process of updating the parameters. Therefore, we propose a haze loss that utilizes the input hazy image and the haze- loss image to supervise the training process of the neural network. And the haze-loss image is generated by using the output of the proposed LFR-Net, medium transmission map and atmospheric light value. The haze loss can be formulated as

In this section, the dehazing ability of the LFR-Net is evaluated. First, the experiment settings are introduced. Then, We organize com- parison experiments with seven SOTA methods to prove better the proposed method. Finally, we exploit ablation experiments for demon- strating the efficacy of the architecture of our LFR-Net.

To prove the structural superiority of LFR-Net, we carried out ab- lation study to assess the usefulness of each module, including feature residual block, adaptive feature fusion model and haze loss. We choose U-Net, L1 loss and perceptual loss as the baseline network. Based on the baseline network, each module is added in turn to perform the ablation experiment: NetWork 1: baseline+FR, feature residual block is added to each scale of U-Net to constitute NetWork 1. NetWork 2: baseline+FR+ AFF, based on Network1, we use the adaptive feature fusion model to fuse shallow features and deep features when the generator generates feature maps at different scales, respectively. LFR-Net: LFR-Net has the same network architecture as NetWork 2, and adds haze loss to the loss function to better optimize the parameters of the neural network. The test set used in the ablation study is outdoor images of SOTS, and we used PSNR as an evaluation metric.

This work proposed a local feature residual network for single image dehazing, which takes full advantage of the information, including the hazy images, media transmission maps and atmospheric light values, in the training dataset. Also, the feature residual block of the proposed LFR-Net is exploited to enhance the deep features extraction capacity of the encoder. The adaptive feature fusion model is used to fuse the shallow and deep features of the encoder, which is finally connected to the decoder through a skip connection to preserve more details in the restored image. A haze loss is introduced to the loss function during the LFR-Net training process to update the parameters of the network utilizing haze-free images, hazy images, medium transmission maps, and atmospheric light values. Finally, we conducted extended experiments to demonstrate the superiority of LFR-Net from qualitative and quantitative aspects and organized ablation experiments to prove the usefulness of the LFR-Net structure. Moreover, most learning-based dehazing methods use synthetic datasets to train the weights, and poorly process real-world images. To overcome this problem, we will conduct unsupervised image dehazing research in the future.

