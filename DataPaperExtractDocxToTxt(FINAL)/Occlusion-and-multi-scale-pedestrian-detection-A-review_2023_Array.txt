Array 19 (2023) 100318










Occlusion and multi-scale pedestrian detection A review
Wei Chen a,b,c, Yuxuan Zhu a, Zijian Tian, CA a,*, Fan Zhang a, Minda Yao b
a School of Mechanical, Electrical & Information Engineering, China University of Mining and Technology (Beijing), Beijing, 100083, China
b School of Computer Science & Technology, China University of Mining and Technology, Xuzhou, 221116, China
c Key Laboratory of Intelligent Mining and Robotics, Ministry of Emergency Management, China



A R T I C L E I N F O 

Keywords:
Pedestrian detection
Occlusion pedestrian detection Multi-scale pedestrian detection
A B S T R A C T 

Pedestrian detection has a wide range of application prospects in many fields such as unmanned driving, intelligent monitoring, robot, etc., and has always been a hot issue in the field of computer vision. In recent years, with the development of deep learning and the proposal of many large pedestrian data sets, pedestrian detection technology has also made great progress, and the detection accuracy and detection speed have been significantly improved. However, the performance of the most advanced pedestrian detection methods is still far behind that of human beings, especially when there is occlusion and scale change, the detection accuracy decreases signif- icantly. Occlusion and scale problems are the key problems to be solved in pedestrian detection. The purpose of this paper is to discuss the research progress of pedestrian detection. Firstly, this paper explores the research
status of pedestrian detection in the past four years (2019–2022), focuses on analyzing the occlusion and scale problems of pedestrian detection and corresponding solutions, summarizes the data sets and evaluation methods
of pedestrian detection, and finally looks forward to the development trend of the occlusion and scale problems of pedestrian detection.





Introduction

Pedestrian detection is a special task of target detection, which is closely related to the development of general target detection. Pedes- trian detection aims to find pedestrians and mark the location and size of pedestrians from given images and videos. It is the basis of multiple tasks such as pedestrian rerecognition [1,2], pedestrian tracking [3,4], pedestrian trajectory prediction [5,6] and has a wide range of applica- tion prospects in intelligent monitoring [7,8], automatic driving [9,10], intelligent robots [11,12] and other fields. Therefore, pedestrian detection has always been a hot and difficult topic in the field of com- puter vision. Because pedestrian detection is easily affected by factors such as occlusion, scale, illumination, weather and similarity, the ac- curacy of pedestrian detection in complex scenes is poor and false pos- itives are easy to occur. Therefore, every year, a large number of scholars focus on coming up with a more robust, faster and more advanced method. Fig. 1 shows the number of studies related to pedestrian detection between 2003 and 2022 (data from Web of Science search, year of publication selected, search results 20).
Pedestrian detection methods are mainly divided into two cate- gories: hand-crafted feature-based methods and deep feature-based
methods. The first kind of methods include VJ, HOG, ICF, etc. In 2003, Viola and Jones [13] first combined motion and appearance in- formation together with Adaboost classifier to constitute VJ detector, which can robustly detect pedestrians from various angles with low false alarm rate. In 2005, Navneet Dalal and Bill Triggs [14] proposed HOG detector and used HOG features to train SVM classifier. HOG can describe local shape information and offset the influence of illumination to a certain extent, reducing the data dimension of the characterized image. In 2009, Piotr Dollar et al. [15] proposed the integral channel feature ICF. The second category of methods is mainly divided into one-stage detection methods YOLO series, SSD series, etc., and two-stage detection methods RCNN series. Joseph Redmon et al. [16] proposed YOLO method as a very representative one-stage detection method in 2016. YOLO treats detection as a regression task, divides the whole image into S*S grids, and each grid is responsible for detecting objects within the grid. It uses bounding box localization, conditional proba- bility, confidence, etc., to complete the prediction in one go. Subse- quently, YOLOv2 [17], YOLOv3 [18] and other versions were developed. Wei Liu et al. [19] proposed SSD as a one-stage detection method different from YOLO. SSD sets many bounding boxes with different aspect ratios and proportions for the image, and directly



* Corresponding author.
E-mail address: tianzj0726@126.com (Z. Tian).

https://doi.org/10.1016/j.array.2023.100318
Received 30 March 2023; Received in revised form 22 August 2023; Accepted 27 August 2023
Available online 3 September 2023
2590-0056/© 2023 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).






Fig. 1. Number of Web of Science searches for literature related to pedestrian detection, 2003–2022.

calculates the confidence of all bounding boxes in the regression. At the same time, multiple convolution layers with different scales are gener- ated in the convolution layer to detect multi-scale objects and improve the detection accuracy. Ross Girshick et al. [20] introduced Convolu- tional Neural Network (CNN) into the field of object detection for the first time in 2014, and proposed R-CNN by combining CNN with tradi- tional machine learning methods. R-CNN uses selective search to obtain as many pre-selected boxes as possible, uses CNN network to extract features instead of manually designed features for the first time, and uses multiple SVM classifiers for classification and regression. Then in 2015, Ross Girshick [21] designed a Region Proposal Network (RPN) to replace the selective search in R-CNN, and selected Softmax classifier to replace multiple SVM classifiers, which greatly improved the detection performance. With the rapid development of deep learning technology, many researchers have proposed many detection methods with better performance, such as Faster RCNN [22], MSCNN [23], YOLOv4 [24], CSP [25], SAF-RCNN [26] and other methods based on R-CNN. Although hand-designed features are effective in simple cases, their generalization ability is weak and it is difficult to obtain high-level se- mantic information. Deep features obtain feature representations based on the learning of a large number of samples, which can be learned end-to-end, with strong robustness and better generalization ability. In recent years, pedestrian detection has gradually evolved from hand-crafted features to deep features.
The detection speed and accuracy of pedestrian detection methods
have improved significantly. However, the most advanced pedestrian detection methods are still not comparable to human perception. Pedestrian detection still faces a number of challenges, for example:

Multiple gestures of pedestrian object: Pedestrian objects are both rigid and flexible and pedestrians may present a wide variety of postures, such as stationary, standing, squatting, bending, or walking. In addition, the appearance of pedestrians are all dressed differently, in various colors and styles. These variations pose a great challenge to current pedestrian detection. How to design a pedestrian detection method that is not affected by changes in pedestrian posture and clothing appearance is a challenge that needs to be solved for pedestrian detection nowadays.
Weather and low-lighting: Rain, snow, fog, haze, dust storms and other phenomena seriously reduce the clarity of photos, the reduced visibility of the pedestrian object and the blurred con- tours severely limit the performance of pedestrian detection. At night when the light intensity is low, the pedestrian images have higher gray values, lack of color information, and increased interference information. Also low light conditions generally use infrared images, which have low resolution, contain less pedes- trian information, and have blurred pedestrian object outlines. These problems seriously affect the accuracy of pedestrian detection. How to solve the problem of pedestrian object
contouring due to bad weather and low light is a major challenge in pedestrian detection.
Occlusion: Occlusion in pedestrian detection is divided into two main categories: One is intra-class occlusion between pedes- trians, and the other is inter-class occlusion of pedestrian objects by other objects. The mutual occlusion between pedestrians brings a lot of interference information, which may lead to false detection and affects detection performance. When the pedes- trian object is obscured by other objects, the structure of the pedestrian is incomplete and the information of the pedestrian object is missing, which can easily produce missed detection and reduce the accuracy of pedestrian detection.
Multi-scale pedestrian: Different distances of pedestrian objects from the camera will bring different spatial scales of pedestrians, there may be multiple pedestrians at different scales in the same image. This has caused a significant negative impact on pedes- trian detection. Large-scale pedestrians have richer information for better detection. But small-scale pedestrians tend to have lower pixels, blurred appearance and contours, contain less valid information, which easily misses detection and seriously affects the accuracy of pedestrian detection. It is a great challenge to accurately detect pedestrian objects at different scales.
Real-time detection: The application of pedestrian detection in automatic driving, intelligent monitoring, etc. has high re- quirements for detection speed and needs to be able to detect in real time. With the development of deep learning, the pedestrian detection model is becoming more and more complex. While the detection accuracy is improved, it also brings a lot of calculations, which reduces the detection speed of pedestrian detection. How to achieve real-time detection while improving the accuracy of pedestrian detection is a great challenge in the field of pedestrian detection.

Faced with many challenges, pedestrian detection, although a cate- gory of general object detection, can still be studied as an independent problem. In recent years, in order to improve the detection accuracy and detection speed of pedestrian detection, researchers have proposed many new detection methods with better performance. This paper dis- cusses and explores the research status of pedestrian detection from 2019 to 2022, summarizes commonly used pedestrian data sets and evaluation indicators, and focuses on the analysis of occlusion and scale problems and corresponding solutions of pedestrian detection.

Research status of pedestrian detection

Pedestrian detection is a special task of object detection and a basic task in real-world applications. It can be divided into two main cate- gories: hand-crafted features based and deep learning features based. In recent years, many new pedestrian detection algorithms have been proposed, and the detection performance is constantly improved. The success relies heavily on large-scale datasets, such as, Caltech [27], KITTI [28], CityPersons [29].The following is a brief summary of the progress in pedestrian detection in 2019–2022.
Hand-crafted features based

Although the earliest hand-made features such as HOG, Hear, LBP and LUV are no longer so excellent with the development of pedestrian detection technology, they also provide ideas and innovative inspiration for later researchers. Over the past 19 years, researchers have designed many new feature descriptors with better performance. Wenshu Li [30] et al. designed eHOG feature by enhancing the contrast of HOG feature in order to balance the speed and accuracy of pedestrian detection. Ritesh Kumar Mishra [31] reduces the redundant information of HSG by adding a feature selection module to reduce the feature size and improve the calculation speed. Ming Yang [32]et al. proposed a Feature



Descriptor generation model (DGM), which can systematically generate various HOG descriptors for pedestrian detection and evaluate the detection performance of each descriptor. GuoYun Lian [33] proposed QGWLD descriptor by combining WLD feature and quaternion repre- sentation, which not only extracts features from gray images but also fuses color information and texture information, as shown in Fig. 2. Lienhard Pfeifer [34] believes that Shearlets feature can obtain the di- rection information well to detect the edge direction in the target image. Two image features, shearlet amplitude and shearlet histogram, are designed.
Some researchers believe that the fusion of different feature opera- tors can effectively use the characteristics of different features and improve the performance. Yu Jiang [35] et al. extracted a new fusion feature HOG-LBP by means of series fusion of HOG features and LBP features. Zijie Xie [36] et al. serially concatenated HOG features and three-layer LBP features extracted in three times to form a new multi-level concatenated feature, and performed dimensionality reduc- tion operation (PCA) before feature fusion. The concatenated features are shown in Fig. 3. Kaushal Kumar [37] et al. combined HSG and NRULBP to generate new descriptors, which incorporated shape and texture information and contained more valuable feature information. Hongzhi Zhou [38] et al. fused the feature vectors of color image fea- tures and depth image features into a complex vector by weighted fusion method. Daxue Liu [39] et al. proposed Shallow and Deep feature Fusion (SDFF) based on ACF, which uses shallow features to quickly generate pedestrian proposals and effectively removes false positives through deep features.

Deep features based

Pedestrian detection based on deep features is further divided into one-stage and two-stage. Recently, a number of single-stage pedestrian detection methods have been proposed. Wei Liu [40] et al. proposed CSP detector to directly predict pedestrian center point and scale through high-level semantic feature detection, which opened up a new idea for later researchers. The model framework is shown in Fig. 4. Tao Zhang
[41] et al. proposed F-CSP network. F-CSP introduces FPN and BFP to improve the original feature fusion module. FPN can reduce the number of channels of the feature map, and BFP fuses multiple feature maps into a feature map, reducing other parameters. Based on the original YOLOv3 network model, Jingwei Cao [42] et al. improved the multi-scale bounding box prediction based on receptive field and introduced the Soft-NMS algorithm, which improved the performance of the detection algorithm in various complex scenes. Haohui Lv [43] et al. proposed YOLOv5-AC based on YOLOv5s, introduced L1 regularization in BN layer to remove networks with small impact factors to reduce model size and improve speed, introduced CEM module to extract more features and used two attention modules CxAM and CnAM to filter useless fea- tures. Correct the position offset to improve the accuracy. Wei Liu [44] et al. designed the Progressive Localization Fitting (ALF) module, which

Fig. 2. QGWLD pedestrian detector(image from literature [33]).



Fig. 3. Multilayer cascading features (image from literature [36]).

uses a series of predictors to gradually convolutional evolve the default anchor box of SSD. Residual learning and multi-scale context coding are combined to improve the accuracy of localization and enhance the prediction ability. Mahmoud Saeidi [45] et al. designed a DM-PPP pedestrian detection model based on the estimation of different parts. The improved SSD is used to generate initial candidates and expand the region with safety boundaries, and the pedestrian proposal is divided into nine parts and evaluated independently. Chintakindi Balaram
Murthy [46] et al. proposed an optimized MobileNet+SSD network,
which makes feature extraction, deformation, and classification com-
ponents work together to reduce the number of parameters to improve the detection speed. Yuang Zhang [47] et al. regard single-stage pedestrian detection as a variational inference problem, and propose a customized Auto-coded variational Bayes (AEVB) algorithm by modeling dense proposals as latent variables. The algorithm process is shown in Fig. 5.
There are many two-stage pedestrian detection algorithms with excellent performance that have been proposed in recent years. Garrick Brazil [48] et al. proposed AR-Ped pedestrian detection method. AR-RPN can autoregressively generate and improve features and pre- dictions by retaining more context information and improving perfor- mance by using convolutional resampling layer, and its framework is shown in Fig. 6. Zhihang Fu [49] et al. think that although rich context information is important, the core area of the target instance is more important, and propose the ExtAtt two-stage pedestrian detection framework. Jin Ren [50] et al. improved Faster RCNN, designed a method of pooling Context Environment (PCE) around the candidate window, and fused different levels of features to improve the detection accuracy. Fiseha B. Tesema [51] et al. believe that manual features can
and CNN features for detection on the basis of RPN+BF. RuihaoYin [52] be a good supplement to CNN features, and combine manual features et al. proposed a Multi-resolution Generative Adversarial Network
(MRGAN) to generate high-resolution images from low-resolution im- ages for multi-resolution pedestrian detection, introducing a novel perceptual loss. Peijia Yu [53] et al. performed quality assessment by fusing multi-channel visual features and proposed a new reduction Adjustment module (RA). RA can improve the connection between feature channels and enhance the features with less information. Zebin Lin [54] et al. proposed an example Guided Contrastive learning (EGCL) model, which learns a feature transformation module through contras- tive learning, projects the initial feature space into a new feature space, minimizes the semantic distance between pedestrians to eliminate the appearance diversity of pedestrians, and maximizes the semantic dis- tance between pedestrians and the background. Han Xie [55] et al. designed a deformable convolution with an attention module to sample from non-rigid locations and extract attention feature maps with context information.




Fig. 4. CSP algorithm (image from literature [40]).


Fig. 5. AEVB algorithm (image from literature [47]).


Fig. 6. AR-RPN framework and de-encoder module (image from literature [48]).


Datasets and performance evaluation

In the past few decades, the performance of pedestrian detection has been greatly improved, and a large-scale research system has been formed. At the same time, some datasets dedicated to pedestrian detection and some evaluation methods for pedestrian detection per- formance evaluation have emerged in the field of pedestrian detection.
Datasets

The dataset is the basis of the research in the field of object detection. It is not only a general means to measure the performance of similar algorithms, but also a power to promote the development of object detection research. The size of the dataset and the quality of the labeling information are very important for the detector training, and accurate



labeling information can help the detector to learn the specified content. To date, published pedestrian datasets include MIT [56], INRIA [14], KAIST [57], ECP [58], Caltech [27], Cityperson [29], KITTI [28],
Daimler [59], NICTA [60], ETH [61], CrowdHuman [62], WidePedes- trian and WiderPerson [63] and others. The attributes of these datasets are summarized in Table 1. These datasets each have different charac- teristics depending on their content. Such as CrowdHuman, WidePe- destrian and WiderPerson. The content of these datasets is more diversified and diverse, which helps to improve the robustness and generalization of the network, while Caltech, CityPersons and KITTI, which have more perfect annotation information, have better effects for occlusion and multi-scale scenes, and therefore have a wide range of applications. Three datasets Caltech, CityPersons and KITTI are detailed here.
The Caltech dataset was published by Caltech in 2009. It is mainly captured by a car camera running normally in a regular traffic scene. The video is about 10 h long and has about 250 k frames, which contains 350,000 bounding boxes and 2300 pedestrian annotations. And the annotations include bounding boxes and correspondences for different occlusion levels.
The CityPersons dataset is a subset of the Cityscapes dataset and contains only pedestrian annotations. There are 2975 images for training and 500 and 1575 images for validation and testing. On
detector.
Average precision AP is one of the commonly used indicators in the detection field. Generally, the performance of the model is dynamically evaluated by plotting the Precious-Recall(P-R) curve, where the abscissa is the recall rate and the ordinate is the accuracy rate. Their calculations can be shown in (1) and (2). Where TP (True Positive) predicts positive samples and the prediction is correct. The closer this metric is to the annotated number of pedestrians in the validation set, the higher detection rate of the detector is indicated. FP (False Positive) predicts a positive sample but is wrong. This index reflects the false detection rate, and the lower the false detection rate, the better. FN (False Negative) The prediction result is negative samples but the prediction result is wrong, this index reflects the missed detection rate, the smaller the
index, the better. Based on the TP and FP detections, the precision P(β) and recall R(β) can be computed as a function of the confidence threshold β. P-R curve can be obtained by varying the confidence threshold, and then the Average Precision (AP) can be found. The mean
Average Precision (mAP) is a commonly used evaluation metric in multi- object detection and multi-label image classification. The mAP is the sum of the average accuracy AP on the multi-class classification task and the average, which measures how good the model is on all classes, its calculations can be shown in (3), c represents the total number of categories.

average, each image contains 7 pedestrians, and the density of pedes-
trians is high and there are many occlusions.
KITTI is one of the important datasets in the field of autonomous
Recall
	NTP	
= (NTP + NFN)
(1)

driving, which provides a large amount of real scene data, about 50 min of outdoor scenes. It has 7481 images for training, 7518 images for testing, and their corresponding point cloud data with ~200,000 3D
Precision
	NTP	
=	(2)
( TP + FP )

labeled boxes. There are up to 15 vehicles and 30 pedestrians in each
image, and various degrees of occlusion and truncation are included.

mAP
∑c AP
= k=0
c

(3)

Evaluation method

The detection performance of pedestrian detector is generally re- flected by the corresponding evaluation method, and an excellent evaluation method can objectively reflect the excellence of pedestrian

Table 1
Summary of pedestrian datasets.

Intersection Over Union (IOU) is a measure of the overlap between the prediction box and the Ground Truth, which can determine whether the predicted detection box meets the conditions. Its calculations can be shown in (4), where Bgt represents the Ground Truth, Bp represents the predicted bounding box.
area Bp ∩ Bgt)
IOU = area Bp ∪ Bgt )	(4)
The log-average Miss Rate(MR) is an indicator to describe the miss rate in the detection results. False Positive Per Image(FPPI) describes the average false detection rate per image. Their calculations can be shown in (5) and (6). The MR-FPPI curve is similar to the P-R curve used for
Mr—2 uses a curve with FPPI as the abscissa and log(MR) as the ordinate. object detection and can reflect the overall performance of the detector. Nine FPPS in the range of [0.01,1] are uniformly selected to obtain their
corresponding nine log(MR) values, and these vertical values are aver-
form of MR by exponential operation, and the MR—2 index is obtained, aged. Finally, the above average values are restored to the percentage the smaller the index is, the better the performance of the detector.
MR = NFN = 1 — Recall	(5)
Ngt
FPPI = NFP	(6)
N
Multi-scale pedestrian detection

Although pedestrian detection technology has made great progress in recent years, multi-scale problem has always been a big challenge for pedestrian detection. In the convolutional feature map, the features of large-scale and small-scale pedestrian instances are very different. In addition, large-scale pedestrians also have more abundant information, while small-scale pedestrians have low resolution and blurred edges,



which are difficult to distinguish from the background. Multi-scale pedestrian detection should be able to detect and accurately locate pedestrian instances of different scales without being affected. This is a great challenge for pedestrian detection, and this chapter reviews the 19 years that some researchers have proposed new methods for the scale
problem, as shown in Fig. 7. Tables 2–4 show the detection capability of the introduced pedestrian detection method.


Based on context information

Context information can effectively improve the accuracy of pedes- trian detection. Small-scale pedestrian targets are difficult to provide rich ROI features, and additional context information can effectively supplement the original ROI features. In 2019, Han Xie and Yunfan Chen
[64] et al. introduced deconvolution and porous modules into the Faster R-CNN network to add more semantic context information to enhance the feature map. The new synthetic feature map can provide richer vi-
and Lei Jin [65] et al. proposed FPN++ on the basis of FPN. In order to sual detail information and semantic context representation. Junhao Hu extract deeper features with more semantic information and increase the
local receptive field, the convolution is replaced by dilated convolution and the step size of the convolution is reduced in the backbone of FPN. Chen Zhang [66] et al. proposed a multi-scale pedestrian detector. The detector fuses pooled features with different resolutions and context information in the fully connected layer to make full use of their unique
features, and designs a recurrent convolutional layer with feature connection (RCL-FC) to extract strong and deep context information by iteratively integrating large RF features and small RF features. In 2021, Xiaoting Yang [67] et al. proposed Scale-sensitive Feature Recombina- tion Network (SSNet), which uses a multi-parallel branch sampling module to flexibly adjust the receptive field and anchor stride to extract scale-sensitive features, and introduces a context enhancement fusion module to reduce the information loss of medium and high-level fea- tures. The framework is shown in Fig. 8. The method proposed by Han Xie and Xiaoting Yang et al. performs well for small-scale pedestrian detection, but the detection speed is not fast enough to meet the
real-time requirements. The processing speed of Xiaoting Yang’s method is relatively fast, and it shows good compatibility in different driving
scenarios.


Based on attentional mechanisms

The attention mechanism can find the correlation between the original data and highlight some important features. The introduction of the attention mechanism in pedestrian detection can better fuse different features and improve the robustness of pedestrian detection at different scales. In 2019, Zhichang Chen [68] et al. believed that the competitive attention module can be used to improve the hard negative samples and multi-scale problems of pedestrian detection, and the competitive attention module helps the network architecture to obtain




















































Fig. 7. Summary of algorithms in this chapter.


Table 2
Detection performance of the presented method on the Caltech (R represents Reasonable setting, M0 represents Medium setting, F represents Far setting, MR—2 as evaluation index in %) and KITTI (E represents Easy setting, M1 represents Moderate setting, H represents Hard setting, Red numbers indicate the evaluation index in %
with average precision, Black numbers indicate the evaluation index in % with the mean average precision) dataset.


Table 3
represents Bare setting, S represents Small setting, M represents Medium setting, L represents Large setting, A represents ALL setting, MR—2 as evaluation index in %). Detection performance of the presented method on the Cityperson dataset (R represents Reasonable setting, H represents Heavy setting, P represents Partial setting, B














Table 4
Detection performance of the presented method on the other dataset (VOC series dataset with mAP as evaluation index, 2D-light dataset with MR—2 as evaluation index, all units are in %).




Fig. 8. SSNet framework(image from literature [67]).



valuable specific information from multi-scale feature maps. They designed a novel architecture (CompAt). In 2020, Chunze Lin and Jiwen Lu [69] et al. proposed a granular aware deep feature learning method (CA-GDFL), which can use the convolution backbone to generate mul- tiple feature maps to represent pedestrian targets at different scales. Then, the scale-aware pedestrian attention module is used to generate the attention map, and the attention map and the feature map are fused into a granular aware feature map to better distinguish the background and pedestrians. Finally, the zoom and zoom module is used to combine context information to enhance shallow features. T T Feng [70] et al. introduced the feature enhancement strategy and attention mechanism module into SSD, and proposed a new pedestrian detection algorithm. In 2021, the MSCM ANet network proposed by Jun Ma [71] et al. intro- duced a multi-scale convolution module, and added an attention module to make the detection network focus on the characteristics of pedes- trians. The feature maps extracted from the attention module are merged by the pyramid fusion structure, and then the CRM is used for regression and classification. T T Feng et al. ’s method has certain
recognition ability for small targets, but the model parameters and
calculation are not small enough. Although the detection accuracy of Jun Ma et al.’s method is improved, the detection speed is reduced.

Based on multi-scale features and feature fusion

The extracted features are very important in pedestrian detection, and the amount of information contained in the features directly affects the detection performance of pedestrian detection. For small-scale pedestrian detection, single-scale feature maps are not robust. Some researchers propose to extract multi-scale feature maps from images of different scales for prediction, and multi-scale features can combine semantic features and geometric features to obtain richer information. In 2020, XiaoWei Zhang [72] et al. proposed a scale-aware hierarchical detection network, which introduced a cross-scale feature aggregation module on FPN to fuse the semantics and localization of pedestrians at different scales, and enhanced the feature pyramid representation. Yufeng Zhao [73] et al. proposed a multi-focus pedestrian detection network (MFDN) based on Faster R-CNN. MFDN uses multiple refocused images as input to solve the problem of small-scale pedestrian detection and confusion with anthropomorphic negative samples. The Cumulative Probability Selection (CPS) layer was introduced to combine the results of multiple detection branches. In 2021, Zhiwei Cao [74] et al. proposed a multi-scale anchor-free region proposal network. Adaptive Channel Feature Fusion (ACFF) was used to select features at different scales, and multi-scale anchor-free region Proposal (MSAF) was used to predict the position, center offset and height of the person to obtain the boundary box. Reducing hyperparameters improves the scale imbalance problem. W.-Y. Hsu [75] et al. introduced the idea of segmentation on the basis of YOLOv4. After extracting the feature information of the entire image,
the non-overlapping pedestrians were divided into new subimages and the feature information of the subimages was extracted. Lu Ding [76] et al. proposed a new framework based on SSD. FPN was introduced into the SSD framework to effectively utilize features of different scales, and NIN strategy was used to fuse global information and local details to enhance feature maps. Qiming Li [77] et al. proposed an Anchor-free Multi-scale Pedestrian Detection Network (MPAF-Net) to simplify pedestrian detection into the prediction task of center and scale, and improve the multi-scale representation strength of the detector for pe- destrians by designing a new bottleneck block and improving Res2Net. And the CRF-based message passing mechanism is used to enhance the multi-scale features, whose framework is shown in Fig. 9. In 2022, Chaoqi Yan [78] et al. proposed R-SSD based on the SSD architecture. During feature fusion, feature maps of different scales are fused, and then the fusion block is fused with other layers to generate six prediction layers from different depths. A residual block is added to each prediction layer of SSD to improve prediction performance. The method proposed by XiaoWei Zhang, Zhiwei Cao, Qiming Li et al. has good performance for small-scale pedestrian detection. Lu Ding’s method has relatively fast
detection speed, but it is not effective for small-scale pedestrian detec-
tion. Some hyperparameters of W.-Y. Hsu’s method need to be selected manually and the segmentation function leads to an increase in reasoning time. Chaoqi Yan’s method does not need to configure an- chors for different data sets, but it does not perform well for crowded
pedestrian scenes.
At the same time, feature maps of different depths contain different semantic information. Shallow feature maps have strong semantic in- formation that can well activate small-scale pedestrians, while deep feature maps have rich spatial information. In 2020, REN J [79] et al. proposed the IF-RCNN method, which adjusted the size of the anchor box in the RPN network and used three convolution kernels with different sizes to generate candidate regions from the last layer feature map. In order to obtain the deep semantic features and shallow detail features at the same time, the feature maps generated by the Conv5_3 and Conv4_3 layers of the feature extraction network are fused. Bing Han [80] et al. proposed a small-scale perception network (SSN). SNN generates more proposal regions from lower convolutional layers, uses the highest convolutional layer to supplement the global information of the image, and uses deconvolution to merge convolutional layers to generate new feature maps. Chintakindi Balaram Murthy [81] et al. proposed an improved YOLOv2 pedestrian detection algorithm (YOLOv2PD), which used multi-layer feature fusion (MLFF) strategy to improve the feature extraction ability of the model and removed a convolutional layer in the last layer to reduce the computational complexity. Normalization is applied to improve the loss function to improve the detection performance. In 2022, Hao Xia [82] et al. pro- posed the MAFA-Net pedestrian detection method, which uses deep expansion blocks to extract deeper features, uses pedestrian attention




Fig. 9. MPAF-Net framework(image from literature [77]).



blocks to obtain more mutual information between features, and in- troduces a feature aggregation module to combine high-level features and low-level features. Yuzhe He [83] et al. proposed a multi-scale feature balance enhancement network. The network extends a bottom-up short-circuit path to improve the utilization of low-level feature information, designs a feature balance module to obtain the same amount of semantic information from different resolutions, and uses a feature enhancement module to expand the receptive field to retain more information. The method proposed by REN J makes good
use of the deep features of the network and has good detection effect. Bing Han’s method has good performance for small-scale pedestrians, but the detection speed is relatively slow. Chintakindi Balaram Murthy’s
method can detect in real time, but it has poor performance for
small-scale pedestrians and occluded pedestrians. The method proposed by Hao Xia and Yuzhe He both explored the use of feature fusion to improve detection accuracy, but did not balance accuracy and speed well.

Based on other methods

In recent years, some researchers have proposed some other methods to deal with the scale problem in pedestrian detection. Some researchers have introduced semantic segmentation into pedestrian detection. Se- mantic segmentation actually understands the image from the pixel level, which can separate the pedestrian target and background to help small-scale pedestrian detection achieve better detection performance. In 2021, Peiyu Yang and Guofeng Zhang [84] et al. proposed a partially aware Multi-scale fully convolutional Network (PEMS-FCN). Pems-fcn designs a multi-scale FCN to detect pedestrians at different scales and utilizes partially aware RoI pooling and instance RoI pooling to combine local and global information to deal with occlusion. In 2022, Chengju Zhou [85] et al. proposed a detection framework based on R-FCN, which proposed several new components to improve the detection perfor- mance of small-scale pedestrians by using semantic segmentation. Some researchers believe that large-scale pedestrians can obtain good detec- tion accuracy, while small-scale pedestrian detection is difficult, so the relationship between small-scale pedestrians and large-scale pedestrians can be used to help small-scale pedestrian detection. In 2019, Yanwei Pang and Jiale Cao [86] et al. used the connection between large-scale and small-scale pedestrians to recover the details of small-scale pedes- trians, and designed JCS-Net for small-scale pedestrian detection through joint optimization classification and super-resolution. In 2020, Jialian Wu [87] et al. believed that the weak representation of small-scale pedestrians was the main reason for the classifier to miss them, so they proposed component of Self-simulation Learning (SML). SML forces the feature representation of small-scale pedestrians to be close to that of large-scale pedestrians by designing a simulation loss. Peiyu Yang’s method has relatively slow detection speed and little help
for normal scale pedestrian detection. The method proposed by Chengju
Zhou is not effective for small-scale pedestrian detection with height less than 40 pixels. The method proposed by Yanwei Pang only considers the similarity between reconstructed pedestrians and large-scale pedes- trians, and ignores the dissimilarity between reconstructed background and large-scale pedestrians. The method proposed by Jialian Wu is a general component, which can be effectively applied to other detectors with backbone networks.
Some researchers have improved the robustness of multi-scale pedestrian detection through multi-scale detection. In 2021, Hexiang Zhang [88] et al. proposed YOLOv3-Z based on the Retinex algorithm and the improved YOLOv3 algorithm. The Retinex algorithm is used as a preprocessing algorithm to improve the brightness and contrast of pe- destrians, and the YOLOv3 algorithm is improved by adding multiple scale detection. In 2022, Chintakindi Balaram Murthy [89] et al. pro- posed a lightweight real-time detection algorithm (EfficientLiteSet), which introduced a three-scale transformer prediction head (TPH) in Tiny-YOLOv4 to replace the original detection head, which could
improve the detection performance of small targets. At the same time, the attention mechanism is introduced to weaken the influence of messy information and only focus on the key information. The method pro- posed by Hexiang Zhang is not good enough for small-scale data sets. Chintakindi Balaram Murthy’s method is a lightweight real-time de-
tector, which is easier to adapt to edge devices.
In addition, Jiachi Wang [90] et al. proposed SICNN network, which adds a spatial pyramid pooling layer on the basis of Faster RCNN to pool all feature vectors, and uses pooling Windows of different scales to pool different target areas to improve the performance of multi-scale pedes- trian detection. Shan Zhang and Xiaoshan Yang [91] et al. believe that the body shape of pedestrians is always rectangular, so they designed an asymmetric Multi-stage network (AMSNet). AMSNet uses rectangular convolution kernels instead of square convolutions to extract features, and designs a three-stage framework based on RPN to exclude non-pedestrian prediction boxes according to coarse-to-fine features. Xiao Wang [92] et al. discovered a discriminant surface (SSS) in the score scale space by studying the functional relationship between pedestrian scores and scales. According to the position of pedestrians on the discriminant surface, pedestrians can be distinguished at different scale levels. Based on this, the S3D pedestrian detection method is proposed, and its framework is shown in Fig. 10. The method proposed by Jiachi Wang and Xiao Wang performs well for small-scale pedestrian detection.

Occluded pedestrian detection

Most of the pedestrian detectors have good detection capability for pedestrian objects with high visibility and small percentage of occlusion. However, when the pedestrian target is occluded, the performance of the pedestrian detector may degrade, especially when there is severe oc- clusion the performance of the detector can be significantly degraded. And occlusion can appear in different places, and the degree of occlusion is difficult to control, so how to deal with occlusion is a hot topic of
research in recent years. This chapter reviews the new methods pro- posed by researchers for the occlusion problem in the past 19–22 years, as shown in Fig. 11. Table 5 shows the detection performance of the
occluded pedestrian detection algorithms reviewed in this chapter.

Based on body parts

Because of the lack of sufficient information of occluded pedestrians, the detector cannot accurately identify pedestrians and effectively locate the part of pedestrians. Some researchers construct local detectors to assist whole-body detection according to the characteristics of different parts of the human body. The detection method based on body parts can effectively improve the accuracy of occluded pedestrian detection. In 2019, LIN C-Y [93] et al. proposed PedJointNet, a dual-branch archi- tecture, which uses the feature pyramid module to predict the head-shoulder region and the full-body region respectively, and pro- poses a new sharing mechanism that can dynamically and adaptively adjust the weights between the head-shoulder region and the full-body region. Junhua Gu [94] et al. designed a new method for joint pedes- trian and body part detection. The BPIF representation was used to represent the semantic relationship between each body part and high- light the characteristics of each part, which had good robustness to partial occlusion. Chunluan Zhou [95] et al. used a multi-label learning method to construct a joint learning part detector. Part detectors share a set of decision trees, which reduce the computational complexity by exploiting partial correlations and obtain an overall score for all parts. Muhammad Mobaidul Islam [96] et al. proposed a new training strategy, which learns a set of body parts during training, and each part corre- sponds to the defined occluded pedestrian, detects pedestrians from the body parts, and turns the occluded pedestrian detection problem into a multi-class classification problem. In 2021, Shanshan Zhang [97] et al. found that some channel features can not only be located but also




Fig. 10. S3D framework(image from literature [92]).


correspond to certain body parts, and the occlusion situation can be represented as a specific combination of body parts. Therefore, a channel attention mechanism was designed to obtain a more efficient representation of occluded pedestrians. In 2022, Jiali Ding [98] et al. proposed a head-aware pedestrian detection network (HAPNet) based on the structural relationship between the human body and the head. HAPNet detects both the head and the body of pedestrians, and proposes a head-side affinity module to represent the association between the head and the body. Ameen Abdelmutalab [99] et al. proposed a multi-branch pedestrian detection algorithm (MB-CSP), which used four
branches to extract features from the pedestrian’s ground, middle, lower and whole body respectively, and at the same time to mark the visibility
of different pedestrian parts for training. The model framework is shown in Fig. 12. The methods proposed by Chunluan Zhou, Shanshan Zhang, Jiali Ding etc. have good performance in severe occlusion, and the attention network proposed by Shanshan Zhang can be applied to other
detection tasks. Ameen Abdelmutalab’s method achieves good detection performance, but it does not work well when the pedestrian height is
below 50 pixels.

Based on context information

Some researchers use context information to supplement the features of occluded pedestrians to better represent occluded pedestrians and improve the robustness of occluded pedestrian detection. In 2019, Chi Fei [100] et al. proposed Context-aware feature Learning (CAFL). CAFL uses the pixel-level context embedding module to integrate the context information of multiple surrounding regions into the feature layer, improving the discrimination ability of the detector and enhancing the robustness to occlusion. Wittawin Susutti [101] et al. believe that local information is as important as global information, and propose a multi-channel pedestrian detection method based on appearance. The complete image is divided into multiple regions, and the features of each region are extracted and analyzed. ACF and uLBP features are used to hierarchically combine to represent pedestrians. In 2020, Zhaoqing Li
[102] et al. proposed the SCN model by combining segmentation ideas and context information. SCN uses segmentation to obtain pedestrian contours to generate more accurate pedestrian information and uses LSTM for information exchange. Sheping Zhai [103] et al. proposed FCF R-CNN, which adopts a progressive cascade strategy in the backbone network to extract features from different layers for fusion, and the feature information of shallow layers is utilized. A multi-layer LSTM module is also designed to extract the global context information of the
image. In 2022, Hangzhi Jiang [104] et al. proposed the SMPD pedes- trian detector, designed a semantic integration module, independently of the CSP detector, used the semantic context of urban scenes for detection, and fused the output of CSP detector and semantic integration module as the final detection result. Zhenxing Liu [105] et al. proposed a global context-aware feature extraction module, which can combine context information with local and global pedestrian characteristics. At the same time, a visual feature enhancement module was designed to introduce unblocked upper body information into the network to
enhance the representation ability of extracted features. Chi Fei’s
method performs well for severe occlusion and the network is relatively lightweight. Wittawin Susutti’s method is fast and can be applied in real time. A Although the detection accuracy of Zhaoqing Li’s method is
good, the training and detection are slow. The auxiliary module pro-
posed by Hangzhi Jiang can be applied to the rest of the general de- tectors. Zhenxing Liu’s method has unstable performance in different datasets and weak generalization ability.

Based on GAN network

Some researchers believe that GAN networks can be used to cope with occlusion in pedestrian detection. In 2020, Songyan Liu [106] et al. proposed attribute Preserving Generative Adversarial Network (APGAN), which introduced a new occlusion reconstruction loss on the basis of CycleGAN to improve image quality and complete attribute preservation after style changes. Firstly, pedestrian images of different scales and occlusive were simulated to improve the diversity of data. Then, the style changes are performed to make the generated pedestrian images more realisti. In 2021, Jin Xie and Yanwei Pang [107] et al. proposed a mask-guided attention network (MGAN). The standard pedestrian detection branch of MGAN uses whole-body annotations to generate features for supervision, while the MGA branch uses unoc- cluded body regions to generate spatial attention maps that enhance the features of unoccluded regions and suppress the background. MGAN also uses OSEM to introduce occlusion level into the sampling process and designs OSL occlusion brightness loss. Yi Jin [108] et al. proposed an end-to-end Super-Resolution Detection (SRD) network. SRD per- formed Super-resolution reconstruction (SRGAN) on the image to better distinguish pedestrians from the background, improved the loss function of Faster R-CNN, and fixed the size of the input image. Occluded pe- destrians are re-detected by using the improved Faster R-CNN. Yong- qiang Zhang [109] et al. proposed a keypoint-guided Super-resolution network (KGSNet). Firstly, the corresponding SR image blocks are
















































































Fig. 11. Summary of algorithms in this chapter.


Table 5
Detection performance of the presented method on the Caltech(R0 represents Reasonable setting, P represents Partial setting, H represents Heavy setting, the log- average miss rate as evaluation index in %)and CityPersons(R1 represents Reasonable setting, H represents Heavy setting, P represents Partial setting, B represents Bare setting, the log-average miss rate as evaluation index in %)dataset.



Fig. 12. MB-CSP Framework(image from literature [99]).


generated according to the key points of the pedestrian in the small-scale pedestrian image through the super-resolution network. The method proposed by Songyan Liu and Jin Xie has strong generalization ability. Yi Jin’s method still has good performance in low-quality image
detection.

Based on feature enhancement

Researchers believe that the representation of occluded pedestrians
can be improved by enhancing features, so that the detector can detect the occlusion form more easily. Some researchers enhance the occluded pedestrian features by feature fusion. In 2020, the feature learning model CircleNet proposed by Tianliang Zhang [110] et al., uses multiple top-down and bottom-up paths to reciprocally fuse features. The top-down path can strengthen semantic information and the bottom-up path can expand the receptive field and combine contextual informa- tion. And the instance decomposition training strategy is used to detect pedestrian instances with different occlusions in each cycle. In 2021,



Binjie Ruan [111] et al. proposed the MF-CSP detector combined with semantic features on the basis of CSP, designed a semantic feature enhancement module to enhance semantic features by fusing feature maps at different levels, and then detected pedestrians according to their position and proportion. Yuzhi Tan [112] et al. proposed the PRF-Ped anchorage free pedestrian detector, designed the Bidirectional Feature Enhancement Module (BFEM) to fuse the features of different levels, and proposed the prior based receptive field Block (PRFB) to guide the network to pay attention to pedestrians and reduce the interference of background information. The model framework is shown in Fig. 13. In 2022, Guiyi Yang [113] et al. proposed a Multi-scale Feature Attention Fusion Network (PFF-CB). PPF can enhance the key important features through parallel feature fusion, and the convolutional attention module can enhance the effective feature information of space and channel and adjust its weight. Jing Wang [114] et al. proposed a pedestrian detection technology in crowded scenes, which used the unoccluded part to assist pedestrians to improve the detection accuracy as a whole. Dual Region Feature Generation (DRFG) and Selective Kernel feature fusion (SKFF) were designed to eliminate false positives in crowded pedestrian detection, and Paired Multiple Instance Prediction (PMIP) was intro- duced. Yugang Qin [115] et al. proposed FE-CSP single-stage pedestrian detection algorithm, which combines GCB and attention and selects deformable convolution to improve the feature extraction ability of the backbone network. At the same time, the feature pyramid network is used to fuse the low-level and high-level features to obtain more se- mantic information. The method of Binjie Ruan and Jing Wang does not consider the detection speed. Yugang Qin’s method is difficult to accu-
rately detect a single pedestrian when pedestrians are very crowded.
Guiyi Yang’s method is a general module, which can be well applied to other detectors.
Some other researchers enhance occluded pedestrian features by attention and improving feature extraction networks. In 2020, Ruihong Yin [116] et al. proposed the DA-Net network. In order to better deal with occlusion and highlight the unoccluded part of the pedestrian, DA-Net uses CWAM to weight each channel feature, and uses GAM to supplement the global information for the occluded part. Tengtao Zou
[117] et al. proposed an Attention Guided Neural network model (AGNN) to deal with occlusion. AGNN is actually a pedestrian classifi- cation model, and the most important thing is that the attention guid- ance network weights the local features to enhance the features. In 2021, Xiaotao Shao [118] et al. proposed an occluded pedestrian detection algorithm (MFPN). MFPN designs a new feature extraction network DFR, which can effectively enhance the semantic information and con- tour of occluded pedestrians while reducing the computational complexity. Jin Xie [119] et al. introduced a Local Spatial Co-occurrence (PSC) module based on Faster R-CNN. The PSC module can obtain the intra-part and inter-part spatial co-occurrence of different body parts through  graph  convolution  to  enhance  the  body  part  feature
representation and the final feature representation. Ye He [120] et al. proposed the Pedestrian Detection Network (DMSFLN), which performs pedestrian detection through a standard whole-body detection branch and an additional visible body branch, and the two branches are su- pervised by full-body annotations and visible body annotations, respectively. In 2022, Yan Luo [121] et al. proposed the Occluded Pedestrian Detection Network (SA-DPM), which used sequential atten- tion to extract local features and introduced Frobenius norm for con- straints to ensure the diversity of local features. Its framework is shown in Fig. 14. The Feature Calibration Network (FC-Net) proposed by Tianliang Zhang [122] et al. can adaptively detect pedestrians under various occlusions. Its core is a self-activation module, which can simply and effectively enhance features by reusing classification weights to estimate pedestrian activation maps. The method of Xiaotao Shao and Tengtao Zou still has good performance in severe occlusion. Ye He’s
method does not perform well enough in crowded scenes. The network
module proposed by Yan Luo is complex and has too many parameters. Tianliang Zhang’s method is suitable for general object detection tasks.

Based on center point detection

Some researchers regard the center point of pedestrians as a high- level semantic feature, and transform the pedestrian detection prob- lem into the detection problem of high-level semantic features, and improve the performance of occluded pedestrian detection through center point detection. In 2021, Yang Wang [123] et al. proposed the MAPD detector for crowd detection, which obtained the attributes of center, scale, offset, density and id through five output graphs, and proposed a multi-attribute NMS based on the segmented NMS algorithm and id information to distinguish mutually occluded pedestrians. Jia- liang Zhang [124] et al. proposed an attribute-aware pedestrian detec- tor, which transformed pedestrian detection into high-level feature detection. In addition to semantic information and location, pedestrian attribute features were also introduced to represent the differences be- tween pedestrians. In 2022, the OAF-Net proposed by Qiming Li and Yijing Su [125] et al., uses the occlusion perception detection head to detect pedestrians with different occlusion levels. The occlusion perception detection head contains three central prediction branches with different occlusion levels, and selects the most appropriate branch according to the pedestrian occlusion level. Yu Zhang [126] et al. pro- posed an anchor-free method (CSPRS) combining pedestrian detector CSP, region resolution learning and segmentation learning. Xinchen Lin
[127] et al. proposed a scale-refined CSP model (SASR-CSP). SASR-CSP
establishes a regression branch refinement scale through the distance between the candidate box center and the edge of the image, which can improve the prediction results and accuracy when the predicted center deviates from the actual situation. The model is shown in Fig. 15. Qiming Li [128] et al. proposed Bi-Center Detector to solve the occlusion




Fig. 13. PRF-Ped Framework(image from literature [112]).




Fig. 14. SA-DPM Framework(image from literature [121]).


Fig. 15. SASR-CSP Framework(image from literature [127]).


problem. The first center prediction branch downweights the occluded part around the center of the occluded pedestrian according to the de- gree of occlusion. The second center prediction branch integrates the pedestrian occlusion ratio into the Gaussian mask of center ground truth. Zhuowei Wang [129] et al. proposed a multi-branch detection network based on triggered attention (MBDN). MBDN predicts the center points of the upper, middle and lower pedestrian respectively
through three prediction branches. Yang Wang and Qiming Li’s method still has good results in crowd scenes. Yu Zhang and Qiming Li’s method still performs well in severe occlusion.

Based on other methods

In addition to the methods introduced in the previous sections, some other researchers have proposed new occluded pedestrian detection methods. In 2019, some researchers generated saliency maps to elimi- nate background interference on occluded pedestrians to improve detection accuracy. Inyong Yun [130] et al. used saliency and bounding box alignment for pedestrian detection. The model uses saliency to eliminate false positives such as trees, knots FCN and CAM to improve the resolution of the confidence map and successfully recall missing body parts. Wei Wei [131] et al. used MobileNet for detection and positioning to balance detection speed and detection accuracy, intro- duced binocular depth information to reduce the influence of clutters,
and used the saliency of depth map to distinguish pedestrians to improve detection accuracy. Chunluan Zhou [132] et al. proposed a discrimi- native feature transformation to solve the pedestrian occlusion problem. In the feature space, the pedestrian example was close to the center of the easily classified non-occlusion pedestrian example and the back- ground example was pushed to the easily classified background example, and a new network was constructed by combining Faster RCNN. Lijun Xu [133] et al. proposed to improve the accuracy of pedestrian detection by using edge perception, and proposed a new edge perception pool module to extract edge maps from trained EDS and fuse them with features to obtain more detailed pedestrian contour infor- mation. Yuting Xu [134] et al. used deep Omega shape feature to represent pedestrians. The multi-path detection and online hard example mining were introduced to reduce the impact of scale change and clutter background, and a non-maximum suppression method with boot-up strategy was designed to improve the detection performance under partial occlusion. Chunze Lin [135] et al. parallel multi-scale networks and human parsing generator. The multi-scale network uses multi-granularity features to detect and select the most appropriate feature map to predict the pedestrian at the corresponding scale. The human parsing generator generates fine-grained attention maps to guide the multi-scale network to pay more attention to the pedestrian visible area. In 2021, Yi Tang [136] et al. used data augmentation to improve pedestrian detection in crowded environments. Firstly, the data



augmentation strategy and loss function were represented by the prob- abilities of different hyperparameters respectively, and then an auto- matic pedestrian scheme was designed according to the automatic ML principle, and the double-loop scheme with importance sampling was used to optimize the data augmentation and loss function types. Tianrui Liu [137] et al. proposed a pedestrian detection method with a coupling network. The deformable occlusion processing sub-network adaptively adjusts the relative position of the body parts of the pooling grid by using the deformable region of interest pooling, so as to better adapt to the occluded pedestrians. Yifan Jiao [138] et al. proposed the Pose Embedded Pedestrian Detection Network (PEN), which generates a large number of candidate boxes and corresponding confidence scores through the region proposal network, and the pedestrian recognition network filters candidate boxes through pedestrian posture information and visual information. In 2022, Xiaolin Song [139] et al. proposed the Progressive Refinement Network (PRNet). The proposed confident perception anchor calibration method can adaptively initialize anchor points in the presence of occlusion. Wei Wei’s method has low latency
and fast response, and can be deployed in embedded devices. Chunluan
Zhou used discriminative feature transformation for pedestrian detec- tion and Yifan Jiao improved detection performance by embedding human pose information, both of which provided new ideas for others. Yuting Xu’s method has some limitations when detecting small-scale
pedestrians. Yi Tang’s method can be well applied to other detectors.
Xiaolin Song’s method is effective for different occlusions in different fields.

Conclusion

Pedestrian detection has always been a research hotspot in the field of computer vision. From manually designed feature descriptors com- bined with machine learning to the now widely used deep learning methods, pedestrian detection has made great progress in detection accuracy and detection speed, but there are still many problems and challenges waiting for us. This paper discusses the pedestrian detection methods proposed in the past, and introduces some newly proposed pedestrian detection algorithms after the 2019 years in terms of hand- crafted features and deep features. In addition, dozens of detection methods proposed to solve the scale problem and occlusion problem in pedestrian detection are discussed. In the past 4 years, the detection accuracy and detection speed of pedestrian detection have been signif- icantly improved. Researchers have done a lot of work. Aiming at the scale problem, some researchers use context information and attention mechanism to improve multi-scale pedestrian detection, some re- searchers improve the robustness of pedestrian detection for pedestrians at different scales by fusing multi-scale features, and some researchers fuse deep features and shallow features to enrich the semantic infor- mation and spatial features of features. The MR-2 index of MPAF-Net network with better performance on the Small, Medium and Large subsets of Cityperson dataset reaches 14.0%, 3.3% and 5.2%. For the occlusion problem, some researchers use pedestrian detection based on body parts to reduce the impact of occlusion. Some researchers use center point detection to transform pedestrian detection into high-level semantic feature detection, which effectively improves the detection accuracy in the presence of occlusion. Some researchers enhance feature representation through attention mechanism, context information and other methods to significantly improve the detection performance of occluded pedestrians. Some researchers introduce saliency map, edge perception and other methods to cope with occlusion. The MR-2 index of SA-DPM network with better performance reaches 30.18% in the severely occluded subset of Caltech dataset. However, there is still a big gap between the detection ability of pedestrian detection and human ability. In order to better apply pedestrian detection to unmanned driving, intelligent video surveillance and other fields, there is still a lot of work to be done:
Scale problem: Despite the rapid development of pedestrian
detection technology, the detection accuracy and detection speed have been greatly improved, but the scale problem of pedestrians is still a big challenge. Constructing multi-scale feature maps is a common method to deal with the scale problem of pedestrian detection. Deep feature maps often have rich semantic information, while shallow feature maps contain accurate positioning information, and fusing multi-scale feature maps can obtain more effective information. Exploring a better fusion method of multi-scale feature maps and designing a more reasonable and efficient pyramid structure are important ways to solve the multi- scale problem of pedestrian detection. At the same time, improving the representation ability of features by fusing features is also an effective way to deal with the scale problem. In the future, multiple attention mechanisms such as competitive attention can be explored for feature fusion. Multi-scale representation is an important solution to the problem of pedestrian detection scale. This method improves the detection performance while inevitably increasing the amount of calculation. How to balance the accuracy and calculation needs further exploration, and designing a more reasonable FPN structure is also worth studying. Context information improves the performance of pedestrian detection by enriching feature information, but not all context information can play a positive role in improving detection performance. How to select effective context information and be able to better insert it in the network is a direction worthy of research. Adding pre-processing and post-processing modules to the pedestrian detection framework can significantly improve the detection performance, such as Mosaic, flip, etc. Exploring more efficient pre-processing and post- processing methods is also an important way to improve the perfor- mance of the detector. Multi-task joint learning is also a good research direction, which can obtain richer visual information through multiple visual tasks. Therefore, how to effectively use multi-task joint learning to improve the accuracy of multi-scale pedestrian detection is a good research direction in the future. The method based on super-resolution is a new direction to solve the pedestrian scaling problem in recent years, and its biggest difficulty is the training of GAN network. How to balance the generator and discriminator is a direction to be explored in the future. Data augmentation strategies can reduce the negative impact of imbalanced data to improve detection performance. How to design efficient data augmentation strategies is also worth studying.
Occlusion problem: Pedestrian detection technology develops very
rapidly, and has a high detection accuracy under normal circumstances. However, when there is occlusion in the image, the detection accuracy is significantly reduced, especially in severe occlusion, pedestrian detec- tion can not maintain good robustness, which is still a huge challenge for us. Deep convolutional networks can extract higher dimensional pedestrian information, but some shallow information will be lost with the increase of dimension. The fusion of feature information of different dimensions can effectively improve the adverse impact of occlusion. Feature fusion has always been a common method to deal with occlu- sion. The fusion feature has rich information and strong representation ability. Exploring how to design an efficient feature fusion network is also an effective method to solve the occlusion problem. Pedestrian detection is only one task of computer vision, which also includes se- mantic segmentation and human pose estimation. Using other vision tasks to assist pedestrian detection is a way to improve the performance of occluded pedestrian detection, and the integration of multiple vision tasks is also an important research direction. In the future, the accuracy of occlusion pedestrian detection can be improved by exploring the degree of help of different body parts of pedestrians for occlusion detection to select the most appropriate body part for detection. At the same time, different training strategies will also affect the detection effect, and it is very important to explore efficient training strategies. Context information can make up for the lack of information in the invisible part, and how to design a more efficient context information extraction network can be explored in the future. Center-based pedes- trian detection can effectively improve the adverse effects caused by occlusion. In the future, whether the body part-based pedestrian



detection and center-based pedestrian detection can be combined, and the pedestrian body part is used as the center point to improve the robustness of occlusion pedestrian detection. At the same time, the ability of data augmentation, edge perception and other methods to improve occlusion can also be explored in the future, and the detection accuracy of occluded pedestrians can be improved by combining these methods.

Funding

National Natural Science Foundation of China (52274160, 52074305, 51874300); National Natural Science Foundation of China- Shanxi Joint Fund for Coal-Based Low-Carbon Technology (U1510115).

Declaration of competing interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

Data availability

No data was used for the research described in the article.

References

Wang X, Liu M, Raychaudhuri DS, et al. Learning person Re-identification models from videos with weak supervision. IEEE Trans Image Process 2021;30:3017–28.
Wang H, Du H, Zhao Y, et al. A comprehensive overview of person Re-
identification approaches. IEEE Access 2020;8:45556–83.
Xu X, Li X, Zhao H, et al. A real-time, continuous pedestrian tracking and positioning method with multiple coordinated overhead-view cameras. Measurement 2021:178.
Dimitrievski M, Veelaert P, Philips W. Behavioral pedestrian tracking using a camera and LiDAR sensors on a moving vehicle. Sensors 2019;19(2).
Wang CX, Cai SF, An G, et al. GraphTCN: spatio-temporal interaction modeling for human trajectory prediction. In: Proceedings of the IEEE Winter conference on applications of computer vision (WACV). Electr Network, F Jan 05-09; 2021 [C].
Xue H, Huynh DQ, Reynolds M. PoPPL: pedestrian trajectory prediction by LSTM
with automatic route class clustering. IEEE Transact Neural Networks Learn Syst 2021;32(1):77–90.
Mhalla A, Chateau T, Gazzah S, et al. An embedded computer-vision system for
multi-object detection in traffic surveillance. IEEE Trans Intell Transport Syst 2019;20(11):4006–18.
Yang L, Hu G, Song Y, et al. Intelligent video analysis: a Pedestrian trajectory
extraction method for the whole indoor space without blind areas. Computer Vision And Image Understanding 2020:196.
Du Y, Hetherington NJ, Oon CL, et al. Group surfing: a pedestrian-based approach to sidewalk robot navigation. In: Proceedings of the IEEE international conference on robotics and automation (ICRA). Montreal: CANADA, F May 20-24; 2019 [C].
Li T, Ma Y, Shen H, et al. FPGA implementation of real-time pedestrian detection using normalization-based validation of adaptive features clustering. IEEE Trans
Veh Technol 2020;69(9):9330–41.
Robin C, Lacroix S. Multi-robot target detection and tracking: taxonomy and survey. Aut Robots 2016;40(4):729–60.
Qiao Z, Zhao L, Gu L, et al. Research on abnormal pedestrian trajectory detection
of dynamic crowds in public scenarios. IEEE Sensor J 2021;21(20):23046–54.
Viola P, Jones MJ, Snow D. Detecting pedestrians using patterns of motion and appearance. Int J Comput Vis 2005;63(2):153–61.
Dalal N, Triggs B. Histograms of oriented gradients for human detection. In:
Proceedings of the 2005 IEEE computer society conference on computer vision and pattern recognition, CVPR 2005, June 20, 2005 - June 25, 2005. San Diego, CA, United states, F: IEEE Computer Society; 2005 [C].
Dollar P, Tu Z, Perona P, et al. Integral channel features. In: Proceedings of the 2009 20th British machine vision conference, BMVC 2009, september 7, 2009 - september 10, 2009,. London, United kingdom, F: British Machine Vision Association, BMVA; 2009 [C].
Redmon J, Divvala S, Girshick R, et al. You only look once: unified, real-time object detection. In: Proceedings of the 29th IEEE conference on computer vision and pattern recognition, CVPR 2016, June 26, 2016 - July 1, 2016, Las Vegas, NV, United States, F. IEEE Computer Society; 2016 [C].
Redmon J, Farhadi A. Ieee. YOLO9000: better, faster, stronger; proceedings of the 30th IEEE/CVF conference on computer vision and Pattern recognition (CVPR), Honolulu, HI, F Jul 21-26. 2017 [C].
Redmon J, Farhadi A. YOLOv3: an incremental improvement. 2018 [M]. arXiv.
Liu W, Anguelov D, Erhan D, et al. SSD: single shot multibox detector. In: Proceedings of the 14th European conference on computer vision, ECCV 2016,
October 8, 2016 - October 16, 2016, Amsterdam, Netherlands, F. Springer Verlag;
2016 [C].
Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation. In: Proceedings of the 27th IEEE conference on computer vision and pattern recognition, CVPR 2014, June 23, 2014 - June 28, 2014, columbus, OH, United States, F. IEEE Computer Society; 2014 [C].
Girshick R. Fast R-CNN. In: Proceedings of the 15th IEEE international conference on computer vision, ICCV 2015, December 11, 2015 - December 18, 2015, santiago, Chile, F. Institute of Electrical and Electronics Engineers Inc; 2015 [C].
Ren S, He K, Girshick R, et al. Faster R-CNN: towards real-time object detection
with region proposal networks. IEEE Trans Pattern Anal Mach Intell 2017;39(6): 1137–49.
Cai Z, Fan Q, Feris RS, et al. A unified multi-scale deep convolutional neural
network for fast object detection. In: Proceedings of the 21st ACM conference on computer and communications security, CCS 2014, November 3, 2014 - November 7, 2014, scottsdale, AZ, United States, F. Springer Verlag; 2016 [C].
Bochkovskiy A, Wang C-Y, Liao H-YM. YOLOv4: optimal speed and accuracy of object detection. 2020 [M]. arXiv.
Liu W, Hasan I, Liao S. Center and scale prediction: anchor-free approach for pedestrian and face detection. 2019 [M]. arXiv.
Li J, Liang X, Shen S, et al. Scale-aware fast R-CNN for pedestrian detection. IEEE Trans Multimed 2018;20(4):985–96.
Dollar P, Wojek C, Schiele B, et al. Pedestrian detection: a benchmark;
proceedings of the 2009 IEEE conference on computer vision and Pattern recognition, CVPR 2009, June 20, 2009 - June 25, 2009. Miami, FL, United states, F: IEEE Computer Society; 2009 [C].
Geiger A, Lenz P, Urtasun R. Are we ready for autonomous driving? the KITTI vision benchmark suite. In: Proceedings of the 2012 IEEE conference on computer vision and pattern recognition, CVPR 2012, June 16, 2012 - June 21, 2012, providence, RI, United States, F. IEEE Computer Society; 2012 [C].
Zhang S, Benenson R, Schiele B. CityPersons: a diverse dataset for pedestrian detection. In: Proceedings of the 30th IEEE conference on computer vision and pattern recognition, CVPR 2017, July 21, 2017 - July 26, 2017, Honolulu, HI, United States, F. Institute of Electrical and Electronics Engineers Inc; 2017 [C].
Li W, Ruan M, Guo X, et al. A novel architecture of pedestrian detection. In: Proceedings of the IEEE int conf on parallel and Distributed processing with applications, big data and cloud computing, sustainable computing and communications, social computing and networking (ISPA/BDCloud/SocialCom/ SustainCom), Xiamen, PEOPLES R China, F Dec 16-18; 2019 [C].
Kumar K, Mishra RK. A robust mRMR based pedestrian detection approach using shape descriptor. Trait Du Signal 2019;36(1):79–85.
Yang M, Qian Y, Xue L, et al. G2P: a new descriptor for pedestrian detection.
Neural Comput Appl 2020;32(9):4665–74.
Lian G. Pedestrian detection using quaternion gradient based weber local descriptor. IEEE Access 2021;9:43675–83.
Pfeifer L. Shearlet features for pedestrian detection. J Math Imag Vis 2019;61(3):
292–309.
Jiang Y, Tong G, Yin H, et al. A pedestrian detection method based on genetic
algorithm for optimize XGBoost training parameters. IEEE Access 2019;7: 118310–21.
Xie Z, Yang R, Guan W, et al. A novel descriptor for pedestrian detection based on
multi-layer feature fusion. In: Proceedings of the IEEE international conference on real-time computing and robotics (IEEE-RCAR), electr network, F sep 28-29; 2020 [C].
Kumar K, Mishra RK. A heuristic SVM based pedestrian detection approach employing shape and texture descriptors. Multimed Tool Appl 2020;79(29–30): 21389–408.
Zhou H, Yu G. Research on pedestrian detection technology based on the SVM
classifier trained by HOG and LTP features. Future Generation Computer Systems- the International Journal Of Escience 2021;125:604–15.
Liu D, Zang K, Shen J. A shallow-deep feature fusion method for pedestrian
detection. Applied Sciences-Basel 2021;11(19).
Liu W, Liao S, Ren W, et al. High-level semantic feature detection: a new perspective for pedestrian detection. In: Proceedings of the 32nd IEEE/CVF conference on computer vision and pattern recognition (CVPR), long Beach, CA, F Jun 16-20; 2019 [C].
Zhang T, Cao Y, Zhang L, et al. Efficient feature fusion network based on center and scale prediction for pedestrian detection. Visual Computer; 2022.
Cao J, Song C, Peng S, et al. Pedestrian detection algorithm for intelligent vehicles in complex scenarios. Sensors 2020;20(13).
Lv H, Yan H, Liu K, et al. YOLOv5-AC: attention mechanism-based lightweight YOLOv5 for track pedestrian detection. Sensors 2022;22(15).
Liu W, Liao S, Hu W. Efficient single-stage pedestrian detector by asymptotic localization fitting and multi-scale context encoding. IEEE Trans Image Process
2020;29:1413–25.
Saeidi M, Ahmadi A. High-performance and deep pedestrian detection based on estimation of different parts. J Supercomput 2021;77(2):2033–68.
Murthy CB, Hashmi MF, Keskar AG. Optimized MobileNet plus SSD: a real-time
pedestrian detection on a low-end edge device. International Journal Of Multimedia Information Retrieval 2021;10(3):171–84.
Zhang Y, He H, Li J, et al. Variational pedestrian detection. In: Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition (CVPR). Electr Network, F Jun 19-25; 2021 [C].



Brazil G, Liu X, Soc IC. Pedestrian detection with autoregressive network phases. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR), long Beach, CA, F Jun 16-20; 2019 [C].
Fu Z, Chen Y, Jiang R. See extensively while focusing on the core area for pedestrian detection. IEEE Access 2019;7:27017–25.
Ren J, Han J. A new multi-scale pedestrian detection algorithm in traffic
environment. Journal Of Electrical Engineering & Technology 2021;16(2): 1151–61.
Tesema FB, Wu H, Chen M, et al. Hybrid channel based pedestrian detection.
Neurocomputing 2020;389:1–8.
Ruihaoyin IEEE. MULTI-RESOLUTION generative adversarial networks for tiny- scale pedestrian detection. In: Proceedings of the 26th IEEE international conference on image processing (ICIP), Taipei, TAIWAN, F sep 22-25; 2019 [C].
Yu P, Zhao Y, Zhang J, et al. Pedestrian detection using multi-channel visual feature fusion by learning deep quality model. J Vis Commun Image Represent 2019:63.
Lin Z, Pei W, Chen F, et al. Pedestrian detection by exemplar-guided contrastive learning. IEEE transactions on image processing : a publication of the IEEE Signal Processing Society; 2022.
Xie H, Zheng W, Shin H. Occluded pedestrian detection techniques by deformable attention-guided network (DAGN). Applied Sciences-Basel 2021;11(13).
Papageorgiou C, Poggio T. A trainable system for object detection. Int J Comput Vis 2000;38(1):15–33.
Hwang S, Park J, Kim N, et al. Multispectral pedestrian detection: benchmark
dataset and baseline. In: Proceedings of the IEEE conference on computer vision and pattern recognition, CVPR 2015, June 7, 2015 - June 12, 2015, Boston, MA, United States, F. IEEE Computer Society; 2015 [C].
Braun M, Krebs S, Flohr F, et al. EuroCity persons: a novel benchmark for person detection in traffic scenes. IEEE Trans Pattern Anal Mach Intell 2019;41(8):
1844–61.
Enzweiler M, Gavrila DM. Monocular pedestrian detection: survey and experiments, F. IEEE Computer Society; 2009 [C].
Overett G, Petersson L, Brewer N, et al. A new pedestrian dataset for supervised learning; proceedings of the 2008 IEEE Intelligent Vehicles Symposium, IV, June 4, 2008 - June 6, 2008. Eindhoven, Netherlands, F: Institute of Electrical and Electronics Engineers Inc; 2008 [C].
Ess A, Leibe B, Van Gool L. Depth and appearance for mobile scene analysis. In: Proceedings of the 2007 IEEE 11th international conference on computer vision, ICCV, October 14, 2007 - October 21, 2007, Rio de Janeiro, Brazil, F. Institute of Electrical and Electronics Engineers Inc; 2007 [C].
Shao S, Zhao Z, Li B, et al. CrowdHuman: a benchmark for detecting human in a crowd. 2018 [M]. arXiv.
Zhang S, Xie Y, Wan J, et al. WiderPerson: a diverse dataset for dense pedestrian detection in the wild. IEEE Trans Multimed 2020;22(2):380–93.
Xie H, Chen Y, Shin H. Context-aware pedestrian detection especially for small-
sized instances with Deconvolution Integrated Faster RCNN (DIF R-CNN). Appl Intell 2019;49(3):1200–11.
Hu J, Jin L, Gao S, et al. FPN plus plus : a simple baseline for pedestrian detection.
In: Proceedings of the IEEE international conference on multimedia and expo (ICME), Shanghai, PEOPLES R China, F Jul 08-12; 2019 [C].
Zhang C, Kim J. Multi-scale pedestrian detection using skip pooling and recurrent convolution. Multimed Tool Appl 2019;78(2):1719–36.
Yang X, Liu Q. Scale-sensitive feature reassembly network for pedestrian
detection. Sensors 2021;21(12).
Chen Z, Zhang L, Khattak AM, et al. Deep feature fusion by competitive attention for pedestrian detection. IEEE Access 2019;7:21981–9.
Lin C, Lu J, Wang G, et al. Graininess-aware deep feature learning for robust
pedestrian detection. IEEE Trans Image Process 2020;29:3820–34.
Feng TT, Ge HY. Pedestrian detection based on attention mechanism and feature enhancement with SSD; proceedings of the 5th international conference on communication, image and signal processing (CCISP), chengdu, PEOPLES R
China. F Nov 2020;13–15 [C].
Ma J, Wan H, Wang J, et al. An improved one-stage pedestrian detection method based on multi-scale attention feature extraction. Journal of Real-Time Image
Processing 2021;18(6):1965–78.
Zhang X, Cao S, Chen C. Scale-aware hierarchical detection network for pedestrian detection. IEEE Access 2020;8:94429–39.
Zhao Y, Shi F, Zhao M, et al. Detecting small scale pedestrians and
anthropomorphic negative samples based on light-field imaging. IEEE Access 2020;8:105082–93.
Cao Z, Yang H, Xu W, et al. Multiscale anchor-free region proposal network for
pedestrian detection. Wireless Commun Mobile Comput 2021;2021.
Hsu W-Y, Lin W-Y. Adaptive fusion of multi-scale YOLO for pedestrian detection. IEEE Access 2021;9:110063–73.
Ding L, Wang Y, Laganiere R, et al. Learning efficient single stage pedestrian
detection by squeeze-and-excitation network. Neural Comput Appl 2021;33(23): 16697–712.
Li Q, Qiang H, Li J. Conditional random fields as message passing mechanism in
anchor-free network for multi-scale pedestrian detection. Inf Sci 2021;550:1–12.
Yan C, Zhang H, Li X, et al. R-SSD: refined single shot multibox detector for pedestrian detection. Appl Intell 2022;52(9):10430–47.
Ren J, Niu C, Han J. An IF-RCNN algorithm for pedestrian detection in pedestrian
tunnels. IEEE Access 2020;8:165335–43.
Han B, Wang Y, Yang Z, et al. Small-scale pedestrian detection based on deep neural network. IEEE Trans Intell Transport Syst 2020;21(7):3046–55.
Murthy CB, Hashmi MF, Muhammad G, et al. YOLOv2PD: an efficient pedestrian detection algorithm using improved YOLOv2 model. Cmc-Computers Materials &
Continua 2021;69(3):3015–31.
Xia H, Wan H, Ou J, et al. MAFA-net: pedestrian detection network based on multi-scale attention feature aggregation. Appl Intell 2022;52(7):7686–99.
He Y, He N, Zhang R, et al. Multi-scale feature balance enhancement network for
pedestrian detection. Multimed Syst 2022;28(3):1135–45.
Yang P, Zhang G, Wang L, et al. A part-aware multi-scale fully convolutional
network for pedestrian detection. IEEE Trans Intell Transport Syst 2021;22(2): 1125–37.
Zhou C, Wu M, Lam S-K. Enhanced multi-task learning architecture for detecting
pedestrian at far distance. IEEE Trans Intell Transport Syst 2022;23(9): 15588–604.
Pang Y, Cao J, Wang J, et al. JCS-net: joint classification and super-resolution
network for small-scale pedestrian detection in surveillance images. IEEE Trans Inf Forensics Secur 2019;14(12):3322–31.
Wu J, Zhou C, Zhang Q, et al. Self-mimic learning for small-scale pedestrian
detection. In: Proceedings of the 28th ACM international conference on multimedia (MM), electr network, F Oct 12-16; 2020 [C].
Zhang H, Hu Z, Hao R. Joint information fusion and multi-scale network model for pedestrian detection. Vis Comput 2021;37(8):2433–42.
Murthy CB, Hashmi MF, Keskar AG. EfficientLiteDet: a real-time pedestrian and
vehicle detection algorithm. Mach Vis Appl 2022;33(3).
Wang J, Li H, Yin S, et al. Research on improved pedestrian detection algorithm based on convolutional neural network. In: Proceedings of the IEEE int congr on cybermat/12th IEEE int conf on cyber, phys and social comp (CPSCom)/15th IEEE int conf on green computing and communications (GreenCom)/12th IEEE int conf on internet of things (iThings)/5th IEEE int conf on smart data, Atlanta, GA, F Jul 14-17; 2019 [C].
Zhang S, Yang X, Liu Y, et al. Asymmetric multi-stage CNNs for small-scale pedestrian detection. Neurocomputing 2020;409:12–26.
Wang X, Liang C, Chen C, et al. (SD)-D-3: scalable pedestrian detection via score
scale surface discrimination. IEEE Trans Circ Syst Video Technol 2020;30(10): 3332–44.
Lin C-Y, Xie H-X, Zheng H. PedJointNet: joint head-shoulder and full body deep
network for pedestrian detection. IEEE Access 2019;7:47687–97.
Gu J, Lan C, Chen W, et al. Joint pedestrian and body Part Detection via semantic relationship learning. Applied Sciences-Basel 2019;9(4).
Zhou C, Yuan J. Multi-label learning of part detectors for occluded pedestrian detection. Pattern Recogn 2019;86:99–111.
Islam MM, Newaz AAR, Gokaraju B, et al. Pedestrian detection for autonomous
cars: occlusion handling by classifying body parts. In: Proceedings of the IEEE international conference on systems, man, and cybernetics (SMC). Electr Network, F Oct 11-14; 2020 [C].
Zhang S, Chen D, Yang J, et al. Guided attention in CNNs for occluded pedestrian detection and Re-identification. Int J Comput Vis 2021;129(6):1875–92.
Ding J, Liu T, Zhao Y, et al. HAPNet: a head-aware pedestrian detection network
associated with the affinity field. Sci China Inf Sci 2022;65(6).
Abdelmutalab A, Wang C. Pedestrian detection using MB-CSP model and boosted
identity aware non-maximum suppression. IEEE Trans Intell Transport Syst 2022; 23(12):24454–63.
Fei C, Liu B, Chen Z, et al. Learning pixel-level and instance-level context-aware
features for pedestrian detection in crowds. IEEE Access 2019;7:94944–53.
Susutti W, Lursinsap C, Sophatsathit P. Pedestrian detection by using weighted
channel features with hierarchical region reduction. Journal Of Signal Processing Systems for Signal Image And Video Technology 2019;91(6):587–608.
Li Z, Chen Z, Wu QMJ, et al. Pedestrian detection via deep segmentation and
context network. Neural Comput Appl 2020;32(10):5845–57.
Zhai S, Dong S, Shang D, et al. An improved faster R-CNN pedestrian detection
algorithm based on feature fusion and context analysis. IEEE Access 2020;8: 138117–28.
Jiang H, Liao S, Li J, et al. Urban scene based semantical modulation for
pedestrian detection. Neurocomputing 2022;474:1–12.
Liu Z, Song X, Feng Z, et al. Global context-aware feature extraction and visible
feature enhancement for occlusion-invariant pedestrian detection in crowded scenes. Neural Process Lett 2023;55(1):803–17.
Liu S, Guo H, Hu J-G, et al. A novel data augmentation scheme for pedestrian
detection with attribute preserving GAN. Neurocomputing 2020;401:123–32.
Xie J, Pang Y, Khan MH, et al. Mask-guided attention network and occlusion- sensitive hard example mining for occluded pedestrian detection. IEEE Trans
Image Process 2021;30:3872–84.
Jin Y, Zhang Y, Cen Y, et al. Pedestrian detection with super-resolution reconstruction for low-quality image. Pattern Recogn 2021:115.
Zhang Y, Bai Y, Ding M, et al. KGSNet: key-point-guided super-resolution network for pedestrian detection in the wild. IEEE Transact Neural Networks Learn Syst
2021;32(5):2251–65.
Zhang T, Han Z, Xu H, et al. CircleNet: reciprocating feature adaptation for robust pedestrian detection. IEEE Trans Intell Transport Syst 2020;21(11):4593–604.
Ruan B, Zhang C. Occluded pedestrian detection combined with semantic
features. IET Image Process 2021;15(10):2292–300.
Tan Y, Yao H, Li H, et al. PRF-ped: multi-scale pedestrian detector with prior- based receptive field. In: Proceedings of the 25th international conference on pattern recognition (ICPR). Electr Network, F Jan 10-15; 2021 [C].
Yang G, Wang Z, Zhuang S, et al. PFF-CB: multiscale occlusion pedestrian detection method based on PFF and CBAM. Comput Intell Neurosci 2022;2022.



Wang J, Zhao C, Huo Z, et al. High quality proposal feature generation for crowded pedestrian detection. Pattern Recogn 2022:128.
Qin Y, Qian Y, Wei H, et al. FE-CSP: a fast and efficient pedestrian detector with center and scale prediction. J Supercomput 2023;79(4):4084–104.
Yin R, Zhang R, Zhao W, et al. DA-net: pedestrian detection using dense
connected block and attention modules. IEEE Access 2020;8:153929–40.
Zou T, Yang S, Zhang Y, et al. Attention guided neural network models for occluded pedestrian detection. Pattern Recogn Lett 2020;131:91–7.
Shao X, Wang Q, Yang W, et al. Multi-scale feature pyramid network: a heavily
occluded pedestrian detection network based on ResNet. Sensors 2021;21(5).
Xie J, Pang Y, Cholakkal H, et al. PSC-Net: learning part spatial co-occurrence for occluded pedestrian detection. Sci China Inf Sci 2021;64(2).
He Y, Zhu C, Yin X-C. Occluded pedestrian detection via distribution-based
mutual-supervised feature learning. IEEE Trans Intell Transport Syst 2022;23(8): 10514–29.
Luo Y, Zhang C, Lin W, et al. Sequential attention-based distinct Part Modeling for
balanced pedestrian detection. IEEE Trans Intell Transport Syst 2022;23(9): 15644–54.
Zhang T, Ye Q, Zhang B, et al. Feature calibration network for occluded
pedestrian detection. IEEE Trans Intell Transport Syst 2022;23(5):4151–63.
Wang Y, Han C, Yao G, et al. MAPD: an improved multi-attribute pedestrian detection in a crowd. Neurocomputing 2021;432:101–10.
Zhang J, Lin L, Zhu J, et al. Attribute-aware pedestrian detection in a crowd. IEEE
Trans Multimed 2021;23:3085–97.
Li Q, Su Y, Gao Y, et al. OAF-net: an occlusion-aware anchor-free network for
pedestrian detection in a crowd. IEEE Trans Intell Transport Syst 2022;23(11): 21291–300.
Zhang Y, Wang H, Liu Y, et al. Region resolution learning and region
segmentation learning with overall and body Part Perception for pedestrian detection. Electronics 2022;11(6).
Lin X, Zhao C, Zhang C, et al. Self-attention-guided scale-refined detector for pedestrian detection. Complex & Intelligent Systems; 2022.
Li Q, Bi Y, Cai R, et al. Occluded pedestrian detection through bi-center prediction in anchor-free network. Neurocomputing 2022;507:199–207.
Wang Z, Lin W, Cheng L, et al. Multi-branch detection network based on trigger
attention for pedestrian detection under occlusion. Applied Intelligence; 2022.
Yun I, Jung C, Wang X, et al. Part-level convolutional neural networks for pedestrian detection using saliency and boundary box AlignmentD. IEEE Access 2019;7:23027–37.
Wei W, Cheng L, Xia Y, et al. Occluded pedestrian detection based on depth vision significance in biomimetic binocular. IEEE Sensor J 2019;19(23):11469–74.
Zhou C, Yang M, Yuan J, et al. Discriminative feature transformation for occluded
pedestrian detection. In: Proceedings of the IEEE/CVF international conference on computer vision (ICCV), seoul, South Korea, F Oct 27-Nov 02; 2019 [C].
Xu L, Yan S, Chen X, et al. Motion recognition algorithm based on deep edge-
aware pyramid pooling network in human-computer interaction. IEEE Access 2019;7:163806–13.
Xu Y, Zhou X, Liu P, et al. Rapid pedestrian detection based on deep omega-shape
features with partial occlusion handing. Neural Process Lett 2019;49(3):923–37.
Lin C, Lu J, Zhou J. Multi-grained deep feature learning for robust pedestrian detection. IEEE Trans Circ Syst Video Technol 2019;29(12):3608–21.
Tang Y, Li B, Liu M, et al. AutoPedestrian: an automatic data augmentation and
loss function search scheme for pedestrian detection. IEEE Trans Image Process 2021;30:8483–96.
Liu T, Luo W, Ma L, et al. Coupled network for robust pedestrian detection with
gated multi-layer feature extraction and deformable occlusion handling. IEEE Trans Image Process 2021;30:754–66.
Jiao Y, Yao H, Xu C. PEN: pose-embedding network for pedestrian detection. IEEE
Trans Circ Syst Video Technol 2021;31(3):1150–62.
Song X, Chen B, Li P, et al. PRNet plus plus : learning towards generalized occluded pedestrian detection via progressive refinement network. Neurocomputing 2022;482:98–115.
