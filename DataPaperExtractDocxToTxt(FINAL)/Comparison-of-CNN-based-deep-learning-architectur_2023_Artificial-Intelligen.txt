Artificial Intelligence in Agriculture 9 (2023) 22–35











Comparison of CNN-based deep learning architectures for rice diseases classification
Md Taimur Ahad a,⁎, Yan Li b, Bo Song c, Touhid Bhuiyan d
a Department of Computer Science and Engineering, Daffodil International University, Savar, Bangladesh
b School of Mathematics, Physics and Computing University of Southern Queensland, Toowoomba, Australia
c School of Engineering University of Southern Queensland, Toowoomba, Australia
d Department of Computer Science and Engineering, Faculty of Science and Information Technology, Daffodil International University, Bangladesh



a r t i c l e	i n f o


Article history:
Received 10 June 2022
Received in revised form 6 July 2023 Accepted 7 July 2023
Available online 14 July 2023


Keywords:
Deep learning
Convolutional neural networks (CNNs) Transfer learning
Plant leaf disease detection
a b s t r a c t

Although convolutional neural network (CNN) paradigms have expanded to transfer learning and ensemble models from original individual CNN architectures, few studies have focused on the performance comparison of the applicability of these techniques in detecting and localizing rice diseases. Moreover, most CNN-based rice disease detection studies only considered a small number of diseases in their experiments. Both these short- comings were addressed in this study. In this study, a rice disease classification comparison of six CNN-based deep-learning architectures (DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V, and Seresnext101) was conducted using a database of nine of the most epidemic rice diseases in Bangladesh. In ad- dition, we applied a transfer learning approach to DenseNet121, MobileNetV2, Resnet152V, Seresnext101, and an ensemble model called DEX (Densenet121, EfficientNetB7, and Xception) to compare the six individual CNN net- works, transfer learning, and ensemble techniques. The results suggest that the ensemble framework provides the best accuracy of 98%, and transfer learning can increase the accuracy by 17% from the results obtained by Seresnext101 in detecting and localizing rice leaf diseases. The high accuracy in detecting and categorisation rice leaf diseases using CNN suggests that the deep CNN model is promising in the plant disease detection domain and can significantly impact the detection of diseases in real-time agricultural systems. This research is significant for farmers in rice-growing countries, as like many other plant diseases, rice diseases require timely and early identification of infected diseases and this research develops a rice leaf detection system based on CNN that is ex- pected to help farmers to make fast decisions to protect their agricultural yields and quality.
© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).





Introduction

The observable success of convolutional neural networks (CNNs) has shifted the technology in detecting and localizing rice diseases using their leaves. Following the path, recent CNN studies suggest that the use of CNN has increased in rice leaf disease detection and segmentation (Chen et al., 2021; Patil and Kumar, 2022). Usually, a diseased rice leaf is covered with spots, colours, and diseased shapes (Mohanty et al., 2016). Thus, a diseased leaf which has a different colour texture and dimension than a healthy rice leaf provides an opportunity to perform image anal- ysis using a CNN network and to collect information on inconsistency among the pixels of the entire leaf (Mitkal et al., 2016; Xu et al., 2020). Each of the pixels of a leaf is expected to be similar concerning

* Corresponding author at: Department of Computer Science and Engineering, Daffodil International University, Savar, Bangladesh
E-mail addresses: MdTaimur.Ahad@usq.edu.au, taimurahad.cse@diu.edu.bd (M.T. Ahad).
any characteristic or available property, such as colour, intensity, or tex- ture. However, in a case where a small group of pixels differs from others, it provides information about inconsistency in an object or the presence of other objects.
Despite this fact, a handful of research efforts were devoted (Chen et al., 2018; Akhter et al., 2019; Islam et al., 2018; Sarker et al. 2016) in detecting rice disease using CNN, however, there are still gaps in the CNN-based rice leaf disease detection research. Firstly, as rice dis- eases are different from country to country, a comprehensive study on most of the epidemic diseases in a given country should be conducted. The number of types of rice diseases should be increased instead of using a few key classes (Acharya et al., 2020). Secondly, a study should inform whether original CNN architectures, transfer learning, or ensem- ble techniques can provide better accuracy for rice leaf disease detection. Consequently, this study aims to examine the success of original state-of-the-art CNN architectures, such as DenseNet121 (Huang et al., 2017), Inceptionv3 (Adegun and Viriri, 2021), MobileNetV2 (Nagasubramanian et al., 2020), resNext101 (Adegun and Viriri, 2021),


https://doi.org/10.1016/j.aiia.2023.07.001
2589-7217/© 2023 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/).



Resnet152V (Sankupellay and Konovalov, 2018) and Seresnext101 (Chen et al., 2018; He et al., 2015) in classifying the rice plant disease detection. The ultimate goal of this research is to reach the model that provides the highest accuracy rate in classifying rice leaf disease detection. Furthermore, this study also aims to conduct a transfer learning of DenseNet121, MobileNetV2, Resnet152V (Xie et al., 2017), and Seresnext101 (Chen et al., 2018) networks, and ensemble learning of Densenet121, EfficientNetB7, and Xception (Chollet, 2017) networks.
Another motivation to conduct this research is that rice disease de- tection is still preliminary among farmers in most developing countries with technical laggards. A commonly used method for rice disease de- tection is still manual visual inspection - simply using naked-eye obser- vation by trained experts (Mohanty et al., 2016). In doing so, a large team of experts, as well as continuous monitoring, are required. This is costly and time-consuming for poor farmers when a farm is large. On the other hand, in some countries, farmers do not have proper mecha- nisms or even have no idea that they can consult with experts. Manual plant disease identification is a more laborious task, subject to human errors, and can be done only in limited areas. Therefore, automatic de- tection techniques have become increasingly in demand.
The main contributions of this paper are as follows: firstly, this re- search provides a comparison of six original CNN architectures, namely DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V, and Seresnext101, using a dataset of the nine most epidemic rice diseases in Bangladesh. Secondly, we also applied a transfer learning approach on DenseNet121, MobileNetV2, Resnet152V, and Seresnext101 to conclude if transfer learning is capable of increasing accuracy, and thirdly, an ensembled model called DEX based on Densenet121, EfficientNetB7 and Xception networks were applied to draw a comparison among orig- inal, transfer learning, and ensemble techniques.

Literature review

This section reviews the related research work aiming at a deep- learning network model that can provide better accuracy for rice leaf disease detection. It includes an overview of the basic CNN networks and their various architectural structures. Several image processing technologies that were applied to rice leaf disease detection are also discussed.

Types of rice diseases

As a cereal grain, rice is the most widely consumed staple food for over half of the population in the world (Nguyen-Quoc and Hoang, 2020). Like many other developing countries, rice is the major source of income for rural farmers, especially in Bangladesh. Therefore, when rice production is hindered due to various rice diseases, it impacts the national economy.
Rice diseases are commonly involved in an abnormal physiological process that distorts the rice plant's normal structure, growth, and nu- trition. Each country, however, has different rice diseases that impact people differently (Acharya et al., 2020). For example, rice yellow mot- tle disease is not known to occur in other parts of the world, except Tanzania (Huang et al., 2017). Blast rice disease causes 11–15% yield loss annually (Adegun and Viriri, 2021). Sarker et al. reported that Sheath blight, a rice disease caused by Rhizoctonia solani, affects the crop in almost every season in Bangladesh. The disease reduces the quality of the rice as well as the quantity of the crop, which in turn af- fects the economy of a country like Bangladesh where agriculture is the main sector (Nagasubramanian et al., 2020). However, among all the rice diseases, the following are the most adverse rice diseases in Bangladesh (Sankupellay and Konovalov, 2018):
Bacterial Leaf Blight: Xanthomonas Oryzae Pvoryzae is responsible for bacterial leaf blight (BL), occurring mostly during the wet season,
especially when water overflows through rice fields. In some areas in Asia, it can reduce crop yield by up to 50%, even up to 80% (Chen et al., 2018).
Blight: Bacterial panicle blight, also known as blight, is caused by gram-negative bacterial pathogens Burkholderia glumae and
B. gladioli. It is a prevalent disease in many rice-growing regions glob- ally. The symptoms of bacterial panicle blight include several charac- teristic features. Panicle discolouration is a common symptom, where affected panicles may turn dark brown or black. Another symptom is grain rot, where the infected grains may exhibit decay or rotting. Additionally, sterile florets, which fail to produce viable seeds, are observed in affected panicles (Sainath et al., 2015; Zhu and Gong, 2018).
Brown Spot: Brown leaf spots are another serious rice disease world- wide, caused by Bipolaris Oryzae (Breda de Haan) Shoemaker. The symptoms are leaf spots throughout the growing season, mostly on the leaf blade, small spots of dark brown to reddish-brown, circular to oval in shape, while older spots have a light, reddish-brown or grey centre surrounded by a dark to reddish-brown margin (Zhu and Gong, 2018).
Hispa: Rice Hispa, scientifically known as Dicladispa Armigera, is a major pest that affects rice plants. It is commonly found during the tillering stage of rice growth, with higher populations observed at this stage. Rice Hispa feeds on the epidermis of the upper leaves, causing scraping damage. In the context of Sylhet, a region in Bangladesh, it is mentioned that Rice Hispa forms part of a large and contiguous population that extends into neighbouring Assam. This suggests that the pest is prevalent and poses a significant prob- lem in both areas (He et al., 2015).
Leaf Scald: Leaf scald, caused by Microdochium Oryzae, is a fungal dis- ease. This causes the scalded appearance of leaves. Zonate lesions of alternating light tan and dark brown starting from leaf tips or edges, oblong lesions with light brown halos in mature leaves. Individual le- sions are 15 cm long and 0.51 cm wide or may almost cover an entire leaf. The continuous enlargement and coalescing of lesions result in the blighting of a large part of the leaf blade.
Leaf Smut: Leaf smut, caused by the fungus Entyloma Oryzae, is a type of smut disease that affects rice plants. However, it does not pro- duce smut balls on spikelets. Instead, leaf smut causes dark brown to black lesions on the leaves of the rice plant. These lesions are com- posed of masses of fungal spores. False smut causes chalkiness of grains which leads to a reduction in grain weight. It also reduces seed germination. Velvety smut balls on spikelets, Spore balls are ini- tially orange and turn greenish black when mature, they are some identifiable symptoms of leaf smut. The second stage of infection oc- curs when the spikelet nearly reaches maturity.
Leaf Blast: Blast disease is a rice disease caused by Rhizoctonia solani. It affects the crop in almost every season in Bangladesh, causing 11–15% yield loss annually reported that Sheath blight. The disease reduces the rice quality as well as its quantity, which in turn affects the economy of a country like Bangladesh where agriculture is the main sector (Chen et al., 2018).
Shath Blight: Sheath blight is caused by the fungal pathogen Rhizoc- tonia solani. It is a widespread disease that affects rice plants in both temperate and tropical rice-growing regions. The typical symptoms of sheath blight manifest as oval to irregular lesions on the rice sheath (the protective covering of the stem) and leaf blades. These lesions typically have a greyish inner colour and a dark brown mar- gin. The distinct colouration helps in identifying and distinguishing the disease from other rice pathogens.
Tungro: Tungro is a viral disease that affects rice plants. It is distrib- uted in South and Southeast Asia, including Bangladesh. The disease is characterized by several characteristic features, such as stunted growth of the plant, twisted leaves, reduced tillering (formation of side shoots) and delayed flowering. The main vector responsible for the transmission of rice tungro virus is the green planthopper



(Nephotettix virus). In Bangladesh, susceptible rice varieties are par- ticularly susceptible to Tungro disease. Studies have shown that tungro incidences were common in susceptible cultivars, with re- corded incidence rates ranging from 85% to 81% in the south to northwest of the country. This indicates a significant impact of the disease on rice cultivation in these regions.

Convolutional neural networks
In CNNs, the term “convolutional” refers to the mathematical opera- tion of convolution, which combines two functions to produce a third function. In the context of CNNs, convolutional layers apply filters or ker- nels to the input data, resulting in the generation of feature maps. These feature maps capture different aspects or patterns in the input data.
CNNs consist of multiple layers arranged sequentially. The basic structure typically includes an input layer, followed by several convolutional layers, pooling layers, a fully connected layer, and finally an output layer. The convolutional layers are responsible for extracting features from the input data through the application of filters. The pooling layers help reduce the spatial dimensions of the feature maps, reducing computational complexity. The fully connected layer connects the extracted features to the output layer, allowing the network to make predictions or perform classification based on the learned features.
The input and output layers are considered the visible layers of the CNN, while the intermediate layers, such as convolutional and pooling layers, are referred to as hidden layers. These hidden layers play a cru- cial role in learning and extracting hierarchical representations from the input data. Overall, the combination of convolutional layers, pooling layers, and fully connected layers in CNNs allows the network to effec- tively learn and recognize patterns in complex data, making them par- ticularly well-suited for tasks such as image recognition and computer vision (Xie et al., 2017).

State-of-the-art CNN architectures. In this study, several CNN archi- tectures are divided into three broad categories, original, transfer learn- ing, and ensemble technique. The architecture of a basic CNN is given in Fig. 1.

Original CNN networks. An original CNN architecture in this re- search refers to a CNN network and algorithm that is available in
Keras or Github. In this research, a CNN algorithm is kept original as first proposed by its authors and programmers, with no change of pro- cessing units, parameters and hyper-parameter optimization strategies, design patterns and connectivity of layers. Often a well-known CNN network was developed and evolved by different researchers and pro- grammers through various challenges For example, the AlexNet archi- tecture was the winner of ILSVRC 2012 and was proposed by Krizhevsky et al., (Chollet, 2017) ResNet was proposed by He et al. (Chollet, 2017) from Microsoft and won 2015 ILSVRC. DenseNet as an extension of ResNet was first proposed in 2016 by Huang et al. from Facebook (Chollet, 2017; Patil and Kumar, 2022). Several original CNN architectures with the versions are discussed in the next sections:
DenseNet-121. DenseNet-121 architecture iteratively concat- enates the feature maps from one layer to another layer along the net- work, which is useful for classification tasks. The DenseNet-121 model was claimed better than MobileNetV2, ResNet50 and NASNet architec- tures (Shujaat et al., 2021).
Inception V3. Inception V3 developed by Google is the third release in the Deep Learning Evolutionary Architectures series. The In- ception V3 architecture, which has the Softmax function in the last layer, consists of 42 layers in total and the input layer takes images with 299 × 299 pixels.
MobileNetV2. Overall, MobileNetV2's design choices make it well-suited for deployment on resource-constrained mobile devices while maintaining competitive performance for various computer vi- sion tasks such as image classification, object detection, and semantic segmentation. One key feature of MobileNetV2 is the use of an inverted residual structure with residual connections between the bottleneck layers. Inverted residual blocks aim to reduce computational complexity while maintaining accuracy. The residual connections help in gradient flow and facilitate the training of deeper networks. The intermediate ex- pansion layer in MobileNetV2 incorporates lightweight depth-wise con- volutions (referred to as depth-wise separable convolutions) to introduce non-linearity and filter features efficiently. Depth-wise con- volutions separate the spatial and channel-wise convolutions, reducing the computational cost while retaining the expressive power of the net- work.
The architecture of MobileNetV2 typically starts with an initial fully convolutional layer with 32 filters. This layer processes the input data





Fig. 1. The architecture of a basic CNN.



and extracts initial features. It is followed by 19 residual bottleneck layers, which are the primary building blocks of the network. These bot- tleneck layers further refine and transform the features, utilizing the inverted residual structure and depth-wise convolutions (Shujaat et al., 2021).
ResNeXt. ResNeXt, short for Aggregated Residual Transform Network, is a CNN architecture that builds upon the concepts of Resid- ual Networks (ResNets) and Inception Networks. It introduces the idea of a split, transform, and merge block and emphasizes the concept of cardinality to improve performance. In ResNeXt, a split, transform, and merge block is used, where multiple transformations are applied within the block. These transformations help in learning diverse repre- sentations and capturing different levels of abstraction. The cardinality parameter is introduced to define the number of transformation paths within the block. Increasing cardinality has been shown to enhance the model's performance. ResNeXt has demonstrated impressive per- formance in various computer vision tasks, including image classifica- tion, object detection, and image segmentation. By combining the concepts of ResNets, Inception Networks, and cardinality-based trans- formations, ResNeXt achieves improved accuracy while maintaining computational efficiency. It's worth noting that the details of ResNeXt's architecture, such as the number of layers, cardinality, and block config- urations, may vary depending on specific implementations and varia- tions. Different versions of ResNeXt have been proposed to optimize the trade-off between performance and computational cost for different tasks and datasets (Patil and Kumar, 2022).
ResNet. ResNet, short for Residual Network, introduced the
concept of residual layers and skip connections to address the issue of vanishing gradients in deep neural networks. The main innovation of ResNet is the residual layer, which allows the network to learn residual mappings rather than attempting to learn the full mapping from the input to the desired output directly. By using residual layers, the net- work can more easily capture and propagate gradients through the net- work, even in very deep architectures. To facilitate the flow of gradients and address the vanishing gradient problem, ResNet incorporates skip connections, also known as shortcut connections or identity mappings. These connections enable the gradients to flow directly from the end layers to earlier layers, bypassing the intermediate layers. This allows the gradients to propagate more effectively, preventing them from diminishing or vanishing as they backpropagate through the network. The skip connections in ResNet also enable the network to be significantly deeper than previous architectures. ResNet models have been successfully built with depths of 50, 101, or even 152 layers. The ability to train and effectively optimize such deep networks has been a major advancement in the field of deep learning. By using residual layers and skip connections, ResNet mitigates the vanishing gradient problem and facilitates the training of very deep neural networks. This has led to improved performance and accuracy in various computer vi- sion tasks, including image classification, object detection, and image segmentation (Alegbejo et al., 2006; Ou, 1980).

Transfer learning. One approach, a transfer learning technique, is based on the knowledge gained from a training dataset and is used for training a different but relevant task or field (Weiss et al., 2016). In this deep learning process, the first few layers are trained to define the characteristics of the task. The last few layers of the trained network can be removed and retrained with new layers for the target task. It re- fers to the situation whereby what has been learned in one setting is adopted to improve the optimization in another setting. With limited computational requirements, ResNeXt-101 achieved state-of-the-art power and time speed (Albawi et al., 2017).
Training a deep learning model with a small dataset is often insuffi- cient for its model's performance. Transfer learning is a process of pre- initialize a model using the weights obtained by training a different model on a larger, different, dataset. In the work conducted by Karimi et al. (2021), it was reported that although transfer learning reduced
the training time on the target task, accuracy improvement depends on data quality. Large improvements are observed only when the seg- mentation task is more challenging and the target training data is smaller (Hossain et al., 2017).

Ensemble technique. Ensemble learning is one of the deep learning technologies that combine multiple primary learners through a fusion strategy to improve overall generalization performance (He et al., 2015). Ensemble learning has attracted a lot of attention because of its easy-to-understand structure and promising classification performance by combining more than one CNN model. Ensemble learning is a tech- nique that incorporates multiple models for final decision-making The ultimate goal of an ensemble is that by combining multiple models, the errors of a single model can be corrected (compensated for) by other models, making the overall score (prediction and classification) of the ensemble better than any individual participating model (Kawasaki et al., 2015).

Literature review

The literature review suggests that four approaches can be used for the automatic diagnosis of rice diseases.
The first approach to automatic rice disease detection is through conventional means, such as pattern recognition techniques (Chen et al., 2018; Akhter et al., 2019). The study by Phadikar Sil (Islam et al., 2018) proposed an approach to rice disease identification in which the diseased rice images were classified using a self-organizing map (SOM) (via a neural network) that extracted the train images character- istics of the infected parts of a leaf were obtained from the rice diseases, while four different types of images were used for testing purposes. Sat- isfactory classification results have been reported. Sarker et al. (2016) presented a technique that uses only one feature, namely red, green, and blue (RGB) values, to detect and classify rice diseases. Using image processing, a disease was identified based on percentages of RGB values of an affected region. After extracting the RGB percentages from the affected region and grouping them into different classes, they were fed into a simple classifier called Naive Bayes, which classified diseases into different categories. Three rice diseases were successfully detected and identified using this technique: rice, brown spot, rice blight and rice blast. This technique was efficient and faster because only one feature (RGB values) extracted from the affected area was used, requiring minimal computation time to identify and classify the diseases. Instead of processing the whole leaf, this technique was suc- cessful in detecting the diseases using only small parts.
The second method is to use a Support Vector Machine (SVM). For
example, Albawi et al. (2017); Hossain et al. (2017) used this method. Alfred et al. (2021) proposed an automated approach to classify rice plant diseases, brown spot diseases and leaf smut diseases based on their morphological changes. A total of 1000 spot images taken with a Nikon COOLPIX P4 digital camera of a rice field were used. Results were reported with 79.5% and 68.1% accuracy on the Bayesian and SVM classifiers, respectively. An SVM technique was also used by (Singh and Misra, 2017) for multiclass classification to identify three types of rice diseases (bacterial leaf blight, brown spot and leaf smut). The images of infected rice plants were taken with a digital camera from a paddy field and achieved an accuracy of 93.33% on the training data set and 73.33% on the test data set.
The third approach is the digital image processing techniques of McNeely-White et al. (2020); Atila et al. (2021); Chambon et al. (2021). Zhou et al. investigated a technique for assessing the extent of hop disease in rice crops, using a fuzzy C-means algorithm to classify re- gions into one of four classes: no disease, light disease, moderate dis- ease, and severe disease. Their study achieved an accuracy of 87% in distinguishing cases in which a planthopper did or did not occur, while the accuracy in distinguishing four groups was 63.5%. Chambon et al. (2021) was to identify and classify six types of mineral deficiencies



in rice. The study used features such as texture and colour for a devel- oped specific multi-layer neural network. Both networks consist of a hidden layer with a different number (40 for texture and 70 forcolourr) of neurons in the hidden layer, in which 88.56% of the pixels were cor- rectly classified. Similarly, the same authors proposed another similar work that successfully identified two types of diseases (blast and brown spot) affecting rice plants (Chambon et al., 2021).
The fourth approach is texture analysis and feature extraction using computer vision for enhancing the accuracy and rapidity of diagnosing the results. Phadikar and Sil (2008) developed an approach of texture analysis to identify four rice diseases (bacterial leaf blight, blast, brown spot and tungro virus) using fractal Fourier. In their proposed study, the image of a rice leaf was converted to CIELab colour space, and the system was able to achieve an accuracy of 92.5% (Phadikar and Sil, 2008). The features extracted from diseased and unaffected leaf images, the grey level co-occurrence matrix (GLCM) and the colour moment of the leaf lesion region were implemented by Lu et al. (2017) to create a 2-dimensional \\D feature vector and related features. Re- dundant features were eliminated with a genetic algorithm-based fea- ture selection method to generate 14-D feature vectors to minimize complexity. The technique has shown a promising result. However, to improve its detection accuracy, there is a need for more optimization procedures to take place. The key features of rice diseases, the brown spot and blast diseases, were described utilizing the colour of texture of rice leaf photos by Phadikar and Sil (2008). However, the efficiency of rice disease identification needs to be improved.
Phadikar et al. (2012), the entropy-based bipolar threshold tech- nique was employed for the segmentation of the image after improving its brightness and contrast. The author sought to integrate image pro- cessing and soft computing technique for the detection of rice plants attacked by several types of diseases. The idea behind the technique was robust when utilized effectively. However, the average accuracy of identification on the four datasets was 82% which indicated that more enhancement was still required. Image processing and machine learning methods were utilized to non-destructively screen seedlings with rickets (Islam et al., 2018). Moreover, genetic algorithms were em- ployed to develop SVM classifiers to optimize feature selection and model parameters for differentiating healthy seedlings and infected ones. The overall accuracy achieved in their study was 87.9%. Since a dis- ease may have several different symptoms at the same time, this ap- proach should be tested if other diseases are also present. It suggests that this approach has its limitations. Therefore, deep learning-based models became popular to detect diseases in various plants.
Singh and Singh (2010) study performed rice plant disease detection with a deep CNN. Using a VGGNet architecture, researchers at Chen et al. (2021) performed the classification of rice plant diseases. Chen et al. also proposed a CNN model, namely MobileNet Beta, by extending a pre-trained MobileNetV2 model to detect plant diseases (Chen et al., 2020). Too et al. reported that the DenseNet architecture achieved a high test accuracy of 99.75% (Praveen Kumar and Domnic, 2019). Geetharamani and Pandian trained a 9-layer CNN architecture using the PlantVillage dataset and achieved a classification accuracy of 96.46% using the test dataset (Too et al., 2019). Mohanty et al. (2016), on the other hand, used AlexNet and GoogLeNet to classify plant dis- eases and achieved a classification accuracy of 99.35% Geetharamani and Pandian (2019). Using the PlantVillage dataset, the Ferentinoss model of the VGG architecture delivered the highest accuracy at 99.53% (Arnal Barbedo, 2013).
Zhou et al. (2013) reported an automatic identification and diagno- sis of rice diseases using CNN as a deep learning method. Using a dataset of 500 natural images of diseased and healthy rice leaves and stems cap- tured from the rice experimental field, a CNN network was trained to identify 10 common rice diseases. Under the 10-fold cross-validation strategy, the proposed CNN-based model achieved an accuracy of 95.48%.
Sanyal and Patel (2008) suggested a faster R-CNN approach, which seemed to be ideal for the detection of rice diseases due to its good speed and high accuracy. Shrivastava et al. (2019) also applied a CNN al- gorithm for rice plant disease classification using a transfer learning of deep convolution neural network. Using an AlexNet CNN model, the model was able to classify rice diseases with a classification accuracy of 91.37%.
Asfarian et al. (2014) developed a CNN approach for detecting dis- eases and pests (five classes of diseases, three classes of pests, and one class of healthy plants and others) from rice plant images. A total num- ber of 1426 images were collected that were captured using four differ- ent types of cameras and the system achieved a mean validation accuracy of 94.33%.
Akhter et al. (2019) also suggested a new stacked CNN architecture that used two-stage training to substantially reduce the model size while retaining a high classification accuracy. Several CNN architectures, such as MobileNet, NasNet Mobile, and SqueezeNet, were used. Experi- mental results showed that the proposed architecture achieved the de- sired accuracy of 93.3% with a significantly reduced model size, for example, 99% smaller than that of VGG16.

3.1.1. Knowledge gap in rice LEAF disease detection using CNN
Despite the fact, Phadikar et al. (2012) observed that computer- aided rice disease detection and classification have received special at- tention, Asfarian et al. (2014) criticized for low accuracy rates using the rice disease detection models. Our literature review in this study also suggest that the classification accuracies by most of the existing methods are between 50% and 95% (Asfarian et al., 2014). Moreover, those achieving higher accuracies were usually tested with fewer dis- eases. The performance would deteriorate if more diseases were in- cluded. (Acharya et al., 2020) and (Huang et al., 2017) discussed the gap between the current capabilities of image-based methods for auto- matic rice disease identification and the real-world implementation needs.

Methodology

The experiments in this study were conducted based on Google CoLab using the Keras library. TensorFlow which is one of the best Py- thon deep learning libraries available for working with machine learn- ing methods on Python was used. In this study, the original, transfer learning and ensemble models were trained using google collab Tesla graphics processing unit (GPU). TPU is available through the Google Collaboratory framework by Google. Initially, the colab framework pro- vides up to 12 GB random access memory (RAM) and about 360 GB GPU in the cloud for research purposes.

Datasets

Data collection was the exceedingly cardinal quest for our research. We have put a vast effort to gather a great number of datasets. Since this research aimed to detect rice diseases, that mainly occurred in Bangladesh, most rice epidemic diseases found in the country were con- sidered. Therefore, the data collected from rice leaf images included a combination of the Rice Leaf Disease Dataset from the University of Cal- ifornia Irvine (UCI) Machine Learning Repository, a dataset from pub- licly available respiratory and a dataset collected from Bangladesh Rice Research Institute (BRRI). An example of rice leaves with various dis- eases is given in Fig. 2.
The final combined dataset contains nine (9) classes of rice diseases, with each class having one hundred (100) images for each type of disease. Images in the dataset are coloured images of various sizes and have a white background. The original images were divided into training and test sets with a ratio of 70:30 (see Table 1).



Process of experiments

The processes of the experiments are described in Fig. 3.
Image Acquisition: In this step, we downloaded the images from the targeted sites to provide as input. Images in the dataset were checked manually to identify if they had a white background. In the case where images (mainly from the BRRI) had coloured backgrounds, images were placed on a white background. If dis- ease symptoms such as spots, diseased colour, and diseased shape were not visible in an image, the image was removed from the dataset.
Image Augmentation: Image augmentation is used in this step. Image augmentation is the procedure by which an existing dataset is expanded by transforming the original dataset to cre- ate more new data, and in such a way that new data are also label-preserving (Sankupellay and Konovalov, 2018, Meeras Salman Al-Shemarry et al., 2019). The goal is to increase the var- iance of the dataset while ensuring that new data are meaningful and do not merely add unnecessary volume to the dataset (Sankupellay and Konovalov, 2018). When used in a machine- learning context, it can improve model generalization, make trained models more robust to unseen data, and increase model accuracy (Sankupellay and Konovalov, 2018).

With these aims, we conducted data augmentation in the training data. However, position augmentation such as scaling, cropping, flip- ping, rotation, and colour augmentation such as brightness, contrast, and saturation was deployed. Random rotation from −15 degrees to 15 degrees, rotations of multiple of 90 degrees at random, random dis- tortion, shear transformation, vertical flip, horizontal flip, skewing and intensity transformation were also used as part of the data augmenta- tion process. In this way, 10 augmented images from every original image have been created. Random choice of a subset of the transforma- tions helps augment an original image in a heterogeneous way.
In this study, each pixel value of images in the original and aug- mented images was first normalized dividing by 255. The images were then resized to a default size accepted by each model. In our experi- ment, input image resolutions were necessarily resized for all models of EfficientNet architecture due to our hardware limitations. Through trial and error, it was seen that the maximum allowed input size that our hardware resources were sufficient for the training of the EfficientNet model which has the highest number of parameters of 132 × 132. Therefore, the input size for all models of EfficientNet archi- tecture was set as 132 × 132 to evaluate all models under the same con- ditions. Table II summarizes the default image resolutions and the number of parameters defined for deep learning models.
Table 1
Images used in the train, test and validation sets.
Total images	Training images	Validation images Original Dataset	900	630	270
Augmented Dataset	42,876	34,992	7884



Training: A CNN learner model is created at this stage. By using DenseNet, EfficientNetB3, MobileNet, VGG16 and ResNet10 ar- chitectures, a model was trained based on the given dataset and then tested its classification accuracy.
All the models were trained for 175 epochs (iterations) with Early Stopping callbacks (patience = 10 iterations) Patience is the number of epochs with no improvement after which training will be stopped. An Adam optimizer, a combination of Stochastic Gradient Descent (SGD) with momentum and RMSProp (Root Mean Squared Propaga- tion, or RMSProp, is an extension of gradient descent and the AdaGrad version of gradient descent that uses a decaying average of partial gra- dients in the adaptation of the step size for each parameter.) were used for faster convergence with the parameters like learning rate was set at αα = 0.0001, β1β1 = 0.9, β2β2 = 0.999 and ϵ = 1 × 10 − 7ϵ = 1 × 10 − 7. The same optimizer was used for all three models and then the models were saved as .h5 files. The time taken for model training is −31 s (s)/epoch (Iterations) for DenseNet201 and 17 s/epoch for each of the models ResNet50V2 and Inceptionv3.
In this research standard deviation was used as a model performance metric since the dataset used in this experiment does not have any major imbalance. Categorical cross-entropy was used as a loss function for all CNN architectures since this work deals with multi-class classifi- cation. All intermediate layers of the CNN architectures used in this work have relu as the activation function while the activation function used in the last layer was softmax. The hyperparameters used are as fol- lows: the dropout rate was 0.3, the learning rate was 0.0001, the batch size was 64, and the number of epochs was 275. An adaptive moment estimation (Adam) optimizer was used for updating the model weights. All the images were resized to the default image size for each prior architecture.
Classiﬁcation: In this step, neural networks (DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V, resnext101, and Xception) were used in the automatic detection of leaf dis- eases. The neural network was chosen as a classification tool due to its well-known technique as a successful classifier for many real applications. After the training model, the evaluation model was built for rice disease detection based on the highest probability of occurrence, the images of rice leaves were classi- fied into different disease classes using a softmax output layer.





Fig. 2. Images examples of the rice diseases used.




Fig. 3. Process of experiments.


Experimental results

The results from the experiments are presented in three sections based on the architectures of original individual networks, transfer learning and ensemble techniques. The results obtained are expected to answer the following questions:
Which original CNN network provides better accuracy in detecting rice leaf disease?
Does transfer learning improve accuracy?
Does the ensemble technique improve the accuracy?

Several performance measures for machine learning classification models are used to assess how well those CNN base algorithms perform in a given context. The following performance metrics are considered:
many of the correctly predicted cases turned out to be positive. Preci- sion is a useful metric in cases where FP is a higher concern than FN. The formula of precision is given below (2):
Precision =  TP	(2)
TP + FP


Recall

Recall or Sensitivity is the accuracy of positively predicted instances describing how many were labelled correctly (Kawasaki et al., 2015). Recall tells us how many of the actual positive cases we were able to predict correctly with our model. The recall is a useful metric in cases where FN trumps FP. The formula of recall is given below (3):


Accuracy
F1 — score =	2
 1  +   1 
(3)

Recall  Precision

Accuracy is one metric for evaluating classification models. Infor- mally, accuracy is the fraction of predictions our model got right. For- mally, Accuracy is the ratio of correctly labelled images to the total number of samples (Kawasaki et al., 2015). The formula for accuracy is given below (1):
F1-score, as an additional measure for classification accuracy, con- siders both precision and recall. F1-score is a harmonic mean of Preci- sion and Recall, and so it gives a combined idea about these two metrics. It is maximum when Precision is equal to Recall.

Accuracy =	TP + TN
TP + FP + TN + FN


Precision

(1)
Specificity

Specificity refers to the ability of a diagnostic test to correctly iden- tify a rice leaf that is healthy or free from disease. It measures the per- centage of true negative results. A highly specific test has a low false positive rate. However, in case of a highly specific test can be interpreted

Precision is defined as the probability given a positive label, and how many of them are positive (Ferentinos, 2018). Precision tells us how
with confidence as a strong indication that the rice leaf is a diseased one. The equation is given below (4):




Specificity =	TN	(4)
TN + FP


Training loss and validation loss

Training loss is a measure of how well a model fits the training data. It quantifies the discrepancy between the predicted output of the model and the actual target values in the training set. The goal during training is to minimize this loss, which indicates that the model is learning to ac- curately represent the relationship between the input data and the cor- responding output targets.
Validation loss, on the other hand, assesses how well the model gen- eralizes to new, unseen data. It measures the discrepancy between the model's predictions and the true target values in a validation set or a portion of the training data that is held out for evaluation. The validation loss helps determine if the model has learned meaningful patterns or if it is overfitting.
Overfitting occurs when a model becomes too complex or too closely fits the training data. In such cases, the model may start capturing noise or irrelevant patterns from the training set, making it less effective at generalizing to new data. Overfitting is often characterized by a low training loss but a high validation loss, indicating that the model is not performing well on unseen data.
To combat overfitting, techniques such as regularization, dropout, and early stopping can be employed. Regularization methods help pre- vent the model from excessively fitting the training data by introducing penalties or constraints on the model's parameters. Dropout randomly deactivates a portion of the neurons during training, reducing the model's reliance on specific features or patterns. Early stopping stops the training process when the validation loss starts to increase, prevent- ing the model from further overfitting.
The aim is to strike a balance where the model minimizes both the training loss and the validation loss, indicating that it is learning mean- ingful patterns without overfitting the data. This ensures that the model generalizes well and performs accurately on unseen data.

Confusion matrix

A confusion matrix is a table that summarizes the results of a classi- fication model by comparing the predicted labels with the true labels of a dataset. It provides a comprehensive view of the model's performance by displaying the counts of true positive (TP), false positive (FP), true negative (TN), and false negative (FN) predictions. Confusion matrices are valuable tools in evaluating and comparing different models, selecting appropriate thresholds, and understanding the trade-offs be- tween various performance measures. They offer a clear and concise summary of the model's predictive performance and are widely used in machine learning and classification tasks.

Support

Support refers to the number of actual occurrences or instances of a particular class within a dataset. It represents the frequency or preva- lence of a specific class. Imbalanced support occurs when there is a sig- nificant disparity in the number of instances between different classes in the training data. For example, if one class has a much larger number of instances compared to another class, the dataset is considered imbal- anced. Imbalanced support can pose challenges in training classifiers and evaluating their performance. Classifiers tend to be biased towards the majority class due to the larger number of instances, resulting in lower accuracy or performance metrics for the minority class. This im- balance can indicate potential structural weaknesses in the reported scores of the classifier, as the overall performance may not accurately reflect its ability to correctly classify all classes. To address imbalanced
support, various techniques can be employed. Stratified sampling is one approach that ensures each class is represented proportionally in the training and evaluation datasets. This helps provide a more balanced representation of classes during model training and evaluation. Rebalancing techniques, such as oversampling the minority class or undersampling the majority class, can also be used to mitigate the effects of imbalanced support during training.

Which original CNN network provides better accuracy in detecting rice LEAF disease?

In this section, the performances of the six original individual CNN networks (DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V, and Seresnext101) are presented. The classification perfor- mance of the models is first presented. The overall measures for those models are then discussed. Gathering in addition to the descriptors, pos- sible causes, and areas of opportunity for improvement of results.
Table 2 displays the accuracy of the DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V, Seresnext101. The DenseNet121 and Inceptionv3 models achieved the highest accuracy at 97% and Seresnext101 gave the lowest accuracy value of 79%.
The Precision, Recall, F1-score and Specificity obtained by the DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V, and Seresnext101 models for each of the classes are shown in Table 3. Considering the precision values for each on the test dataset, DenseNet121, Inceptionv3, and MobileNetV2, architectures provide the best performance. The above table suggests that the DenseNet121, Inceptionv3, and MobileNetV2 models classified Blight, Leaf Blast and Tungro diseases with 99% accuracy. The Seresnext101 performed low precision having the lowest identification of the Bacterial blight leaf with only 56% accuracy. All models identified Hispa with an average ac- curacy by the six models. Seresnext-101 requires large amounts of im- ages for training to learn accurate representations compared with DenseNet121, Inceptionv3, MobileNetV2, resNext101, and Resnet152V. If the network receives less testing data, it provides lower classification accuracy. Moreover, the architecture and hyperparameters of the SEResNeXt-101 model could impact its performance. If the model archi- tecture is not suitable for the specific image classification task, or if hyperparameters such as learning rate, batch size, or regularization set- tings are not properly tuned, it could result in lower accuracy. Lastly, since the SEResNeXt-101 model is too complex and has too many pa- rameters relative to the size of the training dataset, leading to overfitting and reducing performance on new images (See Table 4).

Does transfer learning improve accuracy?

In this section, the performance of four transfer learning CNN archi- tectures is presented. Table 6 shows the accuracies obtained in the test sets by DenseNet121, Seresnext101, EfficientNet and, Xception models. The test accuracies shown in Table 5 were calculated as the ratio of the number of correctly classified samples to the number of all samples. The DenseNet1121 model achieved the highest accuracy of 97%. However, the accuracy improvement from the original network to transfer learn- ing by the SeresNext101 network is mentionable. The network


Table 2
Classification accuracy of the individual CNN networks in detecting rice diseases.



Table 3
Precision, Recall, f1 and Specificity result of CNN networks with transfer learning.



improved by a 17% accuracy increase after applying the transfer learn- ing approach.
Table 6 shows the Precision, Recall, F1-score, and Specificity results from the CNN networks with transfer learning. In general, high Preci-



Table 4
Table 4 shows the values of TP, TN, FP, and FN by the different CNN architectures.




sion, high Recall, and high Specificity represent a better model. The ex- perimental results demonstrate that SeresNext-101 had a low precision in detecting Bacterial leaf Blight with 56% accuracy. However, after transfer learning, the model reached 98% accuracy.
The associated TP, FN, FP, and TN are shown in Table 8. For rice disease detection and classification, we applied the seresNext101 Model with a transfer learning approach as the model received the lowest accuracy in earlier experiments (Without transfer learning). In addition to the SeresNext101 model, we also selected DenseNet121, EfficientNet and Xception models for rice leaf disease detection and classification. As these are deep convolutional networks and we were interested to see if the models are useful for small-scale datasets. The confusion matrix of DenseNet121, Seresnext101, EfficientNet and Xception is shown in Fig. 4.

Does the ensemble technique improve the accuracy?

In this research, the ensemble stack is developed on three different original CNN models, Densenet121, EfficientNetB7, and XceptionNet. To accelerate the training process, we adopted a transfer learning strategy. In addition to this, the output from these models was sent to a post-processing block containing a fully connected layer followed by a dropout layer and a final logit layer for classifying the image. For better convergence of our models, we used a learning rate decaying strategy which divided the learning rate by 10 only when the loss stops decreas- ing for three continuous epochs and an early-stopping strategy that halts the training process after the learning rate decayed 5 times (Kawasaki et al., 2015).
Bacterial
leaf blight Densenet121
Blight Brown
Spot
Hispa Leaf
blast
Leaf
scaled
Leaf
smut
Sheath
Blight
Tungro



Table 5
Accuracy results of CNN networks with transfer learning. Architecture	Accuracy
Loss value implies how poorly or well a model behaves after each itera- tion of optimization. Fig. 7 suggests that the training loss was around 3% while the validation loss was 5% in 175 epochs.






All the models have been trained for 60 epochs with Early Stopping callbacks (patience = 10 epochs). Adam optimizer, a combination of SGD with momentum and RMSProp, was used for faster convergence with the parameters as learning rate αα = 0.0001, β1β1 = 0.9, β2β2 = 0.999 and ϵ = 1 × 10 − 7ϵ = 1 × 10 − 7. The same optimizer is used for all three models and then the models are saved as .h5 files. The time taken for model training is −31 s/epoch for DenseNet201 and 17 s/epoch for each of the models ResNet50V2 and Inceptionv3. In Figure the gradual change in the loss function (both training as well as validation) through the epochs has been depicted for all three models of DenseNet201, ResNet50V2 and Inceptionv3. With a 97.62% (see Table 7) accuracy, the ensemble model outperformed the original CNN architecture (Densenet121, EfficientNetB7 and XceptionNet).
The precision on ensembling suggests that the model received 99% on Bacterial blight, which was 98% with transfer learning and 56% on the original CNN model (see Table 8). Even though the F1-score had the lowest accuracy (53% in the case of Brown Spot using Seresnext101) the ensemble model had 95% in that case). However, the Precision, Re- call, f1 and Specificity result of CNN networks with the ensemble is shown in Table 8.
Fig. 5 shows the confusion matrix of the ensemble model. Fig. 6 shows the training accuracy and validation accuracy of the ensemble model of Densenet121, EfficientNetB7 and XceptionNet, where the x-axis represents the number of epochs and the y-axis represents the accuracy and loss percentages. Fig. 6 indicates that the training and validation data are split appropriately with no over-fitting.
Fig. 7 shows the training loss and validation loss over epochs by the ensemble technique. A loss function is used in CNN to optimize an architecture. The loss is calculated on training and validation and its in- terpretation is based on how well the model is doing in these two sets. It is the sum of errors made for each example in training or validation sets.

In this research, we performed an in-depth investigation of the per- formances of original individual CNN, transfer learning, and ensemble models. We compared the results of six different CNN-based models of DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V and SeresNext101 by applying them to the nine classes of rice diseases (see Fig. 8 for accuracy). The dataset used includes 14,118 rice leaf images. After image expansion through rotation, we obtained 34,992 images for training and 7884 images for testing. Among the original in- dividual networks, Densenet121 provides the best classification results in identifying rice leaf diseases. Bari et al., 2021; Nayak and Singh, 2021 also support the findings that Denesenet121 delivers relatively high ac- curacy. This is because, in DenseNet, each layer obtains a “collective knowledge” from all preceding layers as layers receive inputs from all preceding layers and pass them on to the next layers.
Our investigation suggests that transfer learning of deep learning models provides slightly improved accuracy than the original individual networks for small datasets (Number of imageless than 2000). In this case, only after careful training including transfer learning, the accuracy was higher than the original CNN architecture. The transfer learning strategies in this research were based on using the pre-trained model for training and extracting features. Surprisingly we found that seresNext101 has improved by 17% of accuracy after a transfer learning process. This is consistent with the results from the study conducted by Oloko-Oba and Viriri (2021) that SE-ResNeXt-101 normally would in- volve more parameters and was computationally expensive but has shown good results on the ImageNet classification tasks. Performing transfer learning from images trained on Imagenet (general images such as cats, dogs, etc.) or MURA (X-ray images on different parts of the body but not the chest) improved results compared to scenarios when transfer learning was not used at all.




Table 6
Precision, Recall, f1 and Specificity result of CNN networks (Based on the number of images).





Fig. 4. (A): CM after TL of DenseNet121. (B): CM after TL of EfficientNetB7.(C): CM after TL of Xception. (D): CM after TL of Seresnext101.


Not surprisingly, from our investigation, we found that the ensemble of deep learning models improved its accuracy over a single CNN archi- tecture. Our findings also support the study by (Acharya et al., 2020).


Table 7
Accuracy results of the Ensemble model.

Architecture	Accuracy


Ensemble model (DEX)	97.62%


Contributions of this research

This research offers several key contributions. Firstly, this research experimented using nine types of rice diseases. Secondly, in this re- search, a comparison of six original CNN architectures (DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V, and Seresnext101) was conducted. Thirdly, we applied a transfer learning approach on DenseNet121, MobileNetV2, Resnet152V, Seresnext101, and an ensem- ble model called DEX (Densenet121, EfficientNetB7, and Xception) to draw a comparison among the original CNN networks, transfer learning,


Table 8
Precision, Recall, f1 and Specificity result of ensembled CNN networks. Ensemble DEX model (Densenet121, EfficientNetB7 & XceptionNet)






Fig. 5. CM of ensembled three CNN.


Fig. 6. Training and validation errors over the iteration of ensembled three CNN.




Fig. 7. Training and validation accuracy over the epochs of ensembled three CNN.


and ensemble technique. The results suggest that the ensemble frame- work provides the best accuracy of 98%, and the transfer learning in- creases a 17% accuracy from the results by Seresnext101 in detecting and localizing rice leaf diseases.

Conclusion and future research

There are some limitations in the current stage of the research, which need to address in future work. The use of free-of-charge re- sources (Google Colab) limits the experiments of this study. As Google Colab offers the server for a limited time, the hyperparameter tuning, training the base model training other than Imagenet (this research used Imagenet as the base database), and the application of Adadelta,
FTRL, NAdam, Adadelta, and many more optimizers were not performed in this study. Another limitation is that the research used secondary data that are available publicly, not primary data directly collected from fields.
In the future, we want to create a user interface for the detection and localization of rice leaf diseases for farmers. This interface would not only detect but also provide a guide on how the diseases can be con- trolled. As mobile phones are seen as a preferred technological device among developing country users, we aim to develop a mobile phone- based rice leaf disease detection application tool.
The experimentation and the observations presented here are very important when models are being constructed with small datasets. In this research, the accuracy of the ensemble DEX model from




Fig. 8. Accuracy comparison among individual CNN, transfer learning and ensemble.



Densenet121, EfficientNetB7 & XceptionNet was found to produce the highest accuracy in classifying rice diseases from rice leaves. The success of the proposed architecture was compared with the transfer learning and six state-of-the-art individual CNN architectures. Experimental studies were conducted in both original and augmented versions of the image dataset. Considering both the average accuracy and the aver- age precision metric on both the original and augmented datasets, the DEX model was found to be superior to other CNN architectures.

Funding

The work was not supported by any external funding.
CRediT     authorship     contribution     statement Md Taimur Ahad: Writing – original draft, Conceptualization, Meth-
odology. Yan Li: Data curation, Writing – original draft, Supervision. Bo Song: Visualization, Investigation. Touhid Bhuiyan: Writing – review & editing.

Data availability

The data used to support the findings of this study are available from the corresponding author upon request.

Declaration of Competing Interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influ- ence the work reported in this paper.

References
Acharya, A., et al., 2020, November. Plant disease detection for paddy crop using ensemble of CNNs. 2020 IEEE International Conference for Innovation in Technology (INOCON). IEEE, pp. 1–6.
Adegun, A., Viriri, S., 2021. Deep learning techniques for skin lesion analysis and mela- noma cancer detection: a survey of the state-of-the-art. Artif. Intell. Rev. 54 (2), 811–841.
Akhter, M.S., et al., 2019. Plant virus diseases and their management in Bangladesh. Crop Prot. 118, 57–65.
Albawi, S., Mohammed, T.A., Al-Zawi, S., 2017. August). Understanding of a convolutional neural network. 2017 international conference on engineering and technology (ICET). Ieee, pp. 1–6.
Alegbejo, M.D., et al., 2006. Rice yellow mottle virus disease, a new disease of rice in Zamfara, Nigeria. Intern. Rice Res. Notes 31 (39), 39.
Alfred, R., et al., 2021. Towards paddy rice smart farming: a review on big data, machine learning, and rice production tasks. IEEE Access 9, 50358–50380.
Al-Shemarry, Meeras Salman, Li, Yan, Abdulla, Shahab, Wen, Peng, 2019. An efficient tex- ture descriptor for the detection of license plates from vehicle images in difficult con- ditions. IEEE Transactions on Intelligent Transportation Systems. Vol 99, pp. 1–12. https://doi.org/10.1109/TITS.2019.2897990.
Arnal Barbedo, J.G., 2013. Digital image processing techniques for detecting, quantifying and classifying plant diseases. SpringerPlus 2 (1), 1–12.
Asfarian, A., et al., 2014. A computer vision for rice disease identification to support inte- grated pest management. Crop Prot. 61, 103–104.
Atila, Ü., et al., 2021. Plant leaf disease classification using EfficientNet deep learning model. Ecol. Inform. 61, 101182.
Bari, B.S., et al., 2021. A real-time approach of diagnosing rice leaf disease using deep learning-based faster R-CNN framework. PeerJ Comp. Sci. 7, e432.
Chambon, S., et al., 2021. When High-Performing Models Behave Poorly in Practice: Peri- odic Sampling Can Help.
Chen, C.F., et al., 2018. Big-little net: an efficient multi-scale feature representation for vi- sual and speech recognition. arXiv preprint arXiv:1807.03848.
Chen, J., et al., 2020. Identifying plant diseases using deep transfer learning and enhanced lightweight network. Multimed. Tools Appl. 79 (41), 31497–31515.
Chen, J., et al., 2021. Identification of rice plant diseases using lightweight attention net- works. Expert Syst. Appl. 169, 114514.
Chollet, F., 2017. Xception: deep learning with depthwise separable convolutions. Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pp. 1251–1258.
Ferentinos, K.P., 2018. Deep learning models for plant disease detection and diagnosis.
Comput. Electron. Agric. 145, 311–318.
Geetharamani, G., Pandian, A., 2019. Identification of plant leaf diseases using a nine-layer deep convolutional neural network. Comput. Electr. Eng. 76, 323–338.
He, K., et al., 2015. Delving deep into rectifiers: surpassing human-level performance on imagenet classification. Proceedings of the IEEE International Conference on Com- puter Vision, pp. 1026–1034.
Hossain, M., et al., 2017. Occurrence of blast disease in rice in Bangladesh. Am. J. Agricult.
Sci. 4 (4), 74–80.
Huang, G., et al., 2017. Densely connected convolutional networks. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4700–4708.
Islam, T., et al., 2018, April. A faster technique on rice disease detectionusing image pro- cessing of affected area in agro-field. 2018 Second International Conference on Inven- tive Communication and Computational Technologies (ICICCT). IEEE, pp. 62–66.
Karimi, D., Warfield, S.K., Gholipour, A., 2021. Transfer learning in medical image segmen- tation: New insights from analysis of the dynamics of model parameters and learned representations. Artificial intelligence in medicine 116, 102078.
Kawasaki, Y., et al., 2015, December. Basic study of automated diagnosis of viral plant dis- eases using convolutional neural networks. International Symposium on Visual Com- puting. Springer, Cham, pp. 638–645.
Kumar, J.P., Domnic, S., 2019. Image based leaf segmentation and counting in rosette plants. Inform. Proc. Agricult. 6 (2), 233–246.
Lu, Y., et al., 2017. Identification of rice diseases using deep convolutional neural net- works. Neurocomputing 267, 378–384.
McNeely-White, D., et al., 2020. Inception and ResNet features are (almost) equivalent.
Cogn. Syst. Res. 59, 312–318.
Mitkal, P., et al., 2016. Leaf disease detection and prevention using image processing using MATLAB. Intern. J. Recent Trends Eng. Res. (IJRTER) 2 pp.2455–1457.
Mohanty, S.P., et al., 2016. Using deep learning for image-based plant disease detection.
Front. Plant Sci. 7, 1419.
Nagasubramanian, K., et al., 2020. Usefulness of interpretability methods to explain deep learning based plant stress phenotyping. arXiv preprint arXiv:2007.05729.
Nayak, J.K., Singh, P., 2021. Fundamentals of Research Methodology Problems and Pros- pects. SSDN Publishers & Distributors.
Nguyen-Quoc, H., Hoang, V.T., 2020. Rice seed image classification based on HOG descrip- tor with missing values imputation. TELKOMNIKA (Telecommunication Computing Electronics and Control) 18 (4), 1897–1903.
Ou, S.H., 1980. Pathogen variability and host resistance in rice blast disease. Annu. Rev.
Phytopathol. 18 (1), 167–187.
Patil, R.R., Kumar, S., 2022. Rice-fusion: a multimodality data fusion framework for Rice disease diagnosis. IEEE Access 10, 5207–5222.
Phadikar, S., Sil, J., 2008, December. Rice disease identification using pattern recognition techniques. 2008 11th International Conference on Computer and Information Tech- nology. IEEE, pp. 420–423.
Phadikar, S., Sil, J., Das, A.K., 2012. Classification of rice leaf diseases based on morpholog- ical changes. International Journal of Information and Electronics Engineering 2 (3), 460–463.
Sainath, T.N., Kingsbury, B., Saon, G., Soltau, H., Mohamed, A.R., Dahl, G., Ramabhadran, B., 2015. Deep convolutional neural networks for large-scale speech tasks. Neural Netw. 64, 39–48.
Sankupellay, M., Konovalov, D., 2018, November. Bird call recognition using deep convolutional neural network, ResNet-50. Proceedings of ACOUSTICS. Vol. 7, No. 9,
pp. 1–8.
Sanyal, P., Patel, S.C., 2008. Pattern recognition method to detect two diseases in rice plants. Imag. Sci. J. 56 (6), 319–325.
Sarker, M.M., et al., 2016. Status of rice false smut disease in Natore district of Bangladesh.
Bangl. Rice J. 20 (2), 31–37.
Shrivastava, P., Soon, T.K., Idris, M.Y.I.B., Mekhilef, S., 2019. Overview of model-based on- line state-of-charge estimation using Kalman filter family for lithium-ion batteries. Renewable and Sustainable Energy Reviews 113, 109233.
Shujaat, M., et al., 2021. Cr-prom: a convolutional neural network-based model for the prediction of rice promoters. IEEE Access 9, 81485–81491.
Singh, K.K., Singh, A., 2010. A study of image segmentation algorithms for different types of images. Intern. J. Comp. Sci. Iss. (IJCSI) 7 (5), 414.
Singh, V., Misra, A.K., 2017. Detection of plant leaf diseases using image segmentation and soft computing techniques. Inform. Proc. Agricult. 4 (1), 41–49.
Too, E.C., et al., 2019. A comparative study of fine-tuning deep learning models for plant disease identification. Comput. Electron. Agric. 161, 272–279.
Weiss, K., Khoshgoftaar, T.M., Wang, D., 2016. A survey of transfer learning. Journal of Big data 3 (1), 1–40.
Xie, S., et al., 2017. Aggregated residual transformations for deep neural networks. Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pp. 1492–1500.
Xu, Zhe, Guo, Xi, Zhu, Anfan, He, Xiaolin, Zhao, Xiaomin, Han, Yi, Subedi, Roshan, 2020. Using deep convolutional neural networks for image-based diagnosis of nutrient de- ficiencies in rice. Comput. Intell. Neurosci. 2020.
Zhou, Z., et al., 2013. Rice plant-hopper infestation detection and classification algorithms based on fractal dimension values and fuzzy C-means. Math. Comput. Model. 58 (3–4), 701–709.
Zhu, X., Gong, S., 2018. Knowledge distillation by on-the-fly native ensemble. Adv. Neural Inf. Proces. Syst. 31.
