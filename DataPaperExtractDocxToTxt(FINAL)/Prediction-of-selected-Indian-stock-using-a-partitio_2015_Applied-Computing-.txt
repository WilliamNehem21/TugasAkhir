

ORIGINAL ARTICLE

Prediction of selected Indian stock using a partitioning–interpolation based ARIMA–GARCH model
C. Narendra Babu *, B. Eswara Reddy
Dept. of Computer Science & Engg., JNT University College of Engineering, Anantapuramu, India

Received 21 February 2014; revised 8 July 2014; accepted 18 September 2014
Available online 6 October 2014

Abstract Accurate long-term prediction of time series data (TSD) is a very use- ful research challenge in diversified fields. As financial TSD are highly volatile, multi-step prediction of financial TSD is a major research problem in TSD min- ing. The two challenges encountered are, maintaining high prediction accuracy and preserving the data trend across the forecast horizon. The linear traditional models such as autoregressive integrated moving average (ARIMA) and gener- alized autoregressive conditional heteroscedastic (GARCH) preserve data trend to some extent, at the cost of prediction accuracy. Non-linear models like ANN maintain prediction accuracy by sacrificing data trend. In this paper, a linear hybrid model, which maintains prediction accuracy while preserving data trend, is proposed. A quantitative reasoning analysis justifying the accuracy of proposed model is also presented. A moving-average (MA) filter based pre- processing, partitioning and interpolation (PI) technique are incorporated by the proposed model. Some existing models and the proposed model are applied on selected NSE India stock market data. Performance results show that for


* Corresponding author. Tel.: +91 90356 44182.
E-mail address: narendrababu.c@gmail.com (C. Narendra Babu). Peer review under responsibility of King Saud University.

http://dx.doi.org/10.1016/j.aci.2014.09.002
2210-8327 ª 2014 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/).

multi-step ahead prediction, the proposed model outperforms the others in terms of both prediction accuracy and preserving data trend.
ª 2014 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://
creativecommons.org/licenses/by-nc-nd/3.0/).


Introduction

Financial TSD mining provides useful information for the investors, banks and insurance companies to channel their funds properly for better returns. This deci- sion making is the primary motivation for prediction of financial TSD. Accurate multi-step ahead prediction of financial TSD becomes more difficult, as the finan- cial TSD is highly volatile. If prediction is one-step ahead preserving data trend is irrelevant. However, as the forecast horizon increases, preserving data trend becomes significant. In either case, prediction accuracy should remain high. Hence, the two basic requirements for multi-step ahead prediction model are maintaining high prediction accuracy and preserving the data trend across the pre- diction horizon.
Traditional models like ARIMA, GARCH or ANN cannot meet both the requirements simultaneously. However, a hybrid model may provide scope for preserving data trend across the forecast horizon while maintaining good predic- tion accuracy, which motivates the research work of this paper. Most of the tra- ditional models such as ARIMA, GARCH and ANN are applied for one-step ahead forecasting in many works of the literature, where prediction accuracy is of major concern. However, in the present paper, we target multi-step ahead pre- diction, which requires preserving data trend in addition to high prediction accu- racy. Such a model should account for the nature of TSD at every stage in the model.
Rest of the paper is organized as follows. Section 2 presents a literature survey of different prediction models existing in the literature. The proposed PI based hybrid ARIMA–GARCH model is detailed in Section 3. A quantitative analysis of the proposed model is discussed in 4. The proposed and the traditional models are applied on selected NSE India data and the performance is compared in Sec- tion 6. The paper ends with conclusion in 7.

Related work

ARIMA models are popularized after Box and Jenkins, who developed a coher- ent, versatile three-stage iterative cycle for time series identification, estimation, and verification. This method is also known as the BoxJenkins approach [1]. In
[2] quarterly automobile insurance paid claim costs are forecasted using economet- ric and ARIMA models. In [3] the performance of ARIMA model is compared with extended Wiener filtering for short term load forecasting in electric power



systems. In [4] ARIMA is used to perform one-day-ahead forecasts of tomorrow’s federal funds rate. ARIMA with a wavelet based decomposition is used in one- step ahead forecasting of average global temperature in [5]. ARIMA model is suit- able for short term forecasting, if this model is applied for long term prediction the prediction accuracy may not very accurate which can observed from [6], where employment information of Chinese computer industry is forecasted.
Engle in 1982 introduced ARCH model [7] which is known for forecasting high- ly volatile TSD. An improved version of ARCH model called generalized ARCH also known as GARCH model [8] was introduced by Bollerslev, Engle, and Nel- son in 1994. Several extensions of GARCH model are found in the literature. Some of the extensions are extensively surveyed in [9]. In [10] a simple (linear) GARCH(1,1) model is applied on Swiss market index and the results show that the model provides a good parametrization for the daily returns. GARCH model is further explored and studied in [11] and showed that the presence of outliers has an impact on the forecast results. In [12] GARCH models are used to forecast hourly prices in the deregulated electricity markets of Spain and California and the results outperform ARIMA model when volatility and price spikes are present. Some times GARCH models are inappropriate to model as they assume Gaussian distribution. In such cases student-T distribution can be assumed. This fact is fur- ther investigated in [13].
Many Hybrid models are derived in the literature for time series forecasting. The hybrid models combine strengths of few individual models to render better prediction accuracy. A composite ARIMA–GARCH model for forecasting rain- fall data is presented in [14]. ARIMA is used with GARCH model for forecasting daily load and maximum electricity demand estimation as seen in [15], which pro- vides a better long term forecasting. In [16], traffic modeling and prediction using ARIMA and GARCH models are proposed. A MA filter based hybrid ARIMA– ANN model is proposed in [17]. Other techniques like spectral analysis to forecast real time traffic flow [18], Grey–Markov model to forecast Chaina electric-power demand [19] also exist in the literature.

PI based hybrid ARIMA–GARCH prediction model

Details of modeling TSD using ARIMA, GARCH, ANN, and wavelet-ARIMA are all present in the literature mentioned in Section 2. Here, the proposed hybrid ARIMA–GARCH prediction model is discussed.
Financial data are highly volatile in nature. If this volatility nature is character- ized and accounted at every stage in a prediction model, both the data trend and accuracy requirements can be met simultaneously. General characteristics of high- ly volatile TSD are changing variance as a function of time, volatility clustering (VC) and fat tail distribution (FTD) [20]. These are mathematically characterized using conditional standard deviation, autocorrelation plot of absolute or squared returns, Quartile–Quartile plot respectively [20]. Using these characteristics a MA

filter decomposition technique is developed. Along with this, a unique PI technique is used to build the PI-based hybrid ARIMA–GARCH model. The two techniques are detailed as follows.

MA filter based decomposition technique

Given TSD is decomposed into two components, one of which is smooth, called the trend component and the other named as noise component. This decomposi- tion is shown in Fig. 1. The MA filter is given in (1), where m indicates length of the filter, smt is the smoothened trend component and ert is the noise component. It is adjusted such that one of the decomposed components is highly volatile with predominant VC and FTD, but the other is low volatile with relatively very less VC and no FTD.

1
smt = m
t
yk
k=t—m+1
(1)

ert = yt — smt
To decide on m, the TSD should be mathematically characterized for volatility,
VC and FTD.
Volatility

Volatility is termed as the continuous changing of variance as a function of time
[21] or variability of prices or returns of a given TSD [22]. The popular measure of volatility is the conditional standard deviation, rt, given in (2), which is the vari- ance of TSD available till the time lag t. In (2), rt represents the returns data. If rt changes slowly with time, the TSD is identified as low volatile, else it is highly volatile.


Figure 1	Time series decomposition using MA filter.

rt = rEﬃﬃﬃﬃnﬃﬃﬃ(ﬃﬃrﬃﬃtﬃﬃ—ﬃﬃﬃﬃﬃEﬃﬃﬃ{ﬃﬃrﬃﬃtﬃ}ﬃﬃﬃ)ﬃﬃ2ﬃoﬃﬃﬃ
Volatility clustering
(2)

According to [23], some TSD can be characterized by VC, which means large changes are more likely to be followed by large changes and small changes more likely follow small changes, in the given TSD. VC implies, though the time samples appear uncorrelated across time, they are actually dependent across time. VC can be quantified using the autocorrelation plot of absolute returns data [23], or using autocorrelation plot of squared returns [20]. If these plots slowly decay as a func- tion of time lag, then the data are said to exhibit VC. If the decay is relatively slow, the effect of VC is high, else it is low. The autocorrelation sequence can be calcu- lated using (3), where, s represents the time lag.


C(r ; r
	E{(rt — E{rt})(rt+s — E{rt+s})}	
(3)

t  t+s) = rﬃﬃﬃﬃnﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃoﬃﬃﬃﬃﬃﬃﬃnﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃoﬃﬃﬃ

Fat tail distribution

If the distribution of given TSD deviates from that of Gaussian (Normal), then the data are fat tail distributed. This means the data exhibit peaked nature at the cen- ter and the tails are fatter than that of Gaussian distribution. To quantify FTD, Jarque–Bera normality test can be used. According to this test, if the kurtosis of TSD is 3, it is Gaussian distributed and if kurtosis is not equal to 3, it exhibits FTD. Note that if the data are highly outlier prone, kurtosis is greater than 3 and if it is less prone to outliers, the kurtosis is less than 3 [24]. Kurtosis is com- puted using (4). Another way of identifying FTD is the Q–Q plot on returns data [20]. If this Q–Q plot deviates substantially from the standard normal Q–Q plot, the data have FTD.

En(rt
 En(r
— E{r })4o
— E{r })2o 2
(4)

Note that in [20], it is shown that log returns on the data are same as the relative
by  rt  = yt—yt—1  are  referred  to  as  returns  data  in  this  paper. returns on the data, by using Taylor expansion. So the relative returns data given
t—1

Partitioning and interpolation

Let the original TSD be represented as {x1; x2; x3; x4; x5 .. . xTr}, where Tr repre- sents the last sample data point in the series. These data are then split into P par-
titions as shown in (6).
{x1; xP+1; x2P+1; .. .}; {x2; xP+2; x2P+2; .. .}; .. . ; {xP; x2P; x3P; x4P; .. .}	(5)
Consider any one of the partitions in (6). Each partition is a TSD with less than Tr
sample data points. On this data, a linear interpolation is done to obtain Tr data points. This process is repeated on each of the partitions and P different TSD are obtained, each consisting of Tr sample data points. Thus interpolated TSD parti-
tions are notated as TP1; TP2; TP3; .. . ; TPP.

Steps in proposed model

The steps involved in the proposed model are described below.
The given TSD are decomposed into two series using a MA filter given in (1). m is chosen such that one of these decompositions is highly volatile with pre- dominant VC, FTD (notated as S1), while the other which is low volatile with relatively less VC, FTD (notated as S2).
The S2 series with En data values is given as training data, and an ARIMA model is fit. Correspondingly predictions are made over the prediction horizon.
The S1 series is split into M partitions. If original S1 is considered as
{x1; x2; x3; x4; x5 .. . xEn}, the M partitions are indicated in (6).
{x1; xM+1; x2M+1; .. .}; {x2; xM+2; x2M+2; .. .}; .. . ; {xM; x2M; x3M; x4M; .. .}
(6)
Then each partition is linearly interpolated to obtain same number of data
points  En,  as  in  S1  series.  Let  these  M  interpolated  partitions  be
P1; P2; P3; .. . ; PM.
values as training data a GARCH model is fit, validated and En — Er forecasts are obtained. The mean absolute percentage error (MAPE) with En — Er pre- 4. Consider one partition P 1 with first Er data values, where Er < En. Using Er
dicted and actual data values is obtained. This process is repeated on all P 2
to PM partitions. The best GARCH model is finalized as the one with mini- mum error. The best partition which gives this best GARCH model is used to forecast over the complete prediction horizon.
5. The predictions from step 2 and step 4 are added to form the final predictions. The above proposed hybrid model is shown in Fig. 2.



Figure 2	The proposed hybrid ARIMA–GARCH model.

Simulated TSD: Analysis of decomposition and PI techniques

The proposed PI based hybrid ARIMA–GARCH model has improved prediction accuracy than individual models. The success of this technique lies in the success of the decomposition and PI techniques. On a simulated highly volatile TSD, these two techniques are applied and analyzed. Later, the improved prediction accuracy of the proposed method is justified and its other advantages and limitations are discussed.

Analysis of MA filter based decomposition technique

In particular MA-filter should be able to provide series S1 and S2 properly, with a suitable m. A highly volatile TSD is simulated. It is verified for volatility, VC and FTD as follows:
The presence of volatility is verified using conditional standard deviation plot.
The prominence of VC is verified using autocorrelation plot of absolute returns.
The presence of FTD is verified using Q–Q plot and also using value of kurtosis,
k.
For a filter length, m = 35, the results of the analysis are shown in Fig. 3. The figure shows from left to right, the two decompositions, their conditional standard






800

600

400
Series 1 Data

0.15

0.1

0.05
For Volatility

1


0.5
For VC

0.01
0
−0.01
−0.02
For FTD

200 0	500	1000
0 0	500
0 0	20	40
−0.03
−5	0	5

Time instant
40	Series 2 Data
20
0
−20
−40





0.1

0.05

0
Time lag For volatility
Time lag
1.5	For VC
1
0.5
0
−0.5


0.04

0.02

0

−0.02
Standard Normal Quantiles For FTD

0	500	1000
Time instant
0	500
Time lag
0	20	40
Time lag
−5	0	5
Standard Normal Quantiles

Figure 3	MA filter length m = 35; k = 1.93 for series 1; k = 2.87 for series 2.
deviation plots, the autocorrelation of absolute returns plots and the Q–Q plots. It can be observed that the series S1 is highly volatile with predominant VC and FTD, and the other is series S2, is low volatile with less VC and no FTD. Thus it is indeed possible to obtain the required two series by selecting a proper value of m. Note that the value of m is not unique. For example in this case, we observed that for values of m ranging in 25 6 m 6 35, the required two series can be prop- erly obtained (Results are not presented).

Analysis of PI technique

Let a TSD, referred as raw data here, have 500 data points. If 10 partitions are done, each partition will have 50 points. In this case, the first partition has the data points 1; 11; 21; .. . ; 491, second partition has data points 2; 12; 22; .. . ; 492, and
the last partition has data points 10; 20; 30; .. . ; 500. To have the same number
of data points as the original data in each partition, each partition is interpolated, to obtain 500 data points. On series 1 of Fig. (3), the PI technique is applied with 10 partitions. It is observed that all the interpolated partitions retain volatility; and VC, FTD change only slightly than that of the series 1. If the number of partitions made 30, this change is more. However, in both the cases, the partitions have volatility, VC and FTD. From this observation we can conclude the following. When the PI step is performed with 10 partitions, the partitioning did not violate Nyquist sampling theorem [25]; and after interpolation, each partition still has same frequency content as the initial series. In this case kurtosis of all the partitions is nearly same as the kurtosis of initial series. When PI with 30 partitions is performed, it violates Nyquist sampling rate, which implies that some high frequency components are being removed from the partitions. In this case, kurtosis of different partitions is different.

Performance of the proposed model

The proposed model renders better prediction accuracy for a long term prediction on a highly volatile TSD. In this section, quantitative reasoning as to why the pro- posed method is better, is illustrated.

Application of the right model

From Fig. 2, on the low volatile decomposition with less VC and no FTD, ARIMA model is applied. This is apt because ARIMA model assumes a Gaussian distribution (i.e. no FTD), no VC and constant variance [1]. Similarly on the high- ly volatile decomposition, which has VC, and FTD, GARCH model is being applied. This is apt because, GARCH model relaxes the constraint of constant variance [26], and is suitable for data with VC [23]. The proposed hybrid model is hence applying apt individual models based on the nature of decompositions. Note that in general decomposition improves prediction accuracy [24], and in this case, due to the application of right model to each of the decomposition accuracy further improves.
Instead of directly applying GARCH model on S1, if PI technique is applied, P different data series result. On each of the series, GARCH is suitable because, the volatility, VC and FTD still prevail as discussed in Section 4.2, irrespective of the number of partitions P. Now out of the P different GARCH models, the best model can be chosen. Let this best model be obtained due to the Bth partition. This means that some of the data points, which do not really play any role in prediction (for example, outliers) are not present in this Bth partition and so this partition gave the best prediction accuracy.

Advantages and limitations of the proposed model

The advantages of the proposed model are that, it is well suited for long term pre- diction. Also, being a linear model, the data dynamics i.e. data trend is preserved and the prediction accuracy is high, better than the popular ANN. The ANN on the other hand uses the training data and learns from the data before prediction. It blindly tries to maximize the overall prediction accuracy. In this process, the data dynamics are sacrificed. This reasoning supports the fact that the proposed prediction model is better than the ANN model. The proposed model is clearly better than ARIMA, GARCH and Wavelet ARIMA models also, because the nature of the given time series data is clearly accounted at every stage in the model.
The limitation of the proposed model is that, the number of partitions P is decided based on trial and error. If the estimation of P for a given data set is possible, it will improve the model, though complexity increases. Also, in this paper, the covariates are not considered. The proposed model is shown to work

well for univariate data. If the covariates are considered, the prediction accuracy still further improves because taking the effect of covariates, implies the dependen- cies of the data are completely being accounted. The drawback will be the model complexity and tuning of the increased number of model parameters [22]. So this study is not included in this paper.

Experimental results and discussion

In this section, on selected financial TSD originating from NSE India data, the proposed model, ARIMA, GARCH, wavelet-ARIMA and ANN are applied. The performance measures used for comparison, are the error measures, MAPE, Maximum Absolute Percentage Error (MaxAPE), MAE and Root Mean Square Error (RMSE) which are given in (7)–(10) respectively. In these equations, pi and pf are the start and end time instants of the prediction interval. yi;actual is the actual
value of TSD at time instant i; yi;predicted is the predicted value of TSD at time
instant i.


pf
i;actual
— yi;predicted !

MAPE = pf — pi + 1
i=pi
yi;actual
* 100	(7)




where i ∈ [pi; pf]
1
yi;actual


  Xpf	 !



RMSE = sﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ1ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃﬃﬃXﬃﬃﬃﬃﬃﬃﬃpﬃfﬃﬃﬃﬃﬃÿﬃﬃyﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ—ﬃﬃﬃﬃﬃyﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃﬃ2ﬃﬃ ﬃﬃﬃ
(10)

The highly volatile NSE India data [27] selected are close price stock data of SBI,
number of trades data of Tata Steel. A 20-step ahead prediction is performed in both the cases. This implies using the data values available till yesterday, the data values from today till another 20 days are predicted. In both these TSD cases, the proposed method outperformed other models in terms of prediction accuracy and also in preserving data trend.

TSD1

The close price values of SBI shares from January 2010 to December 2011 are con- sidered as TSD1 for the study. On this highly volatile TSD, the proposed model is

applied. Accordingle, S1 and S2 are obtained. On S2, ARIMA is applied and fore- casts are obtained. On S1 PI is applied to result in twelve partitions. The VC, FTD and Q–Q plot of all the partitions are similar to those all S1 indicating that all the partitions retained the same nature as S1. The corresponding error measures, MAPE, MaxAPE, MAE, and RMSE are tabulated in Table 1 along with the error measures of ARIMA, GARCH, ANN and wavelet ARIMA. The actual and the predicted TSD values over the forecast horizon are shown in Fig. 4. It is inferred from the table that the proposed model outperforms all the others. From Fig. 4, it is clear that the proposed model follows the data trend better than the other mod- els. Unfortunately, this fact is not evident from MAPE, but from MAE and RMSE, it is very much evident.






2400
2300

2200

2100
Actual forecast horizon

2400

2200

2000
ARIMA model predictions

20000	5	10	15	20
Time Step
18000	5	10	15	20
Time Step

Wavelet ARIMA model predictions
2400
2300

2200

2100

2400
2300

2200

2100
GARCH model predictions

20000	5	10	15	20
Time Step
20000	5	10	15	20
Time Step



2400

2300

2200

2100

2000

ANN model predictions


0	5	10	15	20
Time Step


2400

2300

2200

2100

2000

Proposed model predictions


0	5	10	15	20
Time Step



Figure 4	Forecast results for SBI close price data.

TSD2

The number of trades of Tata Steel from January 2011 to December 2011 is con- sidered as TSD2 for the study. On this highly volatile TSD, the ARIMA, GARCH, wavelet ARIMA, ANN and the proposed model are applied. The results of MAPE, Max APE, MAE, and RMSE for these models are given in Table 2. The proposed model outperformed others as in the previous case. The corresponding actual and the predicted values in the prediction horizon are shown in Fig. 5. The figure shows that ANN failed to follow the data trend, whereas the proposed method preserved the data trend more accurately. In this case the pro- posed model used 11 partitions, where 6 of them had almost same VC, FTD and Q–Q nature as the S1 series while the other 5 showed very different nature. The




x 104
6
Actual forecast horizon

x 104
15
ARIMA model predictions


4	10


2

00	5	10	15	20
Time Step
5

00	5	10	15	20
Time Step

x 104Wavelet ARIMA model predictions
6
x 104
6
GARCH model predictions


4	4


2

00	5	10	15	20
Time Step
2

00	5	10	15	20
Time Step

x 104
6
ANN model predictions
x 104
6
Proposed model predictions


4	4


2

00	5	10	15	20
Time Step
2

00	5	10	15	20
Time Step



Figure 5	Forecast results for number of trades of Tata Steel.


best partition is one of these 5 partitions. As the results for this TSD2 given in Table 2 and Fig. 5 showed that the proposed model has improved performance, it is enough evidence for the quantitative justification given in Section 4.
For ten other NSE data sets, the results of MAPE are tabulated in Table 3. The table shows that in all the cases, the proposed method is better than all the other methods discussed in this paper.
Conclusion

In this paper, for highly volatile financial TSD, a hybrid ARIMA–GARCH model is proposed, which is suitable for multi-step ahead forecasting. The technique involves a MA filter based decomposition as a pre-processing step on given TSD. The proposed model is applied on selected NSE India data sets to get mul- ti-step ahead prediction. The obtained results are evaluated using error perfor- mance measures MAPE, MaxAPE, RMSE, whose values confirm the improved prediction accuracy compared to traditional models ARIMA, GARCH and ANN. The proposed model also preserved the data trend over the prediction hori- zon better than the others. The prediction performance can be studied by the inclusion of covariates, which forms the future scope of this paper.
Appendix A. Supplementary material

Supplementary data associated with this article can be found, in the online ver- sion, at http://dx.doi.org/10.1016/j.aci.2014.09.002.

References
G.E.P. Box, G. Jenkins, Time Series Analysis, Forecasting and Control, revised ed. 1976 Edition, Holden- Day, Incorporated, 1990.
G.L. Griepentrog, J.D. Cummins, Forecasting automobile insurance paid claims using econometric and ARIMA models, Int. J. Forecast. 1 (1985) 203–215.
R. Genesio, S. Pozzi, A. Vicino, U. Di Caprio, Short term load forecasting in electric power systems: a comparison of ARMA models and extended wiener filtering, J. Forecast. 2 (1983) 59–76.

R.E. Spudeck, Scott E. Hein, Forecasting the daily federal funds rate, Int. J. Forecast. 4 (1988) 581–591.
C. Babu, B. Reddy, Predictive data mining on average global temperature using variants of ARIMA models, in: 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), 2012,
pp. 256–260.
X. Wang, Y. Liu, ARIMA time series application to employment forecasting, in: 4th International Conference on Computer Science Education, 2009, ICCSE ’09, 2009, pp. 1124–1127. http://dx.doi.org/10. 1109/ICCSE.2009.5228480.
R.F. Engle, Autoregressive conditional heteroscedasticity with estimates of the variance of the united kingdom inflation, Econometrica 50 (1982) 987–1008.
R.F. Engle, D.B. Nelson, T. Bollerslev, ARCH models, in: R.F. Engle, D.L. McFadden (Eds.), Ch. Handbook of Econometrics, vol. IV, 1994, pp. 2959–3038.
T. Bollerslev, R.Y. Chou, K.F. Kroner, Arch modeling in finance: a review of the theory and empirical evidence, J. Econom. 52 (1–2) (1992) 5–59.
L. Bianchi, J. Jarrett, R.C. Hanumara, Improving forecasting for telemarketing centers by {ARIMA} modeling with intervention, Int. J. Forecast. 14 (4) (1998) 497–504, http://dx.doi.org/10.1016/S0169-
2070(98)00037-5.
H. Ghijsels, P.H. Franses, Additive outliers, GARCH and forecasting volatility, Int. J. Forecast. 15 (1999) 1–
9.
R. Garcia, J. Contreras, M. van Akkeren, J. Garcia, A GARCH forecasting model to predict day-ahead electricity prices, IEEE Trans. Power Syst. 20 (2) (2005) 867–874, http://dx.doi.org/10.1109/ TPWRS.2005.846044.
E. Scott, Ken Johnston, GARCH models and the stochastic process underlying exchange rate price change,
J. Financ. Strateg. Decis. 13 (2000) 13–24.
F. Yusof, I. Kane, Volatility modeling of rainfall time series, Theoret. Appl. Climatol. 113 (1–2) (2013) 247– 258, http://dx.doi.org/10.1007/s00704-012-0778-8.
C.-L. Hor, S. Watson, S. Majithia, Daily load forecasting and maximum demand estimation using ARIMA and GARCH, in: International Conference on Probabilistic Methods Applied to Power Systems, 2006, PMAPS 2006, 2006, pp. 1–6.
B. Zhou, D. He, Z. Sun, Traffic modeling and prediction using ARIMA/GARCH model, in: A. Nejat Ince,
E. Topuz (Eds.), Modeling and Simulation Tools for Emerging Telecommunication Networks, Springer, US, 2006, pp. 101–121.
C.N. Babu, B.E. Reddy, A moving-average filter based hybrid ARIMA–ANN model for forecasting time series data, Appl. Soft Comput. 23 (0) (2014) 27–38, http://dx.doi.org/10.1016/j.asoc.2014.05.028.
M. O’Mahony, Tigran T. Tchrakian, Biswajit Basu, Real-time traffic flow forecasting using spectral analysis,
IEEE Trans. Intell. Transport. Syst. 13 (2012) 519–526.
M. Huang, Y. He, H. Cen, Predictive analysis on electric-power supply and demand in China, Renew. Energy 32 (7) (2007) 1165–1174, http://dx.doi.org/10.1016/j.renene.2006.04.005.
P. Fryzlewicz, Lecture Notes: Financial Time Series, ARCH and GARCH Models, University of Bristol, 2007.
Robert F. Engle III, Risk and Volatility: Econometric Models and Financial Practise, New York University, 2003.
M.S. Heracleous, Volatility Modeling Using the Student-t Distribution, Ph.D. Thesis, Virginia Polytechnic Institute and State University, 2003.
J.-J. Tseng, S.-P. Li, Quantifying volatility clustering in financial time series, Int. Rev. Financ. Anal. 23 (0) (2012) 11–19, http://dx.doi.org/10.1016/j.irfa.2011.06.017 (Complexity and Non-Linearities in Financial Markets: Perspectives from Econophysics).
J.S. Armstrong, Principles of Forecasting: A Handbook for Researchers and Practitioners, Kluwer Academic
Publishers, MA, 2001.
B.P. Lathi, Signal Processing and Linear Systems, Oxford University Press, 2000.
T. Bollerslev, R.F. Engle, Common persistence in conditional variances, Econometrica 61 (1) (1993) 167–
186.
http://www.nseindia.com.
