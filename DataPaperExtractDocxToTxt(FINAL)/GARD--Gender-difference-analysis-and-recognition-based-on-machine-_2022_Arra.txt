Array 14 (2022) 100140










GARD: Gender difference analysis and recognition based on machine learning‚ú©
Shiwen He a,b,c,‚àó, Jian Song a, Yeyu Ou a, Yuanhong Yuan d,‚àó‚àó, Xiaojie Zhang e,f, Xiaohua Xu g
a School of Computer Science and Engineering, Central South University, Changsha 410083, China
b National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China
c The Purple Mountain Laboratories, China
d Emergency Center of Hunan Children‚Äôs Hospital, Changsha 410007, China
e Department of Psychiatry, The Second Xiangya Hospital, Central South University, Changsha 410011, China
f National Clinical Research Center for Mental Disorders, Changsha, 410011, China
g Department of Endocrinology, Nanjing First Hospital, Nanjing Medical University, Nanjing 210012, China


A R T I C L E  I N F O	A B S T R A C T

	

Keywords:
Gender difference analysis Gender recognition Medical examination data Machine learning
In recent years, intelligent diagnosis and intelligent medical treatment based on big data of medical examina- tions have become the main trend of medical development in the future. In this paper, we propose a method for analyzing the difference between males and females in medical examination items (medical attributes) and find that males and females of different ages have differences in medical attributes. Then, the cluster analysis method is used to further analyze the differences between male and female in medical examination items, such that some common important attributes (CIAs) that can be used for gender recognition are found within a specific age range. Following, we propose two gender recognition models (GRMs) by using the found CIAs to identify the gender. A large number of experimental results are provided to validate the effectiveness of the proposed GRMs. Experimental results show that the medical attributes with a large value of difference really contribute to gender recognition. Within a certain age range, such as 17 to 51 years old, the proposed GRM can reach 92.8% accuracy using only six medical attributes.





Introduction

With the rapid development of computer technology and hospital information systems, electronic medical record (EMR) has been pop- ularized to replace the traditional handwritten medical records [1]. Furthermore, the establishment of an advanced EMR system will bring the hospital into a new era of digital hospitals and provide proactive, convenient, and efficient data services for the hospital‚Äôs medical, scien- tific research and teaching as well as hospital management. However, during collecting the EMR data, the values of some medical examina- tion items cannot be avoided to lose, such as the value of gender. For EHR analysis, patient ender information plays a very essential role in referring some useful information, and the lack of this information will affect the data quality of EMR. However, in some Chinese EHRs, gender information is either missing [2], or it is hidden and deleted due to
privacy concerns [3]. Therefore, it is necessary to investigate the filling miss value algorithm with the non-missing value of medical data, and predict gender from data that does not involve privacy risks.
It is well-known that accurate analysis of medical examination data, which depends on data integrity, is conducive to early disease detection, patient care, and community service. However, the incom- pleteness of medical examination data will reduce the analysis accu- racy. Yoon et al. proposed a generative adversarial imputation network (GAIN) for imputing missing data by adopting the well-known gener- ative adversarial network (GAN) framework [4]. Yang et al. pointed out that GAIN is not suitable for analyzing medical examination data, because GAN itself adapts to pixel data, so they combined fuzzy coding to adjust the GAIN [5]. As most of the medical examination data in the intensive care unit are time series, Luo et al. combined GAN



‚ú© This work was supported in part by National Natural Science Foundation of China under Grants 62171474, in part by the open research fund of National Mobile Communications Research Laboratory Southeast University under Grants No. 2022D03, in part by OPPO research fund under Grants No. CN05202112160224.
‚àó Corresponding author at: School of Computer Science and Engineering, Central South University, Changsha 410083, China.
‚àó‚àó Corresponding author.
E-mail addresses: shiwen.he.hn@csu.edu.cn (S. He), 1301140117@csu.edu.cn (J. Song), Ouyeyu@csu.edu.cn (Y. Ou), yyhong120@163.com (Y. Yuan), Xiaojiezhang2014@163.com (X. Zhang), xxh7812@163.com (X. Xu).
https://doi.org/10.1016/j.array.2022.100140 Received 8 January 2022; Accepted 7 March 2022
Available online 25 March 2022
2590-0056/¬© 2022 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by- nc-nd/4.0/).



with the gated recurrent unit to construct the gated recurrent unit for data imputation for filling missing values in time series data [6]. Similarly, the time dimension information is used to fill missing values by multidirectional recurrent neural network [7]. Machine learning
EMR. McLean et al. introduced Predictive Mean Matching, ùêæ Nearest and deep learning are also widely used to fill in missing values in
Neighbors, Iterative Imputer, and MICE to generate values for missing data in EMR centered on oncology [8]. Farnaz et al. developed a time series medical generative adjunctive network (GANs) for a wound prognosis model that can generate continuous and categorical features from EMR [9].
When solving the problem of data incompleteness, filling gender information, i.e., gender recognition is also a research hotspot. For gender identification, Li et al. introduced a multiple support vector machine (SVM) gender classifier based on five facial features in addi- tion to human hair and clothes [10]. The Gabor filter responses of face images were used to identify gender and age [11]. A RestNet based gender recognizer was developed by detecting and locating the face landmarks on the regression tree set [12]. In addition to face images, there are studies that use text, mobile phone behaviors, and neural signals to distinguish males and females. Moumita et al. effectively identified the male and female by extracting the Euler Numbers of names [13]. The gender information of users is predicted by matching the mobile text data of users with the gender representative word set based on Web documents [14]. Dongxu et al. used reposing behav- iors on social networks to distinguish male and female by combining statistical knowledge and sociological knowledge [15]. Kaur et al. tried to mine useful information from neural signals, they designed a prediction framework to use neural signals collected by brain wave sensors to identify age and gender [16]. In the medical field, Jun- mei et al. developed a data management method using convolutional neural network(CNN) to predict missing values of patient gender from EMR [2]. Serkan et al. proposed a machine learning algorithm based on multidetector computed tomography (MDCT) image measurement of the patella, using a decision tree (DT) method to determine gen- der [17]. Yuichiro et al. used brain MRI(magnetic resonance imaging) to construct a multichannel 3D-CNN and verified the effect of brain structure image patterns on gender recognition [18].
In this paper, we first analyze the differences between males and females in medical examination items, and then build two gender recognition models based on the results of the analysis to identify males and females. The main contributions are summarized as follows:
An algorithm based on overlapping areas is proposed to analyze the difference between males and females in medical examina- tion;
Some common important attributions (CIAs) in a certain age ranges are found to facilitate the recognition of males and females via using cluster analysis, and an age range division algorithm is proposed as a by-product;
Two gender recognition models (GRMs), i.e., GRM A for the sample to be identified with known age, and GRM B for the sample to be identified with unknown age, are developed to identify the gender of samples. Experimental results show that in certain age ranges, such as 17 to 51 years old, the proposed GRM A and GRM B can reach 92.8% and 93.8% accuracy, respectively.
The rest of the paper is organized as follows. In Section 2, we describe the dataset and analyze the differences between males and females in medical examination. In Section 3, we further analyze through cluster analysis and determine the medical examination items that play an important role in gender recognition in each age subrange. In Section 4, two gender recognition models are proposed according to whether the age of the examples is known or not. Then, we evaluate the proposed models and the role of data analysis in gender recognition in Section 5. Finally, we conclude in Section 6.
Data description and analysis

Data description

To analyze the differences between males and females in medical ex- amination data, we collected 62,072 samples from the Xiangya Medical
the set of samples. Each sample contains ùëÅ = 39 medical examination Big Data System after desensitization. For ease of presentation, let Q be
items (medical attributes) and 2 basic attributes (‚Äò‚ÄòAGE‚Äô‚Äô: Age, ‚Äò‚ÄòSEX‚Äô‚Äô: Sex). In particular, Table 1 lists the medical attribute types, index, attributes, and full name of attributes. The medical attributes include the routine blood test, liver function test, renal function test, and examination of plasma prothrombin time measurements. To grasp the data structure in set Q, we list the common statistics of each attribute, including the mean value (Mean), minimum (MIN), and maximum (MAX). For the basic attributes, the minimum age and the maximum age of samples in set Q are 1 and 70, respectively, i.e., the age range is
f = {1, 2, ‚Ä¶ , 69, 70}. For the male samples, the value of attribute ‚Äò‚ÄòSEX‚Äô‚Äô
is ‚Äò‚Äò0‚Äô‚Äô, while for the female samples, the value of attribute ‚Äò‚ÄòSEX‚Äô‚Äô is ‚Äò‚Äò1‚Äô‚Äô.


Difference analysis

The existing studies have shown that there are differences between males and females in some medical attributes listed in Table 1. For example, the medical attributes RBC, HGB, and HCT have a signifi-
cant differences between males and females after 2 years old [19,20].
Through the statistical analysis of samples between 1 and 17 years old,
CREA and UA have a significant differences between males and females within 12 to 17 years old [21]. However, the statistical methods used in the aforementioned literature can only determine whether the distribu-
tions of medical attributes ùõæ of males and females are the same or not.
mEdical Attribute (DEFEA) ùõæ is considered significant. However, these If they are not the same, the Difference between malEs and Females in
aforementioned literature has not revealed the change trend of DEFEA
ùõæ, what we only know is there is the DEFEA ùõæ. In other words, they do not compare the magnitude of DEFEA ùõæ. In short, these statistical analysis cannot tell us the specific value of DEFEA ùõæ [22]. In what follows, we analyze the DEFEA ùõæ through the distribution of medical attribute ùõæ of male and female, respectively.
Fig. 1 shows the numerical distribution of three medical attributes at different ages of males and females. Specifically, Figs. 1(a), 1(b), and 1(c) illustrate the numerical distribution of medical attributes CREA, HGB, and PT%, respectively. It is not difficult to find that for medical attributes CREA and HGB, the numerical distribution of males and females is almost the same at the age of 5. However, there are large differences between the numerical distribution of males and females over 5 years old. For the medical attribute PT%, the difference between the numerical distribution of males and females is not obvious at these
ages. From the statistical viewpoint, for the medical attribute ùõæ, the
closer the numerical distribution of males and females is, the larger
DEFEA ùõæ at age ùë° can be evaluated with the overlap area ùêé (ùë°, ùõæ) of the the overlap area of the numerical distribution is. This implies that the numerical distribution of medical attribute ùõæ of males and females at age ùë°, given by
ùêÉ (ùë°, ùëü) = ‚àí ln (ùêé (ùë°, ùëü)) ,	(1)
where ùëü represents the index of the corresponding medical attribute ùõæ,
ùëü ‚àà k = {1, 2, ‚Ä¶ , 39}, and ùêé (ùë°, ùõæ) is calculated by
ùêé (ùë°, ùëü) =	min ùëÉùëö (ùë°, ùëü, ùëó) , ùëÉùëì (ùë°, ùëü, ùëó) ,	(2)
ùëó‚ààùõ¨ùõæ
where ùõ¨ùõæ is a set of subintervals generated by dividing uniformly the value range of medical attribute ùõæ into multiple intervals, ùëÉùëö (ùë°, ùëü, ùëó) and ùëÉùëì (ùë°, ùëü, ùëó) represent the frequency of samples of medical attribute
ùõæ of males and females belonging to the ùëóth subinterval at age ùë°,


Table 1
Data structure.


respectively. Note that ùêÉ (ùë°, ùëü) is negatively correlated with ùêé (ùë°, ùëü), and approximates 0 when ùêé (ùë°, ùëü) is close to 1. In other words, the overlap
of the two numerical distributions means that there is no difference between females and males in a medial attribute.
Fig. 2 shows the change of the value of DEFEA as age increases. It can be seen that for most medical attributes, the value of DEFEA is smaller than 0.5 at all ages and fluctuates with age. However, with an increasing age, the value of DEFEA has obvious changes for some medical attributes, such as CREA, HGB, HCT, RBC, UA, AST/ALT, and ALT. In particular, one can see that for these medical attributes, the value of DEFEA grows rapidly from the age of 12, and reaches the highest point between the ages of 15 and 50 years old. After 50 years old, the values of DEFEA CREA, HGB, HCT, RBC, and UA are still large, while the values of DEFEA AST/ALT and ALT drop to a lower level

an age subrange Cùëñ, i.e., ‚à™ùëñCùëñ = f . As a result, in the age subrange Cùëñ, we focus on designing an effective method to divide age range f into
some common medical attributes can be used to distinguish males and females. Note that to reduce the computational complexity and to take into account the fact that the age itself is ordered, the age contained in
age subrange Cùëñ should be adjacent, such as Cùëñ = {1, 2, 3}.
DEFEAs      at      age      ùë°      as For easy of presentation, we define the mean value of the values of
ùúã (ùë°) =  ùëü‚ààk ùêÉ (ùë°, ùëü) .	(3)
ùëÅ
If ùêÉ (ùë°, ùëü) is higher than ùúã (ùë°), the medical attribute ùõæ is regarded as an important attribute (IA) in distinguishing males and females at age ùë°. We introduce a matrix ùêå whose element is given by
{1,  if ùêÉ (ùë°, ùëü) > ùúã (ùë°)

compared with other medical attributes, such as MONO#, MCH, and LYM.
ùêå (ùë°, ùëü) =
(4)
0,  other,

Cluster analysis
where ùë° ‚àà f , ùëü ‚àà k. The cohesion of IAs in the age subrange Cùëñ is
defined as


After the aforementioned analysis, one can find that only a few
ùõ∑ (ùëñ) =
ùë°1 ,ùë°2 ‚ààCùëñ
ùêª (ùë°1, ùë°2) ,	(5)

medical attributes, such as CREA, ALT, have an obvious differences between males and females in a certain age range in terms of the value of DEFEA. The difference between the values of other medical attributes is not obvious at each age. Can we find medical attributes, which play an important role in distinguishing males and females with a higher value of DEFEA at each age? To answer this question, in what follows,
where ùêª ùë°1, ùë°2  is calculated by
ùêª ùë°1, ùë°2  =	ùêå ùë°1, ùëü ‚àí ùêå ùë°2, ùëü  .	(6)
ùëü‚ààk
As can be seen from Eqs. (5) and (6), the smaller the cohesion, the larger similarity of IAs in age subrange Cùëñ.


































/ig. 1. Numerical distribution of (a) CREA, (b) HGB, (c) PT% in different ages.





/ig. 2. The value of DEFEAs.



By using the concept of cohesion, we use division hierarchical clustering (DHC) to divide the age range f into some age subranges with the goal of minimizing the sum of cohesion of age subranges,
such that the IAs between ages in age subrange Cùëñ is as the same as
possible. The detailed DHC is summarized as Algorithm 1. To illustrate
the process of running Algorithm 1, Fig. 3 gives out an example of the
age subrange contains a small number of age before the age of 16, and contains more ages after the age of 16. This implies that the common IAs changes frequently between the ages of 1 and 16 years, and tends to be stable after the age of 16. Furthermore, the IAs of different ages within the same age subrange obtained by DHC may also be different.
In the age subrange Cùëñ, we regard the mean value of DEFEA ùõæ at all
ages as the value of DEFEA ùõæ, given by
ùêï (ùëñ, ùëü) =  ùë°‚ààCùëñ ùêÉ (ùë°, ùëü) ,	(7)

Cùëñ
where ùëü ‚àà k, Cùëñ means the number of ages in the age subrange Cùëñ. Similarly, for the age subrange Cùëñ, we define the mean value of the
values of DEFEAs as
ùõ± (ùëñ) =	ùëü‚ààk ùêï (ùëñ, ùëü) .	(8)
ùëÅ
If ùêï (ùëñ, ùëü) is higher than ùõ± (ùëñ), the medical attribute ùõæ is regarded as a
common important attribute (CIAs) in distinguishing males and females in the age subrange Cùëñ.

Algorithm 1 Divisive Hierarchical Clustering
Input: ùëõ (the number of age subranges (ùëõ ‚â§ 70));
Output: Cell array ùê∂ùëôùë¢ùë†ùë°ùëíùëü, ùëõ cells of ùê∂ùëôùë¢ùë†ùë°ùëíùëü represent ùëõ age subranges;
1: Using Eq. Eq. (4) to calculate ùêå;
2: Initialize cell array ùê∂ùëôùë¢ùë†ùë°ùëíùëü =  {1, 2, ‚ãØ , 70} , ‚àÖ, ‚àÖ, ‚ãØ , ‚àÖ ;
‚èü‚èû‚èû‚èû‚èü‚èû‚èû‚èû‚èü

number of age subranges is 10. One can see that when ùëõ = 10, each
3: while ùê∂ùëôùë¢ùë†ùë°ùëíùëü {ùëõ} = ‚àÖ do	‚é©
ùëõ‚àí1	‚é≠












/ig. 4. Change of cohesion and number of CIAs with an increasing number of age subranges.

choice,1 i.e., C1 = {1, 2, ‚Ä¶ , 7}, C2 = {8, 9, ‚Ä¶ , 16}, C3 = {17, 18, ‚Ä¶ , 51},
C4 = {52, 53, ‚Ä¶ , 70}. Table 2 lists the CIAs in age subrange Cùëñ and the ratio of DEFEA ùõæ calculated by
  ùêÉ (ùëñ, ùëü)	

/ig. 3. Change of cohesion and number of IAs with division number.
ùëü (ùëñ, ùëü) =
‚àëùëò‚ààk ùêÉ (ùëñ, ùëò)
‚ãÖ 100%.	(9)

4:		Initialize array ùêøùê∂, the size of ùêøùê∂ is ùëõ, the elements of ùêøùê∂ are 0;
5:	for ùëó = 1 ‚à∂ ùëõ do
6:	if ùê∂ùëôùë¢ùë†ùë°ùëíùëü {ùëó} ‚â† ‚àÖ then
7:	ùêøùê∂ (ùëó) ‚Üêthe cohesion of ùê∂ùëôùë¢ùë†ùë°ùëíùëü {ùëó};
8:	end if
9:	end for
10:	ùëò ‚Üê arg max ùêøùê∂;
11:	ùëé ‚Üê min ùê∂ùëôùë¢ùë†ùë°ùëíùëü {ùëò};
12:	ùëè ‚Üê max ùê∂ùëôùë¢ùë†ùë°ùëíùëü {ùëò};
13:	Initialize array ùëÜùê∂, the size of ùëÜùê∂ is (ùëè ‚àí ùëé), the elements of ùëÜùê∂
are 0;
14:	for ùëô = 1 ‚à∂ ùëè ‚àí ùëé do
15:	ùëÜùê∂ (ùëô) ‚Üêthe sum of the cohesion of {ùëé, ùëé + 1, ‚ãØ , ùëé + ùëô ‚àí 1}
and
16: {ùëé + ùëô, ‚ãØ , ùëè};
17:	end for
18:	ùë¢ ‚Üê arg min ùëÜùê∂ + ùëé ‚àí 1;
19:	for ùëñ = ùëõ ‚àí 1 ‚à∂ ‚àí1 ‚à∂ ùëò + 1 do
20:	ùê∂ùëôùë¢ùë†ùë°ùëíùëü {ùëñ + 1} ‚Üê ùê∂ùëôùë¢ùë†ùë°ùëíùëü {ùëñ};
In Table 2, there is a total of 27 different medical attributes. The number of CIAs varies greatly across age subranges. Specifically, there
are 18 CIAs in the age subrange C1, which is the most. The number of
CIAs in the age subrange C3 is 7, which is the least. In addition, the number of CIAs in age subrange C2 and C4 are 13 and 11, respectively.
non-CIAs in age subrange C1 are not much different, on the contrary, This implies that the values of DEFEA CIAs and the values of DEFEA the values of DEFEA CIAs in age subrange C3 are much higher than
that of non-CIAs, which is consistent with Fig. 2. For the most medical attributes, the value of DEFEA remains below 0.4 at any age, we can
think that the smaller the number of CIAs in age subrange Cùëñ, the higher the value of DEFEA of CIAs in age subrange Cùëñ.
Note that the correlation between CIAs is not considered in Algo- rithm 1, therefore, the Pearson correlation method is firstly used to reduce some correlated medical attributes for facilitating the construc- tion of GRMs. Generally speaking, if the absolute value of Pearson
correlation coefficient corr (x, y) is greater than ùõø = 0.80, the variables
ùë• and ùë¶ have a strong correlation. Table 3 lists all medical attributes
with the absolute value of Pearson correlation coefficients larger than
ùõø. When corr (x, y) > ùõø, we discard the medical attribute with a low
value of DEFEA. For a more intuitive display, Table 2 shows whether

21:	end for
the attribute is retained or not, in which ‚Äò‚Äò
‚Åì‚Åì‚Åì‚Åì
‚Äô‚Äô means that the

22:	ùê∂ùëôùë¢ùë†ùë°ùëíùëü {ùëò} ‚Üê {ùëé, ùëé + 1, ‚ãØ , ùë¢};
23:	ùê∂ùëôùë¢ùë†ùë°ùëíùëü {ùëò + 1} ‚Üê {ùë¢ + 1, ùë¢ + 2, ‚ãØ , ùëè};
24: end while
25: return ùê∂ùëôùë¢ùë†ùë°ùëíùëü

Through Algorithm 1, the age range f is divided into many age subranges, but excessive division is not necessary. To determine the optimal number of age subranges, two methods are used in this paper. One is to observe the changing trend of the sum of cohesion of all age subranges as the number of age subranges increases. The other is to observe the changing trend of the number of different CIAs in all age subranges as the number of age subranges increases. Fig. 4 illustrates the aforementioned two trends with an increasing number of age subranges. One observes that the total cohesion decreases with the number of age subranges increases and tends to saturation. While, the number of different CIAs in all age subranges increases with an increasing number of age subranges and also tends to saturation. To make the division results as accurate as possible, we need to make trade-offs. On the one hand, it is necessary to avoid unnecessary
medical attribute is discarded, otherwise the medical attribute is used to construct the GRMs.

Gender recognition

To further assess the effectiveness of CIAs, in this section, according to whether the age is known or not, we construct two GRMs to distin- guish the gender of samples. In particular, we study an effective GRM for case I in which the age is known. While, for the age is not known,
represent the reserved CIAs in the age subrange ùê∂ùëñ as the set ùúéùëñ. called case II, we design another GRM. For the sake of explanation, we
Case I: When the age is known, it is easy to know that the sam- ple belongs to which of the four age subranges. This implies that we can use the CIAs of each age subrange to construct the corresponding
GRM. Let the samples whose age belongs to age subrange Cùëñ constitute a sample subset Xùëñ, ùëñ ‚àà ùúõ = {1, 2, 3, 4}. It is not difficult to find that
the gender recognition problem belongs to two-classification problem. Therefore, for the age subrange Cùëñ, the two-classification learning algo- rithm such as Logistic Regression (LR) [23], Random Forest (RF) [24],

divisions. On the other hand, it is necessary to ensure that ages within		

in what follows, we divide age ranges f into 4 age subranges is a better the same age subrange have similar CIAs. Combining these two factors,
1 The proposed gender recognition can be used in other cases, i.e. other number of age subranges.


Table 2
CIAs and their DEFEA ratio.
Age subrange	CIAs and the DEFEA ratios
MCV (4.00%), MCH (3.14%), ALT (3.04%), MONO (3.01%), A_G (2.95%), RDW-SD (2.95%),

C1 = {1, 2, ‚Ä¶ , 7}
C2 = {8, 9, ‚Ä¶ , 16}
RDW-CV (2.95%), EO (2.95%), TP (2.93%), AST/ALT (2.89%), HGB (2.87%), RBC (2.83%),
PDW (2.82%), LYM (2.81%), MPV (2.80%), LYM# (2.74%), CREA (2.68%), BUN (2.62%)
RBC (5.44%), HGB (5.14%), HCT (4.53%), UA (4.35%), CREA (3.94%),
MCV (3.34%), INR (3.01%), BUN (2.85%), ALT (2.76%), PT% (2.68%),
AST (2.62%), PT_Ratio (2.58%), MONO (2.56%)
HGB (9.79%), CREA (9.77%), HCT (9.60%), RBC (8.26%),

C3 = {17, 18, ‚Ä¶ , 51}
‚Åì‚Åì
UA (5.51%), AST/ALT (4.52%), ALT
(4.40%)

CREA (8.76%), HGB (6.02%), HCT (5.40%), RBC (4.34%), UA (4.11%), MONO# (3.50%),

C4 = {52, 53, ‚Ä¶ , 70}
‚Åì‚Åì
MONO (3.00%), MCH (2.86%), DBIL
(2.75%), LYM (2.74%), MCHC (2.58%)




Table 3
Correlation coefficient of the removed medical attributes.
recognition model ùêµùëñ is trained using samples at all ages. In particular, to train recognition ùêµùëñ, the CIAs in set ‚à™ùëñ‚ààùúõ ùúéùëñ are regarded as features.
At the same time, the males sample and females sample in sample subset Xùëñ are labeled as ‚Äò‚Äòm‚Äô‚Äô and ‚Äò‚Äòf‚Äô‚Äô, respectively, and the sample
in set ‚à™ùëó‚â†ùëñXùëó is labeled as ‚Äò‚Äòo‚Äô‚Äô. Then, the three probabilities of each
age subrange are jointly used to identify the gender of samples via computing the integrated probabilities of males and females, i.e.,
ùúå (ùëö) = ‚àë ùëùùëñ (ùëö) ,

ùëñ‚ààùúõ ùëùùëñ (ùëú)
( ) =	ùëùùëñ (ùëì )
ùëñ‚ààùúõ ùëùùëñ (ùëú)
(10)



/ig. 5. Gender recognition process of GRM A.


/ig. 6. GRM B.



can be used to construct the recognition model ùê¥ùëñ. The recognition model ùê¥ùëñ is trained with the samples in sample subset Xùëñ by regarding the elements in the set ùúéùëñ as the features and the basic attribute SEX as the label of samples, respectively. Thus, all recognition models ùê¥ùëñ
constitute GRM A. When using GRM A for gender recognition, if the age
of sample to be identified is within the age subrange Cùëñ, the sample is identified by the corresponding recognition model ùê¥ùëñ is shown in Fig. 5.
Case II: When the age is not known, we do not know which age subrange the age of sample to be identified belongs to, it means that the ideas of designing GRM A cannot be directly used. To effectively exploit the CIAs of each age subranges, in what follows, we design a three-classification learning for each age subrange. Then, the integration learning method is used to construct GRM B to identify the gender of the samples to be identified. Specifically, recognition model
ùêµùëñ for age subrange ùê∂ùëñ has the ability of identifying the gender of the
probabilities ùëùùëñ (ùëö), ùëùùëñ (ùëì ), and ùëùùëñ (ùëú). ùëùùëñ (ùëö) is the probability that the sample and judging the age range of the sample by outputting three
the age subrange Cùëñ. ùëùùëñ (ùëì ) is the probability that the age of sample to age of sample to be identified with the gender being males is within be identified with the gender being females is within age subrange Cùëñ.
ùëùùëñ (ùëú) is the probability that the age of sample to be identified is not in
age subrange Cùëñ. Unlike the training process of recognition model ùê¥ùëñ,
If ùúå (ùëö) > ùúå (ùëì ), the gender of sample is males, otherwise is females.
To clearly describe GRM B for case II, the detailed structure of GRM B is
illustrated in Fig. 6. Note that even the age of samples to be identified is known, we also can use GRM B to identify the gender of samples via ignoring the age information. This implies that GRM B has a wider range of applications compared to GRM A.

Experiment

In this section, we evaluate the performance of the GRMs and discuss further the role of CIAs as well as the important of the division of age range. For each experiment, five learning algorithms, i.e., LR, linear discriminant analysis (LDA) [25], naive Bayes (NB) [26], RF, and gradient boosting decision tree (GBDT) [27], are used. In addition, for
comparison, we also evaluate several simple GRM, i.e., GRM0, GRM1,
and GRM2. In particular, GRM0 directly identifies the gender of the
factor. GRM0 is trained with samples at all ages and uses ‚à™ùëñ‚ààùúõ ùúéùëñ as sample via two-classification method, i.e., without considering the age the training feature. GRM1 and GRM2 regard the CIAs in ‚à™ùëñ‚ààùúõ ùúéùëñ and in
‚à™ùëó‚â†ùëñùúéùëó as features to train GRM ùê¥ùëñ, respectively. We take the recognition
result of recognition model ùê¥ùëñ as the result of GRM A (GRM1 and GRM2) in age subrange Cùëñ. The recognition results of GRM B and GRM0 in age subrange Cùëñ are computed via the sample whose age belongs to age
subrange Cùëñ.
Table 4 shows the recognition accuracy of GRM A and GRM B. It can
be seen that when we use the classical learning algorithm such as LR, LDA, and NB, there is a comparable performance difference between
GRM A and GRM B in age subrange C1 and C2. Specifically, GRM A
is a tiny difference between GRM A and GRM B in age subrange C3 and obtains about 6% accuracy gain compared to GRM B. However, there C4. When using learning algorithms with strong learning ability, such
reach the level of GRM A in age subrange C1, and in age subrange C3 as RF and GBDT are adopted, the recognition accuracy of GRM B can and C4, GRM B outperforms GRM A. Experimental results show that the
in age subrange C1 and C2. In addition, no matter GRM A or GRM B, the lack of age information has a more severe impact on gender recognition accuracy of five algorithms is the lowest in age subrange C1, and is the highest in age subrange C3. This is because the smaller the number of
CIAs in age subrange Cùëñ, the larger the value of DEFEA in age subrange
Cùëñ. We also find that the smaller the number of CIAs in age subrange Cùëñ,

Recognition performance of GRM A and GRM B.
Model	Age subrange	Algorithm (Mean¬±Std of Accuracy)


Table 5
Comparison between GRM0 , GRM B and GRM1 .
Age subrange	Model	Algorithm (Mean¬±Std of Accuracy (Gain (%)))


the better the recognition accuracy of GRMs in age subrange Cùëñ. This shows that the medical attributes with a large value of DEFEA really
contribute to gender recognition.
Table 5 gives out the comparison between GRM0, GRM B, and GRM1
to further evaluate the effectiveness of GRM B and analyze the role
of age range division. Note that in most age subranges, GRM B with
age subrange C2, GRM B does not show an overwhelming advantage. the five learning algorithms obtains up to 1% gain. However, in the
However, it is worth mentioning that if the learning algorithms NB, RF
that of GRM0 in age subrange C2. This means that GRM B is effective or GBDT are used, the recognition accuracy of GRM B is still higher than even for age subrange C2 which is most affected by the lack of age
information. At the same time, it also shows that if we do not know the age of samples and divide the age range, we can still improve the accuracy of gender recognition. Let us look at the results of another
GRM1 outperforms GRM0 in terms of the recognition accuracy for the group of control experiments, it can be seen that in all age subranges, five learning algorithms. In particular, in age subrange C1 and C2, the average gain is 10.3%, while in age subrange C3 and C4, the average
gain is 2.8%. This means that if we know the age of samples, the age range division will improve the accuracy of gender recognition more, which is much higher than the case of unknown sample age. Furthermore, the division of age range is more helpful for gender
recognition in age subrange C1 and C2. This is because the gender
differences are different in different age subranges, and learning their
gender difference information separately helps improve recognition accuracy. If the age range is not divided, GRM is more inclined to learn the gender difference information of medical attributions in age
subrange C3 and C4 in which the gender difference is obvious.
Table 6 lists the comparison between GRM A, GRM1, and GRM2 to reflect the role of CIAs. We can see that in age subrange C1 and C2, GRM1 has no significant improvement in terms of the recognition accuracy compared to GRM A. This means that for age subranges C1 and C2, the selection of CIAs is appropriate, and we have not left out
age subranges C3 and C4, the participation of more medical attributes any useful medical attributes for distinguishing males and females. For
leads to a small improvement in recognition accuracy. In particular, in age subrange C3 and C4, GRM1 obtains about 2% gain in terms of the recognition accuracy at the cost of large computation complexity. This
distinguishing males and females. For example, in age subrange C3, the means that the CIAs cover the vast majority of useful information for
with only six CIAs. In age subrange C1 and C2, compared to GRM five learning algorithms can achieve about 92% recognition accuracy A, GRM2 has 10% recognition accuracy loss. While, the recognition accuracy loss will be more in age subrange C3 and C4, close to 20%.
subrange C1 and C2 are not much different, on the contrary, the values The values of DEFEA CIAs and the values of DEFEA non-CIAs in age of DEFEA CIAs in age subrange C3 and C4 are much higher than
that of non-CIAs, which leads to the above situation. The above two comparisons show that the CIAs are indeed more conducive to gender


Table 6
Controlled experiments on the role of CIAs.
Age subrange	Model	Algorithm (Mean¬±Std of Accuracy (Gain (%)))
(Attribute number)	LR	LDA	NB	RF	GBDT
GRM A	0.6069 ¬± 0.0203	0.6254 ¬± 0.0206	0.6152 ¬± 0.0300	0.6134 ¬± 0.0230	0.6192 ¬± 0.0136
(16)	(‚Äì)	(‚Äì)	(‚Äì)	(‚Äì)	(‚Äì)

C1 = {1, 2, ‚Ä¶ , 7}


C2 = {8, 9, ‚Ä¶ , 16}


C3 = {17, 18, ‚Ä¶ , 51}


C4 = {52, 53, ‚Ä¶ , 70}
GRM1	0.6069 ¬± 0.0248	0.6217 ¬± 0.0224	0.6120 ¬± 0.0312	0.6051 ¬± 0.0150	0.6203 ¬± 0.0177
(23)	(0.00%)	(‚àí0.59%)	(‚àí0.52%)	(‚àí1.35%)	(0.18%)
GRM2	0.5138 ¬± 0.0225	0.5917 ¬± 0.0278	0.5895 ¬± 0.0295	0.5536 ¬± 0.0227	0.5783 ¬± 0.0259
(7)	(‚àí15.34%)	(‚àí5.39%)	(‚àí4.18%)	(‚àí9.75%)	(‚àí6.61%)
GRM A	0.6999 ¬± 0.0356	0.7308 ¬± 0.0337	0.6807 ¬± 0.0287	0.7276 ¬± 0.0192	0.7295 ¬± 0.0273
(11)	(‚Äì)	(‚Äì)	(‚Äì)	(‚Äì)	(‚Äì)
GRM1	0.6992 ¬± 0.0433	0.7321 ¬± 0.0202	0.6807 ¬± 0.0295	0.7270 ¬± 0.0154	0.7315 ¬± 0.0258
(23)	(‚àí0.10%)	(0.18%)	(0.00%)	(‚àí0.08%)	(0.27%)
GRM2	0.5969 ¬± 0.0522	0.6542 ¬± 0.0212	0.6420 ¬± 0.0214	0.6349 ¬± 0.0212	0.6426 ¬± 0.0271
(12)	(‚àí14.72%)	(‚àí10.48%)	(‚àí5.69%)	(‚àí12.74%)	(‚àí11.91%)
GRM A	0.9222 ¬± 0.0060	0.9276 ¬± 0.0049	0.9116 ¬± 0.0072	0.9234 ¬± 0.0059	0.9287 ¬± 0.0058
(6)	(‚Äì)	(‚Äì)	(‚Äì)	(‚Äì)	(‚Äì)
GRM1	0.9390 ¬± 0.0078	0.9428 ¬± 0.0045	0.9155 ¬± 0.0057	0.9377 ¬± 0.0044	0.9413 ¬± 0.0060
(23)	(1.82%)	(1.64%)	(0.43%)	(1.55%)	(1.35%)
GRM2	0.7444 ¬± 0.0151	0.7564 ¬± 0.0130	0.7345 ¬± 0.0151	0.7521 ¬± 0.0068	0.7545 ¬± 0.0086
(17)	(‚àí19.28%)	(‚àí18.46%)	(‚àí19.43%)	(‚àí18.55%)	(‚àí18.76%)
GRM A	0.8419 ¬± 0.0117	0.8391 ¬± 0.0124	0.8235 ¬± 0.0108	0.8475 ¬± 0.0087	0.8460 ¬± 0.0077
(10)	(‚Äì)	(‚Äì)	(‚Äì)	(‚Äì)	(‚Äì)
GRM1	0.8678 ¬± 0.0151	0.8656 ¬± 0.0126	0.8367 ¬± 0.0175	0.8677 ¬± 0.0086	0.8674 ¬± 0.0105
(23)	(3.08%)	(3.16%)	(1.60%)	(2.38%)	(2.53%)
GRM2	0.6630 ¬± 0.0134	0.6683 ¬± 0.0129	0.6554 ¬± 0.0136	0.7054 ¬± 0.0102	0.6724 ¬± 0.0122
(13)	(‚àí21.25%)	(‚àí20.36%)	(‚àí20.41%)	(‚àí16.77%)	(‚àí20.52%)




recognition than other attributes and cover most of the information that can be used for gender recognition.

Conclusion

In this paper, we proposed a method for calculating the difference of medical attributes between males and females at a specified age via the distribution of medical attributes of males and females. We find that only a few medical attributes have an obvious differences between males and females. Then, we further analyzed the differences between males and females by cluster analysis, and found some CIAs in a certain age subrange. In addition, we proposed two GRMs based on the results of data analysis to identify the gender of samples according to whether the age is known or not. Experiment results have shown that in a certain age range, such as 17 to 51 years old, the proposed GRM can reach 92.8% accuracy using only six medical attributes. In addition to evaluating GRM recognition effect, we also verified the effectiveness of GRM B, cluster analysis, and CIAs through comparative experiments.

Declaration of competing interest

The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper.

References

Hydari MZ, Telang R, Marella W. Saving patient ryan - Can advanced electronic medical records make patient care safer? Manage Sci 2018;65:2041‚Äì59.
Junmei Z, Xiu Y, Jian W, Zhuquan S. Artificial intelligence based data governance for Chinese electronic health record analysis. Int J Data Min Knowl Manage Process 2018;8(3):29‚Äì41.
Chen L, Yang J-J, Wang Q. Privacy-preserving data publishing for free text Chinese electronic medical records. In: IEEE annual computer software and applications conference. 2012, p. 567‚Äì72.
Yoon J, Jordon J, van der Schaar M. GAIN: Missing data imputation using generative adversarial nets. In: International conference on machine learning, Vol. 80. 2018, p. 5689‚Äì98.
Yang Y, Wu Z, Tresp V, Fasching PA. Categorical EHR imputation with generative adversarial nets. In: IEEE international conference on healthcare informatics (ICHI). 2019.
Luo Y, Cai X, Zhang Y, Xu J, Yuan X. Multivariate time series imputation with generative adversarial networks. In: International conference on neural information processing systems. 2018, p. 1603‚Äì14.
Yoon J, Zame WR, Der Schaar MV. Estimating missing data in temporal data streams using multi-directional recurrent neural networks. IEEE Trans Biomed Eng 2019;66(5):1477‚Äì90.
McLean C, Ransom J, Galaznik A. PCN432 evaluation of missing data imputation strategies in clinical trial and emr data using standardized data models. Value Health 2019;22:S520.
Foomani FH, Anisuzzaman D, Niezgoda J, Niezgoda J, Guns W, Gopalakrish- nan S, Yu Z. Synthesizing time-series wound prognosis factors from electronic medical records using generative adversarial networks. 2021, arXiv preprint arXiv:2105.01159.
Li B, Lian X, Lu B. Gender classification by combining clothing, hair and facial component classifiers. Neurocomputing 2012;76(1):18‚Äì27.
Hosseini S, Lee SH, Kwon HJ, Koo HI, Cho NI. Age and gender classification using wide convolutional neural network and gabor filter. In: International workshop on advanced image technology. 2018, p. 1‚Äì3.
Nie Y, Liang B, Huang P, Ren W, Dai J. A study on image based gender classification using convolutional neural network. In: International conference on deep learning technologies (ICDLT). Association for Computing Machinery; 2019, p. 81‚Äì4.
pal M, Bhattacharyya S, Sarkar T. Euler number based feature extraction technique for gender discrimination from offline hindi signature using SVM & BPNN classifier. In: Emerging trends in electronic devices and computational techniques. 2018, p. 1‚Äì6.
Choi Y, Kim Y, Kim S, Park K, Park J. An on-device gender prediction method for mobile users using representative wordsets. Expert Syst Appl 2016;64:423‚Äì33.
Dongxu LI, Yongjun LI, Wenli JI. Gender identification via reposting behaviors in social media. IEEE Access 2017;PP(99):1.
Kaur B, Singh D, Roy PP. Age and gender classification using brain-computer interface. Neural Comput Appl 2019;31(10):5887‚Äì900.
Serkan O, Turan M, Z√ºlal O. Estimation of gender by using decision tree, a machine learning algorithm, with patellar measurements obtained from MDCT images. Med Rec 2021;3(1):1‚Äì9.
Nitta Y, Shinomiya Y, Park K, Yoshida S. A 3D-CNN classifier for gender discrimination from diffusion tensor imaging of human brain. In: International conference on soft computing and intelligent systems and 21st international symposium on advanced intelligent systems (SCIS-ISIS). 2021, p. 1‚Äì4.
Zheng J, Hui Y, Fu Q. Investigation and analysis on reference value range of peripheral blood routine in preschool children from Shanghai. Int J Lab Med 2014;(16):2194‚Äì6.



Min-Jie WU, Liang-Feng HU, Miao Y, Shen GJ, Hospital SP. Influence of age and gender on the red cell parameters in healthy people. Chin J Health Lab Technol 2016;26(11):1619‚Äì21.
Clifford SM, Bunker AM, Jacobsen JR, Roberts WL. Age and gender spe- cific pediatric reference intervals for aldolase, amylase, ceruloplasmin, creatine kinase, pancreatic amylase, prealbumin, and uric acid. Clin Chim Acta 2011;412(9):788‚Äì90.
Casella G, Berger RL. Statistical inference, Vol. 2. Pacific Grove, CA: Duxbury; 2002.
Hosmer Jr DW, Lemeshow S, Sturdivant RX. Applied logistic regression, Vol.
34. 2013, p. 358‚Äì9, no. 3.
Breiman L. Random forests. Mach Learn 2001;45(1):5‚Äì32.
Fukunaga K. Inroduction to statistical pattern recognition, Vol. 22. 1990, p. 70.
Domingos P, Pazzani M. On the optimality of the simple Bayesian classifier under zero-oneloss. Mach Learn - ML 1997;29:103‚Äì30.
Friedman JH. Greedy function approximation: A gradient boosting machine. Ann Statist 2001;29(5):1189‚Äì232.
