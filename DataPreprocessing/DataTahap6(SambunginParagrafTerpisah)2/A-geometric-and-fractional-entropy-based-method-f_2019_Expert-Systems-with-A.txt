Xia, Pan, and Qin (2014) proposed face clustering in a photo al- bum, where the method explores spectral features, similarity fea- tures, minimum cost flow and clustering. The proposed features are extracted from cropped face images. The main objective of the method is to find images which share the same faces. This idea is good for grouping personal collections but not family and non- family image classification.

Qin, Tan, and Chen (2015) proposed tri-subject kinship verifica- tion for understanding the core of a family. The method proposes a degree of similarity between children and parents, resulting in a triangular relationship. To achieve this, the method uses a rela- tive symmetric bilinear model for estimating similarity. To improve the results, the method takes spatial information into account. This method is good as long as the recognition approach provides suc- cessful results; however, recognition-based methods may not be

Robinson et al. (2018) proposed visual kinship recognition of families in the wild. This method explores deep learning for face verification, clustering and boosted baseline scores. The method involves multimodal labeling to optimize the annotation process. This includes information of faces and metadata collected from family photos. It is noted that although the method explores re- cent powerful deep learning approaches for kinship identification, it is still limited to family photos but not non-family photos.

Wang et al. (2015, 2017) proposed leveraging geometry and ap- pearance cues for recognizing family photos. The methods identify facial points for each face in an image. Based on facial points, the method constructs polygons to study geometric features of faces in the image. Due to the height difference of persons and the arrange- ment of faces in family and non-family images, the method gets different polygons to study geometric features. It estimates pair- wise relationships like kinship recognition, and generates a code- book using k-means clustering. Furthermore, the degree of similar- ity of each group is extracted for classifying family and non-family photos with the help of an SVM classifier. However, classification may not be accurate when the heights of persons in an image do not follow a hierarchical arrangement. In addition, one might ex- pect that non-family members could have the same arrangements and heights.

In light of the above discussions, we can assert that a few methods have addressed family and non-family photo classification or identification, but most of the methods focus on kinship recog- nition based on face detection and recognition. These methods may not work well for images where we can see faces with multi- ple emotions, postures and actions. The methods which addressed family and non-family classification explore only foreground in- formation (facial information) for achieving their results. This is good for images with simple backgrounds but not images that have complex backgrounds, where we can expect open scenes and out- door environments in the case of non-family photos. Therefore, we can conclude that there is a critical need for an accurate method to classify family and non-family photos.

images. The combination of spatial information, angles that extract the geometric structure of faces, and fractional entropy that ex- tracts the texture of facial and background regions, produces a fea- ture vector. Furthermore, the feature vector is passed to a Convo- lutional Neural Network (CNN) to overcome the above-mentioned challenges.

The contributions of this work are two-fold. (1) Exploring spa- tial and angle features for extracting the spatial and directional co- herence through the geometric structure of face regions. (2) Intro- ducing fractional entropy for extracting the texture of facial and background regions, which extracts regular patterns in the images.

The proposed method computes the mean of distances to ex- tract spatial features and the mean of angles for extracting angle features for each image. The reason for computing the average is to widen the difference between family and non-family images. As discussed in the Introduction Section, family images have persons with almost the same facial appearance, while non-family images have persons with different facial appearances. This is valid be- cause one can expect a high degree of similarity between the ap- pearances of faces from the same family. It may not be true for non-family images. In addition, family and non-family images can have any number of faces, which should be more than 3 persons in the images. In this situation, the average features for a family does not make much difference, while for non-family, the average makes a vast difference. Since the appearance of faces in a family have a high degree of similarity compared to those in non-family images, it is expected that the average gives almost the same val- ues for family images while for non-family, we cannot predict the same values always. Besides, to make the spatial and angle features invariant to the number of faces, the proposed method considers the average for achieving better results.

As mentioned in the Introduction Section, it is found that the other than face region also provides cues for discriminating fam- ily and non-family images. However, the previous step does not explore other than face region. Therefore, inspired by the method in Ibrahim, Moghaddasi, Hamid, and Noor (2015) where fractional calculus has been used for studying texture in splicing images, this section explores a new Tsallis fractional entropy-based texture (Tsallis et al., 2009) for studying variations in background as well as facial regions in family and non-family images. An overview of the Tsallis fractional entropy is presented in the following.

a large number of samples for training and labeling samples, we prefer to use the combination of the proposed features and the CNNs rather than raw pixels with the recent deep learning mod- els. The main objective of the proposed work is to propose fea- tures that can classify the family and non-family photos. Thus, the proposed features are fed to a pre-defined CNN classifier which is available online (Arora & Suman, 2012) for classification in this work. For learning parameters of the classifier, we follow a 10-fold cross-validation procedure, which splits the dataset into training and testing components. The training samples are used for learn- ing and adjusting the parameters of the classifier and the testing samples are used for evaluation. The complete algorithmic steps of the proposed method for classifying family and non-family images are presented below.

The concatenated features are then passed to a fully connected Convolutional Neural Network (CNN) for classifying family and non-family images (McAllister et al., 2016). Inspired by the method (Nanni, Chidoni, & Brahnam, 2018), where it is mentioned that the combination of handcrafted features and the ensemble of CNNs give better results than deep learning tools such as GoogleNet, ResNet50 that use raw pixels of the input images for bioimage clas- sification, we explore the same idea of combining the proposed features with the CNN for family and non-family image classifi- cation in this work. Since the proposed work does not provide instructions suggested in Gallagher et al. (2009), Wang et al. (2017, 2015). Furthermore, the dataset includes one photo for one family. In other words, the dataset does not have multiple photos of the same family. In total, our dataset consists of 388 family images and 382 non-family images, which gives a total of 770 images.

To show that the proposed method is superior in comparison to existing methods, we implemented two state-of-the-art meth- ods, namely, Wang et al. (2015), which explores facial geometric features and facial appearance model-based features. The features are passed to an SVM classifier for family and non-family image classification. Please note, the same idea is extended and the re- sults are improved in Wang et al. (2017) for the purpose of family and non-family image classification. However, both the ideas fo- cused only on facial regions for achieving results; these also ig- nored background clues.

382 for non-family images of our dataset. This is the advantage of the benchmark dataset for achieving the best results compared to ours. This is because when we feed a large number of training samples to the classifier, it covers more possible variations in im- ages. Therefore, a large number of training samples and more vari- ations led to achieving the best results for the benchmark dataset by the proposed method compared to our dataset.

proposed method on our dataset and the benchmark dataset. The reason for misclassification is that when the images of family and non-family images share geometric structures of the faces and the properties of backgrounds, the proposed method fails to perform correct classification. Therefore, there is scope for improvement in the future.

In this paper, we have proposed a new idea for classifying fam- ily and non-family photos by combining facial structure and back- ground texture. The proposed method explores distances between facial key points for extracting spatial features. In addition, angles between facial key points are also explored for studying the struc- tures of faces, which are called geometric features. To make use of the background information and textural properties of facial re- gions, we have proposed novel Tsallis fractional entropy-based fea- tures. Furthermore, the proposed method combines spatial, angle and fractional entropy features to obtain the feature vector. The feature vector is applied to a conventional convolutional neural network for classification. Experimental results on our own dataset and the benchmark datasets show that the proposed method is better than two state-of-the-art methods in terms of average clas- sification rate.

The main contributions are the following. It is inherent that fa- cial regions are the key factor for family and non-family photo im- age classification. Based on this observation, we explore distance features for facial key points as spatial features to study the struc- ture of facial regions. We have used angle information for facial key points to make spatial features robust to extract the detailed structure of facial regions. The way we combine spatial and angle- based features as geometric ones is novel and an interesting ap- proach to tackle the issues of family and non-family photo classifi- cation. To extract regular patterns in facial and background regions (other than facial region), we propose a novel idea of introducing Tsallis fractional entropy for extracting texture properties of facial regions and other background regions. Furthermore, the proposed method combines geometric and fractional entropy features in a different way for achieving the best results.

Despite having proposed a new idea for family and non-family images classification, there are some limitations to the proposed approach. Sometimes, when family and non-family image share the same properties of facial regions with the background, the pro- posed method fails to yield good results. This is understandable because one can expect similar patterns of foreground and back- ground for both family and non-family images. In this case, we need a method, which can work irrespective of background and facial regions. One way is to introduce context features using fore- ground and background information to find a solution regarding

When photos contain both family and non-family members, the proposed method may not work well. It is beyond the scope of the proposed work as it is hard to separate family or non-family mem- bers in the same image. To find a solution, one possible way is to bring multimodal concepts, such as face, skin, dress, and structure of the body. This is due to the potential of sharing personal traits and habits with members belonging to the same family. If individ- uals do not belong to a particular family, we can expect different habits, structures (apart from the face), skin, etc.

Maryam Asadzadeh Kaljahi: Implementing Methodology, data curation. Palaiahnakote Shivakumara: Conceptualization, Formal analysis, Supervision, Draft writing, Investigation. Tiangping Hu: data curation, Validation. Hamid A. Jalab: Formal analysis, Model- ing. Rabha W. Ibrahim: Formal analysis, Modeling. Michael Blu- mentsein: Review editing. Tong Lu: Validation and reviewing. Mohamad Nizam: Validation and reviewing.

