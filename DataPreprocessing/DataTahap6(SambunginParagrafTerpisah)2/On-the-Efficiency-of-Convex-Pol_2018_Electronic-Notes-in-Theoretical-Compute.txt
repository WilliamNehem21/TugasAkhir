The domain of convex polyhedra plays a special role in the collection of numerical domains considered for program analysis and verification. As far as precision is concerned, it would be the most natural choice in many contexts but, due to its worst case exponential complexity, it is sometimes considered an unaffordable option. This has led to a systematic quest for simpler domains that are capable of reasonable precision using less computational resources. There are anyway cases where the use of the domain of convex polyhedra turns out to be feasible, also due to recent progress in their implementation. After reviewing a few known approaches to decrease the amount of resources needed when computing on this domain, we will introduce a couple of novel techniques that can be used to further improve its efficiency, without incurring precision losses.

As far as precision is concerned, the domain of convex polyhedra would be the most natural choice in many contexts. However, due to its worst case exponential complexity, it is often considered an unaffordable option from a practical point of view. This has led to a systematic quest for domains that are simpler than convex polyhedra, so as to be less demanding in terms of computational resources, and yet capable of reasonable precision. An incomplete list of so-called weakly relational abstract domains can be filled by a review of the relevant literature of the past years: bounded differences [26,33], bounded logahedra [21], octagons [27], octahedra [10],

In the following we will consider new algorithms and implementation techniques that can be used to decrease the amount of resources needed when computing on the domain of convex polyhedra. In particular, we will focus on those approaches that have the potential of improving the efficiency of the analysis without incurring precision losses. The techniques presented, which are the result of ongoing collabo- rations, have all been implemented in the context of the Parma Polyhedra Library. Being work in progress, only preliminary experimental evaluations have been con- ducted so far. The initial results, besides confirming the absence of precision losses, are encouraging in terms of the efficiency gains that can be obtained.

The paper is structured as follows. Section 2, after introducing some notation and terminology, provides an informal presentation for the DD method. In the next two sections we present some of the work in progress on the domain of convex polyhedra: Section 3 discusses the use of domain wrappers to improve the efficiency in specific contexts; Section 4 describes a new approach for the representation and manipulation of NNC polyhedra. We conclude in Section 5.

The Double Description method due to Motzkin et al. [29], by exploiting the duality principle, allows to combine the constraints and the generators of a poly- hedron P into a DD pair (C, G): a conversion procedure is used to obtain each description starting from the other one, also removing the redundant elements. 4 For presentation purposes, we focus on the conversion from constraints to genera- tors. We also omit the description of important concepts such as polyhedral cones, homogenization, the lattice of faces and adjacency; the interested reader is referred to [37] for the theory and to [9,24] for the details related to implementation.

Another possible optimization can be applied to the approximation of invert- ible affine assignments, i.e., those where the variable assigned also occurs in the right hand side affine expression (e.g., x = x + 1). If the variable is known to be unconstrained, then the affine map modeling the assignment is the identity func- tion. However, the Apron interface layer to the PPL domains seems to prevent the use of domain operators computing affine images: an assignment such as x = x + 1 is implemented by (a) adding the primed variable xj, (b) adding the constraint xj = x + 1, (c) projecting away the unprimed variable x and finally (d) renaming xj to x. Also, invertible assignments rarely occur when analyzing programs using PAGAI (we conjecture this is another side effect of the SSA transformation).

A preliminary experimental evaluation, passing all of the regression tests of the PPL, shows important efficiency improvements on many benchmarks. Besides the expected gains on the NNC tests, we also observed a few unexpected efficiency gains on the topologically closed tests, i.e., when comparing the new algorithm with the

Despite the intrinsic limitations implied by its theoretical complexity bounds, the domain of convex polyhedra turns out to be a feasible option in several contexts [36]. This is due not only to the recent progress on their implementation, but also to the understanding of the common efficiency bugs that a static analysis tool using this domain should definitely avoid. In this paper we have proposed a few domain wrap- pers that are able to provide an automatic workaround to some of these efficiency bugs. We have also sketched a new idea for the representation and manipulation of NNC polyhedra that seems to have a great potential in terms of efficiency with respect to the currently available implementations.

Most of the new material presented in this paper is the result of joint work still in progress. The author would like to acknowledge Gianluca Amato and Francesca Scozzari for the contents presented in Sections 3.2 and 3.3; Anna Becchi and Simone Perri for the contents of Section 4.

