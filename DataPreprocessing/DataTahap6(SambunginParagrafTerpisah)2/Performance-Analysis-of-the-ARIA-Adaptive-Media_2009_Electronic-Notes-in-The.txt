Multimedia systems are one of the most complex and interesting applications that are nowadays proposed to the users. Their complexity derives mainly from the fact that multimedia systems have to process huge amounts of data, while respecting real-time deadlines. For this reason performance evaluation of the underlaying workflow is a key issue in the design process of a new Multimedia system.

During the last years the complexity of systems has grown considerably, together with the need of fast and performing architectures. In this paper we will focus on multimedia systems, where there is the need to process huge amounts of data, while respecting real-time deadlines. Several approaches have been proposed in the literature, for example: Telegraph [22], STREAM [2] and Aurora [6]. In this paper we will focus on the ARIA [17] system. ARIA is a middleware for describing and executing media processing work-flow capable of processing, filtering, fusing sensory inputs and actuating corresponding reactions. More precisely it extracts

The ARIA system has been developed by the Arizona State University at the Computer Science and Engineering Department. It offers a new medium which allows artists to integrate novel sensing, interaction, content, and response mecha- nisms in their stage performances. This enables digital media and art researchers to expand the expressive and interactive possibilities in performative, multimedia environments.

Workflows [18] are modeled as directed graphs where nodes represent sensors (data acquisition), filters and fusion operators (data manipulation) and actuators (data output). Edges are used instead to define connections that stream objects between components [5]. Each path in the media workflow graph, describes how objects are streamed between ARIA processing components.

The basic information unit is a data object, which can be as simple as a numeric value or as complex as an entire image. Each object has two types of information: object payload and object header. The object payload can be a numeric value, a string or an image. The object header consists of two fields:

Operators are programmable components whose delay and quality characteris- tics can be controlled via input parameters. They have input and output queues and a set of behaviors. During its computation, an operator picks a set of objects from each of its input queue and applies one of its behaviors. It then builds an object result and puts it into the output queues.

Each operator can have n input queues and m output queues. Each queue has a bound on the number of objects and a bound on the memory occupancy (in bytes). Each queue is monitored by a manager that in the case of overflow, can remove some of the objects according to a drop policy. The drop policy can be based on some of the parameter of the object, like its age, size, precision, history, amount of resources used so far, etc.

(that determines the order in which objects in the queue are considered) and an ob- ject ignore criteria (that determines which objects in the queue should be ignored). Each behavior is essentially a different implementation, with different processing, delay and quality characteristic. A particular behavior is chosen depending on an execution condition. When an operator has multiple behaviors ready for triggering (i.e. there is more than one behavior whose condition is satisfied) the ARIA kernel picks the most appropriate one, based on the quality, delay, or resource constraints [16].

Colored Petri Nets [11] (CPN) are a modeling formalism used in performance evalu- ation and in many other fields. In particular, they are an extension of ordinary Petri Nets, where tokens are augmented with attributes. Attributes are called colors, and belong to specific classes called types. Each token has associated a set of types that defines its attributes. When a transition fires, it removes some of the tokens from its input places, and collects their attributes into variables. At the same time, the firing of a transition inserts tokens into its output places. The attributes of the generated token are computed as functions of the variables collected from the input places. For a tutorial on CPN, the reader can refer to [10].

The firing of a transition representing a sensor models the acquisition of a mul- timedia object. The attributes of the multimedia object are injected into the color of the produced token, according to the procedure described earlier. In a similar way, the firing of a transition representing an actuator models the consumption of a multimedia objects. In this case the attributes of the token might be used to determine particular aspect of the specific action performed by the actuator. For example the attribute representing the resolution of a token that corresponds to an image, can be used to determine the firing time of a transition that models the transfer of the picture to a storing device.

tion about the time in which each object went through sensing, filtering, and fusion operations. This set of data may also be used to calculate the total time delay incurred by the object. From these values we can extract the arrival and departure time of all the objects arrived or departed from the input and output queues.

For example, to compute the processing time distribution of the matching oper- ator described in the next session, we used a timer that counts the seconds elapsed from the start to the end of the operation. In this case, the operator was imple- mented using the the ImageMagick Library [13], and times were considered using the timer structure implemented in the library. This allowed us to optimize the counting operation and to reduce the errors due to the use of external data struc- tures.

ARIA objects are very complex entities, which are characterized by several pa- rameters. Most of the operators changes or defines the values of these parameters, and they greatly influence the behavior of the downstream nodes. It is thus very important to characterize how values changes between the operators.

We have chosen to model the evolution of the system in a probabilistic way. Let us call i the set of input parameters, of all the input queues to an operator. We define the output parameters o, according to a conditional probability distribution P (o|i) that corresponds to the probability of generate a value o in output, given that the value of the parameter in input is i.

operator performs the match of two images. The ImageMagick Library used in this example allowed the use of several algorithms, like for example the absolute number of different pixels or the mean absolute error. The difference is the output returned by the matching operator that express the difference between the two images as a numerical value.

For the medium resolution we tested also different qualities on the database. We changed only that because we assume that the quality of the image captured by the camera cannot be changed. This parameter however has a great impact on the database, since an increase in quality, produces also an increase in the dimension of the images file size.

The Camera sub-model models the sensor that acquires an image of the incoming employee. Its firing corresponds to the entrance of a new employee. In this example, we imagine that 9 employees will arrive in front of the camera: 6 belonging to the DB, and 3 not included in the images library. Each token representing an arrival has an attribute e that belongs to the set E = {k, u}. When e = k, the employee has his picture stored in the DB, while e = u represents an unknown visitor. The sensor has a state that is used to count the number of visitors that still have to enter the face-recognition system. The corresponding place is initialized with 3 tokens of color u and 6 tokens of color k.

The Picture Library component represents the employee DB. It is implemented as a sensor that loads the images of the DB in the matching operator. Each picture is modeled as a token with an attribute ij belonging to the set I = {i1,..., i20}. The state of the sensor keeps track of the next image to be considered. Every time an image is loaded (firing of the corresponding transition), the DB starts loading the next one, until all the pictures have been considered. When the last image has been loaded, the place that represents the state is emptied. This prevents new objects from being generated until the operator is reset.

The Sync sub-model models the synchronization among the various components. In particular, it allows only one employee to enter at a time, by blocking the tran- sition that represents the sensor used to model the entrance of a new employee. It also reset the DB, by restoring the state of the corresponding actuator to the first image.

In this paper we have proposed a methodology to transform an ARIA model into a CPN with a semi-automatic procedure. This could be the basis for a tool that might allow the design of an ARIA system before actually building it. We have also presented a methodology to study the single components in isolation, and then use the results to set the parameters of the generated CPN. Moreover, the methodology proposed here could be exploited to study similar component based systems, such as the one used in other similar application domain like flexible-manufacturing.

