In a specification language like Z [24] [3], this simple relational model is given additional structure so that parts of the relational state can be used to model internal Z state, inputs, and outputs. Also, Z operations can be par- tial relations. The refinement proof obligations become correspondingly more complicated [24], primarily by the introduction of an applicability (precondi- tion) law to handle partial relations.

Finalisation solves the old paradox of why the clock that is 5 minutes slow (hence never right) is better than the stopped clock (right twice a day). The first clock has a simple finalisation that can be applied to it: add five minutes to the displayed time. The second has no finalisation that produces a useful result (without recourse to a second clock).

In all these cases, however, the key thing is that the process is defined by what we chose to observe. The fact of whether a system is a refinement of another depends solely on those observations. So the arguments we make in the rest of the paper also apply to CSP-style refinements.

The specification defines what is intended to be observable about the system, and what is not. Parts of the system may be intended to be unobservable, often for security reasons (for example, a secret cryptographic key). The specifier captures this property in terms of a finalisation.

Once the refinement model constraints have been relaxed to include non- trivial finalisations, it becomes easier to see how certain covert channels arise. It may be possible to apply finalisations other than the intended one, in order to observe different information. Such finalisations may not provide formal refinements of the original models, but are important because they may be performable in practice.

Arguing about the security of modern systems grows increasingly hard, and there have been numerous surprises over the past decade in particular (timing attacks [15], power attacks [16], etc). Systematic analysis is needed. We provide a simple taxonomy, motivated by the formal refinement models presented earlier.

With any system there is an obvious finalisation: that intended by the speci- fier. This may give sufficient security (or it may not). It is, however, a choice, and comes with its own assumptions about the system and its context. Con- sidering other choices of system elements and context provides an interesting and informative means of highlighting possible unwanted analyses.

The intended observation is with the intended finalisation glasses (for ex- ample, the discrete values produced by a crypto-algorithm). We can consider the intended finalisation to correspond to the identity applied to the outputs of the most abstract specification. Unintended observations vary the finali- sation glasses, and can observe discrete properties (for example, page faults, interrupts, i/o buffers), or analogue properties (for example, power, timing, RF).

We may choose to observe the operation of a single instance of a system (for example, a single smart card) or multiple instances. The single instance is the usual user view; an analyst may well prefer the multiple instance system, allowing differentiated analyses. Instances of standard and perturbed systems may be analysed together.

Many systems have specified environmental ranges for operation. For exam- ple, smart cards have power supply specifications and operating temperature ranges. Each attribute may be standard (within specification) or perturbed (out of specification). Environmental variation provides opportunities for al- tering the finalisation; for example, digital circuitry operates differently at different temperatures. Since we are generally dealing with ranges, there are also possibilities for variation even within specification.

We can be flexible in our interpretation of the environment. The above examples are expressed in terms of concrete environments. For an abstract model, the environment could encompass elements such as assumptions about operations of use, for example, that a system is subjected only to limited demands, or that the users understand the system sufficiently well not to breach security inadvertently.

level, or in the implementation (for example, that voltage levels are precisely binary). One formal technique attempting to handle deviations from pure re- finement is retrenchment [2]. An interesting open problem is how much can properties of interest be preserved under such circumstances.

Typically, the system being observed is the system being analysed. It is also possible to make higher order observations. For example, the analysis tech- niques themselves have standard and non-standard properties. One common analysis technique is meta-heuristic guided search (genetic algorithms, simu- lated annealing, etc) to find a potential solution. A guided search has a final result, but also has a trajectory (the path followed to reach that result).

Analysis analogies can be found for other approaches too. For example, perturbing the mathematics in some way ([7] uses the term problem warping ) and observing the results of searches can also give rise to new analyses. Thus, a higher order analogue of fault injection may apply. Due to the way meta- heuristic search proceeds, non-standard or highly perturbed cost functions typically produced better overall results [7].

It is interesting to note that there are few such annotations, and even fewer multiple annotations. Published analyses tend to exploit only a single view- point, for example, unintended finalisations involving power or timing. There appears to be little in the way of multiple viewpoint analyses, where timing and power information, say, are used together. Given the considerable success of the single aspect analyses, availing oneself of multiple sources and exploit- ing correlations between them would seem a promising avenue to explore (if one is an attacker).

Traffic analysis most naturally consists of observation of multiple systems. Even if the content of messages over a network is encrypted, analysis of net- work source and destination fields leaks information. (One could instead view this as a single networked system with multiple probes, distributed around the system.)

There may be timing attacks on the finalisation operation itself. How long does it take to compute a finalisation that is more complicated than the identity? A directory listing operation invoked by an unclassified process might need to filter out the names of more highly classified files. Although the listing may output only unclassified files, the time taken to complete may depend on the presence of more highly classified files.

The most obvious and direct approach is to enforce the use of the intended finalisation glasses. These may, for example, form a layer between electrical signals and what the analyst can observe. Invasive attacks may be prevented, or made more difficult, by a variety of means. For example, smart cards may have resin coatings applied, and be encircled with tamper-detection coils.

Overwhelming the resources of an analyst provides another means of effect- ing security. For example, user A may communicate with B by very rapidly sending trillions of bits of potential key material having secretly agreed previ- ously which time slot contains the actual key to be used. An attacker without this knowledge could observe all the data but would not be able to store it all for future reference.

We have shown how finalisation can be viewed as a crucial formal framework for explaining many security-related aspects of systems. We have examined the power of various finalisations, enabling factors and countermeasures. Above all we have shown that finalisation is a practical as well as a formal issue. When we do formal specification and refinement we are working on formal models of an envisaged system. Each model comes complete with a set of assumptions. These may be particular to the application concerned or else derive from the semantics of the representations used. If the assumptions do not hold (or can be made not to hold) in an implementation then we have the basis of an attack. Our taxonomy and many of the attacks outlined (for example, multiple systems) indicate that a useful criterion for formal analysis may be to model the system not as the user is expected to access it, but as an attacker may view it.

As Jackson [13] points out, the world is unbounded. There is a richer set of experiences to be had in the implementation (physical) world. The quest for attackers is to sample that richness, in order to avail themselves of correlations and relationships with data of interest.

