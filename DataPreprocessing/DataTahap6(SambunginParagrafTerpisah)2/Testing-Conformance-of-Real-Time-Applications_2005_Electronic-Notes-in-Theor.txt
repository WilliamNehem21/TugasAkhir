We propose a new methodology for automated testing of real-time applications in general and robotic applications in particular. The starting point is a high-level specification which can be automatically translated into a network of timed automata. Analog or digital-clock observers are then generated from the timed automata specification. The system under test (SUT) is instru- mented to export observable events and corresponding time-stamps. The traces generated by the SUT are fed to the observer (on-the-fly or off-line). The latter checks whether each trace conforms to the specification. The approach has been applied to the K9 Martian Rover executive of NASA.

Computer-aided verification of programs has been studied for decades by the formal method research community. Different models and specification lan- guages have been proposed to describe systems and express desired proper- ties about them in a precise way. The expressivity and the applicability of such models to various domains has been studied. It has been realized quite early, however, that the approach suffers from two fundamental problems of in- tractability. First, undecidability, because of Turing-machine expressiveness of many infinite-state models. Second, intractability because of state-explosion, that is, prohibitively large state spaces to be explored. A large effort then con- centrated in tackling these problems, resulting in a number of significant ad- vances. Powerful theorem-proving techniques, (semi-)automatic abstractions,

In this paper, we propose a new methodology of dynamic testing for real- time applications. It is dynamic in the sense that it makes use of instrumenta- tion of the SUT and of run-time verification technology. The class of systems we are targetting includes all systems where a specification exists and can be translated into (or given directly as) a network of timed automata (TA) [2]. Many instances of such systems can be found in the domain of robotics. There, a plan defines the steps to be performed to achieve a mission, and also gives detailed information about order, timing, etc., of these steps. The plan is fed as an input to an execution platform (the term includes software, middleware and hardware) which must implement it, by performing the specified steps in the specified timing and order. Thus, the plan can be taken to be the specification and the platform executing this plan to be the SUT.

The main advantage of our method is that it is potentially fully-automatic. Plans can be automatically translated into networks of TA [1]. Observers for TA can be generated automatically, as we show here. For the case study reported in this paper, we relied on the help of Klaus Havelund and Rich Washington at NASA, for the instrumentation of the execution platform and the generation of the traces. However, it should be possible to automate this part as well, in the general case, by identifying a mapping between platform events and specification events, and automatically scanning the code, adding event/time-stamp exporting commands to the identified platform events. Fi- nally, the observation/testing process is automatic as well.

The rest of the paper is organized as follows. Section 2 presents the methodology in detail. Section 3 gives a short review of the model of timed automata. Section 4 describes plans and their translation to networks of TA. Section 5 shows how observers can be generated automatically from TA. Sec- tion 6 discusses the application of our method on the K9 Rover case study. Section 7 contains conclusions and plans for future work.

[4] report work very much related to ours. Their scheme is also based on the instrumentation of the SUT and the runtime analysis of the instrumented SUT using an observer. The starting point of their method is a test-input generator, which generates inputs to the instrumented SUT. These inputs are also fed to a property generator, which generates properties that the SUT must satisfy on these particular inputs. The properties and the execution traces are fed to an observer, which checks whether the former are satisfied by the latter. The test-input generator and the property generator are specifically written for the application to be tested, while the instrumentation package and the observer are generic tools used on different applications. In one of the two case studies reported in [4], namely, the K9 rover controller, the inputs are plans like the ones we use in this paper (see Section 6). The test-input generator generates all possible plans up to given number of nodes and bounds on timing constraints.

In our work, plans are translated into networks of timed automata. This is a fully-automatic and efficient process, which captures the full semantics of a plan [1]. Notice that, once generated, the TA corresponding to a plan can be also used for other purposes than generating an observer. For instance, to check whether the plan meets certain properties, measure delays of various sub-stages, and so on.

Our methodology is mainly focused at testing robotic applications, such as the NASA K9 Rover (see Section 6). Such applications are often structured in two layers. A high-level planning layer and a low-level execution layer. The planning layer follows an input plan, which is a detailed description of the steps needed to accomplish the mission at hand. The planning layer issues commands to the execution layer, which tries to implement them and returns the results, including status information about success or failure. The planning layer then plans the next steps depending on this feedback and the instructions in the plan.

The third step is the instrumentation of the execution platform. It aims at interfacing the latter with the testing device (the observer). Two possibilities exist here. Either testing is performed on-the-fly (or on-line), that is, during execution of the platform, which is connected to the observer at real-time. Or it is performed off-line, that is, by first executing the platform multiple times to obtain a set of log-traces, then feeding these traces to the observer. In both cases, the instrumented platform must be able to expose a set of observable events to the observer. In the case of testing off-line, the platform must also record the time-stamps of these events. For testing on-line, time-stamping can be done by the platform or by the observer. In the latter case, possible interfacing delays must be taken into account.

Instrumentation can be done manually or automatically. Depending on the complexity of the SUT, it can be a non-trivial task. Care should be taken so that the instrumentation does not itself alter the behavior of the system. For instance, the overhead of added code should be minimal, so as not to affect execution times of the tasks in the system. These are problems inherent in any instrumentation process, and are beyond the scope of this paper.

The final step is the testing procedure per-se. The traces generated by the instrumented platform are fed to the observer, either in real-time (for on-the- fly testing) or off-line. The observer checks conformance of each trace. If a trace is found non-conforming to the specification, the SUT is non-conforming. Otherwise, no conclusion can be made. However, confidence to the correctness of the SUT is increased with the number of tests. Obtaining a representative set of tests, so that some coverage criterion is met is an issue in any testing method (e.g., see [27]), and is beyond the scope of the present paper.

In this section we describe how to obtain TA models from plans. We give the construction for the concrete language of plans performed by the K9 Rover executive, which is actually our case study (see section 6). Nevertheless, TA models are general enough to capture most of the constraints expressed in plan languages.

We present now the semantics of nodes and plans in terms of timed au- tomata. The semantics is constructive in the sense that, automata can be ef- fectively constructed, depending on syntactical description of the nodes. The semantics is also compositional in the sense that, the semantics of the plan is obtained directly by composing of timed automata associated to nodes.

State estimation is not more expensive than reachability analysis. In fact, in some cases it is cheaper. 1 As shown in [25,19], state estimates can be represented using standard data structures for TA, such as DBMs [12], and can be computed using various versions of symbolic successor operators, depending on the desired estimator (analog or digital).

1  The worst-case complexity of the membership problem in timed automata is studied in [3]. There, it is shown that for automata without epsilon-transitions (i.e., fully ob- servable), the problem is NP-complete whereas for automata with epsilon-transitions the problem is PSPACE-complete (i.e., as hard as reachability).

We have implemented a prototype observer generation tool, called TTG, on top of the IF environment [10]. The IF modeling language allows to specify systems consisting of many processes communicating through message passing or shared variables and includes features such as hierarchy, priorities, dynamic creation and complex data types. The IF tool-suite includes a variety of tools for simulation, model checking and test generation. TTG is written in C++ and uses the basic libraries of IF for parsing and symbolic reachability of timed automata with deadlines.

TTG takes as main input the specification automaton, written in IF lan- guage, and generates an off-line observer. The observer takes as input a trace and the set of unobservable actions of the original IF specification. The ob- server can function either as an analog observer (default) or as a digital ob- server (-d option).

The Rover executive is a software prototype written in C++ by researchers at NASA Ames. It is a multi-threaded program that consists of approximately 35,000 lines of C++ code, of which 9600 lines of code are related to actual functionality. The C++ code was manually translated into Java and C to experiment with tools using three technologies: static analysis, model checking and runtime analysis [11,4].

A main coordinating component named Executive. It provides the main control over how the plan is executed. Executive waits for a plan to be available, and signals at the end of the plan execution. So, the PlanWatcher signals when a plan is ready, and waits for end of execution to send a new plan.

The ActionExecution thread is responsible for issuing the commands to the Rover. It consists of a list of methods internalDoAction, doAction, stopAction, and abortAction. ActionExecution runs the internalDoAction method, the other methods are just called by the Executive on its own thread by simple calls.

Due to intellectual property restrictions, we did not have access to the execu- tion platform of the K9 Rover. However, NASA provided us with a set of one hundred plans and traces, generated by the K9 Rover execution platform. We applied our method, using the plan-to-IF translator to obtain IF models for each plan, and TTG to generate an observer for each IF model of a plan. The observer was then used to check the traces.

We have proposed a methodology for testing conformance of an important class of real-time applications in an automatic way. The class includes all applications for which a specification is available and can be translated into a network of timed automata. In particular, the class includes robotic applica- tions where specifications are considered to be the plans describing the robot mission. Such plans can be automatically translated to timed automata [1].

The method relies on the automatic generation of an observer from the specification, on the one hand, and on the instrumentation of the system to be tested, on the other hand. The testing process consists in feeding the traces generated by the instrumented system to the observer, which is a testing device, used to check conformance of a trace to the specification. We have validated the approach on the NASA K9 Rover case study.

We also plan to study the representation of observers as finite automata (timed or untimed). This is not always possible, because timed automata are non-determinizable in general [2]. Moreover, checking whether a particular TA is determinizable and determinizing it is algorithmically impossible in general [26]. Identifying classes of TA (e.g. those generated from plans) for which the above problems are solvable is a possible step in this direction.

