Replacing pieces of component-based systems carries a serious risk on the expected stability. Substitutability of components must then be carefully identified. With this intent, this paper presents a process to evaluate replacement components by complementing the conventional compatibility analysis with component testing criteria. Functions of data transformation encapsulated by components (i.e. their behaviour) are analysed according to the Observability testing metric. For a component under substitution, a Component Behaviour Test Suite is built to be later applied on candidate replacement components. This approach is also known as Back-to-Back testing. The whole process is currently supported through the tool testooj, which is focused on testing Java components.

Maintenance of component-based systems involves replacing existing pieces with upgrades or new components. This implies a serious risk on the stability of func- tioning systems [15,27]. Substitutability is then an important challenge due to the evolutive nature of software and the impact of changes. Whether there can be a certain control on versions of a component, under successive releases changes may spread across most of the codified functions and structures producing a massive difference with respect to the original component. This is even harder when compo- nents are acquired from different vendors, where system integrators cannot control deployment, and cannot be sure if the same environment (e.g. compiler, and com- piling options) were used on components that are supposed to be alike. This even applies to successive releases [20,4].

The main concern for an integrator is therefore identifying if new releases or new acquired components can safely replace pieces from a component-based system already deployed and in-use. With that intent, this paper presents a Process for Evaluating Component Replaceability. The proposal complements the conventional compatibility analysis by means of black box testing coverage criteria. The central idea is to observe the operational behaviour of a component (i.e. its output as a known testing frameworks like JUnit and MuJava [17,22], from where the Compo- nent Behaviour TS is easily validated in the development phase and later effectively executed against candidate components to analyse compatibility. A .Net version of the same tool has been partially implemented as well, and will be updated to include support for the remainder phases of the process.

The paper is organised as follows. Section 2 presents an overview of the whole approach. Section 3 describes aspects of the Component Behaviour TS. Section 4 presents the evaluation of Interface Compatibility which is done at a syntactic level before the testing-based evaluation. Section 5 describes the Testing-based Behaviour Compatibility analysis. Section 6 presents results of an experiment. Section 7 presents some related work. Conclusions and future work are presented afterwards.

1st Phase. A TS is generated with the purpose to represent behavioural aspects of a component C. This TS complies with certain criteria which help describing different facets of interactions of component C with others components into a software system. Notice that the goal of such TS is not to find faults but to represent behaviour. This will be fully explained in Section 3.

The approach can also be understood from the point of view of the technique called Back-to-Back testing, which makes use of a reference implementation for a component (i.e. C) to generate a TS to exercise both a unit under test (i.e. K) and the reference implementation. Then results from the reference component help to judge the correctness of the unit under test [8].

The goal of this TS is to check that a candidate component K coincides on behaviour with a given original component C. Therefore, each test case in TS will consist of a set of calls to services of C, from where the testing results are saved in a repository for determining acceptance or refusal when the TS is applied against component K. Following we list some relevant component coverage notions, to then explain the strategy for their implementation on the approach.

Each combination becomes a test case, in the form of a testing method inside a test driver file. For JCalculator, 468 test cases were generated into a class called JUnitJCalculator. After this the TS is validated against JCalculator, where testooj launches the JUnit tool and iterating through the test cases. They

In an object-oriented framework like Java, there exists a set of methods that are inherited from the Object class [13]. In some cases, though not often, those methods may help finding matching when some of them are conveniently overridden. Thus, the option could be to omit those methods in a first try. In case no match is found for a given component service, such Object methods could then be considered to observe the results of the matching procedure.

This phase may not only give a differentiation from syntactic similar services, but mainly assures that interface correspondences also match at the semantic level. Thus the purpose is finding services from a candidate replacement K that expose a similar behaviour with respect to the original component C. In this approach, this implies to exercise the Component Behaviour TS, generated in the first phase of the process, against K.

The wrapping approach thus makes use of concerns from interface muta- tion [12,6] by applying operators to change service invocations and also to change parameter values. The former is done through the list of matching services. The later, by varying arguments on parameters with the same type. Nevertheless, the amount of correspondences can be reduced by taking the highest compatibility level

In summary, the total amount of wrappers is the result from a product of all services from C which have more than one correspondence to K services and those who have parameter correspondences. When the size of W is too high, a system integrator may decide to manually set the correspondences to build only one wrap- per, based on the knowledge provided by the Interface Compatibility. For this the testooj tool provides ad-hoc utilities. In case no success is obtained with the gener- ated wrapper, another correspondences could be applied, or even decide to change to an automatic building of a bigger set of wrappers.

Whether hypothetically the generated wrappers would give unsuccessful results, the next option would be among the combinations of parameters for those whose type is identical. Since 4 services involve two alike parameters and 3 others involve six alike parameters, the amount of wrappers by considering that option can actually grow to 3456. This means a major saving in effort has been achieved.

