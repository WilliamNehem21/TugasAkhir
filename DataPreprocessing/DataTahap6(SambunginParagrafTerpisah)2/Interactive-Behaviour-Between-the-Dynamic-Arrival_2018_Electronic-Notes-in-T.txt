In the practical network system, especially when involving commercial Internet connections, the maximal potential arrival rate is very likely to be greater than the mean service rate of the bottleneck gateway over the connection [12], at least during certain phase. As it is extremely unlikely that many network users peak their network traffic at the exact same time, in order to keep the utilisation rate of the bandwidth resource at a acceptably high level, the bandwidth/maximal throughput of a long-distance connection is reasonably made to be smaller than the sum of those of all the edge links that it connects to [22]. As a TCP source identifies the congestion if it detects a loss event over this connection and responds by decreasing transmission speed, the overall mean traffic arrival rate for the entire connection will be much less than the peak transmission rate. If a number of greedy TCP sender is sharing a bottleneck gateway, it is extremely likely that the global arrival rate is greater than the departure rate during some portion of time, resulting in an increase of queue length; this would then be followed by the global arrival rate smaller than

This subsection demonstrates the method of representing TCP traffic as its trans- mission rate varies in response to the network positive and negative congestion feedback. TCP employs flow control and congestion avoidance features. It in- creases the sizes of flow control window and congestion window in order to transmit data packets as fast as possible and keep the bandwidth resource utilisation rate high, while avoiding congestion by decreasing the window sizes when loss events are detected [1]. If the modelled queue is the bottleneck of the TCP connection, then the transmission rate, which is directly affected by the two window sizes, has a direct relationship with the throughput performance of that queue and gateway [6].

The model represent the size of congestion and flow control windows (which directly affect the transmission rate) probabilistically, while representing the trans- mission rate in different states deterministically. The term deterministically here indicates that for each time slot, the source must be in either one of the trans- mission stage, active or idle, determined by the probabilistically calculated window size, and the transmission rate in each state can be directly derived from the net- work specification. From the perspective of the bottleneck queue, the arrival rate during the active transmission stage is associated with the link bandwidth between the source and the bottleneck gateway and is zero during the idle state, while the departure rate is associated with the link bandwidth between the bottleneck gate- way and the destination, assuming that the hardware processing speed is always much faster than the link speed, which is usually a valid assumption in modern computer network system. It is a logic choice to make the link bandwidth between the source and the bottleneck gateway greater than the link bandwidth between the bottleneck gateway and the destination, which means the arrival rate in the active transmitting state to be greater than the departure rate, as it would be pointless to study queueing theory for congestion control if this is not the case as congestion will never occur [14]. In addition, it is also an accurate representation of the practical network system.

All possible changes to window size happen over at least one round-trip time (RTT). In each RTT, there is a possibility of either no loss event of any kind is detected, or the opposite. In the former case, the window size increases by a specified size if an positive acknowledgement packet (ACK) is received and maximal window size smax has not been reached yet (or remains if smax has been reached); in the latter case, loss event is detected in forms of triple duplicate ACKs or timeout, and the window size decreases by a specified size. The congestion window size can be represented recursively as

In most of the research utilising the conventional queueing theory and method, the results from the mathematical derivations remains theoretical. The parame- ters of the arrival and departure process are represented with probability and the performance measures are generally represented with the unit of time slots, which makes them very difficult to be compared with those from practical systems. One of the major reasons for that is with the discrete-time queueing model, the size of the time slot is not generally associated with the physical time unit. Most of the performance measures, with the exception of dropping probability, depends on the size of the time slot. The throughput and waiting time in discrete-time queueing model are both associated with the unit of time slot, which means that with the identical physical system, if different sizes of time slot are selected during two dif- ferent modelling process, the throughput and waiting time value calculated would be different.

where Dj is all other delays contributing the RTT. It is a parameter that needs to be specified before the experiment. This is combined with the queueing delay calculated for each packet and used to determine how long the acknowledgement can get back to the TCP source after the packet has been sent.

the combined arrival rate is much higher than that of the departure rate, and at the same time, the queue length is sufficiently large, so that even with the arrival rate during some time period experiences heavy decrease, it would only drop to partially full, and rarely becomes empty. According to the characteristics of the single service queue, as long as the queue is not completely empty, the service would be fully utilised during that time. The constant background traffic which would single-handedly guaranteed a 50% link utilisation also greatly contribute to this.

In this subsection, more groups of MATLAB numerical solutions and NS-2 sim- ulations with different parameters are performed. In each group, one MATLAB numerical solution will be calculated, as the model produces the statistical result. Several NS-2 simulations will also be performed in every group. The goal is to minimise the difference between the deterministic result of NS-2 simulation and the statistical result of MATLAB calculation. The experiments and simulations are divided into multiple groups, varying the buffer size (queueing capacity), overall ar- rival rate (entering link bandwidth), departure rate (exiting link bandwidth) one at a time. All the results from NS-2 simulations are the average value of five different instances.

When the buffer size varies, queue length is the first to be affected. It would be intuitively obvious that when the maximal buffer size increases, so will the average queue length, as the dropping event will happen much later for the TCP sources. Higher queue length means larger queueing delay. However, as the queue are now less likely to be empty, the service utilisation rate also increases, and this is directly linked to the throughput, in which an increasing trend can also be observed. Overall, the results from simulation matches very well in all of the scenarios.

and throughput. The dropping rate also decreases slightly. There is a similar trend in reverse that was observed in the increasing overall arrival rate scenarios. It can be concluded that the values from numerical solutions match well with those from NS-2 simulations. This, along with two previous groups of scenarios with various buffer sizes and various arrival rates, provide potent validation for the proposed modification of conventional queueing method and dynamic traffic source model.

