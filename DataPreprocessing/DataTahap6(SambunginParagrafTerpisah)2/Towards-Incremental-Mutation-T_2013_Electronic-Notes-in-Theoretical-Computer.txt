The rest of this paper is organised as follows. Section 2 briefly covers the princi- ples behind mutation testing and discusses problems preventing its wider adoption. This is followed by Section 3 which provides an overview of incremental mutation testing and formally shows the sanity of the approach. Next, in Section 4, we give an instantiation of incremental mutation testing and present a preliminary evaluation of the idea. Finally, Section 5 provides an overview of related work in the literature whilst Section 6 draws conclusions and discusses our future plans in this area.

Furthermore, we assume that given the composition of two programs, the mu- tation operator applies itself on each part in turn, i.e. it is never the case that the change spans across the two parts. This assumption enables us to reason about the sub-parts independently in the proofs which follow. Note that simple mutants, mutation testing on all three scenarios. Considering that each scenario consisted of two versions of the code v1 and v2, with v2 occurring chronologically after v1, then traditional mutation testing was carried out on v2 for each scenario while incremen- tal mutation testing was applied on the the differences between v1 and v2. In each case, we collected data about the total number of generated mutants, the number of killed mutants and the execution time of the end-to-end process including static analysis to select which tests to execute.

JUnitMax 8 is a unit test runner which was designed with the goal of providing ongoing feedback to developers while they work. As a developer writes code and saves it, JUnitMax automatically checks which part of the code has changed and non-intrusively executes relevant test cases in the background. If there are any fail- ures, the developer is notified. This significantly shortens feedback loops and also leads to faster fix times because failures are likely to be related to something which the developer has just done. This is similar to incremental mutation testing in that the aim is to provide regular bite-sized feedback about the quality of a test suite as code evolves. Symbolic execution [9] and automated static code analysis [10] are both useful techniques which like mutation testing suffer from scalability issues. Attempts to address this problem have leveraged the incremental nature of software development to perform symbolic execution efficiently [11, 12] and to selectively dis- play results of automated static code which developers are likely to be interested in [10]. While incremental mutation testing is not directly related to these fields, we combine these ideas to optimise the computational efficiency of mutation testing and shorten the feedback loop to the developers.

