Correctness of compilation is important for the reliability of software. New techniques to guarantee correctness do not verify the compiler itself, but check for each compiled program whether it is correctly translated. Following these ideas, we developed an approach in which checking is realized as proof checking within a formal specification and verification framework. Based on formal specifications of source and target language and a translation predicate, compilers produce, in addition to the target program c, a proof that c is correct w.r.t. its source program. This proof can be checked independently of the compiler by the framework. Thus, it can be used as a translation certificate.

The paper describes the overall approach and applies it to a simple translation scenario. Specifi- cation and verification is done within the theorem prover Isabelle/HOL. To show the flexibility of the approach, we present two different proof techniques for translation correctness.

To avoid the last problem, many researchers in the area have concentrated on translation correctness in the last years. The basic difference between com- piler correctness and translation correctness is as follows: instead of proving that the compiler implementation correctly translates all admissible source programs, the compiler is enhanced by techniques that provide evidence for the correctness of the translations each time the compiler is applied to a source program. The approaches to translation correctness differ in what form the evidence takes and how it is generated.

Our approach to translation correctness is characterized by (a) a clear sepa- ration between the two language specifications, (b) an explicit specification of translation correctness, (c) the flexibility gained by supporting further speci- fications and deriving program independent properties from the given specifi- cations, and (d) an explicit translation certificate in the form of a proof script. It provides flexibility in different directions. Language specifications can be taken as they are and adapted to the special needs of translation correctness within the SVF without loosing correctness. This helps to reuse language spec- ifications and simplifies the definition of when a translation is correct (problem 1 above). In addition, the approach allows for different proof techniques and supports the introduction of intermediate languages (as further specifications) without affecting the original proof goal (this can help to master complexity; problem 2 above). As said above, the problem of implementation correctness is avoided by using translation correctness.

In our approach, the SVF is a general tool that is typically provided by a third party and not by the compiler developer. The SVF has to be suf- ficiently powerful to specify and reason about programming languages. It should guarantee that specifications are consistent by construction. Ideally, the SVF should provide a powerful prover and a proof checker with a simple to verify implementation and an open architecture. This would allow compiler users with critical applications to inspect the proof checker or ask trusted third parties to do so. Currently, most available SV frameworks do not support a separate proof checker. But, we assume that with the increasing importance of proof carrying code and checking technology, this situation will change soon. For the techniques developed in this paper, we used Isabelle/HOL ([6]) as SVF.

Although this work has profited from several publications on compiler correct- ness in general (e.g. [2,9]), we restrict the discussion here to the more closely related work on translation correctness. As already said above, our approach shares the basic idea with the credible compilation approach as presented in [7,8]. The approaches differ in how specification and verification is done. In the papers of Rinard and Marinov, the main contributions are logical rules for verifying transformations on flow graphs. These rules are manually proven sound with respect to an operational semantics of the flow graphs. They develop elaborate techniques for several kinds of optimizations based on pow- erful program analyses. Our focus is different. We use an existing SVF and argue to separate the language specifications from aspects depending on the compiler implementation.

In [3], Necula and Lee described certifying compilers. A certifying com- piler produces for each source program S a certificate that the corresponding target program T has a certain property. A typical property of interest is type safety. Note that certifying compilers guarantee a property only depend- ing on T whereas translation correctness is a property depending on S and

T. However, what is related to our work, is the clear separation between the compilation infrastructure and the checkable ceritificate. That is why many techniques developed for proof carrying code apply as well to our approach (for example, work on the encoding of logical frameworks, see [1]).

To explain the important aspects of our approach, we present its application to a tiny translation scenario, namely the translation of a simple assignment language to a stack-machine language. In Section 2, we formally specify the translation contract. Sections 3 and 4 explain two different proof techniques to illustrate the overall approach and its flexibility. The first technique is directly built on the semantics-based definition of correct translation. The second technique uses an intermediate specification layer that states that cor- rect compilation can be derived if certain syntactical relations between source and target program hold.

For modern high-level programming languages, a formalization of translation correctness is a non-trivial task. In particular, it is not sufficient to look at the initial and final states. One has to precisely define what the observable states are and how they are related to the implementation in the target language. In addition, translation correctness has to specify how bounded resources must be handled. These aspects are beyond this paper. We focus here on the relation between the states of S programs and their counterpart in T programs.

A memory map maps variables to addresses. A memory m and a state s are called conform w.r.t. a memory map mu, if the map is bijective for the elements on which m and s are defined. Of course, in practical scenarios, memory maps become more complex and the definition of conformance can be less restrictive.

A T program T is a correct tranlation of an S program S, iff there exists a memory map mu such that for all appropriate initial states st of S the following holds: Starting computation of S in st yields the same result as executing T with an initial memory m that is conform to st w.r.t. mu. With our restrictive version of conformance, the initial memory m is uniquely defined by st and mu, that is, it can be defined as a function of st and mu and conformance can be proved:

For the correctness proofs, we need a representation of source and target pro- grams within the SVF. As already mentioned above, we use abstract syntax here. Instead of using strings for variable identifiers and integers for addresses, our compiler generates the enumeration types variable for the finite number of variables of a source program S and address for the set of needed adresses.

In the last section, we concentrated on the principle aspects of our approach. In particular, we explained how programs and proofs are represented. For illustration reasons, we used a simple proof technique based on symbolic eval- uation. For more complex languages, such a technique is not applicable. In this section, we describe a more realistic proof technique and use it to demon- strate the flexibility of the overall approach. Whereas the first technique was directly based on the semantics of source and target program, the second technique is closer to verification of compilation algorithms. The flexibility to enable different proof techniques is important. This way, different steps in a compiler architecture can be handled by appropriate proof techniques. In particular, we can exploit the proof and reasoning techniques developed in [7] and implement them in our SVF.

We presented an approach to compilers that, given source program S, generate a target program T together with a formal proof that T is a correct transla- tion of S. Whereas most work in this area concentrated on logics and proof techniques for such proofs, this presentation discussed the issues on how ex- isting formal specification and verification frameworks can be used as a basis for such proof generating compilers. In particular, we introduced the no- tion of compiler-independent translation contracts and showed how additional compiler-dependent specification parts can be helpful. A clear separation of these aspects is necessary to provide

To demonstrate our approach, we implemented a proof generating com- piler in ML that translates a simple assignment language into a stack machine language. The mentioned flexibility was illustrated by developing two very dif- ferent, simple proof techniques: One based on symbolic evaluation, the other one based on syntactic program patterns. As SVF, we used Isabelle/HOL. Currently, we work on simple optimizations. As our next step, we plan to ap- ply our approach to more realistic programming languages and to implement translation and proof techniques as described in [7] within our framework. Furthermore, we aim to improve the proof checking support.

In this section, we present summarizations of two predefined Isabelle/HOL theories: Option and Map that we used to formalize the languages S and T . The following two sections are adapted quotations of Sections 3.4.3 and 3.4.4 from Nipkow et al. [5].

