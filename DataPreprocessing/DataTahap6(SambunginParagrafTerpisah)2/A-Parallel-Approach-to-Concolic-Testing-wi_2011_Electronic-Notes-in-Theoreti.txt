Software testing is a popular methodology to find bugs. The most crucial step of software testing is designating proper test inputs. Some tools pay attention to automate this step. Pex [16] is an automated unit testing tool that can automat- ically generate test inputs for .NET applications. CUTE [15] is another tool that can analyze and generate test data for C programs. The underlying techniques for automated test data generation have experienced a long time of development. Symbolic execution [11], initially introduced in 1970s, uses symbols to represent con- crete input values of programs and provides alternative execution semantics over these symbols. By relying on the advance of constraint solvers, it is possible to obtain precise concrete inputs to guide program executions from program states which are represented over symbols. This idea has inspired many works on auto- mated testing [8,13,18,17,20,21]. Recently, the concept of concolic testing [10,15,7] has been proposed. Concolic testing is a variant of symbolic execution and aiming at generating test data automatically, with the advantage that concrete program states are also adopted to guide the process of symbolic execution. Constraints of program paths are incrementally collected while some of those are replaced by concrete states. It is an enhanced dynamic symbolic execution [12] technique. The constraints collected along one path can be simplified with this technique. It is a novel way to improve the usability and the performance of pure symbolic execution. Based on this improvement, many other techniques [14,6,5,9,4] have been proposed to further improve the usability of concolic testing.

Concolic testing [15], which derives from dynamic test data generation [12], is a variant of symbolic execution. It combines symbolic execution and executing pro- gram under test concretely to dynamically generate test inputs and cover all feasible paths. When executing the program under test, it monitors the choices of branches along execution paths, then uses backtracking to collect path constraints and rep- resents path constraints by a set of formula with constants and symbols which are related to input variables. In order to explore new paths and generate test data, the concolic testing algorithm modifies the collected path constraints slightly to sat- isfy some other expected paths, and uses a constraint solver to solve modified path constraints. The constraint solver returns a solution, which forms the inputs of a new expected path and for the execution of next iteration. This process is iterated until no new path can be generated, which indicates that all feasible paths of the program under test are fully explored.

This subsection presents the parallel algorithm of the concolic test data generation. We design a parallel model that makes the process of test data generation run concurrently. An interesting point in this parallel algorithm is that we divide the whole path space into different disjoint areas dynamically that can be managed and updated by different computing units. Thus, each computing unit can freely access and analyze the paths belonging to its own allocated area. This means the global synchronization can be fundamentally removed among parallel computing units. This technique can further improve our performance of parallelized concolic testing. The removal of global synchronization is implemented by a runtime task scheduler which allows each computing unit safely updates its own data on a shared global decision tree.

When one WorkerStub has been started up, it begins to maintain an individual task list and a partial decision tree which will be built from the complete tasks in the individual task list. If the started WorkerStub is the first instance and the task list is empty, it will start an instance of Worker with empty inputs in order to get the first path data from the target program. Otherwise, the WorkerStub will wait for some tasks sent from other WorkerStubs to the individual task list and then run a series of Worker iteratively to compute tasks. When an instance of WorkerStub has received a set Sp from its worker, it firstly uses the local deterministic task scheduler to decide for a specific path prefix in Sp which WorkerStub should receive it as an individual task. After the sorting, every item in Sp with related program trace will be sent as individual task to corresponding WorkerStub told by the scheduler.

The Coordinator maintains a global view of the path decision tree by periodically collecting and merging partial trees from all instances of WorkerStub. It initially starts several instances of WorkerStub (the exact number of instances is decided by the number of processors installed on the target computer). It terminates the whole testing process when the global path decision tree is full.

workers connect directly with each other to exchange path records only when nec- essary(determined by the deterministic scheduler on each worker). The effect of the deterministic scheduler is that for each task generated by the testing process, the scheduler tells which worker should compute the task by a universal indepen- dent algorithm instead of randomly allowing some free worker to compute the task. Thus, the deterministic scheduler can be placed in each computing unit instead of a global one, which makes the serialized task list be separated to each computing unit. Finally, the global synchronization is eliminated.

Several observations should be kept to implement the deterministic task sched- uler. The global path decision tree of a program is dynamically combined through concolic testing iterations. Each Worker iteration consumes only one task that consists of a path prefix which is corresponded to program history traces, and gen- erates only one path from the prefix despite the path is feasible or infeasible. Each path along with its prefix on the tree is computed independently from others. By dividing and projecting paths and prefixes on the tree into the discrete space, the whole computation of the target program is naturally classified to several disjoint regions on the space. Every working unit takes charge of one region so that all working units have the knowledge of a specific task which working unit should take charge of.

A good design of the schedule function is a hard problem. One reason for its difficulty is that the condition of the path tree can be varied. Different programs, even different units in the same program, have different kinds of path distribution. This means there can hardly be a universal scheduler which performs the same well on every testing unit. Another reason for the difficulty is the inability in the prediction of the running time of every worker iteration. Even if we find a scheduler which can balance the number of paths on workers, the total time cost on different workers may be still unbalanced.

This scheduler assigns a task to the working unit identified by the length of path prefix modulo the number of computing units. If the number of computing units is larger than the length of the longest path in the target program, some computing units will stay in starving state for a long time. Thus, the design of a fair function H is important to improve the whole testing performance.

We have implemented the parallel algorithm and integrated it into the unit testing toolkit CAUT 5 . In this section, some details on the experiments will be given. Also, some typical results will be shown, and the explanations to them will be given. Our experiments are conducted on 2.66GHz Intel Core i7 CPU running Windows 7 with 6GB RAM, which provides eight logical processors.

The experimental examples mainly come from SIR [1], including bash, flex, grep, make, printtoken2 and schedule. Other examples are algebra linear [2] and micro OpenGL core (c00nGL) [3]. We selected parts of those programs but not whole programs to ensure that the testing time of each experiment was less than 15 minutes in the single core mode. For each example, we tested every separated function one by one in the target program and then summed the data of every tested unit (such as feasible paths) up as the result data. The calling dependencies in the unit under test enough. The experimental data shows that the paths allocation is not average for two processors: one is assigned to 782 cross-cpu tasks, while the other even only has 208 cross-cpu tasks, and computing tasks from 14 of 19 functions completely cannot be parallelized. To explain this reason, we analyzed the source code of grep. We found that many paths in grep program are short, which leads to the bad performance of our adopted scheduler function, because it may map the short paths to the same processor. The other examples which behaves not well in the parallel algorithm have the same reason.

This paper gives a different perspective on the performance improvement of concolic testing technique by introducing a parallel algorithm. This kind of method is able to fully utilize resources of hardware, so the performance can be gained by increasing hardware processors or computation nodes in the distributed system. The contribu- tion of our work is to apply parallel capability to traditional concolic testing with a low-synchronization framework. The parallel algorithm has been implemented and

Xiao Yu is partially supported by NFSC No. 61021004. Sun Shuai is partially sup- ported by NFSC No. 90818024. Geguang Pu is partially supported by Fundamental Research Funds for the Central Universities and 863 Project No. 2009AA010313. Jiang Siyuan is supported by Project NFSC No. 61061130541. Zheng Wang is partially supported by Shanghai Leading Academic Discipline Project No. B412.

