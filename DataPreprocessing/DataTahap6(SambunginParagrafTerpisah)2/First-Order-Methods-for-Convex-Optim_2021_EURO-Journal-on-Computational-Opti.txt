First-order methods for solving convex optimization problems have been at the forefront of mathematical opti- mization in the last 20 years. The rapid development of this important class of algorithms is motivated by the success stories reported in various applications, including most importantly machine learning, signal process- ing, imaging and control theory. First-order methods have the potential to provide low accuracy solutions at low computational complexity which makes them an attractive set of tools in large-scale optimization problems. In this survey, we cover a number of key developments in gradient-based optimization methods. This includes non-Euclidean extensions of the classical proximal gradient method, and its accelerated versions. Additionally we survey recent developments within the class of projection-free methods, and proximal versions of primal- dual schemes. We give complete proofs for various key results, and highlight the unifying aspects of several optimization algorithms.

The traditional standard in convex optimization was to trans- late a problem into a conic program and solve it using a primal- dual interior point method (IPM). The monograph Nesterov and Ne- mirovski (1994) was instrumental in setting this standard. The primal- dual formulation is a mathematically elegant and powerful approach as these conic problems can then be solved to high accuracy when the di- mension of the problem is of moderate size. This philosophy culminated into the development of a robust technology for solving convex opti- mization problems which is nowadays the computational backbone of many specialized solution packages like MOSEK (Andersen and Ander- sen, 2000), or SeDuMi (Sturm, 1999). However, in general, the iteration timization, mainly because of its good scalability properties and small iteration costs. Conceptually, it is an interesting optimization method, as it allows us to solve convex programming problems with complicated geometry on which proximal operators are not easy to evaluate. This, in fact, applies to many important domains, like the Spectrahedron, or domains defined via intersections of several half spaces. CG is also rele- vant when the iterates should preserve structural features of the desired solution, like sparsity. Section 5 gives a comprehensive account of this versatile method.

work of the Proximal Gradient Method (PGM). PGM is a very powerful method which received enormous interest in optimization and its ap- plications. For a survey in the context of signal processing we refer the reader to Combettes and Pesquet (2011). A general survey on proximal operators can be found in Beck (2017); Parikh and Boyd (2014).

problem (P) (usually obtained after consulting a black-box oracle). Var- ious conditions on the well-posedness of the prox-mapping have been stated in the literature. We will not repeat them here, but rather refer to the recent survey (Teboulle, 2018). Below we give some examples.

ror Descent (MD) method (Nemirovski and Yudin, 1983). A version of this method for convex composite non-smooth optimization was pro- posed in Duchi et al. (2010), and an overview of Subgradient/Mirror Descent type of methods for non-smooth problems can be found in Beck (2017); Dvurechensky et al. (2020b); Lan (2020). The main dif- ference between BPGM and MD is that one replaces the assumption that

In this section we turn our attention to a classical method for solv- ing linearly constrained optimization problems building on the classi- cal idea of the celebrated method of multipliers. An extremely powerful proponent of this class of algorithms is the Alternating Direction Method of Multipliers (ADMM), which has received enormous interest from dif- ferent directions, including PDEs (Attouch et al., 2011; 2007), mixed- integer programming (Feizollahi et al., 2017), optimal control (Lin et al., 2012) and signal processing (Yang and Zhang, 2011; Yuan, 2012). The very influential monograph (Boyd et al., 2011) contains over 180 refer- ences, reflecting the deep impact of alternating methods on optimization theory and its applications. Following the general spirit of this survey, we introduce alternating direction methods in a proximal framework, it impossible to implement the algorithm in parallel, which makes it slightly unattractive for large-scale problems in distributed optimiza- tion. Moreover, due to the result of Chen et al. (2016) the conver- gence of ADMM for general linear constraints does not generalize to more than two blocks. Leaving parallelization issues aside, Shefi and Teboulle Shefi and Teboulle (2014) proposed an interesting extension of the ADMM by adding further quadratic penalty terms, which allows much flexibility by suitably choosing the norms employed in the algo-

sults in a smaller step-size than the adaptive step, which hints towards a deterioration of performance. Nevertheless, this trick allows us to han- dle convex programming problems outside the Lipschitz smooth case, which is not uncommon in various applications (Bian and Chen, 2015; Bian et al., 2015; Haeser et al., 2018).

To conclude, we reiterate that the step-size choices analyzed here are the most common, but there may be many more choices of step- size which provide similar guarantees. For example, Freund and Gri- gas (2016) suggests new step-size rules based on an alternative analysis of the CG method that utilizes an updated duality gap. (Nesterov, 2018a) discusses recursive step-size rules, and in Dvurechensky et al. (2020a); Odor et al. (2016) new step-size rules are suggested based on additional assumptions on the problem structure.

Bregman proximal gradient method in the setting of relative smooth- ness (Hanzely et al., 2021) and relative strong convexity (Dvurechensky et al., 2021; Hendrikx et al., 2020) (see Section 3.3.3 for the definition of relative smoothness). Yet, the negative result of (Dragomir et al., 2021) suggest that, in general, the acceleration in the relative smoothness set- ting is not possible.

which allow to obtain linear convergence rate we refer the reader to Bolte et al. (2017); Necoara et al. (2019). The linear convergence rate can be obtained under quadratic error bound condition by a widely used restart technique, which dates back to Nemirovskii and Nesterov (1985); Nesterov (1983).

We close this survey, with a very important fact which Nesterov writes in the introduction of his important textbook (Nesterov, 2018b): in general, optimization problems are unsolvable. Convex programming stands out from this general fact, since it describes a significantly large class of model problems, with important practical applications, for which general solution techniques have been developed within the mathematical framework of interior-point techniques. However, mod- ern optimization problems are large-scale in nature, which renders these polynomial time methods impractical. First-order methods have become the gold standard in balancing cheap iterations with low solution accu- racy, and many theoretical and practical advances having been made in the last 20 years.

