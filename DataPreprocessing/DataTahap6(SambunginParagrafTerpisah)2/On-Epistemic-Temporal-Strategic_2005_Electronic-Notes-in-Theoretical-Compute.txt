ATEL is one of the most expressive logics for reasoning about knowledge, time and strategies. Several issues around the interpretation of this logic are still unresolved. This paper contributes to the ongoing discussion by showing that agents do not have to know a specific strategy for doing something in order to have a capability. Furthermore we claim that agents can possess so-called strategic knowledge that is derived from their knowledge of strategies being played. In order to prove these claims we present an alternative interpretation of ATEL over extensive game forms. For the definition of abilities we use strategy domination, and to deal with strategic knowledge we include strategy profiles in the model. We illustrate the interpretation issues mentioned using several small examples. Furthermore we show how perfect recall and perfect memory can be characterized.

strategies. This logic can be applied to the formal analysis of a wide range of systems, for instance distributed protocols, synchronisation and security, but also to any issue that can be modeled as an extensive game, such as argumen- tation, auctions or language games. In this paper we are concerned with the interpretation of ATEL. The original interpretation of the language featured attractive computational properties, but suffered from some counterintuitive properties, which led to a number of refinements [16,9,8]. In this paper we provide a new interpretation for ATEL. In order to keep things simple we do this for turn based systems, but we see no reason why the approach could not be extended to the more general class of concurrent systems.

that an agent is not supposed to know. One of the main points of this paper is that this latter condition is too strong. A coalition does not have to be able to identify a strategy of which they know it will be successful. A coalition of sensible agents will choose, if they cannot identify a foolproof strategy, the best strategy that they can come up with. More precisely, they will choose a strategy that is not dominated by any other strategy. We say that a coalition of agents can do X if any undominated strategy achieves X. We will define domination later in this paper.

A second point of this paper is that the knowledge of a coalition does not have to depend only on the state of a game or system, but also on the strate- gies they employ. It seems safe to assume that agents know what strategies they employ, and that this gives them extra information about the future. This phenomenon can be called strategic knowledge [5]. The interpretation developed here addresses this issue by assuming all agents know their own strategy. We stress that this is intended not as the final answer on this is- sue, but as a demonstration how one can incorporate some form of strategic knowledge.

Games are models for interaction between agents with different and possibly competing objectives [12]. An extensive game gives a detailed description of such interaction. It shows which decisions are made in order to reach an outcome. It can be represented in a game tree, where each leaf corresponds to an outcome and each node corresponds to a choice between options. The preferences of all agents are part of an extensive game. In many cases one wants to study the structure of a game independent of the preferences of the agents. In that case one can use the idea of a game form, which is an extensive game without preference function. The notion of an extensive game goes back to Kuhn [11]. We have adapted the next definition from Osborne [12]. Since the structure encodes the fact that agents may not be sure what exactly the current state is when making a decision, we speak of an extensive game with imperfect information.

For the purposes of this paper, we think of a game form as a description of a commonly known protocol for interaction between autonomous agents. All agents have preferences and it is common knowledge that these are private, thus not known to other agents. It is also commonly known that agents with different objectives cannot communicate outside the structure of the game. If an agent adopts a certain strategy, for instance to reach a certain goal, then the agent itself knows which strategy it is playing, but other agents do not know this. If a coalition of agents has a goal, then it is assumed that agents have the right means of coordination in order to select a group strategy.

2. Agent B then chooses for either action 3 or action 4. The dashed line indicated that agent B does not know what agent A has done when B has to choose. For this game form we are interested in the strategic abilities of agent

q. If A chooses action 1 it would chooses action 3, if A chooses action 2 it would choose action 4. However, at t1 agent B does not know whether agent A has played action 1 or 2. In terms of Jonker [9], agent B does not have a uniform strategy to satisfy q in t0. The conclusion is thus that for situation where we have a unique starting point, demanding that agents should have a uniform strategy i s sufficient to get intuitive results.

If we start in one of the two nodes satisfying t1, then things are a bit different. Agent B does have a uniform strategy to achieve q in for instance the leftmost t1 situation, and also a uniform strategy that would work in the rightmost situation, but does not know which one to employ because he does not know what is the current situation. In terms of Jonker and Van der Hoek and Jamroga, it cannot identify the right strategy. If agent B would want to satisfy p, it would be able to identify a uniform strategy in t1: choosing action 3.

action leads to a desired state. Thus, the agent has two strategies that might make him reach his goal and to him it is not clear whether to use one or the other, they are both undominated. The best he can do is to randomly choose one of the two. Fortunately, since agent A has played action 2, agent B will reach his goal with any of his undominated strategies. Therefore, we say that agent B is able to satisfy p, or that p is achievable for agent B.

