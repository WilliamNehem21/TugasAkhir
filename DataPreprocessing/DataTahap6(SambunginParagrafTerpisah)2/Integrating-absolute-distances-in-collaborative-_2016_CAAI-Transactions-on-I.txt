Image classification is an crucial technique applied in biometrics like face recognition [1,2] and one of the most significant steps in image classification is to represent or code the images. Proper description or representation of images is the basis of achieving robust image classification results [3,4]. Only with well represented, one subject in the form of the image can be easily distinguished from the others. The basic process of representation-based classification is firstly repre- senting the targeted sample with a linear combination on training samples and then evaluating the dissimilarity to classify the test sample into a closest class. Representation- based classification algorithms play a significant role in face recognition. Among various representation-based classifica- tion methods [5e7], sparse representation (SR) and collabo- rative representation (CR) based classifications are two of most crucial methods that have drawn wide attention [8,9].

finally used to perform classification. We tested the pro- posed method on a number of facial or non-facial datasets and found that it archived higher accuracy than conventional CRC. The paper has the following main contributions to image classification. First, it proposes a novel fusion method to improve CRC. Second, it analyzes and implements a reverse integration on multiple classifiers. Third, it dem- onstrates an experiment way to find tuned factors for integration on multiple classifiers.

The structure of the following content in this paper is as follows. The related work on SRC, CRC is introduced in Section 2. In Section 3, we describe our proposed method to integrate absolute distances in collaborative representation based classification (AbsCRC). In the next Section 4, we analyze the selection of fusion factors a and b, as well as some classification examples in the experiments. Section 5 conducts our experiments on a couple of popular benchmark datasets, and Section 6 concludes the paper.

side the representation coefficient matrix. Allen Y. Yang et al. proposed fast l1-minimization algorithms called augmented lagrangian methods (ALM) for robust face recognition [16]. Furthermore, many researchers proposed different SRC implementation and improvement, such as kernel sparse rep- resentation proposed by Gao et al. [17], an algorithm by Yang and Zhang that using a Gabor occlusion dictionary to raise the computing performance during the process for face occlusion [18], l1-graph for image classification by Cheng et al. [19], sparsity preserving projections by Qiao et al. [20], and a rep- resentation model by prototype together with variation for sparsity based face recognition [21]. Studies also show that the classification accuracy can be also improved by using virtual samples [12,22,23]. All of these are trying to improve the robustness of image classification for face recognition. And it's

proposed to optimize CRC. Zhang et al. proposed to inte- grating globality from other samples with locality in current sample to generate robust classification [26]. Xu et al. applied transfer learning algorithm into sparse representation [27]. Fusion of multiple classifiers is also applied in CRC [28]. And recently CRC was reinterpreted with a probabilistic theory [29]. CRC still has large space to improve, especially on the collaborative coefficient for test sample.

Based on nearest feature line (NFL) and nearest feature plane (NFP) [30,31], we can calculate the sum of represen- tation coefficients from all samples in one class and use them to represent to weight of one class. Then the test sample is classified into one class with maximal weight value. The greater the sum value is, the more contribution is produced from that class.

In this section, we use some experiment cases to demon- strate the rationale and effects of our proposed AbsCRC method. Indeed, the absolute distance vector alone does not bring good enough helps on image classification or face recognition, by which the classification results can not match the results by conventional CRC in most cases. However, when integrating the absolute distance vector with the re- siduals from CRC, the fusion residuals can produce outstanding classification results.

In this section, we will demonstrate our experimental re- sults on some popular visual benchmark datasets. Extensive experiments were conducted on these datasets to evaluate the classification accuracy of conventional CRC, absolute distance only (ABS) and our AbsCRC method, as well as the selections of fusion factors a and b. The chosen benchmark datasets include Caltech Faces [32], Caltech Leaves [32], ORL [33], FERET [34], CMU Faces [35], and Senthil IRTT Face Data- base [36].

ever, there are still some exceptional experiments cases. So our experiments also paid efforts to seek a optimal fusion factor b. The following subsections will demonstrate the samples, steps, factors and results in every experimental case, as well as our discussion on the results. The experimental results indicate that in most cases the AbsCRC is managed to produce higher accuracy of classification than CRC.

Caltech Leaves dataset [32] is also taken around Caltech by Markus Weber from California Institute of Technology. There are 186 images of leaves against different backgrounds and with approximate scale normalization. All images are also in JPEG format and in size of 896*592 pixels as well. We again resized them to half scale. At this time, we selected only 7 subjects with more that 10 samples in our experiments so that

ORL face database [33] is a small database that includes only 400 facial images taken from 40 folks and every single class provides only 10 distinct face images. The facial images were captured at different conditions for every subject like times, lighting, facial expressions (open or closed eyes, smil- ing, or not smiling), and facial details (glasses or no glasses). Besides, these images were taken against a dark consistent background while the folks were in an upright, frontal posi- tion. For simplicity, we resized all the face images to 56*46 pixels. We designedly renamed all image files to filenames with ordered numbers in 3 digits, which are elegant to reflect the right position of classes in experiments.

Using 1 to 8 training samples, our experiments run fast and smoothly. The most promising case for AbsCRC is the one using 6 training samples with b = 0.1. The improvement rate from AbsCRC to CRC and ABS reaches 20% and the classi-

In the all 6 datasets, there are 5 facial datasets and one non- facial datasets. The experiments showed that integrating ABS into face recognition method CRC helps improve the classi- fication robustness of CRC, which is effective in both facial and non-facial image classification. Besides we can find some other useful hints for image classification when applying ab- solute distance in collaborative representation.

This paper proposed a novel absolute collaborative repre- sentation based classification (AbsCRC) method for robust image classification. When solving the representation coeffi- cient CRC, we calculate the sum of the absolute distance between the test sample and the training samples at the same time. And then this absolute distance vector is integrated with original collaborative coefficient to generate a more promising classification. In the fusion, a tuned factor b is involved to adjust the weights from both distance vectors to output the best classification. Extensive experiments were conducted on a couple of facial and non-facial benchmark databases, and the results demonstrate that AbsCRC outperforms state-of-the-art CRC in most of cases.

This work was supported in part by Research Foundation of Education Bureau of Guangdong Province of China (Grant No. A314.0116), Scientific Research Starting Foundation for Ph.D. in Huizhou University (Grant No. C510.0210), National Natural Science Foundation of China (Grant No. 61502208) and Natural Science Foundation of Jiangsu Province of China (Grant No. BK20150522).

in Computer Science from Central China Normal University, PR China, in 2005 and the Ph.D. degree at Institute for Pattern Recognition and Artificial Intel- ligence, Huazhong University of Science and Tech- nology, PR China, in 2010. Since 2010, he has been teaching in the Department of Computer Science and Technology, Huizhou University, PR China. His cur- rent research interests include pattern recognition and

from the Southwest Jiaotong University, China in 2008, and the PhD degree in computer science from University of Electronic Science and Technology of China, China in 2012. He is currently a lecturer in School of Computer Science and Telecommunication Engineering, JiangSu University, China. His current research interests include pattern classification, ma- chine learning. He has published over 20 technical

