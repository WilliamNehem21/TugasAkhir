The PAGAI tool is dedicated to experimenting new analysis algorithms. It al- lows independent selection of abstract domain and iteration strategy, and partially independent selection of decision procedure, and thus is well-suited for comparisons. We thus conducted extensive experiments both on examples we produced ourselves (sometimes inspired by industrial code) and on GNU programs, for which the ability to run on any C or C++ code, through the LLVM system, was especially useful. Front-ends for many analysis tools put restrictions (e.g. no backward goto instruc- tions, no pointer arithmetic...), often satisfied by safety-critical embedded programs, but not by generic programs; our tool suffers no such restrictions, though it may in some cases apply coarse abstractions which may possibly yield weak invariants.

In most forward abstract interpretation-based analyzes, when control flows from several nodes into a single node, the abstract value at that node is obtained by computing the least upper bound of the incoming abstract values in the abstract domain (in backward analysis, this occurs when control flows from a single node to several nodes). If the abstract domain is convex polyhedra, then this means computing the convex hull of the incoming polyhedra. Such an operation may induce unrecoverable loss of precision by introducing spurious states that cannot occur in concrete program runs.

Removing program point n0 breaks all cycles; we are thus primarily concerned with obtaining an inductive invariant at that point. We consider the domain of convex polyhedra and thus wish to obtain this invariant as a polyhedron. Because convex polyhedra form a lattice of infinite height, we use Kleene iterations (pushing abstract values through control-flow edges) with a widening scheme, which ensures convergence in finite time to an inductive invariant, followed by decreasing (nar- rowing) iterations.

At program point n5, classical forward abstract interpretation with convex polyhedra computes the convex hull of three incoming polyhedra over variables (phase, x, t). This convex hull introduces extra states, unreachable in the concrete programs, for the analysis of the fragment from n5 to n9. When analyzing the whole loop, these extra states prevent proving x < 100.

To cope with this problem, a solution is compute disjunctive invariants at all intermediate nodes: at n5, keep an explicit list of three polyhedra, and thus obtain a list of nine polyhedra at n9. We pass the convex hull of these polyhedra to the widening operator at point n0 (which operates on polyhedra, not on lists of polyhedra). The drawback is that the number of elements in the lists may grow exponentially with the number of successive tests.

This motivates a key implement decision of our tool: only those variables v1, . . . , vn that are not defined by arithmetic operations are retained as coordinates in the abstract domain (e.g. as dimensions in polyhedra), assuming they are live at the associated control point.

For instance, assume that x, y, z are numerical variables of a program, x is defined as x = y + z, and x, y, z are live at point p. Instead of having x as a dimension for the abstract value at point p, we only have y and z. All the properties for x can be directly extracted from the abstract value attached to p and the relation x = y + z. This is an optimisation in the sense that there is redundant information in the abstract value if both x, y and z are dimensions of Xp. The classical definition of liveness can be adapted to our case:

However, these two techniques also lose precision in an important number (4.64% for G, 5.14% for PF) of control points, and obtain worse results than the classical many times. This result is unexpected, and could be partially explained by bad behaviour of the widening operator.

Finally, our combined technique gives the most promising results, since it is statistically more precise than the other techniques. It improves the precision of the inductive invariant in 8.29% to 9.86% of the control points compared to the three previous techniques. Still, we obtain worse result in a non-negligible number

Statistically, the domain of convex polyhedra gives the better results, but com- monly yields weaker invariants than the domains of octagons/intervals; this is a known weakness of its widening operator [16]. The Octagon domain appears to be much better than intervals; this is unsurprising since in most programs and libraries, bounds on loop indices are non constant: they depend on some parameters (array sizes etc.).

Finally, we evaluated the benefits of the improved version of the widening opera- tor for convex polyhedra from Bagnara et al. [1], compared to the classical widening. We found that the improved version from Bagnara et al. [1] yields more precise in- variants for 3.70% of the control points in PR.

It is not totally relevant to compare by inclusion the abstract values obtained by the various analysis techniques. Indeed, a slightly smaller invariant may not always be useful to prove the desired properties. Future work should thus include experiments with better comparison metrics, such as (i) the number of assert that have been proved in the code. Unfortunately, it is difficult to find good benchmarks or real life programs with many assert statements; (ii) the number of false alarms in a client analysis that detects array bound violations, arithmetic overflows, etc.

