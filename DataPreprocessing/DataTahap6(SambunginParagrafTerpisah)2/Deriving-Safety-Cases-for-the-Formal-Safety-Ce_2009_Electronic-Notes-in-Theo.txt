We present an approach to systematically derive safety cases for automatically generated code from infor- mation collected during a formal, Hoare-style safety certification of the code. This safety case makes explicit the formal and informal reasoning principles, and reveals the top-level assumptions and external dependen- cies that must be taken into account; however, the evidence still comes from the formal safety proofs. It uses a generic goal-based argument that is instantiated with respect to the certified safety property (i.e.,

The second subgoal of the top-level strategy is to show that the established variable safety is maintained along all paths. This proceeds accordingly. The final subgoal is then to show that the variable safety implies the validity of the safety condition. This can again lead to any number of VCs. If (and only if) all VCs can be shown to hold, then the safety property holds for the entire program. The evidence for the VCs is provided by the formal proofs; we plan to convert these into safety cases as well.

We have described work still in progress. So far, we have developed the overall structure of the generic program safety case and instantiated it manually. The example shown here uses code generated by our AutoFilter system [10], but the underlying annotation inference algorithm has also been applied to code generated from Matlab models using Real-Time Workshop, and we expect that the same derivation can be applied there as well. Current work involves constructing a more comprehensive, combined safety case that covers the components of the certification system itself (i.e., the formal framework, the inference system and its individual components, and the safety proofs). There we rely on the fact that trust in the complex components of the system can be reduced to trust in simpler components. For example, the use of proof checking mitigates the risk of the automated theorem prover.

