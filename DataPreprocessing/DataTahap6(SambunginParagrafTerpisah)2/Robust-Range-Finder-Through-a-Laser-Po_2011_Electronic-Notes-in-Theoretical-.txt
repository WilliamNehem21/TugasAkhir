Vision is one of the main senses used by humans to move around the world. The amount of information received through the eyes is incomparable with other senses. The goal of the artificial vision, in the field of computer vision, is to construct a computational prototype capable of understand a digital image [28]. For descrip- tions of scenes, computer vision provides techniques such as pattern recognition, statistical learning, projective geometry, image processing. One technique which is becoming important in the computer vision field is the image range finding, which is defined as the distance between the object into the scene and the image captured by the sensor [8,10,11,13]. This kind of technique allows us obtain three- dimensional information of scenes such as background, shape and depth measures of objects. Many applications has been created using depth information, e.g. colli- sion detection on mobile robots [2,10] and engineering applications with range optic sensors. Several applications works with applications of quality control and storage planning. The latter is very important for companies which need to obtain three- dimensional measurements of objects for manipulation [8]. This work is focused in the robust estimation of the absolute distance [6,7,8,21,24], where are considered low-cost components such as a webcam and a laser pointer, both used to estimate distances obtained from the real world.

This work is organized as follows: In Section 2 previous works related to distance estimation are briefly described. In Section 3 is shown the process used to camera calibration. The scanner and the geometry of the model are detailed in Section 4. Finally, in Section 5 the implementation and analysis are presented. Conclusions and possible future directions of the results are described in Section 6.

3D range acquisition through differential light absorption (2002) [18]. This work describes a 3-D camera based on the differential absorption of light by a colored liquid that was illuminated by a circular light source to obtain 3-D information. The illumination is a function of range in addition to other parameters such as the orientation of the surface, the position of the light sources, the spectral characteristics of the liquid and the position of the observer.

A projective method to the measurement of box dimensions in real time (2006) [8]. This work describes a method to the computation of box dimensions in real time, focusing on projective geometry which uses the information of the box edges and the projection of two dot lasers on one side of the box, leading to recover the box dimensions in real time. The effectiveness of this work was validated through a scanner prototype implemented by the authors.

There are several aspects to consider when we look results among different tech- niques. The precision is the most important aspect, in that sense, we adopted the procedure of camera calibration proposed by Abdel-Azis and Karara [1] who were the first in developing the Direct Linear Transformation (DLT). Karara, in 1979, improved the method that take into account the lens distortions. The simplicity of the model and the robust results obtained have led to extend the application of this

Much effort was performed in the procedure of camera calibration. Some authors proposed the use of genetic algorithms [16,26] and the pre- and post-processing of data. From a practical point of view, some authors suggest a method based on 2-D patterns [5] as a model simply to use which obtains good results.

The camera orientation includes the calculation of external parameters to define its state and its axis in a coordinates system of high order, generally called World Coordinate System. We use three translational parameters and three rotational parameters for the camera 4 . See in [24] a description of the realized procedure in the camera calibration. In the implementation of our approach has been used OpenCV [9] and the obtained results from the camera calibration were validated with the MatLab Camera Calibration Toolbox [3].

Previous works, as see in [8], have used two laser pointers Class II with a wave- length of 650nm to make a projection. In [21], J. Y. Montiel et al., used a laser pointer of Class II of 633-670nm in order to calculate distance to objects applying a line tracking. For our work we used a modification of a laser pointer Class II with red light color and 630-650nm of wavelength.

In the experiments were used different measures of H (distance between webcam and laser pointer). Different image resolutions and different data samples were used in the regression model. In order to obtain the data samples, used in the regression model, we consider the parameter S that defines the difference between each sample obtained from real world (step).

Dataset used in the experiments. Example: In the set 7 was used a distance H of 25cm with a resolution of 352x288 using a calibrated camera, considering 25 samples, linearly separated by a step of 5cm. The samples was collected between 73cm to 193cm.

From this last experiment we can note the high level of approximation of the distances obtained by the scanner. The mean absolute error (MAE) of approxi- mation was 0.8613cm and the MAPE was 0.824% for an uncalibrated camera and present a MAE of 0.6492cm and 0.557% of MAPE for a calibrated camera.

