Mobile identity management can be considered as a subgroup of identity man- agement. This statement is partially true. The new context data especially location data has its own characteristics and therefore not all identity management solutions can be applied to mobile identity management. In this paper, we focus on a specific push context-aware application (i.e. the Friend Finder) and evaluate the important privacy aspects from the perspective of mobile identity management. The aspects we mention are not only specific to mobile identity management, but their evalua- tion is more mobile-centric.

The business logic of the Friend Finder works as follows: The mobile users par- ticipating in the Friend Finder application send periodically their location data com- puted by their mobile devices to the central location provider. They can then query locations of their particular friends and relatives through the location provider. Normally, the location provider presents the location information as simple text to mobile users. The map provider can enhance this functionality by showing the location information of mobile users on a visual map with navigation instructions.

Mobile identity management helps users interacting with mobile applications to safeguard their personal data in the digital world as they do in the physical life. You have many relations with other people and organizations in the society. You are a computer scientist, a husband, a child, a friend or a stranger for somebody at the same time. That means, you have many partial identities [24]. Each partial identity is mapped to a group of attributes. You can intuitively decide which partial identity is used for communicating with whom. You also switch from one partial identity to another very easily and quickly. You can control to whom you trust and do not trust. This scenario needs to be also possible in the digital world. You should be able to create different partial identities, map a group of attributes to this identity and decide which partial identity to use based on your partner.

application shows how privacy of personal data and pseudonymity are protected against mobile operators and service providers. Unlike our focus on push services, the demo application considers only pull services. Besides, certain aspects like context relations and dependencies, blurring in levels are not within the concern of the PRIME LBS.

The FIDIS (Future of Identity in the Information Society ) [5] project is a Net- work of Excellence project and supported by the European Union under the 6th Framework Programme for Research and Technological Development. FIDIS fo- cuses on the topics like future identity management, identity thefts, privacy with legal-social content, mobility and identity, etc. They have surveyed a detailed database of identity management solutions in academia and industry [6].

Blurring can be applied in levels. For example, for outdoor locations; GPS coordinates, street name, zip code, city, country and continent can compose such location levels. For indoor locations; room number, floor number and building name can compose the levels. Blurring in levels can also be used to improve the quality of service. Assume you hold your PDA and are in the city center of Stuttgart. You are interested in finding restaurants around you. You can either give your exact GPS coordinates or you can release your zip code or city name. If you release your GPS coordinates, the service provider presents a visual map which directs you to different restaurants around. If you give only the zip code, than you get the restaurants as

The specification language for privacy preferences is very important for mobile iden- tity management. Appel [1] as privacy preference language has limitations for iden- tity management [20]. It is not straightforward to extend Appel for the integration of the aspects explained in this paper. The preference language for the Friend Finder application should take into consideration different static and dynamic context data, their dependencies and relations and also blurring in levels.

After releasing your personal data to a service provider, you can not control whether your data is misused or not. It can then be used for profiling, forwarded to other parties, used for spamming, etc. You need some trust relation with your partners before you release your data. With P3P [16], you can build this trust relation with your partners. By publishing its P3P policy, a service provider exactly explains what kind of personal data it collects, its purpose and duration of the collection, the other receivers of the personal data, whether the user can be identified from the collected data, etc. You check this policy automatically with Appel preference language and decide whether or not to communicate with the provider. P3P does not guarantee the enforcement of the policies, but it can be evaluated as a promise of providers.

With the increasing popularity of mobile devices, confidentiality of mobile data has become more serious. Many mobile devices (e.g. laptops, PDAs, mobile phones) are either forgotten in taxis or public transport or they get stolen. If the mobile data stored on devices are not encrypted, the confidentiality of personal data is left in danger.

is released, it is also clear that the receiver can easily find out this attribute. He is warned against this confliction. If he confirms, his location is sent within a pe- riodical time to the location provider. For the first time, he sends also his Appel preferences and context relation rules. The location provider takes his preferences and the exceptions into consideration and evaluates them before his location data is forwarded to other principals.

When the visual map provider asks for his location information, the location provider compares his Appel preferences and the P3P policy of the visual map provider. It also checks the exceptions for the context relations and then releases the relevant data to the visual map provider. In addition, if Mr. Fischer communicates directly with the map provider, the communication is built upon an anonymous network automatically (i.e. the aspect anonymity).

