Production scheduling is an important decision-making in operational level that plays a crucial role in manufacturing and services industries. Scheduling problems deal with the allocation of available resources to jobs over given time periods and the goal is to optimize one or more objectives (or criteria) [38]. These problems are extensively investigated in the literature [9]. It occurs mainly by two aspects: the

PMS problems can be defined by a set of n jobs that need to be processed by a set of m parallel machines. The objective is to schedule jobs (each job is to be assigned to exactly one of the m machines) so that one or more criterion is minimized. When the processing time of each job is the same on all those m machines, the problem is said to be identical PMS problem. In PMS problems, the most studied optimization criterion is the minimization of the maximum completion time of the schedule, a criterion that is known as makespan. Garey and Johnson [17] showed that minimizing the makespan on m = 2 identical machines is a NP-hard problem.

There are two other types of problems in PMS: uniform and unrelated PMS. Unrelated parallel machines can be characterized as machines that perform the same function but have different capabilities or capacities. The processing times of the jobs depend on the machine to which they are assigned to. Unrelated parallel machines is the most realistic case which is also a generalization of the uniform and identical machines cases.

Unrelated parallel machines scheduling (UPMS) problems have been much less studied in the literature [33]. Exact and approximation algorithms for makespan minimization have been proposed by Van de Velde [48] and Martello et al. [34]. Local search and heuristics methods have also been employed for makespan minimization [18], [37], [13], [30]. Recently, other performance criteria have been considered in the UPMS problem. The total weighted completion times is minimized by Lin et al. [30] and Rodriguez et al. [41], and the total weighted tardiness minimization is considered by Liaw et al. [28] and Lin et al. [30].

spectively, variable neighborhood search and GRASP algorithms to minimize the makespan added to the weighted total tardiness. In [40] also is developed a branch- and-bound algorithm for the same problem. For minimizing the total tardiness, an simple iterated greedy heuristic is presented by Lin et al. [29].

solution construction phase, which randomly constructs a greedy solution, and an improvement phase, which uses that solution as an initial starting point. The second heuristic is a hybridization of GRASP with Path Relinking [19]. In the third heuristic we use an ILS heuristic [32] as improvement procedure of GRASP.

GRASP and ILS are metaheuristic algorithms that have been applied with suc- cess to solve a variety of combinatorial optimization problems [15], [32]. Path Re- linking is a search intensification procedure that explores paths in the neighborhood solution space connecting two good-quality solutions. The hybridization of PR and GRASP adds memory mechanisms to GRASP.

the setup time between i and j and the processing time of j. If xi,j,k = 0, then the big constant M renders the constraint redundant. Constraints (8) and (9) define the earliness and tardiness of each job, respectively. Finally, constraint set (10) identifies the non-negativity conditions and set (11) defines the binary variables.

The three developed heuristics are named basic GRASP, GRASP+PR and GRASP+ILS+PR, respectively. In the next subsections, first, we describe the rep- resentation and evaluation of a feasible solution. Then we describe each phase of the GRASP algorithm (construction and improvement), the PR technique and the ILS local search algorithm.

To compute the objective function f (s) of a given solution s, first, the optimal starting times of the jobs are calculated. In the calculation of these times, the occurrence of machine idle time can be allowed. That is, a machine can be idle until the processing of the next job is started. Szwarc and Mukhopadhyay [45] and Wang and Yen [49] proposed optimal timing algorithms to compute the optimal starting times of the jobs on single machine scheduling. In this work, we adapt these algorithms for the parallel machine case. The implemented algorithm decides the optimal starting time and completion time according to the corresponding due date for each job. The goal of the optimal algorithm is to minimize the total earliness and tardiness penalties for a solution previously determined.

In order to better understand the machine idle time insertion, we make use of an example problem with six jobs and two machines (n = 6, m = 2). Assume that the due dates of jobs 1, ..., 6 are d1 = 7, d2 = 10, d3 = 18, d4 = 20, d5 = 27

Each solution s built in the constructive phase is the starting point for a Local Search procedure in which we try to improve the solution. The LocalSearch method implemented in this work is based on neighborhood search. This method generates new solutions (neighbor solutions) through job insertions made in the current solu- tion s. An insert move generates a new solution by removing a job from its original position u and inserting it into position v of the same or different machine.

The neighborhood contains all the solutions reached through single moves made in the current solution. In this neighborhood a solution that is better than the current solution is picked up. The chosen solution becomes a new solution (or current) and the process continues until a local minimum is reached. The pseudocode of the Local Search procedure can be seen in Algorithm 2.

The Path Relinking (PR) technique is an intensification strategy proposed by Glover [19]. This technique generates new solutions by exploring trajectories that connect high-quality (elite) solutions previously produced during the search. The PR needs a pair of solutions, say so (initial solution) and sg (guiding solution), so /=sg. A path that links so to sg is generated by applying neighborhood moves to the initial solution, which progressively introduces attributes from the guiding solution. At each step, all movements that incorporate attributes of the guiding solution are analyzed and the movement that best improves (or least deteriorates) the current solution is chosen to be the next intermediate solution of the path.

Resende and Ribeiro [39] describe alternatives that have been considered in recent implementations of PR between two input solutions so and sg. In this work, we implement the PR variant called Mixed Path Relinking. Instead of starting from a solution so and gradually transforming it into the solution sg, this variant performs one step from so to sg, obtaining an intermediate solution s1. Then sg becomes the initial solution and s1 the guiding solution, obtaining a new intermediate solution s2. In the next step of the procedure s1 becomes the initial solution and s2 the guiding solution, obtaining s3 and so on. This process is executed until both paths joint in the middle. The main advantage of this strategy is that it explores deeply neighborhoods of both input solutions.

(12, 1) and (1, 4). Swaps concerning jobs 4 and 2 are not made. The job 4 should be swapped with the job that occupy the fifth position in machine 2. This exchange is impossible since in machine 2 there is no such position. The job 2 should be swapped with the job 7, but this swap is not necessary because it will yield a solution already analyzed. In this example, we can note that job 3 of the machine 1 was inserted into the machine 2. This move is made because the machine 1 in solution so has a larger number of jobs in comparison to the same machine in solution sg.

The algorithm starts initializing the elite set E as empty. During each iteration of the algorithm, a greedy randomized solution s is constructed and improved by the local search procedure, resulting in a local minimum so. If the elite set E has at least 2 elements, then the Mixed Path Relinking is applied between so and an elite solution sg randomly chosen from E. The solution returned by the PR procedure is used to update the elite set E. The best elite solution is returned by the GRASP+PR algorithm.

An efficient hybrid algorithm proposed here brings together the components of GRASP, ILS and PR. This algorithm, called GRASP+ILS+PR, is similar to GRASP+PR. The difference is in the improvement procedure (Local Search). GRASP+ILS+PR uses the Iterated Local Search (ILS) heuristic in the improve- ment phase.

In this work, we analyze the efficiency of the three developed heuristics: GRASP, GRASP+PR and GRASP+ILS+PR. All algorithms were coded in Java 1.6, using IDE Eclipse 3.5.1 compiler and run on an Intel Core 2 Quad CPU Q9550, 2.83GHz, with 6GB of RAM running under Windows 7, 64 bits OS. Only a single thread was used in the experiments.

The computational tests were divided in three experiments. In the first, the heuristics are tested using small instances. We compared the obtained solutions with optimal results obtained by the MIP model fort the considered problem (presented in Section 2) and solved via ILOG-IBM CPLEX 12.2. In the second experiment, the heuristics are tested using medium-to-large instances. The third experiment evaluates the probability distribution of the running time of the heuristics by using time-to-target plots.

In this first experiment, we use the Set I of small instances. The MIP model for these instances were solved by ILOG-IBM CPLEX 12.2 software. This software was able to obtain the optimal solutions for all the instances of Set I spending a low computational time.

For the 40 medium instances, the heuristics are also compared with CPLEX solver. This solver was applied to solve the MIP model with a threshold CPU time of three hours for each medium instance. That is, if after the established time no optimal solution is obtained, the best current solution (upper bound) is returned by CPLEX.

