The original HOA is a special algorithm that can also work effectively on large scale data. In the study, the HOA is convert- ed based on the binary search field. Then, the binary horse herd algorithm was applied to the feature selection problem with the wrapper method (BHOAFS). A detailed literature study was con- ducted to convert the HOA to a binary version and apply it to the feature selection problem;

In this study, while trying to maximize the classification ac- curacy, it was aimed to minimize the number of selected fea- tures. In this context, many criteria were evaluated (e.g., average fitness values, average accuracy values, average num- ber of selected features, and CPU time).

is used has not been proposed as far as we know. The rest of this paper is organized as follows: The foundations of the research and the proposed binary BHOAFS method are given in Section 2. The proposed FS-based binary chaotic BCHOAFS methods are described in Section 3. Experimental results and discussions are given in Section 4. Finally, the results and conclusions are presented in Section 5.

best to worst. As a result, the first 10% of the horses in the ranked population with good fitness values are selected as a horses. The following 20% b horses, c, and d horses are made up of 30% and 40% of the remaining horses, respectively. Therefore, this algorithm

S-shaped (sigmoid), V-shaped [49,50], and U-shaped [51] trans- fer functions are commonly used transfer functions. The feature se- lection problem works in a discrete space, while HOA works in a continuous space. To apply the feature selection problem to HOA, continuous space must be converted to discrete space. This trans- formation is done by using the U-Shaped Transfer function in the

The SMF, designed for the local search strategy for the proposed algorithm, aims to improve the current positions of the individuals with good positions in the herd and forward them to the next iter- ation. SMF is a function that measures the similarity/proximity of the two candidate horses that make up the population. Its main function is to calculate the distance between solutions. Then, ac- cording to this distance, it generates a candidate horse solution that is different from the existing solutions but is more likely to be in a better position.

Random population generation is provided by using Pareto Law rules in FS. According to this rule, the binary vector array is initially set to 80% zero and 20% one. 90% of the datasets were reserved for training and 10% for testing. k-NN and SVM classifiers were used as classifiers by randomly selecting the data in the training and test set. Results for the test set were obtained by ten-fold cross- validation. The accuracy average of this classifier was used. The fit- ness function in the FS problem depends not only on the classifica- tion accuracy but also on the number of selected features. The one

The datasets are randomly divided into two parts (i.e., training and test datasets). The data splitting is repeated many times to en- sure the robustness and measurability of the results. The following statistical measures are tested from validation data at each run.

When chaotic maps are ranked in terms of obtained accuracy, and the number of selected features, Piecewise and Singer chaotic maps gave the best results. In contrast, Logistic, Tent, and Sinu- soidal maps followed them. All these results prove that Piecewise and Singer Map-based BCHOAFS (BCHOAFS3 and BCHOAFS4) re- duces the number of selected features while increasing the quality compared to the proposed BCHOAFS versions.

a = 0.05 is 18.31. The null hypothesis can be rejected if the calcu- If we look at the [71] for the expected X2 value for df = 10 and lated value of X2 is higher than the expected value and the p-value

and BCHOAFS - Sinusoidal (BCHOAFS5). The Age Determination process used in the proposed algorithm allows the horses to do a global search in the search space. The SMF operator, which is pro- posed as a local search technique, has been developed to overcome the disadvantages, such as early convergence while preserving population diversity. A comprehensive study was conducted using 18 standard datasets from the UCI repository of varying sizes and characters to evaluate the effectiveness of the proposed BHOAFS and BCHOAFS versions. The performance of the proposed methods was compared with various methods such as well-known opti- mization algorithms in the literature such as GA, PSO, ALO, GWO, SSA [69], and binary optimization algorithms such as BGA, BPSO, BALO, BGWO, and BSSA [68]. When the FS problem is considered a multi-objective problem, the classification accuracy should be at the highest level, and the number of selected features should be at the lowest level. When the results were examined, the best performance among the recommended algorithms was found to belong to BCHOAFS3 and BCHOAFS4 algorithms (BCHOAFS- Piecewise and BCHOAFS-Singer) in terms of classification accuracy and FS.

