the concept of parser combinators has a long history in functional programming[11,13,21]. from an object-oriented perspective, the basic idea is to view the operators of bnf as methods, known as combinators, that operate on objects representing productions of a grammar. each such object is a parser that accepts the language generated by a particular production. the results of the combinator invocations are also such parsers.



here slots are initialized to their corresponding parser, so each slot definition gives a production rule of the grammar. the rules for digit and letter are in direct correspondence to the grammar. they use the inherited utility method charbetween:and: that produces a parser that accepts characters within a given range.



the rule for id is the same one we saw before. at this point, however, it becomes evident that the lack of distinction between lexing and parsing is a bit of a problem. traditionally, we rely on a lexer to tokenize the input. as it does that, it does away with whitespace(ignoring languages that make whitespace significant) and comments. this is dealt with by the operator, tokenfor:, that takes a parser p and returns a new parser that skips any leading whitespace and comments and then accepts whatever p accepts. this parser will also attach start and end source indices to the result, which is very handy when integrating a parser into an ide. it is useful to define a production identifier that produces such tokenized results.



one complaint about using closures as arguments for parser combinators is that programmers may mistakenly pass parsers as arguments directly. in fact, this is a non-issue. such mistakes were dynamically detected by our earlier framework. even though detection was dynamic, it occurred during the construction of the grammar, not during actual parsing. the effect was essentially the same as with static checking. moreover, it would be trivial to allow combinators to accept either parsers or closures.



nevertheless, the use of closures detracts from the clarity of the grammar. we are fortunate that the closure syntax in smalltalk(and hence newspeak) is very lightweight, but we still prefer to avoid closures altogether. the use of closures introduces a disturbing asymmetry, where the receiver of a combinator is a parser, but its argument is a closure that evaluates to a parser.



the ability to define a parser by writing a program that so closely corresponds to the grammar is attractive. however, just accepting a language is not all that useful. typically, some processing needs to be performed(e.g., to produce an ast as a result).



to address the need for processing, we introduce a new operator on parsers, wrapper:. the result of this operator is a parser that accepts the same language as the receiver. however, the result it produces from parsing differs; during parsing, the results produced by the receiver are passed to a closure which wrapper: takes as its sole parameter. the overall result is the the result returned by the closuretypically an abstract syntax tree.



this is illustrated above. the grammar productions for id, identifier and returnstatement have been augmented with processing using wrapper:. the grammar remains clearly distinguishable, with the ast generation on separate lines. however, it is preferable to keep the grammar completely separated. we will therefore move the ast generation code to a subclass, where the grammar production accessors will be overridden as shown below.



some parser combinator libraries offer support for naming parsers. this makes it easier to debug errors in the grammar. it can also be useful to print out the name of the production when reporting errors. unfortunately, naming the productions in this way adds clutter and obscures the grammar. it also forces the programmer to repeat information already given in the specification, for example:



consider that exampleparser1 is not a subtype of examplegrammar1. for example, in exampleparser1, returnstatement returns a parser that returns returnstatast, whereas in examplegrammar1 the returnstatement method returns a parser that returns a collection. these types are unrelated. in general, every production in the grammar has a corresponding method, and in most cases, the type of the subclass method is not a subtype of the type in the superclass. in most statically typed object-oriented programming languages, this situation is illegal. despite this, our design is correct and causes no type errors during execution.



in our first formulation, the grammar is represented by class examplegrammar1, which has one type parameter for each production in the grammar. to keep our example short, we have only two non-lexical productions, and two type variables. a realistic grammar would include dozens of productions, with dozens of type variables.



the type of this, this in examplegrammar1 is declared to be an instance of abstractgrammar. the type variables are passed through; examplegrammar1 does not depend on the return types of the parsers it creates, so these type variables play the role of wildcards. naming them explicitly will allow us to typecheck the subclass that creates the ast, exampleparser1.



below we illustrate an approach that eases the notational burden somewhat. we can typecheck the superclass against a self type that returns parsers with an unknown return type, using the wildcards construct of java 5. we use type selection on the type this in the return type examplegrammar1.returnstat() to make that type vary according to the return type actually declared by the expression() method in subclasses. this enables us to obtain an accurate type for super in exampleparser1. selection on this provides us implicitly with the necessary type parameterization, allowing this approach to scale to real grammars where the previous one does not.



level, from lowest to highest. the base case is given as the second parameter. another possible solution is for the parser to refactor itself dynamically to eliminate left recursion. dynamic refactoring is relatively easy in smalltalklike languages, thanks to the rich reflective system and the absence of manda-



in principle, parser combinators can be used to parse context-sensitive grammars as well. in a functional setting, monadic parser combinators are necessary to achieve such behavior, but in an imperative language, parsers can communicate shared state. hence we see no serious difficulty supporting context sensitive parsing, though we have not yet had a need to implement one.



andrew black developed a parser combinator framework in smalltalk. that framework was designed to be as similar as possible to a monadic parser combinator framework in haskell for pedagogical reasons. it does not support the separation of the grammar from processing.



