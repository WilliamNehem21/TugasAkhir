the ddos is an attack which uses multiple distributed resources, for example, servers, services, or networks against its targets. ddos attacks are on the rise due to the increasing number of users or organizations using the internet to exchange and deliver important data and information. this tempts the attacker to make online services unavailable, or to stop legitimate users from accessing a specific network by overwhelming it with traffic from multiple sources. the ddos attack started in 1998, but people only became aware when it attacked corporations and organizations in july 1999.one study noted that many organizations were attacked by the ddos since the summer of 1999, and the numbers of attacks have been increasing. due to this, research on



security practitioners conducted various experiments to detect ddos. however, it is crucial to scrutinize the features that lead to the ddos detection through a machine learning intelligent prediction model. the selection of features from the security event data or database will improve the performance of the machine learning detection[10,11,12]. the huge number of features in the dataset could decrease the performance of machine learning by slowing down the process of the training data, thereby making analysis less efficient[13,14,15,16].



the denial of services(dos) attacks use a single computer and a single internet connection to flood a targeted resource or system. this attack will interrupt the network services, thereby leading to significant losses. the dos attacks can be easily conducted and controlled by unskilled threat actors because of the uncomplicated steps. there are multiple types of dos attacks, such as volumetric attacks, syn flooding, fragmentation attacks, tcp-state exhaustion attack, application layer attacks, and plashing.



the anomaly-based methodology will create a baseline profile of the normal network, program, or system. it also will help in implementing a system that can learn from data. the unseen data also will provide a prediction based on the data that had been learned. there are several advantages regarding this method such as the ability to detect unknown and new attacks(zero-day).all events detection of malfunctioning of the protected webserver whether the events are malicious or not is one of the advan-



this method identifies the ddos attacks by using various types of soft computing, such as fuzzy reasoning, artificial neural networks, and others. this method is mostly performed for known and supervised attacks. it uses a collection of optimization and processing styles that allow inexactness and uncertainty to be identified[29,30].



learning and improving the performance of the group or specific task is characterized as a framework, or capacity program of the machine learning-based method. this method can detect features, such as packet size, packet rate, bit rate, and others. the previous results generated from this method can be used as a strategy to build a framework. the execution of this strategy can be changed based on newly acquired data. the machine learning-based method can be broadly classified as genetic algorithms, bayesian approaches, neural networks, support vector machines, and fuzzy logic[32,33]. one of its advantages is its ability to capture interdependencies, adaptability, and flexibility[31,34].



the boruta algorithm was invented by witold rudnicki, and miron kursa, polish researchers from the university of warsaw. this algorithm works as a wrapper around random forest. its function is to capture all the interesting and important features in the dataset with the outcome variable.



shuffled copies and the originals are then combined. a random forest classifier is then established to calculate the average reduced accuracy, z value, and the importance of all the features, with the more important features being calculated based on the highest value of z. the zmax is recorded as the highest zvalue in the shadow features.



unsupervised learning occurs by using unlabelled data to discover and analyze the pattern and trends for association and clustering problems. however, this learning also allows the model to learn more about the data, and to understand many structure or distribution in the data. this learning will perform more complex tasks since it depends on the model to work on its own.



supervised learning learns and uses labelled datasets to train data for the prediction and classification of the outcomes accurately, for unforeseen data. however, this learning will teach models to give the perfect outcome. two types of supervised learning are classification and regression.



random forest is the most famous classification model in machine learning. this classifier has a huge number of decision trees(dt) which consist of two types of nodeschild and parent nodes. this classifier was developed by adele cutler and leo breiman who combined the decision trees for predicting new unlabeled data[34,38]. scikit-learn was implemented for each decision tree by calculating the importance of a node using the gini importance. here two child nodes(binary tree) are assumed: tion for neural network. it can be used to solve a difficult, and complex task in machine learning. there are three layers to run data through, such as input layer, hidden layer, and output layer. the backpropagation or supervised learning technique is utilized by multilayer perceptron to train the network.



a decision tree is generated in the weka, for example, id3(iterative dichotomiser 3) which was built by using a set of training data[39,40]. the c4.5 algorithm is used to build a decision tree by implementing j48 as a classifier. besides being accurate in prediction, this classifier can also help to explain the patterns. it can easily deal with missing values, estimate error rate, pruning, and generating rules from the tree. however, it has numeric attributes, and complexity in the induction of the decision tree. this classifier can handle discrete and continuous attributes. the internal nodes of a decision tree denote the different attributes while the branches between the nodes denote the possible values that these attributes can have in the observed samples. the terminal nodes denote the final values(classification) of the dependent variable.



of the mlp is that it minimizes the prediction error of one or more target variables. the mlp algorithm is good for mapping and regression. it is also capable of generalization where an unknown pattern is classified into known patterns that share the same features. even if a significant fraction of its neurons and interconnection fails, it can still work, and relearn after the damage. its disadvantage is that during the training process, the stop time cannot be guaranteed. at this time, if the user sets the number of hidden neurons to low value, the model may become underfitting while if set at high value, the model may be overfitting.



where x=(x1, x2,..., xn) denotes a feature vector and j= 1, 2,..., n, denote possible class labels. the training phase for learning a classifier consists of estimating conditional probabilities p(xj\ ci), and prior probabilities p(ci). here, p(ci) is estimated by counting the training examples that fall into class ci, and then dividing the resulting count by the size of the training set.



this phase is a process of manually or automatically selecting those features which contribute to the prediction variable or output. the presence of any irrelevant data could decrease the accuracy of the model. three types of feature selection were made: filter, wrapper, and embedded.



shadow attributes corresponding to the maximum, average, and minimum of z_score results. the green and red box plots represent the z_score for the confirmation, and refusal attributes. the plot analysis below shows that the variables in the red color of a box plot and line graph represent the unimportant attributes. mean-



the accuracy of the random forest algorithm was found to be highest among all the classifiers when detecting the ddos. hence, for this section, it was used as a base learner. although it has several parameters, only two would influence the amount of pruning. in random forest, the hyperparameters include the number of decision trees in the forest, and the number of features considered by each tree, when splitting a node. the parameters of random forest are the variables and thresholds used to split each node learned during training. in this experiment, number on iterations and maxdepth will be used to tune the performance of random forest so as to discover the progress of the accuracy in ddos detection: number of iterations: this determines the number of trees included in the ensemble. each iteration yields a single tree. increasing this value constructs the model more articulate which improves the accuracy of the training data. however, if set too high, the accuracy rate may diminish.



on the other hand, using the boruta algorithm for best feature selection may also be time consuming as the run time to complete this process took more than six hours for 99 iterations. due to this deficiency, the data cannot be traced for every iteration. this is hampered by the large number of features present in the dataset.



