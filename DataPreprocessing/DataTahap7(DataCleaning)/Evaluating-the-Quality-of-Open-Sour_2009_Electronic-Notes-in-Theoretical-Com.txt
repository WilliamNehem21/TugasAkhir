traditionally, research on quality attributes was either kept under wraps within the organization that performed it, or carried out by outsiders using narrow, black-box techniques. the emergence of open source software has changed this picture allowing us to evaluate both software products and the processes that yield them. thus, the software source code and the associated data stored in the version control system, the bug tracking databases, the mailing lists, and the wikis allow us to evaluate quality in a transparent way. even better, the large number of(often competing) open source projects makes it possible to contrast the quality of comparable systems serving the same domain. furthermore, by combining historical source code snapshots with significant events, such as bug discoveries and fixes, we can further dig into the causes and effects of problems. here we present motivating examples, tools, and techniques that can be used to evaluate the quality of open source(and by extension also proprietary) software.



each one of the above goals is not a unique or an innovative tool idea. there are several open source tools that try to evaluate code quality of a single software project by examining several aspects of it. pmd 1 is a java scanner that tries to find possible bugs from exception handling statements and code problems, such as dead or duplicate code. findbugs 2 performs static analysis to reveal bugs in java based programs. checkstyle 3 is a coding style checker for java programs. sonar 4, unlike the above, is a plug in metrics tool, for java. it integrates, as plug-ins, a set of code measurement tools(like the ones presented) in a single application and presents overall results. the presentation follows the iso/iec 9126 quality model way initiative). this framework manages loosely-coupled collections of components and provides lifecycle and remote management. this means that parts of the system may be selectively replaced in the field without affecting the rest of the system. it provides additional protection to system components through a strict separation of the different modules within the system. the cruncher consists of the actual computation core(which in turn handles caching, resource management, scheduling and some data storage), connection services for the other tiers of a complete alitheia deployment and plugins that implement the computation of specific quality metrics



the core of the cruncher is a single module for osgi, although it fulfils a number of separate roles. this monolithic(local) design was chosen to ease testing and performance issues; the components of the core are tightly coupled and we deemed that they cannot or should no be updated separately. the connection layer contains a java servlet container for web-services and other connectivity. the portion of the system that sees the biggest benefit from the osgi framework is the collection of metric plugins that may be extended, disabled, removed and upgraded through a combination of cruncher functions(removing local data storage for a metric plugin) and osgi functions(unloading the code of a plugin, for instance).



once the core has activated metric plugins for calculations, the roles of master and servant are reversed: the metric plugins begin querying the core for services. the core provides two levels of data access, each with their own caching scheme, through a thin and a fat data services layer. metrics may use either layer but the fat layer is recommended, as it provides more processed and cached data than the thin layer.



measurement so as to return a better result next time). in other situations, response time is immaterial. suppose we have a metric that calculates the ratio between two other measurements in the system(for instance, percentage of comments in a file, by dividing the number of comment lines by the total number of lines). here, the calculation must have both values to proceed.



the principles behind the agile development methods and common practice within the open source community are vastly different. in recent years there has been a rise of interest in these, in order to detect and inform on areas of compatible shared practices. in we argue that it is possible to quantify the level of agility displayed by open source projects. an indicator of agility, the mean developer engagement(mde) metric is introduced and tested through the analysis of public project data. projects sampled from two repositories(kde and sourceforge) are studied and a null hypothesis is formulated: projects from the two samples display a similar level of mde.



clmt accepts as input an xml file that describes specific metric calculation tasks. the source files are parsed and ixr files are generated. the metrics are calculated through a series of queries on the ixr. the results are presented as textual output or as xml structured documents.



the availability of large open-source software systems allowed us to study the existence of scale-free networks of their modules. we chose modules of varying size and functionality, ranging from simple java classes to systems using self-contained libraries written in c, perl, and ruby. for our purposes, the links connecting the modules are given by their dependencies. for two modules a and b we add a directed link from b to a when b depends on a. this produces a directed graph. we explore the structure of both the incoming links and the outgoing links.



evaluation, based on software models that define and measure software quality. this particular model aims at capturing the particularities arising from the special nature of open source software development process. moreover, it focuses both on source code and the community around a project.



it is important to note that sqo-oss is not(another) metrics evaluation system. it is a platform on which metrics can be developed, plugged it, and run, on projects of any size. our plans include extending and maintaining sqo-oss so as to function as a digital repository for open source software research.





