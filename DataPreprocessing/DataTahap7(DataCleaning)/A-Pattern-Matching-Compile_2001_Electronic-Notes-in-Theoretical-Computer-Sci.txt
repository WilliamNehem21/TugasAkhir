implementation of a rule-based transformation engine consists of several tasks with various abstraction levels. we present a new tool called mtom for the efficient implementation of rule-based transformations. this engine should help to bridge the gap between rewriting implementations and practical applications. it aims at implementing well-identified parts of complex applications where the use of rewriting is natural or crucial. these parts are specified using rewrite rules and integrated with the rest of the application, which is kept in a classical imperative language such as c, c++ or java. our tool, which can be viewed as a yacc-like pre-processor, does not depend on a given term representation, rather it accepts implementation of terms(or term like data-types) of yet existing applications and it permits to define and execute rewrite rules upon those types. from our experiences, this system is well-suited for industrial use as well as for implementations of rule-based languages. the paper introduces several features supported by mtom.



only few industrial applications are implemented using tools that perform rewrite rules. however, rewriting is of greatest interest for symbolic and algebraic computations, program transformations, compiler constructions, etc. a couple of existing rule-based programming languages(such as asf+sdf, cafe-obj, elan or maude) have been yet used in the development of large applications but their connections with industrials are rather limited. this is probably not because of a lack of will on both sides(industrials as well as rule-based programming promoters). for example, several serious attempts have been made to use elan in industrial applications. but those attempts



to bridge the gap between rewriting implementations and practical applications, we propose a new tool called mtom(for many-to-one matching). its design follows our industrial experiences and our works on the efficient compilation of rewriting[30,16]. from our point of view, this new tool is very useful for implementing well-identified parts of complex applications. these parts are specified using rewrite rules and integrated with the rest of the application, which is kept in a classical imperative language such as c, c++ or java, called goal language in the rest of the document.



when trying to integrate a black-box tool into an existing system, one of the main bottlenecks comes from data conversion and the flexibility offered to the user. one of the main originality of our system is to allow a flexible term representation. the programmer can use(or re-use) his own data-structures for terms and then execute rule-based functions defined upon those data-structures. we propose to access terms using only a simple userdefined application interface(api). this allows the programmer to work on multiple term representations, including user-defined data-structures as well as existing built-in data-types. the proposed tool is also able to cooperate with a variety of memory management methods and does not impose any particular evaluation strategy. it is general enough to permit the user to implement his own rewriting strategies. the innermost normalisation remains the default strategy and we will use it in most of the cases.



the paper is organized as follows. after this introduction, we start with a brief overview of our approach that has led to the development of mtom(section 2). the notations and definitions are given in section 3. then, we present in section 4 how to encode innermost rewriting using mtom. the specification language of mtom is given in section 5. its main features are discussed in section 6. eventually, we compare our tool with existing works(section 7), and we conclude with some final remarks(section 8).



way and we believe that there is no need for a particular new syntax to represent them. simply, let us suppose that for each n-ary function symbol occurring in the signature, we have implemented a term constructing function(n-ary) f, written in the goal language and whose evaluation returns the term f(t1,..., tn), when called with t1,..., tn as arguments. in this case, the construction of a given term(right hand side of a rule), can be directly implemented in the goal language by several nested function calls. for example, in order to construct the term f(g(a)) we just write the code: f(g(a())).



because of the above discussion, our tool will only process left hand sides of rules, which are called patterns. given a set of patterns, the tool generates a many-to-one matching function in the goal language. each pattern has a semantic action, which is executed if the given pattern matches the input term. the semantic action is directly written in the goal language and is supposed to construct the right hand side of the rewrite rule.



our tool can be seen as a yacc-like pre-processor. the input is a set of patterns together with their semantic actions(written in the goal language). the output is a function, say mtom main(input term), providing many-toone matching of the input term against the given set of patterns. similarly to yacc, semantic actions are inserted directly into the generated function. in order to keep the tool general and simple, the mtom main function performs matching only at the top position of the input term(see section 4 and section 6.5 for full normalisation implementations). if a particular pattern matches the input term, then the corresponding semantic action is executed. this also explains why we call our tool mtom, since it provides basically a many-to-one matching compilation. in order to be as general as possible, we restrict our tool to this unique functionality. hence, even elementary rewriting strategies must be implemented by the user. however, as we will see in then translated into a specific goal language such as c, c++ or java. this code can then be compiled by a standard compiler and linked together with other files of the whole project. an important question is: what will be the form of rewrite rules given to mtom? we will give an answer to this question after explaining how to implement efficiently an innermost rewriting.



as a special support for innermost normalisation, mtom generates a skeleton of normalising term construction function for each defined function symbol. there are two reasons that explain why mtom does not generate a term construction function for constructor symbols of the signature and is only restricted to defined symbols. the first main reason is that mtom does not construct terms, and a term construction function for a constructor symbol always results in the construction of a constructor-based term. another reason is that we suppose that the description of a rewrite system can be organized into several files sharing the same signature. in this case, the generation of functions for all symbols in each of those files would generate conflicts at link time.



the two first functions(zero and suc) use the atmake function, which only consists in constructing a term for the pattern introduced as a string(first argument). the third function(plus) is more interesting since it decomposes its first argument u, using the atmatch function 1, and returns either y(corresponding to the first rule), or suc(plus(x,y))(corresponding to the second rule). as we can see, the compilation of innermost normalisation of a term is quite easy and straightforward. if we need to get the normal form of a term, say plus(suc(zero()),plus(suc(zero()), zero)), we just write in the goal language the expression plus(suc(zero()), plus(suc(zero()),zero())). the result of its evaluation will be the term suc(suc(zero)).



the generation of normalising term constructing functions does not restrict the user to an innermost normalisation strategy: there is no obligation for the user to construct terms with this set of functions generated by mtom. when implementing other evaluation strategy, the user can define its own term construction functions. the reduction mechanism is therefore kept fully under the control of the user.



in order to be flexible, the user is not restricted to have only one uniform term representation(see section 6.2 for more details): the api can be parametrized by the type name of the class of terms to be considered. those types are enclosed between< and> signs.



patterns and rewrite rules are introduced by the%rule keyword followed by a pattern, the%--> sign and by a semantic action. the semantic action will be executed if its corresponding pattern matches the input term. in this case, local variables(generated by mtom) record the matching substitution. if a return statement occurs in a semantic action it is supposed to return the right hand side of the rule.



rewriting, rewriting with local assignments, strategy controlled rewriting, etc.), possible ambiguities are solved as follows: if there are several patterns applicable on the given input_term then the first applicable rule is taken, i.e. the semantic action corresponding to the first applicable pattern is executed. if a semantic action does not exit by the return statement, then the next possible match of this rule is taken and the semantic action is executed again for the new substitution(this applies only on possible extensions of matching, see section 6.4). if there is no more different matches for the same pattern then the next applicable pattern(in order of appearance) is taken and its semantic action is executed. those rules permit us in particular to implement conditional rewrite systems, where the construction of each right hand side will be enclosed in an if statement(this if statement comes from the goal language, it is not an mtom construction, of course). let us take for example two rules(note that this example involves built-in data-types of the goal language, see section 6.1):



until now, we did not take into account the question of memory management. this is because the user has to take care of this problem. however, unless an automatic garbage collector is used(like for instance with aterms), some kind of cooperation is desired. this concerns mainly accessing parts of a term matched by a pattern. some parts should be freed after an application of rewrite rule. semantic actions need to be able to access particular subterms of the term to be reduced. in mtom, a special mechanism is provided to handle this situation. by convention any subterm of the input term corresponds to a local variable denoted by its position in the pattern. for example, the local variable _1 denotes the first subterm, whereas the variable _2_1 denotes the first subterm of the second subterm. note that when a particular semantic



a variable may have multiple occurrences in a pattern. such non-linear patterns cause that mtom will need to compare two subterms of the input term. because mtom is not supposed to know the entire term representation, the user needs to specify how to compare two terms in its api part.



c)(where+ is associative and commutative), then x has to be instantiated by the(b+ c) which did not exist before. it must be created during the matching process. second, specific non-syntactic matching algorithms are usually working with their own internal term representations. in order to be efficient, this would oblige the users to adopt this term representation and we would loose another nice mtom property, which is to be independent on a particular term representation.



when starting our work on mtom we thought that a particularly good choice of the many-to-one matching algorithm would be essential. now it seems that the tool design has its importance in its own. it offers a specification language for industrial use of rewriting. when a user practices with mtom, its application will not depend on a concrete implementation of the manyto-one matching algorithm. the user is free to switch among different mtom implementations with different pattern matching algorithms.



for the moment, the concrete choice of the many-to-one algorithm does not have so much importance. however, we feel that such an algorithm should have reasonable time and space complexities. in the future, we plan to make experiments with sophisticated pattern matching algorithms like the one introduced in.



as we have mentioned previously, the user can define its own evaluation strategies when using mtom. if semantic actions are just building right hand sides of rules instead of reducing them, then mtom itself does not provide and does not impose any reduction strategy. it turns into a simple tool for many-to-one matching and the generated function mtom_main provides one reduction step at the top position of its input term. using this function, the user can easily define its own evaluation strategies.



however note that this case is much more complicated. for example, the fact that no rule is applicable does not necessary mean a wrong design. it may mean that an argument is not sufficiently evaluated at the moment. due to this fact, the default rules should evaluate their arguments before causing an error message. also conditions have to explicitly call an evaluation function before failing in the application of a rule.



let us take for example a rewrite system computing the(infinite) list of all prime numbers. this example defines a function ilist computing the(infinite) list of all natural numbers; a function isprime testing whether a number is prime or not by trying to divide it by previously computed prime numbers; a function pfilter getting the infinite list of natural numbers and filtering it by the isprime function which results into the list of all prime numbers. the pfilter function also keeps the list of already computed prime numbers in its second argument. semantic actions use functions cons, ilist, isprime, pfilter which are supposed to construct corresponding terms without trying to reduce them. this example acts on peano arithmetics and uses functions mul, mod and div implementing respectively the multiplication, module and division between two peano integers. those functions are supposed to return normal forms of the result(innermost normalisation), so the example demonstrates also a combination of different rewriting strategies in a single program.



in this example we have to define two c functions controlling applications of rewrite rules: the function lazystep providing a single application of a rule and the function lazynf computing a normal form of a given term. both functions act in a lazy manner meaning that they reduce an outermost position first. those functions use global variable mtom reduction occured. this variable is cleared by the mtom main function in case that it did not provide any reduction.



in some languages(elan for example), rewriting is performed in a nondeterministic way, meaning that several possible rewrite steps are explored successively by backtracking. non-determinism occurs when several rewrite rules can be applied on a single term. in such a case, all the possibilities should be explored.



instruction and the default rewrite rules(applied when no regular pattern matches) execute the fail() function. this ensures that a choice point is set and then the right hand side is constructed and returned(the true branch of the if statement). in the case that a fail occurs somewhere in further computation, the control comes back to the last if(setchoicepoint()) statement and pass throw the false branch at the end of the semantic action. this will cause that next match and the next applicable pattern will be examined.



in the single-match style, a successful match yields just one binding. this style is usually taken in declarative programming languages. in particular, most functional programming languages such as caml[8,31], clean[6,24], erlang[2,1], gofer, haskell[15,23], or ml[9,18] allow defining functions by pattern matching.



the compilation scheme consists of two phases:(a) the abstract syntax tree is transformed(using mtom itself) into another tree representation where each group of rule constructs is replaced by a matching automaton.(b) the latter is pretty-printed according to the chosen goal language. if one wants to enrich the generator with another goal language, it is sufficient to parameterize or to extend this phase according to the goal language constructs(how to declare a variable? how to assign a variable? how to perform an if-then-else? etc.)



a new match primitive is added. contrary to the existing rule construct, the match construct can be used everywhere a goal language instruction is allowed(in blocks or functions for example). furthermore, this construct is more powerful since it can be used to group any set of patterns(even those with different top symbols). this feature is particularly useful when compiling strategy controlled rewriting[5,29](i.e. a set of rules applied under a given strategy). it is clear that the current rule construct is implemented using this more atomic construct.



