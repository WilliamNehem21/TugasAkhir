debugging is one of the most time-consuming activities in program design. work on automatic debugging has received a great deal of attention and there are a number of symposiums dedicated to this field. automatic debugging is usually invoked when a test fails in one situation, but succeeds in another. for example, a test fails in one version of the program(or scheduler), but succeeds in another. automatic debugging searches for the smallest difference that causes the failure. this is very useful when working to identify and fix the root cause of the bug.



a new testing method instruments concurrent programs with schedule-modifying instructions to reveal concurrent bugs. this method is designed to increase the probability of concurrent bugs(such as races, deadlocks) appearing. this paper discusses integrating this new testing technology with automatic debugging. instead of just showing that a bug exists, we can pinpoint its location by finding the minimal set of instrumentations that reveal the bug.



forefront. concurrent defects, such as unintentional race conditions or deadlocks, are difficult and expensive to uncover and analyze, and such faults often escape to the field. production of multi-core processors is another trend that highlights the need for testing and debugging of multi-threaded applications in the client space. as a result, commercial enterprises such as intel, ibm, and microsoft are giving increased attention to developing methodologies and tools for this domain.



much research has been done on testing multi-threaded programs. research has examined data race detection,,; replay in distributed and concurrent contexts; static analysis,,; and the problem of generating different interleaving to reveal concurrent faults,. model checking, coverage analysis,,, and cloning are also techniques used to improve testing in this domain.



in a previous paper, we demonstrated how to build a testing tool that randomizes the interleaving on top of aspectj. aspectj implements aspect oriented programming for the java language. using 12 lines of aspectj, we created a testing tool similar to contest, an ibm commercial tool that proved useful in finding concurrent bugs. this kind of testing tool, works by instrumenting locations whose timing may impact the program result, such as access to global variables, with randomly executed sleep statements. when we wanted to carry out a full implementation of contest, we found that aspectj was missing some features. because aspectj is open source, we claim that test tool makers can add the features themselves without waiting for an aspectj version that contains them.



in this paper, we describe our work on a new debugging tool that is based on noise creation testing technology. noise creation, in our context, is insertion of delays, random or otherwise to modify the timing of the program under test. noise generation is very useful in finding intermittent bugs. our tool looks for the minimal set of noise that contains instrumentation that reveals the bug. if one or several locations can be found where the instrumentation of noise reveals the bug, the description of these locations can be very useful to developers. as expected, our experiments found that it is valuable, in debugging, to know where a thread switch causes a bug to be manifested. a different approach uses genetic algorithms. in that work, instead of looking for the minimal set of changes, they searched for the set of changes that yields the maximum likelihood of finding the bug.



create technology for self-healing. for intermittent bugs that depend on specific interleaving, it may be possible to automatically detect and remove the bug-causing interleaving. while the work is not yet mature, we believe that it is interesting due to the following contributions: we show, at least on small programs, that the combination of a dd technique and testing via noise generation yields a practical concurrent debugging technique. we show a new dd algorithm that, in some scenarios, is better than those found in the literature. in addition, the actual implementation is detailed, which includes modifications to aspectj that can be applied to other applications.



we implemented our work using aspectj, an aspect-oriented extension to java. with just a few new constructs, aspectj can extend java to provide support for the modular implementation of a range of cross-cutting concerns. dynamic cross-cutting makes it possible to define additional implementations that run at certain well-defined points in the execution of the program. static cross-cutting makes it possible to define new operations on existing types. dynamic cross-cutting in aspectj is based on a small but powerful set of constructs: join points are welldefined points in the execution of the program; pointcuts are a means of referring to collections of join points and certain values at those join points; advices are methodlike constructs used to define additional behavior at join points; and aspects are units of modular cross-cutting implementation, composed of pointcuts, advices, and ordinary java member declarations. we use dynamic cross-cutting to implement the features of contest using aspectj, in a manner similar to that used by the contest instrumentor.



this section describes the algorithms we use to find the minimal amount of instrumentation needed to uncover the bug. first, we have to deal with the fact that the bugs are not deterministic. if execution succeeds(i.e., if it finds the bug), it does not necessarily mean that the instrumentation is in the correct location, since the bug would be found anyway with some degree of probability. when execution fails to find the bug, it does not necessarily mean that the instrumentation is not in the correct place, for two reasons. as discussed earlier, the instrumentation must be activated with probability, and in this execution it may have been activated at the wrong time or not activated at all. additionally, there may be other thread switches



a very important issue is the expected size of f, which is the minimal group of changes needed to reveal a bug. studies on bug patterns, have shown that f is generally very small and is often a singleton. finding a singleton is very easy. the simplest algorithm we use creates|n| mutations of the program, each created with a single addition of a sleep statement, and then checks which mutation finds the bug. the advantages of this trivial algorithm are its simplicity and the fact that it is oblivious to the existence of bad changes. a disadvantage is its complexity, as the number of possible changes is linear in s. the number of changes from which we select is dominated by the number of accesses to global variables in the files that contain synchronization elements; this turns out to be about the number of lines of code divided by five in the program we viewed(mainly industrial middleware programs). the second disadvantage is that this algorithm only works if the set of changes is a singleton. if more than one change is necessary, this algorithm fails.



at each stage in this algorithm we apply half of the remaining changes. if a bug is found, we continue with that half, and if not, we continue with the other. the complexity of this algorithm is log(n), which is very good; however, it is still limited to a singleton solution. if the solution is not a singleton, then the half we choose may contain a subset of the changes, in which case we continue with the other half



we set out to devise an algorithm that is optimized to search for small sets as we expect most of the solutions to be small. another advantage of the algorithm is that every query has a relatively small number of changes. this property is desirable for efficiency, as every instrumentation incurs costs in runtime and accuracy. we have seen that a program with more instrumentations is less likely to exhibit the bug than a program that uses less instrumentation but has it in the correct places. having less instrumentation is also beneficial from a performance point of view. due to the existence of bad instrumentation and the non-monotonicity of the problem, the less instrumentation we have, the less likely we are to face these problems, assuming, of course, the right instrumentation.



or part b, there is no change. if the changes are in both a and b, search for the relevant changes in part a(as before). next, search for the relevant changes in part b, while holding only the relevant changes in part a(as opposed to holding all the changes). while the algorithm can no longer be parallelized, it is more efficient for our application when run on a single processor.



this algorithm is slightly better than our modification of the dd algorithm. to find a singleton(if we do not know that the reply is a singleton), the average complexity of the dd algorithm is 1.5log(n). this is because every time we check, we choose with 50 percent probability in the first try and with 50 percent in the



we conducted several experiments to show the feasibility of our approach, mainly on code taken from the concurrent bugs benchmark. we illustrate the approach using synthetic programs created for this work and a program from sun that demonstrates concurrent issues. for each program, we examine the performance of each search algorithm described in section 3.



we synthesized a short program in which one location is not enough to reveal the bug. we chose this program because its entire code can be shown here. we have seen quite a few examples in the field where one location is not enough.



the technique for automatically locating the relevant concurrent faults is a step towards automatically fixing concurrent bugs. in previous work, we exposed existing bugs and studied bug patterns. after pinpointing the bug location, the next step is to suggest a fix. this goal is still far from being attained, especially



to achieve our goal, we developed a new dd algorithm. this algorithm is superior for our implementation and may be of further use to other applications. traditional dd algorithms can easily take advantage of parallel computing. different usage scenarios lend themselves to different algorithms.



we are now performing experiments on real applications. the key point is the question of monotonicity. if, in practice, the problem proves to be monotonic, then the algorithms suggested in this paper have practical applications. even if there are 100,000 instrumentation points, due to the logarithmic nature of the algorithm and the use scenario the running time will be reasonable. if the problem turns out to be non-monotonic, then alternative search techniques will be necessary.



another problem is that even if the bug can be seen, the probability of exposing it depend on the instrumentation points chosen. if it goes down bellow a certain threshold it will be very hard to detect it. to find the bugs automatically many tests need to be run. it will take longer on long running tests. deadlocks can also be found using this technique as the tests that find them use timeouts or look for circular lock probability.



in our previous work, we saw that aspectj can be used for testing but fell short in fulfilling the needs of contest because some features were missing. in this paper, we took advantage of the fact that aspectj is an open source tool and altered it to meet our needs. performing our changes to aspectj was relatively simple, since it is well written and easy to comprehend. using our altered version of aspectj, we were able to implement our tool to its fullest extent. the change we made is useful for a number of other testing tools, for example when performing coverage measurement and aiming to reduce the performance impact. coverage measurement is usually done by instrumenting the code and measuring which instrumentation points were executed. the main performance impact is due to the commonly executed instrumentations. after each test, removing the instrumentation points that were executed results in very good performance. creating such coverage tools with aspectj is now feasible due to our enhancement.



