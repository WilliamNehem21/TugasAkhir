safety-critical embedded applications are often distributed. for example, software in an automotive control or in avionics control are distributed over a large number of distributed processors which are connected over some domain specific buses. correctness of such applications is of paramount importance due to their safety-critical nature. synchronous programming models(e.g. esterel, signal, lustre) make synchrony assumption(zero time intra-module computation and zero time inter module communication) while modeling such applications so that the model is easier to verify. once verified, models built with such assumptions need to be distributed over an asynchronous communication based platform which brings out the challenge ensures safe communication between modules. in this paper, first we provide a more general sufficient condition for isochrony. second, we generalize the definition of isochrony for weakly-endochronous modules. further, we introduce the notion of directional isochrony which provides sufficient conditions for safe communication between modules in one direction but not in the other direction. the results in this paper not only simplifies the understanding of the conditions under which a polychronous specification can be implemented in gals, but also sheds interesting lights on causality and isochrony. when the synchronous modules are reused as ips, the conditions described here can be checked to see whether those modules can be composed asynchronously with the same behavior as their synchronous composition.



reaching one end of the chip from another end within a clock cycle is becoming difficult; second, the power consumed in the clock distribution network is too much compared to the power consumed in computation. therefore, a push towards multiple clock domains, and signals crossing clock domains have given rise to interest in gals design. since it is widely accepted that synchronous design is much easier than asynchronous designs, it is important to develop methodologies and tools for gals design.



this means that a new value of y is computed by function f by sampling the values at signals x1,x2,...,xn. it is the responsibility of the modeler to ensure that the values of each signal is present at its rate. in other words, the usage of signals by the modeler itself will indicate to the compiler that rates at which the values of x1,x2,...,xn are updated are the same, and y gets updated at the same rate, as by synchrony hypothesis, f computes in zero time. the signal compiler assumes the environment will supply the inputs at each clock instant and will show errors in case the clock calculus reveals this cannot be guaranteed.



where x, y, and z must have the same data type, and whenever x gets sampled or evaluated, y gets the value of x. if x is not evaluated or updated but z does get evaluated or updated, then y gets that value. so it is a deterministic merge with priority to the signal x over z.



signals have to be evaluated. even though the statements in signal are in parallel composition, there exists dependency between some of the signals which necessitates this ordering. this causality is caused by boolean gaurds in sampler operator, availability of inputs etc. which gives rise to rate relations. we are interested in the evaluation of these rate relations and how they influence the communication between components.



signal language has a syntactic construct called process which is its way of modularizing the dataflow specification. the processes are assumed concurrent modules. as a result, if process boundaries are deleted, one gets a large dataflow network where operators are connected with some other operators via signals. the signals at the boundaries of modules or processes also communicate in zero time as per synchrony assumption. however, when distributed in a gals environment, usually separate modules are deployed at different sites. as a result, signals that cross the module boundaries call for special attention, because the zero time communication for these signals cannot be assumed any more. the concept of isochrony concerns particularly these signals.



so the clocks of the signals computed by the operators must be related to check for this condition. when signals cross boundaries of modules, this is particularly problematic to check, because the modules may be coming from different modelers, and may already be compiled into code. hence, the clock relations of all signals inside each module must be exported along with the compiled module when exporting a module as an ip. the clock relations between different modules should be analyzed using clock calculus to check for such cycles. in the rest of this paper, we assume that such cycles have been checked before trying to create gals implementation of the model.



the clock of a signal specifies when the signal is valid. when two signals are used in a signal statement on either sides of the assignment operator, their clocks are said to be related. now we formally define a clock relation.



here process endo1 has two output signals which are received by endo2 through an asynchronous medium. according to the order of arrival of inputs to endo2, the value of c will change. two cases of reconstruction of c for different rates of out2 is shown below.



sharing of clock information between ips in a distributed environment involves exchanging meta-information about the clock relations for these endochronous processes. this information will include the signals and their rate relations which can be used to check for isochronoy. it is not possible to add any clock information into the ip, once it is implemented and shipped as an ip. so the meta-information will help in checking for isochorny and to redesign the ips to make them isochronous. now we formalize a sufficient condition for isochrony. for two endochronous processes pi and pj, where the set of signals of is vi and vj respectively, we define a communication structure cij.



the communication structure consists of the shared signals in both processes and the clock relations between them. the relation r will depend on the relation between signals in pi. for an endochronous process, there exists a direct or indirect relation between any two signals. now a2 can be rewritten as follows.



isochrony is verified. another way of correcting the example would be to share the signal a along with out1 and out2 and maintain the relation between them in the communicating ip. since correcting ip blocks while composition is not feasible, care has to be taken to ensure that the communication structure and relations are complete, during the design process of an ip.



another important factor is the independence of clocks of signals in weakly endochronous processes. in wendo3, the clocks(b^1, b^2) and(b^1, c^1) are totally independent. similar is the case in r43. to formally express this situation, we use the confirms with the known result. since any endochronous processes is also a weakly endochronous processes, assertion a4 also works for two endochronous processes. this demonstrates a uniform way to sufficiently evaluate correct communication(isochrony) for two endochronous or two weakly endochronous processes.



the composition of endo5 with wendo6 is correct since the statements in wendo6 are concurrent. the clock dependencies in endo5 are not relevant, since the statements in wendo6 are independent. wendo6 can be reconstructed with multiple behaviors which will have the same output. on the other hand, the communication from wendo7 to endo8 results in loss of values since endo8 get values of c2 only when d2> 0 holds. from these examples we can conclude: opposite direction cannot be guaranteed. we can observe similar behaviour for wendo7 and endo8. assertion a5 is not limited for only(endochronous, weakly endochronous) processes, it can also be used to analyze any two weakly endochronous processes by checking the clock relations between any pair of shared variables.



in other synchronous languages, different code generation strategies for incorporating distributed operation has been proposed. in esterel, code has been divided into atomic tasks which is scheduled with parallelism by referring a linked list containing the dependencies. more focus is given to the study of compositionality of processes which will later help in designing compilers with the goal of distributed implementation. in the signal language, one of the earliest work was regarding the clustering and schedulability of signal programs discussed in. a prominent work in distributed execution of synchronous languages was done by converting them into a common object code(oc) and then parallelizing this code into the many computing sites. in this work, no characterization of the modules or the inter-module communication were done to check for distributed deployment. it was assumed that a global clock is implemented distributively by virtue of clock synchronization algorithms. however, since global clock synchronization is expensive, in the signal literature or in this work, it is not considered. instead, one seeks characterizations under which such expensive protocols would not be needed for gals execution. multi-threaded code generation remains an important milestone in achieving a separated, but centralized implementation for synchronous programs. in the current polychrony compiler, only endochronous processes can be implemented. a beta version of multi-threaded code generating compiler is being developed. process based threading for weakly endochronous programs with separate compilation for composing processes have been implemented using the existing compiler for signal and a synchronous data-flow based threading strategy has been proposed in.



