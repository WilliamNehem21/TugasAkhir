deletions in binary search trees are difficult to analyse as they are not randomness preserving. we will present a new kind of tree which differs slightly from the standard binary search tree. it will be referred to as an ordered binary search tree as it stores a history element in its nodes, which provides information about the order in which the nodes were inserted. using this extra information it is possible to design a new randomness preserving and order preserving deletion algorithm.



d. knott(). when an algorithm is randomness preserving the general consensus is that average-case time analysis is feasible. that this is indeed the case has been formally demonstrated in where schellekens introduces a new programming language moqa for which all programs are guaranteed to be randomness preserv-



the remainder of this paper is organised as follows: in section 2 we describe this new kind of tree and provide an explanation of the deletion algorithm as well as its pseudo code. in section 3 we compare the probabilities of the different tree structures after a normal deletion with those using the new deletion algorithm on an example of a tree of size three. we then move on to provide a general proof of randomness preservation by proving that there is a bijection between the set of obsts and the set of permutations which respects the corresponding deletion and insertion operations. the average-case analysis of the algorithms can be found in section 4 where we show that both the insertion and the deletion algorithm have an expected performance of o(log n). finally we provide a conclusion and some ideas for future work in section 5.



however we have only looked at trees of a very small size and cannot infer from these examples that it will hold for all trees. to prove that it does, we will first prove the correctness of the operations described in section 2.2. in the following we will show



let p=(e1 e2... en) denote a permutation of the set x of keys e1 to en and let t=[e1, e2... en] denote the obst which was created by inserting the keys e1 to en in exactly that order.



does not hold, i.e. we have two different permutations for one obst. this would mean that we have at least one key at a different position which would result in a node with a different key-history value pair, hence a different tree. so we have found a contradiction and thus we know that



deletion: to analyse the deletion algorithm, we divide it into two main parts. in the first part we perform a search for the node to be deleted, let us refer to the cost for this as se. the second part of the algorithm is concerned with re-structuring the tree to make sure it is still an obst. the cost for this part will be referred to as re. finding the cost se involves arguments similar to the ones used for the insertion algorithm. again, the cost is directly related to the number of nodes visited along our search path, only this time we are looking for an internal node rather than an external node. therefore we can simply take the value for the expected depth of a node: se= de.



tree of arbitrary size into a tree of size n plus the cost of calling reinsert on a smaller tree tsub with only s nodes. we stop when we reach an external node, i.e. when s= 0. inserting a tree is not very different from inserting a single node: we consider only the root of the tree and try and find the correct position in the tree, insert the root and through its children pointers, the rest of the tree gets automatically inserted. as part of reinsert we do not necessarily need to find an external node to insert the tree and so we use the cost of finding a node in a tree of size n:



