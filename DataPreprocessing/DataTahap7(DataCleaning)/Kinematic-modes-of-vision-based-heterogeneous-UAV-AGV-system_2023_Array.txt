by the system to execute any intended task or application. in ref., authors have applied cnn(convolutional neural networks) for pose estimation of agv to implement landing of aerial vehicle over moving agv. in ref., vision-based landing over moving vehicle is developed for uav-agv system. a visual marker is placed over ground vehicle and detected using classical machine vision techniques. the proposed technique is validated with the field experiments. similarly, in ref., autonomous landing of uav over a static target is experimentally verified[22,24,26]. have developed vision-based techniques for the autonomous take-off, tracking and landing for the uav-agv system. thus, vision-based motion control techniques are well estab-



input velocity vector. input parameters space contains apparent velocity of agv, depth velocity of uav and velocity of the agv. velocity of uav and agv are expressed in the camera frame. velocity of the uav for various input vectors, satisfies the kinematic model of the system. thus, forward relation calculates velocity vector for the uav for different input vectors such that both agents are connected, or the kinematic model is satisfied. similarly, for the agv, forward relation can be obtained as,



collaborative motion. the objective of this study is to establish and use the kinematic model to develop control techniques. sliding mode control theory is chosen to support the objective of the present work. however, it is possible to implement both linear and non-linear control techniques using the kinematic model.



sliding surface, and then sliding phase keeps the system on the surface and brings down the error to zero. the main advantage of sliding mode controller is its robustness and simple implementation. thus, in the present work, sliding mode control theory is applied to develop motion control for the uav using each kinematic mode of the system.



both agents is function apparent relative acceleration. tracking control method can be developed by calculating the appropriate acceleration commands to the uav or agv to track the other. low-level control commands(torque) can be designed for the motion control of uav using acceleration form.



a formation control can be developed for the system by using this mode. in a situation where, uav and agv are performing a collaborative task and finished, formation mode can be activated where both move together towards each to facilitate the landing of uav over agv. an artificial formation mechanism is described for uav-agv system in refs.[50,51] where uav is controlled to keep constant separation from agv and to follow it. however, present analysis, brings out a novel natural formation(in-built behaviour) of the system which is useful to facilitate the landing task and also to contain the agv in the fov. this kinematic mode also explains the shrinking or broadening of the position of the agv in camera frame. it may be useful to navigate the agv in the complex environments.



displacement can be achieved by either controlling in-plane motion of uav parallel to ground plane or motion of agv. a formation mechanism can be designed to facilitate for landing of the uav over the agv after the mission. and, shrinking and broadening of position of the agv with respect to uav can be controlled to guide the agv in the complex environments such as narrow passages. similarly, when uav is controlled to a desired depth position, agv can be commanded to maintain the constant r. during a mission, if agv is tending to move out of the image plane, this mode can be activated so that uav directs upward to keep the agv in the fov. this behaviour of the system is useful during the collaborative tasks to contain the agv in the fov.



target and moving target have been developed in the literature. the 3-d(3dimensional) relative position is calculated by transforming the 2-d position of the target in the image plane. velocity of uav is controlled along 3 directions based on the 3-d position of the target. however, the 2-d position of target in the image plane is coupled



