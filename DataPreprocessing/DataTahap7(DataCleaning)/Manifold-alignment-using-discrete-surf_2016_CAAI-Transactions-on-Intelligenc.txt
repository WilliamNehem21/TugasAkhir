manifold alignment is useful to extract the shared latent structure among multiple data sets and the similarity among different datasets. as many kinds of real world data can be analyzed using low dimensional representations, manifold alignment algorithms can be used in a wide range of applications, such as data mining. in this paper, we propose a three-stage approach to manifold alignment using discrete surface ricci flow. our approach transforms the original intrinsic manifolds to hyper spheres using conformal mapping in the first stage, and then zooms these hyper spheres into the same scale and aligns them in the following stages. we describe in details about our algorithm, its theoretical principles, our experimental results, and the comparison to previous alignment methods. to prove the effectiveness of our algorithm, three kinds of experiments are presented, including a toy dataset, one containing parallel corpus of parliament proceedings and another containing both images and texts. with these experiments, the latent utility in discovering the similarity among different kinds of data sets can be demonstrated, whether within the same kind of data or across different kinds of modals of data.



in this paper, we propose an approach based on discrete surface ricci flow to solve the problems discussed above. in our approach, the original intrinsic manifolds of the data sets are transformed to hyper spheres via conformal mapping. the relative distances between each pair of data points on the surfaces are preserved, and then these hyper spheres are aligned. the generated manifolds are zoomed into the same scale, and then they are aligned to minimize the distance between each pair of corresponding points.



of notations necessary to describe our manifold alignment algorithm. section 4 shows the whole structure and the details of our manifold alignment algorithm based on discrete surface ricci flow. section 5 gives our analysis that proves the effectiveness of the proposed algorithm. experimental results and discussions are given in section 6. finally, section 7 provides concluding remarks.



definition 3.(discrete gaussian curvature) suppose m is a mesh with a discrete metric, which is in euclidean background geometry.[vi, vj, vk] is a face in m and represents the corner angle at vi on the face. the discrete gaussian curvature of vi is defined as composed of three stages, i.e., the conformal transformation stage, the scale adjusting stage, and the alignment stage. as the surface structures of manifolds are quite complex, it can be too difficult to find a proper function to describe its shape exactly. therefore, we intend to transform the original intrinsic manifolds in the first stage, after which they can be assumed to approximate hyper spheres. then in the following stages, it is the hyper spheres that are to be adjusted and aligned, rather than



which are two hyper spheres having the same dimensionality with a and b. we calculate the centroid a of the manifold a, and transform each data point on a so that the distance between each data point ac is the same as the largest one. this generated manifold is a*. a* is a hyper sphere with radius r and a means the centroid of manifold a. the correspondence between b and b* is similar.



in this stage, we aim to transform the original manifolds to hyper spheres. as we intend to convert the problem of aligning two manifolds with complex structures to the problem of aligning two hyper spheres, it is important to preserve the structure features on the manifolds. we preserve the local structures on the manifolds in this stage. in other words, the relative distances between each data point with the data points in its neighborhood and the intersection angles formed by the edges connected to each data point are preserved. the preservation is of great help when aligning these hyper spheres.



as mentioned above, in our algorithm, we transform the manifolds a and b into hyper spheres in the first step. the distances between each pair of points on these hyper spheres are used to determine the connectivity of points on a and b. therefore, it is of great significance to guarantee that the transformation preserves properties regards to connectivity on a and b. in this section, we analyze this problem and state it as the following theorem.



to test the effectiveness of our alignment algorithm, we use three data sets. the first one is protein, which is a small data set. the second one is the european corpus, which is a large data set used for cross-lingual retrieval. the third one is the wikipedia's featured articles, which is used for cross-media retrieval. both toy data set, which is easy to be drawn directly, and real world data sets, which are more complex, are used in our experiment. the experimental results using these data sets are discussed below.



assume that there are n correspondences in the training data set, then the document x can be represented by a vector v whose length is n. in this vector, v(i) represents the similarity between x and the i-th document in the training correspondences. the baseline algorithm maps the documents from different collections into the same embedding space rn.



the effectiveness of alignment algorithms can be described as follows. for each english document, we select k italian documents that are most similar with it. the effectiveness of these algorithms is represented by the probability for the true match to be among these k most similar documents. all of these algorithms map the data into a 100 dimensional space.



in this experiment, we rely on wikipedia's featured articles. this is a continually updated collection of articles that have been selected and reviewed by wikipedia's editors. the articles are accompanied by one or more pictures from the wikimedia commons, supplying a pairing of the desired kind. in addition, each featured article is categorized by wikipedia into one of 29 categories. these category labels were assigned to both the text and image components of each article. since some of the categories are very scarce, we considered only the 10 most populated ones.



each article was split into sections, based on its section headings, and each image in the article assigned to the section in which it was placed by the article author. this produced a set of short and focused articles, usually containing a single image. the dataset was finally pruned by removing the sections without any image. the final corpus contains a total of 2866 documents. a



these selected algorithms can cover most of the widely used methods, such as linear/nonlinear algorithms, regression algorithms and manifold alignment algorithms. among the above mentioned algorithm, the algorithms of lrga and tsc can be considered as applications of manifold alignment algorithm to solve the problem of cross-media retrieval. comparing with these algorithms, the effectiveness of processing the correspondence between images and texts using our algorithm can be proven.



in this paper, we have proposed a manifold alignment algorithm using discrete surface ricci flow, in order to transform a surface with a complex structure into a hyper sphere and then align these hyper spheres. the experimental results show that our algorithm can perform well on both small and large data sets. the alignment algorithm can not only explore the similarity of data of the same kind, but also can help find the similarity among different kinds of data.



in order to align two manifolds with complex structures, one of the most critical steps is constructing the triangle meshes to approximate intrinsic manifolds. however, when the intrinsic dimensionalities of manifolds are quite high, there may be more than one proper approach to construct the triangle meshes. therefore, for future works, we will focus on searching for the approach to construct the most proper triangle meshes, which can both be efficient and approximate the manifold accurately, when the intrinsic structure is complex.



significance in manifold alignment algorithms as well. the calculation of correspondences among different data sets can be regarded as the alignment of position in high dimensional spaces. however, alignment of the normal bundle among the latent manifolds can be helpful to understand the properties of data sets, such as semantic information.



zhongxin liu received the b.s. degree in software engineering from nankai university, tianjin, china in 2012 and the m.s. degree in computer application technology from peking university, beijing, china in 2015. since 2015, he has been a software engineer with the baidu co., ltd, beijing, china. his research interests include recommender systems, information retrieval, machine learning, computer vision, image processing, robotics and multi-agent systems.



qun jin is currently a tenured full professor at the department of human informatics and cognitive sciences, faculty of human sciences, waseda university, japan. he has been engaged extensively in research works in the fields of computer science, information systems, and social and human informatics. he seeks to exploit the rich interdependence between theory and practice in his work with interdisciplinary and integrated approaches. dr. jin has published more than 200 refereed papers in the world-renowned academic journals and international conference proceedings in the related research areas. his recent research interests cover human-centric ubiquitous computing, behavior and cognitive informatics, data analytics and big data security, personal analytics and individual modeling, cyber-enabled applications in e-learning and e-health, and computing for wellbeing. he is a member of ieee, ieee cs, and acm, usa, ieice, ipsj, and jsai, japan, and ccf, china.



