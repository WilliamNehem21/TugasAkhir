having established a local ordering< among the instructions in a single thread, we must now describe the behavior of multiple threads which execute together. the only means of communication between threads is via stores and loads. at the highest level, any multithreaded execution must be serializable modulo reordering. we begin by giving a formal definition of serializability in a transactional setting; this definition is more complex than the definition of non-transactional serializability.



note that we have pictured only one of several possible executions of this fragment. it is possible for l5 to instead observe s2. in that case, no known ordering would exist between s2 and s3, and l6 could observe either s1 or s4.



we have written the above procedure to be as clear as possible. however, it is not a normalizing strategy: a program which contains an infinite loop can get stuck in the graph generation and execution phases and never resolve a load. more complicated procedures exist which fix this problem(one starting point is to avoid unfolding or execution past an unresolved load).



what distinguishes speculation from mere reordering is the possibility that it can go wrong. we can describe speculation in our graph-based formalism in two ways: first, we can perform value speculation, guessing values and verifying them later; we defer this to future work. second, we can resolve instructions early, before all of their dependencies have been satisfied. this can result in violations of store atomicity. in we discuss a particular example, address aliasing speculation, arguing that while it permits new behaviors compared with a non-speculative model, it leads to a simpler and easier-to-understand memory model.



the operational framework given in section 4.1 limits load resolution to a transaction which contains a mix of resolved and unresolved loads. conceptually, it is simple to permit load resolution to occur in any thread: simply discard a behavior if it is ever discovered to contradict the rules of store atomicity. an actual system, however, only works with one behavior at a time. when an inconsistency occurs, we must decide which instructions to roll back.



the literature on memory models is a study in the tension between elegant, simple specification and efficient implementation. collier is a standard reference on the subject for computer architects, and established the tradition of reasoning from examples which we have continued. the tutorial by adve and gharachorloo is an accessible introduction to the foundations of memory consistency.



locks. however, data races are still possible in a transactional setting if shared data is manipulated outside a transaction. the idea of properly synchronized programs will continue to be relevant, albeit under simplified assumptions. the community is just beginning to formulate transactional consistency protocols comparable to release consistency[7,13].



better understanding of transactional serialization: store atomicity is a property that captures which instructions must be ordered in any serialization of an execution. in this respect, our semantics for transactional memory are not yet completely satisfactory: in practice many implementations interleave the instructions of multiple transactions without harm. the conditions outlined in section 3.5 are a starting point, but further refinement of these conditions is undoubtedly possible.



tools for verifying memory model violations: it should be relatively easy to take a program execution and demonstrate that it is correct according to a given memory model without the need to compute serializations. graph-based approaches such as tsotool have already demonstrated their effectiveness in this area. techniques similar to those described here(most notably routing interthread dependencies through trans and commit operations) have been suggested for checking transactional memory models. similarly, it would not be difficult to adapt the techniques of umm to perform exhaustive model checking in a transactional setting.



an easy to understand memory model. it is our hope that transactional models are simpler to understand, particularly for programmers. it has been conjectured that transactional techniques(particularly batched updates) can scale well even when a relatively strong memory model is chosen. it remains to be seen how well these claims stand up on very large systems(those with tens, hundreds, or even thousands of multi-core cpus).



krste asanovic played a vital role in targeting our work to computer architects. our work has benefited greatly from numerous comments and conversations over the years. for our treatment of transactions in particular we would like to thank maurice herlihy, victor luchangco, yossi lev, and the rest of the scalable synchronization research group at sun microsystem laboratories. jan-willem maessen would like to thank the fortress team. arvind was supported in part by the ibm percs project. both projects were funded in part by the darpa hpcs program.



