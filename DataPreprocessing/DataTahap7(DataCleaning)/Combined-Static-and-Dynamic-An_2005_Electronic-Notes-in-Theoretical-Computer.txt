program and calculates the fix point of properties using that graph. this is very different from dynamic analysis, which evaluates properties against an event trace originating from a concrete program execution. using a graphfree analysis, static analysis is again close to dynamic execution. in this paper, a graph-free static analysis is extended to a generic analysis which is applicable to dynamic analysis as well.



in jnuke, static analysis works very much like dynamic execution, where the environment only implements non-deterministic control flow. it thus implements a graph-free data flow analysis where data locality is improved because an entire path of computation is followed as long as valid new successor states are discovered. each java method can be executed in this way. the abstract behavior of the program is modelled by the user. the environment runs the analysis algorithm until an abortion criterion is met or the full abstract state space is exhausted.



the iteration over the program state space is separated from the analysis logics. a generic control flow module controls symbolic execution of instructions, while the analysis algorithm deals with the representation of(abstract) data and the semantics of the analysis. the control flow module implements a variant of priority queue iteration, executing a full path of computation as long as successor states have not been visited before, without storing the flow graph.



the generic control flow module first chooses an instruction to be executed from a set of unvisited states. it then runs the specific analysis algorithm on that unvisited state. that algorithm updates its abstract state and verifies the properties of interest. after evaluation of the current instruction, the control flow module adds all valid successor states to the queue of states to visit, avoiding duplicates by keeping a set of seen states. when encountering a branch instruction such as switch, all possible successors are added to the state space. furthermore, each possible exception target is also added to the states that have to be explored.



many java bytecode instructions do not affect control flow. therefore our algorithm does not store the current state if an immediate successor instruction is eligible. a state is only stored if it is target of a branch instruction. this reduces memory usage but may visit a state twice: if an instruction ib is the target of a backward jump, such as in a while loop, it is only recognized as such when the branch instruction is visited, which usually occurs after ib has been visited before. however, this overhead is small since it only occurs during the first iteration.



a generic analysis represents a single program state or a set of program states at a single program location. it also embodies a number of event handlers that model the semantics of byte code operations. both static analysis and run-time analysis trigger an intermediate layer that evaluates the events. the environment hides its actual nature(static or dynamic) from the generic algorithm and maintains a representation of the program state that is suitably detailed.



information used by the generic analysis. the generic analysis only operates on such data. the environment thus acts as a proxy for the virtual machine, if present, or replaces that data with appropriate facsimiles in static analysis. these facsimiles have to be conceptually isomorphic with respect to concrete values obtained during run-time analysis. distinct objects have to map to distinct representations. of course, true isomorphism is only achieved if pointer analysis is absolutely accurate.



conversely, analyzing a context-insensitive(method-local), thread-local property is more amenable to static analysis, but actually makes run-time analysis more difficult. this is counter-intuitive because such properties are conceptually simpler. however, in run-time verification, a new instance of the analysis has to be created on each method call and thread. instances of analysis algorithms then correspond to stack frames on the program stack. each new analysis instance is completely independent of any others, except for a shared, global context(such as lock sets, which are kept throughout method calls) and return values of method calls. the dynamic environment maintains the shared context and relays return values of method calls to the analysis instance corresponding to the caller. detailed knowledge of run-time verification is not necessary for the remainder of this paper; more about run-time verification in jnuke is described in the extended version of this paper.



static analysis calculates the set of all possible program states. branches(test nodes) are treated non-derministically by considering all possible successors and copying(cloning) the current state for each outcome. junction nodes denote points where control flow of several predecessor nodes merges. in this paper, the operation that creates a new set of possible states at this node will be called merging.



in dynamic analysis, only one program location l is active(per thread), corresponding to a single program state s. in static analysis, the sets of states sl at all program locations l are of interest. each set of states sl is represented by an instance of the generic algorithm. the type of operation performed to model the semantics of each instruction remains the same for static and dynamic analysis.



the effect of each evaluated method call is stored as a summary. contextsensitivity is modeled by evaluating each method call once for each possible context. if an analysis is context-insensitive, an empty context is assumed, having the effect that each method is only evaluated once.



in principle, every analysis algorithm can be split up into a generic algorithm and its environment. most data flow problems can be seen as settheoretic or closure problems and their nature will affect how the merge operation is implemented. precision of the analysis will depend on the approximation of pointer aliasing. if accurate information about data values is needed or when environment-specific optimizations are called for, the generic part of an algorithm may become rather small compared to the size of its(static or dynamic) environment. however, with the block-local atomicity algorithm, it has been our experience that the generic algorithm does indeed embody the entire logics and thus is not just a negligeable part of the whole. notably, adapting a static algorithm for dynamic analysis is greatly facilitated with our approach.



given warnings are all false positives. 2 in daisy, they were caused by readonly[ro] and thread-local[tl] values. for the prodcons benchmark, the stale value comes from a synchronized buffer[buf] and is thread-local. the two false alarms for the tsp benchmark are caused by thread-local exceptions[exc].



static and dynamic analysis algorithms can be abstracted to a generic version, which can be run in a static or dynamic environment. by using a graph-free analysis, static analysis remains close enough to program execution such that the algorithmic part can be re-used for dynamic analysis. the environment encapsulates the differences between these two scenarios, making evaluation of the generic algorithm completely transparent to its environment. this way, the entire analysis logics and data structures can be re-used, allowing for comparing the two technologies with respect to precision and efficiency. experiments with jnuke have shown that the static variant of a stale-value detection algorithm is significantly faster but less precise than the dynamic version. this underlines the benefit of using static information in order to reduce the overhead of run-time analysis. the fact that both types of analysis share the algorithm also allows for combining them in a tool that applies run-time verification to test cases resulting from static analysis reports.



