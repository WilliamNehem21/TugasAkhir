agents have a partial representation of the external environment and limited capabilities of interacting with it. an agent typically represents the external environment in terms of its individual perceptions of the environment. the type of such perceptions of course depends on the sensing capabilities owned by the agent.



we will focus on the way in which the behaviour of an agent may be influenced by its perceptions of the external environment, rather than on the way in which the agent will get such perceptions. for instance, we will abstract from the way in which a software agent accesses some piece of information available in the external environment(e.g., by receiving a message, by downloading a file, or by getting data from physical sensors).



at each moment, the external environment is hence represented by the perceptions of the agent. when agents are specified by logic programs, environment perceptions can be naturally represented as herbrand interpretations. moreover, while an agent is performing its computation, the external environment may arbitrarily and independently evolve. we therefore define an environment representation as follows.



example 3.3 consider for instance a walking robot that controls its walking speed on the base of its perception of the weather. suppose that the robot can move at two different speeds(slow or fast), and that it is able to perceive three weather conditions(sun, rain and snow). a natural specification of the speed control is to move slowly when it rains, to move fast when it is sunny, and not to move when it is snows. the speed control of such a robot can then be described by the following program p: where the set of possible environment perceptions is e={{red},{black}}. suppose that the initial budget of the agent is 100$. after the first round the agent will have either 99$ or 101$, depending on the result of wheel revolvement. after the second round the agent will have 98$, 100$, or 102$, and so on and so forth. the possible behaviours of the agent are illustrated by the



in the previous section, we have informally discussed the idea of associating a probability distribution with the set of environment perceptions of an agent. following definition 4.1, a probabilistic environment representation can be now formally defined as a set of probabilistic interpretations. we will consider sets of probabilistic interpretations such that the probabilities associated with the interpretations form a probability distribution, as stated by the following definition.



in order to further analyse the behaviour of the agent, we may make some further assumptions on the probabilities of the environment perceptions. for instance, we may assume that the robot will operate in an environment where snow is a quite rare event, while sun and rain alternate one another with sun slightly prevailing over rain. the assumption that in each moment the weather will be sunny with.5 probability, rainy with.4 probability and snowing with



one of the properties of interest in the practice of multi-agent systems is which are the conclusions that the agent may draw by reacting to the external environment, the evolution of the latter being a priori unknown. the notion of possible beliefs was introduced in to formally characterise the set of conclusions that a program p may possibly draw, starting with an initial set of interpretations i and reacting to a set of environment perceptions e. an effective, resource bounded characterisation of the possible beliefs of a program after n steps of computation can be formalised as follows.



it is worth observing that the notion of likely beliefs gives a handy representation of a subset of the probabilistic beliefs of practical use. consider for instance again the problem of comparing the probabilistic behaviours of the walking robot when varying its speed control program. if the robot engineers consider.8 as their belief threshold, then they obtain:



the invariant of a conventional program defines the properties that hold at each stage of the program computation. analogously, the invariant of a reactive program defines the largest set of conclusions that the program will be able to draw at any time in any environment. an effective, resource bounded characterisation of the invariant of a program after n steps of computation can be formalised as follows.



several efforts have been devoted to investigate the role of computational logic in multi-agent systems(see for a quite recent road map). the impact system is one of the best known examples of multi-agent system relying on computational logic. agent beliefs are represented by agent programs, in the style of logic programming, while integrity constraints and action bases are used to describe the actions that individual agents can perform. a number of interesting applications of impact have been illustrated, including its recent extension to deal with temporal reasoning. several other efforts have focussed on the use of computational logic to represent incomplete information in multi-agent systems. the use of abduction to represent incomplete communication environments, and the use of updates to represent dynamically evolving knowledge[2,12] are two promising approaches that have been recently proposed. the agent-based architecture presented in



a considerable amount of work has been devoted in the logic programming community to model open programs and their composition(see for a survey). while these works share with ours the adoption of the logic programming paradigm as specification language, they focus on the composition of static programs. in contrast, we focus on the composition of a program with an external dynamic environment, and analyse its reactive, incremental computations.



abductive logic programming is another approach to modeling incomplete knowledge. in this setting, agents may abduce external hypotheses provided that they satisfy existing integrity constraints. while we focus on bottom-up semantics, abductive logic programming is defined via proof procedures which combine backward reasoning with integrity constraint checking. a promising direction for further developments is to employ abduction to express forms of interaction among agents, as indicated in[6,7].



finally, a large body of research has been devoted in the last two decades to the study of concurrency. the main focus of these activities is to model process interactions abstracting from internal computations steps. in contrast our focus is on the interplay between interaction and computation. it is worth mentioning that explicitly introduces a notion of external environment which resembles ours, even if in a quite different context. also the semantics of interaction presented in employs an explicit representation of the environment. that semantics is formulated in categorical terms and it is based on linear logic and game semantics.



we have presented a simple logic-based formalization of the behaviours of agents capable of reacting to changes occurring in the external environment. in particular we have focussed on modeling the probabilistic behaviours of agents reacting to environment perceptions with an associated probability distribution. we have shown how the availability of a formal characterisation supports effective, resource bounded, quantitative analyses of the probabilistic behaviours of reactive agents, as illustrated by the notions of probabilistic beliefs and probabilistic invariants discussed in section 5.



