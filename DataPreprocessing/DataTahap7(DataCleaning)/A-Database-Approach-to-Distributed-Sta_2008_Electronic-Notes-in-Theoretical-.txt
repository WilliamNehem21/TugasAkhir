we study distributed state space generation on a cluster of workstations. it is explained why state space partitioning by a global hash function is problematic when states contain variables from unbounded domains, such as lists or other recursive datatypes. our solution is to introduce a database which maintains a global numbering of state values. we also describe tree-compression, a technique of recursive state folding, and show that it is superior to manipulating plain state vectors.



we study distributed explicit state space generation on a cluster of workstations in the presence of recursive data types, like lists and trees. recursive data types allow natural modeling of data needed in complicated protocols and distributed systems, e.g., the current knowledge of an intruder in security protocols. such systems can be analyzed by finite state model checkers, when the scenario is limited to a fixed number of participants. however, an upper bound on the size of the data terms is not known a priori.



we show that the basic scheme for distributed state space generation based on a shared hash function is limited(sec. 2.2). it breaks down in the presence of state space generators that produce recursive data types. implementing them as acyclic pointer structures works well on one computer but sharing pointer structures over a number of workstations is non-trivial.



our solution(sec. 3) is to introduce a database(basically an indexed set) that maintains a global numbering of values that occur in state vectors. instead of exchanging vectors of(serialized) pointer structures, the workers now exchange vectors of indices. in addition, workers must communicate with the database in order to agree on the semantics of these indices.



a further improvement(sec. 3.3) is to recursively fold states using a tree of databases. each node in this tree represents a set of subvectors. the leaf databases store sets of individual state components, while the root database represents a set of full state vectors by pairs of integers. this so-called tree-compression reduces the memory needed to store a set of states.



we implemented several versions(sec. 5), in order to measure the effects of recursive state folding, and the effects of organizing the intermediate node databases globally or locally. we report an interesting trade-off for organizing the internal databases locally or globally, depending on the available bandwidth and latency of the underlying network.



in these algorithms, the state space is partitioned over the memory of w workers by a hash function. each worker keeps its own part of the explored state space in closed w. the states that still have to be explored are kept in the set open w. the explore-thread picks an open state, calculates the hash of all its successors in order to put them in the local queue of the right owners. the receive-thread picks states from the local queue, checks if they are new by consulting closed, and if so, adds the state to both the closed set(to avoid duplicate exploration) and the open set(to be explored by explore).



the other problem is that in order to transmit a state across the network it has to be serialized into a flat binary form. serializing an array of integers is very efficient. serializing an array of aterms, however, is a serious problem: the printed version of a single aterm often takes 40 bytes or more, because typically the sharing gets lost. that means that it is factor 10 larger than the pointer we started with. it becomes infeasible, if we consider that a state



furthermore, we can communicate the(compressed) index vectors to other workers w. this reduces bandwidth demands between workers, however we must keep in mind their additional communication to the database. we will return to this point in sec. 3.2.



in the example and in our implementation, we chose to split the vector in half each time. this is a reasonable assumption if one does not have additional knowledge about the vector. but in some cases, we know in advance that one of the vector positions is going to have a lot of different elements. in that case it would be useful to split the vector in a short and a long part where the element with many different values is in the short part. permuting the vector can also have large effects. we leave research in this direction for future work.



ciardo et al. consider multi-valued decision diagrams(mdds) for efficient storage of state sets. a distributed version is described in. mdds branch according to the value of state variables, while our trees branch on the position of variables in the state vector.



results for models of three different sizes: lift5 is the model of an elevator system with multiple legs in order to lift large vehicles. swp is a model of the sliding window protocol. ccp33 models the cache coherence protocol jackal for java programs. columns are explained in sec. 5.



we enhanced the basic scheme of distributed state space generation with a global database, in order to provide a globally unique representation of values from recursive data types. the round-trip costs are lowered by using database replication. furthermore, we introduced tree compression as a means of compressing state spaces by means of recursive state folding. local and global(but replicated) implementations of index databases have been implemented and their effect on latency and throughput was measured. speed



we see three lines of future research regarding tree compression. so far, we only experimented with exchanging long index vectors(no tree compression) or index vectors of length 2(full tree compression). intermediate solutions are possible too. it would be interesting to experimentally establish an optimal cut-off point for state vector compression, or even build an adaptive tool that dynamically finds the optimum w.r.t. a given model and cluster.



finally, another interesting possibility is to adapt our scheme to heterogeneous systems, where several clusters of workstations are connected by a high-latency network to form a grid. in such settings, databases could be local to a cluster, providing indices that are unique within a cluster. this would allow to exchange compressed vectors within a cluster, while across clusters uncompressed vectors have to be exchanged in order to contain the effects of latency.



