in this paper we will show the performance of a second order pic algorithm. our implementation uses second order finite elements and particles that are represented with a collection of surrounding ghost particles. these ghost particles each have associated weights and offsets around the true particle position and therefore represent a charge distribution. we also test our pic implementation against a first order algorithm on various modern compute architectures.



the warp code, developed at lawrence berkeley national laboratory(lbnl) and lawrence livermore national laboratory(llnl) implements an explicit and three-dimensional pic algorithm in order to model the behaviour of high intensity ion beams. like epoch, warp applies a second order leapfrog method to advance particles, but only uses linear interpolation functions between the particles and the grid points. instead of the fdtd method, an electrostatic poisson solver is used to conduct the field solve. there have been several versions of warp, these include a code capable of adaptive mesh refinement(amr), and both twodimensionial and three-dimensional electromagnetic implementations.



tions. the algorithm uses second order weighting functions to deposit charge on all cells adjacent to the particle. at problem boundaries the charge weighting is smoothly changed from second to first order, becoming entirely first order once the particle is on the boundary itself. through the use of a test problem that consists of a conducting sphere in the centre of a square grid it was shown that charge is exactly conserved within the bounds of round off error. however, the algorithm requires further testing to determine its performance on three dimensional problems with strong electric and magnetic fields.



the pic method implemented within empire-pic is used to model the behaviour of plasmas through representation of an electric field(e) and magnetic field(b) on an unstructured grid. the values of these fields are stored at each of the grid nodes, with interpolation being used to determine the field values at a specific point within a cell. the simulation also contains discrete particles that represent the plasma being simulated. each of these is associated with a position on the grid, an electrical charge, a mass, and a velocity.



to a multiplication of the charge to mass ratio of the given particle, and the value of the electric field at its current location. once the velocity has been determined, we can update the particle position trivially by multiplying by the timestep size to calculate how much the particle should be moved. in the event of crossing an element boundary, the move is broken up into segments and the process is applied to each of these segments in turn.



the final step of the core electrostatic pic algorithm is for the particles to deposit their contribution of electrical charge back onto the grid nodes before the beginning of the next field solve. the process is almost identical to that of weighting the fields to the particles: basis functions are used to calculate how much charge a particle must contribute to each node, and the relevant nodes are updated accordingly. however, the node updates must be carried out using atomic addition operations in order to prevent multiple threads attempting to update the charge value of the same node simultaneously, which would lead to erroneous results.



in this section we present the outline of our second order algorithm along with some of its implementation details. pseudocode for this algorithm is shown in algorithm 1. before summarising the second order algorithm implemented within empire-pic, it is first necessary to introduce the concept of both first and second order finite elements. consider a two dimensional grid made up of quadrilateral elements. as outlined in section 3 the values of the electric field are stored at the nodes of each element of this grid. in the first order situation nodes are situated at each of the four corners of the cell, and basis functions must be used to interpolate the value of e at a specific location within the cell.



of the subparticle(through addition of its offset to the central particle position) which are then multiplied by the electric field value as normal. this result is then weighted according to the weight associated with the specific subparticle. in this way we compute the value of the electric field felt by each subparticle, it is then trivial to obtain the value on the true particle by simply summing the contributions of each subparticle for each grid dimension.



much like the traditional pic algorithm, particles in our second order method must deposit their charge contribution back to the grid nodes before the next field solve can be carried out. this follows a procedure much like our field weighting process, except in reverse. for each particle, each of its subparticles deposit their charge individually. as usual we obtain the subparticle position from its offset in order to determine the values of the element basis function at its location. we then multiply the particle charge by its weight, the basis function values, and the amount of physical particles that the particle is representing within our simulation before depositing it at each of the grid nodes. it should be noted that our algorithm still suffers from the issue of race conditions between threads when depositing this charge. currently this issue is resolved through the use of atomic operations as in many other codes, though this leads to a performance overhead due to reduced parallelism.



in order to examine the peformance of our algorithm we compare its behaviour to that of the first order implementation. to this end we use a two dimensional two stream instability problem as our primary test case. this consists of two beams of electrons travelling in opposite directions separated by a stationary stream of positively charged ions. this leads to an increase in the energy of plasma waves. we also present performance results for landau damping problems, where we simulate the effects of exponentially decreasing the energy of longitudinal waves in a charged plasma environment. this can be thought of as the inverse of the described two stream scenario.



our largest test cases use a total of 1 million particles on a grid consisting of 64 cells in the x dimension, and 2 in the y dimension, for a total of 500 timesteps. this leads to a large amount of particles per grid cell, facilitating the later investigation of the effects of the overhead of atomic operations on the performance of the algorithm. besides this, we use simulations with a variety of particle counts to assess the scalability of our pic implementation. in addition to total execution time, and the timing of various key kernels, we also examine the average memory bandwidth used by the application at both first and second order in order to establish whether the move to second order drastically alters the degree to which the code is memory bound.



the intel systems show very comparable scaling, with the initial gap between the two systems narrowing as problem size is increased. therefore, while the nonaccelerator systems are competitive with each other, on our algorithm the p100 is clearly superior and it is reasonabe to conclude that this would be the case on much larger problem sizes. however, at first order all three modern architectures exhibit similar scaling with very little difference between the three. the scaling behaviour does suggest that if first order problem size were to continue to increase a performance gap would appear between the p100 and intel systems.



experiments. we see almost no difference in the bandwidth achieved by the tesla k20, whereas there is a noticeable increase for second order problems on both the tesla p100 and the knl. however, these increases do not make the application significantly more memory bound due to the high bandwidth limit for both systems. surprisingly we observe a decrease of approximately 1 gb/s in the achieved bandwidth on the broadwell system at second order. this result warrants further investigation.



while second order methods currently perform and scale worse versus first order, our results suggest that second order pic methods are becoming more viable on modern architectures when compared to previous generations of many-core hardware. we have also highlighted that, for our unstructured code, the significant performance issues are located within routines that involve weighting the values of the electric field to particle locations, or vice versa. this is both due to the usage of atomic operations, and also the conversion of physical points to reference points in order to determine basis function values.



this is the first paper to document our electrostatic second order algorithm and its performance behaviour on various compute architectures. in future work we aim to use convergence analysis to quantify the accuracy improvement gained through using our method. additionally, through resolution of performance issues we hope to show improved performance and scaling behaviours versus first order problems. finally, we will extend our algorithm to function on electromagnetic simulations, where particles are influenced by both magnetic and electric fields.



