automatically generated lexers and parsers for programming languages have a long history. although they are well-suited for many languages, many widely-used generators, among them flex and bison, fail to handle input stream ambiguities that arise in embedded languages, in legacy languages, and in programming by voice. we have developed blender, a combined lexer and parser generator that enables designers to describe many classes of embedded languages and to handle ambiguities in spoken input and in legacy languages. we have enhanced the incremental lexing and parsing algorithms in our harmonia framework to analyze lexical, syntactic and semantic ambiguities. the combination of better language description and enhanced analysis provides a powerful platform on which to build the next generation of language analysis tools.



the methods described in this paper handle four kinds of input streams, three of which are ambiguous; our solutions are summarized in section 3. combinations of these ambiguities arise in different forms of embedded languages. the handling of this fifth kind of input stream is presented in sections 4 to 7. some of these ambiguities have also been addressed in related work, which is summarized in section 8.



multiple spellings; single lexical type. programming by voice introduces potential ambiguities into programming that do not occur when programs are typed. if the user speaks a homophone which corresponds to multiple lexemes(for example, i and eye), and all the lexemes are of the same lexical type(the token identifier), using one or the other homophone may change the meaning of the program. multiple spellings of a single lexical type might also be used to model voice recognition errors or lexical misspellings of typed lexemes(e.g. the identifier counter occurring instead as conter).



to their structural and semantic properties. high-level transformation operations can be created and maintained in the program representation. harmonia furnishes the xemacs and eclipse programming editors with interactive, on-line services to be used by the end user during program composition, editing and navigation.



support for each user language is provided by a plug-in module consisting of a lexical description, syntax description and semantic analysis definition. the framework maintains a versioned, annotated parse tree that retains all edits made by the user(or other tools) and all analyses that have ever been executed. when the user makes a keyboard-based edit, the editor finds the lexemes(i.e., the terminal nodes of the tree) that have been modified and updates their text, temporarily invalidating the tree because the changes are unanalyzed. if the input was spoken, the words from the voice recognizer are turned into a new unanalyzed terminal node and added to the appropriate location in the parse tree. these changes make up the most recently edited version(a.k.a the last edited version). this version of the tree and the preedited version are used by an incremental lexer and parser to analyze and reconcile the changes in the tree.



unambiguous lexing and parsing is the normal state of our analysis framework. programming languages have mostly straightforward language descriptions, only incorporating bounded ambiguities when described using glr. thus, the typical process of the lexer and parser is as follows. the incremental parser identifies the location of the edited node in the last edited parse tree and invokes the incremental lexer. the incremental lexer looks at a previously computed lookback value(stored in each token) to identify how many tokens back in the input stream to start lexing due to the change in this token. 5 the characters of the starting token are fed to the flex-based lexical analyzer one at a time until a regular expression is matched. the action associated with the regular expression creates a single, unambiguous token, which is returned to the parser to use as its lookahead symbol. in response to the parser asking for tokens, lexing continues until the next token would be a token that is already in the edited version of the syntax tree.(the details of the parser incrementality are not essential to this discussion and are omitted for brevity. notice that additional information must be stored in each tree node to support incrementality).



a similar mechanism could be used for automated semantic error recovery. identifiers can easily be misspelled by a user when typing on a keyboard. compilers have long supported substituting similarly spelled(or phonetically similar) words for the incorrect identifier. in an incremental setting, where the



if the alternate spellings for a spoken word(as described above) have differing lexical types(such as 4/for/fore), they are returned to the parser as individual tokens grouped in the same ambignode container described above. when the lexer/parser interface sees an ambignode, it forks the parser and lexer instance, and assigns one token to each lexer instance. the state of each lexer instance must be reset to the lexical state encountered after lexing its assigned alternative, since each spelling variant may traverse a different path through the lexer automaton. 6 once each token is re-lexed, it is returned to its associated parser to be used as its lookahead token and shifted into the parse tree.



using blender, the outer and inner languages that constitute an embedded language can be specified by two completely independent language definitions, for example, one for php and another for xhtml, which are composed to produce the final language analysis tool. embedded language descriptions may be arbitrarily nested and mutually recursive. it is the job of the language description writer to provide appropriate boundary descriptions.



one technique for identifying boundaries is to use a special program editor that understands the boundary tokens that divide the two languages(e.g., php embedded in xhtml) and enforces a high-level document/subdocument editing structure. the boundary tokens are fixed, and once inserted, can not be edited or removed without removing the entire subdocument. the two languages can then be analyzed independently.



another technique is to use regular expression matching(or a simple lexer) to identify the boundary tokens in the document and use them as an indication to switch analysis services to or from the inner language. these services are usually limited to lexically based ones, such as syntax highlighting or imprecise indentation. more complex services based on syntax analysis cannot easily be used, since the regular expressions are not powerful enough to determine the boundary tokens accurately.



lexical descriptions are written in a variant of the format used by flex. the header contains a set of token declarations which are used to name the tokens that will be returned by the actions in this description. at the beginning of a rule is a regular expression(optionally preceded by a lexical condition state) that when matched creates a token of the desired type(s) and returns it to the parser.



grammar descriptions are written in a variant of the bison format. each grammar consists of a header containing precedence and associativity declarations, followed by a set of grammar productions. to support descriptional modularity, one or more%import-token declarations are written to specify which lexical descriptions to load(of which one is specified as the default) in order to find tokens to use in this grammar. in addition to importing tokens, a grammar may import nonterminals from another grammar using the



in blender, boundary tokens for an inner language are specified with the outer language, so that the outer analyzer can detect the boundaries. the data for the inner language is written in a different specification, named commentlang, which is imported into the java grammar. in this simple case, the embedding is lexical. comment boundary tokens are described by regular expressions that detect the tokens/* and*/. they are placed in the main java lexical description(the one that describes keywords, identifiers and literals).



a flex rule consists of a regular expression followed by an optionallybraced c compound statement. the regular expression is denoted by the regexp root nonterminal from the regexp grammar. the symbol wspc denotes a white-space character. the compound statement is denoted by the compound stmt from the c grammar.



when a blender language description incorporates grammars for more than one language, the grammars are merged. 9 each grammar symbol is tagged with its language name to ensure its uniqueness. parser generation proceeds normally as for a glr parser generator(i.e. lalr(1) with glr conflict resolution).



next, if each parser has its own private lexer instance, and each lexer instance is in a different lexical state when reading the input stream, then the input streams may diverge at their token boundaries, with some streams producing fewer tokens, some producing more. this may cause each parser to be at a different position in the input stream than the others, which is a departure from the traditional glr parsing algorithm in which all parsers are kept in sync shifting the same lookahead token during each major iteration. unless we are careful, this could have serious repercussions on the ability of parsers to merge, as well as performance implications if one parser were forced to repeat the work of another.



we introduce a new data structure, a map from a lookahead token to the parsers with that lookahead. the map is initialized to empty in glrparse(), and is filled with each parser in the active-parsers list after each lookahead has been lexed in parse-next-symbol(). any new parsers created during do-reductions() are added to the map. in do-reductions(), when a parser



in principle, both incrementality and the extensions described in this paper could be added to scannerless glr parsers. however, as always, the devil is in the details. in an incremental setting, parse tree nodes have significant size because they contain data to maintain incremental state. if the number of nodes increases, even by a linear factor, performance can be affected. more significantly, incremental performance is based on the fact that the potentially changed region of the tree can be both determined and limited prior to parsing by the set of changed tokens reported from the lexer. for example, only a trivial amount of reparsing is needed if the spelling of an identifier changes, since the change does not cross a node boundary. although we have not done a detailed analysis, our intuition is that without a lexer, the potentially changed regions that would end up being re-analyzed for each change would be considerably larger.



