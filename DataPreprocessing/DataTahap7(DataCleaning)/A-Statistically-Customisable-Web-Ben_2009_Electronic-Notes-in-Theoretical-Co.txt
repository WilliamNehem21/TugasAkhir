we describe a statistically customisable solution for web benchmarking that includes three utilities: an internet traffic generator for http traffic, an static and dynamic web pages generator in the web server that is going to be tested and a performance monitor that reports some performance metrics during the test. the design of the tool is based on the implementation of the most important probability distributions that mainly characterise statistical properties of internet traffic like the inter-arrival rate of the incoming web traffic to the server, the number of objects contained in a web page and the size of these web objects. these properties can be customised for a specific capacity planning analysis. in this work, we describe the generation process of the web pages and the customisable traffic characterization used by the benchmark. the monitoring process details and the validation of the probability distributions implemented are also included.



our goal is to generate a specific and customisable workload based on probability distributions. these distributions will model some statistical properties of the web test that the benchmark will perform. the properties that can be defined through these distributions are: the inter-arrival rate of the incoming web traffic to the server, the number of objects contained in a web page and the size of the web objects. the fact of customising a benchmark by using probability distributions is very useful to reproduce some workloads that follow a determined characteristics that are described in literature. it can also be used to emulate real traffic in simulation scenarios and to validate the results that are obtained by some network simulators as opnet modeler or ns-2.



the rest of the paper is organised in the following way. section 2 discusses the motivation of using probability distributions to characterise the workload the benchmark introduces in the web server. the next three sections outline the proposed benchmark. the web page generator and the web traffic generator are presented in section 3 and 4, respectively. some details about the monitoring process are described in section 5. the experimental results and the validation of the probabil-



the number of objects per page. a web page can contain many kinds of information in addition to textual information. these elements are defined as objects and can be images, audio, video, scripts,..., etc. the probability distribution that models the number of objects per page is pareto.



we organise the web server site construction in two different steps. firstly we create the web objects that compose the web pages by following the distribution assigned to model the size of the web objects. once all the web objects are created, the second step consists of the inclusion of these objects in the web pages by following the distribution that model the number of objects that are contained in the web pages.



the benchmarking client sends the information introduced by the user to the web server. this information determines the characteristics of the web pages that are going to be generated. it includes the probability distributions that affect to the number of objects per page and the size of these objects. a process starts in the web server to generate the file structure that afterwards is going to be demanded by the web client. once the file structure has been created, the paths and the names of the web files are sent back to the client to inform the benchmark about where are the files the client is going to ask for.



before starting the workload generator, the benchmarking tool executes the performance monitoring process in the web server to get some information about the cpu utilization while the test is being performed. the processes involved in the web server system are the web server process and the database server process. in the case of static pages the database server is not monitored. a log is created with the information obtained by the monitor during the test.



the test-bed scenario consists of two computers that are connected through a fastethernet switch. the processor of the computer that acts as the web server is an intel pentium d at 3000 mhz and it has 2 gb of ram memory. the client runs in an amd turion 64 at 1600 mhz and with 512 mb of ram.



a flexible web benchmarking tool that can be statistically customised is presented in this paper. the tool permits generating a representative workload based on the probability distributions that mainly characterise some useful properties as the number of objects per web page, the objects size and the inter-arrival rate. this tool also includes a web page generator and a monitoring process that permits to obtain some important performance metrics in the web client and server. this benchmarking tool fills a gap in the currently available set of benchmarks. the validation of the customised properties is also presented at the end of the paper.



