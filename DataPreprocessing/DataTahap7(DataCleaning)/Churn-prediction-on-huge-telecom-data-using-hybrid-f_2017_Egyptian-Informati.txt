this section discusses the recent approaches for churn prediction. a risk prediction technique that identifies probable customers for churn was presented by coussement et al. in. this technique utilizes generalized additive models(gam). these models relaxe the linearity constraints, hence allowing complex non-linear fits to the data. this technique is exhibited to improve marketing decisions by identifying the risky customers and also providing visualizations of non-linear relationships.



class imbalance plays a major role in affecting the reliability of a classifier. the major issue existing due to class imbalance is that the minority class is not well represented and hence the classifier is undertrained on the minority classes. the technique proposed by zhu et al. in proposes to eliminate this issue by using transfer learning techniques. the approach presented in operates by training the classifier using customer related behavioral data obtained from related domains. this approach has its major focus on the banking industry and the results are proposed to exhibit enhanced performance. another technique that considers the imbalance nature of data to perform churn prediction was presented by xiao et al. in. a comparison of sampling techniques for effectively operating on churn data was presented by amin et al. in. game theory based churn prediction techniques



utilizing heuristics for predictions are on the raise due to the complex nature of data. a rule generation techniques that employs heuristics for customer churn prediction in telecom services was presented by huang et al. in. a combination of self organizing maps(som) and genetic programming(gp) to identify and predict churn was presented by faris et al. in. som is utilized to cluster the customers and then outliers are eliminated to obtain clusters depicting customer behaviors. an enhanced classification tree is built using gp.



building the search space marks the beginning of the classification process. the initial population of fireflies is generated and are distributed across the search space. the distribution of fireflies is carried out in random. position of each firefly is recorded and the initial intensity of the fireflies(intensity) are identified on the basis of their distance from the test data.



this process is continued until the specified stopping criterion is met. stopping criterion is usualy set with two conditions. the operations are terminated when a specified maximum generations(maxgen) have been reached, or if the system does not move to a better solution for a specified number of iterations. criteria of the first type is usually set in a production environment, while the second type is set during development to identify the time complexity. this process is carried out for each of the test data. cross validation is finally performed to identify the accuracy of the classifier.



and the top right. it could be interpreted that the algorithm exhibits very high true positive rates(tpr), i.e. it performs excellent classification of the positive cases. the false positive rates(fpr) are found to be low initially, however, finally the false positives show a huge increase.



