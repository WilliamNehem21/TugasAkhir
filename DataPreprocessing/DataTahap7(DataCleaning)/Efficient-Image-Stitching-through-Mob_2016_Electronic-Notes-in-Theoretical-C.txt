taking photographs has become one of the most widely used applications on mobile devices. cameras in mobile phones have become very good over the past years. images are used to preserve memorable moments, but also to take scans of documents. for panoramic pictures as well as for images of larger documents one image alone may sometimes not be enough to represent the full picture. then several images of parts of the scene are taken. to restore the full picture those images must be



image stitching is an old problem in computer vision that has been solved in different ways in history and is often described in the literature[6,24,13,21,16]. the process of combining different images to one is used, for example to combine images taken by satellites for navigation, to generate panoramic views from impressive landscapes and huge objects, the stitching of microscopical scenes or for image stabilization. today, taking pictures has become one of the most widely used applications for mobile phones, hence stitching those images has also gained relevance.



there are two main categories of methods for automatic image stitching, direct and feature-based methods. direct methods are using all image data and minimize the pixel-to-pixel dissimilarities. feature-based methods extract features from the images and try to match these, which enables the automatic detection of the correlation of images with overlapping parts[6,24].



to create a prototype of an image stitching application that uses mobile offloading a very basic, simple and not scale invariant feature-based approach is used, which basically can be divided into five steps, feature-point detection[11,17,23], featurepoint description, feature matching, homography estimation[4,12,21] and warping and projection. those steps are briefly described in section 3. for all these steps intensive research has been done and there are several ways of doing them[6,13,24]. herbon et al. have also described methods to reduce the complexity of the image stitching procedure for the execution on mobile devices by adding preconditions. the implementation of the used algorithms in this paper is not optimized for mobile devices, does not include image post-processing, like blending or feathering to hide the transitions from image to image, and does not deal with ghosting effects.



these platforms can be considered as the prototypes of a general and standard mobile application offloading structure. we believe that mobile application offloading systems are still in an early stage of development. with the invention of more intelligent mobile devices, mobile offloading structures will also be further developed. there is no doubt, more novel structures will also be proposed. in fact, if some uniform standards can be formulated to define either the offloading work flow or the basic elements of the system structure, the development of mobile offloading will be facilitated.



the first step in image stitching is to decide which type of points will be used to find correspondence between two images. one possible option is to use corners as feature-points of the images. to detect corners in an image the harris corner detection algorithm can be used, which is rotation invariant and robust to illumination changes but not scale invariant[11,17,23].



and, like its predecessor, uses small windows around each pixel. these windows are slightly shifted in every direction. the change of average image intensity resulting from those shifts is used to make a statement about the existence of a corner in the area of the pixel that is located in the center of the considered window. the image intensity of a pixel can be defined as the greylevel of the pixel in the 8-bit grayscale version of the image.



the feature-points described in section 3.1 are single pixels. the only information we can get when considering only one single pixel is its(x, y) position and its color. because the images to stitch images together can differ, the position of corresponding points do not have to be identical on both images and the illumination might have changed, so that the color is also not the same. therefore, it is not sufficient to consider only the found feature-points to compare and find corresponding ones. in order to compare them, they have to be described uniformly with the help of more information about the area around them.



by david g. lowe and uses histograms of gradient directions and magnitudes around sift keypoints to describe them and generate sift features. to provide the scale invariance, sift keypoints provide information about the scale of the image at which the keypoint was detected. the feature-points described in section



one method to measure the similarity of two vectors is to compute their euclidean distance. if the distance is small, the vectors are very similar. if the distance is large, they differ much. one very intuitive and simple way to find the best match for a feature fa of image a in the set of features of image b is to find the feature fb in image b which has the smallest euclidean distance to fa. this approach finds a best match for every feature fa of image a, if the set of features of image b is not empty. as setting a global threshold for the distance of features to filter false matches does not perform well a threshold for the ratio of the distance of the feature fa to the nearest feature fb,best and the second nearest feature fb,2ndbest found is used. if the distance to the best matching feature is much smaller than to the second best match, the best match is found with high certainty.



with the homography h found as described in section 3.4 it is possible to paste the two images onto each other. to do so, a new empty surface is created and one image is put in the center of it. then the positions of the pixel of the other image on the new surface can be computed by multiplying the coordinates of the pixel in the original image with h.



this information can be sent as xml. the xml data will be much smaller than the large panoramic image and therefore the data transmission time will be reduced. after parsing the xml data, the mobile device can stitch the images together locally, according to the received order and the homographies. since the last step of the image stitching process will be performed on the mobile device, the local execution period will be slightly larger, but the time to send the result back to the server is expected to be much smaller than in the first method.



the third method aims at minimizing the total execution time and the transmission time by minimizing both file sizes of the data to send and return. if the images are converted into 8-bit grayscale images, the time needed to compute the image intensities in the process of image stitching can be reduced. because the color information is not needed, these images need less memory than color images. for that reason, the time needed to send them to the server will also be less than sending the coloured ones.



the application was tested with two and four images. the execution was repeated 20 times for each combination. the time stamps for measuring were automatically written to a.csv file stored in the smartphone at the end of the computation.



local execution time: the second metric is the local execution time tlocal. this is the time needed to compute parts of the image stitching process on the mobile device. as it is assumed that the computation on the server is more efficient and saves the battery life of the mobile device, the maximum possible amount of computation should be performed on the server. therefore the local execution time should be as small as possible.



if b< 1, the tradeoff leads to a decrease of toffload. if b= 1 the tradeoff will not influence the total execution time but can be desirable, for example if there are limits to the monthly data volume and the reduce of transmission time is therefore better than less local execution time. if b> 1, the tradeoff will increase the total execution time.



the biggest parts of the execution with method two and three are the local execution time tlocal and the transmission time ttrans. the remote execution period is very small, because the remote server is very powerful. it can also be seen, that trading the transmission time ttrans against local execution time tlocal is not beneficial, if a good internet connection exists. the local execution time needed to warp and project the images is larger than the saved transmission time and therefore



method two keeps the step of warping and projection on the mobile device, therefore the remote execution time is shorter. method three also keeps the conversion of the images to 8-bit grayscale images on the mobile device, which reduces the remote execution time a bit more. since the part of warping and projection is more computationally intensive than the conversion, the difference of the remote execution time of method one and two is greater than the difference between the ones of method two and three.



the methods one and two send the whole image data, compressed to jpeg format, to the server. method three compresses the image data by omitting the color information. therefore only one byte per pixel has to be transmitted. however, jpeg is a compressed image format and therefore it is possible that the size in byte of the compressed file is smaller than the amount of pixels of the image. sending one byte per pixel will then take longer than sending the compressed jpeg file. for that reason method three should only be considered if the sum of file sizes in byte of the images is greater than the sum of pixels of them.



as all the stitching computation has been migrated to the server, method one needs the lowest amount of memory in all cases. the memory usage decreased by up to 25% for two images and up to 45% for four images when using method one. method three has the highest memory usage in comparison to the other offloading methods, because both the steps of image compression and warping and projection are executed on the mobile device.



under the conditions in our experiments all offloading methods result in decreased total execution time in comparison with the completely local execution, if the network condition is at least edge. as tlocal> toffload is always satisfied, it can be said in general that using the offloading methods is beneficial. depending on the network speed and latency, the total execution time could be decreased by around 50% for stitching two images and 73% for stitching four images together.



contrary to the presumption of section 4.4, method one results in the smallest total execution time and local execution time of the offloading methods in nearly every case, which makes this method clearly be the best. to trade transmission time for local execution period only makes sense for stitching two images under bad network conditions.



however, the transmission time is the highest when using method one. if the size of data to transmit should be minimized, method two is preferrable. in some cases as the sum of the file sizes of the images in byte is greater than the sum of pixels of the images, method three is optimal, because it needs the smallest data transmission time.



any offloading method decreased the memory usage in comparison to the memory usage of the local execution. the memory usage could be decreased by up to 45%. it is minimized by using method one. in general method one will be the best choice to minimize the total execution time and relieve the mobile device and therefore improve the user experience.



perhaps the measurements should be repeated with a more optimized version of the application and with more diverse image sets. we conclude that all described offloading methods for image stitching aim at finding a good tradeoff between local execution time and transmission time. it has turned out that sending all the computation to the resourceful and powerful remote server is the best choice in terms of the total execution time and that it even enables us to stitch high-resolution images without any optimisation of the program regarding the execution on mobile devices. however, the developed program for stitching images is not optimized yet. parallelization is not used, but possible at many stages of the stitching process. the features of the different, independent images could be found in parallel, to give an example. it is also possible to reduce the complexity of the image stitching algorithm by adding some preconditions, like the order of the images, as described by herbon et al.. the results received by the stitching process could be further improved by techniques like filtering, feathering or blending, to hide the transition



the offloading methods described in this paper are three good working, but basic ones. they are only a sneak preview of the possibilities mobile offloading can offer. the offloading methods can be extended in many ways and adding decision making, like choosing the offloading method dynamically according to network speed, number of images and image size, and local restart methods described in could lead to further improvements.



