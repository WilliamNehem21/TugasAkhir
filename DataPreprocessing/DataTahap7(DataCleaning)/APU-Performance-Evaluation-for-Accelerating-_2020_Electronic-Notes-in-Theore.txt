through the years, computer systems have advanced in integration, performance, functionality, and applications. a clear example of this evolution are cpus(central processing unit) which are the most widely used resource for computers. initially, cpus were conceived to process general purpose tasks but now incorporate application-specific circuitry for functions like video processing, acceleration of vector operations, multimedia decoding, and hardware acceleration for scientific applications. nonetheless, cpus show notorious performance limitations when processing big data sets or when the task at hand has a large number of computing operations.



computers. pixel color computation for an image can be performed in parallel(using rasterization) by several processors. this observation guided the design of the graphics processing unit or gpu: a circuit that incorporates a lot of minimalist processors highly optimized for the mathematical operations needed for this specific task. the performance gain obtained in computer graphics with gpus is massive, and, now, it is widely used in video games and multimedia applications.



due to the limitations of cpu performance in several tasks, a lot of research has been targeted toward the gpu architecture to utilize it as a general purpose processor. this research has improved the execution time of several computationally intensive workloads(e.g., artificial intelligence, blockchain, bioinformatics, etc.). thus, the gpu has positioned itself as the default architecture in a significant number of demanding workloads due to its parallel processing capabilities and high optimization for mathematical operations.



in 2011, with the introduction of novel specialized circuits in the cpu die, a new type of computer architecture known as apu(accelerated processing unit) was born. this setup has a cpu and a gpu that share system memory(ram) in the same integrated circuit, with a coherence mechanism between their memories and the possibility of efficiently sharing data structures. the apu design brings up the opportunity to create specialized algorithms that make use of these specific characteristics. nonetheless, point out that there is a lot of pending work in evaluating the performance of apus in tasks where gpu performance is not practical due to constraints like the pci-express bus transfer rate, inability of sharing data structures between the cpu and gpu or when the gpu is executing code with a high number of branches. also, the same authors mention that the design and evaluation of tightly coupled algorithms, that can take advantage of the specific characteristics of the apu architecture to improve performance, are opportunities to be explored.



section 2 shows the different efforts made to accelerate the ray tracing algorithm through approaches and the obtained results of this initiatives, while section 3 describes the design and details of our implementation of an acceleration mechanism for the apu. the experiments executed for this research, including the experiment design, the hardware used, and the analysis method for the data obtained are detailed in section 4. in turn, the results of these experiments are presented in section 5 and discussed in section 6. finally, section 7 summarizes all the conclusions of his paper and identifies avenues for future work.



just for ray tracing, it does not spend time in instruction fetch and instruction decode cycles like a typical cpu. on the other hand, this solution was just a prototype with limited functionality. besides, it was developed on an fpga due to the high cost of implementing the design on silicon by the time of the publication.



another approach of using pre-processed data structures as an acceleration mechanism is the bounding volume hierarchy(bvh). this method analyses each one of the elements in the scene and adds them to bounding boxes that progressively will be added inside bigger containers, creating a binary tree data structure. in this way, when a ray does not crosses a bounding box, all the objects in the sub-tree and in that container are discarded, saving a lot of processing time. a high-performance gain can be obtained through this acceleration mechanism as it avoids the unnecessary calculation of several ray/object intersections. that algorithm was initially conceived to run in cpus, and it was ported later to gpus by, however, a specific implementation for apus is yet to be found.



we focus on showing apus as viable architectures for improving the performance of computationally intensive workloads, in particular ray tracing. this is pertinent because apus are widely available and present in a lots of commodity hardware. we are not just looking for a porting of an algorithm from the cpu to the gpu nor the optimization of an existent algorithm. a novel ray tracing algorithm for the apu that presents an insight into how the specific characteristics of this architecture can be used to improve the performance of computationally intensive workloads was designed. for instance, we depend heavily on the ability to share in an efficient manner data structures between the integrated gpu and the cpu because the memory is shared by both processors, which avoids the communication bottleneck of the pci-express bus. the amount of memory can be expanded to the same memory available to the operating system. furthermore, the tasks



the very same ray tracing algorithm was developed for cpu(using c) and gpu(using opencl). even the data structures are the same. the implementations do not provide any optimization that favors any architecture. it is based on. the gpu development followed the recommendations pointed out by to improve the performance when processing a general workload. the code for the apu is exactly the same code as the cpu architecture for its internal cpu rendering, as well as the same code of the discrete gpu for its internal gpu. thus, any optimization to these components, would be present in all the affected actors.



loads as the unit to be given to a processor to render. for each available cpu core in the system, a thread that checks if there is any available workload pending is spawned. if this is the case, the thread executes the workload, saves its result to memory and looks for the next workload. each thread finishes if there is no more pending work. since each of the work assignments to the gpu component of the apu implies an overhead, there should be at least enough work to maximize the gpu resources utilization, i.e., all its processing units should have enough workload. amd documentation recommends experimenting with different workload sizes to achieve optimal performance. as a rule of thumb, we found that if there are



factorial analysis of variance(anova) experiments are designed to evaluate efficiently the effects that different factors under research might have on a response variable. this methodology was chosen due to its capacity to evaluate the performance of the ray tracing algorithm across the apu, cpu and gpu architecture and several other factors that directly impact rendering time. for practicality, the evaluation of the effects(anti-aliasing, reflections, transparencies) uses a 2k form, which significantly reduced the number of executed experiments while preserving the influence of those effects in rendering time.



image resolution: image quality is dependent on the level of detail that it can contain. a pixel is the smallest possible detail that is present in a digital picture, so it is directly related to the quality. this means that more pixels in an image(more resolution), the better quality it has. three common computer resolutions were selected for the experiment:



the basic scene used for the experiments is constituted by the quantity and position of the objects. from there, the factors of resolution, effects, and architecture were adjusted to fit a specific combination. a complex ray-traced image has several objects distributed across all the scene. this criterion was used to randomly distribute the objects in the x and y axis of the projection frame and the z axis of the scene. different object sizes and shapes were used to simulate the unpredictability of the elements contained in a typical ray-traced scene.



we presented an alternative low-cost architecture for accelerating computationally intensive workloads. our design utilizes all available computing resources in the apu(integrated gpu and cpu) to process a computationally intensive task, in this specific case, ray tracing. our approach takes advantage of the particular characteristics of the apu architecture, for instance, its ability to share data structures from ram and the ability to efficiently coordinate work within its internal processors.



should be studied to measure whether the apu keeps its performance and costefficiency advantage in those tasks. as the apu uses the same code as their cpu and gpu counterparts, it would be interesting to explore the effects of extensive optimization of the rendering code in the three architectures. also, an in-depth exploration of the pci-express and memory transfers in the discrete gpu solution could provide an interesting insight into ways to obtain more performance from the apu. finally, as there are several techniques to minimize the fp32 rounding error, the experiments could be run focusing on fp32 operations.



