abstract the ability to control data and information through the internet can be challenging. preliminary analysis showed that some tampering and forgery may occur to some words of the quran in the electronic versions that span the internet. such small modifications may not be noticed by public audience. the holy book of quran includes a unique feature in that its worldwide copies are all identical. the 114 chapters(suras) and all their verses and words are preserved in the exact form. as such, we designed and evaluated a model and a tool to evaluate the integrity of the wording in the e-versions of the quran through generating a meta data related to all words in the quran preserving the counts and locations. such meta data can be used in the same way hash algorithms are used in security to check the integrity of a disk and its data files where any small change in the data will result in a different hash value. we conducted several experiments to evaluate the different parameters and challenges that can impact the automatic authentication process of quranic verses based on information retrieval and hashing algorithms.



is no control on the type, nature or details of information uploaded to the web by any user. accordingly, credibility and accuracy are the foremost concerns when reading information from the web. credibility can be linked to the website, hosting the information, author of uploaded data and the type of data or information itself. for example, in social networks or even news websites the same story can be told in exactly opposite versions given by two different websites or authors.



and digital signatures. document control is related to permissions before and after publishing the document online. document control then is needed to be dynamically applied in a manner that document can be tracked even after publishing it online. integrity is about making sure that the document is not altered by any unauthorized person and hence is authenticated. in digital signatures, signed documents should be verified by the people who signed it(i.e. non-repudiation).



nowadays, many multilingual copies of the holy quran are available online. the holy quran is originally written in arabic language. the exact wording and statements in quran verses are identical for all arabic versions of the quran.1 however, one problem with translation is that it may change, intentionally or unintentionally the meaning of some verses when translated to another language. this is a general problem when dealing with translation. on the other hand, for the same language, it is possible that the same verse be written in different words due to intentional fraud or due to language translation issues.



the identity and integrity of the data must be periodically and systematically verified through mechanisms such as secure hash standard(shs) and secure hash algorithm(sha). quran verses can be considered plagiarized or unauthenticated even for one letter change. hence, hash algorithms are good option as such algorithms are very sensitive even for a very small change in data or documents.



it should be mentioned that in this research we are not focusing on encryption but rather integrity checking. the problem is that in our scenario for quranic documents online, the relation between information providers and readers is not a typical e-commerce one-to-one relation in which typical hash or encryption algorithms can be sent to the known receiver or customer. accordingly, private keys intended for a particular receiver will not be applicable in our scenario where the tool is expected to check quickly through the internet that quranic documents are authentic and do not contain tampering.



the rest of the paper is organized as follows: section 2 discusses the related work to this research field followed by a discussion of the adopted methodology in section 3. section 4 discusses the developed authentication system, while the experiments are presented and discussed in section 5. section 6 presents the conclusion and future work.



papers that tried to detect diacritics proposed morphological rules to do that. known patterns and an initial training set are used to match subject word for one of the morphological rules. hidden markov model(hmm) is used where the hidden states are the possible diacritized selections of the words. in arabic text, diacritic marks can be challenging whether they exist or not in the arabic text. if they exist, the challenge will be to read or parse them correctly especially as they need extra resources in addition to typical letters parsing in all other languages. on the other hand, diacritic marks are necessary to arabic words to clarify words and statements from ambiguity.



sbbah and selamat have developed a framework for quranic verses authenticity detection in online forum. they used a numerical approach to detect quran quotes. the numerical approach calculates the diacritical ratio(dr) of each word in the text. their authentication system depends on defining the weights of quranic letters and diacritics and calculate the identifiers of distinctive quranic words.



the details of developing the authentication system are discussed in more detail in section 4. the goal of this research is to design a search engine or authentication system that is able to retrieve results based on a search query. a customized quran search engine or information retrieval system should focus on parsing and indexing quran verses from all over the web. for proposed program search user interface and queries will then represent verses or part of verses.



we have conducted an experiment to evaluate the top websites that are used to search for quranic verses. this is based on the popular search engine google. we built a customized crawler to search through google for quran verses one by one from the first to the last verse. for each verse, we collected information related to the approximate number of index pages in google for the verse. this represents the approximate number for web or internet links that include the queried verse. the developed crawler uses quran verses as search queries. results are retrieved from embedded information in search web pages. meta data related to the retrieved web pages are collected and saved in a dataset. google ranks retrieved results based on its popularity page rank algorithm.



in order to deal with the verses having harakat and tashkeel, we have considered two versions of the quran: one that considers harakat or tashkeel and one that does not. quran indexed in the web can be with or without tashkeel. in many cases, search engines and their queries can be sensitive to these symbols that are unique in arabic language; hence a search for verse that does not include tashkeel in the query may not retrieve results for verses that include tashkeel symbols.



1, sha-256, sha-384, sha-512, tiger, and whirlpool gave different values for the verses with and without tashkeels. we repeated the process several times and noticed that all hashing algorithms for all evaluated verses show different hash values comparing with and without harakat or tashkeel. we noticed however, that different implementations for the same hashing algorithm may give different hash values for the same text. as such, the system should use the same algorithm implementation for initial and consecutive authentications or verifications. this is what we have done in developing the authentication system where we used the md5 hashing algorithm for hashing purposes.



this simple experiment showed that if we want to check correctness or authenticity of verses with tashkeel and exact form, hashing algorithms can be used. however, if we want to stem those parts, hashing algorithms will not be then effective unless those additions are stemmed from all verses. in the second experiment and in order to check whether same hash functions can produce same hash codes, we tried different implementations for the same hashing algorithm and check hash values for several verses. we believe that verse should be the standard unit to measure with. sizes of smaller or larger than a verse can have several issues and challenges specially related to false alarms.



this experiment shows that not all hashing functions are identical or should always produce same hash values for same text. nonetheless, this is not due to reliability issue with hashing algorithms. rather, it has to do with the detail implementation of the hashing algorithm. hashing values for the same algorithm implementation for the same text should always produce same hash values.





hash values are randomly generated. hence one difference may result in a completely different hash. hence the idea is not to see how much the text is far from the actual text. the idea is to come up with a boolean decision: version is identical relative to the original authenticated copy or not.



while we only conducted the current experiments on quran verses, we believe that same process and tasks can be applied to evaluate hadeeths as well. the case of quranic verses can be considered easier as quranic verses are literally identical even in the different quran readings(with some few and minor exceptions). however, for the case of hadeeths, some hadeeths are mentioned in different wordings where this needs to be considered in the authentication evaluation process.



