main-memory database(mmdb) is a database management system that primarily relies on main-memory for computer data storage. it is contrasted with database management systems which employ a disk storage mechanism. main-memory databases are faster than disk-based databases since the internal optimization algorithms are simpler and execute fewer cpu instructions. accessing data in memory eliminates seek



recent evolution in main-memory sizes has prompted huge increases in the prevalence of database systems that keep the entire database in memory. nonetheless, main-memory is still a scarce resource and expensive compared to disk. a major goal of recent research works is to improve main-memory storage optimization. the more free memory the larger systems to be stored in the database, which improves the performance and the cost efficiency. the objective is to separate the data into active(hot) and inactive(cold) data. the hot data will remain in main-memory and the cold ones will be moved to a cheaper cold store. the main difference in the existing techniques is the level of granularity in which the data is accessed and classified as hot or cold; which in some databases is at the tuple-level and in others at page-level.



the remaining of this paper is organized as follow. section 2 surveys the recent related work. section 3 introduces the proposed hybrid filtering approach. section 4 presents a detailed case study to illustrate the workflow of the proposed approach. section 5 reports the experimental evaluation of the proposed approach. finally, section 6 concludes the paper.



recent development in hardware has led to rapidly dropping market prices of main-memory in the past years. this development made it economically feasible to use the main-memory as the primary data store of dbms, which is the main characteristic of a main-memory dbms. recent research works focus on main-memory dbms storage.



stores the primary copy of the data on disk, and then uses the concept of hybrid filtering in its approach. however, it applies hf and vf on disk, and then moves these hot data into in-memory columnar store. in contrast, we apply hybrid filtering approach on data resident in main-memory. hyper[16,17] perform cold/hot data classification at the vm page level, which is different from our scope. it is proved by that it is best to make the classification at the same level of granularity that the data is accessed, which is at the



our novel hybrid filtering approach(hfa) is based on a row store main-memory database. our primary copy of data is entirely stored in main-memory. first, hfa horizontally filters the data by hot tuples. then, it vertically filters the data by hot columns.



the offline phase is composed of three modules. periodically, we run the offline analysis to define the hot and cold attributes in the log files and update the hot/cold attributes list. the duration is predefined by the system administration according to one of two factors either by time(i.e. number of months) or by database workload(i.e. number of queries).



