for two-stage detectors, domain adaptation approaches are mainly based on adversarial discriminative methods. they are often designed to align features at several levels, and have been improved in various manners. for example, imageand instance-level alignments have been used in ref.. however, it is difficult to assume such an approach in one-stage detectors, predicting bounding boxes and object classes concurrently.



transfer(dt) based on adversarial generative methods in a weakly supervised cross-domain setting. with dt, images with instance-level annotations are transferred from the source domain to the target domain. under an unsupervised setting, the authors of proposed weak self-training(wst) based on self-supervision-based methods. wst enables the training of unlabeled images, by reducing the negative effects of inaccurate pseudo-labels. however, the performances of these domain adaptation methods for one-stage detectors are insufficient compared with those for two-stage detectors.



among the four categories of domain adaptation, adversarial generative and self-supervision-based methods can be easily applied to onestage detectors. moreover, these two methods have different advantages. an adversarial generative method can access accurate source labels; meanwhile, a self-supervision-based method can use the original target images. to take advantage of both methods, we propose an unsupervised domain adaptation method that combines an adversarial generative method with a self-supervision-based method. for each method, we use dt and wst, which have been shown to be effective for one-stage detectors[16,19]. we show that the two components complement each other, thereby improving the detection performance.



the development of deep convolutional neural networks(cnn) has improved the performance of object detection. two-stage detectors(such as r-cnn, fast r-cnn, and faster r-cnn) extract region proposals, and then, classify them. one of the advantages of the two-stage detectors is that the classifier can be customized to suit a specific task. in contrast, one-stage detectors, such as you only look once(yolo) and single shot multibox detector(ssd), achieve significant improvements in the inference speed using a single-stage network. furthermore, recent studies[6,7] have improved both the accuracy and inference speed.



in this study, we tested our method on an ssd, which is a representative one-stage detector. ssd has a simple architecture, and is well balanced in terms of inference speed and performance. furthermore, because ssd has been used in related studies[16,19], we can make a fair comparison.



xs, and the target data{(xi; yi)}nt are drawn from the target domain xt, where ns. nt is the number of source and target samples, respectively. we denote the distribution of domain x as p(x) and p(xs)/= p(xt). therefore, the source and target data have different distributions, as shown in dataset, and has the same classes as pascal voc. it provides 500 images for the training set and another 500 images for the test set. watercolor2k and comic2k are unrealistic datasets, and have six classes in pascal voc. each dataset provided 1000 images for the training set and 1000 images for the test set. we trained a model without using the labels of the target images, because we tackled unsupervised domain adaptation.



dt performance: we found that dt is ineffective for watercolor2k as compared to clipart1k and comic2k. although the fid between the domain-adapted and target images did not differ significantly among the datasets, the distance difference on watercolor2k was the smallest, which led to dt's poor performance. in contrast, dt performs better for clipart1k and comic2k, where the distance differences are larger. thus, the effectiveness of the adversarial generative method depends on the target dataset.



in this study, we the addressed unsupervised domain adaptation for one-stage detectors. to take advantage of both the adversarial generative method and self-supervision-based method, we introduced a generative and self-supervised domain adaptation method. specifically, we proposed a learning strategy for ssds by applying dt and wst.



