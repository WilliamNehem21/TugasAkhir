code injection is one of the top cyber security attack vectors in the modern world. to overcome the limitations of conventional signature-based detection techniques, and to complement them when appropriate, multiple machine learning approaches have been proposed. while analysing these approaches, the surveys focus predominantly on the general intrusion detection, which can be further applied to specific vulnerabilities. in addition, among the machine learning steps, data preprocessing, being highly critical in the data analysis process, appears to be the least researched in the context of network intrusion detection, namely in code injection. the goal of this survey is to fill in the gap through analysing and classifying the existing machine learning techniques applied to the code injection attack detection, with special attention to deep learning. our analysis reveals that the way the input data is preprocessed considerably impacts the performance and attack detection rate. the proposed full preprocessing cycle demonstrates how various machine-learning-based approaches for detection of code injection attacks take advantage of different input data preprocessing techniques. the most used machine learning methods and preprocessing stages have been also identified.



code injection is the most popular and most impactful attack, which is at the top of the owasp vulnerabilities list. the detection of code injection attacks, traditionally carried out using signature/pattern-based recognition techniques, has been recently supplemented by the application of advanced machine learning approaches. the advantage of such techniques is that similar algorithms, e.g., deep or convolutional neural networks, may find application in a broad range of various threat detection scenarios. indeed, big cyber security companies are investing significant funds into the research and deployment of machine learning algorithms for the cyberthreat detection purposes, including malware analysis, vulnerable code detection, and intrusion detection(i.e. vulnerability exploitation attempts). ai-enhanced security adoption is growing rapidly,1 and a range of machine learning methods for intrusion detection has already accumulated over the years.



cyber security(specifically, network intrusion detection) have been analysed, out of which only 20 covered preprocessing for code injection detection in sufficient details(see section 4.4). further revision revealed a wide variety of diverse preprocessing methods, that as well will be documented later on in the survey.



preprocessing, a highly critical step in the data analysis process, shapes data for the neural network to be trained, forming a structured multi-dimensional dataset. preprocessing may increase or reduce the accuracy of the applied method based on a multitude of factors, discussed later in the survey. for example, duplicates can make the neural model biased.



the last step in the machine learning process is to read the output data, evaluate and present it in a way that can be further used by other systems or visually represented for human understanding. e.g., improper selection of a testing dataset can affect the metrics of the output performance.



exchangeable image file format(exif) data contains information about the file: e.g., file source, creation and modification dates, gps coordinates, camera model, time, compression type, etc. in the vast majority of cases, this data is present in every image or photo.



injection attack types and their detection approaches, methods and tools, including the pre-deployment detection of vulnerable code in web applications. in 2019, mitropoulos et al. published a survey, reviewing methods of the web application attack detection, which included a class of hybrid approaches, some of which were based on machine learning(e.g., amnesia).



in their survey alwan and younis list and classify the approaches and methods of the sqlia detection. the authors claim that none of the enumerated tools addresses the issues of the more recent types of sqlia, e.g., fast flux sqlia. in the advanced cases of non-typical injections, the data preprocessing can assist in successful detection.



valeur et al. proposed a method to identify queries that did not match multiple models of typical queries at runtime. as this was one of the early methods, it did not reach accuracy as high as modern approaches do, however the method has shown the potential of deep learning in malicious query detection.



the above list shows that there is a variety of machine learning methods applied to the code injection detection. the majority of the methods are supervised, with a half of them being deep learning methods, such as cnns. the deep learning methods demonstrate themselves as more versatile, allowing to analyse 2d, 3d or 4d data using convolution(cnn), or lstm, as they keep memory of the previous items from the dataset or network sessions. detecting time-spread malicious behaviour can trigger intrusion prevention mechanisms and improve overall security of the application.



support vector machines(svms) are supervised learning models with the associated learning algorithms that analyse the data used for classification and regression analysis. for the code injection detection, svms were applied by dussel et al. and dong et al.(y.



as per, reinforcement learning is the learning of a mapping from the input situations(events) to the output actions so as to maximise a measurable reward or the reinforcement signal. in practice, it is a reward-based system, that works as a semi-supervised approach to learning. the machine-learning-based system learns from the environment and gets rewarded for correct predictions, and penalised for incorrect predictions.



to the extent of our knowledge, there have not yet been any applications of the reinforcement learning to the code injection detection, as its successful applications to intrusion detection have started only recently. in 2020, lopez-martin et al. presented a survey on the application of reinforcement learning to the issues of network intrusion detection in general. they state that for the code injection detection, reinforcement has to be limited to only one numeric reinforcement value, i.e. successful detection.



a variety of automated tools can be used for data collection. for example, for he event collection cova et al. use modified zend engine. aceto et al. collected data from a mobile service provider and from various applications on android devices, which resulted in a binary dataset that was published by yao et al.. after collection or generation is complete, the raw data has to be preprocessed and then features must be extracted to transform any type of data into a numerical form that can be analysed during future stages.



in the context of code injection attacks, collection of benign and malicious queries can yield a limited number of samples, that is insufficient for the effective model training. generation of new datasets from the existing data can resolve this challenge. a trend in the recent years shows the use of generative adversarial networks(gan), however, there are multiple ways to successfully generate new samples from the existing ones.



adversarial inputs created by introducing permutations of patterns from the already existing datasets can easily subvert their predictions. the 2017 report by biggio et al. highlights common misconceptions related to the evaluation of machine learning methods and approaches for security applications.



cheon et al. develop their own way of generating samples based on the existing query templates, by randomising numbers, usernames, passwords, email addresses, etc. edalat et al. outline the dataset generation approach to multiply the number of malicious samples using concolic input generation.



there also exist the non-machine learning based methods that include fuzzing for the attack generation and testing of the experimental system. they can also be used to create a dataset, that is usually stored in text files or database files. one of the most popular tools in fuzzing sql databases is sqlmap,11 presented by damele and stampar. sqlmap is now a part of the majority of the existing security testing toolkits and operating systems. this non-machine learning toolkit can be used for the attack generation to test prototype systems against real life attacks. cheon et al. use sqlmap for the evaluation of their method. edalat et al., while also researching the sql injection detection, instead of machine learning methods, use taint analysis for the evaluation of their considroid.



the automatic scripts, toolsets, and virtual networks can be used for the attack sample generation. tools like tcpreplay can be used to emulate the traffic activity from an already existing*.pcap file. taken a step further, to generate a cicids2017 dataset,12 the university of brunswick used a virtual machine with kali linux as an attack station. the network traffic was recorded during several days of simulations on a virtual network. after that, the ip addresses were removed from the dataset(csv file), anonymizing the data. the newer versions of 2018 and 2020 are also available.



using the adversarial approach, it is possible to create additional permutations and multiply the dataset, increasing the number of samples and improving the detective capabilities of the ids. however, in real-life attacks, the malicious actors can use sophisticated techniques to avoid simple ids. to be able to detect more sophisticated malicious queries, generative adversarial approach can be used to increase the complexity of code samples, both malicious and non-malicious.



parameter fine-tuning is an important step in machine learning. it can be defined as the adjustment of parameters of the model for optimal performance. a parameter or a hyperparameter is a value that impacts the learning process. every machine learning method has a set of such(sometimes unique) parameters. for example, artificial neural networks(ann) have different layers of different types, number of neurons, activation functions for each layer, optimisers, loss function for the output layer, batch size, and number of epochs. tuning hyperparameters aims to improve the speed of and overcome the limitations of small datasets.



preprocessing is the process of data transformation and its conversion into another form, that aids the neural network with the learning process. it changes the initial data in such a way that it allows the machine learning algorithms to analyse the data. preprocessing can include any process that involves data manipulation before the correlation process(using machine learning or any other algorithm), and taskspecific, as the architecture of the neural networks can be tailored for detection(of any type), classification(detection and attack identification), or clustering. for example, it can include data cleaning and refinement(filtering, reducing, reshaping, encoding, etc), handling missing attributes, imbalanced dataset and elimination of noise or



the revision of the selected academic publications revealed a wide variety of diverse preprocessing methods, that need to be summarized and classified for effective use in intrusion detection. the way in which the input data is pre-processed(cleaned, reduced, reshaped, encoded, etc.) significantly influences and affects the performance of the machine learning techniques employed to detect code injection attacks. for example, some of the features in the data set may be random in nature and corrupt the output results, or, similarly, may be more impactful and introduce biases.



it is worth noting that pretreatment does not involve any transformation of the data values. in specific cases some steps of pretreatment might be repeated after the feature-based and encoding-based preprocessing as well. for example, in the cases when the data cleaning(pretreatment), and its further encoding(preprocessing), produce duplicates, those have to be removed again(pretreatment).



dong et al.(y. mention data normalisation, that may reduce the number of samples, by techniques, such as decoding the ascii characters, transforming to lowercase, un-escaping, removing queries whose length is less than four symbols, etc. after such normalisation, the initially different queries may become identical, as the distinguishing items were removed. however, transformation like this might be irreversible. for example, valeur et al. replace certain values in the query white spaces. when queries with different values but similar structures are pretreated using this method, they become similar or even duplicates. with an approach like this it may be impossible to backtrack the event record and identify the origin or condition of the attack.



deep learning is considered to be the most advanced technique and effective against the sophisticated attacks and constantly evolving attack vectors. one of the earliest attempts to specifically detect code injection attacks(specifically sql injections) using deep learning was amnesia, a method developed in 2005 by halfond and orso. the entire preprocessing was similar to the one used by gould et al., except the use of ndfas in amnesia instead of dfas.



dataset by mapping the ip address. the mapped ip includes the source ip address(src ip) as well as the destination ip address(dst ip). as ip addresses cannot be processed by any classifier without pretreatment, they are converted either to a decimal format, or to assigned relevant id numbers.



as an example of a successful data preprocessing, dong et al.(y. use the logs(6.11 gb) where during pretreatment, that included cleaning, normalisation, and filtering, the data effectively reduced in volume by 4 times while ensuring its high quality. another example of a complete data preprocessing is the above-mentioned cicids 2017 dataset, which is reduced from 50 gb of pcap files to less than 1 gb csv file with all the features describing bidirectional traffic flow.



dussel et al. introduced a payload-based anomaly detection method through adding structural information from a protocol analyser, with the detection of sql and php code injection attacks. the goal of that particular research was to analyse the network traffic based on the grammatical characteristics of an underlying protocol.



computation complexity without affecting the prediction accuracy in the classification process. in their work, the chi-squared scored function is used to rank the top 5000 hashing features in descending order to return the most appropriate labels to improve the sqlia prediction accuracy. yan et al. extract all javascript code written by developers(javascript libraries like jquery are excluded) in the application to



it is worth mentioning beyond the scope of our research, that before the pretreatment stage the collected data has to go through a quality check and proofing. ehrlinger et al. identified 667 tools to evaluate the data quality and composed a review of ways to measure data quality, clean it, and monitor.



shuffling the dataset in an uneven manner would result in a biased statistics, similar to the bias in an unbalanced dataset training. furthermore, splitting dataset 50/50 as compared to 80/20 in an unbalanced way may increase that bias. for example, if the training dataset contains only non-malicious samples, the model will not be able to detect malicious samples during the testing phase.



tomar et al. use feature selection for dimensionality reduction using two methods: feature ranking and feature subset selection. they propose feature selection using four different approachesfilter method, wrapper method, embedded method, and hybrid method, while also presenting comparative characteristics of these four methods.



yan et al. presented a hybrid deep learning network(hdln), a more efficient model, based on the approach by xiao et al.(x. in addition to the already existing features in the dataset, xiao et al. suggest to extracts the new features from the abstract syntax tree of javascript in hybrid applications through the feature space generation and feature selection.



the feature selection process can be manual or automated. manually they can be selected via trial and error, while automatically, the features can be selected using recursive feature elimination, lassocv, etc. in 2019, proposed a deep learning approach as a viable strategy to design a mobile traffic classifiers based on automatically-extracted features, able to cope with the encrypted traffic, and reflecting their complex traffic patterns. for example:



with the features already extracted and dimensionally reduced(e.g., using principle component analysis, kmeans clustering, etc.), a smaller neural network can be used, to analyse the patterns faster, without the need to detect any new features. for example, use the principal component analysis(pca) as a form of preprocessing for support vector machines(svm). with a smaller dataset, the bigger neural networks will not train as effectively due to insufficient samples. the cicids2017 dataset contains sessions described in 78 features, however, pca can reduce the number of values down to 10(principal components) without a feasible loss in accuracy. gao et al. use pca for the experiments with nsl-kdd.



conversion of values like ip addresses can be another cornerstone. the intuitive conversion of ipv4 into a decimal value, and further division by 10 power 10, would not work as intended. for example, 192.168.1.1 would be into 3232235777, and 192.167.1.1 into 3232170241. once scaled between 0 and 1, those two decimal values are very close to each other, even though they represent different subnetworks, and the neural network may not be able to notice any difference.



the research by uwagbole et al. uses a combination of data composed of the extracted dictionary wordlist with words and unique sql tokens extracted from the mssql reserved keywords. the dataset items are labelled based on the exhibition of the sqlia types characteristics which are: the presence of the sql tokens in the injection point, disjointed text, single quotes, semicolons, comments, hex, etc. the data set items labelling is represented in the binary values of 0(sql negative) or 1(sql negative).



there is a variety of methods on the network data visualisation, that can be used to generate static images, and then further use various automated tools(e.g., imgaug22, autoaugment, k-correct) and image augmentation techniques presented in the surveys by shorten and khoshgoftaar and mikolajckzyk and grochowski to further improve the detection rates.



translation of natural language into commands, images, lines of code, and samples for the dataset has been researched since the early days of programming languages. to illustrate the mechanism in the context of the survey, we have studied the sql query as an example. the approach of the natural language translation into sql queries can be potentially abused by attackers to bypass filtering.



ing. liang et al. used masking for symbolic parsing by storing key-variable pairs in the memory. masking presented by cai et al. supports more complex operations, covering both short-term and long-term dependencies. moreover, the authors emphasize that the grammar structure of sql is known to be more complicated than the logical forms used in semantic parsing.



it is our understanding that to ensure maximum efficiency the full preprocessing cycle should be respected. this cycle is suggested based on our previous research in the respective area. to maximise the performance efficiency of machine learning for the code injection detection, we propose six stages of pretreatment, three stages of feature-based preprocessing, and three stages of encoding-based preprocessing. this approach, however, can be also applied to all other cyber security methods in general. revealing the present inconsistencies and to harmonise the preprocessing methodology, we map the existing approaches against our proposed classification to identify the gaps.



as per the assessment, feature-based preprocessing is the most represented stage. feature extraction is mentioned in 100% of the analysed works, while shuffling of the dataset is the least mentioned substage. cleaning, unification, and encoding transformation are mentioned in 85% of the methods, followed closely by feature engineering in 80%. the remaining stages and substages are mentioned in less than a half of the analysed publications.



based on the selected academic publications, the survey explored the existing approaches to the applications of machine learning for the detection of code injection attacks, with special attention to deep learning. we identified at least 13 different methods of code injection detection using various types of machine learning. deep learning is observed being the most used approach.



the stages of machine learning for intrusion detection have been further revised and least researched have been identified. the findings confirm that the scarcity of the datasets remains one of the biggest and most common challenges for the adoption of machine learning in cyber security. the findings also revealed that data preprocessing being one of the most critical stages in machine learning, lacks consistency in the approaches in the context of code injection attack detection.



the suggested classification of a full preprocessing cycle for the code injection detection will result in the harmonisation of the approaches to this stage and will improve the accuracy and performance of the machine-learning-based intrusion detection systems. the proposed consecutive stages of data preprocessing can be further used by machine learning researchers and practitioners for other cyber security needs, such as network traffic analysis and intrusion detection. and finally, the presented classification will allow to better understand the role of deep learning in the code injection attack detection process in machinelearning-based intrusion detection systems.





