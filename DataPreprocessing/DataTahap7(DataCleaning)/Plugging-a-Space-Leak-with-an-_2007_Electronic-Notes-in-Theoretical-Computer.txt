the implementation of conceptually continuous signals in functional reactive programming(frp) is studied in detail. we show that recursive signals in standard implementations using streams and continuations lead to potentially serious time and space leaks under conventional call-by-need evaluation. however, by moving to the level of signal functions, and structuring the design around arrows, this class of time and space leaks can be avoided. we further show that the use of optimal reduction can also avoid the problem, at the expense of a much more complex evaluator.



in this paper we focus on the continuous nature of frp, and ignore its reactive component. since the continuous nature of frp is only an ideal, it must be approximated in a real implementation. the original implementations of frp used time-ordered streams of values for this approximation[9,10].



in the remainder of this paper we first describe two standard non-arrowbased implementations of frp, and show that they are both susceptible to serious space leaks. we then describe arrows in section 3, and use them to design a new implementation of frp in section 4 that is similar to that of yampa. we show in section 5 that this new implementation does not suffer from the same space leak problem as the standard implementation. in section 6 we discuss some alternative approaches to solving the space leak problem. we assume familiarity with haskell and basic functional programming concepts.



our intuition tells us that unfolding e should be linear in time and constant in space. yet in reality, the time complexity of computing the nth value of e is o(n2) and the space complexity is o(n). thus evaluating successive values of e will soon blow up in any standard haskell compiler, eating up memory and taking successively longer and longer to compute each value.(the same problem arises if we use integrals instead of integralc.)



note that the data structures sf and c are similar: both are continuation based, and both consist of a value and a function. both e and esf are the fixed point of some higher-order function since the integral functions are already recursively defined. having to compute the fixed point of recursively defined higher-order functions, and the inability of the standard call-by-need evaluation to properly detect emerging vertical sharing, are the reasons for the time and space leak in the first two frp implementations.



trying to generalize this kind of clever transformation as rewrite rules, however, is difficult. the reason it works for frp is that the structure of such recursively defined signals all share a common characteristic, namely that their future values retain the same kind of structure. but this is not necessarily the case in general.



on the other hand, being optimal does not necessarily imply being the most efficient. the extra book-keeping of sharing analysis during optimal evaluation incurs a large operational overhead of both time and space. compared to the relatively well-developed call-by-need compilation techniques, optimal evaluation is far less explored, and no truly practical implementations yet exist.



we have described two standard(albeit simplified) implementations of continuous signals in frp, one based on streams, the other on continuations. unfortunately, recursive signals expressed using both of these implementations have serious space and time leaks when using conventional call-by-need evaluation. the source of the problem is the failure to recognize sharing that arises inside of a recursive lambda expression.



this research was supported in part by a subcontract from galois connections under darpa sttr contract 06st1-0016, and by yale university under a kempner fund fellowship. thanks also to the ifip wg2.8 working group on functional programming(especially simon peyton jones) for comments received during a preliminary presentation of the research.



