xia, pan, and qin(2014) proposed face clustering in a photo album, where the method explores spectral features, similarity features, minimum cost flow and clustering. the proposed features are extracted from cropped face images. the main objective of the method is to find images which share the same faces. this idea is good for grouping personal collections but not family and nonfamily image classification.



qin, tan, and chen(2015) proposed tri-subject kinship verification for understanding the core of a family. the method proposes a degree of similarity between children and parents, resulting in a triangular relationship. to achieve this, the method uses a relative symmetric bilinear model for estimating similarity. to improve the results, the method takes spatial information into account. this method is good as long as the recognition approach provides successful results; however, recognition-based methods may not be



robinson et al.(2018) proposed visual kinship recognition of families in the wild. this method explores deep learning for face verification, clustering and boosted baseline scores. the method involves multimodal labeling to optimize the annotation process. this includes information of faces and metadata collected from family photos. it is noted that although the method explores recent powerful deep learning approaches for kinship identification, it is still limited to family photos but not non-family photos.



wang et al.(2015, 2017) proposed leveraging geometry and appearance cues for recognizing family photos. the methods identify facial points for each face in an image. based on facial points, the method constructs polygons to study geometric features of faces in the image. due to the height difference of persons and the arrangement of faces in family and non-family images, the method gets different polygons to study geometric features. it estimates pairwise relationships like kinship recognition, and generates a codebook using k-means clustering. furthermore, the degree of similarity of each group is extracted for classifying family and non-family photos with the help of an svm classifier. however, classification may not be accurate when the heights of persons in an image do not follow a hierarchical arrangement. in addition, one might expect that non-family members could have the same arrangements and heights.



in light of the above discussions, we can assert that a few methods have addressed family and non-family photo classification or identification, but most of the methods focus on kinship recognition based on face detection and recognition. these methods may not work well for images where we can see faces with multiple emotions, postures and actions. the methods which addressed family and non-family classification explore only foreground information(facial information) for achieving their results. this is good for images with simple backgrounds but not images that have complex backgrounds, where we can expect open scenes and outdoor environments in the case of non-family photos. therefore, we can conclude that there is a critical need for an accurate method to classify family and non-family photos.



images. the combination of spatial information, angles that extract the geometric structure of faces, and fractional entropy that extracts the texture of facial and background regions, produces a feature vector. furthermore, the feature vector is passed to a convolutional neural network(cnn) to overcome the above-mentioned challenges.



the contributions of this work are two-fold.(1) exploring spatial and angle features for extracting the spatial and directional coherence through the geometric structure of face regions.(2) introducing fractional entropy for extracting the texture of facial and background regions, which extracts regular patterns in the images.



the proposed method computes the mean of distances to extract spatial features and the mean of angles for extracting angle features for each image. the reason for computing the average is to widen the difference between family and non-family images. as discussed in the introduction section, family images have persons with almost the same facial appearance, while non-family images have persons with different facial appearances. this is valid because one can expect a high degree of similarity between the appearances of faces from the same family. it may not be true for non-family images. in addition, family and non-family images can have any number of faces, which should be more than 3 persons in the images. in this situation, the average features for a family does not make much difference, while for non-family, the average makes a vast difference. since the appearance of faces in a family have a high degree of similarity compared to those in non-family images, it is expected that the average gives almost the same values for family images while for non-family, we cannot predict the same values always. besides, to make the spatial and angle features invariant to the number of faces, the proposed method considers the average for achieving better results.



as mentioned in the introduction section, it is found that the other than face region also provides cues for discriminating family and non-family images. however, the previous step does not explore other than face region. therefore, inspired by the method in ibrahim, moghaddasi, hamid, and noor(2015) where fractional calculus has been used for studying texture in splicing images, this section explores a new tsallis fractional entropy-based texture for studying variations in background as well as facial regions in family and non-family images. an overview of the tsallis fractional entropy is presented in the following.



a large number of samples for training and labeling samples, we prefer to use the combination of the proposed features and the cnns rather than raw pixels with the recent deep learning models. the main objective of the proposed work is to propose features that can classify the family and non-family photos. thus, the proposed features are fed to a pre-defined cnn classifier which is available online(arora& suman, 2012) for classification in this work. for learning parameters of the classifier, we follow a 10-fold cross-validation procedure, which splits the dataset into training and testing components. the training samples are used for learning and adjusting the parameters of the classifier and the testing samples are used for evaluation. the complete algorithmic steps of the proposed method for classifying family and non-family images are presented below.



the concatenated features are then passed to a fully connected convolutional neural network(cnn) for classifying family and non-family images. inspired by the method(nanni, chidoni,& brahnam, 2018), where it is mentioned that the combination of handcrafted features and the ensemble of cnns give better results than deep learning tools such as googlenet, resnet50 that use raw pixels of the input images for bioimage classification, we explore the same idea of combining the proposed features with the cnn for family and non-family image classification in this work. since the proposed work does not provide instructions suggested in gallagher et al.(2009), wang et al.(2017, 2015). furthermore, the dataset includes one photo for one family. in other words, the dataset does not have multiple photos of the same family. in total, our dataset consists of 388 family images and 382 non-family images, which gives a total of 770 images.



to show that the proposed method is superior in comparison to existing methods, we implemented two state-of-the-art methods, namely, wang et al.(2015), which explores facial geometric features and facial appearance model-based features. the features are passed to an svm classifier for family and non-family image classification. please note, the same idea is extended and the results are improved in wang et al.(2017) for the purpose of family and non-family image classification. however, both the ideas focused only on facial regions for achieving results; these also ignored background clues.



382 for non-family images of our dataset. this is the advantage of the benchmark dataset for achieving the best results compared to ours. this is because when we feed a large number of training samples to the classifier, it covers more possible variations in images. therefore, a large number of training samples and more variations led to achieving the best results for the benchmark dataset by the proposed method compared to our dataset.



proposed method on our dataset and the benchmark dataset. the reason for misclassification is that when the images of family and non-family images share geometric structures of the faces and the properties of backgrounds, the proposed method fails to perform correct classification. therefore, there is scope for improvement in the future.



in this paper, we have proposed a new idea for classifying family and non-family photos by combining facial structure and background texture. the proposed method explores distances between facial key points for extracting spatial features. in addition, angles between facial key points are also explored for studying the structures of faces, which are called geometric features. to make use of the background information and textural properties of facial regions, we have proposed novel tsallis fractional entropy-based features. furthermore, the proposed method combines spatial, angle and fractional entropy features to obtain the feature vector. the feature vector is applied to a conventional convolutional neural network for classification. experimental results on our own dataset and the benchmark datasets show that the proposed method is better than two state-of-the-art methods in terms of average classification rate.



the main contributions are the following. it is inherent that facial regions are the key factor for family and non-family photo image classification. based on this observation, we explore distance features for facial key points as spatial features to study the structure of facial regions. we have used angle information for facial key points to make spatial features robust to extract the detailed structure of facial regions. the way we combine spatial and anglebased features as geometric ones is novel and an interesting approach to tackle the issues of family and non-family photo classification. to extract regular patterns in facial and background regions(other than facial region), we propose a novel idea of introducing tsallis fractional entropy for extracting texture properties of facial regions and other background regions. furthermore, the proposed method combines geometric and fractional entropy features in a different way for achieving the best results.



despite having proposed a new idea for family and non-family images classification, there are some limitations to the proposed approach. sometimes, when family and non-family image share the same properties of facial regions with the background, the proposed method fails to yield good results. this is understandable because one can expect similar patterns of foreground and background for both family and non-family images. in this case, we need a method, which can work irrespective of background and facial regions. one way is to introduce context features using foreground and background information to find a solution regarding



when photos contain both family and non-family members, the proposed method may not work well. it is beyond the scope of the proposed work as it is hard to separate family or non-family members in the same image. to find a solution, one possible way is to bring multimodal concepts, such as face, skin, dress, and structure of the body. this is due to the potential of sharing personal traits and habits with members belonging to the same family. if individuals do not belong to a particular family, we can expect different habits, structures(apart from the face), skin, etc.



maryam asadzadeh kaljahi: implementing methodology, data curation. palaiahnakote shivakumara: conceptualization, formal analysis, supervision, draft writing, investigation. tiangping hu: data curation, validation. hamid a. jalab: formal analysis, modeling. rabha w. ibrahim: formal analysis, modeling. michael blumentsein: review editing. tong lu: validation and reviewing. mohamad nizam: validation and reviewing.



