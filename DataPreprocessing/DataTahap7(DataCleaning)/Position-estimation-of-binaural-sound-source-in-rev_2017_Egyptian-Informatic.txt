the human auditory system is capable of extracting the spatial location of objects in the spherical coordinates in terms of direction(azimuth, elevation) and distance. researches focus on directional perception, mainly, azimuth estimation in various scenarios. recently, elevation has gained more attention, but in distance perception the researches mostly addressed it with microphones arrays, while binaural audition was less considered. since azimuth and distance are the most effective relevance to human listeners in position estimation, several studies were conducted investigating the relation and the influence of the cues of direction and distance on each other. they reported that the combination of azimuth and distance estimation maximizes localization accuracy[6,5,7]. however, the majority of the studies provide either of them as given information that improves the accuracy as test cases or to study their influence. despite the distance represents depth information and destination for mobile robots, most of 3d systems ignore distance. few researches correlate azimuth and distance for position estimation based on microphone arrays for tracking mobile objects[8,9]. hence, this work proposed in the direction of jointly estimation of azimuth and distance for position estimation based on a combination of statistical features of binaural signal.



statistical properties of the binaural cues and the standard deviation of the spectral magnitude difference of the binaural signal and the rest of the paper is organized as follows: the next section describes the model approach, the details of features extraction and selection process. in section 3 the classification approach to estimate the source position is explained, and section 4 demonstrates the simulation and the used database details. the experiment results and evaluation are found in section 5. finally the conclusion is in section 6.



in azimuth estimation inspired by the human auditory system and based on only two microphones, the primary cues are interaural time difference(itd) that is the time difference of arrival of the sound signal between left and right ears and interaural level difference(ild) that is defined as the level of intensity difference between the two ears. these cues have been extensively studied to present localization systems; in recent years researches estimate azimuth based on joint itd and ild features as raspaud in. may developed gaussian mixture model depending on probabilistic model of itd and ild, and youssef et al. used neural network approach to estimate the azimuth in a humanoid robotic context.



instead of full covariance matrix which is computationally more complex and expensive. the expectation maximization algorithm is used with maximum number of iterations 300 iterations to estimate the parameters. since the features vary in scales, variance normalization is applied prior to classification process.



this paper presented a system that robustly estimates the position of a sound source in both distance and direction perception in reverberant environments based on a bsmd-std and set of statistical properties of binaural cues. a combined feature vector is provided as input to gaussian mixture models(gmms) for classification, then the corresponding position of the sound source is estimated. various reverberation conditions and positions were tested and evaluated. the system provided robust and high accuracy performance results in different scenarios and the ability to adjust untrained positions.



