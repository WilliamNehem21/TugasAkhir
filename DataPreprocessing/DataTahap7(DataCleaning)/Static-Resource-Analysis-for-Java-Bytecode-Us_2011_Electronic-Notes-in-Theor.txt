in, robert atkey shows how methods from amortised complexity analysis can be combined with separation logic to obtain a technique for resource analysis of imperative programs which manipulate heap-based data-structures such as trees and linked lists. he shows how to apply this method to a small stack-based virtual machine, similar to the jvm. in this paper we describe an analyser which applies this analysis to real jvm bytecode, using specifications obtained from programmersupplied annotations in java source code.



we begin with an outline of the ideas involved in the analysis. this is followed by a detailed description of the java annotations used to communicate the specifications to our analyser, together with examples of the analyser in action. we also describe some of the methods used in the implementation of the analyser.



the work described in this paper was carried out in the resa project(epsrc follow-on fund grant number ep/g006032/1) at the university of edinburgh. 3 more information can be found in. we would like to thank robert atkey for extensive discussions.



much of this paper is based on previous work of robert atkey. this work is somewhat technical from the point of view of non-experts, and in this section we will attempt to give a non-technical overview. we present a fairly simple example here, but we hope to make an online demonstration available on the resa webpages including more complex examples.



the intended meaning of this specification is that if when we enter the method, the arguments p and q point to well-defined list segments, then when we reach the end of the method, the return value will also point to a well-defined list segment. the specification may be regarded as a contract with the user: if the inputs to the method satisfy the precondition, then the output is guaranteed to satisfy the postcondition. ideally, we will be able to prove that the implementation of the method does actually guarantee this behaviour.



complicated; a better strategy is to amend the assertions to exclude problematic inputs from the outset. the key to this is to base the assertions on separation logic, a logic which is designed for arguing about non-overlapping structures and has proved very useful in the analysis of heap-allocated data structures in recent years. separation logic has a number of novel logical connectives for arguing about non-overlapping objects. for example, in addition to the usual logical conjunction



java annotations are a specific form of metadata that can be added to java source code. they can be associated with java classes, fields, methods and method parameters, and are embedded in classfiles when compiling java code. they are defined using class-like structures in files named after the annotation.



we have also introduced a dummy method called consume which does nothing except tell the static analyser that at the point where it is introduced, a unit of resource is being used. we can imagine such a dummy method being hidden inside library code in the future, stating the amount of resource used by each method defined in each class, so that programmers will not need to add it explicitly but rather implicitly use it by invoking library methods. in the present implementation though, libraries have not been modified and developers have to specify resource consumption explicitly in their code.



loop invariants have to be given for each loop for the amortised analysis to be effective but the java language does not allow the inclusion of annotations inside the code. this is problematic if the method being analysed contains two or more loops, since we need a way to decide which invariant refers to which loop. we could simply give invariants in the same order as the loops appear in the code, but it is possible that a compiler might produce bytecode in which the order in which the loops appear in the bytecode does not correspond to the order in the source code. our way to obviate this limitation was to identify each loop with an integer identifier. each loop invariant is given a identifier(@invariant(id, assertion)) and the same identifier has to match the argument of a dummy method loop.invariant(id) placed just before the loop in the code. thus by searching the code, the analyser can associate the declared invariants with the corresponding loop.



our analyser is implemented in ocaml, and java class files are represented by a collection of datatypes. for program analysis, the most important part of this is the representation of method bytecode. our design is intended to be fairly generalpurpose since we intend to support multiple analysis techniques, including the amortised analysis described earlier.



java classfiles are initially converted into a low-level ocaml representation which is a fairly faithful representation of structure of the class as described in the jvm specification. this is then converted into a higher-level representation which is more suited to analysis. we will give an outline of this representation here, but space limitations preclude a detailed description.



instructions which act on the stack are represented by a datatype of operations which take values as arguments. this has 19 constructors which suffice to represent all of the jvm operations(putfield, getfield, invokevirtual and so on) except for those which involve control-flow transfer. basic blocks are represented by a list of pairs consisting of operations together with the local variable or stack location where the result(if any) of the operation is to be stored. at the end of a basic block we have a member of a continuation datatype: this represents various types of jump, comparison, switch, and return operation, together with information specifying which blocks control can flow to after leaving the current block. we do not provide any representation for the jsr and ret instructions used by exception handlers, since these complicate analysis and are supposedly deprecated in current java releases(although we have encountered them in a few of the standard api classes in rt.jar). if one of these instructions is encountered during decompilation then an exception is thrown and the class is rejected.



the amortised analysis can only handle bounds on resource usage which are linear in the size of the data structures involved. the experience of other authors suggests that this is sufficient in many(but by no means all) practical situations. the linear-programming-based inference technique we use here is intrinsically tied to linear bounds; nevertheless, recent work[14,13] has shown how it can be extended to deduce non-linear bounds in certain specialised cases. there are other inference techniques which can deal with non-linear bounds, and we will discuss some of these later.



the analyser currently only supports linked lists and trees, and the proof-search implementation depends quite strongly on this. it would be desirable to find more generic annotation and analysis techniques, for example for dealing with data structures in the standard java api which are accessed via interfaces. one method here might be to attach annotations to existing library classes in order to enable the analysis of client code.





