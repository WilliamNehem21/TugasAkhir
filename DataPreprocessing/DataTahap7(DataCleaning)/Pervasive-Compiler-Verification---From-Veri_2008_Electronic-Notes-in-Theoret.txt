specification. we also sketch a method to solve the boot strap problem, i.e., how to obtain a trustworthy binary of the c0 compiler from its c0 implementation. ultimately, this allows to prove pervasively the correctness of compiled c0 programs in the real system.



compiler verification is a well established field. there are correctness proofs covering issues from simple expression translation in to compilers with optimizations in[8,25]. also, different source languages are considered: from toy languages to subsets of c and java or the java virtual machine.



in the verifix project, impressive work concerning correct compilers has been done. in, the authors present an elegant theory for the translation of intermediate languages to machine languages; the work was partially formalized in the pvs theorem prover. the implementation of a compiler for comlisp(a subset of common lisp) was verified on the machine code level by a manual check.



in the specification of an optimizing compiler back-end from the ssa intermediate language has been formally verified. however, the machine model used there is not the language of a realistic processor and hence the work does not suffice to bridge the gap between software and hardware for pervasive verification. on the other hand, the work from describes a framework for modeling the semantics of expression evaluation including non-determinism in the evaluation order. in the context of pervasive verification, such complicated languages are not desirable as they make correctness proofs of larger programs infeasible.



the famous cli project resulted in a stack of verified components including a compiler specification. the produced collection of verified programs has mostly been done in low-level languages. recently, zhong shao presented very nice logics for the assembler level verification of different kinds of low-level software. however,



as pointed out above, there are many additional challenges for compiler verification due to pervasive verification. some of them have been solved(in isolation) in a similar or even more general way in other work. however, in the context of pervasive verification an essential part of the verification effort has to be invested in the combination of the individual solutions into a single framework. in addition to the impressive work of the cli stack project, early work from joyce discusses problems imposed by the formal combination of a verified compiler with verified hardware. to the best of our knowledge, the work presented in this paper is the first which integrates all the separate solutions into a single framework that provably meets the needs of pervasive verification of complex systems.



the remainder of this paper is structured as follows. in section 2, we introduce the c0 language and sketch its small-step semantics. we present a simulation theorem for the compiling specification in section 3 and a correctness proof for the compiler implementation in section 4. the section about the correct compiler implementation contains a sketch of our approach to solve the bootstrap problem. we conclude in section 5 and discuss some future work.



semantics of the full c language are complex[17,36,37] and the use of all features of c leads to an error-prone programming style. in contrast, formal verification of programs is easier and more efficient for programming languages with concise semantics. verisoft uses the c-like imperative language c0 which has sufficient features to implement all system and application software in verisoft while still allowing for efficient verification of programs with several thousand lines of code.



dynamic allocation of zero-initialized heap memory for a type t is supported via new(e, t) which assigns a pointer to the newly allocated memory region to the left side expression e. observe, that c0 does not support explicit deallocation. instead, a garbage collector will be used to deallocate unreachable parts of the heap in user applications. 6 the implementation correctness of a copying garbage collector for c0 has already been formally verified but is not yet integrated into the compiler correctness proof.



function calls to a function f with parameters e1 to en are represented by scall(x, f, e1,..., en). because c0 expressions must not have side effects, function calls are not supported as subexpressions. instead, the return value of the function will be copied implicitly to variable x. return from functions is handled by return(e).



generalized variables(short g-variables) are a structural way of referring to memory objects. pointers in the c0 small-step semantics are represented using g-variables. there are three base cases for g-variables: global variables of name x are represented by gvar gm(x), local variables x in the i-th local memory frame by gvar lm(i, x), and nameless heap variables with index i by gvar hm(i). the inductive case defines g-variables for structure and array access. if g is a g-variable of structure type then a component g'= gvar str(g, n) of name n is also a g-variable. if g is a g-variable of array type then its i-th element g'= gvar arr(g, i) is also a g-variable. in these two cases, g' is called a sub g-variable of g.



for later reference, we highlight some parts of the definition of the new program rest c'.pr. let the old program rest start with statement s, i.e., c.pr= s; r. in most cases s is simply executed and the new program rest is set to c'.pr= r. in three cases the length of the program rest can grow.(i) if s= while(e, s') and va(c, e)= true then the new program rest is c'.pr= s'; s; r.(ii) if s= if(e, s1, s2) then the new program rest is c'.pr= s1; r or c'.pr= s2; r.(iii) if s is a function call to some function f with body b then the new program rest is c'.pr= b; r.



by induction we define the i-th parent statement by pa0(p, s)= s and pai+1(p, s)= pai(p, pa(p, s)). we define the environment of statements s, i.e., the list of statements in the basic block which s belongs to.



if s= if(e, s1, s2) the new program rest is ci+1.pr= s1; r or ci+1.pr= s2; r, depending on the value of e. let for both cases s' denote the last statement in the corresponding branch s1 or s2. we have to show that s' is followed by succ(s') in the new program rest. by the third case of the definition of succ, we know that succ(s')= succ(s). therefore, we can conclude with help of the induction hypothesis that s' is followed by the same statement which followed the conditional s in the original program rest(in all cases this is the first statement in statement list r).



proof. we prove this theorem by induction on i. for the induction start i= 0 we mainly have to show that the initialization part of codes(p) works correctly. the induction step from i to i+ 1 is proved by a case distinction over the first statement s in the program rest ci.pr= s; r. we cannot present all cases here but concentrate on one interesting detail of the proof which comes from the fact that we prove a small-step simulation theorem.



if s is the last statement in the body of some loop while(e, lb), we know from the definition of succ that while(e, lb) itself is the successor of s. by a proof, which is local w.r.t. the while loop, we can show that the distance of the jump instruction behind the loop body is correct and we finally have di+t.dpc= cad(while(e, lb))= cad(succ(s)).



1.500 lines of c0 code in about 60 procedures. due to limited project resources, parsing and i/o operations have not been verified. the verified compiler core is embedded into an unverified front-end written in c/c++, which parses a c0 input program, checks its syntactical correctness, and produces a syntax tree, which is then being fed into the compiler core. the verified core translates the c0 syntax tree into a list of vamp assembler instructions, which is output by an unverified i/o routine.



the compiling specification works in one pass: offsets for relative jumps are determined on the fly via functions which compute solely the size of the generated code. in contrast, the compiler implementation in section 4 uses two-pass compilation. jump distances for relative jumps are left out in the first pass and filled in with correct values in a second pass when the position of all jump destinations is known.



we formulate preand postconditions of the hoare triples using so-called abstraction relations, which state the correspondence between the current state variables and abstract hol types. abstraction relations have to be defined for all relevant data structures of the compiler implementation. absence of pointers in the specification language results in very different representation of objects and, hence, makes abstraction relations and verification more complex.



we highlight some of the key verification issues for the compiler implementation(besides code size). one of these follows from the implementation and specification being written in an imperative and a functional programming language, respectively. thus, the correct implementation of recursive functions by while loops is an issue. additionally, the recursion directions often differ; for example, in the implementation lists are traversed from head to tail and the specification exploits natural recursion with the last list element as induction base. another example is the code generation for complex literals, where mutually recursive functions in the specification are implemented by a combination of recursive functions and loops.



proof for the total correctness(including termination and validity of guards) of the compiler implementation consisting of 1.500 lines of c0 code. 8 the formal proofs and definitions consist of roughly 85.000 lines of isabelle code. this number covers the c0 small-step semantics(15.000 lines, including type correctness proofs and theorem 2.1), the correctness proof for the compiler implementation(40.000 lines), and the simulation proof for the compiling specification(30.000 lines).



