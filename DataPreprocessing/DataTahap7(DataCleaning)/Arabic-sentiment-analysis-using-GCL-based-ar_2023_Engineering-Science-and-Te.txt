sentiment analysis is a form of natural language processing which detects the sentiment expressed in a text. by 2025, it is estimated that sentiment analysis will be worth$3.8 billion, due to its many practical applications in business and politics. as a result, it has become a very active research field in recent years.



the paper is organized as follows. section 2 reviews previous work on sentiment analysis for arabic. section 3 outlines the proposed approach and model architecture. section 4 presents our experiments, including preprocessing steps, experimental settings, baselines, results, and discussion. finally, section 5 is the conclusion and suggests future work.



afooz et al. compared their ensemble model, which included xgboost(xg), gradient boosting(gb), adaboost(ada) and random forest(rf), with machine learning classifiers on arabic text which was collected from youtube comments. svm, followed by linear regression(lr), had the best performance accuracy(77.00%).



applied the svm, nb, and knn algorithms, with three tools(sentistrength, socialmention, and aopi), to a corpus of 3,015 arabic opinions, which they collected from three main domains: food, sport, and weather. svm proved the best(76.33%). the aopi tool was shown to be more effective than the two free online tools.



model, which was constructed from a large arabic journal corpus; accuracy was 92.00%. recently, elfaik et al. used a bidirectional lstm model on several datasets: astd, artwitter, labr, mpqa, multi-domain, and ahsd. accuracies were 79.25%, 91.82%, 80.70%, 75.85%, 89.70%, and



concerning the machine learning classifiers, we note that svm was the most used, while lr achieved the highest performance. generally, ml models have three problems. first, they are susceptible to noise; a small amount of incorrectly labeled samples can have a significant impact on performance. second, selecting the perfect kernel is a difficult undertaking. third, when the dataset is large, training is slow.



as is well known, the key idea behind word embeddings is that words with similar meanings are converted to similar vectors, which enables that similarity to be determined by vector comparison methods such as dot product or angle. they are also ideal for input to neural network models, as has been shown for a large number of nlp tasks in many different languages, including arabic. in the context of word embeddings, there are three interesting questions to consider,(1) how to handle word polysemy, i.e. words with many meanings,(2) how to handle metaphorical or hidden meanings, and(3) how to handle words whose meanings differ lem directly, but it can do so implictly. for example, if a tweet refers to someone as a lion and the sentiment associated with the training data instance is positive, the model can learn that being described as a lion is a positive attribution, similar to being described as a hero. in such a way, the sentiment assigned to an unseen input can still be correct, even in cases of metaphorical language use.



dings from aravec, the meaning(s) associated with a word will depend on the dialects spoken in the training data used to create the embeddings. a typical dataset may indeed contain instances of different arabic dialects. however, the proposed model does not rely on the interpretation of any single word in the input text; instead, the meanings of all words are converted to vector form and then input to the cnn model. in this way, the model can learn to overcome contradictions resulting from the incorrect interpretation of words. thus, overall, we can see that the use of word embeddings in a neural network model can alleviate these three problems, still resulting in a sentiment analyis tool of high accuracy, while it cannot completely solve them.



the multi-domain arabic sentiment corpus, masc4 is for moroccan arabic(mor). it contains 8,860 ratings from various realms and dialects of arabic. the information was gathered manually from a variety of sources, including the jeeran and qaym websites, google play, twitter, and facebook. there are 4,476 positive tweets and 2,257 negative.



for ahsd, validation losses with gcl+ bc, gcl+ hinge, gcl+ poisson, gcl+ kl-divergence, and gcl+(cr+ binary-cros s-entropy) were 0.437, 0.5571, 0.6934, 0.4316, and 0.3822, respectively. gcl+(cr+ binary-cross-entropy) had the lowest validation loss(0.382), and the lowest time except for gcl+ hinge.



for artwitter, masc and bbn, gcl+(cr+ binary-cross-entro py) also had the lowest validation loss(0.3685, 0.5449, 0.5442). we therefore conclude that the proposed method with customized regularization plus binary-cross-entropy was the best performing model on the four datasets.



the saudi dialect comprises seven local dialects derived from ancient arabic, while the moroccan dialect has words from the spanish and french dictionaries. certain words from turkish and english appear in the sudanese dialect. also, the lebanese dialect contains influences from aramaic and syriac. since the essence of all dialects is in the msa, some differences in vocabulary resulted in various associations with msa in the results when using the proposed methods in the classification tasks. please refer back to section 3.3 for further dis-



fourth, we used the proposed model to analyze the link between emotions in modern standard arabic and those in five distinct arabic dialects. first, we trained on hard(msa) and evaluated on ahsd(sau), artwitter(jor), masc(mor), sudsenti2(sud), and bbn(lev). we found that the most similar dialect to msa is sau, and that the least similar dialects are sud and jor. second, we trained on hard and tested on all dialects together. this showed that a useful level of performance could be obtained in this way, but lower than when training and testing on a specific dialect.



this research was supported by the national natural science foundation of china(grant no. 61877050) and open project fund of shaanxi province key lab of satellite and terrestrial network technology, shaanxi province financed projects for scientific and technological activities of overseas students(grant no. 202160002).



