the fibonacci heap, 2-3 heap, and trinomial heap support insert and decrease key in o(1) time, and delete min in o(log n) time. since every vertex is visited there are n insert and n delete min operations. the number of decrease key operations is o(m) since this corresponds to the number of edges in the graph. thus, the overall time complexity when a fibonacci heap, 2-3 heap, or trinomial heap, is used for f is o(m+ n log n).



the distance updates in algorithm 3 are restricted from propagating between trees. even though this is not strictly necessary for the algorithm to work, for now it makes the explanation simpler. a more efficient version of this algorithm, which is not presented, allows the distance updates to be less restrictive, which can reduce the number of distance updates during the second updating pass.



for the second updating pass, only trigger vertices are involved in the frontier set, f, and solution set, s. at lines 5 and 6, the trigger vertex, u, which has minimum d[u], is selected and removed from f. call this the minimum trigger vertex. this vertex is then added to the solution set, s.



as was mentioned, the updates for shortest path distances in the new algorithm were deliberately limited to make the description simpler. an improved version of the algorithm can allow distance updates to propagate between trigger vertices during the first updating pass, without changing the correctness of the algorithm. then, if during the second updating pass, the distance to a vertex, v, does not update, the algorithm does not need to continue distance updates past v. by terminating the search at vertices which do not update, on average there may be a slight gain in time efficiency, even though the worst case time complexity will not change.



further work for possible improvements to this algorithm includes generalising from tree decomposition to a special form of acyclic decompositions. for an acyclic part a resulting from decomposition of the graph, there must be only one trigger vertex ancestor, u, of vertices in a. thus, now a trigger vertex u triggers updates into its acyclic part instead of a tree structure. this allows the selection of trigger vertices to be less restrictive, reducing the number of trigger vertices, and number of delete min operations that must occur.



the new all-pairs algorithm consists of two stages. algorithm 5 shows the first stage, and algorithm 6 shows the second stage. the algorithm uses a two dimensional array, d, to hold shortest path distances as the computation proceeds. at the end of the algorithm, array d holds the shortest path distance between any pair of vertices. in the algorithm, the reference array, d, is used for referring to a row in d. updating the shortest path calculation through vertices in t, can be done efficiently, since the graph induced by t is acyclic. the algorithm uses a topological ordering of vertices in t, stored in an ordered set, l, which can be obtained in o(m+ n) time. a graph, p, whose vertices correspond to triggers, is constructed by the first stage of the algorithm, and used by gss for calculating shortest path distances through vertices in t.



if for a given graph, k is large and v is small, the new algorithm can give significant improvement over the previous shortest path algorithms. other implementations of this algorithm are possible which are more efficient by a constant factor. more efficient implementations can avoid distance updates from a vertex, v, when d[v] is still infinite. one such algorithm uses two separate depth first search(dfs) like functions, where one of the dfs functions only traverses edges and does not update shortest path distances.



for nearly acyclic graphs, it is possible to solve the generalised single source problem in o(m+ v log v) time, where v is the number of trigger vertices, with trigger vertices defined as roots of trees that result when the graph is decomposed into trees. this gives an improvement on existing shortest path algorithms for nearly acyclic graphs from abuaiadh and kingston and takaoka. it is possible to combine this new algorithm and the previous algorithms into a hybrid algorithm which incorporates the properties of each. future work involves generalising from tree decomposition to an acyclic decomposition, in order to allow a reduced number of trigger vertices.



