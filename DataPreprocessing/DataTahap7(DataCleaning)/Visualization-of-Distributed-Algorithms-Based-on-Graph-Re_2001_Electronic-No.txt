in this paper, we present a uniform approach to simulate and visualize distributed algorithms encoded by graph relabelling systems. in particular, we use the distributed applications of local relabelling rules to automatically display the execution of the whole distributed algorithm. we have developed a java prototype tool for implementing and visualizing distributed algorithms. we illustrate the di erent aspects of our framework using various distributed algorithms including election and spanning trees.



we present in this work a method based on local graph transformations to visualize distributed algorithms. our work goes beyond the known animation of isolated examples of distributed algorithms. we show that a large class of distributed algorithms, which can be described by some graph transformation systems, can be simulated and visualized automatically. graph relabelling systems and, more generally, local computations in graphs are powerful models which provide general tools for encoding distributed algorithms, for proving their correctness and for understanding their power. we consider an anonymous network of processors with arbitrary topology, represented as a connected, undirected graph where vertices denote processors, and edges denote direct communication links. an algorithm is encoded by means of local relabellings. labels attached to vertices and edges are modi ed locally, that is on a subgraph of xed radius k of the given graph, according to certain rules depending on the subgraph only(k local computations). the relabelling is performed until no more transformation is possible. the corresponding conalgorithms are presented in[23,25,6]. m etivier et al.[20,21] have investigated randomized algorithms to implement distributed algorithms speci ed by local computations. intuitively, each process tries at random to synchronize with one of its neighbours or with all of its neighbours depending on the model we choose, then once synchronized, local computations can be done. a synchronization between two neighbours is called a rendez-vous, and a synchronization between a vertex and all its neighbours is called a star synchronization. procedures implementing synchronizations are given and discussed in[20,21]. we use these techniques to visualize the execution of a distributed algorithm. all random local synchronizations throughout the network are displayed, and messages exchanged during these synchronizations are also shown. hence, the visualization of the execution of the whole algorithm is carried out until termination. we have developed a prototype tool with an interactive visual



the paper is organized as follows. section 2 introduces graph relabelling systems, and their use to describe distributed algorithms. section 3 presents a method to simulate and visualize distributed algorithms coded by graph relabelling systems. section 4 presents future work and concludes the paper.



all graphs we consider are nite, undirected, simple and connected. a graph g is thus a pair(v(g); e(g)); where v(g) is a nite set of vertices and e(g) ffv; v0g j v; v0 2 v(g); v0 6= vg is the set of edges. main notions may be found in.



an l labelled graph is a graph whose vertices and edges are labelled with labels from a possibly in nite alphabet l. it will be denoted by(g;), where g is a graph and: v(g)[ e(g)! l is the labelling function. the graph g is called the underlying graph of(g;), and is a labelling of g. the class of l labelled graphs will be denoted by gl, or simply g if the alphabet l is clear from the context.



hence, several vertices may be active at the same time. concurrent steps will be allowed provided that two such steps involve distinct vertices. the computation stops as soon as all the vertices have been activated. the spanning tree is given by the 1-labelled edges.



consider a graph representing a network, where nodes correspond to processors and edges correspond to communication channels. the visualization of a distributed algorithm consists of showing and animating its execution. data exchanged between processors, as well as status and label updates of processors and of channels are displayed on-they on the screen. of course, other interesting events depend on the algorithm itself. for instance, to determine a spanning tree, it is important to mark edges belonging to the spanning tree.



rendez-vous(rv): in a computation step, the labels attached to vertices of k2(the complete graph with 2 vertices) are modi ed according to some rules depending on the labels appearing on k2: to implement rv, we consider the following distributed randomized procedure. the implementation is partitioned into rounds; in each round each vertex v selects one of its neighbours c(v) at random. there is a rendezvous between v and c(v) if c(v)= v; we say that v and c(v) are synchronized. when v and c(v) are



local computation 1(lc1): in a computation step, the label attached to the center of a star is modi ed according to some rules depending on the labels of the star, labels of the leaves are not modi ed. the implementation of lc1 is the following randomized local election. it is partitioned into rounds, and in each round, every processor v selects an integer rand(v) randomly from the set f1;:::; n g: the processor v sends to its neighbours the value rand(v): the vertex v is elected in the star centered on d and denoted sv; if for each leave w of sv: rand(v)> rand(w): in this case a computation step on sv is allowed: the center collects labels of the leaves and then changes its label.



local computation 2(lc2): in a computation step, labels attached to the center and to the leaves of a star may be modi ed according to some rules depending on the labels of the star. the implementation of lc2 is the following randomized local election. it is partitioned into rounds, and in each round, every processor v selects an integer rand(v) randomly from the set f1;:::; n g: the processor v sends to its neighbours the value rand(v): when it has received from each neighbour an integer, it sends to each neighbour w the max of the set of integers it has received from neighbours di erent from w: the vertex v center of the star sv is elected if rand(v) is strictly greater than rand(w) for any vertex w of the ball centered on v of radius 2; in this case a computation step may be done on sv: during this computation step there is a total exchange of labels by nodes of sv; this exchange allows nodes of sv to change their labels.



java language, the processors are simulated by java threads. to program a relabelling system, a library of high level primitives allows the user to implement local computations. in particular, three functions(rendezvous(), starsynchro1() and starsynchro2()) implementing the previous synchronizations are provided. moreover, communications between processors can be expressed by primitives such as sendto(neighbour, message), and receivefrom(neighbour). an illustrative example shows the implementation of the spanning tree example discussed in section 2.



