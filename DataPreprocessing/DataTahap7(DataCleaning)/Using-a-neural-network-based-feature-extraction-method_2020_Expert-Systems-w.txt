citation screening is a labour-intensive part of the process of a systematic literature review that identifies citations eligible for inclusion in the review. in this paper, we present an automatic text classification approach that aims to prioritise eligible citations earlier than ineligible ones and thus reduces the manual labelling effort that is involved in the screening process. e.g. by automatically excluding lower ranked citations. to improve the performance of the text classifier, we develop a novel neural network-based feature extraction method. unlike previous approaches to citation screening that employ unsupervised feature extraction methods to address a supervised classification task, our proposed method extracts document features in a supervised setting. in particular, our method generates a feature representation for documents, which is explicitly optimised to discriminate between eligible and ineligible citations.



higgins and green(2011). however, owing to the proliferation of the published literature(bastian, glasziou,& chalmers, 2010), the manual production of a systematic review has become a time-consuming process, with an average completion time of approximately 2.4 years(bekhuis& demner-fushman, 2012). greenhalgh et al.(2014). in addition, shojania et al.(2007) ree.g. sentiment analysis(cambria, 2016), constitutes a direct application area of our method. our experiments demonstrate that the proposed method can substantially improve text classification performance. moreover, our method could be integrated with text search engines, e.g. apache solr(smiley, pugh, parisa,& mitchell, 2015), in order to learn to identify documents that are relevant to individual user preferences.



the vast majority of existing semi-automatic citation screening methods adopts unsupervised document representation techniques, such as bag-of-words, to address an inherently supervised classification task. therefore, the induced feature representation of documents naturally ignores the readily available classmembership information of manually labelled citations. in this paper, we present a new supervised feature representation technique that leverages the class-membership information of the manually screened citations to generate informative document features. the proposed method uses a multi-layer feed forward neural network to learn a latent representation of documents that encodes discriminative and class-specific information about the citation screening task.



more specifically, our proposed feed forward neural network is trained on the manually labelled citations, while the hidden layers of the network are iteratively optimised to better discriminate between eligible and ineligible studies. we then extract an embedded feature representation of documents using the fixed weights of the hidden layers. the document embeddings can be integrated with any classification algorithm used for automatic screening prioritisation. following previous approaches, we use a support vector machine with a linear kernel to assign a classification confidence to each citation set and we rank the citation list in order of relevance to the review.



for evaluation, we conduct a series of experiments to investigate the performance of our supervised feature induction method when applied to the citation screening task of 23 publicly available systematic review datasets from the medical domain. experimental results demonstrate that our proposed feature extraction method can reduce the number of items that need to be manually screened without decreasing the sensitivity of the review, i.e. at least 95% of relevant studies are identified by the semi-automatic screening method. moreover, our neural network-based feature extraction method shows substantial performance improvements when compared to 10 baseline feature extraction methods. the contributions of this paper can be summarised as follows:



kim& choi, 2012; wallace et al., 2010). in the bow model, each document is represented as a sparse, high-dimensional feature vector, wherein the dimensions of the vector correspond to words or phrases that occur in the document. bekhuis and demnerfushman(2012) demonstrated that an automatic text classification method trained on bow features achieved substantial workload savings of 35%-46% on two medical systematic reviews. moreover, the authors showed that single-word features yielded an optimal performance when compared to bi-gram or tri-gram features, i.e. phrases consisting of two or three words, respectively. however, a limitation of the bow model is that the resulting feature space consists of a large number of word-features and therefore the model is associated with increased memory and computational costs when applied to large-scale systematic review datasets(forman, 2003).



feature selection methods, e.g. forward feature selection or information gain filters(bekhuis& demner-fushman, 2012), have been previously used to reduce the size of the bow space, although adeva et al.(2014) reported that such feature selection methods result in insignificant performance improvements.



in a study closely related to our work, hashimoto et al.(2016) presented a variation of the widely popular paragraph vectors(pv) model(le& mikolov, 2014), a document representation technique for extracting informative document features. the pv model is a neural network-based feature extraction method that follows a distributional semantics approach to better account for words and documents semantics. more specifically, the pv model trains a shallow neural network, consisting of one hidden layer, by maximising the conditional probability of a word given its context and the document that it appears. hashimoto et al.(2016) modified the original implementation of the pv method in order to model each document as a distribution of latent topics. the authors further showed that their proposed pv method achieved a superior performance on complex, multidisciplinary reviews when compared to the lda topic modelling method. however, a limitation of the pv model is that it follows an unsupervised approach to feature representation and therefore the generated feature space is not explicitly optimised to discriminate between eligible and ineligible studies.



the main advantage of our method when compared to previous feature extraction methods is that it follows a supervised approach to extract discriminative document features. moreover, our method generates a dense and low-dimensional feature space which is easier to manage when compared to the sparse and high-dimensional feature space produced by the bow model. we further show that our supervised feature extraction method can enhance the performance of semi-automatic citation screening when compared to previously used unsupervised feature extraction methods, including bow, bibliographic metadata, a low dimensional projection of the bow space using the singular value decomposition, a topicbased feature extraction method based on latent dirichlet allocation and a topicbased feature induction method which exploits a shallow neural network. moreover, we report statistical significant improvements over the baseline methods in several review datasets.



in this section, we detail the methodology that we follow to semi-automate the citation screening process of systematic reviews. firstly, we describe the automatic screening prioritisation framework that we use to evaluate different feature representation methods. we then provide implementation details of our proposed neural network-based feature extraction method.



the labelled set is manually annotated by a human reviewer with include/exclude codes and it is used by the text classification method to learn to discriminate between eligible and ineligible studies. it should be noted that in our experiments we use publicly available datasets which were manually annotated with include and exclude codes in prior work.



the text classification method firstly uses a feature extraction component to transform the textual content of citations into a numerical representation, i.e. feature vectors. in our approach, we develop a new supervised feature extraction method that uses a neural network model to generate a discriminative feature representation of documents. document features extracted by our method are then used as input to a linear svm classifier. the proposed supervised feature extraction method is described in the following section, section 3.2.



in our approach, we use a straightforward variation of the onelayer denoising autoencoder(dae), namely a deep dae, which simply adds additional intermediate hidden layers into the network to learn more complex non-linear projections of the input data(hinton& salakhutdinov, 2006). moreover, we use three different daes to learn potentially different reconstructions of the bow space. the experiments that we conducted, presented in section 4.5.3, demonstrate that a multi-branch model architecture that uses multiple dae components obtains a statistically significantly better performance, in comparison to a single-branch architecture that uses only a single dae component. each dae consists of 5 hidden layers, whereas we vary the dimensionality of the first and last hidden layer across the three daes to obtain different reconstructions of the bow space. the reconstructed output of each dae is then used to initialise the supervised feed forward neural network. this type of unsupervised pre-training, where the feed forward neural network is initialised by deep daes, has been previously shown to substantially improve the performance of the feed forward network.



b) the size of the dataset in terms of number citations that need to be screened, c) the percentage of eligible citations and d) the availability of bibliographic metadata. each citation in the review datasets consists of a title, abstract and a classification label, i.e. eligible or ineligible, associated with that citation. moreover, 18 out of 23 review datasets include additional bibliographic metadata for



the singular value decomposition(svd) method is a dimensionality reduction technique that projects an input high dimensional feature space into a dense, lower dimensional space. svd is different than the widely used principal component analysis(pca), as it computes eigenvalues and eigenvectors directly on the input data matrix, whereas pca computes eigenvalues and eigenvectors on the covariance matrix of the input data(wall, rechtsteiner,& rocha, 2003). in the context of this study, we use the svd baseline method to derive a low dimensional projection of the bow feature space. the svd baseline method is implemented using the scikit-learn library. it should be noted that no prior work has previously evaluated svd derived features for semi-automatic citation screening. we therefore identify optimal parameter settings, i.e. dimensionality of the projected space according to the top k eigenvalues, for the svd method using a grid search method on the same two development reviews that we used to fine-tune our supervised feature extraction method. experimental results showed



mesh tags are single word or multi-word keywords that are manually assigned to every citation indexed by the medline bibliographic database(lipscomb, 2000). mesh tags aim at summarising the textual content of citations using a set of descriptive keywords. considering that mesh keywords may not always appear in the title or in the abstract of a citation, mesh-based features can potentially provide complimentary information to bow features. in order to retrieve mesh tags from the medline database, we use the biopython library. we then construct binary feature vectors, where each dimension of the vectors corresponds to a different mesh tag, while feature values determine the presence or absence of a mesh tag in a given citation.



the wss@95% performance of the dae-ff method shows a different pattern on the larger bpa development review, when compared to the performance recorded on the smaller statins review. here, the performance of the method continuously improves as the number of dae epochs increases. an optimal wss@95% score of 0.792 is observed when training the dae components for 150 epochs, whereas for 200 epochs the performance of the method slightly decreases to 0.782.



the results show that the composite feature extraction methods improved upon the performance of the bow single-view baseline. performance gains in terms of the average wss@95% range between~ 1% to~ 6%. the concatenation of lda with bow features(i.e. bow-lda) achieved the best average wss@95% of 0.492 among the two-view composite baselines while the four-view composite method obtained a slightly higher average wss@95% of 0.5 when compared to the bow-lda baseline. the dae-ff method showed a superior wss@95% score in 15 out of the 23 review datasets and a statistically significant improved performance over the 5 composite baselines in 7 datasets. finally, our method increased the average wss@95% score of the composite baselines by~ 6% to~ 11%.



the results that we obtained demonstrate that our neural network-based feature extraction method substantially reduced the screening workload of 23 systematic reviews by approximately 56%. however, the workload savings varied across the 23 reviews from a low wss@95% score of~ 9% on the oral hypoglycemics review to a higher wss@95% score of~ 84% on the pfoa/pfos review. moreover, we observed a weak correlation(r2= 0.279) between the wss@95% performance and the size of the corresponding review dataset which was statistically insignificant(p=.197). this indicates that our method can obtain meaningful workload savings on both small and large review datasets.



views. here, threshold estimation techniques, such as the s-d rank optimisation(arampatzis, kamps,& robertson, 2009), can be used to approximate an optimal threshold value. a second limitation of our method is that the underlying neural network-based feature extraction method is trained independently for each systematic review dataset. as an example, in our experiments we produced 23 neural network models corresponding to the 23 review datasets. however, different systematic reviews may share one or more more eligibility criteria(e.g. if included studies are randomised control trials) and thus learned document features could be applied to different reviews. as future work, we plan to investigate the use of domain adaptation and transfer learning in order to domain adapt a single feature extraction model across



we have demonstrated that by initialising the feed forward neural network using multiple denoising autoencoders of varying dimensionality we can improve upon the performance of our feature extraction method. we have further performed a number of experiments to assess the performance of our method across 23 publicly available systematic review datasets. it was shown that for 22 out of 23 review datasets the proposed method achieved significant workload savings on at least 10%, while in several cases our method yielded a statistically significantly better performance over 10 baseline feature extraction methods.



georgios kontonatsios: conceptualization, methodology, software, writingoriginal draft, formal analysis, writingreview& editing. sally spencer: supervision, writingreview& editing. peter matthew: software, validation, writingreview& editing. ioannis korkontzelos: conceptualization, methodology, software, supervision, writingreview& editing.



