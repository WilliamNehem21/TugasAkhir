elastic scaling, elimination of up-front capital and operational expenses, and establishing a pay-as-you-go business model for computing and information technology services. cloud computing data centers consume enormous amounts of electrical energy resulting in high operating costs and carbon dioxide emissions. the reason for high energy consumption is not just the quantity of computing resources and the power inefficiency of hardware, but rather lies in the inefficient usage of these resources. one way to address the energy inefficiency is to leverage the capabilities of the virtualization technology. the reduction in energy consumption can be achieved by switching idle nodes to low-power modes(i.e., sleep, hibernation), thus eliminating the idle power consumption. moreover, by using live migration the vms can be dynamically consolidated to the minimal



most of current researches migrates vms based on cpu utilization since there is a relationship between the total power consumption by a server and its cpu utilization. basically their model proposes that power consumption by a server grows linearly with the growth of the cpu utilization. cpu utilization based models are able to provide an accurate prediction for cpuintensive applications; however they tend to be inaccurate for other types of applications like network, i/o and memory intensive applications. the purpose of this work is: virtual machine consolidation. section 3 presents the virtual machine selection. section 4 discusses the related work. section 5 discusses the multiple regression host overload detection(mrhod) algorithm. section 6 discusses the hybrid local regression host overload detection. section 7 discusses the evaluation methodology. section 8 simulation results and analysis. finally, the conclusion and future work is discussed in section 9.



loaded. if it is still considered as being overloaded, the vm selection policy is applied again to select another vm to migrate from the host. this is repeated until the host is considered as being not overloaded. this section presents three policies for vm selection.



random choice policy is another simple method to select vms from overloading hosts. it randomly selects a vm to be migrated from the host according to a uniformly distributed discrete random variable. if it is still overloaded, repeat the step until the host considered being not overloaded.



the idea behind the maximum correlation(mc) policy is that the higher the correlation between the resource usages by applications running on an oversubscribed server is the higher the probability of the server overloading will be. according to this idea, we select those vms to be migrated that have the highest correlation of the cpu utilization with other vms. to estimate the correlation between cpu utilizations multiple correlation coefficients is applied. it is used in multiple regression analysis to assess the quality of the prediction of the dependent variable. the multiple correlation coefficients correspond to the squared correlation between the predicted and the actual values of the dependent variable.



lots of work has been proposed for energy efficiency and management on cloud data centers. in some approaches, vm consolidation has been formulated as an optimization problem with the objective to find a near optimal solution since an optimization problem is associated with constraints, such as data center capacity and sla. farahnakian et al. presented distributed system architecture to perform dynamic vm consolidation to improve



ghribi et al. presented two algorithms for energy efficient scheduling of virtual machines(vms) in cloud data centers. modeling of energy aware allocation and consolidation to minimize overall energy consumption leads us to the combination of an optimal allocation algorithm with a consolidation algorithm relying on migration of vms at service departures. the optimal allocation algorithm is solved as a bin packing problem with a minimum power consumption objective. it is compared with an energy aware best fit algorithm. the exact migration algorithm results from a linear and integer formulation of vm migration to adapt placement when resources are released. the results show the benefits of combining the allocation and migration algorithms and demonstrate their ability to achieve significant energy savings while maintaining feasible convergence times when compared with the best fit heuristic. this approach is achieved at the virtual machine(vm) level(or iaas level) and hence it is better to be achieved at the task level to be able to fit the platform or software as a service(paas, saas) levels.



beloglazov and buyya presented a heuristics for dynamic consolidation of vms based on an analysis of historical data from the resource usage by vms. to calculate the upper cpu utilization threshold a statistical methods(median absolute deviation and interquartile range) are used. also regression based algorithms(local regression and local robust regression) that are based on estimation of future cpu utilization are used. these statistical methods and policies to select a vm to be migrated are combined to form various strategies. these approaches do not consider hybrid parameters for host utilization calculation on contrary they depend on cpu only.



monil and rahman proposed a new host overload detection algorithm based on mean, median and standard deviation(mmsd) of utilization of vms. also a fuzzy vm selection method is proposed which takes intelligent decision to select a vm to be migrated from one host to the other. the disadvantage of the host overload detection algorithm is that they still use mean and standard deviation that are very much influenced by terminal/outlier values.



shidik et al. presented a vm selection model in dynamic vm consolidation to improve the energy efficiency in cloud data center based on fuzzy markov normal algorithm. fuzzy logic has been used for categorizing the attributes of vm candidates then deciding to which category vm should be migrated. the proposed vm selection model has been evaluated using various vm instance conditions(homogeneous or heterogeneous). its disadvantage is that it does not consider hybrid factors.



beloglazov and buyya presented openstack neat to provide an extensible framework for dynamic consolidation of vms based on the openstack platform. the functionality covered by this project will be implemented in the form of services separate from the core openstack services. the services of this project will interact with the core openstack services using their public apis. now openstack neat is used as the terracotta code base at the very early stage. terracotta is an extension to openstack implementing dynamic consolidation of resources, e.g. virtual machines(vms) using live migration. since terracotta is at its early stage and the devices to measure power are not on our premise we use an authenticated simulator.



in this paper we propose multiple regression host overload detection algorithm(mrhod) to enhance vm consolidation using hybrid factors. the pseudo code for the multiple regression host overload detection(mrhod) algorithm is presented in algorithm 1. algorithm 1. multiple regression host overload detection algoproblem. therefore, we utilize real data on power consumption provided by the results of the specpower benchmark instead of using an analytical model of power consumption by a server. we have simulated a data center that comprises 50 hosts and 50 vms using random workload traces. the host overload is frequently evaluated according to the scheduling interval which is set to 300 s. the host types are:



we normalize the results with respect to mrhod-mmt1.5. mrhod and hlrhod algorithms save more energy than all algorithms when we run random workload traces. mrhod gives better results than mmsd since it is a regression based algorithm which is based on estimation of future cpu utilization which represents a better prediction of host overloading but mmsd is based on statistical analysis of historical data using mean, median and standard deviations which are sensitive to outliers. as number of vms(30, 50, and 70) increases, the energy saving of mrhod and hlrhod algorithms gets higher than lr and lrr algorithms. for high number of vms, the improvement in mrhod and hlrhod is reduced compared to lr and lrr however they are still the best marginally.



parameter for each algorithm. for recently proposed algorithms(thr, iqr, mad, lrr, and lr) we used the recommended safety parameters provided in. single factor local regression based algorithms outperform single factor thr, iqr and mad and mmsd due to better predictions of host overloading, and therefore decreased sla violations due to host overloading(slatah) and the number of vm migrations. across different metrics for power/performance and qos multiple regression host overload detection(mrhod) algorithm outperforms all other algorithms that use single factor in host overload since esv metric is improved 6 times compared to other single factor regression algorithms(lr, and lrr) and more than 10 times(an order of magnitude) compared to mad, mmsd, iqr and thr.



across different metrics for power/performance and qos multiple regression host overload detection(mrhod) algorithm outperforms all other techniques that utilize single factor in host overload detection since the energy consumption is minimized by about 20% than lr and lrr algorithms. slav is minimized in lrr and lr than other multiple factor algorithms because the energy and slav are negatively correlated. so we use esv metric to decide if the host is the best in predicting of node overloading. for mrhod the esv metric is improved by about 24% compared to other single factor regression algorithms(lr, and lrr) and more than 40% compared to thr, mad, and iqr. multiple factor regression algorithms give enhanced results than all other single factor algorithms due to improved predictions of host overload detection, and thus minimized the number of migrations of vm which cause a minimization in slav. number of vm migration is very high in mad and iqr algorithms.



we perform multiple regression significance test using anova and data analysis tool in excel. r-square is a statistical measure of how close the data are to the fitted regression line. in our experiment adjusted r square is 0.91 which means the model greatly fits the data.



