fault-based testing uses test data designed to demonstrate the absence of a set of pre-specified faults. a well-known fault-based technique is mutation testing. in mutation testing, first, faults are injected into a program by altering(mutating) its source code. then, test cases that can detect these errors are designed. the assumption is that other faults will be caught, too. in this paper, we apply the mutation technique to both, specifications and programs.



the theory we contribute was designed to be a complement to the existing body of knowledge. traditionally, theories of programming focus on semantical issues, like correctness, refinement and the algebraic properties of a programming language. a complementary testing theory should focus on the dual concept of fault. the main idea of a fault-centred testing approach, also called fault-based testing, is to design test data to demonstrate the absence of a set of pre-specified faults.



the paper is structured as follows. after this general introduction, section 2 gives a very brief introduction to the theory of designs of and defines what we mean by a faulty design. the next two sections include the main contributions of this paper. section 3 contains a construction for test cases that will find anticipated errors in a design. this test case generation technique works on the semantic level of designs. in section 4, a purely algebraic(syntax-oriented) test case generation technique is presented. it is based on the algebraic properties of a small, but nontrivial, programming language. finally, in section 5 we discuss the results as well as its related work, and present an outlook on future research directions.



here, we restrict ourselves to model-based(model-oriented) specifications. more precisely, we use the design calculus of utp to assign specifications a precise semantics. designs are a special form of predicates with a preand postcondition part, together with an alphabet. the alphabet is a set of variables that declares the observation space. the free variables of a design predicate are a subset of the alphabet and represent state variables before(undecorated variable names) and after execution(decorated variable names) of a program. in addition, special boolean variables



in this section, we relate test cases via refinement to designs and programs. this is possible, since we give test cases a denotational semantics by viewing them as specification predicates. the result is a test case generation technique based on non-refinement.



previous work of the first author has shown that refinement is the key to understand the relation between test cases, specifications and implementations. refinement is an observational order relation, usually used for step-wise development from specifications to implementations, as well as to support substitution of software components. since we view test cases as(a special form of) specification, it is obvious that a correct implementation should refine its test cases. thus, test cases are abstractions of an implementation, if and only if the implementation passes the test cases. this view can be lifted to the specification level. when test cases are this condition is at the heart of our test domain. since we have to show nonrefinement, this must hold for all the non-deterministic choices of p( j). finally, each non-deterministic choice of pm may contribute to non-refinement( k).



example 4.8 assume that we want to find an index t pointing to the smallest element in an array a[1..n], where n is the length of the array and n> 0. a program for finding such a minimum can be expressed in our programming language as follows:



it can be seen from the first three approximations that our normal form approximations represent computation paths as guarded commands. as the approximation progresses, more and more paths are included. obviously, the normal form approximations of the whole program, including the initialisations of k and t, can be easily obtained by substituting 2 for k and 1 for t in s1, s2,....



the first test case generation law(definition 3.4) is a general criterion for faultbased test cases. it is not completely new, but has been translated from our previous work to the theory of designs. it states that a test case in order to find a fault in a design(which can range from specifications to programs) must be an abstraction of the original design, and in addition, it must not be an abstraction of the faulty design. no such test cases exist if the faulty design is a refinement of the original one. note that the translation of this criterion from a different mathematical framework was straightforward. since our previous definition was solely based on the algebraic properties of refinement, we just had to change the definition of refinement(from weakest precondition inclusion to implication). this demonstrates the generality of our refinement-based testing theory. in we applied this technique to labelled transition systems.



the second test case generation law(theorem 3.8) is more constructive and specialised for designs. it can be applied to specification languages that use preand postconditions, including vdm-sl, rsl, z, b and ocl. its finding is based on the conditions, when refinement between designs does not hold. it uses the operations on predicates(conditions and relations) to find the test cases. this approach forms the basis for our constraint solving approach to generate test cases from ocl specifications in.



tai and su proposed algorithms for generating test cases that guarantee the detection of operator errors, but they restrict themselves to the testing of singular boolean expressions, in which each operand is a simple boolean variable that cannot occur more than once. tai extends this work to include the detection of boolean operator faults, relational operator faults and a type of fault involving arithmetic expressions. however, the functions represented in the form of singular boolean expressions constitute only a small proportion of all boolean functions.



burton presented a fault-based test case generator for z specifications. he uses a combination of a theorem prover and a collection of constraint solvers. the theorem prover generates a disjunctive normal form, simplifies the formulas and helps in formulating different testing strategies.



