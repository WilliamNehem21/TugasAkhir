we have developed a command line tool to detect nano-patterns for methods in java bytecode class files, based on the asm bytecode analysis toolkit. our tool reads in a class file name specified as a command line argument, and dumps out a bitstring of nano-patterns exhibited for each method in the class. the detection tool is written in java; it is only 600 source lines of code. our code makes extensive use of data structures and visitor code from the asm api. the tool operates in two different ways to detect specific nano-patterns:



we envisage that it should be possible to automate the generation of asm-based detection code for specific nano-patterns, given some kind of formal specification of the nano-pattern characteristics. a meta-language like jtl may be useful here. we do not address this issue in the current research.



they are stored in library container data structures. even with addition of generics in java 5 source, type casts are still present in java bytecode for retrieving objects from container data structures. therefore this rule is an idiomatic artifact of the java source to bytecode transformation.



such methods take a single argument, write this value to a field of the current object and return void. the code listing below gives an outline example. one would expect to see this kind of rule for well-written programs in any object-oriented language.



detection of high-level design patterns from low-level nano-patterns. in general, design pattern discovery is acknowledged to be difficult[14,9]. we have shown above that some combinations of low-level features are potential indicators for higher-level patterns. gueheneuc et al explore this concept further, although with a possibly more restrictive set of static code features.



identification of potential bugs. given a large and varied corpus of code, we can extract a set of high-confidence association rules. if these rules are not kept in new code, an online interactive checker can inform the developer of the rule violations.



the specjvm98 benchmark suite was originally intended to evaluate the performance of commercial java virtual machine(jvm) implementations. however due to its small size and relative age, it is now only used as a target for academic research such as points-to analysis. a potential replacement for specjvm98 is the dacapo benchmark suite, compiled by an academic research group. the dacapo introductory paper presents an extensive empirical study to highlight the differences between these two benchmark suites. the authors claim that dacapo is superior to specjvm98 for two main reasons:



a higher proportion of methods create objects in dacapo, and it also has many more type manipulating methods. these are clear indications of object orientation. on the other hand, there are similar amount of object field reading for both suites. interestingly, specjvm98 seems to perform much more object field writing. we investigate the difference between accesses to static and instance fields, since fr and fw cover both static and instance accesses by definition. again we found similar statistics in both suites: around 20% of reads are to static fields, and less than 10% of writes are to static fields.



one potential limitation of this study is that the nano-pattern catalogue does not presently capture all object-oriented behaviour. for instance, we do not have any measure of method overriding via virtual method calls. also we make no distinction between accessing object fields through a this pointer and other pointers. perhaps a richer set of nano-patterns would provide a clearer picture.



nano-patterns can be used to indicate similarity between methods; we assert that similar methods should exhibit similar nano-patterns. the dacapo paper criticizes the specjvm98 benchmarks for being overly similar. the authors take a set of architectural metrics for each benchmark and perform a principal components analysis with four dimensions. they show that the dacapo programs are spread around this 4-d space, whereas the specjvm98 programs are concentrated close together.



analysis based on nano-patterns is entirely static. for a true comparison between the benchmark suites(especially in relation to diversity) it would be better to look at both static and dynamic behaviour. the dacapo study focused entirely on dynamic behaviour, whereas we have only looked at static behaviour here. however we reach the same conclusions in relation to intra-suite diversity.



ison of the benchmark suites in isolation. often these particular java benchmarks are used to compare static analysis techniques(as opposed to runtime jvm performance) in which case, static object orientation and diversity become the main concern. hence this style of empirical comparison based on nano-patterns is indeed valuable.



clustering is a form of unsupervised learning. it is used to group data points into a variable number of clusters based upon a similarity measure, usually a distance metric. this enables a quick characterisation of data into higher level groupings. in this particular context, we aim to cluster similar methods to enable program comprehension, where method similarity is based on nano-pattern bitstrings. there are two main obstacles:



we note in passing that there has been previous work using clustering to analyse java methods. however our set of static method features appears to be richer than in earlier work. the application area for this analysis is mostly program comprehension.



