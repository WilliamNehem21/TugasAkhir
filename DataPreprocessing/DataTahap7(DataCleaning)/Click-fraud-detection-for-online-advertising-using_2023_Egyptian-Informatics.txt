the remainder of this paper is structured as follows. section 2 presents and discusses related studies. in section 3, the proposed research methodology is demonstrated. the evaluation results are discussed in section 4. finally, we conclude and discuss future work in section 5.



layer to enhance classification accuracy. finally, the classification was conducted at the fourth layer utilizing a decision tree classification algorithm. the developed model was applied to a combination of two open-source datasets: ctu-13 dataset of botnet traffic, consisting of thirteen scenarios using different botnet samples, and isot, which contain both malicious and benign traffic. they applied 10-fold cross-validation and achieved an accuracy of 98.7%.



notably, the provided datasets are unbalanced because the human dataset is almost 28 times the size of the bot dataset. unbalanced datasets are considered one of the common challenges when creating any intelligent model. several methods were proposed in the literature to address this problem. among others, under-sampling is the most commonly used technique. this research used the under-sampling method by randomly selecting a subset of examples from the human dataset. hence, 86 random samples were chosen from the human dataset and merged with the bot dataset resulting in an almost balanced training dataset.



validation involves evaluating whether the mathematical models assessing relations amongst features sufficiently explain the dataset. normally, an error estimation for the produced classification model is created as soon as the training phase is completed. however, the main concern with such a strategy is that it will not clarify how well the produced classification models might work on the unseen dataset. on the other hand, cross-validation



f1 score: f1 provides an overview of both precision and recall by taking the harmonic average of both. it is sometimes used in place of accuracy. precision and recall are inverse metrics and often juxtaposed, meaning that as you optimize for one, the other worsens. sometimes it is more desirable to optimize for precision and sometimes for recall.



tp, fp, fn, and tn have specific meanings in this research. for instance, tp denotes the set of examples correctly classified as bots. tn represents the set of examples accurately categorized as human. fp represents the set of examples that are classified as bots ing very few discriminative data points that can be used to determine if they are bots or humans. nb produced the worst classification performance in terms of all evaluation metrics. this can be justified because nb assumes all input features are independent and gives every feature the same level of importance when building the classification model. however, this assumption is not always accurate because some features might be more important than others when building classification models and should garner more attention when creating the classification models.



