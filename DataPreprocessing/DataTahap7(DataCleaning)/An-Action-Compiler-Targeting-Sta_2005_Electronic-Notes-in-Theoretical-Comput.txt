we present an action compiler that can be used in connection with an action semantics based compiler generator. our action compiler produces code with faster execution times than code produced by other action compilers, and for some non-trivial test examples it is only a factor two slower than the code produced by the gnu c compiler. targeting standard ml makes the description of the code generation simple and easy to implement. the action compiler has been tested on a description of the core of standard ml and a subset of c.



an action. the front end is then connected to an action compiler, and the result is a compiler for the described language. previous results[20,21] have shown that it is possible to generate compilers that produce code that is less than ten times slower than the code generated by handwritten compilers, and in some cases even as fast as only two times slower. some restrictions have been put on the actions handled by the compiler to achieve this result, and often the implementation of the code generator in the action compiler is very complicated.



an action compiler annotates and transforms the action in several steps. our action compiler performs type inference(section 3) and code generation(section 4), but no optimizations on the action as seen in previous results. instead we generate code that can easily be optimized by mlton.



action semantics(as) is a hybrid of denotational semantics and operational semantics. as in a conventional denotational description, inductively defined semantic functions map programs(and declarations, expressions, statements, etc.) compositionally to their denotations, which model their behavior. the difference is that here denotations are actions instead of higher-order functions.



actions are expressed in action notation(an)[12,16], a notation resembling english but still strictly formal. an consists of a kernel that is defined operationally; the rest of an can be reduced to kernel notation. actions are constructed from yielders, action constants, and action combinators, where yielders consist of data, data operations, and predicates. yielders are not part



the performance of an action might be seen as an evaluation of a function from data and bindings to data, with side effects like changing storage and sending messages. we shall often refer to the input data/bindings of an action as the given data/bindings. the action combinators correspond to different ways of composing functions to obtain different kinds of control and data flow in the evaluation. the evaluation can terminate in three different ways: normally(the performance of the enclosing action continues normally), abruptly(the enclosing action is skipped until the exception is handled), or failing(corresponding to abandoning the current alternative of a choice and trying alternative actions). an has actions to represent evaluation of expressions, declarations, abstractions, manipulation of storage, and communication between agents. the yielders can be used to inspect memory locations and compute data and bindings.



in section 2 we present the action environment which serves as a front end generator in our compiler generator. type inference of actions is an essential part of generating efficient code from actions, and the subject of section 3. the main contribution of this paper, namely the rules for translating actions into sml, is described in section 4. before evaluating the action compiler in section 6 we take a look at previous work on compiling actions in section 5. in section 7 the limitations of our action compiler are discussed. section 8 concludes.



how the type information is used will be explained in section 4. knowing that we translate actions to sml and that the sml compiler does type inference, one might wonder whether this type inference is necessary. if the sml code can be produced without knowledge of types, the sml compiler could try to infer a type and thereby check that the input action is type correct. the problem with this approach is that the generated sml code would be less efficient if the code generator could not take advantage of type annotations. to give an example, the translation of the and combinator(rule 4 in



in this section we will look at a representative selection of the rules; the rest can be found in the appendix. we shall use a to range over actions, o to range over data operators, e to range over sml expressions(e.g., anonymous functions), d and i to range over sml identifiers, n to range over integers, i and j to range over labels, and t to range over types. some rules use the function t that takes an action and returns its type. the type of an action is of course context dependent and has been derived by the preceding type inference. we shall also assume that all identifiers occurring in an action have been mapped into identifiers that are not reserved words in sml.



the action copy has the simplest translation(rule 1) since it just returns the data given to it. translating result d is only a little bit more complicated(rule 2); here the data d produced by the action must be translated into an sml expression e. if the data d is an action it is translated using the rules, in other cases it is translated into sml representations of the data, e.g., integers and booleans are just translated to the same integers and booleans.



an contains a number of builtin data operators on integers and booleans that can trivially be translated to corresponding sml data operators. the builtin data operators on binding maps(operators for creating single bindings, looking up bindings, uniting binding maps, etc.) are translated into selection of elements from records and construction of records. to translate these data operators the type information about the given bindings is used. asdf lets the user specify data and data constructors, and these are also translated into sml by the action compiler.



the actress system showed how to compile actions into c code. the compilation involved several action optimizations where the most important one was binding elimination. the system has been tested on a specification of a small imperative language called specimen, and the running time of the generated c code for some programs has been compared to running times for implementations of the same programs in pascal. this comparison shows that the generated c code is between a factor 5 to 28 slower than the compiled pascal code. the rules describing the code generation are complicated because they use a set of variables to pass data between actions and must keep track of which variables are used and have been used by sub-actions.



continuing the work done by brown, moura and watt on the actress system, kent d. lee developed the genesis system. the systems have many similarities with respect to type inference and action transformations, but instead of generating c code, genesis generates java bytecode. one advantage of this is the portability of the generated code. as with the oasis system, the low level target language makes code generation complicated, and special transformations of actions are needed. lee does not present any evaluation of the generated code.



a somewhat different approach has been demonstrated by bondorf and palsberg in. by writing an action interpreter in scheme and applying the similix partial evaluator, they were able to generate an action compiler that generates scheme code. the advantage of this approach is that it is easier to write an action interpreter than an action compiler, and the hard work is done by similix. should an change it is also easier to update an action interpreter than an action compiler. their evaluation of the generated scheme code shows that it is almost 100 times slower than code generated by a hand written compiler.



in gentle the specification of a compiler is done in a logic programming language which is used in all parts of the specification. the specification language resembles prolog but is more restricted and therefore the unification algorithm could be optimized. in vollmer reports that gentle generates very efficient compilers with respect to compilation time, and that user experience shows that developing compilers in gentle saves time compared to hand-coding compilers.



the test programs exploit both the functional and the imperative aspects of the core ml language. the second column shows the running time for the output from the action compiler. the third column shows the running time for the program compiled with the mlton compiler, and the last column shows how many times slower the output from the generated compiler is.



on this program. the problem with tail recursion is not noticeable in the recursive fibonacci program(fibo), because the recursive function there is not tail recursive. in the as description of core ml the action representing a function is wrapped in a data type, and this is the main reason for the bad results when running the church test program which exploits higher-order functions.



the compiler generator has also been tested on a small subset of c. the subset includes simple expressions, assign-, ifand whilestatements, statement blocks, variable declarations, and recursive functions. the values are integers and arrays of integers, but no pointers. the seven test programs are:



comparing a compiler generated from a subset of c with a compiler for the whole c language is of course not fair. it is likely that the generated compiler will become less efficient when we extend the subset of c, especially if we allow more data than just integers and arrays of integers. adding more features often means that the simple semantics of a construct is replaced by a more complex semantics, for instance, adding pointers and floats to the subset of c would mean that the semantic of+ becomes more complicated because the operator should now be overloaded. on the other hand our compiler generates code that performs bounds checking on arrays, which the gcc compiler does not, which makes the generated compilers less efficient.



support for user defined data types is work in progress. currently we support the data defined in the asdf modules as part of a language description. it is only possible to describe languages where the user can define his own data types to some extent. the length program in section 6 is an example of how the user can define a list data type in the core ml language, but the description of data types in core ml is not fully supported by the action compiler yet, and only works on some examples. the representation of data is the main reason for performance loss in the generated compilers.



future work includes investigating how to generate code that is easier for the sml compiler to optimize. especially the way data is represented in the generated code needs improvement. relaxing the restrictions put on actions would also improve the system. improving the type inference algorithm such that it accepts a bigger set of actions, would allow more natural descriptions of languages, but here we are also limited by the target language(sml) being strongly typed.



