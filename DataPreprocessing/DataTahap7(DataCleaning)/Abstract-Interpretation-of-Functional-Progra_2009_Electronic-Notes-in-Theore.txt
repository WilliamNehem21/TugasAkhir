we describe an algorithm for abstract interpretation of an intermediate language in a haskell compiler, itself also written in haskell. it computes approximations of possible values for all variables in the program, which can be used for optimizing the object code. the analysis is done by collecting constraints on variables, which are then solved by fixpoint iteration. the set of constraints grows while solving, as possible values of unknown functions become known. the constraints are collected by decorating the abstract syntax tree with an attribute grammar based preprocessor for haskell. an introduction to this preprocessor is also given.



in a naive implementation, the function reference can be a tag, and a special evaluation function performs case distinction on this tag. peyton jones et al. describe an encoding, where the tag is actually a pointer to the code of the function[13,11]. evaluating a closure now amounts to just calling that code. on modern pipelined processors, this is a costly operation, as it stalls the prefetching pipeline. therefore, boquist proposes to return to the naive encoding. to avoid the overhead of calling the evaluation function which



to do the pruning it is necessary to know for each closure what its possible tags are. this is to be determined by a global control flow analysis. boquist sketches an algorithm for this abstract interpretation. here we present a full implementation we employ in our experimental haskell compiler(a few left out details can be found in an accompanying technical report).



the implementation is presented by giving the actual code. we use a preprocessor for haskell that enables us to use notions derived from the realm of attribute grammars. this makes the code concise enough to present it(almost) in full. to make the paper self-contained, we include a description of this preprocessor as well. the aim of this paper is twofold:



we describe the main features of the preprocessor here, and explain why they overcome the five problems mentioned above. the abstract syntax of the language is defined in a syntax declaration, which is like a haskell data declaration with named fields, without the braces and commas(see section 3 for an example). constructor function names need not to be unique between types. the preprocessor generates corresponding data declarations(making the constructors unique by prepending the type name, like expr const), and generates a custom fold function. this overcomes problem 1.



in many situations, sem rules only specify that attributes a tree node inherites should be passed unchanged to its children. to scrap the boilerplate expressing this, the preprocessor has a convention that, unless stated otherwise, attributes with the same name are automatically copied. a similar automated copying is done for synthesized attributes passed up the tree. when more than one child offers a candidate to be copied, normally the rightmost one is taken, unless we specify to use an operator to combine several candidates:



we describe a slightly modified version here by means of syntax declarations for the ag preprocessor. we do not provide a concrete syntax for the language, as grin programs are only an intermediate representation. we start with a definition of toplevel constructs. a program consists of a name, and a list of function bindings. each binding binds a parameterized name to an expression.



grin programs manipulate five kinds of values: integers, standalone tags, nodes with a known tag and a list of fields, pointers to a node stored on the heap, and the empty value. the first three have a direct syntactic representation as a term, pointers and the empty value have not. another possible term is a variable, which can refer to any of the five kinds of value.



two constructs have a side effect on the heap: store, which stores a node value in a new heap cell and returns a pointer to it, and fetchupdate, which copies the contents of a heap location to another location, and returns the empty value. next, we have call for calling a grin function. boquist proposes the use of two builtin functions eval and apply, which can be called to force evaluation of a variable, or to apply an unknown function in a strict context, respectively. as these functions behave quite different from ordinary functions, we include special constructs eval and apply for these cases.



in this section we describe an abstract interpretation algorithm, which solves a set of constraints by fixpoint iteration. constraints are first collected in a walk over the tree that represents the grin program. we start with a description of an abstract domain, and a language for specifying the constraints.



in the abstags case, abstract interpretation reveals to which tags a variable can possibly refer. similarly, for abslocs we determine to which locations a pointer can point. in the absnodes case, we not only determine the possible tags of the nodes, but for each of these also a list of the abstract values of their parameters. as for concrete values, the elements of the fields of a node are never absnodes themselves, but can be abslocs pointing to locations which store inner nodes.



in the case of a unit we distinguish the four combinations of target pattern and source term(each variable or node). when both are variables, the target is constrained to hold a superset of the source; when the target is a variable and the source is a node, the target can hold that node. if the target is a node and the source is a variable, all the fields of the node should be projections of the source variable. when both are nodes, their corresponding fields should be unified. for the last two cases we have auxiliary functions:



an alternative approach to collect information on a syntax tree is using asf. in comparison, the ag approach is lightweight, in that it relies on the underlying language for the definition of semantic rules. yet another approach would be to provide combinators that manipulate attributes within the language, instead of as a preprocessor.



the information revealed by the abstract interpretation is detailed enough to do the intended inlining of eval and apply expressions. ultimately we strive to replace indirect jumps by a resonable number of direct branches. this depends on more optimizing transformations in the compilation pipeline which we have not yet implemented all, so we can not yet be decisive whether the optimizations have the desired effect.



