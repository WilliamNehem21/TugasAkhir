global wire delays are one the most critical issue in designing systems-on-chips(soc). with recent nanometer technology processes, global wire delays do not scale anymore. most industrial cad flows are all based on the synchronous hypothesis, that imposes strict unitary delays for communication(and explicit lines of repeaters to divide long wires). this may incur that designers need to take these delays into account when designing the local intellectual property(ip) blocks themselves(those



definition 2.1[computation network scheme] we call computation network scheme(cns) a graph whose vertices are called computation nodes, and whose arcs are called links. we also allow arcs without a source vertex, called input links, or without target vertex, called output links.



definition 2.2 a marked graph is a cns where time is asynchronous: computations are performed independently, provided they find enough tokens in their incoming links; links have a place holding a number of tokens; in other words, marked graphs form a subclass of petri nets. the initial marking of the graph is the number of tokens held in each place. in addition a marked graph is said to be of capacity k if each place can hold no more than k tokens.



the shell wrapper in lid leads the pearl to work as soon as all input datas are present. the interconnection element of latency-insensitive design is a 2-places capacity buffer named relay-station. moreover, the back pressure protocol ensures this capacity is never overflow. these two features of a lid are both present in a smg with place of capacity 2.



definition 2.8 a statically scheduled lid is a lid where the expanded smg obtained as above uses places of capacity either 1 or 2 in between cns and tns. this reduction of capacity is possible because the static schedule of the lid ensures places do not overflow. the graph throughput and explicit schedule of each cn is known.



its period p and its periodicity k: a ssip has an ultimate periodic behaviour. it consumes and produces k values in p instants. the throughput of the ssip is k. k and p are computed from the internal network of the ssip.



from the point each ssip are independantly designed, the rate( k) of each ssip is different. the composition of these ssips with other one, gals components or synchronous components works at the rate of the worst. all other ssip have to be slow down without changing there internal behaviour. this can be easily done using clock gating managed by the state of input and output buffers. if input buffer is empty or if output buffer is full, this means the ssip work too fast for respectly input component(s) and output component(s); in these two last case, neither valid inputs nor place to stock valid output are present.



generally, we are just inserting a gals interface on the input/output side of the ssip. this interface is able to handle a specific synchronization protocol certifying correctness of the behaviour, providing necessary buffering ressources and needed clock synchronizers. that is to say we do not know anything about such components, there is no no assumption about the periodicity, the throughput of the component. we assume the worst case: its chaotic behaviour is propagated to other components through the synchronization protocol. then, a control-flow protocol such as latency insensitive protocol is needed between all components of the gals to ensure correctness of the behaviour. this protocol is also used to prevent the input component production to attain the maximal buffering capacity in input of the concerned component. in this case, the system works without more buffers than needed by the protocol.



the size of the interconnection fifo is bounded by the maximal value between the periodicity of the connected component and the periodicity of the ssip(k). in worst case, the element with the biggest periodicity(k) produces/consumes all its data in k instants and stay inactive during the rest of its period. the two previous conditions about clock rate ensure that the connected element consume/produce enough data before the next period.



however, in the case of strongly connected sdf graph there is no strong theoritical result that ensures liveness just like in the case of event/marked graph. we known the minimum amount each node should fire during a whole period but not the explicit schedule for each node taking care of the initial marking. moreover, we do not known the size of the buffering places needed between each ip.



the composition in the case of a fully-synchronous framework is more complex, because a synchronous circuit is not patient. we need a lot of buffering in order to absorb advance/retard of the ssip versus the synchronous environment, we found an upper bound of such buffering which is dependent on k(is the number of occurences of firing of the ssip during a period of length p). the initialization of the global system is more difficult, we have to delay the startup of downward synchronous circuits until the ssip is reaching its stationary regime: because the ssip can be slower or faster than the synchronous circuit during initialization, we may add some buffering in the fifos on both ends of the ssip to absorb the local lack/burst of throughput.



