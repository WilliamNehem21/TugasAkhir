in reality, most of time, machine is idle, resulting in a significant waste of computing power. when using the task manager under windows or other tools under linux platforms(such as top, xload) to observe the cpu, we will find the common utilization of the cpu is just among 1 to 2 percent. in fact, if there are more computers, the waste will be intensified. in a department that includes 300 computers, the idle rate of cpu is amazing. however, these sectors still need powerful servers to be used to compile or simulation. sometimes this situation will be exacerbated, because with the increase of users, more than one even if the 8 cpu servers, nor can the full load duty of landing to another free server because users rarely change their habits to log in another server. if you can take advantage of the existing computing resources and idle cpu utilization, or allow the migration of load on the server smartly, it will be a very happy thing.



in recent years, grid technology with the compatibility of heterogeneous resources become the research focus of the industry, providing a new theoretical and technical support for us to build heterogeneous clusters. the computer's cpu, memory, disk, network parameters vary on intranet, so the system formed by connecting them together simply is not a cluster. they must be clustered and divided into logical computer clusters of different calculation types, and then allocate computing tasks. in order to effectively divide clusters, we proposed the study and implementation of fuzzy-based cluster model(fuzzy-based cluster model) which have practical significance in integration of existing idle computing resources to be a computing device.



the parallel and serial attribute of computing tasks essentially determines the application efficiency of the cluster. the operating efficiency of each node is the computing essence of the node. therefore, when fuzzy clustering, the parameters of one or several key attributes corresponding to a task is very important given relatively large weights, so that the impact of the attribute parameters with large weights for similarity is relatively large, the division of cluster can be based on the characteristics of the task, and adapt to the task.



(where k1= k2= k3= k4= k5= 0.2, if the similarity is too small, it does not make sense, so the coordinate origin moved to 0.9, the specific move to where depending on the application, here according to the values of the last 30 sample computers).



(computer using the serial number, self-group: the computer serial number to be a group alone)according to the classification results, we can easily find, with the weight of cpu gradually reduce, degree of cpu concern is getting smaller and smaller. for example, in the first category, when the cpu's weight 0.8, only 1,4, when it reduced to 0.4, 2,3,7,8,9 is added in. it can be seen even if there are some differences on the cpu, but considering the other factors, it is quite similar. when it reduce to 0, without considering the cpu, the addition to the number of the computer which other aspects are similar will be more, and cpu is somewhat similar, but the other four areas are not very similar is excluded. so that by adjusting the weights will be able to better control the properties of interest.



(computer using the serial number, self-group: the computer serial number to be a group alone)it can be seen that the cluster will be increased when clustering threshold increases, and the number of self-group is also increased, so that the characteristics of each computer in the cluster will be even more distinctive, and the internal similarity of each cluster will be more closer, the granularity of the cluster smaller that forms very similar cluster. small clusters formed with a larger threshold can not be separated when clustering with a smaller threshold. experiments verify the theoretical results.



