training a neural network to reconstruct images from time-series waveforms obtained from fiber optic probes not only yields high-quality, content-aware images but can also acquire different types of images from lower quality training images. image reconstruction, as an inverse problem, involves using collected signals and system models to retrieve desired images, encountering mathematical challenges like distortion and degradation. in this paper, we introduce recanet, a multi-mode fiber image restoration model based on an enhanced residual convolutional neural network(cnn). the network employs a symmetrical architecture that downscales the image before upscaling it for restoration, and it reconstructs the high-level semantic feature map generated by the encoder to the original image resolution. additionally, we incorporate weight initialization, attention mechanisms, and residual connections to enhance the final restored feature map with more low-dimensional features and promote fusion of features from distinct layers. the algorithm performs well on three datasets collected by multi-mode fibers, namely minist, clothes, and omiglot. among them, various indicators such as ssim have been significantly improved.



fiber optic transmission image restoration. fan p et al. used pre-trained autoencoders to reconstruct images from multimode fiber imaging systems. zhu c et al. achieved the same fidelity level as cnn in image reconstruction through a single hidden layer dense neural network.



although there has been extensive research on multimode fiber transmission image restoration in the past few years, it is still a challenging task due to the relatively complex operation of the physical instruments used for multimode fiber transmission and its special characteristics compared to other image restoration tasks. first, after the input image is transformed into a signal through a series of physical operations, some features of the original image may be lost due to compression. some of the lost features will cause a lack of key information in two-dimensional image restoration, making it impossible to distinguish between two similar images. based on the challenges discussed above, this paper proposes a new neural network based on unet called recanet.



network, recanet adopts initialized weights, adds vertical skip connections for each convolution block in the network, and introduces ecaattention mechanism modules in each downscaling or upscaling process, which makes the overall network perform well while remaining lightweight. qilong wang et al. designed this efficient channel attention module, by replacing the fully connected layer in the channel attention module with a one-dimensional convolutional layer, they realized a lightweight attention module. currently, recanet has achieved high accuracy and low time consumption in multiple benchmark tests.



furthermore, the center-extended convolution can be employed in a cascading manner to improve the performance of our method. the encoder section consists of five downscaling layers. when processing an image with dimensions of 64x64, the output feature map generated by the encoder measures 8x8.



gradient of the activation function in the middle layer from exploding or disappearing during the forward(forward) propagation of the deep neural network. for image restoration, it is important to determine which features of the waveform are important and need to be focused by the neural network. at the same time, the default initialization of the network is all 0 initialization, which is easy to make the gradient close to each other. in order to make the gradient have greater discrimination, so that different dimensions have different performances and show more features, the weight initialization is used, and the problem is solved.



cognitive attention. this effect enhances some parts of the input data while reducing others, motivated by the idea that the network should pay more attention to smaller but important parts of the data. learning which part of the data is more important than the other depends on the context, which is trained via gradient descent.



the core idea of ecaattention is to use the global average pooling(gap) operation to perform overall statistics on the features of each channel. by exchanging the channel features for location-independent global information, ecaattention can capture the relationship and context information inside the channel. this enables the network to better understand the importance between different channels and improve the expressiveness of the feature map.



our goal was to train the model on the training set, fine-tune the model parameters based on the validation set, and evaluate the model performance using the testing set. during training, we fed the training set samples into the model in batches, performed forward propagation to obtain the current prediction value, compared it with the restored image label, and calculated the mean squared error(mse) as the model loss value. mse is a common loss function for regression problems that effectively measures the difference between the model predicted value and the actual target value, the mse function is shown as follows.



main reasons to add skip connections: the first is to avoid the problem of vanishing gradients, which makes it easier to optimize the neural network. the gating mechanism facilitates information flow across multiple layers, or mitigates the degradation(accuracy saturation) problem. simply adding deeper structure to the model of will lead to other changes, such as loss fluctuation or vanishing gradient, which is a serious degradation phenomenon. another point is that the edge of the feature map of larger size obtained by deconvolution is lack of information. every down-sampling and extracting features will inevitably lose some edge features, and the lost features cannot be recovered from up-sampling.



in optical fiber transmission image restoration problems, each feature is crucial, especially when the image size is small. the edge features convolved can be directly extracted via skip connections, serving as a reference during upscaling to enhance the image restoration quality. this approach also helps to avoid the issue of non-recoverable edge features following convolution.



this article proposes a convolutional neural network called recanet for image restoration in multi-mode fiber. recanet preserves detailed information while integrating multi-scale features in the central part by enlarging the receptive field, which can to some extent address the sparsity of the two-dimensional waveform features obtained from the fiber. the attention mechanism module allows for better focusing on the key features in scarce features. however, recanet still has issues with restoration accuracy, and we plan to conduct more research to address these problems in functionality.



lawandy n m, balachandran r m, gomes a s l, et al. laser action in strongly scattering media[j]. nature, 1994, 368(6470): 436-438. yoon s, kim m, jang m, et al. deep optical imaging within complex scattering media[j]. nature reviews physics, 2020, 2(3): 141-158.



