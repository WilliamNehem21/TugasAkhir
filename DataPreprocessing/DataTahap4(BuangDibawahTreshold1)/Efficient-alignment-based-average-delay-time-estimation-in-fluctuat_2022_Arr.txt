We propose an alignment-based average delay time estimation algorithm between two time series in the propagation of time-varying delay. Though the number of the minimum cost alignments may be exponential in the length of the time series, the proposed algorithm takes account of all such alignments, and as a post- alignment process, it runs in time linear in the number of the nodes in the minimum cost alignment graph, which is at most the length squared. The efficiency of our algorithm is confirmed through numerical experiments compared to the naive enumeration algorithm using recursive calls to traverse the graph.

Time delay estimation among signals has been studied well in the fields of sonar and radar systems, seismology, geophysics, etc. [1]. In most studies of those fields, constant delay for a moment is assumed and the cross-correlation method [2] is most widely used for the estimation. Improvement using more realistic models [3,4] and spatial prediction technique [5] has been done since then.

to calculate the delay time averaged over all the aligned positions in all the minimum-cost alignments, which we call the mean time delay by the minimum-cost alignments. You can enumerate all the minimum-cost alignments and calculate their delay time at each aligned position one by one, then average them. Unfortunately, this strategy is inefficient in the worst case because the number of the minimum-cost alignments can be exponential in the length of the time series.

culation way for the warping-based cost is proposed with its process for our introduced example, and the time and space complexities are analysed in Section 3. In Section 4, we show the efficiency of our calculation way by numerical experiments compared with the naive calculation way. We conclude by summarizing the paper and describing its future direction in Section 5. Calculation way for the gap-based cost is explained in Appendix to clarify the slight difference in calculations between the two types of costs.

