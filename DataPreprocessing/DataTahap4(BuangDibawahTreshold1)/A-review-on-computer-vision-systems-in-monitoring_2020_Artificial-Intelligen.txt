sensor, image processing board, software, and hardware. The camera sensor converts photons to electrical signals. In chicken monitoring sys- tems, visual light-based (charge-coupled devices (CCD) and comple- mentary metal-oxide-semiconductor (CMOS)), thermal and infrared (IR) depth-based sensors have been applied to acquire chicken images in different farm environments. The image processing board is also known as the digitizer, converts the visual image into numerical form (pixels). The software is the underlying image analysis code that per- forms image manipulations to achieve the desired output. Different pro- cessing algorithms have been developed and applied to the acquired images to perform the objective tasks based on a specific programming framework such as Matlab, ImageJ, and OpenCV, to mention a few. The hardware refers to all the connected components that make up the computer vision system, i.e., a camera sensor, connecting cables, com- puters, etc.

abnormal, and disturbed behaviors (Bessei, 2018). Furthermore, from the studies of Hughes et al. (2018) based on human and animal neural responses, under constant conditions, then the welfare situa- tion won't be considered as well-being even in good conditions and management if the psychological balance isn't offset. Finally, animals are complex individual and time-variant (CIT) systems that are indi- vidually different and respond differently at different moments. Thus, they can't be analyzed as a typical classical steady-state system (Berckmans, 2006). Moreover, welfare condition indicators can be contradicting, and according to Alm et al. (2016), presently, there is no consensus on the ideal technique to access animal welfare. PLF itself hasn't lived up to its expectation. Lehr (2014) presented the main obstacles to the implementation of PLF as, lack of consistent marketing, lack of direct cooperation between farmers, biologists, engineers, and economists, little focus on data interpretation and control, the technological gap between consumers and modern farming, and lack of awareness, animal complexities, lack of robust- ness of developed techniques and technologies, and the difficulties and reliability of PLF systems in commercial farms. Despite the men- tioned hindrances on assessing animal welfare and adoption of PLF, studies have reported on several PLF techniques in the monitoring of various bio-responses and bio-processes aiming at improving effi- ciency, animal health, welfare, and farm economy in large-scale chicken production.

Several research efforts have been reported in literature on the development of computer vision systems for chicken monitoring of welfare-related issues such as weight, lameness, behaviors, temper- ature, activities, and health (Aydin, 2017a, 2017b; Mortensen et al., 2016; Okinda et al., 2019; Wang et al., 2019b; Zhuang et al., 2018; Zhuang and Zhang, 2019). This review aims at providing a proper synthesis of literature to provide clear guidance on the state-of- the-art techniques and the potential future direction on the monitor- ing of welfare-related bio-processes and bio-responses in chicken production. Therefore, this work will focus on up-to-date research advances to provide useful technical information for the develop- ment of more relevant and reliable computer vision techniques for the monitoring of welfare-related bio-processes in chicken production.

served in the study by Mortensen et al. (2016), where multiple broilers could be detected in a depth image, based on a height function defined over a depth image based on the watershed segmentation method. Sim- ilarly, in the study by Okinda et al. (2019), the background was removed by a simple depth threshold and image subtraction.

Not all the extracted regions after foreground detections are often the ROI (may contain noise and misclassified pixels). A region validation is usually applied to improve quality by removing regions that aren't consistent with the features of the ROI. These are often artifacts present in the background, such as droppings and shadows due to feathers and the head within the foreground (Amraei et al., 2017a, 2017b; Mollah

Locomotor features are one of the most important characteristics used to identify poultry gait score (GS) and have been widely applied in the monitoring of birds regarding lameness, activeness, and health. Generally, monitoring poultry mobility helps to detect the occurrence of an infection and infestation, and provides a basis to evaluate if the management procedures and environmental conditions are conducive (Aydin, 2017b, 2017a; Okinda et al., 2019). Based on the idea by Winter (1985), the movement of a subject is an effort rather than the cause of the underlying problem. Hence, the locomotor features can be subdivided into two categories, i.e., kinematic and kinetic features.

Kinetic analysis was introduced as a technique to analyze the pain levels by the pressure a bird exerts on a particular foot. Kinetic features are calculated by analyzing the walking forces on the toes of a chicken such as forces on the middle, medial, back, and lateral toes and metatar- sal pad as a chicken walk on a pedobarographic surface or a piezoelec- tric crystal sensor (Corr et al., 2007, 1998). Therefore, they are never applied in computer vision systems. Additionally, as Caplen et al. (2012) explained, few steps were analyzed in the kinetic analysis due to bird pausing or sitting on the surface; hence, high levels of data redundancy.

Feature selection involves choosing a subset of relevant features after feature extraction engineering before model development. The ex- tracted features may contain irrelevant and redundant variables that would influence the modeling task. A feature selection criterion is re- quired to measure the significance of each feature and to remove extra- neous features, by selecting a subset of variables from an input data that efficiently describes the input while reducing the effects of noise and other irrelevant variables but still capable of producing a generalized model (Chandrashekar and Sahin, 2014). Therefore, feature selection helps to provide an in-depth understanding of the dataset, reduces computational complexities, reduces the curse of dimensionality effects, and improves the general performance of the model. From a data-type perspective, Li et al. (2017) categorized feature selection techniques as similarity-based, hybrid feature selection, information-theoretical- based, statistical-based, sparse-learning-based, reconstruction-based, and deep-learning-based methods. In chicken monitoring systems, few features are always extracted; therefore, most studies don't per- form feature selection. However, Amraei et al. (2017a) and Amraei et al. (2018) performed feature selection based on a statistical-based method (correlation analysis) to select the best predictors in chicken weight estimation.

The modeling step in poultry monitoring systems can be categorized as regression and classification tasks. Based on different modeling tech- niques, the tasks can be performed by conventional machine learning or DL techniques. Machine learning algorithms are computerized model- ing approaches based on sample data (use statistics to find patterns in data) to make decisions or predictions without being reprogrammed time and again (Bhargava and Bansal, 2018; Wang et al., 2019a). Ma- chine learning algorithms are grouped into three categories; Supervised Learning, Unsupervised Learning, and Reinforcement Learning.

Supervised Learning is a governed learning technique that incorpo- rates the use of example inputs and their desired outputs, and the main objective is to learn the pattern (training) that maps the inputs into outputs (Alpaydin, 2020). Supervised Learning involves model training and model testing tasks. The model training process is an essen- tial procedure performed using labeled data as the supervisory signal. Supervised learning algorithms learn a function that can map new in- puts into outputs (prediction) by iterative optimization of an objective function. The model testing is the application of new or unknown data to the trained model and observing the accuracy of the predicted out- put. In chicken monitoring systems, the outputs are weight (regres- sion), health condition (classification), or behavior (classification), among others. Linear, nonlinear, and logit regression, Support vector machine (SVM), Support vector regression (SVR), and artificial neural networks (ANN) are the mostly applied supervised machine learning al- gorithms that have been applied in poultry monitoring systems.

separating support vectors in the training data vectors by finding the appropriate hyperplane. The SVM kernels include linear, polynomial (quadratic and cubic), and radial basis function (RBF) kernels (Nyalala et al., 2019; Okinda et al., 2020). RBF kernel was applied by Amraei et al. (2017b) in chicken weight estimation, while Okinda et al. (2019) applied all the SVM kernels mentioned above in chicken health status classification.

Biological neural networks inspired the ANN machine learning technique. The ANN simulates the way the human brain analyzes and processes information. Therefore, it's a non-linear statistical model. ANN consist of input, hidden, and output layer. The hidden layer transforms the input into output by solving an optimization problem by minimization of a loss function during optimization (Samarasinghe, 2016). The most basic types of ANN are the feedforward neural network and recurrent neural network, which are trained by the Backpropagation algorithms. The number of neu- rons in the hidden layer is often adjusted during training to minimize network error. This can be observed in the study by Mortensen et al. (2016) in the selection of 3 and 10 neurons in the hidden layer. How- ever, these regression models performed reasonably similarly. The Bayesian ANN being a probabilistic model using an ANN regression

ResNets, also known as Deep Residual Networks, presented a solu- tion to solve complex problems in CNNs as the network becomes deeper (vanishing gradients) (Balduzzi et al., 2017). ResNet consists of a series of residual modules (layers), and each layer is a function set to be per- formed on an input with the gradient signal capable of feedback to ear- lier layers via shortcut connections (Balduzzi et al., 2017; He et al., 2016;

and Zisserman, 2014). The MobileNet is essentially a rationalized ver- sion of the Xception architecture optimized for mobile applications. The SqueezeNet is powerful DL architecture that's efficient in low band- width platforms. It is based on a CNN architecture but with 50 times fewer parameters than AlexNet and maintains AlexNet-level accuracy on ImageNet (Iandola et al., 2016). The CapsNet, a multi-layer capsule system, is an advanced variation of CNNs that deepens in terms of nesting or internal structure (Sabour et al., 2017). It's mainly used for accurate image recognition tasks because it is robust to geometric dis- tortions and transformations. Thus, it can exceptionally handle orienta- tions, rotations, and translations.

Recursive neural networks have a return loop to feed the network into itself. This allows for the identification of input data constituents and their relationships through a binary tree structure and shared- weight matrix (Hosseini et al., 2020). Recursive neural networks are characterized by a top-down propagation method and a bottom-up feed-forward method. There are two main types of Recursive neural networks, i.e., supervised recursive neural tensor (applied in computer vision) and the semi-supervised recursive autoencoder (applied in sen- tence deconstruction). The main advantage of Recursive neural net- works over RNNs is that they can capture long-term dependencies efficiently. However, Recursive neural networks suffer from substantial

The LSTM is a special RNN that applies recurrent edges as a solution to the vanishing gradient problem. LSTM use memory cell to hold infor- mation and a set of gates (input, forget, and output gates) to indicate the status of the memory cell (Sundermeyer et al., 2015, 2012). The con- tents of the memory cell are modified by the input and forget gates con- ditions at each time step. The input gate selects the new information that should be added to the cell state. The forget gate selects which in- formation should be discarded from the cell state. The output state se- lects relevant information from the cell state as the output.

GANs involve the training of two DL models (the generator and the discriminator) simultaneously that compete with each other. The gen- erator creates new instances by modeling a transform function during training. In comparison, the discriminator classifies if an instance origi- nates from the generator or the training data, while the former maxi- mizes the final classification error while the later minimizes the error between the generated data and the training data. Thus, the two net- works are referred to as adversaries. Hence, the whole network im- proves with each iteration during training. GANs are widely applied in computer vision, especially in image generation and also in speech, prose, and music because of GANs ability to mimic any distribution of data in any domain (Hosseini et al., 2020).

DBNs are an extensive layered network structured by connecting several smaller unsupervised neural networks. A DBM is composed of Belief Net and the Restricted Boltzmann Machine (RBM) (Hosseini et al., 2020). Belief Net is composed of connected layers (binary unit layers), each assigned a weight function (layer-by-layer learning). The

probability of the binary outcome depends on the weight factor and the bias inputs. RBM is a stochastic RNN designed on the principles of energy-based models (EBMs) (Haque and Neubert, 2020; Hosseini et al., 2020). Learning is performed by minimization of the energy func- tion, and prediction is achieved by determining the values of residual variables that minimize the energy based on observed variables. The RBM consists of one input layer and one hidden layer without an output layer. Another type of RBM is the Deep Boltzmann Machine (DBM), characterized by undirected connections. Hence, DBM is robust in han- dling certainty due to noisy inputs.

Data labeling which involve the creation of bounding boxes is an- other vital pre-processing procedure. Data labeling is often performed manually to reference the ground truth by a bounding box. Labeling software such as LabelImg (Windows-based) is applied to draw the bounding boxes and extract their co-ordinate locations. Ground truth labeling is a vital step in classification tasks as it provides a basis for per- formance evaluation of the proposed detector (Zhuang and Zhang, 2019). The procedures mentioned above are the main techniques that have been applied in poultry monitoring DL modeling systems. Other pre-processing operations include image segmentation to highlight the ROI hence, facilitating the learning process as performed by Fang

Several studies have applied DL models in poultry monitoring sys- tems ranging from behavior classification, tracking, sick birds' detection, to droppings classification. Pu et al. (2018) developed a CNN detector to classify chicken flock behaviors at the feeders using color and depth im- ages (two parameter-sharing CNNs). His network consisted of three convolutional layers, each with a rectified linear unit (ReLU) activation function, a max-pooling layer with a local response normalization step. The system achieved an accuracy of 99.17% in the chicken behavior classification. A Faster R-CNN chicken activity detector combined with the temperature-humidity index (THI) was used to monitor heat stress in chicken (Lin et al., 2018). The detector applied the Zeiler and Fergus network (Zeiler and Fergus, 2014) as the base CNN. The chicken move- ment was determined by tracking the chicken location between subse- quent frames using the minimum distance matching and color feature matching techniques. As already mentioned, the detection speed of

normalization (LRN) layer and a pooling layer for max-pooling between the 1st and 2nd layer and between the 2nd and 3rd layers effectively prevents overfitting. This technique achieved a mixed tracking perfor- mance evaluation of 0.730 at a processing speed of 30.53 fps.

studies have applied other modeling techniques. The transfer function (TF) represents the relationship between the input and the output sig- nals of a control system for all possible input values. The parameters of a TF model can be estimated using several estimation techniques such as least squares (LS), state variable filters approach, instrument variable approach, generalized Poisson moment functions approach, etc. However, due to noise, the model parameters become asymptoti- cally biased when LS is applied. Therefore, Leroy et al. (2006) applied a simplified refined instrumental variable (SRIV) to estimate TF model parameters from an optimal shape posture parameters (ellipse shape

tioned, feature extraction engineering is an arduous task. Therefore, Zaninelli et al. (2018) performed bird recognition from a shape classifi- cation point of view. A normalized cross-correlation was performed be- tween a processed image and a template to detect multiple nest

Several studies have introduced chicken weighing systems based on computer vision based on 2D (Amraei et al., 2017b; De Wet et al., 2003; Mollah et al., 2010) and 3D (Mortensen et al., 2016) images. The basic principle of machine vision-based weighing systems is the correlation of image object shape geometric features to animal weight or volume. This is theoretically simple but quite challenging in a real farm environ- ment. As already mentioned, firstly, the bird's body must be segmented from the background (ROI extraction). Secondly, the chicken's body segmented from the image is to be presented by describing characteris- tics (feature extraction). Thirdly, these describing characteristics are correlated to the bodyweight by a mathematical model.

Poultry weight estimation systems are mainly challenged by varia- tion of ambient lighting conditions and the localization of a bird when in a flock condition. To address the problem of variable light conditions, the solution would be the use of illuminant invariant cameras and flex- ible image sensors in the farm environment. IR-based depth cameras such as the Microsoft Kinect have been applied in weight estimation by Mortensen et al. (2016). However, IR depth cameras are sensitive to sunlight, thus, limiting their application to an indoor environment. However, illuminant invariant visual light-based cameras (Jansen-van Vuuren et al., 2016) are readily available in the market they haven't been applied in poultry monitoring systems. Providing a controlled lighting environment for visual light-based sensors can be another solu- tion, although it's challenging if not infeasible due to farm structure, size, and other complexities. Therefore, the potential research and de- velopment area could be to provide a controlled illumination in the farm environment for image acquisition in farmhouses and the use of il- luminant invariant cameras.

drance to lameness detection systems in birds. Additionally, as much as kinematic posture trackers have yielded positive results, more re- search should be undertaken in the development of automated body position trackers without the use of markers (non-intrusive and non- invasive systems). Moreover, the applicable camera position in a real farm environment is still a challenge. Overhead camera positions are most preferred, i.e., non-invasive. Aydin (2017a) and Aydin (2017b) ap- plied overhead depth and RGB images, respectively. However, as al- ready mentioned, IR depth sensors are susceptible to sunlight, hence, limited to indoor applications or would limit the operation time of the system if it is installed in an outdoor environment. Additionally, RGB cameras are associated with visual light-based sensor errors.

Furthermore, these experiments were conducted in a controlled en- vironment, whereby the birds' movements were restricted. Therefore, further research should focus on lameness detection of chickens in a flock setting such that occlusion problems and dynamic movements are considered. Lastly, lameness in chicken is affected by several factors. However, the easiest to control from a stockman perspective are the en- vironmental factors such as illumination, bedding, ventilation, and stocking density. Therefore, more research should focus on the opti- mum environmental conditions for chicken regarding lameness.

Tracking of poultry is an essential parameter in the assessment of be- havioral (types of activities) and physical (lameness and health) indica- tors in poultry welfare. There is a need to automatically record the behavior and movement of birds continuously for welfare monitoring purpose and behavior phenotyping. Noldus and Jansen (2004) catego- rized automated video tracking systems as analog and digital video tracking systems. Analog systems detected high peaks in the voltage of a video signal, i.e., regions of high contrast between the bird and

background. However, these systems could only track one bird in a ded- icated experiment set up unit with restricted illumination and back- ground conditions. Digital systems allowed for pattern recognition techniques to be applied to image frames for the quantitative measure- ment of the birds. However, this system is limited by the computational speed and the complexity of the underlying software.

behavior detection systems with illumination invariancy, factors in the background complexity, overlapping, and occlusion problems. The ap- plication of improved YOLO v3 has solved these problems, referred to as the YOLO v3-dense model (Tian et al., 2019), whereby DenseNet is used to process feature layers with compromised images (low resolu- tion, occluded objects). Similarly, the speed and performance of the real-time YOLO v3 system can be improved by extending the detection scale and down-sampling of feature fusion target detection layer (Ju et al., 2019). The mentioned improvements haven't been applied in chicken monitoring CNN-based systems. Therefore, more research should be performed to improve the performance of real-time detection models.

Animal activity is highly associated with behavior levels, GS, and health. In computer vision systems, activity is measured as percentage pixel change over the total area coverage over a period of time, i.e., the higher the activity levels, the higher the difference in pixel values. EthoVision XT and eYeNamic are software that can directly

tribution monitoring at drinking and feeding areas (Guo et al., 2020), ef- fect of feeder types (Neves et al., 2015), type of light illuminance (Kristensen et al., 2007), backpack (Stadig et al., 2018) on bird's behav- ior have also been presented regarding activity and behavior monitor- ing. However, animal behavior is a complex bio-response to both internal and external stimuli. Therefore, more research should be di- rected towards the drivers of behavioral responses such as pen con- struction designs and materials and structures inside the pen as well as health and micro-environment.

Generally, appropriate image processing algorithms in computer vi- sion are essential for the poultry monitoring in the farm environment for precise localization of birds. This will be pivotal in the monitoring of several bioprocesses and bio-responses and also provide a solution to occlusion problems. Even though several challenges still exist, more researches are being performed to improve the monitoring systems in poultry.

