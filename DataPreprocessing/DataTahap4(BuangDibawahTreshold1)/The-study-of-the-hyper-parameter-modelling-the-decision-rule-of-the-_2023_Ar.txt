and a trade-off has to be made between these two criteria. On one hand, a classifier that predicts always the whole set of the candidate classes is cautious but its predictions are uninformative. On the other hand, a classifier that predicts always a single class is precise when the predictions are good but it is not cautious. Some set-valued classifiers can control this trade-off as the ndc and eclair classifiers. Indeed, the utility function implemented in the decision step of both classifiers

proposes to study this parameter in the case of the two classifiers and aims to propose suggestions for the choice of the parameter value in the case of classification task. In the first experiment results, we show, on simulated data, the impact of the selected hyper-parameter value on the prediction of the two classifiers when faced to strange samples, i.e., to

presented. The paper is organized as follows. In the second section, the reminders about the decision step in the classifiers eclair and ndc and the measures of set-valued classification performances are given. The third section presents the studies of the expected utility functions introduced in the decision step of the two classifiers. Finally, the fourth section presents the experimental results.

In this section we present the illustration of the performances of the classifiers ndc and eclair using generated data in Section 4.1 and using fashion mnist data in Section 4.2. In the two subsections we give the comparisons of the classifiers when the hyper-parameter is tuned based on grid search method or based on the proposition of this paper regarding the set-valued classification metrics and in Section 4.2 we show how to control the number of the predictions using our propositions.

complexity is challenging for conformal prediction (see [14] for more details) and for eclair classifiers (see [10] for more details). Indeed, for conformal predictions, the non-conformity scores are calculated using the nearest neighbours of the calibration or test samples in the training data [11]. Regarding eclair classifier, as for any approach representing imprecision in the data, the computational complexity can be very high. Indeed, the computational complexity of the reasoning step of the eclair

function used in the decision step of two set-valued classifiers. More precisely, we studied the predicted subsets depending on this hyper- parameter. In addition to theoretical propositions, we give practical method to control the size of the predicted subset in machine learning applications. While trying to remain very efficient on point prediction task, set-valued classifiers have the challenge of making machine learn- ing methods more trustworthy, especially in the presence of imperfect data. The decision-maker who knows well his data could better control, using the proposal of this article, the size of the predictions by fixing

