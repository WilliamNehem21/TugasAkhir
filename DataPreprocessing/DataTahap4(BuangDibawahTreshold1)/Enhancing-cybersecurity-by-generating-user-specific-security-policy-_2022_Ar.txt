Organizations today are faced with the difficult challenge of balancing the embrace of new and emerging technology, and securing their systems and data that support critical business functions. Although there have been significant advances in security enforcement technology, attackers are still able to compromise organiza- tions and access. The impacts of computer intrusions have become so untenable that many organizations are looking at a drastic rethinking of their approach to the security of internal networks. This approach is called Zero Trust and it seeks to remove all notion of a trusted internal network boundary. The benefits of Zero Trust include significantly increasing the work that attackers would need to perform to achieve their objectives. But Zero Trust will also increase the management complexity for internal security teams. These teams will need a way to collect data and enforce policy decisions based upon analysis. This process will need to be done for all organizational systems, and data, and it will need to be done in all access contexts.

Organizations today are faced with the difficult challenge of bal- ancing the embrace of new and emerging technology, and securing their systems and data that support critical business functions. Al- though there have been significant advances in security enforcement technology, attackers are still able to compromise organizations and access. Perhaps more now than ever before, Organizations are re- quired to embrace new technical innovations including advances in the Internet of Things, Machine Learning and Statistical Analysis, and Cloud Computing. As these new devices and services become available, organizations have a business need to connect them to their business networks. If they do not, they risk becoming overtaken in their market by competitors. This further tests their security teams ability to prevent

Our approach uses results from the study of human intentions, at- titudes, norms, and resulting cybersecurity decision making behaviors. There are many studies showing that usable security is a hard problem. Users often ignore explicit warnings and misunderstand the likelihood of many risks and their resulting impacts [17]. Users also rationally reject warnings because they have experienced so many false alarms in their past experience [18,19]. Human and Computer interaction interfaces are hard to design and inherent cognitive weaknesses can negatively affect security decisions [3,20]. Some studies find that indi- vidual users behave differently when presented with security decisions based upon background, culture, and attitudes [2,5,21].

The first step in FMUSPGF involves selecting security behaviors, this was achieved by conducting a survey of existing literature to identify what are the expected security behaviors. Once the security behaviors are selected, the second step involves modeling these behaviors, where we implemented a formal method-based approach. After the security behaviors are modeled, the next step involves labeling the security behaviors, this was accomplished by executing queries designed us- ing formal specification. Finally, user specific security policies are generated guided by the labeling in the previous step.

Our main contribution is in the design of a formal method based framework to support the process of user specific policy generation for cybersecurity. In the process, we demonstrated how to identify and select the essential characteristics that define users security behavior. Then, we modeled the identified security behaviors as formal models to enable automated reasoning. Finally, we were able to detect weakness in users security behavior and then propose relevant policies.

The architecture modeling the representation of knowledge about the security behavior includes different levels of abstractions, in order to ease the debugging, increase readability/maintainability and lessen the complexity. We decomposed the structure into different sorts of se- curity services on multiple layers, starting from (1) as the highest level of abstraction and ending with (3) as the lowest level of abstraction. By doing so, we eliminate a fair bit of confusion around which security aspect we employed for a specific SeBIS dimension.

Layer (1) is the most abstract of the four security service check layers. It assimilates the SeBIS concepts: device securement, pass- word generation, proactive awareness, and updating that are specified by Egelman and Peer. These correspond to the highest level of representation of the security task that needs to be executed.

To conduct the experiments the first step involved the experimental setup, which involved the modeling of the selected security behaviors in timed automata 6.1. Once the models were developed, the next step involved conducting the experiments (6.2) to label good and bad security behaviors.

The design of our models were guided by the capability to for- mally check the existence of good and bad user security behaviors (as measured by instruments taken from academic literature) in TCTL. Sections 6.1.1 to 6.1.4 will present a further illustration of why and how we chose the most critical matters within different security settings that are parts of device securement, password generation, proactive aware- ness, and updating. Using behavioral measurement scales in existing literature, we set up a selection of examples separating good decisions from poor ones.

for users to remember, and thus more likely to be stored inse- curely. Users are adjusting and developing coping mechanisms to overcome this burden by making some alterations to their current passwords. We included this rule to our set of specifications to show an example of the criteria that can be included in the knowledge base.

In this section, we model several test cases with different security behaviors, as Finite-State Automata (FSA). For each separate test case, we generate a set of user-specific linear-time properties. We then clas- sify the behavior as good or bad based on the results of the reachability analysis. Once the behavior is classified we generate the relevant security permissions such as, Strict, Moderate and Least restrictive.

Reachability analysis with model checking is a verification procedure for models that are designed based on the state-transition concept. According to Kong et al. (2015), reachability analysis is a technique used in a state-transition system in order to find out the type and number of states which can be accessed through a particular system model [49]. Reachability analysis allows formal analysis for validation, verification, and checking performance metrics, explained as follows:

