space, where samples can be linearly separable [49]. This mapping is achieved through the use of a kernel function, (e.g., polynomial, linear, sigmoid, or radial basis) [59]. Then, a hyperplane that best separates the different classes of compounds (e.g., active/inactive) is generated via the definition of the larger margins (support hyperplanes) traced using the nearest data points of each class (support vectors) [17,45,49]. Thus, unseen compounds are also mapped into this high-dimensional feature space and classified according to the side of the boundary where they lie [45]. SVM is one of the best-performing algorithms for the prediction of chemical and biological properties thanks to its ability to deal with com- plex, non-linear, high-dimensional, and noisy problems [45,48,54,60]. However, depending on the size of the dataset, feature space, and kernel, SVMs can be computationally expensive [49].

typically overcomes the vanishing gradient problem [81]. ReLU outputs the input directly if it is positive; otherwise, it will output zero. ReLU has become the gold standard activation function for many types of DNNs because models that use it are easier to train and often achieves better performance [82].

Among GCNN representations, geometric DL approaches have been employed for predicting the binding conformations of ligands to pro- tein targets. Concretely, the model learns based on distance likelihood which is tailor-made for each ligand-target pair. In the first step, the neural network extracts a pool of mesh (i.e., collection of nodes, edges, and faces) which defines the shapes of the molecular surfaces of bind- ing sites. In a similar way, ligands are represented as a two-dimensional undirected graph, where atoms and bonds are represented by nodes and edges, respectively. Both the target mesh and the ligand graph are pro- cessed by independent residual GCNNs. In the following step, the pro- cessed features from the protein targets and ligands are concatenated using a mixture density network to model the interaction of the ligands with the targets [99].

There are several approaches for optimizing and calibrating MTL models. Existing works often focus on developing aggregated loss func- tions adapted to sparse data as a way to learn multiple tasks at once. Different loss weighing mechanisms may be used to aid MTL optimiza- tion, such as adding weights to the individual loss functions to prevent a task with more data from dominating the optimization [103].

ing strategy was then employed to learn the general features (weights) from a larger dataset of compounds with known pKi values, and ap- ply them to a smaller dataset of compounds with defined pIC50 and pEC50 values, through fine-tuning. In each epoch, the generated chemi- cal structures were interactively evaluated by the MTL-DNNs model and further screened based on various criteria, including drug-likeness and synthetic accessibility [123]. High-ranking compounds were then sam- pled to boost the training set for the next iteration. Importantly, this

A MOO task always begins with some statement of desired proper- ties. First, the chemical and biological properties must be converted to mathematical objectives. If more than one objective exists, they must ei- ther be treated with an appropriate multi-objective formulation [124]. In this section, we explore two of these MOO formulations in detail, namely scalarization and Pareto method. An in-depth discussion of MOO methods in drug discovery is provided by Former and Coley [124].

and their similarity at different levels of biology. Chemical Checker di- vides data into five levels of increasing complexity. The drug is often a compound (chemistry) that interacts with one or several protein re- ceptors (targets), triggering perturbations of biological pathways (net- works) and eliciting phenotypic, cell-based assays (cells), which can then be translated into their clinical outcomes (clinics). The authors showed that these signatures can aid drug discovery tasks, including target identification and library characterization.

dominance is there to differentiate the non-dominated and dominated solutions. The goodness of a solution is determined by dominance. A solution is called non-dominated if none of the objective functions can be improved without being detrimental to at least one other objective. The dominated solution is usually achieved when an objective function can be improved without reducing the remaining objective functions [124,125].

The shape and electrostatic properties of molecules are what deter- mine how similar two different substances can be. Learning from past drug discovery experiences, these characteristics should therefore play a major role in determining which comparison method is used. Some- times, it is hard to reach the desired complex effect with one, one drug (even considering magic shotgun drugs). In this case, combining the drugs with different mechanisms of action and/or hitting a variety of selected targets could serve as an alternative approach. The application of such approaches in the discovery of synergistic drug combinations against SARS-CoV-2 has been reviewed elsewhere.

Li YH, Wang PP, Li XX, Yu CY, Yang H, Zhou J, et al. The human kinome targeted by fda approved multi-target drugs and combination products: a comparative study from the drug-target interaction network perspective. Zou Q, editor. PLoS ONE 2016;11:e0165737. doi:10.1371/journal.pone.0165737.

Li D, Hu J, Zhang L, Li L, Yin Q, Shi J, et al. Deep Learning and Machine Intelli- gence: New Computational Modeling Techniques for Discovery of the Combination Rules and Pharmacodynamic Characteristics of Traditional Chinese Medicine. Eur J Pharmacol 2022;933:175260. doi:10.1016/j.ejphar.2022.175260.

