The need for entrepreneurship training is growing globally [1]. This need is because government alone can no longer provide jobs for everyone, and people must find ways to create jobs and wealth for themselves. Entrepreneurship education has become necessary as un- employment bites harder and poverty increases [2]. Many educational institutions and governments are refocusing their policies and curricu- lum on education on problem-solving [3]. This factor is necessary to bridge the employment gap and encourage critical thinking. Mobile

factors, including the digital divide and network issues. However, technology is believed to be very much needed to promote entrepre- neurship education, learning and practice. This study attempted to predict the adaptability of students in online entrepreneurship educa- tion courses to recommend possible ways to improve their adaptation.

was enacted in Japan in 1998 to encourage students to pursue entre- preneurial endeavours while still in school. We systematically evaluated the technologies used from three perspectives: pedagogy, usability, and technology. A total of five specific cases have been chosen for in-depth investigation and comparison [8].

This paper is designed with aiming of prediction of adaptability of online education. section 2 defines the various existing works carried out in this problem domain. section 3 explains the about datasets used for experimental purpose. In this paper, educational dataset from Kaggle is being taken. section 4 demonstrates proposed Stacking Ensemble Learning. Next section 5 demonstrate the result followed by conclusion of the paper in section 6.

Various creators have introduced research concentrates on business expectation and their suggestions; nonetheless, research concentrates on instructive advancements in E.E. have been restricted notwithstanding the functional turn of events and shown off on the web and hybrid courses utilizing the web and instructive apparatuses since most recent twenty years.

Rubia et al. [12] explore the significance of the evaluation frame- work in the Web-based distance learning schooling climate and lays out an astute appraisal framework model, which is portrayed for its positive presentation and versatility. In addition, the execution of the evaluation framework is given in light of this model. In an incorporated instruction climate, this evaluation framework helps out different subsystems dur- ing educating and growing experiences and assumes a significant part in working on the presentation of the entire schooling system.

innovative mentalities, despite no tremendous contrasts in age and orientation. Then again, measurably, contrasts have been tracked in light of the designing mastery region. Understudies of the speciality in Industrial Electronics Engineering have higher mentalities concerning innovativeness and development, which are vital for business ventures. Xu et al. [16] utilize the standards of helpful arrangement to dissect and upgrade a few parts of the Entrepreneurship course. The attention is on surveying and adjusting the appraisal assignments to guarantee a successful assessment and the accomplishment of understudy learning results. The course update process and the beneficial arrangement and creative appraisal can be applied to different courses in the field and more extensively to educational planning, instructing, and learning in

Wang et al. [17] utilized A.I. (ML) algorithms to distinguish low-commitment understudies in a sociology course at the Open Uni- versity (O.U.) to evaluate the impact of commitment on understudy execution. The info factors of the review included the most extraordi- nary schooling level, eventual outcomes, score on the appraisal, and the number of snaps on virtual learning climate (VLE) exercises. The results showed that the J48, choice tree, JRIP, and angle helped classifiers display better execution regarding the exactness, kappa worth, and re- view contrasted with the other tried models.

Xueli et al. [18] propose the conduct order-based e-learning execu- tion (BCEP) expectation system, which chooses the elements of e-learning ways of behaving, utilizes highlight combination with conduct information as indicated by the conduct characterization model to acquire the classification including upsides of each sort of conduct, lastly assembles a learning execution indicator in light of A.I.

e-educational experience called the cycle conduct grouping (PBC) model. Trial results with the Open University Learning Analytics Dataset (OULAD) show that the learning execution indicator in light of the BCEP forecast outline work has a decent expectation impact, and the presen- tation of the PBC model in learning execution expectation is superior to conventional grouping strategies. We develop an e-gaining execution indicator according to another viewpoint and give another answer for the quantitative assessment of e-learning grouping techniques.

Pardede et al. [19] also endeavour to blueprint and think to gauge the accompanying feeling and social elements of commitment (abilities, cooperation/collaboration, and execution, close to home). The out- comes uncovered that the exploratory gathering is measurably funda- mentally higher than those in the benchmark group. These experimental outcomes infer the capability of a versatile e-learning climate to connect with understudies towards learning.

combining unrelated data are the most common causes of missing numbers. Performance deterioration, data analysis challenges, and skewed outputs can all be caused by missing values in any data-related domain [20]. Lost data can have varying degrees of significance depending on the amount, the pattern, and the cause behind its absence. A technique known as imputation can be used to address missing data, which involves deleting instances and replacing them with possible or estimated values [21]. In this paper, the authors applied Hot-deck imputation approach for handling missing values in the context of

directly assigning the values of the donors or using statistical methods like taking the mean or median value of the donor values. It is important to be cautious of potential donor selection bias. The authors ensure that the selected donors represent a diverse range of characteristics and that the imputed values do not introduce bias into the dataset. Bias may arise if there are systematic differences between the students with missing values and the selected donors.

technique. It is crucial to examine if the imputed values provide reasonable estimates and do not distort the relationship between pre- dictors and the target variable. The authors conduct sensitivity analysis to examine the robustness of the imputed values and their impact on the forecasting results. Hot-deck imputation provides a way to fill in missing

Data that is markedly different from the rest of the data is known as an outlier. An outlier might be caused by measurement variability or an experimental mistake; the latter are often eliminated from the data set. Analyzing an outlier might complicate data. Detecting outliers in Python uses used following methods such as:

demographic information, prior academic performance, learning be- haviors, self-efficacy, motivation, social support, and any other factors deemed important. Each variable will be represented as a node in the Bayesian network. It determine the relationships and dependencies be- tween the variables. This step involves analyzing how the variables interact with each other and influence adaptability.

It is a machine learning algorithm that combines predictions of machine learning models, like bagging and boosting. It involves two base models, level-0 and level-1 models [31]. The other is commonly known as the meta-model or level-1. This model is used in predicting the

Ensemble models are inherently robust to noisy data and outliers. By combining predictions from multiple models, the modified ensemble model can mitigate the influence of individual outliers or noisy in- stances, reducing their impact on the overall prediction. This robustness allows for more reliable adaptability forecasts, even in the presence of data imperfections.

Ensemble models are known for their ability to generalize well to unseen data. The modified ensemble model, trained on a diverse set of base models, can effectively capture the underlying patterns and trends in the data. This generalization capability enables the model to make accurate predictions for new students entering online entrepreneurship education, ensuring the practical applicability of the forecasts.

In this work, five machine learning classifier models (Bayesian Network, Random Forest, CART, Neural Network. and their ensembles) were tested to predict online education adaptively. These techniques used the public database from Kaggle as an evaluation set, which con- tains multiple predictors like state, gender, and internet connection, as well as the financial status for classification. The experimental results obtained in the performance metrics among the proposed techniques were analyzed according to their means and standard deviation. The best results were obtained with a proposed ensemble learning method combining B.N., N.N., CART and Neural Network, which achieved

The results show that all students met the course goals to a high degree of satisfaction but that students who took the course in a class- room felt they had done a better job than those who took it online. Students were able to adapt online based on the results. The discrep- ancies can be traced partly to the educational techniques utilized in the online course. That is to say, it is not the delivery modality to blame for

Given that entrepreneurship education aims to help students find and realize their entrepreneurial potential, this point should not be neglec- ted. The study would contribute to the growing knowledge of the use of technology in entrepreneurship. The future work will focus on devel- oping a mobile platform to assist startups in marketing their products and connecting and interacting with global audiences.

