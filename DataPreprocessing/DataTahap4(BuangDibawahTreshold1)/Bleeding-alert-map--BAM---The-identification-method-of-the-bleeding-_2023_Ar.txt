prolonged hemorrhage. Moreover, bleeding may obscure the surgical field view, decreasing visibility and complicating the surgical opera- tion. Of course, bleeding itself causes damage to tissues, increasing the burden on patients, so that monitoring the extent of bleeding is extremely important for the judgment of whether or not an endoscopic surgery should be suspended [14,15].

In the field of wireless capsule endoscopy technique, there are sev- eral researches that develop systems for automatic bleeding detection from endoscopic images. For example, Jia and Meng [16] demonstrates an approach to bleeding detection based on segmentation of bleeding regions using deep learning. In addition, Caroppo et al. [17] proposed

Meanwhile, there are not many studies that utilize thoraco-laparo scopic images. Regarding bleed detection, Okamoto et al. [18] devel- oped a method that uses the combination of RGB values and HSV values of images as input to a support vector machine to categorize the presence/absence of bleeding. Garcia-Martinez et al. [19] proposed a technique using RGB information from a single endoscopic image. By comparing and analyzing the ratio of red/blue and the ratio of red/green with the average pixel value throughout the operation as the threshold value, the bleeding area and the background area are separated to identify the existence of bleeding. The technique is partic- ularly effective for large-scale hemorrhage. There are also researches on a framework for estimating the bleeding area in more detail, where a bounding box labeled by the surgeon is used for training data.

Among them, the estimation accuracy for a bleeding source and bleeding area has been improved by using spatio-temporal information of the site obtained from time-series image data [20]. However, if the surgeon moves the camera during surgery, the position of the bleeding source may not be constant, and it may be difficult to apply this technique at such moments. Moreover, surrounding tissues may be constantly deformed by the surgical instrument. If information from an image at a single time point allows accurate estimation, it would greatly contribute to the development of a safer hemostasis support system.

To generate the BAM, Pix2Pix, one of the Image to Image translation methods, was used for validation along with the generation of the alert map.Pix2Pix, which was proposed by Isola et al. [23] , is a technology that realizes image-to-image translation such as generating an actual building image from its segmentation image and coloring an edge image. It is a kind of conditional GAN (Generative Adversarial Network). GAN is a network called a generative model that learns training data and generates new data similar to them. GAN consists

For the laparotomy images, we employed the video data from laparotomy operation on a porcine (Zenno-premium-pig, 2.5-months- old male, KAC Co., Ltd., Kyoto, Japan). The video data was obtained for verification on hemostasis [24,25]. All procedures and protocols were approved by the Animal Care and Use Committee of the Na-

For the endoscopic surgery images, we employed the video data from a thoracoscopic operation on another porcine (LW species, female, 4-months-old female, Science Bleeding Co., Ltd., Chiba, Japan). The data was also obtained during the operational check of a surgical robot, where the research was approved by the Animal Research Committee of Tokyo Medical and Dental University (authorization number: A2020-

RGB). The organ to be imaged was a lung. In this case study, there is no information on the bleeding source, because the images were from an actual surgery removing one of the lungs, where the bleeding source location was set as a rectangular region and labeled by surgeons and veterinarians.

state. The other is the evaluation of the extent to which the area of the generated alert map overlaps with that of the BAM generated from the ground truth or the bounding circle specified by humans, and how much of the areas do not overlap. As for the accuracy of the bleeding position estimation, the threshold of 0.1 was employed to determine if a bleeding source exits. If the source actually existed, it was judged that an alert map covering the bleeding position was successfully generated. In order to verify the performance of the proposed method, the accuracy rate, precision rate, and recall rate are introduced as follows.

recognized as bleeding regions, with the accuracy rate being 77.0%, while the accuracy was improved to 90.5% for the BAM generation using Pix2pix. The recall rates were about the same (93.3% and 94.0%) for both cases. The precision rate was 79.5% for L1 only, while it was higher at 93.4% for Pix2Pix. The F1 score was 0.94 when using Pix2Pix,

for Pix2Pix is slightly higher, but there was no significant difference. When there was no bleeding, the generated BAM did not give any areas with bleeding source probability. Furthermore, in one case where blood is present but hemostasis is already applied and there is no bleeding, the generated BAM presented no bleeding source.

By using the BAM which is generated by the Generator constructed with the help of Pix2Pix, it has become possible to obtain probability information on a bleeding source on the endoscopic screen, while the conventional approaches are only capable of determining a segmented area where the bleeding source may exist. The accuracy at which a BAM could be correctly generated was 90.5%. Moreover, it has become

surgeries using 4 K and 8 K endoscopes are on the rise. In this case, the calculation time is expected to be longer, and it is necessary to consider algorithm acceleration to obtain real-time performance. In addition, when VR/AR is used for BAM information, there are issues such as whether rendering and information presentation should be 2D or 3D, and in such cases, speeding up the computation will be essential.

method, will be improved for higher accuracy and visibility by using a more state of the art image-to-image translation method in the future. There are also several limitations of the proposed method. Fur- thermore, the method was developed by assuming bleeding occurs in blood vessels exposed on the tissue surface, because such vessels easily come into contact with surgical instruments. However, the current mimicking device does not assume a complicated shape and cannot provide depth information, so that bleeding that may occur at blood vessels running behind the organ or hidden in the back cannot be accounted for. As future work, a mimicking device incorporating a variety of features in the depth direction may be developed to further

The proposed method also proposes a new provision method of bleeding state information called BAM. Since it differs from existing bleeding areas and labeling problems, it cannot be evaluated by direct image comparison. It is necessary to re-evaluate it in a clinical environ- ment with scores such as improved hemostasis accuracy to clarify the effectiveness of the proposed method in the future.

A BAM an alert map that not only shows the location of a bleeding area but also has the expectation information of a bleeding source. Such information can be applied to Context-aware Augmented Reality in laparoscopic surgery [28,29], although issues such as real-time and clear visualization need to be considered. Furthermore, the ability to ac- quire detailed location information of a bleeding source would allow its application to hemostasis assistance under robot-assisted laparoscopic surgery as well as autonomous hemostasis.

Maina Sogabe: Conceptualization, Methodology, Investigation, Data Curation, Resources, Software, Writing- Original draft preparation, Writing- Reviewing & Editing, Visualization, Funding acquisition. Kaoru Ishikawa: Investigation, Data Curation, Resources, Writing- Original draft preparation, Writing- Reviewing & Editing. Toshihiro Taka- matsu: Data Curation, Resources. Koh Takeuchi: Software, Formal analysis. Takahiro Kanno: Data Curation, Writing- Reviewing & Edit- ing . Koji /ujimoto: Data Curation, Formal analysis. Tetsuro Miyazaki: Data Curation, Writing- Reviewing & Editing. Toshihiro Kawase: Data Curation. Toshihiko Sato: Resources. Kenji Kawashima: Supervision, Project administration, Writing- Original draft preparation, Writing- Reviewing & Editing.

