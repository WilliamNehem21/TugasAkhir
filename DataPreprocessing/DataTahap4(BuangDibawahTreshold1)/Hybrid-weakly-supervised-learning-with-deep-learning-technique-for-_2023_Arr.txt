Due to the emergence of social networking sites and social media platforms, there is faster information dissemination to the public. Unverified information is widely disseminated across social media platforms without any apprehension about the accuracy of the information. The propagation of false news has imposed significant challenges on governments and society and has several adverse effects on many aspects of human life. Fake News is inaccurate information deliberately created and spread to the public. Accurate detection of fake news from cyber propagation is thus a significant and challenging issue that can be addressed through deep learning techniques. It is impossible to manually annotate large volumes of social media-generated data. In this research, a hybrid approach is proposed to detect fake news, novel weakly supervised learning is applied to provide labels to the unlabeled data, and detection of fake news is performed using Bi- GRU and Bi-LSTM deep learning techniques. Feature extraction was performed by utilizing TF-IDF and Count Vectorizers techniques. Bi-LSTM and Bi-GRU deep learning techniques with Weakly supervised SVM techniques provided an accuracy of 90% in detecting fake news. This approach of labeling large amounts of unlabeled data with weakly supervised learning and deep learning techniques for the detection of fake and real news is highly effective and efficient when there exist no labels to the data.

This study focuses on the dissemination of false information through social media as cyber propaganda. Fake news is widely spread through social media networks, such as Twitter, Facebook, and WhatsApp [3]. The increasing popularity of social media raises the possibility of creating and disseminating false information. Users can share and ex- press their views and opinions in a straightforward and unchecked way across social media networks. Some news reports posted or shared on Facebook and Twitter have more views than those reported directly on the news website. Massachusetts Institute of Technology (MIT) researched disseminating fake news on social media sites. Findings revealed that fake news stories propagated 70% faster than real news

This paper is structured as follows: The second section discusses the most recent related work for detecting fake news with weakly supervised and deep learning techniques. Section 3 describes the methods used to detect fake news in this research study, focusing on weakly supervised learning techniques. Section 4 discusses the suggested Hybrid approach for identifying fake news. The experimental findings are presented in Section 5, and the suggested investigation is wrapped up in Section 6.

A Hybrid CNN and RNN model was proposed in Ref. [13] to recog- nize fake news from Twitter data. A private data set of 58,000 tweets from five different rumor stories was utilized. A two-step approach was adopted for fake news detection: first, features were extracted from Twitter posts without prior information about the topic, and then fake news was predicted from Twitter posts comprising text and images using an LSTM and CNN hybrid deep learning model.

selector, and an annotator. By assigning weak labels to unlabeled news articles in response to user input, the annotator was trained on a small collection of labeled fake news. High-quality samples were selected, and low-quality samples were filtered out through a reinforced selector. Additionally, the CNN model was fed with the extracted features to classify false information.

In [16], a weak social supervision technique for identifying disin- formation was proposed. FakeNewsNet benchmark dataset was utilized, which was collected from PolitiFact and GossipCop fact-checking web- sites. Weak labels were generated through three statistical measures such as sentiment, bias, and credibility. In sentiment based on whether

have been clustered using hierarchical clustering. The average credi- bility score below the threshold was weakly labeled as false news. For the classification of false information, CNN and robustly optimized BERT (RoBERT) model, along with multi-source Weak Social Supervi- sion (MWSS), were used. CNN-MWSS provided an accuracy of 77% for GossipCop data and 82% for PolitiFact data, whereas RoBERTa-MWSS provided an accuracy of 80% for GossipCop data and 82% for Polit- iFact data.

The authors in Ref. [18] presented a weakly supervised learning technique based exclusively on content features for fake news detection. They prefer news articles to social media posts. A probabilistic weak labeling system was employed to label the content features, and a test set from the fact-examination groups - PolitiFact3 and Snopes2 was used. Five machine learning classifiers on content features were applied for the classification of fake news with and without weak labels to explore the efficacy of applying weakly supervised learning. For the test set, RoBERTa with weak labels achieved the highest accuracy of 79.3%.

Using the labeled LIAR dataset, authors in Ref. [19] demonstrated an ensemble-based deep learning model to recognize news as real or false. Two deep learning methods, Bi-LSTM and GRU, were utilized for the statement attribute, while dense, deep learning models were applied for the other attributes. With the suggested approach, an accuracy of 89% was attained.

data annotation and weakly supervised learning was not performed to label unlabeled data, furthermore the performance did not increase significantly even after applying deep learning techniques to the open- source data. The limitation of the existing techniques motivated us to propose novel weakly supervised learning techniques to label large amounts of unlabeled data. Additionally, it was also observed in Ref. [19] that ensemble BiLSTM-GRU deep learning techniques provided better performance compared to ALBERT and RoBERTa. The key bene- fits of Bi-LSTM and BI-GRU deep learning approaches are that they

Convolutional Neural Networks are made up of neurons with learnable parameters, namely biases and weights. CNN assumes that each input has a grid pattern, such as images, which enables certain features to be encoded into the architecture. CNN is very similar to dense neural networks, except the hidden layers consist of layers of convolu- tion and pooling accompanied by one or more fully connected layers (i. e. dense layers) at the end. Feature extraction in CNN is performed

Further statistical tests were conducted to verify the accuracy of the annotated labeled data. The statistical test determines whether the two samples or features are significantly different from the others. A t-test with null hypothesis was used. The aim of the t-test was to assess if the measured value of alpha was smaller compared to the assumed one (i.e.,

Experiments were performed through our proposed hybrid approach, which includes transductive weakly supervised learning for data annotation and deep learning approaches for the classification of fake news. The data was split into a ratio of 80:20 for model training and testing. Using the TensorFlow framework. The deep learning techniques applied in the implementation are discussed below.

The BiLSTM model was trained for 40 epochs and the Adam opti- mizer was applied since it produced optimized results and was designed for 128 units. A SpatialDropout1D of (0.1) rate was added to the input layer to minimize the problem of overfitting. Followed by two LSTM layers to extract features from the input text. Both layers have bidirec- tional extensions. The model is able to recognize the context by retaining input information in the hidden state from the past to the future and from the future to the past. At every timestep, the network averages the outputs of the LTSM node to obtain hidden representation. Hidden

4.2. SVM provided the highest accuracy compared to other machine learning models for data annotation hence was considered for data annotation. Furthermore, several deep learning algorithms such as BiLSTM, BiGRU, LSTM and CNN were applied for classification of fake news. It was observed that Bi-LSTM and BiGRU deep learning model provided a higher prediction accuracy of 90% than the other deep learning techniques, namely CNN and LSTM models. Bi-LSTM produces results slightly higher than Bi-GRU by almost 0.35%. CNN has low performance compared to other deep learning models. The decrease in

performance with CNN is due to the complexity of the neural network. CNN extracts high-level features, LSTM captures long-term de- pendencies, and Bi-LSTM and Bi-GRU retain long-time information by propagating in both directions without duplicate representation. Hence Bi-LSTM and Bi-GRU performance is better. Bi-GRU is similar to Bi- LSTM with a lesser number of gates.

transductive weakly supervised learning model. Training accuracy of 89% was achieved, the validation accuracy increased along with the training accuracy, and attained an accuracy of 87% for the test dataset Simultaneously the validation loss i.e. error rate started to reduce along

Bi-LSTM and BiGRU outperformed other deep learning models with an increase in accuracy of 89.5%. The performance of CNN was worse when compared to other deep learning models. Bi-LSTM and BiGRU with weakly supervised SVM are the best models for the classification of Fake news when compared to other state-of-the-art approaches using large amounts of weakly labeled data, hence the proposed approaches are significantly more effective and efficient at identifying false information.

