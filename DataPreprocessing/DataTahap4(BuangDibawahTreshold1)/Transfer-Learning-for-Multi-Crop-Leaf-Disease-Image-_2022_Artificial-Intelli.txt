Artificial intelligence (AI) provides considerable assistance to agri- culture, which enhances a nation's gross domestic product (GDP) mostly through this sector. Climate change, labour scarcity, rainy season uncertainty, natural disasters, and various diseases on plant leaves are all major issues in agriculture. The plant leaves recognition and detec- tion studies with edge intelligence applied to agriculture. There is a new advancement with different deep learning models that overcomes the challenge. The YOLOv3 neural network model is based on deep learning and is built on an embedded system and the NVIDIA Jetson TX2. The system is implemented on a drone, and photographs of plants are taken, pest positions are identified, and pesticides are applied as needed; this is a novel approach based on deep learning (Al Hiary et al., 2011).

The massive crop loss occurred because of the failure to predict dis- ease at an early stage, which always results in lower crop production. As a result, identifying and analysing crop diseases is a critical step in en- suring crop quality (Wu, 2020). As high computing speed and power have recently improved, the availability of massive datasets improves the system's efficiency.

The identification of weeds in crops using the CovNet algorithm is also a potent and cutting-edge approach. In recent research, bounding boxes were drawn across cropped images and the model was trained. Colour-based segmentations are applied to images and colour informa- tion, and visual categorization is calculated for weed images. The colour index was examined with a genetic algorithm and Bayesian categoriza- tion (Jin et al., 2021). The deep residual network and the deep dense network are combined in the hybrid deep learning model. The hybrid deep learning model reduces training parameters while increasing ac- curacy by up to 95.00 % (Zhou et al., 2021).

To detect and recognize corn dietary sickness, a Deep Convolutional Neural Network was deployed., The recognition of corn leaf diseased ac- curacy was 88.46 %, and the usage of hardware, such as a raspberry pi3 with an Intel Movidius Neural Compute Stick and a system GPU that pre-trained the CNN Model, resulted in superior metric accuracy perfor- mance (Sun et al., 2020).

With the rapid growth of artificial intelligence and deep learn- ing technology, computer vision (CV) made a breakthrough. The CV-based approaches are commonly utilized for diagnosing grape leaf diseases. The principle component analysis (PCA) and back propagation methods aid in the diagnosis of grape diseases such as downy mildew and powdery mildew, with a research accuracy of 94.29 % (Xie et al., 2020), using VGGNet. The weights are initial- ized using ImageNet pre-trained datasets, and over through the real - world dataset, such approaches had a validation accuracy of

a result, data augmentation broadens the range of training data available to deep learning models. Deep learning-based augmentation approaches include image flipping, cropping, rotation, colour transformation, PCA colour augmentation, noise rejection, Generative Adversarial Networks (GANs), and Neural Style Transfer (NST) (Arun Pandian et al., 2019). The Faster DR-IACNN approach for detecting grape leaf diseases is based on deep learning. The automatic extraction of spots on leaves has a high de- tection speed and accuracy. There are 4449 original photographs and 62,286 photos developed using data augmentation techniques.

The images are converted into a vector of fixed features through fea- ture extraction in segmentation. The color, texture, and shape are the system-adopted features. A means, confidence intervals, and sleekness have been employed as colored methods, with HSV and RGB color spaces being retrieved. The gray-level co-occurrence matrix is preferred when extracting texture features from a colour image. This approach is used to identify plant diseases.

Convolutional layers' fundamental function is to extract unique fea- tures from images. The implementation of convolutional layers on a normal basis facilitates the extraction of input features (Chen et al., 2020), The features extraction (Hi) among several layers in CNN is com- puted using the formula below.

The pooling layers are a crucial component of a Convolutional Neural Network (CNN). It shrinks the size of convolved features in dimension while simultaneously minimizing the computational resources neces- sary for image processing. Pooling arise categorized into two types: max pooling and average pooling. Max pooling returns the maximum value of images, whereas an average pooling returns the average value of the image section.

The dropout layers improve the capability of a trained model. It pro- vides regularization and prevents the model from over-fitting by de- creasing the correlation between the neurons. The drop out process is used in all the activation functions but it is scaled by factor (Liu, 2020).

The model performance for all classes is accurately measured. The accuracy is calculated by adding the total number of correct predictions to the total number of predictions. The performance parameter calcula- tion of precision and recall and F1-Score are measured. The accuracy is expressed in terms as follows.

A prototype also with largest true negative rate values was used to cor- rectly categorize defectives, and the model with the highest true positive rate values was used to correctly classify healthily. To boost productivity by reducing processing time for training and testing, the MCC (Matthews Correlation Coefficient) is employed for the total computation. MCC is a criterion for categorizing complex data into distinct categories. MCC is a su- perior method to accuracy which only has significant importance if the true positives, true negatives, false negatives, and false positives outcomes are all positive. The MCC ranges from 1 (poorest judgment) to 1 (perfect predictions), with an MCC of 0 suggesting a random guess.

The model is tuned by the number of epochs, hidden layers, hidden nodes, activation functions, dropout, learning rates, and batch size. The model performance is affected by hyper parameter tuning. The term "hyper parameter tuning" refers to the process of repeatedly adjusting hid- den layers, epochs, activation function, or learning rate. The model is fine- tuned to achieve the best accuracy while minimising the average loss.

The experimental analysis was carried out on Google research prod- ucts on Google Colaboratory. The Colaboratory platform supports python programming, and nearly all of the Python libraries are uploaded and installed for research purposes. The Python 3 Google Compute Engine backend (GPU) with RAM of 12.72 GB and disc space of 68.40 GB is avail- able while experimenting. The dataset is uploaded with the drive mounted, and the model is trained on the Google platform with high

Mean average precision (mAP), which consists of Precision, Recall, and Mean, is the algorithm assessment standard employed. Image pro- cessing and detection rely heavily on the mAP. From the entire results, the accuracy has classified correctly. From the complete findings, the re- call is correctly classified.

of the last layer is a oftmax-activation multi-crop-developed prediction. During the network's training phase, hyper parameters such as learning rate and epoch size were adjusted. The average accuracy achieved was 98.40% for grapes and 95.71% for tomatoes, respectively. The learning rate is tested at different values to optimize targeted performance mea- sured. The validation process is based on a total number of images from the multi-crop dataset. With the setting of different epochs and batch size, the accuracy improved and grew.

Validation and testing. The testing is done on the images that were used to evaluate the model, and new images from outside modeling are used to check the model effectiveness. The output results are compared to the real categories, the effectiveness of the control that goes with them is computed.

The residual block collection and DesnseNet used in task of tomato leaf disease identification with RDN restructured model. After input image normalizing and adding the convolutional layer residual modules dense layer classify the tomato disease images with 95% accuracy dis- ease dataset (Zhou et al., 2021). The public data set of the AI Challenger Competition in 2018 used the Inception-ResNet-v2 model using the RELU activation function, with an accuracy of 86.1%. (Ai et al., 2020), under complex background conditions, the accuracy of VGG Net is

