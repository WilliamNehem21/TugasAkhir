process using the L-BFGS-B algorithm [47]. Step 7: The resulting Q (from Step 5) and MLL (from Step 6) update the Gaussian process model for the next iteration of the outer loop. B, Flow diagram of simulation-based candidate-point evaluation. For each sample (see Step 5 in A), the optimizer executes play-throughs in both the Hairpin (top) and Tunnel

Neuroscience-inspired learning and control methods have seen in- creased interest from robotics, artificial intelligence, and multi-agent control. Here, we presented a demonstration of exploring and visu- alizing the parameter space of a multi-agent model with complex dynamical behaviors using sample-efficient Bayesian optimization with Gaussian process surrogate models. We introduced an objective func- tion for a spatial cooperative foraging task in NeuroSwarms simula- tions [34] to predict reward-capture performance across two distinct maze environments. Training the surrogate model was facilitated by the

By learning UMAP embeddings [57], we demonstrated visualiza- tion of 9-dimensional parameter points to identify and select high performing clusters of parameters. We illustrated the identification of parameters that generalized across environments by jointly evaluating the NeuroSwarms metacontroller in two distinct maze environments. Overall, our study serves as an example application of Bayesian op- timization of complex multi-agent models to explore and select for complex behaviors like goal-directed spatial navigation in a system with distributed neural control.

Future work is needed to develop new controller models and crit- ical spatial tasks to explore the capabilities of multi-agent objective functions that adapt efficiently to the characteristics of diverse environ- ments (e.g., occlusive geometry, dynamic change, reward distribution, cue richness, etc.). We theorize that heterogeneous variation of swarm spatial structure and intertemporal coordination dynamics will be able to support a form of swarm metacognition that allows adjustment to the available goals in an environment, without initial knowledge of the goals or their locations. This approach could extend the flexibility of Bayesian optimization to operate in diverse environments and adapt efficiently to tasks with difficult or uncertain goals.

Funding for this work was provided by the National Science Foun- dation (NCS/FO Award No. 1835279 to GMH, KZ, KMS, and JDM), the NIH National Institute for Neurological Disorders and Stroke (NINDS R03NS109923 to KZ and JDM), and Johns Hopkins University Applied Physics Laboratory (JHUAPL) internal research and development pro- grams (AH, GMH, and KMS). Additional support was provided to GMH by the Johns Hopkins University Kavli Neuroscience Discovery Institute and the JHUAPL Innovation and Collaboration Janney Program.

Mr. Armin Hadzic is a computer vision researcher at the Johns Hopkins University Applied Physics Laboratory. He has a B.S. in Computer Engineering, a B.S. in Electrical Engineering, and an M.S. in Computer Science from the University of Kentucky. His research interests include developing deep learning methods to address challenges in latent information representation from multiple sources, as well as computer vision, reinforcement learning, remote sensing, and brain-inspired robotics.

