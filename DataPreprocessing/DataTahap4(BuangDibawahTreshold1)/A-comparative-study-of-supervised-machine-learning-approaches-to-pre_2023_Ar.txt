Methods: A comparative study of selected supervised ML models was conducted to determine the best-performing approach to evaluate patient triage outcomes in hospital emergency departments. A retrospective dataset of 2688 patients who visited the ED between April 1, 2020 and June 9, 2020 was collected. Data included patient de- mographics (age and gender), Vital signs (body temperature, respiratory rate, heart rate, blood pressure and oxygen saturation), chief complaints, and chronic illness. Nine supervised ML techniques were investigated in this study. Models were trained based on patient disposition outcomes and then validated to evaluate their performance.

triage more challenging [16]. Since standard triage tools rely heavily on human judgments, they are subject to high variation and individual bias and may affect the accuracy and precision of triage evaluation [16]. Raising the need for a more robust assessment of patient conditions.

Triage assessment in emergency care systems has become a challenge due to the rapid increase of patients with different acuity levels [20]. Despite traditional triage systems showing a good ability to tackle ED overcrowding, it lacks better patient sorting in busy ED settings. Over- crowding also forces nursing staff to rush the triage process to see other patients, resulting in human errors that can endanger patient lives. The recent advancement of ML technologies has emerged as a solid candi-

clarity issues are essential as they help future researchers whether to adopt or avert these issues for similar problems. Dugas et al. [25] indi- cated that some ED data used in their study might not be based on the same triage system evaluations included in the analysis. This selection of various data sources results in systematic differences between different EDs, where the data collected might have been based on further clinical evaluations of other triage systems or liable to human bias. This can impact predictor outcomes (e.g., accuracy), leading to a significant difference in the statistical performance evaluation. Most studies tried to

[13] followed a manual selection for model hyperparameter tuning. However, these parameters might not be the best to apply to minimize the total error and obtain optimal performance. Moreover, applying random or manual hyperparameter tunning takes time away from essential steps of the ML pipeline, like feature engineering and inter- preting results. This study will address the reported issues in the

A comparative study of selected supervised ML models was con- ducted to determine the best-performing approach to evaluate triage outcomes in hospital ED settings. The collected dataset in this study was extracted from a single-center ED of a university hospital in Istanbul with an annual visit of 200,000 patients. A retrospective dataset of 4540 patients admitted to the ED between April 1, 2020 and June 30, 2020 has been collected. No personally identifiable data is part of the dataset. Data processing and analysis were done using Python 3.9 programming language and some related scientific libraries, including Pandas, NumPy, and scikit-learn [30,31]. Ethical approvals have been granted from all relevant parties.

Data include patient demographics (age and gender), vital signs (respiratory rate, body temperature, oxygen saturation, blood pressure and pulse rate), chief complaints (CCs), and chronic illness. Since we aim to create a simple dataset with less complexity during the model training stage, the chronic illness variable was analyzed based on whether the patient has past or current chronic illness instead of creating multiple columns for each illness. Patient outcomes evaluation was identified based on Manchester Triage System (MTS) as the current triage system used within the hospital. Most of the CCs identified during data analysis were limited to patient complaints related to patients with Coronavirus (COVID-19) symptoms, including (cough, chest pain, fever, etc.). The reason behind that is there was a national lockdown during the data collection stage. Most patients were shielded and avoided visiting hos- pitals due to the fear of contracting the virus. The target variable was patient disposition outcome during their visit to the ED, whether they were discharged, hospitalized (admitted into hospital wards), hospital- ized to isolated wards for COVID-19 suspicion, transferred to the Intensive care unit (ICU), or died.

We have conducted an exploratory data analysis (EDA) to identify the relationship between variables and understand how each variable contributes to the learning process. EDA helps to identify which variable contains the most relevant information that can provide accurate pre- dictions [34]. For this purpose, we analyzed the correlation between each feature before elaborating on the predictive model. We used the Pearson correlation coefficient to determine which features have the most significant impact on others. The Pearson correlation coefficient measures the linear dependence between two random variables (real-- valued vectors) [34]. We used Python Matplotlib and Seaborn data visualization libraries to plot the matrix.

After completing the data pre-processing task, we applied multiple transformation techniques to our dataset. We started by inspecting the skewness in each feature to improve the normality of the data. Fixing the skewness in data is a vital task that must be carried out before building the model. The tail region of the data distribution in skewed data may act as an outlier for the statistical model that can affect the training process. We applied the Box-cox transformation technique for this task to transform the skewed data into normal distribution [35]. We then inspected the outliers within the dataset. We used Interquartile Range (IQR) method to eliminate the outliers from the dataset, which are the patterns that are not in the range of normal behavior [36].

units, and ranges. Since most ML algorithms use Euclidean Distance be- tween two data points in their computations, it can generate wrong computations and, therefore, affect the model evaluation. To solve this problem, we applied standardization as a feature scaling technique. Standardization is the transformation of features by subtracting from the mean and dividing by standard deviation. Standardization rescales a dataset with a mean of zero and a standard deviation of one. This is often

The selection of ML models mainly depends on those algorithms that initially achieved better prediction performance. Multiple algorithms were preselected to train the model before tuning the hyperparameters to select the best-performed algorithms for the primary model selection. Nine models were chosen for the principal analysis used in this study, including (LR, DT, KNN, SVM, MLP, GBDT, XGBoost, AdaBoost, and RF). After selecting the best-performed models, it is essential to tune the

[13]. Since triage is a high-class imbalanced problem, reporting only one evaluation metric, such as accuracy or precession, will not be enough to evaluate model performance, such as Levin et al. [16] evaluation. However, there are no gold-standard performance metrics that can be

class classification problem, only a limited set of performance metrics is available (typically accuracy, recall, precision, and F1-score) [53]. Fawcett [54] also indicated that Receiver operating characteristics (ROC) could be applied to evaluate multiclass problems; however, the complexity of analysis increases with the number of classes. Therefore, this study will only consider the predetermined evaluation metrics to evaluate the performance of the selected models. We first generated the confusion matrix of each model, which is a machine learning concept that provides information about predicted and actual classification values generated by a prediction system [55]. It consists of two di- mensions, the first is the actual classes of the data, and the second is the predicted classes of the dataset. The evaluation metrics defined for bi- nary classification do not apply to the full extent in multi-class classifi- cation problems due to the difference in the matrix dimension between

This study provides a comparative approach between a selected su- pervised machine learning techniques in the case of predicting triage outcomes within hospital ED. The study presented the best methodo- logical practices for the application of machine learning in predicting patient triage in hospital EDs settings with in-depth clarification and explanation of each step taken within this study. We developed multiple ML-based triage models on patient data collected at the time of ED triage. We evaluated multiple triage models and compared their per- formance using standard evaluation metrics. The novelty of this study was not in offering a new machine-learning technique to build the model; instead, this study contributed to tackling some of the short- comings reported in the literature and revealed some important points about the choice of the models as follows: (1) This study applied an automated hyperparameters optimization using genetic algorithm to reduce model bias-variance errors and obtain the optimal performance.

and predict patient needs based on the available data through EHRs [60]. It can also capture complex interactions that are likely to be pre- sent when predicting less specific outcomes [21]. ML techniques have shown promise to enhance predictive triage abilities in many conditions (e.g., Congestive Heart Failure, sepsis) [23] and better analyze patient conditions across a wide range of medical conditions and illness severity

and reduces morbidity and mortality rates. Our developed ML triage models show a high capability in predicting patient disposition out- comes in ED settings for both high acuity and low acuity patients, indicating that machine learning techniques demonstrate high promise in improving predictive abilities in emergency medicine, especially in triage evaluation in ED settings. The implementation of this developed model within the hospital settings, therefore, will translate into a better Manchester Triage evaluation tool that will assist triage nurses in their judgement and provide faster and more accurate evaluation for many complicated cases.

human bias or data input error. Moreover, the models were validated on the same retrospective data. Future research will consider evaluating the model on prospective data. The data sample used for the model devel- opment was relatively small. Finally, this research was conducted on a small data sample compared to the one in the literature; however, the main aim of this research was mainly to compare different ML ap- proaches rather than to implement the model within a hospital envi- ronment. Future research will consider collecting multi-sources large data samples for model development and validation to enhance the generalization and the performance of the model in a broader sample of data.

Machine learning techniques have proven good ability in supporting triage decision-making within hospital ED settings. These models demonstrated a considerable performance in differentiation between patients with critical outcomes (Mortality and ICU admission) from patients with less critical outcomes (e.g., discharged and hospitalized) in ED settings. Implementing these models can enhance patient outcomes, reduce waiting times and length of stay, manage hospital resources more effectively and thus reduce overcrowding. Moreover, the outcomes of this study will benefit future research whether to adapt or ignore certain criteria when designing triage prediction models and guide them toward the best methodological practices for such a problem.

Rahimian F, Salimi-Khorshidi G, Payberah AH, Tran J, Ayala Solares R, Raimondi F, Nazarzadeh M, Canoy D, Rahimi K. Predicting the risk of emergency admission with machine learning: development and validation using linked electronic health records. PLoS Med 2018;15:e1002695. https://doi.org/10.1371/ journal.pmed.1002695.

Ong MEH, Lee Ng CH, Goh K, Liu N, Koh Z, Shahidah N, Zhang T, Fook-Chong S, Lin Z. Prediction of cardiac arrest in critically ill patients presenting to the emergency department using a machine learning score incorporating heart rate variability compared with the modified early warning score. Crit Care 2012;16: R108. https://doi.org/10.1186/cc11396.

