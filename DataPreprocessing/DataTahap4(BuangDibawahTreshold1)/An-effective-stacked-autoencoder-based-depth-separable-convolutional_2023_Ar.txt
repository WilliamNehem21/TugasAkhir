People are still reluctant to go back to work even though the virus will eventually be eradicated, and such sectors are becoming increas- ingly eager to begin employing people face-to-face. 65% of workers today report feeling anxious about returning to the workplace [1]. Since the beginning of the viral pandemic, researchers from all over the world have been looking for answers and strategies that will stop the spread. The current virus travels through the respiratory system of the patient to the lung cells, where it then causes direct harm. The most effective strategy to stop the transmission of the virus is to keep distance from other people and always wear a mask when in a busy or public place.

This study proposes a model for categorising facial photos based on MobileNet. To handle this challenge, the model utilises the Depth Wise Separable Convolution (DWSC) technique. DSC is widely used in the process of identifying issues that arise in image processing. In the

The following outline has been chosen for this research article: The techniques of image processing and deep learning are utilised in the discussion of the current state of the art (SOTA) of face mask identifi- cation in section 2. In addition to this, it addresses the problems and difficulties associated with face mask detection approaches. In section 3, you will find a full presentation of the research methods. It describes the anticipated study endeavour and includes an in-depth architectural breakdown of the architecture. Section 4 provides an in-depth presen- tation of the datasets that were utilised for this body of research work, as well as the experimental setup, trial findings, and related examinations. The research is ended in section 5. It comprises a summary as well as the potential improvements that can be made in the future because of the research work.

William Wells, a professor of engineering at Harvard, and his wife, Mildred Wells, a physician, began using more modern experimental methods to investigate airborne transmission in the 1930s [4]. Infec- tious particles and droplets containing germs are discharged when a person has a cold or illness [5]. The resolution limit for viruses is extremely tiny, much smaller than the one-to two-micron range and is in the five-to-ten-micron region. There are several examples of respiratory viruses involved; regrettably, this happens to them as well [6]. During a few pandemic pathogenicity outbreaks, numerous attempts to prevent or reduce airborne infections were made during this time. This contrasts from all other types of airborne diseases, which are distributed by air pollutants and may move up to 1 m in the air for lengthy periods of time,

It was previously thought that COVID-19 was transmitted through the respiratory system; however, research then showed that airborne transmission was the primary mode of infection [7]. To control airborne infections effectively, a wide range of strategies needed to be employed. This is necessary since diverse organisations hold varying opinions regarding the efficacy of certain strategies. Both air circulation and droplet dispersion have been the subject of a significant amount of

Some studies try to prove that face masks have been demonstrated to be of little benefit [13], even if there is no evidence that they reduce the prevalence of respiratory infections and some of the assumptions about their efficacy are up for debate. But new studies have shown that using a face mask can help prevent the flu, even in otherwise healthy in- dividuals. Although face masks were more useful but had limited effi- cacy, a systematic review of randomised controlled trials evaluating the effectiveness of respirators and face masks against respiratory viruses found that nurses were better protected. Respirators worn by healthcare workers also seemed to be effective, but the results only indicated temporary efficacy.

Early on, the researchers largely concentrated on a few techniques, such as the Gray-scale facial picture algorithms [14]. While AdaBoost, one of the top classifiers at the time, processed the initial information of the face models, a small number of others concentrated on pattern detection techniques. Real-time face detection was made possible later with the development of the Viola-Jones detector. But it had a problem: the dull, low light made it unable to function effectively, and the low light source made it unable to categorise properly. Additional hypoth- eses have evolved to elucidate these notions, describing the same views in further depth. It has been revealed without doubt that many viruses can spread by airborne pathways.

In the recent past, there has been a trend toward the development of object recognition algorithms that utilise deep learning models rather than shallow models [15]. This trend has resulted in deep learning models being theorised to be superior to shallow models in terms of their ability to perform complex tasks. A good illustration of this would be the development of a model or system that operates in real time and is able to determine whether or not individuals in public locations are wearing masks.

For facial detection in Ref. [20], the authors make use of the Darknet-53 (YOLOv3 algorithm). Machine learning and artificial intel- ligence are the two primary components of deep learning, which is largely a blend of the two. In general, it has been demonstrated to be more adaptive and to develop more exact models than ML that is inspired by the operation of brain cells [21].

A method of detection that relies on mobile phones was developed by the authors of [22]. From the Gray-Level Co-Occurrence Matrix (GLCM) of face mask micro images, it was able to obtain three different aspects. The KNN algorithm was utilised to carry out a three-result recognition analysis, which ended up having an accuracy rating of 82.87% overall. The system made use of a gray level co-occurrence matrix to determine the presence of face masks in micro photos. However, given that the model was only compatible with mobile phones, it was clear that it could not be used in all situations.

Facial expressions and face mask detection are related in the sense that they both involve analyzing features of the face. Facial expressions are typically used to infer emotions or mood from the face, while face mask detection is used to determine whether a person is wearing a mask over their face or not. In recent studies [25,26], the authors used directional gradients techniques to recognise the face and expressions of face. Yassine et al. [27] published a review paper on the recent works in face mask detection. The paper described the various parameters that have been used to evaluate the face mask detection.

Using CNN, face mask detection was implemented by Li et al. [18]. It could identify whether an individual was wearing a mask or not to track and enforce compliance to directives given by competent authorities. The authors came up with the HGL approach to categorise head postures by making use of masks for faces. This method involved the examination

In the previous studies, the YOLO-v3, MobileNet and Inception were used along with various techniques for detecting the mask on the face. The proposed work aims to reduce the dimensions of the datasets using PCA technique. It is worth noting that there exists a paucity of research on the application of a stacked autoencoder-based deep learning model with principal component analysis for face mask detection. The objec- tive of the proposed study is to construct a deep learning framework utilising MobileNET-v2 architecture in conjunction with a stacked auto encoder. The images undergo pre-processing by PCA, which serves to decrease dimensionality and reduce time complexity.

Within the scope of this study, an attempt is being made to investi- gate a variety of significant facets of face mask identification. The objective of face detection is to search for and determine the identities of all faces that may be seen in an image or video. If there are numerous faces, each one will have a bounding box surrounding it. This will allow other people to locate each individual face if there are multiple faces.

It is common practise to identify things based on the unique qualities that they possess. A human face can be distinguished from a wide variety of other things due to the fact that it possesses a number of distinctive traits. It does this by isolating structural features of the face, such as the eyes, nose, and mouth, and then utilising those features to determine the identity of a face. A statistical classifier is helpful in most situations for distinguishing between areas of the face and areas that do not contain faces. Additionally, human faces have distinct textures that can be used to differentiate them from the textures of other objects. In addition, one can identify elements on a face by looking at the boundaries of the characteristics that make up that item. In the following section, it will utilise OpenCV to design a feature-based approach, and then it will use NumPy to evaluate that approach.

A sophisticated framework successfully developed has been demonstrated in this article for the purpose of identifying masks in the face of individuals. The learning architecture generates results by clas- sifying the input picture according to whether it has a mask. These findings are output. A warning is displayed if an individual is not wearing a mask or is not correctly applying it to their face. If the user

puts on a mask and applies it correctly, the remaining procedures can continue. Because of this, everyone will be safe from the respiratory droplet transmissions so long as they wear their masks appropriately. In this way, the utilisation of this technology will contribute to the reduction in the proliferation of any droplet-based transmissions. If the

Before moving on to the testing and training of the model, it is necessary to complete this crucial phase, which assists in the processing of the data. As soon as it reaches this point, it will initiate the process of turning all of the images that are contained within the dataset files into arrays. It will develop the deep learning module by utilising these arrays as its building blocks and all the relevant tools are going to be imported from the corresponding modules. Then, following the completion of the data processing and the delivery of the conclusions to user in the form of labels and then it will proceed to construct the variables and objects.

another type of data that has a high degree of correlation. When it comes to the extraction of characteristics from pictures, PCA performs signifi- cantly better. The image matrix is subjected to a variety of processes, after which it is turned into an eigen subspace with less dimensions. After that, the covariance matrix is computed using the lower- dimensional matrix, as a starting point for computation. The covari- ance matrix is a representation of the relative variation that exists be- tween individual pixels in an image. After that, Eigen vectors are computed using the covariance matrix as a starting point. The Eigen vectors that have the highest values are the ones that are taken into consideration to be the principal components.

There is a possibility that a single autoencoder will be unable to bring down the dimensionality of the input features. As a result, for situations like these, we make use of stacked autoencoders. As its name indicates, stacked autoencoders are a collection of encoders that are arranged in a vertical stack. The stacked autoencoder works based on the following principle.

an output layer make up a network. There are several levels of convo- lution in hidden layers. Numerous dense neural networks employ the characteristics collected from CNNs for categorization. There are three pairs of convection levels in each of the 32 formations, followed by the highest pooling level. 100 kernels with a 3x3 window size and a maximum pooling level of 2x2 window size make up the convolution layer. The highest value inside the 2x2 frame will be chosen by this layer after combining the results of the preceding convolution level.

For unlabelled input, the autoencoder consists of two core models: an encoder and a decoder. The input feature map is encoded using an encoder, and then the feature map is decoded and rebuilt using a decoder module. For a more comprehensive modelling of the features in this study, it squeezed the output feature vector from the MobileNetV2 model using the encoder function of the stacked autoencoder. Global average pooling is used to decrease the output dimensions of the

global average pooling to further extract more representative compo- nents for the last stage classification. The features vectors 1280 di- mensions are first converted to 640 and then to 320 dimensions. The autoencoder complexity is mostly decreased by feature encoding uti- lising their halves.

The comparison of the effectiveness of proposed algorithm makes use of a confusion matrix. By combining the values of True Negative (TN), True Positive (TP), False Negative (FN), and False Positive (FP), this matrix is used to generate various metrics. The performance metrics used to assess models using the confusion matrix are listed below.

rate against its false positive rate at a variety of threshold values. Because lower values on the x-axis indicate a lesser number of false positives and a higher number of true negatives, the fact that the curve is located in the top-left corner is seen as a sign of excellent performance. On the other hand, a higher significance level on the y-axis indicates a lower number of false negatives and a higher number of real positives. The time complexity of using PCA with DWSC for detecting masks in the face will depend on several factors, including the size of the input images, the number of principal components selected, and the archi- tecture of the DWSC. PCA involves computing the eigenvectors and ei- genvalues of the covariance matrix of the input data. The time

The proposed work is experimented using Windows 10 computer, an Intel Core i5 processor, and Nvidia GTX 1080 GPU for the tests. Pro- gramming was carried out using Python 3.8. The pre-trained model is using 224x3 STIF frames. The proposed approach is tested using this

dataset. Datasets for training and testing have been produced. The scaling factor was first set at 0.001, and after that, it decreases by a factor of 0.9 every 10 epochs. The Adam optimizer uses a momentum value of 0.999. The training process is repeated up till 100 epochs have

evaluates the results of the research in comparison to the original con- volutional filters. According to the findings of the trials, the proposed system performed much better than the existing conventional convolu- tions. In addition, past work on a motivated baseline approach is compared with the strategy that has been offered here. According to the results, which include an accuracy score of 94.1%, a precision score of 97.6%, a recall score of 94.4%, and an F-score of 96.01%. The DWSC- PCA-SAE algorithm generates the greatest overall performance across a range of evaluation criteria. This model needs additional processing to create visualisations, and due to the limitations of the dataset, it is un- able to differentiate between appropriate and inappropriate mask application. In the future, one of our goals is to provide face mask identification datasets that include a variety of various mask wearing

Howard J, Huang A, Li Z, Tufekci Z, Zdimal V, van der Westhuizen H, von Delft A, Price A, Fridman L, Tang L, Tang V, Watson GL, Bax CE, Shaikh R, Questier F, Hernandez D, Chu LF, Ramirez CM, Rimoin AW. Face masks against COVID-19: an evidence review. Preprints 2020:2020040203. https://doi:10.20944/preprints20 2004.0203.v1.

Jimenez JL, Marr LC, Randall K, Ewing ET, Tufekci Z, Greenhalgh T, Tellier R, Tang JW, Li Y, Morawska L, Mesiano-Crookston J, Fisman D, Hegarty O, Dancer SJ, Bluyssen PM, Buonanno G, Loomans MGLC, Bahnfleth WP, Yao M, Sekhar C, Wargocki P, Melikov AK, Prather KA. What were the historical reasons for the resistance to recognizing airborne transmission during the COVID-19 pandemic? Indoor Air 2022 Aug;32(8):e13070. https://doi.org/10.1111/ina.13070. PMID: 36040283; PMCID: PMC9538841.

