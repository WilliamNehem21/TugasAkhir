Array 11 (2021) 100070

Contents lists available at ScienceDirect

Array

journal homepage: www.elsevier.com/journals/array/2590-0056/open-access-journal

All-Three: Near-optimal and domain-independent algorithms for
near-duplicate detection

Aziz Fellah

School of Computer Science and Information Systems, Northwest Missouri State University, Maryville, MO, 64468, USA

A R T I C L E I N F O

A B S T R A C T

Keywords:
Near-duplicate detection
Near-duplicates
Approximate duplicates
Clustering
Data mining applications and discovery
Data cleaning

In this paper, we propose a general domain-independent approach called Merge-Filter Representative-based
Clustering (Merge(cid:1)Filter(cid:1)RC) for detecting near-duplicate records within a single and across multiple data
sources. Subsequently, we develop three near-optimal classes of algorithms: constant threshold (CT) variable
threshold (VT) and function threshold (FT), which we collectively call All(cid:1)Three algorithms. Merge(cid:1)Filter(cid:1)RC
and All(cid:1)Three mold the basis of this work. Merge(cid:1)Filter(cid:1)RC works recursively in the spirit of divide-merge
fashion for distilling locally and globally near-duplicates as hierarchical clusters along with their prototype
representatives. Each cluster is characterized by one or more representatives which are in turn reﬁned dynami-
cally. Representatives are used for further similarity comparisons to reduce the number of pairwise comparisons
and consequently the search space. In addition, we segregate the results of the comparisons by labels which we
refer to as very similar, similar, or not similar. We complement All(cid:1)Three algorithms by a more thorough
reexamination of the original well-tuned features of the seminal work of Monge-Elkan's (ME) algorithm which we
circumvented by an afﬁne variant of the Smith-Waterman's (SW) similarity measure.

Using both real-world benchmarks and synthetically generated data sets, we performed several experiments
and extensive analysis to show that All(cid:1)Three algorithms which are rooted in the Merge(cid:1)Filter(cid:1)RC approach
signiﬁcantly outperform Monge-Elkan's algorithm in terms of accuracy in detecting near-duplicates. In addition,
All(cid:1)Three algorithms are as efﬁcient in terms of computations as Monge-Elkan's algorithm.

1. Introduction

The problem of identifying whether multiple representations of a
real-world entity or object are the same has been originally deﬁned by
NewCombe et al. [1]. Since then, this long-standing problem has been
studied extensively in computer science and related ﬁelds under various
names using a multiplicity of terminology; just to name, record linkage
[2,3] in the statistics community, approximate matching [4] in infor-
mation retrieval, entity resolution [5], object identiﬁcation [6] in ma-
chine learning, merge/purge [4,7,8] and near-duplicate detection [9–18]
in databases and algorithms. In large and various databases, a major task
in a data cleaning process is identifying sets of records that are seman-
tically duplicates of each other, but not syntactically identical. Such type
of duplicate records are also referred to as similar, approximate or
near-duplicates in research literature. In the context of this paper, we
adopt the last terminology, that is, near-duplicates. The most common
variations in representing the same entity (i.e., records, objects) with a
multitude of representations can primarily arise from typographical er-
rors, misspellings, missing data, and differences in abbreviations and

schemes, as well as the integration of multiples data sources into a single
data set. In general in data cleaning, near-duplicates may exist within a
single source, whereas in data integration near-duplicates may exist
within or across various data sources. However, both cases have the same
common goal, detecting near-duplicates and the closeness of similarity
among entities in a large collection accurately and efﬁciently. That is, to
determine which records/objects in the same or different databases refer
to the same underlying real-world entity.

For example, consider the following references that have been
recorded at three different colleges, “Jeff David Ullman Stanford Univer-
sity, Dept. of Computer Science”; “Jeffrey D. Ullman Computer Science Dept.,
Stanford Univ., CA, USA”; “J. D. Ullman, Department of Computer Science,
Stanford University, USA”. All the three references refer to the same in-
dividual, even though they are quite different if byte-by-byte compari-
sons are used. It is often the case that data in different repositories hold
information regarding identical entities, but might be stored in different
formats and schemes which may result in a possible data inconsistency
and nonconformity. One example would be identifying authors and ci-
tations in a bibliography database such as DBLP, CompuScience, and

E-mail address: afellah@nwmissouri.edu.

https://doi.org/10.1016/j.array.2021.100070
Received 20 February 2021; Received in revised form 5 May 2021; Accepted 12 May 2021
Available online 27 May 2021
2590-0056/© 2021 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

A. Fellah

Array 11 (2021) 100070

CiteSeer. Several algorithms, in particular domain-dependent, for quan-
tifying the degree of similarities have received particular attention in a
wide range of applications, including web search engines and mining,
medical and census data, plagiarism and spams, mailing list deduplica-
tion, and image database. A substantial body of research has been con-
ducted in a spectrum of domains, see for example [19–28].

2. Background and related work

Naive near-duplicate detection methods which are based on
comparing every pair of records become intractable in the context of
huge data collections such as social networks. For example, Facebook
with over 2.97 billion active users worldwide, results in more than 2.45
(cid:3) 1019 comparisons. Several methodologies and solutions have been
proposed in research to reduce the total computational cost and improve
the accuracy. In a stand-alone literature review, a variety of blocking
methods which are based on the selection of a key (blocking key) for
generating subsets of potential near duplicates have been investigated in
research [5,11,29]. The main focus of these methods is that records
having the same key value should be added to the same block and labeled
as potential near-duplicates for further analysis. Jaro and Winkler [3,24,
30] extended the key-based approach by using expressions with multiple
keys which increases the accuracy and reduces the number of false
matches and false misses. Such keys can be adjusted interactively by
trial-and-error analysis to achieve the best results. However, the process
of ﬁnding a perfect key is often difﬁcult and requires good domain
knowledge. Other related blocking criteria based on applications’ char-
acteristics (i.e., medical, census, bibliography data) are also used as a
ﬁrst-step preprocessing to identify initial blocking. In general, blocking
algorithms are of low time complexity, but with several drawbacks. For
example, records with minor typographical errors or simple misspelling
are clustered in different blocks. It has been observed in Refs. [23,24]
that 40–70% of the matches are found in the ﬁrst blocking pass. By the
fourth blocking pass, 0.0001% of the pairs are actually duplicates. These
results show that the proportions of pairs that were duplicates in suc-
cessive blocking criteria fell at an exponential rate. A well-known
duplicate detection framework known as sorted neighborhood method
(SNM) was proposed by Hernandez and Stolfo [8,31] and is based on that
near-duplicates tend to localize in the neighborhood. The algorithm uses
blocking to sort all records based on a sorting key and then slides
sequentially a window of ﬁxed size (sliding window) over the sorted re-
cords. The window uses the blocking scheme by including all records
with similar keys (lexically nearby keys) in the same window. All records
within each sliding window are considered as potential near-duplicates
and then compared with each other, however, the window size is difﬁ-
cult to set. Overall, the sliding window is a more robust approach than
other techniques in improving the near-duplicate detection accuracy, but
it is likely to fail in grouping similar records outside the window size if
substantial typographical errors occurs in the ﬁrst characters of the
sorting key. Moreover, there is substantial research that has been pro-
posed as an umbrella for SNM where blocking has been empirically
evaluated on different domains and data sets. Some of these extended
variations of SNM and blocking approaches outperform the basic SNM
and blocking approaches in terms of reducing the complexity cost and
improving the accuracy. For instance, Yan et al. [7] proposed an adaptive
variant scheme of SNM for record linkage by adjusting the size of the
sliding window dynamically during the execution time to build
non-overlapping blocks, but it has been conﬁrmed that their work did not
outperform the original SNM. Other complicated near-duplicate identi-
ﬁcation techniques such as q-gram,
iterative blocking, overlapping
blocking, multiple blocking, token-based, learning process, and domain
knowledge, with some assumptions on the entities have been investi-
gated in the literature, just to name few [5,25,32–34].

Furthermore, with rapid advances in big data computing and web era,
near-duplicate detection research is expanding in many ways to industry
applications such as managing massive documents, and extracting

insights and multi-dimensional information from business, ﬁnancial (i.e.,
credit cards), and healthcare data. A comprehensive evaluation and an
umbrella of techniques have been investigated. A common factor be-
tween these algorithms is they cannot guarantee ﬁnding all near-
duplicates and also cannot guarantee the accuracy. Vogal et al. [35]
provided an annealing standard to evaluate near-duplicate detection
results. In other words, the accuracy and completeness of duplicates
should converge incrementally and interatively to a gold or silver stan-
dard that deﬁnes which records represent the same real-world entities.
Near-duplicate detection algorithms mainly focus on effectiveness
and efﬁciency, but not on scalability which has been addressed by
Naumann et al. [36], who assign appropriate similarity measures to at-
tributes based on their semantics. For instance, names of persons should
be compared differently than email addresses even though they belong to
the same string data type. Overall, most of these methods require a good
understanding of the application domain and a supervised user interac-
tion for reﬁning and adjusting parameters such as distance functions,
window size, and thresholds.

The most predominant domain-independent algorithm for near-
duplicate detection is that of Monge-Elkan (ME) [4,14]. This seminal
work is based on stretching adequately the SNM's sliding window [8] that
holds a ﬁxed number of record sets and grouping records into clusters.
Monge-Elkan's algorithm has a much more improved efﬁciency over
many duplication methods including the SNM algorithm, but has the
same detection accuracy as the SNM and performs even far better than a
large number of other algorithms in terms of time and accuracy. In
addition, a spectrum of similarity and distance measures, highly depen-
dent on the application domain, have been investigated in the literature
and are certainly not a new area of research. They range from fairly
simple schemes to more complex well-tuned edit distances. The most
prominent class of character-based metrics known as edit distances are
Levenshtien, Jaro-Winkler, and Smith-Waterman similarity measures [3,
30,37]. One
the
the
Needleman-Wunsch [38], which additionally allows variable sub-
stitution's cost for different characters. That is, it provides a mapping for
each pair of symbols (i.e., characters) from the alphabet to some cost.
Other effective similarity measures, token-based and hybrid metrics,
have been also investigated in the literature, for example, Jaccard,
n-grams, Cosine, Monge-Elkan, and natural language processing tech-
niques (i.e., TF-IDF) similarity measures. Similarity metrics range from
fairly simple schemes to more complex well-tuned edit distances, see for
example, [11,13,37,38].

Levenshtein

extension

distance

to

is

3. Contributions

We propose a new generalized domain-independent framework and
subsequently three classes of algorithms for detecting near-duplicates
among entities within one or more attributes in large database sets.
These algorithms are synthetically complemented by near-duplicate
generator algorithm (NDG). In the rest of the paper, we refer to such a
framework as Merge-Filter Representative-based Clustering (Mer-
ge(cid:1)Filter(cid:1)RC) and to such a set of algorithms as constant threshold (CT),
variable threshold (VT), and function thresholds (FT), respectively. For
convenience, we collectively refer to these three algorithms as All(cid:1)Three
algorithms and to a speciﬁc algorithm by its conventional name, either
CT, VT, or FT. In addition, we integrate an efﬁcient synthetic near-
duplicate generator algorithm (NDG) into All(cid:1)Three algorithms. The
NDG algorithm is capable of scaling up to generate algorithmically tens of
millions of synthetic records. One of our aim here is to capture and
modify the full power of Monge-Elkan (ME) [4,14] and Smith-Waterman
(SW) [37] algorithms in the context of our work. That is, Mer-
ge(cid:1)Filter(cid:1)RC is a domain-independent approach that combines the
token-based of Monge-Elkan and the character-based internal of
Smith-Waterman similarity function, both of which we modiﬁed and
augmented with a well-tuned afﬁne parameterization. Still, this is not
enough to solve the quality and complexity of our approach due to

2

A. Fellah

Array 11 (2021) 100070

anomalies which are associated with the transitivity relation and
threshold choices. Thus, we segregate the results of the comparisons by
labels which we refer to as very similar, similar, or not similar, and
furthermore minimize an objective function without the user's inter-
vention. Each constructed cluster has one or more representatives which
are dynamically computed to measure the prototypicality of each record
in the cluster. The record comparison is performed with only represen-
tatives rather than with all records in the cluster. Thus, records do not
have to be compared to all other records, but to only cluster represen-
tatives which are considered for subsequent comparisons. We introduce
cluster representatives which retain the most relevant syntactic and se-
mantics features of the records in the cluster. The idea behind this
approach is that cluster representatives reduce the total number of record
comparisons, without reducing substantially the accuracy of the dupli-
cate detection process.

Clusters’ representatives are dynamically distilled and accurately
achieved throughout a set of comparison functions, very similar, similar,
or not similar, and threshold settings, constant, variable, or function. The
number of similarity comparisons is reduced from O(n2) to O(nm), where
m and and n are the number of representatives and records, respectively
and m ≪ n, m is always independent of n, but dependent on the class of
the algorithm. Each of these algorithms has a different impact when
running on a set of thresholds, a constant, variable, or function. All al-
gorithms are implemented in Cþþ and use the same data set to make fair
comparisons. We ran an extensive experimental study using several real
benchmarks and algorithmically generated synthetic data. We do not
assume any speciﬁc structure in the data nor rely on any information
available in the source data. That is, data has not been standardized,
preprocessed, nor transformed, and syntactic as well as semantic errors
remain as potential errors in the data. Experimental implementations
show the Merge(cid:1)Filter(cid:1)RC detection approach greatly reduces the
number of comparisons and the precision achieves a value of nearly 1.0, a
precision which is close to the optimal outperforming consistently the
seminal work of Monge-Elkan.

Our proposed set of algorithms do not presume a speciﬁc application
domain, but in contrast they are tuned toward any domain-independent
applications. Monge-Elkan's (ME) algorithm is relatively domain-
independent with the purpose of integrating and matching web scienti-
ﬁc papers from multiple sources, typically an alphanumeric domain class.
The parameters used in ME are mapped to such a class of applications
with only a restricted possibility of tuning the threshold values to provide
a better accuracy. In addition, the heuristic method of ME minimizes the
number of pairwise record comparisons with potential record duplicates
and integrates some key concepts such as the minimum edit-distance of
SW.

The rest of the paper is organized as follows. Section 3 reviews and
summarizes the effectiveness of Monge-Elkan and Smith-Waterman al-
gorithms. Section 4 addresses the metric measures used in detecting near-
duplicates. Section 5 explains how to calculate and choose between
precision and recall using F-measure. The choice, adjustment, and
threshold tuning are deﬁned in this section.

Section 6 proposes the merge-ﬁlter cluster representative framework
which addresses the details of the accuracy performance using cluster
representatives throughout precision and recall metrics. Section 7 pro-
vides a fully algorithmic technique and presents three different domain-
independent algorithms, constant, variable, and function thresholds for
detecting near-duplicates, all of
the umbrella of
Merge(cid:1)Filter(cid:1)RC.

them under

In Section 8, we present a thorough experimental evaluation of our
approach and compare the effectiveness of All(cid:1)Three algorithms in
terms of accuracy and efﬁciency with the seminal work of Monge-Elkan.
We used benchmark data as well as synthetic data to meet speciﬁc con-
ditions that are not available in existing real data. Synthetic data has been
generated using the near-duplicate generator (NDG) algorithm. Section 9
concludes the paper with potential and future research directions. In
addition, we provide an appendix to make our paper self contained.

3

4. Effectiveness of Monge-Elkan and Smith-Waterman algorithms

In this paper, we focus on the Smith-Waterman (SW) edit distance
[37] that was originally developed for identifying common molecular
subsequences, like DNA or proteins. Two strings x and y may not be
entirely similar but contain regions, perhaps in the middle, that exhibit
high similarity. Finding such a pair of regions, one from each of the two
strings, is referred to as a local alignment. The Smith-Waterman algorithm
ﬁnds the local alignment between two strings with the maximum possible
score using a dynamic approach that runs in O(|x||y|) time. The main
limitation of SW is it places heavier penalties (i.e., higher cost) on mis-
matches in the middle of strings rather than at the beginning and the end
of strings. This may create a problem when the errors are in the middle of
the strings. In this regard and in order to eliminate this inconvenience,
we primarily consider the Monge-Elkan's methodology [14,26], a
well-tuned matching methodology normalized in the interval ½0; 1(cid:4),
allowing additional parameters, and introduces gaps in the alignment of
two strings. Much of the power of the Monge-Elkan's algorithm is due to
its ability to include sequences of non-matching characters, gaps (afﬁne
gaps), in the alignment of two strings. In our work, we add the gap cost as
another variant of the Smith-Waterman (SW) algorithm that offers a
solution to the above problem and other related duplicate detection is-
sues. By adding a cost, we extend the two extra edit operations, starting
gap and extending gap.

In general and for instance, the gap penalty denoted by cost(gap) ¼ s
þ e (cid:3) l, where s is the afﬁne cost of starting a gap in an alignment, e is the
cost of extending a gap, and l is the length of a gap in the alignment of two
strings. Usually afﬁne gap penalizes gap extension less than gap opening
(e < s) thus we decrease the penalty for contiguous mismatched sub-
strings by using a single long gap over many short gaps. Since the dif-
ferences between near-duplicate records often arise because of many
abbreviations or extra-string insertions and omissions, the afﬁne-gap
model produces a better similarity and more accurate results than most
the other edit distance metrics. Moreover, the afﬁne-gap algorithm per-
forms well to detect similarities when records have minor syntactical
differences, including typographical errors, abbreviations, and trunca-
tions. In fact, the Monge-Elkan's algorithm approximates the solution to
the optimal assignment problem in combinatorial optimization. This
approximation is a reasonable trade-off between accuracy and
complexity.

In sum, Monge-Elkan's complexity is quadratic in number of tokens
and one can deﬁne the Monge-Elkan's measure over two text strings that
contain several tokens as:

MongeElkanðx; yÞ ¼

1
jxj

Xjxj

i¼1

max sim
j¼1;jyj

ðx½i(cid:4); y½i(cid:4)Þ

where |x| and |y| are the number of tokens in x and y, respectively and
sim(x, y) is an internal similarity function to measure the similarity be-
tween two individual tokens.

In the paper, we adopt a modiﬁed version of the Smith-Waterman
similarity edit distance as inter-token similarity measure. Formally, let
c(xi, yi) denote the cost of the edit distance that aligns ith character of
string x to jth character of string y. Then the SW algorithm computes a
cost matrix M that represents a maximum-cost string alignment by the
following recurrence rule based on Monge-Elkan's algorithm [4].

(cid:3)

xi;yj

8

>>>><
Mði;jÞ¼max
>>>>:

(cid:2)
Mði(cid:1)1;j(cid:1)1Þþc
Mði(cid:1)1;jÞþe
Mði(cid:1)1;jÞþs
Mði;j(cid:1)1Þþe
Mði;j(cid:1)1Þþs

if alignði(cid:1)1;j(cid:1)1Þends in a gap
if alignði(cid:1)1;j(cid:1)1Þends in a match
if alignði(cid:1)1;j(cid:1)1Þends in a gap
if alignði(cid:1)1;j(cid:1)1Þends in a match

5. Metric measures and threshold effects

Similarity refers to a measure of likeness between two objects (i.e.,

A. Fellah

Array 11 (2021) 100070

records, entities); and the dissimilarity between two objects is refereed
to as a distance. We deﬁne a record as a set of tokens drawn from a ﬁnite
universe U. Let n be the number of real-world entities over a plurality of
large databases that consist of records Rn ¼ r1; r2; …; rn, where a large
number of ri are potential near-duplicates. We denote by D ¼ D1; D2;
…; Dd the set of problem domains.

Similarity and distance measures are often normalized in the range
½0; 1(cid:4), and ½0; ∞(cid:4) or ½0; some distance(cid:4), respectively. Formally, we deﬁne
a similarity and distance measures as follows:

Deﬁnition 5.1. A similarity measure is a non-negative function sim:
D1 (cid:3) D2 → [0,1], such that sim(r1, r2) ¼ 0 if r1 and r2 are least similar
and sim(r1, r2) ¼ 1 if r1 and r2 are identical. (D1 might be equal to D2).

Deﬁnition 5.2. A distance measure is a non-negative function dist:
D1 (cid:3) D2 → [0, 1], such that dist(r1, r2) ¼ 0 if r1 and r2 are exactly
similar or identical, and dist(r1, r2) ¼ 1 if r1 and r2 are not similar.

The search space for detecting near-duplicates can be reduced under
the assumption the relation “is duplicate of” or “is similar to”, is transitive.
However, the theory of transitivity is not always ﬂawless in practice
because of the propagation of errors as explained earlier. Duplicate re-
cords tend to be sparsely distributed over a large database space and the
propagation of errors is statistically insigniﬁcant [26]. The complexity
and evaluation measures to assess a near-duplicate record algorithm that
have been addressed are the efﬁciency and accuracy. Accuracy is
considered the most
important quality assessment dimension in
near-duplicate algorithms, and it is measured in terms of two prominent
measures, precision and recall. The other related measure is F-measure
which determines the harmonic mean of the precision and recall values.
The goal of our evaluation is to ﬁnd the best metrics in terms of quality
and effectiveness with respect to different domain-independent data sets.
We classify each value pair of comparisons as very similar, similar, or not
since errors may occur during the process of detecting
similar
near-duplicates. For completeness, as it is illustrated in Fig. 1, we divide
the search space into subspaces and denote by true positives all candidate
pairs that are correctly declared to be duplicates (i.e., expected matches),
and false positives all candidate pairs that are incorrectly declared to be
duplicates while in fact they may not be duplicates (i.e., there should not
be a match).

Similarly, true negatives are pairs that are correctly recognized as not
being duplicates (i.e., expected mismatch), and false negatives are pairs
that are not declared to be duplicates while in fact they are (i.e., there
should be a match). The metric precision measures the fraction of correct
duplicates over the total number of record pairs classiﬁed as duplicates
by the algorithm. The metric recall measures the fraction of records
correctly clustered over the total number of duplicates. A high recall
means no false misses and a high precision means few false matches;
thus, there is a trade-off between high recall and high precision. The
other measure we want to introduce is the reduction ratio, which is the
relative reduction in the number of pairs to be compared. This means a
search space reduction strategy is needed in order to reduce the number
of record comparisons. As a consequence, we introduce prototype cluster

Fig. 1. Similarity threshold factors and tradeoff between prominent mea-
sure metrics.

4

representatives which retain the most relevant syntactic and semantics
features of the records in the cluster where comparisons take place with
cluster representatives, instead of all records, thus the search space can
be reduced with the improvement of both true and declared subspaces. In
other words, the reduction of false positives and in particular false neg-
atives have an impact on the accuracy. A high recall means no false
misses and indicates high accuracy of the duplicate detection results. A
high reduction ratio achieves an even more effective search space
reduction. A high precision means few false matches and has the opposite
effect than recall. The other metric measure, reduction ratio in the range
of ½0; 1(cid:4), is deﬁned as 1 - (declared duplicates/all tuple pairs). The simi-
larity threshold line in Fig. 1 ensures a trade-off among recall, precision
and reduction ratio. If we shift the similarity threshold line (similarity
threshold 1) to the right, consequently more tuple pairs will be rejected
and increase the reduction ratio and precision. This rejection would ul-
timately lead to decrease the recall metric. If we shift the similarity
threshold line to the left then the opposite trade-off effect between recall,
precision, and reduction ratio will take place. Similarly and in the same
fashion, shifting the similarity threshold line (similarity threshold 2)
would have an effect on true and false positives.

Relations between threshold similarity metrics and accuracy are an
important part of the near-duplication detection process. Different
threshold setting and parameter tuning (i.e., distance functions, window
size) have been used to classify whether a pair of records is a duplicate or
a non-duplicate. Several experiments have been conducted and cutoff
thresholds for a speciﬁc application domain with its own characteristics,
often manually conﬁgured, have shown to achieve the “best” precision,
recall and F-measure values. The cutoff value of the threshold along with
other key tuning parameters can be very time consuming as the search
space can grow exhaustively and even exponentially, which necessitates
some forms of threshold optimization [35,39,40].

6. Merge-Filter Representative-based Clustering: A near-optimal
domain-independent approach

Similar in spirit to divide and merge methodology for clustering [41],
Merge-Filter Representative-based Clustering (Merge(cid:1)Filter(cid:1)RC) com-
bines a top-down divide phase with a bottom-up merge phase in a hier-
archical scheme as described in subsequent sections. Merge(cid:1)Filter(cid:1)RC is
made of two trees, a top-down and bottom-up tree, annotated with
cluster records. Merge(cid:1)Filter(cid:1)RC is mainly geared towards the needs of
detecting near-duplicates with a provision of forming the best possible
near-optimal clusters of records by integrating a variant of Smith-Wa-
terman's and Monge-Elkan's algorithms into the detection approach.
Importantly, we are only interested in unconstrained algorithms, rather
than adopting any standard clustering algorithm. That is, there is no
preliminary assumption of rationality to choose the number of clusters as
input or other domain speciﬁc parameters. Let C denote the initial cluster
containing n records in Rn, and d denote the depth of a node in the
top-down cluster tree T whose root (C; n) is at d ¼ 0 and internal nodes
are (C i, nb), where Ci and nb refer to the name of the cluster and the
number of records in C i, respectively as illustrated in Fig. 2. The divide
phase of Merge(cid:1)Filter(cid:1)RC recursively splits the collection of records
into two equal halves at each level of T and constructs the tree T on the
basis of these records. The near-duplicate detection process starts with
is expected to contain
the data set of
near-duplicate records. We start the construction at the root with n re-
cords and end-up at the leaf level with one single record per cluster, (C l,
1) (Fig. 2). The number of times the split is done is exactly equal to the
height of the tree T, O(log n), because the size of the clusters decreases
approximately by half at each level of T which is deﬁned as follows:

the initial cluster C that

Deﬁnition 6.1. A top-down cluster tree T is a full binary tree such that
(i) the nodes of T are subclusters of C (ii) every internal node of T has two
subcluster of records, each of size n/2d, (iii) every leaf of T is a subcluster
of records of size one; (iv) the root node of T is the cluster C that consists

A. Fellah

Array 11 (2021) 100070

Fig. 2. Construction of a top-down cluster tree T.

of n records.

Let ℂ ¼ C 1; C 2; …; C n be the set of clusters of T produced by the
divide phase. Each internal node of T is a subset of the data set records.
The left and right children of a node C i forms a partition of the parent
such that∣ C i∣¼ n=2d and 1 (cid:5) i, i (cid:5) n (Fig. 2). Let T be a top-down cluster
tree then for any two clusters we have either C i ⊂ C j or C j ⊂ C i or
C i \ C j ¼ ∅, i 6¼ j, 1 (cid:5) i, j (cid:5) n.

^C 1; ^C 2; …; ^C q where one or more

Starting at the leaves of T, the bottom-up merging phase is applied
recursively to each node of T towards the root enabling the construction
of a new tree of clusters whose root is ^T as depicted in Fig. 3. To
^C i in the
accomplish this, the near-optimal cluster of an interior node
tree ^T is obtained by merging and distilling dynamically the near-optimal
^C i. The result of clustering T is a
clusters of the left and right children of
^C i are the nodes of ^T,
partition ^C ¼
referred to as near-optimal duplicate tree, i (cid:5) q and q ≪ n (q is much less
than n). The value of q is not known in advance and is independent of n.
At the beginning of the Merge(cid:1)Filter(cid:1)RC bottom-up phase, we
initialize the set of leaf clusters of ^T with the set of leaf clusters of T. Then,
we apply a hierarchical agglomerative clustering to the leaf clusters by
bringing the leaves up to the root level by level, and near-optimizing the
objective function locally at each iteration when two clusters are
compared and eventually merged. The choice of the objective function
uses the dynamic programming of SW algorithm reﬁned by different
parameters as it will be explained in the next sections. Each constructed
^C i has one or more cluster representatives that are dynamically
cluster
computed to measure the prototypicality of each record in the cluster.
The record comparison is performed with only representatives rather
than with all records in the cluster. Consequently, records do not have to
be compared to all others but only cluster representatives are considered
for subsequent comparisons. That is, if a given record is not similar to a
record(s) in a set of cluster representatives then it will not match the
other record members of the cluster. In general, Merge(cid:1)Filter(cid:1)RC takes
^C j), and their
as parameters two unordered pairs of clusters (
respective cluster representatives ( ^Ri, ^Rj) where 1 (cid:5) i, j (cid:5) n, then returns
^C j) are very similar, similar or not similar by ﬁnding the
whether (
optimal local alignment using the SW algorithm with the maximum

^C i,

^C i,

(cid:4)
(cid:4)
(cid:4) ^Ri

(cid:4)
(cid:4)
(cid:4) ^C i

j¼1 and f^rijgl

(cid:4)
(cid:4)
(cid:4) ¼ k and

similarity score. Let such a set of cluster representatives denoted by ^Ri ¼
f^ri1;^ri2; …;^rijg, 1 (cid:5) j (cid:5) l where l indicates the number of representatives
(cid:4)
(cid:4)
for a ﬁxed i.
(cid:4) ¼ l, where l is much less than k. Every
^C i, represented as a node in ^T, has a set of near-
generated ith cluster
duplicates and cluster representatives referred to as frijgk
j¼1,
respectively. The results of detecting near-duplicates, however, may
become sensitive to the initial selection of representatives. Initially,
Merge(cid:1)Filter(cid:1)RC uses one record as a cluster representative, then rep-
resentative(s) might be subsequently updated, either by retaining the
same ones or iteratively re-computing and re-assigning new representa-
tives. In addition, Merge(cid:1)Filter(cid:1)RC enforces transitivity between re-
^C i. Each remaining record is compared to the
cords in a cluster
representatives and placed in the cluster of the closest representative.
The idea behind this approach is that cluster representatives reduce the
total number of record comparisons, without reducing substantially the
accuracy of the duplicate detection process. The number of similarity
comparisons to be considered is reduced from O(n2) to O(nm), where m
and and n are the number of representatives and records, respectively. m
≪ n and m is always independent of n, but dependent on the class of the
algorithm (constant, variable, or function).

The cornerstone property of Merge(cid:1)Filter(cid:1)RC is based on the choice
of the appropriate objective function g and its parameters. We are
interested in ﬁnding locally the optimal clustering at each level of ^T, and
also ﬁnding globally the near-optimal clustering at the root created by
the Merge(cid:1)Filter(cid:1)RC merge phase. That is, g should guarantee to ﬁnd
the optimal local alignment, OPTðAÞ, and quantiﬁes the similarity in
terms of a high-scoring alignment A. That is, we maximize the objective
function g by assigning a score for each alignment obtained by the SW
algorithm. Let Σ* denote the set of ﬁnite words over an alphabet Σ and x
¼ x1…xp, y ¼ y1…yq where x, y 2 Σ*. The state space of all alignments of
x and y is the mapping g: ð〈x; y〉Þ 7! Z, the set of integers. The optimal
local alignment score of the subsequences x1…xp and y1…yq is obtained
by maximizing g among all alignments. That is,

g0ð〈x; y〉Þ ¼ max
A

gð〈x; y〉Þ

Fig. 3. Vizualization of a near-optimal duplicate cluster tree ^T.

5

A. Fellah

OPTðAÞ ¼ argmax

gð〈x; y〉Þ

A

Let.

^C l and

^C r be the left and right children of an internal node

^C in ^T.
^C ; iÞ be the near-optimal duplicate sub-tree for
Let NEAR (cid:1) OPTDUPTREEð
^C using i clusters as stated recurrently in the following theo-
the node
rem. The space of near-optical solutions is represented in a data structure.
That is, a tree that can be efﬁciently used to ﬁnd near-optimal solutions
that satisfy the optimal local alignment. Near-optimal and recursively

^C ; iÞ,

^C using i clusters, DUPTREEð

constructed bottom-up subtrees, DUPTREEð
facilitate the re-
optimization (i.e., tuning) in the object function g to satisfy the proper-
ties and accomplish the near-optimality solution. Thus, each subtree of
^C ;iÞ, transparently represents the
the node
space of near-optimal solutions and how each subtree relates to each
other. We propose the following theorem which formally and compactly
describes the near-optimal detection solution along with the corre-
sponding objective function g. We explore the clustering methodology of
[41] further and formally introduce near-optimal duplication tree of a
^C ; iÞ. The
node
objective function values of each alignment obtained by the SW algo-
rithm guarantee the optimal local alignment across all subtrees of ^T.

^C using i cluster deﬁned as NEAR (cid:1) OPTDUPTREEð

Theorem 6.1. NEAR (cid:1) OPTDUPTREEð
(cid:5) ^C
NEAR (cid:1) OPTDUPTREE

^C l;j

(cid:6)

(cid:7)

^C ; iÞ ¼

[ NEAR (cid:1) OPTDUPTREE

(cid:7)

(cid:6)
^C r;i (cid:1) j

if i ¼ 1
if i > 1

where

j¼argmin

1(cid:5)j<i

(cid:6)
NEAR(cid:1)OPTDUPTREE
g

(cid:6)
^C l;j

(cid:7)

[NEAR(cid:1)OPTDUPTREE

(cid:7)(cid:7)

(cid:6)
^C r;i(cid:1)j

Proof. We proceed by induction on i. The base case handles all clusters
^C 1; ^C 2; …; ^C q with a single represen-
of ^T. That is, all initial clusters
tative that is generated in the divide phase. Starting at the leaves, the ﬁrst
optimal clusters are originated from the SW algorithm. If two records are
in the same cluster then they are considered to be near duplicate or
similar, and if not they are dissimilar.

l

For the induction case, we can now assume the claim is true for all i, 1
< i < n. Let inode(^T) be an internal node of ^T, and ^T 1 and ^T 2 the left and
right subtrees recursively build from the leaf clusters of ^T, respectively.
^C 1
Without loss of generality, deﬁne
^C 2
root is ^T 1; and
l; ^C 1
^C 1
ordered as ð
the set of cluster representatives of (
¼ ^R1
tively. Let ^R1
(cid:4)
(cid:4)
(cid:4) ^Ri

to be the clusters whose
be the clusters rooted in the right subtree ^T 2,
l; ^C 2
),

(cid:4)
(cid:4)
(cid:4) ¼ q > 1, for i ¼ 1, 2. That is, a cluster has more than one

Þ. Denote by ( ^R1
l; ^C 1

) and ( ^R2
l; ^C 2
(cid:4)
(cid:4)
(cid:4) ^Ri

l; ^R2
), respec-
(cid:4)
(cid:4)
(cid:4) ¼ p > 1

^C 2
such that

l; ^R1
) and (

^C 1
¼ ^R2

and
r
Þ; ð

^C 2
^C 2

and ^R2

[ ^R1

[ ^R2

^C 1

and

and

r

r

r

r

r

r

r

r

r

r

r

l

l

l

l

l

l

r

^C l ¼
; ^rl

representative which is used for subsequent comparisons. Importantly,
representative clustering reduces the total number of record comparisons
substantially and furthermore representatives are bounded by two sim-
ilarity threshold values, θu and θl. Keeping this potential of multiple
l
. For
cluster representatives,
convenience, let ^R1
2;pg.
and ^R2
Similarly ^R1
are deﬁned. If two records (i.e., representatives)
are in the same cluster then they are considered to be near-duplicates or
exactly similar, and if not they are dissimilar. For instance, let R3 ¼ fr1;
r2; r3g be the set of records to be compared and the initial good threshold
chosen is in the interval ½0:83⋯0:90(cid:4). Assume we have the following
similarities: sim(r1, r2) ¼ 0.88, sim(r1, r3) ¼ 0.72, and sim(r2, r3) ¼ 0.80.
Then, (r1, r2) are classiﬁed as near-duplicates and assigned to the same

^C 1
and
1;pg and ^R2

^C r ¼
¼ f^rl

^C 1
[
; …; ^rl

^C 2
; …; ^rl

^C 2
[
; ^rl

¼ f^rl
r

1;2

2;2

2;1

1;1

r

r

l

l

Array 11 (2021) 100070

cluster. However, (r1, r3) and (r2, r3) would be non-duplicates. Now,
consider a new record r4 added to R3 with sim(r1, r4) ¼ 0.75, sim(r2, r4) ¼
0.88, and sim(r3, r4) ¼ 0.96. Then, (r2, r4) and (r1, r4) are classiﬁed as
near-duplicated and non-duplicated, respectively. However, due to the
anomaly in the transitivity relation and the non-appropriate choice of the
threshold, the pair of records, (r1, r4) and (r2, r3), would be reclassiﬁed as
near-duplicates although there were not. This is an important note that
should largely foster the choice of appropriate thresholds for larger data
sets. With our proposed approach, the results of the comparisons are
segregated by labels referred to as very similar, similar, or not similar;
and the quality and accuracy of the classiﬁcation is further improved by
ﬁnding near-optimal or sub-optimal thresholds to identify more accu-
rately duplicate records by minimizing the objective function without the
users intervention. With this viewpoint and based on the SW algorithm,
we start computing the optimal clustering for the leaf nodes and then ﬁnd
the near-optimal clustering, relatively to the optimal local alignment, for
any internal node. That is, at the end of the SW algorithm during the
merge phase, NEAR (cid:1) OPTDUPTREEð^TÞ gives the almost optimal clus-
tering. We consider two upper and lower bound threshold values, θl and
θu, which are extensively studied in domain independent large databases.
Both bounds which are rooted in the seminal Monge-Elkan's algorithm
have shown effectiveness as they become core standard thresholds in
research literature [39,40,42] and in almost every approximate duplicate
detection algorithm. The two upper and lower bound threshold values
are mainly governed by the probability of errors for ﬁnding optimal re-
cord alignments. Thus, we set the semantic similarity threshold param-
eter for which two records are considered semantically similar to θu. In
the same way as semantically similar records, we set the non-similarity
threshold to θl.

^C l and

We set θu to 0.7 and θl to 0.5 for declaring two records as near-
duplicate and non-duplicate, respectively. θ (cid:5) θl produces loose simi-
larity (not similar), θ (cid:6)θu produces high similarity (very similar), and if θ
falls between these values it is regarded as a regular similarity (similar).
^C r be the left and right children of an internal node
^C whose
Let
cluster representative is ^R. We denote by ^Rl and ^Rr the left and right
cluster representative children of ^R. As a consequence of Theorem 6.1,
we state the following result.
Corollary 6.1. NEAR (cid:1) OPTDUPTREEð ^R; iÞ ¼
(cid:5) ^R
NEAR (cid:1) OPTDUPTREE

[ NEAR (cid:1) OPTDUPTREE

if i ¼ 1
if i > 1

(cid:6)
^Rl;j

^Rr;i (cid:1) j

(cid:7)

(cid:7)

(cid:6)

where

j ¼ argmin

1(cid:5)j<i

gðNEAR (cid:1) OPTDUPTREE

(cid:7)

(cid:6)
^Rl;j

[ NEAR (cid:1) OPTDUPTREE

(cid:7)(cid:7)

(cid:6)
^Rr;i (cid:1) j

7. Competitive algorithms

We introduce three classes of algorithms from different perspectives,
a constant threshold (CT), a variable threshold (VT), and a function
threshold (FT) algorithm, collectively referred to as All(cid:1)Three algo-
rithms. Each of these algorithms has a different impact when running on
various benchmarks and synthetic data sets.

7.1. Constant threshold (CT) algorithm

We use the same notations in line with Section 6. Let ^T be the bottom-
up cluster tree, and ^T 1 and ^T 2 the left and right subtrees recursively build
from the leaf clusters of ^T, respectively. Assume n, the number of records,
is a power of 2 for the sake of convenience. The output of the approxi-
^C 1; ^C 2;…;
mate duplicate SW merge phase is a partition of clusters ^C ¼

6

A. Fellah

Array 11 (2021) 100070

^C q, where each
loss of generality, let assume
^C 2
l; ^C 1

^C 2
ordered as ð

^C 1

^C 2

and

and

Þ; ð

r

r

l

^C i is a node of ^T and q is unknown in advance. Without
be the clusters whose root ^T 1;
be the clusters rooted in the right subtree ^T 2 of ^T,

^C 1

^C 1

and

r

l

l; ^C 2

r

Þ.

^C 1

l; ^C 2

l

The procedure CONSTANT THRESHOLD (

) in algorithm 1 is based
on the idea of the Merge(cid:1)Filter(cid:1)RC approach which compares and
subsequently updates two given clusters, either by merging them into a
new cluster and removing one of the original cluster. Moreover, the al-
gorithm iteratively recomputes and reassigns new representatives. Each
record is compared to the representatives and placed in the cluster of the
closest representative. The number of comparisons is reduced from O(n2)
to O(mn), where reduced m and n are the number of representatives and
records, respectively (m is much smaller than n).

7.2. Variable threshold (VT) algorithm

^C 1

l; ^C 2

l

In procedure VARIABLE THRESHOLD (

) in algorithm 1, each
cluster has only one representative and only one variable threshold value
is considered, starting at θ1 ¼ 0.5. In line with the approximate duplicate
SW algorithm, the variable threshold algorithm (VT) compares clusters
from the left subtree with clusters from right subtree. That is, we compare
^C 1
^C 2
r
.
, then we compare
Without loss of generality and for algorithmic simplicity, we assume
^C 1 has ^r1 as a record representative and θ1 as a threshold. Sim-
^C 2 has ^r2 as a record representative and θ2 as a threshold. At
ilarity,
start, clusters have one record and the threshold value θ1 is set to 0.5.

cluster

^C 1

^C 2

^C 2

^C 2

with

with

and

and

r

r

l

l

l

7.3. Function threshold (FT) algorithm

In this third category of algorithms each cluster has more than one
representative. Furthermore, two variable threshold values are consid-
ered, an upper bound value θu ¼ 0.7, and a calculated threshold value θc.
In line with the approximate duplicate SW algorithm, the function
threshold algorithm (FT) compares clusters from the left subtree with
^C 2
r
^C 1

clusters from right subtree. That is, we compare

. In addition, we compare

then we compare
with every cluster in the second half subtree.

^C 1

^C 1

^C 2

^C 2

^C 2

with

with

and

and

,
r

r

r

l

l

l

The function COMPARE ð

(lines 4 and 5). The other

^C 1; ^C 2Þ shows the very similar case when
max SW > θu
similar
(θl (cid:5) max SW (cid:5) θu) and not similar (max SW < θl), can also be treated
^C 1; ^C 2) should
in a same manner. Lines 4 and 5 in the function COMPARE (
^C 1; ^C 2Þ,
be substituted by lines 4 and 5 in the function CHECK-SIMILARITY ð
respectively. In the same way, lines 11 and 12 should be substituted by
lines 4 and 5. For the case of no similarity, lines 4 and 5 in the function
^C 1; ^C 2Þ should be substituted by lines 7 and 8 in the function

two cases,

COMPARE ð
CHECK-SIMILARITY ð

^C 1; ^C 2Þ.

(cid:4)
(cid:4)
(cid:4) ^R1

In the same way lines 11 and 12 should be substituted by lines 7 and
^C 2,
8. Let ^R1 and ^R2 be the set of the cluster representatives of
(cid:4)
(cid:4)
(cid:4)
(cid:4)
(cid:4) ¼ q, where p, q (cid:6) 1. For algo-
(cid:4) ¼ p and
respectively such that
rithmic convenience, let assume that q (cid:6) p. Let ^R1 ¼ f^r1igp
i¼1 and ^R2 ¼
^C 2, respectively. The
f^r2jgq
value max SW refers to the value returned by the Smith-Watermann
algorithm.

j¼1 be the cluster representatives of

^C 1 and

^C 1 and

(cid:4)
(cid:4)
(cid:4) ^R2

Algorithm 1
All (cid:1) Three Algorithms.

1: Initialization: Two cluster leaf records (C l, C l)

2: procedure CONSTANT THRESHOLD (

^C 1

l

l; ^C 2

) \(⊳\) CT algorithm

(continued on next column)

Algorithm 1 (continued )

l

^C 1

^C 2

l

) \(⊳\) comparison of

l

^C 1

with

l

^C 2

) are very similar then
^C 2

^C 1

)

,

l

l

\(⊳\) cluster rep. ← rep. of

l

^C 1

are similar then
^C 1

^C 2

)

,

l

l

l

l

l

l

l

,

5:

4: if (

3: Compare (
^C 2
^C 1
,
^C new ← Merge (
^C 2
6: Remove
7: ^Rnew ← ^R1
8: end if
^C 1
l

^C 2
,
9: if
10: ^Rnew ← Merge (
^C 2
11: Remove
12: ^Rnew ← ^R1
13: end if
^C 2
^C 1
14: if (
15: no operation
16: end if

[ ^R2

,

l

l

l

l

l

\(⊳\) cluster rep. ← rep. of

l

^C 1

[ rep. of

l

^C 2

) are not similar then

17: Goto step 1 and compare (

18: Goto step 1 and compare (

19: Goto step 1 and compare (
l; ^R2
20: return ( ^R1
21: end procedure

l

l

r

r

,

)

^C 1
^C 1
^C 1

^C 2
^C 2
^C 2
)\(⊳\) returns cluster representatives

)

)

,

,

r

r

l

^C 1,

^C 2) \(⊳\) VT algorithm

1: procedure VARIABLE THRESHOLD (
2: Compare and ﬁnd SW of ^r1 and ^r2 \(⊳\) at start θ1, θ2 are 0.5 for
3: if (SW > θ1 or (SW > θ2) then
4: if (θ1 > θ2) then
^C 2)
5: Merge (

^C 1,

^C 2

^C 1,
^C 2

^C 1,
^C 1

6: Remove
7: Set representative ← ^r1 \(⊳\) update representative to ^r1
8: θ1 ← ðθ1 þSWÞ=2 \(⊳\) update θ1
9: end if
10: if (θ2 (cid:6)θ1) then
^C 2)
11: Merge (

12: Remove
13: Set representative ← ^r2 \(⊳\) update representative to ^r2
14: θ2 ← ðθ2 þ SWÞ=2
15: end if
16: else

^C 2 are not similar

^C 1 and
17:
18: no operation
19: end if
20: end procedure

^C 1

l

l; ^C 2

) \(⊳\) FT algorithm

and every cluster in ^T 2
^C 2
^C 1

and

r

l

l

r

^C 2

1: procedure FUNCTION THRESHOLD (
^C 1
2: Find max SW between
3: Suppose maxSW is between
4: if (max SW > θu) then
^C 1
l
,
^C 1
l

5: Merge (

6: Remove
7: Representative ← representative of
8: end if
9: if (θc (cid:5) max SW < θu) then
^C 1
l
,
^C 2
r

10: Merge (

^C 2

)

)

r

r

^C 2

11: Remove
12: Representative ← Union of representatives
13: end if
14: if (max SW < COMPUTE(θc) then
15: no operation
16: end if
17: end procedure

^C 1; ^C 2) \(⊳\) very similar case

j¼1

^C 1,

1: function COMPARE (
2: Compare and ﬁnd SW of ^r11 with each f^r2jgq
3: Find max SW; m ← max SW
4: if at any time (max SW > θu) then
^C 2) are very similar
5: (
6: Stop and return max SW
7: end if
8: if (max SW < θu) then
9: Compare and ﬁnd SW of ^r12 with each f^r2jgq
10: Find maxSW; start with max SW equal to m
11: if at any time (max SW > θu) then

j¼1

(continued on next page)

7

A. Fellah

Algorithm 1 (continued )

^C 1,

^C 2) are very similar
12: (
13: Stop and return max SW
14: end if
15: end if
16: end function

1: function COMPUTE (θc)
2: t ← 0.3 (1 (cid:1)θu) \(⊳\) θu: Monge-Elkan's threshold
3: x ← the number of representative in
4: Let m ← minimum(x, maximum number of allowed representatives)
5: D ← t/(maximum number of allowed representatives)
6: θc ← 2 (cid:3) t (cid:1) m (cid:3) D
7: return θc
8: end function

^C 2

(cid:1) 1

r

1: function CHECK SIMILARITY (
similar, similar, not similar

^C 1; ^C 2) \(⊳\) Check degree of similarity: \(⊳\) very

^C 2) are similar

^C 2) are very similar

2: if (max SW > θu) then
^C 1,
3: (
4: end if
5: if (max SW (cid:5) θu) and (max SW (cid:6) θl) then
^C 1,
6: (
7: end if
8: if (max SW < θl) then
^C 1,
9: (
10: end if
11: end function

^C 2) are not similar

^C 1

l; ð

^C 2

l; ^C 2

r

Þ)
and every cluster in ^T 2 \(⊳\) similar to function COMPARE
^C 1

^C 2

r

l

l

r

and

^C 2

^C 1

5: Merge (

1: function COMPARE LEFT-RIGHT SUBTREES (
2: Find max SW between
3: Suppose max SW is between
4: if (max SW > θu) then
^C 1
l
,
^C 1
l

6: Remove
7: Representative ← representative of
8: end if
9: if (θc (cid:5) max SW < θu) then
^C 1
l
,
^C 2
r

10: Merge (

^C 2

)

)

r

r

^C 2

11: Remove
12: Representative ← Union of representatives
13: end if
14: if (max SW < θc) then
15: do nothing
16: end if
17: end function

Without loss of generality, let assume
^C 2

whose root ^T 1; and
and
subtree ^T 2 of ^T, ordered as ð

^C 2
l; ^C 1

^C 1

Þ; ð

r

l

l

r

and

^C 1

^C 1
be the clusters rooted in the right
r

be the clusters

r

^C 2

l; ^C 2

Þ.

As a result of Theorem 6.1, we state the following results:
Corollary 7.1. NEAR (cid:1) OPTDUPTREEð

l; iÞ ¼

^C 1

8
<

:

l

^C 1
NEAR (cid:1) OPTDUPTREE

(cid:6)

(cid:7)

^C l
2

;j

[ NEAR (cid:1) OPTDUPTREE

(cid:7)

(cid:6)
^C r
2

;i (cid:1) j

if i ¼ 1
if i > 1

(cid:6)
NEAR(cid:1)OPTDUPTREE
j¼argmin
g

1(cid:5)j<i

(cid:6)
^C l
2

(cid:7)

;j

[NEAR(cid:1)OPTDUPTREE

(cid:7)(cid:7)

(cid:6)
^C r
2

;i(cid:1)j

Array 11 (2021) 100070

8. Evaluation metrics and experiments

8.1. Evaluation metrics

The main goal of this experimental evaluation is to compare the
performance in terms of accuracy and effectiveness of all four algorithms
covered in this work, ME, CT, VT, and FT algorithms. We adopt the pu-
rity, inverse purity, and F-measure metrics for our extensive evaluation.
^C 1; ^C 2; …; ^C q the set of the true actual clusters where
Denote by ^C ¼
^C i as a class and let C ¼ C 1; C 2; …; C k be the set of
we refer to each
near-duplicate clusters to be evaluated by the SW algorithm. Then the
^C i with respect to C j are

^C i; C jÞ and recall Rð

^C i; C jÞ of

precision, Pð
deﬁned as follows:

(cid:6)
^C i; C j

P

(cid:7)

¼

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4) ^C i \ C j
(cid:4)
(cid:4)C j

(cid:4)
(cid:4)

(cid:6)

and R

^C i; C j

(cid:7)

¼

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4) ^C i \ C j
(cid:4)
(cid:4)
(cid:4) ^C i

(cid:4)
(cid:4)
(cid:4)

^C i; C jÞ ¼ RðC j; ^C iÞ. Let ^n be the total number of clustered
where Pð
entities, including near-duplicates, purity is formulated by the weighted
average of the maximum precision values achieved by the clusters on one

^C j:

of

fPurityg ¼

(cid:4)
(cid:4)

(cid:4)
(cid:4)C j
^n

Xk

j¼1

q
max
i¼1

(cid:6)

P

^C i; C j

(cid:7)

However, inverse purity considers the cluster with maximum recall for
^C i, and it is obtained by taking the weighted average of the

each class
maximum recall values

Inverse Purity ¼

(cid:4)
(cid:4)
(cid:4) ^C

(cid:4)
(cid:4)
k
(cid:4)^n max
j¼1

i

Xq

i¼1

(cid:8)

(cid:9)

R

^C

; C j

i

The values of the purity and inverse purity metrics are within the range of
0–1. The higher purity the better is the inverse purity. Purity penalizes
clustering noise (i.e., duplicates) in a cluster, which means grouping re-
cords incorrectly, but it does not reward grouping records from the same
^C j. If every cluster contains only one record, the maximum purity is 1.
However, reversing the role of ^C and C, that is inverse purity (C; ^C)
^C j into
would penalize splitting records belonging to the same cluster
different clusters. In other words, inverse purity rewards grouping near-
duplicates together, but it does not penalize noisy records from different
^C j. In a similar way to precision and recall, there is a tradeoff relation-
ship between inverse purity and purity. Inverse purity rewards grouping
near-duplicates and the maximum inverse purity is achieved by putting
^C i, the F-measure of that

all records in one single cluster. For each class
class is:

where

(cid:6)
NEAR(cid:1)OPTDUPTREE
g
j¼argmin

1(cid:5)j<i

(cid:6)
^C l
2

(cid:7)

;j

[NEAR(cid:1)OPTDUPTREE

(cid:7)(cid:7)

(cid:6)

^C r
2

;i(cid:1)j

(cid:6)
^C i; C j

F

(cid:7)

k

¼ max
j¼1

(cid:6)
^C i; C j
(cid:7)

2 (cid:3) P
(cid:6)
^C i; C j

P

(cid:7)

(cid:7)

(cid:6)
^C i; C j
(cid:7)

(cid:3) R
(cid:6)
^C i; C j

þ R

Corollary 7.2. NEAR(cid:1)OPTDUPTREEð

^C 1

r; iÞ ¼

8
<

:

r

^C 1
NEAR (cid:1) OPTDUPTREE

(cid:6)

(cid:7)

^C l
2

;j

[ NEAR (cid:1) OPTDUPTREE

(cid:7)

(cid:6)
^C r
2

;i (cid:1) j

if i ¼ 1
if i > 1

The F-measure, a combination of purity and inverse purity, is in the range
of ½0; 1(cid:4) and a higher F-measure indicates a better clustering. The F-
measure, is in the range of ½0; 1(cid:4), indicates a better clustering. The F-
measure of the clustering [35,36] which computes the weighted average
of maximal F-measure values is deﬁned as:

where

8

A. Fellah

F (cid:1) measure ¼

Xq

(cid:6)
^C i; C j

F

(cid:7)

i¼1

(cid:4)
(cid:4)
(cid:4)
(cid:4)
(cid:4) ^C i
(cid:4)
(cid:4)
(cid:4)
(cid:4)
(cid:4)
(cid:4) ^C
(cid:4)

8.2. Experiments and data sets

Although ME and All(cid:1)Three algorithms are provably correct, but
verifying the accuracy of an implementation is a challenging task. With
no prepossessing steps, all these algorithms are implemented in Cþþ.
The experiments were carried out on several publicly available real data
sets which cover a spectrum of different data characteristics and sizes. We
have used four different data sets in our experiments. Three real data sets
from various sources often used in related research, and the fourth large
data set was generated synthetically (artiﬁcially) using the near-
duplicate generator (NDG) algorithm as described below. NDG gener-
ates ten of millions of near-duplicates for each set of real data.

Algorithm 2Near-Duplicate Generator (NDG) Algorithm

1: Remove a random number of characters from the data set record
2: Replace a random number of characters with others
3: Flip the ﬁrst and last attributes (i.e., ﬂip the ﬁrst and last names in the lists)
4: Duplicate a random character. This might be done to more than one character
5: Abbreviate randomly - Keep the ﬁrst character but this might be duplicated or

removed as above

We ran our experiments on four categories of data set as follows.
Voting1 We used the list of registrar voters in British Columbia as our
original small data set with no duplicates. The original total number of
records in the voting list is 225 and 975 records. Then we complement
each of the two original voting data sets with a set of near-duplicates
generated by the NDG algorithm. Additionally, we augmented and top-
ped the voting data set to 1977 and 3745 references, respectively.

Cora2 Cora data set contains bibliographic records and citations in
scientiﬁc papers classiﬁed in several classes. The cora citation data set,
which consists of a data set of original references and research papers, is
often used in the duplicate detection community. Additionally, we
augmented and topped the cora data set to 21,152 references and 32,005,
a substantial larger data set for our experiments.

DBLP3 DBLP is the bibliography database for computer science re-
cords from the DBLP web site. Each record is a concatenation of author
names(s), title of the publication, some keywords, an abbreviated refer-
ence format citation (i.e., journal, book, editor). It consists of 43,935 real
objects, both for relational and XML data. Additionally and for our ex-
periments, we augmented the data set to 63,553 references.

Synthetic4 The near-duplicate generator algorithm (NDG) is capable
of algorithmically generating tens of millions of synthetic records from a
set or original records. For instance, the voting, cora and DBLP data sets
have been scaled up and topped by tens of thousands of records. The
synthetic data set of 573,879 has been augmented and topped by NDG to
an average of 352.992 records, for an average total of 926.871 records
over three runs.

We generated a random number (0–8) of near-duplicates for each
record using the NDG algorithm for the voting and DBLP data sets, and a
random number (9–20) for the cora data set. Finally, all generated near-
duplicates as explained above in the NDG algorithm are appended to the
original data set ﬁle. Moreover, we ran the NDG algorithm three times,
for each original real data, to generate three different sets of data (see
Tables 1-6).

1 http://ww.rootsweb.ancestry.com/canbc.vote898/votea.html.
2 http://www.cs.umass.edu and mccallum/code-data.html.
3 http://www.informatik.uni-trier.de/ley/db/.
4 Algorithm 2: The near-duplicate generator (NDG) algorithm.

9

Array 11 (2021) 100070

Table 1
Detection of near-duplicates in voting list1 data sets.

Voting lists

Runs

NDG near-duplicates
Real data & NDG near-duplicates
ME near-duplicates
CT near-duplicates
VT near-duplicates
FT near-duplicates

List1 Real Data Set 255

Average

run1

1058
1313
1142
1054
1098
1064

run2

947
1202
1003
987
988
968

run3

1002
1257
1078
1056
1003
998

Avg

1002
1257
1074
1032
1029
1010

Table 2
Detection of near-duplicates in voting list2 data sets.

Voting lists

Runs

NDG near-duplicates
Real data & NDG near-duplicates
ME near-duplicates
CT near-duplicates
VT near-duplicates
FT near-duplicates

List2 Real Data Set 975

Average

run1

1857
2832
1633
1793
1859
1855

run2

1901
2876
1818
1877
1856
1902

run3

1840
2815
1702
1823
1803
1857

Avg

1866
2841
1717
1831
1839
1871

Table 3
Detection of near-duplicates in Cora data sets.

Cora Data Set

Runs

NDG near-duplicates
Real data & NDG near-duplicates
ME near-duplicates
CT near-duplicates
VT near-duplicates
FT near-duplicates

Cora Real Data Set: 21,152

Average

run1

run2

run3

Avg

9320
30,472
11,412
9234
9341
9289

12,754
33,906
11,674
12,657
12,788
12,768

10,487
31,639
10,078
10,456
10,501
10,485

10,853
32,005
11,054
10,782
10,876
10,847

Table 4
Detection of near-duplicates in DBLP data sets.

DBLP Data Set

DBLP Real Data Set: 43,935

Average

Runs

run1

run2

run3

Avg

NDG near-duplicates
Real data & NDG near-duplicates
ME near-duplicates
CT near-duplicates
VT near-duplicates
FT near-duplicates

21,134
65,069
22,160
21,203
21,119
21,147

19,345
63,280
20,018
19,177
19,256
19,257

18,376
62,311
19,102
18,723
18,303
18,362

19,618
63,553
20,426
19,643
19,559
19,589

Table 5
Detection of near-duplicates in Synthetic data sets.

Synthetic Data Set

Synthetic Data Set: 573,879

Average

Runs

run1

run2

run3

Avg

NDG near-duplicates
Real data & NDG near-duplicates
ME near-duplicates
CT near-duplicates
VT near-duplicates
FT near-duplicates

344,516
918,395
348,602
342,823
343,945
344,323

364,890
938,769
361,768
363,239
363,885
364,299

349,571
923,450
352,459
348,697
348,880
349,105

352.992
926.871
354.276
351.586
352.236
352.575

8.3. Voting lists data sets analysis

First, we consider a small set of records extracted from the voting list1
and list2 of 255 and 975 individuals, respectively. Then we ran three
times the NDG algorithm on the voting lists where each run has generated
a larger list of near-duplicates. For instance, run1 generated 1058 near-

A. Fellah

Array 11 (2021) 100070

Table 6
ME, CT, VT and FT algorithms: Performance evaluation of purity, inverse purity
and F-measure.

(Figs. 3 and 4 in Appendix). However, the ME algorithm is far behind
with an average of 808 (4.12%) false negatives.

Data set

near-duplicates

Purity

Inverse

F-measure

8.5. Synthetic data set analysis

Voting List1

Voting List2

Cora

DBLP

Synthetic

Performance

ME
CT
VT
FT
ME
CT
VT
FT
ME
CT
VT
FT
ME
CT
VT
FT
ME
CT
VT
FT

0.893
0.986
0.980
0.996
0.812
0.965
0.989
0.996
0.925
0.968
0.986
0.978
0.815
0.978
0.996
0.999
0.945
0.937
0.964
0.982

Purity

0.839
0.913
0.952
0.998
0.907
0.988
0.995
0.899
0.97
0.988
0.992
0.993
0.934
0.988
0.985
0.979
0.957
0.986
0.983
0.990

0.702
0.956
0.968
0.997
0.821
0.929
0.967
0.998
0.890
0.929
0.943
0.998
0.867
0.932
0.985
0.998
0.921
0.959
0.994
0.991

duplicates for a total of 1313 records. That is, the original real voting list1
has been topped by 1058 near-duplicates (Table 1). Similarly, the orig-
inal real voting list2 has been topped by 1857 for a total of 2832
(Table 2).

Both tables show the results of the NDG algorithm on the voting lists
over three runs. We carried out the experiments by running the four al-
gorithms, ME, CT, VT, and FT on the total number of records. The real
data is topped by duplicates generated by NDG (4th row of Tables 1 and
2). Then we checked whether these algorithms identify the near-
duplicates accurately. ME and All(cid:1)Three algorithms performed more
or less accurately on small data set sizes (1257 and 2841 voting records)
because of the small amount of noise added to the data set. For instance,
on small-sized data such as list2, CT and VT algorithms show an accuracy
of 98.34% on the average with 31 false positives ((1831/1866 þ 1839/
1866)/2 ¼ 98.34%). However, FT algorithm's accuracy is 100.27%
where the extra 0.27% represents few false negatives on the average in
list2 (Figs. 1 and 2 in Appendix). The ME algorithm accuracy is 92.02%
with 149 false positives. Still, the ME accuracy is behind the performance
of All(cid:1)Three Algorithms.

8.4. Cora and DBLP data sets analysis

On the other types, medium- and large-sized data, All(cid:1)Three algo-
rithms consistently outperformed the ME algorithm in terms of accuracy.
On the negative side, the ME algorithm added 2092 false negatives in
run1, but converged to 201 false negatives on the average due to read-
justing the threshold to 0.8 set by the algorithm (Fig. 3 in Appendix).
Overall, the ME algorithm added an extra 1.85% of false negatives over
the 32,005 records (Table 3). The Merge(cid:1)Filter(cid:1)RC paradigm com-
plemented by the comparison and construction of cluster representatives
are very noticeable with a high similarity threshold which helped to
improve the accuracy of All(cid:1)Three algorithms (Table 3, Fig. 3 in Ap-
pendix). This has been shown in the FT algorithm with only an average of
6 false positives (99.95% of accuracy) on the cora data set of 32,005
records. Furthermore, the FT algorithm added only 29 false positives
(99.85 of accuracy) on the DBLP data set of 63,553 records (Table 4,
Figure 4 in Appendix). The performance of All(cid:1)Three algorithms is the
most substantial on DBLP with an average of 63,553 records where
merging and ﬁltering clusters’ representatives is accurately achieved
throughout the similarity variable and function thresholds. In particular,
the VT and FT algorithms falsely detected an average of only 59 and 29
false positives, respectively. That is, an accuracy of 99.70% and 99.86%

Another important observation is that the tuning parameters that we
inserted in both ME and SW algorithms overall added some extra sig-
niﬁcant accuracy to the near-duplicate detection. For instance, and over
the 926,871 synthetic data set (Table 5, Figure 5 in Appendix). All(cid:1)Three
algorithms detected only 860 (0.092%) false negatives. That is, an ac-
curacy of 99.90%. The ME algorithm performed also quite well over
926,871 synthetic large-sized data set with 1284 (0.14%) false negative,
that is, an accuracy of 99.86%. Overall, ME and CT algorithms had
missed to identify a very small number of false positives. That is, 0.14%
and 0.15% over 926,871 records. On the DBLP data set, All(cid:1)Three al-
gorithms,
in particular VT and FT algorithms, outperform the ME
algorithm.

8.6. Performance evalution: purity, inverse purity and F-measure

With an extensive experimental analysis, the purity, inverse and F-
measure achieved a value of nearly 1.0, a precision which outperforms
the seminal work of Monge-Elkan. For instance, in the ME algorithm
which is based on Jaro-Winkler's metric and using the attribute name
provided by DBLP, the maximum F-measure is at threshold 0.8 and
robust up to 0.9. The precision drops steadily below 0.8 due to many false
positives. However, with the same algorithm based on Smith-Waterman's
metric, the maximum F-measure is at threshold 0.9 and the SW precision
is within the interval ½0:9⋯1:0(cid:4) due to preﬁxes and sufﬁxes which are
ignored in some references. For the same algorithm and for different
metrics (i.e., Jaro-Winkler, Smith-Waterman, Levenshtein), the perfor-
mance in terms of F-measure, precision and recall are quite different if we
consider only the attribute afﬁliation in the experiment (Table 6, Figure 6
thru Figure 10 in Appendix). As needed, the near optimal threshold was
not evaluated only once, but reevaluated and reconﬁgured if necessary as
records are added to clusters as illustrated in the set of ﬁgures in
appendix.

9. Conclusion

In this paper, we have introduced a near-duplication detection
framework by improving Monge-Elkan's algorithm and also including an
afﬁne variant of the Smith-Waterman's algorithm to reduce the number
of record comparisons. We have investigated and implemented a family
of algorithms – constant threshold (CT), variable threshold (VT) and
function threshold (FT) which are collectively referred to as All(cid:1)Three
algorithms, all based on the merge-ﬁlter cluster representatives Mer-
ge(cid:1)Filter(cid:1)RC approach. Our experiments with real-world and generated
data sets have shown substantial gains in accuracy and potential efﬁ-
ciency to detect near-duplicates in very large data sets and across
different domains.

As we have predicted in this investigation, the performance of Monge-
Elkan's algorithm which is mainly evaluated by the number of near-
duplicates within their correct clusters would not be as good and accu-
rate as expected. This is due to several ﬂaws in the algorithm, including
priority queue and union set structures, record comparison algorithms,
restricted clustering methods, and other parameters. The Mer-
ge(cid:1)Filter(cid:1)RC approach, complemented with the three classes of algo-
rithms achieves a value of nearly 1.0, a precision which is nearly perfect
and outperforms the seminal work of Monge-Elkan. In each run of the
experiment, the major evaluation metric is the accuracy measured in
terms of near-duplicate clusters. The effect of imperfection in terms of
number of clusters and accuracy is reﬂected in cluster miss-classiﬁcation
with increasing data set sizes in Monge-Elkan's algorithm. All of these
affect the precision, recall, and F-measure metrics. We believe that the
cutoff and optimization values of threshold with other key tuning

10

A. Fellah

Array 11 (2021) 100070

parameters throughout semi-supervised machine learning will signiﬁ-
cantly improve the quality of the accuracy and effectiveness of detecting
near-duplicate clusters. This is being investigated as the likely direction
and outlook of our current research.

following a 2012 collaborative workshop led by Harvard University and
the Wellcome Trust, with input from researchers, the International
Committee of Medical Journal Editors (ICMJE) and publishers, including
Elsevier, represented by Cell Press.

Acronyms

Declaration of competing interest

Constant Threshold
Variable Threshold
Function Threshold

Merge(cid:1)Filter(cid:1)RC Merge-Filter Representative-based Clustering
CT
VT
FT
All(cid:1)Three Constant Threshold, Variable Threshold, Function Threshold
ME
SW
SNM
NDG
OPTðAÞ Optimal Local Alignment ðAÞ
NEAR (cid:1) OPTDUPTREEð

Monge-Elkan
Smith-Waterman
Sorted Neighborhood Method
Near-duplicate Generator

^C ; iÞ near-optimal duplicate subtree for the node

^C using i clusters

Credit author statement

The authors declare that they have no known competing ﬁnancial
interests or personal relationships that could have appeared to inﬂuence
the work reported in this paper.

Acknowledgments

I acknowledge the collaboration of Dr. Maamir Allaoua who collab-
orated with me on several interrelated published papers. He is now
retired from the Dept. of Computer Science, University of Sharjah,
Sharjah UAE. I would also like to thank two graduate students, Sepideh
Pashami and Serveh Ghaderi, who spent one entire term carrying out the
experiments and programming parts reported in this paper. I also thank
Professors A. Elmagarmid and V. Verykios for providing me with some of
the original benchmark data sets.

CRediT (Contributor Roles Taxonomy) was introduced with the
intention of recognizing individual author contributions, reducing
authorship disputes and facilitating collaboration. The idea came about

Appendix

Fig. 1. Voting list1 data set: True duplicates vs. ME, CT, VT, and FT Algorithms

Fig. 2. Voting list2 data set: True duplicates vs. ME, CT, VT, and FT Algorithms

11

A. Fellah

Array 11 (2021) 100070

Fig. 3. Cora data set: True duplicates vs. ME, CT, VT, and FT Algorithms.

Fig. 4. DBLP data set: True duplicates vs. ME, CT, VT, and FT Algorithms.

Fig. 5. Synthetic data set: Optimal duplicates vs. ME, CT, VT, and FT Algorithms

12

A. Fellah

Array 11 (2021) 100070

Fig. 6. Voting list1 data set: Optimal measures vs. ME, CT, VT, and FT measures

Fig. 7. Voting list2 data set: Optimal duplicates vs. ME, CT, VT, and FT measures

Fig. 8. Core data set: Optimal duplicates vs. ME, CT, VT, and FT measures

13

A. Fellah

Array 11 (2021) 100070

Fig. 9. DBLP data set: Optimal duplicates vs. ME, CT, VT, and FT measures

Fig. 10. Synthetic data set: Optimal duplicates vs. ME, CT, VT, and FT measures

References

[1] Newcombe H, Kennedy J, Axford S, James A. Automatic linkage of vital records.

J Sci 1959;130(3881):954–9.

[2] Christen P. A survey of indexing techniques for scalable record linkage and

deduplication. IEEE Transactions on Knowledge and Data Engineering (TKDE 2012;
24(9):1537–55.

[3] Jaro M. Advances in record-linkage methodology as applied to matching. J Am Stat

Assoc 1989;84(406):414–20.

[4] Monge A. Adaptive detection of approximately duplicate database records and the
database integration approach to information discovery. Ph.D. thesis, Ph.D. Thesis.
San Diego: Dept. of Comp. Sci. and Eng., Univ. of California; 1997.

[5] Whang S, Menestrina D, Koutrika G, Theobald M, Garcia-Molina H. Entity

resolution with iterative blocking. In: Proceedings of the ACM international
conference on management of data. SIGMOD); 2009. p. 219–32.

[6] Weis M, Naumann F, Brosy F. A duplicate detection benchmark for xml (and

relational) data. In: Proceedings of the SIGMOD inter. Workshop on information
quality for information systems. IQIS); 2004. p. 10–9.

[7] Yan S, Lee D, Kan M, Giles L. Adaptive sorted neighborhood methods for efﬁcient
record linkage. In: Proceedings of the 7th ACM/IEEE-CS joint conf. on Digital
libraries; 2007. p. 185–94.

[8] Hernandez M, Stolfo S. The merge/purge problem for large databases. In:

Proceedings of the ACM SIGMOD international conference on management of data;
1995. p. 127–38.

[9] Papenbrock T, Naumann F, Heise A. Progressive duplicate detection. IEEE Trans

Knowl Data Eng 2018;27(5). 1316–132.

[10] Draisbach U, Naumann F. On choosing thresholds for duplicate detection. In:

Proceedings of the 18th international conference on information quality. ICIQ);
2013. p. 37–45.

[11] Elmagarmid A, Ipeirotis P, Verykios V. Duplicate record detection: a survey. IEEE

Trans Knowl Data Eng 2007;19(1):1–16.

[12] Chen Q, Zobel J, Verspoor K. Duplicates, redundancies and inconsistencies in the
primary nucleotide databases: a descriptive study, Jounal of Biological databases
and curation. 2017. p. 2–16. https://doi.org/10.1093/database/baw163.

14

A. Fellah

Array 11 (2021) 100070

[13] Xiao C, Wang W, Lin X, Yu J, Wang G. Efﬁcient similarity joins for near-duplicate

detection. ACM Trans Database Syst 2011;36(3):15–41.

[14] Monge A, Elkan C. Domain-independent algorithm for detecting approximately
duplicate database records. In: Proceedings of the ACM SIGMOD workshop on
research issues on data mining and knowledge discovery. DMKD); 1997. p. 23–9.

[28] Thyagharajan KK, Kalaiarasi G. A review on near-duplicate detection of images

using computer vision techniques. Arch Comput Methods Eng 2021;28:897–916.
[29] Draisbach U, Naumann F, Szott S, Wonneberg O. Adaptive windows for duplicate
detection. In: Proceedings of the IEEE 28th international conference on data
engineering. ICDE); 2012. p. 1073–83.

[15] Fellah A, Maamir A. A domain independent methodology for near-duplicate

[30] Jaro M. Probabilistic linkage of large public. Journal of Statistics in Medicine 1995;

detection. In: Proceedings of the international conference on applied computing,
madrid Spain; 2012. p. 139–46.

84(406):414–20.

[31] Hernandez M, Stolfo S. Real-world data is dirty: data cleansing and the merge/

[16] Navarra G. A guided tour to approximate string matching. ACM Comput Surv 2001;

purge problem. Data Min Knowl Discov 1998;2(1):9–37.

33(1):31–88.

[32] Kopcke H, Rahm E. Frameworks for entity matching: a comparison. Data Knowl Eng

[17] D. Moreira, al, Image provenance analysis at scale, IEEE Trans Image Process 27

2010;69(2):197–210.

(12).

[18] Fellah A, Maamir A. Near-optimal domain independent approach for detecting

duplicates. In: Proceedings of the 19th international conference on data mining,
multimedia and image processing. Paris France; 2017. p. 2633–42.

[19] Bharambe D, Jain S, Jain A. A survey: detection of duplicate record. International
Journal of Emerging Technology and Advanced Engineering 2012;2(11):298–307.
[20] Hassanian-esfahani R, Kargar Mj. Sectional minhash for near-duplicate detection.

Expert Syst Appl 2018;99(1):203–12.

[21] Herschel M, Naumann F, Szott S, Taubert M. Scalable iterative graph duplicate

detection. IEEE Trans Knowl Data Eng 2012;4(11). 2294–2108.

[22] Naumann F, Herschel M. An introduction to duplicate detection. Synthesis Lectures

on Data Management 2010;2(1):1–87.

[33] Papadakis G, Svirsky J, Gal A, Palpanas T. Comparative analysis of approximate

blocking techniques for entity resolution. In: Proceedings of the VLDB endowment.
PVLDB); 2016. p. 684–95.

[34] Papadakis G, Alexiou G, Papastefanatos G, Koutrika G. Schema-agnostic vs schema-
based conﬁgurations for blocking methods on homogeneous data. In: Proceedings
of the VLDB endowment. PVLDB); 2015. p. 312–23.

[35] Vogel T, Heise A, Draisbach U, Lange D, Naumann F. Reach for gold: an annealing

standard to evaluate duplicate selection results. ACM Journal of Data and
Information Quality 2014;5:1–22.

[36] Vogel T, Naumann F. Instance-based “one-to-some” assignment of similarity

measures to attributes. In: Proceedings of the international conference on
cooperative information systems. CoopIS); 2011. 412–0420.

[23] Winkler W. Overview of record linkage and current research directions. A Statistical

[37] Smith T, Waterman M. Identiﬁcation of common molecular subsequences. J Mol

Research Division, U.S. Census Bureau; 2006. p. 1–44.

Biol 1981;147. 195–107.

[24] Winkler W. Approximate string comparator search strategies for very large

[38] Needleman S, Wunsch C. General method applicable to the search for similarities in

administrative lists, A Statistical Research Report Series (Statistics 2005-02). U.S.
Census Bureau; 2005. p. 1–9. 02.

[25] Baxter R, Christen P, Churches T. A comparison of fast blocking methods for record

linkage. In: Proceedings of the ACM SIGKDD workshop on data Cleaning,Record
linkage, and object consolidation; 2003. p. 25–8.

the amino acid sequence of two proteins. J Mol Biol 1970;48:443–53.

[39] Deepa K, Rangarajan R, Selvi M. Automatic threshold selection using pso for ga
based duplicate record detection. Int J Comput Appl 2013;62(4):181–7.

[40] dos Santos J, Heuser A, Moreira V, Wives L. Automatic threshold estimation for data

matching applications. Inf Sci 2011;181(13):2685–99.

[26] Monge A. Matching algorithms within a duplicate detection system. IEEE Data

[41] Cheng D, Kannan R, Vempala S, Wang G. A divide-and-merge methodology for

Engineering Bulletin 2000;23(4):14–20.

[27] Yandrapally R, Stocco A, Mesbah A. Near-duplicate detection in web app model

inference. In: Proceedings of the ACM/IEEE 42nd international conference on
software engineering; 2020. p. 186–97.

clustering. ACM Trans Database Syst 2006;31(4):1499–525.

[42] Li M, Wang H, Li J, Gao H. Efﬁcient duplicate record detection based on similarity
estimation. In: Proceedings of the 11th inter. Conf. on Web-page and Information
Management (WAIM); 2010. p. 595–607.

15

