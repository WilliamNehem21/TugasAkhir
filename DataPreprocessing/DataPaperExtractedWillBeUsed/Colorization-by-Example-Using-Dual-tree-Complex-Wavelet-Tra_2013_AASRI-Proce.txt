 AASRI Procedia  4 ( 2013 )  261 – 267 
2212-6716 © 2013 The Authors. Published by Elsevier B.V.
Selection and/or peer review under responsibility of American Applied Science Research Institute
doi: 10.1016/j.aasri.2013.10.039 
ScienceDirect
2013 AASRI Conference on Intelligent Systems and Control 
Colorization by Example Using Dual-Tree Complex Wavelet 
Transform and Jseg 
Zahid Ali a*, S.A.M Gilania* 
a National University of Computer and Emerging Sciences, 
Lahore,Pakistan 
 
Abstract 
A novel and automated way to colorize gray images by giving an example color image is being proposed. Both images are 
partially segmented using unsupervised segmentation JSeg. Proposed methodology controls merging of segments in JSeg 
by analyzing histogram of gray image. Maximum fitting square patches are extracted from each segment in linear time. 
Some square patches are discarded to avoid error. Gray image and color image segments are matched using Dual Tree 
Complex Wavelet Transform. Colors between matched segments are transferred using simple mean and standard 
deviation. Remaining image is colorized using optimization. Experimental results performed show the advantage of 
automation.   
 
© 2013. Published by Elsevier B.V.  
Selection and/or peer-review under responsibility of American Applied Science Research Institute 
 
Keywords:Colorization; DT-CWT; texture matching; JSeg; automated; 
1. Introduction  
Colorization is adding colors to gray scale images. It is used for enhancing old grayscale photos, marking 
regions of interest in medical images, enhancing electron microscopic images and satellite images. It can also 
be used for re-coloring or modifying color images for getting visually pleasant results.  
Despite progress in the field it is a tedious job because a lot of human effort is required. Colorization can be 
                                                           
* a E-mail address:  ranazahid@gmail.com,  asif.gilani@nu.edu.pk 
 
Available online at www.sciencedirect.com
© 2013 The Authors. Published by Elsevier B.V.
Selection and/or peer review under responsibility of American Applied Science Research Institute
Open access under CC BY-NC-ND license.
Open access under CC BY-NC-ND license.
262  
 Zahid Ali and S.A.M. Gilani /  AASRI Procedia  4 ( 2013 )  261 – 267 
done by providing example images or by providing color markers on image. Both of these schools of thoughts 
have merits and demerits.  Reinhard[1] showed that color of an image can be transferred to other image using 
histogram based techniques in perceptually uniform color space lab. Reinhard transfer colors at global level 
by transferring distribution of one image into other. Welsh [2] transfers color at local level using simple mean 
and standard deviation. Simple mean and standard deviation are not enough to colorize images correctly. He 
suggested an interactive approach based on texture synthesis. Irony [4] uses example image for color transfer. 
This image is supplied along with a partially segmented image. By learning this segmentation target image is 
segmented. Yao Xiang [6] suggested in which there can be multisource images but target image is chromatic 
for multi-source transfer. 
A novel way to colorize images in which user is not required to provide segmented image or interaction is 
being proposed. Target image is still gray image and visually pleasant results are obtained and compared with 
earlier approaches.  
1. Background 
1.1 Complex Dual Tree Wavelet Transform 
Wavelets are being used as an efficient tool in texture based image retrievals. Kingsbury [7] suggested 
Complex Wavelets (CW) because these are shift invariant which means texture features are more robust to 
translation in images. Complex Wavelets can distinguish between -45 and 45 lines using dual tree at each 
scale using one tree for real coefficients and other for complex coefficient. A complex wavelet can be 
represented as 
 
  
 
 
 
                                                       (1) 
where 
 and 
  are real valued wavelets. 
 
1.2 JSeg- An Unsupervised Segmentation 
JSeg is unsupervised segmentation framework for natural images and gives good results on grayscale 
images [8]. First an image is quantized to 16 levels using Peer Group Filtering (PGF) [9]. Each level 
represents a class thus forming a class map. Let Z be a set of all points on this maps such that  
 .The 
value of z is its coordinates i.e. 
. Let N be the total points in class map. Mean m can be calculated 
as follow, 
 
 
A J-image is calculated as follow 
 
 
 
 
 
                                                                     (2) 
where 
 is total variance and 
 is mean of variance of each class,     
   
 
Higher value of J called mountains indicates edge and low value called valley indicate centre area of a region. 
A different size windows (starting from 65x65 to 9x9) operation is performed forming a multi-resolution 
z Z
z
N
m
1
2|
|
Z
z
T
m
z
S
263
 Zahid Ali and S.A.M. Gilani /  AASRI Procedia  4 ( 2013 )  261 – 267 
image called J-image. Lowest windows size is 9x9 called scale 1. Highest is 65x65 called scales 4. From 
lowest J values, a region growing method is used to segment the image. Valley points are determined in a 
region below a threshold. Threshold is determined as follow. 
From lowest J values, a region growing method is used to segment the image. Valley points are 
determined in a region below a threshold. Threshold is determined as follow. 
 
 
 
 
 
                                      
  
                          (3) 
where 
 are mean and variance of J values of a region. Finally, this results in over-segmented regions. 
Regions with similar intensity are merged. Regions with Euclidean distance below a threshold are merged. 
The optimum threshold used is 0.4. This works well for color images. For gray images it is used adaptively 
after analyzing peaks in a histogram explained in section 3.1. 
2. Proposed approach 
An algorithm for colorization in which source image is color and target image is a gray scale image is 
being presented. Segmentation of natural images is subjective and task dependent. But when a similar image 
is provided the target image can be matched to source image with reasonable accuracy. The color image can 
be segmented by keeping color and texture coherency to maximum accuracy with above mentioned approach 
JSeg [8] . The gray image is segmented using the same approach except adaptive region merging explained in 
sub-section 3.1. The main steps of proposed algorithm are as follows: 
Step 1: Source and target images are subjected to unsupervised segmentation; 
Step 2:  Find maximum fitting square in each segment of both images;  
Step 3: Extract features from each square by performing CWT; 
Step 4: Only feature vectors of color image and gray image square are matched which are above 15x15 
sizes;  
Step 5:   Transfer color between matching color square to matched segment of gray image using mean and 
standard deviation; 
Step 6:  Remaining pixels are colorized using optimization technique. 
2.1 Segmenting Source and Target Image 
The color image is segmented using default scale parameters used in JSeg. Threshold for merging phase 
used is 0.4. For gray scale image adaptive merging based on histogram analysis is used. Histogram of an 
image shows distribution of an image. A peak is defined as maxima between two low points [11]. Highest 
peaks represent major areas of interest in an image. If N is total pixels in an image and 
 is total number of 
pixels between two minima. Then percentage of area 
 of a peak with respect to whole image can be 
determined as follow: 
 
 
              
 
             
 
 
 
 
 
                                                                   (4) 
Let K represent the count of percentage area of peaks, 
) 
 
 
 
 
264  
 Zahid Ali and S.A.M. Gilani /  AASRI Procedia  4 ( 2013 )  261 – 267 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Peak
merg
unm
2.2 
O
these
extra
conv
box 
Fig
ks which repre
ging otherwis
merged. 
Finding a Ma
Once the imag
e irregular se
acted from e
verted to bina
can be determ
• 
Start from
• 
Move tow
• 
If pixel v
value in 
           
 
Where h 
g 1. Diagram show
( , ) =
r c
S
esents below 5
e a scale of 0.
aximum Fitting
ge is segment
gments will n
each segment
ary image. A 
mined as follow
m bottom righ
wards left, row
value is one th
all of three an
 
  
and w are hei
ws pictorial overv
1
1-
=
1
= 1-
min
=
h
r
w
c
5% of an imag
4 is used. For
g Box 
ed into differe
not yield corr
t using existi
scan line algo
w: 
ht corner of S;
w by row; 
hen look for r
nd add one in t
ight and width
view of proposed
+1),
n( ( ,
r c
S
ge are ignored
r 0.3 means ar
ent segments,
rect match. So
ing technique
orithm is used
 
right pixel, bo
that     
h of image. 
d approach. 
),
( + ,1
,
S
c
r
S
d. If K is great
reas of interest
 every segmen
o a square pa
e. Suppose S
d on binary c
ottom pixel an
+1
( + ,1
c
r
S
ter than 4 then
t are many and
nt is of irregu
atch, represent
S represents a
converted segm
nd down diago
+1
))
n a scale of 0.3
d should be le
ular shape. Co
tative of that 
a single segm
ment S. Maxi
onal pixel. Fin
3 is used for 
eft 
omparison of 
segment, is 
mented area 
imum fitting 
nd minimum 
(5) 
265
 Zahid Ali and S.A.M. Gilani /  AASRI Procedia  4 ( 2013 )  261 – 267 
• 
Square starts from maximum value of S and at position of max(S). Its size is  
 . 
2.3 Feature Extractions 
Feature vector for each square patch is calculated by applying Complex Wavelet at two scales and six 
orientations. 12 real and 12 imaginary sub-bands are got along with 2 real and 2 imaginary approximation 
sub-bands. By taking the magnitude of both real and imaginary coefficients and approximation and detailed 
bands 14 sub-bands are received. Mean and standard deviation is calculated as suggested by Kingsbury [7].  
This feature vector extraction is applied on gray square patches and at color patches after conversion to 
gray scale. These feature vectors are store for later matching. Feature vectors for color image square patches 
are taken above 20. The reason is that for small square patches mismatch rate can increase. 
2.4 Matching of Segmented Regions between Source and Target Image  
Once the feature vectors are calculated a square patch representing a segment in gray image is picked. 
Distance of its feature vector with other feature vectors representing color image square patch is calculated. 
Let q be the feature vector of a query gray patch and  be feature vectors of M reference color patches. The 
distance metric between query template image q and  used is given below 
  
The color patch with minimum distance is the match for the whole gray segment. 
2.5 Colorization 
After the match of gray segment is found from color square patches that color square patches is used for 
colorizing the whole gray segment of image. Colors are transferred based on mean and standard deviation 
suggested by Welsh [2]. This process is repeated for all gray segments whose size patch is above 15. This will 
leave some small gray segments in image. Colors for these gray areas are determined using optimization [3]. 
All colored pixels are considered known variables (scribbles) and remaining gray pixels are considered 
unknown variables. Image is converted into YUV color space. Let r be a center pixel and s be its neighbors.  A 
constraint is imposed that neighboring pixels should have similar colors if their intensities(Y) are similar. 
        
 
 
 
 
 
                       
where  
 is affinity function it tells how similar intensities are.  
 
 
 
If a color at pixel r i.e U(r), is known, the color value U(s) of its neighbours s will be weighted average of 
. Similarly  V channel of YUV color space can be determined. Now the remaining image is fully colorized. 
3. Results 
(6) 
(7)
1
=
1
=
+
-
) =
,
(
M
i
i
M
i
i
i
q
f
q
f
q
f
D
266  
 Zahid Ali and S.A.M. Gilani /  AASRI Procedia  4 ( 2013 )  261 – 267 
with
Alth
inter
 
 
4. 
A
techn
textu
     R
[1] 
Comp
[2] 
ACM
[3] 
694, 2
[4] 
Rend
[5] 
Bava
[6] 
FOR 
[7] 
and e
Fig
fro
Proposed app
hout any user
hough minor a
raction is achi
Conclusion 
A novel and
niques of ima
ure matching a
References 
Reinhard E, A
puter Graphic
Welsh T, Ash
M SIGGRAPH’
A. Levin, D. 
2004. 
R. Irony1, D.
dering (2005). 
Xiaodi Hou L
aria, Germany.
Yao Xiang1, 
NATURAL I
Kingsbury, N
enhancement. 
g 2. First row show
m proposed appr
proach is appl
r interaction. 
artifacts (for s
ieved after the
d automated 
age processing
and segmenta
Ashikhmin M
cs andApplica
hikhmin M an
’02, San Anton
Lischinski an
 Cohen-Or1, a
Liqing Zhang 
. 
Beiji Zou1, H
IMAGES” ICI
N.G. The Dual
Proc. Europe
ws example color
oach. It is to be n
lied on image
For Irony a 
small patches
e similar imag
colorization 
g are used to a
ation technique
, Gooch B. et 
ations, pp: 34-4
nd Mueller K. 
nio, USA, pp:
d Y. Weiss. “
and D. Lischin
“Color Conce
Hui Wang2, H
CIP-2008 IEEE
l Tree Comple
ean Signal Pro
r image and targe
noted no segment
s used by lan
segmented i
s left unmatch
e has been sup
procedure fo
achieve this.  T
es. 
al. “Color tra
40, 2001. 
“Transferring
: 277-280, 200
Colorization u
nski2 “Colori
eptualization”
ong Li1, Zhen
E. 
ex Wavelet Tr
ocessing Conf
et gray image. In 
ed image has to b
ndmark papers
image has to
hed) are intro
pplied. 
or example im
The process c
ansfer between
g Color to Gre
02. 
using optimiza
zation by Exa
 MM’07, Sep
ng Xie1  “MU
ransform: a ne
f., pp319-322,
bottom row first 
be supplied along
s of Irony. Sim
o supply whil
duced someti
mages is pro
an be improve
n images”. IEE
eyscale Images
ation”, ACM T
ample”, Eurog
tember 23–28
ULTI-SOURC
ew efficient to
Spetempber 1
image is the resu
g example image o
milar results a
le Welsh use
mes but adva
oposed.  Sta
ed by incorpo
EE Transactio
s”. In Proceed
Trans. Graph
graphics Symp
8, 2007, Augsb
CE COLOR TR
ool for image r
998. 
ult of Irony et al. a
or any user-side i
are achieved 
es swatches. 
antage of no 
ate-of-the-art 
orating better 
on on 
dings of 
, pp: 689-
posium on 
burg, 
RANSFER 
restoration 
and second result
interaction. 
t is 
267
 Zahid Ali and S.A.M. Gilani /  AASRI Procedia  4 ( 2013 )  261 – 267 
[8] Y. Deng and B. S. Manjunath, “Unsupervised segmentation of colour- texture regions in images and 
video”, IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 23, no. 8, pp. 800-810, August 2001. 
[9] Y. Deng, S.Kenney, M.S.Moore and B. S.Manjunath, "Peer group filtering and perceptual color image 
quantization", Proc. IEEE International Symposium on Circuits and Systems VLSI , (ISCAS'99), Orlando, 
FL,  vol 4, pp.21-4 , June 1999 
De Silva, D. V. S., et al. "Adaptive sharpening of depth maps for 3D-TV."Electronics Letters 46.23 (2010): 
1546-1548. 
