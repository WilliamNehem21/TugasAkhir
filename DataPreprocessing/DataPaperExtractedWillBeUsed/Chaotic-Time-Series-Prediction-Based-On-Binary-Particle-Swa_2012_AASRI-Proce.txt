 AASRI Procedia  1 ( 2012 )  377 – 383 
2212-6716 © 2012 Published by Elsevier Ltd. 
doi: 10.1016/j.aasri.2012.06.058 
2012 AASRI Conference on Computational Intelligence and Bioinformatics   
Chaotic Time Series Prediction Based On Binary Particle 
Swarm Optimization
Xiaoxiao Cui, Mingyan Jiang* 
School of Information Science and Engineering, Shandong University, Jinan 250100, P.R. China 
Abstract 
Prediction of chaotic time series based on the phase space reconstruction theory has been applied in many research fields. 
Local linear model is widely used in chaos prediction due to its versatility and small computation amount. The embedding 
dimension and time delay parameters of the local linear prediction model can take different values with those of the phase 
space reconstruction. The Binary Particle Swarm Optimization (BPSO) is applied to choose the optimal parameters of the 
new local linear prediction model for its strong search ability. The main objective of this approach is to increase the 
predictive accuracy of the local linear model. In this paper the local linear one-step and multi-step predictive model 
predicts the chaotic time series respectively. Simulation results show the feasibility and effectiveness of the proposed 
method.
2012 Published by Elsevier B.V. Selection and/or peer review under responsibility of American Applied 
Science Research Institute 
Keywords: Local linear model; Prediction; Chaotic time series; BPSO 
1. Introduction 
Chaotic phenomenon is an irregular motion produced by determinate nonlinear dynamical system. It is 
widely encountered in various fields ranging from physics and mathematics to biology and others. Though 
* Corresponding author. Tel.:13361073798. 
E-mail address: jiangmingyan@sdu.edu.cn. 
AASRI
Procedia
www.elsevier.com/locate/procedia
Available online at www.sciencedirect.com
Open access under CC BY-NC-ND license.
Open access under CC BY-NC-ND license.
378  
 Xiaoxiao Cui and Mingyan Jiang /  AASRI Procedia  1 ( 2012 )  377 – 383 
chaos seemed complicated and stochastic, a certain rule indicating that it can be predicted in the short term 
exists internally-[1]. Modeling and prediction of chaotic time series has already been an important branch of 
nonlinear information procession, such as weather forecasting, economic analysis and biomedical signal 
procession, etc.-[2]. With the development of chaos theory and research on its application, many methods have 
been proposed to predict chaotic time series, mainly including global and local prediction methods. The 
global methods use the whole time series data to fit the true function of the chaos attractor-[3]. It is obvious 
that if new information is taken into account, all parameters of the model have to be changed. Besides, the 
equation of global dynamic system is rather difficult to fit because of the complex attractor’s construction and 
computation-[4]. There are a few prediction tools about the global model, such as artificial neural network and 
Least Square Support Vector Machine (LS-SVM). Data normalization is necessary for artificial neural 
network, which makes calculation more complicated-[5]. Parameters are extremely crucial to LS-SVM 
learning results and generalization ability, but in most cases they are empirical values-[6]. The local methods 
can overcome the disadvantage above because it builds model only on the current state and utilizes part of the 
past information. On the basis of phase space reconstruction, parameters of the local linear method are valued 
the same with those of reconstruction traditionally-[7]. But parameters which are optimal for the state space 
reconstruction may not be suitable for the prediction. The improvement is that one parameter is optimized by 
minimizing the standard prediction errors, when other parameter is empirical value-[8]. The obtained 
parameter value, in theory, is optimal on the condition that the other parameter is fixed. But both of the 
parameters value may not be optimal for the prediction model. In this paper BPSO is introduced to search the 
optimal parameters of the new local linear prediction model by minimizing the standard prediction errors. For 
the local linear model there are one-step and multi-step prediction.  
This paper is organized as follows: The local linear prediction model, BPSO and adaptive weighted fusion 
algorithm are described in Section 2. The new local linear prediction model is illustrated in Section 3. 
Simulation and results are shown in Section 4 and discussion is described in Section 5. The conclusion is 
given in Section 6. 
2. Background theory 
2.1. The local linear prediction model 
Phase space reconstruction from a scale time series is the foundation of chaotic time series analysis. 
Takens has proved that state space can be reconstructed based on Whitney’s topological embedding theorem–
[9-10]. For observed scalar time series �
�
( ), 
1, 2, 
, 
x n
n
N
�
�
, the state space can be reconstructed as 
�
�
( )
( ), ( - ), 
, ( -(
-1) )
T ,
X n
x n
x n
x n
m
�
�
�
�
1
(
-1) , 2
(
-1) , 
, .
n
m
m
N
�
�
� �
�
�
 according to Takens’s delay 
embedding theorem. Where m  is the embedding dimension and �  is the time delay. With the optimal 
parameters the state evolution of chaotic systems can be reflected by the state space.  
Prediction of chaotic time series is to forecast the dynamic trajectories of reconstructed state space. That is 
to find the mapping function
ˆ
: (
1)
(
N )
F x N
F X
�
�
, where 
XN
 is the current state vector and ˆ(
x N �1)
 is the 
next predictive data. The local linear prediction expression is:  
0
1
ˆ(
)
(
-( -1) )
(
).
m
i
i
x N
n
a
a x N
i
AY N
�
�
�
�
�
�
�
                                                                                           (1) 
Where
0
1
2
[
,
,
,
,
] , (
)
[1, (
), (
- ), 
, (
-(
-1) )]T
m
A
a a a
a
Y N
x N
x N
x N
m
�
�
�
�
�
�
. And n  is the predictive step. 
Clearly, the embedding dimension of the reconstructed space becomes the order of the prediction model. In 
379
 Xiaoxiao Cui and Mingyan Jiang /  AASRI Procedia  1 ( 2012 )  377 – 383 
order to compute A , we need to find out the nearest neighboring points of the current state 
(
)
X N  in the 
reconstructed state space. These nearest neighboring points are obtained by the formula:  
( )
-
, 
1, 2, 
,
-1.
N
i
dist i
X
X
i
N
�
�
�
                                                                                                     (2) 
Form formula (2) we can see that the dist  can reflect the similarity of state evolution of the neighbouring 
and current state vectors. A can be obtained by computing the equation  AB = D  and k  is the number of the 
neighbouring points. B is an �
�
m+1 * k
 matrix whose ith column is made up of Y
 and 
�
�
,
,
,
.
1
2
k
D = x(N +step) x(N +step)
� x(N +step)
Number of the neighbouring points is usually no smaller than 
1
m �  to make sure that the matrix is non-singular. For local linear one-step prediction the predictive step is 
one each time, and then the obtained prediction data is added into the training set to predict the next data with 
the same procedure. The local multi-step prediction is achieved by changing prediction step, and the obtained 
prediction value is also added into the training set. 
The optimal value of parameters m  and �  in phase space reconstruction may not be optimal for prediction 
in the local linear prediction model. They should be more suitable for the prediction. 
2.2.  BPSO  
Kenney and Eberhart presented the Particle Swarm Optimization (PSO) algorithm as an optimization 
technique to solve problems of real-number spaces in 1995-[11]. It is described as:  
1 1
2 2
(
1)
( )
( )[
( )-
( )]
( )[
( )-
( )],
(
1)
( )
(
1).                           
ij
ij
j
best
ij
best
ij
ij
ij
ij
v t
wv t
c r t p
t
x t
c r t g
t
x t
x t
x t
v t
�
�
�
�
�
�
�
�
                                                           (3) 
Where 
( )
ijv t  is the velocity of particle i  and t  is the number of iterations. 
( )
ijx t  represents the particle 
position. j  is dimension of velocity or position of particles. 
1c  and 
2c  are the positive constant parameters. 
1r  and 
2r  are random number between 0 and 1. 
pbest
 is the best position of the particle itself and 
gbest
 is the 
best position among all the particle swarm. And w  is the inertia weight to influence the convergence 
behavior of PSO. In most cases 
max
max
min
max
-(
-
) /
.
w
w
w
w
k k
�
                                                                                                                  (4) 
It is used to speed up the convergence. But typical problems are set in a variable space with discrete and 
qualitative features, such as scheduling and routing problems. Then Kenney and Eberhart proposed BPSO to 
settle zero-one integer programming problems in 1997-[12]. In BPSO algorithm 
( )
ijv t  is no longer the velocity 
of particles but the possibility of 
( )
ijx t  equaling to 1. Sigmoid function is used to confine the possibilities 
to�
�
0   1 . Values of v  are assigned �
�
min
max
V
V
  in case of Equation (5) reaching saturation-[13].
-
1
( )
1
v
sigmoid v
e
�
�
                                                                                                                                  (5) 
380  
 Xiaoxiao Cui and Mingyan Jiang /  AASRI Procedia  1 ( 2012 )  377 – 383 
3. Modeling method based on BPSO 
Parameters of the traditional local linear are valued the same with that of phase space reconstruction during 
the traditional predictive methods. Ref [8] points out that parameters of the model can be assigned different to 
improve the predictive result. For these two parameters, the authors estimate the optimal value of one 
parameter with the other parameter fixed by minimizing the standard prediction error in Ref [8]. This method 
improves the predictive error indeed. But the problem is that there always a corresponding value for one 
parameter with the other parameter settled, so the obtained value could not be optimal in theory. In this paper 
the BPSO is used to evaluate the both parameters simultaneously. 
The local linear prediction model uses the BPSO algorithm to choose the parameters m  and � for 
improving the precision of prediction. Then m  and � become the particle swarms, so the dimension of the 
particle swarm is two. The process of obtaining the optimal parameters is illustrated as follows:
Step 1: Setting parameters 
Initialize the swarm parameters. In this paper swarm size is 30 and number of iteration is 30, length of the 
binary number is 4. Other parameters are set as:
max
min
1
2
1.2,
0.4,
2
w
 w
 c
c
�
�
�
�
.
Step 2: Learning and Computing 
1).Initialize particles with random positions and velocities;  
2).Input the training set and search for nearest neighboring points. Local linear model begins to predict 
with the training set; 
3).Compute the fitness values of each particle. To evaluate the performance of the prediction model, the 
standard prediction errors is chosen as the fitness function. 
2
1
2
1
ˆ
[ (
)- (
)]
( , )
 
,
1,2,
, .
[ (
)- ]
l
i
l
i
x n i
x n i
e m
i
l
x n i
x
�
�
�
�
�
�
�
�
�
�
�
                                                                                             (6) 
Where l  is the length of the prediction data and  
1
1
(
)
l
i
x
x n
i
l
�
�
�
�
                                                                                                                                         (7) 
(
)
x n
� i
 is the real data and  (
)
x n
� i
�
 is the output data of the model. Value of parameters could be 
acquired by minimizing formula (6). 
4).Iterate and update the particle swarm. Compare the fitness value of each iteration particle swarm and 
update the 
gbest
 and 
pbest
.
5).Obtain the optimal parameters when iteration ends. 
Step 3: Predicting 
Local linear model predicts with the parameters obtained from Step 2. 
4. Simulation and results 
In this paper the classical Lorenz time series is introduced to verify the feasibility and practicability of the 
proposed method.  
381
 Xiaoxiao Cui and Mingyan Jiang /  AASRI Procedia  1 ( 2012 )  377 – 383 
Based on Galerkin’s approximation to the partial differential equations of thermal convection in the lower 
atmosphere derived by Salzman, Lorenz proposed three ordinary differential equations-[14]. It is given by the 
following three Ordinary Differential Equations (ODEs): 
( - )
(
- ) -
.
-
x
y x
y
z x y
z
xy
z
�
�
�
� �
�
�
�
� �
�
�
�
�
             (8)
Where x  is the amplitude of the convection motion, y  is the temperature difference between ascending 
and descending currents and z  is distortion of the vertical temperature profile from linearity. � , �  and �
are dimensionless parameters. In this paper these parameters are set to be 
� � 10
,
� � 28
 and 
� � 8 / 3
 for a 
rich dynamical behavior. The standard fourth-order Runge–Kutta method is used to solve the equations. The 
time step is 
h � 0.01
 and the x  value are used to simulate and test. 
In this paper, 2000 data is chosen to build the local linear one-step model of Lorenz time series and the 
following 50 data is to be predicted. For comparison, the fitness value of proposed one-step predictive model 
and traditional model are shown in Table 1.  
Table 1. Comparison results of Lorenz time series 
Method 
Fitness value 
Traditional method 
0.00491 
Proposed method 
0.00215 
In order to compare the method of Ref [8] and the new model, 3000 data is chosen to build the model of 
Lorenz time series. The following 600 data is to be predicted. With the method of Ref [8] we set the 
parameter 
m � 3
and search for the optimal value of � that minimizes ( , )
e m � . Then we get that the optimal 
value of � is 1. Comparison results are shown separately in Fig.1 and Fig.2.Simulation results show that the 
optimal method is better than the method proposed in Ref [8]. 
0
100
200
300
400
500
600
-20
-10
0
10
20
predictive time
value
predictive value
real value
0
100
200
300
400
500
600
-1
-0.5
0
0.5
1
predictive time
error
Fig.1. the local linear multi-step prediction output of Lorenz time series with 
2,
2
m
�
�
�
382  
 Xiaoxiao Cui and Mingyan Jiang /  AASRI Procedia  1 ( 2012 )  377 – 383 
0
100
200
300
400
500
600
-20
-10
0
10
20
predictive step
value
predictive value
real value
0
100
200
300
400
500
600
-2
0
2
4
predictive step
error
Fig.2. the local linear multi-step prediction output of Lorenz time series with 
3,
1
m
�
�
�
5. Discussion   
All the figures above demonstrate the short-term predictive of chaotic time series. The predictive validity 
depends on not only the dynamic characteristics of time series, but the predictive step as well. From error 
diagrams we can see that the error of prediction is increasing basically with the prediction step in the local 
linear prediction. The reason is that each prediction value obtained by the model is used to predict the next 
data. Therefore the shorter the predictive step is, the more accurate the predictive result will be. Furthermore, 
the local linear multi-step prediction predicts chaotic time series with the training data by changing the step. 
The neighboring points do not need to be recalculated during the predictive procedure, which reduces the 
complexity of computation and is more suitable for the long-term chaos prediction.  
To get better predictive value, we can also use some other methods such as the adapted weighted fusion 
algorithm to fusion the obtained data. The adapted weighted fusion algorithm allocates the weighted factors 
automatically according to the adaptive criteria-[15]. It merges the output obtained by local one-step and multi-
step prediction model with weighted factors and improves predictive accuracy and the algorithm can 
minimize the predictive error theoretically.  
6. Conclusion 
A new method of predicting chaotic time series based on BPSO is proposed in this paper. Parameters of 
prediction model can be set to different value with those of phase space reconstruction. Because the 
parameters have important impact on the prediction accuracy, optimal values are chosen for the prediction 
model. BPSO is applied to search the optimal parameters due to its strong global search capability. The local 
linear one-step prediction updates the training set to search for new neighboring points and increases the 
complexity of computation. The multi-step prediction can overcome the disadvantage by changing the 
predictive step. The adaptive weighted fused algorithm also can be employed to improve the predictive 
accuracy by fusing the models with weighted factors. Simulation results demonstrate that the proposed 
method is superior to the traditional local linear model and more suitable for high precision short-term 
prediction.  
383
 Xiaoxiao Cui and Mingyan Jiang /  AASRI Procedia  1 ( 2012 )  377 – 383 
Acknowledgements 
This work is supported by the Natural Science Foundation of Shandong Province (No. ZR2010FM040).  
References 
[1] H. Kantz and T. Schreiber. Nonlinear Time Series Analysis, 2nd ed. Cambridge University Press 2003. 
[2] M. Casdagli. Nonlinear prediction of chaotic time-series. Physica D 1989:35: 335-356. 
[3] A.J. Lichtenberg, M.A. Lieberman. Regular and Stochastic Motion. Springer 1983. 
[4] Ansgar Freking, Wolfgang Kinzel. Learning and predicting time series by neural networks. Phys. Rev. E,  
2002:65, 050903. 
[5] D. S. K. Karunasinghe, S. Y. Liong. Chaotic time series prediction with a global model: Artificial neural 
network. Journal of Hydrology, 2006: 323 (1): 92-105. 
[6] Ping Liu, Jian Yao. Application of Least Square Support Vector Machine based on Particle Swarm 
Optimization to Chaotic Time Series Prediction. IEEE International Conference on Intelligent Computing and 
Intelligent Systems, 2009: 4: 458-462. 
[7] D. Kugiumtzis, O. C. Lingjerde, N. Christophersen. Regularized local linear prediction of chaotic time 
series. Physica D, 1998:112: 344-360. 
[8] Qingfang Meng, Yuhua Peng. A new local linear prediction model for chaotic time series. Physics Letters 
A, 2007: 370: 465–470. 
[9] Kennel M B, Brown R, Abarbanel H D I. Determining embedding dimension for phase-space 
reconstruction using a geometrical construction. Physical Review A, 1992: 45: 3403-3411. 
[10] F. Takens. On the numerical determination of the dimension of an attractor. Dynamical System and 
Turbulence, Lecture Notes in Mathematics. Springer-Verlag, Berlin, 1981: 898:230-241.  
[11] J.Kennedy, R.C.Eberhart. Particle swarm optimization. IEEE Service Center, 1995: IV: 1942-1948. 
[12] James Kennedy, Russell C. Eberhart. A Discrete Binary Version Of The Particle Swarm Algorithm. 
IEEE Service Center, 1997:4104-4108. 
[13] Xuyi Chun, Xiaoran Bin. An Improved Binary Particle Swarm Optimizer. Pattern Reorganization �
Artificial Intelligent, 2007: 20(6): 788-793,.(in Chinese) 
[14] E.N. Lorenz. Deterministic nonperiodic flow. Journal of the Atmospheric Sciences, 1963: 20: 131-141. 
[15] Yu Zhang, Jinhe Ran. Dynamic Weighted Track Fusion Algorithm Based on Track Comparability 
Degree. IEEE, 2010: 710-713. 
