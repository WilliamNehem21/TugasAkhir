On the stability of (self-)adaptive behaviour in continuously changing
environments: A quantiﬁcation approach
Martin Goller, Sven Tomforde *
Christian-Albrechts-Universit€at zu Kiel, Intelligent Systems, Hermann-Rodewald-Str. 3, 24118, Kiel, Germany
A R T I C L E I N F O
Keywords:
Self-awareness
Self-adaptive and self-organising systems
System analysis
Stability
Degree of self-adaptation
Autonomic computing
Organic computing
A B S T R A C T
The concept of self-adaptation and self-organisation (SASO) is a modern approach to cope with the ever-
increasing complexity and interconnectedness of large-scale component systems. The basic idea is to react to
environmental dynamics and disturbances by re-conﬁguring the productive behaviour and/or the relations to
other systems. However, this may result in unstable and even oscillating macro-level behaviour, potentially
rendering the adaptation efforts of the contained component systems inappropriate. We assume that such an
unstable conﬁguration is an indicator of unexpected behaviour which can lead to a reduced utility of the overall
system. To enable the system to be self-aware about such events, we propose a concept to measure the conﬁg-
uration stability of a SASO system by creating a derived time series based on the conﬁgurations. This is based on
the application of the Kinoshita measure. We show the applicability of the concept and the observed behaviour in
different simulated use-cases.
1. Introduction
Within the last decade, (self-)adaptivity increasingly became an in-
tegral part of the design of next-generation information and communi-
cation
systems
[1].
Concepts
such
as
intelligent
systems
[2],
cyber-physical systems [3], Internet of Things [4] or self-aware
computing systems [5] established a trend in systems engineering to-
wards constellations of typically distributed autonomous subsystems that
integrate dynamically into an overall system constellation and self-adapt
their behaviour in response to changing situations [6]. We refer to sys-
tems with abilities to autonomously modify their behaviour and their
structural integration in terms of cooperation with other (sub-)systems as
self-adaptive and self-organising (SASO) systems in the remainder of this
article.
To equip a SASO system with the capability of context-aware self-
adaptation, different approaches have been proposed [9], e.g. by the
Automatic Computing [7] or Organic Computing [8] initiatives. gives an
overview. These system designs often incorporate autonomous learning
techniques to allow a continuous and unsupervised improvement of the
self-adaptation behaviour [10]. The result of these efforts is that systems
can react fast and continuously to changing conditions as well as dis-
turbances [11] and consequently achieve higher robustness [12].
As outlined in previous work [13], we assume that too frequent
adaptation decisions of the (sub-)systems will lead to decreased stability
of the overall system and potentially to a decreased user acceptance.
Although there might be a perfect reason for each decision about
self-adaptation at sub-system-level, the resulting macro-level behaviour
and the interplay of the distributed subsystems’ behaviour may lead to
unstable or even oscillating conditions. Although there is some work on
the quantiﬁcation of system properties and runtime behaviour in SASO
system (see section 2.2 for an overview), what is missing is an integrated
approach to balancing the adaptation decision between possible perfor-
mance and robustness gains on the one hand and system stability and
user acceptance on the other. With this article, we propose a ﬁrst step
towards such a constructive trade-off – the basis for this is an awareness
of the actual stability within the system federation, based on external
observation.
Based on the ideas to quantify a ‘degree of adaptation’, the authors
have presented a ﬁrst concept for measuring the stability of the system's
conﬁguration in Ref. [14]. The previous article evaluated the measure in
an external disturbance scenario and a system failure scenario. This
article extends the previous work by the evaluation of the measure in two
new scenarios (see sections 4.2 and 4.4), determines novel insights about
the behaviour and its interpretability, and gives an approach to deter-
mine the necessary parameters for the evaluation (see section 3.3).
The remainder of this article is organised as follows: Section 2
* Corresponding author.
E-mail address: st@informatik.uni-kiel.de (S. Tomforde).
Contents lists available at ScienceDirect
Array
journal homepage: www.elsevier.com/journals/array/2590-0056/open-access-journal
https://doi.org/10.1016/j.array.2021.100069
Received 7 December 2020; Received in revised form 22 March 2021; Accepted 10 May 2021
Available online 28 May 2021
2590-0056/© 2021 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-
nc-nd/4.0/).
Array 11 (2021) 100069
explains the underlying system model for SASO systems including the
assumptions made by the authors and describes related work. Section 3
presents an approach to the measurement of adaptation behaviour sta-
bility, which is experimentally analysed in section 4. Finally, section 5
summarises the paper and gives an outlook on future work.
2. Background
In this section, we initially describe our system model that deﬁnes
which characteristics and capabilities of a SASO system we argue. Af-
terwards, we brieﬂy summarise developments of related work.
2.1. System model
In this article, we refer to a SASO system S as a collection A of
autonomous subsystems ai that are able to adapt their behaviour based on
self-awareness of the internal and external conditions. We further assume
that such a subsystem is an entity that interacts with other entities, i.e.,
other systems, including hardware, software, humans, and the physical
world with its natural phenomena. These other entities are referred to as
the environment of the given system. The system boundary is the common
frontier between the system and its environment.
Each ai 2 A is equipped with sensors and actuators (both, physical or
virtual). Internally, each ai consists of two parts: The productive system
part PS, which is responsible for the basic purpose of the system, and the
control mechanism CM, which controls the behaviour of the PS (i.e.,
performs self-adaptation) and decides about relations to other sub-
systems. In comparison to other system models, this corresponds to the
separation of concerns between System under Observation and Control
(SuOC) and Observer/Controller tandem [15] in the terminology of
Organic Computing (OC) [16] or Managed Resource and Autonomic
Manager in terms of Autonomic Computing [7]. Fig. 1 illustrates this
concept with its input and output relations. The user describes the system
purpose by providing a utility or goal function U which determines the
behaviour of the subsystem. The User usually takes no further action to
inﬂuence the decisions of the subsystem. Actual decisions are taken by
the productive system and the CM based on the external and internal
conditions and messages exchanged with other subsystems. We model
each subsystem to act autonomously, i.e., there are no control hierarchies
in the overall system. Please note that for the context of this article an
explicit local conﬁguration of the PS is necessary – which in turn limits
the scope of the applicability of the proposed method. Furthermore, each
subsystem must provide a read access to the conﬁguration.
At each point in time, the productive system of each ai is conﬁgured
using a vector ci. This vector contains a speciﬁc value for each control
variable that can be altered to steer the behaviour, independently of the
particular realisation of the parameter (e.g., as real value, boolean/ﬂag,
integer or categorical variable). Each subsystem has its own conﬁgura-
tion space, i.e. an n-dimensional space deﬁning all possible realisations of
the conﬁguration vector. The combination of the current conﬁguration
vectors of all contained subsystems of the overall system S deﬁnes the
joint conﬁguration of S. We assume that modiﬁcations of the conﬁgu-
ration vectors are done by the different CM only, i.e. locally at each
subsystem, and are the result of the self-adaptation process of the CM.
2.2. Related work
Within the last two decades, some work has been presented that aims
at measuring and assessing SASO system properties. The most prominent
examples are self-organisation [17] and emergence [18]. However, most
of these metrics require domain knowledge, are dedicated to a speciﬁc
application, are restricted to simple, small-scale models [19], or describe
architectural and implementational properties for the comparison of
systems at design-time [20].
Kaddoum et al. [21] discuss the need to reﬁne classical performance
metrics to SASO purposes and present speciﬁc metrics for self-adaptive
systems. They distinguish between “nominal” and “self-*” situations
and their relations. For instance, they measure the operation time about
the adaptation time to determine the effort. Some of the developed
metrics have been investigated in detail by Camara et al. for software
architecture scenarios [22]. Besides, success and adaptation efforts and
ways to measure autonomy have been investigated, see e.g. [23].
Only a few contributions focused on general metrics to determine the
effort and the beneﬁt of (self-)adaptation in distributed collections of
autonomous subsystems, see Ref. [24] for an overview. Examples include
the relation between working and adaptation time, the availability of
subsystems for task processing, and the performance of the overall system
(i.e., the degree to which a certain goal is achieved). This has been
accompanied by a transfer of traditional performance metrics, see
Ref. [21] or augmented with measures necessary for control strategies of
SASO systems [25]. However, the focus on an degree of adaptation, the
stability of adaptations, and the foundation for deriving a trade-off be-
tween possible performance gain of individual component systems and
negative impact on macro-level behaviour has not been focused.
In general, there is only a very limited number of contributions on
when (and if at all) to adapt in literature. Recently, Chen et al. presented
a concept that is based on the so-called ‘technical debt’ [26]: The authors
introduce a gate that either enables or disables the adaptation mecha-
nism. This decision is based on deriving an integrated score for deﬁning
the current so-called ‘temporal interest’ and the expected ‘revenue’. This
implicitly allows for a similar goal as outlined in this paper: More sta-
bility rather than frequent self-adaptation. However, it does not come
with a measurement that determines the degree of self-adaptation or the
degree of stability, preferable in relation to the current context.
In
[17]
Tomforde
et
al.
introduce
a
method
to
measure
self-organisation based on a comparison of observed communication
patterns between subsystems. Their basic idea is comparable to the
approach presented in this paper. In Refs. [13,27] the authors present the
idea to consider the conﬁgurations of subsystems as an observable state
in a generative probabilistic model of observation. Although the tech-
nical approach is comparable to this article, the focus is different as it
goes beyond a ‘degree of self-adaptation/self-organisation’. Fundamen-
tally, this article presents the next step on-top of these measurements.
As a summary of this discussion, we can state that a uniﬁed mea-
surement framework for the quantiﬁcation of externally measurable
system properties that consider the adaptation behaviour of SASO sys-
tems is still missing. Either existing approaches focus on isolated aspects
such as performance or they make use of domain knowledge. Based on
the assumption of being able to assess the conﬁguration of the productive
components that are steered by adaptation modules, we add a novel
approach for modelling system behaviour at macro-level. This serves as a
starting point for higher-levelled assessments such as stability (discussed
Fig. 1. Schematic illustration of a subsystem ai from Ref. [15]. The arrows from
the sensors and PS to the CM indicate observation ﬂows, while the arrows from
the CM to the PS and the actuators indicate control ﬂows. Dashed arrows
emphasise a possible path that is typically not used. Not shown: The CM is able
to communicate with other CMs in the shared environment to exchange infor-
mation such as sensor reading and to negotiate policies.
M. Goller, S. Tomforde
Array 11 (2021) 100069
2
in this article), variability, or acceptability (which is subject to future
work). Technically, our probabilistic approach differs fundamentally
from other approaches as it models each aspect of the distributed sub-
systems’ conﬁgurations as random variables without any assumptions on
the impact of the performance, the causes for adaptation decisions, or
temporal implications. We compare the observations using divergence
measures, which then allows for deﬁning different measures for self-
adaptation on-top of this quantiﬁcation.
3. Conﬁguration stability
If the CM decides that an adaptation is necessary it will change the
conﬁguration of the productive system. Since the decision models used
by the CM are hidden to external observers, we model the conﬁguration
changes as a random process with the conﬁguration vector as a random
variable. Therefore, the observed conﬁgurations form a random distri-
bution. For this distribution, an estimated density can be associated and
new conﬁgurations can be assigned a probability concerning that density.
Our approach is based on the idea that if new conﬁgurations with a
high probability are chosen the system works as expected and the un-
derlying adaptation is desirable or ‘normal’. In such a case, we call the
conﬁguration state ‘stable’. If a new conﬁguration has a low probability
we still assume that the system is working as usual and that this adap-
tation is due to a minor disturbance. Only when conﬁgurations with low
probability are chosen over a longer course of time, we presume that a
major disturbance or a system failure is on hand.
If it comes down to the implementation, conﬁguration parameters are
usually represented as real numbers. Since a single vector of real numbers
has a probability of P ¼ 0 in a continuous density, we will look at the
probability densities that are created by several vectors.
By comparing the conﬁgurations of a subsystem in a current time
window with those of a previous window, we can identify abnormal
adaptation activity in a single subsystem. To identify abnormal changes
in a SASO system at a global scale (i.e. at macro-level, we take all
conﬁguration comparisons into account and then apply a measure based
on the “macroscopic measure for detecting abnormal changes in a multi-
agent system” as deﬁned by Kinoshita [28].
3.1. Deﬁnition of the Kinoshita measures
Kinoshita proposes a measure which he uses as an indicator for un-
usual activity changes in a distributed multi-agent system. Kinoshita
deﬁnes two values, the activity factor at a given time and the variance of
ﬂuctuation of the activity factor. The activity factor is based on the
classiﬁcation of each agent as either active or inactive. Let N denote the
total number of agents in the multi-agent system and let nt be the number
of active agents at a given time t. The activity factor zt is deﬁned as
zt :¼ 2 � nt � N þ 1
2 � N
(1)
For a given window size M, the ﬂuctuation ξt of the activity factor at
time t is calculated as
ξt :¼ zt � 1
M �
X
M�1
i¼0
zt�i
and ﬁnally, we calculate the variance νt of the ﬂuctuation:
νt :¼ 1
M
X
M�1
i¼0
ξ2
t�i �
 
1
M
X
M�1
i¼0
ξt�i
!2
(2)
Kinoshita argues that unusual peaks in the time series of νt are an indi-
cator of abnormal changes in the underlying distribution of active and
inactive subsystems. Consequently, we aim at using this measure to
detect such peaks that then serve as an indicator for undesired adaptation
behaviour that needs to be suppressed.
3.2. Application of the Kinoshita measures
To apply the Kinoshita measure, we need to deﬁne what active and
inactive agents are. Obviously, the subsystems of our SASO system are
the agents in Kinoshita's measure. Our goal is to determine whether the
conﬁguration of each subsystem is stable or not. Therefore, we deﬁne a
subsystem as active if and only if its conﬁguration is unstable. That is that
the divergence of the density of the latest conﬁgurations and the density
of previous conﬁgurations is greater than a certain threshold. That means
that for the latest conﬁgurations values were chosen that follow a dis-
tribution which signiﬁcantly differs from the previous one.
Let ca;t 2 Rn be the n-dimensional conﬁguration vector of the sub-
system a at time t. We model ca,t as a random variable. Let M > 1 be the
window size and L > 0 be the delay parameter. Using an appropriate
density estimation technique, we deﬁne two probability densities DCa,t
and DPa,t based on parts of the time series of ca,t:
DCa;t :¼ densityðca;t�m; ca;t�mþ1; …; ca;tÞ
DPa;t :¼ densityðca;t�l�m; ca;t�l�mþ1; …; ca;t�lÞ
DC is the density of the current window and DP the density of a
previous window in the time series. To these two densities, we now apply
the Kullback-Leibler divergence [29] measure
KL2ðP; QÞ
¼
Z ∞
�∞
pðxÞlog
�pðxÞ
qðxÞ
��
2
�
Z ∞
�∞
qðxÞlog
�qðxÞ
pðxÞ
��
2
(3)
and get a new time series
da;t :¼ KL2ðDCa;t; DPa;tÞ
(4)
Finally, we deﬁne a subsystem a to be active at time t if da,t > ϵ for a
threshold value ϵ. Otherwise, the subsystem is called inactive.
3.3. Finding the right parameters
Finding suitable values for the parameters M, L and ϵ is crucial for the
signiﬁcance of the calculated Kinoshita measure. A low ϵ will mark
conﬁguration changes as unstable which at a closer look are still
acceptable as stable. On the other hand, too high values for M and L
would mask short term occurrences of high amplitude changes. Our ex-
periments show that good choices for these parameters highly depend on
the actual SASO-System. In general, the conﬁguration of these parame-
ters is consequently application-speciﬁc and should be customised at
runtime using hyper-parameter-tuning. However, we aim at a ‘good-
enough’ reference conﬁguration.
A ﬁrst approach to ﬁnd such acceptable values is to create a simula-
tion of the SASO system and gather the conﬁguration time series of the
simulated subsystems. In the next step, change these data samples for
some of the agents such that at controlled time points for a few steps high
amplitude changes occur. Then we create an optimisation problem: Find
the best values for M, L and ϵ such that the controlled changes create
unique peaks in the Kinoshita measure.
Our experiments show that the best values vary depending on where
we set the artiﬁcial changes. However, they vary only in a very limited
range. Therefore, a reasonable next step is to run this optimisation
several times with different points for the changes. This gives a distri-
bution for M, L and ϵ. The values that occur most often usually are in fact
good values for the actual evaluation.
Of course, this method only works if it is possible to create such
artiﬁcial changes. If the base simulation already generates conﬁguration
samples with a wide range of values and a lot of changes in one time
frame and very few changes in another, then it is hardly possible to ﬁnd
values that will give satisfying results. In this case, we consider the
M. Goller, S. Tomforde
Array 11 (2021) 100069
3
conﬁguration of the system as unstable from the beginning. In fact,
normal and abnormal adaptation behaviour cannot be distinguished in
these scenarios, which renders our measure not applicable. However,
current experiments show that this is not the case for the investigated
scenarios (where future work aims also at deﬁning the limits for the
application).
4. Experiments and evaluation
We analyse the behaviour of the proposed measure in two artiﬁcial
ﬂocking [30] and two basic trafﬁc simulations. All simulations are
implemented in the MASON [31] simulation environment.
4.1. Flocks with external disturbance
This ﬂocking simulation consists of 50 birds on a toroidal plane with
random starting points and random initial orientations. We consider two
cases: First a normal simulation and second a disturbed one. In both
scenarios, the birds follow the usual rules of ﬂocking:
● Alignment: A bird will align its direction with the average direction of
its neighbours
● Cohesion: A bird will steer towards the centre of all neighbouring
birds
● Avoidance: A bird will steer away from neighbours that are too close
For each of these rules, a direction vector vx is computed, weighted
(with factor wx) and then added together. This sum is then normalised
and eventually added to the current direction vcurrent vector of the given
bird to determine it's direction vnext in the next time step:
vnext
¼ vcurrent þ normalise
�
w*
alignmentvalignment
þw*
cohesionvcohesion
þ w*
avoidancevavoidance
�
(5)
For the two simulations, the values are wcohesion ¼ walignment ¼ 1.0,
wavoidance ¼ 0.33 and the sum is normalised to a value of 0.7.
In the undisturbed case, all birds follow these three rules. In the
disturbed case, one bird A0 is removed at time point t ¼ 500. All birds
within a distance of 50 units ﬂy diametrically away from A0 for two time
steps and then follow their usual behaviour again (which simulates the
response to a shot killing the bird, for instance).
The conﬁguration on which we apply the measures is the orientation
of the birds, represented as the angle against the x-axis (with values from
� π to π) of the simulation environment. Fig. 2 shows the time series of
Fig. 2. The orientation time series of one of the affected birds. The values wrap
around at � π. The disturbance is visible as the drop at t ¼ 500.
Fig. 3. Some results of the heuristic 3.3 for the ﬁrst ﬂocking simulation for a
ﬁxed ϵ ¼ 1. Red: M ¼ L ¼ 10, blue: M ¼ L ¼ 20 and grey: M ¼ L ¼ 25.
Fig. 4. Some results of the heuristic 3.3 for the ﬁrst ﬂocking simulation for a
ﬁxed M ¼ L ¼ 20. Red: ϵ ¼ 2, blue: ϵ ¼ 1 and grey: ϵ ¼ 0.5.
M. Goller, S. Tomforde
Array 11 (2021) 100069
4
the orientation of one of the affected birds. Most of the time, this bird has
an orientation near � π, but when the disturbance occurs it changes it's
orientation abruptly to a value near 1. It then takes the bird about 120
steps to realign to the majority of the ﬂock.
To apply the Kinoshita measure, we need to ﬁx values for M, L and ϵ.
For this, we put the undisturbed simulation into the heuristic from sec-
tion 3.3 and change the conﬁguration values for 10% of the agents. From
t ¼ 200 to t ¼ 210 these agents get a constant conﬁguration value of 1 and
from t ¼ 300 to t ¼ 310 they get a value of 0. Therefore, we expect the
heuristic to ﬁnd values such that one peak at t ¼ 200 � L and one at t ¼
300 � L is sufﬁciently prominent.
Fig. 3 shows results for a ﬁxed ϵ ¼ 1. For M ¼ L ¼ 10 (red graph) we
see the peaks at t ¼ 190 and t ¼ 290 but also two additional peaks at t ¼
200 and t ¼ 210 which are almost the same height as the ﬁrst one. M ¼ L
¼ 25 (grey graph) we have no sufﬁciently prominent peak at t ¼ 175. The
blue graph shows the result for M ¼ L ¼ 20 which meets our expectation
fairly well.Fig. 4 gives an impression on the effects of changing the
ϵ-parameter. A low ϵ allows too many agents to be counted as active, even
those who are not using artiﬁcially changed conﬁguration data. There-
fore, the grey graph (ϵ ¼ 0.5 gives too many peaks. The blue graph shows
the results for ϵ ¼ 1, where we can identify the desired peaks alongside a
few smaller ones. The red graph shows ϵ ¼ 2. Here, no other peaks are
present. We then repeat this process with other time points for the arti-
ﬁcially changed data. Finally, the heuristic tells us that good values for M
and L are in fact near M ¼ L ¼ 20 and that ϵ � 1 is suitable. We keep in
mind that a high value for ϵ could suppress important agents. Therefore,
we choose M ¼ L ¼ 20 and ϵ ¼ 1 for the evaluation of this simulation.
To determine whether the bird a is count as active at t ¼ 520 in the
disturbed simulation, we need to calculate the distribution densities
DCa,520 ¼ density(ca,500, …, ca,520) and DPa,520 ¼ density(ca,480, …, ca,500)
of its orientation. To do so, we use the common kernel density estimation
methods from Ref. [32]. Since the orientation is circular (wrapping
around at � π), we need to use a circular kernel function. In this case, we
chose a von Mises kernel [33]. Fig. 5 shows the resulting densities with
the centre of distribution near 2.7 in the ﬁrst time window and near 1.2 in
the second window.
The KL2-value for this bird is da;520 ¼ KL2
�
DCa;520; DPa;520
�
� 6:11.
This is higher than our threshold value. Consequently, the bird a is
considered to be ‘active’ at t ¼ 520.
Doing this for all birds and all time points, we can calculate the
Kinoshita activity factor (which is basically the ratio of active agents)
using formula 1. The result is shown in Fig. 6. Here, we can already
identify a peak at the disturbance event together with other phases of
high activity. Finally, we can calculate the ﬂuctuation variance νt. Fig. 7
shows the resulting time series for the disturbed (red) and the
Fig. 5. Densities for the orientation distributions of bird from Fig. 2 in the
disturbed ﬂocking simulation. Red: during t ¼ 480 to t ¼ 500, blue: during t ¼
500 to t ¼ 520.
Fig. 6. The Kinoshita activity factor for the disturbed ﬂocking simulation.
Fig. 7. The Kinoshita ﬂuctuation variance of the ﬂocking simulation. Red: the
disturbed case, blue: undisturbed.
M. Goller, S. Tomforde
Array 11 (2021) 100069
5
undisturbed (blue) simulation. Except for minimal differences due to the
arithmetic precision ﬂaws of the Java double type [34] both graphs are
identical until t ¼ 480. At that point, the time windows incorporate the
disturbance. The disturbance creates a clear peak in the graph. Shortly
after the disturbance, the birds group in three isolated ﬂocks, two of them
merge at t ¼ 900 which results in a second peak. Other than the activity
factor, the ﬂuctuation variance emphasises these two events.
4.2. Flocks with change of utility
In this simulation, we model 50 agents that again roam a toroidal
plane with random starting points and random initial orientations. Next,
we assign each point of the plane a utility value such that the utility
values for all points in the plane are zero except for two circular, inter-
secting areas. The agents follow the rule of avoidance as in the previous
scenarios (but not alignment or cohesion, i.e. wcohesion ¼ walignment ¼ 0)
and they can evaluate the utility value of their current position. The goal
for each agent is to stay inside the area of the highest utility value. If it is
not inside that area it will steer towards the centre of that area until the
area is entered (see Fig. 8). This can be viewed as a ﬂock of predators
running around in an area with the best supply of prey or as a group of
vacuum cleaning robots that clean the dirtiest area in the house.
In analogy to the real world, where the predators will decimate the
prey and the robots will remove the dirt, we introduce a dynamic in the
utility values. The values U for the two non-zero utility areas change over
time following a sinus function with a constant phase p and the time step
variable t:
UðtÞ :¼ ðsinð0:001*p*tÞ þ 1Þ=2
The phase parameters for the two areas are p ¼ 7 and p ¼ 9. Therefore,
their utility values oscillate between 0 and 1 with different speeds. By
this means, we force the agents to migrate to the other area which creates
a notable overlay over the usual chaotic motion behaviour. At the
beginning of the simulation, the lower right area is the one with the
highest utility value. Within 150 steps, all agent have reached this area.
At t ¼ 205 the upper left area will become the one with the higher value
and the agents start migrating towards it. At t ¼ 588 the roles will switch
again.
Putting the time series of the agents’ orientation into our measures
and applying the parameters M ¼ L ¼ 12 and ϵ ¼ 0.8 as given by the
heuristic creates the graph for νt as shown in Fig. 9. The two prominent
peaks show the reaction of the agents to the changing utility. They are an
indicator for a major conﬁguration change that a system user should
examine.
4.3. Network of trafﬁc lights with internal disturbance
The third scenario is inspired by the Organic Trafﬁc Control (OTC)
system that self-adapts the green duration of trafﬁc lights [35], estab-
lishes progressive signal systems [36], and guides drivers through the
network using variable message signs [37]. Here, we used an abstract
trafﬁc simulation, where the SASO system consists of seven inter-
connected intersection controllers. Fig. 10 shows the layout of the street
Fig. 8. The second ﬂocking simulation at time step t ¼ 250. The agents are
heading towards the upper left area which has a higher utility value than the
lower right area since t ¼ 205.
Fig. 9. The Kinoshita ﬂuctuation variance for the utility changing simulation.
The peaks at t ¼ 205 and t ¼ 588 show the reaction of the agents to the change
of the highest utility area.
Fig. 10. The street network for trafﬁc simulation. The circles are intersections
and the arrows are the street lanes.
M. Goller, S. Tomforde
Array 11 (2021) 100069
6
network.
Each intersection tries to minimise the waiting time for all cars at all
incoming lanes by optimising the red light times for each lane. There are
250 cars in the simulation. They are part of the environment and not of
the SASO system itself. Each car picks its destination randomly and
chooses the shortest path to it. When it reaches the destination, the
process is repeated and therefore all cars in motion constantly. In contrast
to OTC system, the intersections of the SASO system in this simulation do
not communicate with each other. Their reconﬁguration results are only
based on the current trafﬁc volume at intersection's lanes.
The optimisation function to be minimised is the sum of all waiting
times of all cars in all lanes. We assume that each car needs a constant
time to cross the intersection if it is in the ﬁrst position of an incoming
lane with a green light. Therefore, the waiting time for one car is deﬁned
by the number of cars that are processed before the current car leaves the
intersection. In one time step of the simulation, several cars can be pro-
cessed. The waiting time of the unprocessed cars is carried over to the
next simulation step. After each simulation step, the intersections look at
the waiting times of the unprocessed cars and try to ﬁnd a red light
conﬁguration that minimises the expected waiting time over all cars in
the next step.
In this scenario, the path between intersections A and B is chosen with
a probability of p ¼ 0.9 and the path between E1 and E2 is chosen with p
¼ 0.75. Consequently, these two separate paths have the highest trafﬁc
volume. We then block the central intersection C between t ¼ 250 and t
¼ 400. During this time, the intersection C is unavailable and the cars
have to use other paths. Therefore, the intersection D2 will have to
reconﬁgure its red-light times to handle both trafﬁc streams. Fig. 11
shows the results of the disturbance for one lane at the intersection D2.
We re-used the heuristic approach from the previous scenarios, which
chose a window size of M ¼ 20 steps, a delay of L ¼ 20 and a threshold ϵ
¼ 10 to generate the time series νt. Fig. 12 shows νt for the simulation
with (red) and without (blue) the disturbance. After an initial setup
phase, which takes 70 steps, there is no longer a difference between
currently and previously chosen conﬁgurations in the undisturbed case.
The conﬁguration is stable for all t > 70. In the disturbed case, on the
other hand, the instability of the conﬁguration is clearly visible. The start
and the end of the blockade require high reconﬁguration effort of the
intersections to handle the changed trafﬁc ﬂow. The effects manifest
themselves as the two peaks at t ¼ 250 and t ¼ 400. In the beginning of
the simulation, and during and after the blockade, there are still
conﬁguration changes that are big enough to count as active but they
generate no isolated peaks. For the sake of completeness, We provide the
Kinoshita activity factor for this simulation in Fig. 13. In this time series,
the signals for the blockade are not as prominent and the setup phase
creates similar signals.
Fig. 11. The red light times at intersection D2 for the lane E2 → D2.
Fig. 12. The Kinoshita ﬂuctuation variance of the ﬁrst trafﬁc simulation. Red:
with a blocked intersection from t ¼ 250 to t ¼ 400, blue: undisturbed.
Fig. 13. The Kinoshita activity factor of the ﬁrst trafﬁc simulation with a
blocked intersection from t ¼ 250 to t ¼ 400.
M. Goller, S. Tomforde
Array 11 (2021) 100069
7
4.4. Network of trafﬁc lights with changes in the environment
We created this additional simulation to test the measures in a more
noisy and larger environment where a smaller part of the subsystems
experience a direct inﬂuence from external events. The scenario simu-
lates rush hours in a city street network. The trafﬁc lights and the cars
operate in the same way as in the previous scenario, but we use a
different street network. The network represents two islands each with a
Manhattan-type network of sizes 3 by 5. The islands are connected with
three bridges. The connections between two intersections provide one
lane for each direction (see Fig. 14).
During the whole simulation, there are 250 cars driving around
randomly. Furthermore, three intersections on one island are designated
to be homesteads and three intersections on the other island are labelled
as work places. At t ¼ 250 a total count of 500 new cars will appear
randomly in the three homesteads and start driving towards one of the
three workplaces. Therefore, the bridges have to handle an increasing
ﬂow from one side to the other in the following time steps. When the new
cars arrive at their work places, they are removed from the simulation. At
t ¼ 750 this is repeated but this time the new cars will go from the
workplaces towards home.
Fig. 15 shows the time series νt for this scenario with parameters M ¼
L ¼ 15 and ϵ ¼ 2. Since the random background trafﬁc has no preferred
routes, we see a more noisy time series with more peaks. The peaks
occurring after t ¼ 250 and t ¼ 750 are due to the increased conﬁguration
changes that are caused by the higher trafﬁc ﬂow. These peaks are still
clearly visible but are not as outstanding as in the previous simulations.
The other peaks are a result of the random trafﬁc. This shows that the
measure is still applicable in such an environment although its perfor-
mance to identify major events is not as good as in situations with less
noise.
5. Conclusion
This article presented a step towards an integrated framework for the
quantiﬁcation of runtime SASO behaviour. Based on preliminary work on
a probabilistic approach to assess a degree of self-adaption and self-
organisation, this article presented a method to measure the stability of
conﬁgurations of autonomous subsystems within an overall SASO
constellation. Taking the design concepts of Organic Computing and
Autonomic Computing as basis, we found our approach on the interface
between adaption mechanism and productive system by assuming read
access to the current conﬁgurations of the productive units. We showed
that the proposed measure building upon the Kinoshita approach can be
used to identify global anomalies in the system's conﬁguration which
serve as indicators for abnormal adaptation processes. The capability to
identify such anomalies relies on the choices for the incorporated hyper-
parameters.
The presented approach is a step towards the overall goal of devel-
oping an integrated measurement framework for a continuous runtime
analysis of SASO system properties. Future work follows two major
research directions: On the one hand, we aim at an application to further,
more complex scenarios of distributed SASO constellations and assess the
behaviour of the measure. This includes an evaluation of this method in
real-world applications and ﬁnding more constructive methods to iden-
tify suitable parameters. On the other hand, we build on-top of the in-
dicators provided by the measure to establish a runtime approach to
using this information within the adaption logic, e.g., to better balance
the trade-off between possible performance gain due to adaptation de-
cisions and the impact on the stability and correspondingly the users’
acceptance.
Declaration of competing interest
The authors declare that they have no known competing ﬁnancial
interests or personal relationships that could have appeared to inﬂuence
the work reported in this paper.
Acknowledgements
This
research
is
partly
funded
by
the
Deutsche
For-
schungsgemeinschaft (DFG, German Research Foundation) under grant
TO 843/5-1 (project ‘InTURN’). The publication of this article was
ﬁnancially supported by DFG within the funding programme Open Ac-
cess Publizieren. The authors acknowledge the support by the DFG.
References
[1] Bellman K, Botev J, Diaconescu A, Esterle L, Gruhl C, Landauer C, Lewis PR,
Nelson PR, Pournaras E, Stein A, Tomforde S. Self-improving system integration:
mastering continuous change. Future Generat Comput Syst 2021;117:29–46.
https://doi.org/10.1016/j.future.2020.11.019. http://www.sciencedirect.com/sci
ence/article/pii/S0167739X20330430.
[2] Calma A, Kottke D, Sick B, Tomforde S. Learning to learn: dynamic runtime
exploitation of various knowledge sources and machine learning paradigms. In:
2017 IEEE 2nd international workshops on foundations and applications of self*
systems; 2017. p. 109–16.
Fig. 14. The street network for the second trafﬁc simulations. Home steads are
marked with a square, work places with a triangle.
Fig. 15. The Kinoshita ﬂuctuation variance of the rush hour simulation with
increased trafﬁc ﬂow starting at t ¼ 250 and t ¼ 750.
M. Goller, S. Tomforde
Array 11 (2021) 100069
8
[3] Rajkumar R, Lee I, Sha L, Stankovic J. Cyber-physical systems: the next computing
revolution. In: Design automation conference. IEEE; 2010. p. 731–6.
[4] Atzori L, Iera A, Morabito G. The internet of things: a survey. Comput Network
2010;54(15):2787–805.
[5] Kounev S, Lewis P, Bellman K, Bencomo N, Camara J, Diaconescu A, Esterle L,
Geihs K, Giese H, et al. The notion of self-aware computing. In: Self-aware
computing systems. Springer; 2017. p. 3–16.
[6] Bellman K, Tomforde S, Würtz R. Interwoven systems: self-improving systems
integration. In: 8th IEEE int. Conf. on self-adaptive and self-organizing systems
workshops; 2014. p. 123–7.
[7] Kephart J, Chess D. The vision of autonomic computing. IEEE Computer 2003;
36(1):41–50.
[8] Müller-Schloer C, Tomforde S. Organic computing – techncial systems for survival
in the real world, autonomic systems. Birkh€auser Verlag; 2017.
[9] Weyns D, Schmerl B, Grassi V, Malek S, Mirandola R, Prehofer C, Wuttke J,
Andersson J, Giese H, G€oschka K. On patterns for decentralized control in self-
adaptive systems. In: Software engineering for self-adaptive systems II. Springer;
2013. p. 76–107.
[10] D'Angelo M, Gerasimou S, Ghahremani S, Grohmann J, Nunes I, Pournaras E,
Tomforde S. On learning in collective self-adaptive systems: state of practice and a
3d framework. In: 2019 IEEE/ACM 14th international symposium on software
engineering for adaptive and self-managing systems. IEEE; 2019. p. 13–24.
[11] Krupitzer C, Roth F, VanSyckel S, Schiele G, Becker C. A survey on engineering
approaches for self-adaptive systems. Pervasive Mob Comput 2015;17:184–206.
[12] Tomforde S, Kantert J, Müller-Schloer C, B€odelt S, Sick B. Comparing the effects of
disturbances in self-adaptive systems - a generalised approach for the quantiﬁcation
of robustness. Trans. Comput. Collect. Intell. 2018;28:193–220.
[13] Tomforde S, Goller M. To adapt or not to adapt: a quantiﬁcation technique for
measuring an expected degree of self-adaptation. Computers 2020;9(1):21.
[14] M. Goller, S.Tomforde, Towards a continuous assessment of stability in (Self-)
Adaptation behaviour, Proceedings of the 1st IEEE international conference on
autonomic computing and self-organising systems workshops (ACSOS-W), 6th
Workshop on Self-Aware Computing (SeAC20).
[15] Tomforde S, Prothmann H, Branke J, H€ahner J, Mnif M, Müller-Schloer C,
Richter U, Schmeck H. Observation and control of organic systems. In: Müller-
Schloer C, Schmeck H, Ungerer T, editors. Organic computing - a paradigm shift for
complex systems, autonomic systems. Birkh€auser Verlag; 2011. p. 325–38.
[16] Tomforde S, Sick B, Müller-Schloer C. Organic computing in the spotlight, CoRR
abs/1701.08125. http://arxiv.org/abs/1701.08125.
[17] Tomforde S, Kantert J, Sick B. Measuring self-organisation at runtime - a
quantiﬁcation method based on divergence measures. In: Proc. of 9th int. Conf. on
agents and artiﬁcial intelligence; 2017. p. 96–106.
[18] Fisch D, J€anicke M, Sick B, Müller-Schloer C. Quantitative emergence–a reﬁned
approach based on divergence measures. In: IEEE int. Conf. on self-adaptive and
self-organizing systems. IEEE; 2010. p. 94–103.
[19] Chan W. Interaction metric of emergent behaviours in agent simulations. In: Proc.
of the winter sim. Conf.; 2011. p. 357–68.
[20] Raibulet C, Masciadri L. Metrics for the evaluation of adaptivity aspects in software
systems. Int. J. Adv. Softw. 2010;3(1 & 2):238–51.
[21] Kaddoum E, Raibulet C, Georg�e J-P, Picard G, Gleizes M-P. Criteria for the
evaluation of self-* systems. In: Pro. of ICSE works. on softw. Eng. for adaptive and
self-managing sys.; 2010. p. 29–38.
[22] C�amara J, Correia P, de Lemos R, Vieira M. Empirical resilience evaluation of an
architecture-based self-adaptive software system. In: Pro. of 10th int. ACM sigsoft
conf. on quality of softw. Architectures; 2014. p. 63–72.
[23] Gronau N. Determinants of an appropriate degree of autonomy in a cyber-physical
production system. In: Proc. of 6th Int. Conf. on Changeable, Agile, Reconﬁgurable,
and Virtual Production, 52; 2016. p. 1–5.
[24] Eberhardinger B, Anders G, Seebach H, Siefert F, Reif W. A research overview and
evaluation of performance metrics for self-organization algorithms. In: Proc. of self-
adaptive and self-organizing systems works. SASO-W’15); 2015. p. 122–7.
[25] Filieri A, Maggio M, Angelopoulos K, D’ippolito N, Gerostathopoulos I, Hempel A,
Hoffmann H, Jamshidi P, Kalyvianaki E, Klein C, Krikava F, Misailovic S,
Papadopoulos A, Ray S, Shariﬂoo A, Shevtsov S, Ujma M, Vogel T. Control strategies
for self-adaptive software systems. ACM Trans Autonom Adapt Syst 2017;11(4):24:
1–24:31.
[26] Chen T, Bahsoon R, Wang S, Yao X. To adapt or not to adapt? technical debt and
learning driven self-adaptation for managing runtime performance. In: Proc. of the
2018 ACM/SPEC int. Conf. on Performance Engineering; 2018. p. 48–55.
[27] Tomforde S. From ”normal” to ”abnormal”: a concept for determining expected self-
adaptation behaviour. In: IEEE 4th international workshops on foundations and
applications of self* systems; 2019. p. 126–9.
[28] Kinoshita T. Basic characteristics of a macroscopic measure for detecting abnormal
changes in a multiagent system. MDPI Sensors 2015;15(4):9112–35.
[29] Bishop C. Pattern recognition and machine learning. second ed. Information Science
and Statistics, Springer; 2011.
[30] Reynolds CW. Flocks, herds and schools: a distributed behavioral model. ACM
SIGGRAPH Comput. Graph. 1987;21:25—–34.
[31] Luke S, Ciofﬁ-Revilla C, Panait L, Sullivan K, Balan G, Mason. A multi-agent
simulation environment. Trans. Soc. Model. Simul. Int. 2005;82(7):517–27.
[32] Parzen E. On estimation of a probability density function and mode. Ann Math Stat
1962;33:1065—–1076.
[33] Mardia K, Jupp P. Directional statistics. Wiley; 1999.
[34] D. Goldberg, What every computer scientist should know about ﬂoating point
arithmetic, ACM Comput Surv 23. doi:10.1145/103162.103163.
[35] Prothmann H, Rochner F, Tomforde S, Branke J, Müller-Schloer C, Schmeck H.
Organic control of trafﬁc lights. In: Autonomic and trusted computing, 5th
international conference, ATC 2008, Oslo, Norway, june 23-25, 2008, proceedings;
2008. p. 219–33.
[36] Tomforde S, Prothmann H, Rochner F, Branke J, H€ahner J, Müller-Schloer C,
Schmeck H. Decentralised progressive signal systems for organic trafﬁc control. In:
Second IEEE international conference on self-adaptive and self-organizing systems,
SASO 2008, 20-24 october 2008, Venice, Italy; 2008. p. 413–22.
[37] Prothmann H, Schmeck H, Tomforde S, Lyda J, H€ahner J, Müller-Schloer C,
Branke J. Decentralised route guidance in organic trafﬁc control. In: 5th IEEE
international conference on self-adaptive and self-organizing systems, SASO 2011,
ann arbor, MI, USA, october 3-7, 2011; 2011. p. 219–20.
M. Goller, S. Tomforde
Array 11 (2021) 100069
9
