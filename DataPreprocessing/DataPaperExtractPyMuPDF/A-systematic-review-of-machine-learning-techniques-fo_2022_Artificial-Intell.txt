A systematic review of machine learning techniques for cattle
identiﬁcation: Datasets, methods and future directions
Md Ekramul Hossain a,e, Muhammad Ashad Kabir a,b,e,⁎, Lihong Zheng a,e, Dave L. Swain b,c,e,
Shawn McGrath b,d,e, Jonathan Medway b,e
a School of Computing, Mathematics and Engineering, Charles Sturt University, Bathurst, NSW 2795, Australia
b Gulbali Institute for Agriculture, Water and Environment, Charles Sturt University, Wagga Wagga, NSW 2678, Australia
c TerraCipher Pty. Ltd., Alton Downs, QLD 4702, Australia
d Fred Morley Centre, School of Animal and Veterinary Sciences, Charles Sturt University, Wagga Wagga, NSW 2678, Australia
e Food Agility CRC Ltd, Sydney, NSW 2000, Australia
a b s t r a c t
a r t i c l e
i n f o
Article history:
Received 6 July 2022
Received in revised form 1 September 2022
Accepted 11 September 2022
Available online 18 September 2022
Increased biosecurity and food safety requirements may increase demand for efﬁcient traceability and identiﬁca-
tion systems of livestock in the supply chain. The advanced technologies of machine learning and computer
vision have been applied in precision livestock management, including critical disease detection, vaccination,
production management, tracking, and health monitoring. This paper offers a systematic literature review
(SLR) of vision-based cattle identiﬁcation. More speciﬁcally, this SLR is to identify and analyse the research
related to cattle identiﬁcation using Machine Learning (ML) and Deep Learning (DL). This study retrieved 731
studies from four online scholarly databases. Fifty-ﬁve articles were subsequently selected and investigated in
depth. For the two main applications of cattle detection and cattle identiﬁcation, all the ML based papers only
solve cattle identiﬁcation problems. However, both detection and identiﬁcation problems were studied in the
DL based papers. Based on our survey report, the most used ML models for cattle identiﬁcation were support
vector machine (SVM), k-nearest neighbour (KNN), and artiﬁcial neural network (ANN). Convolutional neural
network (CNN), residual network (ResNet), Inception, You Only Look Once (YOLO), and Faster R-CNN were pop-
ular DL models in the selected papers. Among these papers, the most distinguishing features were the muzzle
prints and coat patterns of cattle. Local binary pattern (LBP), speeded up robust features (SURF), scale-
invariant feature transform (SIFT), and Inception or CNN were identiﬁed as the most used feature extraction
methods. This paper details important factors to consider when choosing a technique or method. We also iden-
tiﬁed major challenges in cattle identiﬁcation. There are few publicly available datasets, and the quality of those
datasets are affected by the wild environment and movement while collecting data. The processing time is a
critical factor for a real-time cattle identiﬁcation system. Finally, a recommendation is given that more publicly
available benchmark datasets will improve research progress in the future.
© 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open
access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
Keywords:
Cattle identiﬁcation
Cattle detection
Machine learning
Deep learning
Cattle farming
Contents
1.
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
139
2.
Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
140
2.1.
Review process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
140
2.2.
Research questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
140
2.3.
Search strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
140
2.4.
Study selection criteria. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
140
2.5.
Data extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
3.
Cattle identiﬁcation overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
⁎ Corresponding author at: School of Computing, Mathematics and Engineering, Charles Sturt University, Panorama Ave, Bathurst, NSW 2795, Australia.
E-mail addresses: mdhossain@csu.edu.au (M.E. Hossain), akabir@csu.edu.au (M.A. Kabir), lzheng@csu.edu.au (L. Zheng), dave.swain@terracipher.com (D.L. Swain),
shmcgrath@csu.edu.au (S. McGrath), jmedway@csu.edu.au (J. Medway).
https://doi.org/10.1016/j.aiia.2022.09.002
2589-7217/© 2022 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NC-ND license (http://
creativecommons.org/licenses/by-nc-nd/4.0/).
Contents lists available at ScienceDirect
Artiﬁcial Intelligence in Agriculture
journal homepage: http://www.keaipublishing.com/en/journals/artificial-
intelligence-in-agriculture/
3.1.
Ear tag-based methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
3.2.
DNA-based methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
142
3.3.
Visual features-based methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
142
4.
Review reports
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
143
4.1.
Machine learning approaches for cattle identiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
143
4.2.
Deep learning approaches for cattle identiﬁcation and detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
4.3.
Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
4.4.
Feature extraction methods
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
148
4.5.
Evaluation metrics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
150
4.6.
Performance of the ML and DL models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
150
5.
Discussions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
151
5.1.
Challenges and future research directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
151
5.2.
Limitations of this study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
153
6.
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
153
Funding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
154
Declaration of Competing Interest
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
154
Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
154
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
154
1. Introduction
The demand for efﬁcient traceability and identiﬁcation systems for
livestock is growing due to biosecurity and food safety requirements
in the supply chain. The advanced technologies of machine learning
and computer vision have been applied in precision livestock manage-
ment, including critical disease detection, vaccination, production
management, tracking, health monitoring, and animal well-being mon-
itoring (Awad, 2016). ‘Cattle identiﬁcation’ refers to ‘cattle detection’
and ‘cattle recognition’ (Mahmud et al., 2021). Cattle identiﬁcation
systems start from manual identiﬁcation to automatic identiﬁcation
with the help of image processing. Traditional cattle identiﬁcation sys-
tems such as ear tagging (Awad, 2016), ear notching (Neary and
Yager, 2002), and electronic devices (Ruiz-Garcia and Lunadei, 2011)
have been used for individual identiﬁcation in cattle farming. Disadvan-
tages of these individual identiﬁcation methods include the possibility
of losses, duplication, electronic device malfunctions, and fraud of the
tag number (Rossing, 1999; Roberts, 2006). These are the issues and
challenges for cattle identiﬁcation in livestock farm management.
With the advent of computer-vision technology, cattle visual fea-
tures have gained popularity for cattle identiﬁcation (Kusakunniran
and Chaiviroonjaroen, 2018; Andrew et al., 2016, 2017; de Lima
Weber et al., 2020). Visual feature based cattle identiﬁcation systems
are used to detect and classify different breeds or individuals based on
a set of unique features. In recent years, machine learning (ML) and
deep learning (DL) approaches have been widely used for automatic
cattle identiﬁcation using visual features (Andrew et al., 2016;
Tharwat et al., 2014b; Andrew et al., 2019; Qiao et al., 2019; Li et al.,
2021a). ML and DL are subﬁelds of artiﬁcial intelligence that can solve
complex problems for automatic decision-making. ML is mainly divided
into two approaches, such as supervised learning and unsupervised
learning. The supervised ML approach is deﬁned by its use of labelled
datasets, whereas the unsupervised learning uses ML algorithms to an-
alyse and cluster unlabeled datasets. An unsupervised ML approach can
detect hidden patterns in data without human supervision (Janiesch
et al., 2021). DL approaches are useful in areas with large and high-
dimensional datasets. Thus, DL models are usually outperformed over
traditional ML models in the area of text, speech, image, video, and
audio data processing (LeCun et al., 2015). There are two main steps
in the development of ML and DL models. In the ﬁrst step, a training
dataset is used to train the model, and in the second, the model is vali-
dated using a separate validation dataset. Thus, a trained model is cre-
ated that is later used on the test dataset to determine its performance
based on the test dataset. The dataset used for ML models includes the
features and their corresponding outcomes or labels. The features are
extracted from the input data using a feature extraction method. DL al-
gorithms can automatically extract high-level features from the dataset
and learn from these features. Although the implementation of the ML
and DL models is straightforward, there are some challenges with
selecting algorithms, tuning parameters, and features for better predic-
tion accuracy (Janiesch et al., 2021).
Several important review studies have been completed in livestock
farm management. Some recent literature reviews have addressed var-
ious research challenges in livestock farming, such as identiﬁcation,
tracking, and health monitoring, using tag-based, ML, and DL ap-
proaches. Recently, Awad (2016) and Kumar and Singh (2020)
reviewed the literature on using different classical and visual biometrics
methods for cattle identiﬁcation and tracking. Li et al. (2021b) reviewed
the deep learning-based approaches for classiﬁcation, object detection
and segmentation, pose estimation, and tracking for different kinds of
animals such as cattle, pigs, sheep, and poultry. A systematic literature
review based on applying ML and DL approaches in precision livestock
farming by Garcia et al. (2020) focused on grazing and animal health.
Qiao et al. (2021) summarised the ML and DL approaches in precision
cattle farming for cattle identiﬁcation, body condition score evaluation,
and live weight estimation. They reviewed a small number of articles
(n = 13) related to cattle identiﬁcation using ML and DL approaches.
Mahmud et al. (2021) conducted a systematic literature review show-
ing the recent progress of DL applications for cattle identiﬁcation and
health monitoring. Their review included only a few articles related to
cattle identiﬁcation. Moreover, these review articles focused on the
combination of different types of challenges (e.g., tracking, pose estima-
tion, weight estimation, identiﬁcation, and detection) solved by tag-
based, ML, and DL methods in precision livestock farming. Thus, they
lack in providing a comprehensive review on cattle identiﬁcation.
Also, the existing review articles lack information on ML and DL applica-
tions combined for cattle identiﬁcation as they cover partly either ML or
DL for cattle identiﬁcation. Moreover, the details of the cattle dataset for
identiﬁcation are not discussed. In this context, an extensive systematic
literature review is needed, particularly for the challenge of cattle iden-
tiﬁcation addressed by ML and DL approaches. Also, the details of the
dataset used in the relevant articles need to be discussed, and the
current trend of using ML and DL techniques in cattle identiﬁcation
and future research opportunities with challenges need to be identiﬁed.
This systematic literature review (SLR) aims to summarise and
analyse the ML and DL applications used extensively in cattle identiﬁca-
tion. A total of 55 articles for cattle identiﬁcation and detection have
been selected for this SLR. The reviewed articles are ﬁrst summarised,
and then the datasets used in the selected articles are discussed. We
then analyse the reviewed articles for trends in using ML and DL
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
139
approaches for cattle identiﬁcation in recent years before presenting the
feature extraction methods and performance evaluation metrics
extracted from the reviewed articles. Finally, the challenges and future
research directions in this ﬁeld are discussed.
2. Methodology
2.1. Review process
The review process of an SLR is divided into three phases – planning,
conducting, and reporting the review (Kitchenham and Charters, 2007).
In the ﬁrst phase, the research questions for the SLR are identiﬁed. Based
on the research questions, the electronic databases and search terms or
keywords were determined. The search keywords are used to create a
search string that is applied to the different electronic databases to
extract the related articles for the SLR. This study used the IEEE Xplore,
Science Direct, Scopus, and Web of Science databases. These databases
were selected to cover a wide range of studies in our targeted sector
as they index most of the journals from various publishers such
as Springer, ACM, Inderscience, Elsevier, Sage, Taylor & Francis, IOS,
Wiley, and so on. In the second phase, the relevant research studies
are identiﬁed by searching the databases. After that, the selection
criteria are determined for the quality assessment of the primary stud-
ies. The eligible studies are selected by applying the selection criteria,
and then the relevant data are extracted from the selected articles
based on the research questions. In the ﬁnal phase, the extracted data
are analysed and used to address the research questions. Then, the re-
sults are reported in the form of tables and ﬁgures followed by a brief
discussion of research challenges and future research opportunities.
2.2. Research questions
This SLR focuses on published research studies into cattle identiﬁca-
tion using ML and DL approaches. The search process identiﬁes poten-
tial primary studies that address the research questions. The answers
to the research questions are discussed based on the data extracted
from the selected studies. This study deﬁned the following seven
research questions (RQs) for the SLR.
• RQ1: What ML models are used in cattle identiﬁcation?
• RQ2: What DL models are used in cattle identiﬁcation?
• RQ3: What datasets are used in cattle identiﬁcation?
• RQ4:
What
feature
extraction
methods
are
used
in
cattle
identiﬁcation?
• RQ5: What performance evaluation metrics are used for ML and DL
models in cattle identiﬁcation?
• RQ6: What are the best ML and DL models used in a speciﬁc cattle
identiﬁcation problem?
• RQ7: What are the challenges in solving cattle identiﬁcation
problems?
2.3. Search strategy
A search strategy is applied to keep the search results within the
scope of the SLR. In this study, the initial search was performed using
a string with four keywords. The search string was (“cattle” AND “iden-
tiﬁcation”) AND (“machine learning” OR “deep learning”). Some articles
were extracted from the search results, and the title, abstract, and
author-speciﬁed keywords were read to ﬁnd the synonyms for the
basic search keywords. For “cattle”, synonyms considered were “cow”
and “livestock”. For “identiﬁcation”, synonyms considered were “recog-
nition” and “detection”. The keywords “neural network”, “image pro-
cessing” and “vision” were added with “machine learning” and “deep
learning” as similar terms. Thus, the general search string was (“cattle”
OR “cow*” OR “livestock”) AND (“identiﬁcation” OR “recognition” OR
“detection”) AND (“machine learning” OR “deep learning” OR “neural
network” OR “image processing” OR “vision”). The search keywords
were used for articles in four databases (August 2021). The search
strings for the databases are shown in Table 1.
This study reduced some keywords from the search string for the
Science Direct database as the maximum Boolean connectors (AND/
OR) for this database is eight. Since the Scopus database yielded many
articles with the general search string, the search results were reduced
by putting two different keywords together. In this SLR, we did not
limit the publication year during the search. After performing the
above search strings, a total of 731 articles were retrieved.
2.4. Study selection criteria
The selection criteria are used to identify the studies that can answer
the research questions. In this study, inclusion and exclusion criteria
were deﬁned based on the research questions. The search results from
all databases were recorded on a spreadsheet for scrutiny using the in-
clusion and exclusion criteria. A study was selected for the SLR when the
inclusion criteria were true but the exclusion criteria were false. The ex-
clusion criteria were: (1) publication is not related to ML or DL for cattle
identiﬁcation, (2) publication is a survey or review paper, (3) publica-
tion is not written in English. The inclusion criteria were that the publi-
cation must be applied to either the ML and/or DL approaches for cattle
identiﬁcation.
After excluding duplicate records (n = 125), the selection criteria
were applied to the rest of the records (n = 606). Thus, a total of 54
full-text articles were assessed for eligibility. For selecting the ﬁnal arti-
cles, we considered articles that were published in the last ten years.
During the eligibility check and quality assessment, four more full-text
articles were excluded because they did not satisfy the quality criteria,
including not related to ML or DL for cattle identiﬁcation and published
more than ten years ago. The quality assessment was performed by
following the study of Kitchenham et al. (2009). Then, this study applied
backward and forward snowballing techniques (Wohlin, 2014) to
50 articles and found ﬁve more relevant articles. Thus, a total of 55
articles were ﬁnally selected for this SLR. A complete ﬂow of the article
selection process is shown in Fig. 1 using PRISMA. We also conducted
search in the Association for Computing Machinery (ACM), Springer,
Inderscience and some other publishers databases with the search
strings. The related articles found from the search results were duplicate
Table 1
Search strings for the selected databases.
Database
name
Search string
IEEE Xplore
((cattle OR cow* OR livestock) AND (identiﬁcation OR
recognition OR detection) AND (“deep learning” OR “machine
learning” OR “neural network” OR “image processing” OR
vision)) (anywhere).
Science Direct
(cattle OR cow) AND (identiﬁcation OR recognition OR
detection) AND (“deep learning” OR “machine learning” OR
“neural network” OR “image processing”). It was used to search
in the title, abstract and keywords.
Scopus
TITLE-ABS-KEY ((“cattle identiﬁcation” OR “cow* identiﬁcation”
OR “livestock identiﬁcation” OR “cattle recognition” OR “cow*
recognition” OR “livestock recognition” OR “cattle detection” OR
“cow* detection” OR “livestock detection”) AND (“deep learning”
OR “machine learning” OR “neural network” OR “image
processing” OR vision)). It was used to search in the title (TITLE),
abstract (ABS) and keywords (KEY).
Web of Science
AB=((cattle OR cow* OR livestock) AND (identiﬁcation OR
recognition OR detection) AND (“deep learning” OR “machine
learning” OR “neural network”)) OR AK=((cattle OR cow* OR
livestock) AND (identiﬁcation OR recognition OR detection) AND
“deep learning” OR“machine learning” OR “neural network”))
OR TI=((cattle OR cow* OR livestock) AND (identiﬁcation OR
recognition OR detection) AND (“deep learning” OR “machine
learning” OR “neural network”)). It was used to search in the title
(TI), abstract (AB) and author keywords (AK).
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
140
to our selected databases search. For this reason, we did not report them
in the PRISMA in details.
2.5. Data extraction
To address the research questions, each selected article was read in
full and the necessary data elements were extracted from it. A spread-
sheet was prepared to store all the extracted data for the selected
articles. The spreadsheet columns represent the different data elements
of the studies, and the rows represent the articles reviewed for the SLR.
In the spreadsheet, each article is summarised by research goal, dataset,
feature used, featured extraction, model, location, publishing year,
performance evaluation metrics and challenges. The extracted data are
then classiﬁed according to the research questions. The summarised
results of this SLR are reported in Section 4.
3. Cattle identiﬁcation overview
Cattle identiﬁcation is the process of recognising cattle using unique
identiﬁers or features (Awad, 2016). Accurate cattle identiﬁcation plays
an important role in allowing cattle farmers to implement individual
animal management techniques. Individual identiﬁcation also under-
pins genetic improvement, disease management, biosecurity, and sup-
ply chain management. Fig. 2 shows the three major types of cattle
identiﬁcation methods – ear tag-based methods, DNA-based methods,
and visual features-based methods.
3.1. Ear tag-based methods
Ear tag-based cattle identiﬁcation methods are widely used in live-
stock farm management (Ruiz-Garcia and Lunadei, 2011; Kumar et al.,
2016a). These methods can help to understand disease trajectories
and control the spread of acute diseases (Vlad et al., 2012; Wang et al.,
2010). Tag-based methods use unique identiﬁers, including permanent
markings (e.g., ear notching, tattooing, and branding), temporary mark-
ings (e.g., ear tagging), and electronic devices (e.g., radio frequency
identiﬁcation (RFID)) (Awad, 2016).
Ear notching is a system of removing portions of the ear or ears of an
animal so the removed portions create a distinct, recognisable shape
(Neary and Yager, 2002). A combination of the positions of the ear
Fig. 1. Article selection ﬂowchart for the systematic literature review.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
141
notches is used to identify individual cattle. Ear notching has potential
welfare implications, and other identiﬁcation methods are more welfare
friendly (Noonan et al., 1994). The ear notching method applies only to
a limited number of cattle on a farm. Thus, it is not used to identify indi-
vidual cattle on large-sized farms.
Ear tagging is a livestock identiﬁcation method (Awad, 2016) that is
widely used to provide individual cattle identiﬁcation. It is quick to im-
plement and features a low-cost identiﬁcation system. An ear tag can be
made of metal or plastic with bar codes, letters or numbers, and the tags
can vary in size and colour. But ear tags can fall out, resulting in lost in-
dividual identiﬁcation (Wang et al., 2010). In addition, ear tags risk
damage, can be duplicated, and are susceptible to fraudulent manipula-
tion. Lost tags do not allow for the long-term recognition of individual
animals (Fosgate et al., 2006). These limitations led to the development
of electronic identiﬁcation devices (EIDs).
Passive radio frequency identiﬁcation devices (RFID) are commonly
used for individual identiﬁcation and tracking in livestock farming (Ruiz-
Garcia and Lunadei, 2011). The architecture of the RFID device includes
an RFID tag, a communication channel, a tag reader, a server, and an
RFID back-end. These devices use radio waves to transmit livestock data
as a unique code made up of a sequence of numbers. However, skilled peo-
ple are needed to set up and manage the RFID system. Additionally, it has
some limitations in terms of security, including tag-content changes and a
high possibility of system spooﬁng (Roberts, 2006).
Although tag-based cattle identiﬁcation methods have wide accept-
ability, well-deﬁned research documents and long term utilisation, they
have some common problems with vulnerabilities, monitoring, disease
control, fraud, and cattle welfare concerns (Bowling et al., 2008; Huhtala
et al., 2007).
3.2. DNA-based methods
DNA-based cattle identiﬁcation methods have been developed to
identify individual cattle for the understanding of critical diseases,
production management, and health monitoring. However, these
methods are expensive in terms of both time and cost. DNA-based iden-
tiﬁcation methods are used for speciﬁc applications, such as determin-
ing genetic linkages for genetic improvement programs. Using DNA
for routine identiﬁcation is not cost effective as it is a very time-
consuming process to get unique DNA identiﬁers to identify individual
animals (Kumar and Singh, 2020). Gallinat et al. (2013) introduced a
DNA-based identiﬁcation model for bovine casein gene variants. This
study used four casein genes that were sequenced in a total of 319
animals.
3.3. Visual features-based methods
As the cattle identiﬁcation system follows pattern recognition, it re-
trieves the animal’s unique biometric and visual features to identify
them individually. The unique features for cattle identiﬁcation include
the muzzle print, face, body coat pattern, and iris pattern. The biometric
features-based approaches can offer an accurate and efﬁcient solution
for individual cattle identiﬁcation using traditional methods (e.g., SIFT,
pattern matching, and Euclidean distance), ML methods (e.g., SVM,
KNN, and ANN) and DL methods (e.g., CNN, ResNet, and Inception)
(Noviyanto and Arymurthy, 2013; Kumar et al., 2016b; Barry et al.,
2007; Arslan et al., 2014; Jaddoa et al., 2019; Andrew et al., 2016, 2017).
In the literature, muzzle print images have been widely used for cat-
tle identiﬁcation (Kusakunniran and Chaiviroonjaroen, 2018; Awad and
Hassaballah, 2019; Kumar et al., 2017a; Barry et al., 2007). Like human
ﬁngerprints, the muzzle print and nose print of cattle show distinct
grooves and beaded patterns. It has been recognised as a unique
biometric feature since 1921 (Petersen, 1922). Cattle muzzle print im-
ages can be captured using digital cameras, then feature extraction
methods (e.g., SIFT and SURF) are used to extract unique features for
identiﬁcation.
Iris and retinal biometric features have been used for individual cat-
tle identiﬁcation. The cattle retinal pattern remains unchanged over
Fig. 2. Different types of cattle identiﬁcation methods.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
142
time, and the iris contains some discriminating biometric features
(Allen et al., 2008; Lu et al., 2014). However, these methods have had
limited applications due to the difﬁculty of capturing livestock retinal
and iris images.
The body coat pattern and face are unique features for identifying in-
dividual cattle (Kumar and Singh, 2020). With the recent advent of ML
and DL methods, facial and body coat patterns have been widely used
for cattle identiﬁcation (Arslan et al., 2014; Andrew et al., 2016; Yang
et al., 2019). For the ML models, the features are extracted from the
face or body images and then fed into the models for identiﬁcation. DL
models have powerful feature extraction abilities for cattle identiﬁca-
tion without pre-specifying any features (Kumar et al., 2018a; Andrew
et al., 2017).
In recent times, automatic cattle identiﬁcation has gained popularity
among researchers using ML and DL methods. The traditional methods
cannot handle large datasets, and the accuracy of these methods is poor
relative to ML and DL methods (Kumar and Singh, 2020). In this SLR, ML
and DL based approaches for cattle identiﬁcation are considered for dis-
cussion as the other methods are out of scope in this study.
4. Review reports
In total, 55 papers were selected for this SLR after applying the selec-
tion criteria. The year-wise distribution of these papers is shown in
Fig. 3. The papers for cattle identiﬁcation are divided into two groups:
(1) ML based papers and (2) DL based papers. The ﬁgure indicates
that the number of published papers based on ML was higher than for
DL based papers before 2018. This result indicates that the application
of ML techniques dominated cattle identiﬁcation in livestock farm man-
agement before DL approaches began gaining in popularity. Based on
our survey report, the number of ML based papers for cattle identiﬁca-
tion published annually has been greater than the number of DL based
papers since 2018. In addition, the ﬁgure shows that the researchers
have emphasised DL models for cattle identiﬁcation in recent years.
This is mainly because of the higher accuracy of DL models on large
datasets (Mahmud et al., 2021)
The distribution of journals and conferences for the selected papers
is presented in Fig. 4. The ﬁgure indicates that IEEE Conferences, ACM
Conference Proceedings, and the Computer and Electronics in Agricul-
ture journal are the three top outlets that published the highest number
of automatic cattle identiﬁcation papers. The other three outlets,
Biosystems Engineering, Advances in Intelligent Systems and Comput-
ing, and Springer Conferences, published more than two papers in this
sector.
Fig. 5 shows a Sankey diagram for the country-wise overall summary
of the selected papers in terms of dataset types and approaches used in
cattle identiﬁcation. This SLR reports that China published the highest
number of papers (14) for cattle identiﬁcation, followed by Egypt (7),
India (6), and Japan (5). Most of the reviewed papers use image-based
datasets (40 times) for cattle identiﬁcation. Most of the video-based
datasets are used in DL based papers. As this study only considers ML
and DL based papers for the review, we have found 17 papers that use
ML models and 38 papers that use DL models for cattle identiﬁcation.
The papers are divided into three groups based on the study goal(s):
(i) only identiﬁcation (34), (ii) only detection (10), and (iii) both detec-
tion and identiﬁcation (11). The cattle identiﬁcation is the process of
identifying individual cattle using ML and DL approaches. In Fig. 5, it is
noticeable that all the ML based papers are only for identiﬁcation pur-
poses, as the classical ML algorithms are only used for classiﬁcation
problems. The cattle detection system allows us to detect the cattle for
individual identiﬁcation, monitoring, and counting. It can implemented
only by DL approaches.
In the following subsections we have addressed the research ques-
tions identiﬁed in Section 2.2.
4.1. Machine learning approaches for cattle identiﬁcation
Classical ML approaches perform well for cattle identiﬁcation in live-
stock farming. Table 2 presents a summary of the ML based papers. The
summary includes the best model, dataset, used feature, feature extrac-
tion method, and performance for automatic cattle identiﬁcation. In this
SLR, many ML based papers used more than one ML approach. In those
cases, the performance of the best model is reported in Table 2. Based on
our review, most of the ML based papers used the image dataset. The
images were used to form the training and testing dataset for cattle
identiﬁcation. About 70% of the papers used the cattle muzzle print as
a feature because of its unique patterns.
To address research question one (RQ1), ML models were analysed
and listed in Table 3. As shown in the table, the top three most used
ML models are SVM, KNN, and ANN. They are also the best models
found in the most reviewed studies as shown in Table 2. Fig. 6 provides
a timeline of the ML models used for the ﬁrst time for cattle identiﬁca-
tion as per the reviewed papers. The ﬁgure indicates that SVM and
KNN have been used since 2014 for cattle identiﬁcation. ML models
such as ANN and decision tree (DT) started to be used for cattle identi-
ﬁcation in 2017, whereas random forest (RF) and logistic regression
(LR) started in 2018. The most used classical ML algorithms are brieﬂy
explained below.
Fig. 3. Distribution of selected papers in terms of year.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
143
SVM (Joachims, 1998) is a widely used algorithm for cattle identiﬁ-
cation. It is a technique that uses a hyperplane to classify different
groups that separate the classes by maximising their marginal distance
in high dimensional feature space (Joachims, 1998). The marginal dis-
tance is the gap between the hyperplane and its nearest data points
for the two classes. The dataset follows the condition that each data
point belongs to only one of the two classes.
KNN (Cover and Hart, 1967) is a simple and older machine learning
classiﬁcation algorithm. In KNN classiﬁcation, the nearest neighbours
are the data samples with minimum distance between the feature space
and the new data sample. The ‘K’ is the number of closest neighbours
considered for voting to classify a new sample. A class label provided for
most ‘K’ nearest neighbours forms the training data and is deﬁned as
a predicted class for the new data sample. The different classiﬁcation
outcomes can generate different ‘K’ values for the same sample example.
ANNs (McCulloch and Pitts, 1943; Rumelhart et al., 1986) are
machine learning algorithms developed based on the function of
neural parts of the human brain. The neurons of the human brain are
connected using multiple axon junctions. Thus, they form a graph-like
architecture. The links among neurons help to receive, process, and
store information. Similarly, an ANN algorithm can be presented as a
network of interconnected nodes. According to the inter-connectivity,
one node’s output becomes the input of another node. A group of
nodes forms a matrix, which is called a layer. An ANN can be repre-
sented by input, output, and hidden layers. The nodes and their connec-
tions have a weight that is used to adjust the signal strength which can
be increased or decreased through repeated training. ANNs can classify
the test data based on the training and subsequent adjustment of
weights for nodes and their connections.
4.2. Deep learning approaches for cattle identiﬁcation and detection
In recent years, deep learning (DL) has been applied successfully
in livestock farm management. Various DL approaches have been
Fig. 4. Distribution of journals and conferences for the selected papers related to cattle identiﬁcation (published 2014–2021).
Fig. 5. Country-wise summary of selected papers in terms of model, dataset type and task.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
144
proposed in this sector for different applications, including animal iden-
tiﬁcation, detection, tracking, and health monitoring. Over the last few
years, DL approaches have been widely used in research related to cattle
identiﬁcation and detection. Table 4 presents a summary of the papers
related to DL. The papers are divided into three groups: identiﬁcation
and detection, identiﬁcation only, and detection only. The groups are
generated after analysing the extracted information from the reviewed
papers according to the study goal. The goal of the papers from the iden-
tiﬁcation and detection category is to ﬁrst detect the cattle using DL de-
tection models and then classify the individual cattle using DL
classiﬁcation models. The only identiﬁcation-related papers proposed
automatic individual cattle identiﬁcation systems using DL approaches.
The only detection category papers developed cattle detection systems
using DL detection algorithms. Table 4 includes the dataset attributes,
used features, feature extraction method, DL models for detection and
identiﬁcation, and performance of the models. It is observed that
many DL based papers use cattle images as a dataset that is divided
into training and testing sets. Based on our survey data, the cattle
images for the head, muzzle print, and full body in terms of top and
side view are widely used for detection and identiﬁcation systems.
Most of the DL based studies use the cattle body coat pattern as a feature
because DL approaches have powerful feature extraction and image
representation abilities.
To address the second research question (RQ2), we explored and
summarised DL detection and identiﬁcation models. Table 5 shows a list
of DL models used in the DL based papers for cattle identiﬁcation. The
top three identiﬁcation models are the convolutional neural network
(CNN), residual network (ResNet) and Inception models. Cattle detection
models are listed in Table 6. You Only Look Once (YOLO) and Faster
R-CNN are the top two detection models used in the reviewed papers.
In Fig. 7, we have created a matrix plot that shows the combination of de-
tection and identiﬁcation models used for cattle identiﬁcation. The result
shows that the YOLO detection model is used the most with the CNN
identiﬁcation model. It is also observed that ResNet and VGG are used as
Table 2
Performance of ML models used in cattle identiﬁcation research papers.
Reference
Best model
Dataset
Used feature
Feature extraction method
Best performance (%)
Breed
Size
Split (Train,Val,Test)
(Kusakunniran and Chaiviroonjaroen, 2018)
SVM
NC
217 images
186, –, 31
Muzzle
LBP
100 (A)
(Andrew et al., 2016)
SVM
H
377 images
83, –, 294
Body
ASIFT
97 (A)
(Schilling et al., 2018)
SVM
NC
302 images
150, –, 152
Mammary glands|
LBP
60 (A)
(Li et al., 2017)
QDA
H
1965 images
1667, 298, –
Tailhead
Zernike moments
99.7 (A)
(Awad and Hassaballah, 2019)
SVM
NC
105 images
75, 15, 15
Muzzle
SURF
93 (A)
(Zhao et al., 2019)
FLANN
H
528 videos
198, –, 330
Body
FAST
96.72 (A)
(Kumar et al., 2018b)
GSRC
M
5000 images
3000, –, 2000
Muzzle
LBP
93.87 (A)
(Lv et al., 2018)
BruteForce
H
1500 images
900, –, 600
Body
SIFT
98.33 (A)
(Kumar and Singh, 2017)
ANN
M
5000 images
3000, –, 2000
Muzzle
LBP
96.74 (A)
(Kumar et al., 2017a)
KNN
M
5000 images
3000, –, 2000
Muzzle
SURF
93.87 (A)
(Kumar et al., 2017b)
SVM
M
5000 images
3000, –, 2000
Muzzle
FLPP
96.87 (A)
(Gaber et al., 2016)
AdaBoost
NC
217 images
186, –, 31
Muzzle
WLD
98.9 (A)
(Zaoralek et al., 2016)
SVM
NC
322 images
–, –, –
Muzzle
SVD
75 (F)
(Ahmed et al., 2015)
SVM
NC
217 images
186, –, 31
Muzzle
SURF
100 (A)
(Tharwat et al., 2014a)
SVM
NC
217 images
186, –, 31
Muzzle
Gabor ﬁlter
99.5 (A)
(Tharwat et al., 2014b)
SVM
NC
217 images
186, –, 31
Muzzle
LBP
99.5 (A)
(El-Henawy et al., 2017)
ANN
NC
1060 images
636, 212, 212
Muzzle
Box-counting
99.18 (A)
NC=Non-classiﬁed, H=Holstein, M=Multiple (Ongole, Punganur, Holstein, Cross and Balinese).
A=Accuracy, F=F1 score.
QDA=Quadratic discriminant analysis, FLANN=Fast library for approximate nearest neighbors.
GSRC= Group sparsity residual constraint, FLPP=Fuzzy linear preserving projections, WLD=Weber’s native descriptor.
Table 3
Traditional machine learning models used in cattle identiﬁcation.
ML model
Paper reference
Count
SVM
(Kusakunniran and Chaiviroonjaroen, 2018; Andrew
et al., 2016; Schilling et al., 2018; Li et al., 2017; Awad
and Hassaballah, 2019; Kumar et al., 2017b; Zaoralek
et al., 2016); Ahmed et al., 2015; Tharwat et al., 2014a,
2014b; Hu et al., 2020; Kumar et al., 2018a; Achour
et al., 2020)
13
KNN
(Schilling et al., 2018; Kumar and Singh, 2017; Kumar
et al., 2017a; Gaber et al., 2016; Tharwat et al., 2014b;
Andrew et al., 2021)
6
ANN
(Li et al., 2017; Zhao et al., 2019; Kumar and Singh,
2017; El-Henawy et al., 2017)
4
DT
(Schilling et al., 2018; Kumar and Singh, 2017)
2
LDA
(Li et al., 2017; Zaoralek et al., 2016)
2
BruteForce
(Zhao et al., 2019; Lv et al., 2018)
2
Naive Bayes
(Kumar and Singh, 2017; Tharwat et al., 2014b)
2
SRC
(Kumar et al., 2018b)
1
RF
(Schilling et al., 2018)
1
LR
(Schilling et al., 2018)
1
QDA
(Li et al., 2017)
1
AdaBoost
(Gaber et al., 2016)
1
Trucket
decomposition
(Zaoralek et al., 2016)
1
DT = Decision tree, LDA = Linear discriminant analysis, SRC = Sparsity residual
constraint.
RF = Random forest, LR = Logistic regression.
Fig. 6. Timeline of the ML models used for the ﬁrst time in the selected papers.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
145
Table 4
Performance of DL models used in cattle identiﬁcation.
Task
Reference
Dataset
Used
feature
Feature
extraction
Best detection
Best identiﬁcation
Breed
Size
Split
(Train,Val,Test)
Model
Performance
(%)
Model
Performance
(%)
Detection and identiﬁcation
(Chen et al., 2021)
An
5042 images
2521, –, 2521
Face & body
–
Mask R-CNN
–
VGG16
85.4 (A)
(Zin et al., 2020)
NC
6000 images
–, –, –
Head
–
YOLO
96 (A)
CNN
84 (A)
(Andrew et al., 2019)
H
32 videos
14, –, 18
Body
Inception v3, LSTM
YOLO v2
92.4 (A)
LRCN
93.6 (A)
(Andrew et al., 2017)
H
940 images 1064 videos
–, –, – 957, –, 107
Dorsal coat
VGG-M 2024, LSTM
R-CNN
99.3 (mAP) –
R-CNN LRCN
96.03 (mAP) 98.13 (A)
(Tassinari et al., 2021)
H
11,754 frames
10,105, 1649, –
Body
–
YOLO v3
66 (P)
DarkNet
73 (F)
(Hu et al., 2020)
H
958 images
593, –, 365
Body
Multi CNN
YOLO
–
SVM
98.36 (A)
(Achour et al., 2020)
H
4875 images
2931, –, 1944
Head
CNN
Xception
–
Multi CNN
97.06 (A)
(Andrew et al., 2021)
H
4736 images
1895, 473, 2368
body
ResNet
YOLO v3
98.4 (mAP)
KNN
93.75 (A)
(Shen et al., 2020)
H
1433 images
1015, 418, –
Body
–
YOLO
–
AlexNet
96.65 (A)
(Guan et al., 2020)
NC
1650 images
1100, 550, –
Face & body
–
ReﬁneDet
87.4 (A)
CNN
80 (A)
(Yao et al., 2019)
NC
18,231 images
14,585, –, 3646
Face
ResNet101
Faster R-CNN
99.6 (A)
PnasNet-5
94.7 (A)
Only identiﬁcation
(Phyo et al., 2018)
NC
13,603 frames
9064, –, 4539
Body
Skew histogram
–
–
3D-CNN
96.3 (A)
(Qiao et al., 2020)
NC
363 videos
288, –, 75
Body
BiLSTM
–
–
Custom
91 (A)
(Manoj et al., 2021)
NC
150 images
–, –, –
Body
SIFT
–
–
CNN
–
(Bergamini et al., 2018)
NC
17,802 images
12,952, 4289, 561
Body
CNN
–
–
3D-CNN
89.1 (A)
(Yukun et al., 2019)
H
3430 images
2400, –, 1030
Body
CNN
–
–
DenseNet
98.5 (A)
(Santoni et al., 2015)
M
775 images
620, –, 155
Body
GLCM
–
–
CNN and LeNet-5
98.92 (A)
(Kumar et al., 2018a)
NC
5000 images
4000, –, 1000
Muzzle
CNN
–
–
DBN
98.99 (A)
(Qiao et al., 2019)
NC
516 videos
439, –, 77
Body
LSTM
–
–
Custom
91 (A)
(de Lima Weber et al., 2020)
P
27,849 images
25,085, –, 2764
Body
CNN
–
–
DenseNet201
99.86 (A) (A)
(Wang et al., 2020b)
H
2880 activity
2304, 576, –
Activity
Min & Max
–
–
DNN
93.81 (A)
(Bello et al., 2020b)
NC
4000 images
3000, –, 1000
Nose
CNN
–
–
DBN
98.99 (A)
(Bello et al., 2020a)
NC
1000 images
400, –, 600
Body
CNN
–
–
SDAE
89.95 (A)
(Yang et al., 2019)
H
85,200 images
82,010, –, 3190
Face
CNN
–
–
CNN and ResNet50
94.92 (A)
(Zin et al., 2018)
H
22 videos
–, –, –
Body
–
–
–
3D-CNN
97.01 (A)
(Li et al., 2018)
NC
21,600 images
19,440,–, 2160
Body
CNN
–
–
Inception v3
98 (A)
(Bhole et al., 2019)
H
1237 images
–, –, –
Body
CNN
–
–
AlexNet
97.5 (A)
(Wang et al., 2020a)
S
187 images
65, –, 122
Face
CNN
–
–
VGG16
93 (A)
Only detection
(Xu et al., 2020)
NC
750 images
500, –, 250
Body
CNN
Mask R-CNN
94 (A)
–
–
(Wang et al., 2020c)
NC
1323 images
926, –, 397
Face
–
BaseNet
95 (P)
–
–
(Barbedo et al., 2020)
NC
15,410 images
12,328, –, 3082
Body
–
Xception
87 (A)
–
–
(Zuo et al., 2020)
NC
3139 images
2825, –, 314
Body
–
MultiResUNet
95.37 (A)
–
–
(Shao et al., 2020)
NC
656 images
245, –, 411
Body
–
YOLO v2
95.7 (P)
–
–
(Han et al., 2019)
NC
43 images
36, –, 7
Body
–
Faster R-CNN
89.1 (P)
–
–
(Rivas et al., 2018)
NC
13,520 images
10,816, –, 2704
Body
–
CNN
95.5 (A)
–
–
(Barbedo et al., 2019)
C
17,258 images
13,806, –, 3452
Body
CNN
NasNet large
99.2 (A)
–
–
(Lin et al., 2019)
NC
1000 images
–, –, –
Body
SURF
Fast R-CNN
96.9 (A)
–
–
(Aburasain et al., 2020)
NC
300 images
270, –, 30
Body
–
YOLO v3
100 (P)
–
–
NC = Non-classiﬁed, An = Angus, H = Holstein, P = Pantaneira, M = Multiple (Ongole, Punganur, Holstein, Cross and Balinese), S = Simmental, C = Canchim.
A = Accuracy, F = F1 score, P = Precision, mAP = Mean average precision.
LSTM = Long short-term memory, BiLSTM = Bidirectional long short-term memory, DNN = Deep neural network, DBN = Deep belief network.
SDAE = Stacked denoising autoencoder, GLCM= Gray level co-occurrence matrices.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
146
identiﬁcation models where they are combined with three different de-
tection models (i.e., YOLO, Faster R-CNN and Mask R-CNN). Fig. 8 shows
a timeline of the DL identiﬁcation and detection models that were used
for the ﬁrst time for cattle identiﬁcation in the reviewed papers. It is ob-
served that DL based classiﬁcation models were ﬁrst used for cattle iden-
tiﬁcation in 2015, whereas the detection models were used from 2019.
Based on our survey, CNN and LeNet are the ﬁrst DL models used for cattle
identiﬁcation, as they are the oldest models in DL techniques. Short
descriptions of the frequently used DL models are given below.
CNN (Alzubaidi et al., 2021) is one of the most popular models in the
ﬁeld of DL. It is a widely used model for cattle identiﬁcation, perhaps be-
cause it is the oldest DL model. Another explanation could be that the
CNN model is simpler to explain and apply than the other DL models.
The CNN architecture comprises three layers: convolutional, pooling,
and fully connected layers. Convolutional layers are the signiﬁcant
parts of the CNN model. They consist of convolutional ﬁlters (or kernels)
and feature maps. Each ﬁlter has weighted inputs, and they are
convolved with the input volume to create a feature map. Each
convolutional ﬁlter can create one feature map (Brownlee, 2019). The
function of the pooling layer is to shrink the larger feature maps into
smaller feature maps. It is also used to reduce overﬁtting. Fully
connected layers are placed at the end of the CNN model and are used
as the CNN classiﬁer. Thus, the output of the fully connected layers rep-
resents the ﬁnal model output.
ResNet (He et al., 2016) is one of the most used DL models in cattle
identiﬁcation (see Table 5). It was developed to solve the vanishing and
exploding gradients problem. During the training time of the deep neural
network (DNN) with back-propagation, the hidden layers and derivatives
are multiplied by each other. The vanishing gradients problem occurs
when the gradients rapidly decrease or even vanish due to the smaller
value of derivatives. The exploding gradients problem occurs when the
gradients rapidly increase due to the larger value of derivatives. To
avoid the vanishing and exploding gradients problem, ResNet uses the
skip connections technique to skip one or more layers and connect
them to the output layer. The DL network can learn from residual map-
ping instead of underline mapping using the skip connections technique.
The Inception model (Szegedy et al., 2015) is a state-of-the-art DL
model used for classiﬁcation and detection problems. In cattle farm
management, it has been widely used for cattle identiﬁcation and detec-
tion. An inception network is a combination of repeating components
referred to as inception modules. Each module consists of the input
layer, a 1 ×1 convolution layer, a 3 × 3 convolution layer, a 5 × 5 convo-
lution layer, a max pooling layer, and concatenation layer. The 1 × 1 con-
volution layer reduces the input dimensions, and it can learn patterns
across the input depth. The 3 × 3 and 5 × 5 convolution layers can
learn patterns across all input dimensions. The max pooling layer re-
duces the input dimensions to create a smaller output. The outputs of
the convolution layer and the max pooling layer are concatenated in
the concatenation layer.
This SLR found that YOLO (Redmon et al., 2016) is the most used de-
tection algorithm for cattle detection problems. It is a popular and well-
performing object detection model. The YOLO algorithm follows the re-
gression model, and it predicts classes and bounding boxes for the full
object in one run of the algorithm. It has several versions, including
YOLO, YOLO-V2, and YOLO-V3. The localisation accuracy was improved
in YOLO-V2 by adding batch normalisation to the convolutional layers.
Additionally, it increased the image resolution and used anchor boxes
to predict bounding boxes (Redmon and Farhadi, 2017). In YOLO-V3
(Redmon and Farhadi, 2018), the authors increased the convolutional
layers to 106 and built residual blocks and applied the skip connections
technique to improve the object detection performance.
The region-based CNN (R-CNN) (Girshick et al., 2014) is another
powerful object detection model that is part of the family of CNN
models. R-CNN has improved versions named Fast R-CNN, Faster R-
CNN and Mask R-CNN. Faster R-CNN consists of two modules (Ren
et al., 2015). The ﬁrst module, called a fully convolutional network, pro-
poses regions, whereas the second module, named the Fast-RCNN de-
tector, uses the proposed regions. These two modules together form a
single and uniﬁed DL network for object detection. This study found
that the Faster-RCNN is one of the most used detection algorithms for
cattle detection.
4.3. Datasets
A dataset plays an important role in achieving the best performance
in any study. To address the third research question (RQ3), we have
summarised the cattle datasets used in the reviewed articles as shown
in Table 7. The datasets are summarised in terms of several factors, in-
cluding breed, the number of cattle, data type and size, image resolu-
tion, capture location, and acquisition device. The table indicates that
many reviewed papers used the dataset for the Holstein cattle breed.
This is mainly because of the unique coat patterns and patches on Hol-
stein cattle bodies. The cattle coat patterns are unique features in the
ML and DL approaches for identiﬁcation. Our SLR reported that the
most used dataset type was the image-based dataset (40 times),
which included different data acquisition systems such as RGB (red,
green, and blue), grey, and near-infrared (NIR) images. The images
Table 5
Deep learning models used in cattle identiﬁcation.
Identiﬁcation
model
Paper reference
Count
CNN
(Zin et al., 2020; Manoj et al., 2021; Santoni et al., 2015;
Achour et al., 2020; Guan et al., 2020; Bello et al., 2020b;
Yang et al., 2019)
7
ResNet
(Chen et al., 2021; de Lima Weber et al., 2020; Shen et al.,
2020; Yao et al., 2019; Yang et al., 2019; Barbedo et al.,
2019)
6
Inception
(de Lima Weber et al., 2020; Zuo et al., 2020; Han et al.,
2019; Li et al., 2018; Barbedo et al., 2019)
5
VGG
(Chen et al., 2021; Shen et al., 2020; Yao et al., 2019;
Barbedo et al., 2019; Wang et al., 2020a)
5
DenseNet
(Yukun et al., 2019; de Lima Weber et al., 2020; Shen
et al., 2020; Barbedo et al., 2019)
4
DCNN
(Phyo et al., 2018; Bergamini et al., 2018; Zin et al., 2018)
3
AlexNet
(Shen et al., 2020; Yao et al., 2019; Bhole et al., 2019)
3
DBN
(Kumar et al., 2018a; Bello et al., 2020b, 2020a)
3
SDAE
(Kumar et al., 2018a; Bello et al., 2020b; Han et al., 2019)
3
LRCN
(Andrew et al., 2019, 2017)
2
NasNet
(Yao et al., 2019; Barbedo et al., 2019)
2
LeNet
(Santoni et al., 2015; Yao et al., 2019)
2
PrimNet
(Chen et al., 2021)
1
R-CNN
(Andrew et al., 2017)
1
DarkNet
(Tassinari et al., 2021)
1
DNN
(Wang et al., 2020b)
1
LRCN = Long-term recurrent convolutional network.
Table 6
Deep learning detection models used in cattle identiﬁcation.
Detection
model
Paper reference
Count
YOLO
(Zin et al., 2020; Andrew et al., 2019; Tassinari et al.,
2021; Hu et al., 2020; Andrew et al., 2021; Shen et al.,
2020; Shao et al., 2020; Han et al., 2019; Aburasain et al.,
2020)
9
Faster R-CNN
(Andrew et al., 2021; Han et al., 2019; Yao et al., 2019)
3
Mask R-CNN
(Chen et al., 2021; Xu et al., 2020)
2
Xception
(Achour et al., 2020; Barbedo et al., 2020)
2
R-CNN
(Andrew et al., 2017)
1
RETINANET
(Andrew et al., 2021)
1
BaseNet
(Wang et al., 2020c)
1
ReﬁneDet
(Guan et al., 2020)
1
Fast R-CNN
(Lin et al., 2019)
1
SSD
(Aburasain et al., 2020)
1
SSD = Single-shot detector.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
147
were captured from different positions of the cattle, including the side,
top, rear, and front. A total of 15 studies used a video-based dataset. Of
these, most of the data were collected using a digital camera. A few
studies used unmanned aerial vehicles (UAVs)/drones as data acquisi-
tion devices. The cattle images or videos were captured from the cattle
farm (indoor or outdoor), and then processed to develop a decision-
making system using ML or DL for cattle identiﬁcation. In the reviewed
articles, different image resolutions are found in the datasets. Image res-
olution indicates the number of pixels in an image. A high resolution
(i.e., a higher number of pixels) ensures the higher quality of cattle im-
ages, although it requires more storage space due to the large ﬁle size. It
should be noted that high-resolution images are not necessary for the
highest accuracy. Most of the reviewed studies used lower resolution
(i.e., a lower number of pixels) cattle images as inputs to the ML or DL
models and achieved good results for cattle identiﬁcation.
4.4. Feature extraction methods
A cattle identiﬁcation dataset stores the cattle images or frames cap-
tured from videos. For individual cattle identiﬁcation, the features of the
cattle images are extracted using feature extraction methods and stored
in the feature dataset along with a speciﬁc cattle number. The features
are then fed into a DL or ML model for training and testing.
To address the fourth research question (RQ4), feature extraction
methods are investigated and summarised. Table 8 shows the list of dif-
ferent feature extraction methods used in the ML and DL models for cat-
tle identiﬁcation. The top ﬁve most used feature extraction methods are
CNN, local binary pattern (LBP), speeded up robust features (SURF),
scale-invariant feature transform (SIFT), and Inception. The other feature
extraction methods are LSTM, VGG, FAST, HOG, ORB, and LTE. Short de-
scriptions of the most used feature extraction methods are given below.
LBP is a feature extraction method used in the ML approaches
(Schilling et al., 2018; Zhao et al., 2019). It is a texture spectrum
model that assigns a binary value to each pixel in the image using the
threshold of the nearest pixels around it. When the value of the nearest
pixel is equal to or higher than the threshold value, it is set to 1. Other-
wise, the LBP value of that pixel is set to 0. After assigning the binary
values to all pixels, they are converted into decimal numbers.
SIFT is a popular and widely used algorithm to detect local features.
The algorithm seeks features by looking at interesting points in an
image as well as descriptors related to scale and orientation. Thus, it
achieves good outcomes in matching image feature points (Lowe,
1999).
SURF is another powerful algorithm to detect and describe local fea-
ture points of an image (Bay et al., 2006). Like SIFT, it performs three
tasks, including the extraction of feature points, descriptions of feature
Fig. 7. Combination of detection and identiﬁcation models used for cattle identiﬁcation.
Fig. 8. Timeline of when use of the DL identiﬁcation and detection models were ﬁrst reported to the selected papers. Blue: Identiﬁcation model, green: detection model and orange:
detection and identiﬁcation model.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
148
Table 7
Datasets used in the literature.
Reference
Breed
# of
animals
Type
Data
size
Resolution
Capture
location
Acquisition
device
Location
Link
(Kusakunniran and Chaiviroonjaroen, 2018;
Gaber et al., 2016; Ahmed et al., 2015;
Tharwat et al., 2014a, 2014b)
NC
31
Image (M)
217
300 × 400
–
Camera
Egypt
–
(Andrew et al., 2016)
H
50
Image (B)
377
–
Indoor
Kinect 2
UK
1
(Schilling et al., 2018)
NC
151
Image (M.G)
302
3840 ×
2160
Indoor
Camera
US
–
(Li et al., 2017)
H
10
Image (T)
1965
1920 ×
1080
Indoor
DS-2CD2T32(D)-I3
China
–
(Awad and Hassaballah, 2019)
NC
15
Image (M)
105
–
–
Camera
Egypt
–
(Zhao et al., 2019)
H
66
Video (B)
528
1280 ×
720
Outdoor
Nikon D5200
US
–
(Kumar et al., 2018b; Kumar and Singh, 2017;
Kumar et al., 2017a, 2017b, 2018a)
M
500
Image (M)
5,000
500 × 500
Indoor
Camera
India
–
(Lv et al., 2018)
H
60
Video (B)
1500
images
1280 ×
720
Outdoor
Camera
China
–
(Zaoralek et al., 2016)
NC
46
Image (M)
322
300 × 400
–
Camera
CZ
–
(El-Henawy et al., 2017)
NC
53
Image (M)
1060
–
–
Camera
Egypt
–
(Chen et al., 2021)
An
216
Image (F & B)
5042
–
Outdoor
Camera
US
–
(Zin et al., 2020)
NC
–
video (He)
6000
images
–
Indoor
AXIS P1448-LE
Japan
–
(Phyo et al., 2018)
NC
60
Video (B)
13,603
images
–
Indoor
Camera
Japan
–
(Qiao et al., 2020)
NC
50
Video (B)
36
401 × 506
Indoor
ZED camera
Australia
–
(Andrew et al., 2019)
H
17
Video (B)
32
720 × 720
Outdoor
DJI Matrice drone
UK
–
(Andrew et al., 2017)
H
112
Image (B)
940
–
Indoor
Kinect 2
UK
2
Video (B)
1064 videos
3840 ×
2160
Outdoor
DJI Inspire drone
(Manoj et al., 2021)
NC
26
Image (B)
150
640 × 480
Outdoor
Camera
India
–
(Bergamini et al., 2018)
NC
439
Image (B)
17,802
–
Indoor
Camera
Italy
–
(Xu et al., 2020)
NC
–
Video (B)
750 images
512 × 512
Outdoor
MAVIC Pro drone
Australia
–
(Yukun et al., 2019)
H
686
Back image (B)
3430
–
Indoor
Camera
China
–
(Santoni et al., 2015)
M
5
Image (B)
775
–
Outdoor
Camera
Indonesia
–
(Tassinari et al., 2021)
H
4
Video (B)
11,745
frames
–
Indoor
HDR-CX115E
Italy
–
(Hu et al., 2020)
H
93
Side-view image
(B)
958
640 × 480
Indoor
ASUS Xtion2
China
–
(Achour et al., 2020)
H
17
Top-view image
(He)
4875
640 × 480
Indoor
Yudanny Webcam
Algeria
–
(Qiao et al., 2019)
NC
41
Rear-view video
(B)
516
401 × 506
Indoor
ZED camera
Australia
–
(de Lima Weber et al., 2020)
P
51
Video (B)
212
–
Outdoor
Video Recorder
Brazil
–
(Andrew et al., 2021)
H
46
Top-view image
(B)
4736
–
Indoor &
Outdoor
DJI Inspire MkI,
Kinect 2
UK
3
(Wang et al., 2020c)
NC
–
Image (F)
1323
–
Indoor
Camera
China
–
(Barbedo et al., 2020)
NC
–
Image (B)
15,410
–
Outdoor
DJIMavic 2 Pro
Brazil
–
(Wang et al., 2020b)
H
5
Activity (B)
14,400
–
Outdoor
–
China
–
(Zuo et al., 2020)
NC
–
Image (B)
3139
3000 ×
4000
Outdoor
Quadcopter
China
4
(Shen et al., 2020)
H
105
Side-view image
(B)
1433
640 × 480
Indoor
ASUS Xtion2
China
–
(Guan et al., 2020)
NC
–
Video (F & B)
1650
frames
–
Indoor
Camera
Japan
–
(Shao et al., 2020)
NC
212
Image (B)
656
2122 ×
2122
Outdoor
DJI Phantom drone
Japan
–
(Bello et al., 2020b)
NC
400
Image (M)
4000
–
Indoor
Camera
Nigeria
–
(Bello et al., 2020a)
NC
10
species
Side-view image
(B)
1000
–
Outdoor
CCD camera
Nigeria
–
(Han et al., 2019)
NC
–
Image (B)
43
4000 ×
4000
Outdoor
Quadcopter
China
4
(Yao et al., 2019)
NC
200
Image (F)
18,231
–
Indoor
Camera
China
–
(Yang et al., 2019)
H
1000
Image (F)
85,200
–
Indoor
Camera
China
–
(Rivas et al., 2018)
NC
–
Image (B)
13,520
–
Outdoor
Multirotors drone
Spain
–
(Zin et al., 2018)
H
45
Video (B)
15
840 × 400
Indoor
Camera
Japan
–
(Li et al., 2018)
NC
30
Video (B)
21,600
–
Outdoor
Camera
China
–
(Barbedo et al., 2019)
C
–
Image (B)
1853
–
Outdoor
JI Phantom 4 Pro
Brazil
–
(Bhole et al., 2019)
H
136
Image (B)
1237
640 × 480
Indoor
FLIR E6
Netherlands
–
(Wang et al., 2020a)
S
36
Video (F)
187 Images
–
Indoor
Camera
China
–
(Lin et al., 2019)
NC
–
Image (B)
1000
866 × 652
Outdoor
Camera
China
–
(Aburasain et al., 2020)
NC
–
Image (B)
300
608 × 608
Outdoor
Drone
UAE
–
Breed: NC = Non-classiﬁed, An = Angus, H = Holstein, P = Pantaneira, M = Multiple, S = Simmental, C = Canchim.
Type: M = Muzzle, B = Body, T = Tailhead, M.G = Mammary glands, F = Face, He = Head.
Location: UK = United Kingdom, US = United States, UAE = United Arab Emirates, CZ = Czech Republic.
1FriesianCattle2015 Dataset – http://data.bris.ac.uk.
2FriesianCattle2017 and AerialCattle2017 Dataset – http://data.bris.ac.uk.
3OpenCows2020 Dataset – http://data.bris.ac.uk.
4https://github.com/hanl2010/Aerial-livestock-dataset/releases.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
149
points, and matching feature points. However, the SURF algorithm was
later updated for high-performance efﬁciency (Bay et al., 2008).
Fig. 9 presents a matrix plot considering the combination of feature
extraction methods and ML models used for cattle identiﬁcation. The re-
sults show that SVM is mainly used with the CNN, LBP, and SURF feature
extraction methods for cattle identiﬁcation, whereas the KNN and DT
classiﬁers are mainly used with the LBP feature extraction methods. It
is also observed that the LBP feature extraction method is used with al-
most all the ML models for cattle identiﬁcation. This is mainly because of
its powerful texture feature extraction capability from images in pattern
recognition systems.
CNN and Inception have been widely used in cattle precision farm-
ing. They are used as both classiﬁers and feature extractors. The DL ar-
chitecture without its last layer (i.e., classiﬁer) is called a feature
extractor. The CNN and Inception models excluding all dense layers
are performed as feature extractors. Fig. 10 shows the combination of
feature extraction methods and DL models used for cattle identiﬁcation
in the reviewed studies. It indicates that DenseNet, ResNet and Incep-
tion as DL classiﬁers have mainly been used with CNN as feature extrac-
tion methods for cattle identiﬁcation.
4.5. Evaluation metrics
Different metrics have been used for evaluating the performance of
models. To address the ﬁfth research question (RQ5), evaluation metrics
are investigated and identiﬁed. Nine evaluation metrics were used for cat-
tle identiﬁcation in the reviewed studies – accuracy, recall, F1 score, pre-
cision, mAP, speciﬁcity, the area under the ROC curve (AUC), equal error
rate, and Kappa, as shown in Fig. 11. Accuracy is deﬁned as the percentage
of correctly predicted instances and was the most used evaluation metric
in ML and DL based studies (17 times for ML and 31 times for DL) for cat-
tle identiﬁcation. The next most used evaluation metrics were recall, F1
score, and precision. Although 85% of the reviewed papers used accuracy
as the evaluation metric, the recall, F1 score, precision, mAP, and speciﬁc-
ity would be best to understand the identiﬁcation outcomes because
these metrics are considered true positive, false positive, true negative,
and false negative for evaluating model performance. It is observed that
accuracy is the best evaluation metric for individual cattle identiﬁcation
using ML and DL models. It is also noteworthy that mAP and precision
are mainly used in DL-based articles as they are appropriate for measuring
the DL model accuracy for identiﬁcation and detection (Zou et al., 2019).
4.6. Performance of the ML and DL models
To address the sixth research question (RQ6), the best perfor-
mance of each model used in the reviewed papers was identiﬁed
and summarised. Some models are used in many studies. This SLR re-
ported the best one in terms of evaluation metrics. Fig. 12 shows the
Table 8
Feature extraction (FE) methods used with ML and DL in cattle identiﬁcation.
FE method
Paper reference
Count
CNN
(Bergamini et al., 2018) (Xu et al., 2020) (Yukun
et al., 2019) (Hu et al., 2020) (Kumar et al., 2018a)
(Achour et al., 2020) (de Lima Weber et al., 2020)
(Bello et al., 2020b) (Bello et al., 2020a) (Rivas et al.,
2018) (Li et al., 2018) (Barbedo et al., 2019) (Bhole
et al., 2019) (Wang et al., 2020a) (Tharwat et al.,
2014a)
15
LBP
(Kusakunniran and Chaiviroonjaroen, 2018)
(Schilling et al., 2018) (Kumar et al., 2018b) (Kumar
and Singh, 2017) (Kumar et al., 2017a) (Tharwat
et al., 2014b)
6
SURF
(Awad and Hassaballah, 2019) (Zhao et al., 2019)
(Kumar et al., 2018b) (Kumar et al., 2017a) (Ahmed
et al., 2015) (Lin et al., 2019)
6
SIFT
(Andrew et al., 2016) (Zhao et al., 2019) (Kumar
et al., 2018b) (Lv et al., 2018) (Manoj et al., 2021)
5
Inception
(Qiao et al., 2020) (Andrew et al., 2019) (Andrew
et al., 2017) (Qiao et al., 2019) (Yao et al., 2019)
5
LSTM
(Qiao et al., 2020) (Andrew et al., 2019) (Andrew
et al., 2017) (Qiao et al., 2019)
4
VGG
(Andrew et al., 2017) (Yao et al., 2019)
2
ResNet
(Andrew et al., 2021) (Yao et al., 2019)
2
Zermike moments
(Li et al., 2017)
1
MSER
(Awad and Hassaballah, 2019)
1
FAST
(Zhao et al., 2019)
1
ORB
(Zhao et al., 2019)
1
HOG
(Kumar and Singh, 2017)
1
LTE
(Kumar and Singh, 2017)
1
WLD
(Gaber et al., 2016)
1
SVD
(Zaoralek et al., 2016)
1
FLPP
(Kumar et al., 2017b)
1
Gabor ﬁlter
(Tharwat et al., 2014a)
1
Box-counting
(El-Henawy et al., 2017)
1
GLCM
(Santoni et al., 2015)
1
DBN
(Kumar et al., 2018a)
1
SDAE
(Kumar et al., 2018a)
1
MSER = Maximally stable extremal regions, FAST = Features from accelerated segment
test.
ORB = Oriented FAST and rotated BRIEF, HOG = Histogram oriented gradient.
LTE = Laws texture energy, SVD = Singular value decomposition.
Fig. 9. Combination of feature extractors and ML models used for cattle identiﬁcation in the reviewed studies. The number indicates the number of studies reporting using the combination
of Feature Extractor and ML model.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
150
highest accuracy of each ML model used for cattle identiﬁcation. The
study found that the top four ML models – SVM, KNN, ANN, and
quadratic discriminant analysis (QDA) had more than 99% cattle
identiﬁcation accuracy. However, other models also showed good
accuracy, such as Naive Bayes (NB), Adaboost, and linear discrimi-
nant analysis (LDA). The accuracy of the DL models used for the indi-
vidual cattle identiﬁcation is shown in Fig. 13. The identiﬁcation
models having more than 99% accuracy are ResNet, Inception,
DenseNet, and the neural architecture search network (NasNet).
CNN, long-term recurrent convolutional network (LRCN), and
LeNet also have good accuracy for cattle identiﬁcation. As the cattle
identiﬁcation problem included cattle detection in this SLR, the
highest accuracy and precision of each DL detection model are
identiﬁed and shown in Fig. 14. Most of the cattle detection papers
reported the performance with accuracy and precision for their eval-
uation metrics. In terms of accuracy and precision, the best detection
models are YOLO, Faster-RCNN, and R-CNN.
5. Discussions
5.1. Challenges and future research directions
The reviewed articles mentioned different types of challenges
encountered during the research. In this SLR, although we identiﬁed
the challenges for cattle identiﬁcation using ML and DL approaches,
the same challenges can be found for identifying other animals
(e.g., sheep and pigs). To address the seventh research question
(RQ7), the identiﬁed main challenges are discussed in this section,
along with future research opportunities.
Data quality. Data quality matters for developing automatic cattle
identiﬁcation systems using ML and DL approaches. In this SLR, poor
image quality is one of the main factors for reducing model performance
for cattle identiﬁcation. It was found that illumination variance and mo-
tion blur are responsible for noisy images. Additionally, the datasets can
be noisy or low quality because they are collected from harsh outdoor
and indoor farm environments. As it requires a long time to process
the high-quality image datasets, the researchers reduced the image
size or divided the images into small pieces to increase the data process-
ing speed (Yao et al., 2019; Yang et al., 2019). Several studies in this SLR
report that small and unbalanced datasets are the causes of low accu-
racy (Kumar et al., 2017a, 2018a; Qiao et al., 2019; Guan et al., 2020).
Additionally, a few studies stated that nonstandard muzzle print images
resulted in low accuracy for ML models. As a larger and complex image
or video dataset is signiﬁcant to train DL models, several studies used
the data augmentation method to enhance the training data and their
corresponding labels (Chen et al., 2021; Andrew et al., 2017; Shen
et al., 2020). Several research studies identiﬁed the redundant informa-
tion in the video dataset as a challenge for cattle identiﬁcation (Tassinari
Fig. 10. Combination of feature extractors and DL models used for cattle identiﬁcation. The number indicates the number of studies reporting using the combination of Feature Extractor
and DL model
Fig. 11. Distribution of performance metrics used in the selected papers.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
151
et al., 2021; Qiao et al., 2019; de Lima Weber et al., 2020). In these cases,
a standard and high-quality cattle dataset is needed to be used for large-
scale evaluations of feature extraction methods and cattle detection and
identiﬁcation models.
Benchmark dataset. There is a lack of benchmark datasets that can
be used to extract all the relevant features for cattle identiﬁcation prob-
lems. Based on this SLR, we found that a few datasets are publicly avail-
able, although the value of these datasets is minimal due to the lack of
uniform data standards. As the performance of the existing ML and DL
models still depends on the dataset, the standard benchmark dataset
needs to be available in the public domain. Thus, the model using a uni-
form dataset may apply to real ﬁrms for cattle identiﬁcation. A recom-
mendation from the current study is to create a large-scale benchmark
cattle dataset that can be used by researchers for cattle identiﬁcation
problems in the ﬁeld of precision livestock farming.
Data collection duration. A few studies tested the same identiﬁca-
tion model with different datasets collected from the same cattle but
at different times (days or months). They reported that the model’s ac-
curacy was much low when they collected cattle images for training and
testing purposes on two different days (Chen et al., 2021). There is an
opportunity for researchers to develop ML or DL models that can handle
uncorrelated data from different days and environments.
Image overlapping. Another challenge identiﬁed for cattle identiﬁ-
cation using DL models is that the model results are not satisfactory
when the full body or any part of the body overlaps with another
animal. Researchers may enhance the DL model’s performance by im-
proving the segmentation ability for overlapping individual cattle por-
tions.
Feature selection. Most of the articles reviewed in this SLR used
datasets with a small number of individual cattle, therefore there was
a lack of efﬁcient feature selection methods on large datasets. Scholars
may develop methods to extract important features from the large
dataset for cattle identiﬁcation. Additionally, like human face land-
marks, researchers can consider cattle face landmarks as features for
cattle face recognition. In this paper, we give a comprehensive overview
of cattle identiﬁcation. For cattle that have coat patterns, for example
Holstein, Belgian blue, Shorthorn, Ayrshire and Irish Moiled, the body
or whole head area can be used to differentiate animals. For those that
have pure colour skin, like Augua, Dexter, and Sussex, the muzzle pat-
tern is the unique biomedical feature to use. Many advanced deep learn-
ing models have been developed for object detection. However, only
limited models have been applied for cattle identiﬁcation. There is a
large opportunity to continue to develop and promote advanced ma-
chine learning technologies for livestock production.
Model complexity. Increasing the number of adjustable weights or
parameters in the model architecture increases the complexity of ML
and DL models (Alzubaidi et al., 2021) but may also increase the
model accuracy. However, when the model becomes too complex, it
tends to overﬁt the training dataset, and such situations reduce the
model performance on the test dataset (Srivastava et al., 2014; Xu
Fig. 12. Highest accuracy of ML models used in cattle identiﬁcation.
Fig. 13. Highest accuracy of DL models used in cattle identiﬁcation.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
152
et al., 2019). Overﬁtting was a commonly reported problem in this SLR.
It makes the model dataset dependent, and therefore the model does
not perform well when applied to other datasets. The researchers use
different methods to prevent overﬁtting problems, including data aug-
mentation, ensembling, and cross-validation. Thus, they can train ML
and DL models to generalise well to a new dataset.
Computational cost. DL models are more computationally expen-
sive than classical ML models, as they require a vast amount of data dur-
ing the training phase. The amount of computational power required for
DL models depends on the size of the dataset as well as the complexity
of the model. The researchers stated that over-parameterisation is one
of the leading causes of the complex model (Alzubaidi et al., 2021). In
this SLR, several reviewed studies needed a long time to train the
model when they used a large amount of data (Andrew et al., 2021;
Yao et al., 2019; Phyo et al., 2018). To reduce the model computational
cost, some studies used a transfer learning approach where pre-trained
DL models were used for cattle identiﬁcation. Future researchers can
use transfer learning for cattle identiﬁcation to save training time and
improve model performance.
Open environment operation challenge. Another challenge iden-
tiﬁed here was the implementation of the cattle identiﬁcation
models in the real farm environment. Although some researchers
tested their models on cattle farms, no models were applied to the
livestock farm management systems. A large dataset incorporating
many individual cattle would be useful to train ML and DL models
for application on real cattle farms for identiﬁcation. Additionally,
due to the computation cost of a vision-based system, it is unlikely
to run real-time identiﬁcation without using a server over the
cloud. Dairy cattle are often kept indoors, making it relatively easy
to implement a vision-based identiﬁcation system for better
biosecurity management. However, for the beef industry, cattle are
scattered in an open environment, and reliable and cheap network
connectivity is still under development. It will be very costly if im-
ages are transferred back to a server via satellite. So the implementa-
tion of cattle identiﬁcation in these environments wild still needs the
maturity of the IoT technology.
At this stage, livestock vision-based tracking and monitoring sys-
tems are still under development. There are some proposed static
image-based approaches (Andrew et al., 2021; Qiao et al., 2020) in
use. For example, dairy cattle that are living indoors, where it is easy
to set up the vision system. But for cattle scattered in the ﬁeld, it will
be very challenging to obtain consistent features for accurate object rec-
ognition from the captured images/videos. Therefore, the power of ma-
chine learning and computer vision has not been fully integrated into
practice.
5.2. Limitations of this study
The main limitation of this study is the database search for the rele-
vant articles. This SLR considered four electronic databases. We identi-
ﬁed 55 studies using the search strategy described in the methodology
section. There may be more articles available that have not been in-
cluded in this study due to not considering other electronic databases.
Some relevant articles might have been missed because of the search
keyword string. To maximise the number of relevant articles, we
chose the databases by considering the scope of this study, and we con-
ducted a broad search with a search string including main search terms
and their synonyms. Another possible limitation is the data extraction
from the selected articles, because some data could be missed in this
process. To minimise the amount of missing data, we cross-checked
the analysed data. These limitations will provide doors for future SLR,
but they do not inhibit the main goal of presenting a comprehensive pic-
ture of the usage of ML and DL approaches for cattle identiﬁcation.
6. Conclusions
This study presents a systematic literature review of the application
of classical ML and DL models for cattle identiﬁcation and detection in
cattle farming. Signiﬁcant numbers of papers were investigated, and
the research value of automatic cattle identiﬁcation using ML and DL ap-
proaches has been extensively examined. In this SLR, we have deter-
mined several important insights such as datasets, visual cattle
features, feature extraction methods, ML and DL algorithms, perfor-
mance evaluation metrics, and challenges related to the use of ML and
DL in this ﬁeld. The results show that the application of ML and DL ap-
proaches for automatic cattle identiﬁcation has gained popularity
among researchers in recent years because of their ability to learn
unique features and provide high accuracy. Based on this SLR, no con-
clusion can be made about the best model. However, it is observed
that some ML and DL models are frequently used for cattle identiﬁca-
tion. The most used ML models are SVM, KNN, and ANN, whereas the
most used DL models are CNN, ResNet, Inception, YOLO, and Faster R-
CNN. Although other ML and DL models are also used for cattle identiﬁ-
cation. This SLR does not compare the performance of different types of
ML and DL models used in cattle identiﬁcation, as the results are case
sensitive due to the sparsity of the benchmark dataset. Thus, there is
no commonly accepted evaluation scheme for a fair comparison. The
main challenges identiﬁed in this study for the application of ML and
DL to cattle identiﬁcation include dataset quality and availability,
benchmark datasets, model selection and complexity, as well as real-
time cattle identiﬁcation in the farm environment. The current major
Fig. 14. Highest accuracy and precision of DL models used in cattle detection.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
153
challenges need to be addressed for efﬁcient and effective cattle identi-
ﬁcation systems and further improvements to ML and DL models. It is
concluded that automated and real-time cattle identiﬁcation systems
will play an important role in livestock farm management in the future.
We believe that this study will facilitate future researchers in develop-
ing automatic cattle identiﬁcation systems.
Funding
This project was supported by funding from Food Agility CRC Ltd,
funded under the Commonwealth Government CRC Program. The CRC
Program supports industry-led collaborations between industry,
researchers and the community.
Declaration of Competing Interest
The authors declare that they have no known competing ﬁnancial
interests or personal relationships that could have appeared to inﬂu-
ence the work reported in this paper.
Acknowledgements
We thank Will Swain (TerraCipher) for his valuable comments.
References
Aburasain, R., Edirisinghe, E.A., Albatay, A., 2020. Drone-based cattle detection using deep
neural networks. Proceedings of SAI Intelligent Systems Conference. Springer,
pp. 598–611.
Achour, B., Belkadi, M., Filali, I., Laghrouche, M., Lahdir, M., 2020. Image analysis for indi-
vidual identiﬁcation and feeding behavior monitoring of dairy cows based on
convolutional neural networks (cnn). Biosyst. Eng. 198, 31–49.
Ahmed, S., Gaber, T., Tharwat, A., Hassanien, A.E., Snáel, V., 2015. Muzzle-based cattle
identiﬁcation using speed up robust feature approach. 2015 International Conference
on Intelligent Networking and Collaborative Systems. IEEE, pp. 99–104.
Allen, A., Golden, B., Taylor, M., Patterson, D., Henriksen, D., Skuce, R., 2008. Evaluation of
retinal imaging technology for the biometric identiﬁcation of bovine animals in
northern ireland. Livestock Sci. 116, 42–52.
Alzubaidi, L., Zhang, J., Humaidi, A.J., Al-Dujaili, A., Duan, Y., Al-Shamma, O., Santamarıa, J.,
Fadhel, M.A., Al-Amidie, M., Farhan, L., 2021. Review of deep learning: concepts, cnn
architectures, challenges, applications, future directions. J. Big Data 8, 1–74.
Andrew, W., Hannuna, S., Campbell, N., Burghardt, T., 2016. Automatic individual holstein
friesian cattle identiﬁcation via selective local coat pattern matching in rgb-d imag-
ery. 2016 IEEE International Conference on Image Processing (ICIP). IEEE,
pp. 484–488.
Andrew, W., Greatwood, C., Burghardt, T., 2017. Visual localisation and individual identi-
ﬁcation of holstein friesian cattle via deep learning. Proceedings of the IEEE Interna-
tional Conference on Computer Vision Workshops, pp. 2850–2859.
Andrew, W., Greatwood, C., Burghardt, T., 2019. Aerial animal biometrics: Individual frie-
sian cattle recovery and visual identiﬁcation via an autonomous uav with onboard
deep inference. 2019 IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS). IEEE, pp. 237–243.
Andrew, W., Gao, J., Mullan, S., Campbell, N., Dowsey, A.W., Burghardt, T., 2021. Visual
identiﬁcation of individual holstein-friesian cattle via deep metric learning. Comput.
Elect. Agric. 185, 106133.
Arslan, A.C., Akar, M., Alagoz, F., 2014. 3d cow identiﬁcation in cattle farms. 2014 22nd
Signal Processing and Communications Applications Conference (SIU). IEEE,
pp. 1347–1350.
Awad, A.I., 2016. From classical methods to animal biometrics: a review on cattle identi-
ﬁcation and tracking. Comput. Elect. Agric. 123, 423–435.
Awad, A.I., Hassaballah, M., 2019. Bag-of-visual-words for cattle identiﬁcation from muz-
zle print images. Appl. Sci. 9, 4914.
Barbedo, J.G.A., Koenigkan, L.V., Santos, T.T., Santos, P.M., 2019. A study on the detection of
cattle in uav images using deep learning. Sensors 19, 5436.
Barbedo, J.G.A., Koenigkan, L.V., Santos, P.M., 2020. Cattle detection using oblique uav
images. Drones 4, 75.
Barry, B., Gonzales-Barron, U., McDonnell, K., Butler, F., Ward, S., 2007. Using muzzle pat-
tern recognition as a biometric approach for cattle identiﬁcation. Trans. ASABE 50,
1073–1080.
Bay, H., Tuytelaars, T., Van Gool, L., 2006. Surf: speeded up robust features. European
Conference on Computer Vision. Springer, pp. 404–417.
Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., 2008. Speeded-up robust features (surf).
Comput. Vision Image Understanding 110, 346–359.
Bello, R.-W., Talib, A.Z., Mohamed, A.S.A., Olubummo, D.A., Otobo, F.N., 2020a. Image-
based individual cow recognition using body patterns. Image 11.
Bello, R.-W., Talib, A.Z.H., Mohamed, A.S.A.B., 2020b. Deep learning-based architectures
for recognition of cow using cow nose image pattern. Gazi Univ. J. Sci. 33, 831–844.
Bergamini, L., Porrello, A., Dondona, A.C., Del Negro, E., Mattioli, M., D’alterio, N., Calderara,
S., 2018. Multi-views embedding for cattle re-identiﬁcation. 2018 14th International
Conference on Signal-Image Technology & Internet-Based Systems (SITIS). IEEE,
pp. 184–191.
Bhole, A., Falzon, O., Biehl, M., Azzopardi, G., 2019. A computer vision pipeline that uses
thermal and rgb images for the recognition of holstein cattle. International Confer-
ence on Computer Analysis of Images and Patterns. Springer, pp. 108–119.
Bowling, M., Pendell, D., Morris, D., Yoon, Y., Katoh, K., Belk, K., Smith, G., 2008. Identiﬁca-
tion and traceability of cattle in selected countries outside of North America. Prof.
Anim.Scient. 24, 287–294.
Brownlee, J., 2019. Deep learning for computer vision: image classiﬁcation, object detec-
tion, and face recognition in python. Machine Learning Mastery.
Chen, S., Wang, S., Zuo, X., Yang, R., 2021. Angus cattle recognition using deep learning.
2020 25th International Conference on Pattern Recognition (ICPR). IEEE,
pp. 4169–4175.
Cover, T., Hart, P., 1967. Nearest neighbor pattern classiﬁcation. IEEE Trans. Inform. Theory
13, 21–27.
de Lima Weber, F., de Moraes Weber, V.A., Menezes, G.V., Junior, A.d.S.O., Alves, D.A., de
Oliveira, M.V.M., Matsubara, E.T., Pistori, H., de Abreu, U.G.P., 2020. Recognition of
pantaneira cattle breed using computer vision and convolutional neural networks.
Comput. Elect. Agric. 175, 105548.
El-Henawy, I., El-bakry, H., El-Hadad, H., 2017. Muzzle classiﬁcation using neural net-
works. Accepted and Under Publication in the International Arab Journal of Informa-
tion Technology.
Fosgate, G., Adesiyun, A., Hird, D., 2006. Ear-tag retention and identiﬁcation methods for
extensively managed water buffalo (Bubalus bubalis) in trinidad. Prev. Vet. Med 73,
287–296.
Gaber, T., Tharwat, A., Hassanien, A.E., Snasel, V., 2016. Biometric cattle identiﬁcation ap-
proach based on weber’s local descriptor and adaboost classiﬁer. Comput. Elect. Agric.
122, 55–66.
Gallinat, J., Qanbari, S., Drogemuller, C., Pimentel, E., Thaller, G., Tetens, J., 2013. Dna-based
identiﬁcation of novel bovine casein gene variants. J. Dairy Sci. 96, 699–709.
Garcia, R., Aguilar, J., Toro, M., Pinto, A., Rodriguez, P., 2020. A systematic literature review
on the use of machine learning in precision livestock farming. Comput. Elect. Agric.
179, 105826.
Girshick, R., Donahue, J., Darrell, T., Malik, J., 2014. Rich feature hierarchies for accurate
object detection and semantic segmentation. Proceedings of the IEEE conference on
computer vision and pattern recognition, pp. 580–587.
Guan, H., Motohashi, N., Maki, T., Yamaai, T., 2020. Cattle identiﬁcation and activity recog-
nition by surveillance camera. Elect, Imaging 2020, 1–174.
Han, L., Tao, P., Martin, R.R., 2019. Livestock detection in aerial images using a fully
convolutional network. Computat, Visual Media 5, 2.
He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. Pro-
ceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770–778.
Hu, H., Dai, B., Shen, W., Wei, X., Sun, J., Li, R., Zhang, Y., 2020. Cow identiﬁcation based on
fusion of deep parts features. Biosyst. Eng. 192, 245–256.
Huhtala, A., Suhonen, K., Makela, P., Hakojärvi, M., Ahokas, J., 2007. Evaluation of instru-
mentation for cow positioning and tracking indoors. Biosyst. Eng. 96, 399–405.
Jaddoa, M., Gonzalez, L., Cuthbertson, H., Al-Jumaily, A., 2019. Multi view face detection in
cattle using infrared thermography. International Conference on Applied Computing
to Support Industry: Innovation and Technology. Springer, pp. 223–236.
Janiesch, C., Zschech, P., Heinrich, K., 2021. Machine learning and deep learning. Electronic
Markets. 607, pp. 1–11.
Joachims, T., 1998. Making large-scale SVM learning practical. Technical Report.
Kitchenham, B., Charters, S., 2007. Guidelines for performing systematic literature reviews
in software engineering.
Kitchenham, B., Brereton, O.P., Budgen, D., Turner, M., Bailey, J., Linkman, S., 2009. System-
atic literature reviews in software engineering–a systematic literature review.
Inform. Softw. Technol. 51, 7–15.
Kumar, S., Singh, S.K., 2017. Automatic identiﬁcation of cattle using muzzle point pattern:
a hybrid feature extraction and classiﬁcation paradigm. Multimedia Tools Appl. 76,
26551–26580.
Kumar, S., Singh, S.K., 2020. Cattle recognition: a new frontier in visual animal biometrics
research. Proc. Natl. Acad. Sci. India Sect. A Phys. Sci. 90, 689–708.
Kumar, S., Singh, S.K., Dutta, T., Gupta, H.P., 2016a. A fast cattle recognition system using
smart devices. Proceedings of the 24th ACM International Conference on Multimedia,
pp. 742–743.
Kumar, S., Tiwari, S., Singh, S.K., 2016b. Face recognition of cattle: can it be done? Proc.
Natl. Acad. Sci. India Sect. A Phys. Sci. 86, 137–148.
Kumar, S., Singh, S.K., Singh, A.K., 2017a. Muzzle point pattern based techniques for indi-
vidual cattle identiﬁcation. IET Image Process. 11, 805–814.
Kumar, S., Singh, S.K., Singh, R.S., Singh, A.K., Tiwari, S., 2017b. Real-time recognition of
cattle using animal biometrics. J. Real-Time Image Process. 13, 505–526.
Kumar, S., Pandey, A., Satwik, K.S.R., Kumar, S., Singh, S.K., Singh, A.K., Mohan, A., 2018a.
Deep learning framework for recognition of cattle using muzzle point image pattern.
Measurement 116, 1–17.
Kumar, S., Singh, S.K., Abidi, A.I., Datta, D., Sangaiah, A.K., 2018b. Group sparse represen-
tation approach for recognition of cattle on muzzle point images. Int. J. Parallel Pro-
gram. 46, 812–837.
Kusakunniran, W., Chaiviroonjaroen, T., 2018. Automatic cattle identiﬁcation based on
multi-channel lbp on muzzle images. 2018 International Conference on Sustainable
Information Engineering and Technology (SIET). IEEE, pp. 1–5.
LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning. Nature 521, 436–444.
Li, W., Ji, Z., Wang, L., Sun, C., Yang, X., 2017. Automatic individual identiﬁcation of hol-
stein dairy cows using tailhead images. Comput. Elect. Agric. 142, 622–631.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
154
Li, Z., Ge, C., Shen, S., Li, X., 2018. Cow individual identiﬁcation based on convolutional
neural network. Proceedings of the 2018 International Conference on Algorithms,
Computing and Artiﬁcial Intelligence, pp. 1–5.
Li, G., Huang, Y., Chen, Z., Chesser, G.D., Purswell, J.L., Linhoss, J., Zhao, Y., 2021a. Practices
and applications of convolutional neural network-based computer vision systems in
animal farming: a review. Sensors 21, 1492.
Li, S., Fu, L., Sun, Y., Mu, Y., Chen, L., Li, J., Geong, H., 2021b. Individual dairy cow identiﬁ-
cation based on lightweight convolutional neural network. PLoS ONE 16 (11),
e0260510.
Lin, M., Chen, C., Lai, C., 2019. Object detection algorithm based adaboost residual correc-
tion fast r-cnn on network. Proceedings of the 2019 3rd International Conference on
Deep Learning Technologies, pp. 42–46.
Lowe, D.G., 1999. Object recognition from local scale-invariant features. Proceedings of
the Seventh IEEE International Conference on Computer Vision, pp. 1150–1157 Ieee
volume 2.
Lu, Y., He, X., Wen, Y., Wang, P.S., 2014. A new cow identiﬁcation system based on iris
analysis and recognition. Int. J. Biometrics 6, 18–32.
Lv, F., Zhang, C., Lv, C., 2018. Image recognition of individual cow based on sift in lαβ color
space. MATEC Web of Conferences, p. 01023 EDP Sciences volume 176.
Mahmud, M.S., Zahid, A., Das, A.K., Muzammil, M., Khan, M.U., 2021. A systematic litera-
ture review on deep learning applications for precision cattle farming. Comput.
Elect. Agric. 187, 106313.
Manoj, S., Rakshith, S., Kanchana, V., 2021. Identiﬁcation of cattle breed using the
convolutional neural network. 2021 3rd International Conference on Signal Process-
ing and Communication (ICPSC). IEEE, pp. 503–507.
McCulloch, W.S., Pitts, W., 1943. A logical calculus of the ideas immanent in nervous
activity. Bull. Math. Biophys. 5, 115–133.
Neary, M., Yager, A., 2002. Methods of Livestock Identiﬁcation.
Noonan, G., Rand, J., Priest, J., Ainscow, J., Blackshaw, J., 1994. Behavioural observations of
piglets undergoing tail docking, teeth clipping and ear notching. Appl. Anim. Behav.
Sci. 39, 203–213.
Noviyanto, A., Arymurthy, A.M., 2013. Beef cattle identiﬁcation based on muzzle pattern
using a matching reﬁnement technique in the sift method. Comput. Elect. Agric. 99,
77–84.
Petersen, W., 1922. The identiﬁcation of the bovine by means of nose-prints. J. Dairy Sci. 5,
249–258.
Phyo, C.N., Zin, T.T., Hama, H., Kobayashi, I., 2018. A hybrid rolling skew histogram-neural
network approach to dairy cow identiﬁcation system. 2018 International Conference
on Image and Vision Computing New Zealand (IVCNZ). IEEE, pp. 1–5.
Qiao, Y., Su, D., Kong, H., Sukkarieh, S., Lomax, S., Clark, C., 2019. Individual cattle identiﬁ-
cation using a deep learning based framework. IFAC-PapersOnLine 52, 318–323.
Qiao, Y., Su, D., Kong, H., Sukkarieh, S., Lomax, S., Clark, C., 2020. Bilstm-based individual
cattle identiﬁcation for automated precision livestock farming. 2020 IEEE 16th Inter-
national Conference on Automation Science and Engineering (CASE). IEEE,
pp. 967–972.
Qiao, Y., Kong, H., Clark, C., Lomax, S., Su, D., Eiffert, S., Sukkarieh, S., 2021. Intelligent per-
ception for cattle monitoring: A review for cattle identiﬁcation, body condition score
evaluation, and weight estimation. Comput. Elect. Agric. 185, 106143.
Redmon, J., Farhadi, A., 2017. Yolo9000: better, faster, stronger. Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, pp. 7263–7271.
Redmon, J., Farhadi, A., 2018. YOLOv3: An Incremental Improvement. arXiv https://doi.
org/10.48550/ARXIV.1804.02767.
Redmon, J., Divvala, S., Girshick, R., Farhadi, A., 2016. You only look once: uniﬁed, real-
time object detection. Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 779–788.
Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster r-cnn: towards real-time object detection
with region proposal networks. Adv. Neural Inform. Process. Syst. 28, 91–99.
Rivas, A., Chamoso, P., Gonzalez-Briones, A., Corchado, J.M., 2018. Detection of cattle using
drones and convolutional neural networks. Sensors 18, 2048.
Roberts, C.M., 2006. Radio frequency identiﬁcation (rﬁd). Comput. Securit. 25, 18–26.
Rossing, W., 1999. Animal identiﬁcation: introduction and history. Comput. Elect. Agric.
24, 1–4.
Ruiz-Garcia, L., Lunadei, L., 2011. The role of rﬁd in agriculture: applications, limitations
and challenges. Comput. Elect. Agric. 79, 42–50.
Rumelhart, D.E., Hinton, G.E., Williams, R.J., 1986. Learning representations by back-
propagating errors. Nature 323, 533–536.
Santoni, M.M., Sensuse, D.I., Arymurthy, A.M., Fanany, M.I., 2015. Cattle race classiﬁcation
using gray level co-occurrence matrix convolutional neural networks. Proc. Comput.
Sci. 59, 493–502.
Schilling, B., Bahmani, K., Li, B., Banerjee, S., Smith, J.S., Moshier, T., Schuckers, S., 2018.
Validation of biometric identiﬁcation of dairy cows based on udder nir images.
2018 IEEE 9th International Conference on Biometrics Theory, Applications and Sys-
tems (BTAS). IEEE, pp. 1–7.
Shao, W., Kawakami, R., Yoshihashi, R., You, S., Kawase, H., Naemura, T., 2020. Cattle de-
tection and counting in uav images based on convolutional neural networks. Int.
J. Remote Sensing 41, 31–52.
Shen, W., Hu, H., Dai, B., Wei, X., Sun, J., Jiang, L., Sun, Y., 2020. Individual identiﬁcation of
dairy cows based on convolutional neural networks. Multimed. Tools Appl. 79,
14711–14724.
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., 2014. Dropout: a
simple way to prevent neural networks from overﬁtting. J. Mach. Learn. Res. 15,
1929–1958.
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V.,
Rabinovich, A., 2015. Going deeper with convolutions. Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition, pp. 1–9.
Tassinari, P., Bovo, M., Benni, S., Franzoni, S., Poggi, M., Mammi, L.M.E., Mattoccia, S., Di
Stefano, L., Bonora, F., Barbaresi, A., et al., 2021. A computer vision approach based
on deep learning for the detection of dairy cows in free stall barn. Comput. Elect.
Agric. 182, 106030.
Tharwat, A., Gaber, T., Hassanien, A.E., 2014a. Cattle identiﬁcation based on muzzle im-
ages using gabor features and svm classiﬁer. International Conference on Advanced
Machine Learning Technologies and Applications. Springer, pp. 236–247.
Tharwat, A., Gaber, T., Hassanien, A.E., Hassanien, H.A., Tolba, M.F., 2014b. Cattle identiﬁ-
cation using muzzle print images based on texture features approach. Proceedings of
the Fifth International Conference on Innovations in Bio-Inspired Computing and
Applications IBICA 2014. Springer, pp. 217–227.
Vlad, M., Parvulet, R.A., Vlad, M.S., et al., 2012. A survey of livestock identiﬁcation systems.
Proceedings of the 13th WSEAS International Conference on Automation and Infor-
mation,(ICAI12). WSEAS Press, Iasi, Romania, pp. 165–170.
Wang, Z., Fu, Z., Chen, W., Hu, J., 2010. A rﬁd-based traceability system for cattle breeding
in china. 2010 International Conference on Computer Application and System Model-
ing (ICCASM 2010) (pp. V2–567). IEEE volume 2.
Wang, H., Qin, J., Hou, Q., Gong, S., 2020a. Cattle face recognition method based on param-
eter transfer and deep learning. Journal of Physics: Conference Series, p. 012054 IOP
Publishing volume 1453.
Wang, X., Cheng, X., Chen, Z., Xu, F., 2020b. A method for individual identiﬁcation of dairy
cows based on deep learning. Proceedings of the 2020 2nd International Conference
on Robotics, Intelligent Control and Artiﬁcial Intelligence, pp. 186–191.
Wang, Z., Ni, F., Yao, N., 2020c. Mtfcn: multi-task fully convolutional network for cow face
detection. International Conference in Communications, Signal Processing, and Sys-
tems. Springer, pp. 1116–1127.
Wohlin, C., 2014. Guidelines for snowballing in systematic literature studies and a repli-
cation in software engineering. Proceedings of the 18th International Conference on
Evaluation and Assessment in Software Engineering, pp. 1–10.
Xu, Q., Zhang, M., Gu, Z., Pan, G., 2019. Overﬁtting remedy by sparsifying regularization on
fully-connected layers of cnns. Neurocomputing 328, 69–74.
Xu, B., Wang, W., Falzon, G., Kwan, P., Guo, L., Chen, G., Tait, A., Schneider, D., 2020. Auto-
mated cattle counting using mask r-cnn in quadcopter vision system. Comput. Elect.
Agric. 171, 105300.
Yang, Z., Xiong, H., Chen, X., Liu, H., Kuang, Y., Gao, Y., 2019. Dairy cow tiny face recogni-
tion based on convolutional neural networks. Chinese Conference on Biometric Rec-
ognition. Springer, pp. 216–222.
Yao, L., Hu, Z., Liu, C., Liu, H., Kuang, Y., Gao, Y., 2019. Cow face detection and recognition
based on automatic feature extraction algorithm. Proceedings of the ACM Turing Cel-
ebration Conference-China, pp. 1–5.
Yukun, S., Pengju, H., Yujie, W., Ziqi, C., Yang, L., Baisheng, D., Runze, L., Yonggen, Z., 2019.
Automatic monitoring system for individual dairy cows based on a deep learning
framework that provides identiﬁcation via body parts and estimation of body condi-
tion score. J. Dairy Sci. 102, 10140–10151.
Zaoralek, L., Prilepok, M., Snasel, V., 2016. Cattle identiﬁcation using muzzle images. Pro-
ceedings of the Second International Afro-European Conference for Industrial
Advancement AECIA 2015. Springer, pp. 105–115.
Zhao, K., Jin, X., Ji, J., Wang, J., Ma, H., Zhu, X., 2019. Individual identiﬁcation of holstein
dairy cows based on detecting and matching feature points in body images. Biosyst.
Eng. 181, 128–139.
Zin, T.T., Phyo, C.N., Tin, P., Hama, H., Kobayashi, I., 2018. Image technology based cow
identiﬁcation system using deep learning. Proceedings of the International
MultiConference of Engineers and Computer Scientists, pp. 236–247 volume 1.
Zin, T.T., Misawa, S., Pwint, M.Z., Thant, S., Seint, P.T., Sumi, K., Yoshida, K., 2020. Cow iden-
tiﬁcation system using ear tag recognition. 2020 IEEE 2nd Global Conference on Life
Sciences and Technologies (LifeTech). IEEE, pp. 65–66.
Zou, Z., Shi, Z., Guo, Y., Ye, J., 2019. Object Detection in 20 Years: A Survey. arXiv https://
doi.org/10.48550/ARXIV.1905.05055.
Zuo, C., Han, L., Tao, P., lei Meng, X., 2020. Livestock detection based on convolutional neu-
ral network. 2020 the 3rd International Conference on Control and Computer Vision,
pp. 1–6.
M.E. Hossain, M.A. Kabir, L. Zheng et al.
Artiﬁcial Intelligence in Agriculture 6 (2022) 138–155
155
