ORIGINAL ARTICLE
A general framework for intelligent recommender
systems
Jose Aguilar a,*, Priscila Valdiviezo-Dı´az b, Guido Riofrio b
a CEMISID, Departamento de Computacio´n, Universidad de Los Andes, Me´rida, Venezuela Prometeo Researcher, UTPL,
Loja, Ecuador
b Depto. de Ciencias de la Computacio´n y Electro´nica, Universidad Te´cnica Particular de Loja, Ecuador
Received 20 April 2016; revised 29 July 2016; accepted 25 August 2016
Available online 21 September 2016
KEYWORDS
Recommender system;
Cognitive maps
Abstract
In this paper, we propose a general framework for an intelligent recommender system
that extends the concept of a knowledge-based recommender system. The intelligent recommender
system exploits knowledge, learns, discovers new information, infers preferences and criticisms,
among other things. For that, the framework of an intelligent recommender system is deﬁned by
the following components: knowledge representation paradigm, learning methods, and reasoning
mechanisms. Additionally, it has ﬁve knowledge models about the different aspects that we can con-
sider during a recommendation: users, items, domain, context and criticisms. The mix of the com-
ponents exploits the knowledge, updates it and infers, among other things. In this work, we
implement one intelligent recommender system based on this framework, using Fuzzy Cognitive
Maps (FCMs). Next, we test the performance of the intelligent recommender system with special-
ized criteria linked to the utilization of the knowledge in order to test the versatility and perfor-
mance of the framework.
� 2016 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University. This is
an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
1. Introduction
The main goal of the Recommender Systems (RS) was to help
users in their decision making. This area proposes the develop-
ment of RS to provide high-quality recommendations in differ-
ent contexts. In general, a recommender system is software
which provides suggestions of items for users [15]. Various
techniques for recommendation have been proposed. From
the domains such as artiﬁcial intelligence, data and semantic
mining,
information
retrieval,
approaches
of
RS
have
emerged.
The
RS
traditionally
have
been
classiﬁed
as
content-based, collaborative, knowledge-based, and hybrid.
A knowledge-based recommender system only exploits the
knowledge naively. We argue that a recommender system
has an intelligent behavior if it has the next set of capabilities:
knowledge representation, learning capabilities, and reasoning
mechanisms. The mix of these capabilities can exploit largely
knowledge, update them, and infer them, among other things.
Based on these ideas, in this paper we propose a new type of
recommender system, called Intelligent Recommender System
* Corresponding author.
E-mail address: aguilar@ula.ve (J. Aguilar).
Peer review under responsibility of King Saud University.
Production and hosting by Elsevier
Applied Computing and Informatics (2017) 13, 147–160
Saudi Computer Society, King Saud University
Applied Computing and Informatics
(http://computer.org.sa)
www.ksu.edu.sa
www.sciencedirect.com
http://dx.doi.org/10.1016/j.aci.2016.08.002
2210-8327 � 2016 The Authors. Production and hosting by Elsevier B.V. on behalf of King Saud University.
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
(IRS), which is an extension of the knowledge-based RS. The
IRS considers learning algorithms, knowledge representation
mechanisms, and reasoning motors, among other aspects. In
this paper, we deﬁne an IRS, and describe its components,
and the relationships among them, among other things.
An IRS can use any intelligent technique (fuzzy logic, onto-
logical approaches, etc.) for its implementation. Additionally,
we give an example of its application using the FCMs. The
FCMs have been used in different domains [1–3]. The FCMs
are based on the Cognitive Maps (CMs) theory, to model sys-
tems based on concepts that describe the main characteristics
of the modeled system (variables or states of the system),
and the causal relationships between them. FCMs are based
on the fuzzy logic theory to deﬁne their structure and their
inference process from a given data input. FCMs have been
applied to diverse ﬁeld such as supporting group-decision,
political analysis [2].
In the following section we present some backgrounds
about the RS. Section 3 presents the theoretical bases of our
approach and then Section 4 presents the IRS framework. Sec-
tion 5 presents details of the description of the knowledge
models of the IRS. Section 6 presents the implementation of
IRS using FCMs. Lastly, the next sections present a case
study, the utilization of IRS based on FCMs, the experiments,
and the analysis of the results.
2. Literature review
In the literature, there are a lot of papers about RS. In this sec-
tion we present some works, speciﬁcally knowledge-based RS
or based on intelligent techniques. In [4] the Team Recom-
mender Systems (TRS) is presented, which is a knowledge-
based RS that helps organizations deﬁne the team needed to
carry out a task requiring multiple skills. TRS solves two
important problems. First, it manages semantic heterogeneity
that occurs when the data describing the same entities are rep-
resented in different ways. It manages specialization excess of
the objects of highest similarity with the user, leaving out con-
sideration
of
irrelevant
information.
Additionally,
they
develop an ontology used to handle the semantic heterogeneity
problem. In [5,6] an overview of knowledge-based RS in differ-
ent domains, such as restaurants, movies is presented. Addi-
tionally,
they
discuss
the
strengths
and
weaknesses
of
knowledge-based and collaborative-ﬁltering RS, and introduce
a hybrid RS that combines the two approaches. In their
approach, the knowledge-based RS is the bootstrap of the col-
laborative ﬁltering engine while the data spool is small, and the
collaborative ﬁlter is the post-ﬁlter of the knowledge-based RS.
In [9] a work to deﬁne the proﬁle of the customers is pre-
sented. Additionally, algorithms for generating personalized
buying proposals, based on the collaborative, content-based
ﬁltering, and knowledge-based approaches are presented.
The proﬁle is created from the user’s nature, and evolves
according to the events observed. Also, they present some
ideas about RS based on the social web and on the consumer
buying behavior theory. In [10] a recommendation system of
academic papers is deﬁned. The paper proposes user situation
awareness and a recommendation system based on fuzzy clus-
tering analysis and fuzzy cognitive maps. They use fuzzy clus-
tering analysis to describe the correlation between lexical
semantics, and FCM to deﬁne the qualitative distribution of
user interests. The fuzzy clustering analysis introduces the view
of the information entropy theory. It carries out a quantitative
description of the information in the database, and generates a
tree data structure based on this, which is converted into a net
data structure used by a FCM for the recommendations. They
verify the validity of the algorithm to recommend sites of aca-
demic theses. In [12] a recommender system based on fuzzy
logic is proposed. This recommender system mines informa-
tion, in order to provide recommendations to potential buyers
about products based on their personal needs. This personal-
ized recommender system driven by fuzzy logic technique
mines information about the features of laptop computers,
and provides services to potential buyers by recommending
optimal products based on their personal needs. They use
the Fuzzy Near Compactness concept to measure the similarity
between consumer needs and product features. In [13] a Fuzzy
linguistic approach to represent the user ratings, and a Fuzzy
Multicriteria Decision Making approach, are used to rank
the relevant items to a user. Their system handles the uncer-
tainty and fuzziness of human decision making behavior.
For that their model of the user ratings considers the subjec-
tive, imprecise and vague nature of the user’s perceptions
and opinions, using fuzzy set paradigm. They test their
approach in a Music Recommender system.
In [17] an ontological approach to recommend on-line aca-
demic research papers is explored. Research papers are classi-
ﬁed using ontology. Recommendation algorithms are used to
recommend papers seen by similar people. They create user
proﬁles representing the proﬁles based on ontology of research
issues. Additionally, they use a proﬁle visualization approach,
in order to acquire proﬁle feedback. The ontological inference
improves the user proﬁling, and external ontological knowl-
edge is used to bootstrap the recommender system. In [18]
an E-Learning RS is presented, based on the use of web mining
techniques, to build an agent that can recommend online learn-
ing activities or course Web sites, based on the learners’ access
history, to assist the online learning process. These techniques
are integrated on the RS platform. Additionally, they present a
Survey about E-Learning RS in the literature. In [19] it is pre-
sented a fuzzy-based recommender system for stimulating
political participation and collaboration. The recommendation
engine is based on a modiﬁed fuzzy c-means algorithm, and the
Sammon mapping technique is used for visualizing recommen-
dations. Additionally, they develop a framework for ePartici-
pation, which allows to analyze different projects and their
development, in order to evaluate the citizens’ participation
and empowerment. In [20] it is explored the role of cognitive
decision effort in RS, using indicators about ‘‘information
quality” and ‘‘service quality”, to examine the performance
of the RS according to the user opinion, in a internet book
store. They conclude that the information quality of the RS
has inﬂuence in the consumer shopping decision-making pro-
cess, and that the e-commerce platform provides recommenda-
tions and information necessary, but, the recommendation
system has not signiﬁcant inﬂuence in the decision-making
effort during the process of consumer’s shopping decision-
making.
In [21] it is determined that collaborative ﬁlter-based RS
can be improved by incorporating side information, such as
natural language reviews. Additionally, they introduce a model
of reviews based on the recurrent neural network, and study its
effects on collaborative ﬁltering performance. The recurrent
148
J. Aguilar et al.
neural network has the ability to act as a regularizer of the item
representations to be recommended. In [22] a personalized rec-
ommendation system is introduced based on accurate models
which capture the user preferences. They propose a picture-
based approach: they use a set of travel related pictures
selected by a user, and an individual travel proﬁle is deduced.
This is accomplished by mapping those pictures onto seven
basic factors, which reﬂect different travel aspects. This model
constitutes the basis of their recommendation algorithm. In
[23] a semantic recommendation approach of pedagogical
resources is proposed within a learning ecosystem. This
approach is based on a voting system, where each member
of the ecosystem evaluates the pedagogical resources found
in his/her sharing space. In this way, they deﬁne a coherent
learning ecosystem that promotes collaborative learning,
which allows exchanging and sharing knowledge and/or skills.
Finally, [15] is a book which present trends, concepts, method-
ologies, challenges and applications on RS. This book
describes the classical methods, as well as novel approaches
such as Context-Aware RS and RS in the social web.
3. Recommender systems
RS are techniques used to provide suggestions of items to the
user [15]. Formally, a recommendation problem can be deﬁned
by a utility function ‘‘rec”, which predicts the utility of an item
i of a set of items I, for a speciﬁc user u of a set of users U. Rec
is a function R  U � I. where R is in the interval [0,1], and it
is the utility score of the recommended item. Rec denotes the
item’s capability to satisfy the needs of the users. In this
way, the prediction task of a recommender system is to deﬁne
this utility score for a given user and item. In general, the data
and knowledge available for RS can be very diverse [15]:
� Items are the objects to recommend. They are deﬁned by
their complexity and their utility. The complexity of an item
is deﬁned by its structure, representation, and dependence
of other items. Normally, RS recommend one speciﬁc type
of item (movies, music, etc.).
� Users of RS are very diverse with respect to their interests,
goals, etc. RS personalize the recommendations with the
information about the users. This information can be orga-
nized in different ways, and the recommendation technique
used deﬁnes the information in the user model.
� Transactions deﬁne the interaction between the users and
the RS. Transactions are the data generated during the
human-RS interaction. The types of information used for
the recommendation generation techniques are very differ-
ent, for example, the item selected by the user, the descrip-
tion of the context of the query. Also, the transaction can
include an explicit feedback of the user. Normally it is
called criticity such as its rating of an item.
Various recommendation techniques have been proposed in
the literature [9,15] (see Table 1).
The concept of critiquing is very important in our frame-
work. It is based on the idea that users specify their requests
as goals not satisﬁed by the recommended ongoing item [9].
Critiquing-based RS articulates preferences without forcing
users to specify concrete values for item properties. The major
steps of a critiquing-based RS are [9]:
– Item recommendation. This step selects a set of items r to be
presented to the user. In the ﬁrst critiquing cycle, the
selected items are based on a user query q (similarity
between the requirements and the candidate items).
– Item reviewing. In this step the user reviews the recom-
mended item, in order to accept the recommendation or
select a critique, which restart a new critiquing cycle. If a
critique has been chosen, only the items that fulﬁll the cri-
teria deﬁned in the critique are further taken into account
(it reduces the candidate item set).
Our IRS extends the ideas behind the classical RS with this
concept [5,6], because it tries to understand users, discover
their interests, etc., through the creation of knowledge, reason-
ing, etc. During this process, we use the notions of ‘‘unit cri-
tique” and ‘‘compound critiques”. Unit critique operates
Table 1
Taxonomy of RS.
Type
Description
Content-based recommendation
approach
In this approach, the RS recommend items, which are similar to the ones that the user chosen in the
past. The similarity is computed according to the characteristics associated with the compared items
Collaborative recommendation approach
This approach uses the opinions of users’ community, or the information about the past behavior,
to predict the items the user will be interested
Demographic recommendation approach
It recommends items according to the demographic proﬁle of the user. The idea is that each
demographic niche has diﬀerent recommendation needs
Utility-based or knowledge-based
recommendation approach
This approach recommends items on the basis of the knowledge about how the item characteristics
meet the needs and preferences of the users. There are two cases: case-based where the system uses
the knowledge, about both the user and the items, to carry out recommendations based on
similarity metrics. Constraint-based recommenders use knowledge bases with set of
recommendation rules about how to map user requirements with item characteristics
Community-based recommendation
approach
This approach is based on the idea that people have more conﬁdence in recommendations from
their friends than from anonymous individuals. The popularity of social networks has generated
interest in these RS
Hybrid approach
This approach is the combination of the previous techniques, in order to use the advantages of each
one. The combination of the diﬀerent techniques generates better or more precise
recommendations, and exploits better the current information
Intelligent recommender systems
149
over one speciﬁc property of an item. It deﬁnes the change
requests of a single item property. For example a unit critique
in a PC IRS can infer that the user is interested in a PC with
more memory than the normally recommended PC; ‘‘more
memory” is a critique over the memory feature. There are cri-
tiques that operate over multiple properties, called compound
critiques. For example a compound critique in our IRS for the
PC domain can infer lower price, faster CPU, and more mem-
ory. The compound critiques are very important because they
reduce the number of critiquing cycles and allow a faster nav-
igation into the item space.
4. A framework for an intelligent recommender system
In this section, we deﬁne the main components of our IRS. The
difference with respect to a knowledge-based recommendation
approach is that in an IRS there are four main elements. The
four main elements are
� A knowledge acquisition mechanism based on learning
algorithms.
� A knowledge explicit modeling, which represents all the
knowledge necessary to recommend.
� A reasoning mechanism to infer information from the
stored knowledge.
� A criticality system based on the automatic inference capa-
bility of the IRS.
Our IRS does not only recommend items based on speciﬁc
knowledge about how the item features meet user needs and
preferences,
such
as
knowledge-based
recommendation
approach; our system uses the rating of the items like the col-
laborative approach, and it discovers the aspects, interests,
properties that the user would like about the items (criticality
system), infers the rating of the items, etc. In this way, it mixes
the classical RS idea based on similarity to infer how much the
user needs the item [9,15] and the concept of criticality deduced
automatically to infer user goals that are not satisﬁed by the
item currently under consideration [22].
The IRS exploits all the knowledge, which is obtained auto-
matically (by learning mechanism), and is modeled appropri-
ately, in order to be used by reasoning mechanisms to infer
how much the user needs the item. If the user’s goals are sat-
isﬁed by the current items. Basically, two aspects must be
deﬁned in our IRS. The two aspects are its architecture, and
the knowledge to model. The general architecture is shown
in Fig. 1.
The main component is the semantic knowledge model,
which stores the different types of knowledge that it uses for
recommending
items.
This
knowledge
must
be
updated
because it requires learning mechanisms. Finally, in order to
exploit the knowledge, it uses a reasoning mechanism, which
is responsible for recommending items using all the knowledge
available. Now, listed below are the different components of
architecture:
– Knowledge modeling: the main aspect was to deﬁne the
paradigm of knowledge representation. There are a lot of
paradigms [1,2,4,10,12]: ontologies, fuzzy rules, conceptual
maps, etc. The main points to select one are the capabilities
of representation of all the knowledge available, and the
possibility to deﬁne reasoning mechanisms with them. In
general, our recommendation paradigm requires different
types of knowledge such as the user model, the contextual
model, the domain model, the item model that have been
recommended, and the rest information about the behavior
Figure 1
The IRS architecture.
150
J. Aguilar et al.
between the users-items that stores ratings, critiques, etc.
(we call it the critical model). Section 3 describes in detail
the different types of knowledge of our IRS.
– Knowledge acquisition: this phase is deﬁned to learn about
the current situations, etc. There are a lot of approaches
(supervised, unsupervised, etc.) [21], but the main point is
to deﬁne an approach that allows all the knowledge avail-
able to be discovered in a given moment. In general, the dif-
ferent machine-learning techniques can be potentially used,
according to the context, for example: information online
available and real time information. The sources of knowl-
edge are very varied and they can be structured (For exam-
ple, the transactional database, or data-warehouse, of an
organization), semi-structured (For example, xml ﬁles) or
unstructured (For example, GPS tracking information,
audio streams, etc.) data, which represent information
about the users, context, etc. The knowledge is acquired
through learning mechanisms based on data mining, seman-
tic meaning (web mining, text mining, ontological mining),
among other techniques [6,9]. The learning mechanisms to
be used depend on the knowledge model and the source
of data. For example, if the knowledge model is ontology
and the source of data is the web, we can use semantic min-
ing techniques to extract knowledge. Additionally, in this
case, data science tasks are very important, in order to
explore, clean, transform and reduce the data, before apply-
ing the learning techniques to extract the knowledge [15].
– Reasoning mechanism: according to the paradigm choice,
there are speciﬁc reasoning mechanisms which can be used.
The main point is that these mechanisms must allow for
inferences. The user needs if the user goals are not satisﬁed
by the current items, considering all the knowledge avail-
able. There are three main reasoning mechanisms that can
be used: induction, abduction, and deduction. Each one
can be used for different tasks, such as analyzing why a rec-
ommendation can be given, predicting an item that can be
interesting for a user and that means, it allows various types
of reasoning: ﬁnd a ‘‘relaxation” or ‘‘compromise” (for
example, What if the user’s requirements cannot be ful-
ﬁlled?), ﬁnd a ‘‘diagnosis” (for example, Why a certain item
is recommended), carry out a ‘‘veriﬁcation” and ‘‘repara
tion-debugging” (for example, What if the user require-
ments are inconsistent?), and so forth. The idea is to deﬁne
logical explanations about the different aspects to be con-
sidered during a recommendation process, using the avail-
able knowledge. There are classic RS responses only to
some of them.
– Criticality system: it is an automatic system to infer the user
preferences without asking users about them, only using the
knowledge stored in the RS [9]. In each cycle of a recom-
mendation session there is a reasoning phase where the
aspects are deduced to accept or criticize. These cycles con-
tinue until a recommendation is carried out. The learning
mechanisms provide the knowledge necessary like a feed-
back procedure, to deduce the preferences of the users.
They provide the knowledge necessary to deduce them to
infer the rating of the items, built over a series of recom-
mendation cycles. If a new cycle has been triggered, then
the only items that fulﬁll the criteria deﬁned in the critique
are further taken into account (reduction in the candidate
items set, in order to reduce the space of search: candidate
items). In general, this process continues until the reasoning
mechanism determines that the user can accept the recom-
mendation and exhausted all the possibilities, or terminates
the recommendation cycles.
5. Knowledge model in our intelligent recommender system
The main component of our IRS is knowledge. An IRS must
exploit all the knowledge available, and to do that, all the
advances must be used in different domains (such as informa-
tion retrieval, data mining), in order to extract this knowledge.
Classically, a RS estimates the similarity among the item prop-
erties and the user preferences, or estimates the ratings for the
items that have not been seen by a user. IRS exploits knowl-
edge to infer the rating of the items, to infer the preferences
of the users, and to match the item properties with the user
preferences. For that, it deﬁnes different types of knowledge:
– An extended user proﬁle (including its opinions, critiques,
etc.): Normally, the information that is modeled is about
his/her preferences, his/her personal information (age, gen-
der, profession, and education), etc. [8,17,22]. Here, we pro-
pose
to
extend
with
new
information
about
his/her
opinions, critiques; his/her relationship with other users
(his/her friend groups, etc.). The user model proﬁles, with
the rest of semantic model of IRS must infer the preferences
and needs of the users.
– An extended item proﬁle: it represents a full description of
an item based on four dimensions: (i) the general descrip-
tion of the product (name, branches that produce the items,
etc.); (ii) the functional information about the item (its func-
tions, etc.), (iii) the structural information about the item
(its components, the relationships among them, depen-
dence, etc.) and ﬁnally, (iv) the operational information
about the item (how can be used, etc.). Some of this infor-
mation can be learned, or inferred from the information
stored.
– Context and domain knowledge: it is very important to know
the domain where the items will be used, the context where
the individual is going to make the decision, etc. The con-
textual knowledge is all the knowledge that explains a given
situation [15,20]. The domain knowledge is the knowledge
of an area of a discipline, a human activity, etc. [15,23]. This
type of knowledge is not currently considered, or the RS
must be customized to be used in a speciﬁc context, chang-
ing part of its structure. Here, we propose to model explic-
itly these aspects.
– A critical knowledge: This is a knowledge that must be dis-
covered, based on the transactions over the RS (relations
between users and items). A transaction may describe the
context of the recommendation, may refer the item chosen,
and may include the feedback the user has provided, among
other things [9,15]. Normally, this knowledge describes the
behavior-based knowledge, and must be discovered using
machine-learning technique in order to obtain interesting
patterns. This knowledge normally represents the interests
of the users. In our IRS, this knowledge must be learned
or discovered.
In our case, the similarity among the item properties and
the user preferences, or the estimation of the ratings for the
items, is the result of an inference process about the knowledge
Intelligent recommender systems
151
model used (for example, if the knowledge model is ontology,
then we can apply an ontological reasoning).
In general, our IRS must use the knowledge available in a
given moment without degrading its performance. That is,
depending on the application domain and the usage scenario,
may be only parts of the previous knowledge are available,
and the IRS must continue to carry out recommendations.
In this way, the deﬁnitions of the different types of knowledge
are very important, but our IRS is very robust in order to work
with the knowledge available. The main difference with the
Knowledge-based RS is that this requires knowledge engineer-
ing, and an IRS uses learning mechanisms from different
sources: product databases, social media, etc. Our system can
exploit the different techniques of machine learning, semantic
mining, in order to build the knowledge that is need. For
example, if the knowledge model is ontology, then we can
apply the merging and alignment of ontologies (two types of
semantic mining techniques) to enrich the model [24]. In this
way, our IRS avoids the problem of acquisition of knowledge
of the knowledge-based RS. Additionally, it has not the ramp-
up or cold-start problem because IRS can draw inferences
about the users or items, even when it has not yet gathered suf-
ﬁcient information. Its recommendations do not depend only
on the user ratings (case of collaborative RS), or on gathering
information about a particular user or item (case of content-
based RS), because it infers this information. We dedicate
the rest of this section to explaining this knowledge.
5.1. Extended user proﬁle
In this model, the knowledge about the users is deﬁned. This
model must allow for responding to queries such as (see
Table 2): Who is the person? What personal data are available?
How is his/her performance? What projects were assigned?
What tasks have been carried out? What skills has he/she?
Table 2 deﬁnes user proﬁles of IRS.
Some of this information is obtained by asking the users,
but some of it is obtained by learning approaches. For exam-
ple, the networks of friends can be obtained using social net-
work analysis [22], or the ideological trend using semantic
mining mechanisms.
5.2. Extended item proﬁle
In this model, we deﬁne the set of features that represent an
item. There are different types of characteristics that can
describe an item:
� General or objective characteristics, such as: functional
information,
structural
information,
descriptive
information.
� Speciﬁc or subjective characteristics, which can be: level of
use, score or rating, utility.
These characteristics can be represented by abstract con-
cepts or attributes that can be described by their properties,
which can be the following:
� Intrinsic or statics (own).
� Dynamics (changing properties).
In our case, we are going to characterize each item by four
(4) dimensions [11,14]:
� Descriptive: information about its intrinsic characteristics.
Answer the question: What is it?
� Structural: elements that compose the item (entities, attri-
butes, processes), relationships and constraints between
them, etc. It reﬂects the invariant structure. Answer the
question: What is its composition?
� Functional: speciﬁc functions of the items. Answer the ques-
tion: What does it do or allow?
� Operational: how it can be used, interacted with it, or inte-
grate with other systems. Answer the question: Can it be
used/reused?
Table 3 deﬁnes the different attributes that describe an item
in our system (the ﬁrst letter next to the item represents if the
attribute is static (I) or dynamic (D), and the second if the
attribute is Descriptive (D), Structural (S), Functional (F) or
Operational (O)):
Some of the subjective attributes are deﬁned here, but they
really belong to critical knowledge, because of a knowledge
based on the judgment of the users. In our case, this judgment
is inferred using reasoning mechanisms over the knowledge
stored and the transactional information of the users.
5.3. Context and domain knowledge
Two additional knowledge, to give more semantic information
to our IRS, are as follows:
– Knowledge about the context: in this case, it is necessary to
catch all information speciﬁc to the context in which the
recommendation is given (see Table 4).
– Domain knowledge: It is the valid knowledge used in a given
area of human activity, in a specialized discipline, etc. Nor-
mally, the experts use and develop their own domain knowl-
edge. In IRS, it refers to the speciﬁc area/domain where it
will be used.
Table 2
User proﬁle in IRS.
Personal data
Name, address, ID, Sex Age,
relationship status, personality
Physical features
Size, weight, physical defects
User type
Student, research, etc.
Languages
Some tastes, preferences
We can ask explicitly to the user,
but some of this information can be
inferred
Education
Level of the education: PhD, etc.
Occupation
Socio-cultural aspects
Behavior patterns, needs, cultural
behavior
Economics aspects
Income, buying habits, etc.
Political aspects
Ideological trend, etc.
Most inﬂuential sectors
Networks of friends, etc.
Technological skills
Intellectual capabilities
Projects developed
Positions held
152
J. Aguilar et al.
5.4. Critical model
The user’s behavior is modeled in order to determine his/her
preferences, opinions, trends, etc. [10]. The model represents
the opinions, critiques (see Table 5). Particularly, the user
opinion (critique) about the items recommended is stored,
as a result of an inference process, a learning process, a
calculation (estimation), or asking the users elicitation. This
model is navigated (it is the space of the critique to the prod-
ucts) in order to be used during the recommendation process
and represents the discovered preferences. In this way, the
IRS can recommend items that satisfy the ongoing critique,
are similar to the previous recommendation, satisfy the
majority of the previous critiques, etc. Our system infers
the user preferences and works through a cycle of recommen-
dations to build it.
6. Example of speciﬁcation of our IRS in an intelligent technique
One of the advantages of our system is that its implementation
can be carried out using any intelligent techniques. The intelli-
gent paradigm (ontologies, based on the evolutionary process,
etc.) can be chosen according to the source of information,
tools available, etc. In this Section, we give one example of
implementation based on the FCM.
6.1. Fuzzy cognitive maps
Cognitive Maps (CMs) are directed graphs that model a real
system as a set of concepts and causal relationships between
them [1–3]. Each concept is a node in the graph, and represents
a characteristic/state of the system. The causal relationships
are positive or negative signs, with speciﬁc weights. The value
of a node is the activation degree of a concept in a given time.
This value is deﬁned as the sum of all values of the concepts at
the preceding state and the incoming edges.
Speciﬁcally, a CM is deﬁned by n concepts (mathematically
is a n state vector A), and a n * n weighted matrix E. Each ele-
ment Eij of the matrix is the value of the weight between con-
cepts Ci and Cj (it measures how much Ci causes Cj). The
activation level Ai for each concept Ci is calculated by the
following:
Ai ¼ f
X
n
j¼1
AjEji
 
!
þ Aold
i
ð1Þ
Ai is the activation level of Ci at time t + 1, Aj is the activation
level of Cj at time t, Aold
i
is the activation level of Ci at time t,
and f is a threshold function. In this way, the new state vector
A is deﬁned by the change in the activation level of one con-
cept due to the other concepts. A CM starts with A0 = S0,
and repeatedly calculates Ai, until the system convergences
(for example, when Anew
i
¼ Aold
i ) or other stopping criteria.
The last value of the state vector A is the response to the ‘‘what
if” question [1–3].
CMs have been extended by Kosko, considering fuzzy logic
and neural network theories [2]. This approach has been called
FCM, and often is deﬁned by concepts that can be deﬁned as
fuzzy sets, and causal relationships between the concepts that
can be deﬁned by fuzzy implications. Also, the threshold func-
tion of the weighted sums can be fuzzy. There are different
learning algorithms for a FCM in the literature. There are
two examples of learning algorithms. One is based on the opin-
ion of the experts and another is based on the historical data.
In [1,3] an exhaustive presentation of different learning algo-
rithms is given.
6.2. IRS based on FCM
We propose a FCM based on two levels, the ﬁrst level contains
the concepts inferred, which represent the knowledge about the
critiques of the products, the preferences of the users, the rec-
ommendations, among other concepts. The second level repre-
sents the description of the current situation: the information
about the items and users, the context, etc. They are deﬁned
according to our models presented in Section 5. In this way,
the ﬁrst level is the knowledge generated by our system, which
can be used in different ways: to recommend, to discover infor-
Table 3
Item proﬁle in IRS.
General attributes
Subjective attributes
– Item ID (I, D)
– Name (I. D)
– Type of item (I, D)
– Description (I, D)
– Localization (I, D)
– Author of the item (I, D)
– Date of elaboration (I, D)
– Provider (I, D)
– Dimension(I,D)
– Version (I, D)
– Format (I, D)
– Components (I, S)
– Relationship between
components (I, S)
– Constrains (I, S)
– Technical Requirements
(I, S)
– Goal (I, F)
– Requirement cover (I, F)
– Level of use (D, O)
– Utility (D, O)
– Punctuation/Qualiﬁcation (D,
O)
– Type of Problems where can
be used (D, O)
– Reusability (D, O)
– Extensibility (D, O)
– Interoperability (D, O)
Table 4
Contextual Knowledge in IRS.
– Environmental conditions
– Space characteristics
– Time: current and historical
– Activities
– Resources and devices
– State
– Peoples
Table 5
Critical model in IRS.
Attribute
Critical type
Behavior patterns
Unit and compound critiques
Trends
Directional or replacement
Opinions
Directional or replacement
Preferences
Unit and compound critiques
Punctuation
Unit and compound critiques
Intelligent recommender systems
153
mation about the users, products, etc. The second level repre-
sents all the knowledge available in a given moment (see Fig. 2,
the FCM developed with the FCM Design tool [7]):
(a) First level:
In this level, there are concepts inferred from the concepts
of the second level or from concepts on the same level. Mainly,
they represent concepts linked to the recommendations (our
system can recommend different things, for example interest-
ing items, similar items), but additionally, other types of con-
cepts about information inferred about the products or items
(for example, users opinions, or punctuation of the item). In
general, the attributes of the critical model belong to this level,
and they reduce the space of candidate items. The concepts on
this level are deﬁned in Table 6.
(b) Second level:
In this level, the concepts represent the different attributes
of the user and item proﬁles, extended by the knowledge about
the context and domain (see Section 5). They are grouped
according to the knowledge that is represented (users, prod-
ucts, etc.).
The relationship between the concepts is according to the
causal relation between them. They determine the dependent
relationships among the concepts. In this case, the learning
process adapts the relationships among the concepts: deleting,
updating or adding. In this way, our FCM is reconﬁgurable
according to the quality of recommendations given.
Fig. 2 shows the initial FCM. In the ﬁrst level we can see
the concepts inferred listed in Table 6, as the preferences,
usability, Use Level (‘‘nivel the uso” in Spanish), etc. In the
second level the concepts are deﬁned in Section 5 about users
proﬁle deﬁned in Table 2 (Languages (‘‘idioma” in Spanish),
Sex, User type (‘‘tipo de usuario” in Spanish), etc.), and item
proﬁle deﬁned in Table 3 (Name (‘‘Nombre” in Spanish),
Localization, etc.), among others. The initial values of the arcs
have been deﬁned by a group of experts on learning resources,
and they have been adapted using the learning mechanisms of
the FCM Designer Tool [7].
Particularly, we can see that in FCM the similarity is
inferred due to the relationships between the concepts of the
item proﬁle and users proﬁle with the concepts inferred (in spe-
cial, with the ‘‘Item of interest” and ‘‘Item preferred by user”
concepts). The recommendation and preference concepts are
examples of elements of the critical model included in the
FCM model which are also inferred. In this way, all the ele-
ments of the different models are included naturally in the
FCM.
7. Case study
In this case study, we deﬁne an IRS of learning resources. In
Section 5 we have presented the general knowledge used by
Figure 2
Our multilevel FCM.
Table 6
Inferred concepts.
Item of interest
It refers to the usefulness of the item for the user
Punctuation
It refers to score or rating that a user provides to
the item
Item preferred
by user
It is the priority that a user has for the item
Preferences
It refers to user-deﬁned preferences based on its
proﬁle information
Use Level
Indicator of the user interaction with the item
Usability
It refers to the ease with which user can use the
item
Interoperability
It concerns whether the item can be integrated
into diﬀerent systems or platforms
Similar user
It concerns whether there are other users with the
same characteristics as the active user
154
J. Aguilar et al.
IRS. Now we need to customize the IRS based on FCM for
this domain.
7.1. Analysis of the user proﬁle of IRS of learning resources
We use the IMS standard, which describes the general infor-
mation to be collected about a student or a producer of learn-
ing content, to customize the user proﬁle [8]. The IMS Learner
Information Package (IMS LIP) speciﬁcation deﬁnes the inter-
operability of internet-based Learner Information systems,
with other Internet systems used by learning processes. Our
IRS must consider this information. The main aspects to con-
sider from the IMS standard are afﬁliations, competencies,
goals, identiﬁcations, interests, qualiﬁcations, certiﬁcations,
accessibilities, activities, and relationships.
We verify whether this information is included in the user
proﬁle deﬁned previously (see Table 7). In Table 7 we can
see that our proﬁle contains the main attributes of the IMS
LIP speciﬁcation and of the Reusable Deﬁnition of Compe-
tency or Educational Objective (RDCEO) speciﬁcation. The
RDCEO allows deﬁning competencies in the learning domain.
Any additional information to be included in our user proﬁle is
speciﬁed like part of the domain knowledge of the IRS. In our
case, initially we do not add more information. Finally, our
FCM will use the same set of concepts, see Table 7.
7.2. Analysis of the item proﬁle of IRS of learning resources
Based on the same idea of the previous Section, we need to
adapt the item’s proﬁle to the context of application of the
IRS. In this case, we need to compare the items to be recom-
mended for a standard in the domain of the Learning Resource
(LR). Speciﬁcally, we use the LOM-IEEE standard [11]. The
LOM-IEEE deﬁnes 9 categories: (a) General category (GC):
general information about the LR, (b) Lifecycle Category
(LC): metadata related to the history and current status of
the LR, (c) Metadata Category: information about the meta-
data itself, (d) Technical category (TC): metadata about the
technical requirements of the LR, (e) Educational category:
metadata for educational uses of LR, (f) Rights Category:
metadata about property rights and intellectual material, (g)
Relation Category: metadata used to establish relationships
between the LRs, (h) Annotation Category: annotations and
comments on the LR, and (i) Classiﬁcation Category: LR clas-
siﬁcation like taxonomies.
The general category of the LOOM-IEEE standard includes
nine types of metadata, such as: Identiﬁer (ID), Title, Lan-
guage, among others. The technical category includes Format,
Size, Location, etc. Educational category groups the metadata:
Interactivity Type (‘‘Active”, ‘‘Expositive”), LR Type (exercise,
simulation, questionnaire, slide, experiments, lecture, etc.),
Interactivity Level (low, high, etc.), Context, Difﬁculty, Typical
Learning Time, among others. For the rest, see [11].
Table 7
User proﬁle in IRS and IMS speciﬁcations.
Attribute
Standard
Personal data (name, id, sex, etc.)
IMS-LIP
Physical Features (physical disability)
User type
IMS-LIP
Languages
Some tastes, preferences (likes)
IMS-LIP
Education (academic degree)
IMS-LIP
Occupation
Socio-cultural aspects (behavior, behavior
patterns)
IMS-LIP
Economics aspects
Political aspects (context)
Most inﬂuential sectors (networks of friends)
IMS –
RDCEO
Technological skills
Intellectual capabilities(score intellectual)
IMS –
RDCEO
Projects developed
IMS-LIP
Positions held (employment performed)
Table 8
Item proﬁle in IRS and in LOM.
General attributes
Speciﬁc attributes
LOM
– Item ID (I, D)
– Identiﬁer (GC)
– Name (I. D)
– Title
– Title (GC)
– Type of item (I, D)
– Catalog entry (GC)
– Description (I, D)
– Description (GC)
– Localization (I, D)
– Location (TC)
– Author of the item (I, D)
– Manager/Artist/Composer
– Date of elaboration (I, D)
– Year of manufacture/production
– Provider (I, D)
– Dimension (size) (I,D)
– Longitude, latitude, Size
– Version (I, D)
– Model, language
– Version (LC)
– Format (I, D)
– Language (GC)
– Components (I, S)
– Structure (CC)
– Relationship between components (I, S)
– Relation category
– Rights category
– Constrains (I, S)
– Requirements, Installation Remarks
– Technical Requirements (platform,
– e-learning platform
– types problems) (I, S)
– Goal (I, F)
– Requirements cover (topic, career, area) (I, F)
– Course Area, Certiﬁcation, subject
– Educational category
Intelligent recommender systems
155
Now, we verify whether this information is included in our
item proﬁle, and the rest is included as part of the domain
knowledge model (see Table 8).
We can see that the IRS covers the main attributes of the
standard LOM, and any additional attribute of this standard
to be included is part of the domain knowledge. In our case,
we do not add additional knowledge.
In the Sections 7.1 and 7.2 we show two examples of imple-
mentation of the user and item proﬁles of our IRS model. In
this study case, we have used two standards of the domain
of learning to deﬁne these proﬁles: the LOM standard for
the item proﬁles, and the IMS standards for the user proﬁle.
We conﬁrm that the general user and item proﬁles deﬁned in
Section 5 are part of these standards. In this way, the FCM
implementation of the IRS deﬁned in Section 6 is correct.
8. Results and discussion
8.1. Experiments with the IRS based on FCM
In this section, we evaluate the capabilities of our FCM-based
IRS in terms of the learning methods and reasoning mecha-
nisms. In the previous sections, we have deﬁned the knowledge
models used by the FCM-based IRS. The knowledge model
based on FCM is deﬁned by the concepts that represent the
information about the users, items, domain, context and criti-
cisms (see Sections 5–7). In this section, we evaluate the learn-
ing and reasoning capabilities.
8.1.1. Learning process
This process is based on two steps:
1. Determination of the initial values of the weights: it
includes the assignment of initial values (weights) of the
relationships between concepts by human experts. The
assignment of the relationship weights is obtained from
the mean weights established by several experts (see [1,3]
for more details of this process).
2. Adjustments of weights based on initial experiments: using
the FCM generated in step one, we have taken a sample of
real examples in which we knew in advance for each case,
the students and the learning resources to recommend.
We have run our recommender system based on FCM,
and its results are compared with the real cases to determine
whether the weights given by the experts provide the desired
output, or whether it is necessary adjust them, in order to
obtain the desired output (see the details of this procedure
in [1,3]).
8.1.2. Inference process
Our RS can be used in two cases: to recommend an LR for a
given student, and to infer quality aspects in an LR. In this sec-
tion, we are going to test both capabilities. To recommend LR,
we only need infer concepts linked to preferences, and to infer
the quality of a learning resource, we only need infer concepts
linked to the characteristics of the learning resources (see
Table 9).
Additionally, the concepts about student and item proﬁles
to be used by the FCM, for the recommendation or inference
of the quality, are reduced (see Tables 10 and 11), considering
only those important for the recommendation, or the quality
of a LR. According to Tables 10 and 11, for the recommenda-
tion, the concepts linked to detailed information of an LR and
a student are not relevant to deﬁne preferences (they are
deleted); and for the inference of the quality, we delete the con-
cepts about the detailed information of the student, and the
information is not relevant for an LR, to determine their
usability and interoperability.
If we like to study the preferences (ﬁrst case), then we need
to keep all the student concepts, and some of the concepts
about learning resources (such as item ID, type, goal). The
attributes related to the educational characteristics of the item
are important in this case (see Table 11). To deﬁne the prefer-
ences of a student we need all of its concepts (see Table 10), but
to infer the quality of the learning resources only the student
concepts about its physical characteristics (sex, disability,
etc.) are of interest (see Table 10).
8.1.2.1. To recommend learning resources. Now, we present an
example of the FCM to recommend an LR. In this case, the
IRS infers whether a student is interested or not in an LR,
whether it has a preference for it, whether the LR is useful
for the student, etc. For this experiment, an example of the val-
ues of the student attributes is given in Table 12, and of the LR
in Table 13.
These values of the concepts are deﬁned at the beginning by
the users, according to the relationship between the user con-
cepts (architecture student) and the speciﬁc educational
resource (Construction). For example, the goal of the item is
according to the proﬁle of the student (for this reason, the con-
cept about ‘‘requirements cover” is 0.8), and the learning
resource can be used in different platforms; for this reason,
the value of the ‘‘constraints” concept is 0.8. In this way, we
deﬁne the initial values of the different concepts of the
FCM, and the FCM starts to iterate until its convergence.
We have used the FCM Designer Tool [7]. We have carried
out several recommendations for the same student and differ-
ent learning resources, and these results are shown in Table 14.
The FCM iterates, until the values of the inferred concepts
are stabilized. The ﬁrst column corresponds to the results of
the pair LR and student, of Tables 12 and 13. In this case,
the FCM iterates 10 times. In that example, we can see that
the values obtained for the inferred concepts indicate that
the LR is recommended (has a good punctuation and prefer-
ence), it should be useful for the student, there are similar stu-
dents that have used this LR, and the student will have a good
level of interaction with the LR. We can carry out a similar
interpretation of the concepts, for the rest of results.
Table 9
Inferred concepts in each case.
Item of interest
To recommend
learning resources
To infer the quality of a
learning resource
Punctuation
X
Item preferred
by user
X
Preferences
X
Use Level
X
Usability
X
Interoperability
X
Similar user
X
156
J. Aguilar et al.
Table 10
Concepts about students without impacts in each case.
Attribute
To recommend learning resources
To infer the quality of a learning resource
Personal data (name, id, sex, etc.)
Physical Features (physical disability)
User type
X
Languages
Some tastes, preferences (likes)
X
Education (academic degree)
X
Occupation
X
Socio-cultural aspects (behavior, behavior patterns)
X
Economics aspects
X
Political aspects (context)
X
Most inﬂuential sectors (networks of friends)
X
Technological skills
X
Intellectual capabilities (score intellectual)
X
Projects developed
X
Positions held (employment performed)
X
Table 11
Concepts about LR without impacts in each case.
General attributes
To recommend learning resources
To infer the quality of a learning resource
Item ID (I, D)
X
Name (I. D)
X
Type of item (I, D)
Description (I, D)
X
Localization (I, D)
X
Author of the item (I, D)
X
Date of elaboration (I, D)
X
Provider (I, D)
X
Dimension (size) (I,D)
X
Version (I, D)
Format (I, D)
X
Components (I, S)
X
Relationship between components (I, S)
X
Constrains (I, S)
X
Technical Requirements (platform, types problems) (I, S)
Goal (I, F)
X
Requirements cover (topic, career, area) (I, F)
X
Table 12
Input value of the student concepts.
Attribute
Student
Concept value
Personal data (name, id, sex, etc.)
Vannesa Alarco´ n, ID 3474342, female, etc.
1
Physical Features (physical disability)
Without physical disability
0.5
User type
Genius
1
Languages
Spanish, French, English
1
Some tastes, preferences (likes)
Painting, music, reading
1
Education (academic degree)
Student of Architecture
1
Occupation
Student
0.5
Socio-cultural aspects (behavior, behavior patterns)
Dance, walk, fans of social network
0.7
Economics aspects
Middle class
0.3
Political aspects (context)
Unknown
0
Most inﬂuential sectors (networks of friends)
Her parents, her friends of study
0.6
Technological skills
Programmer,
Intellectual capabilities (score intellectual)
Analytical, thinker
0.5
Projects developed
Design of a church
0.6
Positions held (employment performed)
Nothing
0
Intelligent recommender systems
157
8.1.2.2. To infer the quality of a learning resource. In this case,
we test the FCM to infer the characteristics of usability and
interoperability. An example of the input of the pair LR and
student is given in Tables 15 and 16.
This FCM can predict the characteristics of usability and
interoperability of a LR. This is an interesting use of the
FCM, in order to determine whether a LR can be interesting
for a given course (that can be very important in courses where
there are students with physical disability). For example, for
the case of the Tables 15 and 16, the ﬁrst column in Table 17
describes the inference. In this case, the FCM infers a high
usability and interoperability of the LR. Particularly, the
FCM infers the LR is easy to use for the students with the pro-
ﬁle of Table 15 (usability), and can be integrated into other
platforms (interoperability).
8.2. General result analysis
In the Section 8.1, we have evaluated the learning and reason-
ing capabilities of the FCM-based IRS. Particularly, the rea-
soning capabilities allow different types of inferences not
only to recommend but also to infer other types of information
such as the quality of the learning resource. With the models
and results obtained in Sections 6,7 and 8.1, we have evaluated
the entire FCM-based RS as an IRS.
Now, we compare the FCM-based IRS approach with
other knowledge-based RS. In order to determine the compar-
ison criteria, we deﬁne some questions about how the knowl-
edge is managed by the different approaches in the context
of learning resources. These questions are as follows: How
can our IRS be evaluated? How can we measure the quality
of the IRS? In general, we are going to use metrics that try
to determine how the knowledge in our IRS is exploited. For
this reason, we propose the next criteria [9,15]:
– Validity: if the RS gives explanations to allow users validate
the recommendation. For example, ‘‘I recommend this
house because you have four children. Because of the num-
ber of children, I cannot recommend a small apartment”.
– Comprehension: determines whether the explanations/rec-
ommendations are based on a deep knowledge about the
domain of interest.
– Efﬁciency: determines whether the RS reduces the decision-
making effort of the users. In our case, the interesting mea-
sure of efﬁciency is the cognitive effort.
– Persuasiveness: it determines whether the IRS can change
the behavior of the users. In this sense, recommendations
persuasively aim to change the user’s behavior.
Table 13
Input value of the learning resource concepts.
General attributes
Educational resource
Value
Name
Construction
1
Type of item
Video, book and slides
1
Description
This resource describes a
course about constructions of
churches
1
Constrains
Windows, Linux,
0.8
Technical Requirements
(platform, types
problems)
3K Ram, VLC tool, players,
OpenOﬃce, graphic processor
0.5
Goal
Bases about the construction of
churches
0.6
Requirements cover
(topic, career, area)
Technical drawing, calculation,
etc.
0.8
Table 14
Results of some recommendations of learning resources.
Attribute inferred
Recomm. 1
Recomm. 2
Recomm. 3
Recomm. 4
Item of interest
0.93422
0.93242
0.01451
0.64154
Punctuation
0.80453
0.89453
0.01385
0.45484
Preferences
0.88349
0.95136
0.10340
0.51858
Use Level
0.95364
0.86465
0.04256
0.39552
Similar user
0.83544
0.82345
0.12034
0.54321
Table 15
Student Concepts in the FCM to infer the charac-
teristics of usability and interoperability of a learning resource.
Attribute
Student
Concept
value
Personal data (name, id,
sex, etc.)
Vannesa Alarco´ n, ID
3474342, female, etc.
1
Physical Features
(physical disability)
Without physical
disability
0.5
Languages
Spanish, French, English
1
Table 16
Learning resource concepts in the FCM to infer the
characteristics of usability and interoperability of a learning
resource.
General attributes
Educational resource
Value
Type of item
Video, book and slides
1
Date of elaboration
Dec 2016
1
Provider
Heber Hoeger
1
Dimension (size)
10 Gb
1
Version
First version
1
Format
Pdf, ppt
1
Components
One part
1
Relationship between
components
Sequential
1
Constrains
Windows and Linux
0.8
Technical Requirements
(platform, types
problems)
3K Ram, VLC tool, players,
OpenOﬃce, graphic processor
0.5
Table 17
Results of some recommendations about the quality
of the learning resources.
Attribute inferred
Inference 1
Inference 2
Inference 3
Usability
0.89545
0.45633
0.09435
Interoperability
0.91322
0.34613
0.12322
158
J. Aguilar et al.
– Effectiveness: determines whether the recommendations
help users for making high-quality decisions.
– Transparency: if the RS provides information at the user to
understand the reasoning which it uses to recommend.
In this section we compare our IRS with other works, using
these metrics to determine how the knowledge is exploited in
each RS (see Table 18).
In general the IRS gives good results. It gives a good expla-
nation of its recommendations and advices based on its infer-
ence process (see Section 7.1) and its knowledge model about
the domain of interest (see Sections 5–7). Due to that this
information can persuade to the users in a transparent way
in order to help them in their processes of making decisions.
The only criterion where our IRS is not good is in efﬁciency,
because the user needs to customize the input and to interpret
the inference process of the IRS. The FCM-based IRS
increases the decision-making effort of the users that is due
to the technique used to test our IRS (FCM), and not to the
IRS framework, because the user needs to know the FCM the-
ory to understand the process followed by the RS.
The works [14,16] do not give explanations about their rec-
ommendations because their recommendations are not based
on a knowledge model. The work presented in [10] has the
same problem of efﬁciency as our work because it is based
on the same technique, but it has not a learning process and
the users must update manually the cognitive map (trans-
parency). Additionally, the knowledge model of [10] is very
simple. It does not consider aspect as the context and the crit-
icisms, and its user and item proﬁles are very simple. These
limitations in the knowledge model or the inexistence of the
knowledge model in [14,16], reduce their persuasive capabili-
ties and for the same reasons in some cases the recommenda-
tions do not help users for making high-quality decisions.
We like to highlight that [10] uses the same technique that
our example of IRS, but its knowledge representation is very
simple and has not a learning mechanism. Our IRS framework
introduces some aspects such as the knowledge representation,
the learning and the reasoning mechanisms, all of which
improve the recommendation process.
In general, the IRS framework is the only one that covers
the different criteria very well and the rest have problems,
because they are ambiguous in the inference process (trans-
parency), which impacts in the persuasion to users. Addition-
ally, our IRS can be used in different contexts.
The evaluation of Section 8.1 allows determining the
advantage of the different capabilities of an IRS (learn, reason,
etc.), and the comparison in this section allows determining the
advantage about how the knowledge is managed in our IRS.
These different comparisons and evaluations allow having an
entire idea of the interest of an approach as the IRS.
9. Conclusions
In this paper, we have presented a new type of RS, called IRS.
We have argued that an IRS framework improves the quality
of the recommendations due to its knowledge representation,
and its learning and reasoning mechanisms. The classical RS
have not all these characteristics simultaneously; for example,
[10] uses the same technique that we have used to implement
our example of the IRS, but in [10] it is deﬁned as a
knowledge-based RS. In the Section 8.2, we have determined
that our system has better behavior due to these characteristics
used simultaneously.
Our IRS allows navigating over knowledge in order to
exploit it. Additionally, our IRS can infer interesting informa-
tion, what is not traditionally deﬁned by classic RS, about user
preferences, critiques, etc. Our IRS can use the knowledge in
different ways (to explain, to persuade, to predict etc.), for dif-
ferent things (to infer or to recommend), in a transparent way.
Our IRS avoids some of the classical drawbacks in RS: it does
not have a ramp-up problem since its recommendations do not
depend on a base of user ratings, it does not require a knowl-
edge engineering process, and it does not have to gather infor-
mation about a particular user because its similarity judgments
are independent of individual tastes, etc. It is immune to statis-
tical anomalies because its recommendations are based on
knowledge, which is updated by learning mechanisms. The
IRS framework has a well-deﬁned knowledge model, which
considers knowledge about the users, items, domain, context
and criticisms. The learning mechanism allows update this
knowledge that initially is deﬁned using the context and
domain information, and is used in the ﬁrst inferences. Then
IRS exploits the knowledge extracted by the learning mecha-
nism particularly about the users to improve its performance.
The implementation of the IRS using FCM shows the ver-
satility of the framework. The main aspects that must guaran-
tee the intelligent techniques to be used to implement IRS, are
the capabilities of reasoning, representation of diverse knowl-
edge and learning. Particularly, the learning capability of the
FCM is used easily by the RS, and the reasoning is deﬁned
by the iterative process implicit in the FCM.
The criteria about the management of knowledge deﬁned in
Section 8.2, are well achieved by our approach. Our approach
obtains two types of results: qualitative (cognitive map) and
quantitative (inferences). With these results it meets the crite-
ria. [14,16] do not reach the validity and efﬁciency criteria
because they do not explain how the results are obtained and
Table 18
Comparison with other approaches.
Criteria
[10]
[14]
[16]
Our IRS
Validity
Not
Not
Not
Yes
Comprehension
Yes
Yes
Yes
Yes
Eﬃciency
Not
Yes
Yes
Not
Persuasiveness
Maybe
Maybe
Maybe
Yes
Eﬀectiveness
Sometime
Sometime
Sometime
Yes
Transparency
Yes
Not
Not
Yes
Intelligent recommender systems
159
the students/teachers must reason about why to use the learn-
ing resources recommended (the validity is not reached). Also,
[10,14,16] are not persuasive and effective due to the knowl-
edge model used which only cover partial information about
the students or learning resources or to the inexistence of a
knowledge model. This does not allow convincing a person,
because it is not possible to deﬁne arguments based on
knowledge.
Further works must test the IRS in other types of problems
with other intelligent techniques, like the ontologies, the fuzzy
logic, in cases which require large knowledge about the domain
and context. Also, more experiments are necessary to deter-
mine other uses of the knowledge stored by the IRS in the con-
text of RS (e.g., for diagnosis).
Acknowledgment
Dr. Aguilar has been partially supported by the Prometeo Pro-
ject of the Ministry of Higher Education, Science, Technology
and Innovation of the Republic of Ecuador.
References
[1] J. Aguilar, Different dynamic causal relationship approaches for
cognitive maps, Appl. Soft Comput. 13 (1) (2013) 271–282,
Elsevier.
[2] J. Aguilar, A Survey about fuzzy cognitive maps papers, Int. J.
Comput. Cognit. 3 (2) (2005) 27–33, Yang’s Scientiﬁc Research
Institute.
[3] J. Aguilar, Dynamic random fuzzy cognitive maps, Revista
Computacio´ n
y
Sistemas,
Revista
Iberoamericana
de
Computacio´ n 7 (2004) 260–271.
[4] M. Ayub, A. Cian, M. Caliusco, E. Reynares, Developing an
ontology-based
team
recommender
system
using
EDON
method: an experience report, SADIO: Electron. J. of Inform.
Operat. Res. 13 (2014) 1–13.
[5] R. Burke, Integrating Knowledge-based and Collaborative-
ﬁltering Recommender Systems, AAAI Technical Report WS-
99-01, pp. 69–72.
[6] R. Burke, Knowledge-based recommender systems, in: A. Kent
(Ed.), Encyclopedia of Library and Information Systems, 69
(32), Marcel Dekker Publisher, 2000.
[7] J. Contreras, J. Aguilar, The FCM designer tool, in: M. Glykas
(Ed.),
Fuzzy
Cognitive
Maps:
Advances
in
Theory,
Methodologies, Tools and Application, Springer, 2010, pp. 71–
88.
[8] IMS Global Learning, <http://www.imsglobal.org/cc/index.
htm>.
[9] D.
Jannach,
M.
Zanker,
A.
Felfernig,
G.
Friedrich,
Recommender
Systems:
An
Introduction,
Cambridge
University Press, New York, 2011.
[10] W. Liu, L. Gao, Recommendation system based on fuzzy
cognitive map, J. Multimedia 9 (7) (2014) 970–976.
[11] LOM-IEEE standard. <http://ieeeltsc.org/wg12LOM/>.
[12] B. Ojokoh, M. Omisore, O. Samuel, T. Ogunniyi, A fuzzy logic
based personalized recommender system, Int. J. Comput. Sci.
Inform. Technol. Secur. (IJCSITS) 2 (5) (2012) 1008–1015.
[13] K. Palanivel, R. Sivakumar, Fuzzy multicriteria decision-
making approach for Collaborative recommender systems, Int.
J. Comput. Theory Eng. 2 (1) (2010) 57–63.
[14] A. Rodriguez, J. Gago, L. Rifo´ n, R. Rodrı´guez, A recommender
system for non-traditional educational resources: a semantic
approach, J. Univ. Comput. Sci. 21 (2015) 306–325.
[15] F.
Ricci,
L.
Rokach,
B.
Shapira,
P.
Kantor
(Eds.),
Recommender Systems Handbook: A Complete Guide for
Research Scientists and Practitioners, Springer, New York,
2011.
[16] L. Rifon, A. Canas, V. Roris, J. Gago, M. Iglesias, A
recommender system for educational resources in speciﬁc
learning
contexts,
in:
8th
International
Conference
on
Computer Science & Education (ICCSE), 2013, pp. 371–376.
[17] E. Stuart, N. Shadbolt, D. De Roure, Ontological user proﬁling
in recommender systems, ACM Transact. Inform. Syst. 22 (1)
(2004) 54–88.
[18] R. Sikka, A. Dhankhar, C. Rana, A survey paper on e-learning
recommender system, Int. J. Comput. Appl. 47 (2012) 27–30.
[19] L. Tera´ n, SmartParticipation: A Fuzzy-Based Recommender
System
for
Political
Community-Building,
Springer,
Switzerland, 2014.
[20] C. Tsai, H. Chuang, The role of cognitive decision effort in
electronic commerce recommendation system, Int. Schol. Sci.
Res. Innovat. 5 (10) (2011) 36–40.
[21] A. Almahairi, K. Kastner, K. Cho, A. Courville, Learning
distributed
representations
from
reviews
for
collaborative
ﬁltering, in: 9th ACM Conference on Recommender Systems
(RecSys ’15), 2015, pp. 147–154.
[22] J. Neidhardt, R. Schuster, L. Seyfang, H. Werthner, Eliciting the
users’ unknown preferences, in: 8th ACM Conference on
Recommender systems (RecSys ’14), 2014, pp. 309–312.
[23] C.
Mediani,
M.H.
Abel,
Semantic
recommendation
of
pedagogical resources within learning ecosystems, in: 2016
International
Conference
on
Industrial
Informatics
and
Computer Systems (CIICS), 2016, pp. 1–5.
[24] M. Mendonc¸ a, N. Perozo, J. Aguilar, An approach for multiple
combination
of
ontologies
based
on
the
ants
colony
optimization
algorithm,
in:
Asia-Paciﬁc
Conference
on
Computer Aided System Engineering (APCASE), 2015, pp.
140–145.
160
J. Aguilar et al.
