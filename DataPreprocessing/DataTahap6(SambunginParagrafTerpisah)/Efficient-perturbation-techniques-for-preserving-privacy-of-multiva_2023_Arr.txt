The remaining portion of this paper is organized as Section 2 summarizes the existing work which are related to this research work. Section 3 represents the overview of perturbation techniques. The metrics used for analyzing privacy and utility are discussed in Section 4. In Section 5, the proposed approaches NOS2R and NOS2R2 are de- scribed. Section 6 represents the experimental analysis and provides a comparative analysis of the performance. In the last section, our research work is concluded.

dispersing the burden of privacy preservation across a dispersed ecosys- tem with resource-constrained devices and high-performance comput- ers, taking advantage of the asymmetry of resources. But this work has a limitation i.e. it works only for horizontally partitioned data. So when some vertically partitioned data appears, this method cannot maintain the utility and privacy trade-off.

For sensitive data mining, a method called NRoReM is proposed by Paul et al. in [5]. This data perturbation approach consists of four stages. At first normalization, secondly geometric rotation, then linear regression, and finally scalar multiplication was followed. The exploratory study of privacy protection, attack resistance, information entropy analysis, data utility, and error analysis reveals that NRoReM protects individual privacy as well as data utility on a greater level. However, when scalar multiplication is used for better privacy, the size of the data set is altered, which sometimes results in a decrease in utility in some cases.

A method for protecting privacy is represented in [24] which is based on distance matrix. Its aim is to secure common comparable data that is disseminated among many organizations. In circumstances where the amount of data in each organization is limited and the data bias is substantial, the suggested method robustly integrates scattered data that is of the same quality as linked raw data. Furthermore, this proposed method can be used with data that has been corrupted by noise. Even after introducing noise, the statistics of the original data could still be calculated which is a threat and it necessitates a more robust method of privacy protection.

The paper [27] introduces a Bayesian-based PPDM approach for classification. This method is a data perturbation method which is algorithm-independent, implying that the perturbed data can be used directly by traditional classification methods. Experiments show that this strategy is effective at securing privacy while maintaining data utility. A semi-supervised privacy-preserving clustering approach is proposed in [28]. The method of this study learns a large margin nearest cluster metric using convex optimization utilizing a limited quantity of supervised data. The method then applies multiplicative perturbation on the original data based on the learned metric, which might change the distribution shape of the original data and therefore protect privacy information while assuring good data usability. Despite that, the inner-site sharing of the LMNC (Large Margin Nearest Cluster) metric within the distributed system, any site that acquires access to the modified data of others is endowed with the capacity to retrieve the corresponding original data.

degrees respectively. So erroneous or faulty value of these parameters can still affect the balance between privacy and utility. The k-means technique is utilized in [30] to propose a Reversible Privacy-Preserving k-means Clustering (kRPP) algorithm that protects the clustering in- formation of a data set. When the noise ratio or noise offset ratio is increased, the inserting noises to a cluster with a minimal total distance in the kRPP method has no significant effect on centroids movement.

makes use of rotation and condensation characteristics. In one version of this method, kmeans was used. This kmeans algorithm delivers better utility, but sometimes privacy suffers and attack resistance declines. A non-reversible perturbation method namely PABIDOT is proposed in [3] that uses optimal geometric transformation for privacy preser- vation of huge data. It uses multidimensional geometrical alternation, reflection, translation, and rotation to disrupt a data set, followed by randomized expansion and random tuple shift out.

In [33], the authors proposed a new data perturbation algorithm, SEAL (Secure and Efficient data perturbation Algorithm utilizing Lo- cal differential privacy) which relies on Chebyshev interpolation and Laplacian noise. SEAL offers a fair balance of privacy and utility with high efficiency and scalability. In [34], the sensitive information of individuals is perturbed via a fuzzy data transformation technique. The technique uses a fuzzifier to transform linguistic data from crisp values so that the inference engine can compare them to the fuzzy rules which had already been stated. Then using a defuzzifier, perturbed data is then translated from the generated linguistic values to crisp values. In this approach, while perturbing the data, privacy is preserved, but the utility can be neglected.

The authors of [36] discussed a method called value swapping. There exists no erroneous information as a result of value swapping. While retaining data set wise properties, methods like value swap- ping [36], condensation [19], random projection [35] and additive noise [6] sacrifice the secrecy of individual records by substituting sensitive information with less sensitive records.

Most of the existing methods still lacks in balancing the privacy and utility. Still a trade-off between utility and privacy has been noticed. In our work, the two proposed approaches follow a combination of normalization and some different transformations. When undergoing these various transformations, normalization aids in maintaining the

Perturbation approaches are commonly evaluated using two types of metrics: privacy metric and data utility metric. The most effective perturbation strategies aim to protect privacy and also maintain data utility. As described below, we have employed different criteria to quantify data utility and privacy in this study.

We have studied the privacy-preserving performance of NOS2R and NOS2R2 utilizing the metrics which were described in Section 4.1. Again an increase in information entropy and ICA attack analysis [41] was evaluated to measure its privacy-preserving capabilities. The pro- posed NOS2R and NOS2R2 approaches are mostly related to NRoReM in secrecy levels between 3DRT, NRoReM, NOS2R and NOS2R2 are significant. We can conclude from the Friedman Mean Rank (FMR) data that NOS2R offers better secrecy than 3DRT and NRoReM. And NOS2R2 provides the greatest secrecy level. As reported by our study, both NOS2R and NOS2R2 offer better secrecy across all the data set compared to NRoReM and 3DRT. Even NOS2R2 provides higher secrecy than our proposed first method NOS2R. So our proposed both methods

There are various sorts of attacks which are addressed against data perturbation methods. One of the attacks is Independent Component Analysis (ICA), which aims to recreate the original data from the altered data [41]. The attack resistance of NOS2R and NOS2R2 is evaluated against an ICA attack because it is based on matrix multiplication. When there is a bigger difference between the altered and actual data, the ICA attack becomes more challenging.

0.000055 respectively, where p demonstrates the significance of the variations in ICA attack resistance among all the methods. According to our analysis, NOS2R offers 33% higher resistance against ICA attack than 3DRT and 11.5% higher resistance than NRoReM. And NOS2R2 is the most resistant method against ICA attack. NOS2R2 is 39.2% more resistant to ICA attack than 3DRT and 15.5% more resistant against ICA attack than NRoReM. So our proposed both methods work better than the existing 3DRT and NRoReM approach. And among all the methods NOS2R2 method is superior in case of attack resistance.

three metrics, for 80% the data set, NOS2R protects more privacy than 3DRT and NRoReM; NOS2R2 offers more privacy for all the data set. Again, using four metrics among those five demonstrate that NOS2R and NOS2R2 provide higher level of privacy for 70% the data set and 90% the data set respectively than both existing approaches which we have used in this study. Moreover, NOS2R2 is compared against 3DRT, NRoReM and NOS2R.

From this accuracy difference, it can be said that the accuracy of NOS2R is 28.62% closer to the original data than 3DRT and 16.81% closer than NRoReM. As well, NOS2R2 is 50.5% closer to the original data than 3DRT and 42.32% closer than NRoReM.

increases privacy to a significant level. Then the results of the proposed methods are compared with the other existing methods. And the pro- posed two methods provide better results than the existing methods. NOS2R and NOS2R2 perturbation approaches maintain data utility and preserve individual privacy on a larger scale for 90% data set. However, the work proposed in this paper can be well extended with feature reduction in multiparty clustering scenarios.

