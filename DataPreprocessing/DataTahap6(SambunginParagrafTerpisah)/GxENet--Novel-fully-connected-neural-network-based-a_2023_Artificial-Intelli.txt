Food crop production faces impending challenges in feeding the global population, including increasing population, reduction in agricul- tural inputs, and global climate change. These challenges have led to global problems in food security. Around 85 million more people were facing a severe food crisis in 2021 compared to what was reported in 2016, which resulted in around 193 million people facing severe hunger across 36 countries (FAO, 2022). This crisis has been worsened recently both by human made and natural phenomena such as domestic food price inflation, war and pandemic (FAO, 2022; World Bank Group, 2022; UN World Food Programme, 2022; Kakaei et al., 2022). To address this problem, we need to produce more food with the limited resources available by creating improved varieties of crops that can perform well in different environments.

A genotype of a crop organism is its complete set of genetic makeup that influence its traits. However, a genotype often refers to genes that have different alleles. Thus to avoid confusion, we will refer genotypes as lines in the rest of the article. To create a new variety from lines with improved traits, we need to consider a line's genetics and its inter- action with the environment where it is sown (Washburn et al., 2021; Lin et al., 2020). This phenomenon is known as genotype by environ- ment interaction (GxE), which refers to the fact that even if a variety produces the desired values of quantitative traits in one environment, it may not provide us with the same outcome in another environment (Lenz et al., 2017). Thus, any tools that are developed to aid in crop breeding need to replicate the impact of GxE within the model by incor- porating genetic and environmental information. In this work, we aim to build such computational tools that estimate a trait even before sow- ing the crop.

et al., 2019). The main building blocks of deep learning models are arti- ficial neural networks, such as fully connected neural networks (linear layers), recurrent neural networks and convolutional neural networks. Each deep learning model has at least one input layer, more than two hidden layers of neural networks and an output layer. The input and output of the neural networks are the neurons, where the input layer neurons are the input features such as genetic marker data or environ- ment variables. The input to the hidden neural networks are the features from the previous layer and produce a learned feature repre- sentation as the output by applying some functions, based on the type of employed neural network. Finally, the output layer takes the output of the last hidden layer as the input and employs the neural network functions to make the final prediction. In this work, all our proposed frameworks employ fully connected neural networks where each neu- ron in a hidden layer is the linear function of all neurons of the previous layer. Thus each neuron of the current layer represents summarized in- formation of all previous neurons.

The weather data for each site-year is collected from the CIMMYT dataverse from 1990 to 2018 containing all locations of International Wheat Improvement Network (IWIN). The weather data contains 769 locations along with nine weather variables of each location such as the hourly average amount of precipitation, maximum relative humid- ity, minimum relative humidity, shortwave radiation (MJ/m2/d), max- imum and minimum temperature (C), maximum vapour pressure deficit (kPa), 2 m wind speed (m/s) and 10 m wind speed (m/s). Although the sowing date of crops are recorded in entirety, there are many missing values for when the crops are harvested; hence, we con- sider nine months of environmental data as the input to the machine learning model. The nine months period starts at least two months before the sowing date to capture the environmental effect on the soil before sowing (as the sowing date is available), and the following seven months are considered as the growing season. A monthly average of all the weather variables for each of the nine months variety of information. Data also differs from trial cycle to trial cycle. This data contains information such as how much and which fertilizer is applied, disease development information, number of irrigations be- fore sowing, moisture available before sowing, major weed species, soil aluminum toxicity and many more. Though our aim was to collect information before sowing, we are unable to verify that all the informa- tion in this data is taken before sowing.

For each previously created partitions, we also randomly sample some locations with 85% probability that the location will be in the training set and 15% probability that the location is in the test set. In this scenario, if the location is in the test set, we did not include any of the site-year data for that location in the training set or validation set. Although most of the lines in the test set were sown in other site- years, the training set also does not contain the 15% lines separated for testing in the previous step. Thus there may be some lines in the test set that are not present in the training data. As the model did not observe the test locations in training data, we will refer this test case as environment unobserved scenario or test scenario two. Finally, the training-test partitioning strategy creates two test scenarios for each partition: i) no lines in the training set are also in the test set, but the test set and training set may contain different lines grown in the same environment, and ii) the training data and the test data do not contain any locations in common, but the training set may contain information on how some lines performed in other site-years.

Research shows that some markers contribute towards yield irre- spective of the environment (Lenz et al., 2017). Also, some specific markers contribute more in a specific condition. For instance, Lenz et al. (Lenz et al., 2017) demonstrated that selecting the top 250 previ- ously known important markers of black spruce results in the same correlation coefficient score obtained by randomly selecting 4993 markers. They also observed that selecting fewer than 500 markers randomly decreases the correlation score between the predicted traits and the true traits. When the important markers are not known, previous research shows that feature selection methods were able to identify biologically and statistically significant markers for yield prediction (Jubair et al., 2021). Thus by applying feature selection, we aim to identify important markers irrespective of any environment (global marker set) as well as markers that play an essential role in a specific condition (local marker set).

In our proposed architecture, we first learn representations of geno- typed data and environmental variables separately. These two models are optimized to predict the average yield over environments and geno- types, respectively. We then concatenate these two representations and predict the environment-specific yield for a specific line assuming that markers and environments work as two groups and one group has an effect on another group for environment specific yield prediction of each line.

ii) optimized for predicting average yield over all lines for an environ- ment (environment-specific average yield). The first step for predicting line-specific average yield is to identify the global marker set by apply- ing the procedure described in section 2.4. After obtaining the global marker set, a neural network model is trained with this marker set as features to predict the line-specific average yield. The last layer before

The input to the second representation learning model optimized for predicting environment-specific average yield is nine months of envi- ronmental variables for each site-year. This model produces a represen- tation of a 54-dimensional vector for each input for the environmental variables. After training and testing these two models, for each site- year, the representation vectors of these two models are concatenated, which serve as the input to the deep regression model that predicts yield for each site-year. This framework will be referred to as F2. Now, we describe the architecture of each of the models of F2 individually.

model (Rezayi et al., 2022) is employed to obtain a representation of soil and environment-related text. A 768-dimensional representation is obtained for all texts and then an average representation is calculated for each site-year. The length of all individual notes are <256 tokens. As the maximum length of texts of the agribert model is 512 tokens, it can obtain the representation of the full note. This 768-dimensional vector is also concatenated with the output of two representation learning models and provided as the input to the shallow model.

We experimented with three deep learning models in deep learning framework 1 (F1M1, F1M2 and F1M3), where these models differ pri- marily on how the environment and genotype interactions are cap- tured within the model. In the F1M1, the assumption was that all genomic and environmental factors interact with each other at the same time. On the other hand, in the F1M2, the assumption is that each marker separately interacts with the environment first, and the resulting outcome then affects yield. Finally, in the F1M3, the re- lationship between markers is first taken into account, and then the environment interacts with the combined marker relationship to es- timate yield.

before sowing crops. In the third month, maximum vapour pressure contributes more than any other environmental variables for predicting average yield. We observe this trend for maximum vapour pressure for the rest of the months of the growing cycle except the fifth month, where shortwave radiation contributes more than the vapour pressure. The effect of shortwave radiation increases significantly in the fourth and fifth months, and then goes down gradually. In the third month, the importance of precipitation and maximum vapour pressure in- creases as we enter the months when seeds are sown. The maximum temperature has a continuous positive effect from the fifth month to the end of the growing cycle. Both wind speed variables have little to no impact from the third month to the end.

On the other hand, only 6.2% observations (6961 observations) are from HRWYT nurseries, where the crop gets rainfall during the cropping cycle. Since the environmental condition of the WYCYT nursery is mixed, we can not verify the amount of rainfall those nurseries received. However, WYCYT nurseries are only contributing to about 3.8% of the data.

predicting line specific average yield and environment specific average yield and then combines these two representations to estimate environment-specific yield for a specific line, is slightly better than the others. This framework shows 1.95 to 1.75 times better performance, depending on the test scenario, than some existing deep learning models. Later, we extend the F2 framework by integrating text data from field notes.

In this dataset, we do not have any information on the soil. As some research shows that soil plays a vital role in yield (Washburn et al., 2021), adding soil information to the model may help estimate yield more accurately. We showed that our F2 framework could easily be ex- tended by adding new information as we extended the F2 framework by adding field notes. While devising these frameworks, we assumed that the weather of the growing season can be predicted ahead of time. Thus our models focus on only estimating the traits of the crops by using a representation of the weather during the growing season. Fu- ture work should incorporate weather prediction for the growing sea- son from historical weather. While obtaining the representation of the weather variable, the input to the model was the monthly average of weather variables. Future work should also try to determine the effect of incorporating weekly or daily weather variables as the input to the model.

Finally, our F2 framework performs well in two test scenarios where the first test scenario is more straightforward to predict than the second one. In the first test scenario, we predicted yield in a scenario where en- vironments are observed, but lines are not observed in any of the envi- ronments during the training of the model. In the second scenario, locations in test sets are not observed but the model may observe lines during training. All the models have better performance in the first test scenario compared to the second one. The result is understand- able as the attribution score obtained by employing DeepLift shows that weather variables play a significant role in estimating yield.

