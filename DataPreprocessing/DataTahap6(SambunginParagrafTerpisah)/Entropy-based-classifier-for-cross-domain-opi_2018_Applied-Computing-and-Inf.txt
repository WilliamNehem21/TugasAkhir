Opinionated text has created a new area of research in text analysis. Traditionally, fact and information-centric view of text was expanded to enable sentiment-aware applications. Nowadays, increased use of the Internet and online activities like ticket book- ing, online transactions, e-commerce, social media communica- tions, blogging, etc. has led to the need for the extraction, transformation and analysis of huge amount of information. There- fore, new approaches need to applied to analyze and summarize the information [14].

Opinion mining is constantly growing due to the availability of views, opinions and experiences about a product/service online, as people are shedding their inhibition to express their opinions online. However, automatic detection and analysis of opinions about products, brands, political issues, etc. is a daunting task. Opinion mining involves three chief elements: feature and feature-of relations, opinion expressions and the related opinion attributes (e.g., polarity), and feature-opinion relations. An opinion lexicon is a list of opinion expressions or a set of adjectives, which are used to indicate opinion/sentiment polarity like positive, nega- tive and neutral. This lexicon arises from synonyms in the Word- Net, while antonyms are used to expand lexicon in the form of graphs. Such a dictionary-based approach has been used to par- tially disambiguate the results of parts of speech tagger. Further, fuzzy logic is used to determine opinion boundaries and to adopt syntactic parsing to learn and infer propagation rules between opinions and features [24,13].

The rest of the paper is structured as follows. In Section 2, we describe the related work on domain adaptation approaches. In Section 3, we introduce our new improved entropy based semi- supervised approach. In Section 4, we evaluate our approach using cross-domain sentiment classification tasks, and compare it with other baseline methods. Finally, in Section 5 we draw conclusions on the proposed approach and set directions for future work.

The main aim of domain adaptation is to transfer knowledge across domains or tasks. Tagging the opinion word and building a classifier is time consuming and expensive, as opinions are domain dependent. Normally, users express their opinions specific to a particular domain. An opinion classifier trained in one domain may not work well when directly applied to another domain due to mismatch between domain-specific words. Thus, domain adapta- tion algorithms are extremely desirable to reduce domain depen- dency and labeling costs. Sentiment classification problem are considered as a feature expansion problem, in which related fea- tures are appended to reduce mismatch of features between the two domains. To overcome this problem, sentiment-sensitive the- saurus, which contains different words and their orientation in dif- ferent domains, has been created. Bollegala et al. [7] used labeled, as well as unlabeled data, for evaluation. The results suggested that method performs significantly well compared to baseline.

Identification of feature and weighting is an important step in opinion mining. Khan et al. [12] proposed a new approach that identified features and assigned term label using SentiWordNet. In this method, point wise mutual information and chi square approaches were used to select features to SentiWordNet that were weighted. Support vector machine was used as classifier. Experimental evaluation on benchmark dataset shows effective- ness of approach.

Sparseness is another issue in short text data. Word co- occurrence and context information approaches are generally used for solving sparseness issue. These approaches are less efficient. To address this problem, Chutao et al. [32] considered probability dis- tribution of terms as the weight of terms.

Similar to ensemble classifiers, graph-based methodology are also used for domain adaptation. Dhillon et al. [25] proposed the graph-based domain adaptation method. Similarity graphs were constructed between features from all domains, if these features were similar then it demonstrated the presence of edge between

Training and testing data from same feature space and same distribution has been reported to give good results for machine learning algorithms. Estimating the effect of distribution changes through statistical models is reported to be very expensive, as it has to be rebuilt from scratch. In many real world applications, it is expensive or impractical to recollect the needed training data and rebuild the models. In such cases, domain adaptation or trans- fer learning between task domains would be desirable.

The variation of opinion found for the same word in different domains restricts the usage of generic lexicons as it generalizes the polarity of a word. Therefore, lexicons with updated polarity values that can give polarity of a same word in different domains using same lexicon database will have to be built. The proposed work attempts in building such an enhanced polarity lexicon using the maximum entropy algorithm with modification being made in increment quantity which helps in refining the classification gran- ularity from document to word level. The knowledge gained from one domain is used to predict and classify the polarity of opinion words from another domain, resulting in an improved lexicon using semi-supervised approach. The common words from all domains having same polarity orientation are treated as domain- independent words and remaining as domain-specific words.

Domain adaptability is a major issue in sentiment analysis or opinion mining, which has been addressed in the proposed frame- work. There are many resources and training corpora available in English with proven results. A proposed model will be trained from a training dataset, which will be used for sentiment classification. SentiWordNet resource will be used for this research as it is a pub- licly available for opinion lexicons with polarity.

An opinion lexicon is one or more words with positive or nega- tive orientation. Lexicons are used when no training data are avail- able because the training data contain prior knowledge about the sentiment of a feature. It is a vital component of unsupervised sen- timent classification methods. The construction of a large sized lex- icon is an expensive and time-consuming task. Hence, building automated methods that influence existing resources to expand existing lexicons are needed.

tive, adverb, verb, etc. are extracted using the parser. Parsing is a vital step as it gives opinion words as an output. Sentence parsing involves assigning different parts of speech tags to a given text. This process is known as Part-Of-Speech (POS) tagging. For infor- mation extraction, POS tagging is important because each category

Adjectives and adverbs are good indicators of opinion, hence are extracted from each review. Some verbs are also considered as opinion, e.g., like, love, recommend, etc. Two consecutive words, i.e., adverb-verb, adverb-adjective also extracted from processed tagged reviews as a verb alone does not indicate opinion. Nouns are not considered in framework.

The dataset from John et al. [6] was used for experiments. It contains a collection of product reviews from Amazon.com. This dataset contains three types of files positive, negative and unla- beled in XML format. Each line in form of: feature:<count>  fea

Baseline methods use in this study are Feature Ensemble plus Sample selection (SS-FE) [27], Spectral feature alignment (SFA) [23], and Supervised word clustering (SWC) [20]. SFA achieved was between 72.5% and 86.75%, SS-FE was between 72.94% and 84.87% and SWC was between 72.11% and 85.33%, whereas accu- racy of proposed algorithm was between 70% and 88.35%.

Accuracy is used as an evaluation measure. Accuracy is the pro- portion of correctly classified examples to the total number of examples; on the other hand, error rate refers to incorrectly classi- fied examples to correctly classified examples. F-measure or preci- sion and recall can be used as evaluation measures.

tronics, kitchen and DVD domains are compatible with each other due to their more similar features. In general, the features of these three domains are more or less similar. Also kitchen as source and electronics as target and vice versa gives better accuracy as both domains share more common features. Kitchen appliances domain also shares electronics appliances; hence, major information of both domains is similar. But kitchen as source and DVD as target does not give good results for both labeled and unlabeled dataset, because kitchen and DVD are not similar to each other, as that of kitchen and electronics. Usually, if two domains are more similar then a number of features transferred from source to target are also more because source data is used as training dataset and tar-

get features are derived from it. The impact of unlabeled target data is more than that of labeled target data. It states that unla- beled target data can be used for the accuracy gain, as well as reduce the annotation cost significantly.

As compared to baseline methods, moderate accuracy was achieved by the proposed method. Relatedness between source and target domain is important factor in domain adaptation. Also for unlabeled target dataset better accuracy was achieved. It means that it can significantly reduce the annotation cost also. F-measure is also taken as evaluation measure which shows better results of proposed framework over base line methods. But it does not con- sider the true negative features. Some domains are not compatible over baseline approach as the proposed framework emphasizes on granularity of the word. This is the major change in classifier in comparison to traditional approach. Importance of each word that has more impact on results of classifier was classified. Testing of approach carried on Amazon cat6 dataset, which shows a signifi- cant improvement in accuracy ranging from 3 to 6 points com- pared to dataset from Blitzer. In comparison to SVM and Navie Bayes, we have proposed an algorithm that could provide better accuracy. It shows that relatedness between domains is a major factor for effectiveness of domain adaptation.

In the proposed system, bipartite graph clustering was used to reduce the mismatch between domain specific words of source domain and target domain. Domain-independent words were used to cluster domain-specific words from source and target domains. To train classifier for target domain, clustering was used as it reduced the gap between domain-specific words of different domains. Future studies can be taken up to determine the co- clustering of words and documents from different domains. The proposed system focuses on only words, in future non-word fea- tures like the age of document, the recommendation counts of doc- ument can be considered. At present, framework considers only unigrams and reviews are in English language. Also in future this work can be extended for other languages as well as n-grams.

