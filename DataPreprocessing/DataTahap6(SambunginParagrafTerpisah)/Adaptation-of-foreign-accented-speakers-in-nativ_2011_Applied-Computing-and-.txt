Abstract This paper addresses the adaptation of Arabic speech recognition (ASR) systems to foreign accented speakers. This adaptation is accomplished by using the adaptation techniques; namely, the Maximum Likelihood Linear Regression (MLLR), the Maximum a posteriori (MAP), and the combination of MLLR and MAP. The LDC-WestPoint Modern Standard Arabic (MSA) cor- pus and HTK toolkit were used in implementing all experiments. The systems were evaluated using both word and phoneme levels. Results show that unique MSA Arabic Phonemes such as pharyngeal and emphatic consonants, which are difficult to pronounce for non-native speakers, benefit from the adaptation process using MLLR and MAP combination. An overall improvement of 7.37% has been obtained. This opens the eyes in benefiting from adaptation tech- niques in overcoming the difficulties of pronouncing nonnative language pho- nemes.

Characteristics of a second, non-native language are largely influenced by the first (native) language. As a result, the performance of automatic speech recognition systems, usually trained by native speakers, often degrades when they are used by non-native speakers. This is mainly due to both acoustic and phonological dif- ferences between accents (Hang et al., 2000; Zheng et al., 2005). These differences are not only due to different phoneme inventories of the languages, but even for the same phoneme, non-native and native speakers pronounce different sounds. The modeling of separate accents remains difficult and inaccurate due to the large number of non-native accents and to the insufficiency of non-native speech data available for training. It is the reason why many studies propose to adapt native phoneme models to accented phoneme models using first language data. Numer- ous studies have been carried out to improve the automatic recognition of speech uttered by non-native speakers.

Bartkova and Jouvet (2004) proposed multiple models for improved speech rec- ognition of non-native French speakers. They addressed the problem of foreign accent by using acoustic models of the target language phonemes (French pho- nemes in their case) adapted with speech data from three other languages: English, German, and Spanish. Their results obtained for 11 language groups of speakers showed that error rate can be significantly reduced when standard acoustic models of phonemes are adapted using speech data from other languages. In their outputs, the highest error rate reduction of 40% was obtained on English native speakers. They improved the recognition performance on almost all language groups, even though only three foreign languages were available in their study for acoustic model adaptation.

The research on Arabic language mainly focuses on Modern standard Arabic, which is used throughout the media, courtrooms and academic institutions of the Arabic countries. Previous work on developing ASR was dedicated to dialectal and colloquial Arabic within the 1997 NIST benchmark evaluations, and more recently on the recognition of conversational and dialectal speech, as it is reported in Kirchhoff et al. (2003). Moreover, and compared to other languages, the Arabic language benefits from very limited number of research efforts. The goal of this paper is to investigate how adaptation techniques could improve a trained recog- nition system to be used by non-native Arabic speakers to get minimum amount of degradation in system accuracy. This adaptation is accomplished by using the adaptation techniques; namely, MLLR, MAP, and combination of MLLR and MAP. The original recognition system was designed for and trained by native Arabic speakers. Before adaptation, the system was tested by non-native Arabic speakers and the performance was considered for the sake comparisons with those of the adapted systems. We have four adaptation lists and three adaptation tech- niques; hence we have 12 adapted systems. Each system is evaluated at both word level and phoneme level.

The organization of this paper is as follows. The second section gives a basic background on Arabic language. In the third section, adaptation methods are briefly presented. Then, the fourth section presents the experimental framework, and the fifth section proceeds with a discussion of the obtained results. Finally, the sixth section concludes and indicates the perspective of this work.

Arabic is a Semitic language, and it is one of the oldest languages in the world to- day. It is the fifth widely used language nowadays (Al-Zabibi, 1990). The Arabic language has many differences when compared to European languages such as English. Some of the other differences are Arabic unique phonemes, phonetic fea- tures, and complicated morphological structures. A major difference lies in the Arabic text, where it is written with the absence of any information that leads to short vowels, geminate, and pharyngealization. This might lead to many iden- tical-looking forms in a large variety of contexts, which decreases predictability in correct word pronunciation, sentence meaning, and language model rules. Hence, the determination of accurate language model from texts becomes very difficult when the type and position of short vowels, for example, are unknown (United Nations, 2003; Selouani and Caelen, 1998). Modern Standard Arabic (MSA) has 34 basic phonemes, of which six are vowels and 28 are consonants. The Arabic language has fewer vowels than English. It has three long and three short vowels, while American English has at least 12 vowels. Permissible syllables in the Arabic language include the following: CV, CVC, and CVCC, where V indicates a (long /H/ and /C/. These phonemes are characterized by the constriction formed between the tongue and the lower pharynx in addition to the rising of the larynx. There are three uvular pharyngeal phonemes, /x/, /G/, and /q/ characterized by a constriction formed between the tongue and the upper pharynx for /x/ and /G/ and a complete closure for /q/ at the same level. On the other hand, there are four emphatic phonemes: /S/, /D/, /T/, and /Z/. These phonemes are emphatic versions of the oral dental consonants /s/, /d/, /t/, and /TH/.

The widely-used adaptation technique is MLLR (Leggeter and Woodland, 1995). It is a parameter transformation technique that has proven successful while using a small amount of adaptation data. It computes a set of transformations that will reduce the mismatch between an initial model set and the adaptation data. MLLR is a model adaptation technique that estimates a set of linear transformations for the mean of Gaussian mixture HMM system. The effect of these transformations is to shift the component means in the initial system so that each state in the HMM is more likely to generate the adaptation data. The MLLR transformation matrix used to give a new estimate of the adapted mean is stated as: this fact by hearing some WestPoint audio files. On the other hand, the extra vowel and diphthong were used because of variations in pronunciations of speak- ers influenced by English and other Latin languages. This type of phoneme exists in these languages but not in MSA. For our study, we finally decided to stick with WestPoint phonemes and transcriptions without any modification. We con- sidered this to make it more easy and logical to compare these results with other researches results which used the same corpus. Using the same settings and vari- ables values will give more correct and comparable outcomes.

The Hidden Markov Model Toolkit (HTK) (Young et al., 2006) is used for design- ing and testing the speech recognition systems throughout all experiments. The baseline system was initially designed as a phoneme level recognizer with three active states, continuous, left-to-right, no skip HMM models. The system was designed by considering all 37 MSA phones as given by the LDC catalog. Since most of the words consisted of more than two phonemes, context-dependent triphone models were created from monophone models. The training phase consists of re-estimating HMM models by using Baum-Welch algorithm after aligning and tying the models by using the decision tree method. Phoneme-based models are good at capturing phonetic details. Also context-dependent phoneme models can be used to characterize formant transition information, which is very important for the discrimination of confusable speech units.

MLLR, MAP, and their combination. In some experiments, MLLR gave improvement better that that of MAP. In other experiments MAP gave better accuracy improvement. The combined MLLR and MAP techniques sometimes gave less improvement compared to either MLLR or MAP. For instance, exper- iment AD100/MLLRMAP gave 1.97% as accuracy improvement but AD100/ MAP gave better performance with a 2.65% improvement. We believe that this is due to the random choice of sentences used in adaptation. In some cases, more relevant and specific Arabic phonemes are included in the adaptation data, while in other cases, the adaptation set contains less of these phonemes. As a general observation, we noticed that MAP gave better accuracy improvements compared to MLLR, and MLLRMAP gave generally better accuracy improvements com- pared to MAP and MLLR.

This work will be continued by investigating the performance of an evolution- ary-based technique to give the Arabic speech recognition system an auto-adapta- tion capability in the context of more foreign accents. Also this work will be expanded to use a better in quality and bigger in size speech corpora. In Addition to this, we are planning to check the effects of other languages (in addition to Eng- lish) as a first language of speakers on improving the performance of Arabic ASR systems. Also we can do it for the opposite way in improving English ASR systems in case of using them by Arabic native speakers whom can pronounce unique (compared to Arabic) English phonemes such as /p/, /v/, and /g/.

