Sen Chen: mainly responsible for modeling and algorithm debugging of combinatorial optimization. Jian Wang: PhD supervisor, generally guiding the article. Manting Yan: mainly responsible for scene research, data collection and research of relevant literature. Chuntao Yang: mainly involved in scene research and sorting out business data. Huihui Han: participated in relevant literature research, data sorting and al- gorithm debugging.

human as data sources has become increasingly obvious. The fusion of human-machine-physical ternary data [1] provides a solid foundation for knowledge discovery. Domain ontology is used to associate big data, then extract knowledge from it, and build a corresponding combination model. Finally, correct decisions through knowledge management and optimization could be made easily.

In summary, based on the fusion of human-machine-physical ternary data, this paper proposes the DOSTAR method for combinatorial opti- mization. The purpose of this method is to model practical problems in complex manufacturing networks. The following content will focus on these points.

The purpose of this study is to improve the efficiency of quality traceability of water heaters. Business scenarios have the characteristics of multiple data sources, multiple decision makers, multiple spatial and temporal constraints, and strong correlation between data. Therefore, data fusion, decision weights based on AHP, spatiotemporal data, ontology and domain knowledge need to be studied separately. There- fore, relevant research also focuses on these topics.

There are many studies on combinatorial optimization. Generally, the multi-objective optimization problem is transformed into sub- objectives of multi-level or multi-stage, and solved relatively sepa- rately. Then the subsets are combined in a certain way to achieve the goal of optimization. In order to better support the proposed combina- tion model, this paper will analyze the literatures of other researchers from the aspects of group decision-making, knowledge discovery, rein- forcement learning, graph computing, production scheduling, and service-oriented manufacturing.

optimization model for different decision-making preferences for pro- duction and distribution plans. Literature [7] first discovers knowledge from the solution, and then integrates the knowledge into the strategy. In addition, the combination of combinatorial optimization and graph computing is also a hot spot. Literature [8] explores the combinatorial optimization of graph, which uses a machine learning (reinforcement learning) model. In the literature [9], a multi-center variable-scale search algorithm is proposed to solve single-objective and multi-objective combinatorial optimization problems. Literature [10] has developed a set of software systems for exploring multiple combi- natorial optimization problems in complex networks. In Refs. [11,12], the process of solving multi-objective production planning problems is hierarchical. Literature [13] integrates combination optimization and collaborative filtering in a complex service network to improve service efficiency.

The above-mentioned studies are all outstanding and close to the scope of this article. The key factors of the studies are: multiple evalu- ation criteria, multiple layers of constraints, different parameters. However, most of them either did not introduce the relationship be- tween the key factors into the model, or the model was not compre- hensive enough.

Human-in-the-loop simulates Human factors and integrates the data obtained with cyberspace data and Internet of Things data. Although there is no clear fusion of human-cyber-physical data, it emphasizes to quantify the human factor and integrate it into of cyber-physical sys- tems. In order to avoid human error and simplify management, self- managed CPS was proposed in the literature [15]. The human factors are further simulated in the mixed environment of machine and mate- rial. The literature [16] proposes an architecture for seamless integra- tion of factory workers in an industrial network physical production environment, using semantic fusion data, and real-time analysis of data for anomaly detection. The literature [17] put forward that in a manufacturing environment, human beings can supervise and adjust Settings to become the source of knowledge and ability, diagnose situ- ations, make decisions and other activities that affect manufacturing performance, providing additional degrees of freedom for the CPS sys- tem as a whole.

compound methods. In literature [18], an advanced supply chain risk assessment model based on order of magnitude AHP (OM-AHP) was developed to compare the tangible and intangible factors that affect supply chain risk. An illustrative example is given to demonstrate the effectiveness of this assessment model. The evaluation method of machining process scheme based on AHP-GREY correlation analysis is proposed in the literature [19]. Analytic hierarchy process (AHP) is used to analyze the factors that affect the quality of the machining process plan, and the correlation degree is calculated by correlation coefficient and combination weight. Finally, the quality of the process plan is determined according to the correlation degree of the plan.

As mentioned earlier, the spatiotemporal data governance studied in this article is mainly to convert specific spatiotemporal data into weight values. At present, the mainstream time alignment methods mainly include interpolation extrapolation, least square method, Taylor expansion method, etc. In the aspect of space governance, the origin of coordinates is not unified, and the common methods include Kalman filtering [20] and least square method [21]. In addition, there are sys- tematic errors for different descriptions of the same object. Since the benchmark of each description object is different, the results may also have errors. The commonly used methods include least squares, maximum likelihood and so on. In addition, spatiotemporal data governance is inseparable from data mining. A spatiotemporal data mining method based on ontology semantics is proposed in the literature [22]. Through the spatial data analysis method based on event-event and event-place, the information is mined from two aspects of space and time.

forms are triples or variants of triples. In literature [25], it is proposed a multi-agent algorithm able to automatically discover relevant regular- ities (knowledge) in a given dataset. Each agent operates independently by performing a Markovian random walk on a weighted graph repre- sentation. In literature [26], it is proposed a principled knowledge-based model in the form of a computational ontology. The literature [27] proposes a knowledge discovery method based on knowledge graph, which integrates heterogeneous data by introducing knowledge graph.

In recent years, reinforcement learning has been used to find the path in the knowledge map [28], as well as entity search and relationship search to construct ontology species [29]. Methods based on reinforce- ment learning and semantic fusion selection are proposed in the litera- ture [30] to give Suggestions for decision making. Reinforcement learning is used in the literature [31] to predict the flow of urban spatial and temporal data. The literature [32] studies the related problems of time series data in the IoTs and uses reinforcement learning to solve the problem of mutual information minimization of historical dependence. All these indicate that reinforcement learning has been gradually used in ontology correlation calculation, but due to the lack of in-depth research, the current reinforcement learning has not made significant progress in associative knowledge discovery.

The quality traceability of water heaters is complex, and work effi- ciency needs to be significantly improved. First, it involves multiple responsible parties such as users, after-sales outlets, retailers, and manufacturers; it is difficult for multiple responsible parties to coordi- nate efficiently. Secondly, the data type, data format and value of each responsible party are different; data fusion is more difficult. Third, there are also stakeholders with different goals within the manufacturer who is the most responsible party; the decision-making weight of stake- holders will seriously affect the outcome of the decision. Fourth, the key factors affecting work efficiency should be assigned to multiple sub- models for research, and the correlative knowledge among them should be found to effectively improve overall work performance.

Overall, the research span of this article is very large. The first step is to collect the human-cyber-physical ternary data in the complex manufacturing environment according to the characteristics of the complex network of multiple factories, multiple sales companies, and multiple after-sales service outlets. The second step is based on the integration of ternary data to establish the domain ontology of the complex manufacturing environment. The third step is parallel to the second step. The weight sub-model converts the collected decision basis and results into decision weights, and transforms spatiotemporal data

The domain ontology model in this article is mainly established based on factors such as domain knowledge, expert experience, and data relationships. There are many places to study in complex manufacturing environment. This article is mainly based on the analysis of the actual situation of the complex manufacturing environment of Haier water heaters.

manufacturing environment includes: systematic planning, quality assurance and coordination meetings. Systematic planning is divided into single factory scheduling, multi factory scheduling, multi-vendor planning, and multi-D&S (delivery and sales) planning. The sched- uling of a single factory mainly refers to the annual plan. In addition,

which are based on text mining. This article believes that decision- making structure, work flow, management specifications and encyclo- pedia can all be used as the basis for ontology construction. Domain ontology is an important step of this research, but the method of con- structing ontology is not the focus. Therefore, it will not go into too much detail here.

Weight refers to the degree of importance of a certain factor or in- dicator relative to a certain thing. Different levels of importance should be represented by different values. The weight value is a relative value, which mainly indicates the order of the importance of different factors or indicators.

The six tuples are combined as parent node, relationship, child node, space weight, time weight and AHP weight. The parent node, child node and relationship are derived from the triples of the ontology (entity 1, relationship, entity 2). Three weights values are from weight sub-model. By adjusting the weights of similarly related data for different targets and different dimensions, the fusion calculation can be smoother. Based on the above analysis, the six-tuple model is expressed as follows: consistency of decision-making results, it is necessary to ensure that CR is less than 0.1. In addition, there are certain conflicts between multiple decision-making preferences. In order to further optimize this situation, different decision preferences need to be weighted to obtain a result that

Based on the multi-factory case of Haier electric water heater, this paper constructs an DOSTAR fusion model for associative knowledge discovery. This fusion model is divided into four parts: Weight sub- model, domain ontology, six-tuple and improved reinforcement learning. This research integrates various types of big data from multiple dimensions, multiple perspectives, cross-regions, and across time hori- zons throughout the whole process. These data include structured, semi- structured and unstructured data. These data are connected through AHP and domain ontology. The inclusiveness of these connections is very good. In particular, this study fuses human data through the AHP sub-model. The improved reinforcement learning sub-model shows that this research uses artificial intelligence algorithms for associative knowledge discovery. Finally, through the case study, it is obviously that this method can effectively optimize the entire manufacturing network to achieve the purpose of reducing costs and increasing efficiency. It provides innovative ideas for solving related problems.

Due to the relatively short time, there is no time to debug the multi- agent reinforcement learning model. I believe this will greatly shorten the calculation time of the reinforcement learning model. In addition, follow-up research work will further expand the data. More detailed and large knowledge discovery is expected.

