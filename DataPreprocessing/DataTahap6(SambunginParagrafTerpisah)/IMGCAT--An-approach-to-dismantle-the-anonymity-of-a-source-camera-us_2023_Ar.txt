With the proliferation of smartphones, digital data collection has become trivial. The ability to analyze images has increased, but source authentication has stagnated. Editing and tampering of images has become more common with advancements in signal processing technology. Recent developments have introduced the use of seam carving (insertion and deletion) techniques to disguise the identity of the camera, specifically in the child pornography market. In this article, we focus on the available features in the image based on PRNU (photo

A picture is worth a thousand words. Photos do not lie. These banal phrases have been around for a long time, and there has been little reason to question the reliability of a photograph in the current era until the recent presence of powerful graphics editors and developments in digital media technology [1]. Many low-cost software are accessible and make it trivial to manipulate images (e.g., Adobe Photoshop, Corel Paint Shop Pro, Skylum, Canva, Stencil, etc.), especially digital images.

To address the implicit problem of these feature-based approaches, techniques using different learning frameworks have been proposed to enable the network to automatically learn forensic features. Many ap- proaches to CNN-based multimedia forensics have been proposed using deep learning [8,19,20]. CNNs for computer vision can learn features from the data using preprocessing layers or network components that are specialized for learning low-level features. CNN-based forensic ap- proaches have been designed to learn forensic features while suppress- ing the content of the image. Bayar et al. [28] introduced a constrained convolution layer, which is referred to as BayarNet, that forces the CNN model to learn prediction error filters to produce low-level forensic features. According to Ref. [29], H-VGG is used in conjunction with VGGNet [30] with high-pass filtering (HPF). This model suggests double compression artifacts within a decoded intracoded frame (I-frame) of sisting of fake videos and showed that Xception could detect artifacts during the generation of fake faces. A framework for steganalysis in both spatial and JPEG domains was presented by Boroumand et al. [25]. To explore low-level artifacts, SRNet operates without the pooling layer in the early and middle stages. As a CNN-based method, Ye et al. proposed YeNet [32], which includes a preprocessing layer for seam-carved image detection.

examine two major methodologies, i.e., seam insertion and deletion. Section 3 deals with acquiring forged images, while Section 4 examines the selection of blocks and numerical analyses experimental approach and decision matrices calculations, correlation patterns, features. We discuss the impact of a 1D CNN model on our proposed approach in Section 5, followed by a conclusion in Section 6.

Our example illustrates a complex problem and a solution through the seam function for insertion and deletion scenarios. We consider restricted forced seam carving to identify camera sources for Microsoft Lumia 640 LTE C10 in the seam deletion case and for Apple_iPad Mini C1 in the seam addition case. As shown in Refs. [34,35], none of the [43] to investigate the effect of varying the number of groups used in the process of constructing camera fingerprints. Specifically, the experiment involved comparing the use of 10 groups (as in our current approach for detail see subsection 4.1) to the use of smaller or larger numbers of groups, such as 5 or 15 groups. The dataset was expanded from 10

The purpose of these ablation studies was to assess the effect of this change on the results. Our analysis revealed that the ablation study had a strong correlation with the concepts presented in our approach. This information is useful for improving the accuracy and reliability of our framework in source attribution tasks.

This suggests that the model may be struggling to learn the more complex patterns present in the seam insertion data, leading to lower accuracy. However, the similarity in the loss function values indicates that the model is still able to effectively learn and optimize the objective function in both tasks. Further analysis, such as examining the confusion matrix, may provide more insights into the model performance.

gerprints to characterize a device may be more reliable than a single PRNU, as we found in an observation. Then, we extracted five features from the correlation values with the series of PRNUs that enabled us to link seam images (deletion and insertion) to their source device. In the next phase, we fused the 1D CNN to validate IMGCAT based on the results recorded from feature extractions. The results prove that the proposed

will explore how we can specialize the CNN to learn additional char- acteristics as well as traces of camera models (e.g. scaling, rotation, blurring, etc.). Meanwhile, how to utilize LSTM capabilities directly for localization by training with split layers and corresponding mitigation strategies on synthetic images.

Irshad M, Law NF, Loo KH. CamCarv - Expose the Source Camera at the Rear of Seam Insertion. In: Rutkowski L, Scherer R, Korytkowski M, Pedrycz W, Tadeusiewicz R, Zurada JM, editors. Artificial Intelligence and Soft Computing. Lecture Notes in Computer Science, 13589. Cham: Springer; 2023. https://doi.org/ 10.1007/978-3-031-23480-4_2.

