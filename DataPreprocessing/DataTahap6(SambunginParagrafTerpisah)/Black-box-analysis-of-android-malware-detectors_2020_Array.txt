If a malware detector relies heavily on a feature that is obfuscated in a given malware sample, then the detector will likely fail to correctly classify the malware. In this research, we obfuscate selected features of known Android malware samples and determine whether these obfuscated samples can still be reliably detected. Using this approach, we discover which features are most significant for various sets of Android malware detectors, in effect, performing a black box analysis of these detectors. We find that there is a surprisingly high degree of variability among the key features used by popular malware detectors.

various Android malware detectors. In this way, we can, in effect, reverse engineer these proprietary algorithms. That is, we can determine which features a detector relies on for its capabilities. Through this process, we also gain some insight into the robustness of various detectors when faced with various obfuscations. While such information is obviously useful to a malware writer, as mentioned above, this information is also important to anyone who strives to build a better malware detector.

The remainder of this paper is organized as follows. In Section 2, we discuss selected example of related previous work. Then in Section 3, we briefly consider relevant background topics. Section 4 contains our experimental results, where we analyze the effectiveness of individual obfuscations and combinations of obfuscators with respect to a set of Android malware detectors. Finally, Section 5 contains our conclusions and provides a brief discussion of future work.

An interesting evaluation of real-world antivirus products (as of 1996) is given by Gordon and Ford in Ref. [16]. In their seminal paper from 2001, Barak et al. [7] formalize the concept of code obfuscation and show that such obfuscation cannot be as strong as cryptography. Nevertheless, malware writers have certainly found obfuscation to be useful for evading detection, which we empirically confirm for Android malware in Section 4 of this paper.

As far as the authors are aware, the most similar work to that pre- sented here is [18]. In this previous work, black box analysis techniques are applied to the Drebin Android malware detector [3]. The research in Ref. [18] highlights relevant local features, and utilizes support vector machines (SVM). This differs substantially from the present paper, as [18] is focused on attacks that target the machine learning models, rather than specific detectors. In addition, the Drebin detector is described in detail in Ref. [3], so Drebin is not a black box in the same sense as the VirusTotal [32] detectors that we consider in this paper.

In this section, we discuss the various obfuscators that we consider in the experiments presented in Section 4. By systematically obfuscating different aspects of the code, we can gain insight into which features contribute most to a given Android malware detector. This information can, in turn, be used to determine the most effective ways to make malware detectors more effective and more robust.

For this project, we developed a modified version of Another Android Malware Obfuscator (AAMO) [21], that we refer to as Modified AAMO, or simply MAAMO. Our MAAMO tool is available to any researchers who would like to conduct experiment similar to those discussed in this paper. MAAMO implements a wide variety of obfuscators for Android code.

The resigned obfuscator resigns the apk file prior to recompilation. Although this obfuscator has essentially no effect on the code itself, it could serve to defeat a malware detector that relies on a specific signa- ture that was applied to a known malware sample. In addition, if an application is expected to be signed, this obfuscation will serve to make it less obvious that the code has been modified.

Call indirections is an advanced obfuscation technique in which various function calls are directed through different values. This obfus- cator has a variety of effects, including changing the register count, changing method calls, and also redirecting all calls to methods. For typical code, this obfuscation will heavily alter control flow information. This would likely have a significant effect on many types of dynamic analysis, and hence should be a powerful obfuscation for detectors that rely on dynamic information.

The renaming obfuscation renames all variables in the source code. Note that this is a far more extensive renaming than occurs with the fields obuscation, as all variable names can be affected. Renaming could be expected to alter signatures and adversely affect other pattern matching techniques that rely on names of variables and functions.

The use of reordering changes the order of the code in the application. This obfuscator changes the location of certain parts of the code and adjusts the control flow accordingly, so that the code executes in the proper order. Such reordering can make it possible to evade signature detection, since signature detection typically depends on the order of instructions.

The goto obfuscation changes the control flow by inserting forward and backward jumps into the code. Such jumps can drastically alter program flow and should have a negative impact on any malware detection technique that relies heavily on control flow information. Such information is often used in dynamic analysis.

The arithmetic branch obfuscator inserts a branch condition, where only one branch can actually execute. This can greatly complicate anal- ysis that relies on control flow, and it has the effect of inserting dead code, which can negatively impact static analysis. As with all other ob- fuscations considered here, this operation leaves the function of the original code unchanged.

The reflection obfuscator takes advantage of the Android dynamic code loading API. Specifically, all static method calls are converted into reflection calls and the reflect method is invoked on a string that contains the target method. It is not clear that this would have a large impact on most malware detection techniques.

We use the VirusTotal [31] website as our source for malware detection results. At the time of our experiments, VirusTotal included 64 applicable malware detectors that we tested on each sample. These de- tectors include products from virtually all of the leading anti-virus companies, including Kaspersky, McAfee, Microsoft, Sophos, Symantec, and Trend Micro. In a few sporadic instances, VirusTotal did not return a result for a particular detector.

The VirusTotal website uploads a malware file to its database and then performs a scan using the various malware detectors available at the website. Each uploaded file is hashed and stored in the database to reduce duplicate effort and minimize scan times. We used VirusTotal to scan each malware sample, and each obfuscated variant of a given sample.

Before giving our main experimental results, we briefly consider false positives. Antivirus products are generally tuned so as to generate an extremely low false positive rate [5], in spite of the fact that this will tend to result in a significantly higher false negative rate. While this may seem counterintuitive, false positives can be disastrous for any antivirus product, since customers will lose confidence in a product that flags a known clean application as malware. Another concern is that a developer whose application is incorrectly flagged as malicious might suffer a major financial loss, and thus any such developer has an incentive to publicize such failings. Such cases would serve to damage the reputation of the offending antivirus product.

Not surprisingly, the results in this section clearly show that obfus- cation can be highly effective. We find that to a large degree, the optimal obfuscation depends on the specific malware detector, as well as the actual malware under consideration. This indicates that the malware detectors considered here are fairly diverse, in the sense that they apparently rely on different features or combinations of features for detection and, furthermore, the precise set of features appears to vary somewhat for different malware samples.

Remarkably, one of the tested virus detectors (ESET-NOD32) was able to classify all obfuscated samples as malware, while two additional de- tectors (Ikarus and Kaspersky) also yielded impressively high detection results. At the other extreme, 19 of the 64 detectors available in Viru- sTotal failed to detect any of the original (unobfuscated) malware sam- ples in our tests. These results indicate that there is an extremely wide range of capability among the detectors in VirusTotal.

Perhaps more surprising than the range in detector capabilities is the range in the malware samples themselves. Some samples (e.g., BankBot and TubeMate) seem to be extremely easy to obfuscate, in the sense that virtually any obfuscation has a large impact. On the other hand, we found that some samples (e.g., CopyCat and SonicSpy) were not effectively obfuscated with any combination of the obfuscators under consideration. And, for at least one application (Operation Electric Powder), selected obfuscations were effective, while most obfuscations had only a limited effect.

Another interesting area of related research would consist of carefully analyzing the strengths and weaknesses of various machine learning based malware detectors when facing obfuscations of the type considered in this paper. Malware detectors based on hidden Markov models (HMM), support vector machines (SVM), deep learning, and a wide va- riety of other machine learning techniques have recently shown great promise [25]. It would be useful to quantify the robustness of such techniques, while comparing machine learning based results to existing antivirus products. Our MAAMO tool, along with the results presented in this paper, could form the basis for such research.

