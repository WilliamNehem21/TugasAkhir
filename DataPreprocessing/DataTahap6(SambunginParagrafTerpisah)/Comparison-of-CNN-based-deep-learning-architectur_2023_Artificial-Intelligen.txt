The observable success of convolutional neural networks (CNNs) has shifted the technology in detecting and localizing rice diseases using their leaves. Following the path, recent CNN studies suggest that the use of CNN has increased in rice leaf disease detection and segmentation (Chen et al., 2021; Patil and Kumar, 2022). Usually, a diseased rice leaf is covered with spots, colours, and diseased shapes (Mohanty et al., 2016). Thus, a diseased leaf which has a different colour texture and dimension than a healthy rice leaf provides an opportunity to perform image anal- ysis using a CNN network and to collect information on inconsistency among the pixels of the entire leaf (Mitkal et al., 2016; Xu et al., 2020). Each of the pixels of a leaf is expected to be similar concerning

Resnet152V (Sankupellay and Konovalov, 2018) and Seresnext101 (Chen et al., 2018; He et al., 2015) in classifying the rice plant disease detection. The ultimate goal of this research is to reach the model that provides the highest accuracy rate in classifying rice leaf disease detection. Furthermore, this study also aims to conduct a transfer learning of DenseNet121, MobileNetV2, Resnet152V (Xie et al., 2017), and Seresnext101 (Chen et al., 2018) networks, and ensemble learning of Densenet121, EfficientNetB7, and Xception (Chollet, 2017) networks.

This section reviews the related research work aiming at a deep- learning network model that can provide better accuracy for rice leaf disease detection. It includes an overview of the basic CNN networks and their various architectural structures. Several image processing technologies that were applied to rice leaf disease detection are also discussed.

As a cereal grain, rice is the most widely consumed staple food for over half of the population in the world (Nguyen-Quoc and Hoang, 2020). Like many other developing countries, rice is the major source of income for rural farmers, especially in Bangladesh. Therefore, when rice production is hindered due to various rice diseases, it impacts the national economy.

B. gladioli. It is a prevalent disease in many rice-growing regions glob- ally. The symptoms of bacterial panicle blight include several charac- teristic features. Panicle discolouration is a common symptom, where affected panicles may turn dark brown or black. Another symptom is grain rot, where the infected grains may exhibit decay or rotting. Additionally, sterile florets, which fail to produce viable seeds, are observed in affected panicles (Sainath et al., 2015; Zhu and Gong, 2018).

Hispa: Rice Hispa, scientifically known as Dicladispa Armigera, is a major pest that affects rice plants. It is commonly found during the tillering stage of rice growth, with higher populations observed at this stage. Rice Hispa feeds on the epidermis of the upper leaves, causing scraping damage. In the context of Sylhet, a region in Bangladesh, it is mentioned that Rice Hispa forms part of a large and contiguous population that extends into neighbouring Assam. This suggests that the pest is prevalent and poses a significant prob- lem in both areas (He et al., 2015).

Leaf Scald: Leaf scald, caused by Microdochium Oryzae, is a fungal dis- ease. This causes the scalded appearance of leaves. Zonate lesions of alternating light tan and dark brown starting from leaf tips or edges, oblong lesions with light brown halos in mature leaves. Individual le- sions are 15 cm long and 0.51 cm wide or may almost cover an entire leaf. The continuous enlargement and coalescing of lesions result in the blighting of a large part of the leaf blade.

Leaf Smut: Leaf smut, caused by the fungus Entyloma Oryzae, is a type of smut disease that affects rice plants. However, it does not pro- duce smut balls on spikelets. Instead, leaf smut causes dark brown to black lesions on the leaves of the rice plant. These lesions are com- posed of masses of fungal spores. False smut causes chalkiness of grains which leads to a reduction in grain weight. It also reduces seed germination. Velvety smut balls on spikelets, Spore balls are ini- tially orange and turn greenish black when mature, they are some identifiable symptoms of leaf smut. The second stage of infection oc- curs when the spikelet nearly reaches maturity.

Shath Blight: Sheath blight is caused by the fungal pathogen Rhizoc- tonia solani. It is a widespread disease that affects rice plants in both temperate and tropical rice-growing regions. The typical symptoms of sheath blight manifest as oval to irregular lesions on the rice sheath (the protective covering of the stem) and leaf blades. These lesions typically have a greyish inner colour and a dark brown mar- gin. The distinct colouration helps in identifying and distinguishing the disease from other rice pathogens.

Tungro: Tungro is a viral disease that affects rice plants. It is distrib- uted in South and Southeast Asia, including Bangladesh. The disease is characterized by several characteristic features, such as stunted growth of the plant, twisted leaves, reduced tillering (formation of side shoots) and delayed flowering. The main vector responsible for the transmission of rice tungro virus is the green planthopper (Nephotettix virus). In Bangladesh, susceptible rice varieties are par- ticularly susceptible to Tungro disease. Studies have shown that tungro incidences were common in susceptible cultivars, with re- corded incidence rates ranging from 85% to 81% in the south to northwest of the country. This indicates a significant impact of the disease on rice cultivation in these regions.

The input and output layers are considered the visible layers of the CNN, while the intermediate layers, such as convolutional and pooling layers, are referred to as hidden layers. These hidden layers play a cru- cial role in learning and extracting hierarchical representations from the input data. Overall, the combination of convolutional layers, pooling layers, and fully connected layers in CNNs allows the network to effec- tively learn and recognize patterns in complex data, making them par- ticularly well-suited for tasks such as image recognition and computer vision (Xie et al., 2017).

Keras or Github. In this research, a CNN algorithm is kept original as first proposed by its authors and programmers, with no change of pro- cessing units, parameters and hyper-parameter optimization strategies, design patterns and connectivity of layers. Often a well-known CNN network was developed and evolved by different researchers and pro- grammers through various challenges For example, the AlexNet archi- tecture was the winner of ILSVRC 2012 and was proposed by Krizhevsky et al., (Chollet, 2017) ResNet was proposed by He et al. (Chollet, 2017) from Microsoft and won 2015 ILSVRC. DenseNet as an extension of ResNet was first proposed in 2016 by Huang et al. from Facebook (Chollet, 2017; Patil and Kumar, 2022). Several original CNN architectures with the versions are discussed in the next sections:

DenseNet-121. DenseNet-121 architecture iteratively concat- enates the feature maps from one layer to another layer along the net- work, which is useful for classification tasks. The DenseNet-121 model was claimed better than MobileNetV2, ResNet50 and NASNet architec- tures (Shujaat et al., 2021).

MobileNetV2. Overall, MobileNetV2's design choices make it well-suited for deployment on resource-constrained mobile devices while maintaining competitive performance for various computer vi- sion tasks such as image classification, object detection, and semantic segmentation. One key feature of MobileNetV2 is the use of an inverted residual structure with residual connections between the bottleneck layers. Inverted residual blocks aim to reduce computational complexity while maintaining accuracy. The residual connections help in gradient flow and facilitate the training of deeper networks. The intermediate ex- pansion layer in MobileNetV2 incorporates lightweight depth-wise con- volutions (referred to as depth-wise separable convolutions) to introduce non-linearity and filter features efficiently. Depth-wise con- volutions separate the spatial and channel-wise convolutions, reducing the computational cost while retaining the expressive power of the net- work.

and extracts initial features. It is followed by 19 residual bottleneck layers, which are the primary building blocks of the network. These bot- tleneck layers further refine and transform the features, utilizing the inverted residual structure and depth-wise convolutions (Shujaat et al., 2021).

Training a deep learning model with a small dataset is often insuffi- cient for its model's performance. Transfer learning is a process of pre- initialize a model using the weights obtained by training a different model on a larger, different, dataset. In the work conducted by Karimi et al. (2021), it was reported that although transfer learning reduced

Ensemble technique. Ensemble learning is one of the deep learning technologies that combine multiple primary learners through a fusion strategy to improve overall generalization performance (He et al., 2015). Ensemble learning has attracted a lot of attention because of its easy-to-understand structure and promising classification performance by combining more than one CNN model. Ensemble learning is a tech- nique that incorporates multiple models for final decision-making The ultimate goal of an ensemble is that by combining multiple models, the errors of a single model can be corrected (compensated for) by other models, making the overall score (prediction and classification) of the ensemble better than any individual participating model (Kawasaki et al., 2015).

The third approach is the digital image processing techniques of McNeely-White et al. (2020); Atila et al. (2021); Chambon et al. (2021). Zhou et al. investigated a technique for assessing the extent of hop disease in rice crops, using a fuzzy C-means algorithm to classify re- gions into one of four classes: no disease, light disease, moderate dis- ease, and severe disease. Their study achieved an accuracy of 87% in distinguishing cases in which a planthopper did or did not occur, while the accuracy in distinguishing four groups was 63.5%. Chambon et al. (2021) was to identify and classify six types of mineral deficiencies in rice. The study used features such as texture and colour for a devel- oped specific multi-layer neural network. Both networks consist of a hidden layer with a different number (40 for texture and 70 forcolourr) of neurons in the hidden layer, in which 88.56% of the pixels were cor- rectly classified. Similarly, the same authors proposed another similar work that successfully identified two types of diseases (blast and brown spot) affecting rice plants (Chambon et al., 2021).

Zhou et al. (2013) reported an automatic identification and diagno- sis of rice diseases using CNN as a deep learning method. Using a dataset of 500 natural images of diseased and healthy rice leaves and stems cap- tured from the rice experimental field, a CNN network was trained to identify 10 common rice diseases. Under the 10-fold cross-validation strategy, the proposed CNN-based model achieved an accuracy of 95.48%.

Sanyal and Patel (2008) suggested a faster R-CNN approach, which seemed to be ideal for the detection of rice diseases due to its good speed and high accuracy. Shrivastava et al. (2019) also applied a CNN al- gorithm for rice plant disease classification using a transfer learning of deep convolution neural network. Using an AlexNet CNN model, the model was able to classify rice diseases with a classification accuracy of 91.37%.

Asfarian et al. (2014) developed a CNN approach for detecting dis- eases and pests (five classes of diseases, three classes of pests, and one class of healthy plants and others) from rice plant images. A total num- ber of 1426 images were collected that were captured using four differ- ent types of cameras and the system achieved a mean validation accuracy of 94.33%.

Akhter et al. (2019) also suggested a new stacked CNN architecture that used two-stage training to substantially reduce the model size while retaining a high classification accuracy. Several CNN architectures, such as MobileNet, NasNet Mobile, and SqueezeNet, were used. Experi- mental results showed that the proposed architecture achieved the de- sired accuracy of 93.3% with a significantly reduced model size, for example, 99% smaller than that of VGG16.

Despite the fact, Phadikar et al. (2012) observed that computer- aided rice disease detection and classification have received special at- tention, Asfarian et al. (2014) criticized for low accuracy rates using the rice disease detection models. Our literature review in this study also suggest that the classification accuracies by most of the existing methods are between 50% and 95% (Asfarian et al., 2014). Moreover, those achieving higher accuracies were usually tested with fewer dis- eases. The performance would deteriorate if more diseases were in- cluded. (Acharya et al., 2020) and (Huang et al., 2017) discussed the gap between the current capabilities of image-based methods for auto- matic rice disease identification and the real-world implementation needs.

The experiments in this study were conducted based on Google CoLab using the Keras library. TensorFlow which is one of the best Py- thon deep learning libraries available for working with machine learn- ing methods on Python was used. In this study, the original, transfer learning and ensemble models were trained using google collab Tesla graphics processing unit (GPU). TPU is available through the Google Collaboratory framework by Google. Initially, the colab framework pro- vides up to 12 GB random access memory (RAM) and about 360 GB GPU in the cloud for research purposes.

Image Acquisition: In this step, we downloaded the images from the targeted sites to provide as input. Images in the dataset were checked manually to identify if they had a white background. In the case where images (mainly from the BRRI) had coloured backgrounds, images were placed on a white background. If dis- ease symptoms such as spots, diseased colour, and diseased shape were not visible in an image, the image was removed from the dataset.

Image Augmentation: Image augmentation is used in this step. Image augmentation is the procedure by which an existing dataset is expanded by transforming the original dataset to cre- ate more new data, and in such a way that new data are also label-preserving (Sankupellay and Konovalov, 2018, Meeras Salman Al-Shemarry et al., 2019). The goal is to increase the var- iance of the dataset while ensuring that new data are meaningful and do not merely add unnecessary volume to the dataset (Sankupellay and Konovalov, 2018). When used in a machine- learning context, it can improve model generalization, make trained models more robust to unseen data, and increase model accuracy (Sankupellay and Konovalov, 2018).

In this research standard deviation was used as a model performance metric since the dataset used in this experiment does not have any major imbalance. Categorical cross-entropy was used as a loss function for all CNN architectures since this work deals with multi-class classifi- cation. All intermediate layers of the CNN architectures used in this work have relu as the activation function while the activation function used in the last layer was softmax. The hyperparameters used are as fol- lows: the dropout rate was 0.3, the learning rate was 0.0001, the batch size was 64, and the number of epochs was 275. An adaptive moment estimation (Adam) optimizer was used for updating the model weights. All the images were resized to the default image size for each prior architecture.

Specificity refers to the ability of a diagnostic test to correctly iden- tify a rice leaf that is healthy or free from disease. It measures the per- centage of true negative results. A highly specific test has a low false positive rate. However, in case of a highly specific test can be interpreted

Training loss is a measure of how well a model fits the training data. It quantifies the discrepancy between the predicted output of the model and the actual target values in the training set. The goal during training is to minimize this loss, which indicates that the model is learning to ac- curately represent the relationship between the input data and the cor- responding output targets.

Validation loss, on the other hand, assesses how well the model gen- eralizes to new, unseen data. It measures the discrepancy between the model's predictions and the true target values in a validation set or a portion of the training data that is held out for evaluation. The validation loss helps determine if the model has learned meaningful patterns or if it is overfitting.

Overfitting occurs when a model becomes too complex or too closely fits the training data. In such cases, the model may start capturing noise or irrelevant patterns from the training set, making it less effective at generalizing to new data. Overfitting is often characterized by a low training loss but a high validation loss, indicating that the model is not performing well on unseen data.

To combat overfitting, techniques such as regularization, dropout, and early stopping can be employed. Regularization methods help pre- vent the model from excessively fitting the training data by introducing penalties or constraints on the model's parameters. Dropout randomly deactivates a portion of the neurons during training, reducing the model's reliance on specific features or patterns. Early stopping stops the training process when the validation loss starts to increase, prevent- ing the model from further overfitting.

support, various techniques can be employed. Stratified sampling is one approach that ensures each class is represented proportionally in the training and evaluation datasets. This helps provide a more balanced representation of classes during model training and evaluation. Rebalancing techniques, such as oversampling the minority class or undersampling the majority class, can also be used to mitigate the effects of imbalanced support during training.

In this section, the performances of the six original individual CNN networks (DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V, and Seresnext101) are presented. The classification perfor- mance of the models is first presented. The overall measures for those models are then discussed. Gathering in addition to the descriptors, pos- sible causes, and areas of opportunity for improvement of results.

In this research, the ensemble stack is developed on three different original CNN models, Densenet121, EfficientNetB7, and XceptionNet. To accelerate the training process, we adopted a transfer learning strategy. In addition to this, the output from these models was sent to a post-processing block containing a fully connected layer followed by a dropout layer and a final logit layer for classifying the image. For better convergence of our models, we used a learning rate decaying strategy which divided the learning rate by 10 only when the loss stops decreas- ing for three continuous epochs and an early-stopping strategy that halts the training process after the learning rate decayed 5 times (Kawasaki et al., 2015).

Our investigation suggests that transfer learning of deep learning models provides slightly improved accuracy than the original individual networks for small datasets (Number of imageless than 2000). In this case, only after careful training including transfer learning, the accuracy was higher than the original CNN architecture. The transfer learning strategies in this research were based on using the pre-trained model for training and extracting features. Surprisingly we found that seresNext101 has improved by 17% of accuracy after a transfer learning process. This is consistent with the results from the study conducted by Oloko-Oba and Viriri (2021) that SE-ResNeXt-101 normally would in- volve more parameters and was computationally expensive but has shown good results on the ImageNet classification tasks. Performing transfer learning from images trained on Imagenet (general images such as cats, dogs, etc.) or MURA (X-ray images on different parts of the body but not the chest) improved results compared to scenarios when transfer learning was not used at all.

This research offers several key contributions. Firstly, this research experimented using nine types of rice diseases. Secondly, in this re- search, a comparison of six original CNN architectures (DenseNet121, Inceptionv3, MobileNetV2, resNext101, Resnet152V, and Seresnext101) was conducted. Thirdly, we applied a transfer learning approach on DenseNet121, MobileNetV2, Resnet152V, Seresnext101, and an ensem- ble model called DEX (Densenet121, EfficientNetB7, and Xception) to draw a comparison among the original CNN networks, transfer learning,

In the future, we want to create a user interface for the detection and localization of rice leaf diseases for farmers. This interface would not only detect but also provide a guide on how the diseases can be con- trolled. As mobile phones are seen as a preferred technological device among developing country users, we aim to develop a mobile phone- based rice leaf disease detection application tool.

Densenet121, EfficientNetB7 & XceptionNet was found to produce the highest accuracy in classifying rice diseases from rice leaves. The success of the proposed architecture was compared with the transfer learning and six state-of-the-art individual CNN architectures. Experimental studies were conducted in both original and augmented versions of the image dataset. Considering both the average accuracy and the aver- age precision metric on both the original and augmented datasets, the DEX model was found to be superior to other CNN architectures.

