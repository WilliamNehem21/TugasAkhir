The challenge of data bias described above has led to the adoption of different data splitting strategies that intend to partition the data into testing and training sets while preserving a balanced representa- tion of the interaction space [16]. The splitting strategy must enable a reliable performance evaluation which reflects model generalisabil- ity and prospective predictive ability. Despite the belief that a random compound split leads to overly optimistic reported performance, it re- mains among the most common approaches to assess performance on benchmarking datasets [18]. In the pharmaceutical setting, models are trained on data gathered at the time the models were made and are used to predict the activity of orphan compounds. A temporal split is thus a common strategy adopted in industry to better assess prospective prediction ability [39]. Hence, in this work we sought to evaluate the PCM model using different splitting strategies: the random ligand split- ting approach, commonly used on benchmarking datasets, the temporal ligand splitting approach, commonly used on industrial datasets and a kinase splitting approach to assess generalisability to new proteins.

To evaluate PCM modelling in an industrial setting, the state-of-the- art GraphDTA model was used as a reference. GraphDTA is a bimodal neural network based on convolutional neural networks. In this study, the graph isomorphism network (GIN) version of GraphDTA was ap- plied. For further details please refer to the original paper [12]. The model was optimized on a MSE loss with Adam and was trained for 200 epochs with a learning rate of 0.0005 and a batch size of 128.

[40] and trained on the descriptors described in the next section. The KNN model used in this study is based on the KNN in Born et al. [41]. The KNN model relied on the combination of the Tanimoto similarity between ligands and the Levenshtein distance between amino acid se- quences of the proteins as a distance metric between samples, for further details refer to the original publication [41]. The ChemProp multitask model was trained using default settings and 50 epochs.

off-target interactions, similar pIC50 cut-offs have been proposed in prior kinase inhibitor classification studies [49]. Hence, this becomes a clas- sification problem for which the sensitivity and specificity can be calcu- lated for each of the 927 ligands that were tested across more than 25 kinases. This analysis was carried out over the validation results since only two ligands in the test were tested across more than 25 kinases. Statistical significance was assessed using the non-parametric Wilcoxon test. Due to the large test number (927 ligands), the alpha threshold was

served for both datasets. Strong biases dominate both datasets and are likely to impact the predictive abilities of models. The experimental re- producibility of the proprietary dataset highlights the importance of re- lating this with the performance limits for any model trained herein.

Considering the random ligand split, GraphDTA achieved a perfor- mance of 0.58 RMSE and a PCC of 0.86 for the proprietary dataset. Despite the increased data availability for the in-house dataset, the per- formance is slightly inferior to the performance reported in the original paper, where the model achieved 0.229 MSE (0.48 RMSE) on the Davis dataset with a similar splitting strategy [12]. Nevertheless, the model ligands in the proprietary dataset. C) Histogram of the number of kinases screened per ligand. More ligands have been screened for over 10 kinase in the proprietary dataset. D) Understudied kinases tend to have more active samples in the proprietary dataset and more inactive samples in BindingDB.

PCC of 0.01; p = 0.008) and the PCM-Zscale (delta in RMSE and PCC marginally better than the KNN (delta in RMSE of 0.05 and delta in of 0.02; p = 0.02 and p = 0.04 respectively) baseline models on pro-

In this section we have provided empirical evidence that the tem- poral splitting strategy provides a more realistic assessment of true prospective performance as it simultaneously considers a shift in the chemical and protein space. We have also demonstrated that with a temporal split the state-of-the-art PCM model performs similarly to a multitask model on a proprietary dataset. We also highlight the impor- tance of considering other modelling approaches, such as KNN, RF and multitask models, as benchmarks for the evaluation of DL PCM models. We call attention to the remaining gap to MAP. This suggests that there is a hypothetical window to be exploited by better performing models in the future.

Taken together, this suggests that for these understudied kinases, all models except for PCM-OHE only offer limited predictive abilities that are dependent on similar ligands being explored in training. Despite the hypothesis that PCM models can better leverage cross-target information and thus generalise better to novel targets, GraphDTA does not signif- icantly outperform a KNN and shows comparable performance to mul- titask models in the prediction of bioactivity for understudied kinases. Since the overall predictive performance of all models remains limited, the PCM models showed the best overall predictive performance, and there is a distinct difference in performance between a RF model with lit- tle protein information (PCM-OHE) and some protein information (PCM- Zscale), there is potentially an opportunity for future PCM models to further optimise cross-target learning with better protein descriptors to improve performance for understudied kinases.

GraphDTA significantly outperformed all models except for the multi- task and PCM-Zscale models. While all models achieved good specificity, poor sensitivity was observed across models (mean true positive rates ranging between 0.30 and 0.54) and thus highlighting their limited abil- ity to correctly identify instances where the ligands are active across spe- cific targets. GraphDTA was the second-best performing model, it was significantly outperformed by the KNN and achieved statistically simi- lar results to the multitask model. Combined, these results suggest that all models have limited predictive power to evaluate ligand promiscuity with a poor ability to identify actives across specific targets.

0.65. We partially attributed the overly optimistic performance to the very lenient random ligand splitting strategy employed in the original publication which did not reflect the shift in chemical space observed over time in an industrial setting. We therefore recommend the use of

