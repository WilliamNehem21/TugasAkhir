Based on the definition of ResNet and DenseNet, the skip-connection structures in RFCN-ResNet and RFCN-DenseNet are fixed. Most neural network architectures are still handcrafted and therefore might not be the best choice for addressing various kinds of scientific problems. As such, we propose another RFCN variant, the randomly-wired residual fully-connected neural network (RRFCN), which adopts neural archi- tecture search (NAS) to generate and search for the best residual fully- connected neural architecture for any given genomic profiling problem. With RRFCN, researchers can search for brand-new RFCN architectures to address their scientific problems.

(1) The blocks structure for DenseNet. The default value is [2, 3, 4,3, 4, 5]. (2) The growth rate of neurons in each block. The default value is [8, 16, 32, 64, 128, 256, 512]. (3) The drop-out ratio of the first layer compared with the input layer, selected from [0.6, 0.8, 1.0]

(1) The number of layers, selected from [3, 4, 5]. (2) The drop-out ratio of the first layer compared with the input layer, selected from [0.6, 0.8, 1.0]. (3) The number of neurons in the first layer, selected from [4096, 2048, 1024, 512, 256, 128]. (4) The neuron number decay ratio of the next layer compared with the previous layer, selected from [0.8, 0.6, 0.5].

into a fully-connected layer to adjust the input of modeling of genomic data. (2) We combined the output of different layers through concate- nation. The number of layers in this mode should be fixed. The default number is 6. And the number of neurons in the first layer should be set in the JSON file (the default number is 2048). The search space is as follows. (1) The number of neurons from the 2nd layer to the last layer, selected from [16, 32, 64, 128, 256, 512, 1024, 2048]. (2) The connection relationship between different layers.

Genomic profiling data are crucial for biomedical researches, and they are growing rapidly. Hence machine learning methods are being used by researchers to predict and interpret genomic data. However, many of the methods also have shortcomings, and new neural network architectures, which mirror the recent progresses in computer vision, natural language processing, and speech processing, are needed to over- come challenges in this area. Compared with the widely used MLP ar- chitecture, the advantages of the RFCN architecture are significant: a. RFCN can be used to train deeper neural networks; b. RFCN can enhance feature propagation and encourage the reuse of features; c. RRFCN can be used to generate new RFCN architectures. AutoGenome has made it easy for researchers to use the RFCN in their research.

