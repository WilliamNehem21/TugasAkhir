Spatial aggregation critically involves generalizing motion features per joint and spatial dependencies between joints. Generalization of motion features per joint means acquiring independent features re- gardless of any joint. For example, the motion features observed in the right knee are also applicable to the left knee. Generalization of spatial dependence among joints means the acquisition of reference relationships among joints to provide each motion, for example, the rotation linkage of the shoulder, elbow, and wrist to produce a straight- line trajectory of the fingertips. Previous methods have focused on the expression of spatial dependency using network structures such as Graph Convolution and Graph Attention. Specifically, they generate a joint graph with each joint as a node, then detach the joint-wise features and the spatial dependencies across joints. For joint-wise fea- tures, they consider the feature dimensions retained by each node as

The methods that use motion trees as adjacency matrices can de- scribe spatial proximity in link connection relationships, but they make it difficult to reference distant joints. Wei et al. [12] enables referencing of distant joints by learning the adjacency matrix. Due to the lack of information on the original connection relations of the motion tree, it was not sufficient for acquiring global features such as capturing the entire near joints of arms and legs. Li et al. [13] gives the closeness of joints to each other by constructing a multi-scale graph that integrates close joints. While wide-area features are easier to acquire, the choice of which joints to integrate relies on heuristics. The generalization of spatial dependence is still an unsolved problem.

We focus on the fact that the generalization issues are different between the two data description methods, position-based and angle- based, which have been evaluated separately as independent problems. Concretely, the position-based description can capture the features that represent a wide range of motions, such as the interlocking of distant joints in the kinematic tree due to the relative positional relationships of the joints. On the other hand, angle-based description has an ad- vantage in capturing features that represent local actions, such as local actions at a terminal joint, regardless of the posture of the root side in the kinematic tree. Therefore, we employ an approach in which the angle-based description gives the features held by each node of the joint graph, and the position-based description provides the spatial dependence during feature aggregation.

We focus on generalizing spatial dependency by utilizing data structures instead of network structures. In general, networks utilize position-based or angle-based descriptions for data structures describ- ing input/output poses. The position-based description directly uses the 3D position of each joint acquired by motion capture [26], etc. The angle-based description determines a skeletal reference shape, such as T-pose or A-pose. It uses Euler angles and rotation vectors to describe the rotation of each joint from the reference shape.

The Attention mechanism aggregates all of the time and joint infor- mation in the input indistinctly. For this purpose, the proximity of time and joint is assigned to the feature vector by Positional Encoding. Our method uses Absolutely Positional Encoding (APE) to obtain features that depend on absolute time and specific joints and Relative Positional Encoding (RPE) to obtain generalized features that do not distinguish the timing of occurrence.

Following the standard evaluation metrics used in Res-sup [10], the Mean Per Joint Position Error (MPJPE), which describes the av- erage distance from the ground-truth value of each joint position in millimeters, is used to evaluate the results. The prediction times were compared for 80, 160, 320, and 400 [ms] as in the previous study. We measured the MPJPE for the output angle converted to the position by forward-kinematics. As a baseline, we compared the results of our method with those of four recent methods: Res-sup, Traj- GCN, DMGNN, and MSR-GCN. We used the results reported in each paper for each error directly. Since DMGNN [13] did not report the

In the ablation of data description, the performance of long-term prediction without position-based and short-term prediction without angle-based are lower than our original. We interpret this result that the position-based description affects long-time prediction since it detects global features of the whole body. In contrast, the angle-based involves short-time prediction since it detects local features of each joint unit.

constraints such as connection relation and link length invariance by using angle as output. By selecting the appropriate architecture for ex- tracting the features of position and angle, we create an inference that can predict with high accuracy even for non-periodic and difficult-to- generalize motion classes. The results show that our model outperforms the state-of-the-art methods in short-term prediction.

Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I. Attention is all you need. In: Guyon I, Luxburg UV, Bengio S, Wallach H, Fergus R, Vishwanathan S, Garnett R, editors. Proceedings of the neural information processing systems (NeurIPS), vol. 30. Curran Associates, Inc.; 2017.

