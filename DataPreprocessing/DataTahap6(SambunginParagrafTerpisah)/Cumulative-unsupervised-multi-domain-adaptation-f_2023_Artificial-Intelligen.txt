However, annotating every cow in each farm is cost-prohibitive. Our objective is to develop Re-ID methods applicable to both labeled and unlabeled farms, accommodating new individuals and diverse environments. Un- supervised Domain Adaptation (UDA) techniques bridge this gap, transferring knowledge from labeled source domains to unlabeled target domains, but have only been mainly designed for pedestrian and vehicle Re-ID applications.

Our work introduces Cumulative Unsupervised Multi-Domain Adaptation (CUMDA) to address challenges of lim- ited identity diversity and diverse farm appearances. CUMDA accumulates knowledge from all domains, enhanc- ing specialization in known domains and improving generalization to unseen domains. Our contributions include a CUMDA method adapting to multiple unlabeled target domains while preserving source domain performance, along with extensive cross-dataset experiments on three cattle Re-ID datasets. These experiments demonstrate significant enhancements in source preservation, target domain specialization, and generalization to unseen domains.

retrieve individuals of interest through camera networks with non- overlapping fields of view. The introduction of supervised learning, fa- cilitated by deep Convolutional Neural Networks (CNNs) Krizhevsky et al. (2012), has significantly advanced the performance of supervised person Re-ID Ye et al. (2021).

The Re-ID paradigm has expanded beyond pedestrian tracking to en- compass a broader array of real-world applications, including vehicle Re-ID for traffic surveillance Khan and Ullah (2019) and animal Re-ID for monitoring cattle Schneider et al. (2020); Liu et al. (2019a, 2019d, 2019b).

Dubourvieux et al. (2021a). UDA seeks to adapt a model to a domain of interest by leveraging an annotated dataset from another domain (the source domain) and unlabeled data from the domain of in- terest (the target domain). While extensively explored for pedestrian and vehicle Re-ID, UDA proves particularly relevant in cow Re-ID appli- cations, given the impracticality of annotating each cow in numerous farms.

To our knowledge, existing UDA Re-ID methods have primarily focused on multi-domain scenarios with multiple annotated source domains. No UDA Re-ID approach has been designed specifically for multiple unlabeled target domains. Moreover, while the Domain Gener- alization framework Wang et al. (2021) seeks to create models that per- form well on unseen target domains, it differs from CUMDA. CUMDA assumes knowledge of all target domains during training and access to unlabeled data from these domains, with the objective of enhancing specialization and cross-domain Re-ID performance through knowledge accumulation. While generalization is not the primary aim, we antici- pate that a CUMDA model, through the accumulation of knowledge from diverse target domains, can enhance its generalization to previously unseen domains.

Prior works highlighted the negative impact on training stage when computing batchnorm statistics with data from different domains Zajkac et al. (2019). Domain-Specific Batch Normalization (DSBN) layers have been proposed to be effective for various domain adaptation problems such as UDA classification Chang et al. (2019a) and UDA re-ID Dubourvieux et al. (2021a). It consists in using domain-specific batchnorm affine parameters and computing domain-specific mean and variance. Other network parameters are still shared and used what-

Image extraction. The images were extracted over one month of ac- quisition. The extraction of cow images from the video stream relies on an oriented bounding-box detector and a tracker. The boxes are centered around cow torsos, excluding their heads, with all individuals facing right. For more details on data acquisition, please refer to Gao et al. (2021).

HolsteinCattleRecognition Bhole et al. (2019) is a dataset featuring RGB and infrared images of 1237 individuals. The data was acquired by a pinhole camera placed at gound level, 5 m away from the milking machine it films. For concision, we refer to it as HolsteinCattle in the rest of the paper.

Image extraction. The images were extracted over nine days of ac- quisition. Each of them contains a single cow in the milking machine. For more details on data acquisition, please refer to Bhole et al. (2019). IDs & samples. In this study, only the RGB data is used. A total of 1227 images depicting 136 distinct individuals were extracted, for an average of 9 shots per identity. More details on image repartition can

CowFisheye is a private dataset featuring RGB images of 78 individ- uals. It was acquired from a single farm from 4 fisheye cameras pointing downwards, positioned 6 m above the ground. Identities were annoted manually. This dataset reflects the usual challenging data encountered in the use case where cows must be identified 24/7 wherever they are in the farm.

ing rate is set to lr  3 5 10 4. Both triplet and cross-entropy losses are used during the training. Source and target share the same fully con- nected layer for classification. When using MMT, testing is systemati- cally done on model number 1 as in real-world applications since determining which model performs best on the target is impossible. In- deed, the target dataset is not annotated. Concerning the adaptation on multiple target datasets, when applicable, DSBN is generalized so as to have one Batch Normalization (BN) per domain. During testing, the BN of the domain that is most similar in appearance to the tested do- main is used. More specifically, the test domain BN is used if it has been computed during training. Otherwise, the BN of CowFisheye is used when testing on Cows2021 or HolsteinCattle, and the BN of Cows2021 is used when testing on CowFisheye.

Because most datasets are extracted from a unique camera, the eval- uation is done without filtering images from the same camera. The mean Average Precision (mAP) is reported as evaluation metric. It is an indicator of the network ability to correctly recall the different shots in a gallery corresponding to a query individual, and should be maximized.

For completeness sake, rank-1 is also reported in Appendix A. It indi- cates the accuracy of the rank-1 proposal for each query individual and is representative of the retrieval performance. However, rank-1 is sensi- tive to shortcomings in the dataset that are especially present in the studied cattle re-id use case (low diversity of images, noise etc.). There- fore, all in text analysis will be made on mAP as it is more robust and representative of the performance on the whole dataset.

experiments stand out. First, the direct transfer Cows2021 HolsteinCattle shows the poorest performance on the target domain at 8.0% mAP vs the 81.2% which can be attained if annotations were avail- able. Second, the direct transfer CowFisheye Cows2021 shows the highest performance of all cross-domain experiments, with 71.0% mAP on the target dataset. These results indicate that the domain gap be- tween farms greatly influences the network ability to perform on a new style of images and is higher between HolsteinCattle and the other datasets than between CowFisheye and Cows2021. Also, the abundance of information present in CowFisheye with its varied view- points and occultations helps bridge the gap with other domains as shown by higher direct transfer scores when pre-training on CowFisheye.

In conclusion, we find that HyPASS-SC has a positive effect on perfor- mance on all datasets. Indeed, it ensures good clustering on all targets. This allows for better source conservation, target specialization and generalization on an unseen dataset than the other approaches pre- sented here.

In the cross-domain HolsteinCattle Cows2021, an oversampling of HolsteinCattle from 9 shots/ID to around 90 shots/ID is carried out. As a result, the ARI doubles, increasing from 0.40 without calibration, to 0.83 with it. In terms of mAP, the performance on the target Cows2021 in- creases from 77.4% without calibration, to 87.2% with it.

In the cross-domain CowFisheye HolsteinCattle, a subsampling of CowFisheye from 112 shots/ID to around 9 shots/ID is carried out. The resulting ARI increase is substantial, evolving from 0.03 without calibra- tion, to 0.23 with it. In terms of mAP, the performance on the target HolsteinCattle increases from 29.3% without calibration, to 38.6% with it. These results show the importance of source validation set calibra- tion in the case of datasets with highly different number of shots per ID, which can be a recurrent issue when dealing with animal datasets.

DSBN allows some domain gap alleviation through domain specific normalization. It also authorizes domains to share the same backbone, which helps generalization. HyPASS-SC provides optimized clustering parameters on each target dataset, depending on its statistics. This en- sures good clustering quality on the target domains, which in turn in- creases the network performance on all datasets.

This is a peculiarity of the cow re-ID problem. Indeed, color information usually facilitates the pseudo-labeling in human re-ID and the performance of unsupervised UDA is close to the performance of su- pervised training Ge et al. (2019). For cow re-ID, color does not contain relevant information for pseudo-labeling. Therefore, subtle information such as shape has to be considered instead. Also, in this paper and cow re-ID in general, the domain gap existing between the chosen datasets can be greater than the one usually seen in person re-ID.

In other words, even if the pseudo-labelling hyperparameters are automatically optimized, the proposed solution is still limited by the pseudo-labelling strategy itself. Namely, pseudo-labels quality depend on the the chosen clustering algorithm, and the networks ability to extract discriminative representations. Detailed discussion on the influence of pseudo-labelling methods on UDA can be found in Dubourvieux et al. (2021b).

