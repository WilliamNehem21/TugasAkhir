

Electronic Notes in Theoretical Computer Science 267 (2010) 101–114
www.elsevier.com/locate/entcs

Extending Abstract Acceleration Methods to Data-Flow Programs with Numerical Inputs
Peter Schrammel1,2 and Bertrand Jeannet3
INRIA Rhoˆne-Alpes, Grenoble, France

Abstract
Acceleration methods are commonly used for computing precisely the effects of loops in the reachability analysis of counter machine models. Applying these methods on synchronous data-flow programs with
Boolean and numerical variables, e.g. Lustre programs, firstly requires the enumeration of the Boolean
states in order to obtain a control graph with numerical variables only. Secondly, acceleration methods have to deal with the non-determinism introduced by numerical input variables. In this article we address the latter problem by extending the concept of abstract acceleration of Gonnord et al. to numerical input variables.
Keywords: Static analysis, acceleration, abstract interpretation, linear relation analysis.

Introduction
This paper considers the reachability analysis of synchronous programs manipulat- ing Boolean and numerical variables, and more generally the reachability analysis of logico-numerical programs, that are symbolic automata combining Boolean and numerical variables. The applications of such a reachability analysis are for instance the verification of safety properties [16] or model-based testing [19].
Abstract interpretation and acceleration.  Since the reachability problem is not decidable for logico-numerical programs, two main approaches have been studied:
Abstract interpretation techniques [6,7] compute only an over-approximation of the reachability set, but terminate always.
Acceleration techniques [21,2,3] compute the exact reachability set in favorable cases, but without guarantee for termination.

1 This work was supported by the INRIA large-scale initiative Synchronics.
2 Email: peter.schrammel@inrialpes.fr
3 Email: bertrand.jeannet@inrialpes.fr


1571-0661 © 2010 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2010.09.009

τ
=⇒

Fig. 1. Simple loop transition (left) and accelerated transition (right).


In both approaches, the set of reachable states is obtained by solving iteratively an equation of the form X = X0 ∪ post (X) where X is a set of states, X0 the initial set, and post the postcondition operator associated with the program.
Abstract interpretation is a classical method for analyzing programs with infinite state space. The key idea is to approximate sets of states X by an element Y of an abstract domain. A classical abstract domain for numerical invariants X ∈ ℘(Rn) is the domain of convex polyhedra Pol(Rn) [9], that can be represented as a con- junction of linear inequalities. An approximation of the reachable set is computed by solving iteratively the equation Y = Y 0 H post (Y ) in the abstract domain. In order to ensure termination when the abstract domain contains infinitely increas- ing sequences, an extrapolation operator called widening is applied, which induces additional approximations.
The idea of acceleration is to accelerate cycles τ in the control structure of a program, by computing the effect of their transitive closure τ∗ on a set of states, see Fig. 1. If the program is flat (i.e. it does not contain nested loops) and all loops can be accelerated, then the method is complete. If the program contains nested loops the method is semi-complete: One starts enumerating and accelerating non- elementary cycles (which form an infinite set) in the hope of converging after a finite number of steps to the smallest fixed point. The same remark applies if transition functions in some cycles are too expressive to be accelerated. Acceleration has been mostly applied to automata manipulating integer variables using Presburger arithmetic [12,11,2], or FIFO queues using subclasses of regular expressions [4,1].
Widening basically extrapolates the limit of a sequence of abstract invariants without referring to the program that generates them, whereas acceleration uses the structure of the program to perform an exact extrapolation. Gonnord et al. [15,14] have proposed the concept of abstract acceleration which combines these approaches: Wherever possible, elementary loops are accelerated in the abstract domain, and in any other cases (nested loops, too expressive transitions) one resorts to the use of widening to guarantee the convergence of the approximated fixed point computation.
Abstract acceleration and logico-numerical programs. Acceleration tech- niques such as [21,2] consider purely numerical automata. There are two short- comings of the abstract acceleration approach when applied to logico-numerical programs such as Lustre [5] data-flow programs:
In order to reduce such a program to a purely numerical automaton, all possible valuations of Boolean state variables need to be enumerated and encoded in a control graph. This partitioning and partial evaluation process may lead to a

combinatorial explosion of control locations.
The concept of input variables as encountered in Lustre programs requires an extension of the results of [15,14]. As opposed to Boolean input variables that can be encoded in an automaton by finite non-deterministic choices, numerical input variables demand a more specific treatment.
This article especially addresses point (ii), although point (i) is our ultimate goal.
Contributions and outline. Our contribution is to extend the abstract acceler- ation concept as introduced in [15] to systems with numerical inputs, which raises some subtle points. In particular we show how to accelerate loops composed of a translation with resets and inputs, provided that the guard of the loop constrains separately state and input variables. Without this restriction indeed, one can em- ulate any affine transformation without inputs. After some preliminary notions in Section 2 about the considered program model, the operations on convex polyhedra and the general verification framework that we use for analysis, we recall the main results of abstract acceleration in Section 3. Section 4 details our contribution. We conclude in Section 6.

Analysis of Logico-Numerical Programs
Program model.  We consider in this article programs modeled as a symbolic

transition system	init (s)
assert (s, i) → s∗ = f (s, i)
where (1) s and i are vectors of state

and input variables, that are either Boolean or real; (2) init (s) is an initial condition on state variables; (3) assert (s, i) is an assertion constraining input variables de- pending on state variables, and typically modeling the environment of the program;
(4) f is the vector of transition functions.

An execution of such a system is a sequence s
0
−→ s
1
−→ ... s
k
−→ ... 
such

that init (s0) and for any k ≥ 0, assert (sk, ik) ∧ sk+1 = f (sk, ik).
This program model corresponds for example to the output of the front-end compilation of synchronous data-flow programs like Lustre and includes various models of counter automata (by emulating locations using Boolean variables) [3]. A control graph manipulating only numerical variables can be generated from this program model by performing a partial evaluation [20] of all Boolean state vari- ables (which are then encoded in control locations) and eliminating Boolean input variables by non-deterministic choices. The partition refinement mechanics imple- mented in the NBac tool [18] are capable of achieving this task and have been employed for connecting the Aspic tool [14,13] to Lustre, for example.
Convex Polyhedra. We use in this paper the abstract domain of convex polyhe- dra for representing invariants on numerical variables. Besides classical operations (intersection, convex hull, assignments of variables by linear expressions, . . . ) de- scribed e.g. in [17], we will use the following operations:

The time elapse operation [17] X 3 D = {x + td | x ∈ X, d ∈ D, t ∈ R≥0} is practically implemented as follows: Let (VX, RX ) respectively (VD, RD) be the systems of generators of the polyhedra X and D then (VX, RX ∪ VD ∪ RD) is a system of generators of the polyhedron X 3 D.
The Minkowski sum [10] of two polyhedra X  = X1 + X2 is defined as
X(x) = Ex1, x2 : (x = x1 + x2) Λ X1(x1) Λ X2(x2).
Overview of Acceleration and Abstract Acceleration
As mentioned in the introduction, the idea of acceleration (Fig. 1) is to replace a loop transition τ by a single transition τ∗ that computes the transitive closure of τ . Abstract acceleration [15,14] relaxes exact acceleration in the sense that it aims at approximating the exact set τ∗(X) by its convex hull τ⊗(X) ≥ τ∗(X). This method is also inspired by the time elapse operator used in timed or in hybrid automata [17].
Following the notations of Section 2, a loop transition τ will have the structure: G → A meaning “while guard G do action A”. Generally, acceleration methods for numerical variables x deal with transitions of the form
Ax ≤ b → x∗ = Cx + d	(1)
where Ax ≤ b represents a conjunction of linear constraints defining a convex polyhedron, and x∗ = Cx + d is an affine transformation; C is a square matrix. A transition is called
a reset if C is the zero matrix,
a translation if C is the identity matrix,
a translation with resets (or translation/reset) if C is a diagonal matrix with zeros and ones only,
a periodic affine transformation if Ep > 0 : Cp = C2p,
a general affine transformation otherwise.
Existing acceleration methods cannot deal with general affine transformations. We will not discuss the case of periodic affine transformations, as it seems to be of limited practical interest.
In the context of abstract acceleration, [15,14] shows that translations (Fig. 2) and translations with resets (Fig. 3) can be accelerated as follows, with X denoting a convex polyhedron and G(x) = (Ax ≤ b) an affine guard (which is also a convex polyhedron):
Theorem 3.1 Let τ be a translation G → xs = x + d. The convex polyhedron
τ⊗(X) = X H	(X H G) 3 d H G(x — d)
is a convex over-approximation of τ∗(X).
Theorem 3.2 Let τ be a translation with resets G → xs = Cx + d. The convex polyhedron




d
G(x — d)
d	x2
X
G



d2

Cd)

Fig. 3. Acceleration of a loop with translations/resets: On the left hand

side, the application of τ (X) – here, with x'
= x1 + d1 and x'
= d2,

Fig. 2. Acceleration of a transla- tion loop starting from X (dark
shadowed) resulting in τ⊗(X) (whole shadowed area).
yields a polyhedron (bold line including arrow) containing the reset val-
ues. The accelerated transition gives τ⊗(S) (shadowed) on the right hand side.

τ⊗(X) = X H τ (X) H	(τ (X) H G) 3 Cd H G(x — Cd)
is a convex over-approximation of τ∗(X).
Remark 3.3 Theorem 3.2 exploits the property that a translation with resets to constants iterated N times is equivalent to the same translation with resets followed by a pure translation iterated N —1 times, hence the obtained formula.
Remark 3.4 Ideally, τ⊗(X) as defined in Theorems 3.1 and 3.2 should be the best over-approximation of τ∗(X) by a convex polyhedron. This is not the case as shown by the following example in one dimension.  Let X = [1, 1] and τ :
x1 ≤ 4 → x∗ = x1 + 2. τ⊗(X) = [1, 6], whereas the best over-approximation of
τ∗(X) = {1, 3, 5} is the interval [1, 5]. This is because the operations involved in
τ⊗(X) manipulate dense sets and do not take into account arithmetic congruences. We will not improve on this in this work, but we will point out in our proofs where this dense approximation takes place.
These theorems can be applied on a control graph by dividing locations with a single self-loop (as shown in Fig. 1). If there are several self-loops in a location then the cases where guards overlap and where they are disjoint must be distinguished, which results in a more elaborate division of the location. [14] gives a range of methods for dealing with more complex cases.
Abstract Acceleration with Numerical Inputs
We now extend numerical abstract acceleration w.r.t. numerical input variables y. This means that we consider transitions of the form

 A L   x  ≤  b  → xs =  C T  x  + u

(2)

` Ax+Ly≤˛b¸ ∧ Jy≤k x	`	Cx+˛T¸y+u	x
Note that the 0 in the matrix of the guard does not imply a loss of generality.
A fundamental observation is that any general affine transformation without inputs Ax ≤ b → xs = Cx + d can be expressed as a “reset with inputs” (Ax ≤

b Λ y = Cx + d) → xs = y. This means that there is no hope to get precise acceleration for such resets with inputs, unless we know how to accelerate precisely general affine transformations without inputs, which is out of the scope of the current state of the art.
Nevertheless, we can accelerate transitions with inputs when the constraints on the state variables do not depend on the inputs, i.e. when L = 0 in Eqn. (2) and the guard is of the form Ax ≤ b Λ Jy ≤ k. We call the resulting guards simple guards. Otherwise, we provide in Section 4.3 a weaker over-approximation of the
exact result for general guards.

Translations with inputs and simple guards

J	y	k	y
identity matrix.
First of all, assume that in a translation without inputs d is not constant, but constrained to be inside a convex polyhedron D. Then Theorem 3.1 can be gener- alized to such polyhedral translations.
Proposition 4.1 Let τ be a transition G → xs = x + d with G(x) = (Ax ≤ b), d ∈ D and D a convex polyhedron. The set
τ⊗(X) = X H τ (X H G) 3 D
is a convex over-approximation of τ∗(X).
Note that τ (X) can be implemented by standard polyhedra operations: τ (X) = (X H G)+D.
Proof. In the proof, the guard G is seen alternatively as a predicate or a set.

xs ∈ .k≥1 τk(X)

 
⎧⎨ xs = x0 + Σk

dj Λ G(x0) Λ
	 

e Ek ≥ 1, Ex0 ∈ X, Ed, dk ∈ D, Exk—1 :
xk—1 = x0 + (k—1)d Λ G(x0) Λ G(xk—1) Λ xs = xk—1 + dk (because D and G are convex)
⇒ Eα≥ 0, Ex0 ∈ X H G, Ed, ds ∈ D, Exss :
xss = x0 + αd Λ xs = xss + ds Λ G(xss)	(dense approximation)
e Exss ∈ (X H G) 3 D H G, Eds ∈ D : xs = xss + ds


We conclude by observing that  (X H G) 3 D H G + D = τ (X H G) 3 D . 2
Mind that the only approximation takes place in the line (⇒) where the integer coefficient k— 1 ≥ 0 is replaced by a dense coefficient α ≥ 0. This is the technical explanation of Remark 3.4.

Remark 4.2 One might think that Theorem 3.1 can be applied directly by accel- erating the transition for each d ∈ D and taking the union, i.e. computing τ∗(X) by X H d∈D Xd with Xd = (X H G) 3 d H G(x — d), but there is a subtle difference: This formula computes the correct set for all states reachable within G, but for the last step crossing the border of G it allows only those vectors d having been used for the previous iterations, whereas actually there is a choice among all d ∈ D.
The following proposition reduces translations with inputs to generalized transla- tions:
Proposition 4.3 A  translation  with  inputs  and  a  simple  guard  τ
is  equivalent  to  a  polyhedral  translation  without  inputs  deﬁned  by
Ax ≤ b Λ d ∈ D → x∗ = x + d
= {d | Ey : d = Ty + u Λ Jy ≤ k}
D
Note that D can be computed by standard polyhedra operations.
Proof.
xs ∈ τ (X) e Ex, Ey : Ax ≤ b Λ Jy ≤ k Λ xs = x + Ty + u
e Ex, Ey, Ed : Jy ≤ k Λ d = Ty + u Λ Ax ≤ b Λ xs = x + d
e Ex, Ed ∈ D : Ax ≤ b Λ xs = x + d
with D = {d | Ey : Jy ≤ k Λ d = Ty + u}
2
Theorem 4.4 The accelerated transition τ⊗ for a translation with inputs and sim- ple guard τ can be computed by applying Propositions 4.1 and 4.3.
Example 4.5 Consider the polyhedron X = {(x1, x2) | 0 ≤ x1 ≤ x2 ≤ 1} and
the transition τ :	x1 + x2 ≤ 4	x∗ = x1 + 2y — 1 .  Eliminating the inputs
≤ y ≤ 2	∗ = x2 + y
as in Proposition 4.3 yields D = {(d1, d2) | 1 ≤ d1 ≤ 3 Λ —d1 + 2d2 = 1}, see Fig. 4 left. After translation of X by D (Fig. 4 right) we obtain the polyhedron
{(x1, x2) | x1 ≥ 0 Λ —x1+x2 ≤ 1 Λ x1+x2 ≤ 9 Λ —2x1+4x2 ≤ 9 Λ 2x1—3x2 ≤ 0}.

Remark 4.6 In analogy to Theorem 3.1, we could consider the formula XH((((XH
G) 3 D) H (G + D)). In order to justify this, we extend the proof of Proposition
4.1 continuing at the label (dense approximation):
e Eα≥ 0, Ex0 ∈ X H G, Ed, ds ∈ D : xs = x0+αd+ds Λ G(xs—ds)
⇒ (Eα≥ 0, Ex0 ∈ X H G, Ed, ds ∈ D : xs = x0+αd+ds)Λ
(Eds ∈ D : G(xs—ds))
⇒ xs ∈ (X H G) 3 D Λ xs ∈ (G + D)
using {x | Ed ∈ D Λ G(x — d)} = {z + d | d ∈ D Λ G(z)} = (G + D). But it can be observed that for the translation of example 4.5 the latter formula results in an









Jy y
Fig. 4. Translation with inputs: Example 4.5: The left hand side shows the transformation of the inputs: Jy ≤ k ∧ d = Ty + u (bold line) is projected on variables d. The shadowed area in the right
figure is the result of the accelerated transition τ⊗(X).




Fig. 5. Precision loss in example 4.5 when using the approximate for- mula according to remark 4.6.


over-approximation (see Fig. 5) as compared to the result in Fig. 4. This reflects the additional approximation steps in the proof.


Translations/Resets with inputs and simple guards

These are defined by  A 0   x  ≤  b  → xs =  C T  x  + u where C is a
diagonal matrix with Ci,i ∈ {0, 1}.
Notations. Let C∗ = I — C with I the identity matrix. Any vector x can be decomposed in x = xt + xr with xt = Cx and xr = C∗x. We extend such notations to sets: Xt = {xt | x ∈ X} and Xr = {xr | x ∈ X}. If I denotes the set of dimensions, It = {i ∈ I | Ci,i = 1} and Ir = I\It are the set of translated and reset dimensions. Any set X can be approximated by the Minkowski sum Xt + Xr, which can also be seen as the Cartesian product of X projected on the subspace of translated dimensions and X projected on the subspace of reset dimensions.
This case can be handled in a way similar to Section 4.1: We combine Theo- rem 3.2 and Proposition 4.3 reducing translations/resets with inputs to generalized translations/resets without inputs. Mind, however, that remark 3.3 does not apply any more and cannot be exploited in the presence of inputs, because the variables being reset may be assigned a different value in each iteration.

Proposition 4.7 . Let τ be a translation with resets G → xs = Cx + d with
G(x) = (Ax ≤ b), d ∈ D and D a convex polyhedron. The set
τ⊗(X) = X H τ (X) H τ	(τ (X) H G)t 3 Dt  + Dr
is a convex over-approximation of τ∗(X).

Proof. The formula is trivially correct for 0 or 1 iterations, so, it remains to show that for the case of k ≥ 2 iterations our formula yields an over-approximation of
.k≥2 τk(X).

xs ∈ .k≥2 τk(X)

e Ek ≥ 2, Ex0
⎪
∈ X, Ed1
s = x
... dk
∈ D, Ex1
... xk :

⎪⎨	k	⎧⎨
i	Σk'	i	t

Λ 6k∗ ∈ [1, k] :
⎪
xks
⎩ xks i
= x0 +
= dks i
j=1 dj
for i ∈ I
for i ∈ Ir

⎪⎩ Λ G(x) Λ 6k∗ ∈ [1,k—1] : G(xks )

⎧⎨	0	1 Σ  k	1	k

⎩ Λ G(x) Λ 6k∗ ∈ [1,k—1] : G(xt + (Σk'
dt)+ dr )



⎪⎧⎪

x1 = xt + d1
∗
2	k—1

t
2
Σk'	t
k—1

r

1	k	Λ xs =
⎪⎩

t k—1
+ dk




e Ek ≥ 2, Ex ∈ X H G, Ed , d
⎪
∈ D, Edt ∈ Dt, Edr ... dr	∈ Dr, Ex1 ... xk :

⎪⎨	x1	x0	1
k—1	1
k—1

⎪⎩ Λ xs = xt	+ dk
(because Dt and G are convex)
⇒ Eα≥ 0, Ex0 ∈ X H G, Ed1, ds ∈ D, Edt ∈ Dt, Edr ∈ Dr, Exss :
⎨
	

⎩ Λ xs
sst	s

(dense over-approximation)
e Eα≥ 0, Ex1 ∈ τ (X) H G, Eds ∈ D, Edt ∈ Dt, Edr ∈ Dr, Exss :
xss = xt + αdt + dr Λ G(xss) Λ xs = xsst + ds
e Exss ∈  (τ (X) H G)t 3 Dt + Dr H G, Eds ∈ D, xs = xsst + ds
e xs ∈   (τ (X) H G)t 3 Dt + Dr H G t + D
The last expression is equal to τ   (τ (X) H G)t 3 Dt + Dr .	2
Theorem 4.8 The accelerated transition τ⊗ for a translation/reset with inputs and a simple guard τ can be computed by applying Proposition 4.7 with D deﬁned as in Proposition 4.3.
Example 4.9 Consider the polyhedron X = {(x1, x2) | 0 ≤x1 Λ 1 ≤x2 Λ x1+x2 ≤ 2}

x2	x2

1	1




Fig. 6. Translation/reset with inputs: Example 4.9. Left hand side: τ (X) (dark shadowed) and ((τ (X) H G)t ) Dt)+ Dr (whole shadowed area). Right hand side: τ (((τ (X) H G)t ) Dt)+ Dr) (dark shadowed) and τ⊗(X) (whole shadowed area).

and the transition τ :  2x1 + 2x2 ≤ 7	x' = x1 + y +1 . Eliminating the inputs
0 ≤ y ≤ 1	' = y
yields D = {(d1, d2)|1 ≤d1 ≤ 2Λd1—d2 = 1} and Dt = {(d1, d2)|1 ≤d1 ≤ 2Λd2 = 0}. We obtain τ⊗(X) = {(x1, x2)|x1+x2 ≥ 1 Λx2 ≥ 0 Λ 2x1—2x2 ≤ 9 Λ 2x1+11x2 ≤ 22 Λx1 ≥ 0}, see Fig. 6.


Weakening general guards to simple guards
As discussed at the beginning of Section 4, allowing constraints on both state and input variables in guards (L /= 0 in Eqn. (2)) makes acceleration very difficult. Our solution is to weaken the guard G(x, y) = Ax + Ly ≤ b Λ Jy ≤ k by the simple guard (or cartesian product) G¯ = (Ey : G) Λ (Ex : G) and to apply Theorems 4.4

`A'˛x¸≤bs x
`J'y˛≤¸ks x

and 4.8. This trivially results in a sound over-approximation because a weaker guard is used for abstract acceleration.
Example 4.10 Consider the polyhedron X = {(x1, x2) |x1 ≤ 1 Λx2 ≤ 1 Λx1+x2 ≥ 1}


and the transition

τ (X
2x1 + x2 + y ≤ 6
) :	2
→  x1
= x1 + y +1 . The weakened

x2 — y ≤
0 ≤ y ≤ 1
 x2
= x2 +1 

guard is G¯ = (2x1+x2 ≤ 6 Λ x1+x2 ≤ 4 Λ x2 ≤ 3) Λ (0 ≤y ≤ 1). Eliminating the inputs yields D = {(d1, d2) | 1 ≤ d1 ≤ 2 Λ d2 = 1}. We obtain τ⊗(X) = {(x1, x2) | x1 +x2 ≥ 1 Λ x2 —x1 ≤ 1 Λ —4 ≤ x1 —2x2 ≤ 1 Λ x1 +2x2 ≤ 10 Λ 2x1 +x2 ≤ 10}, see Fig. 7. The convex hull of the exact result is {(x1, x2) | x1+x2 ≥ 1 Λ —2 ≤x2—x1 ≤ 1 Λ x1—2x2 ≤ 1 Λ x2 ≤ 3 Λ 2x1+x2 ≤ 10}, see Fig. 8.

Comparison with widening
The standard widening operator for convex polyhedra and refinements of it like limited widening [17] 4 may sometimes lead to good results. In this section, we compare the acceleration and the widening approaches on Examples 4.9 and 4.10.

4 Limited widening is also called widening with thresholds [8].

x2


1
1	x1

Fig. 7. Example 4.10: Accelerated tran- sition τ⊗(X) using the weakened guard G (result shadowed).
τ
Fig. 8. Example 4.10: comparison between convex hull of the exact result (dark grey), our method (grey), and widening with no delay and 3 (!) descending iterations (light grey)
τ



X
X'	X

p = p+1
X
p = p+1

Fig. 9. Analysis with acceleration (left)
and with widening (right) for Exam- ples 4.9 and 4.10
Fig. 10. Analysis with acceleration (left) and with widening (right) for Example 5.1.

Analyzing such a program using widening after a number N of initial steps resorts to computing the limit of the sequences
Y0 = X	Z0 = YN
Yn+1 = X H τ (Yn)	for n < N	Zn+1 = Zn∇(Zn H τ (Zn))
in which Xn, Yn, Zn are associated with location l on Fig. 9. The technical proper- ties of the widening operator ∇ guarantee that the sequence (Zn)n≥0 converges in a finite number of steps to Z∞ [7], which is an over-approximation of the reachable valuations at location l. This result may be improved by computing the first ele- ments of the sequence W0 = Z∞, Wn+1 = X H τ (Wn), which does not necessarily converge.

Translation/reset with inputs and simple guard
If we compute the sequences defined above in the context of Example 4.9, we obtain with N = 0 
Z∞ = Z1 = {(x1, x2) | x1 ≥ 0}
W1 = {x1 ≥ 0 Λ x2 ≥ 1 Λ x1+x2 ≥ 1 Λ x2 ≤ 2}	W∞ = W2 = τ⊗(X)
Delaying widening by one step (N = 1) improves the result for Z∞ and makes the sequence (Wn)n≥0 converge in only one step:
Z∞ = Z1 = {x1 ≥ 0 Λ x2 ≥ 1 Λ x1+x2 ≥ 1}
W∞ = W1 = τ⊗(X)
In both cases Z∞ is clearly much less precise than the result obtained by accelera- tion: neither x1 nor x2 get upper bound (to be compared with Fig. 6).

One or two descending iterations allow to get the same result as the one obtained by acceleration. However, it should be pointed out that if this loop is a program fragment, for instance embedded in an outer loop as in Fig. 10, it is not possible any more to apply a descending iteration in the middle of an ascending iteration (otherwise convergence is not guaranteed). Moreover, the acceleration technique is more efficient computationally (in particular it does not require convergence tests), and it has a monotonic behavior, which is not the case of widening.
Example 5.1 To illustrate these points, we consider the program depicted on Fig. 10 in which the inner loop τ is adapted from Example 4.9:

  x1
+ 2x2 ≤ p
x' = x1+y +1
 
 0 ≤x1
Λ 1 ≤x2	⎫⎬

τ :
	≤ y ≤
→ x' = y
 
, X =	(x1, x2, p)
⎩
x +x
≤ 2 Λ p =1 

' = p	1	2
In both cases we apply widening on location l with a delay N = 1, and we per- form one descending iteration after convergence of the ascending iteration. Without acceleration, we obtain a very weak invariant:
Z∞ = {(x1, x2, p) | x1 ≥ 0 Λ p≥ 1}	W∞ = W1 = Z∞

With acceleration we obtain much better results:

'  = Z∞ ∩ {(x1, x2, p) | x1+x2 ≥ 1 Λ x1—x2 ≤ 4 Λ x1+5x2 ≤ 10}
W' = W' = Z' ∩ {(x1, x2, p) | p≤ 20}
∞	1	∞

One can also consider widening with thresholds, that keeps in the result of the widening operation the subset of a fixed set of threshold constraints that are satisfied by both of its arguments. In the case of Example 4.9, a natural threshold constraint set is defined by the postcondition of the guard of τ by the body of τ , which is just τ (T) = {(x1, x2) | 0 ≤ x2 ≤ 1}. Using it with N = 0 one obtains the same Z∞ as with standard widening applied with N = 1. On Example 5.1 and with the same threshold set extended with {p ≤ 21}, the results are improved but are still less precise than those obtained by combining acceleration and widening (in particular the descending iteration does not converge).


Translation with inputs and non-simple guard
In the context of Example 4.10, we obtain with N = 0:
Z∞ = Z1 = {(x1, x2) | x1+x2 ≥ 1}
W1 = {(x1, x2)  | x1+x2 ≥ 1 Λ 2x1+x2 ≤ 10 Λ x2 ≤ 4Λ
0 ≤x1 ≤ 6 Λ 3x1+5x2 ≥ 3}
... 
W3 = {(x1, x2)  | x1+x2 ≥ 1 Λ 2x1+x2 ≤ 10 Λ 3x2—2x1 ≤ 6 Λ 3x2—4x1 ≤ 3Λ
5x1—22x2 ≤ 8 Λ 29x1—157x2 ≤ 29} N τ⊗(X)

Again Z∞ is very unprecise, but here the descending iteration does not converge (even if we use widening with thresholds), see Fig. 8 for W3. If we use N = 1, then Z∞ is more precise, and W∞ = W1 = τ⊗(X).
These results are just small experiments, but they illustrate the sensitiveness of widening (if we delay it, it might improve the result, but this is not guaranteed either because it is not monotonic) and the fact that if the loop is part of a more complex program, the result might be much less precise.


Conclusion
We have presented an extension of abstract acceleration to numerical inputs. This extension is less straightforward than supposed – most notably due to the obser- vation that inputs can be used to turn translations into arbitrary affine transfor- mations; also, resetting variables to input values may cause some subtle behavior. Our methods are ready for use in purely numerical automata by adopting the par- titioning methods from [14] for treating more complex cycles than the case of single self-loops that we have presented in this article. Moreover, limiting ourselves to con- vex guards and inputs that are contained in convex polyhedra is not a theoretical restriction of our methods, since non-convex polyhedra can always be decomposed in convex ones.
Acceleration vs. Widening. From a theoretical point of view acceleration has – in contrast to widening – some advantageous properties that underpin its utility as an auxiliary technique for treating loops: First, a better precision can be obtained since it directly exploits information from the program. Second, the number of iterations in fixed point computation decreases, because accelerating transitions effectively removes loops in the control graph. Furthermore, widening is not a monotonic operator, whereas acceleration is, which makes approximations more regular and predictable. Practical experience has to be gained in order to estimate the degree of improvement attained by these properties. Nonetheless, we have to resort to widening for non-accelerable transitions in order to ensure convergence.
Future work. As mentioned in the introduction, finding an appropriate control graph is the second issue (we have not dealt with in this article) in applying ac- celeration to logico-numerical programs, such as synchronous data-flow programs without explicit control flow. On the one hand the control graph should allow for a reasonably precise reachability analysis, on the other hand it should enable the use of abstract acceleration of numerical variables, while remaining sufficiently sym- bolic w.r.t. Boolean variables in order to prevent a combinatorial explosion. Our idea is to heuristically identify sets of states which behave like timed or linear hybrid automata, such that abstract acceleration can be applied.
Another direction is the extension to input variables of some results of [14] on the combined acceleration of several self-loops around the same location.

References
Abdulla, P. A., A. Collomb-Annichini, A. Bouajjani and B. Jonsson, Using forward reachability analysis for verification of lossy channel systems, Formal Methods in System Design 25 (2004), pp. 39–65.
Bardin, S., A. Finkel, J. Leroux and L. Petrucci, FAST: Fast acceleration of symbolic transition systems, in: Computer-Aided Verification (CAV) (2003), pp. 118–121.
Bardin, S., A. Finkel, J. Leroux and P. Schnoebelen, Flat acceleration in symbolic model checking, in:
Automated Technology for Verification and Analysis (ATVA), LNCS 3707 (2005), pp. 474–488.
Boigelot, B. and P. Godefroid, Symbolic verification of communication protocols with infinite state spaces using QDDs, Formal Methods in System Design 14 (1997), pp. 237–255.
Caspi, P., D. Pilaud, N. Halbwachs and J. A. Plaice, LUSTRE: a declarative language for real-time programming, in: Principles of Programming Languages (POPL) (1987), pp. 178–188.
Cousot, P. and R. Cousot, Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints, in: Principles of Programming Languages (POPL), 1977,
pp. 238–252.
Cousot, P. and R. Cousot, Abstract interpretation and application to logic programs, Journal of Logic Programming 13 (1992), pp. 103–179.
Cousot, P. and R. Cousot, Comparing the Galois connection and widening/narrowing approaches to abstract interpretation, in: PLILP’92, LNCS 631, 1992, pp. 269–295.
Cousot, P. and N. Halbwachs, Automatic discovery of linear restraints among variables of a program, in: Principles of Programming Languages (POPL) (1978), pp. 84–97.
de Berg, M., O. Cheong, M. van Kreveld and M. Overmars, “Computational Geometry: Algorithms and Applications,” Springer, 2008, 3rd edition.
Finkel, A. and J. Leroux, How to compose Presburger-accelerations: Applications to broadcast protocols, in: Foundations of Software Technology and Theoretical Computer Science (FSTTCS), Lecture Notes in Computer Science 2556 (2002), pp. 145–156.
Fribourg, L. and H. Ols´en, Proving safety properties of infinite state systems by compilation into presburger arithmetic, in: Conference on Concurrency Theory (CONCUR), LNCS 1243 (1997), pp. 213–227.
Gonnord, L., The ASPIC tool: Accelerated Symbolic Polyhedral Invariant Computation, http://laure. gonnord.org/pro/aspic/aspic.html.
Gonnord, L., “Acc´el´eration abstraite pour l’am´elioration de la pr´ecision en Analyse des Relations Lin´eaires,” Th`ese de doctorat, Universit´e Joseph Fourier, Grenoble (2007).
Gonnord, L. and N. Halbwachs, Combining widening and acceleration in linear relation analysis, in:
Static Analysis Symposium (SAS), Seoul, Korea, 2006, pp. 144–160.
Halbwachs, N., F. Lagnier and P. Raymond, Synchronous observers and the verification of reactive systems, in: Methodology and Software Technology (AMAST) (1993), pp. 83–96.
Halbwachs, N., Y.-E. Proy and P. Roumanoff, Verification of real-time systems using linear relation analysis, Formal Methods in System Design 11 (1997), pp. 157–185.
Jeannet, B., Dynamic partitioning in linear relation analysis. application to the verification of reactive systems, Formal Methods in System Design 23 (2003), pp. 5–37.
Jeannet, B., T. J´eron, V. Rusu and E. Zinovieva, Symbolic test selection based on approximate analysis, in: Tools and Algorithms for the Construction and Analysis of Systems (TACAS), LNCS 3440, 2005,
pp. 349–364.
Jones, N. D., C. Gomard and P. Sestoft, “Partial Evaluation and Automatic Program Generation,” Prentice Hall International, 1993.
Leroux, J., “Algorithmique de la v´erification des syst`emes `a compteurs – Approximation et acc´el´eration – Impl´ementation dans l’outil FAST,” Th`ese de doctorat, E´cole Normale Sup´erieure de Cachan (2003).
