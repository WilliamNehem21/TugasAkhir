

Electronic Notes in Theoretical Computer Science 267 (2010) 43–53
www.elsevier.com/locate/entcs

The Interval Analysis of Multilinear Expressions
Cosimo Laneve1 Tudor A. Lascu2
Dipartimento di Scienze dell’Informazione Universit`a di Bologna
Bologna, Italy
Vania Sordoni3
Dipartimento di Matematica Universit`a di Bologna Bologna, Italy

Abstract
Expressions are multilinear when variable occurrences are linear and products have factors using different variables. We demonstrate that multilinear expressions are either constant or have never a local minimum or a local maximum. Therefore the interval of multilinear expressions may be computed precisely studying their values at the bounds of the variables therein. We then propose a technique for the interval analysis of generic expressions that transforms them into multilinear ones and computes the interval of the latters.
Keywords: Interval analysis, multilinear expressions, gradient of functions.


Introduction
Interval analysis is a static analysis technique that abstractly computes programs using ranges of variables’ values rather than specific values. For example, if x ∈ [1, 2] and y ∈ [0, 4] and one performs the assignment z := x + y, then, in the final state, z ∈ [1, 6], which is the outcome of the interval addition [1, 2]+ [0, 4].
It is well-known that the loss of precision in interval computations is due to the evaluation of nonlinear expressions such as x ∗ (y − z)+ z. In this case, when x ∈ [0, 1], y ∈ [0, 10] and z ∈ [0, 10], the current interval techniques compute the
expression [0, 1] ∗ ([0, 10] − [0, 10]) +[0, 10] and yield the interval [−10, 20], which is a

1 Email: laneve@cs.unibo.it
2 Email: lascu@cs.unibo.it
3 Email: sordoni@dm.unibo.it

1571-0661 © 2010 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2010.09.017

strict over-approximation of the precise result [0, 10]. This loss of precision is caused by the double occurrence of the variable z that, in a precise evaluation, may reduce the range of the result (because every occurrence of a variable must be replaced by the same value). In an interval evaluation the two occurrences of z disappear because they are replaced by the corresponding interval. The same argument may be used for polynomials in several variables, which is a computational equivalent problem.
In fact, finding the (precise) range of an expression in several variables has been proved to be NP-hard by Gaganov [2] with respect to the number of variables and the degree of the expression. The problem seems practically unfeasible even if we constrain either the degree or the number of variables of the expression. In particular, the problem is NP-hard as long as the degree is greater than 1. If the number n of variables is fixed, Grigoriev and Vorobjov have designed an O(dk) algorithm, where d is the degree of the expression [3]. Unfortunately, the constant k is equal to n2, which makes the algorithm expensive even for small values of n. The survey [6] reports the main results about this problem.
Constraining either the degree or the number of variables are two somehow extreme restrictions. Other restrictions, retaining simple and even more performant
n2
algorithms than O(d  ), may be proposed. To this aim, we have parsed several
programs that have been developed for different purposes (several thousands lines) and we noticed that a large number of expressions were multilinear. An expression is multilinear when variable occurrences are linear – the exponent is 1 – and products have factors using different variables. For example x∗(y−z)+z and x∗(y∗z−u)+y∗u are multilinear (for simplicity we are omitting constant coefficients) and x ∗ (y + x) is not.
We demonstrate that multilinear expressions never manifest a local minimum or a local maximum. That is, if a multilinear expression E has variables x1, ·· ·, xn that range over [a1, b1], ·· ·, [an, bn], respectively, then the least and greatest values of E can be found at the vertices of the hypercube [a1, b1] ×· · · × [an, bn]. Therefore, the range of multilinear expressions may be computed in a precise way by collecting the values of E at the 2n vertices and taking the least and greatest ones. This simple algorithm has computational complexity O(n · 22n).
We then use this result to design a technique for evaluating generic expressions. The idea is to transform an expression into a multilinear one and then compute the range of the latter. The transformation amounts to replace nonlinear variables with fresh linear ones whose interval is defined by the corresponding exponential variable (directly, rather than as a sequence of products). In doing this replacement, we keep the dependencies between variable’s occurrences as much as possible. For example, the expression x3y + x2z + xyz, with x ∈ [−1, 1], is transformed into uxy + uz + xyz by letting u = x2 and u ∈ [0, 1]. The technique is sound, i.e. it introduces over- approximations as in the transformation of the expression x4y + x3z + xyz, with x ∈ [−2, 2]. In this case we obtain uxy + uz + xyz, by letting u = x3 and u ∈ [−8, 8], and we notice that the range of the subexpression ux is [−16, 16], whilst it is [0, 16] in the original expression.

We finally compare our technique with standard interval analysis and with a recent technique proposed by Min´e [5]. This comparison is rather preliminary: a thorough study is delayed to the next future.
Related work
Several proposals for reducing the loss of precision of interval arithmetics may be found in the literature. As usual, in every proposal there is a trade-off between computational cost and precision.
A recent proposal, which has been integrated in ASTREE´ [1], is due to Min´e [5].
In this technique an expression is transformed into an expression of degree 1, called affine. Intervals of affine expressions are then computed without loss of precision. The problem of this technique is that the affine transformation is not unique and may introduce over-approximations (Min´e’s technique, applied to x ∗ (y − z)+ z, when x ∈ [0, 1], y ∈ [0, 10] and z ∈ [0, 10], yields [0, 20], which is an interval (twice) longer than the precise result [0, 10]).
The solution in [4] requires advanced computational techniques such as the study of monotonicity and the analysis of sub-intervals.
Overview of the paper
We recall the mathematical background and define multilinear expressions and demonstrate our results in Section 2. The algorithm for the interval analysis of multilinear expressions and the study of its computational complexity are in Sec- tion 3. In Section 4 we study the extension of our technique to generic expression. Section 5 reports our conclusions.
Multilinear functions
A polynomial function is a function defined by a polynomial. For example, the function f from real numbers  to  , defined by f (x) = 5x3 + 2x + 7 is a polynomial function of one argument. Polynomial functions of multiple arguments can be defined, using polynomials in multiple variables, as f (x, y)= xy2+2xy+y+1.
The gradient of a (differentiable) function f :  n →  , noted ∇f , is the
n-uple (  ∂f , ··· ,  ∂f ).	For example, when g(x, y) = x2 + y2 − 2xy2 − y4,
∂x1	∂xn
∇g(x, y) = (2x − 2y2, 2y − 4xy − 4y3).  The gradient of a function is relavant
because a 0-gradient, i.e. (∇g)(a1, ··· , an) = (0, ··· , 0), is a necessary condition for (a1, ··· , an) being a local minimum or a local maximum. This condition is in general not sufficient: in the case of the above function g, (0, 0), ( 1 , 1 ) and ( 1 , − 1 )
4 2	4	2
are the zeros of the gradient, however only (0, 0) is a local minimum.
The standard technique for computing (local) lower and upper bounds consists of computing the solutions of ∇f (x1, ··· , xn) = 0 and then discarding the stationary points that are neither local minimum nor maximum. However ∇f (x1, ··· , xn)=0 is a system of nonlinear equations, which, in general, do not have explicit solutions

and the numerical methods used to find approximate solutions are expensive from the computational point of view. In this section we demonstrate that we can safely avoid solving ∇f (x1, ··· , xn) = 0 when functions are multilinear.

Definition 2.1 A polynomial function f :  n →  is called multilinear if

f (x1, ··· , xn)=	Σ
S⊆{1,2,···,n}
cS · Y xi
i∈S

where every cS is a constant in  .
The Taylor series of a multilinear function f : n →  in a neighborhood of a point (a1, ··· , an) is a polynomial of the form

f (a1, ··· , an)+ Σ
+ Σ
 ∂f (a1, ··· , an)(xi − ai)
1	∂f	 i1,i2∈{1,···,n},i1/=i2 2! ∂xi1 ∂xi2

1 − ai1 )(xi2

— ai2 )

+ ··· 
For example, the Taylor series of f (x, y) = 2xy + 7y + 12 in a neighborhood of a point (a, b) is
f (a, b)+ 2b(x − a)+ (2a + 7)(y − b)+ (x − a)(y − b) .
The Taylor series approximate the value of functions at given points. We will use them in the following theorem.
Theorem 2.2 Let f : n →  be a multilinear function. If f has a local minimum or a local maximum then f is constant.
Proof. Let f (x1, ··· , xn)=  S⊆{1,2,···,n} cS ·  i∈S xi be a multilinear function and let (a1, ··· , an) be such that ∇f (a1, ··· , an) = 0. Then there are constants dS, with S ⊆ {1, 2, ··· , n}, such that f may be rewritten as:

f (x1, ··· , xn)=	Σ
S⊆{1,2,···,n}
dS · Y(xi − ai) .
i∈S


where d∅ = f (a1, ··· , an) (c.f. the Taylor series in a neighborhood of (a1, ··· , an)). We have the following cases:
Let T = {i1, i2, ··· , il} be a minimal set with l > 0 such that dT /= 0. We demonstrate that (a1, ··· , an) cannot be a local minimum or a local maximum. We observe that T cannot be a singleton because ∇f (a1, ··· , an)= 0.
There are two subcases: l odd and l even:
– when l is odd, consider h(a ,···,a ) :  →  n defined as follows:

1	n


(h	(t))
= ,⎨ t + aj if j ∈ T

(a1,···,an)
, aj	otherwise

Then we have f (h(a ,···,a )(t)) = f (a)+ dS · tl and f (h(a ,···,a )(−t)) = f (a) −
1	n	1	n
dS · tl. Hence, for t > 0:
(f (h(a1,···,an)(t)) − f (a1, ··· , an))(f (h(a1,···,an)(−t)) − f (a1, ··· , an)) < 0 .
Since, for every ε > 0, h(a1,···,an)(] − ε, ε[) is contained in an hypercube H =

n i=1
]ai − ε, ai + ε[ of  n, then there are two points x˜, y˜ ∈ H such that

(f (x) − f (a1, ··· , an))(f (y) − f (a1, ··· , an)) < 0 and then one can conclude
that the point (a1, ··· , an) cannot be a local maximum or a local mimimum.

– when l is even, consider h−
1	n
:  →  n defined as follows
,⎪ aj − t if j = i1;


—
(a1,···,an)
(t))j = ⎪⎨ aj + t if j ∈ T \ {i1};
⎪⎪, aj	if j ∈/ T. 

Then we have f (h−
1	n
(t)) = f (a) − dS · tl. Hence, for t > 0:

(f (h(a ,···,a )(t)) − f (a))(f (h−
(t)) − f (a)) < 0

1	n	(a1,···,an)
and, as before, it is possible to conclude that (a1, ··· , an) cannot be a point of local maximum or local mimimum.
Sl = ∅ (that is l = 0) and dSÆ /= 0 and every other S is such that dS = 0. Then
f (x1, ··· , xn)= d∅, that is f is constant.
2
An immediate consequence of Theorem 2.2 is the following.
Corollary 2.3 Let f : n → be a multilinear function. The lower and upper bounds of f in the hypercube H = [a1, b1] × [a2, b2] × ··· × [an, bn] occur at the vertices of H.
Proof. By Theorem 2.2, the lower and upper bounds cannot be found inside
H. Therefore they are on the borders with respect to some variable. Let it be x1. This means that lower and upper bounds are either in f (a1, x2, ··· , xn) or in f (b1, x2, ··· , xn), which are multilinear functions from n−1 to . We reiterate the argument on these functions. The process terminates with constant functions.  2
Theorem 2.2 and Corollary 2.3 may be generalized as follows.


Let f :  n+m →  be almost-multilinear if
f (x1, ··· , xn, y1, ··· , ym)= c∅(y1, ··· , ym)+	Σ
S⊆{1,2,···,n}

cS(y1, ··· , ym) · Y xi
i∈S

and every cS :  m →  is a polynomial function.
Interestingly, the bounds of almost-multilinear functions may be found by study- ing the non-multilinear parts.
Proposition 2.4 Let f :  n+m →  be almost-multilinear with linear vari- ables x1, ·· ·, xn.	If f has a local minimum or a local maximum at a point

(c1, ··· , cn, cj , ··· , cj
) then c1, ··· , cn are bounds (either lower or upper) of x1, ·· ·,

1	m
xn.


Proof. Let (c1, ··· , cn, cj , ··· , cj ) be such that ∇f (c1, ··· , cn, cj , ··· , cj
) = 0.

1	m	1	m
Since the function f (x1, ··· , xn, cj , ··· , cj ) is multilinear then, by Corollary 2.3,
1	m
its lower and upper bounds may be found at the bounds of the linear variables, let
them be [a1, b1], ·· ·, [an, bn]. This means that, in order to compute the minimum and maximum values of f (x1, ··· , xn, y1, ··· , ym), it is possible to reduce the calculus to the minimum and maximum of the sets of functions {f (d1, ··· , dn, y1, ··· , ym) | di ∈
{ai, bi}, 1 ≤ i ≤ n}.	2

For example, let f (x, y) = 2y2 + xy2, with x, y ∈ [−1, 1]. Then ∇f (x, y) = (y2, 2y(x + 2)), which is 0 when y = 0 (and every x). By Proposition 2.4, in order to compute the lower and upper bound of f , we may reduce to computing the minimum and maximum of the functions f (−1, y)= y2 and f (1, y)= 3y2, that are 0 and 3, respectively (when y ∈ [−1, 1]).

3	Interval analysis for multilinear expressions
We apply the results of the previous section to design a new algorithm for the interval analysis of expressions. In this section we focus on multilinear expressions (see below).
We use an infinite set of identiﬁers, ranged over by x, y, z; constants in  are ranged over by c, d, ·· ·. Polynomial expressions E are defined by the following grammar:
E ::=	c	|	x	|	− E	|	E + E	|	E − E	|	E ∗ E
Let id(E ) be the set of identifiers in E. It is evident that an expression E represents a polynomial in id(E ) variables. Therefore it is a functions from n to , where n is the cardinality of id(E ). An expression is called multilinear if the corresponding polynomial is multilinear.
The algorithm multilinearExp range in Table 1 computes the bounds of mul- tilinear expressions by taking the minimum and maximum values of the expression when instantiated with the lower and upper bounds of variables. More precisely, the algorithm gets (the syntax tree of) an expression E, an array of intervals, i.e. pairs (a, b), and a natural number specifying the number of free variables of E. It is assumed that variables are totally ordered, i.e. x1, x2, x3, ·· ·, and E contains the first n variables. So, the interval of xi is defined in Bounds[i] and we get the lower-bound and the upper-bound by means of proj1 and proj2, respectively.
The computational complexity of multilinearExp range is determined as fol- lows:
statements at lines 2, 3 and 4 do not play any relevant role;
the for statement at line 5 has 2n iterations;

1: multilinearExp range(E,Bounds[],n)
2:	for (1<= i <= n) do ai := proj1(Bounds[i]);
3:	m := E{a1, ··· , an/x1, ··· , xn} ;
4:	M := m ;
5:	for y1 ∈{ proj1(Bounds[1], proj2(Bounds[2] }, ...,
yn ∈{ proj1(Bounds[n], proj2(Bounds[n] } do
6:	t := E{y1, ··· , yn/x1, ··· , xn} ;
7:	m := min(m, t) ;
8:	M := max(M, t) ;
9:	return([m,M])
Table 1
The algorithm multilinearExp range.

at every iteration, the cost of line 6 is computed as follows:
every monomial with k variables has k products (including the constant) and, in the worst case, there are (n) of such monomials;
the total number of operations is
n
n	n−1
k
k=1
Therefore line 6 costs O(n · 2n−1).
the overall complexity of multilinearExp range is O(2n · n · 2n−1)= O(n · 22n).
We observe that our algorithm has a better computational complexity than the
n2
one designed by Grigoriev and Vorobjov – that has a cost O(d  ). (Actually our
algorithm is better when d > 1. When d = 1 we use the standard interval analysis, which returns the precise range.) We also observe that, while an O(n·22n) algorithm is prohibitive, in general, it is more affordable in the case of expressions occurring in programs that very rarely retain more than 4 variables. Last, we remind that interval analysis of arithmetic expressions is computed statically for correctness purposes. In this context it is reasonable to pay more for an accurate analysis.
4	The general case
The technique of Section 3 may be extended to generic, polynomial expressions. Since Theorem 2.2 cannot be generalized to non-multilinear polynomials, and Proposition 2.4 does not help very much from the algorithmic point of view, we decided to define a “reduction” technique. That is, we reduce generic expressions to multilinear ones and compute the intervals of the latters. The ambition is to return more precise intervals than the standard interval arithmetics or other tech- niques.
As for multilinearExp range, we assume that variables are totally ordered and E contains the first n variables, called x1, x2, ·· ·, xn. We also assume the presence of the following identifiers and functions:
$ is a dummy identifier, different from any other occurring in expressions;

nonlinearvar(E) returns either a pair ($,-1), if the expression E is multilinear, or a pair (x,i), where x is the first nonlinear variable (in the total ordering) occurring in E and i is its ordinal;
getexponents(E,x) returns a pair (k,h) of naturals, with k > h, where k is the greatest exponent of x in E and h is the exponent of an occurrence of x that is immediately smaller than k. In case all the occurrences of x have exponent k then h = 0.
intv(x,r,(a,b)) returns the lower-bound and upper-bound of the expression
xr, when x ∈ [a, b].
replace(E,xh, z) replaces the occurrences of xh+h′	h′

1: Exp range(E,Bounds[],n)
2:	(x,i) := nonlinearvar(E) ;
3:	while (x /= $) do
4:	(k,h) := getexponents(E,x) ;
5:	if (h>1) then
6:	E := replace(E,xh, xn+1) ; r:= h
7:	else E := replace(E,xk, xn+1) ; r:= k;
8:	Bounds[n+1] := intv(x,r,Bounds[i]);
9:	n := n+1;
10:	(x,i) := nonlinearvar(E) ;
11:	return(multilinearExp range(E,Bounds[],n))
Table 2
The algorithm Exp range.

The algorithm Exp range is defined in Table 2. Exp range takes a nonlinear variable (line 2). In case no variable is found, then the bounds of the expressions are computed with multilinearExp range (line 11). Otherwise, let the variable be
x. The algorithm grabs the maximum exponent k of x and the exponent h, with k > h, such that the other occurrences of x have either exponent k or exponent lesser or equal to h (line 4). When h > 1, all the powers xk and xh in E are replaced by xn+1xk−h and xn+1, respectively, where xn+1 is the first fresh variable (line 6), and the interval of xn+1 is computed in a precise way (line 8). When h =1 or h =0 the replacement only concerns the terms xk. The iteration at line 3 terminates when the expression becomes multilinear. For example, let E = x5 − x3z + xy − xz + z, with x ∈ [−1, 2], y ∈ [1, 3], and z ∈ [2, 3]. Here, the unique nonlinear variable is x and the two values returned by getexponents are 5 and 3. Therefore, the expression E becomes vx2 − vz + xy − xz + z with v ∈ [−1, 8]. In turn, the evaluation of this expression reduces to computing multilinearExp range on vu − vz + xy − xz + z, with u ∈ [0, 4].
We notice that the replacement of line 6 keeps the dependencies between the occurrences of xh, but definitely breaks those between (i) xh and the exponent k − h and (ii) those exponents lower than h. Such a rupture causes an over-approximation in the interval computation. In the above expression E = x5 − x3z + xy − xz + z,

the dependency of x between the first and second monomial is retained in vx2 − vz + xy − xz + z by means of the variable v. (A greedy strategy replacing x5 with a variable would break this dependency.) This is a choice among several ones and it is not clear to us whether other choices may return better results. We leave this issue to future work.
Next, we analyze the computational complexity of Exp range. Let d be the greatest exponent in the input expression E and let n be the number of variables therein.
In order to turn E into an expression that is linear in x, we need, in the worst case, d/2 iteration of lines 4-10. These iterations introduce d/2 fresh variables. Similarly for every other nonlinear variable. In the worst case, the iterations are n(d/2).
At every iteration, the cost of getexponents(E,x), replace(E,xh,xn+1) and nonlinearvar(E) depend on the size of E, let it be |E|. In the worst case, this size grows linearly with respect to E (because of the products xn+1xk−h that are inserted). That is, the size |E| at the beginning, 2|E| at the second iteration, 3|E| at the third one, and so on.
Therefore, the cost of lines 4-10 is O(|E|· nd(nd + 2)).
Since the cost of invoking multilinearExp range at line 11 with an expression of n + n(d/2) variables is O(22n·(1+d/2)), we obtain a complexity O(|E|· nd(nd + 2) + 22n·(1+d/2)), which is equal to O(22n·(1+d/2)).
We conclude our analysis by comparing the outputs of Exp range with other techniques. We consider the standard interval analysis and Min´e’s symbolic tech- nique [5].
The expression we consider is x5 − x3 ∗ z + x ∗ y − x ∗ z + z with x ∈ [−1, 2], y ∈ [0, 2], and z ∈ [0, 2]. The precise interval of this expression is [−3, 36]. The following table sums up the results:

If the intervals of variables are x ∈ [0, 1], y ∈ [0, 2], and z ∈ [0, 3] then the precise

interval of the above expression is [−2, 3]. The following table sums up the results:

We notice that (in these cases) our techniques gives a better precision than the other ones. While this is reasonable because Exp range has a higher computational cost than interval analysis or Min`e’s technique, it is unclear, as we said, whether this is always the case or not.
5	Conclusions
A new algorithm for the interval analysis of polynomial expressions has been pro- posed and studied. The algorithm is precise when the expressions are multilinear. A preliminary assessment of the algorithm with respect to other techniques has begun and a thorough study is planned. An in-house tool meant to be effectively used and representing a proof of concept implementation of the algorithms presented in this paper is under development. Our algorithm has been already successfully used for the interval analysis of codes of control switchboards, where every expression turns out to be multilinear. In fact, non-multilinear expressions are quite infrequent in programs. That is, the message conveyed by this paper is that interval analy- sis of expressions may be carried out without loss of precision in almost all the cases.

Acknowledgement
Part of this work was carried out as a joint collaboration with the Methodologies & Tools team of Magneti Marelli Powertrain S.p.A.

References
P. Cousot, R. Cousot, J. Feret, L. Mauborgne, A. Min´e, D. Monniaux, and X. Rival. The astre´e analyzer. In S. Sagiv, editor, ESOP, volume 3444 of Lecture Notes in Computer Science, pages 21–30. Springer, 2005.
A. Gaganov. Computational complexity of the range of the polynomial in several variables. Cybernetics and Systems Analysis, 21(4):418–421, July 1985.
D. Grigoriev and N. Vorobjov. Solving systems of polynomial inequalities in subexponential time. J. Symb. Comput., 5(1/2):37–64, 1988.
E. Hansen. Generalized interval arithmetic. In Interval Mathematics, volume 29 of Lecture Notes in Computer Science, pages 7–18. Springer Berlin / Heidelberg, 1975.


A. Min´e. Symbolic methods to enhance the precision of numerical abstract domains. In Proc. of the 7th Int. Conf. on Verification, Model Checking, and Abstract Interpretation (VMCAI’06), volume 3855 of Lecture Notes in Computer Science, pages 348–363, Charleston, South Carolina, USA, January 2006. Springer.
A. L. V. Kreinovich and J. Rohn. Computational Complexity of Interval Algebraic Problems: Some Are Feasible and Some Are Computationally Intractable - A Survey, chapter in Scientific Computing and Validated Numerics, Editors G. Alefeld, A. Frommer and B. Lang, pages 293–306. Akademie Verlag, 1996.
