Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 298 (2013) 29–50
www.elsevier.com/locate/entcs
Layout Randomization and Nondeterminism
Mart´ın Abadi
Microsoft Research, Silicon Valley and UC Santa Cruz
J´er´emy Planul
Stanford University
Gordon Plotkin
LFCS, Informatics, University of Edinburgh and Microsoft Research, Silicon Valley

Abstract
In security, layout randomization is a popular, effective attack mitigation technique. Recent work has aimed to explain it rigorously, focusing on deterministic systems. In this paper, we study layout randomization in the presence of nondeterministic choice. We develop a semantic approach based on denotational models and simulation relations. This approach abstracts from language details, and helps manage the delicate interaction between probabilities and nondeterminism.
Keywords: security, semantics, probabilities, nondeterminism, full abstraction.

Introduction
Randomization has important applications in security, ranging from probabilistic cryptographic schemes [10] to the introduction of artificial diversity in low-level software protection [8]. Developing rigorous models and analyses of the systems that employ randomization can be challenging, not only because of the intrinsic difficulty of reasoning about probabilities but also because these systems typically exhibit many other interesting features. Some of these features, such as assumed bounds on the capabilities and the computational complexity of attackers, stem directly from security considerations. Others, such as nondeterminism, need not be specifically related to security, but arise because of the generality of the ambient computational models, which may for example include nondeterministic scheduling for concurrent programs and for network protocols.

1571-0661 © 2013 Elsevier B.V. Open access under CC BY-NC-ND license.
http://dx.doi.org/10.1016/j.entcs.2013.09.006

The form of randomization that we explore in this paper is layout randomization in software systems (e.g., [6,18,7]). Layout randomization refers to a body of widely used techniques that place data and code randomly in memory. In practice, these techniques effectively thwart many attacks that assume knowledge of the location of data and code. Recent research by the authors and others aims to develop rigorous models and proofs for layout randomization [19,3,13,2]. The research to date has focused on deterministic, sequential programs. Here, we consider layout randomization for programs that may make nondeterministic choices.
We phrase our study in terms of a high-level language in which variables are abstract (symbolic) locations, and a low-level language in which they are mapped to random natural-number addresses in memory. Both languages include a standard construct for nondeterministic choice. We give models for the languages. For each language, we also define a contextual implementation relation. Intuitively, a context may represent an attacker, so contextual implementation relations may serve, in particular, for expressing standard security properties. We characterize contextual implementation relations in terms of semantic simulation relations (so-called logical relations). Throughout, the low-level relations are probabilistic. Via the simulation relations, we obtain a semantic correspondence between the high-level and low-level worlds. Basically, simulation relations in one world induce simulation relations in the other, and therefore contextual implementation in one world implies contextual implementation in the other.
Thus, our approach emphasizes semantic constructions. In comparison with prior syntactic work, arguments via models arguably lead to more satisfying secu- rity arguments, independent of superficial details of particular languages (as layout randomization is largely language-agnostic in practice). They also help reconcile probabilities and nondeterminism, which have a rich but thorny interaction.
Some of the difficulties of this interaction have been noticed in the past. For in- stance, in their development of a framework for the analysis of security protocols [15, Section 2.7], Lincoln et al. observed:
our intention is to design a language of communicating processes so that an ad- versary expressed by a set of processes is restricted to probabilistic polynomial time. However, if we interpret parallel composition in the standard nondetermin- istic fashion, then a pair of processes may nondeterministically “guess” any secret information.
They concluded:
Therefore, although nondeterminism is a useful modeling assumption in study- ing correctness of concurrent programs, it does not seem helpful for analyzing cryptographic protocols.
Thus, they adopted a form of probabilistic scheduling, and excluded nondetermin- ism. In further work, Mitchell et al. [17] refined the framework, in particular defin- ing protocol executions by reference to any polynomial-time probabilistic scheduler that operates uniformly over certain kinds of choices. The uniformity prevents col- lusion between the scheduler and an attacker. Similarly, Canetti et al. [4] resolved

nondeterminism by task schedulers, which do not depend on dynamic information generated during probabilistic executions; they thus generated sets of trace distri- butions, one for each task schedule.
From a semantic perspective, a nondeterministic program denotes a function that produces a set of possible outcomes; equally, a probabilistic program repre- sents a function that produces a distribution over outcomes. Rigorous versions of these statements can be cast in terms of powerdomains and probabilistic powerdo- mains [9]. In principle, a nondeterministic and probabilistic program may represent either a function producing a set of distributions over outcomes or else one produc- ing a distribution over sets of outcomes. However it seems that only the former option, where nondeterministic choice is resolved before probabilistic choice, leads to a satisfactory theory if, for example, one wishes to retain all the usual laws for both forms of nondeterminism [16,21,11].
To illustrate these options, imagine a two-player game in which Player I chooses a bit bI at random, Player II chooses a bit bII nondeterministically, and Player I wins if and only if bI = bII. The system composed of the two players may be seen as producing a set of distributions or a distribution on sets of outcomes.
With the former view, we can say that, in each possible distribution, Player I wins with probability 1/2.
On the other hand, with the latter view, we can say only that, with probability 1, Player I may win and may lose.
The former view is preferable in a variety of security applications, in which we may wish to say that no matter what an attacker does, or how nondeterministic choices are resolved, some expected property holds with high probability.
However, in our work, it does not suffice to resolve nondeterministic choice before probabilistic choice, as we explain in detail below, fundamentally because the probabilistic choices that we treat need not be independent. Instead, we construct a more sophisticated model that employs random variables, here maps from memory layouts to outcomes. The memory layouts form the sample space of the random variables, and, as usual, one works relative to a given distribution over the sample space.
Beyond the study of layout randomization, it seems plausible that an approach analogous to ours could be helpful elsewhere in security analysis. Our models may also be of interest on general grounds, as a contribution to a long line of research on programming-language semantics for languages with nondeterministic and proba- bilistic choice. Specifically, the models support a treatment of dependent probabilis- tic choice combined with nondeterminism, which as far as we know has not been addressed in the literature. Finally, the treatment of contextual implementation relations and simulation relations belongs in a long line of research on refinement.
Contents
In Section 2 we review some preliminary material on cpos.
In Section 3, we consider a high-level language, with abstract locations, stan-

dard imperative constructs, and nondeterminism, and describe its denotational and operational semantics. We define a contextual implementation relation with respect to contexts that represent attackers, which we call public contexts; for this purpose, we distinguish public locations, which attackers can access directly, from private locations. We also define a simulation relation, and prove that it coincides with the contextual implementation relation. The main appeal of the simulation relation, as usual, is that it does not require reasoning about all possible contexts.
In Section 4, we similarly develop a lower-level language in which programs may use natural-number memory addresses (rather than abstract locations). Again, we define a denotational semantics, an operational semantics, a contextual implemen- tation relation, and a simulation relation. These definitions are considerably more delicate than those of the high-level language, in particular because they refer to layouts, which map abstract locations to concrete natural-number addresses, and which may be chosen randomly (so we often make probabilistic statements).
In Section 5, we relate the high-level and the low-level languages. We define a simple compilation function that maps from the former to the latter. We then establish that if two high-level commands are in the contextual implementation re- lation, then their low-level counterparts are also in the contextual implementation relation. The proof leverages simulation relations. In semantics parlance, this result is a full-abstraction theorem; the use of public contexts that represent attackers, however, is motivated by security considerations, and enable us to interpret this the- orem as providing a formal security guarantee for the compilation function, modulo a suitable random choice of memory layouts.
Finally, in Section 6 we conclude by discussing some related and further work.

Preliminaries on cpos
We take a cpo to be a partial order P closed under increasing ω-sups, and consider sets to be cpos with the discrete ordering. We write P⊥ for the lift of P , viz. P extended by the addition of a least element, ⊥. Products P ×Q and function spaces P → Q (which we may also write as QP ) are defined as usual, with the function space consisting of all continuous functions (those monotonic functions preserving the ω-lubs).
We use the lower, or Hoare, powerdomain H(P ) of the nonempty, downwards, and ω-sup-closed subsets of P , ordered by inclusion. The lower powerdomain is the simplest of the three powerdomains, and models “may” or “angelic” nondetermin- ism; the others (upper and convex) may also be worth investigating.
For any nonempty subset X of P , we write X ↓ for the downwards closure
{y | ∃x ∈ X. y ≤ x} of X. We also write X∗ for the downwards and ω-sup closure of X (which is typically the same as X ↓ in the instances that arise below).
Both H(−) and H(−⊥) are monads (those for lower nondeterminism, and lower nondeterminism and nontermination, respectively). The unit of the former is x '→
{x}↓ and any continuous map f : P → H(Q) has an extension f† : H(P ) → H(Q)

given by:
f†(X)=( [ f (x))∗
x∈X

For the latter the unit is x '→ {x}↓ and the extension f† : H(P⊥) → H(Q⊥) of a continuous map f : P → H(Q⊥) is given by:

f†(X)= {⊥} ∪ (	[
x∈X\{⊥}

f (x))∗

The high-level language
In this section, we define our high-level language. In this language, locations are symbolic names, and we use an abstract store to link those locations to their con- tents, which are natural numbers.
For simplicity, the language lacks data structures and higher-order features. Therefore, locations cannot contain arrays or functions (cf. [2]), except perhaps through encodings. So the language does not provide a direct model of overflows and code-injection attacks, for instance.
There are many other respects in which our languages and their semantics are not maximally expressive, realistic, and complex. They are however convenient for our study of nondeterminism and of the semantic approach to layout randomization.

Syntax and informal semantics
The syntax of the high-level language includes categories for natural-number ex- pressions, boolean expressions, and commands:

e ::= k |!lloc | e + e | e ∗ e
b ::= e ≤ e | ¬b | tt | ff | b ∨ b | b ∧ b
c ::= lloc := e | if b then c else c | skip | c; c | c + c | while b do c

where k ranges over numerals, and l over a given finite set of store locations Loc. Natural-number expressions are numerals, dereferencing of memory locations, sums, or products. Boolean expressions are inequalities on natural-number expressions, negations, booleans, disjunctions, or conjunctions. Commands are assignments at a location, conditionals, skip, sequences, nondeterministic choices, or loops. Com- mand contexts C[ ] are commands with holes; we write C[c] for the command obtained by filling all the holes in C[] with c. We further use trivial extensions of this language, in particular with additional boolean and arithmetic expressions.
We assume that the set of store locations Loc is the union of two disjoint sets of locations PubLoc (public locations) and PriLoc (private locations). Let c be a command or a command context. We say that c is public if it does not contain any occurrence of lloc := v or !lloc for l ∈ PriLoc. As in previous work [3], we model


[[lloc := e]](s)	= η(s[l '→ [[e]](s)])	[skip]](s)	= η(s)

[[if b then c else cj]](s) = ⎧⎨[[c]](s) [b]](s)= tt
⎩[[cj]](s) [[b]](s)= ff
[[c; cj]](s)	= [cj]]†([[c]](s))
[[c + cj]](s) = [[c]](s) ∪ [[cj]](s)


[[while b do c]]	= μθ : S → H(S⊥
). λs : S. ⎧⎨η(s)	( [b]](s)= ff)
⎩θ†([[c]](s)) ([[b]](s)= tt)


Fig. 1. High-level denotational semantics

attackers by such public commands and command contexts; thus, attackers have direct access to public locations but not, by default, to private locations.
The distinction between public and private locations is directly analogous to that between external and internal state components in automata and other spec- ification formalisms (e.g., [1]). It also resembles distinctions in information-flow systems, which often categorize variables into levels (e.g., [20]), and typically aim to prevent flows of information from “high” to “low” levels. We do not impose any such information-flow constraint: we permit arbitrary patterns of use of public and private locations. Nevertheless, we sometimes use h for a private location and l for a public location, and also associate the symbols H and L with private and public locations, respectively.

Denotational semantics
A store s is a function from a finite set Loc of store locations to natural numbers. When Loc consists of h and l, for example, we write (h '→ m, l '→ n) for the store that maps h to m and l to n. A public (private) store is a function from PubLoc (PriLoc) to natural numbers. We write S for the set of stores, SL for the set of public stores, and SH for the set of private stores. Note the natural functions:
SL →−L− S −−H→ SH

We write sL for L(s) and s =L sj when sL = sj , and similarly for H.
The denotational semantics
[[e]]: Store →	[[b]]: Store → 

of expressions are defined as usual with, in particular, [[!lloc]](s)= s(l). The deno- tational semantics
[[c]] : S → H(S⊥)
of commands is given in Figure 1, where the semantics of the while loop is the standard least-fixed point one.



⟨lloc := e, s⟩→ s[l '→ [[e]]s]

[[b]]s = ff
[[b]]s = tt


⟨if b then c else cj, s⟩→ ⟨c, s⟩

⟨c, s⟩→ ⟨cj, sj⟩

⟨if b then c else cj, s⟩→ ⟨cj, s⟩	⟨skip, s⟩→ s


⟨c; cjj, s⟩→ ⟨cj; cjj, sj⟩



⟨c, s⟩→ sj


⟨c; cjj, s⟩→ ⟨cjj, sj⟩
⟨c + cj, s⟩→ ⟨c, s⟩	⟨c + cj, s⟩→ ⟨cj, s⟩



[[b]]s = ff


⟨while b do c, s⟩→ s
[[b]]s = tt


⟨while b do c, s⟩→ ⟨c; while b do c, s⟩


Fig. 2. High-level operational semantics
Example 3.1 Consider the two commands:
c0 = (h := tt; l := ¬!l)+ (h := ff)	c1 = (h := tt; l := tt) + (h := ff; l := ff) According to the semantics, [c0 ] maps any store mapping l to t to the set {(h '→
tt,l '→ ff), (h '→ ff,l '→ tt)} ↓, and any store where l is ff to the set {(h '→ tt,l '→
tt), (h '→ ff,l '→ ff)} ↓, while [c1 ] maps any store to the set {(h '→ tt,l '→ tt), (h '→
ff,l '→ ff)} ↓. In sum, we may write:

[[c0]](h '→ ,l '→ tt) = {(h '→ tt,l '→ ff), (h '→ ff,l '→ tt)}↓ 
[[c0]](h '→ ,l '→ ff) = {(h '→ tt,l '→ tt), (h '→ ff,l '→ ff)}↓ 
[[c1]](h '→ ,l '→ ) = {(h '→ tt,l '→ tt), (h '→ ff,l '→ ff)}↓ 
Note that the semantics of the two commands are different. Nevertheless, below we show that these two commands are in a sense equivalent (with respect to public contexts).	2
Operational semantics
The high-level language has a straightforward small-step operational semantics. In this semantics, a high-level state is a pair ⟨c, s⟩ of a command and a store or, in case of termination, just a store s. The transition relation → is a binary relation on such states. Figure 2 gives the rules for →.
Proposition 3.2 (Operational/denotational consistency) Let c be a com- mand and s be a store. We have
[[c]](s)= {sj|⟨c, s⟩ →∗ sj}∪⊥ 

Implementation relations and equivalences
Contextual pre-order
We introduce a contextual pre-order ±L on commands. Intuitively, c ±L cj may be interpreted as saying that c “refines” (or “implements”) cj, in the sense that the publicly observable outcomes that c can produce are a subset of those that cj permits, in every public context and from every initial store. Thus, let f = [[C[c]]] and fj = [[C[cj]]] for an arbitrary public context C, and let s0 be a store; then for every store s in f (s0) there is a store sj in fj(s0) that coincides with s on public locations. Note that we both restrict attention to public contexts and compare s and sj only on public locations.
We define ±L and some auxiliary relations as follows:
For X ∈ H(S⊥), we set:
XL = {sL | s ∈ X\ ⊥} ∪ {⊥}
For f, fj : S → H(S⊥), we write that f ≤L fj when, for every store s0, we have
f (s0)L ≤ fj(s0)L.
Let c and cj be two commands. We write that c ±L cj when, for every public command context C, we have [[C[c]]] ≤L [[C[cj]]].
Straightforwardly, this contextual pre-order relation yields a notion of contextual equivalence with respect to public contexts.
Simulation
In addition to a contextual pre-order, we introduce a simulation relation ≤ whose main advantage, as usual, is that it does not require reasoning about contexts.
As in much previous work, one might expect a simulation relation between two commands c and cj to be a relation on stores that respects the observable parts of these stores, and such that if s0 is related to s1 and c can go from s0 to sj

then there exists sj
such that sj
is related to sj
and cj can go from s1 to sj .

In our setting, respecting the observable parts of stores means that related stores give the same values to public locations (much like refinement mappings preserve externally visible state components [1], and low-bisimulations require equivalence on low-security variables [20]).
Although this idea could lead to a sound proof technique for the contextual pre-order, it does not suffice for completeness. Indeed, forward simulations, of the kind just described, are typically incomplete on their own for nondeterministic systems. They can be complemented with techniques such as backward simulation, or generalized (e.g., [1,14,5]).
Here we develop one such generalization. Specifically, we use relations on sets of stores. We build them from relations over H(SH⊥) as a way of ensuring the condition that public locations have the same values, mentioned above. We also require other standard closure conditions. Our relations are similar to the ND measures of Klarlund and Schneider [14]. Their work takes place in an automata-

theoretic setting; automata consist of states (which, intuitively, are private) and of transitions between those states, labeled by events (which, intuitively, are public). ND measures are mappings from states to sets of finite sets of states, so can be seen as relations between states and finite sets of states. The finiteness requirement, which we do not need, allows a fine-grained treatment of infinite execution paths via K¨onig’s Lemma.
First, we extend relations R over H(SH⊥) to relations R+ over H(S⊥), as follows.
For any X ∈ H(S⊥) and s ∈ SL, we define Xs ∈ H(SH⊥) by:


Xs = {sj
| sj ∈ X, sj
= s} ∪ {⊥}

and then we define R+ by:
XR+Y ≡def ∀s ∈ SL. (Xs ≤= {⊥} ⇒ Ys ≤= {⊥}) ∧ XsRYs
If R is reflexive (respectively, is closed under increasing ω-sups; is right-closed under
≤; is closed under binary unions) the same holds for R+.  Also, if XR+Y  then
XL ≤ YL.
For any f, fj : S⊥ → H(S⊥) and relation R over H(SH⊥) we write that f ≤R fj
when:
∀X, Y ∈ H(S⊥).XR+Y ⇒ f†(X)R+fj†(Y )
Finally, we write that f ≤ fj if f ≤R fj for some reflexive R closed under increasing
ω-sups, right-closed under ≤, and closed under binary unions.
Contextual pre-order vs. simulation
The contextual pre-order coincides with the simulation relation:
Theorem 3.3 Let c and cj be two commands of the high-level language. Then
c ±L cj holds if and only if [[c]] ≤ [[cj]] does.
Example 3.4 We can verify that c0 and c1, introduced in Example 3.1, are equiv- alent (with R the full relation). For instance, let S0 = {(h '→ ff,l '→ tt)}↓ and S1 = {(h '→ tt,l '→ tt)} ↓. We have S0R+S1, and:
[[c0]]†(S0) = {(h '→ tt,l '→ ff), (h '→ ff,l '→ tt)}↓ 
[[c1]]†(S1) = {(h '→ tt,l '→ tt), (h '→ ff,l '→ ff)}↓ 


We can then check that:
[[c0]]†(S0)R+[[c1]]†(S1)
2

Example 3.5 In this example, we study the two commands
c2 = if h = 0 then l := 1 else (h := 0) + (h :=!h − 1)
c3 = if h = 0 then l := 1 else (h := 0) + skip

which seem to share the same behavior on public variables, but that are inherently different because of their behavior on private variables. According to the semantics, we have:
[[c2]](h '→ 0,l '→ )	= {(h '→ 0,l '→ 1)}↓ 
[[c2]](h '→ j + 1,l '→ k) = {(h '→ j, l '→ k), (h '→ 0,l '→ k)}↓ 
[[c3]](h '→ 0,l '→ )	= {(h '→ 0,l '→ 1)}↓ 
[[c3]](h '→ j + 1,l '→ k) = {(h '→ j + 1,l '→ k), (h '→ 0,l '→ k)}↓ 

We can verify that c2 ≤R c3, with R defined as the smallest relation that satisfies our conditions (reflexivity, etc.) and such that
{(h '→ k)}R{(h '→ kj)}	for all k ≤ kj
For instance, suppose S0 = {(h '→ 5,l '→ 0)}↓ and S1 = {(h '→ 7,l '→ 0)} ↓. We have S0R+S1, and:
[[c2]]†(S0) = {(h '→ 4,l '→ 0), (h '→ 0,l '→ 0)}↓ 
[[c3]]†(S1) = {(h '→ 7,l '→ 0), (h '→ 0,l '→ 0)}↓ 


We can then check that:

[[c2]]†(S0)R+[[c3]]†(S1)

On the other hand, there is no suitable relation R such that c3 ≤R c2. If there were such a relation R, it would be reflexive, so {(h '→ 1)} R {(h '→ 1)}. Suppose that S0 = {(h '→ 1,l '→ 0)}↓ and that S1 = {(h '→ 1,l '→ 0)} ↓. We have S0R+S1, and:



We need
[[c3]]†(S0) = {(h '→ 1,l '→ 0), (h '→ 0,l '→ 0)}↓ [[c2]]†(S1) = {(h '→ 0,l '→ 0)}↓ 

{(h '→ 1,l '→ 0), (h '→ 0,l '→ 0)}↓ R+{(h '→ 0,l '→ 0)}↓ 

hence {(h '→ 1)}R{(h '→ 0)}. Now take S2 = {(h '→ 1,l '→ 0)}↓ and S3 = {(h '→
0,l '→ 0)} ↓. We have S2R+S3, and:

[[c3]]†(S2) = {(h '→ 1,l '→ 0), (h '→ 0,l '→ 0)}↓ [[c2]]†(S3) = {(h '→ 0,l '→ 1)}↓ 
Since the values of l do not match, we cannot have [c3]]†(S2)R+[[c2]]†(S3), hence
c3 ≤≤R c2.
As predicted by Theorem 3.3, we also have c3 ≤±L c2. Indeed, for C =	;  and
s0 = (h '→ 1,l '→ 0), we have [C[c3]]](s0) ≤≤L [[C[c2]]](s0).	2

The low-level language
In this section, we define our low-level language. In this language, we use concrete natural-number addresses for memory. We still use abstract location names, but those are interpreted as natural numbers (according to a memory layout), and can appear in arithmetic expressions.

Syntax and informal semantics
The syntax of the low-level language includes categories for natural-number expres- sions, boolean expressions, and commands:

e ::= k | lnat |!e | e + e | e ∗ e
b ::= e ≤ e | ¬b | tt | ff | b ∨ b | b ∧ b
c ::= e := e | if b then c else c | skip | c; c | c + c | while b do c

where k ranges over numerals, and l over the finite set of store locations. Boolean expressions are as in the high-level language. Natural-number expressions and com- mands are also as in the high-level language, except for the inclusion of memory locations among the natural-number expressions, and for the dereferencing con- struct !e and assignment construct e := ej where e is an arbitrary natural-number expression (not necessarily a location).
Importantly, memory addresses are natural numbers, and a memory is a partial function from those addresses to contents. We assume that accessing an address at which the memory is undefined constitutes an error that stops execution imme- diately. In this respect, our language relies on the “fatal-error model” of Abadi and Plotkin [3]. With more work, it may be viable to treat also the alternative “recoverable-error model”, which permits attacks to continue after such accesses, and therefore requires a bound on the number of such accesses.

Denotational semantics
Low-level memories, layouts, and errors
We assume given a natural number r > |Loc| that specifies the size of the memory. A memory m is a partial function from {1,..., r} to natural numbers; we write Mem for the set of memories. A memory layout w is an injection from Loc to {1,..., r}. We consider only memory layouts that extend a given public memory layout wp (an injection from PubLoc to {1,..., r}), fixed in the remaining of the paper. We let W be the set of those layouts.
The security of layout randomization depends on the randomization itself. We let d be a probability distribution on memory layouts (that extend wp). When ϕ is a predicate on memory layouts, we write Pd(ϕ(w)) for the probability that ϕ(w) holds with w sampled according to d.
Given a distribution d on layouts, we write δd for the minimum probability for

a memory address to have no antecedent location (much as in [3]):


δd =	min
i∈{1,...,r}\ran(wp)
Pd(i ≤∈ ran(w))

We assume that δd > 0. This probability bounds 1 minus the maximum probability for an adversary to guess a location. For common distributions (e.g., the uniform distribution), δd approaches 1 as r grows, indicating that adversaries fail most of the time. We assume d fixed below, and may omit it, writing δ for δd.
The denotational semantics of the low-level language uses the “error + nonter- mination” monad Pξ⊥ =def (P + {ξ})⊥, which first adds an “error” element ξ to P and then a least element. As the monad is strong, functions f : P1 ×... ×Pn → Qξ⊥ extend to functions f on (P1)ξ⊥ ×... × (Pn)ξ⊥, where f (x1,..., xn) is ξ or ⊥ if some xj, but no previous xi, is; we write f for f .
For any memory layout w and store s, we let w· s be the memory defined on ran(w) by:
w·s(i)= s(l) for w(l)= i
The notation w · s extends to s ∈ Sξ⊥, as above, so that w · ξ = ξ and w· ⊥=⊥. A 
store projection is a function ζ : MemW of the form w '→ w · s, for some s ∈ Sξ⊥.
What should the denotational semantics be?
We discuss a simple example in order to explain our choice of type of the low-level denotational semantics. A straightforward semantics might have the type:
W × Mem → H(Memξ⊥)
so that the meaning of a command would be a function from layouts and memories to sets of memories (modulo the use of the “error + nontermination” monad). Using our example we argue that this is unsatisfactory, and arrive at a more satisfactory alternative.
Suppose that there is a unique private location l, and that memory has four addresses, {1, 2, 3, 4}. We write si for the store (l '→ i). The 4 possible layouts are wi = (l '→ i), for i = 1,..., 4. Assume that d is uniform. Consider the following command:
c4 = (1 := 1) + (2 := 1) + (3 := 1) + (4 := 1)
which nondeterministically guesses an address and attempts to write 1 into it. In- tuitively, this command should fail to overwrite l most of the time. However, in a straightforward semantics of the above type we would have:
[[c4]](wj, wj ·s0)= {ξ, wj ·s1}↓ 
and we cannot state any quantitative property of the command, only that it some- times fails and that it sometimes terminates.
One can rewrite the type of this semantics as:
Mem → H(Memξ⊥)W

and view that as a type of functions that yield an H(Memξ⊥)-valued random variable with sample space W (the set of memory layouts) and distribution d. Thus, in this semantics, the nondeterministic choice is made after the probabilistic one —the wrong way around, as indicated in the Introduction.
It is therefore natural to reverse matters and look for a semantics of type: Mem → H(MemW )
now yielding a set of Memξ⊥-valued random variables—so, making the nondeter- ministic choice first. Desirable as this may be, there seems to be no good notion of composition of such functions.
Fortunately, this last problem can be overcome by changing the argument type to also be that of Memξ⊥-valued random variables:
MemW → H(MemW )
It turns out that with this semantics we have:
[[c4]](ζi)= {ζ1,ζ2,ζ3,ζ4}↓ 
ξ	ξ	ξ	ξ
where ζi(w) = w · si and ζi(w) = wi · s1 if w = wi and = ξ otherwise. We can then say that, for every nondeterministic choice, the probability of an error (or nontermination, as we are using the lower powerdomain) is 0.75.
In a further variant in the definition of the semantics, one might replace Memξ⊥- valued random variables by the corresponding probability distributions on Memξ⊥,

via the natural map Indd : MemW
−→ V(Memξ⊥) induced by the distribution d on

W. Such a semantics could have the form:
Mem → HV (Memξ⊥)
mapping memories to probability distributions on memories, where HV is a pow- erdomain for mixed nondeterministic and probabilistic choice as discussed above. However, such an approach would imply (incorrectly) that a new layout is chosen independently for each memory operation, rather than once and for all. In our small example with the single private location l and four addresses, it would not capture that (1 := 1); (2 := 1) will always fail. It would treat the two assignments in (1 := 1); (2 := 1) as two separate guesses that may both succeed. Similarly, it would treat the two assignments in (1 := 1); (1 := 2) as two separate guesses where the second guess may fail to overwrite l even if the first one succeeds. With a layout chosen once and for all, on the other hand, the behavior of the second assignment is completely determined after the first assignment.
Denotational semantics
The denotational semantics
[[e]]: Mem × W →  ξ⊥	[[b]]: Mem × W →  ξ⊥

[[c + cj]](ζ)= [[c]](ζ) ∪ [[cj]](ζ)	[c; cj]]= [[cj]]† ◦[[c]]	[[skip]] = η
[[e := ej]](ζ)	= η(λw : W. Ass(ζ(w), [[e]]w	, [[ej]]w	))
[[if b then c else cj]] = Cond([[b]], [[c]], [[cj]])
[[while b do c]]	= μθ : MemW → H(MemW ).Cond([[b]], θ† ◦[[c]], η)


Fig. 3. Low-level denotational semantics
of expressions are defined in a standard way, with, in particular, [lnat]]w

= w(l),

and also [[!e]]w = m([[e]]w ), if [e]]w ∈ dom(m), and = ξ, otherwise, using an obvious
m	m	m
notation for functional application. Note that these semantics never have value ⊥.
As discussed above, the denotational semantics of commands has type:
[[c]] : MemW → H(MemW )
The definition is given in Figure 3; it makes use of two auxiliary definitions. We first define:
Ass: Memξ⊥ ×  ξ⊥ ×  ξ⊥ →  ξ⊥
by setting Ass(m, x, y) = m[x '→ y] if x ∈ dom(m) and = ξ, otherwise, for m ∈ Mem, x, y ∈ , and then using the function extension associated to the “error + nontermination” monad. Second, we define
Cond(p, θ, θj): MemW  → H(MemW )
for any p : Mem × W →  ξ⊥ and θ, θj : MemW → H(MemW ), by:
ξ⊥	ξ⊥

Cond(p, θ, θj)(ζ) = {ζj | ζj|W	∈ θ(ζ)|W	,ζj|W	∈ θj(ζ)|W	,
ζj(Wζ,ξ) ⊆ {ξ}, and ζj(Wζ,⊥) ⊆ {⊥}}

where Wζ,t =def {w | p(ζ(w), w) = t}, for t ∈  ξ⊥, and we apply restriction elementwise to sets of functions.
Example 4.1 In this example, we demonstrate our low-level denotational seman- tics. Consider the command:


c5 = lj
:= lnat; (!lj
) := 1; lj
:= 0

This command stores the address of location l at location lj, then reads the contents of location lj (the address of l) and writes 1 at this address, and finally resets the memory at location lj to 0. Because of this manipulation of memory locations, this command is not the direct translation of a high-level command.
Letting:
si,j = (l '→ i, lj '→ j)	ζi,j = w '→ w·si,j	ζj = w '→ w·(l '→ i, lj '→ w(l))

we have:

j
nat

:= lnat]](ζi,j)= {ζj}↓ 

Note that ζi,j is a store projection, but ζj is not. We also have:
[[(!lj	) := 1 ](ζj)= {ζj }↓	[[lj	:= 0]](ζj )= {ζ1,0}↓ 
nat	i	1	nat	1

In sum, we have:
[[c5]](ζi,j)= {ζ1,0}↓ 
2

Looking at the type of the semantics
[[c]] : MemW
→ H(MemW )

one may be concerned that there is no apparent relation between the layouts used in the input to [c ] and those in its output. However, we note that the semantics could be made parametric. For every Wj ⊆ W , replace W by Wj in the definition of [c ] to obtain:
W ′	W ′
[[c]]W ′ : Memξ⊥ → H(Memξ⊥ )
There is then a naturality property, that the following diagram commutes for all Wjj ⊆ Wj ⊆ W :

MemW ′
[[c]]W)′
H(MemW ′ )

Memι
v
H(Memι )
v

MemW ′′ 	) H(MemW ′′ )
ξ⊥ [[c]]W ′′	ξ⊥
where ι : Wjj ⊆ Wj is the inclusion map. Taking Wj = W and Wjj a singleton yields the expected relation between input and output: the value of a random variable in the output at a layout depends only on the value of the input random variable at that layout. The naturality property suggests re-working the low level denotational semantics in the category of presheaves over sets of layouts, and this may prove illuminating (see [12] for relevant background).
Operational semantics
As a counterpart to the denotational semantics, we give a deterministic operational semantics using oracles to make choices. The oracles are elements of the set Ω of infinite lists of tokens L (for “left”) and R (for “right”). A low-level state σ is:
a triple ⟨c, m, π⟩ of a command c, a memory m, and an oracle π; or
a pair ⟨m, π⟩ of a memory m and an oracle π; or
the error element ξ.


[[e]]w ∈ dom(m) and [ej]]w ≤= ξ	[[e]]w ≤∈ dom(m) or [[ej]]w = ξ
m	m	m	m
w |= ⟨e := ej, m, π⟩→ ⟨m[[[e]]w '→ [[ej]]w ], π⟩	w |= ⟨e := ej, m, π⟩→ ξ
m	m

[[b]]w = tt
w |= ⟨if b then c else cj, m, π⟩→ ⟨c, m, π⟩


[[b]]w = ff


w |= ⟨if b then c else cj, m, π⟩→ ⟨cj, m, π⟩
[[b]]w = ξ


w |= ⟨if b then c else cj, m, π⟩→ ξ



w |= ⟨skip, m, π⟩→ ⟨m, π⟩
w |= ⟨c, m, π⟩→ ⟨cj, mj, πj⟩


w |= ⟨c; cjj, m, π⟩→ ⟨cj; cjj, mj, πj⟩



w |= ⟨c, m, π⟩→ ⟨mj, πj⟩


w |= ⟨c; cjj, m, π⟩→ ⟨cjj, mj, πj⟩
w |= ⟨c, m, π⟩→ ξ w |= ⟨c; cjjm, π⟩→ ξ

w |= ⟨c + cj, m, Lπ⟩→ ⟨c, m, π⟩	w |= ⟨c + cj, m, Rπ⟩→ ⟨cj, m, π⟩
[[b]]w = ff
w |= ⟨while b do c, m, π⟩→ ⟨m, π⟩


[[b]]w = tt


w |= ⟨while b do c, m, π⟩→ ⟨c; while b do c, m, π⟩
[[b]]w = ξ


w |= ⟨while b do c, m, π⟩→ ξ


Fig. 4. Low-level operational semantics



Transitions are given relative to a layout, so we write:

w |= σ → σj


The rules are given in Figure 4. This semantics is deterministic for each choice of layout. We write w |= σ ⇒ σj for the transitive closure of the transition relation (for a given layout).

Example 4.2 Consider the command c4 introduced in Section 4.2.2, with added parentheses for disambiguation:

c4 = (1 := 1) + ((2 := 1) + ((3 := 1) + ((4 := 1))))


w4 |= ⟨c4, w4·sk, RRRπ⟩ ⇒ ⟨w4·s1, π⟩	wj |= ⟨c4, wj ·sk, RRRπ⟩ ⇒ ξ (j ≤= 4)
2
Using the operational semantics, we can define an evaluation function: Eval: Com × W × Mem × Ω → Memξ⊥

by:




We then define
⎧ mj (w |= ⟨c, m, π⟩⇒ ⟨mj, πj⟩) Eval(c, w, m, π)= ⎨ ξ	(w |= ⟨c, m, π⟩⇒ ξ)
⎪⎪⎩ ⊥ (otherwise)


by:
Evalran : Com × MemW → Ω → MemW


Eval


ran
(c, ζ)(π)(w)= ⎧⎨ Eval(w, c, ζ(w), π) (ζ(w) ∈ Mem)
⎩ ζ(w)	(otherwise)

Making use of the image functional ImX : XΩ → P(X), where ImX (f )= f (Ω), we can state the consistency of the operational and denotational semantics:
Proposition 4.3 (Operational/denotational consistency) For c a command and ζ a function in MemW , we have:
[[c]](ζ)= ImMemW (Evalran(c, ζ)) ↓

The evaluation function yields operational correlates of the other possible de- notational semantics discussed in Section 4.2.2, similarly, using image or induced distribution functionals. For example, for the first of those semantics, by currying Eval and composing, one obtains:


curry(Eval)
Ω	ImMemξ⊥

Com × W × Mem −−−−−−−→ Memξ⊥ −−−−−−→ P(Memξ⊥)
Using such operational correlates, one can verify operational versions of the asser- tions made in Section 4.2.2 about the inadequacies of those semantics.

Implementation relations and equivalences
Much as in the high-level language, we define a contextual implementation relation and a simulation relation for the low-level language. The low-level definitions refer to layouts, and in some cases include conditions on induced probabilities.

Contextual pre-order
Again, the contextual pre-order c ±L cj may be interpreted as saying that c “refines” (or “implements”) cj, in the sense that the publicly observable outcomes that c can produce are a subset of those that cj permits, in every public context. In comparison with definition for the high-level language, however, c and cj are not applied to an arbitrary initial store but rather to a function from layouts to memories (extended with “error + nontermination”), and they produce sets of such functions. We restrict attention to argument functions induced by stores, in the sense that they are store projections of the form w '→ w·s. Thus, let f = [[C[c]]] and fj = [[C[cj]]] for an arbitrary public context C, and let s be a store; then (roughly) for every ζ in f (w '→ w·s) there exists ζj in fj(w '→ w·s) such that, for any w, ζ(w) and ζj(w) coincide on public locations.
The treatment of error and nontermination introduces a further complication. Specifically, we allow that ζ produces an error or diverges with sufficient probabil- ity (≥ δ), and that ζj produces an error with sufficient probability (≥ δ), as an alternative to coinciding on public locations.
Therefore, we define ±L and some auxiliary notation and relations:
Set PubMem =def Nran(wp). Then, for any memory m, let mL ∈ PubMem be the restriction of m to ran(wp), extending the notation to Memξ⊥ as usual.

For any ζ ∈ MemW , we define ζL ∈ PubMemW
by setting ζL(w)= ζ(w)L.

ξ⊥	ξ⊥
For X, Y ∈ H(MemW ), we write that X ≤L Y when, for every ζ ∈ X, there exists ζj ∈ Y such that:
ζL ≤ ζj , or
P (ζ(w) ∈ {ξ, ⊥}) ≥ δ and P (ζj(w)= ξ) ≥ δ.

For f, fj ∈ MemW
→ H(MemW ), we write f ≤L fj when, for all s ∈ S, we have:

f (w '→ w·s) ≤L fj(w '→ w·s)


Finally, we write c ±L cj when, for every public command context C, [[C[c]]] ≤L
[[C[cj]]].

Simulation
As in the high-level language, we introduce a simulation relation ≤. This rela- tion works only on commands whose outcomes on inputs that are store projections are themselves store projections; nevertheless, simulation remains a useful tool for proofs.

We define a : Sξ⊥ → H(MemW ) by:

a(⊥) = {w '→⊥} ↓
a(s) = {w '→ w·s}↓ 
a(ξ) = {ζ|P (ζ(w)= ξ) ≥ δ}↓ 

For every X ∈ H(MemW ), we say that X is a store projection set when there exists
Y ∈ H(Sξ⊥) such that



and
a(Y \ {ξ}) ↓⊆ X ⊆ a(Y ) ↓


ξ ∈ Y ⇒ ∃ζ ∈ X. P (ζ(w)= ξ) ≥ δ


In that case, we write χ(X) = Y for the unique such Y ; we have s ∈ Y if, and only if, w '→ w · s ∈ X and ξ ∈ Y if, and only if, ∃ζ ∈ X, P (ζ(w) = ξ) ≥ δ. (The uniqueness of Y depends on the assumption that δ > 0.)
The ≤L relation restricted to store projection sets has a pleasant characteriza- tion. The notation −L extends from S to Sξ⊥, so that ⊥L=⊥ and ξL = ξ; with that, for any X in H(Sξ⊥), define XL in H(SLξ⊥) to be {sL | s ∈ X}.
Fact 4.4 Let X and Y be store projection sets. Then:
X ≤L Y	≡  χ(X)L ≤ χ(Y )L
Much as in the high-level language, we extend relations R over H(SHξ⊥) to relations R× over H(MemW ). First we extend −s to H(Sξ⊥) as follows: for X ∈ H(Sξ⊥) and s ∈ SL, we let Xs ∈ H(SHξ⊥) be (X \ {ξ})s ∪ {ξ | ξ ∈ X}. Then, given a relation R over H(SHξ⊥), we first extend it to a relation R+ over H(Sξ⊥) by setting
XR+Y ≡def (ξ ∈ X ⇒ ξ ∈ Y ) ∧
∀s ∈ SL. ((Xs \ ξ) ≤= {⊥} ⇒ (Ys \ ξ) ≤= {⊥}) ∧ XsRYs
for X, Y ∈ H(Sξ⊥) and then define R× by setting:
XR×Y ≡def X and Y are store projection sets ∧ χ(X)R+χ(Y )
for X, Y ∈ H(MemW ). (Note that if R ⊆ H(SH⊥), then the high- and low-level definitions of R+ coincide.)
If R is closed under increasing ω-sups (respectively, is right-closed under ≤, is closed under binary unions) the same holds for R+, and then for R× (with ≤ restricted to store projection sets). If R is reflexive, then R+ is and R× is reflexive on store projection sets. We also have, much as before, that, for X, Y ∈ H(Sξ⊥), if

XR+Y then XL ≤ YL. It then follows from Fact 4.4 that, for X, Y ∈ H(MemW ),

if XR×Y then X ≤L Y .
For any f, fj : MemW

→ H(MemW ) and relation R over H(SH⊥) we write that

f ≤R fj when:
∀X, Y ∈ H(MemW ).XR×Y ⇒ f†(X)R×fj†(Y )
Finally, we write that f ≤ fj if f ≤R fj for some reflexive R closed under increasing
ω-sups, right-closed under ≤, and closed under binary unions.
Contextual pre-order vs. simulation
The contextual pre-order coincides with the simulation relation, but only for com- mands whose semantics sends store projections to store projection sets. Formally,
we say that a given function f : MemW  → H(MemW ) preserves store projections
if, for every s ∈ S, f (w '→ w·s) is a store projection set. The coincidence remains quite useful despite this restriction, which in particular is not an impediment to our overall goal of relating the low-level language to the high-level language.
Theorem 4.5 Let c and cj be two commands of the low-level language such that [[c]] and [[cj]] preserve store projections. Then c ±L cj holds if and only if [[c]] ≤ [[cj]] does.
Example 4.6 Suppose that there is only one private location, and consider the two commands:
c4 = (1 := 1) + (2 := 1) + (3 := 1) + (4 := 1)	c6 = (1 := 1); (2 := 1)
As seen above, we have that [c4]](ζi)= {ζ1,ζ2,ζ3,ζ4} ↓. We also have that [[c6]](ζi)= 
ξ	ξ	ξ	ξ
{w '→ ξ} ↓. Since P (ζi(w) = ξ) ≥ δ, we can verify that c4 and c6 are equivalent.
(Thus, a nondeterministic guess is no better than failure.)	2

High and low
In this section we investigate the relation between the high-level language and the low-level language. Specifically, we define a simple translation from the high-level language to the low-level language, then we study its properties.
We define the compilation of high-level commands c (expressions e, boolean ex- pressions b) to low-level commands c↓ (expressions e↓ and boolean expressions b↓) by setting: (!lloc)↓ =!lnat, (lloc := e)↓ = lnat := e↓, and proceeding homomorphically in all other cases (e.g., (e + ej)↓ = e↓ + ej↓). Crucially, this compilation function, which is otherwise trivial, transforms high-level memory access to low-level memory access.
Lemma 5.1 Let c be a high-level command. Then [[c↓]] preserves store projections.
Theorem 5.2 relates the simulation relations of the two languages. It states that a high-level command c simulates another high-level command c, with respect to

all public contexts of the high-level language, if and only if the compilation of c simulates the compilation of cj, with respect to all public contexts of the low-level language.
Theorem 5.2 Let c and cj be two high-level commands. Then [[c]] ≤ [[cj]] holds if and only if [[c↓]] ≤ [[cj↓]] does.
Our main theorem, Theorem 5.3, follows from Theorem 5.2, the two previous theorems, and the lemma. Theorem 5.3 is analogous to Theorem 5.2, but refers to the contextual pre-orders: a high-level command c implements another high-level command cj, with respect to all public contexts of the high-level language, if and only if the compilation of c implements the compilation of cj, with respect to all public contexts of the low-level language.
Theorem 5.3 (Main theorem) Let c and cj be two high-level commands. Then
c ±L cj holds if and only if c↓ ±L cj↓ does.
Theorem 5.3 follows from Theorem 5.2, the two previous theorems, and the lemma. The low-level statement is defined in terms of the probability δ that de- pends on the distribution on memory layouts. When δ is close to 1, the statement indicates that, from the point of view of a public context (that is, an attacker), the compilation of c behaves like an implementation of the compilation of cj. This implementation relation holds despite the fact that the public context may access memory via natural-number addresses, and thereby (with some probability) read or write private data of the commands. The public context may behave adaptively, with memory access patterns chosen dynamically, for instance attempting to ex- ploit correlations in the distribution of memory layouts. The public context may also give “unexpected” values to memory addresses, as in practical attacks; the theorem implies that such behavior is no worse at the low level than at the high level.
For example, for the commands c0 and c1 of Example 3.1, the theorem enables us to compare how their respective compilations behave, in an arbitrary public low- level context. Assuming that δ is close to 1, the theorem basically implies that a low-level attacker that may access memory via natural-number addresses cannot distinguish those compilations. Fundamentally, this property holds simply because the attacker can read or write the location h only with low probability.
Conclusion
A few recent papers investigate the formal properties of layout randomization, like ours [19,3,13,2]. They do not consider nondeterministic choice, and tend to reason operationally. However, the work of Jagadeesan et al. includes some semantic el- ements that partly encouraged our research; specifically, that work employs trace equivalence as a proof technique for contextual equivalence.
In this paper we develop a semantic approach to the study of layout random- ization. Our work concerns nondeterministic languages, for which this approach

has proved valuable in reconciling probabilistic choice with nondeterministic choice. However, the approach is potentially more general. In particular, the study of con- currency with nondeterministic scheduling would be an attractive next step. Also, extending our work to higher-order computation presents an interesting challenge.

References
M. Abadi and L. Lamport. The existence of refinement mappings. TCS, 82(2):253–284, 1991.
M. Abadi and J. Planul. On layout randomization for arrays and functions. In POST, volume 7796 of
LNCS, pages 167–185. Springer, 2013.
M. Abadi and G. D. Plotkin. On protection by layout randomization. ACM Transactions on Information and System Security, 15(2):8:1–8:29, 2012.
R. Canetti et al. Analyzing security protocols using time-bounded task-pioas. Discrete Event Dynamic Systems, 18(1):111–159, 2008.
W. P. de Roever and K. Engelhardt. Data Refinement: Model-oriented Proof Theories and their Comparison, volume 46 of Cambridge Tracts in Theo. Comp. Sci. CUP, 1998.
P. Druschel and L. L. Peterson. High-performance cross-domain data transfer. Technical Report TR 92-11, Department of Computer Science, The University of Arizona, 1992.
U´. Erlingsson. Low-level software security: Attacks and defenses. In FOSAD IV Tutorial Lectures, volume 4677 of LNCS, pages 92–134. Springer, 2007.
S. Forrest et al. Building diverse computer systems. In 6th Workshop on Hot Topics in Operating Systems, pages 67–72, 1997.
G. Gierz et al. Continuous lattices and domains, volume 93 of Encyclopaedia of mathematics and its applications. CUP, 2003.
S. Goldwasser and S. Micali. Probabilistic encryption. JCSS, 28:270–299, 1984.
J. Goubault-Larrecq. Prevision domains and convex powercones. In FoSSaCS, volume 4962 of LNCS, pages 318–333. Springer, 2008.
M. Jackson. A sheaf theoretic approach to measure theory. PhD thesis, U. Pitt., 2006.
R. Jagadeesan et al. Local memory via layout randomization. In Proc. of the 24th CSFS, pages 161–174, 2011.
N. Klarlund and F. B. Schneider. Proving nondeterministically specified safety properties using progress measures. Information and Computation, 107(1):151–170, 1993.
P. Lincoln et al. A probabilistic poly-time framework for protocol analysis. In Proceedings of the Fifth ACM Conference on Computer and Communications Security, pages 112–121, 1998.
M. W. Mislove. On combining probability and nondeterminism. ENTCS, 162:261–265, 2006.
J. C. Mitchell et al. A probabilistic polynomial-time process calculus for the analysis of cryptographic protocols. TCS, 353(1-3):118–164, 2006.
PaX Project. The PaX project, 2004. http://pax.grsecurity.net/.
R. Pucella and F. B. Schneider. Independence from obfuscation: A semantic framework for diversity.
Journal of Computer Security, 18(5):701–749, 2010.
A. Sabelfeld and D. Sands. Probabilistic noninterference for multi-threaded programs. In CSFW, pages 200–214, 2000.
R. Tix et al. Semantic domains for combining probability and non-determinism. ENTCS, 222:3–99, 2009.
