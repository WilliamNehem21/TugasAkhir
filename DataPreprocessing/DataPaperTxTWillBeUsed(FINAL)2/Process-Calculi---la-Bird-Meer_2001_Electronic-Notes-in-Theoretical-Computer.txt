Electronic Notes in Theoretical Computer Science 44 No. 1 (2001)
URL: http://www.elsevier.nl/locate/entcs/volume44.html 20 pages


Process Calculi `a la Bird-Meertens

Lu´ıs S. Barbosa 1
Departamento de Inform´atica Universidade do Minho Braga, Portugal


Abstract
This paper is an attempt to apply the reasoning principles and calculational style underlying the so-called Bird-Meertens formalism to the design of process calculi, parametrized by a behaviour model. In particular, basically equational and point- free proofs of process properties are given, relying on the universal characterisation of anamorphisms and therefore avoiding the explicit construction of bisimulations. The developed calculi can be directly implemented on a functional language sup- porting coinductive types, which provides a convenient way to prototype processes and assess alternative design decisions.


Introduction
It is well known that initial algebras and final coalgebras provide abstract descriptions of a variety of phenomena in programming, in particular of data and behavioural structures, respectively. Both initiality and finality, as uni- versal properties, entail definitional and proof principles, i.e., a basis for the development of program calculi directly based on (actually driven by) type specifications. Moreover, such properties can be turned into programming combinators and used, not only to calculate programs, but also to program with. In functional programming the role of such universals — combined with the ‘calculational’ style entailed by category theory — has been fundamental to a whole discipline of algorithm derivation and transformation. This can be traced back to the so-called Bird-Meertens formalism [5,6] and the foun- dational work of T. Hagino [8]. Since then, the area has known a remarkable progress, as witnessed by the vast bibliography published both on theory and applications — see [12,13,4], among many others references.
This paper reports on an attempt to apply the same reasoning principles and calculational style to the design of process calculi, relying on the represen- tation of processes as inhabitants of coinductive types, i.e., final coalgebras for

1 Email: lsb@di.uminho.pt
◯c 2001 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


suitable Set endofunctors. Final semantics for processes is an active research area, namely after Aczel’s landmark paper [1]. Our emphasis is, however, actually placed on the design side: we intend to show how process calculi can be developed and their laws proved along the lines one gets used to in (data-oriented) program calculi. Although only the ‘fine grain’ observational equivalence entailed by (strict) bisimulation is considered in the sequel, we believe that the proposed approach has a number of advantages:
First of all it provides a uniform treatment of processes and other com- putational structures, e.g., data structures, both represented as categorical types for functors capturing signatures of, respectively, observers and con- structors. Placing data and behaviour at a similar level conveys the idea that process models can be chosen and specified according to a given ap- plication area, in the same way that a suitable data structure is defined to meet a particular engineering problem. Moreover, processes and data be- come expressible in programming languages supporting categorical types, such as Charity [7], providing a convenient way to prototype processes and compare alternative design decisions. This builds on the author previous work on component algebras [3].
Proofs are carried out in a purely calculational (basically equational and pointfree) style, therefore circumventing the explicit construction of bisim- ulations used in most of the literature on process calculi. In particular, a ‘conditional fusion’ result is proved to handle conditional laws.
Finally the approach is independent of any particular process calculus and makes explicit the different ingredients present in the design of any such calculi. In particular structural aspects of the underlying behaviour model (e.g., the dichotomies such as active vs reactive, deterministic vs non de- terministic) become clearly separated from the interaction structure which defines the synchronisation discipline.


Preliminaries
Anamorphisms.
Technically, the approach sketched here amounts to the systematic use of the universal property of anamorphisms. Recall that, for a functor T, a T- anamorphism is the unique T-comorphism to the final coalgebra ωT : νT −→ T νT from any other coalgebra ⟨U, p⟩. Also called the coinductive extension of p [17], it is written, in the tradition of [13], as [(p)]T or, simply, [(p)], and satisfies the following universal property:

k = [(p)]T	⇔  ωT · k = T k · p	(1)

from which other laws are easily derived, e.g.:
ωT · [(p)] = T [(p)] · p	(2)
[(ωT)] = idνT	(3)
[(p)] · h = [(q)] if p · h = T h · q	(4)
In the context of the Bird-Meertens formalism equations (2) to (4) are seen as instances of a cancellation, reflection and fusion result, respectively.

Invariants.
In order to derive conditional laws (section 4) we shall resort to the notion of a p-invariant, i.e., a predicate φ over the carrier of a T-coalgebra p closed under the p dynamics. Following [11], φ is an invariant if, as a set, it satisfies φ ⊆ ❡p φ, where ❡p φ denotes the set of all states whose immediate successors, under p, if any, satisfy φ. ❡p is, in fact, a modal combinator which corresponds to the familiar (weak) next operator in modal logics 2 . [11] introduces a definition of ❡p in terms of a lifting operation ( )T : PX −→ PT X defined inductively on the structure of (extended polynomial) functors (see [9] for the complete picture). Formally, ❡p φ = {u ∈ U| pu ∈ (φ)T}. The infinite extension of ❡p characterise the (future) ‘box’ operator relative to a coalgebra
p. This is denoted in [11] by  p, where  p is defined as the greatest fix point of
λx . φ ∩ ❡p x. Informally,  p φ reads ‘φ holds now and in all successor states’.

Process Structure and Combinators.
Processes.
In designing a process calculus, its operational semantics is usually given in terms of a transition relation −a→ over processes, indexed by a set Act of ac- tions 3 , witnessing the collection of actions in which a process gets committed and the resulting ‘continuations’, i.e., the behaviours subsequently exhibited. A first basic design decision concerns the definition of what should be under- stood by such a collection. As a rule it is defined as a set, in order to express non determinism. Other, more restrictive, possibilities consider a sequence or even just a single continuation, modelling, respectively, ‘ordered’ non deter- minism or determinism. In general, this underlying behaviour model can be represented by a functor B .

2 The transition system defined by p is the structure upon which the operator is interpreted. In fact, it has been recently recognised by a number of authors (notably in [15] and [11]) that a modal language associated to a T-coalgebra is determined by its shape, as recorded
in T.
3  This set will later be equipped with further structure to support particular interaction
disciplines. For the moment just assume that actions are generated from a set L of labels, i.e., a set of formal names. The embedding L ‹→ Act will usually be left implicit.


An orthogonal decision concerns the intended interpretation of the transi- tion relation, which is usually left implicit or underspecified in process calculi. We may, however, distinguish between

An ‘active’ interpretation, in which a transition p
−a→	q is informally

characterised as ‘p evolves to q by performing an action a’, both q and a
being solely determined by p.
A ‘reactive’ interpretation, informally reading ‘p reacts to an external stim- ulus a by evolving to q’.
Processes will then be taken as inhabitants of the carrier of the final coalgebra ω : ν −→ T ν, with T defined as B (Act × Id), in the first case, and (B Id)Act, in the second. To illustrate the proposed approach to the development of process calculi, we shall focus on a particular case where B is the finite powerset functor and the ‘active’ interpretation is adopted. The transition relation, for
this case, is given by p −a→ q	iff	⟨a, q⟩ ∈ ω p. Although this corresponds
to the main trend in the literature, some alternatives will be considered in
section 5.
The restriction to the finite powerset avoids cardinality problems and as- sures the existence of a final coalgebra for T. This means, of course, we shall deal only with image-finite processes, a not too severe restriction in practice which may be partially circumvented by a suitable definition of the structure of Act 4 .

Dynamic Combinators.
The cornerstone in the design of a process calculi is the judicious selection of a (hopefully small) set of process combinators. In [14], R. Milner classifies them into two distinct groups. The first group consists of all combinators which persist through action, i.e., which are present before and after a transi- tion occurs. They are called static and used to set up process’ architectures, specifying how their components are linked and which parts of their interface are public or private. Dynamic combinators, on the other hand, are ‘con- sumed’ on action occurrence, disappearing from the expression representing the process continuation. In this paragraph the usual Ccs dynamic combina- tors — i.e., inaction, prefix and non-deterministic choice — are defined as operators on the final universe of processes considered above. Notice that, being non recursive, they have a direct (coinductive) definition which depends solely on the chosen process structure. Therefore, the inactive process is rep- resented as a constant nil : 1 −→ ν upon which no relevant observation can be made. Prefix gives rise to an Act-indexed family of operators a. : ν −→ ν, with a ∈ Act. Finally, the possible actions of the non deterministic choice of two processes p and q corresponds to the collection of all actions allowed for

4 For instance, by taking Act as channel names through which data flows, which corre- sponds closely to ‘Ccs with value passing’ [14]. Therefore, only the set of channels, and not the messages (seen as pairs channel/data), must remain finite.


p and q. Therefore, the operator + : ν × ν −→ ν can only be defined over a process structure in which observations form a collection. Formally,
inaction	ω · nil = ∅
prefix	ω · a. = sing · labela
choice	ω · + = ∪ · (ω × ω)

where sing = λx . {x} and labela = λx . ⟨a, x⟩.
Clearly, structure ⟨ν; +, nil⟩ forms an Abelian idempotent monoid, a fact that can be proved by simple equational reasoning, resorting to the corre- sponding properties of set union. Moreover, finality turns ω into an isomor- phism and therefore, to prove e = e' it is enough to show that ω · e = ω · e'. To illustrate the proposed proof style, consider the proof of a particularly simple result: + associativity, i.e., + · (+ × id)=+ · (id × +) · a 5 .
Proof.
ω · + · (+ × id) = ∪ · (ω × ω) · (+ × id)	{ definition }
= ∪ · (ω · + × ω)	{ functoriality }
= ∪ · ((∪ · (ω × ω)) × ω	{ definition }
= ∪ · (∪× id) · ((ω × ω) · ω)	{ functoriality }
= ∪ · (∪× id) · ((ω × ω) · ω) · a◦ · a	{ a is isomorphism }
= ∪ · (∪× id) · a◦ · (ω × (ω × ω)) · a	{ a naturality }
= ∪ · (id × ∪) · (ω × (ω × ω)) · a	{ ∪ associativity }
= ∪ · (ω × (∪ · (ω × ω)) · a	{ functoriality }
= ∪ · (ω × ω · +) · a	{ definition }
= ∪ · (ω × ω) · (id × +) · a	{ functoriality }
= ω · + · (id × +) · a	{ definition }

✷

Interleaving and Restriction.
Persistence through action occurrence justifies the recursive definition of static combinators. This means that they arise as anamorphisms generated by suitable ‘gene’ coalgebras. Both interleaving and restriction are examples of static combinators, which, moreover, depend only on the process structure. We shall consider them in first place.

5 In the sequel, process properties are stated pointfree, for which we shall resort to standard natural isomorphisms in Set. In particular, associativity, commutativity and product left and right units, will be denoted by a : (A × B) × C −→ A × (B × C), s : A × B −→ B × A, r : 1 × A −→ A and l : A × 1 −→ A, respectively. The converse of an isomorphism i is written as i◦.


Although interleaving, a binary operator  : ν ×ν −→ ν, is not considered as a combinator in most process calculi, it represents the simplest form of ‘parallel’ aggregation in the sense that it is independent of any particular interaction discipline. The following definition captures the intuition that the observations over the interleaving of two processes correspond to all possible interleavings of the observations of its arguments. Thus,  = [(α )], where 6

α	= ν × ν  Δ  (ν × ν) × (ν × ν)( ω×id)×(id×ω) (P (Act × ν) × ν) × (ν × P(Act × ν))
 τr×τl  P (Act × (ν × ν)) × P(Act × (ν × ν))   ∪  P (Act × (ν × ν))
The restriction combinator \K, for each subset K ⊆ L, forbids the occurrence of actions in K. Formally, \K = [(α\K )] where
α	= ν  ω  P (Act × ν) filterK P (Act × ν) where filterK = λs . {t ∈ s| π1 t ∈/ K}.
The interleaving combinator also forms (with nil), an Abelian monoid. Re- striction, on the other hand, is idempotent and commutes with both choice and interleaving. As one could expect, the cornerstone in the proofs of equa- tions involving static combinators, is the application of the fusion law (4). This is illustrated below in the proof of  commutativity.
Proof. By definition  · s =  is equivalent to [(α )] · s = [(α )], which, by fusion, is implied by α · s = P(id × s) · α . Then,
α  · s
= ∪ ·(τr × τl) · ((ω × id) × (id × ω)) · Δ · s	{ definition }
= ∪ ·(τr × τl) · ((ω × id) × (id × ω)) · (s × s) · Δ	{ Δ nat }
= ∪ ·(τr × τl) · (s × s) · ((id × ω) × (ω × id)) · Δ	{ s × s nat }
= ∪ ·(τr · s × τl · s) · ((id × ω) × (ω × id)) · Δ	{ functor }
= ∪ ·(P(id × s) · τl × P(id × s) · τr) · ((id × ω) × (ω × id)) · Δ	{ τr vs τl }
= ∪ ·(P(id × s) × P(id × s)) · (τl × τr) · ((id × ω) × (ω × id)) · Δ	{ functor }
= P(id × s) · ∪ · (τl × τr) · ((id × ω) × (ω × id)) · Δ	{ ∪ nat }
= P(id × s) · ∪ · s · (τl × τr) · ((id × ω) × (ω × id)) · Δ	{ ∪ comm }
= P(id × s) · ∪ · (τr × τl) · ((ω × id) × (id × ω)) · s · Δ	{ s nat }
= P(id × s) · ∪ · (τr × τl) · ((ω × id) × (id × ω)) · Δ	{ s · Δ = Δ }
= P(id × s) · α	{ definition }


✷

6  Morphisms τr : P(Act × X) × C −→ P(Act × (X × C)) and τl : C × P(Act × X) −→ P(Act × (C × X)) stand for, respectively, the right and left strength associated to functor P(Act × Id).

Interaction and Parallel Composition
Interaction Structures.
Process combinators introduced so far depend solely on the process struc- ture, as recorded in the shape of the functor. To specify interaction, however, there is a need to introduce some structure in the set Act of actions. There- fore, we define the interaction structure underlying a process calculus as an Abelian positive monoid ⟨Act; θ, 1⟩ with a zero element 0. It is assumed that neither 0 nor 1 belong to the set L of labels. The intuition is that θ determines the interaction discipline whereas 0 represents the absence of interaction: for all a ∈ Act, aθ0 = 0. On the other hand, a positive monoid entails aθa' =1 iff a = a' = 1. Notice that the role of both 0 and 1 is essentially technical in the description of the interaction discipline. In some situations 1 may be seen as an idle action, but its role, in the general case, is to equip the behaviour functor with a monadic structure, which would not be the case if Act were defined simply as an Abelian semigroup 7 .
A basic example of an interaction structure captures action co-occurrence. Therefore, θ is defined as aθb = ⟨a, b⟩, for all a, b ∈ Act different from 0 and
1. Ccs [14] synchronisation discipline provides another example. In this case
the set L of labels carries an involutive operation represented by an horizontal bar as in a, for a ∈ L. Any two actions a and a are called complementary. A special action τ ∈/ L is introduced to represent the result of a synchronisation between a pair of complementary actions. Therefore, the result of θ is τ whenever applied to a pair of complementary actions and 0 in all other cases, except, obviously, if one of the arguments is 1 8 .
Once an interaction structure is fixed, any homomorphism f : Act −→ Act lifts to a renaming combinator [f ] between processes defined as [f ] = [(α[f])], where


α[f]
= ν   ω  P (Act × ν P(f ×id )P (Act × ν)


Conditional Laws.
The basic properties of renaming, namely that it preserves identity and composition of homomorphisms, extends along prefix and commutes with

7 The structure is similar to what is called a synchronisation algebra in [18] apart from some minor details. In particular, Winskel synchronisation algebras carry a specific constant
 to denote asynchronous occurrence and θ does not necessarily possess a unit. The monoid structure, however, allows for a more uniform characterisation of behaviour models. On the other hand, the definition of parallel composition below, in terms of synchronous product and interleaving, avoids the need for introducing .
8  For the Ccs case we follow the standard notational convention under which complements
are considered implicitly. In particular, a restriction combinator \K, for K ⊆ L is inter- preted as \K∪K . Similarly, the parameter f of a renaming (see below), specifies only the ‘action’ part although it also implies that if f a = b then f a = b. Also, as τ is introduced as a constant in Act, f being a homomorphism forces f τ = τ .


both choice and interleaving, are proved in the style illustrated above, always avoiding the explicit construction of bisimulations. Often, however, process equalities hold just if some ‘side conditions’ are fulfilled. Let us study how such laws are derived in our framework starting with a very simple example. Let f = {b/a} be substitution of a by b, i.e., a homomorphism over Act which is the identity in all actions but a. In several cases, but not in all, we may conclude that renaming with f has no effect. Can this be expressed on a general law? A simple calculation yields
[f ] = id
≡	{ definition }
[(α[f])] = [(ω)]
⇐	{ fusion }
α[f] · id = P(id × id) · ω
≡	{ identity }
α[f] = ω

Clearly, the last equality holds only if a does not show up as an action in the immediate continuations of the process being renamed. This condition is formally expressed by the following predicate:

φ	= =∅ · ∩ ·(Pπ1 · ω × sing · a) · l◦	(5)

Note, however, that φ is stated as a local condition on the immediate con- tinuations of any process candidate to satisfy the given equality. Therefore, it cannot be directly taken as a sufficient condition for [f ] = id. In fact, to proceed, predicate φ has to be made into an invariant in the sense of [11]. This is justified by the following result.

Theorem 4.1 Let α and β be T-coalgebras and φ a predicate on the carrier of β. Then the following ‘conditional’ fusion law holds

(φ ⇒ (α · h = T h · β)) ⇒ ( β φ ⇒ ([(α)]T · h = [(β)]T))

Proof. Let X be the carrier of β and iφ the embedding of the subset of X classified by φ, i.e., φ · iφ = true·!. Recall also that any β-invariant φ induces a subcoalgebra β'. Consequently, iφ becomes a comorphism from β' to β. Then

φ ⇒ (α · h = T h · β)
≡	{ iφ definition }
α · h · iφ = T h · β · iφ
⇒	{  β φ ⊆ φ }
α · h · i β φ = T h · β · i β φ
≡	{ i  φ is a comorphism from β′ to β}

α · h · i β
φ = T h · T i β
φ · β'

≡	{ functoriality}

α · h · i β
φ = T (h · i β
φ) · β'

≡	{ fusion law (4)}

[(α)]T
· h · i β
φ = [(β')]

≡	{ i  φ being a comorphism implies [(β′)] = [(β)] · i  φ}
[(α)]T · h · i β φ = [(β)]T · i β φ
≡	{ iφ definition }
 β φ ⇒ ([(α)]T · h = [(β)]T)
Notice the proof would work if β φ is replaced by any other β-invariant contained in φ. As β φ is the greatest such invariant, it provides the most ‘generous’ condition.	✷





Deriving the Condition.
Applying the previous theorem to the case under consideration, leads to

[{b/a}] = id ⇐  ω φ	(6)

with φ given by (5). Now recall that  ω φ is defined as the greatest fixpoint of Φ = λx . φ ∩ ❡ω x. Looking at predicates as sets, Φ is a function over a complete lattice — ⟨Pν, ⊆⟩ — whose monotony is easily proved by induction on the functor structure. Therefore, a concrete representation for  ω φ can be computed, by the Knaster-Tarski theorem [16], as the union of all post- fixpoints of Φ, i.e.,

 ω φ =  {s ∈ Pν| s ⊆ φ ∩ ❡ω s}

Being a post-fixpoint means, for each s above that, for any process p, p ∈ s
⇒ p ∈ φ ∧ p ∈ ❡ω s
≡ p ∈ φ ∧ p ∈ {x ∈ ν| ωx ∈ (s)P(Act×Id)}
≡ p ∈ φ ∧ p ∈ {x ∈ ν| ωx ∈ {c ∈ P(Act × ν)| ∀t . t ∈ c ⇒ t ∈ (s)Act×Id}}
≡ p ∈ φ ∧ p ∈ {x ∈ ν| ωx ∈ {c ∈ P(Act × ν)| ∀t . t ∈ c ⇒ π2 t ∈ s}}
≡ p ∈ φ ∧ p ∈ {x ∈ ν| (Pπ2 · ω) x ∈ s}

Seen as a set, predicate (5) is given by φ = {x ∈ ν| (Pπ1 · ω) x ∩ {a} = ∅}. Therefore,
 ω φ =   {s ∈ Pν| x ∈ s ⇒ ((Pπ1 · ω) x ∩ {a} = ∅) ∧ ((Pπ2 · ω) x ∈ s))}
or, in words, the set of all processes whose derivations never exhibit an action
a.
In Ccs, the set of all labels, seen as actions, in which a process p can
commit itself, i.e., that appear in at least one derivation of p, is called the sort of p and denoted by L(p). [14] provides a syntactic criterion to compute a majoring approximation of L(p) by induction on the process expression. A semantic definition can, however, be given as
L(p)= (Pπ1 ·   ·Pp)  p true	(7)
where, again, the embedding of L in Act is left implicit. Law (6) may then be rewritten as 9
[{b/a}] = id ⇐ ∈/a ·L	(8)
Parallel.
The next static operator considered here is synchronous product, modelling the simultaneous execution of its two arguments. In each step the resulting action is determined by the interaction structure for the calculus. Formally,
⊗ = [(α⊗)] where
α  = ν × ν (ω×ω) P (Act × ν) × P(Act × ν)  sel·δr	 P (Act × (ν × ν))
where sel = filter{0} filters out all synchronisation failures. Notice how interac- tion is catered by δr — the distributive law for the strong monad P(Act × Id) 10 . δr is the Kleisli composition of the left and the right strengths. This, on its

9 Going pointwise and noticing that, by convention, the parameter of the Ccs renaming operator represents ‘coactions’ implicitly, we end up with the familiar Ccs law p [{b/a}] = p ⇐ a, a ∈/ L(p). Function ∈/a is defined as λx . a ∈/ x.
10 Notice that the monoidal structure in Act extends functor P(Act × Id) to a strong monad.


turn, involves the application of the monad multiplication to ‘flatten’ the result and this, for a monoid monad, requires the suitable application of the under- lying monoidal operation, which, in our case, fixes the interaction discipline. In fact,
δrP(Act×Id)  = µP(Act×Id) · P(id × τrP(Act×Id)) · τlP(Act×Id)
= P((θ × id) · a◦) ·   ·PτlP · P(id × τrP(Act×Id)) · τlP(Act×Id)
i.e., going pointwise,
δrP(Act×Id) ⟨c1, c2⟩ = {⟨a'θa, ⟨p, p'⟩⟩| ⟨a, p⟩∈ c1 ∧ ⟨a', p'⟩∈ c2}
Finally, parallel composition arises as a combination of interleaving and synchronous product, in the sense that the evolution of p | q, for processes p and q, consists of all possible derivations of p and q plus the ones associated to the synchronisations allowed by the particular interaction structure for the calculus. This cannot be achieved by a simple composition of the correspond- ing combinators  and ⊗: it has to be performed at the ‘genes’ level for and ⊗. Formally, | = [(α|)], where
α  = ν × ν   Δ  (ν × ν) × (ν × ν)	∪·(α ×α⊗)	 P (Act × (ν × ν))

Synchronous product is commutative, associative and has nil as a zero element. Furthermore, it distributes over choice and, conditionally, over restriction and renaming. On the other hand, as expected, the | combinator shares some properties that are common to both  and ⊗. In particular, it gives rise, with nil, to an Abelian monoid and distributes along renaming and restriction in certain cases. However, it lacks a zero element and does not distribute through choice. Notice that the verification of such properties ‘re-uses’ the proofs of the corresponding results for  and ⊗.

Two Proofs.
This paragraph is concerned with the proof of restriction distributivity over
⊗ and |, illustrating two important points in our approach: the derivation of side conditions along a proof and proof re-use. The proofs rely on the following immediate consequence of law (1): to prove the equality φ = ψ it is enough to show that both ω · φ = T φ · α and ω · ψ = T ψ · α hold.
Consider, then, the derivation of the following property:
\K · ⊗ = ⊗ · (\K × \K)	⇐ uniform restriction	(9)
Proof. We proceed by unfolding the composite of ω with both sides of the equation. Therefore,

ω · ⊗ · (\K × \K)
=	{ comorphism, definition}
P(id × ⊗) · sel · δr · (ω × ω) · (\K × \K)
=	{ functoriality}
P(id × ⊗) · sel · δr · (ω · \K × ω · \K)
=	{ comorphism, functoriality}
P(id × ⊗) · sel · δr · (P(id × \K) × P(id × \K)) · (α\K × α\K )
=	{ δr naturality}
P(id × ⊗) · sel · P(id × (\K × \K)) · δr · (α\K × α\K )
=	{ sel definition, functoriality}
P(id ×⊗ · (\K × \K)) · sel · δr · (α\K × α\K )
Next a similar calculation is done for ω ·\K ·⊗, trying to arrive at an expression
P(id × (\K · ⊗)) · α, with α = sel · δr · (α\K × α\K ) as above.
ω · \K · ⊗
=		{ comorphism, definition} P(id × \K) · filterK · ω · ⊗
=	{ comorphism}
P(id × \K) · filterK · P(id × ⊗) · α⊗
=	{ definition}
P(id × \K) · filterK · P(id × ⊗) · sel · δr · (ω × ω)
=	{ filterK naturality}
P(id × \K) · P(id × ⊗) · filterK · sel · δr · (ω × ω)
=?	{  }
P(id × \K) · P(id × ⊗) · sel · δr · (filterK × filterK) · (ω × ω)
=	{ functoriality }
P(id × (\K · ⊗)) · sel · δr · (filterK · ω × filterK · ω)
=	{ definition}
P(id × (\K · ⊗)) · sel · δr · (α\K × α\K )
We have succeeded only partially: the step marked with a * does not hold uni- versally. We are then left with the task of establishing under what conditions, if any, the following equality holds:
filterK · sel · δr = sel · δr · (filterK × filterK)
Unfolding the definitions of the functions involved and going pointwise for a

while, we get
( filterK · sel ·δr) ⟨c1, c2⟩ =
= (filterK · sel) {⟨a'θa, ⟨p, p'⟩⟩| ⟨a, p⟩∈ c1 ∧ ⟨a', p'⟩∈ c2}
= filterK {⟨a'θa, ⟨p, p'⟩⟩| ⟨a, p⟩∈ c1 ∧ ⟨a', p'⟩∈ c2 ∧ a'θa /= 0}
= {⟨a'θa, ⟨p, p'⟩⟩| ⟨a, p⟩∈ c1 ∧ ⟨a', p'⟩∈ c2 ∧ a'θa /=0 ∧ a'θa ∈/ K}

On the other hand,
( sel · δr ·(filterK × filterK)) ⟨c1, c2⟩ =
= (sel · δr) ⟨{⟨a, p⟩∈ c1| a ∈/ K}, {⟨a', p'⟩∈ c2| a' ∈/ K}⟩
= sel {⟨a'θa, ⟨p, p'⟩⟩| ⟨a, p⟩∈ c1 ∧ ⟨a', p'⟩∈ c2 ∧ a, a' ∈/ K}
= {⟨a'θa, ⟨p, p'⟩⟩| ⟨a, p⟩∈ c1 ∧ ⟨a', p'⟩∈ c2 ∧ a, a' ∈/ K ∧ a'θa /= 0}
Clearly the two sets can be identified iff, for all possible a and a', such that

a'θa /= 0, a'θa ∈/
K ≡ a, a' ∈/
K. Therefore, step * is only possible if the

expression scope is restricted to pairs of processes satisfying the following predicate:
φ ⟨p, q⟩ = ∀a∈(Pπ1·ω) p,a'∈(Pπ1·ω) q . aθa /=0 ⇒ (aθa ∈/ K ≡ a, a ∈/ K) (10) which is lifted to the invariant uniform restriction =  α φ.	✷
As expected, a similar result holds for parallel composition.
Proof. The attempt to prove \K· | = | ·(\K × \K), proceeds by reducing the composite of ω with both sides of the equation to identify a common coalgebra α'. Thus,
ω · \K· |
=		{ double application of comorphism and definition} P(id × \K) · filterK · P(id× |) · ∪ · (α  × α⊗) · Δ
=	{ filterK naturality}
P(id × \K) · P(id× |) · filterK · ∪ · (α  × α⊗) · Δ
=	{ ∪ naturality, functoriality}
P(id × (\K· |)) · ∪ · (filterK · α  × filterK · α⊗) · Δ
=	{ reusing the proof of (9) and a similar result for  }
P(id × (\K· |) · ∪ · ((∪ · (τr × τl) · ((α\K × id) × (id × α\K )) · Δ)
× sel · δr · (α\K × α\K )) · Δ

Similarly, it is shown that ω· | ·(\K ×\K) = P(id × (| ·(\K × \K))) · α', where
α' = ∪ · ((∪ · (τr × τl) · ((α\K × id) × (id × α\K )) · Δ) × sel · δr · (α\K × α\K )) · Δ


is the common coalgebra. We are, thus, almost ready to conclude. Notice, however, that, on reusing the proof of law (9) in the last step of this derivation, we must also take into account the predicate which constrains the substitution made. Clearly, predicate (10) acts again as a local condition to validate the derivation here. We may then conclude the validity of the law, subjected to the restriction given by uniform restriction' =  α' φ.	✷
We may ask what form such invariants take given a particular interaction structure. For example, in the Ccs case, the result of θ does not belong to L
— θ has only three possible results under Ccs interaction discipline: τ ,1 and
0. Therefore, as K ⊆ L, condition a'θa ∈/ K holds for any K and φ becomes
∀a∈(Pπ1·ω) p,a'∈(Pπ1·ω) q . aθa /=0 ⇒ (aθa ∈/ K ≡ a, a ∈/ K)
≡	{ Ccs interaction structure }
∀a∈P(π1·ω) p,a'∈(Pπ1·ω) q . (aθa = τ ∨ aθa = 1) ⇒ a, a ∈/ K
≡	{ aθa′ = 1 iff a = a′ = 1 }
∀a∈(Pπ1·ω) p,a'∈(Pπ1·ω) q . aθa = τ ⇒ a, a ∈/ K
≡	{ aθa′ = τ iff a′ = a}
'		'

∀a∈(Pπ1·ω) p,a'∈(Pπ1·ω) q . a = a ⇒ a, a
≡	{ rearranging}
∈/ K



(Pπ1 · ω) p ∩ (Pπ1 · ω) q ∩ (K ∪ K)= ∅
where the overbar notation stands here for the lifting of the involutive Ccs complement operation to sets of actions. Now note that, although both invariants are derived from the same local condition (10), they stand for the closure of φ under different coalgebras and are, consequently, distinct. In fact, the number of derivations that have to be considered under φ is much greater in the second case. In particular, uniform restriction does not consider configurations representing interleavings. For example, if one of the processes exhausts after n steps, the condition on the actions is not re- quired to hold after that. On the other hand, in uniform restriction', φ is closed wrt the transitions on α', which include both interleavings and syn- chronisations. Therefore, and  recalling the notion of sort, we conclude that uniform restriction' ≡ L(p) ∩ L(p) ∩ (K ∪ K) = ∅ arriving to the following familiar Ccs presentation of this result

(p | q)\K = p\K | q\K	⇐ L(p) ∩ L(p) ∩ (K ∪ K)= ∅
This discussion illustrates our claim that such an approach to process cal- culi allows us to ‘discover’ the appropriate restrictions a law is constrained by, instead of ‘postulating’ them and verifying their suitability. It also makes explicit that such conditions are essentially dependent only on the calculus interaction structure. Consider, for example, what would happen to the law at hands if a Csp-like interaction discipline is chosen instead. In Csp [10] only

equally named actions synchronise, leading to the following definition of θ: aθa = a ,	aθ1 = 1θa = a and aθb = 0 in all other cases

Therefore, the condition aθa' /= 0 ⇒ (aθa' ∈/
K	≡	a, a' ∈/
K) becomes

trivially true and the law holds without any side condition.
Another Example.
A similar situation occurs when studying the distribution of renaming over
parallel. In an attempt to proof [f ]· | = | ·([f ] × [f ]), application of theorem
makes the following local condition to pop out (see [2] for the complete derivation):


φ ⟨p, q⟩ = 6a∈(Pπ1·ω) p,a'∈(Pπ1·ω) q . aθa
/=0 ≡ fa θfa' /=0 

Under the Ccs interaction discipline, aθa' /= 0 implies that aθa' =1 or aθa' = τ . Hence, when does the equivalence aθa' /=0 ≡ fa θfa' /= 0 hold? Clearly the implication from left to right holds trivially because f is a homomorphism on the interaction structure:
aθa' = *
⇒	{ Leibniz }
f (aθa') = f *
≡	{ f is an Act-homomorphism }
fa θfa' = *
when * stands for either 1 or τ . The implication in the opposite direction, however, reads
fa θfa' = * ⇒ aθa' = *
which, f being an Act-homomorphism, is equivalent to
f (aθa') = f * ⇒ aθa' = *
again for * standing for either 1 or τ . This holds only if f is mono. Thus, for the Ccs case, the generated invariant requires the injectivity of f or, at least, of its restriction to the relevant process sorts. The resulting law is usually written in Ccs as

(p | q)[f ]= p[f ] | q[f ]	⇐ f restricted to L(p | q) ∪ L(p | q) is mono
Variants and Conclusions
Behaviour Monads.
In the introduction to this paper we have remarked that the approach to process calculi design sketched here could cope with a variety of particu-

lar cases because the emphasis was placed on the common underlying struc- tures rather than on the distinctive particularities. A first source of genericity has already been introduced by separating the behaviour from the interaction structures. Note that all the process combinators introduced are either inde- pendent of any particular interaction discipline or parametrized by it. We shall now briefly examine what happens if the behaviour structure itself is changed. Recall that processes were defined as inhabitants of the carrier of the final coalgebra for T = B (Act × Id) where B was taken as the finite powerset func- tor. Next we have shown that, assuming a commutative monoidal structure over Act, the behaviour model captured by P(Act × Id) is a strong Abelian monad. The definitions of some combinators build upon this — in particular synchronous product basically relies on the monad distribution law δr. Com- mutativity of ⊗, and consequently of |, depends on the monoid underlying the interaction structure being itself Abelian. Therefore, a first line of enquire followed below consists of replacing B by different monads and extracting a correspondent family of calculi still parametrized by the interaction structure. The simplest case takes B as the identity Id. The result is, of course, a universe of deterministic (and perpetual) processes. A further elaboration of this replaces Id by Id + 1, entailing a calculus for deterministic but partial processes in the sense that the derivation of a ‘dead’ state is always possible. Such a calculus is far less expressive than the one previously discussed. In fact derivations do not form any kind of collection and, therefore, non determin- ism is ruled out. Similarly, combinators which explore non determinism, lack a counterpart here. Such is the case of choice, interleaving and, as a gener- alisation of the later, parallel. On the other hand, the composition of Id + 1 with the monoidal monad generated by Act is still a strong Abelian monad, and therefore synchronous product is still definable. Inaction and prefix, for partial processes, are defined as ω · nil = ι2 and ω · a. = ι1 · labela, respectively. On the other hand, product, restriction and renaming can be defined in a rather generic way as anamorphisms whose ‘genes’ are parametrized by the
monad B :
α[f] = ν  ω  B (Act × ν)  B (f ×id)  B (Act × ν) α\K  = ν  ω  B (Act × ν)	filterK B	 B (Act × ν)
α⊗ = ν × ν (ω×ω) B (Act × ν) × B (Act × ν) δr B (Act×Id) B (Act × (ν × ν))
selB B (Act × (ν × ν))
where δrB (Act×Id) is the distribution law associated to the composed monad B (Act × Id), therefore encapsulating the θ operation on actions. On the other hand, selB and filterKB explore the B structure in order to rule out synchronisation failures, in the first case, and to perform the action restriction in the second. For B = Act + 1, filterKId+1 = ((∈/K ·π1) → ι1, ι2·!) + id is expressed by a conditional, whereas, for B = P, such conditional was iterated



over a set. Notice that
∈/K is defined as λa . a ∈/
K and, again, selId+1 =

filter{0}Id+1. Finally, notice that when B is non commutative, which is the case of, e.g., B X = X٨, not only is commutativity lost for several combinators, but also two non bisimilar versions of ⊗ emerge, based, respectively, in δr and δl, as equation δr = δl holds only for commutative monads.

Reactive Processes.
Up to this point we have assumed an ‘active’ interpretation of processes. Similarly, an universe for reactive processes may be specified as a final coalge- bra ω for T X = (B X)Act, where B captures, as usual, the behaviour struc- ture. Notice that in this paragraph the overbar notation is used to refer to the transpose of a morphism under the curry/uncurry isomorphism. Let us revisit briefly the process combinators in this new setting, taking again B as the finite powerset monad.
The definitions of inaction, prefix and choice follow closely the ones already considered for ‘active’ processes, reflecting, however, the fact that Act appears now as an exponent. Notice, for example, how prefixing a process p by an action a results in a new process which is blind for every stimulus different from a. Formally,

ω · nil = ∅·!
ω · a. = ((=a ·π2) → sing · π1, ∅·!)
ω · + = ∪ · (ω × ω) · pdl
where pdl : (X ×Y ) ×Z −→ (X ×Y ) × (Y ×Z) is defined as ⟨π1 × id, π2 × id⟩. For any K ∈ L and renaming homomorphism f , restriction and renaming are given by \K = [(αK)] and [f ] = [(αf )], where αK = ((∈/K ·π2) → ω, ∅·!) and αf = ω · (id × f ). Notice that both f and the restriction set K act by constraining the set of meaningful stimuli, thus before the effective derivation is computed. Under the ‘active’ interpretation their effect was defined over
the (previously computed) derivations.
The synchronous product is defined, in this setting, as ⊗ = [(α⊗)], where,

α	= ν × ν (ω×ω) P νAct × PνAct  prod P (Pν × Pν)Act

(Pδr P )Act 
Act ∪Act 
Act

PP(ν × ν)	P(ν × ν)
where
prod ⟨d1, d2⟩ = λa . (a =0 → ∅, {⟨d1 a1, d2 a2⟩| 6a1,a2∈Act . a = a1θa2})
Recall that in the ‘active’ case, interaction was neatly captured by the dis- tribution law for the P(Act × Id) monad, which is no longer the case here. This entails the need to introduce function prod, which, additionally, filters

out synchronisation failures. On the other hand, the definition of the inter- leaving combinator corresponds to the one for the ‘active’ case, but for the replacement of set union by merge where merge ⟨d1, d2⟩ = λa. d1 a ∪ d2 a. Thus,  = [(α )] with
α	= ν × ν   Δ  (ν × ν) × (ν × ν (ω×id)×(id×ω) P νAct × ν) × (ν × PνAct)
)	(
 τr×τl  P (ν × ν)Act × P(ν × ν)Act  merge P (ν × ν)Act

where, of course, the right and left strengths are relative to the (PId)Act monad. The same observation applies to parallel composition, which arises, once again, as a combination of product and interleaving at the ‘genes’ level. The basic properties of this model of reactive processes are essentially the properties of the corresponding calculus of ‘active’ processes. The proof style is also similar, although calculation resorts now heavily to the properties of exponentiation (see [2]).

Process Languages and Prototyping.
One advantage of thinking about processes as inhabitants of (coinductive) types is the possibility of developing prototypes for process calculi in func- tional languages supporting such types. Once a prototype implementation of a particular calculus is developed, processes can be defined in the language and their execution traced. Furthermore, to deal with recursive processes, a language of process expressions has to be defined allowing for guarded oc- currences of process variables as valid terms. As expected, a term language for processes, over a set of labels, is defined as an inductive type. The set of terms is then taken as the carrier of a B (Act×Id)-coalgebra, whose coinductive extension (i.e., the associated anamorphism) provides an interpreter for the calculus. Moreover, process environments have to be introduced to collect all the process defining equations relevant to conduct experiments on a particu- lar network of processes. The environment acts as context information for the interpreter which is, consequently, redefined as a strong anamorphism. Such a strategy is used by the author, in [2], to develop Charity implementations of interpreters for elementary process calculi parametric on the interaction structure.

References
P. Aczel. Final universes of processes. In Brooks et al, editor, Proc. Math. Foundations of Programming Semantics. Springer Lect. Notes Comp. Sci. (802), 1993.
L. S. Barbosa. Components as Coalgebras. PhD thesis, Universidade do Minho (submitted), 2000.


L. S. Barbosa. Components as processes: An exercise in coalgebraic modeling. In S. F. Smith and C. L. Talcott, editors, FMOODS’2000 - Formal Methods for Open Object-Oriented Distributed Systems, pages 397–417, Stanford, USA, September 2000. Kluwer Academic Publishers.
R. Bird and O. Moor. The Algebra of Programming. Series in Computer Science. Prentice-Hall International, 1997.
R. S. Bird. An introduction to the theory of lists. In M. Broy, editor, Logic of Programming and Calculi of Discrete Design, volume 36 of NATO ASI Series F, pages 3–42. Springer-Verlag, 1987.
R. S. Bird and L. Meertens. Two exercises found in a book on algorithmics. In
L. Meertens, editor, Program Specification and Transformation, pages 451–458. North-Holland, 1987.
R. Cockett and T. Fukushima. About Charity. Yellow Series Report No. 92/480/18, Dep. Computer Science, University of Calgary, June 1992.
T. Hagino. Category Theoretic Approach to Data Types. Ph.D. thesis, tech. rep. ECS-LFCS-87-38, Laboratory for Foundations of Computer Science, University of Edinburgh, UK, 1987.
C. Hermida and B. Jacobs. Structural induction and coinduction in a fibrational
setting. Information & Computation, (145):105–121, 1998.
C. A. R Hoare. Communicating Sequential Processes. Series in Computer Science. Prentice-Hall International, 1985.
B. Jacobs. The temporal logic of coalgebras via Galois algebras. Techn. rep. CSI-R9906, Comp. Sci. Inst., University of Nijmegen, 1999.
G. R. Malcolm. Data structures and program transformation. Science of Computer Programming, 14(2–3):255–279, 1990.
E. Meijer, M. Fokkinga, and R. Paterson. Functional programming with bananas, lenses, envelopes and barbed wire. In J. Hughes, editor, Proceedings of the 1991 ACM Conference on Functional Programming Languages and Computer Architecture, pages 124–144. Springer Lect. Notes Comp. Sci. (523), 1991.
A. J. R. G. Milner. Communication and Concurrency. Series in Computer Science. Prentice-Hall International, 1989.
L. Moss. Coalgebraic logic. Ann. Pure & Appl. Logic, 1999.
A. Tarski. A lattice–theoretic fixpoint theorem and its applications. Pacific Journal of Mathematics, 5:285–309, 1955.
D. Turi and J. Rutten. On the foundations of final coalgebra semantics: non- well-founded sets, partial orders, metric spaces. Mathematical Structures in Computer Science, 8(5):481–540, 1998.


G. Winskel and M. Nielsen. Models for Concurrency. In S. Abramsky, D. M. Gabbay, and T. S. E. Gabbay, editors, Handbook of Logic in Computer Science (vol. 4), pages 1–148. 1995.
