Available online at www.sciencedirect.com


Electronic Notes in Theoretical Computer Science 284 (2012) 3–22
www.elsevier.com/locate/entcs

Control Flow Analysis of Generalised Boolean Networks
Chiara Bodei1, Linda Brodo2, Davide Chiarugi3
1 Dipartimento di Informatica, Universita` di Pisa,
chiara@di.unipi.it
2 Dipartimento di Scienze dei Linguaggi, Universit`a di Sassari,
brodo@uniss.it
2 Dipartimento di Scienze Matematiche e Informatiche, Universit`a di Siena,
chiarugi3@unisi.it


Abstract
Generalised Boolean Networks are a well known qualitative model used to analyse the evolution of genetic networks as well as generic biological pathways. Despite the qualitative abstraction due to the few threshold concentration values considered for each biological element in the model, the complexity of the execution of a Generalised Boolean model could be non trivial. In this paper, we propose a tailored process algebra, called Sim-πn, reminiscent of the π-calculus to model GBNs. We further apply the Control Flow Analysis methodology to the resulting computational model for making static (and therefore less computationally
expensive) predictions on the dynamical evolution of the investigated networks.
The scope is twofold: helping in the setting up of the model, for checking its completeness, and checking the evolution of the model, in terms of the possibility to reach particular threshold values of the biological elements in the model, when varying the initial conditions.

Introduction
Regulatory networks play a crucial role in living organisms and understanding their connections and their whole dynamics is quite a challenging task. Executable models
[13] of biological processes implied by these networks can provide useful insights. Nevertheless, building full detailed executable models of biological systems is often hampered by the lack of accurate, high-confidence parameters regarding, say, the kinetics of the chemical reactions or molecular concentrations. One possible solution consists in providing a qualitative model, able to grasp the essential features of the dynamic behavior. This is the approach followed in [33,30,31,29] where the logical Thomas’ method, the Generalised Boolean Network (GBN), is presented. In this model, the state of each gene (seen as a regulatory entity) is represented by a concentration threshold value that varies on a limited number of values, e.g., Low, Medium or High. Values abstractly correspond to distinguished levels of

1571-0661 © 2012 Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2012.05.012

regulation. As a matter of fact, regulators usually act differently above certain threshold values. The logic abstraction is able to capture this non-linear nature of networks behavior, despite its simplicity. The (global) state evolves to the next one, due to a set of functions that define the next state of each gene starting from the current state of the genes which regulate it.
The GBN model allows one to infer biological models from incomplete biolog- ical data and to study the steady states and the feedbacks (positive or negative). Nevertheless their application generates an exponential growth of the states and there is not a large number of formal techniques and analysis tools available. Other executable languages like Petri Nets [26] or Process Algebras (e.g. [19,6]) can offer instead their well-founded theory and tool support, once rendered the logical reg- ulatory models inside their complementary frameworks. Furthermore, GBNs can hardly handle incomplete or inconsistent data, i.e. cases in which there could be more than one next state, while, again, Petri Nets or Process Algebras can model these situations, by exploiting non determinism. Finally, both Petri Nets and Pro- cess Algebras can be easily extended in order to deal with quantitative information, like stochastic ones, e.g., associating rates with transitions.
The theory of Petri Nets, already exploited in Systems Biology (e.g. in [15,14]), has been employed to analyse the dynamics of regulatory networks in several works (see e.g. [7,27,28]), in which the logical models are translated in terms of Petri Nets, thus exploiting some of the above useful features. Process Algebras provide an alternative framework to analyse the dynamics of regulatory networks. They ([23,25,24,9,10,11,5,22,8], to cite only a few) have been fruitfully used to model several kinds of biological systems, relying on the idea that a biological system can be abstractly modelled as a concurrent system. Our approach aims at using process algebras for modelling and analysing GBNs. More in details, our purposes are
to introduce an executable process algebraic model able to capture the syn- chronous behavior of GBNs, where each entity composing the network can change its concentration only when all the other interacting entities have reached their threshold values;
to propose a static analysis technique that, once applied to the obtained model, is able to provide safe approximations of the behavior of the modelled entities. As a consequence, we can test the faithfulness of the model and also provide confident predictions on the dynamics, in case the model is sufficiently accurate.

Which Kind of Process Algebra?
We represent GBN entities as processes and the functions that compute their next states, given the threshold values of all the other regulative entities, as the result of communications between the corresponding processes. We have that an entity can send its new concentration value, only when all its regulators have sent their values.
Process Algebras offer different kinds of synchronisation mechanisms. What we need here is a multiple synchronisation among each entity and its regulators.

Also, we need that all the entities evolve at the same time. To model such a peculiar synchronisation pattern of GBNs, we chose to introduce a new process algebra called Sim-πn, reminiscent of the π-calculus [19]. In our model, each entity offers different combinations of inputs. Each combination of inputs corresponds to the reception of a combination of values coming from the regulative entities, combination that leads to the output of the new value. To this aim, we extend the π-calculus with the selective input prefix {a1(x1 ∈ X1), ..., an(xn ∈ Xn)}.P that simultaneously receives the outputs b1, ..., bn on the channels ai and continues as P , provided that each received value xi, with i ∈ [1, n] is included in the selection sets Xi. Note that a similar joint input has been introduced in [17] to extend CCS [20], where it is proven that the synchronisation on n inputs is more expressive that the one on n-1 inputs. We also need that all the genes simultaneously update their states, after the reception of the values coming from the regulative entities. To reproduce this behavior, every entity, in parallel, sends its threshold value to all the processes waiting for it. In the standard π-calculus, sent values are consumed by their recipients, while in Sim-πn, a value emitted persists until all the recipients have received it. During this first phase every entity commits on one combination of inputs, and it is therefore ready to output, in the second phase, the value resulting from that combination. As a consequence, at each step the process produces a new tuple of outputs ready for a new synchronisation step. Channels used for outputs resemble signals as defined in synchronous π-calculus [2]. What we obtain is a special many to many commitment, in which there is a simultaneous communication on all the input channels with all the corresponding outputs.




Which Kind of Analysis?
Operational semantics allows us to reason in terms of steps and of causal re- lationships among steps. Being an executable model, it is suitable for testing and comparing different hypotheses. As a consequence, our process algebraic model can facilitate the analysis, both dynamic and static, of GBNs behavior and of the network properties related to the concentration levels of the involved elements. In particular, we exploit Control Flow Analysis (CFA), i.e. a static analysis technique based on Flow Logic [21], by applying it to our process algebraic specification of GBNs. Control Flow Analysis provides a safe over-approximation of the exact be- havior of a system, in terms of the possible reachable configurations. The CFA results reflect the dynamics of the GBN model. The advantages derive from the fact that the CFA is in general not time-consuming, nor computationally expensive and this is a crucial point when the number of biological elements or the number of thresholds for each element increases.
We finally apply our framework to a to a case study represented by a real biological pathway, i.e. to a model of the regulatory network controlling the T- helper (Th) lymphocytes differentiation process.



Table 1
The Next State Functions of the Entities G1 and G2

Generalised Boolean Networks
Boolean Networks (BNs) [16] have been introduced in Biology to model Gene Reg- ulatory Networks (GRN), i.e. those networks of interaction between genes that are at the basis of the protein synthesis. A Boolean Network is composed by a set of entities which regulate each other in a positive or negative way. The state of each gene (seen as a regulatory entity) is represented by a boolean value, i.e. active (1) or inactive (0). The (global) state of a boolean network, composed of n genes, is represented as a n-dimension vector of boolean variables, one for each gene. The evolution from a state to the next one is computed by a set of n boolean functions, each acting on each single variable, that define the next state starting from the current state of the genes which regulate it.
We are interested in a generalisation of the BN model (GBN) [32], where each variable xi can take multiple values, that abstractly correspond to different levels of regulation. More formally, a generalised boolean network consists of a set of n nodes G = {G1, ..., Gn} that represent regulatory entities. Each entity Gi has an associated set of possible values Bi and its behavior is usually determined by a subset of involved entities, collected by what is called its neighborhood N (Gi) ⊆ G, with indexes ranged over by IN (Gi) = {l ∈ [1, n]|Gl ∈ N (Gi)}. The dynamics of each entity Gi is given by a logical next-state function [Gi], which given the states of the entities in N (Gi) computes the next state [Gi]. The next-state functions can be given by using state transition tables (the truth tables in the Boolean Networks). For the sake of uniformity, we fix the number of inputs to the whole number n of entities and we reason in terms of n-tuples. Note that here we focus on the synchronous model, where the states of all the entities are updated simultaneously in one single step, by using the corresponding next-state functions. A global state of a generalised boolean network with n entities is represented by a tuple of states (b1, ..., bn), where bi ∈ Bi represents the state of entity Gi ∈ G. The state space is therefore (B1 ×
... × Bn). The sequence of global states in (B1 × ... × Bn) starting from some initial state is calleda trace. The complete behavior of a GBN is described by the set of all the traces. Strongly connected components of the state transition graphs are called attractors. Among attractors, we can distinguish stable states, i.e. states that have no successors (apart from themselves), or states that are involved in cycles.
Running Example To illustrate the GBN model, we present a small system inspired by [28], composed by two entities G1 and G2, whose concentration values vary in













Fig. 1. State Transition Graph [28]
B1 = {0, 1} and in B2 = {0, 1, 2}, respectively. The next-state functions are directly defined using the state transition tables in Table 1, where [G1] ([G2]) represents the next state of G1 (G2, respectively). In this model only G2 influences the concentra- tion of G1 (i.e. the next value only depends on the state of G2) and both influence the concentration of G2. More in detail, the entity G1 inhibits G2, while G2 inhibits G1 only when reaching the state 2. A state s is composed by a pair (b1, b2) with bi ∈ Bi with i ∈ {1, 2}. For instance, s = (0, 0) is a state and, in one single step, we can pass from the state s to the state sj = (1, 1) and therefore on the stable state (1, 0), as shown by the graphical representation in Fig. 1.
BNs and its generalised version are traditionally applied to infer genetic reg- ulatory networks starting from a partial biological knowledge (see [12] for a short review). Nevertheless, GBNs can also be used to describe metabolic networks, where it is possible to have a wider range of concentration values. In general, it is worth- while investigating which conditions allow the molecular species of interest to reach threshold values.

The Process Algebra Sim-πn
To model the synchronisation pattern of GBNs, we introduce a new process al- gebra called Sim-πn, reminiscent of the π-calculus [19] (without summation and restriction), with restricted forms for processes and a special many to many syn- chronisation mechanism.
To obtain the required unisonous synchronisations, our processes P , that rep- resent regulatory entities, are obtained by the parallel composition of special sub- processes S that appear in tailored form. Sub-processes S are structured in two parts: an initial guard, made by a set of inputs that must be all executed (first part), if any, before executing the only last output prefix (second part) in parallel with S. Alternatively a sub-process S can be the continuation (a⟨b⟩ S) or can be

(b1, ..., bn) ∈ (X1 × ... × Xn) for all i ∈ [1, n]
i	i


where si = {a1(x1 ∈ X1), ..., an(xn ∈ Xn)}
i	i	i	i


P −→ P′
P ≡ P′ −→ Q′ ≡ Q P → Q





Table 2
The Reduction Semantics of the Calculus

given by just an output. Formally, let N be a countable set of names, ranged over by n, a, b, . . . , and X be a countable set of variables, ranged over by x, y, z,... , then the processes are built according to the following syntax:
P ::= P  S
S ::= 0 | {a1(x1 ∈ X1), ..., an(xn ∈ Xn)}.(a⟨b⟩ S) | (a⟨b⟩ S) | a⟨b⟩
Like in the π-calculus, the term 0 denotes the empty process and the operator  denotes the parallel composition. As standard, we omit 0, when needed, and we use the shorthand  i∈R Si for abbreviating the parallel composition of processes Si for i ∈ R. The prefix a⟨b⟩ denotes the output of value b on the channel a. The multiple selective input prefix guard {a1(x1 ∈ X1), ..., an(xn ∈ Xn)}.(a⟨bj⟩ S) (see [4] for a similar construct) simultaneously gets the outputs ai⟨bi⟩ on all the channels a1, ..., an and continues as (a⟨bj⟩  S), provided that each bi belongs to Xi for each i ∈ [1, n], where the sets Xi do not include any bound name. In other words, a value received along the channel ai is accepted only if it matches with one of the values included in the corresponding selection sets Xi. Note that inputs in Sim-πn have exactly n items.
The reduction semantics of our calculus is given in Table 2. We use the standard notion of structural congruence ≡ of π-calculus: in particular, processes form a commutative monoid with respect to the parallel composition. The communication is in parallel and in broadcast, i.e. each top-level output simultaneously synchronises with every corresponding input occurring in the combination of inputs, in the rest of the system, as explained below. Note that in the processes used to represent GBNs the values sent are not used for subsequent communications, but are passed for synchronisation purposes, unlike the π-calculus, and more in CCS [20] style. The other rules are standard.
The definition below allows the construction of a system of processes, given a Generalised Boolean Network, which shows a behavior equivalent to that of the original GBN.
Our idea consists in having a process for each regulative entity and a branch for each entry in the next-state function table, with the suitable selective joint input. Furthermore, to introduce the initial conditions, we use single outputs, not preceded

by inputs. For the sake of simplicity, in the following we overload the symbols Gi
and Bi, by using them both in the GBN notation and in the process algebraic one.
Definition 3.1 Given a GBN composed by n entities G = {G1, ..., Gn}, where each entity Gi has associated its next-state function [Gi]: B1 × ... × Bn → Bi, the corresponding Sim-πn system of processes is specified as follows:
G = G1  ...  Gn
Gi = Qj∈[1,m] Gij with m ≤ |B1|× ... × |Bn|
Gij = {a1(x1 ∈ X1 ), ..., an(xn ∈ Xn )}.(ai⟨bi ⟩ Gij),
ij	ij	ij	ij	ij
where, for each gene Gi there isa channel ai possibly sending values in Bi ⊆ N , and where for all combinations (b1, ..., bn) in B1 × ... × Bn such that [Gi](b1, ..., bn)= bj
there is a corresponding branch Gij, that includes the selective input {a1(x1 ∈
X1 ), ..., an(xn ∈ Xn)}, with Xk = {bk} for all k ∈ [1, n].
ij	ij	ij	ij
The initial conditions are given in the form of a parallel composition of n outputs in B1 × ... × Bn, as follows: Qi∈[1,n] ai⟨bi⟩.
In Section 5, we will exploit the full expressiveness of the selective inputs, by allowing not only singleton sets.
Our semantics works under the hypotheses that in each configuration there are exactly n branches (one for each entity) whose selective inputs match the given outputs. More precisely, given a configuration:

ai⟨bi⟩   ( 
sij.(ai⟨bi ⟩ Sij))

i∈[1,n]	i∈[1,n] j∈[1,m]
where sij = {a1(x1 ∈ X1 ), ..., an(xn ∈ Xn )}, by means of the commutative rule
ij	ij	ij	ij
for parallel composition, we can always put in evidence the n branches that match
with the given outputs, i.e. all the branches Sij with indexes j ∈ [1, m], and where
the corresponding selective inputs {a1(x1 ∈ X1 ), ..., an(xn ∈ Xn)}, are such that
ij	ij	ij	ij
for all i ∈ [1, n], (b1, ..., bn) ∈ (X1 × ... × Xn), thus obtaining
ij	ij

ai⟨bi⟩ 
sij.(ai⟨bi ⟩ Sij)     (	 
sik.(ai⟨bi ⟩ Sik))

i∈[1,n]
i∈[1,n]
i∈[1,n] k∈[1,m]\{j}

The communication rule effect is that of consuming the initial tuple of outputs, producing the new tuple of outputs and restoring the whole process representing the entities, therefore leading to the new configuration:

ai⟨bi ⟩   ( 

sij.(ai⟨bi ⟩ Sij))

i∈[1,n]	i∈[1,n] j∈[1,m]
Proposition 3.2 Let G be a GBN composed by n entities {G1, ..., Gn}, where each entity Gi has associated its next-state function [Gi]: B1 × ... × Bn → Bi, and G be the corresponding Sim-πn system of processes, that includes a parallel composition of outputs. In the state transition graph of G there exists a transition from the

G1  = G11  G12	G2  = G21  G22  G23  G24

G11 = {g1(x1 G12 = {g1(x1 G13 = {g1(x1 G14 = {g1(x1 G15 = {g1(x1 G16 = {g1(x1
∈ {0}), g2(x2
∈ {0}), g2(x2
∈ {0}), g2(x2
∈ {1}), g2(x2
∈ {1}), g2(x2
∈ {1}), g2(x2
∈ {0})}.(g1⟨1⟩ G11)
∈ {1})}.(g1⟨1⟩ G12)
∈ {2})}.(g1⟨0⟩ G13)
∈ {0})}.(g1⟨1⟩ G14)
∈ {1})}.(g1⟨1⟩ G15)
∈ {2})}.(g1⟨0⟩ G16)
G21 = {g1(y1 G22 = {g1(y1 G23 = {g1(y1 G24 = {g1(y1 G25 = {g1(y1 G26 = {g1(y1
∈ {0}).g2(y2
∈ {0}).g2(y2
∈ {0}).g2(y2
∈ {1}).g2(y2
∈ {1}).g2(y2
∈ {1}).g2(y2
∈ {0})}.(g2⟨1⟩ G21)
∈ {1})}.(g2⟨2⟩ G22)
∈ {2})}.(g2⟨2⟩ G23)
∈ {0})}.(g2⟨0⟩ G24)
∈ {1})}.(g2⟨0⟩ G25)
∈ {2})}.(g2⟨1⟩ G26)




Table 3
Our Running Example Specification

global state s = (b1, ..., bn) to sj = (bj , ..., bj ) if and only if there is a transition on
1	n
the corresponding system.
Proof Sketch By Def. 3.1, we have that for each reachable entry (b1, ..., bn) in the state transition table for G, there exists a branch Gij (with j ∈ [1, m] and m ≤ |B1|×
...×|Bn|) for each entity Gi in the form {a1(x1 ∈ X1 ), ..., an(xn ∈ Xn)}.(ai⟨bi ⟩|Gij),
ij	ij	ij	ij	ij
such that Xk = {bk}. These are exactly the premises of the communication rule
leading to the desired transition. As a consequence, the operational semantics of
Sim-πn exactly reproduces the simultaneous synchronisations of the GBNs.    2
Running Example (cont’d) The complete specification of our running example cor- responding to the next-state functions in Table 1, is given in Table 3, where the channels are g1 for the first component and g2 for the second one.
Suppose to have the following initial condition process with two outputs: I = g1⟨0⟩  g2⟨0⟩, corresponding to the state (0, 0). The overall system is therefore G1  G2  I. The system evolves first by simultaneously synchronising on the values 0, 0, then on the values 1, 1 and finally on the values 1, 0, as shown by the following transitions, that mimic the representation of the state trace (the sequence of states), leading the GBN from the state (0, 0) to the state (1, 1), and from (1, 1) to (1, 0). To emphasise this correspondence, we enrich the transition arrow with a label that records the corresponding GBN state. The last state is a stable one: indeed, from the last state G1  G2  g1⟨1⟩  g0⟨0⟩ we can only reach the state
1	2
itself. Also, we use the shorthand Gj , Gjj and Gjjj to denote the process G1 except
1	1	1
for the first (fifth and fourth, respectively) parallel sub-process. Similarly, Gj , Gjj
2	2
and Gjjj denote the process G2 except for the first (fifth and fourth, respectively)
parallel sub-process.

{g1(x1
00  
∈ {0}), g2(x2
′
∈ {0})}.(g1⟨1⟩ G11)  G′
′
 {g1(y1
∈ {0}).g2(y2
∈ {0})}.(g2⟨1⟩ G21)  G′  I

−−→ g1⟨1⟩ G11  G1  g2⟨1⟩ G21  G2 ≡ G1  G2  g1⟨1⟩ g2⟨1⟩≡ 

{g1(x1
11  
∈ {1}), g2(x2
′′
∈ {1})}.(g1⟨1⟩ G15)  G′′
′′
{g1(y1
∈ {1}).g2(y2
∈ {1})}.(g2⟨0⟩ G25)  G′′

−−→ g1⟨1⟩ G15  G1  g2⟨0⟩ G25  G2 ≡ G1  G2  g1⟨1⟩ g2⟨0⟩≡ 

{g1(x1
10  
∈ {1}), g2(x2
′′′
∈ {0})}.(g1⟨1⟩ G14)  G′′′
′′′
{g1(y1
∈ {1}).g2(y2
∈ {0})}.(g2⟨0⟩ G24)  G′′′

−−→ g1⟨1⟩ G14  G1	g2⟨0⟩ G24  G2  ≡ G1  G2  g1⟨1⟩ g2⟨0⟩

Similarly, we can model the other traces, one starting from (0, 1) leading to (1, 2) and back to (0, 1), and the other starting from (0, 2) and coming back to (0, 2) (see
Fig. 1).
Note that, in case of incomplete data, i.e. cases in which there could be more than one next state, the process algebraic framework offers us a way out, thanks to the possible introduction of the non deterministic choice operator + in the syntax. We could indeed allow a process to branch on the same selective input, and to choose among different outputs, in a non deterministic way. Dynamically, only one output is chosen each time. In the GBN framework, this is not possible, because we deal with functions that, by definition, require a unique value for each input.
By summarising, Sim-πn seems to offer a first encouraging answer on how ren- dering the GBN synchronous behavior in process algebraic terms.

Control Flow Analysis
The Control Flow Analysis (CFA) extends the one for the π-calculus in [3]. The CFA computes a safe over-approximation of all the possible values that the tuples of variables in the system may be bound to, and of the tuples of values that may simultaneously flow on channels. Furthermore, it can establish a causal relation between a configuration and the next one. In other words, it predicts all the pos- sible communications, and consequently all the possible reachable configurations, in terms of concentration levels. More precisely, the analysis keeps track of the following information:
An approximation ρ : X × ... ×X → ℘(B1 × ... × Bn) of name bindings (see [3]). If (b1, ..., bn) ∈ ρ(x1, ..., xn) then each variable xi can simultaneously assume the value bi, for each i ∈ [1, n].
An approximation κ: N × ... ×N → (B1 × ... × Bn → ℘(B1 × ... × Bn)) that, given a set of n channels and a a tuple of output values, provides all the possi- ble tuples of output prefixes reached after the simultaneous synchronisation. If (b1, ..., bn) ∈ κ(a1, ..., an)(bj , ..., bj ) the output tuple (bj , ...,j bn) could be triggered
1	n	1
by the previous inputs on the tuple (b1, ..., bn). Furthermore, we introduce the
tuple (ϵ, ..., ϵ) to identify the ideal initial tuple. As a consequence, the tuples (b1, ..., bn) in κ(a1, ..., an)(ϵ, ..., ϵ), are the possible tuples of simultaneously sent values.
The approximation of the behavior of a process P is represented by the pair ρ, κ, called estimate for P , whose correctness is validated against a set of clauses that operate upon judgments in the form ρ, κ |= P . Clauses, that amount to a structural traversal of process syntax, are given in Table 4. All the clauses dealing with a compound process require that the components are validated. The rule for the inactive process does not restrict the analysis result while the rules for parallel composition ensure that the analysis also holds for the immediate sub-processes. In particular, the analysis of the composition of the tuple of outputs and the parallel composition of the corresponding selective input branches amounts to separately

analysing the part of outputs and all the selective input branches.
In analysing the parallel composition of n output prefixes, we have to check whether the corresponding sent values, collected in the tuple (b1, ..., bn), belong to κ(a1, ..., an)(ϵ, ..., ϵ), i.e. it is a tuple of simultaneous outputs. Analysing instead the process {a1(x1 ∈ Xi), ..., an(xn ∈ Xi )}.(ai⟨bj⟩  S) requires more steps. Given an
1	n	i
input combination, (i) we look in κ(a1, ..., an)(ϵ, ..., ϵ) for a tuple (b1, ..., bn) of simul-
taneously sent values that match the corresponding selective inputs. For any match- ing combination, (ii) we check whether the tuple (b1, ..., bn) composed by the values bi possibly sent on the i-th channel is included in ρ(x1, ..., xn) of names to which the
i	i
tuples of variable x1, ..., xn can evaluate. Furthermore, (iii) we check whether the
i	i
resulting tuple of sent values (bj , ..., bj ) is included in the set of tuples that belong
1	n
to κ(a1, ..., an)(b1, ..., bn) and to κ(a1, ..., an)(ϵ, ..., ϵ).  In analysing a process, the
tuple of initial sent values, that has no trigger, is recorded in κ(a1, ..., an)(ϵ, ..., ϵ), but also all the tuples that arise from the subsequent communications. This inclu- sion ensures the semantic correctness, since the estimate must be valid for all the derivatives of the initial system.
Intuitively, the estimate components take into account the possible dynamics of the process under consideration. In the clauses, the checks mimic the semantic evolution, by modelling the semantic preconditions and the consequences of the possible synchronisations. For the communication clause, e.g., it checks whether the precondition of a many to many synchronisation is satisfied, i.e. whether there is an output tuple in κ(a1, ..., an)(ϵ, ..., ϵ), matching the analysed input one. The conclusion imposes the additional requirements on the estimate components, neces- sary to give a valid prediction of the analysed synchronisation action, mainly that

the variables xi
can be bound, and that the resulting outputs can be reached, due

to the previous tuple, and collected in a new tuple.
Finally, the analysis of S = a1(x1 ∈ X1), ..., an(xn ∈ Xn)}.(ai⟨bj⟩ S) coincides
i	i	i	i	i
with the one for a1(x1 ∈ X1), ..., an(xn ∈ Xn)}.ai⟨bj⟩, i.e. the CFA does not take
i	i	i	i	i
into account infinite behavior and this is a source of approximation.
Note that, in case of incomplete data, i.e. when it is possible to have more than one output tuple after a given one, we have that κ(a1, ..., an)(b1, ..., bn) is not a singleton, but a set. This can clearly lead to an over-approximation of the possible pathways.
It is possible to prove that there always exists a least estimate (see [3] for a similar proof) and that the CFA is correct, i.e. it respects the semantic specification, as shown below.
Theorem 4.1 If P −→ P j and ρ, κ |= P then ρ, κ |= P j.
Proof. By induction on the inference of P −→ P j.
We only show the case of the communication rule, where P = Qi∈[1,n] ai⟨bi⟩ 

Si, with Si = {a1(x1
Q	

  	
∈ X1), ..., an(xn
∈ Xn)}.(ai⟨bj⟩	Si) and P j =

		 

(1) ρ, κ |=	i∈[1,n] ai⟨bi⟩ and






The conjunct (2) in full is ρ, κ |= Q
Table 4 CFA

{a1(x1 ∈ X1), ..., an(xn ∈ Xn)}.(ai⟨bj⟩ Si),

i∈[1,n]	i	i
that for the CFA rules is equivalent to
i	i	i

ρ, κ |= Q
{a1(x1 ∈ X1), ..., an(xn ∈ Xn)}.ai⟨bj⟩.

We have that:
from (1) (b1, ..., bn) ∈ κ(a1, ..., an)(ϵ, ..., ϵ);
since (b1, ..., bn) ∈ κ(a1, ..., an)(ϵ, ..., ϵ) and (b1, ..., bn) ∈ (X1 × ... × Xn) for all
i	i
i ∈ [1, n], then (b1, ..., bn) ∈ ρi(x1, ..., xn) and furthermore both (bj , ..., bj ) ∈
i	i	1	n
κ(a1, ..., an)(ϵ, ..., ϵ) and (bj , ..., bj ) ∈ κ(a1, ..., an)(b1, ..., bn) hold.
1	n

Since (bj , ..., bj ) ∈ κ(a1, ..., an)(ϵ, ..., ϵ), we can deduce that ρ, κ |= Q
ai⟨bj⟩

and therefore ρ, κ |= Q

i∈[1,n]
ai⟨bj⟩ Q

i∈[1,n]
Si, because ρ, κ |= Q

i∈[1,n]
Si holds by

hypothesis.	2
Running Example (cont’d) We can now apply our CFA to our running example, given the initial conditions I = g1⟨0⟩ g2⟨0⟩, i.e. we analyse the system G1  G2  I.



κ(g1, g2)(є, є)= {(0, 0), (1, 1), (1, 0)}
κ(g1, g2)(0, 0) = {(1, 1)} ρ(x1 , x2 ) ⊇ {(0, 0)} ρ(y1 , y2 ) ⊇ {(0, 0)}
11  11	21  21
κ(g1, g2)(1, 1) = {(0, 1)} ρ(x1 , x2 ) ⊇ {(0, 0)} ρ(y1 , y2 ) ⊇ {(1, 1)}
15  15	25  25
κ(g1, g2)(0, 1) = {(1, 0)} ρ(x1 , x2 ) ⊇ {(0, 0)} ρ(y1 , y2 ) ⊇ {(1, 0)}
14  14	24  24


Table 5
Some of the CFA Results

Some of the results are reported in Table 5. To illustrate our analysis, we show some checks performed by the CFA.
ρ, κ |= G1  G2  I iff ρ, κ |= G1 ∧ ρ, κ |= G2 ∧ ρ, κ |= I and therefore
· ρ, κ |= G1 iff ρ, κ |= G11 ∧ ... ∧ ρ, κ |= G16
· ρ, κ |= G2 iff ρ, κ |= G21 ∧ ... ∧ ρ, κ |= G26
ρ, κ |= I implies that
· (0, 0) ∈ κ(g1, g2)(ϵ, ϵ).
Since (0, 0) ∈ κ(g1, g2)(ϵ, ϵ), 0 ∈ {0, 1}, and 0 ∈ {0}, we have that ρ, κ |= G11 and
ρ, κ |= G21 imply that
· (0, 0) ∈ ρ(x1 , x2 ) ∧ (0, 0) ∈ ρ1(y1 , y2 )
11	11	21	21
· (1, 1) ∈ κ(g1, g2)(0, 0), and (1, 1) ∈ κ(g1, g2)(ϵ, ϵ).
The analysis results reflect the dynamic behavior. We can obtain the possible traces of states, by inspecting the κ component. In this case, from the initial configuration of values (0, 0), the analysis tells us that a possible next configuration is (1, 1), from which it is possible to reach the configuration (1, 0). From (1, 0), we can only reach (1, 0). This is exactly one of the possible traces in Fig. 1. At the same time we can infer that starting from (0, 0) the configuration (1, 2) is not reachable. As this simple example shows, our method can be used for easily checking some properties of biological networks. Its usefulness becomes more relevant when very large samples are considered. In this case, methods based on model checking or on the analysis of simulation results can indeed be computationally expensive. Our analysis, that is a simple extension of the one in [3], operates indeed in low polynomial time in the size of the process algebraic specification of the system of entities.

Possible Optimisations
Slightly modifying our definition of processes derived by GBNs, we obtain a more compact encoding, that recall the more compact formulas, obtained by applying well-known logic minimisation techniques. Under this regard, we can exploit the full expressiveness of the sets in the selective inputs.
Note that if the entity Gi does not depend on the entity Gk, then we could put Xk = Bk in the k-th position in all the branches of Gi. On the process algebraic side, this corresponds to have that the input on the rest of components synchronises, independently from the output on the k-th component. For instance, in our running

example, we could have less branches in the specification of G1, as follows:
G1  = G11  G12  G13

G11 = {g1(x1 G12 = {g1(x1 G13 = {g1(x1
∈ {0, 1}), g2(x2
∈ {0, 1}), g2(x2
∈ {0, 1}), g2(x2
∈ {0})}.(g1⟨1⟩ G11)
∈ {1})}.(g1⟨1⟩ G12)
∈ {2})}.(g1⟨0⟩ G13)

Furthermore, we can merge in one single branch all the combinations that share one of the entries, thus leading to the same result. We can illustrate it still in our running example, where we have that the value of [G1] is 1 either if G2 = 0 or G2 = 1. Consequently, we can have a single branch for both cases, thus further reducing the whole number of branches, as in the following specification.

G1  = G11  G12

G11 = {g1(x1
G12 = {g1(x1
∈ {0, 1}), g2(x2
∈ {0, 1}), g2(x2
∈ {0, 1})}.(g1⟨1⟩ G11)
∈ {2})}.(g1⟨0⟩ G12)

This operation recalls the corresponding minimisation on the multi-values disjunc- tive normal forms, obtained by combining product terms, made by literals in the
form gS where S ⊆ Bi. The two terms can be combined together because they
differ in only the literal g2.
g1 = g0,1 · g0 + g0,1 · g1 = g0,1 · (g0 + g1)= g0,1 · g0,1
1	1	2	1	2	1	2	2	1	2
Finally, when a more concise specification is needed, we could even omit the inputs on the variables xik that belong to Xik = Bk in the specification, as in:
G1  = G11  G12  G13

G11 = {g2(x2
G12 = {g2(x2
∈ {0, 1})}.(g1⟨1⟩ G11)
∈ {2})}.(g1⟨0⟩ G12)

The CFA can be slightly modified accordingly. In the next section, we apply all the above optimisations to our case study.
Case Study: The T-helper Regulatory Network
In this section, we apply our framework to a case study represented by a real biologi- cal pathway, in order to understand the roles of the elements composing a molecular network in influencing the concentration of other species. In particular, we consider the regulatory network that controls the T-helper (Th) lymphocytes differentiation process, following the homologous Thomas’ model taken from [18] and shown in Figure 2. Specifically, the model describes the network of interactions underlying

the differentiation process of two cell lineages, namely lymphocytes T-helper 1 and 2 (Th1 and Th2, respectively) from the common precursor Th0. T-helpers play a crucial role in the context of mammals immune system and their differentiation is finely regulated by different molecules (e.g. Interleukines and Interferons) produced by Th themselves or by other cell types including monocytes and dendritic cells. For more details on T-helper lymphocytes and their role in the immune system we refer the reader to [1] or to [18].
First we show an example of computation according to our formalism illustrating also how to apply the CFA on it. Then we verify the consistency of our model comparing the results of our computation and analysis with those presented in [18]. Finally we show how our method can be used to gain insights on the roles played by the network elements.
We consider and specify the whole network described in [18] (see Table 1 for the complete list of GBN dynamical rules), composed by the following seventeen elements: (1) IL-12, (2) IL-18, (3) IFN -β, (4) IL-12R, (5) IL-18R, (6) IFN -βR,
(7) STAT -4, (8) IRAK, (9) IFN -γ, (10) IFN -γR, (11) STAT -1, (12) IL-4, (13)
IL-4R, (14) STAT -6, (15) GATA-3, (16) SOCS-1, (17) T -BET (with GATA-3
and T -BET without auto-activation). A sketch of the corresponding specification is presented in Tables 6 and 7.






Fig. 2. The T-helper regulatory network. [Adapted from [18]]


Our whole system Sys is given by the parallel composition of the 17 processes represented in our specification. We choose the following tuple of channels: G = (il12b, il18,finβ, il12r, il18r, finβr, stat4, irak, finγ, finγr, stat1, il4, il4r, stat6, gata3, socs1,T ibet)
where the values that can pass on ifnγ, ifnγr, stat1, and tbet range over {L, M, H}, while the values that can pass on the other channels range over {L, H}, and L stands for Low, M for Medium and H for High:


IL-12 = IL-121  IL-122	IL-18 = IL-181  IL-182
IL-121 = {il12(x1 ∈ {L})}.(il12⟨L⟩ IL-121)	IL-181 = {il18(x2 ∈ {L})}.(il18⟨L⟩ IL-181)
IL-122 = {il12(x1 ∈ {H})}.(il12⟨H⟩ IL-122)	IL-182 = {il18(x2 ∈ {H})}.(il18⟨H⟩ IL-182)
IFN -β = IFN -β1  IFN -β2	STAT -6 = STAT -61   STAT -62
IFN -β1 = {ifnβ(x3 ∈ {L})}.(ifnβ⟨L⟩ IFN -β1)    STAT -61 = {il4r(x13 ∈ {L})}.(stat6⟨L⟩ STAT -61)
IFN -β2 = {ifnβ(x3 ∈ {H})}.(ifnβ⟨H⟩ IFN -β2)   STAT -62 = {il4r(x13 ∈ {H})}.(stat6⟨H⟩ STAT -62)
IFNβ-R = IFNβ-R1  IFNβ-R2	IRAK-= IRAK1  IRAK2
IIFNβ-R1 = {ifnβ(x3 ∈ {L})}.(ifnβr⟨L⟩ IFN -β1) IRAK1 = {il18r(x5 ∈ {L})}.(irak⟨L⟩ IRAK1) IFNβ-R2 = {ifnβ(x3 ∈ {H})}.(ifnβr⟨H⟩ IFN -β2) IRAK2 = {il18r(x5 ∈ {H})}.(irak⟨H⟩ IRAK2) IL-12R = IL-12R1 IL-12R2 IL-12R3
IL-12R1 = {il12(x1 ∈ {L}), stat6(x14 ∈ {L, H})}.(il12r⟨L⟩ IL-12R1)
IL-12R2 = {il12(x1 ∈ {H}), stat6(x14 ∈ {H})}.(il12r⟨L⟩ IL-12R2) IL-12R3 = {il12(x1 ∈ {H}), stat6(x14 ∈ {L})}.(il12r⟨H⟩ IL-12R3) IL-18R = IL-18R1  IL-18R2  IL-18R3
IL-18R1 = {il18(x1 ∈ {L}), stat6(x14 ∈ {L, H})}.(il12r⟨L⟩ IL-18R1)
IL-18R2 = {il18(x1 ∈ {H}), stat6(x14 ∈ {H})}.(il12r⟨L⟩ IL-18R2)
IL-18R3 = {il18(x1 ∈ {H}), stat6(x14 ∈ {L})}.(il12r⟨H⟩ IL-18R3)
STAT -4 = STAT -41  STAT -42  STAT -42
STAT -41 = {il12r(x4 ∈ {H}), gata3(x15 ∈ {L, H})}.(il12r⟨L⟩ STAT -41) STAT -42 = {il12r(x1 ∈ {H}), gata3(x15 ∈ {H})}.(il12r⟨L⟩ STAT -42) STAT -43 = {il12r(x1 ∈ {H}), gata3(x15 ∈ {L})}.(il12r⟨H⟩ STAT -43)
IFN -γ = IFN -γ1  IFN -γ2  IFN -γ3  IFN -γ4
IFN -γ1 = {stat4(x7 ∈ {L, M}).irak(x8 ∈ {L, H}), tbet(x17 ∈ {L})}.(ifnγ⟨L⟩ IFN -γ1)
IFN -γ2 = {stat4(x7 ∈ {L, M}).irak(x8 ∈ {L, H}), tbet(x17 ∈ {M})}.(ifnγ⟨M⟩ IFN -γ2)
IFN -γ3 = {stat4(x7 ∈ {L, M, H}).irak(x8 ∈ {L, H}), tbet(x17 ∈ {H})}.(ifnγ⟨H⟩ IFN -γ3)
IFNγ-R = IFNγ-R1  IFNγ-R2  IFNγ-R3  IFNγ-R4
IFNγ-R1 = {ifnγr(x10 ∈ {L}), socs1(x16 ∈ {L, H})}.(ifnγr⟨L⟩ IFNγ-R1
IFNγ-R2 = {ifnγr(x10 ∈ {M}), socs1(x16 ∈ {L})}.(ifnγr⟨M⟩ IFNγ-R2
IFNγ-R3 = {ifnγr(x10 ∈ {H, M}), socs1(x16 ∈ {H})}.(ifnγr⟨M⟩ IFNγ-R3
IFNγ-R4 = {ifnγr(x10 ∈ {H}), socs1(x16 ∈ {L})}.(ifnγr⟨H⟩ IFNγ-R2
STAT -1 = STAT -11  STAT -12  STAT -13  STAT -14
STAT -11 = {ifnβr(x6 ∈ {L}), ifnγr(x10 ∈ {L})}.(stat1⟨L⟩ STAT -11)
STAT -12 = {ifnβr(x6 ∈ {H}), ifnγr(x10 ∈ {L, M})}.(stat1⟨M⟩ STAT -12) STAT -13 = {ifnβr(x6 ∈ {L}), ifnγr(x10 ∈ {M})}.(stat1⟨M⟩ STAT -13) STAT -14 = {ifnβr(x6 ∈ {L, H}), ifnγr(x10 ∈ {H})}.(stat1⟨H⟩ STAT -14)


Table 6
Case Study Specification
Computing the model and applying our CFA: an example
Suppose to have the following initial condition process I with 17 outputs, cor- responding to the state (L, L, H, L, L, L, L, L, L, L, L, L, L, L, L, L, L)

il12⟨L⟩ il18⟨L⟩ ifnβ⟨H⟩ il12r⟨L⟩ il18r⟨L⟩ ifnβr⟨L⟩ stat4⟨L⟩ irak⟨L⟩ 
ifnγ⟨L⟩ ifnγr⟨L⟩ stat1⟨L⟩ il4⟨L⟩ il4r⟨L⟩ stat6⟨L⟩ gata3⟨L⟩ socs1⟨L⟩ tbet⟨L⟩

We can have the following computation, where we use the shorthand Sysj to denote
Sys except for IFN -β2 and IFN -βR2:
Sys  I
≡ {ifnβ(x3∈{H})}.(ifnβ⟨H⟩ IFN -β3)  {ifnβ(x3∈{H})}.(ifnβr⟨H⟩ IFN -βR2)  Sys′  I
≡ Sys  I′

IL-4 = IL-41  IL-42  IL-43
IL-41 = {stat1(x11 ∈ {L, M, H}), gata3 ∈ {L}}.(il4⟨L⟩ IL-41)
IL-42 = {stat1(x11 ∈ {M, H}), gata3 ∈ {H}}.(il4⟨L⟩ IL-42)
IL-43 = {stat1(x11 ∈ {L}), gata3 ∈ {H}}.(il4⟨H⟩ IL-43)
IL-4R = IL-4R1  IL-4R2  IL-4R3  IL-4R4
IL-4R1 = {il4(x12 ∈ {L}), socs1(x16 ∈ {L, H})}.(il4r⟨L⟩ IL-4R1)
IL-4R2 = {il4(x12 ∈ {H}), socs1(x16 ∈ {L})}.(il4r⟨H⟩ IL-4R2)
IL-4R3 = {il4r(x13 ∈ {H}), socs1(x16 ∈ {H})}.(il4r⟨L⟩ IL-4R3)
GATA-3 = GATA-31  GATA-32  GATA-33
GATA-31 = {stat6(x14 ∈ {L}), tbet(x17 ∈ {L}}.(gata3⟨L⟩ GATA-31)
GATA-32 = {stat6(x14 ∈ {L, H}), tbet(x17 ∈ {M, H}}.(gata3⟨L⟩ GATA-32) GATA-33 = {stat6(x14 ∈ {H}), tbet(x17 ∈ {L}}.(gata3⟨H⟩ GATA-33)
SOCS-1 = SOCS-11  SOCS-12  SOCS-13  SOCS-14
SOCS-11 = {stat1(x11 ∈ {L}), tbet(x17 ∈ {L})}.(socs1⟨L⟩ SOCS-11)
SOCS-12 = {stat1(x11 ∈ {L}), tbet(x17 ∈ {M, H})}.(socs1⟨H⟩ SOCS-12)
SOCS-13 = {stat1(x11 ∈ {M, H}), tbet(x17 ∈ {L, M, H})}.(socs1⟨H⟩ SOCS-13)
T -BET = T -BET1  ...  T -BET7
T -BET1 = {stat1(x11 ∈ {L, M, H}), gata3(x15 ∈ {L, H}), tbet(x17 ∈ {L})}.(tbet⟨L⟩ T -BET1
T -BET2 = {stat1(x11 ∈ {L, H}), gata3(x15 ∈ {H}), tbet(x17 ∈ {M, H})}.(tbet⟨L⟩ T -BET2
T -BET3 = {stat1(x11 ∈ {L}), gata3(x15 ∈ {L}), tbet(x17 ∈ {M})}.(tbet⟨M⟩ T -BET3
T -BET4 = {stat1(x11 ∈ {M}), gata3(x15 ∈ {L, H}), tbet(x17 ∈ {M})}.(tbet⟨M⟩ T -BET4
T -BET5 = {stat1(x11 ∈ {L}), gata3(x15 ∈ {L}), tbet(x17 ∈ {H})}.(tbet⟨H⟩ T -BET5
T -BET6 = {stat1(x11 ∈ {M}), gata3(x15 ∈ {L, H}), tbet(x17 ∈ {H})}.(tbet⟨H⟩ T -BET6
T -BET7 = {stat1(x11 ∈ {H}), gata3(x15 ∈ {L}), tbet(x17 ∈ {M, H})}.(tbet⟨H⟩ T -BET7
Table 7
Case Study Specification (Continued)


where Ij, that corresponds to the state (L, L, H, L, L, H, L, L, L, L, L, L, L, L, L, L, L), is the new output tuple and it is specified in Sim-πn as follows

il12⟨L⟩ il18⟨L⟩ ifnβ⟨H⟩ il12r⟨L⟩ il18r⟨L⟩ ifnβr⟨L⟩ stat4⟨L⟩ irak⟨L⟩ 
ifnγ⟨L⟩ ifnγr⟨L⟩ stat1⟨L⟩ il4⟨L⟩ il4r⟨L⟩ stat6⟨L⟩ gata3⟨L⟩ socs1⟨L⟩ tbet⟨L⟩


Now, we can have the following computation, where Sysjj stands for Sys except for
STAT -12:

Sys  I′ ≡ {ifnβr(x6 ∈ {H}), ifnγr(x10 ∈ {L, M})}.(stat1⟨M⟩ STAT -12)  Sys′′  I′ ≡ Sys  I′′
where Ijj, that corresponds to the state (L, L, H, L, L, H, L, L, L, L, M, L, L, L, L, L, L), is the new output tuple and it is specified as follows:

il12⟨L⟩ il18⟨L⟩ ifnβ⟨H⟩ il12r⟨L⟩ il18r⟨L⟩ ifnβr⟨H⟩ stat4⟨L⟩ irak⟨L⟩ 
ifnγ⟨L⟩ ifnγr⟨L⟩ stat1⟨M⟩ il4⟨L⟩ il4r⟨L⟩ stat6⟨L⟩ gata3⟨L⟩ socs1⟨L⟩ tbet⟨L⟩

Similarly, we can start with the initial condition process Iˆ, that corresponds to the state (H, H, H, L, L, L, L, L, L, L, L) and that it is specified as above. The computation will lead us to have the output tuple, corresponding to the state (H, H, H, H, H, H, L, L, L, L, L) and, in turn, to the sequence of tuples that correspond to the following sequence of



κ(G)(є, ..., є) ⊇ {(L, L, H, L, L, L, L, L, L, L, L, L, L, L, L, L, L), (L, L, H, L, L, H, L, L, L, L, L, L, L, L, L, L, L),
(L, L, H, L, L, H, L, L, L, L, M, L, L, L, L, L, L)}
κ(G)(L, L, H, L, L, L, L, L, L, L, L, L, L, L, L, L, L) ⊇ {(L, L, H, L, L, H, L, L, L, L, L, L, L, L, L, L, L)}
κ(G)(L, L, H, L, L, H, L, L, L, L, L, L, L, L, L, L, L) ⊇ {(L, L, H, L, L, H, L, L, L, L, M, L, L, L, L, L, L)}




Table 8
Some of the CFA Results of the Case Study
tuples: (H, H, H, H, H, H, H, H, L, L, M ), (H, H, H, H, H, H, H, H, H, L, M ),
(H, H, H, H, H, H, H, H, H, H, M ) and finally to the tuple (H, H, H, H, H, H, H, H, H, H, H).
Now we apply the CFA to the first composed system Sys  I. Some of the results are reported in Table 8.
Verifying model consistency
We have performed a set of in silico experiments to verify whether our model is consistent with the corresponding specification presented in [18]. To this aim, we have tested the capability of our model of reproducing peculiar features of the described network, such as the characterisation of attractors, in particular of stable states. In [18] the authors identified four stable states and associated to each of them a biological counterpart. In our framework these states can be represented as
(L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L)
(L, L, L, L, L, L, L, L, H, M, M, L, L, L, L, H, H)
(L, L, L, L, L, L, L, L, M, M, M, L, L, L, L, H, M )
(L, L, L, L, L, L, L, L, L, L, L, H, H, H, H, L, L)
where (1) corresponds to the observed state of the Th0 cell, both (2) and (3) cor- respond to the observed state of the Th1 cell, and (4) corresponds to the observed state of the Th2 cell.
For all the four cases depicted above, we applied our analysis assuming each stable state as an initial state. We found that no other state can be reached, consistently with [18]. To further verify the viability of our model, we repeated this kind of experimentation on the attractors identified in [18] when models of mutants Th1/Th2 lymphocytes are analysed. These mutant cells exhibit different combinations of null mutations or over activation of some genes resulting in the hypo or hyper production of the corresponding proteins. In our specifications (following [18]) these two kind of mutations are rendered setting to H or L respectively the levels of the proteins codified by the mutated genes. We tested all the 35 mutants considered in [18] and we found that our model is able to describe all the 110 stable states identified for mutants.
Gaining Insights on the studied network
We are now interested in clarifying the role played by the combined effect of the Interleukins IL-12 and IL-18 and of the Interferon-β (IFN -β) on the intracellu-



Table 9
Dependence Table of STAT -1 on the Initial Values of IL-12 IL-18 IFN -β

lar molecule STAT -1, which is crucial in the intracellular network involved in the Th differentiation process. Monitoring STAT -1 levels allows us to obtain informa- tion on the global activation state of the pathway. We performed a set of in silico experiments starting from different initial conditions, corresponding to the follow- ing states: (L, L, H, L, L, L, L, L, L, L, L, L, L, L, L, L, L), (H, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L),
(H, H, L, L, L, L, L, L, L, L, L, L, L, L, L, L, L), and also (H, L, H, L, L, L, L, L, L, L, L, L, L, L, L, L, L),
(H, H, H, L, L, L, L, L, L, L, L, L, L, L, L, L, L).
From a biological point of view, setting these “initial states” corresponds to in- vestigate the behavior of the network, when different experimental conditions are applied. The initial conditions processes specified above, correspond to experiments in which the concentrations of IL-12, IL-18 and IFN -β are initially set to the val- ues Low or High in different combinations.
For the sake of space, we will not show here all the traces of the computations. We just report a summary table in Table 9, representing how STAT -1 depends on the combinations of IL-12 IL-18 IFN -β values. Applying our CFA to the different obtained systems, we can observe that there are pathways that allow STAT -1 to reach either Medium or High concentration values. From a closer observation of the pathways verifying this property, it turns out an important insight on the relative role of IFN -β w.r.t. IL-12 or IL-18. In particular it can be noticed that the initial concentration value of IFN -β is important in determining the final concentration level of STAT -1, only when IL-12 or IL-18 are both Low. Instead, when the con- centrations of IL-12 and IL-18 are High, IFN -β can be either Low or High, without changing the value of STAT -1.

Conclusions
Using Generalised Boolean Networks to model regulatory networks presents some disadvantages, mainly due to the low number of analysis tools and to the diffi- culty in handling incomplete or inconsistent data. To overcome these limitations, we have relied on the process algebraic framework. We have indeed translated the logical models in terms of Sim-πn, a novel process algebra. As a result, we have obtained process models which show the same behavior of the original GBNs and that are ready to be analysed with the usual process algebraic tools. In particu- lar, we have applied Control Flow Analysis to the process algebraic specifications, therefore gaining insights on the studied biological system, while paying a low com-

putational cost. We have showed these features through a case study represented by the regulatory network underlying Th lymphocytes differentiations. In particular, we have investigated the role played by the genes composing the network in deter- mining the final state of the system under different experimental conditions. This example have showed how our toolkit can be fruitfully exploited to assess interest- ing properties of biological systems. Our method could be particularly useful in the analysis of large GBN models (e.g. whole cell models). Even when partial biological knowledge is available, exploiting both Sim-πn and CFA allows us to design and study realistic models of biological systems i.e. models which are consistent with the observed behavior of their biological counterparts. We are planning to use our framework for describing and analysing large-scale models of biological networks, such as cross-talking signalling pathways. Furthermore, we intend to analyse the expressive power of Sim-πn, as done in [17].

References
H. K. Abbas, A. K. Lichtman, S. Pillai. Cellular and molecular immunology, 7th edition Elsevier- Saunders, 2009.
R. M. Amadio, F. Dabrowski. Feasible reactivity in a synchronous Pi-calculus. Proc. of the 9th International ACM SIGPLAN Conference on Principles and Practice of Declarative Programming (PPDP’07), ACM, 2007.
C. Bodei, P. Degano, F. Nielson, H. Riis Nielson. Static analysis for the π-calculus with applications to security. Information and Computation 168(1): 68–92, 2001.
C. Bodei, P. Degano, C. Priami. Checking security policies through an enhanced Control Flow Analysis
Journal of Computer Security 13(1): 49-85, 2005.
L. Cardelli. Brane Calculi - Interactions of Biological Membranes. Proc. of Computational Methods in Systems Biology (CMSB’04). Lecture Notes in Computer Science 3082, pp. 257-278, Springer, 2005.
L. Cardelli and A. D. Gordon. Mobile Ambients. Theoretical Computer Science 240(1): 177-213 (2000).
C. Chaouiya, A. Naldi, E. Remy, D. Thieffry. Petri net representation of multi-valued logical regulatory graphs Natural Computing 10(2): 727-750, 2011.
D. Chiarugi, P. Degano, R. Marangoni. A Computational Approach to the Functional Screening of Genomes. PLoS Computational Biology 3(9), 2007.
V. Danos, Jean Krivine. Transactions in RCCS. Proc. of Conference on Concurrency Theory (CONCUR’05). Lecture Notes in Computer Science 3653, pp. 398-412, Springer 2005.
V. Danos, C. Laneve. Graphs for Core Molecular Biology. Proc. of Computational Methods in Systems Biology (CMSB’03). Lecture Notes in Computer Science 2602, pp. 34-46, Springer 2003.
V. Danos, J. Feret, W. Fontana, R. Harmer, J. Krivine. Rule-based modelling of cellular signalling. Proc. of Conference on Concurrency Theory (CONCUR’07). Lecture Notes in Computer Science, Springer, 2007.
H. de Jong. Modeling and simulation of genetic regulatory Systems : A literature review. Journal of Computational Biology, 9(1):69-105, 2002.
J. Fisher, T. A. Henzinger. Executable cell biology. Nature Biotechnology 25(11), 2005.
P. Goss, J. Pecked. Quantitative modeling of stochastic systems in molecular biology by using stochastic Petri Nets. Proc. Natl Acad. Sci. USA 95, 1998.
R. Hofestadt, S. Helen. Quantitative modeling of biochemical networks. In Silico Biology 1, 1998.
S.A. Kauffman. The Origins of Order: Self-Organization and Selection in Evolution. Oxford University Press, New York, 1993.
C. Laneve, A. Vitale. The Expressive Power of Synchronizations. Proc. of Logic in Computer Science (LICS 2010), pag. 382-391.
L. Mendoza. A network model for the control of the differentiation process in Th cells. BioSystems 84:101-114, 2005
R. Milner. Communicating and mobile systems: the π-calculus. Cambridge University Press, 1999.
R. Milner. Communication and Concurrency. Prentice-Hall, 1989.
H. R. Nielson and F. Nielson. Flow logic: A multi-paradigmatic approach to static analysis. In The Essence of Computation, Lecture Notes in Computer Science 2566, pp. 223–244. Springer, 2002.

C. Priami and P. Quail. Beta-binders for Biological Interactions. Proc. of Computational Methods in Systems Biology (CMSB’04), Lecture Notes in Computer Science 3380, pp. 20–33, Springer, 2005.
C. Priami, A. Regev, E. Y. Shapiro, W. Silverman. Application of a stochastic name-passing calculus to representation and simulation of molecular processes. Inf. Process. Lett. 80(1): 25-31 (2001).
A. Regev, E. M. Panina, W. Silverman, L. Cardelli, and E. Y. Shapiro. BioAmbients: An abstraction for biological compartments. Theoretical Computer Science 325(1): 141-167. Elsevier, 2004.
A. Regev, W. Silverman, E. Y. Shapiro. Representation and Simulation of Biochemical Processes Using the Pi-Calculus Process Algebra. Pacific Symposium on Biocomputing, pp. 459-470, 2001.
W. Reisig. Petri Nets: an Introduction. Springer-Verlag, 1985.
L. J. Steggles, R. Banks and A. Wipeout. Modelling and Analysing Genetic Networks: From Boolean Networks to Petri Nets. Proc. of Conference on Computational Methods in Systems Biology (CMSB’06), Lecture Notes in Computer Science 4210, Springer, 2006.
L. J. Steggles, R. Banks and A. Wipeout. An Abstraction Theory for Qualitative Models of Biological Systems. Proc. of Membrane Computing and Biologically Inspired Process Calculi (MeCBIC’10), Electronic Proceedings in Theoretical Computer Science 40: 23-38, 2010.
D. Thieffry, R. Thomas. Qualitative Analysis of Gene Networks. Pacific Symposium on Biocomputing, 3: 77-88, 1998.
R. Thomas. Regulatory networks seen as asynchronous automata: A logical description. Journal of Theoretical Biology, 153:1-23,1991.
R. Thomas. The Role of feedback circuits: positive feedback circuits are a necessary condition for positive real eigenvalues in the jacobian matrix. Physical Chemistry, 98 (1148), 1994.
R. Thomas, D. Thieffry, and M. Kaufman. Dynamical behavior of biological regulatory networks: I. Biological role of feedback loops and practical use of the concept of the loop-characteristic state. Bull. Math. Biol. 57(2), 247-276, 1995.
R. Thomas and R. D’Ari. Biological Feedback. CRC Press, Boca Raton, Florida, 1990.
