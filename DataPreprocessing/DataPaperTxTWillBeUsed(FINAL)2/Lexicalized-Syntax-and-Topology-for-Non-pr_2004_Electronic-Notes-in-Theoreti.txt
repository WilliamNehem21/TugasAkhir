Electronic Notes in Theoretical Computer Science 53 (2004)
URL:  http://www.elsevier.nl/locate/entcs/volume53.html  11 pages

Lexicalized Syntax and Topology
for Non-projective Dependency Grammar

Denys Duchier 1
Programming Systems Lab Universita¨t des Saarlandes Saarbru¨cken, Germany


Abstract
We propose a lexicalized formulation of dependency grammar that addresses both immediate dependence and linear precedence. Our approach distinguishes two orthogonal, yet mutually constraining dependency trees: an ID tree of syn- tactic dependencies and a LP tree of topological dependencies. The ID tree is non-ordered, non-projective and its edges are labeled by grammatical functions. The LP tree is ordered and projective and expresses licensed linearizations; its edges are labeled by topological fields. The LP tree can be regarded as deriving from the ID tree through a process of emancipation controlled by lexicalized con- straints and principles. In the present article, we formalize valid ID/LP analyses and show how they can be characterized as the solutions of a constraint satisfac- tion problem. The latter can be solved by constraint programming and forms the basis of our implementation.



Introduction
We propose a lexicalized formulation of dependency grammar which ex- tends the non-projective account of syntax of [3] with an account of linear precedence inspired by the classical model of topological fields [1]. In this framework, an analysis consists of two mutually constraining trees: a tree of syntactic dependencies (ID tree) and a tree of topological dependencies (LP tree). The ID tree is non-ordered and non-projective, and its edges are labeled by syntactic relations. The LP tree is partially ordered and projec- tive, and its edges are labeled by topological fields. The shape of the LP tree is a flattening of the ID tree’s obtained by an emancipation process al- lowing nodes to ‘climbup’. Our theory is formulated in term of lexicalized

1 Email: duchier@ps.uni-sb.de
◯c 2004 Published by Elsevier Science B. V. Open access under CC BY-NC-ND license.


constraints and of principles governing climbing conditions. In [4], we described its application to an account of word-order phenomena in the German verbcomplex. In the present article, we focus on its formalization and state a formal well-formedness condition that precisely characterizes the valid analyses. Furthermore, this condition can also be interpreted as a constraint program and forms the basis of our implementation.

Dependency Trees for Syntax and Topology
Consider the sentence:
(dass) Maria	einen Mann wird lieben ko¨nnen

(that) Marianom a manacc
will
love
can

The corresponding syntax tree (ID tree) is shown in Figure 1. This tree is unordered and non-projective. Its edges are labeled by grammatical func- tions such as subject or object.
We associate with it a topological tree (LP tree) ordered and projective, which is formed from the same set of nodes, but different edges. The edges of the LP tree are labeled by topological fields. One ID tree may give rise to several LP trees: Figure 2 displays 3 possibilities for the ID tree of Figure 1. The edge labels of the LP tree are called (external) fields and are totally ordered: df ≺ mf ≺ vc ≺ xf. This induces a linear precedence among the daughters of a node. This precedence is partial because daughters with the same field label may be freely permuted (which is the basis of our
account of scrambling in the Mittelfeld).
In order to fully linearize a LP tree, each node must also be positioned with respect to its daughters. We achieve this by additionally assigning a label (d, n, or v) to each node. These are called internal fields; in Figure 2 they are shown on the vertical dotted lines joining a node to the word it stands for in the sentence. It is the combined set of internal and external fields which is totally ordered: df ≺ d ≺ n ≺ mf ≺ vc ≺ xf
For an edge w−−`→w0 in the ID tree, we say that w is the head of w0 . For a similar edge in the LP tree, we say that w is the host of w0 or that w0 lands on w. The shape of the LP tree is a flattened version of the ID tree’s obtained by an emancipation process allowing nodes to ‘climb up’ subject to the following principles:
Principle 1. A node must land on a transitive head, 2 i.e. its host in the LP tree must be an ancestor in the ID tree.
Principle 2. A node may not climbthrough a barrier, i.e. none of its ID an- cestors up to (but not including) its host may block its emancipation. We consider only a simple version, where a node can block a set of syntactic relations.

2 This is Bro¨cker’s terminology.













Fig. 1. Syntactic Dependency Tree

























Fig. 2. Topological Dependency Trees

Principle 3. A node must land on, or climb higher than its head. The intuition here is that when a node climbs, it takes its entire subtree along.

Labeled Trees
In this section we review the formalization of finite labeled trees presented in [3] and characterize the trees which can be formed from a finite set V of nodes and a finite set L of edge labels as the solutions of a constraint satisfaction problem.


  ID(V; L) ≡
V = roots    {daughters(w) | w ∈ V }
∧	|roots| = 1 
∧ ∀w ∈ V
eqdown(w) = {w} down(w)
∧	down(w) = ∪{eqdown(w0) | w0 ∈ daughters(w)}
∧	equp(w) = {w} up(w)
∧	up(w) = ∪{equp(w0 ) | w0 ∈ mothers(w)}
∧ daughters(w) = {`(w) | ` ∈ L}
∧ mothers(w) ⊆ V  ∧ |mothers(w)|≤ 1
∧ ∀w0 ∈ V	w0 ∈ daughters(w) ≡ w ∈ mothers(w0)
Fig. 3. Well-formedness condition of labeled trees
We assume given an infinite set of node variables V and a finite set of edge labels L. We write G(V; L) for the set of finite graphs G = (V; E) formed from a finite set of nodes V ⊆ V and the set of labeled edges E ⊆
V × V × L. Note that, since we assume E to be a set, we only consider graphs without duplicate edges. We write G(V; L) for the graphs in G(V; L) whose node set is V .
A finite graph G is a tree whenever it satisfies the following conditions:
(a) each node has at most one incoming edge, (b) there is precisely one node (the root) with no incoming edge, (c) there are no cycles. We write T(V; L) for the subset of G(V; L) satisfying these conditions and T(V; L) for the trees in T(V; L) whose node set is V . We are going to formulate a condition ID(V; L) which a finite graph G = (V; E) ∈ G(V; L) must satisfy in order to be in T(V; L).
We write w−−`→w0 for a directed labeled edge (w; w0; `) and w−−`→ w0 for
w−−`→w0 ∈ E. We define the successor relation → = ∪{−−`→	| ` ∈ L} and

write →+ and →  for its transitive and reflexive transitive closures, ← 
for

G	G	G
the transpose of →  and ⊥  for the negation of →  ∪ ←  . Given a relation
G	G	G	G
R ⊆ V × V , we define functions R; R  1 : V  → 2V  and the overloading
R : 2V → 2V as follows:
R(x) = {y | (x; y) ∈ R}  R  1(y) = {x | (x; y) ∈ R}  R(S) = ∪{R(x) | x ∈ S}
In this manner, the edges of a labeled graph G induce the following func- tions:


`G = −−`→G
downG
= →+
 

daughtersG = →G	eqdownG = →G

mothersG
= daughters 1
upG
= down 1

rootsG
= V \ →G(V )	equpG
= eqdown 1

Given these definitions and the treeness conditions (a), (b) and (c), we for-


mulate, in Figure 3, a condition  ID(V; L) which a finite graph G=(V; E) ∈ G(V; L) must satisfy to be in T(V; L). This forms a constraint satisfac- tion problem (CSP) expressed in terms of variable roots of type 2V and functional variables down, eqdown, up, equp, mothers, daughters and ` (for all
` ∈ L) of type V → 2V . T(V; L) is in bijection with the solutions of   (V; L).

Configuration Lexicon
We now introduce the notion of a configuration lexicon and define the set of labeled trees which it licenses. A configuration lexicon (Lex; valency; labels) for T(V; L) consists of a finite set Lex of variables, called lexical entries, and two functions: valency : Lex →L → 2N , and labels : Lex → 2L.
An attributed tree is a triple (V; E;  ) where (V; E) ∈ T(V; L) and   :
V → Lex assigns a lexical entry to each of its nodes. It is well-configured if it satisfies:

valency( (w))(`) restricts the licensed number of w’s out-going `-edges. There- fore, valency( (w)) represents a constraint on the edges offered by w. Con- versely labels( (w0)) is a restriction on the in-coming edges accepted by w0 .
We write T(V; L; Lex | valency; labels) for the set of well-configured Lex- attributed finite trees with L-labeled edges, and  LEX (V; L; Lex | valency; labels) for the conjunction of  ID(V; L) with (1–2); this is again a CSP with the ad- ditional functional variable .

Linear Precedence Trees
We assume given a finite set of edge labels LLP/E, a finite set of node labels
LLP/N, and a total order ≺ on their disjoint union LLP:
LLP = LLP/E  LLP/N = {`1;::: ; `n}	`1 ≺ `2 ≺ ··· ≺ `n
A linear precedence tree G = (V; E; I; <) consists of a labeled tree (V; E) ∈ T(V; LLP/E), an assignment I : V → LLP/N of node labels to nodes, and a total order < on V . We say that G is well-ordered if it satisfies the following conditions:
w−−`1→G w1 ∧ w−−`2→G w2 ∧ `1 ≺ `2	⇒	w1 < w2	(3)
w1 ⊥G w2 ∧ w1 →G w1 ∧ w2 →G w2 ∧ w1 < w2	⇒	w1 < w2	(4)


We say that S ⊆ V is <-convex in V , and write convex(S; V; <), iff:
∀w1 ; w2 ∈ S; ∀w3 ∈ V	w1 < w3 < w2  ⇒ w3 ∈ S
We say that G is projective iff:
∀w ∈ V	convex(eqdown(w); V; <)	(7)
We are interested in linear precedence trees which are both projective and well-ordered and write T(V; LLP/E; LLP/N; ≺) for those whose node set is V . Again, we are going to characterize the elements of T(V; LLP/E; LLP/N; ≺) as the solutions of a CSP.
G induces the additional functions proj`  : V → 2V for ` ∈L :


projG
= →G
−−`→G
for ` ∈ LLP/E

proj` (w) = <8
{w} if I(w) = `

for ` ∈ LLP/N

: ∅	otherwise


proj` (w) for ` ∈ L

LP/E
is the set of nodes in the subtrees rooted at w’s `-

daughters. The total order < on V can be extended to a partial order on 2V
as follows:
∀S1 ; S2 ⊆ V; S1 < S2  ≡ ∀w1 ∈ S1; ∀w2 ∈ S2 w1 < w2
The well-ordering conditions (3–6) are satisfied iff the following property holds:
`1	`2
∀` ;` ∈L ; ∀w ∈ V	` ≺ `	⇒ proj  (w) < proj  (w)
1	2	LP	1	2	G	G
The projection proj` (w) at an edge label ` ∈L	satisfies:

G
∀w ∈ V; ∀` ∈ LLP/E
LP/E

projG (w) = ∪{eqdownG

(w0 ) | w0 ∈ `(w)}	(8)

i.e. it is the union of the eqdown-sets of w’s `-daughters. Each node label
`0 ∈ L	induces a function `0 : V → 2V , where `0 (w) is empty except when `0 is the node label I(w) assigned to w, in which case it is {w}:
{w} =  {` (w) | ` ∈ LLP/N}	(9)
w ∈ `0 (w) ≡ I(w) = `0	(10)
Thus the ‘projection’ proj`0 (w) at a node label `0 ∈L	satisfies:

G
∀w ∈ V; ∀` ∈ LLP/N
LP/N

projG(w) = ` (w)	(11)

The well-ordering conditions are succinctly captured by the following equa- tion:
eqdown(w) = proj`1 (w)∪  ··· ∪  proj`n (w)	(12)


which has the declarative semantics of:
eqdown(w) = proj 1 (w)	 proj n (w)
proj 1 (w) <	< proj n (w)

but often allows for stronger inferences. We write LP (V; LLP/E; LLP/N; ≺) for the conjunction of ID(V; LLP/E) with conditions (7–12). This is again a CSP, with the additional predicate variable < and functional variables I and `0

for all `0 ∈ L 
. TLP
(V; L
LP/E
; LLP/N
; ≺) is in bijection with the solutions of

  LP (V; LLP/E; LLP/N; ≺).

Lexicalized Dependency Grammar
A grammar G is given by finite sets of labels LID; LLP/E; LLP/N, a total order ≺ on LLP/E  LLP/N, a lexicon Lex and functions:

valencyID : Lex → LID → 2
N
valency	: Lex →L	→ 2N
LP	LP/E
labels	 : Lex → 2LID labels	: Lex → 2LLP/E labels	 : Lex → 2LLP/N
blocks : Lex → 2LID
(V; EID; ELP; I; <; ) is a valid ID/LP analysis iff it satisfies the conditions below as well as the climbing principles formalized in the next section.
(V; EID;  ) ∈ T(V; LID; Lex | valencyID; labelsID) (V; ELP;  ) ∈ T(V; LLP/E; Lex | valencyLP ; labelsLP/E)
(V; ELP; I; <;  ) ∈ T(V; LLP/E; LLP/N; ≺)
∀w ∈ V	I(w) ∈ labelsLP/N(  (w))

Climbing Principles
In this section, we formalizes our ‘climbing principles’ and show that they too can be expressed in terms of set constraints. Given an ID/LP analysis, we use subscripts ID, resp. LP, to distinguish similar variables in the ID tree, resp. the LP tree. For example, we write mothersID(w) for w’s mothers in the ID tree and mothersLP(w) for its mothers in the LP tree.

Principle 1: A node must land on a transitive head. I.e., w →LP
w0. Principle 1 is satisfied whenever:
w0 ⇒ w →+


mothersLP(w) ⊆ equpID(w)	(13)


Principle 2: a node may not climb through a barrier. We consider in this article only a very simple notion of barrier: a node may be a barrier to specific syntactic relations; we say that it blocks them: e.g. a noun blocks det. The nodes which w must climbthrough are:
through(w) = up (w) ∩ ∪{down (w0 ) | w0 ∈ mothers (w)}  (14) Principle 2 is satisfied whenever:
w00 −−`→w ∈ E  ⇒ ` /∈ ∪{blocks( (w0)) | w0 ∈ through(w)}   (15)
Principle 3: a node must land on, or climb higher than its head. This is satisfied whenever:
up  (w) ⊆ ∪{equp  (w0) | w0 ∈ mothers  (w)}	(16)

Example Grammar
Our example grammar uses the following sets of labels:
LID = {root; sbar; s; det; subj; obj; vinf; vpast; vzu} LLP/E = {df; vf; mf; vc; xf}
LLP/N = {d; n; c; v}
df is the determiner field, vf the Vorfeld, mf the Mittelfeld, vc the verbal complement field, and xf the extraposition field. d is an internal field for determiners, n for nouns, c for verb 1st and 2nd (i.e. the complementizer field), v for verblast. The total order ≺ is:
d ≺ df ≺ n ≺ vf ≺ c ≺ mf ≺ vc ≺ v ≺ xf
Figure 4 contains an example lexicon. For convenience, valencies are de- scribed by sets of wildcarded labels. For example, if valency(e) is described by {`1 ; `2?; `3∗}, this means:
8 {1}	if ` = `1
valency(e)(`) = <> {0; 1}	if ` = `2
{0; 1;::: ; ∞} if ` = `3
:>

Mann accepts ID labels {subj; obj} and offers ID valency {det}: it may be subject or object and requires a unique determiner. It accepts LP labels
{vf; mf}, i.e. it may land either in the Vorfeld or in the Mittelfeld. It offers


a unique field df, for its determiner. Furthermore it blocks ID labels {det}, thus preventing emancipation of its determiner.
For verbs, our grammar distinguishes between coherent (field vc) and extraposed position (field xf). While xf is called the extraposition field, it should not be regarded as uniquely dedicated to the phenomenon of ex- traposition. For example, both Oberfeldumstellung and extraposition are explained here by migration to the xf field. As we previously described in [4], a number of phenomena, such as VP extraposition, partial VP extra- position, optional auxiliary flip, V-projection raising, intermediate place- ment, obligatory auxiliary flip, double auxiliary flip, obligatory coherence can be modeled as emergent from the interaction of our lexicalized con- straints.
A finite verb may appear as head of a verb 1st/2nd sentence (internal field c) in which case it typically offers LP valency {vf?; mf∗; vc?; xf}. It may also appear in a verb last sentence (internal field v) in which case it does not offer vf. Finite verbs block all emancipations.
An infinitive in coherent position offers at most vc. This forces its non- verbal arguments to climb to find a landing place. Only ‘zu’ infinitives can be extraposed, in which case they typically offer {mf∗; vc? xf?} which makes possible full or partial extrapositions.
Ersatzinfinitivs are here modeled as infinitives which can be extraposed.
We have implemented a parser using the formalization described in this article and written a slightly larger grammar than presented here. Our experience so far has been very encouraging and confirms the practical effectiveness of constraint propagation. For example, parsing the sen- tence “daß Maria einen Mann wird lieben ko¨nnen” requires no search. Our parser can also function in a mode where it disregards the linear or- der of its input and instead generates all possible linearizations. Figure 5 shows an example of this applied to the same sentence: the window on the left contains the search tree; the 7 lineralizations are enumerated op- timally (without failures). The window on the right displays one analysis: the ID tree is shown above and the LP treebelow.


Conclusion
We described a lexicalized formulation of dependency grammar where an analysis consists of two mutually constraining trees: a non-ordered non- projective tree of syntactic dependencies (ID tree) and an ordered projec- tive tree of topological dependencies (LP tree). Both trees are subject to similar lexicalized configuration constraints. Additionally the shape of the LP tree is a flattening of the ID tree’s obtained by allowing nodes to climb up subject to 3 principles.
We precisely formalized the well-formedness conditions characteriz-




Fig. 4. Example Lexicon



Fig. 5. Searching for all linearizations of “daß Maria einen Mann wird lieben ko¨nnen” and displaying one specific analysis



ing valid analyses. Furthermore, this formalization can also be regarded as a constraint program and forms the basis of our implementation in Oz.


References


Bech, G., “Studien Kopenhagen, 1955.
u¨ber das deutsche Verbum infinitum,” Munksgaard,

Bro¨ker, N., “Eine Dependenzgrammatik zur Kopplung heterogener Wissens- quellen,” Linguistische Arbeiten 405, Max Niemeyer Verlag, Tu¨bingen, 1999.
Duchier, D., Axiomatizing dependency parsing using set constraints, in: Sixth Meeting on Mathematics of Language, Orlando, Florida, 1999, pp. 115–126.
Duchier, D. and R. Debusmann, Topological dependency trees: A constraint- based account of linear precedence, in: 39th Annual Meeting of the Association for Computational Linguistics (ACL 2001), Toulouse, France, 2001.
Kahane, S., A. Nasr and O. Rambow, Pseudo-projectivity: a polynomially parsable non-projective dependency grammar, in: Proceedings of ACL/COLING ’98, Montre´al, 1998, pp. 646–52.
Kathol, A., “Linearization-Based German Syntax,” Ph.D. thesis, Ohio State University (1995).
Mu¨ller, S., “Deutsche Syntax deklarativ. Head-Driven Phrase Structure Grammar fu¨r das Deutsche,” Linguistische Arbeiten 394, Max Niemeyer Verlag, Tu¨bingen, 1999.
Reape, M., Domain union  and word order  variation in German, in:
J. Nerbonne, K. Netter and C. Pollard, editors, German in Head-Driven Phrase Structure Grammar, CSLI, Stanford/CA, 1994 pp. 151–197.
Uszkoreit, H., “Word Order and Constituent Structure in German,” CSLI, Stanford/CA, 1987.
