

Electronic Notes in Theoretical Computer Science 218 (2008) 261–273
www.elsevier.com/locate/entcs

A Technique for Verifying Measurements

Keye Martin1 and Prakash Panangaden2
Center for High Assurance Computer Systems
U.S. Naval Research Laboratory Washington D.C. 20375 United States of America
School of Computer Science McGill University Montreal, Quebec H3A 2A7 Canada

Abstract
We give a technique that can be used to prove that a given function is a measurement. We demonstrate its applicability by using it to resolve three notoriously difficult cases: capacity in information theory, entropy in quantum mechanics and global time in general relativity. We then show that this technique provides a new and surprising characterization of measurement. Thus, in principle, it can always be used.
Keywords: domain theory, measurement, information theory, quantum mechanics, general relativity


Introduction
The measurement formalism expands the scope of domain theory [6,7] by providing new fixed point theorems, including those which apply to nonmonotonic functions, an informatic derivative for measuring the rate at which a process on a domain converges to a fixed point, methods for deriving distance from content, unified ap- proaches to the continuous and discrete, a first order view of recursion ϕ = δ + ϕ ◦ r which models iteration in its natural state and methods for relating algorithmic complexity to entropy via the structure of a domain.
However, having originally been formulated within the context of computation, it offers few ways to deal with the complexity of the types of functions one routinely encounters in information theory and physics. For example, consider the capacity

1 Email: keye.martin@nrl.navy.mil
2 Email: prakash@cs.mcgill.ca

1571-0661Published by Elsevier B.V. Open access under CC BY-NC-ND license.
doi:10.1016/j.entcs.2008.10.016

of a binary channel





a¯H(b)−¯bH(a)
	






bH(a)−aH(b) 




where C(a, a) := 0 and H(x) = −x log2(x) − (1 − x) log2(1 − x) is the base two entropy. After proving that something like this is strictly monotone [10], should we really have to do any additional work to show that it is a measurement? Well, not only did we have to, but the ‘extra work’ required turned out to be more difficult than proving its strict monotonicity [8]. Even worse, all we get for such an effort is that capacity measures the set of maximal elements.
In physics there is a similar well-known problem: entropy is Scott continuous and strictly monotone on the domain of classical states, but the only places where it has been shown that entropy measures content in the sense of domain theory is, again, the set of maximal elements. Why the recurring theme? Because trying to prove implications like

|μx − μy| < ε & x ± y ⇒ x ∈ U


is simply impossible when μ is a quantity such as entropy or capacity. By impossible, we mean that one looks at the implication and basically feels like it’s a headache they just don’t need.
So this is where things have stood in the study of physics and domain theory for the past six years. We have lots of neat and interesting domains with natural measurements but all that anyone has been able to prove is that these ‘natural mea- surements’ are strictly monotone and measure the set of maximal elements. Some- thing has been missing. Despite the long held intuition that a strictly monotone measurement usually measures the entire domain, this has never once been proven in the context of physics or information theory (except in the case of entropy in two dimensions, and that doesn’t count). In this paper we change that.
This paper identifies the ‘missing technique’ that makes it easy to verify mea- surements in physics and information theory. In essence, it means that any strictly monotone Scott continuous map that “arises in applications” will measure its entire domain. The definition of “applicable” is that the Scott continuous map be continu- ous with respect to a second topology that relates to the Scott topology in a natural way. We apply this technique to show that capacity measures the entire domain of binary channels, entropy measures the set of classical states in its majorization relation and global time functions measure the entire domain of spacetime intervals. The technique is so applicable that it makes one wonder if it can always be applied. We show that in principle the answer to this question is yes – one simply takes the second topology to be the μ topology, so the story comes full circle.

Measurement
In a partially ordered set (poset) (D, ±), we write
↓x := {y ∈ D : y ± x} & ↑x := {y ∈ D : x ± y}
Definition 2.1 For a subset X ⊆ D of a poset D, define


↑X :=
x∈X
↑x &	↓X :=	↓x
x∈X

A subset U ⊆ D of a poset D is Scott open when it is an upper set U = ↑U that is
inaccessible by directed suprema:
. S ∈ U ⇒ S ∩ U /= ∅
for all directed S ⊆ D with a supremum. The collection of Scott open sets on D is denoted σD.
The Scott open sets on a poset form a topology. A subset C ⊆ D is Scott closed when it is a lower set C = ↓C such that S ∈ C for all directed S ⊆ C with a supremum in D.
All of the posets in this paper are continuous; the Scott topology has a simple description in this case:
Definition 2.2 Let (D, ±) be a poset. For elements x, y ∈ D, we write x  y iff for every directed subset S that has a supremum,
y ± . S ⇒ (∃s ∈ S) x ± s.
We set
↓x := {y ∈ D : y   x} & ↑x := {y ∈ D : x   y}
A set B ⊆ D is a basis when B ∩ ↓x is directed with supremum x for each x ∈ D. A poset is continuous when it has a basis.
The Scott topology on a continuous poset has {↑x : x ∈ D} as a basis.
Definition 2.3 A function f : D → E between posets is Scott continuous if the inverse image of a Scott open set in E is Scott open in D.
Scott continuity can be characterized order theoretically: a function f : D → E
between posets is Scott continuous iff f is monotone,
(∀x, y ∈ D) x ± y ⇒ f (x) ± f (y), and preserves directed suprema:
f (. S)= . f (S),
for all directed S ⊆ D with a supremum.

Definition 2.4 A Scott continuous map μ : D → E between posets is said to
measure the content of x ∈ D if
x ∈ U ⇒ (∃ε ∈ σE) x ∈ με(x) ⊆ U,
whenever U ∈ σD is Scott open and
με(x) := μ−1(ε) ∩ ↓x
are the elements ε close to x in content. The map μ measures X if it measures the content of each x ∈ X.
Definition 2.5 A measurement is a Scott continuous map μ : D → E between posets that measures ker μ := {x ∈ D : μx ∈ max(E)}.
The domain E = [0, ∞)∗, the set of nonnegative reals in their dual order, is what interests us most in this paper: in this case, for ε > 0, we define
με(x) := μ[0,ε)(x)= {y ∈ D : y ± x & μy < ε}
and see that a Scott continuous μ : D → [0, ∞)∗ measures the content of x ∈ D
when
x ∈ U ⇒ (∃ε > 0) x ∈ με(x) ⊆ U
for all Scott open U ⊆ D. The map μ is then a measurement when it measures the content of its kernel ker(μ)= {x ∈ D : μx = 0}, the elements with no uncertainty. All such elements are maximal in the information order ± on D.

The technique
Let us consider a lemma that stems from the 2007 Montreal Workshop on domains and causal structure:
Lemma 3.1 For a sequence (xn) in a compact Hausdorff space X, the following are equivalent:
The sequence (xn) converges to x,
For any convergent subsequence (xnk ) of (xn), we have xnk → x.
Proof. (ii) ⇒ (i): if (xn) does not converge to x, then there is an open set U ⊆ X with x ∈ U such that for all k there is nk ≥ k with xnk /∈ U . By compactness of X, (xnk ) has a convergent subsequence (yn). Because (yn) is a subsequence of (xn), we have yn → x by (ii), so eventually yn ∈ U , in contrast to xnk /∈ U .	 
It is difficult to believe that such a lemma could be useful. But in fact:
Theorem 3.2 Let μ : D → [0, ∞)∗ be a strictly monotone, Scott continuous func- tion deﬁned on a poset D. If τ is a Hausdorff topology on D such that
every Scott open set is τ open,

every sequence (xn) in ↓x with μxn → μx is contained in some compact K ⊆↓x,
the function μ is continuous from (D, τ ) to [0, ∞) with the Euclidean topology, then μ measures all of D.
Proof. Let xn ± x with μxn → μx. Take a compact set K with xn ∈ K ⊆↓x. Let (xnk ) be any convergent subsequence of (xn). Let us write xnk → y. Then since K is closed, y ∈ K and hence y ± x. However, since the sequence μxn → μx, we know that μxnk → μx. Since μ is continuous with respect to τ , we get

μy = μ  lim xnk  = lim μxnk = μx

and thus by strict monotonicity, x = y. Then every convergent subsequence of (xn) converges to x and all of this happens in the compact Hausdorff space K. Thus, xn → x in (D, τ ).
If μ does not measure the content of x ∈ D, then there is a Scott open set U ⊆ D and a sequence xn ± x with μxn → μx and xn /∈ U . By our above remarks, xn → x in (D, τ ), and since U is τ open, we have xn ∈ U for all but a finite number of n, which is a contradiction.	 
Notice that the proof above also shows that the previous result holds for maps of the form μ : D → E, where E = R or E = R∗. Here is an important corollary:
Corollary 3.3 Let D be a poset with a compact Hausdorff topology τ that contains the Scott topology. If μ : D → [0, ∞)∗ is Scott continuous, strictly monotone and continuous from (D, τ ) to [0, ∞) with the Euclidean topology, then μ measures D.
Proof. The result follows from Theorem 3.2 if we show that (ii) in its statement holds. But this is true: since all Scott open sets are τ open, every Scott closed set is τ closed and hence τ compact. In particular, the set K = ↓x is compact in τ . 

Capacity
A binary channel has two inputs (“0” and “1”) and two outputs (“0” and “1”). An input is sent through the channel to a receiver. Because of noise in the channel, what arrives may not necessarily be what the sender intended. The effect of noise on input data is modelled by a noise matrix u. If data is sent through the channel according to the distribution x, then the output is distributed as y = x · u. The
noise matrix u is given by
u = ⎛a a¯⎞

where a = P (0|0) is the probability of receiving 0 when 0 is sent and b = P (0|1) is the probability of receiving 0 when 1 is sent and x¯ := 1 − x for x ∈ [0, 1]. Thus, the noise matrix of a binary channel can be represented by a point (a, b) in the unit

square [0, 1]2 and all points in the unit square represent the noise matrix of some binary channel.
The capacity of a binary channel (a, b) is


a¯H(b)−¯bH(a)
		

bH(a)−aH(b) 
	


where C(a, a) := 0 and H(x) = −x log2(x) − (1 − x) log2(1 − x). It measures the maximum possible correlation between input to the channel and output from the channel. Because C(a, b)= C(b, a), we can restrict attention to channels of the form (a, b) with a ≥ b. Such channels are called nonnegative and are denoted
N := {(a, b): a ≥ b & a, b ∈ [0, 1]}
Because N is in 1-1 correspondence with elements of the interval domain
I[0, 1] = {[a, b]: a ≤ b & a, b ∈ [0, 1]}, it inherits an information order given by
(∀x, y ∈ N) x = (a, b) ± (c, d)= y ⇐⇒ [b, a] ± [d, c]
where the order on I[0, 1] is reverse inclusion. The following is proven in [10]:
Theorem 4.1 C: N → [0, 1]∗ is Scott continuous and strictly monotone.
What was far from clear in [10] was whether or not capacity was a measurement. In [8], it was shown that C measured its kernel, but the complexity of the argument prevented its extension to all channels. However, as we shall now see, Theorem 3.2 makes it possible for us to prove that capacity measures the entire interval domain without doing any additional work.
We previously viewed the bijection N  I[0, 1] as a way of transferring domain theoretic structure from I[0, 1] to N. However, we can also view it as a way to transfer topological structure from N to I[0, 1]. Specifically, we topologize I[0, 1] with the Euclidean topology N inherits as a subset of the plane. Thus, we represent I[0, 1] as the region of the unit square below and including the main diagonal.
A basic Scott open set is then a right triangle with two sides removed whose hy- potenuse lies along the diagonal within the unit square. In particular, it is Euclidean open. By Corollary 3.3, any strictly monotone Scott continuous μ : I[0, 1] → [0, ∞)∗ that is also Euclidean continuous (under the identification I[0, 1]  N) must mea- sure I[0, 1]. Since capacity is Euclidean continuous [8] in addition to being Scott continuous and strictly monotone, we have:
Theorem 4.2 Capacity measures all of I[0, 1]   N.
Consider a remarkable corollary of this result: if we define d : I[0, 1] × I[0, 1] → [0, 1]∗ by d(x, y)= C(x H y), then the sets
Bε(x)= {y : d(x, y) < ε}

form a basis for the Scott topology on I[0, 1]. The fact that capacity is a measure- ment also has an interesting consequence for communication.
For a binary channel x = (a, b), its probability of error is
ex(t)= ta¯ + (1 − t)b
where t is the probability that the sender sends ‘0’ through the channel. Intuitively, one expects a relationship between the probability of error and the capacity. For instance, as the probability of error increases, the capacity should decrease. We can actually prove this as follows.
Catuscia Palamidessi communicated to the authors at last year’s Bellairs work- shop that the probability of error is monotone with respect to the order on binary channels in the following sense:
x ± y ⇒ (∀t ∈ [0, 1]) ex(t) ≤ ey(t)
In fact, setting t =0 and t = 1 shows that the converse holds:
(∀t ∈ [0, 1])(ex(t) ≤ ey(t)) ⇒ x ± y
Thus, the interval order on binary channels is exactly the requirement that the probability of error increase for all possible input distributions. By the monotonicity of capacity then, increasing the probability of error will decrease the capacity of a nonnegative channel.
However, because capacity is a measurement, we can also prove an ‘asymptotic converse’: any process that shrinks the capacity of a channel to C(x) in successive stages xn with xn ± x and C(xn) → C(x) must in ﬁnite time generate a channel whose probability of error exceeds ea, for any a  x. Paraphrasing, the only way to shrink the capacity is to increase the probability of error.

Entropy
We now consider another fundamental domain: the set of decreasing classical states


Λn :=

 x ∈ [0, 1]n :
Σi=1

xi =1 & (∀i < n) xi ≥ xi+1

with the majorization relation ≤ given by
x ≤ y ≡ (∀i < n) si(x) ≤ si(y)


where

k
sk(x)=	xi.
i=1

Majorization was discovered by Muirhead in 1903 [13] and over the last one hun- dred years has found impressive applications in areas such as economics, computer

science, physics and pure mathematics [2,5,14]. In [9], it was shown that (Λn, ≤) is a continuous dcpo. Specifically, the straight line path πx : [0, 1] → Λn from the least element ⊥ = (1/n,... , 1/n) to x ∈ Λn,
π(t)= (1 − t)⊥ + tx
is Scott continuous and satisfies π(t)  x for each t < 1.
Lemma 5.1 The approximation relation   on Λn is
x  y ≡ (x = ⊥) or (∀i < n) si(x) < si(y).
Proof. The direction (⇐) is clear. For the other, let x  y and consider πy(t)  y
for t < 1. Take some value of t < 1 such that x ≤ πy(t) ≤ y. Then
i
(∀i) si(x) ≤ si(πy(t)) = n (1 − t)+ t · si(y) ≤ si(y).
If si(y) /= si(πy(t)) for all i < n, then si(x) < si(y) for all i < n, and the proof is done. Otherwise, there is some i < n with si(y)= si(πy(t)). Since t < 1, we have si(y)= i/n. We claim that this implies that y = ⊥ as follows.
First, because y is decreasing, i/n = si(y) ≥ iyk for all k ≥ i. Then yk ≤ 1/n for k ≥ i. We then must have yi+1 = 1/n since yi+1 < 1/n implies


i
1= sn(y) < si(y)+ (n − i)yi+1 < n +
n − i
=1 
n

But if yi+1 = 1/n, then si+1(y)= si(y)+ yi+1 = (i + 1)/n, so by the argument we just gave, yi+2 = 1/n. Then we see by induction that yj = 1/n for all j ≥ i + 1.
We have already seen that yi ≤ 1/n. Since yi ≥ yi+1 = 1/n, we have yi = 1/n. That is, whenever si(y)= i/n, we have yi = 1/n. But then si−1(y)= si(y) − yi = (i − 1)/n, which then gives yi−1 = 1/n. Again by induction, yj = 1/n for all j ≤ i. Putting everything together, y = ⊥, and since x ≤ y, we have x = ⊥.	 
Lemma 5.2 Each Scott open subset of (Λn, ≤) is Euclidean open.
Proof. Let y ∈ ↑x in (Λn, ≤) with yk → y in the Euclidean topology. We want to show that all but a finite number of the yk belong to ↑x. If x = ⊥, then this is clearly true, so assume that x /= ⊥. By Lemma 5.1, si(x) < si(y) for all i < n. By the euclidean continuity of the function si : Λn → [0, 1], there is Ki such that k ≥ Ki ⇒ si(x) < si(yk). Setting K = max Ki, we see that
k ≥ K ⇒ (∀i < n) si(x) < si(yk)
By Lemma 5.1, x  yk for k ≥ K, which proves that yk → y in the Scott topology and hence that all Scott open sets are Euclidean open.	 
Corollary 5.3 If μ : Λn → [0, ∞)∗ is strictly monotone and Euclidean continuous, then μ measures Λn.

Proof. Any function Λn → [0, ∞)∗ that is monotone and Euclidean continuous must be Scott continuous. By Corollary 3.3 and Lemma 5.2, the result follows. 
In particular, this is true of entropy:
Example 5.4 Shannon entropy H : Λn → [0, ∞)∗ given by
n
H(x)= −	xi log2(xi)
i=1
is Euclidean continuous. Its monotonicity with respect to majorization, sometimes also called Schur concavity, is well-known [5]. On page 71 of [5] it is also shown that H(x) > H(y) whenever x ≤ y and x is not a permutation of y. This implies its strict monotonicity on Λn as follows.
Let x, y ∈ Λn satisfy x ≤ y and x /= y. Then we claim that x is not a permutation of y. For if x = y · σ ∈ Λn for some permutation σ ∈ S(n), then y = y · σ, since rearranging the elements of y by σ merely puts them into decreasing order when they are already in decreasing order. This gives x = y, which is a contradiction. Thus, if x < y on Λn, then H(x) > H(y). By 5.3, entropy measures all of (Λn, ≤).
Finally, the argument above shows that any Euclidean continuous, strictly Schur concave function on Λn measures all of Λn. Such functions provide important ex- amples of entanglement monotones.

Time
A manifold M is a locally Euclidean Hausdorff space that is connected and has a countable basis. Such spaces are paracompact. A Lorentz metric on a manifold is a symmetric, nondegenerate tensor field of type (0, 2) whose signature is (− + ++).
Definition 6.1 A spacetime is a real four-dimensional 3 smooth manifold M with a Lorentz metric gab.
Let (M, gab) be a time-orientable spacetime. Let Π+ denote the future directed

causal curves, and Π+
denote the future directed time-like curves.

Definition 6.2 For p ∈ M,
I+(p) := {q ∈ M : (∃π ∈ Π+ ) π(0) = p, π(1) = q}


and
J+(p) := {q ∈ M : (∃π ∈ Π+) π(0) = p, π(1) = q}

Similarly, we define I−(p) and J−(p).
We write the relation J+ as
p ≤ q ≡ q ∈ J+(p).

3 The results in the present paper work for any dimension n ≥ 2 [4].

We always assume the chronology conditions, which ensure (M, ≤) is a partially ordered set, and strong causality, which is equivalent [15] to saying that the sets
{I+(p) ∩ I−(q): p, q ∈ M} form a basis for a Hausdorff topology. This topology must then be the manifold topology [15]. Penrose has called globally hyperbolic spacetimes “the physically reasonable spacetimes [17].”
Definition 6.3 A spacetime M is globally hyperbolic if it is strongly causal and if
↑a ∩ ↓b is compact in the manifold topology, for all a, b ∈ M.
Definition 6.4 A continuous poset (P, ≤) is bicontinuous if
For all x, y ∈ P , x   y iff for all filtered S ⊆ P with an infimum,
  S ≤ x ⇒ (∃s ∈ S) s ≤ y,
and
For each x ∈ P , the set ↑x is filtered with infimum x. So for instance, R and Q are bicontinuous.
Definition 6.5 On a bicontinuous poset P , sets of the form
(a, b) := {x ∈ P : a  x  b}
form a basis for a topology called the interval topology.
The following result is proven in [11]:
Theorem 6.6 If M is globally hyperbolic, then (M, ≤) is a bicontinuous poset with
  = I+ whose interval topology is the manifold topology.
This result motivates the following definition:
Definition 6.7 A poset (X, ≤) is globally hyperbolic if it is bicontinuous and each interval [a, b]= {x : a ≤ x ≤ b} is compact in the interval topology.
A well-known domain theoretic construction pertaining to the real line extends in perfect form to the globally hyperbolic posets [11]:
Theorem 6.8 The closed intervals of a globally hyperbolic poset X
IX := {[a, b]: a ≤ b & a, b ∈ X}
ordered by reverse inclusion
[a, b] ± [c, d] ≡ [c, d] ⊆ [a, b]
form a continuous dcpo with
[a, b]   [c, d] ≡ a   c & d   b.

The poset X has a countable basis iff IX is ω-continuous. Finally,
max(IX)  X
where the set of maximal elements has the relative Scott topology from IX.
This natural domain theoretical model of spacetime can be used to explain why it can be reconstructed from certain countable collections of events [12]. A global time function t : M → R on a globally hyperbolic spacetime M is a continuous function such that x < y ⇒ t(x) < t(y) and such that t−1(r) = Σ is a Cauchy surface for M for each r ∈ R. Notice that we write x < y ≡ x ≤ y & x /= y.
Theorem 6.9 For any global time function t : M → R on a globally hyperbolic spacetime, the function Δt : M → [0, ∞)∗ given by Δt[a, b]= t(b) − t(a) measures all of I(M). It is a measurement with ker(Δt)= max(I(M)).
Proof. The function Δt inherits its monotonicity from that of t; it is Scott con- tinuous because t is continuous with respect to the manifold topology and directed suprema in I(M) are calculated using limits in the manifold topology. To prove that Δt measures I(M), we will show that t measures the continuous poset (M, ≤) and that it also measures (M, ≤∗), whose order ≤∗ is given by x ≤∗ y ≡ y ≤ x.
We apply the remark following Theorem 3.2 to t : M → R as follows. (i) The Scott topology is contained in the manifold topology. (ii) Given any sequence xn ≤ x with txn → tx, we have xn ∈ J+(Σ)∩J−(x) ⊆↓x for some Σ = t−1(r), where r exists because (txn) has a limit and the set J+(Σ) ∩ J−(x) is compact [17]. By the remark after Theorem 3.2, t measures (M, ≤). Because (M, ≤) is bicontinuous, t : (M, ≤∗) → R∗ measures the continuous poset (M, ≤∗), again by the remark after Theorem 3.2.	 
What is so interesting about this proof is that in order to apply Theorem 3.2, we not only need continuity, strict monotonicity and the connection between causal structure and topology, we also make use of the Cauchy surface Σ, the latter of which implies that spacetime has an initial value formulation.

The converse
In principle, the technique used to verify measurements in the cases of capacity, entropy and global time can always be used:
Theorem 7.1 If μ measures a poset D, then μ is strictly monotone and there is a Hausdorff topology τ such that
every Scott open set is τ open,
every sequence (xn) in ↓x with μxn → μx is contained in some compact K ⊆↓x,
the function μ is continuous from (D, τ ) to [0, ∞) with the Euclidean topology,
Thus, μ measures D iff it is strictly monotone, Scott continuous and there is a Hausdorff topology τ on D which satisﬁes (i)–(iii).

Proof. The strict monotonicity is proven in [6]. We take τ to be the topology with
B := {U ∩ V : U Scott open,V Scott closed}
as a basis. To see that B is in fact a basis: each point of D is contained in D ∈ B and B is closed under finite intersections, a property it inherits from the collections of Scott open and Scott closed sets, respectively. We call τ the μ topology. Let us now show that it is a Hausdorff topology satisfying (i), (ii) and (iii).
The collection B contains all Scott open sets (take V = D) and all Scott closed sets (take U = D). Thus, every Scott open set is both open and closed in τ , and the same is true of every Scott closed set. This implies that τ is Hausdorff: given distinct x, y ∈ D, we must have x /± y or y /± x; assuming y /± x, the sets U = ↓x and V = D\↓x are disjoint clopen sets that separate x and y. Thus, the μ topology is zero dimensional Hausdorff and contains the Scott topology.
Let xn ± x with μxn → μx. We claim that xn → x in the μ topology as follows. Given any basic μ open set U ∩ V that contains x, with U Scott open and
V Scott closed, there is ε > 0 with
x ∈ με(x)= μ−1([0, ε)) ∩ ↓x ⊆ U
Because x ∈ V and V = ↓V is Scott closed, ↓x ⊆ V . Then x ∈ με(x) ⊆ U ∩ V . Since μxn → μx < ε, we have xn ∈ με(x) ⊆ U ∩ V for all but a finite number of n, which implies xn → x in the μ topology. Then the required compact set is K = {xn}∪ {x} ⊆ ↓x.
Let x ∈ μ−1((a, b) ∩ [0, ∞)). The set [0, b) is Scott open in [0, ∞)∗, so its inverse image is Scott open and contains x. Since μ measures D, there is ε > 0 with
x ∈ με(x) ⊆ μ−1([0, b)).
Since με(x) is open in the μ topology (as the intersection of a Scott open and Scott closed set) and x ∈ με(x) ⊆ μ−1((a, b) ∩ [0, ∞)) by monotonicity of μ, we have that μ is continuous as a function from the μ topology to the Euclidean topology. 

Acknowledgement
The first author thanks the second author for being a great friend and collaborator. The second author reciprocates by offering the first a lifelong invitation to his yearly workshop at the Bellairs Research Institute in Barbados. The first author gratefully accepts this invitation.

References
S. Abramsky and A. Jung. Domain theory. In S. Abramsky, D. M. Gabbay, T. S. E. Maibaum, editors, Handbook of Logic in Computer Science, vol. III. Oxford University Press, 1994.
P. M. Alberti and A. Uhlmann. Stochasticity and partial order: doubly stochastic maps and unitary mixing. Dordrecht, Boston, 1982.

K. Chatzikokolakis and K. Martin. A monotonicity principle for information theory.
P. S. Joshi. Global aspects in gravitation and cosmology. International Series of Monographs on Physics
87. Oxford Science Publications, 1993.
A.W. Marshall and I. Olkin. Inequalities: theory of majorization and its applications. Academic Press, 1979.
K. Martin. A foundation for computation. PhD Thesis, Tulane University, Department of Mathematics, 2000.
K. Martin. Domain theory and measurement. Lecture Notes in Physics, Springer-Verlag, 2008, to appear.
K. Martin. Topology in information theory in topology. Theoretical Computer Science, to appear.
K. Martin. Entropy as a fixed point. Theoretical Computer Science, Vol. 350, Issue 2, 2006.
K. Martin, I. S. Moskowitz and G. Allwein. Algebraic information theory for binary channels. Electronic Notes in Theoretical Computer Science, Volume 158, p. 289–306, 2006.
K. Martin and P. Panangaden. A domain of spacetime intervals in general relativity. Communications in Mathematical Physics, 267(3):563–586, November 2006.
K. Martin and P. Panangaden. Domain theory and general relativity. Lecture Notes in Physics, Springer- Verlag, 2008.
R. F. Muirhead. Some methods applicable to identities and inequalities of symmetric algebraic functions of n letters. Proc. Edinburgh Math. Soc., 21:144-157, 1903.
M. A. Nielsen and G. Vidal. Majorization and the interconversion of bipartite states. Quantum Information and Computation, Vol. 1, No. 1, p. 76–93, 2001.
R. Penrose. Techniques of differential topology in relativity. Society for Industrial and Applied Mathematics, 1972.
C. E. Shannon. A mathematical theory of communication. Bell Systems Technical Journal, 27:379–423, 623–656, 1948.
R.M. Wald. General relativity. The University of Chicago Press, 1984.
