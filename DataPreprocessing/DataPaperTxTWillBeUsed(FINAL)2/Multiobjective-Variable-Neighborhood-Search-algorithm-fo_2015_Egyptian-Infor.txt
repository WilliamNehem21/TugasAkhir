
ORIGINAL ARTICLE
Multiobjective Variable Neighborhood Search algorithm for scheduling independent jobs on computational grid

S. Selvi a,*, D. Manimegalai b,1

a Department of Electronics and Communication Engineering, Dr. Sivanthi Aditanar College of Engineering, Tiruchendur 628215, Tamil Nadu, India
b Department of Information Technology, National Engineering College, Kovilpatti 628503, Tamil Nadu, India

Received 9 April 2014; revised 25 April 2015; accepted 1 June 2015
Available online 25 June 2015

Abstract Grid computing solves high performance and high-throughput computing problems through sharing resources ranging from personal computers to super computers distributed around the world. As the grid environments facilitate distributed computation, the scheduling of grid jobs has become an important issue. In this paper, an investigation on implementing Multiobjective Variable Neighborhood Search (MVNS) algorithm for scheduling independent jobs on computa- tional grid is carried out. The performance of the proposed algorithm has been evaluated with Min–Min algorithm, Simulated Annealing (SA) and Greedy Randomized Adaptive Search Procedure (GRASP) algorithm. Simulation results show that MVNS algorithm generally performs better than other metaheuristics methods.
© 2015 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.
org/licenses/by-nc-nd/4.0/).


Introduction




* Corresponding author. Tel.: +91 8903484336; fax: +91 4639
243188.
E-mail addresses: mathini31@yahoo.co.in (S. Selvi), megalai_nec@ yahoo.co.in (D. Manimegalai).
1 Tel.: +91 9442636698; fax: +91 4632 232749.
Peer review under responsibility of Faculty of Computers and Information, Cairo University.


http://dx.doi.org/10.1016/j.eij.2015.06.001
Grid computing is a form of distributed computing that involves coordinating and sharing computing, application, data and storage or network resources across dynamic and geographically dispersed organization [1]. Users can share grid resources by submitting computing tasks to grid system. Resources can be computers, storage space, instruments, soft- ware applications, and data, all connected through the Internet and a middleware layer that provides basic services for secu- rity, monitoring, resource management and so forth.
One of the main motivations of the grid computing para- digm has been the computational need for solving many com- plex problems from science, engineering, and business such as

1110-8665 © 2015 Production and hosting by Elsevier B.V. on behalf of Faculty of Computers and Information, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).

200	S. Selvi, D. Manimegalai


hard combinatorial optimization problems, protein folding and financial modelling [2–4]. As a cooperative environment of solving problem, it is necessary for the grids to develop efficient job scheduling schemes and resource management policies in regard to their objectives, scope, and structure. However, there exists different and somewhat conflicting QOS objectives for management and security policies among the hierarchy based grid entities such as grid users (applica- tions), grid resource administrative and virtual organization administrative. To increase the level of satisfaction of various grid entities, grid resource management system must use the scheduling strategy, which provides a compromise solution by considering several conflicting objectives.
Minimization of makespan is the most popular and exten- sively studied system-related optimization criterion. Makespan is an indicator of the general productivity of the grid system: Small values of makespan mean that the scheduler is providing good and efficient planning of tasks to resources. Considering makespan as a standalone criterion not necessar- ily implies the optimization of other objectives. Hence, it is necessary to devise the task scheduling algorithms in order to optimize both system-related and user-related objectives. One of the user-related objectives is the flowtime, which refers to the response time to the user submissions of task executions. Minimizing the value of flowtime means that the average response time of the grid system is being reduced. However, as discussed in [5], minimizing the makespan requires the most demanding jobs to be assigned to the fastest resource, at the expense of increasing the finish time of other jobs, and hence increasing flowtime. On the other hand, optimizing flowtime requires all jobs to finish quickly on the average, at the expense of having the most demanding jobs taking a longer completion time, thus increasing makespan. This justifies the search for algorithms that minimize both makespan and flowtime. Scheduling n jobs to m resources had been shown to be NP-complete [6]. Meta-heuristic approaches have shown their effectiveness for a wide variety of hard combinatorial problems and also for multi-objective optimization problems.
The main contribution of this work is the thorough exper- imental exploration of multiobjective VNS, with the problem specific neighborhood structures to solve the grid job schedul- ing problem, by minimizing the makespan and flowtime objec- tives. Efficient numerical results are reported in the experimental analysis performed on a set of 72 well known and large heterogeneous computing scheduling problem instances. The comparative study shows that the proposed MVNS is able to achieve high problem efficiency and outper- forming the results of Min–Min algorithm, SA and GRASP algorithms.
Variable Neighborhood Search is a simple and effective meta-heuristic method developed to efficiently deal with the hard optimization problem. VNS is a framework for building heuristics, based upon systematic changes of neighborhoods both in descent phase, to find a local minimum, and in pertur- bation phase to emerge from the corresponding valley. VNS has also demonstrated good performance on industrial appli- cations such as the design of an offshore pipeline network [7] and the pooling problem [8]. It has also been applied to real- world optimization problems, including optimization of a power plant cable layout [9], optical routing [10] and online
resources allocation problem for ATM networks [11]. Applications of VNS are diverse which include the areas such as location problems, data mining, graph problems, mixed integer problems, scheduling problems, vehicle routing problems and problems in biosciences and chemistry [12].

Related works

Due to the popularization of distributed computing and the growing use of heterogeneous clusters in the 1990s [13,14], the heterogeneous computing scheduling problem (HCSP) became especially important. Hence many researchers paid attention in solving the HCSP. But the multiobjective HCSP variants that propose the simultaneous optimization of several efficiency metrics have been scarcely studied. Krauter et al. [15] provided a useful survey on grid resource management sys- tems, in which most of the grid schedulers such as AppLes, Condor, Globus, Legion, Netsolve, Ninf and Nimrod use sim- ple batch scheduling heuristics. Braun et al. [16] studied the comparison of the performance of batch queuing heuristics, Tabu Search (TS), GA and Simulated Annealing (SA) to minimize the Makespan. The results revealed that GA achieved the best results compared with the batch queuing heuristics. Some of the job scheduling algorithms are nature-inspired, e.g., SA [17], Ant Colony Optimization [18], Particle Swarm Optimization [19], Differential Evolution (DE) [20], parallel Cross generational elitist selection, Heterogeneous recom- bination, and Cataclysmic mutation (pCHC) [21]. There are also non-nature-inspired metaheuristics, such as TS [22], Threshold Accepting (TA) [23], and VNS algorithm [24]. Xhafa [25] studied the performance of Memetic algorithm (MA) with different local search algorithms including TS and VNS. The experimental results revealed that MA + TS hybridization outperforms the combinations of MA with other local search algorithms. Abraham et al. [26] proposed the vari- able neighborhood particle swarm optimization algorithm. They empirically showed the performance of the proposed algorithm and its feasibility and effectiveness for scheduling work flow applications. Lusa and Potts [27] proposed the VNS algorithm for the constrained task allocation problem and compared the performance of the proposed algorithm with the other local search procedures. Moghaddam et al. [28] presented a hybrid GA and VNS to reduce the overall cost of task executions in grid environment.
Few works have considered the optimization of makespan and flowtime objectives for the scheduling problem [25,29]. Jacob et al. [30] studied the optimization of four objectives, namely makespan, resource utilization, time and cost of appli- cation for solving the HCSP. Xu et al. [31] experimented the Chemical Reaction Optimization (CRO) algorithm based grid job scheduling problem by considering makespan, flowtime and tardiness of the solution.
The VNS algorithm has received relatively little attention in solving the grid job scheduling problem. From the literature, it is known that VNS has been used in hybridization with other algorithms for such problems. To our knowledge, there are no other antecedents on applying explicit VNS to solve the heterogeneous computing scheduling problem tackled in this work, so the approach presented here is a novel approach in

Multiobjective Variable Neighborhood Search algorithm	201


this line of research. The performance of VNS algorithm depends on the performance of its neighborhood. Working in that line, the performance of VNS algorithm had been enriched by framing new problem specific neighborhoods, in order to solve the large scale heterogeneous computing scheduling problem instances. The multiobjective version of the scheduling problem studied in this work considers the opti- mization of an aggregation function that sums the makespan and flowtime of the solutions.

The Grid scheduling process and components

A computational grid is a hardware and software infrastruc- ture that provides dependable, consistent, pervasive and inex- pensive access to high end computational capabilities [1]. A Grid Scheduler (GS) receives applications from grid users, selects feasible nodes for these applications according to the acquired information from the Grid Information Service (GIS) module, and finally generates application-to-node map- pings, based on certain objective functions and predicted node performance. Scheduling algorithms are used in the GS for mapping tasks to resources in order to simultaneously opti- mize both systems-related (e.g. makespan) and user-related objectives (e.g. flowtime).
Fig. 1 depicts a model of grid scheduling system. Grid scheduler is referred as Meta scheduler in the literature [32,33] and which is not an indispensible component in the Grid infrastructure.
The role of the Grid information service is to provide infor- mation about the status of available nodes to Grid schedulers. GIS is responsible for collecting and predicting the node state information, such as CPU capacities, memory size, network bandwidth, software availabilities and load of a site in a partic- ular period. GIS can answer queries for node information or push information to subscribers.
Besides raw node information from GIS, application prop- erties such as approximate instruction quantity, memory and storage requirements, subtask dependency in a job and com- munication volumes and performance of a node for different application species are also necessary for making a feasible schedule. Application profiling (AP) is used to extract proper- ties of applications, while analogical benchmarking (AB) provides a measure of how well a node can perform a given type of job [34,35]. Cost estimation module computes the cost of candidate schedules. On the basis of knowledge from AP, AB and cost estimation module, the scheduler chooses those that can optimize the objective functions.
The Launching and Monitoring (LM) module is known as the ‘‘binder’’ which implements a finally-determined schedule by submitting applications to selected nodes, staging input data and executables if necessary, and monitoring the execu- tion of the applications [36].
A Local Resource Manager (LRM) is mainly responsible for two jobs: local scheduling inside a node domain, where not only jobs from exterior Grid users, but also jobs from the domain’s local users are executed, and reporting node information to GIS. For clarity, some key terminologies [37] are defined as follows.
Grid node
A grid node is an autonomous entity composed of one or
multiple nodes. The computational capacity of the node depends on its number of CPUs, amount of memory, basic storage space and other specifications.
Jobs and operations
A job is considered as a single set of multiple atomic
operations/tasks. Each operation will be typically allocated to execute on one single node without pre-emption. It has input and output data and processing requirements in order to complete its task.
Task scheduling
A task scheduling is the mapping of tasks to a selected
group of nodes which may be distributed in multiple adminis- trative domains.
This work deals with the static scheduling problem, in which all tasks can be independently performed. All the infor- mation about tasks and resources is gathered by the Grid scheduler before computing the schedule, and the task to resource assignment is not allowed to change during the execution. Static scheduler acts as the basic building block to develop a powerful dynamic scheduler, able to solve more complex scheduling problems. The concept of static scheduling frequently appears in many scientific research problems, especially in Single-Program Multiple-Data applications used for multimedia processing, scientific computing, data mining, parallel domain decomposition of numerical models for physical phenomena, etc. The independent tasks model also arises when different users submit their tasks to execute in volunteer-based and grid computing services and in parameter sweep applications, which are structured as a set of multiple experiments, each one executed with a different set of parameter values [21].

Scheduling problem formulation

The problem is formulated based on the ‘‘Expected time to compute’’ (ETC) model [16]. In a particular time interval, n independent jobs J1, J2, J3, .. . , Jn (expressed in millions of instructions) are submitted to Meta scheduler for scheduling, and at the same time, GIS locates m (usually n m) grid nodes G1, G2, G3,..., Gm, donating nodes. The processing power of a grid node is measured in terms of ‘‘millions of instructions per second’’. To address the problem, the follow-
ing assumptions are considered [31].

Any job Ji has to be processed in one of the grid nodes Gj
until completion.
Jobs come in batch mode.
A node cannot remain idle when jobs have been assigned to it.
A job can only be executed on one grid node in each interval.




202	S. Selvi, D. Manimegalai


















Figure 1	A logical Grid scheduling architecture.



When a node processes its tasks, there is no priority distinc- tions between the tasks assigned in the previous intervals and those assigned in the current interval.

scheduler computes n · m matrix ETC (ETC : J × G → R+) Based on the specifications of the nodes and tasks, Meta process job i. R+ denotes that the entry ETCij is the positive where entity ETCij represents the expected time for node j to real number. The multi-objective scheduling problem can be
formulated by defining the following notations and variables.
i index of tasks, i = 1; 2; .. . ; n,
j index of nodes, j = 1; 2; .. . ; m,
n number of tasks,
m number of heterogeneous nodes,
xi variable representing the node to execute the task i,
x(U) maximum allowed value of x ,
s.t.  x = {x1; x2; .. . ; xn}; ∀xi ∈ [1; m]; ∀i ∈ [1; n]; ∀j ∈ [1; m]
(3)
a = 0.75	(4)
ETCij > 0;	i = 1; 2; ... ; n; j = 1; 2; ... ; m	(5)
x(U) = m;	i = 1; 2; .. . ; n	(6)
x(L) = 1;	i = 1; 2; ... ; n	(7)
x(U) P x P x(L);	i = 1; 2; .. . ; n	(8)
Cj =	ETCij;	[i/xi = j]
[i/xi =j]
represents the tasks assigned to node j	(9)

i	i

x(L) minimum allowed value of xi,
ETCij expected time for node j to process task i,
Cj completion time of node j.

The job scheduling problem is considered as a bi-objective optimization problem, in which both makespan and flowtime are simultaneously minimized, which is possible since both parameters are measured in the same unit (time units).
fitness = a × Makespan + (1 — a)×  Flowtime	(1)
As flowtime has higher order of magnitude over makespan, it
is normalized by m. Actually, in this method the multi- objective task scheduling problem is converted to a single objective scheduling problem using the linear combination of both objectives. The objective function can be expressed as follows:
In this model, the objective function (2) minimizes both make-
span and flowtime. Constraint (3) defines the weighing factor [25]. Constraint (4) denotes a vector composed of n objective function parameters. Constraint (5) ensures that all entries of n · m ETC matrix are positive. Constraints (6) and (7) define the upper and lower boundary constraints of the objective function parameters respectively. Constraint (8) defines the upper and lower boundary constraints of the variable xi. Constraint (9) calculates the completion time of node j, which is defined as the time required for node j to complete all its assigned tasks.

Implementation of MVNS algorithm for scheduling jobs on computational grid

The following subsections deal with the representation of solu- tion, generation of initial solution, explanation of neighbor- hood  structures,  and  the  proposed  grid  job  scheduling

Minimize fitness; f(x)= a * max
[i/xi =j]
ETCij) +
(1 — a)
m
algorithm.

Solution representation

m
*	Cj
j=1
(2)
The solution is represented as an array of length equal to the number of jobs. The value corresponding to each position i

Multiobjective Variable Neighborhood Search algorithm	203

(a)
(b)

(c)


Figure 2	(a) Solution representation, (b) solution for the problem of 13 jobs and 3 Grid nodes, (c) mapping of jobs with Grid nodes for the solution given in (b).


in the array represents the node to which job i was allocated. The representation of the solution for the problem of schedul- ing 13 jobs to 3 Grid nodes is illustrated in Fig. 2. The first element of the array denotes the first job (J1) in a batch which is allocated to the Grid node 2; the second element of the array denotes the second job (J2) which is assigned to the Grid node 1, and so on.

Initial solution generation

The random initial solution is considered. Let x be the solution composed of n parameters, which is specified as
x = {x1; x2; .. . ; xn}. The parameters are subject to lower and
upper boundary constraints (Eqs. 3, 6, 7 and 8).

Neighborhood structures

The neighborhood structure defines the type of modifications a current solution can undergo and thus, different neighbor- hoods offer different ways to explore the solution space. In other words, definition of the proper neighborhood struc- tures leads to better exploration and exploitation of the solution space. Two attributes of the solutions are consid- ered to define six neighborhood structures so that a larger part of the solution space can be searched and the chance of finding good solutions will be enhanced. The attributes that can be altered from one solution to another are ‘‘Random assignment of grid nodes to jobs’’, and ‘‘Workload of grid nodes’’. The defined neighborhood struc- tures and corresponding moves associated with them are explained in detail below.

SwapMove
This neighborhood structure provides a set of neighbors for current solution x, based on exchanging the nodes assigned for the randomly selected three jobs.

Makespan-InsertionMove
This neighborhood assigns the Light node to the randomly selected job in the job list of Heavy node. Light and Heavy nodes are the nodes with minimum and maximum local make- span respectively, where the local makespan of individual node gives the completion time of its latest job. Maximum local makespan is the makespan of the solution.

InsertionMove
Neighbors generated using this neighborhood structure can be constructed using the assignment of random node G1 in G to the random job J1 in J.
Weightedmakespan-InsertionMove
Based on this neighborhood structure, solutions are generated by assigning the random node Lr to the random job J1 selected from the job list of the random node Hr. Lr and Hr are the nodes having local makespan value less than or equal to 0.25 and greater than or equal to 0.75 of the makespan of current solution respectively.

BestInsertionMove
This neighborhood maps the longest job J1 in the job list of
Heavy to the node having minimum execution time for J1.
To illustrate, a small scale job scheduling problem involving 3 nodes and 13 jobs is considered. The node speeds are 4, 3, 2
cycles/second, and the job lengths of 13 jobs are 6, 12, 16, 20,
24, 28, 30, 36, 40, 42, 48, 52, 60 cycles, respectively. Consider the initial solution with fitness 100.055, which is represented in Fig. 3a. The SwapMove operator swaps the nodes assigned for the selected three jobs J9, J2, and J4 (already mapped with G3, G2, and G1 respectively) and changes the fitness of the solution as 92.33 (Fig. 3b). Then the job J1 assigned for G3 (Heavy-with localmakespan 105) is mapped with the node G2 (Light-with localmakespan 28), according to the Makespan- InsertionMove neighborhood. Thus the fitness of the current solution becomes 90, which is illustrated in Fig. 3c. Then InsertionMove neighborhood selects the node G2 and maps with the Job J11 (already mapped with G1). This mapping changes the localmakespan of G1 and G2 (18 and 46 respec- tively), and also the fitness of current solution as 90.16 (Fig. 3d). According to the Weightedmakespan-InsertionMove, the job J13 from the joblist of G3 (considered as Hr) is assigned to the node G1 (considered as Lr). This neighborhood minimizes the fitness of current solution as 66.58 (Fig. 3e). Then the BestInsertionMove neighborhood selects the longest job J12 from G3 (considered as Heavy) and assigns with G1 (High speed node of J12) (Fig. 3f). Hence the final solution has the fitness 46, which is the optimal result for the example problem.

Proposed MVNS grid job scheduling algorithm

VNS is a metaheuristic which systematically exploits the idea of neighborhood change, both in descent to local minima and in escape from the valleys which contain them. The term VNS is referred to all local search based approaches that are centered on the principle of systematically exploring more than one type of neighborhood structures during the search. VNS iterates over more than one neighborhood structures until some stopping criterion is met. The basic scheme of the VNS was proposed by Mladenovic´and Hansen [38]. Its advanced principles for solving combinatorial optimization problems and applications were further introduced in [39–41] and recently in [42].

204	S. Selvi, D. Manimegalai


































































Figure 3	Explanation of different neighborhood structures (a) initial solution, (b) SwapMove, (c) Makespan-InsertionMove,
(d) InsertionMove, (e) Weightedmakespan-InsertionMove, and (f) BestInsertionMove.

Multiobjective Variable Neighborhood Search algorithm	205

tures denoted as Nk(k = 1, .. . , kmax). Nk(x) denotes the set VNS uses a finite set of pre-selected neighborhood struc- of solutions in the kth neighborhood of solution x. VNS
employs a local search to obtain a solution xsX, called as a local  minimum,  such  that  there  exists  no  solution
x'sNk(x) C X with f(x') < f(x). The local search can be per-
formed in different ways. The generic way consists of choosing
an initial solution x, finding a direction of descent from x within a neighborhood N(x), and moving to the minimum of f(x) within N(x) in the same direction. If there is no direction of descent, the heuristic stops; otherwise, it is iterated. After the local search, a change in the neighborhood structure is per- formed. Function NeighborhoodChange compares the value
f(x') of a new solution x' with the value f(x) of the incumbent
solution x obtained in the neighborhood k. If an improvement
is obtained, k is returned to its initial value and the incumbent solution is updated with the new one. Otherwise, the next neighborhood is considered.
The proposed MVNS grid job scheduling algorithm is sum- marized in Algorithm 1. VNS uses two parameters: tmax, which is the maximum CPU time allowed as the stopping condition, and kmax, which is the number of neighborhood structures
chooses a solution x' from the kth neighborhood of the incum- used. Step 4 of Algorithm 1, which is called shaking, randomly bent solution x. After improving this solution via the
PALSheuristic local search (Algorithm 3), a neighborhood change is employed. The fitness of the solution is evaluated based on the procedure described in the Algorithm 2.




Problem Aware Local Search (PALS)
Basic concept of this local search has been used in the litera- ture for the DNA fragment assembly problem [43], and the heterogeneous computing scheduling problem [44]. Working on a given schedule x, this algorithm selects a node Heavy to
jobs (where it = endheavy — startheavy + 1) of the node perform the search. The outer cycle iterates on ‘it’ number of (where jt = endres — startres + 1) of the randomly selected Heavy, while the inner cycle iterates on ‘jt’ number of jobs node G1, other than Heavy. For each pair (i, j), the double cycle
calculates the makespan variation when swapping the nodes assigned for JJ[i] and JJJ[j], where JJ and JJJ denote the job list of the nodes Heavy and G1 respectively. This neighbor-
hood stores the best improvement on the makespan value for the whole schedule found in the evaluation process of it · jt. At the end of the double cycle, the best move found so far is
applied. In this algorithm, startheavy and endheavy, startres
and endres are assigned with random values based on the length of array JJ and JJJ respectively (Refer lines 4 and 6 of Algorithm 3). The randomness introduced in the parameters endheavy and endres makes this local search to differ from the concept existing in the literature.
After the extensive experimentation, the combination of SwapMove, Makespan-InsertionMove and BestInsertionMove was selected for the proposed MVNS. The details of the neigh- borhood structures are given in Algorithms 4, 5, and 6. The

206	S. Selvi, D. Manimegalai


parameters PALS_maxiter and kmax are set to 5 and 3 respectively.



Computational experiments

When facing the heterogeneous computing scheduling prob- lem, researchers have often used the test instances proposed by Braun et al. [16], following the ETC performance estima- tion model by Ali et al. [45]. ETC takes into account three key properties: machine heterogeneity, task heterogeneity, and consistency. Machine heterogeneity evaluates the varia- tion of execution times for a given task across the heteroge- neous computing nodes, while task heterogeneity represents the variation of the tasks execution times for a given machine. Regarding the consistency property, in a consistent scenario, whenever a given node Gj executes any task Ji faster than other machine Gk, and then node Gj executes all tasks faster than machine Gk. In an inconsistent scenario, a given machine Gj may be faster than machine Gk when executing some tasks and slower for others. Finally, a semiconsistent scenario models those inconsistent systems that include a consistent subsystem.
Nesmachnow et al. [21] proposed a test suite of several large dimension heterogeneous computing scheduling problem instances, in order to model large heterogeneous computing clusters and medium sized grid infrastructures. All test instances of each dimension are composed of m grid nodes and n jobs, which is referred as the configuration m · n.
Each dimension has 24 test instances regarding all the hetero- geneity and consistency combinations, twelve of them consid- ering the parameterization values from Ali et al. [45], and twelve using the values from Braun et al. [16]. The instances are named as M.u_x_yyzz, where the first letter (M) describes the heterogeneity model (A for Ali, and B for Braun), u means uniform distribution (in the ETC matrix generation), x is the type of consistency (c – consistent, i – inconsistent and s means semi-consistent), and yy and zz indicate the job and machine heterogeneity (hi – high, and lo – low).
This paper considers the test instances proposed by Nesmachnow et al., with dimension 1024 · 32, 2048 · 64, and 4096 · 128 [21]. The grid job scheduling algorithm was developed using MATLAB R2010a and run on an Intel(R) Core(TM) i5 2.67 GHz CPU with 4 GB RAM. As the problem size increases, the evaluation of the fitness function consumes larger computing time than the application of neighborhood operators. The maximum running time of the algorithm is not set to uniform value for all configurations. The stopping condition tmax is set to 150, 300, and 700 s for 1024 · 32,
2048 · 64, and 4096 · 128 dimension problems respectively.

Results and discussion

This section discusses the experimental results of applying the MVNS algorithm to solve the grid job scheduling problem. The MVNS results are compared with the deterministic heuris- tic Min–Min algorithm, Simulated Annealing algorithm and GRASP algorithm. For SA, Initial temperature, temperature reduction factor and reannealing interval are set to 50, 0.95 and 10 respectively. GRASP was experimented with PALS heuristic (Algorithm 3) in the local search phase, in which PALS_maxiter and threshold parameter are set to 50 and 0.2 respectively.
Each experiment (for each algorithm) was repeated 50 times with different random seeds. The fitness values of the best solu- tions throughout the optimization run were recorded. In the computation experiments, 72 test instances were solved with SA, GRASP, Min–Min algorithm and MVNS algorithm. The experimental results displayed in bold fonts indicate that the corresponding solution is the best solution obtained out of all algorithms considered for comparison along with MVNS algorithm. The overall best result produced by the MVNS algorithm compared with all algorithms is represented in bold and italic.
The improvement of an algorithm over another is com- puted using Eq. (10).
Improvement (%)= d1 — d2 × 100%	(10)
2
where d1 and d2 are the fitness values of two different algorithms.

Solution quality
Tables 1–3 show the MVNS result for 1024 · 32, 2048 · 64, and 4096 · 128 configurations. The best, average, and stan- dard deviation on the fitness results achieved during the exper- imentation of Min–Min, SA, GRASP and MVNS algorithm are reported in Tables 1–3. From Tables 1–3, it is observed that MVNS produces a good quality schedule for all the test




























210	S. Selvi, D. Manimegalai


instances. Min–Min algorithm gave the second best mapping by yielding better solutions for all the test instances. As the numbers of jobs and resources increase, the performance of Min–Min algorithm improves significantly. SA and GRASP yielded the better mapping for the consistent test cases. The percentage improvement of MVNS over Min–Min, SA and GRASP is reported in column 12, 13 and 14 of Tables 1–3 respectively. Min–Min, SA and GRASP gave better schedules for the semiconsistent and consistent test cases. The percentage improvement of MVNS over Min–Min, SA and GRASP is found to be 23.5%, 82.3% and 83.6% respectively, by consid- ering 72 test cases of various configurations.
Fig. 4 shows the average improvement of MVNS over other heuristic algorithms. It is revealed from Fig. 4 that the percent- age improvement of MVNS is gradually increased when the problem dimension grows for SA and GRASP. Even though MVNS has better improvement over Min–Min algorithm, the percentage of improvement is gradually decreased for increasing problem dimension.

Speed of convergence
Fig. 5 illustrates the performance of MVNS, GRASP and SA algorithms during the search process, for the test case of Braun’s semi-consistent, low job and low machine heterogene- ity model with the configuration of 1024 · 32. It is found that the MVNS algorithm converges faster than the considered multi-objective algorithms with the exploration of shorter schedule.

Performance assessment
The comparison of two sets of non-dominated solutions obtained through two multi-objective optimization algorithms is important. In the literature, many performance assessment metrics for the multi-objective algorithms have been proposed [46–50]. This work makes use of the hyper volume difference
indicator I— for the performance assessment.
The reference set, R had been constructed by merging all of
the archival non-dominated solutions found by each of the
Then the hyper volume difference indicator I— had been used algorithms for a given configuration across 50 runs [51]. to measure the differences between non-dominated fronts gen-
erated by the algorithms and the reference set R [51,52]. The objective values are normalized to find the hyper volume



















Figure 5	Convergence of MVNS, GRASP and SA.


















Figure 6	I— measure of three algorithms for 1024 · 32.












Figure 7	I— measure of three algorithms for 2048 · 64.
difference indicator [53]. I— measures the portion of the objec- tive space that is dominated by R. The lower the value of I—,
Figure 4	Average improvements of MVNS over other heuristics.	the better the algorithm performs [51].

Multiobjective Variable Neighborhood Search algorithm	211



















Figure 8  I— measure of three algorithms for 4096 · 128.
The performance assessment plots had been drawn for the
Ali’s consistent, high job and high machine heterogeneity model, Braun’s inconsistent, low job and high machine hetero- geneity model, and Braun’s semi-consistent, high job and high machine heterogeneity model with the configuration of 1024 · 32, 4096 · 128 and 4096 · 128 respectively.
Box plots for different configurations clearly prove that MVNS algorithm is better than GRASP and SA (Figs. 6–8). From the simulation result of MVNS algorithm in solving grid job scheduling problems, it is seen that the performance of MVNS algorithm is much better than other optimization techniques mentioned in this study.

Conclusions

Grid computing has emerged as one of the hot research areas in the field of computer networking. Scheduling, which decides how to distribute tasks to resources, is one of the most impor- tant issues. This paper presents the VNS algorithm with novel local search for grid job scheduling problem to minimize makespan and flowtime. Extensive computational experiments have been devised to study the performance of the proposed algorithm. The performance of MVNS was evaluated with other optimization algorithms, for a large variety of test cases, and with the consideration of the heterogeneous environment of different configurations. The results of MVNS are better for most of the instances. The computational results demon- strate the superiority of the proposed MVNS in solving the grid job scheduling problem and its computational efficiency. In future work, VNS algorithm for multi-objective complex scheduling problems and workflow model of grid scheduling problems will be developed.

References

Foster I, Kesselman C, Tuecke. The anatomy of the grid: enabling scalable virtual organizations. Int J Supercomput Appl 2001;15: 200–20.
Luna F, Nebro AJ, Alba E. Observations in using grid-enabled technologies for solving multi-objective optimization problems. Parallel Comput 2006;32:377–93.

Talbi EG. Parallel combinatorial optimization. USA: John Wiley & Sons; 2006.
Talbi EG, Zomaya A. Grids for bioinformatics and computa- tional biology. USA: John Wiley & Sons; 2007.
Abraham A, Liu H, Grosan C, Xhafa F. Nature inspired metaheuristics for gird scheduling: single and multi-objective optimization approaches. In: Xhafa F, Abraham A, editors. Metaheuristics for scheduling in distributed computing environ- ments, vol. 146. Berlin (Germany): Springer; 2008. p. 247–72.
Ibarra OH, Ki CE. Heuristic algorithms for scheduling indepen- dent tasks on nonidentical processors. J ACM 1977;24:280–9.
Brimberg J, Hansen P, Lih KW, Mladenovi´c N, Breton M. An oil
pipeline design problem. Oper Res 2003;51:228–39.
Audet C, Brimberg J, Hansen P, Mladenovi´c N. Pooling problem:
alternate formulation and solution methods. Manage Sci 2004;50: 761–76.
Costa MC, Monclar FR, Zrikem M. Variable neighborhood decomposition search for the optimization of power plant cable layout. J Intell Manuf 2005;13:353–65.
Meric L, Pesant G, Pierre S. Variable neighborhood search for optical routing in networks using latin routers. Ann Te´le´commun/ Ann Telecommun 2004;59:261–86.
Loudni S, Boizumault P, David P. On-line resources allocation for ATM networks with rerouting. Comput Oper Res 2006;33: 2891–917.
Hansen P, Mladenovic´N, Moreno Pe´rez JA. Variable neighbor- hood search: methods and applications. 4OR Quart J Oper Res 2008;6:319–60.
Eshaghian M. Heterogeneous computing. Norwood: Artech House; 1996.
Freund R, Sundaram V, Gottlieb A, Hwang K, Sahni S. Special issue on heterogeneous processing. J Parallel Distrib Comput 1994;21(3):255–6.
Krauter K, Buyya R, Maheswaran M. A taxonomy and survey of grid resource management systems for distributed computing. Software-Pract Exper 2002;32:135–64.
Braun TD, Siegel HJ, Beck N, Boloni LL, Maheswaran M, Reuther AI, Robertson JP, Theys MD, Yao B. A comparison of eleven static heuristics for mapping a class of independent tasks onto heterogeneous distributed computing systems. J Parallel Distr Com 2001;61(6):810–37.
Fidanova S. Simulated annealing for grid scheduling problem. In: Proceedings of IEEEJVA international symposium on modern computing. Bulgaria: IEEE Computer Society; 2006. p. 41–5.
Chang R, Chang J, Lin P. An ANT algorithm for balanced job scheduling in grids. Future Gener Comput Syst 2009;25:20–7.
Liu H, Abraham A, Hassanien AE. Scheduling jobs on compu- tational grids using a fuzzy particle swarm optimization algo- rithm. Future Gener Comput Syst 2010;26:1336–43.
Selvi S, Manimegalai D, Suruliandi A. Efficient job scheduling on computational grid with differential evolution algorithm. Int J Comput Theory Eng 2011;3:277–81.
Nesmachnow S, Alba E, Cancela H. Scheduling in heterogeneous computing and grid environments using a parallel CHC evolu- tionary algorithm. Comput Intell 2012;28:131–55.
Xhafa F, Carretero J, Dorronsora B, Alba E. Tabu search algorithm for scheduling independent jobs in computational grids. Comput Inform J 2009;28:237–49.
Dueck G, Scheuer T. Threshold accepting: a general purpose optimization algorithm appearing superior to simulated anneal- ing. J Comput Phys 1990;90:161–75.
Wen Y, Xu H, Yang J. A heuristic-based hybrid genetic- variable neighborhood search algorithm for task scheduling in heterogeneous multiprocessor system. Inform Sci 2011;181: 567–81.
Xhafa F. A hybrid evolutionary heuristic for job scheduling on computational grids. Stud Comput Intell 2007;75:269–311.

212	S. Selvi, D. Manimegalai


Abraham A, Liu H, Zhao M. Particle swarm scheduling for work- flow applications in distributed computing environments. Stud Comput Intell 2008;128:327–42.
Lusa A, Potts CN. A variable neighbourhood search algorithm for the constrained task allocation problem. J Oper Res Soc 2008;59:812–22.
Moghaddam K, Khodadadi F, Entezari-Maleki R. A hybrid genetic algorithm and variable neighborhood search for task scheduling problem in grid environment. Proc Eng 2014;29:3808–14, International workshop on information and electronics engineering.
Xhafa F, Alba E, Dorronsoro B. Efficient batch job scheduling in grids using cellular memetic algorithms. J Math Model Alg 2008;7(2):217–36.
Jacob W, Quinte A, Stucky KU, Sub W. Fastmulti-objective scheduling of jobs to constrained resources using a hybrid evolutionary algorithm. In: Parallel problem solving from nature. Lecture notes in computer science, vol. 5199. Berlin: Springer; 2008. p. 1031–40.
Xu J, Lam AYS, Li VOK. Chemical reaction optimization for task scheduling in grid computing. IEEE Trans Parallel Distr Syst 2011;22:1624–31.
Schopf J. Ten actions when super scheduling, document of scheduling working group. Global Grid Forum; 2001. <http:// www.ggf.org/documents/GFD.4.pdf>.
Mateescu G. Quality of service on the grid via metascheduling with resource co-scheduling and co-reservation. Int J High Perform Comput Appl 2003;17:209–18.
Khokhar AA, Prasanna VK, Shaaban ME, Wang CL. Heterogeneous computing: challenges and opportunities. IEEE Comput 1993;26:18–27.
Siegel HJ, Dietz HG, Antonio JK. Software support for hetero- geneous computing. ACM Comput Surv 1996;28:237–9.
Cooper K, Dasgupta A, Kennedy K, Koelbel C, Mandal A, Marin G, et al. New grid scheduling and rescheduling methods in GrADS project. In: Proceeding of the 18th international parallel and distributed processing symposium (IPDPS ’04). Santa Fe (New Mexico, USA); April 2004. p. 199–206.
Dong F, Akl Selim G. Scheduling algorithms for grid computing: state of the art and open problems. Technical report 2006-504. Ontario, Kingston: Queen’s University, School of Computing
<ftp.qucis.queensu.ca/TechReports/Reports/2006-504.pdf>.
Mladenovic´N, Hansen P. Variable neighborhood search. Comput
Oper Res 1997;24:1097–100.
Mladenovic´N, Hansen P. An introduction to variable neighbor- hood search. In: MetaHeuristics: advances and trends in local search paradigms for optimization. Boston: Kluwer Academic; 1999. p. 449–67.
Mladenovic´N, Hansen P. Variable neighborhood search: princi- ples and applications. Euro J Oper Res 2001;130:449–67.
Hansen P, Mladenovic´N. An introduction to variable neighbor- hood search. Handbook of metaheuristics. Amsterdam: Kluwer; 2003 [chapter 6].
Hansen P, Mladenovic´N, Moreno Pe´rez J. Developments of variable neighborhoodsearch. Ann Oper Res 2010;175(1): 367–407.
Alba E, Luque G. A new local search algorithm for the DNA fragment assembly problem. In: Proceedings of 7th European conference on evolutionary computation in combinatorial opti- mization. Lecture notes in computer science, vol. 4446. Springer; 2007. p. 1–12.
Nesmachnow S, Cancela H, Alba E. A parallel micro evolutionary algorithm for heterogeneous computing and grid scheduling. Appl Soft Comput 2012;12:626–39.
Ali S, Siegel H, Maheswaran M, Hensgen D. Task execution time modelling for heterogeneous computing systems. In: Proceedings of the 9th heterogeneous computing workshop. Washington (USA): IEEE Press; 2000. p. 185.
Deb K, Jain S. Running performance metrics for evolutionary multi-objective optimization. Technical report; 2002. doi: 10.1.1.9.159.
Fonseca CM, Knowles JD, Thiele L, Zitzler E. A tutorial on the performance assessment of stochastic multiobjective optimizers. In: Third international conference on evolutionary multi-criterion optimization (EMO), vol. 216; 2005.
Hansen MP, Jaszkiewicz A. Evaluating the quality of approxi- mations to the non-dominated set. IMM, Department of Mathematical Modelling, Technical University of Denmark; 1998
Zitzler E, Deb K, Thiele L. Comparison of multiobjective evolutionary algorithms: empirical results. Evolut Comput 2000;8(2):173–95.
Rego MF, Souza MJF, Coelho IM, Arroyo JEC. Multi-objective algorithms for the single machine scheduling problem with sequence-dependent family setups. In: The online conference on soft computing in industrial applications anywhere on earth; 2012.
Talukder AKMKA, Kirley M, Buyya R. Multiobjective differen- tial evolution for scheduling workflow applications on global Grids. Concurr Comp: Pract Exper 2009;21(13):1742–56.
Huband S, Hingston P, Barone L, While L. A review of multiobjective test problems and a scalable test problem toolkit. IEEE Trans Evolut Comput 2006;10(5):477–506.
Huang VL, Qin AK, Deb K, Zitzler E, Suganthan PN, Liang JJ, et al. Problem definitions for performance assessment on multi- objective optimization algorithms. Technical report. Nanyang Technological University, Singapore; 2007.
